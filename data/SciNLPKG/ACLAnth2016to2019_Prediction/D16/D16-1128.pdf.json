{"title": [{"text": "Neural Text Generation from Structured Data with Application to the Biography Domain", "labels": [], "entities": [{"text": "Neural Text Generation", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8161835471789042}]}], "abstractContent": [{"text": "This paper introduces a neural model for concept-to-text generation that scales to large, rich domains.", "labels": [], "entities": [{"text": "concept-to-text generation", "start_pos": 41, "end_pos": 67, "type": "TASK", "confidence": 0.7495886981487274}]}, {"text": "It generates biographical sentences from fact tables on anew dataset of biographies from Wikipedia.", "labels": [], "entities": []}, {"text": "This set is an order of magnitude larger than existing resources with over 700k samples and a 400k vocabulary.", "labels": [], "entities": []}, {"text": "Our model builds on conditional neural language models for text generation.", "labels": [], "entities": [{"text": "text generation", "start_pos": 59, "end_pos": 74, "type": "TASK", "confidence": 0.7640486657619476}]}, {"text": "To deal with the large vocabulary, we extend these models to mix a fixed vocabulary with copy actions that transfer sample-specific words from the input database to the generated output sentence.", "labels": [], "entities": []}, {"text": "To deal with structured data, we allow the model to embed words differently depending on the data fields in which they occur.", "labels": [], "entities": []}, {"text": "Our neural model significantly outperforms a Templated Kneser-Ney language model by nearly 15 BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 94, "end_pos": 98, "type": "METRIC", "confidence": 0.9984021782875061}]}], "introductionContent": [{"text": "Concept-to-text generation renders structured records into natural language (.", "labels": [], "entities": [{"text": "Concept-to-text generation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7046641707420349}]}, {"text": "A typical application is to generate a weather forecast based on a set of structured meteorological measurements.", "labels": [], "entities": []}, {"text": "In contrast to previous work, we scale to the large and very diverse problem of generating biographies based on Wikipedia infoboxes.", "labels": [], "entities": []}, {"text": "An infobox is a fact table describing a person, similar to a person subgraph in a knowledge base.", "labels": [], "entities": []}, {"text": "Similar generation applications include the generation of product descriptions based on a catalog of millions of items with dozens of attributes each.", "labels": [], "entities": []}, {"text": "Previous work experimented with datasets that contain only a few tens of thousands of records such as WEATHERGOV or the ROBOCUP dataset, while our dataset contains over 700k biographies from * R\u00e9mi performed this work while interning at Facebook.", "labels": [], "entities": [{"text": "WEATHERGOV", "start_pos": 102, "end_pos": 112, "type": "DATASET", "confidence": 0.8428784012794495}, {"text": "ROBOCUP dataset", "start_pos": 120, "end_pos": 135, "type": "DATASET", "confidence": 0.7738804221153259}]}, {"text": "Furthermore, these datasets have a limited vocabulary of only about 350 words each, compared to over 400k words in our dataset.", "labels": [], "entities": []}, {"text": "To tackle this problem we introduce a statistical generation model conditioned on a Wikipedia infobox.", "labels": [], "entities": [{"text": "statistical generation", "start_pos": 38, "end_pos": 60, "type": "TASK", "confidence": 0.7281351685523987}, {"text": "Wikipedia infobox", "start_pos": 84, "end_pos": 101, "type": "DATASET", "confidence": 0.9417856335639954}]}, {"text": "We focus on the generation of the first sentence of a biography which requires the model to select among a large number of possible fields to generate an adequate output.", "labels": [], "entities": []}, {"text": "Such diversity makes it difficult for classical count-based models to estimate probabilities of rare events due to data sparsity.", "labels": [], "entities": []}, {"text": "We address this issue by parameterizing words and fields as embeddings, along with a neural language model operating on them (.", "labels": [], "entities": []}, {"text": "This factorization allows us to scale to a larger number of words and fields than, or where the number of parameters grows as the product of the number of words and fields.", "labels": [], "entities": []}, {"text": "Moreover, our approach does not restrict the relations between the field contents and the generated text.", "labels": [], "entities": []}, {"text": "This contrasts with less flexible strategies that assume the generation to follow either a hybrid alignment tree, a probabilistic context-free grammar (, or a tree adjoining grammar.", "labels": [], "entities": []}, {"text": "Our model exploits structured data both globally and locally.", "labels": [], "entities": []}, {"text": "Global conditioning summarizes all information about a personality to understand highlevel themes such as that the biography is about a scientist or an artist, while as local conditioning describes the previously generated tokens in terms of the their relationship to the infobox.", "labels": [], "entities": []}, {"text": "We analyze the effectiveness of each and demonstrate their complementarity.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our neural network model (Section 4) is designed to generate sentences from tables for large-scale problems, where a diverse set of sentence types need to be generated.", "labels": [], "entities": []}, {"text": "Biographies are therefore a good framework to evaluate our model, with Wikipedia offering a large and diverse dataset.", "labels": [], "entities": []}, {"text": "We introduce anew dataset for text generation, WIKIBIO, a corpus of 728,321 articles from English Wikipedia.", "labels": [], "entities": [{"text": "text generation", "start_pos": 30, "end_pos": 45, "type": "TASK", "confidence": 0.7403842359781265}, {"text": "WIKIBIO", "start_pos": 47, "end_pos": 54, "type": "DATASET", "confidence": 0.8793577551841736}]}, {"text": "It comprises all biography articles listed by WikiProject Biography 1 which also have a table (infobox).", "labels": [], "entities": [{"text": "WikiProject Biography 1", "start_pos": 46, "end_pos": 69, "type": "DATASET", "confidence": 0.8450433810551962}]}, {"text": "We extract and tokenize the first sentence of each article with Stanford CoreNLP ().", "labels": [], "entities": [{"text": "Stanford CoreNLP", "start_pos": 64, "end_pos": 80, "type": "DATASET", "confidence": 0.9385926127433777}]}, {"text": "All numbers are mapped to a special token, except for years which are mapped to different special token.", "labels": [], "entities": []}, {"text": "Field values from tables are similarly tokenized.", "labels": [], "entities": []}, {"text": "summarizes the dataset statistics: on average, the first sentence is twice as short as the table (26.1 vs 53.1 tokens), about a third of the sentence tokens (9.5) also occur in the table.", "labels": [], "entities": []}, {"text": "The final corpus has been divided into three sub-parts to provide training (80%), validation (10%) and test sets (10%).", "labels": [], "entities": [{"text": "validation", "start_pos": 82, "end_pos": 92, "type": "TASK", "confidence": 0.8742994070053101}]}, {"text": "The dataset is available for download 2 .  We use different metrics to evaluate our models.", "labels": [], "entities": []}, {"text": "Performance is first evaluated in terms of perplexity which is the standard metric for language modeling.", "labels": [], "entities": []}, {"text": "Generation quality is assessed automatically with BLEU-4, ROUGE-4 (F-measure) and NIST-4 3).", "labels": [], "entities": [{"text": "BLEU-4", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9990794658660889}, {"text": "ROUGE-4", "start_pos": 58, "end_pos": 65, "type": "METRIC", "confidence": 0.9970526695251465}, {"text": "F-measure", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.830292820930481}, {"text": "NIST-4", "start_pos": 82, "end_pos": 88, "type": "DATASET", "confidence": 0.7539419531822205}]}], "tableCaptions": [{"text": " Table 1: BLEU, ROUGE, NIST and perplexity without copy actions (first three rows) and with copy actions (last five rows). For  neural models we report \"mean + \u2212 standard deviation\" for five training runs with different initialization. Decoding beam width is 5.  Perplexities marked with and  \u2020 are not directly comparable as the output vocabularies differ slightly.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9989864230155945}, {"text": "ROUGE", "start_pos": 16, "end_pos": 21, "type": "METRIC", "confidence": 0.987699031829834}, {"text": "Decoding beam width", "start_pos": 236, "end_pos": 255, "type": "METRIC", "confidence": 0.717102994521459}]}]}