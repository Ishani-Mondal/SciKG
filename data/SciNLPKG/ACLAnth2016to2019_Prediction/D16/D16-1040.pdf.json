{"title": [{"text": "Relation Schema Induction using Tensor Factorization with Side Information", "labels": [], "entities": [{"text": "Relation Schema Induction", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.9270074367523193}]}], "abstractContent": [{"text": "Given a set of documents from a specific domain (e.g., medical research journals), how do we automatically build a Knowledge Graph (KG) for that domain?", "labels": [], "entities": []}, {"text": "Automatic identification of relations and their schemas, i.e., type signature of arguments of relations (e.g., un-dergo(Patient, Surgery)), is an important first step towards this goal.", "labels": [], "entities": []}, {"text": "We refer to this problem as Relation Schema Induction (RSI).", "labels": [], "entities": [{"text": "Relation Schema Induction (RSI)", "start_pos": 28, "end_pos": 59, "type": "TASK", "confidence": 0.8047038813432058}]}, {"text": "In this paper, we propose Schema Induction using Coupled Tensor Factorization (SICTF), a novel tensor factorization method for relation schema induction.", "labels": [], "entities": [{"text": "Schema Induction", "start_pos": 26, "end_pos": 42, "type": "TASK", "confidence": 0.8382835984230042}, {"text": "relation schema induction", "start_pos": 127, "end_pos": 152, "type": "TASK", "confidence": 0.8401687145233154}]}, {"text": "SICTF factorizes Open Information Extraction (OpenIE) triples extracted from a domain corpus along with additional side information in a principled way to induce relation schemas.", "labels": [], "entities": [{"text": "SICTF factorizes Open Information Extraction (OpenIE) triples extracted", "start_pos": 0, "end_pos": 71, "type": "TASK", "confidence": 0.83769371509552}]}, {"text": "To the best of our knowledge, this is the first application of tensor factorization for the RSI problem.", "labels": [], "entities": [{"text": "RSI problem", "start_pos": 92, "end_pos": 103, "type": "TASK", "confidence": 0.9452728927135468}]}, {"text": "Through extensive experiments on multiple real-world datasets, we find that SICTF is not only more accurate than state-of-the-art base-lines, but also significantly faster (about 14x faster).", "labels": [], "entities": [{"text": "SICTF", "start_pos": 76, "end_pos": 81, "type": "TASK", "confidence": 0.6733288168907166}]}], "introductionContent": [{"text": "Over the last few years, several techniques to build Knowledge Graphs (KGs) from large unstructured text corpus have been proposed, examples include NELL ( and Google Knowledge Vault ().", "labels": [], "entities": []}, {"text": "Such KGs consist of millions of entities (e.g., Oslo, Norway, etc.), their types (e.g., isA(Oslo, City), isA(Norway, Country)), and relationships among them (e.g., cityLocatedInCountry(Oslo, Norway)).", "labels": [], "entities": []}, {"text": "These KG construction techniques are called ontology-guided as they require as input list of relations, their schemas (i.e., their type signatures, e.g., cityLocatedInCountry(City, Country)), and seed instances of each such relation.", "labels": [], "entities": [{"text": "KG construction", "start_pos": 6, "end_pos": 21, "type": "TASK", "confidence": 0.8693449795246124}]}, {"text": "Listing of such relations and their schemas are usually prepared by human domain experts.", "labels": [], "entities": []}, {"text": "The reliance on domain expertise poses significant challenges when such ontology-guided KG construction techniques are applied to domains where domain experts are either not available or are too expensive to employ.", "labels": [], "entities": [{"text": "KG construction", "start_pos": 88, "end_pos": 103, "type": "TASK", "confidence": 0.8528530895709991}]}, {"text": "Even when such a domain expert maybe available fora limited time, she maybe able to provide only a partial listing of relations and their schemas relevant to that particular domain.", "labels": [], "entities": []}, {"text": "Moreover, this expert-mediated model is not scalable when new data in the domain becomes available, bringing with it potential new relations of interest.", "labels": [], "entities": []}, {"text": "In order to overcome these challenges, we need automatic techniques which can discover relations and their schemas from unstructured text data itself, without requiring extensive human input.", "labels": [], "entities": []}, {"text": "We refer to this problem as Relation Schema Induction (RSI).", "labels": [], "entities": [{"text": "Relation Schema Induction (RSI)", "start_pos": 28, "end_pos": 59, "type": "TASK", "confidence": 0.8047038813432058}]}, {"text": "In contrast to ontology-guided KG construction techniques mentioned above, Open Information Extraction (OpenIE) techniques) aim to extract surface-level triples from unstructured text.", "labels": [], "entities": [{"text": "KG construction", "start_pos": 31, "end_pos": 46, "type": "TASK", "confidence": 0.8276650309562683}, {"text": "Open Information Extraction (OpenIE)", "start_pos": 75, "end_pos": 111, "type": "TASK", "confidence": 0.741342082619667}]}, {"text": "Such OpenIE triples may provide a suitable starting point for the RSI problem.", "labels": [], "entities": [{"text": "RSI problem", "start_pos": 66, "end_pos": 77, "type": "TASK", "confidence": 0.8985495269298553}]}, {"text": "In fact, KB-LDA,  a topic modeling-based method for inducing an ontology from SVO (Subject-Verb-Object) triples was recently proposed in.", "labels": [], "entities": []}, {"text": "We note that ontology induction () is a more general problem than RSI, as we are primarily interested in identifying categories and relations from a domain corpus, and not necessarily any hierarchy over them.", "labels": [], "entities": [{"text": "ontology induction", "start_pos": 13, "end_pos": 31, "type": "TASK", "confidence": 0.8334705829620361}]}, {"text": "Nonetheless, KB-LDA maybe used for the RSI problem and we use it as a representative of the state-of-the-art of this area.", "labels": [], "entities": [{"text": "RSI problem", "start_pos": 39, "end_pos": 50, "type": "TASK", "confidence": 0.9177035689353943}]}, {"text": "Instead of a topic modeling approach, we take a tensor factorization-based approach for RSI in this paper.", "labels": [], "entities": [{"text": "RSI", "start_pos": 88, "end_pos": 91, "type": "TASK", "confidence": 0.9463417530059814}]}, {"text": "Tensors area higher order generalization of matrices and they provide a natural way to represent OpenIE triples.", "labels": [], "entities": []}, {"text": "Applying tensor factorization methods over OpenIE triples to identify relation schemas is a natural approach, but one that has not been explored so far.", "labels": [], "entities": []}, {"text": "Also, a tensor factorizationbased approach presents a flexible and principled way to incorporate various types of side information.", "labels": [], "entities": []}, {"text": "Moreover, as we shall see in Section 4, compared to state-of-the-art baselines such as KB-LDA, tensor factorization-based approach results in better and faster solution for the RSI problem.", "labels": [], "entities": [{"text": "RSI problem", "start_pos": 177, "end_pos": 188, "type": "TASK", "confidence": 0.9254423379898071}]}, {"text": "In this paper, we make the following contributions: \u2022 We present Schema Induction using Coupled Tensor Factorization (SICTF), a novel and principled tensor factorization method which jointly factorizes a tensor constructed out of OpenIE triples extracted from a domain corpus, along with various types of additional side information for relation schema induction.", "labels": [], "entities": [{"text": "relation schema induction", "start_pos": 337, "end_pos": 362, "type": "TASK", "confidence": 0.7288808822631836}]}, {"text": "\u2022 We compare SICTF against state-of-the-art baseline on various real-world datasets from diverse domains.", "labels": [], "entities": []}, {"text": "We observe that SICTF is not only significantly more accurate than such baselines, but also much faster.", "labels": [], "entities": [{"text": "SICTF", "start_pos": 16, "end_pos": 21, "type": "TASK", "confidence": 0.7069953083992004}, {"text": "accurate", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9921327233314514}]}, {"text": "For example, SICTF achieves 14x speedup over KB-LDA).", "labels": [], "entities": []}, {"text": "\u2022 We have made the data and code available 1 .", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we evaluate performance of different methods on the Relation Schema Induction (RSI) task.", "labels": [], "entities": [{"text": "Relation Schema Induction (RSI) task", "start_pos": 69, "end_pos": 105, "type": "TASK", "confidence": 0.8366363559450422}]}, {"text": "Specifically, we address the following questions.", "labels": [], "entities": []}, {"text": "\u2022 Which method is most effective on the RSI task?", "labels": [], "entities": [{"text": "RSI task", "start_pos": 40, "end_pos": 48, "type": "TASK", "confidence": 0.923284113407135}]}, {"text": "(Section 4.3.1) \u2022 How important are the additional side information for RSI?", "labels": [], "entities": [{"text": "RSI", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.786494255065918}]}, {"text": "(Section 4.3.2) \u2022 What is the importance of non-negativity in RSI with tensor factorization?", "labels": [], "entities": []}, {"text": "(Section 4.3.3)  Datasets: We used two datasets for the experiments in this paper, they are summarized in.", "labels": [], "entities": []}, {"text": "For MEDLINE dataset, we used Stanford CoreNLP () for coreference resolution and Open IE v4.0 9 for triple extraction.", "labels": [], "entities": [{"text": "MEDLINE dataset", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.8552785515785217}, {"text": "Stanford CoreNLP", "start_pos": 29, "end_pos": 45, "type": "DATASET", "confidence": 0.9189779758453369}, {"text": "coreference resolution", "start_pos": 53, "end_pos": 75, "type": "TASK", "confidence": 0.9578868448734283}, {"text": "triple extraction", "start_pos": 99, "end_pos": 116, "type": "TASK", "confidence": 0.749291330575943}]}, {"text": "Triples with Noun Phrases that have Hypernym information were retained.", "labels": [], "entities": []}, {"text": "We obtained the StackOverflow triples directly from the authors of, which were also prepared using a very similar process.", "labels": [], "entities": []}, {"text": "In both datasets, we use corpus frequency of triples for constructing the tensor.", "labels": [], "entities": []}, {"text": "Side Information: Seven Hearst patterns such as \"<hypernym> such as <NP>\", \"<NP> or other <hypernym>\" etc., given in were used to extract NP side information from the MEDLINE documents.", "labels": [], "entities": [{"text": "MEDLINE documents", "start_pos": 167, "end_pos": 184, "type": "DATASET", "confidence": 0.9525416791439056}]}, {"text": "NP side information for the StackOverflow dataset was obtained from the authors of.", "labels": [], "entities": [{"text": "StackOverflow dataset", "start_pos": 28, "end_pos": 49, "type": "DATASET", "confidence": 0.8623004853725433}]}, {"text": "As described in Section 3, word2vec embeddings of the relation phrases were used to extract relationsimilarity based side-information.", "labels": [], "entities": []}, {"text": "This was done for 8 (A * B)i,j = Ai,j \u00d7 Bi,j 9 Open IE v4.0: http://knowitall.github.io/openie/ both datasets.", "labels": [], "entities": []}, {"text": "Cosine similarity threshold of \u03b3 = 0.7 was used for the experiments in the paper.", "labels": [], "entities": [{"text": "Cosine similarity threshold", "start_pos": 0, "end_pos": 27, "type": "METRIC", "confidence": 0.8245226542154948}]}, {"text": "Samples of side information used in the experiments are shown in.", "labels": [], "entities": []}, {"text": "A total of 2067 unique NP-hypernym pairs were extracted from MEDLINE data and 16,639 were from StackOverflow data.", "labels": [], "entities": [{"text": "MEDLINE data", "start_pos": 61, "end_pos": 73, "type": "DATASET", "confidence": 0.9612750113010406}, {"text": "StackOverflow data", "start_pos": 95, "end_pos": 113, "type": "DATASET", "confidence": 0.8796808123588562}]}, {"text": "25 unique pairs of relation phrases out of 1172 were found to be similar in MEDLINE data, whereas 280 unique pairs of relation phrases out of approximately 3200 were found similar in StackOverflow data.", "labels": [], "entities": [{"text": "MEDLINE data", "start_pos": 76, "end_pos": 88, "type": "DATASET", "confidence": 0.9247683882713318}, {"text": "StackOverflow data", "start_pos": 183, "end_pos": 201, "type": "DATASET", "confidence": 0.8166601657867432}]}, {"text": "Hyperparameters were tuned using grid search and the set which gives minimum reconstruction error for both X and W was chosen.", "labels": [], "entities": []}, {"text": "We set \u03bb np = \u03bb rel = 100 for StackOverflow, and \u03bb np = 0.05 and \u03bb rel = 0.001 for Medline and we use c = 50 for our experiments.", "labels": [], "entities": [{"text": "Medline", "start_pos": 83, "end_pos": 90, "type": "DATASET", "confidence": 0.9050018787384033}]}, {"text": "Please note that our setting is unsupervised, and hence there is no separate train, dev and test sets.", "labels": [], "entities": []}, {"text": "In this section, we shall describe how the induced schemas are presented to human annotators and how final accuracies are calculated.", "labels": [], "entities": []}, {"text": "In factorizations produced by SICTF and other ablated versions of SICTF, we first select a few top relations with best reconstruction score.", "labels": [], "entities": [{"text": "SICTF", "start_pos": 30, "end_pos": 35, "type": "DATASET", "confidence": 0.7957066297531128}, {"text": "SICTF", "start_pos": 66, "end_pos": 71, "type": "DATASET", "confidence": 0.836173415184021}]}, {"text": "The schemas induced for each selected relation k is represented by the matrix slice R k of the core tensor obtained after factorization (see Section 3).", "labels": [], "entities": []}, {"text": "From each such matrix, we identify the indices (i, j) with highest values.", "labels": [], "entities": []}, {"text": "The indices i and j select columns of the matrix A.", "labels": [], "entities": []}, {"text": "A few top ranking NPs from the columns A i and A j along with the relation k are presented to the human annotator, who then evaluates whether the tuple Relation k (A i , A j ) constitutes a valid schema for relation k.", "labels": [], "entities": []}, {"text": "Examples of a few relation schemas induced by SICTF are presented in.", "labels": [], "entities": [{"text": "SICTF", "start_pos": 46, "end_pos": 51, "type": "TASK", "confidence": 0.8239845037460327}]}, {"text": "A human annotator would seethe first and second columns of this table and then offer judgment as indicated in the third column of the table.", "labels": [], "entities": []}, {"text": "All such judgments across all top-reconstructed relations are aggregated to get the final accuracy score.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9993051290512085}]}, {"text": "This evaluation protocol was also used in) to measure learned relation accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.9505946636199951}]}, {"text": "All evaluations were blind, i.e., the annotators were not aware of the method that generated the output they were evaluating.", "labels": [], "entities": []}, {"text": "Moreover, the anno-   tators are experts in software domain and has highschool level knowledge in medical domain.", "labels": [], "entities": []}, {"text": "Though recall is a desirable statistic to measure, it is very challenging to calculate it in our setting due to the non-availability of relation schema annotated text on large scale.", "labels": [], "entities": [{"text": "recall", "start_pos": 7, "end_pos": 13, "type": "METRIC", "confidence": 0.9972541928291321}]}], "tableCaptions": [{"text": " Table 4: Datasets used in the experiments.", "labels": [], "entities": []}, {"text": " Table 6: RSI accuracy comparison of SICTF with its ablated versions when no relation side information is used (\u03bb rel = 0), when", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9774495363235474}]}]}