{"title": [{"text": "A Dataset and Evaluation Metrics for Abstractive Compression of Sentences and Short Paragraphs", "labels": [], "entities": []}], "abstractContent": [{"text": "We introduce a manually-created, multi-reference dataset for abstractive sentence and short paragraph compression.", "labels": [], "entities": [{"text": "abstractive sentence and short paragraph compression", "start_pos": 61, "end_pos": 113, "type": "TASK", "confidence": 0.5891751100619634}]}, {"text": "First, we examine the impact of single-and multi-sentence level editing operations on human compression quality as found in this corpus.", "labels": [], "entities": []}, {"text": "We observe that substitution and rephrasing operations are more meaning preserving than other operations, and that compressing in context improves quality.", "labels": [], "entities": [{"text": "substitution and rephrasing", "start_pos": 16, "end_pos": 43, "type": "TASK", "confidence": 0.7245214978853861}]}, {"text": "Second, we systematically explore the correlations between automatic evaluation metrics and human judgments of meaning preservation and grammaticality in the compression task, and analyze the impact of the linguistic units used and precision versus recall measures on the quality of the met-rics.", "labels": [], "entities": [{"text": "meaning preservation", "start_pos": 111, "end_pos": 131, "type": "TASK", "confidence": 0.727255254983902}, {"text": "precision", "start_pos": 232, "end_pos": 241, "type": "METRIC", "confidence": 0.9959470629692078}, {"text": "recall", "start_pos": 249, "end_pos": 255, "type": "METRIC", "confidence": 0.9103652834892273}]}, {"text": "Multi-reference evaluation metrics are shown to offer significant advantage over single reference-based metrics.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automated sentence compression condenses a sentence or paragraph to its most important content in order to enhance writing quality, meet document length constraints, and build more accurate document summarization systems.", "labels": [], "entities": [{"text": "sentence compression condenses a sentence or paragraph", "start_pos": 10, "end_pos": 64, "type": "TASK", "confidence": 0.8706846066883632}]}, {"text": "Though word deletion is extensively used (e.g.,), state-of-the-art compression models) benefit crucially from data that can represent complex abstractive compression operations, including substitution of words and phrases and reordering.", "labels": [], "entities": [{"text": "word deletion", "start_pos": 7, "end_pos": 20, "type": "TASK", "confidence": 0.7002863585948944}]}, {"text": "This paper has two parts.", "labels": [], "entities": []}, {"text": "In the first half, we introduce a manually-created multi-reference dataset for abstractive compression of sentences and short paragraphs, with the following features: \u2022 It contains approximately 6,000 source texts with multiple compressions (about 26,000 pairs of source and compressed texts), representing business letters, newswire, journals, and technical documents sampled from the Open American National Corpus (OANC 1 ).", "labels": [], "entities": [{"text": "abstractive compression of sentences and short paragraphs", "start_pos": 79, "end_pos": 136, "type": "TASK", "confidence": 0.8576853786196027}, {"text": "Open American National Corpus (OANC 1 )", "start_pos": 386, "end_pos": 425, "type": "DATASET", "confidence": 0.8175027035176754}]}, {"text": "\u2022 Each source text is accompanied by up to five crowd-sourced rewrites constrained to a preset compression ratio and annotated with quality judgments.", "labels": [], "entities": []}, {"text": "Multiple rewrites permit study of the impact of operations on human compression quality and facilitate automatic evaluation.", "labels": [], "entities": []}, {"text": "\u2022 This dataset is the first to provide compressions at the multi-sentence (two-sentence paragraph) level, which may present a steppingstone to whole document summarization.", "labels": [], "entities": [{"text": "whole document summarization", "start_pos": 143, "end_pos": 171, "type": "TASK", "confidence": 0.5964603622754415}]}, {"text": "Many of these two-sentence paragraphs are compressed both as paragraphs and separately sentence-bysentence, offering data that may yield insights into the impact of multi-sentence operations on human compression quality.", "labels": [], "entities": []}, {"text": "\u2022 A detailed edit history is provided that may allow fine-grained alignment of original and compressed texts and measurement of the cognitive load of different rewrite operations.", "labels": [], "entities": []}, {"text": "Our analysis of this dataset reveals that abstraction has a significant positive impact on meaning preservation, and that application of trans-sentential context has a significant positive impact on both meaning preservation and grammaticality.", "labels": [], "entities": [{"text": "meaning preservation", "start_pos": 91, "end_pos": 111, "type": "TASK", "confidence": 0.8703571856021881}, {"text": "meaning preservation", "start_pos": 204, "end_pos": 224, "type": "TASK", "confidence": 0.8513047397136688}]}, {"text": "In the second part, we provide a systematic empirical study of eighty automatic evaluation metrics for text compression using this dataset, correlating them with human judgments of meaning and grammar.", "labels": [], "entities": [{"text": "text compression", "start_pos": 103, "end_pos": 119, "type": "TASK", "confidence": 0.7431189119815826}]}, {"text": "Our study shows strong correlation of the best metrics with human judgments of meaning, but weaker correlations with judgments of grammar.", "labels": [], "entities": []}, {"text": "We demonstrate significant gains from multiple references.", "labels": [], "entities": []}, {"text": "We also provide analyses of the impact of the linguistics units used (surface n-grams of different sizes versus parse-based triples), and the use of precision versus recall-based measures.", "labels": [], "entities": [{"text": "precision", "start_pos": 149, "end_pos": 158, "type": "METRIC", "confidence": 0.9986059069633484}, {"text": "recall-based", "start_pos": 166, "end_pos": 178, "type": "METRIC", "confidence": 0.9894399046897888}]}], "datasetContent": [{"text": "We sampled single sentences and two-sentence paragraphs from several genres in the written text section of the Manually Annotated Sub-Corpus (MASC) () of the Open American National Corpus (OANC), supplemented by additional data from the written section of OANC.", "labels": [], "entities": [{"text": "Open American National Corpus (OANC)", "start_pos": 158, "end_pos": 194, "type": "DATASET", "confidence": 0.775418004819325}, {"text": "OANC", "start_pos": 256, "end_pos": 260, "type": "DATASET", "confidence": 0.9758380055427551}]}, {"text": "Two-sentence paragraphs account for approximately 23% of multi-sentence paragraphs in the OANC.", "labels": [], "entities": [{"text": "OANC", "start_pos": 90, "end_pos": 94, "type": "DATASET", "confidence": 0.8444223999977112}]}, {"text": "The two-sentence paragraphs we sampled contain at least 25 words.", "labels": [], "entities": []}, {"text": "breaks the sampled texts down by genre.", "labels": [], "entities": []}, {"text": "Non-news genres are better represented in our sample than the newswire typically used in compression tasks.", "labels": [], "entities": []}, {"text": "The Letters examples are expected to be useful for learning to compress emails.", "labels": [], "entities": []}, {"text": "The Journal texts are likely to be challenging as their purpose is often more than to convey information.", "labels": [], "entities": []}, {"text": "The Non-Fiction collection includes material from technical academic publications, such as PLoS Medicine, an open access journal.", "labels": [], "entities": []}, {"text": "3  Progress in automated text compression is standardly measured by comparing model outputs at the corpus level.", "labels": [], "entities": [{"text": "text compression", "start_pos": 25, "end_pos": 41, "type": "TASK", "confidence": 0.703930988907814}]}, {"text": "To train models discriminatively and to perform fine-grained system comparisons, however, it is also necessary to have evaluation of system outputs at the individual input level.", "labels": [], "entities": []}, {"text": "Below, we examine automated metric correlation with human judgments at both levels of granularity.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Examples of 1-and 2-sentence crowd-sourced compressions, illustrating different rewrite types.", "labels": [], "entities": []}, {"text": " Table 2: Overview of the dataset by genre.", "labels": [], "entities": []}, {"text": " Table 3: Overview of the dataset, presenting the overall number", "labels": [], "entities": []}, {"text": " Table 4: Agreement on meaning preservation and grammati-", "labels": [], "entities": [{"text": "meaning preservation", "start_pos": 23, "end_pos": 43, "type": "TASK", "confidence": 0.9417564868927002}]}, {"text": " Table 5: Meaning and grammaticality judgments by compres-", "labels": [], "entities": [{"text": "Meaning and grammaticality judgments", "start_pos": 10, "end_pos": 46, "type": "TASK", "confidence": 0.7528061717748642}]}, {"text": " Table 6: Meaning and grammaticality judgments for compress-", "labels": [], "entities": []}, {"text": " Table 8: Average human ratings of system outputs for meaning", "labels": [], "entities": []}]}