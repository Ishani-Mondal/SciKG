{"title": [{"text": "A Neural Network for Coordination Boundary Prediction", "labels": [], "entities": [{"text": "Coordination Boundary Prediction", "start_pos": 21, "end_pos": 53, "type": "TASK", "confidence": 0.7577565411726633}]}], "abstractContent": [{"text": "We propose a neural-network based model for coordination boundary prediction.", "labels": [], "entities": [{"text": "coordination boundary prediction", "start_pos": 44, "end_pos": 76, "type": "TASK", "confidence": 0.7689706285794576}]}, {"text": "The network is designed to incorporate two signals: the similarity between conjuncts and the observation that replacing the whole coordination phrase with a conjunct tends to produce a coherent sentences.", "labels": [], "entities": []}, {"text": "The modeling makes use of several LSTM networks.", "labels": [], "entities": []}, {"text": "The model is trained solely on conjunction annotations in a Treebank, without using external resources.", "labels": [], "entities": []}, {"text": "We show improvements on predicting coordination boundaries on the PTB compared to two state-of-the-art parsers; as well as improvement over previous coordination boundary prediction systems on the Genia corpus.", "labels": [], "entities": [{"text": "predicting coordination boundaries", "start_pos": 24, "end_pos": 58, "type": "TASK", "confidence": 0.8341366847356161}, {"text": "PTB", "start_pos": 66, "end_pos": 69, "type": "DATASET", "confidence": 0.915094256401062}, {"text": "Genia corpus", "start_pos": 197, "end_pos": 209, "type": "DATASET", "confidence": 0.7154531180858612}]}], "introductionContent": [{"text": "Coordination is a common syntactic phenomena, appearing in 38.8% of the sentences in the Penn Treebank (PTB), and in 60.71% of the sentences in the Genia Treebank ().", "labels": [], "entities": [{"text": "Penn Treebank (PTB)", "start_pos": 89, "end_pos": 108, "type": "DATASET", "confidence": 0.9671988248825073}, {"text": "Genia Treebank", "start_pos": 148, "end_pos": 162, "type": "DATASET", "confidence": 0.8419865071773529}]}, {"text": "However, predicting the correct conjuncts span remain one of the biggest challenges for stateof-the-art syntactic parsers.", "labels": [], "entities": []}, {"text": "Both the Berkeley and Zpar phrase-structure parsers (;) achieve F1 scores of around 69% when evaluated on their ability to recover coordination boundaries on the PTB test set.", "labels": [], "entities": [{"text": "F1", "start_pos": 64, "end_pos": 66, "type": "METRIC", "confidence": 0.9997919201850891}, {"text": "PTB test set", "start_pos": 162, "end_pos": 174, "type": "DATASET", "confidence": 0.945047656695048}]}, {"text": "For example, in: \"He has the government's blessing to and in that country.\"", "labels": [], "entities": []}, {"text": "In this work we focus on coordination boundary prediction, and suggest a specialized model for this task.", "labels": [], "entities": [{"text": "coordination boundary prediction", "start_pos": 25, "end_pos": 57, "type": "TASK", "confidence": 0.8075313766797384}]}, {"text": "We treat it as a ranking task, and learn a scoring function over conjuncts candidates such that the correct candidate pair is scored above all other candidates.", "labels": [], "entities": []}, {"text": "The scoring model is a neural network with two LSTM-based components, each modeling a different linguistic principle: (1) conjuncts tend to be similar (\"symmetry\"); and (2) replacing the coordination phrase with each of the conjuncts usually result in a coherent sentence (\"replacement\").", "labels": [], "entities": []}, {"text": "The symmetry component takes into account the conjuncts' syntactic structures, allowing to capture similarities that occur in different levels of the syntactic structure.", "labels": [], "entities": []}, {"text": "The replacement component considers the coherence of the sequence that is produced when connecting the participant parts.", "labels": [], "entities": []}, {"text": "Both of these signals are syntactic in nature, and are learned solely based on information in the Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 98, "end_pos": 111, "type": "DATASET", "confidence": 0.9960960447788239}]}, {"text": "Our model substantially outperforms both the Berkeley and Zpar parsers on the coordination prediction task, while using the exact same training corpus.", "labels": [], "entities": [{"text": "coordination prediction task", "start_pos": 78, "end_pos": 106, "type": "TASK", "confidence": 0.9283664027849833}]}, {"text": "Semantic signals (which are likely to be based on resources external to the treebank) are also relevant for coordination disambiguation and provide complementary information.", "labels": [], "entities": [{"text": "coordination disambiguation", "start_pos": 108, "end_pos": 135, "type": "TASK", "confidence": 0.900581568479538}]}, {"text": "We plan to incorporate such signals in future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our models on their ability to identify conjunction boundaries in the extended Penn Treebank and Genia Treebank () . When evaluating on the PTB, we compare to the conjunction boundary predictions of the generative    Berkeley parser () and the discriminative Zpar parser ().", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 91, "end_pos": 104, "type": "DATASET", "confidence": 0.9936300814151764}, {"text": "Genia Treebank", "start_pos": 109, "end_pos": 123, "type": "DATASET", "confidence": 0.7877455949783325}, {"text": "PTB", "start_pos": 152, "end_pos": 155, "type": "DATASET", "confidence": 0.8322552442550659}]}, {"text": "When evaluating on the Genia treebank, we compare to the results of the discriminative coordination-prediction model of.", "labels": [], "entities": [{"text": "Genia treebank", "start_pos": 23, "end_pos": 37, "type": "DATASET", "confidence": 0.90773805975914}]}, {"text": "8  Baseline Our baseline is the performance of the Berkeley and Zpar parsers on the task presented in Section 3, namely: fora given coordinating word, determine the two spans that are being conjoined by it, and return NONE if the coordinator is not conjoining spans or conjoins spans that are not of the expected type.", "labels": [], "entities": [{"text": "NONE", "start_pos": 218, "end_pos": 222, "type": "METRIC", "confidence": 0.9950018525123596}]}, {"text": "We convert predicted trees to conjunction predictions by taking the two phrases that are immediately adjacent to the coordinator on both sides (ignoring phrases that contain solely punctuation).", "labels": [], "entities": []}, {"text": "For example, in the following Zparpredicted parse tree the conjunct prediction is.", "labels": [], "entities": []}, {"text": "Cases in which the coordination word is the leftmost or right-most non-punctuation element in its phrase (e.g. (PRN (P -)(CC and)(S it's been painful)(P -))) are considered as nocoordination (\"None\").", "labels": [], "entities": []}, {"text": "In the first we are interested in all occurrences of coordination, and in the second we focus on NP coordination.", "labels": [], "entities": [{"text": "NP coordination", "start_pos": 97, "end_pos": 112, "type": "TASK", "confidence": 0.8438997566699982}]}, {"text": "The second scenario requires typed coordinations.", "labels": [], "entities": []}, {"text": "We take the type of a parser-predicted coordination to be the type of the phrase immediately dominating the coordination word.", "labels": [], "entities": []}, {"text": "Evaluation Metrics We measure precision and recall compared to the gold-annotated coordination spans in the extended PTB, where an example is considered correct if both conjunct boundaries match exactly.", "labels": [], "entities": [{"text": "precision", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9994781613349915}, {"text": "recall", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.9994940757751465}, {"text": "PTB", "start_pos": 117, "end_pos": 120, "type": "DATASET", "confidence": 0.8134577870368958}]}, {"text": "When focusing on NPs coordinations, the type of the phrase above the CC level must match as well, and phrases of type NP/NX are considered as NP coordination.", "labels": [], "entities": []}, {"text": "Results and summarize the results.", "labels": [], "entities": []}, {"text": "The Berkeley and Zpar parsers perform similarly on the coordination prediction task.", "labels": [], "entities": [{"text": "coordination prediction task", "start_pos": 55, "end_pos": 83, "type": "TASK", "confidence": 0.9283414483070374}]}, {"text": "Our proposed model outperforms both parsers, with a test-set F 1 score of 72.7 (3.78 F 1 points gain over the better parser) when considering all coordinations, and testset F 1 score of 76.1 (4.77 F 1 points gain) when considering NP coordination.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.9877053697903951}, {"text": "F 1 points gain", "start_pos": 85, "end_pos": 100, "type": "METRIC", "confidence": 0.9039105623960495}, {"text": "F 1 score", "start_pos": 173, "end_pos": 182, "type": "METRIC", "confidence": 0.971121609210968}]}, {"text": "To compare our model to previous work, we evaluate also on the Genia treebank (Beta), a collection of constituency trees for 4529 sentences from Medline abstracts.", "labels": [], "entities": [{"text": "Genia treebank (Beta)", "start_pos": 63, "end_pos": 84, "type": "DATASET", "confidence": 0.8313124477863312}]}, {"text": "The Genia treebank coordination annotation explicitly marks coordination phrases with a special function label (COOD), making the corpus an appealing resource for previous work on coordination boundary prediction.", "labels": [], "entities": [{"text": "Genia treebank coordination annotation", "start_pos": 4, "end_pos": 42, "type": "DATASET", "confidence": 0.842394158244133}, {"text": "special function label (COOD)", "start_pos": 88, "end_pos": 117, "type": "METRIC", "confidence": 0.698302278916041}, {"text": "coordination boundary prediction", "start_pos": 180, "end_pos": 212, "type": "TASK", "confidence": 0.6590027908484141}]}, {"text": "Following, we evaluate the models' ability to predict the span of the entire coordination phrase, disregarding the individual conjuncts.", "labels": [], "entities": []}, {"text": "For example, in \"My plan is to visit Seychelles, ko Samui and Sardinia by the end of the year\" the goal is to recover \"Seychelles, ko Samui and Sardinia\".", "labels": [], "entities": []}, {"text": "This is a recall measure.", "labels": [], "entities": [{"text": "recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9990330934524536}]}, {"text": "We follow the exact protocol of and train and evaluate the model on 3598 coordination phrases in Genia Treebank Beta and report the micro-averaged results of a five-fold cross validation run.", "labels": [], "entities": [{"text": "Genia Treebank Beta", "start_pos": 97, "end_pos": 116, "type": "DATASET", "confidence": 0.8590314984321594}]}], "tableCaptions": [{"text": " Table 1: Coordination prediction on PTB (All coordinations).", "labels": [], "entities": [{"text": "PTB", "start_pos": 37, "end_pos": 40, "type": "DATASET", "confidence": 0.5052221417427063}]}, {"text": " Table 2: Coordination prediction on PTB (NP coordinations).", "labels": [], "entities": [{"text": "Coordination prediction", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.7289110720157623}]}, {"text": " Table 3: Recall on the Beta version of Genia corpus. Numbers", "labels": [], "entities": [{"text": "Genia corpus", "start_pos": 40, "end_pos": 52, "type": "DATASET", "confidence": 0.7427332401275635}]}]}