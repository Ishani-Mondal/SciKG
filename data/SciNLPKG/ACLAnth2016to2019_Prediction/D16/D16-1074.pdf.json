{"title": [{"text": "Generating Coherent Summaries of Scientific Articles Using Coherence Patterns", "labels": [], "entities": [{"text": "Generating Coherent Summaries of Scientific Articles", "start_pos": 0, "end_pos": 52, "type": "TASK", "confidence": 0.7965238740046819}]}], "abstractContent": [{"text": "Previous work on automatic summarization does not thoroughly consider coherence while generating the summary.", "labels": [], "entities": [{"text": "summarization", "start_pos": 27, "end_pos": 40, "type": "TASK", "confidence": 0.7522217631340027}]}, {"text": "We introduce a graph-based approach to summarize scientific articles.", "labels": [], "entities": [{"text": "summarize scientific articles", "start_pos": 39, "end_pos": 68, "type": "TASK", "confidence": 0.9212123354276022}]}, {"text": "We employ coherence patterns to ensure that the generated summaries are coherent.", "labels": [], "entities": []}, {"text": "The novelty of our model is twofold: we mine coherence patterns in a corpus of abstracts , and we propose a method to combine coherence, importance and non-redundancy to generate the summary.", "labels": [], "entities": []}, {"text": "We optimize these factors simultaneously using Mixed Integer Programming.", "labels": [], "entities": []}, {"text": "Our approach significantly outper-forms baseline and state-of-the-art systems in terms of coherence (summary coherence assessment) and relevance (ROUGE scores).", "labels": [], "entities": [{"text": "relevance (ROUGE scores)", "start_pos": 135, "end_pos": 159, "type": "METRIC", "confidence": 0.8496340394020081}]}], "introductionContent": [{"text": "The growth in the scientific output of many different fields makes the task of automatic summarization imperative.", "labels": [], "entities": [{"text": "summarization", "start_pos": 89, "end_pos": 102, "type": "TASK", "confidence": 0.9223974347114563}]}, {"text": "Automatic summarizers assist researchers to have an informative and coherent gist of long scientific articles.", "labels": [], "entities": []}, {"text": "An automatic summarizer produces summaries considering three properties: Importance: The summary should contain the important information of the input document.", "labels": [], "entities": [{"text": "Importance", "start_pos": 73, "end_pos": 83, "type": "METRIC", "confidence": 0.9918409585952759}]}, {"text": "Non-redundancy: The summary should contain non-redundant information.", "labels": [], "entities": []}, {"text": "The information should be diverse in the summary.", "labels": [], "entities": []}, {"text": "Coherence: Though the summary should comprise diverse and important information of the input document, its sentences should be connected to one another such that it becomes coherent and easy to read.", "labels": [], "entities": []}, {"text": "If we do not ensure that a summary is coherent, its sentences may not be properly connected.", "labels": [], "entities": []}, {"text": "This results in an obscure summary.", "labels": [], "entities": []}, {"text": "In previous work coherence has not been thoroughly considered.", "labels": [], "entities": []}, {"text": "use single sentence connectivity in the input document as a coherence measure.", "labels": [], "entities": []}, {"text": "They measure coherence by calculating the outdegree of a sentence in a graph representation of an input document.", "labels": [], "entities": []}, {"text": "This has two disadvantages: first, since it is computed only based on one sentence, it is not sufficient to generate coherent summaries; second, it is obtained based on sentence connectivity in the input document rather than in the summary.", "labels": [], "entities": []}, {"text": "In this work, we focus on the coherence aspect of summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 50, "end_pos": 63, "type": "TASK", "confidence": 0.9744724631309509}]}, {"text": "We use discourse entities as the unit of information that relate sentences.", "labels": [], "entities": []}, {"text": "Here, discourse entities are referred to as head nouns of noun phrases (see Section 2).", "labels": [], "entities": []}, {"text": "The main goal is to extract sentences which refer to those entities which are important and unique, and also to entities which connect the extracted sentences in a coherent manner.", "labels": [], "entities": []}, {"text": "Entities in connected sentences can be used to create linguistically motivated coherence patterns.", "labels": [], "entities": []}, {"text": "Recently, modeled these coherence patterns by subgraphs of the graph representation (nodes represent sentences and edges represent entity connections among sentences) of documents.", "labels": [], "entities": []}, {"text": "They show that the frequency of coherence patterns can be used as features for coherence.", "labels": [], "entities": []}, {"text": "The key idea of this paper is to apply coherence patterns to long scientific articles to extract (possibly) non-adjacent sentences which, however, are already coherent.", "labels": [], "entities": []}, {"text": "Based on the assumption that ab-", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we discuss the datasets and the experimental setup.", "labels": [], "entities": []}, {"text": "We evaluate our model using ROUGE scores and human judgements.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 28, "end_pos": 33, "type": "METRIC", "confidence": 0.9672299027442932}]}, {"text": "First, we extract the text of an article.", "labels": [], "entities": []}, {"text": "We remove figures, tables, references and non-alphabetical characters.", "labels": [], "entities": []}, {"text": "Then we use the Stanford parser ( to determine sentence boundaries.", "labels": [], "entities": []}, {"text": "We apply the Brown coherence toolkit () to convert the articles into entity grids () which then are transformed into entity graphs.", "labels": [], "entities": []}, {"text": "We use gSpan) to extract all subgraphs from the projection graphs of the abstracts of the PubMed corpus.", "labels": [], "entities": [{"text": "PubMed corpus", "start_pos": 90, "end_pos": 103, "type": "DATASET", "confidence": 0.9668086171150208}]}, {"text": "It is possible that patterns with a large number of nodes are not at all present in the projection graph.", "labels": [], "entities": []}, {"text": "Hence, we use coherence patterns with 3 and 4 nodes, referred to as CP 3 and CP 4 , respectively.", "labels": [], "entities": []}, {"text": "We use Gurobi (Gurobi Optimization, Inc., 2014) to solve the MIP problem.", "labels": [], "entities": [{"text": "MIP problem", "start_pos": 61, "end_pos": 72, "type": "TASK", "confidence": 0.9253925979137421}]}, {"text": "We use a pronoun resolution system to replace all pronouns in the summary with their antecedents.", "labels": [], "entities": [{"text": "pronoun resolution", "start_pos": 9, "end_pos": 27, "type": "TASK", "confidence": 0.7331669926643372}]}, {"text": "We determine the best values for \u03bb I , \u03bb R , and \u03bb con the development sets.", "labels": [], "entities": []}, {"text": "\u03bb I = 0.4, \u03bb R = 0.3, and \u03bb c = 0.3 are the best weights for the PLOS Medicine development set.", "labels": [], "entities": [{"text": "PLOS Medicine development set", "start_pos": 65, "end_pos": 94, "type": "DATASET", "confidence": 0.7894977480173111}]}, {"text": "Weights for the DUC 2002 development set are \u03bb I = 0.5, \u03bb R = 0.2 and \u03bb c = 0.3.", "labels": [], "entities": [{"text": "DUC 2002 development set", "start_pos": 16, "end_pos": 40, "type": "DATASET", "confidence": 0.9716345518827438}]}], "tableCaptions": [{"text": " Table 1: PLOS Medicine, editor's summaries with 5 sentences.", "labels": [], "entities": [{"text": "PLOS Medicine", "start_pos": 10, "end_pos": 23, "type": "DATASET", "confidence": 0.7927253544330597}]}, {"text": " Table 2: ROUGE scores on PLOS Medicine with 750 words.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9885481595993042}, {"text": "PLOS Medicine", "start_pos": 26, "end_pos": 39, "type": "TASK", "confidence": 0.5792801678180695}]}, {"text": " Table 3: ROUGE scores on DUC 2002.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9841283559799194}, {"text": "DUC 2002", "start_pos": 26, "end_pos": 34, "type": "DATASET", "confidence": 0.9344407021999359}]}, {"text": " Table 4: The average human scores.", "labels": [], "entities": []}]}