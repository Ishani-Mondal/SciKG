{"title": [{"text": "SimpleScience: Lexical Simplification of Scientific Terminology", "labels": [], "entities": [{"text": "Lexical Simplification of Scientific Terminology", "start_pos": 15, "end_pos": 63, "type": "TASK", "confidence": 0.836358118057251}]}], "abstractContent": [{"text": "Lexical simplification of scientific terms represents a unique challenge due to the lack of a standard parallel corpora and fast rate at which vocabulary shift along with research.", "labels": [], "entities": [{"text": "Lexical simplification of scientific terms", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.9205473780632019}]}, {"text": "We introduce SimpleScience, a lexical simplification approach for scientific terminology.", "labels": [], "entities": []}, {"text": "We use word embeddings to extract simplification rules from a parallel corpora containing scientific publications and Wikipedia.", "labels": [], "entities": []}, {"text": "To evaluate our system we construct SimpleSciGold, a novel gold standard set for science-related simplifications.", "labels": [], "entities": []}, {"text": "We find that our approach out-performs prior context-aware approaches at generating simplifications for scientific terms.", "labels": [], "entities": []}], "introductionContent": [{"text": "Lexical simplification, the process of reducing the complexity of words by replacing them with simpler substitutes (e.g., sodium in place of Na; insects in place of lepidopterans) can make scientific texts more accessible to general audiences.", "labels": [], "entities": [{"text": "Lexical simplification", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8765186369419098}]}, {"text": "Human-inthe-loop interfaces present multiple possible simplifications to a reader (on demand) in place of jargon and give the reader familiar access points to understanding jargon.", "labels": [], "entities": []}, {"text": "Unfortunately, simplification techniques are not yet of high enough quality for fully automated scenarios.", "labels": [], "entities": []}, {"text": "Currently lexical simplification pipelines for scientific texts are rare.", "labels": [], "entities": []}, {"text": "The vast majority of prior methods assume a domain independent context, and rely on Wikipedia and Simple English Wikipedia, a subset of Wikipedia using simplified grammar and terminology, to learn simplifications, with translationbased approaches using an aligned version.", "labels": [], "entities": []}, {"text": "However, learning simplifications from Wikipedia is not well suited to lexical simplification of scientific terms.", "labels": [], "entities": []}, {"text": "Though generic or established terms may appear in Wikipedia, novel terms associated with new advances may not be reflected.", "labels": [], "entities": []}, {"text": "Wikipedia's editing rules also favor generality over specificity and eliminate redundancy, both of which are problematic in providing a rich training set that matches simple and complex terms.", "labels": [], "entities": []}, {"text": "Further, some approaches work by detecting all pairs of words in a corpus and filtering to isolate synonym or hypernym-relationship pairs using WordNet).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 144, "end_pos": 151, "type": "DATASET", "confidence": 0.9638525247573853}]}, {"text": "Like Wikipedia, WordNet is a general purpose semantic database, and does not coverall branches of science nor integrate new terminology quickly.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 16, "end_pos": 23, "type": "DATASET", "confidence": 0.9383997917175293}]}, {"text": "Word embeddings do not require the use of prebuilt ontologies to identify associated terms like simplifications.", "labels": [], "entities": []}, {"text": "Recent work indicates that they may improve results for simplification selection: determining which simplifications fora given complex word can be used without altering the meaning of the text.", "labels": [], "entities": [{"text": "simplification selection", "start_pos": 56, "end_pos": 80, "type": "TASK", "confidence": 0.9456462860107422}]}, {"text": "Embeddings have also been explored to extract hypernym relations from general corpora).", "labels": [], "entities": []}, {"text": "However, word embeddings have not been used for generating lexical simplifications.", "labels": [], "entities": []}, {"text": "We provide a novel demonstration of how using embeddings on a scientific corpus is better suited to learning scientific term simplifications than prior approaches that use WordNet as a filter and Wikipedia as a corpus.", "labels": [], "entities": [{"text": "learning scientific term simplifications", "start_pos": 100, "end_pos": 140, "type": "TASK", "confidence": 0.6340566948056221}]}, {"text": "INPUT: Finally we show that the transient immune activation that renders mosquitoes resistant to the human malaria parasite has little to no effect on mosquito fitness as a measure of survival or fecundity under laboratory conditions.", "labels": [], "entities": [{"text": "INPUT", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.7522407174110413}]}, {"text": "CANDIDATE RULES: {fecundity\u2192fertility} {fecundity\u2192productivity} OUTPUT: Finally we show that the transient immune activation that renders mosquitoes resistant to the human malaria parasite has little to no effect on mosquito fitness as a measure of survival or (fertility; productivity) under laboratory conditions.", "labels": [], "entities": [{"text": "CANDIDATE", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.5674697160720825}, {"text": "RULES", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.7348452210426331}, {"text": "OUTPUT", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.9858525991439819}]}, {"text": "We introduce SimpleScience, a novel lexical simplification pipeline for scientific terms, which we apply to a scientific corpus of nearly 500k publications in Public Library of Science (PLOS) and PubMed Central (PMC) paired with a general corpus from Wikipedia.", "labels": [], "entities": []}, {"text": "We validate our approach using SimpleSciGold, a gold standard set that we create using crowdsourcing that contains 293 sentences containing scientific terms with an average of 21 simplifications per term.", "labels": [], "entities": []}, {"text": "We show how the SimpleScience pipeline achieves better performance (Fmeasure: 0.285) than the prior approach to simplification generation applied to our corpus (F-measure: 0.136).", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9787672758102417}]}, {"text": "We further find that the simplification selection techniques used in prior work to determine which simplifications area good fit fora sentence do not improve performance when our generation pipeline is used.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Simplification Generation Results. SimpleScience achieves the highest F-measure with a cosine threshold of 0.4 and a", "labels": [], "entities": [{"text": "Simplification Generation", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.9724768400192261}, {"text": "F-measure", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.9981698989868164}]}]}