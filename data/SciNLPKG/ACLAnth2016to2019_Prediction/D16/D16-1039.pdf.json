{"title": [{"text": "Learning Term Embeddings for Taxonomic Relation Identification Using Dynamic Weighting Neural Network", "labels": [], "entities": [{"text": "Taxonomic Relation Identification", "start_pos": 29, "end_pos": 62, "type": "TASK", "confidence": 0.8322733243306478}]}], "abstractContent": [{"text": "Taxonomic relation identification aims to recognize the 'is-a' relation between two terms.", "labels": [], "entities": [{"text": "Taxonomic relation identification", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.868092397848765}]}, {"text": "Previous works on identifying taxonomic relations are mostly based on statistical and linguistic approaches, but the accuracy of these approaches is far from satisfactory.", "labels": [], "entities": [{"text": "identifying taxonomic relations", "start_pos": 18, "end_pos": 49, "type": "TASK", "confidence": 0.7867843508720398}, {"text": "accuracy", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.9990298748016357}]}, {"text": "In this paper , we propose a novel supervised learning approach for identifying taxonomic relations using term embeddings.", "labels": [], "entities": []}, {"text": "For this purpose, we first design a dynamic weighting neural network to learn term embeddings based on not only the hypernym and hyponym terms, but also the contextual information between them.", "labels": [], "entities": []}, {"text": "We then apply such embeddings as features to identify taxonomic relations using a supervised method.", "labels": [], "entities": []}, {"text": "The experimental results show that our proposed approach significantly out-performs other state-of-the-art methods by 9% to 13% in terms of accuracy for both general and specific domain datasets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 140, "end_pos": 148, "type": "METRIC", "confidence": 0.9989762306213379}]}], "introductionContent": [{"text": "Taxonomies which serve as the backbone of structured knowledge are useful for many NLP applications such as question answering () and document clustering).", "labels": [], "entities": [{"text": "question answering", "start_pos": 108, "end_pos": 126, "type": "TASK", "confidence": 0.9184941351413727}, {"text": "document clustering", "start_pos": 134, "end_pos": 153, "type": "TASK", "confidence": 0.7533310055732727}]}, {"text": "However, the hand-crafted, well-structured taxonomies including WordNet, OpenCyc () and Freebase) that are publicly available may not be complete for new or specialized domains.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 64, "end_pos": 71, "type": "DATASET", "confidence": 0.9801556468009949}]}, {"text": "It is also time-consuming and error prone to identify taxonomic relations manually.", "labels": [], "entities": []}, {"text": "As such, methods for automatic identification of taxonomic relations is highly desirable.", "labels": [], "entities": [{"text": "automatic identification of taxonomic relations", "start_pos": 21, "end_pos": 68, "type": "TASK", "confidence": 0.7683176517486572}]}, {"text": "The previous methods for identifying taxonomic relations can be generally classified into two categories: statistical and linguistic approaches.", "labels": [], "entities": []}, {"text": "The statistical approaches rely on the idea that frequently co-occurring terms are likely to have taxonomic relationships.", "labels": [], "entities": []}, {"text": "While such approaches can result in taxonomies with relatively high coverage, they are usually heavily dependent on the choice of feature types, and suffer from low accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.9962987303733826}]}, {"text": "The linguistic approaches which are based on lexical-syntactic patterns (e.g. 'A such as B') are simple and efficient.", "labels": [], "entities": []}, {"text": "However, they usually suffer from low precision and coverage because the identified patterns are unable to cover the wide range of complex linguistic structures, and the ambiguity of natural language compounded by data sparsity makes these approaches less robust.", "labels": [], "entities": [{"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.997428834438324}, {"text": "coverage", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.972223162651062}]}, {"text": "Word embedding (), also known as distributed word representation, which represents words with high-dimensional and realvalued vectors, has been shown to be effective in exploring both linguistic and semantic relations between words.", "labels": [], "entities": [{"text": "distributed word representation", "start_pos": 33, "end_pos": 64, "type": "TASK", "confidence": 0.6637939612070719}]}, {"text": "In recent years, word embedding has been used quite extensively in NLP research, ranging from syntactic parsing), machine translation ( to sentiment analysis).", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 94, "end_pos": 111, "type": "TASK", "confidence": 0.7312254309654236}, {"text": "machine translation", "start_pos": 114, "end_pos": 133, "type": "TASK", "confidence": 0.8396083414554596}, {"text": "sentiment analysis", "start_pos": 139, "end_pos": 157, "type": "TASK", "confidence": 0.9226222336292267}]}, {"text": "The current methods for learning word embeddings have focused on learning the representations from word co-occurrence so that similar words will have similar embeddings.", "labels": [], "entities": []}, {"text": "However, using the co-occurrence based similarity learning alone is not effective for the purpose of identifying taxonomic relations.", "labels": [], "entities": []}, {"text": "vised method to learn term embeddings based on pre-extracted taxonomic relation data.", "labels": [], "entities": []}, {"text": "However, this method is heavily dependent on the training data to discover all taxonomic relations, i.e. if a pair of terms is not in the training set, it may become a negative example in the learning process, and will be classified as a non-taxonomic relation.", "labels": [], "entities": []}, {"text": "The dependency on training data is a huge drawback of the method as no source can guarantee that it can coverall possible taxonomic relations for learning.", "labels": [], "entities": []}, {"text": "Moreover, the recent studies ( showed that contextual information between hypernym and hyponym is an important indicator to detect taxonomic relations.", "labels": [], "entities": []}, {"text": "However, the term embedding learning method proposed in () only learns through the pairwise relations of terms without considering the contextual information between them.", "labels": [], "entities": []}, {"text": "Therefore, the resultant quality is not good in some specific domain areas.", "labels": [], "entities": []}, {"text": "In this paper, we propose a novel approach to learn term embeddings based on dynamic weighting neural network to encode not only the information of hypernym and hyponym, but also the contextual information between them for the purpose of taxonomic relation identification.", "labels": [], "entities": [{"text": "taxonomic relation identification", "start_pos": 238, "end_pos": 271, "type": "TASK", "confidence": 0.8342015345891317}]}, {"text": "We then apply the identified embeddings as features to find the positive taxonomic relations using the supervised method SVM.", "labels": [], "entities": []}, {"text": "The experimental results show that our proposed term embedding learning approach outperforms other state-of-the-art embedding learning methods for identifying taxonomic relations with much higher accuracy for both general and specific domains.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 196, "end_pos": 204, "type": "METRIC", "confidence": 0.9954696893692017}]}, {"text": "In addition, another advantage of our proposed approach is that it is able to generalize from the training dataset the taxonomic relation properties for unseen pairs.", "labels": [], "entities": []}, {"text": "Thus, it can recognize some true taxonomic relations which are not even defined in dictionary and training data.", "labels": [], "entities": []}, {"text": "For the rest of this paper, we will discuss the proposed term embedding learning approach and its performance results.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conduct experiments to evaluate the performance of our term embedding learning approach on the general domain areas as well as the specific domain areas.", "labels": [], "entities": []}, {"text": "In performance evaluation, we compare our approach with two other state-of-the-art supervised term embedding learning methods in and the Word2Vec model ().", "labels": [], "entities": []}, {"text": "There are five datasets used in the experiments.", "labels": [], "entities": []}, {"text": "Two datasets, namely BLESS and ENTAILMENT, are general domain datasets.", "labels": [], "entities": [{"text": "BLESS", "start_pos": 21, "end_pos": 26, "type": "METRIC", "confidence": 0.9940162897109985}, {"text": "ENTAILMENT", "start_pos": 31, "end_pos": 41, "type": "METRIC", "confidence": 0.8879697918891907}]}, {"text": "The other three datasets, namely Animal, Plant and Vehicle, are specific domain datasets.", "labels": [], "entities": []}, {"text": "\u2022 BLESS (  \u2022 Animal, Plant and Vehicle datasets (Velardi et al., 2013): They are taxonomies constructed based on the dictionaries and data crawled from the Web for the corresponding domains.", "labels": [], "entities": [{"text": "BLESS", "start_pos": 2, "end_pos": 7, "type": "METRIC", "confidence": 0.9985628724098206}]}, {"text": "The positive examples are created by extracting all possible (direct and indirect) taxonomic relations from the taxonomies.", "labels": [], "entities": []}, {"text": "The negative examples are generated by randomly pairing two terms which are not involved in any taxonomic relation.", "labels": [], "entities": []}, {"text": "The number of terms, positive examples and negative examples extracted from the five datasets are summarized in  For the general domain datasets, we have conducted two experiments to evaluate the performance of our proposed approach.", "labels": [], "entities": []}, {"text": "For the BLESS dataset, we holdout one concept for testing and train on the remaining 199 concepts.", "labels": [], "entities": [{"text": "BLESS dataset", "start_pos": 8, "end_pos": 21, "type": "DATASET", "confidence": 0.888637512922287}]}, {"text": "The hold-out concept and its relatum constitute the testing set, while the remaining 199 concepts and their relatum constitute the training set.", "labels": [], "entities": []}, {"text": "To further separate the training and testing sets, we exclude from the training set any pair of terms that has one term appearing in the testing set.", "labels": [], "entities": []}, {"text": "We report the average accuracy across all concepts.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9921512603759766}]}, {"text": "For the ENTAILMENT dataset, we use the same evaluation method: holdout one hypernym for testing and train on the remaining hypernyms, and we also report the average accuracy across all hypernyms.", "labels": [], "entities": [{"text": "ENTAILMENT dataset", "start_pos": 8, "end_pos": 26, "type": "DATASET", "confidence": 0.7801310420036316}, {"text": "accuracy", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.996830403804779}]}, {"text": "Furthermore, to evaluate the effect of the offset vector to taxonomic relation identification, we deploy a setting that removes the offset vector in the feature vectors of SVM.", "labels": [], "entities": [{"text": "taxonomic relation identification", "start_pos": 60, "end_pos": 93, "type": "TASK", "confidence": 0.7885794242223104}]}, {"text": "Specifically, for SVM+Our and SVM+Word2Vec, the input vector is changed from v x , v y , v x \u2212 v y to v x , v y . We use the subscript short to denote this setting.", "labels": [], "entities": [{"text": "SVM+Word2Vec", "start_pos": 30, "end_pos": 42, "type": "DATASET", "confidence": 0.6385191480318705}]}, {"text": "shows the performance of the three supervised models in Experiment 1.", "labels": [], "entities": []}, {"text": "Our approach achieves significantly better performance than Yu's method and Word2Vec method in terms of accuracy (t-test, p-value < 0.05) for both BLESS and ENTAILMENT datasets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.9994552731513977}, {"text": "BLESS", "start_pos": 147, "end_pos": 152, "type": "METRIC", "confidence": 0.9741592407226562}, {"text": "ENTAILMENT datasets", "start_pos": 157, "end_pos": 176, "type": "DATASET", "confidence": 0.7403717041015625}]}, {"text": "Specifically, our approach improves the average accuracy by 4% compared to Yu's method, and by 9% compared to the Word2Vec method.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9833559989929199}, {"text": "Word2Vec", "start_pos": 114, "end_pos": 122, "type": "DATASET", "confidence": 0.9325193166732788}]}, {"text": "The Word2Vec embeddings have the worst result because it is based only on co-occurrence based similarity, which is not effective for the classifier to accurately recognize all the taxonomic relations.", "labels": [], "entities": []}, {"text": "Our approach performs better than Yu's method and it shows that our approach can learn embeddings more effectively.", "labels": [], "entities": []}, {"text": "Our approach encodes not only hypernym and hyponym terms but also the contextual information between them, while Yu's method ignores the contextual information for taxonomic relation identification.", "labels": [], "entities": [{"text": "taxonomic relation identification", "start_pos": 164, "end_pos": 197, "type": "TASK", "confidence": 0.834945281346639}]}, {"text": "Similarly, for the specific domain datasets, we have conducted two experiments to evaluate the performance of our proposed approach.", "labels": [], "entities": []}, {"text": "For each of the Animal, Plant and Vehicle datasets, we also holdout one term for testing and train on the remaining terms.", "labels": [], "entities": []}, {"text": "The positive and negative examples which contain the holdout term constitute the testing set, while other positive and negative examples constitute the training set.", "labels": [], "entities": []}, {"text": "We also exclude from the training set any pair of terms that has one term appearing in the testing set.", "labels": [], "entities": []}, {"text": "The experimental results are given in.", "labels": [], "entities": []}, {"text": "We can observe that not only for general domain datasets but also for specific domain datasets, our term embedding learning approach has achieved significantly better performance than Yu's method and the Word2Vec method in terms of accuracy (ttest, p-value < 0.05  Another interesting point to observe is that the accuracy of Yu's method drops significantly in specific domain datasets (as shown in) when compared to the general domain datasets (as shown in).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 232, "end_pos": 240, "type": "METRIC", "confidence": 0.9991050362586975}, {"text": "accuracy", "start_pos": 314, "end_pos": 322, "type": "METRIC", "confidence": 0.9992651343345642}]}, {"text": "One possible explanation is the accuracy of Yu's method depends on the training data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9994783997535706}]}, {"text": "As Yu's method learns the embeddings using preextracted taxonomic relations from Probase, and if a relation does not exist in Probase, there is high possibility that it becomes a negative example and be recognized as a non-taxonomic relation by the classifier.", "labels": [], "entities": [{"text": "Probase", "start_pos": 81, "end_pos": 88, "type": "DATASET", "confidence": 0.9838626980781555}, {"text": "Probase", "start_pos": 126, "end_pos": 133, "type": "DATASET", "confidence": 0.9776264429092407}]}, {"text": "Therefore, the training data extracted from Probase plays an important role in Yu's method.", "labels": [], "entities": [{"text": "Probase", "start_pos": 44, "end_pos": 51, "type": "DATASET", "confidence": 0.951043963432312}]}, {"text": "For general domain datasets (BLESS and ENTAIL-MENT), there are about 75%-85% of taxonomic relations in these datasets found in Probase, while there are only about 25%-45% of relations in the specific domains (i.e. Animal, Plant and Vehicle) found in Probase.", "labels": [], "entities": [{"text": "BLESS", "start_pos": 29, "end_pos": 34, "type": "METRIC", "confidence": 0.9948990941047668}, {"text": "Probase", "start_pos": 127, "end_pos": 134, "type": "DATASET", "confidence": 0.9798830151557922}, {"text": "Probase", "start_pos": 250, "end_pos": 257, "type": "DATASET", "confidence": 0.9871596097946167}]}, {"text": "Therefore, Yu's method achieves better performance in general domain datasets than the specific ones.", "labels": [], "entities": []}, {"text": "Our approach, in contrast, less depends on the training relations.", "labels": [], "entities": []}, {"text": "Therefore, it can achieve high accuracy in both the general and specific domain datasets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9987723231315613}]}, {"text": "Similar to experiment 2, this experiment aims to evaluate the generalization capability of our term embeddings.", "labels": [], "entities": []}, {"text": "In this experiment, for each of the Animal, Plant and Vehicle domains, we train the classifier using the positive and negative examples in each domain and test the classifier in other domains.", "labels": [], "entities": []}, {"text": "The experimental results in show that our approach achieves the best performance compared to other state-of-the-art methods for all the datasets.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Datasets used in the experiments.", "labels": [], "entities": []}, {"text": " Table 2: Performance results for the BLESS and ENTAIL-", "labels": [], "entities": [{"text": "BLESS", "start_pos": 38, "end_pos": 43, "type": "METRIC", "confidence": 0.9938071370124817}, {"text": "ENTAIL", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.7846571803092957}]}, {"text": " Table 4: Performance results for the Animal, Plant and Vehicle", "labels": [], "entities": []}, {"text": " Table 5: Performance results for the specific domain datasets", "labels": [], "entities": []}, {"text": " Table 6. The experiments  are carried out on a PC with Intel(R) Xeon(R) CPU  at 3.7GHz and 16GB RAM.", "labels": [], "entities": []}, {"text": " Table 6: Performance results based on training time and accu-", "labels": [], "entities": [{"text": "accu-", "start_pos": 57, "end_pos": 62, "type": "METRIC", "confidence": 0.9790472686290741}]}]}