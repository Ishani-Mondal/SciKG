{"title": [{"text": "Antecedent Selection for Sluicing: Structure and Content", "labels": [], "entities": []}], "abstractContent": [{"text": "Sluicing is an elliptical process where the majority of a question can go unpronounced as long as there is a salient antecedent in previous discourse.", "labels": [], "entities": [{"text": "Sluicing", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.9729577302932739}]}, {"text": "This paper considers the task of antecedent selection: finding the correct antecedent fora given case of sluicing.", "labels": [], "entities": []}, {"text": "We argue that both syntactic and discourse relationships are important in antecedent selection , and we construct linguistically sophisticated features that describe the relevant relationships.", "labels": [], "entities": []}, {"text": "We also define features that describe the relation of the content of the antecedent and the sluice type.", "labels": [], "entities": []}, {"text": "We develop a linear model which achieves accuracy of 72.4%, a substantial improvement over a strong manually constructed baseline.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9997274279594421}]}, {"text": "Feature analysis confirms that both syntactic and discourse features are important in antecedent selection.", "labels": [], "entities": []}], "introductionContent": [{"text": "Ellipsis involves sentences with missing subparts, where those subparts must be interpretatively filled in by the hearer.", "labels": [], "entities": []}, {"text": "How this is possible has been a major topic in linguistic theory for decades.", "labels": [], "entities": [{"text": "linguistic theory", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.7309881001710892}]}, {"text": "One widely studied example is verb phrase ellipsis (VPE), exemplified by (1).", "labels": [], "entities": [{"text": "verb phrase ellipsis (VPE)", "start_pos": 30, "end_pos": 56, "type": "TASK", "confidence": 0.7449013143777847}]}, {"text": "(1) Harry traveled to southern Denmark to study botany . Tom did too . In the second sentence (Tom did too) the verb phrase is entirely missing, yet the hearer effortlessly 'resolves' (understands) its content to be traveled to southern Denmark to study botany.", "labels": [], "entities": []}, {"text": "Another widely studied case of ellipsis is sluicing, in which the majority of a question is unpronounced, as in.", "labels": [], "entities": []}, {"text": "Harry traveled to southern Denmark to study botany . I want to know why . Here the content of the question, introduced by the WH-phrase why, is missing, yet it is understood by the hearer to be why did Harry travel to southern Denmark to study botany?.", "labels": [], "entities": [{"text": "WH-phrase", "start_pos": 126, "end_pos": 135, "type": "METRIC", "confidence": 0.88186115026474}]}, {"text": "In both of these cases, ellipsis resolution is made possible by the presence of an antecedent, material in prior discourse that, informally speaking, is equivalent to what is missing.", "labels": [], "entities": [{"text": "ellipsis resolution", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.8182809054851532}]}, {"text": "Ellipsis poses an important challenge for many applications in language technology, as various forms of ellipsis are known to be frequent in a variety of languages and text types.", "labels": [], "entities": []}, {"text": "This is perhaps most evident in the case of question-answering systems, since elliptical questions and elliptical answers are both very common in discourse.", "labels": [], "entities": []}, {"text": "A computational system that can effectively deal with ellipsis involves three subtasks: ellipsis detection, in which a case of ellipsis is identified, antecedent selection, in which the antecedent fora case of ellipsis is found, and ellipsis resolution, where the content of the ellipsis is filled in with reference to the antecedent and the context of the ellipsis.", "labels": [], "entities": [{"text": "ellipsis detection", "start_pos": 88, "end_pos": 106, "type": "TASK", "confidence": 0.7423208355903625}, {"text": "ellipsis resolution", "start_pos": 233, "end_pos": 252, "type": "TASK", "confidence": 0.7028541713953018}]}, {"text": "Here, we focus on antecedent selection for sluicing.", "labels": [], "entities": []}, {"text": "In addressing this problem of antecedent selection, we make use of a newly available annotated corpus of sluice occurrences.", "labels": [], "entities": []}, {"text": "This corpus consists of 4100 automatically parsed and annotated examples from the New York Times subset of the Gigaword Corpus, of which 2185 are publicly available.", "labels": [], "entities": [{"text": "New York Times subset of the Gigaword Corpus", "start_pos": 82, "end_pos": 126, "type": "DATASET", "confidence": 0.7727621421217918}]}, {"text": "Sluicing antecedent selection might appear simple -after all, it typically involves a sentential expression in the nearby context.", "labels": [], "entities": []}, {"text": "However, analysis of the annotated corpus data reveals surprising ambiguity in the identification of the antecedent for sluicing.", "labels": [], "entities": []}, {"text": "In what follows, we describe a series of algorithms and models for antecedent selection in sluicing.", "labels": [], "entities": []}, {"text": "Following section 2 on background, we describe our dataset in section 3.", "labels": [], "entities": []}, {"text": "Then in section 4, we describe the structural factors that we have identified as relevant for antecedent selection.", "labels": [], "entities": []}, {"text": "In section 5, we look at ways in which the content of the sluice and the content of the antecedent tend to be related to each other: we address lexical overlap, as well as the probabilistic relation of head verbs to WH-phrase types, and the relation of correlate expressions to sluice types.", "labels": [], "entities": []}, {"text": "In section 6 we present two manually constructed baseline classifiers, and then we describe an approach to automatically tuning weights for the complete set of features.", "labels": [], "entities": []}, {"text": "In section 7 we present the results of these algorithms and models, including results involving various subsets of features, to better understand their contributions to the overall results.", "labels": [], "entities": []}, {"text": "Finally in section 8 we discuss the results in light of plans for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our dataset, described in, consists of 4100 sluicing examples from the New York Times subset of the Gigaword Corpus, 2nd edition.", "labels": [], "entities": [{"text": "New York Times subset of the Gigaword Corpus", "start_pos": 71, "end_pos": 115, "type": "DATASET", "confidence": 0.808290533721447}]}, {"text": "This dataset is the first systematic, exhaustive corpus of sluicing.", "labels": [], "entities": []}, {"text": "1 Each example is annotated with four main tags, given in terms of token sequence offsets: the sluice remnant, the antecedent, and then inside the antecedent the main predicate and the correlate, if any.", "labels": [], "entities": []}, {"text": "The annotations also provide a free-text resolution.", "labels": [], "entities": []}, {"text": "Of the 4100 annotated, 2185 sluices have been made publicly available; we use that smaller dataset here.", "labels": [], "entities": []}, {"text": "We make use of the annotation of the antecedent and remnant tags.", "labels": [], "entities": []}, {"text": "See for additional information on the dataset and the annotation scheme.", "labels": [], "entities": []}, {"text": "For the feature extraction in section 4, we rely on the the token, parsetree, and dependency parse information in Annotated Gigaword (extracted from Stanford CoreNLP).", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 8, "end_pos": 26, "type": "TASK", "confidence": 0.708958700299263}, {"text": "Annotated Gigaword (extracted from Stanford CoreNLP", "start_pos": 114, "end_pos": 165, "type": "DATASET", "confidence": 0.7078834005764553}]}], "tableCaptions": [{"text": " Table 2: Average (Con)A(ccuracy) and (Tok)F(-Score) for", "labels": [], "entities": [{"text": "Average (Con)A", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.9021238088607788}, {"text": "Tok)F(-Score)", "start_pos": 39, "end_pos": 52, "type": "METRIC", "confidence": 0.8383436401685079}]}]}