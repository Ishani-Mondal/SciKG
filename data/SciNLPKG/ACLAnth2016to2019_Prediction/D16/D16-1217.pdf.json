{"title": [{"text": "Does 'well-being' translate on Twitter?", "labels": [], "entities": []}], "abstractContent": [{"text": "We investigate whether psychological well-being translates across English and Span-ish Twitter, by building and comparing source language and automatically translated weighted lexica in English and Spanish.", "labels": [], "entities": []}, {"text": "We find that the source language models perform substantially better than the machine translated versions.", "labels": [], "entities": []}, {"text": "Moreover, manually correcting translation errors does not improve model performance, suggesting that meaningful cultural information is being lost in translation.", "labels": [], "entities": []}, {"text": "Further work is needed to clarify when automatic translation of well-being lexica is effective and how it can be improved for cross-cultural analysis.", "labels": [], "entities": [{"text": "automatic translation of well-being lexica", "start_pos": 39, "end_pos": 81, "type": "TASK", "confidence": 0.7052386105060577}]}], "introductionContent": [{"text": "Interest in sentiment analysis spans academic and commercial domains, with wide-ranging applications (.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.9557009637355804}]}, {"text": "While the majority of tools for sentiment analysis have been developed for English text, ideally sentiment and emotion could be analyzed across many languages.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.9556975364685059}]}, {"text": "Does one need to build models for each language of interest, or can models be applied cross-culturally?", "labels": [], "entities": []}, {"text": "More generally, how do cultures differ in the language they use to express sentiment and feeling?", "labels": [], "entities": []}, {"text": "Sentiment in resource-poor languages has commonly been assessed by first translating text into English and then applying an English sentiment model (.", "labels": [], "entities": [{"text": "Sentiment", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9678725004196167}]}, {"text": "This approach is economical and efficient, as building each model of interest in every target language is resource-intensive.", "labels": [], "entities": []}, {"text": "Yet it is not clear how much culturally specific information and accuracy are lost in the translation process, and specifically how this varies across languages, cultures, linguistic content, and corpora (e.g., social media vs. news).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.996505856513977}]}, {"text": "While extensive work has demonstrated that automatic machine translation (MT) methods are competitive when translating opinion in news and blogs, less research has examined the translation of sentiment on social media, and specifically on Twitter, known for its restriction of individual exchanges to short samples of text (140 characters) and informal language.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 53, "end_pos": 77, "type": "TASK", "confidence": 0.8643208146095276}, {"text": "translating opinion in news and blogs", "start_pos": 107, "end_pos": 144, "type": "TASK", "confidence": 0.8821190198262533}, {"text": "translation of sentiment", "start_pos": 177, "end_pos": 201, "type": "TASK", "confidence": 0.9061734080314636}]}, {"text": "Moreover, research has not focused on translating subjective well-being specifically.", "labels": [], "entities": [{"text": "translating subjective well-being", "start_pos": 38, "end_pos": 71, "type": "TASK", "confidence": 0.8844977418581644}]}, {"text": "Beyond sentiment, this paper investigates how expressions of personal well-being translate between English and Spanish on Twitter.", "labels": [], "entities": []}, {"text": "We have English and Spanish speakers annotate Tweets in their native language for five components of subjective wellbeing (positive emotion, engagement, positive relationships, meaning, and accomplishment) (Seligman, 2011).", "labels": [], "entities": []}, {"text": "We then compare how well models trained and tested in the same language compare to (a) models developed in one language, and then translated (using Google Translate) to the other language (e.g., how well English models translated to Spanish work on Spanish Tweets) and (b) how well models developed in one language work on Tweets translated from another language (e.g., how well English models work on Tweets translated from Spanish to English).", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated how well the different models worked, computing the Pearson correlations between message-level PERMA scores predicted from the different models and the ground-truth annotations.", "labels": [], "entities": [{"text": "Pearson correlations", "start_pos": 65, "end_pos": 85, "type": "METRIC", "confidence": 0.9781676828861237}]}, {"text": "Lexica were built on 80% of the messages and then evaluated on the remaining 20%.", "labels": [], "entities": []}, {"text": "Comparing the English and Spanish source language and machine translated models, we observe substantially better performance when models were built over the same language they are applied to, i.e., using models builtin Spanish to predict on Spanish Tweets.", "labels": [], "entities": []}, {"text": "Translating the models (e.g., translating an English model to Spanish and using it on Spanish Tweets) or translating the Tweets (e.g., translating Spanish Tweets to English and using an English model) work substantially less well, with translating the Tweets giving marginally better performance than translating the models.", "labels": [], "entities": []}, {"text": "Finally, we translate both the model and Tweets, giving slightly better performance than translating the Tweets alone.", "labels": [], "entities": []}, {"text": "Complete PERMA lexica were then built over the entire message sets for public release.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Summary of translation errors. Percentages are av-", "labels": [], "entities": [{"text": "Summary of translation", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.5314726034800211}]}, {"text": " Table 3: Examples of specific errors. Error types are denoted", "labels": [], "entities": []}]}