{"title": [{"text": "Improving Multilingual Named Entity Recognition with Wikipedia Entity Type Mapping", "labels": [], "entities": [{"text": "Improving Multilingual Named Entity Recognition", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.8875329732894898}, {"text": "Wikipedia Entity Type Mapping", "start_pos": 53, "end_pos": 82, "type": "TASK", "confidence": 0.5951617211103439}]}], "abstractContent": [{"text": "The state-of-the-art named entity recognition (NER) systems are statistical machine learning models that have strong generalization capability (i.e., can recognize unseen entities that do not appear in training data) based on lexical and contextual information.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 21, "end_pos": 51, "type": "TASK", "confidence": 0.8295849959055582}]}, {"text": "However , such a model could still make mistakes if its features favor a wrong entity type.", "labels": [], "entities": []}, {"text": "In this paper, we utilize Wikipedia as an open knowledge base to improve multilingual NER systems.", "labels": [], "entities": []}, {"text": "Central to our approach is the construction of high-accuracy, high-coverage multilingual Wikipedia entity type mappings.", "labels": [], "entities": []}, {"text": "These mappings are built from weakly annotated data and can be extended to new languages with no human annotation or language-dependent knowledge involved.", "labels": [], "entities": []}, {"text": "Based on these mappings, we develop several approaches to improve an NER system.", "labels": [], "entities": [{"text": "NER", "start_pos": 69, "end_pos": 72, "type": "TASK", "confidence": 0.9654690027236938}]}, {"text": "We evaluate the performance of the approaches via experiments on NER systems trained for 6 languages.", "labels": [], "entities": []}, {"text": "Experimental results show that the proposed approaches are effective in improving the accuracy of such systems on unseen entities, especially when a system is applied to anew domain or it is trained with little training data (up to 18.3 F 1 score improvement).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9985126852989197}, {"text": "18.3 F 1 score improvement", "start_pos": 232, "end_pos": 258, "type": "METRIC", "confidence": 0.7656045019626617}]}], "introductionContent": [{"text": "Named entity recognition (NER) is an important NLP task that automatically detects entities in text and classifies them into pre-defined entity types such as persons, organizations, geopolitical entities, locations, events, etc.", "labels": [], "entities": [{"text": "Named entity recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7757125248511633}]}, {"text": "NER is a fundamental component of many information extraction and knowledge discovery applications, including relation extraction, entity linking, question answering and data mining.", "labels": [], "entities": [{"text": "NER", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8710358142852783}, {"text": "information extraction and knowledge discovery", "start_pos": 39, "end_pos": 85, "type": "TASK", "confidence": 0.7634343981742859}, {"text": "relation extraction", "start_pos": 110, "end_pos": 129, "type": "TASK", "confidence": 0.8409172594547272}, {"text": "entity linking", "start_pos": 131, "end_pos": 145, "type": "TASK", "confidence": 0.8013140559196472}, {"text": "question answering", "start_pos": 147, "end_pos": 165, "type": "TASK", "confidence": 0.9115809798240662}, {"text": "data mining", "start_pos": 170, "end_pos": 181, "type": "TASK", "confidence": 0.8173742890357971}]}, {"text": "The state-of-the-art NER systems are usually statistical machine learning models that are trained with human-annotated data.", "labels": [], "entities": [{"text": "NER", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.9781589508056641}]}, {"text": "Popular models include maximum entropy Markov models (MEMM) (), conditional random fields (CRF) () and neural networks).", "labels": [], "entities": []}, {"text": "Such models have strong generalization capability to recognize unseen entities 1 based on lexical and contextual information (features).", "labels": [], "entities": []}, {"text": "However, a model could still make mistakes if its features favor a wrong entity type, which happens more frequently for unseen entities as we have observed in our experiments.", "labels": [], "entities": []}, {"text": "Wikipedia is an open-access, free-content Internet encyclopedia, which has become the de facto on-line source for general reference.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9268260598182678}]}, {"text": "A Wikipedia page about an entity normally includes both structured information and unstructured text information, and such information can be used to help determine the entity type of the referred entity.", "labels": [], "entities": []}, {"text": "So far there are two classes of approaches that exploit Wikipedia to improve NER.", "labels": [], "entities": []}, {"text": "The first class of approaches use Wikipedia to generate features for NER systems, e.g.,.", "labels": [], "entities": []}, {"text": "try to find the Wikipedia entity for each candidate word sequence and then extract a category label from the first sentence of the Wikipedia entity page.", "labels": [], "entities": []}, {"text": "A part-of-speech (POS) tagger is used to extract the category label features in the training and decoding phase.", "labels": [], "entities": []}, {"text": "aggregate several Wikipedia categories into higher-level concept and build a gazetteer on top of it.", "labels": [], "entities": []}, {"text": "The two approaches were shown to be able to improve an English NER system.", "labels": [], "entities": []}, {"text": "Both approaches, however, are language-dependent because () requires a POS tagger and () requires manual category aggregation by inspection of the annotation guidelines and the training set.", "labels": [], "entities": []}, {"text": "assume that document-specific knowledge base (e.g., Wikipedia) tags for each document are provided, and they use those tags to build gazetteer type features for improving an English NER system.", "labels": [], "entities": []}, {"text": "The second class of approaches use Wikipedia to generate weakly annotated data for training multilingual NER systems, e.g.,).", "labels": [], "entities": []}, {"text": "The motivation is that annotating multilingual NER data by human is both expensive and time-consuming.", "labels": [], "entities": [{"text": "NER", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.8454936742782593}]}, {"text": "utilize the category information of Wikipedia to determine the entity type of an entity based on manually constructed rules (e.g., category phrase \"Living People\" is mapped to entity type PERSON).", "labels": [], "entities": []}, {"text": "Such a rule-based entity type mapping is limited both inaccuracy and coverage, e.g.,).", "labels": [], "entities": [{"text": "coverage", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9729193449020386}]}, {"text": "train a Wikipedia entity type classifier using human-annotated Wikipedia pages.", "labels": [], "entities": [{"text": "Wikipedia entity type classifier", "start_pos": 8, "end_pos": 40, "type": "TASK", "confidence": 0.7355417311191559}]}, {"text": "Such a supervised-learning based approach has better accuracy and coverage, e.g.,.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9993501305580139}, {"text": "coverage", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9829172492027283}]}, {"text": "A number of heuristic rules are developed in both works to label the Wikipedia text to create weakly annotated NER training data.", "labels": [], "entities": []}, {"text": "The NER systems trained with the weakly annotated data may achieve similar accuracy compared with systems trained with little human-annotated data (e.g., up to 40K tokens as in (), but they are still significantly worse than well-trained systems (e.g., a drop of 23.9 F 1 score on the CoNLL data and a drop of 19.6 F 1 score on the BBN data as in).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9988211989402771}, {"text": "F 1 score", "start_pos": 268, "end_pos": 277, "type": "METRIC", "confidence": 0.9636293649673462}, {"text": "CoNLL data", "start_pos": 285, "end_pos": 295, "type": "DATASET", "confidence": 0.9665792882442474}, {"text": "F 1 score", "start_pos": 315, "end_pos": 324, "type": "METRIC", "confidence": 0.9639220237731934}, {"text": "BBN data", "start_pos": 332, "end_pos": 340, "type": "DATASET", "confidence": 0.9808672368526459}]}, {"text": "In this paper, we propose anew class of approaches that utilize Wikipedia to improve multilingual NER systems.", "labels": [], "entities": []}, {"text": "Central to our approaches is the construction of high-accuracy, high-coverage multilingual Wikipedia entity type mappings.", "labels": [], "entities": []}, {"text": "We use weakly annotated data to train an English Wikipedia entity type classifier, as opposed to using humanannotated data as in.", "labels": [], "entities": []}, {"text": "The accuracy of the classifier is further improved via self-training.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9993515610694885}]}, {"text": "We apply the classifier on all the English Wikipedia pages and construct an English Wikipedia entity type mapping that includes entities with high classification confidence scores.", "labels": [], "entities": []}, {"text": "To build multilingual Wikipedia entity type mappings, we generate weakly annotated classifier training data for another language via projection using the inter-language links of Wikipedia.", "labels": [], "entities": [{"text": "multilingual Wikipedia entity type mappings", "start_pos": 9, "end_pos": 52, "type": "TASK", "confidence": 0.5180998146533966}]}, {"text": "This approach requires no human annotation or language-dependent knowledge, and thus can be easily applied to new languages.", "labels": [], "entities": []}, {"text": "Our goal is to utilize the Wikipedia entity type mappings to improve NER systems.", "labels": [], "entities": [{"text": "NER", "start_pos": 69, "end_pos": 72, "type": "TASK", "confidence": 0.945381760597229}]}, {"text": "A natural approach is to use a mapping to create dictionary type features for training an NER system.", "labels": [], "entities": []}, {"text": "In addition, we develop several other approaches.", "labels": [], "entities": []}, {"text": "The first approach applies an entity type mapping as a decoding constraint for an NER system.", "labels": [], "entities": []}, {"text": "The second approach uses a mapping to post-process the output of an NER system.", "labels": [], "entities": []}, {"text": "We also design a robust joint approach that combines the decoding constraint approach and the post-processing approach in a smart way.", "labels": [], "entities": []}, {"text": "We evaluate the performance of the Wikipediabased approaches on NER systems trained for 6 languages.", "labels": [], "entities": []}, {"text": "We find that when a system is well trained (e.g., with 200K to 300K tokens of human-annotated data), the dictionary feature approach achieves the best improvement over the baseline system; while when a system is trained with little human-annotated training data (e.g., 20K to 30K tokens), a more aggressive decoding constraint approach achieves the best improvement.", "labels": [], "entities": []}, {"text": "In both scenarios, the Wikipediabased approaches are effective in improving the accuracy on unseen entities, especially when a system is applied to anew domain (3.6 F 1 score improvement on political party articles/English NER) or it is trained with little training data (18.3 F 1 score improvement on Japanese NER).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9987781643867493}, {"text": "F 1 score", "start_pos": 165, "end_pos": 174, "type": "METRIC", "confidence": 0.9204034805297852}]}, {"text": "We organize the paper as follows.", "labels": [], "entities": []}, {"text": "We describe how to build English Wikipedia entity type mapping in Section 2 and extend it to multilingual mappings in Section 3.", "labels": [], "entities": [{"text": "English Wikipedia entity type mapping", "start_pos": 25, "end_pos": 62, "type": "TASK", "confidence": 0.6727246046066284}]}, {"text": "We present several Wikipedia-based approaches for improving NER systems in Section 4 and evaluate their performance in Section 5.", "labels": [], "entities": [{"text": "NER", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.9564570784568787}]}, {"text": "We conclude the paper in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we evaluate the effectiveness of the proposed Wikipedia-based approaches via experiments on NER systems trained for 6 languages: English, Portuguese, Japanese, Spanish, Dutch and German.", "labels": [], "entities": []}, {"text": "For each language, we compare the baseline NER system with the following approaches: \u2022 DC(i): the decoding constraint approach with mapping Language-Wiki-Mapping(0.9,i).", "labels": [], "entities": []}, {"text": "\u2022 PP(i): the post-processing approach with mapping Language-Wiki-Mapping(0.9,i).", "labels": [], "entities": []}, {"text": "\u2022 Joint: the joint approach that combines DC(3) and PP(2).", "labels": [], "entities": []}, {"text": "\u2022 DF(i): the dictionary feature approach with mapping Language-Wiki-Mapping(0.9,i).", "labels": [], "entities": []}, {"text": "To evaluate the generalization capability of an NER system, we compute the F 1 score on the unseen entities (Unseen) as well as on all the entities (All) in a test data set.", "labels": [], "entities": [{"text": "NER", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.9121056199073792}, {"text": "F 1 score", "start_pos": 75, "end_pos": 84, "type": "METRIC", "confidence": 0.9898220499356588}]}], "tableCaptions": [{"text": " Table 1: F1 score of English Wikipedia entity type classifiers.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9755600690841675}]}, {"text": " Table 2: Improving classifier accuracy via self-training.", "labels": [], "entities": [{"text": "Improving classifier", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.7680087387561798}, {"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.942459225654602}]}, {"text": " Table 3: Experimental results for English NER (the highest F1", "labels": [], "entities": [{"text": "English NER", "start_pos": 35, "end_pos": 46, "type": "TASK", "confidence": 0.6227797120809555}, {"text": "F1", "start_pos": 60, "end_pos": 62, "type": "METRIC", "confidence": 0.9768242239952087}]}, {"text": " Table 4: Experimental results for Portuguese NER.", "labels": [], "entities": [{"text": "Portuguese NER", "start_pos": 35, "end_pos": 49, "type": "TASK", "confidence": 0.651011735200882}]}, {"text": " Table 5: Experimental results for Japanese NER.", "labels": [], "entities": [{"text": "Japanese NER", "start_pos": 35, "end_pos": 47, "type": "TASK", "confidence": 0.5605234652757645}]}, {"text": " Table 6: Experimental results for Spanish, Dutch, and German", "labels": [], "entities": []}]}