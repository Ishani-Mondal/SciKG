{"title": [{"text": "Weakly Supervised Tweet Stance Classification by Relational Bootstrapping", "labels": [], "entities": [{"text": "Tweet Stance Classification", "start_pos": 18, "end_pos": 45, "type": "TASK", "confidence": 0.9375793139139811}]}], "abstractContent": [{"text": "Supervised stance classification, in such domains as Congressional debates and online forums, has been a topic of interest in the past decade.", "labels": [], "entities": [{"text": "Supervised stance classification", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.9149918357531229}]}, {"text": "Approaches have evolved from text classification to structured output prediction , including collective classification and sequence labeling.", "labels": [], "entities": [{"text": "text classification", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.7527677416801453}, {"text": "structured output prediction", "start_pos": 52, "end_pos": 80, "type": "TASK", "confidence": 0.7649744550387064}, {"text": "collective classification", "start_pos": 93, "end_pos": 118, "type": "TASK", "confidence": 0.7341967523097992}, {"text": "sequence labeling", "start_pos": 123, "end_pos": 140, "type": "TASK", "confidence": 0.6334343552589417}]}, {"text": "In this work, we investigate collective classification of stances on Twitter, using hinge-loss Markov random fields (HL-MRFs).", "labels": [], "entities": [{"text": "collective classification of stances", "start_pos": 29, "end_pos": 65, "type": "TASK", "confidence": 0.7386607080698013}]}, {"text": "Given the graph of all posts, users, and their relationships, we constrain the predicted post labels and latent user labels to correspond with the network structure.", "labels": [], "entities": []}, {"text": "We focus on a weakly supervised setting, in which only a small set of hashtags or phrases is labeled.", "labels": [], "entities": []}, {"text": "Using our relational approach, we are able to go beyond the stance-indicative patterns and harvest more stance-indicative tweets, which can also be used to train any linear text classi-fier when the network structure is not available or is costly.", "labels": [], "entities": []}], "introductionContent": [{"text": "Stance classification is the task of determining from text whether the author of the text is in favor of, against, or neutral towards a target of interest.", "labels": [], "entities": [{"text": "Stance classification", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9356276094913483}]}, {"text": "This is an interesting task to study on social networks due to the abundance of personalized and opinionated language.", "labels": [], "entities": []}, {"text": "Studying stance classification can be beneficial in identifying electoral issues and understanding how public stance is shaped.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 9, "end_pos": 30, "type": "TASK", "confidence": 0.7160976827144623}]}, {"text": "Twitter provides a wealth of information: public tweets by individuals, their profile information, whom they follow, and more.", "labels": [], "entities": []}, {"text": "Exploiting all these pieces of information, in addition to the text, could help build better NLP systems.", "labels": [], "entities": []}, {"text": "Examples of this approach include user preference modeling (), stance classification (Rajadesingan and, and geolocation identification).", "labels": [], "entities": [{"text": "user preference modeling", "start_pos": 34, "end_pos": 58, "type": "TASK", "confidence": 0.7887888352076212}, {"text": "stance classification", "start_pos": 63, "end_pos": 84, "type": "TASK", "confidence": 0.9001631140708923}, {"text": "geolocation identification", "start_pos": 108, "end_pos": 134, "type": "TASK", "confidence": 0.7587592005729675}]}, {"text": "For stance classification, knowing the author's past posting behavior, or her friends' stances on issues, could improve the stance classifier.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.9644158184528351}]}, {"text": "These are inherently structured problems, and they demand structured solutions, such as Statistical Relational Learning (SRL).", "labels": [], "entities": [{"text": "Statistical Relational Learning (SRL)", "start_pos": 88, "end_pos": 125, "type": "TASK", "confidence": 0.8345702588558197}]}, {"text": "In this paper, we use hinge-loss Markov random fields (HL-MRFs) (), a recent development in the SRL community.", "labels": [], "entities": [{"text": "SRL", "start_pos": 96, "end_pos": 99, "type": "TASK", "confidence": 0.9584507346153259}]}, {"text": "SemEval 2016 Task 6 organizers () released a dataset with Donald Trump as the target, without stance annotation.", "labels": [], "entities": [{"text": "SemEval 2016 Task 6 organizers", "start_pos": 0, "end_pos": 30, "type": "DATASET", "confidence": 0.9005179047584534}]}, {"text": "The goal of the task was to evaluate stance classification systems, which used minimal labeling on phrases.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.9049493670463562}]}, {"text": "This scenario is becoming more and more relevant due to the vast amount of data and ever-changing nature of the language on social media.", "labels": [], "entities": []}, {"text": "This is critical in applications in which a timely detection is highly desired, such as violence detection) and disaster situations.", "labels": [], "entities": [{"text": "violence detection", "start_pos": 88, "end_pos": 106, "type": "TASK", "confidence": 0.8024814128875732}]}, {"text": "Our work is the first to use SRL for stance classification on Twitter.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.9596666693687439}]}, {"text": "We formulate the weakly supervised stance classification problem as a bi-type collective classification problem: We start from a small set of stance-indicative patterns and label the tweets as positive and negative, accordingly.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 35, "end_pos": 56, "type": "TASK", "confidence": 0.7342342287302017}]}, {"text": "Then, our relational learner uses these noisy-labeled tweets, as well as the network structure, to classify the stance of other tweets and authors.", "labels": [], "entities": []}, {"text": "Our goal will be to constrain pairs of similar tweets, pairs of tweets and their authors, and pairs of neighboring users to have similar labels.", "labels": [], "entities": []}, {"text": "We do this through hinge-loss feature functions that encode our background knowledge about the domain: (1) A person is pro/against Trump if she writes a tweet with such stance; (2) Friends in asocial network often agree on their stance toward Trump; (3) similar tweets express similar stances.", "labels": [], "entities": []}], "datasetContent": [{"text": "We pick the pro-Trump and anti-Trump indicative regular expressions and hashtags, which are shown in.", "labels": [], "entities": []}, {"text": "Tweets that have at least one positive or one negative pattern, and do not have both positive and negative patterns, are considered as our initial positive and negative instances.", "labels": [], "entities": []}, {"text": "This gives us a dataset with noisy labels; for example, the tweet \"his #MakeAmericaGreatAgain #Tag is a bummer.\" is against Donald Trump, incorrectly labeled favorable.", "labels": [], "entities": []}, {"text": "A quantitative analysis of the impact of noise, and the goodness of initial patterns, can be pursued in the future through a supervised approach.", "labels": [], "entities": []}, {"text": "Tweets in the \"neither\" class range from news about the target of interest, to tweets totally irrele- vant to him.", "labels": [], "entities": []}, {"text": "This makes it difficult to collect neutral tweets, and we will classify tweets to be in that class based on a heuristic described in the next subsection.", "labels": [], "entities": []}, {"text": "Given the limited number of seeds, we need to collect more training instances to build a stance classifier.", "labels": [], "entities": []}, {"text": "Because of the original noise in the labels and the imposed fragmentary view of data, self-learning would perform poorly.", "labels": [], "entities": []}, {"text": "Instead, we augment the dataset with tweets that our relational model classifies as positive or negative with a minimum confidence (class value 0.52 for pro-Trump and 0.56 for anti-Trump).", "labels": [], "entities": []}, {"text": "The hyper-parameters were found through experimenting on a development set, which was the stance-annotated dataset of SemEval Task 6.a.", "labels": [], "entities": [{"text": "stance-annotated dataset of SemEval Task 6.a", "start_pos": 90, "end_pos": 134, "type": "DATASET", "confidence": 0.6618537207444509}]}, {"text": "The targets of that dataset include Hillary Clinton, Abortion, Climate Change, and Athesim.", "labels": [], "entities": []}, {"text": "Since there are more anti-Trump tweets than pro-Trump (, for our grid search we prefer a higher confidence threshold for the antiTrump class, making it harder for the class bias to adversely impact the quality of harvested tweets.", "labels": [], "entities": []}, {"text": "We also exclude the tweets that were sent by a user with no friends in the network.", "labels": [], "entities": []}, {"text": "An example which showcases relational harvesting of tweets can be seen in, wherein given the evidence, some of which is shown, three new tweets are found.", "labels": [], "entities": [{"text": "relational harvesting of tweets", "start_pos": 27, "end_pos": 58, "type": "TASK", "confidence": 0.8489152044057846}]}], "tableCaptions": [{"text": " Table 2: Statistics of the data", "labels": [], "entities": []}, {"text": " Table 3: Evaluation on SemEval-2016 Task 6.b.", "labels": [], "entities": [{"text": "SemEval-2016 Task", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.8304092586040497}]}]}