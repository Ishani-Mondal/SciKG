{"title": [{"text": "Improving Sparse Word Representations with Distributional Inference for Semantic Composition", "labels": [], "entities": [{"text": "Improving Sparse Word Representations", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8553808331489563}, {"text": "Semantic Composition", "start_pos": 72, "end_pos": 92, "type": "TASK", "confidence": 0.75462207198143}]}], "abstractContent": [{"text": "Distributional models are derived from co-occurrences in a corpus, where only a small proportion of all possible plausible co-occurrences will be observed.", "labels": [], "entities": []}, {"text": "This results in a very sparse vector space, requiring a mechanism for inferring missing knowledge.", "labels": [], "entities": []}, {"text": "Most methods face this challenge in ways that render the resulting word representations uninterpretable, with the consequence that semantic composition becomes hard to model.", "labels": [], "entities": []}, {"text": "In this paper we explore an alternative which involves explicitly inferring un-observed co-occurrences using the distribu-tional neighbourhood.", "labels": [], "entities": []}, {"text": "We show that distribu-tional inference improves sparse word representations on several word similarity benchmarks and demonstrate that our model is competitive with the state-of-the-art for adjective-noun, noun-noun and verb-object compositions while being fully interpretable.", "labels": [], "entities": []}], "introductionContent": [{"text": "The aim of distributional semantics is to derive meaning representations based on observing cooccurrences of words in large text corpora.", "labels": [], "entities": []}, {"text": "However not all plausible co-occurrences will be observed in any given corpus, resulting in word representations that only capture a fragment of the meaning of a word.", "labels": [], "entities": []}, {"text": "For example the verbs \"walking\" and \"strolling\" may occur in many different and possibly disjoint contexts, although both verbs would be equally plausible in numerous cases.", "labels": [], "entities": []}, {"text": "This subsequently results in incomplete representations for both lexemes.", "labels": [], "entities": []}, {"text": "In addition, models based on counting co-occurrences face the general problem of sparsity in a very high-dimensional vector space.", "labels": [], "entities": []}, {"text": "The most common approaches to these challenges have involved the use of various techniques for dimensionality reduction or the use of low-dimensional and dense neural word embeddings ().", "labels": [], "entities": [{"text": "dimensionality reduction", "start_pos": 95, "end_pos": 119, "type": "TASK", "confidence": 0.7401485741138458}]}, {"text": "The common problem in both of these approaches is that composition becomes a black-box process due to the lack of interpretability of the representations.", "labels": [], "entities": []}, {"text": "Count-based models are therefore a very attractive line of work with regards to a number of important long-term research challenges, most notably the development of an adequate model of distributional compositional semantics.", "labels": [], "entities": [{"text": "distributional compositional semantics", "start_pos": 186, "end_pos": 224, "type": "TASK", "confidence": 0.6693770587444305}]}, {"text": "In this paper we propose the use of distributional inference (DI) to inject unobserved but plausible distributional semantic knowledge into the vector space by leveraging the intrinsic structure of the distributional neighbourhood.", "labels": [], "entities": [{"text": "distributional inference (DI)", "start_pos": 36, "end_pos": 65, "type": "TASK", "confidence": 0.6541335344314575}]}, {"text": "This results in richer word representations and furthermore mitigates the sparsity effect common in high-dimensional vector spaces, while remaining fully interpretable.", "labels": [], "entities": []}, {"text": "Our contributions are as follows: we show that typed and untyped sparse word representations, enriched by distributional inference, lead to performance improvements on several word similarity benchmarks, and that a higher-order dependency-typed vector space model, based on \"Anchored Packed Dependency Trees (APTs)\", is competitive with the state-of-the-art for adjective-noun, noun-noun and verb-object compositions.", "labels": [], "entities": []}, {"text": "Using our method, we are able to bridge the gap in performance between high dimensional interpretable mod-els and low dimensional non-interpretable models and offer evidence to support a possible explanation of why high-dimensional models usually perform worse, together with a simple, practical method for over-coming this problem.", "labels": [], "entities": []}, {"text": "We furthermore demonstrate that intersective approaches to composition benefit more from distributional inference than composition by union and highlight the ability of composition by intersection to disambiguate the meaning of a phrase in a local context.", "labels": [], "entities": []}, {"text": "The remainder of this paper is structured as follows: we discuss related work in section 2, followed by an introduction of the APT framework for semantic composition in section 3.", "labels": [], "entities": [{"text": "semantic composition", "start_pos": 145, "end_pos": 165, "type": "TASK", "confidence": 0.6802811324596405}]}, {"text": "We describe distributional inference in section 4 and present our experimental work, together with our results in section 5.", "labels": [], "entities": [{"text": "distributional inference", "start_pos": 12, "end_pos": 36, "type": "TASK", "confidence": 0.799572080373764}]}, {"text": "We conclude this paper and outline future work in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our model is based on a cleaned October 2013 Wikipedia dump, which excludes all pages with fewer than 20 page views, resulting in a corpus of approximately 0.6 billion tokens.", "labels": [], "entities": []}, {"text": "The corpus is lowercased, tokenised, lemmatised, PoS tagged and dependency parsed with the Stanford NLP tools, using universal dependencies).", "labels": [], "entities": []}, {"text": "We then build our APT model with first, second and third order relations.", "labels": [], "entities": [{"text": "APT", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.9027987122535706}]}, {"text": "We remove distributional features with a count of less than 10, and vectors containing fewer than 50 non-zero entries.", "labels": [], "entities": []}, {"text": "The raw counts are subsequently transformed to PPMI weights.", "labels": [], "entities": []}, {"text": "The untyped vector space model is built from the same lowercased, tokenised and lemmatised Wikipedia corpus.", "labels": [], "entities": [{"text": "Wikipedia corpus", "start_pos": 91, "end_pos": 107, "type": "DATASET", "confidence": 0.8050509989261627}]}, {"text": "We discard terms with a frequency of less than 50 and apply PPMI to the raw co-occurrence counts.", "labels": [], "entities": [{"text": "PPMI", "start_pos": 60, "end_pos": 64, "type": "METRIC", "confidence": 0.6458533406257629}]}, {"text": "We first evaluate our models on 3 word similarity benchmarks, MEN (), which is testing for relatedness (e.g. meronymy or holonymy) between terms, SimLex-999 (, which is testing for substitutability (e.g. synonymy, antonymy, hyponymy and hypernymy), and WordSim-353 (), where we use the version of, who split the dataset into a relatedness and a substitutability subset.", "labels": [], "entities": [{"text": "WordSim-353", "start_pos": 253, "end_pos": 264, "type": "DATASET", "confidence": 0.9319546818733215}]}, {"text": "have shown that untyped models are typically better at capturing relatedness, whereas typed models are better at encoding substitutability.", "labels": [], "entities": []}, {"text": "Performance is measured by computing Spearman's \u03c1 between the cosine similarities of the vector representations and the corresponding aggregated human similarity judgements.", "labels": [], "entities": [{"text": "Spearman's \u03c1", "start_pos": 37, "end_pos": 49, "type": "METRIC", "confidence": 0.5395247439543406}]}, {"text": "For these experiments we keep the number of neighbours that a word vector can consume fixed at 30.", "labels": [], "entities": []}, {"text": "This value is based on preliminary experiments on WordSim-353 (see) using the static top n neighbour retrieval function and a PPMI shift of k = 40.", "labels": [], "entities": [{"text": "WordSim-353", "start_pos": 50, "end_pos": 61, "type": "DATASET", "confidence": 0.9803586006164551}]}, {"text": "shows that distributional inference improves performance for any number of neighbours over a model without DI (marked as horizontal dashed lines for each WordSim-353 subset) and peaks at a value of 30.", "labels": [], "entities": [{"text": "WordSim-353 subset", "start_pos": 154, "end_pos": 172, "type": "DATASET", "confidence": 0.9007768332958221}]}, {"text": "Performance slightly degrades with more neighbours.", "labels": [], "entities": []}, {"text": "For the untyped VSM we use asymmetric window of 5 on either side of the target word.", "labels": [], "entities": []}, {"text": "highlights the effect of the SPPMI shift parameter k, while keeping the number of neighbours fixed at 30 and using the static top n neighbour retrieval function.", "labels": [], "entities": [{"text": "SPPMI shift", "start_pos": 29, "end_pos": 40, "type": "TASK", "confidence": 0.7858957052230835}]}, {"text": "For the APT model, a value of k = 40 performs best (except for SimLex-999, where smaller shifts give better results), with a performance drop-off for larger shifts.", "labels": [], "entities": [{"text": "APT", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.8405532836914062}]}, {"text": "In our experiments we find that a shift of k = 1 results in top performance for the untyped vector space model.", "labels": [], "entities": []}, {"text": "It appears that shifting the PPMI scores in the APT model has the effect of cleaning the vectors from noisy PPMI artefacts, which reinforces the predominant sense, while other senses get suppressed.", "labels": [], "entities": []}, {"text": "Subsequently, this results in a cleaner neighbourhood around the word vector, dominated by a single sense.", "labels": [], "entities": []}, {"text": "This explains why distributional inference slightly degrades performance for smaller values of k. shows that distributional inference successfully infers missing information for both model types, resulting in improved performance over models without the use of DI on all datasets.", "labels": [], "entities": []}, {"text": "The improvements are typically larger for the APT model, suggesting that it is missing more distributional knowledge in its elementary representations than untyped models.", "labels": [], "entities": [{"text": "APT", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.8176273703575134}]}, {"text": "The density window and static top n neighbour retrieval functions perform very similar, however the static approach is more consistent and never underperforms the baseline for either model type on any dataset.", "labels": [], "entities": []}, {"text": "The WordNet based neighbour retrieval function performs particularly well on SimLex-999.", "labels": [], "entities": [{"text": "WordNet based neighbour retrieval", "start_pos": 4, "end_pos": 37, "type": "TASK", "confidence": 0.7538381963968277}]}, {"text": "This can be explained by the fact that antonyms, which frequently happen to be among the nearest neighbours in distributional vector spaces, are regarded as dissimilar in SimLex-999, whereas the WordNet neighbour retrieval function only returns synonyms.", "labels": [], "entities": []}, {"text": "The results furthermore confirm the effect that untyped models perform better on datasets modelling relatedness, whereas typed models work better for substitutability tasks ().", "labels": [], "entities": []}, {"text": "Our approach to semantic composition as described in section 3 requires the dimensions of our vector space models to be meaningful and interpretable.", "labels": [], "entities": [{"text": "semantic composition", "start_pos": 16, "end_pos": 36, "type": "TASK", "confidence": 0.7952643036842346}]}, {"text": "However, the problem of missing information is amplified in compositional settings as many compatible dimensions between words are not observed in the source corpus.", "labels": [], "entities": []}, {"text": "It is therefore crucial that distributional inference is able to inject some of the missing information in order to improve the composition process.", "labels": [], "entities": []}, {"text": "For the experiments involving semantic composition, we enrich the elementary representations of the phrase constituents before composition.", "labels": [], "entities": [{"text": "semantic composition", "start_pos": 30, "end_pos": 50, "type": "TASK", "confidence": 0.7235560268163681}]}, {"text": "We first conduct a qualitative analysis for our APT model and observe the effect of distributional inference on the nearest neighbours of composed adjective-noun, noun-noun and verb-object compounds.", "labels": [], "entities": [{"text": "APT", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.8674342632293701}]}, {"text": "In these experiments, we show how distributional inference changes the neighbourhood in which composed phrases are embedded, and highlight the difference between composition by union and composition by intersection.", "labels": [], "entities": []}, {"text": "For this experiment we use the static top n neighbour retrieval function with 30 neighbours and k = 40.", "labels": [], "entities": []}, {"text": "shows a small number of example phrases together with their top 3 nearest neighbours, computed from the union of all words in the Wikipedia corpus and all phrase pairs in the Mitchell and Lapata (2010) dataset.", "labels": [], "entities": [{"text": "Wikipedia corpus", "start_pos": 130, "end_pos": 146, "type": "DATASET", "confidence": 0.9173300564289093}, {"text": "Mitchell and Lapata (2010) dataset", "start_pos": 175, "end_pos": 209, "type": "DATASET", "confidence": 0.7218789330550602}]}, {"text": "As can be seen, nearest neighbours of phrases can be either single words or other composed phrases.", "labels": [], "entities": []}, {"text": "Words or phrases marked with \"*\" in mean that DI introduced, or failed to downrank, a spurious neighbour, while boldface means that performing distributional inference resulted in a neighbourhood more coherent with the query phrase than without DI.", "labels": [], "entities": []}, {"text": "downrank unrelated neighbours introduced by distributional inference.", "labels": [], "entities": []}, {"text": "For example large quantity is incorrectly introduced as atop ranked neighbour for the phrase small house, due to the proximity of small and large in the vector space.", "labels": [], "entities": []}, {"text": "The phrases market leader and television programme are two examples of incoherent neighbours, which the composition function was unable to downrank and where DI could not improve the neighbourhood.", "labels": [], "entities": []}, {"text": "Composition by intersection on the other hand vastly benefits from distributional inference.", "labels": [], "entities": []}, {"text": "Due to the increased sparsity induced by the composition process, a neighbourhood without DI produces numerous spurious neighbours as in the case of the verb have as a neighbour for win battle.", "labels": [], "entities": []}, {"text": "Distributional inference introduces qualitatively better neighbours for almost all phrases.", "labels": [], "entities": [{"text": "Distributional inference", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8348581194877625}]}, {"text": "For example, government leader and opposition member are introduced as top ranked neighbours for the phrase party leader, and stress importance and underline are introduced as new top neighbours for the phrase emphasise need.", "labels": [], "entities": []}, {"text": "These results show that composition by union does not have the ability to disambiguate the meaning of a word in a given phrasal context, whereas composition by intersection has that ability but requires distributional inference to unleash its full potential.", "labels": [], "entities": []}, {"text": "For a quantitative analysis of distributional inference for semantic composition, we evaluate our model on the composition dataset of, consisting of 108 adjective-noun, 108 noun-noun, and 108 verb-object pairs.", "labels": [], "entities": []}, {"text": "The task is to compare the model's similarity estimates with the human judgements by computing Spearman's \u03c1.", "labels": [], "entities": [{"text": "Spearman's \u03c1", "start_pos": 95, "end_pos": 107, "type": "METRIC", "confidence": 0.5968101620674133}]}, {"text": "For comparing the performance of the different neighbour retrieval functions, we choose the same parameter settings as in the word similarity experiments (k = 40 and using 30 neighbours for DI).", "labels": [], "entities": []}, {"text": "shows that the static top n and density window neighbour retrieval functions perform very similar again.", "labels": [], "entities": []}, {"text": "The density window retrieval function outperforms static top n for composition by intersection and vice versa for composition by union.", "labels": [], "entities": []}, {"text": "The WordNet approach is competitive for composition by union, but underperfoms the other approaches for composition by intersection significantly.", "labels": [], "entities": []}, {"text": "For further experiments we use the static top n approach as it is computationally cheap and easy to interpret due to the fixed number of neighbours.", "labels": [], "entities": []}, {"text": "inference, composition by union does not appear to benefit from it.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Example feature spaces for the lexemes white and clothes extracted from the dependency tree of", "labels": [], "entities": []}, {"text": " Table 2: Comparison of composition by union and composition by intersection. Not all features are displayed for space reasons.", "labels": [], "entities": []}, {"text": " Table 3: Effect of the magnitude of the shift parameter k in SPPMI on the word similarity tasks. Boldface means best performance", "labels": [], "entities": [{"text": "word similarity tasks", "start_pos": 75, "end_pos": 96, "type": "TASK", "confidence": 0.7959464192390442}]}, {"text": " Table 6: Neighbour retrieval function. Underlined means best performance per phrase type, boldface means best average perfor-", "labels": [], "entities": [{"text": "Underlined", "start_pos": 40, "end_pos": 50, "type": "METRIC", "confidence": 0.9872859120368958}]}, {"text": " Table 7: Results for the", "labels": [], "entities": []}]}