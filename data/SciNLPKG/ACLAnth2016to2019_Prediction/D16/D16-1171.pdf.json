{"title": [{"text": "Neural Sentiment Classification with User and Product Attention", "labels": [], "entities": [{"text": "Neural Sentiment Classification", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8777089516321818}]}], "abstractContent": [{"text": "Document-level sentiment classification aims to predict user's overall sentiment in a document about a product.", "labels": [], "entities": [{"text": "Document-level sentiment classification", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.7953562140464783}]}, {"text": "However, most of existing methods only focus on local text information and ignore the global user preference and product characteristics.", "labels": [], "entities": []}, {"text": "Even though some works take such information into account, they usually suffer from high model complexity and only consider word-level preference rather than semantic levels.", "labels": [], "entities": []}, {"text": "To address this issue, we propose a hierarchical neural network to incorporate global user and product information into sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 120, "end_pos": 144, "type": "TASK", "confidence": 0.9312251806259155}]}, {"text": "Our model first builds a hierarchical LSTM model to generate sentence and document representations.", "labels": [], "entities": []}, {"text": "Afterwards, user and product information is considered via attentions over different semantic levels due to its ability of capturing crucial semantic components.", "labels": [], "entities": []}, {"text": "The experimental results show that our model achieves significant and consistent improvements compared to all state-of-the-art methods.", "labels": [], "entities": []}, {"text": "The source code of this paper can be obtained from https://github.", "labels": [], "entities": []}, {"text": "com/thunlp/NSC.", "labels": [], "entities": [{"text": "NSC", "start_pos": 11, "end_pos": 14, "type": "DATASET", "confidence": 0.8625488877296448}]}], "introductionContent": [{"text": "Sentiment analysis aims to analyze people's sentiments or opinions according to their generated texts and plays a critical role in the area of data mining and natural language processing.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9436213970184326}, {"text": "data mining", "start_pos": 143, "end_pos": 154, "type": "TASK", "confidence": 0.7275328487157822}, {"text": "natural language processing", "start_pos": 159, "end_pos": 186, "type": "TASK", "confidence": 0.6395374834537506}]}, {"text": "Recently, sentiment analysis draws increasing attention of researchers with the rapid growth of online review In this work, we focus on the task of documentlevel sentiment classification, which is a fundamental problem of sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.9460704922676086}, {"text": "documentlevel sentiment classification", "start_pos": 148, "end_pos": 186, "type": "TASK", "confidence": 0.6828581591447195}, {"text": "sentiment analysis", "start_pos": 222, "end_pos": 240, "type": "TASK", "confidence": 0.8976627886295319}]}, {"text": "Document-level sentiment classification assumes that each document expresses a sentiment on a single product and targets to determine the overall sentiment about the product.", "labels": [], "entities": [{"text": "Document-level sentiment classification", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.8581855893135071}]}, {"text": "Most existing methods take sentiment classification as a special case of text classification problem.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 27, "end_pos": 51, "type": "TASK", "confidence": 0.974137932062149}, {"text": "text classification", "start_pos": 73, "end_pos": 92, "type": "TASK", "confidence": 0.7837977707386017}]}, {"text": "Such methods treat annotated sentiment polarities or ratings as categories and apply machine learning algorithms to train classifiers with text features, e.g., bag-of-words vectors ().", "labels": [], "entities": []}, {"text": "Since the performance of text classifiers heavily depends on the extracted features, such studies usually attend to design effective features from text or additional sentiment lexicons).", "labels": [], "entities": []}, {"text": "Motivated by the successful utilization of deep neural networks in computer vision (, speech recognition () and natural language processing (), some neural network based sentiment analysis models are proposed to learn low-dimensional text features without any feature engineering).", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.7227012366056442}, {"text": "sentiment analysis", "start_pos": 170, "end_pos": 188, "type": "TASK", "confidence": 0.8459200859069824}]}, {"text": "Most proposed neural network models take the text information in a sentence or a document as input and generate the semantic representations using well-designed neural networks.", "labels": [], "entities": []}, {"text": "However, these methods only focus on the text content and ignore the crucial characteristics of users and products.", "labels": [], "entities": []}, {"text": "It is a commonsense that the user's preference and product's characteristics make significant influence on the ratings.", "labels": [], "entities": []}, {"text": "To incorporate user and product information into sentiment classification, () bring in a text preference matrix and a representation vector for each user and product into CNN sentiment classifier.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 49, "end_pos": 73, "type": "TASK", "confidence": 0.9006429016590118}, {"text": "CNN sentiment classifier", "start_pos": 171, "end_pos": 195, "type": "TASK", "confidence": 0.5844163695971171}]}, {"text": "It modifies the word meaning in the input layer with the preference matrix and concatenates the user/product representation vectors with generated document representation before softmax layer.", "labels": [], "entities": []}, {"text": "The proposed model achieves some improvements but suffers the following two problems: (1) The introduction of preference matrix for each user/product is insufficient and difficult to be well trained with limited reviews.", "labels": [], "entities": []}, {"text": "For example, most users in IMDB and Yelp only have several tens of reviews, which is not enough to obtain a well-tuned preference matrix.", "labels": [], "entities": [{"text": "Yelp", "start_pos": 36, "end_pos": 40, "type": "DATASET", "confidence": 0.8598585724830627}]}, {"text": "The characteristics of user and product should be reflected on the semantic level besides the word level.", "labels": [], "entities": []}, {"text": "For example, a two star review in Yelp said \"great place to grab a steak and I am a huge fan of the hawaiian pizza \u00b7 \u00b7 \u00b7 but I don't like to have to spend 100 bucks fora diner and drinks for two\".", "labels": [], "entities": [{"text": "Yelp", "start_pos": 34, "end_pos": 38, "type": "DATASET", "confidence": 0.9665738940238953}]}, {"text": "It's obvious that the poor rating result mainly relies on the last sentence compared with others.", "labels": [], "entities": []}, {"text": "To address these issues, we propose a novel hierarchical LSTM model to introduce user and product information into sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 115, "end_pos": 139, "type": "TASK", "confidence": 0.928513914346695}]}, {"text": "As illustrated in, our model mainly consists of two parts.", "labels": [], "entities": []}, {"text": "Firstly, we build a hierarchical LSTM model to generate sentence-level representation and document-level representation jointly.", "labels": [], "entities": []}, {"text": "Afterwards, we introduce user and product information as attentions over different semantic levels of a document.", "labels": [], "entities": []}, {"text": "With the consideration of user and product information, our model can significantly improve the performance of sentiment classification in several realworld datasets.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 111, "end_pos": 135, "type": "TASK", "confidence": 0.9396791458129883}]}, {"text": "To summarize, our effort provide the following three contributions: (1) We propose an effective Neural Sentiment Classification model by taking global user and product information into consideration.", "labels": [], "entities": [{"text": "Neural Sentiment Classification", "start_pos": 96, "end_pos": 127, "type": "TASK", "confidence": 0.8344297409057617}]}, {"text": "Comparing with (), our model contains much less parameters and is more efficient for training.", "labels": [], "entities": []}, {"text": "(2) We introduce user and product information based attentions over different semantic levels of a document.", "labels": [], "entities": []}, {"text": "Traditional attention-based neural network models only take the local text information into consideration.", "labels": [], "entities": []}, {"text": "In contrast, our model puts forward the idea of user-product attention by utilizing the global user preference and product characteristics.", "labels": [], "entities": []}, {"text": "(3) We conduct experiments on several realworld datasets to verify the effectiveness of our model.", "labels": [], "entities": []}, {"text": "The experimental results demonstrate that our model significantly and consistently outperforms other state-of-the-art models.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we introduce the experimental settings and empirical results on the task of documentlevel sentiment classification.", "labels": [], "entities": [{"text": "documentlevel sentiment classification", "start_pos": 93, "end_pos": 131, "type": "TASK", "confidence": 0.718533972899119}]}, {"text": "We evaluate the effectiveness of our NSC model on three sentiment classification datasets with user and product information: IMDB, Yelp 2013 and Yelp 2014, which are built by).", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 56, "end_pos": 80, "type": "TASK", "confidence": 0.8147313892841339}, {"text": "IMDB", "start_pos": 125, "end_pos": 129, "type": "DATASET", "confidence": 0.7516428828239441}]}, {"text": "The statistics of the datasets are summarized in.", "labels": [], "entities": []}, {"text": "We split the datasets into training, development and testing sets in the proportion of 8:1:1, with tokenization and sentence splitting by Stanford CoreNLP ().", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 116, "end_pos": 134, "type": "TASK", "confidence": 0.6822234243154526}, {"text": "Stanford CoreNLP", "start_pos": 138, "end_pos": 154, "type": "DATASET", "confidence": 0.9260000288486481}]}, {"text": "We use two metrics including Accuracy which measures the overall sentiment classification performance and RM SE which measures the divergences between predicted sentiment classes and ground truth classes.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9986420273780823}, {"text": "sentiment classification", "start_pos": 65, "end_pos": 89, "type": "TASK", "confidence": 0.839954286813736}, {"text": "RM SE", "start_pos": 106, "end_pos": 111, "type": "METRIC", "confidence": 0.8999762237071991}]}, {"text": "The Accuracy and RM SE metrics are defined as: where T is the numbers of predicted sentiment ratings that are identical with gold sentiment ratings, N is the numbers of documents and gd i , pr i represent the gold sentiment rating and predicted sentiment rating respectively.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9890375733375549}, {"text": "RM SE", "start_pos": 17, "end_pos": 22, "type": "METRIC", "confidence": 0.6088972687721252}]}, {"text": "Word embeddings could be randomly initialized or pre-trained.", "labels": [], "entities": []}, {"text": "We pre-train the 200-dimensional word embeddings on each dataset in () with SkipGram (.", "labels": [], "entities": [{"text": "SkipGram", "start_pos": 76, "end_pos": 84, "type": "DATASET", "confidence": 0.9391146898269653}]}, {"text": "We set the user embedding dimension and product embedding dimension to be 200, initialized to zero.", "labels": [], "entities": []}, {"text": "The dimensions of hidden states and cell states in our LSTM cells are set to 200.", "labels": [], "entities": []}, {"text": "We tune the hyper parameters on the development sets and use adadelta to update parameters when training.", "labels": [], "entities": []}, {"text": "We select the best configuration based on performance on the development set, and evaluate the configuration on the test set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of IMDB, Yelp2013 and Yelp2014 datasets", "labels": [], "entities": [{"text": "IMDB", "start_pos": 24, "end_pos": 28, "type": "DATASET", "confidence": 0.8679956793785095}, {"text": "Yelp2013", "start_pos": 30, "end_pos": 38, "type": "DATASET", "confidence": 0.9302997589111328}, {"text": "Yelp2014 datasets", "start_pos": 43, "end_pos": 60, "type": "DATASET", "confidence": 0.9435621500015259}]}, {"text": " Table 2: Document-level sentiment classification results. Acc.(Accuracy) and RMSE are the evaluation metrics. The best perfor-", "labels": [], "entities": [{"text": "Document-level sentiment classification", "start_pos": 10, "end_pos": 49, "type": "TASK", "confidence": 0.7391233841578165}, {"text": "Acc.(Accuracy)", "start_pos": 59, "end_pos": 73, "type": "METRIC", "confidence": 0.8311627358198166}, {"text": "RMSE", "start_pos": 78, "end_pos": 82, "type": "METRIC", "confidence": 0.9826459884643555}]}, {"text": " Table 2. As  shown in this table, we manually divide the results  into two parts, the first one of which only considers  the local text information and the other one incorpo-", "labels": [], "entities": []}, {"text": " Table 3: Effect of attention mechanisms in word and sentence level. AVG means an average pooling layer, and ATT represents", "labels": [], "entities": [{"text": "AVG", "start_pos": 69, "end_pos": 72, "type": "METRIC", "confidence": 0.9968677163124084}, {"text": "ATT", "start_pos": 109, "end_pos": 112, "type": "METRIC", "confidence": 0.9929494857788086}]}, {"text": " Table 4: Effect of user and product attention mechanisms. UA represents the user attention mechanism, and PA indicates the", "labels": [], "entities": [{"text": "UA", "start_pos": 59, "end_pos": 61, "type": "METRIC", "confidence": 0.955815315246582}, {"text": "PA", "start_pos": 107, "end_pos": 109, "type": "METRIC", "confidence": 0.9861655235290527}]}]}