{"title": [{"text": "Bi-directional Attention with Agreement for Dependency Parsing", "labels": [], "entities": [{"text": "Bi-directional Attention", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.5681841820478439}, {"text": "Dependency Parsing", "start_pos": 44, "end_pos": 62, "type": "TASK", "confidence": 0.7221286296844482}]}], "abstractContent": [{"text": "We develop a novel bi-directional attention model for dependency parsing, which learns to agree on headword predictions from the forward and backward parsing directions.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 54, "end_pos": 72, "type": "TASK", "confidence": 0.8848603069782257}]}, {"text": "The parsing procedure for each direction is formulated as sequentially querying the memory component that stores continuous headword embeddings.", "labels": [], "entities": []}, {"text": "The proposed parser makes use of soft headword embeddings, allowing the model to implicitly capture high-order parsing history without dramatically increasing the computational complexity.", "labels": [], "entities": []}, {"text": "We conduct experiments on English, Chinese, and 12 other languages from the CoNLL 2006 shared task, showing that the proposed model achieves state-of-the-art unlabeled attachment scores on 6 languages.", "labels": [], "entities": [{"text": "CoNLL 2006 shared task", "start_pos": 76, "end_pos": 98, "type": "DATASET", "confidence": 0.9574179500341415}]}], "introductionContent": [{"text": "Recently, several neural network models have been developed for efficiently accessing long-term memory and discovering dependencies in sequential data.", "labels": [], "entities": []}, {"text": "The memory network framework has been studied in the context of question answering and language modeling (, whereas the neural attention model under the encoder-decoder framework has been applied to machine translation () and constituency parsing ().", "labels": [], "entities": [{"text": "question answering", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.8795675039291382}, {"text": "language modeling", "start_pos": 87, "end_pos": 104, "type": "TASK", "confidence": 0.7040789872407913}, {"text": "machine translation", "start_pos": 199, "end_pos": 218, "type": "TASK", "confidence": 0.8342470228672028}, {"text": "constituency parsing", "start_pos": 226, "end_pos": 246, "type": "TASK", "confidence": 0.8413840532302856}]}, {"text": "Both frameworks learn the latent alignment between the source and target sequences, and the mechanism of attention over the encoder can be viewed as a soft operation on the memory.", "labels": [], "entities": []}, {"text": "Although already used in the encoder for capturing global context information (, the bi-directional recurrent neural network (RNN) has yet to be employed in the decoder.", "labels": [], "entities": []}, {"text": "Bi-directional decoding is expected to be advantageous over the previously developed uni-directional counterpart, because the former exploits richer contextual information.", "labels": [], "entities": []}, {"text": "Intuitively, we can use two separate uni-directional RNNs where each one constructs its respective attended encoder context vectors for computing RNN hidden states.", "labels": [], "entities": []}, {"text": "However, the drawback of this approach is that the decoder would often produce different alignments resulting in discrepancies for the forward and backward directions.", "labels": [], "entities": []}, {"text": "In this paper, we design a training objective function to enforce attention agreement between both directions, inspired by the alignmentby-agreement idea from.", "labels": [], "entities": []}, {"text": "Specifically, we develop a dependency parser (BiAtt-DP) using a bi-directional attention model based on the memory network.", "labels": [], "entities": [{"text": "BiAtt-DP", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9515659809112549}]}, {"text": "Given that the golden alignment is observed for dependency parsing in the training stage, we further derive a simple and interpretable approximation for the agreement objective, which makes a natural connection between the latent and observed alignment cases.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.8413746654987335}]}, {"text": "The proposed BiAtt-DP parses a sentence in a linear order via sequentially querying the memory component that stores continuous embeddings for all headwords.", "labels": [], "entities": [{"text": "BiAtt-DP parses a sentence", "start_pos": 13, "end_pos": 39, "type": "TASK", "confidence": 0.7090236023068428}]}, {"text": "In other words, we consider all possible arcs during the parsing.", "labels": [], "entities": []}, {"text": "This formulation is adopted by graph-based parsers such as the MSTParser ().", "labels": [], "entities": [{"text": "MSTParser", "start_pos": 63, "end_pos": 72, "type": "DATASET", "confidence": 0.9391736388206482}]}, {"text": "The consideration of all possible arcs makes the proposed BiAtt-DP different from many recently developed neural dependency parsers, which use a transitionbased algorithm by modeling the parsing procedure as a sequence of actions on buffers.", "labels": [], "entities": []}, {"text": "Moreover, unlike most graph-based parsers which may suffer from high computational complexity when utilizing high-order parsing history), the proposed BiAtt-DP can implicitly inject such information into the model while keeping the computational complexity in the order of O(n 2 ) fora sentence with n words.", "labels": [], "entities": []}, {"text": "This is achieved by feeding the RNN in the query component with a soft headword embedding, which is computed as the probability-weighted sum of all headword embeddings in the memory component.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this is the first attempt to apply memory network models to graphbased dependency parsing.", "labels": [], "entities": [{"text": "graphbased dependency parsing", "start_pos": 90, "end_pos": 119, "type": "TASK", "confidence": 0.6276416182518005}]}, {"text": "Moreover, it is the first extension of neural attention models from unidirection to multi-direction by enforcing agreement on alignments.", "labels": [], "entities": []}, {"text": "Experiments on English, Chinese, and 12 languages from the CoNLL 2006 shared task show the BiAtt-DP can achieve competitive parsing accuracy with several state-of-the-art parsers.", "labels": [], "entities": [{"text": "CoNLL 2006 shared task", "start_pos": 59, "end_pos": 81, "type": "DATASET", "confidence": 0.9484763443470001}, {"text": "BiAtt-DP", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.8514533638954163}, {"text": "parsing", "start_pos": 124, "end_pos": 131, "type": "TASK", "confidence": 0.7730978727340698}, {"text": "accuracy", "start_pos": 132, "end_pos": 140, "type": "METRIC", "confidence": 0.9137827754020691}]}, {"text": "Furthermore, our model achieves the highest unlabeled attachment score (UAS) on Chinese, Czech, Dutch, German, Spanish and Turkish.", "labels": [], "entities": [{"text": "attachment score (UAS)", "start_pos": 54, "end_pos": 76, "type": "METRIC", "confidence": 0.9172648310661315}]}], "datasetContent": [{"text": "In this section, we present the parsing accuracy of the proposed BiAtt-DP on 14 languages.", "labels": [], "entities": [{"text": "parsing", "start_pos": 32, "end_pos": 39, "type": "TASK", "confidence": 0.9389902949333191}, {"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9069733023643494}]}, {"text": "We report both UAS and labeled attachment score (LAS), obtained by the CoNLL-X eval.pl script 2 which ignores punctuation symbols.", "labels": [], "entities": [{"text": "UAS", "start_pos": 15, "end_pos": 18, "type": "METRIC", "confidence": 0.8346309661865234}, {"text": "labeled attachment score (LAS)", "start_pos": 23, "end_pos": 53, "type": "METRIC", "confidence": 0.8547638754049937}, {"text": "CoNLL-X eval.pl script", "start_pos": 71, "end_pos": 93, "type": "DATASET", "confidence": 0.8895668784777323}]}, {"text": "The headword predictions are made through the MST search, which slightly improves both UAS and LAS (less than 0.3% absolutely).", "labels": [], "entities": [{"text": "MST search", "start_pos": 46, "end_pos": 56, "type": "DATASET", "confidence": 0.6336200535297394}, {"text": "UAS", "start_pos": 87, "end_pos": 90, "type": "METRIC", "confidence": 0.9864932894706726}, {"text": "LAS", "start_pos": 95, "end_pos": 98, "type": "METRIC", "confidence": 0.993983805179596}]}, {"text": "Overall, the proposed BiAtt-DP achieves competitive parsing accuracy on all languages as state-of-the-art parsers, and obtains better UAS in 6 languages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9737382531166077}]}, {"text": "We also show the impact of using POS tags and pre-trained word embeddings.", "labels": [], "entities": []}, {"text": "Moreover, different variants of the full model are compared in this section.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Parsing accuracy on PTB test set. Our parser uses", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9824764728546143}, {"text": "PTB test set", "start_pos": 30, "end_pos": 42, "type": "DATASET", "confidence": 0.9630136092503866}]}, {"text": " Table 2: Parsing accuracy on CTB dev and test sets.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.5064277648925781}, {"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9435518383979797}, {"text": "CTB dev and test sets", "start_pos": 30, "end_pos": 51, "type": "DATASET", "confidence": 0.9088072180747986}]}, {"text": " Table 4: Parsing accuracy on PTB dev set for different variants", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9494346976280212}, {"text": "PTB dev set", "start_pos": 30, "end_pos": 41, "type": "DATASET", "confidence": 0.9298974672953287}]}]}