{"title": [{"text": "Modified Dirichlet Distribution: Allowing Negative Parameters to Induce Stronger Sparsity *", "labels": [], "entities": []}], "abstractContent": [{"text": "The Dirichlet distribution (Dir) is one of the most widely used prior distributions in statistical approaches to natural language processing.", "labels": [], "entities": [{"text": "Dirichlet distribution (Dir)", "start_pos": 4, "end_pos": 32, "type": "METRIC", "confidence": 0.7766627192497253}, {"text": "natural language processing", "start_pos": 113, "end_pos": 140, "type": "TASK", "confidence": 0.6303858757019043}]}, {"text": "The parameters of Dir are required to be positive, which significantly limits its strength as a sparsity prior.", "labels": [], "entities": []}, {"text": "In this paper, we propose a simple modification to the Dirichlet distribution that allows the parameters to be negative.", "labels": [], "entities": []}, {"text": "Our modified Dirichlet distribution (mDir) not only induces much stronger sparsity, but also simultaneously performs smoothing.", "labels": [], "entities": []}, {"text": "mDir is still conjugate to the multinomial distribution, which simplifies posterior inference.", "labels": [], "entities": []}, {"text": "We introduce two simple and efficient algorithms for finding the mode of mDir.", "labels": [], "entities": []}, {"text": "Our experiments on learning Gaussian mixtures and un-supervised dependency parsing demonstrate the advantage of mDir over Dir.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.7189061343669891}]}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}