{"title": [{"text": "Fast Coupled Sequence Labeling on Heterogeneous Annotations via Context-aware Pruning", "labels": [], "entities": [{"text": "Sequence Labeling", "start_pos": 13, "end_pos": 30, "type": "TASK", "confidence": 0.8097235262393951}]}], "abstractContent": [{"text": "The recently proposed coupled sequence labeling is shown to be able to effectively exploit multiple labeled data with heterogeneous annotations but suffer from severe inefficiency problem due to the large bundled tag space (Li et al., 2015).", "labels": [], "entities": [{"text": "coupled sequence labeling", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.5921633342901865}]}, {"text": "In their case study of part-of-speech (POS) tagging, Li et al.", "labels": [], "entities": [{"text": "part-of-speech (POS) tagging", "start_pos": 23, "end_pos": 51, "type": "TASK", "confidence": 0.6155369818210602}]}, {"text": "(2015) manually design context-free tag-to-tag mapping rules with a lot of effort to reduce the tag space.", "labels": [], "entities": []}, {"text": "This paper proposes a context-aware pruning approach that performs token-wise constraints on the tag space based on contextual evidences, making the coupled approach efficient enough to be applied to the more complex task of joint word segmentation (WS) and POS tagging for the first time.", "labels": [], "entities": [{"text": "joint word segmentation (WS)", "start_pos": 225, "end_pos": 253, "type": "TASK", "confidence": 0.802034949262937}, {"text": "POS tagging", "start_pos": 258, "end_pos": 269, "type": "TASK", "confidence": 0.7431730926036835}]}, {"text": "Experiments show that using the large-scale People Daily as auxiliary heterogeneous data, the coupled approach can improve F-score by 95.55 \u2212 94.88 = 0.67% on WS, and by 90.58 \u2212 89.49 = 1.09% on joint WS&POS on Penn Chinese Treebank.", "labels": [], "entities": [{"text": "People Daily", "start_pos": 44, "end_pos": 56, "type": "DATASET", "confidence": 0.9834958910942078}, {"text": "F-score", "start_pos": 123, "end_pos": 130, "type": "METRIC", "confidence": 0.9984824061393738}, {"text": "WS", "start_pos": 159, "end_pos": 161, "type": "DATASET", "confidence": 0.5560188889503479}, {"text": "Penn Chinese Treebank", "start_pos": 211, "end_pos": 232, "type": "DATASET", "confidence": 0.9694667061169943}]}, {"text": "All codes are released at http://hlt.suda.edu.cn/~zhli.", "labels": [], "entities": []}], "introductionContent": [{"text": "In statistical natural language processing, manually labeled data is inevitable for model supervision, but is also very expensive to build.", "labels": [], "entities": [{"text": "statistical natural language processing", "start_pos": 3, "end_pos": 42, "type": "TASK", "confidence": 0.6349824592471123}]}, {"text": "However, due to the long-debated differences in underlying linguistic theories or emphasis of application, there often exist multiple labeled corpora for the same or similar tasks following different annotation guidelines (Jiang et * Correspondence author.", "labels": [], "entities": []}, {"text": "gives an example with both CTB and PD annotations.", "labels": [], "entities": [{"text": "CTB", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.4813743829727173}, {"text": "PD", "start_pos": 35, "end_pos": 37, "type": "METRIC", "confidence": 0.8787273168563843}]}, {"text": "We can see that CTB and PD differ in both word boundary standards and POS tag sets.", "labels": [], "entities": []}, {"text": "Previous work on exploiting heterogeneous data mainly focuses on indirect guide-feature methods.", "labels": [], "entities": []}, {"text": "The basic idea is to use one resource to generate extra guide features on another resource (, which is similar to stacked learning.", "labels": [], "entities": []}, {"text": "propose a coupled sequence labeling approach that can directly learn and predict two heterogeneous annotations simultaneously.", "labels": [], "entities": []}, {"text": "The basic idea is to transform a single-side tag into a set of bundled tags for weak supervision based on the idea of ambiguous labeling.", "labels": [], "entities": []}, {"text": "Due to the huge size of the bundled tag space, their coupled model is extremely inefficient.", "labels": [], "entities": []}, {"text": "They then carefully design tag-to-tag mapping rules to constrain the search space.", "labels": [], "entities": []}, {"text": "Their case study on POS tagging shows that the coupled model outperforms the guide-feature method.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 20, "end_pos": 31, "type": "TASK", "confidence": 0.8519697785377502}]}, {"text": "However, the requirement of manually designed mapping rules makes their approach less attractive, since such mapping rules maybe very difficult to construct for more complex tasks such as joint word segmentation (WS) and POS tagging.", "labels": [], "entities": [{"text": "joint word segmentation (WS)", "start_pos": 188, "end_pos": 216, "type": "TASK", "confidence": 0.8028019517660141}, {"text": "POS tagging", "start_pos": 221, "end_pos": 232, "type": "TASK", "confidence": 0.7835163772106171}]}, {"text": "This paper proposes a context-aware pruning approach that can effectively solve the inefficiency problem of the coupled model, making coupled sequence labeling more generally applicable.", "labels": [], "entities": [{"text": "coupled sequence labeling", "start_pos": 134, "end_pos": 159, "type": "TASK", "confidence": 0.5766148269176483}]}, {"text": "Specifically, this work makes the following contributions: (1) We propose and systematically compare two ways for realizing context-aware pruning, i.e., online and offline pruning.", "labels": [], "entities": []}, {"text": "Experiments on POS tagging show that both online and offline pruning can greatly improve the model efficiency with little accuracy loss.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 15, "end_pos": 26, "type": "TASK", "confidence": 0.8247992694377899}, {"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9983329176902771}]}, {"text": "(2) We for the first time apply coupled sequence labeling to the more complex task of joint WS&POS tagging.", "labels": [], "entities": [{"text": "coupled sequence labeling", "start_pos": 32, "end_pos": 57, "type": "TASK", "confidence": 0.5890751779079437}, {"text": "WS&POS tagging", "start_pos": 92, "end_pos": 106, "type": "TASK", "confidence": 0.7668407708406448}]}, {"text": "Experiments show that online pruning works badly due to the much larger tag set while offline pruning works well.", "labels": [], "entities": []}, {"text": "Further analysis gives a clear explanation and leads to more insights in learning from ambiguous labeling.", "labels": [], "entities": []}, {"text": "(3) Experiments on joint WS&POS tagging show that our coupled approach with offline pruning improves F-score by 95.55 \u2212 94.88 = 0.67% on WS, and by 90.58 \u2212 89.49 = 1.09% on joint WS&POS on CTB5-test over the baseline, and is also consistently better than the guide-feature method.", "labels": [], "entities": [{"text": "WS&POS tagging", "start_pos": 25, "end_pos": 39, "type": "TASK", "confidence": 0.6135236322879791}, {"text": "F-score", "start_pos": 101, "end_pos": 108, "type": "METRIC", "confidence": 0.9995051622390747}, {"text": "WS", "start_pos": 137, "end_pos": 139, "type": "DATASET", "confidence": 0.6782764792442322}, {"text": "CTB5-test", "start_pos": 189, "end_pos": 198, "type": "DATASET", "confidence": 0.9604623317718506}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: POS tagging performance of online and offline pruning  with different r and \u03bb on CTB5 and PD.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.7201434671878815}, {"text": "CTB5", "start_pos": 91, "end_pos": 95, "type": "DATASET", "confidence": 0.961948812007904}]}, {"text": " Table 3: POS tagging performance of difference approaches on  CTB5 and PD.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.7726024687290192}, {"text": "CTB5", "start_pos": 63, "end_pos": 67, "type": "DATASET", "confidence": 0.9427554607391357}]}, {"text": " Table 4: WS&POS tagging performance of online and offline  pruning with different r and \u03bb on CTB5 and PD.", "labels": [], "entities": [{"text": "WS&POS tagging", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.6048526838421822}, {"text": "CTB5", "start_pos": 94, "end_pos": 98, "type": "DATASET", "confidence": 0.9624292850494385}]}, {"text": " Table 5: WS&POS tagging performance of difference approaches on CTB5 and PD.", "labels": [], "entities": [{"text": "WS&POS tagging", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.5741743966937065}, {"text": "CTB5", "start_pos": 65, "end_pos": 69, "type": "DATASET", "confidence": 0.9321924448013306}]}, {"text": " Table 6: WS&POS tagging performance of difference ap- proaches on CTB5X and PD.", "labels": [], "entities": [{"text": "WS&POS tagging", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.5454565659165382}, {"text": "CTB5X", "start_pos": 67, "end_pos": 72, "type": "DATASET", "confidence": 0.974614143371582}]}]}