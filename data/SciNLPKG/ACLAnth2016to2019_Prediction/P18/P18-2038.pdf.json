{"title": [{"text": "Hybrid semi-Markov CRF for Neural Sequence Labeling", "labels": [], "entities": [{"text": "Neural Sequence Labeling", "start_pos": 27, "end_pos": 51, "type": "TASK", "confidence": 0.8501518766085306}]}], "abstractContent": [{"text": "This paper proposes hybrid semi-Markov conditional random fields (SCRFs) for neural sequence labeling in natural language processing.", "labels": [], "entities": [{"text": "neural sequence labeling", "start_pos": 77, "end_pos": 101, "type": "TASK", "confidence": 0.6477872133255005}]}, {"text": "Based on conventional conditional random fields (CRFs), SCRFs have been designed for the tasks of assigning labels to segments by extracting features from and describing transitions between segments instead of words.", "labels": [], "entities": []}, {"text": "In this paper, we improve the existing SCRF methods by employing word-level and segment-level information simultaneously.", "labels": [], "entities": []}, {"text": "First, word-level labels are utilized to derive the segment scores in SCRFs.", "labels": [], "entities": []}, {"text": "Second, a CRF output layer and an SCRF output layer are integrated into an unified neural network and trained jointly.", "labels": [], "entities": []}, {"text": "Experimental results on CoNLL 2003 named entity recognition (NER) shared task show that our model achieves state-of-the-art performance when no external knowledge is used 1 .", "labels": [], "entities": [{"text": "CoNLL 2003 named entity recognition (NER) shared task", "start_pos": 24, "end_pos": 77, "type": "TASK", "confidence": 0.8721889674663543}]}], "introductionContent": [{"text": "Sequence labeling, such as part-of-speech (POS) tagging, chunking, and named entity recognition (NER), is a category of fundamental tasks in natural language processing (NLP).", "labels": [], "entities": [{"text": "Sequence labeling", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8902491331100464}, {"text": "part-of-speech (POS) tagging", "start_pos": 27, "end_pos": 55, "type": "TASK", "confidence": 0.6757153034210205}, {"text": "named entity recognition (NER)", "start_pos": 71, "end_pos": 101, "type": "TASK", "confidence": 0.7926514446735382}, {"text": "natural language processing (NLP)", "start_pos": 141, "end_pos": 174, "type": "TASK", "confidence": 0.71601535876592}]}, {"text": "Conditional random fields (CRFs) (), as probabilistic undirected graphical models, have been widely applied to the sequence labeling tasks considering that they are able to describe the dependencies between adjacent word-level labels and to avoid illegal label combination (e.g., I-ORG can't follow B-LOC in the NER tasks using the BIOES tagging scheme).", "labels": [], "entities": [{"text": "NER tasks", "start_pos": 312, "end_pos": 321, "type": "TASK", "confidence": 0.7847424745559692}, {"text": "BIOES tagging", "start_pos": 332, "end_pos": 345, "type": "TASK", "confidence": 0.6050176024436951}]}, {"text": "Original CRFs utilize hand-crafted features which increases the difficulty of performance tuning and domain adaptation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 101, "end_pos": 118, "type": "TASK", "confidence": 0.7076872289180756}]}, {"text": "In recent years, neural networks with distributed word representations (i.e., word embeddings) () have been introduced to calculate word scores automatically for CRFs (.", "labels": [], "entities": []}, {"text": "On the other hand, semi-Markov conditional random fields (SCRFs)) have been proposed for the tasks of assigning labels to the segments of input sequences, e.g., NER.", "labels": [], "entities": []}, {"text": "Different from CRFs, SCRFs adopt segments instead of words as the basic units for feature extraction and transition modeling.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 82, "end_pos": 100, "type": "TASK", "confidence": 0.7541703581809998}, {"text": "transition modeling", "start_pos": 105, "end_pos": 124, "type": "TASK", "confidence": 0.6984796822071075}]}, {"text": "The word-level transitions within a segment are usually ignored.", "labels": [], "entities": []}, {"text": "Some variations of SCRFs have also been studied.", "labels": [], "entities": []}, {"text": "For example, Andrew (2006) extracted segment-level features by combining handcrafted CRF features and modeled the Markov property between words instead of segments in SCRFs.", "labels": [], "entities": []}, {"text": "With the development of deep learning, some models of combining neural networks and SCRFs have also been studied. and employed gated recursive convolutional neural networks (grConvs) and segmental recurrent neural networks (SRNNs) to calculate segment scores for SCRFs respectively.", "labels": [], "entities": []}, {"text": "All these existing neural sequence labeling methods using SCRFs only adopted segment-level labels for score calculation and model training.", "labels": [], "entities": [{"text": "score calculation", "start_pos": 102, "end_pos": 119, "type": "TASK", "confidence": 0.6377175599336624}]}, {"text": "In this paper, we suppose that word-level labels can also contribute to the building of SCRFs and thus design a hybrid SCRF (HSCRF) architecture for neural sequence labeling.", "labels": [], "entities": [{"text": "neural sequence labeling", "start_pos": 149, "end_pos": 173, "type": "TASK", "confidence": 0.6217327813307444}]}, {"text": "In an HSCRF, word-level labels are utilized to derive the segment scores.", "labels": [], "entities": []}, {"text": "Further, a CRF output layer and an HSCRF output layer are integrated into a unified neural network and trained jointly.", "labels": [], "entities": []}, {"text": "We evaluate our model on) and achieve state-of-the-art performance when no external knowledge is used.", "labels": [], "entities": []}, {"text": "In summary, the contributions of this paper are: (1) we propose the HSCRF architecture which employs both word-level and segment-level labels for segment score calculation.", "labels": [], "entities": []}, {"text": "(2) we propose a joint CRF-HSCRF training framework and a naive joint decoding algorithm for neural sequence labeling.", "labels": [], "entities": [{"text": "neural sequence labeling", "start_pos": 93, "end_pos": 117, "type": "TASK", "confidence": 0.6065206726392111}]}, {"text": "(3) we achieve state-of-the-art performance in CoNLL 2003 NER shared task.", "labels": [], "entities": [{"text": "CoNLL 2003 NER shared task", "start_pos": 47, "end_pos": 73, "type": "DATASET", "confidence": 0.9229018211364746}]}], "datasetContent": [{"text": "We evaluated our model on the.", "labels": [], "entities": []}, {"text": "This dataset contained four labels of named entities (PER, LOC, ORG and MISC) and label O for others.", "labels": [], "entities": [{"text": "PER", "start_pos": 54, "end_pos": 57, "type": "METRIC", "confidence": 0.952369213104248}, {"text": "LOC", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.6254408955574036}, {"text": "ORG", "start_pos": 64, "end_pos": 67, "type": "METRIC", "confidence": 0.8751670122146606}, {"text": "MISC", "start_pos": 72, "end_pos": 76, "type": "METRIC", "confidence": 0.9160398840904236}]}, {"text": "The existing separation of training, development and test sets was followed in our experiments.", "labels": [], "entities": []}, {"text": "We adopted the same word-level tagging scheme as the one used in (e.g., BIOES instead of BIO).", "labels": [], "entities": [{"text": "word-level tagging", "start_pos": 20, "end_pos": 38, "type": "TASK", "confidence": 0.6223523169755936}]}, {"text": "For better computation efficiency, the max segment length L introduced in Section 2.1 was set to 6, which pruned less than 0.5% training sentences for building SCRFs and had no effect on the development and test sets.", "labels": [], "entities": [{"text": "max segment length L", "start_pos": 39, "end_pos": 59, "type": "METRIC", "confidence": 0.8952025175094604}]}], "tableCaptions": [{"text": " Table 1: Model descriptions and their performance on CoNLL 2003 NER task.", "labels": [], "entities": [{"text": "CoNLL 2003 NER task", "start_pos": 54, "end_pos": 73, "type": "DATASET", "confidence": 0.9096851050853729}]}, {"text": " Table 2: Hyper-parameters of the models built  in our experiments, where  \u2020 indicates the ones  when using LM-BLSTM for deriving word  representations and  \u2021 indicates the ones when  using CNN-BLSTM.", "labels": [], "entities": [{"text": "CNN-BLSTM", "start_pos": 190, "end_pos": 199, "type": "DATASET", "confidence": 0.9435800909996033}]}, {"text": " Table 4: Model performance on CoNLL 2003 NER task for entities with different lengths.", "labels": [], "entities": [{"text": "CoNLL 2003 NER task", "start_pos": 31, "end_pos": 50, "type": "DATASET", "confidence": 0.8779196888208389}]}]}