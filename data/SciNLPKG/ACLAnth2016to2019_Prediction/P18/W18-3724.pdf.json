{"title": [{"text": "Chinese Grammatical Error Diagnosis Based on CRF and LSTM-CRF model", "labels": [], "entities": [{"text": "Chinese Grammatical Error Diagnosis", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.6897726282477379}]}], "abstractContent": [{"text": "When learning Chinese as a foreign language , the learners may have some grammatical errors due to negative migration of their native languages.", "labels": [], "entities": []}, {"text": "However, few grammar checking applications have been developed to support the learners.", "labels": [], "entities": [{"text": "grammar checking", "start_pos": 13, "end_pos": 29, "type": "TASK", "confidence": 0.9143053591251373}]}, {"text": "The goal of this paper is to develop a tool to automatically diagnose four types of grammatical errors which are redundant words (R), missing words (M), bad word selection (S) and disordered words (W) in Chinese sentences written by those foreign learners.", "labels": [], "entities": []}, {"text": "In this paper, a conventional linear CRF model with specific feature engineering and a LSTM-CRF model are used to solve the CGED (Chinese Grammatical Error Diagnosis) task.", "labels": [], "entities": [{"text": "CGED (Chinese Grammatical Error Diagnosis) task", "start_pos": 124, "end_pos": 171, "type": "TASK", "confidence": 0.6979691348969936}]}, {"text": "We make some improvement on both models and the submitted results have better performance on false positive rate and accuracy than the average of all runs from CGED2018 for all three evaluation levels.", "labels": [], "entities": [{"text": "false positive rate", "start_pos": 93, "end_pos": 112, "type": "METRIC", "confidence": 0.9536321560541788}, {"text": "accuracy", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.9975492358207703}, {"text": "CGED2018", "start_pos": 160, "end_pos": 168, "type": "DATASET", "confidence": 0.9834843277931213}]}], "introductionContent": [{"text": "Nowadays, more and more foreigners take Chinese as their second language.", "labels": [], "entities": []}, {"text": "Unlike English, Chinese has no verb tenses or pluralities, and meanwhile there are various ways to express the same meaning in Chinese, so Chinese has been considered as one of the most difficult languages in the world).", "labels": [], "entities": []}, {"text": "Chinese as a Foreign Language(CFL) learners often make grammatical errors such as redundant words (R), missing words (M), word selection errors (S), and word ordering errors (W), due to language negative migration, over-generalization, teaching methods, learning strategies and other reasons.", "labels": [], "entities": [{"text": "word selection errors (S)", "start_pos": 122, "end_pos": 147, "type": "METRIC", "confidence": 0.7092496852080027}]}, {"text": "Natural Language Processing System(NLPS) which can detect and correct grammatical errors are important and invaluable to language learners.", "labels": [], "entities": []}, {"text": "(. However, few grammar checking applications have been developed to support CFL learners.", "labels": [], "entities": [{"text": "grammar checking", "start_pos": 16, "end_pos": 32, "type": "TASK", "confidence": 0.882999449968338}]}, {"text": "The goal of the CGED (Chinese Grammatical Error Diagnosis) task is to develop NLP (Natural Language Processing) techniques to automatically diagnose grammatical errors in Chinese sentences written by CFL learners.", "labels": [], "entities": [{"text": "Chinese Grammatical Error Diagnosis)", "start_pos": 22, "end_pos": 58, "type": "TASK", "confidence": 0.6406436681747436}]}, {"text": "In this paper, we use both a conventional linear CRF model () with specific feature engineering and a LSTM-CRF model to solve CGED task.", "labels": [], "entities": []}, {"text": "Many researchers have already used these two models in the past few years, but our team make some improvement on both models.", "labels": [], "entities": []}, {"text": "For CRF model, we integrate the syntactic feature into the CRF model.", "labels": [], "entities": []}, {"text": "Character itself, POS feature and syntactic feature are used to generate 50 combinatorial features by template technology.", "labels": [], "entities": []}, {"text": "As for LSTM-CRF model, most researchers use tag transition features only in CRF layer.", "labels": [], "entities": []}, {"text": "The major improvement of our work is that more conventional sparse CRF features are incorporated into the CRF layer such as bag of POS n-grams features, words features, tag transition features, etc.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: Section 2 gives the definition of the CEGD task.", "labels": [], "entities": []}, {"text": "Section 3 introduces two methods we use to solve the CGED task.", "labels": [], "entities": []}, {"text": "Section 4 describes the dataset we use, the evaluation results on the validation set and the test set.", "labels": [], "entities": []}, {"text": "Section 5 discusses conclusion and future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We collect datasets from CGED-HSK-2016, CGED-2017 and CGED-2018 as our training set and validation set.", "labels": [], "entities": [{"text": "CGED-HSK-2016", "start_pos": 25, "end_pos": 38, "type": "DATASET", "confidence": 0.9804372191429138}, {"text": "CGED-2017", "start_pos": 40, "end_pos": 49, "type": "DATASET", "confidence": 0.9591745734214783}, {"text": "CGED-2018", "start_pos": 54, "end_pos": 63, "type": "DATASET", "confidence": 0.9299483299255371}]}, {"text": "shows the distributions of error types in both the training set and validation set.", "labels": [], "entities": []}, {"text": "The ratio of training set size to validation set size is about 8:1.", "labels": [], "entities": []}, {"text": "Besides the sentences with grammatical errors, 1539 correct sentences are added into the validation set.", "labels": [], "entities": []}, {"text": "In the CGED2018 shared task, there are 12 teams submitted the results, totally 32 runs.", "labels": [], "entities": [{"text": "CGED2018 shared task", "start_pos": 7, "end_pos": 27, "type": "DATASET", "confidence": 0.873415489991506}]}, {"text": "Among them, our team submitted three runs.", "labels": [], "entities": []}, {"text": "Run1 and Run2 are based on the CRF model with different size of training set while Run3 is based on the LSTM-CRF model.", "labels": [], "entities": [{"text": "Run1", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8844563961029053}]}, {"text": "The average of all runs is calculated from 32 runs of the 12 teams.", "labels": [], "entities": []}, {"text": "shows the false positive rate of the 3 runs of our team and the average of all runs.", "labels": [], "entities": [{"text": "false positive rate", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.9653613964716593}]}, {"text": "FP (False Positive) is the number of sentences in which non-existent grammatical errors are identified as errors, so the lower the better.", "labels": [], "entities": [{"text": "FP (False Positive)", "start_pos": 0, "end_pos": 19, "type": "METRIC", "confidence": 0.8575092196464539}]}, {"text": "The best false positive rate of our team is 0.1255 (Run3) which is much lower than the average rate of all runs.", "labels": [], "entities": [{"text": "false positive rate", "start_pos": 9, "end_pos": 28, "type": "METRIC", "confidence": 0.9800392985343933}, {"text": "Run3)", "start_pos": 52, "end_pos": 57, "type": "METRIC", "confidence": 0.9784531593322754}]}, {"text": "shows the evaluation result for detection level, identification level and position level.", "labels": [], "entities": []}, {"text": "The submitted results of our: Evaluation results of LSTM-CRF model on validation set for position level team have better performance on accuracy than the average of all runs from CGED2018 for all three evaluation levels, but all three runs do not perform well on recall rate.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 136, "end_pos": 144, "type": "METRIC", "confidence": 0.9990523457527161}, {"text": "CGED2018", "start_pos": 179, "end_pos": 187, "type": "DATASET", "confidence": 0.9756501913070679}, {"text": "recall rate", "start_pos": 263, "end_pos": 274, "type": "METRIC", "confidence": 0.9847705960273743}]}, {"text": "indicates that Run 3 achieved the accuracy of 0.3745 for position level which is the most difficult level and it leads to the final F1 score of 0.1397 although the recall rate is still not above the average.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.999648928642273}, {"text": "F1 score", "start_pos": 132, "end_pos": 140, "type": "METRIC", "confidence": 0.9862498044967651}, {"text": "recall rate", "start_pos": 164, "end_pos": 175, "type": "METRIC", "confidence": 0.9894687235355377}]}], "tableCaptions": [{"text": " Table 1: Two errors are found in the sentence above, one is word ordering error (W) from  position 3 to 5, the other is word selection error (R) from position 16 to 17..", "labels": [], "entities": [{"text": "word ordering error (W)", "start_pos": 61, "end_pos": 84, "type": "METRIC", "confidence": 0.7654635260502497}, {"text": "word selection error (R)", "start_pos": 121, "end_pos": 145, "type": "METRIC", "confidence": 0.7501929799715678}]}, {"text": " Table 3: A snapshot of a sample sentence", "labels": [], "entities": []}, {"text": " Table 4: Description of syntactic features tag", "labels": [], "entities": []}, {"text": " Table 9. LSTM- CRF-1 refers to the LSTM-CRF model with  handcraft features defined in section 3.2. LSTM- CRF2 refers to the LSTM-CRF model with no  handcraft features (i.e. only tag transition feature  is considered). As the experiment results shown  that the feature engineering in CRF part can im- prove the performance (i.e. F1 value) about 2%,  thus we use the LSTM-CRF1 model as our final  model.", "labels": [], "entities": [{"text": "F1", "start_pos": 329, "end_pos": 331, "type": "METRIC", "confidence": 0.9992449283599854}]}, {"text": " Table 7: The distributions of error types", "labels": [], "entities": []}, {"text": " Table 8: Evaluation results of CRF model on  validation set for position level", "labels": [], "entities": []}, {"text": " Table 9: Evaluation results of LSTM-CRF  model on validation set for position level", "labels": [], "entities": []}, {"text": " Table 10: The False Positive Rate (The  lower the better)", "labels": [], "entities": [{"text": "False Positive Rate", "start_pos": 15, "end_pos": 34, "type": "METRIC", "confidence": 0.9219973683357239}]}, {"text": " Table 11: Evaluation Results for Detection  Level", "labels": [], "entities": [{"text": "Detection", "start_pos": 34, "end_pos": 43, "type": "TASK", "confidence": 0.9845802783966064}]}, {"text": " Table 12: Evaluation Results for Identifica- tion Level", "labels": [], "entities": [{"text": "Identifica- tion Level", "start_pos": 34, "end_pos": 56, "type": "TASK", "confidence": 0.8688439279794693}]}]}