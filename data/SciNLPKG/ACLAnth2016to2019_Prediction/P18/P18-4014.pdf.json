{"title": [{"text": "TALEN: Tool for Annotation of Low-resource ENtities", "labels": [], "entities": [{"text": "TALEN", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.8116781115531921}]}], "abstractContent": [{"text": "We present anew web-based interface, TALEN, designed for named entity annotation in low-resource settings where the annotators do not speak the language.", "labels": [], "entities": [{"text": "TALEN", "start_pos": 37, "end_pos": 42, "type": "METRIC", "confidence": 0.8544852137565613}, {"text": "named entity annotation", "start_pos": 57, "end_pos": 80, "type": "TASK", "confidence": 0.6242426534493765}]}, {"text": "To address this non-traditional scenario, TALEN includes such features as in-place lexicon integration, TF-IDF token statistics , Internet search, and entity propagation , all implemented so as to make this difficult task efficient and frictionless.", "labels": [], "entities": [{"text": "entity propagation", "start_pos": 151, "end_pos": 169, "type": "TASK", "confidence": 0.7935040891170502}]}, {"text": "We conduct a small user study to compare against a popular annotation tool, showing that TALEN achieves higher precision and recall against ground-truth annotations , and that users strongly prefer it over the alternative.", "labels": [], "entities": [{"text": "TALEN", "start_pos": 89, "end_pos": 94, "type": "METRIC", "confidence": 0.8429983258247375}, {"text": "precision", "start_pos": 111, "end_pos": 120, "type": "METRIC", "confidence": 0.9990435242652893}, {"text": "recall", "start_pos": 125, "end_pos": 131, "type": "METRIC", "confidence": 0.9987797141075134}]}, {"text": "TALEN is available at: github.com/CogComp/talen.", "labels": [], "entities": [{"text": "TALEN", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.590169370174408}, {"text": "CogComp/talen", "start_pos": 34, "end_pos": 47, "type": "DATASET", "confidence": 0.8231574694315592}]}], "introductionContent": [{"text": "Named entity recognition (NER), the task of finding and classifying named entities in text, has been well-studied in English, and a select few other languages, resulting in a wealth of resources, particularly annotated training data.", "labels": [], "entities": [{"text": "Named entity recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8453812301158905}]}, {"text": "But for most languages, no training data exists, and annotators who speak the language can be hard or impossible to find.", "labels": [], "entities": []}, {"text": "This low-resource scenario calls for new methods for gathering training data.", "labels": [], "entities": []}, {"text": "Several works address this with automatic techniques), but often a good starting point is to elicit manual annotations from annotators who do not speak the target language.", "labels": [], "entities": []}, {"text": "Language annotation strategies and software have historically assumed that annotators speak the language in question.", "labels": [], "entities": []}, {"text": "Although there has been work on non-expert annotators for natural language tasks (, where the annotators lack specific skills related to the task, there has been little to no work on situations where annotators, expert or not, do not speak the language.", "labels": [], "entities": []}, {"text": "To this end, we present a web-based interface designed for users to annotate text quickly and easily in a language they do not speak.", "labels": [], "entities": []}, {"text": "TALEN aids non-speaker annotators 1 with several different helps and nudges that would be unnecessary in cases of a native speaker.", "labels": [], "entities": [{"text": "TALEN", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.7262463569641113}]}, {"text": "The main features, described in detail in Section 2, area Named Entity (NE) specific interface, entity propagation, lexicon integration, token statistics information, and Internet search.", "labels": [], "entities": [{"text": "entity propagation", "start_pos": 96, "end_pos": 114, "type": "TASK", "confidence": 0.8000554442405701}]}, {"text": "The tool operates in two separate modes, each with all the helps described above.", "labels": [], "entities": []}, {"text": "The first mode displays atomic documents in a manner analogous to nearly all prior annotation software.", "labels": [], "entities": []}, {"text": "The second mode operates on the sentence level, patterned on bootstrapping with a human in the loop, and designed for efficient discovery and annotation.", "labels": [], "entities": []}, {"text": "In addition to being useful for non-speaker annotations, TALEN can be used as a lightweight inspection and annotation tool for within-language named entity annotation.", "labels": [], "entities": [{"text": "TALEN", "start_pos": 57, "end_pos": 62, "type": "METRIC", "confidence": 0.7349882125854492}, {"text": "within-language named entity annotation", "start_pos": 127, "end_pos": 166, "type": "TASK", "confidence": 0.5831226333975792}]}, {"text": "TALEN is agnostic to labelset, which means that it can also be used fora wide variety of sequence tagging tasks.", "labels": [], "entities": [{"text": "TALEN", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.8331818580627441}, {"text": "sequence tagging tasks", "start_pos": 89, "end_pos": 111, "type": "TASK", "confidence": 0.748945007721583}]}], "datasetContent": [{"text": "The brat rapid annotation tool (brat) () is a popular and well-featured annotation tool, which makes fora natural comparison to TALEN.", "labels": [], "entities": [{"text": "TALEN", "start_pos": 128, "end_pos": 133, "type": "METRIC", "confidence": 0.490583211183548}]}, {"text": "In this experiment, we compare tools qualitatively and quantitatively by hiring a group of annotators.", "labels": [], "entities": []}, {"text": "We can compare performance between TALEN and brat by measuring the results after having annotators use both tools.", "labels": [], "entities": [{"text": "TALEN", "start_pos": 35, "end_pos": 40, "type": "METRIC", "confidence": 0.7432714104652405}]}, {"text": "We chose to annotate Amharic, a language from Ethiopia.", "labels": [], "entities": []}, {"text": "We have gold training and test data for this language from the Linguistic Data Consortium (LDC2016E87).", "labels": [], "entities": [{"text": "Linguistic Data Consortium (LDC2016E87)", "start_pos": 63, "end_pos": 102, "type": "DATASET", "confidence": 0.8695967843135198}]}, {"text": "The corpus is composed of several different genres, including newswire, discussion forums, web blogs, and social network (Twitter).", "labels": [], "entities": []}, {"text": "In the interest of controlling for the domain, we chose only 125 newswire documents (NW) from the gold data, and removed all annotations before distribution.", "labels": [], "entities": [{"text": "newswire documents (NW) from the gold data", "start_pos": 65, "end_pos": 107, "type": "DATASET", "confidence": 0.7682380278905233}]}, {"text": "Since Amharic is written in Ge'ez script, we romanized it, so it can be read by English speakers.", "labels": [], "entities": []}, {"text": "We partitioned the newswire documents into 12 (roughly even) groups of documents, and assigned each annotator 2 groups: one to be annotated in brat, the other with TALEN.", "labels": [], "entities": [{"text": "TALEN", "start_pos": 164, "end_pos": 169, "type": "METRIC", "confidence": 0.9884672164916992}]}, {"text": "This way, every annotator will use both interfaces, and every document will be annotated by both interfaces.", "labels": [], "entities": []}, {"text": "We chose one fully annotated gold document and copied it into each group, so that the annotators have an annotation example.", "labels": [], "entities": []}, {"text": "We employed 12 annotators chosen from our NLP research group.", "labels": [], "entities": [{"text": "NLP research group", "start_pos": 42, "end_pos": 60, "type": "DATASET", "confidence": 0.8781741261482239}]}, {"text": "Before the annotation period, all participants were given a survey about tool usage and language fluency.", "labels": [], "entities": []}, {"text": "No users had familiarity with TALEN, and only one had any familiarity with brat.", "labels": [], "entities": [{"text": "TALEN", "start_pos": 30, "end_pos": 35, "type": "METRIC", "confidence": 0.8673998117446899}]}, {"text": "Of the annotators, none spoke Amharic or any related language, although one annotator had some familiarity with Hebrew, which shares a common ancestry with Amharic, and one annotator was from West Africa.", "labels": [], "entities": []}, {"text": "Immediately prior to the annotation period, we gave a 15 minute presentation with instructions on tool usage, annotation guidelines, and annotation Ethiopia is in East Africa.: Performance results.", "labels": [], "entities": []}, {"text": "The precision, recall, and F1 are measured against the gold standard Amharic training data.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9997567534446716}, {"text": "recall", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.9997488856315613}, {"text": "F1", "start_pos": 27, "end_pos": 29, "type": "METRIC", "confidence": 0.9998683929443359}, {"text": "Amharic training data", "start_pos": 69, "end_pos": 90, "type": "DATASET", "confidence": 0.8482508261998495}]}, {"text": "When counting Unique Names, each unique surface form is counted once.", "labels": [], "entities": []}, {"text": "We emphasize that these results are calculated over a very small amount of data annotated over a half-hour period by annotators with no experience with TALEN or Amharic.", "labels": [], "entities": []}, {"text": "These only show a quick and dirty comparison to brat, and are not intended to demonstrate high-quality performance. strategies.", "labels": [], "entities": []}, {"text": "The tags used were Person, Organization, Location, and Geo-Political Entity.", "labels": [], "entities": []}, {"text": "As for strategy, we instructed them to move quickly, annotating names only if they are confident (e.g. if they know the English version of that name), and to prioritize diversity of discovered surface forms over exhaustiveness of annotation.", "labels": [], "entities": []}, {"text": "When using TALEN, we encouraged them to make heavy use of the lexicon.", "labels": [], "entities": []}, {"text": "We provided a shortlist (less than 20 names) of English names that are likely to be found in documents from Ethiopia: local politicians, cities in the region, etc.", "labels": [], "entities": []}, {"text": "The annotation period lasted 1 hour, and consisted of two half hour sessions.", "labels": [], "entities": []}, {"text": "For the first session, we randomly assigned half the annotators to use brat, and the other half to use TALEN.", "labels": [], "entities": [{"text": "TALEN", "start_pos": 103, "end_pos": 108, "type": "METRIC", "confidence": 0.9661869406700134}]}, {"text": "When this 30 minute period was over, all annotators switched tools.", "labels": [], "entities": []}, {"text": "Those who had used brat use ours, and vice versa.", "labels": [], "entities": []}, {"text": "We did this because users are likely to get better at annotating overtime, so the second tool presented should give better results.", "labels": [], "entities": []}, {"text": "Our switching procedure mitigates this effect.", "labels": [], "entities": []}, {"text": "At the end of the second session, each document group had been annotated twice: once by some annotator using brat, and once by some annotator using TALEN.", "labels": [], "entities": [{"text": "TALEN", "start_pos": 148, "end_pos": 153, "type": "METRIC", "confidence": 0.8690685033798218}]}, {"text": "These annotations were separate, so each tool started with afresh copy of the data.", "labels": [], "entities": []}, {"text": "We report results in two ways: first, annotation quality as measured against a gold standard, and second, annotator feedback.", "labels": [], "entities": []}, {"text": "shows basic statistics on the datasets.", "labels": [], "entities": []}, {"text": "Since the documents we gave to the annotators came from a gold annotated set, we calculated precision, recall, and F1 with respect to the gold labels.", "labels": [], "entities": [{"text": "precision", "start_pos": 92, "end_pos": 101, "type": "METRIC", "confidence": 0.9998010993003845}, {"text": "recall", "start_pos": 103, "end_pos": 109, "type": "METRIC", "confidence": 0.9997681975364685}, {"text": "F1", "start_pos": 115, "end_pos": 117, "type": "METRIC", "confidence": 0.9998390674591064}]}, {"text": "First, we see that TALEN gives a 5.8 point F1 improvement over brat.", "labels": [], "entities": [{"text": "TALEN", "start_pos": 19, "end_pos": 24, "type": "METRIC", "confidence": 0.9988149404525757}, {"text": "F1", "start_pos": 43, "end_pos": 45, "type": "METRIC", "confidence": 0.9997221827507019}]}, {"text": "This comes mostly from the recall, which improves by 3.9 points.", "labels": [], "entities": [{"text": "recall", "start_pos": 27, "end_pos": 33, "type": "METRIC", "confidence": 0.9993277788162231}]}, {"text": "This maybe due to the automatic propagation, or it maybe that having a lexicon helped users discover more names by proximity to known translations like president.", "labels": [], "entities": [{"text": "president", "start_pos": 152, "end_pos": 161, "type": "DATASET", "confidence": 0.9456197619438171}]}, {"text": "Ina less time-constrained environment, users of brat might be more likely select and annotate all surfaces of a name, but the reality is that all annotation projects are time-constrained, and any help is valuable.", "labels": [], "entities": []}, {"text": "The bottom part of the table shows the annotation statistics from TALEN compared with brat.", "labels": [], "entities": [{"text": "TALEN", "start_pos": 66, "end_pos": 71, "type": "METRIC", "confidence": 0.6217100024223328}]}, {"text": "TALEN yielded more name spans than brat, but fewer unique names, meaning that many of the names from TALEN are copies.", "labels": [], "entities": []}, {"text": "This is also likely a product of the name propagation feature.", "labels": [], "entities": [{"text": "name propagation", "start_pos": 37, "end_pos": 53, "type": "TASK", "confidence": 0.8426247835159302}]}, {"text": "We gathered qualitative results from a feedback form filled out by each annotator after the evaluation.", "labels": [], "entities": []}, {"text": "All but one of the annotators preferred TALEN for this task.", "labels": [], "entities": [{"text": "TALEN", "start_pos": 40, "end_pos": 45, "type": "METRIC", "confidence": 0.8467947840690613}]}, {"text": "In another question, they were asked to select an option for 3 qualities of each tool: efficiency, ease of use, and presentation.", "labels": [], "entities": [{"text": "ease", "start_pos": 99, "end_pos": 103, "type": "METRIC", "confidence": 0.9769148826599121}]}, {"text": "Each quality could take the options Bad, Neutral, or Good.", "labels": [], "entities": []}, {"text": "On each of these qualities, brat had a majority of Neutral, and TALEN had a majority of Good.", "labels": [], "entities": [{"text": "Neutral", "start_pos": 51, "end_pos": 58, "type": "METRIC", "confidence": 0.9774976372718811}, {"text": "TALEN", "start_pos": 64, "end_pos": 69, "type": "METRIC", "confidence": 0.9804874062538147}]}, {"text": "For TALEN, Efficiency was the highest rated quality, with 10 respondents choosing Good.", "labels": [], "entities": [{"text": "TALEN", "start_pos": 4, "end_pos": 9, "type": "DATASET", "confidence": 0.400213360786438}, {"text": "Efficiency", "start_pos": 11, "end_pos": 21, "type": "METRIC", "confidence": 0.9970587491989136}]}, {"text": "We also presented respondents with the 4 major features of TALEN (TF-IDF box, lexicon, entity propagation, Internet search), and asked them to rate them as Useful or Not useful in their experience.", "labels": [], "entities": [{"text": "TALEN", "start_pos": 59, "end_pos": 64, "type": "METRIC", "confidence": 0.9388655424118042}, {"text": "entity propagation", "start_pos": 87, "end_pos": 105, "type": "TASK", "confidence": 0.7102395594120026}]}, {"text": "Only 4 people found the TF-IDF box useful; 10 people found the lexicon useful; all 12 people found the entity propagation useful; 7 people found the Internet search useful.", "labels": [], "entities": [{"text": "entity propagation", "start_pos": 103, "end_pos": 121, "type": "TASK", "confidence": 0.7109604179859161}]}, {"text": "These results are also reflected in the free text feedback.", "labels": [], "entities": []}, {"text": "Most respondents were favorable towards the lexicon, and some respondents wrote that the TF-IDF box would be useful with more exposure, or with better integration (e.g. highlight on hover).", "labels": [], "entities": []}], "tableCaptions": []}