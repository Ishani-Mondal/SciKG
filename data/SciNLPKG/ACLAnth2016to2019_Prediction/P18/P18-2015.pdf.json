{"title": [{"text": "Ranking-Based Automatic Seed Selection and Noise Reduction for Weakly Supervised Relation Extraction", "labels": [], "entities": [{"text": "Seed Selection", "start_pos": 24, "end_pos": 38, "type": "TASK", "confidence": 0.7335757464170456}, {"text": "Weakly Supervised Relation Extraction", "start_pos": 63, "end_pos": 100, "type": "TASK", "confidence": 0.7016010284423828}]}], "abstractContent": [{"text": "This paper addresses the tasks of automatic seed selection for bootstrapping relation extraction, and noise reduction for distantly supervised relation extraction.", "labels": [], "entities": [{"text": "bootstrapping relation extraction", "start_pos": 63, "end_pos": 96, "type": "TASK", "confidence": 0.773547907670339}, {"text": "distantly supervised relation extraction", "start_pos": 122, "end_pos": 162, "type": "TASK", "confidence": 0.6674240231513977}]}, {"text": "We first point out that these tasks are related.", "labels": [], "entities": []}, {"text": "Then, inspired by ranking relation instances and patterns computed by the HITS algorithm, and selecting cluster cen-troids using the K-means, LSA, or NMF method, we propose methods for selecting the initial seeds from an existing resource, or reducing the level of noise in the distantly labeled data.", "labels": [], "entities": []}, {"text": "Experiments show that our proposed methods achieve a better performance than the baseline systems in both tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "Bootstrapping for relation extraction (RE)) is a class of minimally supervised methods frequently used in machine learning: initialized by a small set of example instances called seeds, to represent a particular semantic relation, the bootstrapping system operates iteratively to acquire new instances of a target relation.", "labels": [], "entities": [{"text": "relation extraction (RE))", "start_pos": 18, "end_pos": 43, "type": "TASK", "confidence": 0.8667394042015075}]}, {"text": "Selecting \"good\" seeds is one of the most important steps to reduce semantic drift, which is atypical phenomenon of the bootstrapping process.", "labels": [], "entities": []}, {"text": "Another approach, called \"distant supervision\" (DS) (, does not require any labels on the text.", "labels": [], "entities": [{"text": "distant supervision\" (DS)", "start_pos": 26, "end_pos": 51, "type": "TASK", "confidence": 0.5252413600683212}]}, {"text": "The assumption of DS is that if two entities participate in a known Freebase relation, any sentence that contains those two entities might express that relation.", "labels": [], "entities": []}, {"text": "However, this technique often introduces noise to the generated training data.", "labels": [], "entities": []}, {"text": "As a result, DS is still limited by the quality of training data, and noise existing in positively labeled data may affect the performance of supervised learning.", "labels": [], "entities": [{"text": "DS", "start_pos": 13, "end_pos": 15, "type": "TASK", "confidence": 0.635439395904541}]}, {"text": "In this study, we propose methods that can be applied for both automatic seed selection and noise reduction by formulating these tasks as ranking problems according to different ranking criteria.", "labels": [], "entities": [{"text": "automatic seed selection", "start_pos": 63, "end_pos": 87, "type": "TASK", "confidence": 0.6093692282835642}, {"text": "noise reduction", "start_pos": 92, "end_pos": 107, "type": "TASK", "confidence": 0.715204268693924}]}, {"text": "Our methods are inspired by ranking instances and patterns computed by the HITS algorithm, and selecting cluster centroids using K-means, latent semantic analysis, or the non-negative matrix factorization method.", "labels": [], "entities": []}, {"text": "The main contributions of this paper are (a) an annotated dataset of 5,727 partwhole relations 1 , which contains 8 subtypes for the bootstrapping RE system; (b) methods for automatic seed selection for bootstrapping RE and noise reduction for distant supervised RE; and (c) experimental results showing that the proposed models outperform baselines on two datasets.", "labels": [], "entities": []}], "datasetContent": [{"text": "We provide an annotated dataset of part-whole relations as a reliable resource for selecting seeds.", "labels": [], "entities": []}, {"text": "Our dataset was collected from Wikipedia and ClueWeb, and annotated by two annotators.", "labels": [], "entities": []}, {"text": "One of its special characteristics is that the part-whole relation is a collection of relations, not a single relation.", "labels": [], "entities": []}, {"text": "gives the frequencies of each subtype of part-whole relations.", "labels": [], "entities": []}, {"text": "There are 5,727 instances of 8 subtypes that were annotated with the same labels by both annotators.", "labels": [], "entities": []}, {"text": "We use Espresso+Word2vec (, which is an improved version for the original Espresso algorithm ().", "labels": [], "entities": [{"text": "Word2vec", "start_pos": 16, "end_pos": 24, "type": "DATASET", "confidence": 0.7869579792022705}]}, {"text": "Espresso+Word2vec outperformed the Espresso system for harvesting part-whole relations by utilizing the Similarity Ranker, which uses the embedded vector difference between instance pairs of relations.", "labels": [], "entities": []}, {"text": "The performance is measured with, N = 50.", "labels": [], "entities": [{"text": "N", "start_pos": 34, "end_pos": 35, "type": "METRIC", "confidence": 0.9730437397956848}]}, {"text": "In total, 5,000 instances are checked by  annotators to ascertain whether they express partwhole relations.", "labels": [], "entities": []}, {"text": "We vary the number k of seeds between 5 and 50 with a step of 5 to report the average P@50 of each seed selection method.", "labels": [], "entities": []}, {"text": "For the noise reduction task, we use the training and testing set developed by (, which contains 53 relation classes.", "labels": [], "entities": [{"text": "noise reduction", "start_pos": 8, "end_pos": 23, "type": "TASK", "confidence": 0.7019215822219849}]}, {"text": "This dataset was generated by aligning Freebase relations with the New York Times corpus.", "labels": [], "entities": [{"text": "New York Times corpus", "start_pos": 67, "end_pos": 88, "type": "DATASET", "confidence": 0.7712169289588928}]}, {"text": "After removing noisy triples from the dataset using the proposed methods, we use the filtered data to train two kinds of convolutional neural networks (CNN) (the CNN model in () and the PCNN model in ()) with at-least-one multiinstance learning (ONE) used in (, and the sentence-level attention (ATT) used in ().", "labels": [], "entities": [{"text": "multiinstance learning (ONE)", "start_pos": 222, "end_pos": 250, "type": "METRIC", "confidence": 0.7214072525501252}, {"text": "sentence-level attention (ATT)", "start_pos": 270, "end_pos": 300, "type": "METRIC", "confidence": 0.6375638842582703}]}, {"text": "Finally, we report the area under the precision-recall (AUCPR) of each noise reduction method.", "labels": [], "entities": [{"text": "precision-recall (AUCPR)", "start_pos": 38, "end_pos": 62, "type": "METRIC", "confidence": 0.9447892755270004}]}], "tableCaptions": [{"text": " Table 2: Performance of seed selection methods.", "labels": [], "entities": [{"text": "seed selection", "start_pos": 25, "end_pos": 39, "type": "TASK", "confidence": 0.8203582763671875}]}, {"text": " Table 3: Performance (AUCPR) of each noise reduction method; in bold are the best scores.", "labels": [], "entities": [{"text": "Performance (AUCPR)", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.723070815205574}, {"text": "noise reduction", "start_pos": 38, "end_pos": 53, "type": "TASK", "confidence": 0.7091759890317917}]}]}