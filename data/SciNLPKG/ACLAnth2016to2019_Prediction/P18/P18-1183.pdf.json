{"title": [{"text": "Stock Movement Prediction from Tweets and Historical Prices", "labels": [], "entities": [{"text": "Stock Movement Prediction", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6475858489672343}]}], "abstractContent": [{"text": "Stock movement prediction is a challenging problem: the market is highly stochas-tic, and we make temporally-dependent predictions from chaotic data.", "labels": [], "entities": [{"text": "Stock movement prediction", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7116744816303253}]}, {"text": "We treat these three complexities and present a novel deep generative model jointly exploiting text and price signals for this task.", "labels": [], "entities": []}, {"text": "Unlike the case with discriminative or topic modeling, our model introduces recurrent, continuous latent variables fora better treatment of stochasticity, and uses neural variational inference to address the intractable posterior inference.", "labels": [], "entities": []}, {"text": "We also provide a hybrid objective with temporal auxiliary to flexibly capture predictive dependencies.", "labels": [], "entities": []}, {"text": "We demonstrate the state-of-the-art performance of our proposed model on anew stock movement prediction dataset which we collected.", "labels": [], "entities": []}], "introductionContent": [{"text": "Stock movement prediction has long attracted both investors and researchers.", "labels": [], "entities": [{"text": "Stock movement prediction", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7428013881047567}]}, {"text": "We present a model to predict stock price movement from tweets and historical stock prices.", "labels": [], "entities": []}, {"text": "In natural language processing (NLP), public news and social media are two primary content resources for stock market prediction, and the models that use these sources are often discriminative.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 3, "end_pos": 36, "type": "TASK", "confidence": 0.7629532217979431}, {"text": "stock market prediction", "start_pos": 105, "end_pos": 128, "type": "TASK", "confidence": 0.6528177360693613}]}, {"text": "Among them, classic research relies heavily on feature engineering (.", "labels": [], "entities": []}, {"text": "With the prevalence of deep neural networks (, eventdriven approaches were studied with structured event representations ().", "labels": [], "entities": []}, {"text": "More recently, propose to mine news sequence directly from text with hierarchical attention mechanisms for stock trend prediction.", "labels": [], "entities": [{"text": "stock trend prediction", "start_pos": 107, "end_pos": 129, "type": "TASK", "confidence": 0.6767466763655344}]}, {"text": "However, stock movement prediction is widely considered difficult due to the high stochasticity of the market: stock prices are largely driven by new information, resulting in a random-walk pattern).", "labels": [], "entities": [{"text": "stock movement prediction", "start_pos": 9, "end_pos": 34, "type": "TASK", "confidence": 0.8211580514907837}]}, {"text": "Instead of using only deterministic features, generative topic models were extended to jointly learn topics and sentiments for the task ().", "labels": [], "entities": []}, {"text": "Compared to discriminative models, generative models have the natural advantage in depicting the generative process from market information to stock signals and introducing randomness.", "labels": [], "entities": [{"text": "generative", "start_pos": 35, "end_pos": 45, "type": "TASK", "confidence": 0.9784334301948547}, {"text": "generative process from market information", "start_pos": 97, "end_pos": 139, "type": "TASK", "confidence": 0.8621623277664184}]}, {"text": "However, these models underrepresent chaotic social texts with bag-of-words and employ simple discrete latent variables.", "labels": [], "entities": []}, {"text": "In essence, stock movement prediction is a time series problem.", "labels": [], "entities": [{"text": "stock movement prediction", "start_pos": 12, "end_pos": 37, "type": "TASK", "confidence": 0.7690195441246033}]}, {"text": "The significance of the temporal dependency between movement predictions is not addressed in existing NLP research.", "labels": [], "entities": []}, {"text": "For instance, when a company suffers from a major scandal on a trading day d 1 , generally, its stock price will have a downtrend in the coming trading days until day d 2 , i.e. [d.", "labels": [], "entities": []}, {"text": "If a stock predictor can recognize this decline pattern, it is likely to benefit all the predictions of the movements during [d.", "labels": [], "entities": []}, {"text": "Otherwise, the accuracy in this interval might be harmed.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9996069073677063}]}, {"text": "This predictive dependency is a result of the fact that public information, e.g. a company scandal, needs time to be absorbed into movements overtime (, and thus is largely shared across temporally-close predictions.", "labels": [], "entities": []}, {"text": "Aiming to tackle the above-mentioned outstanding research gaps in terms of modeling high market stochasticity, chaotic market information and temporally-dependent prediction, we propose StockNet, a deep generative model for stock movement prediction.", "labels": [], "entities": [{"text": "stock movement prediction", "start_pos": 224, "end_pos": 249, "type": "TASK", "confidence": 0.6968601842721304}]}, {"text": "To better incorporate stochastic factors, we generate stock movements from latent driven factors modeled with recurrent, continuous latent variables.", "labels": [], "entities": []}, {"text": "Motivated by Variational Auto-Encoders (VAEs;), we propose a novel decoder with a variational architecture and derive a recurrent variational lower bound for end-to-end training (Section 5.2).", "labels": [], "entities": []}, {"text": "To the best of our knowledge, StockNet is the first deep generative model for stock movement prediction.", "labels": [], "entities": [{"text": "stock movement prediction", "start_pos": 78, "end_pos": 103, "type": "TASK", "confidence": 0.7543393770853678}]}, {"text": "To fully exploit market information, StockNet directly learns from data without pre-extracting structured events.", "labels": [], "entities": []}, {"text": "We build market sources by referring to both fundamental information, e.g. tweets, and technical features, e.g. historical stock prices (Section 5.1).", "labels": [], "entities": []}, {"text": "To accurately depict predictive dependencies, we assume that the movement prediction fora stock can benefit from learning to predict its historical movements in a lag window.", "labels": [], "entities": []}, {"text": "We propose trading-day alignment as the framework basis (Section 4), and further provide a novel multi-task learning objective (Section 5.3).", "labels": [], "entities": [{"text": "trading-day alignment", "start_pos": 11, "end_pos": 32, "type": "TASK", "confidence": 0.8430744409561157}]}, {"text": "We evaluate StockNet on a stock movement prediction task with anew dataset that we collected.", "labels": [], "entities": [{"text": "StockNet", "start_pos": 12, "end_pos": 20, "type": "DATASET", "confidence": 0.9178397059440613}, {"text": "stock movement prediction task", "start_pos": 26, "end_pos": 56, "type": "TASK", "confidence": 0.7482366561889648}]}, {"text": "Compared with strong baselines, our experiments show that StockNet achieves state-of-the-art performance by incorporating both data from Twitter and historical stock price listings.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we detail our experimental setup and results.", "labels": [], "entities": []}, {"text": "Following previous work for stock prediction, we adopt the standard measure of accuracy and Matthews Correlation Coefficient (MCC) as evaluation metrics.", "labels": [], "entities": [{"text": "stock prediction", "start_pos": 28, "end_pos": 44, "type": "TASK", "confidence": 0.7963016629219055}, {"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.8647639155387878}, {"text": "Matthews Correlation Coefficient (MCC)", "start_pos": 92, "end_pos": 130, "type": "METRIC", "confidence": 0.9690481921037039}]}, {"text": "MCC avoids bias due to data skew.", "labels": [], "entities": []}, {"text": "Given the confusion matrix tp fn fp tn containing the number of samples classified as true positive, false positive, true negative and false negative, MCC is calculated as . (30)", "labels": [], "entities": [{"text": "MCC", "start_pos": 151, "end_pos": 154, "type": "METRIC", "confidence": 0.9925357103347778}]}], "tableCaptions": [{"text": " Table 1: Performance of baselines and StockNet variations in accuracy and MCC.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.999723494052887}, {"text": "MCC", "start_pos": 75, "end_pos": 78, "type": "METRIC", "confidence": 0.9993647933006287}]}, {"text": " Table 1. TLSDA is the  best baseline in MCC while HAN is the best  baseline in accuracy. Our model, HEDGEFUNDAN- ALYST achieves the best performance of 58.23 in  accuracy and 0.080796 in MCC, outperforming  TLSDA and HAN with 4.16, 0.59 in accuracy, and  0.015414, 0.028996 in MCC, respectively.  Though slightly better than random guess, clas- sic technical analysis, e.g. ARIMA, does not yield  satisfying results. Similar in using only histori- cal prices, TECHNICALANALYST shows an obvious  advantage in this task compared ARIMA. We be- lieve there are two major reasons: (1) TECHNICAL- ANALYST learns from training data and incorpo- rates more flexible non-linearity; (2) our test set  contains a large number of stocks while ARIMA  is more sensitive to peculiar sequence station- arity. It is worth noting that FUNDAMENTALANA-", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9989519119262695}, {"text": "HEDGEFUNDAN- ALYST", "start_pos": 101, "end_pos": 119, "type": "METRIC", "confidence": 0.8257368803024292}, {"text": "accuracy", "start_pos": 163, "end_pos": 171, "type": "METRIC", "confidence": 0.9994853734970093}, {"text": "accuracy", "start_pos": 241, "end_pos": 249, "type": "METRIC", "confidence": 0.9987536668777466}, {"text": "FUNDAMENTALANA", "start_pos": 818, "end_pos": 832, "type": "METRIC", "confidence": 0.7052691578865051}]}]}