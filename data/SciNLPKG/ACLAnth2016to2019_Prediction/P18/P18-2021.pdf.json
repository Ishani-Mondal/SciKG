{"title": [{"text": "A dataset for identifying actionable feedback in collaborative software development", "labels": [], "entities": []}], "abstractContent": [{"text": "Software developers and testers have long struggled with how to elicit proactive responses from their coworkers when reviewing code for security vulnerabilities and errors.", "labels": [], "entities": []}, {"text": "For a code review to be successful , it must not only identify potential problems but also elicit an active response from the colleague responsible for modifying the code.", "labels": [], "entities": []}, {"text": "To understand the factors that contribute to this outcome, we analyze a novel dataset of more than one million code reviews for the Google Chromium project, from which we extract linguistic features of feedback that elicited responsive actions from coworkers.", "labels": [], "entities": []}, {"text": "Using a manually-labeled subset of reviewer comments , we trained a highly accurate clas-sifier to identify \"acted-upon\" comments (AUC = 0.85).", "labels": [], "entities": [{"text": "AUC", "start_pos": 131, "end_pos": 134, "type": "METRIC", "confidence": 0.9952191710472107}]}, {"text": "Our results demonstrate the utility of our dataset, the feasibility of using NLP for this new task, and the potential of NLP to improve our understanding of how communications between colleagues can be authored to elicit positive, proactive responses.", "labels": [], "entities": []}], "introductionContent": [{"text": "As in many other work environments, such as hospitals and law firms, employees in software development must communicate through written feedback and comments to develop functional and secure code.", "labels": [], "entities": []}, {"text": "Developers elicit feedback from their collaborators on the code that they write through the code review process, which is an integral part of the mature software development lifecycle.", "labels": [], "entities": []}, {"text": "Most large software development organizations, including Microsoft) and Google, mandate the review of all changes to the code base.", "labels": [], "entities": []}, {"text": "Code reviews identify potential bugs or errors in software, but not all of the comments made by reviewers are acted upon by developers.", "labels": [], "entities": []}, {"text": "Some code reviews are taken seriously by developers and prompt significant fixes, while many others are overlooked or dismissed.", "labels": [], "entities": []}, {"text": "In some cases, such as when code reviewers misunderstand the purpose of a proposed change or identify an unimportant issue, it maybe appropriate to ignore their comments.", "labels": [], "entities": []}, {"text": "At other times, however, the presentation and language of the reviewer's feedback may cause the problems it identifies to be overlooked.", "labels": [], "entities": []}, {"text": "Understanding which linguistic characteristics of code reviews influence whether reviews are taken seriously can aid developers in providing effective feedback that is acted upon by their peers.", "labels": [], "entities": []}, {"text": "In turn, this can contribute to our general understanding of how to provide meaningful written feedback in a collaborative workplace setting.", "labels": [], "entities": []}, {"text": "With this in mind, we present a dataset of over one million code review comments from the Chromium project, designed with the goal of discovering the linguistic features associated with actionable developer feedback.", "labels": [], "entities": []}, {"text": "We describe the dataset, along with an array of linguistic features capturing characteristics of complexity, content, and style, extracted from that dataset.", "labels": [], "entities": []}, {"text": "Using a labeled subset of this large dataset, we develop a highly accurate classifier for identifying examples of actionable feedback that performs better than the keyword and sentiment features previously explored for similar tasks.", "labels": [], "entities": []}, {"text": "The contributions of this work are: (1) the introduction of anew NLP task: identifying actionable feedback in collaborative work conversations; (2) a large structured dataset of automatically linguistically annotated software developer conversations for feature exploration 1 ; (3) a smaller manuallylabeled subset of that dataset for hypothesis test-ing 1 ; and (4) a demonstration of the feasibility of using NLP for this task in the form of a highaccuracy classifier of actionable feedback.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Results of 10 \u00d7 10\u2212fold cross-validation.", "labels": [], "entities": []}]}