{"title": [{"text": "A Sequence-to-Sequence Model for Semantic Role Labeling", "labels": [], "entities": [{"text": "Semantic Role Labeling", "start_pos": 33, "end_pos": 55, "type": "TASK", "confidence": 0.7280394434928894}]}], "abstractContent": [{"text": "We explore a novel approach for Semantic Role Labeling (SRL) by casting it as a sequence-to-sequence process.", "labels": [], "entities": [{"text": "Semantic Role Labeling (SRL)", "start_pos": 32, "end_pos": 60, "type": "TASK", "confidence": 0.8323232432206472}]}, {"text": "We employ an attention-based model enriched with a copying mechanism to ensure faithful regeneration of the input sequence, while enabling interleaved generation of argument role labels.", "labels": [], "entities": []}, {"text": "Here, we apply this model in a monolingual setting, performing PropBank SRL on English language data.", "labels": [], "entities": [{"text": "PropBank SRL", "start_pos": 63, "end_pos": 75, "type": "TASK", "confidence": 0.6469279229640961}]}, {"text": "The constrained sequence generation setup enforced with the copying mechanism allows us to analyze the performance and special properties of the model on manually labeled data and benchmarking against state-of-the-art sequence labeling models.", "labels": [], "entities": []}, {"text": "We show that our model is able to solve the SRL argument labeling task on English data, yet further structural decoding constraints will need to be added to make the model truly competitive.", "labels": [], "entities": [{"text": "SRL argument labeling task", "start_pos": 44, "end_pos": 70, "type": "TASK", "confidence": 0.9133256077766418}]}, {"text": "Our work represents a first step towards more advanced, generative SRL labeling setups.", "labels": [], "entities": [{"text": "generative SRL labeling", "start_pos": 56, "end_pos": 79, "type": "TASK", "confidence": 0.8888042569160461}]}], "introductionContent": [{"text": "Semantic Role Labeling (SRL) is the task of assigning semantic argument structure to constituents or phrases in a sentence, to answer the question: Who did what to whom, where and when?", "labels": [], "entities": [{"text": "Semantic Role Labeling (SRL) is the task of assigning semantic argument structure to constituents or phrases in a sentence, to answer the question: Who did what to whom, where and when?", "start_pos": 0, "end_pos": 185, "type": "Description", "confidence": 0.7071841222208899}]}, {"text": "This task is normally accomplished in two steps: first, identifying the predicate and second, labeling its arguments and the roles that they play with respect to the predicate.", "labels": [], "entities": []}, {"text": "SRL has been formalized in different frameworks, the most prominent being FrameNet () and).", "labels": [], "entities": [{"text": "SRL", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8037548065185547}]}, {"text": "In this work we focus on argument identification and labeling using the PropBank (PB) annotation scheme.", "labels": [], "entities": [{"text": "argument identification", "start_pos": 25, "end_pos": 48, "type": "TASK", "confidence": 0.7927759885787964}, {"text": "PropBank (PB) annotation scheme", "start_pos": 72, "end_pos": 103, "type": "DATASET", "confidence": 0.8865873912970225}]}, {"text": "Recent end-to-end neural models considerably improved the state-of-the-art results for SRL in English (.", "labels": [], "entities": [{"text": "SRL", "start_pos": 87, "end_pos": 90, "type": "TASK", "confidence": 0.9900546073913574}]}, {"text": "In general, such models treat the problem as a supervised sequence labeling task, using deep LSTM architectures that assign a label to each token within the sentence.", "labels": [], "entities": []}, {"text": "SRL training resources for other languages are more restricted in size and thus, models suffer from sparseness problems because specific predicate-role instances occur only a handful of times in the training set.", "labels": [], "entities": [{"text": "SRL training", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.8391677737236023}]}, {"text": "Since annotating SRL data in larger amounts is expensive, the use of a generative neural network model could be beneficial for automatically obtaining more labeled data in low-resource settings.", "labels": [], "entities": [{"text": "SRL", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.9363490343093872}]}, {"text": "The model that we present in this paper is a first step towards a joint label and language generation formulation for SRL, using the sequence-to-sequence architecture as a starting point.", "labels": [], "entities": [{"text": "language generation", "start_pos": 82, "end_pos": 101, "type": "TASK", "confidence": 0.6910413801670074}, {"text": "SRL", "start_pos": 118, "end_pos": 121, "type": "TASK", "confidence": 0.9864375591278076}]}, {"text": "We explore a sequence-to-sequence formulation of SRL that we apply, as a first step, in a classical monolingual setting on PropBank data, as illustrated in.", "labels": [], "entities": [{"text": "SRL", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.9627379179000854}, {"text": "PropBank data", "start_pos": 123, "end_pos": 136, "type": "DATASET", "confidence": 0.974865049123764}]}, {"text": "This constrained monolingual setting will allow us to analyze the suitablility of a sequence-to-sequence architecture for SRL, by benchmarking the system performance against existing sequence labeling models for SRL on well known labeled evaluation data.", "labels": [], "entities": [{"text": "SRL", "start_pos": 122, "end_pos": 125, "type": "TASK", "confidence": 0.9879869818687439}, {"text": "SRL", "start_pos": 212, "end_pos": 215, "type": "TASK", "confidence": 0.9717183113098145}]}, {"text": "Sequence-to-sequence (seq2seq) models were pioneered by , and later enhanced with an attention mechanism (.", "labels": [], "entities": []}, {"text": "They have been successfully applied in many related structure prediction tasks such as syntactic parsing, parsing into Abstract Meaning Representation (, semantic parsing (, and cross-lingual Open Information Extraction (.", "labels": [], "entities": [{"text": "structure prediction", "start_pos": 52, "end_pos": 72, "type": "TASK", "confidence": 0.7813990414142609}, {"text": "syntactic parsing", "start_pos": 87, "end_pos": 104, "type": "TASK", "confidence": 0.7772518396377563}, {"text": "parsing into Abstract Meaning Representation", "start_pos": 106, "end_pos": 150, "type": "TASK", "confidence": 0.7178071141242981}, {"text": "semantic parsing", "start_pos": 154, "end_pos": 170, "type": "TASK", "confidence": 0.7510240972042084}, {"text": "cross-lingual Open Information Extraction", "start_pos": 178, "end_pos": 219, "type": "TASK", "confidence": 0.5866615772247314}]}, {"text": "When applying a seq2seq model with attention in a monolingual SRL labeling setup, we need to restrict the decoder to reproduce the original input sentence, while in addition inserting PropBank labels into the target sequence in the decoding process (see.", "labels": [], "entities": [{"text": "SRL labeling", "start_pos": 62, "end_pos": 74, "type": "TASK", "confidence": 0.8575908243656158}]}, {"text": "To achieve this, we encode each input sentence into a suitable representation that will be used by the decoder to regenerate word tokens as given in the source sentence and introducing SRL labels inappropriate positions to label argument spans with semantic roles.", "labels": [], "entities": []}, {"text": "In order to avoid lexical deviations in the output string, we add a copying mechanism () to the model.", "labels": [], "entities": []}, {"text": "This technique was originally proposed to deal with rare words by copying them directly from the source when appropriate.", "labels": [], "entities": []}, {"text": "We apply this mechanism in a novel way, with the aim of guiding the decoder to reproduce the input as closely as possible, while otherwise giving it the option of generating role labels inappropriate positions in the target sequence.", "labels": [], "entities": []}, {"text": "Our main contributions in this work are: (i) We propose a novel neural architecture for SRL using a seq2seq model enhanced with attention and copying mechanisms.", "labels": [], "entities": [{"text": "SRL", "start_pos": 88, "end_pos": 91, "type": "TASK", "confidence": 0.9907417297363281}]}, {"text": "(ii) We evaluate this model in a monolingual setting, performing PropBank-style SRL on standard English datasets, to assess the suitability of this model type for the SRL labeling task.", "labels": [], "entities": [{"text": "PropBank-style SRL on standard English datasets", "start_pos": 65, "end_pos": 112, "type": "DATASET", "confidence": 0.547366609176}, {"text": "SRL labeling task", "start_pos": 167, "end_pos": 184, "type": "TASK", "confidence": 0.9419352412223816}]}, {"text": "(iii) We compare the performance of our model to state-of-the-art sequence labeling models, including detailed (also comparative) error analysis.", "labels": [], "entities": []}, {"text": "(iv) We show that the seq2seq model is suited for the task, but still lags behind sequence labeling systems that include higher-level constraints.", "labels": [], "entities": []}], "datasetContent": [{"text": "We test the performance of our system on the span-based SRL datasets CoNLL-05).", "labels": [], "entities": [{"text": "SRL datasets CoNLL-05", "start_pos": 56, "end_pos": 77, "type": "DATASET", "confidence": 0.8736273050308228}]}, {"text": "This means that it is essential to predict perfect argument spans besides the correct role label.", "labels": [], "entities": []}, {"text": "Initially, we trained a model using attention only, and it learned to generate balanced brackets (every opening bracket has a corresponding closing We also experimented with word2vec word embeddings (  bracket within the sequence) without further constraints.", "labels": [], "entities": []}, {"text": "Yet, due to its generative nature, many target sequences diverged from the source in both length and token sequences.", "labels": [], "entities": []}, {"text": "This was expected, because the system has to learn to generate not only the labels at the correct time-step but also to re-generate the complete sentence accurately.", "labels": [], "entities": []}, {"text": "This is a disadvantage compared to the sequence labeling models where the words are already given.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.6488104164600372}]}, {"text": "By adding copying mechanism the model successfully regenerates the source sentence in the majority (up to 99%) of cases, as shown in Table 2.", "labels": [], "entities": []}, {"text": "Such behavior also enables us to measure the performance of the model as an argument role classifier against the gold standard.", "labels": [], "entities": []}, {"text": "Thus, we can benchmark its labeling performance against previous architectures built to solve the SRL task.", "labels": [], "entities": [{"text": "SRL task", "start_pos": 98, "end_pos": 106, "type": "TASK", "confidence": 0.9307929873466492}]}, {"text": "displays the overall labeling performance of our copying-enhanced seq2seq model in comparison to previous neural sequence labeling architectures.", "labels": [], "entities": []}, {"text": "For sequences that do not fully reproduce the input, we cannot compute appropriate scores against the gold standard.", "labels": [], "entities": []}, {"text": "We compute two alternative scores for these cases: oracle-min, by setting the score for these sentences to 0.0 F1, and oracle-max, by setting their results to the scores we would obtain with perfect (= gold) labels.", "labels": [], "entities": [{"text": "F1", "start_pos": 111, "end_pos": 113, "type": "METRIC", "confidence": 0.9951678514480591}]}, {"text": "With these scores, we can better estimate the loss we are experiencing by non-perfectly reproduced sequences (see.)", "labels": [], "entities": []}, {"text": "As seen in, our model achieves an F1 score of 76.05 on the CoNLL-05 development set, and 73.4 on CoNLL-12 (min-oracle), and 77.29 and 75.05 (max-oracle), respectively.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.988556295633316}, {"text": "CoNLL-05 development set", "start_pos": 59, "end_pos": 83, "type": "DATASET", "confidence": 0.961726446946462}, {"text": "CoNLL-12", "start_pos": 97, "end_pos": 105, "type": "DATASET", "confidence": 0.9393808245658875}]}, {"text": "While these scores are still low compared to the latest neural SRL architectures, they are above the relatively simple model of.", "labels": [], "entities": []}, {"text": "Note also that in contrast to the stronger models of; and, our architecture is very lean and does not (yet) employ structured prediction (e.g. Conditional Random Field), to impose structural constraints on the label assignment.", "labels": [], "entities": []}, {"text": "While this is certainly an extension we are going to explore in future work, here we will conduct deeper investigation to learn more about the kind of errors that our unconstrained seq2seq model makes.", "labels": [], "entities": []}, {"text": "We report the analysis on CoNLL-05 development set.", "labels": [], "entities": [{"text": "CoNLL-05 development set", "start_pos": 26, "end_pos": 50, "type": "DATASET", "confidence": 0.9648569027582804}]}], "tableCaptions": [{"text": " Table 2: Quality of reproducing words and SRL  brackets with seq2seq: Attention-only vs. Atten- tion & Copying, on CoNLL-05 and CoNLL-12  datasets: percentage of correctly reproduced sen- tence length and percentage of balanced brackets.", "labels": [], "entities": [{"text": "CoNLL-05", "start_pos": 116, "end_pos": 124, "type": "DATASET", "confidence": 0.9469922780990601}, {"text": "CoNLL-12  datasets", "start_pos": 129, "end_pos": 147, "type": "DATASET", "confidence": 0.8558603823184967}]}, {"text": " Table 3: F1 measure for argument role labeling  of our seq2seq model w/ Attention & Copying on  CoNLL-05 and CoNLL-12 dev and test sets, com- pared to Collobert w/o parser, FitzGerald single  model, Zhou & Xu, and He single model .", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9991859793663025}, {"text": "argument role labeling", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.6646290520826975}, {"text": "CoNLL-05 and CoNLL-12 dev and test sets", "start_pos": 97, "end_pos": 136, "type": "DATASET", "confidence": 0.7944789954594204}]}]}