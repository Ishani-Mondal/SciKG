{"title": [{"text": "Active learning for deep semantic parsing", "labels": [], "entities": [{"text": "deep semantic parsing", "start_pos": 20, "end_pos": 41, "type": "TASK", "confidence": 0.6127397914727529}]}], "abstractContent": [{"text": "Semantic parsing requires training data that is expensive and slow to collect.", "labels": [], "entities": [{"text": "Semantic parsing", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8354822099208832}]}, {"text": "We apply active learning to both traditional and \"overnight\" data collection approaches.", "labels": [], "entities": []}, {"text": "We show that it is possible to obtain good training hyperparameters from seed data which is only a small fraction of the full dataset.", "labels": [], "entities": []}, {"text": "We show that uncertainty sampling based on least confidence score is competitive in traditional data collection but not applicable for overnight collection.", "labels": [], "entities": [{"text": "least confidence score", "start_pos": 43, "end_pos": 65, "type": "METRIC", "confidence": 0.8122425476710001}, {"text": "overnight collection", "start_pos": 135, "end_pos": 155, "type": "TASK", "confidence": 0.6828864514827728}]}, {"text": "We evaluate several active learning strategies for overnight data collection and show that different example selection strategies per domain perform best.", "labels": [], "entities": [{"text": "overnight data collection", "start_pos": 51, "end_pos": 76, "type": "TASK", "confidence": 0.6462447941303253}]}], "introductionContent": [{"text": "Semantic parsing maps a natural language query to a logical form (LF).", "labels": [], "entities": [{"text": "Semantic parsing", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7883874475955963}]}, {"text": "Producing training data for semantic parsing is slow and costly.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 28, "end_pos": 44, "type": "TASK", "confidence": 0.8554472625255585}]}, {"text": "Active learning is effective in reducing costly data requirements for many NLP tasks.", "labels": [], "entities": []}, {"text": "In this work, we apply active learning to deep semantic parsing and show that we can substantially reduce the data required to achieve state-of-the-art results.", "labels": [], "entities": [{"text": "deep semantic parsing", "start_pos": 42, "end_pos": 63, "type": "TASK", "confidence": 0.6375779112180074}]}, {"text": "There are two main methods for generating semantic parsing training data.", "labels": [], "entities": [{"text": "semantic parsing training", "start_pos": 42, "end_pos": 67, "type": "TASK", "confidence": 0.7659003337224325}]}, {"text": "The traditional approach first generates the input natural language utterances and then labels them with output LFs.", "labels": [], "entities": []}, {"text": "We show that active learning based on uncertainty sampling works well for this approach.", "labels": [], "entities": []}, {"text": "The \"overnight\" annotation approach ( generates output LFs from a grammar, and uses crowd workers to paraphrase these LFs into input natural language queries.", "labels": [], "entities": []}, {"text": "This approach is faster and cheaper than traditional annotation.", "labels": [], "entities": []}, {"text": "However, the difficulty and cost of data generation and validation are still substantial if we need a large amount of data for the system to achieve high accuracy; if the logical forms can express complex combinations of semantic primitives that must be covered; or if the target language is one with relatively few crowd workers.", "labels": [], "entities": [{"text": "data generation", "start_pos": 36, "end_pos": 51, "type": "TASK", "confidence": 0.743253618478775}, {"text": "validation", "start_pos": 56, "end_pos": 66, "type": "TASK", "confidence": 0.9441737532615662}, {"text": "accuracy", "start_pos": 154, "end_pos": 162, "type": "METRIC", "confidence": 0.9899880290031433}]}, {"text": "Applying active learning to the overnight approach is even more compelling, since the unlabelled LFs can be generated essentially for free by a grammar.", "labels": [], "entities": []}, {"text": "However, conventional active learning strategies are not compatible with the overnight approach, since the crowd annotators produce inputs (utterances) rather than labels (LFs).", "labels": [], "entities": []}, {"text": "In order to apply active learning to deep semantic parsing, we need away of selecting hyperparameters without requiring the full training dataset.", "labels": [], "entities": [{"text": "deep semantic parsing", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.6292307873566946}]}, {"text": "For optimal performance, we should rerun hyperparameter tuning for each active learning round, but this is prohibitively expensive computationally.", "labels": [], "entities": []}, {"text": "We show that hyperparameters selected using a random subset of the data (about 20%) perform almost as well as those from the full set.", "labels": [], "entities": []}, {"text": "Our contributions are (1) a simple hyperparameter selection technique for active learning applied to semantic parsing, and (2) straightforward active learning strategies for both traditional and overnight data collection that significantly reduce data annotation requirements.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 101, "end_pos": 117, "type": "TASK", "confidence": 0.7638517916202545}]}, {"text": "To the best of our knowledge we are the first to investigate active learning for overnight data collection.", "labels": [], "entities": [{"text": "overnight data collection", "start_pos": 81, "end_pos": 106, "type": "TASK", "confidence": 0.611507515112559}]}], "datasetContent": [{"text": "We experiment with the NLMaps corpus which was collected using the traditional approach.", "labels": [], "entities": [{"text": "NLMaps corpus", "start_pos": 23, "end_pos": 36, "type": "DATASET", "confidence": 0.9338102042675018}]}, {"text": "We also experiment with the Social Network corpus from the Overnight dataset () (which was collected using the overnight approach).", "labels": [], "entities": [{"text": "Social Network corpus", "start_pos": 28, "end_pos": 49, "type": "DATASET", "confidence": 0.8493932286898295}, {"text": "Overnight dataset", "start_pos": 59, "end_pos": 76, "type": "DATASET", "confidence": 0.9521788954734802}]}, {"text": "Social Network was chosen as being the largest dataset available.", "labels": [], "entities": [{"text": "Social Network", "start_pos": 0, "end_pos": 14, "type": "DATASET", "confidence": 0.9642183184623718}]}, {"text": "Since neither corpora have a separate development set, we use 10% of the training set as development data for early stopping.", "labels": [], "entities": [{"text": "early stopping", "start_pos": 110, "end_pos": 124, "type": "TASK", "confidence": 0.9074711501598358}]}, {"text": "We select ATIS as our development corpus for all feature selection and experiments with classifiers in \u00a74.1 and \u00a74.2.", "labels": [], "entities": [{"text": "ATIS", "start_pos": 10, "end_pos": 14, "type": "DATASET", "confidence": 0.658547580242157}, {"text": "feature selection", "start_pos": 49, "end_pos": 66, "type": "TASK", "confidence": 0.6981081366539001}]}, {"text": "For evaluation, we use full LF exact match accuracy for all experiments.", "labels": [], "entities": [{"text": "LF exact match accuracy", "start_pos": 28, "end_pos": 51, "type": "METRIC", "confidence": 0.7403290718793869}]}, {"text": "Note that this is a much stricter evaluation compared with running through database evaluator as in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The LF exact match accuracy on NLMap,  Social Network and ATIS with configurations  from ATIS, from hyperparameter tuning on small  subset of data (10% + dev) or on the full train- ing data. The supervised SOTA for NLMap and  ATIS (Duong et al., 2017) and Social Network (Jia  and Liang, 2016) are provided for reference. 5", "labels": [], "entities": [{"text": "LF exact match", "start_pos": 14, "end_pos": 28, "type": "METRIC", "confidence": 0.7258192300796509}, {"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.5548394918441772}]}]}