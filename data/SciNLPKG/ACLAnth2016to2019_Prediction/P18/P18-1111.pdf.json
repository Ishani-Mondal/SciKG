{"title": [{"text": "Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations", "labels": [], "entities": [{"text": "Revealing Implicit Noun-Compound Relations", "start_pos": 25, "end_pos": 67, "type": "TASK", "confidence": 0.8548577278852463}]}], "abstractContent": [{"text": "Revealing the implicit semantic relation between the constituents of a noun-compound is important for many NLP applications.", "labels": [], "entities": []}, {"text": "It has been addressed in the literature either as a classification task to a set of pre-defined relations or by producing free text paraphrases explicating the relations.", "labels": [], "entities": []}, {"text": "Most existing paraphrasing methods lack the ability to generalize, and have a hard time interpreting infrequent or new noun-compounds.", "labels": [], "entities": []}, {"text": "We propose a neural model that generalizes better by representing paraphrases in a continuous space, generalizing for both unseen noun-compounds and rare paraphrases.", "labels": [], "entities": []}, {"text": "Our model helps improving performance on both the noun-compound paraphrasing and classification tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "Noun-compounds hold an implicit semantic relation between their constituents.", "labels": [], "entities": []}, {"text": "For example, a 'birthday cake' is a cake eaten on a birthday, while 'apple cake' is a cake made of apples.", "labels": [], "entities": []}, {"text": "Interpreting noun-compounds by explicating the relationship is beneficial for many natural language understanding tasks, especially given the prevalence of nouncompounds in English.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 83, "end_pos": 113, "type": "TASK", "confidence": 0.7082399527231852}]}, {"text": "The interpretation of noun-compounds has been addressed in the literature either by classifying them to a fixed inventory of ontological relationships (e.g. or by generating various free text paraphrases that describe the relation in a more expressive manner (e.g..", "labels": [], "entities": []}, {"text": "Methods dedicated to paraphrasing nouncompounds usually rely on corpus co-occurrences of the compound's constituents as a source of explicit relation paraphrases (e.g..", "labels": [], "entities": []}, {"text": "Such methods are unable to generalize for unseen noun-compounds.", "labels": [], "entities": []}, {"text": "Yet, most noun-compounds are very infrequent in text, and humans easily interpret the meaning of anew noun-compound by generalizing existing knowledge.", "labels": [], "entities": []}, {"text": "For example, consider interpreting parsley cake as a cake made of parsley vs. resignation cake as a cake eaten to celebrate quitting an unpleasant job.", "labels": [], "entities": []}, {"text": "We follow the paraphrasing approach and propose a semi-supervised model for paraphrasing noun-compounds.", "labels": [], "entities": []}, {"text": "Differently from previous methods, we train the model to predict either a paraphrase expressing the semantic relation of a noun-compound (predicting '[w 2 ] made of [w 1 ]' given 'apple cake'), or a missing constituent given a combination of paraphrase and noun-compound (predicting 'apple' given 'cake made of [w 1 ]').", "labels": [], "entities": []}, {"text": "Constituents and paraphrase templates are represented as continuous vectors, and semantically-similar paraphrase templates are embedded in proximity, enabling better generalization.", "labels": [], "entities": []}, {"text": "Interpreting 'parsley cake' effectively reduces to identifying paraphrase templates whose \"selectional preferences\" () on each constituent fit 'parsley A qualitative analysis of the model shows that the top ranked paraphrases retrieved for each noun-compound are plausible even when the constituents never co-occur (Section 4).", "labels": [], "entities": []}, {"text": "We evaluate our model on both the paraphrasing and the classification tasks (Section 5).", "labels": [], "entities": []}, {"text": "On both tasks, the model's ability to generalize leads to improved performance in challenging evaluation settings.", "labels": [], "entities": []}], "datasetContent": [{"text": "For quantitative evaluation we employ our model for two noun-compound interpretation tasks.", "labels": [], "entities": [{"text": "noun-compound interpretation", "start_pos": 56, "end_pos": 84, "type": "TASK", "confidence": 0.7158114314079285}]}, {"text": "The main evaluation is on retrieving and ranking paraphrases ( \u00a75.1).", "labels": [], "entities": []}, {"text": "For the sake of completeness, we also evaluate the model on classification to a fixed inventory of relations ( \u00a75.2), although it wasn't designed for this task.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results of the proposed method and the baselines on the SemEval 2013 task.", "labels": [], "entities": [{"text": "SemEval 2013 task", "start_pos": 66, "end_pos": 83, "type": "TASK", "confidence": 0.7133394479751587}]}, {"text": " Table 3: Categories of false positive and false neg- ative predictions along with their percentage.", "labels": [], "entities": []}, {"text": " Table 4: Classification results. For each dataset  split, the top part consists of baseline methods and  the bottom part of methods from this paper. The  best performance in each part appears in bold.", "labels": [], "entities": []}]}