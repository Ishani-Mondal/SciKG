{"title": [{"text": "Identifying Transferable Information Across Domains for Cross-domain Sentiment Classification", "labels": [], "entities": [{"text": "Identifying Transferable Information Across Domains", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.9154558300971984}, {"text": "Cross-domain Sentiment Classification", "start_pos": 56, "end_pos": 93, "type": "TASK", "confidence": 0.7834847966829935}]}], "abstractContent": [{"text": "Getting manually labeled data in each domain is always an expensive and a time consuming task.", "labels": [], "entities": []}, {"text": "Cross-domain sentiment analysis has emerged as a demanding concept where a labeled source domain facilitates a sentiment classifier for an unlabeled target domain.", "labels": [], "entities": [{"text": "Cross-domain sentiment analysis", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8299383123715719}]}, {"text": "However, polarity orientation (positive or negative) and the significance of a word to express an opinion often differ from one domain to another domain.", "labels": [], "entities": []}, {"text": "Owing to these differences, cross-domain sentiment classification is still a challenging task.", "labels": [], "entities": [{"text": "cross-domain sentiment classification", "start_pos": 28, "end_pos": 65, "type": "TASK", "confidence": 0.792768120765686}]}, {"text": "In this paper, we propose that words that do not change their polarity and significance represent the transfer-able (usable) information across domains for cross-domain sentiment classification.", "labels": [], "entities": [{"text": "cross-domain sentiment classification", "start_pos": 156, "end_pos": 193, "type": "TASK", "confidence": 0.8141775131225586}]}, {"text": "We present a novel approach based on \u03c7 2 test and cosine-similarity between context vector of words to identify polarity preserving significant words across domains.", "labels": [], "entities": []}, {"text": "Furthermore, we show that a weighted ensemble of the classifiers enhances the cross-domain classification performance.", "labels": [], "entities": [{"text": "cross-domain classification", "start_pos": 78, "end_pos": 105, "type": "TASK", "confidence": 0.6527457535266876}]}], "introductionContent": [{"text": "The choice of the words to express an opinion depends on the domain as users often use domainspecific words ().", "labels": [], "entities": []}, {"text": "For example, entertaining and boring are frequently used in the movie domain to express an opinion; however, finding these words in the electronics domain is rare.", "labels": [], "entities": []}, {"text": "Moreover, there are words which are likely to be used across domains in the same proportion, but may change their polarity orientation from one domain to another (.", "labels": [], "entities": []}, {"text": "For example, a word like unpredictable is positive in the movie domain (unpredictable plot), but negative in the automobile domain (unpredictable steering).", "labels": [], "entities": []}, {"text": "Such a polarity changing word should be assigned positive orientation in the movie domain and negative orientation in the automobile domain.", "labels": [], "entities": []}, {"text": "Due to these differences across domains, a supervised algorithm trained on a labeled source domain, does not generalize well on an unlabeled target domain and the cross-domain performance degrades.", "labels": [], "entities": []}, {"text": "Generally, supervised learning algorithms have to be re-trained from scratch on every new domain using the manually annotated review corpus ().", "labels": [], "entities": []}, {"text": "This is not practical as there are numerous domains and getting manually annotated data for every new domain is an expensive and time consuming task.", "labels": [], "entities": []}, {"text": "On the other hand, domain adaptation techniques work in contrast to traditional supervised techniques on the principle of transferring learned knowledge across domains).", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.8130898177623749}]}, {"text": "The existing transfer learning based domain adaptation algorithms for cross-domain classification have generally been proven useful in reducing the labeled data requirement, but they do not consider words like unpredictable that change polarity orientation across domains.", "labels": [], "entities": [{"text": "cross-domain classification", "start_pos": 70, "end_pos": 97, "type": "TASK", "confidence": 0.7363863885402679}]}, {"text": "Transfer (reuse) of changing polarity words affects the cross-domain performance negatively.", "labels": [], "entities": []}, {"text": "Therefore, one cannot use transfer learning as the proverbial hammer, rather one needs to gauge what to transfer from the source domain to the target domain.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.9098649024963379}]}, {"text": "In this paper, we propose that the words which are equally significant with a consistent polarity across domains represent the usable information for cross-domain sentiment analysis.", "labels": [], "entities": [{"text": "cross-domain sentiment analysis", "start_pos": 150, "end_pos": 181, "type": "TASK", "confidence": 0.7781869371732076}]}, {"text": "\u03c7 2 is a popularly used and reliable statistical test to identify significance and polarity of a word in an annotated corpus (.", "labels": [], "entities": []}, {"text": "However, for an unlabeled corpus no such statistical technique is applicable.", "labels": [], "entities": []}, {"text": "Therefore, identification of words which are significant with a consistent polarity across domains is a non-trivial task.", "labels": [], "entities": []}, {"text": "In this paper, we present a novel technique based on \u03c7 2 test and cosine-similarity between context vector of words to identify Significant Consistent Polarity (SCP) words across domains.", "labels": [], "entities": []}, {"text": "The major contribution of this research is as follows.", "labels": [], "entities": []}, {"text": "1. Extracting significant consistent polarity words across domains: A technique which exploits cosine-similarity between context vector of words and \u03c7 2 testis used to identify SCP words across labeled source and unlabeled target domains.", "labels": [], "entities": [{"text": "Extracting significant consistent polarity words", "start_pos": 3, "end_pos": 51, "type": "TASK", "confidence": 0.8224612474441528}, {"text": "SCP words", "start_pos": 177, "end_pos": 186, "type": "TASK", "confidence": 0.8589814603328705}]}, {"text": "2. An ensemble-based adaptation algorithm: A classifier (C s ) trained on SCP words in the labeled source domain acts as a seed to initiate a classifier (C t ) on the target specific features.", "labels": [], "entities": []}, {"text": "These classifiers are then combined in a weighted ensemble to further enhance the cross-domain classification performance.", "labels": [], "entities": [{"text": "cross-domain classification", "start_pos": 82, "end_pos": 109, "type": "TASK", "confidence": 0.6336971521377563}]}, {"text": "Our results show that our approach gives a statistically significant improvement over Structured Correspondence Learning (SCL) and common unigrams in identification of transferable words, which eventually facilitates a more accurate sentiment classifier in the target domain.", "labels": [], "entities": [{"text": "identification of transferable words", "start_pos": 150, "end_pos": 186, "type": "TASK", "confidence": 0.8663113862276077}, {"text": "sentiment classifier", "start_pos": 233, "end_pos": 253, "type": "TASK", "confidence": 0.7425298988819122}]}, {"text": "The road-map for rest of the paper is as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the related work.", "labels": [], "entities": []}, {"text": "Section 3 describes the extraction of the SCP and the ensemble-based adaptation algorithm.", "labels": [], "entities": []}, {"text": "Section 4 elaborates the dataset and the experimental protocol.", "labels": [], "entities": []}, {"text": "Section 5 presents the results and section 6 reports the error analysis.", "labels": [], "entities": [{"text": "error analysis", "start_pos": 57, "end_pos": 71, "type": "METRIC", "confidence": 0.9600525200366974}]}, {"text": "Section 7 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this paper, we show comparison between SCPbased domain adaptation (our approach) and SCLbased domain adaptation approach proposed by using four domains, viz., Electronics (E), Kitchen (K), Books (B), and DVD.", "labels": [], "entities": [{"text": "SCPbased domain adaptation", "start_pos": 42, "end_pos": 68, "type": "TASK", "confidence": 0.7669752836227417}, {"text": "SCLbased domain adaptation", "start_pos": 88, "end_pos": 114, "type": "TASK", "confidence": 0.6572989821434021}]}, {"text": "We use SVM algorithm with linear kernel) to train a classifier in all the mentioned classification systems in the paper.", "labels": [], "entities": []}, {"text": "To implement SVM algorithm, we have used the publicly available Python based Scikit-learn package).", "labels": [], "entities": []}, {"text": "12 Data in each domain is divided into three parts, viz., train (60%), validation (20%) and test (20%).", "labels": [], "entities": []}, {"text": "The SCP words are extracted from the training data.", "labels": [], "entities": []}, {"text": "The weights W Sand W t for the source and target classifiers are essentially accuracies obtained by C sand Ct respectively on validation dataset from the target domain.", "labels": [], "entities": []}, {"text": "We report the accuracy for all the systems on the test data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9996765851974487}]}, {"text": "shows the statistics of the dataset.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Cosine-similarity scores with PosPivot  (great) and NegPivot (poor), and inferred polarity  orientation of the words.", "labels": [], "entities": []}, {"text": " Table 4: Classification accuracy in % given by C s ,  C t and WSM with different feature sets for elec- tronics as source and movie as target.", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.795973002910614}, {"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9657073020935059}, {"text": "WSM", "start_pos": 63, "end_pos": 66, "type": "METRIC", "confidence": 0.9718545079231262}]}, {"text": " Table 5: Cross-domain sentiment classification accuracy in the target domain (Source (S) \u2192 Target (T)).", "labels": [], "entities": [{"text": "Cross-domain sentiment classification", "start_pos": 10, "end_pos": 47, "type": "TASK", "confidence": 0.8028859694798788}, {"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9597851634025574}]}, {"text": " Table 6: In-domain sentiment classification accu- racy using significant words and unigrams.", "labels": [], "entities": [{"text": "In-domain sentiment classification accu- racy", "start_pos": 10, "end_pos": 55, "type": "TASK", "confidence": 0.7863879551490148}]}, {"text": " Table 7: t-test (\u03b1 = 0.05) results on the difference  in accuracy produced by various systems (cf. Ta- ble 5).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.9991402626037598}]}, {"text": " Table 8: Common unique words between the do- mains in percent (%).", "labels": [], "entities": []}]}