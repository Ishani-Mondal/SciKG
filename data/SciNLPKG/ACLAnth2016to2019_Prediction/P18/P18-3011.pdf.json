{"title": [], "abstractContent": [{"text": "Automatic abstractive summary generation remains a significant open problem for natural language processing.", "labels": [], "entities": [{"text": "Automatic abstractive summary generation", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.6224801540374756}, {"text": "natural language processing", "start_pos": 80, "end_pos": 107, "type": "TASK", "confidence": 0.6452353298664093}]}, {"text": "In this work, we develop a novel pipeline for Semantic Abstractive Summarization (SAS).", "labels": [], "entities": [{"text": "Semantic Abstractive Summarization (SAS)", "start_pos": 46, "end_pos": 86, "type": "TASK", "confidence": 0.8276626169681549}]}, {"text": "SAS, as introduced by Liu et al.", "labels": [], "entities": [{"text": "SAS", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.6630913019180298}]}, {"text": "(2015) first generates an AMR graph of an input story, through which it extracts a summary graph and finally, creates summary sentences from this summary graph.", "labels": [], "entities": []}, {"text": "Compared to earlier approaches, we develop a more comprehensive method to generate the story AMR graph using state-of-the-art co-reference resolution and Meta Nodes.", "labels": [], "entities": []}, {"text": "Which we then use in a novel unsupervised algorithm based on how humans summarize apiece of text to extract the summary sub-graph.", "labels": [], "entities": []}, {"text": "Our algorithm outperforms the state of the art SAS method by 1.7% F1 score in node prediction.", "labels": [], "entities": [{"text": "SAS", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.9655805230140686}, {"text": "F1 score", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9795076251029968}, {"text": "node prediction", "start_pos": 78, "end_pos": 93, "type": "TASK", "confidence": 0.6830967515707016}]}, {"text": "Miguel Almeida and Andre Martins.", "labels": [], "entities": []}, {"text": "2013. Fast and robust compressive summarization with dual decomposition and multi-task learning.", "labels": [], "entities": [{"text": "summarization", "start_pos": 34, "end_pos": 47, "type": "TASK", "confidence": 0.8004374504089355}]}, {"text": "2013. Abstract meaning representation for sembanking.", "labels": [], "entities": [{"text": "Abstract meaning representation", "start_pos": 6, "end_pos": 37, "type": "TASK", "confidence": 0.7951690355936686}]}, {"text": "Proceedings of Linguistic Annotation Workshop.", "labels": [], "entities": [{"text": "Linguistic Annotation Workshop", "start_pos": 15, "end_pos": 45, "type": "TASK", "confidence": 0.6023940443992615}]}], "introductionContent": [{"text": "Summarization of large texts is still an open problem in natural language processing.", "labels": [], "entities": [{"text": "Summarization of large texts", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.9113432019948959}]}, {"text": "Automatic summarization is often used in summarizing large texts like stories, journal papers, news articles and even larger texts like books and court judgments.", "labels": [], "entities": [{"text": "summarization", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.6402367949485779}, {"text": "summarizing large texts like stories, journal papers, news articles", "start_pos": 41, "end_pos": 108, "type": "TASK", "confidence": 0.80621845071966}]}, {"text": "Existing methods for summarization can be broadly categorized into two categories Extractive and Abstractive.", "labels": [], "entities": [{"text": "summarization", "start_pos": 21, "end_pos": 34, "type": "TASK", "confidence": 0.992659866809845}]}, {"text": "Most of the work done on summarization in the past has been Extractive.", "labels": [], "entities": [{"text": "summarization", "start_pos": 25, "end_pos": 38, "type": "TASK", "confidence": 0.9946038126945496}]}, {"text": "Extractive methods directly pickup words and sentences from the text to generate a summary.", "labels": [], "entities": []}, {"text": "transformed the input to nodes, then used '@cse.iitk.ac.in, \"@microsoft.com, Shibhansh is the corresponding author the Pagerank algorithm to score nodes, and finally grow the nodes from high-value to low-value using some heuristics.", "labels": [], "entities": []}, {"text": "Some of the approaches combine this with sentence compression so that more sentences can be packed in the summary.,,, and among others used ILPs and approximations for encoding compression and extraction.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 41, "end_pos": 61, "type": "TASK", "confidence": 0.7222990095615387}, {"text": "encoding compression and extraction", "start_pos": 168, "end_pos": 203, "type": "TASK", "confidence": 0.8276794254779816}]}, {"text": "However, human level summary generation require rephrasing sentences and combining information from different parts of the text.", "labels": [], "entities": [{"text": "human level summary generation", "start_pos": 9, "end_pos": 39, "type": "TASK", "confidence": 0.6465373635292053}]}, {"text": "Thus, these methods are inherently limited in the sense that they can never generate human level summaries for large and complicated documents.", "labels": [], "entities": []}, {"text": "On the other hand, most Abstractive methods take advantages of the recent developments in deep learning.", "labels": [], "entities": []}, {"text": "Specifically, the recent success of the sequence to sequence learning models, where recurrent networks read the text; encodes it and then generate target text produce promising results.,,, used standard encoder-decoder models along with their variants to generate summaries.", "labels": [], "entities": []}, {"text": "incorporated the AMR information in the standard encoder-decoder models to improve results.", "labels": [], "entities": [{"text": "AMR information", "start_pos": 17, "end_pos": 32, "type": "DATASET", "confidence": 0.7135089337825775}]}, {"text": "These approaches have produced promising results and have been recently shown to be competitive with the extractive methods, but they are still far from reaching human level quality in summary generation.", "labels": [], "entities": [{"text": "summary generation", "start_pos": 185, "end_pos": 203, "type": "TASK", "confidence": 0.7863823771476746}]}, {"text": "One of the significant problems with these methods is that there is no guarantee that they can handle subtleties of language like the presence of a word that negates the meaning of the full text, hard to capture co-references, etc.", "labels": [], "entities": []}, {"text": "introduced AMR as abase for work on statistical natural language understanding and generation.", "labels": [], "entities": [{"text": "AMR", "start_pos": 11, "end_pos": 14, "type": "DATASET", "confidence": 0.7696545124053955}, {"text": "statistical natural language understanding and generation", "start_pos": 36, "end_pos": 93, "type": "TASK", "confidence": 0.7505501608053843}]}, {"text": "AMR tries to cap-ture \"who is doing what to whom\" in a sentence.", "labels": [], "entities": [{"text": "AMR", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8045197129249573}]}, {"text": "An AMR represents the meaning of a sentence using rooted, acyclic, labeled, directed graphs.", "labels": [], "entities": []}, {"text": "shows the AMR graph of the sentence \"I looked carefully all around me\" generated by the JAMR parser.", "labels": [], "entities": [{"text": "JAMR", "start_pos": 88, "end_pos": 92, "type": "DATASET", "confidence": 0.8066692352294922}]}, {"text": "The nodes in the AMR are labeled with concepts, in 'around' represents one such concept.", "labels": [], "entities": []}, {"text": "Edges contain the information regarding the semantic relation between the concepts.", "labels": [], "entities": []}, {"text": "In direction is the relation between the concepts look-01 and around.", "labels": [], "entities": []}, {"text": "AMR relies on Propbank for semantic relations (edge labels).", "labels": [], "entities": [{"text": "AMR", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.5253883600234985}, {"text": "Propbank", "start_pos": 14, "end_pos": 22, "type": "DATASET", "confidence": 0.9236933588981628}]}, {"text": "Concepts can also be of the form run-01 where the index 01 represents the first sense of the word run.", "labels": [], "entities": []}, {"text": "Further details about the AMR can be found in the AMR guidelines.", "labels": [], "entities": [{"text": "AMR", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.4871543049812317}, {"text": "AMR", "start_pos": 50, "end_pos": 53, "type": "DATASET", "confidence": 0.8960011005401611}]}, {"text": "started the work on summarization using AMR, which we call Semantic Abstractive Summarization (SAS).", "labels": [], "entities": [{"text": "summarization", "start_pos": 20, "end_pos": 33, "type": "TASK", "confidence": 0.988610565662384}, {"text": "Semantic Abstractive Summarization (SAS)", "start_pos": 59, "end_pos": 99, "type": "TASK", "confidence": 0.771736611922582}]}, {"text": "introduced the fundamental idea behind SAS.", "labels": [], "entities": [{"text": "SAS", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.9820666313171387}]}, {"text": "In SAS the final summary is produced by extracting a summary subgraph from the story graph and generating the summary from this extracted graph (See.", "labels": [], "entities": [{"text": "SAS", "start_pos": 3, "end_pos": 6, "type": "TASK", "confidence": 0.9693407416343689}]}, {"text": "But the work was limited to obtaining the summary graph due to the absence of AMR to text generators at that time.", "labels": [], "entities": [{"text": "AMR", "start_pos": 78, "end_pos": 81, "type": "DATASET", "confidence": 0.6639426946640015}]}, {"text": "They used various graphical features like distance from the root, the number of outgoing edges, etc. and sentence number as features for nodes.", "labels": [], "entities": []}, {"text": "The procedure then learned weights over these features with the constraint that the nodes must form a connected graph.", "labels": [], "entities": []}, {"text": "In this work, we propose an alternative method to use AMRs for abstractive summarization.", "labels": [], "entities": [{"text": "abstractive summarization", "start_pos": 63, "end_pos": 88, "type": "TASK", "confidence": 0.6891514360904694}]}, {"text": "Our approach is inspired by the way humans summarize any piece of text.", "labels": [], "entities": [{"text": "summarize any piece of text", "start_pos": 43, "end_pos": 70, "type": "TASK", "confidence": 0.8061811566352844}]}, {"text": "User studies; have shown that humans summarize by first writing down the key phrases and then try to figure out the relationships among them and then organize the data accordingly.", "labels": [], "entities": [{"text": "summarize", "start_pos": 37, "end_pos": 46, "type": "TASK", "confidence": 0.9634186029434204}]}, {"text": "used similar ideas to propose the task of concept map based summarization.", "labels": [], "entities": []}, {"text": "We design our algorithm along the same lines.", "labels": [], "entities": []}, {"text": "The first step is to find the most important entities/events in the text.", "labels": [], "entities": []}, {"text": "The second step is to identify the key relations among the most important entities/events, and finally, in the last step, we capture information around the selected relation.", "labels": [], "entities": []}, {"text": "AMRs provide a natural way to achieve this process, as all the events/entities can be represented by anode or a group of nodes, while any relation can be captured by a path in the AMR graph.", "labels": [], "entities": []}, {"text": "We also develop a more comprehensive method to generate the story AMR from the sentence AMRs based on event/entity co-reference resolution and Meta Nodes.", "labels": [], "entities": [{"text": "event/entity co-reference resolution", "start_pos": 102, "end_pos": 138, "type": "TASK", "confidence": 0.6121332287788391}]}, {"text": "Our algorithm outperforms the previous state of the art methods for SAS by 1.7% F1 score on Node prediction.", "labels": [], "entities": [{"text": "SAS", "start_pos": 68, "end_pos": 71, "type": "TASK", "confidence": 0.982083797454834}, {"text": "F1", "start_pos": 80, "end_pos": 82, "type": "METRIC", "confidence": 0.9997908473014832}, {"text": "Node prediction", "start_pos": 92, "end_pos": 107, "type": "TASK", "confidence": 0.8716691136360168}]}, {"text": "Our major contributions in this work are : \u2022 We propose a novel unsupervised algorithm for the key step of summary graph extraction, which provides a stronger baseline for future work on SAS.", "labels": [], "entities": [{"text": "summary graph extraction", "start_pos": 107, "end_pos": 131, "type": "TASK", "confidence": 0.7878557840983073}, {"text": "SAS", "start_pos": 187, "end_pos": 190, "type": "TASK", "confidence": 0.9730994701385498}]}, {"text": "\u2022 We propose a novel method to generate the story AMR based on a more comprehensive co-reference resolution and Meta Nodes.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 and 3 contain description of the datasets and the algorithm used for summary generation respectively.", "labels": [], "entities": [{"text": "summary generation", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.897591769695282}]}, {"text": "Section 4 contains the results of experiments using our approach.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the proxy report section of the AMR Bank, as it is the only section that is relevant for the task because it contains the gold-standard (human-generated) AMR graphs for news articles and their summaries.", "labels": [], "entities": [{"text": "AMR Bank", "start_pos": 39, "end_pos": 47, "type": "DATASET", "confidence": 0.9359900951385498}]}, {"text": "In the training set, the stories and summaries contain 17.5 sentences and 1.5 sentences on average respectively.", "labels": [], "entities": []}, {"text": "The training and test sets include 298 and 33 summary document pairs respectively.", "labels": [], "entities": []}, {"text": "In table 2 we report results on the test set of the proxy report section of the AMR bank.", "labels": [], "entities": [{"text": "AMR bank", "start_pos": 80, "end_pos": 88, "type": "DATASET", "confidence": 0.8955689668655396}]}, {"text": "The table contains results using the human annotated AMRs.", "labels": [], "entities": []}, {"text": "We outperform the state-of-the-art in SAS by 1.7% F1 scores in node prediction.", "labels": [], "entities": [{"text": "SAS", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.9095007181167603}, {"text": "F1", "start_pos": 50, "end_pos": 52, "type": "METRIC", "confidence": 0.9995588660240173}, {"text": "node prediction", "start_pos": 63, "end_pos": 78, "type": "TASK", "confidence": 0.6686866730451584}]}, {"text": "Similar to previous methods we use the target summary size to control the length of the output summary.", "labels": [], "entities": []}, {"text": "To evaluate the effectiveness of the method till the summary graph extraction step, we compare the generated summary graph with the goldstandard target summary graph.", "labels": [], "entities": [{"text": "summary graph extraction", "start_pos": 53, "end_pos": 77, "type": "TASK", "confidence": 0.7530568639437357}]}, {"text": "We report Recall, Precision, and F1 for graph nodes.", "labels": [], "entities": [{"text": "Recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9972442388534546}, {"text": "Precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9976620674133301}, {"text": "F1", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.9996391534805298}]}, {"text": "Finally, to evaluate the effectiveness of the pipeline, we evaluate the performance using ROUGE, and we report ROUGE-1, ROUGE-2, and ROUGE-L.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 90, "end_pos": 95, "type": "METRIC", "confidence": 0.9685412049293518}, {"text": "ROUGE-1", "start_pos": 111, "end_pos": 118, "type": "METRIC", "confidence": 0.9651101231575012}, {"text": "ROUGE-2", "start_pos": 120, "end_pos": 127, "type": "METRIC", "confidence": 0.8722190856933594}, {"text": "ROUGE-L", "start_pos": 133, "end_pos": 140, "type": "METRIC", "confidence": 0.888407826423645}]}], "tableCaptions": [{"text": " Table 2: Results on the Proxy report section of the AMR bank. First-half contains the Recall, Precision,  and F-1 for the nodes in the generated summary AMR. The second half contains the scores for the final  summary generated using state-of-the-art text generator evaluated using the ROUGE metric", "labels": [], "entities": [{"text": "AMR bank", "start_pos": 53, "end_pos": 61, "type": "DATASET", "confidence": 0.7370671033859253}, {"text": "Recall", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.9976206421852112}, {"text": "Precision", "start_pos": 95, "end_pos": 104, "type": "METRIC", "confidence": 0.9746554493904114}, {"text": "F-1", "start_pos": 111, "end_pos": 114, "type": "METRIC", "confidence": 0.9889926314353943}, {"text": "AMR", "start_pos": 154, "end_pos": 157, "type": "DATASET", "confidence": 0.8622429370880127}]}]}