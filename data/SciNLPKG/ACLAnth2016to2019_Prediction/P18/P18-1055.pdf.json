{"title": [{"text": "Constraining MGbank: Agreement, L-Selection and Supertagging in Minimalist Grammars", "labels": [], "entities": [{"text": "MGbank", "start_pos": 13, "end_pos": 19, "type": "DATASET", "confidence": 0.9706173539161682}]}], "abstractContent": [{"text": "This paper reports on two strategies that have been implemented for improving the efficiency and precision of wide-coverage Minimalist Grammar (MG) parsing.", "labels": [], "entities": [{"text": "precision", "start_pos": 97, "end_pos": 106, "type": "METRIC", "confidence": 0.9991356730461121}, {"text": "wide-coverage Minimalist Grammar (MG) parsing", "start_pos": 110, "end_pos": 155, "type": "TASK", "confidence": 0.6689489015511104}]}, {"text": "The first extends the formalism presented in Torr and Stabler (2016) with a mechanism for enforcing fine-grained selectional restrictions and agreements.", "labels": [], "entities": []}, {"text": "The second is a method for factoring computation-ally costly null heads out from bottom-up MG parsing; this has the additional benefit of rendering the formalism fully compatible for the first time with highly efficient Markovian supertaggers.", "labels": [], "entities": [{"text": "MG parsing", "start_pos": 91, "end_pos": 101, "type": "TASK", "confidence": 0.7822524905204773}]}, {"text": "These techniques aided in the task of generating MG-bank, the first wide-coverage corpus of Minimalist Grammar derivation trees.", "labels": [], "entities": [{"text": "MG-bank", "start_pos": 49, "end_pos": 56, "type": "DATASET", "confidence": 0.8698015809059143}, {"text": "Minimalist Grammar derivation trees", "start_pos": 92, "end_pos": 127, "type": "TASK", "confidence": 0.6570452600717545}]}], "introductionContent": [{"text": "Parsers based on deep grammatical formalisms, such as CCG () and HPSG, exhibit superior performance on certain semantically crucial (unbounded) dependency types when compared to those with relatively shallow context free grammars (in the spirit of and) or, in the case of modern dependency parsers (,), no explicit formal grammar at all (,).", "labels": [], "entities": []}, {"text": "As parsing technology advances, the importance of correctly analysing these more complex construction types will also inevitably increase, making research into deep parsing technology an important goal within NLP.", "labels": [], "entities": [{"text": "parsing", "start_pos": 3, "end_pos": 10, "type": "TASK", "confidence": 0.9785913228988647}]}, {"text": "One deep grammatical framework that has not so far been applied to NLP tasks is the Minimalist Grammar (MG) formalism.", "labels": [], "entities": []}, {"text": "Linguistically, MG is a computationally-oriented formalization of many aspects of Chomsky's (1995) Minimalist Program, arguably still the dominant framework in theoretical syntax, but so far conspicuously absent from NLP conferences.", "labels": [], "entities": []}, {"text": "Part of the reason for this has been that until now no Minimalist treebank existed on which to train efficient statistical Minimalist parsers.", "labels": [], "entities": [{"text": "Minimalist treebank", "start_pos": 55, "end_pos": 74, "type": "DATASET", "confidence": 0.8119291365146637}]}, {"text": "The Autobank (Torr, 2017) system was designed to address this issue.", "labels": [], "entities": [{"text": "Autobank (Torr, 2017) system", "start_pos": 4, "end_pos": 32, "type": "DATASET", "confidence": 0.941962548664638}]}, {"text": "It provides a GUI for creating a wide-coverage MG together with a module for automatically generating MG trees for the sentences of the Wall Street Journal section of the Penn Treebank (PTB), which it does using an exhaustive bottom-up MG chart parser . This system has been used to create MGbank, the first wide coverage (precisionoriented) Minimalist Grammar and MG treebank of English, which consists of 1078 hand-crafted MG lexical categories (355 of which are phonetically null) and currently covers approximately half of the WSJ PTB sentences.", "labels": [], "entities": [{"text": "Wall Street Journal section of the Penn Treebank (PTB)", "start_pos": 136, "end_pos": 190, "type": "DATASET", "confidence": 0.9184307889504866}, {"text": "WSJ PTB sentences", "start_pos": 531, "end_pos": 548, "type": "DATASET", "confidence": 0.9555152257283529}]}, {"text": "A problem which arose during its construction was that without any statistical model to constrain the derivation, MG parsing had to be exhaustive, and this presented some significant efficiency challenges once the grammar grew beyond a certain size 2 , mainly because of the problem of identifying the location and category of phonetically silent heads (equivalent to type-changing unary rules) allowed by the theory.", "labels": [], "entities": [{"text": "MG parsing", "start_pos": 114, "end_pos": 124, "type": "TASK", "confidence": 0.9126377701759338}]}, {"text": "This problem was particularly acute for the MGbank grammar, which makes extensive use of such heads to multiply out the lexicon during pars-ing.", "labels": [], "entities": [{"text": "MGbank grammar", "start_pos": 44, "end_pos": 58, "type": "DATASET", "confidence": 0.9720523059368134}]}, {"text": "This approach reduces the amount of time needed for manual annotation, and also enables the parser to better generalise to unseen constructions, but it can quickly lead to an explosion in the search space if left unconstrained.", "labels": [], "entities": []}, {"text": "This paper provides details on two strategies that were developed for constraining the hypothesis space for wide-coverage MG parsing.", "labels": [], "entities": [{"text": "MG parsing", "start_pos": 122, "end_pos": 132, "type": "TASK", "confidence": 0.7373150289058685}]}, {"text": "The first of these is an implementation of the sorts of selectional restrictions 3 standardly used by other formalisms, which allow ahead to specify certain fine-grained properties about its arguments.", "labels": [], "entities": []}, {"text": "refers to this type of finegrained selection as l(exical)-selection, in contrast to coarser-grained c(ategory)-selection and semantic s-selection.", "labels": [], "entities": []}, {"text": "The same system is also used hereto enforce morphosyntactic agreements, such as subject-verb agreement and case 'assignment'.", "labels": [], "entities": []}, {"text": "It is simpler and flatter than the structured feature value matrices one finds in formalisms such as HPSG and LFG, which arguably makes it less linguistically plausible.", "labels": [], "entities": [{"text": "HPSG", "start_pos": 101, "end_pos": 105, "type": "DATASET", "confidence": 0.8972805738449097}]}, {"text": "However, it is also considerably easier to read and to annotate, which greatly facilitated the manual treebanking task.", "labels": [], "entities": []}, {"text": "The second technique to be presented is a method for extracting a set of complex overt categories from a corpus of MG derivation trees which has the dual effect of factoring computationally costly null heads out from parsing (but not from the resulting parse trees) and rendering MGs fully compatible for the first time with existing supertagging techniques.", "labels": [], "entities": []}, {"text": "Supertagging was originally introduced in for the Lexicalised Tree Adjoining Grammar (LTAG) formalism (, and involves applying Markovian part-of-speech tagging techniques to strongly lexicalised tag sets that are much larger and richer than the 45 tags used by the PTB.", "labels": [], "entities": [{"text": "Lexicalised Tree Adjoining Grammar (LTAG) formalism", "start_pos": 50, "end_pos": 101, "type": "TASK", "confidence": 0.6796097047626972}, {"text": "PTB", "start_pos": 265, "end_pos": 268, "type": "DATASET", "confidence": 0.9769495725631714}]}, {"text": "Because each supertag contains a great deal of information about the syntactic environment of the word it labels, such as its subcategorization frame, supertagging is sometimes referred to as 'almost parsing'.", "labels": [], "entities": []}, {"text": "It has proven highly effective at making CCG) parsing in particular efficient enough to support largescale NLP tasks, making it desirable to apply this technique to MGs.", "labels": [], "entities": [{"text": "CCG) parsing", "start_pos": 41, "end_pos": 53, "type": "TASK", "confidence": 0.5405676960945129}]}, {"text": "However, existing supertaggers can only tag what they can see, presenting a problem for MGs, which include phonetically unpronounced heads.", "labels": [], "entities": []}, {"text": "Our extraction algorithm addresses this by anchoring null heads to overt ones within complex LTAG-like supertag categories.", "labels": [], "entities": []}, {"text": "The paper is arranged as follows: section 2 gives an informal overview of MGs; section 3 introduces the selectional mechanisms and shows how these are used in MGbank to enforce case 'assignment' (3.1), l-selection (3.2) and subjectverb agreement (3.3); section 4 presents the algorithm for extracting supertags from a corpus of MG derivation trees (4.1), gives details of how a standard CKY MG parser can straightforwardly be adapted to make use of these complex tags (4.2), and presents some preliminary supertagging results (4.3) and a discussion of these (4.4); section 5 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Accuracies on different MG (super)tag types showing", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9973516464233398}]}]}