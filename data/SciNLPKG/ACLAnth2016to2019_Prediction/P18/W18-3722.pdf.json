{"title": [{"text": "Learning to Automatically Generate Fill-In-The-Blank Quizzes", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we formalize the problem automatic fill-in-the-blank question generation using two standard NLP machine learning schemes, proposing concrete deep learning models for each.", "labels": [], "entities": [{"text": "fill-in-the-blank question generation", "start_pos": 49, "end_pos": 86, "type": "TASK", "confidence": 0.6655057867368063}]}, {"text": "We present an empirical study based on data obtained from a language learning platform showing that both of our proposed settings offer promising results.", "labels": [], "entities": []}], "introductionContent": [{"text": "With the advent of the Web 2.0, regular users were able to share, remix and distribute content very easily.", "labels": [], "entities": []}, {"text": "As a result of this process, the Web became a rich interconnected set of heterogeneous data sources.", "labels": [], "entities": []}, {"text": "Being in a standard format, it is suitable for many tasks involving knowledge extraction and representation.", "labels": [], "entities": [{"text": "knowledge extraction and representation", "start_pos": 68, "end_pos": 107, "type": "TASK", "confidence": 0.6922519505023956}]}, {"text": "For example, efforts have been made to design games with the purpose of semi-automating a wide range of knowledge transfer tasks, such as educational quizzes, by leveraging on this kind of data.", "labels": [], "entities": [{"text": "knowledge transfer tasks", "start_pos": 104, "end_pos": 128, "type": "TASK", "confidence": 0.7986837228139242}]}, {"text": "In particular, quizzes based on multiple choice questions (MCQs) have been proved efficient to judge students knowledge.", "labels": [], "entities": []}, {"text": "However, manual construction of such questions often results a timeconsuming and labor-intensive task.", "labels": [], "entities": []}, {"text": "Fill-in-the-blank questions, where a sentence is given with one or more blanks in it, either with or without alternatives to fill in those blanks, have gained research attention recently.", "labels": [], "entities": []}, {"text": "In this kind of question, as opposed to MCQs, there is no need to generate a WH style question derived from text.", "labels": [], "entities": []}, {"text": "This means that the target sentence could simply be picked from a document on a corresponding topic of interest which results easier to automate.", "labels": [], "entities": []}, {"text": "Fill-in-the-blank questions in its multiplechoice answer version, often referred to as cloze questions (CQ), are commonly used for evaluating proficiency of language learners, including official tests such as TOEIC and TOEFL ().", "labels": [], "entities": [{"text": "TOEIC", "start_pos": 209, "end_pos": 214, "type": "DATASET", "confidence": 0.6732114553451538}, {"text": "TOEFL", "start_pos": 219, "end_pos": 224, "type": "DATASET", "confidence": 0.5257437825202942}]}, {"text": "They have also been used to test students knowledge of English in using the correct verbs () and adjectives (. and generated questions to evaluate students vocabulary.", "labels": [], "entities": []}, {"text": "The main problem in CQ generation is that it is generally not easy to come up with appropriate distractors -incorrect options-without rich experience.", "labels": [], "entities": [{"text": "CQ generation", "start_pos": 20, "end_pos": 33, "type": "TASK", "confidence": 0.9336059391498566}]}, {"text": "Existing approaches are mostly based on domain-specific templates, whose elaboration relies on experts.", "labels": [], "entities": []}, {"text": "Lately, approaches based on discriminative methods, which rely on annotated training data, have also appeared.", "labels": [], "entities": []}, {"text": "Ultimately, these settings prevent end-users from participating in the elaboration process, limiting the diversity and variation of quizzes that the system may offer.", "labels": [], "entities": []}, {"text": "In this work we formalize the problem of automatic fill-in-the-blank question generation and present an empirical study using deep learning models for it in the context of language learning.", "labels": [], "entities": [{"text": "automatic fill-in-the-blank question generation", "start_pos": 41, "end_pos": 88, "type": "TASK", "confidence": 0.5922595784068108}]}, {"text": "Our study is based on data obtained from our language learning platform (Nakajima and Tomimatsu, 2013; Ono and Nakajima; where users can create their own quizzes by utilizing freely available and open-licensed video content on the Web.", "labels": [], "entities": []}, {"text": "In the platform, the automatic quiz creation currently relies on hand-crafted features and rules, making the process difficult to adapt.", "labels": [], "entities": [{"text": "quiz creation", "start_pos": 31, "end_pos": 44, "type": "TASK", "confidence": 0.7735661268234253}]}, {"text": "Our goal is to effectively provide an adaptive learning experience in terms of style and difficulty, and thus better serve users' needs (.", "labels": [], "entities": []}, {"text": "In this context, we study the ability of our proposed architectures in learning to generate quizzes based on data derived of the interaction of users with the platform.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1 summarizes our obtained  results.", "labels": [], "entities": []}, {"text": " Table 2: Results of the seq. classification ap- proach.", "labels": [], "entities": [{"text": "seq. classification ap- proach", "start_pos": 25, "end_pos": 55, "type": "DATASET", "confidence": 0.5943441390991211}]}]}