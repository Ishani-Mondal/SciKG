{"title": [{"text": "Economic Event Detection in Company-Specific News Text", "labels": [], "entities": [{"text": "Economic Event Detection", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6819405953089396}]}], "abstractContent": [{"text": "This paper presents a dataset and supervised classification approach for economic event detection in English news articles.", "labels": [], "entities": [{"text": "economic event detection", "start_pos": 73, "end_pos": 97, "type": "TASK", "confidence": 0.6559066474437714}]}, {"text": "Currently, the economic domain is lacking resources and methods for data-driven supervised event detection.", "labels": [], "entities": [{"text": "data-driven supervised event detection", "start_pos": 68, "end_pos": 106, "type": "TASK", "confidence": 0.6945391744375229}]}, {"text": "The detection task is conceived as a sentence-level classification task for 10 different economic event types.", "labels": [], "entities": [{"text": "sentence-level classification task", "start_pos": 37, "end_pos": 71, "type": "TASK", "confidence": 0.7524880766868591}]}, {"text": "Two different machine learning approaches were tested: a rich feature set Support Vector Machine (SVM) setup and a word-vector-based long short-term memory recurrent neural network (RNN-LSTM) setup.", "labels": [], "entities": []}, {"text": "We show satisfactory results for most event types, with the linear kernel SVM outperforming the other experimental setups .", "labels": [], "entities": []}], "introductionContent": [{"text": "In the financial domain, the way companies are perceived by investors is influenced by the news published about those companies., for example, tried to characterize the relationship between the content of media reports and daily stock market activity, focusing on the immediate influence of the Wall Street Journal's 'Abreast of the Market' column on U.S. stock market returns.", "labels": [], "entities": [{"text": "Wall Street Journal's 'Abreast of the Market' column", "start_pos": 295, "end_pos": 347, "type": "DATASET", "confidence": 0.8718934492631392}]}, {"text": "One of his major findings was that high levels of media pessimism robustly predict downward pressure on market prices.", "labels": [], "entities": []}, {"text": "To provide some insights into the way markets react to new information about companies, financial economists have conducted event studies.", "labels": [], "entities": []}, {"text": "These event studies measure the impact of a specific event on the value of a firm).", "labels": [], "entities": []}, {"text": "They offer insight into the extent to which shareholders of acquired firms gain better returns during mergers, or examine the behavior of companies stock prices around events such as dividend announcements or stock splits.", "labels": [], "entities": [{"text": "dividend announcements or stock splits", "start_pos": 183, "end_pos": 221, "type": "TASK", "confidence": 0.6311457931995392}]}, {"text": "Studying the impact of specific events on the stock markets, however, is a labor-intensive process, starting with the identification of a given event, the estimation of abnormal returns to separate the general movement of stock returns from an individual stock return, followed by a number of statistical tests seeking evidence to support the event's economic significance.", "labels": [], "entities": []}, {"text": "Since identifying news published about certain events in an automatic way enables researchers in the field of event studies to process more data in less time, and can consequently lead to new insights into the correlation between events and stock market movements, automatic techniques have been proposed to detect economic events in text.", "labels": [], "entities": []}, {"text": "Most of the existing approaches to the detection of economic events, however, are knowledge-based and pattern-based ().", "labels": [], "entities": [{"text": "detection of economic events", "start_pos": 39, "end_pos": 67, "type": "TASK", "confidence": 0.8710007071495056}]}, {"text": "These use rule-sets or ontology knowledge-bases which are largely or fully created by hand.", "labels": [], "entities": []}, {"text": "The Stock Sonar project) notably uses domain experts to formulate event rules for rule-based stock sentiment analysis.", "labels": [], "entities": [{"text": "rule-based stock sentiment analysis", "start_pos": 82, "end_pos": 117, "type": "TASK", "confidence": 0.7055575847625732}]}, {"text": "This technology has been successfully used in assessing the impact of events on the stock market ( and in formulating trading strategies.", "labels": [], "entities": []}, {"text": "Other approaches conceptualize economic event detection as the extraction of event tuples or as semantic frame parsing (.", "labels": [], "entities": [{"text": "economic event detection", "start_pos": 31, "end_pos": 55, "type": "TASK", "confidence": 0.6289578477541605}, {"text": "semantic frame parsing", "start_pos": 96, "end_pos": 118, "type": "TASK", "confidence": 0.6602750718593597}]}, {"text": "A drawback of knowledge-based information extraction methods is that creating rules and ontologies is a difficult, time-consuming process.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 30, "end_pos": 52, "type": "TASK", "confidence": 0.7066747397184372}]}, {"text": "Furthermore, defining a set of strict rules often re-sults in low recall scores, since these rules usually cover only a portion of the many various ways in which certain information can be lexicalized.", "labels": [], "entities": [{"text": "recall", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.9978864789009094}]}, {"text": "Thus, the need for flexible data-driven approaches, which do not require predefined ontological resources, arises.", "labels": [], "entities": []}, {"text": "provide an example of successful datadriven, weakly-supervised distress event detection based on bank entity mentions.", "labels": [], "entities": [{"text": "weakly-supervised distress event detection", "start_pos": 45, "end_pos": 87, "type": "TASK", "confidence": 0.6994580328464508}]}, {"text": "Here, bank distress events are conceptualized as mentions of bank entities in a time-window and no typology classification is assigned.", "labels": [], "entities": []}, {"text": "We are not aware of any published data-driven, supervised event detection approaches for the economic domain.", "labels": [], "entities": [{"text": "event detection", "start_pos": 58, "end_pos": 73, "type": "TASK", "confidence": 0.7610011696815491}]}, {"text": "However, in general domain event extraction, as embodied by projects such as ACE) and ERE/TAC-KBP (, supervised methods for extraction of event structures are predominant because of their promise of improved performance.", "labels": [], "entities": [{"text": "domain event extraction", "start_pos": 20, "end_pos": 43, "type": "TASK", "confidence": 0.6381227274735769}, {"text": "ACE", "start_pos": 77, "end_pos": 80, "type": "DATASET", "confidence": 0.9355440139770508}]}, {"text": "As discussed in, the definition of events in the field of information extraction differs widely.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 58, "end_pos": 80, "type": "TASK", "confidence": 0.8542982339859009}]}, {"text": "In this work, we employ a conceptualization of economic event detection as 'retrieving textually reported real-world occurrences, actions, relations, and situations involving companies and firms'.", "labels": [], "entities": [{"text": "economic event detection", "start_pos": 47, "end_pos": 71, "type": "TASK", "confidence": 0.7001802325248718}]}, {"text": "Unlike other supervised data-driven 'event extraction' tasks such as in the ACE/ERE programs (), we do not conceptualize events as structured schemata/frames, but more limited as textual mentions of real-world occurrences.", "labels": [], "entities": [{"text": "event extraction'", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.8256339629491171}, {"text": "ACE/ERE", "start_pos": 76, "end_pos": 83, "type": "DATASET", "confidence": 0.8190222779909769}]}, {"text": "The task presented here is often also referred to as event 'mention', 'nugget', or 'trigger' detection.", "labels": [], "entities": [{"text": "trigger' detection", "start_pos": 84, "end_pos": 102, "type": "TASK", "confidence": 0.6991748412450155}]}, {"text": "The classification experiments described here are currently at the sentence-level, but our event annotation scheme is token-level.", "labels": [], "entities": []}, {"text": "In this paper, we tackle the task of economic event detection by means of a supervised machine learning approach, which we expect will be able to detect a wider variety of lexicalizations of economic events than pattern-based approaches.", "labels": [], "entities": [{"text": "economic event detection", "start_pos": 37, "end_pos": 61, "type": "TASK", "confidence": 0.6165776352087656}]}, {"text": "We consider economic event detection as a sentencelevel multi-label classification task.", "labels": [], "entities": [{"text": "economic event detection", "start_pos": 12, "end_pos": 36, "type": "TASK", "confidence": 0.6580439507961273}, {"text": "sentencelevel multi-label classification task", "start_pos": 42, "end_pos": 87, "type": "TASK", "confidence": 0.6840652897953987}]}, {"text": "The goal is to automatically assign the presence of a set of predetermined economic event categories in a sentence of a news article.", "labels": [], "entities": []}, {"text": "In previous work on the Dutch counterpart of this dataset, ( has shown that SVM classification obtained decent results.", "labels": [], "entities": [{"text": "SVM classification", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.918688029050827}]}, {"text": "Here, we compare two different machine learning approaches, viz.", "labels": [], "entities": []}, {"text": "a rich feature set Support Vector Machine (SVM) approach, and a word-vectorbased sequence long short-term memory recurrent neural network (RNN-LSTM) approach.", "labels": [], "entities": []}, {"text": "We show that supervised classification is a viable approach to extract economic events, with the linear kernel SVM obtaining the best classification performance.", "labels": [], "entities": [{"text": "supervised classification", "start_pos": 13, "end_pos": 38, "type": "TASK", "confidence": 0.7130279839038849}]}, {"text": "The remainder of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we present the annotated corpus of financial news articles we constructed.", "labels": [], "entities": []}, {"text": "Section 3 introduces our two classification approaches to economic event detection, followed by an overview of the results in Section 4.", "labels": [], "entities": [{"text": "economic event detection", "start_pos": 58, "end_pos": 82, "type": "TASK", "confidence": 0.6466419994831085}]}, {"text": "In Section 5, we conduct an error analysis to gain insights in the main shortcomings of the current approach.", "labels": [], "entities": []}, {"text": "Section 6 formulates some conclusions and ideas for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "For this study, the task of economic event detection is conceived as a sentence-level classification task.", "labels": [], "entities": [{"text": "economic event detection", "start_pos": 28, "end_pos": 52, "type": "TASK", "confidence": 0.6275638143221537}, {"text": "sentence-level classification task", "start_pos": 71, "end_pos": 105, "type": "TASK", "confidence": 0.7459972500801086}]}, {"text": "We decided on comparing two different machine learning approaches: an SVM approach requiring offline feature engineering, and a wordvector-based sequence RNN-LSTM approach.", "labels": [], "entities": []}, {"text": "The SVM approach incorporates a rich feature set with syntactic and lexical feature engineering.", "labels": [], "entities": []}, {"text": "We built one SVM classifier per event, predicting whether the event was present in the sentence or not, in effect recasting the problem as a one-vsrest binary classification task for each class.", "labels": [], "entities": []}, {"text": "The RNN-LSTM is tested both as a multi-label single model classifier and a one-vs-rest set-up.", "labels": [], "entities": [{"text": "RNN-LSTM", "start_pos": 4, "end_pos": 12, "type": "DATASET", "confidence": 0.7524598240852356}]}, {"text": "Performance estimation is done on a random hold-out test split (10%), whereas cross-validation experiments were carried out on the hold-in set (train set of 90%) for both hyper-parameter optimization and validation of generalization error.", "labels": [], "entities": [{"text": "hyper-parameter optimization", "start_pos": 171, "end_pos": 199, "type": "TASK", "confidence": 0.6702460646629333}]}, {"text": "Per event type, precision, recall, and F 1 -score are reported for each approach on the hold-out test set.", "labels": [], "entities": [{"text": "precision", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9998235106468201}, {"text": "recall", "start_pos": 27, "end_pos": 33, "type": "METRIC", "confidence": 0.9997691512107849}, {"text": "F 1 -score", "start_pos": 39, "end_pos": 49, "type": "METRIC", "confidence": 0.9875313341617584}]}, {"text": "We do not report accuracy because it is not an apt performance indicator in the case of class imbalance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9952312111854553}]}, {"text": "Cross-validation results on the training set are not reported due to space constraints, but followed the same trends as the reported test results with no indication of over-fitting.", "labels": [], "entities": []}, {"text": "We present per class results of the SVM one-vsrest approach in and for the RNN-LSTM in for multi-label and for one-vsrest.", "labels": [], "entities": []}, {"text": "Even though our classifiers were trained on a limited amount of data, we obtain satisfactory results for the detection of company-specific economic events for most event types.", "labels": [], "entities": []}, {"text": "Overall precision scores are promising, especially for the SVMbased approach and the RNN-LSTM with hold-in trained word vectors.", "labels": [], "entities": [{"text": "precision", "start_pos": 8, "end_pos": 17, "type": "METRIC", "confidence": 0.9985637068748474}]}, {"text": "The best overall results are obtained by the linear kernel SVM which obtained far better recall than any other model.", "labels": [], "entities": [{"text": "recall", "start_pos": 89, "end_pos": 95, "type": "METRIC", "confidence": 0.9993958473205566}]}, {"text": "The one-vs-rest RNN-LSTM systems comes in at a close second and outperforms its multi-label counterparts by a large margin.", "labels": [], "entities": []}, {"text": "Including lexical and syntactic features seems to be worthwhile when compared to the straight-forward word vector/token sequence approach used with the RNN-LSTM.", "labels": [], "entities": []}, {"text": "The best RNN-LSTM multi-label model is outperformed by the linear kernel SVM approach and is on par with the optimized RBF kernel approach.", "labels": [], "entities": []}, {"text": "The pre-trained GloVe vectors trained on our own dataset performed best out of the three input meth-ods with a prevalence-weighted macro-averaged F 1 -score of 0.66 on hold-out.", "labels": [], "entities": [{"text": "prevalence-weighted macro-averaged F 1 -score", "start_pos": 111, "end_pos": 156, "type": "METRIC", "confidence": 0.8581757843494415}]}, {"text": "The GloVe vectors trained on the 6B corpus obtain worse precision but slightly better recall, resulting in a comparable F 1 -score of 0.64.", "labels": [], "entities": [{"text": "6B corpus", "start_pos": 33, "end_pos": 42, "type": "DATASET", "confidence": 0.8981664180755615}, {"text": "precision", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.999559223651886}, {"text": "recall", "start_pos": 86, "end_pos": 92, "type": "METRIC", "confidence": 0.9994787573814392}, {"text": "F 1 -score", "start_pos": 120, "end_pos": 130, "type": "METRIC", "confidence": 0.9910537749528885}]}, {"text": "The 6B GloVe inputs obtain better scores on more classes, but their macroaveraged score is hurt by not detecting any of the Debt class instances.", "labels": [], "entities": []}, {"text": "Not feeding pre-trained embeddings to our network shows the worst performance of all classifiers (F 1 -score of 0.54).", "labels": [], "entities": [{"text": "F 1 -score", "start_pos": 98, "end_pos": 108, "type": "METRIC", "confidence": 0.9892186671495438}]}], "tableCaptions": [{"text": " Table 1: Event type distribution in the Sen- tiFM English economic dataset and sentence level  counts (as used in experiments).", "labels": [], "entities": [{"text": "Sen- tiFM English economic dataset", "start_pos": 41, "end_pos": 75, "type": "DATASET", "confidence": 0.8849960068861643}]}, {"text": " Table 3: Hold-out test precision, recall, and F 1 - scores per type for the linear and optimized RBF  kernels of the feature-engineered SVM one-vs-rest  approach. Boldface indicates best performance  within the SVM set-up. Underline indicates best  of all tested systems.", "labels": [], "entities": [{"text": "precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.5610843896865845}, {"text": "recall", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9992916584014893}, {"text": "F 1 -", "start_pos": 47, "end_pos": 52, "type": "METRIC", "confidence": 0.9939544002215067}]}, {"text": " Table 4: Hold-out test precision, recall, and F 1 - scores per type for RNN-LSTM for different word  vector input. Boldface indicates best perfor- mance within RNN-LSTM multi-label approach.  Underline indicates best of all systems.", "labels": [], "entities": [{"text": "precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.5288121700286865}, {"text": "recall", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9989365935325623}, {"text": "F 1 - scores", "start_pos": 47, "end_pos": 59, "type": "METRIC", "confidence": 0.9876728504896164}, {"text": "Underline", "start_pos": 193, "end_pos": 202, "type": "METRIC", "confidence": 0.956432580947876}]}, {"text": " Table 5: Hold-out test precision, recall, and F 1 - scores per type for the one-vs-rest RNN-LSTM  with 6B GloVe corpus word vectors. Underline  indicates best of all systems.", "labels": [], "entities": [{"text": "Hold-out test", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.8812804520130157}, {"text": "precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.638332188129425}, {"text": "recall", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9994152784347534}, {"text": "F 1 - scores", "start_pos": 47, "end_pos": 59, "type": "METRIC", "confidence": 0.9888375699520111}]}, {"text": " Table 6: Economic event type distribution in the  evaluation set.", "labels": [], "entities": []}]}