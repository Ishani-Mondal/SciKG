{"title": [{"text": "hyperdoc2vec: Distributed Representations of Hypertext Documents", "labels": [], "entities": [{"text": "Distributed Representations of Hypertext Documents", "start_pos": 14, "end_pos": 64, "type": "TASK", "confidence": 0.6686588168144226}]}], "abstractContent": [{"text": "Hypertext documents, such as web pages and academic papers, are of great importance in delivering information in our daily life.", "labels": [], "entities": []}, {"text": "Although being effective on plain documents, conventional text embedding methods suffer from information loss if directly adapted to hyper-documents.", "labels": [], "entities": []}, {"text": "In this paper, we propose a general embedding approach for hyper-documents, namely, hyperdoc2vec, along with four criteria characterizing necessary information that hyper-document embedding models should preserve.", "labels": [], "entities": []}, {"text": "Systematic comparisons are conducted between hyperdoc2vec and several competitors on two tasks, i.e., paper classification and citation recommendation , in the academic paper domain.", "labels": [], "entities": [{"text": "paper classification", "start_pos": 102, "end_pos": 122, "type": "TASK", "confidence": 0.725672036409378}, {"text": "citation recommendation", "start_pos": 127, "end_pos": 150, "type": "TASK", "confidence": 0.7440591156482697}]}, {"text": "Analyses and experiments both validate the superiority of hyperdoc2vec to other models w.r.t. the four criteria.", "labels": [], "entities": []}], "introductionContent": [{"text": "The ubiquitous World Wide Web has boosted research interests on hypertext documents, e.g., personal webpages (, Wikipedia pages (, as well as academic papers.", "labels": [], "entities": []}, {"text": "Unlike independent plain documents, a hypertext document (hyper-doc for short) links to another hyper-doc by a hyperlink or citation mark in its textual content.", "labels": [], "entities": []}, {"text": "Given this essential distinction, hyperlinks or citations are worth specific modeling in many tasks such as link-based classification (, web retrieval (), entity linking, and citation recommendation (.", "labels": [], "entities": [{"text": "link-based classification", "start_pos": 108, "end_pos": 133, "type": "TASK", "confidence": 0.678536131978035}, {"text": "entity linking", "start_pos": 155, "end_pos": 169, "type": "TASK", "confidence": 0.79838827252388}, {"text": "citation recommendation", "start_pos": 175, "end_pos": 198, "type": "TASK", "confidence": 0.8182211220264435}]}, {"text": "To model hypertext documents, various efforts have been made to depict networks of hyper-docs as well as their content.", "labels": [], "entities": []}, {"text": "Among potential techniques, distributed representation () tends to be promising since its validity and effectiveness are proven for plain documents on many natural language processing (NLP) tasks.", "labels": [], "entities": []}, {"text": "Conventional attempts on utilizing embedding techniques in hyper-doc-related tasks generally fall into two types.", "labels": [], "entities": []}, {"text": "The first type) simply downcasts hyper-docs to plain documents and feeds them into word2vec () (w2v for short) or doc2vec () (d2v for short).", "labels": [], "entities": []}, {"text": "These approaches involve downgrading hyperlinks and inevitably omit certain information in hyper-docs.", "labels": [], "entities": []}, {"text": "However, no previous work investigates the information loss, and how it affects the performance of such downcasting-based adaptations.", "labels": [], "entities": []}, {"text": "The second type designs sophisticated embedding models to fulfill certain tasks, e.g., citation recommendation), paper classification ( , and entity linking (, etc.", "labels": [], "entities": [{"text": "citation recommendation", "start_pos": 87, "end_pos": 110, "type": "TASK", "confidence": 0.9209857285022736}, {"text": "paper classification", "start_pos": 113, "end_pos": 133, "type": "TASK", "confidence": 0.7925463914871216}, {"text": "entity linking", "start_pos": 142, "end_pos": 156, "type": "TASK", "confidence": 0.7283100038766861}]}, {"text": "These models are limited to specific tasks, and it is yet unknown whether embeddings learned for those particular tasks can generalize to others.", "labels": [], "entities": []}, {"text": "Based on the above facts, we are interested in two questions: \u2022 What information should hyper-doc embedding models preserve, and what nice property should they possess?", "labels": [], "entities": []}, {"text": "\u2022 Is there a general approach to learning taskindependent embeddings of hyper-docs?", "labels": [], "entities": []}, {"text": "To answer the two questions, we formalize the hyper-doc embedding task, and propose four criteria, i.e., content awareness, context awareness, newcomer friendliness, and context intent aware-ness, to assess different models.", "labels": [], "entities": []}, {"text": "Then we discuss simple downcasting-based adaptations of existing approaches w.r.t. the above criteria, and demonstrate that none of them satisfy all four.", "labels": [], "entities": []}, {"text": "To this end, we propose hyperdoc2vec (h-d2v for short), a general embedding approach for hyperdocs.", "labels": [], "entities": []}, {"text": "Different from most existing approaches, h-d2v learns two vectors for each hyper-doc to characterize its roles of citing others and being cited.", "labels": [], "entities": []}, {"text": "Owning to this, h-d2v is able to directly model hyperlinks or citations without downgrading them.", "labels": [], "entities": []}, {"text": "To evaluate the learned embeddings, we employ two tasks in the academic paper domain 1 , i.e., paper classification and citation recommendation.", "labels": [], "entities": [{"text": "paper classification", "start_pos": 95, "end_pos": 115, "type": "TASK", "confidence": 0.7238516211509705}, {"text": "citation recommendation", "start_pos": 120, "end_pos": 143, "type": "TASK", "confidence": 0.8313145637512207}]}, {"text": "Experimental results demonstrate the superiority of h-d2v.", "labels": [], "entities": []}, {"text": "Comparative studies and controlled experiments also confirm that h-d2v benefits from satisfying the above four criteria.", "labels": [], "entities": []}, {"text": "We summarize our contributions as follows: \u2022 We propose four criteria to assess different hyper-document embedding models.", "labels": [], "entities": []}, {"text": "\u2022 We propose hyperdoc2vec, a general embedding approach for hyper-documents.", "labels": [], "entities": []}, {"text": "\u2022 We systematically conduct comparisons with competing approaches, validating the superiority of h-d2v in terms of the four criteria.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we first introduce datasets and basic settings used to learn embeddings.", "labels": [], "entities": []}, {"text": "We then discuss additional settings and present experimental results of the two tasks, i.e., document classification and citation recommendation, respectively.: F 1 on DBLP when newcomers are discarded.", "labels": [], "entities": [{"text": "document classification", "start_pos": 93, "end_pos": 116, "type": "TASK", "confidence": 0.7905301153659821}, {"text": "citation recommendation", "start_pos": 121, "end_pos": 144, "type": "TASK", "confidence": 0.9034201204776764}, {"text": "F 1", "start_pos": 161, "end_pos": 164, "type": "METRIC", "confidence": 0.988423079252243}, {"text": "DBLP", "start_pos": 168, "end_pos": 172, "type": "DATASET", "confidence": 0.6616165041923523}]}, {"text": "We use three datasets from the academic paper domain, i.e., NIPS 4 , ACL anthology 5 and DBLP 6 , as shown in.", "labels": [], "entities": [{"text": "ACL anthology 5", "start_pos": 69, "end_pos": 84, "type": "DATASET", "confidence": 0.8559004068374634}, {"text": "DBLP", "start_pos": 89, "end_pos": 93, "type": "DATASET", "confidence": 0.7287148833274841}]}, {"text": "They all contain full text of papers, and are of small, medium, and large size, respectively.", "labels": [], "entities": []}, {"text": "We apply ParsCit 7 ( to parse the citations and bibliography sections.", "labels": [], "entities": []}, {"text": "Each identified citation string referring to a paper in the same dataset, e.g.,) is used to implement all w2v and d2v baselines as well as h-d2v.", "labels": [], "entities": []}, {"text": "We use cbow for w2v and pv-dbow for d2v, unless otherwise noted.", "labels": [], "entities": []}, {"text": "For all three baselines, we set the (half) context window length to 50.", "labels": [], "entities": []}, {"text": "For w2v, d2v, and the pv-dm-based initialization of h-d2v, we run 5 epochs following Gensim's default setting.", "labels": [], "entities": []}, {"text": "For h-d2v, its iteration is set to 100 epochs with 1000 negative samples.", "labels": [], "entities": []}, {"text": "The dimension size k of all approaches is 100.", "labels": [], "entities": [{"text": "dimension size k", "start_pos": 4, "end_pos": 20, "type": "METRIC", "confidence": 0.9220066467920939}]}, {"text": "All other parameters in Gensim are kept as default.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: The statistics of three datasets.", "labels": [], "entities": []}, {"text": " Table 4: F 1 scores on DBLP.", "labels": [], "entities": [{"text": "F 1", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9688559472560883}, {"text": "DBLP", "start_pos": 24, "end_pos": 28, "type": "DATASET", "confidence": 0.9443241357803345}]}, {"text": " Table 5: F 1 on DBLP when newcomers are discarded.", "labels": [], "entities": [{"text": "F 1", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9873783588409424}, {"text": "DBLP", "start_pos": 17, "end_pos": 21, "type": "DATASET", "confidence": 0.6447277069091797}]}, {"text": " Table 6: Top-10 citation recommendation results (dimension size k = 100).", "labels": [], "entities": [{"text": "citation recommendation", "start_pos": 17, "end_pos": 40, "type": "TASK", "confidence": 0.8149036765098572}, {"text": "dimension size k", "start_pos": 50, "end_pos": 66, "type": "METRIC", "confidence": 0.921539823214213}]}, {"text": " Table 7: DBLP results evaluated on 63,342 cita- tion contexts with newcomer ground-truth.", "labels": [], "entities": []}, {"text": " Table 9: Papers recommended by different approaches for a citation context in", "labels": [], "entities": []}]}