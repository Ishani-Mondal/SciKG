{"title": [{"text": "Document Similarity for Texts of Varying Lengths via Hidden Topics", "labels": [], "entities": [{"text": "Document Similarity", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8798366189002991}]}], "abstractContent": [{"text": "Measuring similarity between texts is an important task for several applications.", "labels": [], "entities": [{"text": "Measuring similarity between texts", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8718736171722412}]}, {"text": "Available approaches to measure document similarity are inadequate for document pairs that have non-comparable lengths, such as along document and its summary.", "labels": [], "entities": []}, {"text": "This is because of the lexical , contextual and the abstraction gaps between along document of rich details and its concise summary of abstract information.", "labels": [], "entities": []}, {"text": "In this paper, we present a document matching approach to bridge this gap, by comparing the texts in a common space of hidden topics.", "labels": [], "entities": [{"text": "document matching", "start_pos": 28, "end_pos": 45, "type": "TASK", "confidence": 0.7117538899183273}]}, {"text": "We evaluate the matching algorithm on two matching tasks and find that it consistently and widely outper-forms strong baselines.", "labels": [], "entities": []}, {"text": "We also highlight the benefits of the incorporation of domain knowledge to text matching.", "labels": [], "entities": [{"text": "text matching", "start_pos": 75, "end_pos": 88, "type": "TASK", "confidence": 0.8092383146286011}]}], "introductionContent": [{"text": "Measuring the similarity between documents is of key importance in several natural processing applications including information retrieval, book recommendation (), news categorization () and essay scoring.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 117, "end_pos": 138, "type": "TASK", "confidence": 0.8070150911808014}, {"text": "book recommendation", "start_pos": 140, "end_pos": 159, "type": "TASK", "confidence": 0.7303436100482941}, {"text": "essay scoring", "start_pos": 191, "end_pos": 204, "type": "TASK", "confidence": 0.7964620292186737}]}, {"text": "A range of document similarity approaches have been proposed and effectively used in recent applications including.", "labels": [], "entities": [{"text": "document similarity", "start_pos": 11, "end_pos": 30, "type": "TASK", "confidence": 0.7000003010034561}]}, {"text": "Central to the tasks discussed above is the assumption that the documents being compared are of comparable lengths.", "labels": [], "entities": []}, {"text": "Advances in language processing approaches to transform natural language understanding, such as text summarization and recommendation, have generated new requirements for comparing documents.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 56, "end_pos": 86, "type": "TASK", "confidence": 0.6950939893722534}, {"text": "text summarization", "start_pos": 96, "end_pos": 114, "type": "TASK", "confidence": 0.7343429625034332}]}, {"text": "For instance, summarization techniques (extractive and abstractive) are capable of automatically generating textual summaries by converting along document of several hundred words into a condensed text of only a few words while preserving the core meaning of the original text (.", "labels": [], "entities": [{"text": "summarization", "start_pos": 14, "end_pos": 27, "type": "TASK", "confidence": 0.9839056134223938}]}, {"text": "Conceivably, a related aspect of summarization is the task of bidirectional matching of a summary and a document or a set of documents, which is the focus of this study.", "labels": [], "entities": [{"text": "summarization", "start_pos": 33, "end_pos": 46, "type": "TASK", "confidence": 0.9918028712272644}]}, {"text": "The document similarity considered in this paper is between texts that have significant differences not only in length, but also in the abstraction level (such as a definition of an abstract concept versus a detailed instance of that abstract concept).", "labels": [], "entities": []}, {"text": "As an illustration, consider the task of matching a Concept with a Project as shown in.", "labels": [], "entities": []}, {"text": "Here a Concept is a grade-level science curriculum item and represents the summary.", "labels": [], "entities": []}, {"text": "A Project, listed in a collection of science projects, represents the document.", "labels": [], "entities": []}, {"text": "Projects typically are long texts including an introduction, materials and procedures, whereas science concepts are much shorter in comparison having a title and a concise and abstract description.", "labels": [], "entities": []}, {"text": "The concepts and projects are described in detail in Section 5.1.", "labels": [], "entities": []}, {"text": "The matching task here is to automatically suggest a hands-on project fora given concept in the curriculum, such that the project can help reinforce a learner's basic understanding of the concept.", "labels": [], "entities": []}, {"text": "Conversely, given a science project, one may need to identify the concept it covers by matching it to a listed concept in the curriculum.", "labels": [], "entities": []}, {"text": "This would be conceivable in the context of an intelligent tutoring system.", "labels": [], "entities": []}, {"text": "Challenges to the matching task mentioned above include: 1) The mismatch in the relative lengths of the documents being compared -a long piece of text (henceforth termed document) and a short piece of text (termed summary) -gives rise to the vocabulary mismatch problem, where the document and the summary do not share a majority of terms.", "labels": [], "entities": []}, {"text": "2) The context mismatch problem arising because a document provides a reasonable amount of text to infer the contextual meaning of a term, but a summary only provides a limited context, which mayor may not involve the same terms considered in the document.", "labels": [], "entities": []}, {"text": "These challenges render existing approaches to comparing documents-for instance, those that rely on document representations (e.g.,)-inadequate, because the predominance of non-topic words in the document introduces noise to its representation while the summary is relatively noise-free, rendering Doc2Vec inadequate for comparing them.", "labels": [], "entities": []}, {"text": "Our approach to the matching problem is to allow a multi-view generalization of the document, where multiple hidden topics are used to establish a common ground to capture as much information of the document and the summary as possible and use this to score the relevance of the pair.", "labels": [], "entities": []}, {"text": "We empirically validate our approach on two tasks -that of project-concept matching in gradelevel science and that of scientific paper-summary matching -using both custom-made and publicly available datasets.", "labels": [], "entities": [{"text": "scientific paper-summary matching", "start_pos": 118, "end_pos": 151, "type": "TASK", "confidence": 0.7027398149172465}]}, {"text": "The main contributions of this paper are: 1.", "labels": [], "entities": []}, {"text": "We propose an embedding-based hidden topic model to extract topics and measure their importance in long documents.", "labels": [], "entities": []}, {"text": "2. We present a novel geometric approach to compare documents with differing modality (a long document to a short summary) and validate its performance relative to strong baselines.", "labels": [], "entities": []}, {"text": "3. We explore the use of domain-specific word embeddings for the matching task and show the explicit benefit of incorporating domain knowledge in the algorithm.", "labels": [], "entities": []}, {"text": "4. We make available the first dataset 1 on projectconcept matching in the science domain to help further research in this area.", "labels": [], "entities": [{"text": "projectconcept matching", "start_pos": 44, "end_pos": 67, "type": "TASK", "confidence": 0.7114799618721008}]}], "datasetContent": [{"text": "In this section, we evaluate our documentsummary matching approach on two specific applications where texts of different sizes are compared.", "labels": [], "entities": [{"text": "documentsummary matching", "start_pos": 33, "end_pos": 57, "type": "TASK", "confidence": 0.6792747378349304}]}, {"text": "One application is that of concept-project matching useful in science education and the other is that of summary-research paper matching.", "labels": [], "entities": [{"text": "concept-project matching", "start_pos": 27, "end_pos": 51, "type": "TASK", "confidence": 0.7368979752063751}, {"text": "summary-research paper matching", "start_pos": 105, "end_pos": 136, "type": "TASK", "confidence": 0.6354200144608816}]}, {"text": "Two sets of 300-dimension word embeddings were used in our experiments.", "labels": [], "entities": []}, {"text": "They were trained by the Continuous Bag-of-Words (CBOW) model in word2vec () but on different corpora.", "labels": [], "entities": []}, {"text": "One training corpus is the full English WikiCorpus of size 9 GB (Al-).", "labels": [], "entities": []}, {"text": "The second consists of science articles extracted from the WikiCorpus.", "labels": [], "entities": [{"text": "WikiCorpus", "start_pos": 59, "end_pos": 69, "type": "DATASET", "confidence": 0.9167155027389526}]}, {"text": "To extract these science articles, we manually selected the science categories in Wikipedia and considered all subcategories within a depth of 3 from these manually selected root categories.", "labels": [], "entities": []}, {"text": "We then extracted all articles in the aforementioned science categories resulting in a science corpus of size 2.4 GB.", "labels": [], "entities": []}, {"text": "The word vectors used for documents and summaries are both from the pretrained word2vec embeddings.", "labels": [], "entities": []}, {"text": "Baselines We include two state-of-the-art methods of measuring document similarity for comparison using their implementations available in gensim.", "labels": [], "entities": []}, {"text": "(1) Word movers' distance (WMD).", "labels": [], "entities": [{"text": "Word movers' distance (WMD)", "start_pos": 4, "end_pos": 31, "type": "METRIC", "confidence": 0.7692557772000631}]}, {"text": "WMD quantifies the distance between a pair of documents based on word embeddings as introduced previously (c.f. Related Work).", "labels": [], "entities": []}, {"text": "We take the negative of their distance as a measure of document similarity (here between a document and a summary).", "labels": [], "entities": []}, {"text": "(2) Doc2Vec ().", "labels": [], "entities": [{"text": "Doc2Vec", "start_pos": 4, "end_pos": 11, "type": "DATASET", "confidence": 0.9704327583312988}]}, {"text": "Document representations have been trained with neural networks.", "labels": [], "entities": [{"text": "Document representations", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8432922661304474}]}, {"text": "We used two versions of doc2vec: one trained on the full English Wikicorpus and a second trained on the science corpus, same as the corpora used for word embedding training.", "labels": [], "entities": []}, {"text": "We used the cosine similarity between two text vectors to measure their relevance.", "labels": [], "entities": []}, {"text": "For a given document-summary pair, we compare the scores obtained using the above two methods with that obtained using our method.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Classification results for the Concept-Project Matching task. All performance differences were  statistically significant at p = 0.01.", "labels": [], "entities": [{"text": "Concept-Project Matching task", "start_pos": 41, "end_pos": 70, "type": "TASK", "confidence": 0.8189848860104879}]}]}