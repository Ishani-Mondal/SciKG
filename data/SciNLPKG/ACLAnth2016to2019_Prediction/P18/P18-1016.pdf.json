{"title": [{"text": "Simple and Effective Text Simplification Using Semantic and Neural Methods", "labels": [], "entities": [{"text": "Text Simplification", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.7060526609420776}]}], "abstractContent": [{"text": "Sentence splitting is a major simplification operator.", "labels": [], "entities": [{"text": "Sentence splitting", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9393438696861267}]}, {"text": "Here we present a simple and efficient splitting algorithm based on an automatic semantic parser.", "labels": [], "entities": []}, {"text": "After splitting, the text is amenable for further fine-tuned simplification operations.", "labels": [], "entities": []}, {"text": "In particular, we show that neural Machine Translation can be effectively used in this situation.", "labels": [], "entities": [{"text": "neural Machine Translation", "start_pos": 28, "end_pos": 54, "type": "TASK", "confidence": 0.6289805769920349}]}, {"text": "Previous application of Machine Translation for simplification suffers from a considerable disadvantage in that they are over-conservative, often failing to modify the source in anyway.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.808619886636734}]}, {"text": "Splitting based on semantic parsing, as proposed here, alleviates this issue.", "labels": [], "entities": [{"text": "Splitting based on semantic parsing", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.6555034101009369}]}, {"text": "Extensive automatic and human evaluation shows that the proposed method compares favorably to the state-of-the-art in combined lexical and structural simplification.", "labels": [], "entities": []}], "introductionContent": [{"text": "Text Simplification (TS) is generally defined as the conversion of a sentence into one or more simpler sentences.", "labels": [], "entities": [{"text": "Text Simplification (TS)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8611811816692352}]}, {"text": "It has been shown useful both as a preprocessing step for tasks such as Machine Translation (MT;) and relation extraction (, as well as for developing reading aids, e.g. for people with dyslexia () or non-native speakers.", "labels": [], "entities": [{"text": "Machine Translation (MT;)", "start_pos": 72, "end_pos": 97, "type": "TASK", "confidence": 0.8179880738258362}, {"text": "relation extraction", "start_pos": 102, "end_pos": 121, "type": "TASK", "confidence": 0.9147396981716156}]}, {"text": "TS includes both structural and lexical operations.", "labels": [], "entities": [{"text": "TS", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.8493301272392273}]}, {"text": "The main structural simplification operation is sentence splitting, namely rewriting a single sentence into multiple sentences while preserving its meaning.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.770068347454071}]}, {"text": "While recent improvement in TS has been achieved by the use of neural MT (NMT) approaches (, where TS is considered a case of monolingual translation, the sentence splitting operation has not been addressed by these systems, potentially due to the rareness of this operation in the training corpora.", "labels": [], "entities": [{"text": "TS", "start_pos": 28, "end_pos": 30, "type": "TASK", "confidence": 0.9830759763717651}, {"text": "monolingual translation", "start_pos": 126, "end_pos": 149, "type": "TASK", "confidence": 0.80661541223526}, {"text": "sentence splitting", "start_pos": 155, "end_pos": 173, "type": "TASK", "confidence": 0.7330092191696167}]}, {"text": "We show that the explicit integration of sentence splitting in the simplification system could also reduce conservatism, which is a grave limitation of NMT-based TS systems.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.7478483617305756}]}, {"text": "Indeed, experimenting with a stateof-the-art neural system (, we find that 66% of the input sentences remain unchanged, while none of the corresponding references is identical to the source.", "labels": [], "entities": []}, {"text": "Human and automatic evaluation of the references (against other references), confirm that the references are indeed simpler than the source, indicating that the observed conservatism is excessive.", "labels": [], "entities": []}, {"text": "Our methods for performing sentence splitting as pre-processing allows the TS system to perform other structural (e.g. deletions) and lexical (e.g. word substitutions) operations, thus increasing both structural and lexical simplicity.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.7212282121181488}]}, {"text": "For combining linguistically informed sentence splitting with data-driven TS, two main methods have been proposed.", "labels": [], "entities": [{"text": "linguistically informed sentence splitting", "start_pos": 14, "end_pos": 56, "type": "TASK", "confidence": 0.6424562111496925}, {"text": "TS", "start_pos": 74, "end_pos": 76, "type": "TASK", "confidence": 0.9246800541877747}]}, {"text": "The first involves handcrafted syntactic rules, whose compilation and validation are laborious).", "labels": [], "entities": []}, {"text": "For example, used 111 rules for relative clauses, appositions, subordination and coordination.", "labels": [], "entities": []}, {"text": "Moreover, syntactic splitting rules, which form a substantial part of the rules, are usually language specific, requiring the development of new rules when ported to other languages, for Portuguese, French, Vietnamese, and Italian respectively).", "labels": [], "entities": [{"text": "syntactic splitting", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.7875789403915405}]}, {"text": "The second method uses linguistic information for detecting potential splitting points, while splitting probabilities are learned us-ing a parallel corpus.", "labels": [], "entities": []}, {"text": "For example, in the system of, the state-of-the-art for joint structural and lexical TS, potential splitting points are determined by event boundaries.", "labels": [], "entities": []}, {"text": "In this work, which is the first to combine structural semantics and neural methods for TS, we propose an intermediate way for performing sentence splitting, presenting Direct Semantic Splitting (DSS), a simple and efficient algorithm based on a semantic parser which supports the direct decomposition of the sentence into its main semantic constituents.", "labels": [], "entities": [{"text": "TS", "start_pos": 88, "end_pos": 90, "type": "TASK", "confidence": 0.9777771234512329}, {"text": "sentence splitting", "start_pos": 138, "end_pos": 156, "type": "TASK", "confidence": 0.7389629036188126}, {"text": "Direct Semantic Splitting (DSS)", "start_pos": 169, "end_pos": 200, "type": "TASK", "confidence": 0.8167017102241516}]}, {"text": "After splitting, NMT-based simplification is performed, using the NTS system.", "labels": [], "entities": [{"text": "NMT-based simplification", "start_pos": 17, "end_pos": 41, "type": "TASK", "confidence": 0.769993245601654}]}, {"text": "We show that the resulting system outperforms HY-BRID in both automatic and human evaluation.", "labels": [], "entities": [{"text": "HY-BRID", "start_pos": 46, "end_pos": 53, "type": "METRIC", "confidence": 0.5465039014816284}]}, {"text": "We use the UCCA scheme for semantic representation (, where the semantic units are anchored in the text, which simplifies the splitting operation.", "labels": [], "entities": [{"text": "semantic representation", "start_pos": 27, "end_pos": 50, "type": "TASK", "confidence": 0.7806751430034637}]}, {"text": "We further leverage the explicit distinction in UCCA between types of Scenes (events), applying a specific rule for each of the cases.", "labels": [], "entities": []}, {"text": "Nevertheless, the DSS approach can be adapted to other semantic schemes, like AMR (.", "labels": [], "entities": [{"text": "AMR", "start_pos": 78, "end_pos": 81, "type": "DATASET", "confidence": 0.7620705366134644}]}, {"text": "We collect human judgments for multiple variants of our system, its sub-components, HYBRID and similar systems that use phrase-based MT.", "labels": [], "entities": [{"text": "HYBRID", "start_pos": 84, "end_pos": 90, "type": "DATASET", "confidence": 0.9071053266525269}, {"text": "MT", "start_pos": 133, "end_pos": 135, "type": "TASK", "confidence": 0.675909161567688}]}, {"text": "This results in a sizable human evaluation benchmark, which includes 28 systems, totaling at 1960 complex-simple sentence pairs, each annotated by three annotators using four criteria.", "labels": [], "entities": []}, {"text": "1 This benchmark will support the future analysis of TS systems, and evaluation practices.", "labels": [], "entities": [{"text": "TS", "start_pos": 53, "end_pos": 55, "type": "TASK", "confidence": 0.9656168222427368}]}, {"text": "Previous work is discussed in \u00a72, the semantic and NMT components we use in \u00a73 and \u00a74 respectively.", "labels": [], "entities": []}, {"text": "The experimental setup is detailed in \u00a75.", "labels": [], "entities": []}, {"text": "Our main results are presented in \u00a76, while \u00a77 presents a more detailed analysis of the system's sub-components and related settings.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to isolate the effect of NMT, we also implement SEMoses, where the neural-based component is replaced by the phrase-based MT system Moses, which is also used in HYBRID.", "labels": [], "entities": [{"text": "HYBRID", "start_pos": 170, "end_pos": 176, "type": "DATASET", "confidence": 0.9332725405693054}]}, {"text": "The training, tuning and test sets are the same as in the case of SENTS.", "labels": [], "entities": [{"text": "SENTS", "start_pos": 66, "end_pos": 71, "type": "TASK", "confidence": 0.7256839275360107}]}, {"text": "MGIZA 10 is used for word alignment.", "labels": [], "entities": [{"text": "MGIZA 10", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.7876648902893066}, {"text": "word alignment", "start_pos": 21, "end_pos": 35, "type": "TASK", "confidence": 0.8459233641624451}]}, {"text": "The KenLM language model is trained using the target side of the training corpus.", "labels": [], "entities": []}, {"text": "We report human and automatic evaluation scores for Identity (where the output is identical to the input), for Simple Wikipedia where the output is the corresponding aligned sentence in the PWKP corpus, and for the SBMT-SARI system, tuned against SARI (, which maximized the SARI score on this test set in previous works (., which compares the n-grams of the system output with those of the input and the human references, separately evaluating the quality of words that are added, deleted and kept by the systems.", "labels": [], "entities": [{"text": "Simple Wikipedia", "start_pos": 111, "end_pos": 127, "type": "DATASET", "confidence": 0.7763777673244476}, {"text": "PWKP corpus", "start_pos": 190, "end_pos": 201, "type": "DATASET", "confidence": 0.9666879177093506}]}, {"text": "(3) F add : the addition component of the SARI score (F-score); (4) F keep : the keeping component of the SARI score (F-score); (5) P del : the deletion component of the SARI score (precision).", "labels": [], "entities": [{"text": "F add", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.9614298343658447}, {"text": "F-score", "start_pos": 54, "end_pos": 61, "type": "METRIC", "confidence": 0.8490874767303467}, {"text": "F keep", "start_pos": 68, "end_pos": 74, "type": "METRIC", "confidence": 0.938080221414566}, {"text": "P del", "start_pos": 132, "end_pos": 137, "type": "METRIC", "confidence": 0.9439130425453186}, {"text": "precision", "start_pos": 182, "end_pos": 191, "type": "METRIC", "confidence": 0.9965067505836487}]}, {"text": "Each metric is computed against the 8 available references.", "labels": [], "entities": []}, {"text": "We also assess system conservatism, reporting the percentage of sentences copied from the input (%Same), the averaged Levenshtein distance from the source (LD SC , which considers additions, deletions, and substitutions), and the number of source sentences that are split (#Split).", "labels": [], "entities": [{"text": "system conservatism", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.7151246517896652}]}, {"text": "Human evaluation is carried out by 3 in-house native English annotators, who rated the different input-output pairs for the different systems according to 4 parameters: Grammaticality (G), Meaning preservation (M), Simplicity (S) and Structural Simplicity (StS).", "labels": [], "entities": []}, {"text": "Each input-output pair is rated by all 3 annotators.", "labels": [], "entities": []}, {"text": "Elicitation questions are given in.", "labels": [], "entities": []}, {"text": "As the selection process of the input-output pairs in the test corpus of, as well as their crowdsourced references, are explicitly biased towards lexical simplification, the use of human evaluation permits us to evaluate the structural aspects of the system outputs, even where structural operations are not attested in the references.", "labels": [], "entities": []}, {"text": "Indeed, we show that system outputs may receive considerably higher structural simplicity scores than the source, in spite of the sample selection bias.", "labels": [], "entities": [{"text": "simplicity", "start_pos": 79, "end_pos": 89, "type": "METRIC", "confidence": 0.7859112024307251}]}, {"text": "Following previous work (e.g.,, Grammaticality (G) and Meaning preservation (M) are measured using a 1 to 5 scale.", "labels": [], "entities": [{"text": "Grammaticality (G)", "start_pos": 32, "end_pos": 50, "type": "METRIC", "confidence": 0.722641795873642}, {"text": "Meaning preservation (M)", "start_pos": 55, "end_pos": 79, "type": "METRIC", "confidence": 0.6533574104309082}]}, {"text": "Note that in the first question, the input sentence is not taken into account.", "labels": [], "entities": []}, {"text": "The grammaticality of the input is assessed by evaluating the Identity transformation (see), providing a baseline for the grammaticality scores of the other systems.", "labels": [], "entities": []}, {"text": "Following N17, a -2 to +2 scale is used for measuring simplicity, where a 0 score indicates that the input and the output are equally complex.", "labels": [], "entities": [{"text": "N17", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.9574431777000427}, {"text": "simplicity", "start_pos": 54, "end_pos": 64, "type": "METRIC", "confidence": 0.992946207523346}]}, {"text": "This scale, compared to the standard 1 to 5 scale, permits a better differentiation between cases where simplicity is hurt (the output is more complex than the original) and between cases where the output is as simple as the original, for example in the case of the identity transformation.", "labels": [], "entities": [{"text": "simplicity", "start_pos": 104, "end_pos": 114, "type": "METRIC", "confidence": 0.9937559366226196}]}, {"text": "Structural simplicity is also evaluated with a -2 to +2 scale.", "labels": [], "entities": []}, {"text": "The question for eliciting StS is accompanied with a negative example, showing a case of lexical simplification, where a complex word is replaced by a simple one (the other questions appear without examples).", "labels": [], "entities": [{"text": "lexical simplification", "start_pos": 89, "end_pos": 111, "type": "TASK", "confidence": 0.6908529102802277}]}, {"text": "A positive example is not included so as not to bias the annotators by revealing the nature of the operations we focus on (splitting and deletion).", "labels": [], "entities": []}, {"text": "We follow N17 in applying human evaluation on the first 70 sentences of the test corpus.", "labels": [], "entities": [{"text": "N17", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.9376682639122009}]}, {"text": "The resulting corpus, totaling 1960 sentence pairs, each annotated by 3 annotators, also include the additional experiments described in Section 7 as well as the outputs of the NTS and SENTS systems used with the default initialization.", "labels": [], "entities": [{"text": "NTS", "start_pos": 177, "end_pos": 180, "type": "DATASET", "confidence": 0.8868376612663269}]}, {"text": "The inter-annotator agreement, using Cohen's quadratic weighted \u03ba, is computed as the average agreement of the 3 annotator pairs.", "labels": [], "entities": []}, {"text": "The obtained rates are 0.56, 0.75, 0.47 and 0.48 for G, M, Sand StS respectively.", "labels": [], "entities": [{"text": "Sand StS", "start_pos": 59, "end_pos": 67, "type": "DATASET", "confidence": 0.8825299441814423}]}, {"text": "System scores are computed by averaging over the 3 annotators and the 70 sentences.: Human evaluation of the different NMT-based systems.", "labels": [], "entities": []}, {"text": "Grammaticality (G) and Meaning preservation (M) are measured using a 1 to 5 scale.", "labels": [], "entities": [{"text": "Grammaticality (G)", "start_pos": 0, "end_pos": 18, "type": "METRIC", "confidence": 0.8001212924718857}, {"text": "Meaning preservation (M)", "start_pos": 23, "end_pos": 47, "type": "METRIC", "confidence": 0.7518804550170899}]}, {"text": "A -2 to +2 scale is used for measuring simplicity (S) and structural simplicity (StS) of the output relative to the input sentence.", "labels": [], "entities": [{"text": "simplicity (S)", "start_pos": 39, "end_pos": 53, "type": "METRIC", "confidence": 0.9434311240911484}, {"text": "structural simplicity (StS)", "start_pos": 58, "end_pos": 85, "type": "METRIC", "confidence": 0.8896607279777526}]}, {"text": "The highest score in each column appears in bold.", "labels": [], "entities": []}, {"text": "Structural simplification systems are those that explicitly model structural operations.", "labels": [], "entities": [{"text": "Structural simplification", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8588780164718628}]}, {"text": "Replacing the parser by manual annotation.", "labels": [], "entities": []}, {"text": "In order to isolate the influence of the parser on the results, we implement a semi-automatic version of the semantic component, which uses manual UCCA annotation instead of the parser, focusing of the first 70 sentences of the test corpus.", "labels": [], "entities": []}, {"text": "We employ a single expert UCCA annotator and use the UCCAApp annotation tool ( . Results are presented in, for both SENTS and SEMoses.", "labels": [], "entities": []}, {"text": "In the case of SEMoses, meaning preservation is improved when manual UCCA annotation is used.", "labels": [], "entities": [{"text": "preservation", "start_pos": 32, "end_pos": 44, "type": "METRIC", "confidence": 0.5278356671333313}]}, {"text": "On the other hand, simplicity degrades, possibly due to the larger number of Scenes marked by the human annotator (TUPA tends to under-predict Scenes).", "labels": [], "entities": [{"text": "simplicity", "start_pos": 19, "end_pos": 29, "type": "METRIC", "confidence": 0.9965435862541199}]}, {"text": "This effect doesn't show with SENTS, where trends are similar to the automatic parses case, and high simplicity scores are obtained.", "labels": [], "entities": [{"text": "SENTS", "start_pos": 30, "end_pos": 35, "type": "METRIC", "confidence": 0.6032649874687195}, {"text": "simplicity", "start_pos": 101, "end_pos": 111, "type": "METRIC", "confidence": 0.9955437779426575}]}, {"text": "This demonstrates that UCCA parsing technology is sufficiently mature to be used to carryout structural simplification.", "labels": [], "entities": [{"text": "UCCA parsing", "start_pos": 23, "end_pos": 35, "type": "TASK", "confidence": 0.7033083885908127}, {"text": "structural simplification", "start_pos": 93, "end_pos": 118, "type": "TASK", "confidence": 0.7963807582855225}]}, {"text": "We also directly evaluate the performance of the parser by computing F1,, against the manual UCCA annotation.", "labels": [], "entities": [{"text": "F1", "start_pos": 69, "end_pos": 71, "type": "METRIC", "confidence": 0.9984771609306335}, {"text": "UCCA", "start_pos": 93, "end_pos": 97, "type": "DATASET", "confidence": 0.9197368621826172}]}, {"text": "We obtain for primary edges (i.e. edges that form a tree structure) scores of 68.9 %, 70.5%, and 67.4% for F1, Recall and Precision respectively.", "labels": [], "entities": [{"text": "F1", "start_pos": 107, "end_pos": 109, "type": "METRIC", "confidence": 0.999536395072937}, {"text": "Recall", "start_pos": 111, "end_pos": 117, "type": "METRIC", "confidence": 0.9926048517227173}, {"text": "Precision", "start_pos": 122, "end_pos": 131, "type": "METRIC", "confidence": 0.9895122647285461}]}, {"text": "For remotes edges (i.e. additional edges, forming a DAG), the scores are 45.3%, 40.5%, and 51.5%.", "labels": [], "entities": []}, {"text": "These results are comparable with the out-of-domain results reported by.", "labels": [], "entities": []}, {"text": "We test other variants of SEMoses, where phrase-based MT is used instead of NMT.", "labels": [], "entities": []}, {"text": "Specifically, we incorporate semantic information in a different manner by implementing two additional models: (1) SETrain1-Moses, where anew training corpus is obtained by applying the splitting rules to the target side of the", "labels": [], "entities": [{"text": "SETrain1-Moses", "start_pos": 115, "end_pos": 129, "type": "METRIC", "confidence": 0.7972103953361511}]}], "tableCaptions": [{"text": " Table 1: Questions for the human evaluation.", "labels": [], "entities": []}, {"text": " Table 2: Human evaluation of the different NMT-based sys- tems. Grammaticality (G) and Meaning preservation (M) are  measured using a 1 to 5 scale. A -2 to +2 scale is used for  measuring simplicity (S) and structural simplicity (StS) of  the output relative to the input sentence. The highest score in  each column appears in bold. Structural simplification sys- tems are those that explicitly model structural operations.", "labels": [], "entities": [{"text": "Meaning preservation (M)", "start_pos": 88, "end_pos": 112, "type": "METRIC", "confidence": 0.7923046350479126}, {"text": "simplicity (S)", "start_pos": 189, "end_pos": 203, "type": "METRIC", "confidence": 0.9333240687847137}, {"text": "structural simplicity (StS)", "start_pos": 208, "end_pos": 235, "type": "METRIC", "confidence": 0.8363821864128113}]}, {"text": " Table 3: The left-hand side of the table presents BLEU and SARI scores for the combinations of NTS and DSS, as well as for  the baselines. The highest score in each column appears in bold. The right hand side presents lexical and structural properties  of the outputs. %Same: proportion of sentences copied from the input; LDSC: Averaged Levenshtein distance from the source;  #Split: number of split sentences. Structural simplification systems are those that explicitly model structural operations.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.9990677237510681}, {"text": "SARI", "start_pos": 60, "end_pos": 64, "type": "METRIC", "confidence": 0.9902744293212891}, {"text": "NTS and DSS", "start_pos": 96, "end_pos": 107, "type": "TASK", "confidence": 0.37316293517748517}, {"text": "LDSC", "start_pos": 324, "end_pos": 328, "type": "METRIC", "confidence": 0.9940887689590454}]}, {"text": " Table 4: Automatic and human evaluation for the different combinations of Moses and DSS. The automatic metrics as well  as the lexical and structural properties reported (%Same: proportion of sentences copied from the input; LDSC: Averaged  Levenshtein distance from the source; #Split: number of split sentences) concern the 359 sentences of the test corpus. Human  evaluation, with the G, M, S, and StS parameters, is applied to the first 70 sentences of the corpus. The highest score in each  column appears in bold.", "labels": [], "entities": [{"text": "LDSC: Averaged  Levenshtein distance", "start_pos": 226, "end_pos": 262, "type": "METRIC", "confidence": 0.8317190289497376}]}, {"text": " Table 5: System outputs for one of the test sentences with the corresponding human evaluation scores (averaged over the 3  annotators). Grammaticality (G) and Meaning preservation (M) are measured using a 1 to 5 scale. A -2 to +2 scale is used for  measuring simplicity (S) and structural simplicity (StS) of the output relative to the input sentence.", "labels": [], "entities": [{"text": "Grammaticality (G)", "start_pos": 137, "end_pos": 155, "type": "METRIC", "confidence": 0.754977211356163}, {"text": "Meaning preservation (M)", "start_pos": 160, "end_pos": 184, "type": "METRIC", "confidence": 0.868220591545105}, {"text": "A", "start_pos": 220, "end_pos": 221, "type": "METRIC", "confidence": 0.9615499377250671}, {"text": "simplicity (S)", "start_pos": 260, "end_pos": 274, "type": "METRIC", "confidence": 0.937362864613533}, {"text": "structural simplicity (StS)", "start_pos": 279, "end_pos": 306, "type": "METRIC", "confidence": 0.8577997088432312}]}, {"text": " Table 6: Human evaluation using manual UCCA annota- tion. Grammaticality (G) and Meaning preservation (M) are  measured using a 1 to 5 scale. A -2 to +2 scale is used for  measuring simplicity (S) and structural simplicity (StS) of  the output relative to the input sentence. X m refers to the  semi-automatic version of the system X.", "labels": [], "entities": [{"text": "Meaning preservation (M)", "start_pos": 82, "end_pos": 106, "type": "METRIC", "confidence": 0.8189329624176025}, {"text": "simplicity (S)", "start_pos": 183, "end_pos": 197, "type": "METRIC", "confidence": 0.9213182628154755}, {"text": "structural simplicity (StS)", "start_pos": 202, "end_pos": 229, "type": "METRIC", "confidence": 0.7952792584896088}]}]}