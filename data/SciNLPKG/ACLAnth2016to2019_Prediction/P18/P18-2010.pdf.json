{"title": [{"text": "Unsupervised Semantic Frame Induction using Triclustering", "labels": [], "entities": [{"text": "Unsupervised Semantic Frame Induction", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.5444706231355667}]}], "abstractContent": [{"text": "We use dependency triples automatically extracted from a Web-scale corpus to perform unsupervised semantic frame induction.", "labels": [], "entities": [{"text": "semantic frame induction", "start_pos": 98, "end_pos": 122, "type": "TASK", "confidence": 0.6568093001842499}]}, {"text": "We cast the frame induction problem as a triclustering problem that is a generalization of clustering for triadic data.", "labels": [], "entities": [{"text": "frame induction", "start_pos": 12, "end_pos": 27, "type": "TASK", "confidence": 0.7244824469089508}]}, {"text": "Our replicable benchmarks demonstrate that the proposed graph-based approach, Triframes, shows state-of-the art results on this task on a FrameNet-derived dataset and performing on par with competitive methods on a verb class clustering task.", "labels": [], "entities": [{"text": "FrameNet-derived dataset", "start_pos": 138, "end_pos": 162, "type": "DATASET", "confidence": 0.9039906859397888}, {"text": "verb class clustering task", "start_pos": 215, "end_pos": 241, "type": "TASK", "confidence": 0.6781498268246651}]}], "introductionContent": [{"text": "Recent years have seen much work on Frame Semantics, enabled by the availability of a large set of frame definitions, as well as a manually annotated text corpus provided by the FrameNet project ().", "labels": [], "entities": []}, {"text": "FrameNet data enabled the development of wide-coverage frame parsers using supervised learning (, inter alia), as well as its application to a wide range of tasks, ranging from answer extraction in Question Answering and Textual Entailment (.", "labels": [], "entities": [{"text": "FrameNet data", "start_pos": 0, "end_pos": 13, "type": "DATASET", "confidence": 0.8736939132213593}, {"text": "answer extraction", "start_pos": 177, "end_pos": 194, "type": "TASK", "confidence": 0.8247496783733368}, {"text": "Question Answering", "start_pos": 198, "end_pos": 216, "type": "TASK", "confidence": 0.7374909520149231}, {"text": "Textual Entailment", "start_pos": 221, "end_pos": 239, "type": "TASK", "confidence": 0.7135352939367294}]}, {"text": "However, frame-semantic resources are arguably expensive and time-consuming to build due to difficulties in defining the frames, their granularity and domain, as well as the complexity of the construction and annotation tasks requiring expertise in the underlying knowledge.", "labels": [], "entities": []}, {"text": "Consequently, such resources exist only fora few languages and even English is lacking domain-specific frame-based resources.", "labels": [], "entities": []}, {"text": "Possible inroads are cross-lingual semantic annotation transfer), fully unsupervised frame-based semantic annotation exhibits far more challenges, starting with the preliminary step of automatically inducing a set of semantic frame definitions that would drive a subsequent text annotation.", "labels": [], "entities": [{"text": "cross-lingual semantic annotation transfer", "start_pos": 21, "end_pos": 63, "type": "TASK", "confidence": 0.6313024684786797}]}, {"text": "In this work, we aim at overcoming these issues by automatizing the process of FrameNet construction through unsupervised frame induction techniques.", "labels": [], "entities": [{"text": "FrameNet construction", "start_pos": 79, "end_pos": 100, "type": "TASK", "confidence": 0.8350489437580109}]}, {"text": "In this work, we cast the frame induction problem as a triclustering task (, namely a generalization of standard clustering and biclustering), aiming at simultaneously clustering objects along three dimensions (cf..", "labels": [], "entities": [{"text": "frame induction", "start_pos": 26, "end_pos": 41, "type": "TASK", "confidence": 0.7319712340831757}]}, {"text": "First, using triclustering allows to avoid sequential nature of frame induction approaches, e.g. (), where two independent clusterings are needed.", "labels": [], "entities": []}, {"text": "Second, benchmarking frame induction as triclustering against other methods on dependency triples allows to abstract away the evaluation of the frame induction algorithm from other factors, e.g., the input corpus or pre-processing steps, thus allowing a fair comparison of different induction models.", "labels": [], "entities": [{"text": "benchmarking frame induction", "start_pos": 8, "end_pos": 36, "type": "TASK", "confidence": 0.7053269644578298}]}, {"text": "The contributions of this paper are three-fold: (1) we are the first to apply triclustering algorithms for unsupervised frame induction, (2) we propose anew approach to triclustering, achieving state-of-the-art performance on the frame induction task, (3) we propose anew method for the evaluation of frame induction enabling straightforward comparison of approaches.", "labels": [], "entities": [{"text": "frame induction", "start_pos": 120, "end_pos": 135, "type": "TASK", "confidence": 0.7367309629917145}, {"text": "frame induction task", "start_pos": 230, "end_pos": 250, "type": "TASK", "confidence": 0.8129887580871582}, {"text": "frame induction", "start_pos": 301, "end_pos": 316, "type": "TASK", "confidence": 0.7721537947654724}]}, {"text": "In this paper, we focus on the simplest setup with subject-verbobject (SVO) triples and two roles, but our evaluation framework can be extended to more roles.", "labels": [], "entities": []}, {"text": "In contrast to the recent approaches like the one by, our approach induces semantic frames without any supervision, yet capturing only two core roles: the subject and the object of a frame triggered by verbal predicates.", "labels": [], "entities": []}, {"text": "Note that it is not generally correct to expect that the SVO triples obtained by a dependency parser are necessarily the core arguments of a predicate.", "labels": [], "entities": []}, {"text": "Such roles can be implicit, i.e., unexpressed in a given context.", "labels": [], "entities": []}, {"text": "Keeping this limitation in mind, we assume that the triples obtained from a Web-scale corpus cover most core arguments sufficiently.", "labels": [], "entities": []}, {"text": "LDA-Frames) is an approach to inducing semantic frames using LDA () for generating semantic frames and their respective framespecific semantic roles at the same time.", "labels": [], "entities": []}, {"text": "The authors evaluated their approach against the CPA corpus).", "labels": [], "entities": [{"text": "CPA corpus", "start_pos": 49, "end_pos": 59, "type": "DATASET", "confidence": 0.9291001856327057}]}, {"text": "ProFinder () is another generative approach that also models both frames and roles as latent topics.", "labels": [], "entities": []}, {"text": "The evaluation was performed on the in-domain information extraction task and on the text summarization task TAC-2010.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 46, "end_pos": 68, "type": "TASK", "confidence": 0.7152946144342422}, {"text": "text summarization task TAC-2010", "start_pos": 85, "end_pos": 117, "type": "TASK", "confidence": 0.7549989372491837}]}, {"text": "1 build on top of an unsupervised semantic role labeling model ).", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 34, "end_pos": 56, "type": "TASK", "confidence": 0.691084106763204}]}, {"text": "The raw text of sentences from the FrameNet data is used for training.", "labels": [], "entities": [{"text": "FrameNet data", "start_pos": 35, "end_pos": 48, "type": "DATASET", "confidence": 0.9429672062397003}]}, {"text": "The FrameNet gold annotations are then used to evaluate the labeling of the obtained frames and roles, effectively clustering instances known during induction.", "labels": [], "entities": [{"text": "FrameNet gold annotations", "start_pos": 4, "end_pos": 29, "type": "DATASET", "confidence": 0.8850627938906351}]}, {"text": "harvest a huge collection of verbal predicates along with their argument instances and then apply the Chinese Restaurant Process clustering algorithm to group predicates with similar arguments.", "labels": [], "entities": [{"text": "Chinese Restaurant Process clustering", "start_pos": 102, "end_pos": 139, "type": "TASK", "confidence": 0.7334252446889877}]}, {"text": "The approach was evaluated on the verb cluster dataset of.", "labels": [], "entities": []}, {"text": "A major issue with unsupervised frame induction task is that these and some other related approaches, e.g.,, were all evaluated in completely different incomparable settings, and used different input corpora.", "labels": [], "entities": [{"text": "frame induction task", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.7913813988367716}]}, {"text": "In this paper, we propose a methodology to resolve this issue.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our evaluation, we use triple frequencies from the DepCC dataset ( , which is a dependency-parsed version of the Common Crawl corpus, and the standard 300-dimensional word embeddings model trained on the Google News corpus ().", "labels": [], "entities": [{"text": "DepCC dataset", "start_pos": 54, "end_pos": 67, "type": "DATASET", "confidence": 0.987870991230011}, {"text": "Common Crawl corpus", "start_pos": 116, "end_pos": 135, "type": "DATASET", "confidence": 0.8886397878328959}, {"text": "Google News corpus", "start_pos": 207, "end_pos": 225, "type": "DATASET", "confidence": 0.81126602490743}]}, {"text": "All evaluated algorithms are executed on the same set of triples, eliminating variations due to different corpora or pre-processing.", "labels": [], "entities": []}, {"text": "We cast the complex multi-stage frame induction task as a straightforward triple clustering task.", "labels": [], "entities": [{"text": "multi-stage frame induction task", "start_pos": 20, "end_pos": 52, "type": "TASK", "confidence": 0.7109551578760147}]}, {"text": "We constructed a gold standard set of triclusters, each corresponding to a FrameNet frame, similarly to the one illustrated in.", "labels": [], "entities": []}, {"text": "To construct the evaluation dataset, we extracted frame annotations from the over 150 thousand sentences from the FrameNet 1.7 ().", "labels": [], "entities": [{"text": "FrameNet 1.7", "start_pos": 114, "end_pos": 126, "type": "DATASET", "confidence": 0.8846349716186523}]}, {"text": "Each sentence contains data about the frame, FEE, and its arguments, which were used to generate triples in the form (word i : role 1 , word j : FEE, word k : role 2 ), where word i/j/k correspond to the roles and FEE in the sentence.", "labels": [], "entities": [{"text": "FEE", "start_pos": 45, "end_pos": 48, "type": "DATASET", "confidence": 0.6025376319885254}, {"text": "FEE", "start_pos": 145, "end_pos": 148, "type": "METRIC", "confidence": 0.93641597032547}, {"text": "FEE", "start_pos": 214, "end_pos": 217, "type": "METRIC", "confidence": 0.9721809029579163}]}, {"text": "We omitted roles expressed by multiple words as we use dependency parses, where one node represents a single word only.", "labels": [], "entities": [{"text": "dependency parses", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.761229008436203}]}, {"text": "For the sentences where more than two roles are present, all possible triples were generated.", "labels": [], "entities": []}, {"text": "Sentences with less than two roles were omitted.", "labels": [], "entities": [{"text": "Sentences", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9602361917495728}]}, {"text": "Finally, for each frame, we selected only two roles, which are most frequently co-occurring in the FrameNet annotated texts.", "labels": [], "entities": [{"text": "FrameNet annotated texts", "start_pos": 99, "end_pos": 123, "type": "DATASET", "confidence": 0.8605313698450724}]}, {"text": "This has left us with about 100 thousand instances for the evaluation.", "labels": [], "entities": []}, {"text": "For the evaluation purposes, we operate on the intersection of triples from DepCC and FrameNet.", "labels": [], "entities": [{"text": "DepCC", "start_pos": 76, "end_pos": 81, "type": "DATASET", "confidence": 0.966926634311676}, {"text": "FrameNet", "start_pos": 86, "end_pos": 94, "type": "DATASET", "confidence": 0.9015130996704102}]}, {"text": "Experimenting on the full set of DepCC triples is only possible for several methods that scale well (WATSET, CW, k-means), but is prohibitively expensive for other methods (LDA-Frames, NOAC).", "labels": [], "entities": [{"text": "NOAC", "start_pos": 185, "end_pos": 189, "type": "METRIC", "confidence": 0.6642927527427673}]}, {"text": "In addition to the frame induction evaluation, where subjects, objects, and verbs are evaluated together, we also used a dataset of polysemous verb classes introduced in ( and employed by.", "labels": [], "entities": []}, {"text": "Statis-  Note that the polysemous verb dataset is rather small, whereas the FrameNet triples set is fairly large, enabling reliable comparisons.", "labels": [], "entities": [{"text": "FrameNet triples set", "start_pos": 76, "end_pos": 96, "type": "DATASET", "confidence": 0.8304437001546224}]}, {"text": "Following the approach for verb class evaluation by, we employ normalized modified purity (nmPU) and normalized inverse purity (niPU) as the clustering quality measures.", "labels": [], "entities": [{"text": "verb class evaluation", "start_pos": 27, "end_pos": 48, "type": "TASK", "confidence": 0.6754086514314016}, {"text": "normalized modified purity (nmPU)", "start_pos": 63, "end_pos": 96, "type": "METRIC", "confidence": 0.7843864510456721}, {"text": "normalized inverse purity (niPU)", "start_pos": 101, "end_pos": 133, "type": "METRIC", "confidence": 0.8165063808361689}]}, {"text": "Given the set of the obtained clusters K and the set of the gold clusters G, normalized modified purity quantifies the clustering precision as the average of the weighted overlap \u03b4 K i (K i \u2229 G j ) between each cluster K i \u2208 K and the gold cluster G j \u2208 G that maximizes the overlap with K i : where the weighted overlap is the sum of the weights c iv for each word v in i-th cluster: Note that nmPU counts all the singleton clusters as wrong.", "labels": [], "entities": [{"text": "precision", "start_pos": 130, "end_pos": 139, "type": "METRIC", "confidence": 0.9201009273529053}]}, {"text": "Similarly, normalized inverse purity (collocation) quantifies the clustering recall: nmPU and niPU are combined together as the harmonic mean to yield the overall clustering F-score (F 1 ), which we use to rank the approaches.", "labels": [], "entities": [{"text": "recall", "start_pos": 77, "end_pos": 83, "type": "METRIC", "confidence": 0.8247885704040527}, {"text": "F-score (F 1 )", "start_pos": 174, "end_pos": 188, "type": "METRIC", "confidence": 0.8939571738243103}]}, {"text": "Our framework can be extended to evaluation of more than two roles by generating more roles per frame.", "labels": [], "entities": []}, {"text": "Currently, given a set of gold triples generated from the FrameNet, each triple element has a role, e.g., \"Victim\", \"Predator\", and \"FEE\".", "labels": [], "entities": [{"text": "FrameNet", "start_pos": 58, "end_pos": 66, "type": "DATASET", "confidence": 0.8815043568611145}, {"text": "FEE", "start_pos": 133, "end_pos": 136, "type": "METRIC", "confidence": 0.9885693192481995}]}, {"text": "We use fuzzy clustering evaluation measure which operates not on triples, but instead on a set of tuples.", "labels": [], "entities": []}, {"text": "Consider for instance a gold triple (Freddy : Predator, kidnap : FEE, kid : Victim).", "labels": [], "entities": [{"text": "FEE", "start_pos": 65, "end_pos": 68, "type": "METRIC", "confidence": 0.7826499938964844}]}, {"text": "It will be converted to three pairs, (kidnap, FEE), (kid, Victim).", "labels": [], "entities": [{"text": "kidnap", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9356589317321777}, {"text": "FEE", "start_pos": 46, "end_pos": 49, "type": "METRIC", "confidence": 0.9414593577384949}]}, {"text": "Each cluster in both K and G is transformed into a union of all constituent typed pairs.", "labels": [], "entities": []}, {"text": "The quality measures are finally calculated between these two sets of tuples, K, and G.", "labels": [], "entities": []}, {"text": "Note that one can easily pull in more than two core roles by adding to this gold standard set of tuples other roles of the frame, e.g.,.", "labels": [], "entities": []}, {"text": "In our experiments, we focused on two main roles as our contribution is related to the application of triclustering methods.", "labels": [], "entities": []}, {"text": "However, if more advanced methods of clustering are used, yielding clusters of arbitrary modality (n-clustering), one could also use our evaluation schema.", "labels": [], "entities": []}, {"text": "We compare our method to several available state-of-the-art baselines applicable to our dataset of triples.", "labels": [], "entities": []}, {"text": "LDA-Frames by) is a frame induction method based on topic modeling.", "labels": [], "entities": []}, {"text": "We ran 500 iterations of the model with the default parameters.", "labels": [], "entities": []}, {"text": "Higher-Order Skip-Gram (HOSG) by generalizes the Skip-Gram model () by extending it from word-context co-occurrence matrices to tensors factorized with a polyadic decomposition.", "labels": [], "entities": []}, {"text": "In our case, this tensor consisted of SVO triple counts.", "labels": [], "entities": [{"text": "SVO triple counts", "start_pos": 38, "end_pos": 55, "type": "METRIC", "confidence": 0.53338556488355}]}, {"text": "We trained three vector arrays (for subjects, verbs and objects) on the 108,073 SVO triples from the FrameNet corpus, using the implementation by the authors.", "labels": [], "entities": [{"text": "FrameNet corpus", "start_pos": 101, "end_pos": 116, "type": "DATASET", "confidence": 0.874036580324173}]}, {"text": "Training was performed with 5 negative samples, 300-dimensional vectors, and 10 epochs.", "labels": [], "entities": []}, {"text": "We constructed an embedding of a triple by concatenating embeddings for subjects, verbs, and objects, and clustered them using k-means with the number of clusters set to 10,000 (this value provided the best performance).", "labels": [], "entities": []}, {"text": "NOAC () is an extension of the Object Attribute Condition (OAC) triclustering algorithm () to numerically weighted triples.", "labels": [], "entities": [{"text": "NOAC", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7662562131881714}]}, {"text": "This incremental algorithm searches for dense regions in triadic data.", "labels": [], "entities": []}, {"text": "A minimum density of 0.25 led to the best results.", "labels": [], "entities": []}, {"text": "In the Triadic baselines, independent word embeddings of subject, object, and verb are concatenated and then clustered using a hard clustering algorithm: k-means, spectral clustering, or CW.", "labels": [], "entities": []}, {"text": "We tested various hyper-parameters of each of these algorithms and report the best results overall per clustering algorithm.", "labels": [], "entities": []}, {"text": "Two trivial baselines are Singletons that creates a single cluster per instance and Whole that creates one cluster for all elements.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Statistics of the evaluation datasets.", "labels": [], "entities": []}, {"text": " Table 3: Frame evaluation results on the triples from the FrameNet 1.7 corpus (Baker et al., 1998). The  results are sorted by the descending order of the Frame F 1 -score. Best results are boldfaced.", "labels": [], "entities": [{"text": "FrameNet 1.7 corpus", "start_pos": 59, "end_pos": 78, "type": "DATASET", "confidence": 0.9167006611824036}, {"text": "Frame F 1 -score", "start_pos": 156, "end_pos": 172, "type": "METRIC", "confidence": 0.5852152287960053}]}, {"text": " Table 4: Evaluation results on the dataset of poly- semous verb classes by", "labels": [], "entities": []}]}