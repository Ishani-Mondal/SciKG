{"title": [{"text": "Exploring Chunk Based Templates for Generating a subset of English Text", "labels": [], "entities": [{"text": "Exploring Chunk Based Templates", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7390938848257065}]}], "abstractContent": [{"text": "Natural Language Generation (NLG) is a research task which addresses the automatic generation of natural language text representative of an input non-linguistic collection of knowledge.", "labels": [], "entities": [{"text": "Natural Language Generation (NLG)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7789930452903112}]}, {"text": "In this paper, we address the task of the generation of grammatical sentences in an isolated context given a partial bag-of-words which the generated sentence must contain.", "labels": [], "entities": []}, {"text": "We view the task as a search problem (a problem of choice) involving combinations of smaller chunk based templates extracted from a training corpus to construct a complete sentence.", "labels": [], "entities": []}, {"text": "To achieve that, we propose a fitness function which we use in conjunction with an evolutionary algorithm as the search procedure to arrive at a potentially grammatical sentence (modeled by the fitness score) which satisfies the input constraints .", "labels": [], "entities": []}], "introductionContent": [{"text": "One of the reasons why NLG is a challenging problem is because there are many ways in which a given content can be represented.", "labels": [], "entities": []}, {"text": "These are represented by the stylistic constraints which address syntactic and pragmatic choices (largely) independent of the information conveyed.", "labels": [], "entities": []}, {"text": "Classically, there are two major subtasks recognized in NLG: Strategic Generation and Tactical Generation (Sentence Planning and Surface Realization)).", "labels": [], "entities": [{"text": "Strategic Generation", "start_pos": 61, "end_pos": 81, "type": "TASK", "confidence": 0.7674916684627533}, {"text": "Tactical Generation", "start_pos": 86, "end_pos": 105, "type": "TASK", "confidence": 0.6360538154840469}, {"text": "Sentence Planning and Surface Realization", "start_pos": 107, "end_pos": 148, "type": "TASK", "confidence": 0.6350425004959106}]}, {"text": "Strategic Generation -\"what to say\" deals with identifying the relevant information to present to the audience and Tactical Generation -\"how to say\" addresses the problems of linguistic representation of the input concepts.", "labels": [], "entities": []}, {"text": "In this work, we address the problem of tactical generation, with a focus on the grammaticality of the generated sentences.", "labels": [], "entities": [{"text": "tactical generation", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.9065390229225159}]}, {"text": "We formulate our task as follows: to generate syntactically correct sentences given a set of constraints such as a bag-of-words, partial ordering, etc.", "labels": [], "entities": []}, {"text": "So, for example, given a bag of words such as \"man\", \"plays\", \"football\" and length constraints, a sentence like \"The man plays football in October.\" would be acceptable.", "labels": [], "entities": []}, {"text": "Our approach involves a corpus derived formulation of template based generation.", "labels": [], "entities": [{"text": "template based generation", "start_pos": 54, "end_pos": 79, "type": "TASK", "confidence": 0.7185378074645996}]}, {"text": "Templates are instances of canned text with a slot-filler structure (\"gaps\") which can be filled with the appropriate information thus realizing the sentence.", "labels": [], "entities": []}, {"text": "Since they area manual resource, it is rather expensive and hard to generalize over different types or domains of text.", "labels": [], "entities": []}, {"text": "Thus, it is desirable to be able to automatically extract templates from a corpus.", "labels": [], "entities": []}, {"text": "Also, to increase the syntactic coverage, we use sub-sentence level (smaller) templates to generate a sentence.", "labels": [], "entities": []}], "datasetContent": [{"text": "Following are the steps we took to conduct our experiments: 1.", "labels": [], "entities": []}, {"text": "We tokenized, POS tagged, NER tagged, and chunked and abstracted the English Wikipedia corpus using Stanford CoreNLP (), spaCy and LM-LSTM-CRF () to extract the templates.", "labels": [], "entities": [{"text": "English Wikipedia corpus", "start_pos": 69, "end_pos": 93, "type": "DATASET", "confidence": 0.8583998878796896}, {"text": "Stanford CoreNLP", "start_pos": 100, "end_pos": 116, "type": "DATASET", "confidence": 0.8753547370433807}]}, {"text": "2. The number of clusters, k was chosen to be 7500.", "labels": [], "entities": []}, {"text": "3. We used lexvec( pretrained vectors for clustering.", "labels": [], "entities": []}, {"text": "4. The weights for the fitness function were empirically chosen to be 75, 10, 10, 5 and 2.", "labels": [], "entities": []}], "tableCaptions": []}