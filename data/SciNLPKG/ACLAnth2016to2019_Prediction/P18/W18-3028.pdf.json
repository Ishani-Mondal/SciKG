{"title": [{"text": "Predicting Concreteness and Imageability of Words Within and Across Languages via Word Embeddings", "labels": [], "entities": [{"text": "Predicting Concreteness and Imageability of Words Within and Across Languages", "start_pos": 0, "end_pos": 77, "type": "TASK", "confidence": 0.7199687063694}]}], "abstractContent": [{"text": "The notions of concreteness and image-ability, traditionally important in psy-cholinguistics, are gaining significance in semantic-oriented natural language processing tasks.", "labels": [], "entities": [{"text": "semantic-oriented natural language processing tasks", "start_pos": 122, "end_pos": 173, "type": "TASK", "confidence": 0.6789617359638214}]}, {"text": "In this paper we investigate the predictability of these two concepts via supervised learning, using word embed-dings as explanatory variables.", "labels": [], "entities": []}, {"text": "We perform predictions both within and across languages by exploiting collections of cross-lingual embeddings aligned to a single vector space.", "labels": [], "entities": []}, {"text": "We show that the notions of concreteness and imageability are highly predictable both within and across languages, with a moderate loss of up to 20% in correlation when predicting across languages.", "labels": [], "entities": [{"text": "correlation", "start_pos": 152, "end_pos": 163, "type": "METRIC", "confidence": 0.9664994478225708}]}, {"text": "We further show that the cross-lingual transfer via word embeddings is more efficient than the simple transfer via bilingual dictionaries.", "labels": [], "entities": [{"text": "cross-lingual transfer", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.753666341304779}]}], "introductionContent": [{"text": "Concreteness and imageability are very important notions in psycholinguistic research, building on the theory of the double, verbal and non-verbal, modality of representation of concrete words in the mental lexicon, contrasted to single verbal representation of abstract words.", "labels": [], "entities": []}, {"text": "Although often correlated with concreteness, imageability is not a redundant property.", "labels": [], "entities": []}, {"text": "While most abstract things are hard to visualize, some call up images, e.g., torture calls up an emotional and even visual image.", "labels": [], "entities": []}, {"text": "There are concrete things that are hard to visualize too, for example, abbey is harder to visualize than banana ().", "labels": [], "entities": [{"text": "abbey", "start_pos": 71, "end_pos": 76, "type": "DATASET", "confidence": 0.8196274042129517}]}, {"text": "Both notions have proven to be useful in computational linguistics as well.", "labels": [], "entities": [{"text": "computational linguistics", "start_pos": 41, "end_pos": 66, "type": "TASK", "confidence": 0.7742431461811066}]}, {"text": "present a supervised model that exploits concreteness to correctly classify 79% of adjectivenoun pairs as having literal or non-literal meaning.", "labels": [], "entities": []}, {"text": "exploit both the notions of concreteness and imageability to perform metaphor detection on subject-verb-object and adjective-noun relations, correctly classifying 82% and 86% instances, respectively.", "labels": [], "entities": [{"text": "metaphor detection", "start_pos": 69, "end_pos": 87, "type": "TASK", "confidence": 0.8682522177696228}]}, {"text": "The aim of this paper is to investigate the predictability of concreteness and imageability within a language, as well as across languages, by exploiting cross-lingual word embeddings as our available signal.", "labels": [], "entities": []}], "datasetContent": [{"text": "We start our experiments in the in-language setting, running cross-validation experiments over each of our three datasets on all available variables.", "labels": [], "entities": []}, {"text": "The results of these experiments, with some basic information on the size of the datasets, are given in.", "labels": [], "entities": []}, {"text": "Aside from the three lexicons introduced in Section 3.1, we experiment with another lexicon, BWK.3K, which is a randomly downsampled version of the BWK lexicon to the size of the two remaining lexicons.", "labels": [], "entities": [{"text": "BWK.3K", "start_pos": 93, "end_pos": 99, "type": "DATASET", "confidence": 0.7555967569351196}, {"text": "BWK lexicon", "start_pos": 148, "end_pos": 159, "type": "DATASET", "confidence": 0.9178826212882996}]}, {"text": "We introduce this additional resource (1) to control for dataset size when comparing results on our different datasets and (2) to measure the impact of training data size by comparing the results on the two flavours of the BWK dataset.", "labels": [], "entities": [{"text": "BWK dataset", "start_pos": 223, "end_pos": 234, "type": "DATASET", "confidence": 0.9838614165782928}]}, {"text": "The results in show that the support vector regressor consistently performs better than the feedforward neural network at predicting almost all values, with relative error reduction lying between 7% and 12%.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 166, "end_pos": 181, "type": "METRIC", "confidence": 0.9356679320335388}]}, {"text": "The bold results are statistically significantly better than the corresponding non-bold ones given the approximate randomization test with p < 0.05.", "labels": [], "entities": []}, {"text": "Our assumption is that the stronger FFN model does not show a positive impact primarily due to the small size of the datasets and the simplicity of the modeling problem.", "labels": [], "entities": [{"text": "FFN", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.934581458568573}]}, {"text": "We can further observe that the arithmetic mean is much easier to predict than standard deviation on both variables in all the datasets.", "labels": [], "entities": [{"text": "arithmetic mean", "start_pos": 32, "end_pos": 47, "type": "METRIC", "confidence": 0.9267418086528778}]}, {"text": "This can be explained by the fact that standard deviation on the two phenomena can partially be explained with the level of ambiguity of a specific word, and this type of information is at least not directly available in context-based word embeddings.", "labels": [], "entities": []}, {"text": "Furthermore, imageability seems to be consistently slightly harder to predict than concreteness.", "labels": [], "entities": []}, {"text": "Our initial assumption regarding this difference was that imageability is a more vague notion for: Results of the in-language experiments on predicting mean (.M) and standard deviation (.STD) of concreteness (C) and imageability (I), either using a support vector regressor (SVR) or feed-forward network (FFN).", "labels": [], "entities": []}, {"text": "Evaluation metric is the Spearman correlation coefficient.", "labels": [], "entities": [{"text": "Spearman correlation coefficient", "start_pos": 25, "end_pos": 57, "type": "METRIC", "confidence": 0.6886365413665771}]}, {"text": "human subjects, and therefore their responses are more dispersed, adding to the complexity of the prediction.", "labels": [], "entities": []}, {"text": "However, analyzing standard deviations over concreteness and imageability showed that these are rather the same.", "labels": [], "entities": []}, {"text": "We leave this open question for future research.", "labels": [], "entities": []}, {"text": "When comparing the results on predicting mean concreteness on the full BWK and the trimmed BWK.3K datasets, we see a significant improvement of the predictions of the on the larger dataset, showing that having 10 times more data for learning can produce significant improvements in the prediction quality.", "labels": [], "entities": [{"text": "predicting mean concreteness", "start_pos": 30, "end_pos": 58, "type": "TASK", "confidence": 0.7997257709503174}, {"text": "BWK", "start_pos": 71, "end_pos": 74, "type": "DATASET", "confidence": 0.9729822278022766}, {"text": "BWK.3K datasets", "start_pos": 91, "end_pos": 106, "type": "DATASET", "confidence": 0.970967024564743}]}, {"text": "In cross-lingual experiments we compare our two approaches to cross-lingual transfer: dictionary lookup (DIC onwards) and supervised learning on aligned word embedding spaces via the two methods introduced in Section 4.2, SVR and FFN.", "labels": [], "entities": [{"text": "cross-lingual transfer", "start_pos": 62, "end_pos": 84, "type": "TASK", "confidence": 0.7414206266403198}, {"text": "FFN", "start_pos": 230, "end_pos": 233, "type": "DATASET", "confidence": 0.7565039396286011}]}, {"text": "The DIC method simply looks up for each word in the source language resource all possible translations to the target language and directly transfers the concreteness and imageability ratings to the target language words.", "labels": [], "entities": []}, {"text": "In case of collisions in the target language (two source language words being translated to the same word in the target language), we perform averaging over the transfered ratings.", "labels": [], "entities": []}, {"text": "In our experiments, the arithmetic mean showed to be a better averaging method than the median, we therefore report the results on that averaging method.", "labels": [], "entities": []}, {"text": "The SVR and FFN methods use supervised learning in a very similar fashion to the in-language experiments described in Section 4.2.", "labels": [], "entities": []}, {"text": "We train a supervised regression model on the whole source language dataset, using word embedding dimensions as features and the variable of choice as our target.", "labels": [], "entities": []}, {"text": "We obtain estimates of our variable of choice in the target language by applying the source-language model on the target-language word embeddings since the two embedding spaces are aligned.", "labels": [], "entities": []}, {"text": "For both approaches we compare the targetlanguage estimates with the gold data available from our lexicons.", "labels": [], "entities": []}, {"text": "We present the results of the cross-lingual experiments in.", "labels": [], "entities": []}, {"text": "Our first observation is that, while in the in-language setting the SVR method has regularly outperformed the FFN method, in the cross-lingual setting this is not the case anymore, with SVR and FFN obtaining very similar results, in five out of six cases in the range of no statistically significant difference.", "labels": [], "entities": []}, {"text": "Our explanation for the loss of the positive impact in using the weaker, support vector regression model, is that with the noisy alignment of the two embedding spaces the prediction problem became harder, now both models performing similarly.", "labels": [], "entities": []}, {"text": "While the strong point of SVR is that it performs very well on small datasets, the strong point of the FFN method is that it generalizes better.", "labels": [], "entities": [{"text": "SVR", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.9041739106178284}, {"text": "FFN", "start_pos": 103, "end_pos": 106, "type": "TASK", "confidence": 0.8962885141372681}]}, {"text": "That higher generalization is beneficial in case of the cross-lingual problem is observable in the difference in the hyperparameter tuning results on the FFN method, wherein the in-language setting the optimal dropout was 0.5, while in the crosslingual setting it is 0.8.", "labels": [], "entities": []}, {"text": "Our second observation is that all the predicted ratings suffer in the cross-lingual setting, when compared to the in-language results presented in, observing for the SVR method a drop of around 5 to 15%.", "labels": [], "entities": []}, {"text": "While standard deviation was already poorly predicted in the in-language set-: Results of the cross-lingual experiments, either using supervised learning (SVR, FFN), or simple dictionary lookup (DIC).", "labels": [], "entities": []}, {"text": "Evaluation metric is the Spearman correlation coefficient.", "labels": [], "entities": [{"text": "Spearman correlation coefficient", "start_pos": 25, "end_pos": 57, "type": "METRIC", "confidence": 0.6886365413665771}]}, {"text": "Results in bold are best results per problem with no statistically significant difference.", "labels": [], "entities": []}, {"text": "ting, in the cross-lingual setting it drops even further to a non-useful level, below 0.2.", "labels": [], "entities": [{"text": "ting", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9531700015068054}]}, {"text": "This is the reason why we do not calculate statistical significance of the differences in these results and do not include their estimates in our final 77-languagesstrong resource.", "labels": [], "entities": []}, {"text": "In the final cross-lingual resource we include only the mean of concreteness and imageability, the notions for which we have obtained strong correlation in our cross-lingual experiments.", "labels": [], "entities": []}, {"text": "Finally, when comparing the cross-lingual transfer via embeddings (SVR and FFN) and via a dictionary (DIC), the learning-on-embeddings approach outperforms the dictionary method in each instance, with the relative loss in correlation when moving from the EMB to the DIC approach of 5% to 25%.", "labels": [], "entities": [{"text": "correlation", "start_pos": 222, "end_pos": 233, "type": "METRIC", "confidence": 0.9648321866989136}]}], "tableCaptions": [{"text": " Table 1: Results of the in-language experiments on predicting mean (.M) and standard deviation (.STD)  of concreteness (C) and imageability (I), either using a support vector regressor (SVR) or feed-forward  network (FFN). Evaluation metric is the Spearman correlation coefficient.", "labels": [], "entities": [{"text": "Spearman correlation coefficient", "start_pos": 249, "end_pos": 281, "type": "METRIC", "confidence": 0.6525932252407074}]}, {"text": " Table 2: Results of the cross-lingual experiments, either using supervised learning (SVR, FFN), or simple  dictionary lookup (DIC). Evaluation metric is the Spearman correlation coefficient. Results in bold are  best results per problem with no statistically significant difference.", "labels": [], "entities": [{"text": "Spearman correlation coefficient", "start_pos": 158, "end_pos": 190, "type": "METRIC", "confidence": 0.6338399151961008}]}]}