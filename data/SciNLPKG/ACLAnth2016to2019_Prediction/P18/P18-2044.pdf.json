{"title": [{"text": "CNN for Text-Based Multiple Choice Question Answering", "labels": [], "entities": [{"text": "CNN", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9400714039802551}, {"text": "Text-Based Multiple Choice Question Answering", "start_pos": 8, "end_pos": 53, "type": "TASK", "confidence": 0.5385139346122741}]}], "abstractContent": [{"text": "The task of Question Answering is at the very core of machine comprehension.", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.8161340057849884}]}, {"text": "In this paper, we propose a Convolutional Neural Network (CNN) model for text-based multiple choice question answering where questions are based on a particular article.", "labels": [], "entities": [{"text": "text-based multiple choice question answering", "start_pos": 73, "end_pos": 118, "type": "TASK", "confidence": 0.6099120616912842}]}, {"text": "Given an article and a multiple choice question, our model assigns a score to each question-option tuple and chooses the final option accordingly.", "labels": [], "entities": []}, {"text": "We test our model on Textbook Question Answering (TQA) and SciQ dataset.", "labels": [], "entities": [{"text": "Textbook Question Answering (TQA)", "start_pos": 21, "end_pos": 54, "type": "TASK", "confidence": 0.8007779022057852}, {"text": "SciQ dataset", "start_pos": 59, "end_pos": 71, "type": "DATASET", "confidence": 0.8232374489307404}]}, {"text": "Our model outperforms several LSTM-based baseline models on the two datasets.", "labels": [], "entities": []}], "introductionContent": [{"text": "Answering questions based on a particular text requires a diverse skill set.", "labels": [], "entities": [{"text": "Answering questions based on a particular text", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.8444747839655194}]}, {"text": "It requires look-up ability, ability to deduce, ability to perform simple mathematical operations (e.g. to answer questions like how many times did the following word occur?), ability to merge information contained in multiple sentences.", "labels": [], "entities": []}, {"text": "This diverse skill set makes question answering a challenging task.", "labels": [], "entities": [{"text": "question answering", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.8785030245780945}]}, {"text": "Question Answering (QA) has seen a great surge of more challenging datasets and novel architectures in recent times.", "labels": [], "entities": [{"text": "Question Answering (QA)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9089405179023743}]}, {"text": "Question Answering task may require the system to reason over few sentences (, table, Wikipedia passage (), lesson (.", "labels": [], "entities": [{"text": "Question Answering task", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7788831194241842}]}, {"text": "Increase in the size of the datasets has allowed researchers to explore different neural network architectures ( for this task.", "labels": [], "entities": []}, {"text": "Given a question based on a text, the model needs to attend to a specific portion of the text in order to answer the question.", "labels": [], "entities": []}, {"text": "Hence, the use of attention mechanism ( ) is common in these architectures.", "labels": [], "entities": []}, {"text": "Convolutional Neural Networks (CNN) have been shown to be effective for various natural language processing tasks such as sentiment analysis, question classification etc.).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 122, "end_pos": 140, "type": "TASK", "confidence": 0.9406375586986542}, {"text": "question classification", "start_pos": 142, "end_pos": 165, "type": "TASK", "confidence": 0.8226761519908905}]}, {"text": "However for the task of question answering, Long Short Term Memory (LSTM)) based methods are the most common.", "labels": [], "entities": [{"text": "question answering", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.8236950635910034}]}, {"text": "In this paper we build a CNN based model for multiple choice question answering 1 . We show the effectiveness of the proposed model by comparing it with several LSTM-based baselines.", "labels": [], "entities": [{"text": "multiple choice question answering", "start_pos": 45, "end_pos": 79, "type": "TASK", "confidence": 0.5948229655623436}]}, {"text": "The main contributions of this paper are (i) The proposed CNN model performs comparatively or better than LSTM-based baselines on two different datasets.", "labels": [], "entities": [{"text": "CNN", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.9343357086181641}]}, {"text": "( (ii) Our model takes question-option tuple to generate a score for the concerned option.", "labels": [], "entities": []}, {"text": "We argue that this is a better strategy than considering questions and options separately for multiple choice question answering.", "labels": [], "entities": [{"text": "multiple choice question answering", "start_pos": 94, "end_pos": 128, "type": "TASK", "confidence": 0.6450254172086716}]}, {"text": "For example, consider the question \"The color of the ball is\" with three options: red, green and yellow.", "labels": [], "entities": []}, {"text": "If the model generates a vector which is to be compared with the three option embeddings, then this might lead to error since the three option embeddings are close to each other.", "labels": [], "entities": []}, {"text": "(iii) We have devised a simple but effective strategy to deal with questions having options like none of the above, two of the above, all of the above, both (a) and (b) etc.", "labels": [], "entities": []}, {"text": "which was not done before.", "labels": [], "entities": []}, {"text": "(iv) Instead of attending on words present in the text, our model attends at sentence level.", "labels": [], "entities": []}, {"text": "This helps the model for answering look-up questions since the necessary information required to answer such questions will often be contained in a single sentence.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}