{"title": [], "abstractContent": [{"text": "Dialogue state tracking, which estimates user goals and requests given the dialogue context, is an essential part of task-oriented dialogue systems.", "labels": [], "entities": [{"text": "Dialogue state tracking", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7526538372039795}]}, {"text": "In this paper , we propose the Global-Locally Self-Attentive Dialogue State Tracker (GLAD), which learns representations of the user utterance and previous system actions with global-local modules.", "labels": [], "entities": [{"text": "Global-Locally Self-Attentive Dialogue State Tracker (GLAD", "start_pos": 31, "end_pos": 89, "type": "TASK", "confidence": 0.6447274472032275}]}, {"text": "Our model uses global modules to share parameters between estimators for different types (called slots) of dialogue states, and uses local modules to learn slot-specific features.", "labels": [], "entities": []}, {"text": "We show that this significantly improves tracking of rare states and achieves state-of-the-art performance on the WoZ and DSTC2 state tracking tasks.", "labels": [], "entities": [{"text": "tracking of rare states", "start_pos": 41, "end_pos": 64, "type": "TASK", "confidence": 0.8269789218902588}, {"text": "WoZ", "start_pos": 114, "end_pos": 117, "type": "DATASET", "confidence": 0.8816462755203247}, {"text": "DSTC2 state tracking", "start_pos": 122, "end_pos": 142, "type": "TASK", "confidence": 0.6713092724482218}]}, {"text": "GLAD obtains 88.1% joint goal accuracy and 97.1% request accuracy on WoZ, outperforming prior work by 3.7% and 5.5%.", "labels": [], "entities": [{"text": "GLAD", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.48589766025543213}, {"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.863447368144989}, {"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.8166356682777405}, {"text": "WoZ", "start_pos": 69, "end_pos": 72, "type": "DATASET", "confidence": 0.9264405369758606}]}, {"text": "On DSTC2, our model obtains 74.5% joint goal accuracy and 97.5% request accuracy, outper-forming prior work by 1.1% and 1.0%.", "labels": [], "entities": [{"text": "DSTC2", "start_pos": 3, "end_pos": 8, "type": "DATASET", "confidence": 0.8877078294754028}, {"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.8297984600067139}, {"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.8252270817756653}]}], "introductionContent": [{"text": "Task oriented dialogue systems can significantly reduce operating costs by automating processes such as call center dispatch and online customer support.", "labels": [], "entities": [{"text": "call center dispatch", "start_pos": 104, "end_pos": 124, "type": "TASK", "confidence": 0.6293895840644836}]}, {"text": "Moreover, when combined with automatic speech recognition systems, task-oriented dialogue systems provide the foundation of intelligent assistants such as Amazon Alexa, Apple Siri, and Google Assistant.", "labels": [], "entities": []}, {"text": "In turn, these assistants allow for natural, personalized interactions with users by tailoring natural language system responses to the dialogue context.", "labels": [], "entities": []}, {"text": "Dialogue state tracking (DST) is a crucial part of dialogue systems.", "labels": [], "entities": [{"text": "Dialogue state tracking (DST)", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8341185847918192}]}, {"text": "In DST, a dialogue state tracker estimates the state of the conversation using the current user utterance and the conversation history.", "labels": [], "entities": [{"text": "DST", "start_pos": 3, "end_pos": 6, "type": "TASK", "confidence": 0.9289770722389221}]}, {"text": "This estimated state is then used by the system to plan the next action and respond to the user.", "labels": [], "entities": []}, {"text": "A state in DST typically consists of a set of requests and joint goals.", "labels": [], "entities": [{"text": "DST", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.9406598806381226}]}, {"text": "Consider the task of restaurant reservation as an example.", "labels": [], "entities": [{"text": "restaurant reservation", "start_pos": 21, "end_pos": 43, "type": "TASK", "confidence": 0.6947713047266006}]}, {"text": "During each turn, the user may inform the system of particular goals the user would like to achieve (e.g. inform(food=french)), or request for more information from the system (e.g. request(address)).", "labels": [], "entities": []}, {"text": "The set of goal and request slot-value pairs (e.g. (food, french), (request, address)) given during a turn are referred to as the turn goal and turn request.", "labels": [], "entities": []}, {"text": "The joint goal is the set of accumulated turn goals up to the current turn.", "labels": [], "entities": []}, {"text": "shows an example dialogue with annotated turn states, in which the user reserves a restaurant.", "labels": [], "entities": []}, {"text": "Traditional dialogue state trackers rely on Spoken Language Understanding (SLU) systems () in order to understand user utterances.", "labels": [], "entities": [{"text": "dialogue state trackers", "start_pos": 12, "end_pos": 35, "type": "TASK", "confidence": 0.699036588271459}]}, {"text": "These trackers accumulate errors from the SLU, which sometimes do not have the necessary dialogue context to interpret the user utterances.", "labels": [], "entities": []}, {"text": "Subsequent DST research forgo the SLU and directly infer the state using the conversation history and the user utterance).", "labels": [], "entities": []}, {"text": "These trackers rely on handcrafted semantic dictionaries and delexicalization -the anonymization of slots and values using generic tags -to achieve generalization.", "labels": [], "entities": []}, {"text": "Recent work by Mrk\u0161i\u00b4  apply representation learning using convolutional neural networks to learn features relevant for each state as opposed to hand-crafting features.", "labels": [], "entities": [{"text": "representation learning", "start_pos": 29, "end_pos": 52, "type": "TASK", "confidence": 0.9234517514705658}]}, {"text": "A key problem in DST that is not addressed by existing methods is the extraction of rare slotvalue pairs that compose the state during each turn.", "labels": [], "entities": [{"text": "DST", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.9837048649787903}]}, {"text": "Because task oriented dialogues cover large", "labels": [], "entities": []}], "datasetContent": [{"text": "The Dialogue Systems Technology Challenges (DSTC) provides a common framework for developing and evaluating dialogue systems and dialogue state trackers (.", "labels": [], "entities": [{"text": "Dialogue Systems Technology Challenges (DSTC)", "start_pos": 4, "end_pos": 49, "type": "TASK", "confidence": 0.6253551925931659}]}, {"text": "Under this framework, dialogue semantics such as states and actions are based on a task ontology such as restaurant reservation.", "labels": [], "entities": [{"text": "restaurant reservation", "start_pos": 105, "end_pos": 127, "type": "TASK", "confidence": 0.6890622824430466}]}, {"text": "During each turn, the user may inform the system of particular goals (e.g. inform(food=french)), or request for more information from the system (e.g. request(address)).", "labels": [], "entities": []}, {"text": "For instance, food and area are examples of slots in the DSTC2 task, and french and chinese are example values within the food slot.", "labels": [], "entities": [{"text": "DSTC2 task", "start_pos": 57, "end_pos": 67, "type": "TASK", "confidence": 0.6026473939418793}]}, {"text": "We train and evaluate our model using DSTC2 as well as the Wizard of Oz (WoZ) restaurant reservation task ( , which also adheres to the DSTC framework and has the same ontology as DSTC2.", "labels": [], "entities": [{"text": "DSTC2", "start_pos": 38, "end_pos": 43, "type": "DATASET", "confidence": 0.8935163021087646}, {"text": "Wizard of Oz (WoZ) restaurant reservation task", "start_pos": 59, "end_pos": 105, "type": "TASK", "confidence": 0.7532055675983429}]}, {"text": "For DSTC2, it is standard to evaluate using the N-best list of the automatic speech recognition system (ASR) that is included with the dataset.", "labels": [], "entities": []}, {"text": "Because of this, each turn in the DSTC2 dataset contains several noisy ASR outputs instead of a noise-free user utterance.", "labels": [], "entities": [{"text": "DSTC2 dataset", "start_pos": 34, "end_pos": 47, "type": "DATASET", "confidence": 0.9470120966434479}]}, {"text": "The WoZ task does not provide ASR outputs, and we instead train and evaluate using the user utterance.", "labels": [], "entities": [{"text": "ASR", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.8725751042366028}]}], "tableCaptions": [{"text": " Table 1: Test accuracies on the DSTC2 and WoZ restaurant reservation datasets. The other models  are: delexicalisation DSTC2 (Henderson et al., 2014b), delexicalisation WoZ (Wen et al., 2017), and  NBT (Mrk\u0161i\u00b4Mrk\u0161i\u00b4c et al., 2017). We run 10 models using random seeds with early stopping on the development  set, and report the mean and standard deviation test accuracies for each dataset.", "labels": [], "entities": [{"text": "WoZ restaurant reservation datasets", "start_pos": 43, "end_pos": 78, "type": "DATASET", "confidence": 0.695588544011116}, {"text": "DSTC2", "start_pos": 120, "end_pos": 125, "type": "DATASET", "confidence": 0.9018235206604004}, {"text": "NBT", "start_pos": 199, "end_pos": 202, "type": "DATASET", "confidence": 0.9009319543838501}, {"text": "standard deviation test accuracies", "start_pos": 338, "end_pos": 372, "type": "METRIC", "confidence": 0.8092033118009567}]}, {"text": " Table 2: Ablation study showing turn goal, joint  goal, and turn request accuracies on the dev. split  of the WoZ dataset. For \"-self-attn\", we use mean- pooling instead of self-attention. For \"-LSTM\",  we compute self-attention over word embeddings.", "labels": [], "entities": [{"text": "WoZ dataset", "start_pos": 111, "end_pos": 122, "type": "DATASET", "confidence": 0.9784492552280426}]}]}