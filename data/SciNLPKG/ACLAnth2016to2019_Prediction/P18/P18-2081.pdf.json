{"title": [{"text": "Party Matters: Enhancing Legislative Embeddings with Author Attributes for Vote Prediction", "labels": [], "entities": [{"text": "Vote Prediction", "start_pos": 75, "end_pos": 90, "type": "TASK", "confidence": 0.820977658033371}]}], "abstractContent": [{"text": "Predicting how Congressional legislators will vote is important for understanding their past and future behavior.", "labels": [], "entities": []}, {"text": "However , previous work on roll-call prediction has been limited to single session settings , thus did not consider generalization across sessions.", "labels": [], "entities": [{"text": "roll-call prediction", "start_pos": 27, "end_pos": 47, "type": "TASK", "confidence": 0.8806573748588562}]}, {"text": "In this paper, we show that metadata is crucial for modeling voting outcomes in new contexts, as changes between sessions lead to changes in the underlying data generation process.", "labels": [], "entities": []}, {"text": "We show how augmenting bill text with the sponsors' ideologies in a neural network model can achieve an average of a 4% boost inaccuracy over the previous state-of-the-art.", "labels": [], "entities": []}], "introductionContent": [{"text": "Quantitative analysis of the voting behavior of legislators has long been a problem of interest in political science, and recently in NLP as well.", "labels": [], "entities": [{"text": "Quantitative analysis of the voting behavior", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.9027144511540731}]}, {"text": "One of the most popular techniques in political science for modeling legislator behavior is the application of spatial, or ideal point, models built from voting records (, that are often used to represent uni-dimensional or multi-dimensional ideological stances.", "labels": [], "entities": []}, {"text": "While roll call votes (i.e Congressional voting records) provide explanatory power about a legislators position with respect to previously voted-on bills, these models are limited to in-sample analysis, and are thus incapable of predicting votes on new bills.", "labels": [], "entities": []}, {"text": "To address this limitation, recent work has introduced methods that take advantage the text of the bill, along with the voting records, to model Congressional voting behavior (.", "labels": [], "entities": []}, {"text": "This work is related to along line of studies on using political text to model behavior, ranging over political books, Supreme Court decisions, speeches and Twitter;.", "labels": [], "entities": []}, {"text": "In addition to enabling prediction, associating text with ideology allows fora further degree of interpretability.", "labels": [], "entities": [{"text": "prediction", "start_pos": 24, "end_pos": 34, "type": "TASK", "confidence": 0.9757827520370483}]}, {"text": "However, all previous work incorporating text into roll call prediction have limited their evaluation to in-session training and testing.", "labels": [], "entities": [{"text": "roll call prediction", "start_pos": 51, "end_pos": 71, "type": "TASK", "confidence": 0.8222324450810751}]}, {"text": "As legislators typically serve for multiple sessions, and similar bills are proposed across sessions, we want to be able to leverage this data across sessions to inform our model.", "labels": [], "entities": []}, {"text": "However, the generalizability of previous methods to a crosssession setting is unknown.", "labels": [], "entities": []}, {"text": "In this work, we explore the problem of roll call prediction across sessions.", "labels": [], "entities": [{"text": "roll call prediction", "start_pos": 40, "end_pos": 60, "type": "TASK", "confidence": 0.7963919242223104}]}, {"text": "We show that previous methods are unable to generalize across sessions, thus suggesting that current text representations are not sufficient for modeling voting outcomes in new contexts.", "labels": [], "entities": []}, {"text": "We hypothesize that each session has a different underlying data generation process, wherein the ideological position of the observed bills varies depending on the controlling party.", "labels": [], "entities": []}, {"text": "This is supported by the observation that about 75% of bills up fora vote in a given session have a sponsor in the party in power.", "labels": [], "entities": []}, {"text": "As noted in, the policy area, or topic, of the bill, and the ideological position, are two separate dimensions underlying the text.", "labels": [], "entities": []}, {"text": "Since legislators tend to sponsor bills that are ideologically aligned with them, a model trained on a single session will mostly be exposed to bills with a specific ideology on each topic.", "labels": [], "entities": []}, {"text": "Thus, a single session model may get the ideology information as an implicit prior without needing to explicitly capture it.", "labels": [], "entities": []}, {"text": "This challenge was not obvious in previous studies that were limited to a single session.", "labels": [], "entities": []}, {"text": "Across sessions, however, the ideological prior on a given topic changes, resulting in variations in voting patterns that are not captured by current text modeling methodologies alone.", "labels": [], "entities": []}, {"text": "In applications where the text may contain an insufficient signal, researchers may turn to additional metadata features.", "labels": [], "entities": []}, {"text": "This technique has previously been used in various contexts, such as incorporating sponsor and committee features for predicting bill committee survival (, and enhancing tweet recommendations with location data.", "labels": [], "entities": [{"text": "predicting bill committee survival", "start_pos": 118, "end_pos": 152, "type": "TASK", "confidence": 0.6608529388904572}]}, {"text": "We propose a neural architecture that directly models the ideological variation across sessions using metadata about the bill sponsors, and show that this can strongly improve performance with little overhead to complexity and training time.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our dataset was collected from GovTrack, and consists of nonunanimous roll call votes and texts of resolutions and bills introduced in the 106th to 111th Congressional sessions.", "labels": [], "entities": [{"text": "GovTrack", "start_pos": 31, "end_pos": 39, "type": "DATASET", "confidence": 0.9422433376312256}]}, {"text": "We also collect the bill summaries written by the Congressional Research Service 6 (a non-partisan organization), that provide shorter descriptions of the key actions in each bill.", "labels": [], "entities": [{"text": "Congressional Research Service 6", "start_pos": 50, "end_pos": 82, "type": "DATASET", "confidence": 0.8467064648866653}]}, {"text": "All text is preprocessed by lowercasing and removing stop-words.", "labels": [], "entities": []}, {"text": "As bills are often much longer than the typical document encountered in other NLP tasks, with an average of 2683 words per bill, and some bills having hundreds of pages, with correspondingly 4 https://theunitedstates.io/ We exclude bills with unanimous votes because these are typically associated with routine matters (for example, the naming a post office or an official commendation) that do not contain ideological motivation.", "labels": [], "entities": [{"text": "naming a post office or an official commendation)", "start_pos": 337, "end_pos": 386, "type": "TASK", "confidence": 0.8560930490493774}]}, {"text": "We consider bills where less than 1% of legislators voted 'no' to be unanimous; about 42% of bills fall into this category.: Party in power by session lengthy summaries, this poses a problem for our compositional neural architecture.", "labels": [], "entities": []}, {"text": "To address this, we limit the length of each full-text and summary to N words, where N is empirically set to the 80 th percentile of the collection.", "labels": [], "entities": []}, {"text": "For summaries N =400, and for full-text N =2000.", "labels": [], "entities": []}, {"text": "As described earlier, the experimental framework in previous work treated each session individually.", "labels": [], "entities": []}, {"text": "To evaluate the ability of our model to generalize across sessions, we perform several sets of experiments.", "labels": [], "entities": []}, {"text": "In the first set, in-session, we perform 5 fold cross-validation over the 2005-2012 sessions.", "labels": [], "entities": []}, {"text": "In the second, out-of-session, we train on multiple sessions, 2005-2012, and evaluate on sessions not included during training, the sessions.", "labels": [], "entities": []}, {"text": "During testing, we only include legislators present in the training data.", "labels": [], "entities": []}, {"text": "The overall statistics for our dataset are presented in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Count of Bills and Votes", "labels": [], "entities": [{"text": "Count", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9830991625785828}]}, {"text": " Table 2: Party in power by session", "labels": [], "entities": []}]}