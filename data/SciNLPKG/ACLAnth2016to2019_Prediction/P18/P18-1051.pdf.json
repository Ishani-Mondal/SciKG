{"title": [{"text": "Text Deconvolution Saliency (TDS): a deep toolbox for linguistic analysis", "labels": [], "entities": [{"text": "Text Deconvolution Saliency (TDS)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8092803955078125}]}], "abstractContent": [{"text": "In this paper, we propose anew strategy , called Text Deconvolution Saliency (TDS), to visualize linguistic information detected by a CNN for text classification.", "labels": [], "entities": [{"text": "Text Deconvolution Saliency (TDS)", "start_pos": 49, "end_pos": 82, "type": "TASK", "confidence": 0.7308841645717621}, {"text": "text classification", "start_pos": 142, "end_pos": 161, "type": "TASK", "confidence": 0.7509060800075531}]}, {"text": "We extend Deconvolution Networks to text in order to present anew perspective on text analysis to the linguistic community.", "labels": [], "entities": [{"text": "text analysis", "start_pos": 81, "end_pos": 94, "type": "TASK", "confidence": 0.7479048371315002}]}, {"text": "We empirically demonstrated the efficiency of our Text Decon-volution Saliency on corpora from three different languages: English, French, and Latin.", "labels": [], "entities": []}, {"text": "For every tested dataset, our Text Deconvolution Saliency automatically encodes complex linguistic patterns based on co-occurrences and possibly on grammatical and syntax analysis.", "labels": [], "entities": []}], "introductionContent": [{"text": "As in many other fields of data analysis, Natural Language Processing (NLP) has been strongly impacted by the recent advances in Machine Learning, more particularly with the emergence of Deep Learning techniques.", "labels": [], "entities": [{"text": "Natural Language Processing (NLP)", "start_pos": 42, "end_pos": 75, "type": "TASK", "confidence": 0.8061098357041677}]}, {"text": "These techniques outperform all other state-of-the-art approaches on a wide range of NLP tasks and so they have been quickly and intensively used in industrial systems.", "labels": [], "entities": []}, {"text": "Such systems rely on end-to-end training on large amounts of data, making no prior assumptions about linguistic structure and focusing on stastically frequent patterns.", "labels": [], "entities": []}, {"text": "Thus, they somehow step away from computational linguistics as they learn implicit linguistic information automatically without aiming at explaining or even exhibiting classic linguistic structures underlying the decision.", "labels": [], "entities": []}, {"text": "This is the question we raise in this article and that we intend to address by exhibiting classic lin- * L.", "labels": [], "entities": []}, {"text": "Vanni and M. Ducoffe contributed equally to this work and should be considered as co-first authors.", "labels": [], "entities": []}, {"text": "guistic patterns which are indeed exploited implictly in deep architectures to lead to higher performances.", "labels": [], "entities": []}, {"text": "Do neural networks make use of cooccurrences and other standard features, considered in traditional Textual Data Analysis (TDA) (Textual Mining)?", "labels": [], "entities": []}, {"text": "Do they also rely on complementary linguistic structure which is invisible to traditional techniques?", "labels": [], "entities": []}, {"text": "If so, projecting neural networks features back onto the input space would highlight new linguistic structures and would lead to improving the analysis of a corpus and a better understanding on where the power of the Deep Learning techniques comes from.", "labels": [], "entities": []}, {"text": "Our hypothesis is that Deep Learning is sensitive to the linguistic units on which the computation of the key statistical sentences is based as well as to phenomena other than frequency and complex linguistic observables.", "labels": [], "entities": []}, {"text": "The TDA has more difficulty taking such elements into account -such as linguistic linguistic patterns.", "labels": [], "entities": [{"text": "TDA", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.8940951228141785}]}, {"text": "Our contribution confronts Textual Data Analysis and Convolutional Neural Networks for text analysis.", "labels": [], "entities": [{"text": "Textual Data Analysis", "start_pos": 27, "end_pos": 48, "type": "TASK", "confidence": 0.622902492682139}, {"text": "text analysis", "start_pos": 87, "end_pos": 100, "type": "TASK", "confidence": 0.7691513895988464}]}, {"text": "We take advantage of deconvolution networks for image analysis in order to present anew perspective on text analysis to the linguistic community that we call Text Deconvolution Saliency (TDS).", "labels": [], "entities": [{"text": "image analysis", "start_pos": 48, "end_pos": 62, "type": "TASK", "confidence": 0.7435347139835358}, {"text": "text analysis", "start_pos": 103, "end_pos": 116, "type": "TASK", "confidence": 0.7099941819906235}, {"text": "Text Deconvolution Saliency (TDS)", "start_pos": 158, "end_pos": 191, "type": "TASK", "confidence": 0.6454515308141708}]}, {"text": "Our deconvolution saliency corresponds to the sum over the word embedding of the deconvolution projection of a given feature map.", "labels": [], "entities": []}, {"text": "Such a score provides a heat-map of words in a sentence that highlights the pattern relevant for the classification decision.", "labels": [], "entities": []}, {"text": "We examine z-test (see section 4.2) and TDS for three languages: English, French and Latin.", "labels": [], "entities": [{"text": "TDS", "start_pos": 40, "end_pos": 43, "type": "DATASET", "confidence": 0.5236124992370605}]}, {"text": "For all our datasets, TDS highlights new linguistic observables, invisible with z-test alone.", "labels": [], "entities": [{"text": "TDS", "start_pos": 22, "end_pos": 25, "type": "DATASET", "confidence": 0.6651324033737183}]}], "datasetContent": [{"text": "In order to understand what the linguistic markers found by the convolutional neural network approach are, we conducted several tests on different languages and our model seems to get the same behavior in all of them.", "labels": [], "entities": []}, {"text": "In order to perform all the linguistic statistical tests, we used our own simple linguistic toolbox Hyperbase, which allows the creation of databases from textual corpus, the analysis and the calculations such as z-test, cooccurrences, PCA, K-Means distance,...", "labels": [], "entities": []}, {"text": "We use it to evaluate TDS against z-test scoring.", "labels": [], "entities": [{"text": "TDS", "start_pos": 22, "end_pos": 25, "type": "METRIC", "confidence": 0.5857129693031311}]}, {"text": "We compel our analysis by only presenting cases on which ztest fail while TDS does not.", "labels": [], "entities": [{"text": "TDS", "start_pos": 74, "end_pos": 77, "type": "DATASET", "confidence": 0.8200992345809937}]}, {"text": "Indeed TDS captures z-test, as we did not find any sentence on which z-test succeeds while TDS fails.", "labels": [], "entities": []}, {"text": "Red words in the studied examples are the highest TDS.", "labels": [], "entities": [{"text": "TDS", "start_pos": 50, "end_pos": 53, "type": "METRIC", "confidence": 0.9793939590454102}]}, {"text": "The first dataset we used for our experiments is the well known IMDB movie review corpus for sentiment classification.", "labels": [], "entities": [{"text": "IMDB movie review corpus", "start_pos": 64, "end_pos": 88, "type": "DATASET", "confidence": 0.8542915731668472}, {"text": "sentiment classification", "start_pos": 93, "end_pos": 117, "type": "TASK", "confidence": 0.9548698365688324}]}, {"text": "It consists of 25,000 reviews labeled by positive or negative sentiment with around 230,000 words.", "labels": [], "entities": []}, {"text": "The second dataset targets French political discourses.", "labels": [], "entities": []}, {"text": "It is a corpus of 2.5 millions of words of French Presidents from 1958 (with De Gaulle, the first President of the Fifth Republic) to 2018 with the first speeches by Macron.", "labels": [], "entities": []}, {"text": "In this corpus we have removed Macron's speech from the 31st of December 2017, to use it as a test data set.", "labels": [], "entities": [{"text": "Macron's speech from the 31st of December 2017", "start_pos": 31, "end_pos": 77, "type": "DATASET", "confidence": 0.9299801919195387}]}, {"text": "The training task is to recognize each french president.", "labels": [], "entities": []}, {"text": "The last dataset we used is based on Latin.", "labels": [], "entities": []}, {"text": "We assembled a contrastive corpus of 2 million words with 22 principle authors writting in classical Latin.", "labels": [], "entities": []}, {"text": "As with the French dataset, the learning task here is to be able to  For English, we used the IMDB movie review corpus for sentiment classification.", "labels": [], "entities": [{"text": "French dataset", "start_pos": 12, "end_pos": 26, "type": "DATASET", "confidence": 0.8778509497642517}, {"text": "IMDB movie review corpus", "start_pos": 94, "end_pos": 118, "type": "DATASET", "confidence": 0.9069677144289017}, {"text": "sentiment classification", "start_pos": 123, "end_pos": 147, "type": "TASK", "confidence": 0.9688438475131989}]}, {"text": "With the default methods, we can easily show the specific vocabulary of each class (positive/negative), according to the z-test.", "labels": [], "entities": []}, {"text": "There are for example the words too, bad, no or boring as most indicitive of negative sentiment, and the words and, performance, powerful or best for positive.", "labels": [], "entities": []}, {"text": "Is it enough to detect automatically if anew review is positive or not?", "labels": [], "entities": []}, {"text": "Let's see an example excerpted from a review from December 2017 (not in the training set) on the last American blockbuster: [...] i enjoyed three moments in the film in total , and if i am being honest and the person next tome fell asleep in the middle and started snoring during the slow space chasescenes . the story failed to draw me in and entertain me the way In general the z-test is sufficient to predict the class of this kind of comment.", "labels": [], "entities": []}, {"text": "But in this case, the CNN seems to do better, but why?", "labels": [], "entities": [{"text": "CNN", "start_pos": 22, "end_pos": 25, "type": "DATASET", "confidence": 0.9137169718742371}]}, {"text": "If we sum all the z-test (for negative and positive), the positive class obtains a greater score than the negative.", "labels": [], "entities": []}, {"text": "The words film, and, honest and entertain -with scores 5.38, 12.23, 4 and 2.4 -make this example positive.", "labels": [], "entities": []}, {"text": "CNN has activated different parts of this sentence (as we show in bold/red in the example).", "labels": [], "entities": [{"text": "CNN", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9692884683609009}]}, {"text": "If we take the sub-sequence and if i am being honest and, there are two occurences of and but the first one is followed by if and our toolbox gives us 0.84 for and if as a negative class.", "labels": [], "entities": []}, {"text": "This is far from the 12.23 in the positive.", "labels": [], "entities": []}, {"text": "And if we go further, we can do a co-occurrence analysis on and if on the training set.", "labels": [], "entities": []}, {"text": "As we see with our co-occurrence analysis, honest is among the most specific adjectivals 5 associated with and if.", "labels": [], "entities": []}, {"text": "Exactly what we found in our example.", "labels": [], "entities": []}, {"text": "In addition, we have the same behavior with the verb fall.", "labels": [], "entities": []}, {"text": "There is the word asleep next to it.", "labels": [], "entities": []}, {"text": "Asleep alone is not really specific of negative review (z-test of 1.13).", "labels": [], "entities": []}, {"text": "But the association of both words become highly specific of negative sentences (see the co-occurrences analysis -).", "labels": [], "entities": []}, {"text": "Those figures shows the major co-occurrences fora given word (or lemma or PartOfSpeech).", "labels": [], "entities": [{"text": "PartOfSpeech", "start_pos": 74, "end_pos": 86, "type": "DATASET", "confidence": 0.9180062413215637}]}, {"text": "There two layers of co-occurrences, the first one (on top) show the direct cooccurrence and the second (on bottom) show a second level of co-occurrence.", "labels": [], "entities": []}, {"text": "This level is given by the context of two words (taken together).", "labels": [], "entities": []}, {"text": "The colors and the dotted lines are only used to make it more readable (dotted lines are used for the first level).", "labels": [], "entities": []}, {"text": "The width of each line is related to the z-test score (more the z-test is big, more the line is wide).", "labels": [], "entities": []}, {"text": "With our toolbox, we can focus on different part of speech.", "labels": [], "entities": []}, {"text": "The Text Deconvolution Saliency here confirms that the CNN seems to focus not only on high ztest but on more complex patterns and maybe detects the lemma or the part of speech linked to each word.", "labels": [], "entities": []}, {"text": "We will see now that these observations are still valid for other languages and can even be generalized between different TDS.", "labels": [], "entities": []}, {"text": "In this corpus we have removed Macron's speech from the 31st of December 2017, to use it as a test data set.", "labels": [], "entities": [{"text": "Macron's speech from the 31st of December 2017", "start_pos": 31, "end_pos": 77, "type": "DATASET", "confidence": 0.9299801919195387}]}, {"text": "In this speech, the CNN primarily recognizes Macron (the training task was to be able to predict the correct President).", "labels": [], "entities": []}, {"text": "To achieve this task the CNN seems to succeed in finding really complex patterns specific to Macron.", "labels": [], "entities": []}, {"text": "For example in this sequence: [...] notre pays advienn\u00e8 a l'\u00b4 ecole pour nos enfants, au travail pour l' ensemble de nos concitoyens pour le climat pour le quotidien de chacune et chacun d' entre vous . Ces transformations profondes ont commenc\u00e9 et se poursuivront avec la m\u00eame force le m\u00eame rythme la m\u00eame intensit\u00e9 [...]", "labels": [], "entities": []}, {"text": "The z-test gives a result statistically closer to De Gaulle than to Macron.", "labels": [], "entities": []}, {"text": "The error in the statistical attribution can be explained by a Gaullist phraseology and the multiplication of linguistic markers strongly indexed with De Gaulle: De Gaulle had the specificity of making long and literary sentences articulated around co-ordination conjunctions as in et (z-test = 28 for de Gaulle, two oc- currences in the excerpt).", "labels": [], "entities": []}, {"text": "His speech was also more conceptual than average, and this resulted in an over-use of the articles defined le, la, l\u00b4, les) very numerous in the excerpt (7 occurrences); especially in the feminine singular (la r\u00e9publique, la libert\u00e9, la nation, la guerre, etc., here we have la m\u00eame force, la m\u00eame intensit\u00e9.", "labels": [], "entities": []}, {"text": "The best results given by the CNN maybe surprising fora linguist but match perfectly with what is known about the sociolinguistics of Macron's dynamic kind of speeches.", "labels": [], "entities": []}, {"text": "The part of the excerpt, which impacts most the CNN classification, is related to the nominal syntagm transformations profondes.", "labels": [], "entities": [{"text": "CNN classification", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.507418617606163}]}, {"text": "Taken separately, neither of the phrase's two words are very Macronian from a statistical point of view (transformations = 1.9 profondes = 2.9).", "labels": [], "entities": []}, {"text": "Better, the syntagm itself does not appear in the President's learning corpus (0 occurrence).", "labels": [], "entities": [{"text": "President's learning corpus", "start_pos": 50, "end_pos": 77, "type": "DATASET", "confidence": 0.8915208578109741}]}, {"text": "However, it can be seen that the co-occurrence of transformation and profondes amounts to 4.81 at Macron: so it is not the occurrence of one word alone, or the other, which is Macronian but the simultaneous appearance of both in the same window.", "labels": [], "entities": []}, {"text": "The second and complementary most impacting part of the excerpt thus is related to the two verbs advienne and poursuivront.", "labels": [], "entities": []}, {"text": "From a semantic point of view, the two verbs perfectly contribute, after the phrase transformations profondes, to give the necessary dynamic to a discourse that advocates change.", "labels": [], "entities": []}, {"text": "However it is the verb tenses (carried by the morphology of the verbs) that appear to be the determining factor in the analysis.", "labels": [], "entities": []}, {"text": "The calculation of the grammatical codes co-occurring with the word transformations thus indicates that the verbs in the subjunctive and the verbs in the future (and also the nouns) are the privileged codes for Macron).", "labels": [], "entities": [{"text": "Macron", "start_pos": 211, "end_pos": 217, "type": "DATASET", "confidence": 0.9153504371643066}]}, {"text": "More precisely the algorithm indicates that, for Macron, when transformation is associated with a verb in the subjunctive (here advienne), then there is usually a verb in the future co-present (here poursuivront).", "labels": [], "entities": []}, {"text": "transformations profondes, advienne to the subjunctive, poursuivront to the future: all these elements together form a speech promising action, from the mouth of a young and dynamic President.", "labels": [], "entities": []}, {"text": "Finally, the graph indicates that transformations is especially associated with nouns in the President's speeches: in an extraordinary concentration, the excerpt lists 11 (pays, \u00b4 ecole, enfants, travail, concitoyens, climat, quotidien, transformations, force, rythme, intensit\u00e9).", "labels": [], "entities": [{"text": "rythme", "start_pos": 261, "end_pos": 267, "type": "METRIC", "confidence": 0.9529280066490173}]}, {"text": "As with the French dataset, the learning task here is to be able to predict the identity of each author from a contrastive corpus of 2 million words with 22 principle authors writting in classical Latin.", "labels": [], "entities": [{"text": "French dataset", "start_pos": 12, "end_pos": 26, "type": "DATASET", "confidence": 0.8765414357185364}]}, {"text": "The statistics here identify this sentence as Caesar 6 but Livy is not far off.", "labels": [], "entities": []}, {"text": "As historians, Caesar and Livy share a number of specific words: for example tool words like se (reflexive pronoun) or que (a coordinator) and prepositions like in, ad, ex, of.", "labels": [], "entities": []}, {"text": "There are also nouns like equites (cavalry) or castra (fortified camp).", "labels": [], "entities": []}, {"text": "The attribution of the sentence to Caesar cannot only rely only on z-test: que or in or castra, with differences thereof equivalent or inferior to Livy.", "labels": [], "entities": []}, {"text": "On the other hand, the differences of se, ex, are greater, as is that of equites.", "labels": [], "entities": []}, {"text": "Two very Caesarian terms undoubtedly make the difference iubet (he orders) and milia (thousands).", "labels": [], "entities": []}, {"text": "The greater score of quattuor (four), castra, hostem (the enemy), impetu (the assault) in Livy are not enough to switch the attribution to this author.", "labels": [], "entities": []}, {"text": "On the other hand, CNN activates several zones appearing at the beginning of sentences and corresponding to coherent syntactic structures (for Livy) -Tandem reflexes spe castra propius hostem mouit (then, hope having finally returned, he moved the camp closer to the camp of the enemy) -despite the fact that castra in hostem mouit is attested only by Tacitus . There are also in ipso metu (in fear itself), while in followed by metu is counted onetime with Caesar and onetime also with Quinte-Curce 8 . More complex structures are possibly also detected by the CNN: the structure tum + participates Ablative Absolute (tum refecta) is more characteristic of Livy (z-test 3.3 with 8 occurrences) than of Caesar (z-test 1.7 with 3 occurrences), even if it is even more specific of Tacitus (z-test 4.2 with 10 occurrences).", "labels": [], "entities": [{"text": "Ablative Absolute (tum refecta)", "start_pos": 600, "end_pos": 631, "type": "METRIC", "confidence": 0.8969681362311045}]}, {"text": "Finally and more likely, the co-occurrence between castra, hostem and impetu may have played a major role: Figure 8 With Livy, impetu appears as a co-occurrent 7 Publius (or Gaius) Cornelius Tacitus, 56 BC -120 BC, was a senator and a historian of the Roman Empire.", "labels": [], "entities": [{"text": "Publius (or Gaius) Cornelius Tacitus, 56 BC -120 BC", "start_pos": 162, "end_pos": 213, "type": "TASK", "confidence": 0.6912347215872544}]}, {"text": "8 Quintus Curtius Rufus was a Roman historian, probably of the 1st century, his only known and only surviving work being \"Histories of Alexander the Great\" with the lemmas hostis (z-test 9.42) and castra (ztest 6.75), while hostis only has a gap of 3.41 in Caesar and that castra does not appear in the list of co-occurrents.", "labels": [], "entities": []}, {"text": "For castra, the first co-occurent for Livy is hostis (z-test 22.72), before castra (z-test 10.18), ad (z-test 10.85), in (z-test 8.21), impetus (z-test 7.35), que (z-test 5.86) while in Caesar, impetus does not appear and the scores of all other lemmas are lower except castra (z-test, in (5,17), que (4.79).", "labels": [], "entities": [{"text": "que", "start_pos": 159, "end_pos": 162, "type": "METRIC", "confidence": 0.9548284411430359}]}, {"text": "Thus, our results suggest that CNNs manage to account for specificity, phrase structure, and cooccurence networks.", "labels": [], "entities": []}], "tableCaptions": []}