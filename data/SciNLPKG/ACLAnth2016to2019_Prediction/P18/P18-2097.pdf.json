{"title": [{"text": "An Empirical Study of Building a Strong Baseline for Constituency Parsing", "labels": [], "entities": [{"text": "Constituency Parsing", "start_pos": 53, "end_pos": 73, "type": "TASK", "confidence": 0.836279571056366}]}], "abstractContent": [{"text": "This paper investigates the construction of a strong baseline based on general purpose sequence-to-sequence models for constituency parsing.", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 119, "end_pos": 139, "type": "TASK", "confidence": 0.8726238906383514}]}, {"text": "We incorporate several techniques that were mainly developed in natural language generation tasks, e.g., machine translation and summariza-tion, and demonstrate that the sequence-to-sequence model achieves the current top-notch parsers' performance without requiring explicit task-specific knowledge or architecture of constituent parsing.", "labels": [], "entities": [{"text": "natural language generation tasks", "start_pos": 64, "end_pos": 97, "type": "TASK", "confidence": 0.7586713433265686}, {"text": "machine translation", "start_pos": 105, "end_pos": 124, "type": "TASK", "confidence": 0.8282922506332397}]}], "introductionContent": [{"text": "Sequence-to-sequence (Seq2seq) models have successfully improved many well-studied NLP tasks, especially for natural language generation (NLG) tasks, such as machine translation (MT)) and abstractive summarization ().", "labels": [], "entities": [{"text": "natural language generation (NLG) tasks", "start_pos": 109, "end_pos": 148, "type": "TASK", "confidence": 0.8185021536690849}, {"text": "machine translation (MT))", "start_pos": 158, "end_pos": 183, "type": "TASK", "confidence": 0.8468809127807617}, {"text": "abstractive summarization", "start_pos": 188, "end_pos": 213, "type": "TASK", "confidence": 0.6756244897842407}]}, {"text": "Seq2seq models have also been applied to constituency parsing and provided a fairly good result.", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 41, "end_pos": 61, "type": "TASK", "confidence": 0.9147468209266663}]}, {"text": "However one obvious, intuitive drawback of Seq2seq models when they are applied to constituency parsing is that they have no explicit architecture to model latent nested relationships among the words and phrases in constituency parse trees, Thus, models that directly model them, such as RNNG (, are an intuitively more promising approach.", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 83, "end_pos": 103, "type": "TASK", "confidence": 0.8879483938217163}]}, {"text": "In fact, RNNG and its extensions () provide the current stateof-the-art performance.", "labels": [], "entities": [{"text": "RNNG", "start_pos": 9, "end_pos": 13, "type": "DATASET", "confidence": 0.7685439586639404}]}, {"text": "Sec2seq models are currently considered a simple baseline of neuralbased constituency parsing.", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 73, "end_pos": 93, "type": "TASK", "confidence": 0.7747557461261749}]}, {"text": "After the first proposal of an Seq2seq constituency parser, many task-independent techniques have been developed, mainly in the NLG research area.", "labels": [], "entities": [{"text": "Seq2seq constituency parser", "start_pos": 31, "end_pos": 58, "type": "TASK", "confidence": 0.6018881897131602}, {"text": "NLG research area", "start_pos": 128, "end_pos": 145, "type": "DATASET", "confidence": 0.8686767816543579}]}, {"text": "Our aim is to update the Seq2seq approach proposed in as a stronger baseline of constituency parsing.", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 80, "end_pos": 100, "type": "TASK", "confidence": 0.7984324991703033}]}, {"text": "Our motivation is basically identical to that described in.", "labels": [], "entities": []}, {"text": "A strong baseline is crucial for reporting reliable experimental results.", "labels": [], "entities": []}, {"text": "It offers a fair evaluation of promising new techniques if they solve new issues or simply resolve issues that have already been addressed by current generic technology.", "labels": [], "entities": []}, {"text": "More specifically, it might become possible to analyze what types of implicit linguistic structures are easier or harder to capture for neural models by comparing the outputs of strong Seq2seq models and task-specific models, e.g., RNNG.", "labels": [], "entities": []}, {"text": "The contributions of this paper are summarized as follows: (1) a strong baseline for constituency parsing based on general purpose Seq2seq models 1 , (2) an empirical investigation of several generic techniques that can (or cannot) contribute to improve the parser performance, (3) empirical evidence that Seq2seq models implicitly learn parse tree structures well without knowing taskspecific and explicit tree structure information.", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 85, "end_pos": 105, "type": "TASK", "confidence": 0.8611316680908203}]}], "datasetContent": [{"text": "Our experiments used the English Penn Treebank data, which are the most widely used benchmark data in the literature.", "labels": [], "entities": [{"text": "English Penn Treebank data", "start_pos": 25, "end_pos": 51, "type": "DATASET", "confidence": 0.9397655129432678}]}, {"text": "We used the standard split of training (Sec.02-21), development (Sec.22), and test data (Sec.23) and strictly followed the instructions for the evaluation settings explained in.", "labels": [], "entities": []}, {"text": "For data pre-processing, all the parse trees were transformed into linearized forms, which include standard UNK replacement for OOV words and POS-tag normalization by XX-tags.", "labels": [], "entities": [{"text": "POS-tag normalization", "start_pos": 142, "end_pos": 163, "type": "TASK", "confidence": 0.7100303024053574}]}, {"text": "As explained in, we did not apply any parse tree binarization or special unary treatment, which were used as common techniques in the literature.: List of bracketing F-measures on test data (PTB Sec.23) reported in recent top-notch systems: scores with bold font represent our scores.", "labels": [], "entities": [{"text": "PTB Sec.23)", "start_pos": 191, "end_pos": 202, "type": "DATASET", "confidence": 0.8539309700330099}]}, {"text": "One drawback of Seq2seq approach is that it seems sensitive to initialization.", "labels": [], "entities": []}, {"text": "Comparing only with a single result for each setting may produce inaccurate conclusions.", "labels": [], "entities": []}, {"text": "Therefore, we should evaluate the performances over several trials to improve the evaluation reliability.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Results on English PTB data: Results were average (ave), worst (min), and best (max) per- formance of ten models independently trained with distinct random initial values. Test data was only  evaluated on baseline and our best setting ((a), (e), (f) and (j)) to prevent over-tuning to the test  data. We confirmed that all our results contained no malformed parse trees.", "labels": [], "entities": [{"text": "English PTB data", "start_pos": 21, "end_pos": 37, "type": "DATASET", "confidence": 0.9352521101633707}]}, {"text": " Table 5: Ensembling and reranking results", "labels": [], "entities": [{"text": "Ensembling", "start_pos": 10, "end_pos": 20, "type": "TASK", "confidence": 0.9439473152160645}]}, {"text": " Table 6: Impact of hyper-parameter selections. We  only evaluated the development data (PTB Sec.  22) to prevent over-tuning to the test data.", "labels": [], "entities": [{"text": "PTB Sec.  22", "start_pos": 89, "end_pos": 101, "type": "DATASET", "confidence": 0.9126819372177124}]}]}