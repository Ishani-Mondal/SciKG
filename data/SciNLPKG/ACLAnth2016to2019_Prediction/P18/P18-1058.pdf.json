{"title": [{"text": "Give Me More Feedback: Annotating Argument Persuasiveness and Related Attributes in Student Essays", "labels": [], "entities": []}], "abstractContent": [{"text": "While argument persuasiveness is one of the most important dimensions of argumentative essay quality, it is relatively little studied in automated essay scoring research.", "labels": [], "entities": [{"text": "argument persuasiveness", "start_pos": 6, "end_pos": 29, "type": "TASK", "confidence": 0.811408668756485}, {"text": "essay scoring", "start_pos": 147, "end_pos": 160, "type": "TASK", "confidence": 0.6700852066278458}]}, {"text": "Progress on scoring argument persuasiveness is hindered in part by the scarcity of annotated corpora.", "labels": [], "entities": [{"text": "scoring argument persuasiveness", "start_pos": 12, "end_pos": 43, "type": "TASK", "confidence": 0.8878977100054423}]}, {"text": "We present the first corpus of essays that are simultaneously annotated with argument components , argument persuasiveness scores, and attributes of argument components that impact an argument's persuasiveness.", "labels": [], "entities": []}, {"text": "This corpus could trigger the development of novel computational models concerning argument persuasiveness that provide useful feedback to students on why their arguments are (un)persuasive in addition to how persuasive they are.", "labels": [], "entities": []}], "introductionContent": [{"text": "The vast majority of existing work on automated essay scoring has focused on holistic scoring, which summarizes the quality of an essay with a single score and thus provides very limited feedback to the writer (see for the state of the art).", "labels": [], "entities": [{"text": "essay scoring", "start_pos": 48, "end_pos": 61, "type": "TASK", "confidence": 0.7094053030014038}]}, {"text": "While recent attempts address this problem by scoring a particular dimension of essay quality such as coherence (), technical errors, relevance to prompt), organization (, and thesis clarity (, argument persuasiveness is largely ignored in existing automated essay scoring research despite being one of the most important dimensions of essay quality.", "labels": [], "entities": [{"text": "essay scoring", "start_pos": 259, "end_pos": 272, "type": "TASK", "confidence": 0.7100031226873398}]}, {"text": "Nevertheless, scoring the persuasiveness of arguments in student essays is by no means easy.", "labels": [], "entities": []}, {"text": "The difficulty stems in part from the scarcity of persuasiveness-annotated corpora of student essays.", "labels": [], "entities": []}, {"text": "While persuasiveness-annotated corpora exist for other domains such as online debates (e.g.,), to our knowledge only one corpus of persuasivenessannotated student essays has been made publicly available so far (.", "labels": [], "entities": []}, {"text": "Though a valuable resource, Persing and Ng's (2015) (P&N) corpus has several weaknesses that limit its impact on automated essay scoring research.", "labels": [], "entities": [{"text": "P&N) corpus", "start_pos": 53, "end_pos": 64, "type": "DATASET", "confidence": 0.6149313569068908}, {"text": "automated essay scoring research", "start_pos": 113, "end_pos": 145, "type": "TASK", "confidence": 0.6960165873169899}]}, {"text": "First, P&N assign only one persuasiveness score to each essay that indicates the persuasiveness of the argument an essay makes for its thesis.", "labels": [], "entities": []}, {"text": "However, multiple arguments are typically made in a persuasive essay.", "labels": [], "entities": []}, {"text": "Specifically, the arguments of an essay are typically structured as an argument tree, where the major claim, which is situated at the root of the tree, is supported by one or more claims (the children of the root node), each of which is in turn supported by one or more premises.", "labels": [], "entities": []}, {"text": "Hence, each node and its children constitute an argument.", "labels": [], "entities": []}, {"text": "In P&N's dataset, only the persuasiveness of the overall argument (i.e., the argument represented at the root and its children) of each essay is scored.", "labels": [], "entities": [{"text": "P&N's dataset", "start_pos": 3, "end_pos": 16, "type": "DATASET", "confidence": 0.8755411386489869}]}, {"text": "Hence, any system trained on their dataset cannot provide any feedback to students on the persuasiveness of any arguments other than the overall argument.", "labels": [], "entities": []}, {"text": "Second, P&N's corpus does not contain annotations that explain why the overall argument is not persuasive if its score is low.", "labels": [], "entities": [{"text": "P&N's corpus", "start_pos": 8, "end_pos": 20, "type": "DATASET", "confidence": 0.8065085768699646}]}, {"text": "This is undesirable from a feedback perspective, as a student will not understand why her argument is not persuasive if its score is low.", "labels": [], "entities": []}, {"text": "Our goal in this paper is to annotate and make publicly available a corpus of persuasive student essays that addresses the aforementioned weaknesses via designing appropriate annotation schemes and scoring rubrics.", "labels": [], "entities": []}, {"text": "Specifically, not only do we score the persuasiveness of each ar-gument in each essay (rather than simply the persuasiveness of the overall argument), but we also identify a set of attributes that can explain an argument's persuasiveness and annotate each argument with the values of these attributes.", "labels": [], "entities": []}, {"text": "These annotations enable the development of systems that can provide useful feedback to students, as the attribute values predicted by these systems can help a student understand why her essay receives a particular persuasiveness score.", "labels": [], "entities": []}, {"text": "To our knowledge, this is the first corpus of essays that are simultaneously annotated with argument components, persuasiveness scores, and related attributes.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 4: Description of the Eloquence scores.", "labels": [], "entities": []}, {"text": " Table 5: Description of the Evidence scores.", "labels": [], "entities": []}, {"text": " Table 6: Description of the Claim and MajorClaim Specificity scores.", "labels": [], "entities": [{"text": "MajorClaim", "start_pos": 39, "end_pos": 49, "type": "METRIC", "confidence": 0.7810141444206238}]}, {"text": " Table 7: Description of the Premise Specificity scores.", "labels": [], "entities": [{"text": "Premise Specificity", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.7995471656322479}]}, {"text": " Table 9: Description of the Strength scores.", "labels": [], "entities": []}, {"text": " Table 10: Class/Score distributions by component  type.", "labels": [], "entities": []}, {"text": " Table 11: Krippendorff's \u03b1 agreement on each at- tribute by component type.", "labels": [], "entities": []}, {"text": " Table 12: Correlation of each attribute with Per- suasiveness and the corresponding p-value.", "labels": [], "entities": []}, {"text": " Table 13: Persuasiveness scoring using gold at- tributes.", "labels": [], "entities": [{"text": "Persuasiveness", "start_pos": 11, "end_pos": 25, "type": "METRIC", "confidence": 0.8810562491416931}]}, {"text": " Table 14: An example essay. Owing to space limitations, only its first two paragraphs are shown.", "labels": [], "entities": []}]}