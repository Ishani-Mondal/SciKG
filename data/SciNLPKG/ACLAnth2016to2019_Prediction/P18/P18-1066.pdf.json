{"title": [{"text": "Mining Cross-Cultural Differences and Similarities in Social Media", "labels": [], "entities": [{"text": "Cross-Cultural Differences and Similarities", "start_pos": 7, "end_pos": 50, "type": "TASK", "confidence": 0.8045821934938431}]}], "abstractContent": [{"text": "Cross-cultural differences and similarities are common in cross-lingual natural language understanding, especially for research in social media.", "labels": [], "entities": [{"text": "cross-lingual natural language understanding", "start_pos": 58, "end_pos": 102, "type": "TASK", "confidence": 0.6349194124341011}]}, {"text": "For instance, people of distinct cultures often hold different opinions on a single named entity.", "labels": [], "entities": []}, {"text": "Also, understanding slang terms across languages requires knowledge of cross-cultural similarities.", "labels": [], "entities": [{"text": "understanding slang terms across languages", "start_pos": 6, "end_pos": 48, "type": "TASK", "confidence": 0.8489961147308349}]}, {"text": "In this paper , we study the problem of computing such cross-cultural differences and similarities.", "labels": [], "entities": []}, {"text": "We present a lightweight yet effective approach, and evaluate it on two novel tasks: 1) mining cross-cultural differences of named entities and 2) finding similar terms for slang across languages.", "labels": [], "entities": []}, {"text": "Experimental results show that our framework substantially outperforms a number of baseline methods on both tasks.", "labels": [], "entities": []}, {"text": "The framework could be useful for machine translation applications and research in computational social science.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.8169454336166382}]}], "introductionContent": [{"text": "Computing similarities between terms is one of the most fundamental computational tasks in natural language understanding.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 91, "end_pos": 121, "type": "TASK", "confidence": 0.6614523530006409}]}, {"text": "Much work has been done in this area, most notably using the distributional properties drawn from large monolingual textual corpora to train vector representations of words or other linguistic units ().", "labels": [], "entities": []}, {"text": "However, computing cross-cultural similarities of terms between different cultures is still an open research question, which is important in cross-lingual natural language understanding.", "labels": [], "entities": [{"text": "cross-lingual natural language understanding", "start_pos": 141, "end_pos": 185, "type": "TASK", "confidence": 0.7273181974887848}]}, {"text": "In this paper, we address cross-cultural research questions such as these: * Both authors contributed equally.", "labels": [], "entities": []}, {"text": "#Nanjing says no to Nagoya# This small Japan, is really irritating.", "labels": [], "entities": [{"text": "Nanjing", "start_pos": 1, "end_pos": 8, "type": "DATASET", "confidence": 0.8905261158943176}, {"text": "Nagoya", "start_pos": 20, "end_pos": 26, "type": "DATASET", "confidence": 0.7689704298973083}]}, {"text": "We Chinese people are tolerant of good and evil, and you?", "labels": [], "entities": []}, {"text": "People do things, and the gods are watching.", "labels": [], "entities": []}, {"text": "Japanese, be careful, and beware of thunder chop!", "labels": [], "entities": [{"text": "Japanese", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8017830848693848}]}, {"text": "(via Bing Translation) Figure 1: Two social media messages about Nagoya from different cultures in 2012 1.", "labels": [], "entities": []}, {"text": "Were there any cross-cultural differences between Nagoya (a city in Japan) for native English speakers and \u540d\u53e4\u5c4b (Nagoya in Chinese) for Chinese people in 2012?", "labels": [], "entities": []}, {"text": "2. What English terms can be used to explain \"\u6d6e\u4e91\" (a Chinese slang term)?", "labels": [], "entities": []}, {"text": "These kinds of questions about cross-cultural differences and similarities are important in crosscultural social studies, multi-lingual sentiment analysis, culturally sensitive machine translation, and many other NLP tasks, especially in social media.", "labels": [], "entities": [{"text": "multi-lingual sentiment analysis", "start_pos": 122, "end_pos": 154, "type": "TASK", "confidence": 0.7745499610900879}, {"text": "culturally sensitive machine translation", "start_pos": 156, "end_pos": 196, "type": "TASK", "confidence": 0.6419564709067345}]}, {"text": "We propose two novel tasks in mining them from social media.", "labels": [], "entities": []}, {"text": "The first task (Section 4) is to mine crosscultural differences in the perception of named entities (e.g., persons, places and organizations).", "labels": [], "entities": []}, {"text": "Back in 2012, in the case of \"Nagoya\", many native English speakers posted their pleasant travel experiences in Nagoya on Twitter.", "labels": [], "entities": []}, {"text": "However, Chinese people overwhelmingly greeted the city with anger and condemnation on Weibo (a Chinese version of Twitter), because the city mayor denied the truthfulness of the Nanjing Massacre.", "labels": [], "entities": [{"text": "Weibo", "start_pos": 87, "end_pos": 92, "type": "DATASET", "confidence": 0.9878131151199341}, {"text": "Nanjing Massacre", "start_pos": 179, "end_pos": 195, "type": "DATASET", "confidence": 0.8451013565063477}]}, {"text": "illustrates two example microblog messages about Nagoya in Twitter and Weibo respectively.", "labels": [], "entities": [{"text": "Nagoya", "start_pos": 49, "end_pos": 55, "type": "DATASET", "confidence": 0.8298856019973755}, {"text": "Weibo", "start_pos": 71, "end_pos": 76, "type": "DATASET", "confidence": 0.9704121947288513}]}, {"text": "The second task (Section 5) is to find similar terms for slang across cultures and languages.", "labels": [], "entities": []}, {"text": "Social media is always a rich soil where slang terms emerge in many cultures.", "labels": [], "entities": []}, {"text": "For example, \"\u6d6e\u4e91\" literally means \"floating clouds\", but now almost equals to \"nothingness\" on the Chinese web.", "labels": [], "entities": []}, {"text": "Our experiments show that well-known online machine translators such as Google Translate are only able to translate such slang terms to their literal meanings, even under clear contexts where slang meanings are much more appropriate.", "labels": [], "entities": []}, {"text": "Enabling intelligent agents to understand such cross-cultural knowledge can benefit their performances in various cross-lingual language processing tasks.", "labels": [], "entities": []}, {"text": "Both tasks share the same core problem, which is how to compute cross-cultural differences (or similarities) between two terms from different cultures.", "labels": [], "entities": []}, {"text": "A term here can be either an ordinary word, an entity name, or a slang term.", "labels": [], "entities": []}, {"text": "We focus on names and slang in this paper for they convey more social and cultural connotations.", "labels": [], "entities": []}, {"text": "There are many works on cross-lingual word representation () to compute general cross-lingual similarities.", "labels": [], "entities": [{"text": "cross-lingual word representation", "start_pos": 24, "end_pos": 57, "type": "TASK", "confidence": 0.648977796236674}]}, {"text": "Most existing models require bilingual supervision such as aligned parallel corpora, bilingual lexicons, or comparable documents ().", "labels": [], "entities": []}, {"text": "However, they do not purposely preserve social or cultural characteristics of named entities or slang terms, and the required parallel corpora are rare and expensive.", "labels": [], "entities": []}, {"text": "In this paper, we propose a lightweight yet effective approach to project two incompatible monolingual word vector spaces into a single bilingual word vector space, known as social vector space (SocVec).", "labels": [], "entities": []}, {"text": "A key element of SocVec is the idea of \"bilingual social lexicon\", which contains bilingual mappings of selected words reflecting psychological processes, which we believe are central to capturing the socio-linguistic characteristics.", "labels": [], "entities": []}, {"text": "Our contribution in this paper is two-fold: (a) We present an effective approach to mine cross-cultural similarities and differences of terms, which could benefit research in machine translation, cross-cultural social media analysis, and other cross-lingual research in natural language processing and computational social science.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 175, "end_pos": 194, "type": "TASK", "confidence": 0.8176062107086182}, {"text": "cross-cultural social media analysis", "start_pos": 196, "end_pos": 232, "type": "TASK", "confidence": 0.6244744807481766}]}, {"text": "(b) We propose two novel and important tasks in cross-cultural social studies and social media analysis.", "labels": [], "entities": [{"text": "cross-cultural social studies", "start_pos": 48, "end_pos": 77, "type": "TASK", "confidence": 0.7448211709658304}, {"text": "social media analysis", "start_pos": 82, "end_pos": 103, "type": "TASK", "confidence": 0.6730903685092926}]}, {"text": "Experimental results on our annotated datasets show that the proposed method outperforms many strong baseline methods.", "labels": [], "entities": []}], "datasetContent": [{"text": "Prior to evaluating SocVec with our two proposed tasks in Section 4 and Section 5, we present our preparation steps as follows.", "labels": [], "entities": []}, {"text": "Social Media Corpora Our English Twitter corpus is obtained from Archive Team's Twitter stream grab . The Chinese Weibo corpus comes from Open Weiboscope Data Access 5 (.", "labels": [], "entities": [{"text": "Archive Team's Twitter stream grab", "start_pos": 65, "end_pos": 99, "type": "DATASET", "confidence": 0.8178887069225311}, {"text": "Chinese Weibo corpus", "start_pos": 106, "end_pos": 126, "type": "DATASET", "confidence": 0.8494160970052084}, {"text": "Open Weiboscope Data Access 5", "start_pos": 138, "end_pos": 167, "type": "DATASET", "confidence": 0.8205141544342041}]}, {"text": "Both corpora cover the whole year of 2012.", "labels": [], "entities": []}, {"text": "We then randomly down-sample each corpus to 100 million messages where each message contains at least 10 characters, normalize the text (, lemmatize the text ( ) and use LTP () to perform word segmentation for the Chinese corpus.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 188, "end_pos": 205, "type": "TASK", "confidence": 0.7202286273241043}]}, {"text": "Entity Linking and Word Embedding Entity linking is a preprocessing step which links various entity mentions (surface forms) to the identity of corresponding entities.", "labels": [], "entities": [{"text": "Entity Linking", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7327175140380859}, {"text": "Word Embedding Entity linking", "start_pos": 19, "end_pos": 48, "type": "TASK", "confidence": 0.695715568959713}]}, {"text": "For the Twitter corpus, we use Wikifier (), a widely used entity linker in English.", "labels": [], "entities": []}, {"text": "Because no sophisticated tool for Chinese short text is available, we implement our own tool that is greedy for high precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 117, "end_pos": 126, "type": "METRIC", "confidence": 0.9940811991691589}]}, {"text": "We train English and Chinese monolingual word embedding respectively using word2vec's skip-gram method with a window size of 5 (.", "labels": [], "entities": []}, {"text": "Bilingual Lexicon Our bilingual lexicon is collected from Microsoft Translator 6 , which translates English words to multiple Chinese words with confidence scores.", "labels": [], "entities": [{"text": "Microsoft Translator 6", "start_pos": 58, "end_pos": 80, "type": "DATASET", "confidence": 0.8313145240147909}]}, {"text": "Note that all named entities and slang terms used in the following experiments are excluded from this bilingual lexicon.", "labels": [], "entities": []}, {"text": "Social Word Vocabulary Our social word vocabularies come from and OpinionFinder () for English, and TextMind () for Chinese.", "labels": [], "entities": []}, {"text": "Empath is similar to LIWC, but has more words and more categories and is publicly available.", "labels": [], "entities": [{"text": "Empath", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8797963857650757}]}, {"text": "We manually select 91 categories of words that are relevant to human perception and psychological processes following.", "labels": [], "entities": []}, {"text": "OpinionFinder consists of words relevant to opinions and sentiments, and TextMind is a Chinese counterpart for Empath.", "labels": [], "entities": [{"text": "TextMind", "start_pos": 73, "end_pos": 81, "type": "DATASET", "confidence": 0.9078229069709778}, {"text": "Empath", "start_pos": 111, "end_pos": 117, "type": "DATASET", "confidence": 0.926302969455719}]}, {"text": "In summary, we obtain 3,343 words from Empath, 3,861 words from OpinionFinder, and 5,574 unique social words in total.", "labels": [], "entities": [{"text": "Empath", "start_pos": 39, "end_pos": 45, "type": "DATASET", "confidence": 0.9253643155097961}]}, {"text": "To quantitatively evaluate our methods, we need to measure similarities between a produced word set and the ground truth set.", "labels": [], "entities": []}, {"text": "Exact-matching Jaccard similarity is too strict to capture valuable relatedness between two word sets.", "labels": [], "entities": []}, {"text": "We argue that average cosine similarity (ACS) between two sets of word vectors is a better metric for evaluating the similarity between two word sets.", "labels": [], "entities": [{"text": "average cosine similarity (ACS)", "start_pos": 14, "end_pos": 45, "type": "METRIC", "confidence": 0.91977858543396}]}, {"text": "The above equation illustrates such computation, where A and B are the two word sets: A is the truth set and B is a similar list produced by each method.", "labels": [], "entities": []}, {"text": "In the previous case of \"\u4e8c\u767e\u4e94\" (Section 5.1), A is {foolish, stubborn, rude, impetuous} while B can be {imbecile, brainless, scum-.", "labels": [], "entities": []}, {"text": "The performance of online translators for slang typically depends on human-set rules and supervised learning on well-annotated parallel corpora, which are rare and costly, especially for social media where slang emerges the most.", "labels": [], "entities": []}, {"text": "This is probably the reason why they do not perform well.", "labels": [], "entities": []}, {"text": "The Linear Transformation (LT) model is trained on highly confident translation pairs in the bilingual lexicon, which lacks OOV slang terms and social contexts around them.", "labels": [], "entities": [{"text": "Linear Transformation (LT)", "start_pos": 4, "end_pos": 30, "type": "TASK", "confidence": 0.7575329542160034}]}, {"text": "The TransBL method is competitive because its similarity computations are within monolingual semantic spaces and it makes great use of the bilingual lexicon, but it loses the information from the related words that are not in the bilingual lexicon.", "labels": [], "entities": []}, {"text": "Our method (SV) outperforms baselines by directly using the distances in the SocVec space, which proves that the SocVec well captures the cross-cultural similarities between terms.", "labels": [], "entities": []}, {"text": "To qualitatively evaluate our model, in, we present several examples of our translations for Chinese and English slang terms as well as their explanations from the glossary.", "labels": [], "entities": []}, {"text": "Our results are highly correlated with these explanations and capture their significant semantics, whereas most online translators just offer literal translations, even within obviously slang contexts.", "labels": [], "entities": []}, {"text": "We take a step further to directly translate Chinese slang terms to English slang terms by filtering out ordinary (nonslang) words in the original target term lists, with examples shown in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Selected culturally different entities with summarized Twitter and Weibo's trending topics", "labels": [], "entities": []}, {"text": " Table 2: Comparison of Different Methods", "labels": [], "entities": []}, {"text": " Table 3: Different Similarity Functions", "labels": [], "entities": []}, {"text": " Table 4: Different Pseudo-word Generators", "labels": [], "entities": []}]}