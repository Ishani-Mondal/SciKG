{"title": [{"text": "Bilingual Sentiment Embeddings: Joint Projection of Sentiment Across Languages", "labels": [], "entities": [{"text": "Bilingual Sentiment Embeddings", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7427486975987753}]}], "abstractContent": [{"text": "Sentiment analysis in low-resource languages suffers from alack of annotated corpora to estimate high-performing models.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9510961472988129}]}, {"text": "Machine translation and bilingual word embeddings provide some relief through cross-lingual sentiment approaches.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7773805260658264}]}, {"text": "However , they either require large amounts of parallel data or do not sufficiently capture sentiment information.", "labels": [], "entities": []}, {"text": "We introduce Bilingual Sentiment Embeddings (BLSE), which jointly represent sentiment information in a source and target language.", "labels": [], "entities": []}, {"text": "This model only requires a small bilingual lexicon, a source-language corpus annotated for sentiment, and monolingual word embed-dings for each language.", "labels": [], "entities": []}, {"text": "We perform experiments on three language combinations (Spanish, Catalan, Basque) for sentence-level cross-lingual sentiment classification and find that our model significantly out-performs state-of-the-art methods on four out of six experimental setups, as well as capturing complementary information to machine translation.", "labels": [], "entities": [{"text": "cross-lingual sentiment classification", "start_pos": 100, "end_pos": 138, "type": "TASK", "confidence": 0.7536169787247976}]}, {"text": "Our analysis of the resulting embedding space provides evidence that it represents sentiment information in the resource-poor target language without any annotated data in that language.", "labels": [], "entities": []}], "introductionContent": [{"text": "Cross-lingual approaches to sentiment analysis are motivated by the lack of training data in the vast majority of languages.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.9713211059570312}]}, {"text": "Even languages spoken by several million people, such as Catalan, often have few resources available to perform sentiment analysis in specific domains.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.934752345085144}]}, {"text": "We therefore aim to harness the knowledge previously collected in resource-rich languages.", "labels": [], "entities": []}, {"text": "Previous approaches for cross-lingual sentiment analysis typically exploit machine translation based methods or multilingual models.", "labels": [], "entities": [{"text": "cross-lingual sentiment analysis", "start_pos": 24, "end_pos": 56, "type": "TASK", "confidence": 0.8299953937530518}]}, {"text": "Machine translation (MT) can provide away to transfer sentiment information from a resource-rich to resourcepoor languages ().", "labels": [], "entities": [{"text": "Machine translation (MT", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8290697187185287}]}, {"text": "However, MT-based methods require large parallel corpora to train the translation system, which are often not available for underresourced languages.", "labels": [], "entities": [{"text": "MT-based", "start_pos": 9, "end_pos": 17, "type": "TASK", "confidence": 0.9722991585731506}]}, {"text": "Examples of multilingual methods that have been applied to cross-lingual sentiment analysis include domain adaptation methods (), delexicalization (, and bilingual word embeddings ().", "labels": [], "entities": [{"text": "cross-lingual sentiment analysis", "start_pos": 59, "end_pos": 91, "type": "TASK", "confidence": 0.7966722249984741}]}, {"text": "These approaches however do not incorporate enough sentiment information to perform well cross-lingually, as we will show later.", "labels": [], "entities": []}, {"text": "We propose a novel approach to incorporate sentiment information in a model, which does not have these disadvantages.", "labels": [], "entities": []}, {"text": "Bilingual Sentiment Embeddings (BLSE) are embeddings that are jointly optimized to represent both (a) semantic information in the source and target languages, which are bound to each other through a small bilingual dictionary, and (b) sentiment information, which is annotated on the source language only.", "labels": [], "entities": [{"text": "Bilingual Sentiment Embeddings (BLSE)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.7241740127404531}]}, {"text": "We only need three resources: (i) a comparably small bilingual lexicon, (ii) an annotated sentiment corpus in the resourcerich language, and (iii) monolingual word embeddings for the two involved languages.", "labels": [], "entities": []}, {"text": "We show that our model outperforms previous state-of-the-art models in nearly all experimental settings across six benchmarks.", "labels": [], "entities": []}, {"text": "In addition, we offer an in-depth analysis and demonstrate that our model is aware of sentiment.", "labels": [], "entities": []}, {"text": "Finally, we provide a qualitative analysis of the joint bilingual sentiment space.", "labels": [], "entities": []}, {"text": "Our implementation is publicly available at https://github.com/jbarnesspain/blse.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Statistics for the OpeNER English (EN)  and Spanish (ES) as well as the MultiBooked Cata- lan (CA) and Basque (EU) datasets.", "labels": [], "entities": [{"text": "OpeNER English (EN)  and Spanish (ES)", "start_pos": 29, "end_pos": 66, "type": "DATASET", "confidence": 0.8805458962917327}, {"text": "MultiBooked Cata- lan (CA) and Basque (EU) datasets", "start_pos": 82, "end_pos": 133, "type": "DATASET", "confidence": 0.7402583131423364}]}, {"text": " Table 3: Precision (P), Recall (R), and macro F 1 of  four models trained on English and tested on Span- ish (ES), Catalan (CA), and Basque (EU). The bold  numbers show the best results for each metric per  column and the highlighted numbers show where  BLSE is better than the other projection methods,  ARTETXE and BARISTA (** p < 0.01, * p < 0.05).", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9894505143165588}, {"text": "Recall (R)", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.921264037489891}, {"text": "macro F 1", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9014601111412048}, {"text": "BLSE", "start_pos": 255, "end_pos": 259, "type": "METRIC", "confidence": 0.999200165271759}, {"text": "ARTETXE", "start_pos": 306, "end_pos": 313, "type": "DATASET", "confidence": 0.7019661664962769}, {"text": "BARISTA", "start_pos": 318, "end_pos": 325, "type": "METRIC", "confidence": 0.9529483318328857}]}, {"text": " Table 4: Error analysis for different phenomena.  See text for explanation of error classes.", "labels": [], "entities": [{"text": "Error analysis", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.8558955788612366}]}]}