{"title": [{"text": "Zero-Shot Transfer Learning for Event Extraction", "labels": [], "entities": [{"text": "Zero-Shot Transfer", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.6964400559663773}, {"text": "Event Extraction", "start_pos": 32, "end_pos": 48, "type": "TASK", "confidence": 0.7195874154567719}]}], "abstractContent": [{"text": "Most previous supervised event extraction methods have relied on features derived from manual annotations, and thus cannot be applied to new event types without extra annotation effort.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 25, "end_pos": 41, "type": "TASK", "confidence": 0.7010322064161301}]}, {"text": "We take afresh look at event extraction and model it as a generic grounding problem: mapping each event mention to a specific type in a target event ontology.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 23, "end_pos": 39, "type": "TASK", "confidence": 0.7343045771121979}]}, {"text": "We design a trans-ferable architecture of structural and com-positional neural networks to jointly represent and map event mentions and types into a shared semantic space.", "labels": [], "entities": []}, {"text": "Based on this new framework, we can select, for each event mention, the event type which is semantically closest in this space as its type.", "labels": [], "entities": []}, {"text": "By leveraging manual annotations available fora small set of existing event types, our framework can be applied to new unseen event types without additional manual annotations.", "labels": [], "entities": []}, {"text": "When tested on 23 unseen event types, this zero-shot framework, without manual annotations , achieves performance comparable to a supervised model trained from 3,000 sentences annotated with 500 event mentions.", "labels": [], "entities": []}], "introductionContent": [{"text": "The goal of event extraction is to identify event triggers and their arguments in unstructured text data, and then to assign an event type to each trigger and a semantic role to each argument.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 12, "end_pos": 28, "type": "TASK", "confidence": 0.7236447334289551}]}, {"text": "An example is shown in.", "labels": [], "entities": []}, {"text": "Traditional supervised methods have typically modeled this task of event The programs are publicly available for research purpose at: https://github.com/wilburOne/ZeroShotEvent extraction as a classification problem, by assigning event triggers to event types from a pre-defined fixed set.", "labels": [], "entities": [{"text": "ZeroShotEvent extraction", "start_pos": 163, "end_pos": 187, "type": "TASK", "confidence": 0.6334148645401001}]}, {"text": "These methods rely heavily on manual annotations and features specific to each event type, and thus are not easily adapted to new event types without extra annotation effort.", "labels": [], "entities": []}, {"text": "Handling new event types may even entail starting over, without being able to re-use annotations from previous event types.", "labels": [], "entities": []}, {"text": "To make event extraction effective as new realworld scenarios emerge, we take a look at this task from the perspective of zero-shot learning, ZSL.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 8, "end_pos": 24, "type": "TASK", "confidence": 0.8140608072280884}]}, {"text": "ZSL, as a type of transfer learning, makes use of separate, pre-existing classifiers to build a semantic, cross-concept space that maps between their respective classes.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 18, "end_pos": 35, "type": "TASK", "confidence": 0.8855315148830414}]}, {"text": "The resulting shared semantic space then allows for building a novel \"zero-shot\" classifier, i,e,, requiring no (zero) additional training examples, to handle unseen cases.", "labels": [], "entities": []}, {"text": "We observe that each event mention has a structure consisting of a candidate trigger and arguments, with corresponding predefined name labels for the event type and argument roles.", "labels": [], "entities": []}, {"text": "We propose to enrich the semantic representations of each event mention and event type with rich structures, and determine the type based on the semantic similarity between an event mention and each event type defined in a target ontology.", "labels": [], "entities": []}, {"text": "Let's consider two example sentences: E1.", "labels": [], "entities": []}, {"text": "The Government of China has ruled Tibet since 1951 after dispatching troops to the Himalayan region in 1950.", "labels": [], "entities": []}, {"text": "Iranian state television stated that the conflict between the Iranian police and the drug smugglers took place near the town of mirjaveh.", "labels": [], "entities": []}, {"text": "In E1, as also diagrammed in, dis- patching is the trigger for the event mention of type Transport Person and in E2, conflict is the trigger for the event mention of type Attack.", "labels": [], "entities": []}, {"text": "We make use of Abstract Meaning Representations (AMR) () to identify the candidate arguments and construct event mention structures as shown in (top).", "labels": [], "entities": [{"text": "Abstract Meaning Representations (AMR)", "start_pos": 15, "end_pos": 53, "type": "METRIC", "confidence": 0.7140956421693166}]}, {"text": "(bottom) also shows event type structures defined in the Automatic Content Extraction (ACE) guideline.", "labels": [], "entities": [{"text": "Automatic Content Extraction (ACE)", "start_pos": 57, "end_pos": 91, "type": "TASK", "confidence": 0.6927692989508311}]}, {"text": "We can see that a trigger and its event type name usually have some shared meaning.", "labels": [], "entities": []}, {"text": "Furthermore, their structures also tend to be similar: a Transport Person event typically involves a Person as its patient role, while an Attack event involves a Person or Location as an Attacker.", "labels": [], "entities": []}, {"text": "This observation matches the theory by: \"the semantics of an event structure can be generalized and mapped to event mention structures in a systematic and predictable way\".", "labels": [], "entities": []}, {"text": "Inspired by this theory, for the first time, we model event extraction as a generic grounding problem, by mapping each mention to its semantically closest event type.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 54, "end_pos": 70, "type": "TASK", "confidence": 0.7845507562160492}]}, {"text": "Given an event ontology, 2 https://en.wikipedia.org/wiki/Automatic content extraction where each event type structure is well-defined, we will refer to the event types for which we have annotated event mentions as seen types, while those without annotations as unseen types.", "labels": [], "entities": [{"text": "Automatic content extraction", "start_pos": 57, "end_pos": 85, "type": "TASK", "confidence": 0.7898461818695068}]}, {"text": "Our goal is to learn a generic mapping function independent of event types, which can be trained from annotations fora limited number of seen event types and then used for any new unseen event types.", "labels": [], "entities": []}, {"text": "We design a transferable neural architecture, which jointly learns and maps the structural representations of event mentions and types into a shared semantic space, by minimizing the distance between each event mention and its corresponding type.", "labels": [], "entities": []}, {"text": "For event mentions with unseen types, their structures will be projected into the same semantic space using the same framework and assigned types with top-ranked similarity values.", "labels": [], "entities": []}, {"text": "To summarize, to apply our new zero-shot transfer learning framework to any new unseen event types, we only need (1) a structured definition of the unseen event type (its type name along with role names for its arguments, from the event ontology); and (2) some annotations for one or a few seen event types.", "labels": [], "entities": []}, {"text": "Without requiring any additional manual annotations for the new unseen types, our ZSL framework achieves performance comparable to supervised methods trained from a substantial amount of training data for the same types.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 4: Statistics for Positive/Negative Instances in Training, Dev, and Test Sets for Each Experiment.", "labels": [], "entities": []}, {"text": " Table 5: Comparison between Structural Representation (Our Approach) and Word Sense Embedding  based Approaches on Hit@K Accuracy (%) for Trigger and Argument Classification.", "labels": [], "entities": [{"text": "Trigger and Argument Classification", "start_pos": 139, "end_pos": 174, "type": "TASK", "confidence": 0.7449343651533127}]}, {"text": " Table 6: Performance on Various Types Using Jus- tice Subtypes for Training", "labels": [], "entities": []}, {"text": " Table 7: Event Trigger and Argument Extraction Performance (%) on Unseen ACE Types.", "labels": [], "entities": [{"text": "Event Trigger", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.6249754577875137}, {"text": "Argument Extraction Performance", "start_pos": 28, "end_pos": 59, "type": "METRIC", "confidence": 0.8983213504155477}]}, {"text": " Table 8: Impact of AMR and Semantic Roles on  Trigger and Argument Extraction (%).", "labels": [], "entities": [{"text": "AMR", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.8168248534202576}, {"text": "Trigger and Argument Extraction", "start_pos": 47, "end_pos": 78, "type": "TASK", "confidence": 0.7524460330605507}]}]}