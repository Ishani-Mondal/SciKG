{"title": [{"text": "Neural Machine Translation Techniques for Named Entity Transliteration", "labels": [], "entities": [{"text": "Neural Machine Translation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7557442585627238}, {"text": "Named Entity Transliteration", "start_pos": 42, "end_pos": 70, "type": "TASK", "confidence": 0.7618372837702433}]}], "abstractContent": [{"text": "Transliterating named entities from one language into another can be approached as neural machine translation (NMT) problem , for which we use deep attentional RNN encoder-decoder models.", "labels": [], "entities": [{"text": "Transliterating named entities from one language", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.8379107813040415}, {"text": "neural machine translation (NMT)", "start_pos": 83, "end_pos": 115, "type": "TASK", "confidence": 0.8254569371541342}]}, {"text": "To build a strong transliteration system, we apply well-established techniques from NMT, such as dropout regularization, model en-sembling, rescoring with right-to-left models , and back-translation.", "labels": [], "entities": [{"text": "dropout regularization", "start_pos": 97, "end_pos": 119, "type": "TASK", "confidence": 0.61972576379776}]}, {"text": "Our submission to the NEWS 2018 Shared Task on Named Entity Transliteration ranked first in several tracks.", "labels": [], "entities": [{"text": "NEWS 2018 Shared Task on Named Entity Transliteration", "start_pos": 22, "end_pos": 75, "type": "TASK", "confidence": 0.6700248718261719}]}], "introductionContent": [{"text": "Transliteration of Named Entities (NEs) is defined as the phonetic translation of names across languages (.", "labels": [], "entities": [{"text": "Transliteration of Named Entities (NEs)", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.8297288162367684}, {"text": "phonetic translation of names across languages", "start_pos": 58, "end_pos": 104, "type": "TASK", "confidence": 0.8002333045005798}]}, {"text": "It is an important part of a number of natural language processing tasks, and machine translation in particular ().", "labels": [], "entities": [{"text": "machine translation", "start_pos": 78, "end_pos": 97, "type": "TASK", "confidence": 0.7892559170722961}]}, {"text": "Machine transliteration can be approached as a sequence-to-sequence modeling problem (.", "labels": [], "entities": [{"text": "Machine transliteration", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7620724439620972}]}, {"text": "In this work, we explore the Neural Machine Translation (NMT) approach based on an attentional RNN encoderdecoder neural network architecture ( ), motivated by its successful application to other sequence-to-sequence tasks, such as grammatical error correction, automatic post-editing, sentence summarization (, or paraphrasing.", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT)", "start_pos": 29, "end_pos": 61, "type": "TASK", "confidence": 0.839643786350886}, {"text": "grammatical error correction", "start_pos": 232, "end_pos": 260, "type": "TASK", "confidence": 0.7057497302691141}, {"text": "sentence summarization", "start_pos": 286, "end_pos": 308, "type": "TASK", "confidence": 0.7560230493545532}]}, {"text": "We apply well-established techniques from NMT to machine transliteration building a strong system that achieves state-of-the-art-results.", "labels": [], "entities": [{"text": "machine transliteration", "start_pos": 49, "end_pos": 72, "type": "TASK", "confidence": 0.7250002026557922}]}, {"text": "The techniques we exploit include: \u2022 Regularization with various dropouts preventing model overfitting; \u2022 Ensembling strategies involving independently trained models and model checkpoints; \u2022 Re-scoring of n-best list of candidate transliterations by right-to-left models; \u2022 Using synthetic training data generated via back-translation.", "labels": [], "entities": [{"text": "Regularization", "start_pos": 37, "end_pos": 51, "type": "TASK", "confidence": 0.9826551675796509}, {"text": "Re-scoring of n-best list of candidate transliterations", "start_pos": 192, "end_pos": 247, "type": "TASK", "confidence": 0.7218119757516044}]}, {"text": "The developed system constitutes our submission to the NEWS 2018 Shared Task 1 on Named Entity Transliteration ranked first in several tracks.", "labels": [], "entities": [{"text": "NEWS 2018 Shared Task 1", "start_pos": 55, "end_pos": 78, "type": "DATASET", "confidence": 0.7856801271438598}, {"text": "Named Entity Transliteration", "start_pos": 82, "end_pos": 110, "type": "TASK", "confidence": 0.5736212233702341}]}, {"text": "We describe the shared task in Section 2, including provided data sets and evaluation metrics.", "labels": [], "entities": []}, {"text": "In Section 3, we present the model architecture and adopted NMT techniques.", "labels": [], "entities": []}, {"text": "The experiment details are presented in Section 4, the results are reported in Section 5, and we conclude in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Five different datasets have been made available for use as the training and development data.", "labels": [], "entities": []}, {"text": "No other parallel nor monolingual data are allowed for the constrained standard submissions that we participate in.", "labels": [], "entities": []}, {"text": "The quality of machine transliterations is evaluated with four automatic metrics in the shared task: word accuracy, mean F-score, mean reciprocal rank, and MAP ref.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.8288833498954773}, {"text": "F-score", "start_pos": 121, "end_pos": 128, "type": "METRIC", "confidence": 0.717248260974884}, {"text": "mean reciprocal rank", "start_pos": 130, "end_pos": 150, "type": "METRIC", "confidence": 0.7157110174496969}, {"text": "MAP ref", "start_pos": 156, "end_pos": 163, "type": "METRIC", "confidence": 0.9539088904857635}]}, {"text": "As a main evaluation metric for our experiments we use word accuracy (Acc) on the top candidate: The closer the value to 1.0, the more top candidates c i,1 are correct transliterations, i.e. they match one of the references r i,j . N is the total number of entries in a test set.", "labels": [], "entities": [{"text": "word accuracy (Acc)", "start_pos": 55, "end_pos": 74, "type": "METRIC", "confidence": 0.7849849581718444}]}, {"text": "We train all systems with Marian NMT toolkit 3,4 (Junczys-Dowmunt et al., 2018).", "labels": [], "entities": [{"text": "Marian NMT toolkit 3,4", "start_pos": 26, "end_pos": 48, "type": "DATASET", "confidence": 0.868782639503479}]}], "tableCaptions": [{"text": " Table 1: Official data sets in NEWS 2018 which  we use in our experiments.", "labels": [], "entities": [{"text": "Official data sets in NEWS 2018", "start_pos": 10, "end_pos": 41, "type": "DATASET", "confidence": 0.8460947374502817}]}, {"text": " Table 2: Comparison of training data sets without  and with synthetic examples. The original data are  oversampled R times in synthetic data sets.", "labels": [], "entities": []}, {"text": " Table 3: Results (Acc) on the official NEWS 2018 development set. Bolded systems have been evaluated  on the official test set (last row).", "labels": [], "entities": [{"text": "Acc", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.997973620891571}, {"text": "NEWS 2018 development set", "start_pos": 40, "end_pos": 65, "type": "DATASET", "confidence": 0.9429239481687546}, {"text": "official test set", "start_pos": 110, "end_pos": 127, "type": "DATASET", "confidence": 0.7746710379918417}]}]}