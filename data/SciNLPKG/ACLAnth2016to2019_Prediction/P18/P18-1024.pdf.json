{"title": [{"text": "LinkNBed: Multi-Graph Representation Learning with Entity Linkage", "labels": [], "entities": [{"text": "Multi-Graph Representation Learning", "start_pos": 10, "end_pos": 45, "type": "TASK", "confidence": 0.7361053923765818}]}], "abstractContent": [{"text": "Knowledge graphs have emerged as an important model for studying complex multi-relational data.", "labels": [], "entities": []}, {"text": "This has given rise to the construction of numerous large scale but incomplete knowledge graphs encoding information extracted from various resources.", "labels": [], "entities": []}, {"text": "An effective and scalable approach to jointly learn over multiple graphs and eventually construct a unified graph is a crucial next step for the success of knowledge-based inference for many downstream applications.", "labels": [], "entities": []}, {"text": "To this end, we propose LinkNBed, a deep relational learning framework that learns entity and relationship representations across multiple graphs.", "labels": [], "entities": []}, {"text": "We identify entity linkage across graphs as a vital component to achieve our goal.", "labels": [], "entities": []}, {"text": "We design a novel objective that leverage entity linkage and build an efficient multi-task training procedure.", "labels": [], "entities": []}, {"text": "Experiments on link prediction and entity linkage demonstrate substantial improvements over the state-of-the-art relational learning approaches.", "labels": [], "entities": [{"text": "link prediction", "start_pos": 15, "end_pos": 30, "type": "TASK", "confidence": 0.8249920904636383}]}], "introductionContent": [{"text": "Reasoning over multi-relational data is a key concept in Artificial Intelligence and knowledge graphs have appeared at the forefront as an effective tool to model such multi-relational data.", "labels": [], "entities": []}, {"text": "Knowledge graphs have found increasing importance due to its wider range of important applications such as information retrieval), natural language processing (, recommender systems, question-answering ( and many more.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 107, "end_pos": 128, "type": "TASK", "confidence": 0.7992807030677795}, {"text": "natural language processing", "start_pos": 131, "end_pos": 158, "type": "TASK", "confidence": 0.6435123781363169}]}, {"text": "This has led to the increased efforts in constructing numerous large-scale Knowledge Bases (e.g. Freebase (,), Google's Knowledge graph (),) and NELL), that can cater to these applications, by representing information available on the web in relational format.", "labels": [], "entities": []}, {"text": "All knowledge graphs share common drawback of incompleteness and sparsity and hence most existing relational learning techniques focus on using observed triplets in an incomplete graph to infer unobserved triplets for that graph ().", "labels": [], "entities": []}, {"text": "Neural embedding techniques that learn vector space representations of entities and relationships have achieved remarkable success in this task.", "labels": [], "entities": []}, {"text": "However, these techniques only focus on learning from a single graph.", "labels": [], "entities": []}, {"text": "In addition to incompleteness property, these knowledge graphs also share a set of overlapping entities and relationships with varying information about them.", "labels": [], "entities": []}, {"text": "This makes a compelling case to design a technique that can learn over multiple graphs and eventually aid in constructing a unified giant graph out of them.", "labels": [], "entities": []}, {"text": "While research on learning representations over single graph has progressed rapidly in recent years (, there is a conspicuous lack of principled approach to tackle the unique challenges involved in learning across multiple graphs.", "labels": [], "entities": []}, {"text": "One approach to multi-graph representation learning could be to first solve graph alignment problem to merge the graphs and then use existing relational learning methods on merged graph.", "labels": [], "entities": [{"text": "multi-graph representation learning", "start_pos": 16, "end_pos": 51, "type": "TASK", "confidence": 0.8089268406232198}]}, {"text": "Unfortunately, graph alignment is an important but still unsolved problem and there exist several techniques addressing its challenges () in limited settings.", "labels": [], "entities": [{"text": "graph alignment", "start_pos": 15, "end_pos": 30, "type": "TASK", "confidence": 0.7835343778133392}]}, {"text": "The key challenges for the graph alignment problem emanate from the fact that the real world data are noisy and intricate in nature.", "labels": [], "entities": [{"text": "graph alignment", "start_pos": 27, "end_pos": 42, "type": "TASK", "confidence": 0.728727713227272}]}, {"text": "The noisy or sparse data make it difficult to learn robust alignment features, and data abundance leads to computational challenges due to the combinatorial permutations needed for alignment.", "labels": [], "entities": []}, {"text": "These challenges are compounded in multi-relational settings due to heterogeneous nodes and edges in such graphs.", "labels": [], "entities": []}, {"text": "Recently, deep learning has shown significant impact in learning useful information over noisy, large-scale and heterogeneous graph data (.", "labels": [], "entities": []}, {"text": "We, therefore, posit that combining graph alignment task with deep representation learning across multi-relational graphs has potential to induce a synergistic effect on both tasks.", "labels": [], "entities": [{"text": "graph alignment", "start_pos": 36, "end_pos": 51, "type": "TASK", "confidence": 0.7294004857540131}]}, {"text": "Specifically, we identify that a key component of graph alignment process-entity linkage-also plays a vital role in learning across graphs.", "labels": [], "entities": [{"text": "graph alignment process-entity linkage-also", "start_pos": 50, "end_pos": 93, "type": "TASK", "confidence": 0.8261072337627411}]}, {"text": "For instance, the embeddings learned over two knowledge graphs for an actor should be closer to one another compared to the embeddings of all the other entities.", "labels": [], "entities": []}, {"text": "Similarly, the entities that are already aligned together across the two graphs should produce better embeddings due to the shared context and data.", "labels": [], "entities": []}, {"text": "To model this phenomenon, we propose LinkNBed, a novel deep learning framework that jointly performs representation learning and graph linkage task.", "labels": [], "entities": [{"text": "representation learning", "start_pos": 101, "end_pos": 124, "type": "TASK", "confidence": 0.8615116775035858}]}, {"text": "To achieve this, we identify key challenges involved in the learning process and make the following contributions to address them: \u2022 We propose novel and principled approach towards jointly learning entity representations and entity linkage.", "labels": [], "entities": []}, {"text": "The novelty of our framework stems from its ability to support linkage task across heterogeneous types of entities.", "labels": [], "entities": []}, {"text": "\u2022 We devise a graph-independent inductive framework that learns functions to capture contextual information for entities and relations.", "labels": [], "entities": []}, {"text": "It combines the structural and semantic information in individual graphs for joint inference in a principled manner.", "labels": [], "entities": []}, {"text": "\u2022 Labeled instances (specifically positive instances for linkage task) are typically very sparse and hence we design a novel multi-task loss function where entity linkage task is tackled in robust manner across various learning scenarios such as learning only with unlabeled instances or only with negative instances.", "labels": [], "entities": []}, {"text": "\u2022 We design an efficient training procedure to perform joint training in linear time in the number of triples.", "labels": [], "entities": []}, {"text": "We demonstrate superior performance of our method on two datasets curated from Freebase and IMDB against stateof-the-art neural embedding methods.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 79, "end_pos": 87, "type": "DATASET", "confidence": 0.9541215300559998}, {"text": "IMDB", "start_pos": 92, "end_pos": 96, "type": "DATASET", "confidence": 0.8996619582176208}]}], "datasetContent": [{"text": "We evaluate LinkNBed and baselines on two real world knowledge graphs: D-IMDB (derived from large scale IMDB data snapshot) and D-FB (derived from large scale Freebase data snapshot).", "labels": [], "entities": [{"text": "Freebase data snapshot", "start_pos": 159, "end_pos": 181, "type": "DATASET", "confidence": 0.962387482325236}]}, {"text": "Table 5.1 provides statistics for our final dataset used in the experiments.", "labels": [], "entities": []}, {"text": "Appendix B.1 provides complete details about dataset processing.", "labels": [], "entities": [{"text": "Appendix B.1", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.7802920937538147}, {"text": "dataset processing", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.6978616863489151}]}, {"text": "We evaluate our model using two inference tasks: Link Prediction.", "labels": [], "entities": []}, {"text": "Given a test triplet (e s , r, e o ), we first score this triplet using Eq.", "labels": [], "entities": [{"text": "Eq", "start_pos": 72, "end_pos": 74, "type": "METRIC", "confidence": 0.7899148464202881}]}, {"text": "10. We then replace e o with all other entities in the dataset and filter the resulting set of triplets as shown in).", "labels": [], "entities": []}, {"text": "We score the remaining set of perturbed triplets using Eq.", "labels": [], "entities": [{"text": "Eq", "start_pos": 55, "end_pos": 57, "type": "METRIC", "confidence": 0.6035016775131226}]}, {"text": "10. All the scored triplets are sorted based on the scores and then the rank of the ground truth triplet is used for the evaluation.", "labels": [], "entities": []}, {"text": "We use this ranking mechanism to compute HITS@10 (predicted rank \u2264 10) and reciprocal rank ( 1 rank ) of each test triplet.", "labels": [], "entities": [{"text": "HITS", "start_pos": 41, "end_pos": 45, "type": "METRIC", "confidence": 0.8693800568580627}, {"text": "reciprocal rank ( 1 rank )", "start_pos": 75, "end_pos": 101, "type": "METRIC", "confidence": 0.8650019764900208}]}, {"text": "We report the mean overall test samples.", "labels": [], "entities": []}, {"text": "In alignment with Insight 2, we pose a novel evaluation scheme to perform entity linkage.", "labels": [], "entities": []}, {"text": "Let there be two ground truth test sample triplets: (e X , e + Y , 1) representing a positive duplicate label and (e X , e \u2212 Y , 0) representing a negative duplicate label.", "labels": [], "entities": []}, {"text": "Algorithm 2 outlines the procedure to compute linkage probability or score q) for the pair (e X , e Y ).", "labels": [], "entities": []}, {"text": "We use L1 distance between the two vectors analogous", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics for Datasets: D-IMDB and D-FB", "labels": [], "entities": [{"text": "D-FB", "start_pos": 46, "end_pos": 50, "type": "DATASET", "confidence": 0.5889003872871399}]}, {"text": " Table 2: Link Prediction Results on both datasets", "labels": [], "entities": [{"text": "Link Prediction", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.629982590675354}]}, {"text": " Table 3: Entity Linkage Results -Unsupervised  case uses classifier at second step", "labels": [], "entities": [{"text": "Entity Linkage", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.853923112154007}]}]}