{"title": [{"text": "Sense-Aware Neural Models for Pun Location in Texts", "labels": [], "entities": [{"text": "Pun Location in Texts", "start_pos": 30, "end_pos": 51, "type": "TASK", "confidence": 0.8651023656129837}]}], "abstractContent": [{"text": "A homographic pun is a form of wordplay in which one signifier (usually a word) suggests two or more meanings by exploiting polysemy for an intended humorous or rhetorical effect.", "labels": [], "entities": [{"text": "homographic pun is a form of wordplay in which one signifier (usually a word) suggests two or more meanings by exploiting polysemy for an intended humorous or rhetorical effect", "start_pos": 2, "end_pos": 178, "type": "Description", "confidence": 0.784169336480479}]}, {"text": "In this paper, we focus on the task of pun location, which aims to identify the pun word in a given short text.", "labels": [], "entities": [{"text": "pun location", "start_pos": 39, "end_pos": 51, "type": "TASK", "confidence": 0.8096977472305298}]}, {"text": "We propose a sense-aware neu-ral model to address this challenging task.", "labels": [], "entities": []}, {"text": "Our model first obtains several WSD results for the text, and then leverages a bidi-rectional LSTM network to model each sequence of word senses.", "labels": [], "entities": []}, {"text": "The outputs at each time step for different LSTM networks are then concatenated for prediction.", "labels": [], "entities": []}, {"text": "Evaluation results on the benchmark SemEval 2017 dataset demonstrate the efficacy of our proposed model.", "labels": [], "entities": [{"text": "SemEval 2017 dataset", "start_pos": 36, "end_pos": 56, "type": "DATASET", "confidence": 0.7341919640700022}]}], "introductionContent": [{"text": "There exists a class of language constructs known as puns in natural language utterances and texts, and the speaker or writer intends fora certain word or other lexical item to be interpreted as simultaneously carrying two or more separate meanings.", "labels": [], "entities": []}, {"text": "Though puns are an important feature in many discourse types, they have attracted relatively little attention in the area of natural language processing.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 125, "end_pos": 152, "type": "TASK", "confidence": 0.6517268220583597}]}, {"text": "A pun is a form of wordplay in which a word suggests two or more meanings by exploiting polysemy, homonymy, or phonological similarity to another word, for an intended humorous or rhetorical effect.", "labels": [], "entities": [{"text": "A pun is a form of wordplay in which a word suggests two or more meanings by exploiting polysemy, homonymy, or phonological similarity to another word, for an intended humorous or rhetorical effect", "start_pos": 0, "end_pos": 197, "type": "Description", "confidence": 0.77679729130533}]}, {"text": "Puns where the two meanings share the same pronunciation are known as homographic puns, which are the focus of this study.", "labels": [], "entities": []}, {"text": "For example, the following punning joke exploits contrasting meanings of the word \"interest\" and it is a homographic pun.", "labels": [], "entities": []}, {"text": "I used to be a banker but I lost interest.", "labels": [], "entities": []}, {"text": "Since the pun word plays the key role in forming a pun, it is very important and meaningful to identify the pun word in a given text.", "labels": [], "entities": []}, {"text": "The task of identifying the pun word is known as pun location, which is defined in SemEval 2017 Task 7 . In order to address this special task, various approaches have been attempted, including rule based approach, knowledgebased approach and supervised approach.", "labels": [], "entities": [{"text": "SemEval 2017 Task 7", "start_pos": 83, "end_pos": 102, "type": "TASK", "confidence": 0.6133510917425156}]}, {"text": "However, these approaches do not achieve good results, and the best F1 score for homographic pun location is just 0.6631, which is achieved by the Idiom Savant system with a knowledge based approach (.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9850043654441833}, {"text": "homographic pun location", "start_pos": 81, "end_pos": 105, "type": "TASK", "confidence": 0.6976880033810934}]}, {"text": "The results demonstrate that pun location is a very challenging task.", "labels": [], "entities": [{"text": "pun location", "start_pos": 29, "end_pos": 41, "type": "TASK", "confidence": 0.9225071668624878}]}, {"text": "In order to address this challenging task and improve the state-of-the-art results, we propose a sense-aware neural model in this study.", "labels": [], "entities": []}, {"text": "Our model first obtains several WSD (Word Sense Disambiguation) results for the text, and leverages a bidirectional LSTM network to model each sequence of word senses.", "labels": [], "entities": [{"text": "WSD (Word Sense Disambiguation)", "start_pos": 32, "end_pos": 63, "type": "TASK", "confidence": 0.6170782397190729}]}, {"text": "The outputs at each time step for different LSTM networks are then concatenated for pun word prediction.", "labels": [], "entities": [{"text": "pun word prediction", "start_pos": 84, "end_pos": 103, "type": "TASK", "confidence": 0.690353532632192}]}, {"text": "Evaluation results of cross-validation on the benchmark SemEval 2017 dataset demonstrate the efficacy of our proposed model.", "labels": [], "entities": [{"text": "SemEval 2017 dataset", "start_pos": 56, "end_pos": 76, "type": "DATASET", "confidence": 0.783147782087326}]}, {"text": "The contributions of this paper are summarized as follows: \u2022 We propose a novel sense-aware neural model to address the pun location task.", "labels": [], "entities": [{"text": "pun location task", "start_pos": 120, "end_pos": 137, "type": "TASK", "confidence": 0.7525729934374491}]}, {"text": "\u2022 Our proposed model outperforms several baseline neural models and achieves the state-of-theart performance.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the benchmark dataset from SemEval 2017 Task 7.", "labels": [], "entities": [{"text": "benchmark dataset from SemEval 2017 Task 7", "start_pos": 11, "end_pos": 53, "type": "DATASET", "confidence": 0.7272213484559741}]}, {"text": "There area total of 2250 sentences in the dataset, 1607 of which contain a pun.", "labels": [], "entities": []}, {"text": "For Pun Location, we only use sentences with pun words for evaluation, the same as the task setting.", "labels": [], "entities": [{"text": "Pun Location", "start_pos": 4, "end_pos": 16, "type": "TASK", "confidence": 0.9515382349491119}]}, {"text": "Since no training data is provided, so we test our models with 10-fold cross validation.", "labels": [], "entities": []}, {"text": "We combine the output results on each test set of all 10 folds and then calculate precision, recall and F-score on the combined set.", "labels": [], "entities": [{"text": "precision", "start_pos": 82, "end_pos": 91, "type": "METRIC", "confidence": 0.9998146891593933}, {"text": "recall", "start_pos": 93, "end_pos": 99, "type": "METRIC", "confidence": 0.9996076226234436}, {"text": "F-score", "start_pos": 104, "end_pos": 111, "type": "METRIC", "confidence": 0.9993491768836975}]}, {"text": "Thus the scores are comparable to the official results based on the whole test set.", "labels": [], "entities": []}, {"text": "We compared our proposed SAM model (w/ three groups of WSD results) with the baseline model BM.", "labels": [], "entities": []}, {"text": "We also apply the bi-directional LSTM model on the sequence of senses for each single WSD result and thus get BiLSTM-WSD1 through BiLSTM-WSD4.", "labels": [], "entities": [{"text": "BiLSTM-WSD1", "start_pos": 110, "end_pos": 121, "type": "METRIC", "confidence": 0.8018067479133606}]}, {"text": "Moreover, we apply SVM and CRF models with various features (e.g., ngram, POS tagging, word location, word similarity, etc.) on this task.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 74, "end_pos": 85, "type": "TASK", "confidence": 0.741192489862442}]}, {"text": "In the table, we also present the results of the best participating system Idiom Savant, and two official baselines (last word and max. polysemy).", "labels": [], "entities": [{"text": "Idiom Savant", "start_pos": 75, "end_pos": 87, "type": "DATASET", "confidence": 0.8916988968849182}]}, {"text": "We can see that the baseline BM model does not perform well, while the CRF model performs very well.", "labels": [], "entities": []}, {"text": "The results of BiLSTM-WSD1 through BiLSTM-WSD4 are much better than the BM model, which indicates that the sense-level prediction is more suitable than the word-level prediction.", "labels": [], "entities": []}, {"text": "Our proposed SAM model with different groups of WSD results can further improve the performance, because different WSD results may provide complementary information for pun location.", "labels": [], "entities": [{"text": "pun location", "start_pos": 169, "end_pos": 181, "type": "TASK", "confidence": 0.7927737534046173}]}, {"text": "The SAM model with G1 performs the best, even outperforming the SAM model with more WSD results (G3), which indicates the necessity for choosing proper WSD results.", "labels": [], "entities": []}], "tableCaptions": []}