{"title": [{"text": "Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting", "labels": [], "entities": []}], "abstractContent": [{"text": "Inspired by how humans summarize long documents, we propose an accurate and fast summarization model that first selects salient sentences and then rewrites them abstractively (i.e., compresses and paraphrases) to generate a concise overall summary.", "labels": [], "entities": [{"text": "summarize long documents", "start_pos": 23, "end_pos": 47, "type": "TASK", "confidence": 0.8931509057680765}]}, {"text": "We use a novel sentence-level policy gradient method to bridge the non-differentiable computation between these two neural networks in a hierarchical way, while maintaining language fluency.", "labels": [], "entities": []}, {"text": "Empirically , we achieve the new state-of-the-art on all metrics (including human evaluation) on the CNN/Daily Mail dataset, as well as significantly higher abstractiveness scores.", "labels": [], "entities": [{"text": "CNN/Daily Mail dataset", "start_pos": 101, "end_pos": 123, "type": "DATASET", "confidence": 0.9345422387123108}]}, {"text": "Moreover, by first operating at the sentence-level and then the word-level, we enable parallel decoding of our neural generative model that results in substantially faster (10-20x) inference speed as well as 4x faster training convergence than previous long-paragraph encoder-decoder models.", "labels": [], "entities": []}, {"text": "We also demonstrate the generalization of our model on the test-only DUC-2002 dataset, where we achieve higher scores than a state-of-the-art model.", "labels": [], "entities": [{"text": "DUC-2002 dataset", "start_pos": 69, "end_pos": 85, "type": "DATASET", "confidence": 0.9790739119052887}]}], "introductionContent": [{"text": "The task of document summarization has two main paradigms: extractive and abstractive.", "labels": [], "entities": [{"text": "document summarization", "start_pos": 12, "end_pos": 34, "type": "TASK", "confidence": 0.5523680299520493}]}, {"text": "The former method directly chooses and outputs the salient sentences (or phrases) in the original document).", "labels": [], "entities": []}, {"text": "The latter abstractive approach involves rewriting the summary (), and has seen substantial recent gains due to neural sequence-tosequence models ().", "labels": [], "entities": []}, {"text": "Abstractive models can be more concise by performing generation from scratch, but they suffer from slow and inaccurate encoding of very long documents, with the attention model being required to look at all encoded words (in long paragraphs) for decoding each generated summary word (slow, one by one sequentially).", "labels": [], "entities": []}, {"text": "Abstractive models also suffer from redundancy (repetitions), especially when generating multi-sentence summary.", "labels": [], "entities": []}, {"text": "To address both these issues and combine the advantages of both paradigms, we propose a hybrid extractive-abstractive architecture, with policy-based reinforcement learning (RL) to bridge together the two networks.", "labels": [], "entities": []}, {"text": "Similar to how humans summarize long documents, our model first uses an extractor agent to select salient sentences or highlights, and then employs an abstractor network to rewrite (i.e., compress and paraphrase) each of these extracted sentences.", "labels": [], "entities": [{"text": "summarize long documents", "start_pos": 22, "end_pos": 46, "type": "TASK", "confidence": 0.9014264345169067}]}, {"text": "To overcome the non-differentiable behavior of our extractor and train on available document-summary pairs without saliency label, we next use actorcritic policy gradient with sentence-level metric rewards to connect these two neural networks and to learn sentence saliency.", "labels": [], "entities": []}, {"text": "We also avoid common language fluency issues ( by preventing the policy gradients from affecting the abstractive summarizer's word-level training, which is supported by our human evaluation study.", "labels": [], "entities": []}, {"text": "Our sentence-level reinforcement learning takes into account the word-sentence hierarchy, which better models the language structure and makes parallelization possible.", "labels": [], "entities": []}, {"text": "Our extractor combines reinforcement learning and pointer networks, which is inspired by's attempt to solve the Traveling Salesman Problem.", "labels": [], "entities": []}, {"text": "Our abstractor is a simple encoder-aligner-decoder model (with copying) and is trained on pseudo document-summary sentence pairs obtained via simple automatic matching criteria.", "labels": [], "entities": []}, {"text": "Thus, our method incorporates the abstractive paradigm's advantages of concisely rewriting sentences and generating novel words from the full vocabulary, yet it adopts intermediate extractive behavior to improve the overall model's quality, speed, and stability.", "labels": [], "entities": [{"text": "speed", "start_pos": 241, "end_pos": 246, "type": "METRIC", "confidence": 0.9836185574531555}]}, {"text": "Instead of encoding and attending to every word in the long input document sequentially, our model adopts a human-inspired coarse-to-fine approach that first extracts all the salient sentences and then decodes (rewrites) them (in parallel).", "labels": [], "entities": []}, {"text": "This also avoids almost all redundancy issues because the model has already chosen non-redundant salient sentences to abstractively summarize (but adding an optional final reranker component does give additional gains by removing the fewer across-sentence repetitions).", "labels": [], "entities": []}, {"text": "Empirically, our approach is the new state-ofthe-art on all ROUGE metrics) as well as on METEOR of the CNN/Daily Mail dataset, achieving statistically significant improvements over previous models that use complex long-encoder, copy, and coverage mechanisms ().", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 60, "end_pos": 65, "type": "METRIC", "confidence": 0.8798136711120605}, {"text": "METEOR", "start_pos": 89, "end_pos": 95, "type": "METRIC", "confidence": 0.9917945265769958}, {"text": "CNN/Daily Mail dataset", "start_pos": 103, "end_pos": 125, "type": "DATASET", "confidence": 0.9147684931755066}]}, {"text": "The test-only DUC-2002 improvement also shows our model's better generalization than this strong abstractive system.", "labels": [], "entities": [{"text": "DUC-2002", "start_pos": 14, "end_pos": 22, "type": "DATASET", "confidence": 0.8065650463104248}]}, {"text": "In addition, we surpass the popular lead-3 baseline on all ROUGE scores with an abstractive model.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 59, "end_pos": 64, "type": "METRIC", "confidence": 0.9212695360183716}]}, {"text": "Moreover, our sentence-level abstractive rewriting module also produces substantially more (3x) novel N -grams that are not seen in the input document, as compared to the strong flat-structured model of.", "labels": [], "entities": []}, {"text": "This empirically justifies that our RL-guided extractor has learned sentence saliency, rather than benefiting from simply copying longer sentences.", "labels": [], "entities": [{"text": "RL-guided extractor", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.9093354940414429}]}, {"text": "We also show that our model maintains the same level of fluency as a conventional RNN-based model because the reward does not leak to our abstractor's word-level training.", "labels": [], "entities": []}, {"text": "Finally, our model's training is 4x and inference is more than 20x faster than the previous state-of-the-art.", "labels": [], "entities": [{"text": "inference", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9505884051322937}]}, {"text": "The optional final reranker gives further improvements while maintaining a 7x speedup.", "labels": [], "entities": []}, {"text": "Overall, our contribution is three fold: First we propose a novel sentence-level RL technique for the well-known task of abstractive summarization, effectively utilizing the word-then-sentence hierarchical structure without annotated matching sentence-pairs between the document and ground truth summary.", "labels": [], "entities": [{"text": "abstractive summarization", "start_pos": 121, "end_pos": 146, "type": "TASK", "confidence": 0.49333785474300385}]}, {"text": "Next, our model achieves the new state-of-the-art on all metrics of multiple versions of a popular summarization dataset (as well as a test-only dataset) both extractively and abstractively, without loss in language fluency (also demonstrated via human evaluation and abstractiveness scores).", "labels": [], "entities": []}, {"text": "Finally, our parallel decoding results in a significant 10-20x speed-up over the previous best neural abstractive summarization system with even better accuracy.", "labels": [], "entities": [{"text": "neural abstractive summarization", "start_pos": 95, "end_pos": 127, "type": "TASK", "confidence": 0.689845860004425}, {"text": "accuracy", "start_pos": 152, "end_pos": 160, "type": "METRIC", "confidence": 0.9970255494117737}]}], "datasetContent": [{"text": "Please refer to the supplementary for full training details (all hyperparameter tuning was performed on the validation set).", "labels": [], "entities": []}, {"text": "We use the CNN/Daily Mail dataset () modified for summarization (.", "labels": [], "entities": [{"text": "CNN/Daily Mail dataset", "start_pos": 11, "end_pos": 33, "type": "DATASET", "confidence": 0.9405559062957763}, {"text": "summarization", "start_pos": 50, "end_pos": 63, "type": "TASK", "confidence": 0.9665254950523376}]}, {"text": "Because there are two versions of the dataset, original text and entity anonymized, we show results on both versions of the dataset fora fair comparison to prior works.", "labels": [], "entities": []}, {"text": "The experiment runs training and evaluation for each version separately.", "labels": [], "entities": []}, {"text": "Despite the fact that the 2 versions have been considered separately by the summarization community as 2 different datasets, we use same hyper-parameter values for both dataset versions to show the generalization of our model.", "labels": [], "entities": []}, {"text": "We also show improvements on the DUC-2002 dataset in a test-only setup.", "labels": [], "entities": [{"text": "DUC-2002 dataset", "start_pos": 33, "end_pos": 49, "type": "DATASET", "confidence": 0.9859525561332703}]}, {"text": "For all the datasets, we evaluate standard ROUGE-1, ROUGE-2, and ROUGE-L (Lin, 2004) on fulllength F 1 (with stemming) following previous works (.", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 43, "end_pos": 50, "type": "METRIC", "confidence": 0.901584267616272}, {"text": "ROUGE-2", "start_pos": 52, "end_pos": 59, "type": "METRIC", "confidence": 0.7996241450309753}, {"text": "ROUGE-L", "start_pos": 65, "end_pos": 72, "type": "METRIC", "confidence": 0.9559531211853027}]}, {"text": "Following, we also evaluate on METEOR) fora more thorough analysis.", "labels": [], "entities": [{"text": "METEOR", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.8867354989051819}]}, {"text": "We also conduct human evaluation to ensure robustness of our training procedure.", "labels": [], "entities": []}, {"text": "We measure relevance and readability of the summaries.", "labels": [], "entities": [{"text": "relevance", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.9756410717964172}]}, {"text": "Relevance is based on the summary containing important, salient information from the input article, being correct by avoiding contradictory/unrelated information, and avoiding repeated/redundant information.", "labels": [], "entities": [{"text": "Relevance", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9495140314102173}]}, {"text": "Readability is based on the summarys fluency, grammaticality, and coherence.", "labels": [], "entities": []}, {"text": "To evaluate both these criteria, we design the following Amazon MTurk experiment: we randomly select 100 samples from the CNN/DM test set and ask the human testers (3 for each sample) to rank between summaries (for relevance and readability) produced by our model and that of (the models were anonymized and randomly shuffled), i.e. A is better, B is better, both are equally good/bad.", "labels": [], "entities": [{"text": "CNN/DM test set", "start_pos": 122, "end_pos": 137, "type": "DATASET", "confidence": 0.8882857084274292}]}, {"text": "Following previous work, the input article and ground truth summaries are also shown to the human participants in addition to the two model summaries.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results on the original, non-anonymized CNN/Daily Mail dataset. Adding RL gives statisti- cally significant improvements for all metrics over non-RL rnn-ext models (and over the state-of-the-art  See et al.", "labels": [], "entities": [{"text": "CNN/Daily Mail dataset", "start_pos": 50, "end_pos": 72, "type": "DATASET", "confidence": 0.918576693534851}]}, {"text": " Table 2: ROUGE for anonymized CNN/DM.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9830817580223083}, {"text": "CNN/DM", "start_pos": 31, "end_pos": 37, "type": "DATASET", "confidence": 0.6812881231307983}]}, {"text": " Table 3: Generalization to DUC-2002 (F1).", "labels": [], "entities": [{"text": "Generalization", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9240111112594604}, {"text": "DUC-2002 (F1)", "start_pos": 28, "end_pos": 41, "type": "DATASET", "confidence": 0.6980035454034805}]}, {"text": " Table 4: Human Evaluation: pairwise comparison  between our final model and See et al. (2017).", "labels": [], "entities": []}, {"text": " Table 5: Speed comparison with See et al. (2017).", "labels": [], "entities": [{"text": "Speed", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9835854768753052}]}, {"text": " Table 6: Abstractiveness: novel n-gram counts.", "labels": [], "entities": [{"text": "Abstractiveness", "start_pos": 10, "end_pos": 25, "type": "METRIC", "confidence": 0.9828459620475769}]}]}