{"title": [], "abstractContent": [{"text": "End-to-end learning framework is useful for building dialog systems for its simplicity in training and efficiency in model updating.", "labels": [], "entities": []}, {"text": "However, current end-to-end approaches only consider user semantic inputs in learning and under-utilize other user information.", "labels": [], "entities": []}, {"text": "Therefore, we propose to include user sentiment obtained through multimodal information (acous-tic, dialogic and textual), in the end-to-end learning framework to make systems more user-adaptive and effective.", "labels": [], "entities": []}, {"text": "We incorporated user sentiment information in both supervised and reinforcement learning settings.", "labels": [], "entities": []}, {"text": "In both settings, adding sentiment information reduced the dialog length and improved the task success rate on a bus information search task.", "labels": [], "entities": []}, {"text": "This work is the first attempt to incorporate multimodal user information in the adaptive end-to-end dialog system training framework and attained state-of-the-art performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "Most of us have had frustrating experience and even expressed anger towards automated customer service systems.", "labels": [], "entities": []}, {"text": "Unfortunately, none of the current commercial systems can detect user sentiment and let alone act upon it.", "labels": [], "entities": []}, {"text": "Researchers have included user sentiment in rule-based systems, where there are strictly-written rules that guide the system to react to user sentiment.", "labels": [], "entities": []}, {"text": "Because traditional modular-based systems are harder to train, to update with new data and to debug errors, end-to-end trainable systems are more popular.", "labels": [], "entities": []}, {"text": "However, no work has tried to incorporate sentiment information in the end-to-end trainable systems so far to create sentiment-adaptive systems that are easy to train.", "labels": [], "entities": []}, {"text": "The ultimate evaluators of dialog systems are users.", "labels": [], "entities": []}, {"text": "Therefore, we believe dialog system research should strive for better user satisfaction.", "labels": [], "entities": []}, {"text": "In this paper, we not only included user sentiment information as an additional context feature in an end-to-end supervised policy learning model, but also incorporated user sentiment information as an immediate reward in a reinforcement learning model.", "labels": [], "entities": []}, {"text": "We believe that providing extra feedback from the user would guide the model to adapt to user behaviour and learn the optimal policy faster and better.", "labels": [], "entities": []}, {"text": "There are three contributions in this work: 1) an audio dataset 1 with sentiment annotation (the annotators were given the complete dialog history); 2) an automatic sentiment detector that considers conversation history by using dialogic features, textual features and traditional acoustic features; and 3) end-to-end trainable dialog policies adaptive to user sentiment in both supervised and reinforcement learning settings.", "labels": [], "entities": []}, {"text": "We believe such dialog systems with better user adaptation are beneficial in various domains, such as customer services, education, healthcare and entertainment.", "labels": [], "entities": []}], "datasetContent": [{"text": "We experimented our methods on DSTC1 dataset (), which has a bus information search task.", "labels": [], "entities": [{"text": "DSTC1 dataset", "start_pos": 31, "end_pos": 44, "type": "DATASET", "confidence": 0.9720264077186584}]}, {"text": "Although DSTC2 dataset is a more commonly-used dataset in evaluating dialog system performance, the audio recordings of DSTC2 are not publicly available and therefore, DSTC1 was chosen.", "labels": [], "entities": [{"text": "DSTC2 dataset", "start_pos": 9, "end_pos": 22, "type": "DATASET", "confidence": 0.954095721244812}, {"text": "DSTC1", "start_pos": 168, "end_pos": 173, "type": "DATASET", "confidence": 0.9308806657791138}]}, {"text": "There area total of 914 dialogs in DSTC1 with both text and audio information.", "labels": [], "entities": [{"text": "DSTC1", "start_pos": 35, "end_pos": 40, "type": "DATASET", "confidence": 0.9550514817237854}]}, {"text": "Statistics of this dataset are shown in.", "labels": [], "entities": []}, {"text": "We used the automatic speech recognition (ASR) as the user text inputs instead of the transcripts, because the system's action decisions heavily depend on ASR.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 12, "end_pos": 46, "type": "TASK", "confidence": 0.7578518589337667}]}, {"text": "There are 212 system action templates in this dataset.", "labels": [], "entities": []}, {"text": "Four types of entities are involved, <place>, <time>, <route>, and <neighborhood>.", "labels": [], "entities": []}, {"text": "We designed four experiments with different reward functions.", "labels": [], "entities": []}, {"text": "A discount factor of 0.9 was applied to all the experiments.", "labels": [], "entities": [{"text": "discount", "start_pos": 2, "end_pos": 10, "type": "METRIC", "confidence": 0.9799342751502991}]}, {"text": "And the maximum number of turns is 15.", "labels": [], "entities": []}, {"text": "Following, we used LSTM with 32 hidden units for the RNN in the HCN and AdaDelta for the optimization, and updated the reinforcement learning policy after each dialog.", "labels": [], "entities": [{"text": "HCN", "start_pos": 64, "end_pos": 67, "type": "DATASET", "confidence": 0.9319954514503479}]}, {"text": "The \u270f-greedy exploration strategy was applied here.", "labels": [], "entities": []}, {"text": "Given that the entire system was simulated, we only used the presence of each entity and the last action taken by the system as the context features, and didn't use bag-of-words or utterance embedding features.", "labels": [], "entities": []}, {"text": "In order to evaluate the method, we froze the policy after every 200 updates, and ran 500 simulated dialogs to calculate the task success rate.", "labels": [], "entities": []}, {"text": "We repeated the process 20 times and reported the average performance in, 2 and.", "labels": [], "entities": []}, {"text": "We evaluated every model on two metrics: dialog lengths and task success rates.", "labels": [], "entities": []}, {"text": "We observed in that all the sentiment reward functions, even SRRS with random samples, reduced the average length of the dialogs, meaning that the system finished the task faster.", "labels": [], "entities": [{"text": "SRRS", "start_pos": 61, "end_pos": 65, "type": "METRIC", "confidence": 0.8360077738761902}]}, {"text": "The rationale behind is that by adapting to user sentiment, the model can avoid unnecessary system actions to make systems more effective.", "labels": [], "entities": []}, {"text": "In terms of success rate, sentiment reward with both repetition and interruption penalties (SRRIP) performed the best (see).", "labels": [], "entities": [{"text": "repetition and interruption penalties (SRRIP)", "start_pos": 53, "end_pos": 98, "type": "METRIC", "confidence": 0.8147061041423252}]}, {"text": "In, SR-RIP is converging faster than the baseline.", "labels": [], "entities": []}, {"text": "For example, around 5000 iterations, it outperforms the baseline by 5% in task success rate (60% vs 55%) with statistical significance (p < 0.01).", "labels": [], "entities": []}, {"text": "It also converges to a better task success rate after 10000 iterations (92.4% vs 94.3%, p < 0.01).", "labels": [], "entities": []}, {"text": "We describe all models' performance in in terms of the convergent success rate calculated as the mean success rate after 10000 dialogs.", "labels": [], "entities": []}, {"text": "We observed that incorporating various sentiment rewards improved the success rate and expedited the training process overall with statistical significance.", "labels": [], "entities": []}, {"text": "We found that even sentiment reward with random samples (SRRS) outperformed the baseline after convergence.", "labels": [], "entities": [{"text": "sentiment reward", "start_pos": 19, "end_pos": 35, "type": "TASK", "confidence": 0.9190967977046967}]}, {"text": "By adding penalties for  repetition, the algorithm covered more data points, and therefore, the task success rate and the convergence speed improved.", "labels": [], "entities": [{"text": "repetition", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.937530517578125}, {"text": "convergence speed", "start_pos": 122, "end_pos": 139, "type": "METRIC", "confidence": 0.863406628370285}]}, {"text": "We also found that penalizing interruption and repetition together (SR-RIP) achieved a slightly better performance compared to penalizing repetition only (SRRP).", "labels": [], "entities": [{"text": "repetition", "start_pos": 47, "end_pos": 57, "type": "METRIC", "confidence": 0.9748905897140503}]}, {"text": "This suggests that interruptions is another factor to consider when approximating sentiment.", "labels": [], "entities": [{"text": "approximating sentiment", "start_pos": 68, "end_pos": 91, "type": "TASK", "confidence": 0.7038888931274414}]}, {"text": "But the performances between SRRP and SRRIP is not significant.", "labels": [], "entities": [{"text": "SRRP", "start_pos": 29, "end_pos": 33, "type": "DATASET", "confidence": 0.5477830171585083}, {"text": "SRRIP", "start_pos": 38, "end_pos": 43, "type": "DATASET", "confidence": 0.6266794800758362}]}, {"text": "Our guess is that only 7.5% turns in our data contains interruption and the penalty is just an extra -1, so the model confused this signal with noises.", "labels": [], "entities": []}, {"text": "But given more interruptions in the data, interruptions could still be helpful.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the text data.", "labels": [], "entities": [{"text": "text data", "start_pos": 28, "end_pos": 37, "type": "DATASET", "confidence": 0.8517743945121765}]}, {"text": " Table 2: Statistics of the annotated audio set.", "labels": [], "entities": []}, {"text": " Table 3: Dialogic features' relative importance  rank in sentiment detection.", "labels": [], "entities": [{"text": "sentiment detection", "start_pos": 58, "end_pos": 77, "type": "TASK", "confidence": 0.977332204580307}]}, {"text": " Table 4: Results of sentiment detectors using dif- ferent features. The best result is highlighted in  bold and * indicates statistical significance com- pared to the baseline, which is using acoustic fea- tures only. (p < 0.0001)", "labels": [], "entities": [{"text": "sentiment detectors", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.944811999797821}]}, {"text": " Table 5: Results of different SL models. The best  result is highlighted in bold. \u21e4 indicates that the  result is significantly better than the baseline (p <  0.01). Dialog accuracy indicates if all turns in a  dialog are correct, so it's low. For DSTC2 data,  the state-of-art dialog accuracy is 1.9%, consistent  with our results.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 174, "end_pos": 182, "type": "METRIC", "confidence": 0.9224171042442322}, {"text": "DSTC2 data", "start_pos": 249, "end_pos": 259, "type": "DATASET", "confidence": 0.8997611701488495}, {"text": "accuracy", "start_pos": 286, "end_pos": 294, "type": "METRIC", "confidence": 0.992161214351654}]}]}