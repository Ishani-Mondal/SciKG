{"title": [{"text": "Policy Gradient as a Proxy for Dynamic Oracles in Constituency Parsing", "labels": [], "entities": [{"text": "Parsing", "start_pos": 63, "end_pos": 70, "type": "TASK", "confidence": 0.6933696866035461}]}], "abstractContent": [{"text": "Dynamic oracles provide strong supervision for training constituency parsers with exploration, but must be custom defined fora given parser's transition system.", "labels": [], "entities": []}, {"text": "We explore using a policy gradient method as a parser-agnostic alternative.", "labels": [], "entities": []}, {"text": "In addition to directly optimizing fora tree-level metric such as F1, policy gradient has the potential to reduce exposure bias by allowing exploration during training; moreover, it does not require a dynamic oracle for supervision.", "labels": [], "entities": [{"text": "F1", "start_pos": 66, "end_pos": 68, "type": "METRIC", "confidence": 0.99662184715271}]}, {"text": "On four constituency parsers in three languages, the method substantially outperforms static oracle likelihood training in almost all settings.", "labels": [], "entities": []}, {"text": "For parsers where a dynamic oracle is available (in-cluding a novel oracle which we define for the transition system of Dyer et al.", "labels": [], "entities": []}, {"text": "(2016)), policy gradient typically recaptures a substantial fraction of the performance gain afforded by the dynamic oracle.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many recent state-of-the-art models for constituency parsing are transition based, decomposing production of each parse tree into a sequence of action decisions, building on along line of work in transition-based parsing.", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 40, "end_pos": 60, "type": "TASK", "confidence": 0.7836391031742096}]}, {"text": "However, models of this type, which decompose structure prediction into sequential decisions, can be prone to two issues (.", "labels": [], "entities": [{"text": "structure prediction", "start_pos": 46, "end_pos": 66, "type": "TASK", "confidence": 0.7346681654453278}]}, {"text": "The first is exposure bias: if, at training time, the model only observes states resulting from correct past decisions, it will not be prepared to recover from its own mistakes during prediction.", "labels": [], "entities": []}, {"text": "Second is the loss mismatch between the action-level loss used at training and any structure-level evaluation metric, for example F1.", "labels": [], "entities": [{"text": "F1", "start_pos": 130, "end_pos": 132, "type": "METRIC", "confidence": 0.9953712821006775}]}, {"text": "A large family of techniques address the exposure bias problem by allowing the model to make mistakes and explore incorrect states during training, supervising actions at the resulting states using an expert policy; these expert policies are typically referred to as dynamic oracles in parsing.", "labels": [], "entities": []}, {"text": "While dynamic oracles have produced substantial improvements in constituency parsing performance (, they must be custom designed for each transition system.", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 64, "end_pos": 84, "type": "TASK", "confidence": 0.9035034477710724}]}, {"text": "To address the loss mismatch problem, another line of work has directly optimized for structurelevel cost functions.", "labels": [], "entities": []}, {"text": "Recent methods applied to models that produce output sequentially commonly use policy gradient () or beam search ( at training time to minimize a structured cost.", "labels": [], "entities": []}, {"text": "These methods also reduce exposure bias through exploration but do not require an expert policy for supervision.", "labels": [], "entities": []}, {"text": "In this work, we apply a simple policy gradient method to train four different state-of-theart transition-based constituency parsers to maximize expected F1.", "labels": [], "entities": [{"text": "F1", "start_pos": 154, "end_pos": 156, "type": "METRIC", "confidence": 0.9817109107971191}]}, {"text": "We compare against training with a dynamic oracle (both to supervise exploration and provide loss-augmentation) where one is available, including a novel dynamic oracle that we define for the top-down transition system of.", "labels": [], "entities": []}, {"text": "We find that while policy gradient usually outperforms standard likelihood training, it typically underperforms the dynamic oracle-based methods -which provide direct, model-aware supervision about which actions are best to take from arbitrary parser states.", "labels": [], "entities": []}, {"text": "However, a substantial fraction of each dynamic oracle's performance gain is often recovered using the model-agnostic policy gradient method.", "labels": [], "entities": []}, {"text": "In the process, we obtain new state-of-the-art results for single-model discriminative transition-based parsers trained on the English PTB (92.6 F1), French Treebank (83.5 F1), and Penn Chinese Treebank Version 5.1 (87.0 F1).", "labels": [], "entities": [{"text": "English PTB", "start_pos": 127, "end_pos": 138, "type": "DATASET", "confidence": 0.9062697291374207}, {"text": "French Treebank", "start_pos": 150, "end_pos": 165, "type": "DATASET", "confidence": 0.9824950993061066}, {"text": "Penn Chinese Treebank Version 5.1", "start_pos": 181, "end_pos": 214, "type": "DATASET", "confidence": 0.9663049936294555}]}], "datasetContent": [{"text": "We compare the constituency parsers listed in Section 2 using the above training methods.", "labels": [], "entities": [{"text": "constituency parsers", "start_pos": 15, "end_pos": 35, "type": "TASK", "confidence": 0.7330782413482666}]}, {"text": "Our experiments use the English PTB (, French Treebank (, and Penn Chinese Treebank (CTB) Version 5.1 ().", "labels": [], "entities": [{"text": "English PTB", "start_pos": 24, "end_pos": 35, "type": "DATASET", "confidence": 0.8504345118999481}, {"text": "French Treebank", "start_pos": 39, "end_pos": 54, "type": "DATASET", "confidence": 0.9786688685417175}, {"text": "Penn Chinese Treebank (CTB) Version 5.1", "start_pos": 62, "end_pos": 101, "type": "DATASET", "confidence": 0.9688037857413292}]}, {"text": "Training To compare the training procedures as closely as possible, we train all models fora given parser in a given language from the same randomly-initialized parameter values.", "labels": [], "entities": []}, {"text": "We train two different versions of the RNNG model: one model using size 128 for the LSTMs and hidden states (following the original work), and a larger model with size 256.", "labels": [], "entities": []}, {"text": "We perform evaluation using greedy search in the Span-Based and Top-Down parsers, and beam search with beam size 10 for the RNNG and In-Order parsers.", "labels": [], "entities": [{"text": "RNNG", "start_pos": 124, "end_pos": 128, "type": "DATASET", "confidence": 0.8312128186225891}]}, {"text": "We found that beam search improved performance for these two parsers by around 0.1-0.3 F1 on the development sets, and use it at inference time in every setting for these two parsers.", "labels": [], "entities": [{"text": "beam search", "start_pos": 14, "end_pos": 25, "type": "TASK", "confidence": 0.8149781823158264}, {"text": "F1", "start_pos": 87, "end_pos": 89, "type": "METRIC", "confidence": 0.9969180822372437}]}, {"text": "In our experiments, policy gradient typically requires more epochs of training to reach performance comparable to either of the dynamic oraclebased exploration methods.", "labels": [], "entities": []}, {"text": "gives atypical learning curve, for the Top-Down parser on English.", "labels": [], "entities": []}, {"text": "We found that policy gradient is also more sensitive to the number of candidates sampled per sentence than either of the other exploration methods, with best performance on the development set usually obtained with k = 10 fork \u2208 {2, 5, 10} (where k also counts the sentence's gold tree, included in the candidate set).", "labels": [], "entities": []}, {"text": "See Appendix A in the supplemental material for the values of k used.", "labels": [], "entities": [{"text": "Appendix A", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9578166306018829}]}, {"text": "Tags, Embeddings, and Morphology We largely follow previous work for each parser in our use of predicted part-of-speech tags, pretrained word embeddings, and morphological features.", "labels": [], "entities": []}, {"text": "All parsers use predicted part-of-speech tags as part of their sentence representations.", "labels": [], "entities": []}, {"text": "For English and Chinese, we follow the setup of: training the Stanford tagger () on the training set of each parsing corpus to predict development and test set tags, and using 10-way jackknifing to predict tags for the training set.", "labels": [], "entities": []}, {"text": "For French, we use the predicted tags and morphological features provided with the SPMRL dataset ().", "labels": [], "entities": [{"text": "SPMRL dataset", "start_pos": 83, "end_pos": 96, "type": "DATASET", "confidence": 0.9103658497333527}]}, {"text": "We modified the publicly released code for all parsers to use predicted morphological features for French.", "labels": [], "entities": []}, {"text": "We follow the approach outlined by and for representing morphological features as learned embeddings, and use the same dimensions for these embeddings as in their papers.", "labels": [], "entities": []}, {"text": "For RNNG and In-Order, we similarly use 10-dimensional learned embeddings for each morphological feature, feeding them as LSTM inputs for each word alongside the word and part-of-speech tag embeddings.", "labels": [], "entities": []}, {"text": "For RNNG and the In-Order parser, we use the same word embeddings as the original papers for English and Chinese, and train 100-dimensional word embeddings for French using the structured skip-gram method of on French Wikipedia.", "labels": [], "entities": []}, {"text": "compares parser F1 by training procedure for each language.", "labels": [], "entities": [{"text": "F1", "start_pos": 16, "end_pos": 18, "type": "METRIC", "confidence": 0.9536863565444946}]}, {"text": "Policy gradient improves upon likelihood training in 14 out of 15 cases, with improvements of up to 1.5 F1.", "labels": [], "entities": [{"text": "likelihood", "start_pos": 30, "end_pos": 40, "type": "METRIC", "confidence": 0.8884365558624268}, {"text": "F1", "start_pos": 104, "end_pos": 106, "type": "METRIC", "confidence": 0.994550883769989}]}, {"text": "One of the three dynamic oracle-based training methods -either likelihood with exploration, softmax margin (SMM), or softmax margin with exploration -obtains better performance than policy gradient in 10 out of 12 cases.", "labels": [], "entities": [{"text": "softmax margin (SMM)", "start_pos": 92, "end_pos": 112, "type": "METRIC", "confidence": 0.7891914486885071}]}, {"text": "This is perhaps unsurprising given the strong supervision provided by the dynamic oracles and the credit assignment problem faced by  policy gradient.", "labels": [], "entities": [{"text": "credit assignment", "start_pos": 98, "end_pos": 115, "type": "TASK", "confidence": 0.7003856748342514}]}, {"text": "However, a substantial fraction of this performance gain is recaptured by policy gradient inmost cases.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Test set F1 by training procedure, and  in comparison to past work using the same mod- els. Improvements over likelihood training are  indicated in parentheses, with the highest results  among the training procedures compared here in  bold.  *  : training uses a dynamic oracle;  \u2020 : past  work using a global scoring model (all models we  train here are locally-normalized).", "labels": [], "entities": [{"text": "F1", "start_pos": 19, "end_pos": 21, "type": "METRIC", "confidence": 0.9987379908561707}]}]}