{"title": [{"text": "Context-Aware Neural Model for Temporal Information Extraction", "labels": [], "entities": [{"text": "Temporal Information Extraction", "start_pos": 31, "end_pos": 62, "type": "TASK", "confidence": 0.6764919559160868}]}], "abstractContent": [{"text": "We propose a context-aware neural network model for temporal information extraction , with a uniform architecture for event-event, event-timex and timex-timex pairs.", "labels": [], "entities": [{"text": "temporal information extraction", "start_pos": 52, "end_pos": 83, "type": "TASK", "confidence": 0.6690828402837118}]}, {"text": "A Global Context Layer (GCL), inspired by the Neural Turing Machine (NTM), stores processed temporal relations in the narrative order, and retrieves them for use when the relevant entities are encountered.", "labels": [], "entities": []}, {"text": "Relations are then classified in this larger context.", "labels": [], "entities": []}, {"text": "The GCL model uses long-term memory and attention mechanisms to resolve long-distance dependencies that regular RNNs cannot recognize.", "labels": [], "entities": []}, {"text": "GCL does not use postprocess-ing to resolve timegraph conflicts, outper-forming previous approaches that do so.", "labels": [], "entities": [{"text": "GCL", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.6897703409194946}]}, {"text": "To our knowledge, GCL is also the first model to use an NTM-like architecture to incorporate the information about global context into discourse-scale processing of natural text.", "labels": [], "entities": []}], "introductionContent": [{"text": "Extracting information about the order and timing of events from text is crucial to any system that attempts an in-depth natural language understanding, whether related to question answering, temporal inference, or other related tasks.", "labels": [], "entities": [{"text": "Extracting information about the order and timing of events from text", "start_pos": 0, "end_pos": 69, "type": "TASK", "confidence": 0.8580884554169395}, {"text": "question answering", "start_pos": 172, "end_pos": 190, "type": "TASK", "confidence": 0.8071414232254028}]}, {"text": "Earlier temporal information extraction (TemporalIE) systems tended to rely on traditional statistical learning with feature-engineered task-specific models, typically used in succession (.", "labels": [], "entities": [{"text": "temporal information extraction (TemporalIE)", "start_pos": 8, "end_pos": 52, "type": "TASK", "confidence": 0.7592596064011256}]}, {"text": "Recently, there have been some attempts to extract temporal relations with neural network models, particularly with recurrent neural networks (RNN) models) and convolutional neural networks (CNN) ().", "labels": [], "entities": []}, {"text": "These models predominantly use token embeddings as input, avoiding handcrafted features for each task.", "labels": [], "entities": []}, {"text": "Typically, neural network models outperform traditional statistical models.", "labels": [], "entities": []}, {"text": "Some studies also try to combine neural network models with rule-based information retrieval methods.", "labels": [], "entities": []}, {"text": "These systems require different models for different pair types, so several models must be combined to fully process text.", "labels": [], "entities": []}, {"text": "A common disadvantage of all these models is that they build relations from isolated pairs of entities (events or temporal expressions).", "labels": [], "entities": []}, {"text": "This context-blind, pairwise classification often generates conflicts in the resulting timegraph.", "labels": [], "entities": []}, {"text": "Common ways of ameliorating the conflicts is to apply some ad hoc constraints to account for basic properties of relations (e.g. transitivity), often without considering the content of the text per se.", "labels": [], "entities": []}, {"text": "For example, designed transitivity formulae, used with local features.", "labels": [], "entities": []}, {"text": "proposed a strategy that \"prefers the edges that can be inferred by other edges in the graph and remove the ones that are least so\".", "labels": [], "entities": []}, {"text": "Another approach is to use the results from separate classifiers to rank results according to their general confidence ().", "labels": [], "entities": []}, {"text": "High-ranking results overwrite low-ranking ones.", "labels": [], "entities": []}, {"text": "used a greedy pruning algorithm to remove weak edges from the timegraph until it is coherent.", "labels": [], "entities": []}, {"text": "When humans read text, we certainly do not follow the procedure of interpreting interpret relations only locally first, and later come up with a compromise solution that involves all the entities.", "labels": [], "entities": []}, {"text": "Instead, if local information is insufficient, we consider the relevant information from the wider context, and resolve the ambiguity as soon as possible.", "labels": [], "entities": []}, {"text": "The resolved relations are stored in our memory as \"context\" for further processing.", "labels": [], "entities": []}, {"text": "If the later evidence suggests our early interpretation was wrong, we can correct it.", "labels": [], "entities": []}, {"text": "This paper proposes a model to simulate such mechanisms.", "labels": [], "entities": []}, {"text": "Our model introduces a Global Context Layer (GCL), inspired by the Neural Turing Machine (NTM) architecture (), to store processed relations in narrative order, and retrieve them for use when related entities are encountered.", "labels": [], "entities": []}, {"text": "The stored information can also be updated if necessary, allowing for self-correction.", "labels": [], "entities": []}, {"text": "This paper's contributions are as follows.", "labels": [], "entities": []}, {"text": "To our knowledge, this is the first attempt to use neural network models with updateable external memory to incorporate global context information for discourse-level processing of natural text in general and for temporal relation extraction in particular.", "labels": [], "entities": [{"text": "temporal relation extraction", "start_pos": 213, "end_pos": 241, "type": "TASK", "confidence": 0.617021898428599}]}, {"text": "It gives a uniform treatment of all pairs of temporally relevant entities.", "labels": [], "entities": []}, {"text": "We obtain stateof-the-art results on TimeBank-Dense, which is a standard benchmark for TemporalIE.", "labels": [], "entities": [{"text": "TimeBank-Dense", "start_pos": 37, "end_pos": 51, "type": "DATASET", "confidence": 0.7419437766075134}]}], "datasetContent": [{"text": "We train and evaluate our model on TimeBankDense 1).", "labels": [], "entities": [{"text": "TimeBankDense 1", "start_pos": 35, "end_pos": 50, "type": "DATASET", "confidence": 0.8952214419841766}]}, {"text": "There are 6 classes of relations: SIMULTANEOUS, BEFORE, AFTER, IS INCLUDED, INCLUDES, and VAGUE TimeBank-Dense annotation aims to approximate a complete temporal relation graph by including all intra-sentential relations, all relations between adjacent sentences, and all relations with document creation time.", "labels": [], "entities": [{"text": "BEFORE", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9985460042953491}, {"text": "AFTER", "start_pos": 56, "end_pos": 61, "type": "METRIC", "confidence": 0.9886531233787537}, {"text": "IS", "start_pos": 63, "end_pos": 65, "type": "METRIC", "confidence": 0.9890017509460449}, {"text": "INCLUDED", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.6220260858535767}, {"text": "INCLUDES", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9928123354911804}, {"text": "VAGUE", "start_pos": 90, "end_pos": 95, "type": "METRIC", "confidence": 0.9870935082435608}]}, {"text": "TimeBank-Dense is one of the standard benchmarks for intrinsic evalution of TemporalIE systems.", "labels": [], "entities": [{"text": "TimeBank-Dense", "start_pos": 0, "end_pos": 14, "type": "DATASET", "confidence": 0.7911139726638794}]}, {"text": "We follow the experimental setup in, which splits the corpus into training/validation/test sets of 22, 5, and 9 documents, respectively.", "labels": [], "entities": []}, {"text": "Previous publications often use the micro-averaged F1 score, which is equivalent to accuracy in this case.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9315760433673859}, {"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9995768666267395}]}, {"text": "We also rely on the micro-averaged F1 score for model selection and evaluation.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.965737521648407}, {"text": "model selection", "start_pos": 48, "end_pos": 63, "type": "TASK", "confidence": 0.7012339234352112}]}, {"text": "Following, we augment the data by flipping all pairs, except for relations involving document creation time.", "labels": [], "entities": []}, {"text": "In other words, if a pair (e i , e j ) exists, we add (e j , e i ) to the dataset with the opposite label (e.g. BEFORE becomes AFTER).", "labels": [], "entities": [{"text": "BEFORE", "start_pos": 112, "end_pos": 118, "type": "METRIC", "confidence": 0.9903837442398071}, {"text": "AFTER", "start_pos": 127, "end_pos": 132, "type": "METRIC", "confidence": 0.769088625907898}]}, {"text": "The augmentation applies to the validation and test sets also.", "labels": [], "entities": [{"text": "augmentation", "start_pos": 4, "end_pos": 16, "type": "METRIC", "confidence": 0.9873665571212769}]}, {"text": "In the final evaluation, a double-checking technique picks one result from the two-way classification, based on output scores.", "labels": [], "entities": []}, {"text": "The dataset is heavily imbalanced.", "labels": [], "entities": []}, {"text": "The training set has as much as 44.1% VAGUE labels, whereas only 1.8% labels are SIMULTANEOUS.", "labels": [], "entities": [{"text": "VAGUE", "start_pos": 38, "end_pos": 43, "type": "METRIC", "confidence": 0.9911423921585083}]}, {"text": "We did not do any up-sampling or down-sampling.", "labels": [], "entities": []}, {"text": "For all the experiments, hyperparameters including the number of epochs are tuned with the validation set only.", "labels": [], "entities": []}, {"text": "Training data is segmented into chunks.", "labels": [], "entities": []}, {"text": "Each chunk contains relation pairs in the narrative order.", "labels": [], "entities": []}, {"text": "The size of chunks is randomly chosen from at the beginning of each epoch of training.", "labels": [], "entities": []}, {"text": "The GCL maintains a memory for each chunk, and clears it at the end of a chunk.", "labels": [], "entities": []}, {"text": "The idea here is to train the model on short paragraphs to avoid overfitting.", "labels": [], "entities": []}, {"text": "To introduce further randomness, the chunks are rotated for each epoch.", "labels": [], "entities": []}, {"text": "For a specific training file, if chunk i starts with pair n i in epoch 1, in epoch 2, chunk i will start with pair n i +chunksize+11. 11 is a prime number we chose to assure each epoch observes different compositions of chunks.", "labels": [], "entities": []}, {"text": "By doing the rotation, some pairs in the final chunk of epoch 1 will show up in the first chunk in epoch 2 as well.", "labels": [], "entities": []}, {"text": "However, within each chunk, we do not randomize pairs, so narrative order is preserved at this level.", "labels": [], "entities": []}, {"text": "We also do not shuffle the chunks, but only rotate them.", "labels": [], "entities": []}, {"text": "Evaluation on the test set uses only one chunk for each file (chunk size is the number of pairs).", "labels": [], "entities": []}, {"text": "Each relation pair is only processed once, without \"multiple rounds of reading\".", "labels": [], "entities": []}, {"text": "Thus, we essentially train the model to read shorter paragraphs (varied in length), but test it on long articles.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results on the test set. The GCL models use  the same hyperparameters, if possible. The two models on  the top do not use neural networks. The results in the two  lower blocks all use double-check. \"Two more hidden lay- ers\" means adding two dense layers on top of the pre-trained  model without using GCL. The last row corresponds to con- necting the output layer of a pre-trained model to GCL layers  with stateless controller.", "labels": [], "entities": []}, {"text": " Table 2: Overall results per relation.", "labels": [], "entities": []}, {"text": " Table 3: Results on the E-D, E-D and E-T pairs. GCL  stands for the GCL-enabled system with a stateless controller.  Frequencies are percentages in the test set. T-T pairs are  not shown here. CAEVO is from Chambers et al. (2014).  CATENA is from", "labels": [], "entities": [{"text": "Frequencies", "start_pos": 118, "end_pos": 129, "type": "METRIC", "confidence": 0.9803181886672974}, {"text": "CAEVO", "start_pos": 194, "end_pos": 199, "type": "METRIC", "confidence": 0.8598085641860962}]}, {"text": " Table 4: Test results from event and document creation time  (E-D) pairs. The rows are true labels and the columns are  predicted labels.", "labels": [], "entities": []}]}