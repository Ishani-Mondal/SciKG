{"title": [{"text": "EmotionX-DLC: Self-Attentive BiLSTM for Detecting Sequential Emotions in Dialogues", "labels": [], "entities": [{"text": "Detecting Sequential Emotions in Dialogues", "start_pos": 40, "end_pos": 82, "type": "TASK", "confidence": 0.8315436601638794}]}], "abstractContent": [{"text": "In this paper, we propose a self-attentive bidirectional long short-term memory (SA-BiLSTM) network to predict multiple emotions for the EmotionX challenge.", "labels": [], "entities": [{"text": "EmotionX challenge", "start_pos": 137, "end_pos": 155, "type": "TASK", "confidence": 0.6644236445426941}]}, {"text": "The BiLSTM exhibits the power of mod-eling the word dependencies, and extracting the most relevant features for emotion classification.", "labels": [], "entities": [{"text": "emotion classification", "start_pos": 112, "end_pos": 134, "type": "TASK", "confidence": 0.7196157425642014}]}, {"text": "Building on top of BiL-STM, the self-attentive network can model the contextual dependencies between utterances which are helpful for classifying the ambiguous emotions.", "labels": [], "entities": []}, {"text": "We achieve 59.6 and 55.0 unweighted accuracy scores in the Friends and the EmotionPush test sets, respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9818019270896912}, {"text": "Friends", "start_pos": 59, "end_pos": 66, "type": "DATASET", "confidence": 0.9284619092941284}, {"text": "EmotionPush test sets", "start_pos": 75, "end_pos": 96, "type": "DATASET", "confidence": 0.8692917227745056}]}], "introductionContent": [{"text": "Emotion detection plays a crucial role in developing a smart dialogue system such as a chit-chat conversational bot.", "labels": [], "entities": [{"text": "Emotion detection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8786885738372803}]}, {"text": "As atypical sub-problem of sentence classification, emotion classification requires not only to understand sentence of a single utterance, but also capture the contextual information from the whole conversations.", "labels": [], "entities": [{"text": "sentence classification", "start_pos": 27, "end_pos": 50, "type": "TASK", "confidence": 0.7451698482036591}, {"text": "emotion classification", "start_pos": 52, "end_pos": 74, "type": "TASK", "confidence": 0.7351900637149811}]}, {"text": "The problems of sentence-level classification have been investigated heavily by means of deep neural networks, such as convolutional neural networks (CNN), long short-term memory (LSTM) (, and attention-based CNN (.", "labels": [], "entities": [{"text": "sentence-level classification", "start_pos": 16, "end_pos": 45, "type": "TASK", "confidence": 0.701522171497345}]}, {"text": "Additional soft attention layers () are usually built on top of those networks, such that more attention will be paid to the most relevant words that lead to a better understanding of the sentence.", "labels": [], "entities": []}, {"text": "LSTMs are also useful to model contextual dependencies.", "labels": [], "entities": []}, {"text": "For example, a contextual LSTM model is proposed to select the next sentence based on the former context (, and a bidirectional LSTM (BiLSTM) is adopted to detect multiple emotions.", "labels": [], "entities": [{"text": "BiLSTM", "start_pos": 134, "end_pos": 140, "type": "METRIC", "confidence": 0.8870760202407837}]}, {"text": "In this work, we utilize the self-attentive BiL-STM (SA-BiLSTM) model to predict multiple types of emotions for the given utterances in the dialogues.", "labels": [], "entities": []}, {"text": "Our model imitates human's twostep procedures for classifying an utterance within the context, i.e., sentence understanding and contextual utterances dependence extraction.", "labels": [], "entities": [{"text": "sentence understanding", "start_pos": 101, "end_pos": 123, "type": "TASK", "confidence": 0.7255203872919083}, {"text": "contextual utterances dependence extraction", "start_pos": 128, "end_pos": 171, "type": "TASK", "confidence": 0.6347609758377075}]}, {"text": "More specifically, we propose the bidirectional long short-term memory (BiLSTM) with the maxpooling architecture to embed the sentence into a fixed-size vector, as the BiLSTM network is capable of modeling the word dependencies in the sentence while the max-pooling helps to reduce the model size and obtains the most related features for emotion classification.", "labels": [], "entities": [{"text": "emotion classification", "start_pos": 339, "end_pos": 361, "type": "TASK", "confidence": 0.7245077043771744}]}, {"text": "Since data in this challenge is limited and specific words play significant role to classifying the corresponding emotion, we apply the self-attention network to extract the dependence of all the utterances in the dialogue.", "labels": [], "entities": []}, {"text": "Technically, the selfattention model computes the influence of utterance pairs and outputs the sentence embedding of one utterance by a weighted sum overall the utterances in the dialogue.", "labels": [], "entities": []}, {"text": "The fully connected layers are then applied on the output sentence embedding to classify the corresponding emotion.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conduct two experiments with different model variants: BiLSTM and SA-BiLSTM, to validate whether our proposed model can learn the contextual information.", "labels": [], "entities": []}, {"text": "The network settings for each model are summarized as follows: \u2022 BiLSTM: BiLSTM + max-pooling + fully connected layers.", "labels": [], "entities": []}, {"text": "\u2022 SA-BiLSTM: BiLSTM + max-pooling + self-attentive network + fully connected layers.", "labels": [], "entities": []}, {"text": "The word embedding is 300-dimensional from the the Glove.", "labels": [], "entities": []}, {"text": "Pack padded sequence and pad packed sequence are implemented to deal with varying sequence lengths.", "labels": [], "entities": []}, {"text": "For SA-BiLSTM, we limit the utterance number to 25 for each dialogue.", "labels": [], "entities": []}, {"text": "Due to the limit of training data, LSTM is set to one layer with only 256 hidden units.", "labels": [], "entities": []}, {"text": "The fully connected layers consist of two middle layers with the same size of 128.", "labels": [], "entities": []}, {"text": "The mini-batch size for training BiLSTM is set to 16.", "labels": [], "entities": [{"text": "BiLSTM", "start_pos": 33, "end_pos": 39, "type": "DATASET", "confidence": 0.5389364361763}]}, {"text": "Unlike BiLSTM, we feed one dialogue to SA-BiLSTM for every training step.", "labels": [], "entities": []}, {"text": "Adam () is the adopted optimizer with initial learning rate 0.0002 and decay factor 0.99 for every epoch.", "labels": [], "entities": [{"text": "initial learning rate 0.0002", "start_pos": 38, "end_pos": 66, "type": "METRIC", "confidence": 0.8556136637926102}]}, {"text": "Dropout probability is set to 0.3 for BiLSTM and self-attention layers.", "labels": [], "entities": [{"text": "Dropout probability", "start_pos": 0, "end_pos": 19, "type": "METRIC", "confidence": 0.9021754562854767}]}, {"text": "We train BiLSTM for 10 epochs and SA-BiLSTM for 20 epochs to gain the best accuracy in the validation sets.", "labels": [], "entities": [{"text": "BiLSTM", "start_pos": 9, "end_pos": 15, "type": "METRIC", "confidence": 0.5645211338996887}, {"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9991683959960938}]}, {"text": "reports the model performance in the validation sets, which consist of 80 dialogues for Friends and EmotionPush, respectively.", "labels": [], "entities": []}, {"text": "We evaluate two criteria, the weighted accuracy (WA) and the unweighted accuracy (UWA) (Chen et al.,  2018).", "labels": [], "entities": [{"text": "accuracy (WA)", "start_pos": 39, "end_pos": 52, "type": "METRIC", "confidence": 0.8869759738445282}, {"text": "unweighted accuracy (UWA)", "start_pos": 61, "end_pos": 86, "type": "METRIC", "confidence": 0.8050972938537597}]}, {"text": "The predicted accuracy for each class is also given in the table.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9263352155685425}]}], "tableCaptions": [{"text": " Table 1: Experimental results of Friends and EmotionPush in the validation sets.", "labels": [], "entities": []}, {"text": " Table 2: Experimental results of Friends and EmotionPush in the test sets.", "labels": [], "entities": []}]}