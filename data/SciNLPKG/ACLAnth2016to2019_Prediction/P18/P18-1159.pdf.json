{"title": [{"text": "Joint Training of Candidate Extraction and Answer Selection for Reading Comprehension", "labels": [], "entities": [{"text": "Answer Selection", "start_pos": 43, "end_pos": 59, "type": "TASK", "confidence": 0.8897529542446136}, {"text": "Reading Comprehension", "start_pos": 64, "end_pos": 85, "type": "TASK", "confidence": 0.7087753713130951}]}], "abstractContent": [{"text": "While sophisticated neural-based techniques have been developed in reading comprehension, most approaches model the answer in an independent manner, ignoring its relations with other answer candidates.", "labels": [], "entities": []}, {"text": "This problem can be even worse in open-domain scenarios, where candidates from multiple passages should be combined to answer a single question.", "labels": [], "entities": []}, {"text": "In this paper, we formulate reading comprehension as an extract-then-select two-stage procedure.", "labels": [], "entities": [{"text": "reading comprehension", "start_pos": 28, "end_pos": 49, "type": "TASK", "confidence": 0.8006621301174164}]}, {"text": "We first extract answer candidates from passages, then select the final answer by combining information from all the candidates.", "labels": [], "entities": []}, {"text": "Furthermore, we regard candidate extraction as a latent variable and train the two-stage process jointly with reinforcement learning.", "labels": [], "entities": [{"text": "candidate extraction", "start_pos": 23, "end_pos": 43, "type": "TASK", "confidence": 0.8230363428592682}]}, {"text": "As a result, our approach has improved the state-of-the-art performance significantly on two challenging open-domain reading comprehension datasets.", "labels": [], "entities": []}, {"text": "Further analysis demonstrates the effectiveness of our model components , especially the information fusion of all the candidates and the joint training of the extract-then-select procedure.", "labels": [], "entities": [{"text": "information fusion", "start_pos": 89, "end_pos": 107, "type": "TASK", "confidence": 0.7583044767379761}]}], "introductionContent": [{"text": "Teaching machines to read and comprehend human languages is a long-standing objective in natural language processing.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 89, "end_pos": 116, "type": "TASK", "confidence": 0.6596963008244833}]}, {"text": "In order to evaluate this ability, reading comprehension (RC) is designed to answer questions through reading relevant passages.", "labels": [], "entities": [{"text": "reading comprehension (RC)", "start_pos": 35, "end_pos": 61, "type": "TASK", "confidence": 0.6326607286930084}]}, {"text": "In recent years, RC has attracted intense interest.", "labels": [], "entities": [{"text": "RC", "start_pos": 17, "end_pos": 19, "type": "TASK", "confidence": 0.7062870264053345}]}, {"text": "Various advanced neural models have been proposed along with newly released datasets).", "labels": [], "entities": []}, {"text": "Daiquiris area family of cocktails whose main ingredients are rum and lime juice.", "labels": [], "entities": [{"text": "Daiquiris area", "start_pos": 0, "end_pos": 14, "type": "DATASET", "confidence": 0.9320293664932251}]}, {"text": "P4 A homemade Cuba Libre Preparation To make a Cuba Libre properly, fill a highball glass with ice and half fill with cola.", "labels": [], "entities": []}], "datasetContent": [{"text": "In addition to results of previous work, we add two baselines to demonstrate the effectiveness of our framework.", "labels": [], "entities": []}, {"text": "The first baseline only applies the extraction model to score the answers, which is aimed at explaining the importance of the selection model.", "labels": [], "entities": []}, {"text": "The second one only uses the pre-trained extraction model and selection model: Experimental results on the test set of Quasar-T and SearchQA.", "labels": [], "entities": []}, {"text": "Full re-ranker is the ensemble of three different re-rankers in ().", "labels": [], "entities": []}, {"text": "to illustrate the benefits from our joint training schema.", "labels": [], "entities": []}, {"text": "The often used evaluation metrics for extractive RC are exact match (EM) and F1 (.", "labels": [], "entities": [{"text": "extractive RC", "start_pos": 38, "end_pos": 51, "type": "TASK", "confidence": 0.9102495014667511}, {"text": "exact match (EM)", "start_pos": 56, "end_pos": 72, "type": "METRIC", "confidence": 0.9679307699203491}, {"text": "F1", "start_pos": 77, "end_pos": 79, "type": "METRIC", "confidence": 0.9980713725090027}]}, {"text": "The experimental results on Quasar-T and SearchQA are shown in.", "labels": [], "entities": [{"text": "SearchQA", "start_pos": 41, "end_pos": 49, "type": "DATASET", "confidence": 0.920617938041687}]}, {"text": "As seen from the results on Quasar-T, our quite simple extraction model alone almost reaches the state-of-the-art result compared with other methods without re-rankers.", "labels": [], "entities": []}, {"text": "The combination of the extraction and selection models exceeds our extraction baseline by a great margin, and also results in performance surpassing the best single reranker in ().", "labels": [], "entities": []}, {"text": "This result illustrates the necessity of introducing the selection model, which incorporates information from all the candidates.", "labels": [], "entities": []}, {"text": "In the end, by joint training with RL, our method produces better performance even compared with the ensemble of three different rerankers.", "labels": [], "entities": [{"text": "RL", "start_pos": 35, "end_pos": 37, "type": "DATASET", "confidence": 0.5341125726699829}]}, {"text": "On SearchQA, we find that our extraction model alone performs not that well compared with the state-of-the-art model without re-rankers.", "labels": [], "entities": []}, {"text": "However, the improvement brought by our selection model isolatedly or jointly trained still demonstrates the importance of our two-stage framework.", "labels": [], "entities": []}, {"text": "Not surprisingly, comparing the results, our isolated training strategy still lags behind the single re-ranker proposed in (, partly because of the deficiency with our extraction model.", "labels": [], "entities": []}, {"text": "However, uniting our extraction and selection models with RL makes up the disparity, and the performance surpasses the ensemble of three different re-rankers, let alone the result of  any single re-ranker.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Experimental results on the test set of Quasar-T and SearchQA. Full re-ranker is the ensemble  of three different re-rankers in (", "labels": [], "entities": []}, {"text": " Table 4: Ablation results concerning the selec- tion model on the test set of Quasar-T. Obviously,  candidates fused representation is the most evident  feature when modeling the answer selection pro- cedure.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9728772640228271}]}, {"text": " Table 6: Different number of extracted candidates  results in different final performance on the test set  of Quasar-T.", "labels": [], "entities": []}]}