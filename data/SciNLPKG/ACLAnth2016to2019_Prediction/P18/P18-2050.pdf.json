{"title": [{"text": "Extreme Adaptation for Personalized Neural Machine Translation", "labels": [], "entities": [{"text": "Extreme Adaptation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.6062147617340088}, {"text": "Personalized Neural Machine Translation", "start_pos": 23, "end_pos": 62, "type": "TASK", "confidence": 0.7232587486505508}]}], "abstractContent": [{"text": "Every person speaks or writes their own flavor of their native language, influenced by a number of factors: the content they tend to talk about, their gender, their social status, or their geographical origin.", "labels": [], "entities": []}, {"text": "When attempting to perform Machine Translation (MT), these variations have a significant effect on how the system should perform translation, but this is not captured well by standard one-size-fits-all models.", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 27, "end_pos": 51, "type": "TASK", "confidence": 0.855993390083313}]}, {"text": "In this paper, we propose a simple and parameter-efficient adaptation technique that only requires adapting the bias of the output softmax to each particular user of the MT system, either directly or through a factored approximation.", "labels": [], "entities": [{"text": "MT", "start_pos": 170, "end_pos": 172, "type": "TASK", "confidence": 0.9201220273971558}]}, {"text": "Experiments on TED talks in three languages demonstrate improvements in translation accuracy, and better reflection of speaker traits in the target text.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.8740007877349854}]}], "introductionContent": [{"text": "The production of language varies depending on the speaker or author, be it to reflect personal traits (e.g. job, gender, role, dialect) or the topics that tend to be discussed (e.g. technology, law, religion).", "labels": [], "entities": []}, {"text": "Current Neural Machine Translation (NMT) systems do not incorporate any explicit information about the speaker, and this forces the model to learn these traits implicitly.", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT)", "start_pos": 8, "end_pos": 40, "type": "TASK", "confidence": 0.8265403310457865}]}, {"text": "This is a difficult and indirect way to capture inter-personal variations, and in some cases it is impossible without external context,).", "labels": [], "entities": []}, {"text": "Recent work has incorporated side information about the author such as personality (), gender or politeness (), but these methods can only handle phenomena where there are ex- Translation I went home: Je suis rentr\u00e9rentr\u00e9`rentr\u00e9\u00e0 la maison: Je suis rentr\u00e9\u00e8 a la maison I do drug testing: Je teste des m\u00e9dicaments: Je d\u00e9piste des drogues: Examples where speaker information influences English-French translation.", "labels": [], "entities": []}, {"text": "plicit labels for the traits.", "labels": [], "entities": []}, {"text": "Our work investigates how we can efficiently model speaker-related variations to improve NMT models.", "labels": [], "entities": []}, {"text": "In particular, we are interested in improving our NMT system given few training examples for any particular speaker.", "labels": [], "entities": [{"text": "NMT", "start_pos": 50, "end_pos": 53, "type": "TASK", "confidence": 0.8813685178756714}]}, {"text": "We propose to approach this task as a domain adaptation problem with an extremely large number of domains and little data for each domain, a setting where we may expect traditional approaches to domain adaptation that adjust all model parameters to be sub-optimal ( \u00a72).", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.7143222242593765}, {"text": "domain adaptation", "start_pos": 195, "end_pos": 212, "type": "TASK", "confidence": 0.7332213521003723}]}, {"text": "Our proposed solution involves modeling the speakerspecific variations as an additional bias vector in the softmax layer, where we either learn this bias directly, or through a factored model that treats each user as a mixture of a few prototypical bias vectors ( \u00a73).", "labels": [], "entities": []}, {"text": "We construct anew dataset of Speaker Annotated TED talks (SATED, \u00a74) to validate our approach.", "labels": [], "entities": [{"text": "Speaker Annotated TED talks", "start_pos": 29, "end_pos": 56, "type": "TASK", "confidence": 0.452034592628479}]}, {"text": "Adaptation experiments ( \u00a75) show that explicitly incorporating speaker information into the model improves translation quality and accuracy with respect to speaker traits.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 132, "end_pos": 140, "type": "METRIC", "confidence": 0.9976673722267151}]}], "datasetContent": [{"text": "In order to evaluate the effectiveness of our proposed methods, we construct anew dataset, Speaker Annotated TED (SATED) based on TED talks, with three language pairs, English-French (en-fr), English-German (en-de) and EnglishSpanish (en-es) and speaker annotation.", "labels": [], "entities": []}, {"text": "The dataset consists of transcripts directly collected from https://www.ted.com/talks, and contains roughly 271K sentences in each language distributed among 2324 talks.", "labels": [], "entities": []}, {"text": "We pre-process the data by removing sentences that don't have any translation or are longer than 60 words, lowercasing, and tokenizing (using the Moses tokenizer ().", "labels": [], "entities": []}, {"text": "Some talks are partially or not translated in some of the languages (in particular there are fewer translations in German than in French or Spanish), we therefore remove any talk with less than 10 translated sentences in each language pair.", "labels": [], "entities": []}, {"text": "The data is then partitioned into training, validation and test sets.", "labels": [], "entities": []}, {"text": "We split the corpus such that the test and validation split each contain 2 sentence pairs from each talk, thus ensuring that all talks are present in every split.", "labels": [], "entities": []}, {"text": "Each sentence pair is annotated with the name of the talk and the speaker.", "labels": [], "entities": []}, {"text": "We run a set of experiments to validate the ability of our proposed approach to model speakerinduced variations in translation.", "labels": [], "entities": []}, {"text": "We test three models base (a baseline ignoring speaker labels), full bias and fact bias.", "labels": [], "entities": [{"text": "full bias", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.8940475583076477}]}, {"text": "During training, we limit our vocabulary to the 40,000 most frequent words.", "labels": [], "entities": []}, {"text": "Additionally, we discard any word appearing less than 2 times.", "labels": [], "entities": []}, {"text": "Any word that doesn't satisfy those conditions is replaced with an UNK token.", "labels": [], "entities": [{"text": "UNK token", "start_pos": 67, "end_pos": 76, "type": "DATASET", "confidence": 0.8821791708469391}]}, {"text": "All our models are implemented with the DyNet ( ) framework, and unless specified we use the default settings therein.", "labels": [], "entities": []}, {"text": "We refer to appendix B fora detailed explanation of the training process.", "labels": [], "entities": []}, {"text": "We translate the test set using beam search with beam size 5.", "labels": [], "entities": []}, {"text": "One of the quirks of the TED talks is that the speaker annotation correlates with the topic of their talk to a high degree.", "labels": [], "entities": []}, {"text": "Although the topics that a speaker talks about can be considered as a manifestation of speaker traits, we also perform a control experiment on a different dataset to verify that our model is indeed learning more than just topical We use roughly the same training procedure as the one described in \u00a75.1, with a random train/dev/test split since none is provided in the original dataset.", "labels": [], "entities": []}, {"text": "Note that in this case, the number of speakers is much lower (747) whereas the total size of the dataset is bigger (\u2248300k).", "labels": [], "entities": []}, {"text": "We report the results in table 4.", "labels": [], "entities": []}, {"text": "Although the difference is less salient than in the case of SATED, our factored bias model still performs significantly better than the baseline (+0.83 BLEU).", "labels": [], "entities": [{"text": "SATED", "start_pos": 60, "end_pos": 65, "type": "DATASET", "confidence": 0.5319948196411133}, {"text": "BLEU", "start_pos": 152, "end_pos": 156, "type": "METRIC", "confidence": 0.9985384941101074}]}, {"text": "This suggests that even outside the context of TED talks, our proposed method is capable of improvements over a speaker-agnostic model.", "labels": [], "entities": [{"text": "TED talks", "start_pos": 47, "end_pos": 56, "type": "TASK", "confidence": 0.7863280773162842}]}], "tableCaptions": [{"text": " Table 3: Test BLEU. Scores significantly (p <  0.05) better than the baseline are written in bold", "labels": [], "entities": [{"text": "Test", "start_pos": 10, "end_pos": 14, "type": "DATASET", "confidence": 0.6978957056999207}, {"text": "BLEU", "start_pos": 15, "end_pos": 19, "type": "METRIC", "confidence": 0.9821864366531372}]}]}