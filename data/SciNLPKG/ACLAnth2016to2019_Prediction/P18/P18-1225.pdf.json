{"title": [{"text": "AdvEntuRe: Adversarial Training for Textual Entailment with Knowledge-Guided Examples", "labels": [], "entities": [{"text": "Textual Entailment", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.6960819661617279}]}], "abstractContent": [{"text": "We consider the problem of learning tex-tual entailment models with limited supervision (5K-10K training examples), and present two complementary approaches for it.", "labels": [], "entities": []}, {"text": "First, we propose knowledge-guided adversarial example generators for incorporating large lexical resources in entail-ment models via only a handful of rule templates.", "labels": [], "entities": []}, {"text": "Second, to make the entailment model-a discriminator-more robust, we propose the first GAN-style approach for training it using a natural language example generator that iteratively adjusts based on the discriminator's performance.", "labels": [], "entities": []}, {"text": "We demonstrate effectiveness using two entailment datasets, where the proposed methods increase accuracy by 4.7% on SciTail and by 2.8% on a 1% training sub-sample of SNLI.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.9993690848350525}, {"text": "SNLI", "start_pos": 167, "end_pos": 171, "type": "DATASET", "confidence": 0.8079383373260498}]}, {"text": "Notably, even a single handwritten rule, negate, improves the accuracy on the negation examples in SNLI by 6.1%.", "labels": [], "entities": [{"text": "negate", "start_pos": 41, "end_pos": 47, "type": "TASK", "confidence": 0.952370822429657}, {"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9995589852333069}, {"text": "SNLI", "start_pos": 99, "end_pos": 103, "type": "DATASET", "confidence": 0.5742984414100647}]}], "introductionContent": [{"text": "The impressive success of machine learning models on large natural language datasets often does not carryover to moderate training data regimes, where models often struggle with infrequently observed patterns and simple adversarial variations.", "labels": [], "entities": []}, {"text": "A prominent example of this phenomenon is textual entailment, the fundamental task of deciding whether a premise text entails () a hypothesis text.", "labels": [], "entities": []}, {"text": "On certain datasets, recent deep learning entailment systems () have achieved close to human level performance.", "labels": [], "entities": []}, {"text": "Nevertheless, the problem is far from solved, as evidenced by how easy it is to generate minor adversarial ex-: Failure examples from the SNLI dataset: negation (Top) and re-ordering (Bottom).", "labels": [], "entities": [{"text": "SNLI dataset", "start_pos": 138, "end_pos": 150, "type": "DATASET", "confidence": 0.8349941074848175}]}, {"text": "P is premise, H is hypothesis, and S is prediction made by an entailment system (.", "labels": [], "entities": []}, {"text": "amples that break even the best systems.", "labels": [], "entities": []}, {"text": "As Table 1 illustrates, a state-of-the-art neural system for this task, namely the Decomposable Attention Model (, fails when faced with simple linguistic phenomena such as negation, or a re-ordering of words.", "labels": [], "entities": []}, {"text": "This is not unique to a particular model or task.", "labels": [], "entities": []}, {"text": "Minor adversarial examples have also been found to easily break neural systems on other linguistic tasks such as reading comprehension.", "labels": [], "entities": []}, {"text": "A key contributor to this brittleness is the use of specific datasets such as SNLI () and SQuAD () to drive model development.", "labels": [], "entities": []}, {"text": "While large and challenging, these datasets also tend to be homogeneous.", "labels": [], "entities": []}, {"text": "E.g., SNLI was created by asking crowd-source workers to generate entailing sentences, which then tend to have limited linguistic variations and annotation artifacts.", "labels": [], "entities": [{"text": "SNLI", "start_pos": 6, "end_pos": 10, "type": "TASK", "confidence": 0.9602511525154114}]}, {"text": "Consequently, models overfit to sufficiently repetitive patterns-and sometimes idiosyncrasies-in the datasets they are trained on.", "labels": [], "entities": []}, {"text": "They fail to cover long-tail and rare patterns in the training distribution, or linguistic phenomena such as negation that would be obvious to a layperson.", "labels": [], "entities": []}, {"text": "To address this challenge, we propose to train textual entailment models more robustly using ad-versarial examples generated in two ways: (a) by incorporating knowledge from large linguistic resources, and (b) using a sequence-to-sequence neural model in a GAN-style framework.", "labels": [], "entities": []}, {"text": "The motivation stems from the following observation.", "labels": [], "entities": []}, {"text": "While deep-learning based textual entailment models lead the pack, they generally do not incorporate intuitive rules such as negation, and ignore large-scale linguistic resources such as PPDB ( and WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 198, "end_pos": 205, "type": "DATASET", "confidence": 0.960488498210907}]}, {"text": "These resources could help them generalize beyond specific words observed during training.", "labels": [], "entities": []}, {"text": "For instance, while the SNLI dataset contains the pattern two men people, it does not contain the analogous pattern two dogs animals found easily in WordNet.", "labels": [], "entities": [{"text": "SNLI dataset", "start_pos": 24, "end_pos": 36, "type": "DATASET", "confidence": 0.8843802213668823}, {"text": "WordNet", "start_pos": 149, "end_pos": 156, "type": "DATASET", "confidence": 0.9651561975479126}]}, {"text": "Effectively integrating simple rules or linguistic resources in a deep learning model, however, is challenging.", "labels": [], "entities": []}, {"text": "Doing so directly by substantially adapting the model architecture ( can be cumbersome and limiting.", "labels": [], "entities": []}, {"text": "Incorporating such knowledge indirectly via modified word embeddings), as we show, can have little positive impact and can even be detrimental.", "labels": [], "entities": []}, {"text": "Our proposed method, which is task-specific but model-independent, is inspired by dataaugmentation techniques.", "labels": [], "entities": []}, {"text": "We generate new training examples by applying knowledge-guided rules, via only a handful of rule templates, to the original training examples.", "labels": [], "entities": []}, {"text": "Simultaneously, we also use a sequence-to-sequence or seq2seq model for each entailment class to generate new hypotheses from a given premise, adaptively creating new adversarial examples.", "labels": [], "entities": []}, {"text": "These can be used with any entailment model without constraining model architecture.", "labels": [], "entities": []}, {"text": "We also introduce the first approach to train a robust entailment model using a Generative Adversarial Network or GAN () style framework.", "labels": [], "entities": []}, {"text": "We iteratively improve both the entailment system (the discriminator) and the differentiable part of the data-augmenter (specifically the neural generator), by training the generator based on the discriminator's performance on the generated examples.", "labels": [], "entities": []}, {"text": "Importantly, unlike the typical use of GANs to create a strong generator, we use it as a mechanism to create a strong and robust discriminator.", "labels": [], "entities": []}, {"text": "Our new entailment system, called AdvEntuRe, demonstrates that in the moderate data regime, adversarial iterative data-augmentation via only a handful of linguistic rule templates can be surprisingly powerful.", "labels": [], "entities": []}, {"text": "Specifically, we observe 4.7% accuracy improvement on the challenging SciTail dataset () and a 2.8% improvement on 10K-50K training subsets of SNLI.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9993988275527954}, {"text": "SciTail dataset", "start_pos": 70, "end_pos": 85, "type": "DATASET", "confidence": 0.8597228825092316}]}, {"text": "An evaluation of our algorithm on the negation examples in the test set of SNLI reveals a 6.1% improvement from just a single rule.", "labels": [], "entities": [{"text": "SNLI", "start_pos": 75, "end_pos": 79, "type": "DATASET", "confidence": 0.6172505021095276}]}], "datasetContent": [{"text": "Our empirical assessment focuses on two key questions: (a) Can a handful of rule templates improve a state-of-the-art entailment system, especially with moderate amounts of training data?", "labels": [], "entities": []}, {"text": "(b) Can iterative GAN-style training lead to an improved discriminator?", "labels": [], "entities": [{"text": "GAN-style training", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.8470154106616974}]}, {"text": "To this end, we assess various models on the two entailment datasets mentioned earlier: SNLI (570K examples) and SciTail (27K examples).", "labels": [], "entities": [{"text": "SNLI", "start_pos": 88, "end_pos": 92, "type": "DATASET", "confidence": 0.7941040396690369}]}, {"text": "To test our hypothesis that adversarial example based training prevents overfitting in small to moderate training data regimes, we compare model accuracies on the test sets when using 1%, 10%, 50%, and 100% subsamples of the train and dev sets.", "labels": [], "entities": []}, {"text": "We consider two baseline models: D, the Decomposable Attention model () with intra-sentence attention using pre-trained word embeddings (; and D retro which extends D with word embeddings initialized by retrofitted vectors.", "labels": [], "entities": []}, {"text": "The vectors are retrofitted on PPDB, Word-5 SNLI has a 96.4%/1.7%/1.7% split and SciTail has a 87.3%/4.8%/7.8% split on train, valid, and test sets, resp.", "labels": [], "entities": [{"text": "PPDB", "start_pos": 31, "end_pos": 35, "type": "DATASET", "confidence": 0.9476625919342041}, {"text": "Word-5 SNLI", "start_pos": 37, "end_pos": 48, "type": "DATASET", "confidence": 0.8051368594169617}]}, {"text": "Net, FrameNet, and all of these, with the best results for each dataset reported here.", "labels": [], "entities": []}, {"text": "Our proposed model, AdvEntuRe, is evaluated in three flavors: D augmented with examples generated by G rule , G s2s , or both, where G rule = G KB [G H . In the first two cases, we create new examples for each batch in every epoch using a fixed generator (cf. Section 3.5).", "labels": [], "entities": []}, {"text": "In the third case (D + G rule + G s2s ), we use the GAN-style training.", "labels": [], "entities": []}, {"text": "We uses grid search to find the best hyperparameters for D based on the validation set: hidden size 200 for LSTM layer, embedding size 300, dropout ratio 0.2, and fine-tuned embeddings.", "labels": [], "entities": []}, {"text": "The ratio between the number of generated vs. original examples, \u02db is empirically chosen to be 1.0 for SNLI and 0.5 for SciTail, based on validation set performance.", "labels": [], "entities": [{"text": "SNLI", "start_pos": 103, "end_pos": 107, "type": "DATASET", "confidence": 0.7231814861297607}]}, {"text": "Generally, very few generated examples (small \u02db) has little impact, while too many of them overwhelm the original dataset resulting in worse scores (cf. Appendix for more details).", "labels": [], "entities": [{"text": "Appendix", "start_pos": 153, "end_pos": 161, "type": "METRIC", "confidence": 0.8535086512565613}]}, {"text": "summarizes the test set accuracies of the different models using various subsampling ratios for SNLI and SciTail training data.", "labels": [], "entities": [{"text": "SNLI", "start_pos": 96, "end_pos": 100, "type": "DATASET", "confidence": 0.7884154319763184}, {"text": "SciTail training data", "start_pos": 105, "end_pos": 126, "type": "DATASET", "confidence": 0.7095375259717306}]}], "tableCaptions": [{"text": " Table 4: Test accuracies with different subsam- pling ratios on SNLI (top) and SciTail (bottom).", "labels": [], "entities": [{"text": "SNLI", "start_pos": 65, "end_pos": 69, "type": "DATASET", "confidence": 0.9093909859657288}]}, {"text": " Table 5: Test accuracies across various rules R  and classes C. Since SciTail has two classes, we  only report results on two classes of G s2s", "labels": [], "entities": [{"text": "accuracies", "start_pos": 15, "end_pos": 25, "type": "METRIC", "confidence": 0.9189005494117737}]}]}