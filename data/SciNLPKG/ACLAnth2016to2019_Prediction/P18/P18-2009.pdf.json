{"title": [{"text": "Learning Thematic Similarity Metric Using Triplet Networks", "labels": [], "entities": [{"text": "Learning Thematic Similarity Metric", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.5947452485561371}]}], "abstractContent": [{"text": "In this paper we suggest to leverage the partition of articles into sections, in order to learn thematic similarity metric between sentences.", "labels": [], "entities": []}, {"text": "We assume that a sentence is thematically closer to sentences within its section than to sentences from other sections.", "labels": [], "entities": []}, {"text": "Based on this assumption, we use Wikipedia articles to automatically create a large dataset of weakly labeled sentence triplets, composed of a pivot sentence , one sentence from the same section and one from another section.", "labels": [], "entities": []}, {"text": "We train a triplet network to embed sentences from the same section closer.", "labels": [], "entities": []}, {"text": "To test the performance of the learned embeddings, we create and release a sentence clustering benchmark.", "labels": [], "entities": []}, {"text": "We show that the triplet network learns useful thematic metrics, that significantly outperform state-of-the-art semantic similarity methods and multipurpose embeddings on the task of thematic clustering of sentences.", "labels": [], "entities": []}, {"text": "We also show that the learned embeddings perform well on the task of sentence semantic similarity prediction.", "labels": [], "entities": [{"text": "sentence semantic similarity prediction", "start_pos": 69, "end_pos": 108, "type": "TASK", "confidence": 0.7925678044557571}]}], "introductionContent": [{"text": "Text clustering is a widely studied NLP problem, with numerous applications including collaborative filtering, document organization and indexing (.", "labels": [], "entities": [{"text": "Text clustering", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.744431346654892}, {"text": "document organization", "start_pos": 111, "end_pos": 132, "type": "TASK", "confidence": 0.7200463712215424}]}, {"text": "Clustering can be applied to texts at different levels, from single words to full documents, and can vary with respect to the clustering goal.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the problem of clustering sentences based on thematic similarity, aiming to group together sentences that discuss the same theme, as opposed * * These authors contributed equally to this work.", "labels": [], "entities": []}, {"text": "to the related task of clustering sentences that represent paraphrases of the same core statement.", "labels": [], "entities": []}, {"text": "Thematic clustering is important for various use cases.", "labels": [], "entities": [{"text": "Thematic clustering", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8602592647075653}]}, {"text": "For example, in multi-document summarization, one often extracts sentences from multiple documents that have to be organized into meaningful sections and paragraphs.", "labels": [], "entities": [{"text": "multi-document summarization", "start_pos": 16, "end_pos": 44, "type": "TASK", "confidence": 0.6018801033496857}]}, {"text": "Similarly, within the emerging field of computational argumentation (, arguments maybe found in a widespread set of articles (, which further require thematic organization to generate a compelling argumentative narrative.", "labels": [], "entities": []}, {"text": "We approach the problem of thematic clustering by developing a dedicated sentence similarity measure, targeted at a comparative task -Thematic Distance Comparison (TDC): given a pivot sentence, and two other sentences, the task is to determine which of the two sentences is thematically closer to the pivot.", "labels": [], "entities": [{"text": "thematic clustering", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.8837714493274689}]}, {"text": "By training a deep neural network (DNN) to perform TDC, we are able to learn a thematic similarity measure.", "labels": [], "entities": []}, {"text": "Obtaining annotated data for training the DNN is quite demanding.", "labels": [], "entities": [{"text": "DNN", "start_pos": 42, "end_pos": 45, "type": "DATASET", "confidence": 0.802517294883728}]}, {"text": "Hence, we exploit the natural structure of text articles to obtain weakly-labeled data.", "labels": [], "entities": []}, {"text": "Specifically, our underlying assumption is that sentences belonging to the same section are typically more thematically related than sentences appearing in different sections.", "labels": [], "entities": []}, {"text": "Armed with this observation, we use the partition of Wikipedia articles into sections to automatically generate sentence triplets, where two of the sentences are from the same section, and one is from a different section.", "labels": [], "entities": []}, {"text": "This results in a sizable training set of weakly labeled triplets, used to train a triplet neural network, aiming to predict which sentence is from the same section as the pivot in each triplet.", "labels": [], "entities": []}, {"text": "shows an example of a triplet.", "labels": [], "entities": []}, {"text": "To test the performance of our network on the-matic clustering of sentences, we create anew clustering benchmark based on Wikipedia sections.", "labels": [], "entities": []}, {"text": "We show that our methods, combined with existing clustering algorithms, outperform state-of-the-art general-purpose sentence embedding models in the task of reconstructing the original section structure.", "labels": [], "entities": []}, {"text": "Moreover, the embeddings obtained from the triplet DNN perform well also on standard semantic relatedness tasks.", "labels": [], "entities": []}, {"text": "The main contribution of this work is therefore in proposing anew approach for learning thematic relatedness between sentences, formulating the related TDC task and creating a thematic clustering benchmark.", "labels": [], "entities": []}, {"text": "To further enhance research in these directions, we publish the clustering benchmark on the IBM Debater Datasets webpage 1 .", "labels": [], "entities": [{"text": "IBM Debater Datasets webpage 1", "start_pos": 92, "end_pos": 122, "type": "DATASET", "confidence": 0.9355034470558167}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Example of a section-sen triplet from the  article 'James Smith McDonnell'. The first two  sentences are from the section 'Career' and the  third is from 'Early life'", "labels": [], "entities": [{"text": "James Smith McDonnell'", "start_pos": 62, "end_pos": 84, "type": "DATASET", "confidence": 0.9271372258663177}]}, {"text": " Table 4: Results on the clustering task", "labels": [], "entities": [{"text": "clustering task", "start_pos": 25, "end_pos": 40, "type": "TASK", "confidence": 0.9062771499156952}]}, {"text": " Table 5: Results on the SICK semantic relatedness  subtask.", "labels": [], "entities": [{"text": "SICK semantic relatedness", "start_pos": 25, "end_pos": 50, "type": "TASK", "confidence": 0.9056198596954346}]}]}