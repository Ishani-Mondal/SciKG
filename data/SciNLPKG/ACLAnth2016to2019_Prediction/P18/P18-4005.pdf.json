{"title": [{"text": "Jack the Reader -A Machine Reading Framework", "labels": [], "entities": [{"text": "Jack the Reader -A Machine Reading", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.5458793214389256}]}], "abstractContent": [{"text": "Many Machine Reading and Natural Language Understanding tasks require reading supporting text in order to answer questions.", "labels": [], "entities": [{"text": "Machine Reading and Natural Language Understanding", "start_pos": 5, "end_pos": 55, "type": "TASK", "confidence": 0.6749880363543829}]}, {"text": "For example, in Question Answering , the supporting text can be newswire or Wikipedia articles; in Natural Language Inference, premises can be seen as the supporting text and hypotheses as questions.", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.8167798221111298}, {"text": "Natural Language Inference", "start_pos": 99, "end_pos": 125, "type": "TASK", "confidence": 0.6763314207394918}]}, {"text": "Providing a set of useful primitives operating in a single framework of related tasks would allow for expressive modelling, and easier model comparison and replication.", "labels": [], "entities": [{"text": "model comparison and replication", "start_pos": 135, "end_pos": 167, "type": "TASK", "confidence": 0.714789018034935}]}, {"text": "To that end, we present Jack the Reader (JACK), a framework for Machine Reading that allows for quick model prototyp-ing by component reuse, evaluation of new models on existing datasets as well as integrating new datasets and applying them on a growing set of implemented baseline models.", "labels": [], "entities": [{"text": "Machine Reading", "start_pos": 64, "end_pos": 79, "type": "TASK", "confidence": 0.7842239141464233}]}, {"text": "JACK is currently supporting (but not limited to) three tasks: Question Answering , Natural Language Inference, and Link Prediction.", "labels": [], "entities": [{"text": "JACK", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8451480865478516}, {"text": "Question Answering", "start_pos": 63, "end_pos": 81, "type": "TASK", "confidence": 0.8640354871749878}, {"text": "Natural Language Inference", "start_pos": 84, "end_pos": 110, "type": "TASK", "confidence": 0.6401137312253317}, {"text": "Link Prediction", "start_pos": 116, "end_pos": 131, "type": "TASK", "confidence": 0.8495552837848663}]}, {"text": "It is developed with the aim of increasing research efficiency and code reuse.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automated reading and understanding of textual and symbolic input, to a degree that enables question answering, is at the core of Machine Reading (MR).", "labels": [], "entities": [{"text": "question answering", "start_pos": 92, "end_pos": 110, "type": "TASK", "confidence": 0.8848035335540771}, {"text": "Machine Reading (MR)", "start_pos": 130, "end_pos": 150, "type": "TASK", "confidence": 0.8456399440765381}]}, {"text": "A core insight facilitating the development of MR models is that most of these tasks can be cast as an instance of the Question Answering (QA) task: an input can be cast in terms of question, support documents and answer candidates, and an output in terms of answers.", "labels": [], "entities": [{"text": "MR", "start_pos": 47, "end_pos": 49, "type": "TASK", "confidence": 0.9862496852874756}, {"text": "Question Answering (QA) task", "start_pos": 119, "end_pos": 147, "type": "TASK", "confidence": 0.8370346973339716}]}, {"text": "For instance, in case of Natural Language Inference (NLI), we can view the hypothesis as a multiple choice question about the underlying premise (support) with predefined set of specific answer candidates (entailment, contradiction, neutral).", "labels": [], "entities": [{"text": "Natural Language Inference (NLI)", "start_pos": 25, "end_pos": 57, "type": "TASK", "confidence": 0.796751985947291}]}, {"text": "Link Prediction (LP) -a task which requires predicting the truth value about facts represented as (subject, predicate, object)-triples -can be conceived of as an instance of QA (see Section 4 for more details).", "labels": [], "entities": [{"text": "Link Prediction (LP)", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7800508439540863}]}, {"text": "By unifying these tasks into a single framework, we can facilitate the design and construction of multicomponent MR pipelines.", "labels": [], "entities": []}, {"text": "There are many successful frameworks such as STANFORD CORENLP), NLTK (, and SPACY 1 for NLP, LUCENE 2 and SOLR 3 for Information Retrieval, and SCIKIT-LEARN 4 , PYTORCH and TENSOR-FLOW () for general Machine Learning (ML) with a special focus on Deep Learning (DL), among others.", "labels": [], "entities": [{"text": "Information Retrieval", "start_pos": 117, "end_pos": 138, "type": "TASK", "confidence": 0.8019882440567017}, {"text": "general Machine Learning (ML)", "start_pos": 192, "end_pos": 221, "type": "TASK", "confidence": 0.7246137062708536}]}, {"text": "All of these frameworks touch upon several aspects of Machine Reading, but none of them offers dedicated support for modern MR pipelines.", "labels": [], "entities": [{"text": "Machine Reading", "start_pos": 54, "end_pos": 69, "type": "TASK", "confidence": 0.8595666289329529}, {"text": "MR pipelines", "start_pos": 124, "end_pos": 136, "type": "TASK", "confidence": 0.940042108297348}]}, {"text": "Pre-processing and transforming MR datasets into a format that is usable by a MR model as well as implementing common architecture building blocks all require substantial effort which is not specifically handled by any of the aforementioned solutions.", "labels": [], "entities": []}, {"text": "This is due to the fact that they serve a different, typically much broader purpose.", "labels": [], "entities": []}, {"text": "In this paper, we introduce Jack the Reader (JACK), a reusable framework for MR.", "labels": [], "entities": [{"text": "Jack the Reader (JACK)", "start_pos": 28, "end_pos": 50, "type": "DATASET", "confidence": 0.5149193505446116}, {"text": "MR", "start_pos": 77, "end_pos": 79, "type": "TASK", "confidence": 0.9907398223876953}]}, {"text": "It allows for the easy integration of novel tasks and datasets by exposing a set of high-level primitives and a common data format.", "labels": [], "entities": []}, {"text": "For supported tasks it is straight-forward to develop new models without worrying about the cumbersome implementation 1 https://spacy.io 2 https://lucene.apache.org 3 http://lucene.apache.org/solr/ 4 http://scikit-learn.org 5 http://pytorch.org/ of training, evaluation, pre-and post-processing routines.", "labels": [], "entities": []}, {"text": "Declarative model definitions make the development of QA and NLI models using common building blocks effortless.", "labels": [], "entities": []}, {"text": "JACK covers a large variety of datasets, implementations and pretrained models on three distinct MR tasks and supports two ML backends, namely PYTORCH and TENSORFLOW.", "labels": [], "entities": [{"text": "JACK", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7727338075637817}, {"text": "PYTORCH", "start_pos": 143, "end_pos": 150, "type": "METRIC", "confidence": 0.5574209094047546}, {"text": "TENSORFLOW", "start_pos": 155, "end_pos": 165, "type": "METRIC", "confidence": 0.8937857151031494}]}, {"text": "Furthermore, it is easy to train, deploy, and interact with MR models, which we refer to as readers.", "labels": [], "entities": []}], "datasetContent": [{"text": "Experimental setup and results for different models on the three above-mentioned MR tasks are reported in this section.", "labels": [], "entities": [{"text": "MR tasks", "start_pos": 81, "end_pos": 89, "type": "TASK", "confidence": 0.9204264283180237}]}, {"text": "Note that our reimplementations or training configurations may not be entirely faithful.We performed slight modifications to original setups where we found this to perform better in our experiments, as indicated in the respective task subsections.", "labels": [], "entities": []}, {"text": "However, our results still vary from the reported ones, which we believe is due to the extensive hyper-parameter engineering that went into the original settings, which we did not perform.", "labels": [], "entities": []}, {"text": "For each experiment, a ready to use training configuration as well as pretrained models are part of JACK.", "labels": [], "entities": [{"text": "JACK", "start_pos": 100, "end_pos": 104, "type": "DATASET", "confidence": 0.7695847749710083}]}], "tableCaptions": [{"text": " Table 1: Metrics on the SQuAD development set  comparing F1 metric from the original implemen- tation to that of JACK, number of parameters, and  relative speed of the models.", "labels": [], "entities": [{"text": "SQuAD development set", "start_pos": 25, "end_pos": 46, "type": "DATASET", "confidence": 0.7181336283683777}, {"text": "F1 metric", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9745871126651764}, {"text": "JACK", "start_pos": 114, "end_pos": 118, "type": "METRIC", "confidence": 0.748991072177887}]}, {"text": " Table 2: Accuracy on the SNLI test set achieved  by cBiLSTM, DAM, and ESIM.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9963757395744324}, {"text": "SNLI test set", "start_pos": 26, "end_pos": 39, "type": "DATASET", "confidence": 0.8490285674730936}, {"text": "cBiLSTM", "start_pos": 53, "end_pos": 60, "type": "DATASET", "confidence": 0.9329766035079956}]}]}