{"title": [], "abstractContent": [{"text": "Style transfer is the task of rephrasing the text to contain specific stylistic properties without changing the intent or affect within the context.", "labels": [], "entities": [{"text": "Style transfer", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7847333550453186}]}, {"text": "This paper introduces anew method for automatic style transfer.", "labels": [], "entities": [{"text": "style transfer", "start_pos": 48, "end_pos": 62, "type": "TASK", "confidence": 0.7196623831987381}]}, {"text": "We first learn a latent representation of the input sentence which is grounded in a language translation model in order to better preserve the meaning of the sentence while reducing stylistic properties.", "labels": [], "entities": [{"text": "language translation", "start_pos": 84, "end_pos": 104, "type": "TASK", "confidence": 0.7693220376968384}]}, {"text": "Then adversarial generation techniques are used to make the output match the desired style.", "labels": [], "entities": []}, {"text": "We evaluate this technique on three different style transformations: sentiment, gender and political slant.", "labels": [], "entities": []}, {"text": "Compared to two state-of-the-art style transfer mod-eling techniques we show improvements both in automatic evaluation of style transfer and in manual evaluation of meaning preservation and fluency.", "labels": [], "entities": [{"text": "style transfer", "start_pos": 122, "end_pos": 136, "type": "TASK", "confidence": 0.7123053073883057}, {"text": "meaning preservation", "start_pos": 165, "end_pos": 185, "type": "TASK", "confidence": 0.7184305936098099}]}], "introductionContent": [{"text": "Intelligent, situation-aware applications must produce naturalistic outputs, lexicalizing the same meaning differently, depending upon the environment.", "labels": [], "entities": []}, {"text": "This is particularly relevant for language generation tasks such as machine translation (, caption generation (, and natural language generation ().", "labels": [], "entities": [{"text": "language generation", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.7258329540491104}, {"text": "machine translation", "start_pos": 68, "end_pos": 87, "type": "TASK", "confidence": 0.8405439853668213}, {"text": "caption generation", "start_pos": 91, "end_pos": 109, "type": "TASK", "confidence": 0.9081571102142334}, {"text": "natural language generation", "start_pos": 117, "end_pos": 144, "type": "TASK", "confidence": 0.651246041059494}]}, {"text": "In conversational agents (, for example, modulating the politeness style, to sound natural depending upon a situation: at a party with friends \"Shut up!", "labels": [], "entities": []}, {"text": "the video is starting!\", or in a professional setting \"Please be quiet, the video will begin shortly.\".", "labels": [], "entities": []}, {"text": "These goals have motivated a considerable amount of recent research efforts focused at \"controlled\" language generation-aiming at separating the semantic content of what is said from the stylistic dimensions of how it is said.", "labels": [], "entities": [{"text": "controlled\" language generation-aiming", "start_pos": 88, "end_pos": 126, "type": "TASK", "confidence": 0.7884931117296219}]}, {"text": "These include approaches relying on heuristic substitutions, deletions, and insertions to modulate demographic properties of a writer, integrating stylistic and demographic speaker traits in statistical machine translation (, and deep generative models controlling fora particular stylistic aspect, e.g., politeness, sentiment, or tense (.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 191, "end_pos": 222, "type": "TASK", "confidence": 0.6587137877941132}]}, {"text": "The latter approaches to style transfer, while more powerful and flexible than heuristic methods, have yet to show that in addition to transferring style they effectively preserve meaning of input sentences.", "labels": [], "entities": [{"text": "style transfer", "start_pos": 25, "end_pos": 39, "type": "TASK", "confidence": 0.7332526594400406}]}, {"text": "This paper introduces a novel approach to transferring style of a sentence while better preserving its meaning.", "labels": [], "entities": [{"text": "transferring style of a sentence", "start_pos": 42, "end_pos": 74, "type": "TASK", "confidence": 0.8855283617973327}]}, {"text": "We hypothesize-relying on the study of who showed that author characteristics are significantly obfuscated by both manual and automatic machine translation-that grounding in back-translation is a plausible approach to rephrase a sentence while reducing its stylistic properties.", "labels": [], "entities": []}, {"text": "We thus first use back-translation to rephrase the sentence and reduce the effect of the original style; then, we generate from the latent representation, using separate style-specific generators controlling for style ( \u00a72).", "labels": [], "entities": []}, {"text": "We focus on transferring author attributes: (1) gender and (2) political slant, and (3) on sentiment modification.", "labels": [], "entities": [{"text": "sentiment modification", "start_pos": 91, "end_pos": 113, "type": "TASK", "confidence": 0.9671820998191833}]}, {"text": "The second task is novel: given a sentence by an author with a particular political leaning, rephrase the sentence to preserve its meaning but to confound classifiers of political slant ( \u00a73).", "labels": [], "entities": []}, {"text": "The task of sentiment modification enables us to compare our approach with state-of-: Style transfer pipeline: to rephrase a sentence and reduce its stylistic characteristics, the sentence is back-translated.", "labels": [], "entities": [{"text": "sentiment modification", "start_pos": 12, "end_pos": 34, "type": "TASK", "confidence": 0.9325291812419891}, {"text": "Style transfer", "start_pos": 86, "end_pos": 100, "type": "TASK", "confidence": 0.7005202174186707}]}, {"text": "Then, separate style-specific generators are used for style transfer.", "labels": [], "entities": [{"text": "style transfer", "start_pos": 54, "end_pos": 68, "type": "TASK", "confidence": 0.7791748344898224}]}, {"text": "Style transfer is evaluated using style classifiers trained on held-out data.", "labels": [], "entities": [{"text": "Style transfer", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8511542081832886}]}, {"text": "Our back-translation style transfer model outperforms the state-of-theart baselines on the tasks of political slant and sentiment modification; 12% absolute improvement was attained for political slant transfer, and up to 7% absolute improvement in modification of sentiment ( \u00a75).", "labels": [], "entities": [{"text": "sentiment modification", "start_pos": 120, "end_pos": 142, "type": "TASK", "confidence": 0.7074731141328812}, {"text": "political slant transfer", "start_pos": 186, "end_pos": 210, "type": "TASK", "confidence": 0.6740320026874542}]}, {"text": "Meaning preservation was evaluated manually, using A/B testing ( \u00a74).", "labels": [], "entities": [{"text": "Meaning preservation", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9456867277622223}, {"text": "A/B", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.8211173415184021}]}, {"text": "Our approach performs better than the baseline on the task of transferring gender and political slant.", "labels": [], "entities": [{"text": "transferring gender and political slant", "start_pos": 62, "end_pos": 101, "type": "TASK", "confidence": 0.6541459143161774}]}, {"text": "Finally, we evaluate the fluency of the generated sentences using human evaluation and our model outperforms the baseline in all experiments for fluency.", "labels": [], "entities": []}, {"text": "The main contribution of this work is anew approach to style transfer that outperforms stateof-the-art baselines in both the quality of inputoutput correspondence (meaning preservation and fluency), and the accuracy of style transfer.", "labels": [], "entities": [{"text": "style transfer", "start_pos": 55, "end_pos": 69, "type": "TASK", "confidence": 0.8170580267906189}, {"text": "accuracy", "start_pos": 207, "end_pos": 215, "type": "METRIC", "confidence": 0.999079704284668}, {"text": "style transfer", "start_pos": 219, "end_pos": 233, "type": "TASK", "confidence": 0.7287469506263733}]}, {"text": "The secondary contribution is anew task that we propose to evaluate style transfer: transferring political slant.", "labels": [], "entities": [{"text": "style transfer", "start_pos": 68, "end_pos": 82, "type": "TASK", "confidence": 0.8562965989112854}]}], "datasetContent": [{"text": "In what follows, we describe our experimental settings, including baselines used, hyperparameter settings, datasets, and evaluation setups.", "labels": [], "entities": []}, {"text": "We compare our model against the \"cross-aligned\" auto-encoder (, which uses style-specific decoders to align the style of generated sentences to the actual distribution of the style.", "labels": [], "entities": []}, {"text": "We used the off-the-shelf sentiment model released by for the sentiment experiments.", "labels": [], "entities": []}, {"text": "We also separately train this model for the gender and political slant using hyper-parameters detailed below.", "labels": [], "entities": [{"text": "gender and political slant", "start_pos": 44, "end_pos": 70, "type": "TASK", "confidence": 0.6459924280643463}]}, {"text": "We trained an EnglishFrench neural machine translation system and a French-English back-translation system.", "labels": [], "entities": [{"text": "EnglishFrench neural machine translation", "start_pos": 14, "end_pos": 54, "type": "TASK", "confidence": 0.7831073105335236}]}, {"text": "We used data from Workshop in Statistical Machine Translation 2015 (WMT15) () to train our translation models.", "labels": [], "entities": [{"text": "Statistical Machine Translation 2015 (WMT15)", "start_pos": 30, "end_pos": 74, "type": "TASK", "confidence": 0.8056062374796186}]}, {"text": "We used the FrenchEnglish data from the Europarl v7 corpus, the news commentary v10 corpus and the common crawl corpus from WMT15.", "labels": [], "entities": [{"text": "FrenchEnglish data", "start_pos": 12, "end_pos": 30, "type": "DATASET", "confidence": 0.9856072068214417}, {"text": "Europarl v7 corpus", "start_pos": 40, "end_pos": 58, "type": "DATASET", "confidence": 0.9040667215983073}, {"text": "news commentary v10 corpus", "start_pos": 64, "end_pos": 90, "type": "DATASET", "confidence": 0.6655904576182365}, {"text": "WMT15", "start_pos": 124, "end_pos": 129, "type": "DATASET", "confidence": 0.892731249332428}]}, {"text": "Data were tokenized using the Moses tokenizer ().", "labels": [], "entities": []}, {"text": "Approximately 5.4M English-French parallel sentences were used for training.", "labels": [], "entities": []}, {"text": "A vocabulary size of 100K was used to train the translation systems.", "labels": [], "entities": []}, {"text": "In all the experiments, the generator and the encoders area twolayer bidirectional LSTM with an input size of 300 and the hidden dimension of 500.", "labels": [], "entities": []}, {"text": "The generator In addition, we compared our model with the current state-of-the-art approach introduced by; use this method as baseline, obtaining comparable results.", "labels": [], "entities": []}, {"text": "We reproduced the results reported in () using their tasks and data.", "labels": [], "entities": []}, {"text": "However, the same model trained on our political slant datasets (described in \u00a73), obtained an almost random accuracy of 50.98% in style transfer.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 109, "end_pos": 117, "type": "METRIC", "confidence": 0.9864028096199036}, {"text": "style transfer", "start_pos": 131, "end_pos": 145, "type": "TASK", "confidence": 0.8101236522197723}]}, {"text": "We thus omit these results.", "labels": [], "entities": []}, {"text": "samples a sentence of maximum length 50.", "labels": [], "entities": []}, {"text": "All the generators use global attention vectors of size 500.", "labels": [], "entities": []}, {"text": "The CNN classifier is trained with 100 filters of size 5, with max-pooling.", "labels": [], "entities": []}, {"text": "The input to CNN is of size 302: the 300-dimensional word embedding plus two bits for membership of the word in our style lexicons, as described in \u00a72.2.1.", "labels": [], "entities": [{"text": "CNN", "start_pos": 13, "end_pos": 16, "type": "DATASET", "confidence": 0.8764545917510986}]}, {"text": "Balancing parameter \u03bb c is set to 15.", "labels": [], "entities": [{"text": "Balancing", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.6996901631355286}]}, {"text": "For sentiment task, we have used settings provided in.", "labels": [], "entities": [{"text": "sentiment task", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.9499186873435974}]}, {"text": "CAE BST Gender 60.40 57.04 Political slant 75.82 88.01 Sentiment 80.43 87.22: Accuracy of the style transfer in generated sentences.", "labels": [], "entities": [{"text": "CAE BST Gender 60.40 57.04 Political slant 75.82 88.01 Sentiment 80.43 87.22", "start_pos": 0, "end_pos": 76, "type": "DATASET", "confidence": 0.8366144696871439}, {"text": "Accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.971636950969696}, {"text": "style transfer", "start_pos": 94, "end_pos": 108, "type": "TASK", "confidence": 0.6854599118232727}]}, {"text": "In, we detail the accuracy of each classifier on generated style-transfered sentences.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9991583824157715}]}, {"text": "We denote the Cross-aligned Auto-Encoder model as CAE and our model as Back-translation for Style Transfer (BST).", "labels": [], "entities": [{"text": "CAE", "start_pos": 50, "end_pos": 53, "type": "METRIC", "confidence": 0.8384515643119812}, {"text": "Style Transfer (BST)", "start_pos": 92, "end_pos": 112, "type": "TASK", "confidence": 0.770597392320633}]}, {"text": "On two out of three tasks our model substantially outperforms the baseline, by up to 12% in political slant transfer, and by up to 7% in sentiment modification.", "labels": [], "entities": [{"text": "political slant transfer", "start_pos": 92, "end_pos": 116, "type": "TASK", "confidence": 0.7074016233285269}, {"text": "sentiment modification", "start_pos": 137, "end_pos": 159, "type": "TASK", "confidence": 0.9066003262996674}]}], "tableCaptions": [{"text": " Table 3: Average sentence length and class distri- bution of style corpora.", "labels": [], "entities": []}, {"text": " Table 5: Human preference for meaning preserva- tion in percentages.", "labels": [], "entities": []}, {"text": " Table 6: Fluency of the generated sentences.", "labels": [], "entities": []}]}