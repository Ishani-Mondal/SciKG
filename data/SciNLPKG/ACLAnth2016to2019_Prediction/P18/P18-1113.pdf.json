{"title": [{"text": "Word Embedding and WordNet Based Metaphor Identification and Interpretation", "labels": [], "entities": [{"text": "WordNet Based Metaphor Identification and Interpretation", "start_pos": 19, "end_pos": 75, "type": "TASK", "confidence": 0.6192349841197332}]}], "abstractContent": [{"text": "Metaphoric expressions are widespread in natural language, posing a significant challenge for various natural language processing tasks such as Machine Translation.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 144, "end_pos": 163, "type": "TASK", "confidence": 0.8180119693279266}]}, {"text": "Current word embedding based metaphor identification models cannot identify the exact metaphorical words within a sentence.", "labels": [], "entities": [{"text": "word embedding based metaphor identification", "start_pos": 8, "end_pos": 52, "type": "TASK", "confidence": 0.6498650252819062}]}, {"text": "In this paper, we propose an un-supervised learning method that identifies and interprets metaphors at word-level without any preprocessing, outperforming strong baselines in the metaphor identification task.", "labels": [], "entities": [{"text": "metaphor identification task", "start_pos": 179, "end_pos": 207, "type": "TASK", "confidence": 0.7965718905131022}]}, {"text": "Our model extends to interpret the identified metaphors, paraphrasing them into their literal counterparts, so that they can be better translated by machines.", "labels": [], "entities": []}, {"text": "We evaluated this with two popular translation systems for English to Chi-nese, showing that our model improved the systems significantly.", "labels": [], "entities": []}], "introductionContent": [{"text": "Metaphor enriches language, playing a significant role in communication, cognition, and decision making.", "labels": [], "entities": [{"text": "decision making", "start_pos": 88, "end_pos": 103, "type": "TASK", "confidence": 0.7742383182048798}]}, {"text": "Relevant statistics illustrate that about one third of sentences in typical corpora contain metaphor expressions.", "labels": [], "entities": []}, {"text": "Linguistically, metaphor is defined as a language expression that uses one or several words to represent another concept, rather than taking their literal meanings of the given words in the context (.", "labels": [], "entities": []}, {"text": "Computational metaphor processing refers to modelling non-literal expressions (e.g., metaphor, metonymy, and personification) and is useful for improving many NLP tasks such as Machine Translation (MT) and Sentiment Analysis ().", "labels": [], "entities": [{"text": "Computational metaphor processing", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8192658027013143}, {"text": "Machine Translation (MT)", "start_pos": 177, "end_pos": 201, "type": "TASK", "confidence": 0.8485813140869141}, {"text": "Sentiment Analysis", "start_pos": 206, "end_pos": 224, "type": "TASK", "confidence": 0.8608954846858978}]}, {"text": "For instance, Google Translate failed in translating devour within a sentence, \"She devoured his novels.\", into Chinese.", "labels": [], "entities": []}, {"text": "The term was translated into \u541e\u566c, which takes the literal sense of swallow and is not understandable in Chinese.", "labels": [], "entities": []}, {"text": "Interpreting metaphors allows us to paraphrase them into literal expressions which maintain the intended meaning and are easier to translate.", "labels": [], "entities": []}, {"text": "Metaphor identification approaches based on word embeddings have become popular) as they do not rely on hand-crafted knowledge for training.", "labels": [], "entities": [{"text": "Metaphor identification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8797107338905334}]}, {"text": "These models follow a similar paradigm in which input sentences are first parsed into phrases and then the metaphoricity of the phrases is identified; they do not tackle word-level metaphor.", "labels": [], "entities": []}, {"text": "E.g., given the former sentence \"She devoured his novels.\", the aforementioned methods will first parse the sentence into a verb-direct object phrase devour novel, and then detect the clash between devour and novel, flagging this phrase as a likely metaphor.", "labels": [], "entities": []}, {"text": "However, which component word is metaphorical cannot be identified, as important contextual words in the sentence were excluded while processing these phrases.", "labels": [], "entities": []}, {"text": "Discarding contextual information also leads to a failure to identify a metaphor when both words in the phrase are metaphorical, but taken out of context they appear literal.", "labels": [], "entities": []}, {"text": "E.g., \"This young man knows how to climb the social ladder.\") is a metaphorical expression.", "labels": [], "entities": []}, {"text": "However, when the sentence is parsed into a verbdirect object phrase, climb ladder, it appears literal.", "labels": [], "entities": []}, {"text": "In this paper, we propose an unsupervised metaphor processing model which can identify and interpret linguistic metaphors at the wordlevel.", "labels": [], "entities": []}, {"text": "Specifically, our model is built upon word embedding methods () and uses WordNet for lexical re-lation acquisition.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 73, "end_pos": 80, "type": "DATASET", "confidence": 0.9566994905471802}, {"text": "lexical re-lation acquisition", "start_pos": 85, "end_pos": 114, "type": "TASK", "confidence": 0.6686424215634664}]}, {"text": "Our model is distinguished from existing methods in two aspects.", "labels": [], "entities": []}, {"text": "First, our model is generic which does not constrain the source domain of metaphor.", "labels": [], "entities": []}, {"text": "Second, the developed model does not rely on any labelled data for model training, but rather captures metaphor in an unsupervised, data-driven manner.", "labels": [], "entities": []}, {"text": "Linguistic metaphors are identified by modelling the distance (in vector space) between the target word's literal and metaphorical senses.", "labels": [], "entities": [{"text": "Linguistic metaphors", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.729983776807785}]}, {"text": "The metaphorical sense within a sentence is identified by its surrounding context within the sentence, using word embedding representations and WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 144, "end_pos": 151, "type": "DATASET", "confidence": 0.9420411586761475}]}, {"text": "This novel approach allows our model to operate at the sentence level without any preprocessing, e.g., dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 103, "end_pos": 121, "type": "TASK", "confidence": 0.7882962822914124}]}, {"text": "Taking contexts into account also addresses the issue that a two-word phrase appears literal, but it is metaphoric within a sentence (e.g., the climb ladder example).", "labels": [], "entities": []}, {"text": "We evaluate our model against three strong baselines () on the task of metaphor identification.", "labels": [], "entities": [{"text": "metaphor identification", "start_pos": 71, "end_pos": 94, "type": "TASK", "confidence": 0.8981938362121582}]}, {"text": "Extensive experimentation conducted on a publicly available dataset shows that our model significantly outperforms the unsupervised learning baselines () on both phrase and sentence evaluation, and achieves equivalent performance to the state-ofthe-art deep learning baseline ( on phrase-level evaluation.", "labels": [], "entities": [{"text": "phrase and sentence evaluation", "start_pos": 162, "end_pos": 192, "type": "TASK", "confidence": 0.5880943238735199}]}, {"text": "In addition, while most of the existing works on metaphor processing solely evaluate the model performance in terms of metaphor classification accuracy, we further conducted another set of experiments to evaluate how metaphor processing can be used for supporting the task of MT.", "labels": [], "entities": [{"text": "metaphor processing", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.8381040990352631}, {"text": "metaphor classification", "start_pos": 119, "end_pos": 142, "type": "TASK", "confidence": 0.6717581450939178}, {"text": "accuracy", "start_pos": 143, "end_pos": 151, "type": "METRIC", "confidence": 0.6109798550605774}, {"text": "MT", "start_pos": 276, "end_pos": 278, "type": "TASK", "confidence": 0.9919986128807068}]}, {"text": "Human evaluation shows that our model improves the metaphoric translation significantly, by testing on two prominent translation systems, namely, Google Translate 1 and Bing Translator 2 . To our best knowledge, this is the first metaphor processing model that is evaluated on MT.", "labels": [], "entities": [{"text": "metaphoric translation", "start_pos": 51, "end_pos": 73, "type": "TASK", "confidence": 0.9290400445461273}, {"text": "MT", "start_pos": 277, "end_pos": 279, "type": "TASK", "confidence": 0.7489646077156067}]}, {"text": "To summarise, the contributions of this paper are two-fold: (1) we proposed a novel framework for metaphor identification which does not require any preprocessing or annotated corpora for training; (2) we conducted, to our knowledge, the first metaphor interpretation study of apply-ing metaphor processing for supporting MT.", "labels": [], "entities": [{"text": "metaphor identification", "start_pos": 98, "end_pos": 121, "type": "TASK", "confidence": 0.7990359961986542}, {"text": "metaphor interpretation", "start_pos": 244, "end_pos": 267, "type": "TASK", "confidence": 0.7381325364112854}, {"text": "MT", "start_pos": 322, "end_pos": 324, "type": "TASK", "confidence": 0.9832603335380554}]}, {"text": "We describe related work in \u00a72, followed by our labelling method in \u00a74, experimental design in \u00a75, results in \u00a76 and conclusions in \u00a77.", "labels": [], "entities": []}], "datasetContent": [{"text": "We compare the performance of our framework for metaphor identification against three strong baselines, namely, an unsupervised word embedding based model by , a supervised deep learning model by, and the Context2Vec model 5) which achieves the best performance on Microsoft Sentence Completion Challenge ().", "labels": [], "entities": [{"text": "metaphor identification", "start_pos": 48, "end_pos": 71, "type": "TASK", "confidence": 0.8746709823608398}, {"text": "Microsoft Sentence Completion Challenge", "start_pos": 265, "end_pos": 304, "type": "TASK", "confidence": 0.6038267761468887}]}, {"text": "Context2Vec was not designed for processing metaphors, in order to use it for this we plug it into a very similar framework to that described in.", "labels": [], "entities": []}, {"text": "We use Context2Vec to predict the best fit word from the candidate set, as it similarly uses context to predict the most likely centre word but with bidirectional LSTM based context embedding method.", "labels": [], "entities": []}, {"text": "After locating the best fit word with Context2Vec, we identify the metaphoricity of a target word with the same method (see Step (4) in \u00a74), so that we can also apply it for metaphor interpretation.", "labels": [], "entities": [{"text": "metaphor interpretation", "start_pos": 174, "end_pos": 197, "type": "TASK", "confidence": 0.8084409236907959}]}, {"text": "Note that while Shutova et al. and Rei et al. detect metaphors at the phrase level by identifying metaphorical phrases, Melamud et al.'s model can perform metaphor identification and interpretation on sentences.", "labels": [], "entities": [{"text": "metaphor identification", "start_pos": 155, "end_pos": 178, "type": "TASK", "confidence": 0.8113278448581696}]}, {"text": "Evaluation was conducted based on a dataset developed by.", "labels": [], "entities": []}, {"text": "This dataset 6 , containing 1,230 literal and 409 metaphor sentences, has been widely used for metaphor identification related research.", "labels": [], "entities": [{"text": "metaphor identification related", "start_pos": 95, "end_pos": 126, "type": "TASK", "confidence": 0.8603020906448364}]}, {"text": "There is a verbal target word annotated by 10 annotators in each sentence.", "labels": [], "entities": []}, {"text": "We use two subsets of the Mohammad et al. set, one for phrase evaluation and one for sentence evaluation.", "labels": [], "entities": [{"text": "phrase evaluation", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.8588047921657562}]}, {"text": "The phrase evaluation dataset was kindly provided by Shutova, which consists of 316 metaphorical and 331 literal phrases (subject-verb and verb-direct object word pairs), parsed from Mohammad et al.'s dataset.", "labels": [], "entities": [{"text": "Mohammad et al.'s dataset", "start_pos": 183, "end_pos": 208, "type": "DATASET", "confidence": 0.6887946724891663}]}, {"text": "Similar to , we use 40 metaphoric and 40 literal phrases as a development set and the rest as a test: Metaphor identification results.", "labels": [], "entities": [{"text": "Metaphor identification", "start_pos": 102, "end_pos": 125, "type": "TASK", "confidence": 0.7635067403316498}]}, {"text": "NB: * denotes that our model outperforms the baseline significantly, based on two-tailed paired t-test with p < 0.001.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Metaphor identification results. NB: * denotes that  our model outperforms the baseline significantly, based on  two-tailed paired t-test with p < 0.001.", "labels": [], "entities": [{"text": "Metaphor identification", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.7889060378074646}, {"text": "NB", "start_pos": 43, "end_pos": 45, "type": "METRIC", "confidence": 0.6872468590736389}]}, {"text": " Table 2: Model performance vs. different threshold (\u03c4 )  settings. NB: the sentence level results are based on", "labels": [], "entities": []}, {"text": " Table 3: Accuracy of metaphor interpretation, evaluated on  Google and Bing Translation.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9709727168083191}, {"text": "metaphor interpretation", "start_pos": 22, "end_pos": 45, "type": "TASK", "confidence": 0.8706903755664825}]}]}