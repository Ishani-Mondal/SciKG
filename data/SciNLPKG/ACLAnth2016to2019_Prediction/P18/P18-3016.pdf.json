{"title": [{"text": "Graph-based Filtering of Out-of-Vocabulary Words for Encoder-Decoder Models", "labels": [], "entities": []}], "abstractContent": [{"text": "Encoder-decoder models typically only employ words that are frequently used in the training corpus to reduce the computational costs and exclude noise.", "labels": [], "entities": []}, {"text": "However , this vocabulary set may still include words that interfere with learning in encoder-decoder models.", "labels": [], "entities": []}, {"text": "This paper proposes a method for selecting more suitable words for learning encoders by utilizing not only frequency but also co-occurrence information, which we capture using the HITS algorithm.", "labels": [], "entities": []}, {"text": "We apply our proposed method to two tasks: machine translation and grammatical error correction.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.8195328712463379}, {"text": "grammatical error correction", "start_pos": 67, "end_pos": 95, "type": "TASK", "confidence": 0.5914817253748575}]}, {"text": "For Japanese-to-English translation, this method achieves a BLEU score that is 0.56 points more than that of a baseline.", "labels": [], "entities": [{"text": "Japanese-to-English translation", "start_pos": 4, "end_pos": 35, "type": "TASK", "confidence": 0.6132836788892746}, {"text": "BLEU score", "start_pos": 60, "end_pos": 70, "type": "METRIC", "confidence": 0.9858732223510742}]}, {"text": "Furthermore, it outperforms the baseline method for English grammatical error correction , with an F 0.5-measure that is 1.48 points higher.", "labels": [], "entities": [{"text": "English grammatical error correction", "start_pos": 52, "end_pos": 88, "type": "TASK", "confidence": 0.6995767876505852}, {"text": "F 0.5-measure", "start_pos": 99, "end_pos": 112, "type": "METRIC", "confidence": 0.9692349433898926}]}], "introductionContent": [{"text": "Encoder-decoder models are effective in tasks such as machine translation ( and grammatical error correction.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.8378132283687592}, {"text": "grammatical error correction", "start_pos": 80, "end_pos": 108, "type": "TASK", "confidence": 0.6056462128957113}]}, {"text": "Vocabulary in encoder-decoder models is generally selected from the training corpus in descending order of frequency, and low-frequency words are replaced with an unknown word token <unk>.", "labels": [], "entities": []}, {"text": "The so-called out-of-vocabulary (OOV) words are replaced with <unk> to not increase the decoder's complexity and to reduce noise.", "labels": [], "entities": []}, {"text": "However, naive frequency-based OOV replacement may lead to loss of information that is necessary for modeling context in the encoder.", "labels": [], "entities": [{"text": "OOV replacement", "start_pos": 31, "end_pos": 46, "type": "TASK", "confidence": 0.8081744909286499}]}, {"text": "This study hypothesizes that vocabulary constructed using unigram frequency includes words that interfere with learning in encoder-decoder models.", "labels": [], "entities": []}, {"text": "That is, we presume that vocabulary selection that considers co-occurrence information selects fewer noisy words for learning robust encoders in encoder-decoder models.", "labels": [], "entities": [{"text": "vocabulary selection", "start_pos": 25, "end_pos": 45, "type": "TASK", "confidence": 0.726056843996048}]}, {"text": "We apply the hyperlink-induced topic search (HITS) algorithm to extract the co-occurrence relations between words.", "labels": [], "entities": []}, {"text": "Intuitively, the removal of words that rarely co-occur with others yields better encoder models than ones that include noisy lowfrequency words.", "labels": [], "entities": []}, {"text": "This study examines two tasks, machine translation (MT) and grammatical error correction (GEC) to confirm the effect of decreasing noisy words, with a focus on the vocabulary of the encoder side, because the vocabulary on the decoder side is relatively limited.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 31, "end_pos": 55, "type": "TASK", "confidence": 0.8348882377147675}, {"text": "grammatical error correction (GEC)", "start_pos": 60, "end_pos": 94, "type": "METRIC", "confidence": 0.668458417057991}]}, {"text": "Ina Japanese-to-English MT experiment, our method achieves a BLEU score that is 0.56 points more than that of the frequency-based method.", "labels": [], "entities": [{"text": "MT", "start_pos": 24, "end_pos": 26, "type": "TASK", "confidence": 0.8836479783058167}, {"text": "BLEU score", "start_pos": 61, "end_pos": 71, "type": "METRIC", "confidence": 0.9849041998386383}]}, {"text": "Further, it outperforms the frequencybased method for English GEC, with an F 0.5 -measure that is 1.48 points higher.", "labels": [], "entities": [{"text": "English GEC", "start_pos": 54, "end_pos": 65, "type": "TASK", "confidence": 0.5351621508598328}, {"text": "F 0.5 -measure", "start_pos": 75, "end_pos": 89, "type": "METRIC", "confidence": 0.9728206098079681}]}, {"text": "The main contributions of this study are as follows: 1.", "labels": [], "entities": []}, {"text": "The simple but effective preprocessing method we propose for vocabulary selection improves encoder-decoder model performance.", "labels": [], "entities": [{"text": "vocabulary selection", "start_pos": 61, "end_pos": 81, "type": "TASK", "confidence": 0.838299572467804}]}, {"text": "2. This study is the first to address noise reduction in the source text of encoder-decoder models.", "labels": [], "entities": []}], "datasetContent": [{"text": "The second experiment addresses GEC.", "labels": [], "entities": [{"text": "GEC", "start_pos": 32, "end_pos": 35, "type": "DATASET", "confidence": 0.8592336773872375}]}, {"text": "We combine the FCE public dataset (Yannakoudakis et al., 2011), NUCLE corpus (, and English learner corpus from the Lang-8 learner corpus) and remove sentences longer than 100 words to create a training corpus.", "labels": [], "entities": [{"text": "FCE public dataset", "start_pos": 15, "end_pos": 33, "type": "DATASET", "confidence": 0.9225620031356812}, {"text": "NUCLE corpus", "start_pos": 64, "end_pos": 76, "type": "DATASET", "confidence": 0.8716254532337189}, {"text": "Lang-8 learner corpus", "start_pos": 116, "end_pos": 137, "type": "DATASET", "confidence": 0.8044454256693522}]}, {"text": "From the Lang-8 learner corpus, we use only the pairs of erroneous and corrected sentences.", "labels": [], "entities": [{"text": "Lang-8 learner corpus", "start_pos": 9, "end_pos": 30, "type": "DATASET", "confidence": 0.8283078869183859}]}, {"text": "We use 1,452,584 sentences as a training set (502,908 types on the encoder side and 639,574 types on the decoder side).", "labels": [], "entities": []}, {"text": "We evaluate the models' performances on the standard sets from the CoNLL-14 shared task () using CoNLL-13 data as a development set (1,381 sentences) and CoNLL-14 data as a test set (1,312 sentences) . We employ F 0.5 as an evaluation measure for the CoNLL-14 shared task.", "labels": [], "entities": [{"text": "CoNLL-14 shared task", "start_pos": 67, "end_pos": 87, "type": "DATASET", "confidence": 0.8298147916793823}, {"text": "CoNLL-13 data", "start_pos": 97, "end_pos": 110, "type": "DATASET", "confidence": 0.9203998446464539}, {"text": "CoNLL-14 data", "start_pos": 154, "end_pos": 167, "type": "DATASET", "confidence": 0.8937754929065704}, {"text": "F 0.5", "start_pos": 212, "end_pos": 217, "type": "METRIC", "confidence": 0.9706137776374817}]}, {"text": "We use the same model as in Section 4.1 as a neural model for GEC.", "labels": [], "entities": [{"text": "GEC", "start_pos": 62, "end_pos": 65, "type": "DATASET", "confidence": 0.6283702254295349}]}, {"text": "The models' parameter settings are similar to the MT experiment, except for the vocabulary and batch sizes.", "labels": [], "entities": [{"text": "MT", "start_pos": 50, "end_pos": 52, "type": "TASK", "confidence": 0.9309414029121399}]}, {"text": "In this experiment, we set the vocabulary size on the encoder and decoder sides to 150K and 50K, respectively.", "labels": [], "entities": []}, {"text": "Ad-src Genetic refers the chance of inheriting a disorder or disease . baseline Genetic refers the chance of inheriting a disorder or disease . PPMI Genetic refers to the chance of inheriting a disorder or disease . gold Genetic risk refers to the chance of inheriting a disorder or disease .: An example of GEC using a source sentence from COMMON.", "labels": [], "entities": [{"text": "COMMON", "start_pos": 341, "end_pos": 347, "type": "DATASET", "confidence": 0.9055376052856445}]}, {"text": "ditionally, we conduct the experiment of changing vocabulary size of the encoder to 50K to investigate the effect of the vocabulary size.", "labels": [], "entities": []}, {"text": "Unless otherwise noted, we conduct an analysis of the model using the vocabulary size of 150K.", "labels": [], "entities": []}, {"text": "The mini-batch size is 100.", "labels": [], "entities": []}, {"text": "shows the performance of the baseline and proposed method.", "labels": [], "entities": []}, {"text": "The PPMI model improves precision and recall; it achieves a F 0.5 -measure 1.48 points higher than the baseline method.", "labels": [], "entities": [{"text": "precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.999612033367157}, {"text": "recall", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9996974468231201}, {"text": "F 0.5 -measure", "start_pos": 60, "end_pos": 74, "type": "METRIC", "confidence": 0.984057754278183}]}], "tableCaptions": [{"text": " Table 1: BLEU scores for Japanese-to-English  translation 3 . The parentheses indicate vocabulary  size of the encoder.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9993739724159241}, {"text": "Japanese-to-English  translation", "start_pos": 26, "end_pos": 58, "type": "TASK", "confidence": 0.6161064356565475}]}, {"text": " Table 2: BLEU scores of the COMMON and DIFF  outputs.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9993508458137512}]}, {"text": " Table 3: An example of Japanese-to-English translation on a source sentence from COMMON.", "labels": [], "entities": []}, {"text": " Table 5: F 0.5 of COMMON and DIFF outputs.", "labels": [], "entities": [{"text": "F 0.5", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9768309891223907}]}, {"text": " Table 7: Number of words included only in either  the baseline or PPMI vocabulary.", "labels": [], "entities": []}, {"text": " Table 8: Number of the POS of words only in- cluded in the baseline or PPMI.", "labels": [], "entities": [{"text": "Number", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9584373831748962}]}]}