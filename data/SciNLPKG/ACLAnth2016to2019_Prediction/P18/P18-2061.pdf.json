{"title": [{"text": "Bleaching Text: Abstract Features for Cross-lingual Gender Prediction", "labels": [], "entities": [{"text": "Cross-lingual Gender Prediction", "start_pos": 38, "end_pos": 69, "type": "TASK", "confidence": 0.7539276083310446}]}], "abstractContent": [{"text": "Gender prediction has typically focused on lexical and social network features, yielding good performance, but making systems highly language-, topic-, and platform-dependent.", "labels": [], "entities": [{"text": "Gender prediction", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8211527168750763}]}, {"text": "Cross-lingual embeddings circumvent some of these limitations, but capture gender-specific style less.", "labels": [], "entities": []}, {"text": "We propose an alternative: bleaching text, i.e., transforming lexical strings into more abstract features.", "labels": [], "entities": []}, {"text": "This study provides evidence that such features allow for better transfer across languages.", "labels": [], "entities": []}, {"text": "Moreover, we present a first study on the ability of humans to perform cross-lingual gender prediction.", "labels": [], "entities": [{"text": "cross-lingual gender prediction", "start_pos": 71, "end_pos": 102, "type": "TASK", "confidence": 0.7667134602864584}]}, {"text": "We find that human predictive power proves similar to that of our bleached models, and both perform better than lexical models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Author profiling is the task of discovering latent user attributes disclosed through text, such as gender, age, personality, income, location and occupation (.", "labels": [], "entities": [{"text": "Author profiling", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.6762450933456421}]}, {"text": "It is of interest to several applications including personalized machine translation, forensics, and marketing (.", "labels": [], "entities": [{"text": "personalized machine translation", "start_pos": 52, "end_pos": 84, "type": "TASK", "confidence": 0.6604536175727844}]}, {"text": "Early approaches to gender prediction (, e.g.) are inspired by pioneering work on authorship attribution.", "labels": [], "entities": [{"text": "gender prediction", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.8393018543720245}, {"text": "authorship attribution", "start_pos": 82, "end_pos": 104, "type": "TASK", "confidence": 0.812258780002594}]}, {"text": "Such stylometric models typically rely on carefully handselected sets of content-independent features to capture style beyond topic.", "labels": [], "entities": []}, {"text": "Recently, open vocabulary approaches (, where the entire linguistic production of an author is used, yielded substantial performance gains in online user-attribute prediction.", "labels": [], "entities": [{"text": "user-attribute prediction", "start_pos": 149, "end_pos": 174, "type": "TASK", "confidence": 0.6628618538379669}]}, {"text": "Indeed, the best performing gender prediction models exploit chiefly lexical information (.", "labels": [], "entities": [{"text": "gender prediction", "start_pos": 28, "end_pos": 45, "type": "TASK", "confidence": 0.7212090194225311}]}, {"text": "Relying heavily on the lexicon though has its limitations, as it results in models with limited portability.", "labels": [], "entities": []}, {"text": "Moreover, performance might be overly optimistic due to topic bias).", "labels": [], "entities": []}, {"text": "Recent work on cross-lingual author profiling has proposed the use of solely language-independent features), e.g., specific textual elements (percentage of emojis, URLs, etc) and users' meta-data/network (number of followers, etc), but this information is not always available.", "labels": [], "entities": [{"text": "cross-lingual author profiling", "start_pos": 15, "end_pos": 45, "type": "TASK", "confidence": 0.6584068238735199}]}, {"text": "We propose a novel approach where the actual text is still used, but bleached out and transformed into more abstract, and potentially better transferable features.", "labels": [], "entities": []}, {"text": "One could view this as a method in between the open vocabulary strategy and the stylometric approach.", "labels": [], "entities": []}, {"text": "It has the advantage of fading out content in favor of more shallow patterns still based on the original text, without introducing additional processing such as part-of-speech tagging.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 161, "end_pos": 183, "type": "TASK", "confidence": 0.7227778136730194}]}, {"text": "In particular, we investigate to what extent gender prediction can rely on generic non-lexical features (RQ1), and how predictive such models are when transferred to other languages (RQ2).", "labels": [], "entities": [{"text": "gender prediction", "start_pos": 45, "end_pos": 62, "type": "TASK", "confidence": 0.7921012043952942}]}, {"text": "We also glean insights from human judgments, and investigate how well people can perform cross-lingual gender prediction (RQ3).", "labels": [], "entities": [{"text": "cross-lingual gender prediction (RQ3)", "start_pos": 89, "end_pos": 126, "type": "TASK", "confidence": 0.7015359997749329}]}, {"text": "We focus on gender prediction for Twitter, motivated by data availability.", "labels": [], "entities": [{"text": "gender prediction", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.7118973135948181}]}, {"text": "Contributions In this work i) we are the first to study cross-lingual gender prediction without relying on users' meta-data; ii) we propose a novel simple abstract feature representation which is surprisingly effective; and iii) we gauge human ability to perform cross-lingual gender detection, an angle of analysis which has not been studied thus far.", "labels": [], "entities": [{"text": "cross-lingual gender prediction", "start_pos": 56, "end_pos": 87, "type": "TASK", "confidence": 0.7416362166404724}, {"text": "cross-lingual gender detection", "start_pos": 263, "end_pos": 293, "type": "TASK", "confidence": 0.7305797338485718}]}], "datasetContent": [{"text": "In order to test whether abstract features are effective and transfer across languages, we setup experiments for gender prediction comparing lexicalized and bleached models for both in-and cross-language experiments.", "labels": [], "entities": [{"text": "gender prediction", "start_pos": 113, "end_pos": 130, "type": "TASK", "confidence": 0.6979270428419113}]}, {"text": "We compare them to a model using multilingual embeddings.", "labels": [], "entities": []}, {"text": "Finally, we elicit human judgments both within language and across language.", "labels": [], "entities": []}, {"text": "The latter is to check whether a person with no prior knowledge of (the lexicon of) a given language can predict the gender of a user, and how that compares to an in-language setup and the machine.", "labels": [], "entities": []}, {"text": "If humans can predict gender cross-lingually, they are likely to rely on aspects beyond lexical information.", "labels": [], "entities": []}, {"text": "Data We obtain data from the TWISTY corpus ( ), a multi-lingual collection of Twitter users, for the languages with 500+ users, namely Dutch, French, Portuguese, and Spanish.", "labels": [], "entities": [{"text": "TWISTY corpus", "start_pos": 29, "end_pos": 42, "type": "DATASET", "confidence": 0.7775684893131256}]}, {"text": "We complement them with English, using data from a predecessor of TWISTY (.", "labels": [], "entities": [{"text": "TWISTY", "start_pos": 66, "end_pos": 72, "type": "DATASET", "confidence": 0.8360801935195923}]}, {"text": "All datasets contain manually annotated gender information.", "labels": [], "entities": []}, {"text": "To simplify interpretation for the cross-language experiments, we balance gender in all datasets by downsampling to the minority class.", "labels": [], "entities": []}, {"text": "The datasets' final sizes are given in.", "labels": [], "entities": []}, {"text": "We use 200 tweets per user, as done by previous work ).", "labels": [], "entities": []}, {"text": "We leave the data untokenized to exclude any languagedependent processing, because original tokenization could preserve some signal.", "labels": [], "entities": []}, {"text": "Apart from mapping usernames to 'USER' and urls to 'URL' we do not perform any further data pre-processing.", "labels": [], "entities": []}, {"text": "We experimented with three different conditions, one within language and two across language.", "labels": [], "entities": []}, {"text": "For the latter, we setup an experiment where native speakers of Dutch were presented with tweets written in Portuguese and were asked to guess the poster's gender.", "labels": [], "entities": []}, {"text": "In the other experiment, we asked speakers of French to identify the gender of the writer when reading Dutch tweets.", "labels": [], "entities": []}, {"text": "In both cases, the participants declared to have no prior knowledge of the target language.", "labels": [], "entities": []}, {"text": "For the in-language experiment, we asked Dutch speakers to identify the gender of a user writing Dutch tweets.", "labels": [], "entities": []}, {"text": "The  Dutch speakers who participated in the two experiments are distinct individuals.", "labels": [], "entities": []}, {"text": "Participants were informed of the experiment's goal.", "labels": [], "entities": []}, {"text": "Their identity is anonymized in the data.", "labels": [], "entities": []}, {"text": "We selected a random sample of 200 users from the Dutch and Portuguese data, preserving a 50/50 gender distribution.", "labels": [], "entities": [{"text": "Dutch and Portuguese data", "start_pos": 50, "end_pos": 75, "type": "DATASET", "confidence": 0.689955472946167}]}, {"text": "Each user was represented by twenty tweets.", "labels": [], "entities": []}, {"text": "The answer key (F/M) order was randomized.", "labels": [], "entities": [{"text": "answer key (F/M) order", "start_pos": 4, "end_pos": 26, "type": "METRIC", "confidence": 0.7851680815219879}]}, {"text": "For each of the three experiments we had six judges, balanced for gender, and obtained three annotations per target user.", "labels": [], "entities": []}, {"text": "Results and Analysis Inter-annotator agreement for the tasks was measured via Fleiss kappa (n = 3, N = 200), and was higher for the in-language experiment (K = 0.40) than for the cross-language tasks (NL \u2192PT: K = 0.25; FR \u2192NL: K = 0.28).", "labels": [], "entities": [{"text": "agreement", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.6885310411453247}, {"text": "Fleiss", "start_pos": 78, "end_pos": 84, "type": "METRIC", "confidence": 0.9138883948326111}]}, {"text": "shows accuracy against the gold labels, comparing humans (average accuracy over three annotators) to lexical and bleached models on the exact same subset of 200 users.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 6, "end_pos": 14, "type": "METRIC", "confidence": 0.9993614554405212}, {"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.8855798244476318}]}, {"text": "Systems were tested under two different conditions regarding the number of tweets per user for the target language: machine and human saw the exact same twenty tweets, or the full set of tweets per user, as done during training (Section 3.1).", "labels": [], "entities": []}, {"text": "First of all, our results indicate that in-language performance of humans is 70.5%, which is quite inline with the findings of, who report an accuracy of 75% on English.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 142, "end_pos": 150, "type": "METRIC", "confidence": 0.99886155128479}]}, {"text": "Within language, lexicalized models are superior to humans if exposed to enough information (200 tweets setup).", "labels": [], "entities": []}, {"text": "One explanation for this might lie in an observation by, according to which people tend to rely too much on stereotypical lexical indicators when assigning gender to the poster of a tweet, while machines model less evident patterns.", "labels": [], "entities": []}, {"text": "Lexicalized models are also superior to the bleached ones, as already seen on the full datasets.", "labels": [], "entities": []}, {"text": "We can also observe that the amount of information available to represent a user influences system's performance.", "labels": [], "entities": []}, {"text": "Training on 200 tweets per user, but testing on 20 tweets only, decreases performance by 12 percentage points.", "labels": [], "entities": []}, {"text": "This is likely due to the fact that inputs are sparser, especially since the bleached model is trained on 5-grams.", "labels": [], "entities": []}, {"text": "The bleached model, when given 200 tweets per user, yields a performance that is slightly higher than human accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.9798330068588257}]}, {"text": "In the cross-language setting, the picture is very different.", "labels": [], "entities": []}, {"text": "Here, human performance is superior to the lexicalized models, independently of the amount of tweets per user at testing time.", "labels": [], "entities": []}, {"text": "This seems to indicate that if humans cannot rely on the lexicon, they might be exploiting some other signal when guessing the gender of a user who tweets in a language unknown to them.", "labels": [], "entities": []}, {"text": "Interestingly, the bleached models, which rely on non-lexical features, not only outperform the lexicalized ones in the cross-language experiments, but also neatly match the human scores.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Abstract features example transformation.", "labels": [], "entities": [{"text": "Abstract", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.8756096363067627}]}, {"text": " Table 2: Number of users per language and results for gender prediction (accuracy). IN-LANGUAGE:  10-fold cross-validation. CROSS-LANGUAGE: Testing on all test data in two setups: averages over single  source models (AVG) or training a single model on all languages except the target (ALL). Comparison of  lexical n-gram models (LEX), bleached models (ABS) and multilingual embeddings model (EMBEDS).", "labels": [], "entities": [{"text": "gender prediction", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.6694101691246033}, {"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9934492707252502}, {"text": "IN-LANGUAGE", "start_pos": 85, "end_pos": 96, "type": "METRIC", "confidence": 0.9796022176742554}, {"text": "CROSS-LANGUAGE", "start_pos": 125, "end_pos": 139, "type": "METRIC", "confidence": 0.8872272968292236}]}, {"text": " Table 3: Pair-wise results for lexicalized models.", "labels": [], "entities": []}, {"text": " Table 4: Ten most predictive features of the ABS  model across all five languages. Features are  ranked by how often they were in the top-ranked  features for each language. Those prefixed with 0  (line 9) are length features. The prefix is used to  avoid clashes with the frequency features.", "labels": [], "entities": []}, {"text": " Table 5: Accuracy human versus machine.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.989676296710968}]}]}