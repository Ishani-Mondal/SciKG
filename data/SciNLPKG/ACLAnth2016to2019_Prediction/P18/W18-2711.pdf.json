{"title": [{"text": "Multi-Source Neural Machine Translation with Missing Data", "labels": [], "entities": [{"text": "Multi-Source Neural Machine Translation", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.5861538872122765}]}], "abstractContent": [{"text": "Multi-source translation is an approach to exploit multiple inputs (e.g. in two different languages) to increase translation accuracy.", "labels": [], "entities": [{"text": "Multi-source translation", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.793766975402832}, {"text": "accuracy", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.7590237855911255}]}, {"text": "In this paper, we examine approaches for multi-source neural machine translation (NMT) using an incomplete multilingual corpus in which some translations are missing.", "labels": [], "entities": [{"text": "multi-source neural machine translation (NMT)", "start_pos": 41, "end_pos": 86, "type": "TASK", "confidence": 0.7483274851526532}]}, {"text": "In practice, many multilingual corpora are not complete due to the difficulty to provide translations in all of the relevant languages (for example, in TED talks, most English talks only have subtitles fora small portion of the languages that TED supports).", "labels": [], "entities": [{"text": "TED", "start_pos": 243, "end_pos": 246, "type": "DATASET", "confidence": 0.8923896551132202}]}, {"text": "Existing studies on multi-source translation did not explicitly handle such situations.", "labels": [], "entities": [{"text": "multi-source translation", "start_pos": 20, "end_pos": 44, "type": "TASK", "confidence": 0.7115525901317596}]}, {"text": "This study focuses on the use of incomplete multilingual corpora in multi-encoder NMT and mixture of NMT experts and examines a very simple implementation where missing source translations are replaced by a special symbol <NULL>.", "labels": [], "entities": []}, {"text": "These methods allow us to use incomplete corpora both at training time and test time.", "labels": [], "entities": []}, {"text": "In experiments with real incomplete multilingual corpora of TED Talks, the multi-source NMT with the <NULL> tokens achieved higher translation accuracies measured by BLEU than those by any one-to-one NMT systems.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 166, "end_pos": 170, "type": "METRIC", "confidence": 0.9983002543449402}]}], "introductionContent": [{"text": "In general, machine translation systems translate from one source language to a target language.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.7722146213054657}]}, {"text": "For example, we may translate a document or speech that was written in English to anew language such as French.", "labels": [], "entities": []}, {"text": "However, in many real translation scenarios, there are cases where there are multiple rated translations in a number of languages, and we'd like to generate translations in the remaining languages for which we do not yet have translations.", "labels": [], "entities": []}, {"text": "In this work, we focus on this sort of multilingual scenario using multi-source translation.", "labels": [], "entities": []}, {"text": "Multi-source translation takes in multiple inputs, and references all of them when deciding which sentence to output.", "labels": [], "entities": [{"text": "Multi-source translation", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7296640276908875}]}, {"text": "Specifically, in the context of neural machine translation (NMT), there are several methods proposed to do so.", "labels": [], "entities": [{"text": "neural machine translation (NMT)", "start_pos": 32, "end_pos": 64, "type": "TASK", "confidence": 0.836583822965622}]}, {"text": "For example, propose a method where multiple sentences are each encoded separately, then all referenced during the decoding process (the \"multi-encoder\" method).", "labels": [], "entities": []}, {"text": "In addition, propose a method where NMT systems over multiple inputs are ensembled together to make a final prediction (the \"mixture-of-NMT-experts\" method).", "labels": [], "entities": []}, {"text": "However, this paradigm assumes that we have data in all of the languages that go into our multisource system.", "labels": [], "entities": []}, {"text": "For example, if we decide that English and Spanish are our input languages and that we would like to translate into French, we are limited to training and testing only on data that contains all of the source languages.", "labels": [], "entities": []}, {"text": "However, it is unusual that translations in all of these languages are provided-there will be many sentences where we have only one of the sources.", "labels": [], "entities": []}, {"text": "In this work, we consider methods for multi-source NMT with missing data, such situations using an incomplete multilingual corpus in which some translations are missing, as shown in.", "labels": [], "entities": []}, {"text": "This incomplete multilingual scenario is useful in practice, such as when creating translations for incomplete multilingual corpora such as subtitles for TED Talks.", "labels": [], "entities": []}, {"text": "In this paper, we examine a simple implementation of multi-source NMT using such an incomplete multilingual corpus that uses a special symbol <NULL> to represent the missing sentences.", "labels": [], "entities": []}, {"text": "This can be used with any existing multi-source NMT implementations without no special modifications.", "labels": [], "entities": []}, {"text": "Experimental results with real incomplete multilingual corpora of TED Talks show that it is effective in allowing for multi-source NMT in situations where full multilingual corpora are not available, resulting in BLEU score gains of up to 2 points compared to standard bi-lingual NMT.) and mixture of NMT experts (.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 213, "end_pos": 223, "type": "METRIC", "confidence": 0.972547858953476}]}, {"text": "We first review them in this section.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted two experiments with different incomplete multilingual corpora.", "labels": [], "entities": []}, {"text": "One is an experiment with a pseudo-incomplete multilingual corpus, the other is an experiment with an actual incomplete multilingual corpus.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results in BLEU for one-to-one and multi-source ({Es, Fr, Ar}-to-En) translation on UN6WAY  data (parentheses are BLEU gains against the best one-to-one results).  *  indicates the difference from  mixture of NMT experts is statistically significant (p < 0.01).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 21, "end_pos": 25, "type": "METRIC", "confidence": 0.9959878325462341}, {"text": "UN6WAY  data", "start_pos": 94, "end_pos": 106, "type": "DATASET", "confidence": 0.9201240837574005}, {"text": "BLEU", "start_pos": 124, "end_pos": 128, "type": "METRIC", "confidence": 0.9978148937225342}]}, {"text": " Table 3: Data statistics in the tasks on TED data  (in the number of sentences). Note that the number  of target sentences is equal to that of English for  each task.", "labels": [], "entities": [{"text": "TED data", "start_pos": 42, "end_pos": 50, "type": "DATASET", "confidence": 0.8924803137779236}]}, {"text": " Table 4: The percentage of data without missing  sentences on TED data.", "labels": [], "entities": [{"text": "TED data", "start_pos": 63, "end_pos": 71, "type": "DATASET", "confidence": 0.9065290987491608}]}, {"text": " Table 5: Results in BLEU (and BLEU gains) by one-to-one and multi-source NMT on TED data. Note  that the target language in each row differs so the results in different rows cannot be compared directly.  All the differences are statistically significant (p < 0.01).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 21, "end_pos": 25, "type": "METRIC", "confidence": 0.9971101880073547}, {"text": "BLEU", "start_pos": 31, "end_pos": 35, "type": "METRIC", "confidence": 0.994976282119751}, {"text": "TED data", "start_pos": 81, "end_pos": 89, "type": "DATASET", "confidence": 0.8083724081516266}]}, {"text": " Table 6: Translation examples in {English, French, Brazilian Portuguese}-to-Spanish translation.", "labels": [], "entities": []}]}