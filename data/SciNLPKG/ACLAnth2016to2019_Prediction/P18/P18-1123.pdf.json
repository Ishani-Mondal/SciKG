{"title": [{"text": "Exemplar Encoder-Decoder for Neural Conversation Generation", "labels": [], "entities": [{"text": "Neural Conversation", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.7628581821918488}]}], "abstractContent": [{"text": "In this paper we present the Exemplar Encoder-Decoder network (EED), a novel conversation model that learns to utilize similar examples from training data to generate responses.", "labels": [], "entities": []}, {"text": "Similar conversation examples (context-response pairs) from training data are retrieved using a traditional TF-IDF based retrieval model.", "labels": [], "entities": []}, {"text": "The retrieved responses are used to create exemplar vectors that are used by the decoder to generate the response.", "labels": [], "entities": []}, {"text": "The contribution of each retrieved response is weighed by the similarity of corresponding context with the input context.", "labels": [], "entities": []}, {"text": "We present detailed experiments on two large data sets and find that our method out-performs state of the art sequence to sequence generative models on several recently proposed evaluation metrics.", "labels": [], "entities": []}, {"text": "We also observe that the responses generated by the proposed EED model are more informative and diverse compared to existing state-of-the-art method.", "labels": [], "entities": []}], "introductionContent": [{"text": "With the availability of large datasets and the recent progress made by neural methods, variants of sequence to sequence learning (seq2seq) () architectures have been successfully applied for building conversational systems).", "labels": [], "entities": []}, {"text": "However, despite these methods being the stateof-the art frameworks for conversation generation, they suffer from problems such as lack of diversity in responses and generation of short, repetitive and uninteresting responses (.", "labels": [], "entities": [{"text": "conversation generation", "start_pos": 72, "end_pos": 95, "type": "TASK", "confidence": 0.814475804567337}]}, {"text": "A large body of recent literature has focused on overcoming such challenges (.", "labels": [], "entities": []}, {"text": "In part, such problems arise as all information required to generate responses needs to be captured as part of the model parameters learnt from the training data.", "labels": [], "entities": []}, {"text": "These model parameters alone may not be sufficient for generating natural conversations.", "labels": [], "entities": []}, {"text": "Therefore, despite providing enormous amount of data, neural generative systems have been found to be ineffective for use in real world applications (.", "labels": [], "entities": []}, {"text": "In this paper, we focus our attention on closed domain conversations.", "labels": [], "entities": []}, {"text": "A characteristic feature of such conversations is that over a period of time, some conversation contexts 1 are likely to have occurred previously ().", "labels": [], "entities": []}, {"text": "For instance, shows some contexts from the Ubuntu dialog corpus.", "labels": [], "entities": [{"text": "Ubuntu dialog corpus", "start_pos": 43, "end_pos": 63, "type": "DATASET", "confidence": 0.867412269115448}]}, {"text": "Each row presents an input dialog context with its corresponding gold response followed by a similar context and response seen in training data -as can be seen, contexts for \"installing dms\", \"sharing files\", \"blocking ufw ports\" have all occurred in training data.", "labels": [], "entities": []}, {"text": "We hypothesize that being able to refer to training responses for previously seen similar contexts could be a helpful signal to use while generating responses.", "labels": [], "entities": []}, {"text": "In order to exploit this aspect of closed domain conversations we build our neural encoderdecoder architecture called the Exemplar Encoder Decoder (EED), that learns to generate a response fora given context by exploiting similar contexts from training conversations.", "labels": [], "entities": []}, {"text": "Thus, instead of having the seq2seq model learn patterns of language only from aligned parallel corpora, we assist the model by providing it closely related (similar) samples from the training data that it can refer to while generating text.", "labels": [], "entities": []}, {"text": "Specifically, given a context c, we retrieve a set of context-response pairs (c (k) , r (k) ), 1 \u2264 k \u2264 K using an inverted index of training data.", "labels": [], "entities": []}, {"text": "We create an exemplar vector e (k) by encoding the response r (k) (also referred to as exemplar response) along with an encoded representation of the current context c.", "labels": [], "entities": []}, {"text": "We then learn the importance of each exemplar vector e (k) based on the likelihood of it being able to generate the ground truth response.", "labels": [], "entities": []}, {"text": "We believe that e (k) may contain information that is helpful in generating the response.", "labels": [], "entities": []}, {"text": "highlights the words in exemplar responses that appear in the ground truth response as well.", "labels": [], "entities": []}, {"text": "Contributions: We present a novel Exemplar Encoder-Decoder (EED) architecture that makes use of similar conversations, fetched from an index of training data.", "labels": [], "entities": []}, {"text": "The retrieved contextresponse pairs are used to create exemplar vectors which are used by the decoder in the EED model, to learn the importance of training context-response pairs, while generating responses.", "labels": [], "entities": []}, {"text": "We present detailed experiments on the publicly benchmarked Ubuntu dialog corpus data set ( as well a large collection of more than 127,000 technical support conversations.", "labels": [], "entities": [{"text": "Ubuntu dialog corpus data set", "start_pos": 60, "end_pos": 89, "type": "DATASET", "confidence": 0.8847520232200623}]}, {"text": "We compare the performance of the EED model with the existing state of the art generative models such as HRED ( ) and VHRED ().", "labels": [], "entities": [{"text": "HRED", "start_pos": 105, "end_pos": 109, "type": "METRIC", "confidence": 0.8999978303909302}, {"text": "VHRED", "start_pos": 118, "end_pos": 123, "type": "DATASET", "confidence": 0.5001953840255737}]}, {"text": "We find that our model out-performs these models on a wide variety of metrics such as the recently proposed Activity Entity metrics () as well as Embedding-based metrics ().", "labels": [], "entities": []}, {"text": "In addition, we present qualitative insights into our results and we find that exemplar based responses are more informative and diverse.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 briefly describes the recent works in neural dialogue generation The details of the proposed EED model for dialogue generation are described in detail in Section 3.", "labels": [], "entities": [{"text": "neural dialogue generation", "start_pos": 48, "end_pos": 74, "type": "TASK", "confidence": 0.675040046374003}, {"text": "dialogue generation", "start_pos": 117, "end_pos": 136, "type": "TASK", "confidence": 0.8198321163654327}]}, {"text": "In Section 4, we describe the datasets as well as the details of the models used during training.", "labels": [], "entities": []}, {"text": "We present quantitative and qualitative results of EED model in Section 5.", "labels": [], "entities": [{"text": "EED", "start_pos": 51, "end_pos": 54, "type": "DATASET", "confidence": 0.7107800245285034}]}], "datasetContent": [{"text": "We also conduct our experiments on a large technical support dataset with more than 127K conversations.", "labels": [], "entities": []}, {"text": "We will refer to this dataset as Tech Support dataset in the rest of the paper.", "labels": [], "entities": [{"text": "Tech Support dataset", "start_pos": 33, "end_pos": 53, "type": "DATASET", "confidence": 0.8818435867627462}]}, {"text": "Tech Support dataset contains conversations pertaining to an employee seeking assistance from an agent (technical support) -to resolve problems such as password reset, software installation/licensing, and wireless access.", "labels": [], "entities": [{"text": "Tech Support dataset", "start_pos": 0, "end_pos": 20, "type": "DATASET", "confidence": 0.8499503135681152}, {"text": "password reset", "start_pos": 152, "end_pos": 166, "type": "TASK", "confidence": 0.7677253186702728}]}, {"text": "In contrast to Ubuntu dataset, this dataset has clearly two distinct users -employee and agent.", "labels": [], "entities": [{"text": "Ubuntu dataset", "start_pos": 15, "end_pos": 29, "type": "DATASET", "confidence": 0.9194592535495758}]}, {"text": "In our experiments we model the agent responses only.", "labels": [], "entities": []}, {"text": "For each conversation in the tech support data, we sample context and response pairs to create a dataset similar to the Ubuntu dataset format.", "labels": [], "entities": [{"text": "Ubuntu dataset format", "start_pos": 120, "end_pos": 141, "type": "DATASET", "confidence": 0.8997000853220621}]}, {"text": "Note that multiple context-response pairs can be generated from a single conversation.", "labels": [], "entities": []}, {"text": "For each conversation, we sample 25% of the possible contextresponse pairs.", "labels": [], "entities": []}, {"text": "We create validation pairs by selecting 5000 conversations randomly and sampling context response pairs).", "labels": [], "entities": []}, {"text": "Similarly, we create test pairs from a different subset of 5000 conversations.", "labels": [], "entities": []}, {"text": "The remaining conversations are used to create training context-response pairs.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Sample input contexts and corresponding gold responses from Ubuntu validation dataset along  with similar contexts seen in training data and their corresponding responses. We refer to training data  as training data for the Ubuntu corpus. The highlighted words are common between the gold response  and the exemplar response.", "labels": [], "entities": [{"text": "Ubuntu validation dataset", "start_pos": 70, "end_pos": 95, "type": "DATASET", "confidence": 0.8920726776123047}, {"text": "Ubuntu corpus", "start_pos": 234, "end_pos": 247, "type": "DATASET", "confidence": 0.9594743847846985}]}, {"text": " Table 4: Activity & Entity metrics for the Ubuntu corpus. LSTM*, HRED* & VHRED* as reported by  Serban et al. (2017a).", "labels": [], "entities": [{"text": "Ubuntu corpus", "start_pos": 44, "end_pos": 57, "type": "DATASET", "confidence": 0.908269464969635}, {"text": "LSTM", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.9292070269584656}, {"text": "HRED", "start_pos": 66, "end_pos": 70, "type": "METRIC", "confidence": 0.9831384420394897}, {"text": "VHRED", "start_pos": 74, "end_pos": 79, "type": "METRIC", "confidence": 0.911808967590332}]}, {"text": " Table 5: Embedding Metrics (Lowe et al., 2015) for Ubuntu and Technical Support Corpus.", "labels": [], "entities": []}, {"text": " Table 6: The number of unique tokens, token-pairs and token-triplets for Ubuntu and Technical Support  Corpus.", "labels": [], "entities": [{"text": "Technical Support  Corpus", "start_pos": 85, "end_pos": 110, "type": "DATASET", "confidence": 0.6047484874725342}]}, {"text": " Table 7: Contexts, exemplar responses and responses generated by HRED, VHRED and the proposed  EED model. We use the published responses for HRED and VHRED. GT indicates the ground truth  response. The change of turn is indicated by \u2192. The highlighted words in bold are common between  the exemplar response and the response predicted by EED.", "labels": [], "entities": [{"text": "HRED", "start_pos": 66, "end_pos": 70, "type": "DATASET", "confidence": 0.8953933119773865}, {"text": "VHRED", "start_pos": 72, "end_pos": 77, "type": "DATASET", "confidence": 0.938230037689209}, {"text": "VHRED", "start_pos": 151, "end_pos": 156, "type": "DATASET", "confidence": 0.929731547832489}, {"text": "EED", "start_pos": 339, "end_pos": 342, "type": "DATASET", "confidence": 0.9277569055557251}]}]}