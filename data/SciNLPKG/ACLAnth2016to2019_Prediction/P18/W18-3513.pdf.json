{"title": [{"text": "Political discourse classification in social networks using context sensitive convolutional neural networks", "labels": [], "entities": [{"text": "Political discourse classification", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7500276366869608}]}], "abstractContent": [{"text": "In this study we propose anew approach to analyse the political discourse in on-line social networks such as Twitter.", "labels": [], "entities": []}, {"text": "To do so, we have built a discourse classi-fier using Convolutional Neural Networks.", "labels": [], "entities": []}, {"text": "Our model has been trained using election manifestos annotated manually by political scientists following the Regional Manifestos Project (RMP) methodology.", "labels": [], "entities": []}, {"text": "In total, it has been trained with more than 88,000 sentences extracted from more that 100 annotated manifestos.", "labels": [], "entities": []}, {"text": "Our approach takes into account the context of the phrase in order to classify it, like what was previously said and the political affiliation of the transmitter.", "labels": [], "entities": []}, {"text": "To improve the classification results we have used a simplified political message taxonomy developed within the Electronic Regional Manifestos Project (E-RMP).", "labels": [], "entities": []}, {"text": "Using this tax-onomy, we have validated our approach analysing the Twitter activity of the main Spanish political parties during 2015 and 2016 Spanish general election and providing a study of their discourse.", "labels": [], "entities": []}], "introductionContent": [{"text": "OSN-s area commonplace element inmost citizens daily lives.", "labels": [], "entities": [{"text": "OSN-s", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8188860416412354}]}, {"text": "A significant amount of the social engagement between citizens takes place in the OSN-s.", "labels": [], "entities": []}, {"text": "The same trend is taking place in the political sphere.", "labels": [], "entities": []}, {"text": "The on-line presence of political parties and public servants has increased dramatically in the last decades.", "labels": [], "entities": []}, {"text": "Political campaigns include an on-line component and politicians use the OSN-s as another medium for their political discourse.", "labels": [], "entities": []}, {"text": "As a result, the content of the OSN-s can be used to analyse different aspects of the political activity.", "labels": [], "entities": []}, {"text": "OSN activity can serve as an input to study the possible results of political campaigns)(Ortiz-\u00b4, to generate profiles) of the politicians according to their OSN usage or to analyse their reactions to certain events or topics.", "labels": [], "entities": []}, {"text": "To take advantage of the political data available in the OSN-s, we present in this paper a deep neural network architecture for political discourse analysis.", "labels": [], "entities": [{"text": "political discourse analysis", "start_pos": 128, "end_pos": 156, "type": "TASK", "confidence": 0.6952541271845499}]}, {"text": "Our architecture takes advantage of the context of the political discourse (what was previously said and who was the transmitter) to improve the classification process.", "labels": [], "entities": [{"text": "classification process", "start_pos": 145, "end_pos": 167, "type": "TASK", "confidence": 0.8797211349010468}]}, {"text": "To do so, we have used the annotated political manifestos database created by the Regional Manifestos Project (RMP) (.", "labels": [], "entities": []}, {"text": "To improve the classification we use the simplified taxonomy that have been developed within the Electronic Regional Manifestos Project (E-RMP), which adapts the initial RMP taxonomy to the political discourse analysis in OSN-s.", "labels": [], "entities": []}, {"text": "Using this new taxonomy and the created deep neural network architecture we have analysed the discourse during the electoral campaigns of the 2015 and 2016 Spanish general elections.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we analyse the previous work done in the area of automatic political discourse analysis in social networks.", "labels": [], "entities": [{"text": "automatic political discourse analysis", "start_pos": 62, "end_pos": 100, "type": "TASK", "confidence": 0.6588324308395386}]}, {"text": "In Section 3 we describe the classification taxonomy that we have used for the analysis of the political discourse.", "labels": [], "entities": []}, {"text": "In Section 4 we present our neural network architecture for political discourse classification.", "labels": [], "entities": [{"text": "political discourse classification", "start_pos": 60, "end_pos": 94, "type": "TASK", "confidence": 0.6859801908334097}]}, {"text": "In Section 5 we discuss the evaluation of the system.", "labels": [], "entities": []}, {"text": "In Section 6 we offer areal use case of the presented system by analysing the political activity on Twitter during the 2015 and 2016 general elections in Spain.", "labels": [], "entities": []}, {"text": "Finally, section 7 draws some conclusions and proposes fur-ther work.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experimentation performed in this research work has been done with the dataset provided by the Regional Manifestos Project, which has a high annotators' intercoder reliability (.", "labels": [], "entities": [{"text": "Regional Manifestos Project", "start_pos": 99, "end_pos": 126, "type": "DATASET", "confidence": 0.8296801249186198}]}, {"text": "This dataset has almost two decades of political manifestos in Spain and therefore covers a wider span of political issues with a high language variation.", "labels": [], "entities": []}, {"text": "The dataset consists in 88,511 annotated phrases and the distribution of codes is highly imbalanced: External Relations (0.9%), Welfare (35.91%), Economy (47.83%), Democratic Regeneration (4.38%), Immigration (1.77%), Territorial debate (7.81%), Boasting (1.3%).", "labels": [], "entities": [{"text": "Territorial debate", "start_pos": 218, "end_pos": 236, "type": "TASK", "confidence": 0.7941301465034485}, {"text": "Boasting", "start_pos": 246, "end_pos": 254, "type": "TASK", "confidence": 0.7379969358444214}]}, {"text": "Almost 85% of the dataset belongs to Welfare and Economy categories, leaving around the 15% of the dataset for the remaining 5 categories.", "labels": [], "entities": []}, {"text": "In order to evaluate our approach, we have divided our dataset in 2 different subsets: training and validation sets (85%), and test set (15%).", "labels": [], "entities": []}, {"text": "The training and validation set has been used in order to create models with 5-fold cross validation to: Results with political manifestos.", "labels": [], "entities": []}, {"text": "later test their performance with the same test set.", "labels": [], "entities": []}, {"text": "The reason why we have split the dataset in 2 subsets and then apply cross-validation to one of them is because we have used early stopping) in order to stop our model's training when it started to over-fit.", "labels": [], "entities": []}, {"text": "Early stopping compares the training accuracy with the validation accuracy and after some epochs without any improvements in the validation accuracy it stops the training.", "labels": [], "entities": [{"text": "Early stopping", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.6558281034231186}, {"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9325419068336487}, {"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.5042480826377869}]}, {"text": "Nevertheless, the model may have over-fitted with respect to the validation set, therefore, a third set (test set) is needed in order to measure the real performance of the model.", "labels": [], "entities": []}, {"text": "Furthermore, since we work with an imbalanced dataset, we have applied stratification in order to preserve the same percentage of samples for each class.", "labels": [], "entities": []}, {"text": "Using this approach we are able to evaluate how each class is classified since it ensures that in each of the subsets there will be a representation of each class.", "labels": [], "entities": []}, {"text": "Taking into account both the high number of classes and the imbalance between them, we have used the fmeasure as the evaluation metric.", "labels": [], "entities": []}, {"text": "Additionally we also provide the accuracy of each experiment.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9996854066848755}]}, {"text": "We have performed five different experiments to analyse the importance of the context (both the what was said previously and who is saying it) when classifying the political discourse: 1) Only the sentence to be classified with no additional context (E1); 2) the sentence plus the political party who belongs to (E2); 3) the sentence plus the previous sentence in an additional channel on the CNNs (E3); 4) the sentence plus the previous sentence in another CNNs structure, concatenating the features extracted by both networks (E4); and 5) the sentence, the political party who belongs to and the previous sentence in another CNN(E5).", "labels": [], "entities": []}, {"text": "As it is shown in table 2, the performance of the classifiers improves when adding the previous sentence and the political party as extra features.", "labels": [], "entities": []}, {"text": "On the one hand, the previous sentence provides a remarkable increase inaccuracy and F1 when it is inserted as an additional channel on the CNNs: Results with annotated tweets.", "labels": [], "entities": [{"text": "inaccuracy", "start_pos": 70, "end_pos": 80, "type": "METRIC", "confidence": 0.988235354423523}, {"text": "F1", "start_pos": 85, "end_pos": 87, "type": "METRIC", "confidence": 0.9993031024932861}]}, {"text": "(E3) and as as anew structure of CNNs (E4).", "labels": [], "entities": []}, {"text": "However, the improvement in E4 is greater than in E3.", "labels": [], "entities": [{"text": "E4", "start_pos": 28, "end_pos": 30, "type": "DATASET", "confidence": 0.6005709171295166}]}, {"text": "On the other hand, adding the political party who says the phrase as an extra feature (E2) improves the F1 in 0.45 points compared with the baseline (E1).", "labels": [], "entities": [{"text": "F1", "start_pos": 104, "end_pos": 106, "type": "METRIC", "confidence": 0.99949049949646}]}, {"text": "With regard to E5, since combining party and previous phrase does not improve the results of E4, we can affirm that those two features are not complementary.", "labels": [], "entities": []}, {"text": "Additionally, we have also tested the performance of our model on Twitter.", "labels": [], "entities": []}, {"text": "To do so, we have tested the aforementioned models in a dataset of 404 manually annotated tweets.", "labels": [], "entities": []}, {"text": "The category distribution of the test set is the following one: external relations (0.74%), welfare(33.66%), economy(30.69%), democratic regeneration(14.35%), immigration(0.49%), territorial debate(16.58%), boasting(3.46%).", "labels": [], "entities": [{"text": "territorial debate", "start_pos": 179, "end_pos": 197, "type": "TASK", "confidence": 0.8328195512294769}]}, {"text": "It is important to remark that these models have been trained using the annotated manifestos from the Regional Manifestos Project dataset, without using any tweet during the training process.", "labels": [], "entities": [{"text": "Regional Manifestos Project dataset", "start_pos": 102, "end_pos": 137, "type": "DATASET", "confidence": 0.895527184009552}]}, {"text": "We have performed four different experiments to analyse the performance of the previously explained architecture when classifying manually annotated tweets: 1) Only the tweet to be classified with no additional context and a Word2Vec model generated with generic Spanish text (T1); 2) the tweet to be classified with no additional context and a Word2Vec model generated with generic Spanish text and on-line trained with the tweets of our Spanish elections dataset (T2); 3) the tweet to be classified with the tweet it is answering to in another CNNs structure and a Word2Vec model generated with generic Spanish text (T3); 4) the tweet to be classified with the tweet it is answering to in another CNNs structure and a Word2Vec model generated with generic Spanish text and online trained with the tweets of our Spanish elections dataset (T4).", "labels": [], "entities": []}, {"text": "As it can be seen in table 3, retraining the Word2Vec model with tweets of our Spanish elections dataset significantly increases the accuracy and F-measure of the model.", "labels": [], "entities": [{"text": "Word2Vec model", "start_pos": 45, "end_pos": 59, "type": "DATASET", "confidence": 0.9491739273071289}, {"text": "Spanish elections dataset", "start_pos": 79, "end_pos": 104, "type": "DATASET", "confidence": 0.7764303882916769}, {"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.9996101260185242}, {"text": "F-measure", "start_pos": 146, "end_pos": 155, "type": "METRIC", "confidence": 0.9996817111968994}]}, {"text": "On the one hand, from T1 to T2 there is an improvement of 2.5 points inaccuracy and 6 points in F1.", "labels": [], "entities": [{"text": "F1", "start_pos": 96, "end_pos": 98, "type": "METRIC", "confidence": 0.9977405071258545}]}, {"text": "On the other hand, from T3 to T4 there is an improvement of 4 points inaccuracy and 3 points in F1.", "labels": [], "entities": [{"text": "F1", "start_pos": 96, "end_pos": 98, "type": "METRIC", "confidence": 0.9976233839988708}]}, {"text": "With regard to the use of the previous tweet in the thread, it improves the accuracy of the model in 1.5 points.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9996383190155029}]}], "tableCaptions": [{"text": " Table 2: Results with political manifestos.", "labels": [], "entities": []}, {"text": " Table 3: Results with annotated tweets.", "labels": [], "entities": []}]}