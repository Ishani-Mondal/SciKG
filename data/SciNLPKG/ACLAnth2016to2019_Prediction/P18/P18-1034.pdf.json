{"title": [{"text": "Semantic Parsing with Syntax-and Table-Aware SQL Generation", "labels": [], "entities": [{"text": "Semantic Parsing", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8055643737316132}]}], "abstractContent": [{"text": "We present a generative model to map natural language questions into SQL queries.", "labels": [], "entities": []}, {"text": "Existing neural network based approaches typically generate a SQL query word-byword , however, a large portion of the generated results is incorrect or not exe-cutable due to the mismatch between question words and table contents.", "labels": [], "entities": []}, {"text": "Our approach addresses this problem by considering the structure of table and the syntax of SQL language.", "labels": [], "entities": []}, {"text": "The quality of the generated SQL query is significantly improved through (1) learning to repli-cate content from column names, cells or SQL keywords; and (2) improving the generation of WHERE clause by leverag-ing the column-cell relation.", "labels": [], "entities": []}, {"text": "Experiments are conducted on WikiSQL, a recently released dataset with the largest question-SQL pairs.", "labels": [], "entities": []}, {"text": "Our approach significantly improves the state-of-the-art execution accuracy from 69.0% to 74.4%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.9868713617324829}]}], "introductionContent": [{"text": "We focus on semantic parsing that maps natural language utterances to executable programs (.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 12, "end_pos": 28, "type": "TASK", "confidence": 0.7522695660591125}]}, {"text": "In this work, we regard SQL as the programming language, which could be executed on a table or a relational database to obtain an outcome.", "labels": [], "entities": []}, {"text": "Datasets are the main driver of progress for statistical approaches in semantic parsing.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 71, "end_pos": 87, "type": "TASK", "confidence": 0.8748294711112976}]}, {"text": "Recently, Zhong * Work is done during internship at Microsoft Research Asia.", "labels": [], "entities": [{"text": "Microsoft Research Asia", "start_pos": 52, "end_pos": 75, "type": "DATASET", "confidence": 0.9019759297370911}]}, {"text": "et al. release WikiSQL, the largest handannotated semantic parsing dataset which is an order of magnitude larger than other datasets in terms of both the number of logical forms and the number of tables.", "labels": [], "entities": [{"text": "handannotated semantic parsing", "start_pos": 36, "end_pos": 66, "type": "TASK", "confidence": 0.6506104866663615}]}, {"text": "Pointer network () based approach is developed, which generates a SQL query word-by-word through replicating from a word sequence consisting of question words, column names and SQL keywords.", "labels": [], "entities": []}, {"text": "However, a large portion of generated results is incorrect or not executable due to the mismatch between question words and column names (or cells).", "labels": [], "entities": []}, {"text": "This also reflects the real scenario where users do not always use exactly the same column name or cell content to express the question.", "labels": [], "entities": []}, {"text": "To address the aforementioned problem, we present a generative semantic parser that considers the structure of table and the syntax of SQL language.", "labels": [], "entities": [{"text": "generative semantic parser", "start_pos": 52, "end_pos": 78, "type": "TASK", "confidence": 0.8657110134760538}]}, {"text": "The approach is partly inspired by the success of structure/grammar driven neural network approaches in semantic parsing (.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 104, "end_pos": 120, "type": "TASK", "confidence": 0.7938719689846039}]}, {"text": "Our approach is based on pointer networks, which encodes the question into continuous vectors, and synthesizes the SQL query with three channels.", "labels": [], "entities": []}, {"text": "The model learns when to generate a column name, a cell or a SQL keyword.", "labels": [], "entities": []}, {"text": "We further incorporate columncell relation to mitigate the ill-formed outcomes.", "labels": [], "entities": []}, {"text": "We conduct experiments on WikiSQL.", "labels": [], "entities": []}, {"text": "Results show that our approach outperforms existing systems, improving state-of-the-art execution accuracy to 74.4% and logical form accuracy to 60.7%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9741297364234924}, {"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.9229570627212524}]}, {"text": "An extensive analysis reveals the advantages and limitations of our approach.", "labels": [], "entities": []}], "datasetContent": [{"text": "As shown in, we focus on sequence-to-SQL generation in this work.", "labels": [], "entities": [{"text": "sequence-to-SQL generation", "start_pos": 25, "end_pos": 51, "type": "TASK", "confidence": 0.7513885200023651}]}, {"text": "Formally, the task takes a question q and a tablet consisting of n col-Question\uff1a what 's the total number of songs originally performed by anna nalick ? Sequence-to-SQL Generation \u00ed \u00b5\u00ed\u00b1\u0086\u00ed \u00b5\u00ed\u00b0\u00b8\u00ed \u00b5\u00ed\u00b0\u00bf\u00ed \u00b5\u00ed\u00b0\u00b8\u00ed \u00b5\u00ed\u00b0 \u00b6\u00ed \u00b5\u00ed\u00b1\u0087 \u00ed \u00b5\u00ed\u00b0 \u00b6\u00ed \u00b5\u00ed\u00b1\u0082\u00ed \u00b5\u00ed\u00b1\u0088\u00ed \u00b5\u00ed\u00b1\u0081\u00ed \u00b5\u00ed\u00b1\u0087 \u00ed \u00b5\u00ed\u00b1\u0086\u00ed \u00b5\u00ed\u00b1\u009c\u00ed \u00b5\u00ed\u00b1\u009b\u00ed \u00b5\u00ed\u00b1\u0094 \u00ed \u00b5\u00ed\u00b1\u0090\u210e\u00ed \u00b5\u00ed\u00b1\u009c\u00ed \u00b5\u00ed\u00b1\u0096\u00ed \u00b5\u00ed\u00b1\u0090\u00ed \u00b5\u00ed\u00b1\u0092 \u00ed \u00b5\u00ed\u00b1\u008a\u00ed \u00b5\u00ed\u00b0\u00bb\u00ed \u00b5\u00ed\u00b0\u00b8\u00ed \u00b5\u00ed\u00b1 \u00ed \u00b5\u00ed\u00b0\u00b8\u00ed\u00b5\u00ed\u00b0\u00b8\u00ed \u00b5\u00ed\u00b1\u0082\u00ed \u00b5\u00ed\u00b1\u009f\u00ed \u00b5\u00ed\u00b1\u0096\u00ed \u00b5\u00ed\u00b1\u0094\u00ed \u00b5\u00ed\u00b1\u0096\u00ed \u00b5\u00ed\u00b1\u009b\u00ed \u00b5\u00ed\u00b1\u008e\u00ed \u00b5\u00ed\u00b1\u0099 \u00ed \u00b5\u00ed\u00b1\u008e\u00ed \u00b5\u00ed\u00b1\u009f\u00ed \u00b5\u00ed\u00b1\u00a1\u00ed \u00b5\u00ed\u00b1\u0096\u00ed \u00b5\u00ed\u00b1 \u00ed \u00b5\u00ed\u00b1\u00a1 = \u00ed \u00b5\u00ed\u00b1\u008e\u00ed \u00b5\u00ed\u00b1\u009b\u00ed \u00b5\u00ed\u00b1\u009b\u00ed \u00b5\u00ed\u00b1\u008e \u00ed \u00b5\u00ed\u00b1\u0090\u210e\u00ed \u00b5\u00ed\u00b1\u009f\u00ed \u00b5\u00ed\u00b1\u0096\u00ed \u00b5\u00ed\u00b1 \u00ed \u00b5\u00ed\u00b1\u00a1\u00ed \u00b5\u00ed\u00b1\u0096\u00ed \u00b5\u00ed\u00b1\u009b\u00ed \u00b5\u00ed\u00b1\u0092 \u00ed \u00b5\u00ed\u00b1\u009b\u00ed \u00b5\u00ed\u00b1\u008e\u00ed \u00b5\u00ed\u00b1\u0099\u00ed \u00b5\u00ed\u00b1\u0096\u00ed \u00b5\u00ed\u00b1\u0090\u00ed \u00b5\u00ed\u00b1\u0098: An brief illustration of the task.", "labels": [], "entities": []}, {"text": "The focus of this work is sequence-to-SQL generation.", "labels": [], "entities": [{"text": "sequence-to-SQL generation", "start_pos": 26, "end_pos": 52, "type": "TASK", "confidence": 0.7673691511154175}]}, {"text": "We conduct experiments on the WikiSQL dataset  , which measures the percentage of the generated SQL queries that obtain the correct answer.", "labels": [], "entities": [{"text": "WikiSQL dataset", "start_pos": 30, "end_pos": 45, "type": "DATASET", "confidence": 0.9595105051994324}]}], "tableCaptions": [{"text": " Table 1: Performances of different approaches on the WikiSQL dataset. Two evaluation metrics are  logical form accuracy (Acc lf ) and execution accuracy (Acc ex ). Our model is abbreviated as (STAMP).", "labels": [], "entities": [{"text": "WikiSQL dataset", "start_pos": 54, "end_pos": 69, "type": "DATASET", "confidence": 0.8583835959434509}, {"text": "logical form accuracy (Acc lf )", "start_pos": 99, "end_pos": 130, "type": "METRIC", "confidence": 0.7606172263622284}, {"text": "execution accuracy (Acc ex )", "start_pos": 135, "end_pos": 163, "type": "METRIC", "confidence": 0.8917250633239746}]}, {"text": " Table 2: Fine-grained accuracies on the WikiSQL dev and test sets. Accuracy (Acc lf ) is evaluated on  SELECT column (Acc sel ) , SELECT aggregator (Acc agg ), and WHERE clause (Acc where ), respectively.", "labels": [], "entities": [{"text": "Accuracy (Acc lf )", "start_pos": 68, "end_pos": 86, "type": "METRIC", "confidence": 0.8949983835220336}, {"text": "SELECT column (Acc sel )", "start_pos": 104, "end_pos": 128, "type": "METRIC", "confidence": 0.9006446599960327}, {"text": "SELECT aggregator (Acc agg )", "start_pos": 131, "end_pos": 159, "type": "METRIC", "confidence": 0.8409268856048584}]}, {"text": " Table 3: Execution accuracy (Acc ex ) on different  groups of WikiSQL dev and test sets.", "labels": [], "entities": [{"text": "Execution", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9352731704711914}, {"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.7245272994041443}, {"text": "Acc ex )", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9642953475316366}]}, {"text": " Table 4: Percentage of the executable SQL queries  on WikiSQL dev and test sets.", "labels": [], "entities": []}]}