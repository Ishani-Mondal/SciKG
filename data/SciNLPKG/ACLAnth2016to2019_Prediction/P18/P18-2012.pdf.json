{"title": [{"text": "Named Entity Recognition With Parallel Recurrent Neural Networks", "labels": [], "entities": [{"text": "Entity Recognition", "start_pos": 6, "end_pos": 24, "type": "TASK", "confidence": 0.68160480260849}]}], "abstractContent": [{"text": "We present anew architecture for named entity recognition.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 33, "end_pos": 57, "type": "TASK", "confidence": 0.6232947210470835}]}, {"text": "Our model employs multiple independent bidirectional LSTM units across the same input and promotes diversity among them by employing an inter-model regularization term.", "labels": [], "entities": []}, {"text": "By distributing computation across multiple smaller LSTMs we find a reduction in the total number of parameters.", "labels": [], "entities": []}, {"text": "We find our architecture achieves state-of-the-art performance on the CoNLL 2003 NER dataset.", "labels": [], "entities": [{"text": "CoNLL 2003 NER dataset", "start_pos": 70, "end_pos": 92, "type": "DATASET", "confidence": 0.9528308510780334}]}], "introductionContent": [{"text": "The ability to reason about entities in text is an important element of natural language understanding.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 72, "end_pos": 102, "type": "TASK", "confidence": 0.6588419775168101}]}, {"text": "Named entity recognition (NER) concerns itself with the identification of such entities.", "labels": [], "entities": [{"text": "Named entity recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7879448334376017}]}, {"text": "Given a sequence of words, the task of NER is to label each word with its appropriate corresponding entity type.", "labels": [], "entities": [{"text": "NER", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.9387165904045105}]}, {"text": "Examples of entity types include Person, Organization, and Location.", "labels": [], "entities": []}, {"text": "A special Other entity type is often added to the set of all types and is used to label words which do not belong to any of the other entity types.", "labels": [], "entities": []}, {"text": "Recently, neural network based approaches which use no language-specific resources, apart from unlabeled corpora for training word embeddings, have emerged.", "labels": [], "entities": []}, {"text": "There has been a shift of focus from handcrafting better features to designing better neural architectures for solving NER.", "labels": [], "entities": [{"text": "solving NER", "start_pos": 111, "end_pos": 122, "type": "TASK", "confidence": 0.6731138080358505}]}, {"text": "In this paper, we propose anew parallel recurrent neural network model for entity recognition.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 75, "end_pos": 93, "type": "TASK", "confidence": 0.8370037972927094}]}, {"text": "We show that rather than using a single LSTM component, as many other recent architecture have, we instead resort to using multiple smaller LSTM units.", "labels": [], "entities": []}, {"text": "This has the benefit of reducing the total number of parameters in our model.", "labels": [], "entities": []}, {"text": "We present results on the CoNNL 2003 English dataset and achieve the new state of the art results for models without help from an outside lexicons.", "labels": [], "entities": [{"text": "CoNNL 2003 English dataset", "start_pos": 26, "end_pos": 52, "type": "DATASET", "confidence": 0.9688409119844437}]}], "datasetContent": [{"text": "We achieve state-of-the-art results on the CoNNL 2003 English NER dataset (see).", "labels": [], "entities": [{"text": "CoNNL 2003 English NER dataset", "start_pos": 43, "end_pos": 73, "type": "DATASET", "confidence": 0.9461270093917846}]}, {"text": "Although we do not employ additional external resources (language specific dictionaries or gazetteers), our model is competitive even with some of the models that do.", "labels": [], "entities": []}, {"text": "To gain a better understanding of the performance of our model including how its various components affect performance we prepared four additional tables of runs.", "labels": [], "entities": []}, {"text": "shows performance as a function of the number of RNN units with a fixed unit size.", "labels": [], "entities": []}, {"text": "The Model F1 ( 88.31 ( 88.76 ( 89 number of units is clearly a hyperparameter which must be optimized for.", "labels": [], "entities": []}, {"text": "We find good performance across the board (there is no catastrophic collapse in results) however when using 16 units we do outperform other models substantially.", "labels": [], "entities": []}, {"text": "Even with very small unit sizes of 8 our models performs relatively well without a significant degradation in results.", "labels": [], "entities": []}, {"text": "shows and 5 show additional results for unit size and component impact on our best performing model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: English NER F1 score of our model on  the test set of CoNLL-2003 (English). During  training we optimize for the development set and  report test set results for our best performing de- velopment set model. The bounded F1 results we  report (\u00b10.22) are taken after 10 runs. For the pur- pose of comparison, we also list F1 scores of pre- vious top-performance systems.  \u2021 marks the neu- ral models.  *  marks model which use external re- sources.", "labels": [], "entities": [{"text": "F1", "start_pos": 22, "end_pos": 24, "type": "METRIC", "confidence": 0.777644693851471}, {"text": "test set of CoNLL-2003 (English)", "start_pos": 52, "end_pos": 84, "type": "DATASET", "confidence": 0.7439691083771842}, {"text": "F1", "start_pos": 229, "end_pos": 231, "type": "METRIC", "confidence": 0.9854000210762024}, {"text": "F1", "start_pos": 330, "end_pos": 332, "type": "METRIC", "confidence": 0.995434582233429}]}, {"text": " Table 2: Performance as a function of the number  of RNN units with a fixed unit size of 64; aver- aged across 5 runs apart from the 16 unit (average  across 10 runs).", "labels": [], "entities": []}, {"text": " Table 3: Performance of our model with various  unit sizes resulting in a fixed final output size h t .  Single runs apart from 16 unit.", "labels": [], "entities": []}, {"text": " Table 4: Performance as a function of the unit size  for our best performing model (16 biLSTM units).  Single runs apart from with size 64.", "labels": [], "entities": []}, {"text": " Table 5: Impact of various architectural decisions  on our best performing model (16 biLSTM units,  64 unit size). Single runs.", "labels": [], "entities": []}]}