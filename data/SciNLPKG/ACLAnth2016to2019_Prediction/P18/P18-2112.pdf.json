{"title": [{"text": "Personalized Review Generation by Expanding Phrases and Attending on Aspect-Aware Representations", "labels": [], "entities": [{"text": "Personalized Review Generation", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7674503525098165}]}], "abstractContent": [{"text": "In this paper, we focus on the problem of building assistive systems that can help users to write reviews.", "labels": [], "entities": []}, {"text": "We cast this problem using an encoder-decoder framework that generates personalized reviews by expanding short phrases (e.g. review summaries , product titles) provided as input to the system.", "labels": [], "entities": []}, {"text": "We incorporate aspect-level information via an aspect encoder that learns 'aspect-aware' user and item representations.", "labels": [], "entities": []}, {"text": "An attention fusion layer is applied to control generation by attending on the outputs of multiple encoders.", "labels": [], "entities": [{"text": "control generation", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.7162463814020157}]}, {"text": "Experimental results show that our model is capable of generating coherent and diverse reviews that expand the contents of input phrases.", "labels": [], "entities": []}, {"text": "In addition, the learned aspect-aware representations discover those aspects that users are more inclined to discuss and bias the generated text toward their personalized aspect preferences.", "labels": [], "entities": []}], "introductionContent": [{"text": "Contextual, or 'data-to-text' natural language generation is one of the core tasks in natural language processing and has a considerable impact on various fields.", "labels": [], "entities": [{"text": "Contextual, or 'data-to-text' natural language generation", "start_pos": 0, "end_pos": 57, "type": "TASK", "confidence": 0.5209451781378852}, {"text": "natural language processing", "start_pos": 86, "end_pos": 113, "type": "TASK", "confidence": 0.6695622404416403}]}, {"text": "Within the field of recommender systems, a promising application is to estimate (or generate) personalized reviews that a user would write about a product, i.e., to discover their nuanced opinions about each of its individual aspects.", "labels": [], "entities": [{"text": "estimate (or generate) personalized reviews that a user would write about a product, i.e., to discover their nuanced opinions about each of its individual aspects", "start_pos": 71, "end_pos": 233, "type": "Description", "confidence": 0.7002226730872845}]}, {"text": "A successful model could work (for instance) as (a) a highly-nuanced recommender system that tells users their likely reaction to a product in the form of text fragments; (b) a writing tool that helps users 'brainstorm' the review-writing process; or (c) a querying system that facilitates personalized natural language queries (i.e., to find items about which a user would be most likely to write a particular phrase).", "labels": [], "entities": []}, {"text": "Some recent works have explored the review generation task and shown success in generating cohesive reviews ().", "labels": [], "entities": [{"text": "review generation task", "start_pos": 36, "end_pos": 58, "type": "TASK", "confidence": 0.8010371128718058}]}, {"text": "Most of these works treat the user and item identity as input; we seek a system with more nuance and more precision by allowing users to 'guide' the model via short phrases, or auxiliary data such as item specifications.", "labels": [], "entities": [{"text": "precision", "start_pos": 106, "end_pos": 115, "type": "METRIC", "confidence": 0.9961867928504944}]}, {"text": "For example, a review writing assistant might allow users to write short phrases and expand these key points into a plausible review.", "labels": [], "entities": []}, {"text": "Review text has been widely studied in traditional tasks such as aspect extraction, extraction of sentiment lexicons (, and aspectaware sentiment analysis ().", "labels": [], "entities": [{"text": "aspect extraction", "start_pos": 65, "end_pos": 82, "type": "TASK", "confidence": 0.8291915357112885}, {"text": "extraction of sentiment lexicons", "start_pos": 84, "end_pos": 116, "type": "TASK", "confidence": 0.8985343128442764}, {"text": "aspectaware sentiment analysis", "start_pos": 124, "end_pos": 154, "type": "TASK", "confidence": 0.7669408917427063}]}, {"text": "These works are related to review generation since they can provide prior knowledge to supervise the generative process.", "labels": [], "entities": [{"text": "review generation", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.800100564956665}, {"text": "generative process", "start_pos": 101, "end_pos": 119, "type": "TASK", "confidence": 0.9256223142147064}]}, {"text": "We are interested in exploring how such knowledge (e.g. extracted aspects) can be used in the review generation task.", "labels": [], "entities": [{"text": "review generation task", "start_pos": 94, "end_pos": 116, "type": "TASK", "confidence": 0.8268028497695923}]}, {"text": "In this paper, we focus on designing a review generation model that is able to leverage both user and item information as well as auxiliary, textual input and aspect-aware knowledge.", "labels": [], "entities": []}, {"text": "Specifically, we study the task of expanding short phrases into complete, coherent reviews that accurately reflect the opinions and knowledge learned from those phrases.", "labels": [], "entities": []}, {"text": "These short phrases could include snippets provided by the user, or manifest aspects about the items themselves (e.g. brand words, technical specifications, etc.).", "labels": [], "entities": []}, {"text": "We propose an encoderdecoder framework that takes into consideration three encoders (a sequence encoder, an attribute encoder, and an aspect encoder), and one decoder.", "labels": [], "entities": []}, {"text": "The sequence encoder uses a gated recurrent unit   (GRU) network to encode text information; the attribute encoder learns a latent representation of user and item identity; finally, the aspect encoder finds an aspect-aware representation of users and items, which reflects user-aspect preferences and item-aspect relationships.", "labels": [], "entities": []}, {"text": "The aspect-aware representation is helpful to discover what each user is likely to discuss about each item.", "labels": [], "entities": []}, {"text": "Finally, the output of these encoders is passed to the sequence decoder with an attention fusion layer.", "labels": [], "entities": []}, {"text": "The decoder attends on the encoded information and biases the model to generate words that are consistent with the input phrases and words belonging to the most relevant aspects.", "labels": [], "entities": []}], "datasetContent": [{"text": "We consider areal world dataset from Amazon Electronics () to evaluate our model.", "labels": [], "entities": [{"text": "Amazon Electronics", "start_pos": 37, "end_pos": 55, "type": "DATASET", "confidence": 0.7967556118965149}]}, {"text": "We convert all text into lowercase, add start and end tokens to each review, and perform tokenization using NLTK.", "labels": [], "entities": [{"text": "NLTK", "start_pos": 108, "end_pos": 112, "type": "DATASET", "confidence": 0.8843643665313721}]}, {"text": "We discard reviews with length greater than 100 tokens and consider a vocabulary of 30,000 tokens.", "labels": [], "entities": []}, {"text": "After preprocessing, the dataset contains 182,850 users, 59,043 items, and 992,172 reviews (sparsity 99.993%), which is much sparser than the datasets used in previous works ().", "labels": [], "entities": [{"text": "sparsity", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9760338664054871}]}, {"text": "On average, each review contains 49.32 tokens as well as a short-text summary of 4.52 tokens.", "labels": [], "entities": []}, {"text": "In our experiments, the basic ExpansionNet uses these summaries as input phrases.", "labels": [], "entities": []}, {"text": "We split the dataset into training (80%), validation (10%) and test sets (10%).", "labels": [], "entities": []}, {"text": "All results are reported on the test set.", "labels": [], "entities": []}, {"text": "We use PyTorch 3 to implement our model.", "labels": [], "entities": []}, {"text": "Parameter settings are shown in.", "labels": [], "entities": [{"text": "Parameter", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.970002293586731}]}, {"text": "For the attribute encoder and aspect encoder, we set the dimensionality to 64 and 15 respectively.", "labels": [], "entities": []}, {"text": "For both the sequence encoder and decoder, we use a 2-layer GRU with hidden size 512.", "labels": [], "entities": []}, {"text": "We also add dropout layers before and after the GRUs.", "labels": [], "entities": [{"text": "GRUs", "start_pos": 48, "end_pos": 52, "type": "DATASET", "confidence": 0.7819639444351196}]}, {"text": "The dropout rate is set to 0.1.", "labels": [], "entities": []}, {"text": "During training, the input sequences of the same source (e.g. review, summary) inside each batch are padded to the same length.", "labels": [], "entities": []}, {"text": "We evaluate the model on six automatic metrics: Perplexity, BLEU-1/BLEU-4, ROUGE-L and Distinct-1/2 (percentage of distinct unigrams and bi-grams) ( ).", "labels": [], "entities": [{"text": "Perplexity", "start_pos": 48, "end_pos": 58, "type": "METRIC", "confidence": 0.9884080290794373}, {"text": "BLEU-1", "start_pos": 60, "end_pos": 66, "type": "METRIC", "confidence": 0.9986226558685303}, {"text": "BLEU-4", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.9883915781974792}, {"text": "ROUGE-L", "start_pos": 75, "end_pos": 82, "type": "METRIC", "confidence": 0.9972438812255859}, {"text": "Distinct-1/2", "start_pos": 87, "end_pos": 99, "type": "METRIC", "confidence": 0.9419539173444113}]}, {"text": "We compare User/Item user A3G831BTCLWGVQ and item B007M50PTM Review summary \"easy to use and nice standard apps\" Item title \"samsung galaxy tab 2 (10.1-Inch, wi-fi) 2012 model\" Real review \"the display is beautiful and the tablet is very easy to use.", "labels": [], "entities": []}, {"text": "it comes with some really nice standard apps.\"", "labels": [], "entities": []}, {"text": "against three baselines: Rand (randomly choose a review from the training set), GRU-LM (the GRU decoder works alone as a language model) and a state-of-the-art model Attr2Seq that only considers user and item attribute (.", "labels": [], "entities": [{"text": "Rand", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.6725126504898071}, {"text": "GRU-LM", "start_pos": 80, "end_pos": 86, "type": "DATASET", "confidence": 0.7844803333282471}]}, {"text": "ExpansionNet (with summary, item title, attribute and aspect as input) achieves significant improvements over Attr2Seq on all metrics.", "labels": [], "entities": []}, {"text": "As we add more input information, the model continues to obtain better results, except for the ROUGE-L metric.", "labels": [], "entities": [{"text": "ROUGE-L", "start_pos": 95, "end_pos": 102, "type": "METRIC", "confidence": 0.9948510527610779}]}, {"text": "This proves that our model can effectively learn from short input phrases and aspect information and improve the correctness and diversity of generated results.", "labels": [], "entities": [{"text": "correctness", "start_pos": 113, "end_pos": 124, "type": "METRIC", "confidence": 0.9567746520042419}]}, {"text": "presents a sample generation result.", "labels": [], "entities": []}, {"text": "ExpansionNet captures fine-grained item information (e.g. that the item is a tablet), which Attr2Seq fails to recognize.", "labels": [], "entities": []}, {"text": "Moreover, given a phrase like \"easy to use\" in the summary, ExpansionNet generates reviews containing the same text.", "labels": [], "entities": []}, {"text": "This demonstrates the possibility of using our model in an assistive review generation scenario.", "labels": [], "entities": []}, {"text": "Finally, given extra aspect information, the model successfully estimates that the screen would bean important aspect (i.e., for the current user and item); it generates phrases such as \"screen is very respon- sive\" about the aspect \"screen\" which is also covered in the real (ground-truth) review (\"display is beautiful\").", "labels": [], "entities": []}, {"text": "We are also interested in seeing how the aspectaware representation can find related aspects and bias the generation to discuss more about those aspects.", "labels": [], "entities": []}, {"text": "We analyze the average number of aspects in real and generated reviews and show on average how many aspects in real reviews are covered in generated reviews.", "labels": [], "entities": []}, {"text": "We consider a review as covering an aspect if any of the aspect's representative words exists in the review.", "labels": [], "entities": []}, {"text": "As shown in, Attr2Seq tends to cover more aspects in generation, many of which are not discussed in real reviews.", "labels": [], "entities": []}, {"text": "On the other hand, ExpansionNet better captures the distribution of aspects that are discussed in real reviews.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Parameter settings used in our experiments.", "labels": [], "entities": []}, {"text": " Table 3: Results on automatic metrics", "labels": [], "entities": []}, {"text": " Table 4: Aspect coverage analysis", "labels": [], "entities": [{"text": "Aspect coverage analysis", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.9117793838183085}]}]}