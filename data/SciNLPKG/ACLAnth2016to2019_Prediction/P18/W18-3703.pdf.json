{"title": [{"text": "Feature Optimization for Predicting Readability of Arabic L1 and L2", "labels": [], "entities": [{"text": "Predicting Readability of Arabic L1", "start_pos": 25, "end_pos": 60, "type": "TASK", "confidence": 0.8559603571891785}]}], "abstractContent": [{"text": "Advances in automatic readability assessment can impact the way people consume information in a number of domains.", "labels": [], "entities": [{"text": "automatic readability assessment", "start_pos": 12, "end_pos": 44, "type": "TASK", "confidence": 0.6625610788663229}]}, {"text": "Ara-bic, being a low-resource and morphologically complex language, presents numerous challenges to the task of automatic readability assessment.", "labels": [], "entities": [{"text": "automatic readability assessment", "start_pos": 112, "end_pos": 144, "type": "TASK", "confidence": 0.5358145733674368}]}, {"text": "In this paper, we present the largest and most in-depth computational readability study for Arabic to date.", "labels": [], "entities": []}, {"text": "We study a large set of features with varying depths, from shallow words to syntactic trees, for both L1 and L2 read-ability tasks.", "labels": [], "entities": []}, {"text": "Our best L1 readability accuracy result is 94.8% (75% error reduction from a commonly used baseline).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9806180596351624}, {"text": "error reduction", "start_pos": 54, "end_pos": 69, "type": "METRIC", "confidence": 0.949932873249054}]}, {"text": "The comparable results for L2 are 72.4% (45% error reduction).", "labels": [], "entities": [{"text": "error reduction", "start_pos": 45, "end_pos": 60, "type": "METRIC", "confidence": 0.9831399321556091}]}, {"text": "We also demonstrate the added value of leveraging L1 features for L2 readability prediction.", "labels": [], "entities": [{"text": "L2 readability prediction", "start_pos": 66, "end_pos": 91, "type": "TASK", "confidence": 0.6311171650886536}]}], "introductionContent": [{"text": "The purpose of studies in readability is to develop and evaluate measures of how well a reader can understand a given text.", "labels": [], "entities": []}, {"text": "Computational readability measures, historically shallow and formulaic, are now leveraging machine learning (ML) models and natural language processing (NLP) features for automated, in-depth readability assessment systems.", "labels": [], "entities": []}, {"text": "Advances in readability assessment can impact the way people consume information in a number of domains.", "labels": [], "entities": [{"text": "readability assessment", "start_pos": 12, "end_pos": 34, "type": "TASK", "confidence": 0.8893204033374786}]}, {"text": "Prime among them is education, where matching reading material to a learner's level can serve instructors, book publishers, and learners themselves looking for suitable reading material.", "labels": [], "entities": []}, {"text": "Content for the general public, such as media and news articles, administrative, legal or healthcare documents, governmental websites and soon, needs to be written at a level accessible to different educational backgrounds.", "labels": [], "entities": []}, {"text": "Efforts in building computational readability models and integrating them in various applications continue to grow, especially for more resourcerich languages.", "labels": [], "entities": []}, {"text": "In this paper, we present a large-scale and indepth computational readability study for Arabic.", "labels": [], "entities": []}, {"text": "Arabic, being a relatively low-resource and morphologically complex language, presents numerous challenges to the task of automatic readability assessment.", "labels": [], "entities": [{"text": "automatic readability assessment", "start_pos": 122, "end_pos": 154, "type": "TASK", "confidence": 0.5131490429242452}]}, {"text": "Compared to work done for English and other European languages, efforts for Arabic have only picked up in recent years, as better NLP tools and resources became available.", "labels": [], "entities": []}, {"text": "We evaluate data from both Arabic as a First Language (L1) and Arabic as a Second or Foreign Language (L2) within the same experimental setting, to classify text documents into one of four levels of readability in increasing order of difficulty (level 1: easiest; level 4: most difficult).", "labels": [], "entities": []}, {"text": "This is a departure from all previously published results on Arabic readability, which have only focused on either L1 or L2.", "labels": [], "entities": []}, {"text": "We examine a larger array of predictive features combining language modeling (LM) and shallow extraction techniques for lexical, morphological and syntactic features.", "labels": [], "entities": []}, {"text": "Our best L1 Readability accuracy result is 94.8%, a 75% error reduction from a baseline feature set of raw and shallow text attributes commonly used in traditional readability formulas and simpler computational models).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.8687248826026917}]}, {"text": "The comparable results for L2 are 72.4%, a 45% error reduction from the corresponding baseline performance in L2.", "labels": [], "entities": [{"text": "error", "start_pos": 47, "end_pos": 52, "type": "METRIC", "confidence": 0.9822929501533508}]}, {"text": "We leverage our rich Arabic L1 resources to support Arabic L2 readability.", "labels": [], "entities": []}, {"text": "We increase the L2 accuracy to 74.1%, an additional 6% error reduction, by augmenting the L2 feature set with features based on L1-generated language models (LM: Comparative summary of recent work and our current study on computational readability for Arabic in terms of corpus size, focus on L1 or L2, use of shallow vs. deep features requiring heavier processing for extraction from the text, use of language models in generating features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9839774966239929}]}, {"text": "Results reported are presented for reference rather than direct comparison.", "labels": [], "entities": []}], "datasetContent": [{"text": "First, we build classifiers on the full feature set FEAT Raw.M orph.Syn", "labels": [], "entities": [{"text": "FEAT Raw.M orph.Syn", "start_pos": 52, "end_pos": 71, "type": "DATASET", "confidence": 0.8552905122439066}]}], "tableCaptions": [{"text": " Table 3: Descriptive corpus statistics for our L1 and L2 data.", "labels": [], "entities": []}, {"text": " Table 4: Comparison of different classifiers using the full feature set FEAT Raw.M orph.Syn", "labels": [], "entities": [{"text": "FEAT Raw.M orph.Syn", "start_pos": 73, "end_pos": 92, "type": "DATASET", "confidence": 0.7691413362820944}]}, {"text": " Table 5: Comparison of different feature subsets  using SVM Classifier for L1 (based on best per- formance results from", "labels": [], "entities": []}, {"text": " Table 6: Comparison of different feature subsets  using SVM Classifier for L2 (based on best per- formance results from", "labels": [], "entities": []}, {"text": " Table 7: L2 results with different classifiers  on FEAT Raw.M orph.Syn", "labels": [], "entities": [{"text": "FEAT Raw.M orph.Syn", "start_pos": 52, "end_pos": 71, "type": "DATASET", "confidence": 0.9450980424880981}]}]}