{"title": [{"text": "Classification of Moral Foundations in Microblog Political Discourse", "labels": [], "entities": [{"text": "Classification of Moral Foundations in Microblog Political Discourse", "start_pos": 0, "end_pos": 68, "type": "TASK", "confidence": 0.6942118704319}]}], "abstractContent": [{"text": "Previous works in computer science, as well as political and social science, have shown correlation in text between political ideologies and the moral foundations expressed within that text.", "labels": [], "entities": []}, {"text": "Additional work has shown that policy frames, which are used by politicians to bias the public towards their stance on an issue, are also correlated with political ideology.", "labels": [], "entities": []}, {"text": "Based on these associations, this work takes a first step towards modeling both the language and how politicians frame issues on Twitter, in order to predict the moral foundations that are used by politicians to express their stances on issues.", "labels": [], "entities": []}, {"text": "The contributions of this work includes a dataset annotated for the moral foundations, annotation guidelines, and probabilistic graph-ical models which show the usefulness of jointly modeling abstract political slogans, as opposed to the unigrams of previous works, with policy frames for the prediction of the morality underlying political tweets.", "labels": [], "entities": []}], "introductionContent": [{"text": "Social media microblogging platforms, specifically Twitter, have become highly influential and relevant to current political events.", "labels": [], "entities": []}, {"text": "Such platforms allow politicians to communicate with the public as events are unfolding and shape public discourse on various issues.", "labels": [], "entities": []}, {"text": "Furthermore, politicians are able to express their stances on issues and by selectively using certain political slogans, reveal their underlying political ideologies and moral views on an issue.", "labels": [], "entities": []}, {"text": "Previous works in political and social science have shown a correlation between political ideology, stances on political issues, and the moral convictions used to justify these stances (.", "labels": [], "entities": []}, {"text": "For example, presents a tweet, by a prominent member of the U.S. Congress, which expresses concern We are permitting the incarceration and shooting of thousands of black and brown boys in their formative years.", "labels": [], "entities": []}, {"text": "about the fate of young individuals (i.e., incarceration, shooting), specifically for vulnerable members of minority groups.", "labels": [], "entities": []}, {"text": "The Moral Foundations Theory (MFT) () provides a theoretical framework for explaining these nuanced distinctions.", "labels": [], "entities": [{"text": "Moral Foundations Theory (MFT)", "start_pos": 4, "end_pos": 34, "type": "TASK", "confidence": 0.7888001849253973}]}, {"text": "The theory suggests that there are five basic moral values which underlie human moral perspectives, emerging from evolutionary, social, and cultural origins.", "labels": [], "entities": []}, {"text": "These are referred to as the moral foundations (MF) and include Care/Harm, Fairness/Cheating, Loyalty/Betrayal, Authority/Subversion, and Purity/Degradation provides a more detailed explanation).", "labels": [], "entities": []}, {"text": "The above example reflects the moral foundations that shape the author's perspective on the issue: Harm and Cheating.", "labels": [], "entities": [{"text": "Harm", "start_pos": 99, "end_pos": 103, "type": "TASK", "confidence": 0.711654782295227}]}, {"text": "Traditionally, analyzing text based on the MFT has relied on the use of a lexical resource, the Moral Foundations Dictionary (MFD)).", "labels": [], "entities": []}, {"text": "The MFD, similar to LIWC (, associates a list of related words with each one of the moral foundations.", "labels": [], "entities": []}, {"text": "Therefore, analyzing text equates to counting the number of occurrences of words in the text which also match the words in the MFD.", "labels": [], "entities": [{"text": "MFD", "start_pos": 127, "end_pos": 130, "type": "DATASET", "confidence": 0.8369369506835938}]}, {"text": "Given the highly abstract and generalized nature of the moral foundations, this approach often falls short of dealing with the highly ambiguous text politicians use to express their perspectives on specific issues.", "labels": [], "entities": []}, {"text": "The following tweet, by another prominent member of the U.S. Congress, reflects the author's use of both the Harm and Cheating moral foundations.", "labels": [], "entities": [{"text": "Harm", "start_pos": 109, "end_pos": 113, "type": "METRIC", "confidence": 0.6309061646461487}]}, {"text": "30k Americans die to gun violence.", "labels": [], "entities": []}, {"text": "Still, I'm moving to North Carolina where it's safe to go to the bathroom.", "labels": [], "entities": []}, {"text": "While the first foundation (Harm) can be directly identified using a word match to the MFD (as shown in red), the second foundation requires first identifying the sarcastic expression referring to LGBTQ rights and then using extensive world knowledge to determine the appropriate moral foundation.", "labels": [], "entities": [{"text": "Harm)", "start_pos": 28, "end_pos": 33, "type": "TASK", "confidence": 0.7585647106170654}, {"text": "MFD", "start_pos": 87, "end_pos": 90, "type": "DATASET", "confidence": 0.82813560962677}]}, {"text": "Relying on a match of safe to the MFD would indicate the Care MF is being used instead of the Cheating foundation.", "labels": [], "entities": [{"text": "Care MF", "start_pos": 57, "end_pos": 64, "type": "DATASET", "confidence": 0.8318678140640259}, {"text": "Cheating foundation", "start_pos": 94, "end_pos": 113, "type": "DATASET", "confidence": 0.8090789020061493}]}, {"text": "In this paper, we aim to solve this challenge by suggesting a data-driven approach to moral foundation identification in tweets.", "labels": [], "entities": [{"text": "moral foundation identification", "start_pos": 86, "end_pos": 117, "type": "TASK", "confidence": 0.7663131852944692}]}, {"text": "Previous work () has looked at classification-based approaches over tweets specifically related to Hurricane Sandy, augmenting the textual content with background knowledge using entity linking (.", "labels": [], "entities": []}, {"text": "Different from this and similar works, we look at the tweets of U.S. politicians over along period of time, discussing a large number of events, and touching on several different political issues.", "labels": [], "entities": []}, {"text": "Our approach is guided by the intuition that the abstract moral foundations will manifest differently in text, depending on the specific characteristics of the events discussed in the tweet.", "labels": [], "entities": []}, {"text": "As a result, it is necessary to correctly model the relevant contextualizing information.", "labels": [], "entities": []}, {"text": "Specifically, we are interested in exploring how political ideology, language, and framing interact to represent morality on Twitter.", "labels": [], "entities": []}, {"text": "We examine the interplay of political slogans (for example \"repeal and replace\" when referring to the Affordable Care Act), and policy framing techniques as features for predicting the underlying moral values which are expressed in politicians' tweets.", "labels": [], "entities": [{"text": "repeal and replace\"", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.7932821810245514}]}, {"text": "Additionally, we identify high-level themes characterizing the main point of the tweet, which allows the model to identify the author's perspective on specific issues and generalize over the specific wording used (for example, if the tweet mentions Religion or Political Maneuvering).", "labels": [], "entities": []}, {"text": "This information is incorporated into global probabilistic models using Probabilistic Soft Logic (PSL), a graphical probabilistic modeling framework (.", "labels": [], "entities": []}, {"text": "PSL specifies high level rules over a relational representation of these features, which are compiled into a graphical model called a hinge-loss Markov random field that is used to make the final prediction.", "labels": [], "entities": []}, {"text": "Our experiments show the importance of modeling contextualizing information, leading to significant improvements over dictionary driven approaches and purely lexical methods.", "labels": [], "entities": []}, {"text": "In summary, this paper makes the following contributions: (1) This work is among the first to explore jointly modeling language and political framing techniques for the classification of moral foundations used in the tweets of U.S. politicians on Twitter.", "labels": [], "entities": [{"text": "classification of moral foundations", "start_pos": 169, "end_pos": 204, "type": "TASK", "confidence": 0.8309006690979004}]}, {"text": "(2) We provide a description of our annotation guidelines and an annotated dataset of 2,050 tweets.", "labels": [], "entities": []}, {"text": "2 (3) We suggest computational models which easily adapt to new policy issues, for the classification of the moral foundations present in tweets.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we present an analysis of the results of our modeling approach.", "labels": [], "entities": []}, {"text": "summarizes our overall results and compares the traditional BoW SVM classifier 4 to several variations of our model.", "labels": [], "entities": [{"text": "BoW SVM classifier 4", "start_pos": 60, "end_pos": 80, "type": "DATASET", "confidence": 0.931689590215683}]}, {"text": "We provide an in-depth analysis, broken down by the different types of moral foundations, in.", "labels": [], "entities": []}, {"text": "We also study the relationship between moral foundations, policy framing, and political ideology.", "labels": [], "entities": [{"text": "policy framing", "start_pos": 58, "end_pos": 72, "type": "TASK", "confidence": 0.8506823182106018}]}, {"text": "Evaluation Metrics: Since each tweet can have more than one moral foundation, our prediction task is a multilabel classification task.", "labels": [], "entities": []}, {"text": "The precision of a multilabel model is the ratio of how many predicted labels are correct: The recall of this model is the ratio of how many of the actual labels were predicted: In both formulas, T is the number of tweets, Y t is the true label for tweet t, x t is a tweet example, and h(x t ) are the predicted labels for that tweet.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9983232617378235}, {"text": "recall", "start_pos": 95, "end_pos": 101, "type": "METRIC", "confidence": 0.9997120499610901}]}, {"text": "The F 1 score is computed as the harmonic mean of the precision and recall.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.978073239326477}, {"text": "precision", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9996727705001831}, {"text": "recall", "start_pos": 68, "end_pos": 74, "type": "METRIC", "confidence": 0.9985533356666565}]}, {"text": "Additionally, the last lines of provide the macro-weighted average F 1 score overall moral foundations.", "labels": [], "entities": [{"text": "macro-weighted average F 1 score", "start_pos": 44, "end_pos": 76, "type": "METRIC", "confidence": 0.750921618938446}]}, {"text": "Analysis of Supervised Experiments: We conducted supervised experiments using five-fold cross validation with randomly chosen splits.", "labels": [], "entities": []}, {"text": "Table 6 shows an overview of the average results of our supervised experiments for five of the PSL models.", "labels": [], "entities": []}, {"text": "The first column lists the SVM or PSL model.", "labels": [], "entities": []}, {"text": "The second column presents the results of a given model when using the MFD as the source of the unigrams for the initial model (M1).", "labels": [], "entities": [{"text": "MFD", "start_pos": 71, "end_pos": 74, "type": "DATASET", "confidence": 0.8514554500579834}]}, {"text": "The final column shows the results when the AR unigrams are used as the initial source of supervision.", "labels": [], "entities": []}, {"text": "The first two rows show the results of predicting the morals present in tweets using a bag-of-words (BoW) approach.", "labels": [], "entities": []}, {"text": "Both the SVM and PSL models perform poorly due to the eleven predictive classes and noisy input features.", "labels": [], "entities": []}, {"text": "The third row shows the results when taking a majority vote over the presence of MFD unigrams, similar to previous works.", "labels": [], "entities": []}, {"text": "This approach is simpler and less noisy than M1, the PSL model closest to this approach.", "labels": [], "entities": []}, {"text": "The last five lines of this table also show the overall trends of the full results shown in.", "labels": [], "entities": []}, {"text": "As can be seen in all three tables, as we add more information with each PSL model, the overall results continue to improve, with the final model (M13) achieving the highest F 1 score for both sources of unigrams.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 174, "end_pos": 183, "type": "METRIC", "confidence": 0.9913689891497294}]}, {"text": "An interesting trend to note is that the AR unigrams based models result in better average performance for most of the models until M9.", "labels": [], "entities": [{"text": "M9", "start_pos": 132, "end_pos": 134, "type": "DATASET", "confidence": 0.7565380334854126}]}, {"text": "Models M9 and above incorporate the most powerful features: bigrams and trigrams with phrases and frames.", "labels": [], "entities": []}, {"text": "This suggests that the AR unigrams, designed specifically for the political Twitter domain, are more useful than the MFD unigrams, when only unigrams are available.", "labels": [], "entities": [{"text": "MFD", "start_pos": 117, "end_pos": 120, "type": "DATASET", "confidence": 0.8577120900154114}]}, {"text": "Conversely, the MFD unigrams are designed to conceptually capture morality, and therefore have weaker performance in the unigram-based models, but achieve higher performance when combined with the more powerful features of the higher models.", "labels": [], "entities": []}, {"text": "For all models, incorporating phrases and frames results in a more accurate prediction than when using unigrams alone.", "labels": [], "entities": []}, {"text": "Analysis of Joint Experiments: In addition to studying the effects of each feature on the models' ability to predict moral foundations, we also explored jointly predicting both policy frames and moral foundations.", "labels": [], "entities": []}, {"text": "These tasks are highly related as shown by the large increase in score between the baseline and skyline measurements in once frames are incorporated into the models.", "labels": [], "entities": []}, {"text": "Both moral foundations and frame classification are challenging multilabel classification tasks, the former using 11 possible foundations and the latter consisting of 17 possible frames.", "labels": [], "entities": [{"text": "frame classification", "start_pos": 27, "end_pos": 47, "type": "TASK", "confidence": 0.8271190822124481}]}, {"text": "Furthermore, joint learning problems are harder to learn due to a larger numbers of parameters, which in turn also affects learning and inference.", "labels": [], "entities": []}, {"text": "shows the macro-weighted average F 1 scores for three different models.", "labels": [], "entities": [{"text": "macro-weighted average F 1 scores", "start_pos": 10, "end_pos": 43, "type": "METRIC", "confidence": 0.7035648465156555}]}, {"text": "The BASELINE model shows the results of predicting only the MORAL of the tweet using the non-joint model M13, which uses all features with frames initialized.", "labels": [], "entities": [{"text": "BASELINE", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9836306571960449}, {"text": "MORAL", "start_pos": 60, "end_pos": 65, "type": "METRIC", "confidence": 0.9977501034736633}]}, {"text": "The JOINT model is designed to predict both the moral foundation and frame of a tweet simultaneously (as shown in), with no frame initialization.", "labels": [], "entities": []}, {"text": "Finally, the SKYLINE model is M13 with all features, where the frames are initialized with their known values.", "labels": [], "entities": [{"text": "SKYLINE", "start_pos": 13, "end_pos": 20, "type": "DATASET", "confidence": 0.7244923114776611}]}, {"text": "The joint model using AR unigrams outperforms the baseline, showing that there is some benefit to modeling moral foundations and frames together, as well as using domain-specific unigrams.", "labels": [], "entities": []}, {"text": "However, it is unable to beat the MFDbased unigrams model.", "labels": [], "entities": [{"text": "MFDbased", "start_pos": 34, "end_pos": 42, "type": "DATASET", "confidence": 0.8172098994255066}]}, {"text": "This is likely due to the large amount of noise introduced by incorrect frame predictions into the joint model.", "labels": [], "entities": []}, {"text": "As expected, the joint model does not outperform the skyline model which is able to use the known values of the frames in order to accurately classify the moral foundations associated with the tweets.", "labels": [], "entities": []}, {"text": "Finally, the predictions for the frames in the joint model were quite low, going from an average F 1 score of 26.09 in M1 to an average F 1 score of 27.99 in M13.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 97, "end_pos": 106, "type": "METRIC", "confidence": 0.9913753072420756}, {"text": "F 1 score", "start_pos": 136, "end_pos": 145, "type": "METRIC", "confidence": 0.9920327464739481}, {"text": "M13", "start_pos": 158, "end_pos": 161, "type": "DATASET", "confidence": 0.9128068089485168}]}, {"text": "This likely has two causes: (1) frame prediction is a challenging 17-label classification task, with a random baseline of 6% (which our approach is able to exceed) and (2) the lower performance is because the frames are predicted with no initialization.", "labels": [], "entities": [{"text": "frame prediction", "start_pos": 32, "end_pos": 48, "type": "TASK", "confidence": 0.8213284611701965}, {"text": "17-label classification task", "start_pos": 66, "end_pos": 94, "type": "TASK", "confidence": 0.7510816852251688}]}, {"text": "In previous works, the frame prediction models are initialized with a set of unigrams expected to occur for each frame.", "labels": [], "entities": [{"text": "frame prediction", "start_pos": 23, "end_pos": 39, "type": "TASK", "confidence": 0.7289280146360397}]}, {"text": "Different from this approach, the only information our models provide to the frames are political party, issue, associated bigrams and trigrams, and the predicted values for the moral foundations from using this information.", "labels": [], "entities": []}, {"text": "The F 1 score of 27.99 with such minimal initialization indicates that there is indeed a relationship between policy frames and the moral foundations expressed in tweets worth exploring in future work.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.991008480389913}]}], "tableCaptions": [{"text": " Table 2: Distributions of Moral Foundations. Overall is across the entire dataset. Party is the Republican  (REP) or Democrat (DEM) specific distributions. Issue lists the six issue-specific distributions (Abortion,  ACA, Guns, Immigration, LGBTQ, Terrorism).", "labels": [], "entities": [{"text": "Distributions of Moral Foundations", "start_pos": 10, "end_pos": 44, "type": "TASK", "confidence": 0.6507966965436935}]}, {"text": " Table 6: Overview of Macro-weighted Average F 1  Scores of SVM and PSL Models. The top portion  of the table shows the results of the three base- lines. The bottom portion shows a subset of the  PSL models (parentheses indicate features added  onto the previous models).", "labels": [], "entities": [{"text": "Macro-weighted Average F 1  Scores", "start_pos": 22, "end_pos": 56, "type": "METRIC", "confidence": 0.6460524320602417}]}, {"text": " Table 7: F 1 Scores of PSL Models Using the Moral Foundations Dictionary (MFD). The highest predic- tion per moral foundation is marked in bold.", "labels": [], "entities": []}, {"text": " Table 8: F 1 Scores of PSL Models Using Annotator's Rationale (AR). The highest prediction per moral  foundation is marked in bold.", "labels": [], "entities": [{"text": "Annotator's Rationale (AR)", "start_pos": 41, "end_pos": 67, "type": "METRIC", "confidence": 0.7065370976924896}]}, {"text": " Table 9: Overview of Macro-weighted Average F 1  Scores of Joint PSL Model M13. BASELINE is  the MORAL prediction result. JOINT is the result  of jointly predicting the MORAL and uninitialized  FRAME predicates. SKYLINE shows the results  when using all features with initialized frames.", "labels": [], "entities": [{"text": "Macro-weighted Average F 1  Scores", "start_pos": 22, "end_pos": 56, "type": "METRIC", "confidence": 0.7033774137496949}, {"text": "Joint PSL Model M13", "start_pos": 60, "end_pos": 79, "type": "DATASET", "confidence": 0.6958158165216446}, {"text": "BASELINE", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9988792538642883}, {"text": "MORAL", "start_pos": 98, "end_pos": 103, "type": "METRIC", "confidence": 0.8476378321647644}, {"text": "JOINT", "start_pos": 123, "end_pos": 128, "type": "METRIC", "confidence": 0.9605764150619507}, {"text": "SKYLINE", "start_pos": 213, "end_pos": 220, "type": "DATASET", "confidence": 0.7825139164924622}]}, {"text": " Table 10: Accuracy of Author Political Party Pre- diction. REP represents Republican and DEM rep- resents Democrat.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.993720293045044}, {"text": "REP", "start_pos": 60, "end_pos": 63, "type": "METRIC", "confidence": 0.8576169610023499}]}]}