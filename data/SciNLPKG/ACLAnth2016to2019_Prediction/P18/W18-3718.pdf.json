{"title": [{"text": "A Short Answer Grading System in Chinese by Support Vector Approach", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we report a short answer grading system in Chinese.", "labels": [], "entities": []}, {"text": "We build a system based on standard machine learning approaches and test it with translated corpus from two publicly available corpus in English.", "labels": [], "entities": []}, {"text": "The experiment results show similar results on two different corpus as in English.", "labels": [], "entities": []}], "introductionContent": [{"text": "To assess the learning outcomes of students with tests in various question types and grading methods, short answer question is one type of test that can test the level of students' understanding of specific concepts in a subject domain.", "labels": [], "entities": []}, {"text": "Since grading short answer question requires natural language understanding, the test was manually graded by teachers.", "labels": [], "entities": []}, {"text": "Although technically similar to automatic essay grading, automatic short answer grading is not as mature as automatic essay grading.", "labels": [], "entities": []}, {"text": "( gives a survey on how the automatic short answer grading is dealt by various researchers.", "labels": [], "entities": []}, {"text": "The traditional approach is string matching, which could be very efficient but not very effective.", "labels": [], "entities": [{"text": "string matching", "start_pos": 28, "end_pos": 43, "type": "TASK", "confidence": 0.8500713109970093}]}, {"text": "Early work relied on regular expression patterns which were manually extracted from reference answers ().", "labels": [], "entities": []}, {"text": "The patterns included keywords in the reference answers.", "labels": [], "entities": []}, {"text": "Patterns could also be learnt from the reference answers.", "labels": [], "entities": []}, {"text": "() adopted the simpler notion of semantic alignment to avoid explicitly generating complicated patterns.", "labels": [], "entities": [{"text": "semantic alignment", "start_pos": 33, "end_pos": 51, "type": "TASK", "confidence": 0.7453673481941223}]}, {"text": "Semantic matching had also been proposed in early work (.", "labels": [], "entities": [{"text": "Semantic matching", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7720299065113068}]}, {"text": "This approach was also used by many researchers () in supervised learning machine learning.", "labels": [], "entities": [{"text": "supervised learning machine learning", "start_pos": 54, "end_pos": 90, "type": "TASK", "confidence": 0.6236750558018684}]}, {"text": "A large set of similarity measures is defined as features fora supervised learning model.", "labels": [], "entities": []}, {"text": "Features range from word level n-gram overlap to deeper semantic similarity measures based on dictionary and distributional methods.", "labels": [], "entities": []}, {"text": "The short-text grading in SemEval Semantic Textual Similarity (STS) task) drew the attention of many researchers and provided an evaluation platform.", "labels": [], "entities": [{"text": "SemEval Semantic Textual Similarity (STS) task", "start_pos": 26, "end_pos": 72, "type": "TASK", "confidence": 0.8670909553766251}]}, {"text": "Since then, several systems have been proposed for short answer grading based on the semantic similarity with given reference answers.", "labels": [], "entities": [{"text": "short answer grading", "start_pos": 51, "end_pos": 71, "type": "TASK", "confidence": 0.5913372834523519}]}, {"text": "() presented a simple short answer grading system for short answer in English.", "labels": [], "entities": []}, {"text": "Given a question and its reference answers, a system measures the correctness of a student answer by calculating the similarity with the correct answers.", "labels": [], "entities": []}, {"text": "Comparing to the field in English, there are very little research projects on short answer grading in Chinese, and there is no publicly available corpus for short answering grading in Chinese.", "labels": [], "entities": []}, {"text": "In this paper we report how we build a system and how to test it with a translated corpus from two publicly available English corpus.", "labels": [], "entities": []}, {"text": "The system first extracts the text similarity features, and the features are used in a support vector model.", "labels": [], "entities": []}, {"text": "In the first corpus, answers are graded from 0 to 5; we use support vector regression (SVR) model to learn the grading.", "labels": [], "entities": []}, {"text": "In the second corpus, answers are graded as correct/incorrect; we use a support vector machine (SVM) classifier approach to deal with it.", "labels": [], "entities": []}, {"text": "In the following sections, we will show the system architecture and experimental results.", "labels": [], "entities": []}], "datasetContent": [{"text": "Since the SciEntBank data set has 5 way labelling, we use regression model to predict the scores of the student responses.", "labels": [], "entities": [{"text": "SciEntBank data set", "start_pos": 10, "end_pos": 29, "type": "DATASET", "confidence": 0.8726360201835632}]}, {"text": "And the Data Structure Data Set has 2 way labelling, we use the classification model to predict the scores of the student responses.", "labels": [], "entities": [{"text": "Data Structure Data Set", "start_pos": 8, "end_pos": 31, "type": "DATASET", "confidence": 0.7599301636219025}]}], "tableCaptions": [{"text": " Table 1: Features used in the system", "labels": [], "entities": []}, {"text": " Table 2: Performance on the Chinse version  of the Mohler et al. (2011) dataset with in-do- main training.", "labels": [], "entities": [{"text": "Mohler et al. (2011) dataset", "start_pos": 52, "end_pos": 80, "type": "DATASET", "confidence": 0.6732417307794094}]}, {"text": " Table 3: Performance on the Chinse ver- sion of the SemEval-2013 datasets.", "labels": [], "entities": [{"text": "SemEval-2013 datasets", "start_pos": 53, "end_pos": 74, "type": "DATASET", "confidence": 0.8151112794876099}]}]}