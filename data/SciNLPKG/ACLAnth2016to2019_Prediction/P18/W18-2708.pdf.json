{"title": [{"text": "Document-Level Adaptation for Neural Machine Translation", "labels": [], "entities": [{"text": "Neural Machine Translation", "start_pos": 30, "end_pos": 56, "type": "TASK", "confidence": 0.7216742436091105}]}], "abstractContent": [{"text": "It is common practice to adapt machine translation systems to novel domains, but even a well-adapted system maybe able to perform better on a particular document if it were to learn from a translator's corrections within the document itself.", "labels": [], "entities": []}, {"text": "We focus on adaptation within a single document appropriate for an interactive translation scenario where a model adapts to a human translator's input over the course of a document.", "labels": [], "entities": []}, {"text": "We propose two methods: single-sentence adaptation (which performs online adaptation one sentence at a time) and dictionary adaptation (which specifically addresses the issue of translating novel words).", "labels": [], "entities": [{"text": "single-sentence adaptation", "start_pos": 24, "end_pos": 50, "type": "TASK", "confidence": 0.7782407701015472}, {"text": "dictionary adaptation", "start_pos": 113, "end_pos": 134, "type": "TASK", "confidence": 0.8182038068771362}]}, {"text": "Combining the two models results in improvements over both approaches individually, and over base-line systems, even on short documents.", "labels": [], "entities": []}, {"text": "On WMT news test data, we observe an improvement of +1.8 BLEU points and +23.3% novel word translation accuracy and on EMEA data (descriptions of medications) we observe an improvement of +2.7 BLEU points and +49.2% novel word translation accuracy.", "labels": [], "entities": [{"text": "WMT news test data", "start_pos": 3, "end_pos": 21, "type": "DATASET", "confidence": 0.9480325132608414}, {"text": "BLEU", "start_pos": 57, "end_pos": 61, "type": "METRIC", "confidence": 0.9959927797317505}, {"text": "word translation", "start_pos": 86, "end_pos": 102, "type": "TASK", "confidence": 0.6786751300096512}, {"text": "accuracy", "start_pos": 103, "end_pos": 111, "type": "METRIC", "confidence": 0.7662264704704285}, {"text": "EMEA data", "start_pos": 119, "end_pos": 128, "type": "DATASET", "confidence": 0.9166969954967499}, {"text": "BLEU", "start_pos": 193, "end_pos": 197, "type": "METRIC", "confidence": 0.998262345790863}, {"text": "word translation", "start_pos": 222, "end_pos": 238, "type": "TASK", "confidence": 0.7140695005655289}, {"text": "accuracy", "start_pos": 239, "end_pos": 247, "type": "METRIC", "confidence": 0.5898283123970032}]}], "introductionContent": [{"text": "The challenge of adapting to anew domain is a well-studied problem in machine translation research.", "labels": [], "entities": [{"text": "machine translation research", "start_pos": 70, "end_pos": 98, "type": "TASK", "confidence": 0.8626377383867899}]}, {"text": "But even within a particular domain, each new document may pose unique challenges due to novelty of vocabulary, word senses, style, and more.", "labels": [], "entities": []}, {"text": "1 It stands to reason that fine-grained adaptation using sentences from within a document (for example, as it is being translated by a human translator in a computer aided translation (CAT) environment) could provide the added benefit of a closer in-domain match than existing approaches that use data from other documents within the same domain.", "labels": [], "entities": [{"text": "computer aided translation (CAT) environment", "start_pos": 157, "end_pos": 201, "type": "TASK", "confidence": 0.8066632321902684}]}, {"text": "We propose two complementary approaches to the treatment of novel words and fine-grained document-level adaptation of machine translation systems, and show that the combination of approaches outperforms each approach individually, resulting in BLEU point improvements of +1.8 and +2.7 across two domains, in addition to demonstrating improvements in novel word translation accuracy.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 118, "end_pos": 137, "type": "TASK", "confidence": 0.7252901345491409}, {"text": "BLEU point", "start_pos": 244, "end_pos": 254, "type": "METRIC", "confidence": 0.9712287485599518}, {"text": "novel word translation", "start_pos": 350, "end_pos": 372, "type": "TASK", "confidence": 0.6499834259351095}, {"text": "accuracy", "start_pos": 373, "end_pos": 381, "type": "METRIC", "confidence": 0.5935664176940918}]}, {"text": "As Carpuat (2009) observed, there is a tendency for translators to produce translations such that the \"one translation per discourse\" hypothesis holds within a particular document.", "labels": [], "entities": []}, {"text": "That is, human translators tend to prefer consistent translations of individual terms throughout a document.", "labels": [], "entities": []}, {"text": "Other work on \"translationese\" has also found that translations show regularities in syntax and punctuation ().", "labels": [], "entities": []}, {"text": "Thus, even expanding beyond words with multiple senses, we expect that learning from the translator's lexical, syntactic, and stylistic choices at the beginning of a document should result in a well-tailored system that is better at translating subsequent sentences.", "labels": [], "entities": []}, {"text": "We can think of fine-grained adaptation over a document as producing a document-specific machine translation system that encodes or highlights document context.", "labels": [], "entities": [{"text": "document-specific machine translation", "start_pos": 71, "end_pos": 108, "type": "TASK", "confidence": 0.6480337778727213}]}, {"text": "Continued training of neural machine translation (NMT) systems has been shown to bean effective and efficient way to tune them fora specific target domain (.", "labels": [], "entities": [{"text": "neural machine translation (NMT)", "start_pos": 22, "end_pos": 54, "type": "TASK", "confidence": 0.8513270815213522}]}, {"text": "One such technique is incremental updating -comparing the system's predicted translation of an input sentence to a reference translation and then updat-: Examples of novel words and their mistranslations.", "labels": [], "entities": []}, {"text": "The subword segmentation (in parentheses) is indicated by \"/\" for the source and reference.", "labels": [], "entities": [{"text": "subword segmentation", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.7281208634376526}]}, {"text": "ing the model parameters to improve future predictions.", "labels": [], "entities": []}, {"text": "Though this is typically done in batches during training, a single sentence pair or even a word and its translation can be treated as a training instance.", "labels": [], "entities": []}, {"text": "Computer aided translation provides an ideal use case for exploring model adaptation at such a fine granularity.", "labels": [], "entities": [{"text": "model adaptation", "start_pos": 68, "end_pos": 84, "type": "TASK", "confidence": 0.758134126663208}]}, {"text": "As a human translator works, each sentence that they translate (or each novel word for which they provide a translation) can then be used as anew training example fora neural machine translation system.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 175, "end_pos": 194, "type": "TASK", "confidence": 0.7667593359947205}]}, {"text": "In an interactive translation setting or a post-editing scenario, rapid incremental updating of the neural model will allow the neural system to adapt to an individual translator, a particular new domain, or novel vocabulary over the course of a document.", "labels": [], "entities": []}, {"text": "In an open-vocabulary NMT system that uses byte-pair encoding), tokens that were never seen in training data are represented as sequences of known subword units.", "labels": [], "entities": []}, {"text": "These may sometimes be successfully translated (or copied, subword by subword, when appropriate) on the first try, but sometimes systems generate incorrect translations or even nonsensical words.", "labels": [], "entities": []}, {"text": "shows example mistranslations of novel words.", "labels": [], "entities": []}, {"text": "We test our two complementary approaches to document-level NMT adaptation (dictionary training and single-sentence adaptation) on two very different domains: news and formal descriptions of medications, each of which provide their own challenges.", "labels": [], "entities": [{"text": "NMT adaptation", "start_pos": 59, "end_pos": 73, "type": "TASK", "confidence": 0.9143328368663788}, {"text": "single-sentence adaptation", "start_pos": 99, "end_pos": 125, "type": "TASK", "confidence": 0.8003385365009308}]}, {"text": "In our datasets, just under 80% of news documents and just over 90% of medical documents contain at least one word that was unobserved in the training data.", "labels": [], "entities": []}, {"text": "In the news documents, 12.8% of lines contain at least one novel word, whereas in the medical data, 38.3% of lines contain at least one novel word.", "labels": [], "entities": []}, {"text": "We show that models can learn to correctly translate novel vocabulary items and can adapt to document-specific terminology usage and style, even in short documents.", "labels": [], "entities": []}], "datasetContent": [{"text": "The two domains and their respective baseline models provide us two distinct scenarios to evaluate our methodology.", "labels": [], "entities": []}, {"text": "Both simulate a relatively data-rich realistic setting in which translators have completed translations of in-domain data and continue to work on new documents (with novel terminology) within that domain.", "labels": [], "entities": []}, {"text": "Each domain provides its own challenges: the WMT data covers a wide range of topics and sources of news stories, while the EMEA data includes highly technical medical vocabulary, presented in fairly consistent ways.", "labels": [], "entities": [{"text": "WMT data", "start_pos": 45, "end_pos": 53, "type": "DATASET", "confidence": 0.7655641436576843}, {"text": "EMEA data", "start_pos": 123, "end_pos": 132, "type": "DATASET", "confidence": 0.9417290985584259}]}, {"text": "Due to the way our EMEA data splits were produced, this in particular means that the new EMEA documents will likely contain novel vocabulary (such as names of medications and other specific terminology).", "labels": [], "entities": [{"text": "EMEA data splits", "start_pos": 19, "end_pos": 35, "type": "DATASET", "confidence": 0.8739044467608134}]}, {"text": "Similarly, we expect news stories to cover new names, locations, and more as news breaks overtime.", "labels": [], "entities": []}, {"text": "For hyperparameter optimization, we did a complete grid search over a span of learning rates (0.1, 0.01, 0.001, 0.0001, 0.00001), train epochs, and optimizers (Adam, SGD) on WMT data and a partial search on EMEA data.", "labels": [], "entities": [{"text": "hyperparameter optimization", "start_pos": 4, "end_pos": 31, "type": "TASK", "confidence": 0.8422021865844727}, {"text": "WMT data", "start_pos": 174, "end_pos": 182, "type": "DATASET", "confidence": 0.8907813727855682}, {"text": "EMEA data", "start_pos": 207, "end_pos": 216, "type": "DATASET", "confidence": 0.9578238725662231}]}, {"text": "We use BLEU () to measure the effect of adaptation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 7, "end_pos": 11, "type": "METRIC", "confidence": 0.9988240599632263}]}, {"text": "We found the optimum configurations (optim, lr, epochs) of (SGD, 0.01, 5) for EMEA 9 and (SGD, 0.1, 20) for WMT.", "labels": [], "entities": [{"text": "EMEA 9", "start_pos": 78, "end_pos": 84, "type": "DATASET", "confidence": 0.8480486571788788}, {"text": "WMT", "start_pos": 108, "end_pos": 111, "type": "TASK", "confidence": 0.6225152015686035}]}, {"text": "The difference in optimum configurations can be partly attributed to the different domains of the two datasets.", "labels": [], "entities": []}, {"text": "We note that the best EMEA configuration matched the second-best WMT one.", "labels": [], "entities": [{"text": "WMT", "start_pos": 65, "end_pos": 68, "type": "TASK", "confidence": 0.6718232035636902}]}, {"text": "For the EMEA dictionary experiments, we completed a grid search over number of epochs (1, 2, 5, 10) and learning rate (0.1, 0.5, 1.0) using SGD as the optimizer.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 104, "end_pos": 117, "type": "METRIC", "confidence": 0.9439328908920288}]}, {"text": "Finding consistent results, we ran a smaller grid search (epochs: 2 and 5 and learning rates 0.1, 0.5, and 1.0) over a development set of the first 20 documents from WMT 2016.", "labels": [], "entities": [{"text": "WMT 2016", "start_pos": 166, "end_pos": 174, "type": "DATASET", "confidence": 0.8562119603157043}]}, {"text": "Setting the learning rate and/or number of epochs too low resulted in minimal changes, while setting them too high resulted in pathological overfitting (loops of repeated tokens, etc.).", "labels": [], "entities": []}, {"text": "Based on these initial experiments, we set a learning rate of 0.5 for both data sets, with 5 epochs for EMEA data and 2 epochs for WMT data.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 45, "end_pos": 58, "type": "METRIC", "confidence": 0.9337230026721954}, {"text": "EMEA data", "start_pos": 104, "end_pos": 113, "type": "DATASET", "confidence": 0.8654367923736572}, {"text": "WMT data", "start_pos": 131, "end_pos": 139, "type": "DATASET", "confidence": 0.7056894153356552}]}, {"text": "The parameters chosen were those that maximized BLEU score on the development sets.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 48, "end_pos": 58, "type": "METRIC", "confidence": 0.9703436195850372}]}, {"text": "We compare our dictionary training approach against an approach that uses the same dictionaries During hyperparameter selection, document lengths were clipped to the first 60 lines.", "labels": [], "entities": [{"text": "hyperparameter selection", "start_pos": 103, "end_pos": 127, "type": "TASK", "confidence": 0.7320227324962616}]}, {"text": "We also considered lower learning rates (0.01, 0.001, 0.0001), but found that they did not result in much, if any, change to the model.: Results of baseline and dictionary training across the full set of EMEA test documents.", "labels": [], "entities": [{"text": "EMEA test documents", "start_pos": 204, "end_pos": 223, "type": "DATASET", "confidence": 0.9374720652898153}]}, {"text": "Accuracy is computed for novel words only.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9957041144371033}]}, {"text": "Here we combine the approaches: for every document, we first do dictionary training.", "labels": [], "entities": [{"text": "dictionary training", "start_pos": 64, "end_pos": 83, "type": "TASK", "confidence": 0.815443366765976}]}, {"text": "Using that as the starting point, we perform single sentence adaptation.", "labels": [], "entities": [{"text": "single sentence adaptation", "start_pos": 45, "end_pos": 71, "type": "TASK", "confidence": 0.6276465753714243}]}, {"text": "We use the best hyperparameters obtained from the grid search for the individual methods.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Complementary nature of two approaches: single-sentence approach learns the preferred trans- lation of \"while taking\" (\"W\u00e4hrend der Behandlung\"), but mistranslates Siklos as Ivlos. Dictionary  training produces Siklos correctly, but makes no other changes. Combined, the overall translation is  improved, though it would still require post-editing for correctness.", "labels": [], "entities": []}, {"text": " Table 3: Results of baseline and dictionary train- ing across the full set of EMEA test documents.  Accuracy is computed for novel words only.", "labels": [], "entities": [{"text": "EMEA test documents", "start_pos": 79, "end_pos": 98, "type": "DATASET", "confidence": 0.9473863641421}, {"text": "Accuracy", "start_pos": 101, "end_pos": 109, "type": "METRIC", "confidence": 0.9993575215339661}]}, {"text": " Table 4: Results of baseline and dictionary train- ing across the full set of WMT test documents.  Accuracy is computed for novel words only.", "labels": [], "entities": [{"text": "dictionary train- ing", "start_pos": 34, "end_pos": 55, "type": "TASK", "confidence": 0.5586991831660271}, {"text": "WMT test documents", "start_pos": 79, "end_pos": 97, "type": "DATASET", "confidence": 0.7733938694000244}, {"text": "Accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.9993402361869812}]}, {"text": " Table 5: Novel word accuracy divided into tokens  to be copied (Copy) vs. translated (Trans.).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9442133903503418}]}]}