{"title": [{"text": "Discourse Marker Augmented Network with Reinforcement Learning for Natural Language Inference", "labels": [], "entities": [{"text": "Discourse Marker Augmented Network", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8055006042122841}, {"text": "Natural Language Inference", "start_pos": 67, "end_pos": 93, "type": "TASK", "confidence": 0.7086463967959086}]}], "abstractContent": [{"text": "Natural Language Inference (NLI), also known as Recognizing Textual Entailment (RTE), is one of the most important problems in natural language processing.", "labels": [], "entities": [{"text": "Natural Language Inference (NLI)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7703516433636347}, {"text": "Recognizing Textual Entailment (RTE)", "start_pos": 48, "end_pos": 84, "type": "TASK", "confidence": 0.6953270584344864}, {"text": "natural language processing", "start_pos": 127, "end_pos": 154, "type": "TASK", "confidence": 0.6390648086865743}]}, {"text": "It requires to infer the logical relationship between two given sentences.", "labels": [], "entities": []}, {"text": "While current approaches mostly focus on the interaction architectures of the sentences, in this paper, we propose to transfer knowledge from some important discourse markers to augment the quality of the NLI model.", "labels": [], "entities": []}, {"text": "We observe that people usually use some discourse markers such as \"so\" or \"but\" to represent the logical relationship between two sentences.", "labels": [], "entities": []}, {"text": "These words potentially have deep connections with the meanings of the sentences, thus can be utilized to help improve the representations of them.", "labels": [], "entities": []}, {"text": "Moreover, we use reinforcement learning to optimize anew objective function with a reward defined by the property of the NLI datasets to make full use of the labels information.", "labels": [], "entities": [{"text": "NLI datasets", "start_pos": 121, "end_pos": 133, "type": "DATASET", "confidence": 0.892053484916687}]}, {"text": "Experiments show that our method achieves the state-of-the-art performance on several large-scale datasets.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper, we focus on the task of Natural Language Inference (NLI), which is known as a significant yet challenging task for natural language understanding.", "labels": [], "entities": [{"text": "Natural Language Inference (NLI)", "start_pos": 39, "end_pos": 71, "type": "TASK", "confidence": 0.8102716207504272}, {"text": "natural language understanding", "start_pos": 130, "end_pos": 160, "type": "TASK", "confidence": 0.6662512123584747}]}, {"text": "In this task, we are given two sentences which are respectively called premise and hypothesis.", "labels": [], "entities": []}, {"text": "The goal is to determine whether the logical relationship between them is entailment, neutral, or contradiction.", "labels": [], "entities": []}, {"text": "Recently, performance on NLI()", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Statistics of the labels of SNLI and  MuliNLI. Total means the number of examples  whose number of annotators is in the left column.", "labels": [], "entities": [{"text": "MuliNLI", "start_pos": 48, "end_pos": 55, "type": "DATASET", "confidence": 0.890835702419281}]}, {"text": " Table 3: Statistics of discouse markers in our  dataset from BookCorpus.", "labels": [], "entities": [{"text": "BookCorpus", "start_pos": 62, "end_pos": 72, "type": "DATASET", "confidence": 0.9109371304512024}]}, {"text": " Table 4: Performance on the SNLI dataset and the MultiNLI dataset. In the top part, we show sentence  encoding-based models; In the medium part, we present the performance of integrated neural network  models; In the bottom part, we show the results of ensemble models.", "labels": [], "entities": [{"text": "SNLI dataset", "start_pos": 29, "end_pos": 41, "type": "DATASET", "confidence": 0.847167581319809}, {"text": "MultiNLI dataset", "start_pos": 50, "end_pos": 66, "type": "DATASET", "confidence": 0.9662297070026398}]}, {"text": " Table 5: Ablations on the SNLI development  dataset.", "labels": [], "entities": [{"text": "Ablations", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.956378161907196}, {"text": "SNLI development  dataset", "start_pos": 27, "end_pos": 52, "type": "DATASET", "confidence": 0.7096999287605286}]}]}