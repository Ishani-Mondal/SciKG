{"title": [{"text": "MOJITALK: Generating Emotional Responses at Scale", "labels": [], "entities": []}], "abstractContent": [{"text": "Generating emotional language is a key step towards building empathetic natural language processing agents.", "labels": [], "entities": []}, {"text": "However, a major challenge for this line of research is the lack of large-scale labeled training data, and previous studies are limited to only small sets of human annotated sentiment labels.", "labels": [], "entities": []}, {"text": "Additionally, explicitly controlling the emotion and sentiment of generated text is also difficult.", "labels": [], "entities": []}, {"text": "In this paper, we take a more radical approach: we exploit the idea of leveraging Twitter data that are naturally labeled with emojis.", "labels": [], "entities": []}, {"text": "We collect a large corpus of Twitter conversations that include emojis in the response and assume the emojis convey the underlying emotions of the sentence.", "labels": [], "entities": []}, {"text": "We investigate several conditional variational autoencoders training on these conversations , which allow us to use emojis to control the emotion of the generated text.", "labels": [], "entities": []}, {"text": "Experimentally , we show in our quantitative and qualitative analyses that the proposed models can successfully generate high-quality abstractive conversation responses in accordance with designated emotions.", "labels": [], "entities": []}], "introductionContent": [{"text": "A critical research problem for artificial intelligence is to design intelligent agents that can perceive and generate human emotions.", "labels": [], "entities": []}, {"text": "In the past decade, there has been significant progress in sentiment analysis ( and natural language understanding-e.g., classifying the sentiment of online reviews.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.9568975865840912}, {"text": "natural language understanding-e.g.", "start_pos": 84, "end_pos": 119, "type": "TASK", "confidence": 0.7065747380256653}, {"text": "classifying the sentiment of online reviews", "start_pos": 121, "end_pos": 164, "type": "TASK", "confidence": 0.8772203326225281}]}, {"text": "To build empathetic conversational agents, machines must also have the ability to learn to generate emotional sentences.", "labels": [], "entities": []}, {"text": "One of the major challenges is the lack of largescale, manually labeled emotional text datasets.", "labels": [], "entities": []}, {"text": "Due to the cost and complexity of manual annotation, most prior research studies primarily focus on small-sized labeled datasets (), which are not ideal for training deep learning models with a large number of parameters.", "labels": [], "entities": []}, {"text": "In recent years, a handful of medium to large scale, emotional corpora in the area of emotion analysis () and dialog () are proposed.", "labels": [], "entities": [{"text": "emotion analysis", "start_pos": 86, "end_pos": 102, "type": "TASK", "confidence": 0.7284911721944809}]}, {"text": "However, all of them are limited to a traditional, small set of labels, for example, \"happiness,\" \"sadness,\" \"anger,\" etc. or simply binary \"positive\" and \"negative.\"", "labels": [], "entities": []}, {"text": "Such coarse-grained classification labels make it difficult to capture the nuances of human emotion.", "labels": [], "entities": []}, {"text": "To avoid the cost of human annotation, we propose the use of naturally-occurring emoji-rich Twitter data.", "labels": [], "entities": []}, {"text": "We construct a dataset using Twitter conversations with emojis in the response.", "labels": [], "entities": []}, {"text": "The fine-grained emojis chosen by the users in the response can be seen as the natural label for the emotion of the response.", "labels": [], "entities": []}, {"text": "We assume that the emotions and nuances of emojis are established through the extensive usage by Twitter users.", "labels": [], "entities": []}, {"text": "If we can create agents that are able to imitate Twitter users' language style when using those emojis, we claim that, to some extent, we have captured those emotions.", "labels": [], "entities": []}, {"text": "Using a large collection of Twitter conversations, we then trained a conditional generative model to automatically generate the emotional responses.", "labels": [], "entities": []}, {"text": "To generate emotional responses in dialogs, another technical challenge is to control the target emotion labels.", "labels": [], "entities": []}, {"text": "In contrast to existing work () that uses information retrieval to generate emotional responses, the research question we are pursuing in this paper, is to design novel techniques that can generate abstractive responses of any given arbitrary emotions, without having human annotators to label a huge amount of training data.", "labels": [], "entities": []}, {"text": "To control the target emotion of the response, we investigate several encoder-decoder generation models, including a standard attention-based SEQ2SEQ model as the base model, and a more sophisticated CVAE model (, as VAE is recently found convenient in dialog generation (.", "labels": [], "entities": [{"text": "dialog generation", "start_pos": 253, "end_pos": 270, "type": "TASK", "confidence": 0.8156300783157349}]}, {"text": "To explicitly improve emotion expression, we then experiment with several extensions to the CVAE model, including a hybrid objective with policy gradient.", "labels": [], "entities": [{"text": "emotion expression", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.6969444751739502}]}, {"text": "The performance in emotion expression is automatically evaluated by a separate sentence-to-emoji classifier.", "labels": [], "entities": []}, {"text": "Additionally, we conducted a human evaluation to assess the quality of the generated emotional text.", "labels": [], "entities": []}, {"text": "Results suggest that our method is capable of generating state-of-the-art emotional text at scale.", "labels": [], "entities": []}, {"text": "Our main contributions are three-fold: \u2022 We provide a publicly available, large-scale dataset of Twitter conversation-pairs naturally labeled with fine-grained emojis.", "labels": [], "entities": []}, {"text": "\u2022 We are the first to use naturally labeled emojis for conducting large-scale emotional response generation for dialog.", "labels": [], "entities": [{"text": "emotional response generation", "start_pos": 78, "end_pos": 107, "type": "TASK", "confidence": 0.7078097462654114}]}, {"text": "\u2022 We apply several state-of-the-art generative models to train an emotional response generation system, and analysis confirms that our models deliver strong performance.", "labels": [], "entities": [{"text": "emotional response generation", "start_pos": 66, "end_pos": 95, "type": "TASK", "confidence": 0.6854683955510458}]}, {"text": "In the next section, we outline related work on sentiment analysis and emoji on Twitter data, as well as neural generative models.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.956877589225769}]}, {"text": "Then, we will introduce our new emotional research dataset and formalize the task.", "labels": [], "entities": []}, {"text": "Next, we will describe the neural models we applied for the task.", "labels": [], "entities": []}, {"text": "Finally, we will show automatic evaluation and human evaluation results, and some generated examples.", "labels": [], "entities": []}, {"text": "Experiment details can be found in supplementary materials.", "labels": [], "entities": []}], "datasetContent": [{"text": "We start by describing our dataset and approaches to collecting and processing the data.", "labels": [], "entities": []}, {"text": "Social media is a natural source of conversations, and people use emojis extensively within their posts.", "labels": [], "entities": []}, {"text": "However, not all emojis are used to express emotion and frequency of emojis are unevenly distributed.", "labels": [], "entities": []}, {"text": "Inspired by, we use 64 common emojis as labels (see), and collect a large corpus of Twitter conversations conBefore: @amy miss you soooo much!!!", "labels": [], "entities": []}, {"text": "After: miss you soo much!", "labels": [], "entities": []}, {"text": "Label: Figure 2: An artificial example illustrating preprocess procedure and choice of emoji label.", "labels": [], "entities": []}, {"text": "Note that emoji occurrences in responses are counted before the deduplication process.", "labels": [], "entities": []}, {"text": "Note that emojis with the difference only in skin tone are considered the same emoji.", "labels": [], "entities": []}, {"text": "We conducted several experiments to finalize the hyper-parameters of our models.", "labels": [], "entities": []}, {"text": "During training, fully converged base SEQ2SEQ model is used to initialize its counterparts in CVAE models.", "labels": [], "entities": []}, {"text": "Pretraining is vital to the success of our models since it is essentially hard for them to learn a latent variable space from total randomness.", "labels": [], "entities": [{"text": "Pretraining", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9766561388969421}]}, {"text": "For more details, please refer to the supplementary materials.", "labels": [], "entities": []}, {"text": "In this section, we first report and analyze the general results of our models, including perplexity, loss and emotion accuracy.", "labels": [], "entities": [{"text": "loss", "start_pos": 102, "end_pos": 106, "type": "METRIC", "confidence": 0.9463363885879517}, {"text": "accuracy", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.9721125364303589}]}, {"text": "Then we take a closer look at the generation quality as well as our models' capability of expressing emotion.", "labels": [], "entities": []}, {"text": "We employed crowdsourced judges to evaluate a random sample of 100 items, each being assigned to 5 judges on the Amazon Mechanical Turk.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk", "start_pos": 113, "end_pos": 135, "type": "DATASET", "confidence": 0.954612652460734}]}, {"text": "We present judges original tweets and generated responses.", "labels": [], "entities": []}, {"text": "In the first setting of human evaluation, judges are asked to decide which one of the two generated responses better reply the original tweet.", "labels": [], "entities": []}, {"text": "In the second setting, the emoji label is presented with the item discription, and judges are asked to pick one of the two generated responses that they decide better fits this emoji.", "labels": [], "entities": []}, {"text": "(These two settings of evaluation are conducted separately so that it will not affect judges' verdicts.)", "labels": [], "entities": []}, {"text": "Order of two generated responses under one item is permuted.", "labels": [], "entities": []}, {"text": "Ties are permitted for an-: Some examples from our generated emotional responses.", "labels": [], "entities": [{"text": "Ties", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9754287004470825}]}, {"text": "Context is the original tweet, and target emotion is specified by the emoji.", "labels": [], "entities": []}, {"text": "Following are the responses generated by each of the three models based on the context and the target emotion. swers.", "labels": [], "entities": []}, {"text": "We batch five items as one assignment and insert an item with two identical outputs as the sanity check.", "labels": [], "entities": []}, {"text": "Anyone who failed to choose \"tie\" for that item is considered as a careless judge and is therefore rejected from our test.", "labels": [], "entities": [{"text": "tie", "start_pos": 29, "end_pos": 32, "type": "METRIC", "confidence": 0.9735572338104248}]}, {"text": "We then conducted a simplified Turing test.", "labels": [], "entities": []}, {"text": "Each item we present judges an original tweet, its reply by a human, and its response generated from Reinforced CVAE model.", "labels": [], "entities": []}, {"text": "We ask judges to decide which of the two given responses is written by a human.", "labels": [], "entities": []}, {"text": "Other parts of the setting are similar to above-mentioned tests.", "labels": [], "entities": []}, {"text": "It turned out 18% of the test subjects mistakenly chose machine-generated responses as human written, and 27% stated that they were notable to distinguish between the two responses.", "labels": [], "entities": []}, {"text": "In regard of the inter-rater agreement, there are four cases.", "labels": [], "entities": []}, {"text": "The ideal situation is that all five judges choose the same answer fora item, and in the worst-case scenario, at most two judges choose the same answer.", "labels": [], "entities": []}, {"text": "In light of this, we have counted that 32%/33%/31%/5% of all items have 5/4/3/2 judges in agreement, showing that our experiment has a reasonably reliable inter-rater agreement.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: All 64 emoji labels, and number of con- versations labeled by each emoji.", "labels": [], "entities": []}, {"text": " Table 2: Generation perplexity and emoji accuracy  of the three models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9922758936882019}]}, {"text": " Table 3: Type-token ratios of the generation by  the three models. Scores of tokenized human- generated target responses are given for reference.", "labels": [], "entities": []}, {"text": " Table 4: Results of human evaluation. Tests are  conducted pairwise between CVAE models and  the base model.", "labels": [], "entities": []}]}