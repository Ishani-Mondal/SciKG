{"title": [], "abstractContent": [{"text": "We investigate a lattice-structured LSTM model for Chinese NER, which encodes a sequence of input characters as well as all potential words that match a lexicon.", "labels": [], "entities": []}, {"text": "Compared with character-based methods, our model explicitly leverages word and word sequence information.", "labels": [], "entities": []}, {"text": "Compared with word-based methods, lattice LSTM does not suffer from segmentation errors.", "labels": [], "entities": []}, {"text": "Gated recurrent cells allow our model to choose the most relevant characters and words from a sentence for better NER results.", "labels": [], "entities": [{"text": "NER", "start_pos": 114, "end_pos": 117, "type": "TASK", "confidence": 0.9730191230773926}]}, {"text": "Experiments on various datasets show that lattice LSTM outperforms both word-based and character-based LSTM baselines, achieving the best results.", "labels": [], "entities": []}], "introductionContent": [{"text": "As a fundamental task in information extraction, named entity recognition (NER) has received constant research attention over the recent years.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.8446439206600189}, {"text": "named entity recognition (NER)", "start_pos": 49, "end_pos": 79, "type": "TASK", "confidence": 0.7877067476511002}]}, {"text": "The task has traditionally been solved as a sequence labeling problem, where entity boundary and category labels are jointly predicted.", "labels": [], "entities": [{"text": "sequence labeling problem", "start_pos": 44, "end_pos": 69, "type": "TASK", "confidence": 0.7076518138249716}]}, {"text": "The current stateof-the-art for English NER has been achieved by using LSTM-CRF models () with character information being integrated into word representations.", "labels": [], "entities": [{"text": "NER", "start_pos": 40, "end_pos": 43, "type": "TASK", "confidence": 0.5716990232467651}]}, {"text": "Chinese NER is correlated with word segmentation.", "labels": [], "entities": [{"text": "NER", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.48778271675109863}, {"text": "word segmentation", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.7066295742988586}]}, {"text": "In particular, named entity boundaries are also word boundaries.", "labels": [], "entities": []}, {"text": "One intuitive way of performing Chinese NER is to perform word segmentation first, before applying word sequence labeling.", "labels": [], "entities": [{"text": "Chinese NER", "start_pos": 32, "end_pos": 43, "type": "TASK", "confidence": 0.5134115219116211}, {"text": "word segmentation", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.7509163916110992}, {"text": "word sequence labeling", "start_pos": 99, "end_pos": 121, "type": "TASK", "confidence": 0.6100329160690308}]}, {"text": "The segmentation \u2192 NER pipeline, however, can suffer the potential issue of error propagation, since NEs are an important source of OOV", "labels": [], "entities": [{"text": "segmentation \u2192 NER", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.8520646691322327}, {"text": "error propagation", "start_pos": 76, "end_pos": 93, "type": "TASK", "confidence": 0.7138865441083908}, {"text": "OOV", "start_pos": 132, "end_pos": 135, "type": "TASK", "confidence": 0.4523202180862427}]}], "datasetContent": [{"text": "We carryout an extensive set of experiments to investigate the effectiveness of word-character lattice LSTMs across different domains.", "labels": [], "entities": []}, {"text": "In addition, we aim to empirically compare word-based and character-based neural Chinese NER under different settings.", "labels": [], "entities": [{"text": "character-based neural Chinese NER", "start_pos": 58, "end_pos": 92, "type": "TASK", "confidence": 0.5401903539896011}]}, {"text": "Standard precision (P), recall (R) and F1-score (F1) are used as evaluation metrics.", "labels": [], "entities": [{"text": "precision (P)", "start_pos": 9, "end_pos": 22, "type": "METRIC", "confidence": 0.9385461211204529}, {"text": "recall (R)", "start_pos": 24, "end_pos": 34, "type": "METRIC", "confidence": 0.9606342166662216}, {"text": "F1-score (F1)", "start_pos": 39, "end_pos": 52, "type": "METRIC", "confidence": 0.939472109079361}]}, {"text": ", which consists of resumes of senior executives from listed companies in the Chinese stock market.", "labels": [], "entities": []}, {"text": "We randomly selected 1027 resume summaries and manually annotated 8 types of named entities.", "labels": [], "entities": []}, {"text": "Statistics of the dataset is shown in.", "labels": [], "entities": []}, {"text": "The inter-annotator agreement is 97.1%.", "labels": [], "entities": []}, {"text": "We release this dataset as a resource for further research.", "labels": [], "entities": []}, {"text": "For the OntoNotes and MSRA datasets, gold-standard segmentation is available in the training sections.", "labels": [], "entities": [{"text": "MSRA datasets", "start_pos": 22, "end_pos": 35, "type": "DATASET", "confidence": 0.8621344268321991}]}, {"text": "For OntoNotes, gold segmentation is also available for the development and test sections.", "labels": [], "entities": []}, {"text": "On the other hand, no segmentation is available for the MSRA test sections, nor the Weibo / resume datasets.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 22, "end_pos": 34, "type": "TASK", "confidence": 0.9651737809181213}, {"text": "MSRA test sections", "start_pos": 56, "end_pos": 74, "type": "DATASET", "confidence": 0.9397971431414286}, {"text": "Weibo / resume datasets", "start_pos": 84, "end_pos": 107, "type": "DATASET", "confidence": 0.9260218143463135}]}, {"text": "As a result, OntoNotes is leveraged for studying oracle situations where gold segmentation is given.", "labels": [], "entities": [{"text": "gold segmentation", "start_pos": 73, "end_pos": 90, "type": "TASK", "confidence": 0.6811639964580536}]}, {"text": "We use the neural word segmentor of to automatically segment the development and test sets for word-based NER.", "labels": [], "entities": []}, {"text": "In particular, for the OntoNotes and MSRA datasets, we train the segmentor using gold segmentation on their respective training sets.", "labels": [], "entities": [{"text": "OntoNotes", "start_pos": 23, "end_pos": 32, "type": "DATASET", "confidence": 0.8621203899383545}, {"text": "MSRA datasets", "start_pos": 37, "end_pos": 50, "type": "DATASET", "confidence": 0.9112445116043091}]}, {"text": "For Weibo and resume, we take the best model of off the shelf 5 , which is trained using CTB 6.0 (  Word Embeddings.", "labels": [], "entities": [{"text": "Weibo", "start_pos": 4, "end_pos": 9, "type": "DATASET", "confidence": 0.947623610496521}]}, {"text": "We pretrain word embeddings using word2vec () over automatically segmented Chinese Giga-Word 6 , obtaining 704.4k words in a final lexicon.", "labels": [], "entities": []}, {"text": "In particular, the number of single-character, twocharacter and three-character words are 5.7k, 291.5k, 278.1k, respectively.", "labels": [], "entities": []}, {"text": "The embedding lexicon is released alongside our code and models as a resource for further research.", "labels": [], "entities": []}, {"text": "Word embeddings are fine-tuned during NER training.", "labels": [], "entities": [{"text": "NER training", "start_pos": 38, "end_pos": 50, "type": "TASK", "confidence": 0.8831456899642944}]}, {"text": "Character and character bigram embeddings are pretrained on Chinese Giga-Word using word2vec and finetuned at model training.", "labels": [], "entities": [{"text": "Chinese Giga-Word", "start_pos": 60, "end_pos": 77, "type": "DATASET", "confidence": 0.8694031238555908}]}, {"text": "shows the values of hyper-parameters for our models, which as fixed according to previous work in the literature without grid-search adjustments for each individual dataset.", "labels": [], "entities": []}, {"text": "In particular, the embedding sizes are set to 50 and the hidden size of LSTM models to 200.", "labels": [], "entities": []}, {"text": "Dropout () is applied to both word and character embeddings with a rate of 0.5.", "labels": [], "entities": []}, {"text": "Stochastic gradient descent (SGD) is used for optimization, with an initial learning rate of 0.015 and a decay rate of 0.05.", "labels": [], "entities": [{"text": "Stochastic gradient descent (SGD)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.731859435637792}, {"text": "initial learning rate", "start_pos": 68, "end_pos": 89, "type": "METRIC", "confidence": 0.7559396028518677}]}, {"text": "We compare various model configurations on the OntoNotes development set, in order to select the best settings for word-based and character-based NER models, and to learn the influence of lattice word information on character-based models.", "labels": [], "entities": [{"text": "OntoNotes development set", "start_pos": 47, "end_pos": 72, "type": "DATASET", "confidence": 0.8892257213592529}]}, {"text": "As shown in, without using word segmentation, a characterbased LSTM-CRF model gives a development F1-score of 62.47%.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.7080845385789871}, {"text": "F1-score", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9018562436103821}]}, {"text": "Adding character-bigram and softword representations as described in Section 3.1 increases the F1-score to 67.63% and 65.71%, respectively, demonstrating the usefulness of both sources of information.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9991135001182556}]}, {"text": "In addition, a combination of both gives a 69.64% F1-score, which is the best 6 https://catalog.ldc.upenn.edu/ LDC2011T13  Word-based NER.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9991869330406189}, {"text": "LDC2011T13  Word-based NER", "start_pos": 111, "end_pos": 137, "type": "DATASET", "confidence": 0.6004464824994405}]}, {"text": "shows a variety of different settings for word-based Chinese NER.", "labels": [], "entities": [{"text": "word-based Chinese NER", "start_pos": 42, "end_pos": 64, "type": "TASK", "confidence": 0.4197862446308136}]}, {"text": "With automatic segmentation, a word-based LSTM CRF baseline gives a 64.12% F1-score, which is higher compared to the character-based baseline.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.999200165271759}]}, {"text": "This demonstrates that both word information and character information are useful for Chinese NER.", "labels": [], "entities": [{"text": "Chinese NER", "start_pos": 86, "end_pos": 97, "type": "TASK", "confidence": 0.46568048000335693}]}, {"text": "The two methods of using character LSTM to enrich word representations in Section 3.2, namely word+char LSTM and word+char LSTM , lead to similar improvements.", "labels": [], "entities": []}, {"text": "A CNN representation of character sequences gives a slightly higher F1-score compared to LSTM character representations.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9996615648269653}]}, {"text": "On the other hand, further using character bigram information leads to increased F1-score over word+char LSTM, but decreased F1-score over word+char CNN.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9995396137237549}, {"text": "F1-score", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.9986242055892944}]}, {"text": "A possible reason is that CNN inherently captures character n-gram information.", "labels": [], "entities": [{"text": "CNN", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.8823304772377014}]}, {"text": "As a result, we use word+char+bichar LSTM for wordbased NER in the remaining experiments, which gives the best development results, and is structurally consistent with the state-of-the-art English NER models in the literature.", "labels": [], "entities": []}, {"text": "shows the F1-score of character-based and lattice-based models against the number of training iterations.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9993263483047485}]}, {"text": "We include models that use concatenated character and character bigram embeddings, where bigrams can play a role in disambiguating characters.", "labels": [], "entities": []}, {"text": "As can be seen from the figure, lattice word information is useful for improving character-based NER, improving the best development result from 62.5% to 71.6%.", "labels": [], "entities": [{"text": "NER", "start_pos": 97, "end_pos": 100, "type": "TASK", "confidence": 0.8267098069190979}]}, {"text": "On the other hand, the bigram-enhanced lattice model does not lead to further improvements compared with the original lattice model.", "labels": [], "entities": []}, {"text": "This is likely because words are better sources of information for character disambiguation compared with bigrams, which are also ambiguous.", "labels": [], "entities": [{"text": "character disambiguation", "start_pos": 67, "end_pos": 91, "type": "TASK", "confidence": 0.7754861116409302}]}, {"text": "As shown in, the lattice LSTM-CRF model gives a development F1-score of 71.62%, which is significantly 7 higher compared with both the word-based and character-based methods, despite that it does not use character bigrams or word segmentation information.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9474263787269592}, {"text": "word segmentation", "start_pos": 225, "end_pos": 242, "type": "TASK", "confidence": 0.6919603049755096}]}, {"text": "The fact that it significantly outperforms char+softword shows the advantage of lattice word information as compared with segmentor word information.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Detailed statistics of resume NER.", "labels": [], "entities": [{"text": "resume NER", "start_pos": 33, "end_pos": 43, "type": "DATASET", "confidence": 0.7457391321659088}]}, {"text": " Table 5: Main results on OntoNotes.", "labels": [], "entities": [{"text": "OntoNotes", "start_pos": 26, "end_pos": 35, "type": "DATASET", "confidence": 0.8599429726600647}]}, {"text": " Table 6: Main results on MSRA.", "labels": [], "entities": [{"text": "MSRA", "start_pos": 26, "end_pos": 30, "type": "DATASET", "confidence": 0.6807845234870911}]}, {"text": " Table 7: Weibo NER results.", "labels": [], "entities": [{"text": "Weibo NER results", "start_pos": 10, "end_pos": 27, "type": "DATASET", "confidence": 0.9215959707895914}]}, {"text": " Table 8: Main results on resume NER.", "labels": [], "entities": [{"text": "Main", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.871899425983429}, {"text": "resume NER", "start_pos": 26, "end_pos": 36, "type": "DATASET", "confidence": 0.8567538261413574}]}, {"text": " Table 10: Entities in lexicon.", "labels": [], "entities": []}]}