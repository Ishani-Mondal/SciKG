{"title": [{"text": "Learning Prototypical Goal Activities for Locations", "labels": [], "entities": []}], "abstractContent": [{"text": "People go to different places to engage in activities that reflect their goals.", "labels": [], "entities": []}, {"text": "For example, people go to restaurants to eat, libraries to study, and churches to pray.", "labels": [], "entities": []}, {"text": "We refer to an activity that represents a common reason why people typically go to a location as a prototypical goal activity (goal-act).", "labels": [], "entities": []}, {"text": "Our research aims to learn goal-acts for specific locations using a text corpus and semi-supervised learning.", "labels": [], "entities": []}, {"text": "First, we extract activities and locations that co-occur in goal-oriented syntactic patterns.", "labels": [], "entities": []}, {"text": "Next, we create an activity profile matrix and apply a semi-supervised label propagation algorithm to iteratively revise the activity strengths for different locations using a small set of labeled data.", "labels": [], "entities": []}, {"text": "We show that this approach outperforms several baseline methods when judged against goal-acts identified by human annotators.", "labels": [], "entities": []}], "introductionContent": [{"text": "Every day, people go to different places to accomplish goals.", "labels": [], "entities": []}, {"text": "People go to stores to buy clothing, go to restaurants to eat, and go to the doctor for medical services.", "labels": [], "entities": []}, {"text": "People travel to specific destinations to enjoy the beach, go skiing, or see historical sites.", "labels": [], "entities": []}, {"text": "For most places, people typically go therefor a common set of reasons, which we will refer to as prototypical goal activities (goal-acts) fora location.", "labels": [], "entities": []}, {"text": "For example, a prototypical goal-act for restaurants would be \"eat food\" and for IKEA would be \"buy furniture\".", "labels": [], "entities": [{"text": "IKEA", "start_pos": 81, "end_pos": 85, "type": "DATASET", "confidence": 0.8627875447273254}]}, {"text": "Previous research has established that recognizing people's goals is essential for narrative text understanding and story comprehension).", "labels": [], "entities": [{"text": "narrative text understanding", "start_pos": 83, "end_pos": 111, "type": "TASK", "confidence": 0.6303395330905914}]}, {"text": "Goals and plans are essential to understand people's behavior and we use our knowledge of prototypical goals to make inferences when reading.", "labels": [], "entities": []}, {"text": "For example, consider the following pair of sentences: \"Mary went to the supermarket.", "labels": [], "entities": []}, {"text": "Most people will infer that Mary purchased milk, unless told otherwise.", "labels": [], "entities": []}, {"text": "But a purchase event is not explicitly mentioned.", "labels": [], "entities": []}, {"text": "In contrast, a similar sentence pair \"Mary went to the theatre.", "labels": [], "entities": []}, {"text": "She needed milk.\" feels incongruent and does not produce that inference.", "labels": [], "entities": []}, {"text": "Recognizing goals is also critical for conversational dialogue systems.", "labels": [], "entities": []}, {"text": "For example, if a friend tells you that they went to a restaurant, you might reply \"What did you eat?\", but if a friend says that they went to Yosemite, a more appropriate response might be \"Did you hike?\" or \"Did you seethe waterfalls?\".", "labels": [], "entities": []}, {"text": "Our knowledge of prototypical goal activities also helps us resolve semantic ambiguity.", "labels": [], "entities": []}, {"text": "For example, consider the following sentences: (a) She went to the kitchen and got chicken.", "labels": [], "entities": []}, {"text": "(b) She went to the supermarket and got chicken.", "labels": [], "entities": []}, {"text": "(c) She went to the restaurant and got chicken.", "labels": [], "entities": []}, {"text": "In sentence (a), we infer that she retrieved chicken (e.g., from the refrigerator) but did not pay for it.", "labels": [], "entities": []}, {"text": "In (b), we infer that she paid for the chicken but probably did not eat it at the supermarket.", "labels": [], "entities": []}, {"text": "In (c), we infer that she ate the chicken at the restaurant.", "labels": [], "entities": []}, {"text": "Note how the verb \"got\" maps to different presumed events depending on the location.", "labels": [], "entities": []}, {"text": "Our research aims to learn the prototypical goalacts for locations using a text corpus.", "labels": [], "entities": []}, {"text": "First, we extract activities that co-occur with locations in goaloriented syntactic patterns.", "labels": [], "entities": []}, {"text": "Next, we construct an activity profile matrix that consists of an activity vector (profile) for each of the locations.", "labels": [], "entities": []}, {"text": "We then apply a semi-supervised label propagation algorithm to iteratively revise the activity profile strengths based on a small set of labeled locations.", "labels": [], "entities": [{"text": "label propagation", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.7686424851417542}]}, {"text": "We also incorporate external resources to measure similarity between different activity expressions.", "labels": [], "entities": []}, {"text": "Our results show that this semi-supervised learning approach outperforms several baseline methods in identifying the prototypical goal activities for locations.", "labels": [], "entities": []}], "datasetContent": [{"text": "All of our methods produce a ranked list of hypothesized goal-acts fora location.", "labels": [], "entities": []}, {"text": "So we use Mean Reciprocal Rank (MRR) to judge the quality of the top 10 activities in each ranked list.", "labels": [], "entities": [{"text": "Mean Reciprocal Rank (MRR)", "start_pos": 10, "end_pos": 36, "type": "METRIC", "confidence": 0.9657492538293203}]}, {"text": "We report two types of MRR scores.", "labels": [], "entities": [{"text": "MRR", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.7288863658905029}]}, {"text": "MRR based on the Exact Match criteria (MRR E ) is computed as follows, where n is the number of locations in the test set: We also compute MRR using both the Exact Match and Partial Match criteria.", "labels": [], "entities": [{"text": "Exact Match criteria (MRR E )", "start_pos": 17, "end_pos": 46, "type": "METRIC", "confidence": 0.8104395398071834}, {"text": "MRR", "start_pos": 139, "end_pos": 142, "type": "TASK", "confidence": 0.8898899555206299}]}, {"text": "First, we need to identify the \"best\" answer among the 10 activities in the ranked list, which depends both on each activity's ranking and its matching score.", "labels": [], "entities": []}, {"text": "The matching score for activity a j is defined as: Given 10 ranked activities a 1 ...", "labels": [], "entities": []}, {"text": "a 10 for l i , we then compute: And then finally define MRR P as follows:  Unless otherwise noted, all of our experiments report results using 4-fold cross-validation on the 200 locations in our test set.", "labels": [], "entities": [{"text": "MRR P", "start_pos": 56, "end_pos": 61, "type": "METRIC", "confidence": 0.8618136942386627}]}, {"text": "We used 4 folds to ensure 50 seed locations for each run (i.e., 1 fold for training and 3 folds for testing).", "labels": [], "entities": []}, {"text": "The first two columns of show the MRR results under Exact Match and Partial Match conditions.", "labels": [], "entities": [{"text": "MRR", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.8296501636505127}, {"text": "Exact Match", "start_pos": 52, "end_pos": 63, "type": "METRIC", "confidence": 0.7644125819206238}]}, {"text": "The first 3 rows show the results for the baseline systems, and the remaining rows show results for our Activity Profile (AP) semi-supervised learning method.", "labels": [], "entities": []}, {"text": "We show results for 5 variations of the algorithm: AP uses Algorithm 1, and the others use Algorithm 2 with different Activity Similarity measures: AP+A L (location profile similarity), AP+A O (overlap similarity), AP+A E (embedding similarity), and AP+A L+E (location profiles plus embeddings).", "labels": [], "entities": [{"text": "AP+A L (location profile similarity)", "start_pos": 148, "end_pos": 184, "type": "METRIC", "confidence": 0.7532650331656138}, {"text": "AP+A O (overlap similarity)", "start_pos": 186, "end_pos": 213, "type": "METRIC", "confidence": 0.8465661704540253}]}, {"text": "shows that our AP algorithm outperforms all 3 baseline methods.", "labels": [], "entities": []}, {"text": "When adding Activity Similarity into the algorithm, we find that AL slightly improves performance, but A O and A E do not.", "labels": [], "entities": [{"text": "AL", "start_pos": 65, "end_pos": 67, "type": "METRIC", "confidence": 0.9411947131156921}]}, {"text": "However, we also tried combining them and obtained improved results by using AL and A E together, yielding an MRR P score of 0.42.", "labels": [], "entities": [{"text": "AL", "start_pos": 77, "end_pos": 79, "type": "METRIC", "confidence": 0.9846028089523315}, {"text": "MRR P score", "start_pos": 110, "end_pos": 121, "type": "METRIC", "confidence": 0.9504867593447367}]}, {"text": "To gain more insight about the behavior of the models, also shows results for the topranked 1, 2, and 3 answers.", "labels": [], "entities": []}, {"text": "For these experiments, the system gets full credit if any of its top k answers exactly matches the gold standard, or 50% credit if a partial match is among its top k answers.", "labels": [], "entities": []}, {"text": "These results show that our AP method produces more correct answers at the top of the list than the baseline methods.", "labels": [], "entities": []}, {"text": "shows six locations with their gold answers and the Top 3 goal-acts hypothesized by our best AP system and the PMI and FREQ baselines.", "labels": [], "entities": [{"text": "PMI", "start_pos": 111, "end_pos": 114, "type": "DATASET", "confidence": 0.7506543397903442}, {"text": "FREQ", "start_pos": 119, "end_pos": 123, "type": "METRIC", "confidence": 0.874474823474884}]}, {"text": "The activities in boldface were deemed correct (including Partial Match).", "labels": [], "entities": [{"text": "Partial Match)", "start_pos": 58, "end_pos": 72, "type": "TASK", "confidence": 0.6426298022270203}]}, {"text": "For \"bookstore\" and \"pharmacy\", all of the methods perform well.", "labels": [], "entities": []}, {"text": "Note the challenge of recognizing that different phrases mean essentially the same thing (e.g., \"fill prescription\", \"pick up prescription\", \"find medicine\").", "labels": [], "entities": []}, {"text": "For \"university\" and \"Meijer\", the AP method produces more appropriate answers than the baseline methods.", "labels": [], "entities": [{"text": "AP", "start_pos": 35, "end_pos": 37, "type": "METRIC", "confidence": 0.7791367769241333}]}, {"text": "For \"market\" and \"phone\", all three methods struggle to produce good answers.", "labels": [], "entities": []}, {"text": "Since \"market\" is polysemous, we see activities related to both stores and financial markets.", "labels": [], "entities": []}, {"text": "And \"phone\" arguably is not a location at all, but most human annotators treated it as a virtual location, listing goal-acts related to telephones.", "labels": [], "entities": []}, {"text": "However our algorithm considered phones to be similar to computers, which makes sense for today's smartphones.", "labels": [], "entities": []}, {"text": "In general, we also observed that Internet sites behave as virtual locations in language (e.g., \"I went to YouTube...\").", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: An illustration of the activity profile matrix Y .", "labels": [], "entities": []}, {"text": " Table 3: Scores for MRR and Top k results.", "labels": [], "entities": [{"text": "Scores", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9631900191307068}, {"text": "MRR", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.7032864689826965}]}]}