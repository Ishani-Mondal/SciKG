{"title": [], "abstractContent": [{"text": "Previous approaches to multilingual semantic dependency parsing treat languages independently, without exploiting the similarities between semantic structures across languages.", "labels": [], "entities": [{"text": "multilingual semantic dependency parsing", "start_pos": 23, "end_pos": 63, "type": "TASK", "confidence": 0.6704461947083473}]}, {"text": "We experiment with anew approach where we combine resources from a pair of languages in the CoNLL 2009 shared task (Haji\u010d et al., 2009) to build a polyglot semantic role la-beler.", "labels": [], "entities": [{"text": "CoNLL 2009 shared task", "start_pos": 92, "end_pos": 114, "type": "DATASET", "confidence": 0.8434736132621765}]}, {"text": "Notwithstanding the absence of parallel data, and the dissimilarity in annotations between languages, our approach results in an improvement in SRL performance on multiple languages over a mono-lingual baseline.", "labels": [], "entities": [{"text": "SRL", "start_pos": 144, "end_pos": 147, "type": "TASK", "confidence": 0.9834167957305908}]}, {"text": "Analysis of the poly-glot model shows it to be advantageous in lower-resource settings.", "labels": [], "entities": []}], "introductionContent": [{"text": "The standard approach to multilingual NLP is to design a single architecture, but tune and train a separate model for each language.", "labels": [], "entities": []}, {"text": "While this method allows for customizing the model to the particulars of each language and the available data, it also presents a problem when little data is available: extensive language-specific annotation is required.", "labels": [], "entities": []}, {"text": "The reality is that most languages have very little annotated data for most NLP tasks.", "labels": [], "entities": []}, {"text": "found that using training data from multiple languages annotated with Universal Dependencies (, and represented using multilingual word vectors, outperformed monolingual training.", "labels": [], "entities": []}, {"text": "Inspired by this, we apply the idea of training one model on multiple languages-which we call polyglot trainingto PropBank-style semantic role labeling (SRL).", "labels": [], "entities": [{"text": "polyglot trainingto PropBank-style semantic role labeling (SRL)", "start_pos": 94, "end_pos": 157, "type": "TASK", "confidence": 0.7366511821746826}]}, {"text": "We train several parsers for each language in the): a tra- ditional monolingual version, and variants which additionally incorporate supervision from English portion of the dataset.", "labels": [], "entities": []}, {"text": "To our knowledge, this is the first multilingual SRL approach to combine supervision from several languages.", "labels": [], "entities": [{"text": "SRL", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.8588907122612}]}, {"text": "The CoNLL 2009 dataset includes seven different languages, allowing study of trends across the same.", "labels": [], "entities": [{"text": "CoNLL 2009 dataset", "start_pos": 4, "end_pos": 22, "type": "DATASET", "confidence": 0.9602275292078654}]}, {"text": "Unlike the Universal Dependencies dataset, however, the semantic label spaces are entirely language-specific, making our task more challenging.", "labels": [], "entities": [{"text": "Universal Dependencies dataset", "start_pos": 11, "end_pos": 41, "type": "DATASET", "confidence": 0.6197238862514496}]}, {"text": "Nonetheless, the success of polyglot training in this setting demonstrates that sharing of statistical strength across languages does not depend on explicit alignment in annotation conventions, and can be done simply through parameter sharing.", "labels": [], "entities": []}, {"text": "We show that polyglot training can result in better labeling accuracy than a monolingual parser, especially for low-resource languages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9364132285118103}]}, {"text": "We find that even a simple combination of data is as effective as more complex kinds of polyglot training.", "labels": [], "entities": []}, {"text": "We include a breakdown into label categories of the differences between the monolingual and polyglot models.", "labels": [], "entities": []}, {"text": "Our findings indicate that polyglot training consistently improves label accuracy for common labels.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9432712197303772}]}], "datasetContent": [{"text": "We present our results in.", "labels": [], "entities": []}, {"text": "We observe that simple polyglot training improves over monolingual training, with the exception of Czech, where we observe no change in performance.", "labels": [], "entities": []}, {"text": "The languages with the fewest training examples (German, Japanese, Catalan) show the most improvement, while large-dataset languages such as Czech or Chinese see little or no improvement.", "labels": [], "entities": []}, {"text": "The language ID model performs inconsistently; it is better than the simple polyglot model in some cases, including Czech, but not in all.", "labels": [], "entities": []}, {"text": "The language-specific LSTMs model performs best on a few languages, such as Catalan and Chinese, but worst on others.", "labels": [], "entities": []}, {"text": "While these results may reflect differences between languages in the optimal amount of crosslingual sharing, we focus on the simple polyglot results in our analysis, which sufficiently demonstrate that polyglot training can improve performance over monolingual training.", "labels": [], "entities": []}, {"text": "We also report performance of state-of-the-art systems in each of these languages, all of which make explicit use of syntactic features, Marcheg- excepted.", "labels": [], "entities": []}, {"text": "While this results in better performance on many languages, our model has the advantage of not relying on a syntactic parser, and is hence more applicable to languages with lower resources.", "labels": [], "entities": []}, {"text": "However, the results suggest that syntactic information is critical for strong performance on German, which has the fewest predicates and thus the least semantic annotation fora semantics-only model to learn from.", "labels": [], "entities": []}, {"text": "Nevertheless, our baseline is on par with the best published scores for Chinese, and it shows strong performance on most languages.", "labels": [], "entities": []}, {"text": "gives the F 1 scores for individual label categories in the Catalan and Spanish datasets, as an illustration of the larger trend.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9816284577051798}, {"text": "Catalan and Spanish datasets", "start_pos": 60, "end_pos": 88, "type": "DATASET", "confidence": 0.619973435997963}]}, {"text": "In both languages, we find a small but consistent improvement in the most common label categories (e.g., arg 1 and arg M ).", "labels": [], "entities": []}, {"text": "Less common label categories are sensitive to small changes in performance; they have the largest changes in F 1 in absolute value, but without a consistent direction.", "labels": [], "entities": [{"text": "F 1 in absolute value", "start_pos": 109, "end_pos": 130, "type": "METRIC", "confidence": 0.8293783009052277}]}, {"text": "This could be attributed to the addition of English data, which improves learning of representations that are useful for the most common labels, but is essentially a random perturbation for the rarer ones.", "labels": [], "entities": []}, {"text": "This pattern is seen across languages, and consistently results in overall gains from polyglot training.", "labels": [], "entities": []}, {"text": "One exception is in Czech, where polyglot training reduces accuracy on several common argument labels, e.g., PAT and LOC.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9986188411712646}, {"text": "PAT", "start_pos": 109, "end_pos": 112, "type": "METRIC", "confidence": 0.7890682816505432}]}, {"text": "While the effect sizes are small (consistent with other languages), the overall F 1 score on Czech decreases slightly in the polyglot condition.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.9922177592913309}]}, {"text": "It maybe that the Czech dataset is too large to make use of the comparatively small amount of English data, or that differences in the annotation schemes prevent effective crosslingual transfer.", "labels": [], "entities": [{"text": "Czech dataset", "start_pos": 18, "end_pos": 31, "type": "DATASET", "confidence": 0.942936897277832}, {"text": "crosslingual transfer", "start_pos": 172, "end_pos": 193, "type": "TASK", "confidence": 0.7956817746162415}]}, {"text": "Future work on language pairs that do not include English could provide further insights.", "labels": [], "entities": []}, {"text": "Catalan and Spanish, for example, are closely related and use the same argument label set (both being drawn from the AnCora corpus) which would allow for sharing output representations as well as input tokens and parameters.", "labels": [], "entities": [{"text": "AnCora corpus", "start_pos": 117, "end_pos": 130, "type": "DATASET", "confidence": 0.9001245498657227}]}, {"text": "For each language pair, we also evaluated the simple polyglot model on the English test set from the CoNLL 2009 shared task.", "labels": [], "entities": [{"text": "English test set", "start_pos": 75, "end_pos": 91, "type": "DATASET", "confidence": 0.773798664410909}, {"text": "CoNLL 2009 shared task", "start_pos": 101, "end_pos": 123, "type": "DATASET", "confidence": 0.8489703387022018}]}, {"text": "English SRL consistently benefits from polyglot training, with an increase of 0.25-0.7 absolute F 1 points, depending on the language.", "labels": [], "entities": [{"text": "English SRL", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.517295703291893}, {"text": "F 1 points", "start_pos": 96, "end_pos": 106, "type": "METRIC", "confidence": 0.9204016725222269}]}, {"text": "Surprisingly, Czech provides the smallest improvement, despite the large amount of data added; the absence of crosslingual transfer in both directions for the English-Czech case, breaking the pattern seen in other languages, could therefore be due to differences in annotation rather than questions of dataset size.", "labels": [], "entities": []}, {"text": "Labeled vs. unlabeled F 1 . provides unlabeled F 1 scores for each language pair.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 47, "end_pos": 57, "type": "METRIC", "confidence": 0.8733934164047241}]}, {"text": "As can be seen here, the unlabeled F 1 improvements are generally positive but small, indicating that polyglot training can help both in structure prediction and labeling of arguments.", "labels": [], "entities": [{"text": "F 1", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.9184510707855225}, {"text": "structure prediction", "start_pos": 137, "end_pos": 157, "type": "TASK", "confidence": 0.7784777283668518}]}, {"text": "The pattern of seeing the largest improvements on the languages with the smallest datasets generally holds here: the largest F 1 gains are in German and Catalan, followed by Japanese, with minimal or no improvement elsewhere.", "labels": [], "entities": [{"text": "F 1", "start_pos": 125, "end_pos": 128, "type": "METRIC", "confidence": 0.9613238275051117}]}], "tableCaptions": [{"text": " Table 1: Train data statistics. Languages are indi- cated with ISO 639-3 codes.", "labels": [], "entities": [{"text": "ISO 639-3 codes", "start_pos": 64, "end_pos": 79, "type": "DATASET", "confidence": 0.8759195407231649}]}, {"text": " Table 2: Semantic F 1 scores (including predicate sense disambiguation) on the CoNLL 2009 dataset.  State of the art for Catalan and Japanese is from Zhao et al. (2009), for German and Spanish from Roth  and Lapata (2016), for English and Chinese from Marcheggiani and Titov (2017). Italics indicate use of  syntax.", "labels": [], "entities": [{"text": "CoNLL 2009 dataset", "start_pos": 80, "end_pos": 98, "type": "DATASET", "confidence": 0.9721421400705973}]}, {"text": " Table 3: Per-label breakdown of F 1 scores for Catalan and Spanish. These numbers reflect labels for  each argument; the combination is different from the overall semantic F 1 , which includes predicate sense  disambiguation.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 33, "end_pos": 43, "type": "METRIC", "confidence": 0.8682423830032349}, {"text": "predicate sense  disambiguation", "start_pos": 194, "end_pos": 225, "type": "TASK", "confidence": 0.631289541721344}]}, {"text": " Table 4: Semantic F 1 scores on the English test set for each language pair.", "labels": [], "entities": [{"text": "English test set", "start_pos": 37, "end_pos": 53, "type": "DATASET", "confidence": 0.7592306236426035}]}, {"text": " Table 5: Unlabeled semantic F 1 scores on the CoNLL 2009 dataset.", "labels": [], "entities": [{"text": "Unlabeled semantic F 1 scores", "start_pos": 10, "end_pos": 39, "type": "METRIC", "confidence": 0.6682476580142975}, {"text": "CoNLL 2009 dataset", "start_pos": 47, "end_pos": 65, "type": "DATASET", "confidence": 0.979017953077952}]}]}