{"title": [{"text": "Sequicity: Simplifying Task-oriented Dialogue Systems with Single Sequence-to-Sequence Architectures", "labels": [], "entities": []}], "abstractContent": [{"text": "Existing solutions to task-oriented dialogue systems follow pipeline designs which introduce architectural complexity and fragility.", "labels": [], "entities": []}, {"text": "We propose a novel, holistic, extendable framework based on a single sequence-to-sequence (seq2seq) model which can be optimized with supervised or reinforcement learning.", "labels": [], "entities": []}, {"text": "A key contribution is that we design text spans named belief spans to track dialogue believes, allowing task-oriented dialogue systems to be modeled in a seq2seq way.", "labels": [], "entities": []}, {"text": "Based on this, we propose a sim-plistic Two Stage CopyNet instantiation which demonstrates good scalability: significantly reducing model complexity in terms of number of parameters and training time by an order of magnitude.", "labels": [], "entities": [{"text": "Two Stage CopyNet instantiation", "start_pos": 40, "end_pos": 71, "type": "TASK", "confidence": 0.5617767795920372}]}, {"text": "It significantly outperforms state-of-the-art pipeline-based methods on two datasets and retains a satisfactory entity match rate on out-of-vocabulary (OOV) cases where pipeline-designed competitors totally fail.", "labels": [], "entities": []}], "introductionContent": [{"text": "The challenge of achieving both task completion and human-like response generation for taskoriented dialogue systems is gaining research interest.) pioneered a set of models to address this challenge.", "labels": [], "entities": [{"text": "task completion", "start_pos": 32, "end_pos": 47, "type": "TASK", "confidence": 0.7191844433546066}]}, {"text": "Their proposed architectures follow traditional pipeline designs, where the belief tracking component is the key component ().", "labels": [], "entities": [{"text": "belief tracking", "start_pos": 76, "end_pos": 91, "type": "TASK", "confidence": 0.6678144037723541}]}, {"text": "In the current paradigm, such a belief tracker builds a complex multi-class classifier for each * Work performed during an internship at Data Science Lab, JD.com.", "labels": [], "entities": [{"text": "JD.com", "start_pos": 155, "end_pos": 161, "type": "DATASET", "confidence": 0.9089657068252563}]}, {"text": "slot (See \u00a73.2) which can suffer from high complexity, especially when the number of slots and their values grow.", "labels": [], "entities": []}, {"text": "Since all the possible slot values have to be pre-defined as classification labels, such trackers also cannot handle the requests that have out-of-vocabulary (OOV) slot values.", "labels": [], "entities": []}, {"text": "Moreover, the belief tracker requires delexicalization, i.e., replacing slot values with their slot names in utterances).", "labels": [], "entities": []}, {"text": "It does not scale well, due to the lexical diversity.", "labels": [], "entities": []}, {"text": "The belief tracker also needs to be pre-trained, making the models unrealistic for end-to-end training.", "labels": [], "entities": [{"text": "belief tracker", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.6840346902608871}]}, {"text": "While Eric and Manning (2017a,b) investigated building task-oriented dialogue systems by using a seq2seq model, unfortunately, their methods are rather preliminary and do not perform well in either task completion or response generation, due to their omission of a belief tracker.", "labels": [], "entities": [{"text": "response generation", "start_pos": 217, "end_pos": 236, "type": "TASK", "confidence": 0.6670637428760529}]}, {"text": "Questioning the basic pipeline architecture, in this paper, we re-examine the tenets of belief tracking in light of advances in deep learning.", "labels": [], "entities": [{"text": "belief tracking", "start_pos": 88, "end_pos": 103, "type": "TASK", "confidence": 0.7789831161499023}]}, {"text": "We introduce the concept of a belief span (bspan), a text span that tracks the belief states at each turn.", "labels": [], "entities": []}, {"text": "This leads to anew framework, named Sequicity, with a single seq2seq model.", "labels": [], "entities": []}, {"text": "Sequicity decomposes the task-oriented dialogue problem into the generation of bspans and machine responses, converting this problem into a sequence optimization problem.", "labels": [], "entities": []}, {"text": "In practice, Sequicity decodes in two stages: in the first stage, it decodes a bspan to facilitate knowledge base (KB) search; in the second, it decodes a machine response on the condition of knowledge base search result and the bspan.", "labels": [], "entities": []}, {"text": "Our method represents a shift in perspective compared to existing work.", "labels": [], "entities": []}, {"text": "Sequicity employs a single seq2seq model, resulting in a vastly simplified architecture.", "labels": [], "entities": []}, {"text": "Unlike previous approaches with an overly parameterized delexicalization-based belief tracker, Sequicity achieves much less train-ing time, better performance on larger a dataset and an exceptional ability to handle OOV cases.", "labels": [], "entities": []}, {"text": "Furthermore, Sequicity is a theoretically and aesthetically appealing framework, as it achieves true end-to-end trainability using only one seq2seq model.", "labels": [], "entities": []}, {"text": "As such, Sequicity leverages the rapid development of seq2seq models) in developing solutions to task-oriented dialogue scenarios.", "labels": [], "entities": []}, {"text": "In our implementation, we improve on CopyNet () to instantiate Sequicity framework in this paper, as key words present in bspans and machine responses recur from previous utterances.", "labels": [], "entities": []}, {"text": "Extensive experiments conducted on two benchmark datasets verify the effectiveness of our proposed method.", "labels": [], "entities": []}, {"text": "Our contributions are fourfold: (1) We propose the Sequicity framework, which handles both task completion and response generation in a single seq2seq model; (2) We present an implementation of the Sequicity framework, called Two Stage CopyNet (TSCP), which has fewer number of parameters and trains faster than state-of-the-art baselines; We demonstrate that TSCP significantly outperforms state-of-the-art baselines on two large-scale datasets, inclusive of scenarios involving OOV; (4) We release source code of TSCP to assist the community to explore Sequicity 1 .", "labels": [], "entities": [{"text": "response generation", "start_pos": 111, "end_pos": 130, "type": "TASK", "confidence": 0.6726166009902954}]}], "datasetContent": [{"text": "We assess the effectiveness of Sequicity in three aspects: the task completion, the language quality, and the efficiency.", "labels": [], "entities": []}, {"text": "The evaluation metrics are listed as follows: \u00b7 BLEU to evaluate the language quality () of generated responses (hence top-1 candidate in).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 48, "end_pos": 52, "type": "METRIC", "confidence": 0.9993215799331665}]}, {"text": "\u00b7 Entity match rate evaluates task completion.", "labels": [], "entities": [{"text": "Entity match rate", "start_pos": 2, "end_pos": 19, "type": "METRIC", "confidence": 0.8952585458755493}]}, {"text": "According to, it determines if a system can generate all correct constraints to search the indicated entities of the user.", "labels": [], "entities": []}, {"text": "This metric is either 0 or 1 for each dialogue.", "labels": [], "entities": []}, {"text": "\u00b7 Success F 1 evaluates task completion and is modified from the success rate in.", "labels": [], "entities": [{"text": "Success F 1", "start_pos": 2, "end_pos": 13, "type": "METRIC", "confidence": 0.9562393625577291}]}, {"text": "The original success rate measures if the system answered all the requested information (e.g. address, phone number).", "labels": [], "entities": []}, {"text": "However, this metric only evaluates recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9985880255699158}]}, {"text": "A system can easily achieve a perfect task success by always responding all possible request slots.", "labels": [], "entities": []}, {"text": "Instead, we here use success F 1 to balance both recall and precision.", "labels": [], "entities": [{"text": "success F 1", "start_pos": 21, "end_pos": 32, "type": "METRIC", "confidence": 0.8683746854464213}, {"text": "recall", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.999382495880127}, {"text": "precision", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9987615346908569}]}, {"text": "It is defined as the F 1 score of requested slots answered in the current dialogue.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.988699754079183}]}, {"text": "The training time is important for iteration cycle of a model in industry settings.", "labels": [], "entities": []}, {"text": "We adopt the CamRest676 ( and) datasets.", "labels": [], "entities": [{"text": "CamRest676 ( and) datasets", "start_pos": 13, "end_pos": 39, "type": "DATASET", "confidence": 0.7567266702651978}]}, {"text": "Both datasets are created by a Wizard-of-Oz) method on Amazon Mechanical Turk platform, where a pair of workers are recruited to carryout a fluent conversation to complete an assigned task (e.g. restaurant reservation).", "labels": [], "entities": [{"text": "Amazon Mechanical Turk platform", "start_pos": 55, "end_pos": 86, "type": "DATASET", "confidence": 0.9287774711847305}, {"text": "restaurant reservation)", "start_pos": 195, "end_pos": 218, "type": "TASK", "confidence": 0.7713611920674642}]}, {"text": "During conversation, both informable and requestable slots are recorded by workers.", "labels": [], "entities": []}, {"text": "CamRest676's dialogs are in the single domain of restaurant searching, while KVRET is broader, containing three domains: calendar scheduling, weather information retrieval and point of interest (POI) Navigation.", "labels": [], "entities": [{"text": "CamRest676", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9558523297309875}, {"text": "restaurant searching", "start_pos": 49, "end_pos": 69, "type": "TASK", "confidence": 0.7107700854539871}, {"text": "KVRET", "start_pos": 77, "end_pos": 82, "type": "DATASET", "confidence": 0.8205587863922119}, {"text": "calendar scheduling", "start_pos": 121, "end_pos": 140, "type": "TASK", "confidence": 0.6731669455766678}, {"text": "weather information retrieval", "start_pos": 142, "end_pos": 171, "type": "TASK", "confidence": 0.5955672264099121}, {"text": "point of interest (POI) Navigation", "start_pos": 176, "end_pos": 210, "type": "TASK", "confidence": 0.6687187467302594}]}, {"text": "Detailed slot information in each domain are shown in.", "labels": [], "entities": []}, {"text": "We follow the data splits of the original papers as shown in 1.", "labels": [], "entities": []}, {"text": "As shown in, TSCP outperforms all baselines (Row 5 vs. Rows 1-4) in task completion (entity match rate, success F1) and language quality (BLEU).", "labels": [], "entities": [{"text": "TSCP", "start_pos": 13, "end_pos": 17, "type": "TASK", "confidence": 0.49654537439346313}, {"text": "language quality (BLEU)", "start_pos": 120, "end_pos": 143, "type": "METRIC", "confidence": 0.7174238801002503}]}, {"text": "The more significant performance of TSCP in KVRET dataset indicates the scalability Importantly, ablation studies validate the necessity of bspans.", "labels": [], "entities": [{"text": "KVRET dataset", "start_pos": 44, "end_pos": 57, "type": "DATASET", "confidence": 0.9429868757724762}]}, {"text": "With bspans, even a standard seq2seq model (Att-RNN, Row 6) beats sophisticated models such as attention copyNets (TSCP\\B t , Row 9) in KVRET.", "labels": [], "entities": [{"text": "Att-RNN", "start_pos": 44, "end_pos": 51, "type": "METRIC", "confidence": 0.7817204594612122}, {"text": "KVRET", "start_pos": 136, "end_pos": 141, "type": "DATASET", "confidence": 0.8956629633903503}]}, {"text": "Furthermore, TSCP (Row 5) outperforms TSCP\\B t (Row 9) in all aspects: task completion, language quality and training speed.", "labels": [], "entities": [{"text": "TSCP", "start_pos": 13, "end_pos": 17, "type": "METRIC", "confidence": 0.6541546583175659}, {"text": "task completion", "start_pos": 71, "end_pos": 86, "type": "TASK", "confidence": 0.7291573286056519}]}, {"text": "This validate our theoretical analysis in Sec 4.3.", "labels": [], "entities": []}, {"text": "Other components of TSCP are also important.", "labels": [], "entities": [{"text": "TSCP", "start_pos": 20, "end_pos": 24, "type": "TASK", "confidence": 0.6814178228378296}]}, {"text": "If we only use vanilla Attention-based RNN instead of copyNet, all metrics for model effectiveness decrease, validating our hypothesize that the copied words need to be specifically modeled.", "labels": [], "entities": []}, {"text": "Secondly, BLEU score is sensitive to knowl-edge base search result kt (Row 7 vs. Row 5).", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9782644510269165}]}, {"text": "By examining error cases, we find that the system is likely to generate common sentences like \"you are welcome\" regardless of context, due to corpus frequency.", "labels": [], "entities": []}, {"text": "Finally, reinforcement learning effectively helps both BLEU and success F 1 although it takes acceptable additional time for training.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 55, "end_pos": 59, "type": "METRIC", "confidence": 0.9986999034881592}, {"text": "success F 1", "start_pos": 64, "end_pos": 75, "type": "METRIC", "confidence": 0.9227531750996908}]}], "tableCaptions": [{"text": " Table 1: Dataset demographics. Following the  respective literature, Cam676 is split 3:1:1 and  KVRET is split 8:1:1, into training, developing  and testing sets, respectively.", "labels": [], "entities": [{"text": "Cam676", "start_pos": 70, "end_pos": 76, "type": "DATASET", "confidence": 0.9755390882492065}, {"text": "KVRET", "start_pos": 97, "end_pos": 102, "type": "DATASET", "confidence": 0.7149928212165833}]}, {"text": " Table 2: Model performance on CamRes676 and KVRET. This table is split into two parts: competitors  on the upper side and our ablation study on the bottom side. Mat. and Succ. F1 are for match rate and  success F1 respectively. Time full column reports training time till converge. For NDM, NDM+Att+SS  and LIDM, we also calculate the training time for the rest parts except for the belief tracker (Time N.B. ).", "labels": [], "entities": [{"text": "KVRET", "start_pos": 45, "end_pos": 50, "type": "DATASET", "confidence": 0.8600670695304871}, {"text": "Succ. F1", "start_pos": 171, "end_pos": 179, "type": "METRIC", "confidence": 0.9668818513552347}, {"text": "match rate", "start_pos": 188, "end_pos": 198, "type": "METRIC", "confidence": 0.9015979766845703}, {"text": "LIDM", "start_pos": 308, "end_pos": 312, "type": "METRIC", "confidence": 0.9345762729644775}]}]}