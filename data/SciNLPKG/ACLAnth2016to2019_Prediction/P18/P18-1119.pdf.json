{"title": [{"text": "Which Melbourne? Augmenting Geocoding with Maps", "labels": [], "entities": [{"text": "Augmenting Geocoding", "start_pos": 17, "end_pos": 37, "type": "TASK", "confidence": 0.8671916425228119}]}], "abstractContent": [{"text": "The purpose of text geolocation is to associate geographic information contained in a document with a set (or sets) of coordinates , either implicitly by using linguistic features and/or explicitly by using geographic metadata combined with heuristics.", "labels": [], "entities": []}, {"text": "We introduce a geocoder (loca-tion mention disambiguator) that achieves state-of-the-art (SOTA) results on three diverse datasets by exploiting the implicit lexical clues.", "labels": [], "entities": []}, {"text": "Moreover, we propose anew method for systematic encoding of geographic metadata to generate two distinct views of the same text.", "labels": [], "entities": []}, {"text": "To that end, we introduce the Map Vector (MapVec), a sparse representation obtained by plotting prior geographic probabilities, derived from population figures, on a World Map.", "labels": [], "entities": [{"text": "World Map", "start_pos": 166, "end_pos": 175, "type": "DATASET", "confidence": 0.9058772623538971}]}, {"text": "We then integrate the implicit (lan-guage) and explicit (map) features to significantly improve a range of metrics.", "labels": [], "entities": []}, {"text": "We also introduce an open-source dataset for geoparsing of news events covering global disease outbreaks and epidemics to help future evaluation in geoparsing.", "labels": [], "entities": []}], "introductionContent": [{"text": "Geocoding 1 is a specific case of text geolocation, which aims at disambiguating place references in text.", "labels": [], "entities": []}, {"text": "For example, Melbourne can refer to more than ten possible locations and a geocoder's task is to identify the place coordinates for the intended Melbourne in a context such as \"Melbourne hosts one of the four annual Grand Slam tennis tournaments.\"", "labels": [], "entities": []}, {"text": "This is central to the success of tasks such as indexing and searching documents by geography (, geospatial Also called Toponym Resolution in related literature.", "labels": [], "entities": [{"text": "Toponym Resolution", "start_pos": 120, "end_pos": 138, "type": "TASK", "confidence": 0.7315111458301544}]}, {"text": "analysis of social media), mapping of disease risk using integrated data (, and emergency response systems).", "labels": [], "entities": [{"text": "mapping of disease risk", "start_pos": 27, "end_pos": 50, "type": "TASK", "confidence": 0.8400481343269348}]}, {"text": "Previous geocoding methods (Section 2) have leveraged lexical semantics to associate the implicit geographic information in natural language with coordinates.", "labels": [], "entities": []}, {"text": "These models have achieved good results in the past.", "labels": [], "entities": []}, {"text": "However, focusing only on lexical features, to the exclusion of other feature spaces such as the Cartesian Coordinate System, puts a ceiling on the amount of semantics we are able to extract from text.", "labels": [], "entities": []}, {"text": "Our proposed solution is the Map Vector (MapVec), a sparse, geographic vector for explicit modelling of geographic distributions of location mentions.", "labels": [], "entities": []}, {"text": "As in previous work, we use population data and geographic coordinates, observing that the most populous Melbourne is also the most likely to be the intended location.", "labels": [], "entities": []}, {"text": "However, MapVec is the first instance, to our best knowledge, of the topological semantics of context locations explicitly isolated into a standardized vector representation, which can then be easily transferred to an independent task and combined with other features.", "labels": [], "entities": []}, {"text": "MapVec is able to encode the prior geographic distribution of any number of locations into a single vector.", "labels": [], "entities": [{"text": "MapVec", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9298391342163086}]}, {"text": "Our extensive evaluation shows how this representation of context locations can be integrated with linguistic features to achieve a significant improvement over a SOTA lexical model.", "labels": [], "entities": [{"text": "SOTA lexical", "start_pos": 163, "end_pos": 175, "type": "TASK", "confidence": 0.8533143103122711}]}, {"text": "MapVec can be deployed as a standalone neural geocoder, significantly beating the population baseline, while remaining effective with simpler machine learning algorithms.", "labels": [], "entities": []}, {"text": "This paper's contributions are: (1) Lexical Geocoder outperforming existing systems by analysing only the textual context; (2) MapVec, a geographic representation of locations using a sparse, probabilistic vector to extract and isolate spatial features; (3) CamCoder, a novel geocoder that exploits both lexical and geographic knowledge producing SOTA results across multiple datasets; and (4) GeoVirus, an open-source dataset for the evaluation of geoparsing (Location Recognition and Disambiguation) of news events covering global disease outbreaks and epidemics.", "labels": [], "entities": [{"text": "Location Recognition and Disambiguation) of news events covering global disease outbreaks and epidemics", "start_pos": 461, "end_pos": 564, "type": "TASK", "confidence": 0.8339831914220538}]}], "datasetContent": [{"text": "Our evaluation compares the geocoding performance of six systems from Section 2, our geocoder (CamCoder) and the population baseline.", "labels": [], "entities": []}, {"text": "Among these, our CNN-based model is the only neural approach.", "labels": [], "entities": []}, {"text": "We have included all open-source/free geocoders in working order we were able to find and they are the most up-to-date versions.", "labels": [], "entities": []}, {"text": "Tables 1 and 2 feature several machine learning algorithms including Long-Short Term Memory (LSTM)  News Corpus: The Local Global Corpus (LGL) by contains 588 news articles (4460 test instances), which were collected from geographically distributed newspaper sites.", "labels": [], "entities": []}, {"text": "This is the most frequently used geocoding evaluation dataset to date.", "labels": [], "entities": []}, {"text": "The toponyms are mostly smaller places no larger than a US state.", "labels": [], "entities": []}, {"text": "Approximately 16% of locations in the corpus do not have any coordinates assigned; hence, we do not use those in the evaluation, which is also how the previous figures were obtained.", "labels": [], "entities": []}, {"text": "Wikipedia Corpus: This corpus was deliberately designed for ambiguity hence the population heuristic is not effective.", "labels": [], "entities": [{"text": "Wikipedia Corpus", "start_pos": 0, "end_pos": 16, "type": "DATASET", "confidence": 0.9699887633323669}]}, {"text": "Wikipedia Toponym Retrieval (WikToR) by is a programmatically created corpus and although not necessarily representative of the real world distribution, it is a test of ambiguity for geocoders.", "labels": [], "entities": [{"text": "Wikipedia Toponym Retrieval (WikToR)", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.8035411437352499}]}, {"text": "It is also a large corpus (25,000+ examples) containing the first few paragraphs of 5,000 Wikipedia pages.", "labels": [], "entities": []}, {"text": "High quality, free and open datasets are not readily available (GeoVirus tries to address this).", "labels": [], "entities": [{"text": "GeoVirus", "start_pos": 64, "end_pos": 72, "type": "DATASET", "confidence": 0.8841896653175354}]}, {"text": "The following corpora could not be included:) due to limited coverage (southern US) and domain type (historical language, the 1860s),) contains fewer than 180 locations, GeoCorpora ( could not be retrieved in full due to deleted Twitter users/tweets, GeoText () only allows for user geocoding,) involves prohibitive costs, GeoSemCor () was annotated with WordNet senses (rather than coordinates).", "labels": [], "entities": [{"text": "WordNet senses", "start_pos": 355, "end_pos": 369, "type": "DATASET", "confidence": 0.9152580201625824}]}, {"text": "We now introduce GeoVirus, an open-source test dataset for the evaluation of geoparsing of news events covering global disease outbreaks and epidemics.", "labels": [], "entities": []}, {"text": "It was constructed from free WikiNews 8 and collected during 08/2017 -09/2017.", "labels": [], "entities": []}, {"text": "The dataset is suitable for the evaluation of Geotagging/Named Entity Recognition and Geocoding/Toponym Resolution.", "labels": [], "entities": [{"text": "Geotagging/Named Entity Recognition", "start_pos": 46, "end_pos": 81, "type": "TASK", "confidence": 0.5652142524719238}, {"text": "Geocoding/Toponym Resolution", "start_pos": 86, "end_pos": 114, "type": "TASK", "confidence": 0.5641430616378784}]}, {"text": "Articles were identified using the WikiNews search box and keywords such as Ebola, Bird Flu, Swine Flu, AIDS, Mad Cow Disease, West Nile Disease, etc.", "labels": [], "entities": [{"text": "WikiNews search box", "start_pos": 35, "end_pos": 54, "type": "DATASET", "confidence": 0.8782995541890463}]}, {"text": "Off-topic articles were not included.", "labels": [], "entities": []}, {"text": "Buildings, POIs, street names and rivers were not annotated.", "labels": [], "entities": []}, {"text": "(1) The WikiNews contributor(s) who wrote the article annotated most, but not all location references.", "labels": [], "entities": []}, {"text": "The first author checked those annotations and identified further references, then proceeded to extract the place name, indices of the start and end characters in", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: AUC scores for CamCoder and its Lexical and MapVec components (model ablation). Lower  AUC scores are better.  \u2020 Standard context2vec model augmented with MapVec representation.", "labels": [], "entities": [{"text": "AUC", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.7429933547973633}, {"text": "CamCoder", "start_pos": 25, "end_pos": 33, "type": "DATASET", "confidence": 0.9665254950523376}]}]}