{"title": [{"text": "Augmenting Textual Qualitative Features in Deep Convolution Recurrent Neural Network for Automatic Essay Scoring", "labels": [], "entities": [{"text": "Augmenting Textual Qualitative", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8428594867388407}, {"text": "Automatic Essay Scoring", "start_pos": 89, "end_pos": 112, "type": "TASK", "confidence": 0.6878389418125153}]}], "abstractContent": [{"text": "In this paper we present a qualitatively enhanced deep convolution recurrent neural network for computing the quality of a text in an automatic essay scoring task.", "labels": [], "entities": []}, {"text": "The novelty of the work lies in the fact that instead of considering only the word and sentence representation of a text, we try to augment the different complex linguistic, cognitive and psychological features associated within a text document along with a hierarchical convolution recurrent neu-ral network framework.", "labels": [], "entities": []}, {"text": "Our preliminary investigation shows that incorporation of such qualitative feature vectors along with standard word/sentence embeddings can give us better understanding about improving the overall evaluation of the input essays.", "labels": [], "entities": []}], "introductionContent": [{"text": "The quality of text depends upon a number of linguistic factors, corresponding to different textual properties, such as grammar, vocabulary, style, topic relevance, clarity, comprehensibility, informativeness, lexical diversity, discourse coherence, and cohesion)().", "labels": [], "entities": [{"text": "clarity", "start_pos": 165, "end_pos": 172, "type": "METRIC", "confidence": 0.9501491189002991}]}, {"text": "In addition, there are deep cognitive and psychological features, such as types of syntactic constructions, grammatical relations and measures of sentence complexity, that make automatic analysis of text quality a non-trivial task.", "labels": [], "entities": []}, {"text": "Developing tools for automatic text quality analysis have become extremely important to organizations that need to assess writing skills among adults and students on a regular basis.", "labels": [], "entities": [{"text": "automatic text quality analysis", "start_pos": 21, "end_pos": 52, "type": "TASK", "confidence": 0.6284426674246788}]}, {"text": "Because of the high participation in such assessments, the amount of time and effort required to grade the large volume of textual data generated is too high to be feasible by a human evaluator.", "labels": [], "entities": []}, {"text": "Manual evaluation processes by multiple evaluators may also be prone to erroneous judgments due to mutual disagreements between the evaluators.", "labels": [], "entities": []}, {"text": "Therefore, developing a means through which such essays can be automatically scored, with minimum human interference, seem to be the best way forward to meet the growing demands of the education world, while keeping inter-evaluator disagreements to a minimum.", "labels": [], "entities": []}, {"text": "Automatic Essay Scoring (AES) systems have thus been in the research focus of multiple organizations to counter the above issues.", "labels": [], "entities": [{"text": "Automatic Essay Scoring (AES)", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8090670059124628}]}, {"text": "A typical AES system takes as input an essay written on a specific topic.", "labels": [], "entities": []}, {"text": "The system then assigns a numeric score to the essay reflecting its quality, based on its content, grammar, organization and other factors discussed above.", "labels": [], "entities": []}, {"text": "A plethora of research have been done to develop AES systems on various languages).", "labels": [], "entities": []}, {"text": "Most of these tools are based on regression methods applied to a set of carefully designed complex linguistic and cognitive features.", "labels": [], "entities": []}, {"text": "Knowledge of such complex features have been shown to achieve performance that is indistinguishable from that of human examiners.", "labels": [], "entities": []}, {"text": "However, since it is difficult to exhaustively enumerate all the multiple factors that influence the quality of texts, the challenge of automatically assigning a satisfactory score to an essay still remains.", "labels": [], "entities": []}, {"text": "Recent advancement in deep learning techniques have influenced researchers to apply them for AES tasks.", "labels": [], "entities": [{"text": "AES tasks", "start_pos": 93, "end_pos": 102, "type": "TASK", "confidence": 0.8861143589019775}]}, {"text": "The deep multi-layer neural networks can automatically learn useful features from data, with lower layers learning basic feature detectors and upper levels learning more high-level abstract features.", "labels": [], "entities": []}, {"text": "Deep neural network models, however, do not allow us to identify and extract those properties of text that the network identi-fies as discriminative ().", "labels": [], "entities": []}, {"text": "In particular, deep network models fail to take into account integral linguistic and cognitive factors present in text, which play an important role in an essay score assigned by experts.", "labels": [], "entities": []}, {"text": "Such models emphasizes a simple uniform paradigm for NLP: \"language is just sequences of words\".", "labels": [], "entities": []}, {"text": "While this approach has rapidly found enormous popularity and success, its limitations are now becoming more apparent.", "labels": [], "entities": []}, {"text": "Gradually researchers stressing towards the importance of linguistic structure and the fact that it reduces the search space of possible outputs, making it easier to generate well-formed output.", "labels": [], "entities": []}, {"text": "Dyer (Dyer, 2017) also argued for the importance of incorporating linguistic structure into deep learning.", "labels": [], "entities": []}, {"text": "He drew attention to the inductive biases inherent in the sequential approach, arguing that RNNs have an inductive bias towards sequential recency, while syntax-guided hierarchical architectures have an inductive bias towards syntactic recency.", "labels": [], "entities": []}, {"text": "Several papers noted the apparent inability of RNNs to capture longrange dependencies, and obtained improvements using recursive models instead.", "labels": [], "entities": []}, {"text": "In order to overcome the aforementioned issues, in this paper we propose a qualitatively enhanced deep convolution recurrent neural network architecture for automatic scoring of essays.", "labels": [], "entities": [{"text": "automatic scoring of essays", "start_pos": 157, "end_pos": 184, "type": "TASK", "confidence": 0.6822705641388893}]}, {"text": "Our model takes into account both the word-level and sentence-level representations, as well as linguistic and psychological feature embeddings.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, no other prior work in this field has investigated the effectiveness of combining word and sentence embeddings with linguistic features for AES tasks.", "labels": [], "entities": [{"text": "AES tasks", "start_pos": 170, "end_pos": 179, "type": "TASK", "confidence": 0.8691052198410034}]}, {"text": "Our preliminary investigation shows that incorporation of linguistic feature vectors along with standard word/sentence embeddings do improve the overall scoring of the input essays.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: Section 2 describes the recent state of art in AES systems.", "labels": [], "entities": [{"text": "AES", "start_pos": 94, "end_pos": 97, "type": "TASK", "confidence": 0.7495157122612}]}, {"text": "Our proposed Linguistically informed Convolution LSTM model architecture is discussed in Section 3, while section 4 has further details on generation of linguistic feature vectors.", "labels": [], "entities": []}, {"text": "In section 5, we cover the experimentation and evaluation technique, reporting the obtained results in section 6, and finally concluding the paper in section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "In past literature, a number of techniques were used to measure the quality of AES systems.", "labels": [], "entities": []}, {"text": "This includes Pearson's correlation r, Spearman's ranking correlation \u03c1, Kendall's Tau and kappa, and quadratic weighted kappa (QWK).", "labels": [], "entities": [{"text": "Pearson's correlation r", "start_pos": 14, "end_pos": 37, "type": "METRIC", "confidence": 0.8833556920289993}, {"text": "Spearman's ranking correlation \u03c1", "start_pos": 39, "end_pos": 71, "type": "METRIC", "confidence": 0.604658430814743}, {"text": "quadratic weighted kappa (QWK)", "start_pos": 102, "end_pos": 132, "type": "METRIC", "confidence": 0.8525839149951935}]}, {"text": "( proposed to evaluate their model in terms of the first three parameters, whereas works of () uses QWK as the evaluation criteria.", "labels": [], "entities": [{"text": "QWK", "start_pos": 100, "end_pos": 103, "type": "DATASET", "confidence": 0.7814148664474487}]}, {"text": "This is primarily due to the fact that   The QWK statistics or its other variants are widely used to measure inter-rater agreement of the annotators or experts.", "labels": [], "entities": [{"text": "QWK statistics", "start_pos": 45, "end_pos": 59, "type": "DATASET", "confidence": 0.8870694637298584}]}, {"text": "In our case inter-raters refer to the human rater and the system predicted ratings.", "labels": [], "entities": []}, {"text": "QWK is modified from kappa which takes quadratic weights.", "labels": [], "entities": [{"text": "QWK", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7897830009460449}]}, {"text": "The quadratic weight matrix in QWK is defined as: W i,j = (i\u2212j) (R\u22121) 2 , where i and j are the reference rating (assigned by a human rater) and the system rating (assigned by an AES system), respectively, and R is the number of possible ratings.", "labels": [], "entities": [{"text": "QWK", "start_pos": 31, "end_pos": 34, "type": "DATASET", "confidence": 0.8587296605110168}]}, {"text": "An observed agreement score O is calculated such that O i,j refers to the number of essays that receive a rating i by the human rater and a rating j by the AES system.", "labels": [], "entities": [{"text": "agreement score O", "start_pos": 12, "end_pos": 29, "type": "METRIC", "confidence": 0.79326331615448}, {"text": "O", "start_pos": 54, "end_pos": 55, "type": "METRIC", "confidence": 0.9838003516197205}, {"text": "AES", "start_pos": 156, "end_pos": 159, "type": "METRIC", "confidence": 0.4658483564853668}]}, {"text": "An expected score E is calculated as the outer product of the two ratings.", "labels": [], "entities": [{"text": "expected score E", "start_pos": 3, "end_pos": 19, "type": "METRIC", "confidence": 0.8191896478335062}]}, {"text": "Finally, given the three matrices W, O, and E, the QWK value is calculated as:", "labels": [], "entities": [{"text": "QWK", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.9735311269760132}]}], "tableCaptions": [{"text": " Table 2: Statistics of the Kaggle dataset;  Range:score range and Med: median scores.", "labels": [], "entities": [{"text": "Kaggle dataset", "start_pos": 28, "end_pos": 42, "type": "DATASET", "confidence": 0.9323670864105225}, {"text": "Range", "start_pos": 45, "end_pos": 50, "type": "METRIC", "confidence": 0.9918335676193237}, {"text": "Med: median scores", "start_pos": 67, "end_pos": 85, "type": "METRIC", "confidence": 0.946053758263588}]}, {"text": " Table 5: Comparing performance of the proposed model taking all the prompts together with that of the  existing models  Models  Pearson's r Spearman's \u03c1 RMSE Cohen's \u03ba  doc2vec  0.63  0.62  4.43  0.85  SVM  0.77  0.78  8.85  0.75  LSTM  0.60  0.59  6.80  0.54  Bi-LSTM  0.5  0.70  7.32  0.36  word2vec + Bi-LSTM  0.86  0.75  4.34  0.85  SSWE+ Bi-LSTM  0.92  0.80  3.21  0.95  SSWE+ Two-layer Bi-LSTM 0.96  0.91  2.40  0.96  Qe-C-LSTM  0.97  0.94  2.1  0.97", "labels": [], "entities": []}]}