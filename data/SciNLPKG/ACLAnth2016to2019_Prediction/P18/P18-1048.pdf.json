{"title": [{"text": "Self-regulation: Employing a Generative Adversarial Network to Improve Event Detection", "labels": [], "entities": [{"text": "Improve Event Detection", "start_pos": 63, "end_pos": 86, "type": "TASK", "confidence": 0.844851573308309}]}], "abstractContent": [{"text": "Due to the ability of encoding and mapping semantic information into a high-dimensional latent feature space, neural networks have been successfully used for detecting events to a certain extent.", "labels": [], "entities": []}, {"text": "However , such a feature space can be easily contaminated by spurious features inherent in event detection.", "labels": [], "entities": [{"text": "event detection", "start_pos": 91, "end_pos": 106, "type": "TASK", "confidence": 0.7250211238861084}]}, {"text": "In this paper, we propose a self-regulated learning approach by utilizing a generative adversarial network to generate spurious features.", "labels": [], "entities": []}, {"text": "On the basis, we employ a recurrent network to eliminate the fakes.", "labels": [], "entities": []}, {"text": "Detailed experiments on the ACE 2005 and TAC-KBP 2015 corpora show that our proposed method is highly effective and adaptable.", "labels": [], "entities": [{"text": "ACE 2005 and TAC-KBP 2015 corpora", "start_pos": 28, "end_pos": 61, "type": "DATASET", "confidence": 0.8610575099786123}]}], "introductionContent": [{"text": "Event detection aims to locate the event triggers of specified types in text.", "labels": [], "entities": [{"text": "Event detection", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8805191814899445}]}, {"text": "Normally, triggers are words or nuggets that evoke the events of interest.", "labels": [], "entities": []}, {"text": "Detecting events in an automatic way is challenging, not only because an event can be expressed in different words, but also because a word may express a variety of events in different contexts.", "labels": [], "entities": [{"text": "Detecting events", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.9029276371002197}]}, {"text": "In particular, the frequent utilization of common words, ambiguous words and pronouns in event mentions makes them harder to detect: 1) Generality -taken home <Transport> Ambiguity 1 -campaign in Iraq <Attack> Ambiguity 2 -political campaign <Elect> Coreference -Either its bad or good <Marry> A promising solution to this challenge is through semantic understanding.", "labels": [], "entities": [{"text": "semantic understanding", "start_pos": 344, "end_pos": 366, "type": "TASK", "confidence": 0.7554598450660706}]}, {"text": "Recently, neural networks have been widely used in this direction, which allows semantics of event mentions (trigger plus context) to be encoded in a high-dimensional latent feature space.", "labels": [], "entities": []}, {"text": "This facilitates the learning of deep-level semantics.", "labels": [], "entities": []}, {"text": "Besides, the use of neural networks not only strengthens current supervised classification of events but alleviates the complexity of feature engineering.", "labels": [], "entities": [{"text": "feature engineering", "start_pos": 134, "end_pos": 153, "type": "TASK", "confidence": 0.7618016004562378}]}, {"text": "However, compared to the earlier study, in which the features are carefully designed by experts, the neural network based methods suffer more from spurious features.", "labels": [], "entities": []}, {"text": "Here, spurious feature is specified as the latent information which looks like the semantically related information to an event, but actually not ().", "labels": [], "entities": []}, {"text": "For example, in the following sample, the semantic information of the word \"prison\" most probably enables spurious features to come into being, because the word often co-occurs with the trigger \"taken\" to evoke an Arrest-jail event instead of the ground-truth event Transport: 2) Prison authorities have given the nod for Anwar to betaken home later in the afternoon.", "labels": [], "entities": []}], "datasetContent": [{"text": "We test the presented model on the ACE 2005 corpus.", "labels": [], "entities": [{"text": "ACE 2005 corpus", "start_pos": 35, "end_pos": 50, "type": "DATASET", "confidence": 0.9865644971529642}]}, {"text": "The corpus is annotated with single-token event triggers and has 33 predefined event types (), along with one class \"None\" for the non-trigger tokens, constitutes a 34-class classification problem.", "labels": [], "entities": []}, {"text": "For comparison purpose, we use the corpus in the traditional way, randomly selecting 30 articles in English from different genres as the development set, and utilizing a separate set of 40 English newswire articles as the test set.", "labels": [], "entities": []}, {"text": "The remaining 529 English articles are used as the training set.", "labels": [], "entities": []}, {"text": "We evaluate our model using Precision (P), Recall (R) and F-score (F).", "labels": [], "entities": [{"text": "Precision (P)", "start_pos": 28, "end_pos": 41, "type": "METRIC", "confidence": 0.9550188034772873}, {"text": "Recall (R)", "start_pos": 43, "end_pos": 53, "type": "METRIC", "confidence": 0.963474690914154}, {"text": "F-score (F)", "start_pos": 58, "end_pos": 69, "type": "METRIC", "confidence": 0.9602289795875549}]}, {"text": "To facilitate the comparison, we review the best performance of the competitors, which has been evaluated using the same metrics, and publicly reported earlier.", "labels": [], "entities": []}, {"text": "Trigger identification shows the trigger identification performance.", "labels": [], "entities": [{"text": "Trigger identification", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.829791247844696}, {"text": "trigger identification", "start_pos": 33, "end_pos": 55, "type": "TASK", "confidence": 0.6419633626937866}]}, {"text": "It can be observed that SELF outperforms other models, with a performance gain of no less than 1.1% F-score.", "labels": [], "entities": [{"text": "SELF", "start_pos": 24, "end_pos": 28, "type": "TASK", "confidence": 0.6110619902610779}, {"text": "F-score", "start_pos": 100, "end_pos": 107, "type": "METRIC", "confidence": 0.9986380934715271}]}, {"text": "Frankly, the performance mainly benefits from the higher recall (78.8%).", "labels": [], "entities": [{"text": "recall", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.999800980091095}]}, {"text": "But in fact the relatively comparable precision (75.3%) to the recall reinforces the advantages.", "labels": [], "entities": [{"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9994624257087708}, {"text": "recall", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.9989431500434875}]}, {"text": "By contrast, although most of the compared models achieve much higher precision over SELF, they suffer greatly from the substantial gaps between precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9989051818847656}, {"text": "precision", "start_pos": 145, "end_pos": 154, "type": "METRIC", "confidence": 0.9991402626037598}, {"text": "recall", "start_pos": 159, "end_pos": 165, "type": "METRIC", "confidence": 0.9965295195579529}]}, {"text": "The advantage is offset by the greater loss of recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.9955736398696899}]}, {"text": "GAN plays an important role in optimizing Bi-RNN.", "labels": [], "entities": []}, {"text": "This is proven by the fact that SELF (Bi-LSTM+GAN) outperforms Nguyen et al (2016)'s Bi-RNN.", "labels": [], "entities": [{"text": "SELF", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.9483835697174072}]}, {"text": "To be honest, the models use two different kinds of recurrent units.", "labels": [], "entities": []}, {"text": "Bi-RNN uses GRUs, but SELF uses the units that possess LSTM.", "labels": [], "entities": [{"text": "Bi-RNN", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8972700238227844}, {"text": "GRUs", "start_pos": 12, "end_pos": 16, "type": "METRIC", "confidence": 0.8569393754005432}, {"text": "SELF", "start_pos": 22, "end_pos": 26, "type": "DATASET", "confidence": 0.8493704795837402}]}, {"text": "Nevertheless, GRU has been experimentally proven to be comparable in performance to LSTM.", "labels": [], "entities": [{"text": "GRU", "start_pos": 14, "end_pos": 17, "type": "METRIC", "confidence": 0.8755391240119934}]}, {"text": "This allows a fair comparison between Bi-RNN and SELF.", "labels": [], "entities": []}, {"text": "shows the performance of multi-class classification.", "labels": [], "entities": [{"text": "multi-class classification", "start_pos": 25, "end_pos": 51, "type": "TASK", "confidence": 0.7529555559158325}]}, {"text": "SELF achieves nearly the same F-score as's Hybrid, and outperforms the others.", "labels": [], "entities": [{"text": "SELF", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.8179563879966736}, {"text": "F-score", "start_pos": 30, "end_pos": 37, "type": "METRIC", "confidence": 0.9995403289794922}]}, {"text": "More importantly, SELF is the only one which obtains a performance higher than 70% for both precision and recall.", "labels": [], "entities": [{"text": "SELF", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.5780291557312012}, {"text": "precision", "start_pos": 92, "end_pos": 101, "type": "METRIC", "confidence": 0.9995623230934143}, {"text": "recall", "start_pos": 106, "end_pos": 112, "type": "METRIC", "confidence": 0.9965841770172119}]}], "tableCaptions": [{"text": " Table 1: Trigger identification performance", "labels": [], "entities": [{"text": "Trigger identification", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.982306718826294}]}, {"text": " Table 2: Detection performance (trigger identifi- cation plus multi-class classification)", "labels": [], "entities": [{"text": "Detection", "start_pos": 10, "end_pos": 19, "type": "TASK", "confidence": 0.8451597690582275}]}, {"text": " Table 3: Embedding types and training data (DEP:  Dependency grammar; PSN: Position)", "labels": [], "entities": []}, {"text": " Table 4: Experimental results of domain adaptation on the ACE 2005 corpus", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.7751833498477936}, {"text": "the ACE 2005 corpus", "start_pos": 55, "end_pos": 74, "type": "DATASET", "confidence": 0.8071465194225311}]}, {"text": " Table 5: Experimental results of domain adaptation on the TAC-KBP 2015 corpus (NA: not released)", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.7123807072639465}, {"text": "TAC-KBP 2015 corpus", "start_pos": 59, "end_pos": 78, "type": "DATASET", "confidence": 0.9260130325953165}]}]}