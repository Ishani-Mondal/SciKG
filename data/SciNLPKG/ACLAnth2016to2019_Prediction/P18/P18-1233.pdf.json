{"title": [{"text": "Cross-Domain Sentiment Classification with Target Domain Specific Information", "labels": [], "entities": [{"text": "Cross-Domain Sentiment Classification", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.7169638276100159}]}], "abstractContent": [{"text": "The task of adopting a model with good performance to a target domain that is different from the source domain used for training has received considerable attention in sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 168, "end_pos": 186, "type": "TASK", "confidence": 0.9703283905982971}]}, {"text": "Most existing approaches mainly focus on learning representations that are domain-invariant in both the source and target domains.", "labels": [], "entities": []}, {"text": "Few of them pay attention to domain specific information, which should also be informative.", "labels": [], "entities": []}, {"text": "In this work, we propose a method to simultaneously extract domain specific and invariant representations and train a classifier on each of the representation, respectively.", "labels": [], "entities": []}, {"text": "And we introduce a few target domain labeled data for learning domain-specific information.", "labels": [], "entities": []}, {"text": "To effectively utilize the target domain labeled data, we train the domain-invariant representation based classifier with both the source and target domain labeled data and train the domain-specific representation based classifier with only the target domain labeled data.", "labels": [], "entities": []}, {"text": "These two classifiers then boost each other in a co-training style.", "labels": [], "entities": []}, {"text": "Extensive sentiment analysis experiments demonstrated that the proposed method could achieve better performance than state-of-the-art methods.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.9528883695602417}]}], "introductionContent": [{"text": "Sentiment classification aims to automatically predict sentiment polarity of user generated sentiment data like movie reviews.", "labels": [], "entities": [{"text": "Sentiment classification", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.926019936800003}]}, {"text": "The exponential increase in the availability of online reviews and recommendations makes it an interesting topic in research and industrial areas.", "labels": [], "entities": []}], "datasetContent": [{"text": "Domain adaptation for sentiment classification has been widely studied in the NLP community.", "labels": [], "entities": [{"text": "Domain adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7581098079681396}, {"text": "sentiment classification", "start_pos": 22, "end_pos": 46, "type": "TASK", "confidence": 0.9701384007930756}]}, {"text": "The major experiments were performed on the benchmark made of reviews of Amazon products gathered by . This data set 1 contains Amazon product reviews from four different domains: Books, DVD, Electronics, and Kitchen appliances from Amazon.com.", "labels": [], "entities": []}, {"text": "Each review was originally associated with a rating of 1-5 stars.", "labels": [], "entities": []}, {"text": "For simplicity, we are only concerned with whether or not a review is positive (higher than 3 stars) or negative (3 stars or lower: Average prediction accuracy with 5 runs on target domain testing data set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 151, "end_pos": 159, "type": "METRIC", "confidence": 0.9711946249008179}]}, {"text": "The left group of models refer to previous state-of-the-art methods and the right group of models refer to the proposed model and some of its variants.", "labels": [], "entities": []}, {"text": "We list the p-values of the T-test between CoCMD and CMD-ft for more intuitive understanding.", "labels": [], "entities": [{"text": "T-test", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.880889892578125}, {"text": "CoCMD", "start_pos": 43, "end_pos": 48, "type": "DATASET", "confidence": 0.8982759118080139}, {"text": "CMD-ft", "start_pos": 53, "end_pos": 59, "type": "DATASET", "confidence": 0.8216580152511597}]}, {"text": "2,000 unlabeled target examples, and 50 labeled target examples for training.", "labels": [], "entities": []}, {"text": "To fine-tune the hyper-parameters, we randomly select 500 target examples as developing data set, leaving 2,500-5,500 examples for testing.", "labels": [], "entities": []}, {"text": "All of the compared methods and CoCMD share this setting.", "labels": [], "entities": [{"text": "CoCMD", "start_pos": 32, "end_pos": 37, "type": "DATASET", "confidence": 0.6775853633880615}]}], "tableCaptions": [{"text": " Table 1: Average prediction accuracy with 5 runs on target domain testing data set. The left group of  models refer to previous state-of-the-art methods and the right group of models refer to the proposed  model and some of its variants. We list the p-values of the T-test between CoCMD and CMD-ft for more  intuitive understanding.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9629057049751282}, {"text": "T-test", "start_pos": 267, "end_pos": 273, "type": "METRIC", "confidence": 0.9178072810173035}, {"text": "CoCMD", "start_pos": 282, "end_pos": 287, "type": "DATASET", "confidence": 0.895588755607605}, {"text": "CMD-ft", "start_pos": 292, "end_pos": 298, "type": "DATASET", "confidence": 0.8457843661308289}]}]}