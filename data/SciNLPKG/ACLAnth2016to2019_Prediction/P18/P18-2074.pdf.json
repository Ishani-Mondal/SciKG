{"title": [{"text": "Do Neural Network Cross-Modal Mappings Really Bridge Modalities?", "labels": [], "entities": [{"text": "Neural Network Cross-Modal Mappings", "start_pos": 3, "end_pos": 38, "type": "TASK", "confidence": 0.5650482326745987}]}], "abstractContent": [{"text": "Feed-forward networks are widely used in cross-modal applications to bridge modalities by mapping distributed vectors of one modality to the other, or to a shared space.", "labels": [], "entities": []}, {"text": "The predicted vectors are then used to perform e.g., retrieval or labeling.", "labels": [], "entities": []}, {"text": "Thus, the success of the whole system relies on the ability of the mapping to make the neighborhood structure (i.e., the pairwise similarities) of the predicted vectors akin to that of the target vectors.", "labels": [], "entities": []}, {"text": "However, whether this is achieved has not been investigated yet.", "labels": [], "entities": []}, {"text": "Here, we propose anew similarity measure and two ad hoc experiments to shed light on this issue.", "labels": [], "entities": [{"text": "similarity measure", "start_pos": 22, "end_pos": 40, "type": "METRIC", "confidence": 0.9270893633365631}]}, {"text": "In three cross-modal benchmarks we learn a large number of language-to-vision and vision-to-language neural network mappings (up to five layers) using a rich diversity of image and text features and loss functions.", "labels": [], "entities": []}, {"text": "Our results reveal that, surprisingly, the neighborhood structure of the predicted vectors consistently resembles more that of the input vectors than that of the target vectors.", "labels": [], "entities": []}, {"text": "Ina second experiment, we further show that untrained nets do not significantly disrupt the neighborhood (i.e., semantic) structure of the input vectors.", "labels": [], "entities": []}], "introductionContent": [{"text": "Neural network mappings are widely used to bridge modalities or spaces in cross-modal retrieval (, zero-shot learning () in building multimodal representations ( or in word translation (), to name a few.", "labels": [], "entities": [{"text": "Neural network mappings", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7408518592516581}, {"text": "word translation", "start_pos": 168, "end_pos": 184, "type": "TASK", "confidence": 0.7538989186286926}]}, {"text": "Typically, a neural network is firstly trained to predict the distributed vectors of one modality (or space) from the other.", "labels": [], "entities": []}, {"text": "At test time, some operation such as retrieval or labeling is performed based on the nearest neighbors of the predicted (mapped) vectors.", "labels": [], "entities": []}, {"text": "For instance, in zero-shot image classification, image features are mapped to the text space and the label of the nearest neighbor word is assigned.", "labels": [], "entities": [{"text": "zero-shot image classification", "start_pos": 17, "end_pos": 47, "type": "TASK", "confidence": 0.6595353682835897}]}, {"text": "Thus, the success of such systems relies entirely on the ability of the map to make the predicted vectors similar to the target vectors in terms of semantic or neighborhood structure.", "labels": [], "entities": []}, {"text": "However, whether neural nets achieve this goal in general has not been investigated yet.", "labels": [], "entities": []}, {"text": "In fact, recent work evidences that considerable information about the input modality propagates into the predicted modality (.", "labels": [], "entities": []}, {"text": "To shed light on these questions, we first introduce the (to the best of our knowledge) first existing measure to quantify similarity between the neighborhood structures of two sets of vectors.", "labels": [], "entities": []}, {"text": "Second, we perform extensive experiments in three benchmarks where we learn image-to-text and text-to-image neural net mappings using a rich variety of state-of-the-art text and image features and loss functions.", "labels": [], "entities": []}, {"text": "Our results reveal that, contrary to expectation, the semantic structure of the mapped vectors consistently resembles more that of the input vectors than that of the target vectors of interest.", "labels": [], "entities": []}, {"text": "Ina second experiment, by using six concept similarity tasks we show that the semantic structure of the input vectors is preserved after mapping them with an untrained network, further evidencing that feed-forward nets naturally preserve semantic information about the input.", "labels": [], "entities": []}, {"text": "Overall, we uncover and rise awareness of a largely: Effect of applying a mapping f to a (disconnected) manifold M with three hypothetical classes (, and \u2022).", "labels": [], "entities": []}, {"text": "ignored phenomenon relevant to a wide range of cross-modal / cross-space applications such as retrieval, zero-shot learning or image annotation.", "labels": [], "entities": []}, {"text": "Ultimately, this paper aims at: (1) Encouraging the development of better architectures to bridge modalities / spaces; (2) Advocating for the use of semantic-based criteria to evaluate the quality of predicted vectors such as the neighborhood-based measure proposed here, instead of purely geometric measures such as mean squared error (MSE).", "labels": [], "entities": [{"text": "mean squared error (MSE)", "start_pos": 317, "end_pos": 341, "type": "METRIC", "confidence": 0.9394404192765554}]}, {"text": "In the context of zero-shot learning, shortcomings of cross-space neural mappings have also been identified.", "labels": [], "entities": [{"text": "zero-shot learning", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.8384025394916534}]}], "datasetContent": [{"text": "To complement the setting above (Sect. 3.1), it is instructive to consider the limit case of an untrained network.", "labels": [], "entities": []}, {"text": "Concept similarity tasks provide a suitable setting to study the semantic structure of distributed representations ().", "labels": [], "entities": []}, {"text": "That is, semantically similar concepts should ideally be close together.", "labels": [], "entities": []}, {"text": "In particular, our interest is in comparing X with its projection f (X) through a mapping with random parameters, to understand the extent to which the mapping may disrupt or preserve the semantic structure of X.", "labels": [], "entities": []}, {"text": "Results below are with cosine neighbors and K = 10.", "labels": [], "entities": []}, {"text": "Euclidean neighbors yield similar results and are thus left to the Supplement.", "labels": [], "entities": [{"text": "Supplement", "start_pos": 67, "end_pos": 77, "type": "DATASET", "confidence": 0.4973800480365753}]}, {"text": "Similarly, results in ImageNet with GloVe embeddings are shown below and word2vec results in the Supplement.", "labels": [], "entities": [{"text": "Supplement", "start_pos": 97, "end_pos": 107, "type": "DATASET", "confidence": 0.5767803192138672}]}, {"text": "The choice of K = {5, 10, 30} had no visible effect on results.", "labels": [], "entities": []}, {"text": "Results with 3-and 5-layer nets did not show big differences with the results below (see Supplement).", "labels": [], "entities": [{"text": "Supplement", "start_pos": 89, "end_pos": 99, "type": "TASK", "confidence": 0.5265064835548401}]}, {"text": "The cosine and max-margin losses find that max-margin performs the best in their tasks, we do not find our result entirely surprising given that max-margin focuses on inter-class differences while we look also at intraclass neighbors (in fact, we do not require classes).", "labels": [], "entities": []}, {"text": "1 shows our core finding, namely that the semantic structure off (X) resembles more that of X than that of Y , for both lin and nn maps.", "labels": [], "entities": []}, {"text": "2 shows that untrained linear (f lin ) and neural net (f nn ) mappings preserve the semantic structure of the input X, complementing thus the findings of Experiment 1.", "labels": [], "entities": []}, {"text": "Experiment 1 concerns learning, while, by \"ablating\" the learning part and randomizing weights, Experiment 2 is revealing about the natural tendency of neural nets to preserve semantic information about the input, regardless of the choice of the target vectors and loss function.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Test mean nearest neighbor over- lap. Boldface indicates the largest score at each  mNNO 10 (X, f (X)) and mNNO 10 (Y, f (X)) pair,  which are abbreviated by X, f (X) and Y, f (X).", "labels": [], "entities": []}, {"text": " Table 2: Spearman correlations between human  ratings and the similarities (cosine or Euclidean)  predicted from the embeddings. Boldface denotes  best performance per input embedding type.", "labels": [], "entities": []}]}