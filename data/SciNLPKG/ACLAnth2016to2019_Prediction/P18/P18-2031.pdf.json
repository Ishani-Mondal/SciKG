{"title": [{"text": "Fighting Offensive Language on Social Media with Unsupervised Text Style Transfer", "labels": [], "entities": []}], "abstractContent": [{"text": "We introduce anew approach to tackle the problem of offensive language in online social media.", "labels": [], "entities": []}, {"text": "Our approach uses unsuper-vised text style transfer to translate offensive sentences into non-offensive ones.", "labels": [], "entities": []}, {"text": "We propose anew method for training encoder-decoders using non-parallel data that combines a collaborative classifier, attention and the cycle consistency loss.", "labels": [], "entities": []}, {"text": "Experimental results on data from Twitter and Red-dit show that our method outperforms a state-of-the-art text style transfer system in two out of three quantitative metrics and produces reliable non-offensive transferred sentences.", "labels": [], "entities": []}], "introductionContent": [{"text": "The use of offensive language is a common problem of abusive behavior on online social media networks.", "labels": [], "entities": []}, {"text": "Various work in the past have attacked this problem by using different machine learning models to detect abusive behavior ().", "labels": [], "entities": []}, {"text": "Most of these work follow the assumption that it is enough to filter out the entire offensive post.", "labels": [], "entities": []}, {"text": "However, a user that is consuming some online content may not want an entirely filtered out message but instead have it in a style that is non-offensive and still be able to comprehend it in a polite tone.", "labels": [], "entities": []}, {"text": "On the other hand, for those users who plan to post an offensive message, if one could not only alert that a content is offensive and will be blocked, but also offer a polite version of the message that can be posted, this could encourage many users to change their mind and avoid the profanity.", "labels": [], "entities": []}, {"text": "In this work we introduce anew way to deal with the problem of offensive language on social media.", "labels": [], "entities": []}, {"text": "Our approach consists on using style transfer techniques to translate offensive sentences into nonoffensive ones.", "labels": [], "entities": [{"text": "style transfer", "start_pos": 31, "end_pos": 45, "type": "TASK", "confidence": 0.7238923907279968}]}, {"text": "A simple encoder-decoder with attention () would be enough to create a reasonable translator if a large parallel corpus is available.", "labels": [], "entities": []}, {"text": "However, unlike machine translation, to the best of our knowledge, there exists no dataset of parallel data available for the case of offensive to non-offensive language.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 16, "end_pos": 35, "type": "TASK", "confidence": 0.7237421274185181}]}, {"text": "Moreover, it is important that the transferred text uses a vocabulary that is common in a particular application domain.", "labels": [], "entities": []}, {"text": "Therefore, unsupervised methods that do not use parallel data are needed to perform this task.", "labels": [], "entities": []}, {"text": "We propose a method to perform text style transfer addressing two main challenges arising when using non-parallel data in the encoder-decoder framework: (a) there is no straightforward way to train the encoder-decoder because we cannot use maximum likelihood estimation on the transferred text due to lack of ground truth; (b) it is difficult to preserve content while transferring the input to anew style.", "labels": [], "entities": [{"text": "text style transfer", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.6591461499532064}]}, {"text": "We address (a) using a single collaborative classifier, as an alternative to commonly used adversarial discriminators, e.g., as in (.", "labels": [], "entities": []}, {"text": "We approach (b) by using the attention mechanism combined with a cycle consistency loss.", "labels": [], "entities": [{"text": "consistency", "start_pos": 71, "end_pos": 82, "type": "METRIC", "confidence": 0.6909740567207336}]}, {"text": "In this work we also introduce two benchmark datasets for the task of transferring offensive to non-offensive text that are based on data from two popular social media networks: Twitter and Reddit.", "labels": [], "entities": []}, {"text": "We compare our method to the approach of using three quantitative metrics: classification accuracy, content preservation and perplexity.", "labels": [], "entities": [{"text": "classification", "start_pos": 75, "end_pos": 89, "type": "TASK", "confidence": 0.9425301551818848}, {"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.7446820735931396}, {"text": "content preservation", "start_pos": 100, "end_pos": 120, "type": "TASK", "confidence": 0.7979183197021484}]}, {"text": "Additionally, some qualitative results are also presented with a brief error analysis.", "labels": [], "entities": []}], "datasetContent": [{"text": "We created datasets of offensive and non-offensive texts by leveraging's preprocessing of Twitter ( and Reddit Politics () corpora, which contain a large number of social media posts.", "labels": [], "entities": []}, {"text": "have used Twitter and Reddit datasets to evaluate the impact of offensive language and hate speech in neural dialogue systems.", "labels": [], "entities": []}, {"text": "We classified each entry in the two datasets using the offensive language and hate speech classifier from ().", "labels": [], "entities": []}, {"text": "For Reddit, since the posts are long, we performed the classification at the sentence level.", "labels": [], "entities": []}, {"text": "We note that since ground truth (parallel data) is not available, it is important to use the same classifier for data generation and evaluation so as to have a fair comparison and avoid inconsistencies.", "labels": [], "entities": [{"text": "data generation", "start_pos": 113, "end_pos": 128, "type": "TASK", "confidence": 0.7813595533370972}]}, {"text": "Therefore, we use the classifier from ( to test the performance of the compared algorithms in Sec.", "labels": [], "entities": []}, {"text": "For our experiments, we used sentences/tweets with size between 2 and 15 words and removed repeated entries, which were frequent in Reddit.", "labels": [], "entities": []}, {"text": "The final datasets have the following number of instances: Twitter -train (offensive / non-ofensive), dev (offensive), test; Reddit -, dev, test . In both training sets the number of non-offensive entries is much larger than of the offensive ones, which is not a problem since the objective is to have the best possible transfer to the non-offensive domain.", "labels": [], "entities": []}, {"text": "We limited the vocabulary size by using words with frequency equal or larger than 70 in Reddit (Twitter) dataset.", "labels": [], "entities": [{"text": "Reddit (Twitter) dataset", "start_pos": 88, "end_pos": 112, "type": "DATASET", "confidence": 0.7706601858139038}]}, {"text": "All the other words are replaced by a placeholder token.", "labels": [], "entities": []}, {"text": "In all the presented experiments, we have used the same model parameters and the same configuration: the encoder/decoder is a single layer GRU RNN with 200 hidden neurons; the classifier is a single layer CNN with a set of filters of width 1, 2, 3 and 4, and size 128 (the same configuration as in the discriminators of).", "labels": [], "entities": []}, {"text": "Following, we have also used randomly initialized word embeddings of size 100, and trained the model using Adam optimizer with the minibatch size of 64 and learning rate of 0.0005.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 156, "end_pos": 169, "type": "METRIC", "confidence": 0.9708884656429291}]}, {"text": "The validation set has been used to select the best model by early stopping.", "labels": [], "entities": []}, {"text": "Our model has a quite fast convergence rate and achieves good results within just 1 epoch for the Reddit dataset and 5 epochs for the Twitter dataset.", "labels": [], "entities": [{"text": "Reddit dataset", "start_pos": 98, "end_pos": 112, "type": "DATASET", "confidence": 0.9613455235958099}, {"text": "Twitter dataset", "start_pos": 134, "end_pos": 149, "type": "DATASET", "confidence": 0.9686462581157684}]}, {"text": "Our baseline is the model of 1 and it has been used with the default hyperparameter setting proposed by the authors.", "labels": [], "entities": []}, {"text": "We have trained the baseline neural net for three days using a K40 GPU machine, corresponding to about 13 epochs on the Twitter dataset and 5 epochs on the Reddit dataset.", "labels": [], "entities": [{"text": "Twitter dataset", "start_pos": 120, "end_pos": 135, "type": "DATASET", "confidence": 0.9663348495960236}, {"text": "Reddit dataset", "start_pos": 156, "end_pos": 170, "type": "DATASET", "confidence": 0.9595176577568054}]}, {"text": "The validation set has also been used to select the best model by early stopping.", "labels": [], "entities": []}, {"text": "CP PPL As can be seen from the table, our proposed method achieves high accuracy on both datasets, which means that almost 100% of the time's classifier detects that the transferred sentences are non-offensive.", "labels": [], "entities": [{"text": "CP PPL", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8910762667655945}, {"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9993796348571777}]}, {"text": "In terms of the content preservation, for both datasets our method also produces better results (the closer to 1 the better) when compared to.", "labels": [], "entities": [{"text": "content preservation", "start_pos": 16, "end_pos": 36, "type": "TASK", "confidence": 0.7472037374973297}]}, {"text": "The use of the back transfer loss and the attention mechanism makes our model good at preserving the original sentence content while being precise at replacing offensive words by the non-offensive ones.", "labels": [], "entities": []}, {"text": "Also observe from that, quite often,'s model changes many words in the original sentence, significantly modifying the content.", "labels": [], "entities": []}, {"text": "On the other hand, our model produces worse results in terms of perplexity values.", "labels": [], "entities": []}, {"text": "We believe this can be due to one type of mistake that is frequent among the transferred sentences and that is illustrated in.", "labels": [], "entities": []}, {"text": "The model uses the same non-offensive word (e.g. big) to replace an offensive word (e.g. f***ing) almost everywhere, which produces many unusual and unexpected sentences.", "labels": [], "entities": []}, {"text": "We have performed ablation experiments by removing some components of the proposed model.", "labels": [], "entities": []}, {"text": "The results for the Twitter dataset are shown in Table 4.", "labels": [], "entities": [{"text": "Twitter dataset", "start_pos": 20, "end_pos": 35, "type": "DATASET", "confidence": 0.960587352514267}]}, {"text": "We can see that attention and back-transfer loss play important roles in the model.", "labels": [], "entities": []}, {"text": "In particular, when both of them are removed (last row in), although the classification accuracy improves, the perplexity and the content preservation drop significantly.", "labels": [], "entities": [{"text": "classification", "start_pos": 73, "end_pos": 87, "type": "TASK", "confidence": 0.9218248724937439}, {"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9574119448661804}, {"text": "perplexity", "start_pos": 111, "end_pos": 121, "type": "METRIC", "confidence": 0.9821343421936035}]}, {"text": "This behavior happens due to the trade off that the decoder has to balance when transferring a sentence from a style to another.", "labels": [], "entities": []}, {"text": "The decoder must maintain a proper balance between transferring to the correct style and generating sentences of good quality.", "labels": [], "entities": []}, {"text": "Each of these properties can easily be achieved on its own, e.g., copying the entire input sentence will give low perplexity and good content preservation but low accuracy, on the other hand, outputting a single keyword can give high accuracy but high perplexity and low content preservation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 163, "end_pos": 171, "type": "METRIC", "confidence": 0.99558025598526}, {"text": "accuracy", "start_pos": 234, "end_pos": 242, "type": "METRIC", "confidence": 0.9777286648750305}]}, {"text": "While the classification loss guides the decoder to generate sentences that belong to the target style, the back transfer loss and the attention mechanism encourage the decoder to copy words from the input sentence.", "labels": [], "entities": []}, {"text": "When both back transfer loss and attention are removed, the model is encouraged to just meet the classification requirement in the transfer step.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Classification accuracy, content preserva- tion and perplexity for two datasets.", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9349563717842102}, {"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9800523519515991}]}, {"text": " Table 4: Ablation results for the Twitter dataset.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9951602816581726}, {"text": "Twitter dataset", "start_pos": 35, "end_pos": 50, "type": "DATASET", "confidence": 0.930073469877243}]}]}