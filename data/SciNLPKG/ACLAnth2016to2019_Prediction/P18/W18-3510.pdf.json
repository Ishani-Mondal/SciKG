{"title": [{"text": "EmotionX-JTML: Detecting emotions with Attention", "labels": [], "entities": [{"text": "Detecting emotions", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.9028028249740601}]}], "abstractContent": [{"text": "This paper addresses the problem of automatic recognition of emotions in text-only conversational datasets for the EmotionX challenge.", "labels": [], "entities": [{"text": "automatic recognition of emotions in text-only conversational", "start_pos": 36, "end_pos": 97, "type": "TASK", "confidence": 0.7906544634274074}]}, {"text": "Emotion is a human characteristic expressed through several modalities (e.g., auditory, visual, tactile), therefore, trying to detect emotions only from the text becomes a difficult task even for humans.", "labels": [], "entities": []}, {"text": "This paper evaluates several neural architectures based on Attention Models, which allow extracting relevant parts of the context within a conversation to identify the emotion associated with each utterance.", "labels": [], "entities": []}, {"text": "Empirical results the effectiveness of the attention model for the Emo-tionPush dataset compared to the baseline models, and other cases show better results with simpler models.", "labels": [], "entities": [{"text": "Emo-tionPush dataset", "start_pos": 67, "end_pos": 87, "type": "DATASET", "confidence": 0.920372724533081}]}], "introductionContent": [{"text": "With technology increasingly present in people's lives, human-machine interaction needs to be as natural as possible, including the recognition of emotions.", "labels": [], "entities": []}, {"text": "Emotions are an intrinsic characteristic of humans, often associated with mood, temperament, personality, disposition or motivation.", "labels": [], "entities": []}, {"text": "Moreover, emotions are inherently multimodal, as such, we perceived them in great detail through vision or speech (Jain and Li, 2011).", "labels": [], "entities": []}, {"text": "Detecting emotions from text poses particular difficulties.", "labels": [], "entities": [{"text": "Detecting emotions from text", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8878830969333649}]}, {"text": "For instance, an issue that arises from working with conversational text data is that the same utterance (message) can express different emotions depending on its context.", "labels": [], "entities": []}, {"text": "The table 1 illustrate the issue with some utterances expressing different emotions with the same word from the challenge datasets.", "labels": [], "entities": []}, {"text": "Despite improvements with neural architectures, given an utterance in a conversation without any previous context, it is not always obvious even for human beings to identify the emotion associated.", "labels": [], "entities": []}, {"text": "In many cases, the classification of utterances that are too short is hard.", "labels": [], "entities": [{"text": "classification of utterances", "start_pos": 19, "end_pos": 47, "type": "TASK", "confidence": 0.8956729769706726}]}, {"text": "For instance, the utterance 'Okay' can be either an Agreement or indicative of Anger, for such cases the context plays an essential role at disambiguation.", "labels": [], "entities": []}, {"text": "Therefore, using context information from the previous utterances in a conversation flow is a crucial step for improving DA classification.", "labels": [], "entities": [{"text": "DA classification", "start_pos": 121, "end_pos": 138, "type": "TASK", "confidence": 0.9884023070335388}]}, {"text": "In this paper, we explore the use of AMs to learn the context representation, as a manner to differentiate the current utterance from its context as well as a mechanism to highlight the most relevant information while ignoring unnecessary parts for emotion classification.", "labels": [], "entities": [{"text": "emotion classification", "start_pos": 249, "end_pos": 271, "type": "TASK", "confidence": 0.737236738204956}]}, {"text": "We propose and compare different neural-based methods for context representation learning by leveraging a recurrent neu-ral network architecture with LSTM) or gated recurrent units (GRUs) () in combination with AMs.", "labels": [], "entities": [{"text": "context representation learning", "start_pos": 58, "end_pos": 89, "type": "TASK", "confidence": 0.8276662230491638}]}], "datasetContent": [{"text": "For the experiments, neural architectures apply an end-to-end learning approach, i.e., with minimum text preprocessing.", "labels": [], "entities": []}, {"text": "For cross-validation, the splitting strategy divides them by the dialogues, similar to (.", "labels": [], "entities": []}, {"text": "The challenge evaluates the performance using the metrics weighted accuracy (WA) and unweighted accuracy (UWA), as defined in equations 5 and 6.", "labels": [], "entities": [{"text": "accuracy (WA)", "start_pos": 67, "end_pos": 80, "type": "METRIC", "confidence": 0.9309534281492233}, {"text": "unweighted accuracy (UWA)", "start_pos": 85, "end_pos": 110, "type": "METRIC", "confidence": 0.8266761302947998}]}, {"text": "where a l denotes the accuracy of emotion class land s l denotes the percentage of utterances in emotion class l.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9993501305580139}]}, {"text": "The shows the experimental results including baselines for the emotion detection task.", "labels": [], "entities": [{"text": "emotion detection task", "start_pos": 63, "end_pos": 85, "type": "TASK", "confidence": 0.8416478435198466}]}, {"text": "This paper evaluated a Multinomial Naive Bayes (NB) model and the proposed Attention Model (AM).", "labels": [], "entities": []}, {"text": "Surprisingly, NB model outperforms neural models for UWA metric in both datasets with 57.4% and 57.3%.", "labels": [], "entities": []}, {"text": "This result could be related to the size of the dataset since neural architectures take advantage of learning on large-scale datasets.", "labels": [], "entities": []}, {"text": "The attention model performs well on the EmotionPush dataset but fails to improve on the Friends datasets for WA metric.", "labels": [], "entities": [{"text": "EmotionPush dataset", "start_pos": 41, "end_pos": 60, "type": "DATASET", "confidence": 0.9005207419395447}, {"text": "Friends datasets", "start_pos": 89, "end_pos": 105, "type": "DATASET", "confidence": 0.7734383940696716}]}, {"text": "Further evaluation of the results as depicted in the, show that the label imbalance for neutral emotion affects the predictions of other labels.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Weighted and unweighted accuracy on Friends and EmotionPush", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9814797043800354}]}]}