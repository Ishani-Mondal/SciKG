{"title": [], "abstractContent": [{"text": "This study describes the approach developed by the Tilburg University team to the shallow track of the Multilingual Surface Realization Shared Task 2018 (SR18).", "labels": [], "entities": [{"text": "Tilburg University team", "start_pos": 51, "end_pos": 74, "type": "DATASET", "confidence": 0.8163201014200846}, {"text": "Multilingual Surface Realization Shared Task 2018 (SR18)", "start_pos": 103, "end_pos": 159, "type": "TASK", "confidence": 0.7584547764725156}]}, {"text": "Based on Castro Ferreira et al.", "labels": [], "entities": []}, {"text": "(2017), the approach works by first preprocess-ing an input dependency tree into an ordered linearized string, which is then realized using a statistical machine translation model.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 142, "end_pos": 173, "type": "TASK", "confidence": 0.6158034801483154}]}, {"text": "Our approach shows promising results, with BLEU scores above 40 for 4 different languages in development and test sets (English, French, Italian and Spanish) and above 30 for the Dutch and Portuguese languages.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 43, "end_pos": 47, "type": "METRIC", "confidence": 0.9989131689071655}]}, {"text": "The model is publicly available 1 .", "labels": [], "entities": []}], "introductionContent": [{"text": "This study presents the approach developed by the Tilburg University team for the shallow track of the Multilingual Surface Realization Shared Task 2018 (SR18) (.", "labels": [], "entities": [{"text": "Tilburg University team", "start_pos": 50, "end_pos": 73, "type": "DATASET", "confidence": 0.8569932381312052}, {"text": "Multilingual Surface Realization Shared Task 2018 (SR18)", "start_pos": 103, "end_pos": 159, "type": "TASK", "confidence": 0.7731781701246897}]}, {"text": "Given a lemmatized dependency tree without word order information, the goal of this task consists of linearizing the lemmas in the correct order and realizing them as a surface string with the proper morphological form.", "labels": [], "entities": []}, {"text": "For the task, parallel datasets were provided for 10 different languages and we developed our model for 6 out of the 10 languages (Dutch, English, French, Italian, Portuguese, Spanish).", "labels": [], "entities": []}, {"text": "We started from the surface realization approach described in Castro, where a semantic graph structure is first preprocessed into a preordered linearized form, which is subsequently converted into text using a statistical https://github.com/ThiagoCF05/ Dep2Text machine translation model implemented in Moses (.", "labels": [], "entities": [{"text": "Dep2Text machine translation", "start_pos": 253, "end_pos": 281, "type": "TASK", "confidence": 0.7339315215746561}]}, {"text": "However for this shared task, instead of a semantic structure, our current approach preprocesses the lemmas of the dependency tree into an ordered linearized version.", "labels": [], "entities": []}, {"text": "Although for the task sufficient parallel corpus data, pairing dependency tree inputs to textual outputs, were made available to train and test our approach, alignments between the source lemmas and the target words were not provided.", "labels": [], "entities": []}, {"text": "Since this information is crucial to train our approach, we implemented a method consisting of four consecutive strategies to obtain the alignments.", "labels": [], "entities": []}, {"text": "Except for two languages (Dutch and Portuguese, ironically), our approach showed promising results, with BLEU scores higher than 40 in development and test sets.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 105, "end_pos": 109, "type": "METRIC", "confidence": 0.9989388585090637}]}, {"text": "In the remainder of this paper, we describe the method in more detail: Section 2 explains the alignment method, Section 3 describes the general approach, Section 4 describes the results and discussion of our approach in development and test sets and, finally, Section 5 concludes the study, also describing future work which can be done to improve the model.", "labels": [], "entities": [{"text": "alignment", "start_pos": 94, "end_pos": 103, "type": "TASK", "confidence": 0.953616738319397}]}, {"text": "only provides models for 6 out of the 10 covered languages, the approach described in this study is limited to these six.", "labels": [], "entities": []}, {"text": "For the Portuguese language, we also parsed the contractions between preposition and determiners (e.g., da/do and na/no, corresponding to of the and in the in English) into two single tokens (de a/de o and em a/em o for the previous examples).", "labels": [], "entities": []}, {"text": "Once the target texts were preprocessed, the first step simply compares the lemmas of the source side with the words on the target side.", "labels": [], "entities": []}, {"text": "If a lemma on the source side and a word on the target side matched with each other and not with any other element, they were aligned.", "labels": [], "entities": []}, {"text": "In the second step, we applied the same comparison used in the first step, but now for the lemmas of the target words.", "labels": [], "entities": []}, {"text": "If lemmas on source and target sides only matched each other and no other element, the source lemma was aligned to the corresponding target word.", "labels": [], "entities": []}, {"text": "The third step aimed to solve situations where a source lemma matches more than one element on the other side, by aligning the source and target lemmas with the same dependency tags which only matched each other.", "labels": [], "entities": []}, {"text": "Finally, the fourth step matched the remaining source and target lemmas of a parallel instance with the shortest string distance.", "labels": [], "entities": []}, {"text": "Based on the alignment between source and target sides of a parallel instance, we trained our approach, as described in the following section.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: BLEU scores of our approach in the tok- enized development sets.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9994220733642578}]}, {"text": " Table 2: BLEU, DIST and NIST scores of our ap- proach in the original (non-tokenized) test sets.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9993226528167725}, {"text": "DIST", "start_pos": 16, "end_pos": 20, "type": "METRIC", "confidence": 0.9147264957427979}]}]}