{"title": [{"text": "AllenNLP: A Deep Semantic Natural Language Processing Platform", "labels": [], "entities": [{"text": "AllenNLP", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9150227308273315}]}], "abstractContent": [{"text": "Modern natural language processing (NLP) research requires writing code.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 7, "end_pos": 40, "type": "TASK", "confidence": 0.803816537062327}]}, {"text": "Ideally this code would provide a precise definition of the approach, easy repeatability of results, and a basis for extending the research.", "labels": [], "entities": []}, {"text": "However, many research codebases bury high-level parameters under implementation details, are challenging to run and debug, and are difficult enough to extend that they are more likely to be rewritten.", "labels": [], "entities": []}, {"text": "This paper describes AllenNLP, a library for applying deep learning methods to NLP research, which addresses these issues with easy-to-use command-line tools, declarative configuration-driven experiments, and modular NLP abstractions.", "labels": [], "entities": [{"text": "AllenNLP", "start_pos": 21, "end_pos": 29, "type": "DATASET", "confidence": 0.9767505526542664}]}, {"text": "AllenNLP has already increased the rate of research experimentation and the sharing of NLP components at the Allen Institute for Artificial Intelligence, and we are working to have the same impact across the field.", "labels": [], "entities": [{"text": "AllenNLP", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9816780686378479}]}], "introductionContent": [{"text": "Neural network models are now the state-of-theart fora wide range of tasks such as text classification, machine translation (, semantic role labeling (, coreference resolution (, and semantic parsing (.", "labels": [], "entities": [{"text": "text classification", "start_pos": 83, "end_pos": 102, "type": "TASK", "confidence": 0.8025240302085876}, {"text": "machine translation", "start_pos": 104, "end_pos": 123, "type": "TASK", "confidence": 0.8292857110500336}, {"text": "semantic role labeling", "start_pos": 127, "end_pos": 149, "type": "TASK", "confidence": 0.6355188290278116}, {"text": "coreference resolution", "start_pos": 153, "end_pos": 175, "type": "TASK", "confidence": 0.9155487418174744}, {"text": "semantic parsing", "start_pos": 183, "end_pos": 199, "type": "TASK", "confidence": 0.7200131416320801}]}, {"text": "However it can be surprisingly difficult to tune new models or replicate existing results.", "labels": [], "entities": []}, {"text": "State-of-the-art deep learning models often takeover a week to train on modern GPUs and are sensitive to initialization and hyperparameter settings.", "labels": [], "entities": []}, {"text": "Furthermore, reference implementations often re-implement NLP components from scratch and make it difficult to reproduce results, creating a barrier to entry for research on many problems.", "labels": [], "entities": []}, {"text": "AllenNLP, a platform for research on deep learning methods in natural language processing, is designed to address these problems and to significantly lower barriers to high quality NLP research by \u2022 implementing useful NLP abstractions that make it easy to write higher-level model code fora broad range of NLP tasks, swap out components, and re-use implementations, \u2022 handling common NLP deep learning problems, such as masking and padding, and keeping these low-level details separate from the high-level model and experiment definitions, \u2022 defining experiments using declarative configuration files, which provide a high-level summary of a model and its training, and make it easy to change the deep learning architecture and tune hyper-parameters, and \u2022 sharing models through live demos, making complex NLP accessible and debug-able.", "labels": [], "entities": [{"text": "AllenNLP", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9749334454536438}]}, {"text": "The AllenNLP website 1 provides tutorials, API documentation, pretrained models, and source code 2 . The AllenNLP platform has a permissive Apache 2.0 license and is easy to download and install via pip, a Docker image, or cloning the GitHub repository.", "labels": [], "entities": [{"text": "AllenNLP website 1", "start_pos": 4, "end_pos": 22, "type": "DATASET", "confidence": 0.9729346434275309}, {"text": "AllenNLP", "start_pos": 105, "end_pos": 113, "type": "DATASET", "confidence": 0.9451208114624023}]}, {"text": "It includes reference implementations for recent state-of-the-art models (see Section 3) that can be easily run (to make predictions on arbitrary new inputs) and retrained with different parameters or on new data.", "labels": [], "entities": []}, {"text": "These pretrained models have interactive online demos 3 with visualizations to help interpret model decisions and make predictions accessible to others.", "labels": [], "entities": []}, {"text": "The reference implementations provide examples of the framework functionality (Section 2) and also serve as baselines for future research.", "labels": [], "entities": []}, {"text": "AllenNLP is an ongoing open-source effort maintained by several full-time engineers and researchers at the Allen Institute for Artificial Intelligence, as well as interns from top PhD programs and contributors from the broader NLP community.", "labels": [], "entities": [{"text": "AllenNLP", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9703196883201599}]}, {"text": "It is used widespread internally for research on commonsense, logical reasoning, and stateof-the-art NLP components such as: constituency parsers, semantic parsing, and word representations.", "labels": [], "entities": [{"text": "constituency parsers", "start_pos": 125, "end_pos": 145, "type": "TASK", "confidence": 0.6749556809663773}, {"text": "semantic parsing", "start_pos": 147, "end_pos": 163, "type": "TASK", "confidence": 0.7122158110141754}, {"text": "word representations", "start_pos": 169, "end_pos": 189, "type": "TASK", "confidence": 0.7249854803085327}]}, {"text": "AllenNLP is gaining traction externally and we want to invest to make it the standard for advancing NLP research using PyTorch.", "labels": [], "entities": [{"text": "AllenNLP", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9841835498809814}, {"text": "PyTorch", "start_pos": 119, "end_pos": 126, "type": "DATASET", "confidence": 0.8914316296577454}]}], "datasetContent": [{"text": "The primary design goal of AllenNLP is to make it easy to do good science with controlled experiments.", "labels": [], "entities": [{"text": "AllenNLP", "start_pos": 27, "end_pos": 35, "type": "DATASET", "confidence": 0.9654890298843384}]}, {"text": "Because of the abstractions described in Section 2.2, large parts of the model architecture and training-related hyper-parameters can be configured outside of model code.", "labels": [], "entities": []}, {"text": "This makes it easy to clearly specify the important decisions that define anew model in configuration, and frees the researcher from needing to code all of the implementation details from scratch.", "labels": [], "entities": []}, {"text": "This architecture design is accomplished in AllenNLP using a HOCON 5 configuration file that specifies, e.g., which text representations and encoders to use in an experiment.", "labels": [], "entities": [{"text": "AllenNLP", "start_pos": 44, "end_pos": 52, "type": "DATASET", "confidence": 0.9793441891670227}, {"text": "HOCON 5 configuration file", "start_pos": 61, "end_pos": 87, "type": "DATASET", "confidence": 0.8045313358306885}]}, {"text": "The mapping from strings in the configuration file to instantiated objects in code is done through the use of a registry, which allows users of the library to add new implementations of any of the provided abstractions, We use it as JSON with comments.", "labels": [], "entities": []}, {"text": "See https://github.com/lightbend/config/blob/master/HOCON.md for the full spec. or even to create their own new abstractions.", "labels": [], "entities": []}, {"text": "While some entries in the configuration file are optional, many are required and if unspecified AllenNLP will raise a ConfigurationError when reading the configuration.", "labels": [], "entities": [{"text": "AllenNLP", "start_pos": 96, "end_pos": 104, "type": "DATASET", "confidence": 0.9055169820785522}, {"text": "ConfigurationError", "start_pos": 118, "end_pos": 136, "type": "METRIC", "confidence": 0.9620767831802368}]}, {"text": "Additionally, when a configuration file is loaded, AllenNLP logs the configuration values, providing a record of both specified and default parameters for your model.", "labels": [], "entities": [{"text": "AllenNLP", "start_pos": 51, "end_pos": 59, "type": "DATASET", "confidence": 0.9026111364364624}]}], "tableCaptions": []}