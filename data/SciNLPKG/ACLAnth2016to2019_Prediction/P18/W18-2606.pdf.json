{"title": [{"text": "Robust and Scalable Differentiable Neural Computer for Question Answering", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.8211658596992493}]}], "abstractContent": [{"text": "Deep learning models are often not easily adaptable to new tasks and require task-specific adjustments.", "labels": [], "entities": []}, {"text": "The differen-tiable neural computer (DNC), a memory-augmented neural network, is designed as a general problem solver which can be used in a wide range of tasks.", "labels": [], "entities": [{"text": "problem solver", "start_pos": 103, "end_pos": 117, "type": "TASK", "confidence": 0.7193095684051514}]}, {"text": "But in reality , it is hard to apply this model to new tasks.", "labels": [], "entities": []}, {"text": "We analyze the DNC and identify possible improvements within the application of question answering.", "labels": [], "entities": [{"text": "DNC", "start_pos": 15, "end_pos": 18, "type": "DATASET", "confidence": 0.825391411781311}, {"text": "question answering", "start_pos": 80, "end_pos": 98, "type": "TASK", "confidence": 0.8644731938838959}]}, {"text": "This motivates a more robust and scalable DNC (rsDNC).", "labels": [], "entities": []}, {"text": "The objective precondition is to keep the general character of this model intact while making its application more reliable and speeding up its required training time.", "labels": [], "entities": []}, {"text": "The rsDNC is distinguished by a more robust training, a slim memory unit and a bidirectional architecture.", "labels": [], "entities": []}, {"text": "We not only achieve new state-of-the-art performance on the bAbI task, but also minimize the performance variance between different initializations.", "labels": [], "entities": []}, {"text": "Furthermore, we demonstrate the simplified applicability of the rsDNC to new tasks with passable results on the CNN RC task without adap-tions.", "labels": [], "entities": []}], "introductionContent": [{"text": "In contrast to traditional statistical models, which often require a large amount of human effort on feature engineering and task-specific adjustments, a promise of deep learning is that little taskspecific knowledge and minimal adaption is required to achieve state-of-the-art performance on different tasks.", "labels": [], "entities": []}, {"text": "But in reality, many deep learning solutions have to be adapted to a specific task to achieve good performance.", "labels": [], "entities": []}, {"text": "However, there are more universal approaches for example the differentiable neural computer (DNC).", "labels": [], "entities": []}, {"text": "It is introduced by as a general artificial neural network (ANN) model with an external memory \"to solve complex, structured tasks\".", "labels": [], "entities": []}, {"text": "It can be seen as a generic memoryaugmentation framework.", "labels": [], "entities": []}, {"text": "Unlike a vanilla ANN, it separates computation and memorization with a computational controller and a memory unit, which are independently modifiable.", "labels": [], "entities": []}, {"text": "This allows a more accurate model design.", "labels": [], "entities": []}, {"text": "Due to its fully differentiable design, it can be learned in a supervised fashion.", "labels": [], "entities": []}, {"text": "The original paper shows applications on the bAbI question answering (QA) task, graph experiments and a reinforcement learning block puzzle solver (.", "labels": [], "entities": [{"text": "bAbI question answering (QA) task", "start_pos": 45, "end_pos": 78, "type": "TASK", "confidence": 0.7885780121598925}, {"text": "reinforcement learning block puzzle solver", "start_pos": 104, "end_pos": 146, "type": "TASK", "confidence": 0.6261871516704559}]}, {"text": "But when applying this model to new QA tasks, no satisfying results are achieved.", "labels": [], "entities": []}, {"text": "The issues of QA are the huge vocabulary, the length of the contexts and the required model complexity to find the correct answer.", "labels": [], "entities": [{"text": "QA", "start_pos": 14, "end_pos": 16, "type": "TASK", "confidence": 0.959159791469574}]}, {"text": "In this work, we analyze the DNC in QA tasks and identify four main challenges: 1.", "labels": [], "entities": []}, {"text": "High memory consumption makes it hard to train large models efficiently.", "labels": [], "entities": []}, {"text": "2. The large variance in training performance within different initializations.", "labels": [], "entities": []}, {"text": "3. A slow and unstable convergence requires long varying training times.", "labels": [], "entities": []}, {"text": "4. The unidirectional architecture makes it hard to handle variable question appearance.", "labels": [], "entities": []}, {"text": "This work addresses these issues while keeping the general character of the model intact.", "labels": [], "entities": []}, {"text": "We extend the DNC to be more robust and scalable (rs-DNC) with the following contributions: 1.", "labels": [], "entities": []}, {"text": "A robust training with a strong focus on an early memory usage and normalization.", "labels": [], "entities": []}, {"text": "2. The usage of a slim, memory efficient, content-based memory unit for QA tasks.", "labels": [], "entities": []}, {"text": "3. A bidirectional DNC which allows a richer encoding of the input sequences.", "labels": [], "entities": []}, {"text": "The rsDNC is evaluated on two datasets.", "labels": [], "entities": []}, {"text": "On the synthetic bAbI task (, we show performance improvements by 80% compared to the DNC.", "labels": [], "entities": []}, {"text": "These are new state-of-theart results within multiple runs in a joint training.", "labels": [], "entities": []}, {"text": "We also decrease the variance by up to 90% between different random initializations.", "labels": [], "entities": [{"text": "variance", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9751767516136169}]}, {"text": "Additionally, with training-data augmentation on one task, our model solves all tasks and provides the bestrecorded results to the best of our knowledge.", "labels": [], "entities": []}, {"text": "On the CNN RC task (, we show the adaptability of the rsDNC and achieve passable results without task-specific adaption.", "labels": [], "entities": [{"text": "CNN RC task", "start_pos": 7, "end_pos": 18, "type": "DATASET", "confidence": 0.9203281998634338}]}], "datasetContent": [{"text": "The rsDNC and the BrsDNC are evaluated on two datasets, the bAbI task and the CNN RC task.", "labels": [], "entities": [{"text": "BrsDNC", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9905539155006409}, {"text": "CNN RC task", "start_pos": 78, "end_pos": 89, "type": "DATASET", "confidence": 0.753049890200297}]}], "tableCaptions": [{"text": " Table 2: The validation and test accuracy (%) of  the rsDNC/BrsDNC and others on CNN dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9486245512962341}, {"text": "BrsDNC", "start_pos": 61, "end_pos": 67, "type": "METRIC", "confidence": 0.8834233283996582}, {"text": "CNN dataset", "start_pos": 82, "end_pos": 93, "type": "DATASET", "confidence": 0.983028382062912}]}]}