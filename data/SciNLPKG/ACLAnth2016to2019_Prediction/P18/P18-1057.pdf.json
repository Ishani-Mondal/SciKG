{"title": [{"text": "TutorialBank: A Manually-Collected Corpus for Prerequisite Chains, Survey Extraction and Resource Recommendation", "labels": [], "entities": []}], "abstractContent": [{"text": "The field of Natural Language Processing (NLP) is growing rapidly, with new research published daily along with an abundance of tutorials, codebases and other on-line resources.", "labels": [], "entities": [{"text": "Natural Language Processing (NLP)", "start_pos": 13, "end_pos": 46, "type": "TASK", "confidence": 0.780857652425766}]}, {"text": "In order to learn this dynamic field or stay up-to-date on the lat-est research, students as well as educators and researchers must constantly sift through multiple sources to find valuable, relevant information.", "labels": [], "entities": []}, {"text": "To address this situation , we introduce TutorialBank, anew, publicly available dataset which aims to facilitate NLP education and research.", "labels": [], "entities": []}, {"text": "We have manually collected and categorized over 6,300 resources on NLP as well as the related fields of Artificial Intelligence (AI), Machine Learning (ML) and Information Retrieval (IR).", "labels": [], "entities": [{"text": "Information Retrieval (IR)", "start_pos": 160, "end_pos": 186, "type": "TASK", "confidence": 0.8593365550041199}]}, {"text": "Our dataset is notably the largest manually-picked corpus of resources intended for NLP education which does not include only academic papers.", "labels": [], "entities": []}, {"text": "Additionally, we have created both a search engine 1 and a command-line tool for the resources and have annotated the corpus to include lists of research topics, relevant resources for each topic, prerequisite relations among topics, relevant sub-parts of individual resources, among other annotations.", "labels": [], "entities": []}, {"text": "We are releasing the dataset and present several avenues for further research .", "labels": [], "entities": []}], "introductionContent": [{"text": "NLP has seen rapid growth over recent years.", "labels": [], "entities": [{"text": "NLP", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7360336780548096}]}, {"text": "A Google search of \"Natural Language Processing\" returns over 100 million hits with papers, tutorials, 1 http://aan.how blog posts, codebases and other related online resources.", "labels": [], "entities": []}, {"text": "Additionally, advances in related fields such as Artificial Intelligence and Deep Learning are strongly influencing current NLP research.", "labels": [], "entities": []}, {"text": "With these developments, an increasing number of tutorials and online references are being published daily.", "labels": [], "entities": []}, {"text": "As a result, the task of students, educators and researchers of tracking the changing landscape in this field has become increasingly difficult.", "labels": [], "entities": []}, {"text": "Recent work has studied the educational aspect of mining text for presenting scientific topics.", "labels": [], "entities": []}, {"text": "One goal has been to develop concept maps of topics, graphs showing which topics are prerequisites for learning a given topic (.", "labels": [], "entities": []}, {"text": "Another goal has been to automatically create reading lists fora subject either by building upon concept graphs (  or through an unstructured approach.", "labels": [], "entities": []}, {"text": "Additionally, other work has aimed to automatically summarize scientific topics, either by extractively summarizing academic papers ( or by producing Wikipedia articles on these topics from multiple sources.", "labels": [], "entities": [{"text": "summarize scientific topics", "start_pos": 52, "end_pos": 79, "type": "TASK", "confidence": 0.9054396947224935}, {"text": "summarizing academic papers", "start_pos": 104, "end_pos": 131, "type": "TASK", "confidence": 0.8536330262819926}]}, {"text": "Scientific articles constitute primary texts which describe an author's work on a particular subject, while Wikipedia articles can be viewed as tertiary sources which summarize both results from primary works as well as explanations from secondary sources. and  explore the pedagogical function among the types of sources.", "labels": [], "entities": []}, {"text": "To address the problem of the scientific education of NLP more directly, we focus on the annotation and utilization of secondary sources presented in a manner immediately useful to the NLP community.", "labels": [], "entities": []}, {"text": "We introduce the TutorialBank corpus, a manually-collected dataset of links to over 6,300 high-quality resources on NLP and related fields.", "labels": [], "entities": []}, {"text": "The corpus's magnitude, manual collection and focus on annotation for education in addition to research differentiates it from other corpora.", "labels": [], "entities": []}, {"text": "Throughout this paper we use the general term \"resource\" to describe any tutorial, research survey, blog post, codebase or other online source with a focus on educating on a particular subject.", "labels": [], "entities": []}, {"text": "We have created a search engine for these resources and have annotated them according to a taxonomy to facilitate their sharing.", "labels": [], "entities": []}, {"text": "Additionally, we have annotated for pedagogical role, prerequisite relations and relevance of resources to hand-selected topics and provide a command-line interface for our annotations.", "labels": [], "entities": []}, {"text": "Our main contribution is the manual collection of good quality resources related to NLP and the annotation and presentation of these resources in a manner conducive to NLP education.", "labels": [], "entities": []}, {"text": "Additionally, we show initial work on topic modeling and resource recommendation.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 38, "end_pos": 52, "type": "TASK", "confidence": 0.8046185970306396}]}, {"text": "We present a variant of standard reading-list generation which recommends resources based on a title and abstract pair and demonstrate additional uses and research directions for the corpus.", "labels": [], "entities": []}], "datasetContent": [{"text": "Annotations were performed by a group of 3 PhD students in NLP, and 6 undergraduate Computer Science students who have taken at least one course in AI or NLP.", "labels": [], "entities": []}, {"text": "We created reading lists for 182 of the 200 topics we identify in Section 4.2.", "labels": [], "entities": []}, {"text": "Resources were not found for 18 topics due to the granularity of the topic (e.g., Radial Basis Function Networks) as well as our intended restriction of the chosen resources to PowerPoint presentations and HTML pages.", "labels": [], "entities": [{"text": "Radial Basis Function Networks", "start_pos": 82, "end_pos": 112, "type": "TASK", "confidence": 0.8026373758912086}]}, {"text": "The average number of resources per reading list for the 182 topics is 3.94.", "labels": [], "entities": []}, {"text": "As an extension to the reading lists we collected Wikipedia pages for 184 of the topics and present these urls as part of the dataset.", "labels": [], "entities": []}, {"text": "We annotated prerequisite relations for the 200 topics described above.", "labels": [], "entities": []}, {"text": "We present a subset of our annotations in, which shows the network of topic relations (nodes without incoming edges were not annotated for their prerequisites as part of this shown inter-annotation round).", "labels": [], "entities": []}, {"text": "Our network consists of 794 unidirectional edges and 33 bidirectional edges.", "labels": [], "entities": []}, {"text": "The presence of bidirectional edges stems from our definition of a prerequisite, which does not preclude bidirectionality (one topic can help explain another and viceversa) as well as the similarity of the topics.", "labels": [], "entities": []}, {"text": "The set of bidirectional edges consists of topic pairs (BLEU -ROUGE; Word Embedding -Distributional Semantics; Backpropagation -Gradient descent) which could be collapsed into one topic to create a directed acyclic graph in the future.", "labels": [], "entities": [{"text": "BLEU -ROUGE", "start_pos": 56, "end_pos": 67, "type": "METRIC", "confidence": 0.894416073958079}]}, {"text": "For survey extraction, we automatically split 313 resources into content cards which we annotated for usefulness in survey extraction.", "labels": [], "entities": [{"text": "survey extraction", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.8550134897232056}, {"text": "survey extraction", "start_pos": 116, "end_pos": 133, "type": "TASK", "confidence": 0.8835406005382538}]}, {"text": "These resources area subset of the reading lists limited in number due to constraints in downloading urls and parsing to our annotation interface.", "labels": [], "entities": []}, {"text": "The total number of cards which were not marked as repeats/mis-parsed totals 17,088, with 54.59 per resource.", "labels": [], "entities": []}, {"text": "6,099 cards were labeled as somewhat relevant or relevant for the target topic.", "labels": [], "entities": []}, {"text": "The resources marked as non-relevant maybe poorly  presented or may not pertain fully to the topic of that survey.", "labels": [], "entities": []}, {"text": "These numbers confirm the appropriateness of this survey corpus as a non-trivial information retrieval task.", "labels": [], "entities": [{"text": "information retrieval task", "start_pos": 81, "end_pos": 107, "type": "TASK", "confidence": 0.7731737693150839}]}, {"text": "To better understand the difficulty of our annotation tasks, we performed inter-annotator agreement experiments for each of our annotations.", "labels": [], "entities": []}, {"text": "We randomly sampled twenty-five resources and had annotators label for pedagogical function.", "labels": [], "entities": []}, {"text": "Additionally, we sampled twenty-five topics for prerequisite annotations and five topics with reading list lengths of five for survey annotation.", "labels": [], "entities": []}, {"text": "We used Fleiss's Kappa (), a variant of Cohen's Kappa) designed to measure annotator agreement for more than two annotators.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "Using the scale as defined in, pedagogical function annotation exhibits substantial agreement while prerequisite annotation and survey extraction annotation show fair agreement.", "labels": [], "entities": []}, {"text": "The Kappa score for pedagogical function is comparable to that of while the prerequisite annotation is slightly lower than the agreement metric used in (0.36) although they measure agreement through Pearson correlation.", "labels": [], "entities": [{"text": "Kappa score", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9747936129570007}]}, {"text": "We believe that the sparsity of the labels plays a role in these scores.", "labels": [], "entities": []}, {"text": "Our corpus distinguishes itself in its magnitude, manual collection and focus on annotation for educational purposes in addition to research tasks.", "labels": [], "entities": []}, {"text": "We use similar categories for classifying pedagogical function as , but our corpus is hand-picked and over four-times larger, while exhibiting similar annotation agreement.", "labels": [], "entities": []}, {"text": "present a corpus for prerequisite relations among topics, but this corpus differs in coverage.", "labels": [], "entities": [{"text": "coverage", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9761265516281128}]}, {"text": "They used LDA topic modeling to generate a list of 300 topics, while we manually create a list of 200 topics based on criteria described above.", "labels": [], "entities": []}, {"text": "Although their topics are generated from the ACL Anthology and related to NLP, we find less than a 40% overlap in topics.", "labels": [], "entities": [{"text": "ACL Anthology", "start_pos": 45, "end_pos": 58, "type": "DATASET", "confidence": 0.945903867483139}]}, {"text": "Additionally, they only annotate a subset of the topics for prerequisite annotations while we focus on broad coverage, annotating two orders of magnitude larger in terms of prerequisite edges while exhibiting fair inter-annotator agreement.", "labels": [], "entities": []}, {"text": "Previous work and datasets on generating surveys for scientific topics have focused on scientific articles ( and Wikipedia pages as a summarization task.", "labels": [], "entities": []}, {"text": "We, on the other hand, view this problem as an information retrieval task and focus on extracting content from manually-collected PowerPoint slides and online tutorials.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 47, "end_pos": 68, "type": "TASK", "confidence": 0.758391410112381}]}, {"text": "differ in their domain coverage, and while the surveys of) focus on NLP, we collect resources for an order of magnitude larger set of topics.", "labels": [], "entities": []}, {"text": "Finally, our focus herein creating surveys, as well as the other annotations, is first and foremost to create a useful tool for students and researchers.", "labels": [], "entities": []}, {"text": "Websites such as the ACL Anthology and arXiv 4 provide an abundance of resources, but do not focus on the pedagogical aspect of their content.", "labels": [], "entities": [{"text": "ACL Anthology", "start_pos": 21, "end_pos": 34, "type": "DATASET", "confidence": 0.9452444612979889}, {"text": "arXiv 4", "start_pos": 39, "end_pos": 46, "type": "DATASET", "confidence": 0.8495313227176666}]}, {"text": "Meanwhile, websites such as Wikipedia which aim to create a survey of a topic may not reflect the latest trends in rapidly changing fields.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Top-level Taxonomy Topics", "labels": [], "entities": []}, {"text": " Table 2: Corpus count by taxonomy topic for the  most frequent topics (excluding topic \"Other\").", "labels": [], "entities": []}, {"text": " Table 3: Corpus count by pedagogical feature.", "labels": [], "entities": []}]}