{"title": [{"text": "Adaptive Scaling for Sparse Detection in Information Extraction", "labels": [], "entities": [{"text": "Adaptive Scaling", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8418078720569611}, {"text": "Sparse Detection in Information Extraction", "start_pos": 21, "end_pos": 63, "type": "TASK", "confidence": 0.7194810450077057}]}], "abstractContent": [{"text": "This paper focuses on detection tasks in information extraction, where positive instances are sparsely distributed and models are usually evaluated using F-measure on positive classes.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 41, "end_pos": 63, "type": "TASK", "confidence": 0.7856435775756836}, {"text": "F-measure", "start_pos": 154, "end_pos": 163, "type": "METRIC", "confidence": 0.977891206741333}]}, {"text": "These characteristics often result in deficient performance of neural network based detection models.", "labels": [], "entities": []}, {"text": "In this paper, we propose adaptive scaling, an algorithm which can handle the positive sparsity problem and directly optimize over F-measure via dynamic cost-sensitive learning.", "labels": [], "entities": []}, {"text": "To this end, we borrow the idea of marginal utility from economics and propose a theoretical framework for instance importance measuring without introducing any additional hyper-parameters.", "labels": [], "entities": [{"text": "importance measuring", "start_pos": 116, "end_pos": 136, "type": "TASK", "confidence": 0.8482943773269653}]}, {"text": "Experiments show that our algorithm leads to a more effective and stable training of neural network based detection models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Detection problems, aiming to identify occurrences of specific kinds of information (e.g., events, relations, or entities) in documents, are fundamental and widespread in information extraction (IE).", "labels": [], "entities": [{"text": "identify occurrences of specific kinds of information (e.g., events, relations, or entities) in documents", "start_pos": 30, "end_pos": 135, "type": "TASK", "confidence": 0.6157580190583279}, {"text": "information extraction (IE)", "start_pos": 171, "end_pos": 198, "type": "TASK", "confidence": 0.8681528925895691}]}, {"text": "For instance, an event detection () system may want to detect triggers for \"Attack\" events, such as \"shot\" in sentence \"He was shot\".", "labels": [], "entities": [{"text": "event detection", "start_pos": 17, "end_pos": 32, "type": "TASK", "confidence": 0.7484660446643829}]}, {"text": "In relation detection (, we may want to identify all instances of a specific relation, such as \"Jane joined Google\" for \"Employment\" relation.", "labels": [], "entities": [{"text": "relation detection", "start_pos": 3, "end_pos": 21, "type": "TASK", "confidence": 0.9290011525154114}, {"text": "Jane joined Google\"", "start_pos": 96, "end_pos": 115, "type": "DATASET", "confidence": 0.870053693652153}]}, {"text": "Recently, a number of researches have employed neural network models to solve detection problems, and have achieved significant improvement in many tasks, such as event detection: Comparison between standard classification tasks and detection problems.", "labels": [], "entities": [{"text": "event detection", "start_pos": 163, "end_pos": 178, "type": "TASK", "confidence": 0.8122178614139557}]}, {"text": "detection ( and named entity recognition (.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 16, "end_pos": 40, "type": "TASK", "confidence": 0.6682238976160685}]}, {"text": "These methods usually regard detection problems as standard classification tasks, with several positive classes for targets to detect and one negative class for irrelevant (background) instances.", "labels": [], "entities": []}, {"text": "For example, an event detection model will identify event triggers in sentence \"He was shot\" by classifying word \"shot\" into positive class \"Attack\", and classifying all other words into the negative class \"NIL\".", "labels": [], "entities": [{"text": "event detection", "start_pos": 16, "end_pos": 31, "type": "TASK", "confidence": 0.7563740909099579}]}, {"text": "To optimize classifiers, cross-entropy loss function is commonly used in this paradigm.", "labels": [], "entities": []}, {"text": "However, different from standard classification tasks, detection tasks have unique class inequality characteristic, which stems from both data distribution and applied evaluation metric.", "labels": [], "entities": []}, {"text": "First, positive instances are commonly sparsely distributed in detection tasks.", "labels": [], "entities": []}, {"text": "For example, in event detection, less than 2% of words area trigger of an event in RichERE dataset ().", "labels": [], "entities": [{"text": "event detection", "start_pos": 16, "end_pos": 31, "type": "TASK", "confidence": 0.765267550945282}, {"text": "RichERE dataset", "start_pos": 83, "end_pos": 98, "type": "DATASET", "confidence": 0.9861627817153931}]}, {"text": "Furthermore, detection tasks are commonly evaluated using F-measure on positive classes, rather than accuracy or F-measure on all classes.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9922651052474976}, {"text": "accuracy", "start_pos": 101, "end_pos": 109, "type": "METRIC", "confidence": 0.9991455078125}, {"text": "F-measure", "start_pos": 113, "end_pos": 122, "type": "METRIC", "confidence": 0.9881420731544495}]}, {"text": "Therefore positive and negative classes play different roles in the evaluation: the performance is evaluated by only considering how well we can detect positive instances, while correct predictions of negative instances are ignored.", "labels": [], "entities": []}, {"text": "Due to the class inequality characteristic, reported results indicate that simply applying stan-dard classification paradigm to detection tasks will result in deficient performance.", "labels": [], "entities": [{"text": "stan-dard classification", "start_pos": 91, "end_pos": 115, "type": "TASK", "confidence": 0.772568941116333}]}, {"text": "This is because minimizing cross-entropy loss function corresponds to maximize the accuracy of neural networks on all training instances, rather than Fmeasure on positive classes.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9991439580917358}, {"text": "Fmeasure", "start_pos": 150, "end_pos": 158, "type": "METRIC", "confidence": 0.8486003279685974}]}, {"text": "Furthermore, due to the positive sparsity problem, training procedure will easily achieve a high accuracy on negative class, but is difficult to converge on positive classes and often leads to a low recall rate.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9985430240631104}, {"text": "recall rate", "start_pos": 199, "end_pos": 210, "type": "METRIC", "confidence": 0.9823018014431}]}, {"text": "Although simple sampling heuristics can alleviate this problem to some extent, they either suffer from losing inner class information or over-fitting positive instances (, which often result in instability during the training procedure.", "labels": [], "entities": []}, {"text": "Some previous approaches) tried to solve this problem by directly optimizing F-measure.", "labels": [], "entities": []}, {"text": "proved that it is sufficient to solve F-measure optimization problem via cost-sensitive learning, where class-specific cost factors are applied to indicate the importance of different classes to F-measure.", "labels": [], "entities": [{"text": "F-measure optimization", "start_pos": 38, "end_pos": 60, "type": "TASK", "confidence": 0.86893430352211}]}, {"text": "However, optimal factors are not known a priori so \u03b5-search needs to be applied, which is too time consuming for the optimization of neural networks.", "labels": [], "entities": []}, {"text": "To solve the class inequality problem for sparse detection model optimization, this paper proposes a theoretical framework to quantify the importance of positive/negative instances during training.", "labels": [], "entities": [{"text": "sparse detection model optimization", "start_pos": 42, "end_pos": 77, "type": "TASK", "confidence": 0.852098360657692}]}, {"text": "We borrow the idea of marginal utility from Economics, and regard the evaluation metric (i.e., F-measure commonly) as the utility to optimize.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 95, "end_pos": 104, "type": "METRIC", "confidence": 0.9599401354789734}]}, {"text": "Based on the above idea, the importance of an instance is measured using the marginal utility of correctly predicting it.", "labels": [], "entities": []}, {"text": "For standard classification tasks evaluated using accuracy, our framework proves that correct predictions of positive and negative instances will have equal and unchanged marginal utility, i.e., all instances are with the same importance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9986351132392883}]}, {"text": "For detection problems evaluated using F-measure, our framework proves that the utility of correctly predicting one more positive instance (marginal positive utility) and that of correctly predicting one more negative instance (marginal negative utility) are different and dynamically changed during model training.", "labels": [], "entities": []}, {"text": "That is, the importance of instances of each class is not only determined by their data distribution, but also affected by how well the current model can converge on different classes.", "labels": [], "entities": []}, {"text": "Based on the above framework, we propose adaptive scaling, a dynamic cost-sensitive learning algorithm which adaptively scales costs of instances of different classes with above quantified importance during the training procedure, and thus can make the optimization criteria consistent with the evaluation metric.", "labels": [], "entities": []}, {"text": "Furthermore, a batchwise version of our adaptive scaling algorithm is proposed to make it directly applicable as a plug-in of conventional neural network training algorithms.", "labels": [], "entities": []}, {"text": "Compared with previous methods, adaptive scaling is designed based on marginal utility framework and doesn't introduce any additional hyper-parameter, and therefore is more efficient and stable to transfer among datasets and models.", "labels": [], "entities": []}, {"text": "Generally, the main contributions of this paper are: \u2022 We propose a marginal utility based framework for detection model optimization, which can dynamically quantify instance importance to different evaluation metrics.", "labels": [], "entities": [{"text": "detection model optimization", "start_pos": 105, "end_pos": 133, "type": "TASK", "confidence": 0.8232597907384237}]}, {"text": "\u2022 Based on the above framework, we present adaptive scaling, a plug-in algorithm which can effectively resolve the class inequality problem in neural detection model optimization via dynamic cost-sensitive learning.", "labels": [], "entities": [{"text": "neural detection model optimization", "start_pos": 143, "end_pos": 178, "type": "TASK", "confidence": 0.8484746962785721}]}, {"text": "We conducted experimental studies 1 on event detection, atypical sparse detection task in IE.", "labels": [], "entities": [{"text": "event detection", "start_pos": 39, "end_pos": 54, "type": "TASK", "confidence": 0.802388459444046}, {"text": "IE", "start_pos": 90, "end_pos": 92, "type": "TASK", "confidence": 0.8747100234031677}]}, {"text": "We thoroughly compared various methods for adapting classical neural network models into detection problems.", "labels": [], "entities": []}, {"text": "Experiment results show that our adaptive scaling algorithm not only achieves a better performance, but also is more stable and more adaptive for training neural networks on various models and datasets.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Experiment results on TAC KBP 2017  evaluation datasets. * indicates the best (ensem- bling) results reported in the original paper. \"A- Scaling\" is batch-wise adaptive scaling algorithm.", "labels": [], "entities": [{"text": "TAC KBP 2017  evaluation datasets", "start_pos": 32, "end_pos": 65, "type": "DATASET", "confidence": 0.904367458820343}, {"text": "ensem- bling)", "start_pos": 89, "end_pos": 102, "type": "METRIC", "confidence": 0.8151096850633621}]}]}