{"title": [{"text": "DSGAN: Generative Adversarial Training for Distant Supervision Relation Extraction", "labels": [], "entities": [{"text": "Distant Supervision Relation Extraction", "start_pos": 43, "end_pos": 82, "type": "TASK", "confidence": 0.9386025220155716}]}], "abstractContent": [{"text": "Distant supervision can effectively label data for relation extraction, but suffers from the noise labeling problem.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 51, "end_pos": 70, "type": "TASK", "confidence": 0.9010201394557953}]}, {"text": "Recent works mainly perform soft bag-level noise reduction strategies to find the relatively better samples in a sentence bag, which is suboptimal compared with making a hard decision of false positive samples in sentence level.", "labels": [], "entities": [{"text": "soft bag-level noise reduction", "start_pos": 28, "end_pos": 58, "type": "TASK", "confidence": 0.6669771447777748}]}, {"text": "In this paper, we introduce an adversarial learning framework, which we named DSGAN, to learn a sentence-level true-positive generator.", "labels": [], "entities": []}, {"text": "Inspired by Generative Adversarial Networks, we regard the positive samples generated by the generator as the negative samples to train the discriminator.", "labels": [], "entities": []}, {"text": "The optimal generator is obtained until the discrimination ability of the discriminator has the greatest decline.", "labels": [], "entities": []}, {"text": "We adopt the generator to filter distant supervision training dataset and redistribute the false positive instances into the negative set, in which way to provide a cleaned dataset for relation classification.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 185, "end_pos": 208, "type": "TASK", "confidence": 0.8557240962982178}]}, {"text": "The experimental results show that the proposed strategy significantly improves the performance of distant supervision relation extraction comparing to state-of-the-art systems .", "labels": [], "entities": [{"text": "distant supervision relation extraction", "start_pos": 99, "end_pos": 138, "type": "TASK", "confidence": 0.6112796664237976}]}], "introductionContent": [{"text": "Relation extraction is a crucial task in the field of natural language processing (NLP).", "labels": [], "entities": [{"text": "Relation extraction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.958981841802597}, {"text": "natural language processing (NLP)", "start_pos": 54, "end_pos": 87, "type": "TASK", "confidence": 0.8139566679795583}]}, {"text": "It has a wide range of applications including information retrieval, question answering, and knowledge base completion.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 46, "end_pos": 67, "type": "TASK", "confidence": 0.8690274059772491}, {"text": "question answering", "start_pos": 69, "end_pos": 87, "type": "TASK", "confidence": 0.9356981217861176}, {"text": "knowledge base completion", "start_pos": 93, "end_pos": 118, "type": "TASK", "confidence": 0.7376802563667297}]}, {"text": "The goal of relation extraction system is to predict relation between entity pair in a sentence ().", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.7598508596420288}]}, {"text": "For exam-  ple, given a sentence \"The e1 held the mouse in its e2 .\", a relation classifier should figure out the relation Component-Whole between entity owl and claw.", "labels": [], "entities": []}, {"text": "With the infinite amount of facts in real world, it is extremely expensive, and almost impossible for human annotators to annotate training dataset to meet the needs of all walks of life.", "labels": [], "entities": []}, {"text": "This problem has received increasingly attention.", "labels": [], "entities": []}, {"text": "Fewshot learning and Zero-shot) try to predict the unseen classes with few labeled data or even without labeled data.", "labels": [], "entities": []}, {"text": "Differently, distant supervision () is to efficiently generate relational data from plain text for unseen relations with distant supervision (DS).", "labels": [], "entities": []}, {"text": "However, it naturally brings with some defects: the resulted distantly-supervised training samples are often very noisy (shown in, which is the main problem of impeding the performance ().", "labels": [], "entities": []}, {"text": "Most of the current state-of-the-art methods () make the denoising operation in the sentence bag of entity pair, and integrate this process into the distant supervision relation ex-traction.", "labels": [], "entities": []}, {"text": "Indeed, these methods can filter a substantial number of noise samples; However, they overlook the case that all sentences of an entity pair are false positive, which is also the common phenomenon in distant supervision datasets.", "labels": [], "entities": []}, {"text": "Under this consideration, an independent and accurate sentence-level noise reduction strategy is the better choice.", "labels": [], "entities": [{"text": "sentence-level noise reduction", "start_pos": 54, "end_pos": 84, "type": "TASK", "confidence": 0.6211151580015818}]}, {"text": "In this paper, we design an adversarial learning process () to obtain a sentence-level generator that can recognize the true positive samples from the noisy distant supervision dataset without any supervised information.", "labels": [], "entities": []}, {"text": "In, the existence of false positive samples makes the DS decision boundary suboptimal, therefore hinders the performance of relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 124, "end_pos": 143, "type": "TASK", "confidence": 0.8592678308486938}]}, {"text": "However, in terms of quantity, the true positive samples still occupy most of the proportion; this is the prerequisite of our method.", "labels": [], "entities": []}, {"text": "Given the discriminator that possesses the decision boundary of DS dataset (the brown decision boundary in), the generator tries to generate true positive samples from DS positive dataset; Then, we assign the generated samples with negative label and the rest samples with positive label to challenge the discriminator.", "labels": [], "entities": [{"text": "DS dataset", "start_pos": 64, "end_pos": 74, "type": "DATASET", "confidence": 0.9520646929740906}]}, {"text": "Under this adversarial setting, if the generated sample set includes more true positive samples and more false positive samples are left in the rest set, the classification ability of the discriminator will drop faster.", "labels": [], "entities": []}, {"text": "Empirically, we show that our method has brought consistent performance gains in various deep-neural-network-based models, achieving strong performances on the widely used New York Times dataset (.", "labels": [], "entities": [{"text": "New York Times dataset", "start_pos": 172, "end_pos": 194, "type": "DATASET", "confidence": 0.8075578063726425}]}, {"text": "Our contributions are three-fold: \u2022 We are the first to consider adversarial learning to denoise the distant supervision relation extraction dataset.", "labels": [], "entities": [{"text": "distant supervision relation extraction", "start_pos": 101, "end_pos": 140, "type": "TASK", "confidence": 0.6131361275911331}]}, {"text": "\u2022 Our method is sentence-level and modelagnostic, so it can be used as a plug-and-play technique for any relation extractors.", "labels": [], "entities": [{"text": "relation extractors", "start_pos": 105, "end_pos": 124, "type": "TASK", "confidence": 0.7193398922681808}]}, {"text": "\u2022 We show that our method can generate a cleaned dataset without any supervised information, in which way to boost the performance of recently proposed neural relation extractors.", "labels": [], "entities": [{"text": "neural relation extractors", "start_pos": 152, "end_pos": 178, "type": "TASK", "confidence": 0.6742567320664724}]}, {"text": "In Section 2, we outline some related works on distant supervision relation extraction.", "labels": [], "entities": [{"text": "distant supervision relation extraction", "start_pos": 47, "end_pos": 86, "type": "TASK", "confidence": 0.6769334077835083}]}, {"text": "Next, we describe our adversarial learning strategy in Section 3.", "labels": [], "entities": []}, {"text": "In Section 4, we show the stability analyses of DSGAN and the empirical evaluation results.", "labels": [], "entities": [{"text": "DSGAN", "start_pos": 48, "end_pos": 53, "type": "DATASET", "confidence": 0.9422173500061035}]}, {"text": "And finally, we conclude in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "After our adversarial learning process, we obtain one generator for one relation type; These generators possess the capability of generating true positive samples for the corresponding relation type.", "labels": [], "entities": []}, {"text": "Thus, we can adopt the generator to filter the noise samples from distant supervision dataset.", "labels": [], "entities": []}, {"text": "Simply and clearly, we utilize the generator as a binary classifier.", "labels": [], "entities": []}, {"text": "In order to reach the maximum utilization of data, we develop a strategy: for an entity pair with a set of annotated sentences, if all of these sentences are determined as false negative by our generator, this entity pair will be redistributed into the negative set.", "labels": [], "entities": []}, {"text": "Under this strategy, the scale of distant supervision training set keeps unchanged.", "labels": [], "entities": []}, {"text": "This paper proposes an adversarial learning strategy to detect true positive samples from the noisy distant supervision dataset.", "labels": [], "entities": []}, {"text": "Due to the absence of supervised information, we define a generator to heuristically learn to recognize true positive samples through competing with a discriminator.", "labels": [], "entities": []}, {"text": "Therefore, our experiments are intended to demonstrate that our DSGAN method possess this capability.", "labels": [], "entities": []}, {"text": "To this end, we first briefly introduce the dataset and the evaluation metrics.", "labels": [], "entities": []}, {"text": "Empirically, the adversarial learning process, to some extent, has instability; Therefore, we next illustrate the convergence of our adversarial training process.", "labels": [], "entities": []}, {"text": "Finally, we demonstrate the efficiency of our generator from two angles: the quality of the generated samples and the performance on the widely-used distant supervision relation extraction task.", "labels": [], "entities": [{"text": "distant supervision relation extraction task", "start_pos": 149, "end_pos": 193, "type": "TASK", "confidence": 0.6438037097454071}]}, {"text": "The Reidel dataset 2 () is a commonly-used distant supervision relation extraction dataset.", "labels": [], "entities": [{"text": "Reidel dataset 2", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.8753031094868978}, {"text": "distant supervision relation extraction", "start_pos": 43, "end_pos": 82, "type": "TASK", "confidence": 0.5859468653798103}]}, {"text": "Freebase is a huge knowledge base including billions of triples: the entity pair and the specific relationship between them.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9652721881866455}]}, {"text": "Given these triples, the sentences of each entity pair are selected from the New York Times corpus(NYT).", "labels": [], "entities": [{"text": "New York Times corpus(NYT)", "start_pos": 77, "end_pos": 103, "type": "DATASET", "confidence": 0.7813072970935276}]}, {"text": "Entity mentions of NYT corpus are recognized by the Stanford named entity recognizer ().", "labels": [], "entities": [{"text": "NYT corpus", "start_pos": 19, "end_pos": 29, "type": "DATASET", "confidence": 0.849725753068924}]}, {"text": "There are 52 actual relationships and a special relation N A which indicates there is no relation between head and tail entities.", "labels": [], "entities": []}, {"text": "N A are defined as the entity pairs that appear in the same sentence but are not related according to Freebase.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 102, "end_pos": 110, "type": "DATASET", "confidence": 0.9584819078445435}]}, {"text": "Due to the absence of the corresponding labeled dataset, there is not a ground-truth test dataset to evaluate the performance of distant supervision relation extraction system.", "labels": [], "entities": [{"text": "distant supervision relation extraction", "start_pos": 129, "end_pos": 168, "type": "TASK", "confidence": 0.5743117183446884}]}, {"text": "Under this circumstance, the previous work adopt the held-out evaluation to evaluate their systems, which can provide an approximate measure of precision without requiring costly human evaluation.", "labels": [], "entities": [{"text": "precision", "start_pos": 144, "end_pos": 153, "type": "METRIC", "confidence": 0.9981672763824463}]}, {"text": "It builds a test set where entity pairs are also extracted from Freebase.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 64, "end_pos": 72, "type": "DATASET", "confidence": 0.9619848728179932}]}, {"text": "Similarly, relation facts that discovered from test articles are automatically compared with those in Freebase.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 102, "end_pos": 110, "type": "DATASET", "confidence": 0.9617645740509033}]}, {"text": "CNN is widely used in relation classification (, thus the generator and the discriminator are both modeled as a simple CNN with the window size cw and the kernel size ck . Word embedding is directly from the released word embedding matrix by . Position embedding has the same setting with the previous works: the maximum distance of -30 and 30.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 22, "end_pos": 45, "type": "TASK", "confidence": 0.8919240534305573}]}, {"text": "Some detailed hyperparameter settings are displayed in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Comparison of AUC values between  previous studies and our DSGAN method. The p- value stands for the result of t-test evaluation.", "labels": [], "entities": [{"text": "AUC", "start_pos": 24, "end_pos": 27, "type": "METRIC", "confidence": 0.823612630367279}, {"text": "DSGAN", "start_pos": 69, "end_pos": 74, "type": "DATASET", "confidence": 0.9307233095169067}]}]}