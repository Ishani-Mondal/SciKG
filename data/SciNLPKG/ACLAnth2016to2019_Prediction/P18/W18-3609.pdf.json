{"title": [{"text": "The DipInfo-UniTo System for SRST 2018", "labels": [], "entities": [{"text": "DipInfo-UniTo System", "start_pos": 4, "end_pos": 24, "type": "DATASET", "confidence": 0.9038908183574677}, {"text": "SRST", "start_pos": 29, "end_pos": 33, "type": "TASK", "confidence": 0.9709137082099915}]}], "abstractContent": [{"text": "This paper describes the system developed by the DipInfo-UniTo team to participate to the shallow track of the Surface Realization Shared Task 2018 (Mille et al., 2018).", "labels": [], "entities": [{"text": "Surface Realization Shared Task 2018", "start_pos": 111, "end_pos": 147, "type": "TASK", "confidence": 0.8187345266342163}]}, {"text": "The system employs two separate neu-ral networks with different architectures to predict the word ordering and the morphological inflection independently from each other.", "labels": [], "entities": []}, {"text": "The UniTo realizer is language independent , and its simple architecture allowed it to be scored in the central part of the final ranking of the shared task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Natural Language Generation from formal structures, and in particular tree-like structures, has been approached with a variety of methods in the literature.", "labels": [], "entities": [{"text": "Natural Language Generation", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7299064993858337}]}, {"text": "For instance, SimpleNLG) takes as input a tree-like representation (a sort of quasi-syntactic tree enriched with a series of features) and produces an English sentence.", "labels": [], "entities": []}, {"text": "SimpleNLG has is largely used in different NLG systems and has been ported to a number of different language (Italian among them ().", "labels": [], "entities": [{"text": "SimpleNLG", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.8110576868057251}]}, {"text": "In the PhD thesis of, the generation process starts from a recursive representation of the semantics of a discourse (a Discourse Representation Structure, from Discourse Representation Theory) and it is carried out by transforming the original DRS into a directed graph (quite similar to a tree) aligned with the surface format the word level.", "labels": [], "entities": []}, {"text": "While the approach of is aimed towards generation from abstract representations of meaning, in practice it is applicable to similar structures encoding information at a different level of abstraction, such as the trees that form the input of the present shared task.", "labels": [], "entities": []}, {"text": "We draw further inspiration from the aforementioned work in dividing the generation process into the word ordering prediction and morphology inflection generation.", "labels": [], "entities": [{"text": "word ordering prediction", "start_pos": 101, "end_pos": 125, "type": "TASK", "confidence": 0.8483688235282898}, {"text": "morphology inflection generation", "start_pos": 130, "end_pos": 162, "type": "TASK", "confidence": 0.661266694466273}]}, {"text": "We follow a simplified approach by considering these two subtasks as independent from each other.", "labels": [], "entities": []}, {"text": "We implement two modules based on neural networks that work in parallel, and whose output is later combined to produce the final surface form (cf.).", "labels": [], "entities": []}, {"text": "In this paper we describe the the DipInfo-UniTo realizer (hencefort UniTO realizer) participating to the shallow track of the Surface Realization Shared Task 2018 (.", "labels": [], "entities": [{"text": "DipInfo-UniTo realizer", "start_pos": 34, "end_pos": 56, "type": "TASK", "confidence": 0.6975897550582886}, {"text": "Surface Realization Shared Task", "start_pos": 126, "end_pos": 157, "type": "TASK", "confidence": 0.7528838142752647}]}, {"text": "In Section 2 we describe the system implemented from scratch for the word ordering subtask, and in Section 3 we briefly describe the deep learning-based approach that we used for the morphology inflection subtask.", "labels": [], "entities": [{"text": "word ordering subtask", "start_pos": 69, "end_pos": 90, "type": "TASK", "confidence": 0.7643350760142008}]}, {"text": "In Section 4 we describe the experimental pipelines used for training and testing the UniTo realizer and, moreover, we report the results on the test set.", "labels": [], "entities": []}, {"text": "Finally, Section 5 closes the paper with some considerations and points to future developments.", "labels": [], "entities": []}], "datasetContent": [{"text": "Since our approach does not rely on language specific procedures or hand-made rules, we have initially planned to train the UniTo realizer for all the ten languages proposed by the SRST organizers.", "labels": [], "entities": [{"text": "SRST", "start_pos": 181, "end_pos": 185, "type": "TASK", "confidence": 0.8001556992530823}]}, {"text": "However, because of time constraints, we decided to focus on four specific languages first: English, Spanish, French and Italian (EN-ES-FR-IT).", "labels": [], "entities": []}, {"text": "In particular, for English, French and Italian the learning time for word ordering and morphology inflection was around 36 and 24 hours respectively . In contrast, for Spanish language, which has a considerable larger learning file, the learning time was approximatively doubled.", "labels": [], "entities": [{"text": "word ordering", "start_pos": 69, "end_pos": 82, "type": "TASK", "confidence": 0.7527972757816315}]}, {"text": "The rules of the shallow track for the SRST 2018 allowed to use any resource to train the surface realizers.", "labels": [], "entities": [{"text": "SRST", "start_pos": 39, "end_pos": 43, "type": "TASK", "confidence": 0.7580403089523315}]}, {"text": "However, in order to investigate about the syntactic information contained in the Universal Dependency format and its appropriateness for NLG tasks, we decided to use mostly information derived from the project Universal Dependency (.", "labels": [], "entities": []}, {"text": "Indeed, the only exception regards the encoding of the open classes words in terms of language specific pre-compiled embeddings for the word order model (Al-Rfou' et al., 2013) (cf. Section 2.2)).", "labels": [], "entities": []}, {"text": "The task organizers provided ten training and ten development files derived from the version 2.1 of the UD dataset for the ten languages included in the shallow track.", "labels": [], "entities": [{"text": "UD dataset", "start_pos": 104, "end_pos": 114, "type": "DATASET", "confidence": 0.9148716628551483}]}, {"text": "Indeed, they provided a modified versions of the original treebanks in which the information about the inflected word form was removed and, the original word order was replaced with a random order.", "labels": [], "entities": []}, {"text": "Additionally, the organizers provided ten text files containing the sentences of the treebank in their original form.", "labels": [], "entities": []}, {"text": "However, we noted that the training files provided by the organizers had an unresolvable ambiguity in the case of a sentence containing the same lemma multiple times.", "labels": [], "entities": []}, {"text": "As a consequence, we decided to use the original versions 2.1 of the treebank files since they contain both the gold word order and the inflected forms of the word.", "labels": [], "entities": []}, {"text": "During the conversion of the dependency trees into a vector form (see Section 2), we ignored the information about word ordering and inflected forms.", "labels": [], "entities": []}, {"text": "For English, Spanish and French, we used the training files developed in the English, SpanishAnCora, and French main UD treebanks respectively.", "labels": [], "entities": [{"text": "SpanishAnCora", "start_pos": 86, "end_pos": 99, "type": "DATASET", "confidence": 0.9118413925170898}, {"text": "French main UD treebanks", "start_pos": 105, "end_pos": 129, "type": "DATASET", "confidence": 0.6878838464617729}]}, {"text": "In contrast, for Italian we built anew training file by merging together the training file of the Italian main UD treebank with the training files of the UD Italian treebanks Italian-PUD, Italian-  ParTUT and Italian-PoSTWITA.", "labels": [], "entities": [{"text": "UD treebank", "start_pos": 111, "end_pos": 122, "type": "DATASET", "confidence": 0.9249366223812103}, {"text": "UD Italian treebanks Italian-PUD", "start_pos": 154, "end_pos": 186, "type": "DATASET", "confidence": 0.7871337682008743}]}], "tableCaptions": [{"text": " Table 1: The performance in terms of BLUE,  DIST and NIST scores of the UniTo Realizer. The  average is computed by considering the mean over  the ten languages proposed for the shallow track.", "labels": [], "entities": [{"text": "BLUE", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.9241747856140137}]}]}