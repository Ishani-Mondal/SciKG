{"title": [{"text": "Investigating Audio, Video, and Text Fusion Methods for End-to-End Automatic Personality Prediction", "labels": [], "entities": [{"text": "Audio, Video, and Text Fusion", "start_pos": 14, "end_pos": 43, "type": "TASK", "confidence": 0.7015704980918339}, {"text": "End-to-End Automatic Personality Prediction", "start_pos": 56, "end_pos": 99, "type": "TASK", "confidence": 0.5542035549879074}]}], "abstractContent": [{"text": "We propose a tri-modal architecture to predict Big Five personality trait scores from video clips with different channels for audio , text, and video data.", "labels": [], "entities": []}, {"text": "For each channel, stacked Convolutional Neural Networks are employed.", "labels": [], "entities": []}, {"text": "The channels are fused both on decision-level and by concatenating their respective fully connected layers.", "labels": [], "entities": []}, {"text": "It is shown that a multimodal fusion approach outperforms each single modality channel, with an improvement of 9.4% over the best individual modality (video).", "labels": [], "entities": []}, {"text": "Full backprop-agation is also shown to be better than a linear combination of modalities, meaning complex interactions between modalities can be leveraged to build better models.", "labels": [], "entities": []}, {"text": "Furthermore, we can seethe prediction relevance of each modality for each trait.", "labels": [], "entities": []}, {"text": "The described model can be used to increase the emotional intelligence of virtual agents.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic prediction of personality is important for the development of emotional and empathetic virtual agents.", "labels": [], "entities": [{"text": "Automatic prediction of personality", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.7005139514803886}]}, {"text": "Humans are very quick to assign personality traits to each other, as well as to virtual characters (.", "labels": [], "entities": []}, {"text": "People infer personality from different cues, both behavioral and verbal, hence a model to predict personality should take into account multiple modalities including language, speech and visual cues.", "labels": [], "entities": []}, {"text": "Personality is typically modeled with the Big Five personality descriptors).", "labels": [], "entities": []}, {"text": "In this model an individual's personality is defined as a collection of five scores in range for personality traits Extraversion, Agreeableness, Conscientiousness, Neuroticism and Openness to Experience.", "labels": [], "entities": [{"text": "Extraversion", "start_pos": 116, "end_pos": 128, "type": "METRIC", "confidence": 0.7720423340797424}, {"text": "Agreeableness", "start_pos": 130, "end_pos": 143, "type": "METRIC", "confidence": 0.994688868522644}]}, {"text": "These score are usually calculated by each subject filling in a specific questionnaire.", "labels": [], "entities": []}, {"text": "The biggest effort to predict personality, as well as to release a benchmark open-domain personality corpus, was given by the ChaLearn 2016 shared task challenge).", "labels": [], "entities": [{"text": "ChaLearn 2016 shared task challenge", "start_pos": 126, "end_pos": 161, "type": "DATASET", "confidence": 0.8922687411308289}]}, {"text": "All the best performing teams used neural network techniques.", "labels": [], "entities": []}, {"text": "They extracted traditional audio features (zero crossing rate, energy, spectral features, MFCCs) and then fed them into the neural network (.", "labels": [], "entities": []}, {"text": "A deep neural network should however be able to extract such features itself.", "labels": [], "entities": []}, {"text": "took a different approach by feeding the raw audio and video samples to the network.", "labels": [], "entities": []}, {"text": "However they mostly designed the network for computer vision, and used the same architecture to audio input without any adaptation or considerations to merge modalities.", "labels": [], "entities": [{"text": "computer vision", "start_pos": 45, "end_pos": 60, "type": "TASK", "confidence": 0.751897543668747}]}, {"text": "The challenge was in general aimed at the computer vision community (many only used facial features), thus not many looked into what their deep network was learning regarding other modalities.", "labels": [], "entities": []}, {"text": "In this paper, we are interested in predicting personality from speech, language and video frames (facial features).", "labels": [], "entities": []}, {"text": "We first consider the different modalities separately, in order to have more understanding of how personality is expressed and which modalities contribute more to the personality definition.", "labels": [], "entities": []}, {"text": "Then we design and analyze fusion methods to effectively combine the three modalities in order to obtain a performance improvement over each individual modality.", "labels": [], "entities": []}, {"text": "The readers can refer to the survey by for more information on multi-modal approaches.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Optimal weights learned for combining  the three modalities for each trait. E, A, C, N, and  O stand for Extraversion, Agreeableness, Conscien- tiousness, Neuroticism and Openness, respectively.", "labels": [], "entities": [{"text": "Agreeableness", "start_pos": 129, "end_pos": 142, "type": "METRIC", "confidence": 0.9485297203063965}, {"text": "Openness", "start_pos": 181, "end_pos": 189, "type": "METRIC", "confidence": 0.9114720225334167}]}, {"text": " Table 2: MAE for each individual modality, fusion  approaches and average of training set labels. DLF  refers to decision-level fusion, NNLB and NNFB  refer to neural network limited backprop and full  back respectively.", "labels": [], "entities": [{"text": "MAE", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9742543697357178}]}, {"text": " Table 3:  Mean accuracy for each individual  modality, fusion approaches, two winners of the  ChaLearn 2016 competition (DCC and evolgen),  and average of training set labels.", "labels": [], "entities": [{"text": "Mean", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.9622390866279602}, {"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.8252271413803101}, {"text": "ChaLearn 2016 competition", "start_pos": 95, "end_pos": 120, "type": "DATASET", "confidence": 0.8480866551399231}]}]}