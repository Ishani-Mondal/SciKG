{"title": [{"text": "Learning to Control the Specificity in Neural Response Generation", "labels": [], "entities": [{"text": "Neural Response Generation", "start_pos": 39, "end_pos": 65, "type": "TASK", "confidence": 0.7966875831286112}]}], "abstractContent": [{"text": "In conversation, a general response (e.g., \"I don't know\") could correspond to a large variety of input utterances.", "labels": [], "entities": []}, {"text": "Previous generative conversational models usually employ a single model to learn the relationship between different utterance-response pairs, thus tend to favor general and trivial responses which appear frequently.", "labels": [], "entities": [{"text": "generative conversational", "start_pos": 9, "end_pos": 34, "type": "TASK", "confidence": 0.9136106967926025}]}, {"text": "To address this problem, we propose a novel controlled response generation mechanism to handle different utterance-response relationships in terms of specificity.", "labels": [], "entities": []}, {"text": "Specifically, we introduce an explicit specificity control variable into a sequence-to-sequence model, which interacts with the usage representation of words through a Gaussian Kernel layer, to guide the model to generate responses at different specificity levels.", "labels": [], "entities": []}, {"text": "We describe two ways to acquire distant labels for the specificity control variable in learning.", "labels": [], "entities": []}, {"text": "Empirical studies show that our model can significantly outperform the state-of-the-art response generation models under both automatic and human evaluations.", "labels": [], "entities": []}], "introductionContent": [{"text": "Human-computer conversation is a critical and challenging task in AI and NLP.", "labels": [], "entities": []}, {"text": "There have been two major streams of research in this direction, namely task oriented dialog and general purpose dialog (i.e., chit-chat).", "labels": [], "entities": []}, {"text": "Task oriented dialog aims to help people complete specific tasks such as buying tickets or shopping, while general purpose dialog attempts to produce natural and meaningful conversations with people regarding a wide range of topics in open domains (.", "labels": [], "entities": []}, {"text": "In recent years, the latter has at- tracted much attention in both academia and industry as away to explore the possibility in developing a general purpose AI system in language (e.g., chatbots).", "labels": [], "entities": []}, {"text": "A widely adopted approach to general purpose dialog is learning a generative conversational model from large scale social conversation data.", "labels": [], "entities": [{"text": "general purpose dialog", "start_pos": 29, "end_pos": 51, "type": "TASK", "confidence": 0.7426115075747172}, {"text": "generative conversational", "start_pos": 66, "end_pos": 91, "type": "TASK", "confidence": 0.8837975263595581}]}, {"text": "Most methods in this line are constructed within the statistical machine translation (SMT) framework, where a sequence-to-sequence (Seq2Seq) model is learned to \"translate\" an input utterance into a response.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 53, "end_pos": 90, "type": "TASK", "confidence": 0.7745063106218973}]}, {"text": "However, general purpose dialog is intrinsically different from machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 64, "end_pos": 83, "type": "TASK", "confidence": 0.7550464272499084}]}, {"text": "In machine translation, since every sentence and its translation are semantically equivalent, there exists a 1-to-1 relationship between them.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 3, "end_pos": 22, "type": "TASK", "confidence": 0.7651839256286621}]}, {"text": "However, in general purpose dialog, a general response (e.g., \"I don't know\") could correspond to a large variety of input utterances.", "labels": [], "entities": []}, {"text": "For example, in the chit-chat corpus used in this study (as shown in), the top three most frequently appeared responses are \"Must support!", "labels": [], "entities": []}, {"text": "Cheer!\", \"Support!", "labels": [], "entities": [{"text": "Support", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.7616443037986755}]}, {"text": "It's good.\", and \"My friends and I are shocked!\", where the response \"Must support!", "labels": [], "entities": []}, {"text": "Cheer!\" is used for 1216 different input utterances.", "labels": [], "entities": []}, {"text": "Previous Seq2Seq models, which treat all the utteranceresponse pairs uniformly and employ a single model to learn the relationship between them, will inevitably favor such general responses with high frequency.", "labels": [], "entities": []}, {"text": "Although these responses are safe for replying different utterances, they are boring and trivial since they carry little information, and may quickly lead to an end of the conversation.", "labels": [], "entities": []}, {"text": "There have been a few efforts attempting to address this issue in literature.", "labels": [], "entities": []}, {"text": "proposed to use the Maximum Mutual Information (MMI) as the objective to penalize general responses.", "labels": [], "entities": [{"text": "Maximum Mutual Information (MMI)", "start_pos": 20, "end_pos": 52, "type": "METRIC", "confidence": 0.7664310336112976}]}, {"text": "It could be viewed as a post-processing approach which did not solve the generation of trivial responses fundamentally.", "labels": [], "entities": []}, {"text": "pre-defined a set of topics from an external corpus to guide the generation of the Seq2Seq model.", "labels": [], "entities": []}, {"text": "However, it is difficult to ensure that the topics learned from the external corpus are consistent with that in the conversation corpus, leading to the introduction of additional noises.", "labels": [], "entities": []}, {"text": "introduced latent responding factors to model multiple responding mechanisms.", "labels": [], "entities": []}, {"text": "However, these latent factors are usually difficult in interpretation and it is hard to decide the number of the latent factors.", "labels": [], "entities": []}, {"text": "In our work, we propose a novel controlled response generation mechanism to handle different utterance-response relationships in terms of specificity.", "labels": [], "entities": []}, {"text": "The key idea is inspired by our observation on everyday conversation between humans.", "labels": [], "entities": []}, {"text": "In human-human conversation, people often actively control the specificity of responses depending on their own response purpose (which might be affected by a variety of underlying factors like their current mood, knowledge state and so on).", "labels": [], "entities": []}, {"text": "For example, they may provide some interesting and specific responses if they like the conversation, or some general responses if they want to end it.", "labels": [], "entities": []}, {"text": "They may provide very detailed responses if they are familiar with the topic, or just \"I don't know\" otherwise.", "labels": [], "entities": []}, {"text": "Therefore, we propose to simulate the way people actively control the specificity of the response.", "labels": [], "entities": []}, {"text": "We employ a Seq2Seq framework and further introduce an explicit specificity control variable to represent the response purpose of the agent.", "labels": [], "entities": []}, {"text": "Meanwhile, we assume that each word, beyond the semantic representation which relates to its meaning, also has another representation which relates to the usage preference under different response purpose.", "labels": [], "entities": []}, {"text": "We name this representation as the usage representation of words.", "labels": [], "entities": []}, {"text": "The specificity control variable then interacts with the usage representation of words through a Gaussian Kernel layer, and guides the Seq2Seq model to generate responses at different specificity levels.", "labels": [], "entities": []}, {"text": "We refer to our model as Specificity Controlled Seq2Seq model (SC-Seq2Seq).", "labels": [], "entities": []}, {"text": "Note that unlike the work by), we do not rely on any external corpus to learn our model.", "labels": [], "entities": []}, {"text": "All the model parameters are learned on the same conversation corpus in an end-to-end way.", "labels": [], "entities": []}, {"text": "We employ distant supervision to train our SCSeq2Seq model since the specificity control variable is unknown in the raw data.", "labels": [], "entities": []}, {"text": "We describe two ways to acquire distant labels for the specificity control variable, namely Normalized Inverse Response Frequency (NIRF) and Normalized Inverse Word Frequency (NIWF).", "labels": [], "entities": [{"text": "Normalized Inverse Response Frequency (NIRF)", "start_pos": 92, "end_pos": 136, "type": "METRIC", "confidence": 0.7147876279694694}]}, {"text": "By using normalized values, we restrict the specificity control variable to be within a pre-defined continuous value range with each end has very clear meaning on the specificity.", "labels": [], "entities": []}, {"text": "This is significantly different from the discrete latent factors in ( ) which are difficult in interpretation.", "labels": [], "entities": []}, {"text": "We conduct an empirical study on a large public dataset, and compare our model with several state-of-the-art response generation methods.", "labels": [], "entities": []}, {"text": "Empirical results show that our model can generate either general or specific responses, and significantly outperform existing methods under both automatic and human evaluations.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we conduct experiments to verify the effectiveness of our proposed model.", "labels": [], "entities": []}, {"text": "We conduct our experiments on the public Short Text Conversation (STC) dataset 1 released in NTCIR-13.", "labels": [], "entities": [{"text": "Short Text Conversation (STC) dataset 1 released in NTCIR-13", "start_pos": 41, "end_pos": 101, "type": "DATASET", "confidence": 0.7687136205759916}]}, {"text": "STC maintains a large repository of post-comment pairs from the Sina Weibo which is one of the popular Chinese social sites.", "labels": [], "entities": [{"text": "STC", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9545385837554932}, {"text": "Sina Weibo", "start_pos": 64, "end_pos": 74, "type": "DATASET", "confidence": 0.7551664113998413}]}, {"text": "STC dataset contains roughly 3.8 million postcomment pairs, which could be used to simulate the utterance-response pairs in conversation.", "labels": [], "entities": [{"text": "STC dataset", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.968215823173523}]}, {"text": "We employ the Jieba Chinese word segmenter 2 to tokenize the utterances and responses into sequences of Chinese words, and the detailed dataset statistics are shown in.", "labels": [], "entities": [{"text": "tokenize the utterances and responses into sequences of Chinese words", "start_pos": 48, "end_pos": 117, "type": "TASK", "confidence": 0.7298740386962891}]}, {"text": "We randomly selected two subsets as the development and test dataset, each containing 10k pairs.", "labels": [], "entities": []}, {"text": "The left pairs are used for training.", "labels": [], "entities": []}, {"text": "For evaluation, we follow the existing work and employ both automatic and human evaluations: we count numbers of distinct unigrams and bigrams in the generated responses, and divide the numbers by total number of generated unigrams and bigrams.", "labels": [], "entities": []}, {"text": "Distinct metrics (both the numbers and the ratios) can be used to evaluate the specificity/diversity of the responses.", "labels": [], "entities": []}, {"text": "(2) BLEU (): BLEU has been proved strongly correlated with human evaluations.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.998980700969696}, {"text": "BLEU", "start_pos": 13, "end_pos": 17, "type": "METRIC", "confidence": 0.9987564086914062}]}, {"text": "BLEU-n measures the average n-gram precision on a set of reference sentences.", "labels": [], "entities": [{"text": "BLEU-n", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9875554442405701}, {"text": "precision", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.9498326182365417}]}, {"text": "(3) Average & Extrema (Serban et al., 2017): Average and Extrema projects the generated response and the ground truth response into two separate vectors by taking the mean over the word embeddings or taking the extremum of each dimension respectively, and then computes the cosine similarity between them.", "labels": [], "entities": [{"text": "Average", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9571709632873535}, {"text": "Extrema", "start_pos": 14, "end_pos": 21, "type": "METRIC", "confidence": 0.9292571544647217}]}, {"text": "(4) Human evaluation: Three labelers with rich Weibo experience were recruited to conduct evaluation.", "labels": [], "entities": [{"text": "Human evaluation", "start_pos": 4, "end_pos": 20, "type": "TASK", "confidence": 0.78114253282547}]}, {"text": "Responses from different models are randomly mixed for labeling.", "labels": [], "entities": []}, {"text": "Labelers refer to 300 random sampled test utterances and score the quality of the responses with the following criteria: 1) +2: the response is not only semantically relevant and grammatical, but also informat-   ive and interesting; 2) +1: the response is grammatical and can be used as a response to the utterance, but is too trivial (e.g., \"I don't know\"); 3) +0: the response is semantically irrelevant or ungrammatical (e.g., grammatical errors or UNK).", "labels": [], "entities": [{"text": "UNK", "start_pos": 453, "end_pos": 456, "type": "DATASET", "confidence": 0.6342546343803406}]}, {"text": "Agreements to measure inter-rater consistency among three labelers are calculated with the Fleiss' kappa ().", "labels": [], "entities": []}, {"text": "Model Analysis: We first analyze our models trained with different distant supervision information.", "labels": [], "entities": [{"text": "Model Analysis", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7693188786506653}]}, {"text": "For each model, given a test utterance, we vary the control variable s by setting it to five different values (i.e., 0, 0.2, 0.5, 0.8, 1) to check whether the learned model can actually achieve different specificity levels.", "labels": [], "entities": []}, {"text": "As shown in, we find that: (1) The SC-Seq2Seq model trained with NIRF cannot work well.", "labels": [], "entities": []}, {"text": "The test performances are almost the same with different s value.", "labels": [], "entities": []}, {"text": "This is surprising since the NIRF definition seems to be directly corresponding to the specificity of a response.", "labels": [], "entities": []}, {"text": "By conducting further analysis, we find that even though the conversation dataset is large, it is still limited and a general response could appear very few times in this corpus.", "labels": [], "entities": []}, {"text": "In other words, the inverse frequency of a response is very weakly correlated with its response specificity.", "labels": [], "entities": [{"text": "inverse frequency", "start_pos": 20, "end_pos": 37, "type": "METRIC", "confidence": 0.9416862428188324}]}, {"text": "The SC-Seq2Seq model trained with NIWF can achieve our purpose.", "labels": [], "entities": [{"text": "NIWF", "start_pos": 34, "end_pos": 38, "type": "DATASET", "confidence": 0.9521985054016113}]}, {"text": "By varying the control variable s from 0 to 1, the generated responses turn from general to specific as measured by the distinct metrics.", "labels": [], "entities": []}, {"text": "The results indicate that the max inverse word frequency in a response is a good distant label for the response specificity.", "labels": [], "entities": [{"text": "max inverse word frequency", "start_pos": 30, "end_pos": 56, "type": "METRIC", "confidence": 0.8587941378355026}]}, {"text": "When we compare the generated responses against ground truth data, we find the SC-Seq2Seq NIWF model with the control variable s set to 0.5 can achieve the best performances.", "labels": [], "entities": []}, {"text": "The results indicate that there are diverse responses in real data in terms of specificity, and it is necessary to take a balanced setting if we want to fit the ground truth.", "labels": [], "entities": []}, {"text": "Baseline Comparison: The performance comparisons between our model and the baselines are shown in.", "labels": [], "entities": []}, {"text": "We have the following observations: (1) By using MMI as the objective, MMI-bidi can improve the specificity (in terms of distinct ratios) over the traditional Seq2Seq-att model.", "labels": [], "entities": []}, {"text": "(2) MARM can achieve the best distinct ratios among the baseline methods, but the worst in terms of the distinct numbers.", "labels": [], "entities": [{"text": "MARM", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.41112279891967773}]}, {"text": "The results indicate that MARM tends to generate specific but very short responses.", "labels": [], "entities": [{"text": "MARM", "start_pos": 26, "end_pos": 30, "type": "TASK", "confidence": 0.8663437962532043}]}, {"text": "Meanwhile, its low BLEU scores also show that the responses generated by MARM deviate from the ground truth significantly.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.9996281862258911}]}, {"text": "(3) By using the IDF information as the reward to train  the Seq2Seq model, the Seq2Seq+IDF does not show much advantages, but only achieves comparable results as MMI-bidi.", "labels": [], "entities": [{"text": "IDF", "start_pos": 17, "end_pos": 20, "type": "METRIC", "confidence": 0.9384418725967407}]}, {"text": "(4) By setting the control variable s to 1, our SC-Seq2Seq NIWF model can achieve the best specificity performance as evaluated by the distinct metrics.", "labels": [], "entities": []}, {"text": "By setting the control variable s to 0.5, our SC-Seq2Seq NIWF model can best fit the ground truth data as evaluated by the BLEU scores, Average and Extrema.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 123, "end_pos": 127, "type": "METRIC", "confidence": 0.9966688752174377}, {"text": "Average", "start_pos": 136, "end_pos": 143, "type": "METRIC", "confidence": 0.9839423298835754}, {"text": "Extrema", "start_pos": 148, "end_pos": 155, "type": "METRIC", "confidence": 0.987130343914032}]}, {"text": "All the improvements over the baseline models are statistically significant (p-value < 0.01).", "labels": [], "entities": []}, {"text": "These results demonstrate the effectiveness as well as the flexibility of our controlled generation model.", "labels": [], "entities": []}, {"text": "shows the human evaluation results.", "labels": [], "entities": []}, {"text": "We can observe that: (1) SC-Seq2Seq NIWF,s=1 generates the most informative responses and interesting (labeled as \"+2\") and the least general responses than all the baseline models.", "labels": [], "entities": []}, {"text": "Meanwhile, SC-Seq2Seq NIWF,s=0 generates the most general responses (labeled as \"+1\"); (2) MARM generates the most bad responses (labeled as \"+0\"), which indicates the drawbacks of the unknown latent responding mechanisms; (3) The kappa values of our models are all larger than 0.4, considered as \"moderate agreement\" regarding quality of responses.", "labels": [], "entities": []}, {"text": "The largest kappa value is achieved by SC-Seq2Seq NIWF,s=0 , which seems reasonable since it is easy to reach an agreement on general responses.", "labels": [], "entities": []}, {"text": "Sign tests demonstrate the improvements of SC-Seq2Seq NIWF,s=1 to the baseline models are statistically significant (p-value < 0.01).", "labels": [], "entities": []}, {"text": "All the human judgement results again demonstrate the effectiveness of our controlled generation mechanism.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Short Text Conversation (STC) data statistics: #w  denotes the number of Chinese words.", "labels": [], "entities": [{"text": "Short Text Conversation (STC)", "start_pos": 10, "end_pos": 39, "type": "TASK", "confidence": 0.737485925356547}]}, {"text": " Table 2: Model analysis of our SC-Seq2Seq under the automatic evaluation.", "labels": [], "entities": []}, {"text": " Table 3: Comparisons between our SC-Seq2Seq and the baselines under the automatic evaluation.", "labels": [], "entities": []}, {"text": " Table 4: Results on the human evaluation.", "labels": [], "entities": []}]}