{"title": [{"text": "From Credit Assignment to Entropy Regularization: Two New Algorithms for Neural Sequence Prediction", "labels": [], "entities": [{"text": "Credit Assignment", "start_pos": 5, "end_pos": 22, "type": "TASK", "confidence": 0.723740428686142}, {"text": "Entropy Regularization", "start_pos": 26, "end_pos": 48, "type": "TASK", "confidence": 0.6708906292915344}, {"text": "Neural Sequence Prediction", "start_pos": 73, "end_pos": 99, "type": "TASK", "confidence": 0.7896725336710612}]}], "abstractContent": [{"text": "In this work, we study the credit assignment problem in reward augmented maximum likelihood (RAML) learning, and establish a theoretical equivalence between the token-level counterpart of RAML and the entropy regularized reinforcement learning.", "labels": [], "entities": [{"text": "reward augmented maximum likelihood (RAML) learning", "start_pos": 56, "end_pos": 107, "type": "TASK", "confidence": 0.5903979539871216}]}, {"text": "Inspired by the connection , we propose two sequence prediction algorithms, one extending RAML with fine-grained credit assignment and the other improving Actor-Critic with a systematic entropy regularization.", "labels": [], "entities": [{"text": "sequence prediction", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.7536014318466187}, {"text": "RAML", "start_pos": 90, "end_pos": 94, "type": "METRIC", "confidence": 0.8556190133094788}]}, {"text": "On two benchmark datasets, we show the proposed algorithms outperform RAML and Actor-Critic respectively, providing new alternatives to sequence prediction.", "labels": [], "entities": [{"text": "RAML", "start_pos": 70, "end_pos": 74, "type": "METRIC", "confidence": 0.9639426469802856}, {"text": "sequence prediction", "start_pos": 136, "end_pos": 155, "type": "TASK", "confidence": 0.757595419883728}]}], "introductionContent": [{"text": "Modeling and predicting discrete sequences is the central problem to many natural language processing tasks.", "labels": [], "entities": [{"text": "Modeling and predicting discrete sequences", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.7262237250804902}]}, {"text": "In the last few years, the adaption of recurrent neural networks (RNNs) and the sequenceto-sequence model (seq2seq)) has led to a wide range of successes in conditional sequence prediction, including machine translation (), automatic summarization (, image captioning ( and speech recognition (.", "labels": [], "entities": [{"text": "conditional sequence prediction", "start_pos": 157, "end_pos": 188, "type": "TASK", "confidence": 0.6479626893997192}, {"text": "machine translation", "start_pos": 200, "end_pos": 219, "type": "TASK", "confidence": 0.8058131039142609}, {"text": "summarization", "start_pos": 234, "end_pos": 247, "type": "TASK", "confidence": 0.873451292514801}, {"text": "image captioning", "start_pos": 251, "end_pos": 267, "type": "TASK", "confidence": 0.7858959138393402}, {"text": "speech recognition", "start_pos": 274, "end_pos": 292, "type": "TASK", "confidence": 0.7634142637252808}]}, {"text": "Despite the distinct evaluation metrics for the aforementioned tasks, the standard training algorithm has been the same for all of them.", "labels": [], "entities": []}, {"text": "Specifically, the algorithm is based on maximum likelihood estimation (MLE), which maximizes the log- * Equal contribution.", "labels": [], "entities": [{"text": "maximum likelihood estimation (MLE)", "start_pos": 40, "end_pos": 75, "type": "METRIC", "confidence": 0.7977790236473083}]}, {"text": "likelihood of the \"ground-truth\" sequences empirically observed.", "labels": [], "entities": []}, {"text": "While largely effective, the MLE algorithm has two obvious weaknesses.", "labels": [], "entities": [{"text": "MLE", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.959102213382721}]}, {"text": "Firstly, the MLE training ignores the information of the task specific metric.", "labels": [], "entities": [{"text": "MLE", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9666954278945923}]}, {"text": "As a result, the potentially large discrepancy between the log-likelihood during training and the task evaluation metric attest time can lead to a suboptimal solution.", "labels": [], "entities": []}, {"text": "Secondly, MLE can suffer from the exposure bias, which refers to the phenomenon that the model is never exposed to its own failures during training, and thus cannot recover from an error attest time.", "labels": [], "entities": [{"text": "MLE", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.8633052110671997}, {"text": "exposure bias", "start_pos": 34, "end_pos": 47, "type": "METRIC", "confidence": 0.9594370424747467}]}, {"text": "Fundamentally, this issue roots from the difficulty in statistically modeling the exponentially large space of sequences, where most combinations cannot be covered by the observed data.", "labels": [], "entities": []}, {"text": "To tackle these two weaknesses, there have been various efforts recently, which we summarize into two broad categories: \u2022 A widely explored idea is to directly optimize the task metric for sequences produced by the model, with the specific approaches ranging from minimum risk training (MRT)) and learning as search optimization (LaSO) to reinforcement learning (RL) (.", "labels": [], "entities": [{"text": "learning as search optimization (LaSO)", "start_pos": 297, "end_pos": 335, "type": "TASK", "confidence": 0.7269613785403115}, {"text": "reinforcement learning (RL)", "start_pos": 339, "end_pos": 366, "type": "TASK", "confidence": 0.6614255964756012}]}, {"text": "In spite of the technical differences, the key component to make these training algorithms practically efficient is often a delicate credit assignment scheme, which transforms the sequence-level signal into dedicated smaller units (e.g., token-level or chunk-level), and allocates them to specific decisions, allowing for efficient optimization with a much lower variance.", "labels": [], "entities": []}, {"text": "For instance, the beam search optimiza-tion (BSO) utilizes the position of margin violations to produce signals to the specific chunks, while the actor-critic (AC) algorithm () trains a critic to enable token-level signals.", "labels": [], "entities": []}, {"text": "\u2022 Another alternative idea is to construct a task metric dependent target distribution, and train the model to match this task-specific target instead of the empirical data distribution.", "labels": [], "entities": []}, {"text": "As atypical example, the reward augmented maximum likelihood (RAML) () defines the target distribution as the exponentiated pay-off (sequence-level reward) distribution.", "labels": [], "entities": [{"text": "reward augmented maximum likelihood (RAML)", "start_pos": 25, "end_pos": 67, "type": "METRIC", "confidence": 0.7938580555575234}]}, {"text": "This way, RAML not only can incorporate the task metric information into training, but it can also alleviate the exposure bias by exposing imperfect outputs to the model.", "labels": [], "entities": [{"text": "RAML", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.8026083707809448}]}, {"text": "However, RAML only works on the sequence-level training signal.", "labels": [], "entities": [{"text": "RAML", "start_pos": 9, "end_pos": 13, "type": "METRIC", "confidence": 0.9490843415260315}]}, {"text": "In this work, we are intrigued by the question whether it is possible to incorporate the idea of fine-grained credit assignment into RAML.", "labels": [], "entities": [{"text": "credit assignment", "start_pos": 110, "end_pos": 127, "type": "TASK", "confidence": 0.6912818849086761}]}, {"text": "More specifically, inspired by the token-level signal used in AC, we aim to find the token-level counterpart of the sequence-level RAML, i.e., defining a token-level target distribution for each autoregressive conditional factor to match.", "labels": [], "entities": []}, {"text": "Motived by the question, we first formally define the desiderata the token-level counterpart needs to satisfy and derive the corresponding solution ( \u00a72).", "labels": [], "entities": []}, {"text": "Then, we establish a theoretical connection between the derived token-level RAML and entropy regularized RL ( \u00a73).", "labels": [], "entities": []}, {"text": "Motivated by this connection, we propose two algorithms for neural sequence prediction, where one is the token-level extension to RAML, and the other a RAML-inspired improvement to the AC ( \u00a74).", "labels": [], "entities": [{"text": "neural sequence prediction", "start_pos": 60, "end_pos": 86, "type": "TASK", "confidence": 0.613697330156962}, {"text": "RAML", "start_pos": 130, "end_pos": 134, "type": "METRIC", "confidence": 0.7734447717666626}]}, {"text": "We empirically evaluate the two proposed algorithms, and show different levels of improvement over the corresponding baseline.", "labels": [], "entities": []}, {"text": "We further study the importance of various techniques used in our experiments, providing practical suggestions to readers ( \u00a76).", "labels": [], "entities": []}], "datasetContent": [{"text": "In this work, we focus on two sequence prediction tasks: machine translation and image captioning.", "labels": [], "entities": [{"text": "sequence prediction", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.7620754539966583}, {"text": "machine translation", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.8176330029964447}, {"text": "image captioning", "start_pos": 81, "end_pos": 97, "type": "TASK", "confidence": 0.7619423866271973}]}, {"text": "Due to the space limit, we only present the information necessary to compare the empirical results at this moment.", "labels": [], "entities": []}, {"text": "For a more detailed description, we refer readers to Appendix B and the code 6 . Machine Translation Following, we evaluate on IWSLT 2014 German-toEnglish dataset ().", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 81, "end_pos": 100, "type": "TASK", "confidence": 0.8116211891174316}, {"text": "IWSLT 2014 German-toEnglish dataset", "start_pos": 127, "end_pos": 162, "type": "DATASET", "confidence": 0.928172156214714}]}, {"text": "The corpus contains approximately 153K sentence pairs in the training set.", "labels": [], "entities": []}, {"text": "We follow the pre-processing procedure used in (.", "labels": [], "entities": []}, {"text": "Architecture wise, we employ a seq2seq model with dot-product attention (, where the encoder is a bidirectional LSTM (Hochreiter and Schmidhuber, 1997) with each direction being size 128, and the decoder is another LSTM of size 256.", "labels": [], "entities": []}, {"text": "Moreover, we consider two variants of the decoder, one using the input feeding technique () and the other not.", "labels": [], "entities": []}, {"text": "For all algorithms, the sequence-level BLEU score is employed as the pay-off function R, while the corpus-level BLEU score () is used for the final evaluation.", "labels": [], "entities": [{"text": "sequence-level BLEU score", "start_pos": 24, "end_pos": 49, "type": "METRIC", "confidence": 0.8422080675760905}, {"text": "BLEU score", "start_pos": 112, "end_pos": 122, "type": "METRIC", "confidence": 0.9185954630374908}]}, {"text": "The sequence-level BLEU score is scaled up by the sentence length so that the scale of the immediate reward at each step is invariant to the length.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 19, "end_pos": 29, "type": "METRIC", "confidence": 0.9340605139732361}]}, {"text": "Image Captioning For image captioning, we consider the MSCOCO dataset ().", "labels": [], "entities": [{"text": "Image Captioning", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7248427718877792}, {"text": "image captioning", "start_pos": 21, "end_pos": 37, "type": "TASK", "confidence": 0.7492240369319916}, {"text": "MSCOCO dataset", "start_pos": 55, "end_pos": 69, "type": "DATASET", "confidence": 0.9605343043804169}]}, {"text": "We adapt the same preprocessing procedure and the train/dev/test split used by.", "labels": [], "entities": []}, {"text": "The NIC ( ) is employed as the baseline model, where a feature vector of the image is extracted by a pre-trained CNN and then used to initialize the LSTM decoder.", "labels": [], "entities": []}, {"text": "Different from the original NIC model, we employ a pretrained 101-layer ResNet () rather than a GoogLeNet as the CNN encoder.", "labels": [], "entities": []}, {"text": "https://github.com/zihangdai/ERAC-VAML For training, each image-caption pair is treated as an i.i.d. sample, and sequence-level BLEU score is used as the pay-off.", "labels": [], "entities": [{"text": "sequence-level", "start_pos": 113, "end_pos": 127, "type": "METRIC", "confidence": 0.9071334004402161}, {"text": "BLEU score", "start_pos": 128, "end_pos": 138, "type": "METRIC", "confidence": 0.8701231479644775}]}, {"text": "For testing, the standard multi-reference BLEU4 is used.", "labels": [], "entities": [{"text": "BLEU4", "start_pos": 42, "end_pos": 47, "type": "METRIC", "confidence": 0.982384204864502}]}], "tableCaptions": [{"text": " Table 1: Test results on two benchmark tasks. Bold faces highlight the best in the corresponding category.", "labels": [], "entities": []}, {"text": " Table 2. 8 As we can see, both VAML and  ERAC outperform previous methods, with ERAC  leading the comparison with a significant margin.  This further verifies the effectiveness of the two  proposed algorithms.", "labels": [], "entities": [{"text": "VAML", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.7588529586791992}, {"text": "ERAC", "start_pos": 42, "end_pos": 46, "type": "TASK", "confidence": 0.36809444427490234}]}, {"text": " Table 2: Comparison with existing algorithms on  IWSTL 2014 dataset for MT. All numbers of pre- vious algorithms are from the original work.", "labels": [], "entities": [{"text": "IWSTL 2014 dataset", "start_pos": 50, "end_pos": 68, "type": "DATASET", "confidence": 0.9640355706214905}, {"text": "MT", "start_pos": 73, "end_pos": 75, "type": "TASK", "confidence": 0.9534971117973328}]}, {"text": " Table 3: Average validation BLEU of ERAC. As  a reference, the average BLEU is 28.1 for MLE.  \u03bb var = 0 means not using the smoothing technique.  \u03b2 = 1 means not using a target network.  \u2020 indi- cates excluding extreme values due to divergence.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 29, "end_pos": 33, "type": "METRIC", "confidence": 0.9413465261459351}, {"text": "ERAC", "start_pos": 37, "end_pos": 41, "type": "TASK", "confidence": 0.5232746005058289}, {"text": "BLEU", "start_pos": 72, "end_pos": 76, "type": "METRIC", "confidence": 0.9973465204238892}]}, {"text": " Table 4. As  we can see, simply adding a local entropy gradient  does not even improve upon the AC. This further  verifies the difference between ERAC and A3C,  and shows the importance of taking future entropy  into consideration.", "labels": [], "entities": [{"text": "ERAC", "start_pos": 147, "end_pos": 151, "type": "METRIC", "confidence": 0.5204116702079773}]}, {"text": " Table 4: Comparing ERAC with the variant with- out considering future entropy.", "labels": [], "entities": [{"text": "ERAC", "start_pos": 20, "end_pos": 24, "type": "METRIC", "confidence": 0.6388546228408813}]}]}