{"title": [{"text": "Linear-Time Constituency Parsing with RNNs and Dynamic Programming", "labels": [], "entities": [{"text": "Linear-Time Constituency Parsing", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7452560464541117}]}], "abstractContent": [{"text": "Recently, span-based constituency parsing has achieved competitive accuracies with extremely simple models by using bidirec-tional RNNs to model \"spans\".", "labels": [], "entities": [{"text": "span-based constituency parsing", "start_pos": 10, "end_pos": 41, "type": "TASK", "confidence": 0.6398975153764089}]}, {"text": "However, the minimal span parser of Stern et al.", "labels": [], "entities": []}, {"text": "(2017a) which holds the current state of the art accuracy is a chart parser running in cubic time, O(n 3), which is too slow for longer sentences and for applications beyond sentence boundaries such as end-to-end discourse parsing and joint sentence boundary detection and parsing.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9994767308235168}, {"text": "O", "start_pos": 99, "end_pos": 100, "type": "METRIC", "confidence": 0.9656352996826172}, {"text": "discourse parsing", "start_pos": 213, "end_pos": 230, "type": "TASK", "confidence": 0.7181372344493866}, {"text": "joint sentence boundary detection and parsing", "start_pos": 235, "end_pos": 280, "type": "TASK", "confidence": 0.6175239632527033}]}, {"text": "We propose a linear-time constituency parser with RNNs and dynamic programming using graph-structured stack and beam search, which runs in time O(nb 2) where b is the beam size.", "labels": [], "entities": []}, {"text": "We further speed this up to O(nb log b) by integrating cube pruning.", "labels": [], "entities": [{"text": "O", "start_pos": 28, "end_pos": 29, "type": "METRIC", "confidence": 0.9979667663574219}]}, {"text": "Compared with chart parsing base-lines, this linear-time parser is substantially faster for long sentences on the Penn Treebank and orders of magnitude faster for discourse parsing, and achieves the highest F1 accuracy on the Penn Treebank among single model end-to-end systems.", "labels": [], "entities": [{"text": "chart parsing", "start_pos": 14, "end_pos": 27, "type": "TASK", "confidence": 0.7351103127002716}, {"text": "Penn Treebank", "start_pos": 114, "end_pos": 127, "type": "DATASET", "confidence": 0.9960789978504181}, {"text": "discourse parsing", "start_pos": 163, "end_pos": 180, "type": "TASK", "confidence": 0.7080090939998627}, {"text": "F1", "start_pos": 207, "end_pos": 209, "type": "METRIC", "confidence": 0.9974719882011414}, {"text": "accuracy", "start_pos": 210, "end_pos": 218, "type": "METRIC", "confidence": 0.595469057559967}, {"text": "Penn Treebank", "start_pos": 226, "end_pos": 239, "type": "DATASET", "confidence": 0.995999276638031}]}], "introductionContent": [{"text": "Span-based neural constituency parsing) has attracted attention due to its high accuracy and extreme simplicity.", "labels": [], "entities": [{"text": "Span-based neural constituency parsing", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.5627795308828354}, {"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9991143345832825}]}, {"text": "Compared with other recent neural constituency parsers;) which use neural networks to model tree structures, the spanbased framework is considerably simpler, only using bidirectional RNNs to model the input sequence and not the output tree.", "labels": [], "entities": []}, {"text": "Because of this factorization, the output space is decomposable which enables efficient dynamic programming algorithm such as CKY.", "labels": [], "entities": []}, {"text": "But existing span-based parsers suffer from a crucial limitation in terms of search: on the one hand, a greedy span parser) is fast (linear-time) but only explores one single path in the exponentially large search space, and on the other hand, a chartbased span parser () performs exact search and achieves state-of-the-art accuracy, but in cubic time, which is too slow for longer sentences and for applications that go beyond sentence boundaries such as end-to-end discourse parsing and integrated sentence boundary detection and parsing.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 324, "end_pos": 332, "type": "METRIC", "confidence": 0.9972352385520935}, {"text": "discourse parsing", "start_pos": 467, "end_pos": 484, "type": "TASK", "confidence": 0.7553577125072479}, {"text": "sentence boundary detection and parsing", "start_pos": 500, "end_pos": 539, "type": "TASK", "confidence": 0.6736007630825043}]}, {"text": "We propose to combine the merits of both greedy and chart-based approaches and design a linear-time span-based neural parser that searches over exponentially large space.", "labels": [], "entities": []}, {"text": "Following, we perform left-to-right dynamic programming in an action-synchronous style, with (2n \u2212 1) actions (i.e., steps) fora sentence of n words.", "labels": [], "entities": []}, {"text": "While previous non-neural work in this area requires sophisticated features and thus high time complexity such as O(n 11 ), our states are as simple as : (i, j) where is the step index and (i, j) is the span, modeled using bidirectional RNNs without any syntactic features.", "labels": [], "entities": [{"text": "O", "start_pos": 114, "end_pos": 115, "type": "METRIC", "confidence": 0.8885267972946167}]}, {"text": "This gives a running time of O(n 4 ), with the extra O(n) for step index.", "labels": [], "entities": [{"text": "O", "start_pos": 29, "end_pos": 30, "type": "METRIC", "confidence": 0.9921438694000244}, {"text": "O", "start_pos": 53, "end_pos": 54, "type": "METRIC", "confidence": 0.9880111813545227}]}, {"text": "We further employ beam search to have a practical runtime of O(nb 2 ) at the cost of exact search where b is the beam size.", "labels": [], "entities": [{"text": "beam search", "start_pos": 18, "end_pos": 29, "type": "TASK", "confidence": 0.9157447516918182}, {"text": "O", "start_pos": 61, "end_pos": 62, "type": "METRIC", "confidence": 0.9941867589950562}]}, {"text": "However, on the Penn Treebank, most sentences are less than 40 words (n < 40), and even with a small beam size of b = 10, the observed complexity of an O(nb 2 ) parser is not exactly linear inn (see Experiments).", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 16, "end_pos": 29, "type": "DATASET", "confidence": 0.9958507120609283}]}, {"text": "To solve this problem, we apply cube pruning to improve the runtime to O(nb log b) which renders an observed complexity that is linear inn (with minor extra inexactness).", "labels": [], "entities": [{"text": "O", "start_pos": 71, "end_pos": 72, "type": "METRIC", "confidence": 0.9862676858901978}]}, {"text": "We make the following contributions: \u2022 We design the first neural parser that is both linear time and capable of searching over exponentially large space.", "labels": [], "entities": []}, {"text": "1 \u2022 We are the first to apply cube pruning to incremental parsing, and achieves, for the first time, the complexity of O(nb log b), i.e., linear in sentence length and (almost) linear in beam size.", "labels": [], "entities": [{"text": "O", "start_pos": 119, "end_pos": 120, "type": "METRIC", "confidence": 0.9895288348197937}]}, {"text": "This leads to an observed complexity strictly linear in sentence length n.", "labels": [], "entities": []}, {"text": "\u2022 We devise a novel loss function which penalizes wrong spans that cross gold-tree spans, and employ max-violation update to train this parser with structured SVM and beam search.", "labels": [], "entities": []}, {"text": "\u2022 Compared with chart parsing baselines, our parser is substantially faster for long sentences on the Penn Treebank, and orders of magnitude faster for end-to-end discourse parsing.", "labels": [], "entities": [{"text": "chart parsing", "start_pos": 16, "end_pos": 29, "type": "TASK", "confidence": 0.7603861391544342}, {"text": "Penn Treebank", "start_pos": 102, "end_pos": 115, "type": "DATASET", "confidence": 0.9959667325019836}, {"text": "discourse parsing", "start_pos": 163, "end_pos": 180, "type": "TASK", "confidence": 0.7412766516208649}]}, {"text": "It also achieves the highest F1 score on the Penn Treebank among single model end-to-end systems.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9881193041801453}, {"text": "Penn Treebank", "start_pos": 45, "end_pos": 58, "type": "DATASET", "confidence": 0.9922007322311401}]}, {"text": "\u2022 We devise anew formulation of graphstructured stack which requires no extra bookkeeping, proving anew theorem that gives deep insight into GSS.", "labels": [], "entities": [{"text": "GSS", "start_pos": 141, "end_pos": 144, "type": "DATASET", "confidence": 0.6142827868461609}]}], "datasetContent": [{"text": "We present experiments on the Penn Treebank () and the PTB-RST discourse treebank ().", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 30, "end_pos": 43, "type": "DATASET", "confidence": 0.9960965514183044}, {"text": "PTB-RST discourse treebank", "start_pos": 55, "end_pos": 81, "type": "DATASET", "confidence": 0.9647902051607767}]}, {"text": "In both cases, the training set is shuffled before each epoch, and dropout () is employed with probability 0.4 to the recurrent outputs for regularization.", "labels": [], "entities": [{"text": "dropout", "start_pos": 67, "end_pos": 74, "type": "METRIC", "confidence": 0.9512210488319397}]}, {"text": "Updates with minibatches of size 10 and 1 are used for PTB and the PTB-RST respectively.", "labels": [], "entities": [{"text": "PTB", "start_pos": 55, "end_pos": 58, "type": "DATASET", "confidence": 0.9303998947143555}, {"text": "PTB-RST", "start_pos": 67, "end_pos": 74, "type": "DATASET", "confidence": 0.979601263999939}]}, {"text": "We use Adam () with default settings to schedule learning rates for all the weights.", "labels": [], "entities": []}, {"text": "To address unknown words during training, we adopt the strategy described by; words in the training set are replaced with the unknown word symbol UNK with probability punk = 1 1+f (w) , with f (w) being the number of  occurrences of word win the training corpus.", "labels": [], "entities": []}, {"text": "Our system is implemented in Python using the DyNet neural network library (.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison of PTB development set  results, with the time measured in seconds-per- sentence. The baseline chart parser is from Stern  et al. (2017b), with null-label scores unconstrained  to be nonzero, replicating their paper.", "labels": [], "entities": []}, {"text": " Table 2: Final PTB Test Results. We compare our  models with other (neural) single-model end-to- end trained systems.", "labels": [], "entities": []}, {"text": " Table 3: Overall test accuracies for PTB-RST dis- course treebank. Starred rows indicate a run that  was decoded from the beam 200 model.", "labels": [], "entities": [{"text": "PTB-RST dis- course treebank", "start_pos": 38, "end_pos": 66, "type": "DATASET", "confidence": 0.743631112575531}]}, {"text": " Table 4: F1 scores comparing discourse systems.  Results correspond to the accuracies in", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9989290833473206}]}]}