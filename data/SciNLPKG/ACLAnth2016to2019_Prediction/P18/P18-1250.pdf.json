{"title": [{"text": "Pre-and In-Parsing Models for Neural Empty Category Detection", "labels": [], "entities": [{"text": "Neural Empty Category Detection", "start_pos": 30, "end_pos": 61, "type": "TASK", "confidence": 0.73382768034935}]}], "abstractContent": [{"text": "Motivated by the positive impact of empty categories on syntactic parsing, we study neural models for pre-and in-parsing detection of empty categories, which has not previously been investigated.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 56, "end_pos": 73, "type": "TASK", "confidence": 0.7240617573261261}]}, {"text": "We find several non-obvious facts: (a) BiLSTM can capture non-local contextual information which is essential for detecting empty categories , (b) even with a BiLSTM, syntactic information is still able to enhance the detection, and (c) automatic detection of empty categories improves parsing quality for overt words.", "labels": [], "entities": []}, {"text": "Our neural ECD models outperform the prior state-of-the-art by significant margins.", "labels": [], "entities": []}], "introductionContent": [{"text": "Encoding unpronounced nominal elements, such as dropped pronouns and traces of dislocated elements, the empty category is an important piece of machinery in representing the (deep) syntactic structure of a sentence.", "labels": [], "entities": []}, {"text": "In linguistic theory, e.g., empty category is a key concept bridging S-Structure and D-Structure, due to its possible contribution to trace movements.", "labels": [], "entities": []}, {"text": "In practical treebanking, empty categories have been used to indicate long-distance dependencies, discontinuous constituents, and certain dropped elements).", "labels": [], "entities": []}, {"text": "Recently, there has been an increasing interest in automatic empty category detection.", "labels": [], "entities": [{"text": "empty category detection", "start_pos": 61, "end_pos": 85, "type": "TASK", "confidence": 0.6121728618939718}]}, {"text": "And it has been shown that ECD is able to improve the linear model-based dependency parsing ().", "labels": [], "entities": [{"text": "linear model-based dependency parsing", "start_pos": 54, "end_pos": 91, "type": "TASK", "confidence": 0.5896541327238083}]}, {"text": "There are two key dimensions of approaches Pre-Parsing In-Parsing Post-Parsing Linear \u2714 \u2714 \u2714 Neural \u2718 \u2718 \u2714: ECD approaches that have been investigated.", "labels": [], "entities": []}, {"text": "for ECD: the relationship with parsing and statistical disambiguation.", "labels": [], "entities": [{"text": "parsing", "start_pos": 31, "end_pos": 38, "type": "TASK", "confidence": 0.9802474975585938}]}, {"text": "Considering the relationship with parsing, we can divide ECD models into three types: (1) Pre-parsing approach (e.g.) where empty categories are identified without using syntactic analysis, (2) In-parsing approach (e.g.;) where detection is integrated into a parsing model, and (3) Post-parsing approach (e.g. Johnson (2002);) where parser outputs are utilized as clues to determine the existence of empty categories.", "labels": [], "entities": []}, {"text": "For disambiguation, while early work on dependency parsing focused on linear models, recent work started exploring deep learning techniques for the post-parsing approach (.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.8145818114280701}]}, {"text": "From the above two dimensions, we show all existing systems for ECD in.", "labels": [], "entities": [{"text": "ECD", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.856948733329773}]}, {"text": "Neural models for pre-and in-parsing ECD have not been studied yet.", "labels": [], "entities": [{"text": "ECD", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.780370831489563}]}, {"text": "In this paper, we fill this gap in the literature.", "labels": [], "entities": []}, {"text": "It is obvious that empty categories are highly related to surface syntactic analysis.", "labels": [], "entities": [{"text": "surface syntactic analysis", "start_pos": 58, "end_pos": 84, "type": "TASK", "confidence": 0.6828150351842245}]}, {"text": "To determine the existence of empty elements between two overt words relies on not only the sequential contexts but also the hierarchical contexts.", "labels": [], "entities": []}, {"text": "Traditional linear structured prediction models, e.g. conditional random fields (CRF), for sequence structures are rather weak to capture hierarchical contextual information which is essentially non-local for their architectures.", "labels": [], "entities": []}, {"text": "Accordingly, pre-parsing models based on linear disambiguation techniques fail to produce comparable accuracy to the other two models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 101, "end_pos": 109, "type": "METRIC", "confidence": 0.9991416931152344}]}, {"text": "In striking contrast, RNN based se-: An example from CTB: Shanghai Pudong recently enacted 71 regulatory documents involving the economic fields.", "labels": [], "entities": [{"text": "CTB", "start_pos": 53, "end_pos": 56, "type": "DATASET", "confidence": 0.9719671010971069}, {"text": "Shanghai Pudong", "start_pos": 58, "end_pos": 73, "type": "DATASET", "confidence": 0.9216486215591431}]}, {"text": "The dependency structure is according to.", "labels": [], "entities": []}, {"text": "\"\u2205 1 \" indicates a null operator that represents empty relative pronouns.", "labels": [], "entities": []}, {"text": "\"\u2205 2 \" indicates a trace left by relativization.", "labels": [], "entities": []}, {"text": "quence labeling models have been shown very powerful to capture non-local information, and therefore have great potential to advance the preparsing approach for ECD.", "labels": [], "entities": [{"text": "quence labeling", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8588933944702148}]}, {"text": "In this paper, we propose anew bidirectional LSTM (BiLSTM) model for pre-parsing ECD using information about contextual words.", "labels": [], "entities": []}, {"text": "Previous studies highlight the usefulness of syntactic analysis for ECD.", "labels": [], "entities": [{"text": "syntactic analysis", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.7263248711824417}, {"text": "ECD", "start_pos": 68, "end_pos": 71, "type": "TASK", "confidence": 0.9371830224990845}]}, {"text": "Furthermore, syntactic parsing of overt words can benefit from detection of empty elements and vice versa (.", "labels": [], "entities": [{"text": "syntactic parsing of overt words", "start_pos": 13, "end_pos": 45, "type": "TASK", "confidence": 0.8326282262802124}]}, {"text": "In this paper, we follow Zhang et al.'s encouraging results obtained with linear models and study first-and second-order neural models for inparsing ECD.", "labels": [], "entities": []}, {"text": "The main challenge for neural inparsing ECD is to encode empty element candidates and integrate the corresponding embeddings into a parsing model.", "labels": [], "entities": [{"text": "neural inparsing ECD", "start_pos": 23, "end_pos": 43, "type": "TASK", "confidence": 0.5948558350404104}]}, {"text": "We focus on the state-ofthe-art parsing architecture developed by and, which use BiLSTMs to extract features from contexts followed by a nonlinear transformation to perform local scoring.", "labels": [], "entities": []}, {"text": "To evaluate the effectiveness of deep learning techniques for ECD, we conduct experiments on a pro-drop language, i.e. Chinese.", "labels": [], "entities": [{"text": "ECD", "start_pos": 62, "end_pos": 65, "type": "TASK", "confidence": 0.9810896515846252}]}, {"text": "The empirical evaluation indicates some non-obvious facts: 1.", "labels": [], "entities": []}, {"text": "Neural ECD models outperform the prior state-of-the-art by significant margins.", "labels": [], "entities": []}, {"text": "Even a pre-parsing model without any syntactic information outperforms the best existing linear in-parsing and post-parsing ECD models.", "labels": [], "entities": []}, {"text": "2. Incorporating empty elements can help neural dependency parsing.", "labels": [], "entities": [{"text": "neural dependency parsing", "start_pos": 41, "end_pos": 66, "type": "TASK", "confidence": 0.6359483301639557}]}, {"text": "This parallels Zhang et al.'s investigation on linear models.", "labels": [], "entities": []}, {"text": "3. Our in-parsing neural models obtain better predictions than the pre-parsing model.", "labels": [], "entities": []}, {"text": "The implementation of all models is available at https://github.com/draplater/ empty-parser.", "labels": [], "entities": []}], "datasetContent": [{"text": "We adopt two kinds of metrics for the evaluation of our experiments.", "labels": [], "entities": []}, {"text": "The first one focuses on EC's position and type, in accordance with the labeled empty elements measure proposed by, which can be implemented on all models in our experiments.", "labels": [], "entities": []}, {"text": "The second one is stricter.", "labels": [], "entities": []}, {"text": "Besides position and type, it also checks EC's head information.", "labels": [], "entities": [{"text": "EC's head information", "start_pos": 42, "end_pos": 63, "type": "DATASET", "confidence": 0.8343208879232407}]}, {"text": "An EC is considered to be correct, only when all the three parts are the same as the corresponding gold standard.", "labels": [], "entities": [{"text": "EC", "start_pos": 3, "end_pos": 5, "type": "METRIC", "confidence": 0.9453710317611694}, {"text": "correct", "start_pos": 26, "end_pos": 33, "type": "METRIC", "confidence": 0.9661231637001038}]}, {"text": "Thus only models involved in dependency structures can be evaluated according to the latter metric.", "labels": [], "entities": []}, {"text": "Based on above measures of the two degrees, we evaluate our neural pre-and in-parsing models regarding each type of EC as well as overall performance.", "labels": [], "entities": []}, {"text": "Besides, to compare different models' abilities to capture non-local information, we design Dependency Distance to indicate the number of words from one EC to its head, not counting other ECs on the path.", "labels": [], "entities": []}, {"text": "Taking the two ECs in as an example, \u2205 2 has a Dependency Distance of 0 while \u2205 1 's Dependency Distance is 3.", "labels": [], "entities": [{"text": "Dependency Distance", "start_pos": 47, "end_pos": 66, "type": "METRIC", "confidence": 0.9173187017440796}, {"text": "Dependency Distance", "start_pos": 85, "end_pos": 104, "type": "METRIC", "confidence": 0.795889288187027}]}, {"text": "We calculate labeled recall scores for enumerated Dependency Distance.", "labels": [], "entities": [{"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9591529965400696}]}, {"text": "A higher score means greater capability to catch and to represent long-distance details.", "labels": [], "entities": []}, {"text": "shows overall performances of the two sequential models on development data.", "labels": [], "entities": []}, {"text": "From the results, we can clearly see that the introduction of neural structure pushes up the scores exceptionally.", "labels": [], "entities": []}, {"text": "The reason is that our LSTM-CRF model not only benefits from the linear weighted combination of local characteristics like ordinary CRF models, but also has the ability to integrate more contextual information, especially long-distance information.", "labels": [], "entities": []}, {"text": "It confirms LSTM-based models' great superiority in sequence labeling problems.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 52, "end_pos": 69, "type": "TASK", "confidence": 0.6703748404979706}]}], "tableCaptions": [{"text": " Table 2: The distribution of ECs' continuous  lengths in training, development and test data.", "labels": [], "entities": []}, {"text": " Table 3: The overall performance of the two sequential models on development data.", "labels": [], "entities": []}, {"text": " Table 4: The overall performance on test data. \"*\"  indicates more stringent evaluation metrics.", "labels": [], "entities": []}, {"text": " Table 5: Occurrences of different ECs in test data  and detailed results of Interspace with POS infor- mation.", "labels": [], "entities": [{"text": "Occurrences", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9843358993530273}, {"text": "POS infor- mation", "start_pos": 93, "end_pos": 110, "type": "DATASET", "confidence": 0.6624601036310196}]}, {"text": " Table 6: The performances of the first-and  second-order in-parsing models on test data.", "labels": [], "entities": []}]}