{"title": [{"text": "Generating Fine-Grained Open Vocabulary Entity Type Descriptions", "labels": [], "entities": [{"text": "Generating Fine-Grained Open Vocabulary Entity Type Descriptions", "start_pos": 0, "end_pos": 64, "type": "TASK", "confidence": 0.584995299577713}]}], "abstractContent": [{"text": "While large-scale knowledge graphs provide vast amounts of structured facts about entities, a short textual description can often be useful to succinctly characterize an entity and its type.", "labels": [], "entities": []}, {"text": "Unfortunately, many knowledge graph entities lack such tex-tual descriptions.", "labels": [], "entities": []}, {"text": "In this paper, we introduce a dynamic memory-based network that generates a short open vocabulary description of an entity by jointly leverag-ing induced fact embeddings as well as the dynamic context of the generated sequence of words.", "labels": [], "entities": []}, {"text": "We demonstrate the ability of our architecture to discern relevant information for more accurate generation of type description by pitting the system against several strong baselines.", "labels": [], "entities": [{"text": "type description", "start_pos": 111, "end_pos": 127, "type": "TASK", "confidence": 0.7943019866943359}]}], "introductionContent": [{"text": "Broad-coverage knowledge graphs such as Freebase, Wikidata, and NELL are increasingly being used in many NLP and AI tasks.", "labels": [], "entities": []}, {"text": "For instance, DBpedia and YAGO were vital for IBM's Watson!", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 14, "end_pos": 21, "type": "DATASET", "confidence": 0.8917601108551025}, {"text": "YAGO", "start_pos": 26, "end_pos": 30, "type": "METRIC", "confidence": 0.8819147348403931}, {"text": "Watson!", "start_pos": 52, "end_pos": 59, "type": "DATASET", "confidence": 0.8868330717086792}]}, {"text": "Google's Knowledge Graph is tightly integrated into its search engine, yielding improved responses for entity queries as well as for question answering.", "labels": [], "entities": [{"text": "question answering", "start_pos": 133, "end_pos": 151, "type": "TASK", "confidence": 0.8287903368473053}]}, {"text": "Ina similar effort, Apple Inc. is building an inhouse knowledge graph to power Siri and its next generation of intelligent products and services.", "labels": [], "entities": []}, {"text": "Despite being rich sources of factual knowledge, cross-domain knowledge graphs often lack a succinct textual description for many of the existing entities.", "labels": [], "entities": []}, {"text": "depicts an example of a concise entity description presented to a user.", "labels": [], "entities": []}, {"text": "Descriptions of this sort can be beneficial both to humans and in downstream AI and natural language processing tasks, including question answering (e.g., Who is Roger Federer?), named entity disambiguation (e.g., Philadelphia as a city vs. the film or even the brand of cream cheese), and information retrieval, to name but a few.", "labels": [], "entities": [{"text": "question answering", "start_pos": 129, "end_pos": 147, "type": "TASK", "confidence": 0.803175300359726}, {"text": "named entity disambiguation", "start_pos": 179, "end_pos": 206, "type": "TASK", "confidence": 0.6744557917118073}, {"text": "information retrieval", "start_pos": 290, "end_pos": 311, "type": "TASK", "confidence": 0.8550118803977966}]}, {"text": "Additionally, descriptions of this sort can also be useful to determine the ontological type of an entity -another challenging task that often needs to be addressed in cross-domain knowledge graphs.", "labels": [], "entities": []}, {"text": "Many knowledge graphs already provide ontological type information, and there has been substantial previous research on how to predict such types automatically for entities in knowledge graphs, in semistructured resources such as Wikipedia (, or even in unstructured text (;.", "labels": [], "entities": []}, {"text": "However, most such work has targeted a fixed inventory of types from a given target ontology, many of which are more abstract in nature (e.g., human or artifact).", "labels": [], "entities": []}, {"text": "In this work, we consider the task of generating more detailed open vocabulary descriptions (e.g., Swiss tennis player) that can readily be presented to end users, generated from facts in the knowledge graph.", "labels": [], "entities": []}, {"text": "Apart from type descriptions, certain knowledge graphs, such as Freebase and DBpedia, also provide a paragraph-length textual abstract for every entity.", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 77, "end_pos": 84, "type": "DATASET", "confidence": 0.8650543689727783}]}, {"text": "In the latter case, these are sourced from Wikipedia.", "labels": [], "entities": []}, {"text": "There has also been research on generating such abstracts automatically.", "labels": [], "entities": []}, {"text": "While abstracts of this sort provide considerably more detail than ontological types, they are not sufficiently concise to be grasped at a single glance, and thus the onus is put on the reader to comprehend and summarize them.", "labels": [], "entities": [{"text": "summarize", "start_pos": 211, "end_pos": 220, "type": "TASK", "confidence": 0.9207701086997986}]}, {"text": "Typically, a short description of an entity will hence need to be synthesized just by drawing on certain most relevant facts about it.", "labels": [], "entities": []}, {"text": "While in many circumstances, humans tend to categorize entities at a level of abstraction commonly referred to as basic level categories (, in an information seeking setting, however, such as in, humans naturally expect more detail from their interlocutor.", "labels": [], "entities": []}, {"text": "For example, occupation and nationality are often the two most relevant properties used in describing a person in Wikidata, while terms such as person or human being are likely to be perceived as overly unspecific.", "labels": [], "entities": []}, {"text": "However, choosing such most relevant and distinctive attributes from the set of available facts about the entity is non-trivial, especially given the diversity of different kinds of entities in broad-coverage knowledge graphs.", "labels": [], "entities": []}, {"text": "Moreover, the generated text should be coherent, succinct, and non-redundant.", "labels": [], "entities": []}, {"text": "To address this problem, we propose a dynamic memory-based generative network that can generate short textual descriptions from the available factual information about the entities.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, we are the first to present neural methods to tackle this problem.", "labels": [], "entities": []}, {"text": "Previous work has suggested generating short descriptions using predefined templates (cf. Section 4).", "labels": [], "entities": []}, {"text": "However, this approach severely restricts the expressivity of the model and hence such templates are typically only applied to very narrow classes of entities.", "labels": [], "entities": []}, {"text": "In contrast, our goal is to design a broad-coverage open domain description generation architecture.", "labels": [], "entities": []}, {"text": "In our experiments, we induce anew benchmark dataset for this task by relying on Wikidata, which has recently emerged as the most popular crowdsourced knowledge base, following Google's designation of Wikidata as the successor to Freebase.", "labels": [], "entities": []}, {"text": "With abroad base of 19,000 casual Web users as contributors, Wikidata is a crucial source of machine-readable knowledge in many applications.", "labels": [], "entities": []}, {"text": "Unlike DBpedia and Freebase, Wikidata usually contains a very concise description for many of its entities.", "labels": [], "entities": []}, {"text": "However, because Wikidata is based on user contributions, many new entries are created that still lack such descriptions.", "labels": [], "entities": []}, {"text": "This can be a problem for downstream tools and applications using Wikidata for background knowledge.", "labels": [], "entities": []}, {"text": "Hence, even for Wikidata, there is a need for tools to generate fine-grained type descriptions.", "labels": [], "entities": []}, {"text": "Fortunately, we can rely on the entities for which users have already contributed short descriptions to induce anew benchmark dataset for the task of automatically inducing type descriptions from structured data.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe the process of creating our benchmark dataset as well as the baseline methods and the experimental results.", "labels": [], "entities": []}, {"text": "For the evaluation of our method, we introduce a novel benchmark dataset that we have extracted from Wikidata and transformed to a suitable format.", "labels": [], "entities": []}, {"text": "We rely on the official RDF exports of Wikidata, which are generated regularly), specifically, the RDF dump dated 2016-08-01, which consists of 19,768,780 entities with 2,570 distinct properties.", "labels": [], "entities": [{"text": "Wikidata", "start_pos": 39, "end_pos": 47, "type": "DATASET", "confidence": 0.6079971790313721}, {"text": "RDF dump dated 2016-08-01", "start_pos": 99, "end_pos": 124, "type": "DATASET", "confidence": 0.883793979883194}]}, {"text": "A pair of a property and its corresponding value represents a fact about an entity.", "labels": [], "entities": []}, {"text": "In Wikidata parlance, such facts are called statements.", "labels": [], "entities": [{"text": "Wikidata parlance", "start_pos": 3, "end_pos": 20, "type": "TASK", "confidence": 0.743706464767456}]}, {"text": "We sample a dataset of 10K entities from Wikidata, and henceforth refer to the resulting dataset as WikiFacts10K.", "labels": [], "entities": []}, {"text": "Our sampling method ensures that each entity in WikiFacts10K has an English description and at least 5 associated statements.", "labels": [], "entities": []}, {"text": "We then transform each extracted statement into a phrasal form by concatenating the words of the property name and its value.", "labels": [], "entities": []}, {"text": "For example, the (subject, predicate, object) triple (Roger Federer, occupation, tennis player) is transformed to 'occupation tennis player'.", "labels": [], "entities": []}, {"text": "We refer to these phrases as the factual phrases, which are embedded as described earlier.", "labels": [], "entities": []}, {"text": "We randomly divide this dataset into training, validation, and test sets with a 8:1:1 ratio.", "labels": [], "entities": []}, {"text": "We have made our code and data available 1 for reproducibility and to facilitate further research in this area.", "labels": [], "entities": []}, {"text": "For each entity in the WikiFacts10K dataset, there is a corresponding set of facts expressed as factual phrases as defined earlier.", "labels": [], "entities": [{"text": "WikiFacts10K dataset", "start_pos": 23, "end_pos": 43, "type": "DATASET", "confidence": 0.9606654644012451}]}, {"text": "Each factual phrase in turn is encoded as a vector by means of the positional encoding scheme described in Section 2.1.", "labels": [], "entities": []}, {"text": "Although other variants could be considered, such as LSTMs and GRUs, we apply this standard fact encoding mechanism for our model as well as all our baselines for the sake of uniformity and fair comparison.", "labels": [], "entities": []}, {"text": "Another factor that makes the use of a sequence encoder such as LSTMs or GRUs less suitable is that the set of input facts is essentially unordered without any temporal correlation between facts.", "labels": [], "entities": []}, {"text": "We fixed the dimensionality of the fact embeddings and all hidden states to be 100.", "labels": [], "entities": []}, {"text": "The vocabulary size is 29K.", "labels": [], "entities": []}, {"text": "Our models and all other baselines are trained fora maximum of 25 epochs with an early stopping criterion and a fixed learning rate of 0.001.", "labels": [], "entities": [{"text": "early stopping criterion", "start_pos": 81, "end_pos": 105, "type": "METRIC", "confidence": 0.8957050840059916}]}, {"text": "To evaluate the quality of the generated descriptions, we rely on the standard BLEU (B-1, B-2, B-3, B-4), ROUGE-L, METEOR and CIDEr metrics, as implemented by.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 79, "end_pos": 83, "type": "METRIC", "confidence": 0.998860239982605}, {"text": "ROUGE-L", "start_pos": 106, "end_pos": 113, "type": "METRIC", "confidence": 0.9950646758079529}, {"text": "METEOR", "start_pos": 115, "end_pos": 121, "type": "METRIC", "confidence": 0.9623783826828003}]}, {"text": "Of course, we would be remiss not to point out that these metrics are imperfect.", "labels": [], "entities": []}, {"text": "In general, they tend to be conservative in that they only reward generated descriptions that overlap substantially with the ground truth descriptions given in Wikidata.", "labels": [], "entities": []}, {"text": "In reality, it may of course be the case that alternative descriptions are equally appropriate.", "labels": [], "entities": []}, {"text": "In fact, inspecting the generated descriptions, we found that our method often indeed generates correct alternative descriptions.", "labels": [], "entities": []}, {"text": "For instance, Darius Kaiser is described as a cyclist, but one could also describe him as a German bicycle racer.", "labels": [], "entities": []}, {"text": "Despite their shortcomings, the aforementioned metrics have generally been found suitable for comparing supervised systems, in that systems with significantly higher scores tend to fare better at learning to reproduce ground truth captions.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Automatic evaluation results of different models. For a detailed explanation of the baseline models, please refer to  Section 3.2. The best performing model for each column is highlighted in boldface.", "labels": [], "entities": []}, {"text": " Table 2: A representative sample of the generated descriptions and its comparison with the ground truth descriptions.", "labels": [], "entities": []}]}