{"title": [{"text": "Simpler but More Accurate Semantic Dependency Parsing", "labels": [], "entities": [{"text": "Accurate", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9760928153991699}, {"text": "Parsing", "start_pos": 46, "end_pos": 53, "type": "TASK", "confidence": 0.46083080768585205}]}], "abstractContent": [{"text": "While syntactic dependency annotations concentrate on the surface or functional structure of a sentence, semantic dependency annotations aim to capture between-word relationships that are more closely related to the meaning of a sentence, using graph-structured representations.", "labels": [], "entities": []}, {"text": "We extend the LSTM-based syntactic parser of Dozat and Manning (2017) to train on and generate these graph structures.", "labels": [], "entities": []}, {"text": "The resulting system on its own achieves state-of-the-art performance, beating the previous , substantially more complex state-of-the-art system by 0.6% labeled F1.", "labels": [], "entities": [{"text": "F1", "start_pos": 161, "end_pos": 163, "type": "METRIC", "confidence": 0.9944696426391602}]}, {"text": "Adding linguistically richer input representations pushes the margin even higher, allowing us to beat it by 1.9% labeled F1.", "labels": [], "entities": [{"text": "F1", "start_pos": 121, "end_pos": 123, "type": "METRIC", "confidence": 0.9899985194206238}]}], "introductionContent": [{"text": "Syntactic dependency parsing is arguably the most popular method for automatically extracting the low-level relationships between words in a sentence for use in natural language understanding tasks.", "labels": [], "entities": [{"text": "Syntactic dependency parsing", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.896323581536611}, {"text": "automatically extracting the low-level relationships between words in a sentence", "start_pos": 69, "end_pos": 149, "type": "TASK", "confidence": 0.7611017286777496}, {"text": "natural language understanding tasks", "start_pos": 161, "end_pos": 197, "type": "TASK", "confidence": 0.7110836431384087}]}, {"text": "However, typical syntactic dependency frameworks are limited in the number and types of relationships that can be captured.", "labels": [], "entities": []}, {"text": "For example, in the sentence Mary wants to buy a book, the word Mary is the subject of both want and buy-either or both relationships could be useful in a downstream task, but a tree-structured representation of this sentence (as in) can only represent one of them.", "labels": [], "entities": []}, {"text": "The 2014 SemEval shared task on BroadCoverage Semantic Dependency Parsing () introduced three new dependency representations that do away with the assumption of strict tree structure in favor of a richer graphstructured representation, allowing them to capture more linguistic information about a sentence.", "labels": [], "entities": [{"text": "SemEval shared task on BroadCoverage Semantic Dependency Parsing", "start_pos": 9, "end_pos": 73, "type": "TASK", "confidence": 0.7348798215389252}]}, {"text": "This opens up the possibility of providing more useful information to downstream tasks (, but increases the difficulty of automatically extracting that information, since most previous work on parsing has focused on generating trees.", "labels": [], "entities": []}, {"text": "Dozat and Manning (2017) developed a successful syntactic dependency parsing system with few task-specific sources of complexity.", "labels": [], "entities": [{"text": "syntactic dependency parsing", "start_pos": 48, "end_pos": 76, "type": "TASK", "confidence": 0.6203386584917704}]}, {"text": "In this paper, we extend that system so that it can train on and produce the graph-structured data of semantic dependency schemes.", "labels": [], "entities": []}, {"text": "We also consider straightforward extensions of the system that are likely to increase performance over the straightforward baseline, including giving the system access to lemma embeddings and building in a characterlevel word embedding model.", "labels": [], "entities": []}, {"text": "Finally, we briefly examine some of the design choices of that architecture, in order to assess which components are necessary for achieving the highest accuracy and which have little impact on final performance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 153, "end_pos": 161, "type": "METRIC", "confidence": 0.9971964359283447}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Comparison between our system and the previous state of the art on in-domain (WSJ) and  out-of-domain (Brown corpus) data, according to labeled F1 (LF1).", "labels": [], "entities": [{"text": "Brown corpus) data", "start_pos": 113, "end_pos": 131, "type": "DATASET", "confidence": 0.81008230894804}, {"text": "F1", "start_pos": 154, "end_pos": 156, "type": "METRIC", "confidence": 0.9732975363731384}]}, {"text": " Table 2: Final hyperparameter configuration.", "labels": [], "entities": []}]}