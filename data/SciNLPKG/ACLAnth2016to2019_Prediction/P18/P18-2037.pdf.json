{"title": [{"text": "Filtering and Mining Parallel Data in a Joint Multilingual Space", "labels": [], "entities": []}], "abstractContent": [{"text": "We learn a joint multilingual sentence embedding and use the distance between sentences in different languages to filter noisy parallel data and to mine for parallel data in large news collections.", "labels": [], "entities": []}, {"text": "We are able to improve a competitive baseline on the WMT'14 English to German task by 0.3 BLEU by filtering out 25% of the training data.", "labels": [], "entities": [{"text": "WMT'14 English to German task", "start_pos": 53, "end_pos": 82, "type": "DATASET", "confidence": 0.7629403471946716}, {"text": "BLEU", "start_pos": 90, "end_pos": 94, "type": "METRIC", "confidence": 0.999512791633606}]}, {"text": "The same approach is used to mine additional bitexts for the WMT'14 system and to obtain competitive results on the BUCC shared task to identify parallel sentences in comparable corpora.", "labels": [], "entities": [{"text": "WMT'14 system", "start_pos": 61, "end_pos": 74, "type": "DATASET", "confidence": 0.7899358570575714}, {"text": "BUCC shared task", "start_pos": 116, "end_pos": 132, "type": "DATASET", "confidence": 0.8498080770174662}]}, {"text": "The approach is generic, it can be applied to many language pairs and it is independent of the architecture of the machine translation system.", "labels": [], "entities": []}], "introductionContent": [{"text": "Parallel data, also called bitexts, is an important resource to train neural machine translation systems (NMT).", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 70, "end_pos": 96, "type": "TASK", "confidence": 0.7670091986656189}]}, {"text": "It is usually assumed that the quality of the automatic translations increases with the amount of available training data.", "labels": [], "entities": []}, {"text": "However, it was observed that NMT systems are more sensitive to noise than SMT systems, e.g. (. Well known sources of parallel data are international organizations like the European Parliament or the United Nations, or community provided translations like the TED talks.", "labels": [], "entities": [{"text": "SMT", "start_pos": 75, "end_pos": 78, "type": "TASK", "confidence": 0.9761974215507507}]}, {"text": "In addition, there are many texts on the Internet which are potential mutual translations, but which need to be identified and aligned.", "labels": [], "entities": []}, {"text": "Typical examples are Wikipedia or news collections which report on the same facts in different languages.", "labels": [], "entities": []}, {"text": "These collections are usually called comparable corpora.", "labels": [], "entities": []}, {"text": "In this paper we propose an unified approach to filter noisy bitexts and to mine bitexts in huge monolingual texts.", "labels": [], "entities": []}, {"text": "The main idea is to first learn a joint multilingual sentence embedding.", "labels": [], "entities": []}, {"text": "Then, a threshold on the distance between two sentences in this joint embedding space can be used to filter bitexts (distance between source and target sentences), or to mine for additional bitexts (pairwise distances between all source and target sentences).", "labels": [], "entities": []}, {"text": "No additional features or classifiers are needed.", "labels": [], "entities": []}], "datasetContent": [{"text": "Since 2017, the workshop on Building and Using Comparable Corpora (BUCC) is organizing a shared task to evaluate the performance of approaches to mine for parallel sentences in comparable corpora (.", "labels": [], "entities": []}, {"text": "summarizes the available data, and the official results.", "labels": [], "entities": []}, {"text": "Roughly a 40th of the sentences are aligned.", "labels": [], "entities": []}, {"text": "The best performing system \"VIC\" is based on the so-called STACC method which was shown to achieve state-of-the-art performance.", "labels": [], "entities": [{"text": "VIC", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.9323006272315979}]}, {"text": "It combines probabilistic dictionaries, search for similar sentences in both directions and a decision module which explores various features (common word prefixes, numbers, capitalized true-case tokens, etc).", "labels": [], "entities": []}, {"text": "This STACC system was improved and adapted to the BUCC tasks with a word weighting scheme which is optimized on the monolingual corpora, and a named entity penalty.", "labels": [], "entities": [{"text": "BUCC", "start_pos": 50, "end_pos": 54, "type": "DATASET", "confidence": 0.7352700233459473}, {"text": "word weighting", "start_pos": 68, "end_pos": 82, "type": "TASK", "confidence": 0.7221896946430206}]}, {"text": "This task adaption substantially improved the generic STACC approach ().", "labels": [], "entities": [{"text": "STACC", "start_pos": 54, "end_pos": 59, "type": "TASK", "confidence": 0.8043695092201233}]}, {"text": "The systems RALI (Gr\u00e9goire and Langlais, 2017) and H2 (Bouamor and Sajjad, 2018) have been already described in section 2.", "labels": [], "entities": [{"text": "RALI", "start_pos": 12, "end_pos": 16, "type": "METRIC", "confidence": 0.8442718386650085}]}, {"text": "NLP2CT uses a denoising auto-encoder and a maximum-entropy classifier ().", "labels": [], "entities": [{"text": "NLP2CT", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9400795698165894}]}, {"text": "We applied our approach to all language pairs of the BUCC shared task (see System en-fr en-de en-ru en-zh18 ---56 embeddings from (Schwenk and Douze, 2017) for ru and zh, which were trained on the UN corpus.", "labels": [], "entities": [{"text": "BUCC shared task", "start_pos": 53, "end_pos": 69, "type": "DATASET", "confidence": 0.8254944284756979}, {"text": "UN corpus", "start_pos": 197, "end_pos": 206, "type": "DATASET", "confidence": 0.9132096469402313}]}, {"text": "The only task-specific adaptation is the optimization of the threshold on the distance in the multilingual joint space.", "labels": [], "entities": []}, {"text": "Our system does not match the performance of the heavily tuned VIC system, but it is on-pair with H2 on en-fr, and outperforms all other approaches by a large margin.", "labels": [], "entities": []}, {"text": "We would like to emphasize that our approach uses no additional features or classifiers, and that we apply the same approach to all language pairs.", "labels": [], "entities": []}, {"text": "It is nice to see that the performance varies little for the languages.", "labels": [], "entities": []}, {"text": "Espa\u00f1a-Bonet et al. have also evaluated their technique on the BUCC data, but results on the official test set are not provided.", "labels": [], "entities": [{"text": "BUCC data", "start_pos": 63, "end_pos": 72, "type": "DATASET", "confidence": 0.9721972644329071}]}, {"text": "Also, their joint encoder uses the \"news-commentary\" corpus during training.", "labels": [], "entities": []}, {"text": "This is likely to add an important bias since all the parallel sentences in the BUCC corpus are from the news-commentary corpus.", "labels": [], "entities": [{"text": "BUCC corpus", "start_pos": 80, "end_pos": 91, "type": "DATASET", "confidence": 0.9847511053085327}]}, {"text": "Since we learn multilingual embeddings for many languages in one joint space, we can mine for parallel data for any language pair.", "labels": [], "entities": []}, {"text": "As an example, we have mined for French/German and Chinese/Russian bitexts, respectively.", "labels": [], "entities": []}, {"text": "There are no reference alignments to optimize the threshold for this language pair.", "labels": [], "entities": []}, {"text": "Based on the experiments with the other languages, we chose a value of 0.55.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: BUCC evaluation to mine bitexts. Num- ber of sentences and size of the gold alignments.", "labels": [], "entities": [{"text": "BUCC", "start_pos": 10, "end_pos": 14, "type": "DATASET", "confidence": 0.445932537317276}, {"text": "Num- ber", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9639099637667338}]}, {"text": " Table 3: Results on the BUCC test set of our ap- proach: Precision, Recall and F-measure (%). We  also provide the optimal threshold.", "labels": [], "entities": [{"text": "BUCC test set", "start_pos": 25, "end_pos": 38, "type": "DATASET", "confidence": 0.8933344483375549}, {"text": "Precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9992682337760925}, {"text": "Recall", "start_pos": 69, "end_pos": 75, "type": "METRIC", "confidence": 0.996780514717102}, {"text": "F-measure", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.9987518787384033}]}, {"text": " Table 4: Our baseline results on WMT'14 en-de.", "labels": [], "entities": [{"text": "WMT'14 en-de", "start_pos": 34, "end_pos": 46, "type": "DATASET", "confidence": 0.8931211829185486}]}, {"text": " Table 6: BLEU scores when training on the mined  data only, adding it (at different thresholds) to the  human translated training corpus (Eparl+NC) and  to our best system using filtered Common Crawl.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9986211061477661}]}]}