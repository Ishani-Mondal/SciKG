{"title": [{"text": "Target-Sensitive Memory Networks for Aspect Sentiment Classification", "labels": [], "entities": [{"text": "Aspect Sentiment Classification", "start_pos": 37, "end_pos": 68, "type": "TASK", "confidence": 0.903393010298411}]}], "abstractContent": [{"text": "Aspect sentiment classification (ASC) is a fundamental task in sentiment analysis.", "labels": [], "entities": [{"text": "Aspect sentiment classification (ASC)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.9186107218265533}, {"text": "sentiment analysis", "start_pos": 63, "end_pos": 81, "type": "TASK", "confidence": 0.9500036835670471}]}, {"text": "Given an aspect/target and a sentence, the task classifies the sentiment polarity expressed on the target in the sentence.", "labels": [], "entities": []}, {"text": "Memory networks (MNs) have been used for this task recently and have achieved state-of-the-art results.", "labels": [], "entities": []}, {"text": "In MNs, attention mechanism plays a crucial role in detecting the sentiment context for the given target.", "labels": [], "entities": [{"text": "MNs", "start_pos": 3, "end_pos": 6, "type": "TASK", "confidence": 0.969405472278595}]}, {"text": "However, we found an important problem with the current MNs in performing the ASC task.", "labels": [], "entities": [{"text": "ASC task", "start_pos": 78, "end_pos": 86, "type": "TASK", "confidence": 0.9430845379829407}]}, {"text": "Simply improving the attention mechanism will not solve it.", "labels": [], "entities": []}, {"text": "The problem is referred to as target-sensitive sentiment, which means that the sentiment polarity of the (detected) context is dependent on the given target and it cannot be inferred from the context alone.", "labels": [], "entities": []}, {"text": "To tackle this problem, we propose the target-sensitive memory networks (TMNs).", "labels": [], "entities": []}, {"text": "Several alternative techniques are designed for the implementation of TMNs and their effectiveness is experimentally evaluated.", "labels": [], "entities": []}], "introductionContent": [{"text": "Aspect sentiment classification (ASC) is a core problem of sentiment analysis.", "labels": [], "entities": [{"text": "Aspect sentiment classification (ASC)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.913755734761556}, {"text": "sentiment analysis", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.9462735950946808}]}, {"text": "Given an aspect and a sentence containing the aspect, ASC classifies the sentiment polarity expressed in the sentence about the aspect, namely, positive, neutral, or negative.", "labels": [], "entities": [{"text": "ASC", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.966424286365509}]}, {"text": "Aspects are also called opinion targets (or simply targets), which are usually product/service features in customer reviews.", "labels": [], "entities": []}, {"text": "In this paper, we use aspect and target interchangeably.", "labels": [], "entities": []}, {"text": "In practice, aspects can be specified by the user or extracted automatically using an aspect extraction technique.", "labels": [], "entities": [{"text": "aspect extraction", "start_pos": 86, "end_pos": 103, "type": "TASK", "confidence": 0.6913421601057053}]}, {"text": "In this work, we assume the aspect terms are given and only focus on the classification task.", "labels": [], "entities": [{"text": "classification task", "start_pos": 73, "end_pos": 92, "type": "TASK", "confidence": 0.89387646317482}]}, {"text": "Due to their impressive results in many NLP tasks), neural networks have been applied to ASC (see the survey ().", "labels": [], "entities": [{"text": "ASC", "start_pos": 89, "end_pos": 92, "type": "TASK", "confidence": 0.9883602857589722}]}, {"text": "Memory networks (MNs), a type of neural networks which were first proposed for question answering, have achieved the state-of-the-art results in ASC (.", "labels": [], "entities": [{"text": "question answering", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.8548443615436554}, {"text": "ASC", "start_pos": 145, "end_pos": 148, "type": "TASK", "confidence": 0.9609648585319519}]}, {"text": "A key factor for their success is the attention mechanism.", "labels": [], "entities": []}, {"text": "However, we found that using existing MNs to deal with ASC has an important problem and simply relying on attention modeling cannot solve it.", "labels": [], "entities": [{"text": "ASC", "start_pos": 55, "end_pos": 58, "type": "TASK", "confidence": 0.9665850400924683}]}, {"text": "That is, their performance degrades when the sentiment of a context word is sensitive to the given target.", "labels": [], "entities": []}, {"text": "Let us consider the following sentences: (1) The screen resolution is excellent but the price is ridiculous.", "labels": [], "entities": [{"text": "resolution", "start_pos": 56, "end_pos": 66, "type": "METRIC", "confidence": 0.7846459746360779}]}, {"text": "(2) The screen resolution is excellent but the price is high.", "labels": [], "entities": [{"text": "screen resolution", "start_pos": 8, "end_pos": 25, "type": "METRIC", "confidence": 0.7189764380455017}]}, {"text": "3) The price is high.", "labels": [], "entities": []}, {"text": "(4) The screen resolution is high.", "labels": [], "entities": [{"text": "screen", "start_pos": 8, "end_pos": 14, "type": "METRIC", "confidence": 0.9484341740608215}, {"text": "resolution", "start_pos": 15, "end_pos": 25, "type": "METRIC", "confidence": 0.5251074433326721}]}, {"text": "In sentence (1), the sentiment expressed on aspect screen resolution (or resolution for short) is positive, whereas the sentiment on aspect price is negative.", "labels": [], "entities": []}, {"text": "For the sake of predicting correct sentiment, a crucial step is to first detect the sentiment context about the given aspect/target.", "labels": [], "entities": [{"text": "predicting correct sentiment", "start_pos": 16, "end_pos": 44, "type": "TASK", "confidence": 0.8858988881111145}]}, {"text": "We call this step targeted-context detection.", "labels": [], "entities": [{"text": "targeted-context detection", "start_pos": 18, "end_pos": 44, "type": "TASK", "confidence": 0.7619438171386719}]}, {"text": "Memory networks (MNs) can deal with this step quite well because the sentiment context of a given aspect can be captured by the internal attention mechanism in MNs.", "labels": [], "entities": []}, {"text": "Concretely, in sentence (1) the word \"excellent\" can be identified as the sentiment context when resolution is specified.", "labels": [], "entities": []}, {"text": "Likewise, the context word \"ridiculous\" will be placed with a high attention when price is the target.", "labels": [], "entities": []}, {"text": "With the correct targeted-context detected, a trained MN, which recognizes \"excellent\" as positive sentiment and \"ridiculous\" as negative sentiment, will infer correct sentiment polarity for the given target.", "labels": [], "entities": []}, {"text": "This is relatively easy as \"excellent\" and \"ridiculous\" are both target-independent sentiment words, i.e., the words themselves already indicate clear sentiments.", "labels": [], "entities": []}, {"text": "As illustrated above, the attention mechanism addressing the targeted-context detection problem is very useful for ASC, and it helps classify many sentences like sentence (1) accurately.", "labels": [], "entities": [{"text": "targeted-context detection", "start_pos": 61, "end_pos": 87, "type": "TASK", "confidence": 0.7691577076911926}, {"text": "ASC", "start_pos": 115, "end_pos": 118, "type": "TASK", "confidence": 0.9922326803207397}]}, {"text": "This also led to existing and potential research in improving attention modeling (discussed in Section 5).", "labels": [], "entities": [{"text": "attention modeling", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.8279494345188141}]}, {"text": "However, we observed that simply focusing on tackling the target-context detection problem and learning better attention are not sufficient to solve the problem found in sentences (2), (3) and (4).", "labels": [], "entities": [{"text": "tackling the target-context detection problem", "start_pos": 45, "end_pos": 90, "type": "TASK", "confidence": 0.6996391534805297}]}, {"text": "Sentence is similar to sentence (1) except that the (sentiment) context modifying aspect/target price is \"high\".", "labels": [], "entities": []}, {"text": "In this case, when \"high\" is assigned the correct attention for the aspect price, the model also needs to capture the sentiment interaction between \"high\" and price in order to identify the correct sentiment polarity.", "labels": [], "entities": []}, {"text": "This is not as easy as sentence (1) because \"high\" itself indicates no clear sentiment.", "labels": [], "entities": []}, {"text": "Instead, its sentiment polarity is dependent on the given target.", "labels": [], "entities": []}, {"text": "Looking at sentences (3) and (4), we further seethe importance of this problem and also why relying on attention mechanism alone is insufficient.", "labels": [], "entities": []}, {"text": "In these two sentences, sentiment contexts are both \"high\" (i.e., same attention), but sentence (3) is negative and sentence (4) is positive simply because their target aspects are different.", "labels": [], "entities": []}, {"text": "Therefore, focusing on improving attention will not help in these cases.", "labels": [], "entities": []}, {"text": "We will give a theoretical insight about this problem with MNs in Section 3.", "labels": [], "entities": [{"text": "MNs", "start_pos": 59, "end_pos": 62, "type": "TASK", "confidence": 0.9505496025085449}]}, {"text": "In this work, we aim to solve this problem.", "labels": [], "entities": []}, {"text": "To distinguish it from the aforementioned targetedcontext detection problem as shown by sentence (1), we refer to the problem in (2), (3) and (4) as the target-sensitive sentiment (or target-dependent sentiment) problem, which means that the sentiment polarity of a detected/attended context word is conditioned on the target and cannot be directly inferred from the context word alone, unlike \"excellent\" and \"ridiculous\".", "labels": [], "entities": [{"text": "targetedcontext detection", "start_pos": 42, "end_pos": 67, "type": "TASK", "confidence": 0.7480504512786865}]}, {"text": "To address this problem, we propose target-sensitive memory networks (TMNs), which can capture the sentiment interaction between targets and contexts.", "labels": [], "entities": []}, {"text": "We present several approaches to implementing TMNs and experimentally evaluate their effectiveness.", "labels": [], "entities": []}], "datasetContent": [{"text": "We perform experiments on the datasets of SemEval Task 2014 (), which contain online reviews from domain Laptop and Restaurant.", "labels": [], "entities": [{"text": "SemEval Task 2014", "start_pos": 42, "end_pos": 59, "type": "TASK", "confidence": 0.702310303846995}]}, {"text": "In these datasets, aspect sentiment polarities are labeled.", "labels": [], "entities": []}, {"text": "The training and test sets have also been provided.", "labels": [], "entities": []}, {"text": "Full statistics of the datasets are given in  with a state-of-the-art attention-based LSTM for ASC, AE-LSTM (.", "labels": [], "entities": [{"text": "AE-LSTM", "start_pos": 100, "end_pos": 107, "type": "METRIC", "confidence": 0.9773917198181152}]}, {"text": "ATAE-LSTM: Another attention-based LSTM for ASC reported in (.", "labels": [], "entities": [{"text": "ATAE-LSTM", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.664326012134552}, {"text": "ASC", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.9710993766784668}]}, {"text": "Target-sensitive Memory Networks (TMNs): The six proposed techniques, NP, CNP, IT, CI, JCI, and JPI give six target-sensitive memory networks.", "labels": [], "entities": []}, {"text": "Note that other non-neural network based models like SVM and neural models without attention mechanism like traditional LSTMs have been compared and reported with inferior performance in the ASC task (), so they are excluded from comparisons here.", "labels": [], "entities": [{"text": "ASC task", "start_pos": 191, "end_pos": 199, "type": "TASK", "confidence": 0.8935030996799469}]}, {"text": "Also, note that non-neural models like SVMs require feature engineering to manually encode aspect information, while this work aims to improve the aspect representation learning based approaches.", "labels": [], "entities": []}, {"text": "Since we have a three-class classification task (positive, negative and neutral) and the classes are imbalanced as shown in, we use F1-score as our evaluation measure.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 132, "end_pos": 140, "type": "METRIC", "confidence": 0.9984115362167358}]}, {"text": "We report both F1-Macro overall classes and all individual classbased F1 scores.", "labels": [], "entities": [{"text": "F1-Macro", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9165205359458923}, {"text": "F1", "start_pos": 70, "end_pos": 72, "type": "METRIC", "confidence": 0.9851603507995605}]}, {"text": "As our problem requires finegrained sentiment interaction, the class-based F1 provides more indicative information.", "labels": [], "entities": []}, {"text": "In addition, we report the accuracy (same as F1-Micro), as it is used in previous studies.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.999815046787262}, {"text": "F1-Micro", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.973673403263092}]}, {"text": "However, we suggest using F1-score because accuracy biases towards the majority class.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.998696506023407}, {"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.999326229095459}]}], "tableCaptions": [{"text": " Table 2: Statistics of Datasets", "labels": [], "entities": [{"text": "Statistics of Datasets", "start_pos": 10, "end_pos": 32, "type": "DATASET", "confidence": 0.6749672293663025}]}, {"text": " Table 3: Results of all models on two datasets. Top three F1-Macro scores are marked in bold. The first  nine models are 1-hop memory networks. The last nine models are 3-hop memory networks.", "labels": [], "entities": [{"text": "F1-Macro", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9946562051773071}]}, {"text": " Table 4: Results with Recurrent Attention", "labels": [], "entities": [{"text": "Recurrent Attention", "start_pos": 23, "end_pos": 42, "type": "TASK", "confidence": 0.7444667816162109}]}, {"text": " Table 5: Sample Records and Model Comparison between MN and TMN", "labels": [], "entities": [{"text": "TMN", "start_pos": 61, "end_pos": 64, "type": "DATASET", "confidence": 0.36900392174720764}]}]}