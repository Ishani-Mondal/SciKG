{"title": [{"text": "Knowledge Diffusion for Neural Dialogue Generation", "labels": [], "entities": [{"text": "Knowledge Diffusion", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.6014075577259064}, {"text": "Neural Dialogue", "start_pos": 24, "end_pos": 39, "type": "TASK", "confidence": 0.7119800299406052}]}], "abstractContent": [{"text": "End-to-end neural dialogue generation has shown promising results recently, but it does not employ knowledge to guide the generation and hence tends to generate short, general, and meaningless responses.", "labels": [], "entities": [{"text": "End-to-end neural dialogue generation", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.7415216714143753}]}, {"text": "In this paper, we propose a neural knowledge diffusion (NKD) model to introduce knowledge into dialogue generation.", "labels": [], "entities": [{"text": "neural knowledge diffusion (NKD)", "start_pos": 28, "end_pos": 60, "type": "TASK", "confidence": 0.8127135038375854}, {"text": "dialogue generation", "start_pos": 95, "end_pos": 114, "type": "TASK", "confidence": 0.7604084610939026}]}, {"text": "This method cannot only match the relevant facts for the input utterance but diffuse them to similar entities.", "labels": [], "entities": []}, {"text": "With the help of facts matching and entity diffusion , the neural dialogue generation is augmented with the ability of convergent and divergent thinking over the knowledge base.", "labels": [], "entities": [{"text": "facts matching", "start_pos": 17, "end_pos": 31, "type": "TASK", "confidence": 0.7568491399288177}, {"text": "entity diffusion", "start_pos": 36, "end_pos": 52, "type": "TASK", "confidence": 0.7900483310222626}, {"text": "neural dialogue generation", "start_pos": 59, "end_pos": 85, "type": "TASK", "confidence": 0.7953815857569376}]}, {"text": "Our empirical study on a real-world dataset proves that our model is capable of generating meaningful, diverse and natural responses for both factoid-questions and knowledge grounded chi-chats.", "labels": [], "entities": []}, {"text": "The experiment results also show that our model outperforms competitive baseline models significantly.", "labels": [], "entities": []}], "introductionContent": [{"text": "Dialogue systems are receiving more and more attention in recent years.", "labels": [], "entities": []}, {"text": "Given previous utterances, a dialogue system aims to generate a proper response in a natural way.", "labels": [], "entities": []}, {"text": "Compared with the traditional pipeline based dialogue system, the new method based on sequence-to-sequence model () impressed the research communities with its elegant simplicity.", "labels": [], "entities": []}, {"text": "Such methods are usually in an end-to-end manner: utterances are encoded by a recurrent neural network * Work done when the first author was an intern at Data Science Lab, JD.com.", "labels": [], "entities": [{"text": "JD.com", "start_pos": 172, "end_pos": 178, "type": "DATASET", "confidence": 0.8964225053787231}]}, {"text": "while responses are generated sequentially by another (sometimes identical) recurrent neural network.", "labels": [], "entities": []}, {"text": "However, due to lack of universal background knowledge and common senses, the endto-end data-driven structure inherently tends to generate meaningless and short responses, such as \"haha\" or \"I don't know.\"", "labels": [], "entities": []}, {"text": "To bridge the gap of the common knowledge between human and computers, different kinds of knowledge bases ( e.g., the freebase (Google, 2013) and DBpedia ( ) are leveraged.", "labels": [], "entities": []}, {"text": "A related application of knowledge bases is question answering, where the given questions are first analyzed, followed by retrieving related facts from knowledge bases (KBs), and finally the answers are generated.The facts are usually presented in the form of \"subject-relationobject\" triplets, where the subject and object are entities.", "labels": [], "entities": [{"text": "question answering", "start_pos": 44, "end_pos": 62, "type": "TASK", "confidence": 0.8048156499862671}]}, {"text": "With the aid of knowledge triplets, neural generative question answering systems are capable of answering facts related inquiries (), WH questions in particular, like \"who is Yao Ming's wife ?\".", "labels": [], "entities": [{"text": "neural generative question answering", "start_pos": 36, "end_pos": 72, "type": "TASK", "confidence": 0.784637063741684}]}, {"text": "Although answering enquiries is essential for dialogue systems, especially for task-oriented dialogue systems (, it is still far behind a natural knowledge grounded dialogue system, which should be able to understand the facts involved in current dialogue session (socalled facts matching), as well as diffuse them to other similar entities for knowledge-based chitchats (i.e. entity diffusion): 1) facts matching: in dialogue systems, matching utterances to exact facts is much harder than explicit factoid inquiries answering.", "labels": [], "entities": [{"text": "answering enquiries", "start_pos": 9, "end_pos": 28, "type": "TASK", "confidence": 0.875075489282608}, {"text": "entity diffusion", "start_pos": 377, "end_pos": 393, "type": "TASK", "confidence": 0.7285774648189545}, {"text": "facts matching", "start_pos": 399, "end_pos": 413, "type": "TASK", "confidence": 0.7369478046894073}]}, {"text": "Though some utterances are facts related inquiries, whose subjects and relations can be easily recognized, for some utterances, the subjects and relations are elusive, which leads the trouble inexact facts matching.: Examples of knowledge grounded conversations.", "labels": [], "entities": []}, {"text": "shows an example: Item 1 and 2 are talking about the film \"Titanic\", Unlike item 1, which is atypical question answering conversation,item 2 is a knowledge related chit-chat without any explicit relation.", "labels": [], "entities": []}, {"text": "It is difficult to define the exact fact match for item 2. 2) entity diffusion: another noticeable phenomenon is that the conversation usually drifts from one entity to another.", "labels": [], "entities": [{"text": "entity diffusion", "start_pos": 62, "end_pos": 78, "type": "TASK", "confidence": 0.7473586797714233}]}, {"text": "In, utterances in item 3 and 4 are about entity \"Titanic\", however, the entity of responses are other similar films.", "labels": [], "entities": []}, {"text": "Such entity diffusion relations are rarely captured by the current knowledge triplets.", "labels": [], "entities": [{"text": "entity diffusion", "start_pos": 5, "end_pos": 21, "type": "TASK", "confidence": 0.7471274137496948}]}, {"text": "The response in item 3 shows that the two entities \"Titanic\" and \"Waterloo Bridge\" are relevant through \"love stories\".", "labels": [], "entities": [{"text": "Waterloo Bridge", "start_pos": 66, "end_pos": 81, "type": "DATASET", "confidence": 0.9670503735542297}]}, {"text": "Item 4 suggests another similar shipwreck film of \"Titanic\".", "labels": [], "entities": [{"text": "Item 4", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9241129755973816}]}, {"text": "To deal with the aforementioned challenges, in this paper, we propose a neural knowledge diffusion (NKD) dialogue system to benefit the neural dialogue generation with the ability of both convergent and divergent thinking over the knowledge base, and handle factoid QA and knowledge grounded chit-chats simultaneously.", "labels": [], "entities": [{"text": "neural knowledge diffusion (NKD) dialogue", "start_pos": 72, "end_pos": 113, "type": "TASK", "confidence": 0.7881893515586853}, {"text": "neural dialogue generation", "start_pos": 136, "end_pos": 162, "type": "TASK", "confidence": 0.7847645282745361}]}, {"text": "NKD learns to match utterances to relevant facts; the matched facts are then diffused to similar entities; and finally, the model generates the responses with respect to all the retrieved knowledge items.", "labels": [], "entities": []}, {"text": "In general, our contributions are as follows: \u2022 We identify the problem of incorporating knowledge bases and dialogue systems as facts matching and entity diffusion.", "labels": [], "entities": [{"text": "facts matching", "start_pos": 129, "end_pos": 143, "type": "TASK", "confidence": 0.7181996405124664}, {"text": "entity diffusion", "start_pos": 148, "end_pos": 164, "type": "TASK", "confidence": 0.7558435499668121}]}, {"text": "\u2022 We manage both facts matching and entity diffusion by introducing a novel knowledge diffusion mechanism and generate the responses with the retrieved knowledge items, which enable the convergent and divergent thinking over the knowledge base.", "labels": [], "entities": [{"text": "facts matching", "start_pos": 17, "end_pos": 31, "type": "TASK", "confidence": 0.737162858247757}, {"text": "entity diffusion", "start_pos": 36, "end_pos": 52, "type": "TASK", "confidence": 0.7586270868778229}, {"text": "knowledge diffusion", "start_pos": 76, "end_pos": 95, "type": "TASK", "confidence": 0.7470735013484955}]}, {"text": "\u2022 The experimental results show that the proposed model effectively generate more diverse and meaningful responses involving more accurate relevant entities compared with the state-of-the-art baselines.", "labels": [], "entities": []}, {"text": "The corpus will be released upon publication.", "labels": [], "entities": []}, {"text": "Given the input utterance X = (x 1 , x 2 , ..., x N X ), NKD produces a response Y = (y 1 , y 2 , ..., y NY ) containing the entities from the knowledge base K.", "labels": [], "entities": []}, {"text": "N X and NY are the number of tokens in the utterance and response respectively.", "labels": [], "entities": [{"text": "NY", "start_pos": 8, "end_pos": 10, "type": "METRIC", "confidence": 0.9399247765541077}]}, {"text": "The knowledge base K is a collection of knowledge facts in the form of triplets (subject, relation, object).", "labels": [], "entities": []}, {"text": "In particular, both subjects and objects are entities in this work.", "labels": [], "entities": []}, {"text": "As illustrated in, the model mainly consists of four components:", "labels": [], "entities": []}], "datasetContent": [{"text": "Most existing knowledge related datasets are mainly focused on single-turn factoid question answering (.", "labels": [], "entities": [{"text": "single-turn factoid question answering", "start_pos": 63, "end_pos": 101, "type": "TASK", "confidence": 0.6115084141492844}]}, {"text": "We here collect a multi-turn conversation corpus grounded on the knowledge base, which includes not only facts related inquiries but also knowledge-based chit-chats.", "labels": [], "entities": []}, {"text": "The data is publicly available online 1 . We first obtain the element information of each movie, including the movie's title, publication time, directors, actors and other attributes from https://movie.douban.com/, a popular Chinese social network for movies.", "labels": [], "entities": []}, {"text": "Then, entities and relations are extracted as triplets to build the knowledge base K.", "labels": [], "entities": []}, {"text": "To collect the question-answering dialogues, we crawled the corpus from a question-answering forum https://zhidao.baidu.com/.", "labels": [], "entities": []}, {"text": "To gather the knowledge related chit-chat corpus, we mined the dataset from the social forum https://www.douban.com/group/.", "labels": [], "entities": []}, {"text": "Users post their comments, feedbacks, and impressions of films and televisions on it.", "labels": [], "entities": []}, {"text": "The conversations are grounded on the knowledge using NER, string match, and artificial scoring and filtering rules.", "labels": [], "entities": []}, {"text": "The statistical information of the dataset is shown in.", "labels": [], "entities": []}, {"text": "We observed that the conversations follow the long tail distribution, where famous films and televisions are discussed repeatedly and the low rating ones are rarely mentioned.", "labels": [], "entities": []}, {"text": "The total 32977 conversations consisting of 104567 utterances are divided into training (32177) and testing set (800).", "labels": [], "entities": []}, {"text": "Bi-directional LSTM  layer is set to 512.", "labels": [], "entities": []}, {"text": "For the context RNN, the dimension of the LSTM unit is set to 1024.", "labels": [], "entities": [{"text": "RNN", "start_pos": 16, "end_pos": 19, "type": "DATASET", "confidence": 0.8396106362342834}]}, {"text": "The dimension of word embedding shared by the vocabulary, entities and relations is also set to 512 empirically.", "labels": [], "entities": []}, {"text": "We use Adam learning) to update the gradient and clip the gradient in 5.0.", "labels": [], "entities": []}, {"text": "It takes 140 to 150 epochs to train the model with a batch size of 80.", "labels": [], "entities": []}, {"text": "All the NKD variants in generate more entities than GenDS.", "labels": [], "entities": [{"text": "GenDS", "start_pos": 52, "end_pos": 57, "type": "DATASET", "confidence": 0.9052848815917969}]}, {"text": "LSTM and HRED also produce a certain amount of entities, but are of low  accuracies and recalls.", "labels": [], "entities": [{"text": "LSTM", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7609798908233643}, {"text": "HRED", "start_pos": 9, "end_pos": 13, "type": "METRIC", "confidence": 0.5163853764533997}, {"text": "accuracies", "start_pos": 73, "end_pos": 83, "type": "METRIC", "confidence": 0.9757022857666016}, {"text": "recalls", "start_pos": 88, "end_pos": 95, "type": "METRIC", "confidence": 0.980176568031311}]}, {"text": "We also noticed that NKDgated achieves the highest accuracy and recall, but generates fewer entities compared with NKDori and NKD-gated, whereas NKD-atte generates more entities but also with relatively low accuracies and recalls.This demonstrates that NKDgated not only learns to generate more entities but also maintains the quality ( with a relatively high accuracy and recall ).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9986238479614258}, {"text": "recall", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.999188244342804}, {"text": "recalls.This", "start_pos": 222, "end_pos": 234, "type": "METRIC", "confidence": 0.9621421694755554}, {"text": "accuracy", "start_pos": 360, "end_pos": 368, "type": "METRIC", "confidence": 0.9972223043441772}, {"text": "recall", "start_pos": 373, "end_pos": 379, "type": "METRIC", "confidence": 0.9955236911773682}]}, {"text": "The results of human evaluation in also validate the superiority of the proposed model, especially on appropriateness.", "labels": [], "entities": []}, {"text": "Responses generated by LSTM and HRED are of high fluency, but are simply repetitions, or even dull responses as \"I don't know.\", \"Good.\".", "labels": [], "entities": []}, {"text": "NKD-gated is more adept at incorporating the knowledge base with respect to appropriateness and correctness, while NKDatte generates more fluent responses.", "labels": [], "entities": [{"text": "NKD-gated", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9383686184883118}]}, {"text": "NKD-ori is a compromise, and obtains the best correctness in completing an entire dialogue.", "labels": [], "entities": [{"text": "NKD-ori", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8662028312683105}]}, {"text": "Four evaluators rated the scores independently.", "labels": [], "entities": []}, {"text": "The pairwise Cohen's Kappa agreement scores are 0.67 on fluency, 0.54 on appropriateness, and 0.60 on entire correctness, which indicate a strong annotator agreement.", "labels": [], "entities": []}, {"text": "To our surprise, one of the variant model of NKD, which utilized both probabilistic gated decoder and coefficient attenuation tracker does not perform well on entire dataset.", "labels": [], "entities": [{"text": "NKD", "start_pos": 45, "end_pos": 48, "type": "DATASET", "confidence": 0.8809587359428406}]}, {"text": "The accuracy of the model is quite high, but the recall is very low compared to others.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9996563196182251}, {"text": "recall", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.9997461438179016}]}, {"text": "We speculate that this is due to the method of minimizing negative log-likelihood during the training process, which makes the model tend to generate completely correct answers, and therefore reduces the number of generated entities.", "labels": [], "entities": []}, {"text": "shows typical examples of the generated responses.", "labels": [], "entities": []}, {"text": "Both Item 1 and 2 are based on facts relevant utterances.", "labels": [], "entities": []}, {"text": "NKD handles these questions by facts matching.", "labels": [], "entities": [{"text": "NKD", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8225751519203186}, {"text": "facts matching", "start_pos": 31, "end_pos": 45, "type": "TASK", "confidence": 0.7118475437164307}]}, {"text": "Item 3 asks fora recommendation.", "labels": [], "entities": []}, {"text": "NKD obtains similar entities by diffusing the entities.", "labels": [], "entities": [{"text": "NKD", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8525038361549377}]}, {"text": "For item 4, 5 and 6, no explicit entity appears in the utterances.", "labels": [], "entities": []}, {"text": "NKD is able to output appropriate recommendations through entity diffusion.", "labels": [], "entities": [{"text": "NKD", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9193758964538574}, {"text": "entity diffusion", "start_pos": 58, "end_pos": 74, "type": "TASK", "confidence": 0.7207998186349869}]}, {"text": "The entities are recorded during the whole dialogue session, so NKD keeps recommending for several turns.", "labels": [], "entities": [{"text": "NKD", "start_pos": 64, "end_pos": 67, "type": "DATASET", "confidence": 0.9033586978912354}]}, {"text": "Item 7 fails to generate an appropriate response because the entity in the golden response does not appear in the training set, which suggests the future work for out-ofvocabulary cases.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Statistics of knowledge base and conversations.", "labels": [], "entities": []}, {"text": " Table 3: Evaluation results on factoid question  answering dialogues.", "labels": [], "entities": [{"text": "factoid question  answering dialogues", "start_pos": 32, "end_pos": 69, "type": "TASK", "confidence": 0.8320196717977524}]}, {"text": " Table 4: Evaluation results on entire dataset.", "labels": [], "entities": []}, {"text": " Table 5: Human evaluation result.", "labels": [], "entities": []}]}