{"title": [], "abstractContent": [{"text": "Small perturbations in the input can severely distort intermediate representations and thus impact translation quality of neural machine translation (NMT) models.", "labels": [], "entities": []}, {"text": "In this paper, we propose to improve the robustness of NMT models with adver-sarial stability training.", "labels": [], "entities": []}, {"text": "The basic idea is to make both the encoder and decoder in NMT models robust against input perturbations by enabling them to behave similarly for the original input and its perturbed counterpart.", "labels": [], "entities": []}, {"text": "Experimental results on Chinese-English, English-German and English-French translation tasks show that our approaches cannot only achieve significant improvements over strong NMT systems but also improve the robustness of NMT models.", "labels": [], "entities": [{"text": "English-French translation tasks", "start_pos": 60, "end_pos": 92, "type": "TASK", "confidence": 0.7890966931978861}]}], "introductionContent": [{"text": "Neural machine translation (NMT) models have advanced the state of the art by building a single neural network that can better learn representations ().", "labels": [], "entities": [{"text": "Neural machine translation (NMT)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7711383799711863}]}, {"text": "The neural network consists of two components: an encoder network that encodes the input sentence into a sequence of distributed representations, based on which a decoder network generates the translation with an attention model (.", "labels": [], "entities": []}, {"text": "A variety of NMT models derived from this encoder-decoder framework have further improved the performance of machine translation systems (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 109, "end_pos": 128, "type": "TASK", "confidence": 0.789271742105484}]}, {"text": "NMT is capable of generalizing better to unseen text by exploiting word similarities in embeddings and capturing long-distance reordering by conditioning on larger contexts in a continuous way.", "labels": [], "entities": [{"text": "NMT", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7926071286201477}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Case-insensitive BLEU scores on Chinese-English translation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 27, "end_pos": 31, "type": "METRIC", "confidence": 0.9368419051170349}]}, {"text": " Table 3: Case-sensitive BLEU scores on WMT 14 English-German translation.", "labels": [], "entities": [{"text": "Case-sensitive", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.8737629055976868}, {"text": "BLEU", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9040547013282776}, {"text": "WMT 14 English-German translation", "start_pos": 40, "end_pos": 73, "type": "DATASET", "confidence": 0.8348866105079651}]}, {"text": " Table 4: Case-sensitive BLEU scores on IWSLT  English-French translation.", "labels": [], "entities": [{"text": "Case-sensitive", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.8996862769126892}, {"text": "BLEU", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9090228080749512}, {"text": "IWSLT  English-French translation", "start_pos": 40, "end_pos": 73, "type": "DATASET", "confidence": 0.8511085311571757}]}, {"text": " Table 5: Translation results of synthetic perturbations on the validation set in Chinese-English translation.  \"1 Op.\" denotes that we conduct one operation (swap, replacement or deletion) on the original sentence.", "labels": [], "entities": []}]}