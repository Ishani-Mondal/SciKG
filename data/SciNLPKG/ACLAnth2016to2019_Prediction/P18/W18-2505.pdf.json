{"title": [{"text": "The risk of sub-optimal use of Open Source NLP Software: UKB is inadvertently state-of-the-art in knowledge-based WSD", "labels": [], "entities": [{"text": "UKB", "start_pos": 57, "end_pos": 60, "type": "DATASET", "confidence": 0.9372296929359436}, {"text": "WSD", "start_pos": 114, "end_pos": 117, "type": "TASK", "confidence": 0.7080910205841064}]}], "abstractContent": [{"text": "UKB is an open source collection of programs for performing, among other tasks, knowledge-based Word Sense Dis-ambiguation (WSD).", "labels": [], "entities": [{"text": "UKB", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9824584126472473}, {"text": "Word Sense Dis-ambiguation (WSD)", "start_pos": 96, "end_pos": 128, "type": "TASK", "confidence": 0.6777678479750952}]}, {"text": "Since it was released in 2009 it has been often used out-of-the-box in sub-optimal settings.", "labels": [], "entities": []}, {"text": "We show that nine years later it is the state-of-the-art on knowledge-based WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 76, "end_pos": 79, "type": "TASK", "confidence": 0.8155169486999512}]}, {"text": "This case shows the pitfalls of releasing open source NLP software without optimal default settings and precise reproducibility instructions.", "labels": [], "entities": []}], "introductionContent": [{"text": "The release of open-source Natural Language Processing (NLP) software has been key to make the field progress, as it facilitates other researchers to build upon previous results and software easily.", "labels": [], "entities": []}, {"text": "It also allows easier reproducibility, allowing for sound scientific progress.", "labels": [], "entities": []}, {"text": "Unfortunately, in some cases, it can also allow competing systems to run the open-source software out-of-the-box with suboptimal parameters, specially in fields where there is no standard benchmark and new benchmarks (or new versions of older benchmarks) are created.", "labels": [], "entities": []}, {"text": "Once a paper reports sub-optimal results fora NLP software, newer papers can start to routinely quote the low results from the previous study.", "labels": [], "entities": []}, {"text": "Finding a fix to this situation is not easy.", "labels": [], "entities": []}, {"text": "The authors of the software can contact the authors of the more recent papers, but it is usually too late for updating the paper.", "labels": [], "entities": []}, {"text": "Alternatively, the authors of the NLP software can try to publish anew paper with updated results, but there is usually no venue for such a paper, and, even if published, it might not be noticed in the field.", "labels": [], "entities": []}, {"text": "In this paper we want to report such a casein Word Sense Disambiguation (WSD), where the original software (UKB) was released with suboptimal default parameters.", "labels": [], "entities": [{"text": "casein Word Sense Disambiguation (WSD)", "start_pos": 39, "end_pos": 77, "type": "TASK", "confidence": 0.6275362031800407}, {"text": "UKB)", "start_pos": 108, "end_pos": 112, "type": "DATASET", "confidence": 0.937824547290802}]}, {"text": "Although the accompanying papers did contain the necessary information to obtain state-of-the-art results, the software did not contain step-by-step instructions, or endto-end scripts for optimal performance.", "labels": [], "entities": []}, {"text": "This case is special, in that we realized that the software is able to attain state-of-the-art results also in newer datasets, using the same settings as in the papers.", "labels": [], "entities": []}, {"text": "The take-away message for open-source NLP software authors is that they should not rely on other researchers reading the papers with care, and that it is extremely important to include, with the software release, precise instructions and optimal default parameters, or better still, end-toend scripts that download all resources, perform any necessary pre-processing and reproduce the results.", "labels": [], "entities": []}, {"text": "The first section presents UKB and WSD, followed by the settings and parameters.", "labels": [], "entities": [{"text": "UKB", "start_pos": 27, "end_pos": 30, "type": "DATASET", "confidence": 0.8147044777870178}, {"text": "WSD", "start_pos": 35, "end_pos": 38, "type": "DATASET", "confidence": 0.43770402669906616}]}, {"text": "Next we present the results and comparison to the state-ofthe-art.", "labels": [], "entities": []}, {"text": "Section 5 reports some additional results, and finally, we draw the conclusions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: F1 results for knowledge-based systems on the (Raganato et al., 2017a) dataset. Top rows show  conflicting results for UKB.  \u2020 for results reported in (Raganato et al., 2017a),  \u2021 for results reported in  (Chaplot and Sakajhutdinov, 2018). Best results in bold. S2 stands for Senseval-2, S3 for Senseval-3,  S07 for Semeval-2007, S13 for Semeval-2013 and S15 for Semeval-2015.", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9980486631393433}, {"text": "UKB", "start_pos": 129, "end_pos": 132, "type": "DATASET", "confidence": 0.9606427550315857}]}, {"text": " Table 2: F1 results for supervised systems on the (Raganato et al., 2017a) dataset.  \u2020 for results reported  in (Raganato et al., 2017a). Best results in bold. Note that (Raganato et al., 2017b) used S07 for  development.", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9988511800765991}]}, {"text": " Table 3: Additional results on other settings of UKB. nf subscript stands for \"no sense frequency\". Top  rows use a single sentence as context, while the bottom rows correspond to extended context (cf. Sect.  3). Best results in bold.", "labels": [], "entities": [{"text": "UKB", "start_pos": 50, "end_pos": 53, "type": "DATASET", "confidence": 0.9843053221702576}]}]}