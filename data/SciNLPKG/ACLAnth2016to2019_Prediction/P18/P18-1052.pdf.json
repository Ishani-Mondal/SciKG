{"title": [{"text": "Coherence Modeling of Asynchronous Conversations: A Neural Entity Grid Approach", "labels": [], "entities": [{"text": "Coherence Modeling of Asynchronous Conversations", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.8305637121200562}]}], "abstractContent": [{"text": "We propose a novel coherence model for written asynchronous conversations (e.g., forums, emails), and show its applications in coherence assessment and thread reconstruction tasks.", "labels": [], "entities": [{"text": "coherence assessment", "start_pos": 127, "end_pos": 147, "type": "TASK", "confidence": 0.7202155888080597}, {"text": "thread reconstruction tasks", "start_pos": 152, "end_pos": 179, "type": "TASK", "confidence": 0.7732634643713633}]}, {"text": "We conduct our research in two steps.", "labels": [], "entities": []}, {"text": "First, we propose improvements to the recently proposed neural entity grid model by lexicalizing its entity transitions.", "labels": [], "entities": []}, {"text": "Then, we extend the model to asynchronous conversations by incorporating the underlying conversational structure in the entity grid representation and feature computation.", "labels": [], "entities": []}, {"text": "Our model achieves state of the art results on standard coherence assessment tasks in monologue and conversations outperforming existing models.", "labels": [], "entities": []}, {"text": "We also demonstrate its effectiveness in reconstructing thread structures.", "labels": [], "entities": [{"text": "reconstructing thread structures", "start_pos": 41, "end_pos": 73, "type": "TASK", "confidence": 0.838536540667216}]}], "introductionContent": [{"text": "Sentences in a text or a conversation do not occur independently, rather they are connected to form a coherent discourse that is easy to comprehend.", "labels": [], "entities": []}, {"text": "Coherence models are computational models that can distinguish a coherent discourse from incoherent ones.", "labels": [], "entities": []}, {"text": "It has ranges of applications in text generation, summarization, and coherence scoring.", "labels": [], "entities": [{"text": "text generation", "start_pos": 33, "end_pos": 48, "type": "TASK", "confidence": 0.8224692642688751}, {"text": "summarization", "start_pos": 50, "end_pos": 63, "type": "TASK", "confidence": 0.9891364574432373}, {"text": "coherence scoring", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.7861436009407043}]}, {"text": "Inspired by formal theories of discourse, a number of coherence models have been proposed (.", "labels": [], "entities": []}, {"text": "The entity grid model () is one of the most popular coherence models that has received much attention over the years.", "labels": [], "entities": []}, {"text": "As exemplified in, the model represents a text by a grid that captures how grammatical roles of different discourse entities (e.g., nouns) change from one sentence to  another in the text.", "labels": [], "entities": []}, {"text": "The grid is then converted into a feature vector containing probabilities of local entity transitions, enabling machine learning models to measure the degree of coherence.", "labels": [], "entities": []}, {"text": "Earlier extensions of this basic model incorporate entityspecific features, multiple ranks, and coherence relations.", "labels": [], "entities": []}, {"text": "Recently, proposed a neural version of the grid models.", "labels": [], "entities": []}, {"text": "Their model first transforms the grammatical roles in a grid into their distributed representations, and employs a convolution operation over it to model entity transitions in the distributed space.", "labels": [], "entities": []}, {"text": "The spatially maxpooled features from the convoluted features are used for coherence scoring.", "labels": [], "entities": [{"text": "coherence scoring", "start_pos": 75, "end_pos": 92, "type": "TASK", "confidence": 0.7720957100391388}]}, {"text": "This model achieves state-of-the-art results in standard evaluation tasks on the Wall Street Journal (WSJ) corpus.", "labels": [], "entities": [{"text": "Wall Street Journal (WSJ) corpus", "start_pos": 81, "end_pos": 113, "type": "DATASET", "confidence": 0.9538607171603611}]}, {"text": "Although the neural grid model effectively captures long entity transitions, it is still limited in that it does not consider any lexical information regarding the entities, thereby, fails to distinguish between entity types.", "labels": [], "entities": []}, {"text": "Although the extended neural grid considers entity features like named entity and proper mention, it requires an explicit feature extraction step, which can prevent us to transfer the model to a resource-poor language or domain.", "labels": [], "entities": []}, {"text": "Apart from these limitations, previous research on coherence models has mainly focused on monologic discourse (e.g., news article).", "labels": [], "entities": []}, {"text": "The only exception is the work of, who applied coherence models to the task of conversation disentanglement in synchronous conversations like phone and chat conversations.", "labels": [], "entities": [{"text": "conversation disentanglement", "start_pos": 79, "end_pos": 107, "type": "TASK", "confidence": 0.7092566192150116}]}, {"text": "With the emergence of Internet technologies, asynchronous communication media like emails, blogs, and forums have become a commonplace for discussing events and issues, seeking answers, and sharing personal experiences.", "labels": [], "entities": []}, {"text": "Participants in these media interact with each other asynchronously, by writing at different times.", "labels": [], "entities": []}, {"text": "We believe coherence models for asynchronous conversations can help many downstream applications in these domains.", "labels": [], "entities": []}, {"text": "For example, we will demonstrate later that coherence models can be used to predict the underlying thread structure of a conversation, which provides crucial information for building effective conversation summarization systems and community question answering systems (.", "labels": [], "entities": [{"text": "conversation summarization", "start_pos": 193, "end_pos": 219, "type": "TASK", "confidence": 0.6840932369232178}, {"text": "community question answering", "start_pos": 232, "end_pos": 260, "type": "TASK", "confidence": 0.6061182022094727}]}, {"text": "To the best of our knowledge, none has studied the problem of coherence modeling in asynchronous conversation before.", "labels": [], "entities": [{"text": "coherence modeling in asynchronous conversation", "start_pos": 62, "end_pos": 109, "type": "TASK", "confidence": 0.792404317855835}]}, {"text": "Because of its asynchronous nature, information flow in these conversations is often not sequential as in monologue or synchronous conversation.", "labels": [], "entities": []}, {"text": "This poses a novel set of challenges for discourse analysis models (.", "labels": [], "entities": []}, {"text": "For example, consider the forum conversation in.", "labels": [], "entities": []}, {"text": "It is not obvious how a coherence model like the entity grid can represent the conversation, and use it in downstream tasks effectively.", "labels": [], "entities": []}, {"text": "In this paper we aim to remedy the above limitations of existing models in two steps.", "labels": [], "entities": []}, {"text": "First, we propose improvements to the existing neural grid model by lexicalizing its entity transitions.", "labels": [], "entities": []}, {"text": "We propose methods based on word embeddings to achieve better generalization with the lexicalized model.", "labels": [], "entities": []}, {"text": "Second, we adapt the model to asynchronous conversations by incorporating the underlying conversational structure in the grid representation and subsequently in feature computation.", "labels": [], "entities": []}, {"text": "For this, we propose a novel grid representation for asynchronous conversations, and adapt the convolution layer of the neural model accordingly.", "labels": [], "entities": []}, {"text": "We evaluate our approach on two discrimination tasks.", "labels": [], "entities": []}, {"text": "The first task is the standard one, where we assess the models based on their performance in discriminating an original document from its random permutation.", "labels": [], "entities": []}, {"text": "In our second task, we ask the models to distinguish an original document from its inverse order of the sentences.", "labels": [], "entities": []}, {"text": "For our adapted model to asynchronous conversation, we also evaluate it on thread reconstruction, a task specific to asynchronous conversation.", "labels": [], "entities": [{"text": "thread reconstruction", "start_pos": 75, "end_pos": 96, "type": "TASK", "confidence": 0.6867972612380981}]}, {"text": "We performed a series of experiments, and our main findings are: (a) Our experiments on the WSJ corpus validate the utility of our proposed extension to the existing neural grid model, yielding absolute F 1 improvements of up to 4.2% in the standard task and up to 5.2% in the inverse-order discrimination task, setting anew state-of-the-art.", "labels": [], "entities": [{"text": "WSJ corpus", "start_pos": 92, "end_pos": 102, "type": "DATASET", "confidence": 0.9715712070465088}, {"text": "absolute F 1", "start_pos": 194, "end_pos": 206, "type": "METRIC", "confidence": 0.7916989326477051}, {"text": "inverse-order discrimination task", "start_pos": 277, "end_pos": 310, "type": "TASK", "confidence": 0.7153919736544291}]}, {"text": "(b) Our experiments on a forum dataset show that our adapted model that considers the conversational structure outperforms the temporal baseline by more than 4% F 1 in the standard task and by about 10% F 1 in the inverse order discrimination task.", "labels": [], "entities": [{"text": "F 1", "start_pos": 161, "end_pos": 164, "type": "METRIC", "confidence": 0.9727038145065308}, {"text": "F 1", "start_pos": 203, "end_pos": 206, "type": "METRIC", "confidence": 0.9758573770523071}, {"text": "inverse order discrimination task", "start_pos": 214, "end_pos": 247, "type": "TASK", "confidence": 0.6763251349329948}]}, {"text": "(c) When applied to the thread reconstruction task, our model achieves promising results outperforming several strong baselines.", "labels": [], "entities": [{"text": "thread reconstruction task", "start_pos": 24, "end_pos": 50, "type": "TASK", "confidence": 0.8465093374252319}]}, {"text": "We have released our source code and datasets at https://ntunlpsg.github.", "labels": [], "entities": []}, {"text": "io/project/coherence/n-coh-acl18/", "labels": [], "entities": []}], "datasetContent": [{"text": "To validate our proposed extension to the neural grid model, we first evaluate our lexicalized neural grid model in the standard evaluation setting.", "labels": [], "entities": []}, {"text": "Evaluation Tasks and Dataset: We evaluate our models on the standard discrimination task (, where a coherence model is asked to distinguish an original document from its incoherent renderings generated by random permutations of its sentences.", "labels": [], "entities": []}, {"text": "The model is considered correct if it ranks the original document higher than the permuted one.", "labels": [], "entities": []}, {"text": "We use the same train-test split of the WSJ dataset as used in) and other studies.", "labels": [], "entities": [{"text": "WSJ dataset", "start_pos": 40, "end_pos": 51, "type": "DATASET", "confidence": 0.9653567969799042}]}, {"text": "Following previous studies, we use 20 random permutations of each article for both training and testing, and exclude permutations that match the original article.", "labels": [], "entities": []}, {"text": "gives some statistics about the dataset along with the number of pairs used for training and testing.", "labels": [], "entities": []}, {"text": "randomly selected 10% of the training pairs for development purposes, which we also use for tuning hyperparameters in our models.", "labels": [], "entities": []}, {"text": "In addition to the standard setting, we also evaluate our models on an inverse-order setting, where we ask the models to distinguish an original document from the inverse order of its sentences (i.e., from last to first).", "labels": [], "entities": []}, {"text": "The transitions of roles in a negative grid are in the reverse order of the original grid.", "labels": [], "entities": []}, {"text": "We do not train our models explicitly on this task, rather use the trained model from the standard setting., which gave better results than using dropout.", "labels": [], "entities": []}, {"text": "Minibatch size, embedding size and filter number were fixed to 32, 300 and 150, respectively.", "labels": [], "entities": [{"text": "Minibatch size", "start_pos": 0, "end_pos": 14, "type": "METRIC", "confidence": 0.8434464931488037}]}, {"text": "We tuned for optimal filter and pooling lengths in {2, \u00b7 \u00b7 \u00b7 , 12}.", "labels": [], "entities": []}, {"text": "We train up to 25 epochs, and select the model that performs best on the development set; see supplementary documents for best hyperparameter settings for different models.", "labels": [], "entities": []}, {"text": "We run each experiment five times, each time with a different random seed, and we report the average of the runs to avoid any randomness in results.", "labels": [], "entities": []}, {"text": "Statistical significance tests are done using an approximate randomization test with SIGF V.2).", "labels": [], "entities": [{"text": "SIGF V.2", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.7580588757991791}]}, {"text": "Results and Discussions: We present our results on the standard discrimination task and the inverse-order task in; see Std (F 1 ) and Inv (F 1 ) columns, respectively.", "labels": [], "entities": [{"text": "Inv (F 1 )", "start_pos": 134, "end_pos": 144, "type": "METRIC", "confidence": 0.8842955708503724}]}, {"text": "For space limitations, we only show F 1 scores here, and report both accuracy and F 1 in the supplementary document.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 36, "end_pos": 46, "type": "METRIC", "confidence": 0.9829268455505371}, {"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.999772846698761}, {"text": "F 1", "start_pos": 82, "end_pos": 85, "type": "METRIC", "confidence": 0.9951174855232239}]}, {"text": "We compare our lexicalized models (group III) with the unlexicalized models (group II) of Nguyen and Joty (2017).", "labels": [], "entities": []}, {"text": "We also report the results of non-neural entity grid models) in group I.", "labels": [], "entities": []}, {"text": "The extended versions use entity-specific features.", "labels": [], "entities": []}, {"text": "We experimented with both random and pretrained initialization for word embeddings in our lexicalized models.", "labels": [], "entities": []}, {"text": "As can be noticed in Table 3, both versions give significant improvements over the unlexicalized models on both the standard and the inverse-order discrimination tasks (2.7 -4.3% absolute).", "labels": [], "entities": []}, {"text": "Our best model with Google pretrained embeddings () yields state-of-the-art results.", "labels": [], "entities": []}, {"text": "We also experimented  We evaluate our coherence models for asynchronous conversations on two tasks: discrimination and thread reconstruction.", "labels": [], "entities": [{"text": "thread reconstruction", "start_pos": 119, "end_pos": 140, "type": "TASK", "confidence": 0.6874458342790604}]}, {"text": "The discrimination tasks are applicable to conversations also.", "labels": [], "entities": []}, {"text": "We first present the dataset we use, then we describe how we create coherent and incoherent examples to train and test our models.", "labels": [], "entities": []}, {"text": "Dataset: Our conversational corpus contains discussion threads regarding computer troubleshooting from the technology related news site CNET.", "labels": [], "entities": []}, {"text": "This corpus was originally collected by, and it contains 13,352 threads.", "labels": [], "entities": []}, {"text": "For our experiments, we selected 3,825 threads assuring that each contains at least 3 and at most 15 posts.", "labels": [], "entities": []}, {"text": "We use 2,400 threads for training, 750 for testing and 675 for development purposes.", "labels": [], "entities": []}, {"text": "Model Settings and Training: To validate the efficacy of our conversational grid model, we compare it with the following baseline settings: \u2022 Temporal: In the temporal setting, we construct an entity grid from the chronological order of the sentences in a conversation, and use it with our monologue-based coherence models.", "labels": [], "entities": []}, {"text": "Models in this setting thus disregard the structure of the conversation and treat it as a monologue.", "labels": [], "entities": []}, {"text": "\u2022 Path-level: This is a special case of our model, where we consider each path (a column in our conversational grid) in the conversation tree separately.", "labels": [], "entities": []}, {"text": "We construct an entity grid fora path and provide as input to our monologue-based models.", "labels": [], "entities": []}, {"text": "To train the models with pairwise ranking, we create 20 incoherent conversations for each original conversation by shuffling the sentences in their temporal order.", "labels": [], "entities": []}, {"text": "For models involving conversation trees (path-level and our model), the tree structure remains unchanged for original and permuted conversations, only the position of the sentences vary based on the permutation.", "labels": [], "entities": []}, {"text": "Since the shuffling is done globally at the conversation level, this scheme allows us to compare the three representations (temporal, path-level and tree-level) fairly with the same set of permutations.", "labels": [], "entities": []}, {"text": "An incoherent conversation may have paths in the tree that match the original paths.", "labels": [], "entities": []}, {"text": "We remove those matched paths when training the path-level model.", "labels": [], "entities": []}, {"text": "See for number of pairs used for training and testing our models.", "labels": [], "entities": []}, {"text": "We evaluate pathlevel models by aggregating correct/wrong decisions for the paths -if the model makes more correct decisions for the original conversation than the incoherent one, it is counted as a correct decision overall.", "labels": [], "entities": []}, {"text": "Aggregating path-level coherence scores (e.g., by averaging or summing) would allow a coherence model to get awarded for assigning higher score to an original path (hence, correct) while making wrong decisions for the rest; see supplementary document for an example.", "labels": [], "entities": []}, {"text": "Similar to the setting in Monologue, we did not train explicitly on the inverse-order task, rather use the trained model from the standard setting.", "labels": [], "entities": []}, {"text": "One crucial advantage of our tree-level model over other models is that we can use it to build predictive models to uncover the thread structure of a conversation from its posts.", "labels": [], "entities": []}, {"text": "Consider again the thread in.", "labels": [], "entities": []}, {"text": "Our goal is to train a coherence model that can recover the tree structure in(b) from the sequence of posts (p 1 , p 2 , . .", "labels": [], "entities": []}, {"text": "This task has been addressed previously ().", "labels": [], "entities": []}, {"text": "Most methods learn an edgelevel classifier to decide fora possible link between two posts using features like distance in position/time, cosine similarity, etc.", "labels": [], "entities": []}, {"text": "To our knowledge, we are the first to use coherence models for this problem.", "labels": [], "entities": []}, {"text": "However, our goal in this paper is not to build a state-of-the-art system for thread reconstruction, rather to evaluate coherence models by showing its effectiveness in scoring candidate tree hypotheses.", "labels": [], "entities": [{"text": "thread reconstruction", "start_pos": 78, "end_pos": 99, "type": "TASK", "confidence": 0.7740112543106079}]}, {"text": "In contrast to previous methods, our approach therefore considers the whole thread structure at once, and computes coherence scores for all possible candidate trees of a conversation.", "labels": [], "entities": []}, {"text": "The tree that receives the highest score is predicted as the thread structure of the conversation.", "labels": [], "entities": []}, {"text": "Training: We train our coherence model for thread reconstruction using pairwise ranking loss as before.", "labels": [], "entities": [{"text": "thread reconstruction", "start_pos": 43, "end_pos": 64, "type": "TASK", "confidence": 0.7484578192234039}]}, {"text": "For a given sequence of comments in a thread, we construct a set of valid candidate trees; a valid tree is one that respects the chronological order of the comments, i.e., a comment can only reply to a comment that precedes it.", "labels": [], "entities": []}, {"text": "The training set contains ordered pairs (T i , T j ), where Ti is a true (gold) tree and T j is a valid but false tree.", "labels": [], "entities": []}, {"text": "Experiments: The number of valid trees grows exponentially with the number of posts in a thread, which makes the inference difficult.", "labels": [], "entities": []}, {"text": "As a proof of concept that coherence models are useful for finding the right tree, we built a simpler dataset by selecting forum threads from the CNET corpus ensuring that a thread contains at most 5 posts.", "labels": [], "entities": [{"text": "CNET corpus", "start_pos": 146, "end_pos": 157, "type": "DATASET", "confidence": 0.9502034187316895}]}, {"text": "The final dataset contains 1200 threads with an average of 3.8 posts and 27.64 sentences per thread.", "labels": [], "entities": []}, {"text": "We assess the performance of the models at two levels: (i) thread-level, where we evaluate if the model could identify the entire conversation thread correctly, and (ii) edge-level, where we evaluate if the model could identify individual replies correctly.", "labels": [], "entities": []}, {"text": "For comparison, we use a number of simple but well performing baselines: \u2022 All-previous creates thread structure by linking  a comment to its previous (in time) comment.", "labels": [], "entities": []}, {"text": "\u2022 All-first creates thread structure by linking all the comments to the initial comment.", "labels": [], "entities": []}, {"text": "\u2022 COS-sim creates thread structure by linking a comment to one of the previous comments with which it has the highest cosine similarity.", "labels": [], "entities": []}, {"text": "We use TF.IDF representation for the comments.", "labels": [], "entities": []}, {"text": "compares our best conversational grid model (tree-level with Google vectors) with the baselines.", "labels": [], "entities": []}, {"text": "The low thread-level accuracy across all the systems prove that reconstructing an entire tree is a difficult task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.8516420125961304}]}, {"text": "Models are reasonably accurate at the edge level.", "labels": [], "entities": []}, {"text": "Our coherence model shows promising results, yielding substantial improvements over the baselines.", "labels": [], "entities": []}, {"text": "It delivers 2.7% improvements in thread-level and 2.5% in edgelevel accuracy over the best baseline (COS-sim).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.913916289806366}, {"text": "COS-sim", "start_pos": 101, "end_pos": 108, "type": "METRIC", "confidence": 0.8550711274147034}]}, {"text": "Interestingly, our best model for this task uses a filter width of 2 (maximum can be 4 for 5 posts).", "labels": [], "entities": []}, {"text": "This indicates that spatial (left-to-right) relations between entity transitions are important to find the right thread structure of a conversation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Statistics on the WSJ dataset.", "labels": [], "entities": [{"text": "WSJ dataset", "start_pos": 28, "end_pos": 39, "type": "DATASET", "confidence": 0.9777645170688629}]}, {"text": " Table 3: Discrimination results on the WSJ  dataset. Superscript  \u2020 indicates a lexicalized  model is significantly superior to the unlexicalized  Neural Grid (N&J) model with p-value < 0.01.", "labels": [], "entities": [{"text": "WSJ  dataset", "start_pos": 40, "end_pos": 52, "type": "DATASET", "confidence": 0.9626769423484802}]}, {"text": " Table 4: Statistics on the CNET dataset.", "labels": [], "entities": [{"text": "CNET dataset", "start_pos": 28, "end_pos": 40, "type": "DATASET", "confidence": 0.9852552711963654}]}, {"text": " Table 5: Discrimination results on CNET. Super- script  \u2020 indicates a model is significantly superior  to its temporal counterpart with p-value < 0.01.", "labels": [], "entities": [{"text": "CNET", "start_pos": 36, "end_pos": 40, "type": "DATASET", "confidence": 0.9208468198776245}]}, {"text": " Table 6: Thread reconstruction results;  \u2020 indicates  significant difference from COS-sim (p< .01).", "labels": [], "entities": [{"text": "Thread", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9308297634124756}, {"text": "COS-sim", "start_pos": 83, "end_pos": 90, "type": "METRIC", "confidence": 0.4726034998893738}]}]}