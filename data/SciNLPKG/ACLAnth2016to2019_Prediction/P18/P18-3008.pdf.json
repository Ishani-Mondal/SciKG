{"title": [{"text": "Language Identification and Named Entity Recognition in Hinglish Code Mixed Tweets", "labels": [], "entities": [{"text": "Language Identification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6290462166070938}, {"text": "Named Entity Recognition", "start_pos": 28, "end_pos": 52, "type": "TASK", "confidence": 0.6263663470745087}, {"text": "Hinglish Code Mixed Tweets", "start_pos": 56, "end_pos": 82, "type": "DATASET", "confidence": 0.8683528453111649}]}], "abstractContent": [{"text": "While growing code-mixed content on Online Social Networks (OSNs) provides a fertile ground for studying various aspects of code-mixing, the lack of automated text analysis tools render such studies challenging.", "labels": [], "entities": []}, {"text": "To meet this challenge, a family of tools for analyzing code-mixed data such as language identifiers, parts-of-speech (POS) taggers, chunkers have been developed.", "labels": [], "entities": [{"text": "parts-of-speech (POS) taggers", "start_pos": 102, "end_pos": 131, "type": "TASK", "confidence": 0.6914271473884582}]}, {"text": "Named Entity Recognition (NER) is an important text analysis task which is not only informative by itself , but is also needed for downstream NLP tasks such as semantic role labeling.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.763523519039154}, {"text": "text analysis task", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.7934772968292236}, {"text": "semantic role labeling", "start_pos": 160, "end_pos": 182, "type": "TASK", "confidence": 0.6801435152689616}]}, {"text": "In this work, we present an exploration of automatic NER of code-mixed data.", "labels": [], "entities": [{"text": "NER", "start_pos": 53, "end_pos": 56, "type": "TASK", "confidence": 0.9550614953041077}]}, {"text": "We compare our method with existing off-the-shelf NER tools for social media content, and find that our systems outperforms the best baseline by 33.18 % (F 1 score).", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 154, "end_pos": 163, "type": "METRIC", "confidence": 0.9870436986287435}]}], "introductionContent": [{"text": "Code-switching or code-mixing occurs when \"lexical items and grammatical features from two languages appear in one sentence\").", "labels": [], "entities": []}, {"text": "1 It is frequently seen in multilingual communities and is of interest to linguists due to its complex relationship with societal factors.", "labels": [], "entities": []}, {"text": "With the rise of Web 2.0, the volume of text on online social networks (OSN) such as Twitter, Facebook, Reddit has grown.", "labels": [], "entities": []}, {"text": "It is estimated that around 240 Million Indian users, alone, are active on Twitter 2 . A significant fraction of these users are bilingual, or even trilingual, and their tweets can be monolingual in English or their vernacular, or code-mixed.", "labels": [], "entities": []}, {"text": "Past research has looked at multiple dimensions of this behaviour such as its relationship to emotion expression ( and identity.", "labels": [], "entities": []}, {"text": "Code-mixing or multilingualism of tweets poses a significant problem to both the OSNs' underlying text mining algorithms as well as researchers trying to study online discourse, since most existing tools for analyzing OSN text content caters to monolingual data.", "labels": [], "entities": [{"text": "OSNs' underlying text mining", "start_pos": 81, "end_pos": 109, "type": "TASK", "confidence": 0.6253691539168358}]}, {"text": "For example, Twitter's abuse detection systems fail to flag code-mixed tweets as offensive.", "labels": [], "entities": [{"text": "abuse detection", "start_pos": 23, "end_pos": 38, "type": "TASK", "confidence": 0.7311393320560455}]}, {"text": "Recent efforts to build tools for code-mixed content include language identifiers, partsof-speech(POS) taggers (), and chunking (.", "labels": [], "entities": [{"text": "partsof-speech(POS) taggers", "start_pos": 83, "end_pos": 110, "type": "TASK", "confidence": 0.5829113245010376}]}, {"text": "A natural extension of these set of automated natural language processing (NLP) tools is a Named Entity Recognizer (NER) for code-mixed social media data, which we present in this paper.", "labels": [], "entities": []}, {"text": "Additionally, as language tags are an essential feature for NLP tasks, including NER, we also present a neural network based language identifier.", "labels": [], "entities": []}, {"text": "Our main contributions are: 1.", "labels": [], "entities": []}, {"text": "Building a token-level language identification system for Hindi-English (Hi-En) code mixed tweets, described in detail in Section 3. 2. Building an NER for En-Hi code-mixed tweets, which we explain in Section 4.", "labels": [], "entities": [{"text": "token-level language identification", "start_pos": 11, "end_pos": 46, "type": "TASK", "confidence": 0.6512913902600607}]}, {"text": "We also show, in Section 5, that our NER performs better than existing baselines.", "labels": [], "entities": [{"text": "NER", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.7110393047332764}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Performance of different transliteration  models. Reported CER is in percentage and was  calculated after a 5-fold cross validation. Depth  was kept the same for both encoding and decoding  layers.", "labels": [], "entities": [{"text": "CER", "start_pos": 69, "end_pos": 72, "type": "METRIC", "confidence": 0.4945709705352783}, {"text": "Depth", "start_pos": 143, "end_pos": 148, "type": "METRIC", "confidence": 0.9756289720535278}]}, {"text": " Table 2: Performance (F 1 scores) of different mod- els on segmentation and classification. N is the  total number of entities in the entire dataset. Re- ported numbers are in percentages. Results of  CRF and LSTM are on 5-fold cross validation.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 23, "end_pos": 33, "type": "METRIC", "confidence": 0.9479106068611145}, {"text": "segmentation", "start_pos": 60, "end_pos": 72, "type": "TASK", "confidence": 0.9698680639266968}]}, {"text": " Table 3: Performance of different models at entity  segmentation. All numbers are in percentages.", "labels": [], "entities": [{"text": "entity  segmentation", "start_pos": 45, "end_pos": 65, "type": "TASK", "confidence": 0.7643325626850128}]}]}