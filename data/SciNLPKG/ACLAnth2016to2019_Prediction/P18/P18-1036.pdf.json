{"title": [{"text": "Character-Level Models versus Morphology in Semantic Role Labeling", "labels": [], "entities": [{"text": "Semantic Role Labeling", "start_pos": 44, "end_pos": 66, "type": "TASK", "confidence": 0.6719330449899038}]}], "abstractContent": [{"text": "Character-level models have become a popular approach specially for their accessibility and ability to handle unseen data.", "labels": [], "entities": []}, {"text": "However, little is known on their ability to reveal the underlying morphological structure of a word, which is a crucial skill for high-level semantic analysis tasks, such as semantic role labeling (SRL).", "labels": [], "entities": [{"text": "semantic role labeling (SRL)", "start_pos": 175, "end_pos": 203, "type": "TASK", "confidence": 0.784818192323049}]}, {"text": "In this work, we train various types of SRL models that use word, character and morphology level information and analyze how performance of characters compare to words and morphology for several languages.", "labels": [], "entities": [{"text": "SRL", "start_pos": 40, "end_pos": 43, "type": "TASK", "confidence": 0.9779286980628967}]}, {"text": "We conduct an in-depth error analysis for each morphological typology and analyze the strengths and limitations of character-level models that relate to out-of-domain data, training data size, long range dependencies and model complexity.", "labels": [], "entities": []}, {"text": "Our exhaustive analyses shed light on important characteristics of character-level models and their semantic capability.", "labels": [], "entities": []}], "introductionContent": [{"text": "Encoding of words is perhaps the most important step towards a successful end-to-end natural language processing application.", "labels": [], "entities": []}, {"text": "Although word embeddings have been shown to provide benefit to such models, they commonly treat words as the smallest meaning bearing unit and assume that each word type has its own vector representation.", "labels": [], "entities": []}, {"text": "This assumption has two major shortcomings especially for languages with rich morphology: (1) inability to handle unseen or out-ofvocabulary (OOV) word-forms (2) inability to exploit the regularities among word parts.", "labels": [], "entities": []}, {"text": "The limitations of word embeddings are particularly pronounced in sentence-level semantic tasks, especially in languages where word parts play a crucial role.", "labels": [], "entities": []}, {"text": "Consider the Turkish sentences \"K\u00f6y+\u00ef u-ler (villagers) s \u00b8ehr+e (to town) geldi (came)\" and \"Sendika+l\u0131-lar (union members) meclis+e (to council) geldi (came)\".", "labels": [], "entities": []}, {"text": "Here the stems k\u00f6y (village) and sendika (union) function similarly in semantic terms with respect to the verb come (as the origin of the agents of the verb), where s \u00b8ehir (town) and meclis (council) both function as the endpoint.", "labels": [], "entities": []}, {"text": "These semantic similarities are determined by the common word parts shown in bold.", "labels": [], "entities": []}, {"text": "However ortographic similarity does not always correspond to semantic similarity.", "labels": [], "entities": []}, {"text": "For instance the ortographically similar words knight and night have large semantic differences.", "labels": [], "entities": []}, {"text": "Therefore, fora successful semantic application, the model should be able to capture both the regularities, i.e, morphological tags and the irregularities, i.e, lemmas of the word.", "labels": [], "entities": []}, {"text": "Morphological analysis already provides the aforementioned information about the words.", "labels": [], "entities": []}, {"text": "However access to useful morphological features maybe problematic due to software licensing issues, lack of robust morphological analyzers and high ambiguity among analyses.", "labels": [], "entities": []}, {"text": "Characterlevel models (CLM), being a cheaper and accessible alternative to morphology, have been reported as performing competitively on various NLP tasks (.", "labels": [], "entities": []}, {"text": "However the extent to which these tasks depend on morphology is small; and their relation to semantics is weak.", "labels": [], "entities": []}, {"text": "Hence, little is known on their true ability to reveal the underlying morphological structure of a word and their semantic capabilities.", "labels": [], "entities": []}, {"text": "Furthermore, their behaviour across languages from different families; and their limitations and strengths such as handling of longrange dependencies, reaction to model complexity or performance on out-of-domain data are unknown.", "labels": [], "entities": []}, {"text": "Analyzing such issues is a key to fully understanding the character-level models.", "labels": [], "entities": []}, {"text": "To achieve this, we perform a case study on semantic role labeling (SRL), a sentencelevel semantic analysis task that aims to identify predicate-argument structures and assign meaningful labels to them as follows: [Villagers] comers came [to town] endpoint We use a simple method based on bidirectional LSTMs to train three types of base semantic role labelers that employ (1) words (2) characters and character sequences and (3) gold morphological analysis.", "labels": [], "entities": [{"text": "semantic role labeling (SRL)", "start_pos": 44, "end_pos": 72, "type": "TASK", "confidence": 0.8198896845181783}, {"text": "sentencelevel semantic analysis task", "start_pos": 76, "end_pos": 112, "type": "TASK", "confidence": 0.752516396343708}]}, {"text": "The gold morphology serves as the upper bound for us to compare and analyze the performances of character-level models on languages of varying morphological typologies.", "labels": [], "entities": []}, {"text": "We carryout an exhaustive error analysis for each language type and analyze the strengths and limitations of character-level models compared to morphology.", "labels": [], "entities": []}, {"text": "In regard to the diversity hypothesis which states that diversity of systems in ensembles lead to further improvement, we combine character and morphology-level models and measure the performance of the ensemble to better understand how similar they are.", "labels": [], "entities": []}, {"text": "We experiment with several languages with varying degrees of morphological richness and typology: Turkish, Finnish, Czech, German, Spanish, Catalan and English.", "labels": [], "entities": []}, {"text": "Our experiments and analysis reveal insights such as: \u2022 CLMs provide great improvements over whole-word-level models despite not being able to match the performance of morphology-level models (MLMs) for indomain datasets.", "labels": [], "entities": []}, {"text": "However their performance surpass all MLMs on out-of-domain data, \u2022 Limitations and strengths differ by morphological typology.", "labels": [], "entities": [{"text": "MLMs", "start_pos": 38, "end_pos": 42, "type": "TASK", "confidence": 0.9588821530342102}]}, {"text": "Their limitations for agglutinative languages are related to rich derivational morphology and high contextual ambiguity; whereas for fusional languages they are related to number of morphological tags (morpheme ambiguity) , \u2022 CLMs can handle long-range dependencies equally well as MLMs, \u2022 In presence of more training data, CLM's performance is expected to improve faster than of MLM.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the datasets distributed by LDC for Catalan (CAT), Spanish (SPA), German (DEU), Czech (CZE) and English (ENG) (; S \u00b8 ahin and Adal\u0131 (2017).", "labels": [], "entities": []}, {"text": "To fit the requirements of the SRL task and of our model, we performed the following: Spanish, Catalan: Multiword expressions (MWE) are represented as a single token, (e.g., Confederaci\u00f3n Francesa del Trabajo), that causes notably long character sequences which are hard to handle by LSTMs.", "labels": [], "entities": [{"text": "SRL task", "start_pos": 31, "end_pos": 39, "type": "TASK", "confidence": 0.9306683242321014}]}, {"text": "For the sake of memory efficiency and performance, we used an abbreviation (e.g., CFdT) for each MWE during training and testing.", "labels": [], "entities": []}, {"text": "Finnish: Original dataset defines its own format of semantic annotation, such as 17:PBArgM mod|19:PBArgM mod meaning the node is an argument of 17 th and 19 th tokens with ArgM-mod (temporary modifier) semantic role.", "labels": [], "entities": [{"text": "ArgM-mod", "start_pos": 172, "end_pos": 180, "type": "METRIC", "confidence": 0.98338782787323}]}, {"text": "They have been converted into CoNLL-09 tabular format, where each predicate's arguments are given in a specific column.", "labels": [], "entities": [{"text": "CoNLL-09 tabular format", "start_pos": 30, "end_pos": 53, "type": "TASK", "confidence": 0.6802807450294495}]}, {"text": "Turkish: Words are splitted from derivational boundaries in the original dataset, where each inflectional group is represented as a separate token.", "labels": [], "entities": []}, {"text": "We first merge boundaries of the same word, i.e, tokens of the word, then we use our own \u03c1 function to split words into subwords.", "labels": [], "entities": []}, {"text": "Training and Evaluation: We lowercase all tokens beforehand and place special start and end of the token characters.", "labels": [], "entities": []}, {"text": "For all experiments, we initialized weight parameters orthogonally and used one layer bi-LSTMs both for subword composition and argument labeling with hidden size of 200.", "labels": [], "entities": [{"text": "subword composition", "start_pos": 104, "end_pos": 123, "type": "TASK", "confidence": 0.754975825548172}, {"text": "argument labeling", "start_pos": 128, "end_pos": 145, "type": "TASK", "confidence": 0.6955038607120514}]}, {"text": "Subword embedding size is chosen as 200.", "labels": [], "entities": []}, {"text": "We used gradient clipping and early stopping to prevent overfitting.", "labels": [], "entities": [{"text": "gradient clipping", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.765074610710144}, {"text": "early stopping", "start_pos": 30, "end_pos": 44, "type": "METRIC", "confidence": 0.8883264064788818}]}, {"text": "Stochastic gradient descent is used as the optimizer.", "labels": [], "entities": []}, {"text": "The initial learning rate is set to 1 and reduced by half if scores on development set do not improve after 3 epochs.", "labels": [], "entities": [{"text": "initial learning rate", "start_pos": 4, "end_pos": 25, "type": "METRIC", "confidence": 0.7335541347662607}]}, {"text": "We use the provided splits and evaluate the results with the official evaluation script provided by CoNLL-09 shared task.", "labels": [], "entities": [{"text": "CoNLL-09 shared task", "start_pos": 100, "end_pos": 120, "type": "DATASET", "confidence": 0.8549839456876119}]}, {"text": "In this work (and inmost of the recent SRL works), only the scores for argument labeling are reported, which may cause confusions for the readers while comparing with older SRL studies.", "labels": [], "entities": [{"text": "SRL", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.9669055938720703}, {"text": "argument labeling", "start_pos": 71, "end_pos": 88, "type": "TASK", "confidence": 0.7352851927280426}]}, {"text": "Most of the early SRL work report combined scores (argument labeling with predicate sense disambiguation (PSD)).", "labels": [], "entities": [{"text": "SRL", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.9871169924736023}, {"text": "argument labeling", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.7103552669286728}]}, {"text": "However, PSD is considered a simpler task with higher F1 scores 3 . Therefore, we believe omitting PSD helps us gain more useful insights on character level models.", "labels": [], "entities": [{"text": "PSD", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.9765032529830933}, {"text": "F1 scores", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9748543202877045}, {"text": "omitting PSD", "start_pos": 90, "end_pos": 102, "type": "TASK", "confidence": 0.7685832381248474}]}], "tableCaptions": [{"text": " Table 3: F1 scores of word, character, character  trigram and morphology models for argument la- beling. Best F1 for each language is shown in  bold. First row: results on test, Second row: re- sults on development.", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9993809461593628}, {"text": "F1", "start_pos": 111, "end_pos": 113, "type": "METRIC", "confidence": 0.963401198387146}]}, {"text": " Table 4: Results of ensembling via averaging (Avg) and stack generalization (SG). IOB: Improvement  Over Best of baseline models", "labels": [], "entities": [{"text": "IOB", "start_pos": 83, "end_pos": 86, "type": "METRIC", "confidence": 0.9868925213813782}, {"text": "Improvement", "start_pos": 88, "end_pos": 99, "type": "METRIC", "confidence": 0.9680837988853455}]}, {"text": " Table 5: F1 scores on out of domain data. Best  scores are shown with bold.", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9995679259300232}]}, {"text": " Table 6: Effect of layer size on model perfor- mances. I: Improvement over model with one  layer.", "labels": [], "entities": []}]}