{"title": [{"text": "The Hitchhiker's Guide to Testing Statistical Significance in Natural Language Processing", "labels": [], "entities": []}], "abstractContent": [{"text": "Statistical significance testing is a standard statistical tool designed to ensure that experimental results are not coincidental.", "labels": [], "entities": [{"text": "Statistical significance testing", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.867926299571991}]}, {"text": "In this opin-ion/theoretical paper we discuss the role of statistical significance testing in Natural Language Processing (NLP) research.", "labels": [], "entities": [{"text": "statistical significance testing", "start_pos": 58, "end_pos": 90, "type": "TASK", "confidence": 0.7161319653193156}]}, {"text": "We establish the fundamental concepts of significance testing and discuss the specific aspects of NLP tasks, experimental setups and evaluation measures that affect the choice of significance tests in NLP research.", "labels": [], "entities": [{"text": "significance testing", "start_pos": 41, "end_pos": 61, "type": "TASK", "confidence": 0.9183784127235413}]}, {"text": "Based on this discussion, we propose a simple practical protocol for statistical significance test selection in NLP setups and accompany this protocol with a brief survey of the most relevant tests.", "labels": [], "entities": [{"text": "statistical significance test selection", "start_pos": 69, "end_pos": 108, "type": "TASK", "confidence": 0.6421063020825386}]}, {"text": "We then survey recent empirical papers published in ACL and TACL during 2017 and show that while our community assigns great value to experimental results , statistical significance testing is often ignored or misused.", "labels": [], "entities": [{"text": "TACL", "start_pos": 60, "end_pos": 64, "type": "DATASET", "confidence": 0.6387732028961182}]}, {"text": "We conclude with a brief discussion of open issues that should be properly addressed so that this important tool can be applied in NLP research in a statistically sound manner 1 .", "labels": [], "entities": []}], "introductionContent": [{"text": "The field of Natural Language Processing (NLP) has recently made great progress due to the data revolution that has made abundant amounts of textual data from a variety of languages and linguistic domains (newspapers, scientific journals, social media etc.) available.", "labels": [], "entities": [{"text": "Natural Language Processing (NLP)", "start_pos": 13, "end_pos": 46, "type": "TASK", "confidence": 0.8040063579877218}]}, {"text": "This, together with the emergence of anew generation of computing resources and the related development of Deep Neural Network models, have resulted in dramatic improvements in the capabilities of NLP algorithms.", "labels": [], "entities": []}, {"text": "The extended reach of NLP algorithms has also resulted in NLP papers giving much more emphasis to the experiment and result sections by showing comparisons between multiple algorithms on various datasets from different languages and domains.", "labels": [], "entities": []}, {"text": "This emphasis on empirical results highlights the role of statistical significance testing in NLP research: if we rely on empirical evaluation to validate our hypotheses and reveal the correct language processing mechanisms, we better be sure that our results are not coincidental.", "labels": [], "entities": []}, {"text": "This paper aims to discuss the various aspects of proper statistical significance testing in NLP and to provide a simple and sound guide to the way this important tool should be used.", "labels": [], "entities": []}, {"text": "We also discuss the particular challenges of statistical significance in the context of language processing tasks.", "labels": [], "entities": [{"text": "language processing tasks", "start_pos": 88, "end_pos": 113, "type": "TASK", "confidence": 0.7583732505639394}]}, {"text": "To facilitate a clear and coherent presentation, our (somewhat simplified) model of an NLP paper is one that presents anew algorithm and makes the hypothesis that this algorithm is better than a previous strong algorithm, which serves as the baseline.", "labels": [], "entities": []}, {"text": "This hypothesis is verified in experiments where the two algorithms are applied to the same datasets (test sets), reasoning that if one algorithm is consistently better than the other, hopefully with a sufficiently large margin, then it should also be better on future, currently unknown, datasets.", "labels": [], "entities": []}, {"text": "Yet, the experimental differences might be coincidental.", "labels": [], "entities": []}, {"text": "Here comes statistical significance testing into the picture: we have to make sure that the probability of falsely concluding that one algorithm is better than the other is very small.", "labels": [], "entities": []}, {"text": "We note that in this paper we do not deal with the problem of drawing valid conclusions from multiple comparisons between algorithms across a large number of datasets , a.k.a. replicability analysis (see).", "labels": [], "entities": [{"text": "replicability analysis", "start_pos": 176, "end_pos": 198, "type": "TASK", "confidence": 0.947524905204773}]}, {"text": "Instead, our focus is on a single comparison: how can we make sure that the difference between the two algorithms, as observed in an individual comparison, is not coincidental.", "labels": [], "entities": []}, {"text": "Statistical significance testing of each individual comparison is the basic building block of replicability analysis -its accurate performance is a pre-condition for any multiple dataset analysis.", "labels": [], "entities": [{"text": "replicability analysis", "start_pos": 94, "end_pos": 116, "type": "TASK", "confidence": 0.9841119647026062}]}, {"text": "Statistical significance testing ( \u00a7 2) is a well researched problem in the statistical literature.", "labels": [], "entities": [{"text": "Statistical significance testing", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8959314624468485}]}, {"text": "However, the unique structured nature of natural language data is reflected in specialized evaluation measures such as BLEU (machine translation,), ROUGE (extractive summarization,), UAS and LAS (dependency parsing,).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 119, "end_pos": 123, "type": "METRIC", "confidence": 0.9980844259262085}, {"text": "machine translation", "start_pos": 125, "end_pos": 144, "type": "TASK", "confidence": 0.6601158976554871}, {"text": "ROUGE", "start_pos": 148, "end_pos": 153, "type": "METRIC", "confidence": 0.9931413531303406}, {"text": "UAS", "start_pos": 183, "end_pos": 186, "type": "METRIC", "confidence": 0.7183791399002075}, {"text": "LAS", "start_pos": 191, "end_pos": 194, "type": "METRIC", "confidence": 0.9334571361541748}, {"text": "dependency parsing", "start_pos": 196, "end_pos": 214, "type": "TASK", "confidence": 0.6797661036252975}]}, {"text": "The distribution of these measures is of great importance to statistical significance testing.", "labels": [], "entities": [{"text": "statistical significance testing", "start_pos": 61, "end_pos": 93, "type": "TASK", "confidence": 0.8011085192362467}]}, {"text": "Moreover, certain properties of NLP datasets and the community's evaluation standards also affect the way significance testing should be performed.", "labels": [], "entities": [{"text": "NLP datasets", "start_pos": 32, "end_pos": 44, "type": "DATASET", "confidence": 0.703440710902214}]}, {"text": "An NLP-specific discussion of significance testing is hence in need.", "labels": [], "entities": [{"text": "significance testing", "start_pos": 30, "end_pos": 50, "type": "TASK", "confidence": 0.9346297979354858}]}, {"text": "In \u00a7 3 we discuss the considerations to be made in order to select the proper statistical significance test in NLP setups.", "labels": [], "entities": []}, {"text": "We propose a simple decision tree algorithm for this purpose, and survey the prominent significance tests -parametric and nonparametric -for NLP tasks and data.", "labels": [], "entities": []}, {"text": "In \u00a7 4 we survey the current evaluation and significance testing practices of the community.", "labels": [], "entities": []}, {"text": "We provide statistics collected from the long papers of the latest ACL proceedings ( as well as from the papers published in the TACL journal during 2017.", "labels": [], "entities": [{"text": "TACL journal during 2017", "start_pos": 129, "end_pos": 153, "type": "DATASET", "confidence": 0.9229021817445755}]}, {"text": "Our analysis reveals that there is still a room for improvement in the way statistical significance is used in papers published in our top-tier publication venues.", "labels": [], "entities": []}, {"text": "Particularly, a large portion of the surveyed papers do not test the significance of their results, or use incorrect tests for this purpose.", "labels": [], "entities": []}, {"text": "Finally, in \u00a7 5 we discuss open issues.", "labels": [], "entities": []}, {"text": "A particularly challenging problem is that while most significance tests assume the test set consists of independent observations, most NLP datasets consist of dependent data points.", "labels": [], "entities": []}, {"text": "For example, many NLP standard evaluation sets consist of sentences coming from the same source (e.g. newspaper) or document (e.g. newspaper article) or written by the same author.", "labels": [], "entities": []}, {"text": "Unfortunately, the nature of these dependencies is hard to characterize, let alone to quantify.", "labels": [], "entities": []}, {"text": "Another important problem is how to test significance when cross-validation, a popular evaluation methodology in NLP papers, is performed.", "labels": [], "entities": []}, {"text": "Besides its practical value, we hope this paper will encourage further research into the role of statistical significance testing in NLP and on the questions that still remain open.", "labels": [], "entities": [{"text": "NLP", "start_pos": 133, "end_pos": 136, "type": "TASK", "confidence": 0.8436686396598816}]}], "datasetContent": [{"text": "In \u00a7 4 we analyze the (long) ACL and TACL 2017 papers, and observe that the most commonly used evaluation measures are the 12 measures that appear in or in R.", "labels": [], "entities": [{"text": "ACL and TACL 2017 papers", "start_pos": 29, "end_pos": 53, "type": "DATASET", "confidence": 0.8503707647323608}]}, {"text": "Notice though that accuracy may reflect an average over a set of categorical scores (observations), e.g., in document-level binary sentiment analysis where every document is tagged as either positive or negative.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9992055296897888}, {"text": "document-level binary sentiment analysis", "start_pos": 109, "end_pos": 149, "type": "TASK", "confidence": 0.7097217440605164}]}, {"text": "In other cases, the individual observations are also continuous.", "labels": [], "entities": []}, {"text": "For example, when comparing two dependency parsers, we may want to understand how likely it is, given our results, that one parser will do better than the other on anew sentence.", "labels": [], "entities": []}, {"text": "In such a case we will consider the sentence-level UAS or LAS differences between the two parsers on all the sentences in the test set.", "labels": [], "entities": [{"text": "UAS", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.8145610690116882}, {"text": "LAS", "start_pos": 58, "end_pos": 61, "type": "METRIC", "confidence": 0.9545391201972961}]}, {"text": "Such sentence level UAS or LAS scores -the individual observations to be considered in the significance test -are real-valued.", "labels": [], "entities": [{"text": "LAS", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.8675641417503357}]}, {"text": "With the basic concepts clarified, we are ready to discuss the considerations to be made when choosing a statistical significance test.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Statistical significance statistics for em- pirical ACL and TACL 2017 papers.", "labels": [], "entities": [{"text": "ACL and TACL 2017 papers", "start_pos": 62, "end_pos": 86, "type": "DATASET", "confidence": 0.678558099269867}]}]}