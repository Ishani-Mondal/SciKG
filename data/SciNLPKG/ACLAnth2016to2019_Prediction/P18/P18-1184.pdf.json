{"title": [{"text": "Rumor Detection on Twitter with Tree-structured Recursive Neural Networks", "labels": [], "entities": [{"text": "Rumor Detection", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.818206250667572}]}], "abstractContent": [{"text": "Automatic rumor detection is technically very challenging.", "labels": [], "entities": [{"text": "Automatic rumor detection", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7714768846829733}]}, {"text": "In this work, we try to learn discriminative features from tweets content by following their non-sequential propagation structure and generate more powerful representations for identifying different type of rumors.", "labels": [], "entities": []}, {"text": "We propose two recursive neural models based on a bottom-up and a top-down tree-structured neural networks for rumor representation learning and classification, which naturally conform to the propagation layout of tweets.", "labels": [], "entities": [{"text": "rumor representation learning and classification", "start_pos": 111, "end_pos": 159, "type": "TASK", "confidence": 0.7727280139923096}]}, {"text": "Results on two public Twit-ter datasets demonstrate that our recursive neural models 1) achieve much better performance than state-of-the-art approaches; 2) demonstrate superior capacity on detecting rumors at very early stage.", "labels": [], "entities": [{"text": "Twit-ter datasets", "start_pos": 22, "end_pos": 39, "type": "DATASET", "confidence": 0.9047888815402985}]}], "introductionContent": [{"text": "Rumors have always been asocial disease.", "labels": [], "entities": []}, {"text": "In recent years, it has become unprecedentedly convenient for the \"evil-doers\" to create and disseminate rumors in massive scale with low cost thanks to the popularity of social media outlets on Twitter, Facebook, etc.", "labels": [], "entities": []}, {"text": "The worst effect of false rumors could be devastating to individual and/or society.", "labels": [], "entities": []}, {"text": "Research pertaining rumors spans multiple disciplines, such as philosophy and humanities, social psychology (, political studies), management science ( and recently computer science and artificial intelligence.", "labels": [], "entities": []}, {"text": "Rumor is commonly defined as information that emerge and spread among people whose truth value is unverified or intentionally false).", "labels": [], "entities": [{"text": "Rumor", "start_pos": 0, "end_pos": 5, "type": "TASK", "confidence": 0.9386680722236633}]}, {"text": "Analysis shows that people tend to stop spreading a rumor if it is known as false ().", "labels": [], "entities": []}, {"text": "However, identifying such misinformation is non-trivial and needs investigative journalism to fact check the suspected claim, which is labor-intensive and time-consuming.", "labels": [], "entities": []}, {"text": "The proliferation of social media makes it worse due to the ever-increasing information load and dynamics.", "labels": [], "entities": []}, {"text": "Therefore, it is necessary to develop automatic and assistant approaches to facilitate real-time rumor tracking and debunking.", "labels": [], "entities": [{"text": "rumor tracking", "start_pos": 97, "end_pos": 111, "type": "TASK", "confidence": 0.8188278079032898}]}, {"text": "For automating rumor detection, most of the previous studies focused on text mining from sequential microblog streams using supervised models based on feature engineering, and more recently deep neural models ().", "labels": [], "entities": [{"text": "automating rumor detection", "start_pos": 4, "end_pos": 30, "type": "TASK", "confidence": 0.8102711041768392}, {"text": "text mining", "start_pos": 72, "end_pos": 83, "type": "TASK", "confidence": 0.7646004855632782}]}, {"text": "These methods largely ignore or oversimplify the structural information associated with message propagation which however has been shown conducive to provide useful clues for identifying rumors.", "labels": [], "entities": [{"text": "message propagation", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.7179758846759796}, {"text": "identifying rumors", "start_pos": 175, "end_pos": 193, "type": "TASK", "confidence": 0.8777909278869629}]}, {"text": "Kernel-based method ( was thus proposed to model the structure as propagation trees in order to differentiate rumorous and non-rumorous claims by comparing their tree-based similarities.", "labels": [], "entities": []}, {"text": "But such kind of approach cannot directly classify a tree without pairwise comparison with all other trees imposing unnecessary overhead, and it also cannot automatically learn any high-level feature representations out of the noisy surface features.", "labels": [], "entities": []}, {"text": "In this paper, we present a neural rumor detection approach based on recursive neural networks (RvNN) to bridge the content semantics and propagation clues.", "labels": [], "entities": [{"text": "neural rumor detection", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.7049670219421387}]}, {"text": "RvNN and its variants were originally used to compose phrase or sentence representation for syntactic and semantic parsing.", "labels": [], "entities": [{"text": "syntactic and semantic parsing", "start_pos": 92, "end_pos": 122, "type": "TASK", "confidence": 0.6408372968435287}]}, {"text": "Unlike parsing, the input into our model is a propagation tree rooted from a source post rather than the parse tree of an individual sentence, and each tree node is a responsive post instead of an individual words.", "labels": [], "entities": [{"text": "parsing", "start_pos": 7, "end_pos": 14, "type": "TASK", "confidence": 0.9686242938041687}]}, {"text": "The content semantics of posts and the responsive relationship among them can be jointly captured via the recursive feature learning process along the tree structure.", "labels": [], "entities": []}, {"text": "So, why can such neural model do better for the task?", "labels": [], "entities": []}, {"text": "Analysis has generally found that Twitter could \"self-correct\" some inaccurate information as users share opinions, conjectures and evidences (.", "labels": [], "entities": []}, {"text": "To illustrate our intuition, exemplifies the propagation trees of two rumors in our dataset, one being false and the other being true 1 . Structure-insensitive methods basically relying on the relative ratio of different stances in the text cannot do well when such clue is unclear like this example.", "labels": [], "entities": []}, {"text": "However, it can be seen that when a post denies the false rumor, it tends to spark supportive or affirmative replies confirming the denial; in contrast, denial to a true rumor tends to trigger question or denial in its replies.", "labels": [], "entities": []}, {"text": "This observation may suggest a more general hypothesis that the repliers tend to disagree with (or question) who support a false rumor or deny a true rumor, and also they tend to agree with who deny a false rumor or support a true rumor.", "labels": [], "entities": []}, {"text": "Meanwhile, a reply, rather than directly responding to the source tweet (i.e., the root), is usually responsive to its immediate ancestor, suggesting obvious local characteristic of the interaction.", "labels": [], "entities": []}, {"text": "The recursive network naturally models such structures for learning to capture the rumor indicative signals and enhance the representation by recursively aggregating the signals from different branches.", "labels": [], "entities": []}, {"text": "To this end, we extend the standard RvNN into two variants, i.e., a bottom-up (BU) model and a top-down (TD) model, which represent the propagation tree structure from different angles, in order to visit the nodes and combine their representations following distinct directions.", "labels": [], "entities": []}, {"text": "The important merit of such architecture is that the node features can be selectively refined by the recursion given the connection and direction of all paths of the 1 False (true) rumor means the veracity of the rumorous claim is false (true).", "labels": [], "entities": [{"text": "False", "start_pos": 168, "end_pos": 173, "type": "METRIC", "confidence": 0.9774461388587952}]}, {"text": "The edge arrow indicates the direction from a response to its responded node, and the polarity is marked as '+' ('-') for support (denial).", "labels": [], "entities": []}, {"text": "The same node color indicates the same stance on the veracity of root node (i.e., source tweet). tree.", "labels": [], "entities": []}, {"text": "As a result, it can be expected that the discriminative signals are better embedded into the learned representations.", "labels": [], "entities": []}, {"text": "We evaluate our proposed approach based on two public Twitter datasets.", "labels": [], "entities": []}, {"text": "The results show that our method outperforms strong rumor detection baselines with large margin and also demonstrate much higher effectiveness for detection at early stage of propagation, which is promising for realtime intervention and debunking.", "labels": [], "entities": [{"text": "rumor detection", "start_pos": 52, "end_pos": 67, "type": "TASK", "confidence": 0.7269073128700256}]}, {"text": "Our contributions are summarized as follows in three folds: \u2022 This is the first study that deeply integrates both structure and content semantics based on tree-structured recursive neural networks for detecting rumors from microblog posts.", "labels": [], "entities": [{"text": "detecting rumors from microblog posts", "start_pos": 201, "end_pos": 238, "type": "TASK", "confidence": 0.8259283900260925}]}, {"text": "\u2022 We propose two variants of RvNN models based on bottom-up and top-down tree structures to generate better integrated representations fora claim by capturing both structural and textural properties signaling rumors.", "labels": [], "entities": []}, {"text": "\u2022 Our experiments based on real-world Twitter datasets achieve superior improvements over state-of-the-art baselines on both rumor classification and early detection tasks.", "labels": [], "entities": [{"text": "rumor classification", "start_pos": 125, "end_pos": 145, "type": "TASK", "confidence": 0.7948420345783234}, {"text": "early detection tasks", "start_pos": 150, "end_pos": 171, "type": "TASK", "confidence": 0.7852801283200582}]}, {"text": "We make the source codes in our experiments publicly accessible 2 .", "labels": [], "entities": []}], "datasetContent": [{"text": "For experimental evaluation, we use two publicly available Twitter datasets released by, namely Twitter15 and Twitter16 4 , which respectively contains 1,381 and 1,181 propagation trees (see) for detailed statistics).", "labels": [], "entities": [{"text": "Twitter15", "start_pos": 96, "end_pos": 105, "type": "DATASET", "confidence": 0.9561001062393188}]}, {"text": "In each dataset, a group of widespread source tweets along with their propagation threads, i.e., replies and retweets, are provided in the form of tree structure.", "labels": [], "entities": []}, {"text": "Each tree is annotated with one of the four class labels, i.e., non-rumor, false rumor, true rumor and unverified rumor.", "labels": [], "entities": []}, {"text": "We remove the retweets from the trees since they do not provide any extra information or evidence contentwise.", "labels": [], "entities": []}, {"text": "We build two versions for each tree, one for the bottom-up tree and the other for the top-down tree, by flipping the edges' direction.", "labels": [], "entities": []}, {"text": "We make comprehensive comparisons between our models and some state-of-the-art baselines on rumor classification and early detection tasks.", "labels": [], "entities": [{"text": "rumor classification", "start_pos": 92, "end_pos": 112, "type": "TASK", "confidence": 0.8338759541511536}, {"text": "early detection tasks", "start_pos": 117, "end_pos": 138, "type": "TASK", "confidence": 0.8330562512079874}]}, {"text": "-DTR: Zhao et al. proposed a DecisionTree-based Ranking model to identify trending rumors by searching for inquiry phrases.", "labels": [], "entities": [{"text": "DTR", "start_pos": 1, "end_pos": 4, "type": "DATASET", "confidence": 0.810321033000946}]}, {"text": "-DTC: The information credibility model using a Decision-Tree Classifier) based on manually engineering various statistical features of the tweets.", "labels": [], "entities": []}, {"text": "-RFC: The Random Forest Classier using 3 fitting parameters as temporal properties and a set of handcrafted features on user, linguistic and structural properties (.", "labels": [], "entities": [{"text": "RFC", "start_pos": 1, "end_pos": 4, "type": "DATASET", "confidence": 0.7656638622283936}]}, {"text": "-SVM-TS: A linear SVM classifier that uses time-series to model the variation of handcrafted social context features (.", "labels": [], "entities": []}, {"text": "-SVM-BOW: A naive baseline we built by representing text content using bag-of-words and using linear SVM for rumor classification.", "labels": [], "entities": [{"text": "rumor classification", "start_pos": 109, "end_pos": 129, "type": "TASK", "confidence": 0.8634370565414429}]}, {"text": "-SVM-TK and SVM-HK: SVM classifier uses a Tree Kernel ( and that uses a Hybrid Kernel (), respectively, both of which model propagation structures with kernels.", "labels": [], "entities": []}, {"text": "-GRU-RNN: A detection model based on recurrent neural networks () with GRU units for learning rumor representations by modeling sequential structure of relevant posts.", "labels": [], "entities": [{"text": "learning rumor representations", "start_pos": 85, "end_pos": 115, "type": "TASK", "confidence": 0.6809890667597452}]}, {"text": "-BU-RvNN and TD-RvNN: Our bottom-up and top-down RvNN models, respectively.", "labels": [], "entities": [{"text": "BU-RvNN", "start_pos": 1, "end_pos": 8, "type": "METRIC", "confidence": 0.9741644263267517}]}, {"text": "We implement DTC and RFC using Weka 5 , SVM-based models using LibSVM and all neural-network-based models with Theano . We conduct 5-fold cross-validation on the datasets and use accuracy overall the four categories and F1 measure on each class to evaluate the performance of models.", "labels": [], "entities": [{"text": "DTC", "start_pos": 13, "end_pos": 16, "type": "DATASET", "confidence": 0.7147939205169678}, {"text": "RFC", "start_pos": 21, "end_pos": 24, "type": "DATASET", "confidence": 0.7480159401893616}, {"text": "Weka", "start_pos": 31, "end_pos": 35, "type": "DATASET", "confidence": 0.9078074097633362}, {"text": "Theano", "start_pos": 111, "end_pos": 117, "type": "DATASET", "confidence": 0.8837023377418518}, {"text": "accuracy", "start_pos": 179, "end_pos": 187, "type": "METRIC", "confidence": 0.9927298426628113}, {"text": "F1 measure", "start_pos": 220, "end_pos": 230, "type": "METRIC", "confidence": 0.9819564521312714}]}], "tableCaptions": [{"text": " Table 1: Results of rumor detection. (NR: non- rumor; FR: false rumor; TR: true rumor; UR: un- verified rumor)", "labels": [], "entities": [{"text": "rumor detection", "start_pos": 21, "end_pos": 36, "type": "TASK", "confidence": 0.7050514817237854}, {"text": "FR", "start_pos": 55, "end_pos": 57, "type": "METRIC", "confidence": 0.9943645000457764}, {"text": "TR", "start_pos": 72, "end_pos": 74, "type": "METRIC", "confidence": 0.7129045128822327}, {"text": "UR", "start_pos": 88, "end_pos": 90, "type": "METRIC", "confidence": 0.7940189838409424}]}]}