{"title": [{"text": "Fluency Boost Learning and Inference for Neural Grammatical Error Correction", "labels": [], "entities": [{"text": "Neural Grammatical Error Correction", "start_pos": 41, "end_pos": 76, "type": "TASK", "confidence": 0.7571506053209305}]}], "abstractContent": [{"text": "Most of the neural sequence-to-sequence (seq2seq) models for grammatical error correction (GEC) have two limitations: (1) a seq2seq model may not be well generalized with only limited error-corrected data; (2) a seq2seq model may fail to completely correct a sentence with multiple errors through normal seq2seq inference.", "labels": [], "entities": [{"text": "grammatical error correction (GEC)", "start_pos": 61, "end_pos": 95, "type": "TASK", "confidence": 0.7971258709828059}]}, {"text": "We attempt to address these limitations by proposing a fluency boost learning and inference mechanism.", "labels": [], "entities": []}, {"text": "Fluency boosting learning generates fluency-boost sentence pairs during training, enabling the error correction model to learn how to improve a sentence's fluency from more instances, while fluency boosting inference allows the model to correct a sentence incrementally through multi-round seq2seq inference until the sentence's fluency stops increasing.", "labels": [], "entities": []}, {"text": "Experiments show our approaches improve the performance of seq2seq models for GEC, achieving state-of-the-art results on both CoNLL-2014 and JFLEG benchmark datasets.", "labels": [], "entities": [{"text": "GEC", "start_pos": 78, "end_pos": 81, "type": "TASK", "confidence": 0.5243746638298035}, {"text": "CoNLL-2014", "start_pos": 126, "end_pos": 136, "type": "DATASET", "confidence": 0.9175896048545837}, {"text": "JFLEG benchmark datasets", "start_pos": 141, "end_pos": 165, "type": "DATASET", "confidence": 0.8855260411898295}]}], "introductionContent": [{"text": "Sequence-to-sequence (seq2seq) models) for grammatical error correction (GEC) have drawn growing attention () in recent years.", "labels": [], "entities": [{"text": "grammatical error correction (GEC)", "start_pos": 43, "end_pos": 77, "type": "TASK", "confidence": 0.7740048418442408}]}, {"text": "However, most of the seq2seq models for GEC have two flaws.", "labels": [], "entities": [{"text": "GEC", "start_pos": 40, "end_pos": 43, "type": "DATASET", "confidence": 0.9588813781738281}]}, {"text": "First, the seq2seq models are trained with only limited error-corrected sentence pairs like(a).", "labels": [], "entities": []}, {"text": "Limited by the size of training data, the models with millions of parameters may not be well generalized.", "labels": [], "entities": []}, {"text": "Thus, it is She see Tom is catched by policeman in park at last night.", "labels": [], "entities": []}, {"text": "She saw Tom caught by a policeman in the park last night.", "labels": [], "entities": []}, {"text": "She sees Tom is catched by policeman in park at last night.", "labels": [], "entities": []}, {"text": "Figure 1: (a) an error-corrected sentence pair; (b) if the sentence becomes slightly different, the model fails to correct it perfectly; (c) single-round seq2seq inference cannot perfectly correct the sentence, but multi-round inference can.", "labels": [], "entities": []}, {"text": "common that the models fail to correct a sentence perfectly even if the sentence is slightly different from the training instance, as illustrated by(b).", "labels": [], "entities": []}, {"text": "Second, the seq2seq models usually cannot perfectly correct a sentence with many grammatical errors through single-round seq2seq inference, as shown in(b) and 1(c), because some errors in a sentence may make the context strange, which confuses the models to correct other errors.", "labels": [], "entities": []}, {"text": "To address the above-mentioned limitations in model learning and inference, this paper proposes a novel fluency boost learning and inference mechanism, illustrated in.", "labels": [], "entities": []}, {"text": "For fluency boosting learning, not only is a seq2seq model trained with original errorcorrected sentence pairs, but also it generates less fluent sentences (e.g., from its n-best outputs) to establish new error-corrected sentence pairs by pairing them with their correct sentences during training, as long as the sentences' fluency 1 is be-: Fluency boost learning and inference: (a) given a training instance (i.e., an error-corrected sentence pair), fluency boost learning establishes multiple fluency boost sentence pairs from the seq2seq's n-best outputs during training.", "labels": [], "entities": [{"text": "fluency boosting learning", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.8423283894856771}]}, {"text": "The fluency boost sentence pairs will be used as training instances in subsequent training epochs, which helps expand the training set and accordingly benefits model learning; (b) fluency boost inference allows an error correction model to correct a sentence incrementally through multi-round seq2seq inference until its fluency score stops increasing.", "labels": [], "entities": []}, {"text": "low that of their correct sentences, as(a) shows.", "labels": [], "entities": []}, {"text": "Specifically, we call the generated errorcorrected sentence pairs fluency boost sentence pairs because the sentence in the target side always improves fluency over that in the source side.", "labels": [], "entities": []}, {"text": "The generated fluency boost sentence pairs during training will be used as additional training instances during subsequent training epochs, allowing the error correction model to see more grammatically incorrect sentences during training and accordingly improving its generalization ability.", "labels": [], "entities": []}, {"text": "For model inference, fluency boost inference mechanism allows the model to correct a sentence incrementally with multi-round inference as long as the proposed edits can boost the sentence's fluency, as(b) shows.", "labels": [], "entities": [{"text": "model inference", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.6934072971343994}]}, {"text": "For a sentence with multiple grammatical errors, some of the errors will be corrected first.", "labels": [], "entities": []}, {"text": "The corrected parts will make the context clearer, which may benefit the model to correct the remaining errors.", "labels": [], "entities": []}, {"text": "Experiments demonstrate fluency boost learning and inference enable neural seq2seq models to perform better for GEC and achieve state-of-theart results on multiple GEC benchmarks.", "labels": [], "entities": [{"text": "GEC", "start_pos": 112, "end_pos": 115, "type": "DATASET", "confidence": 0.5771960020065308}, {"text": "GEC benchmarks", "start_pos": 164, "end_pos": 178, "type": "DATASET", "confidence": 0.8234840631484985}]}, {"text": "Our contributions are summarized as follows: \u2022 We present a novel learning and inference mechanism to address the limitations in previous seq2seq models for GEC.", "labels": [], "entities": []}, {"text": "\u2022 We propose and compare multiple novel fluency boost learning strategies, exploring the learning methodology for neural GEC.", "labels": [], "entities": []}, {"text": "\u2022 Our approaches are proven to be effective to improve neural seq2seq GEC models to achieve state-of-the-art results on CoNLL-2014 and JFLEG benchmark datasets.", "labels": [], "entities": [{"text": "CoNLL-2014", "start_pos": 120, "end_pos": 130, "type": "DATASET", "confidence": 0.9416845440864563}, {"text": "JFLEG benchmark datasets", "start_pos": 135, "end_pos": 159, "type": "DATASET", "confidence": 0.9115368723869324}]}], "datasetContent": [{"text": "We setup experiments in order to answer the following questions:   \u2022 Whether is fluency boost learning mechanism helpful for training the error correction model, and which of the strategies (back-boost, selfboost, dual-boost) is the most effective?", "labels": [], "entities": [{"text": "error correction", "start_pos": 138, "end_pos": 154, "type": "TASK", "confidence": 0.6600488424301147}]}, {"text": "\u2022 Whether does our fluency boost inference improve normal seq2seq inference for GEC?", "labels": [], "entities": []}, {"text": "\u2022 Whether can our approach improve neural GEC to achieve state-of-the-art results?", "labels": [], "entities": [{"text": "GEC", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.6349838376045227}]}, {"text": "The training details for our seq2seq error correction model and error generation model are as follows: the encoder of the seq2seq models is a 2-layer bidirectional GRU RNN and the decoder is a 2-layer GRU RNN with the general attention mechanism (.", "labels": [], "entities": [{"text": "seq2seq error correction", "start_pos": 29, "end_pos": 53, "type": "TASK", "confidence": 0.5787152846654257}, {"text": "error generation", "start_pos": 64, "end_pos": 80, "type": "TASK", "confidence": 0.6646439433097839}]}, {"text": "Both the dimensionality of word embeddings and the hidden size of GRU cells are 500.", "labels": [], "entities": []}, {"text": "The vocabulary sizes of the encoder and decoder are 100,000 and 50,000 respectively.", "labels": [], "entities": []}, {"text": "The models' parameters are uniformly initialized in.", "labels": [], "entities": []}, {"text": "We train the models with an Adam optimizer with a learning rate of 0.0001 up to 40 epochs with batch size = 128.", "labels": [], "entities": []}, {"text": "Dropout is applied to non-recurrent connections at a ratio of 0.15.", "labels": [], "entities": []}, {"text": "For fluency boost learning, we generate disfluency candidates from 10-best outputs.", "labels": [], "entities": [{"text": "fluency boost learning", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.883582353591919}]}, {"text": "During model inference, we set beam size to 5 and decode 1-best result with a 2-layer GRU RNN language model () through shallow fusion () with weight \u03b2 = 0.15.", "labels": [], "entities": []}, {"text": "The RNN language model is trained from the native data mentioned in Section 5.1, which is also used for computing fluency score in Eq (3).", "labels": [], "entities": []}, {"text": "UNK tokens are replaced with the source token with the highest attention weight.", "labels": [], "entities": [{"text": "UNK", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8445320129394531}]}, {"text": "We resolve spelling errors with a public spellchecker 4 as preprocessing, as and  do. compares the performance of seq2seq error correction models with different learning and inference methods.", "labels": [], "entities": []}, {"text": "By comparing by row, one can observe that our fluency boost learning approaches improve the performance over normal seq2seq learning, especially on the recall metric, since the fluency boost learning approaches generate a variety of grammatically incorrect sentences, allowing the error correction model to learn to correct much more sentences than the conventional learning strategy.", "labels": [], "entities": [{"text": "recall metric", "start_pos": 152, "end_pos": 165, "type": "METRIC", "confidence": 0.9748536944389343}]}, {"text": "Among the proposed three fluency boost learning strategies, dual-boost achieves the best result inmost cases because it produces more diverse incorrect sentences (average |D dual | \u2248 9.43) than either back-boost (avg |D back | \u2248 1.90) or self-boost learning (avg |D self | \u2248 8.10).", "labels": [], "entities": [{"text": "fluency boost learning", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.7587275008360544}]}, {"text": "With introducing large amounts of native text data, the performance of all the fluency boost learning approaches gets improved.", "labels": [], "entities": []}, {"text": "One reason is that our learning approaches produce more error-corrected sentence pairs to let the model be better generalized.", "labels": [], "entities": []}, {"text": "In addition, the huge volume of native data benefits the decoder to learn better to generate a fluent and error-free sentence.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Error-corrected training data.", "labels": [], "entities": [{"text": "Error-corrected", "start_pos": 10, "end_pos": 25, "type": "METRIC", "confidence": 0.9785810112953186}]}, {"text": " Table 3: The effect of \u03c3 on dual-boost learning  with normal seq2seq inference. |D dual | is the av- erage size of dual-boost disfluency candidate sets.", "labels": [], "entities": []}, {"text": " Table 5: Performance of systems on CoNLL-2014  dataset. The system with bold fonts are based on  seq2seq models. denotes the system uses the  non-public error-corrected data from Lang-8.com.", "labels": [], "entities": [{"text": "CoNLL-2014  dataset", "start_pos": 36, "end_pos": 55, "type": "DATASET", "confidence": 0.9850094318389893}, {"text": "Lang-8.com", "start_pos": 180, "end_pos": 190, "type": "DATASET", "confidence": 0.7088230848312378}]}, {"text": " Table 6: JFLEG Leaderboard. Ours denote the  single dual-boost models in", "labels": [], "entities": [{"text": "JFLEG Leaderboard", "start_pos": 10, "end_pos": 27, "type": "DATASET", "confidence": 0.8566587269306183}]}, {"text": " Table 5. The systems  with bold fonts are based on seq2seq models.  *   denotes the system is tuned on JFLEG.", "labels": [], "entities": [{"text": "JFLEG", "start_pos": 104, "end_pos": 109, "type": "DATASET", "confidence": 0.9461564421653748}]}]}