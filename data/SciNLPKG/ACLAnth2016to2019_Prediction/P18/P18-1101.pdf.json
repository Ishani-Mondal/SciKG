{"title": [{"text": "Unsupervised Discrete Sentence Representation Learning for Interpretable Neural Dialog Generation", "labels": [], "entities": [{"text": "Unsupervised Discrete Sentence Representation Learning", "start_pos": 0, "end_pos": 54, "type": "TASK", "confidence": 0.6361168682575226}, {"text": "Interpretable Neural Dialog Generation", "start_pos": 59, "end_pos": 97, "type": "TASK", "confidence": 0.7259269505739212}]}], "abstractContent": [{"text": "The encoder-decoder dialog model is one of the most prominent methods used to build dialog systems in complex domains.", "labels": [], "entities": []}, {"text": "Yet it is limited because it cannot output interpretable actions as in traditional systems, which hinders humans from understanding its generation process.", "labels": [], "entities": []}, {"text": "We present an unsupervised discrete sentence representation learning method that can integrate with any existing encoder-decoder dialog models for interpretable response generation.", "labels": [], "entities": [{"text": "sentence representation learning", "start_pos": 36, "end_pos": 68, "type": "TASK", "confidence": 0.769898533821106}, {"text": "interpretable response generation", "start_pos": 147, "end_pos": 180, "type": "TASK", "confidence": 0.6711722612380981}]}, {"text": "Building upon vari-ational autoencoders (VAEs), we present two novel models, DI-VAE and DI-VST that improve VAEs and can discover inter-pretable semantics via either auto encoding or context predicting.", "labels": [], "entities": [{"text": "context predicting", "start_pos": 183, "end_pos": 201, "type": "TASK", "confidence": 0.6809499561786652}]}, {"text": "Our methods have been validated on real-world dialog datasets to discover semantic representations and enhance encoder-decoder models with interpretable generation.", "labels": [], "entities": []}], "introductionContent": [{"text": "Classic dialog systems rely on developing a meaning representation to represent the utterances from both the machine and human users).", "labels": [], "entities": []}, {"text": "The dialog manager of a conventional dialog system outputs the system's next action in a semantic frame that usually contains hand-crafted dialog acts and slot values.", "labels": [], "entities": []}, {"text": "Then a natural language generation module is used to generate the system's output in natural language based on the given semantic frame.", "labels": [], "entities": []}, {"text": "This approach suffers from generalization to more complex domains because it soon become intractable to man-ually design a frame representation that covers all of the fine-grained system actions.", "labels": [], "entities": []}, {"text": "The recently developed neural dialog system is one of the most prominent frameworks for developing dialog agents in complex domains.", "labels": [], "entities": []}, {"text": "The basic model is based on encoder-decoder networks ( ) and can learn to generate system responses without the need for hand-crafted meaning representations and other annotations.", "labels": [], "entities": []}, {"text": "Although generative dialog models have advanced rapidly, they cannot provide interpretable system actions as in the conventional dialog systems.", "labels": [], "entities": [{"text": "generative dialog", "start_pos": 9, "end_pos": 26, "type": "TASK", "confidence": 0.9143509268760681}]}, {"text": "This inability limits the effectiveness of generative dialog models in several ways.", "labels": [], "entities": [{"text": "generative dialog", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.9627365171909332}]}, {"text": "First, having interpretable system actions enables human to understand the behavior of a dialog system and better interpret the system intentions.", "labels": [], "entities": []}, {"text": "Also, modeling the high-level decision-making policy in dialogs enables useful generalization and dataefficient domain adaptation.", "labels": [], "entities": [{"text": "dataefficient domain adaptation", "start_pos": 98, "end_pos": 129, "type": "TASK", "confidence": 0.6911015113194784}]}, {"text": "Therefore, the motivation of this paper is to develop an unsupervised neural recognition model that can discover interpretable meaning representations of utterances (denoted as latent actions) as a set of discrete latent variables from a large unlabelled corpus as shown in.", "labels": [], "entities": []}, {"text": "The discovered meaning representations will then be integrated with encoder decoder networks to achieve interpretable dialog generation while preserving all the merit of neural dialog systems.", "labels": [], "entities": [{"text": "interpretable dialog generation", "start_pos": 104, "end_pos": 135, "type": "TASK", "confidence": 0.6316041648387909}]}, {"text": "We focus on learning discrete latent representations instead of dense continuous ones because discrete variables are easier to interpret (van den and can naturally correspond to categories in natural languages, e.g. topics, dialog acts and etc.", "labels": [], "entities": []}, {"text": "Despite the difficulty of learning discrete latent variables in neural networks, the recently proposed Gumbel-Softmax offers a reliable way to back-propagate through discrete variables ().", "labels": [], "entities": []}, {"text": "However, we found a simple combination of sentence variational autoencoders (VAEs) and Gumbel-Softmax fails to learn meaningful discrete representations.", "labels": [], "entities": []}, {"text": "We then highlight the anti-information limitation of the evidence lowerbound objective (ELBO) in VAEs and improve it by proposing Discrete Information VAE (DI-VAE) that maximizes the mutual information between data and latent actions.", "labels": [], "entities": [{"text": "evidence lowerbound objective (ELBO)", "start_pos": 57, "end_pos": 93, "type": "METRIC", "confidence": 0.740566278497378}]}, {"text": "We further enrich the learning signals beyond auto encoding by extending Skip Thought ( to Discrete Information Variational Skip Thought (DI-VST) that learns sentence-level distributional semantics.", "labels": [], "entities": [{"text": "auto encoding", "start_pos": 46, "end_pos": 59, "type": "TASK", "confidence": 0.7764296233654022}]}, {"text": "Finally, an integration mechanism is presented that combines the learned latent actions with encoder decoder models.", "labels": [], "entities": []}, {"text": "The proposed systems are tested on several realworld dialog datasets.", "labels": [], "entities": []}, {"text": "Experiments show that the proposed methods significantly outperform the standard VAEs and can discover meaningful latent actions from these datasets.", "labels": [], "entities": []}, {"text": "Also, experiments confirm the effectiveness of the proposed integration mechanism and show that the learned latent actions can control the sentence-level attributes of the generated responses and provide humaninterpretable meaning representations.", "labels": [], "entities": []}], "datasetContent": [{"text": "The proposed methods are evaluated on four datasets.", "labels": [], "entities": []}, {"text": "The first corpus is Penn Treebank (PTB) () used to evaluate sentence VAEs (.", "labels": [], "entities": [{"text": "Penn Treebank (PTB)", "start_pos": 20, "end_pos": 39, "type": "DATASET", "confidence": 0.962395167350769}, {"text": "evaluate sentence VAEs", "start_pos": 51, "end_pos": 73, "type": "TASK", "confidence": 0.5834380288918813}]}, {"text": "We used the version pre-processed by.", "labels": [], "entities": []}, {"text": "The second dataset is the Stanford Multi-Domain Dialog (SMD) dataset that contains 3,031 human-Woz, task-oriented dialogs collected from 3 different domains (navigation, weather and scheduling).", "labels": [], "entities": [{"text": "Stanford Multi-Domain Dialog (SMD) dataset", "start_pos": 26, "end_pos": 68, "type": "DATASET", "confidence": 0.784089275768825}]}, {"text": "The other two datasets are chat-oriented data: Daily Dialog (DD) and Switchboard (SW) (Godfrey and Holliman, 1997), which are used to test whether our methods can generalize beyond task-oriented dialogs but also to to open-domain chatting.", "labels": [], "entities": []}, {"text": "DD contains 13,118 multi-turn human-human dialogs annotated with dialog acts and emotions.", "labels": [], "entities": []}, {"text": "(. SW has 2,400 human-human telephone conversations that are annotated with topics and dialog acts.", "labels": [], "entities": []}, {"text": "SW is a more challenging dataset because it is transcribed from speech which contains complex spoken language phenomenon, e.g. hesitation, self-repair etc.", "labels": [], "entities": [{"text": "SW", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.8183331489562988}]}], "tableCaptions": [{"text": " Table 1: Results for various discrete sentence rep- resentations. The KL for VAE is KL(q(z|x)p(z))  instead of KL(q(z)p(z)) (Zhao et al., 2017)", "labels": [], "entities": [{"text": "discrete sentence rep- resentations", "start_pos": 30, "end_pos": 65, "type": "TASK", "confidence": 0.638906466960907}, {"text": "VAE", "start_pos": 78, "end_pos": 81, "type": "METRIC", "confidence": 0.39970663189888}]}, {"text": " Table 2: DI-VAE on PTB with different latent di- mensions under the same budget.", "labels": [], "entities": [{"text": "PTB", "start_pos": 20, "end_pos": 23, "type": "DATASET", "confidence": 0.9003607630729675}]}, {"text": " Table 3. On DD, results show DI-VST", "labels": [], "entities": [{"text": "DD", "start_pos": 13, "end_pos": 15, "type": "DATASET", "confidence": 0.858082115650177}, {"text": "DI-VST", "start_pos": 30, "end_pos": 36, "type": "DATASET", "confidence": 0.5497538447380066}]}, {"text": " Table 3: Homogeneity results (bounded [0, 1]).", "labels": [], "entities": []}, {"text": " Table 4: Human evaluation results on judging the  homogeneity of latent actions in SMD.", "labels": [], "entities": [{"text": "SMD", "start_pos": 84, "end_pos": 87, "type": "TASK", "confidence": 0.9804952144622803}]}, {"text": " Table 6: Results for attribute accuracy with and  without attribute loss.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.8990662097930908}]}]}