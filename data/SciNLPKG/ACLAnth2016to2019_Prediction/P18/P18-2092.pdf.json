{"title": [{"text": "Exploiting Document Knowledge for Aspect-level Sentiment Classification", "labels": [], "entities": [{"text": "Aspect-level Sentiment Classification", "start_pos": 34, "end_pos": 71, "type": "TASK", "confidence": 0.704400380452474}]}], "abstractContent": [{"text": "Attention-based long short-term memory (LSTM) networks have proven to be useful in aspect-level sentiment classification.", "labels": [], "entities": [{"text": "aspect-level sentiment classification", "start_pos": 83, "end_pos": 120, "type": "TASK", "confidence": 0.7637700438499451}]}, {"text": "However, due to the difficulties in annotating aspect-level data, existing public datasets for this task are all relatively small, which largely limits the effectiveness of those neural models.", "labels": [], "entities": []}, {"text": "In this paper, we explore two approaches that transfer knowledge from document-level data, which is much less expensive to obtain, to improve the performance of aspect-level sentiment classification.", "labels": [], "entities": [{"text": "aspect-level sentiment classification", "start_pos": 161, "end_pos": 198, "type": "TASK", "confidence": 0.7352239092191061}]}, {"text": "We demonstrate the effectiveness of our approaches on 4 public datasets from Se-mEval 2014, 2015, and 2016, and we show that attention-based LSTM benefits from document-level knowledge in multiple ways.", "labels": [], "entities": []}], "introductionContent": [{"text": "Given a sentence and an opinion target (also called an aspect term) occurring in the sentence, aspectlevel sentiment classification aims to determine the sentiment polarity in the sentence towards the opinion target.", "labels": [], "entities": [{"text": "aspectlevel sentiment classification", "start_pos": 95, "end_pos": 131, "type": "TASK", "confidence": 0.7014955679575602}]}, {"text": "An opinion target or target for short refers to a word or a phrase describing an aspect of an entity.", "labels": [], "entities": []}, {"text": "For example, in the sentence \"This little place has acute interior decor but the prices are quite expensive\", the targets are interior decor and prices, and they are associated with positive and negative sentiment respectively.", "labels": [], "entities": []}, {"text": "A sentence may contain multiple sentimenttarget pairs, thus one challenge is to separate different opinion contexts for different targets.", "labels": [], "entities": []}, {"text": "For this purpose, state-of-the-art neural methods () adopt attention-based LSTM networks, where the LSTM aims to capture sequential patterns and the attention mechanism aims to emphasize target-specific contexts for encoding sentence representations.", "labels": [], "entities": []}, {"text": "Typically, LSTMs only show their potential when trained on large datasets.", "labels": [], "entities": []}, {"text": "However, aspect-level training data requires the annotation of all opinion targets in a sentence, which is costly to obtain in practice.", "labels": [], "entities": []}, {"text": "As such, existing public aspect-level datasets are all relatively small.", "labels": [], "entities": []}, {"text": "Insufficient training data limits the effectiveness of neural models.", "labels": [], "entities": []}, {"text": "Despite the lack of aspect-level labeled data, enormous document-level labeled data are easily accessible online such as Amazon reviews.", "labels": [], "entities": []}, {"text": "These reviews contain substantial linguistic patterns and come with sentiment labels naturally.", "labels": [], "entities": []}, {"text": "In this paper, we hypothesize that aspect-level sentiment classification can be improved by employing knowledge gained from document-level sentiment classification.", "labels": [], "entities": [{"text": "aspect-level sentiment classification", "start_pos": 35, "end_pos": 72, "type": "TASK", "confidence": 0.7214356362819672}, {"text": "document-level sentiment classification", "start_pos": 124, "end_pos": 163, "type": "TASK", "confidence": 0.6557417710622152}]}, {"text": "Specifically, we explore two transfer methods to incorporate this sort of knowledge -pretraining and multi-task learning.", "labels": [], "entities": []}, {"text": "In our experiments, we find that both methods are helpful and combining them achieves significant improvements over attentionbased LSTM models trained only on aspect-level data.", "labels": [], "entities": []}, {"text": "We also illustrate by examples that additional knowledge from document-level data is beneficial in multiple ways.", "labels": [], "entities": []}, {"text": "Our source code can be obtained from https://github.com/ ruidan/Aspect-level-sentiment.", "labels": [], "entities": []}], "datasetContent": [{"text": "We run experiments on four benchmark aspect-.", "labels": [], "entities": []}, {"text": "We derived two document-level datasets from Yelp2014 ( ) and the Amazon Electronics dataset) respectively.", "labels": [], "entities": [{"text": "Yelp2014", "start_pos": 44, "end_pos": 52, "type": "DATASET", "confidence": 0.8954827785491943}, {"text": "Amazon Electronics dataset", "start_pos": 65, "end_pos": 91, "type": "DATASET", "confidence": 0.9557138085365295}]}, {"text": "The original reviews were rated on a 5-point scale.", "labels": [], "entities": []}, {"text": "We consider 3-class classification and thus label reviews with rating < 3, > 3, and = 3 as negative, positive, and neutral respectively.", "labels": [], "entities": []}, {"text": "Each sampled dataset contains 30k instances with exactly balanced class labels.", "labels": [], "entities": []}, {"text": "We pair up an aspectlevel dataset and a document-level dataset when they are from a similar domain -the Yelp dataset is used by D1, D3, and D4 for PRET and MULT, and the Electronics dataset is only used by D2.", "labels": [], "entities": [{"text": "Yelp dataset", "start_pos": 104, "end_pos": 116, "type": "DATASET", "confidence": 0.9347666203975677}, {"text": "PRET", "start_pos": 147, "end_pos": 151, "type": "TASK", "confidence": 0.912420392036438}, {"text": "Electronics dataset", "start_pos": 170, "end_pos": 189, "type": "DATASET", "confidence": 0.9527859687805176}]}, {"text": "In all experiments, 300-dimension GloVe vectors () are used to initialize E and E when pretraining is not conducted for weight initialization.", "labels": [], "entities": [{"text": "GloVe", "start_pos": 34, "end_pos": 39, "type": "METRIC", "confidence": 0.7839789986610413}]}, {"text": "These vectors are also used for initializing E in the pretraining phase.", "labels": [], "entities": [{"text": "initializing E", "start_pos": 32, "end_pos": 46, "type": "TASK", "confidence": 0.8154115676879883}]}, {"text": "Values for hyperparameters are obtained from experiments on development sets.", "labels": [], "entities": []}, {"text": "We randomly sample 20% of the original training data from the aspectlevel dataset as the development set and only use the remaining 80% for training.", "labels": [], "entities": [{"text": "aspectlevel dataset", "start_pos": 62, "end_pos": 81, "type": "DATASET", "confidence": 0.9282926619052887}]}, {"text": "For all experiments, the dimension of LSTM hidden vectors is set to 300, \u03bb is set to 0.1, and we use dropout with probability 0.5 on sentence/document representations before the output layer.", "labels": [], "entities": []}, {"text": "We use RMSProp as the optimizer with the decay rate set to 0.9 and the base learning rate set to 0.001.", "labels": [], "entities": []}, {"text": "The mini-batch size is set to 32.", "labels": [], "entities": []}, {"text": "shows the results of LSTM, LSTM+ATT, PRET, MULT, PRET+MULT, and four representative prior works (Tang et al., 2016a,b;.", "labels": [], "entities": []}, {"text": "Significance tests are conducted for testing the robustness of methods under random parameter initialization.", "labels": [], "entities": []}, {"text": "Both accuracy and macro-F1 are used for evaluation as label distribution is unbalanced.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 5, "end_pos": 13, "type": "METRIC", "confidence": 0.9996148347854614}]}, {"text": "The reported numbers are obtained as the average value over 5 runs with random initialization for each method.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Average accuracies and Macro-F1 scores over 5 runs with random initialization. The best results  are in bold.  *  indicates that PRET+MULT is significantly better than Tang et al. (2016a), Wang et al.  (2016), Tang et al. (2016b), Chen et al. (2017), LSTM, and LSTM+ATT with p < 0.05 according to  one-tailed unpaired t-test.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 18, "end_pos": 28, "type": "METRIC", "confidence": 0.6502118110656738}, {"text": "PRET+", "start_pos": 139, "end_pos": 144, "type": "METRIC", "confidence": 0.9302525520324707}, {"text": "MULT", "start_pos": 144, "end_pos": 148, "type": "METRIC", "confidence": 0.5891201496124268}, {"text": "LSTM", "start_pos": 261, "end_pos": 265, "type": "METRIC", "confidence": 0.7733561992645264}, {"text": "LSTM+ATT", "start_pos": 271, "end_pos": 279, "type": "METRIC", "confidence": 0.788694699605306}]}, {"text": " Table 3: PRET with different transferred layers. Averaged results over 5 runs are reported.", "labels": [], "entities": [{"text": "PRET", "start_pos": 10, "end_pos": 14, "type": "TASK", "confidence": 0.8324136137962341}]}]}