{"title": [{"text": "Improved Evaluation Framework for Complex Plagiarism Detection", "labels": [], "entities": [{"text": "Improved Evaluation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7604230046272278}, {"text": "Complex Plagiarism Detection", "start_pos": 34, "end_pos": 62, "type": "TASK", "confidence": 0.6549710035324097}]}], "abstractContent": [{"text": "Plagiarism is a major issue in science and education.", "labels": [], "entities": []}, {"text": "It appears in various forms, starting from simple copying and ending with intelligent paraphrasing and summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 103, "end_pos": 116, "type": "TASK", "confidence": 0.9657760262489319}]}, {"text": "Complex plagiarism, such as plagiarism of ideas, is hard to detect, and therefore it is especially important to track improvement of methods correctly and not to overfit to the structure of particular datasets.", "labels": [], "entities": []}, {"text": "In this paper, we study the performance of plagdet, the main measure for Plagiarism Detection Systems evaluation, on manually paraphrased plagiarism datasets (such as PAN Summary).", "labels": [], "entities": [{"text": "Plagiarism Detection Systems evaluation", "start_pos": 73, "end_pos": 112, "type": "TASK", "confidence": 0.9147384166717529}, {"text": "PAN Summary", "start_pos": 167, "end_pos": 178, "type": "DATASET", "confidence": 0.7917700707912445}]}, {"text": "We reveal its fallibility under certain conditions and propose an evaluation framework with normalization of inner terms, which is resilient to the dataset imbalance.", "labels": [], "entities": []}, {"text": "We conclude with the experimental justification of the proposed measure.", "labels": [], "entities": []}, {"text": "The implementation of the new framework is made publicly available as a Github repository.", "labels": [], "entities": []}], "introductionContent": [{"text": "Plagiarism is a problem of primary concern among publishers, scientists, teachers).", "labels": [], "entities": []}, {"text": "It is not only about text copying with minor revisions but also borrowing of ideas.", "labels": [], "entities": [{"text": "text copying", "start_pos": 21, "end_pos": 33, "type": "TASK", "confidence": 0.7522237300872803}]}, {"text": "Plagiarism appears in substantially paraphrased forms and presents conscious and unconscious appropriation of others' thoughts (.", "labels": [], "entities": []}, {"text": "This kind of borrowing has very serious consequences and cannot be detected with common Plagiarism Detection Systems (PDS).", "labels": [], "entities": []}, {"text": "That is why detection of complex plagiarism cases comes to the fore and becomes a central challenge in the field.", "labels": [], "entities": [{"text": "detection of complex plagiarism cases", "start_pos": 12, "end_pos": 49, "type": "TASK", "confidence": 0.8313203096389771}]}], "datasetContent": [{"text": "PAN corpora of datasets for plagiarism text alignment is the main resource for PDS evaluation.", "labels": [], "entities": [{"text": "PAN corpora of datasets", "start_pos": 0, "end_pos": 23, "type": "DATASET", "confidence": 0.7428581863641739}, {"text": "plagiarism text alignment", "start_pos": 28, "end_pos": 53, "type": "TASK", "confidence": 0.6283867359161377}, {"text": "PDS evaluation", "start_pos": 79, "end_pos": 93, "type": "TASK", "confidence": 0.9340168535709381}]}, {"text": "This collection consists of slightly or substantially different datasets used at the PAN competitions since 2009 to 2015.", "labels": [], "entities": [{"text": "PAN competitions", "start_pos": 85, "end_pos": 101, "type": "DATASET", "confidence": 0.8157592415809631}]}, {"text": "We used the most recent 2013 () English datasets to develop and evaluate our models and metrics.", "labels": [], "entities": [{"text": "English datasets", "start_pos": 32, "end_pos": 48, "type": "DATASET", "confidence": 0.8476047217845917}]}, {"text": "They consist of copy&paste, random, translation, and summary plagiarism types.", "labels": [], "entities": []}, {"text": "We consider only the last part, as it exhibits the problems of plagdet framework to the greatest extent.", "labels": [], "entities": []}, {"text": "Standard evaluation framework for text alignment task is plagdet (, which consists of macro-and micro-averaged precision, recall, granularity and the overall plagdet score.", "labels": [], "entities": [{"text": "text alignment task", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.8427603244781494}, {"text": "plagdet", "start_pos": 57, "end_pos": 64, "type": "METRIC", "confidence": 0.9473939538002014}, {"text": "precision", "start_pos": 111, "end_pos": 120, "type": "METRIC", "confidence": 0.9297562837600708}, {"text": "recall", "start_pos": 122, "end_pos": 128, "type": "METRIC", "confidence": 0.9989056587219238}]}, {"text": "In this work, we consider only the macro-averaged metrics, where recall can be defined as follows: and precision can be defined through recall as follows: where Sand R are true plagiarism cases and system's detections, respectively.", "labels": [], "entities": [{"text": "recall", "start_pos": 65, "end_pos": 71, "type": "METRIC", "confidence": 0.9978532195091248}, {"text": "precision", "start_pos": 103, "end_pos": 112, "type": "METRIC", "confidence": 0.9994686245918274}, {"text": "recall", "start_pos": 136, "end_pos": 142, "type": "METRIC", "confidence": 0.9785152673721313}]}, {"text": "Single case recall rec single macro (s, R s ) is defined as follows: where R sis the union of all detections of a given case s.", "labels": [], "entities": []}, {"text": "The PAN Summary datasets turnout to be highly imbalanced.", "labels": [], "entities": [{"text": "PAN Summary datasets", "start_pos": 4, "end_pos": 24, "type": "DATASET", "confidence": 0.9090031782786051}, {"text": "turnout", "start_pos": 25, "end_pos": 32, "type": "METRIC", "confidence": 0.8817071914672852}]}, {"text": "\u2022 Source part of each plagiarism case takes up the whole source document:: Single case recall computation for text alignment task.", "labels": [], "entities": [{"text": "text alignment", "start_pos": 110, "end_pos": 124, "type": "TASK", "confidence": 0.8265848457813263}]}, {"text": "Note the imbalance in this case: plagiarism part s plg is much shorter than source part s src . \u2022 For any given case, its plagiarism part is much shorter than its source part 1 : As these datasets are publicly available, anyone can figure out these details and, therefore, construct an algorithm where statements 3 and 4 are true for detections R as well.", "labels": [], "entities": []}, {"text": "Let us now consider a true case s, its detections R sand its source document d src . Then single case recall for PAN Summary document will be equal to: (here we used that and s src = (R s ) src = d src ).", "labels": [], "entities": [{"text": "recall", "start_pos": 102, "end_pos": 108, "type": "METRIC", "confidence": 0.7902824282646179}, {"text": "PAN Summary document", "start_pos": 113, "end_pos": 133, "type": "DATASET", "confidence": 0.7714299956957499}]}, {"text": "Since plagiarism part s plg of the case sis much shorter than source document d src , the term |d src | dominates numerator and denominator in eq.", "labels": [], "entities": []}, {"text": "5, which results in inadequately high documentlevel precision and recall on PAN Summary datasets.", "labels": [], "entities": [{"text": "precision", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.9774282574653625}, {"text": "recall", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.999297022819519}, {"text": "PAN Summary datasets", "start_pos": 76, "end_pos": 96, "type": "DATASET", "confidence": 0.6581153174241384}]}, {"text": "Other datasets for manual plagiarism detection display the similar properties, however, not to the PAN Summary extent.", "labels": [], "entities": [{"text": "manual plagiarism detection", "start_pos": 19, "end_pos": 46, "type": "TASK", "confidence": 0.6179635524749756}]}, {"text": "Examples include: Palkovskii15,.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results of Summary Plagiarism Detection using Plagdet  Dataset  Model  Year  Precision Recall  Plagdet", "labels": [], "entities": [{"text": "Summary Plagiarism Detection", "start_pos": 21, "end_pos": 49, "type": "TASK", "confidence": 0.9252338608105978}]}, {"text": " Table 2: Results of Summary Plagiarism Detection using NormPlagdet  Dataset  Model  Year  Precision Recall  Plagdet", "labels": [], "entities": [{"text": "Summary Plagiarism Detection", "start_pos": 21, "end_pos": 49, "type": "TASK", "confidence": 0.9256867369016012}, {"text": "NormPlagdet  Dataset  Model  Year  Precision Recall  Plagdet", "start_pos": 56, "end_pos": 116, "type": "DATASET", "confidence": 0.8635768464633397}]}]}