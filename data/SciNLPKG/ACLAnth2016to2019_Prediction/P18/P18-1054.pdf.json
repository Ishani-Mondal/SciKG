{"title": [{"text": "Entity-Centric Joint Modeling of Japanese Coreference Resolution and Predicate Argument Structure Analysis", "labels": [], "entities": [{"text": "Entity-Centric Joint Modeling of Japanese Coreference Resolution", "start_pos": 0, "end_pos": 64, "type": "TASK", "confidence": 0.5525887863976615}, {"text": "Predicate Argument Structure Analysis", "start_pos": 69, "end_pos": 106, "type": "TASK", "confidence": 0.6820799335837364}]}], "abstractContent": [{"text": "Predicate argument structure analysis is a task of identifying structured events.", "labels": [], "entities": [{"text": "Predicate argument structure analysis", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8275556266307831}]}, {"text": "To improve this field, we need to identify a salient entity, which cannot be identified without performing coreference resolution and predicate argument structure analysis simultaneously.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 107, "end_pos": 129, "type": "TASK", "confidence": 0.8820580244064331}]}, {"text": "This paper presents an entity-centric joint model for Japanese coreference resolution and predicate argument structure analysis.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 63, "end_pos": 85, "type": "TASK", "confidence": 0.8262853622436523}, {"text": "predicate argument structure analysis", "start_pos": 90, "end_pos": 127, "type": "TASK", "confidence": 0.8426233977079391}]}, {"text": "Each entity is assigned an embedding, and when the result of both analyses refers to an entity, the entity embedding is updated.", "labels": [], "entities": []}, {"text": "The analyses take the entity embedding into consideration to access the global information of entities.", "labels": [], "entities": []}, {"text": "Our experimental results demonstrate the proposed method can improve the performance of the inter-sentential zero anaphora resolution drastically , which is a notoriously difficult task in predicate argument structure analysis.", "labels": [], "entities": [{"text": "inter-sentential zero anaphora resolution", "start_pos": 92, "end_pos": 133, "type": "TASK", "confidence": 0.6456784978508949}, {"text": "predicate argument structure analysis", "start_pos": 189, "end_pos": 226, "type": "TASK", "confidence": 0.840863436460495}]}], "introductionContent": [{"text": "Natural language often conveys a sequence of events like \"who did what to whom\", and extracting structured events from the raw text is a kind of touchstone for machine reading.", "labels": [], "entities": [{"text": "machine reading", "start_pos": 160, "end_pos": 175, "type": "TASK", "confidence": 0.8074817061424255}]}, {"text": "This is realized by a combination of coreference resolution (called CR, hereafter) and predicate argument structure analysis (called PA, hereafter).", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 37, "end_pos": 59, "type": "TASK", "confidence": 0.8619543612003326}, {"text": "predicate argument structure analysis", "start_pos": 87, "end_pos": 124, "type": "TASK", "confidence": 0.6519139185547829}, {"text": "PA", "start_pos": 133, "end_pos": 135, "type": "METRIC", "confidence": 0.957064688205719}]}, {"text": "The characteristics and difficulties in the analyses vary among languages.", "labels": [], "entities": []}, {"text": "In English, there are few omissions of arguments, and thus PA is relatively easy, around 83% accuracy ( , while CR is relatively difficult, around 70% accuracy ( . On the other hand, in Japanese and Chinese, where arguments are often omitted, PA is a difficult task, and even state-of-the-art systems only achieve around 50% accuracy.", "labels": [], "entities": [{"text": "PA", "start_pos": 59, "end_pos": 61, "type": "METRIC", "confidence": 0.9428433179855347}, {"text": "accuracy", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.999064028263092}, {"text": "CR", "start_pos": 112, "end_pos": 114, "type": "METRIC", "confidence": 0.9898321628570557}, {"text": "accuracy", "start_pos": 151, "end_pos": 159, "type": "METRIC", "confidence": 0.998506486415863}, {"text": "PA", "start_pos": 243, "end_pos": 245, "type": "TASK", "confidence": 0.9105640649795532}, {"text": "accuracy", "start_pos": 325, "end_pos": 333, "type": "METRIC", "confidence": 0.9937934875488281}]}, {"text": "Zero anaphora resolution (ZAR) is a difficult subtask of PA, detecting a zero pronoun and identifying a referent of the zero pronoun.", "labels": [], "entities": [{"text": "Zero anaphora resolution (ZAR)", "start_pos": 0, "end_pos": 30, "type": "METRIC", "confidence": 0.6083501825730006}]}, {"text": "As the following example shows, CR in English (identifying the antecedent of it) and ZAR in Japanese (identifying the omitted nominative argument) are similar problems.", "labels": [], "entities": [{"text": "CR", "start_pos": 32, "end_pos": 34, "type": "METRIC", "confidence": 0.9858490228652954}, {"text": "ZAR", "start_pos": 85, "end_pos": 88, "type": "METRIC", "confidence": 0.9873539805412292}]}, {"text": "John bought a car last month.", "labels": [], "entities": []}, {"text": "It was made by Toyota. b. John-TOP last month a car-ACC bought.", "labels": [], "entities": [{"text": "Toyota. b. John-TOP", "start_pos": 15, "end_pos": 34, "type": "DATASET", "confidence": 0.7117786010106405}]}, {"text": "() (\u03d5-NOM) Toyota made-COPULA.", "labels": [], "entities": []}, {"text": "Note that CR such as the relation between \"the company\" and \"Toyota\" is also difficult in Japanese.", "labels": [], "entities": []}, {"text": "According to the argument position relative to the predicate, ZAR is classified into the following three types: \u2022 intra-sentential (intra in short): an argument is located in the same sentence with the predicate \u2022 inter-sentential (inter in short): an argument is located in the preceding sentences, such as \"\" for \"\" (Toyota made-COPULA) in sentence (1b) \u2022 exophora: an argument does not appear in a document, such as author and reader Among these three types, the analysis of inter is extremely difficult because there are many candidates in preceding sentences, and clues such as a dependency path between a predicate and an argument cannot be used.", "labels": [], "entities": []}, {"text": "This paper presents a joint model of CR and PA in Japanese.", "labels": [], "entities": [{"text": "CR and PA", "start_pos": 37, "end_pos": 46, "type": "TASK", "confidence": 0.6319734354813894}]}, {"text": "It is necessary to perform them together because PA (especially inter-sentential ZAR) needs to identify salient entities, which cannot be identified without performing CR and PA simultaneously.", "labels": [], "entities": []}, {"text": "Our results support this claim, and suggest that the status quo of PA-exclusive research in Japanese is an insufficient approach.", "labels": [], "entities": []}, {"text": "Our work is inspired by, which described an English CR system, where entities are represented by embeddings, and they are updated by CR results dynamically.", "labels": [], "entities": []}, {"text": "We perform Japanese CR and PA by extending this idea.", "labels": [], "entities": [{"text": "Japanese CR", "start_pos": 11, "end_pos": 22, "type": "TASK", "confidence": 0.4784371852874756}, {"text": "PA", "start_pos": 27, "end_pos": 29, "type": "METRIC", "confidence": 0.873745322227478}]}, {"text": "Our experimental results demonstrate the proposed method can improve the performance of the inter-sentential zero anaphora resolution drastically.", "labels": [], "entities": [{"text": "inter-sentential zero anaphora resolution", "start_pos": 92, "end_pos": 133, "type": "TASK", "confidence": 0.5992593392729759}]}], "datasetContent": [{"text": "The two kinds of evaluation sets were used for our experiments.", "labels": [], "entities": []}, {"text": "One is the KWDLC (Kyoto Uni-versity Web Document Leads Corpus) evaluation set (, and the other is Kyoto Corpus.", "labels": [], "entities": [{"text": "KWDLC (Kyoto Uni-versity Web Document Leads Corpus) evaluation set", "start_pos": 11, "end_pos": 77, "type": "DATASET", "confidence": 0.8400215560739691}, {"text": "Kyoto Corpus", "start_pos": 98, "end_pos": 110, "type": "DATASET", "confidence": 0.991829514503479}]}, {"text": "KWDLC consists of the first three sentences of 5,000 Web documents (15,000 sentences) and Kyoto Corpus consists of 550 News documents (5,000 sentences).", "labels": [], "entities": [{"text": "KWDLC", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9341538548469543}, {"text": "Kyoto Corpus", "start_pos": 90, "end_pos": 102, "type": "DATASET", "confidence": 0.9742391109466553}]}, {"text": "Word segmentations, POSs, dependencies, PASs, and coreferences were manually annotated (the closest referents and antecedents were annotated for zero anaphora and coreferences, respectively).", "labels": [], "entities": [{"text": "Word segmentations", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.6402819901704788}]}, {"text": "Since we want to focus on the accuracy of CR and PA, gold segmentations, POSs, and dependencies were used.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9992514252662659}, {"text": "PA", "start_pos": 49, "end_pos": 51, "type": "METRIC", "confidence": 0.6419482231140137}, {"text": "POSs", "start_pos": 73, "end_pos": 77, "type": "METRIC", "confidence": 0.9439406394958496}]}, {"text": "KWDLC (Web) was divided into 3,694 documents (11,558 sents.) for training, 512 documents (1,585 sents.) for development, and 700 documents (2,195 sents.) for testing; Kyoto Corpus (News) was divided into 360 documents (3,210 sents.) for training, 98 documents (971 sents.) for development, and 100 documents (967 sents.) for testing.", "labels": [], "entities": [{"text": "KWDLC (Web)", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.8885858356952667}, {"text": "Kyoto Corpus (News)", "start_pos": 167, "end_pos": 186, "type": "DATASET", "confidence": 0.9623196959495545}]}, {"text": "The evaluation measure is an F-measure, and the evaluation of both CR and PA was relaxed using a gold coreference chain, which leads to an entity-based evaluation.", "labels": [], "entities": [{"text": "PA", "start_pos": 74, "end_pos": 76, "type": "METRIC", "confidence": 0.818433940410614}]}, {"text": "We did not use the conventional CR evaluation measures (MUC, B 3 , CEAF and CoNLL) because our F-measure is almost the same as MUC, which is a link-based measure, and the other measures considering singletons get excessively high values 6 , and thus they do not accord with the actual performance in our setting.", "labels": [], "entities": [{"text": "CoNLL", "start_pos": 76, "end_pos": 81, "type": "METRIC", "confidence": 0.8194297552108765}, {"text": "F-measure", "start_pos": 95, "end_pos": 104, "type": "METRIC", "confidence": 0.9682014584541321}]}, {"text": "The following three methods were compared: \u2022 Baseline: the method described in Section 5.", "labels": [], "entities": []}, {"text": "\u2022 \"+entity (CR)\": this method corresponds to.", "labels": [], "entities": []}, {"text": "Entity embedding is updated based on the CR result, and CR takes the entity embedding into consideration.", "labels": [], "entities": [{"text": "CR", "start_pos": 56, "end_pos": 58, "type": "METRIC", "confidence": 0.8663830757141113}]}, {"text": "\u2022 \"+entity (CR,PA)\" (proposed method): entity embedding is updated based on PA as well as CR result, and the CR and PA take the entity embedding into consideration.", "labels": [], "entities": []}, {"text": "The performance of CR and PA (case analysis and zero anaphora resolution (ZAR)) is shown in.", "labels": [], "entities": [{"text": "CR", "start_pos": 19, "end_pos": 21, "type": "METRIC", "confidence": 0.9297856688499451}, {"text": "PA", "start_pos": 26, "end_pos": 28, "type": "METRIC", "confidence": 0.9899590611457825}, {"text": "zero anaphora resolution (ZAR))", "start_pos": 48, "end_pos": 79, "type": "METRIC", "confidence": 0.8251236180464426}]}, {"text": "The performance of CR and case analysis was almost the same for all the methods.", "labels": [], "entities": [{"text": "CR", "start_pos": 19, "end_pos": 21, "type": "TASK", "confidence": 0.9682818055152893}, {"text": "case analysis", "start_pos": 26, "end_pos": 39, "type": "TASK", "confidence": 0.8264623284339905}]}, {"text": "For ZAR, \"+entity (CR,PA)\" improved the performance drastically.", "labels": [], "entities": []}, {"text": "CR surely benefits from the entity salience.", "labels": [], "entities": []}, {"text": "Since entity embeddings are updated based on system outputs, its performance matters.", "labels": [], "entities": []}, {"text": "The performance of Japanese CR is lower than that of English CR.", "labels": [], "entities": [{"text": "Japanese CR", "start_pos": 19, "end_pos": 30, "type": "TASK", "confidence": 0.5746274590492249}]}, {"text": "Therefore, we assume there are improved/worsen examples, and our CR performance did not improve significantly.", "labels": [], "entities": [{"text": "CR", "start_pos": 65, "end_pos": 67, "type": "METRIC", "confidence": 0.9884048700332642}]}, {"text": "The performance of ZAR also matters.", "labels": [], "entities": [{"text": "ZAR", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.5193161964416504}]}, {"text": "However, the performance of ZAR in our baseline model is extremely low, and thus there are few worsen examples and   a number of improved examples.", "labels": [], "entities": [{"text": "ZAR", "start_pos": 28, "end_pos": 31, "type": "METRIC", "confidence": 0.7183991074562073}]}, {"text": "Therefore, ZAR can benefit from the entity representation obtained by both CR and PA.", "labels": [], "entities": []}, {"text": "shows performance of case analysis and zero anaphora resolution for each case, and each argument position.", "labels": [], "entities": [{"text": "case analysis", "start_pos": 21, "end_pos": 34, "type": "TASK", "confidence": 0.8286517858505249}]}, {"text": "Unspecified was counted for exophora.", "labels": [], "entities": []}, {"text": "Both for the News and Web evaluation sets, the performance for inter arguments of zero anaphora resolution, which was extremely difficult in the baseline method, was improved by a large margin by our proposed method.", "labels": [], "entities": [{"text": "News and Web evaluation sets", "start_pos": 13, "end_pos": 41, "type": "DATASET", "confidence": 0.7632197856903076}]}], "tableCaptions": [{"text": " Table 1: Performance (F-measure) of coreference resolution, case analysis and zero anaphora resolution.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9500875473022461}, {"text": "coreference resolution", "start_pos": 37, "end_pos": 59, "type": "TASK", "confidence": 0.9627807438373566}]}, {"text": " Table 2: Performance of case analysis and zero anaphora resolution for each case, and each argument  position for zero anaphora resolution. The underlined values indicate the proposed method outperforms  the baseline by a large margin.", "labels": [], "entities": [{"text": "case analysis", "start_pos": 25, "end_pos": 38, "type": "TASK", "confidence": 0.8484208285808563}]}, {"text": " Table 3: Ablation study on the development set. The cells shaded gray represent they are not directly  affected from the ablation, but from the counterpart analysis result.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9442053437232971}]}]}