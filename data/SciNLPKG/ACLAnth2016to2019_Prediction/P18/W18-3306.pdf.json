{"title": [{"text": "Polarity and Intensity: the Two Aspects of Sentiment Analysis", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 43, "end_pos": 61, "type": "TASK", "confidence": 0.9649533033370972}]}], "abstractContent": [{"text": "Current multimodal sentiment analysis frames sentiment score prediction as a general Machine Learning task.", "labels": [], "entities": [{"text": "multimodal sentiment analysis", "start_pos": 8, "end_pos": 37, "type": "TASK", "confidence": 0.7293148636817932}, {"text": "sentiment score prediction", "start_pos": 45, "end_pos": 71, "type": "TASK", "confidence": 0.8558196028073629}]}, {"text": "However , what the sentiment score actually represents has often been overlooked.", "labels": [], "entities": []}, {"text": "As a measurement of opinions and affective states, a sentiment score generally consists of two aspects: polarity and intensity.", "labels": [], "entities": []}, {"text": "We decompose sentiment scores into these two aspects and study how they are conveyed through individual modalities and combined multimodal models in a natu-ralistic monologue setting.", "labels": [], "entities": []}, {"text": "In particular, we build unimodal and multimodal multi-task learning models with sentiment score prediction as the main task and polarity and/or intensity classification as the auxiliary tasks.", "labels": [], "entities": [{"text": "sentiment score prediction", "start_pos": 80, "end_pos": 106, "type": "TASK", "confidence": 0.6289560496807098}]}, {"text": "Our experiments show that sentiment analysis benefits from multi-task learning, and individual modalities differ when conveying the polarity and intensity aspects of sentiment.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.9595474004745483}]}], "introductionContent": [{"text": "Computational analysis of human multimodal language is a growing research area in Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "Computational analysis of human multimodal language", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.8763131300608317}, {"text": "Natural Language Processing (NLP)", "start_pos": 82, "end_pos": 115, "type": "TASK", "confidence": 0.7040375967820486}]}, {"text": "One important type of information communicated through human multimodal language is sentiment.", "labels": [], "entities": []}, {"text": "Current NLP studies often define sentiments using scores on a scale, e.g., a 5-point Likert scale representing sentiments from strongly negative to strongly positive.", "labels": [], "entities": []}, {"text": "Previous work on multimodal sentiment analysis has focused on identifying effective approaches for sentiment score prediction (e.g.,).", "labels": [], "entities": [{"text": "multimodal sentiment analysis", "start_pos": 17, "end_pos": 46, "type": "TASK", "confidence": 0.7745842734972636}, {"text": "sentiment score prediction", "start_pos": 99, "end_pos": 125, "type": "TASK", "confidence": 0.7963828047116598}]}, {"text": "However, in these studies sentiment score prediction is typically represented as a regression or classification task, without taking into account what the sentiment score means.", "labels": [], "entities": [{"text": "sentiment score prediction", "start_pos": 26, "end_pos": 52, "type": "TASK", "confidence": 0.8603914777437845}]}, {"text": "As a measurement of human opinions and affective states, a sentiment score can often be decomposed into two aspects: the polarity and intensity of the sentiment.", "labels": [], "entities": []}, {"text": "In this work, we study how individual modalities and multimodal information convey these two aspects of sentiment.", "labels": [], "entities": []}, {"text": "More specifically, we conduct experiments on the Carnegie Mellon University Multimodal Opinion Sentiment Intensity (CMU-MOSI) database ().", "labels": [], "entities": [{"text": "Carnegie Mellon University Multimodal Opinion Sentiment Intensity (CMU-MOSI)", "start_pos": 49, "end_pos": 125, "type": "TASK", "confidence": 0.6083662569522857}]}, {"text": "The CMU-MOSI database is a widely used benchmark database for multimodal sentiment analysis.", "labels": [], "entities": [{"text": "CMU-MOSI database", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.9048379361629486}, {"text": "multimodal sentiment analysis", "start_pos": 62, "end_pos": 91, "type": "TASK", "confidence": 0.7527211507161459}]}, {"text": "It contains naturalistic monologues expressing opinions on various subjects.", "labels": [], "entities": []}, {"text": "Sentiments are annotated as continuous scores for each opinion segment in the CMU-MOSI database, and data were collected over the vocal, visual, and verbal modalities.", "labels": [], "entities": [{"text": "CMU-MOSI database", "start_pos": 78, "end_pos": 95, "type": "DATASET", "confidence": 0.9709794223308563}]}, {"text": "We build unimodal and multimodal multi-task learning models with sentiment score regression as the main task, and polarity and/or intensity classification as the auxiliary tasks.", "labels": [], "entities": []}, {"text": "Our main research questions are: 1.", "labels": [], "entities": []}, {"text": "Does sentiment score prediction benefit from multi-task learning?", "labels": [], "entities": [{"text": "sentiment score prediction", "start_pos": 5, "end_pos": 31, "type": "TASK", "confidence": 0.7791182398796082}]}, {"text": "2. Do individual modalities convey the polarity and intensity of sentiment differently?", "labels": [], "entities": []}, {"text": "3. Does multi-task learning influence unimodal and multimodal sentiment analysis models in different ways?", "labels": [], "entities": [{"text": "multimodal sentiment analysis", "start_pos": 51, "end_pos": 80, "type": "TASK", "confidence": 0.6385178367296854}]}, {"text": "Our work contributes to our current understanding of the intra-modal and inter-modal dynamics of how sentiments are communicated inhuman multimodal language.", "labels": [], "entities": []}, {"text": "Moreover, our study provides detailed analysis on how multi-task learning and modality fusion influences sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 105, "end_pos": 123, "type": "TASK", "confidence": 0.9654225409030914}]}], "datasetContent": [{"text": "Here we report our sentiment score prediction experiments.", "labels": [], "entities": [{"text": "sentiment score prediction", "start_pos": 19, "end_pos": 45, "type": "TASK", "confidence": 0.8458243608474731}]}, {"text": "In, \"S\" is the singletask learning model; \"S+P\" is the bi-task learning model with polarity classification as the auxillary task; \"S+I\" is the bi-task learning model with intensity classification as the auxillary task; \"S+P+I\" is the tri-task learning model.", "labels": [], "entities": []}, {"text": "To evaluate the performance of sentiment score prediction, following previous work (Zadeh et al., 2018a), we, the numbers in bold are the best performance for each modality or fusion strategy.", "labels": [], "entities": [{"text": "sentiment score prediction", "start_pos": 31, "end_pos": 57, "type": "TASK", "confidence": 0.8539090752601624}]}, {"text": "To identify the significant differences in results, we perform a two-sample Wilcoxon test on the sentiment score predictions given by each pair of models being compared and consider p < 0.05 as significant.", "labels": [], "entities": []}, {"text": "We also include random prediction as a baseline and the human performance reported by .  The results of unimodal sentiment prediction experiments are shown in.", "labels": [], "entities": [{"text": "unimodal sentiment prediction", "start_pos": 104, "end_pos": 133, "type": "TASK", "confidence": 0.7125097910563151}]}, {"text": "The verbal models have the best performance here, which is consistent with previous sentiment analysis studies on multiple databases (e.g.,).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 84, "end_pos": 102, "type": "TASK", "confidence": 0.8851394057273865}]}, {"text": "This suggests that lexical information remains the most effective for sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 70, "end_pos": 88, "type": "TASK", "confidence": 0.9714438915252686}]}, {"text": "On each modality, the best performance is achieved by a multi-task learning model.", "labels": [], "entities": []}, {"text": "This answers our first research question and suggests that sentiment analysis can benefit from multi-task learning.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.9810050129890442}]}, {"text": "In multi-task learning, the main task gains additional information from the auxillary tasks.", "labels": [], "entities": []}, {"text": "Compared to the S model, the S+P model has increased focus on the polarity of sentiment, while the S+I model has increased focus on the intensity of sentiment.", "labels": [], "entities": []}, {"text": "On the verbal modality, the S+P model achieved the best performance, while on the visual modality the S+I model achieved the best performance.", "labels": [], "entities": []}, {"text": "This suggests that the verbal modality is weaker at communicating the polarity of sentiment.", "labels": [], "entities": []}, {"text": "Thus, verbal sentiment analysis benefits more from including additional information on polarity.", "labels": [], "entities": [{"text": "verbal sentiment analysis", "start_pos": 6, "end_pos": 31, "type": "TASK", "confidence": 0.8274351358413696}]}, {"text": "On the contrary, the visual modality is weaker at communicating the intensity of sentiment.", "labels": [], "entities": [{"text": "communicating the intensity of sentiment", "start_pos": 50, "end_pos": 90, "type": "TASK", "confidence": 0.7310283780097961}]}, {"text": "Thus, visual sentiment analysis benefits more from including additional information on intensity.", "labels": [], "entities": [{"text": "visual sentiment analysis", "start_pos": 6, "end_pos": 31, "type": "TASK", "confidence": 0.794818123181661}]}, {"text": "For the vocal modality, the S+P+I model achieved the best performance, and the S+P model yielded improved performance over that of the S model.", "labels": [], "entities": []}, {"text": "This suggests that the vocal modality is weaker at communicating the polarity of sentiment.", "labels": [], "entities": []}, {"text": "Thus, addressing our second research question, the results suggest that individual modalities differ when conveying each aspect of sentiment.: Unimodal sentiment analysis results on the CMU-MOSI test set.", "labels": [], "entities": [{"text": "Unimodal sentiment analysis", "start_pos": 143, "end_pos": 170, "type": "TASK", "confidence": 0.7864068746566772}, {"text": "CMU-MOSI test set", "start_pos": 186, "end_pos": 203, "type": "DATASET", "confidence": 0.9697633584340414}]}, {"text": "Numbers in bold are the best results on each modality.", "labels": [], "entities": []}, {"text": "The results of the multimodal experiments are shown in.", "labels": [], "entities": []}, {"text": "We find that EF>HF>TFN>LF.", "labels": [], "entities": [{"text": "EF", "start_pos": 13, "end_pos": 15, "type": "METRIC", "confidence": 0.9253038763999939}]}, {"text": "The reason that the EF model yields the best performance maybe that it is the least complex.", "labels": [], "entities": []}, {"text": "This is shown to be beneficial for the small CMU-MOSI database (.", "labels": [], "entities": [{"text": "CMU-MOSI database", "start_pos": 45, "end_pos": 62, "type": "DATASET", "confidence": 0.8973340094089508}]}, {"text": "Unlike , here the EF model outperforms the TFN model.", "labels": [], "entities": []}, {"text": "However, the TFN model achieved the best performance on the training and validation sets.", "labels": [], "entities": []}, {"text": "This indicates that performance of the TFN model maybe limited by over-fitting.", "labels": [], "entities": [{"text": "TFN", "start_pos": 39, "end_pos": 42, "type": "DATASET", "confidence": 0.7866030335426331}]}, {"text": "Compared to the feature concatenation used in EF, the Cartesian product used in TFN results in higher dimensionality of the multimodal input vector, 5 which in turn increases the complexity of the model.", "labels": [], "entities": []}, {"text": "Similarly, the HF model has worse performance than the EF model here, unlike in.", "labels": [], "entities": []}, {"text": "This maybe due to the HF model having the deepest structure with the most hidden layers, which increases its complexity.", "labels": [], "entities": []}, {"text": "The performance of unimodal and multimodal models are significantly different.", "labels": [], "entities": []}, {"text": "In general, the multimodal models have better performance than the unimodal models.", "labels": [], "entities": []}, {"text": "Unlike unimodal models, multimodal models benefit less from multi-task learning.", "labels": [], "entities": []}, {"text": "In fact, the HF and LF models have better performance using single-task learning.", "labels": [], "entities": []}, {"text": "For the TFN models, only the S+P model outperforms the S model, although the improvement is not significant.", "labels": [], "entities": [{"text": "TFN", "start_pos": 8, "end_pos": 11, "type": "DATASET", "confidence": 0.8257409334182739}]}, {"text": "For the EF models, multi-task learning results in better performance.", "labels": [], "entities": []}, {"text": "The reason that EF benefits from multi-task learning maybe that it combines modalities without bias and individual features have more influence on the EF model.", "labels": [], "entities": []}, {"text": "Thus, the benefit of multi-task learning is preserved in EF.", "labels": [], "entities": []}, {"text": "However, the other fusion strategies (TFN, LF, HF) attempt to compensate one modality with information from other modalities, i.e., relying more on other modalities when one modality is weaker at predicting an aspect of sentiment.", "labels": [], "entities": [{"text": "predicting an aspect of sentiment", "start_pos": 196, "end_pos": 229, "type": "TASK", "confidence": 0.8154771208763123}]}, {"text": "In Section 4.1 we showed that each modality has different weaknesses when conveying the polarity or intensity aspect of sentiment.", "labels": [], "entities": []}, {"text": "The multimodal models are able to overcome such weaknesses by modality fusion.", "labels": [], "entities": []}, {"text": "Thus, multi-task learning does not yield additional improvement in these models.", "labels": [], "entities": []}, {"text": "Our observations answer our third research question: multi-task learning influences unimodal and multimodal sentiment analysis differently.: Multimodal sentiment analysis results on the CMU-MOSI test set.", "labels": [], "entities": [{"text": "multimodal sentiment analysis", "start_pos": 97, "end_pos": 126, "type": "TASK", "confidence": 0.6607610285282135}, {"text": "Multimodal sentiment analysis", "start_pos": 141, "end_pos": 170, "type": "TASK", "confidence": 0.7799998919169108}, {"text": "CMU-MOSI test set", "start_pos": 186, "end_pos": 203, "type": "DATASET", "confidence": 0.9752903779347738}]}, {"text": "Numbers in bold are the best results for each fusion strategy in each row.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Unimodal sentiment analysis results on  the CMU-MOSI test set. Numbers in bold are the  best results on each modality.", "labels": [], "entities": [{"text": "Unimodal sentiment analysis", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.8703067302703857}, {"text": "CMU-MOSI test set", "start_pos": 54, "end_pos": 71, "type": "DATASET", "confidence": 0.9756951332092285}]}, {"text": " Table 3: Multimodal sentiment analysis results on  the CMU-MOSI test set. Numbers in bold are the  best results for each fusion strategy in each row.", "labels": [], "entities": [{"text": "Multimodal sentiment analysis", "start_pos": 10, "end_pos": 39, "type": "TASK", "confidence": 0.791421115398407}, {"text": "CMU-MOSI test set", "start_pos": 56, "end_pos": 73, "type": "DATASET", "confidence": 0.9689701596895853}]}]}