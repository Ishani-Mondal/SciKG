{"title": [{"text": "LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modeling Structure Makes Them Better", "labels": [], "entities": []}], "abstractContent": [{"text": "Language exhibits hierarchical structure, but recent work using a subject-verb agreement diagnostic argued that state-of-the-art language models, LSTMs, fail to learn long-range syntax-sensitive dependencies.", "labels": [], "entities": []}, {"text": "Using the same diagnostic, we show that, in fact, LSTMs do succeed in learning such dependencies-provided they have enough capacity.", "labels": [], "entities": []}, {"text": "We then explore whether models that have access to explicit syntactic information learn agreement more effectively, and how the way in which this structural information is incorporated into the model impacts performance.", "labels": [], "entities": []}, {"text": "We find that the mere presence of syntactic information does not improve accuracy , but when model architecture is determined by syntax, number agreement is improved.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9991808533668518}]}, {"text": "Further, we find that the choice of how syntactic structure is built affects how well number agreement is learned: top-down construction outperforms left-corner and bottom-up variants in capturing long-distance structural dependencies.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recurrent neural networks (RNNs) are remarkably effective models of sequential data.", "labels": [], "entities": []}, {"text": "Recent years have witnessed the widespread adoption of recurrent architectures such as LSTMs) in various NLP tasks, with state of the art results in language modeling ( ) and conditional generation tasks like machine translation () and text summarization (.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 149, "end_pos": 166, "type": "TASK", "confidence": 0.7169714570045471}, {"text": "machine translation", "start_pos": 209, "end_pos": 228, "type": "TASK", "confidence": 0.7787788510322571}, {"text": "text summarization", "start_pos": 236, "end_pos": 254, "type": "TASK", "confidence": 0.7728376984596252}]}, {"text": "Here we revisit the question asked by: as RNNs model word sequences without explicit notions of hierarchical structure,: An example of the number agreement task with two attractors and a subject-verb distance of five.", "labels": [], "entities": []}, {"text": "to what extent are these models able to learn non-local syntactic dependencies in natural language?", "labels": [], "entities": []}, {"text": "Identifying number agreement between subjects and verbs-especially in the presence of attractors-can be understood as a cognitivelymotivated probe that seeks to distinguish hierarchical theories from sequential ones, as models that rely on sequential cues like the most recent noun would favor the incorrect verb form.", "labels": [], "entities": [{"text": "Identifying number agreement between subjects and verbs-especially in the presence of attractors-can", "start_pos": 0, "end_pos": 100, "type": "TASK", "confidence": 0.8267563084761301}]}, {"text": "We provide an example of this task in, where the plural form of the verb have agrees with the distant subject parts, rather than the adjacent attractors (underlined) of the singular form.", "labels": [], "entities": []}, {"text": "Contrary to the findings of, our experiments suggest that sequential LSTMs are able to capture structural dependencies to a large extent, even for cases with multiple attractors ( \u00a72).", "labels": [], "entities": []}, {"text": "Our finding suggests that network capacity plays a crucial role in capturing structural dependencies with multiple attractors.", "labels": [], "entities": []}, {"text": "Nevertheless, we find that a strong character LSTM language model-which lacks explicit word representation and has to capture much longer sequential dependencies in order to learn non-local structural dependencies effectively-performs much worse in the number agreement task.", "labels": [], "entities": []}, {"text": "Given the strong performance of word-based LSTM language models, are there are any substantial benefits, in terms of number agreement accuracy, to explicitly modeling hierarchical structures as an inductive bias?", "labels": [], "entities": [{"text": "accuracy", "start_pos": 134, "end_pos": 142, "type": "METRIC", "confidence": 0.7758718132972717}]}, {"text": "We discover that a certain class of LSTM language models that explicitly models syntactic structures, the recurrent neural network grammars (, considerably outperforms sequential LSTM language models for cases with multiple attractors ( \u00a73).", "labels": [], "entities": []}, {"text": "We present experiments affirming that this gain is due to an explicit composition operator rather than the presence of predicted syntactic annotations.", "labels": [], "entities": []}, {"text": "Rather surprisingly, syntactic LSTM language models without explicit composition have no advantage over sequential LSTMs that operate on word sequences, although these models can nevertheless be excellent predictors of phrase structures.", "labels": [], "entities": []}, {"text": "Having established the importance of modeling structures, we explore the hypothesis that how we build the structure affects the model's ability to identify structural dependencies in English.", "labels": [], "entities": []}, {"text": "As RNNGs build phrase-structure trees through top-down operations, we propose extensions to the structure-building sequences and model architecture that enable left-corner) and bottom-up) generation orders ( \u00a74).", "labels": [], "entities": []}, {"text": "Extensive prior work has characterized topdown, left-corner, and bottom-up parsing strategies in terms of cognitive plausibility and neurophysiological evidence inhuman sentence processing).", "labels": [], "entities": []}, {"text": "Here we move away from the realm of parsing and evaluate the three strategies as models of generation instead, and address the following empirical question: which generation order is most appropriately biased to model structural dependencies in English, as indicated by number agreement accuracy?", "labels": [], "entities": []}, {"text": "Our key finding is that the top-down generation outperforms left-corner and bottom-up variants for difficult cases with multiple attractors.", "labels": [], "entities": []}, {"text": "In theory, the three traversal strategies approximate the same chain rule that decompose the joint probability of words and phrase-structure trees, denoted as p(x, y), differently and as such will impose different biases on the learner.", "labels": [], "entities": []}, {"text": "In \u00a74.3, we show that the three variants achieve similar perplexities on a held-out validation set.", "labels": [], "entities": []}, {"text": "As we observe different patterns in number agreement, this demonstrates that while perplexity can be a useful diagnostic tool, it may not be sensitive enough for comparing models in terms of how well they capture grammatical intuitions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We optimize the hyper-parameters of each RNNG variant using grid searches based on validation set perplexity.: Number agreement error rates for topdown (TD), left-corner (LC), and bottom-up (BU) RNNGs, broken down by the number of attractors.", "labels": [], "entities": [{"text": "Number agreement error rates", "start_pos": 111, "end_pos": 139, "type": "METRIC", "confidence": 0.8921235203742981}]}, {"text": "LM indicates the best sequential language model baseline ( \u00a72).", "labels": [], "entities": []}, {"text": "We report the mean, standard deviation, and minimum/maximum of 10 different random seeds of each model.", "labels": [], "entities": []}, {"text": "action adds the open nonterminal symbol (X to the stack, followed by a deterministic swap operator that swaps the top two elements on the stack.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Number agreement error rates for vari- ous LSTM language models, broken down by the  number of attractors. The top two rows represent  the random and majority class baselines, while the  next row (  \u2020 ) is the reported result from Linzen  et al. (2016) for an LSTM language model with  50 hidden units (some entries, denoted by \u2248, are  approximately derived from a chart, since Linzen  et al. (2016) did not provide a full table of results).  We report results of our LSTM implementations of  various hidden layer sizes, along with our re-run of  the Jozefowicz et al. (2016) language model, in the  next five rows. We lastly report the performance of  a state of the art character LSTM baseline with a  large model capacity (Melis et al., 2018).", "labels": [], "entities": []}, {"text": " Table 3: Validation set perplexity of LSTM lan- guage model, sequential syntactic LSTM, and RN- NGs.", "labels": [], "entities": []}, {"text": " Table 4: Average stack depth and validation set  perplexity for top-down (TD), left-corner (LC),  and bottom-up (BU) RNNGs.", "labels": [], "entities": []}, {"text": " Table 5: Number agreement error rates for top- down (TD), left-corner (LC), and bottom-up (BU)  RNNGs, broken down by the number of attractors.  LM indicates the best sequential language model  baseline ( \u00a72). We report the mean, standard devia- tion, and minimum/maximum of 10 different ran- dom seeds of each model.", "labels": [], "entities": [{"text": "Number agreement error", "start_pos": 10, "end_pos": 32, "type": "METRIC", "confidence": 0.8431022763252258}]}]}