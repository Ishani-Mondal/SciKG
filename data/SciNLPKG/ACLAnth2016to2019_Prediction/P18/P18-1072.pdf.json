{"title": [{"text": "On the Limitations of Unsupervised Bilingual Dictionary Induction", "labels": [], "entities": [{"text": "Limitations of Unsupervised Bilingual Dictionary Induction", "start_pos": 7, "end_pos": 65, "type": "TASK", "confidence": 0.625388965010643}]}], "abstractContent": [{"text": "Unsupervised machine translation-i.e., not assuming any cross-lingual supervision signal, whether a dictionary, translations , or comparable corpora-seems impossible , but nevertheless, Lample et al.", "labels": [], "entities": [{"text": "machine translation-i.e.", "start_pos": 13, "end_pos": 37, "type": "TASK", "confidence": 0.7274647057056427}]}, {"text": "(2018a) recently proposed a fully unsu-pervised machine translation (MT) model.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 48, "end_pos": 72, "type": "TASK", "confidence": 0.8317829966545105}]}, {"text": "The model relies heavily on an adversar-ial, unsupervised alignment of word embedding spaces for bilingual dictionary induction (Conneau et al., 2018), which we examine here.", "labels": [], "entities": [{"text": "bilingual dictionary induction", "start_pos": 97, "end_pos": 127, "type": "TASK", "confidence": 0.5905111730098724}]}, {"text": "Our results identify the limitations of current unsupervised MT: un-supervised bilingual dictionary induction performs much worse on morphologically rich languages that are not dependent marking , when monolingual corpora from different domains or different embedding algorithms are used.", "labels": [], "entities": [{"text": "MT", "start_pos": 61, "end_pos": 63, "type": "TASK", "confidence": 0.9869998097419739}, {"text": "bilingual dictionary induction", "start_pos": 79, "end_pos": 109, "type": "TASK", "confidence": 0.6613905628522238}]}, {"text": "We show that a simple trick, exploiting a weak supervision signal from identical words, enables more robust induction, and establish a near-perfect correlation between unsupervised bilingual dictionary induction performance and a previously unexplored graph similarity metric.", "labels": [], "entities": []}], "introductionContent": [{"text": "Cross-lingual word representations enable us to reason about word meaning in multilingual contexts and facilitate cross-lingual transfer.", "labels": [], "entities": [{"text": "cross-lingual transfer", "start_pos": 114, "end_pos": 136, "type": "TASK", "confidence": 0.7314978539943695}]}, {"text": "Early cross-lingual word embedding models relied on large amounts of parallel data (), but more recent approaches have tried to minimize the amount of supervision necessary.", "labels": [], "entities": [{"text": "cross-lingual word embedding", "start_pos": 6, "end_pos": 34, "type": "TASK", "confidence": 0.6036040882269541}]}, {"text": "Some researchers have even presented unsupervised methods that do not rely on any form of cross-lingual supervision at all.", "labels": [], "entities": []}, {"text": "Unsupervised cross-lingual word embeddings hold promise to induce bilingual lexicons and machine translation models in the absence of dictionaries and translations), and would therefore be a major step toward machine translation to, from, or even between low-resource languages.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 89, "end_pos": 108, "type": "TASK", "confidence": 0.7319681644439697}, {"text": "machine translation", "start_pos": 209, "end_pos": 228, "type": "TASK", "confidence": 0.7416555881500244}]}, {"text": "Unsupervised approaches to learning crosslingual word embeddings are based on the assumption that monolingual word embedding graphs are approximately isomorphic, that is, after removing a small set of vertices (words) ().", "labels": [], "entities": []}, {"text": "In the words of Barone (2016): . .", "labels": [], "entities": []}, {"text": "we hypothesize that, if languages are used to convey thematically similar information in similar contexts, these random processes should be approximately isomorphic between languages, and that this isomorphism can be learned from the statistics of the realizations of these processes, the monolingual corpora, in principle without any form of explicit alignment.", "labels": [], "entities": []}, {"text": "Our results indicate this assumption is not true in general, and that approaches based on this assumption have important limitations.", "labels": [], "entities": []}, {"text": "Contributions We focus on the recent stateof-the-art unsupervised model of.", "labels": [], "entities": []}, {"text": "Our contributions are: (a) In \u00a72, we show that the monolingual word embeddings used in are not approximately isomorphic, using the VF2 algorithm () and we therefore introduce a metric for quantifying the similarity of word embeddings, based on Laplacian eigenvalues.", "labels": [], "entities": []}, {"text": "(b) In \u00a73, we identify circumstances under which the unsupervised bilingual dictionary induction (BDI) algorithm proposed in does not lead to good performance.", "labels": [], "entities": [{"text": "unsupervised bilingual dictionary induction (BDI)", "start_pos": 53, "end_pos": 102, "type": "TASK", "confidence": 0.6525561724390302}]}, {"text": "(c) We show that a simple trick, exploiting a weak supervision signal from words that are identical across languages, makes the algorithm much more robust.", "labels": [], "entities": []}, {"text": "Our main finding is that the performance of unsupervised BDI depends heavily on all three factors: the language pair, the comparability of the monolingual corpora, and the parameters of the word embedding algorithms.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the following experiments, we investigate the robustness of unsupervised cross-lingual word embedding learning, varying the language pairs, monolingual corpora, hyper-parameters, etc., to obtain a better understanding of when and why unsupervised BDI works.", "labels": [], "entities": []}, {"text": "Task: Bilingual dictionary induction After the shared cross-lingual space is induced, given a list of N source language words x u,1 , . .", "labels": [], "entities": [{"text": "Bilingual dictionary induction", "start_pos": 6, "end_pos": 36, "type": "TASK", "confidence": 0.824292262395223}]}, {"text": ", x u,N , the task is to find a target language word t for each query word x u relying on the representations in the space.", "labels": [], "entities": []}, {"text": "ti is the target language word closest to the source language word x u,i in the induced cross-lingual space, also known as the cross-lingual nearest neighbor.", "labels": [], "entities": []}, {"text": "The set of learned N (x u,i , ti ) pairs is then run against a gold standard dictionary.", "labels": [], "entities": []}, {"text": "We use bilingual dictionaries compiled by Conneau et al.", "labels": [], "entities": []}, {"text": "(2018) as gold standard, and adopt their evaluation procedure: each test set in each language consists of 1500 gold translation pairs.", "labels": [], "entities": []}, {"text": "We rely on CSLS for retrieving the nearest neighbors, as it consistently outperformed the cosine similarity in all our experiments.", "labels": [], "entities": []}, {"text": "Following a standard evaluation practice, we report Precision at 1 scores (P@1): how many times one of the correct translations of a source word w is retrieved as the nearest neighbor of win the target language.", "labels": [], "entities": [{"text": "Precision", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.9511604905128479}, {"text": "P@1)", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.8006031662225723}]}, {"text": "Our default experimental setup closely follows the setup of: Bilingual dictionary induction scores (P@1\u00d7100%) using a) the unsupervised method with adversarial training; b) the supervised method with a bilingual seed dictionary consisting of identical words (shared between the two languages).", "labels": [], "entities": [{"text": "Bilingual dictionary induction", "start_pos": 61, "end_pos": 91, "type": "TASK", "confidence": 0.6392993231614431}]}, {"text": "The third columns lists eigenvector similarities between 10 randomly sampled source language nearest neighbor subgraphs of 10 nodes and the subgraphs of their translations, all from the benchmark dictionaries in.", "labels": [], "entities": []}, {"text": "BDI models are evaluated on a held-out set of query words.", "labels": [], "entities": []}, {"text": "Here, we analyze the performance of the unsupervised approach across different parts-ofspeech, frequency bins, and with respect to query words that have orthographically identical counterparts in the target language with the same or a different meaning.", "labels": [], "entities": []}, {"text": "Part-of-speech We show the impact of the partof-speech of the query words in; again on a representative subset of our languages.", "labels": [], "entities": []}, {"text": "The results indicate that performance on verbs is lowest across the board.", "labels": [], "entities": []}, {"text": "This is consistent with research on distributional semantics and verb meaning (.", "labels": [], "entities": []}, {"text": "Frequency We also investigate the impact of the frequency of query words.", "labels": [], "entities": [{"text": "Frequency", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.8189446926116943}]}, {"text": "We calculate the word frequency of English words based on Google's Trillion Word Corpus: query words are divided in groups based on their rank -i.e., the first group contains the top 100 most frequent words, the second one contains the 101th-1000th most frequent words, etc.", "labels": [], "entities": [{"text": "Trillion Word Corpus", "start_pos": 67, "end_pos": 87, "type": "DATASET", "confidence": 0.8314608931541443}]}, {"text": "-and plot performance (P@1) relative to rank in.", "labels": [], "entities": [{"text": "P@1)", "start_pos": 23, "end_pos": 27, "type": "METRIC", "confidence": 0.8696483820676804}]}, {"text": "For EN-FI, P@1 was 0 across all frequency ranks.", "labels": [], "entities": [{"text": "P@1", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.9709179202715555}]}, {"text": "The plot shows sensitivity to frequency for HU, but less so for ES.", "labels": [], "entities": [{"text": "sensitivity", "start_pos": 15, "end_pos": 26, "type": "METRIC", "confidence": 0.9689140915870667}, {"text": "HU", "start_pos": 44, "end_pos": 46, "type": "DATASET", "confidence": 0.637951672077179}, {"text": "ES", "start_pos": 64, "end_pos": 66, "type": "DATASET", "confidence": 0.6375620365142822}]}, {"text": "Homographs Since we use identical word forms (homographs) for supervision, we investigated   whether these are representative or harder to align than other words.", "labels": [], "entities": []}, {"text": "lists performance for three sets of query words: (a) source words that have homographs (words that are spelled the same way) with the same meaning (homonyms) in the target language, e.g., many proper names; (b) source words that have homographs that are not homonyms in the target language, e.g., many short words; and (c) other words.", "labels": [], "entities": []}, {"text": "Somewhat surprisingly, words which have translations that are homographs, are associated with lower precision than other words.", "labels": [], "entities": [{"text": "precision", "start_pos": 100, "end_pos": 109, "type": "METRIC", "confidence": 0.9952625036239624}]}, {"text": "This is probably due to loan words and proper names, but note that using homographs as supervision for alignment, we achieve high precision for this part of the vocabulary for free.", "labels": [], "entities": [{"text": "precision", "start_pos": 130, "end_pos": 139, "type": "METRIC", "confidence": 0.9978294968605042}]}], "tableCaptions": [{"text": " Table 1: Languages in Conneau et al. (2018) and  in our experiments (lower half)", "labels": [], "entities": []}, {"text": " Table 2: Bilingual dictionary induction scores  (P@1\u00d7100%) using a) the unsupervised method  with adversarial training; b) the supervised method  with a bilingual seed dictionary consisting of iden- tical words (shared between the two languages).  The third columns lists eigenvector similarities be- tween 10 randomly sampled source language near- est neighbor subgraphs of 10 nodes and the sub- graphs of their translations, all from the benchmark  dictionaries in", "labels": [], "entities": [{"text": "Bilingual dictionary induction", "start_pos": 10, "end_pos": 40, "type": "TASK", "confidence": 0.686572273572286}]}, {"text": " Table 3: Varying the underlying fastText algorithm  and hyper-parameters. The first column lists differ- ences in training configurations between English  and Spanish monolingual embeddings.", "labels": [], "entities": []}, {"text": " Table 4: P@1 \u00d7 100% scores for query words with  different parts-of-speech.", "labels": [], "entities": [{"text": "P@1 \u00d7 100% scores", "start_pos": 10, "end_pos": 27, "type": "METRIC", "confidence": 0.8882132683481488}]}, {"text": " Table 5: Scores (P@1 \u00d7 100%) for query words  with same and different spellings and meanings.", "labels": [], "entities": []}]}