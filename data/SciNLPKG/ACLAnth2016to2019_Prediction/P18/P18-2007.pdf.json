{"title": [{"text": "Domain Adapted Word Embeddings for Improved Sentiment Classification", "labels": [], "entities": [{"text": "Improved Sentiment Classification", "start_pos": 35, "end_pos": 68, "type": "TASK", "confidence": 0.7057868242263794}]}], "abstractContent": [{"text": "Generic word embeddings are trained on large-scale generic corpora; Domain Specific (DS) word embeddings are trained only on data from a domain of interest.", "labels": [], "entities": []}, {"text": "This paper proposes a method to combine the breadth of generic embed-dings with the specificity of domain specific embeddings.", "labels": [], "entities": [{"text": "breadth", "start_pos": 44, "end_pos": 51, "type": "METRIC", "confidence": 0.970905601978302}]}, {"text": "The resulting embed-dings, called Domain Adapted (DA) word embeddings, are formed by aligning corresponding word vectors using Canonical Correlation Analysis (CCA) or the related nonlinear Kernel CCA.", "labels": [], "entities": []}, {"text": "Evaluation results on sentiment classification tasks show that the DA embeddings substantially outper-form both generic and DS embeddings when used as input features to standard or state-of-the-art sentence encoding algorithms for classification.", "labels": [], "entities": [{"text": "sentiment classification tasks", "start_pos": 22, "end_pos": 52, "type": "TASK", "confidence": 0.9528716206550598}]}], "introductionContent": [{"text": "Generic word embeddings such as Glove and word2vec) which are pre-trained on large sets of raw text, have demonstrated remarkable success when used as features to a supervised learner in various applications such as the sentiment classification of text documents.", "labels": [], "entities": [{"text": "sentiment classification of text documents", "start_pos": 220, "end_pos": 262, "type": "TASK", "confidence": 0.9346853733062744}]}, {"text": "There are, however, many applications with domain specific vocabularies and relatively small amounts of data.", "labels": [], "entities": []}, {"text": "The performance of generic word embedding in such applications is limited, since word embeddings pre-trained on generic corpora do not capture domain specific semantics/knowledge, while embeddings learned on small data sets are of low quality.", "labels": [], "entities": []}, {"text": "A concrete example of a small-sized domain specific corpus is the Substances User Disorders (SUDs) data set (, which contains messages on discussion forums for people with substance addictions.", "labels": [], "entities": [{"text": "Substances User Disorders (SUDs) data set", "start_pos": 66, "end_pos": 107, "type": "TASK", "confidence": 0.7265114411711693}]}, {"text": "These forums are part of a mobile health intervention treatment that encourages participants to engage in sobriety-related discussions.", "labels": [], "entities": []}, {"text": "The goal of such treatments is to analyze content of participant's digital media content and provide human intervention via machine learning algorithms.", "labels": [], "entities": []}, {"text": "This data is both domain specific and limited in size.", "labels": [], "entities": []}, {"text": "Other examples include customer support tickets reporting issues with taxi-cab services, product reviews, reviews of restaurants and movies, discussions by special interest groups and political surveys.", "labels": [], "entities": []}, {"text": "In general they are common in domains where words have different sentiment from what they would have elsewhere.", "labels": [], "entities": []}, {"text": "Such data sets present significant challenges for word embedding learning algorithms.", "labels": [], "entities": [{"text": "word embedding learning", "start_pos": 50, "end_pos": 73, "type": "TASK", "confidence": 0.7972601056098938}]}, {"text": "First, words in data on specific topics have a different distribution than words from generic corpora.", "labels": [], "entities": []}, {"text": "Hence using generic word embeddings obtained from algorithms trained on a corpus such as Wikipedia, may introduce considerable errors in performance metrics on specific downstream tasks such as sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 194, "end_pos": 218, "type": "TASK", "confidence": 0.9535252749919891}]}, {"text": "For example, in SUDs, discussions are focused on topics related to recovery and addiction; the sentiment behind the word 'party' maybe very different in a dating context than in a substance abuse context.", "labels": [], "entities": [{"text": "SUDs", "start_pos": 16, "end_pos": 20, "type": "TASK", "confidence": 0.9747217297554016}]}, {"text": "Thus domain specific vocabularies and word semantics maybe a problem for pre-trained sentiment classification models (.", "labels": [], "entities": [{"text": "word semantics", "start_pos": 38, "end_pos": 52, "type": "TASK", "confidence": 0.6868817955255508}, {"text": "sentiment classification", "start_pos": 85, "end_pos": 109, "type": "TASK", "confidence": 0.7824872434139252}]}, {"text": "Second, there is insufficient data to completely retrain anew set of word embeddings.", "labels": [], "entities": []}, {"text": "The SUD data set consists of a few hundred people and only a fraction of these are active (,.", "labels": [], "entities": [{"text": "SUD data set", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.9287436604499817}]}, {"text": "This results in a small data set of text messages available for analysis.", "labels": [], "entities": []}, {"text": "Furthermore, content is generated spontaneously on a day today basis, and language use is informal and unstructured.", "labels": [], "entities": []}, {"text": "Finetuning the generic word embedding also leads to noisy outputs due to the highly non-convex training objective and the small amount of data.", "labels": [], "entities": []}, {"text": "Since such data sets are common, a simple and effective method to adapt word embedding approaches is highly valuable.", "labels": [], "entities": []}, {"text": "While existing work, (?), (?), (?), (?) combines word embeddings from different algorithms to improve upon intrinsic tasks such as similarities, analogies etc, there does not exist a concrete method to combine multiple embeddings to perform domain adaptation or improve on extrinsic tasks.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 241, "end_pos": 258, "type": "TASK", "confidence": 0.7288120836019516}]}, {"text": "This paper proposes a method for obtaining high quality word embeddings that capture domain specific semantics and are suitable for tasks on the specific domain.", "labels": [], "entities": []}, {"text": "The new Domain Adapted (DA) embeddings are obtained by combining generic embeddings and Domain Specific (DS) embeddings via CCA/KCCA.", "labels": [], "entities": []}, {"text": "Generic embeddings are trained on large corpora and do not capture domain specific semantics, while DS embeddings are obtained from the domain specific data set via algorithms such as Latent Semantic Analysis (LSA) or other embedding methods.", "labels": [], "entities": [{"text": "Latent Semantic Analysis (LSA)", "start_pos": 184, "end_pos": 214, "type": "TASK", "confidence": 0.7402272522449493}]}, {"text": "The two sets of embeddings are combined using a linear CCA or a nonlinear kernel CCA (KCCA) ().", "labels": [], "entities": []}, {"text": "They are projected along the directions of maximum correlation, and anew (DA) embedding is formed by averaging the projections of the generic embeddings and DS embeddings.", "labels": [], "entities": [{"text": "correlation", "start_pos": 51, "end_pos": 62, "type": "METRIC", "confidence": 0.908643901348114}]}, {"text": "The DA embeddings are then evaluated in a sentiment classification setting.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 42, "end_pos": 66, "type": "TASK", "confidence": 0.8948384821414948}]}, {"text": "Empirically, it is shown that the CCA/KCCA combined DA embeddings improve substantially over the generic embeddings, DS embeddings and a concatenation-SVD (concSVD) based baseline.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 briefly introduces the CCA/KCCA and details the procedure used to obtain the DA embeddings.", "labels": [], "entities": [{"text": "CCA/KCCA", "start_pos": 33, "end_pos": 41, "type": "DATASET", "confidence": 0.8794121742248535}]}, {"text": "Section 3 describes the experimental setup.", "labels": [], "entities": []}, {"text": "Section 4 discusses the results from sentiment classification tasks on benchmark data sets using standard classification as well as using a sophisticated neural network based sentence encoding algorithm.", "labels": [], "entities": [{"text": "sentiment classification tasks", "start_pos": 37, "end_pos": 67, "type": "TASK", "confidence": 0.9329790075620016}, {"text": "sentence encoding", "start_pos": 175, "end_pos": 192, "type": "TASK", "confidence": 0.7371024489402771}]}, {"text": "Section 5 concludes this work.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section evaluates DA embeddings in binary sentiment classification tasks on four standard data sets.", "labels": [], "entities": [{"text": "DA embeddings in binary sentiment classification", "start_pos": 23, "end_pos": 71, "type": "TASK", "confidence": 0.7379990369081497}]}, {"text": "Document embeddings are obtained via (i) a standard framework, i.e document embeddings area weighted combination of their constituent word embeddings and (ii) by initializing a state of the art sentence encoding algorithm InferSent (Conneau et al., 2017) with word embeddings to obtain sentence embeddings.", "labels": [], "entities": []}, {"text": "Encoded sentences are then classified using a Logistic Regressor.", "labels": [], "entities": []}, {"text": "The following balanced and imbalanced data sets are used for experimentation,: This table shows results from the classification task using sentence embeddings obtained from weighted averaging of word embeddings.", "labels": [], "entities": []}, {"text": "Metrics reported are average Precision, F-score and AUC and the corresponding standard deviations (STD).", "labels": [], "entities": [{"text": "Precision", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.9866524338722229}, {"text": "F-score", "start_pos": 40, "end_pos": 47, "type": "METRIC", "confidence": 0.9970172643661499}, {"text": "AUC", "start_pos": 52, "end_pos": 55, "type": "METRIC", "confidence": 0.9968881011009216}, {"text": "standard deviations (STD)", "start_pos": 78, "end_pos": 103, "type": "METRIC", "confidence": 0.9539383888244629}]}, {"text": "Best results are attained by KCCA (GlvCC, LSA) and are highlighted in boldface.", "labels": [], "entities": [{"text": "KCCA (GlvCC, LSA)", "start_pos": 29, "end_pos": 46, "type": "DATASET", "confidence": 0.7345106353362402}]}, {"text": "\u2022 Amazon: In this balanced data set there are 1000 product reviews obtained from Amazon.", "labels": [], "entities": [{"text": "Amazon", "start_pos": 2, "end_pos": 8, "type": "DATASET", "confidence": 0.787848711013794}]}, {"text": "Each product review is labeled either 'Positive' or 'Negative'.", "labels": [], "entities": []}, {"text": "There area total of 1865 distinct word tokens in this data set.", "labels": [], "entities": []}, {"text": "\u2022 IMDB: This is a balanced data set consisting of 1000 reviews for movies on IMDB.", "labels": [], "entities": [{"text": "IMDB", "start_pos": 2, "end_pos": 6, "type": "DATASET", "confidence": 0.5276679992675781}, {"text": "IMDB", "start_pos": 77, "end_pos": 81, "type": "DATASET", "confidence": 0.9526950716972351}]}, {"text": "Each movie review is labeled either 'Positive' or 'Negative'.", "labels": [], "entities": []}, {"text": "There area total of 3075 distinct  word tokens in this data set.", "labels": [], "entities": []}, {"text": "\u2022 A-CHESS: This is a proprietary data set 1 obtained from a study involving users with alcohol addiction.", "labels": [], "entities": [{"text": "A-CHESS", "start_pos": 2, "end_pos": 9, "type": "METRIC", "confidence": 0.9929115176200867}]}, {"text": "Text data is obtained from a discussion forum in the A-CHESS mobile app ().", "labels": [], "entities": [{"text": "A-CHESS mobile app", "start_pos": 53, "end_pos": 71, "type": "DATASET", "confidence": 0.9079030950864156}]}, {"text": "There area total of 2500 text messages, with 8% of the messages indicative of relapse risk.", "labels": [], "entities": []}, {"text": "Since this data set is part of a clinical trial, an exact text message cannot be provided as an example.", "labels": [], "entities": []}, {"text": "However, the following messages illustrate typical messages in this data set, \"I've been clean for about 7 months but even now I still feel like maybe I won't make it.\"", "labels": [], "entities": []}, {"text": "Such a message is marked as 'threat' by a human moderator.", "labels": [], "entities": []}, {"text": "On the other hand there are other benign messages that are marked 'not threat' such as \"30 days sober and counting, I feel like I am getting my life back.\"", "labels": [], "entities": [{"text": "counting", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9898598790168762}]}, {"text": "The aim is to eventually automate this process since human moderation involves considerable effort and time.", "labels": [], "entities": []}, {"text": "This is an unbalanced data set ( 8% of the messages are marked 'threat') with a total of 3400 distinct work tokens.", "labels": [], "entities": []}, {"text": "The first three data sets are obtained from (Kotzias et al., 2015).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: This table shows results from the classi- fication task using sentence embeddings obtained  from weighted averaging of word embeddings.  Metrics reported are average Precision, F-score  and AUC and the corresponding standard devia- tions (STD). Best results are attained by KCCA  (GlvCC, LSA) and are highlighted in boldface.", "labels": [], "entities": [{"text": "Precision", "start_pos": 176, "end_pos": 185, "type": "METRIC", "confidence": 0.9981759786605835}, {"text": "F-score", "start_pos": 187, "end_pos": 194, "type": "METRIC", "confidence": 0.9912278652191162}, {"text": "AUC", "start_pos": 200, "end_pos": 203, "type": "METRIC", "confidence": 0.9950098991394043}, {"text": "standard devia- tions (STD)", "start_pos": 226, "end_pos": 253, "type": "METRIC", "confidence": 0.7540410586765834}, {"text": "KCCA  (GlvCC, LSA)", "start_pos": 284, "end_pos": 302, "type": "DATASET", "confidence": 0.7393882075945536}]}, {"text": " Table 2: This table shows results obtained by us- ing sentence embeddings from the InferSent en- coder in the sentiment classification task. Met- rics reported are average Precision, F-score and  AUC along with the corresponding standard devi- ations (STD). Best results are obtained by KCCA  (GlvCC, LSA) and are highlighted in boldface.", "labels": [], "entities": [{"text": "sentiment classification task", "start_pos": 111, "end_pos": 140, "type": "TASK", "confidence": 0.9276359677314758}, {"text": "Precision", "start_pos": 173, "end_pos": 182, "type": "METRIC", "confidence": 0.9981797933578491}, {"text": "F-score", "start_pos": 184, "end_pos": 191, "type": "METRIC", "confidence": 0.991393506526947}, {"text": "AUC", "start_pos": 197, "end_pos": 200, "type": "METRIC", "confidence": 0.9958668947219849}, {"text": "standard devi- ations (STD)", "start_pos": 230, "end_pos": 257, "type": "METRIC", "confidence": 0.6912595757416317}, {"text": "KCCA  (GlvCC, LSA)", "start_pos": 288, "end_pos": 306, "type": "DATASET", "confidence": 0.7246016214291254}]}]}