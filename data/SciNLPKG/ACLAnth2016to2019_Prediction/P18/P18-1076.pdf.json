{"title": [{"text": "Knowledgeable Reader: Enhancing Cloze-Style Reading Comprehension with External Commonsense Knowledge", "labels": [], "entities": []}], "abstractContent": [{"text": "We introduce a neural reading comprehension model that integrates external com-monsense knowledge, encoded as a key-value memory, in a cloze-style setting.", "labels": [], "entities": []}, {"text": "Instead of relying only on document-to-question interaction or discrete features as in prior work, our model attends to relevant external knowledge and combines this knowledge with the context representation before inferring the answer.", "labels": [], "entities": []}, {"text": "This allows the model to attract and imply knowledge from an external knowledge source that is not explicitly stated in the text, but that is relevant for inferring the answer.", "labels": [], "entities": []}, {"text": "Our model improves results over a very strong baseline on a hard Common Nouns dataset, making it a strong competitor of much more complex models.", "labels": [], "entities": [{"text": "Common Nouns dataset", "start_pos": 65, "end_pos": 85, "type": "DATASET", "confidence": 0.8031581242879232}]}, {"text": "By including knowledge explicitly, our model can also provide evidence about the background knowledge used in the RC process.", "labels": [], "entities": []}], "introductionContent": [{"text": "Reading comprehension (RC) is a language understanding task similar to question answering, where a system is expected to read a given passage of text and answer questions about it.", "labels": [], "entities": [{"text": "Reading comprehension (RC)", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8237524390220642}, {"text": "language understanding task", "start_pos": 32, "end_pos": 59, "type": "TASK", "confidence": 0.7951005299886068}, {"text": "question answering", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.8061515092849731}]}, {"text": "Cloze-style reading comprehension is a task setting where the question is formed by replacing a token in a sentence of the story with a placeholder (left part of).", "labels": [], "entities": []}, {"text": "In contrast to many previous complex models () that perform multi-turn reading of a story and a question before inferring the correct answer, we aim to tackle the cloze-style RC task in away that resembles how humans solve it: using, in addition, background knowledge.", "labels": [], "entities": []}, {"text": "We develop a neural model for RC that can successfully deal with tasks where most of the information to infer answers from is given in the document (story), but where additional information is needed to predict the answer, which can be retrieved from a knowledge base and added to the context representations explicitly.", "labels": [], "entities": [{"text": "RC", "start_pos": 30, "end_pos": 32, "type": "TASK", "confidence": 0.9653211236000061}]}, {"text": "An illustration is given in.", "labels": [], "entities": []}, {"text": "Such knowledge maybe commonsense knowledge or factual background knowledge about entities and events that is not explicitly expressed but can be found in a knowledge base such as ConceptNet (,), Freebase ( or domain-specific KBs collected with Information Extraction approaches).", "labels": [], "entities": []}, {"text": "Thus, we aim to define a neural model that encodes preselected knowledge in a memory, and that learns to include the available knowledge as an enrichment to the context representation.", "labels": [], "entities": []}, {"text": "The main difference of our model to prior state-of-the-art is that instead of relying only on document-to-question interaction or discrete features while performing multiple hops over the document, our model (i) attends to relevant selected external knowledge and (ii) combines this knowledge with the context representation before inferring the answer, in a single hop.", "labels": [], "entities": []}, {"text": "This allows the model to explicitly imply knowledge that is not stated in the text, but is relevant for inferring the answer, and that can be found in an external knowledge source.", "labels": [], "entities": []}, {"text": "Moreover, by including knowledge explicitly, our model provides evidence and insight about the used knowledge in the RC.", "labels": [], "entities": []}, {"text": "Our main contributions are: (i) We develop a method for integrating knowledge in a simple but effective reading comprehension model (AS Reader,) and improve its results significantly whereas other models employ features or multiple hops.", "labels": [], "entities": []}, {"text": "(ii) We examine two sources of common knowledge:) and ConceptNet ( and show that this type of knowledge is important for answering common nouns questions and also improves slightly the performance for named entities.", "labels": [], "entities": [{"text": "answering common nouns questions", "start_pos": 121, "end_pos": 153, "type": "TASK", "confidence": 0.7995496094226837}]}, {"text": "(iii) We show that knowledge facts can be added directly to the text-only representation, enriching the neural context encoding.", "labels": [], "entities": []}, {"text": "(iv) We demonstrate the effectiveness of the injected knowledge by case studies and data statistics in a qualitative evaluation study.", "labels": [], "entities": []}], "datasetContent": [{"text": "We perform quantitative analysis through experiments.", "labels": [], "entities": [{"text": "quantitative analysis", "start_pos": 11, "end_pos": 32, "type": "TASK", "confidence": 0.8242825567722321}]}, {"text": "We study the impact of the used knowledge and different model components that employ the external knowledge.", "labels": [], "entities": []}, {"text": "Some of the experiments below focus only on the Common Nouns (CN) dataset, as it has been shown to be more challenging than Named Entities (NE) in prior work.", "labels": [], "entities": [{"text": "Common Nouns (CN) dataset", "start_pos": 48, "end_pos": 73, "type": "DATASET", "confidence": 0.5436056802670161}]}], "tableCaptions": [{"text": " Table 1: Characteristics of Children Book Test  datasets. CN: Common Nouns, NE: Named En- tities. Cells for Train, Dev, Test show overall num- bers of examples and average story size in tokens.", "labels": [], "entities": [{"text": "Children Book Test  datasets", "start_pos": 29, "end_pos": 57, "type": "DATASET", "confidence": 0.6308176591992378}]}, {"text": " Table 2: Results with different knowledge sources,  for CBT-CN (Full model, 50 facts).", "labels": [], "entities": [{"text": "CBT-CN", "start_pos": 57, "end_pos": 63, "type": "DATASET", "confidence": 0.7995766997337341}]}, {"text": " Table 3: Results for CBT (CN) with different num- bers of facts. (Full model, CN5Sel)", "labels": [], "entities": []}, {"text": " Table 4: Results for different combinations of in- teractions between document (D) and question (Q)  context (ctx) and context + knowledge (ctx+kn)  representations. (CN5Sel, 50 facts)", "labels": [], "entities": [{"text": "CN5Sel", "start_pos": 168, "end_pos": 174, "type": "DATASET", "confidence": 0.9525501132011414}]}, {"text": " Table 5: Results for key-value knowledge retrieval  and integration. (CN5Sel, 50 facts). Subj/Obj  means: we attend over the fact subject (Key) and  take the weighted fact object as value (Value).", "labels": [], "entities": [{"text": "key-value knowledge retrieval", "start_pos": 22, "end_pos": 51, "type": "TASK", "confidence": 0.6705729762713114}, {"text": "CN5Sel", "start_pos": 71, "end_pos": 77, "type": "DATASET", "confidence": 0.960127055644989}, {"text": "Obj", "start_pos": 95, "end_pos": 98, "type": "METRIC", "confidence": 0.8418178558349609}]}, {"text": " Table 6: Comparison of KnReader to existing end- to-end neural models on the benchmark datasets.", "labels": [], "entities": []}]}