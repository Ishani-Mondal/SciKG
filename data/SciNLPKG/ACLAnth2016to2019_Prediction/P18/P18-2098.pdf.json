{"title": [], "abstractContent": [{"text": "How to make the most of multiple heterogeneous treebanks when training a mono-lingual dependency parser is an open question.", "labels": [], "entities": []}, {"text": "We start by investigating previously suggested, but little evaluated, strategies for exploiting multiple treebanks based on concatenating training sets, with or without fine-tuning.", "labels": [], "entities": []}, {"text": "We goon to propose anew method based on treebank embed-dings.", "labels": [], "entities": []}, {"text": "We perform experiments for several languages and show that in many cases fine-tuning and treebank embeddings lead to substantial improvements over single treebanks or concatenation, with average gains of 2.0-3.5 LAS points.", "labels": [], "entities": [{"text": "LAS", "start_pos": 212, "end_pos": 215, "type": "METRIC", "confidence": 0.9963143467903137}]}, {"text": "We argue that treebank embeddings should be preferred due to their conceptual simplicity, flexibility and extensibility.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper we investigate how to train monolingual parsers in the situation where several treebanks are available fora single language.", "labels": [], "entities": []}, {"text": "This is quite a common occurrence; in release 2.1 of the Universal Dependencies (UD) treebanks), 25 languages have more than one treebank.", "labels": [], "entities": [{"text": "Universal Dependencies (UD) treebanks", "start_pos": 57, "end_pos": 94, "type": "DATASET", "confidence": 0.5891107072432836}]}, {"text": "These treebanks can differ in several respects: they can contain material from different language variants, domains, or genres, and written or spoken material.", "labels": [], "entities": []}, {"text": "Even though the UD project provides guidelines for consistent annotation, treebanks can still differ with respect to annotation choices, consistency and quality of annotation.", "labels": [], "entities": [{"text": "UD project", "start_pos": 16, "end_pos": 26, "type": "DATASET", "confidence": 0.9172889590263367}, {"text": "consistency", "start_pos": 137, "end_pos": 148, "type": "METRIC", "confidence": 0.9919678568840027}]}, {"text": "Some treebanks are thoroughly checked by human annotators, whereas others are based entirely on automatic conversions.", "labels": [], "entities": []}, {"text": "All this means that it is often far from trivial to combine multiple treebanks for the same language.", "labels": [], "entities": []}, {"text": "The 2017 CoNLL Shared Task on Universal Dependency Parsing () included 15 languages with multiple treebanks.", "labels": [], "entities": [{"text": "CoNLL Shared Task on Universal Dependency Parsing", "start_pos": 9, "end_pos": 58, "type": "TASK", "confidence": 0.49791387362139566}]}, {"text": "An additional parallel test set of 1000 sentences, PUD, was also made available fora selection of languages.", "labels": [], "entities": [{"text": "PUD", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.6527835726737976}]}, {"text": "Most of the participating teams did not take advantage of the multiple treebanks, however, and simply trained one model per treebank instead of one model per language.", "labels": [], "entities": []}, {"text": "There were a few exceptions to this rule, but these teams typically did not investigate the effect of their proposed strategies in detail.", "labels": [], "entities": []}, {"text": "In this paper we begin by performing a thorough investigation of previously proposed strategies for training with multiple treebanks for the same language.", "labels": [], "entities": []}, {"text": "We then propose a novel method, based on treebank embeddings.", "labels": [], "entities": []}, {"text": "Our new technique has the advantage of producing a single flexible model for each language, regardless of the number of treebanks.", "labels": [], "entities": []}, {"text": "We show that this method leads to substantial improvements for many languages.", "labels": [], "entities": []}, {"text": "Of the competing methods, training on the concatenation of treebanks, followed by fine-tuning for each treebank, also performed well, but this method results in longer training times and necessitates multiple unwieldy models per language.", "labels": [], "entities": []}], "datasetContent": [{"text": "We perform experiments for 24 treebanks from 9 languages, using UUParser (de.", "labels": [], "entities": [{"text": "UUParser", "start_pos": 64, "end_pos": 72, "type": "DATASET", "confidence": 0.911584734916687}]}, {"text": "We compare concatenation (CONCAT), concatenation with fine-tuning (C+FT), and treebank embeddings (TB-EMB).", "labels": [], "entities": []}, {"text": "In addition we compare these results to using only single treebanks for training (SINGLE).", "labels": [], "entities": []}, {"text": "While some of these methods were previously suggested in the literature, no proper evaluation and comparison between them has been performed.", "labels": [], "entities": []}, {"text": "For the PUD test data, there is no corresponding training set, so we need to choose a model or set a treebank embedding based on some other treebank.", "labels": [], "entities": [{"text": "PUD test data", "start_pos": 8, "end_pos": 21, "type": "DATASET", "confidence": 0.7749075889587402}]}, {"text": "We call this a proxy treebank.", "labels": [], "entities": []}, {"text": "For evaluation we use labeled attachment score (LAS).", "labels": [], "entities": [{"text": "labeled attachment score (LAS)", "start_pos": 22, "end_pos": 52, "type": "METRIC", "confidence": 0.9184966385364532}]}, {"text": "Significance testing is performed using a randomization test, with the script from the CoNLL 2017 Shared Task.", "labels": [], "entities": [{"text": "CoNLL 2017 Shared Task", "start_pos": 87, "end_pos": 109, "type": "DATASET", "confidence": 0.9392736554145813}]}], "tableCaptions": [{"text": " Table 1: LAS scores when testing on the training treebank and on the PUD test set with training treebank  as proxy. For each test set, the best result is marked with bold. Treebank size is given as number of  sentences in the training data. Statistically significant differences, at the 0.05-level, from SINGLE are  marked with +, from CONCAT with \u00d7 and from both these systems with *. For clarity, significance for  PUD is only shown for the proxy treebank with the highest score.", "labels": [], "entities": [{"text": "LAS", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9388418197631836}, {"text": "PUD test set", "start_pos": 70, "end_pos": 82, "type": "DATASET", "confidence": 0.8911569913228353}, {"text": "significance", "start_pos": 400, "end_pos": 412, "type": "METRIC", "confidence": 0.9562986493110657}]}]}