{"title": [{"text": "Dating Documents using Graph Convolution Networks", "labels": [], "entities": [{"text": "Dating Documents", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.9119543731212616}]}], "abstractContent": [{"text": "Document date is essential for many", "labels": [], "entities": [{"text": "Document date", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.8427110910415649}]}], "introductionContent": [{"text": "Date of a document, also referred to as the Document Creation Time (DCT), is at the core of many important tasks, such as, information retrieval (, temporal reasoning), text summarization, event detection (, and analysis of historical text), among others.", "labels": [], "entities": [{"text": "Date", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9505806565284729}, {"text": "Document Creation Time (DCT)", "start_pos": 44, "end_pos": 72, "type": "TASK", "confidence": 0.5285703390836716}, {"text": "information retrieval", "start_pos": 123, "end_pos": 144, "type": "TASK", "confidence": 0.7853937745094299}, {"text": "temporal reasoning)", "start_pos": 148, "end_pos": 167, "type": "TASK", "confidence": 0.8234065969785055}, {"text": "text summarization", "start_pos": 169, "end_pos": 187, "type": "TASK", "confidence": 0.7625311613082886}, {"text": "event detection", "start_pos": 189, "end_pos": 204, "type": "TASK", "confidence": 0.7695941627025604}, {"text": "analysis of historical text)", "start_pos": 212, "end_pos": 240, "type": "TASK", "confidence": 0.8210811138153076}]}, {"text": "In all such tasks, the document date is assumed to be available and also DCT (?)", "labels": [], "entities": [{"text": "DCT", "start_pos": 73, "end_pos": 76, "type": "METRIC", "confidence": 0.762234628200531}]}, {"text": "AFTER SAME obj subj SAME AFTER Swiss adopted that form of taxation in 1995.", "labels": [], "entities": [{"text": "AFTER SAME obj subj SAME AFTER Swiss", "start_pos": 0, "end_pos": 36, "type": "DATASET", "confidence": 0.700612553528377}]}, {"text": "An example document annotated with syntactic and temporal dependencies.", "labels": [], "entities": []}, {"text": "In order to predict the right value of 1999 for the Document Creation Time (DCT), inference over these document structures is necessary.", "labels": [], "entities": [{"text": "Document Creation Time (DCT)", "start_pos": 52, "end_pos": 80, "type": "TASK", "confidence": 0.6693420559167862}]}, {"text": "Bottom: Document date prediction by two state-of-the-art-baselines and NeuralDater, the method proposed in this paper.", "labels": [], "entities": [{"text": "Document date prediction", "start_pos": 8, "end_pos": 32, "type": "TASK", "confidence": 0.7176395157972971}]}, {"text": "While the two previous methods are getting misled by the temporal expression in the document, NeuralDater is able to use the syntactic and temporal structure of the document to predict the right value (1999).", "labels": [], "entities": []}, {"text": "accurate -a strong assumption, especially for arbitrary documents from the Web.", "labels": [], "entities": [{"text": "accurate", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9724336266517639}]}, {"text": "Thus, there is a need to automatically predict the date of a document based on its content.", "labels": [], "entities": []}, {"text": "This problem is referred to as Document Dating.", "labels": [], "entities": [{"text": "Document Dating", "start_pos": 31, "end_pos": 46, "type": "TASK", "confidence": 0.7746964395046234}]}, {"text": "Initial attempts on automatic document dating started with generative models by (de).", "labels": [], "entities": [{"text": "automatic document dating", "start_pos": 20, "end_pos": 45, "type": "TASK", "confidence": 0.6030106643835703}]}, {"text": "This model is later improved by) who incorporate additional features such as POS tags, collocations, etc.", "labels": [], "entities": []}, {"text": "Chambers (2012) shows significant improvement over these prior efforts through their discriminative models using handcrafted temporal features.", "labels": [], "entities": []}, {"text": "propose a statistical approach for document dating exploiting term bursti- Figure 2: Overview of NeuralDater.", "labels": [], "entities": [{"text": "document dating", "start_pos": 35, "end_pos": 50, "type": "TASK", "confidence": 0.7634122371673584}]}, {"text": "NeuralDater exploits syntactic and temporal structure in a document to learn effective representation, which in turn are used to predict the document time.", "labels": [], "entities": []}, {"text": "NeuralDater uses a Bi-directional LSTM (Bi-LSTM), two Graph Convolution Networks (GCN) -one over the dependency tree and the other over the document's temporal graph -along with a softmax classifier, all trained end-to-end jointly.", "labels": [], "entities": []}, {"text": "Please see Section 4 for more details.", "labels": [], "entities": []}, {"text": "Document dating is a challenging problem which requires extensive reasoning over the temporal structure of the document.", "labels": [], "entities": [{"text": "Document dating", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.9371039271354675}]}, {"text": "Let us motivate this through an example shown in.", "labels": [], "entities": []}, {"text": "In the document, four years after plays a crucial role in identifying the creation time of the document.", "labels": [], "entities": []}, {"text": "The existing approaches give higher confidence for timestamp immediate to the year mention 1995.", "labels": [], "entities": []}, {"text": "NeuralDater exploits the syntactic and temporal structure of the document to predict the right timestamp (1999) for the document.", "labels": [], "entities": []}, {"text": "With the exception of, all prior works on the document dating problem ignore such informative temporal structure within the document.", "labels": [], "entities": [{"text": "document dating problem", "start_pos": 46, "end_pos": 69, "type": "TASK", "confidence": 0.7875005900859833}]}, {"text": "Research in document event extraction and ordering have made it possible to extract such temporal structures involving events, temporal expressions, and the (unknown) document date in a document (.", "labels": [], "entities": [{"text": "document event extraction", "start_pos": 12, "end_pos": 37, "type": "TASK", "confidence": 0.6417351762453715}]}, {"text": "While methods to perform reasoning over such structures exist, none of them have exploited advances in deep learning ().", "labels": [], "entities": []}, {"text": "In particular, recently proposed Graph Convolution Networks (GCN)) have emerged as away to learn graph representation while encoding structural information and constraints represented by the graph.", "labels": [], "entities": []}, {"text": "We adapt GCNs for the document dating problem and make the following contributions: \u2022 We propose NeuralDater, a Graph Convolution Network (GCN)-based approach for document dating.", "labels": [], "entities": [{"text": "document dating problem", "start_pos": 22, "end_pos": 45, "type": "TASK", "confidence": 0.8334769805272421}, {"text": "document dating", "start_pos": 163, "end_pos": 178, "type": "TASK", "confidence": 0.7659412324428558}]}, {"text": "To the best of our knowledge, this is the first application of GCNs, and more broadly deep neural network-based methods, for the document dating problem.", "labels": [], "entities": [{"text": "document dating problem", "start_pos": 129, "end_pos": 152, "type": "TASK", "confidence": 0.8528006474177042}]}, {"text": "\u2022 NeuralDater is the first document dating approach which exploits syntactic as well temporal structure of the document, all within a principled joint model.", "labels": [], "entities": [{"text": "document dating", "start_pos": 27, "end_pos": 42, "type": "TASK", "confidence": 0.7502008974552155}]}, {"text": "\u2022 Through extensive experiments on multiple real-world datasets, we demonstrate NeuralDater's effectiveness over state-of-the-art baselines.", "labels": [], "entities": []}, {"text": "NeuralDater's source code and datasets used in the paper are available at http://github.", "labels": [], "entities": []}, {"text": "com/malllabiisc/NeuralDater.", "labels": [], "entities": []}], "datasetContent": [{"text": "Datasets: We experiment on Associated Press Worldstream (APW) and New York Times (NYT) sections of Gigaword corpus).", "labels": [], "entities": [{"text": "Associated Press Worldstream (APW) and New York Times (NYT) sections of Gigaword corpus", "start_pos": 27, "end_pos": 114, "type": "DATASET", "confidence": 0.8540608690065496}]}, {"text": "The original dataset contains around 3 million documents of APW and 2 million documents of NYT from span of multiple years.", "labels": [], "entities": [{"text": "APW", "start_pos": 60, "end_pos": 63, "type": "DATASET", "confidence": 0.9133200645446777}, {"text": "NYT", "start_pos": 91, "end_pos": 94, "type": "DATASET", "confidence": 0.9531299471855164}]}, {"text": "From both sections, we randomly sample around 650k documents while maintaining balance among years.", "labels": [], "entities": []}, {"text": "Documents belonging to years with substantially fewer documents are omitted.", "labels": [], "entities": []}, {"text": "Details of the dataset can be found in.", "labels": [], "entities": []}, {"text": "For train, test and validation splits, the dataset was randomly divided in 80:10:10 ratio.", "labels": [], "entities": [{"text": "validation splits", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.9728497862815857}]}, {"text": "Evaluation Criteria: Given a document, the model needs to predict the year in which the document was published.", "labels": [], "entities": []}, {"text": "We measure performance in terms of overall accuracy of the model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9992133378982544}]}, {"text": "Baselines: For evaluating NeuralDater, we compared against the following methods: This is a purely statistical method which uses lexical similarity and term burstiness () for dating documents in arbitrary length time frame.", "labels": [], "entities": []}, {"text": "For our experiments, we took the time frame length as 1 year.", "labels": [], "entities": []}, {"text": "Please refer to () for more details.", "labels": [], "entities": []}, {"text": "\u2022 MaxEnt-Time-NER: Maximum Entropy (MaxEnt) based classifier trained on hand-crafted temporal and Named Entity Recognizer (NER) based features.", "labels": [], "entities": []}, {"text": "\u2022 MaxEnt-Joint: Refers to MaxEnt-Time-NER combined with year mention classifier as described in).", "labels": [], "entities": []}, {"text": "\u2022 MaxEnt-Uni-Time: MaxEnt based discriminative model which takes bag-of-words representation of input document with normalized time expression as its features.", "labels": [], "entities": []}, {"text": "\u2022 CNN: A Convolution Neural Network (CNN) () based text classification model proposed by, which attained state-of-the-art results in several domains.", "labels": [], "entities": [{"text": "text classification", "start_pos": 51, "end_pos": 70, "type": "TASK", "confidence": 0.7473332583904266}]}, {"text": "\u2022 NeuralDater: Our proposed method, refer Section 4.", "labels": [], "entities": []}, {"text": "Hyperparameters: By default, edge gating (Section 3.3) is used in all GCNs.", "labels": [], "entities": []}, {"text": "The parameter K represents the number of layers in T-GCN (Section 5.3).", "labels": [], "entities": []}, {"text": "We use 300-dimensional GloVe embeddings and 128-dimensional hidden state for both: Accuracies of different ablated methods on the APW dataset.", "labels": [], "entities": [{"text": "APW dataset", "start_pos": 130, "end_pos": 141, "type": "DATASET", "confidence": 0.9721253216266632}]}, {"text": "Overall, we observe that incorporation of context (Bi-LSTM), syntactic structure (S-GCN) and temporal structure (T-GCN) in NeuralDater achieves the best performance.", "labels": [], "entities": [{"text": "Bi-LSTM", "start_pos": 51, "end_pos": 58, "type": "METRIC", "confidence": 0.9293276071548462}]}, {"text": "Please see Section 7.1 for details.", "labels": [], "entities": []}, {"text": "GCNs and BiLSTM with 0.8 dropout.", "labels": [], "entities": [{"text": "GCNs", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9348025918006897}, {"text": "BiLSTM", "start_pos": 9, "end_pos": 15, "type": "METRIC", "confidence": 0.6341128945350647}]}, {"text": "We used Adam () with 0.001 learning rate for training.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Details of datasets used. Please see Section 6 for  details.", "labels": [], "entities": []}, {"text": " Table 2: Accuracies of different methods on APW and NYT  datasets for the document dating problem (higher is better).  NeuralDater significantly outperforms all other competitive  baselines. This is our main result. Please see Section 7.1 for  more details.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9698250889778137}, {"text": "APW", "start_pos": 45, "end_pos": 48, "type": "DATASET", "confidence": 0.8955860733985901}, {"text": "NYT  datasets", "start_pos": 53, "end_pos": 66, "type": "DATASET", "confidence": 0.8654805719852448}, {"text": "document dating", "start_pos": 75, "end_pos": 90, "type": "TASK", "confidence": 0.7432007193565369}]}, {"text": " Table 3: Accuracies of different ablated methods on the APW  dataset. Overall, we observe that incorporation of context  (Bi-LSTM), syntactic structure (S-GCN) and temporal struc- ture (T-GCN) in NeuralDater achieves the best performance.  Please see Section 7.1 for details.", "labels": [], "entities": [{"text": "APW  dataset", "start_pos": 57, "end_pos": 69, "type": "DATASET", "confidence": 0.9509978890419006}, {"text": "Bi-LSTM", "start_pos": 123, "end_pos": 130, "type": "METRIC", "confidence": 0.9591796398162842}]}]}