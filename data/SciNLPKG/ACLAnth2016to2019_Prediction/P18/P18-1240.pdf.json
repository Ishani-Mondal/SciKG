{"title": [{"text": "On the Automatic Generation of Medical Imaging Reports", "labels": [], "entities": [{"text": "Automatic Generation of Medical Imaging Reports", "start_pos": 7, "end_pos": 54, "type": "TASK", "confidence": 0.8829666872819265}]}], "abstractContent": [{"text": "Medical imaging is widely used in clinical practice for diagnosis and treatment.", "labels": [], "entities": [{"text": "Medical imaging", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.6654519736766815}]}, {"text": "Report-writing can be error-prone for unexperienced physicians, and time-consuming and tedious for experienced physicians.", "labels": [], "entities": []}, {"text": "To address these issues, we study the automatic generation of medical imaging reports.", "labels": [], "entities": [{"text": "automatic generation of medical imaging reports", "start_pos": 38, "end_pos": 85, "type": "TASK", "confidence": 0.7917257845401764}]}, {"text": "This task presents several challenges.", "labels": [], "entities": []}, {"text": "First, a complete report contains multiple heterogeneous forms of information, including findings and tags.", "labels": [], "entities": []}, {"text": "Second, abnormal regions in medical images are difficult to identify.", "labels": [], "entities": []}, {"text": "Third, the reports are typically long, containing multiple sentences.", "labels": [], "entities": []}, {"text": "To cope with these challenges , we (1) build a multi-task learning framework which jointly performs the prediction of tags and the generation of paragraphs , (2) propose a co-attention mechanism to localize regions containing abnormalities and generate narrations for them, (3) develop a hierarchical LSTM model to generate long paragraphs.", "labels": [], "entities": []}, {"text": "We demonstrate the effectiveness of the proposed methods on two publicly available datasets.", "labels": [], "entities": []}], "introductionContent": [{"text": "Medical images, such as radiology and pathology images, are widely used in hospitals for the diagnosis and treatment of many diseases, such as pneumonia and pneumothorax.", "labels": [], "entities": []}, {"text": "The reading and interpretation of medical images are usually conducted by specialized medical professionals.", "labels": [], "entities": [{"text": "reading and interpretation of medical images", "start_pos": 4, "end_pos": 48, "type": "TASK", "confidence": 0.7953031013409296}]}, {"text": "For example, radiology images are read by radiologists.", "labels": [], "entities": []}, {"text": "They write textual reports) to narrate the findings regarding each area of the body examined in the imaging study, specifically whether each area was found to be normal, abnormal or potentially abnormal.", "labels": [], "entities": []}, {"text": "For less-experienced radiologists and pathologists, especially those working in the rural area where the quality of healthcare is relatively low, writing medical-imaging reports is demanding.", "labels": [], "entities": []}, {"text": "For instance, to correctly read a chest x-ray image, the following skills are needed): (1) thorough knowledge of the normal anatomy of the thorax, and the basic physiology of chest diseases; (2) skills of analyzing the radiograph through a fixed pattern; (3) ability of evaluating the evolution overtime; (4) knowledge of clinical presentation and history; (5) knowledge of the correlation with other diagnostic results (laboratory results, electrocardiogram, and respiratory function tests).", "labels": [], "entities": []}, {"text": "For experienced radiologists and pathologists, writing imaging reports is tedious and timeconsuming.", "labels": [], "entities": [{"text": "writing imaging reports", "start_pos": 47, "end_pos": 70, "type": "TASK", "confidence": 0.7538890441258749}]}, {"text": "In nations with large population such as China, a radiologist may need to read hundreds of radiology images per day.", "labels": [], "entities": []}, {"text": "Typing the findings of each image into computer takes about 5-10 minutes, which occupies most of their working time.", "labels": [], "entities": []}, {"text": "In sum, for both unexperienced and experienced medical professionals, writing imaging reports is unpleasant.", "labels": [], "entities": []}, {"text": "This motivates us to investigate whether it is possible to automatically generate medical image reports.", "labels": [], "entities": []}, {"text": "Several challenges need to be addressed.", "labels": [], "entities": []}, {"text": "First, a complete diagnostic report is comprised of multiple heterogeneous forms of information.", "labels": [], "entities": []}, {"text": "As shown in, the report fora chest xray contains impression which is a sentence, findings which area paragraph, and tags which area list of keywords.", "labels": [], "entities": []}, {"text": "Generating this heterogeneous information in a unified framework is technically demanding.", "labels": [], "entities": []}, {"text": "We address this problem by building a multi-task framework, which treats the prediction of tags as a multi-label classification task, and treats the generation of long descriptions as a text generation task.", "labels": [], "entities": [{"text": "text generation", "start_pos": 186, "end_pos": 201, "type": "TASK", "confidence": 0.6775987595319748}]}, {"text": "Second, how to localize image-regions and attach the right description to them are challenging.", "labels": [], "entities": []}, {"text": "We solve these problems by introducing a co-attention mechanism, which simultaneously attends to images and predicted tags and explores the synergistic effects of visual and semantic information.", "labels": [], "entities": []}, {"text": "Third, the descriptions in imaging reports are usually long, containing multiple sentences.", "labels": [], "entities": []}, {"text": "Generating such long text is highly nontrivial.", "labels": [], "entities": []}, {"text": "Rather than adopting a single-layer LSTM, which is less capable of modeling long word sequences, we leverage the compositional nature of the report and adopt a hierarchical LSTM to produce long texts.", "labels": [], "entities": []}, {"text": "Combined with the co-attention mechanism, the hierarchical LSTM first generates high-level topics, and then produces fine-grained descriptions according to the topics.", "labels": [], "entities": []}, {"text": "Overall, the main contributions of our work are: \u2022 We propose a multi-task learning framework which can simultaneously predict the tags and generate the text descriptions.", "labels": [], "entities": []}, {"text": "\u2022 We introduce a co-attention mechanism for localizing sub-regions in the image and generating the corresponding descriptions.", "labels": [], "entities": []}, {"text": "\u2022 We build a hierarchical LSTM to generate long paragraphs.", "labels": [], "entities": []}, {"text": "\u2022 We perform extensive experiments to show the effectiveness of the proposed methods.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 reviews related works.", "labels": [], "entities": []}, {"text": "Section 3 introduces the method.", "labels": [], "entities": []}, {"text": "Section 4 present the experimental results and Section 5 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we evaluate the proposed model with extensive quantitative and qualitative experiments.", "labels": [], "entities": []}, {"text": "We used two publicly available medical image datasets to evaluate our proposed model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Main results for paragraph generation on the IU X-Ray dataset (upper part), and single sentence  generation on the PEIR Gross dataset (lower part). BLUE-n denotes the BLEU score that uses up to  n-grams.", "labels": [], "entities": [{"text": "paragraph generation", "start_pos": 27, "end_pos": 47, "type": "TASK", "confidence": 0.8565521538257599}, {"text": "IU X-Ray dataset", "start_pos": 55, "end_pos": 71, "type": "DATASET", "confidence": 0.8913772702217102}, {"text": "single sentence  generation", "start_pos": 90, "end_pos": 117, "type": "TASK", "confidence": 0.7290919621785482}, {"text": "PEIR Gross dataset", "start_pos": 125, "end_pos": 143, "type": "DATASET", "confidence": 0.9508400758107504}, {"text": "BLUE-n", "start_pos": 158, "end_pos": 164, "type": "METRIC", "confidence": 0.9980406165122986}, {"text": "BLEU score", "start_pos": 177, "end_pos": 187, "type": "METRIC", "confidence": 0.9806378483772278}]}, {"text": " Table 2: Portion of sentences which describe the  normalities and abnormalities in the image.", "labels": [], "entities": []}]}