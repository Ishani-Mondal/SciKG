{"title": [{"text": "A Simple and Effective Approach to Coverage-Aware Neural Machine Translation", "labels": [], "entities": [{"text": "Coverage-Aware Neural Machine Translation", "start_pos": 35, "end_pos": 76, "type": "TASK", "confidence": 0.8517421633005142}]}], "abstractContent": [{"text": "We offer a simple and effective method to seek a better balance between model confidence and length preference for Neural Machine Translation (NMT).", "labels": [], "entities": [{"text": "length", "start_pos": 93, "end_pos": 99, "type": "METRIC", "confidence": 0.9521480202674866}, {"text": "Neural Machine Translation (NMT)", "start_pos": 115, "end_pos": 147, "type": "TASK", "confidence": 0.8203323980172476}]}, {"text": "Unlike the popular length normalization and coverage models, our model does not require training nor reranking the limited n-best outputs.", "labels": [], "entities": [{"text": "length normalization", "start_pos": 19, "end_pos": 39, "type": "TASK", "confidence": 0.6572506725788116}]}, {"text": "Moreover, it is robust to large beam sizes, which is not well studied in previous work.", "labels": [], "entities": []}, {"text": "On the Chinese-English and English-German translation tasks, our approach yields +0.4 \u223c 1.5 BLEU improvements over the state-of-the-art base-lines.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 92, "end_pos": 96, "type": "METRIC", "confidence": 0.9989545345306396}]}], "introductionContent": [{"text": "In the past few years, Neural Machine Translation (NMT) has achieved state-of-the-art performance in many translation tasks.", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT)", "start_pos": 23, "end_pos": 55, "type": "TASK", "confidence": 0.7774976293245951}]}, {"text": "It models the translation problem using neural networks with no assumption of the hidden structures between two languages, and learns the model parameters from bilingual texts in an end-to-end fashion).", "labels": [], "entities": [{"text": "translation problem", "start_pos": 14, "end_pos": 33, "type": "TASK", "confidence": 0.9179934859275818}]}, {"text": "In such systems, target words are generated over a sequence of time steps.", "labels": [], "entities": []}, {"text": "The model score is simply defined as the sum of the log-scale word probabilities: log P(y|x) = |y| j=1 log P(y j |y <j , x) where x and y are the source and target sentences, and P(y j |y <j , x) is the probability of generating the j-th wordy j given the previously-generated words y <j and the source sentence x.", "labels": [], "entities": []}, {"text": "However, the straightforward implementation of this model suffers from many problems, the most obvious one being the bias that the system tends to choose shorter translations because the log-probability is added overtime steps.", "labels": [], "entities": []}, {"text": "The situation is worse when we use beam search where the shorter translations have more chances to beat the longer ones.", "labels": [], "entities": [{"text": "beam search", "start_pos": 35, "end_pos": 46, "type": "TASK", "confidence": 0.8165235817432404}]}, {"text": "It is in general to normalize the model score by translation length (say length normalization) to eliminate this system bias (.", "labels": [], "entities": []}, {"text": "Though widely used, length normalization is not a perfect solution.", "labels": [], "entities": [{"text": "length normalization", "start_pos": 20, "end_pos": 40, "type": "TASK", "confidence": 0.8973534107208252}]}, {"text": "NMT systems still have under-translation and over-translation problem even with a normalized model.", "labels": [], "entities": []}, {"text": "It is due to the lack of the coverage model that indicates the degree a source word is translated.", "labels": [], "entities": []}, {"text": "As an extreme case, a source word might be translated for several times, which results in many duplicated target words.", "labels": [], "entities": []}, {"text": "Several research groups have proposed solutions to this bad case ().", "labels": [], "entities": []}, {"text": "E.g., developed a coveragebased model to measure the fractional count that a source word is translated during decoding.", "labels": [], "entities": []}, {"text": "It can be jointly learned with the NMT model.", "labels": [], "entities": []}, {"text": "Alternatively, one can rerank the n-best outputs by coverage-sensitive models, but this method just affects the final output list which has a very limited scope (.", "labels": [], "entities": []}, {"text": "In this paper we present a simple and effective approach by introducing a coverage-based feature into NMT.", "labels": [], "entities": []}, {"text": "Unlike previous studies, we do not resort to developing extra models nor reranking the limited n-best translations.", "labels": [], "entities": []}, {"text": "Instead, we develop a coverage score and apply it to each decoding step.", "labels": [], "entities": [{"text": "coverage score", "start_pos": 22, "end_pos": 36, "type": "METRIC", "confidence": 0.9624202847480774}]}, {"text": "Our approach has several benefits, \u2022 Our approach does not require to train a huge neural network and is easy to implement.", "labels": [], "entities": []}, {"text": "\u2022 Our approach works on beam search for each target position and thus can access more translation hypotheses.", "labels": [], "entities": []}, {"text": "\u2022 Our approach works consistently well under different sized beam search and sentence lengths contrary to what is observed in other systems ().", "labels": [], "entities": []}, {"text": "We test our approach on the NIST ChineseEnglish and WMT English-German translation tasks, and it outperforms several state-of-the-art baselines by 0.4\u223c1.5 BLEU points.", "labels": [], "entities": [{"text": "NIST ChineseEnglish", "start_pos": 28, "end_pos": 47, "type": "DATASET", "confidence": 0.8480429649353027}, {"text": "WMT English-German translation", "start_pos": 52, "end_pos": 82, "type": "TASK", "confidence": 0.6440794269243876}, {"text": "BLEU", "start_pos": 155, "end_pos": 159, "type": "METRIC", "confidence": 0.9985559582710266}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: BLEU against \u03b1 and \u03b2 (zh-en/en-de)", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9995019435882568}]}]}