{"title": [{"text": "End-Task Oriented Textual Entailment via Deep Explorations of Inter-Sentence Interactions", "labels": [], "entities": [{"text": "End-Task Oriented Textual Entailment", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.5851409509778023}]}], "abstractContent": [{"text": "This work deals with SCITAIL, a natural entailment challenge derived from a multi-choice question answering problem.", "labels": [], "entities": [{"text": "SCITAIL", "start_pos": 21, "end_pos": 28, "type": "TASK", "confidence": 0.8848208785057068}, {"text": "multi-choice question answering problem", "start_pos": 76, "end_pos": 115, "type": "TASK", "confidence": 0.6728158369660378}]}, {"text": "The premises and hypotheses in SCITAIL were generated with no awareness of each other, and did not specifically aim at the entailment task.", "labels": [], "entities": []}, {"text": "This makes it more challenging than other entailment data sets and more directly useful to the end-task-question answering.", "labels": [], "entities": [{"text": "end-task-question answering", "start_pos": 95, "end_pos": 122, "type": "TASK", "confidence": 0.7058177888393402}]}, {"text": "We propose DEISTE (deep explorations of inter-sentence interactions for textual entailment) for this entail-ment task.", "labels": [], "entities": [{"text": "DEISTE", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.984825074672699}]}, {"text": "Given word-to-word interactions between the premise-hypothesis pair (P , H), DEISTE consists of: (i) a parameter-dynamic convolution to make important words in P and H play a dominant role in learnt representations; and (ii) a position-aware attentive convolution to encode the representation and position information of the aligned word pairs.", "labels": [], "entities": [{"text": "DEISTE", "start_pos": 77, "end_pos": 83, "type": "METRIC", "confidence": 0.6498156785964966}]}, {"text": "Experiments show that DEISTE gets \u22485% improvement over prior state of the art and that the pretrained DEISTE on SCI-TAIL generalizes well on RTE-5. 1", "labels": [], "entities": [{"text": "DEISTE", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.8941187858581543}]}], "introductionContent": [{"text": "Textual entailment (TE) is a fundamental problem in natural language understanding and has been studied intensively recently using multiple benchmarks -PASCAL RTE challenges (, Paragraph-Headline (), SICK () and SNLI).", "labels": [], "entities": [{"text": "Textual entailment (TE)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8472289025783539}, {"text": "natural language understanding", "start_pos": 52, "end_pos": 82, "type": "TASK", "confidence": 0.6497326791286469}]}, {"text": "In particular, SNLI -while much easier than earlier datasets https://github.com/yinwenpeng/SciTail Premise P Pluto rotates once on its axis every 6.39 Earth days.", "labels": [], "entities": [{"text": "Premise", "start_pos": 99, "end_pos": 106, "type": "METRIC", "confidence": 0.8900935053825378}]}, {"text": "0 Once per day, the earth rotates about its axis.", "labels": [], "entities": []}, {"text": "1 It rotates on its axis once every 60 Earth days.", "labels": [], "entities": []}, {"text": "0 Earth orbits Sun, and rotates once per day about axis.", "labels": [], "entities": []}, {"text": "1: Examples of four premises for the hypothesis \"Earth rotates on its axis once times in one day\" in SCITAIL dataset.", "labels": [], "entities": [{"text": "SCITAIL dataset", "start_pos": 101, "end_pos": 116, "type": "DATASET", "confidence": 0.915913999080658}]}, {"text": "Right column (label): \"1\" means entail, \"0\" otherwise.", "labels": [], "entities": []}, {"text": "-has generated much work based on deep neural networks due to its large size.", "labels": [], "entities": []}, {"text": "However, these benchmarks were mostly derived independently of any NLP problems.", "labels": [], "entities": []}, {"text": "Therefore, the premisehypothesis pairs were composed under the constraint of predefined rules and the language skills of humans.", "labels": [], "entities": []}, {"text": "As a result, while top-performing systems push forward the state-of-the-art, they do not necessarily learn to support language inferences that emerge commonly and naturally in real NLP problems.", "labels": [], "entities": []}, {"text": "In this work, we study SCITAIL (), an end-task oriented challenging entailment benchmark.", "labels": [], "entities": []}, {"text": "SCITAIL is reformatted from a multi-choice question answering problem.", "labels": [], "entities": [{"text": "multi-choice question answering", "start_pos": 30, "end_pos": 61, "type": "TASK", "confidence": 0.6522182921568552}]}, {"text": "All hypotheses H were obtained by rewriting (question, correct answer) pairs; all premises P are relevant web sentences collected by an Information retrieval (IR) method; then (P , H) pairs are annotated via crowdsourcing.", "labels": [], "entities": []}, {"text": "By this construction, a substantial performance gain on SCITAIL can be turned into better QA performance (.", "labels": [], "entities": []}, {"text": "report that SCITAIL challenges neural entailment models that show outstanding performance on SNLI, e.g., Decomposable Attention Model ( and Enhanced LSTM (.", "labels": [], "entities": []}, {"text": "We propose DEISTE for SCITAIL.", "labels": [], "entities": [{"text": "DEISTE", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.9974461793899536}, {"text": "SCITAIL", "start_pos": 22, "end_pos": 29, "type": "TASK", "confidence": 0.6272590756416321}]}, {"text": "Given word-to-word inter-sentence interactions between   For any word in one of (P , H), how to find the best aligned word in the other sentence, so that we know their connection is indicative of the final decision.", "labels": [], "entities": []}, {"text": "(c) For a window of words in P or H, whether the locations of their best aligned words in the other sentence provides clues.", "labels": [], "entities": []}, {"text": "As illustrates, the premise \"in this incident, the cop (C) shot (S) the thief (T )\" is more likely to entail the hypothesis \" X is the word that best matches X.", "labels": [], "entities": []}, {"text": "Our model DEISTE is implemented in convolutional neural architecture ().", "labels": [], "entities": []}, {"text": "Specifically, DEISTE consists of (i) a parameterdynamic convolution for exploration strategy (a) given above; and (ii) a position-aware attentive convolution for exploration strategies (b) and (c).", "labels": [], "entities": [{"text": "DEISTE", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.5712403655052185}]}, {"text": "In experiments, DEISTE outperforms prior top systems by \u22485%.", "labels": [], "entities": [{"text": "DEISTE", "start_pos": 16, "end_pos": 22, "type": "METRIC", "confidence": 0.8700449466705322}]}, {"text": "Perhaps even more interestingly, the pretrained model over SCI-TAIL generalizes well on RTE-5.", "labels": [], "entities": [{"text": "RTE-5", "start_pos": 88, "end_pos": 93, "type": "DATASET", "confidence": 0.84583979845047}]}], "datasetContent": [{"text": "To further study the systems and datasets, gives performance of DEISTE and baselines on SNLI.", "labels": [], "entities": [{"text": "DEISTE", "start_pos": 64, "end_pos": 70, "type": "DATASET", "confidence": 0.6297101974487305}, {"text": "SNLI", "start_pos": 88, "end_pos": 92, "type": "DATASET", "confidence": 0.9312301874160767}]}, {"text": "We see that DEISTE gets competitive performance on SNLI.", "labels": [], "entities": [{"text": "DEISTE", "start_pos": 12, "end_pos": 18, "type": "METRIC", "confidence": 0.8365628719329834}, {"text": "SNLI", "start_pos": 51, "end_pos": 55, "type": "DATASET", "confidence": 0.9102154970169067}]}, {"text": "Comparing, the baselines \"hypothesis only\" and \"premise only\" show analogous while different phenomena between SCI-TAIL and SNLI.", "labels": [], "entities": []}, {"text": "On one hand, both SNLI and SCITAIL can get a relatively high number by looking at only one of {premise, hypothesis} -\"premise only\" gets 73.4% accuracy on SCITAIL, even higher than two more complicated baselines (ESIM-600D and Decomp-Att), and \"hypothesis only\" gets 68.7% accuracy on SNLI which is more than 30% higher than the \"majority\" and \"premise only\" baselines.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 143, "end_pos": 151, "type": "METRIC", "confidence": 0.9934710264205933}, {"text": "accuracy", "start_pos": 273, "end_pos": 281, "type": "METRIC", "confidence": 0.9978871941566467}]}, {"text": "Notice the contrast: SNLI \"prefers\" hypothesis, SCITAIL \"prefers\" premise.", "labels": [], "entities": []}, {"text": "For SNLI, this is not surprising as the crowd-workers tend to construct the hypotheses in SNLI by some regular rules ().", "labels": [], "entities": [{"text": "SNLI", "start_pos": 4, "end_pos": 8, "type": "TASK", "confidence": 0.8241488337516785}, {"text": "SNLI", "start_pos": 90, "end_pos": 94, "type": "DATASET", "confidence": 0.7674241065979004}]}, {"text": "The phenomenon in SCITAIL is left to explore in future work.", "labels": [], "entities": []}, {"text": "We explain them as follows.", "labels": [], "entities": []}, {"text": "Language conventions: The pair #1 uses dash \"-\" to indicate a definition sentence for \"Front\"; The pair #2 has \"A (or B)\" to denote the equivalence between A and B.", "labels": [], "entities": []}, {"text": "This challenge is expected to be handled by rules.", "labels": [], "entities": []}, {"text": "Ambiguity: The pair #3 looks like having a similar challenge with the pair #2.", "labels": [], "entities": [{"text": "Ambiguity", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9831779599189758}]}, {"text": "We guess the annotators treat \"\u00b7 \u00b7 \u00b7 a vertebral column or backbone\" and \" \u00b7 \u00b7 \u00b7 the backbone (or vertebral column)\" as the same convention, which maybe debatable.", "labels": [], "entities": []}, {"text": "the pair #4 has an \"or\" structure.", "labels": [], "entities": []}, {"text": "In the pair #5, \"a molecule made of \u00b7 \u00b7 \u00b7 \" defines the concept \"Ethane\" instead of the \"hydrocarbon\".", "labels": [], "entities": []}, {"text": "Both cases require the model to be able to comprehend the discourse relation.", "labels": [], "entities": []}, {"text": "Knowledge beyond text: The main challenge in the pair #6 is to distinguish between \"weight\" and \"force\", which requires more physical knowledge that is beyond the text described here and beyond the expressivity of word embeddings.", "labels": [], "entities": []}, {"text": "One main motivation of exploring this SCITAIL problem is that this is an end-task oriented TE task.", "labels": [], "entities": [{"text": "SCITAIL problem", "start_pos": 38, "end_pos": 53, "type": "TASK", "confidence": 0.8619884252548218}]}, {"text": "A natural question thus is how well the trained model can be transferred to other end-task oriented TE tasks.", "labels": [], "entities": []}, {"text": "In, we take the models pretrained on SCI-TAIL and SNLI and test them on RTE-5.", "labels": [], "entities": [{"text": "SNLI", "start_pos": 50, "end_pos": 54, "type": "DATASET", "confidence": 0.8290033936500549}, {"text": "RTE-5", "start_pos": 72, "end_pos": 77, "type": "DATASET", "confidence": 0.9151903986930847}]}, {"text": "Clearly, the model pretrained on SNLI has not learned anything useful for RTE-5 -its performance of 46.0% is even worse than the majority baseline.", "labels": [], "entities": [{"text": "SNLI", "start_pos": 33, "end_pos": 37, "type": "DATASET", "confidence": 0.8748549818992615}]}, {"text": "The model pretrained on SCITAIL, in contrast, demonstrates much more promising generalization performance: 60.2% vs. 46.0%.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: DEISTE vs. baselines on SCITAIL", "labels": [], "entities": [{"text": "DEISTE", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9527060389518738}, {"text": "SCITAIL", "start_pos": 34, "end_pos": 41, "type": "TASK", "confidence": 0.4711573123931885}]}, {"text": " Table 3:  DEISTE vs. baselines on SNLI.  DEISTE SCITAIL has exactly the same system layout  and hyperparameters as the one reported on SCI- TAIL in", "labels": [], "entities": [{"text": "SNLI", "start_pos": 35, "end_pos": 39, "type": "DATASET", "confidence": 0.8557706475257874}, {"text": "DEISTE SCITAIL", "start_pos": 42, "end_pos": 56, "type": "DATASET", "confidence": 0.6675229668617249}]}, {"text": " Table 4: Error cases of DEISTE in SCITAIL. \"\u00b7 \u00b7 \u00b7 \": truncated text. \"G/P\": gold/predicted label.", "labels": [], "entities": [{"text": "DEISTE", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.8510479927062988}]}, {"text": " Table 5: Train on different TE datasets, test accu- racy on two-way RTE-5. State-of-the-art refers to  (Iftene and Moruz, 2009)", "labels": [], "entities": [{"text": "TE datasets", "start_pos": 29, "end_pos": 40, "type": "DATASET", "confidence": 0.743845745921135}]}]}