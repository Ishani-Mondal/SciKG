{"title": [{"text": "Reasoning with Sarcasm by Reading In-between", "labels": [], "entities": [{"text": "Reasoning with Sarcasm", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9049030542373657}]}], "abstractContent": [{"text": "Sarcasm is a sophisticated speech act which commonly manifests on social communities such as Twitter and Reddit.", "labels": [], "entities": []}, {"text": "The prevalence of sarcasm on the social web is highly disruptive to opinion mining systems due to not only its tendency of polarity flipping but also usage of figurative language.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 68, "end_pos": 82, "type": "TASK", "confidence": 0.7697410881519318}]}, {"text": "Sarcasm commonly manifests with a contrastive theme either between positive-negative sentiments or between literal-figurative scenarios.", "labels": [], "entities": []}, {"text": "In this paper, we revisit the notion of model-ing contrast in order to reason with sarcasm.", "labels": [], "entities": []}, {"text": "More specifically, we propose an attention-based neural model that looks in-between instead of across, enabling it to explicitly model contrast and incongruity.", "labels": [], "entities": []}, {"text": "We conduct extensive experiments on six benchmark datasets from Twitter, Reddit and the Internet Argument Corpus.", "labels": [], "entities": [{"text": "Internet Argument Corpus", "start_pos": 88, "end_pos": 112, "type": "DATASET", "confidence": 0.7656607230504354}]}, {"text": "Our proposed model not only achieves state-of-the-art performance on all datasets but also enjoys improved interpretability.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sarcasm, commonly defined as 'An ironical taunt used to express contempt', is a challenging NLP problem due to its highly figurative nature.", "labels": [], "entities": []}, {"text": "The usage of sarcasm on the social web is prevalent and can be frequently observed in reviews, microblogs (tweets) and online forums.", "labels": [], "entities": []}, {"text": "As such, the battle against sarcasm is also regularly cited as one of the key challenges in sentiment analysis and opinion mining applications (.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 92, "end_pos": 110, "type": "TASK", "confidence": 0.9701849818229675}, {"text": "opinion mining", "start_pos": 115, "end_pos": 129, "type": "TASK", "confidence": 0.7547379434108734}]}, {"text": "Hence, it is both imperative and intuitive that effective sarcasm detectors can bring about numerous benefits to opinion mining applications.", "labels": [], "entities": [{"text": "sarcasm detectors", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.8675621747970581}, {"text": "opinion mining", "start_pos": 113, "end_pos": 127, "type": "TASK", "confidence": 0.8516068756580353}]}, {"text": "Sarcasm is often associated to several linguistic phenomena such as (1) an explicit contrast between sentiments or (2) disparity between the conveyed emotion and the author's situation (context).", "labels": [], "entities": []}, {"text": "Prior work has considered sarcasm to be a contrast between a positive and negative sentiment (.", "labels": [], "entities": []}, {"text": "Consider the following examples: 1.", "labels": [], "entities": []}, {"text": "I absolutely love to be ignored!", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe our experimental setup and results.", "labels": [], "entities": []}, {"text": "Our experiments were designed to answer the following research questions (RQs).", "labels": [], "entities": []}, {"text": "\u2022 RQ1 -Does our proposed approach outperform existing state-of-the-art models?", "labels": [], "entities": []}, {"text": "\u2022 RQ2 -What are the impacts of some of the architectural choices of our model?", "labels": [], "entities": []}, {"text": "How much does intra-attention contribute to the model performance?", "labels": [], "entities": []}, {"text": "Is the MultiDimensional adaptation better than the Single-Dimensional adaptation?", "labels": [], "entities": []}, {"text": "\u2022 RQ3 -What can we interpret from the intraattention layers?", "labels": [], "entities": []}, {"text": "Does this align with our hypothesis about looking in-between and modeling contrast?", "labels": [], "entities": []}, {"text": "We conduct our experiments on six publicly available benchmark datasets which span across three well-known sources.", "labels": [], "entities": []}, {"text": "\u2022 Tweets -Twitter 2 is a microblogging platform which allows users to post statuses of less than 140 characters.", "labels": [], "entities": []}, {"text": "We use two collections for sarcasm detection on tweets.", "labels": [], "entities": [{"text": "sarcasm detection", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.928113579750061}]}, {"text": "More specifically, we use the dataset obtained from (1)) in which tweets are trained via hashtag based semisupervised learning, i.e., hashtags such as #not, #sarcasm and #irony are marked as sarcastic tweets and (2) () in which Tweets are hand annotated and manually checked for sarcasm.", "labels": [], "entities": []}, {"text": "For both datasets, we retrieve.", "labels": [], "entities": []}, {"text": "Tweets using the Twitter API using the provided tweet IDs.", "labels": [], "entities": []}, {"text": "\u2022 Reddit -Reddit 3 is a highly popular social forum and community.", "labels": [], "entities": []}, {"text": "Similar to Tweets, sarcastic posts are obtained via the tag '/s' which are marked by the authors themselves.", "labels": [], "entities": []}, {"text": "We use two Reddit datasets which are obtained from the subreddits /r/movies and /r/technology respectively.", "labels": [], "entities": [{"text": "Reddit datasets", "start_pos": 11, "end_pos": 26, "type": "DATASET", "confidence": 0.8921783864498138}]}, {"text": "Datasets are subsets from).", "labels": [], "entities": []}, {"text": "\u2022 Debates -We use two datasets 4 from the Internet Argument Corpus (IAC)) which have been hand annotated for sarcasm.", "labels": [], "entities": [{"text": "Internet Argument Corpus (IAC))", "start_pos": 42, "end_pos": 73, "type": "DATASET", "confidence": 0.781153659025828}]}, {"text": "This dataset, unlike the first two, is mainly concerned with long text and provides a diverse comparison from the other datasets.", "labels": [], "entities": []}, {"text": "The IAC corpus was designed for research on political debates on online forums.", "labels": [], "entities": [{"text": "IAC corpus", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.8363274335861206}]}, {"text": "We use the V1 and V2 versions of the sarcasm corpus which are denoted as IAC-V1 and IAC-V2 respectively.", "labels": [], "entities": [{"text": "IAC-V1", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.7474663853645325}, {"text": "IAC-V2", "start_pos": 84, "end_pos": 90, "type": "DATASET", "confidence": 0.7020851373672485}]}, {"text": "The statistics of the datasets used in our experiments is reported in  Finally, the relative performance of competitor methods are as expected.", "labels": [], "entities": []}, {"text": "NBOW performs the worse, since it is just a naive bag-of-words model without any compositional or sequential information.", "labels": [], "entities": [{"text": "NBOW", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9358068108558655}]}, {"text": "On short text, LSTMs are overall better than CNNs.", "labels": [], "entities": []}, {"text": "However, this trend is reversed on long text (i.e., Debates) since the LSTM model maybe overburdened by overly long sequences.", "labels": [], "entities": []}, {"text": "On short text, we also found that attention (or the gated pooling mechanism from GRNN) did not really help make any significant improvements over the vanilla LSTM model and a qualitative explanation to why this is so is deferred to the next section.", "labels": [], "entities": [{"text": "GRNN", "start_pos": 81, "end_pos": 85, "type": "DATASET", "confidence": 0.8305792808532715}]}, {"text": "However, attention helps for long text (such as debates), resulting in Attention LSTMs becoming the strongest baseline on the Debates datasets.", "labels": [], "entities": [{"text": "Debates datasets", "start_pos": 126, "end_pos": 142, "type": "DATASET", "confidence": 0.9211202561855316}]}, {"text": "However, our proposed intra-attentive model is both effective on short text and long text, outperforming Attention LSTMs consistently on all datasets.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of datasets used in our experiments.", "labels": [], "entities": []}, {"text": " Table 2: Experimental Results on Tweets datasets. Best result in is boldface and second best is underlined. Best performing  baseline is in italics.", "labels": [], "entities": [{"text": "Tweets datasets", "start_pos": 34, "end_pos": 49, "type": "DATASET", "confidence": 0.6554786115884781}]}, {"text": " Table 3: Experimental results on Reddit datasets. Best result in is boldface and second best is underlined. Best performing  baseline is in italics.", "labels": [], "entities": [{"text": "Reddit datasets", "start_pos": 34, "end_pos": 49, "type": "DATASET", "confidence": 0.9004665911197662}]}, {"text": " Table 4: Experimental results on Debates datasets. Best result in is boldface and second best is underlined. Best performing  baseline is in italics.", "labels": [], "entities": [{"text": "Debates datasets", "start_pos": 34, "end_pos": 50, "type": "DATASET", "confidence": 0.8294559717178345}]}]}