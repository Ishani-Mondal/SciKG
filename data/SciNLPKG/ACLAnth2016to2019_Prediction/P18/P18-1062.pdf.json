{"title": [{"text": "Unsupervised Abstractive Meeting Summarization with Multi-Sentence Compression and Budgeted Submodular Maximization", "labels": [], "entities": [{"text": "Summarization", "start_pos": 33, "end_pos": 46, "type": "TASK", "confidence": 0.8949286937713623}, {"text": "Submodular Maximization", "start_pos": 92, "end_pos": 115, "type": "TASK", "confidence": 0.6573044657707214}]}], "abstractContent": [{"text": "We introduce a novel graph-based framework for abstractive meeting speech sum-marization that is fully unsupervised and does not rely on any annotations.", "labels": [], "entities": []}, {"text": "Our work combines the strengths of multiple recent approaches while addressing their weaknesses.", "labels": [], "entities": []}, {"text": "Moreover, we leverage recent advances in word embeddings and graph degeneracy applied to NLP to take exterior semantic knowledge into account, and to design custom diversity and informative-ness measures.", "labels": [], "entities": []}, {"text": "Experiments on the AMI and ICSI corpus show that our system improves on the state-of-the-art.", "labels": [], "entities": [{"text": "AMI", "start_pos": 19, "end_pos": 22, "type": "DATASET", "confidence": 0.8392542600631714}, {"text": "ICSI corpus", "start_pos": 27, "end_pos": 38, "type": "DATASET", "confidence": 0.9000846743583679}]}, {"text": "Code and data are publicly available 1 , and our system can be interactively tested 2 .", "labels": [], "entities": []}], "introductionContent": [{"text": "People spend a lot of their time in meetings.", "labels": [], "entities": []}, {"text": "The ubiquity of web-based meeting tools and the rapid improvement and adoption of Automatic Speech Recognition (ASR) is creating pressing needs for effective meeting speech summarization mechanisms.", "labels": [], "entities": [{"text": "Automatic Speech Recognition (ASR)", "start_pos": 82, "end_pos": 116, "type": "TASK", "confidence": 0.7579626987377802}, {"text": "meeting speech summarization", "start_pos": 158, "end_pos": 186, "type": "TASK", "confidence": 0.6286949515342712}]}, {"text": "Spontaneous multi-party meeting speech transcriptions widely differ from traditional documents.", "labels": [], "entities": [{"text": "Spontaneous multi-party meeting speech transcriptions", "start_pos": 0, "end_pos": 53, "type": "TASK", "confidence": 0.6983549237251282}]}, {"text": "Instead of grammatical, well-segmented sentences, the input is made of often ill-formed and ungrammatical text fragments called utterances.", "labels": [], "entities": []}, {"text": "On top of that, ASR transcription and segmentation errors inject additional noise into the input.", "labels": [], "entities": [{"text": "ASR transcription", "start_pos": 16, "end_pos": 33, "type": "TASK", "confidence": 0.8407259285449982}]}, {"text": "In this paper, we combine the strengths of 6 approaches that had previously been applied * Work done as part of 3 rd year project, with equal contribution.", "labels": [], "entities": []}, {"text": "to 3 different tasks (keyword extraction, multisentence compression, and summarization) into a unified, fully unsupervised end-to-end meeting speech summarization framework that can generate readable summaries despite the noise inherent to ASR transcriptions.", "labels": [], "entities": [{"text": "keyword extraction", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.7453026324510574}, {"text": "multisentence compression", "start_pos": 42, "end_pos": 67, "type": "TASK", "confidence": 0.7570924460887909}, {"text": "summarization", "start_pos": 73, "end_pos": 86, "type": "TASK", "confidence": 0.9908782839775085}, {"text": "end-to-end meeting speech summarization", "start_pos": 123, "end_pos": 162, "type": "TASK", "confidence": 0.7093680202960968}, {"text": "ASR transcriptions", "start_pos": 240, "end_pos": 258, "type": "TASK", "confidence": 0.948184072971344}]}, {"text": "We also introduce some novel components.", "labels": [], "entities": []}, {"text": "Our method reaches state-ofthe-art performance and can be applied to languages other than English in an almost out-of-thebox fashion.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted experiments on the widely-used AMI () and ICSI (Janin et al., 2003) benchmark datasets.", "labels": [], "entities": [{"text": "ICSI (Janin et al., 2003) benchmark datasets", "start_pos": 55, "end_pos": 99, "type": "DATASET", "confidence": 0.7466825008392334}]}, {"text": "We used the traditional test sets of 20 and 6 meetings respectively for the AMI and ICSI corpora (.", "labels": [], "entities": [{"text": "AMI", "start_pos": 76, "end_pos": 79, "type": "DATASET", "confidence": 0.8529020547866821}, {"text": "ICSI corpora", "start_pos": 84, "end_pos": 96, "type": "DATASET", "confidence": 0.7996442019939423}]}, {"text": "Each meeting in the AMI test set is associated with a human abstractive summary of 290 words on average, whereas each meeting in the ICSI test set is associated with 3 human abstractive summaries of respective average sizes 220, 220 and 670 words.", "labels": [], "entities": [{"text": "AMI test set", "start_pos": 20, "end_pos": 32, "type": "DATASET", "confidence": 0.9447189569473267}, {"text": "ICSI test set", "start_pos": 133, "end_pos": 146, "type": "DATASET", "confidence": 0.966166079044342}]}, {"text": "For parameter tuning, we constructed development sets of 47 and 25 meetings, respectively for AMI and ICSI, by randomly sampling from the training sets.", "labels": [], "entities": [{"text": "parameter tuning", "start_pos": 4, "end_pos": 20, "type": "TASK", "confidence": 0.7871618568897247}, {"text": "AMI", "start_pos": 94, "end_pos": 97, "type": "DATASET", "confidence": 0.8521154522895813}, {"text": "ICSI", "start_pos": 102, "end_pos": 106, "type": "DATASET", "confidence": 0.7584605813026428}]}, {"text": "The word error rate of the ASR transcriptions is respectively of 36% and 37% for AMI and ICSI.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 4, "end_pos": 19, "type": "METRIC", "confidence": 0.7754410107930502}, {"text": "ASR transcriptions", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.8733109831809998}, {"text": "AMI", "start_pos": 81, "end_pos": 84, "type": "DATASET", "confidence": 0.7042711973190308}, {"text": "ICSI", "start_pos": 89, "end_pos": 93, "type": "DATASET", "confidence": 0.7545262575149536}]}], "tableCaptions": [{"text": " Table 2: Macro-averaged results for 350 and 450 word summaries (ASR transcriptions).", "labels": [], "entities": [{"text": "ASR transcriptions", "start_pos": 65, "end_pos": 83, "type": "TASK", "confidence": 0.7902700901031494}]}]}