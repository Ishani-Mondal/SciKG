{"title": [{"text": "Docforia: A Multilayer Document Model", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we describe Docforia, a multilayer document model and application programming interface (API) to store formatting, lexical, syntactic, and semantic annotations on Wikipedia and other kinds of text and visualize them.", "labels": [], "entities": []}, {"text": "While Wikipedia has become a major NLP resource , its scale and heterogeneity makes it relatively difficult to do experimenta-tions on the whole corpus.", "labels": [], "entities": []}, {"text": "These exper-imentations are rendered even more complex as, to the best of our knowledge, there is no available tool to visualize easily the results of a processing pipeline.", "labels": [], "entities": []}, {"text": "We designed Docforia so that it can store millions of documents and billions of tokens , annotated using different processing tools, that themselves use multiple formats , and compatible with cluster computing frameworks such as Hadoop or Spark.", "labels": [], "entities": []}, {"text": "The annotation output, either partial or complete, can then be shared more easily.", "labels": [], "entities": []}, {"text": "To validate Docforia, we processed six language versions of Wikipedia: En-glish, French, German, Spanish, Russian, and Swedish, up to semantic role labeling, depending on the NLP tools available fora given language.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 134, "end_pos": 156, "type": "TASK", "confidence": 0.6026145815849304}]}, {"text": "We stored the results in our document model and we created a vi-sualization tool to inspect the annotation results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Wikipedia is one of the largest freely available encyclopedic sources: It is comprehensive, multilingual, and continuously expanding.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9024824500083923}]}, {"text": "These unique properties make it a popular resource now used in scores of NLP projects such as translation (, semantic networks, named entity linking, information extraction, or question answering.", "labels": [], "entities": [{"text": "translation", "start_pos": 94, "end_pos": 105, "type": "TASK", "confidence": 0.9842718243598938}, {"text": "named entity linking", "start_pos": 128, "end_pos": 148, "type": "TASK", "confidence": 0.6558981041113535}, {"text": "information extraction", "start_pos": 150, "end_pos": 172, "type": "TASK", "confidence": 0.7895594835281372}, {"text": "question answering", "start_pos": 177, "end_pos": 195, "type": "TASK", "confidence": 0.8970431387424469}]}, {"text": "Nonetheless, the Wikipedia size, where many language versions have now more that one million of articles makes it more difficult to handle than \"classic\" and older corpora such as the Penn treebank (.", "labels": [], "entities": [{"text": "Penn treebank", "start_pos": 184, "end_pos": 197, "type": "DATASET", "confidence": 0.9890669882297516}]}, {"text": "Processing the complete collection of Wikipedia articles, or apart of it, is a nontrivial task that requires dealing with multiple markup variants across the language versions, multiple tools and storage models.", "labels": [], "entities": [{"text": "Processing the complete collection of Wikipedia articles", "start_pos": 0, "end_pos": 56, "type": "TASK", "confidence": 0.6546665089471}]}, {"text": "In addition, the application of a NLP pipeline to carryout the annotation (tokenization, POS tagging, dependency parsing, and so on) is a relatively costly operation that can take weeks on a single computer.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 89, "end_pos": 100, "type": "TASK", "confidence": 0.7874106764793396}, {"text": "dependency parsing", "start_pos": 102, "end_pos": 120, "type": "TASK", "confidence": 0.6816201359033585}]}, {"text": "Docforia is a multilayer document model to store formatting, lexical, syntactic, and semantic annotations on Wikipedia and other kinds of text and visualize them.", "labels": [], "entities": []}, {"text": "To deliver results in a reasonable time, Docforia is compatible with cluster programming frameworks such as Spark or Hadoop.", "labels": [], "entities": []}, {"text": "Using the Langforia language processing pipelines (, we processed six language versions of Wikipedia: English, French, German, Spanish, Russian, and Swedish, up to semantic role labeling, depending on the NLP tools available fora given language.", "labels": [], "entities": [{"text": "Langforia language processing", "start_pos": 10, "end_pos": 39, "type": "DATASET", "confidence": 0.8830284277598063}, {"text": "semantic role labeling", "start_pos": 164, "end_pos": 186, "type": "TASK", "confidence": 0.5972953637441}]}, {"text": "We stored the results in the document model.", "labels": [], "entities": []}, {"text": "We designed an interactive visualization tool, part of Langforia, so that a user can select languages, documents, and linguistic layers and examine the annotation output.", "labels": [], "entities": [{"text": "Langforia", "start_pos": 55, "end_pos": 64, "type": "DATASET", "confidence": 0.9507031440734863}]}], "datasetContent": [], "tableCaptions": []}