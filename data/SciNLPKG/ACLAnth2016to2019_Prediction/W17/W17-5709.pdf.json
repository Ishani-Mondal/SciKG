{"title": [{"text": "Patent NMT integrated with Large Vocabulary Phrase Translation by SMT at WAT 2017", "labels": [], "entities": [{"text": "NMT", "start_pos": 7, "end_pos": 10, "type": "TASK", "confidence": 0.8439463376998901}, {"text": "Large Vocabulary Phrase Translation", "start_pos": 27, "end_pos": 62, "type": "TASK", "confidence": 0.6084939390420914}, {"text": "SMT at WAT", "start_pos": 66, "end_pos": 76, "type": "TASK", "confidence": 0.4978579878807068}]}], "abstractContent": [{"text": "Neural machine translation (NMT) cannot handle a larger vocabulary because the training complexity and decoding complexity proportionally increase with the number of target words.", "labels": [], "entities": [{"text": "Neural machine translation (NMT)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8250960111618042}]}, {"text": "This problem becomes even more serious when translating patent documents, which contain many technical terms that are observed infrequently.", "labels": [], "entities": []}, {"text": "(2017) proposed to select phrases that contain out-of-vocabulary words using the statistical approach of branching entropy.", "labels": [], "entities": []}, {"text": "The selected phrases are then replaced with tokens during training and post-translated by the phrase translation table of SMT.", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 94, "end_pos": 112, "type": "TASK", "confidence": 0.6993238627910614}, {"text": "SMT", "start_pos": 122, "end_pos": 125, "type": "TASK", "confidence": 0.8919878602027893}]}, {"text": "In this paper, we apply the method proposed by Long et al.", "labels": [], "entities": []}, {"text": "(2017) to the WAT 2017 Japanese-Chinese and Japanese-English patent datasets.", "labels": [], "entities": [{"text": "WAT 2017 Japanese-Chinese and Japanese-English patent datasets", "start_pos": 14, "end_pos": 76, "type": "DATASET", "confidence": 0.8746259042194912}]}, {"text": "Evaluation on Japanese-to-Chinese, Chinese-to-Japanese, Japanese-to-English and English-to-Japanese patent sentence translation proved the effectiveness of phrases selected with branching en-tropy, where the NMT model of Long et al.", "labels": [], "entities": [{"text": "English-to-Japanese patent sentence translation", "start_pos": 80, "end_pos": 127, "type": "TASK", "confidence": 0.6681672781705856}]}, {"text": "(2017) achieves a substantial improvement over a baseline NMT model without the technique proposed by Long et al.", "labels": [], "entities": []}], "introductionContent": [{"text": "Neural machine translation (NMT), anew approach to solving machine translation, has achieved promising results ().", "labels": [], "entities": [{"text": "Neural machine translation (NMT)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7939771215120951}, {"text": "solving machine translation", "start_pos": 51, "end_pos": 78, "type": "TASK", "confidence": 0.6726284126440684}]}, {"text": "An NMT system builds a simple large neural network that reads the entire input source sentence and generates an output translation.", "labels": [], "entities": []}, {"text": "The entire neural network is jointly trained to maximize the conditional probability of the correct translation of a source sentence with a bilingual corpus.", "labels": [], "entities": []}, {"text": "Although NMT offers many advantages over traditional phrase-based approaches, such as a small memory footprint and simple decoder implementation, conventional NMT is limited when it comes to larger vocabularies.", "labels": [], "entities": []}, {"text": "This is because the training complexity and decoding complexity proportionally increase with the number of target words.", "labels": [], "entities": []}, {"text": "Words that are out of vocabulary are represented by a single \"\ud97b\udf59unk\ud97b\udf59\" token in translations, as illustrated in.", "labels": [], "entities": []}, {"text": "The problem becomes more serious when translating patent documents, which contain several newly introduced technical terms.", "labels": [], "entities": []}, {"text": "There have been a number of related studies that address the vocabulary limitation of NMT systems.", "labels": [], "entities": []}, {"text": "provided an efficient approximation to the softmax function to accommodate a very large vocabulary in an NMT system.", "labels": [], "entities": []}, {"text": "proposed annotating the occurrences of the out-of-vocabulary token in the target sentence with positional information to track its alignments, after which they replace the tokens with their translations using simple word dictionary lookup or identity copy.", "labels": [], "entities": []}, {"text": "proposed replacing out-of-vocabulary words with similar in-vocabulary words based on a similarity model learnt from monolingual data.", "labels": [], "entities": []}, {"text": "introduced an effective approach based on encoding rare and out-of-vocabulary words as sequences of subword units.", "labels": [], "entities": []}, {"text": "provided a character-level and word-level hybrid NMT model to achieve an open vocabulary, and proposed an NMT system that uses character-based embeddings.", "labels": [], "entities": []}, {"text": "Figure 1: Example of translation errors when translating patent sentences with technical terms using NMT However, these previous approaches have limitations when translating patent sentences.", "labels": [], "entities": []}, {"text": "This is because their methods only focus on addressing the problem of out-of-vocabulary words even though the words are parts of technical terms.", "labels": [], "entities": []}, {"text": "It is obvious that a technical term should be considered as one word that comprises components that always have different meanings and translations when they are used alone.", "labels": [], "entities": []}, {"text": "An example is shown in, where the Japanese word \" \"(bridge) should be translated to Chinese word \" \" when included in technical term \"bridge interface\"; however, it is always translated as \" \".", "labels": [], "entities": []}, {"text": "To address this problem, proposed extracting compound nouns as technical terms and replacing them with tokens.", "labels": [], "entities": []}, {"text": "proposed to select phrase pairs using the statistical approach of branching entropy; this allows the proposed technique to be applied to the translation task on any language pair without needing specific language knowledge to formulate the rules for technical term identification.", "labels": [], "entities": [{"text": "technical term identification", "start_pos": 250, "end_pos": 279, "type": "TASK", "confidence": 0.6076136628786722}]}, {"text": "In this paper, we apply the method proposed by  to the WAT 2017 Japanese-Chinese and Japanese-English patent datasets.", "labels": [], "entities": [{"text": "WAT 2017 Japanese-Chinese and Japanese-English patent datasets", "start_pos": 55, "end_pos": 117, "type": "DATASET", "confidence": 0.8675735337393624}]}, {"text": "On the WAT 2017 Japanese-Chinese JPO patent dataset, the NMT model of  achieves an improvement of 1.4 BLEU points over a baseline NMT model when translating Japanese sentences into Chinese, and an improvement of 0.8 BLEU points when translating Chinese sentences into Japanese.", "labels": [], "entities": [{"text": "WAT 2017 Japanese-Chinese JPO patent dataset", "start_pos": 7, "end_pos": 51, "type": "DATASET", "confidence": 0.9343401491641998}, {"text": "BLEU", "start_pos": 102, "end_pos": 106, "type": "METRIC", "confidence": 0.993256688117981}, {"text": "BLEU", "start_pos": 216, "end_pos": 220, "type": "METRIC", "confidence": 0.9957660436630249}]}, {"text": "On the WAT 2017 Japanese-English JPO patent dataset, the NMT model of  achieves an improvement of 0.8 BLEU points over a baseline NMT model when translating Japanese sentences into English, and an improvement of 0.7 BLEU points when translating English sentences into Japanese.", "labels": [], "entities": [{"text": "WAT 2017 Japanese-English JPO patent dataset", "start_pos": 7, "end_pos": 51, "type": "DATASET", "confidence": 0.9194516241550446}, {"text": "BLEU", "start_pos": 102, "end_pos": 106, "type": "METRIC", "confidence": 0.9934117197990417}, {"text": "BLEU", "start_pos": 216, "end_pos": 220, "type": "METRIC", "confidence": 0.9972527623176575}]}, {"text": "Moreover, the number of translation error of undertranslations 1 by PosUnk model proposed by reduces to around 30% by the NMT model of .", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated the effectiveness of the NMT model of  on the WAT 2017 JapaneseChinese and Japanese-English JPO dataset.", "labels": [], "entities": [{"text": "WAT 2017 JapaneseChinese and Japanese-English JPO dataset", "start_pos": 59, "end_pos": 116, "type": "DATASET", "confidence": 0.837527973311288}]}, {"text": "Out of the training set of the WAT 2017 JapaneseChinese JPO dataset, we used 998,954 patent sentence pairs, whose Japanese sentences contain fewer than 100 morphemes, Chinese sentences contain fewer than 100 words.", "labels": [], "entities": [{"text": "WAT 2017 JapaneseChinese JPO dataset", "start_pos": 31, "end_pos": 67, "type": "DATASET", "confidence": 0.878306257724762}]}, {"text": "Out of the training set of the WAT 2017 Japanese-English JPO dataset, we used 999,636 sentence pairs whose Japanese sentences contain fewer than 100 morphemes and English sentences contain fewer than 100 words.", "labels": [], "entities": [{"text": "WAT 2017 Japanese-English JPO dataset", "start_pos": 31, "end_pos": 68, "type": "DATASET", "confidence": 0.9021212577819824}]}, {"text": "In both cases, we used all of the sentence pairs contained in the development sets of the WAT 2017 JPO datasets as development sets, and we used all of the sentence pairs contained in the test sets of the WAT 2017 JPO datasets as test sets.", "labels": [], "entities": [{"text": "WAT 2017 JPO datasets", "start_pos": 90, "end_pos": 111, "type": "DATASET", "confidence": 0.9174044281244278}, {"text": "WAT 2017 JPO datasets", "start_pos": 205, "end_pos": 226, "type": "DATASET", "confidence": 0.9223857522010803}]}, {"text": "show the statistics of the dataset.", "labels": [], "entities": []}, {"text": "According to the procedure of Section 3.2, from the Japanese-Chinese sentence pairs of the training set, we collected 102,630 occurrences of Japanese-Chinese phrase pairs, which are 69,387 types of phrase pairs with 52,786 unique types of Japanese phrases and 67,456 unique types of Chinese phrases.", "labels": [], "entities": []}, {"text": "Within the total 2,000 Japanese patent sentences in the Japanese-Chinese test set, 266 occurrences of Japanese phrases were extracted, which correspond to 247 types.", "labels": [], "entities": [{"text": "Japanese-Chinese test set", "start_pos": 56, "end_pos": 81, "type": "DATASET", "confidence": 0.7224749525388082}]}, {"text": "With the total 2,000 Chinese patent sentences in the Japanese-Chinese test set, 417 occurrences of Chinese phrases were extracted, which correspond to 382 types.", "labels": [], "entities": [{"text": "Japanese-Chinese test set", "start_pos": 53, "end_pos": 78, "type": "DATASET", "confidence": 0.7438093026479086}]}, {"text": "From the Japanese-English sentence pairs of the training set, we collected 38,457 occurrences of Japanese-English phrase pairs, which are 35,544 types of phrase pairs with unique 34,569 types of Japanese phrases and 35,087 unique types of English phrases.", "labels": [], "entities": []}, {"text": "Within the total 2,000 Japanese patent sentences in the Japanese-English test set, 249 occurrences of Japanese phrases were extracted, which correspond to 221 types.", "labels": [], "entities": [{"text": "Japanese-English test set", "start_pos": 56, "end_pos": 81, "type": "DATASET", "confidence": 0.7219875256220499}]}, {"text": "With the total 2,000 English patent sentences in the Japanese-English test set, 246 occurrences of English phrases were extracted, which correspond to 230 types.", "labels": [], "entities": [{"text": "Japanese-English test set", "start_pos": 53, "end_pos": 78, "type": "DATASET", "confidence": 0.7215662598609924}]}, {"text": "In this work, we calculated automatic evaluation scores for the translation results using a popular metrics called BLEU ().", "labels": [], "entities": [{"text": "BLEU", "start_pos": 115, "end_pos": 119, "type": "METRIC", "confidence": 0.9973790645599365}]}, {"text": "As shown in, we report the evaluation scores, using the translations by Moses ( as the baseline SMT and the scores using the translations produced by the baseline NMT system without the approach proposed by  as the baseline NMT.", "labels": [], "entities": []}, {"text": "As shown in, the BLEU score obtained by the NMT model of  is clearly higher than those of the baselines.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 17, "end_pos": 27, "type": "METRIC", "confidence": 0.981360912322998}]}, {"text": "Here, as described in Section 3, the lower bounds of branching entropy for phrase pair selection are tuned as 5 throughout the evaluation of language pair of JapaneseChinese, and tuned as 8 throughout the evaluation of language pair of Japanese-English, respectively.", "labels": [], "entities": [{"text": "phrase pair selection", "start_pos": 75, "end_pos": 96, "type": "TASK", "confidence": 0.7189507683118185}]}, {"text": "On the WAT 2017 Japanese-Chinese JPO patent dataset, when compared with the baseline SMT, the performance gains of the NMT model of  are approximately 5.6 BLEU points when translating Japanese into Chinese and 5.4 BLEU when translating Chinese into Japanese.", "labels": [], "entities": [{"text": "WAT 2017 Japanese-Chinese JPO patent dataset", "start_pos": 7, "end_pos": 51, "type": "DATASET", "confidence": 0.9376093447208405}, {"text": "SMT", "start_pos": 85, "end_pos": 88, "type": "TASK", "confidence": 0.9610245227813721}, {"text": "BLEU", "start_pos": 155, "end_pos": 159, "type": "METRIC", "confidence": 0.997922956943512}, {"text": "BLEU", "start_pos": 214, "end_pos": 218, "type": "METRIC", "confidence": 0.9972416162490845}]}, {"text": "On the WAT 2017 Japanese-English JPO patent dataset, when compared with the baseline SMT, the performance gains of the NMT model of  are approximately 15.9 BLEU points when translating Japanese into English and 13.1 BLEU when translating English into Japanese.", "labels": [], "entities": [{"text": "WAT 2017 Japanese-English JPO patent dataset", "start_pos": 7, "end_pos": 51, "type": "DATASET", "confidence": 0.9253720541795095}, {"text": "SMT", "start_pos": 85, "end_pos": 88, "type": "TASK", "confidence": 0.9585483074188232}, {"text": "BLEU", "start_pos": 156, "end_pos": 160, "type": "METRIC", "confidence": 0.998214840888977}, {"text": "BLEU", "start_pos": 216, "end_pos": 220, "type": "METRIC", "confidence": 0.9981210827827454}]}, {"text": "When compared with the result of the baseline NMT, the NMT model of  achieved performance gains of 1.4 BLEU points on the task of translating Japanese into Chinese and 0.8 BLEU points on the task of translating Chinese into Japanese.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 103, "end_pos": 107, "type": "METRIC", "confidence": 0.9986860156059265}, {"text": "BLEU", "start_pos": 172, "end_pos": 176, "type": "METRIC", "confidence": 0.998487114906311}, {"text": "translating Chinese into Japanese", "start_pos": 199, "end_pos": 232, "type": "TASK", "confidence": 0.8545370250940323}]}, {"text": "When compared with the result of the baseline NMT, the NMT model of  achieved performance gains of 0.8 BLEU points on the task of translating Japanese into English and 1.4 BLEU points on the task of translating English into Japanese.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 103, "end_pos": 107, "type": "METRIC", "confidence": 0.9987426400184631}, {"text": "BLEU", "start_pos": 172, "end_pos": 176, "type": "METRIC", "confidence": 0.9985639452934265}]}, {"text": "Furthermore, we quantitatively compared our study with the work of.", "labels": [], "entities": []}, {"text": "Table 2 compares the NMT model with the PosUnk model, which is the best model proposed by The NMT model of  achieves performance gains of 0.9 BLEU points when translating Japanese into Chinese, and performance gains of 0.6 BLEU points when translating Chinese into Japanese.", "labels": [], "entities": [{"text": "NMT", "start_pos": 21, "end_pos": 24, "type": "DATASET", "confidence": 0.8759896159172058}, {"text": "BLEU", "start_pos": 142, "end_pos": 146, "type": "METRIC", "confidence": 0.9971269965171814}, {"text": "BLEU", "start_pos": 223, "end_pos": 227, "type": "METRIC", "confidence": 0.99809330701828}]}, {"text": "The NMT model of  achieves performance gains of 0.4 BLEU points when translating Japanese into English, and performance gains of 0.5 BLEU points when translating English into Japanese In this study, we also conducted two types of human evaluations according to the work of: pairwise evaluation and JPO adequacy evaluation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 52, "end_pos": 56, "type": "METRIC", "confidence": 0.9975638389587402}, {"text": "BLEU", "start_pos": 133, "end_pos": 137, "type": "METRIC", "confidence": 0.9978011250495911}]}, {"text": "In the pairwise evaluation, we compared each translation produced by the baseline NMT with that produced by the NMT model of  as well as the NMT model with PosUnk model, and judged which translation is better or whether they have  comparable quality.", "labels": [], "entities": []}, {"text": "In contrast to the study conducted by, we randomly selected 200 sentence pairs from the test set for human evaluation, and both human evaluations were conducted using only one judgement. and show the results of the human evaluation for the baseline SMT, baseline NMT, NMT model with PosUnk model, and the NMT model of . We observe that the NMT model of  achieves the best performance for both the pairwise and JPO adequacy evaluations when we replace the tokens with SMT phrase translations after decoding the source sentence with the tokens.", "labels": [], "entities": [{"text": "SMT", "start_pos": 249, "end_pos": 252, "type": "TASK", "confidence": 0.9343864917755127}, {"text": "SMT phrase translations", "start_pos": 467, "end_pos": 490, "type": "TASK", "confidence": 0.8348770538965861}]}, {"text": "Moreover, shows the results of automatic evaluation, pairwise evaluation and JPO adequacy evaluation from the WAT 2017 ().", "labels": [], "entities": [{"text": "JPO", "start_pos": 77, "end_pos": 80, "type": "METRIC", "confidence": 0.6782453656196594}, {"text": "WAT 2017", "start_pos": 110, "end_pos": 118, "type": "DATASET", "confidence": 0.9029206037521362}]}, {"text": "We observe that the NMT model of  achieves a substantial improvement over the WAT 2017 baseline.", "labels": [], "entities": [{"text": "NMT", "start_pos": 20, "end_pos": 23, "type": "DATASET", "confidence": 0.6774857640266418}, {"text": "WAT 2017 baseline", "start_pos": 78, "end_pos": 95, "type": "DATASET", "confidence": 0.891047477722168}]}, {"text": "For the test sets, we also counted the numbers of the untranslated words of input sentences.", "labels": [], "entities": []}, {"text": "As shown in, the number of untranslated words by the baseline NMT reduced to around 65% by the NMT model of . This is mainly because part of untranslated source words are out-of-vocabulary, and thus are untrans-  In this example, the translation is a translation error because the Japanese word \" (quenching)\" is an out-of-vocabulary word and is erroneously translated into the \"\ud97b\udf59unk\ud97b\udf59\" token.", "labels": [], "entities": [{"text": "NMT", "start_pos": 62, "end_pos": 65, "type": "DATASET", "confidence": 0.8958861231803894}]}, {"text": "The NMT model of  correctly translated the Japanese sentence into Chinese, where the out-of-vocabulary word \" \" is correctly selected by the approach of branching entropy as apart of the Japanese phrase \" (quenching agent)\".", "labels": [], "entities": [{"text": "NMT", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.8336887359619141}]}, {"text": "The selected Japanese phrase is then translated by the phrase translation table of SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 83, "end_pos": 86, "type": "TASK", "confidence": 0.5470268726348877}]}, {"text": "shows another example of correct translation produced by the NMT model of  with one produced by the baseline NMT.", "labels": [], "entities": []}, {"text": "As shown in, the translation produced by baseline NMT is a translation error because the out-of-vocabulary English words \"eukaryotic\" and \"promoters\" are untranslated words and their translations are not contained in the output translation of the baseline NMT.", "labels": [], "entities": []}, {"text": "The NMT model of: An example of correct translations produced by the NMT model of  when addressing the problem of out-of-vocabulary words (Japanese-to-Chinese): An example of correct translations produced by the NMT model of  when addressing the problem of under-translation (English-to-Japanese)  correctly translated those English words into Japanese because those English words \"eukaryotic\" and \"promoters\" are selected as an English phrase \"Eukaryotic promoters\" with branching entropy and then are translated by SMT.", "labels": [], "entities": []}, {"text": "proposed selecting phrases that contain out-of-vocabulary words using the branching entropy.", "labels": [], "entities": []}, {"text": "These selected phrases are then replaced with tokens and post-translated using an SMT phrase translation.", "labels": [], "entities": [{"text": "SMT phrase translation", "start_pos": 82, "end_pos": 104, "type": "TASK", "confidence": 0.9111389517784119}]}, {"text": "In this paper, we apply the method proposed by  to the WAT 2017 Japanese-Chinese and JapaneseEnglish patent datasets.", "labels": [], "entities": [{"text": "WAT 2017 Japanese-Chinese and JapaneseEnglish patent datasets", "start_pos": 55, "end_pos": 116, "type": "DATASET", "confidence": 0.9174141798700605}]}, {"text": "We observed that the NMT model of  performed much better than the baseline NMT system in all of the language pairs: Japanese-to-Chinese/Chineseto-Japanese and Japanese-to-English/English-toJapanese.", "labels": [], "entities": []}, {"text": "One of our important future tasks is to compare the translation performance of the NMT model of  with that based on subword units (e.g. ().", "labels": [], "entities": [{"text": "translation", "start_pos": 52, "end_pos": 63, "type": "TASK", "confidence": 0.9562936425209045}]}, {"text": "Another future work is to integrate the reranking framework for minimizing untranslated content () into the NMT model of , which is expected to further reduce the number of untranslated words.", "labels": [], "entities": [{"text": "minimizing untranslated content", "start_pos": 64, "end_pos": 95, "type": "TASK", "confidence": 0.8384937047958374}]}, {"text": "This future work is roughly based on the observation reported in , where the NMT model of  is not only effective in reducing the untranslated content without any specific framework of minimizing the untranslated content, but also successfully reduced the estimated volumes of the untranslated content, which was proposed by.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of datasets  training validation  test  set  set  set  ja \u2194 ch 998,054  2,000  2,000  ja \u2194 en 999,636  2,000  2,000", "labels": [], "entities": []}, {"text": " Table 2: Automatic evaluation results (BLEU)  System  ja \u2192 ch ch \u2192 ja ja \u2192 en en \u2192 ja  Baseline SMT (Koehn et al., 2007)  30.0  36.2  28.0  29.4  Baseline NMT  34.2  40.8  43.1  41.8  NMT with PosUnk model (Luong et al., 2015b)  34.5  41.0  43.5  42.0  NMT with phrase translation by SMT  35.6  41.6  43.9  42.5  (Long et al., 2017)", "labels": [], "entities": [{"text": "BLEU", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.9952163696289062}, {"text": "phrase translation", "start_pos": 263, "end_pos": 281, "type": "TASK", "confidence": 0.6910722404718399}]}, {"text": " Table 3: Human evaluation results of pairwise evaluation  System  ja \u2192 ch ch \u2192 ja ja \u2192 en en \u2192 ja  NMT with PosUnk model (Luong et al., 2015b)  13  12.5  9.5  14.5  NMT with phrase translation by SMT  23.5  22.5  15.5  19  (Long et al., 2017)", "labels": [], "entities": []}, {"text": " Table 4: Human evaluation results of JPO adequacy evaluation  System  ja \u2192 ch ch \u2192 ja ja \u2192 en en \u2192 ja  Baseline SMT (Koehn et al., 2007)  3.1  3.2  2.9  3.0  Baseline NMT  3.6  3.6  3.7  3.7  NMT with PosUnk model (Luong et al., 2015b)  3.8  3.9  3.9  3.9  NMT with phrase translation by SMT  4.1  4.1  4.2  4.1  (Long et al., 2017)", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 267, "end_pos": 285, "type": "TASK", "confidence": 0.6885683834552765}]}, {"text": " Table 5: Evaluation results from WAT 2017  Evaluation  System  ja \u2192 ch ch \u2192 ja ja \u2192 en en \u2192 ja  Automatic  Baseline (PBSMT)  32.1  38.5  30.8  34.3  evaluation  NMT with phrase translation by SMT  33.2  40.5  37.3  41.1  (BLEU)  (Long et al., 2017)  Pairwise  NMT with phrase translation by SMT  21.8  40.1  51.5  49.5  evaluation  (Long et al., 2017)  JPO adequacy NMT with phrase translation by SMT  4.1  3.9  4.2  4.3  evaluation  (Long et al., 2017)", "labels": [], "entities": [{"text": "BLEU", "start_pos": 223, "end_pos": 227, "type": "METRIC", "confidence": 0.9916015267372131}]}, {"text": " Table 6: Numbers of untranslated morphemes / words of input sentences  System  ja \u2192 ch ch \u2192 ja ja \u2192 en en \u2192 ja  NMT with PosUnk model (Luong et al., 2015b)  1,112  846  1,031  794  NMT with phrase translation by SMT  736  581  655  571  (Long et al., 2017)", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 191, "end_pos": 209, "type": "TASK", "confidence": 0.7091908305883408}]}]}