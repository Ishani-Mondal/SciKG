{"title": [{"text": "Annotating Orthographic Target Hypotheses in a German L1 Learner Corpus", "labels": [], "entities": [{"text": "Annotating Orthographic Target", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7492932081222534}, {"text": "German L1 Learner Corpus", "start_pos": 47, "end_pos": 71, "type": "DATASET", "confidence": 0.8998574167490005}]}], "abstractContent": [{"text": "NLP applications for learners often rely on annotated learner corpora.", "labels": [], "entities": []}, {"text": "Thereby, it is important that the annotations are both meaningful for the task, and consistent and reliable.", "labels": [], "entities": []}, {"text": "We present anew longitudinal L1 learner corpus for German (handwrit-ten texts collected in grade 2-4), which is transcribed and annotated with a target hypothesis that strictly only corrects ortho-graphic errors, and is thereby tailored to research and tool development for ortho-graphic issues in primary school.", "labels": [], "entities": []}, {"text": "While for most corpora, transcription and target hypothesis are not evaluated, we conducted a detailed inter-annotator agreement study for both tasks.", "labels": [], "entities": []}, {"text": "Although we achieved high agreement, our discussion of cases of disagreement shows that even with detailed guidelines, annotators differ here and therefor different reasons, which should also be considered when working with transcriptions and target hypotheses of other corpora, especially if no explicit guidelines for their construction are known.", "labels": [], "entities": []}], "introductionContent": [{"text": "Learner corpora cannot only be used to study the language of learners but they also have a strong connection to the development of educational applications.", "labels": [], "entities": []}, {"text": "NLP tools can be trained on learner corpora to be later used in ICALL (intelligent computer-assisted language learning) systems, to provide immediate analyses of errors occurring in the input text for some examples, see.", "labels": [], "entities": [{"text": "ICALL (intelligent computer-assisted language learning)", "start_pos": 64, "end_pos": 119, "type": "TASK", "confidence": 0.4631909898349217}]}, {"text": "To enable high-quality analyses in such a scenario, it is crucial that the underlying training data have been annotated meaningfully and consistently.", "labels": [], "entities": []}, {"text": "The identification and annotation of errors necessarily depends on a target hypothesis, i.e. the assumed correct form of the learner's utterance, be that stated implicitly or explicitly).", "labels": [], "entities": []}, {"text": "The correct form itself can already serve as error annotation.", "labels": [], "entities": []}, {"text": "This has the advantage that errors do not have to be cast into pre-defined categories, which might not capture all cases ().", "labels": [], "entities": []}, {"text": "However, as demonstrate, there is a possibly infinite number of target hypotheses fora single utterance, depending on the linguistic level that is corrected (orthography, grammar, lexis, etc.).", "labels": [], "entities": []}, {"text": "They argue further that the usefulness of a target hypothesis depends on the research purpose, and that its construction must be comprehensible and transparent to other researchers.", "labels": [], "entities": []}, {"text": "In this paper, we present anew corpus resource which is tailored to research on orthography in texts produced by primary schoolchildren in Germany.", "labels": [], "entities": []}, {"text": "It features a target hypothesis that strictly only corrects orthographic errors in order to keep them apart from other kinds of errors concerning grammar or semantics.", "labels": [], "entities": []}, {"text": "Consider, for instance, the sentence in example (1):", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Number of characters (#char), percent agreement (perc) and Fleiss' \u03ba for transcription, and  numbers of tokens (#tok) and percent agreement for normalization among all four annotators for each  text.", "labels": [], "entities": [{"text": "Fleiss' \u03ba", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9752238392829895}]}, {"text": " Table 2: Agreement results for pairs, triples, and  all four annotators for transcription and normaliza- tion", "labels": [], "entities": []}, {"text": " Table 3: Sources of disagreements in the transcrip- tion", "labels": [], "entities": []}, {"text": " Table 4: Sources of disagreements in the target hy- pothesis", "labels": [], "entities": []}]}