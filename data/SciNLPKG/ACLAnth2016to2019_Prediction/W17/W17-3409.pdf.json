{"title": [], "abstractContent": [{"text": "Languages of directed acyclic graphs (DAGs) are of interest in Natural Language Processing because they can be used to capture the structure of semantic graphs like those of Abstract Meaning Representation.", "labels": [], "entities": [{"text": "Abstract Meaning Representation", "start_pos": 174, "end_pos": 205, "type": "TASK", "confidence": 0.5981972714265188}]}, {"text": "This paper gives an overview of recent results on a family of automata recognizing such DAG languages .", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper attempts to survey, motivate, and explain recent work on automata that recognize sets of directed acyclic graphs (DAGs).", "labels": [], "entities": []}, {"text": "These automata are called DAG automata and the languages they recognize regular DAG languages.", "labels": [], "entities": []}, {"text": "While DAG automata are of interest in various areas of computer science, different application areas place different requirements on what constitutes a good model of such automata.", "labels": [], "entities": []}, {"text": "Here we are interested in DAG automata that are suitable for capturing the structure of semantic graphs in Natural Language Processing, and in particular meaning representations such as Abstract Meaning Representation (AMR).", "labels": [], "entities": [{"text": "Abstract Meaning Representation (AMR)", "start_pos": 186, "end_pos": 223, "type": "TASK", "confidence": 0.7482382406791052}]}, {"text": "AMR was introduced by as a domain-independent graph notation for the semantics of meanings in natural language, and since then a quickly growing AMR bank for English has been built.", "labels": [], "entities": [{"text": "AMR", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7120852470397949}]}, {"text": "The purpose of such graphbanks is to enable research towards domainindependent semantic language processing, thus mirroring the advances in syntactic processing that have been made during the past 20 years thanks to the existence of large syntactic treebanks.", "labels": [], "entities": [{"text": "domainindependent semantic language processing", "start_pos": 61, "end_pos": 107, "type": "TASK", "confidence": 0.6022497117519379}]}, {"text": "AMR serves a similar purpose in the realm of semantic representation as the well-known con-stituent tree does for syntactic representation.", "labels": [], "entities": [{"text": "semantic representation", "start_pos": 45, "end_pos": 68, "type": "TASK", "confidence": 0.7391574382781982}, {"text": "syntactic representation", "start_pos": 114, "end_pos": 138, "type": "TASK", "confidence": 0.7170836180448532}]}, {"text": "For the latter, we have a great variety of well-studied formal models for capturing the structure of correct representations, distinguishing them from faulty ones, and efficiently processing these formal objects.", "labels": [], "entities": []}, {"text": "One of the simplest and at the same time most useful models is the finite-state tree automaton or, equivalently, the regular tree grammar (see and).", "labels": [], "entities": []}, {"text": "Simplicity, though resulting in limited expressive power, is an is an asset in this context.", "labels": [], "entities": []}, {"text": "It is to their simplicity that finite-state tree automata owe their usefulness.", "labels": [], "entities": []}, {"text": "One of the advantages of the model is that it can easily be extended by, then associating with every tree a value that indicates how \"good\" or perhaps probable the tree is.", "labels": [], "entities": []}, {"text": "Such weighted automata are especially useful in Natural Language Processing where one rarely finds a clear dividing line between correct and wrong representations, and where one furthermore has to find ways to resolve ambiguities.", "labels": [], "entities": []}, {"text": "An AMR 2 is usually not a tree but a DAG such as the (somewhat simplified and abstracted) AMR in.", "labels": [], "entities": []}, {"text": "Its vertices are mostly PropBank concepts () connected by edges which are labelled by role labels, intuitively supplying the concepts with their semantic arguments.", "labels": [], "entities": []}, {"text": "Readers familiar with dependency trees probably notice the similarity, but also the difference: if several concepts share a semantic argument the latter is still represented only once, being pointed to by several edges.", "labels": [], "entities": []}, {"text": "This is what turns AMRs into DAGs, thus calling for formal models that allow to specify DAG languages or even weighted DAG languages.", "labels": [], "entities": []}, {"text": "Unsurprisingly, it turns Figure 1: An AMR from the AMR Bank: \"I asked her what she thought about where we'd be and she said she doesn't want to think about that, and that I should be happy about the experiences we've had (which I am).\"", "labels": [], "entities": [{"text": "AMR from the AMR Bank", "start_pos": 38, "end_pos": 59, "type": "DATASET", "confidence": 0.8116747140884399}]}, {"text": "The PropBank frame names (the vertex labels) have been simplified for the sake of readability.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 4, "end_pos": 12, "type": "DATASET", "confidence": 0.9095070362091064}]}, {"text": "They can be found in, which also uses this example.", "labels": [], "entities": []}, {"text": "As aside note, one may note that the AMR does not specify whether her saying was the answer to my asking, the other way around, or the two were independent.", "labels": [], "entities": [{"text": "AMR", "start_pos": 37, "end_pos": 40, "type": "DATASET", "confidence": 0.6626424193382263}]}, {"text": "This, however, would contribute to a discussion about the limits of AMR rather than about formal automata models for AMR.", "labels": [], "entities": [{"text": "AMR", "start_pos": 68, "end_pos": 71, "type": "TASK", "confidence": 0.6109115481376648}]}, {"text": "out that the greater complexity and expressivity of DAGs makes it all too easy to develop natural types of DAG automata that are surprisingly powerful, thus lacking the simplicity that is the great advantage of finite-state tree automata.", "labels": [], "entities": []}, {"text": "The amount of research that has been devoted to DAG automata models that extend finite-state tree automata to the realm of DAGs is rather limited.", "labels": [], "entities": []}, {"text": "Moreover, researchers have come up with various different models that, owing to different intended areas of application, work on different types of DAGs and exhibit different properties.", "labels": [], "entities": []}, {"text": "Most appear to be more powerful than what appears to be reasonable from a linguistic point of view, thus making the model more complex than desirable.", "labels": [], "entities": []}, {"text": "One of the potential problems that comes with greater complexity is computational inefficiency, another one is that such models, when being trained, are prone to overfitting.", "labels": [], "entities": []}, {"text": "2 What Is a \"Good\" Automaton Model for Meaning Representation?", "labels": [], "entities": [{"text": "Meaning Representation", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.8043486475944519}]}, {"text": "Let us have a look at a few aspects that come to mind when thinking about an appropriate automaton model for meaning representation such as AMR.", "labels": [], "entities": [{"text": "meaning representation", "start_pos": 109, "end_pos": 131, "type": "TASK", "confidence": 0.722994014620781}]}], "datasetContent": [], "tableCaptions": []}