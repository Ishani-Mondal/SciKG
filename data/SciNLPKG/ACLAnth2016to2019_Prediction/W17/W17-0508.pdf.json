{"title": [{"text": "Comparing Rule-based and SMT-based Spelling Normalisation for English Historical Texts", "labels": [], "entities": [{"text": "SMT-based Spelling Normalisation", "start_pos": 25, "end_pos": 57, "type": "TASK", "confidence": 0.936499277750651}]}], "abstractContent": [{"text": "To be able to use existing natural language processing tools for analysing historical text, an important preprocessing step is spelling normalisation, converting the original spelling to present-day spelling, before applying tools such as tag-gers and parsers.", "labels": [], "entities": [{"text": "spelling normalisation", "start_pos": 127, "end_pos": 149, "type": "TASK", "confidence": 0.8314675688743591}]}, {"text": "In this paper, we compare a probablistic, language-independent approach to spelling normalisation based on statistical machine translation (SMT) techniques, to a rule-based system combining dictionary lookup with rules and non-probabilistic weights.", "labels": [], "entities": [{"text": "spelling normalisation", "start_pos": 75, "end_pos": 97, "type": "TASK", "confidence": 0.9402060210704803}, {"text": "statistical machine translation (SMT)", "start_pos": 107, "end_pos": 144, "type": "TASK", "confidence": 0.798398753007253}]}, {"text": "The rule-based system reaches the best accuracy, up to 94% precision at 74% recall, while the SMT system improves each tested period.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9994596838951111}, {"text": "precision", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9981518387794495}, {"text": "recall", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9985590577125549}, {"text": "SMT", "start_pos": 94, "end_pos": 97, "type": "TASK", "confidence": 0.9754790663719177}]}], "introductionContent": [{"text": "Language technology for historical texts poses several challenges, as earlier stages of languages are under-resourced.", "labels": [], "entities": []}, {"text": "But language technology is helpful both to researchers in Digital Humanities and Diachronic Linguistics.", "labels": [], "entities": []}, {"text": "Natural Language Processing (NLP) tools are needed at all levels of processing, but spelling is a particularly obvious candidate, for at least two reasons.", "labels": [], "entities": []}, {"text": "First, historical variants not only differ from present-day spellings.", "labels": [], "entities": []}, {"text": "They also often lack normalisation within their period -the same word often appears with several different spellings inside the same document.", "labels": [], "entities": []}, {"text": "Thus, even simple lexicon-based research is hampered by complex corpus queries and low recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.9965611100196838}]}, {"text": "Second, spelling variants can affect all other subsequent processing levels -tokenisation, part-ofspeech tagging and parsing.", "labels": [], "entities": [{"text": "part-ofspeech tagging", "start_pos": 91, "end_pos": 112, "type": "TASK", "confidence": 0.6838725209236145}]}, {"text": "For example, frequent variants like call'd for called lead to a tokenisation error, which in turn results in wrong tagging, and as a consequence parsing quality is also affected., and report that about half of the changes induced by automatic spelling normalisation lead to improved tagging and parsing, which makes it a vital contributor to improved tagging and parsing of historical texts.", "labels": [], "entities": [{"text": "parsing", "start_pos": 295, "end_pos": 302, "type": "TASK", "confidence": 0.9383085370063782}, {"text": "parsing of historical texts", "start_pos": 363, "end_pos": 390, "type": "TASK", "confidence": 0.863648071885109}]}, {"text": "Several approaches for mapping historical variants to present-day standard spelling have been proposed.", "labels": [], "entities": []}, {"text": "For English, on which we are going to focus in this article, VARiant Detector 2 (VARD) () is a popular spelling normalisation tool, but there are other possible approaches.", "labels": [], "entities": [{"text": "VARiant Detector 2 (VARD)", "start_pos": 61, "end_pos": 86, "type": "METRIC", "confidence": 0.8565365175406138}, {"text": "spelling normalisation", "start_pos": 103, "end_pos": 125, "type": "TASK", "confidence": 0.7588050365447998}]}, {"text": "compared three statistical approaches: 1) a filtering approach, 2) a Levenshtein-distance approach, and 3) a character-based statistical machine translation (SMT) approach.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 125, "end_pos": 162, "type": "TASK", "confidence": 0.7821074873209}]}, {"text": "These approaches were applied to five languages, and for four of these (including English), the SMT-based approach yielded the best results.", "labels": [], "entities": [{"text": "SMT-based", "start_pos": 96, "end_pos": 105, "type": "TASK", "confidence": 0.9922494888305664}]}, {"text": "In this paper, we compare the results of applying the SMT-based spelling normalisation approach to the ARCHER corpus of historical English and American texts, to the results achieved for VARD2 on the same corpus.", "labels": [], "entities": [{"text": "SMT-based spelling normalisation", "start_pos": 54, "end_pos": 86, "type": "TASK", "confidence": 0.914939800898234}, {"text": "ARCHER corpus of historical English and American texts", "start_pos": 103, "end_pos": 157, "type": "DATASET", "confidence": 0.9530480802059174}, {"text": "VARD2", "start_pos": 187, "end_pos": 192, "type": "DATASET", "confidence": 0.7955515384674072}]}, {"text": "The comparison is interesting as the approaches are significantly different: SMT is a probablistic, languageindependent approach, whereas VARD2 combines lexicon-lookup with rules and non-probabilistic weights.", "labels": [], "entities": [{"text": "SMT", "start_pos": 77, "end_pos": 80, "type": "TASK", "confidence": 0.9641388654708862}, {"text": "VARD2", "start_pos": 138, "end_pos": 143, "type": "DATASET", "confidence": 0.6668357253074646}]}], "datasetContent": [{"text": "The results of applying VARD2 are given in, in terms of precison, recall, and per-word rates.", "labels": [], "entities": [{"text": "VARD2", "start_pos": 24, "end_pos": 29, "type": "METRIC", "confidence": 0.8224316835403442}, {"text": "precison", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9784672260284424}, {"text": "recall", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.9974191188812256}]}, {"text": "The results using the default rules provided with the VARD2 distribution are in the second column, and using the training from the manually annotated 109 ARCHER documents (in addition to the default rules provided in the VARD2 distribution) in the third column, and best SMT in the fourth column.", "labels": [], "entities": [{"text": "VARD2 distribution", "start_pos": 54, "end_pos": 72, "type": "DATASET", "confidence": 0.9541257619857788}, {"text": "ARCHER documents", "start_pos": 154, "end_pos": 170, "type": "DATASET", "confidence": 0.7960574924945831}, {"text": "VARD2 distribution", "start_pos": 221, "end_pos": 239, "type": "DATASET", "confidence": 0.9268317222595215}, {"text": "SMT", "start_pos": 271, "end_pos": 274, "type": "TASK", "confidence": 0.7507145404815674}]}, {"text": "First, VARD2 improves spelling (in the sense of mapping it to PDE variants) inmost settings, except when applying the defaults settings to the latest period, 19th century texts.", "labels": [], "entities": [{"text": "VARD2", "start_pos": 7, "end_pos": 12, "type": "METRIC", "confidence": 0.6152660250663757}, {"text": "spelling", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.8891698718070984}]}, {"text": "Second, the training with ARCHER has considerably improved results.", "labels": [], "entities": [{"text": "ARCHER", "start_pos": 26, "end_pos": 32, "type": "DATASET", "confidence": 0.5585000514984131}]}, {"text": "Third, we have tested the effect of training on the entire ARCHER or only the appropriate century and show the results in the second last column.", "labels": [], "entities": [{"text": "ARCHER", "start_pos": 59, "end_pos": 65, "type": "DATASET", "confidence": 0.5734009146690369}]}, {"text": "The effect of training VARD2 on different periods could be relatively small, as the default rules are not deleted, the new rules are just added and the the weights adapted.", "labels": [], "entities": [{"text": "VARD2", "start_pos": 23, "end_pos": 28, "type": "METRIC", "confidence": 0.47357386350631714}]}, {"text": "Using less training data leads to results with higher precision and lower recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9992875456809998}, {"text": "recall", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.999093770980835}]}, {"text": "Fourth, the task gets increasingly difficult in later periods, which is related to the fact that only very few tokens need normalisation, as we have already observed in the discussion of inter-annotator agreement.", "labels": [], "entities": []}, {"text": "The performance in the 19th century is partly so low because there are only very few words that require correction, thus absurd cor-: Normalisation accuracy of VARD, in percent, for the evaluation corpus, and split by century, comparing the VARD default rules, and the effect of training on 109 manually annotated ARCHER documents, and a comparison to SMT.", "labels": [], "entities": [{"text": "Normalisation", "start_pos": 134, "end_pos": 147, "type": "METRIC", "confidence": 0.9757723808288574}, {"text": "accuracy", "start_pos": 148, "end_pos": 156, "type": "METRIC", "confidence": 0.7926795482635498}, {"text": "VARD", "start_pos": 160, "end_pos": 164, "type": "METRIC", "confidence": 0.9127150774002075}, {"text": "SMT", "start_pos": 352, "end_pos": 355, "type": "TASK", "confidence": 0.7189196944236755}]}, {"text": "N=number of manual changes, W=number of words rections such as changing idiotism to idiocy affect precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 98, "end_pos": 107, "type": "METRIC", "confidence": 0.9987961053848267}]}, {"text": "Recall is strongly affected by rare words and rare but correct variants, such as silicious which is not corrected to siliceous.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.8544877767562866}]}, {"text": "It might be advisable to stop using historical spelling correction already at 1800 instead of 1850.", "labels": [], "entities": [{"text": "historical spelling correction", "start_pos": 36, "end_pos": 66, "type": "TASK", "confidence": 0.5470482110977173}]}, {"text": "Fifth, the SMT system performs slightly below the highly costumized VARD tool.", "labels": [], "entities": [{"text": "SMT", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.9947088956832886}, {"text": "VARD", "start_pos": 68, "end_pos": 72, "type": "METRIC", "confidence": 0.5517093539237976}]}, {"text": "We elaborate on this point in the following section.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Normalisation accuracy, per word, for  different parts of the corpus. dict = adding dic- tionaries for lexical filtering.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.7193529009819031}]}, {"text": " Table 2: Normalisation accuracy of VARD, in percent, for the evaluation corpus, and split by century,  comparing the VARD default rules, and the effect of training on 109 manually annotated ARCHER  documents, and a comparison to SMT. N=number of manual changes, W=number of words", "labels": [], "entities": [{"text": "Normalisation", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9459753036499023}, {"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.675643801689148}, {"text": "VARD", "start_pos": 36, "end_pos": 40, "type": "METRIC", "confidence": 0.7554388642311096}, {"text": "SMT", "start_pos": 230, "end_pos": 233, "type": "TASK", "confidence": 0.689231276512146}]}]}