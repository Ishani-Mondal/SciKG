{"title": [{"text": "Using gaze to predict text readability", "labels": [], "entities": []}], "abstractContent": [{"text": "We show that text readability prediction improves significantly from hard parameter sharing with models predicting first pass duration, total fixation duration and regression duration.", "labels": [], "entities": [{"text": "text readability prediction", "start_pos": 13, "end_pos": 40, "type": "TASK", "confidence": 0.7925264437993368}, {"text": "first pass duration", "start_pos": 115, "end_pos": 134, "type": "METRIC", "confidence": 0.7042975227038065}, {"text": "total fixation duration", "start_pos": 136, "end_pos": 159, "type": "METRIC", "confidence": 0.7856130599975586}]}, {"text": "Specifically, we induce multi-task Multilayer Perceptrons and Logistic Regression models over sentence representations that capture various aggregate statistics, from two different text readability corpora for English, as well as the Dundee eye-tracking corpus.", "labels": [], "entities": [{"text": "Dundee eye-tracking corpus", "start_pos": 234, "end_pos": 260, "type": "DATASET", "confidence": 0.914154569307963}]}, {"text": "Our approach leads to significant improvements over Single task learning and over previous systems.", "labels": [], "entities": []}, {"text": "In addition, our improvements are consistent across train sample sizes, making our approach especially applicable to small datasets.", "labels": [], "entities": []}], "introductionContent": [{"text": "When we read, our eyes move rapidly back and forth between fixations.", "labels": [], "entities": []}, {"text": "These movements are called saccades.", "labels": [], "entities": []}, {"text": "The distribution of fixations and saccades can provide us with important insight about the reader and the text being read.", "labels": [], "entities": []}, {"text": "For example, long regressive eye movements, which typically involve regressing more than 10 letter spaces, may indicate that the reader is facing some difficulty in understanding the text.", "labels": [], "entities": []}, {"text": "In addition, regressions have been shown to occur during the disambiguation of a sentence.", "labels": [], "entities": []}, {"text": "This relationship between text and eye movements, has led to an influx of studies investigating the use of eye tracking data to improve and test computational models of language i.e.;;.", "labels": [], "entities": []}, {"text": "In this study we aim to incorporate eye movement data for the task of automatic readability assessment.", "labels": [], "entities": [{"text": "automatic readability assessment", "start_pos": 70, "end_pos": 102, "type": "TASK", "confidence": 0.6058677732944489}]}, {"text": "Automatic readability assessment is the task of automatically labeling a text with a certain difficulty level.", "labels": [], "entities": [{"text": "Automatic readability assessment", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6585980554421743}]}, {"text": "An accurate and robust system has many potential applications, for example it can help educators obtain appropriate reading materials for students with normal learning capacities, as well as students with disabilities and language learners.", "labels": [], "entities": []}, {"text": "It can also be used to assess the performance of machine translation, text simplification and language generation systems.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.7791171967983246}, {"text": "text simplification", "start_pos": 70, "end_pos": 89, "type": "TASK", "confidence": 0.8051249384880066}, {"text": "language generation", "start_pos": 94, "end_pos": 113, "type": "TASK", "confidence": 0.7301539331674576}]}, {"text": "Eye-tracking data has previously been used to evaluate readability models, however, our main contribution is to explore the way that eye tracking data can help improve models for readability assessment through multi-task learning and parser metrics based on the surprisal theory of syntactic complexity.", "labels": [], "entities": []}, {"text": "Multi task learning allows the model to learn various tasks in parallel and improve performance by sharing parameters in the hidden layers.", "labels": [], "entities": []}, {"text": "The work most related to ours is by, who used eye tracking measures taken from the Dundee corpus in order to predict word byword reading times for each sentence.", "labels": [], "entities": [{"text": "Dundee corpus", "start_pos": 83, "end_pos": 96, "type": "DATASET", "confidence": 0.9949864149093628}]}, {"text": "Subsequently, they used these word byword reading times as features for predicting readability.", "labels": [], "entities": []}, {"text": "The two tasks were performed separately, and their feature representations were different from the ones presented here.", "labels": [], "entities": []}, {"text": "In contrast, we present a model that predicts gaze and sentence-level readability simultaneously.", "labels": [], "entities": []}, {"text": "We use gaze data from the Dundee corpus () and two different datasets for the readability prediction task: aligned Wikipedia sentences used for the task of text simplification by and the OneStopEnglish dataset used by.", "labels": [], "entities": [{"text": "Dundee corpus", "start_pos": 26, "end_pos": 39, "type": "DATASET", "confidence": 0.9905167818069458}, {"text": "readability prediction", "start_pos": 78, "end_pos": 100, "type": "TASK", "confidence": 0.7406733334064484}, {"text": "text simplification", "start_pos": 156, "end_pos": 175, "type": "TASK", "confidence": 0.7284101992845535}, {"text": "OneStopEnglish dataset", "start_pos": 187, "end_pos": 209, "type": "DATASET", "confidence": 0.9223670065402985}]}, {"text": "Contributions This is, to the best of our knowledge, the first application of multi-task learning to readability prediction.", "labels": [], "entities": [{"text": "readability prediction", "start_pos": 101, "end_pos": 123, "type": "TASK", "confidence": 0.8881908059120178}]}, {"text": "Our model is also different from previous applications of multi-task learning to natural language processing in that we combine a classification task and a regression task.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 81, "end_pos": 108, "type": "TASK", "confidence": 0.6769800186157227}]}, {"text": "We experiment with two multi-task learning algorithms, namely hard parameter sharing for multi-layered perceptrons) and a novel approach to hard parameter sharing between logistic and linear regression.", "labels": [], "entities": []}, {"text": "We evaluate our models on Simple Wikipedia and the OneStopEnglish corpus.", "labels": [], "entities": [{"text": "Simple Wikipedia", "start_pos": 26, "end_pos": 42, "type": "DATASET", "confidence": 0.9281587600708008}, {"text": "OneStopEnglish corpus", "start_pos": 51, "end_pos": 72, "type": "DATASET", "confidence": 0.9379173815250397}]}, {"text": "Finally, we present learning curves that show that the improvements are robust across different sample sizes.", "labels": [], "entities": []}], "datasetContent": [{"text": "Data Our target task is sentence-level readability prediction, i.e. a binary classification problem of sentences into easy-to-read and hard-to-read.", "labels": [], "entities": [{"text": "sentence-level readability prediction", "start_pos": 24, "end_pos": 61, "type": "TASK", "confidence": 0.7071768045425415}]}, {"text": "Our main corpus is a sentence-aligned corpus of 137,000 simple versus normal English sentences from Wikipedia (.", "labels": [], "entities": []}, {"text": "Similar datasets have been used in the past, e.g., in and.", "labels": [], "entities": []}, {"text": "The easy-to-read sentences were taken from Simple Wikipedia and paired with sentences from the standard Wikipedia using cosine similarity.", "labels": [], "entities": [{"text": "Simple Wikipedia", "start_pos": 43, "end_pos": 59, "type": "DATASET", "confidence": 0.8760857582092285}]}, {"text": "In addition, we also evaluate our models on the OneStopEnglish corpus (, specifically the elementary-intermediate and elementary-advanced sentence pairs.", "labels": [], "entities": [{"text": "OneStopEnglish corpus", "start_pos": 48, "end_pos": 69, "type": "DATASET", "confidence": 0.9236753582954407}]}, {"text": "This dataset has been used for readability assessment) using the WeeBit model presented by), so we compare our results with theirs.", "labels": [], "entities": [{"text": "WeeBit", "start_pos": 65, "end_pos": 71, "type": "DATASET", "confidence": 0.9195323586463928}]}, {"text": "Feature representation In this study, features known to affect the complexity of text, such as syntactic, lexical and total surprisal, were used.", "labels": [], "entities": [{"text": "Feature representation", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7027332484722137}]}, {"text": "Most of these features were extracted using a probabilistic top-down parser introduced by.", "labels": [], "entities": []}, {"text": "After removing duplicate sentences and sentences with typos, the final corpus used was of about 80,000 sentence pairs.", "labels": [], "entities": []}, {"text": "The features extracted are shown in table 1.", "labels": [], "entities": []}, {"text": "The prefix probability of word w n is explained by as the probability that w n occurs as a prefix of some string generated by a grammar.", "labels": [], "entities": []}, {"text": "It is the sum of the probabilities of  all trees from the first word to the current word.", "labels": [], "entities": []}, {"text": "Surprisal is then the difference between the log of the prefix probability of w n and w n\u22121 . If we describe D(G, W) as the set of all possible leftmost derivations D with respect to probabilistic context free grammar G and whose last step used a production with terminal W n . We can then express the prefix probability of , where \u03c1(D) is the probability of the derivation of a certain tree.", "labels": [], "entities": [{"text": "Surprisal", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9632394909858704}]}, {"text": "The total surprisal of W n is then defined as: Syntactic surprisal and lexical surprisal are calculated to account for high surprisal scores.", "labels": [], "entities": []}, {"text": "As mentions, a word may surprise because it is unconventional, or because it occurs in an unusual context.", "labels": [], "entities": []}, {"text": "In order to separate the lexical and syntactic components of surprisal, the incremental parser calculates partial derivations immediately before word W n is integrated into the syntactic structure.", "labels": [], "entities": []}, {"text": "Syntactic surprisal (SynS G (W n )) is defined as: and lexical surprisal (LexS G (W n )) as: Where D[1, |D| \u2212 1] is the set of the partial derivations before each word is integrated into the structure D(G, W).", "labels": [], "entities": []}, {"text": "Total surprisal turns out to be sum of syntactic surprisal and lexical surprisal.", "labels": [], "entities": []}, {"text": "We also obtain an entropy score using the parser.", "labels": [], "entities": []}, {"text": "Entropy over a set of derivations D, denoted as H(D), quantifies the uncertainty over the partial derivations.", "labels": [], "entities": [{"text": "Entropy", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.8633637428283691}]}, {"text": "We call this feature Ambiguity, defined as: Furthermore, features corresponding to the first and second words were included, as the initial words in a sentence allow the reader to make preliminary guesses of what the structure will be for the rest of the sentence, although these predictions can often turnout to be wrong.", "labels": [], "entities": [{"text": "Ambiguity", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.9862014651298523}]}, {"text": "In addition, mean syntactic scores and standard deviations for all words in the sentence are included as features.", "labels": [], "entities": []}, {"text": "We also include the mean age of acquisition for the words in a given sentence, using data from.", "labels": [], "entities": []}, {"text": "Finally, we include basic counts and ratios used previously in readability prediction such as sentence length, parse tree height, number of SBAR's, noun phrases, verb phrases, among others . In order to predict gaze, we extract the features seen in from the Dundee corpus.", "labels": [], "entities": [{"text": "Dundee corpus", "start_pos": 258, "end_pos": 271, "type": "DATASET", "confidence": 0.9921904504299164}]}, {"text": "As mentioned earlier, these features offer a good representation of cognitive load, which is also reflected in reading times.", "labels": [], "entities": []}, {"text": "A feature vector of size 33 was built for each sentence, and this information was used in order to predict an average first pass duration, regression path duration and total fixation duration.", "labels": [], "entities": [{"text": "first pass duration", "start_pos": 118, "end_pos": 137, "type": "METRIC", "confidence": 0.6848029692967733}, {"text": "total fixation duration", "start_pos": 168, "end_pos": 191, "type": "METRIC", "confidence": 0.7303916017214457}]}, {"text": "First pass duration refers to the sum of all fixations on a region once the region is first entered until it is left.", "labels": [], "entities": [{"text": "First pass duration", "start_pos": 0, "end_pos": 19, "type": "METRIC", "confidence": 0.7127715945243835}]}, {"text": "Regression path duration includes regressions made out of a region prior to moving forward in the text and total fixation duration is the sum of all fixations in the region including, regressions to that region.", "labels": [], "entities": [{"text": "Regression path duration", "start_pos": 0, "end_pos": 24, "type": "METRIC", "confidence": 0.8350985447565714}, {"text": "total fixation duration", "start_pos": 107, "end_pos": 130, "type": "METRIC", "confidence": 0.7679829597473145}]}, {"text": "As mentioned in, these measures typically concern research questions focusing on sentence or discourse processing.", "labels": [], "entities": [{"text": "sentence or discourse processing", "start_pos": 81, "end_pos": 113, "type": "TASK", "confidence": 0.6588398963212967}]}, {"text": "Logistic/linear regression and MLPs Logistic Regression (LR) models have been widely used in document level readability classification i.e. and).", "labels": [], "entities": [{"text": "MLPs Logistic Regression (LR)", "start_pos": 31, "end_pos": 60, "type": "METRIC", "confidence": 0.7797300467888514}]}, {"text": "LR models are linear models and can bethought of as singlelayer perceptrons with softmax or sigmoid activation functions.", "labels": [], "entities": []}, {"text": "The objective is typically to minimize a cross-entropy loss function.", "labels": [], "entities": []}, {"text": "The same architecture can be used for linear regression, however, when trained to minimize mean squared error.", "labels": [], "entities": [{"text": "linear regression", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.7107711136341095}, {"text": "mean squared error", "start_pos": 91, "end_pos": 109, "type": "METRIC", "confidence": 0.8850528399149576}]}, {"text": "Here, we compare LR with a 3-layered Multi Layer Perceptron (MLP).", "labels": [], "entities": []}, {"text": "For our MLP architecture, we use sigmoid activation at the input and output layers and use ReLu activation in the hidden layer.", "labels": [], "entities": []}, {"text": "The hidden layer contains 100 neurons.", "labels": [], "entities": []}, {"text": "All models presented here use the Adam optimizer, and a drop-out rate of 0.5.", "labels": [], "entities": []}, {"text": "We also use Adam to learn logistic and linear regression models.", "labels": [], "entities": []}, {"text": "As already mentioned, we go beyond singletask LR and MLP models and present two multi-task learning architectures with heterogeneous loss functions (cross-entropy and minimum squared error).", "labels": [], "entities": []}, {"text": "In multi-task learning, the training signals of one task are used as an inductive bias in order to improve the generalization of another task.", "labels": [], "entities": []}, {"text": "Specifically, we use the the task of gaze prediction in order to improve the generalization of readability prediction.", "labels": [], "entities": [{"text": "gaze prediction", "start_pos": 37, "end_pos": 52, "type": "TASK", "confidence": 0.7974073588848114}, {"text": "readability prediction", "start_pos": 95, "end_pos": 117, "type": "TASK", "confidence": 0.7967371046543121}]}, {"text": "Multi-task MLP Our multi-task learning architecture is identical to that of Caruana (1997) and, i.e., two MLPs that share all parameters in their hidden layers.", "labels": [], "entities": []}, {"text": "The only difference is that one of the MLPs in our case is trained to minimize a minimum squared error to predict gaze statistics.", "labels": [], "entities": []}, {"text": "Multi-task logistic and linear regression Our linear multi-task learning model is novel in that it combines a logistic and a linear regression model by tying their parameters.", "labels": [], "entities": []}, {"text": "As mentioned earlier, LR models can bethought of as single-layer perceptrons.", "labels": [], "entities": []}, {"text": "We tie a single-layer perceptron with sigmoid activation to another single-layer perceptron with linear activation by sharing their single layer and giving a higher weight to our main task.", "labels": [], "entities": []}, {"text": "While this is in fact a simpler model than the deep multi-task learning model above, this model has, to the best of our knowledge, not been suggested before, and in many ways, it is surprising that it works.", "labels": [], "entities": []}, {"text": "Baselines Ambati et al. obtained 78.87 percent accuracy on the Wikipedia dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9869383573532104}, {"text": "Wikipedia dataset", "start_pos": 63, "end_pos": 80, "type": "DATASET", "confidence": 0.9809648096561432}]}, {"text": "They use features extracted from a Combinatory Categorical Grammar (CCG) parser.", "labels": [], "entities": []}, {"text": "We also compare our results to, who use their WeeBit model in order to predict readability at the sentence level.", "labels": [], "entities": [{"text": "WeeBit", "start_pos": 46, "end_pos": 52, "type": "DATASET", "confidence": 0.8277647495269775}]}, {"text": "In addition, for the Wikipedia dataset, we include the best results from as it is the study most related to ours.", "labels": [], "entities": [{"text": "Wikipedia dataset", "start_pos": 21, "end_pos": 38, "type": "DATASET", "confidence": 0.9805509746074677}]}], "tableCaptions": [{"text": " Table 1: Features extracted for the readability  data.", "labels": [], "entities": []}, {"text": " Table 2: Accuracy for all models. Most results  obtained using MTL-MLP yield statistically sig- nificant improvements of STL-MLP (p < 0.001).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9990704655647278}]}, {"text": " Table 3: Accuracy when predicting readability us- ing features in groups. The results show, that a  combination of both sets of features provide the  best result.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9868611693382263}]}, {"text": " Table 4: Accuracy on Wikipedia dataset when pre- dicting readability using single features.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9949510097503662}, {"text": "Wikipedia dataset", "start_pos": 22, "end_pos": 39, "type": "DATASET", "confidence": 0.9810698628425598}]}]}