{"title": [], "abstractContent": [{"text": "This paper describes work towards the harmonization of the Greek Dependency Treebank with the Universal Dependencies v2 standard, and the extension of the treebank with enhanced dependencies.", "labels": [], "entities": [{"text": "Greek Dependency Treebank", "start_pos": 59, "end_pos": 84, "type": "DATASET", "confidence": 0.9459836880366007}]}, {"text": "Experiments with the latest version of the UD_Greek resource have led to 88.94/87.66 LAS on gold/automatic POS, morphological features and lemmas.", "labels": [], "entities": [{"text": "UD_Greek resource", "start_pos": 43, "end_pos": 60, "type": "DATASET", "confidence": 0.8304620683193207}, {"text": "LAS", "start_pos": 85, "end_pos": 88, "type": "METRIC", "confidence": 0.8722589612007141}]}], "introductionContent": [{"text": "The Universal Dependencies ( community effort has led to the development and collection of a large number of treebanks adhering to common and extendible annotation guidelines.", "labels": [], "entities": []}, {"text": "These guidelines aim to ease the annotation process and improve the accuracy of parsers and downstream NLP applications in generating useful and linguistically sound representations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9985377788543701}]}, {"text": "Greek is represented in the UD effort with UD_Greek . In this paper, we provide more details on the annotated resource in section 2 and its conversion to the UD standard.", "labels": [], "entities": [{"text": "UD standard", "start_pos": 158, "end_pos": 169, "type": "DATASET", "confidence": 0.8626842200756073}]}, {"text": "In section 3 we discuss ongoing work for extending GDT with a subset of the enhanced dependencies proposed by.", "labels": [], "entities": [{"text": "GDT", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.6221900582313538}]}, {"text": "Section 4 presents experiments with parsers trained on the different-sized versions of the resource and on manually/automatically annotated morphology and lemmas.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we report on experiments with the current version of UD_Greek and its GDT superset.", "labels": [], "entities": [{"text": "UD_Greek", "start_pos": 70, "end_pos": 78, "type": "DATASET", "confidence": 0.8180416027704874}]}, {"text": "In all experiments reported below, we remove the annotations related to the enhanced dependencies described in Section 3, since they do not yet cover the whole resource.", "labels": [], "entities": []}, {"text": "We examined parsing accuracy in scenarios involving manual and automatic annotations for morphology and lemmas.", "labels": [], "entities": [{"text": "parsing", "start_pos": 12, "end_pos": 19, "type": "TASK", "confidence": 0.9533649682998657}, {"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9007562398910522}]}, {"text": "In the latter setting, POS tagging is conducted with a tagger () with an accuracy of 97.49 when only basic POS is considered.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 23, "end_pos": 34, "type": "TASK", "confidence": 0.9310587644577026}, {"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9994151592254639}]}, {"text": "When all features (including, for example, gender and case for nouns, and aspect and tense for verbs) are taken into account, the tagger's accuracy drops to 92.54.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.9996782541275024}]}, {"text": "As an indication of the relatively rich morphology of Greek, the tags/word ratio in the tagger's lexicon is 1.82.", "labels": [], "entities": []}, {"text": "Tags fora word typically differ in only one or two features like case and gender for adjectives.", "labels": [], "entities": []}, {"text": "However, distinct basic parts of speech (e.g. Vb/No) is also a possibility.", "labels": [], "entities": []}, {"text": "Following POS tagging, a lemmatizer retrieves lemmas from a lexicon of 2M different entries.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.7661551535129547}]}, {"text": "When a token under examination is associated in the lexicon with two or more lemmas, the lemmatizer uses information from the POS tags for: Enhanced dependency graph fora backward subject control structure. disambiguation.", "labels": [], "entities": []}, {"text": "For example, the token+POS input \u03b5\u03be\u03b5\u03c4\u03ac\u03c3\u03b5\u03b9\u03c2/Vb guides the lemmatizer to retrieve the lemma \u03b5\u03be\u03b5\u03c4\u03ac\u03b6\u03c9 (examine), while the lemma \u03b5\u03be\u03ad\u03c4\u03b1\u03c3\u03b7 (examination) is returned for \u03b5\u03be\u03b5\u03c4\u03ac\u03c3\u03b5\u03b9\u03c2/No. We use the graph-based Mateparser and the transition-based version of Bistparser (.", "labels": [], "entities": [{"text": "Bistparser", "start_pos": 247, "end_pos": 257, "type": "METRIC", "confidence": 0.7515694499015808}]}, {"text": "For the latter, we projectivise datasets by lifting nonprojective arcs), and we use 100-dimensional word-embeddings obtained with the fastText library () from a 350M token corpus.", "labels": [], "entities": []}, {"text": "Using the whole resource with gold POS, morphological features and lemmas (GDT-MPL), the Mate and Bist LAS are 90.29/89.36, respectively.", "labels": [], "entities": [{"text": "GDT-MPL", "start_pos": 75, "end_pos": 82, "type": "METRIC", "confidence": 0.63869309425354}, {"text": "Bist LAS", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9663788080215454}]}, {"text": "The difference between the two parsers on input with automatic annotations (GDT-APL) is smaller (88.82/88.36).", "labels": [], "entities": []}, {"text": "When comparing the performance of both parsers on the different size datasets, the LAS improvement on the bigger dataset is more evident for Bistparser, with a 1.97% increase from the APL setting with the UD_Greek dataset (UD-APL).", "labels": [], "entities": [{"text": "LAS", "start_pos": 83, "end_pos": 86, "type": "METRIC", "confidence": 0.961995005607605}, {"text": "UD_Greek dataset", "start_pos": 205, "end_pos": 221, "type": "DATASET", "confidence": 0.7543487846851349}]}, {"text": "For both parsers, best LAS is observed for small sentences of 5-15 tokens long, with the accuracy remaining relatively stable for sentences of 15-25 tokens (cf.).", "labels": [], "entities": [{"text": "LAS", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.9895585775375366}, {"text": "accuracy", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.9994034767150879}]}], "tableCaptions": [{"text": " Table 1: Results from parsing UD_Greek and GDT with the Bist-and Mate parsers. UD_Greek contains  63K tokens, a subset of GDT's 178K tokens. (M/A)PL suffixes refer to training and testing on gold  and automatic POS, morphological features and lemmas, respectively. All scores are calculated with  punctuation excluded, on a test partition containing circa 10% of the tokens of each dataset.", "labels": [], "entities": [{"text": "parsing UD_Greek", "start_pos": 23, "end_pos": 39, "type": "TASK", "confidence": 0.7723762691020966}, {"text": "GDT", "start_pos": 44, "end_pos": 47, "type": "DATASET", "confidence": 0.9353005886077881}, {"text": "Bist-and", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9427235722541809}]}]}