{"title": [{"text": "Transfer Learning for Neural Semantic Parsing", "labels": [], "entities": [{"text": "Neural Semantic Parsing", "start_pos": 22, "end_pos": 45, "type": "TASK", "confidence": 0.6217902998129526}]}], "abstractContent": [{"text": "The goal of semantic parsing is to map natural language to a machine interpretable meaning representation language (MRL).", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 12, "end_pos": 28, "type": "TASK", "confidence": 0.729287251830101}, {"text": "machine interpretable meaning representation language (MRL)", "start_pos": 61, "end_pos": 120, "type": "TASK", "confidence": 0.6772641874849796}]}, {"text": "One of the constraints that limits full exploration of deep learning technologies for semantic parsing is the lack of sufficient annotation training data.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 86, "end_pos": 102, "type": "TASK", "confidence": 0.8540062010288239}]}, {"text": "In this paper, we propose using sequence-to-sequence in a multi-task setup for semantic parsing with a focus on transfer learning.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 79, "end_pos": 95, "type": "TASK", "confidence": 0.8787708282470703}, {"text": "transfer learning", "start_pos": 112, "end_pos": 129, "type": "TASK", "confidence": 0.9046699404716492}]}, {"text": "We explore three multi-task architectures for sequence-to-sequence modeling and compare their performance with an independently trained model.", "labels": [], "entities": []}, {"text": "Our experiments show that the multi-task setup aids transfer learning from an auxiliary task with large labeled data to a target task with smaller labeled data.", "labels": [], "entities": []}, {"text": "We see absolute accuracy gains ranging from 1.0% to 4.4% in our in-house data set, and we also see good gains ranging from 2.5% to 7.0% on the ATIS semantic parsing tasks with syntactic and semantic auxiliary tasks.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.8887916207313538}, {"text": "ATIS semantic parsing tasks", "start_pos": 143, "end_pos": 170, "type": "TASK", "confidence": 0.7389322519302368}]}], "introductionContent": [{"text": "Conversational agents, such as Alexa, Siri and Cortana, solve complex tasks by interacting and mediating between the end-user and multiple backend software applications and services.", "labels": [], "entities": []}, {"text": "Natural language is a simple interface used for communication between these agents.", "labels": [], "entities": []}, {"text": "However, to make natural language machine-readable we need to map it to a representation that describes the semantics of the task expressed in the language.", "labels": [], "entities": []}, {"text": "Semantic parsing is the process of mapping a naturallanguage sentence into a formal machine-readable representation of its meaning.", "labels": [], "entities": [{"text": "Semantic parsing", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8244071304798126}]}, {"text": "This poses a challenge in a multi-tenant system that has to interact with multiple backend knowledge sources each with their own semantic formalisms and custom schemas for accessing information, where each formalism has various amount of annotation training data.", "labels": [], "entities": []}, {"text": "Recent works have proven sequence-tosequence to bean effective model architecture) for semantic parsing.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 87, "end_pos": 103, "type": "TASK", "confidence": 0.8541082143783569}]}, {"text": "However, because of the limit amount of annotated data, the advantage of neural networks to capture complex data representation using deep structure has not been fully explored.", "labels": [], "entities": []}, {"text": "Acquiring data is expensive and sometimes infeasible for task-oriented systems, the main reasons being multiple formalisms (e.g., SPARQL for WikiData), MQL for Freebase), and multiple tasks (question answering, navigation interactions, transactional interactions).", "labels": [], "entities": [{"text": "question answering, navigation interactions", "start_pos": 191, "end_pos": 234, "type": "TASK", "confidence": 0.7385351598262787}]}, {"text": "We propose to exploit these multiple representations in a multi-task framework so we can minimize the need fora large labeled corpora across these formalisms.", "labels": [], "entities": []}, {"text": "By suitably modifying the learning process, we capture the common structures that are implicit across these formalisms and the tasks they are targeted for.", "labels": [], "entities": []}, {"text": "In this work, we focus on a sequence-tosequence based transfer learning for semantic parsing.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 76, "end_pos": 92, "type": "TASK", "confidence": 0.8794033527374268}]}, {"text": "In order to tackle the challenge of multiple formalisms, we apply three multi-task frameworks with different levels of parameter sharing.", "labels": [], "entities": []}, {"text": "Our hypothesis is that the encoderdecoder paradigm learns a canonicalized representation across all tasks.", "labels": [], "entities": []}, {"text": "Over a strong single-task sequence-to-sequence baseline, our proposed approach shows accuracy improvements across the target formalism.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9987516403198242}]}, {"text": "In addition, we show that even when the auxiliary task is syntactic parsing we can achieve good gains in semantic parsing that are comparable to the published state-of-the-art.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.758856862783432}, {"text": "semantic parsing", "start_pos": 105, "end_pos": 121, "type": "TASK", "confidence": 0.7184343039989471}]}], "datasetContent": [{"text": "We first study the effectiveness of the multi-task architecture in a transfer learning setup.", "labels": [], "entities": []}, {"text": "Here we consider EviMRL as the large source auxiliary task and the AlexaMRL as the target task we want to transfer learn.", "labels": [], "entities": [{"text": "AlexaMRL", "start_pos": 67, "end_pos": 75, "type": "DATASET", "confidence": 0.9197441339492798}]}, {"text": "We consider various data sizes for the target task -10K, 50K and 100K and 200K by downsampling.", "labels": [], "entities": []}, {"text": "For each target data size, we compare a single-task setup, trained on the target task only, with the the various multitask setups from Section 3.2 -independent, oneto-one, one-to-many, and one-to-manyShare.", "labels": [], "entities": []}, {"text": "The x-axis lists the four model architecture, and y-axis is the accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9993394017219543}]}, {"text": "The positive number above the mark of oneto-one, one-to-many and one-to-manyShare represents the absolute accuracy gain compared with the independent model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9379716515541077}]}, {"text": "For the 10k independent model, we reduce the hidden layer size from 512 to 256 to optimize the performance.", "labels": [], "entities": []}, {"text": "In all cases, the multi-task architectures provide accuracy improvements over the independent architecture.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9986326098442078}]}, {"text": "By jointly training across the two tasks, the model is able to leverage the richer syntactic/semantic structure of the larger task (EviMRL), resulting in an improved encoding of the input utterance that is then fed to the decoder resulting in improved accuracy over the smaller task (Alexa-MRL).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 252, "end_pos": 260, "type": "METRIC", "confidence": 0.9983938336372375}]}, {"text": "We take this sharing further in the one-to-one and one-to-shareMany architecture by introducing shared decoder parameters, which forces the model to learn a common canonical representation for solving the semantic parsing task.", "labels": [], "entities": [{"text": "semantic parsing task", "start_pos": 205, "end_pos": 226, "type": "TASK", "confidence": 0.780428280433019}]}, {"text": "Doing so, we see further gains across all data sizes in 4.", "labels": [], "entities": []}, {"text": "For instance, in the 200k case, the absolute gain improves from +2.0 to +2.7 . As the training data size for the target task increases, we tend to see relatively less gain from model sharing.", "labels": [], "entities": [{"text": "absolute gain", "start_pos": 36, "end_pos": 49, "type": "METRIC", "confidence": 0.9639414846897125}]}, {"text": "For instance, in 10k training cases, the absolute gain from the one-to-one and one-to-manyshared is 1.6, this gain reduces to 0.7 when we have 200k training data.", "labels": [], "entities": []}, {"text": "When we have a small amount of training data, the one-to-shareMany provides better accuracy compared with one-to-one.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9993569254875183}]}, {"text": "For instance, we see 1.0 and 0.6 absolute gain from one-to-one to oneto-shareMany for 10k and 50k cases respectively.", "labels": [], "entities": []}, {"text": "However, no gain is observed for 100k and 200k training cases.", "labels": [], "entities": []}, {"text": "This confirms the hypothesis that for small amounts of data, having a dedicated output layer is helpful to guide the training.", "labels": [], "entities": []}, {"text": "Transfer learning works best when the source data is large, thereby allowing the smaller task to leverage the rich representation of the larger task.", "labels": [], "entities": [{"text": "Transfer learning", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9578289985656738}]}, {"text": "Accuracy (%): Accuracy for AlexaMRL.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9981480836868286}, {"text": "Accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9994932413101196}, {"text": "AlexaMRL", "start_pos": 27, "end_pos": 35, "type": "DATASET", "confidence": 0.8373199701309204}]}, {"text": "However, as the training data size increases, the accuracy gains from the shared architectures become smaller -the largest gain of 4.4% absolute is observed in the 10K setting, but as the data increases to 200K the improvements are almost halved to about 2.7%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9991449117660522}]}, {"text": "In, we summarize the numbers of parameters in each of the four model architectures and their step time.", "labels": [], "entities": []}, {"text": "As expected, we see comparable training time for one-to-many and one-toshareMany, but 10% step time increase for oneto-one.", "labels": [], "entities": []}, {"text": "We also see that one-to-one and oneto-shareMany have similar number of parameter, which is about 15% smaller than one-to-many due to the sharing of weights.", "labels": [], "entities": []}, {"text": "The one-to-shareMany architecture is able to get the increased sharing while still maintaining reasonable training speed per step-size.", "labels": [], "entities": [{"text": "sharing", "start_pos": 63, "end_pos": 70, "type": "METRIC", "confidence": 0.949211597442627}]}, {"text": "We also test the accuracy of EviMRL with the transfer learning framework.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9990630745887756}]}, {"text": "To our surprise, the EviMRL task also benefits from the AlexMRL task.", "labels": [], "entities": [{"text": "AlexMRL", "start_pos": 56, "end_pos": 63, "type": "DATASET", "confidence": 0.7600974440574646}]}, {"text": "We observe an absolute increase of accu-: parameter size and training time comparision for independent and multi-task models racy of 1.3% over the EviMRL baseline.", "labels": [], "entities": [{"text": "accu-: parameter size", "start_pos": 35, "end_pos": 56, "type": "METRIC", "confidence": 0.9332650661468506}, {"text": "EviMRL baseline", "start_pos": 147, "end_pos": 162, "type": "DATASET", "confidence": 0.8761446475982666}]}, {"text": "This observation reinforces the hypothesis that combining data from different semantic formalisms helps the generalization of the model by capturing common sub-structures involved in solving semantic parsing tasks across multiple formalisms.", "labels": [], "entities": [{"text": "solving semantic parsing tasks", "start_pos": 183, "end_pos": 213, "type": "TASK", "confidence": 0.7446849495172501}]}, {"text": "Here, we apply the described transfer learning setups to the ATIS semantic parsing task.", "labels": [], "entities": [{"text": "ATIS semantic parsing task", "start_pos": 61, "end_pos": 87, "type": "TASK", "confidence": 0.7421485930681229}]}, {"text": "We use a single GRU layer of 128 hidden states to train the independent model.", "labels": [], "entities": []}, {"text": "During transfer learning, we increase the model size to two hidden layers each with 512 hid-den states.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 7, "end_pos": 24, "type": "TASK", "confidence": 0.9393016695976257}]}, {"text": "We adjust the minibatch size to 20 and dropout rate to 0.2 for independent model and 0.7 for multi-task model.", "labels": [], "entities": [{"text": "dropout rate", "start_pos": 39, "end_pos": 51, "type": "METRIC", "confidence": 0.9685763716697693}]}, {"text": "We post-process the model output, balancing the braces and removing duplicates in the output.", "labels": [], "entities": []}, {"text": "The initial learning rate has been adjusted to 0.8 using the dev set.", "labels": [], "entities": []}, {"text": "Here, we only report accuracy numbers for the independent and one-to-shareMany frameworks.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9983348250389099}]}, {"text": "Correctness is based on denotation match at utterance level.", "labels": [], "entities": [{"text": "Correctness", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9590549468994141}]}, {"text": "We summarize all the results in: Accuracy on ATIS Our independent model has an accuracy of 77.2%, which is comparable to the published baseline of 76.3% reported in Jia and Liang (2016) before their data recombination.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9983952641487122}, {"text": "ATIS", "start_pos": 45, "end_pos": 49, "type": "DATASET", "confidence": 0.621235191822052}, {"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9992716908454895}]}, {"text": "To start with, we first consider using a related but complementary task -syntactic constituency parsing, to help improve the semantic parsing task.", "labels": [], "entities": [{"text": "syntactic constituency parsing", "start_pos": 73, "end_pos": 103, "type": "TASK", "confidence": 0.7466108401616415}, {"text": "semantic parsing task", "start_pos": 125, "end_pos": 146, "type": "TASK", "confidence": 0.7766631444295248}]}, {"text": "By adding WSJ constituency parsing as an auxiliary task for ATIS, we see a 3% relative improvement inaccuracy over the independent task baseline.", "labels": [], "entities": [{"text": "WSJ constituency parsing", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.6367718279361725}, {"text": "ATIS", "start_pos": 60, "end_pos": 64, "type": "DATASET", "confidence": 0.5993613600730896}]}, {"text": "This demonstrates that the multi-task architecture is quite general and is not constrained to using semantic parsing as the auxiliary task.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 100, "end_pos": 116, "type": "TASK", "confidence": 0.7483776807785034}]}, {"text": "This is important as it opens up the possibility of using significantly larger training data on tasks where acquiring labels is relatively easy.", "labels": [], "entities": []}, {"text": "We then add the EviMRL data of > 1M instances to the multi-task setup as a third task, and we see further relative improvement of 5%, which is comparable to the published state of the art and matches the neural network setup in.", "labels": [], "entities": [{"text": "EviMRL data", "start_pos": 16, "end_pos": 27, "type": "DATASET", "confidence": 0.7541036903858185}]}], "tableCaptions": [{"text": " Table 2: Accuracy on ATIS", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9992570281028748}, {"text": "ATIS", "start_pos": 22, "end_pos": 26, "type": "DATASET", "confidence": 0.45933589339256287}]}]}