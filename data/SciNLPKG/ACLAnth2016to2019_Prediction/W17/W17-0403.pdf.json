{"title": [{"text": "Increasing return on annotation investment: the automatic construction of a Universal Dependency treebank for Dutch", "labels": [], "entities": [{"text": "Universal Dependency treebank", "start_pos": 76, "end_pos": 105, "type": "DATASET", "confidence": 0.7241132855415344}, {"text": "Dutch", "start_pos": 110, "end_pos": 115, "type": "DATASET", "confidence": 0.49977147579193115}]}], "abstractContent": [{"text": "We present a method for automatically converting the Dutch Lassy Small tree-bank, a phrasal dependency treebank, to UD.", "labels": [], "entities": [{"text": "Dutch Lassy Small tree-bank", "start_pos": 53, "end_pos": 80, "type": "DATASET", "confidence": 0.9474365264177322}, {"text": "UD", "start_pos": 116, "end_pos": 118, "type": "METRIC", "confidence": 0.5479758381843567}]}, {"text": "All of the information required to produce accurate UD annotation appears to be available in the underlying annotation.", "labels": [], "entities": [{"text": "UD annotation", "start_pos": 52, "end_pos": 65, "type": "TASK", "confidence": 0.7125492095947266}]}, {"text": "However, we also note that the close connection between POS-tags and dependency labels that is present in UD is missing in the Lassy treebanks.", "labels": [], "entities": [{"text": "Lassy treebanks", "start_pos": 127, "end_pos": 142, "type": "DATASET", "confidence": 0.8852333128452301}]}, {"text": "As a consequence , annotation decisions in the Dutch data for such phenomena as nominaliza-tion and clausal complements of prepositions seem to differ to some extent from comparable data in English and German.", "labels": [], "entities": []}, {"text": "Because the conversion is automatic, we can now also compare three state-of-the-art dependency parsers trained on UD Lassy Small with Alpino, a hybrid Dutch parser which produces output that is compatible with the original Lassy annotations .", "labels": [], "entities": [{"text": "UD Lassy Small", "start_pos": 114, "end_pos": 128, "type": "DATASET", "confidence": 0.8823176821072897}]}], "introductionContent": [{"text": "We present a method for automatically converting Dutch treebanks annotated according to the guidelines of the Lassy project to Universal Dependencies.", "labels": [], "entities": [{"text": "Dutch treebanks annotated", "start_pos": 49, "end_pos": 74, "type": "DATASET", "confidence": 0.7235688169797262}]}, {"text": "The Lassy annotation guidelines combine elements from phrase structure treebanks (such as phrasal nodes and use of co-indexed nodes for encoding fronted WHconstituents) with elements from dependency treebanks (such as dependency labels, discontinuous constituents and crossing branches), similar to the Tiger () and Negra () corpora for German.", "labels": [], "entities": []}, {"text": "The conversion is done by means of an automatic conversion script.", "labels": [], "entities": []}, {"text": "There are two advantages to such a procedure: the original annotation is of high quality as it is the result of careful manual checking and correction of automatically produced parser output.", "labels": [], "entities": []}, {"text": "Using this investment as basis for the UD annotation as well means that this investment can also serve as basis for novel annotation projects.", "labels": [], "entities": []}, {"text": "Second, an automatic conversion script allows any material that has been annotated according to the guidelines of the Lassy project to be converted to UD, and thus also can be used to convert treebanks outside the UD corpus and to make existing tools compliant with UD.", "labels": [], "entities": [{"text": "UD corpus", "start_pos": 214, "end_pos": 223, "type": "DATASET", "confidence": 0.8092964291572571}]}, {"text": "There are two main challenges for the conversion: the Lassy treebanks contain dependency relations between phrasal nodes, whereas UD uses lexical dependency relations only.", "labels": [], "entities": [{"text": "Lassy treebanks", "start_pos": 54, "end_pos": 69, "type": "DATASET", "confidence": 0.8068308234214783}]}, {"text": "Second, the Lassy Treebanks use a more traditional notion of 'head' whereas UD gives precedence to content words over function words.", "labels": [], "entities": [{"text": "Lassy Treebanks", "start_pos": 12, "end_pos": 27, "type": "DATASET", "confidence": 0.872391551733017}]}, {"text": "As a consequence, converting from Lassy to UD requires 'head-switching' in a number of cases.", "labels": [], "entities": [{"text": "UD", "start_pos": 43, "end_pos": 45, "type": "DATASET", "confidence": 0.6399440765380859}]}, {"text": "In section 2 we outline the main principles of the conversion process.", "labels": [], "entities": [{"text": "conversion", "start_pos": 51, "end_pos": 61, "type": "TASK", "confidence": 0.9832242727279663}]}, {"text": "The conversion has been used to produce UD Dutch Lassy Small (v1.3 and 2.0).", "labels": [], "entities": [{"text": "UD Dutch Lassy Small", "start_pos": 40, "end_pos": 60, "type": "DATASET", "confidence": 0.7969515025615692}]}, {"text": "Lassy Small is a manually verified 1 million word treebank for Dutch, consisting of mixed sources.", "labels": [], "entities": []}, {"text": "For reasons of intellectual property rights, only the Wikipedia part (7.641 sentences, 101.841 tokens) is included in the UD corpus.", "labels": [], "entities": [{"text": "UD corpus", "start_pos": 122, "end_pos": 131, "type": "DATASET", "confidence": 0.9248450398445129}]}, {"text": "One of the goals of the UD enterprise is to ensure similar annotations for similar constructions across languages.", "labels": [], "entities": []}, {"text": "While the current state of the general and language specific annotation guidelines suggest that this should be possible for the most common syntactic configurations, it is also true that there still appears to be variation in the way less frequent constructions are annotated.", "labels": [], "entities": []}, {"text": "This is particularly true if such constructions challenge the UD annotation principles.", "labels": [], "entities": []}, {"text": "We illustrate this in section 3 by comparing the analysis in Dutch, German, and English, of verbal nominalizations and clausal arguments of prepositions.", "labels": [], "entities": []}, {"text": "In section 4, we compare the performance of three dependency parsers trained on UD Lassy Small with Alpino), a rule-based grammar that produces output compatible with the original Lassy treebank.", "labels": [], "entities": [{"text": "UD Lassy Small", "start_pos": 80, "end_pos": 94, "type": "DATASET", "confidence": 0.8785703380902609}, {"text": "Lassy treebank", "start_pos": 180, "end_pos": 194, "type": "DATASET", "confidence": 0.7094829678535461}]}, {"text": "The comparison crucially relies on the fact that we can use the conversion script to convert Alpino output to UD.", "labels": [], "entities": []}], "datasetContent": [{"text": "The inclusion of a large number of languages and corpora in the UD corpus has led to a growing number of parsing toolkits that are language independent and that can be trained and evaluated on any of the UD treebanks.", "labels": [], "entities": [{"text": "UD corpus", "start_pos": 64, "end_pos": 73, "type": "DATASET", "confidence": 0.7237234264612198}, {"text": "UD treebanks", "start_pos": 204, "end_pos": 216, "type": "DATASET", "confidence": 0.8541811108589172}]}, {"text": "In this section, we compare state-of-the-art dependency parsers for UD trained on Lassy Small with Alpino, a parser based on a hand-written grammar for Dutch.", "labels": [], "entities": []}, {"text": "introduce SyntaxNet, an open-source implementation of a novel method for dependency parsing based on globally normalized neural networks.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 73, "end_pos": 91, "type": "TASK", "confidence": 0.8498591482639313}]}, {"text": "They also provide a pretrained parser for English, Parsey McParseface.", "labels": [], "entities": [{"text": "Parsey McParseface", "start_pos": 51, "end_pos": 69, "type": "DATASET", "confidence": 0.8795775175094604}]}, {"text": "On the Penn Treebank, the released model for English (Parsey McParseface) recovers dependencies at the word level with over 94% accuracy, beating previous state-of-the-art results.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 7, "end_pos": 20, "type": "DATASET", "confidence": 0.9955142736434937}, {"text": "Parsey McParseface)", "start_pos": 54, "end_pos": 73, "type": "DATASET", "confidence": 0.8401668270428976}, {"text": "accuracy", "start_pos": 128, "end_pos": 136, "type": "METRIC", "confidence": 0.9986166954040527}]}, {"text": "SyntaxNet has been used to train a parser fora large number of corpora in UD (v1.3).", "labels": [], "entities": [{"text": "UD", "start_pos": 74, "end_pos": 76, "type": "DATASET", "confidence": 0.796843409538269}]}, {"text": "'Parsey's Cousins' 8 is a collection of syntactic models trained on UD treebanks, for 40 different languages.", "labels": [], "entities": [{"text": "Parsey's Cousins' 8", "start_pos": 1, "end_pos": 20, "type": "DATASET", "confidence": 0.8750859498977661}]}, {"text": "Per language, more than 70 models have been trained, leading to models that are up to 4% more accurate than models trained without hyperparameter tuning.", "labels": [], "entities": []}, {"text": "The easy-first hierarchical LSTM model of introduces a novel method for applying the LSTM framework to tree structures that is particularly apt for dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 148, "end_pos": 166, "type": "TASK", "confidence": 0.8184345960617065}]}, {"text": "Another notable feature is that it does not use word embeddings.", "labels": [], "entities": []}, {"text": "It achieves stateof-the-art results on dependency parsing for English and Chinese, and can be used to train parsers for any language for which a UD treebank is available.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.7481516301631927}, {"text": "UD treebank", "start_pos": 145, "end_pos": 156, "type": "DATASET", "confidence": 0.7642261683940887}]}, {"text": "'ParseySaurus' () is a collection of models for UD version 2.0 corpora.", "labels": [], "entities": [{"text": "ParseySaurus'", "start_pos": 1, "end_pos": 14, "type": "DATASET", "confidence": 0.9064222574234009}, {"text": "UD version 2.0 corpora", "start_pos": 48, "end_pos": 70, "type": "TASK", "confidence": 0.564710721373558}]}, {"text": "It uses a variant of SyntaxNet that also includes character level embeddings.", "labels": [], "entities": []}, {"text": "The model has a labeled attachment accuracy score that is on average 3.5% better than the SyntexNet models of Parsey's cousins.", "labels": [], "entities": [{"text": "labeled attachment accuracy score", "start_pos": 16, "end_pos": 49, "type": "METRIC", "confidence": 0.6970595046877861}, {"text": "Parsey's cousins", "start_pos": 110, "end_pos": 126, "type": "DATASET", "confidence": 0.8237664500872294}]}, {"text": "Alpino) is a wide-coverage parser for Dutch consisting of a carefully developed hand-written unification-based grammar and  a maximum entropy disambiguation model.", "labels": [], "entities": []}, {"text": "Its output is compatible with the original Lassy treebank.", "labels": [], "entities": [{"text": "Lassy treebank", "start_pos": 43, "end_pos": 57, "type": "DATASET", "confidence": 0.9389307796955109}]}, {"text": "Although Alpino is not a dependency parser, it can be evaluated on UD Dutch data by converting the parser output into UD compatible annotation using the same conversion script that was also used to convert the original Lassy Small treebank to UD.", "labels": [], "entities": [{"text": "UD Dutch data", "start_pos": 67, "end_pos": 80, "type": "DATASET", "confidence": 0.8086344401041666}, {"text": "Lassy Small treebank", "start_pos": 219, "end_pos": 239, "type": "DATASET", "confidence": 0.8201975027720133}]}, {"text": "For the experiment, the disambiguation model for Alpino was trained only on the training section of Lassy Small UD treebank (6641 sentences).", "labels": [], "entities": [{"text": "Lassy Small UD treebank", "start_pos": 100, "end_pos": 123, "type": "DATASET", "confidence": 0.8615043461322784}]}, {"text": "We compare the accuracy of the Dutch SyntaxNet models as well as a model trained with the easy-first LSTM model, with results obtained using Alpino.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9996638298034668}]}, {"text": "gives labeled and unlabeled attachment accuracy scores on the test set of the Lassy Small corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9324998259544373}, {"text": "Lassy Small corpus", "start_pos": 78, "end_pos": 96, "type": "DATASET", "confidence": 0.8199939330418905}]}, {"text": "The scores for Parsey's Cousins are the scores reported in the Google blog post.", "labels": [], "entities": [{"text": "Parsey's Cousins", "start_pos": 15, "end_pos": 31, "type": "DATASET", "confidence": 0.8739951252937317}]}, {"text": "The scores for easy-LSTM were obtained by running the code using the default options.", "labels": [], "entities": []}, {"text": "The scores for ParseySaurus are taken from.", "labels": [], "entities": [{"text": "ParseySaurus", "start_pos": 15, "end_pos": 27, "type": "DATASET", "confidence": 0.9167630076408386}]}, {"text": "Among the dependency parsers trained on the treebank data, the ParseySaurus model achieves a 2.5-3.0% LAS improvement over the two other models.", "labels": [], "entities": [{"text": "ParseySaurus", "start_pos": 63, "end_pos": 75, "type": "DATASET", "confidence": 0.876496434211731}, {"text": "LAS", "start_pos": 102, "end_pos": 105, "type": "METRIC", "confidence": 0.9903402924537659}]}, {"text": "Alpino performs even better, with a 3.8% LAS improvement over the best dependency parser model.", "labels": [], "entities": [{"text": "LAS", "start_pos": 41, "end_pos": 44, "type": "METRIC", "confidence": 0.995073139667511}]}, {"text": "We can only speculate about the reasons for this difference.", "labels": [], "entities": []}, {"text": "The training corpus is relatively small, and it might be that the purely data-driven approaches would benefit relatively strongly from being trained on more data.", "labels": [], "entities": []}, {"text": "On the other hand, results can also be improved by simply correcting errors in the original data.", "labels": [], "entities": []}, {"text": "As we pointed out in section 3, one difference between the original Lassy dependency annotation and UD is that UD dependency labels are organized more strongly in accordance with the   the head and the dependent than the Lassy dependency labels.", "labels": [], "entities": []}, {"text": "The relative independence of Lassy POS annotation and syntactic analysis (as well as the fact that these were done by different partners in the Lassy project), has led to a situation where errors in POS annotation have gone largely unnoticed when evaluating parser output.", "labels": [], "entities": []}, {"text": "For evaluation on UD treebanks, annotating and predicting the correct POS tag is crucial, as it influences the choice of the dependency label.", "labels": [], "entities": [{"text": "UD treebanks", "start_pos": 18, "end_pos": 30, "type": "DATASET", "confidence": 0.7227281033992767}]}, {"text": "Thus, correcting POS tags in the original treebank leads to more consistent data in the original treebank as well as in the converted UD treebank.", "labels": [], "entities": [{"text": "UD treebank", "start_pos": 134, "end_pos": 145, "type": "DATASET", "confidence": 0.9148079454898834}]}, {"text": "If we evaluate the Alpino parser on aversion of the UD treebank based on the corrected underlying Lassy Small treebank, we obtain the accuracy scores given in table 5.", "labels": [], "entities": [{"text": "UD treebank", "start_pos": 52, "end_pos": 63, "type": "DATASET", "confidence": 0.9536817669868469}, {"text": "Lassy Small treebank", "start_pos": 98, "end_pos": 118, "type": "DATASET", "confidence": 0.8650073806444804}, {"text": "accuracy", "start_pos": 134, "end_pos": 142, "type": "METRIC", "confidence": 0.9994551539421082}]}, {"text": "These corrections have been included in UD 2.0 release.", "labels": [], "entities": [{"text": "UD 2.0 release", "start_pos": 40, "end_pos": 54, "type": "DATASET", "confidence": 0.6979127128918966}]}], "tableCaptions": [{"text": " Table 2: Frequency per 100.000 tokens for verbal  heads with nominal properties in three UD tree- banks.", "labels": [], "entities": [{"text": "Frequency", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9933862090110779}]}, {"text": " Table 3: Frequency per 100.000 tokens for verbs  with a case dependent and prepositions governing  a dependent.", "labels": [], "entities": [{"text": "Frequency", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9986177682876587}]}, {"text": " Table 4: Parse results for UD Dutch Lassy Small  (v1.3), using standard training (6641 sentences)  and test set (350 sentences), using CONLL 2007  evaluation script, not counting punctuation.", "labels": [], "entities": [{"text": "Parse", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.8101220726966858}, {"text": "UD Dutch Lassy Small", "start_pos": 28, "end_pos": 48, "type": "DATASET", "confidence": 0.8429093062877655}, {"text": "CONLL 2007  evaluation script", "start_pos": 136, "end_pos": 165, "type": "DATASET", "confidence": 0.9094607532024384}]}, {"text": " Table 5: Parse results for UD Dutch Lassy Small  (v1.3 with corrections), using standard training  (6641 sentences) and test set (350 sentences), us- ing CONLL 2007 evaluation script, not counting  punctuation.", "labels": [], "entities": [{"text": "Parse", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.8466690182685852}, {"text": "UD Dutch Lassy Small", "start_pos": 28, "end_pos": 48, "type": "DATASET", "confidence": 0.8426363170146942}, {"text": "CONLL 2007 evaluation script", "start_pos": 155, "end_pos": 183, "type": "DATASET", "confidence": 0.9206670224666595}]}]}