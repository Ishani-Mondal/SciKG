{"title": [], "abstractContent": [{"text": "A generation system can only be as good as the data it is trained on.", "labels": [], "entities": []}, {"text": "In this short paper , we propose a methodology for analysing data-to-text corpora used for training micro-planner i.e., systems which given some input must produce a text verbalising exactly this input.", "labels": [], "entities": []}, {"text": "We apply this methodology to three existing benchmarks and we elicite a set of criteria for the creation of a data-to-text benchmark which could help better support the development , evaluation and comparison of linguistically sophisticated data-to-text generators.", "labels": [], "entities": []}], "introductionContent": [{"text": "In some scenarios, generation datasets provide linguistic descriptions of a specific domain and application (e.g. ().", "labels": [], "entities": []}, {"text": "However, in other scenarios generation datasets aim at broader syntactic (e.g. the surface realisation shared-task) or domain () coverage.", "labels": [], "entities": []}, {"text": "Recently, several datasets have been created to train data-to-text generators.", "labels": [], "entities": []}, {"text": "It is unclear however to what extent the generation task exercised by these datasets is linguistically challenging.", "labels": [], "entities": []}, {"text": "Do these datasets provide enough variety to support the development of high-quality data-to-text generators ? In this paper, we propose a methodology for characterising the variety and complexity of these datasets.", "labels": [], "entities": []}, {"text": "We exemplify its use by applying it to three existing training corpora for NLG and we conclude by eliciting a set of criteria for the creation of data-to-text benchmarks which could better support the development, evaluation and comparison of linguistically sophisticated data-to-text generators.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Datasets descriptive statistics.  \u2021 Note that we consider as distinct entities those given by the name  relations and that in the RNNLG datasets not all dialogue acts describe entities (e.g. inform count or ?select).", "labels": [], "entities": [{"text": "RNNLG datasets", "start_pos": 140, "end_pos": 154, "type": "DATASET", "confidence": 0.9842769801616669}]}, {"text": " Table 3: Lexical Sophistication (LS) and Mean  Segmental Type-Token Ratio (MSTTR).", "labels": [], "entities": [{"text": "Mean  Segmental Type-Token Ratio (MSTTR)", "start_pos": 42, "end_pos": 82, "type": "METRIC", "confidence": 0.9187581368855068}]}]}