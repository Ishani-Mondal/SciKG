{"title": [{"text": "A Multi-strategy Query Processing Approach for Biomedical Question Answering: USTB PRIR at BioASQ 2017 Task 5B", "labels": [], "entities": [{"text": "Biomedical Question Answering", "start_pos": 47, "end_pos": 76, "type": "TASK", "confidence": 0.6614896059036255}, {"text": "USTB PRIR at BioASQ 2017 Task 5B", "start_pos": 78, "end_pos": 110, "type": "DATASET", "confidence": 0.6925116564546313}]}], "abstractContent": [{"text": "This paper describes the participation of USTB PRIR team in the 2017 BioASQ 5B on question answering, including document retrieval, snippet retrieval and concept retrieval task.", "labels": [], "entities": [{"text": "USTB PRIR team", "start_pos": 42, "end_pos": 56, "type": "DATASET", "confidence": 0.7661329905192057}, {"text": "BioASQ 5B", "start_pos": 69, "end_pos": 78, "type": "DATASET", "confidence": 0.6963675320148468}, {"text": "question answering", "start_pos": 82, "end_pos": 100, "type": "TASK", "confidence": 0.8343622088432312}, {"text": "document retrieval", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.7630844712257385}, {"text": "snippet retrieval", "start_pos": 132, "end_pos": 149, "type": "TASK", "confidence": 0.7986484467983246}, {"text": "concept retrieval task", "start_pos": 154, "end_pos": 176, "type": "TASK", "confidence": 0.8443308075269064}]}, {"text": "We introduce different multimodal query processing strategies to enrich query terms and assign different weights to them.", "labels": [], "entities": []}, {"text": "Specifically, sequential dependence model (SDM), pseudo relevance feedback (PRF), fielded sequential dependence model (FSDM) and Divergence from Randomness model (D-FRM) are respectively performed on different fields of PubMed articles, sentences extracted from relevant articles, the five terminologies or ontologies (MeSH, GO, Jochem, Uniprot and DO) to achieve better search performances.", "labels": [], "entities": [{"text": "fielded sequential dependence model (FSDM)", "start_pos": 82, "end_pos": 124, "type": "METRIC", "confidence": 0.5806756573063987}]}, {"text": "Preliminary results show that our systems outperform others in the document and snippet retrieval task in the first two batches.", "labels": [], "entities": [{"text": "document and snippet retrieval task", "start_pos": 67, "end_pos": 102, "type": "TASK", "confidence": 0.6332124650478363}]}], "introductionContent": [{"text": "Due to the continuous growth of information produced in the biomedical domain, there is a particularly growing demand for biomedical QA from the general public, medical students, healthcare professionals and biomedical researchers).", "labels": [], "entities": []}, {"text": "They consult knowledge about the natures, the preventions or the treatments of diseases, or learn from research results of other researchers.", "labels": [], "entities": []}, {"text": "To some extent, biomedical QA is one of the most significant applications of the existing real-world biomedical systems.", "labels": [], "entities": [{"text": "biomedical QA", "start_pos": 16, "end_pos": 29, "type": "TASK", "confidence": 0.836257129907608}]}, {"text": "Since 2013, BioASQ organizers has proposed a community-based shared task which aims to evaluate the current solutions of a variety of QA subtasks.", "labels": [], "entities": []}, {"text": "Several benchmarks have been provided for researchers to evaluate their QA systems.", "labels": [], "entities": []}, {"text": "Task 5B challenge () is the fifth edition of the question answering task, of which the phase A requires the evaluated system to (i) semantically annotate the questions with concepts from a set of designated terminologies and ontologies (MeSH, GO, Jochem, Uniprot and DO); and (ii) retrieve relevant articles, text snippets, and RDF triples from designated article repositories and ontologies (PubMed/MEDLINE articles) with biomedical questions in natural language provided by biomedical professionals or researchers.", "labels": [], "entities": [{"text": "question answering task", "start_pos": 49, "end_pos": 72, "type": "TASK", "confidence": 0.8311554193496704}]}, {"text": "The ground truth are manually annotated by these experts with some annotated tools.", "labels": [], "entities": []}, {"text": "There are five batches of evaluation and in each batch participants are provided with 100 natural language questions and required to return at most 10 relevant documents, snippets, concepts to the questions within 24 hours.", "labels": [], "entities": []}, {"text": "Over the past decade, a variety of approaches have been proposed for biomedical question answering (.", "labels": [], "entities": [{"text": "biomedical question answering", "start_pos": 69, "end_pos": 98, "type": "TASK", "confidence": 0.6959986090660095}]}, {"text": "Generally, a QA system typically consists of question processing, document processing, and answer processing phases, which are respectively in charge of 1) converting natural language questions into queries, 2) searching relevant documents, and 3) extracting, ranking candidate answers and formatting them into expected answer type.).", "labels": [], "entities": [{"text": "question processing", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.7609591782093048}, {"text": "document processing", "start_pos": 66, "end_pos": 85, "type": "TASK", "confidence": 0.6774672120809555}, {"text": "answer processing", "start_pos": 91, "end_pos": 108, "type": "TASK", "confidence": 0.7073278576135635}]}, {"text": "There are several studies concerning the improvements on query processing phase () and document processing phase.", "labels": [], "entities": [{"text": "query processing phase", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.8183307647705078}, {"text": "document processing", "start_pos": 87, "end_pos": 106, "type": "TASK", "confidence": 0.7191319167613983}]}, {"text": "However for answer processing phase, especially answer matching and ranking, only some simple approaches in previous BioASQ challenge have been proposed.", "labels": [], "entities": [{"text": "answer processing", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.9407413005828857}, {"text": "answer matching", "start_pos": 48, "end_pos": 63, "type": "TASK", "confidence": 0.9193264842033386}]}, {"text": "According to the above researches, the most challenges of biomedical QA are three main issues, specifically 1) how to generate query terms appropriately from natural language questions, 2) how to match relevant documents or sentences when they use different expressions (maybe synonyms of keywords) and 3) how to measure and utilize the difference in importance of query terms.", "labels": [], "entities": [{"text": "biomedical QA", "start_pos": 58, "end_pos": 71, "type": "TASK", "confidence": 0.5490492731332779}]}, {"text": "In order to address these challenges, in this paper we propose a multi-strategy query processing approach which combines several mature query processing models according to the different characteristics of data sources, which is also actually the participation of our USTB PRIR team in the BioASQ Task 5B phase A challenge 1 . Specifically, in order to extract proper keywords and generate queries, we perform stop-words removal, noun extraction with Pos-of-Tagger (POS) and stemming.", "labels": [], "entities": [{"text": "USTB PRIR", "start_pos": 268, "end_pos": 277, "type": "DATASET", "confidence": 0.907145768404007}, {"text": "BioASQ Task 5B phase A challenge", "start_pos": 290, "end_pos": 322, "type": "DATASET", "confidence": 0.6262242545684179}, {"text": "noun extraction", "start_pos": 430, "end_pos": 445, "type": "TASK", "confidence": 0.8530212640762329}]}, {"text": "For the missing issue caused by expressions, we utilize a thesaurus which is produced through computing the similarities between the vector representations of each pairs of words.", "labels": [], "entities": []}, {"text": "Moreover for query keyword weighting, we take the word sequences, different fields of appearance, TF-IDF, etc into consideration for different BioASQ tasks.", "labels": [], "entities": [{"text": "query keyword weighting", "start_pos": 13, "end_pos": 36, "type": "TASK", "confidence": 0.780321478843689}, {"text": "TF-IDF", "start_pos": 98, "end_pos": 104, "type": "METRIC", "confidence": 0.7991068363189697}]}, {"text": "We evaluate our approach on the BioASQ 2016 and 2017 benchmarks for document, snippet, concept retrieval and experimental results demonstrate our method outperforms the baseline methods or other participants so far on document, snippet and concept retrieval tasks.", "labels": [], "entities": [{"text": "BioASQ 2016 and 2017 benchmarks", "start_pos": 32, "end_pos": 63, "type": "DATASET", "confidence": 0.9233893156051636}, {"text": "concept retrieval", "start_pos": 87, "end_pos": 104, "type": "TASK", "confidence": 0.6721394956111908}, {"text": "document, snippet and concept retrieval tasks", "start_pos": 218, "end_pos": 263, "type": "TASK", "confidence": 0.6934398497853961}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: MAP performances compared with  BioASQ Task 5B document retrieval participants.", "labels": [], "entities": [{"text": "MAP", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.8593814373016357}, {"text": "BioASQ Task 5B document retrieval", "start_pos": 42, "end_pos": 75, "type": "TASK", "confidence": 0.7167021930217743}]}, {"text": " Table 1: MAP performances of system components on BioASQ Task 4B document retrieval.", "labels": [], "entities": [{"text": "MAP", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.7634357810020447}, {"text": "BioASQ Task 4B document retrieval", "start_pos": 51, "end_pos": 84, "type": "TASK", "confidence": 0.73532555103302}]}, {"text": " Table 3: Basic DFR Models.", "labels": [], "entities": []}, {"text": " Table 4: MAP performances of system compo- nents on BioASQ Task 4B snippet retrieval.", "labels": [], "entities": [{"text": "MAP", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.6511725783348083}, {"text": "BioASQ Task 4B snippet retrieval", "start_pos": 53, "end_pos": 85, "type": "TASK", "confidence": 0.6906000137329101}]}, {"text": " Table 5: MAP performances compared with  BioASQ Task 5B snippet retrieval participants.", "labels": [], "entities": [{"text": "MAP", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.8258979320526123}, {"text": "BioASQ Task 5B snippet retrieval", "start_pos": 42, "end_pos": 74, "type": "TASK", "confidence": 0.5924062848091125}]}, {"text": " Table 6: MAP performances of system compo- nents on BioASQ Task 4B concept retrieval.", "labels": [], "entities": [{"text": "MAP", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.709778368473053}, {"text": "BioASQ Task 4B concept retrieval", "start_pos": 53, "end_pos": 85, "type": "TASK", "confidence": 0.6788653671741486}]}]}