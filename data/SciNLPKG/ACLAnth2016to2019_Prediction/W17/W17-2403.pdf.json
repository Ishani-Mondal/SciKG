{"title": [{"text": "Merging knowledge bases in different languages", "labels": [], "entities": []}], "abstractContent": [{"text": "Recently, different systems which learn to populate and extend a knowledge base (KB) from the web in different languages have been presented.", "labels": [], "entities": []}, {"text": "Although a large set of concepts should be learnt independently from the language used to read, there are facts which are expected to be more easily gathered in local language (e.g., culture or geography).", "labels": [], "entities": []}, {"text": "A system that merges KBs learnt in different languages will benefit from the complementary information as long as common beliefs are identified, as well as from redundancy present in web pages written in different languages.", "labels": [], "entities": []}, {"text": "In this paper, we deal with the problem of identifying equivalent beliefs (or concepts) across language specific KBs, assuming that they share the same ontol-ogy of categories and relations.", "labels": [], "entities": []}, {"text": "Ina case study with two KBs independently learnt from different inputs, namely web pages written in English and web pages written in Portuguese respectively, we report on the results of two methodologies: an approach based on personalized PageR-ank and an inference technique to find out common relevant paths through the KBs.", "labels": [], "entities": []}, {"text": "The proposed inference technique efficiently identifies relevant paths, outper-forming the baseline (a dictionary-based classifier) in the vast majority of tested categories .", "labels": [], "entities": []}], "introductionContent": [{"text": "In the last few decades, the machine learning community has launched different research projects to take advantage of the massive source of information which has become the web, and of the people who build it up.", "labels": [], "entities": []}, {"text": "Among others, information extraction systems (IES) which use the text found in webpages to extract, validate and incorporate beliefs to a structured knowledge base have been developed (e.g.,), NELL ( or Knowledge Vault ().", "labels": [], "entities": [{"text": "information extraction", "start_pos": 14, "end_pos": 36, "type": "TASK", "confidence": 0.7443232834339142}]}, {"text": "Such knowledge bases (KBs) store facts about the real world, which are represented as entities and relationship among entities.", "labels": [], "entities": []}, {"text": "The reliability of a fact, inferred from the web, is at first questionable due to the noisy information available on the Web.", "labels": [], "entities": [{"text": "reliability", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9970347881317139}]}, {"text": "This difficulty is usually overcome by relying on data redundancy from multiple Web pages.", "labels": [], "entities": []}, {"text": "Requiring higher degrees of redundancy to incorporate beliefs to the KB help to improve the quality of the learnt KB.", "labels": [], "entities": []}, {"text": "In the long run, having two such IES, running independently, tend to generate equivalent KBs, even if they gather information from different webpages, in different time or using different terminology.", "labels": [], "entities": []}, {"text": "However, if those two systems extract (and store) facts from Web pages written in different languages, it can be hard to automatically identify redundant facts, or to automatically merge such KBs.", "labels": [], "entities": []}, {"text": "Let us assume an English KB containing the concept of the city of Sao Carlos as a belief and, also, a Portuguese KB with the equivalent concept represented in Portuguese as S\u00e3o Carlos.", "labels": [], "entities": []}, {"text": "Let us assume also that, in the Portuguese KB, S\u00e3o Carlos is linked to the concept Paulo Altomani, the major of the city.", "labels": [], "entities": [{"text": "Portuguese KB", "start_pos": 32, "end_pos": 45, "type": "DATASET", "confidence": 0.9002929627895355}]}, {"text": "Combining both KBs and identifying the equivalence between Sao Carlos (en) and S\u00e3o Carlos (pt) can help to automatically populate the English KB adding the fact that Paulo Altomani is the mayor of Sao Carlos (en).", "labels": [], "entities": []}, {"text": "In this paper we deal with the problem of merging KBs learnt in different languages.", "labels": [], "entities": [{"text": "merging KBs learnt", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.8230473200480143}]}, {"text": "This task consists of ontology alignment and equivalent concept matching.", "labels": [], "entities": [{"text": "ontology alignment", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.8139099478721619}, {"text": "equivalent concept matching", "start_pos": 45, "end_pos": 72, "type": "TASK", "confidence": 0.6942774057388306}]}, {"text": "We use graph-based inference techniques to deal with the problem of identifying equivalent entities in different KBs assuming that, in spite of being learnt independently, they share a common ontology.", "labels": [], "entities": []}, {"text": "The contributions of this work are as follows: \u2022 An approach to multi-lingual KB merging based on Personalized PageRank \u2022 A path-based graph inference approach that shows promising results when compared to Personalized PageRank.", "labels": [], "entities": [{"text": "KB merging", "start_pos": 78, "end_pos": 88, "type": "TASK", "confidence": 0.8245170712471008}]}, {"text": "\u2022 An empirical analysis by means of a case study.", "labels": [], "entities": []}, {"text": "When graph connectivity is enhanced by means of a SVO corpus, results standout.", "labels": [], "entities": [{"text": "SVO corpus", "start_pos": 50, "end_pos": 60, "type": "DATASET", "confidence": 0.8102355301380157}]}, {"text": "In the remainder of this paper we first provide a formal description of the problem, which is formulated as an inference problem.", "labels": [], "entities": []}, {"text": "Then, the proposed solutions are presented.", "labels": [], "entities": []}, {"text": "In Section 4, the different approaches are tested in a case study with two KBs independently learnt by NELL () from English and Portuguese webpages respectively.", "labels": [], "entities": [{"text": "NELL", "start_pos": 103, "end_pos": 107, "type": "METRIC", "confidence": 0.6709098219871521}]}, {"text": "Next, their behavior is discussed.", "labels": [], "entities": []}, {"text": "The paper finishes with conclusions and ideas for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "A complete set of experiments has been designed to test the performance of both approaches in the task of identifying equivalent concepts across languages.", "labels": [], "entities": []}, {"text": "A baseline based on dictionary translations is used to put these results in context.", "labels": [], "entities": []}, {"text": "In addition to both described techniques, a classifier exclusively based on a dictionary is also considered.", "labels": [], "entities": []}, {"text": "It predicts an equivalence if the nodes of the query pair represent entities with literal strings which are the translation of each other.", "labels": [], "entities": []}, {"text": "Given that a dictionary is probably the simplest solution to deal with this problem, it has been used in this paper as a baseline.", "labels": [], "entities": []}, {"text": "The PPR method has been configured for these experiments with 2,000 random walks of length 5 to estimate the probability distribution, using a probability of restart equal to 0.01.", "labels": [], "entities": [{"text": "restart", "start_pos": 158, "end_pos": 165, "type": "METRIC", "confidence": 0.9605751633644104}]}, {"text": "Regarding our PRA-based technique, the breadth-first search is carried out to a depth of 2.", "labels": [], "entities": [{"text": "PRA-based", "start_pos": 14, "end_pos": 23, "type": "TASK", "confidence": 0.868841826915741}, {"text": "breadth-first", "start_pos": 39, "end_pos": 52, "type": "METRIC", "confidence": 0.993374764919281}]}, {"text": "These values have been selected within a 20\u00d75-fold cross validation.", "labels": [], "entities": []}, {"text": "PPR and the baseline do not need a training step and the results are calculated over the whole training set.", "labels": [], "entities": [{"text": "PPR", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7613275051116943}]}, {"text": "For each category, PRA learns a logistic regression classifier (its implementation in), which is evaluated in a 10 \u00d7 5-fold cross validation.", "labels": [], "entities": [{"text": "PRA", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.9211569428443909}]}, {"text": "Remember that positive pairs are equivalentTo relationships, which are also represented in the graph.", "labels": [], "entities": []}, {"text": "The edges of the graph corresponding to training examples are removed for training and testing.", "labels": [], "entities": []}, {"text": "The PPR and PRA-based approaches, together with the baseline, have been applied over graphs 1 and 2 (without and with SVO-inferred relationships, respectively).", "labels": [], "entities": []}, {"text": "As our PRA-based approach learns a classifier per category, a diverse set of eight categories has been selected to test the proposals and report their performance: animal, country, city, movie, person, writer, actor and sport.", "labels": [], "entities": [{"text": "PRA-based", "start_pos": 7, "end_pos": 16, "type": "TASK", "confidence": 0.9569824934005737}]}, {"text": "In, precision-recall (PR) curves are used to describe the results in the first graph.", "labels": [], "entities": [{"text": "precision-recall (PR)", "start_pos": 4, "end_pos": 25, "type": "METRIC", "confidence": 0.9565130174160004}]}, {"text": "Each subfigure displays the results for one of the selected categories.", "labels": [], "entities": []}, {"text": "Following the same layout, shows the results in the second graph.", "labels": [], "entities": []}, {"text": "Note that results in figures 2 and 3 are not directly comparable as they have been obtained from training sets of different sizes (see in the number of positive entities remaining after pruning in graphs 1 and 2).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: For each language and category, mean  out-degree value and associated standard deviation  of the nodes of that category in the (first) graph,  without isolated nodes, and in the (second) graph,  fed with SVO-inferred relationships before prun- ing. The last row sums up all the categories.", "labels": [], "entities": []}]}