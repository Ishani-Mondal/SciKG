{"title": [{"text": "A Dataset for Sanskrit Word Segmentation", "labels": [], "entities": [{"text": "Sanskrit Word Segmentation", "start_pos": 14, "end_pos": 40, "type": "TASK", "confidence": 0.7045412758986155}]}], "abstractContent": [{"text": "The last decade saw a surge in digitisation efforts for ancient manuscripts in Sanskrit.", "labels": [], "entities": []}, {"text": "Due to various linguistic peculiarities inherent to the language, even the preliminary tasks such as word segmentation are non-trivial in Sanskrit.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 101, "end_pos": 118, "type": "TASK", "confidence": 0.713686466217041}]}, {"text": "Elegant models for Word Segmentation in Sanskrit are indispensable for further syntactic and semantic processing of the manuscripts.", "labels": [], "entities": [{"text": "Word Segmentation", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.7619382739067078}]}, {"text": "Current works in word segmentation for Sanskrit, though commendable in their novelty, often have variations in their objective and evaluation criteria.", "labels": [], "entities": [{"text": "word segmentation for Sanskrit", "start_pos": 17, "end_pos": 47, "type": "TASK", "confidence": 0.7972618117928505}]}, {"text": "In this work, we set the record straight.", "labels": [], "entities": []}, {"text": "We formally define the objectives and the requirements for the word segmentation task.", "labels": [], "entities": [{"text": "word segmentation task", "start_pos": 63, "end_pos": 85, "type": "TASK", "confidence": 0.8065717021624247}]}, {"text": "In order to encourage research in the field and to alleviate the time and effort required in pre-processing, we release a dataset of 115,000 sentences for word segmentation.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 155, "end_pos": 172, "type": "TASK", "confidence": 0.733635425567627}]}, {"text": "For each sentence in the dataset we include the input character sequence, ground truth segmentation, and additionally lexical and morphological information about all the phonetically possible segments for the given sentence.", "labels": [], "entities": [{"text": "ground truth segmentation", "start_pos": 74, "end_pos": 99, "type": "TASK", "confidence": 0.686525563398997}]}, {"text": "In this work, we also discuss the linguistic considerations made while generating the candidate space of the possible segments.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sanskrit was the prevalent medium of knowledge transfer in the demographic of Indian Subcontinent for over four millennia.", "labels": [], "entities": [{"text": "knowledge transfer", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.7451906800270081}]}, {"text": "The culture bearing language of India has about 30 million extant manuscripts that are potent for digitisation ().", "labels": [], "entities": []}, {"text": "The last decade witnessed tremendous excitement in digitisation attempts of ancient manuscripts in Sanskrit.", "labels": [], "entities": []}, {"text": "The Digital Corpus of Sanskrit 1 , The Sanskrit Library 2 and GRETIL 3 are some such laudable efforts.", "labels": [], "entities": [{"text": "Digital Corpus of Sanskrit 1", "start_pos": 4, "end_pos": 32, "type": "DATASET", "confidence": 0.9294314861297608}, {"text": "The Sanskrit Library 2", "start_pos": 35, "end_pos": 57, "type": "DATASET", "confidence": 0.9327313303947449}, {"text": "GRETIL", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.9332878589630127}]}, {"text": "These attempts aim to preserve the cultural heritage of the subcontinent embedded in the works written in Sanskrit.", "labels": [], "entities": []}, {"text": "The writings in Sanskrit follow a 'scriptio continua', thereby making Word Segmentation in Sanskrit a challenging task.", "labels": [], "entities": [{"text": "Word Segmentation in Sanskrit", "start_pos": 70, "end_pos": 99, "type": "TASK", "confidence": 0.8202834725379944}]}, {"text": "Lack of visible markers in written scripts is a prevalent feature observed in numerous Asian languages.", "labels": [], "entities": []}, {"text": "Additionally, the sentence constructs in Sanskrit show a high degree of inflection (), phonemes at the word boundary undergo phonetic transformations called as 'sandhi', and the sentence constructs in Sanskrit follow a loose word order.", "labels": [], "entities": []}, {"text": "The combination of the aforementioned properties makes the segmentation in Sanskrit a complex task.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 59, "end_pos": 71, "type": "TASK", "confidence": 0.955050528049469}]}, {"text": "Given an input Sanskrit sentence, the word segmentation task can be defined as identification of the semantically most valid split of the input sentence.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.7061653435230255}]}, {"text": "There have been commendable efforts to tackle the word segmentation task in Sanskrit.", "labels": [], "entities": [{"text": "word segmentation task", "start_pos": 50, "end_pos": 72, "type": "TASK", "confidence": 0.7926659683386484}]}, {"text": "designed Finite State Transducers (FST) incorporating the rules of sandhi obtained from documented grammatical tradition.", "labels": [], "entities": []}, {"text": "With the defined FSTs, generates all possible splits followed by a probabilistic scoring procedure to select the ideal split.", "labels": [], "entities": [{"text": "FSTs", "start_pos": 17, "end_pos": 21, "type": "DATASET", "confidence": 0.6864036917686462}]}, {"text": "proposed 'S3 -Statistical Sandhi Splitter', a Bayesian word segmentation approach for Sanskrit.", "labels": [], "entities": [{"text": "S3 -Statistical Sandhi Splitter", "start_pos": 10, "end_pos": 41, "type": "TASK", "confidence": 0.537796413898468}, {"text": "word segmentation", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.7418743371963501}]}, {"text": "The work is an extension of and was adapted to handle sandhi formations.", "labels": [], "entities": []}, {"text": "proposed a neural model that jointly solves the problem of: Example instances of sandhi formation in Sanskrit.", "labels": [], "entities": [{"text": "sandhi formation", "start_pos": 81, "end_pos": 97, "type": "TASK", "confidence": 0.704330787062645}]}, {"text": "a) Phonetic transformation of 'u' and '\u00af a' to 'v\u00af a' in the joint form.", "labels": [], "entities": [{"text": "Phonetic transformation", "start_pos": 3, "end_pos": 26, "type": "TASK", "confidence": 0.7607485353946686}]}, {"text": "b) '\u00af a' and '\u00af a' at the word boundaries of vidy\u00af a and \u00af apyate join together to form a single '\u00af a' in the final form.", "labels": [], "entities": []}, {"text": "Both the split words have an overlap at the juncture (.", "labels": [], "entities": []}, {"text": "c) and d) Two possible analyses for the sandhied chunk 'kurvann\u00af apnoti' (, where c) is the negation of d).", "labels": [], "entities": []}, {"text": "compound splitting and sandhi resolution.", "labels": [], "entities": [{"text": "compound splitting", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7700601816177368}, {"text": "sandhi resolution", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.8655720949172974}]}, {"text": "handled the word segmentation problem as an iterative query expansion task.", "labels": [], "entities": [{"text": "word segmentation problem", "start_pos": 12, "end_pos": 37, "type": "TASK", "confidence": 0.7963838080565134}]}, {"text": "The authors used Path Constrained Random Walks (PCRW) () for identifying word segments that are likely to co-occur in the given sentence.", "labels": [], "entities": []}, {"text": "This work considers compound splitting as part of the word segmentation task itself.", "labels": [], "entities": [{"text": "compound splitting", "start_pos": 20, "end_pos": 38, "type": "TASK", "confidence": 0.8045447170734406}, {"text": "word segmentation task", "start_pos": 54, "end_pos": 76, "type": "TASK", "confidence": 0.7930369079113007}]}, {"text": "As the task of Sanskrit word segmentation is gaining traction, it also calls for uniformity and easiness in comparing the competing models.", "labels": [], "entities": [{"text": "Sanskrit word segmentation", "start_pos": 15, "end_pos": 41, "type": "TASK", "confidence": 0.6304479440053304}]}, {"text": "For instance, the aforementioned approaches vary in their defined objectives and are evaluated under different settings, making a direct comparison of the models difficult.", "labels": [], "entities": []}, {"text": "For example,; do not discuss the effect of compounds and compound splitting on the dataset.", "labels": [], "entities": [{"text": "compound splitting", "start_pos": 57, "end_pos": 75, "type": "TASK", "confidence": 0.7402789294719696}]}, {"text": "presents the same as a separate task from that of word segmentation, while do not make an explicit difference between both the tasks.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 50, "end_pos": 67, "type": "TASK", "confidence": 0.7252418696880341}]}, {"text": "report an F-Score of 90.61 % when tested on a curated dataset of 2148 sentences, compared to competing models with an F-Score of 70.07% (Natarajan and Charniak, 2011) and 66.26 %.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9996092915534973}, {"text": "F-Score", "start_pos": 118, "end_pos": 125, "type": "METRIC", "confidence": 0.9985243678092957}]}, {"text": "But, report an F-Score of 77.72 %, when the authors tested their method on a larger dataset of about 10,000 sentences obtained from a digitised corpus.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 15, "end_pos": 22, "type": "METRIC", "confidence": 0.9997132420539856}]}, {"text": "Additionally, The aforementioned systems focus primarily on the correctness of the wordform predicted.", "labels": [], "entities": []}, {"text": "Sanskrit is an agglutinative language and the same inflection of a lemma can signify multiple possible morphological classes.", "labels": [], "entities": []}, {"text": "Therefore, correctness of the morphological class is also important, when the segmentation is performed.", "labels": [], "entities": [{"text": "correctness", "start_pos": 11, "end_pos": 22, "type": "METRIC", "confidence": 0.9569152593612671}]}, {"text": "Though report the performance of their system when considering the correctness of lemma and morphological class prediction, they primarily focus on the word-from prediction task.", "labels": [], "entities": [{"text": "morphological class prediction", "start_pos": 92, "end_pos": 122, "type": "TASK", "confidence": 0.7296193440755209}, {"text": "word-from prediction task", "start_pos": 152, "end_pos": 177, "type": "TASK", "confidence": 0.7815472086270651}]}, {"text": "In perspective of the current scenario of this field, our contributions in this work are two fold: 1.", "labels": [], "entities": []}, {"text": "We formally define the objective for word segmentation task in Sanskrit.", "labels": [], "entities": [{"text": "word segmentation task", "start_pos": 37, "end_pos": 59, "type": "TASK", "confidence": 0.8132775028546652}]}, {"text": "We see word segmentation not as an end but as a means to facilitate further processing of text in Sanskrit.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 7, "end_pos": 24, "type": "TASK", "confidence": 0.7153836190700531}]}, {"text": "We define our requirements with an end-goal of making the current digitised content accessible to an end-user when seen from the perspective of an Information Retrieval system.", "labels": [], "entities": []}, {"text": "To achieve this, the segmentation task should output the information that is valuable for the subsequent syntactic and semantic tasks such as POS Tagging, dependency parsing, sentence summarisation, etc.", "labels": [], "entities": [{"text": "POS Tagging", "start_pos": 142, "end_pos": 153, "type": "TASK", "confidence": 0.8180798888206482}, {"text": "dependency parsing", "start_pos": 155, "end_pos": 173, "type": "TASK", "confidence": 0.8249809145927429}, {"text": "sentence summarisation", "start_pos": 175, "end_pos": 197, "type": "TASK", "confidence": 0.7014411985874176}]}, {"text": "The distinction for the correctness of lemma and morphological class, and not just the correctness of the final word-from, is of utmost importance for this.", "labels": [], "entities": []}, {"text": "2. We release 4 a dataset of 115,000 sentences which can be used for further research in word segmentation task in the Sanskrit.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 89, "end_pos": 106, "type": "TASK", "confidence": 0.7482505440711975}]}, {"text": "With this dataset we aim to alleviate the effort and time that often needs to be spent in prepossessing data.", "labels": [], "entities": []}, {"text": "The pre-processing efforts often require the use of multiple sub-systems, and this can lead to inconsistencies with the assumptions made by each of the subsystems involved.", "labels": [], "entities": []}, {"text": "In Section 2, we discuss in detail about the challenges that need to be tackled in word segmentation in Sanskrit.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 83, "end_pos": 100, "type": "TASK", "confidence": 0.7345827519893646}]}, {"text": "Section 3 discusses the preliminaries followed by the formal definition of word segmentation task.", "labels": [], "entities": [{"text": "word segmentation task", "start_pos": 75, "end_pos": 97, "type": "TASK", "confidence": 0.7900106807549795}]}, {"text": "Section 4 details the structure of the dataset we use.", "labels": [], "entities": []}, {"text": "In Section 5, we explain various linguistic considerations that we have made, while preparing the dataset.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to alleviate the time and effort that is often required to spend for preprocessing of Sanskrit data, we release a dataset of 115,000 Sanskrit sentences with all the candidate segments as mentioned in Section 3.", "labels": [], "entities": []}, {"text": "Since the sentence constructs in Sanskrit follow a free word order, the proximity between two words cannot be used as an indicator for semantic and syntactic compatibility between both the words.", "labels": [], "entities": []}, {"text": "So, we assume that all the words that co-occur in a sentence, are equally prone to influence one another.", "labels": [], "entities": []}, {"text": "In order to reflect this in our dataset, we assume our candidate segment representation as a Graph G(V, E).", "labels": [], "entities": []}, {"text": "For the graph G, anode v \u2208 V is a unique segment z j , \u03c3 j , k j . There exists an edge e \u2208 E between every pair of vertices vi , v j \u2208 V , provided vi , v j are not 'conflicting' with each other.", "labels": [], "entities": []}, {"text": "Two nodes are 'conflicting' if they have an overlap in the position relative to the sentence and the overlapped portion does not adhere to any of the rules that follow sandhi.", "labels": [], "entities": []}, {"text": "Given a sentence in s with n words, the sentence will have t breaks (spaces) between the characters such that t < n.", "labels": [], "entities": []}, {"text": "If t = n\u22121, all the words are segmented.", "labels": [], "entities": []}, {"text": "Otherwise, there are at least two words which are joined together and will be in the sandhied form.", "labels": [], "entities": []}, {"text": "We call such fused forms as chunks in our dataset.", "labels": [], "entities": []}, {"text": "For example in, there are four chunks.", "labels": [], "entities": []}, {"text": "Every node is a possible candidate in the segmentation task.", "labels": [], "entities": [{"text": "segmentation task", "start_pos": 42, "end_pos": 59, "type": "TASK", "confidence": 0.924042135477066}]}, {"text": "Two nodes are said to be conflicting, if they cannot co-occur in the given sentence, i.e, if two nodes share a character position with respect to the input, and the shared portion does not result in a proper sandhi transformation then the nodes are said to be conflicting.", "labels": [], "entities": []}, {"text": "In, the words '\u00af ajayah . ' and 'jayah . ' share a common portion of the input and hence if one of them exists in the sentence, the other needs to be eliminated.", "labels": [], "entities": []}, {"text": "Formally, consider two nodes, represented as (k, z) and (k , z ) in a given chunk.", "labels": [], "entities": []}, {"text": "Here k and k are the starting position (offsets) of these nodes relative to the chunk, let |z| and |z | be the length of the words which nodes represent.", "labels": [], "entities": []}, {"text": "We say that (k, z) and.", "labels": [], "entities": []}, {"text": "If two nodes are not conflicting, then there is a possibility that the two may co-occur in the sentence and hence one can become the context in resolving the other.", "labels": [], "entities": []}, {"text": "Hence we add the edge to all such possible nodes.", "labels": [], "entities": []}], "tableCaptions": []}