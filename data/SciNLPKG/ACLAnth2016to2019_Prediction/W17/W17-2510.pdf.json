{"title": [{"text": "zNLP: Identifying Parallel Sentences in Chinese-English Comparable Corpora", "labels": [], "entities": [{"text": "zNLP", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8674065470695496}, {"text": "Identifying Parallel Sentences in Chinese-English Comparable Corpora", "start_pos": 6, "end_pos": 74, "type": "TASK", "confidence": 0.7637503828321185}]}], "abstractContent": [{"text": "This paper describes the zNLP system for the BUCC 2017 shared task.", "labels": [], "entities": [{"text": "BUCC 2017 shared task", "start_pos": 45, "end_pos": 66, "type": "DATASET", "confidence": 0.8735539317131042}]}, {"text": "Our system identifies parallel sentence pairs in Chinese-English comparable corpora by translating word-byword Chinese sentences into English, using the search engine Solr to select near-parallel sentences and then by using an SVM classifier to identify true parallel sentences from the previous results.", "labels": [], "entities": []}, {"text": "It obtains an F1-score of 45% (resp. 43%) on the test (training) set.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.999705970287323}]}], "introductionContent": [{"text": "Parallel sentences are used in many natural language processing applications, particularly for automatic terminology extraction () and statistical machine translation).", "labels": [], "entities": [{"text": "terminology extraction", "start_pos": 105, "end_pos": 127, "type": "TASK", "confidence": 0.7507907152175903}, {"text": "statistical machine translation", "start_pos": 135, "end_pos": 166, "type": "TASK", "confidence": 0.7606088320414225}]}, {"text": "However, such resources are scarce for many language pairs and domains.", "labels": [], "entities": []}, {"text": "Comparable corpora are sets of texts in two or more languages that are selected according to similar specifications, but are not translations of each other.", "labels": [], "entities": []}, {"text": "Nevertheless, parallel sentences, i.e., sentence pairs that are good translations of each other, can occur naturally in such corpora.", "labels": [], "entities": []}, {"text": "Therefore many approaches have been proposed to spot parallel sentences in comparable corpora (.", "labels": [], "entities": []}, {"text": "Extracting parallel sentences from comparable monolingual corpora is a very challenging task.", "labels": [], "entities": [{"text": "Extracting parallel sentences from comparable monolingual corpora", "start_pos": 0, "end_pos": 65, "type": "TASK", "confidence": 0.8528446980885097}]}, {"text": "According to the shared task web page, The aim of the Building and Using Comparable Corpora (BUCC) 2017 shared task is to quantitatively evaluate competing methods for extracting parallel sentences from comparable monolingual corpora, 1 https://comparable.limsi.fr/bucc2017/ bucc2017-task.html so as to give an overview on the state of the art and to identify the best performing approaches.", "labels": [], "entities": [{"text": "Building and Using Comparable Corpora (BUCC) 2017 shared task", "start_pos": 54, "end_pos": 115, "type": "TASK", "confidence": 0.6573914939706976}, {"text": "extracting parallel sentences from comparable monolingual corpora", "start_pos": 168, "end_pos": 233, "type": "TASK", "confidence": 0.8292752163750785}]}, {"text": "More precisely, given two sentence-split monolingual corpora, the task is to identify pairs of sentences that are translations of each other.", "labels": [], "entities": []}, {"text": "The BUCC 2017 shared task on parallel sentence extraction raises the following three main issues.", "labels": [], "entities": [{"text": "BUCC 2017 shared task", "start_pos": 4, "end_pos": 25, "type": "DATASET", "confidence": 0.9256978631019592}, {"text": "parallel sentence extraction", "start_pos": 29, "end_pos": 57, "type": "TASK", "confidence": 0.5959634284178416}]}, {"text": "One is the cross-language problem: as one must compare sentences across languages (here English with German, French, Russian, or Chinese), one must find away to compare sentences in two different languages, for instance by first translating one language into the other.", "labels": [], "entities": []}, {"text": "Another issue is sentence similarity: how do we define and calculate sentence similarity?", "labels": [], "entities": [{"text": "sentence similarity", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.7471758425235748}]}, {"text": "The last issue is the existence of too many possible sentence combinations: theoretically, for each sentence in a source monolingual corpus, every sentence in the target monolingual corpus could be used to generate a source-target sentence pair for subsequent parallel sentence identification, which would create a quadratic number of candidate sentence pairs.", "labels": [], "entities": [{"text": "parallel sentence identification", "start_pos": 260, "end_pos": 292, "type": "TASK", "confidence": 0.7283494671185812}]}, {"text": "Previous work) on parallel sentence extraction from comparable corpora has used external clues for this purpose.", "labels": [], "entities": [{"text": "parallel sentence extraction from comparable corpora", "start_pos": 18, "end_pos": 70, "type": "TASK", "confidence": 0.7797959546248118}]}, {"text": "() bootstrapped the process with document-level sentence alignment.", "labels": [], "entities": [{"text": "document-level sentence alignment", "start_pos": 33, "end_pos": 66, "type": "TASK", "confidence": 0.5730050106843313}]}, {"text": "() leveraged the publication date of newspaper articles to trim down the number of candidate sentence pairs.", "labels": [], "entities": []}, {"text": "These selection methods are not suitable for the BUCC 2017 shared task as no meta-information is provided on the documents from which the corpus sentences are extracted.", "labels": [], "entities": [{"text": "BUCC 2017 shared task", "start_pos": 49, "end_pos": 70, "type": "DATASET", "confidence": 0.9027466624975204}]}, {"text": "In this context, we test how similar methods fare without any metainformation.", "labels": [], "entities": []}, {"text": "In this paper, we describe the system that we developed for the BUCC 2017 shared task and show that a translating-searching-classifying three-step approach can achieve promising results 51 for Chinese-English Comparable Corpora.", "labels": [], "entities": [{"text": "BUCC 2017 shared task", "start_pos": 64, "end_pos": 85, "type": "DATASET", "confidence": 0.9276788681745529}]}], "datasetContent": [{"text": "We perform three evaluations: two independent evaluations on the training set for Step 2 (Searching for candidate source-target parallel sentence pairs) and Step 3 (Finding parallel sentences in candidate source-target sentence pairs) and one evaluation on the training and test sets for the whole system.", "labels": [], "entities": [{"text": "Finding parallel sentences in candidate source-target sentence pairs)", "start_pos": 165, "end_pos": 234, "type": "TASK", "confidence": 0.7204935087098016}]}, {"text": "The first two evaluations aim to find the best parameters and configurations of their own part.", "labels": [], "entities": []}, {"text": "The last one is for investigating the effectiveness and performance of the whole system.", "labels": [], "entities": []}, {"text": "For the evaluation of Step 2, we use all the English sentences of the training data gold standard as the question set.", "labels": [], "entities": [{"text": "training data gold standard", "start_pos": 70, "end_pos": 97, "type": "DATASET", "confidence": 0.848843976855278}]}, {"text": "According to the success evaluation result, we select the parameter N that provides the required success of 85%.", "labels": [], "entities": []}, {"text": "Then a Solr score threshold is calculated as the highest threshold that maintains the success on top N . To find the best configuration (kernel, class weight, C, gamma parameters) of the SVM classifier, we perform a 5-fold crossvalidation on the training data.", "labels": [], "entities": [{"text": "Solr score threshold", "start_pos": 7, "end_pos": 27, "type": "METRIC", "confidence": 0.9193149407704672}]}, {"text": "As the training data (as well as the test data) is highly imbalanced (the number of negative examples is around 120 times higher than the number of positive examples), the class weight parameter, according to the scikit-learn web page, which sets the parameter C of class i to class weight[i]*C for the SVM classifier, plays an important role.", "labels": [], "entities": []}, {"text": "For the whole system evaluation, after obtaining the final predicted source-target parallel sentence pairs, we use precision, recall and F1-score as evaluation measures: where TP stands for the number of source-target sentence pairs that is present in the gold standard, a false positive FP is a pair of sentences that is not present in the gold standard and a false negative FN is a pair of sentences present in the gold standard but absent from systems results.", "labels": [], "entities": [{"text": "precision", "start_pos": 115, "end_pos": 124, "type": "METRIC", "confidence": 0.9996823072433472}, {"text": "recall", "start_pos": 126, "end_pos": 132, "type": "METRIC", "confidence": 0.9992389678955078}, {"text": "F1-score", "start_pos": 137, "end_pos": 145, "type": "METRIC", "confidence": 0.998465895652771}, {"text": "TP", "start_pos": 176, "end_pos": 178, "type": "METRIC", "confidence": 0.9769397974014282}]}, {"text": "We tested three configurations: 1.", "labels": [], "entities": []}, {"text": "2. Setting N to 1 and replacing the classifier (Step 3) with a baseline ranking method based on the Solr score: we select the M sentence pairs with the highest scores, where M is determined according to the prior probability of being a correct sentence pair, estimated on the training data.", "labels": [], "entities": []}, {"text": "3. The intersection of Configuration 1 and of Configuration 2, with M =10,000.", "labels": [], "entities": [{"text": "M", "start_pos": 68, "end_pos": 69, "type": "METRIC", "confidence": 0.9762560725212097}]}], "tableCaptions": [{"text": " Table 1: Evaluation results: Run 1 = three steps,  Run 2 = no classifier, Run 3 = intersection", "labels": [], "entities": []}]}