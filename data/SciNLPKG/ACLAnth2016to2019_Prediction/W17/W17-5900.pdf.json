{"title": [], "abstractContent": [{"text": "State-of-the-art automated essay scoring engines such as E-rater do not grade essay content, focusing instead on providing diagnostic trait feedback on categories such as grammar, usage, mechanics, style and organization.", "labels": [], "entities": []}, {"text": "Content-based essay scoring is very challenging: it requires an understanding of essay content and is beyond the reach of today's automated essay scoring technologies.", "labels": [], "entities": [{"text": "Content-based essay scoring", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.5863097806771597}, {"text": "essay scoring", "start_pos": 140, "end_pos": 153, "type": "TASK", "confidence": 0.6870367079973221}]}, {"text": "As a result, content-dependent dimensions of essay quality are largely ignored in existing automated essay scoring research.", "labels": [], "entities": [{"text": "essay scoring", "start_pos": 101, "end_pos": 114, "type": "TASK", "confidence": 0.6901727318763733}]}, {"text": "In this talk, we describe our recent and ongoing efforts on content-based essay scoring, sharing the lessons we learned from automatically scoring two of the arguably most important content-dependent dimensions of persuasive essay quality, thesis clarity and argument persuasiveness.", "labels": [], "entities": [{"text": "content-based essay scoring", "start_pos": 60, "end_pos": 87, "type": "TASK", "confidence": 0.6345702211062113}, {"text": "argument persuasiveness", "start_pos": 259, "end_pos": 282, "type": "TASK", "confidence": 0.6881610751152039}]}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}