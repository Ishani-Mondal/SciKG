{"title": [{"text": "Discriminating between Similar Languages using Weighted Subword Features", "labels": [], "entities": []}], "abstractContent": [{"text": "The present contribution revolves around a contrastive subword n-gram model which has been tested in the Discriminating between Similar Languages shared task.", "labels": [], "entities": [{"text": "Discriminating between Similar Languages shared task", "start_pos": 105, "end_pos": 157, "type": "TASK", "confidence": 0.7549411555131277}]}, {"text": "I present and discuss the method used in this 14-way language identification task comprising varieties of 6 main language groups.", "labels": [], "entities": [{"text": "language identification task", "start_pos": 53, "end_pos": 81, "type": "TASK", "confidence": 0.7795335451761881}]}, {"text": "It features the following characteristics: (1) the preprocessing and conversion of a collection of documents to sparse features; (2) weighted character n-gram profiles; (3) a multinomial Bayesian classifier.", "labels": [], "entities": []}, {"text": "Meaningful bag-of-n-grams features can be used as a system in a straightforward way, my approach outperforms most of the systems used in the DSL shared task (3rd rank).", "labels": [], "entities": [{"text": "DSL shared task", "start_pos": 141, "end_pos": 156, "type": "TASK", "confidence": 0.5292409161726633}]}], "introductionContent": [{"text": "Language identification is the task of predicting the language(s) that a given document is written in.", "labels": [], "entities": [{"text": "Language identification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6920889616012573}]}, {"text": "It can be seen as a text categorization task in which documents are assigned to pre-existing categories.", "labels": [], "entities": []}, {"text": "This research field has found renewed interest in the 1990s due to advances in statistical approaches, and it has been active ever since, particularly since the methods developed have also been deemed relevant for text categorization, native language identification, authorship attribution, text-based geolocation, and dialectal studies.", "labels": [], "entities": [{"text": "text categorization", "start_pos": 214, "end_pos": 233, "type": "TASK", "confidence": 0.7639649212360382}, {"text": "native language identification", "start_pos": 235, "end_pos": 265, "type": "TASK", "confidence": 0.6288122038046519}, {"text": "authorship attribution", "start_pos": 267, "end_pos": 289, "type": "TASK", "confidence": 0.723979040980339}]}, {"text": "As of 2014 and the first Discriminating between Similar Languages (DSL) shared task ( ), a unified dataset ( ) comprising news texts of closely-related language varieties has been used to test and benchmark systems.", "labels": [], "entities": [{"text": "Discriminating between Similar Languages (DSL) shared task", "start_pos": 25, "end_pos": 83, "type": "TASK", "confidence": 0.6825043426619636}]}, {"text": "The documents to be classified are quite short and may even be difficult to distinguish for human annotators, thus adding to the difficulty and the interest of the task.", "labels": [], "entities": []}, {"text": "A second shared task took place in 2015 ().", "labels": [], "entities": []}, {"text": "An analysis of recent developments can be found in as well as in the report on the third shared task ( . The present study was conducted on the occasion of the fourth VarDial workshop (.", "labels": [], "entities": []}, {"text": "Not all varieties are to be considered equally since differences may stem from extra-linguistic factors.", "labels": [], "entities": []}, {"text": "It is for instance assumed that Malay and Indonesian derive from a millenium-old lingua franca, so that shorter texts have been considered to be a problem for language identification ().", "labels": [], "entities": [{"text": "language identification", "start_pos": 159, "end_pos": 182, "type": "TASK", "confidence": 0.70176662504673}]}, {"text": "Besides, the Bosnian/Serbian language pair seems to be difficult to tell apart whereas Croatian distinguishes itself from the two other varieties mostly because of political motives (Ljube\u0161i.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows: in section 2 the method is presented, it is then evaluated and discussed in section 3.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Benchmark by F1-weighted of a common range of n-gram length combinations on 2016 DSL  data (*=hashed features)", "labels": [], "entities": [{"text": "F1-weighted", "start_pos": 23, "end_pos": 34, "type": "METRIC", "confidence": 0.9959636926651001}, {"text": "DSL  data", "start_pos": 91, "end_pos": 100, "type": "DATASET", "confidence": 0.8308919668197632}]}, {"text": " Table 2: Evolution of execution time (in seconds)  with respect to n-gram length (*=hashed features)", "labels": [], "entities": []}, {"text": " Table 3: Comparison of several classifier types on the extracted feature vectors, ordered by ascending  training time (in seconds) on data from 2016. Classifiers used without extensive parameter tuning, linear  SVC and SGD with L2 penalty.", "labels": [], "entities": []}]}