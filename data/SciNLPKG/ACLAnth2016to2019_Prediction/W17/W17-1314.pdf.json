{"title": [{"text": "A Characterization Study of Arabic Twitter Data with a Benchmarking for State-of-the-Art Opinion Mining Models", "labels": [], "entities": []}], "abstractContent": [{"text": "Opinion mining in Arabic is a challenging task given the rich morphology of the language.", "labels": [], "entities": [{"text": "Opinion mining", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.9124457240104675}]}, {"text": "The task becomes more challenging when it is applied to Twitter data, which contains additional sources of noise, such as the use of unstan-dardized dialectal variations, the non-conformation to grammatical rules, the use of Arabizi and code-switching, and the use of non-text objects such as images and URLs to express opinion.", "labels": [], "entities": []}, {"text": "In this paper, we perform an analytical study to observe how such linguistic phenomena vary across different Arab regions.", "labels": [], "entities": []}, {"text": "This study of Arabic Twitter characterization aims at providing better understanding of Arabic Tweets, and fostering advanced research on the topic.", "labels": [], "entities": [{"text": "Arabic Twitter characterization", "start_pos": 14, "end_pos": 45, "type": "TASK", "confidence": 0.7218166987101237}]}, {"text": "Furthermore , we explore the performance of the two schools of machine learning on Arabic Twitter, namely the feature engineering approach and the deep learning approach.", "labels": [], "entities": [{"text": "Arabic Twitter", "start_pos": 83, "end_pos": 97, "type": "DATASET", "confidence": 0.9122426807880402}]}, {"text": "We consider models that have achieved state-of-the-art performance for opinion mining in English.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 71, "end_pos": 85, "type": "TASK", "confidence": 0.8314968347549438}]}, {"text": "Results highlight the advantages of using deep learning-based models, and confirm the importance of using morphological abstractions to address Arabic's complex morphology.", "labels": [], "entities": []}], "introductionContent": [{"text": "Opinion mining, or sentiment analysis, aims at automatically extract subjectivity information from text) whether at sentence or document level.", "labels": [], "entities": [{"text": "Opinion mining", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8039256632328033}, {"text": "sentiment analysis", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.8976360559463501}]}, {"text": "This task has attracted a lot of researchers in the last decade due to the wide range of real world applications that are interested in harvesting public opinion in different domains such as politics, stock markets and marketing.", "labels": [], "entities": []}, {"text": "Huge amounts of opinion data are generated, on a daily basis, in many forums, personal blogs and social networking websites.", "labels": [], "entities": []}, {"text": "In particular, Twitter is one of the most used social media platforms, where users generally express their opinions on everything from music to movies to politics and all sort of trending topics.", "labels": [], "entities": []}, {"text": "Furthermore, Arabic language is the 5 th most-spoken language worldwide, and has recently become a key source of the Internet content with a 6,600% growth in number of users compared to the year 2000.", "labels": [], "entities": []}, {"text": "Therefore, developing accurate opinion mining models for Arabic tweets is a timely and intriguing problem that is worth investigating.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 31, "end_pos": 45, "type": "TASK", "confidence": 0.7293655872344971}]}, {"text": "However, applying Natural Language Processing (NLP) and learning opinion models for Arabic Twitter data is not straightforward due to several reasons.", "labels": [], "entities": [{"text": "Arabic Twitter data", "start_pos": 84, "end_pos": 103, "type": "DATASET", "confidence": 0.7432140310605367}]}, {"text": "Tweets contain large variations of unstandardized dialectal Arabic (DA), in addition to significant amounts of misspellings and grammatical errors, mainly due to their length restriction.", "labels": [], "entities": []}, {"text": "They also contain \"Arabizi\", where Arabic words are written using Latin characters.", "labels": [], "entities": []}, {"text": "Due to the cultural diversity across the Arab world, an opinion model that is developed for tweets in one region may not be applicable to extract opinions from tweets in another region.", "labels": [], "entities": []}, {"text": "Finally, tweets usually contain special tokens such as hashtags, mentions, multimedia objects and URLs that need to be han-dled appropriately, in order to make use of the subjective information they may implicitly carry.", "labels": [], "entities": []}, {"text": "In this paper, we present a characterization study of Twitter data collected from different Arab regions, namely Egypt, the Levant and the Arab Gulf.", "labels": [], "entities": []}, {"text": "This study illustrates how the discussed topics, the writing style and other linguistic phenomena, vary significantly from one region to another, reflecting different usages of Twitter around the Arab world.", "labels": [], "entities": []}, {"text": "We also evaluate the model that ranked first at on \"Sentiment Analysis in Twitter\".", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.9556638598442078}]}, {"text": "This model is developed for opinion mining in English, and uses feature engineering to extract surface, syntactic, semantic and Twitter-specific features.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 28, "end_pos": 42, "type": "TASK", "confidence": 0.8428115844726562}]}, {"text": "Therefore, we extract an equivalent feature set for Arabic to train a model for opinion mining in Arabic tweets.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 80, "end_pos": 94, "type": "TASK", "confidence": 0.7174614816904068}]}, {"text": "We compare this model to another class of models that are based on deep learning techniques.", "labels": [], "entities": []}, {"text": "In particular, we use recursive deep models that achieved high performances.", "labels": [], "entities": []}, {"text": "Experimental results show the advantage of deep learning at learning subjectivity in Arabic tweets without the need for artificial features that describe the properties and characteristics of Twitter data.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes previous work on opinion mining with particular focus on application to Twitter data.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 37, "end_pos": 51, "type": "TASK", "confidence": 0.8298477530479431}]}, {"text": "Section 3 presents the characterization study and highlights distinctive characteristics of tweets collected from different Arab regions.", "labels": [], "entities": []}, {"text": "Section 4 describes the opinion models that we evaluate in this paper, and experimental results are presented in Section 5.", "labels": [], "entities": []}, {"text": "Conclusion is provided in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we evaluate the performance of the feature engineering and deep learning-based models for opinion mining in Arabic tweets.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 107, "end_pos": 121, "type": "TASK", "confidence": 0.7591722905635834}]}, {"text": "We focus on the task of three-way opinion classification, where each tweet should be classified as positive, negative or neutral.", "labels": [], "entities": [{"text": "opinion classification", "start_pos": 34, "end_pos": 56, "type": "TASK", "confidence": 0.7928276658058167}]}, {"text": "For our experiments, we use the Arabic Sentiment Twitter Data (ASTD)) that consists of 10,006 tweets belonging to Egyptian Twit-ter accounts.", "labels": [], "entities": [{"text": "Arabic Sentiment Twitter Data (ASTD))", "start_pos": 32, "end_pos": 69, "type": "DATASET", "confidence": 0.7048645189830235}]}, {"text": "These tweets are annotated with four labels: positive (799), negative (1,684), neutral (832) and objective.", "labels": [], "entities": []}, {"text": "Due to the highly skewed distribution of the classes, and since our focus is to perform opinion classification rather than subjectivity classification, we excluded the objective tweets, reducing the size of the data to 3,315 tweets with reasonable class distribution: 24% (positive), 51% (negative) and 25% (neutral).", "labels": [], "entities": [{"text": "opinion classification", "start_pos": 88, "end_pos": 110, "type": "TASK", "confidence": 0.7449635565280914}, {"text": "subjectivity classification", "start_pos": 123, "end_pos": 150, "type": "TASK", "confidence": 0.7417461574077606}]}, {"text": "This data is split into a train set (70%), a development set (10%) and a test set (20%).", "labels": [], "entities": []}, {"text": "Each tweet is preprocessed by (1) replacing user mentions and URLs with special \"global\" tokens, (2) extracting emoticons and emojis using the \"emoji\" java library and replacing them with special tokens (for this we used the emojis sentiment lexicon from, and prepared our own emoticons lexicon), (3) normalizing hashtags by removing the \"#\" symbol and the underscores that are used to separate words in composite hashtags, and (4) normalizing word elongations (letter repetitions).", "labels": [], "entities": [{"text": "normalizing word elongations (letter repetitions", "start_pos": 432, "end_pos": 480, "type": "TASK", "confidence": 0.6145316263039907}]}, {"text": "To extract features for the SVM classifier, we performed lemmatization and POS tagging using MADAMIRA v2.1, the state-of-the-art morphological analyzer and disambiguator in Arabic (, that uses the Standard Arabic Morphological Analyzer (SAMA) (.", "labels": [], "entities": [{"text": "SVM classifier", "start_pos": 28, "end_pos": 42, "type": "TASK", "confidence": 0.8670991361141205}, {"text": "POS tagging", "start_pos": 75, "end_pos": 86, "type": "TASK", "confidence": 0.8163409531116486}]}, {"text": "Since the evaluation corpus is in Egyptian Arabic, we used MADAMIRA in the Egyptian mode.", "labels": [], "entities": [{"text": "MADAMIRA", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.8930215835571289}]}, {"text": "It is worth noting that some recent efforts have added Levantine to MADAMIRA, but it is not public yet.", "labels": [], "entities": [{"text": "MADAMIRA", "start_pos": 68, "end_pos": 76, "type": "DATASET", "confidence": 0.4006340205669403}]}, {"text": "We only included n-grams that occurred more than a pre-defined threshold t, where t \u2208.", "labels": [], "entities": []}, {"text": "Preliminary experiments showed that using the radial basis function (RBF) kernel is better than using the linear kernel.", "labels": [], "entities": []}, {"text": "We used the development set to tune the model's parameters, namely the cost of misclassification and \u03b3 the width of the kernel, Then, the model with the parameters that achieved the best results is applied to the unseen test set.", "labels": [], "entities": []}, {"text": "As for the RNTN model, we generated word embeddings of size 25 by training the skip-gram embedding model () on the QALB corpus, which contains nearly 500K sentences.", "labels": [], "entities": [{"text": "QALB corpus", "start_pos": 115, "end_pos": 126, "type": "DATASET", "confidence": 0.9513539671897888}]}, {"text": "We train RNTN using ArSenTB, and then apply the trained model to perform opinion classification in tweets.", "labels": [], "entities": [{"text": "ArSenTB", "start_pos": 20, "end_pos": 27, "type": "METRIC", "confidence": 0.9667385816574097}, {"text": "opinion classification in tweets", "start_pos": 73, "end_pos": 105, "type": "TASK", "confidence": 0.7954036593437195}]}, {"text": "We alleviate the impact of sparsity by training RNTN using lemmas, which is similar to our choice of training SVM using lemma n-grams.", "labels": [], "entities": []}, {"text": "Finally, the different models are evaluated using accuracy and the F1-score averaged across the different classes.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9996802806854248}, {"text": "F1-score", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.9995054006576538}]}, {"text": "illustrates the performances achieved with the state-of-the-art models in feature engineering (SVM all,lemmas ) and deep learning (RNTN lemmas ).", "labels": [], "entities": []}, {"text": "We compare to the following baselines: (1) the majority baseline that automatically assigns the most frequent class in the train set, and (2) the SVM trained with word ngrams (SVM baseline ), which has been a common approach in the Arabic opinion mining literature.", "labels": [], "entities": [{"text": "Arabic opinion mining", "start_pos": 232, "end_pos": 253, "type": "TASK", "confidence": 0.6458210448424021}]}, {"text": "To emphasize the impact of lemmatization, we include the results of SVM trained with features from (Balikas and Amini, 2016) and using word instead of lemma n-grams (SVM all,words ).", "labels": [], "entities": []}, {"text": "We also include the results of RNTN trained with raw words (RNTN words ).", "labels": [], "entities": []}, {"text": "58.5% 53.6%: Performance of the different models for opinion mining, evaluated on the ASTD dataset.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 53, "end_pos": 67, "type": "TASK", "confidence": 0.837916225194931}, {"text": "ASTD dataset", "start_pos": 86, "end_pos": 98, "type": "DATASET", "confidence": 0.9561212658882141}]}], "tableCaptions": [{"text": " Table 2: Topics discussed in each set.", "labels": [], "entities": []}, {"text": " Table 3: Languages and writing styles in each set.", "labels": [], "entities": []}, {"text": " Table 4: Use of special Twitter tokens in each set.", "labels": [], "entities": []}, {"text": " Table 5: Performance of the different models for  opinion mining, evaluated on the ASTD dataset.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 51, "end_pos": 65, "type": "TASK", "confidence": 0.8575161993503571}, {"text": "ASTD dataset", "start_pos": 84, "end_pos": 96, "type": "DATASET", "confidence": 0.9479363858699799}]}]}