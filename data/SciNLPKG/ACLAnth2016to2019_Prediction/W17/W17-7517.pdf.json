{"title": [{"text": "Document Level Novelty Detection : Textual Entailment Lends a Helping Hand", "labels": [], "entities": [{"text": "Document Level Novelty Detection", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7391259670257568}]}], "abstractContent": [{"text": "In this paper we present away of detecting novelty of a document with respect to the relevant source documents with the aid of methods used in detecting Textual En-tailment (TE).", "labels": [], "entities": [{"text": "detecting Textual En-tailment (TE)", "start_pos": 143, "end_pos": 177, "type": "TASK", "confidence": 0.523015300432841}]}, {"text": "The proposed TE system is based on supervised machine learning approach that makes use of different similarity metrics.", "labels": [], "entities": [{"text": "TE", "start_pos": 13, "end_pos": 15, "type": "TASK", "confidence": 0.8105147480964661}]}, {"text": "The TE system is further interpreted to detect the novelty of an incoming document with respect to some source document(s) already seen by the system.", "labels": [], "entities": [{"text": "TE", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.8503817915916443}]}, {"text": "We design a corpus to support this foundation of novelty at the document level and coin it as the Document Level Novelty Detection (DLND) corpus.", "labels": [], "entities": [{"text": "Document Level Novelty Detection (DLND)", "start_pos": 98, "end_pos": 137, "type": "TASK", "confidence": 0.7200106041772025}]}, {"text": "We employ standard supervised classification algorithms such as Support Vector Machine (SVM), Multilayer Perceptron (MLP) and Random Forest (RF) and investigate their performance on DLND.", "labels": [], "entities": []}, {"text": "Evaluation results show the accuracies of 78.78%, 77.27% and 74.24% for SVM, MLP and RF, respectively on DLND.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 28, "end_pos": 38, "type": "METRIC", "confidence": 0.9987236857414246}, {"text": "SVM", "start_pos": 72, "end_pos": 75, "type": "DATASET", "confidence": 0.5393818020820618}, {"text": "MLP", "start_pos": 77, "end_pos": 80, "type": "METRIC", "confidence": 0.5008496642112732}, {"text": "RF", "start_pos": 85, "end_pos": 87, "type": "METRIC", "confidence": 0.9045121073722839}, {"text": "DLND", "start_pos": 105, "end_pos": 109, "type": "DATASET", "confidence": 0.9346784353256226}]}, {"text": "To establish the efficacy of our methods we evaluate our model on the benchmark datasets released in the shared task of Recognizing Textual Entailment-6 (RTE-6) and Recognizing Textual Entailment-7 (RTE-7).", "labels": [], "entities": [{"text": "Recognizing Textual Entailment-7 (RTE-7)", "start_pos": 165, "end_pos": 205, "type": "TASK", "confidence": 0.6308029840389887}]}, {"text": "Experiments show the accuracies of 94.91% and 96.72% on RTE-6 and RTE-7 dataset, respectively .", "labels": [], "entities": [{"text": "accuracies", "start_pos": 21, "end_pos": 31, "type": "METRIC", "confidence": 0.9985805749893188}, {"text": "RTE-6", "start_pos": 56, "end_pos": 61, "type": "DATASET", "confidence": 0.9033132791519165}, {"text": "RTE-7 dataset", "start_pos": 66, "end_pos": 79, "type": "DATASET", "confidence": 0.9375905990600586}]}], "introductionContent": [{"text": "Novelty detection from texts is an age-old problem in text mining and have found significance in various applications of Natural Language Processing (NLP) such as Text Summarization.", "labels": [], "entities": [{"text": "Novelty detection from texts", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8430829346179962}, {"text": "text mining", "start_pos": 54, "end_pos": 65, "type": "TASK", "confidence": 0.7827824056148529}, {"text": "Text Summarization", "start_pos": 163, "end_pos": 181, "type": "TASK", "confidence": 0.8044673502445221}]}, {"text": "Novelty detection from texts implies figuring out new information from a given piece of text and subsequently arriving to the judgment that whether a given piece of text could be termed as novel or not.", "labels": [], "entities": [{"text": "Novelty detection from texts", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8326714336872101}]}, {"text": "The decision should always be with respect to some relevant pieces of source texts.", "labels": [], "entities": []}, {"text": "The problem of novelty detection has been studied via various NLP and machine learning (ML) paradigms ranging from classification to clustering.", "labels": [], "entities": [{"text": "novelty detection", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.8966640532016754}]}, {"text": "On the other hand TE is a NLP problem which is defined as a directional relationship between the two text fragments, termed as Text (T) and Hypothesis (H).", "labels": [], "entities": [{"text": "TE", "start_pos": 18, "end_pos": 20, "type": "TASK", "confidence": 0.9540411233901978}]}, {"text": "It is said that: T entails H if, typically, a human reading T would infer that H is most likely to be true ( i.e. to judge that whether H could be inferred from T.", "labels": [], "entities": []}, {"text": "This inference is not only based on understanding of T but also on some prior domain knowledge.", "labels": [], "entities": []}, {"text": "Novelty detection finds it's relevance with TE in the sense that, a certain hypothesis H entailed from a certain piece of source text T could be considered as non-novel with respect to T if a human reading the hypothesis H after reading T would find redundant information in H.", "labels": [], "entities": [{"text": "Novelty detection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7610309422016144}]}, {"text": "Whereas if H is not entailed from T then a human reading H after T would find new piece of information in H and hence H could be considered as novel with respect to T.", "labels": [], "entities": []}, {"text": "The basis of our work also proceeds with this intuition and is grounded with the very basic relationships of textual entailment with textual similarity.", "labels": [], "entities": []}, {"text": "Textual similarity is bi-directional relationship between two text fragments whereas textual entailment is an uni-directional relationship between the hypothesis and source text where the former could be derived from the latter but not the reverse.", "labels": [], "entities": [{"text": "textual entailment", "start_pos": 85, "end_pos": 103, "type": "TASK", "confidence": 0.6740904003381729}]}, {"text": "Similarity, it can be manifested in a scale that 131 ranges from semantic equivalence to complete unrelatedness, whereas TE can be either Yes or No. The implication of novelty with TE was first attempted in the TAC RTE-6 Novelty Detection Subtask and also being carried out in RTE-7.", "labels": [], "entities": [{"text": "TE", "start_pos": 121, "end_pos": 123, "type": "METRIC", "confidence": 0.9881889820098877}, {"text": "TAC RTE-6 Novelty Detection Subtask", "start_pos": 211, "end_pos": 246, "type": "TASK", "confidence": 0.6082885026931762}, {"text": "RTE-7", "start_pos": 277, "end_pos": 282, "type": "DATASET", "confidence": 0.9439051747322083}]}, {"text": "In these tracks also they defined those piece of Hypotheses as Novel which are Not Entailed by Texts.", "labels": [], "entities": []}, {"text": "On the basis of this intuition we carryout the experiments described henceforth.", "labels": [], "entities": []}, {"text": "These tasks were rendered at the sentence-level and they established this view of TE as an opposite characteristic to novelty.", "labels": [], "entities": [{"text": "TE", "start_pos": 82, "end_pos": 84, "type": "TASK", "confidence": 0.9266617298126221}]}, {"text": "In this work we take forward this view to investigate novelty detection at the document level via TE with emphasis to textual similarity measures.", "labels": [], "entities": [{"text": "novelty detection", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.8411911725997925}, {"text": "TE", "start_pos": 98, "end_pos": 100, "type": "METRIC", "confidence": 0.8119345903396606}]}, {"text": "The contributions of the present work could be enumerated as follows: \u2022 Investigating the role of TE to detect novelty of a document.", "labels": [], "entities": [{"text": "TE", "start_pos": 98, "end_pos": 100, "type": "TASK", "confidence": 0.6783620119094849}, {"text": "detect novelty of a document", "start_pos": 104, "end_pos": 132, "type": "TASK", "confidence": 0.6953690052032471}]}, {"text": "\u2022 Creating our own benchmark corpora for novelty detection at the document level.", "labels": [], "entities": [{"text": "novelty detection", "start_pos": 41, "end_pos": 58, "type": "TASK", "confidence": 0.8366506397724152}]}], "datasetContent": [{"text": "We evaluate the efficacy of our approach on the RTE-6 and RTE-7 datasets for novelty detection subtask.", "labels": [], "entities": [{"text": "RTE-6", "start_pos": 48, "end_pos": 53, "type": "DATASET", "confidence": 0.9053016304969788}, {"text": "RTE-7 datasets", "start_pos": 58, "end_pos": 72, "type": "DATASET", "confidence": 0.8865289390087128}, {"text": "novelty detection subtask", "start_pos": 77, "end_pos": 102, "type": "TASK", "confidence": 0.8513556917508444}]}, {"text": "It is to be noted that these two datasets were created aiming sentence-level novelty detection.", "labels": [], "entities": [{"text": "sentence-level novelty detection", "start_pos": 62, "end_pos": 94, "type": "TASK", "confidence": 0.6935070256392161}]}, {"text": "However in the present work we focus on detecting document level novelty.", "labels": [], "entities": [{"text": "detecting document level novelty", "start_pos": 40, "end_pos": 72, "type": "TASK", "confidence": 0.8011543452739716}]}, {"text": "To investigate the implication of our methods for detecting novelty of a document we create the Document Level Novelty Detection (DLND) corpus.", "labels": [], "entities": [{"text": "detecting novelty of a document", "start_pos": 50, "end_pos": 81, "type": "TASK", "confidence": 0.8176616311073304}, {"text": "Document Level Novelty Detection (DLND)", "start_pos": 96, "end_pos": 135, "type": "TASK", "confidence": 0.692576697894505}]}, {"text": "The novelty detection subtask was organized in conjunction with the main tasks of RTE-6 and RTE-7 (Bentivogli, 2011) tracks.", "labels": [], "entities": [{"text": "novelty detection", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.8741701543331146}, {"text": "RTE-6", "start_pos": 82, "end_pos": 87, "type": "DATASET", "confidence": 0.9357213377952576}, {"text": "RTE-7 (Bentivogli, 2011)", "start_pos": 92, "end_pos": 116, "type": "DATASET", "confidence": 0.8825652996699015}]}, {"text": "In these tracks, organizers released a benchmark dataset for novelty detection using TE.", "labels": [], "entities": [{"text": "novelty detection", "start_pos": 61, "end_pos": 78, "type": "TASK", "confidence": 0.8490129113197327}, {"text": "TE", "start_pos": 85, "end_pos": 87, "type": "METRIC", "confidence": 0.7468978762626648}]}, {"text": "We make use of this corpus to evaluate our system.", "labels": [], "entities": []}, {"text": "In RTE-6 the novelty detection dataset consists both development and test sets.", "labels": [], "entities": [{"text": "RTE-6", "start_pos": 3, "end_pos": 8, "type": "DATASET", "confidence": 0.8412235379219055}, {"text": "novelty detection", "start_pos": 13, "end_pos": 30, "type": "TASK", "confidence": 0.7833714485168457}]}, {"text": "Each set contains 10 different topics.", "labels": [], "entities": []}, {"text": "Statistics of development and test sets are shown in  In this section we discuss the pre-processing done on the datasets, results obtained through experimentations and thereby analyze the errors.", "labels": [], "entities": []}, {"text": "As the documents were collected from the various web sources, these were not well structured.", "labels": [], "entities": []}, {"text": "We pre-processed the documents by removing white spaces.", "labels": [], "entities": []}, {"text": "We calculate similarity scores between a target (novel/non-novel) and source document using various similarity measures, and use these as features in our classifiers.", "labels": [], "entities": []}, {"text": "These scores are used to generate the feature vectors for classifier's training and/or testing.", "labels": [], "entities": []}, {"text": "As already mentioned we used RF, MLP and SVM as our classification algorithms.", "labels": [], "entities": []}, {"text": "These models are used to assign a class label (Entailed or Not Entailed) to each instance in the test set.", "labels": [], "entities": []}, {"text": "These predicted classes are compared to the gold label to compute the final results.", "labels": [], "entities": []}, {"text": "Novelty and TE are highly co-related.", "labels": [], "entities": [{"text": "TE", "start_pos": 12, "end_pos": 14, "type": "METRIC", "confidence": 0.6283617615699768}]}, {"text": "In the context of similarity, a target document is said to be novel with respect to a collection of source document(s) if it has very less similarity to the sources.", "labels": [], "entities": []}, {"text": "Otherwise, it is termed as novel.", "labels": [], "entities": []}, {"text": "On the other hand similarity and TE are directly proportional if we keep aside the presence of negations in the comparing texts.", "labels": [], "entities": [{"text": "similarity", "start_pos": 18, "end_pos": 28, "type": "METRIC", "confidence": 0.9991238713264465}, {"text": "TE", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.9984239339828491}]}, {"text": "TE between two texts can be judged by measuring the similarity between those two particular texts.", "labels": [], "entities": [{"text": "TE", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9358862638473511}]}, {"text": "We can conclude that novelty and TE are opposed to each other.", "labels": [], "entities": [{"text": "novelty", "start_pos": 21, "end_pos": 28, "type": "METRIC", "confidence": 0.9854716658592224}, {"text": "TE", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.9911935925483704}]}, {"text": "Entailment can be away of judging the non-novelty of a document.", "labels": [], "entities": [{"text": "Entailment", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.8235166072845459}]}, {"text": "We report the results on test set of different classifiers in demonstrate that SVM in both the cases performs best amongst all.", "labels": [], "entities": [{"text": "SVM", "start_pos": 79, "end_pos": 82, "type": "TASK", "confidence": 0.8972904682159424}]}, {"text": "This is not unexpected keeping in mind the success of SVM in solving a wide range of text classification problems with features which are overlapping in nature.", "labels": [], "entities": [{"text": "text classification", "start_pos": 85, "end_pos": 104, "type": "TASK", "confidence": 0.7086598873138428}]}, {"text": "MLP makes use of back-propagation technique to classify instances.", "labels": [], "entities": [{"text": "MLP", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8137673139572144}]}, {"text": "In our setting we use 5 layers that might have caused better accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9978662133216858}]}, {"text": "Random Forest also seems to suit well to our task.", "labels": [], "entities": [{"text": "Random Forest", "start_pos": 0, "end_pos": 13, "type": "DATASET", "confidence": 0.9837735891342163}]}, {"text": "We evaluate our model on the benchmark datasets of RTE-6 and RTE-7 for novelty detection.", "labels": [], "entities": [{"text": "RTE-6", "start_pos": 51, "end_pos": 56, "type": "DATASET", "confidence": 0.9085294008255005}, {"text": "RTE-7", "start_pos": 61, "end_pos": 66, "type": "DATASET", "confidence": 0.8521354794502258}, {"text": "novelty detection", "start_pos": 71, "end_pos": 88, "type": "TASK", "confidence": 0.8367242813110352}]}, {"text": "The task was to detect those hypotheses which are novel (not-entailed) with respect to the corpus.", "labels": [], "entities": []}, {"text": "We show the results in, where P: Precision, R: Recall and F1: F-score.", "labels": [], "entities": [{"text": "Precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9802282452583313}, {"text": "Recall", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.984616219997406}, {"text": "F1", "start_pos": 58, "end_pos": 60, "type": "METRIC", "confidence": 0.999565064907074}, {"text": "F-score", "start_pos": 62, "end_pos": 69, "type": "METRIC", "confidence": 0.8880243301391602}]}, {"text": "We also compare the performance with the best systems reported in RTE-6 (Houping Jia and and also in RTE-7(  tion subtask is with the F-score of 82.91% by.", "labels": [], "entities": [{"text": "RTE-6", "start_pos": 66, "end_pos": 71, "type": "DATASET", "confidence": 0.9070857167243958}, {"text": "Houping Jia", "start_pos": 73, "end_pos": 84, "type": "DATASET", "confidence": 0.853559672832489}, {"text": "RTE-7", "start_pos": 101, "end_pos": 106, "type": "DATASET", "confidence": 0.9248483777046204}, {"text": "F-score", "start_pos": 134, "end_pos": 141, "type": "METRIC", "confidence": 0.999581515789032}]}, {"text": "Syntactic (output of MINIPAR parser, nodes matching texts and hypotheses) and semantic (WordNet, Verb Ocean, and LingPipe) matching between texts and hypotheses were employed for that purpose.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 88, "end_pos": 95, "type": "DATASET", "confidence": 0.9598011374473572}]}, {"text": "An Fscore of 90.95% was obtained as the best score by (Tsuchida and Ishikawa, 2011) on RTE-7 novelty detection dataset, with mostly lexical matching features in a machine learning framework.", "labels": [], "entities": [{"text": "Fscore", "start_pos": 3, "end_pos": 9, "type": "METRIC", "confidence": 0.9997979998588562}, {"text": "RTE-7 novelty detection", "start_pos": 87, "end_pos": 110, "type": "TASK", "confidence": 0.7186396718025208}]}, {"text": "As is evident, our proposed system successfully outperforms those state-of-the-art techniques of RTE-6 and RTE-7 by a significant margin.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the RTEs datasets", "labels": [], "entities": [{"text": "RTEs datasets", "start_pos": 28, "end_pos": 41, "type": "DATASET", "confidence": 0.8463346064090729}]}, {"text": " Table 2. There exists  multiple texts for each hypothesis in both devel- opment and test datasets. The entailment decisions  are either Yes, i.e Non-novel or No i.e Novel for  each hypothesis and text pair.", "labels": [], "entities": []}, {"text": " Table 2: RTE-6 and RTE-7 Novelty Subtask  Dataset Statistics", "labels": [], "entities": [{"text": "RTE-6", "start_pos": 10, "end_pos": 15, "type": "DATASET", "confidence": 0.8024238348007202}, {"text": "RTE-7 Novelty Subtask  Dataset Statistics", "start_pos": 20, "end_pos": 61, "type": "DATASET", "confidence": 0.8436105966567993}]}, {"text": " Table 3: Statistics of the DLND Datasets", "labels": [], "entities": [{"text": "DLND Datasets", "start_pos": 28, "end_pos": 41, "type": "DATASET", "confidence": 0.9361885786056519}]}, {"text": " Table 4. Results reported in", "labels": [], "entities": []}, {"text": " Table 4: Results on DLND test datasets", "labels": [], "entities": [{"text": "DLND test datasets", "start_pos": 21, "end_pos": 39, "type": "DATASET", "confidence": 0.839390238126119}]}, {"text": " Table 5: comparison of results obtained with the  best system's results on RTE-6 and RTE-7", "labels": [], "entities": [{"text": "RTE-6", "start_pos": 76, "end_pos": 81, "type": "DATASET", "confidence": 0.966510534286499}, {"text": "RTE-7", "start_pos": 86, "end_pos": 91, "type": "DATASET", "confidence": 0.8401318192481995}]}, {"text": " Table 6: Feature sensitivity analysis", "labels": [], "entities": [{"text": "Feature sensitivity analysis", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.684770256280899}]}, {"text": " Table 7: Comparison with the state-of-art", "labels": [], "entities": []}]}