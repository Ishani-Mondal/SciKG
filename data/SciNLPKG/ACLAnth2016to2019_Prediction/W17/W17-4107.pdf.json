{"title": [], "abstractContent": [{"text": "Most NLP resources that offer annotations at the word segment level provide morphological annotation that includes features indicating tense, aspect, modality, gender, case, and other inflectional information.", "labels": [], "entities": []}, {"text": "Such information is rarely aligned to the relevant parts of the words-i.e. the al-lomorphs, as such annotation would be very costly.", "labels": [], "entities": []}, {"text": "These unaligned weak label-ings are commonly provided by annotated NLP corpora such as treebanks in various languages.", "labels": [], "entities": []}, {"text": "Although they lack alignment information, the presence/absence of labels at the word level is also consistent with the amount of supervision assumed to be provided to L1 and L2 learners.", "labels": [], "entities": []}, {"text": "In this paper, we explore several methods to learn this latent alignment between parts of word forms and the grammatical information provided.", "labels": [], "entities": []}, {"text": "All the methods under investigation favor hypotheses regarding allomorphs of morphemes that re-use a small inventory, i.e. implicitly minimize the number of allomorphs that a morpheme can be realized as.", "labels": [], "entities": []}, {"text": "We show that the provided information offers a significant advantage for both word segmenta-tion and the learning of allomorphy.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many NLP resources provide weakly labeled morphological resources in data sets that are primarily annotated for higher-level constructs besides morphology.", "labels": [], "entities": []}, {"text": "Most treebanks, for example, include some morphological annotation on the word level of varying granularity.", "labels": [], "entities": []}, {"text": "The Penn treebank) uses a limited label set of 45, while the Universal Dependencies (UD)) project annotates word forms with a much larger set of morphological featurevalue pairs.", "labels": [], "entities": [{"text": "Penn treebank", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.992313414812088}]}, {"text": "Noteworthy is that such annotation is not in anyway aligned with the substrings in the word forms themselves: if the Finnish word kaatuisi 'would fall down' is annotated as kaatua,V,Cond,Pres,3,Sg, there is no indication that kaatu corresponds to the stem, isi to Cond, and that V, 3 and Sg are realized as zero allomorphs.", "labels": [], "entities": []}, {"text": "In essence, such labeled resources provide an inference problem in the realm of inflectional morphology in that one can exploit statistical regularities in the data to perform a morpheme segmentation and labeling of the data.", "labels": [], "entities": []}, {"text": "A linguistically informed observation based on a simple assumption of systematic regularity between form and meaning is that it is very unlikely that a single morpheme such as the Finnish conditional be realized in more than a handful of different allomorphs.", "labels": [], "entities": []}, {"text": "Conversely, it is unlikely that apart of a word, such as the affix isi carry many disparate meanings, i.e. be associated with a large array of different labels.", "labels": [], "entities": []}, {"text": "Still, morphemes are often realized by more than one allomorph although the number of allomorphs is typically small.", "labels": [], "entities": []}, {"text": "Consider for example English plural number which is realized by different allomorphs in the forms dogs, churches, oxen and children.", "labels": [], "entities": []}, {"text": "From a data-driven perspective, the inference problem thus becomes to find a globally good allomorph segmentation and labeling of all word forms given in a large resource of inflected word forms.", "labels": [], "entities": []}, {"text": "Besides NLP applications, this type of input and the related inference problem is consistent with the assumptions of relevant inputs witnessed in L1 acquisition-a combination of stems and other affixes where the learner knows from the environment some semantic signal from the immediate discourse, e.g. plurality, tense, etc.", "labels": [], "entities": []}, {"text": "Children tend to show the ability to analyze affixes before they can use them productively.", "labels": [], "entities": []}, {"text": "For example, threeyear-olds have been shown to be able to associate agentive meaning to an -er morpheme in English, but can only produce the suffix later.", "labels": [], "entities": []}, {"text": "In this paper we explore and evaluate several methods for automatically segmenting and labeling each allomorph present in resources that are labeled with morphosyntactic features at the word level.", "labels": [], "entities": []}, {"text": "This means that our training data consists of plain unsegmented word forms (for example kaatuisi) and morphological feature sets (for example {V, Cond, Pres, 3, Sg}).", "labels": [], "entities": []}, {"text": "The result is a morphologically segmented corpus where each morphological segment is associated with at least one morphological feature as shown in.", "labels": [], "entities": []}, {"text": "In order to account for fusional morphology, we allow one segment to be associated with multiple morphological features.", "labels": [], "entities": [{"text": "fusional morphology", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.9720357060432434}]}, {"text": "We treat the problem of joint segmentation and feature assignment as a search problem in the space of all possible segmentations and labelings of each word form in a (weakly) annotated corpus.", "labels": [], "entities": [{"text": "feature assignment", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.7327469289302826}]}, {"text": "The crucial constraint provided by the weak labeling is that not all labels can be present in a word form-the set of labels present for each inflected word must be restricted to those given by the resource.", "labels": [], "entities": []}, {"text": "To our knowledge, this weakly supervised task has not previously been explored although joint segmentation and labeling has been explored in a fully supervised setting by.", "labels": [], "entities": []}, {"text": "To solve the problem, we explore global metrics that indirectly favor re-use of allomorphs according to the intuition given above.", "labels": [], "entities": []}, {"text": "We formalize a generic objective function that scores the goodness of segmentations and labeling globally in a corpus.", "labels": [], "entities": []}, {"text": "The scoring portion of this objective function is tested with several metrics: symmetric conditional probability, which favors that allomorphs be good predictors of labels and vice versa, a perceptron learner that weights allomorph-label association, a Rescorla-Wagner model based on classical conditioning that also learns such association weights, and a model of Kullback-Leibler divergence that favors that labels and allomorphs have similar distributions throughout a data set.", "labels": [], "entities": []}, {"text": "We also compare the performance of the various meth-1 Our code is freely available at https://github.", "labels": [], "entities": []}, {"text": "com/mpsilfve/learn-allomorphs ods to a baseline unsupervised model, Morfessor 2 , augmented with the capacity to also provide labels of allomorphs in addition to segmenting.", "labels": [], "entities": []}], "datasetContent": [{"text": "We first train each of the scoring functions presented in Section 3 on the combined training data and unsegmented test data.", "labels": [], "entities": []}, {"text": "After that, we find the optimal segmentation and label alignment for each word in the test data using each scoring function.", "labels": [], "entities": []}, {"text": "We explore all segmentations consisting of maximally 5 segments and all assignments of morphological features to the segments using a dynamic algorithm in order to speedup inference.", "labels": [], "entities": []}, {"text": "For perceptron and R-W learning, we run the training algorithm for three epochs over the train and test data.", "labels": [], "entities": []}, {"text": "The learning rate \u03b5 for R-W learning is fixed to 0.01 and the maximum possible association response r is fixed to 100.", "labels": [], "entities": [{"text": "learning rate \u03b5", "start_pos": 4, "end_pos": 19, "type": "METRIC", "confidence": 0.8880786895751953}]}, {"text": "We evaluate each scoring function with regard to three different criteria: (1) identification of morpheme boundaries, (2) identification of unlabeled morphemes, and (3) identification of labeled morphemes.", "labels": [], "entities": []}, {"text": "For each criterion, we give recall, precision and F 1 -score.", "labels": [], "entities": [{"text": "recall", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.9997290968894958}, {"text": "precision", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9996732473373413}, {"text": "F 1 -score", "start_pos": 50, "end_pos": 60, "type": "METRIC", "confidence": 0.9870855212211609}]}, {"text": "Evaluation criteria (1) and (2) are very similar, but we include both for easier comparison with earlier work in the field of unsupervised morphological segmentation.", "labels": [], "entities": [{"text": "morphological segmentation", "start_pos": 139, "end_pos": 165, "type": "TASK", "confidence": 0.6682170331478119}]}, {"text": "To illustrate our evaluation scheme, consider the following gold standard segmentation and alignment for English ping/ping ing/V.PTCP,PRS NULL/V The aligned form contains three morpheme boundaries: at index 1 (start of word), at index 4 (between the stem and participle suffix) and at index 7 (end of word).", "labels": [], "entities": []}, {"text": "It contains two unlabeled morphemes: ping and ing, and four labeled morphemes: ping/ping, ing/V.PTCP, ing/PRS and NULL/V.", "labels": [], "entities": []}, {"text": "Counts for these units are used to compute recall, precision and F 1 -score for each evaluation criterion.", "labels": [], "entities": [{"text": "recall", "start_pos": 43, "end_pos": 49, "type": "METRIC", "confidence": 0.9995957016944885}, {"text": "precision", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9995498061180115}, {"text": "F 1 -score", "start_pos": 65, "end_pos": 75, "type": "METRIC", "confidence": 0.9896735846996307}]}, {"text": "shows the results of all experiments for each language.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Data set sizes for English, Finnish,  Swedish and Turkish.", "labels": [], "entities": []}, {"text": " Table 2: Results for (a) morpheme boundaries; (b) unlabeled morphemes; (c) labeled morphemes. For  each language and each task, the scoring function delivering the best performance is shown in boldface.", "labels": [], "entities": []}]}