{"title": [{"text": "Traversal-Free Word Vector Evaluation in Analogy Space", "labels": [], "entities": [{"text": "Traversal-Free Word Vector Evaluation", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8242885321378708}]}], "abstractContent": [{"text": "In this paper, we propose an alternative evaluating metric for word analogy questions (A to B is as C to D) in word vector evaluation.", "labels": [], "entities": [{"text": "word analogy questions", "start_pos": 63, "end_pos": 85, "type": "TASK", "confidence": 0.831723173459371}, {"text": "word vector evaluation", "start_pos": 111, "end_pos": 133, "type": "TASK", "confidence": 0.761636475721995}]}, {"text": "Different from the traditional method which predicts the fourth word by the given three, we measure the similarity directly on the \"relations\" of two pairs of given words, just as shifting the relation vectors into anew analogy space.", "labels": [], "entities": []}, {"text": "Cosine and Euclidean distances are then calculated as measurements.", "labels": [], "entities": []}, {"text": "Observation and experiments shows the proposed analogy space evaluation could offer a more comprehensive evaluating result on word vectors with word analogy questions.", "labels": [], "entities": []}, {"text": "Meanwhile , computational complexity are remarkably reduced by avoiding traversing the vocabulary.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, word vector, or addressed as word embedding or distributed vector representation of word, achieves high popularity in NLP (Natural Language Processing) applications.", "labels": [], "entities": [{"text": "word vector", "start_pos": 17, "end_pos": 28, "type": "TASK", "confidence": 0.7409429550170898}]}, {"text": "A word vector is a real-valued vector, which is quite lowdimensional when comparing with traditional onehot representation of words.", "labels": [], "entities": []}, {"text": "The theory behind is believed to be the early concept of distributional representation, and modern word vector derives from the training process of neural language models (.", "labels": [], "entities": [{"text": "distributional representation", "start_pos": 57, "end_pos": 86, "type": "TASK", "confidence": 0.7088923305273056}]}, {"text": "The usage of word vectors has been proven highly efficient and successful by various NLP tasks, which further spurs the technical developments to achieve word vectors with better quality, such as Word2Vec (),), Word2Vecf ( ),,, etc.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 196, "end_pos": 204, "type": "DATASET", "confidence": 0.9570216536521912}, {"text": "Word2Vecf", "start_pos": 211, "end_pos": 220, "type": "DATASET", "confidence": 0.9493954181671143}]}, {"text": "However, discussion about how to evaluate the quality of word vectors remains open.", "labels": [], "entities": []}, {"text": "Except for actual applications, most frequently used evaluation tasks are word similarity and word analogy.", "labels": [], "entities": [{"text": "word similarity", "start_pos": 74, "end_pos": 89, "type": "TASK", "confidence": 0.7647551596164703}, {"text": "word analogy", "start_pos": 94, "end_pos": 106, "type": "TASK", "confidence": 0.7826254069805145}]}, {"text": "A word similarity task is to find the nearest word in the vector space of the given word, based on the theory that words with similar meanings should gather together.", "labels": [], "entities": [{"text": "word similarity", "start_pos": 2, "end_pos": 17, "type": "TASK", "confidence": 0.7322210818529129}]}, {"text": "Although it is widely used, arguments are made to question its capability (.", "labels": [], "entities": []}, {"text": "While in a word analogy test, three words A, B and C are given and the goal is to find a fourth word D, which logically conforms \"A to B is as C to D\".", "labels": [], "entities": [{"text": "word analogy", "start_pos": 11, "end_pos": 23, "type": "TASK", "confidence": 0.7403301298618317}]}, {"text": "Word analogy test has along history of being used in examinations or IQ tests for human and is introduced into word vector evaluation by.", "labels": [], "entities": [{"text": "Word analogy", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.6742348670959473}, {"text": "word vector evaluation", "start_pos": 111, "end_pos": 133, "type": "TASK", "confidence": 0.680855413277944}]}, {"text": "After that, it has been widely applied.", "labels": [], "entities": []}, {"text": "Efforts are made to improve the original analogy metric, such as using PAIRDIRECTION to replace 3COSADD in calculation (  or taking multiple word pairs into consideration (, but the goal is still to find word D from the vocabulary.", "labels": [], "entities": [{"text": "PAIRDIRECTION", "start_pos": 71, "end_pos": 84, "type": "METRIC", "confidence": 0.98685222864151}]}, {"text": "Besides, Linzen (2016) made a thorough assessment of word analogy test, and the most prominent finding is that if not exclude three given words, the prediction of D would almost always be C (91%) or B (5%), especially when the lineal offset between words is small.", "labels": [], "entities": [{"text": "word analogy", "start_pos": 53, "end_pos": 65, "type": "TASK", "confidence": 0.7660447359085083}]}, {"text": "This phenomenon would arouse the doubt, that whether we are searching fora word D which holds the same logic to C just as B to A, or actually searching for the nearest word of C?", "labels": [], "entities": []}, {"text": "Furthermore, the general accuracy decline in reversed analogy also suggests the incertainty of current analogy evaluation metric.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9988538026809692}]}, {"text": "In this paper, we would dig deeper into the limitations of current analogy evaluation metric in Section 2 and propose our simple alternative plan in Section 3, which is called \"Analogy Space Evaluation\".", "labels": [], "entities": [{"text": "Analogy Space Evaluation", "start_pos": 177, "end_pos": 201, "type": "TASK", "confidence": 0.6943790713946024}]}, {"text": "A significant difference of our approach is that we avoid traversing vocabulary from time to time.", "labels": [], "entities": []}, {"text": "Experiments are presented in Section 4 and finally come the conclusion and discussion.", "labels": [], "entities": []}], "datasetContent": [{"text": "Proposed analogy space shares same dimensionality of original word vector space.", "labels": [], "entities": []}, {"text": "For each analogy question, two relation vectors can be found in original word vector space, just as the definition of PAIRDIRECTION by . Mathematically, the value of such a relation vector is the same as the position of the ending point if we take the starting point as the space origin.", "labels": [], "entities": [{"text": "PAIRDIRECTION", "start_pos": 118, "end_pos": 131, "type": "METRIC", "confidence": 0.9808254837989807}]}, {"text": "This is illustrates this process by several example words of \"Nation-Capital\" and \"Nation-Language\" analogies (extracted from same test of, visualized by PCA).", "labels": [], "entities": [{"text": "PCA", "start_pos": 154, "end_pos": 157, "type": "DATASET", "confidence": 0.8417073488235474}]}, {"text": "Naturally, we expect relations with same or similar logic gather together in the analogy space.", "labels": [], "entities": []}, {"text": "In order to quantitatively evaluate the similarity, we prepare four different measurements, based on Cosine similarity or Euclidean distance respectively.", "labels": [], "entities": [{"text": "similarity", "start_pos": 40, "end_pos": 50, "type": "METRIC", "confidence": 0.9800989627838135}, {"text": "Cosine similarity", "start_pos": 101, "end_pos": 118, "type": "METRIC", "confidence": 0.9251852929592133}]}, {"text": "If we denote the vectors of word A, B, C and D as a, b, c and d, then while Cos.", "labels": [], "entities": []}, {"text": "\u2208 [\u22121, 1] and Euc.", "labels": [], "entities": [{"text": "Euc.", "start_pos": 14, "end_pos": 18, "type": "DATASET", "confidence": 0.9201105535030365}]}, {"text": "have similar definitions, but using unit word vectors in calculation.", "labels": [], "entities": []}, {"text": "shows the result of examples mentioned in and.", "labels": [], "entities": []}, {"text": "Among them, \"NC:DE-CN\" and \"NL:DE-CN\" succeed 2/2 in traditional nearest word evaluation, while all others achieve 1/2.", "labels": [], "entities": [{"text": "nearest word evaluation", "start_pos": 65, "end_pos": 88, "type": "TASK", "confidence": 0.6579290131727854}]}, {"text": "It's clear that proposed measurements could better represent the quality of these involved words or relations in a quantitative way.", "labels": [], "entities": []}, {"text": "As already mentioned, words in Grammar-2 are considered better trained than Grammar-1, and this difference can be captured by proposed measurements only.", "labels": [], "entities": []}, {"text": "And for NCs and NLs, traditional metric reports exactly the same accuracy, but as we can see, detailed similarities differ a lot.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9991539716720581}]}, {"text": "We believe these phenomena could help word analogy evaluation in the micro aspect.", "labels": [], "entities": [{"text": "word analogy evaluation", "start_pos": 38, "end_pos": 61, "type": "TASK", "confidence": 0.8786664009094238}]}, {"text": "In this section, we would do some experiments on complete analogy question sets and discuss complexity.", "labels": [], "entities": []}, {"text": "For English word vectors, we trained two sets on Wikipedia dump with different window size (w) and iteration (i) by Skip-Gram model, with same dimensionality of 300.", "labels": [], "entities": [{"text": "English word vectors", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.5920011003812155}]}, {"text": "They would further be compared with GoogleNews public set.", "labels": [], "entities": [{"text": "GoogleNews public set", "start_pos": 36, "end_pos": 57, "type": "DATASET", "confidence": 0.9495697418848673}]}, {"text": "We will evaluate these sets with proposed measurements, along with traditional analogy evaluation result and the performances of a downstream application: Sentence Boundary Detection (SBD).", "labels": [], "entities": [{"text": "Sentence Boundary Detection (SBD)", "start_pos": 155, "end_pos": 188, "type": "TASK", "confidence": 0.7448631525039673}]}, {"text": "Details of SBD implementation can be found in references (.", "labels": [], "entities": [{"text": "SBD", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.9212256669998169}]}, {"text": "Beside of English test, we also conducted several tests in German.", "labels": [], "entities": [{"text": "English test", "start_pos": 10, "end_pos": 22, "type": "DATASET", "confidence": 0.8516069054603577}]}, {"text": "Leipzig dataset () are used to training German word vectors with Word2Vec toolkit.", "labels": [], "entities": [{"text": "Leipzig dataset", "start_pos": 0, "end_pos": 15, "type": "DATASET", "confidence": 0.9485101401805878}, {"text": "Word2Vec toolkit", "start_pos": 65, "end_pos": 81, "type": "DATASET", "confidence": 0.9425531923770905}]}, {"text": "Then the vectors with different training configurations are evaluated by a set of analogy questions, which contains 2834 semantic questions in 18 categories (including some reverse logics) and 77886 syntactic questions in 9 categories.", "labels": [], "entities": []}, {"text": "We have uploaded these analogy questions in German for public access . shows the results and time expenditures of these experiments.", "labels": [], "entities": []}, {"text": "It is clear that proposed measurements have same trend with traditional metric, which means once set X achieves better result than set Y in traditional test, it would also do better in proposed alternatives.", "labels": [], "entities": []}, {"text": "Performances in downstream application SBD are also fit this trend in general.", "labels": [], "entities": []}, {"text": "Meanwhile, proposed evaluation could significantly save time, approximately 95%.", "labels": [], "entities": []}, {"text": "These facts prove that we can achieve same performance within way less time.", "labels": [], "entities": []}, {"text": "However, we also found some limitations.", "labels": [], "entities": []}, {"text": "The absolute difference between different vector sets", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Examples of Traditional Word Analogy Evaluation Result (Words in order of A, B, C & D)  Grammar-1  knowing  knew  selling  sold", "labels": [], "entities": [{"text": "Traditional Word Analogy Evaluation Result", "start_pos": 22, "end_pos": 64, "type": "TASK", "confidence": 0.7330930769443512}]}, {"text": " Table 2: Analogy Space Evaluation (Micro)  Analogy  Cos.  Euc. N-Cos. N-Euc.  Grammar-1 0.114 0.334 0.115  0.332  Grammar-2 0.324 0.410 0.320  0.415  NC: US-CN 0.310 0.380 0.314  0.356  NC: US-DE 0.367 0.423 0.376  0.411  NC: DE-CN 0.496 0.492 0.508  0.495  NL: US-CN 0.452 0.420 0.451  0.405  NL: US-DE 0.438 0.430 0.441  0.418  NL: DE-CN 0.712 0.617 0.714  0.619", "labels": [], "entities": []}, {"text": " Table 3: Analogy Space Evaluation (Macro)", "labels": [], "entities": [{"text": "Analogy Space Evaluation", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.7711154818534851}]}]}