{"title": [{"text": "UDLex: Towards Cross-language Subcategorization Lexicons", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper introduces UDLex, a computational framework for the automatic extraction of argument structures for several languages.", "labels": [], "entities": [{"text": "automatic extraction of argument structures", "start_pos": 63, "end_pos": 106, "type": "TASK", "confidence": 0.777608847618103}]}, {"text": "By exploiting the versatility of the Universal Dependency annotation scheme, our system acquires subcat-egorization frames directly from a dependency parsed corpus, regardless of the input language.", "labels": [], "entities": []}, {"text": "It thus uses a universal set of language-independent rules to detect verb dependencies in a sentence.", "labels": [], "entities": []}, {"text": "In this paper we describe how the system has been developed by adapting the LexIt (Lenci et al., 2012) framework, originally designed to describe argument structures of Ital-ian predicates.", "labels": [], "entities": [{"text": "LexIt (Lenci et al., 2012) framework", "start_pos": 76, "end_pos": 112, "type": "DATASET", "confidence": 0.918648726410336}]}, {"text": "Practical issues that arose when building argument structure representations for typologically different languages will also be discussed.", "labels": [], "entities": []}], "introductionContent": [{"text": "The argument structure of predicates is a key research area in Natural Language Processing (NLP), as verb valency has a decisive impact on sentence structure.", "labels": [], "entities": [{"text": "Natural Language Processing (NLP)", "start_pos": 63, "end_pos": 96, "type": "TASK", "confidence": 0.6671199798583984}]}, {"text": "Since including information about the syntactic-semantic realization of predicate arguments in a lexicon proved to benefit many NLP applications, e.g. recognition of textual entailment, information retrieval, machine translation and word-sense disambiguation, research in the (semi-)automatic acquisition of argument structure information from corpora has become widespread.", "labels": [], "entities": [{"text": "recognition of textual entailment", "start_pos": 151, "end_pos": 184, "type": "TASK", "confidence": 0.8710082769393921}, {"text": "information retrieval", "start_pos": 186, "end_pos": 207, "type": "TASK", "confidence": 0.7935397922992706}, {"text": "machine translation", "start_pos": 209, "end_pos": 228, "type": "TASK", "confidence": 0.7950177490711212}, {"text": "word-sense disambiguation", "start_pos": 233, "end_pos": 258, "type": "TASK", "confidence": 0.7132290750741959}, {"text": "automatic acquisition of argument structure information from corpora", "start_pos": 283, "end_pos": 351, "type": "TASK", "confidence": 0.7446710243821144}]}, {"text": "Meanwhile, the last years have also witnessed a growing interest in multilingual studies and evaluation campaigns to test the quality and the robustness of parsing software.", "labels": [], "entities": [{"text": "parsing software", "start_pos": 156, "end_pos": 172, "type": "TASK", "confidence": 0.9058953523635864}]}, {"text": "By combining these two computational linguistic topics, our work is oriented towards the elaboration of a cross-language subcategorization lexicon, i.e. an automatically-built resource that encodes combinatorial properties of verbs at the syntax-semantics interface.", "labels": [], "entities": []}, {"text": "This resource will in turn help the comparison of results among languages.", "labels": [], "entities": [{"text": "comparison", "start_pos": 36, "end_pos": 46, "type": "TASK", "confidence": 0.966513454914093}]}, {"text": "In this paper, we describe the first steps into the realization of this resource, consisting in proposing a general framework to automatically derive verb subcategorization frames regardless of the specificities of the input language.", "labels": [], "entities": []}, {"text": "For our purpose, we decided to exploit Universal Dependencies 1 (UD) annotations: UD is developed by the UD community with the final goal of creating a cross-linguistically consistent treebank annotation scheme for many languages.", "labels": [], "entities": []}, {"text": "The actual UD design combines the (universal) Stanford dependencies (), the Google universal part-of-speech tags (UPOS) () and the Interset interlingua for morpho-syntactic tag sets.", "labels": [], "entities": []}, {"text": "The aim of our project is twofold: on the one hand, we want to test if UD relations are sufficient to describe argument structure for some representative languages, and on the other hand we want to create a multilingual subcategorization lexicon to carryout a contrastive study regarding argument structures, i.e., the analysis of the syntactic realization patterns of verbs arguments across languages.", "labels": [], "entities": []}, {"text": "For instance, we would like to know if synonymous predicates across languages occur with similar or different morpho-syntactic frames, or if the same valency frame in two languages is instantiated or not by similar constructions.", "labels": [], "entities": []}, {"text": "Our aim is so to exploit UD treebanks to explore possible language universals concerning the relationship between form and meaning in argument structures.", "labels": [], "entities": []}, {"text": "This work is the first step into building a unique database where all languages are aligned, in order to facilitate the comparison among lexica, using FrameNet with links between verbs expressing similar semantic frames across different languages.", "labels": [], "entities": []}, {"text": "A frame is a schematic representation of the situations that characterizes human experience, constituted by a group of participants in the situation (Frame Elements), and representing the possible syntactic realizations of the Frame Elements for every word.", "labels": [], "entities": []}, {"text": "The paper is organized as follows: in section 2, we summarize related works on automatic lexical acquisition; in section 3, we describe the key characteristics of the LexIt framework and we then focus on the adaptation of the original module to the UD annotation scheme (section 4).", "labels": [], "entities": [{"text": "automatic lexical acquisition", "start_pos": 79, "end_pos": 108, "type": "TASK", "confidence": 0.6300886869430542}, {"text": "LexIt framework", "start_pos": 167, "end_pos": 182, "type": "DATASET", "confidence": 0.8847470879554749}]}, {"text": "We then describe the resulting lexica for English, Italian, French, German and Finnish.", "labels": [], "entities": []}, {"text": "We conclude with a general discussion about argument representation (section 5).", "labels": [], "entities": [{"text": "argument representation", "start_pos": 44, "end_pos": 67, "type": "TASK", "confidence": 0.7753233313560486}]}, {"text": "Ongoing work will be discussed in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "The standard methodology for testing the accuracy of an automatically acquired subcategorization lexicon is to evaluate extracted SCFs against a manual annotated gold standard (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9980010390281677}]}, {"text": "Although this approach may not be ideal ( ) in our case as we work with small corpora (so a dictionary may include a significant number of SCFs not attested in our data), it can provide a useful starting point.", "labels": [], "entities": []}, {"text": "For our purposes, the gold standard is represented by the valence patterns extracted from three manually-built lexical resources: \u2022 Valency Patterns Leipzig (ValPaL) -an online database 5 that stores valency information fora small sample of verbs of 36 different languages, including English (Goddard, 2013) and Italian (.", "labels": [], "entities": []}, {"text": "The aim of the project is to carry a cross-linguistic study of valency classes, choosing verbs that have the same meanings and encoding the valency information in a standard way.", "labels": [], "entities": []}, {"text": "\u2022 Dicovalence (Mertens, 2010) -a valency lexicon containing information for more than 3,700 French verbs.", "labels": [], "entities": []}, {"text": "It is based on the pronominal approach, a linguistic theory that treats pronouns as semantic primitives due to the purely linguistic nature and a finite inventory of this lexical class.", "labels": [], "entities": []}, {"text": "Accordingly, in this resource valence slots are characterized by the set of accepted pronouns, which subsume the possible lexicalizations of that slot.", "labels": [], "entities": []}, {"text": "For each language, we selected the most frequent 20 verbs among those attested in both the gold standards and in the resulting lexicons.", "labels": [], "entities": []}, {"text": "There are many differences in the way valence patterns are represented in gold standard and in UDLex, so checking which extracted frames also appear in the lexical resources is not a straightforward operation.", "labels": [], "entities": [{"text": "UDLex", "start_pos": 95, "end_pos": 100, "type": "DATASET", "confidence": 0.8758290410041809}]}, {"text": "Accordingly, we manually verified for each SCF whether it was attested in the gold standard or not.", "labels": [], "entities": [{"text": "gold standard", "start_pos": 78, "end_pos": 91, "type": "DATASET", "confidence": 0.9476794302463531}]}, {"text": "For example, ValPaL and Dicovalence use a general label for locative complements, with no information about the type of preposition involved, while UDLex considers all prepositions heading a slot as a distinctive feature for frames.", "labels": [], "entities": []}, {"text": "In these cases, we regarded the extracted frames as correct, if the gold standard contains a frame with an acceptable prepositional phrase looking at the exam-ple sentences in the lexical resources (if available) or at corpus examples.", "labels": [], "entities": []}, {"text": "The standard practice to evaluate automaticallyacquired SCFs is to filter frames with respect to some statistical score so as to exclude \"noisy\" frames caused by tagging or parsing errors.", "labels": [], "entities": []}, {"text": "In particular, only SCFs with a score above a certain threshold are evaluated.", "labels": [], "entities": []}, {"text": "We followed the same procedure resorting to Maximum Likelihood Estimation, that corresponds to the relative frequency of a scf i with a verb v j and it is calculated as follows: We then computed precision (the proportion of extracted SCFs that are attested in the gold standard), recall (the proportion of gold SCFs that have been extracted by our system) and F-measure (i.e., the harmonic mean of precision and recall) over the three gold-standards for increasing thresholds of MLE in order to reach the best scores (.", "labels": [], "entities": [{"text": "precision", "start_pos": 195, "end_pos": 204, "type": "METRIC", "confidence": 0.9968275427818298}, {"text": "recall", "start_pos": 280, "end_pos": 286, "type": "METRIC", "confidence": 0.9988861680030823}, {"text": "F-measure", "start_pos": 360, "end_pos": 369, "type": "METRIC", "confidence": 0.9989303946495056}, {"text": "precision", "start_pos": 398, "end_pos": 407, "type": "METRIC", "confidence": 0.9728867411613464}, {"text": "recall", "start_pos": 412, "end_pos": 418, "type": "METRIC", "confidence": 0.9853636622428894}, {"text": "MLE", "start_pos": 479, "end_pos": 482, "type": "METRIC", "confidence": 0.7325941920280457}]}, {"text": "Results are generally a bit lower than the stateof-the-art (see).", "labels": [], "entities": []}, {"text": "For the three resources we obtained very high recall but low precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.9996600151062012}, {"text": "precision", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.9988948702812195}]}, {"text": "The precision score is mostly affected by the fact that in UDLex our approach do not consider the argument/adjunct distinction, as it extracts all SCFs in an unsupervised way.", "labels": [], "entities": [{"text": "precision score", "start_pos": 4, "end_pos": 19, "type": "METRIC", "confidence": 0.987447589635849}]}, {"text": "On the contrary, the three gold standard resources (in particular ValPaL) code only core verb argument, ignoring possible adjuncts or circumstantial slots that could be meaningful in the description of the frame verb.", "labels": [], "entities": []}, {"text": "This also explains why recall is higher than precision in all settings.", "labels": [], "entities": [{"text": "recall", "start_pos": 23, "end_pos": 29, "type": "METRIC", "confidence": 0.9994175434112549}, {"text": "precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9993844032287598}]}, {"text": "To better understand the differences between the gold standard and the lexicons, we then performed a manual analysis  UDLex has the best performance for English, because ValPaL encodes a very small set of possible SCFs (only 21 distinct and very basic frames can be extracted from the resource).", "labels": [], "entities": []}, {"text": "All ValPaL frames are attested in our resource, but our system extracts a large number of other frames.", "labels": [], "entities": []}, {"text": "For instance, to call is associated with only one frame in ValPal subj#cpred#obj, while 17 SCFs can be found in our lexicon, most of them being without doubt relevant like subj#comp for (I called for assistance), subj#obj (I called the hotel), etc.", "labels": [], "entities": []}, {"text": "Another example is provided by the Italian reflexive pronoun si.", "labels": [], "entities": []}, {"text": "ValPal encodes very finegrained distinctions between different uses of si, such as true reflexive constructions, impersonal uses, pronominal intransitives, etc.", "labels": [], "entities": []}, {"text": "Capturing these differences goes well beyond the expressive capability of our lexicon.", "labels": [], "entities": []}, {"text": "As a matter of fact, for each languages our approach only distinguishes verb frames containing a reflexive pronoun (e.g.,subj#si#0), from those not containing any (e.g.,subj#0).", "labels": [], "entities": []}, {"text": "Consistently, we decided to not consider more fined-grained distinctions in the present evaluation.", "labels": [], "entities": []}, {"text": "Among all languages, French obtains the worst results.", "labels": [], "entities": []}, {"text": "Dicovalence is very different from ValPaL since it is based on a more fined-grained representation, leading to a number of 386 distinct subcategorization frames.", "labels": [], "entities": []}, {"text": "For example, in Dicovalence there is a distinction between the verb appeler (to call) and the construction en appeler, that has the specific meaning \"to appeal\" (cf. J'en appell\u00e8 a votre bont\u00e9 pour lui donner unedeux\u00ec eme chance.", "labels": [], "entities": []}, {"text": "\"I appeal to your kindness to give him a second chance\").", "labels": [], "entities": []}, {"text": "Obviously, this kind of information is difficult to automatically detect, and our resource does not contain this construction (although it is also questionable whether these are really two different, unrelated word senses).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2 summarizes the characteristics of  the input corpora.", "labels": [], "entities": []}, {"text": " Table 3: Syntactic profile of the verb play, giocare and jouer.", "labels": [], "entities": []}, {"text": " Table 5: Top scores with MLE thresholds.", "labels": [], "entities": [{"text": "MLE thresholds", "start_pos": 26, "end_pos": 40, "type": "METRIC", "confidence": 0.9874377548694611}]}]}