{"title": [{"text": "Building Better Open-Source Tools to Support Fairness in Automated Scoring", "labels": [], "entities": [{"text": "Scoring", "start_pos": 67, "end_pos": 74, "type": "TASK", "confidence": 0.579595148563385}]}], "abstractContent": [{"text": "Automated scoring of written and spoken responses is an NLP application that can significantly impact lives especially when deployed as part of high-stakes tests such as the GRE\u00ae and the TOEFL\u00ae.", "labels": [], "entities": [{"text": "Automated scoring of written and spoken responses", "start_pos": 0, "end_pos": 49, "type": "TASK", "confidence": 0.7663167629923139}, {"text": "GRE\u00ae", "start_pos": 174, "end_pos": 178, "type": "DATASET", "confidence": 0.7378336787223816}, {"text": "TOEFL\u00ae", "start_pos": 187, "end_pos": 193, "type": "DATASET", "confidence": 0.7239890694618225}]}, {"text": "Ethical considerations require that automated scoring algorithms treat all test-takers fairly.", "labels": [], "entities": []}, {"text": "The educational measurement community has done significant research on fairness in assessments and automated scoring systems must incorporate their recommendations.", "labels": [], "entities": []}, {"text": "The best way to do that is by making available automated, non-proprietary tools to NLP researchers that directly incorporate these recommendations and generate the analyses needed to help identify and resolve biases in their scoring systems.", "labels": [], "entities": []}, {"text": "In this paper, we attempt to provide such a solution.", "labels": [], "entities": []}], "introductionContent": [{"text": "Natural Language Processing (NLP) applications now form a large part of our everyday lives.", "labels": [], "entities": []}, {"text": "As researchers who build such applications, we have a responsibility to ensure that we prioritize the ideas of fairness and transparency and not just blindly pursue better algorithmic performance.", "labels": [], "entities": []}, {"text": "In this paper, we discuss the ethical considerations pertaining to automated scoring of written or spoken test responses, referred to as \"constructed responses\".", "labels": [], "entities": []}, {"text": "Automated scoring is an NLP application which aims to automatically predict a score for such responses.", "labels": [], "entities": [{"text": "Automated scoring", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6366255432367325}]}, {"text": "We focus on automated systems designed to score open-ended constructed response questions.", "labels": [], "entities": []}, {"text": "Such systems generally use text and speech processing techniques to extract a set of features from responses which are then combined into a scoring model to predict the final score assigned by a human rater.", "labels": [], "entities": []}, {"text": "Test scores whether assigned by human raters or computers can have a significant effect on people's lives and, therefore, must be fair to all test takers.", "labels": [], "entities": []}, {"text": "Automated scoring systems may offer some advantages over human raters, e.g., higher score consistency ().", "labels": [], "entities": [{"text": "consistency", "start_pos": 90, "end_pos": 101, "type": "METRIC", "confidence": 0.7523786425590515}]}, {"text": "Yet, like any other machine learning algorithm, models used for score prediction may inadvertently encode discrimination into their decisions due to biases or other imperfections in the training data, spurious correlations, and other factors.", "labels": [], "entities": [{"text": "score prediction", "start_pos": 64, "end_pos": 80, "type": "TASK", "confidence": 0.7243860960006714}]}, {"text": "The paper has the following structure.", "labels": [], "entities": []}, {"text": "We first draw awareness to the psychometric research and recommendations on quantifying potential biases in automated scoring and how it relates to the ideas of fairness, accountability, and transparency in machine learning (FATML).", "labels": [], "entities": []}, {"text": "The second half of the paper presents an open-source tool called RSMTool 2 for developers of automated scoring models which directly integrates these psychometric recommendations.", "labels": [], "entities": []}, {"text": "Since such developers are likely to be NLP or machine learning researchers, the tool provides an important bridge from the educational measurement side to the NLP side.", "labels": [], "entities": []}, {"text": "Next, we discuss further challenges related to fairness in automated scoring that are not currently addressed by RSMTool as well as methods for avoiding bias in automated scoring rather than just detecting it.", "labels": [], "entities": []}, {"text": "The paper concludes with a discussion of how these tools and methodologies may, in fact, be ap-plicable to other NLP applications beyond automated scoring.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}