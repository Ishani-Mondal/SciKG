{"title": [{"text": "Annotating Errors in Student Texts: First Experiences and Experiments", "labels": [], "entities": [{"text": "Annotating Errors in Student Texts", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8748536109924316}]}], "abstractContent": [{"text": "We describe the creation of an annotation layer for word-based writing errors fora corpus of student writings.", "labels": [], "entities": []}, {"text": "The texts are written in Swedish by students between 9 and 19 years old.", "labels": [], "entities": []}, {"text": "Our main purpose is to identify errors regarding spelling, split compounds and merged words.", "labels": [], "entities": []}, {"text": "In addition , we also identify simple word-based grammatical errors, including morphological errors and extra words.", "labels": [], "entities": []}, {"text": "In this paper we describe the corpus and the annotation process, including detailed descriptions of the error types and guidelines.", "labels": [], "entities": []}, {"text": "We find that we can perform this annotation with a substantial inter-annotator agreement, but that there are still some remaining issues with the annotation.", "labels": [], "entities": []}, {"text": "We also report results on two pilot experiments regarding spelling correction and the consistency of downstream NLP tools, to exemplify the usefulness of the annotated corpus.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 58, "end_pos": 77, "type": "TASK", "confidence": 0.9225318729877472}]}], "introductionContent": [{"text": "The use of automatic tools for the detection and correction of writing errors is not new, and there are many tools that can accurately correct errors in standard texts in many languages, including Swedish.", "labels": [], "entities": [{"text": "detection and correction of writing errors", "start_pos": 35, "end_pos": 77, "type": "TASK", "confidence": 0.8155169238646826}]}, {"text": "However, most of the existing tools are not freely available and usually do not provide any information on the error type.", "labels": [], "entities": []}, {"text": "Automatic grammatical correction of texts written by language learners, especially second language learners is even more problematic with various types of errors.", "labels": [], "entities": [{"text": "grammatical correction of texts written by language learners", "start_pos": 10, "end_pos": 70, "type": "TASK", "confidence": 0.8600612804293633}]}, {"text": "In order to investigate language learning processes, to give students feedback, and to develop computer-assisted language learning and teaching applications (ICALL) by using NLP tools like taggers and parsers for automatic analysis of nonstandard texts, it is important to be able to identify and classify various types of grammatical errors.", "labels": [], "entities": []}, {"text": "Data collection and analysis by creating a corpus on learner language with annotation on various linguistic layers from part-of-speech (POS) to syntactic analysis is a first step.", "labels": [], "entities": [{"text": "Data collection", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.683977797627449}, {"text": "syntactic analysis", "start_pos": 144, "end_pos": 162, "type": "TASK", "confidence": 0.7345842123031616}]}, {"text": "In parallel to corpus creation, tools can be developed for the automatic processing of learner data which can be used for analysis of new texts.", "labels": [], "entities": [{"text": "corpus creation", "start_pos": 15, "end_pos": 30, "type": "TASK", "confidence": 0.7778803110122681}]}, {"text": "In this paper we present the development of a corpus on learner language of Swedish, the Uppsala Corpus of Student Writings ( by creating a normalization layer identifying erroneous constructions on top of an already existing automatic linguistic annotation.", "labels": [], "entities": [{"text": "Uppsala Corpus of Student Writings", "start_pos": 89, "end_pos": 123, "type": "DATASET", "confidence": 0.9698391318321228}]}, {"text": "In this work humans annotate word-based errors focusing on spelling, split compounds, merged words, and simple grammatical errors.", "labels": [], "entities": []}, {"text": "The original corpus includes 2,500 student writings from different age groups and grades, written by students who study Swedish (L1) or Swedish as a second language (L2).", "labels": [], "entities": []}, {"text": "The group of students who study Swedish as a school language consists both of native Swedish speakers, and non-native speakers who have a good command of Swedish, and those essays thus contain texts written both by L1 and L2 speakers.", "labels": [], "entities": []}, {"text": "We describe the creation of the annotation layer for normalization fora subset of this corpus and perform two initial experiments, exemplifying how this corpus can be used.", "labels": [], "entities": []}, {"text": "The corpus presented is intended to be useful for researchers in computational linguistics as well as for scholars interested in student writings and assessment of Swedish as L1 and/or L2.", "labels": [], "entities": []}, {"text": "From a computational linguistics perspective, the data will allow us to develop, train, and evaluate models for error identification and correction that are particularly geared towards student writings in Swedish,  possibly also adapting the models to different age groups, levels, and for students of Swedish as L1 or L2.", "labels": [], "entities": [{"text": "error identification and correction", "start_pos": 112, "end_pos": 147, "type": "TASK", "confidence": 0.784797765314579}]}, {"text": "Being able to correct errors is also important in order to achieve good performance on downstream tasks like tagging and parsing.", "labels": [], "entities": [{"text": "tagging", "start_pos": 109, "end_pos": 116, "type": "TASK", "confidence": 0.9667952656745911}]}, {"text": "From a writing development perspective, the normalized corpus can allow analysis of writing skills development during school years in Swedish as L1 or L2.", "labels": [], "entities": []}, {"text": "The error identification accomplished in this corpus is also interesting from an assessment and grading perspective, and can contribute to the development of advanced computer-assisted language learning and teaching applications.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we will describe two pilot experiments that shows the usefulness of the human error annotation layer of UCSW.", "labels": [], "entities": [{"text": "UCSW", "start_pos": 120, "end_pos": 124, "type": "DATASET", "confidence": 0.9193872809410095}]}, {"text": "In the first experiment we show how the training data can be used for training a simple spellchecker targeting student texts.", "labels": [], "entities": []}, {"text": "In the second experiment we show how much the errors in the corpus affects automatic NLP tools, exemplified by a tagger and parser.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Distribution of texts by year and Sw/SwSL.", "labels": [], "entities": []}, {"text": " Table 2: Inter-annotator agreement and kappa for  the 6-way classification between error types or  correct, including and excluding the cases where  both annotators judged a word as correct.", "labels": [], "entities": [{"text": "kappa", "start_pos": 40, "end_pos": 45, "type": "METRIC", "confidence": 0.9218137860298157}]}, {"text": " Table 3: Confusion matrix for annotations by an- notators A1 and A2, empty cells means no such  confusions.", "labels": [], "entities": [{"text": "Confusion", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9652060866355896}]}, {"text": " Table 4: Different error types in the annotated  data.", "labels": [], "entities": []}]}