{"title": [{"text": "Creating and Validating Multilingual Semantic Representations for Six Languages: Expert versus Non-Expert Crowds", "labels": [], "entities": [{"text": "Creating and Validating Multilingual Semantic Representations", "start_pos": 0, "end_pos": 61, "type": "TASK", "confidence": 0.7686623235543569}]}], "abstractContent": [{"text": "Creating high-quality wide-coverage multilingual semantic lexicons to support knowledge-based approaches is a challenging time-consuming manual task.", "labels": [], "entities": []}, {"text": "This has traditionally been performed by linguistic experts: a slow and expensive process.", "labels": [], "entities": []}, {"text": "We present an experiment in which we adapt and evaluate crowdsourc-ing methods employing native speakers to generate a list of coarse-grained senses under a common multilingual semantic tax-onomy for sets of words in six languages.", "labels": [], "entities": []}, {"text": "451 non-experts (including 427 Mechanical Turk workers) and 15 expert participants semantically annotated 250 words manually for Arabic, Chinese, English, Italian, Portuguese and Urdu lexicons.", "labels": [], "entities": []}, {"text": "In order to avoid erroneous (spam) crowd-sourced results, we used a novel task-specific two-phase filtering process where users were asked to identify synonyms in the target language, and remove erroneous senses.", "labels": [], "entities": []}], "introductionContent": [{"text": "Machine understanding of the meaning of words, phrases, sentences and documents has challenged computational linguists since the 1950s, and much progress has been made at multiple levels.", "labels": [], "entities": [{"text": "Machine understanding of the meaning of words, phrases, sentences and documents", "start_pos": 0, "end_pos": 79, "type": "TASK", "confidence": 0.823637632223276}]}, {"text": "Different types of semantic annotation have been developed, such as word sense disambiguation, semantic role labelling, named entity recognition, sentiment analysis and content analysis.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 68, "end_pos": 93, "type": "TASK", "confidence": 0.6654736797014872}, {"text": "semantic role labelling", "start_pos": 95, "end_pos": 118, "type": "TASK", "confidence": 0.672517200311025}, {"text": "named entity recognition", "start_pos": 120, "end_pos": 144, "type": "TASK", "confidence": 0.6093927423159281}, {"text": "sentiment analysis", "start_pos": 146, "end_pos": 164, "type": "TASK", "confidence": 0.9351255595684052}, {"text": "content analysis", "start_pos": 169, "end_pos": 185, "type": "TASK", "confidence": 0.7447848916053772}]}, {"text": "Common to all of these tasks, in the supervised setting, is the requirement fora wide coverage semantic lexicon acting as a knowledge base from which to selector derive potential word or phrase level sense annotations.", "labels": [], "entities": []}, {"text": "The creation of large-scale semantic lexical resources is a time-consuming and difficult task.", "labels": [], "entities": []}, {"text": "For new languages, regional varieties, dialects, or domains the task will need to be repeated and then revised overtime as word meanings evolve.", "labels": [], "entities": []}, {"text": "In this paper, we report on work in which we adapt crowdsourcing techniques to speedup the creation of new semantic lexical resources.", "labels": [], "entities": []}, {"text": "We evaluate how efficient the approach is, and how robust the semantic representation is across six languages.", "labels": [], "entities": []}, {"text": "The task that we focus on here is a particularly challenging one.", "labels": [], "entities": []}, {"text": "Given a word, each annotator must decide on its meaning and assign the word to single or multiple tags in a pre-existing semantic taxonomy.", "labels": [], "entities": []}, {"text": "This task is similar to that undertaken by trained lexicographers during the process of writing or updating dictionary entries.", "labels": [], "entities": []}, {"text": "Even for experts, this is a complex task.", "labels": [], "entities": []}, {"text": "highlighted a number of issues related to lexicographers 'lumping' or 'splitting' senses of a word and cautioned that even lexicographers do not believe in words having a \"discrete, non-overlapping set of senses\".", "labels": [], "entities": []}, {"text": "showed that interannotator agreement is very low in sense tagging using a traditional dictionary.", "labels": [], "entities": [{"text": "agreement", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.8377435207366943}, {"text": "sense tagging", "start_pos": 52, "end_pos": 65, "type": "TASK", "confidence": 0.780127614736557}]}, {"text": "For our purpose, we use the USAS taxonomy.", "labels": [], "entities": [{"text": "USAS taxonomy", "start_pos": 28, "end_pos": 41, "type": "DATASET", "confidence": 0.9868610203266144}]}, {"text": "If a linguist were undertaking this task, as they have done in the past with) and Russian () USAS taxonomies, they would first spend sometime learning the semantic taxonomy.", "labels": [], "entities": [{"text": "USAS taxonomies", "start_pos": 93, "end_pos": 108, "type": "DATASET", "confidence": 0.939992219209671}]}, {"text": "In this experimental scenario, we aim to investigate whether or not non-expert native speakers can succeed on the word-to-senses classification task without being trained on the taxonomy in advance, therefore mitigating a significant overhead for the work.", "labels": [], "entities": [{"text": "word-to-senses classification task", "start_pos": 114, "end_pos": 148, "type": "TASK", "confidence": 0.7805529236793518}]}, {"text": "In addition, further motivation for our experiments is to validate the applicability of the USAS taxonomy (), with a non-expert crowd, as a framework for multilingual sense representation.", "labels": [], "entities": [{"text": "USAS taxonomy", "start_pos": 92, "end_pos": 105, "type": "DATASET", "confidence": 0.9748019874095917}, {"text": "multilingual sense representation", "start_pos": 154, "end_pos": 187, "type": "TASK", "confidence": 0.6478004157543182}]}, {"text": "The USAS taxonomy was selected for this experiment since it offers a manageable coarse-grained set of categories that have already been applied to a number of languages.", "labels": [], "entities": [{"text": "USAS taxonomy", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.9618399441242218}]}, {"text": "This taxonomy is distinct from other potential choices, such as WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 64, "end_pos": 71, "type": "DATASET", "confidence": 0.9741034507751465}]}, {"text": "The USAS tagset is originally loosely based on the Longman Lexicon of Contemporary English and has a hierarchical structure with 21 major domains (see table 1) subdividing into three levels.", "labels": [], "entities": [{"text": "USAS tagset", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.9812146723270416}, {"text": "Longman Lexicon of Contemporary English", "start_pos": 51, "end_pos": 90, "type": "DATASET", "confidence": 0.9545857191085816}]}, {"text": "Versions of the USAS tagger or tagset exist in 15 languages in total and for each language, native speakers have re-evaluated the applicability of the tagset with some specific extensions for Chinese) but otherwise the tagset is stable across all languages.", "labels": [], "entities": [{"text": "USAS", "start_pos": 16, "end_pos": 20, "type": "DATASET", "confidence": 0.9598708748817444}]}, {"text": "For each language tagger, separate linguistic resources (lexicons) have been created, but they all use the same taxonomy.", "labels": [], "entities": []}, {"text": "In terms of main contributions, our research goes beyond the previous work on crowdsourcing word meanings which requires workers to pick a word sense from an existing list that matches provided contextual examples, such as a concordance list.", "labels": [], "entities": []}, {"text": "In our work, we require the participants to define the list of all possible senses that a word could take in different contexts.", "labels": [], "entities": []}, {"text": "We also see that our two-stage filtering process tailored for this task helps to improve results.", "labels": [], "entities": []}, {"text": "We compare interrater scores for two groups of experts and nonexperts to examine the feasibility of extracting high-quality semantic lexicons via the untrained crowd.", "labels": [], "entities": []}, {"text": "Non-experts achieved results between 45-97% for accuracy, between 48-92% for completeness, with an average of 18% of tasks having erroneous senses being left in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9990647435188293}, {"text": "completeness", "start_pos": 77, "end_pos": 89, "type": "METRIC", "confidence": 0.9550088047981262}]}, {"text": "Experts scored 64-96% for accuracy, 72-95% for completeness, but achieve better results in terms of only 1% of erroneous senses left behind.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.999313235282898}, {"text": "completeness", "start_pos": 47, "end_pos": 59, "type": "METRIC", "confidence": 0.9859991669654846}]}, {"text": "Our experimental results show that the non-expert crowdsourced annotation process is of a good quality and comparable to that of expert linguists in some cases, although there are variations across different languages.", "labels": [], "entities": []}, {"text": "Crowdsourcing provides a promising approach for the speedy generation and expansion of semantic lexicons on a large scale.", "labels": [], "entities": []}, {"text": "It also allows us to validate the semantic representations embedded in our taxonomy in the multilingual setting.", "labels": [], "entities": []}], "datasetContent": [{"text": "We test the wisdom of the crowd in building lexicons and applying the same multilingual semantic representation in six languages: Arabic, Chinese, English, Italian, Portuguese and Urdu.", "labels": [], "entities": []}, {"text": "These languages were selected to provide a range of language families, inflectional and derivational morphology, while covering significant number of speakers worldwide.", "labels": [], "entities": []}, {"text": "For each language, we randomly selected 250 words.", "labels": [], "entities": []}, {"text": "All experiments presented here use the USAS taxonomy to describe semantic categories).", "labels": [], "entities": [{"text": "USAS taxonomy", "start_pos": 39, "end_pos": 52, "type": "DATASET", "confidence": 0.9772538244724274}]}, {"text": "Obtaining reliable results from the crowd remains a challenging task (), which requires a careful experimental design and preselection of crowdsourcers.", "labels": [], "entities": []}, {"text": "In our experiments, we worked on minimising the effort required by participants through designing a user-friendly interface.", "labels": [], "entities": []}, {"text": "Aside from copying the final output code to a text-box everything else is done using mouse clicks.", "labels": [], "entities": []}, {"text": "Poorly designed experiments can negatively affect the quality of the results conducted by MTurk workers (.", "labels": [], "entities": [{"text": "MTurk", "start_pos": 90, "end_pos": 95, "type": "DATASET", "confidence": 0.6713751554489136}]}, {"text": "Feedback from a short sample run with local testers helped us update the interface and provide more information to make the task efficient.", "labels": [], "entities": []}, {"text": "shows a sample task for the word 'car'.", "labels": [], "entities": []}, {"text": "The majority of the testers were able to complete the task within five minutes.", "labels": [], "entities": []}, {"text": "In response to feedback by some of the testers we provided the \"Instructions\" section in the six languages under consideration.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Summary of performance [Non experts]", "labels": [], "entities": []}, {"text": " Table 3: Summary of performance with Second  Filter [Non experts]", "labels": [], "entities": []}, {"text": " Table 4: Summary of performance [Experts]", "labels": [], "entities": []}, {"text": " Table 5: Total Inter-rater agreement [Experts].", "labels": [], "entities": []}, {"text": " Table 6: Total Inter-rater agreement [Non Ex- perts].", "labels": [], "entities": []}]}