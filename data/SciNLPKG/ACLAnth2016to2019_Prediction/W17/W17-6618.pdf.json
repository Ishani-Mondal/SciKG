{"title": [{"text": "Evaluating Word Embeddings for Sentence Boundary Detection in Speech Transcripts", "labels": [], "entities": [{"text": "Sentence Boundary Detection in Speech Transcripts", "start_pos": 31, "end_pos": 80, "type": "TASK", "confidence": 0.8101181387901306}]}], "abstractContent": [{"text": "This paper is motivated by the automation of neuropsychological tests involving discourse analysis in the retellings of narratives by patients with potential cognitive impairment.", "labels": [], "entities": []}, {"text": "In this scenario the task of sentence boundary detection in speech transcripts is important as discourse analysis involves the application of Natural Language Processing tools, such as taggers and parsers, which depend on the sentence as a processing unit.", "labels": [], "entities": [{"text": "sentence boundary detection", "start_pos": 29, "end_pos": 56, "type": "TASK", "confidence": 0.7205155889193217}, {"text": "discourse analysis", "start_pos": 95, "end_pos": 113, "type": "TASK", "confidence": 0.7304927557706833}]}, {"text": "Our aim in this paper is to verify which embedding induction method works best for the sentence boundary detection task, specifically whether it be those which were proposed to capture semantic, syntactic or morphological similarities.", "labels": [], "entities": [{"text": "sentence boundary detection task", "start_pos": 87, "end_pos": 119, "type": "TASK", "confidence": 0.7357281967997551}]}], "introductionContent": [{"text": "The concept of a sentence in written or spoken texts is important in several Natural Language Processing (NLP) tasks, such as morpho-syntactic analysis, sentiment analysis, and speech processing, among others.", "labels": [], "entities": [{"text": "morpho-syntactic analysis", "start_pos": 126, "end_pos": 151, "type": "TASK", "confidence": 0.7806524932384491}, {"text": "sentiment analysis", "start_pos": 153, "end_pos": 171, "type": "TASK", "confidence": 0.9628630578517914}, {"text": "speech processing", "start_pos": 177, "end_pos": 194, "type": "TASK", "confidence": 0.7610252201557159}]}, {"text": "However, punctuation marks that constitute a sentence boundary are ambiguous The Disambiguation of Punctuation Marks (DPM) task analyzes punctuation marks in texts and indicates whether they correspond to a sentence boundary.", "labels": [], "entities": []}, {"text": "The purpose of the DPM task is to answer the question: Among the tokens of punctuation marks in a text, which of them correspond to sentence boundaries?", "labels": [], "entities": []}, {"text": "The Sentence Boundary Detection (SBD) task is very similar to DPM, both of which attempt to break a text into sequential units that correspond to sentences, where DPM is text-based and SBD can be applied to either written text or audio transcriptions and often for clauses, which do not necessarily end in final punctuation marks but are complete thoughts nonetheless.", "labels": [], "entities": [{"text": "Sentence Boundary Detection (SBD) task", "start_pos": 4, "end_pos": 42, "type": "TASK", "confidence": 0.8946382914270673}]}, {"text": "However, performing SBD in speech texts is more complicated due to the lack of information such as punctuation and capitalization; moreover text output is susceptible to recognition errors, in case of Automatic Speech Recognition (ASR) systems are used for automatic transcriptions.", "labels": [], "entities": [{"text": "SBD", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9790673851966858}, {"text": "Automatic Speech Recognition (ASR)", "start_pos": 201, "end_pos": 235, "type": "TASK", "confidence": 0.7631908456484476}]}, {"text": "SBD from speech transcriptions is a task which has gained more attention in the last decades due to the increasing popularity of ASR software which automatically generate text from audio input.", "labels": [], "entities": [{"text": "SBD from speech transcriptions", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.9043292701244354}, {"text": "ASR", "start_pos": 129, "end_pos": 132, "type": "TASK", "confidence": 0.973892331123352}]}, {"text": "This task can also be applied to written texts, like online product reviews, in order to better their intelligibility and facilitate the posterior use of NLP tools.", "labels": [], "entities": []}, {"text": "It is important to point out that the differences between spoken and written texts are notable, mainly when we take into consideration the size of the utterances and the number of disfluencies provided in speech.", "labels": [], "entities": []}, {"text": "shows the result of a transcript from a neuropsychological retelling task that does not include either capitalization or sentence segmentation, preventing the direct application of NLP methods that rely on these marks for their correct use, such as taggers and parsers.", "labels": [], "entities": [{"text": "sentence segmentation", "start_pos": 121, "end_pos": 142, "type": "TASK", "confidence": 0.7436531782150269}]}, {"text": "One can easily note that this type of text differs greatly in style and form from written/edited text (on which most NLP tools are trained), such as text found in novels or a newspaper.", "labels": [], "entities": []}, {"text": "cinderela a hist\u00f3ria da cinderela...", "labels": [], "entities": []}, {"text": "ela:: encontra um cavaleiro com com um cavalo dai ela fica amiga desse cavalo tudo isso \u00e9 pr\u00f3ximo de um castelo e ela vai pro castelo pro castelo na verdade ela vai trabalhar no castelo n\u00e9 e ela come\u00e7a a fazer l\u00e1...", "labels": [], "entities": []}, {"text": "These tests are applied by clinicians who tell a story to patients who are instructed to try and remember as many details as possible so that they may retell it.", "labels": [], "entities": []}, {"text": "The evaluation of language in discourse production, mainly in narratives, is an attractive alternative because it allows the analysis of linguistic microstructures and phonetic-phonological, morpho-syntactic, semantic-lexical components, as well as semantic-pragmatic macrostructures.", "labels": [], "entities": []}, {"text": "Neuropsychological tests are used in clinical settings for detection, progress monitoring and treatment observation in patients with dementias.", "labels": [], "entities": []}, {"text": "In an ideal scenario we would like to automate the application of neuropsychological tests and the discourse analysis of the retellings.", "labels": [], "entities": [{"text": "discourse analysis", "start_pos": 99, "end_pos": 117, "type": "TASK", "confidence": 0.7037509381771088}]}, {"text": "NLP applications generally receive text as input; therefore, words can be considered the basic processing unit.", "labels": [], "entities": []}, {"text": "In this case, it is important that they are represented in away which carries the load of all relevant information.", "labels": [], "entities": []}, {"text": "In the current approach used here, words are induced representations in a dense vector space.", "labels": [], "entities": []}, {"text": "These representations are known as word embeddings; able to capture semantic, syntactic and morphological information from large unannotated corpora.", "labels": [], "entities": []}, {"text": "Various studies show that textual information is important for SBD.", "labels": [], "entities": [{"text": "SBD", "start_pos": 63, "end_pos": 66, "type": "TASK", "confidence": 0.9935077428817749}]}, {"text": "Even though textual information is a strong indicator for sentence delimitation, boundaries are often associated with prosodic information, like pause duration, change in pitch and change in energy.", "labels": [], "entities": [{"text": "sentence delimitation", "start_pos": 58, "end_pos": 79, "type": "TASK", "confidence": 0.7396572232246399}]}, {"text": "However, the extraction of this type of information requires the use of high quality resources, and consequently, few resources with prosodic information are available.", "labels": [], "entities": []}, {"text": "On the other hand, textual information can easily be extracted in large scale from the web.", "labels": [], "entities": []}, {"text": "Textual information can also be represented in various ways for SBD, for example, n-gram based techniques have presented good results for SBD; however, in contrast to word embeddings, they are induced representations in a sparse vector space.", "labels": [], "entities": [{"text": "SBD", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.9712059497833252}, {"text": "SBD", "start_pos": 138, "end_pos": 141, "type": "TASK", "confidence": 0.954309344291687}]}, {"text": "Our aim in this paper is to verify which embedding induction method works best for the SBD task, specifically whether it be those which were proposed to capture seman-tic, syntactic or morphological similarities.", "labels": [], "entities": [{"text": "SBD task", "start_pos": 87, "end_pos": 95, "type": "TASK", "confidence": 0.9327441155910492}]}, {"text": "For example, we imagine that methods that capture morphological similarities may benefit the SBD performance for impaired speech, since a large number of words produced in this type of speech are out-of-vocabulary words.The paper is organized as follows.", "labels": [], "entities": [{"text": "SBD", "start_pos": 93, "end_pos": 96, "type": "TASK", "confidence": 0.9718637466430664}]}, {"text": "Section 2 presents related work on SBD using word embeddings; Section 3 describes the word embedding models evaluated in this paper; Section 4 presents our experimental setup, describing the datasets, method, and preprocessing steps used; Section 5 presents our findings and discussions.", "labels": [], "entities": [{"text": "SBD", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.9727890491485596}]}, {"text": "Finally, Section 6 concludes the paper and outlines some future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "The datasets were divided into two categories: impaired speech and prepared speech.", "labels": [], "entities": []}, {"text": "Impaired speech is not only spontaneous, but also noisy.", "labels": [], "entities": [{"text": "Impaired speech", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7147185504436493}]}, {"text": "The noise is produced internally due to the impaired neuropsychological condition of the participants studied.", "labels": [], "entities": []}, {"text": "When people participate in neuropsychological tests, they produce the following phenomena: syntactically malformed sentences; mispronounced words (modifying the original morphology); low quality prosody (due to the shallow voices of the participants and/or abnormal fluctuations in vocal quality); and in general a great quantity and variety of types of disfluencies.", "labels": [], "entities": []}, {"text": "The first dataset of discourse tests is a set of impaired speech narratives, based on a book of sequenced pictures from the well-known Cinderella story.", "labels": [], "entities": []}, {"text": "This dataset consists of 60 narrative texts told by Brazilian Portuguese speakers; 20 healthy subjects, called controls (CTL), 20 patients with Alzheimer's disease (AD), and 20 patients with Mild Cognitive Impairment (MCI), diagnosed at Medical School of the University of S\u00e3o Paulo (FMUSP) and also used in . The second dataset was made available by the FalaBrasil project, and its contents are structured in the same way as the Brazilian Constitution from 1988].", "labels": [], "entities": []}, {"text": "The speech in this corpus can be categorized as prepared and also as read speech.", "labels": [], "entities": []}, {"text": "To use these files in our scenario a preprocessing step was necessary, which removed lexical tips which indicate the beginning of articles, The corpus used to induce the vectors is made up of text from Wikipedia in 2016, a news crawler which collected articles from the G1 portal and the PLN-BR corpus.", "labels": [], "entities": [{"text": "Wikipedia in 2016", "start_pos": 202, "end_pos": 219, "type": "DATASET", "confidence": 0.9116499225298563}, {"text": "PLN-BR corpus", "start_pos": 288, "end_pos": 301, "type": "DATASET", "confidence": 0.9259741604328156}]}, {"text": "We also executed some basic preprocessing stepson this corpus, being that we forced all of the text to lowercase forms and separated each token from punctuation marks and tokenized the text using whitespace.", "labels": [], "entities": []}, {"text": "We do not remove stopwords.", "labels": [], "entities": []}, {"text": "After these steps, the embedding induction on the corpus returned \u223c356M tokens, of which \u223c1.7M were distinct.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Summary of corpora utilized in the experiments.", "labels": [], "entities": []}]}