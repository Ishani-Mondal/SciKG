{"title": [{"text": "Predicting News Values from Headline Text and Emotions", "labels": [], "entities": [{"text": "Predicting News Values from Headline Text and Emotions", "start_pos": 0, "end_pos": 54, "type": "TASK", "confidence": 0.8625621348619461}]}], "abstractContent": [{"text": "We present a preliminary study on predicting news values from headline text and emotions.", "labels": [], "entities": [{"text": "predicting news", "start_pos": 34, "end_pos": 49, "type": "TASK", "confidence": 0.8819473385810852}]}, {"text": "We perform a multivariate analysis on a dataset manually annotated with news values and emotions, discovering interesting correlations among them.", "labels": [], "entities": []}, {"text": "We then train two competitive machine learning models-an SVM and a CNN-to predict news values from headline text and emotions as features.", "labels": [], "entities": []}, {"text": "We find that, while both models yield a satisfactory performance , some news values are more difficult to detect than others, while some profit more from including emotion information.", "labels": [], "entities": []}], "introductionContent": [{"text": "News values maybe considered as a system of criteria applied to decide about the inclusion or exclusion of material) and about the aspects of the selected material that should be emphasized by means of headlines.", "labels": [], "entities": []}, {"text": "In fact, the informative value of headlines lays its foundations in their capability of optimizing the relevance of their stories for their users.", "labels": [], "entities": []}, {"text": "To the intent of being optimizers of the news relevance, headlines carryout a set of different functions while meeting two needs: attracting users' attention and summarizing contents.", "labels": [], "entities": [{"text": "summarizing contents", "start_pos": 162, "end_pos": 182, "type": "TASK", "confidence": 0.9248066246509552}]}, {"text": "In order to attract users' attention, headlines should provide the triggers for the emotional impact of the news, accounting emotional aspects related to the participants of the event or to the actions performed.", "labels": [], "entities": []}, {"text": "As far as the summarization of contents is concerned, headlines maybe distinguished on the basis of two main goals: headlines that represent the abstract of the main event and headlines that promote one of the details in the news story.", "labels": [], "entities": [{"text": "summarization of contents", "start_pos": 14, "end_pos": 39, "type": "TASK", "confidence": 0.8975019256273905}]}, {"text": "Furthermore, recognize two simultaneous functions: \"a semantic function, regarding the referential text, and a pragmatic function, regarding the reader (the receiver) to whom the text is addressed.\"", "labels": [], "entities": []}, {"text": "In this work we present a preliminary study on predicting news values from headline text and emotions.", "labels": [], "entities": [{"text": "predicting news", "start_pos": 47, "end_pos": 62, "type": "TASK", "confidence": 0.8874886333942413}]}, {"text": "The study is driven by two research questions: what are the relations among news values conveyed by headlines and the human emotions triggered by them, and to what extent can a machine learning classifier successfully identify the news values conveyed by headlines, using merely text or text and triggered emotions as input?", "labels": [], "entities": []}, {"text": "To this end, we manually annotated an existing dataset of headlines and emotions with news values.", "labels": [], "entities": []}, {"text": "To answer the first question, we carried out a multivariate analysis, and discovered interesting correlations among news values and emotions.", "labels": [], "entities": []}, {"text": "To answer our second research question, we trained two competitive machine learning models -a support vector machine (SVM) and a convolutional neural network (CNN) -to predict news values from headline text and emotions.", "labels": [], "entities": []}, {"text": "Results indicate that, while both models yield a satisfactory performance, some news values are more difficult to detect, some profit from including emotion information, and CNN performs better than SVM on this task.", "labels": [], "entities": []}], "datasetContent": [{"text": "As a starting point, we adopt the dataset proposed for the.", "labels": [], "entities": []}, {"text": "The dataset consists of 1250 headlines extracted from major newspapers such as New York Times, CNN, BBC News, and Google News.", "labels": [], "entities": []}, {"text": "Each headline has been manually annotated for valence and six emotions (Anger, Disgust, Fear, Joy, Sadness, and Surprise) on a scale from 0 to 100.", "labels": [], "entities": [{"text": "valence", "start_pos": 46, "end_pos": 53, "type": "METRIC", "confidence": 0.9944615364074707}, {"text": "Surprise", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.9419732689857483}]}, {"text": "In this work, we use only the emotion labels, and not the valence labels.", "labels": [], "entities": []}, {"text": "On top of the emotion annotations, we added an additional layer of news value labels.", "labels": [], "entities": []}, {"text": "Our starting point for the annotation was the news values classification scheme proposed by.", "labels": [], "entities": [{"text": "news values classification", "start_pos": 46, "end_pos": 72, "type": "TASK", "confidence": 0.7429040670394897}]}, {"text": "This study proposes a set of fifteen values, corresponding to a set of requirements that news stories have to satisfy to be selected for publishing.", "labels": [], "entities": []}, {"text": "For the annotation, we decided to omit two news values whose annotation necessitates contextual information: \"Audio-visuals\", which signals the presence of infographics accompanying the news text, and \"News organization's agenda\", which refers to stories related to the news organization's own agenda.", "labels": [], "entities": []}, {"text": "This resulted in a set of 13 news value labels.: Original and adjudicated interannotator agreement (Cohen's \u03ba and F1-macro scores) and counts for each news value (agreement scores averaged over three annotator pairs and four annotator groups; moderate/substantial \u03ba agreement shown in bold).", "labels": [], "entities": [{"text": "F1-macro scores", "start_pos": 114, "end_pos": 129, "type": "METRIC", "confidence": 0.9668305516242981}]}, {"text": "We asked four annotators to independently label the dataset.", "labels": [], "entities": []}, {"text": "The annotators were provided short guidelines and a description of the news values.", "labels": [], "entities": []}, {"text": "We first ran a calibration round on a set of 120 headlines.", "labels": [], "entities": []}, {"text": "After calculating the inter-annotator agreement (IAA), we decided to run a second round of calibration, providing further information about some labels conceived as more ambiguous by the annotators (e.g., \"Bad news\" vs. \"Drama\" vs. \"Conflict\" and \"Celebrity\" vs. \"Power elite\").", "labels": [], "entities": [{"text": "inter-annotator agreement (IAA)", "start_pos": 22, "end_pos": 53, "type": "METRIC", "confidence": 0.8446156978607178}]}, {"text": "For the final annotation round, we arranged the annotators into four distinct groups of three, so that each headline would be annotated by three annotators.", "labels": [], "entities": []}, {"text": "The annotation was done on 798 headlines using 13 labels.", "labels": [], "entities": []}, {"text": "Annotation analysis revealed that two of these labels \"Exclusivity\" and \"Relevance\", have been used in a marginal number of cases so we decide to omit these labels from the final dataset.", "labels": [], "entities": [{"text": "Exclusivity", "start_pos": 55, "end_pos": 66, "type": "METRIC", "confidence": 0.9556989073753357}, {"text": "Relevance", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9918792843818665}]}, {"text": "show the Cohen's \u03ba and F1-macro IAA agreement scores for the 11 news value labels.", "labels": [], "entities": [{"text": "F1-macro IAA agreement", "start_pos": 23, "end_pos": 45, "type": "METRIC", "confidence": 0.8470168113708496}]}, {"text": "We observe a moderate agreement of \u03ba \u2265 0.4 only for the \"Bad news\", \"Celebrity\", and \"Entertainment\" news values, suggesting that recognizing news values from headlines is a difficult task even for humans.", "labels": [], "entities": []}, {"text": "To obtain the final dataset, we adjudicated the annotations of the three annotators my a majority vote.", "labels": [], "entities": []}, {"text": "The adjudicated IAA is moderate/substantial, except for \"Magnitude\", \"Shareability\", and \"Surprise\".", "labels": [], "entities": [{"text": "IAA", "start_pos": 16, "end_pos": 19, "type": "METRIC", "confidence": 0.6055585741996765}, {"text": "Shareability\"", "start_pos": 70, "end_pos": 83, "type": "TASK", "confidence": 0.8701266646385193}, {"text": "Surprise", "start_pos": 90, "end_pos": 98, "type": "TASK", "confidence": 0.9036012887954712}]}, {"text": "headlines, we carryout a multivariate data analysis using factor analysis (FA) ().", "labels": [], "entities": [{"text": "factor analysis (FA)", "start_pos": 58, "end_pos": 78, "type": "METRIC", "confidence": 0.7474819183349609}]}, {"text": "The main goal of FA is to measure the presence of underlying constructs, i.e., factors, which in our case represent the correlation among emotions and news values, and their factor loading magnitudes.", "labels": [], "entities": [{"text": "FA", "start_pos": 17, "end_pos": 19, "type": "TASK", "confidence": 0.9644333124160767}]}, {"text": "The use of FA is justified here because (1) we deal with cardinal (news values) and ordinal (emotions) variables and (2) the data exhibits a substantial degree of multicollinearity.", "labels": [], "entities": [{"text": "FA", "start_pos": 11, "end_pos": 13, "type": "METRIC", "confidence": 0.9035328030586243}]}, {"text": "We applied varimax, an orthogonal factor rotation used to obtain a simplified factor structure that maximizes the variance.", "labels": [], "entities": []}, {"text": "We then inspected the eigenvalue scree plot and chose to use seven factors whose values were larger than 1 as to reduce the number of variables without loosing relevant information.", "labels": [], "entities": []}, {"text": "To visualize the factor structure and relations among news values and emotions, we performed a hierarchical cluster analysis, using complete linkage with one minus Pearson's correlation coefficient as the distance measure.", "labels": [], "entities": [{"text": "Pearson's correlation coefficient", "start_pos": 164, "end_pos": 197, "type": "METRIC", "confidence": 0.7126545757055283}]}, {"text": "We can identify three groups of news values and emotions.", "labels": [], "entities": []}, {"text": "The first group contains the negative emotions related to \"Conflict\" and \"Bad news\", and the rather distant \"Power elite\".", "labels": [], "entities": []}, {"text": "The second group contains only news values, namely \"Drama\", \"Celebrity\", and \"Follow up\".", "labels": [], "entities": []}, {"text": "The last group is formed by two positive emotions, joy and surprise, which are the kernels of two sub-groups: joy is related to \"Good news\", \"Shareability\" and, to a lesser extent, to \"Magnitude\", while surprise emotions relates to \"Entertainment\" and \"Surprise\" news values.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Original and adjudicated interannotator  agreement (Cohen's \u03ba and F1-macro scores) and  counts for each news value (agreement scores aver- aged over three annotator pairs and four annotator  groups; moderate/substantial \u03ba agreement shown  in bold).", "labels": [], "entities": [{"text": "F1-macro scores", "start_pos": 76, "end_pos": 91, "type": "METRIC", "confidence": 0.9713031053543091}]}, {"text": " Table 2: F1-scores of SVM and CNN news values  classifiers using text (\"T\") or text and emotions  (\"T+E\") as features. Best result for each news  value are shown in bold. \"  *  \" denotes a statistically  significant difference between feature sets \"T\" and  \"T+E\" for the same classifier, and \" \u2020\" a statistically  significant difference between SVM and CNN clas- sifiers with the same features (p<0.05, two-tailed  permutation test).", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9917095303535461}]}]}