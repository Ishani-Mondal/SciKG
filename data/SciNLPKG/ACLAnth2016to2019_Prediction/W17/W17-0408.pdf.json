{"title": [{"text": "Towards Universal Dependencies for Learner Chinese", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose an annotation scheme for learner Chinese in the Universal Dependencies (UD) framework.", "labels": [], "entities": [{"text": "Universal Dependencies (UD) framework", "start_pos": 59, "end_pos": 96, "type": "DATASET", "confidence": 0.6170131514469782}]}, {"text": "The scheme was adapted from a UD scheme for Mandarin Chinese to take interlanguage characteristics into account.", "labels": [], "entities": []}, {"text": "We applied the scheme to a set of 100 sentences written by learners of Chinese as a foreign language, and we report inter-annotator agreement on syntactic annotation.", "labels": [], "entities": []}], "introductionContent": [{"text": "A learner corpus consists of texts written by nonnative speakers.", "labels": [], "entities": []}, {"text": "Recent years have seen a rising number of learner corpora, many of which are error-tagged to support analysis of grammatical mistakes made by learners).", "labels": [], "entities": []}, {"text": "In order to derive overuse and underuse statistics on syntactic structures, some corpus have also been part-of-speech (POS) tagged, and syntactically analyzed (.", "labels": [], "entities": []}, {"text": "These corpora are valuable as training data for robust parsing of learner texts, and can also benefit a variety of downstream tasks, including grammatical error correction, learner proficiency identification, and language learning exercise generation.", "labels": [], "entities": [{"text": "grammatical error correction", "start_pos": 143, "end_pos": 171, "type": "TASK", "confidence": 0.582259992758433}, {"text": "learner proficiency identification", "start_pos": 173, "end_pos": 207, "type": "TASK", "confidence": 0.708266039689382}, {"text": "language learning exercise generation", "start_pos": 213, "end_pos": 250, "type": "TASK", "confidence": 0.7461207211017609}]}, {"text": "While most annotation efforts have focused on learner English, a number of large learner Chinese corpora have also been compiled.", "labels": [], "entities": []}, {"text": "However, POS analysis in these corpora has been limited to the erroneous words, and there has not yet been any attempt to annotate syntactic structures.", "labels": [], "entities": [{"text": "POS analysis", "start_pos": 9, "end_pos": 21, "type": "TASK", "confidence": 0.869667261838913}]}, {"text": "This study presents the first attempt to annotate Chinese learner text in the Universal Dependencies (UD) framework.", "labels": [], "entities": []}, {"text": "One advantage of UD is the potential for contrastive analysis, e.g., comparisons between a UD treebank of standard Chinese, a UD treebank of language X and portions of a UD treebank of learner Chinese produced by native speakers of X.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 reviews existing treebanks for learner texts.", "labels": [], "entities": []}, {"text": "Section 3 describes the adaptation of a Mandarin Chinese UD scheme to account for noncanonical characteristics in learner text.", "labels": [], "entities": []}, {"text": "Section 4 reports inter-annotator agreement.", "labels": [], "entities": []}], "datasetContent": [{"text": "We harvested a 100-sentence evaluation dataset from the training data of the most recent shared task on Chinese grammatical diagnosis ().", "labels": [], "entities": [{"text": "Chinese grammatical diagnosis", "start_pos": 104, "end_pos": 133, "type": "TASK", "confidence": 0.7460638483365377}]}, {"text": "The dataset included 20 sentences with extraneous words, 20 with missing words, 20 with word-order errors, and 40 with word selection errors.", "labels": [], "entities": []}, {"text": "In order to include challenging cases of word selection errors, i.e., those involving misuse of POS (Section 3.3.1), we examined the target hypothesis in the corpus.", "labels": [], "entities": [{"text": "word selection errors", "start_pos": 41, "end_pos": 62, "type": "TASK", "confidence": 0.7941844860712687}]}, {"text": "We selected 20 sentences where the replacement word has a different POS, and 20 sentences where it is the same.", "labels": [], "entities": [{"text": "POS", "start_pos": 68, "end_pos": 71, "type": "METRIC", "confidence": 0.9924526810646057}]}, {"text": "Two annotators, one of whom had access to the target hypothesis, independently annotated these sentences.", "labels": [], "entities": []}, {"text": "Word segmentation achieved 97.0% precision and 98.9% recall when one of the annotators was taken as gold.", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6517500281333923}, {"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9982056617736816}, {"text": "recall", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9979957342147827}]}, {"text": "After reconciling their segmentation, each independently annotated POS tags and dependency relations.", "labels": [], "entities": []}, {"text": "The inter-annotator agreement is reported in.", "labels": [], "entities": []}, {"text": "Overall agreement is 94.0% for POS tags and 82.8% for REL (labeled attachment).", "labels": [], "entities": [{"text": "agreement", "start_pos": 8, "end_pos": 17, "type": "METRIC", "confidence": 0.9981083869934082}, {"text": "REL", "start_pos": 54, "end_pos": 57, "type": "METRIC", "confidence": 0.9929829835891724}]}, {"text": "The agreement levels are comparable to those reported in, where agreement on labeled attachment ranges from 73.6% to 88.7% depending on the text and annotator.", "labels": [], "entities": [{"text": "agreement", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9947350025177002}, {"text": "agreement", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.9588010311126709}]}, {"text": "One must bear in mind, however, that annotation agreement for standard Chinese is also generally lower than English.", "labels": [], "entities": [{"text": "annotation agreement", "start_pos": 37, "end_pos": 57, "type": "METRIC", "confidence": 0.759150356054306}]}, {"text": "Annotation agreement based on distributional evidence -i.e., POS d and REL d -is slightly lower.", "labels": [], "entities": [{"text": "Annotation", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9917071461677551}, {"text": "POS d", "start_pos": 61, "end_pos": 66, "type": "METRIC", "confidence": 0.9767081141471863}, {"text": "REL d -", "start_pos": 71, "end_pos": 78, "type": "METRIC", "confidence": 0.9787035584449768}]}, {"text": "This is not unexpected, since it requires a higher degree of subjective interpretation.", "labels": [], "entities": []}, {"text": "The most frequent discrepancies between morphological and distributional tags are ADJ vs. VERB, i.e., an adjective used as a verb (as in; and VERB vs. NOUN, i.e. a verb used as a noun.", "labels": [], "entities": [{"text": "VERB", "start_pos": 90, "end_pos": 94, "type": "METRIC", "confidence": 0.9231283664703369}, {"text": "VERB", "start_pos": 142, "end_pos": 146, "type": "METRIC", "confidence": 0.6382904648780823}]}, {"text": "Annotation agreement is also lower within text spans marked as erroneous in the corpus, with agreement dropping to 91.0% for POS tags and 75.1% for labeled attachment.", "labels": [], "entities": [{"text": "Annotation agreement", "start_pos": 0, "end_pos": 20, "type": "METRIC", "confidence": 0.7764613330364227}, {"text": "agreement", "start_pos": 93, "end_pos": 102, "type": "METRIC", "confidence": 0.9953820109367371}]}, {"text": "Further analysis revealed that agreement is especially challenging for word selection errors whose target hypothesis has a different POS.", "labels": [], "entities": [{"text": "word selection errors", "start_pos": 71, "end_pos": 92, "type": "TASK", "confidence": 0.7987957795461019}, {"text": "POS", "start_pos": 133, "end_pos": 136, "type": "METRIC", "confidence": 0.9635687470436096}]}, {"text": "A post-hoc discussion among the annotators suggests that multiple plausible interpretations of an ungrammatical sentence was the main source of disagreement.", "labels": [], "entities": []}, {"text": "For these cases, more specific guidelines are needed on which interpretation -e.g., considering a word as extraneous, as missing, or misused in terms of POSentails the most literal reading.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: The percentage of POS tags and labelled  attachment on which the two annotators agree,  measured overall and within text spans marked as  erroneous.", "labels": [], "entities": []}]}