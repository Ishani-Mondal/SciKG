{"title": [{"text": "Suggesting Sentences for ESL using Kernel Embeddings", "labels": [], "entities": [{"text": "Suggesting Sentences", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9464605152606964}]}], "abstractContent": [{"text": "Sentence retrieval is an important NLP application for English as a Second Language (ESL) learners.", "labels": [], "entities": [{"text": "Sentence retrieval", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.954608291387558}]}, {"text": "ESL learners are familiar with web search engines, but generic web search results may not be adequate for composing documents in a specific domain.", "labels": [], "entities": []}, {"text": "However, if we build our own search system specialized to a domain, it maybe subject to the data sparseness problem.", "labels": [], "entities": []}, {"text": "Recently proposed word2vec partially addresses the data sparseness problem, but fails to extract sentences relevant to queries owing to the modeling of the latent intent of the query.", "labels": [], "entities": []}, {"text": "Thus, we propose a method of retrieving example sentences using kernel embeddings and N-gram windows.", "labels": [], "entities": []}, {"text": "This method implicitly models latent intent of query and sentences, and alleviates the problem of noisy alignment.", "labels": [], "entities": []}, {"text": "Our results show that our method achieved higher precision in sentence retrieval for ESL in the domain of a university press release corpus , as compared to a previous unsuper-vised method used fora semantic textual similarity task.", "labels": [], "entities": [{"text": "precision", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.9990265369415283}, {"text": "sentence retrieval", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.7281146198511124}]}], "introductionContent": [{"text": "Many English writing assistant tools are currently being studied and developed.", "labels": [], "entities": [{"text": "English writing assistant", "start_pos": 5, "end_pos": 30, "type": "TASK", "confidence": 0.7755632599194845}]}, {"text": "However, even for advanced ESL learners, it is difficult to write sentences conforming to the styles and expressions in a specific domain.", "labels": [], "entities": []}, {"text": "Therefore, it is beneficial for non-native speakers to search for sentences using keywords that the writer aims to use.", "labels": [], "entities": []}, {"text": "However, existing sentence retrieval systems fail to capture the latent intent of query, owing to the modeling of sentences.", "labels": [], "entities": [{"text": "sentence retrieval", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.7159318029880524}]}, {"text": "We address this problem by using a kernel embeddings framework.", "labels": [], "entities": []}, {"text": "Kernel embeddings makes it possible to add expression to the query in sentence retrieval by using latent probability distribution.", "labels": [], "entities": []}, {"text": "In addition, our method of taking N-gram windows boosts the precision of sentence retrieval by considering words that are highly related to the query.", "labels": [], "entities": [{"text": "precision", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9994800686836243}, {"text": "sentence retrieval", "start_pos": 73, "end_pos": 91, "type": "TASK", "confidence": 0.7157037556171417}]}, {"text": "The main contributions of this study are as follows: \u2022 We propose a novel sentence similarity metric based on kernel embeddings and N-gram windows.", "labels": [], "entities": []}, {"text": "\u2022 We build a corpus of university press releases and annotated example sentences for ESL, given a query of two words.", "labels": [], "entities": []}, {"text": "\u2022 We show that our proposed method outperforms unsupervised baselines on our dataset.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated the result using Precision@k (hereafter, p@k), and compared our model with the following two baselines.", "labels": [], "entities": [{"text": "Precision", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9919421672821045}]}, {"text": "A simple baseline was calculated using the average similarity of the vectors of query and sentence.", "labels": [], "entities": []}, {"text": "We used word2vec's word embeddings as the word vector.", "labels": [], "entities": []}, {"text": "As the query vector, we averaged the word vectors of the query.", "labels": [], "entities": []}, {"text": "Similarly, as the sentence vector, we averaged the word vectors of the words in the sentence.", "labels": [], "entities": []}, {"text": "We compared these vectors using cosine similarity and RBF kernel.", "labels": [], "entities": [{"text": "RBF kernel", "start_pos": 54, "end_pos": 64, "type": "METRIC", "confidence": 0.963950902223587}]}, {"text": "As another baseline, we used one of the unsupervised sentence similarity measures proposed by.", "labels": [], "entities": []}, {"text": "These methods achieved state-of-theart performance fora short text similarity (STS) task.", "labels": [], "entities": [{"text": "short text similarity (STS) task", "start_pos": 56, "end_pos": 88, "type": "TASK", "confidence": 0.6634302522454943}]}, {"text": "We used their method to calculate the intersentence similarity (maximum alignment) based on the alignment in the distributed representation expressed by the following equation.", "labels": [], "entities": [{"text": "intersentence similarity (maximum alignment)", "start_pos": 38, "end_pos": 82, "type": "METRIC", "confidence": 0.6694225470225016}]}, {"text": "This method calculates the maximum value of similarity between each keyword q i of the query q and each word s j included in the sentence s.", "labels": [], "entities": [{"text": "similarity", "start_pos": 44, "end_pos": 54, "type": "METRIC", "confidence": 0.9666292667388916}]}, {"text": "Then, the similarity between the query and the sentence is calculated as the maximum value divided by the number of keywords |q|.", "labels": [], "entities": [{"text": "similarity", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.982801616191864}]}, {"text": "We experimented with both cosine similarity and RBF kernel fork in Equation (6).", "labels": [], "entities": [{"text": "RBF kernel fork", "start_pos": 48, "end_pos": 63, "type": "METRIC", "confidence": 0.7750673691431681}]}, {"text": "Note that we did not symmetrize Equation (6).", "labels": [], "entities": [{"text": "Equation", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9458498358726501}]}], "tableCaptions": [{"text": " Table 1: Example of pairs of query.  education innovative, identify research,  provide advice, plan annual,  recipient award, goal ensure,  partnership support, field industry,  improve success, lead experience", "labels": [], "entities": []}]}