{"title": [{"text": "Unlabeled Data for Morphological Generation With Character-Based Sequence-to-Sequence Models", "labels": [], "entities": [{"text": "Morphological Generation", "start_pos": 19, "end_pos": 43, "type": "TASK", "confidence": 0.8657622039318085}]}], "abstractContent": [{"text": "We present a semi-supervised way of training a character-based encoder-decoder recurrent neural network for morphological reinflection, the task of generating one inflected word form from another.", "labels": [], "entities": []}, {"text": "This is achieved by using unlabeled tokens or random strings as training data for an autoencoding task, adapting a network for morphological reinflection, and performing multi-task training.", "labels": [], "entities": []}, {"text": "We thus use limited labeled data more effectively, obtaining up to 9.9% improvement over state-of-the-art baselines for 8 different languages.", "labels": [], "entities": []}], "introductionContent": [{"text": "Morphologically rich languages use inflectionthe adaptation of a surface form to its syntactic context-to mark the properties of a word, e.g., gender or number of nouns or tense of verbs.", "labels": [], "entities": []}, {"text": "This drastically increases the type-token ratio, and thus negatively effects natural language processing (NLP), making morphological analysis and generation an important field of research.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 77, "end_pos": 110, "type": "TASK", "confidence": 0.7867938776810964}, {"text": "morphological analysis and generation", "start_pos": 119, "end_pos": 156, "type": "TASK", "confidence": 0.7084695994853973}]}, {"text": "In this work, we focus on morphological reinflection (MRI), the task of mapping one inflected form of a lemma to another, given the morphological properties of the target, e.g., (smiling, PastPart) \u2192 smiled.", "labels": [], "entities": [{"text": "morphological reinflection (MRI)", "start_pos": 26, "end_pos": 58, "type": "TASK", "confidence": 0.6725947320461273}]}, {"text": "The lemma does not have to be known.", "labels": [], "entities": []}, {"text": "Recently, there have been some advances on the topic, motivated by the SIGMOR-PHON 2016 shared task on morphological reinflection () and the CoNLL-SIGMORPHON 2017 shared task on universal morphological reinflection (.", "labels": [], "entities": [{"text": "SIGMOR-PHON 2016 shared task on morphological reinflection", "start_pos": 71, "end_pos": 129, "type": "TASK", "confidence": 0.5551994570663997}]}, {"text": "In 2016, neural sequence-to-sequence models, specifically attention-based encoder-decoder models, outperformed all other approaches by a wide: Examples for labeled and unlabeled input.", "labels": [], "entities": []}, {"text": "The content of the red boxes (very left in both rows) signalizes if the sample belongs to the MRI task or the autoencoding task. margin.", "labels": [], "entities": [{"text": "margin", "start_pos": 129, "end_pos": 135, "type": "METRIC", "confidence": 0.9981050491333008}]}, {"text": "However, those models require a lot of training data, while in contrast many morphologically rich languages are low-resource, and little work has been done so far on neural models for morphology in settings with limited training data.", "labels": [], "entities": []}, {"text": "This makes sequence-to-sequence models not applicable to morphological generation inmost languages.", "labels": [], "entities": []}, {"text": "An abundance of unlabeled data, in contrast, can be assumed available for each language in the focus of NLP.", "labels": [], "entities": []}, {"text": "Thus, we propose a semisupervised training method fora state-of-the-art encoder-decoder network for MRI using both labeled and unlabeled data, mitigating the need for time-expensive annotations.", "labels": [], "entities": []}, {"text": "We achieve this by treating unlabeled words as training examples for an autoencoding (Vincent et al., 2010) task and multi-task training (cf..", "labels": [], "entities": []}, {"text": "We intuit the following reasons why this should be beneficial: (i) The decoder's character language model can be trained using unlabeled data.", "labels": [], "entities": []}, {"text": "(ii) Training on a second task reduces the problem of overfitting.", "labels": [], "entities": []}, {"text": "(iii) By forcing the model to additionally learn autoencoding, we give it a strong prior to copy the input string.", "labels": [], "entities": []}, {"text": "This might be advantageous as often many forms of a paradigm share the same stem, e.g., smiling and smiled.", "labels": [], "entities": []}, {"text": "In order to investigate the importance of the latter, we further experiment with autoencoding of random strings and find that for our experimental settings and non-templatic languages the performance gain is comparable to using corpus words.", "labels": [], "entities": []}], "datasetContent": [{"text": "We experiment on the task 3 dataset of the SIGMORPHON 2016 shared task on MRI () and all standard languages provided: Arabic, Finnish, Georgian, German, Navajo, Russian, Spanish and Turkish.", "labels": [], "entities": [{"text": "SIGMORPHON 2016 shared task", "start_pos": 43, "end_pos": 70, "type": "TASK", "confidence": 0.5254736840724945}, {"text": "MRI", "start_pos": 74, "end_pos": 77, "type": "DATASET", "confidence": 0.7108545303344727}]}, {"text": "German, Spanish and Russian are suffixing and exhibit stem changes.", "labels": [], "entities": []}, {"text": "Russian differs from the other two in that those stem changes are consonantal and not vocalic.", "labels": [], "entities": []}, {"text": "Finnish and Turkish are agglutinating, almost exclusively suffixing and have vowel harmony systems.", "labels": [], "entities": []}, {"text": "Georgian uses both prefixiation and suffixiation.", "labels": [], "entities": []}, {"text": "In contrast, Navajo mainly makes use of prefixes with consonant harmony among its sibilants.", "labels": [], "entities": []}, {"text": "Finally, Arabic is a templatic, nonconcatenative language.", "labels": [], "entities": []}, {"text": "For each language, we further add randomly sampled words from the respective Wikipedia dumps.", "labels": [], "entities": []}, {"text": "We exclude tokens that are not exclusively composed from characters of the language's alphabet, e.g., digits, or do not appear at least 2 times in the corpus.", "labels": [], "entities": []}, {"text": "The exact amount of unlabaled data added is treated as a hyperparameter depending on the number of available annotated examples and optimized on the development set, cf. Section 4.1.", "labels": [], "entities": []}, {"text": "Evaluation is done on the official shared task test set.", "labels": [], "entities": [{"text": "official shared task test set", "start_pos": 26, "end_pos": 55, "type": "DATASET", "confidence": 0.6898458003997803}]}, {"text": "Training, hyperparameters and evaluation.", "labels": [], "entities": []}, {"text": "We mainly adopt the hyperparameters of (. Embeddings are 300-dimensional, the size of all hidden layers is 100 and for training we use ADADELTA) with a batch size of 20.", "labels": [], "entities": [{"text": "ADADELTA", "start_pos": 135, "end_pos": 143, "type": "METRIC", "confidence": 0.9881733059883118}]}, {"text": "We train all models which use 8 or more of the labeled data for 200 epochs, and models that see 16 and 1 32 of the original data for 400 and 800 epochs, respectively.", "labels": [], "entities": []}, {"text": "In all cases, we apply the last model for testing.", "labels": [], "entities": []}, {"text": "We evaluate using two metrics: accuracy and edit distance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9994829893112183}]}, {"text": "Accuracy reports the percentage of completely correct solutions, while the edit distance between the system's guess and the gold solution gives credit to systems that produce forms that are close to the right form.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9956247210502625}, {"text": "edit distance", "start_pos": 75, "end_pos": 88, "type": "METRIC", "confidence": 0.9691387414932251}]}, {"text": "We compare our system to three baselines: The first one is MED 1 , the winning sys-: Accuracy (the higher the better) and edit distance (the lower the better) for our system and the three baselines on the official test set of task 3 of the SIGMORPHON 2016 shared task.", "labels": [], "entities": [{"text": "MED 1", "start_pos": 59, "end_pos": 64, "type": "METRIC", "confidence": 0.9801723062992096}, {"text": "Accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.999138593673706}, {"text": "edit distance", "start_pos": 122, "end_pos": 135, "type": "METRIC", "confidence": 0.9734740257263184}, {"text": "SIGMORPHON 2016 shared task", "start_pos": 240, "end_pos": 267, "type": "TASK", "confidence": 0.5230956822633743}]}, {"text": "Only the indicated amount (row labels) of the original training data is used, emulating a low-resource setting.", "labels": [], "entities": []}, {"text": "Best results for each language in bold.", "labels": [], "entities": []}, {"text": "tem of the 2016 shared task.", "labels": [], "entities": [{"text": "tem of the 2016 shared task", "start_pos": 0, "end_pos": 27, "type": "DATASET", "confidence": 0.7577239672342936}]}, {"text": "The network architecture is the same as in our system, but it is trained exclusively on labeled data.", "labels": [], "entities": []}, {"text": "Thus, we expect it to suffer stronger from alack of resources.", "labels": [], "entities": []}, {"text": "The second baseline is the official SIGMOR-PHON 2016 shared task baseline (SIG16), which is similar in spirit to the system described by.", "labels": [], "entities": [{"text": "SIGMOR-PHON 2016 shared task baseline (SIG16)", "start_pos": 36, "end_pos": 81, "type": "DATASET", "confidence": 0.6769682951271534}]}, {"text": "The system treats the prediction of edit operations to be performed on the input string as a sequential decision-making problem, greedily choosing each edit action given the previously chosen actions.", "labels": [], "entities": []}, {"text": "The selection of operations is made by an averaged perceptron, using the binary features described in ().", "labels": [], "entities": []}, {"text": "Third, we compare to the baseline system of the CoNLL-SIGMORPHON 2017 shared task on universal morphological reinflection (SIG17), which is extremely suitable for low-resource settings.", "labels": [], "entities": [{"text": "CoNLL-SIGMORPHON 2017 shared task", "start_pos": 48, "end_pos": 81, "type": "DATASET", "confidence": 0.8141628801822662}]}, {"text": "It splits all source and target forms in the training set into prefix, middle part and suffix, and uses those to find prefix or suffix substitution rules.", "labels": [], "entities": []}, {"text": "Every evaluation example is searched for the longest contained prefix or suffix and the rule belonging to the affix and given target tag is applied to obtain the output.", "labels": [], "entities": []}, {"text": "As shown in, additionally training on unlabeled examples improves the performance of the encoder-decoder network for nearly all settings and languages, especially for the very low-resource scenarios with 1 16 and 1 32 of the training data.", "labels": [], "entities": []}, {"text": "The biggest increase inaccuracy can be seen for Russian and Spanish, both in the 1 32 setting, with 0.0963 (0.5023 \u2212 0.4060) and 0.0992 (0.7564 \u2212 0.6572), respectively.", "labels": [], "entities": []}, {"text": "For the settings with bigger amounts 2 Note that our use of the system differs from the official baseline in that we perform a direct form-to-form mapping.", "labels": [], "entities": []}, {"text": "The shared task system predicts first form-to-lemma and then lemma-to-form.", "labels": [], "entities": []}, {"text": "However, we assume no lemmata to be given, and thus are unable to train such a system. of training data available, the unlabeled data does not change performance a lot.", "labels": [], "entities": []}, {"text": "This was expected, as the model already gets enough information from the annotated data.", "labels": [], "entities": []}, {"text": "However, semisupervised training never hurts performance, and can thus always be employed.", "labels": [], "entities": []}, {"text": "Overall, our semisupervised training method shows to be a useful extension of the original system.", "labels": [], "entities": []}, {"text": "Furthermore, there are only two casesGeorgian, 16 , and Navajo, 1 32 -where any of the SIGMORPHON baselines outperforms the neural methods.", "labels": [], "entities": []}, {"text": "This clearly shows the superiority of neural networks for the task and emphasizes the need to reduce the amount of labeled training data required for their training.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracy (the higher the better) and edit distance (the lower the better) for our system and the three baselines on  the official test set of task 3 of the SIGMORPHON 2016 shared task. Only the indicated amount (row labels) of the original  training data is used, emulating a low-resource setting. Best results for each language in bold.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9993340373039246}, {"text": "edit distance", "start_pos": 47, "end_pos": 60, "type": "METRIC", "confidence": 0.9816944897174835}, {"text": "SIGMORPHON 2016 shared task", "start_pos": 166, "end_pos": 193, "type": "TASK", "confidence": 0.5181943327188492}]}, {"text": " Table 2: Accuracies for MED (", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9984691739082336}]}]}