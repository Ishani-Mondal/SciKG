{"title": [{"text": "Biomedical Event Extraction using Abstract Meaning Representation", "labels": [], "entities": [{"text": "Biomedical Event Extraction", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7122050126393636}, {"text": "Abstract Meaning Representation", "start_pos": 34, "end_pos": 65, "type": "TASK", "confidence": 0.5892247259616852}]}], "abstractContent": [{"text": "We propose a novel, Abstract Meaning Representation (AMR) based approach to identifying molecular events/interactions in biomedical text.", "labels": [], "entities": [{"text": "Abstract Meaning Representation (AMR)", "start_pos": 20, "end_pos": 57, "type": "TASK", "confidence": 0.7965761621793112}, {"text": "identifying molecular events/interactions in biomedical text", "start_pos": 76, "end_pos": 136, "type": "TASK", "confidence": 0.7723635658621788}]}, {"text": "Our key contributions are: (1) an empirical validation of our hypothesis that an event is a subgraph of the AMR graph, (2) a neural network-based model that identifies such an event sub-graph given an AMR, and (3) a distant supervision based approach to gather additional training data.", "labels": [], "entities": []}, {"text": "We evaluate our approach on the 2013 Genia Event Extraction dataset 1 (Kim et al., 2013) and show promising results.", "labels": [], "entities": [{"text": "2013 Genia Event Extraction dataset 1 (Kim et al., 2013)", "start_pos": 32, "end_pos": 88, "type": "DATASET", "confidence": 0.8582416956241314}]}], "introductionContent": [{"text": "For several years now, the biomedical community has been working towards the goal of creating a curated knowledge base of biomolecule entity interactions.", "labels": [], "entities": []}, {"text": "The scientific literature in the biomedical domain runs to millions of articles and is an excellent source of such information.", "labels": [], "entities": []}, {"text": "However, automatically extracting information from text is a challenge because natural language allows us to express the same information in several different ways.", "labels": [], "entities": [{"text": "automatically extracting information from text", "start_pos": 9, "end_pos": 55, "type": "TASK", "confidence": 0.7934401750564575}]}, {"text": "The series of Genia Event Extraction shared tasks ( has resulted in various significant approaches to biomolecule event extraction spanning methods that use learnt patterns from annotated text () to machine learning methods) that use syntactic parses as features.", "labels": [], "entities": [{"text": "Genia Event Extraction shared tasks", "start_pos": 14, "end_pos": 49, "type": "TASK", "confidence": 0.8705029964447022}, {"text": "biomolecule event extraction spanning", "start_pos": 102, "end_pos": 139, "type": "TASK", "confidence": 0.7071738168597221}]}, {"text": "In this work, we find that a semantic analysis of text that relies on Abstract Meaning Representations () is highly useful because it normalizes many lexical and syntactic variations in text.", "labels": [], "entities": []}, {"text": "This dataset is different from BioNLP 2016 GE dataset: AMR with sample event annotations for sentence \"This LPA-induced rapid phosphorylation of radixin was significantly suppressed in the presence of C3 toxin, a potent inhibitor of Rho\" AMR is a rooted, directed acyclic graph (DAG) that captures the notion of who did what to whom in text, in away that sentences that have the same basic meaning often have the same AMR.", "labels": [], "entities": [{"text": "BioNLP 2016 GE dataset", "start_pos": 31, "end_pos": 53, "type": "DATASET", "confidence": 0.9097303599119186}, {"text": "AMR", "start_pos": 55, "end_pos": 58, "type": "TASK", "confidence": 0.7212507724761963}]}, {"text": "The nodes in the graph (also called concepts) map to words in the sentence and the edges map to relations between the words.", "labels": [], "entities": []}, {"text": "In the recent past, there have been several efforts towards parsing a sentence into its AMR (.", "labels": [], "entities": [{"text": "parsing a sentence", "start_pos": 60, "end_pos": 78, "type": "TASK", "confidence": 0.8647492329279581}, {"text": "AMR", "start_pos": 88, "end_pos": 91, "type": "DATASET", "confidence": 0.7265958189964294}]}, {"text": "AMR naturally captures hierarchical relations between entities in text making it favorable for complex event detection.", "labels": [], "entities": [{"text": "AMR", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9336251616477966}, {"text": "complex event detection", "start_pos": 95, "end_pos": 118, "type": "TASK", "confidence": 0.6933187445004781}]}, {"text": "For example, consider the following sentence from the biomedical literature: \"This LPA-induced rapid phosphorylation of radixin was significantly suppressed in the presence of C3 toxin, a potent inhibitor of Rho\".", "labels": [], "entities": []}, {"text": "Figure 1 shows its Abstract Meaning Representation (AMR).", "labels": [], "entities": [{"text": "Abstract Meaning Representation (AMR)", "start_pos": 19, "end_pos": 56, "type": "METRIC", "confidence": 0.8926059206326803}]}, {"text": "The subgraph rooted at phosphorylate-01 identifies the event E 1 and the subgraph rooted at induce-01 identifies the event E 2 where E 1 = phosphorylation of radixin; E 2 = LPA induces E1.", "labels": [], "entities": []}, {"text": "We hypothesize that an event structure is a sub-: Event types and their arguments in the 2013 Genia Event Extraction task graph of a DAG structure like AMR and under this assumption, we cast the event extraction task as a graph identification problem.", "labels": [], "entities": [{"text": "Genia Event Extraction task", "start_pos": 94, "end_pos": 121, "type": "TASK", "confidence": 0.6084303483366966}, {"text": "event extraction task", "start_pos": 195, "end_pos": 216, "type": "TASK", "confidence": 0.7969910303751627}]}, {"text": "Our first contribution is the testing of the above hypothesis that an event structure is a subgraph of an AMR graph.", "labels": [], "entities": []}, {"text": "Given a sentence, we automatically obtain its AMR using an AMR parser and explain how an event can be defined as a subgraph of the AMR graph.", "labels": [], "entities": []}, {"text": "Under the assumption that we can correctly identify such an event subgraph from an AMR graph when it exists, we evaluate how good is our definition (Section 2).", "labels": [], "entities": []}, {"text": "Our second contribution is a supervised neural network-based model that is trained to identify an event subgraph given an AMR (Section 3).", "labels": [], "entities": [{"text": "AMR", "start_pos": 122, "end_pos": 125, "type": "DATASET", "confidence": 0.5925142168998718}]}, {"text": "Our model is built on the intuition that the path between an interaction term and an entity term in an AMR graph contains important signal for identifying the relation between them.", "labels": [], "entities": []}, {"text": "For e.g. in the path {'induce-01', 'arg0', 'LPA'} suggests that LPA is the cause of induce.", "labels": [], "entities": [{"text": "arg0", "start_pos": 36, "end_pos": 40, "type": "METRIC", "confidence": 0.9344125390052795}]}, {"text": "We encode this path using word embeddings pre-trained on millions of biomedical text and develop two pipelined neural network models: (a) to identify the theme of an interaction; and (b) to identify the cause of the interaction, if there exists one.", "labels": [], "entities": []}, {"text": "Experimental results show that our model, although achieves a reasonable precision, suffers from low recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9992555975914001}, {"text": "recall", "start_pos": 101, "end_pos": 107, "type": "METRIC", "confidence": 0.9992019534111023}]}, {"text": "Our third contribution is a distant supervision () based approach to collect additional annotated training data.", "labels": [], "entities": []}, {"text": "Distant supervision works on the assumption that given a known relation between two entities, a sentence containing the two entities is likely to express this relation and hence can serve as training data for that relation.", "labels": [], "entities": []}, {"text": "Data gathered using such a method can be noisy (.", "labels": [], "entities": []}, {"text": "have discussed several prior work that address this issue.", "labels": [], "entities": []}, {"text": "The protein annotations T1-T4 are given as starting points.", "labels": [], "entities": []}, {"text": "The task is to identify the events E1-E4 with their interaction type and arguments.", "labels": [], "entities": []}, {"text": "to selectively sample the sentences we obtain using distant supervision (Section 3) and show its effectiveness over our vanilla neural network model.", "labels": [], "entities": []}, {"text": "We evaluate our event extraction model on the 2013 Genia Event Extraction dataset and show that our model achieves promising results when compared to the state-of-the-art system.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 16, "end_pos": 32, "type": "TASK", "confidence": 0.7644654512405396}, {"text": "2013 Genia Event Extraction dataset", "start_pos": 46, "end_pos": 81, "type": "DATASET", "confidence": 0.855692982673645}]}, {"text": "Given that AMR parsing is still a young field, our model, which currently uses a parser of 67% accuracy, would perform better with improved AMR parsers.", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 11, "end_pos": 22, "type": "TASK", "confidence": 0.9077928364276886}, {"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.999077558517456}]}, {"text": "2 AMR based event extraction model", "labels": [], "entities": [{"text": "event extraction", "start_pos": 12, "end_pos": 28, "type": "TASK", "confidence": 0.7447759509086609}]}], "datasetContent": [{"text": "The event extraction task described in this work corresponds to the Task 1 of the Genia Event Extraction task described by the BioNLP Shared Task series.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 4, "end_pos": 20, "type": "TASK", "confidence": 0.7675809562206268}, {"text": "Genia Event Extraction task", "start_pos": 82, "end_pos": 109, "type": "TASK", "confidence": 0.7944478839635849}, {"text": "BioNLP Shared Task series", "start_pos": 127, "end_pos": 152, "type": "DATASET", "confidence": 0.7002125978469849}]}, {"text": "We train a model on a combination of abstract collection (from 2009 edition) and full text collection (from.", "labels": [], "entities": []}, {"text": "We test our model on the dev set of the 2013 edition (since the gold annotation is publicly available only for the dev set and not the test set).", "labels": [], "entities": [{"text": "dev set of the 2013 edition", "start_pos": 25, "end_pos": 52, "type": "DATASET", "confidence": 0.840260257323583}]}], "tableCaptions": [{"text": " Table 3: Upper bound on the dev set using our  \"event is a subgraph of AMR\" hypothesis", "labels": [], "entities": []}, {"text": " Table 5: Evaluation results (Recall/Precision/F1) on the 2013 Genia Event Extraction dev set. LSTM  and LSTM + Distant Supervision are our models. The last column corresponds to the results of EVEX  (Hakala et al., 2013) model on the 2013 test set. Certain notable numbers are emphasized and discussed  under results 5.4.", "labels": [], "entities": [{"text": "F1", "start_pos": 47, "end_pos": 49, "type": "METRIC", "confidence": 0.8618400692939758}, {"text": "2013 Genia Event Extraction dev set", "start_pos": 58, "end_pos": 93, "type": "DATASET", "confidence": 0.6481051196654638}, {"text": "2013 test set", "start_pos": 235, "end_pos": 248, "type": "DATASET", "confidence": 0.774647057056427}]}]}