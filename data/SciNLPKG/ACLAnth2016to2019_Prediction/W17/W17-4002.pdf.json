{"title": [{"text": "Transliterated Mobile Keyboard Input via Weighted Finite-State Transducers", "labels": [], "entities": []}], "abstractContent": [{"text": "We present an extension to a mobile keyboard input decoder based on finite-state transducers that provides general translit-eration support, and demonstrate its use for input of South Asian languages using a QWERTY keyboard.", "labels": [], "entities": []}, {"text": "On-device keyboard decoders must operate under strict latency and memory constraints, and we present several transducer optimizations that allow for high accuracy decoding under such constraints.", "labels": [], "entities": []}, {"text": "Our methods yield substantial accuracy improvements and latency reductions over an existing baseline translit-eration keyboard approach.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9987027645111084}]}, {"text": "The resulting system was launched for 22 languages in Google Gboard in the first half of 2017.", "labels": [], "entities": [{"text": "Google Gboard", "start_pos": 54, "end_pos": 67, "type": "DATASET", "confidence": 0.8675231635570526}]}], "introductionContent": [{"text": "The usefulness of weighted finite-state transducers (WFSTs) has been well-documented for speech recognition decoding.", "labels": [], "entities": [{"text": "speech recognition decoding", "start_pos": 89, "end_pos": 116, "type": "TASK", "confidence": 0.8606448173522949}]}, {"text": "Large component WFSTs representing a context-dependent phone sequence model (C), the pronunciation lexicon (L) and the language model (G) can be composed into a single large transducer (C \u2022 L \u2022 G, or CLG for short) mapping from context-dependent phone sequences on the input to word sequences on the output and optimized for efficient decoding ().", "labels": [], "entities": []}, {"text": "In addition to forming the basis of numerous commercial and research speech recognition engines, this is the approach taken by the widely-used open-source toolkit), which makes use of the OpenFst library () to represent and manipulate the WFSTs.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 69, "end_pos": 87, "type": "TASK", "confidence": 0.7267287522554398}, {"text": "WFSTs", "start_pos": 239, "end_pos": 244, "type": "DATASET", "confidence": 0.8703868389129639}]}, {"text": "Decoding via such an optimized graph permits the efficient combination of acoustic model scores of context-dependent phone sequences with the scores associated with larger (word n-gram) sequences contributed by the language model.", "labels": [], "entities": []}, {"text": "Speech is not the only uncertain input sequence modality requiring transcription to yield word strings -others include optical character recognition (OCR) and handwriting recognition.", "labels": [], "entities": [{"text": "optical character recognition (OCR)", "start_pos": 119, "end_pos": 154, "type": "TASK", "confidence": 0.7935342987378439}, {"text": "handwriting recognition", "start_pos": 159, "end_pos": 182, "type": "TASK", "confidence": 0.8667507171630859}]}, {"text": "WFSTbased methods have also recently been applied to soft keyboard decoding (, where a sequence of taps or continuous gestures is decoded to the most likely word or word sequence.", "labels": [], "entities": [{"text": "WFSTbased", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.8329427242279053}]}, {"text": "Unlike typing on a standard physical keyboard (such as a QWERTY keyboard on a laptop), ambiguity arises on a soft (on-screen) keyboard due to the relatively small size of the keyboard (e.g., on a smartphone) and the resulting imprecision of the tap or gesture.", "labels": [], "entities": []}, {"text": "In such an approach, the same sort of off-line composition of weighted FSTs provides low latency decoding with a modest memory footprint, which is essential for on-device keyboard functionality.", "labels": [], "entities": []}, {"text": "The FST-based decoder described in that paper was launched in the Google Gboard keyboard system in early 2017.", "labels": [], "entities": [{"text": "Google Gboard keyboard system", "start_pos": 66, "end_pos": 95, "type": "DATASET", "confidence": 0.8803596496582031}]}, {"text": "In this paper, we present methods for extending this finite-state decoding approach for mobile keyboard input to transliterated keyboards, where the keyboard representation differs from the output script.", "labels": [], "entities": []}, {"text": "One very common scenario of this sort is the use of a standard QWERTY-style soft keyboard for entering text in a language with another writing system, typically because the Latin alphabet is simpler to represent on a compact soft keyboard.", "labels": [], "entities": []}, {"text": "Systems for mapping from sequences of symbols in the target script to sequences of Latin symbols are known as romanization.", "labels": [], "entities": []}, {"text": "The most widely known romanization system is Pinyin, which is a fully conventionalized system for Chinese.", "labels": [], "entities": []}, {"text": "For example, the word \u6c34 (water) in Chinese is written as \"shu\u012d\" in Pinyin.", "labels": [], "entities": []}, {"text": "Romanization, however, is quite widely used around the world, with such writing systems as Arabic, Cyril- lic, Greek and Thai.", "labels": [], "entities": []}, {"text": "In many cases, unlike Chinese, there is no agreed upon standard romanization system, leading to an increase in ambiguity and noise when decoding to the target words in the native script.", "labels": [], "entities": []}, {"text": "In this paper, we present a general transliteration approach applied to South Asian languages, transliterated from romanized input to a number of scripts, including Devanagari, Bengali and Perso-Arabic.", "labels": [], "entities": []}, {"text": "shows a screenshot of a mobile transliteration keyboard for Hindi with the Devanagari script, showing the trace of the user's input gesture.", "labels": [], "entities": []}, {"text": "While the user inputs romanized sequences, suggested word completions, as well as output strings, are in the target script.", "labels": [], "entities": []}, {"text": "In this context, we find that a WFST encoding of transliteration models allows for several optimizations that yield good accuracy under the strict resource and operating constraints of the ondevice keyboard decoding.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 121, "end_pos": 129, "type": "METRIC", "confidence": 0.9981589913368225}]}, {"text": "In what follows, we first provide background and preliminaries on Indic languages and their various scripts, as well as finite-state transducer terminology that will be used.", "labels": [], "entities": []}, {"text": "We then describe our transliteration modeling approach and a number of WFST optimizations that we perform to achieve the accuracy, latency and memory usage operating points.", "labels": [], "entities": [{"text": "transliteration modeling", "start_pos": 21, "end_pos": 45, "type": "TASK", "confidence": 0.8132002949714661}, {"text": "accuracy", "start_pos": 121, "end_pos": 129, "type": "METRIC", "confidence": 0.9992024302482605}]}, {"text": "Finally we present some experiments demonstrating the impact of the optimizations and comparing to an existing baseline.", "labels": [], "entities": []}, {"text": "On Hindi and Tamil validation sets, we demonstrate strong word error rate and latency reductions versus an existing baseline.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 58, "end_pos": 73, "type": "METRIC", "confidence": 0.6606137951215109}, {"text": "latency", "start_pos": 78, "end_pos": 85, "type": "METRIC", "confidence": 0.9528738856315613}]}, {"text": "We conclude by presenting the various languages and associated scripts for which transliteration keyboards using this approach have so far been launched in Google Gboard, and by discussing future directions of this work.", "labels": [], "entities": []}], "datasetContent": [{"text": "After setting meta-parameters on the development set for Hindi, we ran the decoder on blind test sets for both Hindi and Tamil.", "labels": [], "entities": []}, {"text": "presents a comparison between the WFST-based decoder and a baseline system.", "labels": [], "entities": [{"text": "WFST-based decoder", "start_pos": 34, "end_pos": 52, "type": "DATASET", "confidence": 0.8774256706237793}]}], "tableCaptions": [{"text": " Table 1: Size savings via LOUDS L \u2022 G construction.", "labels": [], "entities": [{"text": "Size", "start_pos": 10, "end_pos": 14, "type": "TASK", "confidence": 0.9105243682861328}, {"text": "LOUDS", "start_pos": 27, "end_pos": 32, "type": "METRIC", "confidence": 0.9162135720252991}]}, {"text": " Table 2: Word error rate (WER) and latency per character", "labels": [], "entities": [{"text": "Word error rate (WER)", "start_pos": 10, "end_pos": 31, "type": "METRIC", "confidence": 0.8927911917368571}]}]}