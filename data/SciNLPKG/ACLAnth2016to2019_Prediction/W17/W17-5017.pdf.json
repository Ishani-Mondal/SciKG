{"title": [{"text": "Investigating neural architectures for short answer scoring", "labels": [], "entities": []}], "abstractContent": [{"text": "Neural approaches to automated essay scoring have recently shown state-of-the-art performance.", "labels": [], "entities": [{"text": "essay scoring", "start_pos": 31, "end_pos": 44, "type": "TASK", "confidence": 0.7230418771505356}]}, {"text": "The automated essay scoring task typically involves abroad notion of writing quality that encompasses content, grammar, organization, and conventions.", "labels": [], "entities": [{"text": "essay scoring task", "start_pos": 14, "end_pos": 32, "type": "TASK", "confidence": 0.7759829958279928}]}, {"text": "This differs from the short answer content scoring task, which focuses on content accuracy.", "labels": [], "entities": [{"text": "short answer content scoring task", "start_pos": 22, "end_pos": 55, "type": "TASK", "confidence": 0.6261753499507904}, {"text": "accuracy", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.919750452041626}]}, {"text": "The inputs to neu-ral essay scoring models-ngrams and embeddings-are arguably well-suited to evaluate content in short answer scoring tasks.", "labels": [], "entities": []}, {"text": "We investigate how several basic neural approaches similar to those used for automated essay scoring perform on short answer scoring.", "labels": [], "entities": [{"text": "essay scoring", "start_pos": 87, "end_pos": 100, "type": "TASK", "confidence": 0.7024319767951965}, {"text": "short answer scoring", "start_pos": 112, "end_pos": 132, "type": "TASK", "confidence": 0.6037193536758423}]}, {"text": "We show that neural ar-chitectures can outperform a strong non-neural baseline, but performance and optimal parameter settings vary across the more diverse types of prompts typical of short answer scoring.", "labels": [], "entities": []}], "introductionContent": [{"text": "Deep neural network approaches have recently been successfully developed for several educational applications, including automated essay assessment.", "labels": [], "entities": [{"text": "automated essay assessment", "start_pos": 121, "end_pos": 147, "type": "TASK", "confidence": 0.6352074146270752}]}, {"text": "In several cases, neural network approaches exceeded the previous state of the art on essay scoring.", "labels": [], "entities": [{"text": "essay scoring", "start_pos": 86, "end_pos": 99, "type": "TASK", "confidence": 0.7956840693950653}]}, {"text": "The task of automated essay scoring (AES) is generally different from the task of automated short answer scoring (SAS).", "labels": [], "entities": [{"text": "automated essay scoring (AES)", "start_pos": 12, "end_pos": 41, "type": "TASK", "confidence": 0.7496717770894369}, {"text": "automated short answer scoring (SAS)", "start_pos": 82, "end_pos": 118, "type": "TASK", "confidence": 0.7612689180033547}]}, {"text": "Essay scoring generally focuses on writing quality, a multidimensional construct that includes ideas and elaboration, organization, style, and writing conventions such as grammar and spelling).", "labels": [], "entities": [{"text": "Essay scoring", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.9311928749084473}]}, {"text": "Short answer scoring, by contrast, typically focuses only on the accuracy of the content of responses (.", "labels": [], "entities": [{"text": "Short answer scoring", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.6902159651120504}, {"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9978943467140198}]}, {"text": "Analyzing the rubrics of prompts from the Automated Student Assessment Prize shared tasks on AES and SAS, while there is some overlap across essay scoring and short answer scoring, there are three main dimensions of differences: 1.", "labels": [], "entities": [{"text": "AES", "start_pos": 93, "end_pos": 96, "type": "DATASET", "confidence": 0.8679006695747375}]}, {"text": "Responses in SAS tasks are typically shorter.", "labels": [], "entities": [{"text": "SAS tasks", "start_pos": 13, "end_pos": 22, "type": "TASK", "confidence": 0.9241777658462524}]}, {"text": "For example, while the ASAP-AES data contains essays that average between about 100 and 600 tokens), short answer scoring datasets may have average answer lengths of just several words () to almost 60 words).", "labels": [], "entities": [{"text": "ASAP-AES data", "start_pos": 23, "end_pos": 36, "type": "DATASET", "confidence": 0.8057485818862915}]}, {"text": "2. Rubrics focus on content only in SAS vs. broader writing quality in AES.", "labels": [], "entities": [{"text": "AES", "start_pos": 71, "end_pos": 74, "type": "DATASET", "confidence": 0.8464818596839905}]}, {"text": "AES tasks cover persuasive, narrative, and source-dependent reading comprehension and English Language Arts (ELA), while SAS tasks tend to be from science, math, and ELA reading comprehension.", "labels": [], "entities": [{"text": "SAS", "start_pos": 121, "end_pos": 124, "type": "METRIC", "confidence": 0.9495995044708252}]}, {"text": "Given these differences, the feature sets for AES and SAS systems are often different, with AES incorporating a larger set of features to capture writing quality.", "labels": [], "entities": []}, {"text": "Nevertheless, deep learning approaches to AES have thus far demonstrated strong performance with minimal inputs consisting of unigrams and word embeddings.", "labels": [], "entities": [{"text": "AES", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.9667406678199768}]}, {"text": "For example, explore simple LSTM and CNN-based architectures with regression and evaluate on the ASAP-AES data.", "labels": [], "entities": [{"text": "ASAP-AES data", "start_pos": 97, "end_pos": 110, "type": "DATASET", "confidence": 0.8333994448184967}]}, {"text": "train score-specific word embeddings with several LSTM architectures.", "labels": [], "entities": []}, {"text": "demonstrate that a hierarchical CNN architecture produces strong results on the ASAP-AES data.", "labels": [], "entities": [{"text": "ASAP-AES data", "start_pos": 80, "end_pos": 93, "type": "DATASET", "confidence": 0.8773210644721985}]}, {"text": "Recently, show state-of-the-art performance on the ASAP-AES dataset with a memory network architecture.", "labels": [], "entities": [{"text": "ASAP-AES dataset", "start_pos": 51, "end_pos": 67, "type": "DATASET", "confidence": 0.8841199278831482}]}, {"text": "In this work, we investigate whether deep neural network approaches with similarly minimal feature sets can produce good performance on the SAS task, including whether they can exceed a strong non-neural baseline.", "labels": [], "entities": [{"text": "SAS task", "start_pos": 140, "end_pos": 148, "type": "TASK", "confidence": 0.9160149693489075}]}, {"text": "Unigram embeddingbased neural network approaches to essay scoring capture content signals from their input features, but the extent to which they capture other aspects of writing quality rubrics has not been established.", "labels": [], "entities": [{"text": "essay scoring", "start_pos": 52, "end_pos": 65, "type": "TASK", "confidence": 0.8184711039066315}]}, {"text": "These approaches as implemented would seem to lend themselves even better to the purely content-focused rubrics in SAS, where content signals should dominate in achieving good humanmachine agreement.", "labels": [], "entities": [{"text": "SAS", "start_pos": 115, "end_pos": 118, "type": "TASK", "confidence": 0.9462239146232605}]}, {"text": "On the other hand, recurrent neural networks may derive some of their predictive power in AES from more redundant signals in longer input sequences (as sketched by).", "labels": [], "entities": []}, {"text": "As a result, the shorter responses in SAS may hinder the ability of recurrent networks to achieve state-of-the-art results.", "labels": [], "entities": [{"text": "SAS", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.9655431509017944}]}, {"text": "To explore the effectiveness of neural network architectures on SAS, we use the basic architecture and parameters of on three publicly available short answer datasets: ASAP-SAS, Powergrading (, and SRA (.", "labels": [], "entities": [{"text": "SAS", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.9755061864852905}, {"text": "ASAP-SAS", "start_pos": 168, "end_pos": 176, "type": "METRIC", "confidence": 0.48672205209732056}, {"text": "SRA", "start_pos": 198, "end_pos": 201, "type": "METRIC", "confidence": 0.6472251415252686}]}, {"text": "While these datasets differ with respect to the length and complexity of student responses, all prompts in the datasets focus on content accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 137, "end_pos": 145, "type": "METRIC", "confidence": 0.9477429986000061}]}, {"text": "We explore how well the optimal parameters for AES from fare on these datasets, and whether different architectures and parameters perform better on the SAS task.", "labels": [], "entities": [{"text": "SAS task", "start_pos": 153, "end_pos": 161, "type": "TASK", "confidence": 0.8886339962482452}]}], "datasetContent": [{"text": "The three datasets we use cover different kinds of prompts and vary considerably in the length of the answers as well as their well-formedness.", "labels": [], "entities": []}, {"text": "shows basic statistics for each dataset.", "labels": [], "entities": []}, {"text": "Figures 1, 2 and 3 show examples for each of the datasets.", "labels": [], "entities": []}, {"text": "The text is lightly preprocessed as input to the neural networks following.", "labels": [], "entities": []}, {"text": "The text is tokenized with the standard NLTK tokenizer and lowercased.", "labels": [], "entities": []}, {"text": "All numbers are mapped to a single <num> symbol.", "labels": [], "entities": []}, {"text": "Each response is padded with a dummy token to uniform length, but these dummy tokens are masked out during model training.", "labels": [], "entities": []}, {"text": "For the ASAP-SAS and Powergrading datasets, prior to training, we scale all scores of responses to and use these scaled scores as input to the networks.", "labels": [], "entities": [{"text": "ASAP-SAS", "start_pos": 8, "end_pos": 16, "type": "TASK", "confidence": 0.5587154626846313}, {"text": "Powergrading datasets", "start_pos": 21, "end_pos": 42, "type": "DATASET", "confidence": 0.6853733658790588}]}, {"text": "For evaluation, the scaled scores are converted back to their original range.", "labels": [], "entities": [{"text": "evaluation", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.9601792693138123}]}, {"text": "The SRA class labels are used as is.", "labels": [], "entities": [{"text": "SRA class labels", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.6980733970801035}]}, {"text": "We fix a number of neural network parame-4 It maybe the case that relevant content information is thus ignored.", "labels": [], "entities": []}, {"text": "However, since many numbers occur with units of measurement, e.g. 1g, we do not have word embeddings for them either and so the embeddings would simply be random initializations.", "labels": [], "entities": []}, {"text": "We leave a full exploration of this issue to future work.", "labels": [], "entities": []}, {"text": "For pretrained embeddings, in preliminary experiments the GloVe 100 dimension vectors () performed slightly better than a selection of other offthe-shelf embeddings, and hence we use these for all conditions that involve pretrained embeddings.", "labels": [], "entities": [{"text": "GloVe 100 dimension vectors", "start_pos": 58, "end_pos": 85, "type": "METRIC", "confidence": 0.8816720992326736}]}, {"text": "Embeddings for word tokens that are not found in the embeddings are randomly initialized from a uniform distribution.", "labels": [], "entities": []}, {"text": "The convolutional layer uses a window length of 3 or 5 and 50 filters.", "labels": [], "entities": []}, {"text": "We use a mean squared error loss for regression models and a cross-entropy loss for classification models.", "labels": [], "entities": [{"text": "mean squared error loss", "start_pos": 9, "end_pos": 32, "type": "METRIC", "confidence": 0.8635685294866562}]}, {"text": "To train the network, we use RMSProp with \u03c1 set to 0.9 and learning rate of 0.001.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 59, "end_pos": 72, "type": "METRIC", "confidence": 0.9795249104499817}]}, {"text": "We clip the norm of the gradient to 10.", "labels": [], "entities": []}, {"text": "The fully connected layer's bias is initialized to the mean score for the training data, and the layer is regularized with dropout of 0.5.", "labels": [], "entities": []}, {"text": "We use a batch size of 32, which provided a good compromise between performance and runtime in preliminary experiments.", "labels": [], "entities": []}, {"text": "To obtain more consistent results and improve predictive performance, we evaluate the models by keeping an exponential moving average of the model's weights during training.", "labels": [], "entities": []}, {"text": "The moving average weights w EM A are updated after each batch by dis a decay rate that is updated dynamically at each batch by taking into account the number of batches so far: where decay is a maximum decay rate, which we set to 0.999.", "labels": [], "entities": []}, {"text": "This decay rate updating procedure allows the weights to be updated quickly at first while stabilizing across time.", "labels": [], "entities": []}, {"text": "All models are trained for 50 epochs for parameter exploration on the development set (Section 3.5) and 50 epochs for the final models on the test set (Section 3.6).", "labels": [], "entities": []}, {"text": "Following, for our parameter exploration experiments on the development set, we report the best performance across epochs.", "labels": [], "entities": []}, {"text": "When we train final models on the combined training and development set and evaluate on the test set, we report the results from the last epoch.", "labels": [], "entities": []}, {"text": "During development, we observed that even after employing best practices for ensuring repro-ducibility of results 5 , there was still some small variation between runs of the same parameter settings.", "labels": [], "entities": []}, {"text": "The reasons for this variability were not clear.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Overview of the datasets used in this work. Since we train prompt-specific models for ASAP- SAS and PG, we report the mean number of responses per set per prompt. For SRA, we train one model  per label set across prompts and report the overall number of prompts per set as well as the mean number  of responses per prompt per set (in parentheses).", "labels": [], "entities": [{"text": "ASAP- SAS", "start_pos": 96, "end_pos": 105, "type": "TASK", "confidence": 0.5819607575734457}, {"text": "SRA", "start_pos": 177, "end_pos": 180, "type": "TASK", "confidence": 0.8636987805366516}]}, {"text": " Table 2: Parameter experiment results on ASAP-SAS and Powergrading on the development set.  \"Baseline\" is the baseline non-neural system. \"T&N best\" is the best-performing parameter set in  Taghipour and Ng (2016): tuned embeddings (here, GLOVE 100 dimensions), 300-dimensional LSTM,  unidirectional, mean-over-time layer. Scores are bolded if they outperform the score for the \"T&N best\"  parameter setting.", "labels": [], "entities": []}, {"text": " Table 3: Parameter experiment results on SRA datasets on the development set. \"wF1\" is the weighted  F1 score. \"Baseline\" is the baseline non-neural system. \"T&N best\" is the best-performing parameter set  in", "labels": [], "entities": [{"text": "SRA datasets", "start_pos": 42, "end_pos": 54, "type": "DATASET", "confidence": 0.8674192726612091}, {"text": "F1 score", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9762276709079742}]}, {"text": " Table 4: Test set results for all datasets across prompts. Scores for ASAP-SAS and PG are QWK.  Mean Fisher is the Fisher-transformed mean QWK used in the ASAP-SAS competition. Scores for SRA  are weighted F1 scores.", "labels": [], "entities": [{"text": "ASAP-SAS", "start_pos": 71, "end_pos": 79, "type": "DATASET", "confidence": 0.8028741478919983}, {"text": "Mean Fisher", "start_pos": 97, "end_pos": 108, "type": "METRIC", "confidence": 0.954864501953125}, {"text": "SRA", "start_pos": 189, "end_pos": 192, "type": "TASK", "confidence": 0.8932251334190369}, {"text": "F1", "start_pos": 207, "end_pos": 209, "type": "METRIC", "confidence": 0.9922978281974792}]}]}