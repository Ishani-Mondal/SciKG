{"title": [{"text": "An enhanced automatic speech recognition system for Arabic", "labels": [], "entities": [{"text": "automatic speech recognition", "start_pos": 12, "end_pos": 40, "type": "TASK", "confidence": 0.6405078570048014}]}], "abstractContent": [{"text": "Automatic speech recognition for Arabic is a very challenging task.", "labels": [], "entities": [{"text": "Automatic speech recognition", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.695884128411611}]}, {"text": "Despite all the classical techniques for Automatic Speech Recognition (ASR), which can be efficiently applied to Arabic speech recognition , it is essential to take into consideration the language specificities to improve the system performance.", "labels": [], "entities": [{"text": "Automatic Speech Recognition (ASR)", "start_pos": 41, "end_pos": 75, "type": "TASK", "confidence": 0.8191714783509573}, {"text": "Arabic speech recognition", "start_pos": 113, "end_pos": 138, "type": "TASK", "confidence": 0.6690082848072052}]}, {"text": "In this article, we focus on Modern Standard Arabic (MSA) speech recognition.", "labels": [], "entities": [{"text": "Modern Standard Arabic (MSA) speech recognition", "start_pos": 29, "end_pos": 76, "type": "TASK", "confidence": 0.8338069543242455}]}, {"text": "We introduce the challenges related to Arabic language, namely the complex morphology nature of the language and the absence of the short vowels in written text, which leads to several potential vowelization for each graphemes, which is often conflicting.", "labels": [], "entities": []}, {"text": "We develop an ASR system for MSA by using Kaldi toolkit.", "labels": [], "entities": [{"text": "ASR", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.9867812991142273}, {"text": "MSA", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.9417918920516968}]}, {"text": "Several acoustic and language models are trained.", "labels": [], "entities": []}, {"text": "We obtain a Word Error Rate (WER) of 14.42 for the baseline system and 12.2 relative improvement by rescoring the lattice and by rewriting the output with the right hamoza above or below Alif.", "labels": [], "entities": [{"text": "Word Error Rate (WER)", "start_pos": 12, "end_pos": 33, "type": "METRIC", "confidence": 0.8876931369304657}]}], "introductionContent": [{"text": "The Arabic language is the fifth most widely spoken language in the world with an estimated 295 million native speakers.", "labels": [], "entities": []}, {"text": "It is one of the most morphologically complex languages.", "labels": [], "entities": []}, {"text": "Due to this, developing an Automatic Speech Recognition (ASR) system for Arabic is a very challenging task.", "labels": [], "entities": [{"text": "Automatic Speech Recognition (ASR)", "start_pos": 27, "end_pos": 61, "type": "TASK", "confidence": 0.7600775162378947}]}, {"text": "Arabic language is characterized by the high number of dialects used in daily communications.", "labels": [], "entities": []}, {"text": "There is a significant difference between these dialects and the Modern Standard Arabic (MSA), which is used in newspapers and formal communication.", "labels": [], "entities": [{"text": "Modern Standard Arabic (MSA)", "start_pos": 65, "end_pos": 93, "type": "DATASET", "confidence": 0.7028716951608658}]}, {"text": "In this article, we will describe our ASR system for MSA implemented using Kaldi toolkit.", "labels": [], "entities": [{"text": "ASR", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.985531210899353}]}, {"text": "Kaldi is a state of the art toolkit for speech recognition based on Weighted Finite State Transducers (WFST).", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.8168898224830627}]}, {"text": "It includes multiple scripts and recipes for most standard techniques.", "labels": [], "entities": []}, {"text": "These recipes are available with many speech corpora and they are frequently updated to support the latest techniques like Deep Neural Networks.", "labels": [], "entities": []}, {"text": "In this work, several state of the art's modeling techniques are tested, namely the GMM-HMM models, the DNN-HMM models and various techniques like: Maximum Mutual Information (MMI) (, feature-space Maximum Likelihood Linear Regression (fMLLR)) and Speaker Adaptive Training (SAT) ().", "labels": [], "entities": [{"text": "Maximum Mutual Information (MMI)", "start_pos": 148, "end_pos": 180, "type": "METRIC", "confidence": 0.7722299744685491}, {"text": "feature-space Maximum Likelihood Linear Regression (fMLLR))", "start_pos": 184, "end_pos": 243, "type": "METRIC", "confidence": 0.6043565534055233}, {"text": "Speaker Adaptive Training (SAT)", "start_pos": 248, "end_pos": 279, "type": "TASK", "confidence": 0.6384707937637965}]}, {"text": "The gain obtained after training each model will be reported later on.", "labels": [], "entities": []}, {"text": "Our ASR system is built using several hours of standard Arabic news broadcasts from corpora distributed by ELRA.", "labels": [], "entities": [{"text": "ASR", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9701959490776062}, {"text": "ELRA", "start_pos": 107, "end_pos": 111, "type": "DATASET", "confidence": 0.9591026306152344}]}, {"text": "Another interesting treatment, proposed in this article, is the auto-correction of hamoza in the ASR system output in order to rectify the orthography confusion of this symbol above or below Alif.", "labels": [], "entities": [{"text": "ASR", "start_pos": 97, "end_pos": 100, "type": "TASK", "confidence": 0.8685864210128784}]}, {"text": "The approach used is inspired from various techniques proposed in the literature for detection and correction of spelling errors.", "labels": [], "entities": [{"text": "detection and correction of spelling errors", "start_pos": 85, "end_pos": 128, "type": "TASK", "confidence": 0.7988841036955515}]}, {"text": "The particularity of our approach is the use of the vector representation of words to retrieve the context and to correct misspelled words.", "labels": [], "entities": []}, {"text": "In the next section, an overview about Arabic language issues and some works proposed in the literature to deal with those problems is presented.", "labels": [], "entities": []}, {"text": "Section 3 describes the different corpus used to train the acoustic and language models, as well as the data normalization process.", "labels": [], "entities": [{"text": "data normalization", "start_pos": 104, "end_pos": 122, "type": "TASK", "confidence": 0.7385603189468384}]}, {"text": "Section 4 details the acoustic and language models.", "labels": [], "entities": []}, {"text": "Finally, the experimental results are discussed in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section presents the speech recognition results obtained with a 95k word lexicon for the baseline system, and after rescoring the lattice.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.7323945462703705}]}, {"text": "We also proposed an approach to auto-correct the hamoza above or below Alif to improve the performance.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Statistics about LMs used to generate and  to rescore the lattice.", "labels": [], "entities": []}, {"text": " Table 4: WERs (%) for baseline systems (without  rescoring and by using the 2-grams LM).", "labels": [], "entities": [{"text": "WERs", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9979091286659241}]}, {"text": " Table 6: WERs (%) before and after correcting the  hamoza.", "labels": [], "entities": [{"text": "WERs", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.999276340007782}]}]}