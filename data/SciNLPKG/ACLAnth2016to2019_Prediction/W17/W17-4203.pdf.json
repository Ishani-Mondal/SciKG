{"title": [{"text": "Tracking Bias in News Sources Using Social Media: the Russia-Ukraine Maidan Crisis of 2013-2014", "labels": [], "entities": [{"text": "Tracking Bias", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.9169839322566986}]}], "abstractContent": [{"text": "This paper addresses the task of identifying the bias in news articles published during apolitical or social conflict.", "labels": [], "entities": [{"text": "identifying the bias in news articles published during apolitical or social conflict", "start_pos": 33, "end_pos": 117, "type": "TASK", "confidence": 0.8241074681282043}]}, {"text": "We create a silver-standard corpus based on the actions of users in social media.", "labels": [], "entities": []}, {"text": "Specifically , we reconceptualize bias in terms of how likely a given article is to be shared or liked by each of the opposing sides.", "labels": [], "entities": []}, {"text": "We apply our methodology to a dataset of links collected in relation to the Russia-Ukraine Maidan crisis from 2013-2014.", "labels": [], "entities": []}, {"text": "We show that on the task of predicting which side is likely to prefer a given article , a Naive Bayes classifier can record 90.3% accuracy looking only at domain names of the news sources.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 130, "end_pos": 138, "type": "METRIC", "confidence": 0.9988563060760498}]}, {"text": "The best accuracy of 93.5% is achieved by a feed forward neural network.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9996141195297241}]}, {"text": "We also apply our methodology to gold-labeled set of articles annotated for bias, where the afore-mentioned Naive Bayes classifier records 82.6% accuracy and a feed-forward neural networks records 85.6% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 145, "end_pos": 153, "type": "METRIC", "confidence": 0.9936656355857849}, {"text": "accuracy", "start_pos": 203, "end_pos": 211, "type": "METRIC", "confidence": 0.9964244961738586}]}], "introductionContent": [{"text": "The proliferation of online information sources and the dissolution of the centralized news delivery system creates a situation where news no longer comes from a restricted set of reputable (or not-so-reputable) news organizations, but rather from a collection of multiple distributed sources such as blogs, political columns, and social media posts.", "labels": [], "entities": []}, {"text": "In times of social or political conflict, or when contentious issues are involved, such sources may present biased opinions or outright propaganda, which an unprepared reader is often not equipped to detect.", "labels": [], "entities": []}, {"text": "News aggregators (such as Google News) present the news organized by topics and popularity.", "labels": [], "entities": []}, {"text": "But an adequate understanding of a news story or a blog post requires weeding out the \"spin\" or \"framing\", which reflects the source's position on the spectrum of conflicting opinions.", "labels": [], "entities": [{"text": "understanding of a news story or a blog post", "start_pos": 16, "end_pos": 60, "type": "TASK", "confidence": 0.7083936168087853}]}, {"text": "In short, we need to know not only the content of the story, but also the intent behind it.", "labels": [], "entities": []}, {"text": "Many supervised approaches to bias detection rely on text analysis (), effectively detecting words, phrases, and memes characteristic of an ideology or apolitical position.", "labels": [], "entities": [{"text": "bias detection", "start_pos": 30, "end_pos": 44, "type": "TASK", "confidence": 0.8307934403419495}]}, {"text": "All such methods can be characterized as language-based methods of bias detection.", "labels": [], "entities": [{"text": "bias detection", "start_pos": 67, "end_pos": 81, "type": "TASK", "confidence": 0.8103614449501038}]}, {"text": "In contrast, the methods that we term reactionbased use human response to a news source in order to identify its bias.", "labels": [], "entities": []}, {"text": "Such response is registered, for example, in social media when users post links to news sources, or like the posts that contain such links.", "labels": [], "entities": []}, {"text": "We observe that with respect to divisive issues, users tend to split into cohesive groups based on their like streams: people from conflicting groups will like and pass around sources and links that express the opinions and the sentiment common only within their group.", "labels": [], "entities": []}, {"text": "Put simply, reaction-based methods determine the bias of a source by how the communities of politically like-minded users react to it, based on the amount of liking, reposting, retweeting, etc., the text gets from the opposing groups.", "labels": [], "entities": []}, {"text": "Such methods have recently been used with success in the context of liberal/conservative biases in US politics.", "labels": [], "entities": []}, {"text": "We believe the language-based and reactionbased methods are complementary and should be combined to supplement each other.", "labels": [], "entities": []}, {"text": "Much work in bias detection relies on pre-existing annotated corpora of texts with known conservative and liberal biases.", "labels": [], "entities": [{"text": "bias detection", "start_pos": 13, "end_pos": 27, "type": "TASK", "confidence": 0.9597949683666229}]}, {"text": "Such corpora obviously do not exist for most ideologies and biases found outside of American or Western discourse.", "labels": [], "entities": []}, {"text": "In this work, we propose to use a reaction-based analysis of biases in news sources in order to create a large silver standard of bias-marked text that will be used to train language-based bias detection models.", "labels": [], "entities": [{"text": "language-based bias detection", "start_pos": 174, "end_pos": 203, "type": "TASK", "confidence": 0.6331071058909098}]}, {"text": "This is done by collecting the articles reacted upon (liked/linked/posted) by the members of opposing political groups in social networks.", "labels": [], "entities": []}, {"text": "We thus conceptualize the bias of a news article in terms of how likely it is to be referenced by one of the opposing groups, following the idea that any publicity is good publicity, and any reference to a source can in a some sense be considered a positive reference.", "labels": [], "entities": []}, {"text": "The resulting \"silver\" corpus is slightly noisier than a manually annotated gold standard such as the one used in), but makes up for this deficiency by not being limited in size.", "labels": [], "entities": [{"text": "silver\" corpus", "start_pos": 15, "end_pos": 29, "type": "DATASET", "confidence": 0.6511569321155548}]}, {"text": "In this work, we use the Russia-Ukraine Maidan conflict of 2013-2014 as a case study for predicting bias in a polarized environment.", "labels": [], "entities": []}, {"text": "We collect a large silver corpus of news articles using the posts in the user groups dedicated to the discussion of this conflict in a Russian social media network VKontakte, and evaluate several methods of using this data to predict which side is likely to like and share a given article.", "labels": [], "entities": []}, {"text": "We use features derived both from a source's URL as well as the text of the article.", "labels": [], "entities": []}, {"text": "We also analyze the news sharing patterns in order to characterize the specific conflict represented in our case study.", "labels": [], "entities": []}, {"text": "Lastly, we annotate a small corpus of news articles for bias in relation to the Maidan crisis.", "labels": [], "entities": [{"text": "Maidan crisis", "start_pos": 80, "end_pos": 93, "type": "DATASET", "confidence": 0.8405451476573944}]}, {"text": "We are then able to test the effectiveness of classifiers on gold-standard data when trained solely with silver-labeled data.", "labels": [], "entities": []}, {"text": "Our results show that predicting bias based on the frequency of sharing patterns of users representing opposing communities for our case study is quite effective.", "labels": [], "entities": [{"text": "predicting bias", "start_pos": 22, "end_pos": 37, "type": "TASK", "confidence": 0.8869251906871796}]}, {"text": "Specifically, a Naive Bayes classifier using only the domain name of a link as a feature (a one-hot input representation) achieves 90% accuracy on a bias prediction task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 135, "end_pos": 143, "type": "METRIC", "confidence": 0.9988296627998352}, {"text": "bias prediction task", "start_pos": 149, "end_pos": 169, "type": "TASK", "confidence": 0.7560121119022369}]}, {"text": "We compare an SVM-based classification method with a Feed Forward Neural Network (FFNN), and find that the best accuracy of 93.5% is achieved by the FFNN.", "labels": [], "entities": [{"text": "SVM-based classification", "start_pos": 14, "end_pos": 38, "type": "TASK", "confidence": 0.7834585309028625}, {"text": "accuracy", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.9993425011634827}, {"text": "FFNN", "start_pos": 149, "end_pos": 153, "type": "DATASET", "confidence": 0.9186084866523743}]}], "datasetContent": [{"text": "In this study, we use data from Russian-speaking online media, posted during the Ukrainian events of.", "labels": [], "entities": []}, {"text": "We use the largest Russian social network \"VKontakte\" (VK)  liveinternet.ru, VKontakte has 320 million registered users and is the most popular social network in both Russia and Ukraine.", "labels": [], "entities": [{"text": "VKontakte\" (VK)  liveinternet.ru", "start_pos": 43, "end_pos": 75, "type": "DATASET", "confidence": 0.7945230603218079}]}, {"text": "During the conflict, both pro-Russian (also known as \"Antimaidan\") and pro-Ukrainian side (also known as \"Pro-\" or \"Evromaidan\") were represented online by large numbers of Russian-speaking users.", "labels": [], "entities": []}, {"text": "We have built a scalable open stack system for data collection from VKontakte using the VK API.", "labels": [], "entities": [{"text": "VKontakte", "start_pos": 68, "end_pos": 77, "type": "DATASET", "confidence": 0.9833941459655762}, {"text": "VK API", "start_pos": 88, "end_pos": 94, "type": "DATASET", "confidence": 0.903108686208725}]}, {"text": "The system is implemented in Python using a PostgreSQL database and Redis-based message queue.", "labels": [], "entities": []}, {"text": "VK API has a less restrictive policy than Facebook's API, making it an especially suitable social network for research.", "labels": [], "entities": [{"text": "VK API", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8760369122028351}]}, {"text": "Our system supports the API methods for retrieving the group members, retrieving all posts from a wall, retrieving comments and likes fora given post, and soon.", "labels": [], "entities": []}, {"text": "In order to seed the data collection, we selected the most popular user groups from the two op-posing camps, the Evromaidan group (154,589 members) and the Antimaidan group (580,672 members).", "labels": [], "entities": [{"text": "Evromaidan group", "start_pos": 113, "end_pos": 129, "type": "DATASET", "confidence": 0.9122543632984161}, {"text": "Antimaidan group", "start_pos": 156, "end_pos": 172, "type": "DATASET", "confidence": 0.9054427742958069}]}, {"text": "We then manually annotated other groups to which the administrators of these two groups belonged, selecting groups with political content.", "labels": [], "entities": []}, {"text": "This process produced 47 Evromaidanrelated groups with 2,445,661 unique members and 51 Antimaidan-related groups with 1,942,918 unique members.", "labels": [], "entities": []}, {"text": "To create a dataset for our experiments, we randomly selected 10,000 links, 5,000 each from Antimaidan and Evromaidan-related group walls.", "labels": [], "entities": []}, {"text": "Links are disregarded if they appear on walls from both sides, which is to ensure an unambiguous assignment of labels.", "labels": [], "entities": []}, {"text": "We made a 90%/10% train/test split of the data.", "labels": [], "entities": []}, {"text": "The labels for the links correspond to whether they came from an Antimaidan or Evromaidan related wall.", "labels": [], "entities": [{"text": "Antimaidan or Evromaidan related wall", "start_pos": 65, "end_pos": 102, "type": "DATASET", "confidence": 0.8515541315078735}]}, {"text": "We refer to these datasets as our silver-labeled training and test sets.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the occurrences of domains  extracted from Google News.", "labels": [], "entities": []}, {"text": " Table 4: Accuracy of the SVM model with text  features based on differing amounts of training  data. Evaluation is done on silver-labeled test set.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9651731848716736}]}]}