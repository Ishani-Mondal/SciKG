{"title": [{"text": "Shortcut-Stacked Sentence Encoders for Multi-Domain Inference", "labels": [], "entities": [{"text": "Multi-Domain Inference", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.6873374134302139}]}], "abstractContent": [{"text": "We present a simple sequential sentence encoder for multi-domain natural language inference.", "labels": [], "entities": [{"text": "multi-domain natural language inference", "start_pos": 52, "end_pos": 91, "type": "TASK", "confidence": 0.6386042758822441}]}, {"text": "Our encoder is based on stacked bidirectional LSTM-RNNs with shortcut connections and fine-tuning of word embeddings.", "labels": [], "entities": []}, {"text": "The overall supervised model uses the above encoder to encode two input sentences into two vectors, and then uses a classifier over the vector combination to label the relationship between these two sentences as that of entailment, contradiction, or neural.", "labels": [], "entities": []}, {"text": "Our Shortcut-Stacked sentence encoders achieve strong improvements over existing encoders on matched and mismatched multi-domain natural language inference (top single-model result in the EMNLP RepEval 2017 Shared Task (Nangia et al., 2017)).", "labels": [], "entities": [{"text": "EMNLP RepEval 2017 Shared Task", "start_pos": 188, "end_pos": 218, "type": "DATASET", "confidence": 0.7920322060585022}]}, {"text": "Moreover , they achieve the new state-of-the-art encoding result on the original SNLI dataset (Bowman et al., 2015).", "labels": [], "entities": [{"text": "SNLI dataset", "start_pos": 81, "end_pos": 93, "type": "DATASET", "confidence": 0.8653841912746429}]}], "introductionContent": [], "datasetContent": [{"text": "As instructed in the RepEval Multi-NLI shared task, we use all of the training data in Multi-NLI combined with 15% randomly selected samples from the SNLI training set resampled at each epoch) as our final training set for all models; and we use both the cross-domain ('mismatched') and in-domain ('matched') Multi-NLI development sets for model selection.", "labels": [], "entities": [{"text": "RepEval Multi-NLI shared task", "start_pos": 21, "end_pos": 50, "type": "TASK", "confidence": 0.7722255140542984}, {"text": "SNLI training set", "start_pos": 150, "end_pos": 167, "type": "DATASET", "confidence": 0.8321947058041891}, {"text": "model selection", "start_pos": 340, "end_pos": 355, "type": "TASK", "confidence": 0.6549191325902939}]}, {"text": "For the SNLI test results in, we train on only the SNLI training set (and we also verify that the tuning decisions hold true on the SNLI dev set).", "labels": [], "entities": [{"text": "SNLI", "start_pos": 8, "end_pos": 12, "type": "TASK", "confidence": 0.8516928553581238}, {"text": "SNLI training set", "start_pos": 51, "end_pos": 68, "type": "DATASET", "confidence": 0.9336193799972534}, {"text": "SNLI dev set", "start_pos": 132, "end_pos": 144, "type": "DATASET", "confidence": 0.847978949546814}]}], "tableCaptions": [{"text": " Table 1: Analysis of results for models with dif- ferent # of biLSTM layers and their hidden state  dimensions.", "labels": [], "entities": []}, {"text": " Table 2: Ablation results with and without shortcut  connections.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9948523640632629}]}, {"text": " Table 3: Ablation results with and without fine- tuning of word embeddings.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9908360242843628}]}, {"text": " Table 4: Ablation results for different MLP classi- fiers.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9968633651733398}, {"text": "MLP classi- fiers", "start_pos": 41, "end_pos": 58, "type": "DATASET", "confidence": 0.6186844483017921}]}, {"text": " Table 5: Final Test Results on SNLI and Multi-NLI datasets.", "labels": [], "entities": [{"text": "SNLI", "start_pos": 32, "end_pos": 36, "type": "DATASET", "confidence": 0.6791601181030273}, {"text": "Multi-NLI datasets", "start_pos": 41, "end_pos": 59, "type": "DATASET", "confidence": 0.6956437081098557}]}]}