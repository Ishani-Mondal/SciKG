{"title": [{"text": "Benchmarking Joint Lexical and Syntactic Analysis on Multiword-Rich Data", "labels": [], "entities": [{"text": "Syntactic Analysis", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.7592894434928894}]}], "abstractContent": [{"text": "This article evaluates the extension of a dependency parser that performs joint syntactic analysis and multiword expression identification.", "labels": [], "entities": [{"text": "multiword expression identification", "start_pos": 103, "end_pos": 138, "type": "TASK", "confidence": 0.7762318054835001}]}, {"text": "We show that, given sufficient training data, the parser benefits from explicit multiword information and improves overall labeled accuracy score in eight of the ten evaluation cases.", "labels": [], "entities": [{"text": "accuracy score", "start_pos": 131, "end_pos": 145, "type": "METRIC", "confidence": 0.9354976415634155}]}], "introductionContent": [{"text": "In this paper, we expand the work of Constant and Nivre (2016) -henceforth CN16-by evaluating their system more extensively, representing Multiword Expressions (MWEs) in different ways that are linguistically motivated.", "labels": [], "entities": []}, {"text": "Their transitionbased system jointly performs lexical analysis and syntactic dependency parsing, using special transitions for MWE identification.", "labels": [], "entities": [{"text": "syntactic dependency parsing", "start_pos": 67, "end_pos": 95, "type": "TASK", "confidence": 0.6342345078786215}, {"text": "MWE identification", "start_pos": 127, "end_pos": 145, "type": "TASK", "confidence": 0.9532248377799988}]}, {"text": "In particular, these special transitions generate new lexical nodes for MWEs, that can also serve as nodes of the syntactic dependency trees.", "labels": [], "entities": []}, {"text": "Their system is based on the classical split between fixed and free MWEs.", "labels": [], "entities": []}, {"text": "Fixed MWEs defined by are contiguous.", "labels": [], "entities": []}, {"text": "They are considered syntactically nondecomposable and are represented as a single syntactic node that requires apart of speech (POS) tag like all other tokens.", "labels": [], "entities": []}, {"text": "Free MWEs are the remaining MWEs, that usually display regular internal structure and variations.", "labels": [], "entities": []}, {"text": "The system predicts their internal syntactic structure, and their MWE status.", "labels": [], "entities": []}, {"text": "The hypothesis behind this approach is that such a specialized extension of a standard transitionbased parser to capture lexical relation for MWEs is a better option than using a regular transition based parser that relies on distributed annotation for MWEs as it is used for example in Universal Dependencies ( ).", "labels": [], "entities": []}, {"text": "In our experiments, we used UD, which we believe is an interesting playground because it provides different lexical-association labels such as MWEs.", "labels": [], "entities": []}, {"text": "Nonetheless, we encounter an important drawback regarding MWEs, i.e. they are not provided with an overall POS, which plays a key role in our parsing systems.", "labels": [], "entities": [{"text": "POS", "start_pos": 107, "end_pos": 110, "type": "METRIC", "confidence": 0.9515700936317444}]}, {"text": "We have therefore proposed a common filler principle in order to automatically assign a POS to each MWE.", "labels": [], "entities": [{"text": "POS", "start_pos": 88, "end_pos": 91, "type": "METRIC", "confidence": 0.981004536151886}]}, {"text": "Our other hypothesis is that enriching treebanks with explicit annotation of MWE status and MWE POS should help parsing accuracy.", "labels": [], "entities": [{"text": "MWE", "start_pos": 92, "end_pos": 95, "type": "DATASET", "confidence": 0.432170569896698}, {"text": "POS", "start_pos": 96, "end_pos": 99, "type": "METRIC", "confidence": 0.47403839230537415}, {"text": "parsing", "start_pos": 112, "end_pos": 119, "type": "TASK", "confidence": 0.9785640239715576}, {"text": "accuracy", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.9478064179420471}]}, {"text": "In addition, since UD treebanks maybe non-projective, we have improved the parsing algorithm to account for nonprojective trees, which the original work in CN16 could not provide.", "labels": [], "entities": [{"text": "parsing", "start_pos": 75, "end_pos": 82, "type": "TASK", "confidence": 0.9596299529075623}]}, {"text": "In the setup of CN16, only projective sentences could be used for training.", "labels": [], "entities": [{"text": "CN16", "start_pos": 16, "end_pos": 20, "type": "DATASET", "confidence": 0.9606876373291016}]}], "datasetContent": [{"text": "Each of the competing systems in our experiments is a combination of one of the five data variants (Section 3.1 ), and one of the three parsers: the full (FULL) or partial (PART) parsers in Section 2.1, or a standard transition-based parser (STD) without a lexical stack or Merge/Complete transitions.", "labels": [], "entities": [{"text": "FULL", "start_pos": 155, "end_pos": 159, "type": "METRIC", "confidence": 0.9767207503318787}]}, {"text": "For instance, the FULL C system uses the FULL parser on Variant C of the multiword inventory.", "labels": [], "entities": []}, {"text": "We compare these systems to a baseline without special data transformations for MWEs, and that depends on the standard transition-based parser.", "labels": [], "entities": []}, {"text": "The aim of our experiments is not to optimize a parser for UD, but to benefit from the amount and variety of data offered by it to benchmark the possibilities of joint lexical and syntactic prediction.", "labels": [], "entities": [{"text": "UD", "start_pos": 59, "end_pos": 61, "type": "TASK", "confidence": 0.8818471431732178}, {"text": "joint lexical and syntactic prediction", "start_pos": 162, "end_pos": 200, "type": "TASK", "confidence": 0.616073602437973}]}, {"text": "Data: We have chosen treebanks where the mwe label constitutes at least 1% of the labels in the development section, and where the support is of at least 100 instances, cf.: Language-wise best system scores for the test (above) and development (below) sections.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Language-wise best system scores for the test (above) and development (below) sections.", "labels": [], "entities": []}]}