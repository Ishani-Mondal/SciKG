{"title": [{"text": "Word Similarity Datasets for Indian Languages: Annotation and Baseline Systems", "labels": [], "entities": [{"text": "Word Similarity", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.5981735587120056}]}], "abstractContent": [{"text": "With the advent of word representations, word similarity tasks are becoming increasing popular as an evaluation metric for the quality of the representations.", "labels": [], "entities": []}, {"text": "In this paper, we present manually annotated monolingual word similarity datasets of six Indian languages-Urdu, Tel-ugu, Marathi, Punjabi, Tamil and Gu-jarati.", "labels": [], "entities": []}, {"text": "These languages are most spoken Indian languages worldwide after Hindi and Bengali.", "labels": [], "entities": []}, {"text": "For the construction of these datasets, our approach relies on translation and re-annotation of word similarity datasets of English.", "labels": [], "entities": []}, {"text": "We also present base-line scores for word representation models using state-of-the-art techniques for Urdu, Telugu and Marathi by evaluating them on newly created word similarity datasets.", "labels": [], "entities": [{"text": "word representation", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.794379860162735}]}], "introductionContent": [{"text": "Word representations are being increasingly popular in various areas of natural language processing like dependency parsing (), named entity recognition () and parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 105, "end_pos": 123, "type": "TASK", "confidence": 0.7444009482860565}, {"text": "named entity recognition", "start_pos": 128, "end_pos": 152, "type": "TASK", "confidence": 0.6040679315725962}, {"text": "parsing", "start_pos": 160, "end_pos": 167, "type": "TASK", "confidence": 0.9779583811759949}]}, {"text": "Word similarity task is one of the most popular benchmark for the evaluation of word representations.", "labels": [], "entities": [{"text": "Word similarity", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.6864252537488937}]}, {"text": "Applications of word similarity range from Word Sense Disambiguation (), Machine Translation Evaluation (, Question Answering (, and Lexical Substitution (.", "labels": [], "entities": [{"text": "word similarity", "start_pos": 16, "end_pos": 31, "type": "TASK", "confidence": 0.7537907958030701}, {"text": "Word Sense Disambiguation", "start_pos": 43, "end_pos": 68, "type": "TASK", "confidence": 0.70428400238355}, {"text": "Machine Translation Evaluation", "start_pos": 73, "end_pos": 103, "type": "TASK", "confidence": 0.8805238405863444}, {"text": "Question Answering", "start_pos": 107, "end_pos": 125, "type": "TASK", "confidence": 0.835753858089447}, {"text": "Lexical Substitution", "start_pos": 133, "end_pos": 153, "type": "TASK", "confidence": 0.8404133021831512}]}, {"text": "Word Similarity task is a computationally efficient method to evaluate the quality of word vectors.", "labels": [], "entities": [{"text": "Word Similarity task", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7288826406002045}]}, {"text": "It relies on finding correlation between human assigned semantic similarity (between words) and corresponding word vectors.", "labels": [], "entities": []}, {"text": "We have used Spearman's Rho for calculating correlation.", "labels": [], "entities": [{"text": "correlation", "start_pos": 44, "end_pos": 55, "type": "METRIC", "confidence": 0.6964423656463623}]}, {"text": "Unfortunately, most of the word similarity tasks have been majorly limited to English language because of availability of well annotated different word similarity test datasets and large corpora for learning good word representations, whereas for Indian languages like Marathi, Punjabi, Telugu etc.", "labels": [], "entities": [{"text": "word similarity", "start_pos": 27, "end_pos": 42, "type": "TASK", "confidence": 0.7357334494590759}]}, {"text": "-which even though are widely spoken by significant number of people, are still computationally resource poor languages.", "labels": [], "entities": []}, {"text": "Even if there are models trained for these languages, word similarity datasets to test reliability of corresponding learned word representations do not exist.", "labels": [], "entities": []}, {"text": "Hence, primary motivation for creation of these six word similarity datasets has been to provide necessary evaluation resources for all the current and future work in field of word representations on these six Indian languages -all ranked in top 25 most spoken languages in the world, since no prior word similarity datasets have been publicly made available.", "labels": [], "entities": [{"text": "word representations", "start_pos": 176, "end_pos": 196, "type": "TASK", "confidence": 0.737819254398346}]}, {"text": "The main contribution of this paper is the set of newly created word similarity datasets which would allow for fast and efficient comparison between.", "labels": [], "entities": []}, {"text": "Word similarity is one of the most important evaluation metric for word representations and hence as an evaluation metric, these datasets would promote development of better techniques that employ word representations for these languages.", "labels": [], "entities": []}, {"text": "We also present baseline scores using state-of-the-art techniques which were evaluated using these datasets.", "labels": [], "entities": []}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "We first discuss the corpus and techniques used for training our models in section 2 which are later used for evaluation.", "labels": [], "entities": []}, {"text": "We then talk about relevant related work that has been done with respect to word similarity datasets in section 3.", "labels": [], "entities": []}, {"text": "We then move onto explain how these datasets have been created in section 4 followed by our evaluation criteria and experimental results of various models evaluated on these datasets in section 5.", "labels": [], "entities": []}, {"text": "Finally, we analyze and explain the results in section 6 and finish this paper with how we plan to extend our work in section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "For all the models trained in this paper, we have used the Skip-gram, CBOW (Mikolov et al., 2013a) and FastText () algorithms.", "labels": [], "entities": [{"text": "Skip-gram", "start_pos": 59, "end_pos": 68, "type": "DATASET", "confidence": 0.8555546402931213}, {"text": "CBOW", "start_pos": 70, "end_pos": 74, "type": "METRIC", "confidence": 0.5359963178634644}]}, {"text": "The dimensionality has been fixed at 300 with a minimum count of 5 along with negative sampling.", "labels": [], "entities": []}, {"text": "As Forrest of the paper, we have calculated the Spearman \u03c1 (multiplied by 100) between human assigned similarity and cosine similarity of our word embeddings for the word-pairs.", "labels": [], "entities": [{"text": "Spearman \u03c1", "start_pos": 48, "end_pos": 58, "type": "METRIC", "confidence": 0.9783772826194763}]}, {"text": "For any word which was is not found, we assign it a zero vector.", "labels": [], "entities": []}, {"text": "In order to learn initial representations of the words, we train word embeddings (word2vec) using the parameters described above on the training set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Inter Annotator Agreement (Fleiss  Kappa) scores for word similarity datasets created  for six languages.", "labels": [], "entities": [{"text": "Inter Annotator Agreement (Fleiss  Kappa) scores", "start_pos": 10, "end_pos": 58, "type": "METRIC", "confidence": 0.6466442868113518}]}, {"text": " Table 2: Results for Urdu", "labels": [], "entities": []}, {"text": " Table 3: Results for Marathi", "labels": [], "entities": []}, {"text": " Table 4: Results for Telugu", "labels": [], "entities": []}]}