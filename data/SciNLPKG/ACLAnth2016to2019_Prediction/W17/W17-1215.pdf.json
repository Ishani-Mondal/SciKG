{"title": [{"text": "Discriminating between Similar Languages with Word-level Convolutional Neural Networks", "labels": [], "entities": []}], "abstractContent": [{"text": "Discriminating between Similar Languages (DSL) is a challenging task addressed at the VarDial Workshop series.", "labels": [], "entities": [{"text": "Discriminating between Similar Languages (DSL)", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.8901276843888419}, {"text": "VarDial Workshop series", "start_pos": 86, "end_pos": 109, "type": "DATASET", "confidence": 0.8496063748995463}]}, {"text": "We report on our participation in the DSL shared task with a two-stage system.", "labels": [], "entities": [{"text": "DSL shared task", "start_pos": 38, "end_pos": 53, "type": "TASK", "confidence": 0.5663966337839762}]}, {"text": "In the first stage, character n-grams are used to separate language groups, then specialized classifiers distinguish similar language varieties.", "labels": [], "entities": []}, {"text": "We have conducted experiments with three system configurations and submitted one run for each.", "labels": [], "entities": []}, {"text": "Our main approach is a word-level convolu-tional neural network (CNN) that learns task-specific vectors with minimal text preprocessing.", "labels": [], "entities": []}, {"text": "We also experiment with multi-layer perceptron (MLP) networks and another hybrid configuration.", "labels": [], "entities": []}, {"text": "Our best run achieved an accuracy of 90.76%, ranking 8th among 11 participants and getting very close to the system that ranked first (less than 2 points).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9996447563171387}]}, {"text": "Even though the CNN model could not achieve the best results, it still makes a viable approach to discriminating between similar languages.", "labels": [], "entities": []}], "introductionContent": [{"text": "Language identification is the task of detecting the language of a given text segment.", "labels": [], "entities": [{"text": "Language identification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6978777796030045}]}, {"text": "Although methods that are able to achieve an accuracy of over 99% for clearly distinct languages like English and Spanish do exist, it is still a major problem to distinguish between closely related languages, like Bosnian and Croatian, and language varieties, like Brazilian and European Portuguese ().", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9991669654846191}]}, {"text": "The problem of discriminating between similar languages was addressed in the DSL shared task at, participants were asked to develop systems that could distinguish between 14 language varieties, distributed over 6 language groups.", "labels": [], "entities": [{"text": "DSL shared task", "start_pos": 77, "end_pos": 92, "type": "DATASET", "confidence": 0.830398956934611}]}, {"text": "Two participation tracks were available: closed and open training.", "labels": [], "entities": []}, {"text": "In closed track, systems should be trained exclusively in the DSL Corpus Collection (), provided by the organizers (see Section 3), while in open training the use of external resources was allowed.", "labels": [], "entities": [{"text": "DSL Corpus Collection", "start_pos": 62, "end_pos": 83, "type": "DATASET", "confidence": 0.9845054149627686}]}, {"text": "For a detailed description of the VarDial workshop and of DSL 2017, refer to the shared task report.", "labels": [], "entities": [{"text": "VarDial workshop", "start_pos": 34, "end_pos": 50, "type": "DATASET", "confidence": 0.701411634683609}, {"text": "DSL 2017", "start_pos": 58, "end_pos": 66, "type": "DATASET", "confidence": 0.8827060163021088}]}, {"text": "This paper describes our system and the results of our submissions for closed track at DSL 2017.", "labels": [], "entities": [{"text": "DSL 2017", "start_pos": 87, "end_pos": 95, "type": "DATASET", "confidence": 0.7188025116920471}]}, {"text": "Our goal was to experiment with deep neural networks in language variety distinction, in particular word-level Convolutional Neural Networks (CNN).", "labels": [], "entities": [{"text": "language variety distinction", "start_pos": 56, "end_pos": 84, "type": "TASK", "confidence": 0.6626666486263275}]}, {"text": "This kind of network has been successfully applied to several natural language processing tasks, such as text classification and question answering.", "labels": [], "entities": [{"text": "text classification", "start_pos": 105, "end_pos": 124, "type": "TASK", "confidence": 0.7948739230632782}, {"text": "question answering", "start_pos": 129, "end_pos": 147, "type": "TASK", "confidence": 0.8897283673286438}]}, {"text": "Like other participants did in previous editions of the DSL shared task (, we chose to use two-stage classification.", "labels": [], "entities": []}, {"text": "First, each sentence gets a group label, that guides the selection of a model especially trained for that group.", "labels": [], "entities": []}, {"text": "Then, it goes through a classifier that predicts the final language variety.", "labels": [], "entities": []}, {"text": "We experimented with different machine learning techniques for variety prediction while the language group classifier was kept the same.", "labels": [], "entities": [{"text": "variety prediction", "start_pos": 63, "end_pos": 81, "type": "TASK", "confidence": 0.9103330969810486}]}, {"text": "This allowed us to compare, not only the overall accuracy of each classifier, but also its accuracy within each language group.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9986680746078491}, {"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9988013505935669}]}, {"text": "To distinguish between language groups, the efficiency of character n-grams was leveraged, while three configurations had their performances comparared for language variety prediction.", "labels": [], "entities": [{"text": "language variety prediction", "start_pos": 156, "end_pos": 183, "type": "TASK", "confidence": 0.7189539869626363}]}, {"text": "One run was submitted for each of the following configurations: (a) run1: a word-level CNN that learns word vectors from scratch; (b) run2: a multi-layer perceptron (MLP) fed by tf-idf vectors of word n-grams, and (c) run3: a hybrid configuration composed by word-level MLP models and character-level Naive Bayes models.", "labels": [], "entities": []}, {"text": "Our best run (run3) was positioned 8th among 11 participants, with 90.76% of accuracy in the test set and with a difference of 1.98 percentage points from the first system in the rank.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9995502829551697}]}, {"text": "Although our word-level CNN did not outperform the other two configurations, it scored very close to our best run.", "labels": [], "entities": []}, {"text": "We also found that combinations of unigrams and bigrams produce higher scores than unigrams alone.", "labels": [], "entities": []}, {"text": "This was observed in both convolutional networks and multi-layer perceptron networks.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Performance of run1 (CNN) in each lan- guage variety.", "labels": [], "entities": [{"text": "run1 (CNN)", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.7286102026700974}]}, {"text": " Table 4: Confusion matrix for the DSL task, run1 (CNN). The horizontal axis indicates predicted labels,  while true labels are on the vertical axis.", "labels": [], "entities": [{"text": "DSL task", "start_pos": 35, "end_pos": 43, "type": "TASK", "confidence": 0.7049447298049927}]}, {"text": " Table 5: Results for the DSL task. Last column shows results computed on the development set.", "labels": [], "entities": [{"text": "DSL task", "start_pos": 26, "end_pos": 34, "type": "TASK", "confidence": 0.8730350136756897}]}]}