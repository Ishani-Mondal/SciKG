{"title": [{"text": "Sentiment Analysis and Lexical Cohesion for the Story Cloze Task", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.964357852935791}]}], "abstractContent": [{"text": "We present two NLP components for the Story Cloze Task-dictionary-based sentiment analysis and lexical cohesion.", "labels": [], "entities": [{"text": "Story Cloze Task-dictionary-based sentiment analysis", "start_pos": 38, "end_pos": 90, "type": "TASK", "confidence": 0.6457052409648896}]}, {"text": "While previous research found no contribution from sentiment analysis to the accuracy on this task, we demonstrate that sentiment is an important aspect.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.9066188037395477}, {"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.999321460723877}]}, {"text": "We describe anew approach, using a rule that estimates sentiment congruence in a story.", "labels": [], "entities": []}, {"text": "Our sentiment-based system achieves strong results on this task.", "labels": [], "entities": []}, {"text": "Our lexical cohesion system achieves accuracy comparable to previously published baseline results.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9994499087333679}]}, {"text": "A combination of the two systems achieves better accuracy than published baselines.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9990397095680237}]}, {"text": "We argue that sentiment analysis should be considered an integral part of narrative comprehension.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 14, "end_pos": 32, "type": "TASK", "confidence": 0.9675462543964386}]}], "introductionContent": [{"text": "The Story Cloze Task (SCT) is a novel challenge task in which an automated NLP system has to choose a correct ending fora short story, from two predefined alternatives.", "labels": [], "entities": [{"text": "Story Cloze Task (SCT)", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.541015605131785}]}, {"text": "This new challenge stems from along line of research on the types of knowledge that are required for narrative comprehension.", "labels": [], "entities": []}, {"text": "Specifically, it is related to a previous type of challenge, the Narrative Cloze Task (NCT).", "labels": [], "entities": []}, {"text": "The SCT departs from the narrow focus of the NCT.", "labels": [], "entities": [{"text": "SCT", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.8907934427261353}, {"text": "NCT", "start_pos": 45, "end_pos": 48, "type": "DATASET", "confidence": 0.9423044323921204}]}, {"text": "It is informed by the interest in the temporal and causal relations that form the intricate fabric of narrative stories.", "labels": [], "entities": []}, {"text": "Some previous research on analyzing and learning commonsense information have focused on blogs (, which are challenging and difficult texts.", "labels": [], "entities": []}, {"text": "Other studies have focused on analysis of short fables (.", "labels": [], "entities": [{"text": "analysis of short fables", "start_pos": 30, "end_pos": 54, "type": "TASK", "confidence": 0.7893720418214798}]}, {"text": "produced a large curated corpus of simple commonsense stories, generated via crowdsourcing.", "labels": [], "entities": []}, {"text": "Each story consists of exactly five short sentences, with a clear beginning, middle and ending, without embellishments, lengthy introductions and digressions.", "labels": [], "entities": []}, {"text": "For the Story Cloze Task, human authors used four-sentence core stories form the corpus, and provided two different ending sentences -a 'right' one and a 'wrong' one.", "labels": [], "entities": []}, {"text": "Some of the 'wrong' endings include logical contradictions, some include events that are impossible or highly unlikely given our standard world knowledge.", "labels": [], "entities": []}, {"text": "Yesterday Stacey was driving to work.", "labels": [], "entities": []}, {"text": "2. Unfortunately a large SUV slammed into her.", "labels": [], "entities": []}, {"text": "3. Luckily she was alright.", "labels": [], "entities": []}, {"text": "4. However her car was destroyed.", "labels": [], "entities": []}, {"text": "Stacey got back in her car and drove to work.", "labels": [], "entities": []}, {"text": "Stacey told the police what happened.", "labels": [], "entities": []}, {"text": "The current SCT has a validation set and a test set, with 1871 stories per set.", "labels": [], "entities": []}, {"text": "Each story consists of four sentences, and two competing sentences as story endings.", "labels": [], "entities": []}, {"text": "An NLP system is tasked to choose the correct ending from the two alternatives.", "labels": [], "entities": []}, {"text": "Systems are evaluated on a simple accuracy measure (number of correct choices divided by number of stories).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9984269142150879}]}, {"text": "In this setting, if ending-choices are made randomly, the baseline success rate would be 50%.", "labels": [], "entities": []}, {"text": "In this paper we present our system for the SCT challenge.", "labels": [], "entities": [{"text": "SCT challenge", "start_pos": 44, "end_pos": 57, "type": "TASK", "confidence": 0.9501591324806213}]}, {"text": "Section 2 outlines the approach, section 3 describes the algorithms and the results.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Sytem accuracy on stories where senti- ment is detected (in paretheses: number of stories  with sentiment).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9791233539581299}]}]}