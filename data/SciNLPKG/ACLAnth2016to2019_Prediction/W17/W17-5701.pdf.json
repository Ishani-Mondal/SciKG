{"title": [{"text": "Overview of the 4th Workshop on Asian Translation", "labels": [], "entities": [{"text": "Asian Translation", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.68047134578228}]}], "abstractContent": [{"text": "This paper presents the results of the shared tasks from the 4th workshop on Asian translation (WAT2017) including J\u2194E, J\u2194C scientific paper translation subtasks, C\u2194J, K\u2194J, E\u2194J patent translation subtasks, H\u2194E mixed domain subtasks, J\u2194E newswire subtasks and J\u2194E recipe subtasks.", "labels": [], "entities": [{"text": "Asian translation (WAT2017)", "start_pos": 77, "end_pos": 104, "type": "TASK", "confidence": 0.683307695388794}, {"text": "scientific paper translation subtasks", "start_pos": 124, "end_pos": 161, "type": "TASK", "confidence": 0.7521485388278961}]}, {"text": "For the WAT2017, 12 institutions participated in the shared tasks.", "labels": [], "entities": [{"text": "WAT2017", "start_pos": 8, "end_pos": 15, "type": "TASK", "confidence": 0.5254530310630798}]}, {"text": "About 300 translation results have been submitted to the automatic evaluation server, and selected submissions were manually evaluated.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Workshop on Asian Translation (WAT) is anew open evaluation campaign focusing on Asian languages.", "labels": [], "entities": [{"text": "Asian Translation (WAT)", "start_pos": 16, "end_pos": 39, "type": "TASK", "confidence": 0.8391997456550598}]}, {"text": "Following the success of the previous workshops WAT2014 (), WAT2015 () and WAT2016 (), WAT2017 brings together machine translation researchers and users to try, evaluate, share and discuss brand-new ideas of machine translation.", "labels": [], "entities": [{"text": "WAT2014", "start_pos": 48, "end_pos": 55, "type": "DATASET", "confidence": 0.8779381513595581}, {"text": "WAT2015", "start_pos": 60, "end_pos": 67, "type": "DATASET", "confidence": 0.8159865140914917}, {"text": "machine translation", "start_pos": 111, "end_pos": 130, "type": "TASK", "confidence": 0.7554836869239807}, {"text": "machine translation", "start_pos": 208, "end_pos": 227, "type": "TASK", "confidence": 0.739441305398941}]}, {"text": "We have been working toward practical use of machine translation among all Asian countries.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.7823962569236755}]}, {"text": "For the 4th WAT, we adopted new translation subtasks with English-Japanese news corpus and English-Japanese recipe corpus in addition to the subtasks at WAT2016 1 . Fur-thermore, we invited research papers on topics related to machine translation, especially for Asian languages.", "labels": [], "entities": [{"text": "WAT", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.40619340538978577}, {"text": "WAT2016", "start_pos": 153, "end_pos": 160, "type": "DATASET", "confidence": 0.7525256872177124}, {"text": "machine translation", "start_pos": 227, "end_pos": 246, "type": "TASK", "confidence": 0.7956280708312988}]}, {"text": "The submitted research papers were peer reviewed by three program committee members and the committee accepted 4 papers, which focus on on neural machine translation, and construction and evaluation of language resources.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 139, "end_pos": 165, "type": "TASK", "confidence": 0.6616444885730743}]}, {"text": "We also launched the small NMT task, which aims to build a small NMT system that keeps a reasonable translation quality.", "labels": [], "entities": []}, {"text": "There are, however, no submissions to the task this year.", "labels": [], "entities": []}, {"text": "WAT is the uniq workshop on Asian language transration with the following characteristics: \u2022 Open innovation platform Due to the fixed and open test data, we can repeatedly evaluate translation systems on the same dataset over years.", "labels": [], "entities": [{"text": "WAT", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8129501938819885}, {"text": "Asian language transration", "start_pos": 28, "end_pos": 54, "type": "TASK", "confidence": 0.6403948068618774}]}, {"text": "There is no deadline of translation result submission with respect to automatic evaluation of translation quality and WAT receives submissions at anytime.", "labels": [], "entities": [{"text": "translation result submission", "start_pos": 24, "end_pos": 53, "type": "TASK", "confidence": 0.874415934085846}, {"text": "WAT", "start_pos": 118, "end_pos": 121, "type": "TASK", "confidence": 0.8902900218963623}]}, {"text": "\u2022 Domain and language pairs WAT is the world's first workshop that targets scientific paper domain, and Chinese\u2194Japanese and Korean\u2194Japanese language pairs.", "labels": [], "entities": [{"text": "WAT", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.6931057572364807}]}, {"text": "In the future, we will add more Asian languages such as Vietnamese, Thai, Burmese and soon.", "labels": [], "entities": []}, {"text": "\u2022 and Recipe Corpus 6 as the dataset.", "labels": [], "entities": [{"text": "Recipe Corpus 6", "start_pos": 6, "end_pos": 21, "type": "DATASET", "confidence": 0.7928836743036906}]}], "datasetContent": [{"text": "We evaluated translation results by three metrics: BLEU (), RIBES () and AMFM (.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.9985865354537964}, {"text": "RIBES", "start_pos": 60, "end_pos": 65, "type": "METRIC", "confidence": 0.9842601418495178}, {"text": "AMFM", "start_pos": 73, "end_pos": 77, "type": "METRIC", "confidence": 0.8905372619628906}]}, {"text": "BLEU scores were calculated using multi-bleu.perl which was distributed with the Moses toolkit (.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9755520224571228}]}, {"text": "RIBES scores were calculated using RIBES.py version 1.02.4 . AMFM scores were calculated using scripts created by the technical collaborators of WAT2017.", "labels": [], "entities": [{"text": "RIBES.py version 1.02.4", "start_pos": 35, "end_pos": 58, "type": "DATASET", "confidence": 0.87171604235967}, {"text": "WAT2017", "start_pos": 145, "end_pos": 152, "type": "DATASET", "confidence": 0.9248098731040955}]}, {"text": "All scores for each task were calculated using the corresponding reference.", "labels": [], "entities": []}, {"text": "Before the calculation of the automatic evaluation scores, the translation results were tokenized with word segmentation tools for each language.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 103, "end_pos": 120, "type": "TASK", "confidence": 0.7038722932338715}]}, {"text": "For Japanese segmentation, we used three different tools: Juman version 7.0 (  The participants submit translation results via an automatic evaluation system deployed on the WAT2017 web page, which automatically gives evaluation scores for the uploaded results.", "labels": [], "entities": [{"text": "Japanese segmentation", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.7365477979183197}, {"text": "Juman version 7.0", "start_pos": 58, "end_pos": 75, "type": "DATASET", "confidence": 0.8155978719393412}, {"text": "WAT2017 web page", "start_pos": 174, "end_pos": 190, "type": "DATASET", "confidence": 0.9606321851412455}]}, {"text": "shows the submission interface for participants.", "labels": [], "entities": []}, {"text": "The system requires participants to provide the following information when they upload translation results: Newswire subtask (J\u2194E), Mixed domain subtask (H\u2194E, H\u2194J) or Recipe subtask (J\u2194E); \u2022 Method: SMT, RBMT, SMT and RBMT, EBMT, NMT or Other; \u2022 Use of other resources in addition to the provided data ASPEC / JPC / IITB Corpus / JIJI Corpus / Recipe Corpus; \u2022 Permission to publish automatic evaluation scores on the WAT2017 web page.", "labels": [], "entities": [{"text": "ASPEC / JPC / IITB Corpus / JIJI Corpus / Recipe Corpus", "start_pos": 302, "end_pos": 357, "type": "DATASET", "confidence": 0.8307305077711741}, {"text": "WAT2017 web page", "start_pos": 418, "end_pos": 434, "type": "DATASET", "confidence": 0.9528453151384989}]}, {"text": "Although participants can confirm only the information that they filled or uploaded, the server for the system stores all submitted information including translation results and scores.", "labels": [], "entities": []}, {"text": "Information about translation results that participants permit to be published is disclosed via the WAT2017 evaluation web page.", "labels": [], "entities": [{"text": "WAT2017 evaluation web page", "start_pos": 100, "end_pos": 127, "type": "DATASET", "confidence": 0.8169311881065369}]}, {"text": "Participants can also submit the results for human evaluation using the same web interface.", "labels": [], "entities": []}, {"text": "This automatic evaluation system will remain available even after WAT2017.", "labels": [], "entities": [{"text": "WAT2017", "start_pos": 66, "end_pos": 73, "type": "DATASET", "confidence": 0.5516013503074646}]}, {"text": "Anybody can register an account for the system by following the procesures in the registration web page 21 .  In WAT2017, we conducted 2 kinds of human evaluations: pairwise evaluation and JPO adequacy evaluation.", "labels": [], "entities": [{"text": "WAT2017", "start_pos": 113, "end_pos": 120, "type": "DATASET", "confidence": 0.7689526081085205}, {"text": "JPO adequacy evaluation", "start_pos": 189, "end_pos": 212, "type": "TASK", "confidence": 0.5891802310943604}]}, {"text": "The pairwise evaluation is the same as the last year, but not using the crowdsourcing this year.", "labels": [], "entities": []}, {"text": "We asked professional translation company to do pairwise evaluation.", "labels": [], "entities": []}, {"text": "The cost of pairwise evaluation per sentence is almost the same to that of last year.", "labels": [], "entities": []}, {"text": "We randomly chose 400 sentences from the Test set for the pairwise evaluation.", "labels": [], "entities": []}, {"text": "We used the same sentences as the last year for the continuous subtasks.", "labels": [], "entities": []}, {"text": "Each submission is compared with the baseline translation (Phrasebased SMT, described in Section 3) and given a Pairwise score.", "labels": [], "entities": [{"text": "Phrasebased SMT", "start_pos": 59, "end_pos": 74, "type": "TASK", "confidence": 0.526303231716156}]}, {"text": "We conducted pairwise evaluation of each of the 400 test sentences.", "labels": [], "entities": []}, {"text": "The input sentence and two translations (the baseline and a submission) are shown to the annotators, and the annotators are asked to judge which of the translation is better, or if they are of the same quality.", "labels": [], "entities": []}, {"text": "The order of the two translations are at random.", "labels": [], "entities": []}, {"text": "The participants' systems, which achieved the top 3 highest scores among the pairwise evaluation results of each subtask , were also evaluated with the JPO adequacy evaluation.", "labels": [], "entities": [{"text": "JPO", "start_pos": 152, "end_pos": 155, "type": "DATASET", "confidence": 0.6493911147117615}]}, {"text": "The JPO adequacy evaluation was carried out by translation experts with a quality evaluation criterion for translated patent documents which the Japanese Patent Office (JPO) decided.", "labels": [], "entities": [{"text": "Japanese Patent Office (JPO)", "start_pos": 145, "end_pos": 173, "type": "DATASET", "confidence": 0.6486300726731619}]}, {"text": "For each system, two annotators evaluate the test sentences to guarantee the quality.", "labels": [], "entities": []}, {"text": "The number of test sentences for the JPO adequacy evaluation is 200.", "labels": [], "entities": [{"text": "JPO", "start_pos": 37, "end_pos": 40, "type": "DATASET", "confidence": 0.5961923003196716}]}, {"text": "The 200 test sentences were randomly selected from the 400 test sentences of the pairwise evaluation.", "labels": [], "entities": []}, {"text": "The test sentence include the input sentence, the submitted system's translation and the reference translation.", "labels": [], "entities": []}, {"text": "5 All important information is transmitted correctly.", "labels": [], "entities": []}, {"text": "(100%) 4 Almost all important information is transmitted correctly.", "labels": [], "entities": []}, {"text": "(80%-) 3 More than half of important information is transmitted correctly.", "labels": [], "entities": []}, {"text": "(50%-) 2 Some of important information is transmitted correctly.", "labels": [], "entities": []}, {"text": "(20%-) 1 Almost all important information is NOT transmitted correctly.", "labels": [], "entities": [{"text": "NOT transmitted correctly", "start_pos": 45, "end_pos": 70, "type": "TASK", "confidence": 0.7298564712206522}]}, {"text": "(-20%): The JPO adequacy criterion shows the JPO adequacy criterion from 5 to 1.", "labels": [], "entities": []}, {"text": "The evaluation is performed subjectively.", "labels": [], "entities": []}, {"text": "\"Important information\" represents the technical factors and their relationships.", "labels": [], "entities": []}, {"text": "The degree of importance of each element is also considered to evaluate.", "labels": [], "entities": []}, {"text": "The percentages in each grade are rough indications for the transmission degree of the source sentence meanings.", "labels": [], "entities": []}, {"text": "The detailed criterion can be found on the JPO document (in Japanese) 23 . shows the list of participants for WAT2017.", "labels": [], "entities": [{"text": "JPO document", "start_pos": 43, "end_pos": 55, "type": "DATASET", "confidence": 0.965762734413147}, {"text": "WAT2017", "start_pos": 110, "end_pos": 117, "type": "TASK", "confidence": 0.7063372731208801}]}, {"text": "This includes not only Japanese organizations, but also some organizations from outside Japan.", "labels": [], "entities": []}, {"text": "12 teams submitted one or more translation results to the automatic evaluation server or human evaluation.", "labels": [], "entities": []}, {"text": "In this section, the evaluation results for WAT2017 are reported from several perspectives.", "labels": [], "entities": [{"text": "WAT2017", "start_pos": 44, "end_pos": 51, "type": "TASK", "confidence": 0.806253969669342}]}, {"text": "Some of the results for both automatic and human evaluations are also accessible at the WAT2017 website 24 ..", "labels": [], "entities": [{"text": "WAT2017 website", "start_pos": 88, "end_pos": 103, "type": "DATASET", "confidence": 0.8497138917446136}]}, {"text": "The weights for the weighted \u03ba) is defined as |Evaluation1 \u2212 Evaluation2|/4.", "labels": [], "entities": []}, {"text": "From the evaluation results, the following can be observed: \u2022 The translation quality of this year is better than that of last year for all the subtasks.", "labels": [], "entities": [{"text": "translation", "start_pos": 66, "end_pos": 77, "type": "TASK", "confidence": 0.9293253421783447}]}, {"text": "\u2022 There is no big difference between the neural network based translation models according to the JPO adequacy evaluation results for ASPEC subtasks.", "labels": [], "entities": []}, {"text": "show the results of statistical significance testing of ASPEC subtasks, show those of JPC subtasks, shows those of IITBC subtasks, shows those of JIJI subtasks and Tables 18, 19 and 20 show those of RECIPE subtasks.", "labels": [], "entities": [{"text": "IITBC subtasks", "start_pos": 115, "end_pos": 129, "type": "DATASET", "confidence": 0.9509637355804443}, {"text": "JIJI subtasks", "start_pos": 146, "end_pos": 159, "type": "DATASET", "confidence": 0.8835344314575195}]}, {"text": "\u226b, \u226b and > mean that the system in 24 http://lotus.kuee.kyoto-u.ac.jp/WAT/evaluation/ the row is better than the system in the column at a significance level of p < 0.01, 0.05 and 0.1 respectively.", "labels": [], "entities": []}, {"text": "Testing is also done by the bootstrap resampling as follows:  1.", "labels": [], "entities": []}, {"text": "randomly select 300 sentences from the 400 pairwise evaluation sentences, and calculate the Pairwise scores on the selected sentences for both systems 2.", "labels": [], "entities": []}, {"text": "iterate the previous step 1000 times and count the number of wins (W ), losses (L) and ties (T )", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics for ASPEC.", "labels": [], "entities": [{"text": "ASPEC", "start_pos": 25, "end_pos": 30, "type": "TASK", "confidence": 0.7915459871292114}]}, {"text": " Table 2: Statistics for JPC.", "labels": [], "entities": [{"text": "JPC", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.5109584927558899}]}, {"text": " Table 2.  The Sentence pairs in each data were ran- domly extracted from a description part of  comparable patent documents under the con- dition that a similarity score between two sen- tences is greater than or equal to the threshold  value 0.05. The similarity score was calculated  by the method from (", "labels": [], "entities": [{"text": "similarity score", "start_pos": 254, "end_pos": 270, "type": "METRIC", "confidence": 0.9760479629039764}]}, {"text": " Table 3: Statistics for JIJI Corpus.", "labels": [], "entities": [{"text": "JIJI Corpus", "start_pos": 25, "end_pos": 36, "type": "DATASET", "confidence": 0.9347966015338898}]}, {"text": " Table 4: Statistics for IITB Corpus. \"Mono\"  indicates monolingual Hindi corpus.", "labels": [], "entities": [{"text": "IITB Corpus", "start_pos": 25, "end_pos": 36, "type": "DATASET", "confidence": 0.8701671063899994}]}, {"text": " Table 9: JPO adequacy evaluation results in detail.", "labels": [], "entities": [{"text": "JPO adequacy evaluation", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.5312674343585968}]}, {"text": " Table 21: The Fleiss' kappa values for the pairwise evaluation results.", "labels": [], "entities": []}, {"text": " Table 23: ASPEC-EJ submissions (Organizer)", "labels": [], "entities": [{"text": "ASPEC-EJ submissions", "start_pos": 11, "end_pos": 31, "type": "TASK", "confidence": 0.8293381333351135}]}, {"text": " Table 24: ASPEC-EJ submissions (Participants)", "labels": [], "entities": [{"text": "ASPEC-EJ submissions", "start_pos": 11, "end_pos": 31, "type": "TASK", "confidence": 0.8580774366855621}]}]}