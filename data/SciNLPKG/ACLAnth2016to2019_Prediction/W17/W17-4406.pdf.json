{"title": [{"text": "Incorporating Metadata into Content-Based User Embeddings", "labels": [], "entities": []}], "abstractContent": [{"text": "Low-dimensional vector representations of social media users can benefit applications like recommendation systems and user attribute inference.", "labels": [], "entities": [{"text": "user attribute inference", "start_pos": 118, "end_pos": 142, "type": "TASK", "confidence": 0.6906708478927612}]}, {"text": "Recent work has shown that user embeddings can be improved by combining different types of information , such as text and network data.", "labels": [], "entities": []}, {"text": "We propose a data augmentation method that allows novel feature types to be used within off-the-shelf embedding models.", "labels": [], "entities": []}, {"text": "Experimenting with the task of friend recommendation on a dataset of 5,019 Twitter users, we show that our approach can lead to substantial performance gains with the simple addition of network and geographic features.", "labels": [], "entities": [{"text": "friend recommendation", "start_pos": 31, "end_pos": 52, "type": "TASK", "confidence": 0.6713451445102692}]}], "introductionContent": [{"text": "A variety of social media tasks benefit from having dense vector representations of users.", "labels": [], "entities": []}, {"text": "For example, \"who to follow\" recommendations can be done by calculating cosine similarity between user vectors.", "labels": [], "entities": []}, {"text": "Recent work has experimented with neural embeddings of social media users, most commonly based on text content (, with some work combining input features from other metadata, including social network information (.", "labels": [], "entities": []}, {"text": "Since social media like Twitter provide different types of data (e.g., text, network, location), constructing user embeddings with appropriate features can improve the performance based on the target task's requirements.", "labels": [], "entities": []}, {"text": "For instance, for recommending tweets a user maybe interested in, the user's text content will be a crucial feature.", "labels": [], "entities": []}, {"text": "For recommending users to follow, information about the user's current follow graph is likely to be important.", "labels": [], "entities": []}, {"text": "How to efficiently integrate diverse types of features into user representations is a challenge we address in this work.", "labels": [], "entities": []}, {"text": "While \"multiview\" models that combine different feature types have been proposed for user embeddings, there is cost in adapting any particular model to a multiview setting.", "labels": [], "entities": []}, {"text": "As an alternative, we propose a simple solution that treats all discrete features as \"words,\" but preprocesses the data in away that removes word order effects from non-textual features.", "labels": [], "entities": []}, {"text": "This approach can be applied to most models of text content, such as the popular paragraph2vec model (, allowing diverse features without constructing specialized models.", "labels": [], "entities": []}, {"text": "Our primary contributions are as follows: \u2022 We describe a preprocessing step that allows the inclusion of non-textual discrete features (e.g., followers, locations) into off-the-shelf text embedding methods.", "labels": [], "entities": []}, {"text": "Our method is easy to use, requiring no special implementation.", "labels": [], "entities": []}, {"text": "\u2022 We introduce a novel type of feature for user embeddings-the geographic locations of users' friends-and show that this improves performance over standard text and network features on anew Twitter dataset.", "labels": [], "entities": []}, {"text": "\u2022 We find that jointly modeling all types of features improves performance over combining independent models of different feature sets, offering evidence that there are informative interactions between text content and metadata, and demonstrating that simply combining independent models is insufficient.", "labels": [], "entities": []}], "datasetContent": [{"text": "To motivate our methods, we will first describe our dataset of over 5,000 Twitter users.", "labels": [], "entities": []}, {"text": "We randomly sampled users who follow American universities.", "labels": [], "entities": []}, {"text": "Specifically, we collected the usernames of up to 5,000 followers of 25 universities (the top 25 undergraduate programs ranked by US News).", "labels": [], "entities": [{"text": "US News", "start_pos": 130, "end_pos": 137, "type": "DATASET", "confidence": 0.9731999933719635}]}, {"text": "Among the 5,000 followers of each university, we randomly sampled 400 users, fora total of 10,000 users.", "labels": [], "entities": []}, {"text": "After removing accounts that were private or non-English (according to the tweet lang attribute), we were left with 5,019 users.", "labels": [], "entities": []}, {"text": "From each user, we collected their 200 most recent tweets (collected January 2017), as well as the usernames and locations of up to 100 followees by collecting the profiles of 100 randomly sampled accounts that are followed by the user.", "labels": [], "entities": []}, {"text": "Our dataset contained an average of 155.4 tweets per user (with an average of 6.7 tokens per tweet, after pre-processing), and an average of 91.9 followees per user (with an average of 32.0 followees for whom we resolved a location).", "labels": [], "entities": []}, {"text": "To evaluate our proposed approach, we experiment with different vector representations of our dataset for the task of friend recommendation).", "labels": [], "entities": [{"text": "friend recommendation", "start_pos": 118, "end_pos": 139, "type": "TASK", "confidence": 0.6669012606143951}]}, {"text": "For friend recommendation, we calculate the cosine similarity between all pairs of users based on their vector representation.", "labels": [], "entities": [{"text": "friend recommendation", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.7157235145568848}]}, {"text": "For each user, we select the top k users with the highest similarity.", "labels": [], "entities": [{"text": "similarity", "start_pos": 58, "end_pos": 68, "type": "METRIC", "confidence": 0.948329746723175}]}, {"text": "Using the user's followee list as ground truth, we measure the precision, recall, and mean reciprocal rank fork in {10, 20, 30, 40, 50}.", "labels": [], "entities": [{"text": "precision", "start_pos": 63, "end_pos": 72, "type": "METRIC", "confidence": 0.9996373653411865}, {"text": "recall", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.9996911287307739}, {"text": "mean reciprocal rank fork", "start_pos": 86, "end_pos": 111, "type": "METRIC", "confidence": 0.8903808295726776}]}, {"text": "Similar to the design of (, we used the most popular accounts as our test set.", "labels": [], "entities": []}, {"text": "Specifically, we selected 58 users who were followed by more than 50 users in our dataset for evaluation.", "labels": [], "entities": []}, {"text": "These users were excluded when generating the username features described in 3.1.", "labels": [], "entities": []}, {"text": "We experimented with our paragraph2vec-based embedding models with different feature sets.", "labels": [], "entities": []}, {"text": "We consider the model with only text features to be our primary baseline, which we compare against models that add username features as well as both username and location features.", "labels": [], "entities": []}, {"text": "For our full model with all three feature types, we compared three different approaches for combining the features.", "labels": [], "entities": []}, {"text": "In addition to training a single paragraph2vec model on all features jointly, as we: Overview of results with precision (P), recall (R), and mean reciprocal rank (MRR) at k.", "labels": [], "entities": [{"text": "precision (P)", "start_pos": 110, "end_pos": 123, "type": "METRIC", "confidence": 0.9481440037488937}, {"text": "recall (R)", "start_pos": 125, "end_pos": 135, "type": "METRIC", "confidence": 0.9468608200550079}, {"text": "mean reciprocal rank (MRR)", "start_pos": 141, "end_pos": 167, "type": "METRIC", "confidence": 0.929483046134313}]}, {"text": "This compares our non-embedding baselines with our embedding model using various feature sets: text only (T), text and usernames (T+U), and text with usernames and locations (T+U+L), either jointly modeled or independently combined by addition or concatenation.", "labels": [], "entities": []}, {"text": "Markers indicate if the results of our joint T+U+L model are significantly different (p<0.05) from the text only ( \u2020), concatenated T+U+L ( \u2021), or TF-IDF ( * ) models.", "labels": [], "entities": []}, {"text": "proposed in Section 4.1, we also trained three separate paragraph2vec models on the three feature types and then combined them, by adding the vectors in one version and by concatenating the three vectors in another.", "labels": [], "entities": []}, {"text": "Since some prior work trained independent models for different views (Section 2), it is important to understand how joint versus independent training affects performance.", "labels": [], "entities": []}, {"text": "To understand the importance of padding the metadata features with dummy tokens, we also measured the performance of the full joint model without using extra tokens, labeled as \"No padding\" in the table.", "labels": [], "entities": []}, {"text": "Finally, we add two other baselines to put our results in context.", "labels": [], "entities": []}, {"text": "First is a random baseline that randomly chooses k users in the ranking, which gives an approximate lower bound on performance.", "labels": [], "entities": []}, {"text": "Second, we compare to a highdimensional bag-of-words representation of text with TF-IDF weighting.", "labels": [], "entities": []}, {"text": "We measured the statistical significance of the results using a paired t-test to compare our full model to the baselines with close performance.", "labels": [], "entities": []}], "tableCaptions": []}