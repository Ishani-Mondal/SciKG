{"title": [{"text": "Using Convolutional Neural Networks to Classify Hate-Speech", "labels": [], "entities": []}], "abstractContent": [{"text": "The paper introduces a deep learning-based Twitter hate-speech text classification system.", "labels": [], "entities": [{"text": "deep learning-based Twitter hate-speech text classification", "start_pos": 23, "end_pos": 82, "type": "TASK", "confidence": 0.5932897080977758}]}, {"text": "The classifier assigns each tweet to one of four predefined categories: racism, sexism, both (racism and sex-ism) and non-hate-speech.", "labels": [], "entities": []}, {"text": "Four Con-volutional Neural Network models were trained on resp.", "labels": [], "entities": []}, {"text": "character 4-grams, word vectors based on semantic information built using word2vec, randomly generated word vectors, and word vectors combined with character n-grams.", "labels": [], "entities": []}, {"text": "The feature set was down-sized in the networks by max-pooling, and a softmax function used to classify tweets.", "labels": [], "entities": []}, {"text": "Tested by 10-fold cross-validation, the model based on word2vec embeddings performed best, with higher precision than recall, and a 78.3% F-score.", "labels": [], "entities": [{"text": "precision", "start_pos": 103, "end_pos": 112, "type": "METRIC", "confidence": 0.9992334842681885}, {"text": "recall", "start_pos": 118, "end_pos": 124, "type": "METRIC", "confidence": 0.9987576007843018}, {"text": "F-score", "start_pos": 138, "end_pos": 145, "type": "METRIC", "confidence": 0.9959047436714172}]}], "introductionContent": [{"text": "During the Spring of 2017, parliamentary committees in Germany and the UK strongly criticised leading social media sites such as Facebook, Twitter and Youtube (Google) for failing to take sufficient and quick enough action against hate-speech, with the German government threatening to fine the social networks up to 50 million euros per year if they continue to fail to act on hateful postings (and posters) within a week.", "labels": [], "entities": []}, {"text": "When called to witness in front of the UK Home Affairs Committee, all the social media companies refused to reveal both the number of people they employ to battle hate-speech and the amount they spend on this.", "labels": [], "entities": [{"text": "UK Home Affairs Committee", "start_pos": 39, "end_pos": 64, "type": "DATASET", "confidence": 0.9132039844989777}]}, {"text": "However, Google claimed to have invested \"hundreds of millions\" while Facebook stated that they had thousands of people working on the problem.", "labels": [], "entities": []}, {"text": "The German government estimated that the companies combined already spend some 50 million euros per year and that the suggested new German law would increase that amount by 50%.", "labels": [], "entities": []}, {"text": "Regardless of the resources actually devoted by the social media networks, it is clear that their current efforts are not enough: \"we are disappointed at the pace of development of technological solutions\" (Home Affairs Committee, 2017, p.24).", "labels": [], "entities": [{"text": "Home Affairs Committee, 2017", "start_pos": 207, "end_pos": 235, "type": "DATASET", "confidence": 0.619327574968338}]}, {"text": "The UK and German governments also indicate that they are moving in the direction of treating online content providers in analogy with publishers of printed material, with the same obligations to abide to publishing laws.", "labels": [], "entities": []}, {"text": "With legislation in other countries set to follow, properly identifying hate-speech is a pressing issue, not only for the major players, but also for smaller companies, clubs, and organisations that allow for user-generated content on their sites (albeit the current German law proposal makes an exception for sites with less than 2 million users).", "labels": [], "entities": []}, {"text": "Many such sites currently use slow, manual moderation, which mean that abusive posts will be left online for too long without appropriate action being taken or that content will be published with delay (which might be unacceptable to the users, e.g., in online chat rooms).", "labels": [], "entities": []}, {"text": "Following the work by, deep neural networks have been shown to effectively solve several language processing tasks such as part-of-speech tagging, sentiment analysis, and named entity recognition.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 123, "end_pos": 145, "type": "TASK", "confidence": 0.7181520164012909}, {"text": "sentiment analysis", "start_pos": 147, "end_pos": 165, "type": "TASK", "confidence": 0.9513997435569763}, {"text": "named entity recognition", "start_pos": 171, "end_pos": 195, "type": "TASK", "confidence": 0.6878109077612559}]}, {"text": "Here a Convolutional Neural Network (CNN) model with various features is utilised for hate-speech categorisation.", "labels": [], "entities": [{"text": "hate-speech categorisation", "start_pos": 86, "end_pos": 112, "type": "TASK", "confidence": 0.7900058627128601}]}, {"text": "Word vectors based on semantic information are built for all tokens using an unsupervised learning algorithm, word2vec.", "labels": [], "entities": []}, {"text": "The word vectors are merged with a set of extracted features, downsized using max-pooling, and together with character n-grams (4-grams) fed to the neural network model to predict the categories of each tweet.", "labels": [], "entities": []}], "datasetContent": [{"text": "Four approaches to hate-speech classification were tested, based on different feature embeddings.", "labels": [], "entities": [{"text": "hate-speech classification", "start_pos": 19, "end_pos": 45, "type": "TASK", "confidence": 0.8360799849033356}]}, {"text": "All models were applied to the English Twitter hatespeech dataset created by.", "labels": [], "entities": [{"text": "English Twitter hatespeech dataset created", "start_pos": 31, "end_pos": 73, "type": "DATASET", "confidence": 0.9316213011741639}]}, {"text": "Each tweet in the dataset has been annotated by one Expert annotator and three Amateur annotators, with four labels: non-hate-speech (84% of the data), racism, sexism, and both (i.e., racism and sexism).", "labels": [], "entities": []}, {"text": "Waseem (2016) defined the \"Expert\" annotators as those having both a theoretical and applied knowledge of hate speech (those were recruited among feminist and antiracism activists), while the \"Amateur\" annotations were obtained by crowd-sourcing (on the CrowdFlower platform).", "labels": [], "entities": []}, {"text": "We combined the annotated tags for each tweet based on majority voting, where the Expert was given double unit votes and each of the Amateurs was given a single unit vote.", "labels": [], "entities": []}, {"text": "The class distributions of the dataset are shown in.", "labels": [], "entities": []}, {"text": "The total size of the dataset (6,655 tweets) is slightly lower than the original set (Waseem reported it as containing 6,909 tweets), since some of the annotated tweets were unavailable or had been deleted.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. The total size of the dataset (6,655  tweets) is slightly lower than the original set  (Waseem reported it as containing 6,909 tweets),  since some of the annotated tweets were unavail- able or had been deleted.", "labels": [], "entities": []}, {"text": " Table 1: Twitter hate-speech dataset statistics", "labels": [], "entities": [{"text": "Twitter hate-speech dataset", "start_pos": 10, "end_pos": 37, "type": "DATASET", "confidence": 0.8275083104769388}]}, {"text": " Table 2: System performance (10-fold cross-validated)", "labels": [], "entities": []}]}