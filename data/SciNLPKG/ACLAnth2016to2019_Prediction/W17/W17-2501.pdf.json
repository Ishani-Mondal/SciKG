{"title": [{"text": "Users and Data: The Two Neglected Children of Bilingual Natural Language Processing Research", "labels": [], "entities": [{"text": "Bilingual Natural Language Processing Research", "start_pos": 46, "end_pos": 92, "type": "TASK", "confidence": 0.6569431126117706}]}], "abstractContent": [{"text": "Despite numerous studies devoted to mining parallel material from bilingual data, we have yet to seethe resulting technologies wholeheartedly adopted by professional translators and terminologists alike.", "labels": [], "entities": []}, {"text": "I argue that this state of affairs is mainly due to two factors: the emphasis published authors put on models (even though data is as important), and the conspicuous lack of concern for actual end-users.", "labels": [], "entities": []}], "introductionContent": [{"text": "Parallel corpora (documents collections that are translations of one another) are the bread and butter of machine translation (MT).", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 106, "end_pos": 130, "type": "TASK", "confidence": 0.8268030822277069}]}, {"text": "Solutions have been proposed for mining parallel texts found on the Web, and for aligning sentences in parallel documents (, leading to socalled \"bitexts\".", "labels": [], "entities": []}, {"text": "It then becomes possible to align words in parallel sentence pairs, in an unsupervised way.", "labels": [], "entities": []}, {"text": "Because parallel data is relatively rare, researchers have turned to exploiting comparable corpora, e.g. news articles in different languages covering the same event.", "labels": [], "entities": []}, {"text": "It is noteworthy that researchers know quite well how to identify parallel sentences in a comparable corpus (), and can then use \"tried and true\" procedures for extracting bilingual lexicons from such a resource.", "labels": [], "entities": []}, {"text": "Being able to benefit from both parallel and comparable data is quite an accomplishment from a scientific point of view, and progress is still being made on the task.", "labels": [], "entities": []}, {"text": "In contrast, and frustratingly, the technologies that professional translators are adopting continue to rely mainly on sentencebased translation memories.", "labels": [], "entities": []}, {"text": "I do not mean to say that other technologies are not being used.", "labels": [], "entities": []}, {"text": "For instance, translation agencies are increasingly integrating machine translation into their workflow, but this is mostly driven by cost reduction, and not by a genuine interest in MT on the part of translators, who remain unconvinced.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 64, "end_pos": 83, "type": "TASK", "confidence": 0.7599838972091675}, {"text": "MT", "start_pos": 183, "end_pos": 185, "type": "TASK", "confidence": 0.9891616106033325}]}, {"text": "I submit that this limited adoption of new resources and technologies is due to the conjunction of two factors: the overall lack of concern for actual users, and the clear preference of the research community for the study of models at the cost of research on data.", "labels": [], "entities": []}, {"text": "Of course, improvements on models have the potential to impact users.", "labels": [], "entities": []}, {"text": "Notably, recent studies ( confirm that neural MT () significantly reduces errors, therefore requiring less post-editing.", "labels": [], "entities": [{"text": "MT", "start_pos": 46, "end_pos": 48, "type": "TASK", "confidence": 0.8524348139762878}, {"text": "errors", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.9716311693191528}]}, {"text": "However, better ways of efficiently acquiring and organizing data equally matters.", "labels": [], "entities": []}, {"text": "As for end-users, more interest in their day-today concerns should lead to a better adoption of the technologies we develop, which in turn would reveal scientific challenges we had never thought of before.", "labels": [], "entities": []}, {"text": "One example of a project I have been involved in is the (at that time pioneering) effort to develop an interactive translation engine named TransType () in which a translator interacts iteratively with a translation engine in order to produce a translation.", "labels": [], "entities": []}, {"text": "After multiple rounds of development, we had several translators beta-test our prototype (), and we realized that the keystroke saving rate used to measure the improvements brought about by TransType was not correlated with the user's productivity gains.", "labels": [], "entities": [{"text": "keystroke saving rate", "start_pos": 118, "end_pos": 139, "type": "METRIC", "confidence": 0.8307477633158366}]}, {"text": "This led us to devise a user model that we could not have foreseen at the beginning of the project.", "labels": [], "entities": []}, {"text": "See (Gonz\u00e1lez-1) for further developments along these lines.", "labels": [], "entities": [{"text": "Gonz\u00e1lez-1", "start_pos": 5, "end_pos": 15, "type": "DATASET", "confidence": 0.9472403526306152}]}, {"text": "Doing research in a vacuum certainly facilitates progress.", "labels": [], "entities": []}, {"text": "For instance, in recent years we have witnessed a tremendous interest in embedding methods for extracting bilingual lexicons, thanks to the pioneering work of (.", "labels": [], "entities": []}, {"text": "It is nowadays a standard procedure to measure the quality of embedding representations on what is called the bilingual lexicon induction (BIL) task.", "labels": [], "entities": [{"text": "bilingual lexicon induction (BIL) task", "start_pos": 110, "end_pos": 148, "type": "TASK", "confidence": 0.7300871057169778}]}, {"text": "One popular evaluation protocol, initially proposed in ( consists in identifying the translation of the last 1000 words of the 6000 most frequent words in the training material.", "labels": [], "entities": []}, {"text": "However, for many language pairs of interest, existing bilingual lexicons already list the translations of frequent (and less frequent) words.", "labels": [], "entities": []}, {"text": "In fact, in (Jakubina and Langlais, 2017), we show that the accuracy of embedding-based methods when translating rare words -which arguably is a test case of better use to end users -is less than 2% at rank 1.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.997703492641449}, {"text": "translating rare words", "start_pos": 101, "end_pos": 123, "type": "TASK", "confidence": 0.8516481320063273}]}, {"text": "I must make it clear at this point that I am excited by embedding methods and their potential to improve the current state of the art.", "labels": [], "entities": []}, {"text": "I am merely saying that the way we evaluate these methods does not reflect their true usefulness.", "labels": [], "entities": []}, {"text": "The purpose of this presentation is to pinpoint a number of challenges I feel are worth being reinvestigated.", "labels": [], "entities": []}, {"text": "They belong to two categories: understanding better how to acquire and organize (bilingual) data, and better exploiting existing resources, with an emphasis on more representative test cases.", "labels": [], "entities": []}, {"text": "This list is not exhaustive, and emanates from the needs expressed by some of the industry professionals I have been discussing with, and from the opinions I have been forming overtime when reading (exciting) publications in my field.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}