{"title": [{"text": "Debunking Sentiment Lexicons: A Case of Domain-Specific Sentiment Classification for Croatian", "labels": [], "entities": [{"text": "Debunking Sentiment Lexicons", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7876309156417847}, {"text": "Domain-Specific Sentiment Classification", "start_pos": 40, "end_pos": 80, "type": "TASK", "confidence": 0.6287627418835958}]}], "abstractContent": [{"text": "Sentiment lexicons are widely used as an intuitive and inexpensive way of tackling sentiment classification, often within a simple lexicon word-counting approach or as part of a supervised model.", "labels": [], "entities": [{"text": "tackling sentiment classification", "start_pos": 74, "end_pos": 107, "type": "TASK", "confidence": 0.9092414577802023}]}, {"text": "However , it is an open question whether these approaches can compete with supervised models that use only word-representation features.", "labels": [], "entities": []}, {"text": "We address this question in the context of domain-specific sentiment classification for Croatian.", "labels": [], "entities": [{"text": "domain-specific sentiment classification", "start_pos": 43, "end_pos": 83, "type": "TASK", "confidence": 0.7237953742345175}]}, {"text": "We experiment with the graph-based acquisition of sentiment lexicons, analyze their quality, and investigate how effectively they can be used in sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 145, "end_pos": 169, "type": "TASK", "confidence": 0.9208949506282806}]}, {"text": "Our results indicate that, even with as few as 500 labeled instances, a supervised model substantially outperforms a word-counting model.", "labels": [], "entities": []}, {"text": "We also observe that adding lexicon-based features does not significantly improve supervised sentiment classification .", "labels": [], "entities": [{"text": "supervised sentiment classification", "start_pos": 82, "end_pos": 117, "type": "TASK", "confidence": 0.6545462707678477}]}], "introductionContent": [{"text": "Sentiment analysis () aims to recognize both subjectivity and polarity of texts, information that can be beneficial in various applications, including social studies (O', marketing analyses (, and stock price prediction.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9044113457202911}, {"text": "stock price prediction", "start_pos": 197, "end_pos": 219, "type": "TASK", "confidence": 0.6660240292549133}]}, {"text": "In general, however, building a well-performing sentiment analysis model requires a fair amount of sentiment-labeled data, whose collection is often costly and time-consuming.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.9185291528701782}]}, {"text": "A popular annotationlight alternative are sentiment polarity lexicons): lists of positive and negative words that most likely induce the corresponding sentiment.", "labels": [], "entities": []}, {"text": "The key selling points of sentiment lexicons are that they are interpretable and quite easy to be compiled manually.", "labels": [], "entities": [{"text": "sentiment lexicons", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.8685137629508972}]}, {"text": "If there is no sentiment-labeled data available, sentiment lexicons can be used directly for sentiment classification: the text is simply classified as positive if it contains more words from a positive than a negative lexicon, and classified as negative otherwise (we refer to this as lexicon word-counting models).", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 93, "end_pos": 117, "type": "TASK", "confidence": 0.9423879086971283}]}, {"text": "On the other hand, if sentiment-labeled data is available, sentiment lexicons can be used as (additional) features for supervised sentiment classification models.", "labels": [], "entities": [{"text": "supervised sentiment classification", "start_pos": 119, "end_pos": 154, "type": "TASK", "confidence": 0.6424285570780436}]}, {"text": "One challenge of sentiment analysis is that the task is highly domain dependent.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.9729208052158356}]}, {"text": "This means that generic sentiment lexicons will often not be useful fora specific domain.", "labels": [], "entities": [{"text": "generic sentiment lexicons", "start_pos": 16, "end_pos": 42, "type": "TASK", "confidence": 0.7892269492149353}]}, {"text": "A notorious example is the word unpredictable, which is typically positive in the domain of movie and book reviews, but generally negative in other domains.", "labels": [], "entities": []}, {"text": "The aim of this paper is to investigate how sentiment lexicons work for domain-specific sentiment classification for Croatian.", "labels": [], "entities": [{"text": "domain-specific sentiment classification", "start_pos": 72, "end_pos": 112, "type": "TASK", "confidence": 0.7098476688067118}]}, {"text": "Our main goal is to find out whether sentiment lexicons can be of use for sentiment classification, either as apart of a simple word-counting model or as an addition to a supervised model using word-representation features.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 74, "end_pos": 98, "type": "TASK", "confidence": 0.9193020462989807}]}, {"text": "To this end, we use a semi-supervised graph-based method to acquire sentiment lexicons from a corpus.", "labels": [], "entities": []}, {"text": "We experiment with acquisition parameters, considering both generic and domain-specific seed sets and corpora.", "labels": [], "entities": []}, {"text": "We compare all the acquired lexicons with the manually annotated ones.", "labels": [], "entities": []}, {"text": "Moreover, we evaluate the lexicon-based models on the task of domain-specific sentiment classification and compare them against supervised models.", "labels": [], "entities": [{"text": "domain-specific sentiment classification", "start_pos": 62, "end_pos": 102, "type": "TASK", "confidence": 0.6528516709804535}]}, {"text": "Finally, we investigate whether a word-counting model can have an edge over a supervised model when the labeled data is lacking.", "labels": [], "entities": []}, {"text": "54 There has been a lot of research on sentiment lexicon acquisition, covering both corpora-and resource-based approaches across many languages (.", "labels": [], "entities": [{"text": "sentiment lexicon acquisition", "start_pos": 39, "end_pos": 68, "type": "TASK", "confidence": 0.8861991167068481}]}, {"text": "A common approach includes bootstrapping, a method which constructs a sentiment lexicon starting from a small manuallylabeled seed set (.", "labels": [], "entities": []}, {"text": "Moreover, a problem of lexicon domain dependence has also been addressed ().", "labels": [], "entities": [{"text": "lexicon domain dependence", "start_pos": 23, "end_pos": 48, "type": "TASK", "confidence": 0.6145011782646179}]}, {"text": "Even though most research on sentiment lexicon acquisition and lexicon-based sentiment classification deals with English, there has been some work on Slavic languages as well, including Macedonian (), Croatian (), Slovene (, and Serbian).", "labels": [], "entities": [{"text": "sentiment lexicon acquisition", "start_pos": 29, "end_pos": 58, "type": "TASK", "confidence": 0.8863426844278971}, {"text": "lexicon-based sentiment classification", "start_pos": 63, "end_pos": 101, "type": "TASK", "confidence": 0.7127639750639597}]}, {"text": "While we follow the work of, who focused on the task of semi-supervised lexicon acqusition, we turn our attention to evaluating the so-obtained lexicons on the task of sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 168, "end_pos": 192, "type": "TASK", "confidence": 0.8982802927494049}]}], "datasetContent": [{"text": "For our experiments, we used a large sentimentannotated dataset of user posts gathered from the Facebook pages of various Croatian internet and mobile service providers.", "labels": [], "entities": []}, {"text": "The dataset comprises 15,718 user posts categorized into three classes: positive (POS), negative (NEG), and neutral (NEU).", "labels": [], "entities": []}, {"text": "The average post length is around 25 tokens.", "labels": [], "entities": [{"text": "post length", "start_pos": 12, "end_pos": 23, "type": "METRIC", "confidence": 0.699700117111206}]}, {"text": "We randomly sampled 3,052 posts (245 positive, 1,638 negative, and 1,169 neutral), which we used for lexicon acquisition.", "labels": [], "entities": [{"text": "lexicon acquisition", "start_pos": 101, "end_pos": 120, "type": "TASK", "confidence": 0.7133234888315201}]}, {"text": "The rest of the dataset (12,666 posts) was used for training and evaluation of supervised models.", "labels": [], "entities": []}, {"text": "We made use of our sentiment-labeled dataset to extract the most representative subset of n-grams for the annotation.", "labels": [], "entities": []}, {"text": "More precisely, we ranked all the n-grams according to their \u03c7 2 scores, which were calculated based on their co-occurrence with POS, NEU, and NEG user posts in the dataset.", "labels": [], "entities": [{"text": "NEG user posts in the dataset", "start_pos": 143, "end_pos": 172, "type": "DATASET", "confidence": 0.6101415803035101}]}, {"text": "To obtain a final list of n-grams for the annotation, we selected 1,000 ngrams by uniformly sampling all these three lists from the top, making sure to avoid duplicates.", "labels": [], "entities": []}, {"text": "Subsequently, five annotators labeled the dataset, and we obtained the final label as a majority vote (there were no ties).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Parameters used for obtaining the best- performing domain-specific lexicon when evalu- ated against the gold lexicon.", "labels": [], "entities": []}, {"text": " Table 3: F1-scores of acquired lexicons evaluated  against the gold lexicon.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9988403916358948}]}, {"text": " Table 4: Scores of word-counting models.", "labels": [], "entities": []}, {"text": " Table 5: Scores of supervised models with  lexicon-based and word-representation features.", "labels": [], "entities": []}]}