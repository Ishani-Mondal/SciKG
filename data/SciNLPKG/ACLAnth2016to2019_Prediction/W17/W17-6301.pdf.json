{"title": [{"text": "Automatically Acquired Lexical Knowledge Improves Japanese Joint Morphological and Dependency Analysis", "labels": [], "entities": [{"text": "Automatically Acquired Lexical Knowledge Improves Japanese Joint Morphological and Dependency Analysis", "start_pos": 0, "end_pos": 102, "type": "TASK", "confidence": 0.6620369553565979}]}], "abstractContent": [{"text": "This paper presents a joint model for morphological and dependency analysis based on automatically acquired lexical knowledge.", "labels": [], "entities": [{"text": "morphological and dependency analysis", "start_pos": 38, "end_pos": 75, "type": "TASK", "confidence": 0.6479950174689293}]}, {"text": "This model takes advantage of rich lexical knowledge to simultaneously resolve word segmentation, POS, and dependency ambiguities.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 79, "end_pos": 96, "type": "TASK", "confidence": 0.7086473107337952}]}, {"text": "In our experiments on Japanese, we show the effectiveness of our joint model over conventional pipeline models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Morphological analysis, i.e., word segmentation, POS tagging and lemmatization, is the first step for processing unsegmented languages such as Chinese and Japanese.", "labels": [], "entities": [{"text": "Morphological analysis", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.849138081073761}, {"text": "word segmentation", "start_pos": 30, "end_pos": 47, "type": "TASK", "confidence": 0.7726387679576874}, {"text": "POS tagging", "start_pos": 49, "end_pos": 60, "type": "TASK", "confidence": 0.8598766624927521}]}, {"text": "Words segmented by a morphological analyzer are usually fed into subsequent analyzers, such as dependency parsers and predicate-argument structure (PAS) analyzers, in a pipeline manner.", "labels": [], "entities": [{"text": "dependency parsers and predicate-argument structure (PAS) analyzers", "start_pos": 95, "end_pos": 162, "type": "TASK", "confidence": 0.6420132087336646}]}, {"text": "One problem with this pipeline process is that errors in morphological analysis are propagated to the subsequent steps.", "labels": [], "entities": []}, {"text": "In morphological analysis, it is also difficult in some cases to determine word segmentations without syntactic and structural knowledge, which could be available at the step of dependency or PAS analysis.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 3, "end_pos": 25, "type": "TASK", "confidence": 0.7133133858442307}, {"text": "determine word segmentations", "start_pos": 65, "end_pos": 93, "type": "TASK", "confidence": 0.6085780958334605}, {"text": "PAS analysis", "start_pos": 192, "end_pos": 204, "type": "TASK", "confidence": 0.7600245773792267}]}, {"text": "For instance, the Japanese phrase \"\" in Sentence (1) can be segmented into (2a) or (2b).", "labels": [], "entities": []}, {"text": "(1) possibility NOM or know not The second author is now affiliated with Fairy Devices Inc.", "labels": [], "entities": [{"text": "possibility", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9843195080757141}, {"text": "NOM", "start_pos": 16, "end_pos": 19, "type": "METRIC", "confidence": 0.5983178019523621}, {"text": "Fairy Devices Inc", "start_pos": 73, "end_pos": 90, "type": "DATASET", "confidence": 0.9148647586504618}]}, {"text": "The third author is now affiliated with Fujitsu Laboratories Ltd.", "labels": [], "entities": [{"text": "Fujitsu Laboratories Ltd", "start_pos": 40, "end_pos": 64, "type": "DATASET", "confidence": 0.9460059205691019}]}, {"text": "In this paper, we use the following abbreviations: NOM (nominative), ACC (accusative), DAT (dative), LOC (locative), ABL (ablative), and TOP (topic marker).", "labels": [], "entities": [{"text": "NOM", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.8876977562904358}, {"text": "ACC", "start_pos": 69, "end_pos": 72, "type": "METRIC", "confidence": 0.9708591103553772}, {"text": "LOC", "start_pos": 101, "end_pos": 104, "type": "METRIC", "confidence": 0.9390739798545837}, {"text": "ABL", "start_pos": 117, "end_pos": 120, "type": "METRIC", "confidence": 0.9878795742988586}, {"text": "TOP", "start_pos": 137, "end_pos": 140, "type": "METRIC", "confidence": 0.9924253225326538}]}, {"text": "In this case, (2a) is the correct segmentation, which means \"whether a possibility exists,\" while the incorrect segmentation (2b) is meaningless: \"a possibility does not walk.\"", "labels": [], "entities": []}, {"text": "It might be possible to select the correct segmentation if a morphological analyzer could lookup selectional preference knowledge of the predicates \"exist\" and \"walk.\"", "labels": [], "entities": []}, {"text": "Thus far, several models have been proposed for joint morphological and dependency analysis, but the performance improvement is not stable among target languages.", "labels": [], "entities": [{"text": "dependency analysis", "start_pos": 72, "end_pos": 91, "type": "TASK", "confidence": 0.6475220173597336}]}, {"text": "For Chinese joint analysis, where the parsing accuracy of a baseline pipeline model is around 80%, an F1 improvement of around 2% was reported ().", "labels": [], "entities": [{"text": "parsing", "start_pos": 38, "end_pos": 45, "type": "TASK", "confidence": 0.9388633370399475}, {"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9387434720993042}, {"text": "F1", "start_pos": 102, "end_pos": 104, "type": "METRIC", "confidence": 0.9996635913848877}]}, {"text": "For Japanese joint analysis, where the parsing accuracy of a pipeline model is around 90%, there have been no studies that report a significant improvement (.", "labels": [], "entities": [{"text": "parsing", "start_pos": 39, "end_pos": 46, "type": "TASK", "confidence": 0.9590919017791748}, {"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9339101314544678}]}, {"text": "One of the reasons for such instability is that most of these joint models are trained only on a small-scale treebank, which consists of several tens of thousands of sentences.", "labels": [], "entities": []}, {"text": "These models do not make use of large-scale external lexical knowledge.", "labels": [], "entities": []}, {"text": "Since it is necessary to use lexical knowledge of selectional preferences to address the abovementioned ambiguities, these joint models cannot solve such ambiguities in many cases.", "labels": [], "entities": []}, {"text": "This paper proposes a joint model for morphological and dependency analysis based on automatically acquired lexical knowledge.", "labels": [], "entities": [{"text": "morphological and dependency analysis", "start_pos": 38, "end_pos": 75, "type": "TASK", "confidence": 0.6192494928836823}]}, {"text": "The lexical knowledge includes case frames acquired from a large-scale raw corpus, which provide useful clues to resolve morphological and syntactic ambiguities.", "labels": [], "entities": []}, {"text": "In our experiments on Japanese corpora, we show a significant improvement over conventional 1 pipeline models.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 summarizes previous joint models for morphological and dependency analysis.", "labels": [], "entities": [{"text": "dependency analysis", "start_pos": 65, "end_pos": 84, "type": "TASK", "confidence": 0.7279496192932129}]}, {"text": "Section 3 describes our method for constructing lexical knowledge.", "labels": [], "entities": []}, {"text": "Section 4 illustrates our idea and describes our joint analysis model in detail.", "labels": [], "entities": []}, {"text": "Section 5 is devoted to our experiments.", "labels": [], "entities": []}, {"text": "Finally, section 6 gives the conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our experiments, we used the Kyoto University Text Corpus 11 () (NEWS) and the Kyoto University Web Document Leads Corpus 12 () (WEB) as Japanese treebanks.", "labels": [], "entities": [{"text": "Kyoto University Text Corpus 11 () (NEWS)", "start_pos": 32, "end_pos": 73, "type": "DATASET", "confidence": 0.8923028310139974}, {"text": "Kyoto University Web Document Leads Corpus 12 () (WEB)", "start_pos": 82, "end_pos": 136, "type": "DATASET", "confidence": 0.8678457953713157}]}, {"text": "NEWS consists of news articles and WEB consists of web pages in various domains.", "labels": [], "entities": [{"text": "NEWS", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9691739678382874}, {"text": "WEB", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.43119534850120544}]}, {"text": "We split these into training and test sets as shown in.", "labels": [], "entities": []}, {"text": "We merged the training sets of NEWS and WEB to generate a training set in our experiment and conducted evaluations on each test set of NEWS and WEB.", "labels": [], "entities": [{"text": "NEWS", "start_pos": 31, "end_pos": 35, "type": "DATASET", "confidence": 0.9211705923080444}, {"text": "WEB", "start_pos": 40, "end_pos": 43, "type": "DATASET", "confidence": 0.7164229154586792}, {"text": "NEWS", "start_pos": 135, "end_pos": 139, "type": "DATASET", "confidence": 0.8813320994377136}, {"text": "WEB", "start_pos": 144, "end_pos": 147, "type": "DATASET", "confidence": 0.8290045261383057}]}, {"text": "For the parser input, we used the Japanese morphological analyzer JUMAN++ ( to generate a word lattice.", "labels": [], "entities": []}, {"text": "We did not use all possible words in the lexicon of JUMAN++, but converted the N-best output of JUMAN++ to a word lattice to speedup parsing.", "labels": [], "entities": []}, {"text": "This is reasonable because the segmentation accuracy of JU-MAN++ is between 98%-99% and its N-best output contains only plausible words.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 31, "end_pos": 43, "type": "TASK", "confidence": 0.9608862400054932}, {"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.8924729824066162}]}, {"text": "N-best outputs were obtained using the option -autoN of JU-: Evaluation results.", "labels": [], "entities": []}, {"text": "\"wo/LK\" means \"without lexical knowledge.\"", "labels": [], "entities": []}, {"text": "MAN++, which increases N proportionally to the length of the input sentence.", "labels": [], "entities": [{"text": "MAN", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.7345489263534546}]}, {"text": "We applied 10-way jackknifing to the training set and analyzed the test set using a model trained on the whole training set.", "labels": [], "entities": []}, {"text": "To train our joint model, we used Classias 13 with L1 regularization.", "labels": [], "entities": []}, {"text": "We set the beam width b of our model to 10 for both training and testing.", "labels": [], "entities": [{"text": "beam width b", "start_pos": 11, "end_pos": 23, "type": "METRIC", "confidence": 0.6687943339347839}]}, {"text": "For comparison, we adopted the latest versions of KNP and CaboCha, both of which are widely used Japanese dependency parsers.", "labels": [], "entities": []}, {"text": "KNP is an implementation of, which accepts the 1-best output of morphological analysis, applies rule-based phrase chunking and performs probabilistic labeled dependency parsing based on case frames.", "labels": [], "entities": [{"text": "KNP", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8002837896347046}, {"text": "morphological analysis", "start_pos": 64, "end_pos": 86, "type": "TASK", "confidence": 0.7176894843578339}, {"text": "phrase chunking", "start_pos": 107, "end_pos": 122, "type": "TASK", "confidence": 0.7014444917440414}, {"text": "labeled dependency parsing", "start_pos": 150, "end_pos": 176, "type": "TASK", "confidence": 0.7181962927182516}]}, {"text": "In KNP, we used the same case frames compiled in this paper.", "labels": [], "entities": [{"text": "KNP", "start_pos": 3, "end_pos": 6, "type": "DATASET", "confidence": 0.6410921216011047}]}, {"text": "CaboCha is an implementation of Sassano, which accepts the 1-best output of morphological analysis, applies CRF-based phrase chunking and performs transition-based unlabeled dependency parsing using SVM.", "labels": [], "entities": [{"text": "phrase chunking", "start_pos": 118, "end_pos": 133, "type": "TASK", "confidence": 0.6459389925003052}, {"text": "transition-based unlabeled dependency parsing", "start_pos": 147, "end_pos": 192, "type": "TASK", "confidence": 0.6622272282838821}]}, {"text": "The training of CRF and SVM was conducted using the training data in this paper.", "labels": [], "entities": [{"text": "CRF", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.7490578293800354}, {"text": "SVM", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.8294017910957336}]}, {"text": "Because phrase chunking in CaboCha was designed to identify bunsetsu, we also tested KNP+CaboCha for fair comparison, which identifies phrases using KNP and parses using CaboCha.", "labels": [], "entities": [{"text": "phrase chunking", "start_pos": 8, "end_pos": 23, "type": "TASK", "confidence": 0.7306205630302429}]}, {"text": "Since KNP and CaboCha are not a joint model and accept only the 1-best output of morphological analysis, we fed the 1-best morphological analysis into KNP and CaboCha.", "labels": [], "entities": []}, {"text": "We fed both 1-best and N-best morphological analysis outputs into http://www.chokkan.org/software/classias/ our model for comparison.", "labels": [], "entities": []}, {"text": "We also tested our model without the automatically acquired lexical knowledge.", "labels": [], "entities": []}, {"text": "We measured the performance of each system using the F1-scores of the following aspects: word segmentation (Seg), \"segmentation + POS\" (POS), \"segmentation+ POS + fine-grained POS + base form\" (All), phrase segmentation (pSeg), and unlabeled/labeled dependency attachment score (UAS/LAS).", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9879457950592041}, {"text": "word segmentation", "start_pos": 89, "end_pos": 106, "type": "TASK", "confidence": 0.6473085135221481}, {"text": "phrase segmentation", "start_pos": 200, "end_pos": 219, "type": "TASK", "confidence": 0.6628388911485672}, {"text": "labeled dependency attachment score (UAS/LAS)", "start_pos": 242, "end_pos": 287, "type": "METRIC", "confidence": 0.7711138526598612}]}, {"text": "For the dependency labels, the following four labels are defined in the treebanks: D (dependency), P (parallel), I (incomplete parallel), and A (apposition).", "labels": [], "entities": []}, {"text": "In this table, the accuracies in bold of \"our model with Nbest input\" are significantly higher than the other models.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 19, "end_pos": 29, "type": "METRIC", "confidence": 0.9904693961143494}]}, {"text": "Statistical testing was conducted using the bootstrap method at p < 0.01.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Evaluation results. \"wo/LK\" means \"without lexical knowledge.\"", "labels": [], "entities": []}, {"text": " Table 5: Results on a corpus with ambiguities.", "labels": [], "entities": []}]}