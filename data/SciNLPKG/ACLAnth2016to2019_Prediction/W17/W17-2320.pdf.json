{"title": [{"text": "Unsupervised Domain Adaptation for Clinical Negation Detection", "labels": [], "entities": [{"text": "Unsupervised Domain Adaptation", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.5590995152791342}, {"text": "Clinical Negation Detection", "start_pos": 35, "end_pos": 62, "type": "TASK", "confidence": 0.6371344824632009}]}], "abstractContent": [{"text": "Detecting negated concepts in clinical texts is an important part of NLP information extraction systems.", "labels": [], "entities": [{"text": "Detecting negated concepts in clinical texts", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.899343878030777}, {"text": "NLP information extraction", "start_pos": 69, "end_pos": 95, "type": "TASK", "confidence": 0.8471837242444357}]}, {"text": "However, generaliz-ability of negation systems is lacking, as cross-domain experiments suffer dramatic performance losses.", "labels": [], "entities": []}, {"text": "We examine the performance of multiple unsupervised domain adaptation algorithms on clinical negation detection, finding only modest gains that fall well short of in-domain performance.", "labels": [], "entities": [{"text": "clinical negation detection", "start_pos": 84, "end_pos": 111, "type": "TASK", "confidence": 0.7203965584437052}]}], "introductionContent": [{"text": "Natural language processing applied to healthrelated texts, including clinical reports, can be valuable for extracting information that does not exist in any other form.", "labels": [], "entities": []}, {"text": "One important NLP task for clinical texts is concept extraction and normalization, where text spans representing medical concepts are found (e.g., colon cancer) and mapped to controlled vocabularies such as the Unified Medical Language System (UMLS).", "labels": [], "entities": [{"text": "concept extraction", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.7358894050121307}]}, {"text": "However, clinical texts often refer to concepts that are explicitly not present in the patient, for example, to document the process of ruling out a diagnosis.", "labels": [], "entities": [{"text": "ruling out a diagnosis", "start_pos": 136, "end_pos": 158, "type": "TASK", "confidence": 0.8751583695411682}]}, {"text": "These negated concepts, if not correctly recognized and extracted, can cause problems in downstream use cases.", "labels": [], "entities": []}, {"text": "For example, in phenotyping, a concept fora disease (e.g., asthma) is a strong feature fora classifier finding patients with asthma.", "labels": [], "entities": []}, {"text": "But if the text ruled out asthma occurs and the negation is not detected, this text will give the exact opposite signal that its inclusion intended.", "labels": [], "entities": []}, {"text": "There exist many systems for negation detection in the clinical domain, and there are also a variety of datasets available.", "labels": [], "entities": [{"text": "negation detection", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.9929287433624268}]}, {"text": "However generalizability of negation systems is still lacking, as cross-domain experiments suffer dramatic performance losses, even while obtaining F1 scores over 90% in the domain of the training data (.", "labels": [], "entities": [{"text": "F1", "start_pos": 148, "end_pos": 150, "type": "METRIC", "confidence": 0.997450053691864}]}, {"text": "Prior work has shown that there is a problem of generalizability in negation detection, but has done little to address it.", "labels": [], "entities": [{"text": "negation detection", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.986453652381897}]}, {"text": "In this work, we describe preliminary experiments to assess the difficulty of the problem, and evaluate the efficacy of existing domain adaptation algorithms on the problem.", "labels": [], "entities": []}, {"text": "We implement three unsupervised domain adaptation methods from the machine learning literature, and find that multiple methods obtain similarly modest performance gains, falling well short of in-domain performance.", "labels": [], "entities": []}, {"text": "Our research has broader implications, as the general problem of generalizabiliy applies to all clinical NLP problems.", "labels": [], "entities": []}, {"text": "Research in unsupervised domain adaptation can have a huge impact on the adoption of machine learning-based NLP methods for clinical applications.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 25, "end_pos": 42, "type": "TASK", "confidence": 0.7847697138786316}]}], "datasetContent": [{"text": "Our evaluation makes use of four corpora of clinical notes with negation annotations -i2b2 See that paper for an discussion of corpus differences.", "labels": [], "entities": []}, {"text": "the training split of the target domain -we made this choice because the development and test sets for some of the corpora are quite small and the training data gives us a more stable estimate of performance.", "labels": [], "entities": []}, {"text": "We tune two hyperparameters, L1 vs. L2 regularization and the values of regularization parameter C, with five-fold cross validation on the source corpus.", "labels": [], "entities": []}, {"text": "We record results for training on all four corpora, testing on all three target domains, as well as a cross-validation experiment to measure in-domain performance.", "labels": [], "entities": []}, {"text": "shows these results, which replicate Wu et al. in finding dramatic performance declines across corpora.", "labels": [], "entities": []}, {"text": "In our domain adaptation experiments, we also use all four corpora as source domains, and for each source domain we perform experiments where the other three corpora are target domains.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 7, "end_pos": 24, "type": "TASK", "confidence": 0.7204804867506027}]}, {"text": "This result is reported in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results (F1 scores) of baseline cross- domain experiments. Bold diagonals indicate  in-domain results, which were obtained with 5- fold cross-validation. Off-diagonal elements were  trained on source data and tested on target data.", "labels": [], "entities": [{"text": "F1 scores)", "start_pos": 19, "end_pos": 29, "type": "METRIC", "confidence": 0.9493857026100159}]}, {"text": " Table 2: Results of unsupervised domain adaptation algorithms (F1 scores). None=No adaptation,  10xReg=Regularization with 10x penalty, SCL A+N is structural correspondence learning with all features  in addition to projected (new) features, SCL P+N is SCL with pivot features and projected features,  BS-All=Bootstrapping with instances of all classes added to source, BS-Minority=Bootstrapping with  only instances of minority class added to source, ISF=Instance similarity features.", "labels": [], "entities": [{"text": "F1", "start_pos": 64, "end_pos": 66, "type": "METRIC", "confidence": 0.9807161092758179}]}]}