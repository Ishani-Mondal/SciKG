{"title": [{"text": "L1-L2 Parallel Dependency Treebank as Learner Corpus", "labels": [], "entities": [{"text": "Parallel Dependency Treebank", "start_pos": 6, "end_pos": 34, "type": "DATASET", "confidence": 0.5334397852420807}]}], "abstractContent": [{"text": "This opinion paper proposes the use of parallel treebank as learner corpus.", "labels": [], "entities": []}, {"text": "We show how an L1-L2 parallel treebank-i.e., parse trees of non-native sentences, aligned to the parse trees of their target hypotheses can facilitate retrieval of sentences with specific learner errors.", "labels": [], "entities": []}, {"text": "We argue for its benefits, in terms of corpus re-use and interoperability, over a conventional learner corpus annotated with error tags.", "labels": [], "entities": []}, {"text": "As a proof of concept, we conduct a case study on word-order errors made by learners of Chinese as a foreign language.", "labels": [], "entities": []}, {"text": "We report precision and recall in retrieving a range of word-order error categories from L1-L2 tree pairs annotated in the Universal Dependency framework.", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9994565844535828}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9994403719902039}]}], "introductionContent": [{"text": "A parallel treebank consists of multiple treebanks with alignments at the sentence level, and often also at the phrase and word levels.", "labels": [], "entities": []}, {"text": "Growing interest in parallel treebanks have yielded treebanks of many language combinations (.", "labels": [], "entities": []}, {"text": "So far, there has been no reported attempt to build an L1-L2 parallel treebank -i.e., parse trees of sentences written by non-native speakers (henceforth, \"L2 sentences\"), aligned to parse trees of their target hypotheses (henceforth, \"L1 sentences\").", "labels": [], "entities": []}, {"text": "shows an example parse tree pair in such a treebank.", "labels": [], "entities": []}, {"text": "The pair consists of the parse tree of a Chinese sentence written by a learner, and the parse tree of its corrected version, or \"target hypothesis\".", "labels": [], "entities": []}, {"text": "Although a number of L2 treebanks have been built, they either do not provide explicit target hypotheses (Ragheb and Dick- : An example L1-L2 tree pair, including word alignments between the learner sentence (\"L2\") and its target hypothesis (\"L1\"), and the parse trees of the two sentences, annotated in Universal Dependencies for Chinese ().", "labels": [], "entities": []}, {"text": "inson, 2014; Nagata and Sakaguchi, 2016), or have not yet provided parse trees for the target hypotheses (.", "labels": [], "entities": []}, {"text": "Parallel L1-L2 treebanks can be expected to serve a number of research agendas.", "labels": [], "entities": []}, {"text": "First, they would support quantitative studies in Contrastive Interlanguage Analysis (CIA) and Error Analysis (EA).", "labels": [], "entities": [{"text": "Contrastive Interlanguage Analysis", "start_pos": 50, "end_pos": 84, "type": "TASK", "confidence": 0.555403878291448}, {"text": "Error Analysis (EA)", "start_pos": 95, "end_pos": 114, "type": "TASK", "confidence": 0.7837354063987731}]}, {"text": "For CIA, they would enable comparisons between native and interlanguages not only on the lexical level but also on the syntactic level.", "labels": [], "entities": []}, {"text": "For EA, parallel parse trees would give more fine-grained characterization of the syntactic environment in which learner errors occur, which can inform the design of language teaching peda-gogy.", "labels": [], "entities": []}, {"text": "Further, just as parallel treebanks can help train machine translation (MT) systems, L1-L2 treebanks can supply sentence pairs to train systems for automatic grammatical error correction (GEC).", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 51, "end_pos": 75, "type": "TASK", "confidence": 0.8726406097412109}, {"text": "automatic grammatical error correction (GEC)", "start_pos": 148, "end_pos": 192, "type": "TASK", "confidence": 0.6941048290048327}]}, {"text": "Indeed, some GEC systems obtained state-of-the-art results by casting the task as an MT problem.", "labels": [], "entities": [{"text": "MT problem", "start_pos": 85, "end_pos": 95, "type": "TASK", "confidence": 0.9208028614521027}]}, {"text": "In this opinion paper, we focus on demonstrating how L1-L2 parallel treebanks can benefit learner language analysis.", "labels": [], "entities": [{"text": "learner language analysis", "start_pos": 90, "end_pos": 115, "type": "TASK", "confidence": 0.6608114341894785}]}, {"text": "In the next section, we argue that these treebanks can better facilitate re-use and interoperability among learner corpora, because they provide a more precise and flexible encoding of learner errors.", "labels": [], "entities": []}, {"text": "As a proof of concept, Section 3 presents a case study on identifying different word-order errors in Chinese L1-L2 parallel trees.", "labels": [], "entities": []}, {"text": "Finally, Section 4 concludes.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Tree queries for (a) subject-verb agree- ment in English (in Stanford Dependencies); and  (b) time expression word-order errors in Chinese  (in Universal Dependencies).", "labels": [], "entities": []}, {"text": " Table 2: Precision (P) and recall (R) of the manu- ally crafted tree queries in retrieving various error  types in the test set. See Jiang (2009) for a descrip- tion of the error types.", "labels": [], "entities": [{"text": "Precision (P)", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9483871459960938}, {"text": "recall (R)", "start_pos": 28, "end_pos": 38, "type": "METRIC", "confidence": 0.9577237963676453}]}]}