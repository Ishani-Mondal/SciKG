{"title": [{"text": "Argument Relation Classification Using a Joint Inference Model", "labels": [], "entities": [{"text": "Argument Relation Classification", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.9025185108184814}]}], "abstractContent": [{"text": "In this paper, we address the problem of argument relation classification where argument units are from different texts.", "labels": [], "entities": [{"text": "argument relation classification", "start_pos": 41, "end_pos": 73, "type": "TASK", "confidence": 0.7661018570264181}]}, {"text": "We design a joint inference method for the task by modeling argument relation classification and stance classification jointly.", "labels": [], "entities": [{"text": "argument relation classification", "start_pos": 60, "end_pos": 92, "type": "TASK", "confidence": 0.6934253970781962}, {"text": "stance classification", "start_pos": 97, "end_pos": 118, "type": "TASK", "confidence": 0.83952197432518}]}, {"text": "We show that our joint model improves the results over several strong baselines.", "labels": [], "entities": []}], "introductionContent": [{"text": "What is a good counterargument or support argument fora given argument?", "labels": [], "entities": []}, {"text": "Despite recent advances in computational argumentation, such as argument unit (e.g., claims, premises) mining (, argumentative relation (e.g., support, attack) prediction between argument units from the same text, as well as assessing argument strength of essays ( or predicting convincingness of Web arguments, this question is still an unsolved problem.", "labels": [], "entities": [{"text": "predicting convincingness of Web arguments", "start_pos": 268, "end_pos": 310, "type": "TASK", "confidence": 0.8076279997825623}]}, {"text": "In this work we focus on the problem of argument relation classification where argument units are from different texts, i.e., given a set of arguments related to the same topic, we aim to predict relations (e.g., agree or disagree) between any two arguments.", "labels": [], "entities": [{"text": "argument relation classification", "start_pos": 40, "end_pos": 72, "type": "TASK", "confidence": 0.7256722549597422}]}, {"text": "We are aware of argumentative relations between premises and the conclusion within a structured argument.", "labels": [], "entities": []}, {"text": "Instead, here we are interested in modeling relations among atomic argument units in dialogic argumentation.", "labels": [], "entities": []}, {"text": "This task is important for argumentation in debates (, stance classification (, or persuasion analysis (), among others.", "labels": [], "entities": [{"text": "argumentation", "start_pos": 27, "end_pos": 40, "type": "TASK", "confidence": 0.9796761274337769}, {"text": "stance classification", "start_pos": 55, "end_pos": 76, "type": "TASK", "confidence": 0.9226483702659607}, {"text": "persuasion analysis", "start_pos": 83, "end_pos": 102, "type": "TASK", "confidence": 0.7032694220542908}]}, {"text": "There are various different views on the meaning of \"support\" and \"attack\" in argumentation theory.", "labels": [], "entities": [{"text": "argumentation theory", "start_pos": 78, "end_pos": 98, "type": "TASK", "confidence": 0.8759527802467346}]}, {"text": "In this paper, we use \"agree\" and \"disagree\" to represent relations between two arguments which bear a stance regarding the same topic.", "labels": [], "entities": []}, {"text": "Specifically, if a 1 agrees with a 2 regarding the topic t then a 1 and a 2 are conflict-free.", "labels": [], "entities": []}, {"text": "And if a 1 disagrees with a 2 then they are not conflictfree.", "labels": [], "entities": []}, {"text": "There is a close relationship between argument relation classification and stance classification.", "labels": [], "entities": [{"text": "argument relation classification", "start_pos": 38, "end_pos": 70, "type": "TASK", "confidence": 0.7417663335800171}, {"text": "stance classification", "start_pos": 75, "end_pos": 96, "type": "TASK", "confidence": 0.8996299207210541}]}, {"text": "First, argument relation classification can benefit from knowing the stance information of arguments.", "labels": [], "entities": [{"text": "argument relation classification", "start_pos": 7, "end_pos": 39, "type": "TASK", "confidence": 0.8447831273078918}]}, {"text": "Specifically, if two arguments hold different stances with regard to the same topic, then they likely disagree with each other.", "labels": [], "entities": []}, {"text": "Likewise, two arguments that hold the same stance regarding the same topic tend to agree with each other.", "labels": [], "entities": []}, {"text": "Secondly, stance classification can benefit from modeling relations between arguments.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.9808925986289978}]}, {"text": "For instance, we would expect two arguments that disagree with each other to hold different stances.", "labels": [], "entities": []}, {"text": "There has been a large amount of work focusing on stance classification in on-line debate forums by integrating disagreement information between posts connected with reply links.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 50, "end_pos": 71, "type": "TASK", "confidence": 0.9645079374313354}]}, {"text": "However, disagreement information is mainly used as an auxiliary variable and is not explicitly evaluated.", "labels": [], "entities": []}, {"text": "Our goal in this paper is to examine argument relation classification in dialogic argumentation.", "labels": [], "entities": [{"text": "argument relation classification", "start_pos": 37, "end_pos": 69, "type": "TASK", "confidence": 0.7511620124181112}]}, {"text": "Our task is more challenging because unlike most previous work on disagreement classification, which can explore meta information (e.g., reply links between posts are strong indicators of disagreement), we are only provided with text information (see examples in.", "labels": [], "entities": [{"text": "disagreement classification", "start_pos": 66, "end_pos": 93, "type": "TASK", "confidence": 0.7432257235050201}]}, {"text": "In this paper, we model argument relation classification and stance classification jointly.", "labels": [], "entities": [{"text": "argument relation classification", "start_pos": 24, "end_pos": 56, "type": "TASK", "confidence": 0.7684400677680969}, {"text": "stance classification", "start_pos": 61, "end_pos": 82, "type": "TASK", "confidence": 0.88246950507164}]}, {"text": "We evaluate our model on a dataset extracted from De-Debate Topic: Are genetically modified foods (GM foods) beneficial?", "labels": [], "entities": []}, {"text": "Sub Topic: Consumer safety Arg (1) Pro Foods with poisonous allergens can be modified to reduce risks.", "labels": [], "entities": [{"text": "Arg", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.9792942404747009}]}, {"text": "Arg (2) Pro GM crops can be fortified with vitamins and vaccines.", "labels": [], "entities": [{"text": "Arg", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9785479307174683}]}, {"text": "Arg (3) Con There are many instances of GM foods proving dangerous.", "labels": [], "entities": [{"text": "Arg", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9798220992088318}]}, {"text": "Sub Topic: socio-economic impacts Arg (4) Pro GM crops are made disease-resistant, which increases yields.", "labels": [], "entities": [{"text": "Arg", "start_pos": 34, "end_pos": 37, "type": "METRIC", "confidence": 0.9970779418945312}]}, {"text": "Arg (5) Con GM agriculture threatens the viability of traditional farming communities.", "labels": [], "entities": [{"text": "Arg", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.8988633155822754}]}, {"text": "Arg (6) Pro GM crops generate greater wealth for farming communities.", "labels": [], "entities": [{"text": "Arg", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9031161665916443}]}, {"text": "Most existing work on argumentative relation focuses on classifying relations between argument units of monologic argumentation, from a single text.", "labels": [], "entities": []}, {"text": "One line of research () extracted argument units and predicted relations (i.e., support, attack, none) between argument units in persuasive student essays.", "labels": [], "entities": []}, {"text": "identified the argument structure of short texts in a bilingual corpus.", "labels": [], "entities": []}, {"text": "In contrast, in our work the argument units are from different texts.", "labels": [], "entities": []}, {"text": "Therefore, we do not have discourse connectives (e.g., \"on the contrary\" or \"however\") which usually are strong indicators for argument relations.", "labels": [], "entities": []}, {"text": "Cabrio and Villata (2012) used a textual entailment system to predict argument relations between argument pairs which are extracted from Debatepedia.", "labels": [], "entities": [{"text": "Debatepedia", "start_pos": 137, "end_pos": 148, "type": "DATASET", "confidence": 0.923898458480835}]}, {"text": "An argument pair could bean argument coupled with the subtopic, or an argument coupled 1 http://www.debatepedia.org/ with another argument of the opposite stance.", "labels": [], "entities": []}, {"text": "Recently, Menini and Tonelli (2016) predicted agreement/disagreement relations between argument pairs of dialogic argumentation in the political domain.", "labels": [], "entities": []}, {"text": "The authors also create a large agreement/disagreement dataset by extracting arguments from the same sub-topic of Debatepedia.", "labels": [], "entities": [{"text": "Debatepedia", "start_pos": 114, "end_pos": 125, "type": "DATASET", "confidence": 0.8314559459686279}]}, {"text": "However, they only consider argument pairs that share a topic keyword.", "labels": [], "entities": []}, {"text": "We do not have such constraints (see Arg (1) and Arg (2) in).", "labels": [], "entities": [{"text": "Arg", "start_pos": 37, "end_pos": 40, "type": "METRIC", "confidence": 0.9945738911628723}, {"text": "Arg", "start_pos": 49, "end_pos": 52, "type": "METRIC", "confidence": 0.982296884059906}]}, {"text": "In addition, they use SVM while we do joint inference.", "labels": [], "entities": []}, {"text": "There has been an increasing interest on modeling stance in debates (e.g., congressional debates or online political forums) ().", "labels": [], "entities": []}, {"text": "As discussed in Section 1, there is a close relationship between stance classification and argument relation classification.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 65, "end_pos": 86, "type": "TASK", "confidence": 0.8989060819149017}, {"text": "argument relation classification", "start_pos": 91, "end_pos": 123, "type": "TASK", "confidence": 0.7524426778157552}]}, {"text": "For instance, showed that stance classification in online debate forums can benefit from modeling disagreement of the reply links (e.g., you could assume an argument is attacking the preceding argument).", "labels": [], "entities": [{"text": "stance classification", "start_pos": 26, "end_pos": 47, "type": "TASK", "confidence": 0.9484252631664276}]}, {"text": "In our work, we focus on modeling argument relations.", "labels": [], "entities": []}, {"text": "Joint inference and Markov logic networks.", "labels": [], "entities": []}, {"text": "Markov logic networks (MLNs)) area statistical relational learning framework that combine first order logic and Markov networks.", "labels": [], "entities": []}, {"text": "They have been successfully applied to various NLP tasks such as semantic role labeling, information extraction, coreference resolution and bridging resolution (.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.7082873980204264}, {"text": "information extraction", "start_pos": 89, "end_pos": 111, "type": "TASK", "confidence": 0.8635536730289459}, {"text": "coreference resolution", "start_pos": 113, "end_pos": 135, "type": "TASK", "confidence": 0.9532307088375092}, {"text": "bridging resolution", "start_pos": 140, "end_pos": 159, "type": "TASK", "confidence": 0.8293108344078064}]}, {"text": "In this paper, we apply MLNs to model argument relation classification and stance classification jointly.", "labels": [], "entities": [{"text": "argument relation classification", "start_pos": 38, "end_pos": 70, "type": "TASK", "confidence": 0.6974064707756042}, {"text": "stance classification", "start_pos": 75, "end_pos": 96, "type": "TASK", "confidence": 0.8792678415775299}]}], "datasetContent": [{"text": "Debatepedia is an encyclopedia of arguments collected from different sources on debate topics.", "labels": [], "entities": [{"text": "Debatepedia", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.8817902207374573}]}, {"text": "Each debate topic is organized hierarchically.", "labels": [], "entities": []}, {"text": "It contains background of the topic and usually a number of subtopics, with pro and con arguments for or against each subtopic (see for an example).", "labels": [], "entities": []}, {"text": "An argument typically includes a claim and a few supporting evidences.", "labels": [], "entities": []}, {"text": "We create a corpus by extracting all subtopics and their arguments from Debatepedia.", "labels": [], "entities": [{"text": "Debatepedia", "start_pos": 72, "end_pos": 83, "type": "DATASET", "confidence": 0.9304293990135193}]}, {"text": "We pair all arguments from the same subtopic and label every argument pair as \"agree\" (for arguments holding the same stance) or \"disagree\" (for arguments holding the opposite stance).", "labels": [], "entities": []}, {"text": "In total we collect data from 657 topics.", "labels": [], "entities": []}, {"text": "We reserve 25 topics as the development set and 25 topics as the test set, using the remaining 607 topics for the training set.", "labels": [], "entities": []}, {"text": "gives an overview of the whole corpus.", "labels": [], "entities": []}, {"text": "Local argument relation classification (localRel).", "labels": [], "entities": [{"text": "Local argument relation classification", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.691890724003315}]}, {"text": "We employ logistic regression to train a local argument relation classification model using agree and disagree pairs from the training set.", "labels": [], "entities": [{"text": "local argument relation classification", "start_pos": 41, "end_pos": 79, "type": "TASK", "confidence": 0.6639720797538757}]}, {"text": "Our local classifier replicates, to the extent possible, the state-of-the-art local stance classifier from used by as well as the disagreement classifier from.", "labels": [], "entities": []}, {"text": "We include features of unigrams, all word pairs of the concatenation of two arguments, the overall sentiment of each argument from Stanford CoreNLP (), the content overlap of two arguments, as well as the number of negations in each argument using a list of negation cues (e.g., not, no, neither) from.", "labels": [], "entities": [{"text": "Stanford CoreNLP", "start_pos": 131, "end_pos": 147, "type": "DATASET", "confidence": 0.8989500403404236}]}, {"text": "We also include three types of dependency features) which consist of triples from the dependency parse of the argument.", "labels": [], "entities": []}, {"text": "Specifically, a basic dependency feature (rel i , t j , t k ) encodes the syntactic relation rel i between words t j and t k . One variant is to replace the headword of the relation rel i with its part-of-speech tag.", "labels": [], "entities": []}, {"text": "The other variant is replacing tokens in a triple with their polarities (i.e., + or \u2212) using MPQA dictionary of opinion words ().", "labels": [], "entities": []}, {"text": "We again employ logistic regression to train a local stance classification model (localStance) using the same features as in localRel.", "labels": [], "entities": []}, {"text": "We construct the training instances by pairing a topic t and all its pro/con arguments in the training set . During testing, we predict two arguments agree/disagree to each other if they have the same/differences stances regarding the topic.", "labels": [], "entities": []}, {"text": "We adapt the attention-based LSTM model used for textual entailment in.", "labels": [], "entities": [{"text": "textual entailment", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.753904789686203}]}, {"text": "We use GloVe vectors () with 100 dimensions trained on Wikipedia and Gigaword as word embeddings.", "labels": [], "entities": []}, {"text": "To avoid over-fitting, we apply dropout before and after the LSTM layer with the probability of 0.1.", "labels": [], "entities": []}, {"text": "We train the model with 60 epochs using cross-entropy loss.", "labels": [], "entities": []}, {"text": "We use Adam for optimization with the learning rate of 0.01.", "labels": [], "entities": []}, {"text": "We reimplement the approach for argument relation classification from.", "labels": [], "entities": [{"text": "argument relation classification", "start_pos": 32, "end_pos": 64, "type": "TASK", "confidence": 0.7690581878026327}]}, {"text": "Specifically, we train the textual entailment system EDIT 4 on our training set using the same configuration used in.", "labels": [], "entities": []}, {"text": "We then apply the trained model on the testing dataset.", "labels": [], "entities": []}, {"text": "For our approach described in Section 3, we use the output of the two local classifiers (localRel and localStance) as the input for formulas f 9 and f 10 in.", "labels": [], "entities": []}, {"text": "The weights of the formulas are learned on the dev dataset.", "labels": [], "entities": []}, {"text": "We use thebeast 6 to learn weights for the formulas and to perform inference.", "labels": [], "entities": []}, {"text": "thebeast employs cutting plane inference to improve the accuracy and efficiency of MAP inference for Markov logic.: Experimental results of argument relation classification on the testing dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9982001781463623}, {"text": "MAP inference", "start_pos": 83, "end_pos": 96, "type": "TASK", "confidence": 0.8697931170463562}, {"text": "argument relation classification", "start_pos": 140, "end_pos": 172, "type": "TASK", "confidence": 0.7045910954475403}]}, {"text": "Bold indicates statistically significant differences over the baselines using randomization test (p < 0.01).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Training, development and testing data.", "labels": [], "entities": []}, {"text": " Table 4: Experimental results of argument relation classification on the testing dataset. Bold indicates  statistically significant differences over the baselines using randomization test (p < 0.01).", "labels": [], "entities": [{"text": "argument relation classification", "start_pos": 34, "end_pos": 66, "type": "TASK", "confidence": 0.7558730840682983}]}]}