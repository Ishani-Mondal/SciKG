{"title": [{"text": "Stacking with Auxiliary Features for Entity Linking in the Medical Domain", "labels": [], "entities": [{"text": "Entity Linking", "start_pos": 37, "end_pos": 51, "type": "TASK", "confidence": 0.8025546967983246}]}], "abstractContent": [{"text": "Linking spans of natural language text to concepts in a structured source is an important task for many problems.", "labels": [], "entities": [{"text": "Linking spans of natural language text to concepts", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.8675291463732719}]}, {"text": "It allows intelligent systems to leverage rich knowledge available in those sources (such as concept properties and relations) to enhance the semantics of the mentions of these concepts in text.", "labels": [], "entities": []}, {"text": "In the medical domain, it is common to link text spans to medical concepts in large, cu-rated knowledge repositories such as the Unified Medical Language System.", "labels": [], "entities": []}, {"text": "Different approaches have different strengths: some are precision-oriented, some recall-oriented; some better at considering context but more prone to hallucination.", "labels": [], "entities": [{"text": "precision-oriented", "start_pos": 56, "end_pos": 74, "type": "METRIC", "confidence": 0.9966880679130554}, {"text": "recall-oriented", "start_pos": 81, "end_pos": 96, "type": "METRIC", "confidence": 0.9972750544548035}]}, {"text": "The variety of techniques suggests that ensem-bling could outperform component technologies at this task.", "labels": [], "entities": []}, {"text": "In this paper, we describe our process for building a Stacking ensemble using additional, auxiliary features for Entity Linking in the medical domain.", "labels": [], "entities": [{"text": "Stacking ensemble", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.88381427526474}, {"text": "Entity Linking", "start_pos": 113, "end_pos": 127, "type": "TASK", "confidence": 0.8991811275482178}]}, {"text": "Our best model beats several base-lines and produces state-of-the-art results on several medical datasets.", "labels": [], "entities": []}], "introductionContent": [{"text": "Entity Linking is the task of mapping phrases in text (mention spans) to concepts in a structured source, such as a knowledge base.", "labels": [], "entities": [{"text": "Entity Linking", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7213830053806305}]}, {"text": "The mention span is usually a word or short phrase describing a single, coherent concept.", "labels": [], "entities": []}, {"text": "For example, \"back pain\" maybe a mention span fora Dorsalgia concept in a knowledge base.", "labels": [], "entities": []}, {"text": "The span context is a window of text surrounding the mention span that maybe useful for disambiguating it.", "labels": [], "entities": []}, {"text": "For example, the sentence \"The patient reports suffering from back pain for several years prior to treatment\" maybe useful for determining that \"back pain\" refers to the concept Chronic Dorsalgia in this context.", "labels": [], "entities": [{"text": "Dorsalgia", "start_pos": 186, "end_pos": 195, "type": "METRIC", "confidence": 0.7407470941543579}]}, {"text": "In the medical domain, it is common to map mention spans to concepts in the Unified Medical Language System (UMLS) . Concepts in UMLS have unique identifiers called CUIs (Concept Unique Identifiers).", "labels": [], "entities": []}, {"text": "For example, the CUI for the concept Dorsalgia is C0004604.", "labels": [], "entities": [{"text": "Dorsalgia", "start_pos": 37, "end_pos": 46, "type": "DATASET", "confidence": 0.8307223916053772}, {"text": "C0004604", "start_pos": 50, "end_pos": 58, "type": "DATASET", "confidence": 0.9057570099830627}]}, {"text": "The concepts in UMLS come from merging concepts from many disparate contributing vocabularies.", "labels": [], "entities": []}, {"text": "Since automatic merging is imperfect, UMLS often contains multiple distinct CUIs for what amounts to the same semantic concept.", "labels": [], "entities": []}, {"text": "For example, the three distinct CUIs C0425687, C1167958 and C3263244 are all Jugular Venous Distension.", "labels": [], "entities": []}, {"text": "An Entity Linking system attempting to link a span such as \"engorgement of the jugular vein\" should be required to return all three CUIs.", "labels": [], "entities": [{"text": "Entity Linking", "start_pos": 3, "end_pos": 17, "type": "TASK", "confidence": 0.7289241999387741}]}, {"text": "A ground truth dataset should include all the three mappings as well.", "labels": [], "entities": []}, {"text": "UMLS also contains multiple textual labels for each CUI (called \"variants\") and semantic relations between CUIs, such as Acetaminophen may treat: Pain.", "labels": [], "entities": [{"text": "UMLS", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9439562559127808}]}, {"text": "Ensembling multiple systems is a well known standard approach to improving accuracy in machine learning).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9974151849746704}]}, {"text": "Ensembles have been applied to a wide variety of problems in all domains of artificial intelligence including natural language processing (NLP).", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 110, "end_pos": 143, "type": "TASK", "confidence": 0.7582998275756836}]}, {"text": "However, these techniques do not learn to discriminate adequately across the component systems and thus are unable to integrate them optimally.", "labels": [], "entities": []}, {"text": "Combining systems intelligently is crucial for improving the overall performance.", "labels": [], "entities": []}, {"text": "In this paper, we use an approach called Stacking with Auxiliary Features (SWAF)) for combining multiple diverse models.", "labels": [], "entities": []}, {"text": "Stacking uses supervised learning to train a meta-classifier to combine multiple system outputs.", "labels": [], "entities": []}, {"text": "SWAF enables the stacker to fuse additional relevant knowledge from multiple systems and thus leverage them to improve prediction.", "labels": [], "entities": []}, {"text": "The idea behind using auxiliary features is that an output is more reliable if not just multiple systems produce it but also agree on its provenance and there is sufficient supporting evidence.", "labels": [], "entities": []}, {"text": "We are the first to use ensembling for entity linking in the medical domain that lacks labeled data.", "labels": [], "entities": [{"text": "entity linking", "start_pos": 39, "end_pos": 53, "type": "TASK", "confidence": 0.7067420333623886}]}, {"text": "All the publicly available datasets are very small and thus learning is a problem.", "labels": [], "entities": []}, {"text": "Our approach is designed to overcome these challenges in the medical domain by using auxiliary features that are precision-focused and can be used to form a classification boundary from small amounts of data.", "labels": [], "entities": []}], "datasetContent": [{"text": "All systems and baselines were evaluated on three datasets.", "labels": [], "entities": []}, {"text": "Scores reflect the quality of concepts assigned to text spans, as decided by human judges.", "labels": [], "entities": []}, {"text": "Detecting span boundaries is not part of this evaluation -all systems are given the same span as input.", "labels": [], "entities": [{"text": "Detecting span boundaries", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8388943870862325}]}, {"text": "Annotations were performed by several human judges.", "labels": [], "entities": []}, {"text": "For scoring, each text span was paired with a list of concepts produced by all component systems.", "labels": [], "entities": [{"text": "scoring", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9634457230567932}]}, {"text": "Annotators marked each span-concept pair corrector incorrect.", "labels": [], "entities": []}, {"text": "The MCR dataset () resulted from running a CRF-based entity recognition system that extracted 1,570 clinical factors from 100 short descriptions (averaging 8 sentences, 100 words) of patient scenarios.", "labels": [], "entities": [{"text": "MCR dataset", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.8257834017276764}, {"text": "CRF-based entity recognition", "start_pos": 43, "end_pos": 71, "type": "TASK", "confidence": 0.5186514457066854}]}, {"text": "The annotated dataset contains a subset of 400 spans resulting in 6,139 annotated span-CUI pairs.", "labels": [], "entities": []}, {"text": "The average of the pairwise kappa scores for annotator agreement on the MCR dataset was 0.56.", "labels": [], "entities": [{"text": "MCR dataset", "start_pos": 72, "end_pos": 83, "type": "DATASET", "confidence": 0.9663170874118805}]}, {"text": "The i2b2 dataset) is based on the annotated patient discharge summaries released with the 2010 i2b2/VA challenge.", "labels": [], "entities": [{"text": "i2b2 dataset", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.8407826721668243}, {"text": "patient discharge summaries released with the 2010 i2b2/VA challenge", "start_pos": 44, "end_pos": 112, "type": "DATASET", "confidence": 0.6167115054347299}]}, {"text": "The concept extraction task was to identify and extract the text span corresponding to patient medical problems, treatments and tests in unannotated patient record text.", "labels": [], "entities": [{"text": "concept extraction", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.7869766354560852}]}, {"text": "We created an entity linking dataset from a random subset of 100 annotated text spans.", "labels": [], "entities": []}, {"text": "We ran all available entity linking systems and produced 2,224 annotated span-CUI pairs.", "labels": [], "entities": []}, {"text": "The average pairwise kappa score for annotator agreement on the i2b2 dataset was 0.52.", "labels": [], "entities": [{"text": "i2b2 dataset", "start_pos": 64, "end_pos": 76, "type": "DATASET", "confidence": 0.7488771975040436}]}, {"text": "The Electronic Medical Record dataset (EMR) is a private dataset containing spans of medical terms identified in doctors' notes within patient medical records.", "labels": [], "entities": [{"text": "Electronic Medical Record dataset (EMR)", "start_pos": 4, "end_pos": 43, "type": "DATASET", "confidence": 0.780814562525068}]}, {"text": "This dataset has 350 text spans with 3,991 annotated span-CUI pairs.", "labels": [], "entities": []}, {"text": "Annotators for the EMR dataset reconciled their annotations to build the ground truth.", "labels": [], "entities": [{"text": "EMR dataset", "start_pos": 19, "end_pos": 30, "type": "DATASET", "confidence": 0.8737764656543732}]}, {"text": "As noted in section 1, UMLS often has multiple distinct CUIs for the same semantic concept.", "labels": [], "entities": []}, {"text": "So fora given span from a dataset, there maybe many true positive concepts in the ground truth.", "labels": [], "entities": []}, {"text": "This leads to two possible scoring schemes: CUI level and Span level.", "labels": [], "entities": []}, {"text": "For CUI level scoring, every CUI in the ground truth is aground truth positive instance.", "labels": [], "entities": [{"text": "CUI level scoring", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.6486226916313171}]}, {"text": "A CUI produced by the Entity Linking system fora given span is a true positive if it is in the ground truth for that span and a false positive if it is not.", "labels": [], "entities": [{"text": "Entity Linking", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.6441354155540466}]}, {"text": "CUIs in the ground truth for the span that are not produced by the system are counted as false negatives.", "labels": [], "entities": []}, {"text": "Spans that have many CUIs in the ground truth, therefore, will have more weight in the precision and recall than spans with fewer CUIs.", "labels": [], "entities": [{"text": "precision", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.999602735042572}, {"text": "recall", "start_pos": 101, "end_pos": 107, "type": "METRIC", "confidence": 0.998450517654419}]}, {"text": "But since the number of appropriate CUIs fora span is often aside effect of the imperfect automatic merging of concepts in building UMLS, the bias is unnatural.", "labels": [], "entities": []}, {"text": "An alternative scoring scheme awards only one true positive, false positive or false negative for each span, not each CUI.", "labels": [], "entities": [{"text": "CUI", "start_pos": 118, "end_pos": 121, "type": "DATASET", "confidence": 0.9158456921577454}]}, {"text": "For this span level scoring, we report two versions of the metrics.", "labels": [], "entities": []}, {"text": "The first version, which we call \"Factor Level\" in the reported results, aggregates CUI scores using MAX.", "labels": [], "entities": [{"text": "MAX", "start_pos": 101, "end_pos": 104, "type": "DATASET", "confidence": 0.6154890060424805}]}, {"text": "The system scores a true positive if any of the CUIs it produces are in the ground truth for the span.", "labels": [], "entities": []}, {"text": "It scores a false positive if none of its CUIs are in the ground truth.", "labels": [], "entities": []}, {"text": "It scores a false negative if it produces no CUIs and there is at least one CUI in the ground truth.", "labels": [], "entities": []}, {"text": "The second version of span level scoring accounts for the fact that the system may produce a mixture of correct and incorrect CUIs for the same span.", "labels": [], "entities": [{"text": "span level scoring", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.6175165275732676}]}, {"text": "Each span still has a weight of one in the overall precision and recall, but the system's score for \"true positiveness\" and \"false positiveness\" can be areal number between 0 and 1.", "labels": [], "entities": [{"text": "precision", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9995858073234558}, {"text": "recall", "start_pos": 65, "end_pos": 71, "type": "METRIC", "confidence": 0.9995554089546204}]}, {"text": "We call this scoring scheme \"Quantum\".", "labels": [], "entities": []}, {"text": "The quantum true positive score fora span is the number of CUIs produced by the system that are in the  ground truth for the span divided by the total number of CUIs produced by the system (i.e., the spanlevel Precision).", "labels": [], "entities": []}, {"text": "Quantum false positive score is the number of incorrect CUIs produced by the system divided by the total number of CUIs produced.", "labels": [], "entities": [{"text": "false positive score", "start_pos": 8, "end_pos": 28, "type": "METRIC", "confidence": 0.7155491312344869}]}], "tableCaptions": [{"text": " Table 1: Results on the MCR dataset.", "labels": [], "entities": [{"text": "MCR dataset", "start_pos": 25, "end_pos": 36, "type": "DATASET", "confidence": 0.8618903458118439}]}, {"text": " Table 2: Results on the i2b2 dataset.", "labels": [], "entities": [{"text": "i2b2 dataset", "start_pos": 25, "end_pos": 37, "type": "DATASET", "confidence": 0.8212026357650757}]}, {"text": " Table 3: Results on the EMR dataset.", "labels": [], "entities": [{"text": "EMR dataset", "start_pos": 25, "end_pos": 36, "type": "DATASET", "confidence": 0.8508088290691376}]}]}