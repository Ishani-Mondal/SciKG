{"title": [{"text": "Improving the Naturalness and Expressivity of Language Generation for Spanish", "labels": [], "entities": [{"text": "Improving", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9742811918258667}, {"text": "Language Generation", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.6849032789468765}]}], "abstractContent": [{"text": "We present a flexible Natural Language Generation approach for Spanish, focused on the surface realisation stage, which integrates an inflection module in order to improve the naturalness and expressivity of the generated language.", "labels": [], "entities": [{"text": "Natural Language Generation", "start_pos": 22, "end_pos": 49, "type": "TASK", "confidence": 0.679756780465444}]}, {"text": "This inflection module inflects the verbs using an ensemble of trainable algorithms whereas the other types of words (e.g. nouns, determiners, etc) are inflected using hand-crafted rules.", "labels": [], "entities": []}, {"text": "We show that our approach achieves 2% higher accuracy than two state-of-art inflection generation approaches.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9987480640411377}]}, {"text": "Furthermore , our proposed approach also predicts an extra feature: the inflection of the imperative mood, which was not taken into account by previous work.", "labels": [], "entities": []}, {"text": "We also present a user evaluation , where we demonstrate that the proposed method significantly improves the perceived naturalness of the generated language.", "labels": [], "entities": []}], "introductionContent": [{"text": "Improving the naturalness and expressivity of the generated language is key in the area of Natural Language Generation (NLG), which aims to automatically generate text from non textual inputs.", "labels": [], "entities": [{"text": "Natural Language Generation (NLG)", "start_pos": 91, "end_pos": 124, "type": "TASK", "confidence": 0.8279968003431956}]}, {"text": "Specifically, one way to address it is by enriching the language through its morphology.", "labels": [], "entities": []}, {"text": "Existing NLG systems are usually applied to non-morphologically rich languages, such as English, where the morphological realisation (i.e. the production of well inflected sentences or words through the use of words' morpho-syntactic properties) of words during the generation can be done using hand-written rules or existing libraries such as SimpleNLG ().", "labels": [], "entities": [{"text": "SimpleNLG", "start_pos": 344, "end_pos": 353, "type": "DATASET", "confidence": 0.895453155040741}]}, {"text": "However, the use of this type of rules in morphologically rich languages, such as Spanish or German, can be expensive and lead to incorrect inflection of a word, thus generating ungrammatical or meaningless texts.", "labels": [], "entities": []}, {"text": "We propose a flexible and domain independent NLG approach for Spanish, focused on the surface realisation stage, which integrates an inflection module.", "labels": [], "entities": []}, {"text": "This inflection module incorporates an ensemble of trainable algorithms to automatically inflect a sentence by learning the inflection of Spanish verbs in conjunction with some hand-crafted rules for inflecting others types of words.", "labels": [], "entities": []}, {"text": "In the next section (Section 2), we refer to the related work on inflection generation in general and on inflection within NLG systems.", "labels": [], "entities": [{"text": "inflection generation", "start_pos": 65, "end_pos": 86, "type": "TASK", "confidence": 0.723389059305191}]}, {"text": "In Section 3, we describe our overall surface realisation approach which consists of three modules, including the proposed inflection module for NLG.", "labels": [], "entities": [{"text": "surface realisation", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.7365390658378601}, {"text": "NLG", "start_pos": 145, "end_pos": 148, "type": "DATASET", "confidence": 0.914456844329834}]}, {"text": "In Section 4, we present the experimental setup for testing the inflection module both with automatic metrics against state-of-the-art approaches and with a user evaluation, and in Section 5, we discuss the results.", "labels": [], "entities": []}, {"text": "Finally, in Section 6, directions for future work are discussed.", "labels": [], "entities": []}], "datasetContent": [{"text": "We performed two experiments: first, we tested the inflection module by comparing it against the stateof-the-art in order to ensure the accuracy for this task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 136, "end_pos": 144, "type": "METRIC", "confidence": 0.9993564486503601}]}, {"text": "Secondly, we generated and inflected the sentences using the whole surface realisation approach in order to test whether the quality of the generated sentences improved.", "labels": [], "entities": []}, {"text": "For the first experiment, we compared our inflection module (RandFT) with two very competitive baselines by) and Ahlberg14 (, by measuring the accuracy of their output for Spanish verb inflections under the same conditions.", "labels": [], "entities": [{"text": "Ahlberg14", "start_pos": 113, "end_pos": 122, "type": "METRIC", "confidence": 0.6682171821594238}, {"text": "accuracy", "start_pos": 143, "end_pos": 151, "type": "METRIC", "confidence": 0.9983896017074585}]}, {"text": "This experiment was done to validate the performing of the inflection module.", "labels": [], "entities": []}, {"text": "In order to compare our system with both baselines, we employed the test set of examples (200 different verbs) which was made available by, since this test-set included verbs with both irregular and regular forms.", "labels": [], "entities": []}, {"text": "This test set does not include any of the entries used within our training dataset.", "labels": [], "entities": []}, {"text": "For the experiments, we generated all the verb inflections for the 200 base forms.", "labels": [], "entities": []}, {"text": "Furthermore, the aforementioned baselines do not predict all the grammatical moods that exist in the Spanish language.", "labels": [], "entities": []}, {"text": "Both baselines are only able to predict the indicative and subjunctive mood, but not the imperative one, which is complex especially for irregular forms.", "labels": [], "entities": []}, {"text": "To tackle this, we used an additional test-set to evaluate this grammatical mood.", "labels": [], "entities": []}, {"text": "We created the additional test-set by employing information from the Freeling's lexicon for the imperative forms of these 200 verbs).", "labels": [], "entities": [{"text": "Freeling's lexicon", "start_pos": 69, "end_pos": 87, "type": "DATASET", "confidence": 0.9257026712099711}]}, {"text": "For the second experiment, we integrated the inflection unit with the surface realisation approach described in Section 3 in order to test if the quality of the generated sentences improved.", "labels": [], "entities": []}, {"text": "For this purpose, we generated a set of three related sentences for each Spanish phoneme (i.e. there area total of 27 phonemes in Spanish).", "labels": [], "entities": []}, {"text": "These sentences have related topics that will appear within the set so that the direct object of a sentence is used as the subject of the following sentence, obtaining a preliminary set of related sentences.", "labels": [], "entities": []}, {"text": "We compared our realisation approach against a random baseline, where a random verb tense was assigned for each of the sentences forming the set.", "labels": [], "entities": []}, {"text": "We set our proposed approach to a fixed tense, either present or indicative.", "labels": [], "entities": []}, {"text": "These sentences were ranked according to the approach described in section 3.2 being the linear combination of FLM as follows: , where f refers to a lemma, p refers to a POS tag, and \u03bb i are set \u03bb 1 = 0.25, \u03bb 2 = 0.25 and \u03bb 3 = 0.5.", "labels": [], "entities": []}, {"text": "These values were empirically determined by testing different values and comparing the results obtained.", "labels": [], "entities": []}, {"text": "For this experiment, we used a collection of Hans Christian Andersen tales, automatically gathered from Ciudad Seva 5 , as a corpus.", "labels": [], "entities": [{"text": "Ciudad Seva 5", "start_pos": 104, "end_pos": 117, "type": "DATASET", "confidence": 0.813338021437327}]}, {"text": "In order to train the FLM, used during the generation, we employed SRILM), a software that allows to build and apply statistical language models, which includes and implementation of FLM.", "labels": [], "entities": [{"text": "FLM", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.8705267310142517}]}, {"text": "In addition, we use Freeling language analyser to tag the corpus with lexical information as well as to perform the analysis of the generated sentences.", "labels": [], "entities": []}, {"text": "This section describes the results obtained with the experimentation carried out.", "labels": [], "entities": []}, {"text": "First, the results obtained from the comparison of our inflection module in order to validate its performance are shown.", "labels": [], "entities": []}, {"text": "Then, the results obtained from the integration of this module within the end-to-end NLG approach are described.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Accuracy of predicting inflection of verb tables and", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9971505999565125}, {"text": "predicting inflection of verb tables", "start_pos": 22, "end_pos": 58, "type": "TASK", "confidence": 0.8623947381973267}]}, {"text": " Table 4. The results of inflecting a sentence in", "labels": [], "entities": []}]}