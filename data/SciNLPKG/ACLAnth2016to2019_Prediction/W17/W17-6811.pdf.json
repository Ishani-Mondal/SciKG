{"title": [{"text": "Coarse Semantic Classification of Rare Nouns Using Cross-Lingual Data and Recurrent Neural Networks", "labels": [], "entities": [{"text": "Coarse Semantic Classification of Rare Nouns", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.7847228050231934}]}], "abstractContent": [{"text": "The paper presents a method for WordNet supersense tagging of Sanskrit, an ancient Indian language with a corpus grown over four millenia.", "labels": [], "entities": [{"text": "WordNet supersense tagging of Sanskrit", "start_pos": 32, "end_pos": 70, "type": "TASK", "confidence": 0.7442645907402039}]}, {"text": "The proposed method merges lexical information from Sanskrit texts with lexicographic definitions from Sanskrit-English dictionaries, and compares the performance of two machine learning methods for this task.", "labels": [], "entities": []}, {"text": "Evaluation concentrates on Vedic, the oldest layer of Sanskrit.", "labels": [], "entities": []}, {"text": "This level of Sanskrit contains numerous rare words that are no longer used in the later language and whose word senses can, therefore, not be induced from their occurrences in other texts.", "labels": [], "entities": []}, {"text": "The paper studies how to efficiently transfer knowledge from later forms of Sanskrit and from modern Western dictionaries for this special task of supersense disambiguation.", "labels": [], "entities": []}], "introductionContent": [{"text": "The paper discusses experiments in coarse-grained word semantic disambiguation (WSD) for Classical (CS) and Vedic Sanskrit (VS).", "labels": [], "entities": [{"text": "word semantic disambiguation (WSD)", "start_pos": 50, "end_pos": 84, "type": "TASK", "confidence": 0.7957501312096914}]}, {"text": "1 These experiments are part of a project that deals with the verb-argument labeling of Vedic texts.", "labels": [], "entities": [{"text": "verb-argument labeling of Vedic texts", "start_pos": 62, "end_pos": 99, "type": "TASK", "confidence": 0.83614022731781}]}, {"text": "The project is based on a manual annotation of all 27,104 verbal forms and their main arguments found in the R . gveda (R . V), the core text of the Vedic corpus.", "labels": [], "entities": [{"text": "R . gveda (R . V), the core text of the Vedic corpus", "start_pos": 109, "end_pos": 161, "type": "DATASET", "confidence": 0.7614111341536045}]}, {"text": "Apart from relating arguments to their governing verbs, the annotation disambiguates case semantic functions such as time or location for the locative, and it assigns a basic word semantic class to each argument (refer to the sample annotation in).", "labels": [], "entities": []}, {"text": "The word semantic annotations differentiate between eight classes that include, among others, abstract concepts, humans, and animals.", "labels": [], "entities": []}, {"text": "We are planning to use the annotation of the R . V as training corpus for building a verb-argument labeler that can be applied to other texts of the Vedic corpus.", "labels": [], "entities": [{"text": "annotation of the R . V", "start_pos": 27, "end_pos": 50, "type": "DATASET", "confidence": 0.7608552475770315}]}, {"text": "Several publications on argument and role labeling use word semantic classes or distributional representations of words for modeling selectional preferences of verbs.", "labels": [], "entities": [{"text": "argument and role labeling", "start_pos": 24, "end_pos": 50, "type": "TASK", "confidence": 0.6212431862950325}]}, {"text": "Following this work, we are going to employ WordNet supersenses (WNSS; of Vedic words as an additional prior in our argument labeling pipeline, both for detecting arguments in unlabeled texts (see the semantic coherence criterion in Laparra and), and for assigning appropriate word semantic classes to arguments.", "labels": [], "entities": []}, {"text": "The paper interprets WSD as a sentence classification task, where definitions from bilingual SanskritEnglish dictionaries and sentential contexts serve for predicting word semantic classes of Sanskrit nouns.", "labels": [], "entities": [{"text": "WSD", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.9712509512901306}, {"text": "sentence classification task", "start_pos": 30, "end_pos": 58, "type": "TASK", "confidence": 0.7667519450187683}, {"text": "predicting word semantic classes of Sanskrit nouns", "start_pos": 156, "end_pos": 206, "type": "TASK", "confidence": 0.8563312717846462}]}, {"text": "The paper concentrates on rare nouns, because the vocabulary of Vedic texts contains numerous lemmata that have disappeared in later Classical Sanskrit, so their distributional properties cannot be estimated: Verb-argument annotation of R . gveda 1.1.3 (\"He will obtain wealth prosperity through Agni every day.\").", "labels": [], "entities": []}, {"text": "Labels on the arcs indicate the syntactic functions (soc, ob, loc) and coarse word semantic classes (m = human, g = object, a = generic expression) of the arguments.", "labels": [], "entities": []}, {"text": "If more than one word fits into an argument class, only the first one is annotated.", "labels": [], "entities": []}, {"text": "reliably from the later corpus.", "labels": [], "entities": []}, {"text": "We will compare the efficiency of different machine learning models for this task.", "labels": [], "entities": []}, {"text": "In addition, the paper pays special attention to the philological setting of WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 77, "end_pos": 80, "type": "TASK", "confidence": 0.8809714913368225}]}, {"text": "While most NLP studies work with huge, contemporaneous corpora from closed domains (newspapers, Twitter), and can rely on richly annotated data sets, WSD for Vedic and Classical Sanskrit lacks most of these prerequisites.", "labels": [], "entities": [{"text": "WSD", "start_pos": 150, "end_pos": 153, "type": "TASK", "confidence": 0.8363569378852844}]}, {"text": "As a consequence, transfer of knowledge between languages (English definitions to Sanskrit word senses) and between different historical domains of Sanskrit literature plays an important role in our research.", "labels": [], "entities": []}, {"text": "While there is, in principle, no lack of Sanskrit texts, 3 the language is nevertheless under-resourced from the perspective of NLP.", "labels": [], "entities": [{"text": "NLP", "start_pos": 128, "end_pos": 131, "type": "DATASET", "confidence": 0.916145384311676}]}, {"text": "First, large parts of the literature have not yet been digitized.", "labels": [], "entities": []}, {"text": "This applies to the Sanskrit source texts and to their translations into modern languages, and complicates unsupervised knowlegde acquisition from large (parallel) corpora as, for instance, proposed by.", "labels": [], "entities": [{"text": "knowlegde acquisition", "start_pos": 120, "end_pos": 141, "type": "TASK", "confidence": 0.658563643693924}]}, {"text": "Second, the rich morphology, especially of VS, the lack of reliable punctuation marks 4 , and the phonetic phenomenon of Sandhi (\"combination [of phonemes]\") make linguistic analysis a hard task for NLP.", "labels": [], "entities": []}, {"text": "Due to these features, standard token-based NLP pipelines cannot be applied to Sanskrit, as becomes apparent fora short phrase such as saitatpa\u00b4syat\u00afsaitatpa\u00b4syat\u00af \u0131tyuktv\u00af a.", "labels": [], "entities": []}, {"text": "This string is formed by phonetically merging the five inflected tokens s\u00af a, etad, pa\u00b4syatipa\u00b4syati, iti, and uktv\u00af a (tiny \"equations\" give the operative Sandhi rules): s\u00af a she:N.SG.", "labels": [], "entities": []}, {"text": "pa\u00b4syatipa\u00b4syati see:3.sg., pr. iti thus:ind.", "labels": [], "entities": []}, {"text": "uktv\u00af a say:abs.", "labels": [], "entities": []}, {"text": "having said: 'She sees this' ...", "labels": [], "entities": []}, {"text": "Apart from the correct analysis given above, this string has at least seven further readings that are lexically valid, though semantically meaningless.", "labels": [], "entities": []}, {"text": "Because the valid tokenization of a Sanskrit text requires a full morphological and lexical analysis, the methods described in this paper operate with fully disambiguated lemmata, instead of tokenized strings as is usually done in NLP of English.", "labels": [], "entities": [{"text": "tokenization of a Sanskrit text", "start_pos": 18, "end_pos": 49, "type": "TASK", "confidence": 0.8150617122650147}]}, {"text": "In order to mitigate the problems introduced by size and structure of the corpus, we use bilingual information for WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 115, "end_pos": 118, "type": "TASK", "confidence": 0.9026045203208923}]}, {"text": "Sanskrit has a rich history of philological research both in India and in the West.", "labels": [], "entities": []}, {"text": "Part of this history are comprehensive Sanskrit-English dictionaries, which are also available in digital form.", "labels": [], "entities": []}, {"text": "These dictionaries provide English definitions for Sanskrit lemmata, and the definitions are ordered following lexicographic considerations.", "labels": [], "entities": []}, {"text": "We will use the lexical definitions and their lexicographic order along with Sanskrit context words for WNSS classification in VS and CS.", "labels": [], "entities": [{"text": "WNSS classification", "start_pos": 104, "end_pos": 123, "type": "TASK", "confidence": 0.8471413850784302}]}, {"text": "This setting may remind The size of Sanskrit literature cannot be estimated reliably.", "labels": [], "entities": []}, {"text": "considers that there exists a total of 30,000,000 Indian manuscripts, a substantial number of which may contain Sanskrit works.", "labels": [], "entities": []}, {"text": "Several thousand Sanskrit texts have been edited and printed in the last 200 years, and a few hundred of them are available in digital form.", "labels": [], "entities": []}, {"text": "Sanskrit texts are structured by dan . d . as 'sticks' (|).", "labels": [], "entities": []}, {"text": "These symbols indicate the end of metrical sequences, which are quite frequently not identical with sentence boundaries.", "labels": [], "entities": []}, {"text": "Sentence internal structuring symbols such as commata and colons are missing completely.", "labels": [], "entities": []}, {"text": "When applied to a Sanskrit text, the term 'sentence' refers to dan . d . a-delimited sequences of words in the rest of the paper.", "labels": [], "entities": []}, {"text": "5 http://www.sanskrit-lexicon.uni-koeln.de/ of knowledge based approaches to WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 77, "end_pos": 80, "type": "TASK", "confidence": 0.9580103754997253}]}, {"text": "However, it should be noted that the proposed method does not calculate the lexical overlap between the Sanskrit text and dictionary glosses for determining the best fitting word sense, as proposed by and later authors.", "labels": [], "entities": []}, {"text": "Moreover, it does not use the graph structure of OpenCyc for WSD (.", "labels": [], "entities": [{"text": "WSD", "start_pos": 61, "end_pos": 64, "type": "DATASET", "confidence": 0.733374834060669}]}, {"text": "On the technical side, the paper will compare the efficiency of Maximum Entropy and of recurrent neural network models, both of which are regularly applied to WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 159, "end_pos": 162, "type": "TASK", "confidence": 0.7584496736526489}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "After an overview of related research in Section 2, Section 3 introduces the corpus and describes its semantic annotation layer.", "labels": [], "entities": []}, {"text": "Section 4 describes how features for WSD are created, and which models are applied to the task.", "labels": [], "entities": [{"text": "WSD", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.9627581238746643}]}, {"text": "Section 5 compares the performance of the models and gives a short error analysis.", "labels": [], "entities": [{"text": "error analysis", "start_pos": 67, "end_pos": 81, "type": "METRIC", "confidence": 0.9358280003070831}]}, {"text": "Section 6 summarizes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "The models are evaluated in two settings: Rare nouns uses the 2,809 sense annotated noun tokens whose lemmata occur less than three times in the complete DCS as test set, and the remaining sense annotated noun tokens as training set.", "labels": [], "entities": []}, {"text": "Vedic nouns uses the 528 sense annotated noun tokens whose lemmata occur only in the Vedic layer of the DCS as test set, and the remaining sense annotated noun tokens as training set.", "labels": [], "entities": []}, {"text": "This setting simulates knowledge transfer from CS to VS.", "labels": [], "entities": [{"text": "knowledge transfer", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.707654595375061}]}, {"text": "Note that lemmata in the test set are not required to be rare, contrary to the rare nouns settings.", "labels": [], "entities": []}, {"text": "presents micro-and macro-averaged precision, recall, and F-scores for the two settings, while breaks up these numbers by WNSS.", "labels": [], "entities": [{"text": "precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9375033974647522}, {"text": "recall", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.9973388314247131}, {"text": "F-scores", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9990684390068054}, {"text": "WNSS", "start_pos": 121, "end_pos": 125, "type": "DATASET", "confidence": 0.9279107451438904}]}, {"text": "Although the historical structure of the Sanskrit corpus, the annotation mode (Sec.", "labels": [], "entities": []}, {"text": "3), and the classifier types do not allow direct comparison with the results reported by and Ciaramita and Altun (2006), shows that ME and RNN achieve good performance, especially for rare nouns.", "labels": [], "entities": []}, {"text": "Both classifiers clearly improve over the baseline.", "labels": [], "entities": []}, {"text": "Low recall rates of the baseline indicate problems with WordNet coverage, while its low precision is caused by the interaction between high semantic ambiguity of Sanskrit nouns and lexicographic arrangement (refer to Fn. 10).", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9984346032142639}, {"text": "WordNet coverage", "start_pos": 56, "end_pos": 72, "type": "DATASET", "confidence": 0.7972927391529083}, {"text": "precision", "start_pos": 88, "end_pos": 97, "type": "METRIC", "confidence": 0.9987383484840393}]}, {"text": "For the word aurabhra, for example, Monier-Williams (1899) provides the definitions \"a coarse woollen blanket\" and \"name of a physician\".", "labels": [], "entities": []}, {"text": "Although the first meaning occurs only in indigenous monolingual dictionaries, Monier-Williams (1899) places it at first position, because it maybe the etymologically older meaning (urabhra 'sheep' aurabhra).", "labels": [], "entities": []}, {"text": "The baseline can, therefore, never access the second, correct solution.", "labels": [], "entities": []}, {"text": "4 demonstrate that ME and RNN have problems with nouns denoting abstract concepts.", "labels": [], "entities": []}, {"text": "While ME and RNN obtain accuracy rates of 81.7% and 83.5% for concrete nouns in the setting rare nouns, they only achieve 56.0% and 54.7% for abstract ones in the same setting.", "labels": [], "entities": [{"text": "ME", "start_pos": 6, "end_pos": 8, "type": "METRIC", "confidence": 0.6973115801811218}, {"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.999508261680603}]}, {"text": "The higher error rate for abstract nouns can partly be explained by missing specialization of the English dictionary.", "labels": [], "entities": [{"text": "error rate", "start_pos": 11, "end_pos": 21, "type": "METRIC", "confidence": 0.9785411953926086}]}, {"text": "In the medical text Su\u00b4srutasamSu\u00b4srutasam . hit\u00af a, Cik.", "labels": [], "entities": []}, {"text": "11.3, for example, the term parisaran . a denotes a symptom of the urinary disease called prameha, as a patient suffering from prameha \"gets the habit of parisaran . a.\" Monier-Williams (1899) glosses the hapax legomenon parisaran . a as \"running or moving about\", which is a direct translation of the meaning \"Umherlaufen\" in.", "labels": [], "entities": []}, {"text": "Both dictionaries were obviously not aware that the term has a medical meaning in this passage, and can best be translated as \"restlessness\".", "labels": [], "entities": []}, {"text": "This translation was actually chosen as the word semantic annotation of parisaran . a, and was connected with the synset \"restlessness (inability to rest or relax or be still)\" in OpenCyc.", "labels": [], "entities": []}, {"text": "While the WNSS of \"restlessness\" is \"attribute\", both ME and RNN classify this occurrence of parisaran . a as an \"act\" -a meaningful proposal given the limited amount of information available in Monier-Williams (1899) and.", "labels": [], "entities": [{"text": "WNSS", "start_pos": 10, "end_pos": 14, "type": "DATASET", "confidence": 0.6480994820594788}, {"text": "ME", "start_pos": 54, "end_pos": 56, "type": "METRIC", "confidence": 0.9679628610610962}]}, {"text": "All three solutions can be justified semantically in the given textual context.", "labels": [], "entities": []}, {"text": "While the gold annotation \"attribute\" fits well into the scientific character of the text, which draws a systematic picture of the ideal king, the solution \"act\" would highlight the voluntary negligence of royal duties.", "labels": [], "entities": []}, {"text": "Interestingly, the semantic ambiguity is reflected, and even increased by the Sanskrit commentaries of the text.", "labels": [], "entities": []}, {"text": "The commentary of Medh\u00af atithi seems to support a reading as an \"act\", because he paraphrases the term with the clause \"when the king has not performed the considerations described above\" (Mandlik; yastu r\u00af aj\u00af a p\u00af urvoktavivekam akr . tv\u00af a ...).", "labels": [], "entities": []}, {"text": "On the other hand, the commentators Kull\u00af uka (\"through bad teachings and lack of knowledge\", dus . t . a\u00b4sisa\u00b4sis . t . \u00af aj\u00f1\u00af anena) and R\u00af amacandra (\"through lack of consideration\", avic\u00af aren . a) interpret anaveks . \u00af a rather as a cognitive feature or process.", "labels": [], "entities": []}, {"text": "If their interpretation is accepted, the term should have been labeled as \"cognition\" in the given context.", "labels": [], "entities": []}, {"text": "Apart from emphasizing the problem of missing adjudication (Sec.", "labels": [], "entities": []}, {"text": "3), this example shows the limits of semantic differentiability when interpreting ancient texts, whose languages are not spoken anymore.", "labels": [], "entities": [{"text": "interpreting ancient texts", "start_pos": 69, "end_pos": 95, "type": "TASK", "confidence": 0.8586716453234354}]}, {"text": "ME and RNN consistently perform better for rare than for Vedic nouns.", "labels": [], "entities": [{"text": "ME", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.9483528733253479}, {"text": "RNN", "start_pos": 7, "end_pos": 10, "type": "METRIC", "confidence": 0.8774600028991699}]}, {"text": "This behavior points to the problems inherent in transfering word semantic knowledge overlong distances in time, and supports the conclusions reached by for projecting parser annotations.", "labels": [], "entities": [{"text": "transfering word semantic knowledge overlong distances in time", "start_pos": 49, "end_pos": 111, "type": "TASK", "confidence": 0.8514641299843788}]}, {"text": "The vast majority of training records in both settings comes from CS, so that classifiers are biased towards this form of Sanskrit.", "labels": [], "entities": []}, {"text": "The composition of the test sets, on the other hand, shows clear differences: Out of the 2,809 words in the test set of rare nouns, 1,363 belong to the medical and alchemical subcorpus, 574 to the epic literature, and 247 to the poetic and narrative subcorpus, while only 118 are from the Vedic period (106 of them from the R . gveda).", "labels": [], "entities": []}, {"text": "The training set of rare words provides plenty of data for disambiguating the WNSS of nouns from the later subcorpora, because the alchemical and the epic subcorpora are more densely annotated than other parts of the DCS (refer to page 4).", "labels": [], "entities": []}, {"text": "These properties are not met for the setting Vedic nouns.", "labels": [], "entities": []}, {"text": "Although the ME is trained with preprocessed English definitions, the RNN produces better overall results in both experimental settings.", "labels": [], "entities": []}, {"text": "This conclusion holds for frequent and for rare WNSS, as is evidenced by the macro-average values in and the F-scores of rare WNSS in.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 109, "end_pos": 117, "type": "METRIC", "confidence": 0.9940595626831055}]}, {"text": "We hypothesize that the ME is notable to integrate context features appropriately in several cases.", "labels": [], "entities": []}, {"text": "In the medical passage Su\u00b4srutasamSu\u00b4srutasam . hit\u00af a, Nid\u00af anasth\u00af ana 9.16, for example, the word veg\u00af agh\u00af ata 'constipation' is correctly labeled as 'state' by the RNN, but as 'act' by the ME, although the headword \"constipation\" receives the highest coefficient of 1.529 for the label 'state'.", "labels": [], "entities": [{"text": "RNN", "start_pos": 169, "end_pos": 172, "type": "DATASET", "confidence": 0.8721818327903748}]}, {"text": "The misclassification of this token is caused by context features such as the Sanskrit lemma vy\u00af ay\u00af ama 'exertion', whose linear combination produces the final decision for 'act'.", "labels": [], "entities": []}, {"text": "On the other hand, performance of the RNN model drops sharply, when randomly 3).", "labels": [], "entities": []}, {"text": "This finding underlines the importance of using appropriate pretrained embeddings in downstream tasks ().", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Size of the word semantic annotation layer in the DCS: Number of lexical tokens and types with  word semantic annotations, split by word classes", "labels": [], "entities": []}, {"text": " Table 2: Proportions of WNSS in three manually annotated samples of 400 lexical tokens; S 1 : hapax  legomena in 200,00 token subcorpora; S 2 : hapax legomena in late Vedic texts; S 3 : random tokens  from the full DCS. -Rows are ordered by summed absolute frequencies (N) of supersenses in the three  samples (P: proportions in the three samples). Differences to the sum of 3 \u00d7 400 indicate that some  samples could not be labeled.", "labels": [], "entities": []}, {"text": " Table 3: Results in terms of mi(cro-) and ma(cro-average) p(recision), r(ecall), and F-score; details in", "labels": [], "entities": [{"text": "F-score", "start_pos": 86, "end_pos": 93, "type": "METRIC", "confidence": 0.9978383183479309}]}, {"text": " Table 4: P(recision), r(ecall) and F-score for rare (upper subtable) and Vedic nouns (lower subtable).  Row-wise maxima are printed bold.", "labels": [], "entities": [{"text": "F-score", "start_pos": 36, "end_pos": 43, "type": "METRIC", "confidence": 0.9881771206855774}]}]}