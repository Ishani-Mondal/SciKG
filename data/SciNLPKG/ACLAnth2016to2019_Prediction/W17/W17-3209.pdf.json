{"title": [{"text": "Detecting Cross-Lingual Semantic Divergence for Neural Machine Translation", "labels": [], "entities": [{"text": "Detecting Cross-Lingual Semantic Divergence", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.8770982325077057}, {"text": "Neural Machine Translation", "start_pos": 48, "end_pos": 74, "type": "TASK", "confidence": 0.7307860652605692}]}], "abstractContent": [{"text": "Parallel corpora are often not as parallel as one might assume: non-literal translations and noisy translations abound, even in cu-rated corpora routinely used for training and evaluation.", "labels": [], "entities": []}, {"text": "We use a cross-lingual tex-tual entailment system to distinguish sentence pairs that are parallel in meaning from those that are not, and show that filtering out divergent examples from training improves translation quality.", "labels": [], "entities": []}], "introductionContent": [{"text": "Parallel sentence pairs provide examples of translation equivalence to train Machine Translation (MT) and cross-lingual Natural Language Processing.", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 77, "end_pos": 101, "type": "TASK", "confidence": 0.8721651911735535}, {"text": "cross-lingual Natural Language Processing", "start_pos": 106, "end_pos": 147, "type": "TASK", "confidence": 0.6056991666555405}]}, {"text": "However, despite what the term \"parallel\" implies, the source and target language often do not convey the exact same meaning.", "labels": [], "entities": []}, {"text": "This is a surprisingly common phenomenon, not only in noisy corpora automatically extracted from comparable collections, but also in parallel training and test corpora, as can be seen in.", "labels": [], "entities": []}, {"text": "This issue has mostly been ignored in machine translation, where parallel sentences are assumed to be translations of each other, and translations are assumed to have the same meaning.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.8001516163349152}]}, {"text": "Prior work on characterizing parallel sentences for MT has focused on data selection and weighting for domain adaptation, among others), and on assessing the relevance of parallel sentences by comparison with a corpus of interest.", "labels": [], "entities": [{"text": "MT", "start_pos": 52, "end_pos": 54, "type": "TASK", "confidence": 0.9070161581039429}, {"text": "domain adaptation", "start_pos": 103, "end_pos": 120, "type": "TASK", "confidence": 0.7466681599617004}]}, {"text": "In contrast, we focus on detecting an intrinsic property of parallel sentence pairs.", "labels": [], "entities": []}, {"text": "Divergent sentence pairs have been viewed as noise both in comparable and non-parallel corpora () and Divergent segments in OpenSubtitles en someone wanted to cook bratwurst.", "labels": [], "entities": []}, {"text": "fr vous vouliez des saucisses grill\u00e9es.", "labels": [], "entities": []}, {"text": "gl you wanted some grilled sausages.", "labels": [], "entities": []}, {"text": "en i don't know what i'm gonna do. fr j'en sais rien.", "labels": [], "entities": []}, {"text": "gl i don't know.", "labels": [], "entities": []}, {"text": "en -has the sake chilled?", "labels": [], "entities": []}, {"text": "-no, it's fine.", "labels": [], "entities": []}, {"text": "fr -c'est assez chaud?", "labels": [], "entities": []}, {"text": "gl -it is hot enough?", "labels": [], "entities": []}, {"text": "en you help me with zander and i helped you with joe.", "labels": [], "entities": []}, {"text": "fr tu m'as aid\u00e9e avec zander, je t'ai aid\u00e9e avec joe.", "labels": [], "entities": []}, {"text": "gl you helped me with zander, i helped you with joe.", "labels": [], "entities": []}], "datasetContent": [{"text": "Training data statistics and their coverage of the test set are summarized in.", "labels": [], "entities": []}, {"text": "Data selection naturally reduces the vocabulary size available compared to using all the training data, by at most 10%.", "labels": [], "entities": []}, {"text": "Selecting non-divergent sentences yields a smaller vocabulary compared to using the same number of parallel sentence pairs selected based on natural order or random sampling.", "labels": [], "entities": []}, {"text": "At the same time, non-divergent examples are richer than those selected based on length alone, with a more diverse vocabulary.", "labels": [], "entities": []}, {"text": "Test data statistics shows the complementarity of the two test conditions considered: the MSLT task consists of shorter sentences similarly to all training settings, while the TED tasks consists of much longer segments.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Data statistics for training and test sets. At train time, selecting non-divergent sentences yields  (1) a smaller vocabulary compared to datasets of the same size (2) richer examples than selection based  on length only, with a more diverse vocabulary.", "labels": [], "entities": []}, {"text": " Table 5: Ensembles of systems (mix) trained on  all data and non-divergent data yield modest im- provements in BLEU", "labels": [], "entities": [{"text": "im- provements", "start_pos": 94, "end_pos": 108, "type": "METRIC", "confidence": 0.9279289245605469}, {"text": "BLEU", "start_pos": 112, "end_pos": 116, "type": "METRIC", "confidence": 0.9800364375114441}]}, {"text": " Table 3: Impact of data selection criterion on TED and MSLT test sets translated by an ensemble of  the 3 best models saved during training. Filtering out DIVERGENT examples yields the best translation  quality.", "labels": [], "entities": [{"text": "TED and MSLT test sets", "start_pos": 48, "end_pos": 70, "type": "DATASET", "confidence": 0.6677093863487243}]}, {"text": " Table 4: Impact of longer training time on BLEU scores for TED and MSLT test sets translated by  ensembles of 3 models. Filtering out divergent examples still yields the best translation quality, outper- forming other selection criteria as well as systems trained on all data.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.9936421513557434}, {"text": "TED and MSLT test sets", "start_pos": 60, "end_pos": 82, "type": "DATASET", "confidence": 0.6730235636234283}]}]}