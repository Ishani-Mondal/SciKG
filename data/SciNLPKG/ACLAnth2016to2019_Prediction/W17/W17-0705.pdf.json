{"title": [{"text": "Inherent Biases of Recurrent Neural Networks for Phonological Assimilation and Dissimilation", "labels": [], "entities": [{"text": "Phonological Assimilation and Dissimilation", "start_pos": 49, "end_pos": 92, "type": "TASK", "confidence": 0.8150077164173126}]}], "abstractContent": [{"text": "A recurrent neural network model of phonological pattern learning is proposed.", "labels": [], "entities": [{"text": "phonological pattern learning", "start_pos": 36, "end_pos": 65, "type": "TASK", "confidence": 0.7166234056154887}]}, {"text": "The model is a relatively simple neural network with one recurrent layer, and displays biases in learning that mimic observed biases inhuman learning.", "labels": [], "entities": []}, {"text": "Single-feature patterns are learned faster than two-feature patterns, and vowel or consonant-only patterns are learned faster than patterns involving vowels and consonants , mimicking the results of laboratory learning experiments.", "labels": [], "entities": []}, {"text": "In non-recurrent models, capturing these biases requires the use of alpha features or some other representation of repeated features, but with a recurrent neural network, these elabora-tions are not necessary.", "labels": [], "entities": []}], "introductionContent": [{"text": "Models of phonological pattern learning typically require large numbers of constraints or rules on where features can occur, and the presence of alpha features or some other representation of repeated features to allow certain patterns to be learned more quickly.", "labels": [], "entities": [{"text": "phonological pattern learning", "start_pos": 10, "end_pos": 39, "type": "TASK", "confidence": 0.6828243931134542}]}, {"text": "In human learning experiments, certain phonological patterns are learned more easily, particularly those involving multiple occurences of the same feature, such as a voicing agreement pattern.", "labels": [], "entities": []}, {"text": "In order to capture this bias towards singlefeature patterns, many models have some representation of repeated features.", "labels": [], "entities": []}, {"text": "Alpha features are one example of this (see for other approaches, such as feature geometry).", "labels": [], "entities": [{"text": "feature geometry", "start_pos": 74, "end_pos": 90, "type": "TASK", "confidence": 0.7118511199951172}]}, {"text": "Alpha features allow a model to learn a harmony pattern with only one predicate -that two features must be the same, having the value \u03b1.", "labels": [], "entities": []}, {"text": "Without alpha features, the model must learn two predicates -that the two features must either both have the value + or the value \u2212.", "labels": [], "entities": []}, {"text": "Therefore, there cannot be a bias towards single-feature patterns, because two-feature patterns also require learning two predicates.", "labels": [], "entities": []}, {"text": "In addition to alpha features, many phonological learning models have to test or search over a large number of possible rules or constraints to learn a pattern.", "labels": [], "entities": []}, {"text": "In models that use conjunctions of features as constraints (, if there are N features in the model, each with three possible values (+, \u2212, \u00b1), there are 3 N possible conjunctions of these features.", "labels": [], "entities": []}, {"text": "With even a small number of features, the number of conjunctive constraints becomes very large.", "labels": [], "entities": []}, {"text": "Moreton, Pater, and Pertsova (2015) describe a cue-based learning model that uses these conjunctive constraints.", "labels": [], "entities": []}, {"text": "Their model is a maximum entropy model trained by gradient descent on negative log-likelihood, and is related to the singlelayer perceptron.", "labels": [], "entities": []}, {"text": "It successfully models the biases found inhuman phonological learning experiments, but still requires listing all possible constraint conjuncions in the input.", "labels": [], "entities": []}, {"text": "In unpublished work, I have found that it is also possible to model these biases without constraint conjunctions using a feed-forward neural network with a hidden layer.", "labels": [], "entities": []}, {"text": "See Alderete and Tupper (To appear) for an overview of other connectionist approaches to phonology.", "labels": [], "entities": []}, {"text": "Hare (1990) uses a recurrent neural network to model Hungarian vowel harmony without phonological rules or constraints.", "labels": [], "entities": [{"text": "Hungarian vowel harmony", "start_pos": 53, "end_pos": 76, "type": "TASK", "confidence": 0.6202916502952576}]}, {"text": "In Hare's model, sequences of individual features describing vowels were the only inputs to the network.", "labels": [], "entities": []}, {"text": "Some features in the input sequence could be left unspecified, and after training, fully specified feature sequences are output.", "labels": [], "entities": []}, {"text": "While the model was only trained on sequences of vowels, not entire words, Hare showed that recurrent neural networks were capable of modeling vowel harmony patterns using only individual features as input.", "labels": [], "entities": []}, {"text": "Rodd (1997) also uses recurrent neural networks to model Turkish vowel harmony.", "labels": [], "entities": [{"text": "Turkish vowel harmony", "start_pos": 57, "end_pos": 78, "type": "TASK", "confidence": 0.6641876101493835}]}, {"text": "Individual phonemes rather than features were used as input to the networks, and the task was to predict the following phoneme.", "labels": [], "entities": []}, {"text": "Rodd showed that the hidden units in small recurrent networks were able to represent distinctions between vowels and consonants, differences in sonority, and differences between front and back vowels.", "labels": [], "entities": []}, {"text": "Although humans most likely do not perform the task of predicting the next phoneme in a word, Rodd showed that simple recurrent network could learn phonological regularities through differences in the distribution of phonemes.", "labels": [], "entities": [{"text": "predicting the next phoneme in a word", "start_pos": 55, "end_pos": 92, "type": "TASK", "confidence": 0.855709399495806}]}, {"text": "Recurrent neural networks are capable of learning more than just vowel harmony patterns and feature representations, though.", "labels": [], "entities": []}, {"text": "This paper describes a simple recurrent neural network model of phonological pattern learning that is biased towards learning single-feature patterns and patterns over only consonants or vowels without using alpha features, separate representations of consonants and vowels, or conjunctive constraints.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Number of epochs to learn patterns with  full training set.", "labels": [], "entities": []}, {"text": " Table 3: Training time comparisons for pairs of  patterns and p-values.", "labels": [], "entities": []}, {"text": " Table 4: Number of epochs to learn patterns with  partial training set.", "labels": [], "entities": []}]}