{"title": [{"text": "Context-Sensitive Recognition for Emerging and Rare Entities", "labels": [], "entities": [{"text": "Context-Sensitive Recognition", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7800473570823669}]}], "abstractContent": [{"text": "We present a novel named entity recognition (NER) system, and its participation in the Emerging and Rare Entity Recognition shared task, hosted at the 2017 EMNLP Workshop on Noisy User Generated Text (W-NUT).", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 19, "end_pos": 49, "type": "TASK", "confidence": 0.8210434317588806}, {"text": "Emerging and Rare Entity Recognition shared task", "start_pos": 87, "end_pos": 135, "type": "TASK", "confidence": 0.6224508200372968}, {"text": "EMNLP Workshop on Noisy User Generated Text (W-NUT)", "start_pos": 156, "end_pos": 207, "type": "TASK", "confidence": 0.5752400577068328}]}, {"text": "With a specialized evaluation highlighting performance on rare, and sparsely-occurring named entities , this task provided an excellent opportunity to build out a newly-developed statistical algorithm and benchmark it against the state-of-the-art.", "labels": [], "entities": []}, {"text": "Powered by flexible context features of word forms, our system's capacity for identifying never-before-seen entities made it well suited for the task.", "labels": [], "entities": []}, {"text": "Since the system was only developed to recognize a limited number of named entity types, its performance was lower overall.", "labels": [], "entities": []}, {"text": "However, performance was competitive on the categories trained, indicating potential for future development.", "labels": [], "entities": []}], "introductionContent": [{"text": "NER is a common foundational step for many pipelines that rely on natural language processing (NLP).", "labels": [], "entities": []}, {"text": "The main goal is the identification of mentions of entities (e.g., persons or locations).", "labels": [], "entities": [{"text": "identification of mentions of entities (e.g., persons or locations)", "start_pos": 21, "end_pos": 88, "type": "TASK", "confidence": 0.8072788119316101}]}, {"text": "As a pre-processing task for unstructured text, NER may, for example, provide index keywords for information retrieval systems, or topic-rich features for machine learning (ML) applications (.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 97, "end_pos": 118, "type": "TASK", "confidence": 0.7318455576896667}]}, {"text": "Effective approaches to NER have long utilized conditional random fields (), support vector machines, and perceptrons.", "labels": [], "entities": [{"text": "NER", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.976986825466156}]}, {"text": "In addition to relying on face-value, goldstandard data, systems may benefit from a variety of other data representations and sources, including gazetteers, word classes (e.g, Brown clusters), orthographic features, and grammatical relations between types of words, such as part of speech.", "labels": [], "entities": []}, {"text": "Large-scale annotated resources for NER have also been developed in semi-supervised fashions, constructed from online encyclopedias) and refined by crowdsourcing (.", "labels": [], "entities": []}, {"text": "While NER systems have been in development for sometime, their applicability to noisy-text domains (i.e., unedited, user-generated content) is somewhat limited.", "labels": [], "entities": []}, {"text": "This is a multi-faceted problem (, involving grammatical inconsistency and rapidly-shifting domains, requiring specialized algorithms.", "labels": [], "entities": []}, {"text": "While progress has been made through annotation and specialized systems development (, there are still large gains to be made for this domain (, which is highlighted well by both the shared task at the W-NUT this year (, and that of the previous year.", "labels": [], "entities": []}, {"text": "Adaptation to the task domain's wide-range of writing styles and abundant grammatical inconsistencies presents the need for algorithmic flexibility.", "labels": [], "entities": []}, {"text": "These properties make precision loss an issue, and the presence of rare and emerging entities makes recall an extreme challenge, too.", "labels": [], "entities": [{"text": "precision", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9937259554862976}, {"text": "recall", "start_pos": 100, "end_pos": 106, "type": "METRIC", "confidence": 0.9754961133003235}]}, {"text": "Our participation in the present shared task relies on a novel approach: utilizing flexible \"contexts\" as features -derived from token forms -alone.", "labels": [], "entities": []}, {"text": "We rely upon these features for their capacity to relate to never-before-seen tokens as potential entities, and incorporate them into a statistical model that can handle both gold-standard data and large, lexical resources.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Description of shared-task data. Each of the Training, Development, and Test data are broken down by types", "labels": [], "entities": []}, {"text": " Table 2: Shared-task results. All precision, recall, and F1 values are computed with respect to unique entity forms, in", "labels": [], "entities": [{"text": "precision", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.9993537068367004}, {"text": "recall", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.994696855545044}, {"text": "F1", "start_pos": 58, "end_pos": 60, "type": "METRIC", "confidence": 0.9993808269500732}]}]}