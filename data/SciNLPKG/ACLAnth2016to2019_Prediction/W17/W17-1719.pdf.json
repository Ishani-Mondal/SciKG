{"title": [], "abstractContent": [{"text": "We are developing a broad-coverage deep semantic lexicon fora system that parses sentences into a logical form expressed in a rich ontology that supports reasoning.", "labels": [], "entities": []}, {"text": "In this paper we look at verb-particle constructions (VPCs), and the extent to which they can be treated compositionally vs idiomatically.", "labels": [], "entities": [{"text": "verb-particle constructions (VPCs)", "start_pos": 25, "end_pos": 59, "type": "TASK", "confidence": 0.740522038936615}]}, {"text": "First we distinguish between the different types of VPCs based on their compositionality and then present a set of heuristics for classifying specific instances as compositional or not.", "labels": [], "entities": []}, {"text": "We then identify a small set of general sense classes for particles when used compositionally and discuss the resulting lexical representations that are being added to the lexicon.", "labels": [], "entities": []}, {"text": "By treating VPCs as compositional whenever possible, we attain broad coverage in a compact way, and also enable interpretations of novel VPC usages not explicitly present in the lexicon.", "labels": [], "entities": []}], "introductionContent": [{"text": "Toward the goal of Natural Language Understanding of full interpretation of a text fragment (or a sentence), we want to produce a good semantic representation of the sentence.", "labels": [], "entities": [{"text": "Natural Language Understanding", "start_pos": 19, "end_pos": 49, "type": "TASK", "confidence": 0.6464464763800303}, {"text": "full interpretation of a text fragment", "start_pos": 53, "end_pos": 91, "type": "TASK", "confidence": 0.7792581021785736}]}, {"text": "This involves combining rich grammatical information with information about specific lexical items in the sentence, such as word senses, among other things.", "labels": [], "entities": []}, {"text": "Since multiword expressions (MWEs) constitute a significant proportion of the lexicon in any natural language, in fact, Jackendoff (1997) estimated the number of MWEs in a speaker's lexicon to be of the same order of magnitude as the number of single words, it is important to get a good interpretation of MWEs.", "labels": [], "entities": []}, {"text": "For this paper, we focus on a specific type of MWEs, namely verb-particle constructions.", "labels": [], "entities": []}, {"text": "These consist of a verb and an adverbial or prepositional particle, e.g., eat up, fade out, goon, showoff and walk down.", "labels": [], "entities": []}, {"text": "1 Adding every single occurrence of such verb particle combinations in a lexicon is possible but not ideal as, for example, some VPCs maybe interpretable compositionally, i.e., the verb and the particle contribute their simplex meanings, e.g. fly up.", "labels": [], "entities": []}, {"text": "Other compositional VPCs include cases such as finish up and made away for which either the verb or the particle, respectively, seems to contribute its simplex meaning ( . However, other VPCs indeed are noncompositional and require special interpretation, and hence need to be added into the lexicon, e.g., bake off 'contest' and egg on 'urge someone for an action that might not be a good idea'.", "labels": [], "entities": []}, {"text": "For an interpretation of the compositional types above, we need to determine the best senses for the verb and the particle in the VPCs.", "labels": [], "entities": []}, {"text": "There are many lexical resources for an inventory of senses for verbs, such as WordNet,) and VerbNet).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 79, "end_pos": 86, "type": "DATASET", "confidence": 0.9295492172241211}]}, {"text": "But there is not much for the particles except fora few attempts at the semantics fora few particles, such as up () and out.", "labels": [], "entities": []}, {"text": "Our investigation of hundreds of VPCs has shown that the semantics of particles is also important, as can also be gathered from others' proposals for similar classifications of VPCs as mentioned above involving VPC types where particles contribute to the meaning, see Section 3 for details.", "labels": [], "entities": []}, {"text": "Particles are not just the vacuous entities structurally required by the verbs in VPCs, they also have their own semantics which is found to be general across verbs Note we focus on the particle usage in this paper, not on the prepositional usage, i.e., a verb followed by a particle not a prepositional phrase.", "labels": [], "entities": []}, {"text": "However, there maybe an overlap in lexical semantic content (i.e., senses) of the homophonous particles and prepositions, see Section 4.1.", "labels": [], "entities": []}, {"text": "However, refer to Section 3 for our take on such cases.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted an evaluation of the heuristics 3-8 which is described as follows.", "labels": [], "entities": []}, {"text": "From among all the VPCs for which WordNet has an entry, we automatically extracted 25 random VPCs such that each of the 12 particles (that we investigated, see Section 4) was represented in the extracted VPCs.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 34, "end_pos": 41, "type": "DATASET", "confidence": 0.969594419002533}]}, {"text": "These test VPCs were manually annotated by three annotators for the compositionality labels, Compositional and Noncompositional.", "labels": [], "entities": []}, {"text": "Since a VPC may have both compositional and noncompositional usages in different contexts, we restricted assignment of the annotation label fora specific VPC to only one label by considering the first synset/definition each of the VPCs had in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 243, "end_pos": 250, "type": "DATASET", "confidence": 0.9493756294250488}]}, {"text": "In case of disagreement among the three annotations, the annotators discussed reasons for their decisions and arrived at a consensus to create the Gold annotations for the VPCs.", "labels": [], "entities": []}, {"text": "One of the VPCs was dropped from the test set as the annotators could not reconcile with respect to the VPC.", "labels": [], "entities": [{"text": "VPCs", "start_pos": 11, "end_pos": 15, "type": "DATASET", "confidence": 0.8367964029312134}, {"text": "VPC", "start_pos": 104, "end_pos": 107, "type": "DATASET", "confidence": 0.8567972779273987}]}, {"text": "A python implementation of the heuristics was applied to the remaining 24 test VPCs.", "labels": [], "entities": []}, {"text": "Like the manual annotations mentioned above, for the heuristics also, only those annotations were considered which were based on the first synset/definition of the VPC in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 171, "end_pos": 178, "type": "DATASET", "confidence": 0.7712663412094116}]}, {"text": "The VPCs that heuristics 3-7 identified as representative of their category were annotated as Compositional, whereas the VPCs identified by heuristic 8 were annotated as Noncompositional.", "labels": [], "entities": []}, {"text": "These annotations were tested against the Gold annotations for the VPCs.", "labels": [], "entities": [{"text": "VPCs", "start_pos": 67, "end_pos": 71, "type": "DATASET", "confidence": 0.6370145082473755}]}, {"text": "As mentioned earlier, our heuristics do not coverall the VPCs.", "labels": [], "entities": [{"text": "VPCs", "start_pos": 57, "end_pos": 61, "type": "DATASET", "confidence": 0.886167049407959}]}, {"text": "Out of the 24 VPCs, the heuristics did not assign a label to four VPCs.", "labels": [], "entities": []}, {"text": "Also additional two VPCs had to be disregarded due to assignment of labels to them based on synsets/definitions other than the first synset/definition in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 154, "end_pos": 161, "type": "DATASET", "confidence": 0.962417721748352}]}, {"text": "For the remaining 18 VPCs, the heuristics achieved an overall accuracy of 72%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9996223449707031}]}, {"text": "For compositional cases specifically, the heuristics got 82% correct labels, and for the noncompositional cases, the heuristics achieved an accuracy of 57%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 140, "end_pos": 148, "type": "METRIC", "confidence": 0.9993664622306824}]}, {"text": "One of the cases that the heuristics misidentified, namely flyby, was merely due to the current implementation of the heuristic not involving inflectional variations of the verb.", "labels": [], "entities": []}, {"text": "Note WordNet definition includes the verb fly but in its inflected form flying.", "labels": [], "entities": [{"text": "WordNet definition", "start_pos": 5, "end_pos": 23, "type": "DATASET", "confidence": 0.950078547000885}]}, {"text": "The heuristic 5 could capture it if the implementation is refined to cover inflected forms of verbs.", "labels": [], "entities": []}, {"text": "Finally, note heuristics 1 and 2 could not be evaluated using the same procedure by extracting VPCs from WordNet randomly since heuristics 1 and 2 identify VPCs that are not included in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 186, "end_pos": 193, "type": "DATASET", "confidence": 0.9592998623847961}]}], "tableCaptions": []}