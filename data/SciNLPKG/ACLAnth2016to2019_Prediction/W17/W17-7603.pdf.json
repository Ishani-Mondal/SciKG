{"title": [{"text": "Distributional regularities of verbs and verbal adjectives: Treebank evidence and broader implications", "labels": [], "entities": [{"text": "Distributional regularities of verbs and verbal adjectives", "start_pos": 0, "end_pos": 58, "type": "TASK", "confidence": 0.7947497708456857}]}], "abstractContent": [{"text": "Word formation processes such as derivation and compounding yield realizations of lexical roots in different parts of speech and in different syntactic environments.", "labels": [], "entities": [{"text": "Word formation", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.697075292468071}]}, {"text": "Using verbal adjectives as a case study and treebanks of Dutch and German as data sources, similarities and divergences in syntactic distributions across different realizations of lexical roots are examined and the implications for computational modeling and for treebank construction are discussed.", "labels": [], "entities": [{"text": "treebank construction", "start_pos": 263, "end_pos": 284, "type": "TASK", "confidence": 0.80480095744133}]}], "introductionContent": [{"text": "Due to processes of word formation such as derivation and compounding, lexical roots can be realized in different parts of speech and in different syntactic environments.", "labels": [], "entities": [{"text": "word formation", "start_pos": 20, "end_pos": 34, "type": "TASK", "confidence": 0.7229943424463272}]}, {"text": "For example, the derivational suffix -able can turn the verbal root derive in English into the adjective derivable, and the derivational suffix -ity can turn derivable into the noun derivability.", "labels": [], "entities": []}, {"text": "A direct corollary of this polycategorial property of lexical roots and their morphological derivatives is their participation in different syntactic constructions and contexts, each of which comes with their construction-specific frequency distributions of collocations, syntactic arguments, modifiers, and specifiers.", "labels": [], "entities": []}, {"text": "In structuralist theories of language, the characterization of linguistic categories and structures in terms of their distributional behavior provides the key insight underlying distributional accounts of phonology, morphology, and syntax, most famously articulated by and of semantics, as proposed by.", "labels": [], "entities": []}, {"text": "The correct modeling of the interface of derivational morphology and syntactic derivations was also one of the central issues in the early days of generative grammar, with proponents of Generative Semantics arguing fora transformational, syntactic account of word formation and Chomsky arguing fora non-transformational, interpretative account.", "labels": [], "entities": [{"text": "generative grammar", "start_pos": 147, "end_pos": 165, "type": "TASK", "confidence": 0.9714527130126953}, {"text": "word formation", "start_pos": 259, "end_pos": 273, "type": "TASK", "confidence": 0.710119292140007}]}, {"text": "In non-derivational, lexicalist theories of grammar such as Head-Driven Phrase Structure Grammar, the sharing of argument structure for lexical roots realized in different word classes is modeled by the non-transformational mechanism of lexical rules and sharing of valence information (see for such an account for nominalizations in German).", "labels": [], "entities": [{"text": "Head-Driven Phrase Structure Grammar", "start_pos": 60, "end_pos": 96, "type": "TASK", "confidence": 0.641764834523201}]}, {"text": "Most recently, distributional theories of natural language have also served as an inspiration for distributional modeling of words as word embeddings in computational linguistics ().", "labels": [], "entities": []}, {"text": "Linguistically annotated corpora, so-called treebanks, offer excellent empirical resources for the study of the realization of lexical roots in different morpho-syntactic categories and constructions, provided that their annotations are rich enough to capture relevant information about derivational morphology and lemmatization.", "labels": [], "entities": []}], "datasetContent": [{"text": "The goal of our experiments is to test our thesis that there are distributional regularities between verbal adjectives and their corresponding verbs.", "labels": [], "entities": []}, {"text": "As motivated in Section 2, we will look at co-occurrences with prepositions in particular.", "labels": [], "entities": []}, {"text": "In our experiments, we will use relative entropy to determine how much a distribution Q diverges from a reference distribution P (Equation 1).", "labels": [], "entities": []}, {"text": "The relative entropy estimates the expected number of additional bits that is required when a sample of P is encoded using a code optimized for Q rather than P . The divergence is zero when the two distributions are identical.", "labels": [], "entities": [{"text": "divergence", "start_pos": 166, "end_pos": 176, "type": "METRIC", "confidence": 0.9617577791213989}]}, {"text": "For each subset (Section 4) of our dataset, we estimate a probability distribution P * (p|v) using maximum likelihood estimation, where p is the preposition, v the verb lemma, and count(v, p) the number of times v governs p with a prepositional phrase or prepositional complement relation in the data set (Equation 2).", "labels": [], "entities": [{"text": "count", "start_pos": 180, "end_pos": 185, "type": "METRIC", "confidence": 0.9762187600135803}]}, {"text": "3 The relative entropy fora conditional distribution is the (possibly weighted) average of relative entropies of verbs (Equation 3).", "labels": [], "entities": []}, {"text": "However, the average relative entropy obscures the differences in relative entropy between frequent and infrequent lemmas.", "labels": [], "entities": []}, {"text": "Instead, we sort verbal lemmas by their frequency in the set from which P derives.", "labels": [], "entities": []}, {"text": "We then plot the moving average of maximally 500 lemmas in frequency order.", "labels": [], "entities": []}, {"text": "The resulting graph shows the change in relative entropy as the lemmas become more rare.", "labels": [], "entities": []}, {"text": "We perform four experiments in total, computing the divergences in.", "labels": [], "entities": []}, {"text": "In each experiment, the verbal adjective set is used as the reference distribution P . This is motivated by the fact that verbal adjectives have fewer PP attachment ambiguities and thus serve as a better reference distribution.", "labels": [], "entities": []}, {"text": "Furthermore, since verbs are often far more frequent than verbal adjectives, one would typically want to predict the co-occurrences of a verbal adjective.", "labels": [], "entities": []}], "tableCaptions": []}