{"title": [{"text": "A statistical model for morphology inspired by the Amis language", "labels": [], "entities": []}], "abstractContent": [{"text": "We introduce a statistical model for the morphology of natural languages.", "labels": [], "entities": []}, {"text": "As words contain a root and potentially a prefix and a suffix, we associate three vector components, one for the root, one for the prefix, and one for the suffix.", "labels": [], "entities": []}, {"text": "As the morphology captures important semantic notions and syntactic instructions, anew Content vector c can be associated with the sentences.", "labels": [], "entities": []}, {"text": "It can be computed online and used to find the most likely derivation tree in a grammar.", "labels": [], "entities": []}, {"text": "The model was inspired by the analysis of Amis, an Austronesian language with a rich morphology.", "labels": [], "entities": []}], "introductionContent": [{"text": "The representation of words as vectors of small dimension, introduced by the Word2vec system, is based on the correlation of occurrences of two words in the same sentence, or the second moment of the distribution of words . It is classically applied to predict a missing word in a sentence or to detect an odd word in a list of words.", "labels": [], "entities": [{"text": "Word2vec system", "start_pos": 77, "end_pos": 92, "type": "DATASET", "confidence": 0.9451917409896851}]}, {"text": "Computational linguists also studied how to extend the vector representation of the words to a vector representation of the sentences, capturing some key semantic parameters such as Tense, Voice, Mood, Illocutionary force and Information structure.", "labels": [], "entities": []}, {"text": "Words have an internal structure, also called morphology.", "labels": [], "entities": []}, {"text": "The word preexisting, for example, has a prefix pre-, a root exist and a suffix -ing.", "labels": [], "entities": []}, {"text": "In this case, we write pre-exist-ing to distinguish these three components.", "labels": [], "entities": []}, {"text": "Given some texts, we can then analyse the most frequent prefixes, the distribution of prefix occurrences, the distribution of suffixes given a root, and soon.", "labels": [], "entities": []}, {"text": "We call these statistical distributions the Morphology Statistics of the language.", "labels": [], "entities": []}, {"text": "In this paper, we consider the second moment of the Morphology Statistics and can determine which prefix is the most likely in a missing word of a sentence, which suffix is unlikely given a prefix and a sentence, and many other predictions.", "labels": [], "entities": [{"text": "Morphology Statistics", "start_pos": 52, "end_pos": 73, "type": "DATASET", "confidence": 0.7143786400556564}]}, {"text": "We argue that these informations are very useful to associate a vector representation to sentences and therefore to capture some key semantic and syntactic parameters.", "labels": [], "entities": []}, {"text": "As an example, we selected Amis, a natural language with profuse morphology which is well suited for this analysis.", "labels": [], "entities": []}, {"text": "Amis is one of the twenty-four Austronesian languages originally spoken in Taiwan, only fifteen of which are still spoken nowadays.", "labels": [], "entities": []}, {"text": "This approach can be applied to any other language.", "labels": [], "entities": []}, {"text": "Amis belongs to the putative Eastern Formosan subgroup of the great Austronesian family Blust (1999);;.", "labels": [], "entities": [{"text": "Austronesian family Blust (1999)", "start_pos": 68, "end_pos": 100, "type": "DATASET", "confidence": 0.8066301544507345}]}, {"text": "Amis is spoken along the eastern coast of Taiwan and has four main dialects which display significant differences in their phonology, lexicon and morphosyntactic properties.", "labels": [], "entities": []}, {"text": "The analysis bears on Northern Amis; the data were collected during fieldwork.", "labels": [], "entities": [{"text": "Northern Amis", "start_pos": 22, "end_pos": 35, "type": "DATASET", "confidence": 0.8351978957653046}]}, {"text": "A prior study of the northern dialect dealt mostly with verbal classification and the voice system.", "labels": [], "entities": [{"text": "verbal classification", "start_pos": 56, "end_pos": 77, "type": "TASK", "confidence": 0.7534109055995941}]}, {"text": "We built a tool to represent the statistical morphology of Amis, given a set of texts where each word has been decomposed into components.", "labels": [], "entities": []}, {"text": "The tool is similar to the OLAP (Online Analytical Processing) Analysis used for Data Analysis.", "labels": [], "entities": [{"text": "OLAP (Online Analytical Processing) Analysis", "start_pos": 27, "end_pos": 71, "type": "TASK", "confidence": 0.474241384438106}, {"text": "Data Analysis", "start_pos": 81, "end_pos": 94, "type": "TASK", "confidence": 0.7851597964763641}]}, {"text": "\u2022 We can analyse the global distribution of prefixes, roots, suffixes, i.e. the most frequent occurrences.", "labels": [], "entities": []}, {"text": "\u2022 Given a root (or a prefix, or a suffix), we obtain the distribution of the pairs (Prefixes;Suffixes) of that root, and the distribution of the prefixes, or the distribution of the suffixes by projection.", "labels": [], "entities": []}, {"text": "Similarly fora given prefix, or a given suffix.", "labels": [], "entities": []}, {"text": "We then study the second moment of the Morphology Statistics and are able to predict the most likely prefix, root or suffix given a sequence of words.", "labels": [], "entities": [{"text": "Morphology Statistics", "start_pos": 39, "end_pos": 60, "type": "DATASET", "confidence": 0.7129017114639282}]}, {"text": "As some prefixes or suffixes carry some semantic and syntactic information, as it is the casein Amis, we build a Content vector fora sentence, and then predict the parsing of a sentence.", "labels": [], "entities": []}, {"text": "Our results are: \u2022 A statistical representation of prefixes, roots and suffixes, as structured vectors, \u2022 A vector representation fora sentence, the Content vector.", "labels": [], "entities": []}, {"text": "We show its use to predict the most likely derivation tree.", "labels": [], "entities": []}, {"text": "In the next section, we introduce the basic concepts.", "labels": [], "entities": []}, {"text": "In the third section, we present our statistical model to capture the morphology of a natural language and apply it to Amis.", "labels": [], "entities": []}, {"text": "In the fourth section, we describe its use fora syntactic and semantic analysis.", "labels": [], "entities": [{"text": "semantic analysis", "start_pos": 62, "end_pos": 79, "type": "TASK", "confidence": 0.6997837424278259}]}], "datasetContent": [], "tableCaptions": []}