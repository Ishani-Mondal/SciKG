{"title": [{"text": "Automated Preamble Detection in Dictated Medical Reports", "labels": [], "entities": [{"text": "Automated Preamble Detection in Dictated Medical Reports", "start_pos": 0, "end_pos": 56, "type": "TASK", "confidence": 0.7716785456453051}]}], "abstractContent": [{"text": "Dictated medical reports very often feature a preamble containing metainforma-tion about the report such as patient and physician names, location and name of the clinic, date of procedure, and soon.", "labels": [], "entities": []}, {"text": "In the medical transcription process, the preamble is usually omitted from the final report, as it contains information already available in the electronic medical record.", "labels": [], "entities": [{"text": "medical transcription process", "start_pos": 7, "end_pos": 36, "type": "TASK", "confidence": 0.7698396146297455}]}, {"text": "We present a method which is able to automatically identify preambles in medical dictations.", "labels": [], "entities": [{"text": "identify preambles in medical dictations", "start_pos": 51, "end_pos": 91, "type": "TASK", "confidence": 0.6060490131378173}]}, {"text": "The method makes use of state-of-the-art NLP techniques including word embeddings and Bi-LSTMs and achieves preamble detection performance superior to humans.", "labels": [], "entities": [{"text": "preamble detection", "start_pos": 108, "end_pos": 126, "type": "TASK", "confidence": 0.795091301202774}]}], "introductionContent": [{"text": "For decades, medical dictation and transcription has been used as a convenient and cost-effective way to document patient-physician encounters and procedures and bring reports into a form which can be stored in an electronic medical record (EMR) system, formatted as an out-patient letter, etc.", "labels": [], "entities": [{"text": "medical dictation and transcription", "start_pos": 13, "end_pos": 48, "type": "TASK", "confidence": 0.7371824532747269}]}, {"text": "While dictated speech has traditionally been transcribed by humans (such as clinical assistants or professional transcription personnel), sometimes in multiple stages, it is common nowadays for speech recognition technology to be deployed in the first stage to increase transcription speed and cope with the enormous amount of dictated episodes in the clinical context.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 194, "end_pos": 212, "type": "TASK", "confidence": 0.7210513055324554}]}, {"text": "In its purest form, a speech recognizer transforms spoken into written words, as exemplified in.", "labels": [], "entities": []}, {"text": "Obviously, this raw output will have to undergo multiple transformation steps to format it in away it can be stored in an EMR or sent out as a letter to the patient, including: formatting numbers, dates, units, etc.; punctuation restoration (; and processing physician normals.", "labels": [], "entities": [{"text": "formatting numbers", "start_pos": 177, "end_pos": 195, "type": "TASK", "confidence": 0.8986576199531555}, {"text": "punctuation restoration", "start_pos": 217, "end_pos": 240, "type": "TASK", "confidence": 0.7383205890655518}]}, {"text": "Furthermore, dictated reports often contain metadata in a preamble containing information not intended to be copied into the letter, such as patient and physician names, location and name of the clinic, date of procedure, and soon.", "labels": [], "entities": []}, {"text": "Rather, the metadata serves the sole purpose of enabling realigning dictations with a particular record or file, in case this alignment is not otherwise possible (usually, metadata in medical transcription systems is automatically retrieved from the EMR system and inserted into the outpatient letter).", "labels": [], "entities": []}, {"text": "See for the same text sample as with the preamble highlighted and the above postprocessing rules applied.", "labels": [], "entities": []}, {"text": "Ina second stage, medical transcriptionists take the speech recognizer output and perform a postediting exercise and quality check before entering the final report into the EMR or sending it off as an outpatient letter.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 53, "end_pos": 70, "type": "TASK", "confidence": 0.6838068962097168}]}, {"text": "This stage usually involves the removal of metadata, i.e. the preamble, from the dictation's main text body.", "labels": [], "entities": []}, {"text": "To facilitate this procedure, this paper explores techniques to automatically mark preambles.", "labels": [], "entities": []}, {"text": "It is worth noting that the accurate detection of preambles in dictated reports is a non-trivial task, even for humans.", "labels": [], "entities": [{"text": "accurate detection of preambles in dictated reports", "start_pos": 28, "end_pos": 79, "type": "TASK", "confidence": 0.8740142839295524}]}, {"text": "Clinical dictations may (a) contain metadata at multiple places throughout the report (see for an example), (b) or no such data at all, (c) feature sentences convolving metadata and general narrative, or (d) have grammati-    cal inaccuracies and lack overall structure caused by the spontaneous nature of dictated speech, including the total absence of punctuations.", "labels": [], "entities": []}, {"text": "To systematically quantify the task's complexity, we also determined the human baseline performance of detecting the preamble in clinical dictation.", "labels": [], "entities": [{"text": "detecting the preamble in clinical dictation", "start_pos": 103, "end_pos": 147, "type": "TASK", "confidence": 0.7855713069438934}]}, {"text": "This paper is structured as follows: After discussing related work in Section 2, we describe the corpus and determine the human baseline in Section 3.3.", "labels": [], "entities": []}, {"text": "Section 4 provides details on the techniques we used for the automated detection of preambles, followed by evaluation results and discussion in Section 5.", "labels": [], "entities": [{"text": "automated detection of preambles", "start_pos": 61, "end_pos": 93, "type": "TASK", "confidence": 0.7790385186672211}]}, {"text": "We conclude the paper and provide an outlook on future work in Section 6.", "labels": [], "entities": []}, {"text": "This is Dr Mike Miller.", "labels": [], "entities": [{"text": "Dr Mike Miller", "start_pos": 8, "end_pos": 22, "type": "DATASET", "confidence": 0.9184813102086385}]}, {"text": "The patient is a baking associate over at Backwerk.", "labels": [], "entities": [{"text": "Backwerk", "start_pos": 42, "end_pos": 50, "type": "DATASET", "confidence": 0.9939637780189514}]}, {"text": "Today's date is 03/10/2016.", "labels": [], "entities": []}, {"text": "The patient noted he strained his back while he was helping his mother move some household items.: Example of a report intertwining preamble and main body.", "labels": [], "entities": []}, {"text": "Physician name and date of the visit are commonly considered preamble, whereas the patient's profession and employer are not.", "labels": [], "entities": [{"text": "preamble", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9726791977882385}]}, {"text": "When spontaneously dictating, physicians sometimes remember to mention preamble statements only after they have already started the main body narrative, such as the date of visit in this example.", "labels": [], "entities": []}], "datasetContent": [{"text": "As a first sanity check, we measured the preamble tagging accuracy on the token level.", "labels": [], "entities": [{"text": "preamble tagging", "start_pos": 41, "end_pos": 57, "type": "TASK", "confidence": 0.6645492762327194}, {"text": "accuracy", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.9090228080749512}]}, {"text": "In other words, we determined how many of the tokens in the test set were correctly tagged as being either part of the preamble or the main body.", "labels": [], "entities": []}, {"text": "In this task, Algorithm 1 The Heuristic Splitter.", "labels": [], "entities": [{"text": "Heuristic Splitter", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.6247807741165161}]}, {"text": "1: splitP os \u2190 0 // predicted split position.", "labels": [], "entities": []}, {"text": "counter \u2190 0 // sequence counter.", "labels": [], "entities": []}, {"text": "counter--12: if counter > 0 then return length(predictedT ags) 14: else", "labels": [], "entities": [{"text": "predictedT", "start_pos": 47, "end_pos": 57, "type": "METRIC", "confidence": 0.9746983647346497}]}], "tableCaptions": []}