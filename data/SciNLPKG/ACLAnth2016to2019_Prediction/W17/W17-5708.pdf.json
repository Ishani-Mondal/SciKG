{"title": [{"text": "A Bag of Useful Tricks for Practical Neural Machine Translation: Embedding Layer Initialization and Large Batch Size", "labels": [], "entities": [{"text": "Neural Machine Translation", "start_pos": 37, "end_pos": 63, "type": "TASK", "confidence": 0.6722699205080668}, {"text": "Embedding Layer Initialization", "start_pos": 65, "end_pos": 95, "type": "TASK", "confidence": 0.609750896692276}]}], "abstractContent": [{"text": "In this paper, we describe the team UT-IIS's system and results for the WAT 2017 translation tasks.", "labels": [], "entities": [{"text": "UT-IIS", "start_pos": 36, "end_pos": 42, "type": "DATASET", "confidence": 0.8556640148162842}, {"text": "WAT 2017 translation tasks", "start_pos": 72, "end_pos": 98, "type": "TASK", "confidence": 0.8891766369342804}]}, {"text": "We further investigated several tricks including a novel technique for initializing embedding layers using only the parallel corpus, which increased the BLEU score by 1.28, found a practical large batch size of 256, and gained insights regarding hyperparameter settings.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 153, "end_pos": 163, "type": "METRIC", "confidence": 0.9854078888893127}]}, {"text": "Ultimately , our system obtained a better result than the state-of-the-art system of WAT 2016.", "labels": [], "entities": [{"text": "WAT 2016", "start_pos": 85, "end_pos": 93, "type": "TASK", "confidence": 0.5744733214378357}]}, {"text": "Our code is available on https: //github.com/nem6ishi/wat17.", "labels": [], "entities": []}], "introductionContent": [{"text": "The advent of neural networks in machine translation has contributed greatly to the translation quality.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.7417547106742859}, {"text": "translation", "start_pos": 84, "end_pos": 95, "type": "TASK", "confidence": 0.9724518656730652}]}, {"text": "Since proposed in (, the sequence-to-sequence (SEQ2SEQ) model has been achieving the stateof-the-art performance when combined with the attention mechanism ().", "labels": [], "entities": []}, {"text": "Many studies have focused on modifying the SEQ2SEQ network structure, including modifying the encoder (), or the decoder (.", "labels": [], "entities": []}, {"text": "While these network structure modifications have been found to improve the translation quality, many systems, including the best system from WAT 2016 (, still depend on the vanilla SEQ2SEQ model, the model with the attention mechanism.", "labels": [], "entities": [{"text": "translation", "start_pos": 75, "end_pos": 86, "type": "TASK", "confidence": 0.9565147161483765}]}, {"text": "confirmed the large impact of common techniques such as training algorithms, subwords () and model ensem- * Authors contributed equally.", "labels": [], "entities": []}, {"text": "bles upon this vanilla SEQ2SEQ model.", "labels": [], "entities": []}, {"text": "This suggests that there maybe some unexplored tricks we may apply to the vanilla model to significantly improve the translation quality.", "labels": [], "entities": []}, {"text": "This paper describes the system that we have built for the ASPEC ( ) enja translation subtask for WAT, which incorporates a novel trick, embedding layer initialization.", "labels": [], "entities": [{"text": "ASPEC ( ) enja translation subtask", "start_pos": 59, "end_pos": 93, "type": "TASK", "confidence": 0.6235257635513941}, {"text": "WAT", "start_pos": 98, "end_pos": 101, "type": "TASK", "confidence": 0.8575279116630554}]}, {"text": "This trick improves upon the vanilla SEQ2SEQ model by initializing the word embedding layers of both the encoder and the decoder with word embeddings that are pretrained on the parallel corpus.", "labels": [], "entities": []}, {"text": "Our system involves generating multiple models using SEQ2SEQ with embedding layer initialization, exhaustively searching fora combination of models with the highest ensemble score, and finally, conducting abeam search on the best ensemble.", "labels": [], "entities": []}, {"text": "We achieved a BLEU score of 38.93 on the ASPEC en-ja translation task as the team UT-IIS, which outperforms the state-of-the-art system of WAT 2016.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 14, "end_pos": 24, "type": "METRIC", "confidence": 0.9826423823833466}, {"text": "ASPEC en-ja translation task", "start_pos": 41, "end_pos": 69, "type": "TASK", "confidence": 0.6883900314569473}, {"text": "UT-IIS", "start_pos": 82, "end_pos": 88, "type": "DATASET", "confidence": 0.932881236076355}]}, {"text": "Furthermore, we have provided insight on NMT by detailing experiments on the tricks used in our system.", "labels": [], "entities": [{"text": "NMT", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.8980452418327332}]}, {"text": "This includes testing embedding layer initialization with multiple word embedding methods ( \u00a7 5.3.1), a thorough investigation of the point where increasing the batch size ceases to be beneficial ( \u00a7 5.3.2), finding the optimal learning rate ( \u00a7 5.3.3), and investigating the relation between the number of models used in the ensemble and translation performance ( \u00a7 5.3.4).", "labels": [], "entities": [{"text": "embedding layer initialization", "start_pos": 22, "end_pos": 52, "type": "TASK", "confidence": 0.6607816219329834}]}, {"text": "We believe that these findings, particularly regarding embedding layer initialization and practical batch size, can serve as useful tricks for future neural machine translation (NMT) systems.", "labels": [], "entities": [{"text": "embedding layer initialization", "start_pos": 55, "end_pos": 85, "type": "TASK", "confidence": 0.7217725316683451}, {"text": "neural machine translation (NMT)", "start_pos": 150, "end_pos": 182, "type": "TASK", "confidence": 0.832457443078359}]}, {"text": "The structure of this paper is as follows.", "labels": [], "entities": []}, {"text": "In \u00a7 2, we review related work, and in \u00a7 3, we present an overview of NMT.", "labels": [], "entities": []}, {"text": "We describe our system in \u00a7 4 and show the official evaluation result and further investigations in \u00a7 5.", "labels": [], "entities": []}, {"text": "We conclude our work in \u00a7 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we report the default configuration of our system ( \u00a7 5.1) and the official evaluation result of our system for ASPEC English to Japanese translation subtask ( \u00a7 5.2).", "labels": [], "entities": [{"text": "ASPEC English to Japanese translation subtask", "start_pos": 129, "end_pos": 174, "type": "TASK", "confidence": 0.8461908002694448}]}, {"text": "Furthermore, we report several other experiments that aim to show the effects of our tricks ( \u00a7 5.3).", "labels": [], "entities": []}, {"text": "This section briefly explains how we built our final system and its result for the ASPEC English to Japanese translation subtask.", "labels": [], "entities": [{"text": "ASPEC English to Japanese translation subtask", "start_pos": 83, "end_pos": 128, "type": "TASK", "confidence": 0.836469809214274}]}, {"text": "We trained ten models with different hyperparameters which are listed in.", "labels": [], "entities": []}, {"text": "For these models, we evaluated every possible ensemble combination using greedy search on the development corpus.", "labels": [], "entities": []}, {"text": "We chose the ensemble combination with the highest BLEU score to make prediction on the test corpus using abeam search algorithm.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 51, "end_pos": 61, "type": "METRIC", "confidence": 0.9749703705310822}]}, {"text": "Consequently, we chose an ensemble of eight models, which achieved a BLEU score of 38.93 and an official human evaluation score of 68.000.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 69, "end_pos": 79, "type": "METRIC", "confidence": 0.9857999682426453}]}], "tableCaptions": [{"text": " Table 1: Details of corpus after preprocessing.", "labels": [], "entities": []}, {"text": " Table 2: List of models trained for use in ensemble  (* 200k steps unattained due to time constraints).", "labels": [], "entities": []}, {"text": " Table 3: Translation performance by embedding  methods and window size. Evaluation is done on  development dataset.", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9853037595748901}]}, {"text": " Table 4: Configuration of seq2seq model.", "labels": [], "entities": []}]}