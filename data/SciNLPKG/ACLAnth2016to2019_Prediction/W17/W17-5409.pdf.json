{"title": [{"text": "Strawman: an Ensemble of Deep Bag-of-Ngrams for Sentiment Analysis", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.8704321980476379}]}], "abstractContent": [{"text": "This paper describes a builder entry, named \"strawman\", to the sentence-level sentiment analysis task of the \"Build It, Break It\" shared task of the First Workshop on Building Linguistically General-izable NLP Systems.", "labels": [], "entities": [{"text": "sentence-level sentiment analysis task", "start_pos": 63, "end_pos": 101, "type": "TASK", "confidence": 0.7125739753246307}, {"text": "Build It, Break It\" shared task of the First Workshop on Building Linguistically General-izable NLP Systems", "start_pos": 110, "end_pos": 217, "type": "TASK", "confidence": 0.5073382291528914}]}, {"text": "The goal of a builder is to provide an automated sentiment an-alyzer that would serve as a target for breakers whose goal is to find pairs of minimally-differing sentences that break the analyzer.", "labels": [], "entities": []}, {"text": "1 Data and Preprocessing Data The organizers of the shared task provided two distinct types of training sets.", "labels": [], "entities": []}, {"text": "The first set consists of usual sentences paired with their corresponding sentiment labels (+1 for positive and-1 for negative) and confidences (a real value between 0 and 1.)", "labels": [], "entities": []}, {"text": "The other set consists of phrases paired similarly with sentiment labels and confidences.", "labels": [], "entities": []}, {"text": "In the latter case, the sentiment label maybe either-1, 1 or 0 which indicates neutral.", "labels": [], "entities": []}, {"text": "There are 6920 sentences and 166,737 phrases.", "labels": [], "entities": []}, {"text": "As the goal of \"strawman\" is to build the most naive and straightforward baseline for the shared task, I have decided to use all the examples from both of the training sets whose sentiment labels were either-1 or 1.", "labels": [], "entities": []}, {"text": "In other words, any phrase labelled neutral was discarded.", "labels": [], "entities": []}, {"text": "The confidence scores were discarded as well.", "labels": [], "entities": [{"text": "confidence", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9600560665130615}]}, {"text": "The combined data was shuffled first, and then the first 160k examples were used for training and the last 10k examples for validation.", "labels": [], "entities": [{"text": "validation", "start_pos": 124, "end_pos": 134, "type": "TASK", "confidence": 0.9618528485298157}]}, {"text": "I have decided to ignore 3,657 examples in-between.", "labels": [], "entities": []}, {"text": "Vocabulary The training dataset was lower-cased in order to avoid an issue of data sparsity, as the size of the dataset is relatively small.", "labels": [], "entities": []}, {"text": "Since the provided training examples were already tok-enized to a certain degree, I have not attempted any further tokenization, other than removing a quotation mark \"\"\".", "labels": [], "entities": []}, {"text": "In the case of blind development and test sets, I used spaCy 1 for automatic tokenization.", "labels": [], "entities": []}, {"text": "At this stage, a vocabulary was built using all the n-gram's with n up to 2 from the entire training set.", "labels": [], "entities": []}, {"text": "This resulted in a vocabulary of 102,608 unique n-gram's, and among them, I decided to use only the 100k most frequent n-grams.", "labels": [], "entities": []}, {"text": "2 Model and Training The \"strawman\" is an ensemble of five deep bag-of-ngrams classifiers.", "labels": [], "entities": []}, {"text": "Each classifier is a multi-layer perceptron consisting of an embedding layer which transforms one-hot vector representations of words into continuous vectors, averaging pooling , a 32-dim tanh hidden layer and a binary soft-max layer.", "labels": [], "entities": []}, {"text": "The classifier is trained to minimize cross-entropy loss using Adam (Kingma and Ba, 2014) with the default parameters.", "labels": [], "entities": []}, {"text": "Each training run was early-stopped based on the validation accuracy and took approximately 10-20 minutes on the author's laptop which has a 2.2 GHz In-tel Core i7 (8 cores) and does not have any GPU compute capability.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.6508590579032898}]}, {"text": "The output distributions of all the five classifiers, which were initialized using distinct random seeds, were averaged to form an ensemble.", "labels": [], "entities": []}, {"text": "The entire code was written in Python using PyTorch.", "labels": [], "entities": [{"text": "PyTorch", "start_pos": 44, "end_pos": 51, "type": "DATASET", "confidence": 0.9225722551345825}]}, {"text": "2 The implementation is publicly available at https://github.com/ kyunghyuncho/strawman.", "labels": [], "entities": []}, {"text": "3 Result and Thoughts Despite its simplicity and computational efficiency , the \"strawman\" fared reasonably well.", "labels": [], "entities": []}, {"text": "The \"strawman\" was ranked first in terms of the aver-1 https://spacy.io/ 2 http://pytorch.org/ 59", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}