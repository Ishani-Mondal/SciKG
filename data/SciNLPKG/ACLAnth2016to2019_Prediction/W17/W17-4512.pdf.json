{"title": [{"text": "Reader-Aware Multi-Document Summarization: An Enhanced Model and The First Dataset *", "labels": [], "entities": [{"text": "Reader-Aware Multi-Document Summarization", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.6657879451910654}]}], "abstractContent": [{"text": "We investigate the problem of reader-aware multi-document summarization (RA-MDS) and introduce anew dataset for this problem.", "labels": [], "entities": [{"text": "reader-aware multi-document summarization (RA-MDS)", "start_pos": 30, "end_pos": 80, "type": "TASK", "confidence": 0.6050430784622828}]}, {"text": "To tackle RA-MDS, we extend a variational auto-encodes (VAEs) based MDS framework by jointly considering news documents and reader comments.", "labels": [], "entities": []}, {"text": "To conduct evaluation for summarization performance, we prepare anew dataset.", "labels": [], "entities": [{"text": "summarization", "start_pos": 26, "end_pos": 39, "type": "TASK", "confidence": 0.9885050654411316}]}, {"text": "We describe the methods for data collection, aspect annotation, and summary writing as well as scrutinizing by experts.", "labels": [], "entities": [{"text": "data collection", "start_pos": 28, "end_pos": 43, "type": "TASK", "confidence": 0.7254680395126343}, {"text": "aspect annotation", "start_pos": 45, "end_pos": 62, "type": "TASK", "confidence": 0.8130908906459808}, {"text": "summary writing", "start_pos": 68, "end_pos": 83, "type": "TASK", "confidence": 0.7452346086502075}]}, {"text": "Experimental results show that reader comments can improve the summarization performance, which also demonstrates the usefulness of the proposed dataset.", "labels": [], "entities": [{"text": "summarization", "start_pos": 63, "end_pos": 76, "type": "TASK", "confidence": 0.9743404984474182}]}, {"text": "The annotated dataset for RA-MDS is available online 1 .", "labels": [], "entities": []}], "introductionContent": [{"text": "The goal of multi-document summarization (MDS) is to automatically generate a brief, wellorganized summary fora topic which describes an event with a set of documents from different sources.", "labels": [], "entities": [{"text": "multi-document summarization (MDS)", "start_pos": 12, "end_pos": 46, "type": "TASK", "confidence": 0.8398209810256958}]}, {"text": "In the typical setting of MDS, the input is a set of news documents about the same topic.", "labels": [], "entities": [{"text": "MDS", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.944340705871582}]}, {"text": "The output summary is apiece of short text document containing several sentences, generated only based on the input original documents.", "labels": [], "entities": []}, {"text": "With the development of social media and mobile equipments, more and more user generated * The work described in this paper is supported by a grant from the Grant Council of the Hong Kong Special Administrative Region, China (Project Code: 14203414).", "labels": [], "entities": []}, {"text": "1 http://www.se.cuhk.edu.hk/ \u02dc textmine/ dataset/ra-mds/ NEWS: The most important announcements from Google's big developers' conference content is available. is a snapshot of reader comments under the news report \"The most important announcements from Google's big developers' conference\" 2 . The content of the original news report talks about some new products based on AI techniques.", "labels": [], "entities": []}, {"text": "The news report generally conveys an enthusiastic tone.", "labels": [], "entities": []}, {"text": "However, while some readers share similar enthusiasms, some others express their worries about new products and technologies and these comments can also reflect their interests which may not be very salient in the original news reports.", "labels": [], "entities": []}, {"text": "Unfortunately, existing MDS approaches cannot handle this issue.", "labels": [], "entities": []}, {"text": "We investigate this problem known as reader-aware multi-document summarization (RA-MDS).", "labels": [], "entities": [{"text": "reader-aware multi-document summarization", "start_pos": 37, "end_pos": 78, "type": "TASK", "confidence": 0.6072560350100199}]}, {"text": "Under the RA-MDS setting, one should jointly consider news documents and reader comments when generating the summaries.", "labels": [], "entities": []}, {"text": "One challenge of the RA-MDS problem is how to conduct salience estimation by jointly considering the focus of news reports and the reader interests revealed by comments.", "labels": [], "entities": [{"text": "salience estimation", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.9091781973838806}]}, {"text": "Meanwhile, the model should be insensitive to the availability of diverse aspects of reader comments.", "labels": [], "entities": []}, {"text": "Another challenge is that reader comments are very noisy, not fully grammatical and often expressed in infor-mal expressions.", "labels": [], "entities": []}, {"text": "Some previous works explore the effect of comments or social contexts in single document summarization such as blog summarization ().", "labels": [], "entities": [{"text": "single document summarization", "start_pos": 73, "end_pos": 102, "type": "TASK", "confidence": 0.6790632208188375}, {"text": "blog summarization", "start_pos": 111, "end_pos": 129, "type": "TASK", "confidence": 0.6801422238349915}]}, {"text": "However, the problem setting of RA-MDS is more challenging because the considered comments are about an event which is described by multiple documents spanning a time period.", "labels": [], "entities": []}, {"text": "Another challenge is that reader comments are very diverse and noisy.", "labels": [], "entities": []}, {"text": "Recently, employed a sparse coding based framework for RA-MDS jointly considering news documents and reader comments via an unsupervised data reconstruction strategy.", "labels": [], "entities": []}, {"text": "However, they only used the bag-of-words method to represent texts, which cannot capture the complex relationship between documents and comments.", "labels": [], "entities": []}, {"text": "Recently, proposed a sentence salience estimation framework known as VAESum based on a neural generative model called Variational Auto-Encoders (VAEs)).", "labels": [], "entities": [{"text": "sentence salience estimation", "start_pos": 21, "end_pos": 49, "type": "TASK", "confidence": 0.7471806605656942}]}, {"text": "During our investigation, we find that the Gaussian based VAEs have a strong ability to capture the salience information and filter the noise from texts.", "labels": [], "entities": []}, {"text": "Intuitively, if we feed both the news sentences and the comment sentences into the VAEs, commonly existed latent aspect information from both of them will be enhanced and become salient.", "labels": [], "entities": [{"text": "VAEs", "start_pos": 83, "end_pos": 87, "type": "DATASET", "confidence": 0.5431644320487976}]}, {"text": "Inspired by this consideration, to address the sentence salience estimation problem for RA-MDS by jointly considering news documents and reader comments, we extend the VAESum framework by training the news sentence latent model and the comment sentence latent model simultaneously by sharing the neural parameters.", "labels": [], "entities": [{"text": "sentence salience estimation", "start_pos": 47, "end_pos": 75, "type": "TASK", "confidence": 0.7351220548152924}, {"text": "VAESum", "start_pos": 168, "end_pos": 174, "type": "METRIC", "confidence": 0.6389937996864319}]}, {"text": "After estimating the sentence salience, we employ a phrase based compressive unified optimization framework to generate a final summary.", "labels": [], "entities": []}, {"text": "There is alack of high-quality dataset suitable for RA-MDS.", "labels": [], "entities": []}, {"text": "Existing datasets from DUC 3 and TAC are not appropriate.", "labels": [], "entities": [{"text": "DUC 3", "start_pos": 23, "end_pos": 28, "type": "DATASET", "confidence": 0.8986552953720093}, {"text": "TAC", "start_pos": 33, "end_pos": 36, "type": "DATASET", "confidence": 0.7789066433906555}]}, {"text": "Therefore, we introduce anew dataset for RA-MDS.", "labels": [], "entities": []}, {"text": "We employed some experts to conduct the tasks of data collection, aspect annotation, and summary writing as well as scrutinizing.", "labels": [], "entities": [{"text": "data collection", "start_pos": 49, "end_pos": 64, "type": "TASK", "confidence": 0.7434592247009277}, {"text": "aspect annotation", "start_pos": 66, "end_pos": 83, "type": "TASK", "confidence": 0.821533203125}, {"text": "summary writing", "start_pos": 89, "end_pos": 104, "type": "TASK", "confidence": 0.8047948181629181}]}, {"text": "To our best knowledge, this is the first dataset for RA-MDS.", "labels": [], "entities": []}, {"text": "Our contributions are as follows: (1) We investigate the RA-MDS problem and introduce anew dataset for the problem of RA-MDS.", "labels": [], "entities": []}, {"text": "To our best knowledge, it is the first dataset for RA-MDS.", "labels": [], "entities": []}, {"text": "To tackle the RA-MDS, we extend a VAEs-based MDS framework by jointly considering news documents and reader comments.", "labels": [], "entities": [{"text": "VAEs-based MDS", "start_pos": 34, "end_pos": 48, "type": "TASK", "confidence": 0.49759575724601746}]}, {"text": "(3) Experimental results show that reader comments can improve the summarization performance, which also demonstrates the usefulness of the dataset.", "labels": [], "entities": [{"text": "summarization", "start_pos": 67, "end_pos": 80, "type": "TASK", "confidence": 0.9748067855834961}]}], "datasetContent": [{"text": "The properties of our own dataset are depicted in Section 3.3.", "labels": [], "entities": []}, {"text": "We use ROUGE score as our evaluation metric) with standard options 8 . Fmeasures of ROUGE-1, ROUGE-2 and ROUGE-SU4 are reported.", "labels": [], "entities": [{"text": "ROUGE score", "start_pos": 7, "end_pos": 18, "type": "METRIC", "confidence": 0.943002849817276}, {"text": "Fmeasures", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.9981634020805359}, {"text": "ROUGE-1", "start_pos": 84, "end_pos": 91, "type": "METRIC", "confidence": 0.9412552714347839}, {"text": "ROUGE-2", "start_pos": 93, "end_pos": 100, "type": "METRIC", "confidence": 0.8912215828895569}, {"text": "ROUGE-SU4", "start_pos": 105, "end_pos": 114, "type": "METRIC", "confidence": 0.8327261805534363}]}, {"text": "The input news sentences and comment sentences are represented as BoWs vectors with dimension |V |.", "labels": [], "entities": []}, {"text": "The dictionary V is created using unigrams, bigrams and named entity terms.", "labels": [], "entities": []}, {"text": "n d and n care the number of news sentences and comment sentences respectively.", "labels": [], "entities": []}, {"text": "For the number of latent aspects used in data reconstruction, we let m = 5.", "labels": [], "entities": [{"text": "data reconstruction", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.8191657662391663}]}, {"text": "For the neural network framework, we set the hidden size d h = 500 and the latent size K = 100.", "labels": [], "entities": []}, {"text": "For the parameter \u03bb p used in comment weight, we let \u03bb p = 0.2.", "labels": [], "entities": []}, {"text": "Adam () is used for gradient based optimization with a learning rate 0.001.", "labels": [], "entities": [{"text": "gradient based optimization", "start_pos": 20, "end_pos": 47, "type": "TASK", "confidence": 0.7300334175427755}]}, {"text": "Our neural network based framework is implemented using Theano () on a single GPU 9 .  The results of our framework as well as the baseline methods are depicted in.", "labels": [], "entities": []}, {"text": "It is obvious that our framework RAVAESum is the best among all the comparison methods.", "labels": [], "entities": [{"text": "RAVAESum", "start_pos": 33, "end_pos": 41, "type": "DATASET", "confidence": 0.4247623682022095}]}, {"text": "Specifically, it is better than RA-Sparse significantly (p < 0.05), which demonstrates that VAEs based latent semantic modeling and joint semantic space reconstruction can improve the MDS performance considerably.", "labels": [], "entities": [{"text": "joint semantic space reconstruction", "start_pos": 132, "end_pos": 167, "type": "TASK", "confidence": 0.594419002532959}]}, {"text": "Both RAVAESum and RA-Sparse are better than the methods without considering reader comments.", "labels": [], "entities": [{"text": "RAVAESum", "start_pos": 5, "end_pos": 13, "type": "METRIC", "confidence": 0.5424063205718994}]}], "tableCaptions": [{"text": " Table 2: Further investigation of RAVAESum.", "labels": [], "entities": [{"text": "RAVAESum", "start_pos": 35, "end_pos": 43, "type": "TASK", "confidence": 0.3972361087799072}]}, {"text": " Table 4: Generated summaries for the topic \"Sony  Virtual Reality PS4\".", "labels": [], "entities": [{"text": "Sony  Virtual Reality PS4\"", "start_pos": 45, "end_pos": 71, "type": "DATASET", "confidence": 0.906395435333252}]}]}