{"title": [{"text": "Parsing and MWE Detection: Fips at the PARSEME Shared Task", "labels": [], "entities": [{"text": "MWE Detection", "start_pos": 12, "end_pos": 25, "type": "TASK", "confidence": 0.9490297436714172}, {"text": "PARSEME Shared Task", "start_pos": 39, "end_pos": 58, "type": "DATASET", "confidence": 0.8198709090550741}]}], "abstractContent": [{"text": "Identifying multiword expressions (MWEs) in a sentence in order to ensure their proper processing in subsequent applications, like machine translation, and performing the syntactic analysis of the sentence are interrelated processes.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 131, "end_pos": 150, "type": "TASK", "confidence": 0.7834636270999908}]}, {"text": "In our approach, priority is given to parsing alternatives involving collocations, and hence collocational information helps the parser through the maze of alternatives, with the aim to lead to substantial improvements in the performance of both tasks (collocation identification and parsing), and in that of a subsequent task (machine translation).", "labels": [], "entities": [{"text": "collocation identification", "start_pos": 253, "end_pos": 279, "type": "TASK", "confidence": 0.7656767666339874}, {"text": "parsing)", "start_pos": 284, "end_pos": 292, "type": "TASK", "confidence": 0.9061917960643768}, {"text": "machine translation)", "start_pos": 328, "end_pos": 348, "type": "TASK", "confidence": 0.7988823155562083}]}, {"text": "In this paper, we are going to present our system and the procedure that we have followed in order to participate to the open track of the PARSEME shared task on automatic identification of verbal multiword expressions (VMWEs) in running texts.", "labels": [], "entities": [{"text": "PARSEME shared task", "start_pos": 139, "end_pos": 158, "type": "TASK", "confidence": 0.5026626388231913}, {"text": "automatic identification of verbal multiword expressions (VMWEs) in running texts", "start_pos": 162, "end_pos": 243, "type": "TASK", "confidence": 0.7958126738667488}]}], "introductionContent": [{"text": "Multiword expressions (MWEs) are lexical units consisting of more than one word (in the intuitive sense of 'word').", "labels": [], "entities": [{"text": "Multiword expressions (MWEs)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.712861955165863}]}, {"text": "There are several types of MWEs, including idioms (a frog in the throat, break a leg), fixed phrases (per se, by and large, rock'n roll), noun compounds (traffic light, cable car), phrasal verbs (look up, takeoff ), etc.", "labels": [], "entities": [{"text": "phrasal verbs (look up, takeoff )", "start_pos": 181, "end_pos": 214, "type": "TASK", "confidence": 0.6416626833379269}]}, {"text": "While easily mastered by native speakers, their detection and/or their interpretation pose a major challenge for computational systems, due in part to their flexible and heterogeneous nature.", "labels": [], "entities": []}, {"text": "In our research, MWEs are categorized in five subclasses: compounds, discontinuous words, named entities, collocations and idioms.", "labels": [], "entities": []}, {"text": "While the first three are expressions of lexical category (N, V, Adj, etc.) and can therefore be listed along with simple words, collocations and idioms are expressions of phrasal category (NPs, VPs, etc.).", "labels": [], "entities": []}, {"text": "The identification of compounds and named entities can be achieved during the lexical analysis, but the identification of discontinuous words (e.g. particle verbs or phrasal verbs), collocations and idioms requires grammatical data and should be viewed as part of the parsing process.", "labels": [], "entities": [{"text": "identification of compounds and named entities", "start_pos": 4, "end_pos": 50, "type": "TASK", "confidence": 0.8171691993872324}, {"text": "identification of discontinuous words (e.g. particle verbs or phrasal verbs)", "start_pos": 104, "end_pos": 180, "type": "TASK", "confidence": 0.6799650837977728}]}, {"text": "In this paper, we will primarily focus on collocations, roughly defined as arbitrary and conventional associations of two words (not counting grammatical words) in a particular grammatical configuration (adjective-noun, noun-noun, verbobject, etc.) and especially on the categories of verbal collocations defined in the framework of the PARSEME shared task.", "labels": [], "entities": [{"text": "PARSEME shared task", "start_pos": 337, "end_pos": 356, "type": "TASK", "confidence": 0.4705301622549693}]}, {"text": "Section 2 will give a brief review of MWEs and previous work.", "labels": [], "entities": [{"text": "MWEs", "start_pos": 38, "end_pos": 42, "type": "TASK", "confidence": 0.9594555497169495}]}, {"text": "Section 3 will describe how our system handles MWEs, the way they are represented in its lexical database and will also be concerned with the treatment of collocation types which present a fair amount of syntactic flexibility (e.g. verb-object).", "labels": [], "entities": []}, {"text": "For instance, verbal collocations may undergo syntactic processes such as passivization, relativization, interrogation and even pronominalization, which can leave the collocation constituents faraway from each other and/or reverse their canonical order.", "labels": [], "entities": []}, {"text": "Section 4 will present the modifications made in order to adapt our system to the requirements of the shared task and the section 5 the evaluation and results.", "labels": [], "entities": []}], "datasetContent": [{"text": "Evaluation metrics are precision, recall and F1, both strict (per VMWE) and fuzzy (per token, i.e. taking partial matches into account).", "labels": [], "entities": [{"text": "precision", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9995550513267517}, {"text": "recall", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.9994240999221802}, {"text": "F1", "start_pos": 45, "end_pos": 47, "type": "METRIC", "confidence": 0.9996379613876343}]}, {"text": "The tokenbased F1 takes into account: -discontinuities (take something into account); -overlapping (take a walk and then along shower); -embeddings both at the syntactic level (take the fact that I didn't give up into account) and at the level of lexicalized components (let the cat out of the bag).", "labels": [], "entities": [{"text": "F1", "start_pos": 15, "end_pos": 17, "type": "METRIC", "confidence": 0.9184519052505493}]}, {"text": "However, VMWE categories (e.g., LVC, ID, IReflV, VPC) were ignored by the evaluation metrics.", "labels": [], "entities": []}, {"text": "We measured the best F1 score from all possible matches between the set of MWE token ranks in the gold and system sentences by looking at all possible ways of matching MWEs in both sets.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9831893742084503}]}, {"text": "In the evaluation per MWE, our system achieved 0.4815 precision with a recall of 0.4680 and Fmeasure of 0.4746.", "labels": [], "entities": [{"text": "precision", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9978152513504028}, {"text": "recall", "start_pos": 71, "end_pos": 77, "type": "METRIC", "confidence": 0.9994779229164124}, {"text": "Fmeasure", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9997861981391907}]}, {"text": "In the evaluation per token, our system achieved 0.5865 precision with a recall of 0.5108 and F-measure of 0.5461.", "labels": [], "entities": [{"text": "precision", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9973670840263367}, {"text": "recall", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.9995085000991821}, {"text": "F-measure", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.9996228218078613}]}], "tableCaptions": []}