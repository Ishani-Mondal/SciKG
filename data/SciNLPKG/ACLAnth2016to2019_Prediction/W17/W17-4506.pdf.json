{"title": [{"text": "Automatic Community Creation for Abstractive Spoken Conversation Summarization", "labels": [], "entities": [{"text": "Automatic Community Creation", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6269428332646688}, {"text": "Spoken Conversation Summarization", "start_pos": 45, "end_pos": 78, "type": "TASK", "confidence": 0.8189703424771627}]}], "abstractContent": [{"text": "Summarization of spoken conversations is a challenging task, since it requires deep understanding of dialogs.", "labels": [], "entities": [{"text": "Summarization of spoken conversations", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.9027724117040634}]}, {"text": "Abstractive summarization techniques rely on linking the summary sentences to sets of original conversation sentences, i.e. communities.", "labels": [], "entities": []}, {"text": "Unfortunately, such linking information is rarely available or requires trained anno-tators.", "labels": [], "entities": []}, {"text": "We propose and experiment automatic community creation using cosine similarity on different levels of representation: raw text, WordNet SynSet IDs, and word embeddings.", "labels": [], "entities": []}, {"text": "We show that the ab-stractive summarization systems with automatic communities significantly outper-form previously published results on both English and Italian corpora.", "labels": [], "entities": []}], "introductionContent": [{"text": "Spoken conversation summarization is an important task, since speech is the primary medium of human-human communication.", "labels": [], "entities": [{"text": "Spoken conversation summarization", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.9096037348111471}]}, {"text": "Vast amounts of spoken conversation data are produced daily in call-centers.", "labels": [], "entities": []}, {"text": "Due to this overwhelming number of conversations, call-centers can only evaluate a small percentage of the incoming calls ( . Automatic methods of conversation summarization have a potential to increase the capacity of the call-centers to analyze and assess their work.", "labels": [], "entities": [{"text": "conversation summarization", "start_pos": 147, "end_pos": 173, "type": "TASK", "confidence": 0.6939588189125061}]}, {"text": "Earlier works on conversation summarization have mainly focused on extractive techniques.", "labels": [], "entities": [{"text": "conversation summarization", "start_pos": 17, "end_pos": 43, "type": "TASK", "confidence": 0.7911172211170197}]}, {"text": "However, as pointed out in ( and (), abstractive summaries are preferred to extractive ones by human judges.", "labels": [], "entities": []}, {"text": "The possible reason for this is that extractive techniques are not well suited for the conversation summarization, since there are style differences between spoken conversations and humanauthored summaries.", "labels": [], "entities": [{"text": "conversation summarization", "start_pos": 87, "end_pos": 113, "type": "TASK", "confidence": 0.678636759519577}]}, {"text": "Abstractive conversation summarization systems, on the other hand, are mainly based on the extraction of lexical information ().", "labels": [], "entities": [{"text": "Abstractive conversation summarization", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.6414482494195303}]}, {"text": "The authors cluster conversation sentences/utterances into communities to identify most relevant ones and aggregate them using word-graph models.", "labels": [], "entities": []}, {"text": "The graph paths are ranked to yield abstract sentences -a template.", "labels": [], "entities": []}, {"text": "And these templates are selected for population with entities extracted from a conversation.", "labels": [], "entities": []}, {"text": "Thus the abstractive summarization systems are limited to these templates generated by supervised data sources.", "labels": [], "entities": []}, {"text": "The template selection strategy in these systems leverages on the manual links between summary and conversation sentences.", "labels": [], "entities": [{"text": "template selection", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.7085225582122803}]}, {"text": "Unfortunately, such manual links are rarely available.", "labels": [], "entities": []}, {"text": "In this paper we evaluate a set of heuristics for automatic linking of summary and conversations sentences, i.e. 'community' creation.", "labels": [], "entities": [{"text": "community' creation", "start_pos": 114, "end_pos": 133, "type": "TASK", "confidence": 0.7079516450564066}]}, {"text": "The heuristics rely on the similarity between the two, and we experiment with the cosine similarity computation on different levels of representation -raw text, text after replacing the verbs with their WordNet SynSet IDs, and the similarity computed using distributed word embeddings.", "labels": [], "entities": []}, {"text": "The heuristics are evaluated within the template-based abstractive summarization system of.", "labels": [], "entities": []}, {"text": "We extend this system to Italian using required NLP tools.", "labels": [], "entities": []}, {"text": "However, the approach transparently extends to other languages with available WordNet, minimal supervised summarization corpus and running text.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 78, "end_pos": 85, "type": "DATASET", "confidence": 0.9569127559661865}]}, {"text": "Heuristics are evaluated and compared on AMI meeting corpus and Italian LUNA Human-Human conversation corpus.", "labels": [], "entities": [{"text": "AMI meeting corpus", "start_pos": 41, "end_pos": 59, "type": "DATASET", "confidence": 0.9487781922022501}, {"text": "Italian LUNA Human-Human conversation corpus", "start_pos": 64, "end_pos": 108, "type": "DATASET", "confidence": 0.8993326663970947}]}, {"text": "The overall description of the system with the more detailed description of the heuristics is provided in Section 2.", "labels": [], "entities": []}, {"text": "In Section 3 we describe the corpora, evaluation methodology and the commu- nity creation experiments.", "labels": [], "entities": [{"text": "commu- nity creation", "start_pos": 69, "end_pos": 89, "type": "TASK", "confidence": 0.6807095855474472}]}, {"text": "Section 4 provides concluding remarks and future directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the automatic community creation heuristics on the AMI meeting corpus) and Italian and English LUNA Human-Human corpora ().", "labels": [], "entities": [{"text": "AMI meeting corpus", "start_pos": 63, "end_pos": 81, "type": "DATASET", "confidence": 0.9613168239593506}]}, {"text": "ROUGE-2 metric) is used for the evaluation.", "labels": [], "entities": [{"text": "ROUGE-2", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9753422737121582}]}, {"text": "The metric considers bigram-level precision, recall and F-measure between a set of reference and hypothesis summaries.", "labels": [], "entities": [{"text": "precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9368590712547302}, {"text": "recall", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.999441921710968}, {"text": "F-measure", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9987899661064148}]}, {"text": "For AMI corpus, following), we report ROUGE-2 F-measures on 3-fold cross-validation.", "labels": [], "entities": [{"text": "AMI corpus", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.7853855490684509}, {"text": "ROUGE-2 F-measures", "start_pos": 38, "end_pos": 56, "type": "METRIC", "confidence": 0.7765893042087555}]}, {"text": "For LUNA Corpus, on the other hand, we have used the modified version of ROUGE 1.5.5 toolkit from the CCCS Shared Task ( , which was adapted to deal with a conversation-dependent length limit of 7%.", "labels": [], "entities": [{"text": "LUNA Corpus", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.8815591335296631}]}, {"text": "Unlike the AMI Corpus, the official reported results for the CCCS Shared Task were recall; thus, for LUNA Corpus the reported values are ROUGE-2 recall.", "labels": [], "entities": [{"text": "AMI Corpus", "start_pos": 11, "end_pos": 21, "type": "DATASET", "confidence": 0.9210629165172577}, {"text": "recall", "start_pos": 83, "end_pos": 89, "type": "METRIC", "confidence": 0.9990643858909607}, {"text": "LUNA Corpus", "start_pos": 101, "end_pos": 112, "type": "DATASET", "confidence": 0.9174643158912659}, {"text": "ROUGE-2 recall", "start_pos": 137, "end_pos": 151, "type": "METRIC", "confidence": 0.776728093624115}]}, {"text": "For statistical significance testing, we use a paired bootstrap resampling method proposed in).", "labels": [], "entities": [{"text": "statistical significance testing", "start_pos": 4, "end_pos": 36, "type": "TASK", "confidence": 0.7826373179753622}]}, {"text": "We create new virtual test sets of 15 conversations with random re-sampling 100 times.", "labels": [], "entities": []}, {"text": "For each set, we compute the ROUGE-2 score and compare the system performances using paired t-test with p = 0.05.", "labels": [], "entities": [{"text": "ROUGE-2", "start_pos": 29, "end_pos": 36, "type": "METRIC", "confidence": 0.9961056113243103}]}], "tableCaptions": [{"text": " Table 1: Average ROUGE-2 F-measures on 3-fold  cross-validation for the abstractive summarization  systems on AMI corpus.", "labels": [], "entities": [{"text": "ROUGE-2", "start_pos": 18, "end_pos": 25, "type": "METRIC", "confidence": 0.9915069937705994}, {"text": "F-measures", "start_pos": 26, "end_pos": 36, "type": "METRIC", "confidence": 0.6734833121299744}, {"text": "AMI corpus", "start_pos": 111, "end_pos": 121, "type": "DATASET", "confidence": 0.9593153297901154}]}, {"text": " Table 2: ROUGE-2 recall with 7% summary  length limit for the extractive baselines (Favre  et al., 2015) and abstractive summarization sys- tems with the community creation heuristics on  LUNA corpus.", "labels": [], "entities": [{"text": "ROUGE-2", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9404547214508057}, {"text": "recall", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.7735059857368469}, {"text": "summary  length limit", "start_pos": 33, "end_pos": 54, "type": "METRIC", "confidence": 0.9164688189824423}, {"text": "LUNA corpus", "start_pos": 189, "end_pos": 200, "type": "DATASET", "confidence": 0.9353951215744019}]}]}