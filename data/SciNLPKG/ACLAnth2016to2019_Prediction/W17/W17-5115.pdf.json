{"title": [], "abstractContent": [{"text": "The segmentation of an argumentative text into argument units and their non-argumentative counterparts is the first step in identifying the argumentative structure of the text.", "labels": [], "entities": []}, {"text": "Despite its importance for argument mining, unit segmentation has been approached only sporadically so far.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 27, "end_pos": 42, "type": "TASK", "confidence": 0.8534106314182281}, {"text": "unit segmentation", "start_pos": 44, "end_pos": 61, "type": "TASK", "confidence": 0.7555047273635864}]}, {"text": "This paper studies the major parameters of unit segmentation systematically.", "labels": [], "entities": [{"text": "unit segmentation", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.6263787299394608}]}, {"text": "We explore the effectiveness of various features, when capturing words separately, along with their neighbors, or even along with the entire text.", "labels": [], "entities": []}, {"text": "Each such context is reflected by one machine learning model that we evaluate within and across three domains of texts.", "labels": [], "entities": []}, {"text": "Among the models, our new deep learning approach capturing the entire text turns out best within all domains, with an F-score of up to 88.54.", "labels": [], "entities": [{"text": "F-score", "start_pos": 118, "end_pos": 125, "type": "METRIC", "confidence": 0.9996743202209473}]}, {"text": "While structural features generalize best across domains, the domain transfer remains hard, which points to major challenges of unit segmentation.", "labels": [], "entities": [{"text": "domain transfer", "start_pos": 62, "end_pos": 77, "type": "TASK", "confidence": 0.7311310023069382}]}], "introductionContent": [{"text": "Argument mining deals with the automatic identification and classification of arguments in a text.", "labels": [], "entities": [{"text": "Argument mining", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.81973797082901}, {"text": "automatic identification and classification of arguments in a text", "start_pos": 31, "end_pos": 97, "type": "TASK", "confidence": 0.8208507498105367}]}, {"text": "It has become an emerging topic of research mainly owing to its many applications, such as writing support tools), intelligent personal assistants (, and argument search engines (.", "labels": [], "entities": []}, {"text": "Unit segmentation is often seen as the first task of an argument mining pipeline.", "labels": [], "entities": [{"text": "Unit segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.721229076385498}, {"text": "argument mining pipeline", "start_pos": 56, "end_pos": 80, "type": "TASK", "confidence": 0.7989846666653951}]}, {"text": "It consists in the splitting of a text into its argumentative segments (called argument units from here on) and their nonargumentative counterparts.", "labels": [], "entities": []}, {"text": "Afterwards, the roles that the argument units play in the argumentative The first two authors equally contributed to this paper.", "labels": [], "entities": []}, {"text": "structure of the text as well as the relations between the units are classified.", "labels": [], "entities": []}, {"text": "Conceptually, an argument unit may span a clause, a complete sentence, multiple sentences, or something in between.", "labels": [], "entities": []}, {"text": "The size of the units depends on the domain of an argumentative text (in terms of topic, genre, or similar), but can also vary within a text.", "labels": [], "entities": []}, {"text": "This makes unit segmentation a very challenging task.", "labels": [], "entities": [{"text": "unit segmentation", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.784850001335144}]}, {"text": "As detailed in Section 2, much existing research on argument mining has skipped the segmentation, assuming it to be given.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 52, "end_pos": 67, "type": "TASK", "confidence": 0.8198230564594269}]}, {"text": "For applications, however, an automatic segmentation is obligatory.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 40, "end_pos": 52, "type": "TASK", "confidence": 0.9242970943450928}]}, {"text": "Recently, three approaches have been presented that deal with the unit segmentation of persuasive essays: Persing and Ng (2016) rely on handcrafted rules based on the parse tree of a sentence to identify segments; uses sequence modeling based on sophisticated features to classify the argumentativeness of each single word based on its surrounding words; and employ a deep learning architecture that uses different features to do the same classification based on the entire essay.", "labels": [], "entities": [{"text": "unit segmentation of persuasive essays", "start_pos": 66, "end_pos": 104, "type": "TASK", "confidence": 0.8095841526985168}]}, {"text": "So far, however, it is neither clear what the best segmentation approach is, nor how different features and models generalize across domains and genres of argumentative texts.", "labels": [], "entities": []}, {"text": "In this paper, we carryout a systematic study to explore the major parameters of unit segmentation, reflected in the following three research questions: 1.", "labels": [], "entities": [{"text": "unit segmentation", "start_pos": 81, "end_pos": 98, "type": "TASK", "confidence": 0.6512916386127472}]}, {"text": "What features are most effective in unit segmentation?", "labels": [], "entities": [{"text": "unit segmentation", "start_pos": 36, "end_pos": 53, "type": "TASK", "confidence": 0.7415712177753448}]}, {"text": "2. What is the best machine learning model to capture the context of a unit that is relevant to segmentation?", "labels": [], "entities": []}, {"text": "3. To what extent do the features and models generalize across domains?", "labels": [], "entities": []}, {"text": "We approach the three questions on and across three existing argumentation corpora, each repre-senting a different domain (Section 3): the essays corpus of, the editorials corpus of Al-, and the web discourse corpus of.", "labels": [], "entities": []}, {"text": "All combinations of training and test domain are considered for these corpora, resulting in nine experiments.", "labels": [], "entities": []}, {"text": "Given the corpora, we follow the existing approaches outlined above in tackling unit segmentation as a token-level classification task (Section 4).", "labels": [], "entities": [{"text": "tackling unit segmentation", "start_pos": 71, "end_pos": 97, "type": "TASK", "confidence": 0.6600614686806997}, {"text": "token-level classification task", "start_pos": 103, "end_pos": 134, "type": "TASK", "confidence": 0.8233743906021118}]}, {"text": "To capture the context around each token, we analyze different semantic, syntactic, structural, and pragmatic feature types, and we compare three fundamental machine learning techniques based on these features: standard feature-based classification realized as a support vector machine (SVM), sequence modeling realized as linear-chain conditional random field (CRF), and anew deep learning approach realized as a bidirectional long short-term memory (Bi-LSTM).", "labels": [], "entities": []}, {"text": "These models correspond to increasingly complex levels of modeling context: The SVM considers only the current token, resulting in an isolated classification for each word.", "labels": [], "entities": []}, {"text": "The CRF is additionally able to consider the preceding classifications.", "labels": [], "entities": []}, {"text": "The Bi-LSTM, finally, can exploit all words and classifications before and after the current word.", "labels": [], "entities": []}, {"text": "We evaluate all features and models in Section 5.", "labels": [], "entities": []}, {"text": "Our results provide clear evidence that the capability of deep learning to model the entire context is beneficial for unit segmentation within domains.", "labels": [], "entities": [{"text": "unit segmentation", "start_pos": 118, "end_pos": 135, "type": "TASK", "confidence": 0.7168564200401306}]}, {"text": "The Bi-LSTM achieves the highest effectiveness on each corpus, even outperforming the approach of Stab (2017) on the essays corpus.", "labels": [], "entities": []}, {"text": "Across domains, however, all three perform similar and notably drop in effectiveness.", "labels": [], "entities": []}, {"text": "Matching intuition, semantic features turnout best to characterize argument units in the in-domain experiments, whereas structural features are more effective across domains.", "labels": [], "entities": []}, {"text": "Our findings indicate that the concepts of argument units in the given corpora do not fully match.", "labels": [], "entities": []}, {"text": "Altogether, the contribution of our paper is an extensive analysis of the benefits and limitations of standard approaches to argument unit segmentation.", "labels": [], "entities": [{"text": "argument unit segmentation", "start_pos": 125, "end_pos": 151, "type": "TASK", "confidence": 0.646654854218165}]}, {"text": "Nevertheless, argument unit segmentation is by far not a solved task yet, which is why we end with a discussion of its major challenges in Section 6, before we finally conclude (Section 7).", "labels": [], "entities": [{"text": "argument unit segmentation", "start_pos": 14, "end_pos": 40, "type": "TASK", "confidence": 0.7258624037106832}]}], "datasetContent": [{"text": "Using the three corpora detailed in Section 3, we conduct in-domain and cross-domain experiments to answer the three research questions from Section 1.", "labels": [], "entities": []}, {"text": "In each experiment, we use the training set of one corpus for training the model and the test set of the same or another corpus for evaluating the model.", "labels": [], "entities": []}, {"text": "In all cases, we test all four considered feature sets both in isolation and in combination.", "labels": [], "entities": []}, {"text": "We report the macro F-score as an evaluation measure, since this allows fora comparison to related work and since we consider all three classes (Arg-B, Arg-I, and Arg-O) to be equally important.", "labels": [], "entities": [{"text": "F-score", "start_pos": 20, "end_pos": 27, "type": "METRIC", "confidence": 0.7832151055335999}, {"text": "Arg-B", "start_pos": 145, "end_pos": 150, "type": "METRIC", "confidence": 0.9751694798469543}, {"text": "Arg-I", "start_pos": 152, "end_pos": 157, "type": "METRIC", "confidence": 0.9505278468132019}, {"text": "Arg-O", "start_pos": 163, "end_pos": 168, "type": "METRIC", "confidence": 0.9904664754867554}]}, {"text": "lists the macro F-scores of all combinations of features and models as well as of our reimplementation of the approach of Stab for all combinations of training and test set.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.8732284307479858}]}], "tableCaptions": [{"text": " Table 1: Number of documents, tokens per class, and average tokens per document per corpus and part.", "labels": [], "entities": []}, {"text": " Table 3: Confusion matrix opposing the number of gold BIO labels of pairs of consecutive tokens in the  essays corpus to those predicted by our best-performing method, the Bi-LSTM using all features. The  correct predictions (on the diagonal) are marked in bold.", "labels": [], "entities": []}, {"text": " Table 4: Pearson correlation between argument unit boundaries and structural features. Values range from  -1.00 (total negative correlation) to 1.00 (total positive correlation). Absolute values above or equal to 0.40  can be seen as moderately correlated and are marked in bold.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.8799318075180054}]}]}