{"title": [{"text": "DECCA Repurposed: Detecting transcription inconsistencies without an orthographic standard", "labels": [], "entities": [{"text": "DECCA Repurposed", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.6038615256547928}, {"text": "Detecting transcription inconsistencies", "start_pos": 18, "end_pos": 57, "type": "TASK", "confidence": 0.8850571314493815}]}], "abstractContent": [{"text": "Most language resources and technologies depend on written text, while most endangered languages are primarily spoken.", "labels": [], "entities": []}, {"text": "Transcribing speech into text is time consuming and error-prone.", "labels": [], "entities": [{"text": "Transcribing speech into text", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8728215992450714}]}, {"text": "We propose a method for finding spelling inconsistencies without recourse to a standard reference dictionary or to a large training corpus, by repurposing a method developed for finding annotation errors.", "labels": [], "entities": [{"text": "finding spelling inconsistencies", "start_pos": 24, "end_pos": 56, "type": "TASK", "confidence": 0.7769190073013306}]}, {"text": "We apply this method to improve quality control of audio transcriptions, with particular focus on under-resourced, primarily oral language varieties, including endangered varieties .", "labels": [], "entities": []}], "introductionContent": [{"text": "A critical part of documenting endangered languages is gathering and analyzing texts.", "labels": [], "entities": []}, {"text": "In the case of many such languages, particularly ones without along history of literacy or written literature, many if not most of these texts will be oral.", "labels": [], "entities": []}, {"text": "Although recent work has explored ways of working with audio samples directly, most approaches to building additional resources (such as dictionaries and grammars, whether printed or digital) or human language technologies (such as part of speech taggers, morphological parsers, or automatic speech recognition systems) with audio text require transcription.", "labels": [], "entities": [{"text": "speech taggers, morphological parsers", "start_pos": 240, "end_pos": 277, "type": "TASK", "confidence": 0.680533480644226}]}, {"text": "Even for languages with highly standardized spelling systems, maintaining transcription consistency is challenging.", "labels": [], "entities": []}, {"text": "Inconsistencies in transcription can hamper the use of the corpus for other purposes, by distorting frequency counts and hiding patterns in the data.", "labels": [], "entities": []}, {"text": "Transcription methodologies based on crowdsourced data collection have gained popularity in recent years due to their ability to deliver results at a fraction of the cost and turnaround time of conventional transcription methods and collect linguistic data out of the reach of traditional methods of lexicography).", "labels": [], "entities": []}, {"text": "Yet crowdsourcing also carries a certain degree of risk stemming from the uncertainty inherent in the online marketplace.", "labels": [], "entities": []}, {"text": "While Marge, found, for instance, that workers crowdsourced via Amazon Mechanical Turk (MTurk) had an average word error rate (WER) of less than 5% compared to in-house \"goldstandard\" transcription, Lee and Glass (2011) observed many MTurk transcriptions with a WER above 65%.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk (MTurk)", "start_pos": 64, "end_pos": 94, "type": "DATASET", "confidence": 0.8386990030606588}, {"text": "word error rate (WER)", "start_pos": 110, "end_pos": 131, "type": "METRIC", "confidence": 0.8875399132569631}, {"text": "WER", "start_pos": 262, "end_pos": 265, "type": "METRIC", "confidence": 0.9674724340438843}]}, {"text": "Beyond concerns of authoritative knowledge and accuracy, the ability of crowdsourcing to open public lexicography to a \"never-before-seen breadth of speaker input\" from \"the entire geographic range across which a language might vary\" ushers in both insights and challenges related to language variation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9840914607048035}]}, {"text": "More generally, anytime the task of transcription extends beyond a small number of carefully trained transcribers, with limited resources for checking inter-transcriber agreement, the potential for inconsistencies arises.", "labels": [], "entities": []}, {"text": "We propose a simple, easy-to-apply method to examine transcriptions of audio corpora, including notes from elicitation sessions, for spelling errors and other inconsistencies that may arise in both conventional and crowdsourced data collection processes.", "labels": [], "entities": []}, {"text": "While the proposed method is general enough to apply to any text input, we focus our experiments on transcriptions of spoken text.", "labels": [], "entities": []}, {"text": "Our first set of experiments focus on transcriptions of spoken Arabic, including colloquial varieties; our second set focuses on the type of fieldwork we believe to be typical in building descriptions of (and resources for) endangered languages.", "labels": [], "entities": []}, {"text": "In both cases traditional approaches to spelling correction do not apply, because there is no standard spelling dictionary to which to refer.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.9293978214263916}]}, {"text": "It is our hope that this method could assist field linguists in pinpointing aspects of transcriptions or other texts in need of quality control, reducing the need for manual examination of textual data.", "labels": [], "entities": [{"text": "pinpointing aspects of transcriptions", "start_pos": 64, "end_pos": 101, "type": "TASK", "confidence": 0.7427113205194473}]}], "datasetContent": [{"text": "To test the feasibility of this approach, initial experiments were performed on corpora of transcribed spoken colloquial Arabic available from the Linguistic Data Consortium (LDC).", "labels": [], "entities": [{"text": "Linguistic Data Consortium (LDC)", "start_pos": 147, "end_pos": 179, "type": "DATASET", "confidence": 0.8378592630227407}]}, {"text": "We report hereon two types of variation: spelling and whitespace.", "labels": [], "entities": []}, {"text": "After confirming the basic feasibility of this approach for spelling variation, we proceeded to test it on field notes on Kenyah Lebu' Kulit, an endangered language variety spoken in Indonesian Borneo.", "labels": [], "entities": [{"text": "spelling variation", "start_pos": 60, "end_pos": 78, "type": "TASK", "confidence": 0.9835914969444275}]}, {"text": "Because we do not have complete ground truth on all the spelling inconsistencies for these corpora, we are notable to report recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 125, "end_pos": 131, "type": "METRIC", "confidence": 0.9990577101707458}]}, {"text": "For these experiments, we therefore report precision only, based on an expert's review of the DECCA output in the various experiments.", "labels": [], "entities": [{"text": "precision", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.999406099319458}, {"text": "DECCA output", "start_pos": 94, "end_pos": 106, "type": "DATASET", "confidence": 0.8247895538806915}]}], "tableCaptions": []}