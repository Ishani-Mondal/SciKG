{"title": [{"text": "Stance Detection in Facebook Posts of a German Right-wing Party", "labels": [], "entities": [{"text": "Stance Detection", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.9665201306343079}]}], "abstractContent": [{"text": "We argue that in order to detect stance, not only the explicit attitudes of the stance holder towards the targets are crucial.", "labels": [], "entities": []}, {"text": "It is the whole narrative the writer drafts that counts, including the way he hyposta-sizes the discourse referents: as benefactors or villains, as victims or beneficiaries.", "labels": [], "entities": []}, {"text": "We exemplify the ability of our system to identify targets and detect the writer's stance towards them on the basis of about 100 000 Facebook posts of a Ger-man right-wing party.", "labels": [], "entities": []}, {"text": "A reader and writer model on top of our verb-based attitude extraction directly reveal stance conflicts.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recently, verb-based sentiment relation extraction has been used among others to derive positive and negative attitudes of Democrats and Republicans towards actors or topics.", "labels": [], "entities": [{"text": "verb-based sentiment relation extraction", "start_pos": 10, "end_pos": 50, "type": "TASK", "confidence": 0.7075818106532097}]}, {"text": "The system of  accomplishes this task on the basis of crowd-sourced connotation frames of (transitive) verbs which indicate such relations.", "labels": [], "entities": []}, {"text": "A connotation frame specifies, among others, the polar effects a verb role bears, if the verb is used affirmatively.", "labels": [], "entities": []}, {"text": "We are also interested instance detection, but stance, in our model, is not only the attempt to identify the positive and negative attitudes of the writer of the text (the main opinion holder) towards given actors (e.g. political parties) or (controversial) topics (henceforth targets) (see e.g.).", "labels": [], "entities": [{"text": "instance detection", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.7335442751646042}]}, {"text": "We also strive to identify targets in the first place.", "labels": [], "entities": []}, {"text": "We claim that the way the writer conceptualizes actors, namely as polarized actors -benefactors, villains, victims, beneficiaries (and so on) -reveals who/what the targets are.", "labels": [], "entities": []}, {"text": "This also unveils, as a by-product, the writer's stance.", "labels": [], "entities": []}, {"text": "A writer might not directly call someone a villain, but if he puts forward that a person has told a lie, then he obviously regards him as a villain, which implies a negative attitude.", "labels": [], "entities": []}, {"text": "We propose the following model.", "labels": [], "entities": []}, {"text": "The writer produces -under the assumption of truth commitment -some text.", "labels": [], "entities": []}, {"text": "The reader, on the basis of shared (lexical) semantic knowledge, is able to identify what the text implies for the various targets involved and described.", "labels": [], "entities": []}, {"text": "The reader's personal preferences (his stance, his moral values etc.) might be affected by a given exposition.", "labels": [], "entities": []}, {"text": "He might agree with the (implications of the) proclaimed facts or not.", "labels": [], "entities": []}, {"text": "From what is being said, the reader is thus able to derive at least two things: How does the writer conceptualize the world (i.e. what is his stance, what are the targets) and how does this relate to the reader's stance.", "labels": [], "entities": []}, {"text": "We focus on the interplay of these perspectives.", "labels": [], "entities": []}, {"text": "Our model confronts the writer with the reader perspective.", "labels": [], "entities": []}, {"text": "This way, conflicting conceptualizations of reality and incompatible stances become visible.", "labels": [], "entities": []}, {"text": "This allows the reader to identify charged statements, i.e. main sources of disagreement.", "labels": [], "entities": []}, {"text": "We have implemented a system that predicts advocate and adversary attitudes and that further assigns sources and targets their polarized roles (benefactor, victim etc.) on the basis of a connotation verb lexicon comprising 1500 manually specified connotation frames stemming from 1100 different verbs, also including about hundred nominalisations.", "labels": [], "entities": []}, {"text": "In order to do so, event factuality in the sense of also needs to be coped with.", "labels": [], "entities": []}, {"text": "In this paper, we are interested in a qualitative validation of our approach.", "labels": [], "entities": []}, {"text": "On the basis of 100 000 Facebook posts of a right-wing German party, the AfD (Alternative f\u00fcr Deutschland), and a virtual (kind of prototypical) reader, we exemplify how conflicting perspectives can be identified and how stance is detected.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have evaluated our approach quantitatively on the basis of 160 sentences.", "labels": [], "entities": []}, {"text": "The data consists of 80 (rather complex) made-up sentences (one or more subclause embeddings) and 80 real sentences.", "labels": [], "entities": []}, {"text": "Our goal was to verify the generative capacity of our model, thus the made-up sentences.", "labels": [], "entities": []}, {"text": "It is much more convenient to invent complex sentences, where e.g. negation is permuted exhaustively overall subclauses, than to try to sample such rare constellations.", "labels": [], "entities": []}, {"text": "Two annotators specified advocate and adversary relations and harmonized their annotations in order to get a gold standard.", "labels": [], "entities": []}, {"text": "Our goal was to see how our lexicon, including the principles of factuality determination, determines the performance.", "labels": [], "entities": [{"text": "factuality determination", "start_pos": 65, "end_pos": 89, "type": "TASK", "confidence": 0.6885692775249481}]}, {"text": "The precision was 83.5%, recall was 75.2%, which gives an F measure of 79.1% 5 . We then dropped the verb signatures from the lexicon, that is, we replaced the individual signatures by a default setting.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9997497200965881}, {"text": "recall", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9998180270195007}, {"text": "F measure", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9909831583499908}]}, {"text": "There are three possible settings.", "labels": [], "entities": []}, {"text": "We set the signature for the affirmative use of the verbs to 'T' (truth commitment), the signature for negated cases was set to 'F', 'N' and 'T' in turn.", "labels": [], "entities": []}, {"text": "We got a precision of 69.06%, 75.36% and 74.88% and a recall of 69.36%, 71.62% and 75.2%.", "labels": [], "entities": [{"text": "precision", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.999311089515686}, {"text": "recall", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.9994888305664062}]}, {"text": "The F measure for the best default setting ('T T') is 75.06% which is about 4% points worse than the system's result, 79.1%.", "labels": [], "entities": [{"text": "F measure", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9922155439853668}, {"text": "default setting ('T T')", "start_pos": 27, "end_pos": 50, "type": "METRIC", "confidence": 0.6793430844942728}]}, {"text": "We also see that precision droped by 8% points which is a substantial loss.", "labels": [], "entities": [{"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9996591806411743}]}, {"text": "This demonstrates that verb-specific information is crucial.", "labels": [], "entities": []}, {"text": "Encouraged by these results, we decided to carryout a qualitative study instance detection.", "labels": [], "entities": [{"text": "study instance detection", "start_pos": 66, "end_pos": 90, "type": "TASK", "confidence": 0.6510189771652222}]}, {"text": "We took 360 000 sentences from 100 000 Facebook posts of AfD members.", "labels": [], "entities": []}, {"text": "Our system produced 44 000 polar facts from them: attitudes and polar assignments.", "labels": [], "entities": []}, {"text": "Since these posts are (mostly) from AfD members, they implicitly represent their stance.", "labels": [], "entities": [{"text": "AfD", "start_pos": 36, "end_pos": 39, "type": "DATASET", "confidence": 0.8756043910980225}]}, {"text": "The key messages, the self-conception of the party and the proclaimed friends and enemies should be accessible through these posts.", "labels": [], "entities": []}, {"text": "We aggregated polar facts by counting how often an actor was conceptualized as a villain etc., but also by counting the number of advocate and adversary relations between actors.", "labels": [], "entities": []}, {"text": "We evaluated these aggregated polar facts through introspection.", "labels": [], "entities": []}, {"text": "That is we relied on our knowledge about the AfD, its goals, methods, ideological stance etc.", "labels": [], "entities": [{"text": "AfD", "start_pos": 45, "end_pos": 48, "type": "DATASET", "confidence": 0.9012683033943176}]}, {"text": "as portrayed by the mainstream German media.", "labels": [], "entities": []}, {"text": "The most important (since most frequent) polar fact derived by our systems already was in heart of the AfD's stance, namely that Angela Merkel, the German chancellor, is an adversary of Germany.", "labels": [], "entities": []}, {"text": "That is exactly what the AfD claims.", "labels": [], "entities": [{"text": "AfD", "start_pos": 25, "end_pos": 28, "type": "DATASET", "confidence": 0.9286009669303894}]}, {"text": "Actually, we get a very strong statement, in our tuple notation (recall that Merkel and Germany are reader proponents): That is: myProponent (Merkel) as villain is an adversary of myProponent (Germany) as a victim.", "labels": [], "entities": []}, {"text": "Conversely, these texts imply that the AfD is an advocate of Germany, that the refugees are adversaries of Germany, while the German government is an advocate of the refugees.", "labels": [], "entities": []}, {"text": "Curiously enough, for the relation of the AfD towards refugees, we got inconsistent evidence (three times adversary, three times advocate).", "labels": [], "entities": []}, {"text": "However, if we look at the polar assignment of refugees, which is villain, the picture is clear (see below).", "labels": [], "entities": []}, {"text": "There area couple of polar facts related to an event on New Year's Eve in 2015, where groups of men including migrants sexually assaulted women (that is the official statement).", "labels": [], "entities": []}, {"text": "Our system came up with the polar fact that refugees are adversaries of (these) women.", "labels": [], "entities": []}, {"text": "Another question is, of course, who is to blame for the situation (in Germany).", "labels": [], "entities": []}, {"text": "The mere fact that, in the perception of the AfD, Merkel is an adversary of Germany does not tell us whether this is positive or negative (in the eyes of the AfD).", "labels": [], "entities": []}, {"text": "An adversary relation might be positive (e.g. A0 adversary terrorism), or negative (e.g. A0 adversary truth), i.e. the holder of the adversary attitude might be someone who shares or contemns our values, depending on the event underlying the adversary relation.", "labels": [], "entities": [{"text": "A0 adversary terrorism)", "start_pos": 46, "end_pos": 69, "type": "TASK", "confidence": 0.6221366673707962}]}, {"text": "If Merkel is said to cheat Germany, then the writer wants the reader to believe that Merkel is a villain and Germany her victim.", "labels": [], "entities": []}, {"text": "Only then we know that the writer is (must be) an adversary of Merkel and an advocate of Germany.", "labels": [], "entities": []}, {"text": "In order to see who are villains and victims according to the AfD posts, we determined the most frequent actors that are classified as villains etc.", "labels": [], "entities": [{"text": "AfD posts", "start_pos": 62, "end_pos": 71, "type": "DATASET", "confidence": 0.9781576097011566}]}, {"text": "To give a couple of examples: Among the villains are the refugees (ranked highest), immediately followed by Merkel and men (representing male refugees), the German word for villain itself (T\u00e4ter) and government.", "labels": [], "entities": []}, {"text": "We believe that these are perfect hits.", "labels": [], "entities": []}, {"text": "Victims are Germany, women (New Year's eve event), the AfD (presumably since misunderstood), and the citizen of Germany (AfD seems to believe: the government cheats the citizen).", "labels": [], "entities": [{"text": "AfD", "start_pos": 55, "end_pos": 58, "type": "DATASET", "confidence": 0.8228344321250916}]}, {"text": "Among the beneficiaries are men (male refugees who are free to molest women without consequences), but also refugees (there is a welcome culture), Europe, criminals (since the government is weak) and the government.", "labels": [], "entities": []}, {"text": "From these lists we can also see that the AfD conceptualizes itself as a victim, a positive actor and even a benefactor.", "labels": [], "entities": []}, {"text": "If someone is an adversary of the values of the reader, he might be anew opponent: we defined this and similar relations (no-longer-opponent) on top of our tuple notation.", "labels": [], "entities": []}, {"text": "We found 80 different new opponent candidates, including various politicians, countries (their governments), parties, institutions (e.g. Nato) and concepts like Fl\u00fcchtlingswelle (flood of refugees) or politische Elite (political elite).", "labels": [], "entities": []}, {"text": "The list of entities we should no longer consider a proponent of the reader is perfect, it comprises Asylbewerber (refugee), Bundesregierung (government), Bundestag (parliament), EU, and Merkel.", "labels": [], "entities": [{"text": "Merkel", "start_pos": 187, "end_pos": 193, "type": "DATASET", "confidence": 0.9253734946250916}]}, {"text": "This exactly reflects the stance of the AfD.", "labels": [], "entities": [{"text": "AfD", "start_pos": 40, "end_pos": 43, "type": "DATASET", "confidence": 0.949524998664856}]}], "tableCaptions": []}