{"title": [], "abstractContent": [{"text": "Cohesive-ness is brought by various language phenom-enons.", "labels": [], "entities": []}, {"text": "Co-referring entities bind the sentence through reference phenomenon.", "labels": [], "entities": []}, {"text": "These co-referring entities include various anaphoric expressions namely pronominals, reflexives, reciprocal, distributives, noun-noun anaphora and definite descriptions.", "labels": [], "entities": []}, {"text": "These co-referring entities form the co-reference chains.", "labels": [], "entities": []}, {"text": "In this work, we present a methodology to identify the co-reference chains in Tamil text.", "labels": [], "entities": []}, {"text": "Evaluation of the system shows encouraging results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Cohesiveness of the text is brought by various language phenomenons.", "labels": [], "entities": []}, {"text": "Co-referring entities play a crucial part in binding discourse intra and inter sententially.", "labels": [], "entities": []}, {"text": "These co-referring entities form a chain in the text.", "labels": [], "entities": []}, {"text": "The present work is on identifying the co-reference chains in Tamil text by identifying the co-referring entities.", "labels": [], "entities": []}, {"text": "The coreferring entities consist of pronominal, reciprocal, reflexives, distributives, definite description and noun-noun anaphora and their antecedents.", "labels": [], "entities": []}, {"text": "Co-reference chains are very essential in building cutting edge natural language processing tools such as profile building, entity based summary generator, entity specific sentiment analyser etc.", "labels": [], "entities": [{"text": "profile building", "start_pos": 106, "end_pos": 122, "type": "TASK", "confidence": 0.7997872233390808}, {"text": "entity based summary generator", "start_pos": 124, "end_pos": 154, "type": "TASK", "confidence": 0.5895691141486168}, {"text": "entity specific sentiment analyser", "start_pos": 156, "end_pos": 190, "type": "TASK", "confidence": 0.6412856131792068}]}, {"text": "Consider the following the discourse., the subject of the sentence.", "labels": [], "entities": []}, {"text": "In Ex.1.f, 'ovvoruvar', Distributive refers to 'naNparkaL' (friends).", "labels": [], "entities": []}, {"text": "The other type of anaphor is the noun-noun anaphor which is present inmost of the sentences.", "labels": [], "entities": []}, {"text": "This can be seen in the above exampla as 'baalu' in Ex.1.d refers to 'baalu' in the previous sentence, 'baaluvin' in Ex.1.a.", "labels": [], "entities": []}, {"text": "Similarly 'raajuvai' in Ex.1.d refers to 'raaju' in Ex.1.1.a.", "labels": [], "entities": []}, {"text": "From 392 the above explanation we can form the coreference chain for each type of reference and they are given below.", "labels": [], "entities": []}, {"text": "Following are the Co-reference Chains from the example sentences from Ex.1.a to Thus the anaphoric expressions such as Pronominal, Split-antecedents, Reciprocal, Reflexives, Distributive, One anaphora, DefiniteDescriptions and Noun-Noun anaphora constitute the co-reference chains.", "labels": [], "entities": [{"text": "Ex.1.a", "start_pos": 70, "end_pos": 76, "type": "DATASET", "confidence": 0.9309384226799011}]}, {"text": "In the present work, the co-reference chains are built by resolving these anaphoric entities.", "labels": [], "entities": []}, {"text": "Co-reference resolution was the shared task in DARPA's Message Understanding Coreference MUC-6 (1995) and.", "labels": [], "entities": [{"text": "Co-reference resolution", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7128304243087769}, {"text": "Message Understanding Coreference MUC-6 (1995)", "start_pos": 55, "end_pos": 101, "type": "TASK", "confidence": 0.6467395211969104}]}, {"text": "These two shared tasks were the early initiatives which kick started machine learning based approach for coreference relation resolution task.,, had used decision tree learning algorithm to come up with co-reference resolution system.", "labels": [], "entities": [{"text": "coreference relation resolution task.", "start_pos": 105, "end_pos": 142, "type": "TASK", "confidence": 0.886127158999443}]}, {"text": "demonstrated the system with Japanese texts along with English texts.", "labels": [], "entities": []}, {"text": "used maximum entropy modelling technique to built co-reference resolution engine.", "labels": [], "entities": []}, {"text": "came up with an un-supervised learning approach to identify co-reference relation.", "labels": [], "entities": []}, {"text": "They have evaluated their engine on MUC-6 dataset.", "labels": [], "entities": [{"text": "MUC-6 dataset", "start_pos": 36, "end_pos": 49, "type": "DATASET", "confidence": 0.9655530750751495}]}, {"text": "used decision tree learning approach to identify the co-referencing pairs and used pair-wise model to build the co-reference chains.", "labels": [], "entities": []}, {"text": "enhanced decision tree learning approach with more linguistic and heuristic features.", "labels": [], "entities": [{"text": "decision tree learning", "start_pos": 9, "end_pos": 31, "type": "TASK", "confidence": 0.747097373008728}]}, {"text": "They used bestfirst clustering methodology to build the coreference chains.", "labels": [], "entities": []}, {"text": "First-order probabilistic model was by. tried to present that the approach by would perform better with better features.", "labels": [], "entities": []}, {"text": "They re-implement it with modified features.", "labels": [], "entities": []}, {"text": "employed clusterranking approach to perform co-reference resolution.", "labels": [], "entities": [{"text": "co-reference resolution", "start_pos": 44, "end_pos": 67, "type": "TASK", "confidence": 0.7429495453834534}]}, {"text": "A multilevel sieve based approach was performed by.", "labels": [], "entities": []}, {"text": "SemEval (2010) Coreference Resolution in Multiple Languages aimed to explore the portability of systems across languages, need for different levels of linguistic information.", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 15, "end_pos": 37, "type": "TASK", "confidence": 0.784702330827713}]}, {"text": "The flow of the paper is as follows.", "labels": [], "entities": []}, {"text": "In the following section, we present a brief introduction on characteristics of Tamil.", "labels": [], "entities": []}, {"text": "We have explained our approach in the third section.", "labels": [], "entities": []}, {"text": "In fourth section, we have presented on the experiment, result and observation.", "labels": [], "entities": []}, {"text": "The paper concludes with the conclusion section.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have manually annotated 1000 Tamil newwires collected from online Tamil web pages belonging to three domains, viz, sports, general and disaster.", "labels": [], "entities": [{"text": "Tamil newwires collected from online Tamil web pages", "start_pos": 32, "end_pos": 84, "type": "DATASET", "confidence": 0.8082733005285263}]}, {"text": "We had two annotators and the inter-agreement score is measured to be 0.78 kappa score.", "labels": [], "entities": []}, {"text": "We have used 80% of the annotated corpus for developing the different anaphora resolution engines and co-reference chain builder.", "labels": [], "entities": []}, {"text": "The rest 20% of the annotated corpus is used for testing the different anaphora resolution engines.", "labels": [], "entities": []}, {"text": "In the following table 2, we have presented the statistics of the annotated corpus.", "labels": [], "entities": []}, {"text": "Following table 3, has the statistics of the different anaphoric expression annotated in the corpus.", "labels": [], "entities": []}, {"text": "The co-reference chains are evaluated with standard evaluation metrics such as MUC, BCubed, CEAFe, CEAFm and BLANC.", "labels": [], "entities": [{"text": "MUC", "start_pos": 79, "end_pos": 82, "type": "DATASET", "confidence": 0.6172472238540649}, {"text": "BCubed", "start_pos": 84, "end_pos": 90, "type": "METRIC", "confidence": 0.7506734728813171}, {"text": "CEAFe", "start_pos": 92, "end_pos": 97, "type": "DATASET", "confidence": 0.6054994463920593}, {"text": "CEAFm", "start_pos": 99, "end_pos": 104, "type": "DATASET", "confidence": 0.5132473707199097}, {"text": "BLANC", "start_pos": 109, "end_pos": 114, "type": "METRIC", "confidence": 0.9814648032188416}]}, {"text": "The performance scores for co-reference chain identification are presented in table 4.", "labels": [], "entities": [{"text": "co-reference chain identification", "start_pos": 27, "end_pos": 60, "type": "TASK", "confidence": 0.6863470673561096}]}, {"text": "The performance scores of various anaphora resolution modules with system preprocessed corpus and gold standard corpus as input is presented in table 5.", "labels": [], "entities": []}, {"text": "presents the comparison of performance scores between the results obtained by giving preprocessed corpus, Gold standard and system processed, as input to the anaphoric systems.", "labels": [], "entities": []}, {"text": "This brings out the inherent errors of each anaphora resolution systems and the errors introduced by preprocessing modules.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.7460858821868896}]}, {"text": "On analysing the gold standard corpus result, we find pronominal resolution and one-anaphora resolution need improvement at the anaphora analysis level.", "labels": [], "entities": [{"text": "gold standard corpus result", "start_pos": 17, "end_pos": 44, "type": "DATASET", "confidence": 0.7564399838447571}]}, {"text": "The tendency of pronominal resolution engine to choose the first nominative as antecedent is one of the reason and this needs further analysis.", "labels": [], "entities": [{"text": "pronominal resolution", "start_pos": 16, "end_pos": 37, "type": "TASK", "confidence": 0.7933667302131653}]}, {"text": "In table 6, we have presented the percentage of intrinsic errors, the total percentage of errors introduced by preprocessing modules to each anaphora resolution engine and the percentage of errors contributed by each preprocessing modules to the total preprocessing errors.", "labels": [], "entities": []}, {"text": "With the informations from table 6, we can understand the importance of features derived from each preprocessing module for developing various anaphora resolution engines.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 143, "end_pos": 162, "type": "TASK", "confidence": 0.7654834091663361}]}, {"text": "The output from the gold standard corpus as input is analysed and the observations are discussed below.", "labels": [], "entities": [{"text": "gold standard corpus", "start_pos": 20, "end_pos": 40, "type": "DATASET", "confidence": 0.9210054675738016}]}, {"text": "In singular pronominal resolution engine, which is built using CRFs techniques, the first nominative NP is choosen as the antecedent if the sentences have more than one nominative NP.", "labels": [], "entities": [{"text": "singular pronominal resolution", "start_pos": 3, "end_pos": 33, "type": "TASK", "confidence": 0.6295616924762726}]}, {"text": "Here in both the sentences 'maaNavarkaL' (students) has occurred referring to the same entity.", "labels": [], "entities": []}, {"text": "But these plural NPs occur as a common nons and the definiteness is not signalled with any markers.", "labels": [], "entities": []}, {"text": "So we have not handled these kinds of definite NPs which occur as common nouns.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1 Salience Factors and its Weights", "labels": [], "entities": [{"text": "Salience", "start_pos": 9, "end_pos": 17, "type": "TASK", "confidence": 0.9765064120292664}, {"text": "Weights", "start_pos": 34, "end_pos": 41, "type": "METRIC", "confidence": 0.955909013748169}]}, {"text": " Table 3: Statistics of Anaphoric expressions in  the Corpus", "labels": [], "entities": []}, {"text": " Table 4: Performance scores for Co-reference  chains", "labels": [], "entities": []}, {"text": " Table 5 Comparison of Results with System Preprocessed Corpus and Gold standard Corpus as Input", "labels": [], "entities": []}, {"text": " Table 6  Percentage Distribution of Errors introduced by Various Preprocessing Modules", "labels": [], "entities": []}]}