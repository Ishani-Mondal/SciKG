{"title": [{"text": "deepCybErNet at EmoInt-2017: Deep Emotion Intensities in Tweets", "labels": [], "entities": [{"text": "EmoInt-2017", "start_pos": 16, "end_pos": 27, "type": "DATASET", "confidence": 0.600416898727417}]}], "abstractContent": [{"text": "This working note presents the methodology used in deepCybErNet submission to the shared task on Emotion Intensities in Tweets (EmoInt) WASSA-2017.", "labels": [], "entities": [{"text": "Emotion Intensities in Tweets (EmoInt) WASSA-2017", "start_pos": 97, "end_pos": 146, "type": "TASK", "confidence": 0.8100767806172371}]}, {"text": "The goal of the task is to predict areal valued score in the range [0-1] fora particular tweet with an emotion type.", "labels": [], "entities": []}, {"text": "To do this, we used Bag-of-Words and embedding based on recurrent network architecture.", "labels": [], "entities": []}, {"text": "We have developed two systems and experiments are conducted on the Emotion Intensity shared Task 1 database at WASSA-2017.", "labels": [], "entities": [{"text": "Emotion Intensity shared Task 1 database at WASSA-2017", "start_pos": 67, "end_pos": 121, "type": "DATASET", "confidence": 0.7556087523698807}]}, {"text": "A system which uses word embedding based on recurrent network architecture has achieved highest 5 fold cross-validation accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.9469946026802063}]}, {"text": "This has used embedding with recurrent network to extract optimal features at tweet level and logistic regression for prediction.", "labels": [], "entities": []}, {"text": "These methods are highly language independent and experimental results shows that the proposed methods is apt for predicting areal valued score in than range [0-1] fora given tweet with its emotion type.", "labels": [], "entities": []}], "introductionContent": [{"text": "Internet has become an essential platform to carryout daily activities to our lives.", "labels": [], "entities": []}, {"text": "People use social media resources like Twitter, Facebook, WhatsApp, Hike, WeChat etc.", "labels": [], "entities": [{"text": "WhatsApp", "start_pos": 58, "end_pos": 66, "type": "DATASET", "confidence": 0.8768384456634521}, {"text": "Hike", "start_pos": 68, "end_pos": 72, "type": "DATASET", "confidence": 0.9318870902061462}, {"text": "WeChat", "start_pos": 74, "end_pos": 80, "type": "DATASET", "confidence": 0.9308297634124756}]}, {"text": "to share their language such as views or emotions, stance over issues, reviews related to products, services, blogs etc.", "labels": [], "entities": []}, {"text": "In recent days, the amount of language sharing through the internet is ubiquitous.", "labels": [], "entities": []}, {"text": "This necessitates the need of analyzing reviews to identify the emotions including estimating the degree to which an emotion is expressed in text.", "labels": [], "entities": []}, {"text": "Unlike natural language, the user reviews are small; rich information is represented through nonstandard language such as emoticons, emojis, creatively spelled words (happee), and hash-tagged words (#happy).", "labels": [], "entities": []}, {"text": "These factors can make a high influence on the social and economic behavior worldwide like real-world applications such as marketing, eGovernance, business intelligence, social analysis and applications in Natural Language Processing (NLP) -information extraction, question answering, textual entailment, etc.", "labels": [], "entities": [{"text": "Natural Language Processing (NLP) -information extraction", "start_pos": 206, "end_pos": 263, "type": "TASK", "confidence": 0.6274889475769467}, {"text": "question answering", "start_pos": 265, "end_pos": 283, "type": "TASK", "confidence": 0.8417558073997498}]}, {"text": "Many methods have been introduced by researchers for emotion annotation work.", "labels": [], "entities": [{"text": "emotion annotation", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.8092239797115326}]}, {"text": "This gives binary labels for the given text (),,,,.", "labels": [], "entities": []}, {"text": "only one annotation work exists for providing areal valued score as annotation fora given text).", "labels": [], "entities": []}, {"text": "This was a task included in the SemEval-2007 shared task.", "labels": [], "entities": [{"text": "SemEval-2007 shared task", "start_pos": 32, "end_pos": 56, "type": "TASK", "confidence": 0.6903773546218872}]}, {"text": "Many methods devised for automatic emotion classification,,,,,.", "labels": [], "entities": [{"text": "automatic emotion classification", "start_pos": 25, "end_pos": 57, "type": "TASK", "confidence": 0.6954692006111145}]}, {"text": "However, only less amount work exists on emotion regression other than SemEval-2007 shared task.", "labels": [], "entities": [{"text": "emotion regression", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.7183738350868225}]}, {"text": "In this paper, we use Bag-of-Words (BOW) and a Bag-of-Words (BOW) based recurrent embedding system for predicting areal valued score in the range.", "labels": [], "entities": [{"text": "Bag-of-Words (BOW)", "start_pos": 22, "end_pos": 40, "type": "METRIC", "confidence": 0.676271066069603}, {"text": "Bag-of-Words (BOW)", "start_pos": 47, "end_pos": 65, "type": "METRIC", "confidence": 0.6856884211301804}]}, {"text": "In first case, BOW is used to obtain the feature representation for the tweets and classification is done using logistic regression.", "labels": [], "entities": [{"text": "BOW", "start_pos": 15, "end_pos": 18, "type": "METRIC", "confidence": 0.998482882976532}]}, {"text": "We also employed an RNN and LSTM based method for mining the features at tweets level.", "labels": [], "entities": []}, {"text": "These methods are language independent.", "labels": [], "entities": []}, {"text": "So irrespective of the language, we can use these approaches for finding the stance of micro blogging posts.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 discusses information of shared task.", "labels": [], "entities": []}, {"text": "Section 3 discusses the proposed methodology.: Statistics of Tweet Emotion Intensity dataset Section 4.2 provides experimental analysis and results and at last conclusion is placed in Section 5.", "labels": [], "entities": [{"text": "Tweet Emotion Intensity dataset", "start_pos": 61, "end_pos": 92, "type": "DATASET", "confidence": 0.5916983038187027}]}], "datasetContent": [{"text": "All deep learning architecture are trained using GPU enabled TensorFlow () with backpropogation through time (BPTT)).", "labels": [], "entities": [{"text": "backpropogation through time (BPTT))", "start_pos": 80, "end_pos": 116, "type": "METRIC", "confidence": 0.8625824352105459}]}, {"text": "We have submitted one run based on LSTM based recurrent embedding system to WASSA2017 and the detailed results is displayed in Analysis of training results and testing results showed that there is a significant difference in the performance measure.", "labels": [], "entities": [{"text": "WASSA2017", "start_pos": 76, "end_pos": 85, "type": "DATASET", "confidence": 0.8861772418022156}]}, {"text": "This is due to the overfitting of the model to the training data because, a deep learning framework requires huge amount of data to learn the features.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of Tweet Emotion Intensity  dataset", "labels": [], "entities": [{"text": "Tweet Emotion Intensity  dataset", "start_pos": 24, "end_pos": 56, "type": "DATASET", "confidence": 0.7396434545516968}]}, {"text": " Table 2: 5-fold cross validation with embedding  vector size 128", "labels": [], "entities": []}, {"text": " Table 3: 5-fold cross validation with embedding  vector size 256", "labels": [], "entities": []}, {"text": " Table 4: Test results in range [0-1]", "labels": [], "entities": []}]}