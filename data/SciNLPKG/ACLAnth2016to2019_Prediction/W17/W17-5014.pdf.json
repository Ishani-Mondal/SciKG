{"title": [{"text": "Automatic Extraction of High-Quality Example Sentences for Word Learning Using a Determinantal Point Process", "labels": [], "entities": [{"text": "Automatic Extraction of High-Quality Example Sentences", "start_pos": 0, "end_pos": 54, "type": "TASK", "confidence": 0.7711882690588633}]}], "abstractContent": [{"text": "Flashcard systems are effective tools for learning words but have their limitations in teaching word usage.", "labels": [], "entities": []}, {"text": "To overcome this problem, we propose a novel flashcard system that shows anew example sentence on each repetition.", "labels": [], "entities": []}, {"text": "This extension requires high-quality example sentences, automatically extracted from a huge corpus.", "labels": [], "entities": []}, {"text": "To do this, we use a Determinantal Point Process which scales well to large data and allows to naturally represent sentence similarity and quality as features.", "labels": [], "entities": []}, {"text": "Our human evaluation experiment on Japanese language indicates that the proposed method successfully extracted high-quality example sentences .", "labels": [], "entities": []}], "introductionContent": [{"text": "Learning vocabulary is a crucial step in learning foreign languages and it requires substantial time and effort.", "labels": [], "entities": []}, {"text": "Word learning is often done using flashcards: away of organizing information into question-answer pairs.", "labels": [], "entities": [{"text": "Word learning", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.8085829615592957}]}, {"text": "An example of a flashcard for the Japanese word \"\u67ff\" is shown on.", "labels": [], "entities": []}, {"text": "Flashcard systems frequently use Spaced Repetition technique to optimize the learning process.", "labels": [], "entities": []}, {"text": "The technique is based on the observation that people tend to remember things more effectively if they study in short periods spread overtime (spaced repetition practice) opposed to massed practice (i.e. cramming)).", "labels": [], "entities": []}, {"text": "Anki 1 is one of the most well known open source Spaced Repetition System (SRS).", "labels": [], "entities": [{"text": "Spaced Repetition System (SRS)", "start_pos": 49, "end_pos": 79, "type": "TASK", "confidence": 0.7227446834246317}]}, {"text": "One major drawback of building a vocabulary with flashcards is that most of the time cards look like the one displayed on  To enhance the learning experience, we propose a novel framework of learning words using flashcards.", "labels": [], "entities": []}, {"text": "Instead of showing only a single field like reading or writing of a flashcard in the question card similarly to the, we propose to use example sentences in both types of cards, see (bottom).", "labels": [], "entities": []}, {"text": "Moreover, we want to show anew example sentence on each repetition as the question.", "labels": [], "entities": []}, {"text": "This approach gives users an opportunity to learn correct word usages together with the words themselves.", "labels": [], "entities": []}, {"text": "Obviously, implementing it requires a huge number of example sentences.", "labels": [], "entities": []}, {"text": "Because of this, we focus on automatic extraction of high-quality example sentences to be used in a flashcard system as questions.", "labels": [], "entities": []}, {"text": "Collecting an enormous number of high-quality example sentences manually does not scale well.", "labels": [], "entities": []}, {"text": "Words can have multiple senses and different usage patterns.", "labels": [], "entities": []}, {"text": "A database containing dozens of sentences for each sense of each word would need to contain millions of different sentences.", "labels": [], "entities": []}, {"text": "For a set of example sentences, we say that they are of high-quality if the sentences have the following properties.", "labels": [], "entities": []}, {"text": "\u2022 (Intrinsic) Value: Each individual example sentence should not be bad, for example ungrammatical, a fragment or unrelated to target word.", "labels": [], "entities": []}, {"text": "Additionally, the sentences should not be too difficult for learners to understand them.", "labels": [], "entities": []}, {"text": "\u2022 Diversity: Inside a set, the sentences should cover different usage patterns, and word senses.", "labels": [], "entities": []}, {"text": "In addition we would like our method to support rare words and rare word senses.", "labels": [], "entities": []}, {"text": "For the task of example extraction, we are given a huge monolingual text corpora and a target word or a phrase to output a set of high-quality example sentences.", "labels": [], "entities": [{"text": "example extraction", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.8106247186660767}]}, {"text": "We propose a system architecture consisting of two components: a search engine which indexes a huge raw corpus and can produce a relatively high number of example sentence candidates, and the selection part, which takes the list of candidates and selects only a few of them.", "labels": [], "entities": []}, {"text": "The search system is designed in away so the selected sentences are syntactically rich near the target word (the target word has parents/children).", "labels": [], "entities": []}, {"text": "The DPP allows us to naturally represent data in terms of scalar quality and vector similarity.", "labels": [], "entities": []}, {"text": "Additionally, the DPP has several interesting properties.", "labels": [], "entities": [{"text": "DPP", "start_pos": 18, "end_pos": 21, "type": "DATASET", "confidence": 0.7236043214797974}]}, {"text": "For example, it is possible to compute a marginal probability of drawing a subset of items from a DPP efficiently.", "labels": [], "entities": []}, {"text": "Marginal here means a probability of inclusion of a given set in any subset drawn from the DPP.", "labels": [], "entities": [{"text": "Marginal", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9532222151756287}, {"text": "DPP", "start_pos": 91, "end_pos": 94, "type": "DATASET", "confidence": 0.9183826446533203}]}, {"text": "Furthermore, it is proven that this marginal probability measure is submodular.", "labels": [], "entities": []}, {"text": "Because of this, it is possible to build a greedy algorithm with reasonable guarantees, which selects items one by one, using the marginal probability measure as a weight.", "labels": [], "entities": []}, {"text": "Also, the DPP is computationally and memory efficient.", "labels": [], "entities": []}, {"text": "The computation of marginal probabilities can be performed linearly in respect to number of sentence candidates.", "labels": [], "entities": []}, {"text": "This makes it possible to use Figure 2: Word to token conversion for indexing a sentence.", "labels": [], "entities": []}, {"text": "Tokens contain lexical information (black), POS tags (green) and conjugation forms (magenta).", "labels": [], "entities": []}, {"text": "Dependency information is common fora set of tokens spawned from a single word.", "labels": [], "entities": []}, {"text": "This information consists of word position and dependency position.", "labels": [], "entities": []}, {"text": "the DPP with tens thousands of candidates in nearrealtime scenarios.", "labels": [], "entities": [{"text": "DPP", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.9064605236053467}]}, {"text": "We have performed a human evaluation experiment which has shown that our method was preferred by Japanese learners and a teacher compared to two baselines.", "labels": [], "entities": []}], "datasetContent": [{"text": "Evaluating the suitability of example sentences for learning a foreign language is difficult.", "labels": [], "entities": []}, {"text": "Firstly, it is not possible to assess the diversity of a sentence set when showing them to evaluators one by one.", "labels": [], "entities": []}, {"text": "Also, the automatic evaluation of example sentences is possible if the problem is formulated such that the only criterion is that example sentences should be present for every sense of a word.", "labels": [], "entities": []}, {"text": "However, such evaluation does not determine whether the example sentences are actually useful for learners.", "labels": [], "entities": []}, {"text": "We perform an evaluation experiment with Japanese language learners and a native teacher with two distinct main goals: to assess the performance of the example extraction system and to validate the assumptions on the meaning of the \"quality\" of example sentences.", "labels": [], "entities": [{"text": "example extraction", "start_pos": 152, "end_pos": 170, "type": "TASK", "confidence": 0.7367316484451294}]}, {"text": "We use a web corpus with 0.8B sentences lexically analyzed by JUMAN and parsed by KNP.", "labels": [], "entities": [{"text": "JUMAN", "start_pos": 62, "end_pos": 67, "type": "DATASET", "confidence": 0.8611739277839661}, {"text": "KNP", "start_pos": 82, "end_pos": 85, "type": "DATASET", "confidence": 0.8852748870849609}]}, {"text": "The first goal is achieved by having participants vote on lists of example sentences and select their preferred lists.", "labels": [], "entities": []}, {"text": "We deliberately use lists for the evaluation instead of showing single examples to make the spectrum of possible example sentences visible for each method.", "labels": [], "entities": []}, {"text": "Showing sentences one by one would make it difficult to compare the diversity of different lists.", "labels": [], "entities": []}, {"text": "For the second goal, the evaluation was performed in the form of an interview.", "labels": [], "entities": []}, {"text": "Participants were asked why they have or have not chosen specific lists of example sentences after the initial preference selection.", "labels": [], "entities": []}, {"text": "Three methods were used in the evaluation: the proposed one and two baselines.", "labels": [], "entities": []}, {"text": "The proposed method is labeled DPP in the evaluation results.", "labels": [], "entities": [{"text": "DPP", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.7728335857391357}]}, {"text": "We have used a difficulty bias value bias d = \u22123 to make the sentence difficulty appropriate for the learners around JLPT N3 level.", "labels": [], "entities": [{"text": "difficulty bias value bias d", "start_pos": 15, "end_pos": 43, "type": "METRIC", "confidence": 0.8676462769508362}, {"text": "JLPT N3 level", "start_pos": 117, "end_pos": 130, "type": "DATASET", "confidence": 0.8016596039136251}]}, {"text": "The first baseline was a method by.", "labels": [], "entities": []}, {"text": "However, because our setting uses only monolingual corpora, only lexical centrality and diversity parts were used from this method.", "labels": [], "entities": []}, {"text": "The method received the same set of example sentences as the DPP, namely search results biased towards syntactically rich sentences near a target word.", "labels": [], "entities": []}, {"text": "The method is referred as DeMelo.", "labels": [], "entities": [{"text": "DeMelo", "start_pos": 26, "end_pos": 32, "type": "DATASET", "confidence": 0.9100463390350342}]}, {"text": "The second baseline was a simple uniform random sampling without replacement.", "labels": [], "entities": []}, {"text": "The data, again, was a list of example sentence candidates from the search system, not raw examples.", "labels": [], "entities": []}, {"text": "This method is referred as Rand.", "labels": [], "entities": [{"text": "Rand", "start_pos": 27, "end_pos": 31, "type": "METRIC", "confidence": 0.6180538535118103}]}, {"text": "For the experiment we have used 14 Japanese words.", "labels": [], "entities": []}, {"text": "Each chosen word has more than one sense and different usages.", "labels": [], "entities": []}, {"text": "Words were also chosen to be relatively easy, to be likely familiar to language learners of lower intermediate level.", "labels": [], "entities": []}, {"text": "For each of the words, top 10k search results from the search engine were extracted as example sentence candidates.", "labels": [], "entities": []}, {"text": "Each of the words had more than 10k containing sentences.", "labels": [], "entities": []}, {"text": "After that, 12 sentences were extracted by each method from each list.", "labels": [], "entities": []}, {"text": "That yields a total of 14 \u00d7 12 \u00d7 3 sentences which were presented to participants of the experiment.", "labels": [], "entities": []}, {"text": "The first part of the evaluation experiment used Japanese language learners as participants.", "labels": [], "entities": []}, {"text": "For each word, participants were presented three lists of example sentences produced by three methods.", "labels": [], "entities": []}, {"text": "The lists were placed side by side in a random order to force participants to read sentence lists in a different order every time.", "labels": [], "entities": []}, {"text": "Participants were asked to select a list which was more useful from their point for putting sentences on flashcards.", "labels": [], "entities": []}, {"text": "After a participant would select a personally preferable list, anonymized names for methods were displayed and the participant was asked to explain the: Learners' votes on the best example lists.", "labels": [], "entities": []}, {"text": "Bold numbers are the majority fora person.", "labels": [], "entities": []}, {"text": "FC means the experience of using flashcards.", "labels": [], "entities": [{"text": "FC", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.870083212852478}]}, {"text": "Level is approximate JLPT-style Japanese language proficiency from N5 (lowest) to N1 (highest).", "labels": [], "entities": [{"text": "JLPT-style", "start_pos": 21, "end_pos": 31, "type": "DATASET", "confidence": 0.6330161690711975}]}, {"text": "The second part experiment was performed by showing the same example sentence lists to a native Japanese language teacher.", "labels": [], "entities": []}, {"text": "In addition to selecting the best list, a teacher was asked to rank from 1 to 5 how appropriate the list was for students of approximately N3 and N2 JLPT levels.", "labels": [], "entities": []}, {"text": "N3 is similar to intermediate and N2 to upperintermediate levels in English.", "labels": [], "entities": []}, {"text": "Similarly to the learners' case, no explicit criteria were given.", "labels": [], "entities": []}, {"text": "Unfortunately, because of time limitations only one teacher have participated in the second part of the evaluation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Learners' votes on the best example lists.  Bold numbers are the majority for a person. FC  means the experience of using flashcards. Level is  approximate JLPT-style Japanese language profi- ciency from N5 (lowest) to N1 (highest).", "labels": [], "entities": [{"text": "FC", "start_pos": 98, "end_pos": 100, "type": "METRIC", "confidence": 0.9964828491210938}, {"text": "JLPT-style Japanese language profi- ciency", "start_pos": 166, "end_pos": 208, "type": "TASK", "confidence": 0.6699666182200114}]}]}