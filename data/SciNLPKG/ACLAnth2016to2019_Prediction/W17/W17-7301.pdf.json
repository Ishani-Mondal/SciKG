{"title": [{"text": "The Effect of Negative Sampling Strategy on Capturing Semantic Similarity in Document Embeddings", "labels": [], "entities": [{"text": "Capturing Semantic Similarity in Document Embeddings", "start_pos": 44, "end_pos": 96, "type": "TASK", "confidence": 0.8701062599817911}]}], "abstractContent": [{"text": "In many machine learning tasks, a model needs to be presented with both correct and incorrect examples during the training.", "labels": [], "entities": []}, {"text": "For instance, given a query, a search engine can be trained to predict the relevant (positive) documents from irrelevant (negative) ones.", "labels": [], "entities": []}, {"text": "While each query is associated with a handful of relevant documents, the number of irrelevant documents can be vast.", "labels": [], "entities": []}, {"text": "This imbalance can bias a document retrieval model while the mere volume of irrelevant documents can result in long training times.", "labels": [], "entities": [{"text": "document retrieval", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.7158346474170685}]}, {"text": "In this paper, we show the affect of a tailored negative sampling on the performance of the Deep Structure Semantic Model (DSSM).", "labels": [], "entities": []}, {"text": "We show that a naive random sampling method outperforms more sophisticated ways of selecting negative data.", "labels": [], "entities": []}], "introductionContent": [{"text": "In many machine learning tasks, it is often the case that negative examples vastly outnumber positive ones.", "labels": [], "entities": []}, {"text": "For instance, in a recommendation system, the number of items that a user has rated or purchased are far less than the total number of items available in the system.", "labels": [], "entities": []}, {"text": "Similarly, in an answer retrieval task for the community question answering platforms, the number of relevant answers to a question is very low compared to the total number of available answers.", "labels": [], "entities": [{"text": "answer retrieval task", "start_pos": 17, "end_pos": 38, "type": "TASK", "confidence": 0.8329054713249207}, {"text": "question answering", "start_pos": 57, "end_pos": 75, "type": "TASK", "confidence": 0.7245546281337738}]}, {"text": "To address this imbalance, negative examples are typically down-sampled in accordance with some criteria.", "labels": [], "entities": []}, {"text": "The effect of negative sampling strategy has been studied across a range of machine learning and NLP tasks, with varying results (.", "labels": [], "entities": []}, {"text": "The reason is to selector generate data that challenges a model's capacity to distinguish between seemingly similar items.", "labels": [], "entities": []}, {"text": "The second intuition is associated with distance sampling (, namely selecting negative cases that are as distinct as possible from positive ones in order to ensure the data are properly clustered in the vector space.", "labels": [], "entities": []}, {"text": "The final intuition has led to uniform sampling methods, that is randomly sampling from the space of negative examples.", "labels": [], "entities": []}, {"text": "Adopting the correct negative sampling approach is largely task-dependent (see Section 5).", "labels": [], "entities": []}, {"text": "Our research sought to determine the most suitable strategy for learning semantic similarity.", "labels": [], "entities": [{"text": "learning semantic similarity", "start_pos": 64, "end_pos": 92, "type": "TASK", "confidence": 0.720027357339859}]}, {"text": "In these particular experiments we focused on the widely adopted DSSM model () trained on the task of answer selection in the community question answering platform Yahoo!", "labels": [], "entities": [{"text": "answer selection in the community question answering platform Yahoo!", "start_pos": 102, "end_pos": 170, "type": "TASK", "confidence": 0.7298917680978775}]}, {"text": "Q1: Help im scared!", "labels": [], "entities": []}, {"text": "two of my top adult teeth area little bit loose, will i lose them?", "labels": [], "entities": []}, {"text": "A1: If they are adult teeth, you dentist maybe able to \"tighten\" them ...", "labels": [], "entities": []}, {"text": "Q2: Do I need 2 dental bridges or just one huge one on my teeth?", "labels": [], "entities": []}, {"text": "I have 2 maryland bridges on my top teeth (the teeth on either side of my two top ...", "labels": [], "entities": []}, {"text": "A2: I would suggest cantilever bridges will be more than enough ...", "labels": [], "entities": [{"text": "A2", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.9633941650390625}]}, {"text": "Q3: Can Someone Give Me Links Proving Global Warming Real Or Not?", "labels": [], "entities": [{"text": "Links Proving Global Warming Real", "start_pos": 24, "end_pos": 57, "type": "TASK", "confidence": 0.8806721925735473}]}, {"text": "I believe global warming is real, but lately I realized I don't actually know that global warming is real ...", "labels": [], "entities": []}, {"text": "A3: There are many reason why global warming can occur.", "labels": [], "entities": []}, {"text": "From increased solar input to changes in atmospheric aerosol concentration to albedo and land use changes: The first two QA pairs are under the category and subcategory Health-Dental category.", "labels": [], "entities": []}, {"text": "The last QA is under Environment-Global Warming.", "labels": [], "entities": []}], "datasetContent": [{"text": "We run our experiments on a corpus of Yahoo!", "labels": [], "entities": []}, {"text": "Answers questions and answers, which contains over three million questions and answers.", "labels": [], "entities": [{"text": "Answers questions and answers", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6415846422314644}]}, {"text": "Topic information is available by means of categories and subcategories logged by users when submitting a question.", "labels": [], "entities": []}, {"text": "In our experiments, we use questions for which the following information is available: i) the 'best answer' chosen by the user (used as the positive example), ii) the category and subcategory label.", "labels": [], "entities": []}, {"text": "Negative examples are chosen among other answers according to the preferred negative sampling strategy.", "labels": [], "entities": []}, {"text": "The authors of the DSSM paper () mention that they do not observe any significant difference by using different sampling strategies for the unclicked (irrelevant) documents.", "labels": [], "entities": [{"text": "DSSM paper", "start_pos": 19, "end_pos": 29, "type": "DATASET", "confidence": 0.7164164483547211}]}, {"text": "However, they do not discuss the negative sampling strategies.", "labels": [], "entities": []}, {"text": "In this paper, we study the effect of a refined negative sampling strategy using the category information for the task of answer retrieval in the community question answering platforms.", "labels": [], "entities": [{"text": "answer retrieval", "start_pos": 122, "end_pos": 138, "type": "TASK", "confidence": 0.8429389595985413}, {"text": "question answering", "start_pos": 156, "end_pos": 174, "type": "TASK", "confidence": 0.7025375664234161}]}, {"text": "Intuitively, random sampling has limitations because random examples might not represent all the nuances of semantic dissimilarities.", "labels": [], "entities": []}, {"text": "We hypothesize that providing informative negative examples can help the model to learn more separable embeddings across different topics and within the same topic.", "labels": [], "entities": []}, {"text": "Moreover, refined negative sampling may help the model to converge faster (since we provide it with information we believe is more vital from early on).", "labels": [], "entities": []}, {"text": "We examine this hypothesis using the three experiments described below.", "labels": [], "entities": []}, {"text": "No Category In this experiment, even though we have access to the category information, in order to provide a baseline, no category information is provided during the training.", "labels": [], "entities": []}, {"text": "Since our refined negative sampling strategy uses category information, we only employ random negative sampling.", "labels": [], "entities": []}, {"text": "Category -Random Negative Sampling In this experiment, category and subcategory information is included in the representation of each document as one-hot vectors.", "labels": [], "entities": []}, {"text": "Negative answers for each question are sampled randomly from the pool of all answers across all categories and subcategories.", "labels": [], "entities": []}, {"text": "Category -Refined Negative Sampling Similarly to the above experiment, here the category and subcategory information is included.", "labels": [], "entities": []}, {"text": "However, instead of random negative sampling, we use the refined negative sampling method described in Section 2.1.", "labels": [], "entities": []}, {"text": "At test time, when searching for the correct answer, we search through two spaces.", "labels": [], "entities": []}, {"text": "First, since the user has specified the category of the question, we use this category information to limit the search space by filtering for answers within the same category.", "labels": [], "entities": []}, {"text": "This experiment tests the extent to which embeddings are separable within the same category.", "labels": [], "entities": []}, {"text": "Second, we search through all the answers across all the categories.", "labels": [], "entities": []}, {"text": "This is because we want to test whether the learned embeddings of questions are separable from the answers both globally and in the neighbourhood of the same category.", "labels": [], "entities": []}, {"text": "Evaluation We divide our dataset into train, dev and test sets.", "labels": [], "entities": []}, {"text": "We use the dev set to decide when to stop the training and test set to report the evaluation results.", "labels": [], "entities": []}, {"text": "While we run the experiments with a varying number of QAs in the training set, the dev and the test set each contain 20k QAs.", "labels": [], "entities": []}, {"text": "We report results using Mean Recall@1, Mean Recall@5 and MRR (mean reciprocal rank) ().", "labels": [], "entities": [{"text": "Mean Recall@1", "start_pos": 24, "end_pos": 37, "type": "METRIC", "confidence": 0.9354685097932816}, {"text": "Mean Recall@5", "start_pos": 39, "end_pos": 52, "type": "METRIC", "confidence": 0.934836745262146}, {"text": "MRR", "start_pos": 57, "end_pos": 60, "type": "METRIC", "confidence": 0.9974815249443054}, {"text": "mean reciprocal rank)", "start_pos": 62, "end_pos": 83, "type": "METRIC", "confidence": 0.7333025112748146}]}], "tableCaptions": []}