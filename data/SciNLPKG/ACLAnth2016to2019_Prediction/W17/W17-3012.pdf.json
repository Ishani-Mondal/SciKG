{"title": [{"text": "Understanding Abuse: A Typology of Abusive Language Detection Subtasks", "labels": [], "entities": [{"text": "Understanding Abuse", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8747624158859253}, {"text": "Abusive Language Detection Subtasks", "start_pos": 35, "end_pos": 70, "type": "TASK", "confidence": 0.7441433519124985}]}], "abstractContent": [{"text": "As the body of research on abusive language detection and analysis grows, there is a need for critical consideration of the relationships between different subtasks that have been grouped under this label.", "labels": [], "entities": [{"text": "abusive language detection and analysis", "start_pos": 27, "end_pos": 66, "type": "TASK", "confidence": 0.681816178560257}]}, {"text": "Based on work on hate speech, cyberbully-ing, and online abuse we propose a typol-ogy that captures central similarities and differences between subtasks and we discuss its implications for data annotation and feature construction.", "labels": [], "entities": [{"text": "feature construction", "start_pos": 210, "end_pos": 230, "type": "TASK", "confidence": 0.7417673170566559}]}, {"text": "We emphasize the practical actions that can betaken by researchers to best approach their abusive language detection subtask of interest.", "labels": [], "entities": [{"text": "betaken", "start_pos": 44, "end_pos": 51, "type": "TASK", "confidence": 0.9564236402511597}, {"text": "abusive language detection subtask", "start_pos": 90, "end_pos": 124, "type": "TASK", "confidence": 0.7393068075180054}]}], "introductionContent": [{"text": "There has been a surge in interest in the detection of abusive language, hate speech, cyberbullying, and trolling in the past several years (.", "labels": [], "entities": [{"text": "detection of abusive language", "start_pos": 42, "end_pos": 71, "type": "TASK", "confidence": 0.8089300841093063}]}, {"text": "Social media sites have also come under increasing pressure to tackle these issues.", "labels": [], "entities": []}, {"text": "Similarities between these subtasks have led scholars to group them together under the umbrella terms of \"abusive language\", \"harmful speech\", and \"hate speech\" ( but little work has been done to examine the relationship between them.", "labels": [], "entities": []}, {"text": "As each of these subtasks seeks to address a specific yet partially overlapping phenomenon, we believe that there is much to gain by studying how they are related.", "labels": [], "entities": []}, {"text": "The overlap between subtasks is illustrated by the variety of labels used in prior work.", "labels": [], "entities": []}, {"text": "For example, in annotating for cyberbullying events, Van Hee et al.", "labels": [], "entities": []}, {"text": "(2015b) identifies discriminative remarks (racist, sexist) as a subset of \"insults\", whereas classifies similar remarks as \"hate speech\" or \"derogatory language\".", "labels": [], "entities": []}, {"text": "only consider \"hate speech\" without regard to any potential overlap with bullying or otherwise offensive language, while distinguish hate speech from generally offensive language.", "labels": [], "entities": []}, {"text": "annotates for personal attacks, which likely encompasses identifying cyberbullying, hate speech, and offensive language.", "labels": [], "entities": []}, {"text": "The lack of consensus has resulted in contradictory annotation guidelines -some messages considered as hate speech by are only considered derogatory and offensive by and.", "labels": [], "entities": []}, {"text": "To help to bring together these literatures and to avoid these contradictions, we propose a typology that synthesizes these different subtasks.", "labels": [], "entities": []}, {"text": "We argue that the differences between subtasks within abusive language can be reduced to two primary factors: 1.", "labels": [], "entities": []}, {"text": "Is the language directed towards a specific individual or entity or is it directed towards a generalized group?", "labels": [], "entities": []}, {"text": "2. Is the abusive content explicit or implicit?", "labels": [], "entities": []}, {"text": "Each of the different subtasks related to abu-sive language occupies one or more segments of this typology.", "labels": [], "entities": []}, {"text": "Our aim is to clarify the similarities and differences between subtasks in abusive language detection to help researchers select appropriate strategies for data annotation and modeling.", "labels": [], "entities": [{"text": "abusive language detection", "start_pos": 75, "end_pos": 101, "type": "TASK", "confidence": 0.6627492507298788}]}], "datasetContent": [], "tableCaptions": []}