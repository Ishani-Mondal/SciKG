{"title": [{"text": "Learning when to skim and when to read", "labels": [], "entities": [{"text": "skim", "start_pos": 17, "end_pos": 21, "type": "TASK", "confidence": 0.9403716921806335}, {"text": "read", "start_pos": 34, "end_pos": 38, "type": "TASK", "confidence": 0.3370087742805481}]}], "abstractContent": [{"text": "Many recent advances in deep learning for natural language processing have come at increasing computational cost, but the power of these state-of-the-art models is not needed for every example in a dataset.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 42, "end_pos": 69, "type": "TASK", "confidence": 0.6888929406801859}]}, {"text": "We demonstrate two approaches to reducing unnecessary computation in cases where a fast but weak baseline classier and a stronger, slower model are both available.", "labels": [], "entities": []}, {"text": "Applying an AUC-based metric to the task of sentiment classification, we find significant efficiency gains with both a probability-threshold method for reducing computational cost and one that uses a secondary decision network.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 44, "end_pos": 68, "type": "TASK", "confidence": 0.9658060371875763}]}], "introductionContent": [{"text": "Deep learning models are getting bigger, better and more computationally expensive in the quest to match or exceed human performance (.", "labels": [], "entities": []}, {"text": "With advances like the sparselygated mixture of experts, pointer sentinel (, or attention mechanisms (, models for natural language processing are growing more complex in order to solve harder linguistic problems.", "labels": [], "entities": []}, {"text": "Many of the problems these new models are designed to solve appear infrequently in realworld datasets, yet the complex model architectures motivated by such problems are employed for every example.", "labels": [], "entities": []}, {"text": "For example, illustrates how a computationally cheap model (continuous bag-of-words) represents and clusters sentences. of the activations of the last hidden layer in a computationally cheap bag-ofwords (BoW) model on the binary Stanford Sentiment Treebank (SST) dataset.", "labels": [], "entities": [{"text": "Stanford Sentiment Treebank (SST) dataset", "start_pos": 229, "end_pos": 270, "type": "DATASET", "confidence": 0.8228341170719692}]}, {"text": "Each data point is one sentence, while the plot has been annotated with qualitative descriptions.", "labels": [], "entities": []}, {"text": "Clusters with simple syntax and semantics (\"simple linguistic content\") tend to be classified correctly more often than clusters with difficult linguistic content.", "labels": [], "entities": []}, {"text": "In particular, the BoW model is agnostic to word order and fails to accurately classify sentences with contrastive conjunctions.", "labels": [], "entities": [{"text": "BoW", "start_pos": 19, "end_pos": 22, "type": "DATASET", "confidence": 0.8562905788421631}, {"text": "word order", "start_pos": 44, "end_pos": 54, "type": "TASK", "confidence": 0.6884741187095642}]}, {"text": "This paper starts with the intuition that exclusively using a complex model leads to inefficient use of resources when dealing with more straightforward input examples.", "labels": [], "entities": []}, {"text": "To remedy this, we propose two strategies for reducing inefficiency based on learning to classify the difficulty of a sentence.", "labels": [], "entities": []}, {"text": "In both strategies, if we can determine that a sentence is easy, we use a computationally cheap bagof-words (\"skimming\").", "labels": [], "entities": []}, {"text": "If we cannot, we default: Accuracy for thresholding on binary SST.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9906065464019775}]}, {"text": "Probability thresholds are the maximum of the probability for the two classes.", "labels": [], "entities": [{"text": "Probability thresholds", "start_pos": 0, "end_pos": 22, "type": "METRIC", "confidence": 0.9334092736244202}]}, {"text": "The green bars corresponds to accuracy for each probability bucket (examples within a given probability span, e.g. 0.5 < Pr(Y |X, \u03b8 BoW ) < 0.55), while the orange curve corresponds the accuracy of all examples with a probability above a given threshold (e.g. Pr(Y |X, \u03b8 BoW ) < 0.7).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9992167949676514}, {"text": "accuracy", "start_pos": 186, "end_pos": 194, "type": "METRIC", "confidence": 0.9987026453018188}]}, {"text": "to an LSTM (reading).", "labels": [], "entities": []}, {"text": "The first strategy uses the probability output of the BoW system as a confidence measure.", "labels": [], "entities": [{"text": "BoW system", "start_pos": 54, "end_pos": 64, "type": "DATASET", "confidence": 0.9406940042972565}]}, {"text": "The second strategy employs a decision network to learn the relationship between the BoW and the LSTM.", "labels": [], "entities": [{"text": "BoW", "start_pos": 85, "end_pos": 88, "type": "DATASET", "confidence": 0.9331320524215698}]}, {"text": "Both strategies increase efficiency as measured by an area-under-the-curve (AUC) metric.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Results for each decision strategy. The AUC is the mean value of the curve from 5. Each model  is trained ten times with different initialization, and results are reported as mean and standard deviation  over the ten runs.", "labels": [], "entities": [{"text": "AUC", "start_pos": 50, "end_pos": 53, "type": "METRIC", "confidence": 0.9913661479949951}]}]}