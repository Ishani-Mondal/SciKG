{"title": [], "abstractContent": [{"text": "In this paper we explore several neural network architectures for the WMT 2017 multimodal translation sub-task on multilingual image caption generation.", "labels": [], "entities": [{"text": "WMT 2017 multimodal translation sub-task", "start_pos": 70, "end_pos": 110, "type": "TASK", "confidence": 0.7144268155097961}, {"text": "multilingual image caption generation", "start_pos": 114, "end_pos": 151, "type": "TASK", "confidence": 0.694717288017273}]}, {"text": "The goal of the task is to generate image captions in German, using a training corpus of images with captions in both English and German.", "labels": [], "entities": []}, {"text": "We explore several models which attempt to generate captions for both languages, ignoring the English output during evaluation.", "labels": [], "entities": []}, {"text": "We compare the results to a baseline implementation which uses only the German captions for training and show significant improvement.", "labels": [], "entities": []}], "introductionContent": [{"text": "Neural models have shown great success on a variety of tasks, including machine translation ( ), image caption generation (, and language modeling (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 72, "end_pos": 91, "type": "TASK", "confidence": 0.8343345820903778}, {"text": "image caption generation", "start_pos": 97, "end_pos": 121, "type": "TASK", "confidence": 0.8688340584437052}, {"text": "language modeling", "start_pos": 129, "end_pos": 146, "type": "TASK", "confidence": 0.7788795828819275}]}, {"text": "Recently, huge datasets necessary for training these models have become more widely available, but there are still many limitations.", "labels": [], "entities": []}, {"text": "In some cases, the dataset which is available may not match the domain of the task.", "labels": [], "entities": []}, {"text": "In this paper, we attempt to generate image captions in German, using a training corpus of images with captions in both English and German.", "labels": [], "entities": []}, {"text": "For each image, we have 5 independently generated captions in each language.", "labels": [], "entities": []}, {"text": "Since the training corpus is relatively small (less than 30,000 images), we want to make use of the English language data to improve the German captions.", "labels": [], "entities": []}, {"text": "It is important to note that since these captions were generated independently in each language rather than translated, they often differ from each other quite a bit.", "labels": [], "entities": []}, {"text": "Not only do they often choose to describe different features of an image, but also they sometimes describe contradictory features of the image (one caption describing a man sleeping on a couch while a different caption describes a woman sleeping on a couch).", "labels": [], "entities": []}, {"text": "This inconsistency and the relatively small amount of training data makes it very difficult to train a reliable translation system between the languages based on this corpus.", "labels": [], "entities": []}, {"text": "In this paper, we will start by discussing related work in image caption generation.", "labels": [], "entities": [{"text": "image caption generation", "start_pos": 59, "end_pos": 83, "type": "TASK", "confidence": 0.8702912131945292}]}, {"text": "Then we will explain the baseline German image caption generation model, the soft attention model from.", "labels": [], "entities": [{"text": "German image caption generation", "start_pos": 34, "end_pos": 65, "type": "TASK", "confidence": 0.8050475716590881}]}, {"text": "Several methods of incorporating the English data to improve the performance will be described.", "labels": [], "entities": []}, {"text": "Finally, the experimental setup will be specified and the results will be evaluated.", "labels": [], "entities": []}], "datasetContent": [{"text": "All models were implemented using DyNet (, specifically using the VanillaLSTM class.", "labels": [], "entities": []}, {"text": "Models were trained using the Adam optimizer ().", "labels": [], "entities": []}, {"text": "Multi30k, an expanded of the Flickr 30k training data, was provided for the WMT multimodal task 2 constrained setting (Elliott et al., 2016) and: Attention Pipeline.", "labels": [], "entities": [{"text": "Flickr 30k training data", "start_pos": 29, "end_pos": 53, "type": "DATASET", "confidence": 0.9012449234724045}, {"text": "WMT multimodal task 2 constrained setting", "start_pos": 76, "end_pos": 117, "type": "TASK", "confidence": 0.5129929631948471}]}, {"text": "At each timestep as the German caption is being generated, we produce an embedding (box with dashed outline).", "labels": [], "entities": []}, {"text": "Depending on whether we are using averaged embeddings or random embeddings, this is either (1) the weighted average of all words in the vocabulary, or (2) the contribution of one randomly selected word to that weighted average.", "labels": [], "entities": []}, {"text": "An LSTM with attention produces an English caption using these embeddings.", "labels": [], "entities": []}, {"text": "Each of the models used LSTM hidden size 512, embedding size 512, and hidden dimension 256 for the Attention MLP.", "labels": [], "entities": []}, {"text": "The one exception was AT-TAVG which due to memory limits used LSTM hidden size 256, embedding size 256, and hidden dimension 256 for the attention MLP.", "labels": [], "entities": [{"text": "AT-TAVG", "start_pos": 22, "end_pos": 29, "type": "DATASET", "confidence": 0.9232533574104309}]}, {"text": "Minibatching was used, with each batch formed by grouping together similar length captions to improve efficiency.", "labels": [], "entities": []}, {"text": "Minibatch sizes, vocabulary sizes, and dropout settings are noted in table 1.", "labels": [], "entities": []}, {"text": "The order of the batches was randomized on each epoch.", "labels": [], "entities": []}, {"text": "Models were trained until the perplexity on the validation set no longer improved.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Model evaluation results. * indicates statistically significant improvement relative to baseline  1 (p < 0.05) with paired bootstrap resampling, based on BLEU-4 score on the 2016 test set. Multiple  combinations of vocabulary size, minibatch size, and dropout were tested for each model, but only the  best combination (by BLEU score on the validation set) is reported here.", "labels": [], "entities": [{"text": "BLEU-4", "start_pos": 164, "end_pos": 170, "type": "METRIC", "confidence": 0.99871826171875}, {"text": "BLEU", "start_pos": 333, "end_pos": 337, "type": "METRIC", "confidence": 0.9986420273780823}]}]}