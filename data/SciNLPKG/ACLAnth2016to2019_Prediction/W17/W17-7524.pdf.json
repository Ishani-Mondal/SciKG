{"title": [{"text": "Reasoning with Sets to Solve Simple Word Problems Automatically", "labels": [], "entities": [{"text": "Reasoning with Sets to Solve Simple Word Problems Automatically", "start_pos": 0, "end_pos": 63, "type": "TASK", "confidence": 0.8078727324803671}]}], "abstractContent": [{"text": "A system, Magi, is proposed, which analyses simple addition/subtraction arithmetic word problems expressed in English, represents them in the form of schemas and sets, reasons with set cardinalities and presents the final answer in English phrases.", "labels": [], "entities": []}, {"text": "It also provides simple explanations.", "labels": [], "entities": []}, {"text": "This work presents a study of the features of a knowledge-based system used for solving such a task.", "labels": [], "entities": []}, {"text": "It has been evaluated and has been found to perform better than current knowledge-based systems for similar problems.", "labels": [], "entities": []}], "introductionContent": [{"text": "Natural language understanding is one of the key elements of human intelligence.", "labels": [], "entities": [{"text": "Natural language understanding", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7139381766319275}]}, {"text": "Hence, it has attracted the attention of a sizeable population of researchers of artificial intelligence.", "labels": [], "entities": []}, {"text": "The first published work in this field attempted to solve word problems presented to a computer in English.", "labels": [], "entities": []}, {"text": "The appeal of solving word problems lies in the fact that semantic understanding is required to map the word problem to a mathematical framework.", "labels": [], "entities": []}, {"text": "Input: Keith has 20 books . Jason has 21 books . How many books do they have together?", "labels": [], "entities": [{"text": "Input", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9681575894355774}]}, {"text": "Output: Altogether 41 books Here, the system has to map the word 'they' to '.", "labels": [], "entities": []}, {"text": "This is an example of co-reference resolution.", "labels": [], "entities": [{"text": "co-reference resolution", "start_pos": 22, "end_pos": 45, "type": "TASK", "confidence": 0.7335150241851807}]}, {"text": "Next, the notion of associating '20 books' to ' to 'Jason' has to be captured.", "labels": [], "entities": []}, {"text": "These relevant details are also extracted.", "labels": [], "entities": []}, {"text": "The last piece of information required is the word 'together' that signifies what is the goal of the problem.", "labels": [], "entities": []}, {"text": "In this work, these details are extracted by using the Stanford Core NLP () suite of tools extensively.", "labels": [], "entities": [{"text": "Stanford Core NLP", "start_pos": 55, "end_pos": 72, "type": "DATASET", "confidence": 0.9409158825874329}]}, {"text": "Other approaches include semantic parsing (, learning equation co-efficients ( ), learning expression trees () and soon.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 25, "end_pos": 41, "type": "TASK", "confidence": 0.7857168912887573}]}, {"text": "In this work, as the principle was to build as precise a system as possible, we've used a rule based approach.", "labels": [], "entities": []}, {"text": "The motivation was that if this tool was used by a student, she should be able to seethe trace of the solution.", "labels": [], "entities": []}, {"text": "In order to know what are the elements that are to be extracted from the word problem, some model of word problems must be encoded into the system.", "labels": [], "entities": []}, {"text": "This is the role of knowledge representation.", "labels": [], "entities": [{"text": "knowledge representation", "start_pos": 20, "end_pos": 44, "type": "TASK", "confidence": 0.7122797966003418}]}, {"text": "Here, knowledge representation is in the form of schemas that are templates for solving problems.", "labels": [], "entities": [{"text": "knowledge representation", "start_pos": 6, "end_pos": 30, "type": "TASK", "confidence": 0.6931721270084381}]}, {"text": "They describe common categories of word problems.", "labels": [], "entities": []}, {"text": "The schema for the above problem is 'combine' which describes that the answer is the sum of entities in question.", "labels": [], "entities": []}, {"text": "Internally, this idea is represented as sets for closer coupling to the semantics of the problem.", "labels": [], "entities": []}, {"text": "t 0 Jason has B books Keith has A books --------A 20 B 21 The next step is reasoning.", "labels": [], "entities": [{"text": "reasoning", "start_pos": 75, "end_pos": 84, "type": "TASK", "confidence": 0.9538049697875977}]}, {"text": "The schema 'combine' directs that the sum of the 'books' owned by 'Jason' and 'Keith' is required.", "labels": [], "entities": [{"text": "combine", "start_pos": 12, "end_pos": 19, "type": "METRIC", "confidence": 0.9622073173522949}]}, {"text": "The answer is computed by adding the cardinalities of A and B.", "labels": [], "entities": []}, {"text": "The final answer, '41' is presented as 'Altogether 41 books'.", "labels": [], "entities": []}, {"text": "The last step of generating the answer is facilitated by the schema as well.", "labels": [], "entities": []}, {"text": "The challenges in this problem solving process are high.", "labels": [], "entities": [{"text": "problem solving", "start_pos": 23, "end_pos": 38, "type": "TASK", "confidence": 0.9411666989326477}]}, {"text": "This is because natural language processing is difficult and often ambiguous or 188 may rely on implicit details.", "labels": [], "entities": []}, {"text": "Magi resolves some of the ambiguities by reasoning about implicit events and making some assumptions.", "labels": [], "entities": []}, {"text": "There are some ambiguities in schema identification as well which have been partially addressed using some heuristics.", "labels": [], "entities": [{"text": "schema identification", "start_pos": 30, "end_pos": 51, "type": "TASK", "confidence": 0.7866877913475037}]}, {"text": "While computing elementary problems, numerical efficiency of computers is much more.", "labels": [], "entities": []}, {"text": "The challenging task is the introduction of language and representing the information extracted from the natural language.", "labels": [], "entities": []}], "datasetContent": [{"text": "Magi has been coded in Java 1.7 and has used the same version of () parser as the one used by ARIS () fora fair evaluation.", "labels": [], "entities": []}, {"text": "The work has been compared against other knowledge based systems.", "labels": [], "entities": []}, {"text": "Magi has been evaluated on the three datasets, DS1, DS2 and DS3 provided by (Hosseini et al., with respect to three other systems.", "labels": [], "entities": []}, {"text": "One is ROBUST which has been discussed before.", "labels": [], "entities": [{"text": "ROBUST", "start_pos": 7, "end_pos": 13, "type": "TASK", "confidence": 0.46106666326522827}]}, {"text": "It attempted to learn the equation categorising verbs.", "labels": [], "entities": []}, {"text": "They also presented an algorithm for learning that information.", "labels": [], "entities": []}, {"text": "However, by limiting themselves to verbs (change schemas), other schemas such as 'combine' and 'compare' were missed.", "labels": [], "entities": []}, {"text": "As we have not performed any empirical method to learn the keyword-schema mapping, the system for comparison is is another system that solves math word problems on the Internet without divulging implementation details.", "labels": [], "entities": []}, {"text": "The increased performance over Gold ARIS is because of the use of heuristics, addressing set completion and handling implicit events.", "labels": [], "entities": [{"text": "Gold ARIS", "start_pos": 31, "end_pos": 40, "type": "DATASET", "confidence": 0.8054162561893463}]}, {"text": "Also, simplifying the problem and performing some reasoning with the language helped reduce parser errors mentioned in ().", "labels": [], "entities": []}, {"text": "ROBUST performs relatively better with DS1 because it consists of simple sentences.", "labels": [], "entities": [{"text": "ROBUST", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.6060360074043274}]}, {"text": "As the complexity of processing English increases, the performance of both ROBUST and WolframAlpha reduces.", "labels": [], "entities": [{"text": "ROBUST", "start_pos": 75, "end_pos": 81, "type": "DATASET", "confidence": 0.49877336621284485}, {"text": "WolframAlpha", "start_pos": 86, "end_pos": 98, "type": "DATASET", "confidence": 0.9314794540405273}]}], "tableCaptions": []}