{"title": [{"text": "A Tale of Two DRAGGNs: A Hybrid Approach for Interpreting Action-Oriented and Goal-Oriented Instructions", "labels": [], "entities": []}], "abstractContent": [{"text": "Robots operating alongside humans in diverse , stochastic environments must be able to accurately interpret natural language commands.", "labels": [], "entities": []}, {"text": "These instructions often fall into one of two categories: those that specify a goal condition or target state, and those that specify explicit actions, or how to perform a given task.", "labels": [], "entities": []}, {"text": "Recent approaches have used reward functions as a semantic representation of goal-based commands, which allows for the use of a state-of-the-art planner to find a policy for the given task.", "labels": [], "entities": []}, {"text": "However, these reward functions cannot be directly used to represent action-oriented commands.", "labels": [], "entities": []}, {"text": "We introduce anew hybrid approach, the Deep Recurrent Action-Goal Grounding Network (DRAGGN), for task grounding and execution that handles natural language from either category as input, and generalizes to unseen environments.", "labels": [], "entities": []}, {"text": "Our robot-simulation results demonstrate that a system successfully interpreting both goal-oriented and action-oriented task specifications brings us closer to robust natural language understanding for human-robot interaction.", "labels": [], "entities": []}], "introductionContent": [{"text": "Natural language affords a convenient choice for delivering instructions to robots, as it offers flexibility, familiarity, and does not require users to have knowledge of low-level programming.", "labels": [], "entities": []}, {"text": "In the context of grounding natural language instructions to tasks, human-robot instructions can be interpreted as either high-level goal specifications or low-level instructions for the robot to execute., used throughout this work.", "labels": [], "entities": []}, {"text": "A possible goal-based instruction could be \"Take the chair to the green room,\" while a possible action-based instruction could be \"Go three steps south, then two steps west.\"", "labels": [], "entities": []}, {"text": "Goal-oriented commands define a particular target state specifying where a robot should end up, whereas action-oriented commands specify a particular sequence of actions to be executed.", "labels": [], "entities": []}, {"text": "For example, a human instructing a robot to \"go to the kitchen\" outlines a goal condition to check if the robot is in the kitchen.", "labels": [], "entities": []}, {"text": "Alternatively, a human providing the command \"take three steps to the left\" defines a trajectory for the robot to execute.", "labels": [], "entities": []}, {"text": "We need to consider both forms of commands to understand the full space of natural language that humans may use to communicate their intent to robots.", "labels": [], "entities": []}, {"text": "While humans also combine commands of both types into a single instruction, we make the simplifying assumption that a command belongs entirely to a single type and leave the task of handling mixtures and compositions to future work.", "labels": [], "entities": []}, {"text": "Existing approaches can be broadly divided into one of two regimes.", "labels": [], "entities": []}, {"text": "Goal-based approaches like: System for grounding both actionoriented (left branch) and goal-oriented (right branch) natural language instructions to executable robot tasks.", "labels": [], "entities": []}, {"text": "Our main contribution is the hybrid interpretation system (blue box), for which we present two novel models based on the DRAGGN framework (J-DRAGGN and I-DRAGGN) in Section 4. and leverage some intermediate task representation and then automatically find a low-level trajectory to achieve the goal using a planner.", "labels": [], "entities": []}, {"text": "Other approaches, in the action-oriented regime, directly infer action sequences from the syntactic or semantic parse structure of natural language.", "labels": [], "entities": []}, {"text": "However, these approaches can be computationally intractable for large state-action spaces or use adhoc methods to execute high-level language rather than relying on a planner.", "labels": [], "entities": []}, {"text": "Furthermore, these methods are unable to adapt to dynamic changes in the environment; for example, consider an environment in which the wind, or some other force moves an object that a robot has been tasked with picking.", "labels": [], "entities": []}, {"text": "Action sequence based approaches would fail to handle this without additional user input, while goal-based approaches would be able to replan on the fly, and complete the task.", "labels": [], "entities": []}, {"text": "To address the issue of dealing with both goal-oriented and action-oriented commands, we present anew language grounding framework that, given a natural language command, is capable of inferring the latent command type.", "labels": [], "entities": []}, {"text": "Recent approaches leveraging deep neural networks have formulated the language grounding problem as sequence-to-sequence learning or multi-label classification (.", "labels": [], "entities": [{"text": "multi-label classification", "start_pos": 133, "end_pos": 159, "type": "TASK", "confidence": 0.7046819776296616}]}, {"text": "Inspired by the recent success of neural networks to model programs that are highly compositional and sequential in nature, we present the Deep Recurrent Action/Goal Grounding Network (DRAGGN) framework, derived from the the Neural Programmer-Interpreter (NPI) of Reed and de and outlined in Section 4.2.", "labels": [], "entities": []}, {"text": "We introduce two instances of DRAGGN models, each with slightly different architectures.", "labels": [], "entities": []}, {"text": "The first, the Joint-DRAGGN (J-DRAGGN) is defined in Section 4.3, while the second, the Independent-DRAGGN (I-DRAGGN) is defined in Section 4.4.", "labels": [], "entities": []}], "datasetContent": [{"text": "We assess the effectiveness of both our J-DRAGGN and I-DRAGGN models via instruction grounding accuracy for robot navigation and mobile-manipulation tasks.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9479184150695801}, {"text": "robot navigation", "start_pos": 108, "end_pos": 124, "type": "TASK", "confidence": 0.7536752820014954}]}, {"text": "As a baseline, we compare against the state-of-the-art Single-RNN model introduced by.", "labels": [], "entities": []}], "tableCaptions": []}