{"title": [{"text": "NICT-NAIST System for WMT17 Multimodal Translation Task", "labels": [], "entities": [{"text": "WMT17 Multimodal Translation", "start_pos": 22, "end_pos": 50, "type": "TASK", "confidence": 0.7940667072931925}]}], "abstractContent": [{"text": "This paper describes the NICT-NAIST system for the WMT 2017 shared multi-modal machine translation task for both language pairs, English-to-German and English-to-French.", "labels": [], "entities": [{"text": "WMT 2017 shared multi-modal machine translation task", "start_pos": 51, "end_pos": 103, "type": "TASK", "confidence": 0.7367351055145264}]}, {"text": "We built a hierarchical phrase-based (Hiero) translation system and trained an attentional encoder-decoder neural machine translation (NMT) model to rerank the n-best output of the Hiero system, which obtained significant gains over both the Hiero system and NMT decoding alone.", "labels": [], "entities": [{"text": "phrase-based (Hiero) translation", "start_pos": 24, "end_pos": 56, "type": "TASK", "confidence": 0.6589247584342957}, {"text": "attentional encoder-decoder neural machine translation", "start_pos": 79, "end_pos": 133, "type": "TASK", "confidence": 0.6028649568557739}]}, {"text": "We also present a multi-modal NMT model that integrates the target language descriptions of images that are similar to the image described by the source sentence as additional inputs of the neural networks to help the translation of the source sentence.", "labels": [], "entities": []}, {"text": "We give detailed analysis for the results of the multimodal NMT model.", "labels": [], "entities": []}, {"text": "Our system obtained the first place for the English-to-French task according to human evaluation.", "labels": [], "entities": []}], "introductionContent": [{"text": "We participated in the WMT 2017 shared multimodal machine translation task 1, which translates a source language description of an image into a target language description.", "labels": [], "entities": [{"text": "WMT 2017 shared multimodal machine translation task 1", "start_pos": 23, "end_pos": 76, "type": "TASK", "confidence": 0.6806082800030708}]}, {"text": "We built systems for both English-to-German and English-toFrench language pairs.", "labels": [], "entities": []}, {"text": "Our baseline systems only use text information.", "labels": [], "entities": []}, {"text": "We compared three text-only approaches: a hierarchical phrase-based (Hiero) translation system (, an attentional encoder-decoder neural machine translation (NMT) system), and a system using the NMT model to rerank the n-best output of the Hiero system.", "labels": [], "entities": [{"text": "phrase-based (Hiero) translation", "start_pos": 55, "end_pos": 87, "type": "TASK", "confidence": 0.6269988417625427}, {"text": "attentional encoder-decoder neural machine translation (NMT)", "start_pos": 101, "end_pos": 161, "type": "TASK", "confidence": 0.7257678173482418}]}, {"text": "We also explored ways to improve the NMT model with image information.", "labels": [], "entities": []}, {"text": "Compared to previous multimodal NMT (MNMT) models that integrate visual features directly, we first exploit image retrieval methods to obtain images that are similar to the image described by the source sentence, and then integrate the target language descriptions of these similar images into the NMT model to help the translation of the source sentence.", "labels": [], "entities": []}, {"text": "This makes it possible to exploit a large corpus with only images and target language descriptions through an image retrieval step.", "labels": [], "entities": []}, {"text": "This is similar to's multimodal pivots method, which uses target descriptions of similar images for reranking MT outputs, while we use these target descriptions as additional inputs for the NMT model.", "labels": [], "entities": [{"text": "MT outputs", "start_pos": 110, "end_pos": 120, "type": "TASK", "confidence": 0.8693434000015259}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Image retrieval examples (two most similar images for each query image). Description is  the English descriptions for query and result images. Distance is the Euclidean distance between image  vectors.", "labels": [], "entities": [{"text": "Distance", "start_pos": 153, "end_pos": 161, "type": "METRIC", "confidence": 0.9774001240730286}]}, {"text": " Table 2: Results of text-only approaches (BLEU).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 43, "end_pos": 47, "type": "METRIC", "confidence": 0.9958820343017578}]}, {"text": " Table 4: Comparison of the NMT model and the  MNMT model (BLEU).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.8492880463600159}]}, {"text": " Table 5: Official evaluation results on the 2017  Flickr test sets.", "labels": [], "entities": [{"text": "Flickr test sets", "start_pos": 51, "end_pos": 67, "type": "DATASET", "confidence": 0.9557743271191915}]}]}