{"title": [], "abstractContent": [], "introductionContent": [{"text": "The 6th Workshop on took place in Valencia as part of EACL'17.", "labels": [], "entities": [{"text": "EACL'17", "start_pos": 54, "end_pos": 61, "type": "DATASET", "confidence": 0.8533214330673218}]}, {"text": "The workshop is organised by the European Network on Integrating Vision and Language which is funded as a European COST Action.", "labels": [], "entities": []}, {"text": "The VL workshops have the general aims: to provide a forum for reporting and discussing planned, ongoing and completed research that involves both language and vision; and to enable NLP and computer vision researchers to meet, exchange ideas, expertise and technology, and form new research partnerships.", "labels": [], "entities": []}, {"text": "Research involving both language and vision computing spans a variety of disciplines and applications, and goes back a number of decades.", "labels": [], "entities": []}, {"text": "Ina recent scene shift, the big data era has thrown up a multitude of tasks in which vision and language are inherently linked.", "labels": [], "entities": []}, {"text": "The explosive growth of visual and textual data, both online and in private repositories by diverse institutions and companies, has led to urgent requirements in terms of search, processing and management of digital content.", "labels": [], "entities": []}, {"text": "Solutions for providing access to or mining such data effectively depend on the connection between visual and textual content being made interpretable, hence on the 'semantic gap' between vision and language being bridged.", "labels": [], "entities": []}, {"text": "One perspective has been integrated modelling of language and vision, with approaches located at different points between the structured, cognitive modelling end of the spectrum, and the unsupervised machine learning end, with state-of-the-art results in many areas currently being produced at the latter end, in particular by deep learning approaches.", "labels": [], "entities": []}, {"text": "Another perspective is exploring how knowledge about language can help with predominantly visual tasks, and vice versa.", "labels": [], "entities": []}, {"text": "Visual interpretation can be aided by text associated with images/videos and knowledge about the world learned from language.", "labels": [], "entities": [{"text": "Visual interpretation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7184879332780838}]}, {"text": "On the NLP side, images can help ground language in the physical world, allowing us to develop models for semantics.", "labels": [], "entities": []}, {"text": "Words and pictures are often naturally linked online and in the real world, and each modality can provide reinforcing information to aid the other.", "labels": [], "entities": []}, {"text": "We would like to thank all the people who have contributed to the organisation and delivery of this workshop: the authors who submitted high quality papers; the programme committee for their prompt and effective reviewing; our keynote speakers; the ACL 2017 organising committee, and future readers of these proceedings for your shared interest in this exciting area of research.", "labels": [], "entities": [{"text": "ACL 2017 organising", "start_pos": 249, "end_pos": 268, "type": "DATASET", "confidence": 0.8878764112790426}]}], "datasetContent": [], "tableCaptions": []}