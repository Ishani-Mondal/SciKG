{"title": [{"text": "Graph Databases for Designing High-Performance Speech Recognition Grammars", "labels": [], "entities": [{"text": "Designing High-Performance Speech Recognition Grammars", "start_pos": 20, "end_pos": 74, "type": "TASK", "confidence": 0.7134768784046173}]}], "abstractContent": [{"text": "The present paper reports on the advantages of using graph databases in the development of dynamic language models in Spoken Language Understanding applications, such as spoken dialogue systems.", "labels": [], "entities": [{"text": "Spoken Language Understanding", "start_pos": 118, "end_pos": 147, "type": "TASK", "confidence": 0.8098561962445577}]}, {"text": "First of all, we introduce Neo4J graph databases and, specifically, MultiWordNet-Extended, a graph representing linguistic knowledge.", "labels": [], "entities": [{"text": "Neo4J graph databases", "start_pos": 27, "end_pos": 48, "type": "DATASET", "confidence": 0.8853635390599569}]}, {"text": "After this first overview, we show how information included in graphs can be used in speech recognition grammars to automatically extend a generic rule structure.", "labels": [], "entities": [{"text": "speech recognition grammars", "start_pos": 85, "end_pos": 112, "type": "TASK", "confidence": 0.7914912104606628}]}, {"text": "This can be the case of linguistic elements, such as synonyms, hypernyms, meronyms and phonological neighbours, which are semantically or structurally related to each other in our mental lexicon.", "labels": [], "entities": []}, {"text": "In all the AI based approaches depending on a training process using large and representative corpora, the probability to correctly predict the creativity a speaker can perform in using language and posing questions is lower than expected.", "labels": [], "entities": []}, {"text": "Trying to capture most of the possible words and expressions a speaker could use is extremely necessary, but even an empirical, finite collection of cases could not be enough.", "labels": [], "entities": []}, {"text": "For this reason, the use of our tool appears as an appealing solution, capable of including many pieces of information.", "labels": [], "entities": []}, {"text": "In addition, we used the proposed tool to develop a spoken dialogue system for museums and the preliminary results are shown and discussed in this paper.", "labels": [], "entities": []}], "introductionContent": [{"text": "While research on Natural Language Understanding is still investigating how to reliably interpret unconstrained user utterances, practical applications that are now common on mobile devices, like virtual assistants, heavily rely on utterance templates to provide their services.", "labels": [], "entities": [{"text": "Natural Language Understanding", "start_pos": 18, "end_pos": 48, "type": "TASK", "confidence": 0.693172832330068}]}, {"text": "Such language models can be dynamically loaded depending on the situation so that the speech recognition engine becomes biased towards the set of utterances the underlying dialogue system is able to manage.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.7106173187494278}]}, {"text": "For relatively small and well-defined dialogue domains, using this kind of language model appears to be a practical choice for application developers.", "labels": [], "entities": []}, {"text": "The problems posed by language variability, however, do not only impact the functionality of spoken dialogue systems at run time: developing grammar-based language models can be a time-consuming and error-prone task by itself.", "labels": [], "entities": []}, {"text": "Taking advantage of structured linguistic knowledge to overcome this aspect of dialogue systems design has led, in the past, to the use of linguistic ontologies to automatically expand the set of terms accepted by the speech recognition system.", "labels": [], "entities": []}, {"text": "Using lexical ontologies to represent the knowledge a machine has to process is something which has been investigated in early years: WordNet,) was used in machine translation, information extraction (, automatic text summarisation) and domain-specific dialogue systems management.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 134, "end_pos": 141, "type": "DATASET", "confidence": 0.9035975337028503}, {"text": "machine translation", "start_pos": 156, "end_pos": 175, "type": "TASK", "confidence": 0.8217759430408478}, {"text": "information extraction", "start_pos": 177, "end_pos": 199, "type": "TASK", "confidence": 0.7952204048633575}, {"text": "text summarisation", "start_pos": 213, "end_pos": 231, "type": "TASK", "confidence": 0.6755113452672958}, {"text": "domain-specific dialogue systems management", "start_pos": 237, "end_pos": 280, "type": "TASK", "confidence": 0.6490560472011566}]}, {"text": "In previous works, the preferred way of using ontological knowledge in dialogue systems appears to be based on the use of explicit reference to the classes defined in the taxonomy.", "labels": [], "entities": []}, {"text": "This, however, implies that ontologies supporting the dialogue domain must already exist or be constructed before the system can take advantage from it.", "labels": [], "entities": []}, {"text": "Modern approaches to data representation, however, use powerful querying languages to extract knowledge that is not explicitly structured in the ontological organisation by the presence of dedicated classes.", "labels": [], "entities": [{"text": "data representation", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.756637305021286}]}, {"text": "Moreover, it appears that, while the interest towards using ontologies in dialogue systems is well-established, there has been a less significant effort towards the definition of a common way to merge grammar definitions supporting ontological expansions.", "labels": [], "entities": []}, {"text": "In this paper, we present a formal language to describe ontologically-enriched language models.", "labels": [], "entities": []}, {"text": "This language is obtained by expanding the W3C Speech Recognition Grammar Specification (SRGS) XML standard) with an item dedicated to queries directed towards knowledge bases returning lists of words.", "labels": [], "entities": [{"text": "W3C Speech Recognition Grammar Specification (SRGS) XML", "start_pos": 43, "end_pos": 98, "type": "TASK", "confidence": 0.8173441423310174}]}, {"text": "In our work, we generalise the use of ontologies by proposing the integration with a graph database, which can represent ontologies as well as other forms of data representation based on objects and relationships among objects.", "labels": [], "entities": []}, {"text": "The paper is organised as follows: in Section 2 we describe the Neo4J graph database, which is the system we consider for knowledge representation in our work, and highlight the advantages it poses for dialogue systems support.", "labels": [], "entities": [{"text": "Neo4J graph database", "start_pos": 64, "end_pos": 84, "type": "DATASET", "confidence": 0.926557739575704}, {"text": "knowledge representation", "start_pos": 122, "end_pos": 146, "type": "TASK", "confidence": 0.7274838387966156}]}, {"text": "In the same Section, we also describe a specific Neo4J database hosting different types of linguistic information ranging from morphology to phonology.", "labels": [], "entities": [{"text": "Neo4J database", "start_pos": 49, "end_pos": 63, "type": "DATASET", "confidence": 0.9451350569725037}]}, {"text": "In Section 3, we describe the extended SRGS language we designed while, in Section 4, we present some use cases of interest.", "labels": [], "entities": [{"text": "SRGS language", "start_pos": 39, "end_pos": 52, "type": "TASK", "confidence": 0.7075457572937012}]}, {"text": "In the closing Section 5, we show the results we got in testing a spoken dialogue system using the designed grammars, in order to prove its quality.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}