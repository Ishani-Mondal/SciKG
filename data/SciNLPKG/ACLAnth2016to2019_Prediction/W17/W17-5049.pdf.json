{"title": [{"text": "Stacked Sentence-Document Classifier Approach for Improving Native Language Identification", "labels": [], "entities": [{"text": "Stacked Sentence-Document Classifier Approach", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.599576897919178}, {"text": "Improving Native Language Identification", "start_pos": 50, "end_pos": 90, "type": "TASK", "confidence": 0.9151990115642548}]}], "abstractContent": [{"text": "In this paper, we describe the approach of the ItaliaNLP Lab team to native language identification and discuss the results we submitted as participants to the essay track of NLI Shared Task 2017.", "labels": [], "entities": [{"text": "ItaliaNLP Lab team", "start_pos": 47, "end_pos": 65, "type": "DATASET", "confidence": 0.9774511059125265}, {"text": "native language identification", "start_pos": 69, "end_pos": 99, "type": "TASK", "confidence": 0.60435551404953}]}, {"text": "We introduce for the first time a 2-stacked sentence-document architecture for native language identification that is able to exploit both local sentence information and a wide set of general-purpose features qualifying the lexical and grammatical structure of the whole document.", "labels": [], "entities": [{"text": "native language identification", "start_pos": 79, "end_pos": 109, "type": "TASK", "confidence": 0.6740961273511251}]}, {"text": "When evaluated on the official test set, our sentence-document stacked architecture obtained the best result among all the participants of the essay track with an F1 score of 0.8818.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 163, "end_pos": 171, "type": "METRIC", "confidence": 0.9851246178150177}]}], "introductionContent": [{"text": "Native Language Identification (NLI) is the task of identifying the native language (L1) of a writer based on their writing in another language.", "labels": [], "entities": [{"text": "Native Language Identification (NLI)", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.7746550738811493}]}, {"text": "Since the seminal work by, within the Computational Linguistics community there has been a growing interest in the NLP-based Native Language Identification (henceforth, NLI) task.", "labels": [], "entities": [{"text": "NLP-based Native Language Identification (henceforth, NLI) task", "start_pos": 115, "end_pos": 178, "type": "TASK", "confidence": 0.6982405006885528}]}, {"text": "However, so far, due to the unavailability of balanced and wide-coverage benchmark corpora and the lack of evaluation standards it has been difficult to compare the results achieved for this task with different methods and techniques).", "labels": [], "entities": []}, {"text": "The First Shared Task on Native Language Identification ( ) was the answer to these mentioned problems.", "labels": [], "entities": [{"text": "Native Language Identification", "start_pos": 25, "end_pos": 55, "type": "TASK", "confidence": 0.6085428694883982}]}, {"text": "In this paper, we describe our approach to the essay track of the 2017 Native Language Identification Shared Task ( . Participating teams of this task were asked to classify the native language of writers of 1,100 English essays solely using the sample of their writings.", "labels": [], "entities": [{"text": "2017 Native Language Identification Shared Task", "start_pos": 66, "end_pos": 113, "type": "TASK", "confidence": 0.6742309431234995}, {"text": "classify the native language of writers of 1,100 English essays", "start_pos": 165, "end_pos": 228, "type": "TASK", "confidence": 0.673952603340149}]}, {"text": "11,100 English essays from non-native English writing samples from a standardized, meaningful, and authentic assessment context of English proficiency for academic purposes (the Test Of English as a Foreign Language, TOEFL) were provided as training data and the 11 native languages covered by the corpus are: Arabic, Chinese, French, German, Hindi, Italian, Japanese, Korean, Spanish, Telugu, and Turkish.", "labels": [], "entities": []}, {"text": "Each essay in the TOEFL11 is labeled with an English language proficiency level.", "labels": [], "entities": [{"text": "TOEFL11", "start_pos": 18, "end_pos": 25, "type": "DATASET", "confidence": 0.945852518081665}]}, {"text": "Following the most common approaches and starting from the work of (, we tackled the Native Language Identification task as a text classification problem.", "labels": [], "entities": [{"text": "Native Language Identification task", "start_pos": 85, "end_pos": 120, "type": "TASK", "confidence": 0.7043912410736084}, {"text": "text classification", "start_pos": 126, "end_pos": 145, "type": "TASK", "confidence": 0.7401697635650635}]}, {"text": "The main novelty of our approach is the proposed classification architecture that combines a sentence and a document classifier in a 2-stacked sentence-document architecture.", "labels": [], "entities": []}, {"text": "This system is able to exploit both local sentence information and a wide set of features extracted from the whole document.", "labels": [], "entities": []}, {"text": "The features range across different levels of linguistic description, from lexical to morpho-syntactic and syntactic information.", "labels": [], "entities": []}, {"text": "The proposed method was prompted by our studies on sentence and document readability classification), where we shown differences between document and sentence classification problems by focusing on the role of the features and their importance.", "labels": [], "entities": [{"text": "sentence and document readability classification", "start_pos": 51, "end_pos": 99, "type": "TASK", "confidence": 0.6011898338794708}, {"text": "document and sentence classification", "start_pos": 137, "end_pos": 173, "type": "TASK", "confidence": 0.7025607228279114}]}, {"text": "For example, the classification of the readability of a sentence requires a higher number of features, mainly syntactic ones, and they have different weights with respect to the weights used in the document classification problem.", "labels": [], "entities": [{"text": "classification of the readability of a sentence", "start_pos": 17, "end_pos": 64, "type": "TASK", "confidence": 0.8320372956139701}, {"text": "document classification", "start_pos": 198, "end_pos": 221, "type": "TASK", "confidence": 0.7620260715484619}]}, {"text": "In this work, we show how sentence local information can be exploited also in NLI task providing to the document classifier fruitful local information, thus making some features more effective.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Results obtained by our models on the  NLI Shared Task 2013 official test set compared  to the overall best run and our best run submitted  in the NLI Shared Task 2013 edition.", "labels": [], "entities": [{"text": "NLI Shared Task 2013 official test set", "start_pos": 49, "end_pos": 87, "type": "DATASET", "confidence": 0.9125581468854632}, {"text": "NLI Shared Task 2013 edition", "start_pos": 157, "end_pos": 185, "type": "DATASET", "confidence": 0.7455767035484314}]}, {"text": " Table 3: Results obtained by our models on the  NLI Shared Task 2017 official development set.", "labels": [], "entities": [{"text": "NLI Shared Task 2017 official development set", "start_pos": 49, "end_pos": 94, "type": "DATASET", "confidence": 0.8280930944851467}]}, {"text": " Table 4: Results of our submitted models for the  essay track on the NLI Shared Task 2017 official  test set.", "labels": [], "entities": [{"text": "NLI Shared Task 2017 official  test set", "start_pos": 70, "end_pos": 109, "type": "DATASET", "confidence": 0.8502889190401349}]}, {"text": " Table 5: Results of our not-stacked systems for the  essay track on the NLI Shared Task 2017 official  test set.", "labels": [], "entities": [{"text": "NLI Shared Task 2017 official  test set", "start_pos": 73, "end_pos": 112, "type": "DATASET", "confidence": 0.8439228194100517}]}, {"text": " Table 6: Results of our experiments on the NLI  Shared Task 2017 development set.", "labels": [], "entities": [{"text": "NLI  Shared Task 2017 development set", "start_pos": 44, "end_pos": 81, "type": "DATASET", "confidence": 0.8265714347362518}]}, {"text": " Table 7: Results of our experiments on the official  NLI Shared Task 2013 test set.", "labels": [], "entities": [{"text": "official  NLI Shared Task 2013 test set", "start_pos": 44, "end_pos": 83, "type": "DATASET", "confidence": 0.7937123903206417}]}, {"text": " Table 8: Performances of the sentence classifier  on sentences belonging to the official NLI Shared  Task 2017 development set and on the official NLI  Shared Task 2013 test set.", "labels": [], "entities": [{"text": "NLI Shared  Task 2017 development set", "start_pos": 90, "end_pos": 127, "type": "DATASET", "confidence": 0.8289725879828135}, {"text": "NLI  Shared Task 2013 test set", "start_pos": 148, "end_pos": 178, "type": "DATASET", "confidence": 0.8742533028125763}]}]}