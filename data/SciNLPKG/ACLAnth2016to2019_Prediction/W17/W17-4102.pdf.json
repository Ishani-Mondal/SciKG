{"title": [{"text": "Learning variable length units for SMT between related languages via Byte Pair Encoding", "labels": [], "entities": [{"text": "SMT between related languages", "start_pos": 35, "end_pos": 64, "type": "TASK", "confidence": 0.8709579855203629}]}], "abstractContent": [{"text": "We explore the use of segments learnt using Byte Pair Encoding (referred to as BPE units) as basic units for statistical machine translation between related languages and compare it with orthographic syllables, which are currently the best performing basic units for this translation task.", "labels": [], "entities": [{"text": "statistical machine translation between related languages", "start_pos": 109, "end_pos": 166, "type": "TASK", "confidence": 0.8180410265922546}]}, {"text": "BPE identifies the most frequent character sequences as basic units, while orthographic syllables are linguistically motivated pseudo-syllables.", "labels": [], "entities": [{"text": "BPE", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.5825271606445312}]}, {"text": "We show that BPE units modestly outperform orthographic syllables as units of translation , showing up to 11% increase in BLEU score.", "labels": [], "entities": [{"text": "BPE", "start_pos": 13, "end_pos": 16, "type": "METRIC", "confidence": 0.933315098285675}, {"text": "BLEU score", "start_pos": 122, "end_pos": 132, "type": "METRIC", "confidence": 0.983356237411499}]}, {"text": "While orthographic syllables can be used only for languages whose writing systems use vowel representations, BPE is writing system independent and we show that BPE outperforms other units for non-vowel writing systems too.", "labels": [], "entities": [{"text": "BPE", "start_pos": 160, "end_pos": 163, "type": "METRIC", "confidence": 0.7333694696426392}]}, {"text": "Our results are supported by extensive experimentation spanning multiple language families and writing systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "The term, related languages, refers to languages that exhibit lexical and structural similarities on account of sharing a common ancestry or being in contact fora long period of time (.", "labels": [], "entities": []}, {"text": "Examples of languages related by common ancestry are Slavic and Indo-Aryan languages.", "labels": [], "entities": []}, {"text": "Prolonged contact leads to convergence of linguistic properties even if the languages are not related by ancestry and could lead to the formation of linguistic areas).", "labels": [], "entities": []}, {"text": "Examples of such linguistic areas are the Indian subcontinent), Balkan and Standard Average European linguistic areas.", "labels": [], "entities": []}, {"text": "Genetic as well as contact relationship lead to related languages sharing vocabulary and structural features.", "labels": [], "entities": []}, {"text": "There is substantial government, commercial and cultural communication among people speaking related languages (Europe, India and SouthEast Asia being prominent examples and linguistic regions in Africa possibly in the future).", "labels": [], "entities": []}, {"text": "As these regions integrate more closely and move to a digital society, translation between related languages is becoming an important requirement.", "labels": [], "entities": [{"text": "translation between related languages", "start_pos": 71, "end_pos": 108, "type": "TASK", "confidence": 0.8819490820169449}]}, {"text": "In addition, translation to/from related languages to a lingua franca like English is also very important.", "labels": [], "entities": []}, {"text": "However, despite significant communication between people speaking related languages, most of these languages have few parallel corpora resources.", "labels": [], "entities": []}, {"text": "It is therefore important to leverage the relatedness of these languages to build goodquality statistical machine translation (SMT) systems given the lack of parallel corpora.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 94, "end_pos": 131, "type": "TASK", "confidence": 0.7655677447716395}]}, {"text": "Modelling lexical similarity among related languages is the key to building good-quality SMT systems with limited parallel corpora.", "labels": [], "entities": [{"text": "SMT", "start_pos": 89, "end_pos": 92, "type": "TASK", "confidence": 0.9923807978630066}]}, {"text": "Lexical similarity implies related languages share many words with similar form (spelling/pronunciation) and meaning e.g. blindness is andhapana in Hindi, aandhaLepaNaa in Marathi.", "labels": [], "entities": []}, {"text": "These words could be cognates, lateral borrowings or loan words from other languages.", "labels": [], "entities": []}, {"text": "Subword level transformations are an effective way for translation of such shared words.", "labels": [], "entities": [{"text": "Subword level transformations", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7624728282292684}, {"text": "translation", "start_pos": 55, "end_pos": 66, "type": "TASK", "confidence": 0.9689818024635315}]}, {"text": "In this work, we propose use of Byte Pair Encoding (BPE)), a encoding method inspired from text compression literature, to learn basic translation units for translation between related languages.", "labels": [], "entities": [{"text": "translation between related languages", "start_pos": 157, "end_pos": 194, "type": "TASK", "confidence": 0.8293837606906891}]}, {"text": "In previous work, the basic units of translation are either linguistically motivated (word, morpheme, syllable, etc.) or ad-hoc choices (character n-gram).", "labels": [], "entities": []}, {"text": "In contrast, BPE is motivated by statistical properties of text.", "labels": [], "entities": [{"text": "BPE", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.8974027037620544}]}], "datasetContent": [{"text": "We trained translation systems over the following basic units: character, morpheme, word, orthographic syllable and BPE unit.", "labels": [], "entities": [{"text": "BPE unit", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9683978855609894}]}, {"text": "In this section, we summarize the languages and writing systems chosen for our experiments, the datasets used and the experimental configuration of our translation systems, and the evaluation methodology.", "labels": [], "entities": []}, {"text": "The primary evaluation metric is word-level BLEU ().", "labels": [], "entities": [{"text": "BLEU", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.9276650547981262}]}, {"text": "We also report scores as an alternative evaluation metric.", "labels": [], "entities": []}, {"text": "LeBLEU is a variant of BLEU that does an edit-distance based, soft-matching of words and has been shown to be better for morphologically rich languages.", "labels": [], "entities": [{"text": "LeBLEU", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.7265235781669617}, {"text": "BLEU", "start_pos": 23, "end_pos": 27, "type": "METRIC", "confidence": 0.9953719973564148}]}, {"text": "We used bootstrap resampling for testing statistical significance).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Training Corpus Statistics", "labels": [], "entities": [{"text": "Training Corpus", "start_pos": 10, "end_pos": 25, "type": "DATASET", "confidence": 0.9003304839134216}]}, {"text": " Table 4: Translation accuracies for BPE models  trained with different number of merge operations  (BLEU). Underlined scores indicate the best BPE  configuration when OS is the best-performing for  a language pair.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 101, "end_pos": 105, "type": "METRIC", "confidence": 0.8626882433891296}]}, {"text": " Table 5: Translation accuracies for Agriculture  Domain  \u2020 indicates statistically significant dif- ference in BLEU score between O and B match .  BLEU score differences between B match and W  are also statistically significant (except Konkani- Marathi) (p < 0.05)", "labels": [], "entities": [{"text": "statistically significant dif- ference", "start_pos": 70, "end_pos": 108, "type": "METRIC", "confidence": 0.6537274360656739}, {"text": "BLEU score", "start_pos": 112, "end_pos": 122, "type": "METRIC", "confidence": 0.9747403860092163}, {"text": "BLEU score", "start_pos": 148, "end_pos": 158, "type": "METRIC", "confidence": 0.973448634147644}]}, {"text": " Table 6: Translation accuracies for Joint BPE  models trained with different number of merge op- erations (BLEU). The Best prev indicates the best  performing units and their accuracy scores from", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9171788096427917}, {"text": "merge op- erations (BLEU)", "start_pos": 88, "end_pos": 113, "type": "METRIC", "confidence": 0.8631075535501752}, {"text": "accuracy", "start_pos": 176, "end_pos": 184, "type": "METRIC", "confidence": 0.9992751479148865}]}, {"text": " Table 7: Pearson's correlation coefficient between  lexical similarity and translation accuracy (both in  terms of LCSR at character level). This was com- puted over the test set between: (i) sentence level  lexical similarity between source and target sen- tences and (ii) sentence level translation accuracy  between hypothesis and reference.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.8233819007873535}, {"text": "LCSR", "start_pos": 116, "end_pos": 120, "type": "METRIC", "confidence": 0.9183418154716492}]}]}