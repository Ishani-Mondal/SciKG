{"title": [{"text": "A Morphological Analyzer for Gulf Arabic Verbs", "labels": [], "entities": [{"text": "Gulf Arabic Verbs", "start_pos": 29, "end_pos": 46, "type": "TASK", "confidence": 0.5614099502563477}]}], "abstractContent": [{"text": "We present CALIMA GLF , a Gulf Arabic morphological analyzer currently covering over 2,600 verbal lemmas.", "labels": [], "entities": [{"text": "CALIMA GLF", "start_pos": 11, "end_pos": 21, "type": "METRIC", "confidence": 0.8151227831840515}, {"text": "Gulf Arabic morphological analyzer", "start_pos": 26, "end_pos": 60, "type": "TASK", "confidence": 0.5196450054645538}]}, {"text": "We describe in detail the process of building the analyzer starting from pho-netic dictionary entries to fully inflected ortho-graphic paradigms and associated lexicon and or-thographic variants.", "labels": [], "entities": []}, {"text": "We evaluate the coverage of CALIMA GLF against Modern Standard Arabic and Egyptian Arabic analyzers on part of a Gulf Arabic novel.", "labels": [], "entities": [{"text": "CALIMA GLF", "start_pos": 28, "end_pos": 38, "type": "TASK", "confidence": 0.4628100246191025}]}, {"text": "CALIMA GLF verb analysis token recall for identifying correct POS tag outperforms both the Modern Standard Arabic and Egyptian Arabic analyzers by over 27.4% and 16.9% absolute , respectively.", "labels": [], "entities": [{"text": "CALIMA GLF verb analysis token recall", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.4826781153678894}]}], "introductionContent": [{"text": "Until recently, Dialectal Arabic (DA) was mainly spoken with little to no publicly available written content.", "labels": [], "entities": [{"text": "Dialectal Arabic (DA)", "start_pos": 16, "end_pos": 37, "type": "TASK", "confidence": 0.6220838248729705}]}, {"text": "Modern Standard Arabic (MSA) on the other hand is the official language in more than 20 countries, where most written documents from news articles, to educational materials and entertainment magazines, are written in MSA.", "labels": [], "entities": []}, {"text": "Hence, most of the tools that are available for Natural Language Processing (NLP) tasks are focused on MSA.", "labels": [], "entities": [{"text": "Natural Language Processing (NLP) tasks", "start_pos": 48, "end_pos": 87, "type": "TASK", "confidence": 0.7096061706542969}]}, {"text": "With the introduction of social media platforms online, dialectal written content is being produced abundantly.", "labels": [], "entities": []}, {"text": "Using existing tools that were developed for MSA on DA proved to have limited performance;.", "labels": [], "entities": [{"text": "MSA", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.9476417303085327}]}, {"text": "Having resources specific to DA, such as morphological lexicons is important for Arabic NLP tasks, such as part-of-speech (POS) tagging and morphological disambiguation.", "labels": [], "entities": [{"text": "part-of-speech (POS) tagging", "start_pos": 107, "end_pos": 135, "type": "TASK", "confidence": 0.6665248870849609}, {"text": "morphological disambiguation", "start_pos": 140, "end_pos": 168, "type": "TASK", "confidence": 0.7055606544017792}]}, {"text": "Recently, dialects such as Egyptian (EGY) and Levantine (LEV) Arabic have been receiving increasing attention.", "labels": [], "entities": []}, {"text": "Morphological analyzers for EGY and LEV proved to perform well when used for morphological tagging . To our knowledge, there exist no full morphological analyzers for Gulf Arabic (GLF) that produce segmentation, POS analysis and lemmas.", "labels": [], "entities": [{"text": "EGY", "start_pos": 28, "end_pos": 31, "type": "DATASET", "confidence": 0.8482431173324585}, {"text": "morphological tagging", "start_pos": 77, "end_pos": 98, "type": "TASK", "confidence": 0.7604728937149048}, {"text": "Gulf Arabic (GLF)", "start_pos": 167, "end_pos": 184, "type": "DATASET", "confidence": 0.707892781496048}, {"text": "POS analysis", "start_pos": 212, "end_pos": 224, "type": "TASK", "confidence": 0.8148180544376373}]}, {"text": "Although we note the work of Abuata and Al-Omari (2015) on developing a Gulf Arabic stemmer.", "labels": [], "entities": []}, {"text": "In this paper, we present CALIMA GLF , 1 a morphological analyzer for GLF.", "labels": [], "entities": [{"text": "CALIMA GLF , 1", "start_pos": 26, "end_pos": 40, "type": "METRIC", "confidence": 0.5687667950987816}]}, {"text": "In the current work, we present the effort focusing on GLF verbs only.", "labels": [], "entities": []}, {"text": "We utilize a combination of computational techniques in addition to explicit linguistic knowledge to create this resource.", "labels": [], "entities": []}, {"text": "We also evaluate it against wide coverage tools for MSA and EGY.", "labels": [], "entities": [{"text": "EGY", "start_pos": 60, "end_pos": 63, "type": "DATASET", "confidence": 0.8376280069351196}]}, {"text": "CALIMA GLF verb analysis token recall in terms of identifying correct POS tagging outperforms on both MSA and EGY by over 27.4% and 16.9% absolute, respectively.", "labels": [], "entities": [{"text": "CALIMA GLF verb analysis token recall", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.46365580956141156}, {"text": "POS tagging", "start_pos": 70, "end_pos": 81, "type": "TASK", "confidence": 0.6551748216152191}, {"text": "EGY", "start_pos": 110, "end_pos": 113, "type": "METRIC", "confidence": 0.6388479471206665}]}, {"text": "CALIMA GLF will be made publicly available to researchers working on Arabic and Arabic dialect NLP.", "labels": [], "entities": [{"text": "CALIMA GLF", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.7049177587032318}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we review related literature, then we briefly describe the main characteristics of GLF in Section 3.", "labels": [], "entities": [{"text": "GLF", "start_pos": 96, "end_pos": 99, "type": "TASK", "confidence": 0.4745931625366211}]}, {"text": "In Section 4 we describe the approach and the resources involved and evaluate in Section 5.", "labels": [], "entities": []}, {"text": "We conclude and discuss future work in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Dataset We used apart of an Emirati novel in raw text from the Gumar corpus.", "labels": [], "entities": [{"text": "Gumar corpus", "start_pos": 63, "end_pos": 75, "type": "DATASET", "confidence": 0.915490061044693}]}, {"text": "We contextually annotated all the verbs appearing in first 4,000 words of the novel -a total of 620 verbs.", "labels": [], "entities": []}, {"text": "The annotation includes identifying the CODA spelling, full Buckwalter tag and the morphemic segmentation.", "labels": [], "entities": [{"text": "Buckwalter tag", "start_pos": 60, "end_pos": 74, "type": "DATASET", "confidence": 0.8468779921531677}]}, {"text": "shows an annotation example of one sentence from the data.", "labels": [], "entities": []}, {"text": "In this work we only use one dataset for the evaluation as we didn't use any feedback from the evaluation in the current state of work, i.e., this was a blind test.", "labels": [], "entities": []}, {"text": "Metrics We report token recall on verbs only.", "labels": [], "entities": [{"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9452605843544006}]}, {"text": "We report in terms of CODA spelling, segmentation and POS.", "labels": [], "entities": [{"text": "CODA", "start_pos": 22, "end_pos": 26, "type": "DATASET", "confidence": 0.42886999249458313}, {"text": "spelling", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.7606837749481201}, {"text": "segmentation", "start_pos": 37, "end_pos": 49, "type": "TASK", "confidence": 0.918860137462616}, {"text": "POS", "start_pos": 54, "end_pos": 57, "type": "METRIC", "confidence": 0.9867126941680908}]}, {"text": "We report in two modes of input: raw input and CODA compliant input of the same text.", "labels": [], "entities": []}, {"text": "Token recall counts the percentage of the time one of the analyses returned by the morphological analyzer given a particular input word matches the gold analysis of the input word in the aspect evaluated (e.g., CODA, segmentation or POS).", "labels": [], "entities": [{"text": "recall", "start_pos": 6, "end_pos": 12, "type": "METRIC", "confidence": 0.7846301198005676}]}, {"text": "This is similar to the evaluation carried by.", "labels": [], "entities": []}, {"text": "Systems We used six different analyzers for our experiments.", "labels": [], "entities": []}, {"text": "\u2022 SAMA analyzer for MSA ().", "labels": [], "entities": [{"text": "SAMA analyzer", "start_pos": 2, "end_pos": 15, "type": "TASK", "confidence": 0.6840583086013794}]}, {"text": "\u2022 CALIMA EGY for EGY, which includes MSA ().", "labels": [], "entities": [{"text": "CALIMA EGY", "start_pos": 2, "end_pos": 12, "type": "METRIC", "confidence": 0.6093145310878754}]}, {"text": "\u2022 CALIMA GLF for GLF.", "labels": [], "entities": [{"text": "CALIMA GLF", "start_pos": 2, "end_pos": 12, "type": "TASK", "confidence": 0.4847193956375122}, {"text": "GLF", "start_pos": 17, "end_pos": 20, "type": "DATASET", "confidence": 0.47304531931877136}]}, {"text": "\u2022 CALIMA GLF-CODA is CALIMA GLF without the extensions discussed in 4.10.", "labels": [], "entities": []}, {"text": "\u2022 CALIMA GLF extended with SAMA.", "labels": [], "entities": [{"text": "CALIMA GLF", "start_pos": 2, "end_pos": 12, "type": "TASK", "confidence": 0.46222907304763794}, {"text": "SAMA", "start_pos": 27, "end_pos": 31, "type": "DATASET", "confidence": 0.8243048191070557}]}, {"text": "\u2022 CALIMA GLF extended with CALIMA EGY .", "labels": [], "entities": [{"text": "GLF", "start_pos": 9, "end_pos": 12, "type": "METRIC", "confidence": 0.6197126507759094}, {"text": "CALIMA EGY", "start_pos": 27, "end_pos": 37, "type": "METRIC", "confidence": 0.3967074900865555}]}], "tableCaptions": [{"text": " Table 4: Example of BP for a paradigm of Form I and another of Form II for the roots  qwl and", "labels": [], "entities": [{"text": "BP", "start_pos": 21, "end_pos": 23, "type": "METRIC", "confidence": 0.972931444644928}]}, {"text": " Table 7: Token recall evaluation on CODA matching, Buckwalter POS tag and morphemic segmentation.  Evaluation is on verbs only. The evaluated analyzers are (1) SAMA for MSA, (2) CALIMA EGY for EGY,  which includes MSA, (3) CALIMA GLF for GLF, and (4) CALIMA GLF-CODA , which is CALIMA GLF  without the extension discussed in 4.10.", "labels": [], "entities": [{"text": "Token recall", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.6449206173419952}, {"text": "CODA matching", "start_pos": 37, "end_pos": 50, "type": "TASK", "confidence": 0.8180993795394897}, {"text": "morphemic segmentation", "start_pos": 75, "end_pos": 97, "type": "TASK", "confidence": 0.7667476236820221}]}]}