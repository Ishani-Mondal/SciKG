{"title": [{"text": "Collecting fluency corrections for spoken learner English", "labels": [], "entities": [{"text": "Collecting fluency corrections", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8958319822947184}]}], "abstractContent": [{"text": "We present crowdsourced collection of error annotations for transcriptions of spoken learner English.", "labels": [], "entities": []}, {"text": "Our emphasis in data collection is on fluency corrections, a more complete correction than has traditionally been aimed for in grammatical error correction research (GEC).", "labels": [], "entities": [{"text": "fluency corrections", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.713366687297821}, {"text": "grammatical error correction research (GEC)", "start_pos": 127, "end_pos": 170, "type": "TASK", "confidence": 0.8190561277525765}]}, {"text": "Fluency corrections require improvements to the text, taking discourse and utterance level semantics into account: the result is a more naturalistic, holistic version of the original.", "labels": [], "entities": []}, {"text": "We propose that this shifted emphasis be reflected in anew name for the task: 'holistic error correction' (HEC).", "labels": [], "entities": [{"text": "holistic error correction' (HEC)", "start_pos": 79, "end_pos": 111, "type": "TASK", "confidence": 0.7316391127450126}]}, {"text": "We analyse crowdworker behaviour in HEC and conclude that the method is useful with certain amendments for future work.", "labels": [], "entities": [{"text": "HEC", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.8008913397789001}]}], "introductionContent": [{"text": "By convention, grammatical error detection and correction (GEC) systems depend on the availability of labelled training data in which tokens have been annotated with an error code and a correction.", "labels": [], "entities": [{"text": "grammatical error detection and correction (GEC)", "start_pos": 15, "end_pos": 63, "type": "TASK", "confidence": 0.8087937459349632}]}, {"text": "In (1) for example, taken from the open FCE subset of the Cambridge Learner Corpus (CLC)), the original token 'waken' is coded as a 'TV' (verb tense) error and annotated with the correct token 'woken' on the right-hand side of the pipe.", "labels": [], "entities": [{"text": "FCE subset of the Cambridge Learner Corpus (CLC))", "start_pos": 40, "end_pos": 89, "type": "DATASET", "confidence": 0.952064824104309}]}, {"text": "(1) In the morning, you are <NS type=\"TV\"> waken|woken </NS> up by a singing puppy.", "labels": [], "entities": []}, {"text": "Such efforts to annotate learner corpora are time-consuming and costly, but with sufficient quantities it is possible to train GEC systems to identify and correct errors in unseen texts.", "labels": [], "entities": [{"text": "GEC", "start_pos": 127, "end_pos": 130, "type": "DATASET", "confidence": 0.7965983748435974}]}, {"text": "For example, 29 million tokens of the CLC have been error-annotated, of which the FCE is a publiclyavailable 500k token subset).", "labels": [], "entities": [{"text": "FCE", "start_pos": 82, "end_pos": 85, "type": "DATASET", "confidence": 0.9019137024879456}]}, {"text": "The Write & Improve 1 GEC system (W&I) has been built on these resources, providing automated assessment and pertoken error feedback.", "labels": [], "entities": [{"text": "Write & Improve 1 GEC system (W&I)", "start_pos": 4, "end_pos": 38, "type": "TASK", "confidence": 0.554349506443197}, {"text": "pertoken", "start_pos": 109, "end_pos": 117, "type": "METRIC", "confidence": 0.9021560549736023}]}, {"text": "In common with other GEC systems, W&I prizes precision ahead of recall -so as to avoid false positive corrections being presented to the user.", "labels": [], "entities": [{"text": "precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9992973804473877}, {"text": "recall", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.988867461681366}]}, {"text": "Indeed the field of GEC as a whole adopts a conservative stance on error correction (hence preferring precision to recall in the well-established F 0.5 metric), is focused at the token level, and has tended to train separate classifiers for each error type, has adopted a machine translation approach, or a hybrid of the two.", "labels": [], "entities": [{"text": "error correction", "start_pos": 67, "end_pos": 83, "type": "TASK", "confidence": 0.704359233379364}, {"text": "precision", "start_pos": 102, "end_pos": 111, "type": "METRIC", "confidence": 0.9979825019836426}, {"text": "recall", "start_pos": 115, "end_pos": 121, "type": "METRIC", "confidence": 0.9781123995780945}, {"text": "F 0.5 metric", "start_pos": 146, "end_pos": 158, "type": "METRIC", "confidence": 0.8587475419044495}, {"text": "machine translation", "start_pos": 272, "end_pos": 291, "type": "TASK", "confidence": 0.7360785901546478}]}, {"text": "Ease of correction varies by class of error, with showing best-to-worst recall of the top-performing system for each error type in the CoNLL-2014 shared task on GEC of NUCLE data ( . It is apparent that detection rates are relatively high for certain error types, namely issues of register, subject-verb agreement, determiner errors and noun number.", "labels": [], "entities": [{"text": "recall", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9985635876655579}, {"text": "GEC of NUCLE data", "start_pos": 161, "end_pos": 178, "type": "DATASET", "confidence": 0.8635577410459518}]}, {"text": "We note that there are several error types in the lower half of Table 1 -such as sentence fragments, linking words, redundancy, unclear meaning and wrong collocations -which relate to fluency broadly defined.", "labels": [], "entities": []}, {"text": "This indicates that these error types are harder to solve, or at least have not been worked on so much.", "labels": [], "entities": []}, {"text": "Either way they require further attention.", "labels": [], "entities": []}, {"text": "Some notable blind-spots of the current GEC approach are found above the token level, in sentence and discourse level semantics and coher-  ence.", "labels": [], "entities": []}, {"text": "Hence there has been a call for greater emphasis on fluency in error correction (.", "labels": [], "entities": [{"text": "error correction", "start_pos": 63, "end_pos": 79, "type": "TASK", "confidence": 0.6980520486831665}]}, {"text": "We may think of fluency as encompassing the grammaticality-per-token focus of GEC thus far, with added layers of sentence and discourse level semantics and coherence.", "labels": [], "entities": []}, {"text": "It is also more than just spoken fluency, which is a common usage of the term.", "labels": [], "entities": []}, {"text": "Instead, it is a holistic notion of all-linguistic performance competence.", "labels": [], "entities": []}, {"text": "For example, in (2) we seethe kind of sentence which in the GEC approach might only be corrected for the ungrammaticality of 'shorten', as in (3).", "labels": [], "entities": [{"text": "GEC", "start_pos": 60, "end_pos": 63, "type": "DATASET", "confidence": 0.8367705345153809}]}, {"text": "But in fact the new version still lacks nativelike fluency.", "labels": [], "entities": []}, {"text": "The meaning is clear, a fact we can use to offer the fluent correction seen in (4).", "labels": [], "entities": []}, {"text": "(2) From this scope, social media has shorten our distance 4 . (3) From this scope, social media has shortened our distance.", "labels": [], "entities": []}, {"text": "(4) From this perspective, social media has shortened the distance between us.", "labels": [], "entities": []}, {"text": "Furthermore, in speech the problem is heightened by the fact that, relative to grammaticality, Examples (2)-(4) from Sakaguchi et al fluency is arguably of greater importance than it is in writing.", "labels": [], "entities": []}, {"text": "In the immediate communication scenario of spontaneous conversation -the default setting for speech, though there are others -the signal is ephemeral and interlocutors are both forgiving of errors and adept at rapid repair.", "labels": [], "entities": []}, {"text": "Except in classroom settings or when explicitly asked to do so, the listener rarely corrects or points out the speaker's grammatical errors.", "labels": [], "entities": []}, {"text": "Instead she tends to signal understanding, offer signs of agreement or other emotional reaction, and seek clarification -all of which have been listed among the typical acts of 'alignment' in dialogue ().", "labels": [], "entities": []}, {"text": "She focuses more on the meaning of what is said, and the fluency of linguistic construction plays an important role in how successfully meaning is conveyed.", "labels": [], "entities": []}, {"text": "We work with spoken data from learners, and the implication is that fluency takes on added importance in our view.", "labels": [], "entities": []}, {"text": "We therefore support the call for greater emphasis on fluency rather than grammaticality, propose that we represent that changed emphasis with a changed label for the field -'holistic error correction' (HEC) is our suggestion -and finally we present and evaluate a crowdsourcing method for fluency correction of transcriptions of spoken learner English.", "labels": [], "entities": [{"text": "holistic error correction' (HEC)", "start_pos": 175, "end_pos": 207, "type": "TASK", "confidence": 0.6905706737722669}, {"text": "fluency correction of transcriptions of spoken learner English", "start_pos": 290, "end_pos": 352, "type": "TASK", "confidence": 0.8415832668542862}]}, {"text": "We analyse crowdworker behaviour in this task, discuss how the data can be used, and assess how the method can be improved in future work with a view to creating an open dataset of fluency annotations.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Best recall by error type in the CoNLL-2014 shared task on GEC (Ng et al., 2014), including  frequency of error type in the training data, and recall against gold-standard edits 3 .", "labels": [], "entities": [{"text": "recall", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.9983968138694763}, {"text": "CoNLL-2014 shared task on GEC (Ng et al., 2014)", "start_pos": 43, "end_pos": 90, "type": "DATASET", "confidence": 0.8493484357992808}, {"text": "recall", "start_pos": 153, "end_pos": 159, "type": "METRIC", "confidence": 0.9992296695709229}]}, {"text": " Table 2: L1 of speakers in the BULATS corpus:  number of tokens and speech-units per group.", "labels": [], "entities": [{"text": "BULATS corpus", "start_pos": 32, "end_pos": 45, "type": "DATASET", "confidence": 0.944867879152298}]}, {"text": " Table 3:  CEFR proficiency level of speakers  in the BULATS corpus: number of tokens and  speech-units per group.", "labels": [], "entities": [{"text": "CEFR", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.7660855650901794}, {"text": "BULATS corpus", "start_pos": 54, "end_pos": 67, "type": "DATASET", "confidence": 0.9402281045913696}]}, {"text": " Table 4: CEFR proficiency level of speakers in the BULATS corpus: number of tokens and speech-units  per group.", "labels": [], "entities": [{"text": "CEFR", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.7786731123924255}, {"text": "BULATS corpus", "start_pos": 52, "end_pos": 65, "type": "DATASET", "confidence": 0.9399231672286987}]}, {"text": " Table 5: Number of skips per speech-unit in the  BULATS corpus.", "labels": [], "entities": [{"text": "BULATS corpus", "start_pos": 50, "end_pos": 63, "type": "DATASET", "confidence": 0.9558410048484802}]}, {"text": " Table 6: Example crowdsourced corrections for a speech-unit from the BULATS corpus.", "labels": [], "entities": [{"text": "BULATS corpus", "start_pos": 70, "end_pos": 83, "type": "DATASET", "confidence": 0.9494722485542297}]}]}