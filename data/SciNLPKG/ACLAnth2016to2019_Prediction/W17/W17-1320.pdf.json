{"title": [], "abstractContent": [{"text": "We describe the process of creating NUDAR, a Universal Dependency treebank for Arabic.", "labels": [], "entities": []}, {"text": "We present the conversion from the Penn Arabic Tree-bank to the Universal Dependency syntactic representation through an intermediate dependency representation.", "labels": [], "entities": [{"text": "Penn Arabic Tree-bank", "start_pos": 35, "end_pos": 56, "type": "DATASET", "confidence": 0.9856715401013693}]}, {"text": "We discuss the challenges faced in the conversion of the trees, the decisions we made to solve them, and the validation of our conversion.", "labels": [], "entities": []}, {"text": "We also present initial parsing results on NUDAR.", "labels": [], "entities": [{"text": "NUDAR", "start_pos": 43, "end_pos": 48, "type": "DATASET", "confidence": 0.9233973622322083}]}], "introductionContent": [{"text": "Parsers have been used in many Natural Language Processing (NLP) applications, such as automatic summarization, question answering, and machine translation.", "labels": [], "entities": [{"text": "summarization", "start_pos": 97, "end_pos": 110, "type": "TASK", "confidence": 0.6708775758743286}, {"text": "question answering", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.9243416786193848}, {"text": "machine translation", "start_pos": 136, "end_pos": 155, "type": "TASK", "confidence": 0.8175399303436279}]}, {"text": "This motivates the creation of treebanks on which these parsers can be trained.", "labels": [], "entities": []}, {"text": "Treebanks have two main different syntactic representations.", "labels": [], "entities": []}, {"text": "On one hand, there are phrase structure (constituency) treebanks such as the Penn Treebank (, and its sister treebanks such as the Penn Arabic Treebank (PATB) () and the Penn Chinese Treebank ().", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 77, "end_pos": 90, "type": "DATASET", "confidence": 0.9946516752243042}, {"text": "Penn Arabic Treebank (PATB)", "start_pos": 131, "end_pos": 158, "type": "DATASET", "confidence": 0.9465675155321757}, {"text": "Penn Chinese Treebank", "start_pos": 170, "end_pos": 191, "type": "DATASET", "confidence": 0.9654223521550497}]}, {"text": "On the other hand, there are dependency treebanks, such as Columbia Arabic Treebank (CATiB), and the Prague Dependency Treebank (PDT)).", "labels": [], "entities": [{"text": "Columbia Arabic Treebank (CATiB)", "start_pos": 59, "end_pos": 91, "type": "DATASET", "confidence": 0.9573321839173635}, {"text": "Prague Dependency Treebank (PDT))", "start_pos": 101, "end_pos": 134, "type": "DATASET", "confidence": 0.9363029698530833}]}, {"text": "Other treebanks that followed the style of PDT are the Slovene () and the Croatian) treebanks, as well as the Prague Arabic Dependency Treebank (PADT) (.", "labels": [], "entities": [{"text": "Prague Arabic Dependency Treebank (PADT)", "start_pos": 110, "end_pos": 150, "type": "DATASET", "confidence": 0.8814951862607684}]}, {"text": "Having these different syntactic representations makes it difficult to compare treebanks, and parsing results.", "labels": [], "entities": []}, {"text": "This motivated the creation of the Universal Dependency (UD) syntactic representation, that aims to create cross-linguistically consistent annotation guidelines that facilitate the creation of treebanks that are built with the same label sets and structural basis.", "labels": [], "entities": []}, {"text": "In this paper, we present the New York University Abu Dhabi Universal Dependency Arabic Treebank, a UD treebank for Arabic, which we dub NUDAR.", "labels": [], "entities": [{"text": "New York University Abu Dhabi Universal Dependency Arabic Treebank", "start_pos": 30, "end_pos": 96, "type": "DATASET", "confidence": 0.8413180377748277}, {"text": "UD treebank", "start_pos": 100, "end_pos": 111, "type": "DATASET", "confidence": 0.6940601766109467}, {"text": "NUDAR", "start_pos": 137, "end_pos": 142, "type": "DATASET", "confidence": 0.9380918741226196}]}], "datasetContent": [{"text": "The datasets that are currently included in NUDAR are the PATB part 1, v4.1 (Maamouri et al., 2010a), part 2, v3.1 (Maamouri et al., 2011), and part 3, v3.2 (Maamouri et al., 2010b).", "labels": [], "entities": [{"text": "NUDAR", "start_pos": 44, "end_pos": 49, "type": "DATASET", "confidence": 0.9064263701438904}, {"text": "PATB part 1", "start_pos": 58, "end_pos": 69, "type": "DATASET", "confidence": 0.7830774784088135}]}, {"text": "The tokenization followed in NUDAR is the same tokenization scheme followed in PATB, which tokenizes all the clitics, with the exception of the definite article + Al+ 'the' ().", "labels": [], "entities": [{"text": "NUDAR", "start_pos": 29, "end_pos": 34, "type": "DATASET", "confidence": 0.91571444272995}, {"text": "PATB", "start_pos": 79, "end_pos": 83, "type": "DATASET", "confidence": 0.7536402940750122}]}, {"text": "The treebank contains 19K sentences, containing 738K tokens.", "labels": [], "entities": []}, {"text": "For our parsing experiment, we followed the guidelines detailed by, to split the treebanks into TRAIN, DEV, and TEST.", "labels": [], "entities": [{"text": "parsing", "start_pos": 8, "end_pos": 15, "type": "TASK", "confidence": 0.9833613038063049}, {"text": "TRAIN", "start_pos": 96, "end_pos": 101, "type": "METRIC", "confidence": 0.9899787902832031}, {"text": "DEV", "start_pos": 103, "end_pos": 106, "type": "METRIC", "confidence": 0.9108004570007324}, {"text": "TEST", "start_pos": 112, "end_pos": 116, "type": "METRIC", "confidence": 0.9718053340911865}]}, {"text": "The details of the sizes of the different datasets are shown in.", "labels": [], "entities": []}, {"text": "We conducted some experiments to benchmark the parsing scores in the NUDAR treebank.", "labels": [], "entities": [{"text": "parsing", "start_pos": 47, "end_pos": 54, "type": "TASK", "confidence": 0.9654058218002319}, {"text": "NUDAR treebank", "start_pos": 69, "end_pos": 83, "type": "DATASET", "confidence": 0.9856985807418823}]}, {"text": "We also compare the result of parsing directly in NUDAR space to parsing in CATiB space then converting to NUDAR representation.", "labels": [], "entities": [{"text": "parsing", "start_pos": 30, "end_pos": 37, "type": "TASK", "confidence": 0.9799339771270752}, {"text": "parsing", "start_pos": 65, "end_pos": 72, "type": "TASK", "confidence": 0.9617317318916321}]}, {"text": "For our parsing experiments, we used the MaltParser () to train an Arabic dependency parser in the space of both CATiB and NUDAR.", "labels": [], "entities": [{"text": "parsing", "start_pos": 8, "end_pos": 15, "type": "TASK", "confidence": 0.9785943031311035}, {"text": "NUDAR", "start_pos": 123, "end_pos": 128, "type": "DATASET", "confidence": 0.8617149591445923}]}, {"text": "We compared the output of the NUDAR parser, to the results of converting the output of the CATiB parser to NUDAR using the system described in Section 3.", "labels": [], "entities": []}, {"text": "For the CATiB parser, we used the optimized settings described by, and were able to achieve comparable results.", "labels": [], "entities": [{"text": "CATiB parser", "start_pos": 8, "end_pos": 20, "type": "TASK", "confidence": 0.5555432736873627}]}, {"text": "We used the gold CATiBex POS tags, and gold morphological features derived from gold BW tags, to train the parser on the TRAIN dataset of PATB parts 1, 2, and 3.", "labels": [], "entities": [{"text": "TRAIN dataset of PATB parts 1", "start_pos": 121, "end_pos": 150, "type": "DATASET", "confidence": 0.8132431457440058}]}, {"text": "We tested on the TEST dataset of the same treebank parts.", "labels": [], "entities": [{"text": "TEST dataset", "start_pos": 17, "end_pos": 29, "type": "DATASET", "confidence": 0.767195999622345}]}, {"text": "The output of the parser was then converted to NUDAR representation.", "labels": [], "entities": []}, {"text": "For the NUDAR parser, we ran the MaltOptimizer (Ballesteros and Nivre, 2012) on the full TRAIN dataset of NUDAR.", "labels": [], "entities": [{"text": "TRAIN dataset of NUDAR", "start_pos": 89, "end_pos": 111, "type": "DATASET", "confidence": 0.8442859947681427}]}, {"text": "We used the optimized settings to train and run our parser.", "labels": [], "entities": []}, {"text": "The results of these experiments are shown in.", "labels": [], "entities": []}, {"text": "The first row shows the result of training the MaltParser on the NUDAR training dataset with the optimized settings.", "labels": [], "entities": [{"text": "NUDAR training dataset", "start_pos": 65, "end_pos": 87, "type": "DATASET", "confidence": 0.928128719329834}]}, {"text": "The second row shows the results of training the MatlParser on the CATiB training dataset, with the optimized settings from.", "labels": [], "entities": [{"text": "CATiB training dataset", "start_pos": 67, "end_pos": 89, "type": "DATASET", "confidence": 0.9097466071446737}]}, {"text": "Finally, the last row shows the results of converting the output of the CATiB parser to NUDAR representation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The tokens and sentences in the current NUDAR Treebank, based on PATB parts 1, 2, and 3", "labels": [], "entities": [{"text": "NUDAR Treebank", "start_pos": 50, "end_pos": 64, "type": "DATASET", "confidence": 0.9797039031982422}]}, {"text": " Table 4: Conversion scores against manually cre- ated gold trees", "labels": [], "entities": []}, {"text": " Table 5: Scores for the NUDAR and CATiB pars- ing and conversion experiments", "labels": [], "entities": [{"text": "NUDAR", "start_pos": 25, "end_pos": 30, "type": "DATASET", "confidence": 0.8854870200157166}, {"text": "CATiB pars- ing", "start_pos": 35, "end_pos": 50, "type": "TASK", "confidence": 0.4721345528960228}]}]}