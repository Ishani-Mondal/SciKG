{"title": [], "abstractContent": [{"text": "In this paper we describe the non-linear mappings we used with the Helsinki language identification method, HeLI, in the 4 th edition of the Discriminating between Similar Languages (DSL) shared task, which was organized as part of the Var-Dial 2017 workshop.", "labels": [], "entities": [{"text": "Helsinki language identification", "start_pos": 67, "end_pos": 99, "type": "TASK", "confidence": 0.6515700419743856}, {"text": "Discriminating between Similar Languages (DSL) shared task", "start_pos": 141, "end_pos": 199, "type": "TASK", "confidence": 0.7026711735460494}]}, {"text": "Our SUKI team participated in the closed track together with 10 other teams.", "labels": [], "entities": [{"text": "SUKI team", "start_pos": 4, "end_pos": 13, "type": "DATASET", "confidence": 0.8214319348335266}]}, {"text": "Our system reached the 7 th position in the track.", "labels": [], "entities": []}, {"text": "We describe the HeLI method and the non-linear map-pings in mathematical notation.", "labels": [], "entities": []}, {"text": "The HeLI method uses a probabilistic model with character n-grams and word-based back-off.", "labels": [], "entities": []}, {"text": "We also describe our trials using the non-linear mappings instead of relative frequencies and we present statistics about the back-off function of the HeLI method.", "labels": [], "entities": []}], "introductionContent": [{"text": "The 4 th edition of the Discriminating between Similar Languages (DSL) shared task () was divided into an open and a closed track.", "labels": [], "entities": [{"text": "Discriminating between Similar Languages (DSL) shared task", "start_pos": 24, "end_pos": 82, "type": "TASK", "confidence": 0.7006629804770151}]}, {"text": "In the closed track the participants were allowed to use only the training data provided by the organizers, whereas in the open track the participants could use any data source they had at their disposal.", "labels": [], "entities": []}, {"text": "This year we did not participate in the open track, so we did not use any additional sources for training and development.", "labels": [], "entities": []}, {"text": "The creation of the earlier DSL corpora has been described by . This year's training data consisted of 18,000 lines of text, excerpts of journalistic texts, for each of the 14 languages.", "labels": [], "entities": [{"text": "DSL corpora", "start_pos": 28, "end_pos": 39, "type": "DATASET", "confidence": 0.9141629636287689}]}, {"text": "The corresponding development set had 2,000 lines of text for each language.", "labels": [], "entities": []}, {"text": "The task had a language selection comparable to the 1 st ( ), 2 nd (, and 3 rd () editions of the shared task.", "labels": [], "entities": []}, {"text": "The languages and varieties are listed in.", "labels": [], "entities": []}, {"text": "The differences from the previous year's shared task were the inclusion of Persian and Dari languages, as well as replacing the Mexican Spanish variety with Peruvian Spanish.: The languages and varieties of the 4 th edition of the Discriminating between Similar Languages (DSL) shared task.", "labels": [], "entities": [{"text": "Discriminating between Similar Languages (DSL) shared task", "start_pos": 231, "end_pos": 289, "type": "TASK", "confidence": 0.708928300274743}]}, {"text": "For the 4 th edition, we were interested in modifying the HeLI method and use the TF-IDF scores and some non-linear mappings instead of relative frequencies.", "labels": [], "entities": []}, {"text": "We were inspired by the successful use of TF-IDF scores by.", "labels": [], "entities": []}, {"text": "He was able to significantly boost the accuracy of his identifier after the 3 rd edition of the shared task by using the TF-IDF scores.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9994364380836487}, {"text": "TF-IDF", "start_pos": 121, "end_pos": 127, "type": "METRIC", "confidence": 0.7914096713066101}]}, {"text": "Earlier, managed to boost several language identification methods using non-linear mappings.", "labels": [], "entities": [{"text": "language identification", "start_pos": 34, "end_pos": 57, "type": "TASK", "confidence": 0.7328516393899918}]}], "datasetContent": [{"text": "In order to find the best possible parameters (n max , c, and p), we applied a simple form of the greedy algorithm using the development set.", "labels": [], "entities": []}, {"text": "The best recall for the original HeLI method, 0.9105, was reached using n max = 8, c = 170,000, and p of 6.6.", "labels": [], "entities": [{"text": "recall", "start_pos": 9, "end_pos": 15, "type": "METRIC", "confidence": 0.9984911680221558}]}], "tableCaptions": [{"text": " Table 2. In  the table, \"l. n max \" refers to the maximum num- ber of lowercased n-grams, \"c. n max \" to the n- grams with also capital letters, \"l. w.\" to lower- cased words, and \"c. w.\" to words with original  capitalization. We did similar tests with different  combinations of the language models when choos- ing the models to be used with the loglike-function  described later.", "labels": [], "entities": []}, {"text": " Table 2: Testing the different combinations of lan- guage models on the development set.", "labels": [], "entities": []}, {"text": " Table 4: Testing the loglike function on the devel- opment set.", "labels": [], "entities": []}, {"text": " Table 5: Results for the closed training.", "labels": [], "entities": []}, {"text": " Table 6: Parameters for the closed training.", "labels": [], "entities": [{"text": "Parameters", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9795952439308167}]}, {"text": " Table 7: Number of words identified with each  length of n-gram.", "labels": [], "entities": []}, {"text": " Table 8: Number of words of each length.", "labels": [], "entities": []}]}