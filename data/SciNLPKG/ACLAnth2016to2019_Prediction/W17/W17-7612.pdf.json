{"title": [{"text": "REALEC learner treebank: annotation principles and evaluation of automatic parsing Institute of the Russian Language RAS Moscow", "labels": [], "entities": [{"text": "REALEC learner treebank", "start_pos": 0, "end_pos": 23, "type": "DATASET", "confidence": 0.7008565664291382}, {"text": "automatic parsing Institute of the Russian Language RAS", "start_pos": 65, "end_pos": 120, "type": "TASK", "confidence": 0.632623553276062}]}], "abstractContent": [{"text": "The paper presents a Universal Dependencies (UD) annotation scheme fora learner English corpus.", "labels": [], "entities": []}, {"text": "The REALEC dataset consists of essays written in English by Russian-speaking university students in the course of general English.", "labels": [], "entities": [{"text": "REALEC dataset", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.8052334785461426}]}, {"text": "The original corpus is manually annotated for learners' errors and gives information on the error span, error type, and the possible correction of the mistake provided by experts.", "labels": [], "entities": []}, {"text": "The syntactic dependency annotation adds more value to learner corpora since it makes it possible to explore the interaction of syntax and different types of errors.", "labels": [], "entities": []}, {"text": "Also, it helps to assess the syntactic complexity of learners' texts.", "labels": [], "entities": []}, {"text": "While adjusting existing dependency parsing tools, one has to take into account to what extent students' mistakes provoke errors in the parser output.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.6729545146226883}]}, {"text": "The ungrammatical and stylistically inappropriate utterances may challenge parsers' algorithms trained on grammatically appropriate academic texts.", "labels": [], "entities": []}, {"text": "In our experiments, we compared the output of the dependency parser Ud-pipe (trained on ud-english 2.0) with the results of manual parsing, placing a particular focus on parses of ungrammatical English clauses.", "labels": [], "entities": [{"text": "dependency parser Ud-pipe", "start_pos": 50, "end_pos": 75, "type": "TASK", "confidence": 0.7130964597066244}, {"text": "parses of ungrammatical English clauses", "start_pos": 170, "end_pos": 209, "type": "TASK", "confidence": 0.7699422478675843}]}, {"text": "We show how mistakes made by students influence the work of the parser.", "labels": [], "entities": []}, {"text": "Overall, Ud-pipe performed reasonably well (UAS 92.9, LAS 91.7).", "labels": [], "entities": [{"text": "Ud-pipe", "start_pos": 9, "end_pos": 16, "type": "DATASET", "confidence": 0.6188689470291138}, {"text": "UAS 92.9", "start_pos": 44, "end_pos": 52, "type": "DATASET", "confidence": 0.7368955612182617}, {"text": "LAS", "start_pos": 54, "end_pos": 57, "type": "METRIC", "confidence": 0.9491865634918213}]}, {"text": "We provide the analysis of several cases of erroneous parsing which are due to the incorrect detection of ahead, on the one hand, and with the wrong choice of the relation type, on the other hand.", "labels": [], "entities": []}, {"text": "We propose some solutions which could improve the automatic output and thus make the syntax-based learner corpus research and assessment of the syntactic complexity more reliable.", "labels": [], "entities": []}, {"text": "The REALEC treebank is freely available under the CC BY-SA 3.0 licence.", "labels": [], "entities": [{"text": "REALEC treebank", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.7352742850780487}, {"text": "CC BY-SA 3.0 licence", "start_pos": 50, "end_pos": 70, "type": "DATASET", "confidence": 0.7931696847081184}]}], "introductionContent": [{"text": "The diversity of research based on learner corpora is increasing in the fields of language acquisition and language teaching methodology.", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 82, "end_pos": 102, "type": "TASK", "confidence": 0.7419215738773346}]}, {"text": "The manual and automatic analysis of texts written by learners leads to the creation of various tools used for pedagogical purposes, namely, for improvements in teaching techniques achieved by paying attention to frequent errors that have been made by generations of learners.", "labels": [], "entities": []}, {"text": "Linguistic data obtained in the analysis of the learner corpora texts serve as a basis not only for teaching but also for evaluating the works written by people learning a language.", "labels": [], "entities": []}, {"text": "Using different automatic tools in learner corpus is a frequent idea of works aimed at checking the progress of language learning.", "labels": [], "entities": []}, {"text": "For example, Cobb and Horst point out the importance of such analysis of learners' essays (.", "labels": [], "entities": []}, {"text": "introduce a publicly available syntactic treebank for English as a Second Language (ESL), which provides manually annotated POS tags and Universal Dependency (UD), with which the data obtained from the parser can be checked.", "labels": [], "entities": [{"text": "Universal Dependency (UD)", "start_pos": 137, "end_pos": 162, "type": "METRIC", "confidence": 0.8604928731918335}]}, {"text": "Moreover, ESL annotation allows for consistent syntactic treatment of ungrammatical English texts.", "labels": [], "entities": []}, {"text": "Many applications based on syntactic parsing have been created in cooperation with, in which the results on linguistic evaluation of complexity are presented.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.7567567229270935}]}, {"text": "One more complexity analyzer is made by.", "labels": [], "entities": []}, {"text": "This work provides a set of simple criteria such as the length of each clause, the number of dependent clauses, and soon.", "labels": [], "entities": []}, {"text": "In authors discuss how to improve syntactic annotation for learner language by dint of clarifying the properties which the layers of annotation refer to.", "labels": [], "entities": []}, {"text": "They also show the mistakes of annotation that could be corrected with the help of some tools.", "labels": [], "entities": []}, {"text": "The list of the studies in learner data syntactic parsing also includes, who explore how dependency annotation complements the annotation of errors, and (, who focus on innovations in learner's grammar revealed by parsing, to name just a few.", "labels": [], "entities": [{"text": "learner data syntactic parsing", "start_pos": 27, "end_pos": 57, "type": "TASK", "confidence": 0.6050761267542839}]}, {"text": "In () Bertus van Rooy and Lande Sch\u00e4fer present the idea that spelling errors cause errors in parsing.", "labels": [], "entities": []}, {"text": "Also they show how learners' errors influence the performance of the taggers.", "labels": [], "entities": []}, {"text": "Our research, as we hope to show, also confirms this.", "labels": [], "entities": []}, {"text": "In () syntax complexity is discussed with the examples from REALEC.", "labels": [], "entities": [{"text": "REALEC", "start_pos": 60, "end_pos": 66, "type": "DATASET", "confidence": 0.7948192358016968}]}, {"text": "The paper presents the results of the syntactic analysis made by parsing the sentences and taking into account the mean sentence depth and the average number of relative clauses, other adnominal clauses, and adverbial clauses.", "labels": [], "entities": []}, {"text": "There we cleared up how much these criteria influence the syntactic complexity of the essay.", "labels": [], "entities": []}, {"text": "The analysis showed that the mean sentence depth is insignificant for evaluation of a text, and the average number of clauses, on the contrary, is considered to be the feature distinguishing better works (scored 75% and higher) from all others.", "labels": [], "entities": []}, {"text": "In the section 'Original data' we present data on which we based for this research.", "labels": [], "entities": []}, {"text": "The next part of the text named 'Dependency annotation scheme' shows how we worked on the examples from the corpus.", "labels": [], "entities": []}, {"text": "Section 'Choice among alternatives' explains how we chose the option of the annotation.", "labels": [], "entities": []}, {"text": "The next chapter presents the sample of our research and also reports which tool we have used.", "labels": [], "entities": []}, {"text": "In the section 'Confusion matrix and causes of errors' we show the relations which are confused frequently in students' essays.", "labels": [], "entities": []}, {"text": "In 'Constructions that require attention' the examples from corpus that cause the errors in the parser's work are brought in.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1 illustrates the confusion matrix for the most frequent mismatches in relation types. The totals are  calculated for all relations.", "labels": [], "entities": []}]}