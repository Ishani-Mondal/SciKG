{"title": [], "abstractContent": [{"text": "This paper applies parsing technology to the task of syntactic simplification of En-glish sentences, focusing on the identification of text spans that can be removed from a complex sentence.", "labels": [], "entities": [{"text": "syntactic simplification of En-glish sentences", "start_pos": 53, "end_pos": 99, "type": "TASK", "confidence": 0.8321122050285339}]}, {"text": "We report the most comprehensive evaluation to-date on this task, using a dataset of sentences that exhibit simplification based on coordination , subordination, punctuation/parataxis, adjectival clauses, participial phrases, and appositive phrases.", "labels": [], "entities": []}, {"text": "We train a decision tree with features derived from text span length, POS tags and dependency relations , and show that it significantly outper-forms a parser-only baseline.", "labels": [], "entities": []}], "introductionContent": [{"text": "The task of text simplification aims to rewrite a sentence so as to reduce its complexity, while preserving its meaning and grammaticality.", "labels": [], "entities": [{"text": "text simplification", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.7134964019060135}]}, {"text": "The rewriting may involve various aspects, including lexical simplification, syntactic simplification, content deletion, and content insertion for clarification.", "labels": [], "entities": [{"text": "syntactic simplification", "start_pos": 77, "end_pos": 101, "type": "TASK", "confidence": 0.7014887481927872}, {"text": "content deletion", "start_pos": 103, "end_pos": 119, "type": "TASK", "confidence": 0.715436115860939}, {"text": "content insertion", "start_pos": 125, "end_pos": 142, "type": "TASK", "confidence": 0.7125921547412872}]}, {"text": "This paper focuses on syntactic simplification and, specifically, on splitting a complex sentence into two simpler sentences.", "labels": [], "entities": [{"text": "syntactic simplification", "start_pos": 22, "end_pos": 46, "type": "TASK", "confidence": 0.8692440092563629}]}, {"text": "Consider the input sentence S in, a complex sentence containing a participial phrase, \"carrying numerous books\".", "labels": [], "entities": []}, {"text": "After removing this phrase from S, the system generates S 2 from the phrase by turning the participle \"carrying\" into the finite form \"was carrying\", and by generating the pronoun \"he\" as the subject.", "labels": [], "entities": []}, {"text": "A number of systems can already perform this task (; Siddharthan, * The second author completed this work as a Postdoctoral Fellow at City University of Hong Kong.", "labels": [], "entities": []}, {"text": "The simplified sentences can in turn be split iteratively.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our system's performance at identifying a text span, if any, in a complex sentence that should be removed to form an independent sentence.", "labels": [], "entities": []}, {"text": "As expected, the baseline system achieved relatively high recall (0.88) but low precision (0.34), since it always tries to split a text span that matches any of the tree patterns in.", "labels": [], "entities": [{"text": "recall", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.9994068145751953}, {"text": "precision", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.9989470839500427}]}, {"text": "The decision tree was able to substantially increase the precision (0.63) by learning some useful rules, at the expense of lower recall (0.72).", "labels": [], "entities": [{"text": "precision", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.9996050000190735}, {"text": "recall", "start_pos": 129, "end_pos": 135, "type": "METRIC", "confidence": 0.9994701743125916}]}, {"text": "Some rules that substantially contributed to the performance gain are as follows.", "labels": [], "entities": []}, {"text": "Consider the rule that a comma should separate the word from its parent when the dependency relation is xcomp.", "labels": [], "entities": []}, {"text": "It was able to block the system from mistakenly tak-: Precision, recall and F-measure for identifying the text span to be removed from S. ing the phrase \"conducting at Montreux ...\" out of the sentence \"He began conducting at Montreux ...\".", "labels": [], "entities": [{"text": "Precision", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9979775547981262}, {"text": "recall", "start_pos": 65, "end_pos": 71, "type": "METRIC", "confidence": 0.9988001585006714}, {"text": "F-measure", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9992231130599976}]}, {"text": "Another useful rule was that the parent word in the conj relation must be root; otherwise, the structure is likely coordinated NPs rather than coordinated clauses.", "labels": [], "entities": []}, {"text": "Further, when the modifier is tagged as TO (i.e., an infinitive), or when the subject of the sentence is a determiner (e.g., \"this\", \"that\"), no splitting should be done.", "labels": [], "entities": [{"text": "TO", "start_pos": 40, "end_pos": 42, "type": "METRIC", "confidence": 0.9314031600952148}]}, {"text": "Finally, shorter text spans are less likely to be split up.", "labels": [], "entities": []}, {"text": "Among the different constructs, the proposed system performed best for punctuation/parataxis, with precision at 0.92 and recall at 0.95.", "labels": [], "entities": [{"text": "precision", "start_pos": 99, "end_pos": 108, "type": "METRIC", "confidence": 0.9994900226593018}, {"text": "recall", "start_pos": 121, "end_pos": 127, "type": "METRIC", "confidence": 0.9990956783294678}]}, {"text": "This construct is not only clearly marked, but also more consistently split up.", "labels": [], "entities": []}, {"text": "The most challenging construct turned out to be appositive phrases, with precision at 0.36 and recall at 0.56.", "labels": [], "entities": [{"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9993829727172852}, {"text": "recall", "start_pos": 95, "end_pos": 101, "type": "METRIC", "confidence": 0.9989606142044067}]}, {"text": "Many of the errors trickled down from inaccurate analysis by the automatic parser, especially mistakes in relative clause attachment and clause boundary identification . The precision figures can be viewed as lower bounds.", "labels": [], "entities": [{"text": "relative clause attachment", "start_pos": 106, "end_pos": 132, "type": "TASK", "confidence": 0.684966246287028}, {"text": "clause boundary identification", "start_pos": 137, "end_pos": 167, "type": "TASK", "confidence": 0.6640099783738455}, {"text": "precision", "start_pos": 174, "end_pos": 183, "type": "METRIC", "confidence": 0.998346209526062}]}, {"text": "In post-hoc analysis, we found that many of the proposed text spans by our system can be acceptable, but they were not deemed necessary to be split up by the editors of Simple Wikipedia.", "labels": [], "entities": [{"text": "Simple Wikipedia", "start_pos": 169, "end_pos": 185, "type": "DATASET", "confidence": 0.7668533027172089}]}, {"text": "Ultimately, the decision to split a complex sentence should be made in consideration of the reader's proficiency, but our current dataset does not support the modelling of this factor.", "labels": [], "entities": [{"text": "split a complex sentence", "start_pos": 28, "end_pos": 52, "type": "TASK", "confidence": 0.834009662270546}]}], "tableCaptions": [{"text": " Table 5: Features used by the decision tree.", "labels": [], "entities": []}, {"text": " Table 6: Precision, recall and F-measure for iden- tifying the text span to be removed from S.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9990849494934082}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9995129108428955}, {"text": "F-measure", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9994569420814514}]}]}