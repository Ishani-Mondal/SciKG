{"title": [{"text": "Optimizing a PoS Tagset for Norwegian Dependency Parsing", "labels": [], "entities": [{"text": "PoS Tagset", "start_pos": 13, "end_pos": 23, "type": "DATASET", "confidence": 0.642773300409317}, {"text": "Norwegian Dependency Parsing", "start_pos": 28, "end_pos": 56, "type": "TASK", "confidence": 0.6449475288391113}]}], "abstractContent": [{"text": "This paper reports on a suite of experiments that evaluates how the linguistic granularity of part-of-speech tagsets impacts the performance of tagging and syntactic dependency parsing.", "labels": [], "entities": [{"text": "syntactic dependency parsing", "start_pos": 156, "end_pos": 184, "type": "TASK", "confidence": 0.7394881645838419}]}, {"text": "Our results show that parsing accuracy can be significantly improved by introducing more fine-grained morphological information in the tagset, even if tagger accuracy is compromised.", "labels": [], "entities": [{"text": "parsing", "start_pos": 22, "end_pos": 29, "type": "TASK", "confidence": 0.9816926717758179}, {"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.927794873714447}, {"text": "accuracy", "start_pos": 158, "end_pos": 166, "type": "METRIC", "confidence": 0.8714479207992554}]}, {"text": "Our taggers and parsers are trained and tested using the annotations of the Norwegian Dependency Treebank.", "labels": [], "entities": [{"text": "Norwegian Dependency Treebank", "start_pos": 76, "end_pos": 105, "type": "DATASET", "confidence": 0.9447888533274332}]}], "introductionContent": [{"text": "Part-of-speech (PoS) tagging is an important preprocessing step for many NLP tasks, such as dependency parsing, named entity recognition) and sentiment analysis (.", "labels": [], "entities": [{"text": "Part-of-speech (PoS) tagging", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.5738299727439881}, {"text": "dependency parsing", "start_pos": 92, "end_pos": 110, "type": "TASK", "confidence": 0.8162394464015961}, {"text": "named entity recognition", "start_pos": 112, "end_pos": 136, "type": "TASK", "confidence": 0.6040051678816477}, {"text": "sentiment analysis", "start_pos": 142, "end_pos": 160, "type": "TASK", "confidence": 0.9673845767974854}]}, {"text": "Whereas much effort has gone into the development of PoS taggers -to the effect that this task is often considered more or less a solved task -considerably less effort has been devoted to the empirical evaluation of the PoS tagsets themselves.", "labels": [], "entities": [{"text": "PoS taggers", "start_pos": 53, "end_pos": 64, "type": "TASK", "confidence": 0.856463223695755}]}, {"text": "Error analysis of PoS taggers indicate that, whereas tagging improvement through means of learning algorithm or feature engineering seems to have reached something of a plateau, linguistic and empirical assessment of the distinctions made in the PoS tagsets maybe an avenue worth investigating further.", "labels": [], "entities": [{"text": "PoS taggers", "start_pos": 18, "end_pos": 29, "type": "TASK", "confidence": 0.75346440076828}, {"text": "tagging", "start_pos": 53, "end_pos": 60, "type": "TASK", "confidence": 0.9617607593536377}]}, {"text": "Clearly, the utility of a PoS tagset is tightly coupled with the downstream task for which it is performed.", "labels": [], "entities": []}, {"text": "Even so, PoS tagsets are usually employed in a \"one size fits all\" fashion, regardless of the requirements posed by the task making use of this information.", "labels": [], "entities": [{"text": "PoS tagsets", "start_pos": 9, "end_pos": 20, "type": "TASK", "confidence": 0.7033823728561401}]}, {"text": "It is well known that syntactic parsing often benefits from quite fine-grained morphological distinctions ().", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 22, "end_pos": 39, "type": "TASK", "confidence": 0.843341588973999}]}, {"text": "Morphology interacts with syntax through phenomena such as agreement and case marking, and incorporating information on morphological properties of words can therefore often improve parsing performance.", "labels": [], "entities": [{"text": "case marking", "start_pos": 73, "end_pos": 85, "type": "TASK", "confidence": 0.6835666298866272}]}, {"text": "However, in a realistic setting where the aim is to automatically parse raw text, the generation of morphological information will often require a separate step of morphological analysis that can be quite costly.", "labels": [], "entities": []}, {"text": "In this paper, we optimize a PoS tagset for the task of dependency parsing of Norwegian Bokm\u00e5l.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 56, "end_pos": 74, "type": "TASK", "confidence": 0.8326936364173889}, {"text": "Norwegian Bokm\u00e5l", "start_pos": 78, "end_pos": 94, "type": "DATASET", "confidence": 0.8033455908298492}]}, {"text": "We report on a set of experiments where PoS tags are extended with various morphological properties and evaluated in terms of both tagging accuracy and syntactic parsing accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.9698595404624939}, {"text": "syntactic parsing", "start_pos": 152, "end_pos": 169, "type": "TASK", "confidence": 0.6534325480461121}, {"text": "accuracy", "start_pos": 170, "end_pos": 178, "type": "METRIC", "confidence": 0.6120946407318115}]}, {"text": "Our results show that the introduction of morphological distinctions not present in the original tagset, whilst compromising tagger accuracy, actually leads to significantly improved parsing accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 132, "end_pos": 140, "type": "METRIC", "confidence": 0.8952844142913818}, {"text": "parsing", "start_pos": 183, "end_pos": 190, "type": "TASK", "confidence": 0.9666613340377808}, {"text": "accuracy", "start_pos": 191, "end_pos": 199, "type": "METRIC", "confidence": 0.8617708086967468}]}, {"text": "This optimization also allows us to bypass the additional step of morphological analysis, framing the whole pre-processing problem as a simple tagging task.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 66, "end_pos": 88, "type": "TASK", "confidence": 0.7150141000747681}]}, {"text": "The impact on parser performance is also more pronounced in this study than in similar previous work, as surveyed in Section 2 next.", "labels": [], "entities": []}, {"text": "For the remainder of the paper, Section 3 details the treebank that provides the basis for our experiments, while Section 4 describes the experimental setup.", "labels": [], "entities": []}, {"text": "Section 5 goes onto provide the results from our tagset optimization, before we finally summarize our main findings and discuss some directions for future work in Section 6.", "labels": [], "entities": [{"text": "tagset optimization", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.731802761554718}]}], "datasetContent": [{"text": "This section briefly outlines some key components of our experimental setup.", "labels": [], "entities": []}, {"text": "Data Set Split As there was no existing standardized data set split of NDT due to its recent development, we first needed to define separate sections for training, development and testing.", "labels": [], "entities": [{"text": "NDT", "start_pos": 71, "end_pos": 74, "type": "DATASET", "confidence": 0.9035286903381348}]}, {"text": "1 Our proposed sectioning of the treebank follows a standard 80-10-10 split.", "labels": [], "entities": [{"text": "sectioning", "start_pos": 15, "end_pos": 25, "type": "TASK", "confidence": 0.9776350259780884}]}, {"text": "In establishing the split, care has been taken to preserve contiguous texts in the various sections while also keeping them balanced in terms of genre.", "labels": [], "entities": []}, {"text": "Tagger As our experiments during development required many repeated cycles of training and testing for the various modified tagsets, we sought a PoS tagger that is both reasonably fast and accurate.", "labels": [], "entities": [{"text": "PoS tagger", "start_pos": 145, "end_pos": 155, "type": "TASK", "confidence": 0.6286042481660843}]}, {"text": "There is often a considerable trade-off between the two factors, as the most accurate taggers tend to suffer in terms of speed due to their complexity.", "labels": [], "entities": [{"text": "speed", "start_pos": 121, "end_pos": 126, "type": "METRIC", "confidence": 0.9820027351379395}]}, {"text": "However, a widely used tagger that achieves both close to state-of-the-art accuracy as well as very high speed is TnT, and hence we adopt this for the current study.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9987155199050903}, {"text": "speed", "start_pos": 105, "end_pos": 110, "type": "METRIC", "confidence": 0.9914950132369995}, {"text": "TnT", "start_pos": 114, "end_pos": 117, "type": "METRIC", "confidence": 0.6664907932281494}]}, {"text": "Parser In choosing a syntactic parser for our experiments, we considered previous work on dependency parsing of Norwegian, specifically that of, who found the graphbased Mate parser to have the best performance for NDT.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 90, "end_pos": 108, "type": "TASK", "confidence": 0.7795743346214294}, {"text": "NDT", "start_pos": 215, "end_pos": 218, "type": "DATASET", "confidence": 0.7593626379966736}]}, {"text": "Recent dependency parser comparisons ( show very strong results for Mate also for English, outperforming a range of contemporary state-of-the-art parsers.", "labels": [], "entities": [{"text": "dependency parser", "start_pos": 7, "end_pos": 24, "type": "TASK", "confidence": 0.7121147513389587}]}, {"text": "We will be using Mate for gauging the effects of the tagset modifications in our experiments.", "labels": [], "entities": []}, {"text": "Evaluation To evaluate tagging and parsing with the various tagset modifications in our experiments, we employ a standard set of measures.", "labels": [], "entities": [{"text": "tagging", "start_pos": 23, "end_pos": 30, "type": "TASK", "confidence": 0.9662793278694153}]}, {"text": "Tagging is evaluated in terms of accuracy (computed by the TnT-included tnt-diff script; denoted Acc in the following tables), while parsing is evaluated in terms of labeled and unlabeled attachment score (LAS and UAS; computed by the eval.pl 2 script from the CoNLL shared tasks).", "labels": [], "entities": [{"text": "Tagging", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.9278653860092163}, {"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9991337656974792}, {"text": "Acc", "start_pos": 97, "end_pos": 100, "type": "METRIC", "confidence": 0.9906625151634216}, {"text": "LAS", "start_pos": 206, "end_pos": 209, "type": "METRIC", "confidence": 0.8804376125335693}]}, {"text": "Tagging Baseline In addition to the tagging accuracy for the original unmodified tagset, we include the most-frequent-tag baseline (MFT), as another point of reference.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9230634570121765}, {"text": "most-frequent-tag baseline (MFT)", "start_pos": 104, "end_pos": 136, "type": "METRIC", "confidence": 0.7175273060798645}]}, {"text": "This involves labeling each word with the tag it was assigned most frequently in the training data.", "labels": [], "entities": []}, {"text": "All unknown words, i.e., words not seen in the training data, are assigned the tag most frequently observed for words seen only once.", "labels": [], "entities": []}, {"text": "The MFT baseline will also serve to indicate the ambiguity imposed by the additional tags in a given tagset modification.", "labels": [], "entities": [{"text": "MFT baseline", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.5759672820568085}]}, {"text": "Predicted vs. Gold Tags Seeking to quantify the effects of PoS tagging on parsing, we choose to both evaluate and train the parser on automatically predicted PoS tags.", "labels": [], "entities": [{"text": "PoS tagging", "start_pos": 59, "end_pos": 70, "type": "TASK", "confidence": 0.710747092962265}, {"text": "parsing", "start_pos": 74, "end_pos": 81, "type": "TASK", "confidence": 0.9582631587982178}]}, {"text": "Training on predicted tags makes the training set-up correspond more closely to a realistic test setting and makes it possible for the parser to adapt to errors made by the tagger.", "labels": [], "entities": []}, {"text": "While this is often achieved using jackknifing (n-fold training and tagging of the labeled training data), we here simply apply the taggers to the very same data they have been trained on, reflecting the 'training error' of the taggers.", "labels": [], "entities": []}, {"text": "In an initial experiment we also found that training on  such 'silver-standard' tags actually improves parsing scores substantially compared to training on gold tags, as shown in.", "labels": [], "entities": [{"text": "parsing", "start_pos": 103, "end_pos": 110, "type": "TASK", "confidence": 0.9679743647575378}]}, {"text": "In fact, also found that this set-up actually yields higher parsing scores compared to 10-fold tagging of the training data.", "labels": [], "entities": []}, {"text": "Of course, the test set for which we evaluate the performance is still unseen data for the tagger.", "labels": [], "entities": []}, {"text": "In an initial round of experiments, we concatenated the tag of each token with its full set of morphological features, thereby mapping the original tagset to anew maximally fine-grained tagset, given the annotations available in the treebank.", "labels": [], "entities": []}, {"text": "This resulted in a total of 368 tags, hereafter referred to as the full tagset.", "labels": [], "entities": []}, {"text": "The two initial tagsets, i.e., the original tagset comprising 19 tags and the full tagset comprising 368 tags, thus represent two extremes in terms of granularity.", "labels": [], "entities": []}, {"text": "To establish some initial points of reference for how tagset granularity affects the performance of tagging and parsing on NDT, we trained and tested a full pipeline with both of these initial tagsets.", "labels": [], "entities": [{"text": "NDT", "start_pos": 123, "end_pos": 126, "type": "DATASET", "confidence": 0.7369902729988098}]}, {"text": "The results are reported in.", "labels": [], "entities": []}, {"text": "Unsurprisingly, we see that the tagger accuracy plummets when we move from the original to the full tagset.", "labels": [], "entities": [{"text": "tagger", "start_pos": 32, "end_pos": 38, "type": "TASK", "confidence": 0.9427183866500854}, {"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9795005321502686}]}, {"text": "While the MFT baseline for the original tagset is 94.14%, it drops by almost 9 percentage points to 85.15% for the full tagset.", "labels": [], "entities": [{"text": "MFT baseline", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.8738576769828796}]}, {"text": "Correspondingly, TnT achieves 97.47% and 93.48% accuracy for the original and full tagset, respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9971598386764526}]}, {"text": "These results confirm our hypothesis that the high level of linguistic information in the full, fine-grained tagset comes at the expense of reduced tagger performance.", "labels": [], "entities": []}, {"text": "In spite of this drop, however, we see that the additional information in the full tagset still improves the parser performance.", "labels": [], "entities": []}, {"text": "With the original tagset, Mate achieves 87.01% LAS and 90.19% UAS, which for the full tagset increases to 87.15% and 90.39%, respectively.", "labels": [], "entities": [{"text": "LAS", "start_pos": 47, "end_pos": 50, "type": "METRIC", "confidence": 0.9965924620628357}, {"text": "UAS", "start_pos": 62, "end_pos": 65, "type": "METRIC", "confidence": 0.9985122084617615}]}, {"text": "These preliminary results are encouraging in indicating that the additional linguistic information assists the syntactic parser, motivating further optimization of the tagset.", "labels": [], "entities": []}, {"text": "We modify the tags for nouns (subst), verbs (verb), adjectives (adj), determiners (det) and pronouns (pron) in NDT by appending selected sets of morphological features to each tag in order to increase the linguistic information expressed by the tags.", "labels": [], "entities": [{"text": "NDT", "start_pos": 111, "end_pos": 114, "type": "DATASET", "confidence": 0.8996487855911255}]}, {"text": "For each tag, we in turn first experiment with each of the available features in isolation before testing various combinations.", "labels": [], "entities": []}, {"text": "We base our choices of combinations on how promising the features are in isolation and what we deem worth investigating in terms of linguistic utility.", "labels": [], "entities": []}, {"text": "The morphological properties of the various parts-of-speech are reflected in the morphological features associated with the respective PoS tags.", "labels": [], "entities": []}, {"text": "For instance, as nouns in Norwegian inflect for gender, definiteness and number, the treebank operates with additional features for these properties.", "labels": [], "entities": []}, {"text": "In addition to morphological properties such as definiteness, tense and number, all classes except for verbs have a type feature that provides information about the subtype of the PoS, e.g., whether a noun is common or proper.", "labels": [], "entities": []}, {"text": "Nouns In Norwegian, nouns are assigned gender (feminine, masculine or neuter), definiteness (definite or indefinite) and number (singular or plural).", "labels": [], "entities": []}, {"text": "There is agreement in gender, definiteness and number between nouns and their modifiers (i.e., adjectives and determiners).", "labels": [], "entities": []}, {"text": "Additionally, NDT has a separate case feature for distinguishing nouns in genitive case.", "labels": [], "entities": [{"text": "NDT", "start_pos": 14, "end_pos": 17, "type": "DATASET", "confidence": 0.8873302340507507}]}, {"text": "Genitive case marks possession, hence nouns marked with genitive case are quite different from other nouns, taking a noun phrase as complement.", "labels": [], "entities": []}, {"text": "Distinguishing on type can be useful, as evident by the presence of separate tags for proper and common nouns in many tagsets, such as those of Penn Treebank and Stockholm-Ume\u00e5 corpus.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 144, "end_pos": 157, "type": "DATASET", "confidence": 0.9927432239055634}, {"text": "Stockholm-Ume\u00e5 corpus", "start_pos": 162, "end_pos": 183, "type": "DATASET", "confidence": 0.8104216158390045}]}, {"text": "The results for tagset modifications for nouns are shown in  Verbs Verbs are inflected for tense (infinitive, present, preterite or past perfect) in Norwegian and additionally exhibit mood (imperative or indicative) and voice (active or passive).", "labels": [], "entities": []}, {"text": "Note that both voice and mood have only a single value in the treebank; pass (passive) and imp (imperative), respectively.", "labels": [], "entities": []}, {"text": "Verbs which are not passive are implicitly active, and verbs which are not imperative are in indicative mood.", "labels": [], "entities": []}, {"text": "presents the results from tagging and parsing with modified verb tags.", "labels": [], "entities": [{"text": "tagging", "start_pos": 26, "end_pos": 33, "type": "TASK", "confidence": 0.9663446545600891}]}, {"text": "Imperative clauses are fundamentally different from indicative clauses as they lack an overt subject, which is reflected in the fact that mood is the only feature leading to an increase in LAS, with a reported LAS of 87.04%.", "labels": [], "entities": [{"text": "LAS", "start_pos": 189, "end_pos": 192, "type": "METRIC", "confidence": 0.9899097681045532}, {"text": "LAS", "start_pos": 210, "end_pos": 213, "type": "METRIC", "confidence": 0.9909317493438721}]}, {"text": "Although voice is a very distinguishing property for verbs, and passive clauses are very different from active clauses, introducing this distinction in the tagset leads to a drop in LAS of 0.05 percentage points, while distinguishing between the various tenses yields an LAS of 86.97%.", "labels": [], "entities": [{"text": "LAS", "start_pos": 182, "end_pos": 185, "type": "METRIC", "confidence": 0.9975649118423462}, {"text": "LAS", "start_pos": 271, "end_pos": 274, "type": "METRIC", "confidence": 0.9968389272689819}]}, {"text": "Combining the two most promising features of mood and tense resulted in an LAS of 87.12% and UAS of 90.31%.", "labels": [], "entities": [{"text": "LAS", "start_pos": 75, "end_pos": 78, "type": "METRIC", "confidence": 0.9988946318626404}, {"text": "UAS", "start_pos": 93, "end_pos": 96, "type": "METRIC", "confidence": 0.9995637536048889}]}, {"text": "In an additional experiment, we mapped the verb tenses (and mood, in the case of imperative) to finiteness.", "labels": [], "entities": []}, {"text": "All verbs have finiteness, hence this distinction has broad coverage.", "labels": [], "entities": []}, {"text": "This mapping is syntactically grounded as finite verbs and nonfinite verbs appear in very different syntactic constructions, and proved to improve parsing with a 0.29 and 0.24 percentage points improvement over the baseline, for LAS and UAS, respectively.", "labels": [], "entities": [{"text": "LAS", "start_pos": 229, "end_pos": 232, "type": "METRIC", "confidence": 0.5714946389198303}, {"text": "UAS", "start_pos": 237, "end_pos": 240, "type": "DATASET", "confidence": 0.7235199213027954}]}, {"text": "This coincides with the previous observations for   Swedish in, where finiteness was found to be a very beneficial feature for parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 127, "end_pos": 134, "type": "TASK", "confidence": 0.9761542677879333}]}, {"text": "Adjectives Adjectives agree with the noun they modify in terms of gender, number and definiteness.", "labels": [], "entities": []}, {"text": "Furthermore, adjectives are inflected for degree (positive, comparative or superlative).", "labels": [], "entities": []}, {"text": "shows the results of modifying the pron tag in NDT.", "labels": [], "entities": [{"text": "NDT", "start_pos": 47, "end_pos": 50, "type": "DATASET", "confidence": 0.9340029954910278}]}, {"text": "All features except for number lead to increases in parser accuracy scores, the most successful of which is degree with a reported LAS of 87.29%, while distinguishing adjectives on definiteness yields an LAS of 87.14% and introducing the distinction of gender leads to LAS of 87.10%.", "labels": [], "entities": [{"text": "accuracy scores", "start_pos": 59, "end_pos": 74, "type": "METRIC", "confidence": 0.9654302000999451}, {"text": "degree", "start_pos": 108, "end_pos": 114, "type": "METRIC", "confidence": 0.996234118938446}, {"text": "LAS", "start_pos": 131, "end_pos": 134, "type": "METRIC", "confidence": 0.9048713445663452}, {"text": "LAS", "start_pos": 204, "end_pos": 207, "type": "METRIC", "confidence": 0.984636664390564}, {"text": "LAS", "start_pos": 269, "end_pos": 272, "type": "METRIC", "confidence": 0.9970759153366089}]}, {"text": "Turning to combinations of features, definiteness and number achieve the best parser accuracy scores, very close to those of degree.", "labels": [], "entities": [{"text": "definiteness", "start_pos": 37, "end_pos": 49, "type": "METRIC", "confidence": 0.9399357438087463}, {"text": "number", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.9751386642456055}, {"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9882432818412781}, {"text": "degree", "start_pos": 125, "end_pos": 131, "type": "METRIC", "confidence": 0.9587039947509766}]}, {"text": "Adjectives agree with their head noun and determiner in definiteness and number, making this an expected improvement.", "labels": [], "entities": []}, {"text": "The combination of definiteness and degree is also quite promising, obtaining LAS of 87.23% and UAS of 90.39%.", "labels": [], "entities": [{"text": "definiteness", "start_pos": 19, "end_pos": 31, "type": "METRIC", "confidence": 0.9926880598068237}, {"text": "degree", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9883826375007629}, {"text": "LAS", "start_pos": 78, "end_pos": 81, "type": "METRIC", "confidence": 0.9991326928138733}, {"text": "UAS", "start_pos": 96, "end_pos": 99, "type": "METRIC", "confidence": 0.9973993301391602}]}, {"text": "It is interesting that none of the combinations surpass the experiment with degree in isolation, which indicates that degree does not interact with the other features in any syntactically significant way.", "labels": [], "entities": []}, {"text": "Determiners Like adjectives, determiners in Norwegian agree with the noun they modify in  terms of gender, number and definiteness.", "labels": [], "entities": [{"text": "Determiners", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9475922584533691}]}, {"text": "The results from the experiments with determiners are shown in.", "labels": [], "entities": []}, {"text": "Introducing the distinction of type (demonstrative, amplifier, quantifier, possessive or interrogative) led to an increase in tagger accuracy of 0.14 percentage points to 97.61%, while marginally impacting the parsing, with LAS of 87.00%, 0.01 percentage points below that of the original tagset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.9910551309585571}, {"text": "parsing", "start_pos": 210, "end_pos": 217, "type": "TASK", "confidence": 0.9632150530815125}, {"text": "LAS", "start_pos": 224, "end_pos": 227, "type": "METRIC", "confidence": 0.9978640675544739}]}, {"text": "The increase in tagger accuracy when introducing the distinction of type is noteworthy, as we expected the finer granularity to lead to a decrease inaccuracy.", "labels": [], "entities": [{"text": "tagger", "start_pos": 16, "end_pos": 22, "type": "TASK", "confidence": 0.912205696105957}, {"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9671092629432678}]}, {"text": "This serves to indicate that more fine-grained distinctions for determiners, which is a quite disparate category in the treebank, maybe quite useful for tagging.", "labels": [], "entities": [{"text": "determiners", "start_pos": 64, "end_pos": 75, "type": "TASK", "confidence": 0.9570561051368713}]}, {"text": "Gender, on the other hand, improved parsing (87.09% LAS), but complicated tagging, as the various genders are often difficult to differentiate, in particular masculine and feminine, which share many of the same forms.", "labels": [], "entities": [{"text": "parsing", "start_pos": 36, "end_pos": 43, "type": "TASK", "confidence": 0.9744857549667358}, {"text": "LAS", "start_pos": 52, "end_pos": 55, "type": "METRIC", "confidence": 0.9865806102752686}, {"text": "tagging", "start_pos": 74, "end_pos": 81, "type": "TASK", "confidence": 0.9654362797737122}]}, {"text": "The number of a determiner, i.e., singular or plural, led to a small increase in tagger accuracy and LAS, while marginally lower UAS.", "labels": [], "entities": [{"text": "tagger", "start_pos": 81, "end_pos": 87, "type": "TASK", "confidence": 0.7869951725006104}, {"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9732062816619873}, {"text": "LAS", "start_pos": 101, "end_pos": 104, "type": "METRIC", "confidence": 0.9955678582191467}, {"text": "UAS", "start_pos": 129, "end_pos": 132, "type": "METRIC", "confidence": 0.8536767959594727}]}, {"text": "The introduction of definiteness gave the best parsing results, LAS of 87.30% and UAS of 90.42%, and additionally increased tagger accuracy slightly.", "labels": [], "entities": [{"text": "parsing", "start_pos": 47, "end_pos": 54, "type": "TASK", "confidence": 0.9666561484336853}, {"text": "LAS", "start_pos": 64, "end_pos": 67, "type": "METRIC", "confidence": 0.9991938471794128}, {"text": "UAS", "start_pos": 82, "end_pos": 85, "type": "METRIC", "confidence": 0.9992703795433044}, {"text": "tagger", "start_pos": 124, "end_pos": 130, "type": "TASK", "confidence": 0.9296320080757141}, {"text": "accuracy", "start_pos": 131, "end_pos": 139, "type": "METRIC", "confidence": 0.9702475666999817}]}, {"text": "The increase in LAS and UAS is rather interesting, as there are only 121 determiner tokens with marked definiteness in the development data.", "labels": [], "entities": [{"text": "LAS", "start_pos": 16, "end_pos": 19, "type": "METRIC", "confidence": 0.8068798780441284}, {"text": "UAS", "start_pos": 24, "end_pos": 27, "type": "METRIC", "confidence": 0.5427232980728149}]}, {"text": "As this accounts fora very small number of tokens, we did not consider further fine-grained modifications with definiteness.", "labels": [], "entities": []}, {"text": "This result further underlines the importance of definiteness for parsing of Norwegian.", "labels": [], "entities": [{"text": "parsing of Norwegian", "start_pos": 66, "end_pos": 86, "type": "TASK", "confidence": 0.913506289323171}]}, {"text": "Pronouns Pronouns in Norwegian include personal, reciprocal, reflexive and interrogative.", "labels": [], "entities": []}, {"text": "They can furthermore exhibit gender, number and person, while personal pronouns can be distinguished by case (either accusative or nominative).", "labels": [], "entities": []}, {"text": "The results in show that number, person and type are the most useful features for parsing, with LAS of 87.21%, 87.22% and 87.19%, respectively.", "labels": [], "entities": [{"text": "parsing", "start_pos": 82, "end_pos": 89, "type": "TASK", "confidence": 0.988610565662384}, {"text": "LAS", "start_pos": 96, "end_pos": 99, "type": "METRIC", "confidence": 0.9985307455062866}]}, {"text": "However, when combining number: Tagging and parsing with modified PoS tags for pronouns. and person, we observe a drop of more than 0.2 percentage points, indicating that these features do not interact in any syntactically distinctive way.", "labels": [], "entities": [{"text": "Tagging", "start_pos": 32, "end_pos": 39, "type": "TASK", "confidence": 0.9664311408996582}]}, {"text": "The most interesting observation is that all results exceed the tagging accuracy of the original tagset, with the most fine-grained distinction (type, case and number combined) provides the largest improvement (accuracy of 97.52%).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.7496592402458191}, {"text": "accuracy", "start_pos": 211, "end_pos": 219, "type": "METRIC", "confidence": 0.9991747736930847}]}, {"text": "This shows that the introduction of more fine-grained distinctions for pronouns aids the PoS tagger in disambiguating ambiguous words.", "labels": [], "entities": [{"text": "PoS tagger", "start_pos": 89, "end_pos": 99, "type": "TASK", "confidence": 0.6472896635532379}]}, {"text": "While case alone yields an LAS of 87.08%, we found that the combination of type and case yields the second highest tagging accuracy of 97.51%.", "labels": [], "entities": [{"text": "LAS", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.992999792098999}, {"text": "accuracy", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.9390379190444946}]}, {"text": "Pronouns of different type and personal pronouns of different case exhibit quite different properties and appear in different constructions.", "labels": [], "entities": []}, {"text": "Pronouns in nominative case (i.e., subjects) primarily occur before the main verb, while pronouns in accusative case (i.e., objects) occur after the main verb, as Norwegian exhibits so-called V2 word order, requiring that the finite verb of a declarative clause appears in the second position.: Results of tagging and parsing with the best tagset modification for each category.", "labels": [], "entities": [{"text": "tagging", "start_pos": 306, "end_pos": 313, "type": "TASK", "confidence": 0.9640370607376099}]}], "tableCaptions": [{"text": " Table 3: Results of parsing with Mate using var- ious configurations of PoS tag sources in training  and testing. Gold denotes gold standard tags while  Auto denotes tags automatically predicted by TnT.", "labels": [], "entities": [{"text": "parsing", "start_pos": 21, "end_pos": 28, "type": "TASK", "confidence": 0.9685379862785339}]}, {"text": " Table 4: Tagging and parsing our development  section of NDT with the two initial tagsets. From  left to right, we report the tagger accuracy of the  most-frequent-tag baseline, the tagger accuracy of  TnT, and the labeled and unlabeled attachment  score for the Mate parser.", "labels": [], "entities": [{"text": "Tagging", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9731543660163879}, {"text": "NDT", "start_pos": 58, "end_pos": 61, "type": "DATASET", "confidence": 0.8999179601669312}, {"text": "accuracy", "start_pos": 134, "end_pos": 142, "type": "METRIC", "confidence": 0.8339406251907349}, {"text": "accuracy", "start_pos": 190, "end_pos": 198, "type": "METRIC", "confidence": 0.7037079334259033}]}, {"text": " Table 5: Tagging and parsing with modified PoS  tags for nouns. The first row corresponds to using  the original tagset unmodified.", "labels": [], "entities": [{"text": "Tagging", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9857718348503113}]}, {"text": " Table 6: Tagging and parsing with modified PoS  tags for verbs.", "labels": [], "entities": [{"text": "Tagging", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9865471124649048}]}, {"text": " Table 7: Tagging and parsing with modified PoS  tags for adjectives.", "labels": [], "entities": [{"text": "Tagging", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.987911581993103}]}, {"text": " Table 8: Tagging and parsing with modified PoS  tags for determiners.", "labels": [], "entities": [{"text": "Tagging", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9888900518417358}, {"text": "parsing", "start_pos": 22, "end_pos": 29, "type": "TASK", "confidence": 0.9115721583366394}]}, {"text": " Table 9: Tagging and parsing with modified PoS  tags for pronouns.", "labels": [], "entities": [{"text": "Tagging", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9886981844902039}]}, {"text": " Table 10: Results of tagging and parsing with the  best tagset modification for each category.", "labels": [], "entities": [{"text": "tagging", "start_pos": 22, "end_pos": 29, "type": "TASK", "confidence": 0.9821885228157043}]}, {"text": " Table 12: Results of tagging and parsing with the  optimized tagset, compared to the original NDT  coarse tagset. The parser is both trained and tested  using automatically predicted tags from TnT.", "labels": [], "entities": [{"text": "tagging", "start_pos": 22, "end_pos": 29, "type": "TASK", "confidence": 0.9721677303314209}, {"text": "parsing", "start_pos": 34, "end_pos": 41, "type": "TASK", "confidence": 0.9388154745101929}, {"text": "NDT  coarse tagset", "start_pos": 95, "end_pos": 113, "type": "DATASET", "confidence": 0.9251070022583008}]}]}