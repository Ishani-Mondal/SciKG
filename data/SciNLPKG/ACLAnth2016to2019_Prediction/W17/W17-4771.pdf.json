{"title": [{"text": "BLEU2VEC: the Painfully Familiar Metric on Continuous Vector Space Steroids", "labels": [], "entities": [{"text": "BLEU2VEC", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9836501479148865}]}], "abstractContent": [{"text": "In this participation in the WMT'2017 metrics shared task we implement a fuzzy match score for n-gram precisions in the BLEU metric.", "labels": [], "entities": [{"text": "WMT'2017 metrics shared task", "start_pos": 29, "end_pos": 57, "type": "TASK", "confidence": 0.6730746328830719}, {"text": "BLEU", "start_pos": 120, "end_pos": 124, "type": "METRIC", "confidence": 0.9946744441986084}]}, {"text": "To do this we learn n-gram embeddings; we describe two ways of extending the WORD2VEC approach to do so.", "labels": [], "entities": []}, {"text": "Evaluation results show that the introduced score beats the original BLEU metric on system and segment level.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.9761704802513123}]}], "introductionContent": [], "datasetContent": [{"text": "In order to evaluate the metric we trained word and n-gram embeddings using the monolingual: System-level correlation between human judgments from WMT'2015 and the original BLEU metric as well as our two modifications.", "labels": [], "entities": [{"text": "WMT'2015", "start_pos": 147, "end_pos": 155, "type": "DATASET", "confidence": 0.9511997699737549}, {"text": "BLEU", "start_pos": 173, "end_pos": 177, "type": "METRIC", "confidence": 0.9711607694625854}]}, {"text": "BLEU2VEC SEP stands for separate n-gram embedding learning and BLEU2VEC JOINT stands for the joint learning model.: Segment-level correlation between human judgments and the SENT-BLEU metric as well as our two modifications.", "labels": [], "entities": [{"text": "BLEU2VEC SEP", "start_pos": 0, "end_pos": 12, "type": "METRIC", "confidence": 0.9350356161594391}, {"text": "BLEU2VEC", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9979633092880249}, {"text": "JOINT", "start_pos": 72, "end_pos": 77, "type": "METRIC", "confidence": 0.4995155930519104}]}, {"text": "data from the WMT'2017 news translation shared task: we took a random 50 million sentences from the News Crawl corpora for each language (except Chinese, where we used a portion of Common Crawl).", "labels": [], "entities": [{"text": "WMT'2017 news translation shared task", "start_pos": 14, "end_pos": 51, "type": "TASK", "confidence": 0.8024660110473633}, {"text": "News Crawl corpora", "start_pos": 100, "end_pos": 118, "type": "DATASET", "confidence": 0.9443568189938863}]}, {"text": "While this year's human judgments are still being annotated at the time of final submission, we present correlation results based on WMT 2015 data for English in for system-level correlations and for segment-level correlations.", "labels": [], "entities": [{"text": "WMT 2015 data", "start_pos": 133, "end_pos": 146, "type": "DATASET", "confidence": 0.923554519812266}]}, {"text": "Results show that both our metrics perform better than the baseline on system-level evaluation.", "labels": [], "entities": []}, {"text": "In all cases the joint n-gram embedding learning model performs slightly worse than the separate learning approach.", "labels": [], "entities": []}, {"text": "The same effect can be seen on segment-level evaluations, whereas for Russian-English translations the correlation of both our metrics is worse than SENT-BLEU.", "labels": [], "entities": [{"text": "SENT-BLEU", "start_pos": 149, "end_pos": 158, "type": "METRIC", "confidence": 0.9822937846183777}]}], "tableCaptions": [{"text": " Table 1: System-level correlation between human judgments from WMT'2015 and the original  BLEU metric as well as our two modifications. BLEU2VEC SEP stands for separate n-gram embedding  learning and BLEU2VEC JOINT stands for the joint learning model.", "labels": [], "entities": [{"text": "WMT'2015", "start_pos": 64, "end_pos": 72, "type": "DATASET", "confidence": 0.9520348906517029}, {"text": "BLEU", "start_pos": 91, "end_pos": 95, "type": "METRIC", "confidence": 0.9965469241142273}, {"text": "BLEU2VEC SEP", "start_pos": 137, "end_pos": 149, "type": "METRIC", "confidence": 0.8868979811668396}, {"text": "BLEU2VEC", "start_pos": 201, "end_pos": 209, "type": "METRIC", "confidence": 0.9910861849784851}, {"text": "JOINT", "start_pos": 210, "end_pos": 215, "type": "METRIC", "confidence": 0.5020833015441895}]}, {"text": " Table 2: Segment-level correlation between human judgments and the SENT-BLEU metric as well as our  two modifications.", "labels": [], "entities": [{"text": "SENT-BLEU metric", "start_pos": 68, "end_pos": 84, "type": "METRIC", "confidence": 0.9640651047229767}]}]}