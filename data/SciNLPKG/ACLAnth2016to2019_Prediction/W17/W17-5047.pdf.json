{"title": [{"text": "A deep-learning based native-language classification by using a latent semantic analysis for the NLI Shared Task 2017", "labels": [], "entities": [{"text": "native-language classification", "start_pos": 22, "end_pos": 52, "type": "TASK", "confidence": 0.7115894556045532}]}], "abstractContent": [{"text": "This paper proposes a deep-learning based native-language identification (NLI) using a latent semantic analysis (LSA) as a participant (ETRI-SLP) of the NLI Shared Task 2017 (Malmasi et al., 2017) where the NLI Shared Task 2017 aims to detect the native language of an essay or speech response of a standardized assessment of English proficiency for academic purposes.", "labels": [], "entities": [{"text": "native-language identification (NLI)", "start_pos": 42, "end_pos": 78, "type": "TASK", "confidence": 0.8315967559814453}]}, {"text": "To this end, we use the six unit forms of a text data such as character 4/5/6-grams and word 1/2/3-grams.", "labels": [], "entities": []}, {"text": "For each unit form of text data, we convert it into a count-based vector, extract a 2000-rank LSA feature, and perform a linear discriminant analysis (LDA) based dimension reduction.", "labels": [], "entities": []}, {"text": "From the count-based vector or the LSA-LDA feature, we also obtain the output prediction values of a support vector machine (SVM) based clas-sifier, the output prediction values of a deep neural network (DNN) based classi-fier, and the bottleneck values of a DNN based classifier.", "labels": [], "entities": []}, {"text": "In order to incorporate the various kinds of text-based features and a speech-based i-vector feature, we design two DNN based ensemble classi-fiers for late fusion and early fusion, respectively.", "labels": [], "entities": []}, {"text": "From the NLI experiments, the F1 (macro) scores are obtained as 0.8601, 0.8664, and 0.9220 for the essay track, the speech track, and the fusion track, respectively.", "labels": [], "entities": [{"text": "F1 (macro) scores", "start_pos": 30, "end_pos": 47, "type": "METRIC", "confidence": 0.8572599053382873}]}, {"text": "The proposed method has comparable performance to the top-ranked teams for the speech and fusion tracks, although it has slightly lower performance for the essay track.", "labels": [], "entities": []}], "introductionContent": [{"text": "Native-language identification (NLI) can be used to improve the performance of automatic speech recognition (ASR) for non-native speakers using native-language (L1) specific ASR systems.", "labels": [], "entities": [{"text": "Native-language identification (NLI)", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.849876469373703}, {"text": "automatic speech recognition (ASR)", "start_pos": 79, "end_pos": 113, "type": "TASK", "confidence": 0.8052422602971395}]}, {"text": "NLI can also be used in a computer-assisted language learning system using the L1-specific target-language errors.", "labels": [], "entities": []}, {"text": "A considerable body of research on NLI has been reported and the developed approaches can be classified into text-based NLI, speech-based NLI, and text and speech based NLI ().", "labels": [], "entities": []}, {"text": "Among them, this paper focuses on the NLI of text and speech data for the NLI Shared Task 2017 ( . The first NLI Shared Task aims to identify the L1 of the text data of an essay response.", "labels": [], "entities": []}, {"text": "Notably, apart of the 2016 Computational Paralinguistics Challenge focuses on speech-based NLI (.", "labels": [], "entities": []}, {"text": "This year, the goal of the NLI Shared Task 2017 is to detect the L1 of the essay and speech responses of a standardized assessment of English proficiency for academic purposes among eleven L1s, Arabic, Chinese, French, German, Hindi, Italian, Japanese, Korean, Spanish, Telugu, and Turkish.", "labels": [], "entities": []}, {"text": "To this end, there are 11,000 training data set, 1,100 development data set, and 1,100 test data set.", "labels": [], "entities": []}, {"text": "In addition, each data set contains the text of an essay response, the transcription text and 800-dimensional i-vector feature of a speech response, and the L1 annotation of the participant of essay and speech responses.", "labels": [], "entities": []}, {"text": "In this paper, we propose a deep-learning based NLI method using a latent semantic analysis (LSA) as a participant (ETRI-SLP) of the NLI Shared Task 2017.", "labels": [], "entities": []}, {"text": "First, the higher-rank of an LSA feature is used to detect L1 information; the lower-rank of an LSA feature is used to detect document topic information).", "labels": [], "entities": []}, {"text": "Second, we adopt a state-ofthe-art machine learning methods, a deep-learning method, for L1 classification using various kinds of text-based features and a speech-based feature.", "labels": [], "entities": [{"text": "L1 classification", "start_pos": 89, "end_pos": 106, "type": "TASK", "confidence": 0.7963464558124542}]}, {"text": "2 Feature extraction of the proposed method", "labels": [], "entities": [{"text": "Feature extraction", "start_pos": 2, "end_pos": 20, "type": "TASK", "confidence": 0.722046285867691}]}], "datasetContent": [{"text": "For the L1 detection of the essay track, we only used the vanilla DNN based ensemble classifier with the assumption that the text-related features were not extremely heterogeneous for each other.", "labels": [], "entities": []}, {"text": "The submitted ETRI-SPL NLI system for the essay track was performed as follows.", "labels": [], "entities": [{"text": "ETRI-SPL NLI", "start_pos": 14, "end_pos": 26, "type": "METRIC", "confidence": 0.819888174533844}]}, {"text": "We first transformed each text data into the six unit forms such as word 1/2/3-grams and character 4/5/6-grams.", "labels": [], "entities": []}, {"text": "Then, we extracted the , and Raw LSA2000/LDA10 ) for each unittransformed text.", "labels": [], "entities": [{"text": "Raw LSA2000/LDA10", "start_pos": 29, "end_pos": 46, "type": "DATASET", "confidence": 0.6853079050779343}]}, {"text": "As a result, we obtained the thirty features for each text and then concatenated them into one 450-dimensional feature.", "labels": [], "entities": []}, {"text": "The concatenated feature was then normalized to a zero mean and unit variance.", "labels": [], "entities": []}, {"text": "After that, the normalized feature was fed into the input layer of a vanilla DNN based ensemble classifier.", "labels": [], "entities": []}, {"text": "As shown in  layer, first and third DO hidden layers, second and fourth FC hidden layers, and an output layer.", "labels": [], "entities": []}, {"text": "Each FC layer contained 256 nodes with a tanh activation function.", "labels": [], "entities": []}, {"text": "Prior to the performance comparison of the proposed ETRI-SPL NLI for the essay track, we evaluated the performance corresponding to each unit form.", "labels": [], "entities": [{"text": "ETRI-SPL NLI", "start_pos": 52, "end_pos": 64, "type": "DATASET", "confidence": 0.8822328746318817}]}, {"text": "To this end, we extracted the six Raw LSA2000/LDA10 features for the word 1/2/3-grams and character 4/5/6-grams, respectively.", "labels": [], "entities": [{"text": "Raw LSA2000/LDA10", "start_pos": 34, "end_pos": 51, "type": "DATASET", "confidence": 0.8340888768434525}]}, {"text": "Then, we generated the vanilla DNN based ensemble classifier using each of the six features.", "labels": [], "entities": []}, {"text": "After that, the six classifiers were evaluated for the development data.", "labels": [], "entities": []}, {"text": "It was shown from the second, third, and fourth rows of that the performances corresponding to the word n-grams were improved except for the word 3-gram when compared to the performance of the official baseline.", "labels": [], "entities": []}, {"text": "It was noted that the performance degradation corresponding to the word 3-gram was occurred due to a data sparseness.", "labels": [], "entities": []}, {"text": "Moreover, it was shown from the fifth, sixth, and seventh rows of the table that the performances corresponding to the character n-grams were improved according to the increase of the n-gram order.", "labels": [], "entities": []}, {"text": "Especially, the performance corresponding to the character 6-gram outperformed among the others.", "labels": [], "entities": []}, {"text": "Next, we evaluated the performance corresponding to each feature type.", "labels": [], "entities": []}, {"text": "In other words, we extracted each of the five feature types using the six unit forms of a text.", "labels": [], "entities": []}, {"text": "After that, we generated the five vanilla DNN based ensemble classifiers corresponding to the feature types and then we measured the accuracy-based performance for the development data.", "labels": [], "entities": [{"text": "accuracy-based", "start_pos": 133, "end_pos": 147, "type": "METRIC", "confidence": 0.9965582489967346}]}, {"text": "As shown in the second, third, fourth, fifth, and sixth rows of  , and Raw LSA2000/LDA10 , respectively.", "labels": [], "entities": [{"text": "Raw LSA2000/LDA10", "start_pos": 71, "end_pos": 88, "type": "DATASET", "confidence": 0.9205554276704788}]}, {"text": "Thus, it could be noted that each feature type successes to combine the six unit forms.", "labels": [], "entities": []}, {"text": "Finally, the accuracy of the proposed ETRI-SPL NLI for the essay track was 0.8445 using the thirty features by combining the six unit forms and the five feature types, as shown in the last row of the figure.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9998308420181274}, {"text": "ETRI-SPL NLI", "start_pos": 38, "end_pos": 50, "type": "METRIC", "confidence": 0.7280623614788055}]}, {"text": "When compared to the above rows of the figure, we concluded that the thirty features were well combined for the NLI.", "labels": [], "entities": [{"text": "NLI", "start_pos": 112, "end_pos": 115, "type": "DATASET", "confidence": 0.8859468102455139}]}, {"text": "For the L1 detection of the speech track using the transcription text and i-vector feature of a speech response, we used the multi-column deep-stacking DNN based ensemble classifier with the assumption that the text-related features were clearly heterogeneous to the speech-related i-vector feature.", "labels": [], "entities": []}, {"text": "Moreover, we empirically selected the feature, Raw LSA2000/LDA10 , for the efficient combination with the text-related features and the i-vector feature.", "labels": [], "entities": [{"text": "Raw LSA2000/LDA10", "start_pos": 47, "end_pos": 64, "type": "DATASET", "confidence": 0.7443719208240509}]}, {"text": "The submitted ETRI-SPL NLI for the speech track was performed as follows.", "labels": [], "entities": [{"text": "ETRI-SPL NLI", "start_pos": 14, "end_pos": 26, "type": "METRIC", "confidence": 0.7752238214015961}]}, {"text": "We first transformed each transcription text into the six unit forms and then extracted the Raw LSA2000/LDA10 for each unit-transformed text.", "labels": [], "entities": [{"text": "Raw LSA2000/LDA10", "start_pos": 92, "end_pos": 109, "type": "DATASET", "confidence": 0.9092125445604324}]}, {"text": "In addition, we used the 800-dimensional i-vector feature for each speech response signal.", "labels": [], "entities": []}, {"text": "The text-related feature was then normalized to a zero mean and unit variance and the i-vector feature was normalized using a LDA normalization.", "labels": [], "entities": []}, {"text": "As shown in  feature layers were then connected to the input layer of the fusion layers.", "labels": [], "entities": []}, {"text": "Each feature layers consisted of an input layer, the first and second FC hidden layers, the third DO hidden layer, and an output layer, where the FC layers contained 64 and 256 nodes for Raw LSA2000/LDA10 and i-vector, respectively, with an exponential linear unit (ELU) activation function.", "labels": [], "entities": []}, {"text": "And, the fusion layers consisted of an input layer, the first max-pooling hidden layer, the second and fourth DO hidden layers, the third FC hidden layer, and an output layer, where the FC layer contained 256 nodes with a tanh activation function.", "labels": [], "entities": []}, {"text": "Prior to the performance evaluation of the proposed ETRI-SPL NLI for the speech track, we evaluated the performance corresponding to each text-related feature, the i-vector feature, and the feature combinations using a vanilla DNN based ensemble classifier, as shown in.", "labels": [], "entities": []}, {"text": "To this end, the extracted features were concatenated into one feature and then the concatenated feature was normalized using an LDA normalization since the i-vector feature was well matched with the LDA normalization rather than a normalization to a zero mean and unit variance.", "labels": [], "entities": []}, {"text": "After that, the normalized feature was fed into the input layer of the vanilla  for the speech track when evaluating the development data, where the underlined and the bolded represent the remarkable system and the submitted system, respectively.", "labels": [], "entities": []}, {"text": "The 'early fusion' of the vanilla DNN based ensemble classifier indicates a classifier that uses no feature-based classifier.", "labels": [], "entities": []}, {"text": "And, 'Mean/Var.'", "labels": [], "entities": []}, {"text": "indicates a normalization to a zero mean and unit variance.", "labels": [], "entities": []}, {"text": "The (d)' means the noisy data of the DN N LSA2000/LDA10 bottleneck , which was an unexpected data.", "labels": [], "entities": [{"text": "DN N LSA2000/LDA10 bottleneck", "start_pos": 37, "end_pos": 66, "type": "DATASET", "confidence": 0.9430671036243439}]}, {"text": "The vanilla DNN based ensemble classifier consisted of an input layer, the first, third, and fourth FC hidden layers, the second DO hidden layer, and an output layer, where each FC hidden layer contained 512 nodes with a rectified linear unit (RELU) activation function.", "labels": [], "entities": []}, {"text": "Also, it was noted that the number of nodes of the FC hidden layer was increased according to the increase of the dimension of the input feature data.", "labels": [], "entities": []}, {"text": "From the fourth row to the ninth row of, it was noted that the i-vector feature outperformed the text-related features.", "labels": [], "entities": []}, {"text": "Among the textrelated features, the LSA-LDA based features had better performances when compared to the countbased feature.", "labels": [], "entities": []}, {"text": "From the tenth row to the fourteenth row of the table, the SV M LSA2000/LDA10 output and Raw LSA2000/LDA10 improved the only i-vector feature when combining one text-related feature and the i-vector feature.", "labels": [], "entities": []}, {"text": "However, it was shown from the fifteenth row to the twenty-fifth row of the table that the combination with two or more text-related features and the i-vector feature did not improve the combination with one text-related feature and the i-vector feature.", "labels": [], "entities": []}, {"text": "It was summarized that there was no improvement on the combination with two or more text-related features since the text-related features had similar information using the same unit forms.", "labels": [], "entities": []}, {"text": "From the twenty-sixth row to the thirtieth row of the table, all the combinations of one text-related feature and the i-vector feature were improved using the multi-column deep-stacking DNN based ensemble classifier when compared to the use of one feature; only two features were improved using the vanilla DNN based ensemble classifier.", "labels": [], "entities": []}, {"text": "Moreover, the thirty-first row of the table showed that the performance of the combination with the two text-related features and ivector feature was slightly degraded; however, the degree of the performance degradation was marginal.", "labels": [], "entities": []}, {"text": "Finally, the last row of the table presented the performance of the submitted system.", "labels": [], "entities": []}, {"text": "In fact, the original intention was to combine the two text-related features and i-vector feature.", "labels": [], "entities": []}, {"text": "Unfortunately, we found that the noisy data was inserted as the DN N LSA2000/LDA10 bottleneck after the submission.", "labels": [], "entities": [{"text": "DN N LSA2000/LDA10 bottleneck", "start_pos": 64, "end_pos": 93, "type": "DATASET", "confidence": 0.9007573028405508}]}, {"text": "However, from the performance evaluation, we could examine that the multi-column deep-stacking DNN based ensemble classifier had the robust performance to a noisy data.", "labels": [], "entities": []}, {"text": "For the L1 detection of the fusion track using the text of an essay response and the transcription text and i-vector feature of a speech response, we used the multi-column deep-stacking DNN based ensemble classifier.", "labels": [], "entities": []}, {"text": "For the efficient combination with the text-related features and the speech i-vector feature, we empirically selected the Raw LSA2000/LDA10 among nonclassifier-based features.", "labels": [], "entities": [{"text": "Raw LSA2000/LDA10", "start_pos": 122, "end_pos": 139, "type": "DATASET", "confidence": 0.8230115473270416}]}, {"text": "The submitted ETRI-SPL NLI for the fusion track was performed as  follows.", "labels": [], "entities": [{"text": "ETRI-SPL NLI", "start_pos": 14, "end_pos": 26, "type": "METRIC", "confidence": 0.6116709411144257}]}, {"text": "We first transformed each text of the essay and speech transcription into the six unit forms and then extracted the Raw LSA2000/LDA10 for each unit-transformed text.", "labels": [], "entities": [{"text": "Raw LSA2000/LDA10", "start_pos": 116, "end_pos": 133, "type": "DATASET", "confidence": 0.9030966907739639}]}, {"text": "To fuse an essay response and a speech response, the count-based vector of the speech transcription text was appended to the count-based vector of the essay text for each pair of an essay text and speech transcription text during the feature extraction of the Raw LSA2000/LDA10 . We also used the 800-dimensional i-vector feature of each speech response signal.", "labels": [], "entities": [{"text": "Raw LSA2000/LDA10", "start_pos": 260, "end_pos": 277, "type": "DATASET", "confidence": 0.8692352175712585}]}, {"text": "The text-related features were then normalized to a zero mean and unit variance and the i-vector feature were normalized using a LDA normalization.", "labels": [], "entities": []}, {"text": "As shown in, the Raw LSA2000/LDA10 and i-vector features were fed into the LSA/LDA feature layers and the ivector layers, respectively.", "labels": [], "entities": []}, {"text": "The node values of the last hidden layer of each feature layers were then connected to the input layer of the fusion layers.", "labels": [], "entities": []}, {"text": "Each feature layers consisted of an input layer, the FC hidden layer, and an output layer,  where the FC layers contained 64 and 128 nodes for Raw LSA2000/LDA10 and i-vector, respectively, with an ELU activation function.", "labels": [], "entities": []}, {"text": "And, the fusion layers consisted of an input layer, the first and sixth DO hidden layers, the fourth, fifth, and seventh FC hidden layers, the second p-norm pooling hidden layer, the third variance normalization hidden layer, and an output layer, where each FC layer contained 196 nodes with a tanh activation function and the p-norm and variance normalization layers contained 96 nodes.", "labels": [], "entities": []}, {"text": "Prior to the performance evaluation of the proposed ETRI-SPL NLI for the fusion track, we evaluated the performance corresponding to the Raw LSA2000/LDA10 , the i-vector feature, and the feature combination, respectively, using a vanilla DNN based ensemble classifier, as shown in.", "labels": [], "entities": [{"text": "ETRI-SPL NLI", "start_pos": 52, "end_pos": 64, "type": "DATASET", "confidence": 0.8624872863292694}, {"text": "Raw LSA2000/LDA10", "start_pos": 137, "end_pos": 154, "type": "DATASET", "confidence": 0.8166595250368118}]}, {"text": "To this end, the extracted features were concatenated into one feature and then the concatenated feature was normalized using an LDA normalization.", "labels": [], "entities": []}, {"text": "The normalized feature was then fed into the input layer of the vanilla DNN based ensemble classifier.", "labels": [], "entities": []}, {"text": "The vanilla DNN based ensemble classifier consisted of an input layer, the first, third, fifth, and seventh DO hidden layers, the second, fourth, sixth, and eighth FC hidden layers, and an output layer, where each FC hidden layer contained 512 nodes with a tanh activation function.", "labels": [], "entities": []}, {"text": "It was shown from the second row to the seventh row of that the LSA-LDA features had better performances than the count-based feature and i-vector feature when applying an LDA normalization.", "labels": [], "entities": []}, {"text": "It was shown from the eighth row to the thirteenth row of the table that the count-based feature and i-vector feature were well matched with a normalization to a zero mean and unit variance and with an LDA normalization, respectively.", "labels": [], "entities": [{"text": "LDA", "start_pos": 202, "end_pos": 205, "type": "METRIC", "confidence": 0.8919615745544434}]}, {"text": "From the fourteenth and fifteenth rows of the table, the two DNN based ensemble classifiers obtained the similar accuracies when using the same feature combination.", "labels": [], "entities": []}, {"text": "It was noted from the experiments that the multi-column deep-stacking DNN based ensemble classifier worked better than the vanilla DNN based ensemble classifier when the features were heterogeneous and the performance differences were significant.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance comparison of each unit form of", "labels": [], "entities": []}, {"text": " Table 2: Performance comparison of the proposed method", "labels": [], "entities": []}, {"text": " Table 3: Performance comparison of the proposed method", "labels": [], "entities": []}, {"text": " Table 4: Performance comparison of the proposed method", "labels": [], "entities": []}, {"text": " Table 5: Performance comparison based on the F1 and ac-", "labels": [], "entities": [{"text": "F1", "start_pos": 46, "end_pos": 48, "type": "METRIC", "confidence": 0.7726824283599854}]}]}