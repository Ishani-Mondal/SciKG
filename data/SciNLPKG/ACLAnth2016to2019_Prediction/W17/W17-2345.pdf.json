{"title": [{"text": "Clinical Event Detection with Hybrid Neural Architecture", "labels": [], "entities": [{"text": "Clinical Event Detection", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6093112230300903}]}], "abstractContent": [{"text": "Event detection from clinical notes has been traditionally solved with rule based and statistical natural language processing (NLP) approaches that require extensive domain knowledge and feature engineering.", "labels": [], "entities": [{"text": "Event detection from clinical notes", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.885806655883789}]}, {"text": "In this paper, we have explored the feasibility of approaching this task with recurrent neural networks, clinical word embeddings and introduced a hybrid architecture to improve detection for entities with smaller representation in the dataset.", "labels": [], "entities": []}, {"text": "A comparative analysis is also done which reveals the complementary behavior of neural networks and conditional random fields in clinical entity detection.", "labels": [], "entities": [{"text": "clinical entity detection", "start_pos": 129, "end_pos": 154, "type": "TASK", "confidence": 0.6049791475137075}]}], "introductionContent": [{"text": "Event detection from clinical notes is a well studied problem in biomedical informatics; yet, it is constantly evolving through research.", "labels": [], "entities": [{"text": "Event detection from clinical notes", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8883731007575989}]}, {"text": "Much of this research has been promoted by the i2b2 challenges and their publicly available datasets comprised of annotated discharge summaries.", "labels": [], "entities": []}, {"text": "For the 2010 task, the notes were annotated for three types of events -Problem, Test and Treatment, which are predominantly noun phrases.", "labels": [], "entities": []}, {"text": "(Uzuner et al., 2011) The task was made even more challenging in 2012 with the addition of three new entity classes -Occurrence, Evidential and Clinical Department.", "labels": [], "entities": []}, {"text": "Occurrence and Evidential concepts are mostly verb phrases, with some examples being 'readmitted', 'diagnosed', 'seen in consultation', 'revealed' etc.", "labels": [], "entities": []}, {"text": "Rule based and statistical NLP approaches such as Conditional Random Fields have been used at identifying these entities.", "labels": [], "entities": []}, {"text": "These approaches require extensive domain knowledge and feature engineering.", "labels": [], "entities": []}, {"text": "( In this paper, we explore discretized word embeddings as new features in structured inference and also implement a neural network architecture for clinical entity recognition.", "labels": [], "entities": [{"text": "clinical entity recognition", "start_pos": 149, "end_pos": 176, "type": "TASK", "confidence": 0.5867010851701101}]}, {"text": "We defined a CRF baseline to compare the performance of our neural networks and performed a detailed error analysis.", "labels": [], "entities": []}], "datasetContent": [{"text": "The 2012 i2b2 corpus is made of 310 discharge summaries consisting of 178, 000 tokens annotated with clinical events, temporal expressions and temporal relations.", "labels": [], "entities": [{"text": "2012 i2b2 corpus", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.800868570804596}]}, {"text": "The entire corpus is divided into training and test sets, containing 190 and 120 documents respectively.", "labels": [], "entities": []}, {"text": "Each discharge summary has sections for clinical history and hospital course.", "labels": [], "entities": []}, {"text": "Annotation of clinical events includes problems, tests, treatments, clinical departments, occurrences (admission, discharge) and evidences of information (patient denies, tests revealed).", "labels": [], "entities": [{"text": "Annotation of clinical events", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8688504099845886}]}, {"text": "The inter-annotator agreement for event spans is 0.83 for exact match and 0.87 for partial match.", "labels": [], "entities": []}, {"text": "Clinical Department and Evidential concepts are under-represented in training set with less than 1000 examples each.", "labels": [], "entities": []}, {"text": "We report the micro-averaged precision, recall and F1-score, for 'overlap' match of event spans as per the i2b2 evaluation script.", "labels": [], "entities": [{"text": "precision", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.9417927265167236}, {"text": "recall", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.999455988407135}, {"text": "F1-score", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9989357590675354}]}, {"text": "TP, FP, FN counts of overall performance are calculated for entity spans, irrespective of entity tag.", "labels": [], "entities": [{"text": "TP", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.9601427912712097}, {"text": "FP", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.9863504767417908}, {"text": "FN counts", "start_pos": 8, "end_pos": 17, "type": "METRIC", "confidence": 0.9645387828350067}]}, {"text": "Systems are also evaluated for performance in individual entity classes and TP, FP, FN counts are compared between the CRF and RNN+Embedding systems.", "labels": [], "entities": [{"text": "FP", "start_pos": 80, "end_pos": 82, "type": "METRIC", "confidence": 0.9815805554389954}, {"text": "FN counts", "start_pos": 84, "end_pos": 93, "type": "METRIC", "confidence": 0.9505586326122284}]}, {"text": "We perform five-fold cross validation for various configurations of the baseline and RNN systems on the training set.", "labels": [], "entities": []}, {"text": "The results are presented in.", "labels": [], "entities": []}, {"text": "The best performing CRF system i.e. Baseline + Brown Clusters, achieves F1-score of 89.88.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9997366070747375}]}, {"text": "Except for brown clusters, additional features derived from distributional semantics, such as binarized word embeddings (BinEmb), prototype embeddings (ProtoEmb) contribute marginally to performance of the system.", "labels": [], "entities": []}, {"text": "Pre-trained clinical embeddings improve F1 score by 11.93%, over random initialization of RNNs.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9199219644069672}]}, {"text": "In terms of recall, the RNN initialized with MIMIC embeddings is found to perform remarkably well without handengineered features.", "labels": [], "entities": [{"text": "recall", "start_pos": 12, "end_pos": 18, "type": "METRIC", "confidence": 0.9990290403366089}]}, {"text": "However, it fails to beat the CRF system at F1-score.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9949067234992981}]}, {"text": "Comparative analysis of individual entity classes reveals that the RNN improves recall for evidential and clinical department phrases by 5.44% and 8.32% respectively.", "labels": [], "entities": [{"text": "recall", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.9992812275886536}]}, {"text": "It registers some drop in precision, but improves F1-score by up to 3%.", "labels": [], "entities": [{"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9997283816337585}, {"text": "F1-score", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9998024106025696}]}, {"text": "Clearly, RNNs are better suited for detecting occurrence, evidential and clinical department phrases from clinical text.", "labels": [], "entities": [{"text": "detecting occurrence, evidential and clinical department phrases from clinical text", "start_pos": 36, "end_pos": 119, "type": "TASK", "confidence": 0.7042552015998147}]}, {"text": "Based on these results on the training set, we build the hybrid sequence tagger where the best performing CRF system is combined with RNN.", "labels": [], "entities": []}, {"text": "The former is trained to tag problem, test and treatment and the latter is trained to tag rest of the three entity classes.", "labels": [], "entities": []}, {"text": "The results are merged in a combination module and overlapping predictions are resolved by prioritizing the first three classes.", "labels": [], "entities": []}, {"text": "We evaluate its performance on the i2b2 2012 test set.", "labels": [], "entities": [{"text": "i2b2 2012 test set", "start_pos": 35, "end_pos": 53, "type": "DATASET", "confidence": 0.872760221362114}]}, {"text": "Results are listed in and 4.", "labels": [], "entities": []}, {"text": "The hybrid model improves recall by 2.36% and F1-score by 0.56% over the best-performing CRF system.", "labels": [], "entities": [{"text": "recall", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.9998384714126587}, {"text": "F1-score", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9997784495353699}]}, {"text": "Dramatic improvement in recall (as high as 14%) is noted for some entities, but a similar drop in precision is observed.", "labels": [], "entities": [{"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9996541738510132}, {"text": "precision", "start_pos": 98, "end_pos": 107, "type": "METRIC", "confidence": 0.9995176792144775}]}], "tableCaptions": [{"text": " Table 1: 5-fold cross validation performance of various systems on 2012 i2b2 training set", "labels": [], "entities": [{"text": "2012 i2b2 training set", "start_pos": 68, "end_pos": 90, "type": "DATASET", "confidence": 0.8502087742090225}]}, {"text": " Table 2: Entity-level performance of best performing CRF system and RNN on 2012 i2b2 training set", "labels": [], "entities": [{"text": "Entity-level", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.9312583208084106}, {"text": "2012 i2b2 training set", "start_pos": 76, "end_pos": 98, "type": "DATASET", "confidence": 0.8261664062738419}]}, {"text": " Table 3: Performance of best performing CRF and Hybrid CRF-RNN on 2012 i2b2 test set", "labels": [], "entities": [{"text": "2012 i2b2 test set", "start_pos": 67, "end_pos": 85, "type": "DATASET", "confidence": 0.8976971209049225}]}, {"text": " Table 4: Entity-level performance of best performing CRF and Hybrid CRF-RNN on 2012 i2b2 test set", "labels": [], "entities": [{"text": "Entity-level", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.9714019894599915}, {"text": "2012 i2b2 test set", "start_pos": 80, "end_pos": 98, "type": "DATASET", "confidence": 0.8714578002691269}]}]}