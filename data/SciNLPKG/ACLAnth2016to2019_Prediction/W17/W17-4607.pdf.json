{"title": [{"text": "Spoken Term Discovery for Language Documentation using Translations", "labels": [], "entities": [{"text": "Spoken Term Discovery", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9165369073549906}, {"text": "Translations", "start_pos": 55, "end_pos": 67, "type": "TASK", "confidence": 0.577412486076355}]}], "abstractContent": [{"text": "Vast amounts of speech data collected for language documentation and research remain untranscribed and unsearchable, but often a small amount of speech may have text translations available.", "labels": [], "entities": [{"text": "language documentation", "start_pos": 42, "end_pos": 64, "type": "TASK", "confidence": 0.6982070803642273}]}, {"text": "We present a method for partially labeling additional speech with translations in this scenario.", "labels": [], "entities": []}, {"text": "We modify an unsupervised speech-to-translation alignment model and obtain prototype speech segments that match the translation words, which are in turn used to discover terms in the unlabelled data.", "labels": [], "entities": []}, {"text": "We evaluate our method on a Spanish-English speech translation corpus and on two corpora of endangered languages, Arapaho and Ainu, demonstrating its ap-propriateness and applicability in an actual very-low-resource scenario.", "labels": [], "entities": [{"text": "Spanish-English speech translation", "start_pos": 28, "end_pos": 62, "type": "TASK", "confidence": 0.6125824550787607}, {"text": "ap-propriateness", "start_pos": 150, "end_pos": 166, "type": "METRIC", "confidence": 0.9858888983726501}]}], "introductionContent": [{"text": "Language documentation efforts over the last 50-60 years have resulted in audio recordings of native speakers in a large number of languages, many of which are available online.", "labels": [], "entities": [{"text": "Language documentation", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6620236784219742}]}, {"text": "However, due to the enormous effort required for transcription, much of the data remains unannotated and unsearchable.", "labels": [], "entities": []}, {"text": "For example, out of the 137 unrestricted collections in the Archive of the Indigenous Languages of Latin America, about half (49%) contain no transcriptions at all, and only 7% are fully transcribed.", "labels": [], "entities": []}, {"text": "As a result, some recent documentation efforts have begun to focus instead on annotating with translations, often with the help of bilingual * Equal contribution.", "labels": [], "entities": []}, {"text": "By some estimates, a trained linguist requires up to one hour for to phonetically transcribe one minute of speech).", "labels": [], "entities": []}, {"text": "http://ailla.utexas.org native speakers themselves (.", "labels": [], "entities": []}, {"text": "Nevertheless, even translation takes time and language knowledge, so there may still belittle translated data relative to the amount of recorded audio.", "labels": [], "entities": [{"text": "translation", "start_pos": 19, "end_pos": 30, "type": "TASK", "confidence": 0.9698010087013245}]}, {"text": "An important goal, then, is to bootstrap language technology from this small parallel corpus in order to provide tools to annotate more data or make the data more searchable.", "labels": [], "entities": []}, {"text": "We build on the approach of , who developed a system that performs joint inference to identify recurring segments of audio and cluster them while aligning them to words in a text translation.", "labels": [], "entities": []}, {"text": "Here, we extend the method to be able to search for new instances of the latent clusters within the unlabeled audio, effectively providing keyword translations for some of the unlabeled speech.", "labels": [], "entities": []}, {"text": "We evaluate our method on a Spanish-English corpus used in previous work, and on two datasets from endangered languages (narratives in Arapaho and Ainu).", "labels": [], "entities": []}, {"text": "No previous computational methods have been tested on the latter data, to our knowledge.", "labels": [], "entities": []}, {"text": "We show that in all cases, our system outperforms a recent baseline targeted at the same very low-resource setting (, also showing robustness to audio quality and preprocessing decisions.", "labels": [], "entities": []}], "datasetContent": [{"text": "The CALLHOME Spanish Speech dataset (LDC2014T23) with English translations) has been used in almost all groundlaying previous work, treating Spanish as a low-resource language.", "labels": [], "entities": [{"text": "CALLHOME Spanish Speech dataset (LDC2014T23", "start_pos": 4, "end_pos": 47, "type": "DATASET", "confidence": 0.7409988244374593}]}, {"text": "As a collection of telephone conversations between relatives (about 20 total hours of audio), it doesn't match our language documentation scenario, but we use it in order to compare our method with previous work.", "labels": [], "entities": []}, {"text": "We shuffle the utterances and split them into training, dev, and test sets with 70%, 10%, and 20% of the data, respectively.", "labels": [], "entities": []}, {"text": "We filter the active audio regions using energy-based voice activity detection (VAD).", "labels": [], "entities": [{"text": "energy-based voice activity detection (VAD)", "start_pos": 41, "end_pos": 84, "type": "TASK", "confidence": 0.6837322115898132}]}, {"text": "We obtain prototypes in the training set and tune the values of the length threshold t, the similarity threshold d, and the partial overlap threshold k on the development set using grid search.", "labels": [], "entities": [{"text": "similarity threshold d", "start_pos": 92, "end_pos": 114, "type": "METRIC", "confidence": 0.9354635079701742}, {"text": "partial overlap threshold k", "start_pos": 124, "end_pos": 151, "type": "METRIC", "confidence": 0.7393071055412292}]}, {"text": "The best parameter combination is t = 300 ms, d = 90%, and k = 80%, while s = 0.90 returns the highest F-score.", "labels": [], "entities": [{"text": "F-score", "start_pos": 103, "end_pos": 110, "type": "METRIC", "confidence": 0.9974272847175598}]}, {"text": "We evaluate our discovered translation terms on the test set using precision, recall, and F-score at the token level over the correct bag-of-words translations.", "labels": [], "entities": [{"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9996352195739746}, {"text": "recall", "start_pos": 78, "end_pos": 84, "type": "METRIC", "confidence": 0.9986169338226318}, {"text": "F-score", "start_pos": 90, "end_pos": 97, "type": "METRIC", "confidence": 0.9994221925735474}]}, {"text": "We also evaluate our method on two lowresource endangered languages, Arapaho and Ainu.", "labels": [], "entities": []}, {"text": "For these experiments, we only have a training and test set, so we use the same preprocessing and hyperparameter settings as in CALLHOME.", "labels": [], "entities": []}, {"text": "Arapaho is an Algonquian language with about 1,000 native speakers, mostly in Wyoming.", "labels": [], "entities": []}, {"text": "We use 8 narratives published at The Arapaho Language Project,: Results of our method and baseline work on the CALLHOME dataset.", "labels": [], "entities": [{"text": "The Arapaho Language Project", "start_pos": 33, "end_pos": 61, "type": "DATASET", "confidence": 0.7661794424057007}, {"text": "CALLHOME dataset", "start_pos": 111, "end_pos": 127, "type": "DATASET", "confidence": 0.8508769869804382}]}, {"text": "Our method improves over UTD-align whether inferring alignments or using oracle (silver) alignments.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results of our method and baseline work  on the CALLHOME dataset. Our method im- proves over UTD-align whether inferring align- ments or using oracle (silver) alignments.", "labels": [], "entities": [{"text": "CALLHOME dataset", "start_pos": 58, "end_pos": 74, "type": "DATASET", "confidence": 0.8615800142288208}]}, {"text": " Table 1. The  precision-recall curve obtained by varying the out- put similarity threshold s is shown in", "labels": [], "entities": [{"text": "precision-recall", "start_pos": 15, "end_pos": 31, "type": "METRIC", "confidence": 0.9983744621276855}]}, {"text": " Table 2: Results on Arapaho narratives. In general,  we identify meaningful translation terms.", "labels": [], "entities": []}, {"text": " Table 3: Results on the Ainu narratives. We are  able to correctly identify several terms per story,  with quite high precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 119, "end_pos": 128, "type": "METRIC", "confidence": 0.9979941844940186}]}]}