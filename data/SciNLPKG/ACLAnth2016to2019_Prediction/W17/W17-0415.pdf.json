{"title": [], "abstractContent": [{"text": "Universal Dependencies incur a high cost in computation for unbiased system development.", "labels": [], "entities": []}, {"text": "We propose a 100% empirically chosen small subset of UD languages for efficient parsing system development.", "labels": [], "entities": [{"text": "parsing system development", "start_pos": 80, "end_pos": 106, "type": "TASK", "confidence": 0.9226682186126709}]}, {"text": "The technique used is based on measurements of model capacity globally.", "labels": [], "entities": []}, {"text": "We show that the diversity of the resulting representative language set is superior to the requirements-based procedure.", "labels": [], "entities": []}], "introductionContent": [{"text": "The development of natural language parsing systems has historically relied mainly on the central benchmarking dataset the Penn Treebank, as well as, to a lesser extent, a restrictive selection of very well-resourced languages like German and Chinese.", "labels": [], "entities": [{"text": "natural language parsing", "start_pos": 19, "end_pos": 43, "type": "TASK", "confidence": 0.6699088017145792}, {"text": "Penn Treebank", "start_pos": 123, "end_pos": 136, "type": "DATASET", "confidence": 0.9587534964084625}]}, {"text": "This is problematic in that (1) the development of the technology risks being highly biased towards English and other resource-rich languages and their particular annotations for syntax, (2) the technology is inadequately benchmarked against a central group of languages that do not reflect the linguistic diversity required to adequately evaluate parsing systems with respect to language in general, and (3) the development of linguistic resources for unrepresented or poorly represented languages continues to be erroneously regarded as independent of the development of parsing systems, rather than integral to it.", "labels": [], "entities": []}, {"text": "The Universal Dependencies (UD) project ( , has made great strides towards remedying this situation, by providing a single unified syntactic framework and related support for treebank development.", "labels": [], "entities": []}, {"text": "The Universal Dependencies 1.4 resource now comprises 64 different treebanks covering 47 different languages (, and these numbers continue rising (v2.0 is set to add three languages and six treebanks).", "labels": [], "entities": []}, {"text": "Parsing scores are now expected to be reported overall (modern) languages if not all treebanks as macroaverages of scores.", "labels": [], "entities": []}, {"text": "With this added diversity in treebanks and languages, and with a growing trend towards more computationally intensive learning algorithms that promise greater accuracy (such as neural networks), feasible parser development should be a rising concern.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 159, "end_pos": 167, "type": "METRIC", "confidence": 0.9908532500267029}, {"text": "parser development", "start_pos": 204, "end_pos": 222, "type": "TASK", "confidence": 0.8779638409614563}]}, {"text": "The availability of computational resources to develop-that is, to train across all interesting parameter/hyper-parameter settings-neural network models for 64 treebanks within a reasonable amount of time will counteract progress and shutout researchers without adequate computational resources.", "labels": [], "entities": []}, {"text": "Moreover, there are environmental concerns for the inefficient use of power in the language-exhaustive development of these resources.", "labels": [], "entities": []}, {"text": "In this paper, we provide an entirely empirically motivated sub-sample of nine languages that cancan be used to develop monolingual parsing resources.", "labels": [], "entities": []}, {"text": "The method uses delexicalised parser performance as a measure of similarity to construct a language similarity network.", "labels": [], "entities": []}, {"text": "The network is naturally partitioned into language groups using a standard network clustering algorithm, which does not take the number of clusters as a parameter.", "labels": [], "entities": []}, {"text": "The clusters are assumed to be diverse between them but coherent within them, with respect to their individual parser models.", "labels": [], "entities": []}, {"text": "Using this technique, the mean and standard deviation of monolingual unlabeled accuracy scores for cluster representatives are found to be close to the true average and standard deviation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.8537917137145996}]}, {"text": "Future monolingual parsing systems can extrapolate parser performance over the entire set of languages, using only the set of nine representative languages listed in, which interestingly excludes English, Chinese, German, and Czech.", "labels": [], "entities": []}, {"text": "Efficient parser development for UD languages.", "labels": [], "entities": []}, {"text": "As an efficient alternative to exhaustive parameter search across 47 languages (or 64 treebanks), the method we propose for the development of parsing resources is the following: 1.", "labels": [], "entities": [{"text": "parsing", "start_pos": 143, "end_pos": 150, "type": "TASK", "confidence": 0.9025080800056458}]}, {"text": "Development: develop parsing resources over only the nine languages in, optimising for average and standard deviation of unlabeled attachment across all languages.", "labels": [], "entities": []}, {"text": "2. Full testing: using the parameters discovered in step (1), report final average parsing scores and standard deviation overall UD languages.", "labels": [], "entities": []}, {"text": "In Section 3 we will outline the network analytic method for determining these nine representative languages empirically.", "labels": [], "entities": []}, {"text": "First we discuss the only preceding approach to sampling UD languages for parser development; the approach is essentially non-empirical.", "labels": [], "entities": [{"text": "parser development", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.9110732972621918}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Language clusters, flow (centrality) and rankings, given temperature \u03c4 = 0.025. The most  central languages for clusters are highlighted in blue. Red rows are the languages chosen by de Lhoneux  and Nivre (2016). And the one purple language, Hebrew, was chosen by both methods.", "labels": [], "entities": []}, {"text": " Table 3: UAS contributions and aggregates of  our representative UD languages. The contri- butions (cluster size) * score are collected  over the 9 sampled languages and normalised over  the 47 languages.", "labels": [], "entities": [{"text": "contri- butions (cluster size) * score", "start_pos": 84, "end_pos": 122, "type": "METRIC", "confidence": 0.7947520911693573}]}, {"text": " Table 4: UAS and aggregates of de Lhoneux and  Nivre's (2016) representative UD languages. The  score aggregates are calculated over the 8 sampled  languages.", "labels": [], "entities": []}]}