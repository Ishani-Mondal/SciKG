{"title": [{"text": "Hungarian copula constructions in dependency syntax and parsing", "labels": [], "entities": [{"text": "Hungarian copula constructions", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.5400727490584055}, {"text": "parsing", "start_pos": 56, "end_pos": 63, "type": "TASK", "confidence": 0.7931386828422546}]}], "abstractContent": [{"text": "Copula constructions are problematic in the syntax of most languages.", "labels": [], "entities": []}, {"text": "The paper describes three different dependency syntactic methods for handling copula constructions: function head, content head and complex label analysis.", "labels": [], "entities": [{"text": "complex label analysis", "start_pos": 132, "end_pos": 154, "type": "TASK", "confidence": 0.6451067527135214}]}, {"text": "Furthermore, we also propose a POS-based approach to copula detection.", "labels": [], "entities": [{"text": "copula detection", "start_pos": 53, "end_pos": 69, "type": "TASK", "confidence": 0.8053665161132812}]}, {"text": "We evaluate the impact of these approaches in computational parsing , in two parsing experiments for Hun-garian.", "labels": [], "entities": [{"text": "computational parsing", "start_pos": 46, "end_pos": 67, "type": "TASK", "confidence": 0.7105343341827393}]}], "introductionContent": [{"text": "Copula constructions show some special behaviour inmost human languages.", "labels": [], "entities": []}, {"text": "These constructions are widely studied: many approaches are available in many different syntactic frameworks, like in Den, Partee (1998) and\u00c9and\u00b4and\u00c9.", "labels": [], "entities": [{"text": "Den, Partee (1998)", "start_pos": 118, "end_pos": 136, "type": "DATASET", "confidence": 0.70925372838974}]}, {"text": "in constituency grammar; or and in LFG.", "labels": [], "entities": [{"text": "constituency grammar", "start_pos": 3, "end_pos": 23, "type": "TASK", "confidence": 0.8851517736911774}]}, {"text": "In this paper, we focus on dependency syntactic approaches.", "labels": [], "entities": [{"text": "dependency syntactic", "start_pos": 27, "end_pos": 47, "type": "TASK", "confidence": 0.846555769443512}]}, {"text": "In dependency syntax, the syntactic structure's nodes are the words themselves and the tree is made up of their hierarchical relations, making both two-word predicates and the missing verbal forms cause difficulties.", "labels": [], "entities": []}, {"text": "Should the copula, the verbal part of the predicate, be the head of the structure, parallel to most other types of constructions?", "labels": [], "entities": []}, {"text": "And if so, how can we deal with cases where the copula is not present in the surface structure?", "labels": [], "entities": []}, {"text": "In this paper, three different answers to these questions are discussed: the function head analysis, where function words, such as the copula, remain the heads of the structures; the content head analysis, where the content words, in this case, the nominal part of the predicate, are the heads; and the complex label analysis, where the copula remains the head also, but the approach offers a different solution to zero copulas.", "labels": [], "entities": []}, {"text": "First, we give a short description of Hungarian copula constructions.", "labels": [], "entities": [{"text": "Hungarian copula constructions", "start_pos": 38, "end_pos": 68, "type": "TASK", "confidence": 0.5762830277283987}]}, {"text": "Second, the three dependency syntactic frameworks are discussed in more detail.", "labels": [], "entities": []}, {"text": "Then, we describe two experiments aiming to evaluate these frameworks in computational linguistics, specifically in dependency parsing for Hungarian, similar to.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 116, "end_pos": 134, "type": "TASK", "confidence": 0.7638003826141357}]}, {"text": "The first experiment compares the three previously mentioned frameworks, while the second introduces our new approach, based on differentiating the copula and existential \"be\" verbs on the level of POS-tagging, which can improve the performance of the content head analysis.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated the three approaches in two parsing experiments.", "labels": [], "entities": []}, {"text": "We used the same corpus with three different dependency annotations and the Bohnet parser (Bohnet, 2010) for both.", "labels": [], "entities": [{"text": "Bohnet parser (Bohnet, 2010)", "start_pos": 76, "end_pos": 104, "type": "DATASET", "confidence": 0.8521801659039089}]}, {"text": "In the first experiment, the Bohnet parser was trained using the tenfold cross validation method on the same corpora of texts for the function head, the content head and the complex label representation separately, using gold POS tags and morphological features.", "labels": [], "entities": []}, {"text": "In the evaluation of each model, we used UAS and LAS scores for the whole corpus as well as error analysis for the structures in question.", "labels": [], "entities": [{"text": "UAS", "start_pos": 41, "end_pos": 44, "type": "METRIC", "confidence": 0.8612715005874634}, {"text": "LAS", "start_pos": 49, "end_pos": 52, "type": "METRIC", "confidence": 0.9898309111595154}, {"text": "error analysis", "start_pos": 92, "end_pos": 106, "type": "METRIC", "confidence": 0.9505392611026764}]}, {"text": "shows the UAS and LAS scores for each approach.", "labels": [], "entities": [{"text": "UAS", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.7059299349784851}, {"text": "LAS", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.9826281666755676}]}, {"text": "We were interested in the parsing performances regarding different types of van sentences, so we created filtered subcorpora that contain only the sentences with existential van, only with overt copula and only with zero copula.", "labels": [], "entities": []}, {"text": "We report results calculated for these datasets too.: Syntactic structures for existential, overt and zero copula sentences in function head, content head and complex label approaches.", "labels": [], "entities": []}, {"text": "Note how all three trees for the existential sentence are the same, but the copular ones show differences in the analysis.", "labels": [], "entities": []}, {"text": "Based on these UAS and LAS scores, the function head analysis gives the best results with the complex label analysis as a close second, but we were interested in the specific relations of van and not the full sentences' parsing output.", "labels": [], "entities": [{"text": "UAS", "start_pos": 15, "end_pos": 18, "type": "DATASET", "confidence": 0.6069484949111938}, {"text": "LAS", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.972852349281311}]}, {"text": "We did manual error analysis of the van verb's closest relations to investigate which dependency syntactic theory describes these relations best for computational parsing.", "labels": [], "entities": [{"text": "computational parsing", "start_pos": 149, "end_pos": 170, "type": "TASK", "confidence": 0.6125777959823608}]}, {"text": "We considered the following four errors in our analysis: incorrect head in the clause with van; incorrectly labeled or attached subject of van; incorrectly labeled or attached nominal predicate; subject and nominal predicate mixed up.", "labels": [], "entities": []}, {"text": "Sentences showing none of the above errors were considered correct in the results shown below, regardless of other errors in the sentence.", "labels": [], "entities": []}, {"text": "shows the percentage of correct sentences for each analysis in the three above mentioned subcorpora and the overall results in the bottom row.", "labels": [], "entities": []}, {"text": "In the second experiment, we investigated away to improve the content head analysis with a POSbased approach.", "labels": [], "entities": [{"text": "content head analysis", "start_pos": 62, "end_pos": 83, "type": "TASK", "confidence": 0.5559552609920502}]}, {"text": "Our hypothesis is that the existential van and the overt copula van are better disambiguated on the level of POS tagging: as the copular van has a syntactic structure (in the content head analysis), which is very different from the one of all other verbs, not treating it as a normal verb makes sense from a syntactic parsing point of view.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 109, "end_pos": 120, "type": "TASK", "confidence": 0.7523584365844727}]}, {"text": "For this reason, the level of POS tagging is a better fit to disambiguate existential and copular van than the actual parsing.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 30, "end_pos": 41, "type": "TASK", "confidence": 0.8016954660415649}]}, {"text": "We used the previously introduced Hungarian Universal Dependencies treebank with the content head annotation and created anew, POS-based copula version, where the copula van has anew POS tag, COP distinguishing it from all other verbs including the existential van, as shown in examples (5) and (6).", "labels": [], "entities": [{"text": "Hungarian Universal Dependencies treebank", "start_pos": 34, "end_pos": 75, "type": "DATASET", "confidence": 0.906590461730957}, {"text": "COP", "start_pos": 192, "end_pos": 195, "type": "METRIC", "confidence": 0.9602248668670654}]}, {"text": "In the experiment, we applied the Bohnet parser this time for POS tagger, morphology tagger, and dependency parser training and evaluation, using tenfold cross validation on the original content head treebank and the new version with the COP POS tag.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 62, "end_pos": 72, "type": "TASK", "confidence": 0.7901697158813477}, {"text": "morphology tagger", "start_pos": 74, "end_pos": 91, "type": "TASK", "confidence": 0.7212293297052383}, {"text": "dependency parser training", "start_pos": 97, "end_pos": 123, "type": "TASK", "confidence": 0.8139262994130453}, {"text": "COP POS tag", "start_pos": 238, "end_pos": 249, "type": "DATASET", "confidence": 0.7789120475451151}]}, {"text": "gives the UAS and LAS results for the two analyses on a subcorpus with only the sentences with existential, overt or zero van and on the full corpus.", "labels": [], "entities": [{"text": "UAS", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.7421346306800842}, {"text": "LAS", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.9966287016868591}]}, {"text": "The results in show very little change on the full corpus and marginally better results on the van sentences for the POS-based approach.", "labels": [], "entities": []}, {"text": "Again, we focus on manual error analysis of the affected structures.", "labels": [], "entities": []}, {"text": "In the new POS-based content head approach, the new COP POS tag for the copula van is assigned with 0.699 F-score over the whole corpus and the COP POS tag triggers the dependency parser to assign the content head copula structure as expected.", "labels": [], "entities": [{"text": "F-score", "start_pos": 106, "end_pos": 113, "type": "METRIC", "confidence": 0.9953450560569763}]}, {"text": "To evaluate the approach, we created a subcorpus of the sentences with existential and overt vans, as those are the ones we aim to better disambiguate.", "labels": [], "entities": []}, {"text": "On these sentences, we evaluated the accuracy of dependency label prediction of van.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.999614953994751}, {"text": "dependency label prediction", "start_pos": 49, "end_pos": 76, "type": "TASK", "confidence": 0.5626209576924642}]}, {"text": "In both versions in the gold analysis the overt copula van has the dependency label cop, while the existential van has the appropriate verbal dependency label.", "labels": [], "entities": []}, {"text": "In our results, for the original content head analysis, the correct label is assigned with 58.14% accuracy, while our POS tag based content head approach assigns the correct label with 60.35% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9985888600349426}, {"text": "accuracy", "start_pos": 192, "end_pos": 200, "type": "METRIC", "confidence": 0.994327962398529}]}, {"text": "Although this not a statistically significant improvement, we believe that the tendencies reported on this relatively small corpus are of importance for parsing sentences with copulas.", "labels": [], "entities": [{"text": "parsing sentences", "start_pos": 153, "end_pos": 170, "type": "TASK", "confidence": 0.8895487785339355}]}], "tableCaptions": [{"text": " Table 4: UAS and LAS scores with the three analyses on different subcorpora.", "labels": [], "entities": [{"text": "UAS", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.7788467407226562}, {"text": "LAS", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.9876151084899902}]}, {"text": " Table 5: Percentage of correct sentences in the manual error analysis.", "labels": [], "entities": [{"text": "Percentage", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9799448251724243}]}, {"text": " Table 6: UAS and LAS scores for the original and POS-based content head analyses.", "labels": [], "entities": [{"text": "UAS", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.6227508783340454}, {"text": "LAS", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.9710056185722351}]}]}