{"title": [{"text": "When Sparse Traditional Models Outperform Dense Neural Networks: the Curious Case of Discriminating between Similar Languages", "labels": [], "entities": []}], "abstractContent": [{"text": "We present the results of our participation in the VarDial 4 shared task on discriminating closely related languages.", "labels": [], "entities": [{"text": "VarDial 4 shared task", "start_pos": 51, "end_pos": 72, "type": "TASK", "confidence": 0.5365160927176476}]}, {"text": "Our submission includes simple traditional models using linear support vector machines (SVMs) and a neural network (NN).", "labels": [], "entities": []}, {"text": "The main idea was to leverage language group information.", "labels": [], "entities": []}, {"text": "We did so with a two-layer approach in the traditional model and a multi-task objective in the neural network.", "labels": [], "entities": []}, {"text": "Our results confirm earlier findings: simple traditional models outperform neural networks consistently for this task, at least given the amount of systems we could examine in the available time.", "labels": [], "entities": []}, {"text": "Our two-layer linear SVM ranked 2nd in the shared task.", "labels": [], "entities": []}], "introductionContent": [{"text": "The problem of automatic language identification has been a popular task for at least the last 25 years.", "labels": [], "entities": [{"text": "automatic language identification", "start_pos": 15, "end_pos": 48, "type": "TASK", "confidence": 0.6165502766768137}]}, {"text": "From early on, different solutions showed very high results, while the more recent models achieve nearperfect accuracies.", "labels": [], "entities": []}, {"text": "Distinguishing closely-related languages, however, still remains a challenge.", "labels": [], "entities": []}, {"text": "The Discriminating between similar languages (DSL) shared task () is aimed at solving this problem.", "labels": [], "entities": [{"text": "Discriminating between similar languages (DSL) shared task", "start_pos": 4, "end_pos": 62, "type": "TASK", "confidence": 0.7866585387123955}]}, {"text": "For this year's task our team (mm lct) built a model that discriminates between 14 languages or language varieties across 6 language groups (which had two or three languages or language varieties in them).", "labels": [], "entities": []}, {"text": "The most popular of the more recent systems, such as langid.py) and CLD/CLD2 2 produce very good results based on datasets containing fewer than 100 languages, but even a model trained on as many as 131 languages and whatlang) with trained on 184 and 1100 languages, are notable to distinguish closely-related (and therefore very similar) languages and dialects to a satisfying degree, at least not to the extent of the data available.", "labels": [], "entities": []}, {"text": "As part of the DSL 2017 shared task we chose to further explore traditional linear approaches, as well as deep learning methods.", "labels": [], "entities": [{"text": "DSL 2017 shared task", "start_pos": 15, "end_pos": 35, "type": "DATASET", "confidence": 0.8452339023351669}]}, {"text": "In the next Section we shortly discuss previous approaches to the task of discriminating between similar languages.", "labels": [], "entities": []}, {"text": "Then in Section 3 we describe our systems and the data, followed by the results in Section 4, which are discussed in Section 5.", "labels": [], "entities": []}, {"text": "We conclude in Section 6.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: The number of instances and number of tokens for all languages in the training data and the  development data.", "labels": [], "entities": []}, {"text": " Table 2: Accuracies and F 1 -scores (micro, macro and weighted) for the three systems, along with the  random baseline.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9994919300079346}, {"text": "F 1 -scores", "start_pos": 25, "end_pos": 36, "type": "METRIC", "confidence": 0.9902106374502182}]}, {"text": " Table 3: Confusion matrix for the SVM with grouping.", "labels": [], "entities": []}, {"text": " Table 4: Accuracies for all language groups for  the first SVM (with grouping), the second SVM  (without grouping) and the NN.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9975281357765198}]}, {"text": " Table 5: Language-specific performance measures  for the SVM with grouping.", "labels": [], "entities": []}]}