{"title": [], "abstractContent": [], "introductionContent": [{"text": "This paper describes the winning submission to the Cross-lingual Dependency Parsing shared task at VarDial 2017 (.", "labels": [], "entities": [{"text": "Cross-lingual Dependency Parsing shared task at VarDial 2017", "start_pos": 51, "end_pos": 111, "type": "TASK", "confidence": 0.7495843134820461}]}, {"text": "The goal was to devise a labeled dependency parser fora target language with no treebank available, utilizing treebanks of other very close source languages, and plaintext sentence-aligned sourcetarget parallel data.", "labels": [], "entities": []}, {"text": "The task is simulated on target languages for which treebanks do exists, but are not provided to the participants.", "labels": [], "entities": []}, {"text": "As the focus of the task is on parsing per se, a supervised part-of-speech (POS) tagger for each target language is provided.", "labels": [], "entities": []}, {"text": "Moreover, all of the treebanks come from the Universal Dependencies (UD) collection v 1.4 (, which means that their syntactic and morphological annotation -tree topology, dependency relation labels (deprels), universal POS tags (UPOS), and morphological features (morpho feats) -follows the universal cross-lingual UD scheme.", "labels": [], "entities": [{"text": "Universal Dependencies (UD) collection v 1.4", "start_pos": 45, "end_pos": 89, "type": "DATASET", "confidence": 0.6886033415794373}]}, {"text": "Consonantly with the focus of the VarDial workshop on similar languages, the source and target languages are very close to each other, with very similar grammars and a nearly one-to-one correspondence on the level of individual words.", "labels": [], "entities": []}, {"text": "Therefore, we decided to mostly disregard systematic structural heterogeneity between the languages, and focus primarily on lexical differences.", "labels": [], "entities": []}, {"text": "Our method relies on a context-independent word-by-word machine translation (MT) of the source treebank into the target language, based on a one-to-one word alignment provided by a heuristic aligner for similar languages.", "labels": [], "entities": [{"text": "context-independent word-by-word machine translation (MT)", "start_pos": 23, "end_pos": 80, "type": "TASK", "confidence": 0.7132015611444201}]}, {"text": "This switch from a cross-lingual to a pseudo-monolingual setting allows us to easily apply source-trained taggers and parsers to the target data and vice versa.", "labels": [], "entities": []}, {"text": "We also employ several homogenization techniques, mostly to overcome systematic differences in treebank annotations.", "labels": [], "entities": []}, {"text": "Specifically, we normalize the deprels in the source treebanks to better correspond to the target deprels, and we subselect only cross-lingually consistent morpho feats.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Evaluation using LAS. Reaching super- vised is how far we got on the scale between the  baseline and the supervised setup.", "labels": [], "entities": [{"text": "LAS", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.7072478532791138}]}, {"text": " Table 3: Comparison of LAS and UAS scores of  our system and the second-best system.", "labels": [], "entities": [{"text": "LAS", "start_pos": 24, "end_pos": 27, "type": "METRIC", "confidence": 0.9242137670516968}, {"text": "UAS", "start_pos": 32, "end_pos": 35, "type": "METRIC", "confidence": 0.657941460609436}]}, {"text": " Table 4: Ablation analysis: reduction of LAS  score when removing various components.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9938892126083374}, {"text": "LAS  score", "start_pos": 42, "end_pos": 52, "type": "METRIC", "confidence": 0.9507850110530853}]}]}