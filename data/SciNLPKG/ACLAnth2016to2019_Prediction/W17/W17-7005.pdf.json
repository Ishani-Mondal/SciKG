{"title": [{"text": "Fine-grained domain classification of text using TERMIUM Plus", "labels": [], "entities": [{"text": "Fine-grained domain classification of text", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.7360012352466583}, {"text": "TERMIUM", "start_pos": 49, "end_pos": 56, "type": "METRIC", "confidence": 0.7844616174697876}]}], "abstractContent": [{"text": "In this article, we present the use of a term bank for text classification purposes.", "labels": [], "entities": [{"text": "text classification", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.8115409016609192}]}, {"text": "We developed a supervised text classification approach which takes advantage of the domain-based structure of a term bank, namely TERMIUM Plus, as well as its bilingual content.", "labels": [], "entities": [{"text": "text classification", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.7231003940105438}, {"text": "TERMIUM", "start_pos": 130, "end_pos": 137, "type": "METRIC", "confidence": 0.9190562963485718}]}, {"text": "The goal of the text classification task is to correctly identify the appropriate fine-grained domains of short segments of text in both French and English.", "labels": [], "entities": [{"text": "text classification", "start_pos": 16, "end_pos": 35, "type": "TASK", "confidence": 0.797768771648407}]}, {"text": "We developed a vector space model for this task, which we refer to as the DCVSM (domain classification vector space model).", "labels": [], "entities": []}, {"text": "In order to train and evaluate the DCVSM, we generated two new datasets from the open data contained in TERMIUM Plus.", "labels": [], "entities": []}, {"text": "Results on these datasets show that the DCVSM compares favourably to five other supervised classification algorithms tested, achieving the highest micro-averaged recall (R@1).", "labels": [], "entities": [{"text": "recall (R@1)", "start_pos": 162, "end_pos": 174, "type": "METRIC", "confidence": 0.8316327234109243}]}], "introductionContent": [{"text": "Text classification is a well-known task in Natural Language Processing, which aims at automatically providing additional document-level metadata (e.g. domain, genre, author).", "labels": [], "entities": [{"text": "Text classification", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8171207010746002}]}, {"text": "To our knowledge, the curated domain structures found in term banks have never been used to automatically provide metadata describing the fine-grained domains discussed in a given document.", "labels": [], "entities": []}, {"text": "This might perhaps be due to the fact that term banks have not been made available as open and free resources until recently, as well as the lack of text data annotated using a term bank's domains as target classes, which is necessary fora supervised classification approach.", "labels": [], "entities": []}, {"text": "Our research was stimulated by the gap mentioned above, and our contribution, highlighted in this paper, is both to provide annotated datasets for fine-grained domain classification of texts, and a classification method that achieves high accuracy.", "labels": [], "entities": [{"text": "fine-grained domain classification of texts", "start_pos": 147, "end_pos": 190, "type": "TASK", "confidence": 0.7955048441886902}, {"text": "accuracy", "start_pos": 239, "end_pos": 247, "type": "METRIC", "confidence": 0.9953142404556274}]}, {"text": "We should say that our first contribution is only possible because of the recent release of the term bank TERMIUM Plus, which contains both the domain structuring information and the short text segments which we use to build our two datasets, one for French and one for English.", "labels": [], "entities": [{"text": "TERMIUM", "start_pos": 106, "end_pos": 113, "type": "METRIC", "confidence": 0.9450659155845642}]}, {"text": "Our second contribution is a comparison of six different supervised classification algorithms on these datasets, which aims to determine which kind of classifier produces the best results on this task.", "labels": [], "entities": []}, {"text": "Among the models we tested, the one which achieves the highest accuracy is a vector space model we developed for this task, which we refer to as the domain classification vector space model (DCVSM).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9991254210472107}]}, {"text": "The datasets are described in Section 2 and the DCVSM is explained in Section 3.", "labels": [], "entities": [{"text": "DCVSM", "start_pos": 48, "end_pos": 53, "type": "DATASET", "confidence": 0.8375558257102966}]}, {"text": "The experimental setup and results are presented in Sections 4 and 5.", "labels": [], "entities": []}, {"text": "Related work is outlined in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "The datasets we created for this research were extracted from TERMIUM Plus R , which we will call simply Termium from now on.", "labels": [], "entities": [{"text": "TERMIUM Plus R", "start_pos": 62, "end_pos": 76, "type": "METRIC", "confidence": 0.9382351040840149}]}, {"text": "Termium 1 is a multilingual terminology and linguistic data bank, developed by the Translation Bureau of Canada for over thirty years, but only recently released as open data by the Government of Canada., an open version of Termium Plus is available, with periodic updates.", "labels": [], "entities": []}, {"text": "So far, it has not been used much for research on computational linguistics, yet it is a rich resource which can be used for such research in various ways, as we will show.", "labels": [], "entities": [{"text": "computational linguistics", "start_pos": 50, "end_pos": 75, "type": "TASK", "confidence": 0.7094865143299103}]}, {"text": "The latest release of Termium contains data in four languages: English, French, Castilian Spanish, and Portuguese.", "labels": [], "entities": []}, {"text": "The datasets presented in this paper were extracted from a 2016 release of Termium, which only included English and French data.", "labels": [], "entities": [{"text": "Termium", "start_pos": 75, "end_pos": 82, "type": "DATASET", "confidence": 0.7954533696174622}]}, {"text": "The release we used contains about 1.33 million records associated with 2252 domains.", "labels": [], "entities": []}, {"text": "An example of a record is shown in.", "labels": [], "entities": []}, {"text": "Using the TC datasets (in English and French) described in Section 2, we evaluated the DCVSM as well as five other supervised classification algorithms that have been used for text classification.", "labels": [], "entities": [{"text": "TC datasets", "start_pos": 10, "end_pos": 21, "type": "DATASET", "confidence": 0.7423543781042099}, {"text": "DCVSM", "start_pos": 87, "end_pos": 92, "type": "DATASET", "confidence": 0.922221839427948}, {"text": "text classification", "start_pos": 176, "end_pos": 195, "type": "TASK", "confidence": 0.8797636330127716}]}, {"text": "Each short text (instance) from a TC dataset was converted into a bag of words after applying basic preprocessing (tokenization, lemmatization, case-folding, and removal of stop words and punctuation) . Thus, each instance is represented by a feature vector where each value is the frequency of a specific word.", "labels": [], "entities": [{"text": "TC dataset", "start_pos": 34, "end_pos": 44, "type": "DATASET", "confidence": 0.7110207080841064}]}, {"text": "The set of features contains every word that occurs at least twice in the training data.", "labels": [], "entities": []}, {"text": "Word frequencies were optionally weighted using tf-idf, with idf being defined as follows fora given word w: idf(w) = log , where Dis the set of contexts used for training, |D| is its size, and D w is the subset of training contexts that contain w.", "labels": [], "entities": []}, {"text": "The five other supervised classification algorithms we tested are: multinomial Naive Bayes (NB), Rocchio classification (RC), softmax regression (SR), k-nearest neighbours (k-NN) and a multi-layer perceptron (MLP).", "labels": [], "entities": []}, {"text": "As noted above, multinomial Naive Bayes is commonly used for text classification.", "labels": [], "entities": [{"text": "text classification", "start_pos": 61, "end_pos": 80, "type": "TASK", "confidence": 0.842196524143219}]}, {"text": "Rocchio classification, like Naive Bayes, is a linear classification algorithm.", "labels": [], "entities": [{"text": "Rocchio classification", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6147107183933258}]}, {"text": "The DCVSM is similar to Rocchio classification, which involves computing centroids by averaging all the feature vectors belonging to each class, and classifying new instances by assigning them to the class of the nearest centroid.", "labels": [], "entities": []}, {"text": "The DCVSM is different in that the feature vectors belonging to each class are summed rather than being averaged, and then weighted.", "labels": [], "entities": []}, {"text": "Softmax regression (or multinomial logistic regression) is also a linear classification algorithm.", "labels": [], "entities": [{"text": "linear classification", "start_pos": 66, "end_pos": 87, "type": "TASK", "confidence": 0.7202142179012299}]}, {"text": "The softmax classifier was trained using stochastic gradient descent, with a penalty on the L2 norm of the feature weights for regularisation.", "labels": [], "entities": []}, {"text": "The k-NN algorithm and the MLP are non-linear classifiers.", "labels": [], "entities": []}, {"text": "k-NN classifies a given instance based on the classes of the k most similar instances in the training data.", "labels": [], "entities": []}, {"text": "The MLP is also known as a fully connected artificial neural network.", "labels": [], "entities": []}, {"text": "A description of artificial neural networks and the backpropagation algorithm used to train them can be found in, and Bengio (2012) provides a practical guide to training and tuning neural networks.", "labels": [], "entities": []}, {"text": "We tested MLPs containing 1 or 2 hidden layers of exponential linear units ().", "labels": [], "entities": []}, {"text": "The MLP was trained using the Adam algorithm) and regularised using dropout and a max-norm constraint on the incoming weights of all units ().", "labels": [], "entities": [{"text": "MLP", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.508552610874176}]}, {"text": "Each TC dataset was split into 3 subsets of equal size (about 46K instances in English and 41K in French) for training, validation, and testing.", "labels": [], "entities": [{"text": "TC dataset", "start_pos": 5, "end_pos": 15, "type": "DATASET", "confidence": 0.8058006763458252}]}, {"text": "A grid search was used to tune the hyperparameters of each classifier on the validation set (except Naive Bayes, which has no hyperparameters).", "labels": [], "entities": []}, {"text": "Then the best configuration of each classifier was evaluated on the held-out test set.", "labels": [], "entities": []}, {"text": "Each classifier was tuned and tested twice, once using raw word frequencies as input, and once using tf-idf weighted frequencies.", "labels": [], "entities": []}, {"text": "The impact of this weighting will be assessed in the next section.", "labels": [], "entities": []}, {"text": "For the DCVSM, the only hyperparameter is the weighting scheme \u03c8 used to compute the feature weights.", "labels": [], "entities": []}, {"text": "We tested nine different weighting schemes including tf-idf and the simple association measures defined in Evert.", "labels": [], "entities": [{"text": "Evert", "start_pos": 107, "end_pos": 112, "type": "DATASET", "confidence": 0.8306758999824524}]}, {"text": "These association measures compare the observed frequency of (word, context) pairs to their expected frequency in order to measure the strength of their association.", "labels": [], "entities": []}, {"text": "We calculate this expectation using the following equation: where T f i c j , as defined earlier (see Section 3), is the sum, for each feature vector in the training data belonging to class c j , of the value of feature f i . We set all of the association measures to 0 if We optionally apply a log or square root transformation to the output of all the weighting schemes, following.", "labels": [], "entities": []}, {"text": "For Rocchio classification, we tuned the measure used to estimate the distance between a feature vector and the class centroids (euclidean distance or cosine).", "labels": [], "entities": [{"text": "Rocchio classification", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.642508938908577}]}, {"text": "For k-NN, we tuned the number of neighbours (k) and the distance-based weighting of neighbours.", "labels": [], "entities": []}, {"text": "For the softmax classifier, we tuned the learning rate and the L2 penalty coefficient.", "labels": [], "entities": [{"text": "L2 penalty coefficient", "start_pos": 63, "end_pos": 85, "type": "METRIC", "confidence": 0.8678281108538309}]}, {"text": "As for the MLP, we tuned the number of hidden layers (1 or 2), the number of units in each, the learning rate, the number of training iterations (epochs), the dropout probability and the max-norm constraint.", "labels": [], "entities": [{"text": "MLP", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.851417601108551}]}, {"text": "shows the accuracy achieved by each classifier on the test sets in English and French.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9995793700218201}]}, {"text": "Accuracy is measured using two different evaluation measures, namely micro-averaged recall at rank 1 (R@1) and recall at rank 5 (R@5).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9884405136108398}, {"text": "recall", "start_pos": 84, "end_pos": 90, "type": "METRIC", "confidence": 0.8896850347518921}, {"text": "recall", "start_pos": 111, "end_pos": 117, "type": "METRIC", "confidence": 0.9986129999160767}]}, {"text": "R@1 is simply the percentage of correctly classified instances.", "labels": [], "entities": [{"text": "R@1", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9616525371869405}]}, {"text": "This is the measure that was used to tune the models on the validation set.", "labels": [], "entities": []}, {"text": "It only considers the top prediction of a classifier fora given test case, whereas R@5 considers the top five predictions.", "labels": [], "entities": []}, {"text": "In other words, R@5 is the percentage of test cases for which the correct class is among the five most likely classes according to the classifier.", "labels": [], "entities": [{"text": "R@5", "start_pos": 16, "end_pos": 19, "type": "METRIC", "confidence": 0.9780393441518148}]}], "tableCaptions": [{"text": " Table 3: TC Datasets statistics.", "labels": [], "entities": [{"text": "TC Datasets", "start_pos": 10, "end_pos": 21, "type": "DATASET", "confidence": 0.7485798597335815}]}, {"text": " Table 2. Statistics on the  TC datasets are presented in", "labels": [], "entities": [{"text": "TC datasets", "start_pos": 29, "end_pos": 40, "type": "DATASET", "confidence": 0.7707449197769165}]}, {"text": " Table 3. Contexts contain  about 40-45 tokens on average, which makes these texts  much shorter than those typically used to evaluate text  classification, yet longer than a typical query in informa- tion retrieval. The number of classes (1376 in English,  1342 in French) is also higher than that of other text clas- sification datasets, such as Reuters-21578 3 , which con- tains 118 classes. Thus, this task can be considered a  fine-grained domain classification of short texts.", "labels": [], "entities": [{"text": "text  classification", "start_pos": 135, "end_pos": 155, "type": "TASK", "confidence": 0.6861025989055634}]}, {"text": " Table 4: Micro-averaged R@1 and R@5 on the  test sets in English and French.", "labels": [], "entities": [{"text": "Micro-averaged R@1", "start_pos": 10, "end_pos": 28, "type": "METRIC", "confidence": 0.8467248231172562}, {"text": "R@5", "start_pos": 33, "end_pos": 36, "type": "METRIC", "confidence": 0.9441398779551188}]}, {"text": " Table 5: Impact of weighting the feature values us- ing tf-idf.", "labels": [], "entities": []}, {"text": " Table 7: Low-recall classes (right) and the classes with which they are most often confused (left). The  frequency of each class is shown in brackets. This is their frequency in the training set (in English).", "labels": [], "entities": []}]}