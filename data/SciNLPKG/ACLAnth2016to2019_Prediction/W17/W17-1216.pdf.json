{"title": [{"text": "Cross-Lingual Dependency Parsing for Closely Related Languages - Helsinki's Submission to VarDial 2017", "labels": [], "entities": [{"text": "Cross-Lingual Dependency Parsing for Closely Related Languages - Helsinki's Submission to VarDial", "start_pos": 0, "end_pos": 97, "type": "TASK", "confidence": 0.746941667336684}]}], "abstractContent": [{"text": "This paper describes the submission from the University of Helsinki to the shared task on cross-lingual dependency parsing at VarDial 2017.", "labels": [], "entities": [{"text": "cross-lingual dependency parsing at VarDial 2017", "start_pos": 90, "end_pos": 138, "type": "TASK", "confidence": 0.7185466090838114}]}, {"text": "We present work on annotation projection and treebank translation that gave good results for all three target languages in the test set.", "labels": [], "entities": [{"text": "annotation projection", "start_pos": 19, "end_pos": 40, "type": "TASK", "confidence": 0.7185024917125702}, {"text": "treebank translation", "start_pos": 45, "end_pos": 65, "type": "TASK", "confidence": 0.6940256059169769}]}, {"text": "In particular , Slovak seems to work well with information coming from the Czech treebank, which is inline with related work.", "labels": [], "entities": [{"text": "Czech treebank", "start_pos": 75, "end_pos": 89, "type": "DATASET", "confidence": 0.9081098735332489}]}, {"text": "The attachment scores for cross-lingual models even surpass the fully supervised models trained on the target language treebank.", "labels": [], "entities": []}, {"text": "Croatian is the most difficult language in the test set and the improvements over the baseline are rather modest.", "labels": [], "entities": []}, {"text": "Norwegian works best with information coming from Swedish whereas Danish contributes surprisingly little.", "labels": [], "entities": []}], "introductionContent": [{"text": "Cross-lingual parsing is interesting as a cheap method for bootstrapping tools in anew language from resources in another language.", "labels": [], "entities": [{"text": "Cross-lingual parsing", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.6742702722549438}]}, {"text": "Various approaches have been proposed in the literature, which can mainly be divided into data transfer (i.e. annotation projection, e.g. () and model transfer approaches (e.g. delexicalized models such as).", "labels": [], "entities": [{"text": "data transfer", "start_pos": 90, "end_pos": 103, "type": "TASK", "confidence": 0.7390586286783218}, {"text": "annotation projection", "start_pos": 110, "end_pos": 131, "type": "TASK", "confidence": 0.7242144346237183}, {"text": "model transfer", "start_pos": 145, "end_pos": 159, "type": "TASK", "confidence": 0.6898947060108185}]}, {"text": "We will focus on data transfer in this paper using annotation projection and machine translation to transform source language treebanks to be used as training data for dependency parsers in the target language.", "labels": [], "entities": [{"text": "data transfer", "start_pos": 17, "end_pos": 30, "type": "TASK", "confidence": 0.7620244324207306}, {"text": "machine translation", "start_pos": 77, "end_pos": 96, "type": "TASK", "confidence": 0.7192730009555817}]}, {"text": "Our previous work has shown that these techniques are quite robust and show better performance than simple transfer models based on delexicalized parsers (.", "labels": [], "entities": []}, {"text": "This is especially true for real-world test cases in which part-of-speech (PoS) labels are predicted instead of given as gold standard annotation while testing the parsing models.", "labels": [], "entities": []}, {"text": "Cross-lingual parsing assumes strong syntactic similarities between source and target language which can be seen at the degradation of model performance when using distant languages such as.", "labels": [], "entities": []}, {"text": "The task at VarDial, therefore, focuses on closely related languages, which makes more sense also from a practical point of view.", "labels": [], "entities": [{"text": "VarDial", "start_pos": 12, "end_pos": 19, "type": "DATASET", "confidence": 0.8479864001274109}]}, {"text": "Many pools of closely related languages and language variants exist and, typically, the support in terms of resources and tools is very biased towards one of the languages in such a pool.", "labels": [], "entities": []}, {"text": "Hence, one can say that the task at VarDial simulates real-world cases using existing resources from the universal dependencies project and promotes the ideas for practical application development.", "labels": [], "entities": []}, {"text": "The results show that this testis, in fact, not only a simulation but actually improves the results for one of the languages in the test set: Slovak.", "labels": [], "entities": []}, {"text": "Cross-lingual models outperform the supervised upper bound, which is a great result in favor of the transfer learning ideas.", "labels": [], "entities": []}, {"text": "More details about the shared task on crosslingual parsing at VarDial 2017 can be found in (.", "labels": [], "entities": [{"text": "crosslingual parsing", "start_pos": 38, "end_pos": 58, "type": "TASK", "confidence": 0.7949889600276947}, {"text": "VarDial 2017", "start_pos": 62, "end_pos": 74, "type": "DATASET", "confidence": 0.873474657535553}]}, {"text": "In the following, we will first describe our methodology and the data sets that we have used, before jumping to the results and some discussions in relation to our main findings.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. The same table also sum- marizes our basic results for all language pairs us- ing the three approaches for data transfer as in- troduced in the previous section. All projections  are made in collapseDummy mode as explained  above.", "labels": [], "entities": [{"text": "data transfer", "start_pos": 117, "end_pos": 130, "type": "TASK", "confidence": 0.7151011824607849}]}, {"text": " Table 1: Basic results of cross-lingual parsing  models in terms of labeled attachment scores  (LAS) on development data: Annotation pro- jection on automatically parsed bitexts of vary- ing sizes (projected: number of sentence pairs);  treebank translation models (PBSMT and Syn- taxSMT); compared to three baselines: delexical- ized models (delex), source language models with- out adaptation (cross) and fully-supervised target  language models (supervised).", "labels": [], "entities": [{"text": "cross-lingual parsing", "start_pos": 27, "end_pos": 48, "type": "TASK", "confidence": 0.7102952003479004}, {"text": "labeled attachment scores  (LAS)", "start_pos": 69, "end_pos": 101, "type": "METRIC", "confidence": 0.8140926609436671}, {"text": "Annotation pro- jection", "start_pos": 123, "end_pos": 146, "type": "METRIC", "confidence": 0.9253447651863098}]}, {"text": " Table 2: Added PoS and morphological tagging  to projected data sets: LAS scores on develop- ment data. Only morphological tagging added  (morph) or tagging both, PoS and morphology  (PoS+morph).", "labels": [], "entities": [{"text": "LAS", "start_pos": 71, "end_pos": 74, "type": "METRIC", "confidence": 0.8990222215652466}]}, {"text": " Table 3: Final results on the test set (our model)  compared to baselines and fully supervised mod- els. CUNI refers to a competing system -the  winning team of VarDial. For the Norwegian  baselines we report the results for Swedish as the  source language, which is much better than using  Danish.", "labels": [], "entities": [{"text": "VarDial", "start_pos": 162, "end_pos": 169, "type": "DATASET", "confidence": 0.9282074570655823}]}]}