{"title": [{"text": "Building Graph Representations of Deep Vector Embeddings", "labels": [], "entities": []}], "abstractContent": [{"text": "Patterns stored within pre-trained deep neural networks compose large and powerful descriptive languages that can be used for many different purposes.", "labels": [], "entities": []}, {"text": "Typically, deep network representations are implemented within vector embedding spaces, which enables the use of traditional machine learning algorithms on top of them.", "labels": [], "entities": []}, {"text": "In this short paper we propose the construction of a graph embedding space instead, introducing a methodology to transform the knowledge coded within a deep convolu-tional network into a topological space (i.e., a network).", "labels": [], "entities": []}, {"text": "We outline how such graph can hold data instances, data features, relations between instances and features, and relations among features.", "labels": [], "entities": []}, {"text": "Finally , we introduce some preliminary experiments to illustrate how the resultant graph embedding space can be exploited through graph analytics algorithms.", "labels": [], "entities": []}], "introductionContent": [{"text": "Deep learning models build large and rich data representations by finding complex patterns within large and high-dimensional datasets.", "labels": [], "entities": []}, {"text": "At the end of a deep learning training procedure, the learnt model can be understood as a data representation language, where the pattern learnt by each neuron within the deep model represents a word of such language.", "labels": [], "entities": []}, {"text": "Extracting and reusing the patterns learnt by a deep neural network (DNN) is a subfield of deep learning known as transfer learning.", "labels": [], "entities": [{"text": "Extracting and reusing the patterns learnt by a deep neural network (DNN)", "start_pos": 0, "end_pos": 73, "type": "TASK", "confidence": 0.5960972777434758}, {"text": "transfer learning", "start_pos": 114, "end_pos": 131, "type": "TASK", "confidence": 0.9053454101085663}]}, {"text": "Transfer learning from a pre-trained DNN can be used to initialize the training of a second DNN from a non-random state, improving performance over randomly initialized networks, and also enabling the training of DNNs for domains with limited amount of data.", "labels": [], "entities": []}, {"text": "These two settings, where the purpose of the transfer learning process is to train a second DNN, are cases of transfer learning for fine tuning.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 110, "end_pos": 127, "type": "TASK", "confidence": 0.8790534138679504}]}, {"text": "A different purpose of transfer learning is to extract deep representations so that alternative machine learning methods can be run on top of those.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.9671624004840851}]}, {"text": "This is commonly known as transfer learning for feature extraction, and is the main topic of this paper.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.9299560189247131}, {"text": "feature extraction", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.7637626230716705}]}, {"text": "Extracted DNN representations are typically implemented through vectors, where the length of the vector equals to the number of neural features being used.", "labels": [], "entities": []}, {"text": "These vector embedding spaces have been used to feed classifiers based on the instance-attribute paradigm (e.g., Support Vector Machines).", "labels": [], "entities": []}, {"text": "Instead, in this paper we propose a graph based representation of those same embeddings spaces, with the goal of running a different family of algorithms; those based on the instance-instance paradigm, such as community detection algorithms.", "labels": [], "entities": [{"text": "community detection", "start_pos": 210, "end_pos": 229, "type": "TASK", "confidence": 0.7251735776662827}]}, {"text": "Graph or network based algorithms focus on the associations among instances to find topologically coherent patterns.", "labels": [], "entities": []}, {"text": "These are significantly different from the patterns that can be found using algorithms focused on the associations among instances and attributes.", "labels": [], "entities": []}, {"text": "This paper describes a methodology for building a graph representation of neural network embeddings (in \u00a72), and reports the performance of a community detection algorithm processing the resultant graph (in \u00a73).", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate our graph representation of the deep embedding space we use the VGG16 CNN architecture, pre-trained on the ImageNet [17] dataset.", "labels": [], "entities": [{"text": "VGG16 CNN", "start_pos": 76, "end_pos": 85, "type": "DATASET", "confidence": 0.9349561333656311}, {"text": "ImageNet [17] dataset", "start_pos": 119, "end_pos": 140, "type": "DATASET", "confidence": 0.9095296740531922}]}, {"text": "We process four different datasets through this pre-trained model.", "labels": [], "entities": []}, {"text": "Details on the datasets are shown in: \u2022 The MIT Indoor Scene Recognition dataset (mit67) consists of different indoor scenes to be classified in 67 categories.", "labels": [], "entities": [{"text": "MIT Indoor Scene Recognition dataset (mit67)", "start_pos": 44, "end_pos": 88, "type": "DATASET", "confidence": 0.8748818263411522}]}, {"text": "\u2022 The Oxford Flower dataset (flowers102) is a fine-grained dataset consisting of 102 flower categories.", "labels": [], "entities": [{"text": "Oxford Flower dataset (flowers102)", "start_pos": 6, "end_pos": 40, "type": "DATASET", "confidence": 0.9594024221102396}]}, {"text": "\u2022 The Describable Textures Dataset (textures) is a database of textures categorized according to a list of 47 terms inspired from human perception.", "labels": [], "entities": []}, {"text": "\u2022 The Oulu Knots dataset (wood) contains knot images from spruce wood, classified according to Nordic Standards.", "labels": [], "entities": [{"text": "Oulu Knots dataset", "start_pos": 6, "end_pos": 24, "type": "DATASET", "confidence": 0.8590513865152994}]}, {"text": "For each of the images of those datasets we obtain the full-network embedding.", "labels": [], "entities": []}, {"text": "In the case of the VGG16 architecture, the embedding generates vectors of 12,416 features.", "labels": [], "entities": [{"text": "VGG16", "start_pos": 19, "end_pos": 24, "type": "DATASET", "confidence": 0.9243434071540833}]}, {"text": "Based on those, we build the graph representation, as previously described.", "labels": [], "entities": []}, {"text": "We explore the graph-representation by running a community detection algorithm on top of it.", "labels": [], "entities": []}, {"text": "Particularly, we use the Fluid Communities (FluidC) algorithm.", "labels": [], "entities": []}, {"text": "We chose this algorithm because its based on the efficient label propagation methodology while outperforming the traditional LPA algorithm, because it allows us to specify the number of clusters we wish to find, and because it can be easily adapted to the specific needs of our experiments.", "labels": [], "entities": [{"text": "label propagation", "start_pos": 59, "end_pos": 76, "type": "TASK", "confidence": 0.7143377810716629}]}, {"text": "These specific needs regard mostly cluster initialization and maintainance.", "labels": [], "entities": [{"text": "cluster initialization", "start_pos": 35, "end_pos": 57, "type": "TASK", "confidence": 0.7224092185497284}]}, {"text": "Since the graph is composed by both images and features vertices, but only images have an associated label, clusters should be evaluated considering only the image vertices found in a final community.", "labels": [], "entities": []}, {"text": "For this same reason, we must ensure that all communities found contain at least one image  vertex.", "labels": [], "entities": []}, {"text": "This is done by modifying the FluidC algorithm, forcing it to initialize communities on image vertices, and by making sure that a community contains at least one image vertex at all times.", "labels": [], "entities": []}, {"text": "We measure the quality of the found clusters by measuring the similarity between the found communities and the original dataset labels.", "labels": [], "entities": []}, {"text": "We use both the normalized mutual information measure (NMI) and the adjusted mutual information (AMI).", "labels": [], "entities": [{"text": "mutual information measure (NMI)", "start_pos": 27, "end_pos": 59, "type": "METRIC", "confidence": 0.7260626057783762}, {"text": "adjusted mutual information (AMI)", "start_pos": 68, "end_pos": 101, "type": "METRIC", "confidence": 0.8239020903905233}]}, {"text": "The properties of the graph generated for each dataset and the performance results are shown in.", "labels": [], "entities": []}, {"text": "All experiments were done using the VGG16 model pre-trained on ImageNet2012, freely available online.", "labels": [], "entities": [{"text": "VGG16", "start_pos": 36, "end_pos": 41, "type": "DATASET", "confidence": 0.9570993185043335}, {"text": "ImageNet2012", "start_pos": 63, "end_pos": 75, "type": "DATASET", "confidence": 0.8480573296546936}]}, {"text": "The feature extraction process was done with Caffe.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.8171024024486542}]}, {"text": "The execution of the graph algorithm was done using NetworkX v2.0, which includes FluidC.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Properties of all datasets computed", "labels": [], "entities": []}, {"text": " Table 2: Properties of the graphs built from the deep embedding spaces, and quality of the communities  found by the FluidC algorithm measured in NMI and AMI.", "labels": [], "entities": [{"text": "AMI", "start_pos": 155, "end_pos": 158, "type": "DATASET", "confidence": 0.8567373156547546}]}]}