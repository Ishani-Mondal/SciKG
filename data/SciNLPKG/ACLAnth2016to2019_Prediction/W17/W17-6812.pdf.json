{"title": [{"text": "Extracting hypernym relations from Wikipedia disambiguation pages: comparing symbolic and machine learning approaches", "labels": [], "entities": [{"text": "Extracting hypernym relations from Wikipedia disambiguation", "start_pos": 0, "end_pos": 59, "type": "TASK", "confidence": 0.7706332703431448}]}], "abstractContent": [{"text": "Extracting hypernym relations from text is one of the key steps in the construction and enrichment of semantic resources.", "labels": [], "entities": [{"text": "Extracting hypernym relations from text", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.88428635597229}]}, {"text": "Several methods have been exploited in a variety of propositions in the literature.", "labels": [], "entities": []}, {"text": "However, the strengths of each approach on a same corpus are still poorly identified in order to better take advantage of their complementarity.", "labels": [], "entities": []}, {"text": "In this paper, we study how complementary two approaches of different nature are when identifying hypernym relations on a structured corpus containing both well-written text and syntactically poor formulations, together with a rich formatting.", "labels": [], "entities": []}, {"text": "A symbolic approach based on lexico-syntactic patterns and a statistical approach using a supervised learning method are applied to a sub-corpus of Wikipedia in French, composed of disambiguation pages.", "labels": [], "entities": []}, {"text": "These pages, particularly rich in hypernym relations, contain both kinks of formulations.", "labels": [], "entities": []}, {"text": "We compared the results of each approach independently of each other and compared the performance when combining together their individual results.", "labels": [], "entities": []}, {"text": "We obtain the best results in the latter case, with an F-measure of 0.75.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.9986273050308228}]}, {"text": "In addition, 55% of the identified relations, with respect to a reference corpus, are not expressed in the French DBPedia and could be used to enrich this resource.", "labels": [], "entities": [{"text": "French DBPedia", "start_pos": 107, "end_pos": 121, "type": "DATASET", "confidence": 0.9340017139911652}]}], "introductionContent": [{"text": "In many fields such as artificial intelligence, semantic web, software engineering or information retrieval, applications require a strong reasoning ability, based on semantic resources that describe concepts and the relations between them.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 86, "end_pos": 107, "type": "TASK", "confidence": 0.7411745488643646}]}, {"text": "These resources can be manually designed.", "labels": [], "entities": []}, {"text": "They are of good quality, however due to the high cost of their design, they offer a limited domain coverage.", "labels": [], "entities": []}, {"text": "With the increasing amount of textual documents available in digital format, NLP processing chains offer a good support to design such resources from text.", "labels": [], "entities": []}, {"text": "In this context, the task of automatically extracting relations from text is a crucial step ().", "labels": [], "entities": [{"text": "automatically extracting relations from text", "start_pos": 29, "end_pos": 73, "type": "TASK", "confidence": 0.7401809692382812}]}, {"text": "Numerous studies have attempted to extract hypernym relations, as they allow for expressing the backbone structure of such resources and for assigning types to entities.", "labels": [], "entities": []}, {"text": "While symbolic approaches usually rely on manually defined lexico-syntactic patterns identifying clues of relations between terms (Hearst, 1992), statistical approaches, which are nowadays predominant, are generally based on supervised) or unsupervised ( learning methods, or on distributional spaces (.", "labels": [], "entities": []}, {"text": "These methods of different nature answer to the need of exploiting corpora with different specificities (e.g. domain granularity, nature of the corpus, language, target semantic resource, etc.) and which express the hypernym relation in different forms.", "labels": [], "entities": []}, {"text": "For giving some examples, this kind of relation can be expressed by the lexicon and the syntactic structure as in the sentence sand is a sedimentary rock, by a lexical inclusion as in domestic pigeon (implied domestic pigeon is a pigeon), or by using punctuation or layout features that replace lexical markers like the comma in Trojan horse, a Greek myth or even the disposition in enumerative structures.", "labels": [], "entities": []}, {"text": "The study we conduct in this paper aims to show the interest of applying several approaches on a same corpus in order to identify hypernym relations through their various forms of expression.", "labels": [], "entities": []}, {"text": "We are particularly interested in exploiting a corpus containing both well-written text (i.e., sentences expressed with a complete syntactic structure) and syntactically poor formulations (i.e., sentences with syntactic holes), together with a rich formatting.", "labels": [], "entities": []}, {"text": "We analyze the complementarity of a symbolic approach based on lexico-syntactic patterns and a statistical approach based on supervised learning.", "labels": [], "entities": []}, {"text": "We applied these two approaches to a corpus of Wikipedia disambiguation pages, which are very rich in hypernym relations differently expressed, as these pages contain both well-written text and poorly-written text.", "labels": [], "entities": []}, {"text": "Our proposal focuses on the combination of the individual results rather than on the combination of the approaches themselves (e.g., by learning patterns).", "labels": [], "entities": []}, {"text": "Indeed, combining patterns with machine learning usually relies on path-based methods () () (.", "labels": [], "entities": []}, {"text": "However, dependency parsers have proven to perform worse on poorly-written text.", "labels": [], "entities": [{"text": "dependency parsers", "start_pos": 9, "end_pos": 27, "type": "TASK", "confidence": 0.8383775055408478}]}, {"text": "Although our approach is naive in that sense, it proves to provide good results, in particular, in terms of F-measure.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 108, "end_pos": 117, "type": "METRIC", "confidence": 0.9490147233009338}]}, {"text": "This work is part of the SemPedia 1 project that aims at enriching the semantic resource DBPedia for French (semantic resources targeting this language are scarce), by proposing anew Wikipedia extractors dedicated to the hypernym relation.", "labels": [], "entities": []}, {"text": "Hence, we evaluate how the extracted relations could potentially enrich such kind of resource.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 outlines the main work related to our proposal.", "labels": [], "entities": []}, {"text": "Section 3 presents the materials and methods used in our study, namely the description of the training and reference corpus, their pre-processing, and the extraction approaches.", "labels": [], "entities": []}, {"text": "The results obtained are presented and discussed in Section 4.", "labels": [], "entities": []}, {"text": "Finally, Section 5 concludes the paper and presents future directions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Evaluation of the approaches.", "labels": [], "entities": []}, {"text": " Table 3: Number of true positives (TP) found by the approaches.", "labels": [], "entities": [{"text": "Number of true positives (TP)", "start_pos": 10, "end_pos": 39, "type": "METRIC", "confidence": 0.9209072078977313}]}]}