{"title": [{"text": "Unsupervised Separation of Transliterable and Native Words for Malayalam", "labels": [], "entities": [{"text": "Unsupervised Separation of Transliterable and Native Words", "start_pos": 0, "end_pos": 58, "type": "TASK", "confidence": 0.8485689333506993}]}], "abstractContent": [{"text": "Differentiating intrinsic language words from transliterable words is a key step aiding text processing tasks involving different natural languages.", "labels": [], "entities": [{"text": "Differentiating intrinsic language words", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.8224150240421295}]}, {"text": "We consider the problem of unsupervised separation of transliterable words from native words for text in Malayalam language.", "labels": [], "entities": [{"text": "unsupervised separation of transliterable words from native words", "start_pos": 27, "end_pos": 92, "type": "TASK", "confidence": 0.7473035529255867}]}, {"text": "Outlining a key observation on the diversity of characters beyond the word stem, we develop an optimization method to score words based on their nativeness.", "labels": [], "entities": []}, {"text": "Our method relies on the usage of probability distributions over character n-grams that are refined in step with the nativeness scorings in an iterative optimization formulation.", "labels": [], "entities": []}, {"text": "Using an empirical evaluation, we illustrate that our method, DTIM, provides significant improvements in nativeness scoring for Malayalam, establishing DTIM as the preferred method for the task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Malayalam is an agglutinative language from the southern Indian state of Kerala where it is the official state language.", "labels": [], "entities": []}, {"text": "It is spoken by 38 million native speakers, three times as many speakers as Hungarian () or Greek (), for which specialized techniques have been developed in other contexts.", "labels": [], "entities": []}, {"text": "The growing web presence of Malayalam necessitates automatic techniques to process Malayalam text.", "labels": [], "entities": []}, {"text": "A major hurdle in harnessing Malayalam text from social and web media for multi-lingual retrieval and machine translation is the presence of a large amount of transliterable words.", "labels": [], "entities": [{"text": "multi-lingual retrieval", "start_pos": 74, "end_pos": 97, "type": "TASK", "confidence": 0.7112586200237274}, {"text": "machine translation", "start_pos": 102, "end_pos": 121, "type": "TASK", "confidence": 0.742768257856369}]}, {"text": "By transliterable words, we mean both (a) words (from English) like police and train that virtually always appear in transliterated form in contemporary proper nouns such as names that need to be transliterated than translated to correlate with English text.", "labels": [], "entities": []}, {"text": "On a manual analysis of a news article dataset, we found that transliterated words and proper nouns each form 10-12% of all distinct words.", "labels": [], "entities": []}, {"text": "It is useful to transliterate such words for scenarios that involve processing Malayalam text in the company of English text; this will avoid them being treated as separate index terms (wrt their transliteration) in a multi-lingual retrieval engine, and help a statistical translation system to make use of the link to improve effectiveness.", "labels": [], "entities": [{"text": "statistical translation", "start_pos": 261, "end_pos": 284, "type": "TASK", "confidence": 0.7332813143730164}]}, {"text": "In this context, it ia notable that there has been recent interest in devising specialized methods to translate words that fall outside the core vocabulary (.", "labels": [], "entities": []}, {"text": "In this paper, we consider the problem of separating out such transliterable words from the other words within an unlabeled dataset; we refer to the latter as \"native\" words.", "labels": [], "entities": []}, {"text": "We propose an unsupervised method, DTIM, that takes a dictionary of distinct words from a Malayalam corpus and scores each word based on their nativeness.", "labels": [], "entities": []}, {"text": "Our optimization method, DTIM, iteratively refines the nativeness scoring of each word, leveraging dictionary-level statistics modelled using character n-gram probability distributions.", "labels": [], "entities": []}, {"text": "Our empirical analysis establishes the effectiveness of DTIM.", "labels": [], "entities": [{"text": "DTIM", "start_pos": 56, "end_pos": 60, "type": "TASK", "confidence": 0.9098902940750122}]}, {"text": "We outline related work in the area in Section 2.", "labels": [], "entities": []}, {"text": "This is followed by the problem statement in Section 3 and the description of our proposed approach in Section 4.", "labels": [], "entities": []}, {"text": "Our empirical analysis forms Section 5 followed by conclusions in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "Given that it is easier for humans to crisply classify each word as either native or transliterable (nouns or transliterated english words) in lieu of attaching a score to each word, the nativeness scoring (as generated by a scoring method such as ours) often needs to be evaluated against a crisp nativeness assessment, i.e., a scoring with scores in {0, 1}.", "labels": [], "entities": []}, {"text": "To aid this, we consider the ordering of words in the labeled set in the decreasing (or more precisely, non-increasing) order of nativeness scores (each method produces an ordering for the dataset).", "labels": [], "entities": []}, {"text": "To evaluate this ordering, we use two sets of metrics for evaluation: \u2022 Precision at the ends of the ordering: Topk precision denotes the fraction of native words within the k words at the top of the ordering; analogously, Bottom-k precision is the fraction of transliterable words among the bottom k.", "labels": [], "entities": [{"text": "Precision", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.9771960973739624}, {"text": "precision", "start_pos": 116, "end_pos": 125, "type": "METRIC", "confidence": 0.7158024311065674}, {"text": "Bottom-k precision", "start_pos": 223, "end_pos": 241, "type": "METRIC", "confidence": 0.7689103186130524}]}, {"text": "Since a good scoring would likely put native words at the top of the ordering and the transliterable ones at the bottom, a good scoring method would intuitively score 156 high on both these metrics.", "labels": [], "entities": []}, {"text": "We call the average of the top-k and bottom-k precision fora given k, as Avg-k precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.8775181174278259}, {"text": "Avg-k precision", "start_pos": 73, "end_pos": 88, "type": "METRIC", "confidence": 0.9247278869152069}]}, {"text": "These measures, evaluated at varying values of k, indicate the quality of the nativeness scoring.", "labels": [], "entities": []}, {"text": "\u2022 Clustering Quality: Consider the cardinalities of the native and transliterable words from the labeled set as being N and T respectively.", "labels": [], "entities": []}, {"text": "We now take the top-N words and bottom-T words from the ordering generated by each method, and compare against the respective labeled sets as in the case of standard clustering quality evaluation . Since the cardinalities of the generated native (transliterable) cluster and the native (transliterable) labeled set is both N (T ), the Recall of the cluster is identical to its Purity/Precision, and thus, the F-measure too; we simply call it Clustering Quality.", "labels": [], "entities": [{"text": "Recall", "start_pos": 335, "end_pos": 341, "type": "METRIC", "confidence": 0.9958564639091492}, {"text": "Purity/Precision", "start_pos": 377, "end_pos": 393, "type": "METRIC", "confidence": 0.82782910267512}, {"text": "F-measure", "start_pos": 409, "end_pos": 418, "type": "METRIC", "confidence": 0.9704477787017822}]}, {"text": "A cardinalityweighted average of the clustering quality across the native and transliterable clusters yields a single value for the clustering quality across the dataset.", "labels": [], "entities": []}, {"text": "It maybe noted that we are not making the labeled dataset available to the method generating the ordering, instead merely using it's cardinalities for evaluation purposes.", "labels": [], "entities": []}, {"text": "We now describe our empirical study of DTIM, starting with the dataset and experimental setup leading onto the results and analyses.", "labels": [], "entities": [{"text": "DTIM", "start_pos": 39, "end_pos": 43, "type": "TASK", "confidence": 0.9477577805519104}]}, {"text": "We evaluate DTIM on a set of 65068 distinct words from across news articles sourced from Mathrubhumi 4 , a popular Malayalam newspaper; this word list is made available publicly 5 . For evaluation purposes, we got a random subset of 1035 words labeled by one of three human annotators; that has been made available publicly 6 too, each word labeled as either native, transliterable or unknown.", "labels": [], "entities": [{"text": "Mathrubhumi 4 , a popular Malayalam newspaper", "start_pos": 89, "end_pos": 134, "type": "DATASET", "confidence": 0.9291735291481018}]}, {"text": "There were approximately 3 native words for every transliterable word in the labeled set, reflective of distribution in contemporary Malayalam usage as alluded to in the introduction.", "labels": [], "entities": []}, {"text": "We will use the whole set of 65068 words as input to the method, while the evaluation would obviously be limited to the labelled subset of 1035 words.", "labels": [], "entities": []}, {"text": "As outlined in Section 3, we use top-k, bottom-k and avg-k precision (evaluated at varying values of k) as well as clustering quality in our evaluation.", "labels": [], "entities": [{"text": "precision", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.6559663414955139}]}, {"text": "For the comparative evaluaton, we set DTIM parameters as the following: \u03c4 = 10 and a wordstem length of 2.", "labels": [], "entities": []}, {"text": "We will study trends against variations across these parameters in a separate section.", "labels": [], "entities": []}, {"text": "lists the precision measures over various values of k.", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9992682337760925}]}, {"text": "It maybe noted that any instantiation of DTIM (across the four values of n-gram size, n) is able to beat the baselines convincingly on each metric on each value of k, convincingly establishing the effectiveness of the DTIM formulation.", "labels": [], "entities": []}, {"text": "DTIM is seen to be much more effective in separating out the native and transliterable words at either ends of the ordering, than the baselines.", "labels": [], "entities": []}, {"text": "It is also notable that EM-style iterations are able to significantly improve upon the initialization (i.e., INIT).", "labels": [], "entities": [{"text": "INIT", "start_pos": 109, "end_pos": 113, "type": "METRIC", "confidence": 0.9825785160064697}]}, {"text": "That the bottom-k precision is seen to be consistently lower than top-k precision needs to be juxtaposed in the context of the observation that there were only 25% transliterable words against 75% native words; thus, the lift in precision against a random ordering is much more substantial for the transliterable words.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.8377527594566345}, {"text": "precision", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.870582103729248}, {"text": "precision", "start_pos": 229, "end_pos": 238, "type": "METRIC", "confidence": 0.997763991355896}]}, {"text": "The trends across varying n-gram sizes (i.e., n) in DTIM is worth noting too; the higher values of n (such as 3 and 4) are seen to make more errors at the ends of the lists, whereas they catch-up with then \u2208 {1, 2} versions ask increases.", "labels": [], "entities": []}, {"text": "This indicates that smaller-n DTIM is being able to tell apart a minority of the words exceedingly well (wrt native-ness), whereas the higher n-gram modelling is able to spread out the gains across a larger spectrum of words in W.", "labels": [], "entities": []}, {"text": "Around n = 4 and beyond, sparsity effects (since 4-grams and 5-grams would not occur frequently, making it harder to exploit their occurrence statistics) are seen to kick in, causing reductions in precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 197, "end_pos": 206, "type": "METRIC", "confidence": 0.9980887770652771}]}, {"text": "lists the clustering quality metric across the various methods.", "labels": [], "entities": []}, {"text": "Clustering quality, unlike the precision metrics, is designed to evaluate the entire ordering without limiting the analysis to just the top-k and bottom-k entries.", "labels": [], "entities": [{"text": "precision", "start_pos": 31, "end_pos": 40, "type": "METRIC", "confidence": 0.9854598641395569}]}, {"text": "As in the earlier case, DTIM convincingly outperforms the baselines by healthy margins across all values of n.", "labels": [], "entities": [{"text": "DTIM", "start_pos": 24, "end_pos": 28, "type": "TASK", "confidence": 0.6304567456245422}]}, {"text": "Consequent to the trends across n as observed earlier, n \u2208 {3, 4} are seen to deliver better accuracies, with such gains tapering off beyond n = 4 due to sparsity effects.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 93, "end_pos": 103, "type": "METRIC", "confidence": 0.9828782081604004}]}, {"text": "The words, along with the DTIM nativeness scores for n = 3, can be viewed at https://goo.gl/OmhlB3 (the list excludes words with fewer than 3 characters).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Top-k and Bottom-k Precision (best result in each column highlighted)", "labels": [], "entities": [{"text": "Precision", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.9604326486587524}]}, {"text": " Table 4: DTIM Clustering Quality against Word  Stem Length (best result in each row highlighted)", "labels": [], "entities": [{"text": "DTIM Clustering", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.8070154190063477}]}]}