{"title": [{"text": "Redundancy Localization for the Conversationalization of Unstructured Responses", "labels": [], "entities": []}], "abstractContent": [{"text": "Conversational agents offer users a natural-language interface to accomplish tasks, entertain themselves, or access information.", "labels": [], "entities": []}, {"text": "Informational dialogue is particularly challenging in that the agent has to hold a conversation on an open topic, and to achieve a reasonable coverage it generally needs to digest and present unstructured information from textual sources.", "labels": [], "entities": [{"text": "Informational dialogue", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7477521002292633}]}, {"text": "Making responses based on such sources sound natural and fit appropriately into the conversation context is a topic of ongoing research, one of the key issues of which is preventing the agent's responses from sounding repetitive.", "labels": [], "entities": []}, {"text": "Targeting this issue, we propose anew task, known as redundancy localization, which aims to pinpoint semantic overlap between text passages.", "labels": [], "entities": []}, {"text": "To help address it systematically , we formalize the task, prepare a public dataset with fine-grained redundancy labels , and propose a model utilizing a weak training signal defined over the results of a passage-retrieval system on web texts.", "labels": [], "entities": []}, {"text": "The proposed model demonstrates superior performance compared to a state-of-the-art en-tailment model and yields encouraging results when applied to a real-world dialogue.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent years have seen a growing interest in research on conversational agents.", "labels": [], "entities": []}, {"text": "Several strands of dialogue systems have emerged which differ in underlying goals and methods.", "labels": [], "entities": []}, {"text": "Some systems focus on data-driven learning of models which can autonomously hold conversations with humans or one another, potentially even on open domains (; Li * Work performed during an internship at Google.", "labels": [], "entities": []}], "datasetContent": [{"text": "We implemented both UA and BA in the TensorFlow framework () and trained them with the signal from Sec.", "labels": [], "entities": [{"text": "BA", "start_pos": 27, "end_pos": 29, "type": "METRIC", "confidence": 0.9938904047012329}]}, {"text": "5. As input to the passage-retrieval system we used a set of 1.5 million queries, resulting in the same amount of passage triples; 80% were used for training, 10% were used as a separate validation set for hyperparameter optimization, and the final 10% were held out and served as the basis for the smaller dataset with manually annotated labels (EVAL, Sec.", "labels": [], "entities": [{"text": "hyperparameter optimization", "start_pos": 206, "end_pos": 233, "type": "TASK", "confidence": 0.7269022464752197}]}, {"text": "4) . The hyperparameters of UA (h f1 , d f1 , h f3 , d f3 ) and BA (like our model, plus a few additional ones) were optimized separately.", "labels": [], "entities": [{"text": "UA", "start_pos": 28, "end_pos": 30, "type": "DATASET", "confidence": 0.8435719609260559}, {"text": "BA", "start_pos": 64, "end_pos": 66, "type": "METRIC", "confidence": 0.9605936408042908}]}, {"text": "We also experimented with Dropout () for the feedforward networks in step (a-c) (p f1 , p f2 , p f3 ), with different initial learning rates (\u03b7) for Adagrad (, with different batch sizes, and with different vocabulary sizes (|V |).", "labels": [], "entities": []}, {"text": "The final settings for UA used in the reported experiments are shown in Tab.", "labels": [], "entities": [{"text": "UA", "start_pos": 23, "end_pos": 25, "type": "TASK", "confidence": 0.5535788536071777}, {"text": "Tab.", "start_pos": 72, "end_pos": 76, "type": "DATASET", "confidence": 0.9719490110874176}]}, {"text": "3. Word embeddings were initialized with pre-trained embeddings (), the other model parameters were randomly initialized; out-of-vocabulary words were hashed We only annotated a subset of the passages in this part of the data.", "labels": [], "entities": []}, {"text": "We first compare the performance of different variants of generating the redundancy scores for subpassage ranking, for both UA and BA, on DEV.", "labels": [], "entities": [{"text": "BA", "start_pos": 131, "end_pos": 133, "type": "METRIC", "confidence": 0.9434770345687866}, {"text": "DEV", "start_pos": 138, "end_pos": 141, "type": "DATASET", "confidence": 0.9641896486282349}]}, {"text": "We then pick the respective best-performing model variant and compare the systems on TEST.", "labels": [], "entities": [{"text": "TEST", "start_pos": 85, "end_pos": 89, "type": "DATASET", "confidence": 0.8263012766838074}]}, {"text": "The model variants we test are the following: \u2022 UA: The uni-directional alignment model described in Sec.", "labels": [], "entities": [{"text": "UA", "start_pos": 48, "end_pos": 50, "type": "METRIC", "confidence": 0.9586323499679565}]}, {"text": "6. \u2022 UA \u03a3 : Summation instead of averaging in Eq.", "labels": [], "entities": [{"text": "Summation", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.8972768187522888}]}, {"text": "(8), which gives higher weight to long subsequences with redundancy.", "labels": [], "entities": []}, {"text": "\u2022 UA : Calculation of lsim in analogous fashion as BA (see below).", "labels": [], "entities": [{"text": "UA", "start_pos": 2, "end_pos": 4, "type": "METRIC", "confidence": 0.9932988882064819}, {"text": "BA", "start_pos": 51, "end_pos": 53, "type": "METRIC", "confidence": 0.9980080723762512}]}, {"text": "\u2022 UA \u03a3 : Combination of two variants above.", "labels": [], "entities": [{"text": "UA \u03a3", "start_pos": 2, "end_pos": 6, "type": "METRIC", "confidence": 0.9401126503944397}]}, {"text": "\u2022 BA /BA : Models with bi-directional alignment of input texts.", "labels": [], "entities": [{"text": "BA /BA", "start_pos": 2, "end_pos": 8, "type": "METRIC", "confidence": 0.7921070059140524}]}, {"text": "lsim values for tokens of pare produced by using the first/second one of the two alignment matrices as a basis for the max-based aggregation of the normalized attention weights described in Sec.", "labels": [], "entities": []}, {"text": "\u2022 BA \u03a3 / BA \u03a3 : Like above, but sub-sequence similarity is determined via summation rather than calculating the mean in Eq.", "labels": [], "entities": [{"text": "BA", "start_pos": 2, "end_pos": 4, "type": "METRIC", "confidence": 0.9835308194160461}, {"text": "BA", "start_pos": 9, "end_pos": 11, "type": "METRIC", "confidence": 0.8596954345703125}]}, {"text": "We measure performance by calculating the Spearman correlation of the raw passage scores with the gold redundancy for all segments in the respective partition of the dataset.", "labels": [], "entities": []}, {"text": "4 reports results of the different model variants.", "labels": [], "entities": []}, {"text": "For UA, making direct use of the local redundancy scores calculated in step (b) of the model yields slightly better results than post-processing the alignments from step (a) of the model.", "labels": [], "entities": [{"text": "UA", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.8851037621498108}]}, {"text": "The best overall results for UA are achieved when this is combined with the strategy that represents sub-sequence redundancy as the arithmetic mean of the contained tokens' local scores, meaning sub-sequence length needs to betaken into account.", "labels": [], "entities": [{"text": "UA", "start_pos": 29, "end_pos": 31, "type": "TASK", "confidence": 0.9366832375526428}]}, {"text": "For the baseline BA, exploiting the reverse alignment matrix and summing over the alignment scores without correction for sub-sequence length gives the best results.", "labels": [], "entities": []}, {"text": "The bottom of the table reports the results of applying both models with the respective best strategy on the test partition of the dataset.", "labels": [], "entities": []}, {"text": "The proposed uni-directional model clearly outperforms the bi-directional baseline.", "labels": [], "entities": []}, {"text": "This indicates that the direct modeling of uni-directional redundancy during both training and inference time allows a model to better learn to compare a subsequence to another full passage, in comparison to the case where both passages are analyzed in a fine-granular way.", "labels": [], "entities": []}, {"text": "depicts a scatter plot of the segments in TEST, with the x-axis corresponding to the gold redundancy scores (Sec.", "labels": [], "entities": [{"text": "TEST", "start_pos": 42, "end_pos": 46, "type": "DATASET", "confidence": 0.6952211856842041}]}, {"text": "4) and the y-axis showing the redundancy assessment by UA.", "labels": [], "entities": [{"text": "UA", "start_pos": 55, "end_pos": 57, "type": "DATASET", "confidence": 0.7327081561088562}]}, {"text": "While actually redundant segments tend to be handled correctly by the model, a certain amount of non-redundant segments get assigned a relatively high absolute redundancy value, which is not problematic as long as the actually redundant segments of the same passage are rated even higher.", "labels": [], "entities": []}, {"text": "The next section elaborates on an experiment that looks into the quality of this internal ranking of segments forgiven passages, and how this ranking could potentially be utilized in an application.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Three weakly-labeled examples (Sec. 5). Underlining used to indicate overlapping/distinct  information between items.", "labels": [], "entities": []}, {"text": " Table 2: Distribution of sub-passage labels in  EVAL.", "labels": [], "entities": [{"text": "EVAL", "start_pos": 49, "end_pos": 53, "type": "DATASET", "confidence": 0.8587213158607483}]}]}