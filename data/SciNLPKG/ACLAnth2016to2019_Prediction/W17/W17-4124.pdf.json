{"title": [{"text": "Improving Opinion-Target Extraction with Character-Level Word Embeddings", "labels": [], "entities": [{"text": "Improving Opinion-Target Extraction", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8996434609095255}]}], "abstractContent": [{"text": "Fine-grained sentiment analysis received increasing attention in recent years.", "labels": [], "entities": [{"text": "Fine-grained sentiment analysis", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.6901943385601044}]}, {"text": "Extracting opinion target expressions (OTE) in reviews is often an important step in fine-grained, aspect-based sentiment analysis.", "labels": [], "entities": [{"text": "Extracting opinion target expressions (OTE) in reviews", "start_pos": 0, "end_pos": 54, "type": "TASK", "confidence": 0.8863122595681084}, {"text": "aspect-based sentiment analysis", "start_pos": 99, "end_pos": 130, "type": "TASK", "confidence": 0.6627463102340698}]}, {"text": "Retrieving this information from user-generated text, however, can be difficult.", "labels": [], "entities": []}, {"text": "Customer reviews, for instance, are prone to contain misspelled words and are difficult to process due to their domain-specific language.", "labels": [], "entities": []}, {"text": "In this work, we investigate whether character-level models can improve the performance for the identification of opinion target expressions.", "labels": [], "entities": [{"text": "identification of opinion target expressions", "start_pos": 96, "end_pos": 140, "type": "TASK", "confidence": 0.8028272032737732}]}, {"text": "We integrate information about the character structure of a word into a sequence labeling system using character-level word em-beddings and show their positive impact on the systems performance.", "labels": [], "entities": []}, {"text": "Specifically, we obtain an increase by 3.3 points F 1-score with respect to our baseline model.", "labels": [], "entities": []}, {"text": "In further experiments, we reveal encoded character patterns of the learned embed-dings and give a nuanced view of the performance differences of both models.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, there has been an increased interest in developing sentiment analysis models that predict sentiment at a more fine-grained level than at the level of a complete document.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.9030550122261047}]}, {"text": "A key task within fine-grained sentiment analysis consists in identifying so called opinion target expressions (OTE).", "labels": [], "entities": [{"text": "fine-grained sentiment analysis", "start_pos": 18, "end_pos": 49, "type": "TASK", "confidence": 0.6985027194023132}]}, {"text": "These are the objects of a sentiment expression.", "labels": [], "entities": []}, {"text": "Consider the following example: \" Moules were excellent , but the lobster ravioli was VERY salty ! \" where blue boxes mark opinion targets, (dashed) red boxes the opinion terms and arrows the respective relations.", "labels": [], "entities": [{"text": "VERY", "start_pos": 86, "end_pos": 90, "type": "METRIC", "confidence": 0.9977588653564453}]}, {"text": "In this example, there are two sentiment statements, one positive and one negative.", "labels": [], "entities": []}, {"text": "The positive one is indicated by the word excellent and is expressed towards the Moules.", "labels": [], "entities": [{"text": "Moules", "start_pos": 81, "end_pos": 87, "type": "DATASET", "confidence": 0.9462999105453491}]}, {"text": "The second, negative sentiment, is indicated by the word salty and is expressed towards the lobster ravioli.", "labels": [], "entities": []}, {"text": "In this work, we consider the task of identifying such opinion target expressions in reviews as a sequence labeling problem.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 98, "end_pos": 115, "type": "TASK", "confidence": 0.6670851111412048}]}, {"text": "A particular challenge involved in OTE identification stems from the fact that online reviews can be of low quality and contain misspelled words, novel word creations, rare words etc.", "labels": [], "entities": [{"text": "OTE identification", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.9762596487998962}]}, {"text": "We thus hypothesize that including character-embeddings might be beneficial in the context of OTE extraction, allowing a model to be robust to spelling errors as well as generalize to unseen words.", "labels": [], "entities": [{"text": "OTE extraction", "start_pos": 94, "end_pos": 108, "type": "TASK", "confidence": 0.9428373873233795}]}, {"text": "A further challenge is that an OTE can span multiple tokens.", "labels": [], "entities": []}, {"text": "In this work, we thus investigate whether a character-based approach is capable of using the additional low-level information to improve upon a standard word-based baseline.", "labels": [], "entities": []}, {"text": "We hypothesize that character-level word embeddings capture relevant information for opinion target expression extraction that regular (skip-gram) word embeddings lack.", "labels": [], "entities": [{"text": "opinion target expression extraction", "start_pos": 85, "end_pos": 121, "type": "TASK", "confidence": 0.6242556571960449}]}, {"text": "We propose a neural network model that learns and utilizes character-level word embeddings to extract opinion target expressions and examine its characteristics.", "labels": [], "entities": []}, {"text": "Our experimental analysis shows that with an increase of 3.3 points F 1 -score, the character information is indeed valuable for the task.", "labels": [], "entities": [{"text": "1 -score", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.7288074493408203}]}, {"text": "Further experiments reveal encoded character patterns of the learned embeddings and give a nuanced view of the performance differences of both models.", "labels": [], "entities": []}, {"text": "The rest of the paper is structured as follows: Section 2 discusses related work from two domains: fine-grained sentiment analysis and character-level neural text processing.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.8027256727218628}, {"text": "character-level neural text processing", "start_pos": 135, "end_pos": 173, "type": "TASK", "confidence": 0.762361690402031}]}, {"text": "In Section 3, we describe our approach to address opinion target extraction and present the recurrent neural network models that we use to measure the impact of character information on the task.", "labels": [], "entities": [{"text": "address opinion target extraction", "start_pos": 42, "end_pos": 75, "type": "TASK", "confidence": 0.6169120073318481}]}, {"text": "We carryout our evaluation and analysis in Section 4 and examine the learned character-level word embeddings in more detail.", "labels": [], "entities": []}, {"text": "Finally, Section 5 summarizes our findings and presents directions for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we evaluate the impact of using character-level word embeddings on the task of extracting opinion target expressions from usergenerated reviews.", "labels": [], "entities": [{"text": "extracting opinion target expressions from usergenerated reviews", "start_pos": 96, "end_pos": 160, "type": "TASK", "confidence": 0.7910561391285488}]}, {"text": "For this, we compare the character-enhanced model from Section 3.2 to the baseline RNN of Section 3.1.", "labels": [], "entities": []}, {"text": "We start by describing the used dataset in Section 4.1.", "labels": [], "entities": []}, {"text": "To select a fitting set of hyperparameters for each model, we perform a 5-fold cross validation on the training portion of our dataset.", "labels": [], "entities": []}, {"text": "Using the best hyperparameters, we evaluate both models on the test portion of the data and investigate the models' properties with respect to the induced character information in Sections 4.3 and 4.4.", "labels": [], "entities": []}, {"text": "Evaluation is carried out in terms of F 1 -score of expected opinion target expressions and retrieved opinion term expressions using exact matches . The research code is publicly available at https://github.com/ sjebbara/clwe-ote.", "labels": [], "entities": [{"text": "F 1 -score", "start_pos": 38, "end_pos": 48, "type": "METRIC", "confidence": 0.9558973759412766}]}, {"text": "In our experiments, we use the data for the SemEval aspect-based sentiment analysis challenge of the year 2016).", "labels": [], "entities": [{"text": "SemEval aspect-based sentiment analysis", "start_pos": 44, "end_pos": 83, "type": "TASK", "confidence": 0.9263252168893814}]}, {"text": "The used dataset consists of review sentences from the restaurant domain with annotations for opinion target expressions.", "labels": [], "entities": []}, {"text": "gives a summary of the dataset.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Relevant statistics of the SemEval 2016  dataset (Task 5, restaurant domain).", "labels": [], "entities": [{"text": "SemEval 2016  dataset", "start_pos": 37, "end_pos": 58, "type": "DATASET", "confidence": 0.7295521895090739}]}]}