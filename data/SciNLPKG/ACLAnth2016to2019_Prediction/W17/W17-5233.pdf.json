{"title": [{"text": "YZU-NLP at EmoInt-2017: Determining Emotion Intensity Using a Bi-directional LSTM-CNN Model", "labels": [], "entities": [{"text": "YZU-NLP at EmoInt-2017", "start_pos": 0, "end_pos": 22, "type": "DATASET", "confidence": 0.7152842879295349}, {"text": "Determining Emotion Intensity", "start_pos": 24, "end_pos": 53, "type": "TASK", "confidence": 0.7879430452982584}]}], "abstractContent": [{"text": "The EmoInt-2017 task aims to determine a continuous numerical value representing the intensity to which an emotion is expressed in a tweet.", "labels": [], "entities": []}, {"text": "Compared to classification tasks that identify 1 among n emotions fora tweet, the present task can provide more fine-grained (real-valued) sentiment analysis.", "labels": [], "entities": [{"text": "real-valued) sentiment analysis", "start_pos": 126, "end_pos": 157, "type": "TASK", "confidence": 0.7014115303754807}]}, {"text": "This paper presents a system that uses a bi-directional LSTM-CNN model to complete the competition task.", "labels": [], "entities": []}, {"text": "Combining bi-directional LSTM and CNN, the prediction process considers both global information in a tweet and local important information.", "labels": [], "entities": []}, {"text": "The proposed method ranked sixth among twenty-one teams in terms of Pearson Correlation Coefficient .", "labels": [], "entities": [{"text": "Pearson Correlation Coefficient", "start_pos": 68, "end_pos": 99, "type": "METRIC", "confidence": 0.9275199174880981}]}], "introductionContent": [{"text": "Categorical and dimensional representations are two major approaches to representing emotional states.", "labels": [], "entities": []}, {"text": "The categorical approach represents emotional states using several discrete classes such as positive and negative (binary) or six basic emotions (anger, happiness, fear, sadness, disgust, and surprise), which have been successfully adopted in various sentiment applications (.", "labels": [], "entities": []}, {"text": "Based on this representation, application tasks focus on classification (i.e., identify 1 among n emotions fora given text).", "labels": [], "entities": []}, {"text": "The dimensional approach provides a more fine-grained (real-valued) sentiment analysis.", "labels": [], "entities": [{"text": "real-valued) sentiment analysis", "start_pos": 55, "end_pos": 86, "type": "TASK", "confidence": 0.7424429953098297}]}, {"text": "Knowing the intensity or degree to which an emotion is expressed in text is useful for more intelligent sentiment applications (.", "labels": [], "entities": []}, {"text": "The EmoInt-2017 task) seeks to automatically determine a continuous numerical value representing the intensity or degree to which an emotion is expressed in a tweet.", "labels": [], "entities": []}, {"text": "That is, given a tweet and an emotion X, determine the intensity of emotion X felt by the speaker ranging from 0 (feeling the least amount of emotion X) to 1 (feeling the maximum amount of emotion X).", "labels": [], "entities": []}, {"text": "The proposed system uses word embeddings () and a bi-directional LSTM-CNN model to complete the competition task.", "labels": [], "entities": []}, {"text": "Word embeddings can capture both semantic and syntactic information of selected words and provide a low dimensional and continuous vector representation for them.", "labels": [], "entities": []}, {"text": "Convoluational neural network (CNN)) is effective for extracting features in texts without considering the global information of that text.", "labels": [], "entities": []}, {"text": "Long short-term memory (LSTM) can capture long-distance dependencies by sequentially modeling texts across words.", "labels": [], "entities": []}, {"text": "The proposed bi-directional LSTM-CNN model combines LSTM and CNN to model texts, encoding global information captured by LSTM in the most principal features extracted by CNN.", "labels": [], "entities": []}, {"text": "We first use word vectors to transform tweets into text matrices.", "labels": [], "entities": []}, {"text": "The bi-directional LSTM is applied to these matrices to build new text matrices.", "labels": [], "entities": []}, {"text": "CNN is applied to the output of the bi-directional LSTM to obtain text vectors for emotion intensity prediction.", "labels": [], "entities": [{"text": "CNN", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9312775135040283}, {"text": "emotion intensity prediction", "start_pos": 83, "end_pos": 111, "type": "TASK", "confidence": 0.7042842209339142}]}, {"text": "LSTM, CNN and their combination are described in detail in the following section.", "labels": [], "entities": [{"text": "LSTM", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8447731733322144}, {"text": "CNN", "start_pos": 6, "end_pos": 9, "type": "DATASET", "confidence": 0.8988754749298096}]}, {"text": "shows the overall framework of the proposed Bi-directional LSTM-CNN model.", "labels": [], "entities": []}, {"text": "For a given sentence, the system's input is a sentence matrix composed of the word vectors of all words and punctuation in the sentence.", "labels": [], "entities": []}, {"text": "The sentence matrix is further transformed into anew sentence matrix by the Bi-directional LSTM model.", "labels": [], "entities": []}, {"text": "The new sentence matrix is then sequentially passed through a convolutional layer and a max pooling layer for feature extraction.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 110, "end_pos": 128, "type": "TASK", "confidence": 0.7310901582241058}]}, {"text": "The extracted features are then passed through a dense layer to build a sentence vector for emotion intensity prediction.", "labels": [], "entities": [{"text": "emotion intensity prediction", "start_pos": 92, "end_pos": 120, "type": "TASK", "confidence": 0.718803475300471}]}], "datasetContent": [{"text": "This section evaluates the performance of the proposed bi-directional LSTM-CNN model by submitting the results to the EmoInt-2017 task.", "labels": [], "entities": [{"text": "EmoInt-2017 task", "start_pos": 118, "end_pos": 134, "type": "DATASET", "confidence": 0.8582856953144073}]}, {"text": "The statistics of the official dataset) used in this competition are summarized in.", "labels": [], "entities": []}, {"text": "Each tweet was rated with a real-value (emotion intensity) in the range of (0, 1).", "labels": [], "entities": [{"text": "real-value (emotion intensity)", "start_pos": 28, "end_pos": 58, "type": "METRIC", "confidence": 0.7545844674110412}]}, {"text": "Training, development and test datasets are provided for four emotions: joy, sadness, fear, and anger.", "labels": [], "entities": []}, {"text": "We trained four models corresponding to four emotions using their respective training sets without their development sets.", "labels": [], "entities": []}, {"text": "The anger, joy and fear models used the architecture of the proposed bi-directional LSTM-CNN model.", "labels": [], "entities": []}, {"text": "To improve results, the sadness model used the architecture of CNN model which excludes the bi-directional LSTM layer shown in.", "labels": [], "entities": []}, {"text": "The EmoInt-2017 task published the results for all participants using the Pearson and Spearman correlation coefficient.", "labels": [], "entities": [{"text": "EmoInt-2017 task", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.8711669743061066}, {"text": "Pearson and Spearman correlation coefficient", "start_pos": 74, "end_pos": 118, "type": "METRIC", "confidence": 0.7421347618103027}]}, {"text": "A total of twenty-one teams participated in the task.", "labels": [], "entities": []}, {"text": "shows the results of the proposed bi-directional LSTM-CNN model.", "labels": [], "entities": []}, {"text": "shows the results over the subset of the test data with a gold emotion intensity score greater than or equal to 0.5.", "labels": [], "entities": [{"text": "gold emotion intensity score", "start_pos": 58, "end_pos": 86, "type": "METRIC", "confidence": 0.8104333281517029}]}, {"text": "shows the experimental results for CNN, LSTM and their combineations after the release of test set ratings.", "labels": [], "entities": [{"text": "CNN", "start_pos": 35, "end_pos": 38, "type": "DATASET", "confidence": 0.9685371518135071}, {"text": "LSTM", "start_pos": 40, "end_pos": 44, "type": "DATASET", "confidence": 0.8126621842384338}]}, {"text": "LSTM used the last hidden state as the text vector, which caused the worse performance than CNN and BiLSTM-CNN.", "labels": [], "entities": [{"text": "LSTM", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8433985114097595}, {"text": "CNN", "start_pos": 92, "end_pos": 95, "type": "DATASET", "confidence": 0.9008026719093323}]}, {"text": "In addition, BiLSTM-CNN performed a little better than CNN and performed well for the subset with higher emotion intensity scores (>=0.5).", "labels": [], "entities": [{"text": "BiLSTM-CNN", "start_pos": 13, "end_pos": 23, "type": "METRIC", "confidence": 0.8348034620285034}, {"text": "CNN", "start_pos": 55, "end_pos": 58, "type": "DATASET", "confidence": 0.6929234862327576}]}], "tableCaptions": [{"text": " Table 1: Summary of data statistics.", "labels": [], "entities": [{"text": "Summary", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.8964542150497437}]}, {"text": " Table 3: Results of the proposed BiLSTM- CNN model.", "labels": [], "entities": [{"text": "BiLSTM- CNN", "start_pos": 34, "end_pos": 45, "type": "TASK", "confidence": 0.45053912202517193}]}, {"text": " Table 5: Comparative results of different  methods.", "labels": [], "entities": []}, {"text": " Table 4: Results of the proposed BiLSTM- CNN model over a subset of the test data with a  gold emotion intensity score greater than or  equal to 0.5.", "labels": [], "entities": [{"text": "BiLSTM- CNN", "start_pos": 34, "end_pos": 45, "type": "TASK", "confidence": 0.3581896225611369}, {"text": "gold emotion intensity score", "start_pos": 91, "end_pos": 119, "type": "METRIC", "confidence": 0.7599041610956192}]}]}