{"title": [{"text": "Complex Word Identification: Challenges in Data Annotation and System Performance", "labels": [], "entities": [{"text": "Complex Word Identification", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6752799948056539}]}], "abstractContent": [{"text": "This paper revisits the problem of complex word identification (CWI) following up the SemEval CWI shared task.", "labels": [], "entities": [{"text": "complex word identification (CWI)", "start_pos": 35, "end_pos": 68, "type": "TASK", "confidence": 0.7852348983287811}, {"text": "SemEval CWI shared task", "start_pos": 86, "end_pos": 109, "type": "TASK", "confidence": 0.6019486784934998}]}, {"text": "We use ensemble classifiers to investigate how well computational methods can discriminate between complex and non-complex words.", "labels": [], "entities": []}, {"text": "Furthermore, we analyze the classification performance to understand what makes lexical complexity challenging.", "labels": [], "entities": []}, {"text": "Our findings show that most systems performed poorly on the SemEval CWI dataset, and one of the reasons for that is the way in which human annotation was performed.", "labels": [], "entities": [{"text": "SemEval CWI dataset", "start_pos": 60, "end_pos": 79, "type": "DATASET", "confidence": 0.8395521640777588}]}], "introductionContent": [{"text": "Lexical complexity plays a crucial role in reading comprehension.", "labels": [], "entities": []}, {"text": "Several NLP systems have been developed to simplify texts to second language learners and to native speakers with low literacy levels) and reading disabilities (.", "labels": [], "entities": []}, {"text": "Identifying which words are likely to be considered complex by a given target population is an important task in many text simplification pipelines called complex word identification (CWI).", "labels": [], "entities": [{"text": "complex word identification (CWI)", "start_pos": 155, "end_pos": 188, "type": "TASK", "confidence": 0.8068786263465881}]}, {"text": "CWI has been addressed as a stand-alone task and as part of studies in lexical and text simplification.", "labels": [], "entities": [{"text": "text simplification", "start_pos": 83, "end_pos": 102, "type": "TASK", "confidence": 0.7125127166509628}]}, {"text": "The recent SemEval 2016 Task 11 on Complex Word Identification -henceforth SemEval CWI -addressed this challenge by providing participants with a manually annotated dataset for this purpose).", "labels": [], "entities": [{"text": "SemEval 2016 Task 11 on Complex Word Identification -henceforth SemEval CWI", "start_pos": 11, "end_pos": 86, "type": "TASK", "confidence": 0.6778681327899297}]}, {"text": "In the SemEval CWI dataset, words in context were tagged as complex or non-complex, that is, difficult to be understood by non-native English speakers, or not.", "labels": [], "entities": [{"text": "SemEval CWI dataset", "start_pos": 7, "end_pos": 26, "type": "DATASET", "confidence": 0.7624992330869039}]}, {"text": "Participating teams used this dataset to train classifiers to predict lexical complexity assigning a label 0 to non-complex words and 1 to complex ones.", "labels": [], "entities": []}, {"text": "Below is an example instance from their dataset: (1) A frenulum is a small fold of tissue that secures or restricts the motion of a mobile organ in the body.", "labels": [], "entities": []}, {"text": "The words in bold -frenulum, restricts, motion -have been assigned by at least one of the annotators as complex and thus they were labeled as such in the training set.", "labels": [], "entities": [{"text": "frenulum", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9277846217155457}, {"text": "motion", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.9213746786117554}]}, {"text": "All words that have not been assigned by at least one annotator as complex have been labeled as non-complex.", "labels": [], "entities": []}, {"text": "In this paper we evaluate the dataset annotation and the performance of systems participating in the SemEval CWI task.", "labels": [], "entities": [{"text": "SemEval CWI task", "start_pos": 101, "end_pos": 117, "type": "TASK", "confidence": 0.7990008989969889}]}, {"text": "We first estimate the theoretical upper bound performance of the task given the output of the SemEval systems.", "labels": [], "entities": []}, {"text": "Secondly, we investigate whether human annotation correlates to the systems' performance by carefully analyzing the samples of multiple annotators.", "labels": [], "entities": []}, {"text": "Although in the shared task complexity was modeled as a binary classification task, we pose that lexical complexity should actually be seen in a continuum spectrum.", "labels": [], "entities": []}, {"text": "Intuitively, words that are labeled as complex more often should be easier to be predicted by CWI systems.", "labels": [], "entities": []}, {"text": "This hypothesis is investigated in Section 3.3.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, no evaluation of this kind has been carried out for CWI.", "labels": [], "entities": []}, {"text": "The most similar analyses to ours have been carried out by for native language identification and by for language variety identification.", "labels": [], "entities": [{"text": "native language identification", "start_pos": 63, "end_pos": 93, "type": "TASK", "confidence": 0.6198828518390656}, {"text": "language variety identification", "start_pos": 105, "end_pos": 136, "type": "TASK", "confidence": 0.6286338667074839}]}], "datasetContent": [{"text": "In this section we present the data, the methods, and an overview of the experiments we propose in this paper.", "labels": [], "entities": []}, {"text": "The goal of the experiments is to evaluate CWI performance with respect to computational methods and the manual annotation of the: SemEval CWI -Systems and approaches dataset.", "labels": [], "entities": []}, {"text": "For this purpose we build a plurality ensemble and an oracle classifier and subsequently analyze systems output using the manual annotation provided by the SemEval CWI organizers.", "labels": [], "entities": [{"text": "SemEval CWI organizers", "start_pos": 156, "end_pos": 178, "type": "DATASET", "confidence": 0.7482398847738901}]}], "tableCaptions": [{"text": " Table 2: Results for plurality voting", "labels": [], "entities": [{"text": "plurality voting", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.9340386688709259}]}, {"text": " Table 3: Results for oracle classifier (top-3)", "labels": [], "entities": []}, {"text": " Table 4: Word length and complexity", "labels": [], "entities": []}, {"text": " Table 5. For  comparison we also present five randomly selected  words labeled as complex by only one annotator  which received the same label in the train and test  sets.", "labels": [], "entities": []}, {"text": " Table 5: Annotation vs. prediction.", "labels": [], "entities": []}]}