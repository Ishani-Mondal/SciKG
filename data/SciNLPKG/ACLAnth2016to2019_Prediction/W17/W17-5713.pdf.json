{"title": [{"text": "Comparison of SMT and NMT trained with large Patent Corpora: Japio at WAT2017", "labels": [], "entities": [{"text": "SMT", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.9033214449882507}, {"text": "WAT2017", "start_pos": 70, "end_pos": 77, "type": "TASK", "confidence": 0.3520812690258026}]}], "abstractContent": [{"text": "Japan Patent Information Organization (Japio) participates in patent subtasks (JPC-EJ/JE/CJ/KJ) with phrase-based statistical machine translation (SMT) and neural machine translation (NMT) systems which are trained with its own patent corpora in addition to the sub-task corpora provided by organizers of WAT2017.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation (SMT) and neural machine translation (NMT)", "start_pos": 101, "end_pos": 188, "type": "TASK", "confidence": 0.7516174614429474}, {"text": "WAT2017", "start_pos": 305, "end_pos": 312, "type": "DATASET", "confidence": 0.7529173493385315}]}, {"text": "In EJ and CJ subtasks, SMT and NMT systems whose sizes of training corpora are about 50 million and 10 million sentence pairs respectively achieved comparable scores for automatic evaluations, but NMT systems were superior to SMT systems for both official and in-house human evaluations.", "labels": [], "entities": [{"text": "SMT", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.9691691994667053}, {"text": "SMT", "start_pos": 226, "end_pos": 229, "type": "TASK", "confidence": 0.9646176099777222}]}], "introductionContent": [{"text": "Japan Patent Information Organization (Japio) provides a patent information service named GPG/FX 1 , which enables users to do crosslingual information retrieval (CLIR) on patent documents by translating English and Chinese patents into Japanese and storing the translations in a full-text search engine.", "labels": [], "entities": [{"text": "GPG/FX 1", "start_pos": 90, "end_pos": 98, "type": "DATASET", "confidence": 0.8527336120605469}, {"text": "crosslingual information retrieval (CLIR)", "start_pos": 127, "end_pos": 168, "type": "TASK", "confidence": 0.7488392988840739}]}, {"text": "For this purpose, we use a phrase-based statistical machine translation (SMT) system for Chinese-to-Japanese translation, and are preparing to change an English-to-Japanese translation system from a rule-based machine translation (RBMT) system to an SMT system.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation (SMT)", "start_pos": 27, "end_pos": 77, "type": "TASK", "confidence": 0.7265854946204594}, {"text": "Chinese-to-Japanese translation", "start_pos": 89, "end_pos": 120, "type": "TASK", "confidence": 0.7103514075279236}, {"text": "rule-based machine translation (RBMT)", "start_pos": 199, "end_pos": 236, "type": "TASK", "confidence": 0.7903353869915009}, {"text": "SMT", "start_pos": 250, "end_pos": 253, "type": "TASK", "confidence": 0.9816744923591614}]}, {"text": "To improve translation quality, we have been building technical term dictionaries and parallel corpora, and the current corpora sizes are 300 million sentence pairs for English-Japanese (EJ) and 100 million for Chinese-Japanese (CJ).", "labels": [], "entities": []}, {"text": "We have also built a KoreanJapanese (KJ) corpus which contains about 13 million sentence pairs for adding Korean-toJapanese translation to enable searching Korean patents as well.", "labels": [], "entities": [{"text": "KoreanJapanese (KJ) corpus", "start_pos": 21, "end_pos": 47, "type": "DATASET", "confidence": 0.6800410985946655}]}, {"text": "Our current concern is neural machine translation (NMT), which has been used practically in the field of patent translation since last year.", "labels": [], "entities": [{"text": "neural machine translation (NMT)", "start_pos": 23, "end_pos": 55, "type": "TASK", "confidence": 0.7998479207356771}, {"text": "patent translation", "start_pos": 105, "end_pos": 123, "type": "TASK", "confidence": 0.7030327320098877}]}, {"text": "The new approach has been reported to produce better translations than SMT by training with a smaller corpus than SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 71, "end_pos": 74, "type": "TASK", "confidence": 0.9666897654533386}, {"text": "SMT", "start_pos": 114, "end_pos": 117, "type": "TASK", "confidence": 0.8109210133552551}]}, {"text": "Our translation results in the 4th Workshop on Asian Translation (WAT2017) ( show the same conclusion.", "labels": [], "entities": [{"text": "Asian Translation (WAT2017)", "start_pos": 47, "end_pos": 74, "type": "TASK", "confidence": 0.7607727587223053}]}], "datasetContent": [{"text": "We conducted pairwise evaluation based on adequacy.", "labels": [], "entities": []}, {"text": "When evaluating a translation, which translation is better is determined based on how much of the meaning of a source sentence is expressed in its translation.", "labels": [], "entities": []}, {"text": "Taking JPO adequacy into account, insertion and deletion of conjunctions which are considered not to convey important information are ignored if translations are grammatical.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Official Evaluation Results", "labels": [], "entities": []}, {"text": " Table 2: Official Human Evaluation Results for JPC-EJ subtask", "labels": [], "entities": [{"text": "JPC-EJ subtask", "start_pos": 48, "end_pos": 62, "type": "DATASET", "confidence": 0.8818188011646271}]}, {"text": " Table 3: Translations for in-house evaluations", "labels": [], "entities": [{"text": "Translations", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.9725427031517029}]}, {"text": " Table 4: Result of pairwise evaluations", "labels": [], "entities": []}, {"text": " Table 5: Errors of SMT and NMT for JPC-EJ/CJ", "labels": [], "entities": [{"text": "Errors", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.993152379989624}, {"text": "SMT", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9790619015693665}, {"text": "JPC-EJ/CJ", "start_pos": 36, "end_pos": 45, "type": "DATASET", "confidence": 0.8344303170839945}]}]}