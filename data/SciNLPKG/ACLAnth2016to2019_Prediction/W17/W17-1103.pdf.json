{"title": [{"text": "Potential and Limitations of Cross-Domain Sentiment Classification", "labels": [], "entities": [{"text": "Cross-Domain Sentiment Classification", "start_pos": 29, "end_pos": 66, "type": "TASK", "confidence": 0.7453858852386475}]}], "abstractContent": [{"text": "In this paper we investigate the cross-domain performance of sentiment analysis systems.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.9365734159946442}]}, {"text": "For this purpose we train a con-volutional neural network (CNN) on data from different domains and evaluate its performance on other domains.", "labels": [], "entities": []}, {"text": "Furthermore , we evaluate the usefulness of combining a large amount of different smaller annotated corpora to a large corpus.", "labels": [], "entities": []}, {"text": "Our results show that more sophisticated approaches are required to train a system that works equally well on various domains.", "labels": [], "entities": []}], "introductionContent": [{"text": "Most work regarding sentiment analysis focuses on training and testing a sentiment classifier on data of the same domain.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 20, "end_pos": 38, "type": "TASK", "confidence": 0.9591099619865417}]}, {"text": "For example anew classifier is trained on tweets and tested on tweets.", "labels": [], "entities": []}, {"text": "However, in real-world scenarios the data might originate from different sources and domains.", "labels": [], "entities": []}, {"text": "Often it is the case that sentiment analysis is performed on a domain for which there is no training data available.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.9768686592578888}]}, {"text": "Instead of investing large amounts of money to create such a corpus it would make more sense to use an existing classifier.", "labels": [], "entities": []}, {"text": "However, it is not always clear how well the existing classifier generalizes on the target domain.", "labels": [], "entities": []}, {"text": "Although, it is obvious that the performance will be affected negatively, the magnitude is not known.", "labels": [], "entities": []}, {"text": "This missing information is often useful for assessing the need of generating anew classifier fora given domain which is very costly.", "labels": [], "entities": []}, {"text": "Thus, our work is driven by the question of how useful sentiment classifiers are if we evaluate them with datasets from unseen domains, and if a combination of data from different domains might help to overcome the recurring problem of having too little data.", "labels": [], "entities": [{"text": "sentiment classifiers", "start_pos": 55, "end_pos": 76, "type": "TASK", "confidence": 0.8055287301540375}]}, {"text": "Furthermore, we assess the usefulness of large weakly supervised corpora where the labels are inferred from properties of the text, e.g. the smileys in the text or the rating of a review.", "labels": [], "entities": []}, {"text": "We answer the question of how much gain one can expect from leveraging such corpora.", "labels": [], "entities": []}, {"text": "Usually, cross-domain sentiment analysis has a low performance due to the vocabulary mismatch ().", "labels": [], "entities": [{"text": "cross-domain sentiment analysis", "start_pos": 9, "end_pos": 40, "type": "TASK", "confidence": 0.7637842694918314}]}, {"text": "Thus, we asses the impact of word embeddings trained on large amounts of data, thus guaranteeing a large coverage of the vocabulary.", "labels": [], "entities": []}, {"text": "We then asses how word embeddings trained on different types of data (e.g. News, Twitter) impact the performance of the system.", "labels": [], "entities": []}, {"text": "For this, we train a convolutional neural network (CNN) based on () on data from different combinations of domains and evaluate its performance on foreign domains.", "labels": [], "entities": []}, {"text": "Related Work Some research has been done already in the field of cross-domain sentiment classification.", "labels": [], "entities": [{"text": "cross-domain sentiment classification", "start_pos": 65, "end_pos": 102, "type": "TASK", "confidence": 0.8212985992431641}]}, {"text": "Most of the work in this area focuses on the mismatch in the vocabularies of the different domains.", "labels": [], "entities": []}, {"text": "( overcome the challenge of vocabulary-mismatch by employing a spectral feature alignment algorithm to map domainspecific words to a unified representation which can then be used in conjunction with the domainindependent words to lower the mismatch between the domains.", "labels": [], "entities": []}, {"text": "() use structural correspondence learning to adapt the vocabulary of the various domains.", "labels": [], "entities": []}, {"text": "() experiment with ensembles of classifiers where each classifier was trained on a specific domain and then used in combination to boost the crossdomain performance.", "labels": [], "entities": []}, {"text": "() use a semi-supervised algorithm, which leverages supervised and unsupervised data, to create a sentiment-sensitive thesaurus which is used to compute the relatedness of words from different domains.", "labels": [], "entities": []}, {"text": "() uses the aforementioned sentiment-sensitive thesaurus to generate sentiment-sensitive word embeddings.", "labels": [], "entities": []}, {"text": "() apply unsupervised cross-domain sentiment classification, where they use spectral embeddings to project words and documents into a low dimensional embedding space.", "labels": [], "entities": [{"text": "cross-domain sentiment classification", "start_pos": 22, "end_pos": 59, "type": "TASK", "confidence": 0.7342783411343893}]}, {"text": "() borrow ideas from SCL and combine it with auxiliary binary predicition tasks to learn dense sentence embeddings which incorporate sentiment and can be used in a cross-domain context.", "labels": [], "entities": []}, {"text": "Contribution Our work presents an in-depth analysis on the generalization power of the current state-of-the-art in a cross-domain setting.", "labels": [], "entities": []}, {"text": "This work can be used to estimate and predict the expected drop in performance fora given sentiment classifier.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the following we refer to the system trained on a single target domain (TD) data as specialized TD system, a system trained on one foreign domain (FD) dataset and evaluated on the TD test set is called a specialized FD system, a system trained on a combinations of FD corpora is called a generalized FD system, and a system trained on all data is called a generalized system.", "labels": [], "entities": [{"text": "TD test set", "start_pos": 183, "end_pos": 194, "type": "DATASET", "confidence": 0.7841858367125193}]}, {"text": "We train the system on the data of one domain called target domain (TD) and test it on the TD as well as the foreign domains (FD).", "labels": [], "entities": []}, {"text": "The system is optimized for the TD by using the test set of the TD to perform early-stopping.", "labels": [], "entities": []}, {"text": "Furthermore we trained the system on the union of all domains and tested it on all the domains separately.", "labels": [], "entities": []}, {"text": "For optimization we used the TD test set for earlystopping.", "labels": [], "entities": [{"text": "TD test set", "start_pos": 29, "end_pos": 40, "type": "DATASET", "confidence": 0.8483150204022726}]}, {"text": "For each domain we use the best combination of word embeddings and distant-phase from Section 3.1 as base model (see).", "labels": [], "entities": []}, {"text": "In: Shows for each domain the best combination of word embeddings and distant phase.", "labels": [], "entities": []}, {"text": "The generalization power of a specialized systems is poor.", "labels": [], "entities": []}, {"text": "As expected the best score is achieved by training and testing on the same domain.", "labels": [], "entities": []}, {"text": "However there is a large deterioration in score when the system is tested on another domain than it is trained on.", "labels": [], "entities": [{"text": "score", "start_pos": 42, "end_pos": 47, "type": "METRIC", "confidence": 0.9837035536766052}]}, {"text": "The average score achieved by a specialized FD system on the TD is far below the scores achieved fora specialized TD system.", "labels": [], "entities": [{"text": "TD", "start_pos": 61, "end_pos": 63, "type": "DATASET", "confidence": 0.9171652793884277}]}, {"text": "The differences range from 15 (JCR) up to 30 (DAI and DIL) points in F1 score.: Gives an overview of the averaged scores.", "labels": [], "entities": [{"text": "DAI", "start_pos": 46, "end_pos": 49, "type": "METRIC", "confidence": 0.8021440505981445}, {"text": "DIL", "start_pos": 54, "end_pos": 57, "type": "METRIC", "confidence": 0.6902238726615906}, {"text": "F1 score.", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9841210544109344}]}, {"text": "In Panel A the average score for each dataset is shown.", "labels": [], "entities": []}, {"text": "Panel B shows the average scores achieve by each embedding type.", "labels": [], "entities": []}, {"text": "Panel C shows the average scores for the distant supervised phases.", "labels": [], "entities": []}, {"text": "shows the difference between the best score of TD and FD Avg.", "labels": [], "entities": [{"text": "TD", "start_pos": 47, "end_pos": 49, "type": "METRIC", "confidence": 0.9472527503967285}, {"text": "FD Avg", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.7449229657649994}]}, {"text": "To further assess the generalization performance we ran ablation experiments as follows: We combine all the training sets except for the target domain set, train the system on this combination of data, and then evaluate the system on the target domain.", "labels": [], "entities": []}, {"text": "The generalized FD system performs better than a specialized FD system.", "labels": [], "entities": [{"text": "FD", "start_pos": 16, "end_pos": 18, "type": "TASK", "confidence": 0.7553486824035645}]}, {"text": "shows the performance of the system trained on the combination of FD data excluding the TD.", "labels": [], "entities": [{"text": "FD data", "start_pos": 66, "end_pos": 73, "type": "DATASET", "confidence": 0.7380412667989731}]}, {"text": "The results show that inmost cases training on a mixture of FD data achieves better scores on the TD data than training using a single FD for training (see).", "labels": [], "entities": [{"text": "FD data", "start_pos": 60, "end_pos": 67, "type": "DATASET", "confidence": 0.7092602699995041}]}, {"text": "As expected the general FD system is usually notable to achieve the score on the TD data achieved by the specialized TD system.", "labels": [], "entities": [{"text": "FD", "start_pos": 24, "end_pos": 26, "type": "METRIC", "confidence": 0.639215350151062}, {"text": "TD data", "start_pos": 81, "end_pos": 88, "type": "DATASET", "confidence": 0.7272076308727264}]}, {"text": "shows the difference between the specialized TD system and the generalized FD system.", "labels": [], "entities": []}, {"text": "The differences range from 3 points in the case the DILreviews up to 17 points for the MPQ-news.", "labels": [], "entities": [{"text": "DILreviews", "start_pos": 52, "end_pos": 62, "type": "DATASET", "confidence": 0.9059640169143677}, {"text": "MPQ-news", "start_pos": 87, "end_pos": 95, "type": "DATASET", "confidence": 0.9795560836791992}]}, {"text": "Only for the JCR-quotations the generalized FD system performs better.", "labels": [], "entities": [{"text": "JCR-quotations", "start_pos": 13, "end_pos": 27, "type": "DATASET", "confidence": 0.8750435709953308}, {"text": "FD", "start_pos": 44, "end_pos": 46, "type": "METRIC", "confidence": 0.5950814485549927}]}, {"text": "Thus, it is best to have TD data, although in some cases an acceptable score might be achieved using a generalized FD system.: Results of the ablation experiments.", "labels": [], "entities": [{"text": "TD", "start_pos": 25, "end_pos": 27, "type": "METRIC", "confidence": 0.986167848110199}, {"text": "FD", "start_pos": 115, "end_pos": 117, "type": "METRIC", "confidence": 0.9703598022460938}]}, {"text": "The last column shows the difference between the specific TD system and the Ablation System trained on a mix of FD data excluding data from the TD.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.7994100451469421}, {"text": "FD data", "start_pos": 112, "end_pos": 119, "type": "DATASET", "confidence": 0.7586625516414642}]}, {"text": "To further investigate the difference between a specialized system and a general system we performed experiments where we start with a specialized TD, specialized FD, or a general FD system (referred to as base system) and gradually transform it to a generalized system by adding data.", "labels": [], "entities": []}, {"text": "Let n be the number of texts used to train the base system.", "labels": [], "entities": []}, {"text": "Then we augment the training set by adding n/2, n and 2n datapoints.", "labels": [], "entities": []}, {"text": "The evaluation is always performed on the TD.", "labels": [], "entities": []}, {"text": "Adding FD to a specialized TD system decreases the performance on the target domain.", "labels": [], "entities": []}, {"text": "For each of the 8 TDs we start with a specialized TD system and gradually add a combination of FD data (mixed FD augmentation) or data from a single FD (single FD augmentation) and evaluate the performance on TD.", "labels": [], "entities": [{"text": "FD", "start_pos": 95, "end_pos": 97, "type": "METRIC", "confidence": 0.8279242515563965}]}, {"text": "shows the scores averaged overall experiments for each TD.", "labels": [], "entities": []}, {"text": "The trend shows that adding more data from one or more FDs for training decreases the performance of the system.", "labels": [], "entities": []}, {"text": "Adding TD to a FD system increases the score.", "labels": [], "entities": [{"text": "TD", "start_pos": 7, "end_pos": 9, "type": "METRIC", "confidence": 0.9897729754447937}, {"text": "FD", "start_pos": 15, "end_pos": 17, "type": "METRIC", "confidence": 0.9241458773612976}]}, {"text": "For each TD we start with a specialized FD system (single FD base) or a generalized FD system (mix FD base) and gradually add more data from the TD.", "labels": [], "entities": []}, {"text": "In both cases adding more data from the TD increases the performance of the system when it is evaluated on the TD (see).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Overview of the hyper-parameters chosen  for the CNN. Note that we define a layer as one  convolutional layer followed by one pooling-layer.  For the second pooling layer the length is chosen  over the whole feature.", "labels": [], "entities": []}, {"text": " Table 2: Data used for training the CNN model.", "labels": [], "entities": []}, {"text": " Table 5.B) is up  to 6 points worse than the best score for the partic- ular domain. Thus, pre-trained word embeddings  do not imply an increase in score.", "labels": [], "entities": []}, {"text": " Table 3: Overview of the percentage of missing  vocabulary in the word embeddings.", "labels": [], "entities": []}, {"text": " Table 4: Shows the score for each combination of word embeddings, distant-phase corpus, and domain.  The last row shows the average score achieved on a particular dataset. The scores in bold denote the  best score achieved on the dataset. For each domain we denote the text-type as follows: T: Tweets, N:  News, R: Reviews, H: Headlines and Q: Quotations. Alongside with the text-type we also note the size  of the corpus.", "labels": [], "entities": []}, {"text": " Table 5: Gives an overview of the averaged scores. In Panel A the average score for each dataset is  shown. Panel B shows the average scores achieve by each embedding type. Panel C shows the average  scores for the distant supervised phases.", "labels": [], "entities": []}, {"text": " Table 8: Results obtained by training on a target domain (TD) and evaluation on all domains. The line  FD Avg. shows the average scores for each TD when trained on a foreign domain (FD). The line Diff.", "labels": [], "entities": [{"text": "FD Avg.", "start_pos": 104, "end_pos": 111, "type": "METRIC", "confidence": 0.8431359132130941}, {"text": "line Diff.", "start_pos": 192, "end_pos": 202, "type": "DATASET", "confidence": 0.6981979608535767}]}, {"text": " Table 9: Results of the ablation experiments. The  last column shows the difference between the spe- cific TD system and the Ablation System trained  on a mix of FD data excluding data from the TD.", "labels": [], "entities": [{"text": "FD data", "start_pos": 163, "end_pos": 170, "type": "DATASET", "confidence": 0.7549241483211517}]}]}