{"title": [{"text": "A case study on using speech-to-translation alignments for language documentation", "labels": [], "entities": []}], "abstractContent": [{"text": "For many low-resource or endangered languages , spoken language resources are more likely to be annotated with translations than with transcriptions.", "labels": [], "entities": []}, {"text": "Recent work exploits such annotations to produce speech-to-translation alignments, without access to any text transcriptions.", "labels": [], "entities": [{"text": "speech-to-translation alignments", "start_pos": 49, "end_pos": 81, "type": "TASK", "confidence": 0.6493912637233734}]}, {"text": "We investigate whether providing such information can aid in producing better (mismatched) crowdsourced transcriptions, which in turn could be valuable for training speech recognition systems, and show that they can indeed be beneficial through a small-scale case study as a proof-of-concept.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 165, "end_pos": 183, "type": "TASK", "confidence": 0.7263458669185638}]}, {"text": "We also present a simple phonetically aware string averaging technique that produces transcriptions of higher quality.", "labels": [], "entities": [{"text": "phonetically aware string averaging", "start_pos": 25, "end_pos": 60, "type": "TASK", "confidence": 0.6116887778043747}]}], "introductionContent": [{"text": "For many low-resource and endangered languages, speech data is easier to obtain than textual data.", "labels": [], "entities": []}, {"text": "The traditional method for documenting a language involves a trained linguist collecting speech and then transcribing it, often at a phonetic level, as most of these languages do not have a writing system.", "labels": [], "entities": []}, {"text": "This, however, is a costly and slow process, as it could take up to 1 hour fora trained linguist to transcribe the phonemes of 1 minute of speech (Thi-Ngoc-Diep.", "labels": [], "entities": []}, {"text": "Therefore, speech is more likely to be annotated with translations than with transcriptions.", "labels": [], "entities": []}, {"text": "This translated speech is a potentially valuable source of information as it will make the collected corpus interpretable for future studies.", "labels": [], "entities": []}, {"text": "New technologies are being developed to facilitate collection of translations (, and there already exist recent examples of parallel speech collection efforts focused on endangered languages ( ).", "labels": [], "entities": [{"text": "collection of translations", "start_pos": 51, "end_pos": 77, "type": "TASK", "confidence": 0.8822619120279948}]}, {"text": "Recent work relies on parallel speech in order to create speech-to-translation alignments, discover spoken terms (, learn a lexicon and translation model (, or directly translate speech (.", "labels": [], "entities": []}, {"text": "Another line of work () focuses on training speech recognition systems for low-resource settings using mismatched crowdsoursed transcriptions.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 44, "end_pos": 62, "type": "TASK", "confidence": 0.714701771736145}]}, {"text": "These are transcriptions that include some level of noise, as they are crowdsourced from workers unfamiliar with the language being spoken.", "labels": [], "entities": []}, {"text": "We aim to explore whether the quality of crowdsourced transcriptions could benefit from providing transcribers with speech-to-translation wordlevel alignments.", "labels": [], "entities": []}, {"text": "That way, speech recognition systems trained on the higher-quality probabilistic transcriptions (of at least a sample of the collected data) could be used as part of the pipeline to document an endangered language.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.7084144800901413}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Transcriptions for the utterance o  l` adr\u00f2 \u0131soz\u00e8 embi apo-tt\u00f9 [the thief  must have entered from here] and their Leven- shtein distance to the gold transcription. The  word ladro [thief] is the same in both Griko and  Italian.", "labels": [], "entities": [{"text": "Leven- shtein distance", "start_pos": 124, "end_pos": 146, "type": "METRIC", "confidence": 0.7005114257335663}]}, {"text": " Table 4: Phone Error Rate (PER) of the phonetic  transcriptions produced by the Italian-speaking  participants per utterance set. In the general case,  the quality improves when alignments are pro- vided, as shown by the averages in the last row.", "labels": [], "entities": [{"text": "Phone Error Rate (PER)", "start_pos": 10, "end_pos": 32, "type": "METRIC", "confidence": 0.8773055473963419}]}, {"text": " Table 5: Breakdown of the quality of the transcrip- tions per participant group. As expected, the group  of participants that speak the language closest to  the target language (Italian) produces better tran- scriptions.", "labels": [], "entities": [{"text": "Breakdown", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9467850923538208}]}, {"text": " Table 6: Average Levenshtein distance and PER  of the \"average\" transcriptions obtained with our  string averaging method for different subsets of  the crowdsourced transcriptions. The \"average\"  transcriptions have higher quality than the origi- nal ones, especially when obtained from transcrip- tions of participants familiar with languages close  to the target language. Providing alignments also  improves the resulting \"average\" transcription.", "labels": [], "entities": [{"text": "Levenshtein distance", "start_pos": 18, "end_pos": 38, "type": "METRIC", "confidence": 0.7377005517482758}, {"text": "PER", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.9988598823547363}]}]}