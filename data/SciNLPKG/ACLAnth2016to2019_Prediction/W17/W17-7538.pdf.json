{"title": [{"text": "Experiments with Domain Dependent Dialogue Act Classification using Open-Domain Dialogue Corpora", "labels": [], "entities": [{"text": "Domain Dependent Dialogue Act Classification", "start_pos": 17, "end_pos": 61, "type": "TASK", "confidence": 0.7041839182376861}]}], "abstractContent": [{"text": "Dialogue Act (DA) classification plays a major role in the interpretation of an utterance in a dialogue and hence in the development of a dialogue agent.", "labels": [], "entities": [{"text": "Dialogue Act (DA) classification", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.576323797305425}, {"text": "interpretation of an utterance in a dialogue", "start_pos": 59, "end_pos": 103, "type": "TASK", "confidence": 0.8118419306618827}]}, {"text": "Learning a DA classifier requires large corpora of annotated dialogues which require extensive human efforts and cost.", "labels": [], "entities": [{"text": "DA classifier", "start_pos": 11, "end_pos": 24, "type": "TASK", "confidence": 0.8472054600715637}]}, {"text": "Additionally, nature of dialogue varies based on domain (e.g. tourism, healthcare, finance) as well as the nature of dialogues (e.g. dialogues that involve only queries and responses or dialogues that involve planning or recommendation).", "labels": [], "entities": []}, {"text": "Hence, DA classifier trained on a particular corpus may not perform as per the expectations on another domain-dependent or task-dependent dialogues.", "labels": [], "entities": []}, {"text": "In this paper, we propose Conditional Random Field (CRF) based DA classifier, which we train on an open-domain corpus and extend it fora domain-dependent corpus by enabling a domain expert to incorporate her domain knowledge in the form of simple rules.", "labels": [], "entities": [{"text": "DA classifier", "start_pos": 63, "end_pos": 76, "type": "TASK", "confidence": 0.6606243550777435}]}, {"text": "Hence, our approach does not need domain-dependent labeled corpora.", "labels": [], "entities": []}, {"text": "We show the effectiveness of our proposed approach on two real-world datasets.", "labels": [], "entities": []}], "introductionContent": [{"text": "Dialogues are an integral part of human interactions, and of arts such as literature, theatre, and films.", "labels": [], "entities": []}, {"text": "The presence of discernible common structures in dialogues, despite endless manifestations, has fascinated linguists and artists for ages.", "labels": [], "entities": []}, {"text": "With the advent of virtual assistants (chatbots or dialogue agents), there is keen interest in building systems that are capable of having natural and meaningful dialogues with a human user.", "labels": [], "entities": []}, {"text": "Dialogues also occur in other major applications, including emails), chats, and web forums (like Wikipedia discussions, students discussion forums (), comments sections in newspapers, and in community QA systems) like StackOverflow.com.", "labels": [], "entities": []}, {"text": "The theory of dialogue acts provides an important building block in efforts to understand and model structure, function, and flow in dialogues.", "labels": [], "entities": []}, {"text": "A dialogue act (DA) represents an abstract category of the essential meaning of an utterance (often a sentence or a fragment) in the context of an ongoing dialogue.", "labels": [], "entities": [{"text": "dialogue act (DA) represents an abstract category of the essential meaning of an utterance (often a sentence or a fragment) in the context of an ongoing dialogue", "start_pos": 2, "end_pos": 163, "type": "Description", "confidence": 0.8037346380372201}]}, {"text": "The meaning here usually refers to the agent's intention, the role and relationship of the utterance to the overall dialogue, etc.", "labels": [], "entities": []}, {"text": "The context of an utterance includes the dialogue state, the mental state, beliefs, and agenda of the human user, and in general, any information contained in previous utterances in the dialogue.", "labels": [], "entities": []}, {"text": "There is a well-accepted set of 43 DAs for English (), which have been used to annotate several dialogue corpora; e.g., the human-human telephone English speech Switchboard corpus, Berkeley ICSI Meeting Recorder Digits corpus, etc.", "labels": [], "entities": [{"text": "Berkeley ICSI Meeting Recorder Digits corpus", "start_pos": 181, "end_pos": 225, "type": "DATASET", "confidence": 0.8695616722106934}]}, {"text": "Labeling of the DAs to various utterances in a dialogue bring to the fore various relationships among the utterances.", "labels": [], "entities": [{"text": "Labeling of the DAs", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8050244748592377}]}, {"text": "For instance, if an utterance is tagged with the DA YES-NO-QUESTION then it is likely that the next utterance will have the DA of either YES-ANSWER, NO-ANSWER, NON-UNDERSTANDING or perhaps OTHER-ANSWER like \"I don't know\".", "labels": [], "entities": [{"text": "DA YES-NO-QUESTION", "start_pos": 49, "end_pos": 67, "type": "METRIC", "confidence": 0.7472422420978546}, {"text": "DA", "start_pos": 124, "end_pos": 126, "type": "METRIC", "confidence": 0.9957482218742371}, {"text": "YES-ANSWER", "start_pos": 137, "end_pos": 147, "type": "METRIC", "confidence": 0.96811443567276}, {"text": "NO-ANSWER", "start_pos": 149, "end_pos": 158, "type": "METRIC", "confidence": 0.8711514472961426}, {"text": "NON-UNDERSTANDING", "start_pos": 160, "end_pos": 177, "type": "METRIC", "confidence": 0.834104061126709}, {"text": "OTHER-ANSWER", "start_pos": 189, "end_pos": 201, "type": "METRIC", "confidence": 0.9803589582443237}]}, {"text": "These annotated dialogue corpora have been used to build classifiers that automatically identify the DA for any given utterance as part of a given dialogue.", "labels": [], "entities": []}, {"text": "DA classification is useful in applications where a computer system is one of the participants in the dialogues; examples: customer help-desk (), 305 tutoring systems (), speech recognition, etc.", "labels": [], "entities": [{"text": "DA classification", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9516165852546692}, {"text": "speech recognition", "start_pos": 171, "end_pos": 189, "type": "TASK", "confidence": 0.8536038994789124}]}, {"text": "But it is also used in other applications such as machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 50, "end_pos": 69, "type": "TASK", "confidence": 0.840177983045578}]}, {"text": "Various machine learning techniques have been used to build classifiers for DA, including HMM (), Bayesian Networks, logistic regression), language models, multi-layer perceptrons, Conditional Random Field (CRF)) etc.", "labels": [], "entities": []}, {"text": "Recently, several authors have explored deep learning based methods for DA classification (e.g. ().", "labels": [], "entities": [{"text": "DA classification", "start_pos": 72, "end_pos": 89, "type": "TASK", "confidence": 0.9872250854969025}]}, {"text": "An important limitation of these classification approaches is they need a large annotated corpus.", "labels": [], "entities": []}, {"text": "More often, they are evaluated on the same domain on which they are trained.", "labels": [], "entities": []}, {"text": "Recently there is increasing trend of building domain specific chat-bots (e.g. domains like Insurance, Finance, Healthcare, IT services helpdesks, Tourism, etc.).", "labels": [], "entities": []}, {"text": "It is important to note that conversations in different domains have different characteristics.", "labels": [], "entities": []}, {"text": "For example, conversations recorded in IT services help-desks are frequently occurring queries (questions) and their responses, while conversations recorded in Tourism help-desk may involve planning of a tour, purchase of insurance in insurance domain, or recommendation of a product are likely to involve long, and detailed conversations.", "labels": [], "entities": [{"text": "Tourism help-desk", "start_pos": 160, "end_pos": 177, "type": "DATASET", "confidence": 0.8697245717048645}]}, {"text": "Additionally, some words have a domaindependent sense, for example, the word \"escalation\" is used as a synonym to \"complaint\" in IT services help-desks.", "labels": [], "entities": []}, {"text": "Hence, we hypothesize that a DA classifier trained on an open-domain corpus may not capture characteristics of conversations for different domains and hence, its performance may not be optimal.", "labels": [], "entities": [{"text": "DA classifier", "start_pos": 29, "end_pos": 42, "type": "TASK", "confidence": 0.8234609067440033}]}, {"text": "One way to overcome this problem is to build domain-dependent DA classifiers.", "labels": [], "entities": []}, {"text": "However, the creation of such classifiers requires huge cost and human efforts.", "labels": [], "entities": []}, {"text": "Hence it is important from the practical point of view to build a DA classifier that requires minimum cost and human efforts, at the same time it can be used across multiple domains.", "labels": [], "entities": [{"text": "DA classifier", "start_pos": 66, "end_pos": 79, "type": "TASK", "confidence": 0.8820757567882538}]}, {"text": "In this paper, we propose a CRF based DA classifier that uses a richer set of features which incorporate lexical, syntactic and semantic information as well as dialogue history.", "labels": [], "entities": [{"text": "DA classifier", "start_pos": 38, "end_pos": 51, "type": "TASK", "confidence": 0.7706895768642426}]}, {"text": "Initially, we learn a DA classifier on an open-domain corpus and then allow a domain expert to incorporate her domain knowledge in the form of simple rules.", "labels": [], "entities": [{"text": "DA classifier", "start_pos": 22, "end_pos": 35, "type": "TASK", "confidence": 0.8296228349208832}]}, {"text": "In our approach, we combine both statistical learning and domain knowledge to build a domain-dependent DA classifier.", "labels": [], "entities": []}, {"text": "The paper is organized as follows: In Section 2, we propose our CRF and cue based approach for DA classification.", "labels": [], "entities": [{"text": "DA classification", "start_pos": 95, "end_pos": 112, "type": "TASK", "confidence": 0.9795138537883759}]}, {"text": "Section 3 discusses evaluation of our proposed DA classifier with respect to a Deep Recurrent Neural Network (RNN) based DA classifier proposed by.", "labels": [], "entities": []}, {"text": "In Section 4 we conclude and discuss future prospects of our work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the performance of our algorithm with Recurrent Neural Network based dialogue act classifier proposed in ().", "labels": [], "entities": []}, {"text": "Training datasets: \u2022 DSTC2: The Dialog State Tracking Challenge-2 dataset is a conversational dataset of an automated restaurant assistance system and its users, having a total of 2118 different conversations and a total of 19 different user goals which are mapped to 19 different dialogue acts based on similarity of meaning.", "labels": [], "entities": [{"text": "Dialog State Tracking Challenge-2", "start_pos": 32, "end_pos": 65, "type": "TASK", "confidence": 0.6704365685582161}]}, {"text": "\u2022 DSTC2: we used DSTC2 for both training and testing as it is a domain specific dataset.", "labels": [], "entities": [{"text": "DSTC2", "start_pos": 2, "end_pos": 7, "type": "DATASET", "confidence": 0.9034877419471741}, {"text": "DSTC2", "start_pos": 17, "end_pos": 22, "type": "DATASET", "confidence": 0.9354996085166931}]}, {"text": "\u2022 We used the SwDA and DSTC2 dataset to train RN N DA based model with LSTM layers as described by).", "labels": [], "entities": [{"text": "DSTC2 dataset", "start_pos": 23, "end_pos": 36, "type": "DATASET", "confidence": 0.9519305527210236}]}, {"text": "All conversations in the training set were preprocessed, and a randomized selection of one-third of them was utilized as a development set to allow the LSTM parameters to be trained over a reasonable number As both SwDA and DSTC2 datasets are conversational datasets we trained CRF DA model for sequence labeling of dialogue acts.", "labels": [], "entities": [{"text": "DSTC2 datasets", "start_pos": 224, "end_pos": 238, "type": "DATASET", "confidence": 0.9308150708675385}, {"text": "sequence labeling of dialogue acts", "start_pos": 295, "end_pos": 329, "type": "TASK", "confidence": 0.7822340369224549}]}, {"text": "We used CRF implementation from MALLET 3 for training the model.", "labels": [], "entities": []}], "tableCaptions": []}