{"title": [{"text": "CUNI NMT System for WAT 2017 Translation Tasks", "labels": [], "entities": [{"text": "CUNI NMT", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.6980884373188019}, {"text": "WAT 2017 Translation Tasks", "start_pos": 20, "end_pos": 46, "type": "TASK", "confidence": 0.896110013127327}]}], "abstractContent": [{"text": "The paper presents this year's CUNI submissions to the WAT 2017 Translation Task focusing on the Japanese-English translation, namely Scientific papers sub-task, Patents subtask and Newswire sub-task.", "labels": [], "entities": [{"text": "WAT 2017 Translation Task", "start_pos": 55, "end_pos": 80, "type": "TASK", "confidence": 0.7559541761875153}, {"text": "Japanese-English translation", "start_pos": 97, "end_pos": 125, "type": "TASK", "confidence": 0.6179419904947281}]}, {"text": "We compare two neural network architectures, the standard sequence-to-sequence with attention (Seq2Seq) (Bah-danau et al., 2014) and an architecture using convolutional sentence encoder (FB-Conv2Seq) described by Gehring et al.", "labels": [], "entities": []}, {"text": "(2017), both implemented in the NMT framework Neural Monkey 1 that we currently participate in developing.", "labels": [], "entities": [{"text": "NMT framework Neural Monkey 1", "start_pos": 32, "end_pos": 61, "type": "DATASET", "confidence": 0.8563411593437195}]}, {"text": "We also compare various types of preprocessing of the source Japanese sentences and their impact on the overall results.", "labels": [], "entities": []}, {"text": "Furthermore, we include the results of our experiments with out-of-domain data obtained by combining the corpora provided for each sub-task.", "labels": [], "entities": []}], "introductionContent": [{"text": "With neural machine translation (NMT) currently becoming the leading paradigm in the field of machine translation, many novel NMT architectures with state-of-the-art results are being proposed.", "labels": [], "entities": [{"text": "neural machine translation (NMT)", "start_pos": 5, "end_pos": 37, "type": "TASK", "confidence": 0.8549241324265798}, {"text": "machine translation", "start_pos": 94, "end_pos": 113, "type": "TASK", "confidence": 0.7774150967597961}]}, {"text": "In the past, there were reports on large scale evaluation (, however, the experiments were performed on a limited number of language pairs from related language families (English\u2192German, English\u2192French) or focused on a subset of possible NMT architectures, leaving room for further exploration.", "labels": [], "entities": []}, {"text": "One of the downsides of NMT is the limited allowable size of both input and output vocabularies.", "labels": [], "entities": [{"text": "NMT", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.7614758014678955}]}, {"text": "Various solutions for dealing with potential http://ufal.mff.cuni.cz/neuralmonkey out-of-vocabulary (OOV) tokens were proposed either by using a back-off dictionary look-up (, character-level translation of unknown words or recently quite popular translation via subword units generated by byte pair encoding ().", "labels": [], "entities": [{"text": "character-level translation of unknown words", "start_pos": 176, "end_pos": 220, "type": "TASK", "confidence": 0.7703398048877717}]}, {"text": "However, in the case of Japanese which has no clear definition of a word unit, there has been less research on how a particular preprocessing can influence the overall NMT performance.", "labels": [], "entities": []}, {"text": "In this system description paper we compare two sequence-to-sequence architectures, one using a recurrent encoder and one using a convolutional encoder.", "labels": [], "entities": []}, {"text": "We also report results of our experiments with preprocessing of Japanese.", "labels": [], "entities": []}, {"text": "Furthermore, we report how including additional out-ofdomain training data influence the performance of NMT.", "labels": [], "entities": [{"text": "NMT", "start_pos": 104, "end_pos": 107, "type": "TASK", "confidence": 0.7814375162124634}]}], "datasetContent": [{"text": "In this section we describe the methods we used for preprocessing both Japanese and English.", "labels": [], "entities": []}, {"text": "Due to Japanese being an unsegmented language with no clear definition of word boundaries, proper text segmentation is essential.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 98, "end_pos": 115, "type": "TASK", "confidence": 0.7346230745315552}]}, {"text": "We used MeCab 2 () with the UniDic 3 dictionary to perform the tokenization.", "labels": [], "entities": []}, {"text": "For English, we used morphological analyser MorphoDiTa) to tokenize English training sentences.", "labels": [], "entities": [{"text": "tokenize English training sentences", "start_pos": 59, "end_pos": 94, "type": "TASK", "confidence": 0.877681165933609}]}, {"text": "Based on the generated lemmas, we also performed truecasing of the target side of the training data.", "labels": [], "entities": []}, {"text": "To reduce the vocabulary size, we use byte pair encoding (BPE;) which breaks all words into subword units.", "labels": [], "entities": []}, {"text": "The vocabulary is initialized with all alphabet characters present in the training data and larger units are added on the basis of corpus statistics.", "labels": [], "entities": []}, {"text": "Frequent words make it to the vocabulary, less frequent words are (deterministically) broken into smaller units from the vocabulary.", "labels": [], "entities": []}, {"text": "We generated separate BPE merges for each dataset, both source and target side.", "labels": [], "entities": []}, {"text": "Because the BPE algorithm, when generating the vocabulary, performs its own (subword) segmentation, we decided to compare a system trained on the tokenized Japanese (which was then further segmented by BPE) with a system that was segmented only via BPE.", "labels": [], "entities": [{"text": "BPE", "start_pos": 249, "end_pos": 252, "type": "DATASET", "confidence": 0.8519322276115417}]}, {"text": "Additionally, we also performed a comparison with a system with Japanese text transcribed in Latin alphabet.", "labels": [], "entities": []}, {"text": "The romanization was done by generating Hiragana transcription of each token using MeCab and then transcribing these tokens to Romaji using jaconv.", "labels": [], "entities": [{"text": "MeCab", "start_pos": 83, "end_pos": 88, "type": "DATASET", "confidence": 0.9593542814254761}, {"text": "Romaji", "start_pos": 127, "end_pos": 133, "type": "DATASET", "confidence": 0.9528086185455322}]}, {"text": "The resulting text was then also further segmented by BPE.", "labels": [], "entities": [{"text": "BPE", "start_pos": 54, "end_pos": 57, "type": "DATASET", "confidence": 0.9249222278594971}]}, {"text": "The results are discussed in Section 4.1  In this section we describe all experiments we conducted for the WAT 2017 Translation Task.", "labels": [], "entities": [{"text": "WAT 2017 Translation Task", "start_pos": 107, "end_pos": 132, "type": "TASK", "confidence": 0.8946658670902252}]}, {"text": "We report results over the development set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison of various tokenization  methods measured on the ASPEC dataset.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 32, "end_pos": 44, "type": "TASK", "confidence": 0.9674468636512756}, {"text": "ASPEC dataset", "start_pos": 70, "end_pos": 83, "type": "DATASET", "confidence": 0.8902287185192108}]}]}