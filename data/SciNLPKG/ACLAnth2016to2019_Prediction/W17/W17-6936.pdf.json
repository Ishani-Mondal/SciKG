{"title": [{"text": "Skip-Prop: Representing Sentences with One Vector Per Proposition", "labels": [], "entities": [{"text": "Skip-Prop", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9023925065994263}, {"text": "Representing Sentences", "start_pos": 11, "end_pos": 33, "type": "TASK", "confidence": 0.8448257446289062}]}], "abstractContent": [{"text": "We introduce the notion of a multi-vector sentence representation based on a \"one vector per proposition\" philosophy, which we term skip-prop vectors.", "labels": [], "entities": []}, {"text": "By representing each predicate-argument structure in a complex sentence as an individual vector, skip-prop is (1) a response to empirical evidence that single-vector sentence representations degrade with sentence length, and (2) a representation that maintains a semantically useful level of granularity.", "labels": [], "entities": []}, {"text": "We demonstrate the feasibility of training skip-prop vectors, introducing a method adapted from skip-thought vectors, and compare skip-prop with \"one vector per sentence\" and \"one vector per token\" approaches.", "labels": [], "entities": []}], "introductionContent": [{"text": "The length and complexity of written natural language sentences is highly variable.", "labels": [], "entities": []}, {"text": "Sentences from New York Times (NYT) stories, for example, contain on average 23 tokens, with a standard deviation of 12.", "labels": [], "entities": [{"text": "Sentences from New York Times (NYT) stories", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.7407253185907999}]}, {"text": "By information-theoretic measures, too, natural language sentences convey differing amounts of information).", "labels": [], "entities": []}, {"text": "It is natural to suppose, then, that methods in computational linguistics that aim to learn fixed-size semantic representations of sentences, i.e., with vectors of fixed dimension, maybe limited in their expressiveness or efficiency.", "labels": [], "entities": []}, {"text": "Indeed, on many NLP tasks for which neural sentence embedding methods have been adapted, degraded performance on longer input sentences is commonly observed: in machine translation (), question-answering (, and semantic role labeling (, for example.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 161, "end_pos": 180, "type": "TASK", "confidence": 0.7594455182552338}, {"text": "semantic role labeling", "start_pos": 211, "end_pos": 233, "type": "TASK", "confidence": 0.6579958995183309}]}, {"text": "Motivated by these observations, we introduce skip-prop vectors, a method for learning multi-vector sentence representations following a \"one vector per proposition\" strategy.", "labels": [], "entities": []}, {"text": "Our approach is based on the skip-thought method of, which combines neural sequence-to-sequence models) with a skip-gram-like training objective () to obtain generalpurpose sentence representations as a fixed-size vector.", "labels": [], "entities": []}, {"text": "Skip-prop capitalizes on the idea that a complex sentence maybe represented in terms of the simpler sentences, or propositions, that constitute it.", "labels": [], "entities": []}], "datasetContent": [{"text": "Data All training, development, and test data consist of articles from the NYT portion of the Concretely Annotated Gigaword corpus labeled \"story\").", "labels": [], "entities": [{"text": "NYT portion of the Concretely Annotated Gigaword corpus", "start_pos": 75, "end_pos": 130, "type": "DATASET", "confidence": 0.6766852401196957}]}, {"text": "Train is 100K random sentence triples from Aug. 1997 NYT stories; development is 5K random sentence triples from Sept. 1997; and testis 5K random sentence triples from Oct. 1997. The vocabulary is approximately 39K tokens from Sept. 1997 NYT with minimum frequency of 15.", "labels": [], "entities": [{"text": "NYT stories", "start_pos": 53, "end_pos": 64, "type": "DATASET", "confidence": 0.8726957142353058}, {"text": "NYT", "start_pos": 238, "end_pos": 241, "type": "DATASET", "confidence": 0.8605914115905762}]}, {"text": "Each model is trained for one epoch on the entire train set using mini-batches of size 1.", "labels": [], "entities": []}, {"text": "As described in \u00a74, a sentence triple (s l , s c , s r ) consists of a contiguous set of three sentences from a news story: a \"left,\" \"center,\" and \"right\" sentence.", "labels": [], "entities": []}, {"text": "For the qualitative nearest-neighbor experiments, two datasets are used: (1) a 100K superset of the NYT development set (Sept. 1997), and (2) all sentences from the SICK corpus ().", "labels": [], "entities": [{"text": "NYT development set (Sept. 1997)", "start_pos": 100, "end_pos": 132, "type": "DATASET", "confidence": 0.9271255135536194}, {"text": "SICK corpus", "start_pos": 165, "end_pos": 176, "type": "DATASET", "confidence": 0.7636713683605194}]}, {"text": "Results As a preliminary evaluation of skip-prop vectors, we present both quantitative and qualitative results.", "labels": [], "entities": []}, {"text": "These results show that (1) it is feasible to train skip-prop vectors with our proposed method, and (2) some notion of semantic similarity over propositions is preserved in this representation.", "labels": [], "entities": []}, {"text": "shows the perplexity attained by each model.", "labels": [], "entities": []}, {"text": "Here, perplexity is computed either from the two decoders' predictions of the left and right context sentences (skip-thought objective), or one decoder's prediction of the original sentence (autoencoder objective).", "labels": [], "entities": []}, {"text": "In all cases, the skip-prop models score in between skip-thought and skip-thought with attention models.", "labels": [], "entities": []}, {"text": "This is not surprising: the skipprop decoder has, on average, access to more vectors than the skip-thought decoder, but fewer than the skip-thought with attention decoder.", "labels": [], "entities": []}, {"text": "(See) This kind of result supports the plausibility of skip-prop vectors as a sentence representation that successfully trades off between the size and cost of one-vector-per-sentence strategies (ST) and one-vector-per-token strategies (STA).", "labels": [], "entities": []}, {"text": "shows the qualitative results of a nearest neighbor search for both skip-thought and skip-prop vectors.", "labels": [], "entities": []}, {"text": "We use both in-domain and out-of-domain data: 100K sentences from our NYT development set, and about 40K sentences from the SICK corpus ().", "labels": [], "entities": [{"text": "NYT development set", "start_pos": 70, "end_pos": 89, "type": "DATASET", "confidence": 0.9578160246213278}, {"text": "SICK corpus", "start_pos": 124, "end_pos": 135, "type": "DATASET", "confidence": 0.8426845073699951}]}, {"text": "Both query sentences area random sentence from NYT or SICK with a correct predicate-argument analysis.", "labels": [], "entities": [{"text": "NYT", "start_pos": 47, "end_pos": 50, "type": "DATASET", "confidence": 0.9184263944625854}]}, {"text": "The corresponding query propositions are each an extracted proposition from the query sentence.", "labels": [], "entities": []}, {"text": "The results in suggest that skip-prop vectors provide a useful level of granularity for representing sentence meaning.", "labels": [], "entities": [{"text": "representing sentence meaning", "start_pos": 88, "end_pos": 117, "type": "TASK", "confidence": 0.7726721167564392}]}, {"text": "For example, the NYT query sentence contains multiple salient propositions (?a owns ?b, ?a will jettison ?b, etc.).", "labels": [], "entities": []}, {"text": "While the skip-thought representation must pack all of this information into a single vector, skip-prop vectors allow us to represent each proposition individually.", "labels": [], "entities": []}, {"text": "Accordingly, in the corresponding NYT query proposition, we see that it is possible to isolate a particular proposition of interest (?a owns ?b) and find nearest-neighbors of that proposition, without regard to rest of the sentence's content.", "labels": [], "entities": []}, {"text": "This allows a more targeted search using skip-prop vectors.", "labels": [], "entities": []}, {"text": "Both training objectives, \"skip-thought\" and \"autoencoder\" (-AUTO) are compared.", "labels": [], "entities": [{"text": "autoencoder\" (-AUTO)", "start_pos": 46, "end_pos": 66, "type": "METRIC", "confidence": 0.742657482624054}]}, {"text": "Resulting nearest-neighbor propositions are shown within the full sentence they were extracted from; however, only the proposition's predicate and arguments are represented in its vector.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Average per-token perplexity, both with skip-thought and autoencoder objectives.", "labels": [], "entities": []}]}