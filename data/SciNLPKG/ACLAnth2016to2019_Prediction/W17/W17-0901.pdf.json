{"title": [{"text": "Inducing Script Structure from Crowdsourced Event Descriptions via Semi-Supervised Clustering", "labels": [], "entities": [{"text": "Inducing Script Structure from Crowdsourced Event Descriptions", "start_pos": 0, "end_pos": 62, "type": "TASK", "confidence": 0.8110546214239938}]}], "abstractContent": [{"text": "We present a semi-supervised clustering approach to induce script structure from crowdsourced descriptions of event sequences by grouping event descriptions into paraphrase sets (representing event types) and inducing their temporal order.", "labels": [], "entities": []}, {"text": "Our model exploits semantic and posi-tional similarity and allows for flexible event order, thus overcoming the rigidity of previous approaches.", "labels": [], "entities": []}, {"text": "We incorporate crowdsourced alignments as prior knowledge and show that exploiting a small number of alignments results in a substantial improvement in cluster quality over state-of-the-art models and provides an appropriate basis for the induction of temporal order.", "labels": [], "entities": []}, {"text": "We also show a coverage study to demonstrate the scalability of our approach .", "labels": [], "entities": []}], "introductionContent": [{"text": "During their daily social interactions, people make seamless use of knowledge about standardized event sequences (scripts) describing types of everyday activities, or scenarios, such as GOING TO THE RESTAURANT or BAKING A CAKE (.", "labels": [], "entities": [{"text": "GOING TO THE RESTAURANT", "start_pos": 186, "end_pos": 209, "type": "METRIC", "confidence": 0.7755357623100281}, {"text": "BAKING A CAKE", "start_pos": 213, "end_pos": 226, "type": "METRIC", "confidence": 0.802227775255839}]}, {"text": "Script knowledge is often triggered by the broader discourse context and guides expectations in text understanding and makes missing events and referents in a discourse accessible.", "labels": [], "entities": [{"text": "text understanding", "start_pos": 96, "end_pos": 114, "type": "TASK", "confidence": 0.7117153257131577}]}, {"text": "For example, if we hear someone say \"I baked a cake on Sunday.", "labels": [], "entities": []}, {"text": "I decorated it with buttercream icing!\", our script knowledge allows us to infer that the speaker must have mixed the ingredients, turned on the oven, etc., even if these events are not explicitly mentioned.", "labels": [], "entities": []}, {"text": "Script knowledge is relevant for the computational modeling of various kinds of cognitive abilities and has the potential to support NLP tasks such as anaphora resolution), discourse relation detection, semantic role labeling, temporal order analysis, and applications such as text understanding), information extraction (, question answering (.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 151, "end_pos": 170, "type": "TASK", "confidence": 0.7524691224098206}, {"text": "discourse relation detection", "start_pos": 173, "end_pos": 201, "type": "TASK", "confidence": 0.7027842799822489}, {"text": "semantic role labeling", "start_pos": 203, "end_pos": 225, "type": "TASK", "confidence": 0.6325568755467733}, {"text": "temporal order analysis", "start_pos": 227, "end_pos": 250, "type": "TASK", "confidence": 0.6619283556938171}, {"text": "text understanding", "start_pos": 277, "end_pos": 295, "type": "TASK", "confidence": 0.8370699882507324}, {"text": "information extraction", "start_pos": 298, "end_pos": 320, "type": "TASK", "confidence": 0.8701323866844177}, {"text": "question answering", "start_pos": 324, "end_pos": 342, "type": "TASK", "confidence": 0.8778334856033325}]}, {"text": "Several methods for the automatic acquisition of script knowledge have been proposed.", "labels": [], "entities": [{"text": "automatic acquisition of script knowledge", "start_pos": 24, "end_pos": 65, "type": "TASK", "confidence": 0.7466840982437134}]}, {"text": "Seminal work by provided methods for the unsupervised widecoverage extraction of script knowledge from large text corpora.", "labels": [], "entities": [{"text": "widecoverage extraction of script knowledge from large text corpora", "start_pos": 54, "end_pos": 121, "type": "TASK", "confidence": 0.861761642826928}]}, {"text": "However, texts typically only mention small parts of a script, banking on the reader's ability to infer missing script-related events.", "labels": [], "entities": []}, {"text": "The task is therefore challenging, and the results are quite noisy.", "labels": [], "entities": []}, {"text": "The work presented in this paper follows the approach proposed in (henceforth \"RKP\") who crowdsourced scenario descriptions by asking people how they typically carryout a particular activity.", "labels": [], "entities": []}, {"text": "The collected event sequence descriptions provide generic descriptions of a given scenario (e.g. BAKING A CAKE) in concise telegram style.", "labels": [], "entities": [{"text": "BAKING A CAKE", "start_pos": 97, "end_pos": 110, "type": "METRIC", "confidence": 0.8129259745279948}]}, {"text": "Based on these crowdsourced event sequence descriptions or ESDs, RKP extracted high-quality script knowledge fora variety of different scenarios, in the form of temporal script graphs.", "labels": [], "entities": []}, {"text": "Temporal script graphs are partially ordered structures whose nodes are sets of alternative descriptions denoting the same event type, and whose edges express temporal precedence.", "labels": [], "entities": []}, {"text": "While RKP employ Multiple Sequence Alignment (MSA) (), we use a semisupervised clustering approach for script structure induction.", "labels": [], "entities": [{"text": "Multiple Sequence Alignment (MSA)", "start_pos": 17, "end_pos": 50, "type": "TASK", "confidence": 0.7746309340000153}, {"text": "script structure induction", "start_pos": 103, "end_pos": 129, "type": "TASK", "confidence": 0.7855975230534872}]}, {"text": "The choice of MSA was motivated by the effect of positional information on the detection of scenario-specific paraphrases: event de-: Example ESDs (a) and induced script structure (b) for the BAKING A CAKE scenario from scriptions occurring in similar positions in ESDs tend to denote the same event type.", "labels": [], "entities": []}, {"text": "However, MSA makes far too strong an assumption about the temporal ordering information in the ESDs.", "labels": [], "entities": []}, {"text": "It does not allow for crossing edges and thus must assume a fixed and invariable order, while the ordering of events in a script is to some degree flexible (e.g., one can preheat the oven before or after mixing ingredients).", "labels": [], "entities": []}, {"text": "We propose clustering as an alternative method to overcome the rigidity of the MSA approach, and use a distance measure based on both semantic similarity and positional similarity information, making our clustering algorithm sensitive to ordering information, while allowing for order variation in the scripts.", "labels": [], "entities": []}, {"text": "Clustering accuracy depends on the reliability of similarity estimates, but scenario-specific paraphrase relations are often based on scenariospecific functional equivalence, which cannot be easily determined using semantic similarity, even if complemented with positional information.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.9868283271789551}]}, {"text": "For example in the FLYING IN AN AIRPLANE scenario, it is challenging for any semantic similarity measure to predict that walk up the ramp and board plane refer to the same event, as the broader discourse context would suggest.", "labels": [], "entities": [{"text": "FLYING IN AN AIRPLANE", "start_pos": 19, "end_pos": 40, "type": "METRIC", "confidence": 0.5980307310819626}]}, {"text": "To address this issue, we propose a semi-supervised approach, capitalizing on previous work by.", "labels": [], "entities": []}, {"text": "Semi-supervised approaches to clustering have shown that performance can be enhanced by incorporating prior knowledge in the form of a small number of instance-level constraints.", "labels": [], "entities": []}, {"text": "We automatically identify event descriptions that are likely to cause alignment problems (called outliers), crowdsource alignments for these items and incorporate them as instance-level relational seeds into the clustering process.", "labels": [], "entities": []}, {"text": "Lastly, a main concern with the approach in RKP is scalability: temporal script graphs are created scenario-wise in a bottom-up fashion.", "labels": [], "entities": []}, {"text": "They represent only fragments of the rich amount of script knowledge people use in everyday communication.", "labels": [], "entities": []}, {"text": "In this paper we address this concern with the first assessment of the coverage of existing script resources, and an estimate of the concrete costs for their extension.", "labels": [], "entities": []}], "datasetContent": [{"text": "We applied different versions of our clustering algorithm to the SMILE+OMICS dataset.", "labels": [], "entities": [{"text": "SMILE+OMICS dataset", "start_pos": 65, "end_pos": 84, "type": "DATASET", "confidence": 0.7303736954927444}]}, {"text": "In particular, we explored the influence of positional similarity, of the number of seeds (from 0 to 3%), as well as the proportion of the two seed types (outlier vs. stable).", "labels": [], "entities": []}, {"text": "As a baseline, we ran the unsupervised clustering algorithm based on semantic similarity only.", "labels": [], "entities": []}, {"text": "We evaluated the models on the tasks of event-type induction, paraphrase detection, and temporal order prediction, using the respective gold standard datasets (see Section 2).", "labels": [], "entities": [{"text": "event-type induction", "start_pos": 40, "end_pos": 60, "type": "TASK", "confidence": 0.773248940706253}, {"text": "paraphrase detection", "start_pos": 62, "end_pos": 82, "type": "TASK", "confidence": 0.9132311940193176}, {"text": "temporal order prediction", "start_pos": 88, "end_pos": 113, "type": "TASK", "confidence": 0.5661871532599131}]}, {"text": "First, we evaluated the quality of the induced event types (i.e. sets of event descriptions) against the SMILE+OMICS gold clusters.", "labels": [], "entities": [{"text": "SMILE+OMICS gold clusters", "start_pos": 105, "end_pos": 130, "type": "DATASET", "confidence": 0.744569993019104}]}, {"text": "We used the B-Cubed metric (), which is calculated by averaging per-element precision and recall scores.", "labels": [], "entities": [{"text": "B-Cubed metric", "start_pos": 12, "end_pos": 26, "type": "METRIC", "confidence": 0.957880973815918}, {"text": "precision", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9679303169250488}, {"text": "recall", "start_pos": 90, "end_pos": 96, "type": "METRIC", "confidence": 0.9981517195701599}]}, {"text": "showed B-Cubed to be the metric that appropriately captures all aspects of measuring cluster quality.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results on the clustering, paraphrasing and temporal ordering tasks for state-of-the-art models,  our unsupervised (USC) and semi-supervised clustering approaches (SSC)", "labels": [], "entities": []}]}