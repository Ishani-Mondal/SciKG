{"title": [{"text": "Tagging Named Entities in 19th Century and Modern Finnish Newspaper Material with a Finnish Semantic Tagger", "labels": [], "entities": [{"text": "Tagging Named Entities in 19th Century and Modern Finnish Newspaper Material", "start_pos": 0, "end_pos": 76, "type": "TASK", "confidence": 0.7000703269785101}, {"text": "Finnish Semantic Tagger", "start_pos": 84, "end_pos": 107, "type": "TASK", "confidence": 0.5715286831061045}]}], "abstractContent": [{"text": "Named Entity Recognition (NER), search, classification and tagging of names and name like informational elements in texts, has become a standard information extraction procedure for textual data during the last two decades.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7778683255116144}, {"text": "classification and tagging of names and name like informational elements in texts", "start_pos": 40, "end_pos": 121, "type": "TASK", "confidence": 0.7966489220658938}, {"text": "information extraction", "start_pos": 145, "end_pos": 167, "type": "TASK", "confidence": 0.7361088395118713}]}, {"text": "NER has been applied to many types of texts and different types of entities: newspapers, fiction, historical records, persons, locations, chemical compounds, protein families, animals etc.", "labels": [], "entities": [{"text": "NER", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9028658866882324}]}, {"text": "In general a NER system's performance is genre and domain dependent.", "labels": [], "entities": []}, {"text": "Also used entity categories vary a lot (Nadeau and Sekine, 2007).", "labels": [], "entities": []}, {"text": "The most general set of named entities is usually some version of three part categorization of locations, persons and corporations.", "labels": [], "entities": []}, {"text": "In this paper we report evaluation results of NER with two different data: digitized Finnish historical newspaper collection Digi and modern Finnish technology news, Digitoday.", "labels": [], "entities": [{"text": "NER", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.504038393497467}, {"text": "Finnish historical newspaper collection Digi", "start_pos": 85, "end_pos": 129, "type": "DATASET", "confidence": 0.6326505661010742}]}, {"text": "Historical newspaper collection Digi contains 1,960,921 pages of newspaper material from years 1771-1910 both in Finnish and Swedish.", "labels": [], "entities": [{"text": "Historical newspaper collection Digi", "start_pos": 0, "end_pos": 36, "type": "DATASET", "confidence": 0.7562436014413834}]}, {"text": "We use only material of Finnish documents in our evaluation.", "labels": [], "entities": []}, {"text": "The OCRed newspaper collection has lots of OCR errors; its estimated word level correctness is about 70-75%, and its NER evaluation collection consists of 75 931 words (Kettunen and P\u00e4\u00e4kk\u00f6nen, 2016; Kettunen et al., 2016).", "labels": [], "entities": [{"text": "OCRed newspaper collection", "start_pos": 4, "end_pos": 30, "type": "DATASET", "confidence": 0.9499388933181763}, {"text": "word level correctness", "start_pos": 69, "end_pos": 91, "type": "METRIC", "confidence": 0.6223559379577637}, {"text": "NER evaluation collection", "start_pos": 117, "end_pos": 142, "type": "DATASET", "confidence": 0.6762332518895467}]}, {"text": "Digitoday's annotated collection consists of 240 articles in six different sections of the newspaper.", "labels": [], "entities": [{"text": "Digitoday's annotated collection", "start_pos": 0, "end_pos": 32, "type": "DATASET", "confidence": 0.956376388669014}]}, {"text": "Our new evaluated tool for NER tagging is non-conventional: it is a rule-based Finnish Semantic Tagger, the FST (L\u00f6fberg et al., 2005), and its results are compared to those of a standard rule-based NE tagger, FiNER.", "labels": [], "entities": [{"text": "NER tagging", "start_pos": 27, "end_pos": 38, "type": "TASK", "confidence": 0.9643457233905792}, {"text": "FST", "start_pos": 108, "end_pos": 111, "type": "DATASET", "confidence": 0.7365592122077942}, {"text": "FiNER", "start_pos": 210, "end_pos": 215, "type": "DATASET", "confidence": 0.9474255442619324}]}], "introductionContent": [{"text": "Digital newspapers and journals, either OCRed or born digital, form a growing global network of data that is available 24/7, and as such they are an important source of information.", "labels": [], "entities": []}, {"text": "As the amount of digitized journalistic data grows, also tools for harvesting the data are needed to gather information.", "labels": [], "entities": []}, {"text": "Named Entity Recognition has become one of the basic techniques for information extraction of texts since the mid1990s (.", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6343614459037781}, {"text": "information extraction of texts", "start_pos": 68, "end_pos": 99, "type": "TASK", "confidence": 0.825611837208271}]}, {"text": "In its initial form NER was used to find and mark semantic entities like person, location and organization in texts to enable information extraction related to this kind of material.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 126, "end_pos": 148, "type": "TASK", "confidence": 0.7327820509672165}]}, {"text": "Later on other types of extractable entities, like time, artefact, event and measure/numerical, have been added to the repertoires of NER software (.", "labels": [], "entities": []}, {"text": "In this paper we report evaluation results of NER for both historical 19 th century Finnish and modern Finnish.", "labels": [], "entities": [{"text": "NER", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.6507032513618469}]}, {"text": "Our historical data consists of an evaluation collection out of an OCRed Finnish historical newspaper collection.", "labels": [], "entities": [{"text": "OCRed Finnish historical newspaper collection", "start_pos": 67, "end_pos": 112, "type": "DATASET", "confidence": 0.8793292284011841}]}, {"text": "Our present day Finnish evaluation collection is from a Finnish technology newspaper Digitoday 1 .  have reported NER evaluation results of the historical Finnish data with two tools, FiNER and ARPA.", "labels": [], "entities": [{"text": "Finnish evaluation collection", "start_pos": 16, "end_pos": 45, "type": "DATASET", "confidence": 0.5565223495165507}, {"text": "NER evaluation", "start_pos": 114, "end_pos": 128, "type": "TASK", "confidence": 0.8760851621627808}, {"text": "FiNER", "start_pos": 184, "end_pos": 189, "type": "DATASET", "confidence": 0.920501172542572}]}, {"text": "Both tools achieved maximal F-scores of about 60 at best, but with many categories the results were much weaker.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.8684718608856201}]}, {"text": "Word level accuracy of the evaluation collection was about 73%, and thus the data can be considered very noisy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.7456792593002319}]}, {"text": "Results for modern Finnish NER have not been reported extensively so far.", "labels": [], "entities": [{"text": "Finnish NER", "start_pos": 19, "end_pos": 30, "type": "TASK", "confidence": 0.5237355381250381}]}, {"text": "mentions a few results in his description of transferring an older version of FiNER to anew version.", "labels": [], "entities": [{"text": "FiNER", "start_pos": 78, "end_pos": 83, "type": "DATASET", "confidence": 0.9506261944770813}]}, {"text": "With modern Finnish data F-scores round 90 are achieved.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9030715227127075}]}, {"text": "We use an older version of FiNER in this evaluation as a baseline NE tagger.", "labels": [], "entities": [{"text": "FiNER", "start_pos": 27, "end_pos": 32, "type": "DATASET", "confidence": 0.9387203454971313}]}, {"text": "FiNER is described more in . Shortly described it is a rule-based NER tagger that uses morphological recognition, morphological disambiguation, gazetteers (name lists), as well as pattern and context rules for name tagging.", "labels": [], "entities": [{"text": "FiNER", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9052900075912476}, {"text": "NER tagger", "start_pos": 66, "end_pos": 76, "type": "TASK", "confidence": 0.8838904500007629}, {"text": "name tagging", "start_pos": 210, "end_pos": 222, "type": "TASK", "confidence": 0.777777373790741}]}, {"text": "Along with FiNER we use a non-standard NER tool, a semantic tagger for Finnish, the FST ().", "labels": [], "entities": [{"text": "FiNER", "start_pos": 11, "end_pos": 16, "type": "DATASET", "confidence": 0.92903733253479}, {"text": "FST", "start_pos": 84, "end_pos": 87, "type": "METRIC", "confidence": 0.47885847091674805}]}, {"text": "The FST is not a NER tool as such; it has first and foremost been developed for semantic analysis of full text.", "labels": [], "entities": [{"text": "FST", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.4959604740142822}, {"text": "semantic analysis of full text", "start_pos": 80, "end_pos": 110, "type": "TASK", "confidence": 0.7764272570610047}]}, {"text": "The FST assigns a semantic category to each word in text employing a comprehensive semantic category scheme (USAS Semantic Tagset, available in English 2 and also in Finnish 3 ).", "labels": [], "entities": [{"text": "FST", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.8961166739463806}, {"text": "USAS Semantic Tagset", "start_pos": 109, "end_pos": 129, "type": "DATASET", "confidence": 0.8956352869669596}]}, {"text": "The Finnish Semantic Tagger (the FST) has its origins in Benedict, the EU-funded language technology project from the early 2000s, the aim of which was to discover an optimal way of catering for the needs of dictionary users in modern electronic dictionaries by utilizing state-of-theart language technology of the early 2000s.", "labels": [], "entities": [{"text": "Finnish Semantic Tagger (the FST)", "start_pos": 4, "end_pos": 37, "type": "TASK", "confidence": 0.726586103439331}]}, {"text": "The FST was developed using the English Semantic Tagger as a model.", "labels": [], "entities": [{"text": "FST", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.5444960594177246}, {"text": "English Semantic Tagger", "start_pos": 32, "end_pos": 55, "type": "DATASET", "confidence": 0.7944958408673605}]}, {"text": "This semantic tagger was developed at the University Centre for Corpus Research on Language (UCREL) at Lancaster University as part of the UCREL Semantic Analysis System (USAS 4 ) framework, and both these equivalent semantic taggers were utilized in the Benedict project in the creation of a context-sensitive search tool fora new intelligent dictionary.", "labels": [], "entities": [{"text": "UCREL Semantic Analysis System (USAS 4 ) framework", "start_pos": 139, "end_pos": 189, "type": "DATASET", "confidence": 0.8236216174231635}]}, {"text": "The overall architecture of the FST is described in and the intelligent dictionary application in.", "labels": [], "entities": [{"text": "FST", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.4849455654621124}]}, {"text": "In different evaluations the FST has been shown to be capable of dealing with most general domains which appear in a modern standard Finnish text.", "labels": [], "entities": [{"text": "FST", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.6787891387939453}]}, {"text": "Furthermore, although the semantic lexical resources of the tagger were originally developed for the analysis of general modern standard Finnish, evaluation results have shown that the lexical resources are also applicable to the analysis of both older Finnish text and the more informal type of writing found on the Web.", "labels": [], "entities": []}, {"text": "In addition, the semantic lexical resources can be tailored for various domain-specific tasks thanks to the flexible USAS category system.", "labels": [], "entities": [{"text": "USAS", "start_pos": 117, "end_pos": 121, "type": "DATASET", "confidence": 0.9041033387184143}]}, {"text": "Lexical resources used by the FST consist of two separate lexicons: the semantically categorized single word lexicon contains 45,871 entries and the multiword expression lexicon contains 6,113 entries, representing all parts of speech.", "labels": [], "entities": [{"text": "FST", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.5165503025054932}]}, {"text": "Our aim in the paper is twofold: first we want to evaluate whether a general computational semantic tool like the FST is able to perform a limited semantic task like NER as well as dedicated NER taggers.", "labels": [], "entities": [{"text": "FST", "start_pos": 114, "end_pos": 117, "type": "DATASET", "confidence": 0.7662929892539978}, {"text": "NER taggers", "start_pos": 191, "end_pos": 202, "type": "TASK", "confidence": 0.7348926067352295}]}, {"text": "Secondly, we try to establish the gap on NER performance of a modern Finnish tool with 19 th century low quality OCRed text and good quality modern newspaper text.", "labels": [], "entities": [{"text": "NER", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.9401629567146301}]}, {"text": "These two tasks will inform us about the adaptability of the FST to NER in general and also its adaptability to tagging of 19 th century Finnish that has lots of errors.", "labels": [], "entities": [{"text": "FST", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.6583296060562134}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. Evaluation of the FST and FiNER with  loose criteria and two categories in the historical  newspaper collection. W/v stands for w to v  substitution in words.", "labels": [], "entities": [{"text": "FST", "start_pos": 28, "end_pos": 31, "type": "DATASET", "confidence": 0.5524893999099731}, {"text": "FiNER", "start_pos": 36, "end_pos": 41, "type": "DATASET", "confidence": 0.8419455289840698}, {"text": "historical  newspaper collection", "start_pos": 89, "end_pos": 121, "type": "DATASET", "confidence": 0.8179305593172709}]}, {"text": " Table 2. Percentages of non-recognized words  with correctly and wrongly tagged locations and  persons -Omorfi 0.3", "labels": [], "entities": [{"text": "Omorfi 0.3", "start_pos": 105, "end_pos": 115, "type": "METRIC", "confidence": 0.5621212422847748}]}, {"text": " Table 3. Number of the FST tags in different  quality OCR texts", "labels": [], "entities": [{"text": "Number", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9415879249572754}, {"text": "FST tags", "start_pos": 24, "end_pos": 32, "type": "TASK", "confidence": 0.5235552340745926}]}, {"text": " Table 4. Results of FiNER and the FST with Digitoday's data section-by-section", "labels": [], "entities": [{"text": "FiNER", "start_pos": 21, "end_pos": 26, "type": "DATASET", "confidence": 0.9069796800613403}, {"text": "FST", "start_pos": 35, "end_pos": 38, "type": "DATASET", "confidence": 0.7207025289535522}, {"text": "Digitoday's data section-by-section", "start_pos": 44, "end_pos": 79, "type": "DATASET", "confidence": 0.9025371223688126}]}, {"text": " Table 5. Combined results of all Digitoday's sections", "labels": [], "entities": [{"text": "Combined", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9631235599517822}]}]}