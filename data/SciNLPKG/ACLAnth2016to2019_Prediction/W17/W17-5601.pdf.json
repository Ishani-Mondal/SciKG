{"title": [{"text": "Building a Better Bitext for Structurally Different Languages Through Self-training", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose a novel method to bootstrap the construction of parallel corpora for new pairs of structurally different languages.", "labels": [], "entities": []}, {"text": "We do so by combining the use of a pivot language and self-training.", "labels": [], "entities": []}, {"text": "A pivot language enables the use of existing translation models to bootstrap the alignment and a self-training procedure enables to achieve better alignment, both at the document and sentence level.", "labels": [], "entities": []}, {"text": "We also propose several evaluation methods for the resulting alignment.", "labels": [], "entities": []}], "introductionContent": [{"text": "A parallel corpus is a pair of texts written in different languages which are translation of each other.", "labels": [], "entities": []}, {"text": "Since multilingual publication has become more widespread, there is an increasing amount of such parallel data available.", "labels": [], "entities": []}, {"text": "Those are valuable resources for linguistic research and natural language processing applications, such as machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 107, "end_pos": 126, "type": "TASK", "confidence": 0.8270549476146698}]}, {"text": "It is also valuable when building crosslingual information retrieval software.", "labels": [], "entities": [{"text": "crosslingual information retrieval", "start_pos": 34, "end_pos": 68, "type": "TASK", "confidence": 0.6454101800918579}]}, {"text": "Finding the corresponding documents between two languages is a required step to build a parallel corpus, before more fine-grained alignments (paragraphs and sentences) can be calculated.", "labels": [], "entities": []}, {"text": "In some scenarios, multilingual data with identical or considerably similar texts can be found with more than two languages involved.", "labels": [], "entities": []}, {"text": "We ask whether a language can help as a pivot when aligning corpora and whether self-training may bring additional improvement of the alignment quality.", "labels": [], "entities": []}, {"text": "We see further that both questions can be answered positively.", "labels": [], "entities": []}, {"text": "We propose a novel method to efficiently build better parallel corpora through the combination of pivot language and self-training.", "labels": [], "entities": []}, {"text": "This method is especially targeted at aligning structurally different languages.", "labels": [], "entities": []}, {"text": "We present a topic-based document alignment algorithm and a length and lexiconbased sentence alignment algorithm.", "labels": [], "entities": [{"text": "topic-based document alignment", "start_pos": 13, "end_pos": 43, "type": "TASK", "confidence": 0.6235903998215994}, {"text": "sentence alignment", "start_pos": 84, "end_pos": 102, "type": "TASK", "confidence": 0.7461008727550507}]}, {"text": "Instead of directly aligning languages with widely different structures and even different writing systems, we make use of a pivot language and translate the other language into this pivot language before performing alignment.", "labels": [], "entities": []}, {"text": "Translation can be done with a statistical translation model if previous existing parallel data exist.", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9695237874984741}]}, {"text": "In our case, we perform a joint alignment and training of a translation model for the Korean-English language pair.", "labels": [], "entities": []}, {"text": "We use English as a pivot language.", "labels": [], "entities": []}, {"text": "Therefore, Korean sentences are translated into English before getting aligned.", "labels": [], "entities": []}, {"text": "That is, we align English and Englishtranslated Korean instead of directly aligning English and Korean.", "labels": [], "entities": []}, {"text": "In the end, alignments are restored in the original languages to build a parallel corpus.", "labels": [], "entities": []}, {"text": "We also employ a self-trained translation model in which the statistical translation model is reinforced by the newly aligned data.", "labels": [], "entities": []}, {"text": "The contribution of this work is mainly as follows: (1) We use a pivot language to align two languages with different writing systems.", "labels": [], "entities": []}, {"text": "(2) We propose a self-training method to be able to produce better parallel corpora.", "labels": [], "entities": []}, {"text": "(3) We describe the basic preprocessing scheme for Korean to be able to improve the statistical machine translation results.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 84, "end_pos": 115, "type": "TASK", "confidence": 0.6330083707968394}]}, {"text": "(4) We also propose several experiments for aligned parallel corpora by providing a standard 1 evaluation data set for Korean.", "labels": [], "entities": []}, {"text": "We hope that the present work will pave the way for further development of machine translation for Korean.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 75, "end_pos": 94, "type": "TASK", "confidence": 0.7812391817569733}]}], "datasetContent": [{"text": "In this section, we detail our experiments and present our alignment results obtained through machine translation and self-training 3 .", "labels": [], "entities": [{"text": "machine translation", "start_pos": 94, "end_pos": 113, "type": "TASK", "confidence": 0.740003228187561}]}], "tableCaptions": [{"text": " Table 3: Size of sentence alignment: (sent) for the  number of sentences and (tok) for tokens in the  English-side corpus.", "labels": [], "entities": [{"text": "Size of sentence alignment", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.6097771748900414}, {"text": "English-side corpus", "start_pos": 103, "end_pos": 122, "type": "DATASET", "confidence": 0.8491124510765076}]}, {"text": " Table 4: Results on sentence alignment", "labels": [], "entities": [{"text": "sentence alignment", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.7660177946090698}]}, {"text": " Table 5: Final results on sentence alignment for each bid for MT 1", "labels": [], "entities": [{"text": "sentence alignment", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.7577995955944061}, {"text": "MT", "start_pos": 63, "end_pos": 65, "type": "TASK", "confidence": 0.9861527681350708}]}, {"text": " Table 6: Results on sentence alignment by BLEU  scores. Ko is for results of the baseline system  where the corpus is aligned with the pivot lan- guage. We also perform the translation with and  without the initial bilingual corpus BC 0 .", "labels": [], "entities": [{"text": "sentence alignment", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.7464202642440796}, {"text": "BLEU", "start_pos": 43, "end_pos": 47, "type": "METRIC", "confidence": 0.9975907802581787}, {"text": "Ko", "start_pos": 57, "end_pos": 59, "type": "METRIC", "confidence": 0.9944732785224915}]}]}