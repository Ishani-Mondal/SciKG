{"title": [], "abstractContent": [{"text": "This paper describes Oregon State Uni-versity's submissions to the shared WMT'17 task \"multimodal translation task I\".", "labels": [], "entities": [{"text": "WMT'17 task \"multimodal translation task I", "start_pos": 74, "end_pos": 116, "type": "TASK", "confidence": 0.581878444978169}]}, {"text": "In this task, all the sentence pairs are image captions in different languages.", "labels": [], "entities": []}, {"text": "The key difference between this task and conventional machine translation is that we have corresponding images as additional information for each sentence pair.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.7668477296829224}]}, {"text": "In this paper, we introduce a simple but effective system which takes an image shared between different languages, feeding it into the both encoding and decoding side.", "labels": [], "entities": []}, {"text": "We report our sys-tem's performance for English-French and English-German with Flickr30K (in-domain) and MSCOCO (out-of-domain) datasets.", "labels": [], "entities": [{"text": "Flickr30K", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.7978308200836182}, {"text": "MSCOCO (out-of-domain) datasets", "start_pos": 105, "end_pos": 136, "type": "DATASET", "confidence": 0.7063132524490356}]}, {"text": "Our system achieves the best performance in TER for English-German for MSCOCO dataset.", "labels": [], "entities": [{"text": "TER", "start_pos": 44, "end_pos": 47, "type": "METRIC", "confidence": 0.9855383634567261}, {"text": "MSCOCO dataset", "start_pos": 71, "end_pos": 85, "type": "DATASET", "confidence": 0.9255050122737885}]}], "introductionContent": [{"text": "Natural language generation (NLG) is one of the most important tasks in natural language processing (NLP).", "labels": [], "entities": [{"text": "Natural language generation (NLG)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8061295549074808}, {"text": "natural language processing (NLP)", "start_pos": 72, "end_pos": 105, "type": "TASK", "confidence": 0.7945551077524821}]}, {"text": "It can be applied to a lot of interesting applications suchlike machine translation, image captioning, question answering.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 64, "end_pos": 83, "type": "TASK", "confidence": 0.8113319277763367}, {"text": "image captioning", "start_pos": 85, "end_pos": 101, "type": "TASK", "confidence": 0.7530496716499329}, {"text": "question answering", "start_pos": 103, "end_pos": 121, "type": "TASK", "confidence": 0.9199641644954681}]}, {"text": "In recent years, Recurrent Neural Networks (RNNs) based approaches have shown promising performance in generating more fluent and meaningful sentences compared with conventional models such as rulebased model), corpusbased n-gram models) and trainable generators).", "labels": [], "entities": []}, {"text": "\u2020 Current address: Google Inc., 111 8th Avenue, New York, New York, USA.", "labels": [], "entities": []}, {"text": "More recently, attention-based encoderdecoder models () have been proposed to provide the decoder more accurate alignments to generate more relevant words.", "labels": [], "entities": []}, {"text": "The remarkable ability of attention mechanisms quickly update the state-of-theart performance on variety of NLG tasks, such as machine translation, image captioning (, and text summarization (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 127, "end_pos": 146, "type": "TASK", "confidence": 0.8163522779941559}, {"text": "image captioning", "start_pos": 148, "end_pos": 164, "type": "TASK", "confidence": 0.7506457269191742}, {"text": "text summarization", "start_pos": 172, "end_pos": 190, "type": "TASK", "confidence": 0.7589028179645538}]}, {"text": "However, for multimodal translation, where we translate a caption from one language into another given a corresponding image, we need to design anew model since the decoder needs to consider both language and images at the same time.", "labels": [], "entities": [{"text": "multimodal translation", "start_pos": 13, "end_pos": 35, "type": "TASK", "confidence": 0.6847100555896759}]}, {"text": "This paper describes our participation in the WMT 2017 multimodal task 1.", "labels": [], "entities": [{"text": "WMT 2017 multimodal task 1", "start_pos": 46, "end_pos": 72, "type": "TASK", "confidence": 0.696199095249176}]}, {"text": "Our model feeds the image information to both the encoder and decoder, to ground their hidden representation within the same context of image during training.", "labels": [], "entities": []}, {"text": "In this way, during testing time, the decoder would generate more relevant words given the context of both source sentence and image.", "labels": [], "entities": []}, {"text": "ereed as \"Global attention\".", "labels": [], "entities": [{"text": "Global attention", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.5667864978313446}]}, {"text": "On the other hand, for the early work of neural-basic caption generation models (, the convolutional neural networks (CNN) generate the image features which feed into the decoder directly for generating the description.", "labels": [], "entities": [{"text": "neural-basic caption generation", "start_pos": 41, "end_pos": 72, "type": "TASK", "confidence": 0.6828399995962778}]}, {"text": "The first stage of the above two tasks both map the temporal and spatial information into a fixed dimensional vector which makes it feasible to utilize both information at the same time.", "labels": [], "entities": []}, {"text": "shows the basic idea of our proposed model (OSU1).", "labels": [], "entities": []}, {"text": "The red character I represents the image feature that is generated from CNN.", "labels": [], "entities": [{"text": "CNN", "start_pos": 72, "end_pos": 75, "type": "DATASET", "confidence": 0.9512876868247986}]}, {"text": "In our case, we directly use the image features that are provided by WMT, and these features are generated by residual networks.", "labels": [], "entities": [{"text": "WMT", "start_pos": 69, "end_pos": 72, "type": "DATASET", "confidence": 0.7928272485733032}]}, {"text": "The encoder (blue boxes) in takes the image feature as initialization for generating each hidden representation.", "labels": [], "entities": []}, {"text": "This process is very similar to neural-basic caption generation () which grounds each word's hidden representation to the context given by the image.", "labels": [], "entities": [{"text": "neural-basic caption generation", "start_pos": 32, "end_pos": 63, "type": "TASK", "confidence": 0.7325785756111145}]}, {"text": "On the decoder side (green boxes in), we not only let each decoded word align to source words by global attention but also feed the image feature as initialization to the decoder.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our experiments, we use two datasets", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Summary of datasets statistics.", "labels": [], "entities": [{"text": "Summary", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.903181791305542}]}, {"text": " Table 2: Experiments on Flickr30K dataset for trans- lation from English to German. 16 systems in total.  \u2020  represents our system.", "labels": [], "entities": [{"text": "Flickr30K dataset", "start_pos": 25, "end_pos": 42, "type": "DATASET", "confidence": 0.944419801235199}, {"text": "trans- lation from English to German", "start_pos": 47, "end_pos": 83, "type": "TASK", "confidence": 0.8303973589624677}]}, {"text": " Table 3: Experiments on MSCOCO dataset for trans- lation from English to German. 15 systems in total.  \u2020  represents our system.", "labels": [], "entities": [{"text": "MSCOCO dataset", "start_pos": 25, "end_pos": 39, "type": "DATASET", "confidence": 0.9371641874313354}, {"text": "trans- lation from English to German", "start_pos": 44, "end_pos": 80, "type": "TASK", "confidence": 0.8476043088095528}]}, {"text": " Table 4: Experiments on Flickr30K dataset for trans- lation from English to French. 11 systems in total.  \u2020  represents our system.", "labels": [], "entities": [{"text": "Flickr30K dataset", "start_pos": 25, "end_pos": 42, "type": "DATASET", "confidence": 0.9686877131462097}, {"text": "trans- lation from English to French", "start_pos": 47, "end_pos": 83, "type": "TASK", "confidence": 0.8409838846751622}]}, {"text": " Table 5: Experiments on MSCOCO dataset for trans- lation from English to French. 11 systems in total.", "labels": [], "entities": [{"text": "MSCOCO dataset", "start_pos": 25, "end_pos": 39, "type": "DATASET", "confidence": 0.864030659198761}, {"text": "trans- lation from English to French", "start_pos": 44, "end_pos": 80, "type": "TASK", "confidence": 0.8883090615272522}]}]}