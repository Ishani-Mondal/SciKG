{"title": [], "abstractContent": [{"text": "Query-based text summarization is aimed at extracting essential information that answers the query from original text.", "labels": [], "entities": [{"text": "Query-based text summarization", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7522910833358765}]}, {"text": "The answer is presented in a minimal, often predefined, number of words.", "labels": [], "entities": []}, {"text": "In this paper we introduce anew unsupervised approach for query-based extractive summa-rization, based on the minimum description length (MDL) principle that employs Krimp compression algorithm (Vreeken et al., 2011).", "labels": [], "entities": [{"text": "minimum description length (MDL)", "start_pos": 110, "end_pos": 142, "type": "METRIC", "confidence": 0.7411854565143585}]}, {"text": "The key idea of our approach is to select frequent word sets related to a given query that compress document sentences better and therefore describe the document better.", "labels": [], "entities": []}, {"text": "A summary is extracted by selecting sentences that best cover query-related frequent word sets.", "labels": [], "entities": []}, {"text": "The approach is evaluated based on the DUC 2005 and DUC 2006 datasets which are specifically designed for query-based summarization (DUC, 2005 2006).", "labels": [], "entities": [{"text": "DUC 2005 and DUC 2006 datasets", "start_pos": 39, "end_pos": 69, "type": "DATASET", "confidence": 0.9108224511146545}, {"text": "DUC, 2005 2006)", "start_pos": 133, "end_pos": 148, "type": "DATASET", "confidence": 0.931916332244873}]}, {"text": "It competes with the best results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Query-based summarization (QS) is directed toward generating a summary most relevant to a given query.", "labels": [], "entities": [{"text": "Query-based summarization (QS)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8280762195587158}]}, {"text": "It can relate to a single-document or to a multi-document input.", "labels": [], "entities": []}, {"text": "Our approach for QS is based on the MDL principle, defining the best summary as the one that leads to the best compression of the text with query-related information by providing its shortest and most concise description.", "labels": [], "entities": []}, {"text": "The MDL principle is widely useful in compression techniques of non-textual data, such as summarization of query results for online analytical processing (OLAP) applications;).", "labels": [], "entities": [{"text": "summarization of query results for online analytical processing (OLAP)", "start_pos": 90, "end_pos": 160, "type": "TASK", "confidence": 0.7293520515615289}]}, {"text": "However, only a few works about text summarization using MDL can be found in the literature.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.7377935647964478}]}, {"text": "used K-means clustering extended with the MDL principle, to find diverse topics in the summarized text.", "labels": [], "entities": []}, {"text": "also extended the C4.5 classifier with MDL for learning rhetorical relations.", "labels": [], "entities": [{"text": "learning rhetorical relations", "start_pos": 47, "end_pos": 76, "type": "TASK", "confidence": 0.7108093698819479}]}, {"text": "In () the problem of micro-review summarization is formulated within the MDL framework, where the authors view the tips as being encoded by snippets, and seek to find a collection of snippets that produces the encoding with the minimum number of bits.", "labels": [], "entities": [{"text": "micro-review summarization", "start_pos": 21, "end_pos": 47, "type": "TASK", "confidence": 0.6345390379428864}]}, {"text": "This work proposes a MDL approach where the sentences that are best described by the queryrelated word sequences are selected to a summary.", "labels": [], "entities": []}, {"text": "It is principally different from the mentioned works by (1) using frequent itemsets and not single words in the description model, (2) compressing entire documents instead of summaries, (3) ranking method for sentences, and (4) the description model itself.", "labels": [], "entities": []}, {"text": "We tested our approach on DUC 2005 and DUC 2006 data for English query-based summarization.", "labels": [], "entities": [{"text": "DUC 2005 and DUC 2006 data", "start_pos": 26, "end_pos": 52, "type": "DATASET", "confidence": 0.8893686334292094}, {"text": "English query-based summarization", "start_pos": 57, "end_pos": 90, "type": "TASK", "confidence": 0.41765522956848145}]}], "datasetContent": [{"text": "We generated summaries for each set of related documents (by considering each set of documents as one meta-document) in the DUC 2005 and DUC 2006 corpora.", "labels": [], "entities": [{"text": "DUC 2005 and DUC 2006 corpora", "start_pos": 124, "end_pos": 153, "type": "DATASET", "confidence": 0.914717415968577}]}, {"text": "The summarization quality was measured by the ROUGE-1) recall scores 1 , with the word limit set to 250, without stemming and stopword removal.", "labels": [], "entities": [{"text": "ROUGE-1) recall scores", "start_pos": 46, "end_pos": 68, "type": "METRIC", "confidence": 0.8238969147205353}]}, {"text": "We limited the size of the coding table by 250, as described in Section 3.4, and set support count S = 2 in order to take into account all terms repeated twice or more in the text.", "labels": [], "entities": [{"text": "support count S", "start_pos": 85, "end_pos": 100, "type": "METRIC", "confidence": 0.9454362193743387}]}, {"text": "shows the ROUGE-1 scores of our algorithm comparative to the scores of 32 systems that participated in the DUC 2005 competition.", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9967594742774963}, {"text": "DUC 2005 competition", "start_pos": 107, "end_pos": 127, "type": "DATASET", "confidence": 0.9263086915016174}]}, {"text": "Two options of our algorithm that correspond to constraints described in Section 3.7 appear in the \"Systems\" column of, denoted by Qump(C1-C2).", "labels": [], "entities": [{"text": "Qump", "start_pos": 131, "end_pos": 135, "type": "METRIC", "confidence": 0.9165956377983093}]}, {"text": "Qump(C2) places third on the ROUGE-1 recall and f-measure, and the difference between the top systems (ID=15 and ID=4) and our algorithm is statistically insignificant.", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 29, "end_pos": 36, "type": "METRIC", "confidence": 0.9484983086585999}, {"text": "recall", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.8507879972457886}]}], "tableCaptions": [{"text": " Table 1: CT example, top records.", "labels": [], "entities": []}, {"text": " Table 2: DUC 2005. ROUGE-1 scores.", "labels": [], "entities": [{"text": "DUC 2005", "start_pos": 10, "end_pos": 18, "type": "DATASET", "confidence": 0.9510969519615173}, {"text": "ROUGE-1", "start_pos": 20, "end_pos": 27, "type": "METRIC", "confidence": 0.9945631623268127}]}, {"text": " Table 3: DUC 2006. ROUGE-1 scores.", "labels": [], "entities": [{"text": "DUC 2006", "start_pos": 10, "end_pos": 18, "type": "DATASET", "confidence": 0.9450070858001709}, {"text": "ROUGE-1", "start_pos": 20, "end_pos": 27, "type": "METRIC", "confidence": 0.9954761862754822}]}]}