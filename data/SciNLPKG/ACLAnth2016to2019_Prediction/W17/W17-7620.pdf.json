{"title": [{"text": "What I think when I think about treebanks", "labels": [], "entities": [{"text": "treebanks", "start_pos": 32, "end_pos": 41, "type": "DATASET", "confidence": 0.8472468256950378}]}], "abstractContent": [{"text": "In this opinion piece, I present four somewhat controversial suggestions for the design of future treebanks: a) Treebanks should be based on adversarial samples, rather than pseudo-representative samples.", "labels": [], "entities": []}, {"text": "b) Treebanks should include multiple splits of the data, rather than just a single split, as inmost treebanks today.", "labels": [], "entities": []}, {"text": "c) They should include multiple annotations of each sentence, whenever possible, instead of adjudicated annotations.", "labels": [], "entities": []}, {"text": "d) There is no real motivation for adhering to a notion of well-formedness, since we now have parsers based on deep learning that generalize easily and perform well on any type of graphs, and treebanks therefore do not have to limit themselves to trees or directed acyclic graphs.", "labels": [], "entities": []}], "introductionContent": [{"text": "Treebanks are some of the most ambitious and expensive resources the NLP community has produced, and over the last two decades, they have enabled us to push research horizons and develop more advanced technologies.", "labels": [], "entities": []}, {"text": "While treebanks remain invaluable, and we owe thanks to all the people who have contributed to existing ones, I nevertheless think future treebanks will have significantly more value if they are designed slightly differently.", "labels": [], "entities": []}, {"text": "Treebanks are supposed to enable us to induce syntactic parsers and estimate their performance on held-out, unseen data; that is, their performance in the wild.", "labels": [], "entities": []}, {"text": "We have treebanks for more than 50 languages, albeit some of them very small, but typically only one treebank for each language.", "labels": [], "entities": []}, {"text": "Reported parsing results vary quite a bit from treebank to treebank, and such results are often taken as indicative of our ability to parse the relevant languages in the wild, given our current linguistic resources.", "labels": [], "entities": []}, {"text": "Differences in parsing results, from treebanks to treebanks, are often explained on linguistic grounds.", "labels": [], "entities": [{"text": "parsing", "start_pos": 15, "end_pos": 22, "type": "TASK", "confidence": 0.9711516499519348}]}, {"text": "Here is an example from the shared task description paper from the CoNLL 2007 dependency parsing shared task ( While explaining parsing performance by language characteristics such as freeness of word order and morphological complexity, is quite intuitive, and pleasing for someone with a background in linguistic typology, like me; this explanation was later disputed in, who claimed that what they called derivational perplexity, i.e., (a particular way of measuring) the average complexity of the tree structures in the tree structures, explained performance differences better.", "labels": [], "entities": [{"text": "CoNLL 2007 dependency parsing shared task", "start_pos": 67, "end_pos": 108, "type": "TASK", "confidence": 0.8647488454977671}]}, {"text": "Linguistic properties may of course be confounds, but tree structures are influenced heavily by linguistic theory and annotation guidelines, which also determine the complexity of the structures we use to analyze sentences.", "labels": [], "entities": []}, {"text": "Other factors that influence performance include how homogeneous the underlying corpus is.", "labels": [], "entities": []}, {"text": "If multi-authored, were the texts written with different intended audiences?", "labels": [], "entities": []}, {"text": "Do the authors span multiple demographics?", "labels": [], "entities": []}, {"text": "Do they speak different dialects?", "labels": [], "entities": []}, {"text": "Nevertheless, explanations based on linguistic grounds are far more common, and we often hear claims based on treebank results that some languages are harder to parse than others.", "labels": [], "entities": []}, {"text": "This was also the motivation behind a recent shared task in parsing morphologically rich languages.2 You may think that linguistic differences are much more important than other factors.", "labels": [], "entities": [{"text": "parsing morphologically rich languages.2", "start_pos": 60, "end_pos": 100, "type": "TASK", "confidence": 0.9012291729450226}]}, {"text": "This is not always true, however., for example, evaluate a dependency parser trained on newswire (the English Penn Treebank) on hand-annotated Twitter data.", "labels": [], "entities": [{"text": "English Penn Treebank) on hand-annotated Twitter data", "start_pos": 102, "end_pos": 155, "type": "DATASET", "confidence": 0.7965977638959885}]}, {"text": "On held-out newswire data, the parser has an unlabeled attachment score of 90.6%, but on Twitter data, the score is 73.6%.", "labels": [], "entities": [{"text": "attachment score", "start_pos": 55, "end_pos": 71, "type": "METRIC", "confidence": 0.8564907312393188}]}, {"text": "This 19% relative drop (17% absolute) is bigger than a lot of the drops we observe transferring models across languages.", "labels": [], "entities": []}, {"text": "About the same time, ran the Twitter experiments, revisited the idea of transferring the non-lexical part of parsing models across languages.", "labels": [], "entities": []}, {"text": "Their impoverished English model scored 82.5% in unlabeled attachment score on English data.", "labels": [], "entities": [{"text": "English data", "start_pos": 79, "end_pos": 91, "type": "DATASET", "confidence": 0.7566340267658234}]}, {"text": "When evaluating their model on Portuguese, for example, scores dropped to 68.4%, which is a 17% relative drop (14% absolute).", "labels": [], "entities": []}, {"text": "Changing the domain hurts model performance more than changing the language in this case.", "labels": [], "entities": []}, {"text": "It is easy to find similar examples in the literature.", "labels": [], "entities": []}, {"text": "These factors, by the same token, also influence how well we can generalize from validation and test set performance to performance in the wild or practical usefulness.", "labels": [], "entities": []}, {"text": "This paper discusses different dimensions of this problem and proposes design principles for building treebanks in the future.", "labels": [], "entities": []}, {"text": "My main observation is that our treebanks are being too nice onus, i.e., leading us to overestimate our performance in the wild.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}