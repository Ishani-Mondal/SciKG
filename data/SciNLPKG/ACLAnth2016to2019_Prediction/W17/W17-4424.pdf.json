{"title": [{"text": "A Feature-based Ensemble Approach to Recognition of Emerging and Rare Named Entities", "labels": [], "entities": [{"text": "Recognition of Emerging and Rare Named Entities", "start_pos": 37, "end_pos": 84, "type": "TASK", "confidence": 0.8406487362725394}]}], "abstractContent": [{"text": "Detecting previously unseen named entities in text is a challenging task.", "labels": [], "entities": [{"text": "Detecting previously unseen named entities in text", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.913905782358987}]}, {"text": "The paper describes how three initial classifier models were built using Conditional Random Fields (CRFs), Support Vector Machines (SVMs) and a Long Short-Term Memory (LSTM) recurrent neural network.", "labels": [], "entities": []}, {"text": "The outputs of these three classifiers were then used as features to train another CRF clas-sifier working as an ensemble.", "labels": [], "entities": []}, {"text": "5-fold cross-validation based on training and development data for the emerging and rare named entity recognition shared task showed precision, recall and F 1-score of 66.87%, 46.75% and 54.97%, respectively.", "labels": [], "entities": [{"text": "named entity recognition shared task", "start_pos": 89, "end_pos": 125, "type": "TASK", "confidence": 0.7799577116966248}, {"text": "precision", "start_pos": 133, "end_pos": 142, "type": "METRIC", "confidence": 0.9997863173484802}, {"text": "recall", "start_pos": 144, "end_pos": 150, "type": "METRIC", "confidence": 0.9996820688247681}, {"text": "F 1-score", "start_pos": 155, "end_pos": 164, "type": "METRIC", "confidence": 0.9848792850971222}]}, {"text": "For surface form evaluation, the CRF ensemble-based system achieved precision, recall and F 1 scores of 65.18%, 45.20% and 53.30%.", "labels": [], "entities": [{"text": "surface form evaluation", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.6579056183497111}, {"text": "precision", "start_pos": 68, "end_pos": 77, "type": "METRIC", "confidence": 0.9997765421867371}, {"text": "recall", "start_pos": 79, "end_pos": 85, "type": "METRIC", "confidence": 0.9995635151863098}, {"text": "F 1 scores", "start_pos": 90, "end_pos": 100, "type": "METRIC", "confidence": 0.9799690445264181}]}, {"text": "When applied to unseen test data, the model reached 47.92% precision, 31.97% recall and 38.55% F 1-score for entity level evaluation, with the corresponding surface form evaluation values of 44.91%, 30.47% and 36.31%.", "labels": [], "entities": [{"text": "precision", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9996440410614014}, {"text": "recall", "start_pos": 77, "end_pos": 83, "type": "METRIC", "confidence": 0.9997500777244568}, {"text": "F 1-score", "start_pos": 95, "end_pos": 104, "type": "METRIC", "confidence": 0.9897893071174622}]}], "introductionContent": [{"text": "The recognition of named entities is inherently complicated by the fact that new names emerge constantly and productively.", "labels": [], "entities": [{"text": "recognition of named entities", "start_pos": 4, "end_pos": 33, "type": "TASK", "confidence": 0.8632417619228363}]}, {"text": "This is particularly true for social media text and for other texts that are written in a more informal manner, where the issue is further complicated by a higher degree of misspellings as well as different types of unconventional spellings; on social media such as Twitter, abbreviated forms of words are common, as are merging of multiple words, special symbols and characters inserted into the words, etc.", "labels": [], "entities": []}, {"text": "Several approaches to Twitter named entity extraction have been explored, but it is still a challenging task due to noisiness of the texts.", "labels": [], "entities": [{"text": "Twitter named entity extraction", "start_pos": 22, "end_pos": 53, "type": "TASK", "confidence": 0.6604661792516708}]}, {"text": "proposed a semi-supervised learning framework to identify Twitter names, using a k-Nearest Neighbors (kNN) approach to label names and taking these labels as an input feature to a Conditional Random Fields (CRF) classifier, achieving almost 80% accuracy on their own annotated data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 245, "end_pos": 253, "type": "METRIC", "confidence": 0.9978992938995361}]}, {"text": "proposed a supervised model based on Labeled LDA (, and also showed part-of-speech and chunk information to be important components in Twitter named identification.", "labels": [], "entities": [{"text": "Twitter named identification", "start_pos": 135, "end_pos": 163, "type": "TASK", "confidence": 0.580238918463389}]}, {"text": "introduced an unsupervised Twitter named entity extraction strategy based on dynamic programming.", "labels": [], "entities": [{"text": "entity extraction", "start_pos": 41, "end_pos": 58, "type": "TASK", "confidence": 0.7270464599132538}]}, {"text": "The present work addresses emerging and rare entity recognition.", "labels": [], "entities": [{"text": "rare entity recognition", "start_pos": 40, "end_pos": 63, "type": "TASK", "confidence": 0.6245212455590566}]}, {"text": "The first Twitter named entity shared task was organized at the ACL 2015 workshop on noisy user-generated text (, with two subtasks: Twitter named entity identification and classification of those named entities into ten different types.", "labels": [], "entities": [{"text": "Twitter named entity identification", "start_pos": 133, "end_pos": 168, "type": "TASK", "confidence": 0.617309182882309}]}, {"text": "Of the eight systems participating in the first workshop, the best () achieved an F 1 score of 70.63% for Twitter name identification and 56.41% for classification, by combining supervised machine learning with high quality knowledge obtained from several open knowledge bases such as Wikipedia.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 82, "end_pos": 91, "type": "METRIC", "confidence": 0.9929471413294474}, {"text": "Twitter name identification", "start_pos": 106, "end_pos": 133, "type": "TASK", "confidence": 0.5623265008131663}, {"text": "classification", "start_pos": 149, "end_pos": 163, "type": "TASK", "confidence": 0.9455037117004395}]}, {"text": "Another team, () used a strategy based on differential evolution, getting F 1 scores of 56.81% for the identification task and 39.84% for classification.", "labels": [], "entities": [{"text": "differential evolution", "start_pos": 42, "end_pos": 64, "type": "TASK", "confidence": 0.6137914061546326}, {"text": "F 1 scores", "start_pos": 74, "end_pos": 84, "type": "METRIC", "confidence": 0.9904453555742899}, {"text": "identification task", "start_pos": 103, "end_pos": 122, "type": "TASK", "confidence": 0.8750799298286438}, {"text": "classification", "start_pos": 138, "end_pos": 152, "type": "TASK", "confidence": 0.8392062187194824}]}, {"text": "A second shared task on Twitter Named Entity recognition was organized at COLING in 2016 ().", "labels": [], "entities": [{"text": "Entity recognition", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.6986367553472519}, {"text": "COLING in 2016", "start_pos": 74, "end_pos": 88, "type": "DATASET", "confidence": 0.9332049290339152}]}, {"text": "The best placed system () used a bi-directional LSTM (Long Short-Term Memory) neural network model, and achieved 52.41% and 65.89% F 1 -scores on entity level and segmentation) achieved the best recall at segmentation level evaluation, and the second best F 1 -score (63.22%).", "labels": [], "entities": [{"text": "F 1 -scores", "start_pos": 131, "end_pos": 142, "type": "METRIC", "confidence": 0.9772618860006332}, {"text": "recall", "start_pos": 195, "end_pos": 201, "type": "METRIC", "confidence": 0.9985135197639465}, {"text": "F 1 -score", "start_pos": 256, "end_pos": 266, "type": "METRIC", "confidence": 0.9886128455400467}]}, {"text": "A related shared task on Twitter named entity recognition and linking (NEEL) to the DBpedia database was held in conjunction with the 2016 WWW conference.", "labels": [], "entities": [{"text": "entity recognition and linking (NEEL)", "start_pos": 39, "end_pos": 76, "type": "TASK", "confidence": 0.7914213878767831}, {"text": "DBpedia database", "start_pos": 84, "end_pos": 100, "type": "DATASET", "confidence": 0.8343153893947601}, {"text": "WWW conference", "start_pos": 139, "end_pos": 153, "type": "DATASET", "confidence": 0.8878223896026611}]}, {"text": "Five teams particpated, with the best system (Waitelonis and Sack, 2016) achieving recall, precision and F-scores of 49.4%, 45.3% and 47.3%.", "labels": [], "entities": [{"text": "recall", "start_pos": 83, "end_pos": 89, "type": "METRIC", "confidence": 0.9996471405029297}, {"text": "precision", "start_pos": 91, "end_pos": 100, "type": "METRIC", "confidence": 0.999453604221344}, {"text": "F-scores", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9988357424736023}]}, {"text": "In that system, each token was mapped to gazetteers developed from DBpedia.", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 67, "end_pos": 74, "type": "DATASET", "confidence": 0.9741992950439453}]}, {"text": "Tokens that were not nouns or did not match stop words were discarded.", "labels": [], "entities": []}, {"text": "The present paper outlines an ensemble-based machine learning approach to the identification and classification of rare and emerging named entities.", "labels": [], "entities": [{"text": "identification and classification of rare and emerging named entities", "start_pos": 78, "end_pos": 147, "type": "TASK", "confidence": 0.8687212930785285}]}, {"text": "Here the classification categories are Person, Location, Corporation, Product, Creativework and Group.", "labels": [], "entities": []}, {"text": "A Conditional Random Fields () classifier was trained using the outputs from three other classifiers as features, with those classifiers in turn being built using three different learning strategies: CRFs, Support Vector Machines (SVMs), and a deep learning based Long Short-Term Memory (LSTM) recurrent neural network.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: The named entity identification methodology and the different features used are introduced in Section 2.", "labels": [], "entities": [{"text": "named entity identification", "start_pos": 51, "end_pos": 78, "type": "TASK", "confidence": 0.6357928911844889}]}, {"text": "Results are presented and discussed in Section 3, while Section 4 addresses future work and concludes.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments were based on the datasets provided by the organizers of the W-NUT 2017 shared task on emerging and rare named entity recognition).", "labels": [], "entities": [{"text": "W-NUT 2017 shared task on emerging and rare named entity recognition", "start_pos": 77, "end_pos": 145, "type": "TASK", "confidence": 0.5715850537473505}]}, {"text": "The statistics of the datasets are shown in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Twitter dataset statistics", "labels": [], "entities": [{"text": "Twitter dataset", "start_pos": 10, "end_pos": 25, "type": "DATASET", "confidence": 0.9592775404453278}]}, {"text": " Table 2: 5-fold cross-validated results on combined development and training data", "labels": [], "entities": []}, {"text": " Table 3: Performance on the unseen test data (5-fold cross-validated)", "labels": [], "entities": []}]}