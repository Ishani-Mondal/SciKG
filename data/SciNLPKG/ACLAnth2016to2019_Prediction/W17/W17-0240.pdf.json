{"title": [{"text": "The Effect of Excluding Out of Domain Training Data from Supervised Named-Entity Recognition", "labels": [], "entities": [{"text": "Named-Entity Recognition", "start_pos": 68, "end_pos": 92, "type": "TASK", "confidence": 0.7024932503700256}]}], "abstractContent": [{"text": "Supervised named-entity recognition (NER) systems perform better on text that is similar to its training data.", "labels": [], "entities": [{"text": "named-entity recognition (NER)", "start_pos": 11, "end_pos": 41, "type": "TASK", "confidence": 0.8465279519557953}]}, {"text": "Despite this, systems are often trained with as much data as possible, ignoring its relevance.", "labels": [], "entities": []}, {"text": "This study explores if NER can be improved by excluding out of domain training data.", "labels": [], "entities": [{"text": "NER", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.9915899634361267}]}, {"text": "A maximum entropy model is developed and evaluated twice with each domain in Stockholm-Ume\u00e5 Corpus (SUC), once with all data and once with only in-domain data.", "labels": [], "entities": [{"text": "Stockholm-Ume\u00e5 Corpus (SUC)", "start_pos": 77, "end_pos": 104, "type": "DATASET", "confidence": 0.9436169981956481}]}, {"text": "For some domains, excluding out of domain training data improves tagging, but over the entire corpus it has a negative effect of less than two percentage points (both for strict and fuzzy matching).", "labels": [], "entities": [{"text": "tagging", "start_pos": 65, "end_pos": 72, "type": "TASK", "confidence": 0.9811034202575684}]}], "introductionContent": [{"text": "In named-entity recognition, the aim is to annotate all occurrences of explicit names, like John (person) and General Motors (organization) in a text, using some defined set of name tags.", "labels": [], "entities": [{"text": "named-entity recognition", "start_pos": 3, "end_pos": 27, "type": "TASK", "confidence": 0.7275223433971405}]}, {"text": "Machine learning algorithms can be trained to perform this task.", "labels": [], "entities": []}, {"text": "However, names manifest themselves quite differently in different domains.", "labels": [], "entities": []}, {"text": "It is challenging to create systems that perform well out of domain).", "labels": [], "entities": []}, {"text": "In many cases, NER systems are trained with a balanced corpus to provide as much data as possible.", "labels": [], "entities": [{"text": "NER", "start_pos": 15, "end_pos": 18, "type": "TASK", "confidence": 0.9677791595458984}]}, {"text": "However, this generates a very general model that perhaps is not the best possible for anyone domain.", "labels": [], "entities": []}, {"text": "This study aims to find out is such a model could be outperformed by removing all out of domain training data.", "labels": [], "entities": []}, {"text": "This is done using a basic maximum entropy model.", "labels": [], "entities": []}, {"text": "There are of course other, more up to date methods for NER, for example various types of neural networks, such as the state of the art systems presented by.", "labels": [], "entities": [{"text": "NER", "start_pos": 55, "end_pos": 58, "type": "TASK", "confidence": 0.9730960726737976}]}, {"text": "However, the maximum entropy model is sufficient for this study as the subject of interest is the effect of excluding out of domain data, not the machine learning algorithm itself.", "labels": [], "entities": []}, {"text": "The results of this study have previously been presented in.", "labels": [], "entities": []}], "datasetContent": [{"text": "To measure the effect of excluding out of domain training data, two balanced 10-fold crossvalidations are carried out for each domain.", "labels": [], "entities": []}, {"text": "The 500 documents of SUC are sorted alphanumerically with respect to their name (they are named after domain), and every tenth in-domain document is used for testing, beginning with the k'th document for each fold k.", "labels": [], "entities": []}, {"text": "In the first crossvalidation, all remaining documents in the corpus are used for training, while in the second crossvalidation, only the remaining in-domain documents are used.", "labels": [], "entities": []}, {"text": "When the system is comparing its tagging to the gold standard for evaluation, any given name can only be part of one match, which can either be a partial match or a full match.", "labels": [], "entities": []}, {"text": "The results of all ten folds are summed and an F1-value is calculated for the whole cross-validation.", "labels": [], "entities": [{"text": "F1-value", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9993547797203064}]}, {"text": "Results are presented both for strict and fuzzy matching.", "labels": [], "entities": []}, {"text": "Fuzzy matching accepts all names that have at least one token correctly tagged, while strict matching demands the tagging of a name to be identical to the gold standard.", "labels": [], "entities": [{"text": "Fuzzy matching", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8927476108074188}]}, {"text": "In this study, the system uses SUC's gold standard POS-tagging instead of using a separate POStagger to prepare the test data.", "labels": [], "entities": [{"text": "SUC", "start_pos": 31, "end_pos": 34, "type": "DATASET", "confidence": 0.800190269947052}]}], "tableCaptions": [{"text": " Table 1: Strict matching results. F1-values are presented in pairs of in-domain training data (left) and  mixed training data (right). Cases where in-domain training data gets the better result are highlighted.", "labels": [], "entities": [{"text": "Strict matching", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.7731902599334717}, {"text": "F1-values", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.9974779486656189}]}, {"text": " Table 2: Fuzzy matching results. F1-values are presented in pairs of in-domain training data (left) and  mixed training data (right). Cases where in-domain training data gets the better result are highlighted.", "labels": [], "entities": [{"text": "Fuzzy matching", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.736745297908783}, {"text": "F1-values", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9976842403411865}]}]}