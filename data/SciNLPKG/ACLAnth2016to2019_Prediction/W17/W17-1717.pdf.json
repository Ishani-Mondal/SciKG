{"title": [{"text": "The ATILF-LLF System for Parseme Shared Task: a Transition-based Verbal Multiword Expression Tagger", "labels": [], "entities": [{"text": "ATILF-LLF", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.7687707543373108}, {"text": "Parseme Shared Task", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.8698239922523499}, {"text": "Transition-based Verbal Multiword Expression Tagger", "start_pos": 48, "end_pos": 99, "type": "TASK", "confidence": 0.5978760480880737}]}], "abstractContent": [{"text": "We describe the ATILF-LLF system built for the MWE 2017 Shared Task on automatic identification of verbal multiword expressions.", "labels": [], "entities": [{"text": "ATILF-LLF", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9597458839416504}, {"text": "MWE 2017 Shared Task", "start_pos": 47, "end_pos": 67, "type": "DATASET", "confidence": 0.6842407882213593}, {"text": "automatic identification of verbal multiword expressions", "start_pos": 71, "end_pos": 127, "type": "TASK", "confidence": 0.7712559352318445}]}, {"text": "We participated in the closed track only, for all the 18 available languages.", "labels": [], "entities": []}, {"text": "Our system is a robust greedy transition-based system, in which MWE are identified through a MERGE transition.", "labels": [], "entities": []}, {"text": "The system was meant to accommodate the variety of linguistic resources provided for each language, in terms of accompanying morphological and syntactic information.", "labels": [], "entities": []}, {"text": "Using per-MWE Fscore, the system was ranked first 1 for all but two languages (Hungarian and Romanian).", "labels": [], "entities": [{"text": "Fscore", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9520784616470337}]}], "introductionContent": [{"text": "Verbal multi-word expressions (hereafter VMMEs) tend to exhibit more morphological and syntactic variation than other MWEs, if only because in general the verb is inflected, and it can receive adverbial modifiers.", "labels": [], "entities": []}, {"text": "Furthermore some VMWEs, in particular light verb constructions (one of the VMWE categories provided in the shared task), allow for the full range of syntactic variation (extraction, coordination etc...).", "labels": [], "entities": []}, {"text": "This renders the VMWE identification task even more challenging than general MWE identification, in which fully frozen and contiguous expressions help increasing the overall performance.", "labels": [], "entities": [{"text": "VMWE identification task", "start_pos": 17, "end_pos": 41, "type": "TASK", "confidence": 0.8660166064898173}, {"text": "MWE identification", "start_pos": 77, "end_pos": 95, "type": "TASK", "confidence": 0.960940808057785}]}, {"text": "The data sets are quite heterogeneous, both in terms of the number of annotated VMWEs and of accompanying resources (for the closed track).", "labels": [], "entities": []}, {"text": "2 2 systems participated for one language only (French), and 5 systems participated for more than one language.", "labels": [], "entities": []}, {"text": "Some of the data sets contain the tokenized sentences plus VMWEs only (BG, ES, HE, LT), some are accompanied with morphological information such as lemmas and POS So our first priority when setting up the architecture was to build a generic system applicable to all the 18 languages, with limited language-specific tuning.", "labels": [], "entities": [{"text": "BG", "start_pos": 71, "end_pos": 73, "type": "METRIC", "confidence": 0.9417185187339783}]}, {"text": "We thus chose to participate in the closed track only, relying exclusively on training data, accompanying CoNLL-U file when available, and basic feature engineering.", "labels": [], "entities": [{"text": "CoNLL-U file", "start_pos": 106, "end_pos": 118, "type": "DATASET", "confidence": 0.8969716131687164}]}, {"text": "We developed a onepass greedy transition-based system, which we believe can handle discontinuities elegantly.", "labels": [], "entities": []}, {"text": "We integrated more or less informed feature templates, depending on their availability in the data.", "labels": [], "entities": []}, {"text": "We describe our system in section 2, the experimental setup in section 3, the results in section 4 and the related works in section 5.", "labels": [], "entities": []}, {"text": "We conclude in section 6 and give perspectives for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "For replication purposes, we now describe how the system has been implemented (Subsection 3.1), which feature templates have been used (Subsection 3.2) and how they have been tuned (Subsection 3.3).", "labels": [], "entities": []}, {"text": "Simple descriptions of the system settings are provided in.", "labels": [], "entities": []}, {"text": "We thereafter use symbol Bi to indicate the ith element in the buffer.", "labels": [], "entities": [{"text": "Bi", "start_pos": 25, "end_pos": 27, "type": "METRIC", "confidence": 0.9244189262390137}]}, {"text": "S 0 and S 1 stand for the top and the second top elements of the stack.", "labels": [], "entities": []}, {"text": "For every unit X in the stack or the buffer, we denote Xw its word form, Xl its lemma and Xp its POS tag.", "labels": [], "entities": []}, {"text": "The concatenation of two elements X and Y is noted XY .", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Detailed results of all experiments over all the languages. F columns provide F-score results  and delta columns display the difference in F-score (times 10 \u22122 ) between our system and the best other  system of the shared task for the current evaluation/language configuration.", "labels": [], "entities": [{"text": "F-score", "start_pos": 88, "end_pos": 95, "type": "METRIC", "confidence": 0.980628490447998}, {"text": "F-score", "start_pos": 149, "end_pos": 156, "type": "METRIC", "confidence": 0.9902398586273193}]}]}