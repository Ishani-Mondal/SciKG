{"title": [{"text": "Extract with Order for Coherent Multi-Document Summarization", "labels": [], "entities": [{"text": "Summarization", "start_pos": 47, "end_pos": 60, "type": "TASK", "confidence": 0.5078144073486328}]}], "abstractContent": [{"text": "In this work, we aim at developing an ex-tractive summarizer in the multi-document setting.", "labels": [], "entities": []}, {"text": "We implement a rank based sentence selection using continuous vector representations along with key-phrases.", "labels": [], "entities": [{"text": "sentence selection", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.7214248776435852}]}, {"text": "Furthermore, we propose a model to tackle summary coherence for increasing readability.", "labels": [], "entities": []}, {"text": "We conduct experiments on the Document Understanding Conference (DUC) 2004 datasets using ROUGE toolkit.", "labels": [], "entities": [{"text": "Document Understanding Conference (DUC) 2004 datasets", "start_pos": 30, "end_pos": 83, "type": "DATASET", "confidence": 0.7644837275147438}]}, {"text": "Our experiments demonstrate that the methods bring significant improvements over the state of the art methods in terms of informativity and coherence.", "labels": [], "entities": []}], "introductionContent": [{"text": "The task of automatic document summarization aims at finding the most relevant informations in a text and presenting them in a condensed form.", "labels": [], "entities": [{"text": "automatic document summarization", "start_pos": 12, "end_pos": 44, "type": "TASK", "confidence": 0.5271947681903839}]}, {"text": "A good summary should retain the most important contents of the original document or a cluster of documents, while being coherent, non-redundant and grammatically readable.", "labels": [], "entities": []}, {"text": "There are two types of summarizations: abstractive summarization and extractive summarization.", "labels": [], "entities": [{"text": "summarizations", "start_pos": 23, "end_pos": 37, "type": "TASK", "confidence": 0.9722639918327332}]}, {"text": "Abstractive methods, which are still a growing field are highly complex as they need extensive natural language generation to rewrite the sentences.", "labels": [], "entities": []}, {"text": "Therefore, research community is focusing more on extractive summaries, which selects salient (important) sentences from the source document without any modification to create a summary.", "labels": [], "entities": []}, {"text": "Summarization is classified as single-document or multi-document based upon the number of source document.", "labels": [], "entities": [{"text": "Summarization", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.9533565640449524}]}, {"text": "The information overlap between the documents from the same topic makes the multi-document summarization more challenging than the task of summarizing single documents.", "labels": [], "entities": [{"text": "summarization", "start_pos": 91, "end_pos": 104, "type": "TASK", "confidence": 0.6369608640670776}, {"text": "summarizing single documents", "start_pos": 139, "end_pos": 167, "type": "TASK", "confidence": 0.8984500169754028}]}, {"text": "One crucial step in generating a coherent summary is to order the sentences in a logical manner to increase the readability.", "labels": [], "entities": []}, {"text": "A wrong order of sentences convey entirely different idea to the reader of the summary and also make it difficult to understand.", "labels": [], "entities": []}, {"text": "Ina single document, summary information can be presented by preserving the sentence position in the original document.", "labels": [], "entities": []}, {"text": "In multi-document summarization, the sentence position in the original document does not provide clue to the sentence arrangement.", "labels": [], "entities": [{"text": "multi-document summarization", "start_pos": 3, "end_pos": 31, "type": "TASK", "confidence": 0.6202928423881531}]}, {"text": "Hence it is a very challenging task to perform the arrangement of sentences in the summary.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our system ILPRankSumm (ILP based sentence selection with TextRank for Extractive Summarization) using ROUGE 5 (Lin, 2004) on DUC 2004 (Task-2, Length limit(L) = 100 words).", "labels": [], "entities": [{"text": "sentence selection", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.7004618644714355}, {"text": "ROUGE", "start_pos": 115, "end_pos": 120, "type": "METRIC", "confidence": 0.8971297144889832}, {"text": "DUC 2004", "start_pos": 138, "end_pos": 146, "type": "DATASET", "confidence": 0.8998371660709381}, {"text": "Length limit(L)", "start_pos": 156, "end_pos": 171, "type": "METRIC", "confidence": 0.9297796487808228}]}, {"text": "However, ROUGE scores are biased towards lexical overlap at surface level and insensitive to summary coherence.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 9, "end_pos": 14, "type": "METRIC", "confidence": 0.8853693604469299}]}, {"text": "Moreover, sophisticated coherence evaluation metrics are seldom adopted for summarization thus many of the previous systems used human evaluation for measuring readability.", "labels": [], "entities": [{"text": "summarization", "start_pos": 76, "end_pos": 89, "type": "TASK", "confidence": 0.9905285239219666}]}, {"text": "For this reason, we evaluate our summary coherence using (Lapata and) () which defines coherence probabilities for an ordered set of sentences.", "labels": [], "entities": []}], "tableCaptions": []}