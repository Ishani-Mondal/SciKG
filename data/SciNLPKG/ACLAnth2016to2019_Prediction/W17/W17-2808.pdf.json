{"title": [{"text": "Exploring Variation of Natural Human Commands to a Robot in a Collaborative Navigation Task", "labels": [], "entities": [{"text": "Exploring Variation of Natural Human Commands", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.7017673750718435}]}], "abstractContent": [{"text": "Robot-directed communication is variable , and may change based on human perception of robot capabilities.", "labels": [], "entities": [{"text": "Robot-directed communication", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6811370402574539}]}, {"text": "To collect training data fora dialogue system and to investigate possible communication changes overtime, we developed a Wizard-of-Oz study that (a) simulates a robot's limited understanding, and (b) collects dialogues where human participants build a progressively better mental model of the robot's understanding.", "labels": [], "entities": []}, {"text": "With ten participants, we collected ten hours of human-robot dialogue.", "labels": [], "entities": []}, {"text": "We analyzed the structure of instructions that participants gave to a remote robot before it responded.", "labels": [], "entities": []}, {"text": "Our findings show a general initial preference for including metric information (e.g., move forward 3 feet) over landmarks (e.g., move to the desk) in motion commands , but this decreased overtime, suggesting changes in perception.", "labels": [], "entities": [{"text": "overtime", "start_pos": 188, "end_pos": 196, "type": "METRIC", "confidence": 0.9906008243560791}]}], "introductionContent": [{"text": "Instruction-giving to robots varies based on perception of robots as conversational partners.", "labels": [], "entities": []}, {"text": "We present an experiment designed to elicit robotdirected language that is a happy medium between existing natural language processing capabilities and fully natural communication.", "labels": [], "entities": []}, {"text": "The data elicited will be used to train a dialogue system in the future, and it provides insights into what communication strategies people use when instructing robots.", "labels": [], "entities": []}, {"text": "In this paper, we begin to examine how people vary their strategies as they build a progressively more accurate mental model of the robot and its capabilities.", "labels": [], "entities": []}, {"text": "To simulate a robot's limited understanding of its environment, we employ the Wizard-of-Oz (WOz) method, where humans simulate robot intelligence and actions without participant awareness.", "labels": [], "entities": []}, {"text": "With ten participants, we collected ten hours of human-robot dialogue.", "labels": [], "entities": []}, {"text": "We are currently undertaking corpus curation and plan to make the data freely available in the next year.", "labels": [], "entities": [{"text": "corpus curation", "start_pos": 29, "end_pos": 44, "type": "TASK", "confidence": 0.6715073883533478}]}, {"text": "In this experiment, a human and robot engage in a series of transactions () where an instruction is issued, and wizards acting on behalf of the robot either perform a task or prompt for clarification until the requested task is completed or abandoned.", "labels": [], "entities": []}, {"text": "We propose anew term, instruction unit (IU), to identify all commands within a transaction issued before the robot generates a response.", "labels": [], "entities": []}, {"text": "IUs were analyzed both in structure and variation.", "labels": [], "entities": [{"text": "IUs", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.7738696336746216}]}, {"text": "Our findings suggest a general, initial preference for including metric information over landmarks in motion commands, but this decreased overtime.", "labels": [], "entities": [{"text": "overtime", "start_pos": 138, "end_pos": 146, "type": "METRIC", "confidence": 0.9963452219963074}]}, {"text": "Results will assist in future work adapting robot responses to varied instruction styles.", "labels": [], "entities": []}, {"text": "In the sections to follow, we first give needed background: the experiment setup and our approach to eliciting natural, robot-directed language.", "labels": [], "entities": []}, {"text": "We then describe the annotations we have undertaken thus far to explore communication strategies.", "labels": [], "entities": []}, {"text": "In our results section, we provide some statistics on the data collected thus far as well as noted changes in communication strategies.", "labels": [], "entities": []}, {"text": "We provide a discussion of these results and comparison to related work and close with a summary and description of future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In each session, a (Commander) participant engaged the robot in collaborative search-andnavigation tasks.", "labels": [], "entities": []}, {"text": "A session was comprised of three twenty-minute phases: a training phase and two main task phases (main phase 1 and 2).", "labels": [], "entities": []}, {"text": "Training may voluntarily end when participants were comfortable with controls.", "labels": [], "entities": []}, {"text": "Each phase focused on a slightly different search task and started in a distinct location.", "labels": [], "entities": []}, {"text": "Experiment tasks were developed to encourage the participant to use the robot as a teammate to search for certain objects in the environment.", "labels": [], "entities": []}, {"text": "The participant needed to use their real-world knowledge in order to answer questions that required analysis of the observed environment.", "labels": [], "entities": []}, {"text": "The robot didn't know common words for target objects, which required participants to consider word choice as they addressed the robot.", "labels": [], "entities": []}, {"text": "An example search task was to locate shoes in an environment, relying on robot-provided images.", "labels": [], "entities": []}, {"text": "An example analysis task was to consider whether the explored space was suitable as a headquarterslike environment.", "labels": [], "entities": []}, {"text": "All phases situated the robot in an unfamiliar indoor environment, unlike canonical scenes typically observed in homes and offices.", "labels": [], "entities": []}, {"text": "Preceding the study, participants received a list of robot capabilities (see Appendix A).", "labels": [], "entities": []}, {"text": "They were told that the robot understood basic object properties (e.g., most object labels, color, size), relative proximity, some spatial terms, and location history.", "labels": [], "entities": []}, {"text": "Participants were not given example instructions.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Dialogue-move distribution over all IUs  in the corpus (N=858). An IU may have one or  more dialogue-moves.", "labels": [], "entities": []}]}