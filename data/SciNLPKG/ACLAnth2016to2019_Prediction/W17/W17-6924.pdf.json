{"title": [{"text": "Dual Embeddings and Metrics for Relational Similarity", "labels": [], "entities": [{"text": "Similarity", "start_pos": 43, "end_pos": 53, "type": "TASK", "confidence": 0.786952018737793}]}], "abstractContent": [{"text": "In this work, we study the problem of relational similarity by combining different word embeddings learned from different types of contexts.", "labels": [], "entities": [{"text": "relational similarity", "start_pos": 38, "end_pos": 59, "type": "TASK", "confidence": 0.8498674929141998}]}, {"text": "The word2vec model with linear bag-of-words contexts can capture more topical and less functional similarity, while the dependency-based word embeddings with syntactic contexts can capture more functional and less topical similarity.", "labels": [], "entities": []}, {"text": "We explore topical space and functional space simultaneously by considering these two word embed-dings and different metrics.", "labels": [], "entities": []}, {"text": "We evaluate our model on relational similarity framework, and report state-of-the-art performance on standard test collections.", "labels": [], "entities": []}], "introductionContent": [{"text": "Measuring relational similarity between two word pairs plays important roles in natural language processing (NLP).", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 80, "end_pos": 113, "type": "TASK", "confidence": 0.8041974206765493}]}, {"text": "The techniques for solving this problem can be applied to a variety of NLP tasks, such as query expansion, word sense disambiguation, machine translation, information extraction and question answering.", "labels": [], "entities": [{"text": "query expansion", "start_pos": 90, "end_pos": 105, "type": "TASK", "confidence": 0.7534366846084595}, {"text": "word sense disambiguation", "start_pos": 107, "end_pos": 132, "type": "TASK", "confidence": 0.6781313618024191}, {"text": "machine translation", "start_pos": 134, "end_pos": 153, "type": "TASK", "confidence": 0.8109818696975708}, {"text": "information extraction", "start_pos": 155, "end_pos": 177, "type": "TASK", "confidence": 0.842281311750412}, {"text": "question answering", "start_pos": 182, "end_pos": 200, "type": "TASK", "confidence": 0.9029376804828644}]}, {"text": "Previous work addressing the problem can be roughly classified into three categories: (1) learning word embeddings from large collections of text using variants of neural networks (;;;) or global matrix factorization; Turney (2012)); (2) extracting knowledge from existing semantic networks, such as WordNet (;;) and ConceptNet (); (3) combining the above two models by various ways;;;).", "labels": [], "entities": []}, {"text": "The empirical evidence shows that the word representations learned from neural network models do an especially good job in capturing not only attributional similarities between words but also similarities between pairs of words ().", "labels": [], "entities": []}, {"text": "generalize the skip-gram model with negative sampling to include arbitrary word contexts and present the dependency-based word embeddings, which are learned from syntactic contexts derived from dependency parse-trees.", "labels": [], "entities": []}, {"text": "Qualitative and quantitative analysis demonstrates that the word2vec model with linear bag-of-words contexts can yield broad topical similarity while the dependency-based word embeddings with syntactic contexts can capture more functional similarity.", "labels": [], "entities": []}, {"text": "Turney (2012) is the first, to the best of our knowledge, to raise the word vector representations in a dual space and unify semantic relations and compositions by the dualspace model.", "labels": [], "entities": []}, {"text": "The dual-space model consists of a domain space and a function space, where the domain or topic of a word is characterized by the nouns that occur near it and the function or role of a word is characterized by the syntactic context that relates it to the verbs that occur near it.", "labels": [], "entities": []}, {"text": "We detail our main contributions as follows.", "labels": [], "entities": []}, {"text": "In this paper, we use the word2vec model with linear bag-of-words contexts to capture the domain of a word, and the dependency-based word embeddings with syntactic contexts to characterize the function of a word.", "labels": [], "entities": []}, {"text": "The broad contexts used in our model can provide richer information for measuring domain similarity (i.e., topic, subject, or field similarity) and function similarity (i.e, role, relationship, or usage similarity) than noun or verb-based patterns for contexts in Turney's (2012) model.", "labels": [], "entities": []}, {"text": "The two existing models for measuring relational similarity are: the directional similarity model () and the dual-space model consisting of domain and function space).", "labels": [], "entities": []}, {"text": "Both models suffer some drawbacks.", "labels": [], "entities": []}, {"text": "The directional similarity model explores the difference of two relationships in multiple topicality dimensions in the vector space.", "labels": [], "entities": []}, {"text": "However, it ignores the spatial distances between word vectors, which can reveal the function similarity of words in function space.", "labels": [], "entities": []}, {"text": "The dual-space model can measure the domain similarity and function similarity between words.", "labels": [], "entities": []}, {"text": "However, it only computes the domain similarity between two single words and places less emphasis on the domain similarity between two relations.", "labels": [], "entities": []}, {"text": "In this work, we propose anew dual-space model for measuring relational similarity, which combines the advantages of the two existing models.", "labels": [], "entities": []}, {"text": "(3) We evaluate our model on relational similarity framework and report state-of-the-art performance on SAT analogy questions.", "labels": [], "entities": [{"text": "SAT analogy", "start_pos": 104, "end_pos": 115, "type": "TASK", "confidence": 0.7908658385276794}]}], "datasetContent": [{"text": "In the following experiments, we evaluate our approaches to solving analogies by a set of 374 SAT analogy questions, which is the same set of questions as was used in Turney's Dual-Space mode (Turney).", "labels": [], "entities": [{"text": "Turney)", "start_pos": 193, "end_pos": 200, "type": "DATASET", "confidence": 0.8038950562477112}]}, {"text": "Precision and Recall are two standard performance measurements used for evaluation.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9896341562271118}, {"text": "Recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9955524802207947}]}, {"text": "The definitions of precision and recall are specified by).", "labels": [], "entities": [{"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9995754361152649}, {"text": "recall", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.9991946816444397}]}, {"text": "In all experiments, we use the 300-dimensional W2V and DEP vectors pretrained on a concatenation of three large, diverse English corpora, and those vectors are available for downloading . shows the experimental results of four approaches presented in Section 4.3 on the set of 374 analogy questions.", "labels": [], "entities": []}, {"text": "Two questions are skipped because the vector for the target pair is not available in the collection.", "labels": [], "entities": []}, {"text": "Since there are five options for each target pair of an SAT analogy question, random guessing would yield a recall of 20%.", "labels": [], "entities": [{"text": "SAT analogy question", "start_pos": 56, "end_pos": 76, "type": "TASK", "confidence": 0.7189456621805826}, {"text": "recall", "start_pos": 108, "end_pos": 114, "type": "METRIC", "confidence": 0.9996622800827026}]}, {"text": "Domain similarity Similarity D , function similarity Similarity F 1 and Similarity F 2 all perform much better than random guessing.", "labels": [], "entities": [{"text": "Similarity F 2", "start_pos": 72, "end_pos": 86, "type": "METRIC", "confidence": 0.9084333181381226}]}, {"text": "Our compositional similarity model Similarity ADD in the dual space clearly outperforms Similarity D , Similarity F 1 and Similarity F 2 in single domain or function space.", "labels": [], "entities": [{"text": "Similarity ADD", "start_pos": 35, "end_pos": 49, "type": "METRIC", "confidence": 0.5869584083557129}, {"text": "Similarity F 1", "start_pos": 103, "end_pos": 117, "type": "METRIC", "confidence": 0.8600675662358602}]}], "tableCaptions": [{"text": " Table 1: Experimental results of four models on SAT question bruise:skin", "labels": [], "entities": []}, {"text": " Table 2: Experimental results on the set of 374 analogy questions", "labels": [], "entities": []}, {"text": " Table 3: Experimental results on the 374 SAT questions labeled with different parts of speech", "labels": [], "entities": []}]}