{"title": [{"text": "Unsupervised Detection of Argumentative Units though Topic Modeling Techniques", "labels": [], "entities": [{"text": "Unsupervised Detection of Argumentative Units", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.6942680537700653}]}], "abstractContent": [{"text": "In this paper we present anew unsuper-vised approach, \"Attraction to Topics\"-A2T , for the detection of argumentative units, a sub-task of argument mining.", "labels": [], "entities": [{"text": "Attraction to Topics\"-A2T", "start_pos": 55, "end_pos": 80, "type": "TASK", "confidence": 0.4833595514297485}, {"text": "argument mining", "start_pos": 139, "end_pos": 154, "type": "TASK", "confidence": 0.7257731109857559}]}, {"text": "Motivated by the importance of topic identification in manual annotation, we examine whether topic modeling can be used for performing unsupervised detection of argumentative sentences, and to what extend topic modeling can be used to classify sentences as claims and premises.", "labels": [], "entities": [{"text": "topic identification", "start_pos": 31, "end_pos": 51, "type": "TASK", "confidence": 0.7360049039125443}]}, {"text": "Preliminary evaluation results suggest that topic information can be successfully used for the detection of argumentative sentences, at least for corpora used in the evaluation.", "labels": [], "entities": []}, {"text": "Our approach has been evaluated on two English corpora, the first of which contains 90 persuasive essays, while the second is a collection of 340 documents from user generated content.", "labels": [], "entities": []}], "introductionContent": [{"text": "Argument mining involves the automatic discovery of argument components (i.e. claims, premises) and the argumentative relations (i.e. supports, attacks) among these components in texts.", "labels": [], "entities": [{"text": "Argument mining", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8302001357078552}]}, {"text": "Primarily aiming to extract arguments from texts in order to provide structured data for computational models of argument and reasoning engines (, argument mining has additionally the potential to support applications in various research fields, such as opinion mining (, stance detection), policy modelling (), legal information systems (, etc.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 147, "end_pos": 162, "type": "TASK", "confidence": 0.7478665411472321}, {"text": "opinion mining", "start_pos": 254, "end_pos": 268, "type": "TASK", "confidence": 0.8430404365062714}, {"text": "stance detection", "start_pos": 272, "end_pos": 288, "type": "TASK", "confidence": 0.8735557794570923}, {"text": "policy modelling", "start_pos": 291, "end_pos": 307, "type": "TASK", "confidence": 0.7657184600830078}]}, {"text": "Argument mining is usually addressed as a pipeline of several sub-tasks.", "labels": [], "entities": [{"text": "Argument mining", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.9002832174301147}]}, {"text": "Typically the first sub-task is the separation between argumentative and non-argumentative text units, which can be performed at various granularity levels, from clauses to several sentences, usually depending on corpora characteristics.", "labels": [], "entities": []}, {"text": "Detection of argumentative units (AU) 1 , as discussed in Section 2, is typically modeled as a fully-supervised classification task, either a binary one, where units are separated in argumentative and non-argumentative ones with argumentative ones to be subsequently classified in claims and premises as a second step, or as a multi-class one, where identification of argumentative units and classification into claims and premises are performed as a single step.", "labels": [], "entities": [{"text": "Detection of argumentative units (AU) 1", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.889168880879879}]}, {"text": "According to a recent survey (, the performance of proposed approaches depends on highly engineered and sophisticated, manually constructed, features.", "labels": [], "entities": []}, {"text": "However, fully-supervised approaches rely on manually annotated datasets, the construction of which is a laborious, costly, and error-prone process, requiring significant effort from human experts.", "labels": [], "entities": []}, {"text": "At the same time, reliance on sophisticated features may hinder the generalisation of an approach to new corpora types and domains).", "labels": [], "entities": []}, {"text": "The removal of manual supervision through exploitation of unsupervised approaches is a possible solution to both of the aforementioned problems.", "labels": [], "entities": []}], "datasetContent": [{"text": "For evaluation of the proposed A2T approach, we have used two English corpora.", "labels": [], "entities": [{"text": "A2T", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.7563730478286743}]}, {"text": "The first corpus (C1 in the following) is a collection of 90 student persuasive essays (Stab and Gurevych, 2014a) which has been manually annotated with major claims (one per essay), claims and premises at the clause level.", "labels": [], "entities": []}, {"text": "In addition, the corpus contains manual annotations of argumentative relations, where the claims and premises are linked, while claims are linked to the major claim either with a support or an attack relation.", "labels": [], "entities": []}, {"text": "Interannotation agreement has been measured to unitized alpha) \u03b1 U = 0.724.", "labels": [], "entities": [{"text": "Interannotation agreement", "start_pos": 0, "end_pos": 25, "type": "METRIC", "confidence": 0.8674155473709106}, {"text": "unitized alpha) \u03b1 U", "start_pos": 47, "end_pos": 66, "type": "METRIC", "confidence": 0.9290628790855407}]}, {"text": "These 90 essays consist of a total of 1, 675 sentences (from which 19.3% contain no argument components), with an average length of 18.61 \u00b1 7 sentences per essay, while the 5.4% of sentences contain a major claim, 26.4% contain a claim, and 61.1% contain a premise.", "labels": [], "entities": []}, {"text": "The second corpus (C2 in the following) has been compiled and manually annotated as described in.", "labels": [], "entities": []}, {"text": "This corpus focuses on user generated content, including user comments, forum posts, blogs, and newspaper articles, covering several thematic domains from educational controversies, such as homeschooling, private vs. public schools, or singlesex education.", "labels": [], "entities": []}, {"text": "Containing in total 340 documents, the corpus has been manually annotated with an argument scheme based on extended Toulmin's model, involving claims, premises, and backing, rebuttal, refutation argument units.", "labels": [], "entities": []}, {"text": "The corpus contains documents of various sizes, with a mean size of 11.44 \u00b1 11.70 sentences per document, while the inter-annotator agreement was measured as \u03b1 U = 0.48.", "labels": [], "entities": [{"text": "\u03b1 U", "start_pos": 158, "end_pos": 161, "type": "METRIC", "confidence": 0.7232223451137543}]}, {"text": "The corpus consists of 3,899 sentences, from which 2,214 sentences (57%) contain no argument components.", "labels": [], "entities": []}, {"text": "Both corpora have been preprocessed with NLTK) in order to identify tokens and sentences.", "labels": [], "entities": []}, {"text": "Then, each sentence was annotated as argumentative or non-argumentative, depending on whether it contained an argument unit (i.e. a text fragment annotated as major claim, claim, or premise).", "labels": [], "entities": []}, {"text": "In addition, each argumentative sentence was further annotated with one of major claim, claim, and premise, based on the type of the contained argumentative unit.", "labels": [], "entities": []}, {"text": "For the second corpus, which utilizes a richer argument scheme, we have considered backing, rebuttal and refutation units as premises.", "labels": [], "entities": []}, {"text": "This second corpus does not contain units annotated as major claims.", "labels": [], "entities": []}, {"text": "The following three tasks have been executed: \u2022 Task 1: Argumentative sentence identification -given a sentence, classify whether or not it contains an argument component.", "labels": [], "entities": [{"text": "Argumentative sentence identification", "start_pos": 56, "end_pos": 93, "type": "TASK", "confidence": 0.6769820551077524}]}, {"text": "\u2022 Task 2: Major claim identification -given a argumentative sentence, classify whether or not it contains a major claim.", "labels": [], "entities": [{"text": "Major claim identification", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.7069545785586039}]}, {"text": "\u2022 Task 3: Argumentative sentence classification -given a sentence, classify the sentence as major claim, claim, premise, or nonargumentative.", "labels": [], "entities": [{"text": "Argumentative sentence classification", "start_pos": 10, "end_pos": 47, "type": "TASK", "confidence": 0.6587693790594736}]}, {"text": "As a baseline for comparison against our approach, we created a probabilistic classifier of sentences which evaluates the probability p(l = au|s i ) as follows.", "labels": [], "entities": []}, {"text": "Given the text c containing L(c) sentences s i , let be \u03b6 c \u223c Dir(\u03b1) the probability distribution of the sentences inc, . The rationale of this procedure is to bias the random assignment of a sentence to the au label in favor of sentences appearing either in the beginning or in the end of a text.", "labels": [], "entities": []}, {"text": "This bias attempts to model empirical evidence that in several types of documents, the density of argumentative units in various sections of documents depends on the structure of documents.", "labels": [], "entities": []}, {"text": "The beginning and end of a document are expected to contain argumentative units in structured documents like news, scientific publications, or argumentative essays, where major claims and supporting premises are frequently found in the beginning of documents, with documents frequently ending with repeating the major claims and supporting evidence.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Area under the precision-recall (P) and  the ROC (R) curves", "labels": [], "entities": [{"text": "Area", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9596850275993347}, {"text": "precision-recall (P)", "start_pos": 25, "end_pos": 45, "type": "METRIC", "confidence": 0.9608322829008102}, {"text": "ROC (R)", "start_pos": 55, "end_pos": 62, "type": "METRIC", "confidence": 0.8816467523574829}]}]}