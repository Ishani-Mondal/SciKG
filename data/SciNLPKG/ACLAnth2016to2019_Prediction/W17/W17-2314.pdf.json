{"title": [{"text": "Proactive Learning for Named Entity Recognition", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 23, "end_pos": 47, "type": "TASK", "confidence": 0.7181107799212137}]}], "abstractContent": [{"text": "The goal of active learning is to minimise the cost of producing an annotated dataset, in which annotators are assumed to be perfect , i.e., they always choose the correct labels.", "labels": [], "entities": []}, {"text": "However, in practice, annotators are not infallible, and they are likely to assign incorrect labels to some instances.", "labels": [], "entities": []}, {"text": "Proac-tive learning is a generalisation of active learning that can model different kinds of annotators.", "labels": [], "entities": []}, {"text": "Although proactive learning has been applied to certain labelling tasks, such as text classification, there is little work on its application to named entity (NE) tagging.", "labels": [], "entities": [{"text": "text classification", "start_pos": 81, "end_pos": 100, "type": "TASK", "confidence": 0.8083470165729523}, {"text": "named entity (NE) tagging", "start_pos": 145, "end_pos": 170, "type": "TASK", "confidence": 0.6998023092746735}]}, {"text": "In this paper, we propose a proactive learning method for producing NE annotated corpora, using two an-notators with different levels of expertise, and who charge different amounts based on their levels of experience.", "labels": [], "entities": []}, {"text": "To opti-mise both cost and annotation quality, we also propose a mechanism to present multiple sentences to annotators at each iteration.", "labels": [], "entities": []}, {"text": "Experimental results for several corpora show that our method facilitates the construction of high-quality NE labelled datasets at minimal cost.", "labels": [], "entities": []}], "introductionContent": [{"text": "Manually annotating a dataset with NEs is both time-consuming and costly.", "labels": [], "entities": []}, {"text": "Active learning, a semi-supervised machine learning algorithm, aims to address such issues.", "labels": [], "entities": [{"text": "Active learning", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7705745100975037}]}, {"text": "Instead of asking annotators to label the whole dataset, active learning methods present only representative and informative instances to annotators.", "labels": [], "entities": []}, {"text": "Through iterative application of this process, a high-quality annotated corpus can be produced in less time and at lower cost than traditional annotation methods.", "labels": [], "entities": []}, {"text": "There are two strong assumptions in active learning: (1) instances are labelled by experts, who always produce correct annotations and are not affected by the tedious and repetitive nature of the task; (2) all annotators are paid equally, regardless of their annotation quality or level of expertise.", "labels": [], "entities": []}, {"text": "However, in practice, it is highly unlikely that all annotators will assign accurate labels all of the time.", "labels": [], "entities": []}, {"text": "For example, especially for complex annotation tasks, some labels are likely to be assigned incorrectly (.", "labels": [], "entities": []}, {"text": "Furthermore, if annotation is carried out for long periods of time, tiredness and reduced concentration may ensue, which can lead to annotation errors.", "labels": [], "entities": []}, {"text": "An additional issue is that different annotators may have varying levels of expertise, which could make them reluctant to annotate certain cases, and they may assign incorrect labels in other cases.", "labels": [], "entities": []}, {"text": "It is also possible that an inexperienced annotator may assign random labels.", "labels": [], "entities": []}, {"text": "To address the above-mentioned assumptions, proactive learning has been proposed to model different types of experts (.", "labels": [], "entities": []}, {"text": "Proactive learning assumes that (1) not all annotators are perfect, but that there is at least one \"perfect\" expert and one less experienced or \"fallible\" annotator; (2) as the perfect expert always provides correct answers, their time is more expensive than that of the fallible annotator.", "labels": [], "entities": []}, {"text": "The annotation process in proactive learning is similar to traditional active learning.", "labels": [], "entities": []}, {"text": "At each iteration, annotators will be asked to tag an unlabelled instance, the result of which will be added to the labelled dataset.", "labels": [], "entities": []}, {"text": "However, the difference with proactive learning is that, in order to reduce annotation cost, an appropriate annotator is chosen to label each selected instance.", "labels": [], "entities": []}, {"text": "For example, if there is a high probability that the fallible annotator will provide the correct label for an unlabelled instance, then proactive learning will send this instance to be annotated by fallible annotator.", "labels": [], "entities": []}, {"text": "This aims to ensure a simultaneous saving of costs and maintenance of the quality of the data.", "labels": [], "entities": []}, {"text": "Proactive learning has been used for several annotation tasks, such as binary and multi-class text classification, and parsing (.", "labels": [], "entities": [{"text": "multi-class text classification", "start_pos": 82, "end_pos": 113, "type": "TASK", "confidence": 0.6481671134630839}]}, {"text": "In contrast, this paper proposes a proactive learning method for NE tagging, i.e., a sequence labelling task.", "labels": [], "entities": [{"text": "NE tagging", "start_pos": 65, "end_pos": 75, "type": "TASK", "confidence": 0.9512733221054077}]}, {"text": "Similarly to other efforts that have used proactive learning, our method models two annotators: a reliable one and a fallible one, who have different probabilities of providing correct labels.", "labels": [], "entities": []}, {"text": "The reliable annotator is much more likely to produce correct annotations, but their time is expensive.", "labels": [], "entities": []}, {"text": "In contrast, the fallible annotator is likely to assign incorrect annotations more often, but charges less for their services.", "labels": [], "entities": []}, {"text": "It should be noted that the characteristics of our reliable expert are different from those proposed in previous work (.", "labels": [], "entities": []}, {"text": "Specifically, in the conventional proactive learning, the reliable expert is assumed to be perfect, i.e., he/she always provides correct annotations.", "labels": [], "entities": []}, {"text": "However, in practice, such an assumption is too strong, especially for NE annotation.", "labels": [], "entities": [{"text": "NE annotation", "start_pos": 71, "end_pos": 84, "type": "TASK", "confidence": 0.9134161472320557}]}, {"text": "Therefore, we assume that the reliable expert is not perfect, but that he/she has a higher expertise level in the target domain, and has a very low error rate.", "labels": [], "entities": [{"text": "error rate", "start_pos": 148, "end_pos": 158, "type": "METRIC", "confidence": 0.9829592108726501}]}, {"text": "In order to determine an appropriate annotator for each sentence, we calculate the probability that an annotator will assign the correct sequence of labels in a selected unlabelled sentence.", "labels": [], "entities": []}, {"text": "Furthermore, at each iteration, we use a batch sampling mechanism to select several sentences for annotators to label (instead of selecting only a single sentence), which optimises both cost and performance.", "labels": [], "entities": []}, {"text": "For evaluation purposes, we simulate the two annotators by using two machine-learning based NER methods, namely LSTM-CRF ( as the reliable expert, and CRF () as the fallible expert.", "labels": [], "entities": []}, {"text": "We then apply our method to three corpora from different domains: ACE2005 () for general language entities, COPIOUS-an in-house corpus of biodiversity entities 1 , and GENIA ()-a corpus of biomedical entities.", "labels": [], "entities": [{"text": "ACE2005", "start_pos": 66, "end_pos": 73, "type": "DATASET", "confidence": 0.8365945219993591}]}, {"text": "Our ex- The corpus is available upon request.", "labels": [], "entities": []}, {"text": "perimental results demonstrate that by using the proposed method, we can obtain a high-quality labelled corpus at a lower cost than current baseline methods.", "labels": [], "entities": []}, {"text": "The contributions of our work are as follows.", "labels": [], "entities": []}, {"text": "Firstly, we have modified the conventional proactive learning method to ensure its suitability fora sequence labelling task.", "labels": [], "entities": []}, {"text": "Secondly, in contrast to previous work, which selects a single instance for each annotator at each iteration), our method selects multiple sentences for presentation to annotators.", "labels": [], "entities": []}, {"text": "Thirdly, by applying our method to a number of different corpora, we demonstrate that our method is generalisable to different domains.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have applied our method to three different corpora: (1) ACE2005 () which includes named entities for the general domain, e.g., person, location, and organisation; (2) COPIOUS that includes five categories of biodiversity entities, such as taxon, habitat, and geographical location; (3) GENIA (), a biomedical named entity corpus.", "labels": [], "entities": [{"text": "ACE2005", "start_pos": 59, "end_pos": 66, "type": "DATASET", "confidence": 0.8599390983581543}, {"text": "GENIA", "start_pos": 289, "end_pos": 294, "type": "DATASET", "confidence": 0.8444169163703918}]}, {"text": "shows the entity classes and the number of entities of each class that are annotated in the three corpora.", "labels": [], "entities": []}, {"text": "As shown in the table, for the GE-NIA corpus, we combined the DNA and RNA entities into a single named entity class.", "labels": [], "entities": [{"text": "GE-NIA corpus", "start_pos": 31, "end_pos": 44, "type": "DATASET", "confidence": 0.9702733159065247}]}, {"text": "Meanwhile, for ACE2005, although top-level entity classes are divided into a number of different subtypes, we only considered the top-level classes, as shown in the table.", "labels": [], "entities": [{"text": "ACE2005", "start_pos": 15, "end_pos": 22, "type": "DATASET", "confidence": 0.931575357913971}]}, {"text": "For active and proactive learning experiments, 1% and 20% of sentences of each corpus were used as the initial labelled set and the test set, respectively.", "labels": [], "entities": []}, {"text": "The remaining 79% of sentences were regarded as unlabelled data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistic information of the three corpora", "labels": [], "entities": []}, {"text": " Table 2: Performance of CRF and LSTM-CRF on  the three corpora", "labels": [], "entities": []}, {"text": " Table 3: F 1 scores of each expert on the three cor- pora", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9660441875457764}]}]}