{"title": [{"text": "Automated Word Stress Detection in Russian", "labels": [], "entities": [{"text": "Automated Word Stress Detection", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.6943647190928459}]}], "abstractContent": [{"text": "In this study we address the problem of automated word stress detection in Russian using character level models and no part-speech-taggers.", "labels": [], "entities": [{"text": "word stress detection", "start_pos": 50, "end_pos": 71, "type": "TASK", "confidence": 0.7032045225302378}]}, {"text": "We use a simple bidirec-tional RNN with LSTM nodes and achieve the accuracy of 90% or higher.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.9995007514953613}]}, {"text": "We experiment with two training datasets and show that using the data from an annotated corpus is much more efficient than using a dictionary, since it allows us to take into account word frequencies and the morphological context of the word.", "labels": [], "entities": []}], "introductionContent": [{"text": "Character level models and character embeddings have received a lot of attention recently.", "labels": [], "entities": []}, {"text": "The character embeddings were used for several NLP tasks, such as word similarity, sentence similarity, part-ofspeech tagging (), NER (, speech recognition (, question answering (, language identification (, etc.", "labels": [], "entities": [{"text": "word similarity", "start_pos": 66, "end_pos": 81, "type": "TASK", "confidence": 0.7732173800468445}, {"text": "sentence similarity", "start_pos": 83, "end_pos": 102, "type": "TASK", "confidence": 0.7059308588504791}, {"text": "part-ofspeech tagging", "start_pos": 104, "end_pos": 125, "type": "TASK", "confidence": 0.7271437048912048}, {"text": "speech recognition", "start_pos": 137, "end_pos": 155, "type": "TASK", "confidence": 0.7050923109054565}, {"text": "question answering", "start_pos": 159, "end_pos": 177, "type": "TASK", "confidence": 0.8155539333820343}, {"text": "language identification", "start_pos": 181, "end_pos": 204, "type": "TASK", "confidence": 0.7576190233230591}]}, {"text": "In this study we concentrate on a lesser known problem, which to our knowledge has not been completely solved yet, namely the automatic detection of word stress.", "labels": [], "entities": [{"text": "automatic detection of word stress", "start_pos": 126, "end_pos": 160, "type": "TASK", "confidence": 0.7649428308010101}]}, {"text": "For some languages, e.g. Russian, this problem might be crucial for speech processing and generation.", "labels": [], "entities": [{"text": "speech processing and generation", "start_pos": 68, "end_pos": 100, "type": "TASK", "confidence": 0.7389561831951141}]}, {"text": "Only a few authors touch upon the problem of automated word stress detection in Russian.", "labels": [], "entities": [{"text": "word stress detection", "start_pos": 55, "end_pos": 76, "type": "TASK", "confidence": 0.7371927201747894}]}, {"text": "Among them, one research project in particular is worth mentioning.", "labels": [], "entities": []}, {"text": "The authors restricted the task of stress detection to finding the correct order within an array of stress assumptions where valid stress patterns were closer to the top of the list than the invalid ones.", "labels": [], "entities": [{"text": "stress detection", "start_pos": 35, "end_pos": 51, "type": "TASK", "confidence": 0.7807710766792297}]}, {"text": "Then, the first stress assumption in the rearranged list was considered to be correct.", "labels": [], "entities": []}, {"text": "The authors used the Maximum Entropy Ranking method to address this problem) and took character bi-and trigrams, suffixes and prefixes of ranked words as features as well as suffixes and prefixes represented in an \"abstract\" form where most of the vowels and consonants were replaced with their phonetic class labels.", "labels": [], "entities": []}, {"text": "The study features the results obtained using the corpus of Russian wordforms generated on the basis of Zaliznyaks Dictionary (approx. 2m wordforms).", "labels": [], "entities": []}, {"text": "Testing the model on randomly split train and test samples showed the accuracy of 0.987.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9997045397758484}]}, {"text": "According to the authors, they observed such a high accuracy because splitting the sample randomly during testing helped the algorithm benefit from the lexical information i.e. different wordforms of the same lexical item often share the same stress position.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9989079236984253}]}, {"text": "The authors then tried to solve a more complicated problem and tested their solution on a small number of wordforms for which the paradigms were not included the training sample.", "labels": [], "entities": []}, {"text": "As a result, the accuracy of 0.839 was achieved.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.999810516834259}]}, {"text": "The evaluation technique that the authors proposed is quite far from real-life application which is the main disadvantage of their study.", "labels": [], "entities": []}, {"text": "Usually the solutions in the field of automated stress detection are applied to real texts where the frequency distribution of wordforms differs drastically from the one in a bag of words obtained from \"unfolding\" of all the items in a dictionary.", "labels": [], "entities": [{"text": "automated stress detection", "start_pos": 38, "end_pos": 64, "type": "TASK", "confidence": 0.6554134686787924}]}, {"text": "In addition, another study (Reynolds and Tyers, 2015) describes the rule-based method of automated stress detection without the help of machine learning.", "labels": [], "entities": [{"text": "automated stress detection", "start_pos": 89, "end_pos": 115, "type": "TASK", "confidence": 0.6383183002471924}]}, {"text": "The authors proposed a system of finite-state automata imitating the rules of Russian stress accentuation and formal grammar that partially solved stress ambiguity by applying syntactical restrictions.", "labels": [], "entities": []}, {"text": "Thus, using all the above-mentioned solutions together with wordform frequency information, the authors achieved the accuracy of 0.962 on a relatively small hand-tagged Russian corpus (7689 tokens) that was not found to be generally available.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.999614953994751}]}, {"text": "We can treat the proposed method as a baseline for the automated word stress detection problem in Russian.", "labels": [], "entities": [{"text": "word stress detection problem", "start_pos": 65, "end_pos": 94, "type": "TASK", "confidence": 0.8155783042311668}]}, {"text": "In many languages, such as French, Czech, Finnish and German the rules for automated word stress detection can be formalized quite easily.", "labels": [], "entities": [{"text": "word stress detection", "start_pos": 85, "end_pos": 106, "type": "TASK", "confidence": 0.7173454463481903}]}, {"text": "Nevertheless there are languages where phonological characteristics do not predict stress position, for instance such word prosodic systems can be found in North-West Caucasian (Abkhaz) and Balto-Slavic languages (Lithuanian, SerboCroatian, Russian) (van der Hulst, 1999).", "labels": [], "entities": []}, {"text": "In Russian every word has one and only one stressed syllable.", "labels": [], "entities": []}, {"text": "Lexical stress is free in its positioning (any syllable can be stressed as shown in) and is movable (for many lexemes lexical stress depends on the word form, as shown in).", "labels": [], "entities": [{"text": "Lexical stress", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7993680536746979}]}, {"text": "Lexical stress can be crucial in disambiguating between homographs, both between two wordforms ((3)) as well as between two lexemes (): The position of lexical stress in Russian depends on many factors including the morphological content of the word, but also the type of word formation, its frequency and its meaning.", "labels": [], "entities": []}, {"text": "A complex system of markers which are defined for all morphemes has been developed in fundamental research.", "labels": [], "entities": []}, {"text": "There are rules that define the hierarchy and interaction of markers but some of them are not strict and can be considered more of a tendency.", "labels": [], "entities": []}, {"text": "For practical purposes the dictionary approach to text accentuation can be appropriate.", "labels": [], "entities": [{"text": "text accentuation", "start_pos": 50, "end_pos": 67, "type": "TASK", "confidence": 0.7467504739761353}]}, {"text": "It is possible to imagine a system that finds an accented form for each token using some predefined list.", "labels": [], "entities": []}, {"text": "However such a system would have several disadvantages, the most important of which would be its inability to predict stress for unknown words.", "labels": [], "entities": []}, {"text": "In this paper we propose a formal approach to the problem of automatic accentuation of Russian text by trying to exploit neural character models for these purposes.", "labels": [], "entities": [{"text": "automatic accentuation of Russian text", "start_pos": 61, "end_pos": 99, "type": "TASK", "confidence": 0.8139591693878174}]}, {"text": "Furthermore, we try to avoid using any additional or third-party tools for part of speech tagging and try to develop a simplistic approach that is based only on using the training data.", "labels": [], "entities": [{"text": "speech tagging", "start_pos": 83, "end_pos": 97, "type": "TASK", "confidence": 0.7778482139110565}]}], "datasetContent": [{"text": "We considered two datasets: 1.", "labels": [], "entities": []}, {"text": "Zaliznyak's Russian Grammar Dictionary, which lists over 100,000 lexemes.", "labels": [], "entities": [{"text": "Russian Grammar Dictionary", "start_pos": 12, "end_pos": 38, "type": "DATASET", "confidence": 0.6254282792409261}]}, {"text": "Each lexeme and its wordforms are stressed.", "labels": [], "entities": []}, {"text": "The dictionary was split into a train and test datasets in a 2:1 ratio, so that all forms of one lexeme belong either to the train or to the test dataset and no lexeme belongs to both.", "labels": [], "entities": []}, {"text": "We've assigned the name Dictionary Model (DictM) to the RNN trained on this dataset.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Word length in syllables and the number  of correct detections for Dictionary Model", "labels": [], "entities": []}, {"text": " Table 2: Word length in syllables and the number  of correct detections for Context Free Model", "labels": [], "entities": [{"text": "Context Free", "start_pos": 77, "end_pos": 89, "type": "TASK", "confidence": 0.8331215679645538}]}, {"text": " Table 3: Word length in syllables and the num- ber of correct detections for Context Dependant  Model", "labels": [], "entities": []}, {"text": " Table 4: CFM score on 50 homograph pairs", "labels": [], "entities": [{"text": "CFM", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.7627073526382446}]}, {"text": " Table 5: CDM score on 50 homograph pairs", "labels": [], "entities": []}, {"text": " Table 6: CDM and CFM detailed results for some  of the homograph pairs", "labels": [], "entities": [{"text": "CFM", "start_pos": 18, "end_pos": 21, "type": "DATASET", "confidence": 0.7653017044067383}]}]}