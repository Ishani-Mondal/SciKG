{"title": [{"text": "Distributed Representation, LDA Topic Modelling and Deep Learning for Emerging Named Entity Recognition from Social Media", "labels": [], "entities": [{"text": "LDA Topic Modelling", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.5870652198791504}, {"text": "Emerging Named Entity Recognition", "start_pos": 70, "end_pos": 103, "type": "TASK", "confidence": 0.661900669336319}]}], "abstractContent": [{"text": "This paper reports our participation in the W-NUT 2017 shared task on emerging and rare entity recognition from user generated noisy text such as tweets, online reviews and forum discussions.", "labels": [], "entities": [{"text": "W-NUT 2017 shared task on emerging and rare entity recognition from user generated noisy text such as tweets, online reviews and forum discussions", "start_pos": 44, "end_pos": 190, "type": "TASK", "confidence": 0.6783103048801422}]}, {"text": "To accomplish this challenging task, we explore an approach that combines LDA topic modelling with deep learning on word level and character level embeddings.", "labels": [], "entities": [{"text": "LDA topic modelling", "start_pos": 74, "end_pos": 93, "type": "TASK", "confidence": 0.8685527046521505}]}, {"text": "The LDA topic modelling generates topic representation for each tweet which is used as a feature for each word in the tweet.", "labels": [], "entities": [{"text": "LDA topic modelling", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.5503902832667033}]}, {"text": "The deep learning components consist of two-layer bidirectional LSTM and a CRF output layer.", "labels": [], "entities": []}, {"text": "Our submitted result performed at 39.98 (F1) on entity and 37.77 on surface forms.", "labels": [], "entities": [{"text": "F1", "start_pos": 41, "end_pos": 43, "type": "METRIC", "confidence": 0.9982028007507324}]}, {"text": "Our new experiments after submission reached a best performance of 41.81 on entity and 40.57 on surface forms.", "labels": [], "entities": []}], "introductionContent": [{"text": "The shared task Emerging and Rare Entity Recognition at the 3rd Workshop on Noisy Usergenerated Text (W-NUT 2017) takes on the challenge of identifying unusual, previously-unseen entities in noisy texts such as tweets, online reviews and other social discussions (http://noisytext.github.io/2017/emerging-rare-entities.html).", "labels": [], "entities": [{"text": "Emerging and Rare Entity Recognition at the 3rd Workshop on Noisy Usergenerated Text (W-NUT 2017)", "start_pos": 16, "end_pos": 113, "type": "TASK", "confidence": 0.7974714321248672}]}, {"text": "The emergent nature of novel named entities in user generated content and the often very creative natural of their surface forms make the task of automatic detection of such entities particularly difficult.", "labels": [], "entities": []}, {"text": "To address such challenges, the shared task organizer prepared training, development and test datasets and provided to the participants.", "labels": [], "entities": []}, {"text": "The datasets try to \"resemble turbulent data containing few repeated entities, drawn from rapidlychanging text types or sources of non-mainstream entities\".", "labels": [], "entities": []}, {"text": "Results from the shared task are evaluated using F1 measures on the entities and surface forms found in the test data.", "labels": [], "entities": [{"text": "F1", "start_pos": 49, "end_pos": 51, "type": "METRIC", "confidence": 0.998754620552063}]}, {"text": "It rewards systems at correctly detecting a diverse range of entities rather than only the frequent ones.", "labels": [], "entities": []}, {"text": "Inspired by the work of Limsopatham and Collier (2016, winner of w-nut 2016 shared task on Named Entity Recognition in Twitter),, and, we approached this shared task with bidirectional LSTM models (Long Short Term Memory recurrent neural network model) enhanced by CRF output layer, using both character-level and wordlevel embeddings as inputs.", "labels": [], "entities": [{"text": "Named Entity Recognition in Twitter)", "start_pos": 91, "end_pos": 127, "type": "TASK", "confidence": 0.7098108679056168}]}, {"text": "In addition, different from the study of, we didn't make use of orthographic features of characters but tried to incorporate POS tags as well as document topics extracted from LDA topic modelling as optional inputs to the modelling process.", "labels": [], "entities": []}, {"text": "The LDA topic modelling generates topic representation for each tweet which is used as a feature for each word in the tweet.", "labels": [], "entities": [{"text": "LDA topic modelling", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.5503902832667033}]}, {"text": "Our submitted result performed at 39.98 (F1) on entity and 37.77 (F1) on surface forms, using 10% of the combined training and development set for validation.", "labels": [], "entities": [{"text": "F1", "start_pos": 41, "end_pos": 43, "type": "METRIC", "confidence": 0.9981338381767273}, {"text": "F1", "start_pos": 66, "end_pos": 68, "type": "METRIC", "confidence": 0.9954758286476135}]}, {"text": "After submission, we continued with more experiments, using data combining the training set and development set in training process, with ground truth available that helps the selection of the results.", "labels": [], "entities": []}, {"text": "Our best result reached a performance of 41.81 on entity and 40.57 on surface forms.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we report two sets of experiments and results.", "labels": [], "entities": []}, {"text": "Results from the 1 st set of experiments were submitted to the shared task organizer for evaluation.", "labels": [], "entities": []}, {"text": "The 2 nd set of experiments are done after the submission.", "labels": [], "entities": []}, {"text": "Using the ground truth released by the organizer we evaluated the results directly by ourselves.", "labels": [], "entities": []}, {"text": "The ground truth being available also helps us in identifying the best model.", "labels": [], "entities": []}, {"text": "To train the model, the training set and the dev sets are merged, of which 10% (in terms of size, about half of the original dev set) are used for validation.", "labels": [], "entities": []}, {"text": "We used a batch size of 32 for training, and the RMSprop optimizer with an initial leaning rate of 0.001.", "labels": [], "entities": [{"text": "leaning rate", "start_pos": 83, "end_pos": 95, "type": "METRIC", "confidence": 0.9288558065891266}]}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "The results from all participating systems are presented in).", "labels": [], "entities": []}, {"text": "The overall performance of our system reached 39.98 on entities and 37.77 on surface forms.", "labels": [], "entities": []}, {"text": "The performance on Person and Location types of entities and surface forms are comparatively better, with F1 score at 55,88 and 47,38 respectively for entities, and F1 score at 53.30 and 42.80 for their surface forms.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9848543405532837}, {"text": "F1 score", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.9892613589763641}]}, {"text": "The system is less effective on identifying Corporation, Product, Creative-work and Group types of entities and surface forms, especially disappointing in terms of recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 164, "end_pos": 170, "type": "METRIC", "confidence": 0.9987660646438599}]}, {"text": "For Creative-work and Product type entities, recall only reached 9.86% and 11.02% respectively.", "labels": [], "entities": [{"text": "recall", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.9998072981834412}]}, {"text": "After submission, we continued our modelling work with new training strategies.", "labels": [], "entities": []}, {"text": "In terms of the data, all samples of the training set and dev set are used for training the model, which is then directly applied to test set.", "labels": [], "entities": []}, {"text": "We also experimented more with different options of the number of topics in LDA topic modelling.", "labels": [], "entities": [{"text": "LDA topic modelling", "start_pos": 76, "end_pos": 95, "type": "TASK", "confidence": 0.9320864876111349}]}, {"text": "We found that incorporating LDA features does have a positive effect on the performance.", "labels": [], "entities": []}, {"text": "We used models with topic counts in the range of.", "labels": [], "entities": []}, {"text": "The results (FB1 value for entity and surface forms) are illustrated in  When topic number set as 150, breakdown of the performance shows that the system performed best for the more difficult entity types and surface forms, as is shown in", "labels": [], "entities": [{"text": "FB1", "start_pos": 13, "end_pos": 16, "type": "METRIC", "confidence": 0.998233437538147}]}], "tableCaptions": [{"text": " Table 1. The shared task  focuses on discovering 6 types of target entities  and surface forms of: Corporation, Creative-Work,  Group, Location,", "labels": [], "entities": []}, {"text": " Table 2: Our submitted results", "labels": [], "entities": []}, {"text": " Table 3: Submitted results, all participants", "labels": [], "entities": []}, {"text": " Table 4: Performance variation related with number of  topics for LDA modelling", "labels": [], "entities": [{"text": "LDA", "start_pos": 67, "end_pos": 70, "type": "TASK", "confidence": 0.9691386222839355}]}, {"text": " Table 5. For Creative-work  and Product type entities, recall reached 15.49%  and 14.96% respectively. For their surface forms,  recall reached 16.18% and 16.24% respectively.", "labels": [], "entities": [{"text": "recall", "start_pos": 56, "end_pos": 62, "type": "METRIC", "confidence": 0.9998098015785217}, {"text": "recall", "start_pos": 130, "end_pos": 136, "type": "METRIC", "confidence": 0.9995806813240051}]}, {"text": " Table 5: Performance on different types of entities,  number of topics for LDA modelling = 150", "labels": [], "entities": [{"text": "LDA modelling", "start_pos": 76, "end_pos": 89, "type": "TASK", "confidence": 0.9194216132164001}]}]}