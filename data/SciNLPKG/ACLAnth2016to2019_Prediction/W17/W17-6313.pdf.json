{"title": [{"text": "Effective Online Reordering with Arc-Eager Transitions", "labels": [], "entities": [{"text": "Effective Online Reordering", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6187135279178619}]}], "abstractContent": [{"text": "We present anew transition system with word reordering for unrestricted non-projective dependency parsing.", "labels": [], "entities": [{"text": "unrestricted non-projective dependency parsing", "start_pos": 59, "end_pos": 105, "type": "TASK", "confidence": 0.750022828578949}]}, {"text": "Our system is based on decomposed arc-eager rather than arc-standard, which allows more flexible ambiguity resolution between a local projective and non-local crossing attachment.", "labels": [], "entities": []}, {"text": "In our experiment on Universal Dependencies 2.0, we find our parser outperforms the ordinary swap-based parser particularly on languages with a large amount of non-projectivity.", "labels": [], "entities": []}], "introductionContent": [{"text": "A dependency tree as illustrated in is called a non-projective tree, which contains discontinuous subtrees and is informally remarked with crossing arcs (arcs from idea 4 to talking 8 and from who 5 to to 9 ).", "labels": [], "entities": []}, {"text": "Comparing to the class of projective trees, which has a weak equivalence to the context-free grammars, parsing non-projective trees is generally involved.", "labels": [], "entities": []}, {"text": "This is particularly the case for transition-based dependency parsing; contrary to the graph-based approaches, in which a simple spanning-tree algorithm is capable of handling them), due to the incremental nature, transition-based parsers need some extra mechanisms to find crossing arcs.", "labels": [], "entities": [{"text": "transition-based dependency parsing", "start_pos": 34, "end_pos": 69, "type": "TASK", "confidence": 0.6137879689534506}]}, {"text": "There are several attempts to handle crossing arcs in transition-based parsers.", "labels": [], "entities": []}, {"text": "Among them online reordering with swap) has a number of appealing properties, of which the most notable is that it inherits the standard architecture of the transition systems using a stack and buffer while covering all types of crossing arcs.", "labels": [], "entities": []}, {"text": "This simplicity allows us to incorporate the ideas developed for the standard projective parsers, such as neural network architectures, and joint modeling with other phenomena, with a minimal effort.", "labels": [], "entities": []}, {"text": "Such extensions with swap include a recent nonprojective neural parser () and joint system with POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 96, "end_pos": 107, "type": "TASK", "confidence": 0.6912109553813934}]}, {"text": "Other approaches often employ additional data structures with non-trivial transitions, which interfere with the transparency to the standard systems, or cannot handle all crossing arcs).", "labels": [], "entities": []}, {"text": "Despite the popularity of the swap system, to our knowlege there is little work focusing on the swap mechanism, or the transition system itself, apart from the original proposal.", "labels": [], "entities": []}, {"text": "In other words, we are still unsure whether the current swap mechanism is the best strategy for handling crossing arcs with word reordering.", "labels": [], "entities": []}, {"text": "In this work, we present a dependency parser with anew transition system that employs swapbased reordering but in a different manner from the existing one) built on the arcstandard system.", "labels": [], "entities": []}, {"text": "As we discuss (Section 2.2), in Nivre's transition system, choosing a correct swap transition is sometimes hard due to the parser's preference to local attachments.", "labels": [], "entities": []}, {"text": "The proposed system (Section 3) alleviates this difficulty by allowing a swap transition fora token that is already linked on the stack.", "labels": [], "entities": []}, {"text": "As we will see, it can be seen as an extension to the arc-eager system while we divide each attachment transition into two more primitive operations as in the divided formulation of.", "labels": [], "entities": []}, {"text": "The divided system is more flexible, and by operating swap on this we can deal with the issue of reordering at an appropriate step.", "labels": [], "entities": []}, {"text": "On this transition system we implement a pars-ing model with the stack LSTMs ( ) (Section 4).", "labels": [], "entities": []}, {"text": "We extensively examine the utility of new transition system (Section 5) with the recently released Universal Dependencies (UD) 2.0 dataset, which contains more than 60 treebanks with varying degree of non-projectivity, and find that our system is superior to the ordinary swap system particularly for languages with a larger amount of non-projectivity.", "labels": [], "entities": [{"text": "Universal Dependencies (UD) 2.0 dataset", "start_pos": 99, "end_pos": 138, "type": "DATASET", "confidence": 0.5886217994349343}]}], "datasetContent": [{"text": "Data We use the 63 treebanks in 45 languages in Universal Dependencies 2.0 (, which are distributed with the training data in the recent shared task in.", "labels": [], "entities": []}, {"text": "Following the shared task, we focus on real world parsing and assume the raw input text.", "labels": [], "entities": []}, {"text": "For all preprocessing (sentence segmantion, tokenization, and tagging), we use UDpipe 1.1 (.", "labels": [], "entities": []}, {"text": "We report the official F1 LAS used in the shared task.", "labels": [], "entities": [{"text": "F1 LAS", "start_pos": 23, "end_pos": 29, "type": "METRIC", "confidence": 0.5475084185600281}]}, {"text": "Baseline To make a comparison between transition systems fair, we implement the arc-standard lazy swap (ASS) parser) with almost the same settings as our stay-eager swap (SES) parser including our network architecture (Section 4.2).", "labels": [], "entities": []}, {"text": "We also report the scores of UD-pipe 1.1, the baseline system in the shared task, although the results may not be directly comparable as they tune several settings including the oracle and learning rate etc.", "labels": [], "entities": []}, {"text": "Settings Our network sizes are: 100 dimensional word embeddings and LSTMs, 50 dimentional POS, XPOS, and FEATS embeddings, and 20 dimensional action and label embeddings, and 32 dimensional character embeddings and biLSTMs.", "labels": [], "entities": [{"text": "FEATS", "start_pos": 105, "end_pos": 110, "type": "METRIC", "confidence": 0.9523964524269104}]}, {"text": "We do not use any pre-trained embeddings.", "labels": [], "entities": []}, {"text": "We use Adam () for the optimizer, and set the learning decay of 0.08 and the dropout ratio in LSTMs of 0.33.", "labels": [], "entities": [{"text": "learning decay", "start_pos": 46, "end_pos": 60, "type": "METRIC", "confidence": 0.9012504816055298}]}, {"text": "In addition to the greedy search, we also try beam search for learning and decoding (beam size is 8).", "labels": [], "entities": []}, {"text": "Note that due to swap, each transition sequence may have a different number of actions.", "labels": [], "entities": []}, {"text": "We alleviate this inconsistency by ranking with the average scores).", "labels": [], "entities": []}, {"text": "For non-static oracles, we set both probabilities to postpone RD and SR root to 0.33, which works well for the development set.", "labels": [], "entities": [{"text": "RD", "start_pos": 62, "end_pos": 64, "type": "METRIC", "confidence": 0.532593309879303}, {"text": "SR root", "start_pos": 69, "end_pos": 76, "type": "METRIC", "confidence": 0.8189497590065002}]}], "tableCaptions": [{"text": " Table 2: A static oracle for our transition system. A g is the set of gold arcs. \u00b7 means an arbitrary value.", "labels": [], "entities": []}, {"text": " Table 4: LAS of all sentences and of only non-projective sentences ordered by the ratio of non-projective  sentences in the test data. The scores in brackets are the results with beam search.", "labels": [], "entities": [{"text": "LAS", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9919418096542358}]}]}