{"title": [{"text": "Normalization of Social Media Text using Deep Neural Networks", "labels": [], "entities": [{"text": "Normalization of Social Media Text", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8777446746826172}]}], "abstractContent": [{"text": "This paper sets out to investigate ways of normalizing noisy text that appear on social media platforms like Facebook, Twitter, Whatsapp, etc.", "labels": [], "entities": [{"text": "normalizing noisy text that appear on social media platforms", "start_pos": 43, "end_pos": 103, "type": "TASK", "confidence": 0.8627026544676887}, {"text": "Whatsapp", "start_pos": 128, "end_pos": 136, "type": "DATASET", "confidence": 0.8982000946998596}]}, {"text": "We proposed a deep learning based approach to text normalization using Recurrent Neural Network (RNN) based Encoder-Decoder architecture with Long Short Term Memory (LSTM).", "labels": [], "entities": [{"text": "text normalization", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.7798910140991211}]}, {"text": "To circumvent the unavailability of suitable large noisy-clean parallel dataset, we developed synthetic datasets.", "labels": [], "entities": []}, {"text": "We trained and evaluated the proposed model on our synthetic datasets and the WNUT 1 shared task dataset.", "labels": [], "entities": [{"text": "WNUT 1 shared task dataset", "start_pos": 78, "end_pos": 104, "type": "DATASET", "confidence": 0.8741135716438293}]}, {"text": "The uniqueness of our approach is in the use of synthetic datasets in a transfer learning approach for improving the performance of text normalization based on deep neural models.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 132, "end_pos": 150, "type": "TASK", "confidence": 0.7859518826007843}]}, {"text": "Our transfer learning based deep neural model produced state-of-the-art results (F1 score 0.9098) outperforming the previous best performing model on the WNUT test set by 7%.", "labels": [], "entities": [{"text": "F1 score 0.9098", "start_pos": 81, "end_pos": 96, "type": "METRIC", "confidence": 0.976233164469401}, {"text": "WNUT test set", "start_pos": 154, "end_pos": 167, "type": "DATASET", "confidence": 0.9754116932551066}]}], "introductionContent": [{"text": "There is a large quantity of user-generated content on the web, characterized by social media, creativity and individuality, which has created problems at two levels.", "labels": [], "entities": []}, {"text": "Firstly, social media text is often unsuitable for various Natural Language Processing (NLP) tasks, such as Information Retrieval, Machine Translation, Opinion Mining, etc., due to the irregularities found in such content.", "labels": [], "entities": [{"text": "Information Retrieval", "start_pos": 108, "end_pos": 129, "type": "TASK", "confidence": 0.7898331880569458}, {"text": "Machine Translation", "start_pos": 131, "end_pos": 150, "type": "TASK", "confidence": 0.8128281533718109}, {"text": "Opinion Mining", "start_pos": 152, "end_pos": 166, "type": "TASK", "confidence": 0.7257212698459625}]}, {"text": "Secondly, nonnative speakers of English, older Internet users and non-members of the in-groups often find such texts difficult to comprehend.", "labels": [], "entities": []}, {"text": "Prompt use of Internet and the resulting noisy user generated text found in different social media platforms such as social networking sites, blogs, etc., cause a hindrance in https://noisy-text.github.io/2015/norm-shared-task.html understanding casual written English, which often does not conform to the rules of spelling, grammar and punctuation.", "labels": [], "entities": []}, {"text": "In this paper, we present an approach for text normalization of social media text.", "labels": [], "entities": [{"text": "text normalization of social media text", "start_pos": 42, "end_pos": 81, "type": "TASK", "confidence": 0.8375480969746908}]}, {"text": "Our approach uses a sequence to sequence model () in which we tried Recurrent Neural Network (RNN) based encoder-decoder approach () with Long Short Term Memory (LSTM).", "labels": [], "entities": []}, {"text": "The use of LSTMs for text normalization in the present work is motivated by.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.790155678987503}]}, {"text": "We take a character based LSTM approach motivated by the work of () who showed that character based approach is superior to word based approach for neural network based sequence to sequence modelling tasks 2 . Our LSTM model was trained with attention mechanism ().", "labels": [], "entities": []}], "datasetContent": [{"text": "We crawled 500K sentences from different news domain websites such as Fox News 5 , The Guardian 6 , Yahoo News 7 and CNN News 8 and then with the help of Peter Norvig's corpus we prepared a synthetic noisy dataset by replacing some words in each sentence with their corresponding misspelled words, if found in the Peter Norvig corpus.", "labels": [], "entities": [{"text": "Fox News 5 , The Guardian 6", "start_pos": 70, "end_pos": 97, "type": "DATASET", "confidence": 0.728488198348454}, {"text": "Peter Norvig corpus", "start_pos": 314, "end_pos": 333, "type": "DATASET", "confidence": 0.6837464372316996}]}, {"text": "If there exist multiple misspelled versions for the same word in the Peter Norvig corpus, then the choice of misspelled word was taken randomly.", "labels": [], "entities": [{"text": "Peter Norvig corpus", "start_pos": 69, "end_pos": 88, "type": "DATASET", "confidence": 0.7870229681332906}]}, {"text": "Since many of the sentences were very long in the crawled corpus, we broke them (both the original sentence and the corresponding noisy sentence) down to sequences of five-grams in order to keep the sequence length shorter.", "labels": [], "entities": []}, {"text": "Here sequence length refers to the number of characters in a sequence.", "labels": [], "entities": [{"text": "sequence length", "start_pos": 5, "end_pos": 20, "type": "METRIC", "confidence": 0.6746447384357452}]}, {"text": "Thus, we created a synthetic parallel dataset, Synthetic 1 , and shows how our parallel synthetic dataset look like, in which the misspelled words are shown as underlined.", "labels": [], "entities": []}, {"text": "We also created another synthetic dataset (Synthetic 2 ) using a Chat Conversation dataset 9 in a similar manner, however, with two noticeable changes.", "labels": [], "entities": [{"text": "Chat Conversation dataset 9", "start_pos": 65, "end_pos": 92, "type": "DATASET", "confidence": 0.6954024583101273}]}, {"text": "For this dataset we did not split the sequence into n-grams because in this dataset sequence length was not too large as compared to Synthetic 1 dataset and we took the help of all the four dictionaries to create the parallel dataset.", "labels": [], "entities": [{"text": "Synthetic 1 dataset", "start_pos": 133, "end_pos": 152, "type": "DATASET", "confidence": 0.7955138683319092}]}, {"text": "The chat conversation dataset belongs to the Cornell Movie Dialogue dataset (Danescu-NiculescuMizil and Lee, 2011) and it contains conversational data extracted from movie scripts.", "labels": [], "entities": [{"text": "Cornell Movie Dialogue dataset", "start_pos": 45, "end_pos": 75, "type": "DATASET", "confidence": 0.9561368077993393}]}, {"text": "The dataset was Raw Corpus ...", "labels": [], "entities": [{"text": "Raw Corpus", "start_pos": 16, "end_pos": 26, "type": "DATASET", "confidence": 0.9933740496635437}]}, {"text": "The government guidance will be reviewed early next year after a period of public comment ...", "labels": [], "entities": []}, {"text": "The government guidance will be reviewed government guidance will be reviewed guidance will be reviewed early will be reviwed early next be reviewed early next year reviewed early next year after ...", "labels": [], "entities": []}, {"text": "The govment guidence will be reviewed guverment guidence we'll be reviewed guidance wil be reviewed erly wiull be reviewed eigly next be reviewed erly enxt yeer reviewed erly nexst year afert ...: A snapshot of the Synthetic 1 dataset originally built for building chat systems.", "labels": [], "entities": [{"text": "Synthetic 1 dataset", "start_pos": 215, "end_pos": 234, "type": "DATASET", "confidence": 0.6983254154523214}]}, {"text": "We constructed our synthetic data from this raw data.", "labels": [], "entities": []}, {"text": "With Synthetic 2 , our main motive was to build a very noisy dataset containing errors that are typical to social media.", "labels": [], "entities": []}, {"text": "Therefore, we replaced as many words as we could find in the two WNUT dictionaries and our social media dictionary.", "labels": [], "entities": [{"text": "WNUT dictionaries", "start_pos": 65, "end_pos": 82, "type": "DATASET", "confidence": 0.9452486634254456}]}, {"text": "At last, we checked if any of the non-replaced words in a sequence occurs in keys of the Peter Norvig corpus, and if found, they were also replaced with a corresponding (randomly chosen) misspelled word.", "labels": [], "entities": [{"text": "Peter Norvig corpus", "start_pos": 89, "end_pos": 108, "type": "DATASET", "confidence": 0.7464598814646403}]}, {"text": "Thus, we created the parallel dataset Synthetic 2 reflecting errors typical of social media text.", "labels": [], "entities": []}, {"text": "A snapshot of the Synthetic 2 dataset is shown in.", "labels": [], "entities": [{"text": "Synthetic 2 dataset", "start_pos": 18, "end_pos": 37, "type": "DATASET", "confidence": 0.7358462413152059}]}, {"text": "Other than these synthetic datasets, we also used the standard training dataset released by the WNUT 2015 shared task on \"Normalization of Noisy Text\".", "labels": [], "entities": [{"text": "WNUT 2015 shared task", "start_pos": 96, "end_pos": 117, "type": "DATASET", "confidence": 0.8250738382339478}, {"text": "Normalization of Noisy Text", "start_pos": 122, "end_pos": 149, "type": "TASK", "confidence": 0.8902651369571686}]}, {"text": "This dataset consists of real Twitter data containing different types of abbreviations used and errors made in social media conversations.", "labels": [], "entities": []}, {"text": "Thus, we ended up with three different datasets 10 -Synthetic 1 , Synthetic 2 and WNUT.", "labels": [], "entities": [{"text": "WNUT", "start_pos": 82, "end_pos": 86, "type": "DATASET", "confidence": 0.8631894588470459}]}, {"text": "presents the dataset statistics of all the datasets that we used to train and evaluate our models.", "labels": [], "entities": []}, {"text": "Before loading the datasets for experiments, we padded the data.", "labels": [], "entities": []}, {"text": "For faster computation, input sequences were divided into number of batches.", "labels": [], "entities": []}, {"text": "Since there were variations in sequence length, we padded the data to make them all having uniform length.", "labels": [], "entities": []}, {"text": "\"EOS\" token was kept at the end of each sequence, to identify its end.", "labels": [], "entities": [{"text": "EOS", "start_pos": 1, "end_pos": 4, "type": "METRIC", "confidence": 0.816128134727478}]}, {"text": "Shorter length sequences were padded with trailing zeros.", "labels": [], "entities": []}, {"text": "We used word2index dictionary containing key as all characters and numbers as their indices.", "labels": [], "entities": []}, {"text": "\"EOS\" and \"PAD\" were given \"0\" and \"1\" index respectively.", "labels": [], "entities": [{"text": "EOS", "start_pos": 1, "end_pos": 4, "type": "METRIC", "confidence": 0.9104270935058594}, {"text": "PAD", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.9750170707702637}]}, {"text": "The length of this dictionary was 98.", "labels": [], "entities": [{"text": "length", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9794660806655884}]}, {"text": "The synthetic data and the dictionaries mentioned in Section 4.1 will be made publicly available for research upon publication of the paper.", "labels": [], "entities": []}, {"text": "Our models were built using deep learning library Tensorflow 11 . TensorFlow allows to efficiently perform specific machine learning numbercrunching operations like derivatives on huge matrices . With Tensorflow, processing can be easily distributed across CPU cores, GPU cores, or multiple devices like multiple GPUs and even across a distributed network of computers.", "labels": [], "entities": []}, {"text": "Python 12 was used for preparation of the dataset as mentioned in section 4.2 and scripting of the models.", "labels": [], "entities": []}, {"text": "Accordingly, we evaluated the proposed models using precision, recall and F1-score.", "labels": [], "entities": [{"text": "precision", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.9996904134750366}, {"text": "recall", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.9996539354324341}, {"text": "F1-score", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9991387128829956}]}, {"text": "In the context of text normalization, true positives refer to cases where incorrect words are replaced by the correct words, and true negatives represent correct words being left as they are.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.743046909570694}]}, {"text": "False positives concern cases when the model replaces a correct word by an incorrect word.", "labels": [], "entities": []}, {"text": "False negatives pertain two cases when the model either does not provide any correction or provides a wrong correction for an incorrect word.", "labels": [], "entities": []}, {"text": "shows the evaluation results of all the experiments mentioned in Section 5.", "labels": [], "entities": []}, {"text": "For the benefit of comparison, groups these results into two subsets -the ones evaluated on the synthetic test sets and the others evaluated on the WNUT test set.", "labels": [], "entities": [{"text": "WNUT test set", "start_pos": 148, "end_pos": 161, "type": "DATASET", "confidence": 0.9765967528025309}]}, {"text": "It is to be noted here that the models trained only with the synthetic data (M 1 , M 2 and M 3 ) are not meant to be evaluated with the WNUT test set, however, for the sake of comparison, we also evaluated these models on the the WNUT test set.", "labels": [], "entities": [{"text": "WNUT test set", "start_pos": 136, "end_pos": 149, "type": "DATASET", "confidence": 0.9682569106419882}, {"text": "WNUT test set", "start_pos": 230, "end_pos": 243, "type": "DATASET", "confidence": 0.9863796830177307}]}, {"text": "Among the experiments carried out only with synthetic datasets, the best result (F1 Score = 0.9205) was achieved with M 1 . The other models trained on other synthetic datasets, M 2 and M 3 , could not achieve similar results since M 2 and M 3 could not be trained much due to their large sequence length.", "labels": [], "entities": [{"text": "F1 Score = 0.9205)", "start_pos": 81, "end_pos": 99, "type": "METRIC", "confidence": 0.9366645216941833}]}, {"text": "However, it is to be noted that only the Peter Norvig spelling error corpus was used on news domain data to introduce noise and prepare the Synthetic 1 dataset, while all the four dictionaries were employed to introduce noise in conversational data to prepare the Synthetic 2 dataset.", "labels": [], "entities": [{"text": "Norvig spelling error corpus", "start_pos": 47, "end_pos": 75, "type": "DATASET", "confidence": 0.6185169741511345}, {"text": "Synthetic 1 dataset", "start_pos": 140, "end_pos": 159, "type": "DATASET", "confidence": 0.7910794814427694}, {"text": "Synthetic 2 dataset", "start_pos": 264, "end_pos": 283, "type": "DATASET", "confidence": 0.7139246066411337}]}, {"text": "Therefore, Synthetic 2 dataset is much more reflective of social media data and hence more challenging.", "labels": [], "entities": [{"text": "Synthetic 2 dataset", "start_pos": 11, "end_pos": 30, "type": "DATASET", "confidence": 0.7045600016911825}]}, {"text": "Among M 2 and M 3 , since M 3 was trained on shorter sequences and was also trained for more epochs, it was able to produce better performance than M 2 . Then we evaluated our models on the WNUT dataset, the only standard dataset available for text normalization research.", "labels": [], "entities": [{"text": "WNUT dataset", "start_pos": 190, "end_pos": 202, "type": "DATASET", "confidence": 0.9804190993309021}, {"text": "text normalization", "start_pos": 244, "end_pos": 262, "type": "TASK", "confidence": 0.8574210107326508}]}, {"text": "Since the training dataset size was very small, the model (M 4 ) produced relatively low performance (F1 Score = 0.8223) even after training for 50 epochs.", "labels": [], "entities": [{"text": "F1 Score = 0.8223)", "start_pos": 102, "end_pos": 120, "type": "METRIC", "confidence": 0.9580581903457641}]}, {"text": "This relatively low performance can be attributed to the very small amount of training data (only 2,950 sentences) in the WNUT dataset; deep learning based models are known to perform poorly than traditional machine learning based methods on small training data.", "labels": [], "entities": [{"text": "WNUT dataset", "start_pos": 122, "end_pos": 134, "type": "DATASET", "confidence": 0.9813215732574463}]}, {"text": "However, this result is only next to the best result (F1 Score = 0.8421) achieved in the WNUT 2015 shared task () in the constrained category.", "labels": [], "entities": [{"text": "F1 Score", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9875766336917877}, {"text": "WNUT 2015 shared task", "start_pos": 89, "end_pos": 110, "type": "TASK", "confidence": 0.7303118258714676}]}, {"text": "M 5 , trained on a merged training set of Synthetic 3 and WNUT, produced better results on both the Synthetic 3 as well as WNUT test sets, which can be observed by comparing the performance of M 5 with M 3 and M 4 . Both M 6 and M 7 make use of transfer learning approach.", "labels": [], "entities": [{"text": "WNUT", "start_pos": 58, "end_pos": 62, "type": "DATASET", "confidence": 0.9184012413024902}, {"text": "WNUT test sets", "start_pos": 123, "end_pos": 137, "type": "DATASET", "confidence": 0.969429075717926}]}, {"text": "M 6 improves the model performance on the Synthetic 3 test set over M 3 , however, it could not improve over M 5 . On the other hand, M 6 could not beat the performance of M 4 on the WNUT test set.", "labels": [], "entities": [{"text": "Synthetic 3 test set", "start_pos": 42, "end_pos": 62, "type": "DATASET", "confidence": 0.805751383304596}, {"text": "WNUT test set", "start_pos": 183, "end_pos": 196, "type": "DATASET", "confidence": 0.9777753949165344}]}, {"text": "The reason behind this could be that M 6 is essentially a pre-trained model M 3 , trained on Synthetic 3 and further trained on the WNUT dataset.", "labels": [], "entities": [{"text": "WNUT dataset", "start_pos": 132, "end_pos": 144, "type": "DATASET", "confidence": 0.983103334903717}]}, {"text": "It is to be noticed however that it provides huge improvement over M 3 's performance on the WNUT testset.", "labels": [], "entities": [{"text": "WNUT testset", "start_pos": 93, "end_pos": 105, "type": "DATASET", "confidence": 0.9689600169658661}]}, {"text": "We changed the sequence of training in M 7 , i.e., first on WNUT and then on Synthetic 3 dataset, and also increased the batch size to 128.", "labels": [], "entities": [{"text": "M 7", "start_pos": 39, "end_pos": 42, "type": "DATASET", "confidence": 0.8176242113113403}, {"text": "WNUT", "start_pos": 60, "end_pos": 64, "type": "DATASET", "confidence": 0.9833734035491943}, {"text": "Synthetic 3 dataset", "start_pos": 77, "end_pos": 96, "type": "DATASET", "confidence": 0.8554909626642863}]}, {"text": "These changes improved the model performance significantly and provided the best performance on both the Synthetic 3 and WNUT test sets.", "labels": [], "entities": [{"text": "WNUT test sets", "start_pos": 121, "end_pos": 135, "type": "DATASET", "confidence": 0.8760136763254801}]}, {"text": "It provided an F1 Score of 0.9098 on the WNUT test set which outperforms the best result (F1 Score = 0.8421) reported in the WNUT shared task (.", "labels": [], "entities": [{"text": "F1 Score", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9912793636322021}, {"text": "WNUT test set", "start_pos": 41, "end_pos": 54, "type": "DATASET", "confidence": 0.9884241422017416}, {"text": "F1 Score", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9923419058322906}, {"text": "WNUT shared task", "start_pos": 125, "end_pos": 141, "type": "DATASET", "confidence": 0.8401854038238525}]}, {"text": "shows a comparison of the results obtained by our systems against the two top performing systems in the WNUT shared task in both constrained and unconstrained track.", "labels": [], "entities": [{"text": "WNUT shared task", "start_pos": 104, "end_pos": 120, "type": "DATASET", "confidence": 0.7703855037689209}]}, {"text": "Surprisingly, unconstrained systems were notable to outperform constrained systems in the WNUT shared task, as is also noted in (.", "labels": [], "entities": [{"text": "WNUT shared task", "start_pos": 90, "end_pos": 106, "type": "DATASET", "confidence": 0.7545111576716105}]}, {"text": "However, by making use of our synthetic training data and using a transfer learning approach, we were able to obtain state of the art results on the WNUT dataset.", "labels": [], "entities": [{"text": "WNUT dataset", "start_pos": 149, "end_pos": 161, "type": "DATASET", "confidence": 0.9850617945194244}]}, {"text": "Our models were able to correctly normalize social media specific errors and abbreviations.", "labels": [], "entities": [{"text": "normalize social media specific errors and abbreviations", "start_pos": 34, "end_pos": 90, "type": "TASK", "confidence": 0.8274262206895011}]}, {"text": "For example \"LOL\" was normalized to \"Laughing out Loud\" or \"Lots of Laughs\" depending upon the context, \"GM\" was normalized to \"Good Morning\", \"k\" to \"ok\" and soon.", "labels": [], "entities": [{"text": "LOL", "start_pos": 13, "end_pos": 16, "type": "METRIC", "confidence": 0.9362335801124573}, {"text": "GM", "start_pos": 105, "end_pos": 107, "type": "METRIC", "confidence": 0.9546631574630737}]}, {"text": "Among other types of social media errors, \"ohhhhhhhhhhhhhhhh\" was normalized to \"oh\", \"b4\" to \"before\", \"hiiiiiiiii\" to \"hi\", etc.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: A snapshot of Synthetic 2 dataset", "labels": [], "entities": [{"text": "Synthetic 2 dataset", "start_pos": 24, "end_pos": 43, "type": "DATASET", "confidence": 0.6474946240584055}]}, {"text": " Table 4: Results of different models on synthetic and WNUT datasets", "labels": [], "entities": [{"text": "WNUT datasets", "start_pos": 55, "end_pos": 68, "type": "DATASET", "confidence": 0.8645902872085571}]}]}