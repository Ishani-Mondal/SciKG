{"title": [{"text": "On the Creation of a Security-Related Event Corpus", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper reports on an effort of creating a corpus of structured information on security-related events automatically extracted from on-line news, part of which has been manually curated.", "labels": [], "entities": []}, {"text": "The main motivation behind this effort is to provide material to the NLP community working on event extraction that could be used both for training and evaluation purposes.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 94, "end_pos": 110, "type": "TASK", "confidence": 0.8100154399871826}]}], "introductionContent": [{"text": "Due to a rapid proliferation of textual information in digital form various security-related organisations have recently acknowledged the benefits of deploying techniques to automate the process of extraction of structured information on events from free texts).", "labels": [], "entities": [{"text": "extraction of structured information on events from free texts", "start_pos": 198, "end_pos": 260, "type": "TASK", "confidence": 0.7016777561770545}]}, {"text": "Examples of current capabilities of such techniques for the extraction of disease outbreaks, crisis situations, cross-border crimes and computer security events from on-line sources are given in (.", "labels": [], "entities": [{"text": "extraction of disease outbreaks", "start_pos": 60, "end_pos": 91, "type": "TASK", "confidence": 0.8665666431188583}]}, {"text": "This paper reports on the creation of a corpus of structured information on security-related events automatically extracted from online news over a period of 8 years, part of which has been manually curated.", "labels": [], "entities": []}, {"text": "The main drive behind this endeavour is to provide material to theNLP community working on event extraction, which could be used in various ways, e.g., for: (a) carrying out evaluations of detection and extraction of securityrelated events from online news (human-curated data), (b) training event type classifiers, (c) learning domain-specific terminology, (d) creating fullfledged inline or stand-off annotations with eventcentric information based on the automatically extracted event templates.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 91, "end_pos": 107, "type": "TASK", "confidence": 0.7163369953632355}, {"text": "evaluations of detection and extraction of securityrelated events from online news (human-curated data)", "start_pos": 174, "end_pos": 277, "type": "TASK", "confidence": 0.7843453963597615}]}, {"text": "Other efforts on the creation of corpora with event-related annotation of various nature include: GDELT ( ,), ICEWS (), EventCorefBank), ASTRE and.", "labels": [], "entities": [{"text": "GDELT", "start_pos": 98, "end_pos": 103, "type": "DATASET", "confidence": 0.6209601163864136}]}, {"text": "Contrary to most other initiatives our corpus contains aggregated information on events extracted at news cluster level without provision of links to concrete phrases in news articles from which the information was inferred.", "labels": [], "entities": []}, {"text": "Section 2 briefly presents our news event extraction system.", "labels": [], "entities": [{"text": "news event extraction", "start_pos": 31, "end_pos": 52, "type": "TASK", "confidence": 0.6216615239779154}]}, {"text": "Section 3 reports on an evaluation thereof to provide insights on the quality of extraction.", "labels": [], "entities": []}, {"text": "Section 4 provides some corpus statistics.", "labels": [], "entities": []}], "datasetContent": [{"text": "For the purpose of evaluating the performance of event extraction methods the research community has been predominantly using mention-based metrics and standards such as ACE (), where, e.g., the scores for extracted slot fillers are summed up over their mentions in text.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 49, "end_pos": 65, "type": "TASK", "confidence": 0.7349276691675186}, {"text": "ACE", "start_pos": 170, "end_pos": 173, "type": "METRIC", "confidence": 0.6473466157913208}]}, {"text": "However, motivated by the specific environment in which our event extraction system is used, we propose partly novel evaluation metrics that try to quantify from a user perspective the most relevant semantic dimensions of event information aggregated from multi-document sets.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 60, "end_pos": 76, "type": "TASK", "confidence": 0.7215368300676346}]}, {"text": "As an example, evaluating geo-coding as the task of locating events both on a geographical reference system and an administrative unit hierarchy (rather than as a standard entity recognition task () allows to estimate its usefulness for spatial analysis of aggregated event data.", "labels": [], "entities": []}, {"text": "For an analyst responsible for studying events that happened in a particular administrative region (e.g., country, state) an incorrect extraction of the place, although within the boundaries of the region assigned to him, still does provide some value, which should be awarded with a non-zero score.", "labels": [], "entities": []}, {"text": "We first introduce the metrics for the evaluation of event type and location extraction.", "labels": [], "entities": [{"text": "location extraction", "start_pos": 68, "end_pos": 87, "type": "TASK", "confidence": 0.7507926225662231}]}, {"text": "Let C = {c 1 , . .", "labels": [], "entities": []}, {"text": ", c n } denote the set of input clusters of articles.", "labels": [], "entities": []}, {"text": "Let also t c (l c ) denote the event type (location) for cluster c returned by the system.", "labels": [], "entities": []}, {"text": "For the evaluation of the event location extraction we define two basic metrics: Geographical Closeness (GC) and Administrative Closeness (AC) which are maximized over the gold truth locations.", "labels": [], "entities": [{"text": "event location extraction", "start_pos": 26, "end_pos": 51, "type": "TASK", "confidence": 0.6728298664093018}, {"text": "Administrative Closeness (AC)", "start_pos": 113, "end_pos": 142, "type": "METRIC", "confidence": 0.8983019232749939}]}, {"text": "3 http://www.geonames.org archy of geographical references.", "labels": [], "entities": []}, {"text": "Let T GEO denote the administrative hierarchy in the GeoNames gazetteer and let LCS(x, y) denote the lowest common subsumer for nodes x and yin T GEO . AC is then defined as follows: where \u03b4/2 i is a weighted depth of anode v in T GEO , with \u03b4 empirically set to 10.", "labels": [], "entities": [{"text": "GeoNames gazetteer", "start_pos": 53, "end_pos": 71, "type": "DATASET", "confidence": 0.96612948179245}, {"text": "LCS", "start_pos": 80, "end_pos": 83, "type": "METRIC", "confidence": 0.9654706120491028}]}, {"text": "The main intuition behind AC is to apply a higher penalty to system errors: (a) closer to the root of T GEO (e.g., guessing wrong country is worse than guessing wrong city within a province), and (b) resulting from providing over-specific, false information vis-a-vis system responses being not as specific, but still encompassing, gold truth location (e.g. guessing only the region of a gold truth town).", "labels": [], "entities": [{"text": "T GEO", "start_pos": 102, "end_pos": 107, "type": "METRIC", "confidence": 0.8416956663131714}]}, {"text": "We also compute Location Accuracy (LC) as a weighted harmonic mean of GC and AC, maximized over the gold truth locations: where \u03b2 was set to 1 in the evaluation.", "labels": [], "entities": [{"text": "Location Accuracy (LC)", "start_pos": 16, "end_pos": 38, "type": "METRIC", "confidence": 0.8565863370895386}]}, {"text": "For event slot descriptors we first distinguish two cases: definite description phrases are normalized and possibly merged to the morphological base forms of their noun/adjective components (e.g. 'three Iraqi militants' and 'Iraqi militants' are merged into 'Iraqi militant', while all uppercase phrases (supposedly person names) are kept as such.", "labels": [], "entities": []}, {"text": "In the former case, if descr c is a system output descriptor fora certain role of event in cluster c and descr G c is a gold standard descriptor for the same role, the match between descr c and descr G c is computed as: where descr N c and descr GN care the sets of all N-grams of descr c and descr G c , resp., and W U P (m, n) is a WordNet-based semantic relatedness measure (.", "labels": [], "entities": []}, {"text": "In the latter case, matches are computed as: where StringSim(m, n) is modification of the Jaro metric boosting agreeing initial characters).", "labels": [], "entities": []}, {"text": "In both cases, in order to penalize cases of role filler inversion, we score as 0 the matches of a system output role descriptor if it is lower than the max similarity with any of the other event role fillers in gold standard.", "labels": [], "entities": [{"text": "role filler inversion", "start_pos": 45, "end_pos": 66, "type": "TASK", "confidence": 0.8921061555544535}]}, {"text": "Given the scores above, standard Precision, Recall and F1 measure are computed.", "labels": [], "entities": [{"text": "Precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9988665580749512}, {"text": "Recall", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.9883223176002502}, {"text": "F1 measure", "start_pos": 55, "end_pos": 65, "type": "METRIC", "confidence": 0.9838833212852478}]}, {"text": "Finally, we record the root Mean Squared Error (MSE) of system output victim count values against gold standard, overall applicable roles 5 .", "labels": [], "entities": [{"text": "Mean Squared Error (MSE)", "start_pos": 28, "end_pos": 52, "type": "METRIC", "confidence": 0.9432596961657206}]}], "tableCaptions": [{"text": " Table 1: Evaluation results for event type and loca- tion extraction for the different event type subsets.", "labels": [], "entities": [{"text": "loca- tion extraction", "start_pos": 48, "end_pos": 69, "type": "TASK", "confidence": 0.6484331414103508}]}, {"text": " Table 2: Evaluation of descriptive/numerical slots.", "labels": [], "entities": []}, {"text": " Table 3: Quantitative data on the MOD event set.  The OTHER category includes all less frequent  event types; NONE stands for events which in- clude information on dead/injured, but whose type  does not match any predefined event types", "labels": [], "entities": [{"text": "MOD event set", "start_pos": 35, "end_pos": 48, "type": "DATASET", "confidence": 0.7180342276891073}, {"text": "OTHER", "start_pos": 55, "end_pos": 60, "type": "METRIC", "confidence": 0.590429425239563}, {"text": "NONE", "start_pos": 111, "end_pos": 115, "type": "METRIC", "confidence": 0.992037296295166}]}, {"text": " Table 4: Quantitative data on the AUTO set (num- bers of events are provided in thousands).", "labels": [], "entities": [{"text": "Quantitative", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.875267744064331}, {"text": "AUTO set", "start_pos": 35, "end_pos": 43, "type": "DATASET", "confidence": 0.8958542943000793}]}]}