{"title": [{"text": "A Neural Architecture for Dialectal Arabic Segmentation", "labels": [], "entities": [{"text": "Dialectal Arabic Segmentation", "start_pos": 26, "end_pos": 55, "type": "TASK", "confidence": 0.733273575703303}]}], "abstractContent": [{"text": "The automated processing of Arabic dialects is challenging due to the lack of spelling standards and the scarcity of annotated data and resources in general.", "labels": [], "entities": []}, {"text": "Segmentation of words into their constituent tokens is an important processing step for natural language processing.", "labels": [], "entities": [{"text": "Segmentation of words into their constituent tokens", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.8463843975748334}, {"text": "natural language processing", "start_pos": 88, "end_pos": 115, "type": "TASK", "confidence": 0.6522112389405569}]}, {"text": "In this paper, we show how a segmenter can be trained on only 350 annotated tweets using neural networks without any normalization or reliance on lexical features or linguistic resources.", "labels": [], "entities": []}, {"text": "We deal with segmenta-tion as a sequence labeling problem at the character level.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.6721527576446533}]}, {"text": "We show experimentally that our model can rival state-of-the-art methods that heavily depend on additional resources.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Arabic language has various dialects and variants that exist in a continuous spectrum.", "labels": [], "entities": []}, {"text": "This variation is a result of multiple morpho-syntactic processes of simplification and mutation, as well as coinage and borrowing of new words in addition to semantic shifts of standard lexical items.", "labels": [], "entities": []}, {"text": "Furthermore, there was a considerable effect of the interweave between the standard Arabic language that spread throughout the Middle East and North Africa and the indigenous languages in different countries as well as neighboring languages.", "labels": [], "entities": []}, {"text": "With the passage of time and the juxtaposition of cultures, dialects and variants of Arabic evolved and diverged.", "labels": [], "entities": []}, {"text": "Among the varieties of Arabic is socalled Modern Standard Arabic (MSA) which is the lingua franca of the Arab world, and is typically used in written and formal communications.", "labels": [], "entities": [{"text": "socalled Modern Standard Arabic (MSA)", "start_pos": 33, "end_pos": 70, "type": "TASK", "confidence": 0.448981306382588}]}, {"text": "On the other hand, Arabic dialects, such as Egyptian, Moroccan and Levantine, are usually spoken and used in informal communications.", "labels": [], "entities": []}, {"text": "The advent of the social networks and the spread of smart phones, yielded the need for dialectaware smart systems and motivated the research in Dialectal Arabic such as dialectal Arabic identification for both text) and speech (, morphological analysis () and machine translation ().", "labels": [], "entities": [{"text": "dialectal Arabic identification", "start_pos": 169, "end_pos": 200, "type": "TASK", "confidence": 0.6425018211205801}, {"text": "morphological analysis", "start_pos": 230, "end_pos": 252, "type": "TASK", "confidence": 0.7084981054067612}, {"text": "machine translation", "start_pos": 260, "end_pos": 279, "type": "TASK", "confidence": 0.7755229473114014}]}, {"text": "Due to the rich morphology in Arabic and its dialects, word segmentation is one of the most important processing steps.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.7714603543281555}]}, {"text": "Word segmentation is considered an integral part for many higher Arabic NLP tasks such as part-of-speech tagging, parsing and machine translation.", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6858054548501968}, {"text": "part-of-speech tagging", "start_pos": 90, "end_pos": 112, "type": "TASK", "confidence": 0.7168474197387695}, {"text": "parsing", "start_pos": 114, "end_pos": 121, "type": "TASK", "confidence": 0.950205385684967}, {"text": "machine translation", "start_pos": 126, "end_pos": 145, "type": "TASK", "confidence": 0.7800101339817047}]}, {"text": "For example, the Egyptian word \"wmktbhA$\" meaning: \"and he didn't write it\") includes four clitics surrounding the the verb (stem) \"ktb\", and is rendered after segmentation as \"w+m+ktb+hA+$\".", "labels": [], "entities": []}, {"text": "The clitics in this word are the coordinate conjunction \"w\", the negation prefix \"m\", the object pronoun \"hA\", and the post negative suffix \"$\".", "labels": [], "entities": []}, {"text": "In this paper, we present a dialectal Egyptian segmentater that utilizes Bidirectional LongShort-Term-Memory (BiLSTM) that is trained on limited dialectal data.", "labels": [], "entities": [{"text": "dialectal Egyptian segmentater", "start_pos": 28, "end_pos": 58, "type": "TASK", "confidence": 0.6004330416520437}, {"text": "Bidirectional LongShort-Term-Memory (BiLSTM", "start_pos": 73, "end_pos": 116, "type": "METRIC", "confidence": 0.8822755962610245}]}, {"text": "The approach was motivated by the scarcity of dialectal tools and resources.", "labels": [], "entities": []}, {"text": "The main contribution of this paper is that we build a segmenter of dialectal Egyptian using limited data without the need for specialized lexi-cal resources or deep linguistic knowledge that rivals state-of-the-art tools.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used the dataset described in ().", "labels": [], "entities": []}, {"text": "The data was used in a dialect identification task to distinguish between dialectal Egyptian and MSA.", "labels": [], "entities": [{"text": "dialect identification task", "start_pos": 23, "end_pos": 50, "type": "TASK", "confidence": 0.7837578455607096}]}, {"text": "It contains 350 tweets with more than 8,000 words including 3,000 unique words written in Egyptian dialect.", "labels": [], "entities": []}, {"text": "The tweets have much dialectal content covering most of dialectal Egyptian phonological, morphological, and syntactic phenomena.", "labels": [], "entities": []}, {"text": "It also includes Twitter-specific aspects of the text, such as #hashtags, @mentions, emoticons and URLs.", "labels": [], "entities": []}, {"text": "We manually annotated each word in this corpus to provide: CODA-compliant writing), segmentation, stem, lemma, and POS, also the corresponding MSA word, MSA segmentation, and MSA POS.", "labels": [], "entities": [{"text": "POS", "start_pos": 115, "end_pos": 118, "type": "METRIC", "confidence": 0.96260005235672}, {"text": "MSA segmentation", "start_pos": 153, "end_pos": 169, "type": "TASK", "confidence": 0.68183933198452}]}, {"text": "We make the dataset 2 available to researchers to reproduce the results and help in other tasks such as CODA'fication of dialectal text, dialectal POS tagging and dialect to MSA conversion.", "labels": [], "entities": [{"text": "dialectal POS tagging", "start_pos": 137, "end_pos": 158, "type": "TASK", "confidence": 0.616950124502182}, {"text": "dialect to MSA conversion", "start_pos": 163, "end_pos": 188, "type": "TASK", "confidence": 0.5803073793649673}]}, {"text": "shows an annotation ex-ample of the word \"byqwlk\" (he is saying to you).", "labels": [], "entities": []}, {"text": "For the purpose of this paper, we skip CODA'fication, and conduct segmentation on the original words to increase the robustness of the system.", "labels": [], "entities": []}, {"text": "Therefore, the segmentation of the example in is given as b+yqw+l+k.", "labels": [], "entities": []}, {"text": "We need also to note that, by design, the perfective prefixes are not separated from verbs in the current work.", "labels": [], "entities": []}, {"text": "We split the data described in section 4 into 75 sentences for testing, 75 for development and the remaining 200 for training.", "labels": [], "entities": []}, {"text": "The concept We followed in LSTM sequence labeling is that segmentation is one-to-one mapping at the character level where each character is annotated as either beginning a segment (B), continues a previous segment (M), ends a segment (E), or is a segment by itself (S).", "labels": [], "entities": [{"text": "LSTM sequence labeling", "start_pos": 27, "end_pos": 49, "type": "TASK", "confidence": 0.8774031599362692}]}, {"text": "After the labeling is complete we merge the characters and labels together, for example byqwlwA is labeled as \"SBMMEBE\", which means that the word is segmented as b+yqwl+wA.", "labels": [], "entities": []}, {"text": "We compar results of our two LSTM models (BiLSTM and BiLSTM-CRF) with Farasa (, an open source segementer for MSA 3 , and MADAMIRA for Egyptian dialect.", "labels": [], "entities": []}, {"text": "shows accuracy for Farasa, MADAMIRA, and both of our models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 6, "end_pos": 14, "type": "METRIC", "confidence": 0.9997835755348206}, {"text": "Farasa", "start_pos": 19, "end_pos": 25, "type": "DATASET", "confidence": 0.7908447980880737}, {"text": "MADAMIRA", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.8685718774795532}]}, {"text": "The results show that for this small testset BiLSTM-CRF (92.65%) performs better than  MADAMIRA (92.47%) by only 0.18% which is not statistically significant.", "labels": [], "entities": [{"text": "BiLSTM-CRF", "start_pos": 45, "end_pos": 55, "type": "METRIC", "confidence": 0.9573172330856323}, {"text": "MADAMIRA", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.922000527381897}]}, {"text": "The advantage of our system is that, unlike MADAMIRA which relies on a hand-crafted lexicon, our system generalizes well on unseen data.", "labels": [], "entities": []}, {"text": "To illustrate this point, the test set has 1,449 words, and 586 of them (40%) are not seen in the training set.", "labels": [], "entities": []}, {"text": "This shows how well the system is robust with OOV words.", "labels": [], "entities": []}], "tableCaptions": []}