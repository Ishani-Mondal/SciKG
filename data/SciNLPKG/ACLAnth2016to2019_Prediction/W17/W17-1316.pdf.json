{"title": [{"text": "Arabic POS Tagging: Don't Abandon Feature Engineering Just Yet", "labels": [], "entities": [{"text": "POS Tagging", "start_pos": 7, "end_pos": 18, "type": "TASK", "confidence": 0.7609649002552032}, {"text": "Don't Abandon Feature Engineering Just Yet", "start_pos": 20, "end_pos": 62, "type": "TASK", "confidence": 0.5758693665266037}]}], "abstractContent": [{"text": "This paper focuses on comparing between using Support Vector Machine based ranking (SVM Rank) and Bidirectional Long-Short-Term-Memory (bi-LSTM) neural-network based sequence labeling in building a state-of-the-art Arabic part-of-speech tagging system.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 222, "end_pos": 244, "type": "TASK", "confidence": 0.6635290086269379}]}, {"text": "Using SVM Rank leads to state-of-the-art results, but with a fair amount of feature engineering.", "labels": [], "entities": []}, {"text": "Using bi-LSTM, particularly when combined with word embeddings, may lead to competitive POS-tagging results by automatically deducing latent linguistic features.", "labels": [], "entities": []}, {"text": "However, we show that augmenting bi-LSTM sequence labeling with some of the features that we used for the SVM Rank-based tagger yields to further improvements.", "labels": [], "entities": [{"text": "SVM Rank-based tagger", "start_pos": 106, "end_pos": 127, "type": "TASK", "confidence": 0.6052298645178477}]}, {"text": "We also show that gains realized using embeddings may not be additive with the gains achieved due to features.", "labels": [], "entities": []}, {"text": "We are open-sourcing both the SVM Rank and the bi-LSTM based systems for the research community.", "labels": [], "entities": []}], "introductionContent": [{"text": "Part-of-speech (POS) tagging is an important building blocking in many natural language processing applications such as parsing and named entity recognition.", "labels": [], "entities": [{"text": "Part-of-speech (POS) tagging", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.577540147304535}, {"text": "parsing", "start_pos": 120, "end_pos": 127, "type": "TASK", "confidence": 0.9696727395057678}, {"text": "named entity recognition", "start_pos": 132, "end_pos": 156, "type": "TASK", "confidence": 0.600519984960556}]}, {"text": "An Arabic word is composed of one or more segments (or clitics), which are typically a stem to which prefixes and suffixes maybe attached.", "labels": [], "entities": []}, {"text": "Arabic POS tagging involves assigning appropriate in-context POS tags to each clitic.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 7, "end_pos": 18, "type": "TASK", "confidence": 0.6900472640991211}]}, {"text": "Tagging can be done for each clitic in sequence or for all clitics in a word simultaneously.", "labels": [], "entities": [{"text": "Tagging", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.9598630666732788}]}, {"text": "Much work has been done on Arabic POS tagging and many morphological and surface-level features have been shown to improve tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 34, "end_pos": 45, "type": "TASK", "confidence": 0.7132465690374374}]}, {"text": "Recent work on sequence labeling using deep neural networks, particularly using bidirectional LongShort-Term-Memory (bi-LSTM) and word embeddings, has been shown to be effective for POS tagging in different languages, without the need for explicit feature engineering.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.6778217703104019}, {"text": "POS tagging", "start_pos": 182, "end_pos": 193, "type": "TASK", "confidence": 0.9542558193206787}]}, {"text": "In essence, deep neural networks maybe able to capture latent linguistic features automatically.", "labels": [], "entities": []}, {"text": "In the context of this work, we compare using a discriminative classification technique, namely Support Vector Machine based Ranking (SVM Rank ), that requires significant feature engineering with bi-LSTM neural network with and without feature engineering and word embeddings.", "labels": [], "entities": [{"text": "Support Vector Machine based Ranking (SVM Rank )", "start_pos": 96, "end_pos": 144, "type": "METRIC", "confidence": 0.6125261187553406}]}, {"text": "We experiment with tagging each clitic in context and with tagging all clitics in a word collectively.", "labels": [], "entities": []}, {"text": "We also compare both systems with MADAMIRA, which is a stateof-the-art Arabic POS tagging system.", "labels": [], "entities": [{"text": "MADAMIRA", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.7106726765632629}, {"text": "POS tagging", "start_pos": 78, "end_pos": 89, "type": "TASK", "confidence": 0.648132786154747}]}, {"text": "We show that adding explicit features to the bi-LSTM neural network and employing word embeddings separately improve POS tagging results.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 117, "end_pos": 128, "type": "TASK", "confidence": 0.8303236365318298}]}, {"text": "However, combining both explicit features and embeddings together leads sub-optimal results.", "labels": [], "entities": []}, {"text": "For testing, we employ the so-called \"WikiNews\" test set which is composed of freely available recent news articles in multiple genre (.", "labels": [], "entities": [{"text": "WikiNews\" test set", "start_pos": 38, "end_pos": 56, "type": "DATASET", "confidence": 0.7905371785163879}]}, {"text": "We are making all resultant systems available as opensource systems.", "labels": [], "entities": []}, {"text": "The contributions of this paper are as follows: \u2022 We compare using SVM Rank to using bi-LSTM with and without feature engineering and word embeddigns in Arabic POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 160, "end_pos": 171, "type": "TASK", "confidence": 0.6420703530311584}]}, {"text": "We show that feature engineering improves POS tagging significantly.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 42, "end_pos": 53, "type": "TASK", "confidence": 0.927204042673111}]}, {"text": "\u2022 We explore the effectiveness of many features including morphological and contextual features for tagging each clitic or each word in-context.", "labels": [], "entities": []}, {"text": "\u2022 We open-source both Arabic POS taggers, both of which are written entirely in Java.", "labels": [], "entities": [{"text": "POS taggers", "start_pos": 29, "end_pos": 40, "type": "TASK", "confidence": 0.5970026552677155}]}, {"text": "The SVM Rank -based system has a load time of 5 seconds and can process about 2,000 word/second on an laptop with Intel i7 processor with 16 GB of RAM.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Most common errors for best SVM Rank  configuration", "labels": [], "entities": []}, {"text": " Table 4: Most common errors for best bi-LSTM  configuration", "labels": [], "entities": []}]}