{"title": [{"text": "Graph Convolutional Networks for Named Entity Recognition", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 33, "end_pos": 57, "type": "TASK", "confidence": 0.7612709005673727}]}], "abstractContent": [{"text": "In this paper we investigate the role of the dependency tree in a named entity recognizer upon using a set of Graph Convolutional Networks (GCNs).", "labels": [], "entities": []}, {"text": "We perform a comparison among different Named Entity Recognition (NER) architectures and show that the grammar of a sentence positively influences the results.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 40, "end_pos": 70, "type": "TASK", "confidence": 0.7698609381914139}]}, {"text": "Experiments on the OntoNotes 5.0 dataset demonstrate consistent performance improvements, without requiring heavy feature engineering nor additional language-specific knowledge.", "labels": [], "entities": [{"text": "OntoNotes 5.0 dataset", "start_pos": 19, "end_pos": 40, "type": "DATASET", "confidence": 0.8786493937174479}]}], "introductionContent": [], "datasetContent": [{"text": "We employ the OntoNotes 5.0 dataset (Weischedel, 2013) for training and testing.", "labels": [], "entities": [{"text": "OntoNotes 5.0 dataset (Weischedel, 2013)", "start_pos": 14, "end_pos": 54, "type": "DATASET", "confidence": 0.8764867074787617}]}, {"text": "This dataset annotates various genres of text for the purpose of entity recognition and co-reference resolution.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 65, "end_pos": 83, "type": "TASK", "confidence": 0.7884214818477631}, {"text": "co-reference resolution", "start_pos": 88, "end_pos": 111, "type": "TASK", "confidence": 0.7443737387657166}]}, {"text": "The annotated sentences are provided with Part-of-Speech (PoS) tags and syntactic information.", "labels": [], "entities": []}, {"text": "While we include the PoS tags in our tests, the Phrase Structure Grammar (PSG) structures in the OntoNotes 5.0 are not used.", "labels": [], "entities": [{"text": "OntoNotes 5.0", "start_pos": 97, "end_pos": 110, "type": "DATASET", "confidence": 0.8198215067386627}]}, {"text": "The dependency graphs that are fed to the graph convolutional network are instead computed by an external parser, Spacy v1.8..", "labels": [], "entities": []}, {"text": "In principle we could have translated the syntactic trees in the dataset to dependency graphs using -for example -the CCGBank manual).", "labels": [], "entities": [{"text": "CCGBank manual", "start_pos": 118, "end_pos": 132, "type": "DATASET", "confidence": 0.9402328133583069}]}, {"text": "We will investigate this approach in future works, while this paper lays down the technique for boosting entity recognition using GCNs.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 105, "end_pos": 123, "type": "TASK", "confidence": 0.7126024961471558}]}, {"text": "In this section, we compare the different methods applied and discuss the results.", "labels": [], "entities": []}, {"text": "The scores in are presented as an average of 6 runs with the error being the standard deviation; we keep only the first significant digit of the errors, approximating to the nearest number.", "labels": [], "entities": []}, {"text": "The results show an improvement of 2.2 \u00b1 0.5% upon using a GCN, compared to the baseline result of a bi-directional LSTM alone (1 st row).", "labels": [], "entities": []}, {"text": "When concatenating the gold PoS tag embedding in the input vectors, this improvement raises to 4.6\u00b10.6%.", "labels": [], "entities": []}, {"text": "However, the gold tags in the OntoNotes 5.0 only refer to the sentences within the dataset.", "labels": [], "entities": [{"text": "OntoNotes 5.0", "start_pos": 30, "end_pos": 43, "type": "DATASET", "confidence": 0.8340664803981781}]}, {"text": "Therefore, the performance of the system on new sentences must rely on inferred PoS tags.", "labels": [], "entities": []}, {"text": "The F 1 score improvement for the system while using inferred tags (from the parser) is lower: 3.2\u00b10.6%.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9863649010658264}]}, {"text": "For comparison, increasing the size of the Glove vector from 1M to 2.2M gave an improvement of 0.7 \u00b1 0.5%.", "labels": [], "entities": [{"text": "Glove vector", "start_pos": 43, "end_pos": 55, "type": "METRIC", "confidence": 0.6597203612327576}]}, {"text": "Adding the morphological information of the words, albeit truncated at 12 characters, improves the F 1 score by 2.2\u00b10.5%.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 99, "end_pos": 108, "type": "METRIC", "confidence": 0.9880909522374471}]}, {"text": "Our results strongly suggest that syntactic information is relevant in capturing the role of a word in a sentence, and understanding sentences as one-dimensional lists of words appears as a partial approach.", "labels": [], "entities": []}, {"text": "Sentences embed meaning through internal graph structures: the graph convolutional method approach -used in conjunction with a parser (or a treebank) -seems to provide a lightweight architecture that incorporates grammar while extracting named entities.", "labels": [], "entities": []}, {"text": "Our results -while competitive -fall short of achieving the state-of-the-art.", "labels": [], "entities": []}, {"text": "We believe this to be the result of a few factors: we do not employ BIOES annotations for our tags, lexicon and capitalisation features are ignored, and we truncate words when encoding the morphological vectors.", "labels": [], "entities": []}, {"text": "Another improvement could come from converting the manually parsed trees in the OntoNotes 5.0 dataset into dependency graphs.", "labels": [], "entities": [{"text": "OntoNotes 5.0 dataset", "start_pos": 80, "end_pos": 101, "type": "DATASET", "confidence": 0.9185932675997416}]}, {"text": "Using these graphs during training would eliminate any possible erroneous contributions coming from the external parser.", "labels": [], "entities": []}, {"text": "Our main claim is nonetheless clear: grammatical information positively boosts the performance of recognizing entities, leaving further improvements to be explored.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results of our architecture compared to previous findings.", "labels": [], "entities": []}]}