{"title": [{"text": "Revising the METU-Sabanc\u0131 Turkish Treebank: An Exercise in Surface-Syntactic Annotation of Agglutinative Languages", "labels": [], "entities": [{"text": "METU-Sabanc\u0131 Turkish Treebank", "start_pos": 13, "end_pos": 42, "type": "DATASET", "confidence": 0.9520997603734335}]}], "abstractContent": [{"text": "In this paper, we present a revision of the training set of the METU-Sabanc\u0131 Turkish syntactic dependency treebank composed of 4997 sentences in accordance with the principles of the Meaning-Text Theory (MTT).", "labels": [], "entities": [{"text": "METU-Sabanc\u0131 Turkish syntactic dependency treebank", "start_pos": 64, "end_pos": 114, "type": "DATASET", "confidence": 0.8461539626121521}, {"text": "Meaning-Text Theory (MTT)", "start_pos": 183, "end_pos": 208, "type": "TASK", "confidence": 0.6573697984218597}]}, {"text": "MTT reflects the multilayered nature of language by a linguistic model in which each linguistic phenomenon is treated at its corresponding level(s).", "labels": [], "entities": [{"text": "MTT", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.891050398349762}]}, {"text": "Our analysis of the METU-Sabanc\u0131 syntactic relation tagset reveals that it encodes deep-morphological and surface-syntactic phenomena , which should be separated according to the MTT model.", "labels": [], "entities": [{"text": "METU-Sabanc\u0131 syntactic relation tagset", "start_pos": 20, "end_pos": 58, "type": "DATASET", "confidence": 0.8325644284486771}, {"text": "MTT", "start_pos": 179, "end_pos": 182, "type": "DATASET", "confidence": 0.6724379658699036}]}, {"text": "We propose an alternative surface-syntactic relation annotation schema and show that this schema also allows fora sound projection of the obtained surface annotation onto a deep-syntactic annotation, as needed for the implementation of downstream language understanding applications.", "labels": [], "entities": []}], "introductionContent": [{"text": "Dependency treebanks are crucial for the development of statistical NLP applications, including sentence parsing and generation.", "labels": [], "entities": [{"text": "sentence parsing", "start_pos": 96, "end_pos": 112, "type": "TASK", "confidence": 0.7493381500244141}]}, {"text": "To obtain good performance, well-defined and coherent treebank annotation schemas are needed.", "labels": [], "entities": []}, {"text": "To provide an outcome that is good not only in quantitative but also in qualitative terms in the sense that it is wellsuited for various down-stream applications, the annotation schemas must be equally rigorous from the linguistic viewpoint.", "labels": [], "entities": []}, {"text": "Thus, given that different down-stream applications may start from structures of different abstraction or diferent nature, an annotation schema should strive to annotate phenomena of different nature at different layers or focus on just one layer.", "labels": [], "entities": []}, {"text": "A conflation of different types of phenomena in one layer would make the annotation idiosyncratic and thus less appropriate for down-stream applications.", "labels": [], "entities": []}, {"text": "In addition, in order to be appropriate for down-stream applications, an annotation schema should differentiate between different phenomena at the same layer.", "labels": [], "entities": []}, {"text": "For instance, if a tagset uses just one label for two rather different syntactic relations (e.g., 'adjunct' for both indirect objects and preposition-governed circumstantials), it will not lead to a parse from which, e.g., a semantic role structure can be derived.", "labels": [], "entities": []}, {"text": "The linguistic model of the Meaning-Text Theory (MTT) accomodates for both of the above needs: it foresees different layers of linguistic representation (each one encoding linguistic descriptions at a specific level of abstraction), and it offers a fine-grained analysis of the phenomena at each of the layers.", "labels": [], "entities": [{"text": "Meaning-Text Theory (MTT)", "start_pos": 28, "end_pos": 53, "type": "TASK", "confidence": 0.8026770234107972}]}, {"text": "Furthermore, it provides a theoretically sound framework for the projection of a structure at a given layer to an equivalent structure at the adjacent layer (which is very useful, again, for down-stream applications).", "labels": [], "entities": []}, {"text": "Nearly all available dependency treebanks annotate what in the MTT-model would be the Surface-Syntactic (SSynt) layer.", "labels": [], "entities": []}, {"text": "However, given the multi-layer nature of a language model proposed by MTT (Sem \u21d4 DSynt \u21d4 SSynt \u21d4 DMorph \u21d4 SMorph \u21d4 DPhon \u21d4 SPhon), a SSynt annotation schema should accurately reflect all (surface-)syntactic phenomena of the annotated language and encode all information that is necessary to derive their equivalents at the DMorph and DSynt layers.", "labels": [], "entities": [{"text": "MTT", "start_pos": 70, "end_pos": 73, "type": "DATASET", "confidence": 0.8602665662765503}]}, {"text": "We address the task of the annotation of a Turkish corpus at the SSynt-layer in accordance with the principles of MTT.", "labels": [], "entities": [{"text": "Turkish corpus", "start_pos": 43, "end_pos": 57, "type": "DATASET", "confidence": 0.6974082142114639}, {"text": "MTT", "start_pos": 114, "end_pos": 117, "type": "DATASET", "confidence": 0.5814009308815002}]}, {"text": "In order not to start from scratch, we draw upon already available resources.", "labels": [], "entities": []}, {"text": "memes (discussed in Section 2) are divided into semantic and syntactic grammemes), and thus described at the semantic and (surface-)syntactic layers.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}