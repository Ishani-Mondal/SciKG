{"title": [{"text": "Data point selection for genre-aware parsing", "labels": [], "entities": [{"text": "genre-aware parsing", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.6843221634626389}]}], "abstractContent": [{"text": "In the NLP literature, adapting a parser to new text with properties different from the training data is commonly referred to as domain adaptation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 129, "end_pos": 146, "type": "TASK", "confidence": 0.7435771822929382}]}, {"text": "In practice, however, the differences between texts from different sources often reflect a mixture of domain and genre properties, and it is by no means clear what impact each of those has on statistical parsing.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 192, "end_pos": 211, "type": "TASK", "confidence": 0.7563498020172119}]}, {"text": "In this paper, we investigate how differences between articles in a newspaper corpus relate to the concepts of genre and domain and how they influence parsing performance of a transition-based dependency parser.", "labels": [], "entities": [{"text": "transition-based dependency parser", "start_pos": 176, "end_pos": 210, "type": "TASK", "confidence": 0.7061996658643087}]}, {"text": "We do this by applying various similarity measures for data point selection and testing their adequacy for creating genre-aware parsing models.", "labels": [], "entities": [{"text": "data point selection", "start_pos": 55, "end_pos": 75, "type": "TASK", "confidence": 0.6996673146883646}]}], "introductionContent": [{"text": "The work of and on language variation has brought valuable insights into the concepts of genre and register and the linguistic features that define them.", "labels": [], "entities": []}, {"text": "It has also triggered many studies on genre classification (), trying to automatically predict the genre or register fora particular text.", "labels": [], "entities": [{"text": "genre classification", "start_pos": 38, "end_pos": 58, "type": "TASK", "confidence": 0.8660684823989868}]}, {"text": "This might be due to either domain or genre differences, however, in NLP we usually refer to both as out-of-domain effects.", "labels": [], "entities": []}, {"text": "While many studies have successfully shown how we can adapt tools to new domains (or genres), less is known about the underlying properties that are responsible for the decrease in performance.", "labels": [], "entities": []}, {"text": "Out-of-domain (including out-of-genre) effects might be due to a large amount of unknown words introduced by topic shifts but might also be caused by a higher structural complexity in the data, by longer dependencies or a higher amount of non-projectivity.", "labels": [], "entities": []}, {"text": "Intuitively, we assume that domain differences can be captured by content-related features (e.g. from topic modelling) while we expect that functional differences between genres are reflected in structural features such as part-of-speech n-grams and other morpho-syntactic features.", "labels": [], "entities": []}, {"text": "In the paper, we address these issues and investigate how differences between articles in a newspaper corpus relate to the concepts of genre and domain and how they impact parsing performance of a transition-based dependency parser.", "labels": [], "entities": [{"text": "transition-based dependency parser", "start_pos": 197, "end_pos": 231, "type": "TASK", "confidence": 0.6948965589205424}]}, {"text": "1This is especially true for distinguishing genre from closely related concepts such as register and text type, which is why we will use genre in abroad sense here, i. e., as a cover term for genre, register, text type and similar.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our experiments, we use the T\u00fcBa-D/Z treebank (), a corpus of German newspaper text from the taz, a German daily newspaper, that includes more than 95,000 sentences annotated with constituency trees and grammatical function labels.", "labels": [], "entities": [{"text": "T\u00fcBa-D/Z treebank", "start_pos": 31, "end_pos": 48, "type": "DATASET", "confidence": 0.8011888265609741}]}, {"text": "The data has been automatically converted to dependencies.", "labels": [], "entities": []}, {"text": "Webber (2009) has shown for the Penn treebank) that even newspaper corpora should not be considered as homogeneous objects but typically also consist of multiple genres.", "labels": [], "entities": [{"text": "Penn treebank)", "start_pos": 32, "end_pos": 46, "type": "DATASET", "confidence": 0.9838651220003763}]}, {"text": "Similar to the Penn treebank, the T\u00fcBa-D/Z (v10) includes articles from a variety of genres.", "labels": [], "entities": [{"text": "Penn treebank", "start_pos": 15, "end_pos": 28, "type": "DATASET", "confidence": 0.9903985857963562}, {"text": "T\u00fcBa-D/Z (v10)", "start_pos": 34, "end_pos": 48, "type": "DATASET", "confidence": 0.9305489559968313}]}, {"text": "The genre labels in the T\u00fcBa-D/Z have been assigned by the editors of the taz and are: reports, commentaries, documentaries, letters to the editor, interviews, portraits and messages from news agencies.", "labels": [], "entities": [{"text": "T\u00fcBa-D/Z", "start_pos": 24, "end_pos": 32, "type": "DATASET", "confidence": 0.8114375869433085}]}, {"text": "It is, however, not clear to what extend these labels correspond to linguistically well-defined categories, i. e., whether documents within a specific genre category share \"linguistic characteristics that are used to structure complete texts\" as suggested by.", "labels": [], "entities": []}, {"text": "The vast majority of the articles in the treebank is labelled as taz reports.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Distribution of different genres in the T\u00fcBa-D/Z and training/test sizes.", "labels": [], "entities": [{"text": "T\u00fcBa-D/Z", "start_pos": 50, "end_pos": 58, "type": "DATASET", "confidence": 0.8012204766273499}]}, {"text": " Table 2: LAS for different genres: random training sets from reports (avg. LAS over 5 runs and std dev.)", "labels": [], "entities": []}, {"text": " Table 3: LAS for random training sets from reports and in-domain training sets (avg. LAS over 5 runs).", "labels": [], "entities": [{"text": "LAS", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.8200209140777588}]}, {"text": " Table 4: Differences between test sets (avg. sentence length, no. of finite verbs per sentence, % of  unknown tokens, avg. dependency length, entropy of arc direction, % of non-projective trees) and LAS  for each test set when training the parser on a randomly selected training set from reports (N =380,000).", "labels": [], "entities": [{"text": "LAS", "start_pos": 200, "end_pos": 203, "type": "METRIC", "confidence": 0.9991494417190552}]}, {"text": " Table 6: Results for different data selection methods for genre-aware parsing (LAS; * indicates a signif- icant improvement over the baseline with p < 0.05; ** with p < 0.01).", "labels": [], "entities": [{"text": "genre-aware parsing", "start_pos": 59, "end_pos": 78, "type": "TASK", "confidence": 0.6436059474945068}]}, {"text": " Table 7: LAS for baseline (random training sets from reports; avg. LAS over 5 runs and standard devia- tion) and for topic setting where data selection is not optimised on the test set.", "labels": [], "entities": [{"text": "LAS", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.8848780989646912}]}]}