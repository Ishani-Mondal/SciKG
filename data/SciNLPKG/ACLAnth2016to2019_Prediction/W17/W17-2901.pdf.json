{"title": [], "abstractContent": [{"text": "In this paper we present a set of experiments and analyses on predicting the gender of Twitter users based on language-independent features extracted either from the text or the metadata of users' tweets.", "labels": [], "entities": []}, {"text": "We perform our experiments on the TwiSty dataset containing manual gender annotations for users speaking six different languages.", "labels": [], "entities": [{"text": "TwiSty dataset", "start_pos": 34, "end_pos": 48, "type": "DATASET", "confidence": 0.9693602919578552}]}, {"text": "Our classification results show that, while the prediction model based on language-independent features performs worse than the bag-of-words model when training and testing on the same language, it regularly outperforms the bag-of-words model when applied to different languages, showing very stable results across various languages.", "labels": [], "entities": []}, {"text": "Finally we perform a comparative analysis of feature effect sizes across the six languages and show that differences in our features correspond to cultural distances.", "labels": [], "entities": []}], "introductionContent": [{"text": "Gender prediction is a well-established task in author profiling, useful fora series of downstream analyses (; as well as predictive model improvements.", "labels": [], "entities": [{"text": "Gender prediction", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7926747500896454}, {"text": "author profiling", "start_pos": 48, "end_pos": 64, "type": "TASK", "confidence": 0.8866286873817444}]}, {"text": "Most existing work on predicting gender focuses on exploiting the linguistic production of the users (, just rarely using nonlinguistic information such as metadata or visual information.", "labels": [], "entities": [{"text": "predicting gender", "start_pos": 22, "end_pos": 39, "type": "TASK", "confidence": 0.9345583617687225}]}, {"text": "In this paper we investigate the possibility of predicting gender of a Twitter user regardless of the language used in his or her tweets.", "labels": [], "entities": []}, {"text": "We perform our experiments on an existing dataset of Twitter users speaking six different languages that were manually annotated for their gender.", "labels": [], "entities": []}, {"text": "Our language-independent gender predictor relies on general linguistic features, such as the usage of punctuation, and non-linguistic features calculated from Twitter metadata, such as the user interaction in the form of replying, retweeting and favoriting, time of posting, color choices, client usage etc.", "labels": [], "entities": [{"text": "language-independent gender predictor", "start_pos": 4, "end_pos": 41, "type": "TASK", "confidence": 0.6234202782313029}]}, {"text": "The potential of a language-independent procedure for gender prediction is substantial both for the field of natural language processing where using extra-linguistic variables is currently gaining momentum, as well as disciplines from social sciences and the humanities working with usergenerated content, where such factors have along tradition.", "labels": [], "entities": [{"text": "gender prediction", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.7028455138206482}, {"text": "natural language processing", "start_pos": 109, "end_pos": 136, "type": "TASK", "confidence": 0.6868584752082825}]}, {"text": "We believe that building such languageindependent procedures is the only tractable way of moving forward given the number of different languages used in social media and the existence of training data only fora few high-density languages.", "labels": [], "entities": []}, {"text": "In the next section we briefly describe the dataset we performed our experiments on, in Section 3 we describe our language-independent features, in Section 4 we give the experimental setup of our gender prediction experiments, while in Section 5 we present the gender prediction results, as well as a series of analyses of the feature spaces across languages.", "labels": [], "entities": [{"text": "gender prediction", "start_pos": 196, "end_pos": 213, "type": "TASK", "confidence": 0.696759507060051}, {"text": "gender prediction", "start_pos": 261, "end_pos": 278, "type": "TASK", "confidence": 0.6613977253437042}]}, {"text": "In Section 6 we give some conclusions and directions for further research.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our experiments we fully rely on the TwiSty corpus ( ) which was developed for research in author profiling.", "labels": [], "entities": [{"text": "TwiSty corpus", "start_pos": 40, "end_pos": 53, "type": "DATASET", "confidence": 0.8908654153347015}, {"text": "author profiling", "start_pos": 94, "end_pos": 110, "type": "TASK", "confidence": 0.7945889234542847}]}, {"text": "It contains personality (MBTI) and gender annotations fora total of 18,168 authors posting in German, Italian, Dutch, French, Portuguese or Spanish.", "labels": [], "entities": [{"text": "personality (MBTI)", "start_pos": 12, "end_pos": 30, "type": "METRIC", "confidence": 0.6193855777382851}]}, {"text": "The manual gender annotations in the TwiSty corpus are based on the user's name, handle, description and profile picture and follow the performative view of gender, i.e., that gender is discriminated by performances that respond to societal norms or conventions.", "labels": [], "entities": [{"text": "TwiSty corpus", "start_pos": 37, "end_pos": 50, "type": "DATASET", "confidence": 0.9345024228096008}]}, {"text": "The corpus is distributed in the form of Twitter user IDs and specific tweet IDs of that user.", "labels": [], "entities": []}, {"text": "In this work we use only the user IDs and their gender and language annotations to collect timelines of users through the Twitter API.", "labels": [], "entities": []}, {"text": "For each user we collect up to 3,200 tweets (API restriction) and discard users with less than 100 tweets.", "labels": [], "entities": []}, {"text": "By doing so we collected 45 million tweets for 16,156 users across the six languages.", "labels": [], "entities": []}, {"text": "In this section we outline the setup of our gender classification experiments, whose results we report in Section 5.1.", "labels": [], "entities": [{"text": "gender classification", "start_pos": 44, "end_pos": 65, "type": "TASK", "confidence": 0.7489105761051178}]}, {"text": "We train models based on standardized (zero mean, unit variance) language-independent features described in the previous section with support vector machines (SVMs) using a radial basis function (RBF) kernel and optimizing the \u03b3 and C hyperparameters via 5-fold cross-validation.", "labels": [], "entities": []}, {"text": "To have a reasonable point of comparison for our language-independent models, we built bagof-words (BoW) models on a concatenation of all tweets of a user by using lowercased character 5-grams as features and an SVM with a linear kernel.", "labels": [], "entities": []}, {"text": "We use character 5-grams as they have proven in our initial experiments to yield better results than words or character n-grams of different length.", "labels": [], "entities": []}, {"text": "We use a linear kernel and not the RBF one in these experiments as the number of features is much higher than the number of instances.", "labels": [], "entities": [{"text": "RBF", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.5503183007240295}]}, {"text": "We do not perform any input processing except lowercasing as we expect useful signal for the task to be present in non-alphabetic characters, URLs, hashtags, mentions etc.", "labels": [], "entities": []}, {"text": "The number of features in our BoW models ranges from 6.2 million for German to 51.2 million for Spanish.", "labels": [], "entities": [{"text": "BoW", "start_pos": 30, "end_pos": 33, "type": "DATASET", "confidence": 0.9277724027633667}]}, {"text": "We discriminate between in-language and We use weighted F1 as our evaluation metric and the most-frequent class baseline as our weak baseline.", "labels": [], "entities": [{"text": "F1", "start_pos": 56, "end_pos": 58, "type": "METRIC", "confidence": 0.9028128385543823}]}], "tableCaptions": [{"text": " Table 1: Gender classification results on the six languages (rows), columns encoding the testing lan- guage (Lang), number of instances (Inst. #) and the weighted F1 results on most-frequent class baseline  (MFC), in-language bag-of-words (ILBoW), average cross-language bag-of-words (CLBoW) and the six  language-independent models. Bold results outperform the corresponding BoW baseline.", "labels": [], "entities": [{"text": "Gender classification", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.6659919321537018}, {"text": "Inst. #)", "start_pos": 138, "end_pos": 146, "type": "METRIC", "confidence": 0.9307901859283447}, {"text": "F1", "start_pos": 164, "end_pos": 166, "type": "METRIC", "confidence": 0.9892115592956543}, {"text": "most-frequent class baseline  (MFC)", "start_pos": 178, "end_pos": 213, "type": "METRIC", "confidence": 0.7159778525431951}, {"text": "BoW baseline", "start_pos": 377, "end_pos": 389, "type": "DATASET", "confidence": 0.8807596862316132}]}, {"text": " Table 2: Representation of 30 (out of 51) features with the highest average rank across languages. Each  feature in each language is represented through the difference between feature means of the female and  male subsets in a standardized dataset. Red encodes higher female mean, blue male.", "labels": [], "entities": [{"text": "Representation", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9605165719985962}]}]}