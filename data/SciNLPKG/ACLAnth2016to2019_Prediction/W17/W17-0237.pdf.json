{"title": [{"text": "Word vectors, reuse, and replicability: Towards a community repository of large-text resources", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes an emerging shared repository of large-text resources for creating word vectors, including pre-processed corpora and pre-trained vectors fora range of frameworks and configurations.", "labels": [], "entities": []}, {"text": "This will facilitate reuse, rapid experimentation, and replicability of results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word embeddings provide the starting point for much current work in NLP, not least because they often act as the input representations for neural network models.", "labels": [], "entities": []}, {"text": "In addition to be being timeconsuming to train, it can be difficult to compare results given the effects of different pre-processing choices and non-determinism in the training algorithms.", "labels": [], "entities": []}, {"text": "This paper describes an initiative to create a shared repository of large-text resources for word vectors, including pre-processed corpora and pretrained vector models fora range of frameworks and configurations.", "labels": [], "entities": []}, {"text": "1 This will facilitate rapid experimentation and replicability.", "labels": [], "entities": [{"text": "replicability", "start_pos": 49, "end_pos": 62, "type": "TASK", "confidence": 0.9744544625282288}]}, {"text": "The repository is available for public access at the following address: \u00a8 \u00a9 http://vectors.nlpl.eu To demonstrate the impact of different preprocessing choices and parameterizations, we provide indicative empirical results fora first set of embeddings made available in the repository (Section 3).", "labels": [], "entities": [{"text": "\u00a8", "start_pos": 72, "end_pos": 73, "type": "METRIC", "confidence": 0.9853734374046326}]}, {"text": "Using an interactive web application, users are also able to explore and compare different pretrained models on-line (Section 4).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results for SimLex-999 and the semantic  sections of the Google Analogies Dataset.", "labels": [], "entities": [{"text": "Google Analogies Dataset", "start_pos": 67, "end_pos": 91, "type": "DATASET", "confidence": 0.8425551851590475}]}]}