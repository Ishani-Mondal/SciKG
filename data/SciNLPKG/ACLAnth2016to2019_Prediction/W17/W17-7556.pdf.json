{"title": [{"text": "Neural Networks for Semantic Textual Similarity", "labels": [], "entities": [{"text": "Semantic Textual Similarity", "start_pos": 20, "end_pos": 47, "type": "TASK", "confidence": 0.5907768607139587}]}], "abstractContent": [{"text": "Complex neural network architectures are being increasingly used to learn to compute the semantic resemblances among natural language texts.", "labels": [], "entities": []}, {"text": "It is necessary to establish a lower bound of performance that must be met in order for new complex architectures to be not only novel, but also worthwhile in terms of implementation.", "labels": [], "entities": []}, {"text": "This paper focuses on the specific task of determining semantic textual similarity (STS).", "labels": [], "entities": [{"text": "determining semantic textual similarity (STS)", "start_pos": 43, "end_pos": 88, "type": "TASK", "confidence": 0.6842178872653416}]}, {"text": "We construct a number of models from simple to complex within a framework and report our results.", "labels": [], "entities": []}, {"text": "Our findings show that a small number of LSTM stacks with an LSTM stack comparator produces the best results.", "labels": [], "entities": []}, {"text": "We use Se-mEval 2017 STS Competition Dataset for evaluation.", "labels": [], "entities": [{"text": "Se-mEval 2017 STS Competition Dataset", "start_pos": 7, "end_pos": 44, "type": "DATASET", "confidence": 0.7765577375888825}]}], "introductionContent": [{"text": "Scholars have attempted to capture the semantics in natural language texts in a formal manner for centuries.", "labels": [], "entities": []}, {"text": "Even today, the true meaning of a word can neither be quantified nor computed, but methods have been developed to express meaning numerically in terms of co-occurrence and association.", "labels": [], "entities": []}, {"text": "This is called distributional semantics, and it plays a key role in current approaches to representation of meaning, where although the actual meaning remains unknown, computations can be performed with words or phrases that share the same usage, and therefore, have similar meaning.", "labels": [], "entities": [{"text": "representation of meaning", "start_pos": 90, "end_pos": 115, "type": "TASK", "confidence": 0.878720780213674}]}, {"text": "The theoretical foundation lies in the so-called distributional hypothesis, which states that words that share the same context tend to share similar meaning.", "labels": [], "entities": []}, {"text": "This hypothesis, which is claimed to hold true for words, has been used to obtain vector representations or embeddings for words).", "labels": [], "entities": []}, {"text": "Building on such word embeddings, various methods have been proposed to obtain the meaning of phrases, sentences, paragraphs and whole texts.", "labels": [], "entities": []}, {"text": "These include complex linear-algebra based approaches, and more recently a variety of neural network architectures (.", "labels": [], "entities": []}, {"text": "This research concerns itself specifically with the semantic representation of sentences, and compares the different representations in the task of semantic textual similarity matching.", "labels": [], "entities": [{"text": "semantic textual similarity matching", "start_pos": 148, "end_pos": 184, "type": "TASK", "confidence": 0.6398223489522934}]}, {"text": "Semantic textual similarity matching is the task of determining the resemblance of the meanings between two sentences.", "labels": [], "entities": [{"text": "Semantic textual similarity matching", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.7136057764291763}]}, {"text": "The dataset used for this task is SemEvals' 2017 Semantic Textual Similarity corpus 1 2 . The task specifically is to output a continuous value on the scale from that represents the degree of semantic similarity between two given English sentences, where 0 is no similarity and 5 is complete similarity.", "labels": [], "entities": [{"text": "SemEvals' 2017 Semantic Textual Similarity corpus 1 2", "start_pos": 34, "end_pos": 87, "type": "DATASET", "confidence": 0.6619436889886856}]}, {"text": "In terms of machine learning, this is a regression problem.", "labels": [], "entities": []}, {"text": "The 2017 STS corpus contains 1186 English sentence pairs with a corresponding rating and 249 pairs as the test set.", "labels": [], "entities": [{"text": "STS corpus", "start_pos": 9, "end_pos": 19, "type": "DATASET", "confidence": 0.8085708916187286}]}, {"text": "The test set has been labeled with the average of multiple human expert ratings that SemEval calls the \"gold standard\".", "labels": [], "entities": []}, {"text": "The distribution of ratings is stated to be as uniform throughout as it could be, and the ratios of ratings for the test set are similar to the training set's ratings.", "labels": [], "entities": []}, {"text": "The models that are examined in this re-search are simple neural network architectures compared to some of the more complicated models that are popular in recent natural language processing research ().", "labels": [], "entities": []}, {"text": "Examining the simple neural network architectures better posits a perspective on creating new architectures for practical applications.", "labels": [], "entities": []}, {"text": "If a simple architecture can perform equivalently or better than a more complex model being proposed, the new model is simply anew way to accomplish a task using a resource-hungry method.", "labels": [], "entities": []}, {"text": "Our simple models use perceptrons to simple LSTMs and bidirectional LSTMs and are evaluated on the STS task.", "labels": [], "entities": []}, {"text": "The major components in these models are the pre-trained word vectors, the sentence embeddings, and the comparator of the two sentence embeddings that performs the regression.", "labels": [], "entities": []}], "datasetContent": [{"text": "The STS Benchmark comprises a selection of the English datasets used in the STS tasks organized in the context of SemEval between 2012 and 2017.", "labels": [], "entities": [{"text": "STS Benchmark", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.9558320045471191}]}, {"text": "The selection of datasets includes text from image captions, news headlines and user forums.", "labels": [], "entities": []}, {"text": "There area total of 1186 ranked sentence pairs from various domains such as image captions, Twitter news, questions, answers, headlines, plagiarism, and post-editing.", "labels": [], "entities": []}, {"text": "shows a few pairs of sentences and their gold standard STS rankings from this dataset.", "labels": [], "entities": [{"text": "gold standard STS", "start_pos": 41, "end_pos": 58, "type": "METRIC", "confidence": 0.6843900879224142}]}, {"text": "Each model is evaluated on the sentence similarity task.", "labels": [], "entities": []}, {"text": "The results of various models are compared in terms of Pearson Correlation where n is the number of samples, xi and y i are the single samples indexed with i, \u00af x and \u00af y are the two samples' respective means.", "labels": [], "entities": [{"text": "Pearson Correlation", "start_pos": 55, "end_pos": 74, "type": "METRIC", "confidence": 0.9164751470088959}]}], "tableCaptions": [{"text": " Table 1: Example sentence pairs from the SemEval STS 2017 dataset", "labels": [], "entities": [{"text": "SemEval STS 2017 dataset", "start_pos": 42, "end_pos": 66, "type": "DATASET", "confidence": 0.7587858363986015}]}, {"text": " Table 2: The mean Pearson R out-of-sample and in-sample from k-fold cross validation where  k = 10. The LSTM and LSTM Stack embeddings were all computed with 50 epochs. The  SIF embedding and perceptron comparator were calculated with 100 epochs. The model names  are ordered by embedding component and comparator, except for the L2-LSTM model which  is combined embedding and comparator. In-Sample Pearson R is the Pearson R of the model  evaluated on the data used to train the model.", "labels": [], "entities": [{"text": "Pearson R out-of-sample", "start_pos": 19, "end_pos": 42, "type": "METRIC", "confidence": 0.9089810450871786}]}]}