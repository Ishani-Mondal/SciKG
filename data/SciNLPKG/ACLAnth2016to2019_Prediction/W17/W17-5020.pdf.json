{"title": [{"text": "Detecting Off-topic Responses to Visual Prompts", "labels": [], "entities": [{"text": "Detecting Off-topic Responses to Visual Prompts", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.8856878379980723}]}], "abstractContent": [{"text": "Automated methods for essay scoring have made great progress in recent years, achieving accuracies very close to human annotators.", "labels": [], "entities": [{"text": "essay scoring", "start_pos": 22, "end_pos": 35, "type": "TASK", "confidence": 0.8615849912166595}]}, {"text": "However, a known weakness of such automated scorers is not taking into account the semantic relevance of the submitted text.", "labels": [], "entities": []}, {"text": "While there is existing work on detecting answer relevance given a textual prompt, very little previous research has been done to incorporate visual writing prompts.", "labels": [], "entities": []}, {"text": "We propose a neural architecture and several extensions for detecting off-topic responses to visual prompts and evaluate it on a dataset of texts written by language learners.", "labels": [], "entities": [{"text": "detecting off-topic responses to visual prompts", "start_pos": 60, "end_pos": 107, "type": "TASK", "confidence": 0.6788955281178156}]}], "introductionContent": [{"text": "Evaluating the relevance of learner essays with respect to the assigned prompt is an important part of automated writing assessment (.", "labels": [], "entities": []}, {"text": "Existing systems are able to assign high-quality assessments based on grammaticality), but are known to be vulnerable to memorised off-topic answers which can be a critical weakness in high-stakes testing.", "labels": [], "entities": []}, {"text": "In addition, students who have limited relevant vocabulary may try to shift the topic of their answer in a more familiar direction, which most automated assessment systems are notable to capture.", "labels": [], "entities": []}, {"text": "Solutions for detecting topical relevance can help prevent these weaknesses and provide informative feedback to the students.", "labels": [], "entities": [{"text": "detecting topical relevance", "start_pos": 14, "end_pos": 41, "type": "TASK", "confidence": 0.8037540515263876}]}, {"text": "While there is previous work on assessing the relevance of answers given a textual prompt, very little research has been done to incorporate visual writing prompts.", "labels": [], "entities": []}, {"text": "In this setting, students are asked to write a short description about an image in order to assess their language skills, and we would like to automatically evaluate the semantic relevance of their answers.", "labels": [], "entities": []}, {"text": "An intuitive method for comparing multiple modalities is to map them into a shared distributed space -semantically similar entities will get mapped to similar vector representations, regardless of the information source.", "labels": [], "entities": []}, {"text": "used this principle to improve image recognition, by first training separate visual and textual components, and then mapping the images into the same space as word embeddings.", "labels": [], "entities": [{"text": "image recognition", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.8048421442508698}]}, {"text": "performed information retrieval tasks with a related model based on convolutional networks.", "labels": [], "entities": [{"text": "information retrieval tasks", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.8436639507611593}]}, {"text": "learned to associate word embeddings to images using Fisher vectors.", "labels": [], "entities": []}, {"text": "In this paper, we start with a similar architecture, based on the approach used by for image caption generation, and propose modifications that make the model more suitable for discriminating between relevant and irrelevant answers.", "labels": [], "entities": [{"text": "image caption generation", "start_pos": 87, "end_pos": 111, "type": "TASK", "confidence": 0.8257352113723755}]}, {"text": "The framework uses an LSTM for text composition and a pre-trained image recognition model for extracting visual features.", "labels": [], "entities": [{"text": "text composition", "start_pos": 31, "end_pos": 47, "type": "TASK", "confidence": 0.7665203511714935}]}, {"text": "Both representations are mapped to the same space and a prediction is made about the relevance of the text given the image.", "labels": [], "entities": []}, {"text": "We propose a novel gating component that decides which parts of the image should be considered for the current similarity calculation, based on first reading the input sentence.", "labels": [], "entities": []}, {"text": "Application of dropout to word embeddings and visual features helps increase robustness on an otherwise noisy dataset and assisted in regularising the model.", "labels": [], "entities": []}, {"text": "Finally, the standard loss function is replaced with aversion of crossentropy, encouraging the model to jointly optimise over batches.", "labels": [], "entities": []}, {"text": "We evaluate on a dataset of short answers by language learners, written in response to visual prompts and our experiments show perfor-mance improvements for each of the model modifications.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the visual relevance detection model by training on Flickr30k and testing on the dataset of learner responses to visual prompts.", "labels": [], "entities": [{"text": "visual relevance detection", "start_pos": 16, "end_pos": 42, "type": "TASK", "confidence": 0.6883660157521566}, {"text": "Flickr30k", "start_pos": 64, "end_pos": 73, "type": "DATASET", "confidence": 0.9374894499778748}]}, {"text": "In order to handle multiple sentences in the written responses, every sentence is first scored individually and the scores are then averaged overall the sentences.", "labels": [], "entities": []}, {"text": "For every textual answer in the dataset, we create a negative datapoint by pairing it with a random image.", "labels": [], "entities": []}, {"text": "The task is then to accurately detect whether the pair is truly relevant or randomly created, by assigning it high or low relevance scores.", "labels": [], "entities": []}, {"text": "In order to convert the model output to a binary classification, we employ leave-one-out optimisationone example at a time is used for testing, while the others are used to calculate the optimal threshold for accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 209, "end_pos": 217, "type": "METRIC", "confidence": 0.9955319166183472}]}, {"text": "We also report average precision and precision at detecting irrelevant answers in the top 50 returned instances, which measure the quality of the ranking and do not require a fixed threshold.", "labels": [], "entities": [{"text": "precision", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9918346405029297}, {"text": "precision", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9996205568313599}]}, {"text": "Results for the different system architectures In this picture there are lot of people and each one has a different attitude.", "labels": [], "entities": []}, {"text": "0.81 In the foreground, people are waiting for the green light in order to cross the street.", "labels": [], "entities": []}, {"text": "While a child is talking with an adult about something that is on the other side of the road, instead a women, with lots of bag in her left hand, is chatting with her mobile telephone.", "labels": [], "entities": []}, {"text": "0.63 Generally speaking, the picture is full of bright colours and it conveys the idea of crowded city.", "labels": [], "entities": []}, {"text": "Looking at this pictures reminds me of the time I went scuba diving in the sea.", "labels": [], "entities": []}, {"text": "-2.16 It's fascinating, because you are surrounded by water and fishes and everything seems so coulorful and adventurous.", "labels": [], "entities": []}, {"text": "-1.40 Another good part of diving is coming up.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of images and descriptions in the  Flickr30k dataset.", "labels": [], "entities": [{"text": "Flickr30k dataset", "start_pos": 52, "end_pos": 69, "type": "DATASET", "confidence": 0.9860699772834778}]}, {"text": " Table 3: Results on the dataset of short answers  written by language learners in response to visual  prompts. Reporting accuracy, average precision,  and precision at rank 50.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9781050086021423}, {"text": "average", "start_pos": 132, "end_pos": 139, "type": "METRIC", "confidence": 0.9306702017784119}, {"text": "precision", "start_pos": 140, "end_pos": 149, "type": "METRIC", "confidence": 0.9076670408248901}, {"text": "precision", "start_pos": 156, "end_pos": 165, "type": "METRIC", "confidence": 0.9996556043624878}]}, {"text": " Table 2: Predicted scores from the best relevance scoring model, given example sentences from the  learner dataset and the included photo as a prompt. The first 4 sentences were written in response to this  image, whereas the last 4 were written about a different photo.", "labels": [], "entities": []}, {"text": " Table 4: Results for different system configura- tions on the Flickr30k development and test sets.  We report accuracy and the average predicted  scores for positive and negative examples.", "labels": [], "entities": [{"text": "Flickr30k development and test sets", "start_pos": 63, "end_pos": 98, "type": "DATASET", "confidence": 0.954034173488617}, {"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9996234178543091}]}]}