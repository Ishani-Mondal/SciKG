{"title": [{"text": "Improved Abusive Comment Moderation with User Embeddings", "labels": [], "entities": [{"text": "Improved Abusive Comment Moderation", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.838113322854042}]}], "abstractContent": [{"text": "Experimenting with a dataset of approximately 1.6M user comments from a Greek news sports portal, we explore how a state of the art RNN-based moderation method can be improved by adding user embed-dings, user type embeddings, user biases, or user type biases.", "labels": [], "entities": []}, {"text": "We observe improvements in all cases, with user embeddings leading to the biggest performance gains.", "labels": [], "entities": []}], "introductionContent": [{"text": "News portals often allow their readers to comment on articles, in order to get feedback, engage their readers, and build customer loyalty.", "labels": [], "entities": []}, {"text": "User comments, however, can also be abusive (e.g., bullying, profanity, hate speech), damaging the reputation of news portals, making them liable to fines (e.g., when hosting comments encouraging illegal actions), and putting off readers.", "labels": [], "entities": []}, {"text": "Large news portals often employ moderators, who are frequently overwhelmed by the volume and abusiveness of comments.", "labels": [], "entities": []}, {"text": "Readers are disappointed when nonabusive comments do not appear quickly online because of moderation delays.", "labels": [], "entities": []}, {"text": "Smaller news portals maybe unable to employ moderators, and some are forced to shutdown their comments.", "labels": [], "entities": []}, {"text": "In previous work), we introduced anew dataset of approx. 1.6M manually moderated user comments from a Greek sports news portal, called Gazzetta, which we made publicly available.", "labels": [], "entities": [{"text": "Gazzetta", "start_pos": 135, "end_pos": 143, "type": "DATASET", "confidence": 0.8318563103675842}]}, {"text": "Experimenting on that dataset and the datasets of, which contain moderated English Wikipedia comments, we showed that a method based on a Recurrent Neural Network (RNN) outperforms DETOX (, the previous state of the art in automatic user content moderation.", "labels": [], "entities": []}, {"text": "Our previous work, however, considered only the texts of the comments, ignoring user-specific information (e.g., number of previously accepted or rejected comments of each user).", "labels": [], "entities": []}, {"text": "Here we add user embeddings or user type embeddings to our RNN-based method, i.e., dense vectors that represent individual users or user types, similarly to word embeddings that represent words ().", "labels": [], "entities": []}, {"text": "Experiments on Gazzetta comments show that both user embeddings and user type embeddings improve the performance of our RNN-based method, with user embeddings helping more.", "labels": [], "entities": [{"text": "Gazzetta comments", "start_pos": 15, "end_pos": 32, "type": "DATASET", "confidence": 0.9337845742702484}]}, {"text": "User-specific or user-type-specific scalar biases also help to a lesser extent.", "labels": [], "entities": []}], "datasetContent": [{"text": "We first discuss the dataset we used, to help acquaint the reader with the problem.", "labels": [], "entities": []}, {"text": "The dataset contains Greek comments from Gazzetta ().", "labels": [], "entities": [{"text": "Gazzetta", "start_pos": 41, "end_pos": 49, "type": "DATASET", "confidence": 0.8854038119316101}]}, {"text": "There are approximately 1.45M training comments; we call them G-TRAIN ().", "labels": [], "entities": [{"text": "G-TRAIN", "start_pos": 62, "end_pos": 69, "type": "METRIC", "confidence": 0.7923483848571777}]}, {"text": "An additional set of 60,900 comments (Oct. 7 to) was split to development set (G-DEV, 29,700 comments) and test set (G-TEST, 29,700).", "labels": [], "entities": [{"text": "G-DEV", "start_pos": 79, "end_pos": 84, "type": "DATASET", "confidence": 0.8267955183982849}, {"text": "G-TEST", "start_pos": 117, "end_pos": 123, "type": "DATASET", "confidence": 0.8355609774589539}]}, {"text": "Each comment has a gold label ('accept', 'reject').", "labels": [], "entities": []}, {"text": "The user ID of the author of each comment is also available, but user IDs were not used in our previous work.", "labels": [], "entities": []}, {"text": "When experimenting with user type embeddings or biases, we group the users into the fol-4 Two of the co-authors of are with Jigsaw, who recently announced Perspective, a system to detect toxic comments.", "labels": [], "entities": [{"text": "Jigsaw", "start_pos": 124, "end_pos": 130, "type": "DATASET", "confidence": 0.9231904745101929}]}, {"text": "Perspective is not the same as DETOX (personal communication), but we were unable to obtain scientific articles describing it.", "labels": [], "entities": [{"text": "Perspective", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9255179762840271}, {"text": "DETOX (personal communication)", "start_pos": 31, "end_pos": 61, "type": "TASK", "confidence": 0.5786902070045471}]}, {"text": "The remaining 1,500 comments are not used here.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comment statistics of the dataset used.", "labels": [], "entities": []}, {"text": " Table 2: User statistics of the dataset used.", "labels": [], "entities": []}, {"text": " Table 3: AUC scores. Standard error in brackets.", "labels": [], "entities": [{"text": "AUC", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.8505381941795349}, {"text": "Standard error", "start_pos": 22, "end_pos": 36, "type": "METRIC", "confidence": 0.8567854464054108}]}]}