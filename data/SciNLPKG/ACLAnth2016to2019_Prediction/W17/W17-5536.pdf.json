{"title": [{"text": "Predicting Causes of Reformulation in Intelligent Assistants", "labels": [], "entities": [{"text": "Predicting Causes of Reformulation in Intelligent Assistants", "start_pos": 0, "end_pos": 60, "type": "TASK", "confidence": 0.7741190620831081}]}], "abstractContent": [{"text": "Intelligent assistants (IAs) such as Siri and Cortana conversationally interact with users and execute a wide range of actions (e.g., searching the Web, setting alarms, and chatting).", "labels": [], "entities": []}, {"text": "IAs can support these actions through the combination of various components such as automatic speech recognition, natural language understanding , and language generation.", "labels": [], "entities": [{"text": "automatic speech recognition", "start_pos": 84, "end_pos": 112, "type": "TASK", "confidence": 0.7087094386418661}, {"text": "natural language understanding", "start_pos": 114, "end_pos": 144, "type": "TASK", "confidence": 0.6801337599754333}, {"text": "language generation", "start_pos": 151, "end_pos": 170, "type": "TASK", "confidence": 0.7402103096246719}]}, {"text": "However, the complexity of these components hinders developers from determining which component causes an error.", "labels": [], "entities": []}, {"text": "To remove this hindrance, we focus on reformulation, which is a useful signal of user dissatisfaction , and propose a method to predict the reformulation causes.", "labels": [], "entities": []}, {"text": "We evaluate the method using the user logs of a commercial IA.", "labels": [], "entities": []}, {"text": "The experimental results have demonstrated that features designed to detect the error of a specific component improve the performance of reformulation cause detection.", "labels": [], "entities": [{"text": "reformulation cause detection", "start_pos": 137, "end_pos": 166, "type": "TASK", "confidence": 0.939784824848175}]}], "introductionContent": [{"text": "Intelligent assistants (IAs) such as Apple's Siri and Cortana have gained considerable attention as mobile devices have become prevalent in our daily lives.", "labels": [], "entities": []}, {"text": "They are hybrids of search and dialogue systems that conversationally interact with users and execute a wide range of actions (e.g., searching the Web, setting alarms, making phone calls and chatting).", "labels": [], "entities": []}, {"text": "IAs can support these actions through the combination of various components such as automatic speech recognition (ASR), natural language understanding (NLU), and language generation (LG).", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 84, "end_pos": 118, "type": "TASK", "confidence": 0.8120567202568054}, {"text": "natural language understanding (NLU)", "start_pos": 120, "end_pos": 156, "type": "TASK", "confidence": 0.8083920280138651}, {"text": "language generation (LG)", "start_pos": 162, "end_pos": 186, "type": "TASK", "confidence": 0.8050055384635926}]}, {"text": "One major concern in the development of commercial IAs is how to speedup the cycle of the system performance enhancement.", "labels": [], "entities": [{"text": "IAs", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.9592795372009277}]}, {"text": "The enhancement process is often performed by manually investigating user logs, finding erroneous data, detecting the component responsible for that error, and updating the component.", "labels": [], "entities": []}, {"text": "As IAs are composed of various components, the error cause detection becomes an obstacle in the manual process.", "labels": [], "entities": [{"text": "IAs", "start_pos": 3, "end_pos": 6, "type": "TASK", "confidence": 0.9574694037437439}, {"text": "error cause detection", "start_pos": 47, "end_pos": 68, "type": "TASK", "confidence": 0.6824061671892802}]}, {"text": "In this paper, we attempt to automate the error cause detection to overcome this obstacle.", "labels": [], "entities": [{"text": "error cause detection", "start_pos": 42, "end_pos": 63, "type": "TASK", "confidence": 0.6229938864707947}]}, {"text": "One approach to do this is to utilize user feedback.", "labels": [], "entities": []}, {"text": "In this work, we focus on reformulation, i.e., when a user modifies the previous input.", "labels": [], "entities": []}, {"text": "In web search and dialogue systems, reformulation is known as an implicit feedback signal that the user could not receive a desired response to the previous input due to one or more system components failing.", "labels": [], "entities": []}, {"text": "In IAs, ASR error is a major cause of reformulation and has been extensively studied.", "labels": [], "entities": [{"text": "IAs", "start_pos": 3, "end_pos": 6, "type": "TASK", "confidence": 0.954281210899353}, {"text": "ASR error", "start_pos": 8, "end_pos": 17, "type": "TASK", "confidence": 0.7133076041936874}, {"text": "reformulation", "start_pos": 38, "end_pos": 51, "type": "TASK", "confidence": 0.9855816960334778}]}, {"text": "Besides correcting ASR errors, users of IAs reformulate their previous utterances when they encounter NLU errors, LG errors, and soon.", "labels": [], "entities": [{"text": "ASR", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.7065884470939636}, {"text": "IAs reformulate their previous utterances", "start_pos": 40, "end_pos": 81, "type": "TASK", "confidence": 0.8678432464599609}]}, {"text": "For example, when a user utters \"alarm\", the NLU component may mistakenly conclude that s/he wants to perform a Web search, and consequently the system shows the search results for \"alarm.\" reported that only 12% of the errors in an IA system are related to ASR components, which is the smallest percentage across six components.", "labels": [], "entities": []}, {"text": "They also reported that the NLU component is the biggest source of errors (24%).", "labels": [], "entities": [{"text": "NLU component", "start_pos": 28, "end_pos": 41, "type": "DATASET", "confidence": 0.9267275035381317}, {"text": "errors", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.9954008460044861}]}, {"text": "Therefore, the errors related to the other components should not be ignored to improve system performance.", "labels": [], "entities": []}, {"text": "However, previous work mainly focused on reformulation caused by ASR error, and reformulation caused by the other components has received little attention.", "labels": [], "entities": [{"text": "reformulation", "start_pos": 41, "end_pos": 54, "type": "TASK", "confidence": 0.9826242327690125}, {"text": "ASR", "start_pos": 65, "end_pos": 68, "type": "TASK", "confidence": 0.8659907579421997}, {"text": "reformulation", "start_pos": 80, "end_pos": 93, "type": "TASK", "confidence": 0.9696286916732788}]}, {"text": "In this work, we propose a method to predict reformulation causes, i.e., detect the component responsible for causing the reformulation in IAs.", "labels": [], "entities": []}, {"text": "Features are divided into several categories mainly on the basis of their relations with the components in an IA.", "labels": [], "entities": []}, {"text": "The experiments demonstrate that these features can improve the error detection performances of corresponding components.", "labels": [], "entities": []}, {"text": "The proposed method which combines all features sets, outperforms the baseline, which uses componentindependent features such as session information and reformulation related information.", "labels": [], "entities": []}, {"text": "Our work makes the following contributions.", "labels": [], "entities": []}, {"text": "First, we investigate the reformulation causes among the components in IAs from real data of a commercial IA.", "labels": [], "entities": []}, {"text": "Second, we create dataset of human annotated data obtained from a commercial IA.", "labels": [], "entities": []}, {"text": "Finally, we develop the method to predict reformulation causes in IAs.", "labels": [], "entities": [{"text": "reformulation", "start_pos": 42, "end_pos": 55, "type": "TASK", "confidence": 0.8947131037712097}, {"text": "IAs", "start_pos": 66, "end_pos": 69, "type": "TASK", "confidence": 0.8878762722015381}]}], "datasetContent": [{"text": "Users of the search or conversational systems often reformulate their inputs when they are dissatisfied with the system responses to their previous inputs.", "labels": [], "entities": []}, {"text": "Therefore, reformulation is a useful signal of user dissatisfaction and information related to reformulation has been widely used as a feature to automatically evaluate system performance in web search (, dialogue, and IA systems (.", "labels": [], "entities": []}, {"text": "However, these studies paid little attention to detecting causes of user dissatisfaction.", "labels": [], "entities": []}, {"text": "Information of these causes is beneficial to the developers for both improving system design and engineering feature of automatic evaluation methods.", "labels": [], "entities": []}, {"text": "Thus, we propose a method to automatically detect the reformulation causes in IAs.", "labels": [], "entities": []}, {"text": "The experimental settings of reformulation cause prediction are as follows.", "labels": [], "entities": [{"text": "reformulation cause prediction", "start_pos": 29, "end_pos": 59, "type": "TASK", "confidence": 0.9500912229220072}]}, {"text": "\u2022 The dataset described in Section 3.2 is used for evaluation.", "labels": [], "entities": []}, {"text": "\u2022 We evaluate the performance of the model with 10-fold cross validation.", "labels": [], "entities": []}, {"text": "\u2022 We train the model using a linear SVM classifier with the features described in section 5.", "labels": [], "entities": []}, {"text": "\u2022 We optimize hyper parameters of the classifier with an additional 5-fold cross validation using only training sets (9-folds used fora training set is combined and split into 5 new folds in each validation).", "labels": [], "entities": []}, {"text": "\u2022 The baseline model is trained in the same conditions except that the model uses only Session and Reformulation features.", "labels": [], "entities": []}, {"text": "Comparison between the proposed and the baseline methods enables us to evaluate the effect of the features related to the components of IA.", "labels": [], "entities": [{"text": "IA", "start_pos": 136, "end_pos": 138, "type": "TASK", "confidence": 0.8473036885261536}]}, {"text": "We choose linear SVM because it has scalability and has outperformed RBF-kernel SVM.: Confusion matrix of reformulation cause prediction of (a) baseline and (b) proposed methods.", "labels": [], "entities": []}, {"text": "presents the results for the reformulation cause prediction.", "labels": [], "entities": [{"text": "reformulation cause prediction", "start_pos": 29, "end_pos": 59, "type": "TASK", "confidence": 0.9315400918324789}]}, {"text": "The first row compares the proposed method with the baseline.", "labels": [], "entities": []}, {"text": "The proposed method obtains a 0.67-point F 1 -measure and outperforms the baseline.", "labels": [], "entities": [{"text": "F 1 -measure", "start_pos": 41, "end_pos": 53, "type": "METRIC", "confidence": 0.9686833471059799}]}, {"text": "This result shows the effectiveness of the features related to the components of IA.", "labels": [], "entities": [{"text": "IA", "start_pos": 81, "end_pos": 83, "type": "TASK", "confidence": 0.9489671587944031}]}, {"text": "The second row illustrates the performance when one feature set is added to the baseline.", "labels": [], "entities": []}, {"text": "We can see that ASR and NLU features improve the performance of the baseline.", "labels": [], "entities": [{"text": "ASR", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.8875484466552734}]}, {"text": "In F 1 -measure, statistical significant differences from the baseline detected by the paired t-test are denoted by + (p < 0.01) and \u22c6 (p < 0.05).", "labels": [], "entities": [{"text": "F 1 -measure", "start_pos": 3, "end_pos": 15, "type": "METRIC", "confidence": 0.6902274340391159}]}, {"text": "presents the confusion matrix of the proposed and baseline methods.", "labels": [], "entities": []}, {"text": "The results going diagonally show agreement between the gold labels and the predicted labels.", "labels": [], "entities": []}, {"text": "As shown in, the proposed method outperforms the baseline regardless of the gold labels.", "labels": [], "entities": []}, {"text": "Again, these results indicate the effectiveness of the features related to the components of IA.", "labels": [], "entities": [{"text": "IA", "start_pos": 93, "end_pos": 95, "type": "TASK", "confidence": 0.9539973139762878}]}, {"text": "In other words, F 1 -measures for NLU error and LG error are not high.", "labels": [], "entities": [{"text": "F 1 -", "start_pos": 16, "end_pos": 21, "type": "METRIC", "confidence": 0.9867220719655355}, {"text": "NLU error", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.4431076943874359}, {"text": "LG error", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9254786670207977}]}, {"text": "As the performances of individual labels are in the order of the number of samples belonging to the label, we expect that these low performances are mainly due to insufficient data and will improve given sufficient data.", "labels": [], "entities": []}, {"text": "Focusing on individual feature sets, ASR and NLU features are useful for distinguishing No error from other labels.", "labels": [], "entities": []}, {"text": "Note that statistical significant differences from the baseline detected by the paired t-test are denoted by + (p < 0.01) and \u22c6 (p < 0.05).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Percentage of annotation labels in our  dataset. Error rate is calculated using labels re- lated to reformulation causes.", "labels": [], "entities": [{"text": "Error rate", "start_pos": 59, "end_pos": 69, "type": "METRIC", "confidence": 0.9891560673713684}]}, {"text": " Table 3: Example corrections of \"What's the  weather today?\" in each correction type.", "labels": [], "entities": []}, {"text": " Table 4: Distribution of correction types (%).", "labels": [], "entities": [{"text": "correction", "start_pos": 26, "end_pos": 36, "type": "METRIC", "confidence": 0.8015856146812439}]}, {"text": " Table 5: Distribution of input type switches (%).  For example, V2T means input type of U 1 is voice  input and that of U 2 is text input.", "labels": [], "entities": [{"text": "V2T", "start_pos": 65, "end_pos": 68, "type": "DATASET", "confidence": 0.8626722693443298}]}, {"text": " Table 8: The results of the reformulation cause  prediction.", "labels": [], "entities": [{"text": "reformulation cause  prediction", "start_pos": 29, "end_pos": 60, "type": "TASK", "confidence": 0.9024583299954733}]}, {"text": " Table 9: Confusion matrix of reformulation cause  prediction of (a) baseline and (b) proposed meth- ods.", "labels": [], "entities": [{"text": "reformulation", "start_pos": 30, "end_pos": 43, "type": "TASK", "confidence": 0.966795027256012}]}, {"text": " Table 10: F 1 -measure in reformulation cause pre- diction for each label.", "labels": [], "entities": [{"text": "F 1", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.9757601022720337}, {"text": "reformulation", "start_pos": 27, "end_pos": 40, "type": "TASK", "confidence": 0.9364576935768127}]}, {"text": " Table 11: F 1 -measure in reformulation cause pre- diction of each label between input types.", "labels": [], "entities": [{"text": "F 1", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.9720392525196075}, {"text": "reformulation", "start_pos": 27, "end_pos": 40, "type": "TASK", "confidence": 0.9541050791740417}]}, {"text": " Table 12: The number of predicted samples in  reformulation cause prediction in following two  conditions. First, U 1 and U 2 are voice inputs. Sec- ond, gold labels of all samples are No error.", "labels": [], "entities": []}, {"text": " Table 13: Top and Bottom two feature weights of  the proposed method. Features marked with \"*\"  were computed for U 1 .", "labels": [], "entities": []}]}