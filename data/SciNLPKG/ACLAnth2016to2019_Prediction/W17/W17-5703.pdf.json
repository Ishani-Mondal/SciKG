{"title": [{"text": "Improving Japanese-to-English Neural Machine Translation by Paraphrasing the Target Language", "labels": [], "entities": [{"text": "Improving Japanese-to-English Neural Machine Translation", "start_pos": 0, "end_pos": 56, "type": "TASK", "confidence": 0.8974065780639648}]}], "abstractContent": [{"text": "Neural machine translation (NMT) produces sentences that are more fluent than those produced by statistical machine translation (SMT).", "labels": [], "entities": [{"text": "Neural machine translation (NMT)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7992000033458074}, {"text": "statistical machine translation (SMT)", "start_pos": 96, "end_pos": 133, "type": "TASK", "confidence": 0.7937939763069153}]}, {"text": "However, NMT has a very high computational cost because of the high dimensionality of the output layer.", "labels": [], "entities": []}, {"text": "Generally, NMT restricts the size of the vocabulary, which results in infrequent words being treated as out-of-vocabulary (OOV) and degrades the performance of the translation.", "labels": [], "entities": []}, {"text": "In order to improve the translation quality regarding words that are OOV in the target language, we propose a preprocessing method that paraphrases infrequent words or phrases expressed as OOV with frequent synonyms from the target side of the training corpus.", "labels": [], "entities": []}, {"text": "In an evaluation using Japanese to English translation, we achieved a statistically significant BLEU score improvement of 0.55-0.77 over baselines that included the state-of-the-art method.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 96, "end_pos": 106, "type": "METRIC", "confidence": 0.9758285880088806}]}], "introductionContent": [{"text": "Recently, neural-network-based methods have gained considerable popularity in many natural language processing tasks.", "labels": [], "entities": [{"text": "natural language processing tasks", "start_pos": 83, "end_pos": 116, "type": "TASK", "confidence": 0.7162865698337555}]}, {"text": "In the field of machine translation, neural machine translation (NMT) is actively being researched because of the advantage that it can output sentences that are more fluent compared with statistical machine translation (SMT).", "labels": [], "entities": [{"text": "machine translation", "start_pos": 16, "end_pos": 35, "type": "TASK", "confidence": 0.7745410799980164}, {"text": "neural machine translation (NMT)", "start_pos": 37, "end_pos": 69, "type": "TASK", "confidence": 0.8128420015176138}, {"text": "statistical machine translation (SMT)", "start_pos": 188, "end_pos": 225, "type": "TASK", "confidence": 0.8108260134855906}]}, {"text": "However, NMT has a problem of high computational cost because it addresses the output generation task by solving a classification problem in vocabulary dimension.", "labels": [], "entities": []}, {"text": "Typically, NMT has to restrict the size of the vocabulary to reduce the computational cost.", "labels": [], "entities": []}, {"text": "Therefore, the target language vocabulary includes only high-frequency words (e.g.,,000 high-frequency words) in training; other words are treated as out-of-vocabulary (OOV) and substituted with a special symbol such as \"<unk>\" in the output.", "labels": [], "entities": []}, {"text": "The symbol has no meaning, so the output has reduced quality.", "labels": [], "entities": []}, {"text": "As a previous work attempting to reduce the OOV rate in NMT,, replaced OOV words with a translation table using word similarity in the training and test data.", "labels": [], "entities": [{"text": "OOV rate", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.987718939781189}]}, {"text": "In particular, they replaced each OOV word with an in-vocabulary word using word similarity in a parallel training corpus; they reduced the OOV rate in the output and improved the translation quality.", "labels": [], "entities": [{"text": "OOV rate", "start_pos": 140, "end_pos": 148, "type": "METRIC", "confidence": 0.9829303026199341}]}, {"text": "However, they sometimes substituted OOV words with a similar word such as a proper noun.", "labels": [], "entities": []}, {"text": "In addition, they deleted OOV words that aligned to null, which can result in a loss of sentence content and reduced translation adequacy.", "labels": [], "entities": []}, {"text": "In this work, we present a preprocessing method for improving translation related to OOV words.", "labels": [], "entities": []}, {"text": "We paraphrase low-frequency words treated as OOV in the target corpus with high-frequency words while retaining the meaning.", "labels": [], "entities": []}, {"text": "Our main contributions are as follows.", "labels": [], "entities": []}, {"text": "\u2022 We propose a paraphrasing-based preprocessing method for Japanese-to-English NMT to improve translation accuracy with regard to OOV words.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.8950861692428589}]}, {"text": "Our method can be combined with any NMT system.", "labels": [], "entities": []}, {"text": "\u2022 We show that our method achieved a statistically significant BLEU () score improvement of 0.58 and a ME-TEOR () score improvement of 0.52 over the previous method ( and reduced the OOV rate in output sentences by approximately 0.20.", "labels": [], "entities": [{"text": "BLEU () score improvement", "start_pos": 63, "end_pos": 88, "type": "METRIC", "confidence": 0.9287008792161942}, {"text": "ME-TEOR () score improvement", "start_pos": 103, "end_pos": 131, "type": "METRIC", "confidence": 0.9354734271764755}, {"text": "OOV rate", "start_pos": 183, "end_pos": 191, "type": "METRIC", "confidence": 0.9894343316555023}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Japanese-to-English translation result of each method.  \u2020 and  *  indicate that the proposed method  significantly outperformed the other methods at p<0.01 and p<0.05, respectively, using bootstrap resam- pling.", "labels": [], "entities": []}, {"text": " Table 2: English-to-Japanese translation results  with variations in the number of paraphrasings and  the unit used.", "labels": [], "entities": [{"text": "English-to-Japanese translation", "start_pos": 10, "end_pos": 41, "type": "TASK", "confidence": 0.5306307226419449}]}]}