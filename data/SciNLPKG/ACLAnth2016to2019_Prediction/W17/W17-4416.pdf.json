{"title": [{"text": "Improving Document Clustering by Eliminating Unnatural Language", "labels": [], "entities": [{"text": "Improving Document Clustering", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.9500246047973633}]}], "abstractContent": [{"text": "Technical documents contain a fair amount of unnatural language, such as tables, formulas , and pseudo-code.", "labels": [], "entities": []}, {"text": "Unnatural language can bean important factor of confusing existing NLP tools.", "labels": [], "entities": []}, {"text": "This paper presents an effective method of distinguishing unnatural language from natural language, and evaluates the impact of unnatural language detection on NLP tasks such as document clustering.", "labels": [], "entities": [{"text": "unnatural language detection", "start_pos": 128, "end_pos": 156, "type": "TASK", "confidence": 0.6966790358225504}, {"text": "document clustering", "start_pos": 178, "end_pos": 197, "type": "TASK", "confidence": 0.7330003529787064}]}, {"text": "We view this problem as an information extraction task and build a multiclass classification model identifying unnatural language components into four categories.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 27, "end_pos": 49, "type": "TASK", "confidence": 0.808511883020401}]}, {"text": "First, we create anew annotated corpus by collecting slides and papers in various formats, PPT, PDF, and HTML, where unnatural language components are annotated into four categories.", "labels": [], "entities": []}, {"text": "We then explore features available from plain text to build a statistical model that can handle any format as long as it is converted into plain text.", "labels": [], "entities": []}, {"text": "Our experiments show that removing unnatural language components gives an absolute improvement in document clustering by up to 15%.", "labels": [], "entities": [{"text": "document clustering", "start_pos": 98, "end_pos": 117, "type": "TASK", "confidence": 0.7325170338153839}]}, {"text": "Our corpus and tool are publicly available.", "labels": [], "entities": []}], "introductionContent": [{"text": "Technical documents typically include meta components such as figures, tables, mathematical formulas, and pseudo-code to effectively communicate complex ideas and results.", "labels": [], "entities": []}, {"text": "Let us define the term unnatural language as text blocks that consist of only meta components as opposed to natural language that consists of body text.", "labels": [], "entities": []}, {"text": "There are many effective NLP tools available as the field has been advanced.", "labels": [], "entities": []}, {"text": "However, these tools are mostly built for input text that are natural language.", "labels": [], "entities": []}, {"text": "As many of our tools for NLP can be badly confused by unnatural language, it is necessary to distinguish unnatural language blocks from natural language blocks, or else unnatural language blocks will cause confusion for natural language processing.", "labels": [], "entities": []}, {"text": "Once we salvage natural language blocks from the documents, we can exploit NLP tools much better as they are intended for.", "labels": [], "entities": []}, {"text": "This phenomenon is emphasized in technical documents that have a higher ratio of unnatural language compared to non-technical documents such as essays and novels.", "labels": [], "entities": []}, {"text": "Document layout analysis aiming to identify document format by classifying blocks into text, figures, and tables has been a long-studied problem).", "labels": [], "entities": [{"text": "Document layout analysis", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9185545245806376}, {"text": "identify document format", "start_pos": 35, "end_pos": 59, "type": "TASK", "confidence": 0.7191599408785502}]}, {"text": "Most previous work have focused on image-based documents, PDF and OCR formats, and used geometric analysis on the pages using the visual cues from its layout.", "labels": [], "entities": []}, {"text": "This was a clearly important problem in many applications in NLP and IR.", "labels": [], "entities": [{"text": "IR", "start_pos": 69, "end_pos": 71, "type": "TASK", "confidence": 0.9396973848342896}]}, {"text": "This work was particularly motivated while we attempted to cluster teaching documents (e.g., lecture slides and reading materials from courses) in technical topics.", "labels": [], "entities": []}, {"text": "We discovered that unnatural language blocks introduced significant noise for clustering, causing spurious matches between documents.", "labels": [], "entities": []}, {"text": "For example, code consists of reserved programming keywords and variable names.", "labels": [], "entities": []}, {"text": "Two documents can contain two very different code blocks from one another but their cosine similarity is high because they share many terms by programming convention).", "labels": [], "entities": []}, {"text": "() also recognized this problem by explaining main challenges of semantic search for mathematical formula: (1) Mathematical notation is context-dependent; without human's capability to understand the formula from the context, formulas are just noise.", "labels": [], "entities": []}, {"text": "(2) Identical presentations can stand for multiple distinct mathematical objects.", "labels": [], "entities": []}, {"text": "This paper proposes anew approach for identifying unnatural language blocks in plain text into four types of categories: (1) TABLE (2) CODE (3) MATH-EMATICAL FORMULA, and (4) MISCELLANEOUS (MISC).", "labels": [], "entities": [{"text": "identifying unnatural language blocks in plain text", "start_pos": 38, "end_pos": 89, "type": "TASK", "confidence": 0.7877351215907505}, {"text": "TABLE", "start_pos": 125, "end_pos": 130, "type": "METRIC", "confidence": 0.9908269047737122}, {"text": "CODE", "start_pos": 135, "end_pos": 139, "type": "METRIC", "confidence": 0.9463096261024475}, {"text": "MATH-EMATICAL", "start_pos": 144, "end_pos": 157, "type": "METRIC", "confidence": 0.8823626041412354}, {"text": "FORMULA", "start_pos": 158, "end_pos": 165, "type": "METRIC", "confidence": 0.5336312651634216}]}, {"text": "Text is extracted from technical documents in PDF, PPT, and HTML formats with little to no explicit visual layout information preserved.", "labels": [], "entities": []}, {"text": "We focus on technical documents because they have a significant amount of unnatural language blocks (26.3% and 16% in our two corpora).", "labels": [], "entities": []}, {"text": "Specifically, we focus on documents in slide formats, which have been underexplored.", "labels": [], "entities": []}, {"text": "We further study how removal of unnatural language improves two NLP tasks: document similarity and document clustering.", "labels": [], "entities": [{"text": "document similarity", "start_pos": 75, "end_pos": 94, "type": "TASK", "confidence": 0.634514793753624}, {"text": "document clustering", "start_pos": 99, "end_pos": 118, "type": "TASK", "confidence": 0.7140142470598221}]}, {"text": "Our experiments show that clustering on documents with unnatural language removed consistently showed higher accuracy on many of the settings than on original documents, with the maximum improvements up to 15% and 11% in two datasets, while it never significantly hurts the original clustering.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 109, "end_pos": 117, "type": "METRIC", "confidence": 0.9990711212158203}]}], "datasetContent": [{"text": "We use the Liblinear Support Vector Machine (SVM) (Chang and Lin, 2011) classifier for training and run 5-fold cross-validation for evaluation.", "labels": [], "entities": []}, {"text": "To improve the robustness of structured prediction, we adopt a learning to search algorithm known as DAGGER to SVM).", "labels": [], "entities": [{"text": "structured prediction", "start_pos": 29, "end_pos": 50, "type": "TASK", "confidence": 0.695961594581604}, {"text": "DAGGER", "start_pos": 101, "end_pos": 107, "type": "METRIC", "confidence": 0.8259867429733276}]}, {"text": "We first introduce two baselines to compare the accuracy against our statistical model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9995527863502502}]}], "tableCaptions": [{"text": " Table 1: Datasets used in our paper. All data are available for download at [http://cs.umass.edu/  ~mhjang/publications.html]", "labels": [], "entities": []}, {"text": " Table 2: % of lines by unnatural category. Both  datasets have quite a bit of unnatural language  (26.3% for T SLIDES and 16% for T ACL ), though  T ACL has more TABLES and FORMULAS and less", "labels": [], "entities": [{"text": "TABLES", "start_pos": 163, "end_pos": 169, "type": "METRIC", "confidence": 0.9883406162261963}, {"text": "FORMULAS", "start_pos": 174, "end_pos": 182, "type": "METRIC", "confidence": 0.9897326827049255}]}, {"text": " Table 4: Multi-domain classification improves the  single-domain classification in Table 3. Identifica- tion of categories with particularly low accuracy in  each datasets (TABLE and FORMULA in T SLIDES  and CODE in T ACL ) are improved to be as good as  the other categories.", "labels": [], "entities": [{"text": "Multi-domain classification", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.7847307920455933}, {"text": "Identifica- tion", "start_pos": 93, "end_pos": 109, "type": "METRIC", "confidence": 0.9712072610855103}, {"text": "accuracy", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.9957466721534729}, {"text": "TABLE", "start_pos": 174, "end_pos": 179, "type": "METRIC", "confidence": 0.991678774356842}, {"text": "FORMULA", "start_pos": 184, "end_pos": 191, "type": "METRIC", "confidence": 0.9708616733551025}]}, {"text": " Table 3: Single-domain Classification Result in F1-score: Proposed method is much better than baselines  for classifying unnatural language. Note that we borrowed the F1-score reported on their dataset for  reference. The number is not directly comparable to other numbers since the datasets are different.", "labels": [], "entities": [{"text": "Single-domain Classification Result", "start_pos": 10, "end_pos": 45, "type": "TASK", "confidence": 0.7508038679758707}, {"text": "F1-score", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9934506416320801}, {"text": "F1-score", "start_pos": 168, "end_pos": 176, "type": "METRIC", "confidence": 0.9913673996925354}]}]}