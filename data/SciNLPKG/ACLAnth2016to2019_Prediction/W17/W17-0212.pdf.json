{"title": [{"text": "Linear Ensembles of Word Embedding Models", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper explores linear methods for combining several word embedding models into an ensemble.", "labels": [], "entities": []}, {"text": "We construct the combined models using an iterative method based on either ordinary least squares regression or the solution to the orthogonal Procrustes problem.", "labels": [], "entities": []}, {"text": "We evaluate the proposed approaches on Estonian-a morphologically complex language, for which the available corpora for training word embeddings are relatively small.", "labels": [], "entities": [{"text": "Estonian-a morphologically complex language", "start_pos": 39, "end_pos": 82, "type": "TASK", "confidence": 0.5371869951486588}]}, {"text": "We compare both combined models with each other and with the input word embedding models using synonym and analogy tests.", "labels": [], "entities": []}, {"text": "The results show that while using the ordinary least squares regression performs poorly in our experiments, using orthogonal Procrustes to combine several word embedding models into an ensemble model leads to 7-10% relative improvements over the mean result of the initial models in synonym tests and 19-47% in analogy tests.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word embeddings-dense low-dimensional vector representations of words-have become very popular in recent years in the field of natural language processing (NLP).", "labels": [], "entities": [{"text": "Word embeddings-dense low-dimensional vector representations of words-have", "start_pos": 0, "end_pos": 74, "type": "TASK", "confidence": 0.7559394368103572}, {"text": "natural language processing (NLP)", "start_pos": 127, "end_pos": 160, "type": "TASK", "confidence": 0.8090849220752716}]}, {"text": "Various methods have been proposed to train word embeddings from unannoted text corpora (), most well-known of them being perhaps Word2Vec ().", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 130, "end_pos": 138, "type": "DATASET", "confidence": 0.9390965104103088}]}, {"text": "Embedding learning systems essentially train a model from a corpus of text and the word embeddings are the model parameters.", "labels": [], "entities": []}, {"text": "These systems contain a randomized component and so the trained models are not directly comparable, even when they have been trained on exactly the same data.", "labels": [], "entities": []}, {"text": "This random behaviour provides an opportunity to combine several embedding models into an ensemble which, hopefully, results in a better set of word embeddings.", "labels": [], "entities": []}, {"text": "Although model ensembles have been often used in various NLP systems to improve the overall accuracy, the idea of combining several word embedding models into an ensemble has not been explored before.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9985559582710266}]}, {"text": "The main contribution of this paper is to show that word embeddings can benefit from ensemble learning, too.", "labels": [], "entities": []}, {"text": "We study two methods for combining word embedding models into an ensemble.", "labels": [], "entities": []}, {"text": "Both methods use a simple linear transformation.", "labels": [], "entities": []}, {"text": "First of them is based on the standard ordinary least squares solution (OLS) for linear regression, the second uses the solution to the orthogonal Procrustes problem (OPP), which essentially also solves the OLS but adds the orthogonality constraint that keeps the angles between vectors and their distances unchanged.", "labels": [], "entities": []}, {"text": "There are several reasons why using an ensemble of word embedding models could be useful.", "labels": [], "entities": []}, {"text": "First is the typical ensemble learning argumentthe ensemble simply is better because it enables to cancel out random noise of individual models and reinforce the useful patterns expressed by several input models.", "labels": [], "entities": []}, {"text": "Secondly, word embedding systems require a lot of training data to learn reliable word representations.", "labels": [], "entities": []}, {"text": "While there is a lot of textual data available for English, there are many smaller languages for which even obtaining enough plain unannotated text for training reliable embeddings is a problem.", "labels": [], "entities": []}, {"text": "Thus, an ensemble approach that would enable to use the available data more effectively would be beneficial.", "labels": [], "entities": []}, {"text": "According to our knowledge, this is the first work that attempts to leverage the data by combining several word embedding models into anew improved model.", "labels": [], "entities": []}, {"text": "Linear methods for combin-ing two embedding models for some task-specific purpose have been used previously.", "labels": [], "entities": []}, {"text": "optimized the linear regression with stochastic gradient descent to learn linear transformations between the embeddings in two languages for machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 141, "end_pos": 160, "type": "TASK", "confidence": 0.758427768945694}]}, {"text": "used OPP to translate embeddings between two languages to perform cross-lingual document classification.", "labels": [], "entities": [{"text": "cross-lingual document classification", "start_pos": 66, "end_pos": 103, "type": "TASK", "confidence": 0.6742883324623108}]}, {"text": "aligned a series of embedding models with OPP to detect changes in word meanings overtime.", "labels": [], "entities": []}, {"text": "The same problem was addressed by who aligned the embedding models using piecewise linear regression based on a set of nearest neighboring words for each word.", "labels": [], "entities": []}, {"text": "Recently, experimented with several methods to learn meta-embeddings by combining different word embedding sets.", "labels": [], "entities": []}, {"text": "Our work differs from theirs in two important aspects.", "labels": [], "entities": []}, {"text": "First, in their work each initial model is trained with a different word embedding system and on a different data set, while we propose to combine the models trained with the same system and on the same dataset, albeit using different random initialisation.", "labels": [], "entities": []}, {"text": "Secondly, although the 1toN model proposed in) is very similar to the linear models studied in this paper, it doesn't involve the orthogonality constraint included in the OPP method, which in our experiments, as shown later, proves to be crucial.", "labels": [], "entities": []}, {"text": "We conduct experiments on Estonian and construct ensembles from ten different embedding models trained with Word2Vec.", "labels": [], "entities": [{"text": "Estonian", "start_pos": 26, "end_pos": 34, "type": "DATASET", "confidence": 0.9287267923355103}, {"text": "Word2Vec", "start_pos": 108, "end_pos": 116, "type": "DATASET", "confidence": 0.9662637114524841}]}, {"text": "We compare the initial and combined models in synonym and analogy tests and find that the ensemble embeddings combined with orthogonal Procrustes method indeed perform significantly better in both tests, leading to a relative improvement of 7-10% over the mean result of the initial models in synonym tests and 19-47% in analogy tests.", "labels": [], "entities": []}], "datasetContent": [{"text": "We tested both methods on a number of Word2Vec models () trained on the Estonian Reference Corpus.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 38, "end_pos": 46, "type": "DATASET", "confidence": 0.9355368614196777}, {"text": "Estonian Reference Corpus", "start_pos": 72, "end_pos": 97, "type": "DATASET", "confidence": 0.9831562240918478}]}, {"text": "Corpus is the largest text corpus available for Estonian.", "labels": [], "entities": []}, {"text": "Its size is approximately 240M word tokens, which may seem like a lot but compared to for instance English Gigaword corpus, which is often used to train word embeddings for English words and which contains more than 4B words, it is quite small.", "labels": [], "entities": [{"text": "English Gigaword corpus", "start_pos": 99, "end_pos": 122, "type": "DATASET", "confidence": 0.8768956462542216}]}, {"text": "All models were trained using a window size 10 and the skip-gram architecture.", "labels": [], "entities": []}, {"text": "We experimented with models of 6 different embedding sizes: 50, 100, 150, 200, 250 and 300.", "labels": [], "entities": []}, {"text": "For each dimensionality we had 10 models available.", "labels": [], "entities": []}, {"text": "The number of distinct words in each model is 816757.", "labels": [], "entities": []}, {"text": "During training the iterative algorithm was run until the convergence threshold th = 0.001 was reached.", "labels": [], "entities": [{"text": "convergence threshold th", "start_pos": 58, "end_pos": 82, "type": "METRIC", "confidence": 0.9536343614260355}]}, {"text": "The number of iterations needed for convergence for both methods and for models with different embedding size are given in Table 1.", "labels": [], "entities": []}, {"text": "It can be seen that the convergence with SOPP took significantly fewer iterations than with SOLS.", "labels": [], "entities": []}, {"text": "This difference is probably due to two aspects: 1) SOPP has the additional orthogonality constraint which reduces the space of feasible solutions; 2) although SOLS uses the exact analytical solutions for the least squares problem, the final solution for Y does not move directly to the direction pointed to by the analytical solutions due to the variance rescaling.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Final errors and the number of iterations  until convergence for both SOLS and SOPP. The  first column shows the embedding size.  .", "labels": [], "entities": [{"text": "Final errors", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.9168943464756012}]}, {"text": " Table 2: Average mean ranks of the synonym test,  smaller values are better. The best result in each  row is in bold. All differences are statistically sig- nificant: with p < 2.2 \u00b7 10 \u221216 for all cases.", "labels": [], "entities": []}, {"text": " Table 3: Hit@1 and Hit@10 accuracies of the analogy test. SOLS and SOPP columns show the accu- racies of the combined models. Mean W , Min W and Max W show the mean, minimum and maximum  accuracies of the initial models W i , respectively. The best accuracy among the combined models and the  mean of the initial models is given in bold. The last row shows the average accuracies over all embedding  sizes.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 250, "end_pos": 258, "type": "METRIC", "confidence": 0.9989664554595947}]}]}