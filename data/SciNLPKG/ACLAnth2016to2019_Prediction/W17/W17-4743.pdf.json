{"title": [{"text": "PJIIT's systems for WMT 2017 Conference", "labels": [], "entities": [{"text": "WMT 2017", "start_pos": 20, "end_pos": 28, "type": "TASK", "confidence": 0.8352749049663544}]}], "abstractContent": [{"text": "In this paper, we attempt to improve Statistical Machine Translation (SMT) systems between Czech, Latvian and English in WNT'17 News translation task.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 37, "end_pos": 74, "type": "TASK", "confidence": 0.8240206638971964}, {"text": "WNT'17 News translation", "start_pos": 121, "end_pos": 144, "type": "TASK", "confidence": 0.7444913784662882}]}, {"text": "We also participated in the Biomedical task and produces translation engines from English into Polish, Czech, German, Spanish, French, Hungarian, Romanian and Swedish.", "labels": [], "entities": [{"text": "Biomedical task", "start_pos": 28, "end_pos": 43, "type": "TASK", "confidence": 0.8634378910064697}]}, {"text": "To accomplish this, we performed translation model training, created adaptations of training settings for each language pair, and implemented BPE (subword units) for our SMT systems.", "labels": [], "entities": [{"text": "translation model training", "start_pos": 33, "end_pos": 59, "type": "TASK", "confidence": 0.9025905132293701}, {"text": "BPE", "start_pos": 142, "end_pos": 145, "type": "METRIC", "confidence": 0.9829026460647583}, {"text": "SMT", "start_pos": 170, "end_pos": 173, "type": "TASK", "confidence": 0.982948899269104}]}, {"text": "Innovative tools and data adaptation techniques were employed.", "labels": [], "entities": [{"text": "data adaptation", "start_pos": 21, "end_pos": 36, "type": "TASK", "confidence": 0.7652490735054016}]}, {"text": "Only the official parallel text corpora and monolingual models for the WMT 2017 evaluation campaign were used to train language models, and to develop, tune, and test the system.", "labels": [], "entities": [{"text": "WMT 2017 evaluation campaign", "start_pos": 71, "end_pos": 99, "type": "DATASET", "confidence": 0.7017113417387009}]}, {"text": "We explored the use of domain adaptation techniques, symmetrized word alignment models, the unsupervised transliteration models and the KenLM language modeling tool.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.7410677969455719}, {"text": "word alignment", "start_pos": 65, "end_pos": 79, "type": "TASK", "confidence": 0.6853376626968384}, {"text": "KenLM language modeling", "start_pos": 136, "end_pos": 159, "type": "TASK", "confidence": 0.6282533506552378}]}, {"text": "To evaluate the effects of different preparations on translation results, we conducted experiments and used the BLEU, NIST and TER metrics.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 112, "end_pos": 116, "type": "METRIC", "confidence": 0.9984601736068726}, {"text": "NIST", "start_pos": 118, "end_pos": 122, "type": "DATASET", "confidence": 0.8446438312530518}, {"text": "TER", "start_pos": 127, "end_pos": 130, "type": "METRIC", "confidence": 0.9957774877548218}]}, {"text": "Our results indicate that our approach produced a positive impact on SMT quality.", "labels": [], "entities": [{"text": "SMT", "start_pos": 69, "end_pos": 72, "type": "TASK", "confidence": 0.9970695376396179}]}], "introductionContent": [{"text": "Statistical Machine Translation (SMT) must deal with a number of problems to achieve high quality.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.8518813014030456}]}, {"text": "These problems include the need to align parallel texts in language pairs and cleaning harvested parallel corpora to remove errors.", "labels": [], "entities": []}, {"text": "This is especially true for real-world corpora developed from text harvested from the vast data available on the Internet.", "labels": [], "entities": []}, {"text": "Out-Of-Vocabulary (OOV) words must also be handled, as they are inevitable in real-world texts).", "labels": [], "entities": []}, {"text": "The lack of enough parallel corpora for some less popular languages is another significant challenge for SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 105, "end_pos": 108, "type": "TASK", "confidence": 0.9948175549507141}]}, {"text": "Since the approach is statistical in nature, a significant amount of quality language pair data is needed to improve translation accuracy.", "labels": [], "entities": [{"text": "translation", "start_pos": 117, "end_pos": 128, "type": "TASK", "confidence": 0.9573338031768799}, {"text": "accuracy", "start_pos": 129, "end_pos": 137, "type": "METRIC", "confidence": 0.7372817397117615}]}, {"text": "In addition, very general translation systems that work in a general text domain have accuracy problems in specific domains.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9961583018302917}]}, {"text": "SMT systems are more accurate on corpora from a domain that is not too wide.", "labels": [], "entities": [{"text": "SMT", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9839682579040527}]}, {"text": "This exacerbates the data problem, calling for the enhancement of parallel corpora for particular text domains.", "labels": [], "entities": []}, {"text": "This paper describes SMT research that addresses these problems, particularly domain adaptation within the limits of permissible data for the WMT 2017 campaign.", "labels": [], "entities": [{"text": "SMT", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.9965590834617615}, {"text": "domain adaptation", "start_pos": 78, "end_pos": 95, "type": "TASK", "confidence": 0.7414434254169464}, {"text": "WMT 2017 campaign", "start_pos": 142, "end_pos": 159, "type": "TASK", "confidence": 0.6174518764019012}]}, {"text": "To accomplish this, we performed model training, created adaptations of training settings and data for each language pair.", "labels": [], "entities": []}, {"text": "Innovative tools and data adaptation techniques were employed.", "labels": [], "entities": [{"text": "data adaptation", "start_pos": 21, "end_pos": 36, "type": "TASK", "confidence": 0.7652490735054016}]}, {"text": "We explored the use of domain adaptation techniques, symmetrized word alignment models, the unsupervised transliteration models, and the KenLM language modeling tool.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.7362408638000488}, {"text": "word alignment", "start_pos": 65, "end_pos": 79, "type": "TASK", "confidence": 0.6853843629360199}, {"text": "KenLM language modeling", "start_pos": 137, "end_pos": 160, "type": "TASK", "confidence": 0.6549652616182963}]}, {"text": "To evaluate the effects of different preparations on translation results, we conducted experiments and evaluated the results using standard SMT metrics (.", "labels": [], "entities": [{"text": "SMT", "start_pos": 140, "end_pos": 143, "type": "TASK", "confidence": 0.9894416332244873}]}, {"text": "The languages translated during this research were: Czech, Latvian and English in WNT'17 News translation task.", "labels": [], "entities": [{"text": "WNT'17 News translation task", "start_pos": 82, "end_pos": 110, "type": "TASK", "confidence": 0.7568607032299042}]}, {"text": "We also participated in the Biomedical task and produces translation engines from English into Polish, Czech, German, Spanish, French, Hungarian, Romanian and Swedish.", "labels": [], "entities": [{"text": "Biomedical task", "start_pos": 28, "end_pos": 43, "type": "TASK", "confidence": 0.8634382784366608}]}, {"text": "This paper is structured as follows: Section 2 explains the data preparation.", "labels": [], "entities": []}, {"text": "Section 3 presents experimental setup and the results.", "labels": [], "entities": []}, {"text": "Lastly in Section 4 we summarize the work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Various versions of our SMT systems were evaluated via experimentation.", "labels": [], "entities": [{"text": "SMT", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.9912817478179932}]}, {"text": "In preparation for experiments, we processed the corpora.", "labels": [], "entities": []}, {"text": "This involved tokenization, cleaning, factorization, conversion to lowercase, splitting, and final cleaning after splitting.", "labels": [], "entities": []}, {"text": "Language models were developed and tuned using only the constrained training data.", "labels": [], "entities": []}, {"text": "The Experiment Management System () from the open source Moses SMT toolkit was used to conduct the experiments.", "labels": [], "entities": []}, {"text": "Training of a 6-gram language model was accomplished in our resulting systems using the KenLM Modeling Toolkit instead of 5-gram SRILM) with an interpolated version of Kneser-Key discounting (interpolateunk -kndiscount) that was used in our baseline systems.", "labels": [], "entities": []}, {"text": "Word and phrase alignment was performed using SyMGIZA++) instead of GIZA++.", "labels": [], "entities": [{"text": "Word and phrase alignment", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.5644422248005867}]}, {"text": "KenLM was also used, as described earlier, to binarize the language models.", "labels": [], "entities": []}, {"text": "The OOV's were handled by using Unsupervised Transliteration Model.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "\"BASE\" in the tables represents the baseline SMT system.", "labels": [], "entities": [{"text": "BASE", "start_pos": 1, "end_pos": 5, "type": "METRIC", "confidence": 0.9990885257720947}, {"text": "SMT", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.9889847040176392}]}, {"text": "\"EXT\" indicates results for the baseline system, using the baseline settings but extended with additional permissible data (limited to permissible data) with data adaptation.", "labels": [], "entities": [{"text": "EXT", "start_pos": 1, "end_pos": 4, "type": "METRIC", "confidence": 0.8499807715415955}]}, {"text": "\"BEST\" indicates the results when the new SMT settings were applied and using all permissible data after data adaptation.", "labels": [], "entities": [{"text": "BEST", "start_pos": 1, "end_pos": 5, "type": "METRIC", "confidence": 0.9994440674781799}, {"text": "SMT", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.9868038296699524}]}, {"text": "Three well-known metrics were used for scoring the results: Bilingual Evaluation Understudy (BLEU), the US National Institute of Standards and Technology (NIST) metric and Translation Error Rate (TER).", "labels": [], "entities": [{"text": "Bilingual Evaluation Understudy (BLEU)", "start_pos": 60, "end_pos": 98, "type": "METRIC", "confidence": 0.8423967063426971}, {"text": "Translation Error Rate (TER)", "start_pos": 172, "end_pos": 200, "type": "METRIC", "confidence": 0.8944202760855356}]}, {"text": "The results show that the systems performed well on all data sets in comparison to the baseline SMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 96, "end_pos": 99, "type": "TASK", "confidence": 0.986785352230072}]}, {"text": "Application of the new settings and use of all permissible data improved performance even more.", "labels": [], "entities": []}], "tableCaptions": []}