{"title": [], "abstractContent": [{"text": "Although social media has made it easy for people to connect on a virtually unlimited basis, it has also opened doors to people who misuse it to undermine, harass , humiliate, threaten and bully others.", "labels": [], "entities": []}, {"text": "There is alack of adequate resources to detect and hinder its occurrence.", "labels": [], "entities": []}, {"text": "In this paper , we present our initial NLP approach to detect invective posts as a first step to eventually detect and deter cyberbullying.", "labels": [], "entities": []}, {"text": "We crawl data containing profanities and then determine whether or not it contains invective.", "labels": [], "entities": []}, {"text": "Annotations on this data are improved iteratively by in-lab annotations and crowdsourcing.", "labels": [], "entities": []}, {"text": "We pursue different NLP approaches containing various typical and some newer techniques to distinguish the use of swear words in a neutral way from those instances in which they are used in an insulting way.", "labels": [], "entities": []}, {"text": "We also show that this model not only works for our data set, but also can be successfully applied to different data sets.", "labels": [], "entities": []}], "introductionContent": [{"text": "As the internet has become the preferred means of communication worldwide , it has introduced new benefits as well as new dangers.", "labels": [], "entities": []}, {"text": "One of the most unfortunate effects of online interconnectedness is Cyberbullying -defined as the deliberate use of information/communication technologies (ICT's) to cause harm to people by causing a loss of both self-esteem and the esteem of their friendship circles.", "labels": [], "entities": []}, {"text": "The groups most affected by this phenomenon are teens and pre-teens ().", "labels": [], "entities": []}, {"text": "According to a High School Youth Risk Behavior Survey, 14.8% of students surveyed nationwide in the United States (US) reported being bullied electronically).", "labels": [], "entities": []}, {"text": "Another research done by the Cyberbullying Research Center) from 2007 to 2015 shows that on average, 26.3% of middle and high school students from across the United States have been victims of cyberbullying at some point in their lives.", "labels": [], "entities": []}, {"text": "Also, on average, about 16% of the students have admitted that they have cyberbullied others at some point in their lives.", "labels": [], "entities": []}, {"text": "Studies have shown that cyberbullying victims face social, emotional, physiological and psychological disorders that lead them to harm themselves ().", "labels": [], "entities": []}, {"text": "In this research we perform the initial step towards detecting invective in online posts from social media sites used by teens, as we believe it can be the starting point of cyberbullying events.", "labels": [], "entities": [{"text": "detecting invective in online posts from social media sites", "start_pos": 53, "end_pos": 112, "type": "TASK", "confidence": 0.7621232006284926}]}, {"text": "We first create a data set that includes highly negative posts from ask.fm. ask.fm is a semianonymous social network, where anyone can post a question to any other user, and may choose to do so anonymously.", "labels": [], "entities": []}, {"text": "Given that people tend to engage in cyberbullying behavior under the cover of anonymity (, the anonymity option in ask.fm, as in other social media platforms, allows attackers the power to freely harass users by flooding their pages with profanity-laden questions and comments.", "labels": [], "entities": []}, {"text": "Seeing a lot of vile messages in one's profile page often disturbs the user.", "labels": [], "entities": []}, {"text": "Several teen suicides have been attributed to cyberbullying in ask.fm.", "labels": [], "entities": []}, {"text": "This phenomenon motivated us to crawl a number of ask.fm accounts and to analyze them manually to ascertain how cyberbullying is carried out in this particular site.", "labels": [], "entities": []}, {"text": "We learned that victims have their profile page flooded with abusive posts.", "labels": [], "entities": []}, {"text": "Then from identifying victims of cyberbullying, we switched to looking for word patterns that make a post abusive.", "labels": [], "entities": []}, {"text": "Since, abusive posts are rare compared to the rest of online posts, in order to ensure that we would obtain enough invective posts, we decided to focus exclusively on posts that contain profanity.", "labels": [], "entities": []}, {"text": "This is analogous to the method used in data collection by; they limited their Twitter data to tweets containing the words bully, bullied, bullying.", "labels": [], "entities": []}, {"text": "The main contributions of this paper are as follows: We create anew resource to investigate negative posts in asocial media platform used predominantly by teens, and make our data set public.", "labels": [], "entities": []}, {"text": "The most noticeable difference of our data set with previous similar corpora is that it provides a generalized view of invective posts, which is not biased towards a specific topic or target group.", "labels": [], "entities": []}, {"text": "In our data, each post is judged by three different annotators.", "labels": [], "entities": []}, {"text": "Then we perform experiments with both typical features (e.g. linguistic, sentiment and domain related) and newer features (e.g. embedding and topic modeling), and combinations of these features to automatically identify potential invective posts.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 142, "end_pos": 156, "type": "TASK", "confidence": 0.7243442535400391}]}, {"text": "We also show the robustness of our model by evaluating it on different data sets (Wikipedia Abusive Language Data Set, and Kaggle).", "labels": [], "entities": [{"text": "Wikipedia Abusive Language Data Set", "start_pos": 82, "end_pos": 117, "type": "DATASET", "confidence": 0.9206875443458558}, {"text": "Kaggle", "start_pos": 123, "end_pos": 129, "type": "DATASET", "confidence": 0.8910828828811646}]}, {"text": "Finally, we do an analysis of bad word distributions in our data that, among other things, reflects a sexualized teen culture.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we evaluate our methods on three different data sets we presented in Section 3.", "labels": [], "entities": []}, {"text": "Our goal is to show our model works well not only for our data set, but also for the others.", "labels": [], "entities": []}, {"text": "For our data set, we randomly divide the data into training and test in a 70:30 training-to-test ratio, preserving the class distribution of both invective and neutral classes.", "labels": [], "entities": []}, {"text": "We use 20% of the training data as a validation set to search for the best C parameters for the Linear SVM through grid search over different values.", "labels": [], "entities": [{"text": "Linear SVM", "start_pos": 96, "end_pos": 106, "type": "DATASET", "confidence": 0.6753429472446442}]}, {"text": "Since the data set is highly skewed, we perform oversampling of the invective instances during training to mitigate the imbalance data problem.", "labels": [], "entities": []}, {"text": "Note that Kaggle corpus and Wikipedia corpus contain training, evaluation, and test sets separately.", "labels": [], "entities": [{"text": "Kaggle corpus", "start_pos": 10, "end_pos": 23, "type": "DATASET", "confidence": 0.9562390148639679}, {"text": "Wikipedia corpus", "start_pos": 28, "end_pos": 44, "type": "DATASET", "confidence": 0.950747162103653}]}, {"text": "Moreover, for the embedding features, we build the vector space by training 290,634 unique words coming from all 586K question-answer pairs we crawled from ask.fm.", "labels": [], "entities": []}, {"text": "Also for the LDA feature, using all crawled data from ask.fm, we consider all pairs related to each user as a single document, and ignore the users with less than 10 pairs.", "labels": [], "entities": []}, {"text": "For the other two data sets, we look at each comment as a single document.", "labels": [], "entities": []}, {"text": "In the pre-processing step, we remove stopwords and words that occur less than 7 times, and set the number of topics to 20.", "labels": [], "entities": []}, {"text": "People use emoticons to help convey their emotions when they are posting online.", "labels": [], "entities": []}, {"text": "In our baseline experiment, at first we simply check whether a post contains any emoticons in the list {<3, :-), :), (-:, (:, :o), :c)} since by looking at the training data we found that these emoticons were used to show positive feelings.", "labels": [], "entities": []}, {"text": "If the post contains at least one of these emoticons, we label it \"neutral\".", "labels": [], "entities": []}, {"text": "Otherwise, we calculate the ratio of bad words to total words.", "labels": [], "entities": []}, {"text": "If it is greater than a given threshold, our baseline system predicts the post as \"invective\".", "labels": [], "entities": []}, {"text": "invective(x) = 0, if badW ordRatio(x) < T 1, if badW ordRatio(x) \u2265 T (2) In this research, since we work with highly imbalanced data sets, we used \"f1-score\" and \"area under the receiver operating characteristic curve (AUC)\" as the evaluation metrics as they are less sensitive to imbalanced classes.", "labels": [], "entities": [{"text": "receiver operating characteristic curve (AUC)\"", "start_pos": 178, "end_pos": 224, "type": "METRIC", "confidence": 0.6927040304456439}]}, {"text": "shows the results for our baseline experiment.", "labels": [], "entities": []}, {"text": "We find the best threshold value among all threshold values {0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8} by performing grid search using the training set for training, and the validation set for testing.", "labels": [], "entities": []}, {"text": "With the feature collections we discussed in section 4, we train a Linear SVM classifier.", "labels": [], "entities": []}, {"text": "Similar to the baseline experiment, for each set of features, we tuned SVM C parameter (inverse of regularization strength) with a grid search over values {0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0, 10, 100, 1000, 10000}.", "labels": [], "entities": []}, {"text": "shows the classification results of invective class for all the features and some of their combinations for all three different data sets.", "labels": [], "entities": []}, {"text": "Please note that Question-Answer feature cannot be applied on Kaggle and Wikipedia data, because the comments format in these data sets are not of question-answer type.", "labels": [], "entities": [{"text": "Kaggle and Wikipedia data", "start_pos": 62, "end_pos": 87, "type": "DATASET", "confidence": 0.7841192930936813}]}], "tableCaptions": [{"text": " Table 1: Statistics for our ask.fm data", "labels": [], "entities": [{"text": "ask.fm data", "start_pos": 29, "end_pos": 40, "type": "DATASET", "confidence": 0.9492720067501068}]}, {"text": " Table 3: Average length of the posts, and words in  ask.fm, Kaggle, and Wikipedia data sets in terms  of the average number of words and the average  number of characters", "labels": [], "entities": [{"text": "Average length", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.9376762211322784}, {"text": "Kaggle", "start_pos": 61, "end_pos": 67, "type": "DATASET", "confidence": 0.8604103922843933}, {"text": "Wikipedia data sets", "start_pos": 73, "end_pos": 92, "type": "DATASET", "confidence": 0.9707460403442383}]}, {"text": " Table 5: Baseline experiment results for invective class", "labels": [], "entities": []}, {"text": " Table 6: Classification results for invective class. N/A stands for the features that are not applicable to  Kaggle and Wikipedia data sets", "labels": [], "entities": [{"text": "Kaggle and Wikipedia data sets", "start_pos": 110, "end_pos": 140, "type": "DATASET", "confidence": 0.825397539138794}]}, {"text": " Table 9: Degree of negativity for bad words", "labels": [], "entities": [{"text": "Degree", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9806668758392334}]}]}