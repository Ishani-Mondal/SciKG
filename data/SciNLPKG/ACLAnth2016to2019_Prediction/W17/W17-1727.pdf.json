{"title": [{"text": "Combining Linguistic Features for the Detection of Croatian Multiword Expressions", "labels": [], "entities": [{"text": "Detection of Croatian Multiword Expressions", "start_pos": 38, "end_pos": 81, "type": "TASK", "confidence": 0.8922917127609253}]}], "abstractContent": [{"text": "As multiword expressions (MWEs) exhibit a range of idiosyncrasies, their automatic detection warrants the use of many different features.", "labels": [], "entities": []}, {"text": "Tsvetkov and Wintner (2014) proposed a Bayesian network model that combines linguistically motivated features and also models their interactions.", "labels": [], "entities": []}, {"text": "In this paper, we extend their model with new features and apply it to Croatian, a morphologically complex and a relatively free word order language, achieving a satisfactory performance of 0.823 F1-score.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 196, "end_pos": 204, "type": "METRIC", "confidence": 0.9969937801361084}]}, {"text": "Furthermore , by comparing against (semi)na\u00efve Bayes models, we demonstrate that manually modeling feature interactions is indeed important.", "labels": [], "entities": []}, {"text": "We make our annotated dataset of Croatian MWEs freely available.", "labels": [], "entities": [{"text": "annotated dataset of Croatian MWEs", "start_pos": 12, "end_pos": 46, "type": "DATASET", "confidence": 0.6263276934623718}]}], "introductionContent": [{"text": "Multiword expressions (MWEs) have attracted a great deal of attention in the natural language processing community.", "labels": [], "entities": [{"text": "Multiword expressions (MWEs)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8077885985374451}]}, {"text": "While MWEs span a wide range of types, common to all is the idiosyncrasy at the lexical, syntactic, semantic, pragmatic, or statistical level (.", "labels": [], "entities": []}, {"text": "A variety of models has been proposed for the automatic identification of MWE in corpora, including statistical and linguistic-based approaches; see) fora recent overview.", "labels": [], "entities": [{"text": "automatic identification of MWE", "start_pos": 46, "end_pos": 77, "type": "TASK", "confidence": 0.7017754837870598}]}, {"text": "argued fora combination of the two approaches.", "labels": [], "entities": []}, {"text": "Recently, proposed an approach for the detection of MWE candidates that combines a number of statistical and linguistic features.", "labels": [], "entities": [{"text": "detection of MWE", "start_pos": 39, "end_pos": 55, "type": "TASK", "confidence": 0.7346439957618713}]}, {"text": "The most interesting aspect of their work is that they explicitly model the linguistically motivated interactions between the features using a Bayesian network (BN).", "labels": [], "entities": []}, {"text": "The advantages of BNs lie in their interpretability and the possibility to encode linguistic knowledge in the form of the network structure.", "labels": [], "entities": []}, {"text": "Furthermore, unlike most previous work, Tsvetkov and Wintner address MWE of various types and flexible syntactic constructions.", "labels": [], "entities": []}, {"text": "They show that the manually-designed BN outperforms a number of strong baselines, including an SVM model, on English, French, and Hebrew datasets.", "labels": [], "entities": []}, {"text": "Another advantage of their model is that it is in principle language-independent, aside from a few language-specific features.", "labels": [], "entities": []}, {"text": "In this paper, we address the task of MWE detection (type-level MWE classification) for Croatian, a South Slavic language with a rich morphology and a relatively free word order.", "labels": [], "entities": [{"text": "MWE detection", "start_pos": 38, "end_pos": 51, "type": "TASK", "confidence": 0.9900226891040802}, {"text": "type-level MWE classification", "start_pos": 53, "end_pos": 82, "type": "TASK", "confidence": 0.6150979399681091}]}, {"text": "The starting point of our work is the model of, which we extend with a number of features, including language-specific ones that account for the relatively free word order.", "labels": [], "entities": []}, {"text": "Our main research question is whether modeling the interactions between features is important, and whether these can be learned automatically.", "labels": [], "entities": []}, {"text": "showed that a manually-designed BN substantially outperforms the one whose structure is learned automatically, hypothesizing that the cause for this might be the increased model complexity.", "labels": [], "entities": []}, {"text": "We conduct a similar experiment using a structurelearning algorithm, but also model the interactions using a simpler, semi-naive Bayes classifier, for which the number of parameters is restricted.", "labels": [], "entities": []}, {"text": "Finally, we compare these models against a structurefree counterpart, a na\u00efve Bayes classifier.", "labels": [], "entities": []}, {"text": "For the experiments, we compile anew manually annotated dataset of Croatian MWEs.", "labels": [], "entities": [{"text": "Croatian MWEs", "start_pos": 67, "end_pos": 80, "type": "DATASET", "confidence": 0.9149411618709564}]}, {"text": "Unlike, who only consider bigrams, we consider MWEs of up to five words in length.", "labels": [], "entities": []}, {"text": "We make the dataset freely available, along with all feature sets needed to replicate the experiments.", "labels": [], "entities": []}], "datasetContent": [{"text": "As there is no publicly available annotated datasets of Croatian MWEs, we decided to create one.", "labels": [], "entities": [{"text": "Croatian MWEs", "start_pos": 56, "end_pos": 69, "type": "DATASET", "confidence": 0.7950985133647919}]}, {"text": "We first established a working definition of Croatian MWEs, starting out from the taxonomy proposed by Blagus, and adopted it to the universal classification of.", "labels": [], "entities": [{"text": "Croatian MWEs", "start_pos": 45, "end_pos": 58, "type": "DATASET", "confidence": 0.7516361176967621}]}, {"text": "As a source of data for our dataset, we use hrMWELex, a lexicon of Croatian MWEs candidate n-grams compiled by Ljube\u0161i\u00b4c.", "labels": [], "entities": []}, {"text": "The lexicon was obtained by matching parse trees from hrWaC against a set of predefined syntactic patterns (POS patterns) for Croatian, yielding a high-recall, low-precision MWE lexicon.", "labels": [], "entities": []}, {"text": "The resulting lexicon contains 12M n-grams with matching POS patterns.", "labels": [], "entities": []}, {"text": "We next sorted the n-grams by corpus frequency, and made a balanced 2-, 3-, and 4-gram selection from the most frequent candidates, selecting 4000 MWE candidates.", "labels": [], "entities": []}, {"text": "We then asked four native speakers of Croatian to label the dataset.", "labels": [], "entities": []}, {"text": "Each annotated all 4000 instances, presented in random order to minimize the effect of a context bias.", "labels": [], "entities": []}, {"text": "We also included 124 gold positive MWEs, extracted from, to serve as a control set.", "labels": [], "entities": []}, {"text": "To measure the inter-annotator agreement, we calculated the Cohen's coefficient between all pairs of annotations (.", "labels": [], "entities": []}, {"text": "The agreement ranges between 0.413 and 0.578, which, according to, is considered a moderate agreement.", "labels": [], "entities": [{"text": "agreement", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9714425802230835}]}, {"text": "For the final dataset, we adjudicated the annotations by considering a MWE can-, yielding a total of 461 positive MWEs.", "labels": [], "entities": []}, {"text": "3 Finally, we add an equal number of n-grams annotated as negative MWE instances by at least three annotators, yielding a perfectly-balanced dataset of 922 n-grams.", "labels": [], "entities": []}, {"text": "shows a breakdown of positive and negative examples by n-gram length.", "labels": [], "entities": []}, {"text": "For each n-gram from this dataset, we computed the feature values on a random sample of the hrWaC corpus comprising 200K sentences (\u223c5M tokens).", "labels": [], "entities": [{"text": "hrWaC corpus", "start_pos": 92, "end_pos": 104, "type": "DATASET", "confidence": 0.9049838781356812}]}, {"text": "We make the dataset and the precomputed features publicly available.", "labels": [], "entities": []}, {"text": "We compare the BN model from Section 2 against two commonly used statistical baselines:  such as those among the syntax, frozen, and partial features in.", "labels": [], "entities": []}, {"text": "The NB is even simpler, as it does not model any feature interactions at all, i.e., it assumes all feature pairs are conditionally independent within the MWE and non-MWE classes.", "labels": [], "entities": []}, {"text": "In contrast, the BN and BN-K2 models can model (undirected) circular dependencies.", "labels": [], "entities": [{"text": "BN", "start_pos": 17, "end_pos": 19, "type": "DATASET", "confidence": 0.8583450317382812}]}, {"text": "The difference between them is that for the BN model the feature interactions were designed manually, based on linguistic insights, whereas in case of BN-K2 the interactions are learned from the train set.", "labels": [], "entities": [{"text": "BN", "start_pos": 44, "end_pos": 46, "type": "DATASET", "confidence": 0.8191089630126953}]}, {"text": "shows the MWE classification accuracy, precision, recall, and F1-scores of the two baselines and the four Bayes classifiers.", "labels": [], "entities": [{"text": "MWE classification", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.5226729065179825}, {"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9638422131538391}, {"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9996819496154785}, {"text": "recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9996036887168884}, {"text": "F1-scores", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9997720122337341}]}, {"text": "All models were trained and tested using 10-fold cross-validation on the gold dataset.", "labels": [], "entities": [{"text": "gold dataset", "start_pos": 73, "end_pos": 85, "type": "DATASET", "confidence": 0.8035447895526886}]}, {"text": "The threshold of the two baseline models was optimized on the train sets.", "labels": [], "entities": []}, {"text": "We observe that all four Bayes classifiers outperform the baselines in terms of accuracy and F1-score, except for the NB model which performs worse than Dice in terms of F1-score.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.999596893787384}, {"text": "F1-score", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.9993311166763306}, {"text": "F1-score", "start_pos": 170, "end_pos": 178, "type": "METRIC", "confidence": 0.9850142598152161}]}, {"text": "On the other hand, the BN model outperforms all considered models in terms of both accuracy and F1-score by a considerable margin.", "labels": [], "entities": [{"text": "BN model", "start_pos": 23, "end_pos": 31, "type": "DATASET", "confidence": 0.7137520909309387}, {"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9997996687889099}, {"text": "F1-score", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.9996232986450195}]}, {"text": "This demonstrates that manual modeling of feature interactions is indeed important for MWE detection, and that BN does a reasonably good job in modeling these interactions.", "labels": [], "entities": [{"text": "MWE detection", "start_pos": 87, "end_pos": 100, "type": "TASK", "confidence": 0.9961500763893127}, {"text": "BN", "start_pos": 111, "end_pos": 113, "type": "METRIC", "confidence": 0.842822253704071}]}, {"text": "The more simple NB and TAN models even out in terms of F1-score, but differ in precision and recall scores, while the BN-K2 model performs comparably to TAN.", "labels": [], "entities": [{"text": "TAN", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.8851833939552307}, {"text": "F1-score", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9990228414535522}, {"text": "precision", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.9995012283325195}, {"text": "recall scores", "start_pos": 93, "end_pos": 106, "type": "METRIC", "confidence": 0.9838104248046875}, {"text": "TAN", "start_pos": 153, "end_pos": 156, "type": "METRIC", "confidence": 0.7889233827590942}]}], "tableCaptions": [{"text": " Table 1: Inter-annotator agreement on the MWE  classification", "labels": [], "entities": [{"text": "MWE  classification", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.6321328580379486}]}, {"text": " Table 2: Dataset breakdown by n-gram length", "labels": [], "entities": []}]}