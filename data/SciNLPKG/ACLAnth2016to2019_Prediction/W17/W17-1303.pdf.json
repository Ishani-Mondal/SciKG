{"title": [{"text": "Semantic Similarity of Arabic Sentences with Word Embeddings", "labels": [], "entities": [{"text": "Semantic Similarity of Arabic Sentences", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.7546103119850158}]}], "abstractContent": [{"text": "Semantic textual similarity is the basis of countless applications and plays an important role in diverse areas, such as information retrieval, plagiarism detection, information extraction and machine translation.", "labels": [], "entities": [{"text": "Semantic textual similarity", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7711856365203857}, {"text": "information retrieval", "start_pos": 121, "end_pos": 142, "type": "TASK", "confidence": 0.8036689758300781}, {"text": "plagiarism detection", "start_pos": 144, "end_pos": 164, "type": "TASK", "confidence": 0.7672218084335327}, {"text": "information extraction", "start_pos": 166, "end_pos": 188, "type": "TASK", "confidence": 0.8392123878002167}, {"text": "machine translation", "start_pos": 193, "end_pos": 212, "type": "TASK", "confidence": 0.8141279518604279}]}, {"text": "This article proposes an innovative word embedding-based system devoted to calculate the semantic similarity in Arabic sentences.", "labels": [], "entities": []}, {"text": "The main idea is to exploit vectors as word representations in a multidi-mensional space in order to capture the semantic and syntactic properties of words.", "labels": [], "entities": []}, {"text": "IDF weighting and Part-of-Speech tagging are applied on the examined sentences to support the identification of words that are highly descriptive in each sentence.", "labels": [], "entities": [{"text": "IDF weighting", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.5469793379306793}, {"text": "Part-of-Speech tagging", "start_pos": 18, "end_pos": 40, "type": "TASK", "confidence": 0.7353319078683853}]}, {"text": "The performance of our proposed system is confirmed through the Pearson correlation between our assigned semantic similarity scores and human judgments.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 64, "end_pos": 83, "type": "METRIC", "confidence": 0.972451388835907}]}], "introductionContent": [{"text": "Text Similarity is an important task in several application fields, such as information retrieval, plagiarism detection, machine translation, topic detection, text classification, text summarization and others.", "labels": [], "entities": [{"text": "Text Similarity", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7094272673130035}, {"text": "information retrieval", "start_pos": 76, "end_pos": 97, "type": "TASK", "confidence": 0.7759816646575928}, {"text": "plagiarism detection", "start_pos": 99, "end_pos": 119, "type": "TASK", "confidence": 0.7995117902755737}, {"text": "machine translation", "start_pos": 121, "end_pos": 140, "type": "TASK", "confidence": 0.7888536751270294}, {"text": "topic detection", "start_pos": 142, "end_pos": 157, "type": "TASK", "confidence": 0.9090943932533264}, {"text": "text classification", "start_pos": 159, "end_pos": 178, "type": "TASK", "confidence": 0.8036457300186157}, {"text": "text summarization", "start_pos": 180, "end_pos": 198, "type": "TASK", "confidence": 0.7358496487140656}]}, {"text": "Finding similarity between two texts, paragraphs or sentences, is based on measuring, directly or indirectly, the similarity between words.", "labels": [], "entities": []}, {"text": "There are two known types of words similarity: lexical and semantic.", "labels": [], "entities": []}, {"text": "The first one handles the words as a stream of characters: words are similar lexically if they share the same characters in the same order.", "labels": [], "entities": []}, {"text": "There are many techniques of lexical similarity measures, the most known are :), Needleman Wunsch (, LCS (,, etc.", "labels": [], "entities": [{"text": "LCS", "start_pos": 101, "end_pos": 104, "type": "METRIC", "confidence": 0.80222487449646}]}, {"text": "The second type aims to quantify the degree to which two words are semantically related.", "labels": [], "entities": []}, {"text": "As an example they can be, synonyms, represent the same thing or they are used in the same context.", "labels": [], "entities": []}, {"text": "The classical way to measure this semantic similarity is by using linguistic resources, like WordNet, HowNet (, or Dbnary.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 93, "end_pos": 100, "type": "DATASET", "confidence": 0.9695641398429871}, {"text": "HowNet", "start_pos": 102, "end_pos": 108, "type": "DATASET", "confidence": 0.8958667516708374}]}, {"text": "However, the word embedding techniques can be a more effective alternative to these linguistic databases (.", "labels": [], "entities": []}, {"text": "In this article we focus our investigation on measuring the semantic similarity between short Arabic sentences using word embedding representations.", "labels": [], "entities": []}, {"text": "We also consider the IDF weighting and Part-of-Speech tagging techniques in order to improve the identification of words that are highly descriptive in each sentence.", "labels": [], "entities": [{"text": "IDF weighting", "start_pos": 21, "end_pos": 34, "type": "TASK", "confidence": 0.627521812915802}, {"text": "Part-of-Speech tagging", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.7467604577541351}]}, {"text": "The rest of this article is organized as follows, the next section describes work related to word representations in vector space.", "labels": [], "entities": [{"text": "word representations", "start_pos": 93, "end_pos": 113, "type": "TASK", "confidence": 0.721910148859024}]}, {"text": "In Section 3, we present three variants of our proposed word embedding-based system.", "labels": [], "entities": []}, {"text": "Section 4 describes the experimental results of this study.", "labels": [], "entities": []}, {"text": "Finally, our conclusion and some future research directions are drawn in Section 5.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Training configuration parameters", "labels": [], "entities": []}, {"text": " Table 2: Example of sentence similarity results", "labels": [], "entities": [{"text": "sentence similarity", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.6950846016407013}]}]}