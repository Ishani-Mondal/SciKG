{"title": [{"text": "Generating and Evaluating Summaries for Partial Email Threads: Conversational Bayesian Surprise and Silver Standards", "labels": [], "entities": [{"text": "Generating and Evaluating Summaries", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.6652167215943336}]}], "abstractContent": [{"text": "We define and motivate the problem of summarizing partial email threads.", "labels": [], "entities": [{"text": "summarizing partial email threads", "start_pos": 38, "end_pos": 71, "type": "TASK", "confidence": 0.9075615555047989}]}, {"text": "This problem introduces the challenge of generating reference summaries for partial threads when human annotation is only available for the threads as a whole, particularly when the human-selected sentences are not uniformly distributed within the threads.", "labels": [], "entities": []}, {"text": "We propose an oracular algorithm for generating these reference summaries with arbitrary length, and we are making the resulting dataset publicly available 1.", "labels": [], "entities": []}, {"text": "In addition, we apply a recent unsuper-vised method based on Bayesian Surprise that incorporates background knowledge into partial thread summarization, extend it with conversational features, and modify the mechanism by which it handles redundancy.", "labels": [], "entities": []}, {"text": "Experiments with our method indicate improved performance over the base-line for shorter partial threads; and our results suggest that the potential benefits of background knowledge to partial thread summarization should be further investigated with larger datasets.", "labels": [], "entities": [{"text": "partial thread summarization", "start_pos": 185, "end_pos": 213, "type": "TASK", "confidence": 0.5669860939184824}]}], "introductionContent": [{"text": "Despite the relatively early advent of emails compared to other forms of electronic communication, the continued proliferation of emails make them an ongoing focus of NLP research.", "labels": [], "entities": []}, {"text": "With users experiencing an increasing flow of emails and decreasing screen sizes, there has been a growing interest in the email summarization task: given an email thread with multiple participants, provide a summary of the contents of the thread.", "labels": [], "entities": [{"text": "email summarization task", "start_pos": 123, "end_pos": 147, "type": "TASK", "confidence": 0.7104860742886862}]}, {"text": "Such summaries should contain the key information in a thread and free a user from having to comb through its entire contents.", "labels": [], "entities": []}, {"text": "Also, given that email threads can span days, weeks, or months, and users often participate in multiple threads at once, such summaries can serve as memory aids to users returning to or joining a thread in progress (.", "labels": [], "entities": []}, {"text": "Email threads are dynamic document collections, however, and the content of a summary may need to changeover time as emails come in.", "labels": [], "entities": []}, {"text": "Therefore, while the full thread summarization problem (extensively studied in the past as discussed in section 2) provides a single summary of a complete, archived email thread, we are interested in the partial thread summarization problem where we generate a succession of summaries, each summarizing the thread at different moments in time.", "labels": [], "entities": [{"text": "full thread summarization", "start_pos": 21, "end_pos": 46, "type": "TASK", "confidence": 0.592295785744985}, {"text": "partial thread summarization", "start_pos": 204, "end_pos": 232, "type": "TASK", "confidence": 0.6533967852592468}]}, {"text": "More formally, for each email E i in a given email thread {E 1 ...E i ...E n } we wish to generate a summary for the corresponding partial thread (PT) {E 1 ...E i }.", "labels": [], "entities": []}, {"text": "Given the novelty of the summarization task, in this paper we focus on investigating simple unsupervised extractive approaches, where the summary is a subset of the sentences in the source partial thread, and leave supervised and abstractive approaches for future work.", "labels": [], "entities": [{"text": "summarization task", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.9193548560142517}]}, {"text": "A partial thread summary will provide a summary of the thread so far, including the new email; it is intended to benefit users that may have forgotten the content of the preceding emails in the thread (or maybe new to the thread) and need a quick refresh, possibly on the relatively small screen of a mobile device.", "labels": [], "entities": []}, {"text": "Additionally, a user may want to \"extend\" a partial thread summary in order to get more information; and so we also investigate the ability to generate summaries of arbitrary length.", "labels": [], "entities": []}, {"text": "The PT summarization problem is thus different from the update summariza-tion problem previously studied for news in the Text Analysis Conferences (.", "labels": [], "entities": [{"text": "PT summarization", "start_pos": 4, "end_pos": 20, "type": "TASK", "confidence": 0.5042152851819992}, {"text": "Text Analysis Conferences", "start_pos": 121, "end_pos": 146, "type": "TASK", "confidence": 0.7642518281936646}]}, {"text": "The update summarization problem, applied to email threads, would provide a summary of only the incoming email with the assumption that the user knows and remembers the content of the preceding emails.", "labels": [], "entities": []}, {"text": "The new NLP task of summarizing email PT is challenging, not only because new algorithms may need to be developed, but also with respect to evaluating the generated summaries.", "labels": [], "entities": [{"text": "summarizing email PT", "start_pos": 20, "end_pos": 40, "type": "TASK", "confidence": 0.9168484012285868}]}, {"text": "While there are publicly available datasets -including BC3 ( and an Enron-derived dataset () -that provide gold standard summaries for completed email threads, none to our knowledge provides such summaries for PTs; such annotation by humans would be prohibitive, as it would require a summary for each partial thread (i.e., each email) in the corpus.", "labels": [], "entities": [{"text": "BC3", "start_pos": 55, "end_pos": 58, "type": "DATASET", "confidence": 0.8701623678207397}]}, {"text": "So, a challenge we face in the evaluation of PT summaries is due to the dearth of human annotations.", "labels": [], "entities": [{"text": "evaluation of PT summaries", "start_pos": 31, "end_pos": 57, "type": "TASK", "confidence": 0.6855898201465607}]}, {"text": "More specifically, given gold standard human annotations of a thread as a whole, how do we generate reference summaries of each PT against which to compare automatically generated extractive summaries?", "labels": [], "entities": []}, {"text": "Most current summarization techniques for full thread summarization rely on the analysis of only the content of the input thread to decide what sentences should be included in the summary.", "labels": [], "entities": [{"text": "summarization", "start_pos": 13, "end_pos": 26, "type": "TASK", "confidence": 0.9695658087730408}, {"text": "full thread summarization", "start_pos": 42, "end_pos": 67, "type": "TASK", "confidence": 0.6216545701026917}]}, {"text": "However, since PT can be rather short we hypothesize that the identification of the most informative sentences would benefit from examining the larger informational context in which the PT was generated (eg. all the email generated in an organization).", "labels": [], "entities": []}, {"text": "We test this hypothesis by applying and extending a recent summarization method based on Bayesian Surprise that leverages such background information for PT summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 59, "end_pos": 72, "type": "TASK", "confidence": 0.984815239906311}, {"text": "PT summarization", "start_pos": 154, "end_pos": 170, "type": "TASK", "confidence": 0.7455775737762451}]}, {"text": "The main contributions of this paper are as follows: \u2022 We propose an algorithm for exploiting existing extractive gold standard (EGS) summaries of full threads to automatically generate oracular \"silver standard\" PT summaries of arbitrary length, as discussed in section 3.", "labels": [], "entities": []}, {"text": "Further, we are releasing these silver standard summaries for the dataset used in this work.", "labels": [], "entities": []}, {"text": "\u2022 For PT summary generation, we propose an unsupervised method extending previous work on full-thread summarization that considers not only the input thread, but also background knowledge synthesized from a large number of other email threads.", "labels": [], "entities": [{"text": "PT summary generation", "start_pos": 6, "end_pos": 27, "type": "TASK", "confidence": 0.7805162072181702}, {"text": "full-thread summarization", "start_pos": 90, "end_pos": 115, "type": "TASK", "confidence": 0.6277141273021698}]}, {"text": "In particular, we developed a summarization method based on Bayesian Surprise) which takes into account conversational features of the partial thread, as discussed in section 4.", "labels": [], "entities": [{"text": "summarization", "start_pos": 30, "end_pos": 43, "type": "TASK", "confidence": 0.9559112787246704}]}, {"text": "We then evaluate the system-generated summaries using our silver standards with ROUGE.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 80, "end_pos": 85, "type": "METRIC", "confidence": 0.9964231848716736}]}, {"text": "\u2022 Using our silver standard with ROUGE, we carryout experiments to compare the summaries generated by Bayesian-based methods with summarization techniques that do not take into account background information.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 33, "end_pos": 38, "type": "METRIC", "confidence": 0.9938619136810303}, {"text": "summaries generated", "start_pos": 79, "end_pos": 98, "type": "TASK", "confidence": 0.8972699046134949}, {"text": "summarization", "start_pos": 130, "end_pos": 143, "type": "TASK", "confidence": 0.9733578562736511}]}], "datasetContent": [{"text": "We used the \"corporate thread\" subset of the publicly available annotated email dataset produced by Loza et. al., which was derived from the Enron email dataset ().", "labels": [], "entities": [{"text": "Enron email dataset", "start_pos": 141, "end_pos": 160, "type": "DATASET", "confidence": 0.8488855361938477}]}, {"text": "The data consists of 62 email threads (from which 282 PTs can be extracted) containing a total of 354 emails and 1654 sentences.", "labels": [], "entities": []}, {"text": "Each thread is manually annotated with abstractive and extractive summaries, as well as five ranked keyphrases.", "labels": [], "entities": []}, {"text": "This work focuses on extractive summarization, so only those annotations were used.", "labels": [], "entities": [{"text": "extractive summarization", "start_pos": 21, "end_pos": 45, "type": "TASK", "confidence": 0.716064453125}]}, {"text": "The keyphrases were not used here, because it is not expected that most gold standard annotations will include keyphrases.", "labels": [], "entities": []}, {"text": "Each thread was annotated by two annotators, so for each thread we have two sets of extractive sentences.", "labels": [], "entities": []}, {"text": "The annotators were asked to select up to five sentences \"that contained the most important information in the email, and also rank the sentences in reverse order of their importance\".", "labels": [], "entities": []}, {"text": "To serve as a background corpus that could be used for both Bayesian Surprise methods, we used a publicly available collection of threads extracted from the Enron corpus, of which threads \u223c43k had the metadata required (sender, recipient(s) and subject line in all emails) in order to extract the desired conversational features.", "labels": [], "entities": [{"text": "Enron corpus", "start_pos": 157, "end_pos": 169, "type": "DATASET", "confidence": 0.9383376836776733}]}, {"text": "We generated a number of summaries for each full thread as well as for its corresponding PTs.", "labels": [], "entities": []}, {"text": "First, we generated summaries using both the original and our extended Bayesian Surprise methods (BS and BSE) discussed in sections 4.1 and 4.2.", "labels": [], "entities": []}, {"text": "We then generated additional summaries for each method using the exponential surprise decay (-d) discussed in section 4.3 with df = 0.5.", "labels": [], "entities": [{"text": "exponential surprise decay", "start_pos": 65, "end_pos": 91, "type": "METRIC", "confidence": 0.7732452750205994}]}, {"text": "In addition, we generated summaries using a method (CWS) that scores sentences based on the number of clue words they contain . This method was shown to perform well in email summarization, and we use it here as a baseline.", "labels": [], "entities": [{"text": "email summarization", "start_pos": 169, "end_pos": 188, "type": "TASK", "confidence": 0.6925647258758545}]}, {"text": "Initially, we evaluated the system summaries over the full threads against the human-annotated EGS.", "labels": [], "entities": [{"text": "EGS", "start_pos": 95, "end_pos": 98, "type": "DATASET", "confidence": 0.9237159490585327}]}, {"text": "The evaluation was carried out using ROUGE-1 Fscores.", "labels": [], "entities": [{"text": "ROUGE-1 Fscores", "start_pos": 37, "end_pos": 52, "type": "METRIC", "confidence": 0.8545665144920349}]}, {"text": "In the ROUGE evaluation, stemming was performed, but stopwords were not removed, consistent with previous evaluations of summarization based on Bayesian Surprise (Louis, 2014).", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 7, "end_pos": 12, "type": "METRIC", "confidence": 0.8331648111343384}, {"text": "summarization", "start_pos": 121, "end_pos": 134, "type": "TASK", "confidence": 0.9686287641525269}]}, {"text": "The system summaries were truncated to the length (in words) of the corresponding EGS.", "labels": [], "entities": [{"text": "EGS", "start_pos": 82, "end_pos": 85, "type": "DATASET", "confidence": 0.9379684329032898}]}, {"text": "As a baseline we used a PageRank-based summarizer (PR-MMR) that scores sentences using the same sentence graphs as the silver standard algorithm and employs MMR to minimize redundancy.", "labels": [], "entities": []}, {"text": "The results for this evaluation overfull threads are given in The results of this experiment overfull threads suggest that the Bayesian Surprise-based methods perform comparably to the clue words-based summarizer, and that they all significantly outperform the PR-MMR baseline (p<0.005) 2 . In addition, there appears to be some benefit to the more gradual redundancy handling provided by surprise decay, though the differences in these cases do not appear to be significant.", "labels": [], "entities": []}, {"text": "To evaluate the summarizers over partial threads, we generated two silver standard summaries (one for each annotator) per PT using the algorithm in section 3.", "labels": [], "entities": []}, {"text": "The silver standard and system summaries for each PT were truncated to a fraction of the PT length (in words).", "labels": [], "entities": [{"text": "PT length", "start_pos": 89, "end_pos": 98, "type": "METRIC", "confidence": 0.8990934789180756}]}, {"text": "Since the silver standard algorithm generates summaries of arbitrary length, we evaluated the summarizers at both 20% and 30% of the PT length.", "labels": [], "entities": [{"text": "PT length", "start_pos": 133, "end_pos": 142, "type": "METRIC", "confidence": 0.9724524021148682}]}, {"text": "The hypothesis behind our use of Bayesian Surprise-based methods is that they should work particularly well for PT summarization, because PTs can be rather short, and the identification of the most informative sentences would benefit from examining a larger informational context.", "labels": [], "entities": [{"text": "PT summarization", "start_pos": 112, "end_pos": 128, "type": "TASK", "confidence": 0.8692328929901123}]}, {"text": "To test this hypothesis we sorted the 282 PTs being summarized by length and binned them into quartiles (see).", "labels": [], "entities": []}, {"text": "Since BSE-d is the Bayesian Surprise-based method incorporating all of our extensions, we focus our statistical analysis on comparing it to CWS.", "labels": [], "entities": [{"text": "BSE-d", "start_pos": 6, "end_pos": 11, "type": "DATASET", "confidence": 0.6377593874931335}]}, {"text": "The results of this evaluation are given in  We observe a number of trends in from the experiments over PTs; however, only some cases exhibit at least marginal significance.", "labels": [], "entities": []}, {"text": "This maybe due in part to limited sample size; and so we argue that further work in applying background knowledge to PT summarization over larger datasets is warranted.", "labels": [], "entities": [{"text": "PT summarization", "start_pos": 117, "end_pos": 133, "type": "TASK", "confidence": 0.94312584400177}]}, {"text": "Over the shorter PTs (i.e. first and second quantiles) and at both summary lengths, we observe a trend favoring our hypothesis, namely that Bayesian Surprise-based methods seem to perform better than CWS; for example, the performance improvement of BSE-d over CWS is at least marginally significant (p<0.1) for the second quartile at both summary lengths.", "labels": [], "entities": []}, {"text": "Conversely, for the longest PTs (i.e., the fourth quantile), we see that the effectiveness of clue words is more fully realized, allowing CWS to outperform the Bayesian Surprise-based summarizers.", "labels": [], "entities": []}, {"text": "While this difference is significant (p<0.05) for summaries of 30% PT length, it is not significant at 20% PT length; this suggests that Bayesian Surprise-based summarizers maybe more robust against changes in PT summary length than CWS.", "labels": [], "entities": [{"text": "PT length", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.8280116617679596}, {"text": "PT length", "start_pos": 107, "end_pos": 116, "type": "METRIC", "confidence": 0.8688785135746002}]}, {"text": "Surprisingly, the conversational features used to extend the Bayesian Surprise method have not improved summarizer performance.", "labels": [], "entities": [{"text": "summarizer", "start_pos": 104, "end_pos": 114, "type": "TASK", "confidence": 0.9686262011528015}]}, {"text": "It maybe that treating these features as equivalent to word counts is inappropriate for this task, in which case some other means of extracting these features as background knowledge should be devised.", "labels": [], "entities": []}, {"text": "Alternatively, the inclusion of additional features, such as the number of times a word is used in the first sentence of each email in the thread, may improve the performance of the extended Bayesian Surprise summarizer.", "labels": [], "entities": [{"text": "Bayesian Surprise summarizer", "start_pos": 191, "end_pos": 219, "type": "TASK", "confidence": 0.47353334228197735}]}, {"text": "As with the full threads, the inclusion of surprise decay seems to provide some benefit, though it appears to hamper the summarizers for the shortest PTs; this trend can be seen at 30% PT length, where BS-d outperforms BS in all quartiles except the first.", "labels": [], "entities": [{"text": "PT length", "start_pos": 185, "end_pos": 194, "type": "METRIC", "confidence": 0.9423370957374573}, {"text": "BS", "start_pos": 219, "end_pos": 221, "type": "METRIC", "confidence": 0.9287972450256348}]}, {"text": "This suggests that applying surprise decay factors derived from PT length and desired summary length may improve overall performance; we leave this endeavor for future work.", "labels": [], "entities": [{"text": "PT length", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.8571499586105347}]}], "tableCaptions": [{"text": " Table 1: ROUGE-1 mean F-scores for full threads  as compared to gold standard summaries.", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9957717061042786}, {"text": "F-scores", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9608205556869507}]}, {"text": " Table 2: Length (in words) of the partial threads in  the dataset used to define the quartile bins.", "labels": [], "entities": [{"text": "Length", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9977249503135681}]}, {"text": " Table 3: ROUGE-1 mean F-scores over partial threads (binned into quartiles by length in words) as  compared to silver standard summaries. Values are given for both summary lengths (20% and 30% of PT  length). Bolded ROUGE scores are the highest for their quartile and summary length category. P-values  are given for the comparisons between BSE-d and CWS; underlined p-values indicate at least marginal  significance (p<0.1).", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9095956683158875}, {"text": "F-scores", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9810066819190979}, {"text": "PT  length", "start_pos": 197, "end_pos": 207, "type": "METRIC", "confidence": 0.9122065305709839}, {"text": "BSE-d", "start_pos": 342, "end_pos": 347, "type": "DATASET", "confidence": 0.8747188448905945}]}]}