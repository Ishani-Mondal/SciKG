{"title": [{"text": "Group Linguistic Bias Aware Neural Response Generation", "labels": [], "entities": [{"text": "Linguistic Bias Aware Neural Response Generation", "start_pos": 6, "end_pos": 54, "type": "TASK", "confidence": 0.8317581564188004}]}], "abstractContent": [{"text": "For practical chatbots, one of the essential factor for improving user experience is the capability of customizing the talking style of the agents, that is, to make chatbots provide responses meeting users' preference on language styles, topics, etc.", "labels": [], "entities": []}, {"text": "To address this issue, this paper proposes to incorporate linguistic biases, which implicitly involved in the conversation corpora generated by human groups in the Social Network Services (SNS), into the encoder-decoder based response generator.", "labels": [], "entities": []}, {"text": "By attaching a specially designed neural component to dynamically control the impact of linguistic biases in response generation, a Group Linguistic Bias Aware Neural Response Generation (GLBA-NRG) model is eventually presented.", "labels": [], "entities": [{"text": "response generation", "start_pos": 109, "end_pos": 128, "type": "TASK", "confidence": 0.7879920303821564}, {"text": "Group Linguistic Bias Aware Neural Response Generation (GLBA-NRG)", "start_pos": 132, "end_pos": 197, "type": "TASK", "confidence": 0.6760757952928543}]}, {"text": "The experimental results on the dataset from the Chinese SNS show that the proposed architecture outperforms the current response generating models by producing both meaningful and vivid responses with customized styles.", "labels": [], "entities": [{"text": "Chinese SNS", "start_pos": 49, "end_pos": 60, "type": "DATASET", "confidence": 0.7146474421024323}]}], "introductionContent": [{"text": "Automated Chat Agents (a.k.a chatbots) have drawn great attention in Natural Language Processing research in recent years (, and the springing up of the practical chatbots (e.g., Duer 1 , XiaoIce 2 , etc.) indicates the great potential of such systems for naturally connecting human beings with various online services.", "labels": [], "entities": []}, {"text": "The core functionality of chatbots is to interact with users for the purpose of general conversation.", "labels": [], "entities": []}, {"text": "This requires chatbots to generate responses not only relevant to users' queries but also in accordance with users' preferred talking styles.", "labels": [], "entities": []}, {"text": "State-of-art practical chatbots are capable of providing basic chatting functionality with necessary task-oriented abilities.", "labels": [], "entities": []}, {"text": "However, they all lack the capability of adapting the generated responses to meet users' preferences.", "labels": [], "entities": []}, {"text": "To improve the user experience, it is necessary to add such talking style customization function in these chat agents.", "labels": [], "entities": []}, {"text": "In previous studies, inter-group linguistic biases are observed and found in daily conversations among people from different communities (.", "labels": [], "entities": []}, {"text": "In this paper we generalize such biases into those among groups of people based on their profiles or social attributes.", "labels": [], "entities": []}, {"text": "People from different groups may have different talking styles, including syntactic (sentence structure), semantic (choice of words) or even attitudinal differences.", "labels": [], "entities": []}, {"text": "Then such challenge of chatbots could be defined as: how to express such differences in the generated responses for different user preferences.", "labels": [], "entities": []}, {"text": "Benefiting from the nature of the Deep Neural Networks (DNN) based encoder-decoder framework (), previous studies tried to jointly learn the representation of each individual's talking habits in the training procedure of word embedding, and take such habits as apart of the input to generate personalized responses (.", "labels": [], "entities": []}, {"text": "It is found that, given a large amount of high-quality utterance data of each user, this methodology can obtain promising results of personalized response generation.", "labels": [], "entities": [{"text": "personalized response generation", "start_pos": 133, "end_pos": 165, "type": "TASK", "confidence": 0.6906569202740988}]}, {"text": "For practical chat agents, however, it is not trivial to collect such high-quality utterance from users.", "labels": [], "entities": []}, {"text": "As a consequence, it is observed that the expected responses to similar queries tend to be uncharacteristic, that is, the effect of individuallevel personalized response generator is not significant.", "labels": [], "entities": []}, {"text": "Therefore, it is more reasonable to generate personalized responses by modeling the feature of a group of users, rather than an individual ().", "labels": [], "entities": []}], "datasetContent": [{"text": "According to ( , the perplexity and BLEU metrics are not suitable for evaluating the response generators, although they are widely used in translation evaluation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 36, "end_pos": 40, "type": "METRIC", "confidence": 0.9992064833641052}, {"text": "translation evaluation", "start_pos": 139, "end_pos": 161, "type": "TASK", "confidence": 0.9591461718082428}]}, {"text": "Hence, we only use the human judgement in our experiment.", "labels": [], "entities": []}, {"text": "We recruit 3 annotators for human evaluation.", "labels": [], "entities": []}, {"text": "The annotators are instructed to judge responses from 2 aspects, response quality and accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9985007047653198}]}, {"text": "Response Quality: The response quality refers to whether a response is appropriate and attractive to the input query.", "labels": [], "entities": []}, {"text": "Three levels are assigned to a response with scores of 0, +1, +2: \u2022 Attractive (+2): the response is evidently a vivid and informative response to the query; \u2022 Neutral (+1): the response is plain and general but suitable to the query; \u2022 Unsuitable (0): it is hard or impossible to find a scenario where the response is suitable.", "labels": [], "entities": []}, {"text": "The responses that conform to the first three criteria (a), (b), and (c) but general or flat should be labeled as \"Neutral\".", "labels": [], "entities": []}, {"text": "The responses that completely satisfy the four criteria (a), (b), (c), (d) should be labeled as \"Attractive\".", "labels": [], "entities": [{"text": "Attractive", "start_pos": 97, "end_pos": 107, "type": "METRIC", "confidence": 0.9241605401039124}]}, {"text": "Accuracy: Besides the measure of response quality, we also consider whether a response corresponds to its expected group category (as input to the model).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.980422854423523}]}, {"text": "For GLBA-NRG models (GLBAStatic and GLBA-Dyna), we ask the annotators to provide a rating score 0, 1 for the judgement.", "labels": [], "entities": []}, {"text": "S2S, GLBA-Static and GLBA-Dyna generate B = 30 responses separately using the beam search algorithm described in Section 3.4.", "labels": [], "entities": []}, {"text": "Responses generated by different models are pooled and randomly shuffled for each annotator.", "labels": [], "entities": []}, {"text": "shows an overall evaluation by calculating the average score of the generated responses.", "labels": [], "entities": []}, {"text": "It is clear that GLBA-Dyna outperforms the baseline models, whose average score is up to 1.404, while others' scores are both below 1.0.", "labels": [], "entities": [{"text": "GLBA-Dyna", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.591422438621521}]}, {"text": "This means that the responses generated by GLBA-Dyna are grammatical and query-relevant, and also possess vividness which is crucial for making chatbots attractive to users.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 5: Gender Consistency Results.", "labels": [], "entities": [{"text": "Gender Consistency", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.6992035210132599}]}]}