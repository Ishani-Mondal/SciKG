{"title": [{"text": "Sogou Neural Machine Translation Systems for WMT17", "labels": [], "entities": [{"text": "Neural Machine Translation", "start_pos": 6, "end_pos": 32, "type": "TASK", "confidence": 0.674126555522283}, {"text": "WMT17", "start_pos": 45, "end_pos": 50, "type": "TASK", "confidence": 0.6993212103843689}]}], "abstractContent": [{"text": "We describe the Sogou neural machine translation systems for the WMT 2017 Chinese\u2194English news translation tasks.", "labels": [], "entities": [{"text": "Sogou neural machine translation", "start_pos": 16, "end_pos": 48, "type": "TASK", "confidence": 0.7701198011636734}, {"text": "WMT 2017 Chinese\u2194English news translation tasks", "start_pos": 65, "end_pos": 112, "type": "TASK", "confidence": 0.8404424265027046}]}, {"text": "Our systems are based on a multi-layer encoder-decoder architecture with attention mechanism.", "labels": [], "entities": []}, {"text": "The best translation is obtained with ensemble and reranking techniques.", "labels": [], "entities": [{"text": "translation", "start_pos": 9, "end_pos": 20, "type": "TASK", "confidence": 0.9671410322189331}]}, {"text": "We also propose an approach to improve the named entity translation problem.", "labels": [], "entities": [{"text": "named entity translation problem", "start_pos": 43, "end_pos": 75, "type": "TASK", "confidence": 0.6977760940790176}]}, {"text": "Our Chi-nese\u2192English system achieved the highest cased BLEU among all 20 submitted systems, and our English\u2192Chi-nese system ranked the third out of 16 submitted systems.", "labels": [], "entities": [{"text": "cased", "start_pos": 49, "end_pos": 54, "type": "METRIC", "confidence": 0.9880853891372681}, {"text": "BLEU", "start_pos": 55, "end_pos": 59, "type": "METRIC", "confidence": 0.8593830466270447}]}], "introductionContent": [{"text": "End-to-end neural machine translation (NMT) has recently been introduced as a promising paradigm with the potential to address many shortcomings of traditional statistical machine translation (SMT) systems, and has obtained state-of-the-art performance for several language pairs.", "labels": [], "entities": [{"text": "End-to-end neural machine translation (NMT)", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.7343846985271999}, {"text": "statistical machine translation (SMT)", "start_pos": 160, "end_pos": 197, "type": "TASK", "confidence": 0.8020086089769999}]}, {"text": "In this paper, we describe the Sogou NMT systems submissions for the WMT 2017 Chinese\u2192English and English\u2192Chinese translation tasks.", "labels": [], "entities": [{"text": "Sogou NMT systems submissions", "start_pos": 31, "end_pos": 60, "type": "DATASET", "confidence": 0.9280940592288971}, {"text": "WMT 2017 Chinese\u2192English and English\u2192Chinese translation tasks", "start_pos": 69, "end_pos": 131, "type": "TASK", "confidence": 0.7132990197701887}]}, {"text": "Overview of the systems can be described as follows: we implement a multi-layer attention-based encoder-decoder integrated with recent promising techniques in NMT, including that we use subword units based on byte pair encoding (BPE) rather than words as modelling units and layer normalization ( to isolated layers.", "labels": [], "entities": []}, {"text": "And we improve the performance using ensemble based four systems of the same network trained with different random seeds of parameter initialization.", "labels": [], "entities": []}, {"text": "In addition, we improve the performance further by reranking the n-best translation lists with some effective features, including the target-bidirectional models, target-to-source models, and n-gram language models.", "labels": [], "entities": []}, {"text": "And we use another NMT model to translate the recognized person names for the Chinese\u2192English task, in order to improve the performance of unknown named entity translation.", "labels": [], "entities": [{"text": "unknown named entity translation", "start_pos": 139, "end_pos": 171, "type": "TASK", "confidence": 0.6973257064819336}]}, {"text": "Our Chinese\u2192English system achieved the highest cased BLEU among all 20 submitted systems, and our English\u2192Chinese system ranked the third out of 16 submitted systems.", "labels": [], "entities": [{"text": "cased", "start_pos": 48, "end_pos": 53, "type": "METRIC", "confidence": 0.9935682415962219}, {"text": "BLEU", "start_pos": 54, "end_pos": 58, "type": "METRIC", "confidence": 0.8720152378082275}]}], "datasetContent": [{"text": "This section describes several techniques integrated in our NMT system.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: English\u2192Chinese translation BLEU  results on development set. Submitted system  is the last system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.9925734996795654}]}]}