{"title": [{"text": "Character Based Pattern Mining for Neology Detection", "labels": [], "entities": [{"text": "Neology Detection", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.7677232325077057}]}], "abstractContent": [{"text": "Detecting neologisms is essential in real-time natural language processing applications.", "labels": [], "entities": [{"text": "Detecting neologisms", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9138071537017822}]}, {"text": "Not only can it enable to follow the lexical evolution of languages , but it is also essential for updating linguistic resources and parsers.", "labels": [], "entities": []}, {"text": "In this paper, neology detection is considered as a classification task where a system has to assess whether a given lexical item is an actual neologism or not.", "labels": [], "entities": [{"text": "neology detection", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.9488281011581421}]}, {"text": "We propose a combination of an unsupervised data mining technique and a supervised machine learning approach.", "labels": [], "entities": [{"text": "data mining", "start_pos": 44, "end_pos": 55, "type": "TASK", "confidence": 0.7121712863445282}]}, {"text": "It is inspired by current researches in stylometry and on token-level and character-level patterns.", "labels": [], "entities": []}, {"text": "We train and evaluate our system on a manually designed reference dataset in French and Russian.", "labels": [], "entities": []}, {"text": "We show that this approach is able to outperform state-of-the-art neology detection systems.", "labels": [], "entities": [{"text": "neology detection", "start_pos": 66, "end_pos": 83, "type": "TASK", "confidence": 0.7341918051242828}]}, {"text": "Furthermore, character-level patterns exhibit good properties for multilingual extensions of the system.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper deals with automatic detection of formal neologisms in French and Russian, with a language-agnostic objective.", "labels": [], "entities": [{"text": "automatic detection of formal neologisms", "start_pos": 22, "end_pos": 62, "type": "TASK", "confidence": 0.783437705039978}]}, {"text": "Formal neologisms are composed of anew form linked to anew meaning, in opposition to semantic neologisms, composed of anew meaning with an existing form.", "labels": [], "entities": []}, {"text": "Whereas formal neologisms represent a tiny part of lexical items in corpora, and thus are not yet attracting a lot of research, they are part of the living lexicon of a given language and notably the gate to understand the evolution of languages.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 details related works on computational approaches to neology.", "labels": [], "entities": []}, {"text": "Section 3 describes key aspects of our method and experiments for neology detection.", "labels": [], "entities": [{"text": "neology detection", "start_pos": 66, "end_pos": 83, "type": "TASK", "confidence": 0.904469221830368}]}, {"text": "Section 4 presents evaluation results for French and Russian.", "labels": [], "entities": []}, {"text": "Finally, Section 5 summarizes the experiments and evokes future developments.", "labels": [], "entities": []}], "datasetContent": [{"text": "To the best of our knowledge, there are no existing NLP techniques that take advantage of text mining techniques for detecting neologisms.", "labels": [], "entities": [{"text": "text mining", "start_pos": 90, "end_pos": 101, "type": "TASK", "confidence": 0.7200207114219666}]}, {"text": "Intuitively and practically, formal neologisms, as new form-meaning pairs, appear in specific contexts, such as quotation marks(c'est une v\u00e9ritable \"trumperie\" 2 ) or metalinguistic markers (ce que nous pouvons appeler des catholibans 3 .The word-formation rules at stake involve affixation, composition and borrowings, each implying specific character-based features.", "labels": [], "entities": []}, {"text": "From these intuition and analysis, we propose a novel method combining an unsupervised technique to retrieve the salient features of neologisms (internal structure and context), and a supervised machine learning approach to de-  tect formal neologisms in on-going texts.", "labels": [], "entities": []}, {"text": "In the following, we will first present our corpora and reference data and detail the algorithms used.", "labels": [], "entities": []}, {"text": "Once the CLP are computed in all the training set, they are used as features to train classifiers.", "labels": [], "entities": []}, {"text": "For each candidate, the value of each feature will be the frequency of the CLP in the given context (bilateral, internal, left or right).", "labels": [], "entities": []}, {"text": "The training of the classifiers has been performed with Scikit-learn ().", "labels": [], "entities": []}, {"text": "Various classifiers (decision trees, support vector machines, bayesian networks).", "labels": [], "entities": []}, {"text": "10-fold cross validation has been performed so that the figures presented hereafter are the mean of the results for each fold.", "labels": [], "entities": []}, {"text": "In order to avoid learning biases, all the occurrences of a given candidate will be grouped in only one set per fold : the train set or the test set.", "labels": [], "entities": []}, {"text": "Therefore, with T LP internal and bilateral contexts yield the same results : the NC itself cannot be used by this method.", "labels": [], "entities": []}, {"text": "shows the results obtained with T LP for the French dataset with a SVM classifier (linear kernel) and C-parameter set at 1.", "labels": [], "entities": [{"text": "T LP", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.9506451487541199}, {"text": "French dataset", "start_pos": 45, "end_pos": 59, "type": "DATASET", "confidence": 0.9653056859970093}]}, {"text": "We will only focus on SVM since this classifier outperformed Decision trees, random forests and bayesian networks . The results for the internal end bilateral context are the same because of the design of the train and test sets (see Section 3.2.2).", "labels": [], "entities": []}, {"text": "Two results have to be highlighted here.", "labels": [], "entities": []}, {"text": "First, the left context gave by far the best results, suggesting that there are clues announcing neologisms.", "labels": [], "entities": []}, {"text": "Second, if we forget about left contexts, the results can be improved by expanding the windows size to 50 characters 6 . Our hypothesis is that expanding the context only improves the bad results and that expanding the left context mostly yields noise.", "labels": [], "entities": []}, {"text": "With 72% F-measure in the best case, the T LP method was promising but it was quickly outperformed by the CLP method.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.9988594055175781}, {"text": "T LP", "start_pos": 41, "end_pos": 45, "type": "METRIC", "confidence": 0.9356189072132111}]}, {"text": "On a first approach, we managed to tune the minimal (minlen) and maximal length (maxlen) of the CLP in order to reduce the search space because even in small windows there area huge amount of CLP .", "labels": [], "entities": [{"text": "maximal length (maxlen)", "start_pos": 65, "end_pos": 88, "type": "METRIC", "confidence": 0.9220118522644043}]}], "tableCaptions": [{"text": " Table 1: Composition of the dataset for French  and Russian", "labels": [], "entities": []}]}