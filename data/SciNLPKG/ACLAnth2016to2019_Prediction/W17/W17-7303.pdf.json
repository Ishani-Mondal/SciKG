{"title": [{"text": "Class disjointness constraints as specific objective functions in neural network classifiers", "labels": [], "entities": []}], "abstractContent": [{"text": "Increasing performance of deep learning techniques on computer vision tasks like object detection has led to systems able to detect a large number of classes of objects.", "labels": [], "entities": [{"text": "object detection", "start_pos": 81, "end_pos": 97, "type": "TASK", "confidence": 0.7811499834060669}]}, {"text": "Most deep learning models use simple unstructured labels and assume that any domain knowledge will be learned from the data.", "labels": [], "entities": []}, {"text": "However when the domain is complex and the data limited, it maybe useful to use domain knowledge encoded in an ontology to guide the learning process.", "labels": [], "entities": []}, {"text": "In this paper, we conduct experiments to introduce constraints into the training process of a neural network.", "labels": [], "entities": []}, {"text": "We show that explicitly mod-eling a disjointness axiom between a set of classes as a specific objective function leads to reducing violations for this constraint, while also reducing the overall classification error.", "labels": [], "entities": []}, {"text": "This opens away to import domain knowledge modeled in an ontology into a deep learning process.", "labels": [], "entities": []}], "introductionContent": [{"text": "As deep learning research progresses, efforts are made to add structure to the set of labels used as annotation data.", "labels": [], "entities": []}, {"text": "This seems a logical step as the number of labels in object classification tasks becomes larger.", "labels": [], "entities": [{"text": "object classification tasks", "start_pos": 53, "end_pos": 80, "type": "TASK", "confidence": 0.8116366068522135}]}, {"text": "For example the ImageNet challenge () in its 2017 edition invites system to localize objects in 1000 categories, detect 200 types of objects in images, and detect 20 types of objects in videos.", "labels": [], "entities": []}, {"text": "However little about the organization of these classes is provided.", "labels": [], "entities": []}, {"text": "Models are expected to implicitly acquire the knowledge that, for example, a person has two legs and a car four wheels from the training examples provided as part of the dataset.", "labels": [], "entities": []}, {"text": "What works on a controlled dataset in an academic challenge task might however be less practical in areal world example where annotated data can be scarce, and the modeled domain vast and complex.", "labels": [], "entities": []}, {"text": "The work presented in this paper is part of a larger project for automating the understanding of body worn camera footage in a law enforcement setting.", "labels": [], "entities": [{"text": "understanding of body worn camera footage", "start_pos": 80, "end_pos": 121, "type": "TASK", "confidence": 0.8073578874270121}]}, {"text": "The goal is to provide annotations that will facilitate the manual footage reviewing process that is mandatory across many agencies.", "labels": [], "entities": [{"text": "footage reviewing", "start_pos": 67, "end_pos": 84, "type": "TASK", "confidence": 0.6771801561117172}]}, {"text": "We train deep learning models to categorize videos by their type, for example a Traffic Stop, or a Pedestrian Stop; and to give annotations indicating the type of event ongoing at a specific time segment, for example an Officer Driving, or a Handcuffing.", "labels": [], "entities": []}, {"text": "The illustration below shows an example timeline our tool generates on an unseen video.", "labels": [], "entities": []}, {"text": "In parallel to developing models able to capture the specificities of this visual domain, we develop an ontology modeling this domain.", "labels": [], "entities": []}, {"text": "Type of detections are represented as classes modeled in RDFS and OWL).", "labels": [], "entities": [{"text": "OWL", "start_pos": 66, "end_pos": 69, "type": "DATASET", "confidence": 0.8588324189186096}]}, {"text": "There are three higher level classes for topics, segments, and objects that represent different levels of granularity: topics apply to a whole video, segments apply to a scene in a video that may vary from a few seconds to many minutes, and objects can be detected at any point in the video.", "labels": [], "entities": []}, {"text": "Because of legal and privacy concerns, and because of the cost of annotation, our training data set is limited to a few hundred videos.", "labels": [], "entities": []}, {"text": "This results in the need for models able to learn from small training sets.", "labels": [], "entities": []}, {"text": "In particular, we would like to be able to reflect the constraints modeled in the ontology into the neural network training process, so that this additional knowledge helps the neural network converge faster and compensates for the small training set.", "labels": [], "entities": []}, {"text": "We indeed assume that if a much larger training set would be available, the constraints implicitly modeled in the annotations could be learned by the neural network.", "labels": [], "entities": []}, {"text": "This paper focus on modeling and then learning a class disjointness constraint.", "labels": [], "entities": []}, {"text": "After giving class disjointness modeling examples related to our domain in Section 2 we formulate the constraint as a loss function applied on the disjoint classes.", "labels": [], "entities": []}, {"text": "Then in Section 3 we conduct experiments on a synthetic dataset showing that this method effectively leads to an improvement in enforcing the constraint.", "labels": [], "entities": []}, {"text": "2 From an ontology axiom to a loss function A long term goal of this work is to design a system where changes in the ontology would result in changes in the neural network training process.", "labels": [], "entities": []}, {"text": "Especially we are interested in studying how modeling constraints as ontology axioms can result in adding specific losses on the neural network output classes corresponding to the ontology classes on which these axioms apply.", "labels": [], "entities": []}, {"text": "OWL2) provides three constructs for expressing class disjointness.", "labels": [], "entities": [{"text": "OWL2", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9152194857597351}]}, {"text": "The main one owl:disjointWith is a class axiom specifying disjointness between this class and another.", "labels": [], "entities": []}, {"text": "Multiple owl:disjointWith statements can be defined within a class description.", "labels": [], "entities": []}, {"text": "In our use case, a set of topics are all disjoint fora given annotated video.", "labels": [], "entities": []}, {"text": "OWL2 introduces a convenient way to model this using the owl:DisjointUnion construct allowing to specify the disjointness outside of the class definition.", "labels": [], "entities": [{"text": "OWL2", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9648001194000244}]}, {"text": "The statement below expresses that the class Topic has three disjoint subclasses Pedestrian Stop, Traffic Stop and Car Pursuit.", "labels": [], "entities": [{"text": "Car Pursuit", "start_pos": 115, "end_pos": 126, "type": "TASK", "confidence": 0.6403581500053406}]}, {"text": "Similarly we find it more convenient to express that two classes are disjoint in a separate axiom than in the classes definitions.", "labels": [], "entities": []}, {"text": "The OWL2 construct owl:DisjointClasses allows to express that a set of classes is pairwise disjoint.", "labels": [], "entities": [{"text": "OWL2 construct owl:DisjointClasses", "start_pos": 4, "end_pos": 38, "type": "DATASET", "confidence": 0.8033092975616455}]}, {"text": "The statement below expresses that an officer cannot beat the same time driving a car and be a the passenger of that car.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments consist in testing the effect of the custom loss on forcing the neural network to learn the constraint.", "labels": [], "entities": []}, {"text": "As motivated in the introduction of this paper, the sensitive character of the data we  In order to be able to control parameters of the dataset we work with and to speedup training experiments, we generate synthetic data using the following procedure.", "labels": [], "entities": []}, {"text": "A number of pseudo-random numbers is generated for the input.", "labels": [], "entities": []}, {"text": "Outputs are separated into two sets: one set that represents classes under the disjointness axiom and for which we would like the disjointness constraint to apply, and another set which represent the other classes.", "labels": [], "entities": []}, {"text": "We set the number of outputs to be equal to the number of inputs and generate output values according to this: we take the argmax of the input set that represents disjoint classes, and assign the corresponding output to one.", "labels": [], "entities": []}, {"text": "Every other output in the disjoint set is set to zero.", "labels": [], "entities": []}, {"text": "The rest of the outputs are set to one if their corresponding input is greater than a given threshold, and to zero otherwise.", "labels": [], "entities": []}, {"text": "illustrates inputs and corresponding output values.", "labels": [], "entities": []}, {"text": "In the context of these experiments we use a dataset with a hundred thousand data points, having 50 generic classes and 5 disjoint classes.", "labels": [], "entities": []}, {"text": "We set the threshold parameter for generic classes to 0.5.", "labels": [], "entities": []}, {"text": "We selected the number of generic classes and disjoint classes to be about the same size of the number of classes and disjoint classes we have in our law enforcement use case.", "labels": [], "entities": []}], "tableCaptions": []}