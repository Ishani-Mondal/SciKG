{"title": [{"text": "Sequential Dialogue Context Modeling for Spoken Language Understanding", "labels": [], "entities": [{"text": "Sequential Dialogue Context Modeling", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.8620313704013824}]}], "abstractContent": [{"text": "Spoken Language Understanding (SLU) is a key component of goal oriented dialogue systems that would parse user utterances into semantic frame representations.", "labels": [], "entities": [{"text": "Spoken Language Understanding (SLU)", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8330988883972168}, {"text": "parse user utterances into semantic frame representations", "start_pos": 100, "end_pos": 157, "type": "TASK", "confidence": 0.7378619568688529}]}, {"text": "Traditionally SLU does not utilize the dialogue history beyond the previous system turn and contextual ambiguities are resolved by the downstream components.", "labels": [], "entities": [{"text": "SLU", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.9376609325408936}]}, {"text": "In this paper, we explore novel approaches for modeling dialogue context in a recurrent neural network (RNN) based language understanding system.", "labels": [], "entities": []}, {"text": "We propose the Sequential Dialogue Encoder Network, that allows encoding context from the dialogue history in chronological order.", "labels": [], "entities": [{"text": "Sequential Dialogue Encoder", "start_pos": 15, "end_pos": 42, "type": "TASK", "confidence": 0.7887728412946066}]}, {"text": "We compare the performance of our proposed architecture with two context models, one that uses just the previous turn context and another that encodes dialogue context in a memory network, but loses the order of utterances in the dialogue history.", "labels": [], "entities": []}, {"text": "Experiments with a multi-domain dialogue dataset demonstrate that the proposed architecture results in reduced semantic frame error rates.", "labels": [], "entities": []}], "introductionContent": [{"text": "Goal oriented dialogue systems help users with accomplishing tasks, like making restaurant reservations or booking flights, by interacting with them in natural language.", "labels": [], "entities": []}, {"text": "The capability to understand user utterances and break them down into task specific semantics is a key requirement for these systems.", "labels": [], "entities": []}, {"text": "This is accomplished in the spoken language understanding module, which typically parses user utterances into semantic frames, composed of domains, intents and slots, that can then be processed by downstream dia-  logue system components.", "labels": [], "entities": []}, {"text": "An example semantic frame is shown fora restaurant reservation related query in.", "labels": [], "entities": []}, {"text": "As the complexity of the task supported by a dialogue system increases, there is a need for an increased back and forth interaction between the user and the agent.", "labels": [], "entities": []}, {"text": "For example, a restaurant reservation task might require the user to specify a restaurant name, date, time and number of people required for the reservation.", "labels": [], "entities": [{"text": "restaurant reservation task", "start_pos": 15, "end_pos": 42, "type": "TASK", "confidence": 0.758963942527771}]}, {"text": "Additionally, based on reservation availability, the user might need to negotiate on date, time, or any other attribute with the agent.", "labels": [], "entities": []}, {"text": "This puts the burden of parsing in-dialogue contextual user utterances on the language understanding module.", "labels": [], "entities": [{"text": "parsing in-dialogue contextual user utterances", "start_pos": 24, "end_pos": 70, "type": "TASK", "confidence": 0.8930842995643615}]}, {"text": "The complexity increases further when the system supports more than one task and the user is allowed to have goals spanning multiple domains within the same dialogue.", "labels": [], "entities": [{"text": "complexity", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9654918313026428}]}, {"text": "Natural language utterances are often ambiguous, and the context from previous user and system turns could help resolve the errors arising from these ambiguities.", "labels": [], "entities": []}, {"text": "In this paper, we explore approaches to improve dialogue context modeling within a Recurrent Neural Network (RNN) based spoken language understanding system.", "labels": [], "entities": [{"text": "dialogue context modeling", "start_pos": 48, "end_pos": 73, "type": "TASK", "confidence": 0.7616032759348551}, {"text": "Recurrent Neural Network (RNN) based spoken language understanding", "start_pos": 83, "end_pos": 149, "type": "TASK", "confidence": 0.5505995273590087}]}, {"text": "We propose a novel model architecture to improve dialogue context modeling for spoken language understanding on a multi-domain dialogue dataset.", "labels": [], "entities": [{"text": "dialogue context modeling", "start_pos": 49, "end_pos": 74, "type": "TASK", "confidence": 0.7585616906483968}, {"text": "spoken language understanding", "start_pos": 79, "end_pos": 108, "type": "TASK", "confidence": 0.7687067786852518}]}, {"text": "The proposed architecture is an extension of Hierarchical Recurrent Encoder Decoders (HRED) ( , where we combine the query level encodings with a representation of the current utterance, before feeding it into the session level encoder.", "labels": [], "entities": []}, {"text": "We compare the performance of this model to a RNN tagger injected with just the previous turn context and a single hop memory network that uses an attention weighted combination of the dialogue context ().", "labels": [], "entities": []}, {"text": "Furthermore, we describe a dialogue recombination technique to enhance the complexity of the training dataset by injecting synthetic domain switches, to create a better match with the mixed domain dialogues in the test dataset.", "labels": [], "entities": []}, {"text": "This is, in principle, a multi-turn extension of.", "labels": [], "entities": []}, {"text": "Instead of inducing and composing grammars to synthetically enhance single turn text, we combine single domain dialogue sessions into multi-domain dialogues to provide richer context during training.", "labels": [], "entities": []}], "datasetContent": [{"text": "We crowd sourced multi-turn dialogue sessions for 3 tasks: buying movie tickets, searching fora restaurant and reserving tables at a restaurant.", "labels": [], "entities": []}, {"text": "Our data collection process comprises of two steps: (i) Generating user-agent interactions comprising of dialog acts and slots based on the interplay of a simulated user and a rule based dialogue policy.", "labels": [], "entities": []}, {"text": "(ii) Using a crowd sourcing platform to elicit natural language utterances that align with the semantics of the generated interactions.", "labels": [], "entities": []}, {"text": "The goal of the spoken language understanding module of our dialogue system is to map each user utterance into frame based semantics that can be processed by the downstream components.", "labels": [], "entities": [{"text": "spoken language understanding", "start_pos": 16, "end_pos": 45, "type": "TASK", "confidence": 0.7042223612467448}]}, {"text": "Tables describing the intents and slots present in the dataset can be found in the appendix.", "labels": [], "entities": []}, {"text": "We use a stochastic agenda-based user simulator ( for interplay with our rule based system policy.", "labels": [], "entities": []}, {"text": "The user goal is specified in terms of a tuple of slots, which denote the user constraints.", "labels": [], "entities": []}, {"text": "Some constraints might be unspecified, in which case the user is indifferent to the value of those slots.", "labels": [], "entities": []}, {"text": "At any given turn, the simulator samples a user dialogue act from a set of acceptable actions based on (i) the user goal and agenda that includes slots that still need to be specified, (ii) a randomly chosen user profile (co-operative/aggressive, verbose/succinct etc.) and (iii) the previous user and  We compare the domain classification, intent classification and slot-filling performances, and the overall frame error rates of the encoder-decoder, memory network and sequential dialogue encoder network on the dataset described above.", "labels": [], "entities": [{"text": "intent classification", "start_pos": 341, "end_pos": 362, "type": "TASK", "confidence": 0.6659906208515167}]}, {"text": "The frame error rate of a SLU system is the percentage of utterances where it makes a wrong prediction i.e. any of domain, intent or slot is predicted incorrectly.", "labels": [], "entities": [{"text": "frame error rate", "start_pos": 4, "end_pos": 20, "type": "METRIC", "confidence": 0.8974280953407288}]}, {"text": "We trained all 3 models with RMSProp for 100000 training steps with a batch size of 100.", "labels": [], "entities": [{"text": "RMSProp", "start_pos": 29, "end_pos": 36, "type": "DATASET", "confidence": 0.8097183108329773}]}, {"text": "We started with a learning rate of 0.0003 which was decayed by a factor of 0.95 every 3000 steps.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 18, "end_pos": 31, "type": "METRIC", "confidence": 0.9498579502105713}]}, {"text": "Gradient norms were clipped if they exceed a magnitude of 2.5.", "labels": [], "entities": [{"text": "Gradient norms", "start_pos": 0, "end_pos": 14, "type": "METRIC", "confidence": 0.9700250923633575}]}, {"text": "All model and optimization hyper-parameters were chosen based on a grid search, to minimize validation set frame error rates.: Dialogue from the test set with predictions from Encoder Decoder with recombined data (ED+DR), Memory Network with recombined data (MN+DR) and Sequential Dialogue Encoder Network with dialogue recombination (SDEN+DR).Tokens that have been italicized in the dialogue were out of vocabulary or replaced with special tokens.", "labels": [], "entities": []}, {"text": "The columns to the right of the dialogue history detail the attention distributions.", "labels": [], "entities": []}, {"text": "For SDEN+DR, we use the magnitude of the change in the session GRU state as a proxy for the attention distribution.", "labels": [], "entities": []}, {"text": "Attention weights might not sum up to 1 if there is non-zero attention on history padding.", "labels": [], "entities": [{"text": "Attention weights", "start_pos": 0, "end_pos": 17, "type": "METRIC", "confidence": 0.9614119529724121}]}], "tableCaptions": [{"text": " Table 3: Test set performances for the encoder decoder (ED) model, Memory Network (MN) and the  Sequential Dialogue Encoder Network (SDEN) with and without recombined data (DR).", "labels": [], "entities": []}]}