{"title": [], "abstractContent": [{"text": "Referential translation machines achieve top performance in both bilingual and monolingual settings without accessing any task or domain specific information or resource.", "labels": [], "entities": [{"text": "Referential translation", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8401546478271484}]}, {"text": "RTMs achieve the 3rd system results for German to English sentence-level prediction of translation quality and the 2nd system results according to root mean squared error.", "labels": [], "entities": [{"text": "RTMs", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7206953167915344}, {"text": "German to English sentence-level prediction", "start_pos": 40, "end_pos": 83, "type": "TASK", "confidence": 0.49725005626678465}, {"text": "root mean squared error", "start_pos": 147, "end_pos": 170, "type": "METRIC", "confidence": 0.7592295110225677}]}, {"text": "In addition to the new features about substring distances, punctuation tokens, character n-grams, and alignment crossings, and additional learning models, we average prediction scores from different models using weights based on their training performance for improved results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Quality estimation task (QET) in WMT17 () (QET17) is about prediction of the quality of machine translation output at the sentence-(Task 1), word-(Task 2), and phraselevel) in IT and pharmaceutical domains without using reference translations.", "labels": [], "entities": [{"text": "WMT17", "start_pos": 33, "end_pos": 38, "type": "DATASET", "confidence": 0.9181146621704102}]}, {"text": "Prediction of translation performance can help in estimating the effort required for correcting the translations during post-editing by human translators if needed.", "labels": [], "entities": []}, {"text": "RTMs are capable to model different domains and tasks while achieving top performance in both monolingual and bilingual settings.", "labels": [], "entities": []}, {"text": "We develop RTM models for all of the three subtasks of QET17, which include English to German (en-de), and German to English (de-en) translation directions.", "labels": [], "entities": [{"text": "QET17", "start_pos": 55, "end_pos": 60, "type": "DATASET", "confidence": 0.919239342212677}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Task 1 test results of the top 2 individual RTM models. RTM becomes the 2nd system accord- ing to RMSE and 3rd system in de-en and 6th system in en-de. r P is Pearson's correlation and r S is  Spearman's correlation.", "labels": [], "entities": [{"text": "RMSE", "start_pos": 108, "end_pos": 112, "type": "DATASET", "confidence": 0.7829448580741882}, {"text": "Pearson's correlation", "start_pos": 169, "end_pos": 190, "type": "METRIC", "confidence": 0.8088436325391134}, {"text": "Spearman's correlation", "start_pos": 203, "end_pos": 225, "type": "METRIC", "confidence": 0.5933999021848043}]}, {"text": " Table 2: Number of instances used as interpretants  by the RTM models.", "labels": [], "entities": []}, {"text": " Table 3: RTM Task 2 training results where GLMd  parallelized over 4 splits is referred as GLMd s4  and GLMd with 5 splits as GLMd s5.", "labels": [], "entities": [{"text": "RTM Task 2 training", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.7709099650382996}]}, {"text": " Table 4: RTM Task 2 results on the test set after  the challenge. wF 1 is average weighted F 1 score.", "labels": [], "entities": [{"text": "RTM Task", "start_pos": 10, "end_pos": 18, "type": "TASK", "confidence": 0.4654744416475296}, {"text": "wF 1", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.8869344890117645}, {"text": "average weighted F 1 score", "start_pos": 75, "end_pos": 101, "type": "METRIC", "confidence": 0.740368640422821}]}, {"text": " Table 5: QET16 Task 1 results are not improved with QET17 Task 1 RTM models.", "labels": [], "entities": [{"text": "QET16 Task 1", "start_pos": 10, "end_pos": 22, "type": "DATASET", "confidence": 0.7756400903066}, {"text": "QET17 Task 1 RTM", "start_pos": 53, "end_pos": 69, "type": "DATASET", "confidence": 0.8310593962669373}]}, {"text": " Table 6: Test performance of the top RTM results when predicting sentence-level HTER in 2013-2017.", "labels": [], "entities": [{"text": "predicting sentence-level HTER", "start_pos": 55, "end_pos": 85, "type": "TASK", "confidence": 0.649796187877655}]}]}