{"title": [{"text": "Sense Embeddings in Knowledge-Based Word Sense Disambiguation", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 36, "end_pos": 61, "type": "TASK", "confidence": 0.6515508989493052}]}], "abstractContent": [{"text": "In this paper, we develop anew way of creating sense vectors for any dictionary, by using an existing word embeddings model, and summing the vectors of the terms inside a sense's definition, weighted in function of their part of speech and their frequency.", "labels": [], "entities": []}, {"text": "These vectors are then used for finding the closest senses to any other sense, thus creating a semantic network of related concepts, automatically generated.", "labels": [], "entities": []}, {"text": "This network is hence evaluated against the existing semantic network found in WordNet, by comparing its contribution to a knowledge-based method for Word Sense Dis-ambiguation.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 79, "end_pos": 86, "type": "DATASET", "confidence": 0.9468838572502136}, {"text": "Word Sense Dis-ambiguation", "start_pos": 150, "end_pos": 176, "type": "TASK", "confidence": 0.6395673553148905}]}, {"text": "This method can be applied to any other language which lacks such semantic network, as the creation of word vectors is totally unsupervised, and the creation of sense vectors only needs a traditional dictionary.", "labels": [], "entities": []}, {"text": "The results show that our generated semantic network improves greatly the WSD system, almost as much as the manually created one.", "labels": [], "entities": [{"text": "WSD", "start_pos": 74, "end_pos": 77, "type": "TASK", "confidence": 0.6536663174629211}]}], "introductionContent": [{"text": "In Natural Language Processing (NLP), Word Sense Disambiguation (WSD) aims at assigning the most probable sense of a word in a document, given a pre-defined sense inventory.", "labels": [], "entities": [{"text": "Natural Language Processing (NLP)", "start_pos": 3, "end_pos": 36, "type": "TASK", "confidence": 0.7173813780148824}, {"text": "Word Sense Disambiguation (WSD)", "start_pos": 38, "end_pos": 69, "type": "TASK", "confidence": 0.765713502963384}, {"text": "assigning the most probable sense of a word in a document", "start_pos": 78, "end_pos": 135, "type": "TASK", "confidence": 0.6942260319536383}]}, {"text": "State of the art methods in WSD are often supervised systems, as stated by, which are trained thanks to a great quantity of sense usage examples coming from sense-annotated corpora.", "labels": [], "entities": [{"text": "WSD", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.9713957905769348}]}, {"text": "The trained model is then used to tag a word with the sense that appears to be the most correct given its context.", "labels": [], "entities": []}, {"text": "Unsupervised and knowledge-based methods, on the other hand, have the advantage that they require much less resource to work, and in particular no sense-annotated corpora.", "labels": [], "entities": []}, {"text": "Hence they offer a wider coverage more easily, as they do not need to learn a sense from an example in order to assign it to a word.", "labels": [], "entities": []}, {"text": "In addition, unsupervised and knowledge-based methods are generally the only usable systems to work for disambiguating another language than English.", "labels": [], "entities": []}, {"text": "Indeed, sense-annotated corpora are very expensive resources to produce, and almost practically inexisting for every other languages . For this reason, this paper will focus on a knowledge-based method, and on a novel approach that improves its performance in an unsupervised manner, by using word embeddings.", "labels": [], "entities": []}, {"text": "Word embeddings area set of methods which aim to represent words as vectors.", "labels": [], "entities": []}, {"text": "Several recent state of the art methods such as's Word2Vec,'s GloVe and's dependency-based vectors have proven to be very useful in many NLP tasks, like Machine Translation, Word Similarity tasks, and even in WSD, where word embeddings are also parts of some recent methods, such as, or.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 50, "end_pos": 58, "type": "DATASET", "confidence": 0.9514238238334656}, {"text": "Machine Translation", "start_pos": 153, "end_pos": 172, "type": "TASK", "confidence": 0.8462563753128052}, {"text": "Word Similarity tasks", "start_pos": 174, "end_pos": 195, "type": "TASK", "confidence": 0.7941266298294067}, {"text": "WSD", "start_pos": 209, "end_pos": 212, "type": "TASK", "confidence": 0.8600860834121704}]}, {"text": "In this paper, we are going to produce sense embeddings, i.e. vectors which represent senses present in the lexical database Princeton WordNet.", "labels": [], "entities": [{"text": "Princeton WordNet", "start_pos": 125, "end_pos": 142, "type": "DATASET", "confidence": 0.8835069239139557}]}, {"text": "The methodology used to create these vectors is described in section 2.", "labels": [], "entities": []}, {"text": "Other methods exist for computing sense embeddings, such as in for example, who learn a distributional representation of senses through sense-annotated corpora and Word2Vec, but it presupposes a good WSD system, which is already able to sense-annotate precisely.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 164, "end_pos": 172, "type": "DATASET", "confidence": 0.9558246731758118}]}, {"text": "Our sense vectors are hence evaluated by comparing their performance when used as a semantic network fora knowledge-based WSD system described in section 3.1.", "labels": [], "entities": []}, {"text": "The sense embeddings will be used for expanding the gloss of every sense in WordNet, by concatenating the gloss of the most related senses, in a similar way than's Extended Lesk algorithm does, but instead of considering that two senses are related because they share a lexical or semantic relation in the WordNet network, we consider two senses to be related if their vector's cosine similarity reaches a certain threshold.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 76, "end_pos": 83, "type": "DATASET", "confidence": 0.9672154188156128}]}, {"text": "In the experiments in section 4, we evaluate our method on two different English all-words disambiguation tasks: first, we learn the best value of the similarity threshold on a task, then, this value is tested on the other task.", "labels": [], "entities": [{"text": "English all-words disambiguation", "start_pos": 73, "end_pos": 105, "type": "TASK", "confidence": 0.668299396832784}]}, {"text": "The scores shown are hence the ones we obtain for the latter task, and thereafter, we perform the opposite.", "labels": [], "entities": []}, {"text": "The method could be applied to any language for which it exists a dictionary and a set a unannotated corpora.", "labels": [], "entities": []}, {"text": "However, it is evaluated on an English task for at least two reasons: First, it will be easier to compare our results to other systems, since the main WSD evaluation campaigns also use WordNet.", "labels": [], "entities": [{"text": "WSD evaluation", "start_pos": 151, "end_pos": 165, "type": "TASK", "confidence": 0.6582722067832947}, {"text": "WordNet", "start_pos": 185, "end_pos": 192, "type": "DATASET", "confidence": 0.9441909790039062}]}, {"text": "Second, we wanted to compare the benefits of different pre-existing word embeddings models to our system, and the most popular ones are trained on English corpora.", "labels": [], "entities": []}], "datasetContent": [{"text": "The generated vector representation of senses will be evaluated on a WSD task, as a supplementary resource fora knowledge-based method.", "labels": [], "entities": [{"text": "WSD task", "start_pos": 69, "end_pos": 77, "type": "TASK", "confidence": 0.7092072665691376}]}, {"text": "The idea is to use the embeddings model as a semantic network, which is able to fetch senses related to another sense.", "labels": [], "entities": []}, {"text": "These related senses will then contribute to the similarity measure used in the WSD system, in the same manner than's usage of the semantic network integrated in WordNet.", "labels": [], "entities": [{"text": "similarity measure", "start_pos": 49, "end_pos": 67, "type": "METRIC", "confidence": 0.9267081022262573}, {"text": "WSD", "start_pos": 80, "end_pos": 83, "type": "TASK", "confidence": 0.620640754699707}, {"text": "WordNet", "start_pos": 162, "end_pos": 169, "type": "DATASET", "confidence": 0.9345168471336365}]}, {"text": "In order to see how our sense embeddings model performs as a semantic network, we use it fora lexical expansion of the dictionary's glosses, for improving the Lesk local algorithm of our WSD system.", "labels": [], "entities": []}, {"text": "Our expansion considers the related senses regarding two cosine similarity threshold: \u03b4 1 , filtering out senses based on their similarity with the target sense's lemma vector, and \u03b4 2 , filtering out senses based on their similarity with the target sense vector.", "labels": [], "entities": []}, {"text": "These two parameters have to beset in someway, so we chose two WSD tasks: SemEval 2007 task 7 (), and SemEval 2015 task 13, and we estimated the best set of parameters on a task, then tested this set of parameters on the other.", "labels": [], "entities": [{"text": "WSD tasks", "start_pos": 63, "end_pos": 72, "type": "TASK", "confidence": 0.7916454374790192}, {"text": "SemEval 2007 task 7", "start_pos": 74, "end_pos": 93, "type": "TASK", "confidence": 0.5225627794861794}]}, {"text": "The reason why we chose these two tasks is that they are of the same nature, i.e. both all-words WSD tasks, and that the task 7 of SemEval 2007 is largely used inmost WSD articles, so it is easier to put the results in perspective.", "labels": [], "entities": [{"text": "WSD tasks", "start_pos": 97, "end_pos": 106, "type": "TASK", "confidence": 0.83627849817276}]}, {"text": "All five word embeddings models mentioned in section 2 are evaluated separately.", "labels": [], "entities": []}, {"text": "And the parameters \u03b4 1 and \u03b4 2 have been estimated by testing every values in the range [0.5, 0.9] with steps of 0.1.", "labels": [], "entities": []}, {"text": "The results of the best parameters estimation on SemEval 2007 task 7 and on SemEval 2015 task 13 is in.", "labels": [], "entities": [{"text": "SemEval 2007 task 7", "start_pos": 49, "end_pos": 68, "type": "DATASET", "confidence": 0.7628893554210663}, {"text": "SemEval 2015 task 13", "start_pos": 76, "end_pos": 96, "type": "TASK", "confidence": 0.5969824939966202}]}, {"text": "The parameters \u03b4 1 and \u03b4 2 used in VecLesk are taken from the parameter estimation of from the other task, not the one that is tested.", "labels": [], "entities": []}, {"text": "The results show that our extension improves greatly the score of the Lesk measure, which is at least around +5% for the worst combination of word embeddings model and parameters, on SemEval 2007, and around +7% for the best combination.", "labels": [], "entities": [{"text": "SemEval 2007", "start_pos": 183, "end_pos": 195, "type": "DATASET", "confidence": 0.8408191502094269}]}, {"text": "On SemEval 2015, the worst extension still improves the score by +3%, and the best one gives +9%.", "labels": [], "entities": [{"text": "SemEval 2015", "start_pos": 3, "end_pos": 15, "type": "DATASET", "confidence": 0.8189833760261536}]}, {"text": "Our extension does not reach the score of the Extended Lesk baseline however.", "labels": [], "entities": [{"text": "Extended Lesk baseline", "start_pos": 46, "end_pos": 68, "type": "DATASET", "confidence": 0.8980489174524943}]}, {"text": "Which is a sign that our semantic network is probably less relevant than the explicit links found in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 101, "end_pos": 108, "type": "DATASET", "confidence": 0.9652252793312073}]}, {"text": "An interesting data is the difference of score obtained by the different word embeddings model.", "labels": [], "entities": [{"text": "difference of score", "start_pos": 27, "end_pos": 46, "type": "METRIC", "confidence": 0.8414463996887207}]}, {"text": "The best result on SemEval 2007 uses's count vectors, and the score is 2% higher than the second best word embeddings model's score (using.", "labels": [], "entities": []}, {"text": "This tends to show that the \"older\" approach of word embeddings creation, i.e. counting-based vectors, are in some cases a better choice than the predicting models.", "labels": [], "entities": [{"text": "word embeddings creation", "start_pos": 48, "end_pos": 72, "type": "TASK", "confidence": 0.6250669757525126}]}, {"text": "However, on SemEval 2015, the best model is GloVe.", "labels": [], "entities": [{"text": "SemEval 2015", "start_pos": 12, "end_pos": 24, "type": "DATASET", "confidence": 0.7173635363578796}]}, {"text": "Baroni's count vectors is a close second though.", "labels": [], "entities": []}, {"text": "The fluctuation of the results in function of the model used maybe because of the different natures of the word embeddings models, or due to the different corpora they were trained on.", "labels": [], "entities": []}, {"text": "In any cases, our extension works with any model, systematically raising the score from the Lesk baseline.", "labels": [], "entities": []}, {"text": "The comparison of our system to the best existing method to our knowledge that uses the same kind of resources than us (i.e. a dictionary and unannotated corpora), shows that our extension achieves state of the art results on methods using such few resources.", "labels": [], "entities": []}, {"text": "The score achieved by has to be treated with caution, because they learned a threshold parameter \u03b4 similarly to us, for their construction of vectors, however they estimated their best parameter and tested on the same corpus, leading to an obvious bias.", "labels": [], "entities": []}, {"text": "Note that in the same conditions, when we use the best set of parameters learned on this same task, our method reaches a score of 77.08% on In this article, we created a Sense Embeddings model, representing every sense of a dictionary, based on the words contained in their gloss and using an existing Word Embeddings model.", "labels": [], "entities": []}, {"text": "Our method of construction essentially computes the sum of the gloss terms' vectors, weighted in function of their part of speech and their inverse frequency.", "labels": [], "entities": []}, {"text": "We created five sense embeddings models, each one of them relying on different word embeddings model.", "labels": [], "entities": []}, {"text": "They are available publicly on our GitHub 8 . The models are then used as a semantic network for improving a knowledge-based WSD system, based on the Lesk algorithm.", "labels": [], "entities": []}, {"text": "The idea is to take into account the closest senses to a target sense in our semantic network, in order to disambiguate it, in the same manner as do using the related senses information builtin WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 194, "end_pos": 201, "type": "DATASET", "confidence": 0.9512618780136108}]}, {"text": "The resulting extended WSD system performs systematically better than its unextended baseline counterpart, improving the score from about +3% for the worst extension, to about +9% for the best one.", "labels": [], "entities": [{"text": "WSD", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.798818826675415}]}, {"text": "This article uses WordNet as a dictionary, and evaluations are performed on two English all-words WSD tasks, because it is easier to compare the performance and the robustness of the method, as the majority of the researches in WSD uses this language.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 18, "end_pos": 25, "type": "DATASET", "confidence": 0.9374078512191772}]}, {"text": "However, the whole process of sense embeddings creation and Lesk extension can be easily adapted to many language, requiring only a set of unannotated corpora, and atypical dictionary, thus, giving the possibility to create an efficient WSD system, even fora poorly resourced language.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Estimation of parameters \u03b4 1 and \u03b4 2 on SemEval 2007 task 7 and SemEval 2015 task 13.", "labels": [], "entities": [{"text": "SemEval 2007 task 7", "start_pos": 50, "end_pos": 69, "type": "DATASET", "confidence": 0.7129325419664383}, {"text": "SemEval 2015 task 13", "start_pos": 74, "end_pos": 94, "type": "TASK", "confidence": 0.4913911372423172}]}, {"text": " Table 2: Comparison of our results on SemEval 2007 task 7 and SemEval 2015 task 13 for each word embeddings  model used, in regards with the Lesk and Extended Lesk baselines and a state of the art method that uses similar  resources than us. The parameters \u03b4 1 and \u03b4 2 used in VecLesk are taken from the parameter estimation of", "labels": [], "entities": []}]}