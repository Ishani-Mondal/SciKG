{"title": [{"text": "Adapting a State-of-the-Art Tagger for South Slavic Languages to Non-Standard Text", "labels": [], "entities": [{"text": "Adapting", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.9778023958206177}]}], "abstractContent": [{"text": "In this paper we present the adaptations of a state-of-the-art tagger for South Slavic languages to non-standard texts on the example of the Slovene language.", "labels": [], "entities": []}, {"text": "We investigate the impact of introducing in-domain training data as well as additional supervision through external resources or tools like word clusters and word normalization.", "labels": [], "entities": [{"text": "word normalization", "start_pos": 158, "end_pos": 176, "type": "TASK", "confidence": 0.7729291915893555}]}, {"text": "We remove more than half of the error of the standard tagger when applied to non-standard texts by training it on a combination of standard and non-standard training data, while enriching the data representation with external resources removes additional 11 percent of the error.", "labels": [], "entities": []}, {"text": "The final configuration achieves tagging accuracy of 87.41% on the full morphosyntactic description , which is, nevertheless, still quite far from the accuracy of 94.27% achieved on standard text.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9859756827354431}, {"text": "accuracy", "start_pos": 151, "end_pos": 159, "type": "METRIC", "confidence": 0.9989086389541626}]}], "introductionContent": [{"text": "With the rise of social media, the potential from automatically processing the available textual content is substantial.", "labels": [], "entities": []}, {"text": "However, there is a series of problems connected to processing Computer Mediated Communication (CMC) due to frequent deviation from the norm, such as omission of diacritics, non-standard word spellings and frequent use of colloquial expressions.", "labels": [], "entities": [{"text": "processing Computer Mediated Communication (CMC)", "start_pos": 52, "end_pos": 100, "type": "TASK", "confidence": 0.7135927251407078}]}, {"text": "For example, experiments on English part-of-speech tagging showed a drastic loss inaccuracy when shifting from Wall Street Journal text (97%) to Twitter (85%) (.", "labels": [], "entities": [{"text": "English part-of-speech tagging", "start_pos": 28, "end_pos": 58, "type": "TASK", "confidence": 0.6000056465466818}, {"text": "Wall Street Journal text", "start_pos": 111, "end_pos": 135, "type": "DATASET", "confidence": 0.9491233974695206}]}, {"text": "Part-of-speech (PoS) tagging is a crucial step in the text processing pipeline, as it gives invaluable information about the grammatical properties of words in context and thus enables, e.g., better information extractions from texts, high quality lemmatization, syntactic parsing, the use of factored models in machine translation etc.", "labels": [], "entities": [{"text": "Part-of-speech (PoS) tagging", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6143631398677826}, {"text": "information extractions from texts", "start_pos": 199, "end_pos": 233, "type": "TASK", "confidence": 0.8318731933832169}, {"text": "syntactic parsing", "start_pos": 263, "end_pos": 280, "type": "TASK", "confidence": 0.768744021654129}, {"text": "machine translation", "start_pos": 312, "end_pos": 331, "type": "TASK", "confidence": 0.7220444679260254}]}, {"text": "This paper concentrates on adapting a state-ofthe art tagger of standard Slovene , Croatian and Serbian  to CMC texts on the example of Slovene language by experimenting with in-domain training data and additional external resources and tools such as word clusters and word normalization.", "labels": [], "entities": [{"text": "word normalization", "start_pos": 269, "end_pos": 287, "type": "TASK", "confidence": 0.7627660930156708}]}, {"text": "The rest of the paper is structured as follows: Section 2 gives an overview of the related work on this problem, Section 3 introduces the dataset used, Section 4 describes the tagging experiments we performed, Section 5 reports on the error analysis of the results and Section 6 gives some conclusions and directions for further research.", "labels": [], "entities": []}], "datasetContent": [{"text": "As the primary resource for training and evaluating our tagger of non-standard language we used the publicly available Janes-Tag v1.2 dataset), which contains Slovene CMC texts, with the text types being tweets, forum posts, comments on blog posts and comments on news articles.", "labels": [], "entities": [{"text": "Janes-Tag v1.2 dataset", "start_pos": 119, "end_pos": 141, "type": "DATASET", "confidence": 0.8915929992993673}, {"text": "Slovene CMC texts", "start_pos": 159, "end_pos": 176, "type": "DATASET", "confidence": 0.8591130177179972}]}, {"text": "The texts were sampled from the Janes corpus , a large corpus (9 million texts with about 200 million tokens) of Slovene CMC.", "labels": [], "entities": [{"text": "Janes corpus", "start_pos": 32, "end_pos": 44, "type": "DATASET", "confidence": 0.8828984498977661}, {"text": "Slovene CMC", "start_pos": 113, "end_pos": 124, "type": "DATASET", "confidence": 0.9191060662269592}]}, {"text": "The texts in the Janes corpus are, inter alia, annotated with language standardness scores for each text.", "labels": [], "entities": [{"text": "Janes corpus", "start_pos": 17, "end_pos": 29, "type": "DATASET", "confidence": 0.9457538723945618}]}, {"text": "These scores were assigned automatically) and classify texts into three levels of technical and linguistic standardness.", "labels": [], "entities": []}, {"text": "Technical standardness (T1, quite standard -T3, very non-standard) relates to the use of spaces, punctuation, capitalization and similar, while linguistic standardness (L1 -L3) takes into account the level of adherence to the written norm and more or less conscious decisions to use non-standard language with respect to spelling, lexis, morphology, and word order.", "labels": [], "entities": []}, {"text": "The texts for the Janes-Tag dataset were sampled so that they contain, for each text type, roughly the same number of T1L1, T1L3, T3L3, and T3L3 texts, except for tweets, where only T1L3 and T3L3 texts were included in order to maximize twitter-specific deviations from the norm.", "labels": [], "entities": [{"text": "Janes-Tag dataset", "start_pos": 18, "end_pos": 35, "type": "DATASET", "confidence": 0.9634180963039398}]}, {"text": "The texts in Janes-Tag were first automatically annotated and then manually checked for the following levels of linguistic annotation: tokenization, sentence segmentation, normalization, partof-speech tagging and lemmatization.", "labels": [], "entities": [{"text": "Janes-Tag", "start_pos": 13, "end_pos": 22, "type": "DATASET", "confidence": 0.9054786562919617}, {"text": "sentence segmentation", "start_pos": 149, "end_pos": 170, "type": "TASK", "confidence": 0.6996266096830368}, {"text": "partof-speech tagging", "start_pos": 187, "end_pos": 208, "type": "TASK", "confidence": 0.8085906505584717}]}, {"text": "Here normalization refers to giving the standard equivalent to non-standard word-forms, e.g., jaz (I) assigned to the source jst, js, jest etc., while tagging and lemmatization is then assigned to these normalized forms.", "labels": [], "entities": []}, {"text": "It should be noted that two (or more) source word tokens can be normalized to one token or vice versa.", "labels": [], "entities": []}, {"text": "The tagset used is defined in the (draft) MULTEXT-East morphosyntactic specification Version 5 2 for Slovene, which are identical to the Version 4 specifications, except that four new tags have been added for CMC specific phenomena, such as hashtags and mentions.", "labels": [], "entities": [{"text": "MULTEXT-East morphosyntactic specification Version 5", "start_pos": 42, "end_pos": 94, "type": "DATASET", "confidence": 0.8081815004348755}]}, {"text": "Version 5 tagset for Slovene defines all together 1900 different tags (morphosyntactic descriptions, MSDs), i.e., it is a fine-grained tagset covering all the inflectional properties of Slovene words.", "labels": [], "entities": []}, {"text": "The dataset is distributed in the canonical TEI encoding as well as in the derived vertical format used by concordancers such as CQP.", "labels": [], "entities": [{"text": "CQP", "start_pos": 129, "end_pos": 132, "type": "DATASET", "confidence": 0.9387287497520447}]}, {"text": "Further details on the dataset can be found in ().", "labels": [], "entities": []}, {"text": "We split the dataset into training, development and testing subsets in a 80:10:10 fashion.", "labels": [], "entities": []}, {"text": "We performed stratified sampling over texts with strata being text type and linguistic standardness in order for each subset to have the same distribution of texts given the two variables.", "labels": [], "entities": []}, {"text": "This split is also available as part of ().", "labels": [], "entities": []}, {"text": "Basic statistics of the dataset and subsets are given in Table 1.", "labels": [], "entities": []}, {"text": "It should be noted that in cases of n : 1 or 1 :  In this section we present experiments on introducing non-standard training data (4.1), adding word clustering information (4.2), measuring the impact of the standard inflectional lexicon (4.3), adding word normalization data (4.4) and combining standard and non-standard training data (4.5).", "labels": [], "entities": [{"text": "word clustering", "start_pos": 145, "end_pos": 160, "type": "TASK", "confidence": 0.6927707940340042}, {"text": "word normalization", "start_pos": 252, "end_pos": 270, "type": "TASK", "confidence": 0.6818114072084427}]}], "tableCaptions": [{"text": " Table 1: Janes-Tag dataset statistics.", "labels": [], "entities": [{"text": "Janes-Tag dataset", "start_pos": 10, "end_pos": 27, "type": "DATASET", "confidence": 0.8244930505752563}]}, {"text": " Table 2: Results in accuracy on the first four sets  of experiments.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9994876384735107}]}, {"text": " Table 3: Results in accuracy on combining stan- dard and non-standard training data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9994617104530334}]}, {"text": " Table 4. We  again check whether the difference between the  janes and janes+ configuration is statistically  significant with the McNemar's test, obtaining a  p-value of 1.53  *  10 \u221210 on the MSD level and a  p-value of 9.49  *  10 \u221215 on the PoS level.", "labels": [], "entities": [{"text": "McNemar's test", "start_pos": 132, "end_pos": 146, "type": "DATASET", "confidence": 0.7841678659121195}, {"text": "PoS", "start_pos": 246, "end_pos": 249, "type": "METRIC", "confidence": 0.7320573925971985}]}, {"text": " Table 4: Results in accuracy of the three final con- figurations on the test portion of the dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.999305009841919}]}]}