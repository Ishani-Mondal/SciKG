{"title": [], "abstractContent": [{"text": "This paper describes LIMSI participation to the WMT'17 shared task on Bandit Learning.", "labels": [], "entities": [{"text": "WMT'17 shared task", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.4992903470993042}, {"text": "Bandit Learning", "start_pos": 70, "end_pos": 85, "type": "TASK", "confidence": 0.5380976796150208}]}, {"text": "The method we propose to adapt a seed system trained on out-domain data to anew, unknown domain relies on two components.", "labels": [], "entities": []}, {"text": "First, we use a linear regression model to exploit the weak and partial feedback the system receives by learning to predict the reward a translation hypothesis will get.", "labels": [], "entities": []}, {"text": "This model can then be used to score hypotheses in the search space and translate source sentences while taking into account the specificities of the in-domain data.", "labels": [], "entities": []}, {"text": "Second, we use the UCB1 algorithm to choose which of the 'adapted' or 'seed' system must be used to translate a given source sentence in order to maximize the cumulative reward.", "labels": [], "entities": []}, {"text": "Results on the development and train sets show that the proposed method does not succeed in improving the seed system.", "labels": [], "entities": []}, {"text": "We explore several hypotheses to explain this negative result.", "labels": [], "entities": []}], "introductionContent": [{"text": "The first Bandit Learning for Machine Translation shared task () aims at adapting a 'seed' MT system trained on out-domain corpora to anew domain considering only a 'weak' signal, namely a translation quality judgment rather than a reference translation or a post-edition.", "labels": [], "entities": [{"text": "Bandit Learning for Machine Translation shared task", "start_pos": 10, "end_pos": 61, "type": "TASK", "confidence": 0.7185397446155548}, {"text": "MT", "start_pos": 91, "end_pos": 93, "type": "TASK", "confidence": 0.9675171971321106}]}, {"text": "Such a situation arises when the user is not a skilled translator but can nevertheless decide whether a translation is useful or not.", "labels": [], "entities": []}, {"text": "The signal is qualified as 'weak' as only the score of the translation produced by a system can be known, the same sentence cannot be translated twice and no reference is ever revealed.", "labels": [], "entities": []}, {"text": "Adapting a MT system from a weak signal raises three main challenges.", "labels": [], "entities": [{"text": "MT", "start_pos": 11, "end_pos": 13, "type": "TASK", "confidence": 0.9661635756492615}]}, {"text": "First, the parameters of the MT system must be estimated without knowing the reference translation which rules out most of the usual optimization methods for MT such as MERT, MIRA or the computation of likelihood at the heart of NMT systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 29, "end_pos": 31, "type": "TASK", "confidence": 0.9712502956390381}, {"text": "MT", "start_pos": 158, "end_pos": 160, "type": "TASK", "confidence": 0.9898014664649963}, {"text": "MERT", "start_pos": 169, "end_pos": 173, "type": "METRIC", "confidence": 0.9763486385345459}, {"text": "MIRA", "start_pos": 175, "end_pos": 179, "type": "METRIC", "confidence": 0.992369532585144}]}, {"text": "Second, the system must be trained in a 'one-shot' way as each source sentence can only be translated once and will result in a single reward.", "labels": [], "entities": []}, {"text": "Third, no information about the target domain is available and its specificities must be discovered 'on-the-fly'.", "labels": [], "entities": []}, {"text": "To address these challenges, we propose an adaptation method that relies on two components.", "labels": [], "entities": []}, {"text": "First, we use a linear regression model to exploit the weak and partial feedback the system receives by learning to predict the reward a translation hypothesis will get.", "labels": [], "entities": []}, {"text": "This model can then be used to score hypotheses of the search space and translate source sentences while taking into account the specificities of the in-domain data.", "labels": [], "entities": []}, {"text": "Second, we use the UCB1 algorithm to choose which of the 'adapted' or 'seed' system must be used to translate a given source sentence in order to maximize the cumulative reward.", "labels": [], "entities": []}, {"text": "The rest of this article is organized as follows: we will first describe the shared task and the different challenges it raises ( \u00a72).", "labels": [], "entities": []}, {"text": "Then we will describe the proposed method ( \u00a73-4) and discuss their results in \u00a75.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Results on the Development data set", "labels": [], "entities": [{"text": "Development data set", "start_pos": 25, "end_pos": 45, "type": "DATASET", "confidence": 0.9160499572753906}]}, {"text": " Table 3: Number of times each translation system is chosen by the UCB1 strategy on the development  set. 'Out-Domain' refers to the seed system, In-Domain to the system trained on the rewards and the last  two systems to systems sampling randomly hypotheses from the search space.", "labels": [], "entities": []}]}