{"title": [{"text": "Unsupervised Morpheme Segmentation Through Numerical Weighting and Thresholding", "labels": [], "entities": [{"text": "Morpheme Segmentation", "start_pos": 13, "end_pos": 34, "type": "TASK", "confidence": 0.6792027205228806}]}], "abstractContent": [{"text": "This paper presents an unsupervised model for morpheme segmentation of words collected from any raw textual corpus of a natural language.", "labels": [], "entities": [{"text": "morpheme segmentation of words collected from any raw textual corpus of a natural language", "start_pos": 46, "end_pos": 136, "type": "TASK", "confidence": 0.759018770286015}]}, {"text": "The model incorporates a numerical weighting scheme with thresholding technique for finding legitimate morphemes from a given input corpus.", "labels": [], "entities": []}, {"text": "Kneedle algorithm is used as a thresholding technique for determining legitimacy of the morphemes.", "labels": [], "entities": []}, {"text": "We ran our experiments on five languages-English, Finish, Turkish, German and Bengali, and the model performance is comparable to the state-of-the-art systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "Morpheme segmentation of words is an essential part of many linguistic and natural language processing applications.", "labels": [], "entities": [{"text": "Morpheme segmentation of words", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8966275155544281}]}, {"text": "Appropriate morpheme segmentation helps to understand the hidden structure of a language's words and how new words can be built from the existing words.", "labels": [], "entities": []}, {"text": "In morpheme segmentation, a word is divided into a stem morpheme and a single affix morpheme (for one-slot morphological languages) or multiple affix morphemes (for multi-slot morphological languages).", "labels": [], "entities": [{"text": "morpheme segmentation", "start_pos": 3, "end_pos": 24, "type": "TASK", "confidence": 0.7428849935531616}]}, {"text": "Stem is also often referred to as base, root, lemma, etc., although they have subtle differences and are used in different contexts.", "labels": [], "entities": []}, {"text": "An affix can be of many types; some of the most commonly understood affixes are prefix, suffix, infix, etc.", "labels": [], "entities": []}, {"text": "However, for the proposed model, only prefixes and suffixes are considered.", "labels": [], "entities": []}, {"text": "Two primary functional types of morphemes exist in morphology: inflectional and derivational morphemes.", "labels": [], "entities": []}, {"text": "Inflectional morphemes are affixes that are used to create variant forms of a word in order to signal grammatical information; but they do not change the meaning of the word.", "labels": [], "entities": []}, {"text": "* *Work done while at Jadavpur University.", "labels": [], "entities": []}, {"text": "Derivational morphemes are affixes that are used to derive new words with new meanings.", "labels": [], "entities": []}, {"text": "Both types of morphemes are considered in our work.", "labels": [], "entities": []}, {"text": "The presented model's work principle falls into the category of Unsupervised Learning of Morphology (ULM)) which usually outputs a morphological structure description of a language from an input raw corpus of that language, provided that the system may need some semi-automatic or manual supervision.", "labels": [], "entities": [{"text": "Unsupervised Learning of Morphology (ULM))", "start_pos": 64, "end_pos": 106, "type": "TASK", "confidence": 0.6382210339818682}]}, {"text": "The objectives of an ULM based approach can vary.", "labels": [], "entities": []}, {"text": "It generally ranges from demand for morphological description of a language to finding lexicon, paradigm list for stems, affix list, samestem decision, inflectional table and much more.", "labels": [], "entities": []}, {"text": "The objective of our proposed model is to discover the stem set and an affix set given a large corpus of a particular language.", "labels": [], "entities": []}, {"text": "Although there are many motivating factors behind ULM from both linguistic and practical point of view (Hammarstr\u00f6m and Borin, 2011), the three major motivations are -providing a primary-step for language acquisition, reducing time-consuming manual effort in morphological analysis and language documentation.", "labels": [], "entities": [{"text": "ULM", "start_pos": 50, "end_pos": 53, "type": "TASK", "confidence": 0.9590089917182922}, {"text": "language acquisition", "start_pos": 196, "end_pos": 216, "type": "TASK", "confidence": 0.7425930500030518}, {"text": "language documentation", "start_pos": 286, "end_pos": 308, "type": "TASK", "confidence": 0.6811769902706146}]}, {"text": "The first motivation is elicited from the necessity of grabbing primary details and learning basic word structures fora newly observed language.", "labels": [], "entities": []}, {"text": "The second motivation is that unsupervised statistical approaches take less amount of time for accomplishing a task without taking much external efforts and resources.", "labels": [], "entities": []}, {"text": "The third motivating factor is drawn from a linguistics point of view.", "labels": [], "entities": []}, {"text": "It has been observed that in the current world, 80% of the world's languages (almost 7000 total languages) are spoken by only 100,000 speakers or less.", "labels": [], "entities": []}, {"text": "It has also been observed that many natural languages are at the verge of extinction.", "labels": [], "entities": []}, {"text": "Many linguists fear that with the extinction of such languages, many cultures and valuable information will be lost.", "labels": [], "entities": []}, {"text": "They sug-298 gest taking help from any immediate quick procedures to restore those almost extinct language details (language documentation).", "labels": [], "entities": []}, {"text": "A fast unsupervised approach for morpheme segmentation can provide an essential equipment for language documentation for such languages.", "labels": [], "entities": [{"text": "morpheme segmentation", "start_pos": 33, "end_pos": 54, "type": "TASK", "confidence": 0.7481650710105896}]}], "datasetContent": [{"text": "The proposed method of morpheme segmentation was experimented on five languages -English, Bengali, Finnish, German and Turkish.", "labels": [], "entities": [{"text": "morpheme segmentation", "start_pos": 23, "end_pos": 44, "type": "TASK", "confidence": 0.814924955368042}]}, {"text": "For English, Turkish, German and Finnish, we used the Morpho-Challenge 1 datasets which provide both raw text corpora as well as gold-standard testsets.", "labels": [], "entities": [{"text": "Morpho-Challenge 1 datasets", "start_pos": 54, "end_pos": 81, "type": "DATASET", "confidence": 0.8960736989974976}]}, {"text": "The gold-standard datasets mostly contain multi-slot morpheme segmentation samples.", "labels": [], "entities": []}, {"text": "The datasets also come with evaluation results of a baseline system (Morfessor).", "labels": [], "entities": []}, {"text": "The Morpho-Challenge datasets' training data contains 617,297, 2,338,323, 2,928,030 and 878,036 distinct Turkish, German, Finnish and English words respectively.", "labels": [], "entities": [{"text": "Morpho-Challenge datasets' training data", "start_pos": 4, "end_pos": 44, "type": "DATASET", "confidence": 0.9510519802570343}]}, {"text": "The test sets contain 1,000 words for each of those four languages.", "labels": [], "entities": []}, {"text": "The Dataset also provides a perl script for evaluation on the gold-standard data.", "labels": [], "entities": []}, {"text": "For Bengali, we used a gold standard testset (containing 14,034 words) developed in-house and collected a raw corpus (containing 28,927 unique words) by crawling an online Bengali newspaper.", "labels": [], "entities": []}, {"text": "Unlike MorphoChallenge dataset, the Bengali gold-standard data mostly contain single-slot morpheme segmentation examples.", "labels": [], "entities": [{"text": "MorphoChallenge dataset", "start_pos": 7, "end_pos": 30, "type": "DATASET", "confidence": 0.8964514434337616}, {"text": "Bengali gold-standard data", "start_pos": 36, "end_pos": 62, "type": "DATASET", "confidence": 0.7278855542341868}]}, {"text": "The output generated by the system heavily depends on choosing a proper threshold value for JSAS which we determined using the Kneedle algorithm.", "labels": [], "entities": [{"text": "JSAS", "start_pos": 92, "end_pos": 96, "type": "DATASET", "confidence": 0.5846804976463318}]}, {"text": "graphically shows the JSAS score thresholding by Kneedle algorithm for the Bengali dataset.", "labels": [], "entities": [{"text": "JSAS score thresholding", "start_pos": 22, "end_pos": 45, "type": "METRIC", "confidence": 0.4993654092152913}, {"text": "Bengali dataset", "start_pos": 75, "end_pos": 90, "type": "DATASET", "confidence": 0.8211643099784851}]}, {"text": "System performance was evaluated with precision, recall and f-measure (F1-measure) and the evaluation results are reported in.", "labels": [], "entities": [{"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9997091889381409}, {"text": "recall", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.9995998740196228}, {"text": "f-measure", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9693957567214966}, {"text": "F1-measure", "start_pos": 71, "end_pos": 81, "type": "METRIC", "confidence": 0.982513964176178}]}, {"text": "We developed anew baseline model which is similar to the proposed model except that it considers IS baseline (a x ) = bf ax instead of transforming the branching factor through hyperbolic tangent function.", "labels": [], "entities": []}, {"text": "presents the performance of the newly constructed baseline (B), Morfessor baseline (MB), the proposed model (P) and the best results (Best) reported so far on this dataset 2 . The baseline model produces high recall, however, due to absence of a proper thresholding mechanism, it results in low precision and hence low F-measure.", "labels": [], "entities": [{"text": "Morfessor baseline (MB)", "start_pos": 64, "end_pos": 87, "type": "METRIC", "confidence": 0.7061466455459595}, {"text": "recall", "start_pos": 209, "end_pos": 215, "type": "METRIC", "confidence": 0.9990667700767517}, {"text": "precision", "start_pos": 295, "end_pos": 304, "type": "METRIC", "confidence": 0.998650848865509}, {"text": "F-measure", "start_pos": 319, "end_pos": 328, "type": "METRIC", "confidence": 0.9975718855857849}]}, {"text": "We observed that the proposed model shows much better results for singleslot morpheme segmentation compared to multislot morpheme segmentation.", "labels": [], "entities": [{"text": "singleslot morpheme segmentation", "start_pos": 66, "end_pos": 98, "type": "TASK", "confidence": 0.7054584821065267}, {"text": "multislot morpheme segmentation", "start_pos": 111, "end_pos": 142, "type": "TASK", "confidence": 0.6784312526384989}]}, {"text": "With the aforementioned set-up, the best performance was observed for Bengali (F-measure 0.783) and the lowest for Finnish (F-measure 0.575).", "labels": [], "entities": [{"text": "F-measure", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.9391302466392517}]}, {"text": "The proposed model outperformed the best results reported so far for English and German on this dataset.", "labels": [], "entities": []}, {"text": "Considering that our model is almost unsupervised and it does not require any resources other than a vocabulary, our model results are, overall, comparable with the best results reported on this dataset obtained with semi-supervised approaches.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Evaluation Results  Metric  System Bengali English Turkish Finnish German", "labels": [], "entities": [{"text": "Evaluation Results  Metric  System Bengali English Turkish Finnish German", "start_pos": 10, "end_pos": 83, "type": "DATASET", "confidence": 0.5941637489530776}]}]}