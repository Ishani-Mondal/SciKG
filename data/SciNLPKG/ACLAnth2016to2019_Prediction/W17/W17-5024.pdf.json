{"title": [{"text": "Can string kernels pass the test of time in Native Language Identification?", "labels": [], "entities": [{"text": "Native Language Identification", "start_pos": 44, "end_pos": 74, "type": "TASK", "confidence": 0.6026788353919983}]}], "abstractContent": [{"text": "We describe a machine learning approach for the 2017 shared task on Native Language Identification (NLI).", "labels": [], "entities": [{"text": "2017 shared task on Native Language Identification (NLI)", "start_pos": 48, "end_pos": 104, "type": "TASK", "confidence": 0.704788726568222}]}, {"text": "The proposed approach combines several kernels using multiple kernel learning.", "labels": [], "entities": []}, {"text": "While most of our kernels are based on character p-grams (also known as n-grams) extracted from essays or speech transcripts, we also use a kernel based on i-vectors, a low-dimensional representation of audio recordings, provided by the shared task organizers.", "labels": [], "entities": []}, {"text": "For the learning stage, we choose Kernel Discriminant Analysis (KDA) over Kernel Ridge Regression (KRR), because the former classifier obtains better results than the latter one on the development set.", "labels": [], "entities": []}, {"text": "In our previous work, we have used a similar machine learning approach to achieve state-of-the-art NLI results.", "labels": [], "entities": []}, {"text": "The goal of this paper is to demonstrate that our shallow and simple approach based on string kernels (with minor improvements) can pass the test of time and reach state-of-the-art performance in the 2017 NLI shared task, despite the recent advances in natural language processing.", "labels": [], "entities": []}, {"text": "We participated in all three tracks, in which the competitors were allowed to use only the essays (essay track), only the speech transcripts (speech track), or both (fusion track).", "labels": [], "entities": []}, {"text": "Using only the data provided by the organizers for training our models, we have reached a macro F 1 score of 86.95% in the closed essay track, a macro F 1 score of 87.55% in the closed speech track, and a macro F 1 score of 93.19% in the closed * The authors have equally contributed to this work.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 96, "end_pos": 105, "type": "METRIC", "confidence": 0.9137288530667623}, {"text": "macro F 1 score", "start_pos": 145, "end_pos": 160, "type": "METRIC", "confidence": 0.7831810116767883}, {"text": "macro F 1 score", "start_pos": 205, "end_pos": 220, "type": "METRIC", "confidence": 0.7631546258926392}]}, {"text": "With these scores, our team (UnibucKernel) ranked in the first group of teams in all three tracks, while attaining the best scores in the speech and the fusion tracks.", "labels": [], "entities": []}], "introductionContent": [{"text": "Native Language Identification (NLI) is the task of identifying the native language (L1) of a person, based on a sample of text or speech they have produced in a language (L2) other than their mother tongue.", "labels": [], "entities": [{"text": "Native Language Identification (NLI) is the task of identifying the native language (L1) of a person, based on a sample of text or speech they have produced in a language (L2) other than their mother tongue", "start_pos": 0, "end_pos": 206, "type": "Description", "confidence": 0.7374784024648888}]}, {"text": "This is an interesting sub-task in forensic linguistic applications such as plagiarism detection and authorship identification, where the native language of an author is just one piece of the puzzle (.", "labels": [], "entities": [{"text": "plagiarism detection", "start_pos": 76, "end_pos": 96, "type": "TASK", "confidence": 0.7346476912498474}, {"text": "authorship identification", "start_pos": 101, "end_pos": 126, "type": "TASK", "confidence": 0.8885426819324493}]}, {"text": "NLI can also play a key role in second language acquisition (SLA) applications where NLI techniques are used to identify language transfer patterns that help teachers and students focus feedback and learning on particular areas of interest (.", "labels": [], "entities": [{"text": "second language acquisition (SLA)", "start_pos": 32, "end_pos": 65, "type": "TASK", "confidence": 0.8289516369501749}]}, {"text": "organized the first NLI shared task, providing the participants written essays of non-native English learners.", "labels": [], "entities": []}, {"text": "In 2016, the Computational Paralinguistics Challenge () included a shared task on NLI based on the spoken response of nonnative English speakers.", "labels": [], "entities": []}, {"text": "The 2017 NLI shared task ( attempts to combine these approaches by including a written response (essay) and a spoken response (speech transcript and i-vector acoustic features) for each subject.", "labels": [], "entities": []}, {"text": "Our team (UnibucKernel) participated in all three tracks proposed by the organizers of the 2017 NLI shared task, in which the competitors were allowed to use only the essays (closed essay track), only the speech transcripts (closed speech track), or both modalities (closed fusion track).", "labels": [], "entities": []}, {"text": "Our approach in each track combines two or more kernels using multiple kernel learning.", "labels": [], "entities": []}, {"text": "The first kernel that we considered is the p-grams presence bits kernel 1 , which takes into account only the presence of p-grams instead of their frequency.", "labels": [], "entities": []}, {"text": "The second kernel is the (histogram) intersection string kernel 2 , which was first used in a text mining task by.", "labels": [], "entities": [{"text": "text mining task", "start_pos": 94, "end_pos": 110, "type": "TASK", "confidence": 0.8432483275731405}]}, {"text": "While these kernels are based on character p-grams extracted from essays or speech transcrips, we also use an RBF kernel) based on i-vectors), a lowdimensional representation of audio recordings, made available by the 2017 NLI shared task organizers (.", "labels": [], "entities": []}, {"text": "We have also considered squared RBF kernel versions of the string kernels and the kernel based on i-vectors.", "labels": [], "entities": []}, {"text": "We have taken into consideration two kernel classifiers) for the learning task, namely Kernel Ridge Regression (KRR) and Kernel Discriminant Analysis (KDA).", "labels": [], "entities": [{"text": "Kernel Discriminant Analysis (KDA", "start_pos": 121, "end_pos": 154, "type": "TASK", "confidence": 0.6867575705051422}]}, {"text": "Ina set of preliminary experiments performed on the development set, we found that KDA gives better results than KRR, which is consistent with our previous work (.", "labels": [], "entities": []}, {"text": "Therefore, we decided to submit results using just the KDA classifier.", "labels": [], "entities": [{"text": "KDA classifier", "start_pos": 55, "end_pos": 69, "type": "DATASET", "confidence": 0.8264600038528442}]}, {"text": "We have also tuned the range of p-grams for the string kernels.", "labels": [], "entities": []}, {"text": "Using only the data provided by the organizers for training our models, we have reached a weighted F 1 score of 86.95% in the essay track, a weighted F 1 score of 87.55% in the speech track, and a weighted F 1 score of 93.19% in the fusion track.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 99, "end_pos": 108, "type": "METRIC", "confidence": 0.9903006553649902}, {"text": "F 1 score", "start_pos": 150, "end_pos": 159, "type": "METRIC", "confidence": 0.98652716477712}, {"text": "F 1 score", "start_pos": 206, "end_pos": 215, "type": "METRIC", "confidence": 0.9906371235847473}]}, {"text": "The first time we used string kernels for NLI, we placed third in the 2013 NLI shared task (.", "labels": [], "entities": []}, {"text": "In 2014, we improved our method and reached state-of-the-art performance ().", "labels": [], "entities": []}, {"text": "More recently, we have shown that our method is language independent and robust to topic bias ( . However, with all the improvements since 2013, our method remained a simple and shallow approach.", "labels": [], "entities": []}, {"text": "In spite of its simplicity, the aim of this paper is to demonstrate that our approach can still achieve state-of-the-art NLI results, 4 years after its conception.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "Related work on native language identification and string kernels is presented in Section 2.", "labels": [], "entities": [{"text": "native language identification", "start_pos": 16, "end_pos": 46, "type": "TASK", "confidence": 0.6533841192722321}]}, {"text": "Section 3 presents We computed the p-grams presence bits kernel using the code available at http://string-kernels.herokuapp.com.", "labels": [], "entities": []}, {"text": "We computed the intersection string kernel using the code available at http://string-kernels.herokuapp.com.", "labels": [], "entities": []}, {"text": "the kernels that we used in our approach.", "labels": [], "entities": []}, {"text": "The learning methods used in the experiments are described in Section 4.", "labels": [], "entities": []}, {"text": "Details about the NLI experiments are provided in Section 5.", "labels": [], "entities": []}, {"text": "Finally, we draw conclusions and discuss future work in Section 6.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. We ob- serve that KDA yields better results for both the  blended p-grams presence bits kernel ( \u02c6  k", "labels": [], "entities": []}, {"text": " Table 3: Accuracy rates on the NLI test set obtained by KDA based on various kernels for the essay, the  speech and the fusion tracks. The best marco F 1 score in each track is highlighted in bold. The final rank  of each kernel combination in the 2017 NLI shared task is presented on the last column.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.992579996585846}, {"text": "NLI test set", "start_pos": 32, "end_pos": 44, "type": "DATASET", "confidence": 0.7982724110285441}, {"text": "KDA", "start_pos": 57, "end_pos": 60, "type": "DATASET", "confidence": 0.5130916833877563}, {"text": "marco F 1 score", "start_pos": 145, "end_pos": 160, "type": "METRIC", "confidence": 0.9054200053215027}]}, {"text": " Table 3. Both kernel combi- nations submitted to the essay track obtain equally  good results (86.95%). For the speech and the fu- sion tracks, the squared RBF kernels reach slightly  lower performance than the original kernels. The  best submission to the speech track is the KDA  classifier based on the sum of the presence bits  kernel ( \u02c6  k", "labels": [], "entities": []}]}