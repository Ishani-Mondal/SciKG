{"title": [{"text": "Tree as a Pivot: Syntactic Matching Methods in Pivot Translation", "labels": [], "entities": [{"text": "Pivot Translation", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.7244776487350464}]}], "abstractContent": [{"text": "Pivot translation is a useful method for translating between languages with little or no parallel data by utilizing parallel data in an intermediate language such as En-glish.", "labels": [], "entities": [{"text": "Pivot translation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8192894756793976}]}, {"text": "A popular approach for pivot translation used in phrase-based or tree-based translation models combines source-pivot and pivot-target translation models into a source-target model, as known as triangu-lation.", "labels": [], "entities": [{"text": "pivot translation", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.7670794725418091}]}, {"text": "However, this combination is based on the constituent words' surface forms and often produces incorrect source-target phrase pairs due to semantic ambiguity in the pivot language, and interlingual differences.", "labels": [], "entities": []}, {"text": "In this paper, we propose a approach for the triangulation using syntactic subtrees in the pivot language to distinguish pivot language words by their syntactic roles to avoid incorrect phrase combinations.", "labels": [], "entities": []}, {"text": "Experimental results on the United Nations Parallel Corpus show the proposed method gains in all tested combinations of language , up to 2.3 BLEU points.", "labels": [], "entities": [{"text": "United Nations Parallel Corpus", "start_pos": 28, "end_pos": 58, "type": "DATASET", "confidence": 0.9216806590557098}, {"text": "BLEU", "start_pos": 141, "end_pos": 145, "type": "METRIC", "confidence": 0.9991629123687744}]}], "introductionContent": [{"text": "In statistical machine translation (SMT), it is known that translation with models trained on larger parallel corpora can achieve greater accuracy.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 3, "end_pos": 40, "type": "TASK", "confidence": 0.8268820196390152}, {"text": "accuracy", "start_pos": 138, "end_pos": 146, "type": "METRIC", "confidence": 0.9933924078941345}]}, {"text": "Unfortunately, large bilingual corpora are not readily available for many language pairs, particularly those that do not include English.", "labels": [], "entities": []}, {"text": "One effective solution to overcome the scarceness of bilingual data is to introduce a pivot language for which paral- lel data with the source and target languages exists (de).", "labels": [], "entities": []}, {"text": "Among various methods using pivot languages, one popular and effective method is the triangulation method, which first combines sourcepivot and pivot-target translation models (TMs) into a source-target model, then translates using this combined model.", "labels": [], "entities": []}, {"text": "The procedure of triangulating two TMs into one has been examined for different frameworks of SMT and its effectiveness has been confirmed both in Phrase-Based SMT (PBMT) ( and in Hierarchical Phrase-Based SMT (Hiero).", "labels": [], "entities": [{"text": "SMT", "start_pos": 94, "end_pos": 97, "type": "TASK", "confidence": 0.9915956854820251}, {"text": "Phrase-Based SMT (PBMT)", "start_pos": 147, "end_pos": 170, "type": "TASK", "confidence": 0.756282752752304}, {"text": "Hierarchical Phrase-Based SMT (Hiero)", "start_pos": 180, "end_pos": 217, "type": "TASK", "confidence": 0.6673564116160074}]}, {"text": "However, word sense ambiguity and interlingual differences of word usage cause difficulty in accurately learning correspondences between source and target phrases, and thus the accuracy obtained by triangulated models lags behind that of models trained on direct parallel corpora.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 177, "end_pos": 185, "type": "METRIC", "confidence": 0.9990895986557007}]}, {"text": "In the triangulation method, source-pivot and pivot-target phrase pairs are connected as a sourcetarget phrase pair when a common pivot-side phrase exists.", "labels": [], "entities": []}, {"text": "In (a), we show an example of standard triangulation on Hiero TMs that combines hierarchical rules of phrase pairs by matching pivot phrases with equivalent surface forms.", "labels": [], "entities": []}, {"text": "This example also demonstrates problems of ambiguity: the English word \"record\" can correspond to several different parts-of-speech according to the context.", "labels": [], "entities": []}, {"text": "More broadly, phrases including this word also have different possible grammatical structures, but it is impossible to uniquely identify this structure unless information about the surrounding context is given.", "labels": [], "entities": []}, {"text": "This varying syntactic structure will affect translation.", "labels": [], "entities": [{"text": "translation", "start_pos": 45, "end_pos": 56, "type": "TASK", "confidence": 0.960288941860199}]}, {"text": "For example, the French verb \"enregistrer\" corresponds to the English verb \"record\", but the French noun \"dossier\" also corresponds to \"record\" -as a noun.", "labels": [], "entities": []}, {"text": "As a more extreme example, Chinese is a languages that does not have inflections according to the part-of-speech of the word.", "labels": [], "entities": []}, {"text": "As a result, even in the contexts where \"record\" is used with different parts-of-speech, the Chinese word \"\" will be used, although the word order will change.", "labels": [], "entities": []}, {"text": "These facts might result in an incorrect connection of \" enregistrer\" and \" [X1] \" even though proper correspondence of \" enregistrer\" and \" dossier [X2]\" would be \" [X2]\" and \" [X1] \".", "labels": [], "entities": []}, {"text": "Hence a superficial phrase matching method based solely on the surface form of the pivot will often combine incorrect phrase pairs, causing translation errors if their translation scores are estimated to be higher than the proper correspondences.", "labels": [], "entities": [{"text": "phrase matching", "start_pos": 20, "end_pos": 35, "type": "TASK", "confidence": 0.7608712613582611}]}, {"text": "Given this background, we hypothesize that disambiguation of these cases would be easier if the necessary syntactic information such as phrase structures are considered during pivoting.", "labels": [], "entities": []}, {"text": "To incorporate this intuition into our models, we propose a method that considers syntactic information of the pivot phrase, as shown in.", "labels": [], "entities": []}, {"text": "In this way, the model will distinguish translation rules extracted in contexts in which the English symbol string \" record\" behaves as a verbal phrase, from contexts in which the same string acts as nominal phrase.", "labels": [], "entities": []}, {"text": "Specifically, we propose a method based on Synchronous Context-Free Grammars (SCFGs), which are widely used in tree-based machine translation frameworks ( \u00a72).", "labels": [], "entities": [{"text": "machine translation frameworks", "start_pos": 122, "end_pos": 152, "type": "TASK", "confidence": 0.7872750957806905}]}, {"text": "After describing the baseline triangulation method ( \u00a73), which uses only the surface forms for performing triangulation, we propose two methods for triangulation based on syntactic matching ( \u00a74).", "labels": [], "entities": []}, {"text": "The first places a hard restriction on exact matching of parse trees ( \u00a74.1) included in translation rules, while the second places a softer restriction allowing partial matches ( \u00a74.2).", "labels": [], "entities": []}, {"text": "To investigate the effect of our proposed method on pivot translation quality, we perform experiments of pivot translation on the United Nations Parallel Corpus (, which shows that our method indeed provide significant gains inaccuracy (of up to 2.3 BLEU points), in almost all combinations of 5 languages with English as a pivot language ( \u00a75).", "labels": [], "entities": [{"text": "pivot translation", "start_pos": 105, "end_pos": 122, "type": "TASK", "confidence": 0.7458301186561584}, {"text": "United Nations Parallel Corpus", "start_pos": 130, "end_pos": 160, "type": "DATASET", "confidence": 0.9292168468236923}, {"text": "BLEU", "start_pos": 250, "end_pos": 254, "type": "METRIC", "confidence": 0.9985195994377136}]}, {"text": "In addition, as an auxiliary result, we compare pivot translation using the proposed method with zero-shot neural machine translation, and find that triangulation of symbolic translation models still significantly outperforms neural MT in the zero-resource scenario.", "labels": [], "entities": [{"text": "pivot translation", "start_pos": 48, "end_pos": 65, "type": "TASK", "confidence": 0.7817029356956482}, {"text": "zero-shot neural machine translation", "start_pos": 97, "end_pos": 133, "type": "TASK", "confidence": 0.676168255507946}]}], "datasetContent": [{"text": "To investigate the effect of our proposed approach, we evaluate the translation accuracy through pivot translation experiments on the United Nations Parallel Corpus (UN6Way) (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9173314571380615}, {"text": "United Nations Parallel Corpus (UN6Way)", "start_pos": 134, "end_pos": 173, "type": "DATASET", "confidence": 0.9257604990686689}]}, {"text": "UN6Way is a line-aligned multilingual parallel corpus that includes data in English (En), Arabic (Ar), Spanish (Es), French (Fr), Russian (Ru) and Chinese (Zh), covering different families of languages.", "labels": [], "entities": [{"text": "UN6Way", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9409833550453186}]}, {"text": "It contains more than 11M sentences for each language pair, and is therefore suitable for multilingual translation tasks such as pivot translation.", "labels": [], "entities": [{"text": "pivot translation", "start_pos": 129, "end_pos": 146, "type": "TASK", "confidence": 0.8066582977771759}]}, {"text": "In these experiments, we fixed English as the pivot language considering that it is the language most frequently used as a pivot language.", "labels": [], "entities": []}, {"text": "This has the positive side-effect that accurate phrase structure parsers are available in the pivot language, which is good for our proposed method.", "labels": [], "entities": [{"text": "phrase structure parsers", "start_pos": 48, "end_pos": 72, "type": "TASK", "confidence": 0.696570485830307}]}, {"text": "We perform pivot translation on all the combinations of the other 5 languages, and compared the accuracy of each method.", "labels": [], "entities": [{"text": "pivot translation", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.6516362428665161}, {"text": "accuracy", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.9996232986450195}]}, {"text": "For tokenization, we adopt SentencePiece, an unsupervised text tokenizer and detokenizer, that is although designed mainly for neural MT, we confirmed that it also helps to reduce training time and even improves translation accuracy in our Hiero model as well.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 4, "end_pos": 16, "type": "TASK", "confidence": 0.9704729318618774}, {"text": "MT", "start_pos": 134, "end_pos": 136, "type": "TASK", "confidence": 0.859247624874115}, {"text": "translation", "start_pos": 212, "end_pos": 223, "type": "TASK", "confidence": 0.955227255821228}, {"text": "accuracy", "start_pos": 224, "end_pos": 232, "type": "METRIC", "confidence": 0.7827997803688049}]}, {"text": "We first trained a single shared tokenization model by feeding a total of 10M sentences from the data of all the 6 languages, set the maximum shared vocabulary size to be 16k, and tokenized all available text with the trained model.", "labels": [], "entities": []}, {"text": "We used English raw text without tokenization for phrase structure analysis and for training Hiero and T2S TMs on the pivot side.", "labels": [], "entities": [{"text": "phrase structure analysis", "start_pos": 50, "end_pos": 75, "type": "TASK", "confidence": 0.9178145130475363}, {"text": "Hiero", "start_pos": 93, "end_pos": 98, "type": "DATASET", "confidence": 0.8053818941116333}]}, {"text": "To generate parse trees, we used the Ckylark PCFG-LA parser (, and filtered out lines of length over 60 tokens from all the parallel data to ensure accuracy of parsing and alignment.", "labels": [], "entities": [{"text": "Ckylark PCFG-LA parser", "start_pos": 37, "end_pos": 59, "type": "DATASET", "confidence": 0.8607626756032308}, {"text": "accuracy", "start_pos": 148, "end_pos": 156, "type": "METRIC", "confidence": 0.9988049268722534}]}, {"text": "Since Hiero requires a large amount of computational resources for training and decoding, so we decided not to use all available training data but first 1M lines for training each TM.", "labels": [], "entities": [{"text": "Hiero", "start_pos": 6, "end_pos": 11, "type": "DATASET", "confidence": 0.8715817928314209}]}, {"text": "As a decoder, we use Travatar, and train Hiero and T2S TMs with its rule extraction code.", "labels": [], "entities": [{"text": "Hiero", "start_pos": 41, "end_pos": 46, "type": "DATASET", "confidence": 0.8711504340171814}]}, {"text": "We train 5-gram LMs over the target side of the same parallel data used for training TMs using KenLM.", "labels": [], "entities": [{"text": "KenLM", "start_pos": 95, "end_pos": 100, "type": "DATASET", "confidence": 0.8542224764823914}]}, {"text": "For testing and parameter tuning, we used the first 1,000 lines of the 4,000 lines test and dev sets respectively.", "labels": [], "entities": [{"text": "parameter tuning", "start_pos": 16, "end_pos": 32, "type": "TASK", "confidence": 0.7043205797672272}]}, {"text": "For the evaluation of translation results, we first detokenize with the SentencePiece model and re-tokenized with the tokenizer of the Moses toolkit () for Arabic, Spanish, French and Russian and re-tokenized Chinese text with Kytea tokenizer, then evaluated using case-sensitive BLEU-4 ().", "labels": [], "entities": [{"text": "BLEU-4", "start_pos": 280, "end_pos": 286, "type": "METRIC", "confidence": 0.9824108481407166}]}, {"text": "We evaluate 6 translation methods:  The result of experiments using all combinations of pivot translation tasks for 5 languages via English is shown in.", "labels": [], "entities": []}, {"text": "From the results, we can see that the proposed partial matching method of pivot subtrees in triangulation outperforms the standard triangulation method for all language pairs and achieves higher or almost equal scores than proposed exact matching method.", "labels": [], "entities": []}, {"text": "The exact matching method also outperforms the standard triangulation method in the majority of the language pairs, but has a lesser improvement than partial matching method.", "labels": [], "entities": [{"text": "exact matching", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.7457705736160278}]}, {"text": "In we show the comparison of coverage of each proposed triangulated method.", "labels": [], "entities": []}, {"text": "From this table, we can see that the exact matching method reduces several percent in number of unique phrases while the partial matching method keeps the same coverage with surfaceform matching.", "labels": [], "entities": []}, {"text": "We can consider that it is one of the reasons of the difference in improvement stability between the partial and exact matching methods.", "labels": [], "entities": []}, {"text": "We show an example of a translated sentences for which pivot-side ambiguity is resolved in the the syntactic matching methods:    causing incorrect re-ordering of phrases followed by steps of incorrect word selection.", "labels": [], "entities": []}, {"text": "On the other hand, derivation in Tri.TreeExact and Tri.TreePartial uses rule X \u2192 \u27e8_tous _les X 0 _parties, _todos X 0 _Partes\u27e9 6 synthesized from T2S rules with common pivot subtree (NP (DT all) (NP' X NNP (NNS parties)).", "labels": [], "entities": []}, {"text": "We can confirm that the derivation improves word-selection and word-reordering by using this rule.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison of each triangulation methods. Bold face indicates the highest BLEU score in pivot  translation, and daggers indicate statistically significant gains over Tri. Hiero ( \u2020 : p < 0.05,  \u2021 : p < 0.01).", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 84, "end_pos": 94, "type": "METRIC", "confidence": 0.9826865494251251}, {"text": "Tri. Hiero", "start_pos": 176, "end_pos": 186, "type": "DATASET", "confidence": 0.8264753421147665}]}, {"text": " Table 2: Comparison of rule table coverage in proposed triangulation methods.", "labels": [], "entities": []}, {"text": " Table 3: Main parameters of NMT training", "labels": [], "entities": [{"text": "NMT training", "start_pos": 29, "end_pos": 41, "type": "TASK", "confidence": 0.9659934639930725}]}]}