{"title": [], "abstractContent": [{"text": "This paper describes the Neural Machine Translation systems of Xiamen University for the translation tasks of WMT 17.", "labels": [], "entities": [{"text": "Neural Machine Translation", "start_pos": 25, "end_pos": 51, "type": "TASK", "confidence": 0.6799480517705282}, {"text": "WMT 17", "start_pos": 110, "end_pos": 116, "type": "TASK", "confidence": 0.5688060820102692}]}, {"text": "Our systems are based on the Encoder-Decoder framework with attention.", "labels": [], "entities": []}, {"text": "We participated in three directions of shared news translation tasks: English\u2192German and Chinese\u2194English.", "labels": [], "entities": [{"text": "shared news translation tasks", "start_pos": 39, "end_pos": 68, "type": "TASK", "confidence": 0.8305638134479523}]}, {"text": "We experimented with deep architectures, different segmentation models, synthetic training data and target-bidirectional translation models.", "labels": [], "entities": []}, {"text": "Experiments show that all methods can give substantial improvements.", "labels": [], "entities": []}], "introductionContent": [{"text": "Neural Machine Translation (NMT) ( has achieved great success in recent years and obtained state-of-the-art results on various language pairs ().", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7986270089944204}]}, {"text": "This paper describes the NMT systems of Xiamen University (XMU) for the WMT 17.", "labels": [], "entities": [{"text": "WMT 17", "start_pos": 72, "end_pos": 78, "type": "DATASET", "confidence": 0.7206027209758759}]}, {"text": "We participated in three directions of shared news translation tasks: English\u2192German and Chinese\u2194English.", "labels": [], "entities": [{"text": "shared news translation tasks", "start_pos": 39, "end_pos": 68, "type": "TASK", "confidence": 0.8305638134479523}]}, {"text": "We use two different NMTs for shared news translation tasks: \u2022 MININMT: A deep NMT system () with a simple architecture.", "labels": [], "entities": [{"text": "shared news translation", "start_pos": 30, "end_pos": 53, "type": "TASK", "confidence": 0.7530268232027689}]}, {"text": "The decoder is a stacked Long Short-Term Memory (LSTM)) with 8 layers.", "labels": [], "entities": []}, {"text": "The encoder has two variants.", "labels": [], "entities": []}, {"text": "For English-German translation, we use an interleaved bidirectional encoder with 2 columns.", "labels": [], "entities": []}, {"text": "Each column consists of 4 LSTMs.", "labels": [], "entities": []}, {"text": "For Chinese-English translation, we use a stacked bidirectional encoder with 8 layers.", "labels": [], "entities": []}, {"text": "\u2022 DL4MT: Our reimplementation of dl4mt-tutorial 1 with minor changes.", "labels": [], "entities": []}, {"text": "We also use a modified version of AmuNMT C++ decoder 2 for decoding.", "labels": [], "entities": [{"text": "AmuNMT C++ decoder 2", "start_pos": 34, "end_pos": 54, "type": "DATASET", "confidence": 0.9216491460800171}]}, {"text": "This system is used in the English-Chinese translation task.", "labels": [], "entities": [{"text": "English-Chinese translation task", "start_pos": 27, "end_pos": 59, "type": "TASK", "confidence": 0.6924601296583811}]}, {"text": "We use both Byte Pair Encoding (BPE) () and mixed word/character segmentation () to achieve open-vocabulary translation.", "labels": [], "entities": [{"text": "Byte Pair Encoding (BPE)", "start_pos": 12, "end_pos": 36, "type": "TASK", "confidence": 0.6546802669763565}, {"text": "mixed word/character segmentation", "start_pos": 44, "end_pos": 77, "type": "TASK", "confidence": 0.6743867456912994}, {"text": "open-vocabulary translation", "start_pos": 92, "end_pos": 119, "type": "TASK", "confidence": 0.7130758166313171}]}, {"text": "Back-translation method) is applied to make use of monolingual data.", "labels": [], "entities": []}, {"text": "We also use target-bidiretional translation models to alleviate the label bias problem ().", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows: Section 2 describes the architecture of MIN-INMT.", "labels": [], "entities": [{"text": "MIN-INMT", "start_pos": 93, "end_pos": 101, "type": "DATASET", "confidence": 0.6431216597557068}]}, {"text": "Section 3 describes all experimental features used in WMT 17 shared translation tasks.", "labels": [], "entities": [{"text": "WMT 17 shared translation tasks", "start_pos": 54, "end_pos": 85, "type": "TASK", "confidence": 0.8941075921058654}]}, {"text": "Section 4 shows the results of our experiments.", "labels": [], "entities": []}, {"text": "Section 5 shows the results of shared translation task.", "labels": [], "entities": [{"text": "shared translation task", "start_pos": 31, "end_pos": 54, "type": "TASK", "confidence": 0.6495555440584818}]}, {"text": "Finally, we conclude in section 6.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Chinese-English translation results on  newstest2017.", "labels": [], "entities": [{"text": "Chinese-English translation", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.5421341806650162}, {"text": "newstest2017", "start_pos": 50, "end_pos": 62, "type": "DATASET", "confidence": 0.9707001447677612}]}, {"text": " Table 3: English-Chinese translation results on  newstest2017.", "labels": [], "entities": [{"text": "English-Chinese translation", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.5588178187608719}, {"text": "newstest2017", "start_pos": 50, "end_pos": 62, "type": "DATASET", "confidence": 0.9734511375427246}]}, {"text": " Table 4: Automatic (BLEU) and human ranking  of our submitted systems at WMT17 shared news  translation task.", "labels": [], "entities": [{"text": "Automatic (BLEU)", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.8267982304096222}, {"text": "WMT17 shared news  translation task", "start_pos": 74, "end_pos": 109, "type": "TASK", "confidence": 0.8564138174057007}]}]}