{"title": [{"text": "Inferring Narrative Causality between Event Pairs in Films", "labels": [], "entities": [{"text": "Inferring Narrative Causality between Event Pairs", "start_pos": 0, "end_pos": 49, "type": "TASK", "confidence": 0.8072530627250671}]}], "abstractContent": [{"text": "To understand narrative, humans draw inferences about the underlying relations between narrative events.", "labels": [], "entities": []}, {"text": "Cognitive theories of narrative understanding define these inferences as four different types of causality, that include pairs of events A, B where A physically causes B (X drop, X break), to pairs of events where A causes emotional state B (Y saw X, Y felt fear).", "labels": [], "entities": [{"text": "narrative understanding", "start_pos": 22, "end_pos": 45, "type": "TASK", "confidence": 0.7825672328472137}]}, {"text": "Previous work on learning narrative relations from text has either focused on \"strict\" physical causality, or has been vague about what relation is being learned.", "labels": [], "entities": []}, {"text": "This paper learns pairs of causal events from a corpus of film scene descriptions which are action rich and tend to be told in chronological order.", "labels": [], "entities": []}, {"text": "We show that event pairs induced using our methods are of high quality and are judged to have a stronger causal relation than event pairs from Rel-grams.", "labels": [], "entities": []}], "introductionContent": [{"text": "Telling and understanding stories is a central part of human experience, and many types of human communication involve narrative structures.", "labels": [], "entities": [{"text": "Telling and understanding stories", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8540799915790558}]}, {"text": "Theories of narrative posit that NARRATIVE CAUSAL-ITY underlies human understanding of a narrative ().", "labels": [], "entities": []}, {"text": "However previous computational work on narrative schemas, scripts or event schemas learn \"collections of events that tend to co-occur\", rather than causal relations between events (.", "labels": [], "entities": []}, {"text": "Another limitation of previous work is that it has mostly been applied to newswire, limiting what is learned to relations between newsworthy events, rather than everyday events (.", "labels": [], "entities": []}, {"text": "Our focus here is on NARRATIVE CAUSAL-ITY (; Van den Broek, 1990), the four different relations posited by narrative theories to underly narrative coherence: \u2022 PHYSICAL: Event A physically causes event B to happen \u2022 MOTIVATIONAL: Event A happens with B as a motivation \u2022 PSYCHOLOGICAL: Event A brings about emotions (expressed in event B) \u2022 ENABLING: Event A creates a state or condition for B to happen.", "labels": [], "entities": [{"text": "PHYSICAL", "start_pos": 160, "end_pos": 168, "type": "METRIC", "confidence": 0.9295539259910583}, {"text": "ENABLING", "start_pos": 341, "end_pos": 349, "type": "METRIC", "confidence": 0.8848936557769775}]}, {"text": "Previous work on learning causal relations has primarily focused on physical causality (, while our aim is to learn event pairs manifesting all types of narrative causality, and test their generality as a source of causal knowledge.", "labels": [], "entities": []}, {"text": "We posit that film scene descriptions area good resource for learning narrative causality because they are: (1) action rich; (2) about everyday events; and (3) told in temporal order, providing a primary cue to causality.", "labels": [], "entities": []}, {"text": "Film scenes contain many descriptions encoding PHYSICAL CAUSALITY, e.g. in, Scene 1, Frodo grabs Pippin's sleeve, causing Pippin to spill his beer (grab -spill).", "labels": [], "entities": [{"text": "PHYSICAL CAUSALITY", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.4478812962770462}]}, {"text": "Pippin then pushes Frodo away, causing Frodo to stumble backwards and fall to the floor (push -stumble, stumble -fall, and push -fall).", "labels": [], "entities": []}, {"text": "But they also contain all other types of narrative causality: in Scene 2, Gandalf has to stoop, because he wants to avoid hitting his head on the low ceiling (stoop -avoid: MOTIVA-TIONAL).", "labels": [], "entities": [{"text": "MOTIVA-TIONAL", "start_pos": 173, "end_pos": 186, "type": "METRIC", "confidence": 0.8187568187713623}]}, {"text": "He then looks around, and enjoys the result of looking: the familiarity of Bag End (lookenjoy: PSYCHOLOGICAL).", "labels": [], "entities": [{"text": "Bag End", "start_pos": 75, "end_pos": 82, "type": "DATASET", "confidence": 0.8900316953659058}]}, {"text": "He turns, which causes  This paper learns causal pairs from a corpus of 955 films.", "labels": [], "entities": []}, {"text": "Because previous work shows that more specific, detailed causal relations can be learned from topic-sorted corpora (, we explore differences in learning between genres of film, positing e.g. that horror films may feature very different types of events than comedies.", "labels": [], "entities": []}, {"text": "We also test the quality of what is learned when we train on genre specific texts vs. the whole collection.", "labels": [], "entities": []}, {"text": "Our results show that: \u2022 human judges can distinguish between strong and weakly causal event pairs induced using our method (Section 3.1); 1 Gandalf did not turn in order to knock, which would have been MOTIVATIONAL.", "labels": [], "entities": [{"text": "MOTIVATIONAL", "start_pos": 203, "end_pos": 215, "type": "METRIC", "confidence": 0.9611501693725586}]}, {"text": "Nor was it entailed that turning would cause knocking, which would have been PHYSICAL, because he clearly could have missed hitting his head if he had been more careful.", "labels": [], "entities": [{"text": "knocking", "start_pos": 45, "end_pos": 53, "type": "TASK", "confidence": 0.9724064469337463}, {"text": "PHYSICAL", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9914616346359253}]}, {"text": "\u2022 our strongly causal event pairs are rated as more likely to be causal than those provided by the Rel-gram corpus (Balasubramanian et al., 2013) (Section 3.2); \u2022 human judges can recognize different types of narrative causality (Section 3.3); \u2022 using both whole-corpus and genre-specific methods yields similar results for quality, despite the smaller size of the genre-specific subcorpora.", "labels": [], "entities": [{"text": "Rel-gram corpus", "start_pos": 99, "end_pos": 114, "type": "DATASET", "confidence": 0.9280350506305695}]}, {"text": "Moreover, the genre-specific method learns some event pairs that are different than whole corpus event-pairs, while still being high-quality.", "labels": [], "entities": []}, {"text": "(Section 3.4); We explain our method in Section 2, and then present experimental results in Section 3.", "labels": [], "entities": []}, {"text": "We leave a more detailed discussion of related work until Section 4 when we can compare it more directly with our own.", "labels": [], "entities": []}], "datasetContent": [{"text": "We estimate the likelihood of a narrative causality relation between events in film scenes.", "labels": [], "entities": []}, {"text": "We posit that human judgments are the best way to evaluate the quality of the induced event pairs, as opposed to automatic measures such as Narrative Cloze, which assume that the event pairs in a particular instance of text can be used as held-out test data.", "labels": [], "entities": []}, {"text": "Our first experiment tests whether event pairs with high CPC scores are more likely to have a narrative causality relation.", "labels": [], "entities": []}, {"text": "Our second experiment compares pairs with high CPC scores with their corresponding top Rel-gram pairs.", "labels": [], "entities": []}, {"text": "Our third experiment tests whether annotators can distinguish narrative causality types.", "labels": [], "entities": []}, {"text": "Our final experiment compares the quality and type of causal pairs learned on a per genre basis, vs. those learned on the whole film corpus.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Distribution of Films By Genre.", "labels": [], "entities": [{"text": "Distribution of Films", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.8673182328542074}]}, {"text": " Table 2: Narratively Causal Pairs where all 5 annotators selected the High CPC pair.", "labels": [], "entities": []}, {"text": " Table 3: Percentages of high pairs that receive ma- jority vote results by genre.", "labels": [], "entities": []}, {"text": " Table 6: Event pairs with Highest CPC scores from Fantasy, Action, Sci-Fi and Thriller genres.", "labels": [], "entities": []}, {"text": " Table 7: Event pairs unique to Fantasy, Sci-Fi, Horror, Mystery, Thriller genres and all films.", "labels": [], "entities": []}, {"text": " Table 8: Overlap in learned pairs among the most  distinct genres (Fantasy, Sci-Fi, Horror, Mystery  and Thriller) vs. all films (All).", "labels": [], "entities": []}]}