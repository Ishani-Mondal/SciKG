{"title": [{"text": "Identifying Effective Translations for Cross-lingual Arabic-to-English User-generated Speech Search", "labels": [], "entities": [{"text": "Identifying Effective Translations", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.9047209819157919}, {"text": "Cross-lingual Arabic-to-English User-generated Speech Search", "start_pos": 39, "end_pos": 99, "type": "TASK", "confidence": 0.5517549395561219}]}], "abstractContent": [{"text": "Cross Language Information Retrieval (CLIR) systems area valuable tool to enable speakers of one language to search for content of interest expressed in a different language.", "labels": [], "entities": [{"text": "Cross Language Information Retrieval (CLIR)", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.7514377960136959}]}, {"text": "A group for whom this is of particular interest is bilingual Arabic speakers who wish to search for English language content using information needs expressed in Arabic queries.", "labels": [], "entities": []}, {"text": "A key challenge in CLIR is crossing the language barrier between the query and the documents.", "labels": [], "entities": []}, {"text": "The most common approach to bridging this gap is automated query translation, which can be unreliable for vague or short queries.", "labels": [], "entities": [{"text": "query translation", "start_pos": 59, "end_pos": 76, "type": "TASK", "confidence": 0.7233872264623642}]}, {"text": "In this work, we examine the potential for improving CLIR effectiveness by predicting the translation effectiveness using Query Performance Prediction (QPP) techniques.", "labels": [], "entities": []}, {"text": "We propose a novel QPP method to estimate the quality of translation for an Arabic-Engish Cross-lingual User-generated Speech Search (CLUGS) task.", "labels": [], "entities": []}, {"text": "We present an empirical evaluation that demonstrates the quality of our method on alternative translation outputs extracted from an Arabic-to-English Machine Translation system developed for this task.", "labels": [], "entities": [{"text": "Arabic-to-English Machine Translation", "start_pos": 132, "end_pos": 169, "type": "TASK", "confidence": 0.6550693015257517}]}, {"text": "Finally , we show how this framework can be integrated in CLUGS to find relevant translations for improved retrieval performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "The growing archives of online digital content are increasingly diverse in style, media and the language used.", "labels": [], "entities": []}, {"text": "Within this content the balance between use of languages is very uneven.", "labels": [], "entities": []}, {"text": "An important case of this effect is Arabic multimedia content where the amount of content available is proportionally very small.", "labels": [], "entities": []}, {"text": "This results in a significant demand from bilingual Arabic speakers to access information in other languages, most notably English.", "labels": [], "entities": []}, {"text": "Cross Language Information Retrieval (CLIR) is an effective tool to bridge the language barrier between user search queries in one language and the target documents in another language.", "labels": [], "entities": [{"text": "Cross Language Information Retrieval (CLIR)", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.7594588824680873}]}, {"text": "The simplest and most commonly adopted approach in CLIR is to use machine translation (MT) to translate the user's query.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 66, "end_pos": 90, "type": "TASK", "confidence": 0.781136417388916}]}, {"text": "In most cases, MT is used as a black box as an input stage to an otherwise unchanged monolingual search system Many different MT systems have been studied in CLIR research for different tasks, e.g. ().", "labels": [], "entities": []}, {"text": "However, no single MT system has been reported to be effective for all CLIR tasks.", "labels": [], "entities": [{"text": "MT", "start_pos": 19, "end_pos": 21, "type": "TASK", "confidence": 0.9788340926170349}]}, {"text": "The effectiveness of an MT system for CLIR is primarily evaluated by examining the retrieval quality associated with the translated queries.", "labels": [], "entities": [{"text": "MT", "start_pos": 24, "end_pos": 26, "type": "TASK", "confidence": 0.9796205163002014}]}, {"text": "We follow this practice in this paper, by considering translation quality in terms of measured IR performance on an experimental test collection.", "labels": [], "entities": [{"text": "translation", "start_pos": 54, "end_pos": 65, "type": "TASK", "confidence": 0.9586206078529358}]}, {"text": "We investigation concentrates on a cross-lingual user-generated speech search (CLUGS) task (.", "labels": [], "entities": [{"text": "cross-lingual user-generated speech search (CLUGS) task", "start_pos": 35, "end_pos": 90, "type": "TASK", "confidence": 0.6864982172846794}]}, {"text": "In this work, we propose a prediction framework that utilises Query Performance Prediction (QPP) methods to estimate expected IR performance for specific query translation based both on the translated query itself and the output of the translation process.", "labels": [], "entities": []}, {"text": "As part of our investigation we explore the use of QPP to select from an N-best list of alternative translations for q query generated by an statistical MT systems.", "labels": [], "entities": []}, {"text": "In the next section we give some background and describe the motivation behind our CLUGS task.", "labels": [], "entities": [{"text": "CLUGS task", "start_pos": 83, "end_pos": 93, "type": "TASK", "confidence": 0.6911352872848511}]}, {"text": "Section 3 gives an overview of the QPP approaches that we study in this investigation.", "labels": [], "entities": []}, {"text": "Section 4 introduces our proposed prediction framework for CLUGS.", "labels": [], "entities": [{"text": "CLUGS", "start_pos": 59, "end_pos": 64, "type": "DATASET", "confidence": 0.8679941296577454}]}, {"text": "Section 5 outlines our experimental settings.", "labels": [], "entities": []}, {"text": "Section 6 evaluates the proposed framework and section 7 shows this approach can indeed be utilised for finding relevant translations in CLUGS.", "labels": [], "entities": [{"text": "CLUGS", "start_pos": 137, "end_pos": 142, "type": "DATASET", "confidence": 0.9201671481132507}]}, {"text": "Section 8 concludes, together with some avenues for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to evaluate QPP for our CLUGS task we configured three modules as follows.", "labels": [], "entities": []}, {"text": "A CLIR system, an MT system to generate the N-best translations, and a QPP system to parse each query candidate of the n-best list and assign a prediction value to it.", "labels": [], "entities": []}, {"text": "The CLUGS task is similar to the one described in ().", "labels": [], "entities": []}, {"text": "The task is based on the blip1000 collection which contains 14,838 transcripts automatically extracted using an ASR system from videos which were uploaded to a videosharing website by 2,237 different uploaders, covering a 25 different topics ().", "labels": [], "entities": [{"text": "blip1000 collection", "start_pos": 25, "end_pos": 44, "type": "DATASET", "confidence": 0.8395402431488037}]}, {"text": "For the query topic set, we use a modified monolingual adhoc version of the 60 different original English topics developed within the MediaEval 2012 Search and Hyperlinking task which was developed by . To setup the CLIR system, similar to the procedure adopted in our earlier investigation (2015), we used two native Arabic (AR) speakers who are also fluent on English (EN) to write their equivalent versions of the queries in Arabic for each of these EN topics.", "labels": [], "entities": [{"text": "MediaEval 2012 Search", "start_pos": 134, "end_pos": 155, "type": "DATASET", "confidence": 0.8787761131922404}]}, {"text": "We configured and trained an AR-to-EN MT system to translate each AR query to EN.", "labels": [], "entities": []}, {"text": "Our MT system is a phrase-based (, that is developed using the Moses Statistical Machine Translation (SMT) toolkit (.", "labels": [], "entities": [{"text": "MT", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.9661383032798767}, {"text": "Moses Statistical Machine Translation (SMT)", "start_pos": 63, "end_pos": 106, "type": "TASK", "confidence": 0.790543624332973}]}, {"text": "Word alignments in both directions were calculated using a multi-threaded version of the GIZA++ 6 tool (.", "labels": [], "entities": [{"text": "Word alignments", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.6569981127977371}, {"text": "GIZA++ 6 tool", "start_pos": 89, "end_pos": 102, "type": "DATASET", "confidence": 0.8662976324558258}]}, {"text": "The parameters of our MT system were tuned on a development corpus using Minimum Error Rate Training.", "labels": [], "entities": [{"text": "MT", "start_pos": 22, "end_pos": 24, "type": "TASK", "confidence": 0.9920605421066284}, {"text": "Minimum Error Rate Training", "start_pos": 73, "end_pos": 100, "type": "METRIC", "confidence": 0.6787892580032349}]}, {"text": "The AR-to-En MT system was trained using the bilingual training corpora listed in  We extracted the top 100 translations list for each query generated by the MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 13, "end_pos": 15, "type": "TASK", "confidence": 0.6500314474105835}, {"text": "MT", "start_pos": 158, "end_pos": 160, "type": "TASK", "confidence": 0.9576665163040161}]}, {"text": "The overall number of query candidates generated by was 5,863 with an average of over 90 different translations per query.", "labels": [], "entities": []}, {"text": "These queries were used in searching the EN ASR transcripts extracted from the blip1000 collection.", "labels": [], "entities": [{"text": "EN ASR transcripts extracted from the blip1000 collection", "start_pos": 41, "end_pos": 98, "type": "DATASET", "confidence": 0.7961100116372108}]}, {"text": "The Terrier retrieval platform 7 was used as the IR component of our experimental setup.", "labels": [], "entities": [{"text": "Terrier retrieval", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.6593790948390961}, {"text": "IR", "start_pos": 49, "end_pos": 51, "type": "TASK", "confidence": 0.8414914011955261}]}, {"text": "Stop words were removed based on the standard Terrier list, and stemming performed using the Terrier implementation of Porter stemming.", "labels": [], "entities": [{"text": "Terrier list", "start_pos": 46, "end_pos": 58, "type": "DATASET", "confidence": 0.8374241888523102}, {"text": "Porter stemming", "start_pos": 119, "end_pos": 134, "type": "TASK", "confidence": 0.6402316242456436}]}, {"text": "Retrieval was carried out using the PL2 retrieval model using the settings recommended for this CLUGS task in , with the empirically-determined hyper-parameters that c = 1.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Correlation Coefficients vs AP for each query translation from Ar-to-En vs each QPP. Correlation that are significant  at the 0.05 confidence level are marked in bold.", "labels": [], "entities": [{"text": "AP", "start_pos": 38, "end_pos": 40, "type": "METRIC", "confidence": 0.9790982007980347}]}, {"text": " Table 3: Baseline and adaptive CLIR results using both pre-retrieval and post-retrieval QPP. Percentages % with * indicate  statistically significant different change at 0.05 confidence level", "labels": [], "entities": []}]}