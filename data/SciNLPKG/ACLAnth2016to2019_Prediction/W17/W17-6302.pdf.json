{"title": [{"text": "Dependency Language Models for Transition-based Dependency Parsing", "labels": [], "entities": [{"text": "Dependency Parsing", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.6690282821655273}]}], "abstractContent": [{"text": "In this paper, we present an approach to improve the accuracy of a strong transition-based dependency parser by exploiting dependency language models that are extracted from a large parsed corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9986571073532104}, {"text": "transition-based dependency parser", "start_pos": 74, "end_pos": 108, "type": "TASK", "confidence": 0.6270863115787506}]}, {"text": "We integrated a small number of features based on the dependency language models into the parser.", "labels": [], "entities": []}, {"text": "To demonstrate the effectiveness of the proposed approach, we evaluate our parser on standard En-glish and Chinese data where the base parser could achieve competitive accuracy scores.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 168, "end_pos": 176, "type": "METRIC", "confidence": 0.9856825470924377}]}, {"text": "Our enhanced parser achieved state-of-the-art accuracy on Chinese data and competitive results on English data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9992802739143372}]}, {"text": "We gained a large absolute improvement of one point (UAS) on Chinese and 0.5 points for English.", "labels": [], "entities": [{"text": "absolute", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9671928882598877}, {"text": "UAS)", "start_pos": 53, "end_pos": 57, "type": "METRIC", "confidence": 0.9756594002246857}]}], "introductionContent": [{"text": "In recent years, using unlabeled data to improve natural language parsing has seen a surge of interest as the data can easy and inexpensively be obtained, cf.;.", "labels": [], "entities": [{"text": "natural language parsing", "start_pos": 49, "end_pos": 73, "type": "TASK", "confidence": 0.6579668521881104}]}, {"text": "This is in stark contrast to the high costs of manually labeling new data.", "labels": [], "entities": []}, {"text": "Some of the techniques such as self-training () and cotraining) use auto-parsed data as additional training data.", "labels": [], "entities": []}, {"text": "This enables the parser to learn from its own or other parser's annotations.", "labels": [], "entities": []}, {"text": "Other techniques include word clustering () and word embedding () which are generated from a large amount of unannotated data.", "labels": [], "entities": [{"text": "word clustering", "start_pos": 25, "end_pos": 40, "type": "TASK", "confidence": 0.770609050989151}]}, {"text": "The outputs can be used as features or inputs for parsers.", "labels": [], "entities": []}, {"text": "Both groups of techniques have been shown effective on syntactic parsing tasks (.", "labels": [], "entities": [{"text": "syntactic parsing tasks", "start_pos": 55, "end_pos": 78, "type": "TASK", "confidence": 0.8366208672523499}]}, {"text": "However, most word clustering and the word embedding approaches do not consider the syntactic structures and most self-/co-training approaches can use only a relatively small additional training data as training parsers on a large corpus might be time-consuming or even intractable on a corpus of millions of sentences.", "labels": [], "entities": [{"text": "word clustering", "start_pos": 14, "end_pos": 29, "type": "TASK", "confidence": 0.7434657216072083}]}, {"text": "Dependency language models (DLM)) are variants of language models based on dependency structures.", "labels": [], "entities": []}, {"text": "An N-gram DLM is able to predict the next child when given N-1 immediate previous children and their head.", "labels": [], "entities": []}, {"text": "integrated first a high-order DLM into a second-order graph-based parser.", "labels": [], "entities": []}, {"text": "The DLM allows the parser to explore high-order features but not increasing the time complexity.", "labels": [], "entities": []}, {"text": "Following, we adapted the DLM to transition-based dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 50, "end_pos": 68, "type": "TASK", "confidence": 0.718929648399353}]}, {"text": "Our approach is different from's in a number of important aspects: 1.", "labels": [], "entities": []}, {"text": "We applied the DLM to a strong parser that on its own has a competitive performance.", "labels": [], "entities": []}, {"text": "2. We revised their feature templates to integrate the DLMs with a transition-based system and labeled parsing.", "labels": [], "entities": []}, {"text": "3. We used DLMs in joint tagging and parsing, and gained up to 0.4% on tagging accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 37, "end_pos": 44, "type": "TASK", "confidence": 0.8993877172470093}, {"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9825764894485474}]}, {"text": "4. Our approach could use not only single DLM but also multiple DLMs during parsing.", "labels": [], "entities": []}, {"text": "5. We evaluated additionally with DLMs extracted from higher quality parsed data which two parsers assigned the same annotations.", "labels": [], "entities": []}, {"text": "Overall, our approach improved upon a competitive baseline by 0.51% for English and achieved state-of-the-art accuracy for Chinese.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 110, "end_pos": 118, "type": "METRIC", "confidence": 0.9990215301513672}]}], "datasetContent": [{"text": "For our experiments, we used the Penn English Treebank (PTB) () and Chinese Treebank 5 (CTB5) ().", "labels": [], "entities": [{"text": "Penn English Treebank (PTB)", "start_pos": 33, "end_pos": 60, "type": "DATASET", "confidence": 0.9588183363278707}, {"text": "Chinese Treebank 5 (CTB5)", "start_pos": 68, "end_pos": 93, "type": "DATASET", "confidence": 0.9523088137308756}]}, {"text": "For English, we follow the standard splits and used Stanford parser 1 v3.3.0 to convert the constituency trees into Stanford style dependencies ().", "labels": [], "entities": []}, {"text": "For Chinese, we follow the splits of Zhang and Nivre (2011), the constituency trees are converted to dependency relations by Penn2Malt 2 tool using head rules of. shows the splits of our data.", "labels": [], "entities": []}, {"text": "We used gold segmentation for Chinese tests to make our work comparable with previous work.", "labels": [], "entities": [{"text": "gold segmentation", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.6951031386852264}]}, {"text": "We used predicted part-of-speech tags for both languages in all evaluations.", "labels": [], "entities": []}, {"text": "Tags are assigned by base parser's internal joint tagger trained on the training set.", "labels": [], "entities": []}, {"text": "We report labeled (LAS) and unlabeled (UAS) attachment scores, punctuation marks are excluded from the evaluation.", "labels": [], "entities": [{"text": "UAS) attachment scores", "start_pos": 39, "end_pos": 61, "type": "METRIC", "confidence": 0.7032989710569382}]}, {"text": "For the English unlabeled data, we used the data of which contains around 30 million sentences (800 million words) from the news domain.", "labels": [], "entities": []}, {"text": "For Chinese, we used Xinhua portion of Chinese Gigaword 3 Version 5.0 (LDC2011T13).", "labels": [], "entities": [{"text": "Xinhua portion of Chinese Gigaword 3 Version 5.0 (LDC2011T13)", "start_pos": 21, "end_pos": 82, "type": "DATASET", "confidence": 0.8586640818552538}]}, {"text": "The Chinese unlabeled data we used consists of 20 million sentences which is roughly 450 million words after being segmented by ZPar 4 v0.7.5.", "labels": [], "entities": [{"text": "ZPar 4 v0.7.5", "start_pos": 128, "end_pos": 141, "type": "DATASET", "confidence": 0.9304182926813761}]}, {"text": "The word segmentor is trained on the CTB5 training set.", "labels": [], "entities": [{"text": "CTB5 training set", "start_pos": 37, "end_pos": 54, "type": "DATASET", "confidence": 0.9805281559626261}]}, {"text": "In most of our experiments, the DLMs are extracted from data annotated by our base parser.", "labels": [], "entities": []}, {"text": "For the evaluation on higher quality DLMs, the unlabeled data is additionally tagged and parsed by Berkeley parser and is converted to dependency trees with the same tools as for gold data.", "labels": [], "entities": []}, {"text": "We used Mate transition-based parser with its default setting and abeam of 40 as our baseline.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Feature templates which we use in the  parser.", "labels": [], "entities": []}, {"text": " Table 2: Our data splits for English and Chinese", "labels": [], "entities": []}, {"text": " Table 3: Effects (LAS) of different number of  DLMs for English and Chinese. m = 0 refers the  baseline.", "labels": [], "entities": [{"text": "Effects (LAS)", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.7099522352218628}]}, {"text": " Table 4: Effects (LAS) of DLMs extracted from  different size (in million sentences) of corpus.  Size = 0 refers the baseline.", "labels": [], "entities": [{"text": "Effects (LAS)", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.6757749170064926}]}, {"text": " Table 5: Comparing with top performing parsers  on English. (* means results that are evaluated  on Yamada and Matsumoto (2003) conversion.  \u2020  means neural network-based parsers)", "labels": [], "entities": []}, {"text": " Table 6: Comparing with top performing parsers  on Chinese.", "labels": [], "entities": [{"text": "Chinese", "start_pos": 52, "end_pos": 59, "type": "DATASET", "confidence": 0.9296243786811829}]}]}