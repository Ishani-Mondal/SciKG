{"title": [{"text": "Neural Post-Editing Based on Quality Estimation", "labels": [], "entities": []}], "abstractContent": [{"text": "Automatic post-editing (APE) is a challenging task on WMT evaluation campaign.", "labels": [], "entities": [{"text": "Automatic post-editing (APE)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.5820869266986847}, {"text": "WMT evaluation campaign", "start_pos": 54, "end_pos": 77, "type": "DATASET", "confidence": 0.7577000260353088}]}, {"text": "We find that only a small number of edit operations are required for most machine translation outputs, through analysis of the training set of WMT17 APE en-de task.", "labels": [], "entities": [{"text": "machine translation outputs", "start_pos": 74, "end_pos": 101, "type": "TASK", "confidence": 0.8369161486625671}, {"text": "WMT17 APE en-de task", "start_pos": 143, "end_pos": 163, "type": "DATASET", "confidence": 0.7448756694793701}]}, {"text": "Based on this statistics analysis, two neural post-editing (NPE) models are trained depended on the edit numbers: single edit and minor edits.", "labels": [], "entities": []}, {"text": "The improved quality estimation (QE) approach is exploited to rank models, and select the best translation as the post-edited output from the n-best list translation hypotheses generated by the best APE model and the raw translation system.", "labels": [], "entities": []}, {"text": "Experimental results on the datasets of WMT16 APE test set show that the proposed approach significantly outp-erformed the baseline.", "labels": [], "entities": [{"text": "WMT16 APE test set", "start_pos": 40, "end_pos": 58, "type": "DATASET", "confidence": 0.8824058920145035}]}, {"text": "Our approach can bring considerable relief from the overcorrection problem in APE.", "labels": [], "entities": [{"text": "APE", "start_pos": 78, "end_pos": 81, "type": "TASK", "confidence": 0.5015284419059753}]}], "introductionContent": [{"text": "Automatic post-editing (APE) aims to learn how to correct machine translation errors by use of the human post-editing feedback.", "labels": [], "entities": [{"text": "Automatic post-editing (APE)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.5868506133556366}]}, {"text": "The traditional statistical post-editing builds monolingual statistical phrased-based machine translation system to translate the wrong raw outputs into good translations.", "labels": [], "entities": [{"text": "statistical phrased-based machine translation", "start_pos": 60, "end_pos": 105, "type": "TASK", "confidence": 0.6621930152177811}]}, {"text": "In recent years, with the great success of deep learning achieved in machine translation, many works have applied neural machine translation (NMT) to the APE task.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 69, "end_pos": 88, "type": "TASK", "confidence": 0.7513416409492493}, {"text": "neural machine translation (NMT)", "start_pos": 114, "end_pos": 146, "type": "TASK", "confidence": 0.7899337609608968}, {"text": "APE task", "start_pos": 154, "end_pos": 162, "type": "TASK", "confidence": 0.9214276373386383}]}, {"text": "Pal et al. proposed to exploit the bidirectional source RNN encoder-decoder model to establish a monolingual machine translation system for APE ().", "labels": [], "entities": [{"text": "APE", "start_pos": 140, "end_pos": 143, "type": "TASK", "confidence": 0.7414811253547668}]}, {"text": "Compared with the traditional statistical post-editing approaches, their approach gained more improvement.", "labels": [], "entities": []}, {"text": "In the light of the context information of the translation, Pecina et al. proposed to respectively establish independent encoders for source sentences and raw machine translations (.", "labels": [], "entities": []}, {"text": "Their approach is similar to the multi-source NMT (; the difference lies in the input information are source sentences and raw machine translation outputs.", "labels": [], "entities": []}, {"text": "proposed to combine the outputs of monolingual NMT and bilingual NMT to improve the performance of APE task (.", "labels": [], "entities": [{"text": "APE task", "start_pos": 99, "end_pos": 107, "type": "TASK", "confidence": 0.8053682744503021}]}, {"text": "This paper presents anew approach for APE which was submitted by the JXNU team to WMT17 APE shared task.", "labels": [], "entities": [{"text": "APE", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.9904250502586365}, {"text": "JXNU team", "start_pos": 69, "end_pos": 78, "type": "DATASET", "confidence": 0.9488007724285126}, {"text": "WMT17 APE shared task", "start_pos": 82, "end_pos": 103, "type": "TASK", "confidence": 0.5134419202804565}]}, {"text": "In order to effectively reduce the overcorrection problem, we propose to build two specific neural post-editing (NPE) models in term of the edit numbers, and select the best model by machine translation quality estimation (QE).", "labels": [], "entities": [{"text": "machine translation quality estimation (QE)", "start_pos": 183, "end_pos": 226, "type": "METRIC", "confidence": 0.6429757475852966}]}, {"text": "The experiment results indicate that the proposed approach gains great improvement over the baseline officially released by the evaluation campaign.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to test the performance of the proposed approach, we conduct experiment on the test set of the WMT16 APE Task.", "labels": [], "entities": [{"text": "WMT16 APE Task", "start_pos": 104, "end_pos": 118, "type": "DATASET", "confidence": 0.6744208335876465}]}, {"text": "The task focuses on the information technology domain, in which English source sentences have been translated into German (en-de) by an unknown MT system.", "labels": [], "entities": []}, {"text": "The goal of the APE shared task is to examine automatic methods for correcting errors.", "labels": [], "entities": [{"text": "APE shared task", "start_pos": 16, "end_pos": 31, "type": "TASK", "confidence": 0.8691132465998331}]}, {"text": "Experimental data consist of corpus of WMT16 and WMT17 APE shared task released by the evaluation campaign, and publicly released artificial post-editing data (, including source language sentences, raw machine translation outputs and human references.", "labels": [], "entities": [{"text": "WMT16", "start_pos": 39, "end_pos": 44, "type": "DATASET", "confidence": 0.9371195435523987}, {"text": "WMT17 APE shared task", "start_pos": 49, "end_pos": 70, "type": "DATASET", "confidence": 0.6213378757238388}]}, {"text": "shows more details about this corpus.", "labels": [], "entities": []}, {"text": "Due to the provided training triplets for en-de direction is too small to train neural models, Grundkiewicz et al. created artificial training triplets through applying cross-entropy filtering and round-trip translation to extend the provided training triplets and publicly released the extended one ( The sentences in the corpus have been tokenized and truecased when preprocessing.", "labels": [], "entities": []}, {"text": "To deal with the limited ability of neural translation models to handle out-of-vocabulary words, tokens are splited into subword units) to improve the systems' performance.", "labels": [], "entities": [{"text": "neural translation", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.7654084861278534}]}, {"text": "We apply Nematus 2 to train the bidirectional RNN encoder-decoder model with attention mechanism.", "labels": [], "entities": []}, {"text": "The size of minibatches is set 80, vocabulary size is set 40000, maximum sentence length is set 50, the dimension of word embeddings is set 500, the size of hidden layers is set 1024, and the optimization algorithm proposed by Adadelta) is used.", "labels": [], "entities": []}, {"text": "Compared with Nematus's approach, AmuNMT 3 based on C++/CUDA ( decode at a faster speed on CPU.", "labels": [], "entities": []}, {"text": "Thus, we apply AmuNMT's approach to decode to-be-edited machine translations with abeam size of 12 and length normalization when decoding.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the provided data sets:  number of sentences, average sentence lengths  and TER score.", "labels": [], "entities": [{"text": "TER score", "start_pos": 100, "end_pos": 109, "type": "METRIC", "confidence": 0.984564483165741}]}, {"text": " Table 2: System performance of the NPE MINOR  and the NPE BASELINE systems in the sub  development set.", "labels": [], "entities": [{"text": "NPE MINOR", "start_pos": 36, "end_pos": 45, "type": "DATASET", "confidence": 0.7799557745456696}, {"text": "NPE", "start_pos": 55, "end_pos": 58, "type": "DATASET", "confidence": 0.8241010904312134}, {"text": "BASELINE", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.917509913444519}]}, {"text": " Table 3: System performance of NPE systems in  the sub development set.", "labels": [], "entities": []}, {"text": " Table 4: Results of NPE systems in the WMT16  test set", "labels": [], "entities": [{"text": "WMT16  test set", "start_pos": 40, "end_pos": 55, "type": "DATASET", "confidence": 0.9100228349367777}]}]}