{"title": [{"text": "The Event StoryLine Corpus: A New Benchmark for Causal and Temporal Relation Extraction", "labels": [], "entities": [{"text": "Event StoryLine Corpus", "start_pos": 4, "end_pos": 26, "type": "DATASET", "confidence": 0.7826837698618571}, {"text": "Causal and Temporal Relation Extraction", "start_pos": 48, "end_pos": 87, "type": "TASK", "confidence": 0.7477928638458252}]}], "abstractContent": [{"text": "This paper reports on the Event StoryLine Corpus (ESC) v0.9, anew benchmark dataset for the temporal and causal relation detection.", "labels": [], "entities": [{"text": "Event StoryLine Corpus (ESC) v0.9", "start_pos": 26, "end_pos": 59, "type": "DATASET", "confidence": 0.7209108216421944}, {"text": "temporal and causal relation detection", "start_pos": 92, "end_pos": 130, "type": "TASK", "confidence": 0.6933454751968384}]}, {"text": "By developing this dataset, we also introduce anew task, the StoryLine Extraction from news data, which aims at extracting and classifying events relevant for stories, from across news documents spread in time and clustered around a single seminal event or topic.", "labels": [], "entities": []}, {"text": "In addition to describing the dataset, we also report on three baselines systems whose results show the complexity of the task and suggest directions for the development of more robust systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "Humans have an appetite for information to explain the things they observe.", "labels": [], "entities": []}, {"text": "Our minds constantly mine the present for cues, merge this with information from the past, and derive models for reasoning and taking decisions.", "labels": [], "entities": []}, {"text": "It is by means of such explanatory patterns, and by extension of explanatory relations among entities and events, that we understand the changing world.", "labels": [], "entities": []}, {"text": "The current stream of information poses a big challenge both to humans and systems to extract, organize, and represent events and their relations.", "labels": [], "entities": []}, {"text": "News aggregation systems can easily monitor the burst and the development of a topic, or news story, but they fail in providing a content-based analysis.", "labels": [], "entities": []}, {"text": "Given a topic or trending story, people still have to read the documents and reconstruct a unitary and coherent report mentally.", "labels": [], "entities": []}, {"text": "Current NLP systems can identify complex information but they lack a method to connect it in a unitary and coherent message.", "labels": [], "entities": []}, {"text": "Steps in this direction have been conducted but are very limited and do not cover the full story that is told by these documents (e.g. the textual entailment task, or script extraction).", "labels": [], "entities": [{"text": "script extraction", "start_pos": 167, "end_pos": 184, "type": "TASK", "confidence": 0.8288815915584564}]}, {"text": "Monitoring a news story from its beginning to end is a challenging task, which requires systems to be able to: 1) reconcile information from different sources distributed in time; 2) resolve deduplication of information; and 3) extract informative semantic structures.", "labels": [], "entities": [{"text": "Monitoring a news story from its beginning to end", "start_pos": 0, "end_pos": 49, "type": "TASK", "confidence": 0.816728240913815}, {"text": "resolve deduplication of information", "start_pos": 183, "end_pos": 219, "type": "TASK", "confidence": 0.8762448877096176}]}, {"text": "It is surprising to observe how humans can perform these tasks with relative little effort.", "labels": [], "entities": []}, {"text": "It has been suggested that this capacity is partly based on narrative strategies).", "labels": [], "entities": []}, {"text": "Such a structuring is possible thanks to a key component of narratives, the plot structure, which provides a chronological and logical ordering of events.", "labels": [], "entities": []}, {"text": "This means that events are not simply ordered in time but they are selected and connected in such away that their relations are meaningful, i.e., they give rise to a network of explanatory relations.", "labels": [], "entities": []}, {"text": "Accessing and reconstructing plot structures for different topics would be beneficial for lots of Natural Language Understanding applications (question answering, summarization, co-reference resolution, event processing, and script extraction, among others).", "labels": [], "entities": [{"text": "question answering", "start_pos": 143, "end_pos": 161, "type": "TASK", "confidence": 0.861158698797226}, {"text": "summarization", "start_pos": 163, "end_pos": 176, "type": "TASK", "confidence": 0.9802777171134949}, {"text": "co-reference resolution", "start_pos": 178, "end_pos": 201, "type": "TASK", "confidence": 0.6935612559318542}, {"text": "script extraction", "start_pos": 225, "end_pos": 242, "type": "TASK", "confidence": 0.8127152323722839}]}, {"text": "One of the necessary step fora StoryLine Extraction task is to decide on a corpus to evaluate performance of systems.", "labels": [], "entities": [{"text": "StoryLine Extraction task", "start_pos": 31, "end_pos": 56, "type": "TASK", "confidence": 0.6850993633270264}]}, {"text": "This paper presents such as resource: the Event StoryLine Corpus v0.9, specifically designed for the evaluation of systems aiming at reconstructing event-centric plot structures.", "labels": [], "entities": [{"text": "Event StoryLine Corpus v0.9", "start_pos": 42, "end_pos": 69, "type": "DATASET", "confidence": 0.72657560557127}]}, {"text": "The resource is still being extended with new annotated texts, but in the remainder of the paper we will refer to this first version.", "labels": [], "entities": []}, {"text": "The corpus has been developed by applying annotation guidelines designed to mark-up the network of explanatory relations which can be realized between pairs of events in a document belonging to a specific topic.", "labels": [], "entities": []}, {"text": "Furthermore, the guidelines are compliant with other initiatives for event annotation: temporal processing (TimeML) and Richer Event Description (RED)), event coreference (Event Coreference Bank+ (ECB+)), and causal relations,, ROCStories () among others).", "labels": [], "entities": []}, {"text": "The remainder of the paper is structured as follows: Section 2 will explain the annotation scheme, describe the annotation layers of the Event StoryLines Corpus (ESC) v0.9, and report on agreement measures.", "labels": [], "entities": [{"text": "Event StoryLines Corpus (ESC) v0.9", "start_pos": 137, "end_pos": 171, "type": "DATASET", "confidence": 0.773664802312851}]}, {"text": "Section 3 will describe experiments related to the development of baselines for the StoryLine Extraction task.", "labels": [], "entities": [{"text": "StoryLine Extraction task", "start_pos": 84, "end_pos": 109, "type": "TASK", "confidence": 0.7706550558408102}]}, {"text": "In Section 4 a review of previous annotation initiatives is given, showing differences and commonalities between them and the ESC data.", "labels": [], "entities": [{"text": "ESC data", "start_pos": 126, "end_pos": 134, "type": "DATASET", "confidence": 0.9492388665676117}]}, {"text": "Finally, conclusions and future work are reported in Section 5.", "labels": [], "entities": []}, {"text": "The annotated data, the evaluation scripts, and the baselines models are publicly available.", "labels": [], "entities": []}, {"text": "2 The Event StoryLine Corpus v0.9 The primary goal of the ESC v0.9 dataset is to provide an intrinsic evaluation benchmark for the event-centric StoryLine Extraction task.", "labels": [], "entities": [{"text": "Event StoryLine Corpus v0.9", "start_pos": 6, "end_pos": 33, "type": "DATASET", "confidence": 0.6694402545690536}, {"text": "ESC v0.9 dataset", "start_pos": 58, "end_pos": 74, "type": "DATASET", "confidence": 0.8844167192776998}, {"text": "event-centric StoryLine Extraction task", "start_pos": 131, "end_pos": 170, "type": "TASK", "confidence": 0.6670869290828705}]}, {"text": "The task can be best described as a combination of three basic subtasks: \u2022 Event Detection and Classification Identify and classify events in each document which compose a topic, or a seminal event; \u2022 Temporal Anchoring of Events Anchor each event mention to the temporal expression expressing the time of its happening, as well as to the Document Creation Time (DCT); \u2022 Explanatory Relation Identification and Classification Select event pairs which are temporally and logically connected, and then, classify the storyline relation type.", "labels": [], "entities": [{"text": "Event Detection", "start_pos": 75, "end_pos": 90, "type": "TASK", "confidence": 0.7030197381973267}, {"text": "Explanatory Relation Identification", "start_pos": 371, "end_pos": 406, "type": "TASK", "confidence": 0.8113693197568258}]}, {"text": "A storyline relation can be best described as a loose causal and temporal relation between a pair of event mentions, where one event mention explains/justifies the occurrence of the other event mention in the pair (more details are reported in Section 2.3).", "labels": [], "entities": []}, {"text": "Relations can be classified either as rising action, or falling action.", "labels": [], "entities": []}, {"text": "An additional task is Event Co-reference Resolution, which aims at identifying co-referential chains of events mentions both at within-and cross-document levels.", "labels": [], "entities": [{"text": "Event Co-reference Resolution", "start_pos": 22, "end_pos": 51, "type": "TASK", "confidence": 0.6592470606168112}]}, {"text": "The availability of this information allows us to deduplicate information across event mentions by creating event instances, i.e. formal semantic representation in RDF compliant URIs that may integrate linguistic information with external resources, and thus, allow reasoning (.", "labels": [], "entities": []}, {"text": "In the following sections, we will illustrate the components of the ESC Annotation Scheme and its annotation framework.", "labels": [], "entities": [{"text": "ESC Annotation Scheme", "start_pos": 68, "end_pos": 89, "type": "DATASET", "confidence": 0.9544423222541809}]}], "datasetContent": [{"text": "In this section, we describe the experimental results fora number of StoryLine Extraction baseline systems on the ESC v0.9 dataset.", "labels": [], "entities": [{"text": "ESC v0.9 dataset", "start_pos": 114, "end_pos": 130, "type": "DATASET", "confidence": 0.9464433789253235}]}, {"text": "The outcomes of these experiments will be useful to compare the performance of future (and more complex) systems, as well as to have a preliminary assessment of the complexity of the task.", "labels": [], "entities": []}, {"text": "The ESC v0.9 dataset has been divided into a development set, consisting of 6 seminal events and a test set of 16 seminal events 11 . The test subset contains a total of 4,027 PLOT LINKs when extended with within-document event coreference chains.", "labels": [], "entities": [{"text": "ESC v0.9 dataset", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.8826772371927897}]}, {"text": "All experiments have been conducted considering gold data for event mention extent, temporal expression extent and values, and event co-reference.", "labels": [], "entities": []}, {"text": "Three baselines have been developed: 1) OP: selection of event pairs in relations that mimic the textual order of presentation; 2) PPMI1: selection of event pairs using Positive Pointwise Mutual Information (PPMI) obtained from a set of selected seed pairs and the manually annotated pairs from the development set; 3) PPMI-CONTAINS: selection of the event pairs using PPMI as in the PPMI1 model but restricting the sets of events to those which share the same temporal anchors, i.e. have a TLINK of type contains.", "labels": [], "entities": []}, {"text": "The seed pairs for the PPMI based models have been extracted from the SemEval 2012 Task-2: Measuring Degrees of Relational Similarity ().", "labels": [], "entities": [{"text": "SemEval 2012 Task-2", "start_pos": 70, "end_pos": 89, "type": "TASK", "confidence": 0.6398846705754598}]}, {"text": "In particular, we extracted words pairs from the test set Phase-1 Answers corresponding to class-8 (CAUSE-PURPOSE), retaining only word pairs in the categories Cause:Effect, Cause:Compensatory Action, Action/Activity, and Prevention, where both words express events.", "labels": [], "entities": []}, {"text": "This initial set of seed elements has been further extended by looking for \"cause\", \"enablement\", and \"entails\" relations in SUMO ( and in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 139, "end_pos": 146, "type": "DATASET", "confidence": 0.9344426989555359}]}, {"text": "This resulted in a list of 1,609 unique seed pairs.", "labels": [], "entities": []}, {"text": "PPMI has been computed using the DISSECT Toolkit (, and pair frequencies have been extracted from Google bigrams(: Results of three baselines models on PLOT LINK identification and classification . This has been identified by normalizing the PPMI scores between 0 and 1, computing average and standard deviation.", "labels": [], "entities": [{"text": "DISSECT Toolkit", "start_pos": 33, "end_pos": 48, "type": "DATASET", "confidence": 0.9591716527938843}, {"text": "PLOT LINK identification and classification", "start_pos": 152, "end_pos": 195, "type": "TASK", "confidence": 0.7006691217422485}, {"text": "standard", "start_pos": 293, "end_pos": 301, "type": "METRIC", "confidence": 0.9694184064865112}]}, {"text": "This allowed us to identify a minimum and a maximum normalized score 12 for PPMI, representing the boundaries of the range inside which event pairs in a PLOT LINK relation can be identified and selected.", "labels": [], "entities": []}, {"text": "As for the extraction of the events in a PLOT LINK relation from the test data, co-occurrence frequencies were computed per pairs of eligible event types (i.e. AC-TION OCCURRENCE, ACTION PERCEPTION, ACTION STATE) both at sentence and at document level.", "labels": [], "entities": []}, {"text": "PPMI values were obtained by applying the same procedure used for the seed pairs.", "labels": [], "entities": []}, {"text": "In the PPMI1 model, all event pairs whose score is within the range obtained from the seed pairs were selected.", "labels": [], "entities": []}, {"text": "On the other hand, in the PPMI-CONTAINS model, the event pairs were further filtered by applying the temporal anchor constraints, i.e. they must both have a TLINK of type contains with the same temporal expression.", "labels": [], "entities": [{"text": "TLINK", "start_pos": 157, "end_pos": 162, "type": "METRIC", "confidence": 0.9693454504013062}]}, {"text": "As for relation classification, i.e. the assignment of the values rising action or falling action to an event pair, we decided to always assign the rising action value, i.e. the most frequent value from the manually annotated data.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 7, "end_pos": 30, "type": "TASK", "confidence": 0.8975434601306915}]}, {"text": "In addition to this, we also aimed at evaluating the impact of the order of presentation of the information in a document on PLOT LINKs.", "labels": [], "entities": [{"text": "PLOT LINKs", "start_pos": 125, "end_pos": 135, "type": "TASK", "confidence": 0.4944273382425308}]}, {"text": "In, we report on the aggregated results, i.e. average score over the test data, of the three baselines.", "labels": [], "entities": []}, {"text": "The relation detection subtask limits the evaluation to the correctness/validity of the event pairs identified by each model against the extended gold data.", "labels": [], "entities": [{"text": "relation detection", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.8091545701026917}]}, {"text": "On the other hand, in the classification subtask, both the event pair and the relation value must be correct.", "labels": [], "entities": []}, {"text": "This means that if the PLOT LINK value is wrong but the event pair is correct, then the entire PLOT LINK is considered Average PPMI value=0.582; standard deviation=0.181; minimum PPMI value=0. incorrect.", "labels": [], "entities": [{"text": "PLOT LINK value", "start_pos": 23, "end_pos": 38, "type": "METRIC", "confidence": 0.8547947208086649}, {"text": "Average PPMI value", "start_pos": 119, "end_pos": 137, "type": "METRIC", "confidence": 0.8729288180669149}, {"text": "standard", "start_pos": 145, "end_pos": 153, "type": "METRIC", "confidence": 0.9744341969490051}]}, {"text": "Standard Precision (P), Recall (R), and F1-score (F1) apply for both subtasks.", "labels": [], "entities": [{"text": "Precision (P)", "start_pos": 9, "end_pos": 22, "type": "METRIC", "confidence": 0.9603109508752823}, {"text": "Recall (R)", "start_pos": 24, "end_pos": 34, "type": "METRIC", "confidence": 0.9673430323600769}, {"text": "F1-score (F1)", "start_pos": 40, "end_pos": 53, "type": "METRIC", "confidence": 0.952953115105629}]}, {"text": "The results, though preliminary, highlight the complexity of the task.", "labels": [], "entities": []}, {"text": "Not surprisingly the best Recall value is obtained by the OP model.", "labels": [], "entities": [{"text": "Recall", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.9865009188652039}]}, {"text": "The creation of all possible pairs between eligible event types clearly gives rise to a lot of False Positive pairs (P=0.156), showing that even when only events in relevant sentences of specific topic are selected, there is still information which is not to be included in a storyline.", "labels": [], "entities": [{"text": "False Positive pairs", "start_pos": 95, "end_pos": 115, "type": "METRIC", "confidence": 0.9460116426150004}, {"text": "P", "start_pos": 117, "end_pos": 118, "type": "METRIC", "confidence": 0.7672955989837646}]}, {"text": "For instance, there could be references to events which occurred in the past and which do not have any explanatory relations with the event mentions referring to the current topic, and presented to the reader for comparison or as additional background knowledge.", "labels": [], "entities": []}, {"text": "Different observations apply to the PPMI-based models.", "labels": [], "entities": []}, {"text": "In PPMI1, we can observe a big drop in Recall (-0.841) and as well as in Precision, though lower (-0.019).", "labels": [], "entities": [{"text": "Recall", "start_pos": 39, "end_pos": 45, "type": "METRIC", "confidence": 0.997560977935791}, {"text": "Precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9459800720214844}]}, {"text": "On the other hand, temporal containment seems to facilitate the aggregation of the relevant pairs of a storyline, as shown by Precision (P=0.227).", "labels": [], "entities": [{"text": "temporal containment", "start_pos": 19, "end_pos": 39, "type": "TASK", "confidence": 0.6608502268791199}, {"text": "Precision (P", "start_pos": 126, "end_pos": 138, "type": "METRIC", "confidence": 0.7706499894460043}]}, {"text": "At this stage of the implementation, there is alack of connection between events in different temporal anchors, thus limiting the connections between event pairs and having a negative impact on the Recall.", "labels": [], "entities": [{"text": "Recall", "start_pos": 198, "end_pos": 204, "type": "DATASET", "confidence": 0.7789666056632996}]}, {"text": "By observing the results on the classification task, it immediately appears that the textual order of presentation of the information badly correlates with PLOT LINK values.", "labels": [], "entities": [{"text": "classification task", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.8903929591178894}, {"text": "PLOT LINK", "start_pos": 156, "end_pos": 165, "type": "METRIC", "confidence": 0.8282260894775391}]}, {"text": "The low results were in part expected given the distribution of the rising action and falling action relations in the test data.", "labels": [], "entities": []}, {"text": "To better understand the results, we run an additional evaluation on the baselines by taking into account only same sentence pairs.", "labels": [], "entities": []}, {"text": "In this case, we observed that all baselines increase the Precision (P=0.123 for OP, P=0.095 for PPM1, and P=0.151 for PPMI-CONTAINS) and downgrade the Recall scores.", "labels": [], "entities": [{"text": "Precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9985976815223694}, {"text": "Recall", "start_pos": 152, "end_pos": 158, "type": "METRIC", "confidence": 0.9310170412063599}]}, {"text": "Given the evaluation framework for classification, this suggests that, at least when in the same sentence, there is a tendency to narrate the events following a logi-cal order, not only a temporal one.", "labels": [], "entities": []}, {"text": "However, this does not hold anymore when cross-sentence relations are taken into account.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: TLINK value per DCT and temporal ex- pression in the document.", "labels": [], "entities": [{"text": "TLINK", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9981988072395325}]}, {"text": " Table 2. The  scores for PLOT LINKs have been computed as  an average over the 4 seminal events.", "labels": [], "entities": [{"text": "PLOT LINKs", "start_pos": 26, "end_pos": 36, "type": "METRIC", "confidence": 0.7611759603023529}]}, {"text": " Table 2: Inter-annotator agreement: Dice coeffi- cient at token level.", "labels": [], "entities": []}, {"text": " Table 3: Results of three baselines models on PLOT LINK identification and classification .", "labels": [], "entities": [{"text": "PLOT LINK identification and classification", "start_pos": 47, "end_pos": 90, "type": "TASK", "confidence": 0.6871826827526093}]}]}