{"title": [{"text": "Classifying Lexical-semantic Relationships by Exploiting Sense/Concept Representations", "labels": [], "entities": [{"text": "Classifying Lexical-semantic Relationships", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.8197961846987406}]}], "abstractContent": [{"text": "This paper proposes a method for classifying the type of lexical-semantic relation between a given pair of words.", "labels": [], "entities": []}, {"text": "Given an inventory of target relationships, this task can be seen as a multi-class classification problem.", "labels": [], "entities": [{"text": "multi-class classification", "start_pos": 71, "end_pos": 97, "type": "TASK", "confidence": 0.6687725186347961}]}, {"text": "We train a supervised classi-fier by assuming that a specific type of lexical-semantic relation between a pair of words would be signaled by a carefully designed set of relation-specific similarities between the words.", "labels": [], "entities": []}, {"text": "These similarities are computed by exploiting \"sense represen-tations\" (sense/concept embeddings).", "labels": [], "entities": []}, {"text": "The experimental results show that the proposed method clearly outperforms an existing state-of-the-art method that does not utilize sense/concept embeddings, thereby demonstrating the effectiveness of the sense representations.", "labels": [], "entities": []}], "introductionContent": [{"text": "Given a pair of words, classifying the type of lexical-semantic relation that could hold between them may have a range of applications.", "labels": [], "entities": []}, {"text": "In particular, discovering typed lexical-semantic relation instances is vital in building anew lexical-semantic resource, as well as for populating an existing lexical-semantic resource.", "labels": [], "entities": []}, {"text": "As argued in), even Princeton WordNet (henceforth PWN) is noted for its sparsity of useful internal lexical-semantic relations.", "labels": [], "entities": [{"text": "Princeton WordNet (henceforth PWN)", "start_pos": 20, "end_pos": 54, "type": "DATASET", "confidence": 0.8409440120061239}]}, {"text": "A distributional thesaurus), usually built with an automatic method such as that described in, often comprises a disorganized semantic network internally, where a variety of lexicalsemantic relations are incorporated without having proper relation labels attached.", "labels": [], "entities": []}, {"text": "These issues could be addressed if an accurate method for classifying the type of lexical-semantic relation is available.", "labels": [], "entities": []}, {"text": "A number of research studies on the classification of lexical-semantic relationships have been conducted.", "labels": [], "entities": [{"text": "classification of lexical-semantic relationships", "start_pos": 36, "end_pos": 84, "type": "TASK", "confidence": 0.8796813040971756}]}, {"text": "Among them, Necsules\u00b8cu recently presented two classification methods that utilize word-level feature representations including word embedding vectors.", "labels": [], "entities": []}, {"text": "Although the reported results are superior to the compared systems, neither of the proposed methods exploited \"sense representations,\" which are described as the fine-grained representations of word senses, concepts, and entities in the description of this workshop . Motivated by the above-described issues and previous work, this paper proposes a supervised classification method that exploits sense representations, and discusses their utilities in the lexical relation classification task.", "labels": [], "entities": [{"text": "lexical relation classification task", "start_pos": 456, "end_pos": 492, "type": "TASK", "confidence": 0.708230085670948}]}, {"text": "The major rationales behind the proposed method are: (1) a specific type of lexical-semantic relation between a pair of words would be indicated by a carefully designed set of relation-specific similarities associated with the words; and (2) the similarities could be effectively computed by exploiting sense representations.", "labels": [], "entities": []}, {"text": "More specifically, for each word in the pair, we first collect relevant sets of sense/concept nodes (node sets) from an existing lexical-semantic resource (PWN), and then compute similarities for some designated pairs of node sets, where each node is represented by an embedding vector depending on its type (sense/concept).", "labels": [], "entities": []}, {"text": "In terms of its design, each node set pair is constructed such that it is associated with a specific type of lexical-semantic relation.", "labels": [], "entities": []}, {"text": "The resulting array of similarities, along with the underlying word/sense/concept embedding vectors is finally fed into the classifier as features.", "labels": [], "entities": []}, {"text": "The empirical results that use the BLESS dataset () demonstrate that our method clearly outperformed existing state-ofthe-art methods) that did not employ sense/concept embeddings, confirming that properly combining the similarity features also with the underlying semantic/conceptuallevel embeddings is indeed effective.", "labels": [], "entities": [{"text": "BLESS dataset", "start_pos": 35, "end_pos": 48, "type": "DATASET", "confidence": 0.9469058513641357}]}, {"text": "These results in turn highlight the utility of \"the sense representations\" (the sense/concept embeddings) created by the existing system referred to as.", "labels": [], "entities": []}, {"text": "The remainder of the paper first reviews related work (section 2), and then presents our approach (section 3).", "labels": [], "entities": []}, {"text": "As our experiments (section 4) utilize the BLESS dataset, the experimental results are directly compared with that of (Necsules\u00b8cuNecsules\u00b8cu et al., 2015) (section 5).", "labels": [], "entities": [{"text": "BLESS dataset", "start_pos": 43, "end_pos": 56, "type": "DATASET", "confidence": 0.8942075371742249}]}, {"text": "Although our methods were proved to be superior through the experiments, our operational requirement (sense/concept embeddings should be created from the underlying lexical-semantic resource) could be problematic especially when having to process unknown words.", "labels": [], "entities": []}, {"text": "We conclude the present paper by discussing future work to address this issue (section 6).", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated the effectiveness of the proposed supervised approach by conducting a series of classification experiments using the BLESS dataset ().", "labels": [], "entities": [{"text": "BLESS dataset", "start_pos": 130, "end_pos": 143, "type": "DATASET", "confidence": 0.9515687823295593}]}, {"text": "Among the possible learning algorithms, we adopted the Random Forest TM algorithm as it maintains a balance between performance and efficiency.", "labels": [], "entities": [{"text": "Random Forest TM algorithm", "start_pos": 55, "end_pos": 81, "type": "DATASET", "confidence": 0.7010465860366821}]}, {"text": "The results are assessed by using standard measures such as Precision (P ), Recall (R), and F 1.", "labels": [], "entities": [{"text": "Precision (P )", "start_pos": 60, "end_pos": 74, "type": "METRIC", "confidence": 0.9601474553346634}, {"text": "Recall (R)", "start_pos": 76, "end_pos": 86, "type": "METRIC", "confidence": 0.9727751016616821}, {"text": "F 1", "start_pos": 92, "end_pos": 95, "type": "METRIC", "confidence": 0.9944079518318176}]}, {"text": "We employed the pre-trained Word2Vec embeddings 2 . We trained sense/concept embeddings by applying the AutoExtend system 3 (Rothe and Sch\u00fctze, 2015) while using the Word2Vec embeddings as the input and consulting PWN 3.0 as the underlying lexical-semantic resource.", "labels": [], "entities": []}, {"text": "We utilized the BLESS dataset, which was developed for the evaluation of distributional semantic models.", "labels": [], "entities": [{"text": "BLESS dataset", "start_pos": 16, "end_pos": 29, "type": "DATASET", "confidence": 0.9349174499511719}]}, {"text": "It provides 14,400 tetrads of (w 1 , w 2 , lexical-semantic relation type, topical domain type): where the topical domain type designates a semantic class from the coarse semantic classification system consisting of 17 English concrete noun categories (e.g., tools, clothing, vehicles, and animals).", "labels": [], "entities": []}, {"text": "The lexical-semantic relation types defined in BLESS and their counts are described as follows: \u2022 COORD (3565 word pairs): they are cohyponyms (e.g., alligator-lizard).", "labels": [], "entities": [{"text": "BLESS", "start_pos": 47, "end_pos": 52, "type": "METRIC", "confidence": 0.5191622972488403}, {"text": "COORD", "start_pos": 98, "end_pos": 103, "type": "METRIC", "confidence": 0.9934491515159607}]}, {"text": "\u2022 HYPER (1337 word pairs): w 2 is a hypernym of w 1 (e.g., alligator-animal).", "labels": [], "entities": [{"text": "HYPER", "start_pos": 2, "end_pos": 7, "type": "METRIC", "confidence": 0.9985775947570801}]}, {"text": "\u2022 MERO (2943 word pairs): w 2 is a component/organ/member of w 1 (e.g., alligatormouth).", "labels": [], "entities": [{"text": "MERO", "start_pos": 2, "end_pos": 6, "type": "METRIC", "confidence": 0.9928083419799805}]}, {"text": "\u2022 ATTRI (2731 word pairs): w 2 is an adjective expressing an attribute of w 1 (e.g., alligatoraquatic).", "labels": [], "entities": [{"text": "ATTRI", "start_pos": 2, "end_pos": 7, "type": "METRIC", "confidence": 0.9948029518127441}]}, {"text": "\u2022 EVENT (3824 word pairs): w 2 is a verb referring to an action/activity/happening/event associated with w 1 (e.g., alligator-swim).", "labels": [], "entities": [{"text": "EVENT", "start_pos": 2, "end_pos": 7, "type": "METRIC", "confidence": 0.997041642665863}]}, {"text": "Note here that these lexical-semantic relation types are not completely concord with the PWN relations described in section 3.1.", "labels": [], "entities": []}, {"text": "Data division: In order to compare the performance for the present task we divided the data in three ways: In-domain, Out-of-domain (as employed in), and Collapsed-domain.", "labels": [], "entities": [{"text": "Data division", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.740713581442833}]}, {"text": "For the In-domain setting, the data in the same domain were used both for training and testing.", "labels": [], "entities": []}, {"text": "We thus conducted a five-fold cross validation for each domain.", "labels": [], "entities": []}, {"text": "For the Out-ofdomain setting, one domain is used for testing and the remaining data is used for training.", "labels": [], "entities": []}, {"text": "In addition, we prepared the Collapsed-domain setting, where we conducted a 10-fold cross validation for the entire dataset irrespective of the domain.", "labels": [], "entities": []}, {"text": "The default hyperparameters were used.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Comparison of the overall classification results.", "labels": [], "entities": [{"text": "Comparison", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.865797758102417}]}, {"text": " Table 4: Confusion matrix for the results by P roposal OoD  concat in the Out-of-domain setting.", "labels": [], "entities": []}, {"text": " Table 5: Ablation tests comparing the effective- ness of each node set.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9907159805297852}]}, {"text": " Table 6: Effectiveness comparison of the types of  features.", "labels": [], "entities": []}, {"text": " Table 7: Additional ablation tests comparing the  similarity calculation methods.", "labels": [], "entities": [{"text": "ablation", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9636702537536621}]}]}