{"title": [], "abstractContent": [{"text": "This work describes the AMU-UEdin submission to the WMT 2017 shared task on Automatic Post-Editing.", "labels": [], "entities": [{"text": "AMU-UEdin submission to the WMT 2017 shared task", "start_pos": 24, "end_pos": 72, "type": "DATASET", "confidence": 0.8103079199790955}]}, {"text": "We explore multiple neural architectures adapted for the task of automatic post-editing of machine translation output.", "labels": [], "entities": [{"text": "machine translation output", "start_pos": 91, "end_pos": 117, "type": "TASK", "confidence": 0.7236522436141968}]}, {"text": "We focus on neural end-to-end models that combine both inputs mt and src in a single neural architecture , modeling {mt, src} \u2192 pe directly.", "labels": [], "entities": []}, {"text": "Apart from that, we investigate the influence of hard-attention models which seem to be well-suited for monolingual tasks, as well as combinations of both ideas.", "labels": [], "entities": []}], "introductionContent": [{"text": "During the WMT 2016 APE two systems relied on neural models, the CUNI system ( and the shared task winner, the system submitted by the Adam Mickiewicz University (AMU) team.", "labels": [], "entities": [{"text": "WMT 2016 APE", "start_pos": 11, "end_pos": 23, "type": "TASK", "confidence": 0.5727763672669729}]}, {"text": "This submission explored the application of neural translation models to the APE problem and achieved good results by treating different models as components in a log-linear model, allowing for multiple inputs (the source src and the translated sentence mt) that were decoded to the same target language (post-edited translation pe).", "labels": [], "entities": [{"text": "neural translation", "start_pos": 44, "end_pos": 62, "type": "TASK", "confidence": 0.7840086817741394}, {"text": "APE problem", "start_pos": 77, "end_pos": 88, "type": "TASK", "confidence": 0.9316493570804596}]}, {"text": "Two systems were considered, one using src as the input (src \u2192 pe) and another using mt as the input (mt \u2192 pe).", "labels": [], "entities": []}, {"text": "A simple stringmatching penalty integrated within the log-linear model was used to control for higher faithfulness with regard to the raw MT output.", "labels": [], "entities": [{"text": "MT", "start_pos": 138, "end_pos": 140, "type": "TASK", "confidence": 0.9008994102478027}]}, {"text": "The penalty fires if the APE system proposes a word in its output that has not been seen in mt.", "labels": [], "entities": []}, {"text": "The influence of the components on the final result was tuned with Minimum Error Rate Training) with regard to the task metric TER.", "labels": [], "entities": [{"text": "Minimum Error Rate Training", "start_pos": 67, "end_pos": 94, "type": "METRIC", "confidence": 0.9344486743211746}, {"text": "TER", "start_pos": 127, "end_pos": 130, "type": "METRIC", "confidence": 0.8573404550552368}]}, {"text": "With neural encoder-decoder models, and multi-source models in particular, the combination of mt and src can be now achieved in more natural ways than for previously popular phrase-based statistical machine translation (PB-SMT) systems.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation (PB-SMT)", "start_pos": 174, "end_pos": 227, "type": "TASK", "confidence": 0.7102338969707489}]}, {"text": "Despite this, results for multi-source or doublesource models in APE scenarios are incomplete or unsatisfying in terms of performance.", "labels": [], "entities": [{"text": "APE", "start_pos": 65, "end_pos": 68, "type": "TASK", "confidence": 0.7992079854011536}]}, {"text": "In this work, we explore a number of singlesource and double-source neural architectures which we believe to be better fits to the APE task than vanilla encoder-decoder models with soft attention.", "labels": [], "entities": [{"text": "APE task", "start_pos": 131, "end_pos": 139, "type": "TASK", "confidence": 0.8872475028038025}]}, {"text": "We focus on neural end-to-end models that combine both inputs mt and src in a single neural architecture, modeling {mt, src} \u2192 pe directly.", "labels": [], "entities": []}, {"text": "Apart from that, we investigate the influence of hard-attention models which seem to be well-suited for monolingual tasks.", "labels": [], "entities": []}, {"text": "Finally, we create combinations of both architectures.", "labels": [], "entities": []}, {"text": "Following, we also attempt to generate more artificial data for the task.", "labels": [], "entities": []}, {"text": "Instead of relying on filtering towards specific error rates, we generate text with fitting error rates from the start which allows us to retain more data.", "labels": [], "entities": []}, {"text": "2 Encoder-Decoder Models with APE-specific Attention Models", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Statistics for artificial data sets in  comparison to official training and development  data, adapted from Junczys-Dowmunt and Grund- kiewicz (2016).", "labels": [], "entities": []}, {"text": " Table 3: Results from the literature for the WMT 2016 APE development and test set", "labels": [], "entities": [{"text": "WMT 2016 APE development and test set", "start_pos": 46, "end_pos": 83, "type": "DATASET", "confidence": 0.7541630523545402}]}, {"text": " Table 4: Post-submission results, the main task metric is TER (the lower the better)", "labels": [], "entities": [{"text": "TER", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.9994584918022156}]}]}