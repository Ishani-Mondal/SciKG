{"title": [{"text": "The Code2Text Challenge: Text Generation in Source Code Libraries", "labels": [], "entities": [{"text": "Text Generation", "start_pos": 25, "end_pos": 40, "type": "TASK", "confidence": 0.8023841977119446}]}], "abstractContent": [{"text": "We propose anew shared task for tactical data-to-text generation in the domain of source code libraries.", "labels": [], "entities": [{"text": "tactical data-to-text generation", "start_pos": 32, "end_pos": 64, "type": "TASK", "confidence": 0.7074602444966634}]}, {"text": "Specifically, we focus on text generation of function descriptions from example software projects.", "labels": [], "entities": [{"text": "text generation of function descriptions", "start_pos": 26, "end_pos": 66, "type": "TASK", "confidence": 0.8318187654018402}]}, {"text": "Data is drawn from existing resources used for studying the related problem of semantic parser induction (Richardson and Kuhn, 2017b; Richardson and Kuhn, 2017a), and spans a wide variety of both natural languages and programming languages.", "labels": [], "entities": [{"text": "semantic parser induction", "start_pos": 79, "end_pos": 104, "type": "TASK", "confidence": 0.8006854355335236}]}, {"text": "In this paper, we describe these existing resources, which will serve as training and development data for the task, and discuss plans for building new independent test sets.", "labels": [], "entities": []}], "introductionContent": [{"text": "Source code libraries are collections of computer programs/instructions expressed in a target programming language that aim to solve some set of problems.", "labels": [], "entities": [{"text": "Source code libraries are collections of computer programs/instructions expressed in a target programming language that aim to solve some set of problems", "start_pos": 0, "end_pos": 153, "type": "Description", "confidence": 0.7153679504990578}]}, {"text": "Within these libraries, the designers of the code often use natural language to describe how various internal components work.", "labels": [], "entities": []}, {"text": "For example, Figure 1.1 shows a docstring description (in red) for the max function in the Java standard library, which explains what the function does (i.e., Returns the greater of ), and the types of arguments that the function takes (i.e., two long values).", "labels": [], "entities": []}, {"text": "Similarly, a related function and its documentation for the Python programming language is shown in.2.", "labels": [], "entities": []}, {"text": "Given the tight coupling between such high-level text and lower-level representations, automatically extracting parallel datasets in this domain, consisting of short text descriptions and code templates, is rather straightforward.", "labels": [], "entities": []}, {"text": "Such datasets can then be used to study various translation problems, including translating text to code templates (i.e., se- mantic parsing), or generating representations to text (i.e., data-to-text generation).", "labels": [], "entities": [{"text": "se- mantic parsing)", "start_pos": 122, "end_pos": 141, "type": "TASK", "confidence": 0.7736344337463379}, {"text": "data-to-text generation", "start_pos": 188, "end_pos": 211, "type": "TASK", "confidence": 0.7779876589775085}]}, {"text": "In previous work (, we looked at using source code libraries to study the first problem, and have collected datasets for 43 software libraries across 7 natural languages.", "labels": [], "entities": []}, {"text": "We have also created a tool, called Function Assistant, for extracting new datasets from arbitrary software projects (.", "labels": [], "entities": []}, {"text": "In this paper, we propose using these resources for studying the second problem.", "labels": [], "entities": []}, {"text": "The task can be described as follows: given a source code library dataset or collection of datasets consisting of text and code template pairs, e.g., the text Returns the greater of two.. and the function representation static long max(..) in.1, create a model that generates well-formed natural language descriptions of these formal code inputs.", "labels": [], "entities": []}, {"text": "This task involves solving several sub-tasks, chief among them being lexicalization, or the problem of how to verbalize the function name and return value (here using a VP returns the greater of ), and the function's arguments (expressed here as a plural expression, two long values).", "labels": [], "entities": []}, {"text": "As shown in.3, existing lexicalization tasks tend to involve input representations that have considerable lexical overlap with the verbal output, which is not the case with our datasets and therefore makes our problem more difficult.", "labels": [], "entities": []}, {"text": "In addition, there is the problem of realization, or here aggregating the description as a sentence with an implied subject containing a transitive verb and a complex object, where the referring expression is attached as a PP.", "labels": [], "entities": []}, {"text": "The available resources make the task highly multilingual, both in terms of the input programming languages and output natural languages.", "labels": [], "entities": []}, {"text": "Since programming languages differ in terms of representation conventions, each formal language provides unique challenges related to these differences.", "labels": [], "entities": []}, {"text": "For example, statically-typed languages, such as Java in In what follows, we motivate this task by discussing related work.", "labels": [], "entities": []}, {"text": "We also discuss the current datasets and plans to build new independent test sets.", "labels": [], "entities": []}], "datasetContent": [{"text": "Following other data-to-text shared tasks ( and previous work on text generating from code (), we will use automatic evaluation metrics such as BLEU and METEOR to evaluate system output.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 144, "end_pos": 148, "type": "METRIC", "confidence": 0.9982438087463379}, {"text": "METEOR", "start_pos": 153, "end_pos": 159, "type": "METRIC", "confidence": 0.8943322896957397}]}, {"text": "We will also perform fluency-based human evaluation on a subset of each test set using student volunteers from the Institute for Natural Language Processing (IMS), at the University of Stuttgart, Germany.", "labels": [], "entities": []}, {"text": "To establish baseline results, we have already started a pilot study that uses phrase-based SMT to do generation.", "labels": [], "entities": [{"text": "SMT", "start_pos": 92, "end_pos": 95, "type": "TASK", "confidence": 0.8107413053512573}]}, {"text": "Such models have previously been used to establish strong baseline generation results, and have the advantage of being easy to run using known open-source tools.", "labels": [], "entities": []}, {"text": "Since these models only require parallel data, they also show what a purely input-output driven model is capable of achieving on these datasets.", "labels": [], "entities": []}, {"text": "All publicly available datasets are immediately available for system development.", "labels": [], "entities": []}, {"text": "The goal is to develop the new test sets before the end of 2017, and for the evaluation to be carried out in summer 2018.", "labels": [], "entities": []}], "tableCaptions": []}