{"title": [{"text": "These are not the Stereotypes You are Looking For: Bias and Fairness in Authorial Gender Attribution", "labels": [], "entities": [{"text": "Authorial Gender Attribution", "start_pos": 72, "end_pos": 100, "type": "TASK", "confidence": 0.650614062945048}]}], "abstractContent": [{"text": "Stylometric and text categorization results show that author gender can be discerned in texts with relatively high accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.9923627376556396}]}, {"text": "However , it is difficult to explain what gives rise to these results and there are many possible confounding factors, such as the domain, genre, and target audience of a text.", "labels": [], "entities": []}, {"text": "More fundamentally, such classification efforts risk invoking stereotyping and essential-ism.", "labels": [], "entities": []}, {"text": "We explore this issue in two datasets of Dutch literary novels, using commonly used descriptive (LIWC, topic modeling) and predictive (machine learning) methods.", "labels": [], "entities": []}, {"text": "Our results show the importance of controlling for variables in the corpus and we argue for taking care not to overgeneralize from the results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Women write more about emotions, men use more numbers.", "labels": [], "entities": []}, {"text": "Conclusions such as these, based on Natural Language Processing (NLP) research into gender, are not just compelling to a general audience, they are specific and seem objective, and hence are published regularly.", "labels": [], "entities": []}, {"text": "The ethical problem with this type of research however, is that stressing difference-where there is often considerable overlap-comes with the tendency of enlarging the perceived gap between female and male authors; especially when results are interpreted using gender stereotypes.", "labels": [], "entities": []}, {"text": "Moreover, many researchers are not aware of possible confounding variables related to gender, resulting in well-intentioned but unsound research.", "labels": [], "entities": []}, {"text": "But, rather than suggesting not performing research into gender at all, we look into practical solutions to conduct it more soundly.", "labels": [], "entities": []}, {"text": "The reason we do not propose to abandon gender analysis in NLP altogether is that female-male differences are quite striking when it comes to cultural production.", "labels": [], "entities": []}, {"text": "We focus on literary fiction.", "labels": [], "entities": []}, {"text": "Female authors still remain back-benched when it comes to gaining literary prestige: novels by females are still much less likely to be reviewed, or to win a literary award.", "labels": [], "entities": []}, {"text": "Moreover, literary works by female authors are readily compared to popular bestselling genres typically written by and for women, referred to as 'women's novels,' whereas literary works by male authors are rarely gender-labeled or associated with popular genres.", "labels": [], "entities": []}, {"text": "If we want to do research into the gender gap in cultural production, we need to investigate the role of author gender in texts without overgeneralizing to effects more properly explained by text-extrinsic perceptions of gender and literary quality.", "labels": [], "entities": []}, {"text": "In other words, NLP research can be very useful in revealing the mechanisms behind the differences, but in order for that to be possible, researchers need to be aware of the issues, and learn how to avoid essentialistic explanations.", "labels": [], "entities": []}, {"text": "Thus, our question is: how can we use NLP tools to research the relationship between gender and text meaningfully, yet without resorting to stereotyping or essentialism?", "labels": [], "entities": []}, {"text": "Analysis of gender with NLP has roughly two methodological strands, the first descriptive and the second predictive.", "labels": [], "entities": []}, {"text": "First, descriptive, is the technically least complex one.", "labels": [], "entities": []}, {"text": "The researcher divides a set of texts into two parts, half written by female and half by male authors, processes these with the same computational tool(s), and tries to explain the observed differences.", "labels": [], "entities": []}, {"text": "cleverly reinterprets Cixous' notion of\u00e9critureof\u00b4of\u00e9criture f\u00e9minine to validate an examination of female authors separately from male authors (.", "labels": [], "entities": []}, {"text": "The second, at a first glance more neutral strand of automated gender division, is to use predictive methods such as text categorization: training a machine learning model to automatically recognize texts written by either women or men, and to measure the success of its predictions (e.g.,).", "labels": [], "entities": [{"text": "gender division", "start_pos": 63, "end_pos": 78, "type": "TASK", "confidence": 0.7704476714134216}]}, {"text": "combines descriptive and predictive approaches and mines a dataset for distinctive features with respect to gender.", "labels": [], "entities": []}, {"text": "We will apply both descriptive and predictive methods as well.", "labels": [], "entities": []}, {"text": "The rest of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 discusses two theoretical issues that should be considered before starting NLP research into gender: preemptive categorization, and the semblance of objectivity.", "labels": [], "entities": []}, {"text": "These two theoretical issues are related to two potential practical pitfalls, the ones which we hope to remedy with these paper: dataset bias and interpretation bias (Section 3).", "labels": [], "entities": [{"text": "interpretation bias", "start_pos": 146, "end_pos": 165, "type": "TASK", "confidence": 0.9454538524150848}]}, {"text": "In short, if researchers choose to do research into gender (a) they should be much more rigorous in selecting their dataset, i.e., confounding variables need to be given more attention when constructing a dataset; and (b) they need to avoid potential interpretative pitfalls: essentialism and stereotyping.", "labels": [], "entities": []}, {"text": "Lastly, we provide computational evidence for our argument, and give handles on how to deal with the practical issues, based on a corpus of Dutch, literary novels (Sections 4 through 6).", "labels": [], "entities": []}, {"text": "Note that none of the gender-related issues we argue are new, nor is the focus on computational analysis (see).", "labels": [], "entities": [{"text": "computational analysis", "start_pos": 82, "end_pos": 104, "type": "TASK", "confidence": 0.7848409414291382}]}, {"text": "What is novel, however, is the practical application onto contemporary fiction.", "labels": [], "entities": []}, {"text": "We want to show how fairly simple, commonly used computational tools can be applied in away that avoids bias and promotes fairness-in this case with respect to gender, but note that the method is relevant to other categorizations as well.", "labels": [], "entities": []}], "datasetContent": [{"text": "Strictly speaking, a corpus is supposed to represent a statistically representative sample, and the conclusions from experiments with corpora are only valid insofar as this assumption is met.", "labels": [], "entities": []}, {"text": "In gender research, this assumptions is too often violated, as potential confounding factors are not accounted for, exacerbating the ethical issues discussed.", "labels": [], "entities": []}, {"text": "For example, Johannsen et al. work with a corpus of online reviews divided by gender and age.", "labels": [], "entities": []}, {"text": "However, reflected in the dataset is the types of products that men and women tend to review (e.g., cars vs. makeup).", "labels": [], "entities": []}, {"text": "They argue that their use of abstract syntactic features may overcome this domain bias, but this argument is not very convincing.", "labels": [], "entities": []}, {"text": "For example, the use of measurement phrases as a distinctive feature for men can also be explained by its higher relevance in automotive products versus makeup, instead of as a gender marker.", "labels": [], "entities": []}, {"text": "Argamon et al. carefully select texts by men and women from the same domain, French literature, which overcomes this problem.", "labels": [], "entities": []}, {"text": "However, since the corpus is largely based on nineteenth century texts, any conclusions are strongly influenced by literary and gender norms from this time period (which evidently differ from contemporary norms).", "labels": [], "entities": []}, {"text": "compose a corpus from the BNC, which has more recent texts from the 1970s, and includes genre classifications which together with gender are balanced in the resulting corpus.", "labels": [], "entities": [{"text": "BNC", "start_pos": 26, "end_pos": 29, "type": "DATASET", "confidence": 0.9682970643043518}]}, {"text": "Lastly, Sarawgi et al.", "labels": [], "entities": []}, {"text": "(2011) present a study that carefully and systematically controls for topic and genre bias.", "labels": [], "entities": [{"text": "topic and genre bias", "start_pos": 70, "end_pos": 90, "type": "TASK", "confidence": 0.6627283021807671}]}, {"text": "They show that in cross-domain tasks, the performance of gender attribution decreases, and investigate the different characteristics of lexical, syntactic, and character-based features; the latter prove to be most robust.", "labels": [], "entities": []}, {"text": "On the surface the latter two seem to be a reasonable approach of controlling variables where possible.", "labels": [], "entities": []}, {"text": "One remaining issue is the potential for publication bias: if for whatever reason women are less likely to be published, it will be reflected in this corpus without being obvious (a hidden variable).", "labels": [], "entities": []}, {"text": "In sum, controlling for author characteristics should not be neglected.", "labels": [], "entities": []}, {"text": "Moreover, it is often not clear from the datasets whether text variables are sufficiently controlled for either, such as period, text type, or genre. has shown that researchers too easily attribute differences to gender, when in fact other intersecting variables are at play.", "labels": [], "entities": []}, {"text": "We argue that there is still much to gain in the consideration of author and text type characteristics, but we focus on the latter here.", "labels": [], "entities": []}, {"text": "Even within the text type of fictional novels, in a very restricted period of time, as we shall show, there is a variety of subgenres that each have their own characteristics, which might erroneously be attributed to gender.", "labels": [], "entities": []}, {"text": "In order to confirm the results in the previous section, we now apply machine learning methods that have proved most successful in previous work.", "labels": [], "entities": []}, {"text": "Since we want to compare the two corpora, we opt for training and fitting the models on the Riddle corpus, and applying those models to both corpora.", "labels": [], "entities": [{"text": "Riddle corpus", "start_pos": 92, "end_pos": 105, "type": "DATASET", "confidence": 0.7177049964666367}]}], "tableCaptions": [{"text": " Table 1: A selection of LIWC categories with results on the Riddle corpus. The indented categories are  subcategories forming a subset of the preceding category. * indicates a significant result.", "labels": [], "entities": [{"text": "Riddle corpus", "start_pos": 61, "end_pos": 74, "type": "DATASET", "confidence": 0.8088376224040985}]}, {"text": " Table 2: Gender classification scores (F1) on the  Riddle corpus (above) and the Nominees corpus  (below).", "labels": [], "entities": [{"text": "Gender classification", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.7233687043190002}, {"text": "F1", "start_pos": 40, "end_pos": 42, "type": "METRIC", "confidence": 0.9769192337989807}, {"text": "Riddle corpus", "start_pos": 52, "end_pos": 65, "type": "DATASET", "confidence": 0.7739835381507874}, {"text": "Nominees corpus", "start_pos": 82, "end_pos": 97, "type": "DATASET", "confidence": 0.8135417103767395}]}, {"text": " Table 4: Confusion matrices for the SVM results  with BoW. The diagonal indicates the number of  correctly classified texts. The rows show the true  labels, while the columns show the predictions.", "labels": [], "entities": [{"text": "BoW", "start_pos": 55, "end_pos": 58, "type": "DATASET", "confidence": 0.7070945501327515}]}]}