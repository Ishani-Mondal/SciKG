{"title": [{"text": "Automatic detection of stance towards vaccination in online discussion forums", "labels": [], "entities": []}], "abstractContent": [{"text": "A classifier for automatic detection of stance towards vaccination in online forums was trained and evaluated.", "labels": [], "entities": [{"text": "automatic detection of stance towards vaccination in online forums", "start_pos": 17, "end_pos": 83, "type": "TASK", "confidence": 0.8038560052712759}]}, {"text": "Debate posts from six discussion threads on the British parental website Mumsnet were manually annotated for stance against or for vaccination, or as undecided.", "labels": [], "entities": [{"text": "British parental website Mumsnet", "start_pos": 48, "end_pos": 80, "type": "DATASET", "confidence": 0.8918068110942841}]}, {"text": "A support vector machine, trained to detect the three classes, achieved a macro F-score of 0.44, while a macro F-score of 0.62 was obtained by the same type of classifier on the binary classification task of distinguishing stance against vaccination from stance for vaccination.", "labels": [], "entities": [{"text": "F-score", "start_pos": 80, "end_pos": 87, "type": "METRIC", "confidence": 0.962615966796875}, {"text": "F-score", "start_pos": 111, "end_pos": 118, "type": "METRIC", "confidence": 0.9433959722518921}]}, {"text": "These results show that vaccine stance detection in online forums is a difficult task, at least for the type of model investigated and for the relatively small training corpus that was used.", "labels": [], "entities": [{"text": "vaccine stance detection in online forums", "start_pos": 24, "end_pos": 65, "type": "TASK", "confidence": 0.9258791406949362}]}, {"text": "Future work will therefore include an expansion of the training data and an evaluation of other types of classifiers and features.", "labels": [], "entities": []}], "introductionContent": [{"text": "There have been outbreaks of vaccine-preventable diseases that were caused by decreased vaccination rates, which in turn were due to negative attitudes towards vaccination.", "labels": [], "entities": []}, {"text": "Two examples are an outbreak of polio in, which started in northern Nigeria and spread to 15 other countries (, and an outbreak of measles in Minnesota in 2017.", "labels": [], "entities": []}, {"text": "Information on vaccination can be gathered from many different types of sources.", "labels": [], "entities": []}, {"text": "A survey among British parents showed that 34% consulted web-based resources for vaccination information ().", "labels": [], "entities": []}, {"text": "The survey also showed that 31% of the parents that had consulted chat rooms or discussion forums had seen information that \"would make them doubt having their child(ren) immunised or persuade them not to immunise\", compared to 23% for parents consulting Twitter and 8% among all parents included in the survey.", "labels": [], "entities": []}, {"text": "Discussion forums thus form an important outlet for vaccine hesitancy, and this genre might therefore be relevant to automatically monitor for an increase in posts that express a negative stance towards vaccination.", "labels": [], "entities": [{"text": "vaccine hesitancy", "start_pos": 52, "end_pos": 69, "type": "TASK", "confidence": 0.9271756112575531}]}, {"text": "Most previous work on training and evaluation of classifiers for automatic detection of vaccination stance has, however, been carried out on tweets.", "labels": [], "entities": [{"text": "automatic detection of vaccination stance", "start_pos": 65, "end_pos": 106, "type": "TASK", "confidence": 0.7668274819850922}]}, {"text": "In this study, we therefore take on the task of automatic vaccine stance detection of debate posts in online discussion forums.", "labels": [], "entities": [{"text": "vaccine stance detection of debate posts in online discussion forums", "start_pos": 58, "end_pos": 126, "type": "TASK", "confidence": 0.8000133514404297}]}, {"text": "define stance detection as \".] the task of automatically determining from text whether the author of the text is in favor of, against, or neutral toward a proposition or target\".", "labels": [], "entities": [{"text": "stance detection", "start_pos": 7, "end_pos": 23, "type": "TASK", "confidence": 0.8659840226173401}]}, {"text": "They distinguish stance detection from the better known task of sentiment analysis by that \"in stance detection, systems are to determine favorability toward a given (pre-chosen) target of interest\", whereas sentiment analysis is the task of \"determining whether apiece of text is positive, negative, or neutral, or determining from text the speakers opinion and the target of the opinion\".", "labels": [], "entities": [{"text": "stance detection", "start_pos": 17, "end_pos": 33, "type": "TASK", "confidence": 0.9183325469493866}, {"text": "sentiment analysis", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.8793301284313202}, {"text": "stance detection", "start_pos": 95, "end_pos": 111, "type": "TASK", "confidence": 0.8040671646595001}, {"text": "sentiment analysis", "start_pos": 208, "end_pos": 226, "type": "TASK", "confidence": 0.8657324910163879}]}, {"text": "For instance, the utterance \"The diseases that vaccination can protect you from are horrible\" expresses a stance for the pre-chosen target \"vaccination\", while expressing a negative sentiment towards the sentiment-target \"diseases\".", "labels": [], "entities": []}], "datasetContent": [{"text": "A standard text classification approach, in the form of a linear support vector machine model, was applied to the task of automatically classifying the debate posts.", "labels": [], "entities": [{"text": "text classification", "start_pos": 11, "end_pos": 30, "type": "TASK", "confidence": 0.7303604185581207}]}, {"text": "This follows the approach of, as well as of many of the previously performed vaccine sentiment studies.", "labels": [], "entities": [{"text": "vaccine sentiment", "start_pos": 77, "end_pos": 94, "type": "TASK", "confidence": 0.872722715139389}]}, {"text": "The model was trained on all tokens in the training data, as well as on 2-, 3-and 4-grams that occurred at least twice in the data.", "labels": [], "entities": []}, {"text": "The standard NLTK stop word list for English was used for removing non-content words when constructing one set of n-grams.", "labels": [], "entities": []}, {"text": "An additional set of n-grams was generated with a reduced version of this stop word list, which mainly consisted of articles, forms of copula, and forms of \"it\", \"have\" and \"do\".", "labels": [], "entities": []}, {"text": "The reason for using a reduced list was that negations, pronouns etc. that were included in the standard NLTK stop word list can be important cues for classifying argumentative text.", "labels": [], "entities": []}, {"text": "Two types of classifiers were trained: one to perform the task of classifying posts into all three categories annotated, and the other one to perform the task of distinguishing posts annotated as against vaccination from those annotated as for vaccination.", "labels": [], "entities": []}, {"text": "The classifiers were implemented using scikit-learn's LinearSVC class with the default settings.", "labels": [], "entities": []}, {"text": "For training/evaluation, we applied crossvalidation on the 1,190 annotated posts.", "labels": [], "entities": []}, {"text": "Due to the relatively small data size, we used 30 folds, instead of the more standard approach of 10 folds.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Macro and micro F-score for the two ex- periments, i.e., (i) a classifier that classifies posts  as taking a stance against and for vaccination or  being undecided and (ii) a binary classifier that  classifies posts as against or for vaccination.", "labels": [], "entities": [{"text": "F-score", "start_pos": 26, "end_pos": 33, "type": "METRIC", "confidence": 0.8889718055725098}]}, {"text": " Table 2: Confusion matrix and precision/recall- scores for the three-class classifier. The table  also shows the total number of posts annotated as  against, for or undecided.", "labels": [], "entities": [{"text": "Confusion matrix", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.9639745652675629}, {"text": "precision", "start_pos": 31, "end_pos": 40, "type": "METRIC", "confidence": 0.9988592863082886}, {"text": "recall- scores", "start_pos": 41, "end_pos": 55, "type": "METRIC", "confidence": 0.9564141829808553}]}]}