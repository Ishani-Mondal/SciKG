{"title": [], "abstractContent": [{"text": "A semiautomatic lemmatisation procedure for treebanks.", "labels": [], "entities": []}, {"text": "Old English strong and weak verbs.", "labels": [], "entities": []}, {"text": "Abstract The aim of this paper is to present a semiautomatic lemmatisation procedure implemented on database software that is compatible with the morphological tagging of treebanks.", "labels": [], "entities": [{"text": "Abstract", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.8528203368186951}]}, {"text": "The language of analysis is Old English, for which parsed corpora are available but they are not lemmatised.", "labels": [], "entities": []}, {"text": "The scope of the paper includes both strong and weak verbs.", "labels": [], "entities": []}, {"text": "After describing the lemmatisation procedure, the paper discusses the results of automatic searches and compares them with the lists of inflectional forms by lemma provided by other lexicographical sources.", "labels": [], "entities": []}, {"text": "The conclusions insist on the limits of automatic lemmatisation and the compatibility with treebank parsing.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper deals with lemmatisation in a corpus of Old English and focuses on the seven classes of strong verbs, and classes 1 and 2 of weak verbs.", "labels": [], "entities": []}, {"text": "The analysis reported here is based on the lemmatiser Norna, a building block of the lexical database of Old English Nerthus (www.nerthusproject.com).", "labels": [], "entities": [{"text": "Norna", "start_pos": 54, "end_pos": 59, "type": "DATASET", "confidence": 0.8974831700325012}]}, {"text": "Norna, in turn, draws on the information available from the Dictionary of Old English Corpus (hearafter DOEC,), the Helsinki Corpus (, the York-Toronto-Helsinki Parsed Corpus of Old English Prose () and the York-Helsinki Parsed Corpus of Old English Poetry).", "labels": [], "entities": [{"text": "Dictionary of Old English Corpus", "start_pos": 60, "end_pos": 92, "type": "DATASET", "confidence": 0.6596656382083893}, {"text": "Helsinki Corpus", "start_pos": 116, "end_pos": 131, "type": "DATASET", "confidence": 0.9691806435585022}, {"text": "York-Toronto-Helsinki Parsed Corpus of Old English Prose", "start_pos": 139, "end_pos": 195, "type": "TASK", "confidence": 0.7064908359731946}, {"text": "York-Helsinki Parsed Corpus of Old English Poetry", "start_pos": 207, "end_pos": 256, "type": "DATASET", "confidence": 0.8981570431164333}]}, {"text": "Of these, only the York-Toronto-Helsinki Parsed Corpus of Old English Prose () and the York-Helsinki Parsed Corpus of Old English Poetry) are parsed.", "labels": [], "entities": [{"text": "York-Toronto-Helsinki Parsed Corpus of Old English Prose", "start_pos": 19, "end_pos": 75, "type": "DATASET", "confidence": 0.86257175888334}, {"text": "York-Helsinki Parsed Corpus of Old English Poetry", "start_pos": 87, "end_pos": 136, "type": "DATASET", "confidence": 0.9128155963761466}]}, {"text": "The parsing includes syntactic categories and functions as well as lexical and morphological tagging.", "labels": [], "entities": []}, {"text": "For this reason, these corpora are commonly known as treebanks.", "labels": [], "entities": []}, {"text": "In their current state, these treebanks are unlemmatised.", "labels": [], "entities": []}, {"text": "That is to say, the attestations of the inflections of a given lemma are not related to the dictionary word, which results in a lower descriptive power, especially as regards paradigmatic analysis and the quantification of morphological and lexical aspects.", "labels": [], "entities": []}, {"text": "Moreover, the standard dictionaries of Old English, including An Anglo-Saxon Dictionary, A Concise Anglo-Saxon Dictionary and The student's Dictionary of Anglo-Saxon, constitute valuable sources of philological data, although they are not based on an extensive corpus of the language but on the partial list of texts listed in their prefaces or introductions.", "labels": [], "entities": [{"text": "The student's Dictionary of Anglo-Saxon", "start_pos": 126, "end_pos": 165, "type": "DATASET", "confidence": 0.9469375312328339}]}, {"text": "On its part, The Dictionary of Old English (henceforth DOE) is based on the corpus mentioned above, but is still in progress (the letter H was published in 2016).", "labels": [], "entities": [{"text": "The Dictionary of Old English (henceforth DOE)", "start_pos": 13, "end_pos": 59, "type": "DATASET", "confidence": 0.9111563563346863}]}, {"text": "All in all, neither the textual nor the lexicographical sources of Old English are fully lemmatised.", "labels": [], "entities": []}, {"text": "At the same time, treebanks could improve their descriptive power and searchability by incorporating lemma tags.", "labels": [], "entities": []}, {"text": "For these reasons, the aim of this paper is to present a semiautomatic lemmatisation procedure implemented on database software that is compatible with the morphological tagging of treebanks.", "labels": [], "entities": []}, {"text": "The first step was to carryout a concordance of the texts that the Dictionary of Old English provides in its corpus.", "labels": [], "entities": []}, {"text": "The concordance byword consists of three million lines, one per word in the corpus.", "labels": [], "entities": []}, {"text": "The concordance by fragment, in contrast, contains around two hundred thousand fragments of texts identified with the short title with which they appear in the DOEC, as in Eala \u00f0u cleric ne wana \u00f0u aefre wexbreda fram sidan [Abbo 000100 (103.1)].", "labels": [], "entities": [{"text": "DOEC", "start_pos": 160, "end_pos": 164, "type": "DATASET", "confidence": 0.9225680828094482}, {"text": "Abbo 000100 (103.1)]", "start_pos": 225, "end_pos": 245, "type": "DATASET", "confidence": 0.9052981853485107}]}, {"text": "The target of the analysis is the data retrieved from the word concordance to the DOEC, which turns out an index of approximately one hundred and ninety thousand inflectional forms.", "labels": [], "entities": [{"text": "DOEC", "start_pos": 82, "end_pos": 86, "type": "DATASET", "confidence": 0.8405801057815552}]}, {"text": "Once the data has been identified and extracted from the concordance, the process of lemmatisation starts.", "labels": [], "entities": []}, {"text": "The different types of verbs are lemmatised in turn, depending on their formal transparency.", "labels": [], "entities": []}, {"text": "That is to say, strong verbs have been lemmatised in the first place and then weak verbs from the second class have been processed.", "labels": [], "entities": []}, {"text": "The former can be identified by stem and inflectional ending, the latter by inflectional ending only, but their inflectional paradigm is more transparent that the one of the weak verbs from the first and the third class.", "labels": [], "entities": []}, {"text": "Then, weak verbs from class 1 have been lemmatised.", "labels": [], "entities": []}, {"text": "Weak class 3, anomalous, contracted and preterite-present verbs will be dealt within further research.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}