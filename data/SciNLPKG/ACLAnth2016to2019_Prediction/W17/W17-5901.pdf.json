{"title": [{"text": "NTUCLE: Developing a Corpus of Learner English to Provide Writing Support for Engineering Students", "labels": [], "entities": [{"text": "NTUCLE", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9505528807640076}]}], "abstractContent": [{"text": "This paper describes the creation of anew annotated learner corpus.", "labels": [], "entities": []}, {"text": "The aim is to use this corpus to develop an automated system for corrective feedback on students' writing.", "labels": [], "entities": []}, {"text": "With this system, students will be able to receive timely feedback on language errors before they submit their assignments for grading.", "labels": [], "entities": []}, {"text": "A corpus of assignments submitted by first year engineering students was compiled, and anew error tag set for the NTU Corpus of Learner English (NTUCLE) was developed based on that of the NUS Corpus of Learner English (NU-CLE), as well as marking rubrics used at NTU.", "labels": [], "entities": [{"text": "error tag set", "start_pos": 92, "end_pos": 105, "type": "METRIC", "confidence": 0.941625157992045}, {"text": "NTU Corpus of Learner English (NTUCLE)", "start_pos": 114, "end_pos": 152, "type": "DATASET", "confidence": 0.9483696073293686}, {"text": "NUS Corpus of Learner English (NU-CLE)", "start_pos": 188, "end_pos": 226, "type": "DATASET", "confidence": 0.940948374569416}, {"text": "NTU", "start_pos": 263, "end_pos": 266, "type": "DATASET", "confidence": 0.9705937504768372}]}, {"text": "After a description of the corpus, error tag set and annotation process, the paper presents the results of the annotation exercise as well as followup actions.", "labels": [], "entities": []}, {"text": "The final error tag set, which is significantly larger than that for the NUCLE error categories , is then presented before a brief conclusion summarising our experience and future plans.", "labels": [], "entities": [{"text": "NUCLE error categories", "start_pos": 73, "end_pos": 95, "type": "DATASET", "confidence": 0.7593712210655212}]}], "introductionContent": [{"text": "In this paper, we report on anew project which involves the creation of anew annotated Learner Corpus (LC), and which aims to develop an automated system for corrective feedback at Nanyang Technological University (NTU), Singapore.", "labels": [], "entities": [{"text": "Nanyang Technological University (NTU)", "start_pos": 181, "end_pos": 219, "type": "DATASET", "confidence": 0.8792125085989634}]}, {"text": "The goal of this system is to provide immediate feedback to students on possible errors in syntax, grammar and lexis, as well as possible style problems, in their assignment drafts.", "labels": [], "entities": []}, {"text": "In this project, we follow studies such as, which shows that it is not the medium itself (e.g. a computer, a book, a lecturer, etc.) that determines success in learning, it is the quality of the feedback produced by that medium that affects the results.", "labels": [], "entities": []}, {"text": "This is why a language teacher is likely to be a better medium than a book, and the same reason why a properly designed Computer Assisted Language Learning (CALL) system can also be a better medium than writing guidelines, assuming that such systems can provide timely and constructive feedback to the learner.", "labels": [], "entities": []}, {"text": "Given our current course design and manpower constraints, students are much more likely to learn from the system's automated feedback than from receiving the same feedback from tutors, which will take longer, after an assignment has been submitted and graded.", "labels": [], "entities": []}, {"text": "The immediate feedback through the automated system will enable students to address the possible errors before submitting the final versions for assessment.", "labels": [], "entities": []}, {"text": "Consequently, students are more likely to take the feedback seriously because it can be used to improve the quality of the assignment before it is submitted ().", "labels": [], "entities": []}, {"text": "Furthermore, this automated system will enable tutors to focus more attention on areas that require human judgement in their feedback, such as content, organization and use of rhetorical strategies.", "labels": [], "entities": []}, {"text": "To develop the system, we have tagged an LC of 180 written assignments fora course entitled Engineering Communication I, taught at NTU.", "labels": [], "entities": [{"text": "LC", "start_pos": 41, "end_pos": 43, "type": "METRIC", "confidence": 0.9880911111831665}, {"text": "Engineering Communication I", "start_pos": 92, "end_pos": 119, "type": "TASK", "confidence": 0.8077257374922434}, {"text": "NTU", "start_pos": 131, "end_pos": 134, "type": "DATASET", "confidence": 0.9694264531135559}]}, {"text": "We then developed an error coding system based on the 27 labels used in the NUS Corpus of Learner English (NUCLE,) because of similarities in the demographic profile of the participating learners.", "labels": [], "entities": [{"text": "NUS Corpus of Learner English (NUCLE", "start_pos": 76, "end_pos": 112, "type": "DATASET", "confidence": 0.9558129055159432}]}, {"text": "However, we removed some categories and expanded others so the final list consists of 53 labels.", "labels": [], "entities": []}, {"text": "Part of this was to include categories that are not purely grammatical, but pertain to matters of writing style which we are concerned about, some of which can be automatically detected.", "labels": [], "entities": []}, {"text": "These include not only obvious style issues such as the use of contractions and collo-quial words or expressions but also more subtle ones such as overly long and convoluted sentences and missing parallel clause structures.", "labels": [], "entities": []}, {"text": "In this, our corpus distinguishes itself from the Cambridge Learner Corpus), NUCLE and other corpora which focus solely on grammar.", "labels": [], "entities": [{"text": "Cambridge Learner Corpus", "start_pos": 50, "end_pos": 74, "type": "DATASET", "confidence": 0.9630691409111023}, {"text": "NUCLE", "start_pos": 77, "end_pos": 82, "type": "DATASET", "confidence": 0.9415532946586609}]}, {"text": "Our primary motivation for assembling the NTU Corpus of Learner English (NTUCLE), in other words, is to help individual students to identify their language and style problems, and to rectify these on their own.", "labels": [], "entities": [{"text": "NTU Corpus of Learner English (NTUCLE)", "start_pos": 42, "end_pos": 80, "type": "DATASET", "confidence": 0.9456842690706253}]}, {"text": "This is unlike the broader intentions of the CLC, whose error coding and analysis is intended to provide \"lexicographers, researchers, ELT authors and examiners with easy, direct information which they can interpret and use for widely varying purposes\".", "labels": [], "entities": []}, {"text": "Similarly, our initial motivation differs from that of the NUCLE, whose goal is to provide a large data resource for research purposes, and for development of grammatical error correction systems ().", "labels": [], "entities": [{"text": "NUCLE", "start_pos": 59, "end_pos": 64, "type": "DATASET", "confidence": 0.9175562858581543}, {"text": "grammatical error correction", "start_pos": 159, "end_pos": 187, "type": "TASK", "confidence": 0.6054695943991343}]}, {"text": "Our ultimate goal is also different from many current Natural Language Processing (NLP) projects, which appear to focus on building automated grammatical correction tools, with the holy grail of a \"complete end-to-end application\" that can identify and correct mistakes for the writers, with a high degree of precision (see).", "labels": [], "entities": [{"text": "grammatical correction", "start_pos": 142, "end_pos": 164, "type": "TASK", "confidence": 0.7315703481435776}, {"text": "precision", "start_pos": 309, "end_pos": 318, "type": "METRIC", "confidence": 0.9987932443618774}]}, {"text": "Instead, the goal for NTUCLE was to develop a system that will be able to prompt students to review possible mistakes in their writing drafts and correct them on their own.", "labels": [], "entities": [{"text": "NTUCLE", "start_pos": 22, "end_pos": 28, "type": "DATASET", "confidence": 0.753498375415802}]}, {"text": "This will allow learners to participate more meaningfully in the error correction process and to actively identify and choose from multiple options which are often available and would be considered acceptable by different annotators.", "labels": [], "entities": [{"text": "error correction process", "start_pos": 65, "end_pos": 89, "type": "TASK", "confidence": 0.7398707369963328}]}, {"text": "Finally, NTUCLE differs from other similar corpora in its narrower focus on a specific genre (i.e. technical proposals) and target students (i.e. Singaporean engineering undergraduates).", "labels": [], "entities": [{"text": "NTUCLE", "start_pos": 9, "end_pos": 15, "type": "DATASET", "confidence": 0.8368774652481079}]}, {"text": "Nevertheless, we foresee that our project might be expanded to include other genres and groups of learners, though sub categorisation of specific groups of learners and genres will be ensured.", "labels": [], "entities": []}, {"text": "We have now completed annotation of the corpus, and are currently using this to develop the system for providing feedback to students.", "labels": [], "entities": []}, {"text": "This system will detect and tag potential errors in drafts submitted by students, and identify likely errors using our categories.", "labels": [], "entities": []}, {"text": "It will not correct any error, but will prompt, with different degrees of confidence, students to consider whether corrections are needed.", "labels": [], "entities": []}, {"text": "In this way, we hope to encourage students to adopt a more independent and critical approach to error correction.", "labels": [], "entities": [{"text": "error correction", "start_pos": 96, "end_pos": 112, "type": "TASK", "confidence": 0.6540499776601791}]}, {"text": "We also hope to enable a pedagogy focused on timely, high quality feedback to students.", "labels": [], "entities": []}, {"text": "This paper discusses the completed phases of our new LC primarily from the perspective of professional English instructors.", "labels": [], "entities": []}, {"text": "In Section 2, we describe the compilation of the corpus and the establishment of initial error tag set.", "labels": [], "entities": []}, {"text": "We then describe in Section 3 the annotation process, before presenting in Section 4 the outcomes of our initial annotation, including findings on the most frequent errors identified, inter-annotator differences in tagging and how we resolved them.", "labels": [], "entities": []}, {"text": "Section 5 highlights our revised error tag set.", "labels": [], "entities": []}, {"text": "We conclude with a brief note on the corpus release, followed by a summary of our experience and our future plans for the corpus.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Top errors by annotator (before harmonisation)", "labels": [], "entities": []}]}