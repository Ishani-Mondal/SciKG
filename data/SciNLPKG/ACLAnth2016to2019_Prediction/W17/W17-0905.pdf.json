{"title": [{"text": "Behind the Scenes of an Evolving Event Cloze Test", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper analyzes the narrative event cloze test and its recent evolution.", "labels": [], "entities": []}, {"text": "The test removes one event from a docu-ment's chain of events, and systems predict the missing event.", "labels": [], "entities": []}, {"text": "Originally proposed to evaluate learned knowledge of event scenarios (e.g., scripts and frames), most recent work now builds ngram-like language models (LM) to beat the test.", "labels": [], "entities": []}, {"text": "This paper argues that the test has slowly/unknowingly been altered to accommodate LMs.", "labels": [], "entities": []}, {"text": "Most notably, tests are auto-generated rather than by hand, and no effort is taken to include core script events.", "labels": [], "entities": []}, {"text": "Recent work is not clear on evaluation goals and contains contradictory results.", "labels": [], "entities": []}, {"text": "We implement several models, and show that the test's bias to high-frequency events explains the inconsistencies.", "labels": [], "entities": []}, {"text": "We conclude with recommendations on how to return to the test's original intent, and offer brief suggestions on a path forward.", "labels": [], "entities": []}], "introductionContent": [{"text": "A small but growing body of work is looking at learning real-world event knowledge.", "labels": [], "entities": []}, {"text": "One particular area is how to induce event structures called schemas, scripts, or frames.", "labels": [], "entities": []}, {"text": "This is a wide field, but variations on the narrative cloze test are often used to evaluate learned models.", "labels": [], "entities": []}, {"text": "However, their current form has evolved beyond the cloze's original purpose.", "labels": [], "entities": []}, {"text": "It has evolved into a language modeling (LM) task rather than an evaluation of knowledge.", "labels": [], "entities": [{"text": "language modeling (LM) task", "start_pos": 22, "end_pos": 49, "type": "TASK", "confidence": 0.8194979230562845}]}, {"text": "One proposal suggested avoiding the cloze test absent other options), but we argue that it can be useful if carefully formulated.", "labels": [], "entities": []}, {"text": "This is the first paper to evaluate why LMs can seemingly succeed on the event cloze.", "labels": [], "entities": []}, {"text": "This is also the first paper to reconcile contradictory results across recent papers.", "labels": [], "entities": []}, {"text": "We reproduce several models for cloze prediction, include anew instance-based learning model, and show how high-frequency events pollute the test.", "labels": [], "entities": [{"text": "cloze prediction", "start_pos": 32, "end_pos": 48, "type": "TASK", "confidence": 0.8042642176151276}]}, {"text": "We conclude by discussing the future of the cloze in regards to new corpus developments.", "labels": [], "entities": []}], "datasetContent": [{"text": "There are two ways to evaluate event prediction with scripts.", "labels": [], "entities": [{"text": "event prediction", "start_pos": 31, "end_pos": 47, "type": "TASK", "confidence": 0.7159961462020874}]}, {"text": "The first is to follow a single actor through a chain of events, and predict the missing link in the chain.", "labels": [], "entities": []}, {"text": "This prediction ignores other event arguments and only evaluates whether the system predicts the predicate and the correct syntactic position of the entity.", "labels": [], "entities": []}, {"text": "This was part of the original narrative cloze from Chambers and Jurafsky.", "labels": [], "entities": []}, {"text": "The example in Section 2 illustrates such a chain.) proposed a richer test that requires all arguments of the missing event.", "labels": [], "entities": []}, {"text": "A single actor is still tracked through a chain of events, but correct prediction requires the complete event.", "labels": [], "entities": []}, {"text": "We trained on 12.5 million AP documents from Gigaword with duplicates removed.", "labels": [], "entities": [{"text": "AP documents from Gigaword", "start_pos": 27, "end_pos": 53, "type": "DATASET", "confidence": 0.8374269902706146}]}, {"text": "The test set is 1000 random event chains not in training.", "labels": [], "entities": []}, {"text": "Parameters were tuned on a smaller set of dev documents.", "labels": [], "entities": [{"text": "Parameters", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.8872972130775452}]}, {"text": "The best unigram model used our new instance-based learning, but bigrams gain by 8% absolute.", "labels": [], "entities": []}, {"text": "Notably, PMI performs poorly as in and.", "labels": [], "entities": [{"text": "PMI", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.73965984582901}]}, {"text": "However, by adding a frequency cutoff, the poor result is reversed.", "labels": [], "entities": []}, {"text": "shows the cutoff recall curve.", "labels": [], "entities": [{"text": "recall", "start_pos": 17, "end_pos": 23, "type": "METRIC", "confidence": 0.9357089996337891}]}, {"text": "Both papers concluded that PMI was the problem, but we found it is simply the over-evaluation of frequent events.", "labels": [], "entities": [{"text": "PMI", "start_pos": 27, "end_pos": 30, "type": "TASK", "confidence": 0.7188249826431274}]}, {"text": "PMI is known to prefer infrequent events, and this is evident by looking at the information content (IC) of model predictions.", "labels": [], "entities": []}, {"text": "The information content of an event is its log probability in the Gigaword Corpus.", "labels": [], "entities": [{"text": "Gigaword Corpus", "start_pos": 66, "end_pos": 81, "type": "DATASET", "confidence": 0.9579902291297913}]}, {"text": "What types of events do language models predict?", "labels": [], "entities": []}, {"text": "shows that the average LM prediction contains far less information.", "labels": [], "entities": []}, {"text": "Perhaps more clear, shows an actual list of predictions for one cloze test.", "labels": [], "entities": []}, {"text": "The n-gram models predict frequent events, but PMI predicts seemingly more meaningful events.", "labels": [], "entities": []}, {"text": "We are not arguing in favor of PMI as a model, but simply illustrating how frequency explains almost all of the contradictions in previous work.", "labels": [], "entities": [{"text": "PMI", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.9433445930480957}]}], "tableCaptions": [{"text": " Table 1: Single entity event chain results.", "labels": [], "entities": [{"text": "Single entity event chain", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.6763747334480286}]}, {"text": " Table 2: Multiple argument event chain results.", "labels": [], "entities": [{"text": "Multiple argument event chain", "start_pos": 10, "end_pos": 39, "type": "TASK", "confidence": 0.7204178124666214}]}]}