{"title": [], "abstractContent": [{"text": "Machine translation quality estimation is a challenging task in the WMT evaluation campaign.", "labels": [], "entities": [{"text": "Machine translation quality estimation", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.8358475863933563}, {"text": "WMT evaluation", "start_pos": 68, "end_pos": 82, "type": "TASK", "confidence": 0.8298664093017578}]}, {"text": "Feature extraction plays an important role in automatic quality estimation, and in this paper, we propose neural network features , including embedding features and cross-entropy features of source sentences and machine translations, to improve machine translation quality estimation.", "labels": [], "entities": [{"text": "Feature extraction", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7599378526210785}, {"text": "automatic quality estimation", "start_pos": 46, "end_pos": 74, "type": "TASK", "confidence": 0.6041423479715983}, {"text": "machine translation quality estimation", "start_pos": 245, "end_pos": 283, "type": "TASK", "confidence": 0.7277563661336899}]}, {"text": "The sentence embedding features are extracted through global average pooling from word embedding and are trained by the word2vec toolkits, while the sentence cross-entropy features are calculated by the recurrent neural network language model.", "labels": [], "entities": []}, {"text": "The experimental results on the development set of WMT17 machine translation quality estimation tasks show that the neural network features gain significant improvements over the baseline.", "labels": [], "entities": [{"text": "WMT17 machine translation quality estimation", "start_pos": 51, "end_pos": 95, "type": "TASK", "confidence": 0.7645622253417969}]}, {"text": "Furthermore, when combining the neural network features and the baseline features, the system performance obtains further improvement.", "labels": [], "entities": []}], "introductionContent": [{"text": "Quality estimation (QE) of machine translation estimates the quality of machine translation system outputs without human references using machine learning methods.", "labels": [], "entities": [{"text": "Quality estimation (QE) of machine translation", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.633979931473732}]}, {"text": "It is often divided into two steps: first, it extracts various features from source sentences, translation outputs, and external language resources to describe the translation complexity, fluency and adequacy; and second, it predicts the quality of the translation outputs with the pre-trained machine learning model.", "labels": [], "entities": []}, {"text": "Feature extraction is crucial to the performance of QE, and traditional methods, such as QuEst (, extract linguistically motivated features to improve the correlation between the automatic QE and human assessment.", "labels": [], "entities": [{"text": "Feature extraction", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7672112286090851}, {"text": "QE", "start_pos": 52, "end_pos": 54, "type": "TASK", "confidence": 0.9050624966621399}]}, {"text": "However, extracting linguistically motivated features requires part-of-speech analysis, syntactic analysis, or semantic analysis, and these linguistic analyses relate to the target language types; this consideration limits their application in other languages.", "labels": [], "entities": [{"text": "syntactic analysis", "start_pos": 88, "end_pos": 106, "type": "TASK", "confidence": 0.7570888102054596}, {"text": "semantic analysis", "start_pos": 111, "end_pos": 128, "type": "TASK", "confidence": 0.7066373825073242}]}, {"text": "To address this problem, investigated continuous space language models for sentence-level QE, and proposed word embedding features for documentlevel QE.", "labels": [], "entities": []}, {"text": "Inspired by their work, we propose sentence embedding features and cross-entropy features to improve the correlation between automatic QE and human assessment and to investigate how different sentence embedding dimensions of source sentences and translation outputs, as well as the size of the training corpus, affect the system performance of QE.", "labels": [], "entities": []}], "datasetContent": [{"text": "To test the performance of the neural network features for the QE task, we conduct experiments on the development set of the WMT17 sentence-level QE task.", "labels": [], "entities": [{"text": "WMT17 sentence-level QE task", "start_pos": 125, "end_pos": 153, "type": "DATASET", "confidence": 0.7351862639188766}]}, {"text": "The WMT17 sentence-level QE task contains two translation directions: English to German (en-de) and German to English (de-en).", "labels": [], "entities": [{"text": "WMT17 sentence-level QE task", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.5639123767614365}]}, {"text": "Among them, the en-de corpus concerns the IT domain, while de-en concerns the pharmaceutical domain.", "labels": [], "entities": []}, {"text": "The training set of the en-de direction consists of 23,000 sentences; the development set consists of 1,000 sentences.", "labels": [], "entities": []}, {"text": "The training set of the de-en direction consists of 25,000 sentences; the development set consists of 1,000 sentences.", "labels": [], "entities": []}, {"text": "A test set of 2,000 sentences is provided for each direction.", "labels": [], "entities": []}, {"text": "HTER () is provided as an estimation index for the translation quality of each training set and development set.", "labels": [], "entities": [{"text": "HTER", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.5134977102279663}]}, {"text": "The task of the participants is to establish a QE model to predict the HTER, with the source language sentences and their machine translations.", "labels": [], "entities": []}, {"text": "To train the word embedding and the RNNLM, the source side and the target side of the bilingual parallel corpus for the translation task, publicly released by the WMT evaluation campaign, are used; they include Europarl v7, Common Crawl corpus, News Commentary v8 and v11; Batch1 and Batch2, localization PO files, IT-related terms from Wikipedia 3 ; WMT16 and WMT17 QE task1 corpus.", "labels": [], "entities": [{"text": "RNNLM", "start_pos": 36, "end_pos": 41, "type": "DATASET", "confidence": 0.46133583784103394}, {"text": "translation task", "start_pos": 120, "end_pos": 136, "type": "TASK", "confidence": 0.9005753099918365}, {"text": "WMT evaluation", "start_pos": 163, "end_pos": 177, "type": "DATASET", "confidence": 0.7693895697593689}, {"text": "Europarl", "start_pos": 211, "end_pos": 219, "type": "DATASET", "confidence": 0.960669219493866}, {"text": "Common Crawl corpus", "start_pos": 224, "end_pos": 243, "type": "DATASET", "confidence": 0.8344538410504659}, {"text": "WMT16", "start_pos": 351, "end_pos": 356, "type": "DATASET", "confidence": 0.9573881030082703}, {"text": "WMT17 QE task1 corpus", "start_pos": 361, "end_pos": 382, "type": "DATASET", "confidence": 0.8875458538532257}]}, {"text": "The statistics of the bilingual parallel corpus are shown in, the corpus are shared for the two translation directions.", "labels": [], "entities": []}, {"text": "The Support Vector Regression (SVR) model is utilized for the QE.", "labels": [], "entities": [{"text": "Support Vector Regression (SVR)", "start_pos": 4, "end_pos": 35, "type": "METRIC", "confidence": 0.8129737675189972}, {"text": "QE", "start_pos": 62, "end_pos": 64, "type": "TASK", "confidence": 0.5297935605049133}]}, {"text": "To implement the model, we use the Python machine learning toolkit: scikitlearn , and the radial basis function is chosen for the SVR kernel function, the grid search algorithm for parameter optimization.", "labels": [], "entities": []}, {"text": "The metrics included Pearson's correlation coefficient (Pearson r), Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), Spearman's correlation coefficient (Spearman \u03c1) and Delta Average (DeltaAvg), which were used to evaluate the performance of the QE model.", "labels": [], "entities": [{"text": "Pearson's correlation coefficient (Pearson r)", "start_pos": 21, "end_pos": 66, "type": "METRIC", "confidence": 0.9534657150506973}, {"text": "Mean Absolute Error (MAE)", "start_pos": 68, "end_pos": 93, "type": "METRIC", "confidence": 0.9695545931657156}, {"text": "Root Mean Squared Error (RMSE)", "start_pos": 95, "end_pos": 125, "type": "METRIC", "confidence": 0.8567182506833758}, {"text": "Spearman's correlation coefficient (Spearman \u03c1)", "start_pos": 127, "end_pos": 174, "type": "METRIC", "confidence": 0.7624536156654358}, {"text": "Delta Average (DeltaAvg)", "start_pos": 179, "end_pos": 203, "type": "METRIC", "confidence": 0.9408527135848999}]}, {"text": "Pearson rand Spearman \u03c1 are set as primary metrics for scoring and ranking the evaluation respectively, and higher scores mean better correlations between QE and HTER.", "labels": [], "entities": [{"text": "Pearson rand Spearman \u03c1", "start_pos": 0, "end_pos": 23, "type": "METRIC", "confidence": 0.5741536542773247}, {"text": "QE", "start_pos": 155, "end_pos": 157, "type": "METRIC", "confidence": 0.9710959196090698}]}], "tableCaptions": [{"text": " Table 1: The entropy of each language in the  WMT17 QE development set trained by the  RNNLM toolkit.", "labels": [], "entities": [{"text": "WMT17 QE development set", "start_pos": 47, "end_pos": 71, "type": "DATASET", "confidence": 0.8863973617553711}, {"text": "RNNLM toolkit", "start_pos": 88, "end_pos": 101, "type": "DATASET", "confidence": 0.8845249116420746}]}, {"text": " Table 4: Results of the de-en direction on the development set of the WMT17 QE, task1.", "labels": [], "entities": [{"text": "WMT17 QE", "start_pos": 71, "end_pos": 79, "type": "DATASET", "confidence": 0.8782950937747955}]}, {"text": " Table 5: The system performance on the test set of the WMT16 QE and WMT17 QE", "labels": [], "entities": [{"text": "WMT16 QE", "start_pos": 56, "end_pos": 64, "type": "DATASET", "confidence": 0.9376507997512817}, {"text": "WMT17 QE", "start_pos": 69, "end_pos": 77, "type": "DATASET", "confidence": 0.8508790135383606}]}]}