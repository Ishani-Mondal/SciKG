{"title": [{"text": "Transparent text quality assessment with convolutional neural networks *", "labels": [], "entities": [{"text": "Transparent text quality assessment", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.7741060107946396}]}], "abstractContent": [{"text": "We present a very simple model for text quality assessment based on a deep con-volutional neural network, where the only supervision required is one corpus of user-generated text of varying quality, and one contrasting text corpus of consistently high quality.", "labels": [], "entities": [{"text": "text quality assessment", "start_pos": 35, "end_pos": 58, "type": "TASK", "confidence": 0.7923027475674947}]}, {"text": "Our model is able to provide local quality assessments in different parts of a text, which allows visual feedback about where potentially problematic parts of the text are located, as well as away to evaluate which textual features are captured by our model.", "labels": [], "entities": []}, {"text": "We evaluate our method on two corpora: a large corpus of manually graded student essays and a longitudinal corpus of language learner written production, and find that the text quality metric learned by our model is a fairly strong predictor of both essay grade and learner proficiency level.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "We train two models, as described in Section 2.1: one using only the professional-amateur distinction (axioms 1+2) and one also using the variation in the blog corpus (axioms 1+2+3+4).", "labels": [], "entities": []}, {"text": "The former turns out to be very poor at estimating text quality, and is only briefly discussed in Section 3.2.", "labels": [], "entities": []}, {"text": "For the rest of this section, the 1+2+3+4 model is used throughout.", "labels": [], "entities": []}, {"text": "To illustrate the transparency of the model, Table 1 contains example sentences sampled from two text corpora (Blogs and News).", "labels": [], "entities": []}, {"text": "In general we can see that the news examples are ranked higher than the blog examples, which is to be expected since the model was trained in part to distinguish between these corpora.", "labels": [], "entities": []}, {"text": "The only exception is the second news sentence, whose score the visualization indicates is pulled down by the first word, 'domen' (the sentence).", "labels": [], "entities": []}, {"text": "This turns out to be a homograph of 'dom', a spoken-language form of the third person plural pronoun, which is generally avoided in written Swedish and a strong indicator of either an informal style or poor command of Swedish (since the written language makes a case distinction which does not exist in the modern spoken language).", "labels": [], "entities": []}, {"text": "Other low-scoring features include smileys, frequent use of ellipsis, and informal spellings such as 'ox\u00e5' for 'ocks\u00e5' (also).", "labels": [], "entities": [{"text": "smileys", "start_pos": 35, "end_pos": 42, "type": "METRIC", "confidence": 0.8963940739631653}]}, {"text": "Some of these are typical for informal Internet text, and would easily be avoided in e.g. a highstakes essay setting.", "labels": [], "entities": []}, {"text": "However, rather than low scores stemming from occasional features of poor or informal writing, it seems that the consistent lack of a richer vocabulary is a more important factor.", "labels": [], "entities": []}], "tableCaptions": []}