{"title": [{"text": "Utterance Intent Classification of a Spoken Dialogue System with Efficiently Untied Recursive Autoencoders", "labels": [], "entities": [{"text": "Utterance Intent Classification", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.828314205010732}]}], "abstractContent": [{"text": "Recursive autoencoders (RAEs) for com-positionality of a vector space model were applied to utterance intent classification of a smartphone-based Japanese-language spoken dialogue system.", "labels": [], "entities": [{"text": "utterance intent classification", "start_pos": 92, "end_pos": 123, "type": "TASK", "confidence": 0.7341418663660685}]}, {"text": "Though the RAEs express a nonlinear operation on the vectors of child nodes, the operation is considered to be different intrinsically depending on types of child nodes.", "labels": [], "entities": []}, {"text": "To relax the difference, a data-driven untying of autoencoders (AEs) is proposed.", "labels": [], "entities": []}, {"text": "The experimental result of the utterance intent classification showed an improved accuracy with the proposed method compared with the basic tied RAE and untied RAE based on a manual rule.", "labels": [], "entities": [{"text": "utterance intent classification", "start_pos": 31, "end_pos": 62, "type": "TASK", "confidence": 0.8717924753824869}, {"text": "accuracy", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.9994980096817017}]}], "introductionContent": [{"text": "A spoken dialogue system needs to estimate the utterance intent correctly despite of various oral expressions.", "labels": [], "entities": []}, {"text": "It has been a basic approach to classify the result of automatic speech recognition (ASR) of an utterance into one of multiple predefined intent classes, followed with slot filling specific to the estimated intent class.", "labels": [], "entities": [{"text": "classify the result of automatic speech recognition (ASR) of an utterance", "start_pos": 32, "end_pos": 105, "type": "TASK", "confidence": 0.8315269442705008}]}, {"text": "There have been active studies on word embedding techniques (,, where a continuous real vector of a relatively low dimension is estimated for every word from a distribution of word co-occurence in a large-scale corpus, and on compositionality techniques,, which estimate real vectors of phrases and clauses through arithmetic operations on the word embeddings.", "labels": [], "entities": []}, {"text": "Among them, a series of compositionality models by Socher, such as recursive autoencoders, matrix-vector model which models the dependencies explicitly), compositional vector grammar which combines a probabilistic context free grammar (PCFG) parser with compositional vectors () and the neural tensor network) are gaining attention.", "labels": [], "entities": []}, {"text": "The methods which showed effectiveness in polarity estimation, sentiment distribution and paraphrase detection are effective in utterance intent classification task (,.", "labels": [], "entities": [{"text": "polarity estimation", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.700954481959343}, {"text": "sentiment distribution", "start_pos": 63, "end_pos": 85, "type": "TASK", "confidence": 0.8828419148921967}, {"text": "paraphrase detection", "start_pos": 90, "end_pos": 110, "type": "TASK", "confidence": 0.7992964088916779}, {"text": "utterance intent classification task", "start_pos": 128, "end_pos": 164, "type": "TASK", "confidence": 0.8413659185171127}]}, {"text": "The accuracy of intent classification should improve if the compositional vector gives richer relations between words and phrases compared to thesaurus combined with a conventional bag-of-words model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9991222023963928}, {"text": "intent classification", "start_pos": 16, "end_pos": 37, "type": "TASK", "confidence": 0.7302645742893219}]}, {"text": "Japanese, an agglutative language, has a relatively flexible word order though it does have an underlying subject-object-verb (SOV) order.", "labels": [], "entities": []}, {"text": "In colloquial expressions, the word order becomes more flexible.", "labels": [], "entities": []}, {"text": "In this paper, we applied the recursive autoencoder (RAE) to the utterance intent classification of a smartphone-based Japaneselanguage spoken dialogue system.", "labels": [], "entities": [{"text": "recursive autoencoder (RAE)", "start_pos": 30, "end_pos": 57, "type": "METRIC", "confidence": 0.8043478727340698}, {"text": "utterance intent classification", "start_pos": 65, "end_pos": 96, "type": "TASK", "confidence": 0.6652253170808157}]}, {"text": "The original RAE uses a single tied autoencoder (AE) for all nodes in a tree.", "labels": [], "entities": [{"text": "single tied autoencoder (AE)", "start_pos": 24, "end_pos": 52, "type": "METRIC", "confidence": 0.7504894137382507}]}, {"text": "We applied multiple AEs that were untied depending on node types, because the operations must intrinsically differ depending on the node types of word and phrases.", "labels": [], "entities": []}, {"text": "In terms of syntactic untying, the convolutional vector grammar () introduced syntactic untying.", "labels": [], "entities": []}, {"text": "However, a syntactic parser is not easy to apply to colloquial Japanese expressions.", "labels": [], "entities": []}, {"text": "Hence, to obtain an efficient untying of AEs, we propose a data-driven untying of AEs based on a regression tree.", "labels": [], "entities": []}, {"text": "The regression tree is formed to reduce the total error of reconstructing child nodes with AEs.", "labels": [], "entities": []}, {"text": "We compare the accuracies of utterance intent classification among the RAEs of a single tied AE, AEs untied with a manually defined rule, and AEs untied with a data-driven split method.", "labels": [], "entities": [{"text": "utterance intent classification", "start_pos": 29, "end_pos": 60, "type": "TASK", "confidence": 0.7592882513999939}]}], "datasetContent": [{"text": "An experiment of utterance intent classification was conducted with the annotated data described in Section 2.", "labels": [], "entities": [{"text": "utterance intent classification", "start_pos": 17, "end_pos": 48, "type": "TASK", "confidence": 0.8459820747375488}]}, {"text": "The number of classes was reduced to 65 by merging classes with few pieces of data with a similar class or into the others class.", "labels": [], "entities": []}, {"text": "Considering the balance of frequent utterances and less-frequent ones, the frequencies of utterances were smoothed by applying a square root function.", "labels": [], "entities": []}, {"text": "The numbers of utterances in the training and test sets were 7,833 and 870, respectively.", "labels": [], "entities": []}, {"text": "The ratio of unknown utterances in the test set was 15 percent.", "labels": [], "entities": []}, {"text": "Two types of word vectors, ramdom word vectors and word2vec vectors, were compared as the minimal elements of a tree.", "labels": [], "entities": []}, {"text": "A total of 1.08 million word2vec vectors were trained with Japanese wikipedia texts of 1.1 billion words.", "labels": [], "entities": []}, {"text": "The dimension of the vectors was fixed at 100.", "labels": [], "entities": []}, {"text": "The word2vec vectors were trained by using skip-gram mode on the basis of results of preliminary experiments.", "labels": [], "entities": []}, {"text": "Three types of RAE, that is, a single tied AE, two AEs untied by the manual rule, and multiple AEs untied by the data-driven split, and a baseline method of cosine similarity of bag-of-words were evaluated.", "labels": [], "entities": [{"text": "RAE", "start_pos": 15, "end_pos": 18, "type": "METRIC", "confidence": 0.6271910667419434}, {"text": "AE", "start_pos": 43, "end_pos": 45, "type": "METRIC", "confidence": 0.918531060218811}, {"text": "AEs", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.9557011127471924}]}, {"text": "shows the precision, recall, and accuracy of the classification for the training and test sets.", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9997184872627258}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9993451237678528}, {"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9996485710144043}]}, {"text": "The baseline method (1) showed relatively high performance, because the test set randomly chosen in consideration of the smoothed frequencies contained many known utterances and words seen in the training set.", "labels": [], "entities": []}, {"text": "The tied RAE based on word2vec vectors (3) showed significantly better performance than the tied RAE based on random word vectors (2).", "labels": [], "entities": []}, {"text": "While the RAE of two AEs untied by a manual rule (4) made a slight improvement, the RAE of two AEs untied by data-driven split (5) made more improvement.", "labels": [], "entities": [{"text": "RAE", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9541736245155334}, {"text": "RAE", "start_pos": 84, "end_pos": 87, "type": "METRIC", "confidence": 0.7981138229370117}]}, {"text": "The resulting split was not simple, but one of the two AEs was to add a modifier, roughly speaking.", "labels": [], "entities": [{"text": "AEs", "start_pos": 55, "end_pos": 58, "type": "METRIC", "confidence": 0.9218900799751282}]}, {"text": "However, the RAE of three AEs untied by data-driven split (6) showed a fall.", "labels": [], "entities": [{"text": "RAE", "start_pos": 13, "end_pos": 16, "type": "METRIC", "confidence": 0.9961035251617432}, {"text": "AEs", "start_pos": 26, "end_pos": 29, "type": "METRIC", "confidence": 0.9564730525016785}]}, {"text": "We believe that the RAE was probably overlearned with thousands pieces of training data.", "labels": [], "entities": [{"text": "RAE", "start_pos": 20, "end_pos": 23, "type": "DATASET", "confidence": 0.5134714245796204}]}], "tableCaptions": [{"text": " Table 2: Precision, recall, and accuracy of utterance intent classification of 65 classes  .", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9673448801040649}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9940261840820312}, {"text": "accuracy of utterance intent classification", "start_pos": 33, "end_pos": 76, "type": "TASK", "confidence": 0.6854519754648208}]}]}