{"title": [{"text": "Key-Value Retrieval Networks for Task-Oriented Dialogue", "labels": [], "entities": [{"text": "Key-Value Retrieval", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7036105245351791}]}], "abstractContent": [{"text": "Neural task-oriented dialogue systems often struggle to smoothly interface with a knowledge base.", "labels": [], "entities": [{"text": "Neural task-oriented dialogue", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7464818755785624}]}, {"text": "In this work, we seek to address this problem by proposing anew neural dialogue agent that is able to effectively sustain grounded, multi-domain discourse through a novel key-value retrieval mechanism.", "labels": [], "entities": []}, {"text": "The model is end-to-end dif-ferentiable and does not need to explicitly model dialogue state or belief trackers.", "labels": [], "entities": []}, {"text": "We also release anew dataset of 3,031 dialogues that are grounded through underlying knowledge bases and span three distinct tasks in the in-car personal assistant space: calendar scheduling, weather information retrieval, and point-of-interest navigation.", "labels": [], "entities": [{"text": "calendar scheduling", "start_pos": 171, "end_pos": 190, "type": "TASK", "confidence": 0.7401920855045319}, {"text": "weather information retrieval", "start_pos": 192, "end_pos": 221, "type": "TASK", "confidence": 0.6107284426689148}, {"text": "point-of-interest navigation", "start_pos": 227, "end_pos": 255, "type": "TASK", "confidence": 0.729069173336029}]}, {"text": "Our architecture is simultaneously trained on data from all domains and significantly outperforms a competitive rule-based system and other existing neural dialogue architectures on the provided domains according to both automatic and human evaluation metrics.", "labels": [], "entities": []}], "introductionContent": [{"text": "With the success of new speech-based humancomputer interfaces, there is a great need for effective task-oriented dialogue agents that can handle everyday tasks such as scheduling events and booking hotels.", "labels": [], "entities": []}, {"text": "Current commercial dialogue agents are often brittle pattern-matching systems which are unable to maintain the kind of flexible conversations that people desire.", "labels": [], "entities": []}, {"text": "Neural dialogue agents present one of the most promising avenues for leveraging dialogue corpora to build statistical models directly from data by using powerful distributed representations I have 3 appointments scheduled, with Alex, your sister, and Jeff.", "labels": [], "entities": []}, {"text": "Which are you referring to?", "labels": [], "entities": []}, {"text": "DRIVER: I want to know about the one that Alexis joining meat CAR: That optometrist appointment is at 4 pm.", "labels": [], "entities": [{"text": "DRIVER", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9221449494361877}, {"text": "CAR", "start_pos": 62, "end_pos": 65, "type": "METRIC", "confidence": 0.5944597125053406}]}, {"text": "DRIVER: Thanks CAR: no problem Figure 1: Sample dialogue from our dataset.", "labels": [], "entities": [{"text": "DRIVER", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.7642616033554077}, {"text": "CAR", "start_pos": 15, "end_pos": 18, "type": "METRIC", "confidence": 0.951884388923645}, {"text": "Sample dialogue", "start_pos": 41, "end_pos": 56, "type": "TASK", "confidence": 0.8919049203395844}]}, {"text": "Note some columns and rows from the knowledge base are not included due to space constraints.", "labels": [], "entities": []}, {"text": "A dash indicates a missing value.", "labels": [], "entities": [{"text": "dash", "start_pos": 2, "end_pos": 6, "type": "METRIC", "confidence": 0.9814659357070923}]}, {"text": "While this work has been somewhat successful, these task-oriented neural dialogue models suffer from a number of problems: 1) They struggle to effectively reason over and incorporate knowledge base information while still preserving their endto-end trainability and 2) They often require explicitly modelling user dialogues with belief trackers and dialogue state information, which necessitates additional data annotation and also breaks differentiability.", "labels": [], "entities": []}, {"text": "To address some of the modelling issues in previous neural dialogue agents, we introduce anew architecture called the Key-Value Retrieval Network.", "labels": [], "entities": []}, {"text": "This model augments existing recurrent network architectures with an attention-based key-value retrieval mechanism over the entries of a knowledge base, which is inspired by recent work on key-value memory networks.", "labels": [], "entities": []}, {"text": "By doing so, it is able to learn how to extract useful information from a knowledge base directly from data in an end-to-end fashion, with-out the need for explicit training of belief or intent trackers as is done in traditional task-oriented dialogue systems.", "labels": [], "entities": []}, {"text": "The architecture has no dependence on the specifics of the data domain, learning how to appropriately incorporate world knowledge into its dialogue utterances via attention over the key-value entries of the underlying knowledge base.", "labels": [], "entities": []}, {"text": "In addition, we introduce and make publicly available anew corpus of 3,031 dialogues spanning three different domain types in the incar personal assistant space: calendar scheduling, weather information retrieval, and point-ofinterest navigation.", "labels": [], "entities": [{"text": "calendar scheduling", "start_pos": 162, "end_pos": 181, "type": "TASK", "confidence": 0.7484733462333679}, {"text": "weather information retrieval", "start_pos": 183, "end_pos": 212, "type": "TASK", "confidence": 0.6307612558205923}, {"text": "point-ofinterest navigation", "start_pos": 218, "end_pos": 245, "type": "TASK", "confidence": 0.6708247363567352}]}, {"text": "The dialogues are grounded through knowledge bases.", "labels": [], "entities": []}, {"text": "This makes them ideal for building dialogue architectures that seamlessly reason over world knowledge.", "labels": [], "entities": []}, {"text": "The multi-domain nature of the dialogues in the corpus also makes this dataset an apt test bed for generalizability of modelling architectures.", "labels": [], "entities": []}, {"text": "The main contributions of our work are therefore two-fold: 1) We introduce the Key-Value Retrieval Network, a highly performant neural taskoriented dialogue agent that is able to smoothly incorporate information from underlying knowledge bases through a novel key-value retrieval mechanism.", "labels": [], "entities": []}, {"text": "Unlike other dialogue agents which only rely on prior dialogue history for generation, our architecture is able to access and use database-style information, while still retaining the text generation advantages of recent neural models.", "labels": [], "entities": [{"text": "text generation", "start_pos": 184, "end_pos": 199, "type": "TASK", "confidence": 0.6939727663993835}]}, {"text": "By doing so, our model outperforms a competitive rulebased system and other baseline neural models on a number of automatic metrics as well as human evaluation.", "labels": [], "entities": []}, {"text": "2) We release anew publicly-available dialogue corpus across three distinct domains in the in-car personal assistant space that we hope will help further work on task-oriented dialogue agents.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we first introduce the details of the experiments and then present results from both automatic and human evaluation.", "labels": [], "entities": []}, {"text": "We randomly generated 120 distinct scenarios across the three dialogue domains, where a scenario is defined by an underlying KB as well as a user goal for the dialogue (e.g. find the nearest gas station, avoiding heavy traffic).", "labels": [], "entities": []}, {"text": "We then paired Amazon Mechanical Turkers with one of our systems in a real-time chat environment, where each Turker played the role of the Driver.", "labels": [], "entities": []}, {"text": "We evaluated the rule-based model, Copy Net, and key-value retrieval network on each of the 120 scenarios.", "labels": [], "entities": []}, {"text": "We also paired a Turker with another Turker for each of the scenarios, in order to get evaluations of human performance.", "labels": [], "entities": []}, {"text": "At the end of the chat, the Turker was asked to judge the quality of their partner according to fluency, cooperativeness, and humanlikeness on a scale from 1 to 5.", "labels": [], "entities": []}, {"text": "The average scores per pairing are reported in.", "labels": [], "entities": []}, {"text": "Ina separate experiment, we also had Turkers evaluate the outputs of the systems on 80 randomly selected dialogues from the test split of our dataset.", "labels": [], "entities": []}, {"text": "Those outputs were evaluated according to correctness, appropriateness, and humanlikeness of the responses, and the scores are reported in Table 5.", "labels": [], "entities": [{"text": "correctness", "start_pos": 42, "end_pos": 53, "type": "METRIC", "confidence": 0.9772709012031555}]}, {"text": "We see that on real-time dialogues the key-value retrieval network outperforms the baseline models on all of the metrics, with especially sizeable performance gains over the Copy Net which is the only other recurrent neural model evaluated.", "labels": [], "entities": []}, {"text": "We also see that human performance on this assessment sets the upper bound on scores, as expected.", "labels": [], "entities": []}, {"text": "The results on human evaluation of test outputs show that the rule-based model provides the most correct system responses, the KV network provides the most appropriate responses, and the Copy Net gives the most humanlike responses by small margins.", "labels": [], "entities": [{"text": "KV network", "start_pos": 127, "end_pos": 137, "type": "DATASET", "confidence": 0.8310464918613434}, {"text": "Copy Net", "start_pos": 187, "end_pos": 195, "type": "DATASET", "confidence": 0.8068460524082184}]}, {"text": "We should note, however, that the second regime for human evaluation is more unrealistic because it involves providing a dialogue context that is directly sampled from our dataset, whereas the first regime of real-time dialogues measures the models' abilities to adapt to new and noisier user input.", "labels": [], "entities": []}, {"text": "This suggests that the first set of results are more meaningful and representative for assessing overall model efficacy.", "labels": [], "entities": []}, {"text": "Examples of dialogues conducted between our model and Turkers are included in.", "labels": [], "entities": [{"text": "Turkers", "start_pos": 54, "end_pos": 61, "type": "DATASET", "confidence": 0.8620524406433105}]}, {"text": "Particularly noteworthy is our model's ability to seamlessly integrate world information from the underlying KBs in the respective dialogues, while  your next swimming activity is on the 11th at 3pm.", "labels": [], "entities": []}, {"text": "DRIVER: who is gonna attend with me?", "labels": [], "entities": []}, {"text": "CAR: your swimming activity is on the 11th, one at 3pm with sister DRIVER: thank you!", "labels": [], "entities": [{"text": "DRIVER", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.9815115332603455}]}], "tableCaptions": [{"text": " Table 1: Slots types and number distinct slot values for different domains. POI denotes point-of-interest.", "labels": [], "entities": [{"text": "POI", "start_pos": 77, "end_pos": 80, "type": "METRIC", "confidence": 0.9779844880104065}]}, {"text": " Table 2: Statistics of Dataset.", "labels": [], "entities": [{"text": "Statistics of Dataset", "start_pos": 10, "end_pos": 31, "type": "DATASET", "confidence": 0.7402981718381246}]}, {"text": " Table 3: Evaluation on our test data. Bold values indicate best model performance. We provide both  an aggregated F 1 score as well as domain-specific F 1 scores. Attn. Seq2Seq refers to a sequence-to- sequence model with encoder attention. KV Retrieval Net (no enc. attn.) refers to our new model with  no encoder attention context vector computed during decoding.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 115, "end_pos": 124, "type": "METRIC", "confidence": 0.9475192427635193}, {"text": "F 1", "start_pos": 152, "end_pos": 155, "type": "METRIC", "confidence": 0.8844656646251678}, {"text": "KV Retrieval Net", "start_pos": 242, "end_pos": 258, "type": "DATASET", "confidence": 0.8235089381535848}]}, {"text": " Table 4: Human evaluation results on realtime di- alogues.", "labels": [], "entities": []}, {"text": " Table 5: Human evaluation of system outputs on  test set.", "labels": [], "entities": []}]}