{"title": [{"text": "Social Bias in Elicited Natural Language Inferences", "labels": [], "entities": [{"text": "Social Bias in Elicited Natural Language Inferences", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.7616829190935407}]}], "abstractContent": [{"text": "We analyze the Stanford Natural Language Inference (SNLI) corpus in an investigation of bias and stereotyping in NLP data.", "labels": [], "entities": [{"text": "Stanford Natural Language Inference (SNLI) corpus", "start_pos": 15, "end_pos": 64, "type": "DATASET", "confidence": 0.6021828018128872}]}, {"text": "The human-elicitation protocol employed in the construction of the SNLI makes it prone to amplifying bias and stereotypical associations, which we demonstrate statistically (using pointwise mutual information) and with qualitative examples.", "labels": [], "entities": [{"text": "SNLI", "start_pos": 67, "end_pos": 71, "type": "TASK", "confidence": 0.8767120242118835}]}], "introductionContent": [{"text": "Since the statistical revolution in Artificial Intelligence (AI), it is standard in areas such as natural language processing and computer vision to train models on large amounts of empirical data.", "labels": [], "entities": []}, {"text": "This \"big data\" approach popularly connotes objectivity; however, as a cultural, political, and economic phenomenon in addition to a technological one, big data carries subjective aspects).", "labels": [], "entities": []}, {"text": "The data mining process involves defining a target variable and evaluation criteria, collecting a dataset, selecting a manner in which to represent the data, and sometimes eliciting annotations: bias, whether or implicit or explicit, maybe introduced in the performance of each of these tasks (.", "labels": [], "entities": [{"text": "data mining", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.7798140347003937}]}, {"text": "We focus on the problem of overgeneralization, in which a data mining model extrapolates excessively from observed patterns, leading to bias confirmation among the model's users.", "labels": [], "entities": []}, {"text": "High-profile cases of overgeneralization in the public sphere abound.", "labels": [], "entities": []}, {"text": "Research on the measurement and correction of overgeneralization in NLP in particular is nascent.", "labels": [], "entities": []}, {"text": "Stock word embeddings have been shown to exhibit gender bias, leading to proposed debiasing algorithms (.", "labels": [], "entities": []}, {"text": "Word embeddings have been shown to reproduce harmful implicit associations exhibited by human subjects in implicit association tests.", "labels": [], "entities": []}, {"text": "Gender bias in sports journalism has been studied via language modeling, confirming that male athletes receive questions more focused on the game than female athletes (.", "labels": [], "entities": []}, {"text": "In guessing the gender, age, and education level of the authors of Tweets, crowdworkers found to exaggerate stereotypes.", "labels": [], "entities": []}, {"text": "A prerequisite to resolving the above issues is basic awareness among NLP researchers and practitioners of where systematic bias in datasets exists, and how it may arise.", "labels": [], "entities": []}, {"text": "In service of this goal, we offer a case study of bias in the Stanford Natural Language Inference (SNLI) dataset.", "labels": [], "entities": [{"text": "Stanford Natural Language Inference (SNLI) dataset", "start_pos": 62, "end_pos": 112, "type": "DATASET", "confidence": 0.7850694805383682}]}, {"text": "SNLI is a recent but popular NLP dataset for textual inference, the largest of its kind by two orders of magnitude, offering the potential to substantially advance research in Natural Language Understanding (NLU).", "labels": [], "entities": [{"text": "SNLI", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7753652930259705}, {"text": "textual inference", "start_pos": 45, "end_pos": 62, "type": "TASK", "confidence": 0.712452158331871}, {"text": "Natural Language Understanding (NLU)", "start_pos": 176, "end_pos": 212, "type": "TASK", "confidence": 0.7665870587031046}]}, {"text": "We select this dataset because (1) we predict that natural language inference as a NLP task maybe generally susceptible to emulating human cognitive biases like social stereotyping, and (2) we are interested in how eliciting written inferences from humans with minimal provided context may encourage stereotyped responses.", "labels": [], "entities": []}, {"text": "Using the statistical measure of pointwise mutual information along with qualitative examples, we demonstrate the existence of stereotypes of various forms in the elicited hypotheses of SNLI.", "labels": [], "entities": [{"text": "SNLI", "start_pos": 186, "end_pos": 190, "type": "TASK", "confidence": 0.8033438324928284}]}, {"text": "a photo caption (but not the corresponding photo) from the Flickr30k corpus ( and instructing them to write anew alternate caption for the unseen photo under one of the following specifications: The new caption must either be \"definitely a true description of the photo,\" \"might be a true description of the photo,\" or \"definitely a false description of the photo.\"", "labels": [], "entities": [{"text": "Flickr30k corpus", "start_pos": 59, "end_pos": 75, "type": "DATASET", "confidence": 0.9905931651592255}]}, {"text": "Thus, in the parlance of Natural Language Inference, the original caption and the newly elicited caption form a sentence pair consisting of a premise (the original caption) and a hypothesis (the newly elicited sentence).", "labels": [], "entities": [{"text": "Natural Language Inference", "start_pos": 25, "end_pos": 51, "type": "TASK", "confidence": 0.7113138635953268}]}, {"text": "The pair is labeled with one of three entailment relation types (ENTAILMENT, NEUTRAL, or CONTRADICTION), corresponding to conditions above.", "labels": [], "entities": [{"text": "ENTAILMENT", "start_pos": 65, "end_pos": 75, "type": "METRIC", "confidence": 0.9740399122238159}, {"text": "NEUTRAL", "start_pos": 77, "end_pos": 84, "type": "METRIC", "confidence": 0.9299696683883667}, {"text": "CONTRADICTION", "start_pos": 89, "end_pos": 102, "type": "METRIC", "confidence": 0.9649924635887146}]}, {"text": "The dataset contains 570K such pairs in total.", "labels": [], "entities": []}, {"text": "Given the construction of this dataset, we identify two possible sources of social bias: caption bias, 1 already present in the premises from the Flickr30k corpus, and (inference) elicitation bias, resulting from the SNLI protocol of eliciting possible inferences from humans provided an image caption.", "labels": [], "entities": [{"text": "Flickr30k corpus", "start_pos": 146, "end_pos": 162, "type": "DATASET", "confidence": 0.9857338964939117}]}, {"text": "Though we recognize these sources of bias may not be as tidy and independent as their names suggest, it is a useful conceptual shorthand: In this paper, we are primarily interested in detecting elicitation bias.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}