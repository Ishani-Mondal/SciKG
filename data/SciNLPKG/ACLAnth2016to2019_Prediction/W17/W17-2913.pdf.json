{"title": [{"text": "Ideological Phrase Indicators for Classification of Political Discourse Framing on Twitter", "labels": [], "entities": [{"text": "Ideological Phrase Indicators", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8803867896397909}, {"text": "Classification of Political Discourse Framing", "start_pos": 34, "end_pos": 79, "type": "TASK", "confidence": 0.9072692394256592}]}], "abstractContent": [{"text": "Politicians carefully word their statements in order to influence how others view an issue, apolitical strategy called framing.", "labels": [], "entities": []}, {"text": "Simultaneously, these frames may also reveal the beliefs or positions on an issue of the politician.", "labels": [], "entities": []}, {"text": "Simple language features such as unigrams, bigrams, and tri-grams are important indicators for identifying the general frame of a text, for both longer congressional speeches and shorter tweets of politicians.", "labels": [], "entities": [{"text": "identifying the general frame of a text", "start_pos": 95, "end_pos": 134, "type": "TASK", "confidence": 0.7350988898958478}]}, {"text": "However, tweets may contain multiple unigrams across different frames which limits the effectiveness of this approach.", "labels": [], "entities": []}, {"text": "In this paper, we present a joint model which uses both linguistic features of tweets and ideological phrase indicators extracted from a state-of-the-art embedding-based model to predict the general frame of political tweets.", "labels": [], "entities": []}], "introductionContent": [{"text": "Social media platforms have played an increasingly important role in U.S. presidential elections, beginning in 2008.", "labels": [], "entities": []}, {"text": "Among these, microblogs such as Twitter have a special role, as they allow politicians to react quickly to events as they unfold and to shape the discussion of current political issues according to their views.", "labels": [], "entities": []}, {"text": "Framing is an important tool used by politicians to bias the discussion towards their stance.", "labels": [], "entities": [{"text": "Framing", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.9049234986305237}]}, {"text": "Framing contextualizes the discussion by emphasizing specific aspects of the issue, which creates an association between the issue and a specific frame of reference.", "labels": [], "entities": []}, {"text": "Research on issue framing in political discourse is rooted in social science research and recently has attracted growing interest in the natural language processing community ( as away to automatically analyze political discourse in congressional speeches and political news articles.", "labels": [], "entities": [{"text": "issue framing in political discourse", "start_pos": 12, "end_pos": 48, "type": "TASK", "confidence": 0.8310336709022522}]}, {"text": "Contrary to these sources, Twitter requires politicians to compress their ideas and reactions into 140 character long tweets.", "labels": [], "entities": []}, {"text": "As a result, politicians have to cleverly choose how to frame controversial issues, as well as react to events and each other (.", "labels": [], "entities": []}, {"text": "Framing decisions can be used to build support for political stances and they often reflect ideological differences between politicians.", "labels": [], "entities": [{"text": "Framing decisions", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9125311076641083}]}, {"text": "For example, in debates concerning the issue of abortion, the stance opposing abortion is framed as \"pro-life\", which reflects amoral or religious-based ideology.", "labels": [], "entities": []}, {"text": "Correctly identifying how issues are framed can help reveal the ideological base of the speaker.", "labels": [], "entities": []}, {"text": "However, in many cases framing abstracts this information and groups content reflecting differing ideologies together under the same frame.", "labels": [], "entities": []}, {"text": "As a concrete example consider the following tweets: 1.", "labels": [], "entities": []}, {"text": "order on guns is a gross overreach of power that tramples on the rights of law abiding Americans and our Constitution 2.", "labels": [], "entities": []}, {"text": "With this ruling #SCOTUS has upheld a critical freedom for women to make their own decisions about their bodies In both tweets, the same frame (Legality, Constitutionality, & Jurisdiction) is used to discuss two different issues: guns and abortion, respectively.", "labels": [], "entities": []}, {"text": "Despite the use of a similar frame, the two tweets reflect opposing ideologies.", "labels": [], "entities": []}, {"text": "A straight-forward approach for identifying these differences would be to refine the issueindependent general frames into more specific categories.", "labels": [], "entities": []}, {"text": "However, this would limit their generalization and considerably increase the difficulty of analysis, both for human annotators and for automated techniques.", "labels": [], "entities": []}, {"text": "Instead, we suggest to aug-ment the frame analysis with additional information.", "labels": [], "entities": []}, {"text": "Our modeling approach is based on the observation that politicians often use slogans in both their tweets and speeches.", "labels": [], "entities": []}, {"text": "These are key phrases used to indirectly indicate the political figures' core beliefs and ideological stances.", "labels": [], "entities": []}, {"text": "Identification of these phrases automatically decomposes the frames into more specific categories.", "labels": [], "entities": []}, {"text": "Consider the two tweets in the example above.", "labels": [], "entities": []}, {"text": "In the first tweet, several phrases indicate the frame: \"exec.", "labels": [], "entities": []}, {"text": "order\", \"overreach of power\", \"rights of law abiding Americans\", \"our constitution\".", "labels": [], "entities": []}, {"text": "In the second tweet, the relevant phrases are \"this ruling\" and \"upheld a critical freedom\".", "labels": [], "entities": []}, {"text": "All of these phrases indicate that the same frame is being used in both tweets.", "labels": [], "entities": []}, {"text": "However, analyzing the specific terminology in each case and the context in which it appears helps capture the ideological similarities and differences.", "labels": [], "entities": []}, {"text": "For example, in the context of gun-rights debates, phrases highlighting \"law and order\" and references to the constitution tend to reflect a conservative ideology, while phrases highlighting upholding of freedoms in the abortion debate tend to reflect a liberal ideology.", "labels": [], "entities": []}, {"text": "Given the rapidly changing nature of trending issues and political discourse on Twitter, our key technical challenge is to relay these ideological dimensions to an automated model, such that it will be able to easily adapt to new issues and language.", "labels": [], "entities": []}, {"text": "Our model consists of two components combined together: frame identification and ideological-indicators identification.", "labels": [], "entities": [{"text": "frame identification", "start_pos": 56, "end_pos": 76, "type": "TASK", "confidence": 0.7790720760822296}, {"text": "ideological-indicators identification", "start_pos": 81, "end_pos": 118, "type": "TASK", "confidence": 0.7338859140872955}]}, {"text": "For the first piece we use a structured probabilistic model to capture general framing dimensions by combining content and political context analysis.", "labels": [], "entities": []}, {"text": "For the second task, we employ a state-of-the-art textual similarity model which captures and generalizes over lexical indicators of key phrases that identify the politicians' ideology.", "labels": [], "entities": []}, {"text": "More details of both components are described in Section 4.", "labels": [], "entities": []}, {"text": "In this paper we take a first step towards connecting these two dimensions of analysis: issue framing and ideology identification.", "labels": [], "entities": [{"text": "issue framing", "start_pos": 88, "end_pos": 101, "type": "TASK", "confidence": 0.8038204908370972}, {"text": "ideology identification", "start_pos": 106, "end_pos": 129, "type": "TASK", "confidence": 0.7726384401321411}]}, {"text": "We lay the foundation for more advanced research by identifying this connection, analyzing tweets authored by U.S congressional representatives, and extracting ideological phrase indicators.", "labels": [], "entities": []}, {"text": "We build and analyze a joint model which combines the two dimensions.", "labels": [], "entities": []}, {"text": "Our experiments in Section 5 quantitatively compare the differences in frame prediction performance when using ideological phrase indicators.", "labels": [], "entities": [{"text": "frame prediction", "start_pos": 71, "end_pos": 87, "type": "TASK", "confidence": 0.6483295559883118}]}, {"text": "We also include a qualitative analysis in Section 6 of several examples in which ideological phrase indicators can help differentiate between tweets with similar frame predictions that reflect different ideologies.", "labels": [], "entities": []}], "datasetContent": [{"text": "Analysis of Supervised Experiments: Since each tweet can be classified as having more than one frame, the prediction task becomes a multilabel classification task.", "labels": [], "entities": []}, {"text": "Therefore, we use the standard measurements for precision and recall of a multilabel task.", "labels": [], "entities": [{"text": "precision", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.9990455508232117}, {"text": "recall", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.9983149766921997}]}, {"text": "The F 1 score is the harmonic mean of these two measures.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9799266457557678}]}, {"text": "We conducted supervised experiments using five-fold cross validation with randomly chosen splits on the labeled portion of the dataset.", "labels": [], "entities": []}, {"text": "shows the results of our supervised experiments.", "labels": [], "entities": []}, {"text": "The first column lists the frame number.", "labels": [], "entities": []}, {"text": "The second column presents the results of the baseline model, which includes all of the rules listed in  column lists the results of our model which consists of the baseline model with the addition of the SIMPHRASE(T,P F ) predicate.", "labels": [], "entities": [{"text": "SIMPHRASE(T,P F ) predicate", "start_pos": 205, "end_pos": 232, "type": "METRIC", "confidence": 0.7254055639108022}]}, {"text": "From these results we can see that the joint model that uses both language features (i.e., unigrams, bigrams, and trigrams) and phrase indicators (shown in) is able to improve performance in 9 out of the 17 frames.", "labels": [], "entities": []}, {"text": "The most likely cause for the decrease in score for the other 8 frames is that it is possible that there are too many overlapping sub-phrases within the general phrases of these 8 frames.", "labels": [], "entities": []}, {"text": "This would introduce extra noise into the probabilistic model and result in lower scores.", "labels": [], "entities": []}, {"text": "The 9 frames which improve have either 1 or no overlapping sub-phrases across parties for each general phrase category.", "labels": [], "entities": []}, {"text": "Further refinement of the sub-phrases is left for future work.", "labels": [], "entities": []}, {"text": "Ablation Case Study: To investigate the usefulness of ideological phrase indicators, we conducted an ablation study on the results of Frame 12.", "labels": [], "entities": [{"text": "Frame 12", "start_pos": 134, "end_pos": 142, "type": "DATASET", "confidence": 0.8926354050636292}]}, {"text": "Frame 12 is used when a politician references other political entities (e.g., the House, Senate, former presidents, etc.) as well as political actions (e.g., filibusters or lobbying).", "labels": [], "entities": [{"text": "Frame 12", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.6629728674888611}]}, {"text": "For our dataset, we used the following general phrases for Frame 12 which include references to: Democrats, Republicans, the President (POTUS), the Supreme Court (SCOTUS), and Congress.", "labels": [], "entities": [{"text": "Frame 12", "start_pos": 59, "end_pos": 67, "type": "DATASET", "confidence": 0.9047088921070099}]}, {"text": "We ran our model through an ablation study, in which each pair of phrases is removed one at a time to study their overall effect on the final prediction.: F 1 Scores of Ablation Experiments.", "labels": [], "entities": [{"text": "F 1 Scores", "start_pos": 155, "end_pos": 165, "type": "METRIC", "confidence": 0.9558411439259847}]}, {"text": "All Phrases represents our score for Frame 12 when using all possible phrases.", "labels": [], "entities": [{"text": "Frame 12", "start_pos": 37, "end_pos": 45, "type": "TASK", "confidence": 0.516457810997963}]}, {"text": "The remaining rows indicate which general phrase indicators have been removed from the comprehensive model.", "labels": [], "entities": []}, {"text": "Column 2 presents the F 1 score.", "labels": [], "entities": [{"text": "Column", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9185836911201477}, {"text": "F 1 score", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9717109203338623}]}, {"text": "Column 3 indicates the increase or decrease in score after the respective phrases are removed.", "labels": [], "entities": [{"text": "score", "start_pos": 47, "end_pos": 52, "type": "METRIC", "confidence": 0.9405059814453125}]}, {"text": "From these initial results, it appears that the way politicians refer to Democrats and Congress are the most important phrase indicators for predicting Frame 12.", "labels": [], "entities": [{"text": "Frame 12", "start_pos": 152, "end_pos": 160, "type": "TASK", "confidence": 0.7449465394020081}]}, {"text": "When these two phrase groups are removed, there is a large decrease in F 1 score.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.9923476378122965}]}, {"text": "Additionally, removing references to the president has a slight increase, while removing references to Republicans and the Supreme Court has a larger increase.", "labels": [], "entities": []}, {"text": "Therefore, references to Republicans and the Supreme Court are likely to be the least useful for predicting this frame.", "labels": [], "entities": []}, {"text": "We leave finding the best combinations of phrases for each frame as future work, as described in Section 7.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: F 1 Scores of Supervised Experiments.  The baseline column represents the results of the  best model of Johnson et al. (2017b). The phrases  column indicates the scores for the best model  when combined with our proposed phrases. Items  in bold are the highest score. The weighted aver- age is the micro-weighted average of the F 1 scores.", "labels": [], "entities": [{"text": "F 1 Scores", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9399523138999939}, {"text": "aver- age", "start_pos": 291, "end_pos": 300, "type": "METRIC", "confidence": 0.8891825079917908}, {"text": "F 1 scores", "start_pos": 338, "end_pos": 348, "type": "METRIC", "confidence": 0.9443711837132772}]}, {"text": " Table 6: Example Tweets Associated With the Orlando Pulse Nightclub Shooting on June 12, 2016.", "labels": [], "entities": [{"text": "Orlando Pulse Nightclub Shooting on June 12", "start_pos": 45, "end_pos": 88, "type": "DATASET", "confidence": 0.9568471397672381}]}]}