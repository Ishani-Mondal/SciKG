{"title": [{"text": "Role Semantics for Better Models of Implicit Discourse Relations", "labels": [], "entities": []}], "abstractContent": [{"text": "Predicting the structure of a discourse is challenging because relations between discourse segments are often implicit and thus hard to distinguish computationally.", "labels": [], "entities": []}, {"text": "I extend previous work to classify implicit discourse relations by introducing a novel set of features on the level of semantic roles.", "labels": [], "entities": [{"text": "classify implicit discourse relations", "start_pos": 26, "end_pos": 63, "type": "TASK", "confidence": 0.7543157190084457}]}, {"text": "My results demonstrate that such features are helpful, yielding results competitive with other feature-rich approaches on the PDTB.", "labels": [], "entities": []}, {"text": "My main contribution is an analysis of improvements that can be traced back to role-based features, providing insights into why and when role semantics is helpful.", "labels": [], "entities": []}], "introductionContent": [{"text": "Understanding natural language texts involves, inter alia, correctly identifying coherent segments and the relations that hold between them.", "labels": [], "entities": []}, {"text": "Recognizing discourse relations is an important part of this process because such relations not only conceptualize which parts of a text belong together but also how they are related.", "labels": [], "entities": []}, {"text": "Apart from direct applications in text analysis (e.g., discourse parsing), recognizing discourse relations has further proven a useful preprocessing step fora range of downstream tasks (.", "labels": [], "entities": [{"text": "text analysis", "start_pos": 34, "end_pos": 47, "type": "TASK", "confidence": 0.7168830186128616}, {"text": "discourse parsing)", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.7925411760807037}]}, {"text": "From a computational perspective, it has been shown that recognizing discourse relations can be performed with high accuracy when explicit discourse markers are available.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9890841841697693}]}, {"text": "However, classifying relations without explicit markers, so-called implicit discourse relations, has persisted as a difficult task to date (cf..", "labels": [], "entities": []}, {"text": "One of the main challenges, as identified in, is the need to perform inference over two discourse segments.", "labels": [], "entities": []}, {"text": "In this paper, I propose anew set of features based on semantic roles to address this challenge.", "labels": [], "entities": []}, {"text": "These features are meant to provide a shallow form of semantic representation, which might help a classifier to make better informed classification decisions.", "labels": [], "entities": []}, {"text": "I argue that role semantic representations are particularly well-suited for this task because different types of discourse relations are defined over the propositions that they connect.", "labels": [], "entities": []}, {"text": "For example, definitions in the Penn Discourse TreeBank 2.0 annotation manual () explicitly refer to role-level concepts such as events, situations and involved participants.", "labels": [], "entities": [{"text": "Penn Discourse TreeBank 2.0 annotation manual", "start_pos": 32, "end_pos": 77, "type": "DATASET", "confidence": 0.9633584916591644}]}, {"text": "In Rhetorical Structure Theory (, some definitions contain references to concepts akin to proto-roles (e.g. \"someone's deliberate action\").", "labels": [], "entities": [{"text": "Rhetorical Structure Theory", "start_pos": 3, "end_pos": 30, "type": "TASK", "confidence": 0.9060651858647665}]}, {"text": "To illustrate the usefulness of role semantics for the classification of implicit discourse relations, consider the two sentenes shown in Example (1): (1) a.", "labels": [], "entities": [{"text": "classification of implicit discourse relations", "start_pos": 55, "end_pos": 101, "type": "TASK", "confidence": 0.7704785704612732}]}, {"text": "\"Mr. Brady phoned Mr. Greenspan, . .", "labels": [], "entities": [{"text": "Mr. Brady phoned Mr. Greenspan", "start_pos": 1, "end_pos": 31, "type": "DATASET", "confidence": 0.7705451071262359}]}, {"text": "\"He continued to work the phones through the weekend.\"", "labels": [], "entities": []}, {"text": "Relation: then, Temporal.Asynchronous.Precedence (source: wsj 2413.pdtb) In terms of frame-semantic representation, the roles involved in the second sentence can be identified as an Ongoing activity (the argument of \"continue\"), a definite Duration and a pronominal Agent.", "labels": [], "entities": []}, {"text": "1 These cues indicate a sequence of situations with the same actor, making it likely that a Temporal relation holds to the previous sentence.", "labels": [], "entities": []}], "datasetContent": [{"text": "I evaluate the proposed model on version 2.0 of the Penn Discourse Treebank (PDTB,.", "labels": [], "entities": [{"text": "Penn Discourse Treebank (PDTB", "start_pos": 52, "end_pos": 81, "type": "DATASET", "confidence": 0.9579032063484192}]}, {"text": "To ensure a fair comparison, I use the same preprocessing and weighting techniques as well as the same data instances as previous work.", "labels": [], "entities": []}, {"text": "That is, each instance is a pair of implicitly related discourse segments as annotated in the PDTB corpus.", "labels": [], "entities": [{"text": "PDTB corpus", "start_pos": 94, "end_pos": 105, "type": "DATASET", "confidence": 0.9605402648448944}]}, {"text": "Sections 2-20 of the corpus are used for training, 21-22 for testing, and all other sections for development.", "labels": [], "entities": []}, {"text": "I use three variants of the proposed model to directly examine the utility of semantic roles and combining classifiers.", "labels": [], "entities": []}, {"text": "The first two models are instances of the feature-rich model described in Section 2, with hyperparameter tuning and feature selection done on the training and development sets: AverageFeats uses a combination of feature sets described in subsection 2.1, whereas AverageFeats+SRL also uses the role-level features from subsection 2.2.", "labels": [], "entities": [{"text": "AverageFeats+SRL", "start_pos": 262, "end_pos": 278, "type": "DATASET", "confidence": 0.7073039412498474}]}, {"text": "Note that for each type of role set at most one feature representation is chosen.", "labels": [], "entities": []}, {"text": "All feature sets are selected based on the best performance on the development set.", "labels": [], "entities": []}, {"text": "The third model, AllFeats, is a baseline logistic regression classifier that uses all best development feature sets at the same time.", "labels": [], "entities": []}, {"text": "For comparison, I consider a range of current state-of-the-art models.", "labels": [], "entities": []}, {"text": "The best feature-rich models () use a range of binary indicator features largely identical to the features described in Section 2.1.", "labels": [], "entities": []}, {"text": "The most notable difference to this work is that Rutherford and Xue use a small list of coreference patterns in addition to features that simply indicate coreferring mention counts.", "labels": [], "entities": []}, {"text": "lists F 1 -scores for each of the top-level relations in the PDTB test set.", "labels": [], "entities": [{"text": "F 1 -scores", "start_pos": 6, "end_pos": 17, "type": "METRIC", "confidence": 0.9719849079847336}, {"text": "PDTB test set", "start_pos": 61, "end_pos": 74, "type": "DATASET", "confidence": 0.983366052309672}]}, {"text": "Note that multiple relation types can apply to one relation instance.", "labels": [], "entities": []}, {"text": "Hence, instead of one 4-way classification, this task is traditionally separated into four binary tasks.", "labels": [], "entities": []}, {"text": "The results show that AverageFeats performs competitively with other feature-rich models for discourse relation classification.", "labels": [], "entities": [{"text": "discourse relation classification", "start_pos": 93, "end_pos": 126, "type": "TASK", "confidence": 0.7609543800354004}]}, {"text": "Additional features on semantic roles improve performance for all but one relation.", "labels": [], "entities": []}, {"text": "In the cases in which semantic roles are helpful, both FrameNet-based and PropBank-based feature sets are selected.", "labels": [], "entities": []}, {"text": "Two of the four scores by AverageFeats+SRL represent the best reported results with a feature-rich model.", "labels": [], "entities": [{"text": "AverageFeats+SRL", "start_pos": 26, "end_pos": 42, "type": "DATASET", "confidence": 0.6766077876091003}]}, {"text": "The performance of AllFeats is consistently worse than those of other recent models.", "labels": [], "entities": [{"text": "AllFeats", "start_pos": 19, "end_pos": 27, "type": "DATASET", "confidence": 0.8351418375968933}]}, {"text": "This complies with my hypothesis that hyperparameters tuned for one single model do not generalize well across different feature types.", "labels": [], "entities": []}, {"text": "One advantage of simple classification models based on binary features is that predictions based on learned feature weights can easily be interpreted.", "labels": [], "entities": []}, {"text": "In the following, I take a closer look at classification instances that the model AverageFeats+SRL got correct but that were misclassified by the other models.", "labels": [], "entities": [{"text": "AverageFeats+SRL", "start_pos": 82, "end_pos": 98, "type": "METRIC", "confidence": 0.7099832892417908}]}, {"text": "The weights of the features that apply in these examples provide insights as to how and when semantic roles are beneficial.", "labels": [], "entities": []}, {"text": "For simplicity, I focus the discussion on FrameNet roles (i.e. frame element types).", "labels": [], "entities": []}, {"text": "For the implicit relation Contingency, the learned feature weights indicate that its prediction becomes more likely when an Agent is identified in the first discourse segment (high positive feature weight) but not in the second segment (negative feature weight).", "labels": [], "entities": []}, {"text": "This seems to reflect the fact that most of these relations connect a cause and a result, as shown for instance in Example (2).", "labels": [], "entities": []}, {"text": "traders can buy or sell even when they don't have a customer order . .", "labels": [], "entities": []}, {"text": "[as a result] liquidity becomes a severe problem for thinly traded contracts . .", "labels": [], "entities": []}, {"text": "\" (wsj 2110.pdtb) Semantic roles are helpful in such cases because they provide a means to distinguish events initiated by someone (the cause) from simple states (the result).", "labels": [], "entities": []}, {"text": "A list of features that seem to contribute to this distinction, as identified by their associated feature weights, are given in.", "labels": [], "entities": []}, {"text": "The feature weights assigned in role-based classifiers for other discourse relations are overall smaller and thus harder to interpret.", "labels": [], "entities": []}, {"text": "Still, certain trends can be observed.", "labels": [], "entities": []}, {"text": "For example, I find that co-occurrences of specific roles in both connected discourse segments may indicate a Comparison.", "labels": [], "entities": []}, {"text": "Example (3) shows one such instance, in which the role Purpose has been identified in both segments (assigned feature weight: +0.117).", "labels": [], "entities": []}, {"text": "Other roles, for which the same pattern of weights are observed include, among others, Theme (+0.435) and Businesses (+0.254).", "labels": [], "entities": []}, {"text": "(3) \"Her goal: to top 300 ad pages ... whether she can meet that ambitious goal is still far from certain.\"", "labels": [], "entities": []}, {"text": "(wsj 2109.pdtb) Concerning the Temporal relation, high feature weights are learned for specific FrameNet roles, such as Activity start in the first discourse segment (+1.654) and Process end in the second segment (+1.116).", "labels": [], "entities": []}, {"text": "Even though these feature weights seem to be intuitive, they only lead to marginal improvements to the absolute classification performance, presumably because textual order in discourse not necessarily represents linear temporal order (\"before\" vs. \"after\").", "labels": [], "entities": []}, {"text": "Higher gains could be achieved if training and evaluation was performed on more specific relation annotations but such instances are too rare in practice for the feature-rich classifiers to learn robust generalizations: For example, the current version of the Penn Discourse Treebank contains a total of only 151 implicit relation instances of the discourse relation Temporal.Asynchronous.Succession.", "labels": [], "entities": [{"text": "Penn Discourse Treebank", "start_pos": 260, "end_pos": 283, "type": "DATASET", "confidence": 0.9665732582410177}]}], "tableCaptions": [{"text": " Table 1: One-vs-all results in F 1 -score on  the four PDTB top-level relations (comparison,  contingency, expansion and temporal). Best overall  results are marked in bold, best results by feature- rich models are underlined.", "labels": [], "entities": [{"text": "F 1 -score", "start_pos": 32, "end_pos": 42, "type": "METRIC", "confidence": 0.9750008583068848}, {"text": "PDTB top-level relations", "start_pos": 56, "end_pos": 80, "type": "DATASET", "confidence": 0.8856401642163595}]}]}