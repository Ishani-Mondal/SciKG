{"title": [{"text": "Towards Problem Solving Agents that Communicate and Learn", "labels": [], "entities": [{"text": "Problem Solving", "start_pos": 8, "end_pos": 23, "type": "TASK", "confidence": 0.7735033631324768}]}], "abstractContent": [{"text": "Agents that communicate back and forthwith humans to help them execute non-linguistic tasks area long sought goal of AI.", "labels": [], "entities": []}, {"text": "These agents need to translate between utterances and actionable meaning representations that can be interpreted by task-specific problem solvers in a context-dependent manner.", "labels": [], "entities": []}, {"text": "They should also be able to learn such actionable interpretations for new predicates on the fly.", "labels": [], "entities": []}, {"text": "We define an agent architecture for this scenario and present a series of experiments in the Blocks World domain that illustrate how our architecture supports language learning and problem solving in this domain.", "labels": [], "entities": [{"text": "problem solving", "start_pos": 181, "end_pos": 196, "type": "TASK", "confidence": 0.7335597723722458}]}], "introductionContent": [{"text": "An agent that can engage in natural, back-andforth communication with humans to help them complete areal world task requires the ability to understand and produce language in the context of that task (i.e. to map between utterances and meaning representations the problem solving components of the agent can act on in a particular situation).", "labels": [], "entities": []}, {"text": "The agent may also need to initiate clarification requests when communication fails, and to learn new domain (or conversation) specific vocabulary and its meaning.", "labels": [], "entities": []}, {"text": "This kind of symmetric, grounded communication with a problem-solving agent goes significantly beyond the one-step, single direction understanding tasks considered in standard semantic parsing (e.g. or even short, simple instructions to robots (e.g..", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 176, "end_pos": 192, "type": "TASK", "confidence": 0.775883287191391}]}, {"text": "In order to focus on these concept learning and communication issues, we deliberately limit ourselves hereto a simple, simulated environment.", "labels": [], "entities": []}, {"text": "We operate in a two-dimensional Blocks World domain where a human wants one or more shapes to be constructed on a grid.", "labels": [], "entities": []}, {"text": "The human needs to communicate the goal of this planning task to the agent.", "labels": [], "entities": []}, {"text": "Once the agent has understood the instructions and its planning is done, it communicates its plan to (possibly) another human who will then execute this plan.", "labels": [], "entities": []}, {"text": "Depending on the complexity of the task and the linguistic capabilities of the agent, this scenario may require a lot of back-and-forth communication.", "labels": [], "entities": []}, {"text": "If the human omits details from their description and prevents the agent from accomplishing the task, we expect the agent to initiate communication and ask clarification questions.", "labels": [], "entities": []}, {"text": "If the human uses vocabulary that is new to the agent, we expect the agent to ask fora definition and the human to teach the agent its meaning in the domain.", "labels": [], "entities": []}, {"text": "We define an agent architecture named COG that allows us to investigate the challenges arising in this symmetric communication scenario.", "labels": [], "entities": []}, {"text": "COG combines a problem solving (planning) component with a basic language understanding and generation system that is initially only equipped with a limited vocabulary.", "labels": [], "entities": [{"text": "COG", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7066274881362915}, {"text": "problem solving (planning)", "start_pos": 15, "end_pos": 41, "type": "TASK", "confidence": 0.8573311567306519}]}, {"text": "We perform a sequence of experiments of increasing complexity that illustrate how our architecture supports the problem solving scenarios described above, and how language learning is accomplished within this architecture.", "labels": [], "entities": []}, {"text": "We argue that, within this architecture, all the agent's capabilities -comprehension, production, problem solving and learning -can be improved with additional communication.", "labels": [], "entities": [{"text": "problem solving", "start_pos": 98, "end_pos": 113, "type": "TASK", "confidence": 0.7371294498443604}]}, {"text": "Section 2 defines the domain and problem setup.", "labels": [], "entities": []}, {"text": "Section 3 provides an overview of the COG architecture.", "labels": [], "entities": []}, {"text": "Section 4 describes COG's current components (language comprehension, production, memory, problem solving, and dialogue mediation).", "labels": [], "entities": [{"text": "problem solving", "start_pos": 90, "end_pos": 105, "type": "TASK", "confidence": 0.7376280128955841}, {"text": "dialogue mediation", "start_pos": 111, "end_pos": 129, "type": "TASK", "confidence": 0.7107034474611282}]}, {"text": "Section 5 describes our experiments and results.", "labels": [], "entities": []}], "datasetContent": [{"text": "Although we ultimately wish to evaluate our agent's live interactions with real human users, our current experiments feed it synthetically generated descriptions.", "labels": [], "entities": []}, {"text": "For the descriptions with missing information, we randomly choose dimensional and/or spatial information to omit for every shape, providing the missing information in a follow-up response upon system query.", "labels": [], "entities": []}, {"text": "We also generate sentences with descriptions with unknown terms that have to be clarified in further interactions.", "labels": [], "entities": []}, {"text": "After a full interaction has been carried out (or halted early due to system comprehension failure), we automatically verify the system's output configuration against the gold configuration.", "labels": [], "entities": []}, {"text": "Input consisting of sentences describing various block configurations and their corresponding logical forms was produced using a template-based generation system.", "labels": [], "entities": []}, {"text": "A subset of this data was used for training the semantic parser; the rest was used for the following experiments.", "labels": [], "entities": []}, {"text": "The generation system was setup to create configurations randomizing over shape types, sizes, and relative locations, and the templates for the sentences were designed to introduce lexical and grammatical variety.", "labels": [], "entities": []}, {"text": "Overall, the generation system is able to pro- Generated descriptions contain one sentence (for single shapes) and up to three sentences (for two shapes).", "labels": [], "entities": []}, {"text": "The sentences have an average length of approximately ten words.", "labels": [], "entities": []}, {"text": "Multi-sentence descriptions pose special challenges for semantic parsing due to the need to resolve coreference across sentences.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 56, "end_pos": 72, "type": "TASK", "confidence": 0.713489755988121}]}, {"text": "Thus, increasing the number of shapes in a configuration dramatically increases the complexity of the parsing task.", "labels": [], "entities": [{"text": "parsing task", "start_pos": 102, "end_pos": 114, "type": "TASK", "confidence": 0.9260302782058716}]}, {"text": "The COG system was evaluated on three separate tasks as outlined in Section 2; we present the results below.", "labels": [], "entities": []}], "tableCaptions": []}