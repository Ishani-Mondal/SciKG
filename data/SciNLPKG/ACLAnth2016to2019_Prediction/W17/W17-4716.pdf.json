{"title": [{"text": "Guiding Neural Machine Translation Decoding with External Knowledge", "labels": [], "entities": [{"text": "Guiding Neural Machine Translation Decoding with External Knowledge", "start_pos": 0, "end_pos": 67, "type": "TASK", "confidence": 0.8296530991792679}]}], "abstractContent": [{"text": "Differently from the phrase-based paradigm, neural machine translation (NMT) operates on word and sentence representations in a continuous space.", "labels": [], "entities": [{"text": "neural machine translation (NMT)", "start_pos": 44, "end_pos": 76, "type": "TASK", "confidence": 0.832043319940567}]}, {"text": "This makes the decoding process not only more difficult to interpret, but also harder to influence with external knowledge.", "labels": [], "entities": []}, {"text": "For the latter problem, effective solutions like the XML-markup used by phrase-based models to inject fixed translation options as constraints at decoding time are not yet available.", "labels": [], "entities": []}, {"text": "We propose a \"guide\" mechanism that enhances an existing NMT decoder with the ability to prioritize and adequately handle translation options presented in the form of XML annotations of source words.", "labels": [], "entities": []}, {"text": "Positive results obtained in two different translation tasks indicate the effectiveness of our approach.", "labels": [], "entities": [{"text": "translation tasks", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.9047003984451294}]}], "introductionContent": [{"text": "The need to enforce fixed translations of certain source words is a well known problem in machine translation (MT).", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 90, "end_pos": 114, "type": "TASK", "confidence": 0.8470584273338317}]}, {"text": "For instance, this is an issue in application scenarios in which the translation process has to comply with specific terminology and/or style guides.", "labels": [], "entities": [{"text": "translation process", "start_pos": 69, "end_pos": 88, "type": "TASK", "confidence": 0.8941000998020172}]}, {"text": "In such situations it is generally necessary to consider external resources to guide the decoder in order to ensure consistency or meet other specific requirements.", "labels": [], "entities": [{"text": "consistency", "start_pos": 116, "end_pos": 127, "type": "METRIC", "confidence": 0.9735134840011597}]}, {"text": "Terminology lists, which provide the decoder with the expected translations of specific words or phrases, area typical example of external knowledge used to guide the process to meet such constraints.", "labels": [], "entities": []}, {"text": "Meeting predefined constraints, however, does not represent the only casein which an external guidance can support decoding.", "labels": [], "entities": []}, {"text": "In ensemble MT architectures, for example, the output of a translation system specialised in handling specific phenomena (e.g. numbers or dates) can be used to guide another decoder without changing its underlying model.", "labels": [], "entities": [{"text": "MT", "start_pos": 12, "end_pos": 14, "type": "TASK", "confidence": 0.8350043892860413}]}, {"text": "Phrase-based statistical MT (PBSMT), which explicitly manipulates symbolic representations of the basic constituents (phrases) in the source and target languages, provides solutions to address these needs.", "labels": [], "entities": [{"text": "Phrase-based statistical MT", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6644349098205566}]}, {"text": "For instance, the XML markup implemented in the Moses toolkit () allows one to supply the expected translations to the decoder in the form of tags surrounding the corresponding source phrases.", "labels": [], "entities": []}, {"text": "To our knowledge, solutions to this problem are not yet available for neural machine translation (NMT), which has recently emerged as the dominant approach for MT.", "labels": [], "entities": [{"text": "neural machine translation (NMT)", "start_pos": 70, "end_pos": 102, "type": "TASK", "confidence": 0.809119294087092}, {"text": "MT", "start_pos": 160, "end_pos": 162, "type": "TASK", "confidence": 0.9961458444595337}]}, {"text": "In particular, no work has been done to address the needs of the translation industry, in which language service providers usually receive translation requests that must be satisfied in short time, often taking into account external knowledge that defines specific customers' constraints.", "labels": [], "entities": []}, {"text": "In this case, the time-consuming retraining routines of NMT are not viable, thus making methods to inject external knowledge without retraining of paramount importance.", "labels": [], "entities": []}, {"text": "To address this gap, we investigate problems arising from the fact that NMT operates on implicit word and sentence representations in a continuous space, which makes influencing the process with external knowledge more complex.", "labels": [], "entities": []}, {"text": "In particular, we attempt to answer the following questions: i) How to enforce the presence of a given translation recommendation in the decoder's output?", "labels": [], "entities": []}, {"text": "ii) How to place these word(s) in the right position?", "labels": [], "entities": []}, {"text": "iii) How to guide the translation of outof-vocabulary terms?", "labels": [], "entities": [{"text": "translation of outof-vocabulary terms", "start_pos": 22, "end_pos": 59, "type": "TASK", "confidence": 0.8851309269666672}]}, {"text": "Our solution extends an existing NMT decoder () by introducing the possibility to guide the translation process with constraints provided as XML annotations of the source words with the corresponding translation options.", "labels": [], "entities": []}, {"text": "The guidance mechanism supervises the process, generating the final output with the expected translations, in the right place, including cases of external words unknown to the model.", "labels": [], "entities": []}, {"text": "To test our approach, we experiment in two scenarios that pose different challenges to NMT.", "labels": [], "entities": [{"text": "NMT", "start_pos": 87, "end_pos": 90, "type": "TASK", "confidence": 0.9155186414718628}]}, {"text": "The first one is a translation task in which source sentences contain XML-annotated domain-specific terms.", "labels": [], "entities": [{"text": "translation task", "start_pos": 19, "end_pos": 35, "type": "TASK", "confidence": 0.8959047496318817}]}, {"text": "The presence of few annotated terms poses fewer constraints to the decoder in generating the output sentence.", "labels": [], "entities": []}, {"text": "The second scenario is an automatic post-editing (APE) task, in which the NMT model is trained to translate \"monolingually\" from draft machine-translated sentences into humanquality post-edits.", "labels": [], "entities": []}, {"text": "The external guidance is provided by word-level quality judgements () indicating the \"good\" words in the machine-translated sentence that should be kept in the final APE output.", "labels": [], "entities": []}, {"text": "In this case, the large number of \"good\" words already present in the original MT output poses more constraints to the decoding process.", "labels": [], "entities": [{"text": "MT", "start_pos": 79, "end_pos": 81, "type": "TASK", "confidence": 0.9340599179267883}]}, {"text": "In both scenarios, our guidance mechanism achieves significant performance gains over the original NMT decoder.", "labels": [], "entities": [{"text": "NMT decoder", "start_pos": 99, "end_pos": 110, "type": "DATASET", "confidence": 0.865709513425827}]}], "datasetContent": [{"text": "We use the pre-trained model built for the best English-German submission at the WMT'16 APE task.", "labels": [], "entities": [{"text": "WMT'16 APE task", "start_pos": 81, "end_pos": 96, "type": "TASK", "confidence": 0.6213569045066833}]}, {"text": "This available model was trained with Nematus over a data set of \u223c4M back-translated pairs, and then adapted to the taskspecific data segmented using the BPE technique.", "labels": [], "entities": []}, {"text": "In this experiment, we use the English-German data released at the WMT'16 APE shared task (.", "labels": [], "entities": [{"text": "WMT'16 APE shared task", "start_pos": 67, "end_pos": 89, "type": "DATASET", "confidence": 0.8301980495452881}]}, {"text": "To annotate the test set, instead of relying on automatic quality, predictions, we exploit oracle labels indicating \"good\" words (to be kept in the output) and \"bad\" words (to be replaced by the decoder).", "labels": [], "entities": []}, {"text": "To this aim, we first aligned each MT output with the corresponding human post-edit using TER).", "labels": [], "entities": [{"text": "MT output", "start_pos": 35, "end_pos": 44, "type": "TASK", "confidence": 0.8593345880508423}, {"text": "TER", "start_pos": 90, "end_pos": 93, "type": "METRIC", "confidence": 0.9819896221160889}]}, {"text": "Then, each MT word that was aligned with itself in the post-edit was annotated as \"good\".", "labels": [], "entities": [{"text": "MT word", "start_pos": 11, "end_pos": 18, "type": "TASK", "confidence": 0.8312481343746185}]}, {"text": "This resulted in a high number of \"good\" labels (on average, 79.4% of the sentence terms).", "labels": [], "entities": []}, {"text": "It is worth noting that, by construction, the resulting quality labels are \"gold\" annotations that current word-level quality estimation systems can only approximate.", "labels": [], "entities": []}, {"text": "These make them suitable for our testing purposes, as they allow us to avoid the noise introduced by sub-optimal predictors.", "labels": [], "entities": []}, {"text": "The BPE-level version of the test set is obtained by projecting the word-level QE tags into the sub-words (all sub-words of a word receive the original word tag).", "labels": [], "entities": [{"text": "BPE-level", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.812258780002594}]}, {"text": "If a sub-word was labelled as \"good\", then we annotate it with itself to indicate that the decoder must generate the sub-word in the output.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: BLEU results of different decoders on  the MT task (\" \u2020\" indicates statistically significant  differences wrt. Baseline with p<0.05).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9989882111549377}, {"text": "MT task", "start_pos": 53, "end_pos": 60, "type": "TASK", "confidence": 0.9260717034339905}]}, {"text": " Table 2: Examples covering some cases where GDec improves over the baseline for the MT task", "labels": [], "entities": [{"text": "MT", "start_pos": 85, "end_pos": 87, "type": "TASK", "confidence": 0.9692203402519226}]}]}