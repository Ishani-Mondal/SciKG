{"title": [{"text": "Learning with Learner Corpora: using the TLE for Native Language Identification", "labels": [], "entities": [{"text": "TLE", "start_pos": 41, "end_pos": 44, "type": "METRIC", "confidence": 0.7007811069488525}, {"text": "Native Language Identification", "start_pos": 49, "end_pos": 79, "type": "TASK", "confidence": 0.6872350772221884}]}], "abstractContent": [{"text": "This study investigates the usefulness of the Treebank of Learner English (TLE) when applied to the task of Native Language Identification (NLI).", "labels": [], "entities": [{"text": "Native Language Identification (NLI)", "start_pos": 108, "end_pos": 144, "type": "TASK", "confidence": 0.8178661564985911}]}, {"text": "The TLE is effectively a parallel corpus of Stan-dard/Learner English, as there are two versions ; one based on original learner essays , and the other an error-corrected version.", "labels": [], "entities": []}, {"text": "We use the corpus to explore how useful a parser trained on ungrammatical relations is compared to a parser trained on grammatical relations, when used as features fora native language classification task.", "labels": [], "entities": [{"text": "native language classification task", "start_pos": 169, "end_pos": 204, "type": "TASK", "confidence": 0.7623332142829895}]}, {"text": "While parsing results are much better when trained on grammatical relations, native language classification is slightly better using a parser trained on the original treebank containing ungrammatical relations .", "labels": [], "entities": [{"text": "parsing", "start_pos": 6, "end_pos": 13, "type": "TASK", "confidence": 0.9632140398025513}, {"text": "native language classification", "start_pos": 77, "end_pos": 107, "type": "TASK", "confidence": 0.6384156942367554}]}], "introductionContent": [{"text": "Native Language Identification (NLI), in which an author's first language is derived by analyzing texts written in his or her second language, is often treated as a text classification problem.", "labels": [], "entities": [{"text": "Native Language Identification (NLI)", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.7800449381271998}, {"text": "text classification", "start_pos": 165, "end_pos": 184, "type": "TASK", "confidence": 0.7139623165130615}]}, {"text": "NLI has proven useful in various applications, including in language-learning settings.", "labels": [], "entities": [{"text": "NLI", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7841026782989502}]}, {"text": "As it is wellestablished that a speaker's first language informs mistakes made in a second language, a system that can identify a learner's first language is better equipped to provide learner-specific feedback and identify likely problem areas.", "labels": [], "entities": []}, {"text": "The Treebank of Learner English (TLE) is the first publicly available syntactic treebank for English as a Second Language ( its incorporation of an annotation scheme fora consistent syntactic representation of grammatical errors.", "labels": [], "entities": []}, {"text": "This annotation system has the potential to be useful to native language identification, as the ability to parse ungrammatical and atypical dependency relations could improve the informativeness of dependency-based features in such a classification task.", "labels": [], "entities": [{"text": "native language identification", "start_pos": 57, "end_pos": 87, "type": "TASK", "confidence": 0.6504193147023519}]}, {"text": "Assessing this potential has been accomplished by training a parser on the original treebank and using it to extract dependency relations in a learner English corpus.", "labels": [], "entities": []}, {"text": "Those dependency relations were then used as features in a machine learning classification task.", "labels": [], "entities": [{"text": "machine learning classification task", "start_pos": 59, "end_pos": 95, "type": "TASK", "confidence": 0.7790282666683197}]}, {"text": "The success of this classification was then assessed by comparing the results to a classification on features extracted by a parser trained on the error-corrected version of the treebank, based on the assumption that the original version of the treebank will more accurately handle grammatical errors in learner texts.", "labels": [], "entities": []}, {"text": "This is a novel approach in that other similar experiments have used dependency parsers trained on grammatical treebanks to extract dependency relations.", "labels": [], "entities": []}, {"text": "We found that using the original version of the corpus gave slightly better results on native language classification than using the error-corrected version.", "labels": [], "entities": [{"text": "native language classification", "start_pos": 87, "end_pos": 117, "type": "TASK", "confidence": 0.6944325168927511}]}, {"text": "However, when we investigated parsing results, the original version gave much lower results on parsing both for original and errorcorrected texts.", "labels": [], "entities": [{"text": "parsing", "start_pos": 30, "end_pos": 37, "type": "TASK", "confidence": 0.981713593006134}, {"text": "parsing", "start_pos": 95, "end_pos": 102, "type": "TASK", "confidence": 0.966424822807312}]}, {"text": "This seems to suggest that there is useful information in the types of errors made by this parser.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Score level distributions in TOEFl11", "labels": [], "entities": [{"text": "TOEFl11", "start_pos": 39, "end_pos": 46, "type": "DATASET", "confidence": 0.8160501718521118}]}, {"text": " Table 3. As established by Berzak et al. (2016),  parsers trained on both the corrected and original  versions of the TLE outperform the parser trained  on a standard English treebank, with the merged", "labels": [], "entities": [{"text": "English treebank", "start_pos": 168, "end_pos": 184, "type": "DATASET", "confidence": 0.7058888077735901}]}, {"text": " Table 3: Parser accuracies for all three test sets.", "labels": [], "entities": [{"text": "Parser", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9113689661026001}, {"text": "accuracies", "start_pos": 17, "end_pos": 27, "type": "METRIC", "confidence": 0.5226165056228638}]}, {"text": " Table 5: Accuracy, precision, recall for native lan- guage identification with the three parser models.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.998155415058136}, {"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9995802044868469}, {"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9996435642242432}]}, {"text": " Table 6: Accuracy scores by language for all three  models", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9985596537590027}]}]}