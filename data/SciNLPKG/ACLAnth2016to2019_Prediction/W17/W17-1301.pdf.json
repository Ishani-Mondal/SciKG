{"title": [{"text": "Identification of Languages in Algerian Arabic Multilingual Documents", "labels": [], "entities": [{"text": "Identification of Languages in Algerian Arabic Multilingual Documents", "start_pos": 0, "end_pos": 69, "type": "TASK", "confidence": 0.8481260240077972}]}], "abstractContent": [{"text": "This paper presents a language identification system designed to detect the language of each word, in its context, in a multilingual documents as generated in social media by bilingual/multilingual communities, in our case speakers of Al-gerian Arabic.", "labels": [], "entities": [{"text": "language identification", "start_pos": 22, "end_pos": 45, "type": "TASK", "confidence": 0.7241977751255035}]}, {"text": "We frame the task as a sequence tagging problem and use supervised machine learning with standard methods like HMM and Ngram classification tagging.", "labels": [], "entities": [{"text": "sequence tagging problem", "start_pos": 23, "end_pos": 47, "type": "TASK", "confidence": 0.7515361309051514}, {"text": "Ngram classification tagging", "start_pos": 119, "end_pos": 147, "type": "TASK", "confidence": 0.6768382489681244}]}, {"text": "We also experiment with a lexicon-based method.", "labels": [], "entities": []}, {"text": "Combining all the methods in a fall-back mechanism and introducing some linguistic rules, to deal with unseen tokens and ambiguous words, gives an overall accuracy of 93.14%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 155, "end_pos": 163, "type": "METRIC", "confidence": 0.9996172189712524}]}, {"text": "Finally , we introduced rules for language identification from sequences of recog-nised words.", "labels": [], "entities": [{"text": "language identification from sequences of recog-nised words", "start_pos": 34, "end_pos": 93, "type": "TASK", "confidence": 0.7727518507412502}]}], "introductionContent": [{"text": "Most of the current Natural Language Processing (NLP) tools deal with one language, assuming that all documents are monolingual.", "labels": [], "entities": []}, {"text": "Nevertheless, there are many cases where more than one language is used in the same document.", "labels": [], "entities": []}, {"text": "The present study seeks to fill in some of the needs to accommodate multilingual (including bilingual) documents in NLP tools.", "labels": [], "entities": []}, {"text": "The phenomenon of using more than one language is common in multilingual societies where the contact between different languages has resulted in various language (code) mixing like code-switching and borrowings.", "labels": [], "entities": []}, {"text": "Code-switching is commonly defined as the use of two or more languages/language varieties with fluency in one conversation, or in a sentence, or even in a single word.", "labels": [], "entities": []}, {"text": "Whereas borrowing is used to refer to the altering of words from one language into another.", "labels": [], "entities": []}, {"text": "There is no clear-cut distinction between borrowings and code-switching, and scholars have different views and arguments.", "labels": [], "entities": []}, {"text": "We based our work on) where the authors consider borrowing as the adaptation of lexical items, with a phonological and morphological integration, from one language to another.", "labels": [], "entities": []}, {"text": "Otherwise, it is a code-switching, at single lexical item, phrasal or clausal levels, either the lexical item/phrase/clause exists or not in the first language.", "labels": [], "entities": []}, {"text": "We will use \"language mixing\" as a general term to refer to both code-switching and borrowing.", "labels": [], "entities": [{"text": "language mixing", "start_pos": 13, "end_pos": 28, "type": "TASK", "confidence": 0.730620801448822}]}, {"text": "We frame the task of identifying language mixing as a segmentation of a document/text into sequences of words belonging to one language, i.e. segment identification or chunking based on the language of each word.", "labels": [], "entities": [{"text": "identifying language mixing", "start_pos": 21, "end_pos": 48, "type": "TASK", "confidence": 0.7596155007680258}, {"text": "segment identification", "start_pos": 142, "end_pos": 164, "type": "TASK", "confidence": 0.6746309995651245}]}, {"text": "Since language shifts can occur frequently at each point of a document we base our work on the isolated word assumption as referred to by wherein the authors consider that it is more realistic to assume that every word in a document can be in a different language rather than along sequence of words being in the same language.", "labels": [], "entities": []}, {"text": "However, we are also interested in identifying the boundaries of each language use, sequences of words belonging to the same language, which we address by adding rules for language chunking.", "labels": [], "entities": [{"text": "language chunking", "start_pos": 172, "end_pos": 189, "type": "TASK", "confidence": 0.7234044969081879}]}, {"text": "This paper's main focus is the detection of language mixing in Algerian Arabic texts, written in Arabic script, used in social media while its contribution is to provide a system that is able to detect the language of each word in its context.", "labels": [], "entities": [{"text": "detection of language mixing in Algerian Arabic texts", "start_pos": 31, "end_pos": 84, "type": "TASK", "confidence": 0.7989256083965302}]}, {"text": "The paper is organized as follows: in Section 2, we give a brief overview of Algerian Arabic which is a well suited, and less studied, language for detecting language mixing.", "labels": [], "entities": [{"text": "detecting language mixing", "start_pos": 148, "end_pos": 173, "type": "TASK", "confidence": 0.8882737159729004}]}, {"text": "In Section 3, we present our newly built linguistic resources, from scratch, and we motivate our choices in annotating the data.", "labels": [], "entities": []}, {"text": "In Section 4, we describe the different methods used to build our system.", "labels": [], "entities": []}, {"text": "In Section 5, we survey some related work, and we conclude with the main findings and some of our future directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe the methods and the different experimental setups we used to build our language identification tool.", "labels": [], "entities": [{"text": "language identification", "start_pos": 100, "end_pos": 123, "type": "TASK", "confidence": 0.7218784242868423}]}, {"text": "We analyze and discuss the obtained results.", "labels": [], "entities": []}, {"text": "We start identifying language at a word level and then we combine words to identify the language of sequences.", "labels": [], "entities": []}, {"text": "We approach the language identification at the word level by taking into account the context of these words.", "labels": [], "entities": [{"text": "language identification", "start_pos": 16, "end_pos": 39, "type": "TASK", "confidence": 0.7471907436847687}]}, {"text": "We supplement the method with a lexicon lookup approach and manually constructed rules.", "labels": [], "entities": []}, {"text": "To evaluate the performance of the system, we divided the final human annotated dataset into two parts: the training dataset which contains 10,008 documents (215,832 tokens) and the evaluation dataset which contains 578 documents (10,107 tokens).", "labels": [], "entities": []}, {"text": "None of the documents included in the evaluation dataset were used to compile the lexicons previously described.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Performance of the HMM tagger.", "labels": [], "entities": [{"text": "HMM tagger", "start_pos": 29, "end_pos": 39, "type": "TASK", "confidence": 0.7155953049659729}]}, {"text": " Table 4: Performance of the lexicon tagger.", "labels": [], "entities": []}, {"text": " Table 5: Performance of different n-gram tagger  configurations.", "labels": [], "entities": []}, {"text": " Table 6: Performance of the BackOff(Trigram, Bi- gram, Unigram, UNK) tagger.", "labels": [], "entities": [{"text": "UNK) tagger", "start_pos": 65, "end_pos": 76, "type": "TASK", "confidence": 0.5766184230645498}]}, {"text": " Table 7: Performance of the tagger combining n- gram and lexicons.", "labels": [], "entities": []}]}