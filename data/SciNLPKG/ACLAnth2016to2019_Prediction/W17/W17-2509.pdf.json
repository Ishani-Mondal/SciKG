{"title": [{"text": "Framework for Identifying Parallel Sentences in Comparable Corpora", "labels": [], "entities": [{"text": "Identifying Parallel Sentences in Comparable Corpora", "start_pos": 14, "end_pos": 66, "type": "TASK", "confidence": 0.7885073522726694}]}], "abstractContent": [{"text": "This paper describes our participation in BUCC 2017 shared task: identifying parallel sentences in comparable corpora.", "labels": [], "entities": [{"text": "BUCC 2017 shared task", "start_pos": 42, "end_pos": 63, "type": "DATASET", "confidence": 0.818172812461853}]}, {"text": "Our goal is to leverage continuous vector representations and distributional semantics with a minimal use of external preprocessing and post-processing tools.", "labels": [], "entities": []}, {"text": "We report experiments that were conducted after transmitting our results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Traditional approaches for parallel sentence identification from comparable corpora rely on machine learning models with the use of features measured by statistical machine translation (SMT) systems.", "labels": [], "entities": [{"text": "parallel sentence identification", "start_pos": 27, "end_pos": 59, "type": "TASK", "confidence": 0.6583803792794546}, {"text": "statistical machine translation (SMT)", "start_pos": 153, "end_pos": 190, "type": "TASK", "confidence": 0.8097933828830719}]}, {"text": "present how to extract parallel sentences from newspaper articles using general and alignment features to train a binary maximum entropy classifier.", "labels": [], "entities": []}, {"text": "use an SMT-based system on comparable corpora to translate the source language side to detect corresponding parallel sentences on the target language side.", "labels": [], "entities": [{"text": "SMT-based", "start_pos": 7, "end_pos": 16, "type": "TASK", "confidence": 0.9732670187950134}]}, {"text": "While continuous vector representations of words and sentences estimated by neural language models and neural networks ( have been successfully applied to a variety of natural language processing tasks, ranging from handwriting generation to machine translation (), few efforts have been devoted to parallel sentence identification.", "labels": [], "entities": [{"text": "handwriting generation", "start_pos": 216, "end_pos": 238, "type": "TASK", "confidence": 0.794148176908493}, {"text": "machine translation", "start_pos": 242, "end_pos": 261, "type": "TASK", "confidence": 0.7779955863952637}, {"text": "parallel sentence identification", "start_pos": 299, "end_pos": 331, "type": "TASK", "confidence": 0.628166119257609}]}, {"text": "successfully use word embeddings for cross-language plagiarism detection, which can be considered a similar task to ours.", "labels": [], "entities": [{"text": "cross-language plagiarism detection", "start_pos": 37, "end_pos": 72, "type": "TASK", "confidence": 0.8092994292577108}]}, {"text": "The primary objective of our proposed approach is to assess whether we are able to identify parallel sentences using a scalable and flexible method by relying on recent advances in neural language modeling and deep learning architectures to eliminate the need for any domain specific feature engineering.", "labels": [], "entities": []}, {"text": "We want to evaluate the feasibility of a model learnt from distributional semantics alone in a \"pure\" setting by using as few external tools as possible.", "labels": [], "entities": []}, {"text": "Our approach can be considered as a first attempt to accomplish the proposed task using a deep learning framework.", "labels": [], "entities": []}, {"text": "Our aim is not to attain state-of-the-art performance, but to open interesting directions to enable researchers to advance research with this important task.", "labels": [], "entities": []}, {"text": "In fact, in the following sections we report the approach of our two-day effort to participate on this year's shared task.", "labels": [], "entities": []}, {"text": "Due to the short limit of time, we used models pretrained on a standard parallel corpus.", "labels": [], "entities": []}, {"text": "The details of our approach will be described elsewhere.", "labels": [], "entities": []}, {"text": "In this paper we report what we learned so far and few experiments that were conducted after submitting our results.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we present experiments that were conducted after the submission of our results.", "labels": [], "entities": []}, {"text": "First, we describe the resources used to perform the shared task, the training settings and the evaluation metrics.", "labels": [], "entities": []}, {"text": "We only participated to the f r-en language pair, making use only of our models pretrained on the Europarl v7 English to French parallel corpus from WMT'15 1 . To create our training set, 500K parallel sentence pairs are randomly selected.", "labels": [], "entities": [{"text": "Europarl v7 English to French parallel corpus from WMT'15 1", "start_pos": 98, "end_pos": 157, "type": "DATASET", "confidence": 0.933204185962677}]}, {"text": "The vocabulary sizes range between 103K to 119K for English and 126K to 140K for French depending on the digit preprocessing method (see Section 4.2).", "labels": [], "entities": []}, {"text": "We tokenize the dataset with the scripts from Moses 2 and all words are lowercased.", "labels": [], "entities": []}, {"text": "Empty sentence pairs are removed.", "labels": [], "entities": []}, {"text": "For the shared task, we replaced all digits with 0 (e.g. 1982\u21920000).", "labels": [], "entities": [{"text": "1982", "start_pos": 57, "end_pos": 61, "type": "DATASET", "confidence": 0.940881073474884}]}, {"text": "For the evaluation of our models we present the precision, recall and F 1 scores as mentioned on the shared task website 5 .  Equipped with a filter that seems to work well and a better model trained on a parallel corpus with digits, we expect to obtain a performance in the range of those presented in Section 4.2.", "labels": [], "entities": [{"text": "precision", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.9997121691703796}, {"text": "recall", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.9994113445281982}, {"text": "F 1", "start_pos": 70, "end_pos": 73, "type": "METRIC", "confidence": 0.9952313899993896}]}, {"text": "Unfortunately for us, it is not the case.", "labels": [], "entities": []}, {"text": "presents the results we obtained by using our model trained on Europarl with digits, using the 40-best list and \u03bb = 0.99.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 63, "end_pos": 71, "type": "DATASET", "confidence": 0.9936040043830872}]}, {"text": "One may wonder what happened to our surprisingly low precision score.", "labels": [], "entities": [{"text": "precision score", "start_pos": 53, "end_pos": 68, "type": "METRIC", "confidence": 0.9778770208358765}]}, {"text": "The problem arises from a combination of how the model is trained on negative examples and how we filtered our candidate sentence pairs.", "labels": [], "entities": []}, {"text": "Since our model outputs a positive instance for two sentences sharing an high level of semantic similarity, by filtering the 40 nearest target sentences for each source sentence, we created a pool of candidate sentence pairs that our model outputted as positive most of the time.", "labels": [], "entities": []}, {"text": "That being said, those sentence pairs still exist in the Cartesian product of the training set.", "labels": [], "entities": []}, {"text": "Thus, the proposed training procedure adding neg- 0.99 12.10 70.95 20.67: Performance of our models trained on Europarl with digits using the 40-best cosine similarity filter.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 111, "end_pos": 119, "type": "DATASET", "confidence": 0.9919806718826294}]}, {"text": "ative examples randomly selected from the training set is definitely not adequate and needs to be replaced by a more effective procedure.", "labels": [], "entities": []}, {"text": "For future work, instead of random sampling, we propose to apply the n-best cosine similarity filter on our model's training set in away to select negative examples from the n-best list to train it.", "labels": [], "entities": []}, {"text": "A postprocessing step could also be useful.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Parallel sentences found from the n-best  cosine similarity filter. The \u2206 columns are the per- centage increase in number of parallel sentences  found and candidate sentence pairs.", "labels": [], "entities": []}, {"text": " Table 2: Performance of our models trained on  Europarl with three different digits preprocessing  method and evaluated on our validation sets made  from the shared task training set.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 48, "end_pos": 56, "type": "DATASET", "confidence": 0.9932558536529541}]}]}