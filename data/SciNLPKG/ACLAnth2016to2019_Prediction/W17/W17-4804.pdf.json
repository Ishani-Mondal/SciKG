{"title": [{"text": "Treatment of Markup in Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 23, "end_pos": 54, "type": "TASK", "confidence": 0.7723803321520487}]}], "abstractContent": [{"text": "We present work on handling XML markup in Statistical Machine Translation (SMT).", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 42, "end_pos": 79, "type": "TASK", "confidence": 0.8026843468348185}]}, {"text": "The methods we propose can be used to effectively preserve markup (for instance inline formatting or structure) and to place markup correctly in a machine-translated segment.", "labels": [], "entities": []}, {"text": "We evaluate our approaches with parallel data that naturally contains markup or where markup was inserted to create synthetic examples.", "labels": [], "entities": []}, {"text": "In our experiments, hybrid reinsertion has proven the most accurate method to handle markup, while alignment masking and alignment reinsertion should be regarded as viable alternatives.", "labels": [], "entities": [{"text": "alignment masking", "start_pos": 99, "end_pos": 116, "type": "TASK", "confidence": 0.8461519777774811}, {"text": "alignment reinsertion", "start_pos": 121, "end_pos": 142, "type": "TASK", "confidence": 0.7684988081455231}]}, {"text": "We provide implementations of all the methods described and they are freely available as an open-source framework 1 .", "labels": [], "entities": []}], "introductionContent": [{"text": "It is very common for machine translation to be used in workflows where the source documents contain XML markup.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.7753952145576477}]}, {"text": "If a document was originally written in Microsoft Word, then in a line like Ich bitte Sie, sich zu einer Schweigeminute zu erheben.", "labels": [], "entities": []}, {"text": "[Please rise, then, for this minute's silence.] the inline formatting (boldface) will internally be represented as inline XML markup, similar to: Ich bitte Sie, sich zu einer Schweigeminute zu <b>erheben</b>.", "labels": [], "entities": []}, {"text": "Before translation, such a document would probably be converted to a more flexible and interoperable format that is ubiquitous in the translation industry, XLIFF, which is also an XML standard.", "labels": [], "entities": [{"text": "translation", "start_pos": 7, "end_pos": 18, "type": "TASK", "confidence": 0.982742428779602}]}, {"text": "Nevertheless, inline XML elements will remain in the source segments and in theory could actually be sent to a machine translation system.", "labels": [], "entities": []}, {"text": "But in practice, standard machine translation systems are unable to properly deal with markup and delegate markup handling to downstream applications like computer-assisted translation (CAT) tools.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.7200890779495239}, {"text": "computer-assisted translation (CAT)", "start_pos": 155, "end_pos": 190, "type": "TASK", "confidence": 0.8704853773117065}]}, {"text": "For instance, the machine translation framework Moses () does not have a standard solution for markup handling.", "labels": [], "entities": [{"text": "machine translation framework Moses", "start_pos": 18, "end_pos": 53, "type": "TASK", "confidence": 0.7251483425498009}, {"text": "markup handling", "start_pos": 95, "end_pos": 110, "type": "TASK", "confidence": 0.8080011010169983}]}, {"text": "Using a standard, phrase-based SMT system trained with Moses, the translation of markup breaks as early as during tokenization.", "labels": [], "entities": [{"text": "SMT", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.8491693735122681}]}, {"text": "Standard tokenization is not aware of XML markup and will tear apart XML element tags: Ich bitte Sie , sich zu einer Schweigeminute zu < b > erheben < / b > . No subsequent step during translation will be able to undo the damage and since the XML standard enforces strict rules, the output is very likely a malformed XML fragment.", "labels": [], "entities": []}, {"text": "But even if tokenization were aware of XML markup (we provide an implementation of markup-aware tokenization) another problem remains: XML markup does not need to be translated at all since it has clear-cut, language-independent semantics and a statistical system should not be trusted to copy the markup to the target segment unchanged.", "labels": [], "entities": []}, {"text": "So, if a machine translation system is given a source segment that contains inline markup, it should be able to detect the markup and not treat it as text.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 9, "end_pos": 28, "type": "TASK", "confidence": 0.7024804055690765}]}, {"text": "But simply stripping the markup from the source segment is not satisfactory.", "labels": [], "entities": []}, {"text": "If, for instance, a translation system would offer Please rise, then, for this minute's silence.", "labels": [], "entities": []}, {"text": "as a translation, we argue that part of the information present in the source segment (the formatting encoded in the markup tags <b> and </b>) was \"lost in translation\".", "labels": [], "entities": [{"text": "translation", "start_pos": 5, "end_pos": 16, "type": "TASK", "confidence": 0.9690383076667786}]}, {"text": "From the point of view of translators, losing the markup during translation has inconvenient consequences.", "labels": [], "entities": []}, {"text": "In many translation projects, automatic pre-translation of the source segments is an obligatory step and human translators, instead of translating from scratch, will post-edit the pre-translations.", "labels": [], "entities": []}, {"text": "There is reason to believe that wrongly translated markup has an impact on translator productivity.", "labels": [], "entities": []}, {"text": "argue that an MT system should handle XML markup correctly to avoid inefficient translation workflows.", "labels": [], "entities": [{"text": "MT", "start_pos": 14, "end_pos": 16, "type": "TASK", "confidence": 0.9723180532455444}]}, {"text": "In the same vein, say that \"post-editing SMT output without the formatting information found in the source may represent a serious loss of productivity\".", "labels": [], "entities": [{"text": "SMT output", "start_pos": 41, "end_pos": 51, "type": "TASK", "confidence": 0.9246219098567963}]}, {"text": "state \"that inline tags have a big impact on productivity, a fact which is not reflected in any of the known metrics and which has not yet received much attention in research\".", "labels": [], "entities": []}, {"text": "We agree with this assessment and would like to work towards the goal of implementing markup handling in standard machine translation frameworks.", "labels": [], "entities": [{"text": "markup handling", "start_pos": 86, "end_pos": 101, "type": "TASK", "confidence": 0.8043052554130554}, {"text": "machine translation frameworks", "start_pos": 114, "end_pos": 144, "type": "TASK", "confidence": 0.7741172512372335}]}, {"text": "Several solutions have been put forward, but there is no consensus as to which strategy should be employed in standard use cases.", "labels": [], "entities": []}, {"text": "Studies that compare different approaches are currently lacking.", "labels": [], "entities": []}, {"text": "In order to facilitate those comparisons, we have implemented different markup handling strategies in the same machine translation framework.", "labels": [], "entities": []}, {"text": "We have then carried out experiments to gauge the usefulness of each markup strategy, which we will describe in the remainder of this paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "We compare the overall performance of all 5 implemented markup handling strategies by training a series of SMT systems.", "labels": [], "entities": [{"text": "markup handling", "start_pos": 56, "end_pos": 71, "type": "TASK", "confidence": 0.8076991438865662}, {"text": "SMT", "start_pos": 107, "end_pos": 110, "type": "TASK", "confidence": 0.9857274889945984}]}, {"text": "The systems are identical except for their method of markup handling.", "labels": [], "entities": [{"text": "markup handling", "start_pos": 53, "end_pos": 68, "type": "TASK", "confidence": 0.8510084450244904}]}, {"text": "What all systems have in common is the data sets, preprocessing (except for markup handling), model training and translation parameters.", "labels": [], "entities": []}, {"text": "We have randomly divided the data sets into training (roughly 400k segments for XLIFF data, roughly 1.7m for Euromarkup data), tuning (2000 segments) and testing (1000 segments) sets that were fixed for all systems, the direction of translation is always from German to English.", "labels": [], "entities": [{"text": "XLIFF data", "start_pos": 80, "end_pos": 90, "type": "DATASET", "confidence": 0.7779055535793304}, {"text": "Euromarkup data", "start_pos": 109, "end_pos": 124, "type": "DATASET", "confidence": 0.962242841720581}]}, {"text": "We train a fairly standard, phrase-based SMT system with Moses: a maximum phrase length of 7, a 5-gram KenLM language model with modified Kneser-Ney smoothing, lexicalized reordering model, standard Moses recasing and standard tokenization.", "labels": [], "entities": [{"text": "SMT", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.8982575535774231}]}, {"text": "Word alignment and symmetrization is performed by fast align and atools).", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.6859440058469772}]}, {"text": "The phrase and reordering table are compressed with the cmph library.", "labels": [], "entities": [{"text": "cmph library", "start_pos": 56, "end_pos": 68, "type": "DATASET", "confidence": 0.9716941118240356}]}, {"text": "The weights of the model are tuned with MERT.", "labels": [], "entities": [{"text": "MERT", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.986443281173706}]}, {"text": "For all of the five implemented strategies, such a system was trained, varying only the markup handling.", "labels": [], "entities": []}, {"text": "Since our framework allows more finegrained control over the algorithms, we have used the following settings: if there is uncertainty about where a markup tag should be placed, it must still be inserted into the translation at the very end.", "labels": [], "entities": []}, {"text": "The translation of mask tokens is not enforced (\"forced decoding\"), instead the decision is left to the decoder.", "labels": [], "entities": [{"text": "translation of mask tokens", "start_pos": 4, "end_pos": 30, "type": "TASK", "confidence": 0.8278916925191879}]}, {"text": "In addition to the five systems above, we have trained the following baseline system: \u2022 strip: markup is stripped entirely from the training, tuning and evaluation corpus.", "labels": [], "entities": [{"text": "strip", "start_pos": 88, "end_pos": 93, "type": "METRIC", "confidence": 0.992669939994812}]}, {"text": "in order to have an estimate of the overall quality of machine translation when no markup is involved.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.7411931157112122}]}, {"text": "Finally, we have measured the outcome of our experiments automatically and manually.", "labels": [], "entities": []}, {"text": "Automatic metrics should never be used to evaluate the performance of markup handling methods, and we have employed them only to answer a preliminary question: do mask tokens in the training data have an impact on the overall quality of machine translation?", "labels": [], "entities": [{"text": "machine translation", "start_pos": 237, "end_pos": 256, "type": "TASK", "confidence": 0.7782510221004486}]}, {"text": "It is unclear whether mask tokens affect negatively the overall output of the system and if that were the case, developers should refrain from using masking to handle markup.", "labels": [], "entities": []}, {"text": "We measure the effect of mask tokens by comparing the machine-translated test set with the human reference after removing markup on both sides.", "labels": [], "entities": []}, {"text": "Then, the MultEval tool is used) to report BLEU (), METEOR (Lavie and Agarwal, 2007), TER () and length scores.", "labels": [], "entities": [{"text": "MultEval", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.6487504839897156}, {"text": "BLEU", "start_pos": 43, "end_pos": 47, "type": "METRIC", "confidence": 0.9921667575836182}, {"text": "METEOR", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9972789883613586}, {"text": "TER", "start_pos": 86, "end_pos": 89, "type": "METRIC", "confidence": 0.9979228377342224}, {"text": "length scores", "start_pos": 97, "end_pos": 110, "type": "METRIC", "confidence": 0.9713829159736633}]}, {"text": "While the automatic evaluation translates all of the 1000 segments in the test set, the manual evaluation only looks at the segments where both the source and target reference have tags in them.", "labels": [], "entities": []}, {"text": "Markup tags were inspected manually and assigned one of the following categories (inspired by): \u2022 good: correct markup is present, correctly placed, \u2022 reasonable: correct markup is present, but needs to be moved, \u2022 wrong: markup is broken or not present at all, \u2022 garbage-in: the decoder output is unintelligible and there is no proper place for markup.", "labels": [], "entities": []}, {"text": "In general, it is always preferable to transfer markup tags to the target segment, even if the correct position cannot be determined.", "labels": [], "entities": []}, {"text": "From the point of view of the post-editor, it is more efficient to move a markup tag instead of going back to the source segment.", "labels": [], "entities": []}, {"text": "Therefore, markup tags that are in the wrong place are described as \"reasonable\".", "labels": [], "entities": []}, {"text": "In theory, there are scenarios where markup tags should be dropped entirely (because all tokens related to them have no translation) but in the vast majority of cases, missing markup tags are \"wrong\".", "labels": [], "entities": []}, {"text": "In this manual evaluation we will focus on evaluating the markup handling, not the performance: Automatic evaluation of the overall performance of markup handling methods, after markup was removed completely.", "labels": [], "entities": []}, {"text": "The metrics reported are BLEU (higher is better), METEOR (higher is better) and TER (lower is better).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9996862411499023}, {"text": "METEOR", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9979239702224731}, {"text": "TER", "start_pos": 80, "end_pos": 83, "type": "METRIC", "confidence": 0.9993171691894531}]}, {"text": "IM = identity masking, AM = alignment masking, SR = segmentation reinsertion, AR = alignment reinsertion, HR = hybrid reinsertion. of the systems in general.", "labels": [], "entities": [{"text": "IM", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.9251860976219177}, {"text": "identity masking", "start_pos": 5, "end_pos": 21, "type": "TASK", "confidence": 0.7103182077407837}, {"text": "alignment masking", "start_pos": 28, "end_pos": 45, "type": "TASK", "confidence": 0.6325950920581818}, {"text": "SR", "start_pos": 47, "end_pos": 49, "type": "METRIC", "confidence": 0.9725095629692078}, {"text": "AR", "start_pos": 78, "end_pos": 80, "type": "METRIC", "confidence": 0.9892895817756653}]}, {"text": "For each data set, we decided to look at a maximum of 200 parallel segments from the test set that contain markup.", "labels": [], "entities": []}, {"text": "In the XLIFF test set, only 176 segments contain markup, so all of them were evaluated, which amounts to a total of 658 tags.", "labels": [], "entities": [{"text": "XLIFF test set", "start_pos": 7, "end_pos": 21, "type": "DATASET", "confidence": 0.8899829387664795}]}, {"text": "In the Euromarkup test set, we annotated the first 200 segments that contain markup, and they contain 584 tags in total.", "labels": [], "entities": [{"text": "Euromarkup test set", "start_pos": 7, "end_pos": 26, "type": "DATASET", "confidence": 0.988438069820404}]}, {"text": "We only look at the lowercased, tokenized version of the translation output, after processing the reference accordingly.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Automatic evaluation of the overall performance of markup handling methods, after markup was  removed completely. The metrics reported are BLEU (higher is better), METEOR (higher is better) and  TER (lower is better). IM = identity masking, AM = alignment masking, SR = segmentation reinsertion,  AR = alignment reinsertion, HR = hybrid reinsertion.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 149, "end_pos": 153, "type": "METRIC", "confidence": 0.9994981288909912}, {"text": "METEOR", "start_pos": 174, "end_pos": 180, "type": "METRIC", "confidence": 0.9979665279388428}, {"text": "TER", "start_pos": 205, "end_pos": 208, "type": "METRIC", "confidence": 0.9981088638305664}, {"text": "identity masking", "start_pos": 233, "end_pos": 249, "type": "TASK", "confidence": 0.7032270580530167}, {"text": "alignment masking", "start_pos": 256, "end_pos": 273, "type": "TASK", "confidence": 0.6600976288318634}, {"text": "AR", "start_pos": 307, "end_pos": 309, "type": "METRIC", "confidence": 0.987675666809082}]}, {"text": " Table 4: Manual evaluation of the performance of markup handling methods, by tags. IM = identity  masking, AM = alignment masking, SR = segmentation reinsertion, AR = alignment reinsertion, HR =  hybrid reinsertion.", "labels": [], "entities": [{"text": "IM", "start_pos": 84, "end_pos": 86, "type": "METRIC", "confidence": 0.9885403513908386}, {"text": "identity  masking", "start_pos": 89, "end_pos": 106, "type": "TASK", "confidence": 0.6608115285634995}, {"text": "AR", "start_pos": 163, "end_pos": 165, "type": "METRIC", "confidence": 0.9696661233901978}]}]}