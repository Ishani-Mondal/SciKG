{"title": [{"text": "Representation Learning for Answer Selection with LSTM-Based Importance Weighting", "labels": [], "entities": [{"text": "Answer Selection", "start_pos": 28, "end_pos": 44, "type": "TASK", "confidence": 0.9731174409389496}, {"text": "LSTM-Based Importance Weighting", "start_pos": 50, "end_pos": 81, "type": "TASK", "confidence": 0.5089827179908752}]}], "abstractContent": [{"text": "We present an approach to non-factoid answer selection with a separate component based on BiLSTM to determine the importance of segments in the input.", "labels": [], "entities": [{"text": "answer selection", "start_pos": 38, "end_pos": 54, "type": "TASK", "confidence": 0.7203197926282883}, {"text": "BiLSTM", "start_pos": 90, "end_pos": 96, "type": "DATASET", "confidence": 0.7624850273132324}]}, {"text": "In contrast to other recently proposed attention-based models within the same area, we determine the importance while assuming the independence of questions and candidate answers.", "labels": [], "entities": []}, {"text": "Experimental results show the effectiveness of our approach, which outperforms several state-of-the-art attention-based models on the recent non-factoid answer selection datasets InsuranceQA v1 and v2.", "labels": [], "entities": [{"text": "answer selection datasets InsuranceQA v1", "start_pos": 153, "end_pos": 193, "type": "DATASET", "confidence": 0.6317560732364654}]}, {"text": "We show that it is possible to perform effective importance weighting for answer selection without relying on the relatedness of questions and answers.", "labels": [], "entities": [{"text": "answer selection", "start_pos": 74, "end_pos": 90, "type": "TASK", "confidence": 0.8851618766784668}]}, {"text": "The source code of our experiments is publicly available.", "labels": [], "entities": []}], "introductionContent": [{"text": "Answer selection is an important subtask of question answering (QA) that enables choosing one final answer from a list of candidate answers in regard to the input question;.", "labels": [], "entities": [{"text": "Answer selection", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.9045910239219666}, {"text": "question answering (QA)", "start_pos": 44, "end_pos": 67, "type": "TASK", "confidence": 0.8580932736396789}]}, {"text": "QA itself can be divided into factoid QA, which enables the retrieval of facts, and nonfactoid QA, which enables finding of complex answer texts (e.g. descriptions, opinions, or explanations).", "labels": [], "entities": [{"text": "finding of complex answer texts (e.g. descriptions, opinions, or explanations)", "start_pos": 113, "end_pos": 191, "type": "TASK", "confidence": 0.7620616172041211}]}, {"text": "Answer selection for non-factoid QA is especially difficult because we usually deal with user-generated content, for example questions and answers extracted from community question answering platforms or FAQ websites.", "labels": [], "entities": [{"text": "Answer selection", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.941380649805069}, {"text": "questions and answers extracted from community question answering platforms or FAQ websites", "start_pos": 125, "end_pos": 216, "type": "TASK", "confidence": 0.7453919276595116}]}, {"text": "As a consequence, candidate answers are complex multi-sentence texts with detailed information.", "labels": [], "entities": []}, {"text": "Two examples are shown in Figures 2 and 3.", "labels": [], "entities": []}, {"text": "To deal with this challenge, recent approaches employ attention-based neural networks to focus on segments within the candidate answer that are most related to the question (.", "labels": [], "entities": []}, {"text": "For scoring, dense vector representations of the question and the candidate answer are learned and the distance between the vectors is measured.", "labels": [], "entities": []}, {"text": "With attention-based models, segments with a stronger focus are treated as more important and have more influence on the resulting representations.", "labels": [], "entities": []}, {"text": "Using the relatedness between a candidate answer and the question to determine the importance is intuitive for correct candidate answers because the most important segments of both texts are expected to be strongly related.", "labels": [], "entities": []}, {"text": "However, we also deal with a large number of incorrect candidate answers where the most important segments are usually dissimilar to the question.", "labels": [], "entities": []}, {"text": "In such cases, the relatedness does not correlate with the actual importance.", "labels": [], "entities": []}, {"text": "Thus, different methods for determining the importance could lead to better representations, especially when dealing with incorrect candidate answers.", "labels": [], "entities": []}, {"text": "In this work, we therefore determine the importance of segments in questions and candidate answers with a method that assumes the independence of both items.", "labels": [], "entities": []}, {"text": "Our approach uses CNN and BiLSTM for representation learning and employs a separate network component based on BiLSTM for importance weighting.", "labels": [], "entities": [{"text": "representation learning", "start_pos": 37, "end_pos": 60, "type": "TASK", "confidence": 0.9466736912727356}, {"text": "importance weighting", "start_pos": 122, "end_pos": 142, "type": "TASK", "confidence": 0.7384987771511078}]}, {"text": "Our general concept is similar to self-attention mechanisms that have recently been integrated to models for natural language inference and sentiment classification (.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 140, "end_pos": 164, "type": "TASK", "confidence": 0.923018604516983}]}, {"text": "They however employ feedforward components to derive importance values and deal with classification problems.", "labels": [], "entities": []}, {"text": "In contrast, we directly compare learned representations with a similarity measure and derive the importance using a separate BiLSTM, which was motivated by the effectiveness of stacked models in answer selection.", "labels": [], "entities": [{"text": "BiLSTM", "start_pos": 126, "end_pos": 132, "type": "METRIC", "confidence": 0.5646880269050598}, {"text": "answer selection", "start_pos": 196, "end_pos": 212, "type": "TASK", "confidence": 0.8251319229602814}]}, {"text": "We evaluate our approach on two non-factoid answer selection datasets that contain data from a community question answering platform: InsuranceQA v1 and InsuranceQA v2.", "labels": [], "entities": [{"text": "InsuranceQA", "start_pos": 134, "end_pos": 145, "type": "DATASET", "confidence": 0.9356359839439392}, {"text": "InsuranceQA", "start_pos": 153, "end_pos": 164, "type": "DATASET", "confidence": 0.9356839656829834}]}, {"text": "In comparison to other state-of-the-art representation learning approaches with attention, our approach achieves the best results and significantly outperforms various strong baselines.", "labels": [], "entities": []}, {"text": "An additional evaluation on the factoid QA dataset WikiQA demonstrates that our approach is well-suited for other scenarios that deal with shorter texts.", "labels": [], "entities": [{"text": "factoid QA dataset WikiQA", "start_pos": 32, "end_pos": 57, "type": "DATASET", "confidence": 0.5840087346732616}]}, {"text": "In general, we show that it is possible to perform effective importance weighting in non-factoid answer selection without relying on the relatedness of questions and candidate answers.", "labels": [], "entities": []}], "datasetContent": [{"text": "Training We define the loss L as follows: where r q is the learned question representation, r a+ and r a\u2212 are learned representations of correct and incorrect candidate answers, sis cosine similarity, and m is the desired margin between the similarities.", "labels": [], "entities": [{"text": "sis cosine similarity", "start_pos": 178, "end_pos": 199, "type": "METRIC", "confidence": 0.5544829865296682}]}, {"text": "Because such triples are not pre-defined in our datasets, we construct them during training.", "labels": [], "entities": []}, {"text": "For a pair of question and correct answer we randomly sample 50 incorrect candidate answers from the whole training set and select the candidate with the highest similarity according to our currently trained model.", "labels": [], "entities": []}, {"text": "We evaluate our models on the two recent non-factoid answer selection datasets InsuranceQA v1 and InsuranceQA v2.", "labels": [], "entities": [{"text": "answer selection datasets InsuranceQA v1", "start_pos": 53, "end_pos": 93, "type": "DATASET", "confidence": 0.6600282430648804}, {"text": "InsuranceQA", "start_pos": 98, "end_pos": 109, "type": "DATASET", "confidence": 0.9138616919517517}]}, {"text": "In general, both datasets contain more than 15,000 questions and the candidate answers are long multi-sentence texts.", "labels": [], "entities": []}, {"text": "Even though InsuranceQA v1 and v2 were crawled from the same community question answering website, they model different setups due to a different sampling strategy that was used to create the candidate answer pools.", "labels": [], "entities": [{"text": "InsuranceQA", "start_pos": 12, "end_pos": 23, "type": "DATASET", "confidence": 0.9349687695503235}]}, {"text": "Whereas in InsuranceQA v1 the pools were created randomly (plus the correct answers), the pools in InsuranceQA v2 were created by querying a search engine to retrieve candidate answers that are lexically similar to the question.", "labels": [], "entities": [{"text": "InsuranceQA", "start_pos": 11, "end_pos": 22, "type": "DATASET", "confidence": 0.9107734560966492}, {"text": "InsuranceQA", "start_pos": 99, "end_pos": 110, "type": "DATASET", "confidence": 0.912559449672699}]}, {"text": "In addition, we also test our approaches on the factoid answer selection dataset WikiQA, which was constructed by means of crowd-sourcing through the extraction of sentences from Wikipedia articles ().", "labels": [], "entities": [{"text": "factoid answer selection dataset WikiQA", "start_pos": 48, "end_pos": 87, "type": "DATASET", "confidence": 0.6405007481575012}]}, {"text": "We use this dataset to test our models within the different scenario of factoid answer selection that deals with significantly shorter texts.", "labels": [], "entities": [{"text": "factoid answer selection", "start_pos": 72, "end_pos": 96, "type": "TASK", "confidence": 0.7851701378822327}]}, {"text": "The dataset statistics are listed in   Neural Network Setup We performed grid search over several hyperparameter combinations and found the optimal choices to be similar to hyperparameters of previous work.", "labels": [], "entities": []}, {"text": "The cell size of all LSTMs is 141 (each direction), and the number of filters for all CNNs is 400 with size 3.", "labels": [], "entities": []}, {"text": "The only exception is CNN +BiLSTM with 282 filters and a cell size of 282.", "labels": [], "entities": [{"text": "CNN +BiLSTM", "start_pos": 22, "end_pos": 33, "type": "DATASET", "confidence": 0.8672510782877604}]}, {"text": "We use the Adam optimizer () with a learning rate of 4 \u00b7 10 \u22124 and a margin m = 0.2.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 36, "end_pos": 49, "type": "METRIC", "confidence": 0.9433116316795349}]}, {"text": "We initialize the word embeddings with off-the-shelf 100-dimensional uncased GloVe embeddings () and optimize them further during training.", "labels": [], "entities": []}, {"text": "Dropout of 0.3 was applied on the representations before comparison.", "labels": [], "entities": [{"text": "Dropout", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9701381325721741}]}, {"text": "We chose different hyperparameters for WikiQA, which we do not list here due to space restrictions.", "labels": [], "entities": [{"text": "WikiQA", "start_pos": 39, "end_pos": 45, "type": "DATASET", "confidence": 0.8836296200752258}]}, {"text": "Details can be found in our public source code repository.", "labels": [], "entities": []}, {"text": "InsuranceQA v1 Our evaluation on InsuranceQA v1 allows us to compare our approach against abroad list of recently published attention-based models.", "labels": [], "entities": [{"text": "InsuranceQA", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.9512554407119751}, {"text": "InsuranceQA", "start_pos": 33, "end_pos": 44, "type": "DATASET", "confidence": 0.9048628807067871}]}, {"text": "shows the results of our evaluation where we measure the ratio of correctly selected answers (accuracy).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9992091059684753}]}, {"text": "We observe that by adding LW to either CNN or BiLSTM we can significantly improve the answer selection performance by 9.6% and 4.3% respectively.", "labels": [], "entities": [{"text": "CNN", "start_pos": 39, "end_pos": 42, "type": "DATASET", "confidence": 0.9718363881111145}, {"text": "BiLSTM", "start_pos": 46, "end_pos": 52, "type": "DATASET", "confidence": 0.7754135727882385}, {"text": "answer selection", "start_pos": 86, "end_pos": 102, "type": "TASK", "confidence": 0.8644298911094666}]}, {"text": "This clearly shows that LW is effective and can be used to extend basic models to learn better representations of questions and candidate answers.", "labels": [], "entities": []}, {"text": "Additionally, LW models are more effective than stacked models due to the different network structure that we use to explicitly learn importance weights.", "labels": [], "entities": []}, {"text": "Stacked models are less effective because they need to carry the full representation through all components.", "labels": [], "entities": []}, {"text": "Overall, LW BiLSTM significantly outperforms all our other tested models.", "labels": [], "entities": [{"text": "LW", "start_pos": 9, "end_pos": 11, "type": "DATASET", "confidence": 0.5707225799560547}, {"text": "BiLSTM", "start_pos": 12, "end_pos": 18, "type": "METRIC", "confidence": 0.7757318019866943}]}, {"text": "LW BiLSTM also achieves the best results compared to other state-of-the-art representation learning approaches with attention such as the two-way attention model AP BiLSTM , which derives attention from a learned measure of similarity between questions and answers.", "labels": [], "entities": [{"text": "LW BiLSTM", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.7989451587200165}]}, {"text": "This clearly shows that we can successfully perform importance weighting without relying on the relatedness of questions and answers.", "labels": [], "entities": [{"text": "importance weighting", "start_pos": 52, "end_pos": 72, "type": "TASK", "confidence": 0.7661393582820892}]}, {"text": "It is important to mention that very recently experimented with a novel   method that achieves state-of-the-art results on the InsuranceQA v1 dataset.", "labels": [], "entities": [{"text": "InsuranceQA v1 dataset", "start_pos": 127, "end_pos": 149, "type": "DATASET", "confidence": 0.9546582500139872}]}, {"text": "Instead of learning dense vector representations, they classify pairs of questions and candidate answers with a compare-aggregate model that performs comparisons on the word level, aggregates this information with CNN, and uses additional layers to determine the classification result.", "labels": [], "entities": []}, {"text": "Because their approach is not learning dense vector representations, we did not directly compare against it.", "labels": [], "entities": []}, {"text": "It would however be possible to use our approach in their framework to compare segments of weighted unpooled representations.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Experimental results on InsuranceQA v1  (accuracy). * = significant improvement against  our other models (p < 0.05, Wilcoxon test). 3", "labels": [], "entities": [{"text": "InsuranceQA", "start_pos": 34, "end_pos": 45, "type": "DATASET", "confidence": 0.7095809578895569}, {"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9962211847305298}]}, {"text": " Table 4: Experimental results on WikiQA com- pared to recent approaches with attention.", "labels": [], "entities": []}, {"text": " Table 5: Experimental results with shared vs. sepa- rate LW weights.", "labels": [], "entities": [{"text": "sepa- rate LW weights", "start_pos": 47, "end_pos": 68, "type": "METRIC", "confidence": 0.7409086048603057}]}]}