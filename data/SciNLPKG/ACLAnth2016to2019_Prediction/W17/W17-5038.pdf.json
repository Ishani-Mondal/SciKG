{"title": [{"text": "Question Generation for Language Learning: From ensuring texts are read to supporting learning", "labels": [], "entities": [{"text": "Question Generation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.6760265231132507}]}], "abstractContent": [{"text": "In Foreign Language Teaching and Learning (FLTL), questions are systematically used to assess the learner's understanding of a text.", "labels": [], "entities": [{"text": "Foreign Language Teaching and Learning (FLTL)", "start_pos": 3, "end_pos": 48, "type": "TASK", "confidence": 0.8298113867640495}]}, {"text": "Computational linguistic (CL) approaches have been developed to generate such questions automatically given a text (e.g., Heilman, 2011).", "labels": [], "entities": []}, {"text": "In this paper, we want to broaden the perspective on the different functions questions can play in FLTL and discuss how automatic question generation can support the different uses.", "labels": [], "entities": [{"text": "question generation", "start_pos": 130, "end_pos": 149, "type": "TASK", "confidence": 0.7266864776611328}]}, {"text": "Complementing the focus on meaning and comprehension, we want to highlight the fact that questions can also be used to make learners notice form aspects of the linguistic system and their interpretation.", "labels": [], "entities": []}, {"text": "Automatically generating questions that target linguistic forms and grammatical categories in a text in essence supports incidental focus-on-form (Loewen, 2005) in a meaning-focused reading task.", "labels": [], "entities": []}, {"text": "We discuss two types of questions serving this purpose, how they can be generated automatically ; and we report on a crowd-sourcing evaluation comparing automatically generated to manually written questions targeting particle verbs, a challenging linguistic form for learners of English.", "labels": [], "entities": []}], "introductionContent": [{"text": "\"Learning is goal-oriented . .", "labels": [], "entities": []}, {"text": "Teaching therefore becomes an active thinking and decision-making process in which the teacher is constantly assessing what students already know, what they need to know, and how to provide for successful learning.\"", "labels": [], "entities": []}, {"text": "One of the most common ways to find out what students do and do not know is to ask questions.", "labels": [], "entities": []}, {"text": "In communicative and task-based language teaching, where the meaning and function of language drives the pedagogy, questions are asked to support the task at hand.", "labels": [], "entities": []}, {"text": "Relatedly, when dealing with written language material, recall or comprehension questions can spell out typical goals for reading a text: searching for specific information or more comprehensively integrating the information provided in the text into the reader's background knowledge to draw inferences on that basis.", "labels": [], "entities": [{"text": "recall", "start_pos": 56, "end_pos": 62, "type": "METRIC", "confidence": 0.9967436790466309}]}, {"text": "An increasing body of CL research supports the automatic generation of questions in order to assist teachers in constructing practice exercises and tests.", "labels": [], "entities": [{"text": "automatic generation of questions", "start_pos": 47, "end_pos": 80, "type": "TASK", "confidence": 0.756896123290062}]}, {"text": "For example, Heilman (2011) is a prominent approach for the generation of factual, lowlevel questions suitable for beginner or intermediate students.", "labels": [], "entities": []}, {"text": "His goal is to assess the reader's knowledge of the information in the text, which is relevant for both content and language teaching.", "labels": [], "entities": []}, {"text": "At the same time, Second Language Acquisition (SLA) research since the 90s has emphasized that language input and meaning-based tasks alone are not sufficient to ensure successful language acquisition.", "labels": [], "entities": [{"text": "Second Language Acquisition (SLA)", "start_pos": 18, "end_pos": 51, "type": "TASK", "confidence": 0.8019434809684753}, {"text": "language acquisition", "start_pos": 180, "end_pos": 200, "type": "TASK", "confidence": 0.713597297668457}]}, {"text": "Learners must also notice linguistic forms and grammatical categories and teaching can facilitate such noticing through so-called focus on form.", "labels": [], "entities": []}, {"text": "Focus on form is designed to draw the learner's attention to relevant linguistic features of the language as they arise, while keeping the overriding focus on meaning).", "labels": [], "entities": []}, {"text": "For written language, input enhancement has been proposed to make relevant forms more salient in the input, e.g., by coloring or font choices.", "labels": [], "entities": []}, {"text": "Such visual input enhancement has also been automated using CL methods (, as part of a system also generating in-text exercises.", "labels": [], "entities": []}, {"text": "One problem with form-based visual input enhancement is that coloring a form or otherwise making it visually more salient neither ensures that it is noticed and cognitively processed more thoroughly nor do we know which aspect of that form the reader will notice and how it is interpreted.", "labels": [], "entities": [{"text": "form-based visual input enhancement", "start_pos": 17, "end_pos": 52, "type": "TASK", "confidence": 0.6451272964477539}]}, {"text": "For example, coloring the form has been raining in a text may draw the reader's attention to any aspect of those forms (e.g., number or length of the words, or the -ing suffix of the last word), and noticing the form does not necessarily map it to its present perfect continuous interpretation.", "labels": [], "entities": []}, {"text": "In this paper, we propose another option for providing input enhancement, functionally-driven input enhancement.", "labels": [], "entities": []}, {"text": "Concretely, we propose to generate two types of questions creating a functional need to process the targeted linguistic features.", "labels": [], "entities": []}, {"text": "The first type of questions we generate are content questions about the clause containing the targeted form.", "labels": [], "entities": []}, {"text": "So these questions are like Heilman's factual questions, but they are targeting sentences containing particular linguistic features to be acquired.", "labels": [], "entities": []}, {"text": "To answer such questions, the learner must process form and meaning of the clause, ensuring increased activation of the targeted form.", "labels": [], "entities": []}, {"text": "The goal of these questions is to ensure more exposure to the forms, so we will refer to them as form exposure questions.", "labels": [], "entities": []}, {"text": "The second type of functionally-driven input enhancement is designed to also ensure interpretation of the targeted form.", "labels": [], "entities": []}, {"text": "For this, the nature of the question that is generated must be changed from asking about the content of the text to asking about the interpretation of the form being targeted.", "labels": [], "entities": []}, {"text": "In the spirit of the concept questions of Workman (2008), we will refer to such questions as grammar concept questions.", "labels": [], "entities": []}, {"text": "The goal of this paper is to combine insights from SLA research with CL techniques to explore new options for question generation in support of language learning.", "labels": [], "entities": [{"text": "SLA", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.9494212865829468}, {"text": "question generation", "start_pos": 110, "end_pos": 129, "type": "TASK", "confidence": 0.7326441258192062}]}, {"text": "In section 2, we first characterize the overall spectrum of questions we consider to be of relevance to FLTL, from supporting communication via ensuring texts are read to supporting learning of linguistic forms and their function.", "labels": [], "entities": [{"text": "FLTL", "start_pos": 104, "end_pos": 108, "type": "TASK", "confidence": 0.9522479176521301}]}, {"text": "Section 3.1 then surveys the computational linguistic work on automatic question generation, which has focused on the content-side of the spectrum.", "labels": [], "entities": [{"text": "automatic question generation", "start_pos": 62, "end_pos": 91, "type": "TASK", "confidence": 0.6557268500328064}]}, {"text": "Section 3.2 spells out the SLA background needed to motivate our research on question generation targeting linguistic forms and their interpretation.", "labels": [], "entities": [{"text": "question generation", "start_pos": 77, "end_pos": 96, "type": "TASK", "confidence": 0.7686243057250977}]}, {"text": "In section 4 we then present the question generation approach we developed, mostly concentrating on the two new types of questions designed to provide functionally-driven input enhancement.", "labels": [], "entities": [{"text": "question generation", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.835234522819519}]}, {"text": "For such questions to be effective, they must be reasonably well-formed and answerable, so in section 5 we present the results from a crowd sourcing experiment we conducted to evaluate whether the automatically generated form exposure questions are comparable to manually written questions in those two respects.", "labels": [], "entities": []}, {"text": "Finally, section 6 provides a conclusion and outlook.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results of Schuirmann's TOST for equiv- alence of computer-generated and human-written  questions. Effect size d = 0.5; alpha = 0.05.", "labels": [], "entities": [{"text": "Effect size d", "start_pos": 109, "end_pos": 122, "type": "METRIC", "confidence": 0.9599477251370748}]}]}