{"title": [{"text": "Adapting predominant and novel sense discovery algorithms for identifying corpus-specific sense differences", "labels": [], "entities": [{"text": "sense discovery", "start_pos": 31, "end_pos": 46, "type": "TASK", "confidence": 0.7629213631153107}, {"text": "identifying corpus-specific sense differences", "start_pos": 62, "end_pos": 107, "type": "TASK", "confidence": 0.6654818281531334}]}], "abstractContent": [{"text": "Word senses are not static and may have temporal, spatial or corpus-specific scopes.", "labels": [], "entities": []}, {"text": "Identifying such scopes might benefit the existing WSD systems largely.", "labels": [], "entities": [{"text": "WSD", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.816149890422821}]}, {"text": "In this paper, while studying corpus specific word senses, we adapt three existing predominant and novel-sense discovery algorithms to identify these corpus-specific senses.", "labels": [], "entities": []}, {"text": "We make use of text data available in the form of millions of digitized books and newspaper archives as two different sources of corpora and propose automated methods to identify corpus-specific word senses at various time points.", "labels": [], "entities": []}, {"text": "We conduct an extensive and thorough human judgment experiment to rigorously evaluate and compare the performance of these approaches.", "labels": [], "entities": []}, {"text": "Post adaptation, the output of the three algorithms are in the same format and the accuracy results are also comparable , with roughly 45-60% of the reported corpus-specific senses being judged as genuine.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9992231130599976}]}], "introductionContent": [{"text": "Human language is neither static not uniform.", "labels": [], "entities": []}, {"text": "Almost every individual aspect of language including phonological, morphological, syntactic as well as semantic structure can exhibit differences, even for the same language.", "labels": [], "entities": []}, {"text": "These differences can be influenced by a lot of factors such as time, location, corpus type etc.", "labels": [], "entities": []}, {"text": "However, in order to suitably understand these differences, one needs to be able to analyze large volumes of natural language text data collected from diverse corpora.", "labels": [], "entities": []}, {"text": "It is only in this Big Data era that unprecedented amounts of text data have become available in the form of millions of digitized books (Google Books project), newspaper documents, Wikipedia articles as well as tweet streams.", "labels": [], "entities": [{"text": "Google Books project)", "start_pos": 138, "end_pos": 159, "type": "DATASET", "confidence": 0.9293625205755234}]}, {"text": "This huge volume of time and location stamped data across various types of corpora now allows us to make precise quantitative linguistic predictions, which were earlier observed only through mathematical models and computer simulations.", "labels": [], "entities": []}, {"text": "Scope of a word sense: One of the fundamental dimensions of language change is shift in word usage and word senses.", "labels": [], "entities": []}, {"text": "A word may possess many senses; however, not all of the senses are used uniformly; some are more common than the others.", "labels": [], "entities": []}, {"text": "This particular distribution can be heavily dependent on the underlying timeperiod, location or the type of corpora.", "labels": [], "entities": []}, {"text": "For example, let us consider the word \"rock\".", "labels": [], "entities": []}, {"text": "In books, it is usually associated with the sense reflected by the words 'stone, pebble, boulder' etc., while if we look into newspapers and magazines, we find that it is mostly used in the sense of 'rock music'.", "labels": [], "entities": []}, {"text": "Motivation for this work: The world of technology is changing rapidly, and it is no surprise that word senses also reflect this change.", "labels": [], "entities": []}, {"text": "Let us consider the word \"brand\".", "labels": [], "entities": []}, {"text": "This word is mainly used for the 'brand-name' of a product.", "labels": [], "entities": []}, {"text": "However, it has now become a shorthand reference to the skills, actions, personality and other publicly perceived traits of individuals or for characterizing reputation, public face of the whole group or companies.", "labels": [], "entities": []}, {"text": "The rise of social media and the ability to selfpublish and self-advertise undoubtedly led to the emergence of this new sense of \"brand\".", "labels": [], "entities": []}, {"text": "To further motivate such cross corpus sense differences, let us consider the word 'relay'.", "labels": [], "entities": []}, {"text": "A simple Google search in the News section produces results that are very different from those obtained through a search in the Books section (.", "labels": [], "entities": [{"text": "News section", "start_pos": 30, "end_pos": 42, "type": "DATASET", "confidence": 0.9556575119495392}, {"text": "Books section", "start_pos": 128, "end_pos": 141, "type": "DATASET", "confidence": 0.9480332434177399}]}, {"text": "Since the search engine users mostly go for generic search without any explicit mention of book or news, the target word along with a small associated context vector might help the search engine to retrieve document from the most relevant corpora automatically.", "labels": [], "entities": []}, {"text": "We believe that the target and the automatically extracted corpus-specific context vector can be further used to enhance (i) semantic and personalized search, (ii) corpora-specific search and (iii) corpora-specific word sense disambiguation.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 215, "end_pos": 240, "type": "TASK", "confidence": 0.6280566255251566}]}, {"text": "It is an important as well as challenging task to identify predominant word senses specific to various corpora.", "labels": [], "entities": []}, {"text": "While the researchers have started exploring the temporal and spatial scopes of word senses, corpora-specific senses have remained mostly unexplored.", "labels": [], "entities": []}, {"text": "Our contributions: Motivated by the above applications, this paper studies corpora-specific senses for the first time and makes the following contributions 1 : (i) we take two different meth- The code and evaluation results are available at: http: ods for novel sense discovery () and one for predominant sense identification) and adapt these in an automated and unsupervised manner to identify corpus-specific sense fora given word (noun), and (ii) perform a thorough manual evaluation to rigorously compare the corpus-specific senses obtained using these methods.", "labels": [], "entities": [{"text": "novel sense discovery", "start_pos": 256, "end_pos": 277, "type": "TASK", "confidence": 0.7031954924265543}, {"text": "predominant sense identification", "start_pos": 293, "end_pos": 325, "type": "TASK", "confidence": 0.6117326219876608}]}, {"text": "Manual evaluation conducted using 60 candidate words for each method indicates that \u223c45-60% of the corpus-specific senses identified by the adapted algorithms are genuine.", "labels": [], "entities": []}, {"text": "Our work is a unique contribution since it is able to adapt three very different types of major algorithms suitably to identify corpora specific senses.", "labels": [], "entities": []}, {"text": "Key observations: For manual evaluation of the candidate corpus-specific senses, we focused on two aspects -a) sense representation, which tells if the word cluster obtained from a method is a good representative of the target word, and b) sense difference, which tells whether the sense represented by the corpus-specific cluster is different from all the senses of the word in the other corpus.", "labels": [], "entities": []}], "datasetContent": [{"text": "To study corpora-specific senses, we consider books and newspaper articles as two different corpora sources.", "labels": [], "entities": []}, {"text": "We compare these corpora for the same time-periods to ensure that the sense differences are obtained only because of the change in corpus and not due to the difference in time.", "labels": [], "entities": []}, {"text": "A brief description of these datasets is given below.", "labels": [], "entities": []}, {"text": "Books dataset: The books dataset is based on the Google Books Syntactic n-grams corpus  In this section, we discuss our framework for evaluating the candidate corpus-specific senses obtained from the three methods.", "labels": [], "entities": [{"text": "Books dataset", "start_pos": 0, "end_pos": 13, "type": "DATASET", "confidence": 0.8433915674686432}, {"text": "Google Books Syntactic n-grams corpus", "start_pos": 49, "end_pos": 86, "type": "DATASET", "confidence": 0.7724015116691589}]}, {"text": "We perform manual evaluations using an online survey 4 among \u223c 27 agreed participants (students, researchers, professors, technical persons) with age between 18-34 years.", "labels": [], "entities": []}, {"text": "We randomly selected 60 candidate corpus-specific senses (combining both corpora sources) from each of the three methods (roughly 30 words from each time period).", "labels": [], "entities": []}, {"text": "Each participant was given a set of 20 candidate words to evaluate; thus each candidate sense was evaluated by 3 different annotators.", "labels": [], "entities": []}, {"text": "In the survey, the candidate word was provided with its corpus-specific sense cluster (represented by word-clouds of the words in the cluster) and all the sense clusters in the other corpus.", "labels": [], "entities": []}, {"text": "Questions to the participants: The participants were asked two questions.", "labels": [], "entities": []}, {"text": "First, whether the candidate corpus-specific sense cluster is a good representative sense of the target word? and sec-ond, whether the sense represented by the corpusspecific cluster is different from all the senses of the word in the other corpus?", "labels": [], "entities": []}, {"text": "The participants could answer the first question as 'Yes' or 'No' and this response was taken as a measure of \"sense representation\" accuracy of the underlying scheme.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.9934192299842834}]}, {"text": "If this answer is 'No', the answer to the second response was set as 'NA'.", "labels": [], "entities": [{"text": "NA", "start_pos": 70, "end_pos": 72, "type": "METRIC", "confidence": 0.949120283126831}]}, {"text": "If this answer is 'Yes', they would answer the second question as 'Yes' or 'No', which was taken as a measure of \"discriminative sense detection\" accuracy of the underlying method for comparing the senses across the two corpora.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.9974105954170227}]}, {"text": "The overall confidence of a method was obtained by combining the two responses, i.e., whether both the responses are 'Yes'.", "labels": [], "entities": []}, {"text": "The accuracy values are computed using majority voting, where we take the output as 'Yes' if majority of the responses are in agreement with the system and average accuracy, where we find the fraction of responses that are in agreement with the system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9993569254875183}, {"text": "accuracy", "start_pos": 164, "end_pos": 172, "type": "METRIC", "confidence": 0.9978043437004089}]}, {"text": "Since each case is evaluated by 3 participants, micro-and macro-averages will be similar.", "labels": [], "entities": []}, {"text": "Accuracy results: shows the accuracy for the underlying methods.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9969701766967773}, {"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9995648264884949}]}, {"text": "Mitra's and McCarthy's methods perform better for sense representation, and Mitra's method performs very well for discriminative sense detection.", "labels": [], "entities": [{"text": "sense representation", "start_pos": 50, "end_pos": 70, "type": "TASK", "confidence": 0.8267926573753357}, {"text": "discriminative sense detection", "start_pos": 114, "end_pos": 144, "type": "TASK", "confidence": 0.6625699500242869}]}, {"text": "For discriminative sense detection, there were a few undecided cases . As per overall confidence, we observe that McCarthy's method performs the best.", "labels": [], "entities": [{"text": "discriminative sense detection", "start_pos": 4, "end_pos": 34, "type": "TASK", "confidence": 0.7706766724586487}]}, {"text": "Note that the number of candidate senses returned by McCarthy were much less in comparison to the other methods.", "labels": [], "entities": []}, {"text": "Mitra's method performs comparably for both the time periods, while Lau's method performs comparably only for 2006-2008.", "labels": [], "entities": []}, {"text": "Inter-annotator agreement: The inter-annotator agreement for the three methods using Fleiss' kappa is shown in.", "labels": [], "entities": []}, {"text": "We see that the interannotator agreement for Question 2 is much less in comparison to that for Question 1.", "labels": [], "entities": []}, {"text": "This is quite natural since Question 2 is much more difficult to answer than Question 1 even for humans.", "labels": [], "entities": []}, {"text": "Comparison among methods: Further, we wanted to check the relative performance of the three approaches on a common set of words.", "labels": [], "entities": []}, {"text": "McCarthy's output did not have any overlap with the other methods but for Lau and Mitra, among the.", "labels": [], "entities": []}, {"text": "While Lau performs better on discriminative sense detection accuracy, Mitra performs much better overall.", "labels": [], "entities": [{"text": "discriminative sense detection", "start_pos": 29, "end_pos": 59, "type": "TASK", "confidence": 0.5431705017884573}, {"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9305264949798584}]}], "tableCaptions": [{"text": " Table 1: Number of candidate corpus-specific senses using  Mitra's method after multi-stage filtering", "labels": [], "entities": []}, {"text": " Table 2: Number of candidate corpus-specific senses using  McCarthy's method.", "labels": [], "entities": []}, {"text": " Table 3. Note that a word may have mul- tiple corpus-specific senses.", "labels": [], "entities": []}, {"text": " Table 3: Number of candidate words using Lau's method.", "labels": [], "entities": []}, {"text": " Table 4: Accuracy figures for the three methods from manual evaluation.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9992081522941589}]}, {"text": " Table 5: Comparison of accuracy figures for 30 overlap words between Lau and Mitra.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9957952499389648}]}, {"text": " Table 6: Fleiss' kappa for the three methods", "labels": [], "entities": [{"text": "Fleiss' kappa", "start_pos": 10, "end_pos": 23, "type": "DATASET", "confidence": 0.8141902089118958}]}, {"text": " Table 5. While Lau performs better on discrim- inative sense detection accuracy, Mitra performs  much better overall.", "labels": [], "entities": [{"text": "discrim- inative sense detection", "start_pos": 39, "end_pos": 71, "type": "TASK", "confidence": 0.5517734050750732}, {"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9134520292282104}]}, {"text": " Table 8: Results for different thresholds of McCarthy's method to make a total of 50 words. Each cell represents the total  number of words (number of candidate words chosen for a threshold + number of candidate words from the previous thresholds  = total number of candidate words) (overall confidence).", "labels": [], "entities": [{"text": "overall confidence", "start_pos": 285, "end_pos": 303, "type": "METRIC", "confidence": 0.8430467247962952}]}, {"text": " Table 9: Average accuracy for different threshold values in  Lau's method.", "labels": [], "entities": [{"text": "Average", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9453437328338623}, {"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9345532655715942}]}]}