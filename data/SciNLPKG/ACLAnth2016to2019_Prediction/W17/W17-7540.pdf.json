{"title": [{"text": "Acronym Expansion: A Domain Independent Approach", "labels": [], "entities": []}], "abstractContent": [{"text": "Acronyms are present in usually all documents to express information that is repetitive and well known.", "labels": [], "entities": [{"text": "Acronyms", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9715163111686707}]}, {"text": "But acronyms can be ambiguous because there can be many expansions of the same acronym.", "labels": [], "entities": []}, {"text": "In this paper, we propose a general system for acronym expansion that can work on any acronym given some context information it is used in.", "labels": [], "entities": [{"text": "acronym expansion", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.9332172572612762}]}, {"text": "We present methods for retrieving all the possible expansions of an acronym from Wikipedia and AcronymsFinder.com.", "labels": [], "entities": []}, {"text": "We propose to use these expansions to collect the context in which these acronym expansions are used and then score them using a deep learning technique called Doc2Vec.", "labels": [], "entities": []}, {"text": "All these things collectively lead to achieving an accuracy of 90.9% in selecting the correct expansion forgiven acronym on a dataset we scraped from Wikipedia with 707 distinct acronyms and 14,876 disambigua-tions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9994916915893555}]}], "introductionContent": [{"text": "Acronyms are short descriptors made from important initial letters of a phrase.", "labels": [], "entities": []}, {"text": "The phrase here is referred as an expansion of that acronym.", "labels": [], "entities": []}, {"text": "Acronyms are used within these documents to shorten complicated or oft-repeated terms.", "labels": [], "entities": []}, {"text": "Acronym usage is becoming more and more common in emails, tweets, blog posts, etc.", "labels": [], "entities": []}, {"text": "And with the increasing popularity of mobile devices, the use of acronyms on social platforms has increased even more because typing in these devices is difficult and acronyms provide a succinct way to express information.", "labels": [], "entities": []}, {"text": "Usually, acronyms will be conveniently defined at the point of the first usage, but sometimes a document will omit the definition entirely, assuming the readers familiarity with the acronym.", "labels": [], "entities": []}, {"text": "For example, WHO is often used as an acronym for World Health Organization and usually people are expected to know the expansion of it.", "labels": [], "entities": [{"text": "WHO", "start_pos": 13, "end_pos": 16, "type": "DATASET", "confidence": 0.8419510126113892}, {"text": "World Health Organization", "start_pos": 49, "end_pos": 74, "type": "DATASET", "confidence": 0.8648861845334371}]}, {"text": "Or take CSS as an example, most of the documents wont even mention the expansion of CSS because its such a common acronym for Cascading Style Sheets.", "labels": [], "entities": []}, {"text": "But CSS can also mean Content-Scrambling System, Closed Source Software, and Cross-Site Scripting.", "labels": [], "entities": []}, {"text": "Also, many natural language processing applications require preprocessing of a document.", "labels": [], "entities": []}, {"text": "Text normalization is one of the most important phase of these preprocessing tasks.", "labels": [], "entities": [{"text": "Text normalization", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7902338206768036}]}, {"text": "The basic task of text normalization is to convert non-standard words like numbers, abbreviations, dates, etc. into standard words, though depending on the task and the domain a greater or lesser number of these nonstandard words may need to be normalized.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.7230548858642578}]}, {"text": "In this phase of text normalization, we need to expand all the acronyms in the document.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.7347941249608994}]}, {"text": "Acronyms are typically ambiguous because several expansions exist for the same acronym as we saw in the example before.", "labels": [], "entities": [{"text": "Acronyms", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.901584267616272}]}, {"text": "For example, Cable News Network and Convolutional Neural Network are both expansions for the common acronym CNN.", "labels": [], "entities": []}, {"text": "To disambiguate these acronyms, we can use context paragraphs that surround these acronyms to find the actual expansion.", "labels": [], "entities": []}, {"text": "In our work, we have studied and created an information retrieval system which takes any acronyms along with some context words and then will expand the acronym based on the score it gives to all the possible expansions on the acronym.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 44, "end_pos": 65, "type": "TASK", "confidence": 0.7057022750377655}]}, {"text": "As shown in the figure, the system will search for all the possible expansions of the given acronym on Wikipedia and Acronymfinder.com.", "labels": [], "entities": [{"text": "Acronymfinder.com", "start_pos": 117, "end_pos": 134, "type": "DATASET", "confidence": 0.9259850978851318}]}, {"text": "Once it has the list of all the expansions then it will start finding occurrences of those phrases in Wikipedia to get all the contexts in which it is used.", "labels": [], "entities": []}, {"text": "Our system will then represent each poss-: Acronym Exoansion from Input to Output bile expansion using a deep learning technique called) in high dimensional vector space.) which is used in our system can be seen as a distributional semantic representation and this representation is proved to be effective to compute the semantic similarity between words based on the context without any labeled data.", "labels": [], "entities": []}, {"text": "The Doc2Vec () embeddings represents the expansions of acronyms in vector space.", "labels": [], "entities": []}, {"text": "The placement of each acronym expansion depends on the context that it is used in.", "labels": [], "entities": []}, {"text": "Once the system has represented all the possible context vectors associated with each expansion using Doc2Vec (), we can pick the expansion whose context vector has the highest cosine similarity score with the input context vector which will then be our expansion for that given acronym.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, we are the first to apply embeddings to this task.", "labels": [], "entities": []}, {"text": "Experimental results show that our system achieves a comparable accuracy of 90.9% accuracy and is close to humans performance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.99950110912323}, {"text": "accuracy", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.9992096424102783}]}, {"text": "Our paper is mainly divided into the following sections: \u2022 In Section 1, we begin with an introduction to the task of acronym expansion and briefly describe our approach.", "labels": [], "entities": [{"text": "acronym expansion", "start_pos": 118, "end_pos": 135, "type": "TASK", "confidence": 0.9384391009807587}]}, {"text": "\u2022 In Section 2, we mention the issues with acronym expansion and provide an overview of the past approaches to the same problem.", "labels": [], "entities": [{"text": "acronym expansion", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.9126485586166382}]}, {"text": "\u2022 In Section 3, we descibe our proposed approach to the task of acronym expansion and the creation of document embeddings from context of acronym usage which is at the core of our model.", "labels": [], "entities": [{"text": "acronym expansion", "start_pos": 64, "end_pos": 81, "type": "TASK", "confidence": 0.9074321091175079}]}, {"text": "\u2022 In Section 4, we explain our experimental setup, describe how we gathered the dataset and give results and observations of testing on the datasets.", "labels": [], "entities": []}, {"text": "\u2022 In Section 5, we give our conclusions from the experiments and also describe methods to extend our approach to similar problems.", "labels": [], "entities": []}], "datasetContent": [{"text": "We wanted to be absolutely comprehensive in our approach, so we scraped 707 distinct acronyms with their occurences and context in which they had occured.", "labels": [], "entities": []}, {"text": "We got marginally better results on the distributed memory model, as compared to the distributed bag of words model.", "labels": [], "entities": []}, {"text": "For each acronym, we train a model with all the context possibilities.", "labels": [], "entities": []}, {"text": "We then calculate the cosine similarity between every input-context and crawled-context pair.", "labels": [], "entities": []}, {"text": "Following that, we extract the pair with the highest cosine similarity value.", "labels": [], "entities": []}, {"text": "To give some physical intuition, this means that this pair of vectors are the closest together in vector space.", "labels": [], "entities": []}, {"text": "We predict that the full form associated with the context selected above is the same as the full form associated with the meaning.", "labels": [], "entities": []}, {"text": "Using pythons in built sequence matcher, we match the predicted expansion with the expansion associated with the input context to verify the models prediction and calculate accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 173, "end_pos": 181, "type": "METRIC", "confidence": 0.9992576241493225}]}, {"text": "So, for example, if CNN is the acronym at hand, we have one context paragraph and a expansion (Convolutional Neural Network) associated with it, and several crawled context paragraphs (i.e. places on Wikipedia articles where the acronym CNN has occurred).", "labels": [], "entities": []}, {"text": "Each context paragraph also has a distinct expansion associated with it.", "labels": [], "entities": []}, {"text": "Lets take two distinct context paragraphs, one with a expansion of \"Cable News Network\" associated with it, and another with the expansion \"Convolutional Neural Network\" associated with it.", "labels": [], "entities": [{"text": "Cable News Network", "start_pos": 68, "end_pos": 86, "type": "DATASET", "confidence": 0.8891819914182028}]}, {"text": "We plot all 3 paragraphs in vector space, and calculate the cosine similarity of the input context and all the crawled-contexts pair-wise.", "labels": [], "entities": []}, {"text": "So   The is an approximate plot of the vector space for the acronym API.", "labels": [], "entities": []}, {"text": "This was achieved using Principal Component Analysis.", "labels": [], "entities": []}, {"text": "Keeping in mind that 500 dimensions are being condensed to 2 dimensions, this plot is for representation purposes only, and is in noway indicative of the models accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 161, "end_pos": 169, "type": "METRIC", "confidence": 0.9984228610992432}]}, {"text": "Using the dataset mentioned before, we ran our model on a total of 14,876 disambiguations for 707 distinct acronyms.", "labels": [], "entities": []}, {"text": "We achieved an accuracy of 90.9%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.999795138835907}]}, {"text": "We use this architecture for the network because of the constraint on the dataset size caused by scarcity of labelled data.", "labels": [], "entities": []}, {"text": "We used a NVIDIA 970 GTX GPU and a 4.00 GHz Intel i7-4790 processor with 64GB RAM to train our models.", "labels": [], "entities": []}, {"text": "As the datasets in this domain expand, we would like to scale up our approach to bigger architectures.", "labels": [], "entities": []}, {"text": "The results obtained on different experiments are given in.", "labels": [], "entities": []}, {"text": "We are able to achieve comparable accuracies without using any domain specific feature engineering.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results of experiments", "labels": [], "entities": []}]}