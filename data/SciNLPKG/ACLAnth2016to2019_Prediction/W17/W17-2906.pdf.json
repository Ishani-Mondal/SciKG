{"title": [{"text": "Cross-Lingual Classification of Topics in Political Texts", "labels": [], "entities": [{"text": "Cross-Lingual Classification of Topics in Political Texts", "start_pos": 0, "end_pos": 57, "type": "TASK", "confidence": 0.8114986291953495}]}], "abstractContent": [{"text": "In this paper, we propose an approach for cross-lingual topical coding of sentences from electoral manifestos of political parties in different languages.", "labels": [], "entities": [{"text": "cross-lingual topical coding of sentences from electoral manifestos", "start_pos": 42, "end_pos": 109, "type": "TASK", "confidence": 0.830406665802002}]}, {"text": "To this end, we exploit continuous semantic text representations and induce a joint multilingual semantic vector spaces to enable supervised learning using manually-coded sentences across different languages.", "labels": [], "entities": []}, {"text": "Our experimental results show that classifiers trained on multilingual data yield performance boosts over monolingual topic classification.", "labels": [], "entities": [{"text": "monolingual topic classification", "start_pos": 106, "end_pos": 138, "type": "TASK", "confidence": 0.7632836302121481}]}], "introductionContent": [{"text": "Political parties are at the core of contemporary democratic systems.", "labels": [], "entities": []}, {"text": "Election programs (the socalled manifestos), in which parties declare their positions over a range of topics (e.g., foreign policies, welfare, economy), area widely used information source in political science.", "labels": [], "entities": []}, {"text": "Within the Comparative Manifesto Project (CMP)), political scientists have been collecting and topically coding manifestos from countries around the world for almost two decades now.", "labels": [], "entities": [{"text": "Comparative Manifesto Project (CMP))", "start_pos": 11, "end_pos": 47, "type": "TASK", "confidence": 0.7987034618854523}]}, {"text": "Manual topic coding of manifesto sentences, following the Manifesto Coding scheme with more than fifty fine-grained topics, grouped in seven coarse-grained topics (e.g, External Relations, Economy), is time consuming and requires expert knowledge (.", "labels": [], "entities": [{"text": "topic coding of manifesto sentences", "start_pos": 7, "end_pos": 42, "type": "TASK", "confidence": 0.8370577812194824}]}, {"text": "Moreover, it is difficult to ensure annotation consistency, especially across different countries and languages).", "labels": [], "entities": [{"text": "consistency", "start_pos": 47, "end_pos": 58, "type": "METRIC", "confidence": 0.7704908847808838}]}, {"text": "Nonetheless, manually coded manifestos remain the crucial data source for studies in computational political science).", "labels": [], "entities": []}, {"text": "In order support manual coders and mitigate the issues pertaining to manual coding, researchers have employed automatic text classification to topically label political texts (.", "labels": [], "entities": [{"text": "text classification", "start_pos": 120, "end_pos": 139, "type": "TASK", "confidence": 0.7498810291290283}]}, {"text": "Existing classification models utilize discrete representation of text (i.e., bag of words) and can thus exploit only monolingual data (i.e., train and predict same language instances ).", "labels": [], "entities": []}, {"text": "In contrast, in this work, we aim to exploit multilingual data -topically-coded CMP manifestos in different languages.", "labels": [], "entities": []}, {"text": "We propose a classification model that can be trained on multilingual corpus of political texts.To this effect, we induce semantic representations of texts from ubiquitous word embeddings () and induce a joint multilingual embedding space via the linear translation matrices ().", "labels": [], "entities": []}, {"text": "We then experiment with two classification models, support vector machines (SVM) and convolutional neural network (CNN) that use embeddings from the joint multilingual space as input.", "labels": [], "entities": []}, {"text": "Experimental results offer evidence that topic classifiers leveraging multilingual training sets outperform monolingual classifiers.", "labels": [], "entities": []}], "datasetContent": [{"text": "We first describe the multilingual dataset of manually topically-coded manifestos.", "labels": [], "entities": []}, {"text": "We then describe the experimental setting and finally present and discuss the results.", "labels": [], "entities": []}, {"text": "We collected all available manually topically-coded manifestos in four different languages: English (20196 annotated sentences), French (4808), German (48117), and Italian (4370).", "labels": [], "entities": []}, {"text": "In order to compare the results across languages more clearly, we opted fora language-balanced dataset, containing the same number of instances in all four languages.", "labels": [], "entities": []}, {"text": "Thus, we randomly sampled 4370 (number of annotated sentences in Italian, the lowest number across the four languages) sentences from English, French,: Quality of translation matrices. and German manifestos.", "labels": [], "entities": []}, {"text": "The distribution of sentences over the seven coarse-grained manifesto topics in the obtained dataset is shown in.", "labels": [], "entities": []}, {"text": "We next split the dataset into the train, development, and test portion (70%-15%-15% ratio).", "labels": [], "entities": []}, {"text": "We obtained the pre-trained monolingual word embeddings for all four languages: CBOW embeddings () for German (100 dim.), Italian (300 dim.), and French (300 dim.) and GloVe embeddings () for English (100 dim.).", "labels": [], "entities": []}, {"text": "We created the multilingual embedding space by mapping embeddings of other three languages to the English embedding space.", "labels": [], "entities": []}, {"text": "We obtained the word translation pairs, required to learn the translation matrices by translating 4200 most frequent English words to the other three languages using Google Translate.", "labels": [], "entities": [{"text": "word translation", "start_pos": 16, "end_pos": 32, "type": "TASK", "confidence": 0.6602309793233871}]}, {"text": "We then used 4000 pairs to train each of the translation matrices (DE \u2192 EN, FR \u2192 EN, and IT \u2192 EN) and remaining 200 pairs for evaluation of translation quality.", "labels": [], "entities": []}, {"text": "The quality of obtained translation matrices is shown in in terms of P@1 and P@5.", "labels": [], "entities": []}, {"text": "Our primary goal is to evaluate whether the cross-lingual models, which are able to use instances in different languages for training perform better than models using only instances  from one language (i.e., train and test sentences of same language).", "labels": [], "entities": []}, {"text": "To this end, we evaluate both models, SVM and CNN, in both the monolingual and cross-lingual setting.", "labels": [], "entities": []}, {"text": "In the monolingual setting (Mono-L), the models are respectively trained, optimized, and evaluated on train, validation, and test instances of the same language.", "labels": [], "entities": []}, {"text": "In the crosslingual setting (Cross-L), we train the models on the union of training instances of all four languages.", "labels": [], "entities": []}, {"text": "On one hand, the Cross-L training set is four times larger than each individual Mono-L training set.", "labels": [], "entities": [{"text": "Cross-L training set", "start_pos": 17, "end_pos": 37, "type": "DATASET", "confidence": 0.8456424276034037}, {"text": "Mono-L training set", "start_pos": 80, "end_pos": 99, "type": "DATASET", "confidence": 0.7693654100100199}]}, {"text": "On the other hand, instances of the same topic should be more heterogeneous as they originate from different languages and were obtained via imperfect embedding translation (except for English).", "labels": [], "entities": []}, {"text": "In addition to the models from Section 3.2, in the Mono-L setting, as a baseline, we evaluate a simple linear SVM with bag-of-words features.", "labels": [], "entities": []}, {"text": "We learn the CNN parameters using the RMSProp algorithm.", "labels": [], "entities": []}, {"text": "In all experiments, we optimize the models' hyperparameters (C and \u03b3 for RBF kernel SVM, filter sizes, number of filters, and dropout rate for CNN) on the corresponding (monolingual) validation portion of the dataset.", "labels": [], "entities": []}, {"text": "We then report the performance of the model with optimal hyperparameter values on the corresponding (monolingual) test set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Topic distribution in the dataset.", "labels": [], "entities": []}, {"text": " Table 2: Quality of translation matrices.", "labels": [], "entities": [{"text": "translation", "start_pos": 21, "end_pos": 32, "type": "TASK", "confidence": 0.8060600161552429}]}, {"text": " Table 3: Topic classification results.", "labels": [], "entities": [{"text": "Topic classification", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.9414994418621063}]}]}