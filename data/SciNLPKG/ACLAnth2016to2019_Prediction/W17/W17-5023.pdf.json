{"title": [{"text": "Ensemble Methods for Native Language Identification", "labels": [], "entities": [{"text": "Native Language Identification", "start_pos": 21, "end_pos": 51, "type": "TASK", "confidence": 0.6951334873835245}]}], "abstractContent": [{"text": "Our team-Uvic-NLP-explored and evaluated a variety of lexical features for Native Language Identification (NLI) within the framework of ensemble methods.", "labels": [], "entities": [{"text": "Native Language Identification (NLI)", "start_pos": 75, "end_pos": 111, "type": "TASK", "confidence": 0.8253518839677175}]}, {"text": "Using a subset of the highest-performing features, we train Support Vector Machines (SVM) and Fully Connected Neural Networks (FCNN) as base classifiers, and test different methods for combining their outputs.", "labels": [], "entities": []}, {"text": "Restricting our scope to the closed essay track in the NLI Shared Task 2017, we find that our best SVM ensemble achieves an F1 score of 0.8730 on the test set.", "labels": [], "entities": [{"text": "NLI Shared Task 2017", "start_pos": 55, "end_pos": 75, "type": "DATASET", "confidence": 0.835099995136261}, {"text": "F1 score", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.9879653453826904}]}], "introductionContent": [{"text": "Native Language Identification (NLI) is the task of identifying a person's native language (L1) based on a sample of their writing or speech in a second language (L2).", "labels": [], "entities": [{"text": "Native Language Identification (NLI) is the task of identifying a person's native language (L1) based on a sample of their writing or speech in a second language (L2)", "start_pos": 0, "end_pos": 166, "type": "Description", "confidence": 0.722428503206798}]}, {"text": "The underlying intuition is that those with the same L1 tend to use similar language patterns during L2 production.", "labels": [], "entities": []}, {"text": "This is known as cross-linguistic influence).", "labels": [], "entities": []}, {"text": "NLI can accelerate second language acquisition by giving students L1-specific feedback on their written or spoken samples ().", "labels": [], "entities": [{"text": "second language acquisition", "start_pos": 19, "end_pos": 46, "type": "TASK", "confidence": 0.653867095708847}]}, {"text": "In forensic linguistics, NLI can be applied to identify the L1 of anonymous texts.", "labels": [], "entities": [{"text": "identify the L1 of anonymous texts", "start_pos": 47, "end_pos": 81, "type": "TASK", "confidence": 0.6769026766220728}]}, {"text": "The NLI Shared Task 2013-the first of its kind-was based on written essays , while the 2016 Computational Paralinguistics Challenge was based on spoken responses ().", "labels": [], "entities": []}, {"text": "The NLI Shared Task 2017 organizers provided a dataset of both essays and transcriptions of verbal responses * These authors contributed equally to this work.", "labels": [], "entities": []}, {"text": "As our team-Uvic-NLP-participated in the closed essay track, we performed classification on essays only.", "labels": [], "entities": [{"text": "classification", "start_pos": 74, "end_pos": 88, "type": "TASK", "confidence": 0.9466033577919006}]}, {"text": "We begin our analysis by comparing various lexical features and focus on two high-performing classifiers: Support Vector Machines (SVM) and Fully Connected Neural Networks (FCNN).", "labels": [], "entities": []}, {"text": "Then, we explore different ensemble methods for combining outputs of individual classifiers.", "labels": [], "entities": []}, {"text": "We present and discuss three of our best systems for this task: a single SVM classifier, an SVM ensemble, and an FCNN ensemble.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Comparison of individual feature types  using SVM and FCNN classifiers, using F1 scores  on DEV. The highest F1 score for each feature set  is indicated in bold.  Feature type  SVM  FCNN", "labels": [], "entities": [{"text": "F1", "start_pos": 88, "end_pos": 90, "type": "METRIC", "confidence": 0.9985746145248413}, {"text": "DEV", "start_pos": 102, "end_pos": 105, "type": "DATASET", "confidence": 0.975054919719696}, {"text": "F1 score", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.9790987372398376}, {"text": "FCNN", "start_pos": 192, "end_pos": 196, "type": "DATASET", "confidence": 0.5921216607093811}]}, {"text": " Table 3: Comparison of different ensemble meth- ods to combine outputs of SVM and FCNN clas- sifiers: voting schemes, LDA meta-classifier, and  an ensemble of LDA meta-classifiers. F1 scores  on DEV are shown. The best result for each classi- fier is indicated in bold.", "labels": [], "entities": [{"text": "F1", "start_pos": 182, "end_pos": 184, "type": "METRIC", "confidence": 0.997359573841095}, {"text": "DEV", "start_pos": 196, "end_pos": 199, "type": "DATASET", "confidence": 0.9515189528465271}]}, {"text": " Table 4: F1 scores on TEST and on DEV for final  systems. Ensemble results were obtained after the  test phase. The best result for each dataset is indi- cated in bold.  *  = Official submission to the NLI  Shared Task 2017.  System", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9995156526565552}, {"text": "TEST", "start_pos": 23, "end_pos": 27, "type": "METRIC", "confidence": 0.4749417304992676}, {"text": "DEV", "start_pos": 35, "end_pos": 38, "type": "DATASET", "confidence": 0.9380166530609131}, {"text": "NLI  Shared Task 2017.", "start_pos": 203, "end_pos": 225, "type": "DATASET", "confidence": 0.7957927942276001}]}]}