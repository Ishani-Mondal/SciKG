{"title": [{"text": "Discriminating between Similar Languages Using a Combination of Typed and Untyped Character N-grams and Words", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents the CIC UALG's system that took part in the Discriminating between Similar Languages (DSL) shared task, held at the VarDial 2017 Workshop.", "labels": [], "entities": [{"text": "Discriminating between Similar Languages (DSL) shared task", "start_pos": 64, "end_pos": 122, "type": "TASK", "confidence": 0.6974363393253751}, {"text": "VarDial 2017 Workshop", "start_pos": 136, "end_pos": 157, "type": "DATASET", "confidence": 0.7195216218630472}]}, {"text": "This year's task aims at identifying 14 languages across 6 language groups using a corpus of excerpts of journalistic texts.", "labels": [], "entities": []}, {"text": "Two classification approaches were compared: a single-step (all languages) approach and a two-step (language group and then languages within the group) approach.", "labels": [], "entities": []}, {"text": "Features exploited include lexical features (unigrams of words) and character n-grams.", "labels": [], "entities": []}, {"text": "Besides traditional (untyped) character n-grams, we introduce typed character n-grams in the DSL task.", "labels": [], "entities": []}, {"text": "Experiments were carried outwith different feature representation methods (binary and raw term frequency), frequency threshold values, and machine-learning algorithms Support Vector Machines (SVM) and Multinomial Naive Bayes (MNB).", "labels": [], "entities": []}, {"text": "Our best run in the DSL task achieved 91.46% accuracy.", "labels": [], "entities": [{"text": "DSL task", "start_pos": 20, "end_pos": 28, "type": "TASK", "confidence": 0.5890580117702484}, {"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9777891039848328}]}], "introductionContent": [{"text": "Discriminating between Similar Languages (DSL) is a Natural Language Processing (NLP) task aiming at automatically identifying the language in which a text is written.", "labels": [], "entities": [{"text": "Discriminating between Similar Languages (DSL)", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.8185990537915911}]}, {"text": "From the machine-learning perspective, DSL can be viewed as a multi-class, single-label classification problem, in which automatic methods have to assign class labels (languages) to objects (texts).", "labels": [], "entities": [{"text": "DSL", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.917870044708252}, {"text": "single-label classification", "start_pos": 75, "end_pos": 102, "type": "TASK", "confidence": 0.77127805352211}]}, {"text": "DSL can be used in a variety of applications, including security and forensics, when, for example, identifying the language/dialect in which a given threat is written can help limit the search space of the author of this threat.", "labels": [], "entities": []}, {"text": "Moreover, automated DSL is a useful aid for machine translation and information retrieval systems.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.8231200277805328}, {"text": "information retrieval", "start_pos": 68, "end_pos": 89, "type": "TASK", "confidence": 0.7482677102088928}]}, {"text": "Discriminating between Similar Languages (DSL) shared task 1 provides a common platform for researchers interested in evaluating and comparing their systems' performance on discriminating between similar languages.", "labels": [], "entities": [{"text": "Discriminating between Similar Languages (DSL) shared task 1", "start_pos": 0, "end_pos": 60, "type": "TASK", "confidence": 0.8042801797389985}]}, {"text": "The DSL 2017 edition () focuses on a set of 14 language varieties within 6 language groups using short text excerpts extracted from journalistic texts.", "labels": [], "entities": [{"text": "DSL 2017 edition", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.8449737826983134}]}, {"text": "Similar languages or language varieties are grouped by similarity or by their common origin.", "labels": [], "entities": []}, {"text": "According to, high-order character n-grams and their combinations have proved to be highly discriminative for the DSL task, hence this study examines the variation of n from 1 to 6 on untyped (traditional) n-grams, but foremost this work introduces in this task the use of typed character n-grams (with n varying between 3 and 4), that is, character n-grams classified into the categories introduced by.", "labels": [], "entities": [{"text": "DSL task", "start_pos": 114, "end_pos": 122, "type": "TASK", "confidence": 0.5481188595294952}]}, {"text": "The authors defined 10 different character n-gram categories based on affixes, words, and punctuation.", "labels": [], "entities": []}, {"text": "Typed character n-grams have shown to be predicative features for other classification tasks, such as Authorship Attribution ( and Author Profiling (, including a cross-genre scenario . To the best of our knowledge, this is the first time typed character n-grams are used in the DSL task.", "labels": [], "entities": [{"text": "Authorship Attribution", "start_pos": 102, "end_pos": 124, "type": "TASK", "confidence": 0.6568258106708527}, {"text": "DSL task", "start_pos": 279, "end_pos": 287, "type": "TASK", "confidence": 0.6040220260620117}]}, {"text": "Furthermore, a single-step and a two-step classification approaches were built.", "labels": [], "entities": []}, {"text": "In the single-step approach, all 14 languages are discriminated against each other.", "labels": [], "entities": []}, {"text": "In the two-step approach, first, the language group is predicted, and then the language variety within the group.", "labels": [], "entities": []}, {"text": "Besides, two different feature representation methods were tested, namely, binary feature representation and term frequency weighting scheme.", "labels": [], "entities": [{"text": "binary feature representation", "start_pos": 75, "end_pos": 104, "type": "TASK", "confidence": 0.6398574312527975}]}, {"text": "Several threshold values were evaluated in order to fine-tune the feature set for the final submission.", "labels": [], "entities": []}, {"text": "Finally, the performance of two popular machine-learning algorithms was examined: Support Vector Machines (SVM) and Multinomial Naive Bayes (MNB).", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows: Section 2 discusses the related work.", "labels": [], "entities": []}, {"text": "Section 3 presents the proposed methodology.", "labels": [], "entities": []}, {"text": "First, subsection 3.1 provides some characteristics of the DSL 2017 corpus, and subsection 3.2 describes the conducted experiments.", "labels": [], "entities": [{"text": "DSL 2017 corpus", "start_pos": 59, "end_pos": 74, "type": "DATASET", "confidence": 0.9626245101292928}]}, {"text": "Section 4 provides the obtained results and their evaluation.", "labels": [], "entities": []}, {"text": "Next, Section 5 discusses these results in the light of the typed n-gram features, newly introduced in the DSL task, and based on the results from the experiments carried out on the development set.", "labels": [], "entities": []}, {"text": "Section 6 draws the conclusions and points to possible directions of future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Let us now move to describe the experimental settings for the three runs submitted to the competition.", "labels": [], "entities": []}, {"text": "summarizes the experimental settings presented below.", "labels": [], "entities": []}, {"text": "For runs 1 and 2, a two-step classification approach was examined, since it has previously been proved to be a useful strategy for this task.", "labels": [], "entities": []}, {"text": "In this approach, the language group is predicted first, and then the closely-related languages are discriminated within the group.", "labels": [], "entities": []}, {"text": "This approach was compared against a single-step classification (run 3), where all the 14 languages of the corpus are discriminated, irrespective of their grouping.", "labels": [], "entities": []}, {"text": "The performance of two machine-learning classifiers was compared using their WEKA's (Witten et al., 2016) implementation with default parameters: Support Vector Machines (SVM) and Multinomial Naive Bayes (MNB).", "labels": [], "entities": [{"text": "WEKA", "start_pos": 77, "end_pos": 81, "type": "DATASET", "confidence": 0.8964387774467468}]}, {"text": "These classification algorithms are considered among the best for text categorization tasks (.", "labels": [], "entities": [{"text": "text categorization tasks", "start_pos": 66, "end_pos": 91, "type": "TASK", "confidence": 0.8548566699028015}]}, {"text": "Moreover, SVM was the classifier of choice of the majority of the teams in the previous edition of the DSL shared task).", "labels": [], "entities": [{"text": "SVM", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.8114829659461975}]}, {"text": "In the two-step approach (runs 1 and 2), the first step is the language group discrimination, which was performed using SVM classifier.", "labels": [], "entities": [{"text": "language group discrimination", "start_pos": 63, "end_pos": 92, "type": "TASK", "confidence": 0.632223884264628}]}, {"text": "Due to time constraints, in the second step (language/variety discrimination within a group) these two runs were set differently.", "labels": [], "entities": [{"text": "language/variety discrimination within a group", "start_pos": 45, "end_pos": 91, "type": "TASK", "confidence": 0.7206899779183524}]}, {"text": "In run 1, different algorithms were used for different language groups: SVM was used for groups B (Malay and Indonesian), C (Persian and Dari), and D (Canadian and Hexagonal French); while MNB was used for groups A (Bosnian, Croatian, and Serbian), E (Brazilian and European Portuguese), and F (Argentine, Peninsular, and Peruvian Spanish).", "labels": [], "entities": []}, {"text": "In run 2, all language groups were discriminated using only MNB.", "labels": [], "entities": [{"text": "MNB", "start_pos": 60, "end_pos": 63, "type": "DATASET", "confidence": 0.856843888759613}]}, {"text": "For language group classification (runs 1 and 2), we increased the number of instances for training the classifier by duplicating and in some cases triplicating the training instances.", "labels": [], "entities": [{"text": "language group classification", "start_pos": 4, "end_pos": 33, "type": "TASK", "confidence": 0.6490208705266317}]}, {"text": "In the single-step approach (run 3), only MNB was used to discriminate between the 14 languages (without group classification).", "labels": [], "entities": []}, {"text": "The performance of different feature sets was examined, using term frequency (tf ) weighting scheme.", "labels": [], "entities": [{"text": "term frequency (tf ) weighting", "start_pos": 62, "end_pos": 92, "type": "METRIC", "confidence": 0.9118731021881104}]}, {"text": "Only features with tf \u22655 were selected, that is, only those features that occur at least five times in the training corpus.", "labels": [], "entities": []}, {"text": "The features used are the following: (i) unigrams of words, (ii) untyped (traditional) character n-grams, and (iii) typed character n-grams, that is, character n-grams classified into the categories introduced by.", "labels": [], "entities": []}, {"text": "The authors defined 10 different character n-gram categories based on affixes, words, and punctuation.", "labels": [], "entities": []}, {"text": "In more detail, there are 3 main types, and each one has sub-categories as explained below: \u2022 Affix character n-grams prefix An n-gram that covers the first n characters of a word that is at least n + 1 characters long.", "labels": [], "entities": [{"text": "Affix", "start_pos": 94, "end_pos": 99, "type": "METRIC", "confidence": 0.956973671913147}]}, {"text": "suffix An n-gram that covers the last n characters of a word that is at least n + 1 characters long.", "labels": [], "entities": []}, {"text": "space-prefix An n-gram that begins with a space and that does not contain any punctuation mark.: Experimental settings in the three runs of the system.", "labels": [], "entities": []}, {"text": "space-suffix An n-gram that ends with a space, that does not contain any punctuation mark, and whose first character is not a space.", "labels": [], "entities": []}, {"text": "\u2022 Word character n-grams whole-word An n-gram that encompasses all the characters of a word, and that is exactly n characters long.", "labels": [], "entities": []}, {"text": "mid-word An n-gram that contains n characters of a word that is at least n + 2 characters long, and that does not include neither the first nor the last character of the word.", "labels": [], "entities": []}, {"text": "multi-word An n-gram that spans multiple words, identified by the presence of a space in the middle of the n-gram.", "labels": [], "entities": []}, {"text": "\u2022 Punctuation character n-grams beg-punct An n-gram whose first character is a punctuation mark, but the middle characters are not.", "labels": [], "entities": []}, {"text": "mid-punct An n-gram whose middle character is a punctuation mark (for n =3).", "labels": [], "entities": []}, {"text": "end-punct An n-gram whose last character is punctuation mark, but the first and the middle characters are not.", "labels": [], "entities": []}, {"text": "In this approach, instances of the same untyped n-gram may refer to different typed n-gram features.", "labels": [], "entities": []}, {"text": "For example, in the phrase the mother, the first instance of the 3-gram the is assigned to a whole-word category and the second instance to a mid-word category.", "labels": [], "entities": []}, {"text": "As an example, let us consider the following sample sentence: (1) Ana said, \"Tom will fix it tomorrow.\"", "labels": [], "entities": []}, {"text": "The character n-grams (n = 3) for the sample sentence (1) for each of the categories are shown in. whole-word Ana Tom fix mid-word omo mor orr rro multi-word a s m w l f xi t t punct beg-punct , \" \"To mid-punct * , \" . \" end-punct id, ow.", "labels": [], "entities": []}, {"text": "* In our approach, punctuation marks are separated from adjacent words and from each other by space for this category.", "labels": [], "entities": []}, {"text": "This enables to capture their frequency.: Character 3-grams per category for the sample sentence (1) after applying the algorithm by.", "labels": [], "entities": []}, {"text": "Next, the results of the three runs on the DSL 2017 test set are presented in.", "labels": [], "entities": [{"text": "DSL 2017 test set", "start_pos": 43, "end_pos": 60, "type": "DATASET", "confidence": 0.9640423506498337}]}, {"text": "Firstly, the results of run 3 (single-step, 14 languages and no language group classification, using MNB) are slightly worse than those for runs 1 and 2 (0.0052 and 0.0077, respectively).", "labels": [], "entities": [{"text": "MNB", "start_pos": 101, "end_pos": 104, "type": "DATASET", "confidence": 0.7694161534309387}]}, {"text": "This seems to confirm the validity of the two-step approach.", "labels": [], "entities": []}, {"text": "Secondly,  results of run 2 (two-step classification approach using SVM for groups and MNB for languages) slightly outperformed those of run 1 (similar setting to those of run 2, but using SVM or MNB depending on language group).", "labels": [], "entities": []}, {"text": "This behavior was the opposite of the one seen in the experiments conducted on the development set, where the best results were achieved using an SVM classifier for both group and language classification.", "labels": [], "entities": [{"text": "language classification", "start_pos": 180, "end_pos": 203, "type": "TASK", "confidence": 0.6916043907403946}]}, {"text": "Since time constraints precluded repeating in run 1 test set (mixed SVM/MNB in the second step) exactly the experimental settings adopted for the development set (only SVM in both classification steps), it remains to be seen whether such scenario would change the results, and by how much.", "labels": [], "entities": []}, {"text": "Group classification is extremely important, since a model is unable to recover from mistakes made at the group prediction step.", "labels": [], "entities": [{"text": "Group classification", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8573238551616669}, {"text": "group prediction", "start_pos": 106, "end_pos": 122, "type": "TASK", "confidence": 0.7142556011676788}]}, {"text": "shows the performance of run 2 for the language group classification.", "labels": [], "entities": [{"text": "language group classification", "start_pos": 39, "end_pos": 68, "type": "TASK", "confidence": 0.6297467648983002}]}, {"text": "The overall results for all the language groups are very high and are inline with the experiments on the development set, where similar results were achieved.", "labels": [], "entities": []}, {"text": "As one can see from, the results for language classification are lower than those for group classification.", "labels": [], "entities": [{"text": "language classification", "start_pos": 37, "end_pos": 60, "type": "TASK", "confidence": 0.7274340242147446}, {"text": "group classification", "start_pos": 86, "end_pos": 106, "type": "TASK", "confidence": 0.7600365281105042}]}, {"text": "The most challenging languages are the ones in groups A and F, where the average precision is 0.85 and 0.88, respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.9987744688987732}]}, {"text": "In group A, the Bosnian language showed a precision of 0.79, which makes it the most difficult language to identify when compared with Serbian and Croatian.", "labels": [], "entities": [{"text": "precision", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9984909296035767}]}, {"text": "Another interesting result emerges from the results concerning the Spanish language (group F), which also show a wide variation in the performance of the classifiers.", "labels": [], "entities": []}, {"text": "This maybe due to the (relatively)    The confusion matrix for our best run (run 2) in the closed DSL task is shown in.", "labels": [], "entities": []}, {"text": "The greatest confusion is in the Bosnian-CroatianSerbian group, followed by the Spanish and Portuguese dialect groups.", "labels": [], "entities": []}, {"text": "Bosnian is the most difficult language for identification among all the 14 classes.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Final ranking for the closed track of the  DSL shared task.", "labels": [], "entities": [{"text": "DSL shared task", "start_pos": 53, "end_pos": 68, "type": "TASK", "confidence": 0.5280043284098307}]}, {"text": " Table 4: Results in terms of accuracy and F1 measures for the three submitted runs on the test set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9996020197868347}, {"text": "F1", "start_pos": 43, "end_pos": 45, "type": "METRIC", "confidence": 0.9998599290847778}]}, {"text": " Table 5: Performance of run 2 per group of lan- guages.", "labels": [], "entities": [{"text": "Performance", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9665788412094116}]}, {"text": " Table 6: Performance of run 2 per language.", "labels": [], "entities": []}, {"text": " Table 7: Results from different feature combi- nations on the language group classification step  over the development set.", "labels": [], "entities": [{"text": "language group classification", "start_pos": 63, "end_pos": 92, "type": "TASK", "confidence": 0.667982836564382}]}]}