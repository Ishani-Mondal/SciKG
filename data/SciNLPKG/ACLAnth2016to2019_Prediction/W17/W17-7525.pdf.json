{"title": [{"text": "Improving NER for Clinical Texts by Ensemble Approach using Segment Representations", "labels": [], "entities": [{"text": "Improving NER", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.7444961667060852}]}], "abstractContent": [{"text": "Clinical Named Entity Recognition (Clinical-NER), which aims at identifying and classifying clinical named entities into predefined categories, is a critical pre-processing task in health information systems.", "labels": [], "entities": [{"text": "Clinical Named Entity Recognition (Clinical-NER)", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.7165081884179797}]}, {"text": "Different machine learning approaches have been used to extract and classify clinical named entities.", "labels": [], "entities": [{"text": "classify clinical named entities", "start_pos": 68, "end_pos": 100, "type": "TASK", "confidence": 0.7887777090072632}]}, {"text": "Each approach has its own strength as well as weakness when considered individually.", "labels": [], "entities": []}, {"text": "Ensemble technique uses the strength of one approach to overcome the weakness of another approach by combining the outputs of different classifiers in order to make the decision thereby improving the results.", "labels": [], "entities": []}, {"text": "Segment representation is a technique that is used to add a tag for each token in a given text.", "labels": [], "entities": [{"text": "Segment representation", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9575573801994324}]}, {"text": "In this paper, we propose an ensemble approach to combine the outputs of four different base classifiers in two different ways, namely, majority voting and stacking.", "labels": [], "entities": [{"text": "stacking", "start_pos": 156, "end_pos": 164, "type": "TASK", "confidence": 0.9586347341537476}]}, {"text": "We have used support vector machines to train the base classifiers with different segment representation models namely IOB2, IOE2, IOBE and IOBES.", "labels": [], "entities": []}, {"text": "The proposed algorithm is evaluated on a well-known clinical dataset i2b2 2010 corpus and results obtained illustrate that the proposed approach outperforms the performance of each of the base classifiers.", "labels": [], "entities": [{"text": "clinical dataset i2b2 2010 corpus", "start_pos": 52, "end_pos": 85, "type": "DATASET", "confidence": 0.8602617502212524}]}], "introductionContent": [{"text": "Named Entity Recognition (NER) is a leading subtask of information extraction originated from the Sixth Understanding Conference (MUC-6), which aims at identifying Named Entities (NEs) in a text and classifying them into predefined classes.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7818708618481954}, {"text": "information extraction", "start_pos": 55, "end_pos": 77, "type": "TASK", "confidence": 0.7380585074424744}, {"text": "Sixth Understanding Conference (MUC-6)", "start_pos": 98, "end_pos": 136, "type": "DATASET", "confidence": 0.5854311585426331}]}, {"text": "Names of organizations, locations and persons are examples of NEs in general newswire domain, while DNA, RNA and protein are examples of NEs in biological domain.", "labels": [], "entities": []}, {"text": "In clinical domain, terms representing problem, treatment and laboratory test are considered as NEs.", "labels": [], "entities": []}, {"text": "The exponential growth of health information systems produce a massive amount of Electronic Health Records (EHRs).", "labels": [], "entities": []}, {"text": "It is vital to apply NER for health information systems because EHRs contain NEs representing laboratory test, problem and treatment in unstructured narrative documents.", "labels": [], "entities": [{"text": "NER", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.9625513553619385}]}, {"text": "Moreover, NER in clinical domain (Clinical-NER) is an important pre-processing task in health information systems where further tasks of health information systems depend essentially on the results of Clinical-NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.9804917573928833}]}, {"text": "Clinical-NER is a challenging problem because, in addition to the general challenges of NER there are other challenges resulting from the nature of clinical NEs such as: -1.", "labels": [], "entities": []}, {"text": "Ambiguity:-the major sources of ambiguity are abbreviations and acronyms), which are used routinely in clinical texts.", "labels": [], "entities": []}, {"text": "Two different cases cause the ambiguity, (i) same abbreviation used for different entities such as \"EF (Ejection Fraction)\" which is used as a medical problem as well as a laboratory test, and (ii) an abbreviation conflicts with a word such as \"VS\" which is a laboratory test as well as abbreviation for the word \"versus\".", "labels": [], "entities": []}, {"text": "\"BP (blood pressure)\", a laboratory test occurs in \"control BP\" which is a treatment.", "labels": [], "entities": [{"text": "BP (blood pressure)\"", "start_pos": 1, "end_pos": 21, "type": "METRIC", "confidence": 0.7581765532493592}]}, {"text": "4. Polysemy:-same clinical term can represent different meanings based on the context, such as \"inflammation\" may refer to skin problem, a cellular level problem as well as nonmedical activity.", "labels": [], "entities": []}, {"text": "5. Synonymy:-a single medical concept can be expressed as multiple words) such as \"baby\" and \"foetus\" which means the same in many medical contexts.", "labels": [], "entities": []}, {"text": "In addition to these challenges, there is no standard nomenclature for clinical entities of same class.", "labels": [], "entities": []}], "datasetContent": [{"text": "The performance of our system is reported in terms of f-measure).", "labels": [], "entities": []}, {"text": "F-measure is a harmonic mean of Precision (P) and Recall (R).", "labels": [], "entities": [{"text": "F-measure", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9513606429100037}, {"text": "Precision (P)", "start_pos": 32, "end_pos": 45, "type": "METRIC", "confidence": 0.9497155100107193}, {"text": "Recall (R)", "start_pos": 50, "end_pos": 60, "type": "METRIC", "confidence": 0.9613690972328186}]}, {"text": "Denoting TP as the number of true positives, FP number of false positives and FN as the number of false negatives, recall, precision and f-measure are calculated as follow: Our model is eval on i2b2 dataset), which was originally created for entity and relation extraction purposes at i2b2/VA 2010 challenge.", "labels": [], "entities": [{"text": "TP", "start_pos": 9, "end_pos": 11, "type": "METRIC", "confidence": 0.958044707775116}, {"text": "FP number of false positives", "start_pos": 45, "end_pos": 73, "type": "METRIC", "confidence": 0.9575618386268616}, {"text": "FN", "start_pos": 78, "end_pos": 80, "type": "METRIC", "confidence": 0.989416778087616}, {"text": "recall", "start_pos": 115, "end_pos": 121, "type": "METRIC", "confidence": 0.9996267557144165}, {"text": "precision", "start_pos": 123, "end_pos": 132, "type": "METRIC", "confidence": 0.9996284246444702}, {"text": "f-measure", "start_pos": 137, "end_pos": 146, "type": "METRIC", "confidence": 0.992109477519989}, {"text": "i2b2 dataset", "start_pos": 194, "end_pos": 206, "type": "DATASET", "confidence": 0.7435738444328308}, {"text": "relation extraction", "start_pos": 253, "end_pos": 272, "type": "TASK", "confidence": 0.6909881085157394}, {"text": "i2b2/VA 2010 challenge", "start_pos": 285, "end_pos": 307, "type": "DATASET", "confidence": 0.7328795254230499}]}, {"text": "It includes 826 discharge summaries for real patients from the University of Pittsburgh Medical Centre, Partners Health Care and Beth Israel Deaconess Medical Centre.", "labels": [], "entities": [{"text": "Partners Health Care and Beth Israel Deaconess Medical Centre", "start_pos": 104, "end_pos": 165, "type": "DATASET", "confidence": 0.7776454422208998}]}, {"text": "Pittsburgh discharge summaries was used as a test set in i2b2 challenge and other two sources used as a training set.", "labels": [], "entities": [{"text": "Pittsburgh discharge summaries", "start_pos": 0, "end_pos": 30, "type": "DATASET", "confidence": 0.9773917198181152}]}, {"text": "Statistics of the dataset is shown in.", "labels": [], "entities": []}, {"text": "Both testing and training sets are manually annotated with three different named entities namely, treatment, problem and test.", "labels": [], "entities": []}, {"text": "It is important to note that, there is lack of data sets that used for Clinical-NER.", "labels": [], "entities": []}, {"text": "The proposed method combines the outputs of base-classifiers using two different approaches namely Majority Voting and Stacked Generalization.", "labels": [], "entities": [{"text": "Majority Voting", "start_pos": 99, "end_pos": 114, "type": "TASK", "confidence": 0.7320335805416107}, {"text": "Stacked Generalization", "start_pos": 119, "end_pos": 141, "type": "TASK", "confidence": 0.8994276821613312}]}, {"text": "For training the base classifiers, YamCha 2 toolkit along with TinySVM-0.092 3 is used.", "labels": [], "entities": []}, {"text": "In Majority Voting, the out of all base classifiers are combined together and the output of final system is decided based on majority voting.", "labels": [], "entities": [{"text": "Majority Voting", "start_pos": 3, "end_pos": 18, "type": "TASK", "confidence": 0.7334797084331512}]}, {"text": "If majority voting fail then the highest performance output of the base classifiers is considered on final output.", "labels": [], "entities": []}, {"text": "For Stacked Generalization, an open source implementation of CRF, CRF++ package 4 , has been used for constructing a CRF-based meta classifier.", "labels": [], "entities": [{"text": "Stacked Generalization", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.8756369352340698}]}, {"text": "The results of base classifiers and ensemble classifiers using Majority Voting and Stacking are shown in.", "labels": [], "entities": []}, {"text": "The results show that, the best base classifier is the classifier based on IOBE SR model and the worst is the classifier based on IOE2 SR model.", "labels": [], "entities": [{"text": "IOBE SR", "start_pos": 75, "end_pos": 82, "type": "DATASET", "confidence": 0.6888476312160492}, {"text": "IOE2 SR model", "start_pos": 130, "end_pos": 143, "type": "DATASET", "confidence": 0.8923870921134949}]}, {"text": "Both ensemble classifiers outperform the base classifiers and ensemble using stacking approach reported the best f-score.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Statistics of i2b2 dataset", "labels": [], "entities": [{"text": "i2b2 dataset", "start_pos": 24, "end_pos": 36, "type": "DATASET", "confidence": 0.6843419820070267}]}]}