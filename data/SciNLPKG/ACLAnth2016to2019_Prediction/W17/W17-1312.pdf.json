{"title": [{"text": "Arabic Tweets Treebanking and Parsing: A Bootstrapping Approach", "labels": [], "entities": [{"text": "Arabic Tweets Treebanking", "start_pos": 0, "end_pos": 25, "type": "DATASET", "confidence": 0.850005050500234}]}], "abstractContent": [{"text": "In this paper, we propose using a \"boot-strapping\" method for constructing a dependency treebank of Arabic tweets.", "labels": [], "entities": []}, {"text": "This method uses a rule-based parser to create a small treebank of one thousand Arabic tweets and a data-driven parser to create a larger treebank by using the small tree-bank as a seed training set.", "labels": [], "entities": []}, {"text": "We are able to create a dependency treebank from un-labelled tweets without any manual intervention.", "labels": [], "entities": []}, {"text": "Experiments results show that this method can improve the speed of training the parser and the accuracy of the resulting parsers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9992061257362366}]}], "introductionContent": [{"text": "Rule-based parsers have been developed and used for decades in the NLP community.", "labels": [], "entities": []}, {"text": "In such parsers, linguistic rules are written to represent knowledge about the syntactic structure of a language.", "labels": [], "entities": []}, {"text": "The parser produces the resulting parse trees by applying these rules to input sentences.", "labels": [], "entities": []}, {"text": "It uses a dictionary or lexicon to store information about each word in input text before applying the linguistic rules.", "labels": [], "entities": []}, {"text": "Although this kind of parser is widely-used in a variety of NLP systems to provide deep linguistic analyses, they have disadvantages: they are slow and it is time-consuming, expensive and tedious to construct dictionaries and to write the rules by expert linguists and hard to maintain them.", "labels": [], "entities": []}, {"text": "In recent years, data-driven parsers have been widely used due to the availability of annotated data such as the Penn Treebank (PTB)) and the Penn Arabic Treebak (PATB) ().", "labels": [], "entities": [{"text": "Penn Treebank (PTB))", "start_pos": 113, "end_pos": 133, "type": "DATASET", "confidence": 0.9686896681785584}, {"text": "Penn Arabic Treebak (PATB)", "start_pos": 142, "end_pos": 168, "type": "DATASET", "confidence": 0.9565807084242502}]}, {"text": "These parsers are robust and produce state-of-the-art results compared to rule-based ones.", "labels": [], "entities": []}, {"text": "However, the reliance on annotated data is one of the significant disadvantages of using data-driven parsers because a large amount of rich annotated data is not always available for many languages and domains due to various factors (Ramasamy and\u017dabokrtsk`yand\u02c7and\u017dabokrtsk`and\u017dabokrtsk`y, 2011).", "labels": [], "entities": []}, {"text": "In the domain of Arabic tweets, we decided to use a data-driven approach, but for that a suitable collection of training data (treebank) should be available for training, and to our knowledge no such dataset has yet been created.", "labels": [], "entities": []}, {"text": "For this reason, we have developed a bootstrapping technique for constructing a dependency treebank of the Arabic tweets by using a rule-based parser (RBP) and a data-driven parser (MaltParser).", "labels": [], "entities": []}, {"text": "We are able to create a dependency treebank from unlabelled tweets without any manual intervention.", "labels": [], "entities": []}, {"text": "Experiments results show that using MaltParser and RBP to construct a large training set (treebank) is better in terms of speed of training and accuracy of parsing than constructing it by using RBP only.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 144, "end_pos": 152, "type": "METRIC", "confidence": 0.9989535808563232}]}, {"text": "The rest of this paper is organised as follows: In Section 2, we give an overview of the related work, followed by a description of our bootstrapping approach in Section 3.", "labels": [], "entities": []}, {"text": "In Section 4, we discuss the evaluation, results and their analysis.", "labels": [], "entities": []}, {"text": "In Section 5, we reflect on the work described in the main paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "The speed is a crucial factor to take into account when parsing Arabic tweets since there are millions of tweets that need to be parsed.", "labels": [], "entities": [{"text": "speed", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.9909304976463318}, {"text": "parsing Arabic tweets", "start_pos": 56, "end_pos": 77, "type": "TASK", "confidence": 0.8930777112642924}]}, {"text": "Therefore, rule-based parsers are not suitable in this domain because they are slow (as mentioned in the literature and proved by the first experiment below).", "labels": [], "entities": []}, {"text": "To parse Arabic tweets, we decided to use a datadriven parser, namely MaltParser.", "labels": [], "entities": [{"text": "parse Arabic tweets", "start_pos": 3, "end_pos": 22, "type": "TASK", "confidence": 0.8706254959106445}]}, {"text": "However, this kind of approaches needs training data (treebank).", "labels": [], "entities": []}, {"text": "Therefore, we did two experiments to construct a treebank with a reasonable size.", "labels": [], "entities": []}, {"text": "In the first experiment we used RBP only whereas in the second experiment we used RBP and MaltParser as described in Section 3.", "labels": [], "entities": [{"text": "RBP", "start_pos": 32, "end_pos": 35, "type": "METRIC", "confidence": 0.7493698596954346}, {"text": "RBP", "start_pos": 82, "end_pos": 85, "type": "METRIC", "confidence": 0.6132924556732178}]}, {"text": "The corpus from which we extract our dataset is an existing POS-tagged corpus taken from Twitter.", "labels": [], "entities": [{"text": "POS-tagged corpus taken from Twitter", "start_pos": 60, "end_pos": 96, "type": "DATASET", "confidence": 0.9100814819335937}]}, {"text": "Twitter Stream API was used to retrieve tweets from the Arabian Peninsula by using latitude and longitude coordinates of these regions since Arabic dialects in these regions share similar characteristics and they are the closest Arabic dialects to MSA.", "labels": [], "entities": [{"text": "MSA", "start_pos": 248, "end_pos": 251, "type": "DATASET", "confidence": 0.9288790225982666}]}, {"text": "The corpus was tagged by the Arabic tweets tagger described in).", "labels": [], "entities": []}, {"text": "We sampled 10K tagged tweets from the corpus to experiment on them.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Constructing treebank by using RBP", "labels": [], "entities": [{"text": "RBP", "start_pos": 41, "end_pos": 44, "type": "DATASET", "confidence": 0.5074012875556946}]}, {"text": " Table 2: Constructing treebank by bootstrapping", "labels": [], "entities": []}]}