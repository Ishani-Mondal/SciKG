{"title": [{"text": "IITP at EmoInt-2017: Measuring Intensity of Emotions using Sentence Embeddings and Optimized Features", "labels": [], "entities": [{"text": "IITP at EmoInt-2017", "start_pos": 0, "end_pos": 19, "type": "DATASET", "confidence": 0.6300012866655985}]}], "abstractContent": [{"text": "This paper describes the system that we submitted as part of our participation in the shared task on Emotion Intensity (EmoInt-2017).", "labels": [], "entities": [{"text": "Emotion Intensity", "start_pos": 101, "end_pos": 118, "type": "TASK", "confidence": 0.8824725151062012}, {"text": "EmoInt-2017)", "start_pos": 120, "end_pos": 132, "type": "DATASET", "confidence": 0.6990993916988373}]}, {"text": "We propose a Long short term memory (LSTM) based architecture cascaded with Support Vector Re-gressor (SVR) for intensity prediction.", "labels": [], "entities": [{"text": "intensity prediction", "start_pos": 112, "end_pos": 132, "type": "TASK", "confidence": 0.7974434196949005}]}, {"text": "We also employ Particle Swarm Optimization (PSO) based feature selection algorithm for obtaining an optimized feature set for training and evaluation.", "labels": [], "entities": [{"text": "Particle Swarm Optimization (PSO", "start_pos": 15, "end_pos": 47, "type": "TASK", "confidence": 0.7788058280944824}]}, {"text": "System evaluation shows interesting results on the four emotion datasets i.e. anger, fear, joy and sadness.", "labels": [], "entities": []}, {"text": "In comparison to the other participating teams our system was ranked 5th in the competition.", "labels": [], "entities": []}], "introductionContent": [{"text": "Emotion analysis) deals with automatic extraction of emotion expressed in a user written text.", "labels": [], "entities": [{"text": "Emotion analysis", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8628085255622864}, {"text": "automatic extraction of emotion expressed in a user written text", "start_pos": 29, "end_pos": 93, "type": "TASK", "confidence": 0.8569600641727447}]}, {"text": "Basic emotions expressed by a human being, as categorized by, are joy, sadness, surprise, fear, disgust and anger.", "labels": [], "entities": []}, {"text": "With the growing amount of social media generated text it has become a challenging task to efficiently mine emotions of the user.", "labels": [], "entities": []}, {"text": "However, finding only the emotion does not always reflect exact state of mood of a user.", "labels": [], "entities": []}, {"text": "Level or intensity of emotion often differs on a case-to-case basis within a single emotion.", "labels": [], "entities": []}, {"text": "Some emotions are gentle (e.g 'not good') while others can be very severe (e.g. 'terrible').", "labels": [], "entities": []}, {"text": "Finding the intensity level of the expressed emotion is another non-trivial task that researchers have to face.", "labels": [], "entities": []}, {"text": "The shared task on Emotion Intensity (EmoInt-2015)) was targeted to build an efficient system for intensity prediction on a continuous scale of 0 (least intense) to +1 (most intense).", "labels": [], "entities": [{"text": "Emotion Intensity (EmoInt-2015", "start_pos": 19, "end_pos": 49, "type": "TASK", "confidence": 0.7676460295915604}, {"text": "intensity prediction", "start_pos": 98, "end_pos": 118, "type": "TASK", "confidence": 0.581439420580864}]}, {"text": "There were four datasets collected from Twitter, each reflecting one class of emotion i.e. anger, fear, joy and sadness, respectively.", "labels": [], "entities": []}, {"text": "We propose a Long Short Term Memory (LSTM)) based neural network architecture cascaded with Support Vector Regression (SVR) ().", "labels": [], "entities": [{"text": "Support Vector Regression (SVR)", "start_pos": 92, "end_pos": 123, "type": "METRIC", "confidence": 0.8782356679439545}]}, {"text": "We build our system on top of word embeddings along with the assistance of an optimized feature set obtained through Particle Swarm Optimization (PSO) (.", "labels": [], "entities": [{"text": "Particle Swarm Optimization (PSO)", "start_pos": 117, "end_pos": 150, "type": "TASK", "confidence": 0.7317412495613098}]}, {"text": "A major hurdle in obtaining a good word representation was the noisy and informal nature of text.", "labels": [], "entities": []}, {"text": "Therefore, in the preliminary step, we perform a series of normalization heuristics inline with ().", "labels": [], "entities": []}, {"text": "The word embeddings of the resultant normalized text was more representative than that of the unnormalized text.", "labels": [], "entities": []}, {"text": "The high-dimensionality of feature vector often contributes to high complexity of the system.", "labels": [], "entities": []}, {"text": "Also, some features have high degree of relevance towards a particular task/domain than the others.", "labels": [], "entities": []}, {"text": "Careful selection of features for any task often leads to improved system performance.", "labels": [], "entities": []}, {"text": "However, finding the relevant set of features is cumbersome and time-consuming task.", "labels": [], "entities": []}, {"text": "Motivated by this we employ a Particle Swarm Optimization (PSO) based feature selection technique for selecting a subset of features from a feature pool.", "labels": [], "entities": [{"text": "Particle Swarm Optimization (PSO)", "start_pos": 30, "end_pos": 63, "type": "TASK", "confidence": 0.7640955944856008}]}, {"text": "By utilizing the reduced and pruned feature set for training and evaluation, resultant system often performs considerably well.", "labels": [], "entities": []}, {"text": "At the same time complexity of the system also reduces as it requires fewer parameters to learn.", "labels": [], "entities": []}, {"text": "Literature survey shows successful application of PSO for various tasks and/or domains ().", "labels": [], "entities": [{"text": "PSO", "start_pos": 50, "end_pos": 53, "type": "TASK", "confidence": 0.9430257081985474}]}], "datasetContent": [{"text": "The evaluation dataset  To address the problem of data sparsity we employ a series of heuristics (c.f. Section 2.1) in order to normalize the text.", "labels": [], "entities": []}, {"text": "Consequently, we obtain average Pearson score of 0.6289 with normalization outperforming the baseline system (0.610) provided by the organizers of the shared task.", "labels": [], "entities": [{"text": "Pearson score", "start_pos": 32, "end_pos": 45, "type": "METRIC", "confidence": 0.9862546324729919}]}, {"text": "We then cascade the LSTM network with SVR for the final predictions (LSTM+SVR).", "labels": [], "entities": [{"text": "SVR", "start_pos": 38, "end_pos": 41, "type": "METRIC", "confidence": 0.8331637382507324}]}, {"text": "On cascading we obtain 0.6641 average Pearson score, reporting again of 0.04 points.", "labels": [], "entities": [{"text": "Pearson score", "start_pos": 38, "end_pos": 51, "type": "METRIC", "confidence": 0.9849768877029419}]}, {"text": "Finally, to further improve the prediction accuracies we introduce various handcrafted lexicon features (c.f. Section 2.3.1) into the architecture (LSTM+SVR+Feat).", "labels": [], "entities": []}, {"text": "Although, we see an improvement of 0.01 point in average Pearson score, introduction of same set of lexicons features have contrasting effect on different emotion datasets i.e. anger, fear, joy & sadness.", "labels": [], "entities": [{"text": "Pearson score", "start_pos": 57, "end_pos": 70, "type": "METRIC", "confidence": 0.9321260154247284}]}, {"text": "We observe improvement for joy and sadness, whereas for anger use of this same set of features degrades the system performance.", "labels": [], "entities": []}, {"text": "For fear, introduction of features to LSTM+SVR almost have no effect.", "labels": [], "entities": []}, {"text": "Motivated by these results we perform PSO based feature selection algorithm in order to find optimal set of features for different emotions.", "labels": [], "entities": []}, {"text": "We get the best average Pearson score of 0.7271 on the development set by utilizing sentence embeddings, optimized feature set and SVR (LSTM+SVR+PSO).", "labels": [], "entities": [{"text": "Pearson score", "start_pos": 24, "end_pos": 37, "type": "METRIC", "confidence": 0.9812898933887482}]}, {"text": "We also observe improvement in Pearson score for each of the emotion datasets ranging from 0.5-0.7 points over LSTM+SVR.", "labels": [], "entities": [{"text": "Pearson score", "start_pos": 31, "end_pos": 44, "type": "METRIC", "confidence": 0.9818668961524963}]}, {"text": "It is evident from the obtained results that normalization of tweets is a major factor in obtaining good performance.", "labels": [], "entities": []}, {"text": "Also, introduction of the PSO based feature selection in LSTM+SVR hybrid model further assists the system in improving the performance.", "labels": [], "entities": []}, {"text": "On final evaluation, i.e. on the test set, our proposed system (LSTM+SVR+PSO) scores an average Pearson score of 0.682.", "labels": [], "entities": [{"text": "LSTM+SVR+PSO)", "start_pos": 64, "end_pos": 77, "type": "METRIC", "confidence": 0.6957974334557852}, {"text": "Pearson score", "start_pos": 96, "end_pos": 109, "type": "METRIC", "confidence": 0.9875575006008148}]}, {"text": "In comparison, baseline system produces 0.6470 average Pearson   score, a difference of 4%.", "labels": [], "entities": [{"text": "Pearson   score", "start_pos": 55, "end_pos": 70, "type": "METRIC", "confidence": 0.9823282659053802}]}, {"text": "For anger and fear we observe a small performance drop on the test set as compared to the development set while our proposed system performs better in case of sadness.", "labels": [], "entities": []}, {"text": "Further, we observe that our system does not perform at par (a drop of nearly 17%) for joy as compared to the development set.", "labels": [], "entities": [{"text": "joy", "start_pos": 87, "end_pos": 90, "type": "METRIC", "confidence": 0.9625710248947144}]}, {"text": "However, similar phenomenon was observed for the baseline system as well i.e. a drop of 6% in joy.", "labels": [], "entities": [{"text": "joy", "start_pos": 94, "end_pos": 97, "type": "METRIC", "confidence": 0.9655671715736389}]}, {"text": "We also observe that our proposed system is statistically significant over baseline system with p-value = 0.03683.", "labels": [], "entities": []}, {"text": "shows the optimized set of feature for four datasets i.e. anger, fear, joy and sadness.", "labels": [], "entities": []}, {"text": "It is evident from the table that some of the features have high degree of relevance than others.", "labels": [], "entities": []}, {"text": "For example, NRC Hashtag Emotion () lexicons have been utilized by all four of them, whereas Bing Liu ( and AFINN) lexicons have been employed by only fear & joy, respectively.", "labels": [], "entities": [{"text": "NRC Hashtag Emotion () lexicons", "start_pos": 13, "end_pos": 44, "type": "DATASET", "confidence": 0.8460325360298157}]}], "tableCaptions": [{"text": " Table 1: Evaluation results on development and test set. *Without normalization step; Other models are  with normalization. # With GloVe Twitter word embeddings; Other models utilize GloVe common crawl  embeddings.", "labels": [], "entities": []}]}