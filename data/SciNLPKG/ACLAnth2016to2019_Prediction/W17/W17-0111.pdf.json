{"title": [{"text": "The Automatic Characterization of Grammars from Small Wordlists", "labels": [], "entities": [{"text": "Automatic Characterization of Grammars from Small Wordlists", "start_pos": 4, "end_pos": 63, "type": "TASK", "confidence": 0.8147328921726772}]}], "abstractContent": [{"text": "We present two novel examples of simple algorithms which characterize the grammars of low-resource languages: a tool for the characterization of vowel harmony, and a framework for unsupervised morphological segmentation which achieves state-of-the-art performance.", "labels": [], "entities": [{"text": "characterization of vowel harmony", "start_pos": 125, "end_pos": 158, "type": "TASK", "confidence": 0.8322503566741943}]}, {"text": "Accurate characterization of grammars jump starts the process of description by a trained linguist.", "labels": [], "entities": []}, {"text": "Furthermore, morphological segmentation provides gains in machine translation as well, a perennial challenge for low-resource undocumented and endangered languages.", "labels": [], "entities": [{"text": "morphological segmentation", "start_pos": 13, "end_pos": 39, "type": "TASK", "confidence": 0.805531919002533}, {"text": "machine translation", "start_pos": 58, "end_pos": 77, "type": "TASK", "confidence": 0.7180473506450653}]}], "introductionContent": [{"text": "A persistent difficulty in describing a language's grammar is the time consuming and error prone task of pouring over collected data searching for patterns.", "labels": [], "entities": [{"text": "describing a language's grammar", "start_pos": 27, "end_pos": 58, "type": "TASK", "confidence": 0.717859411239624}]}, {"text": "While the idea of automation is appealing, existing natural language processing applications are often non-functional on the kind of data which maybe collected in the field.", "labels": [], "entities": []}, {"text": "They may rely on supervised algorithms which require labeled or annotated data, but that defeats the purpose here.", "labels": [], "entities": []}, {"text": "A successful tool for characterizing an unknown grammar should not require the user to have described the grammar beforehand.", "labels": [], "entities": []}, {"text": "So called unsupervised algorithms, which are are trained on unlabeled data, exist, but they tend to require very large digital corpora to perform well.", "labels": [], "entities": []}, {"text": "This is not a problem for tools meant to run on English or French, but collecting enough material on an endangered or undocumented language is often extremely difficult or impossible.", "labels": [], "entities": []}, {"text": "Standard NLP applications are not up to the task.", "labels": [], "entities": []}, {"text": "Useful tools in this field must run on unusually small corpora with high enough accuracy if they are to be a help rather than a hindrance to a trained linguist.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9943267703056335}]}, {"text": "So, what is needed is a class of tools designed specifically with small data in mind and which will work fora diverse variety of languages.", "labels": [], "entities": []}, {"text": "We present two such tools that operate on different grammatical domains.", "labels": [], "entities": []}, {"text": "The first is a method for automatically searching for, identifying, and characterizing vowel harmony.", "labels": [], "entities": [{"text": "identifying, and characterizing vowel harmony", "start_pos": 55, "end_pos": 100, "type": "TASK", "confidence": 0.7164021631081899}]}, {"text": "Designed with small raw wordlists in mind, it leverages basic typological and theoretical principles.", "labels": [], "entities": []}, {"text": "Tested on families ranging from Turkic (Turkish, Uyghur) to Pama-Nyungan (Warlpiri), it accurately describes diverse harmony systems.", "labels": [], "entities": []}, {"text": "Our approach is novel in that it does not require the researcher to specify what kind of harmony system, if any, to expect.", "labels": [], "entities": []}, {"text": "The algorithm discovers the patterns on its own.", "labels": [], "entities": []}, {"text": "Additionally, we present an algorithm which achieves state-of-the-art results in unsupervised morphological segmentation.", "labels": [], "entities": []}, {"text": "Prior work in unsupervised segmentation has taken advantage of very large corpora, on the order of billions of words (.", "labels": [], "entities": []}, {"text": "Tested on English and Turkish, our algorithm produces superior results not on billions, but on only hundreds of thousands of words.", "labels": [], "entities": []}, {"text": "An obvious issue here is the lack of languages to test on.", "labels": [], "entities": []}, {"text": "While anyone can run the algorithm on any language, we can only test the quality of the segmentation on languages for which a gold-standard segmentation already exists.", "labels": [], "entities": []}, {"text": "To remedy this, we are currently developing annotation standards for automatic morphological segmentation, with Korean and Faroese as test languages.", "labels": [], "entities": [{"text": "automatic morphological segmentation", "start_pos": 69, "end_pos": 105, "type": "TASK", "confidence": 0.6082826952139536}]}, {"text": "We hope this will prove useful for other researchers working on their own languages of interest.", "labels": [], "entities": []}], "datasetContent": [{"text": "To facilitate comparison between our algorithm and currently used competitors, we adopt the same data set used by and (, the MorphoChallenge 2010 set for training and the combined MorphoChallenge 2005-2010 for testing.", "labels": [], "entities": [{"text": "MorphoChallenge 2010 set", "start_pos": 125, "end_pos": 149, "type": "DATASET", "confidence": 0.9220296144485474}, {"text": "MorphoChallenge 2005-2010", "start_pos": 180, "end_pos": 205, "type": "DATASET", "confidence": 0.8758052885532379}]}, {"text": "We test against Morfessor, as well as AGMorph (, MorphoChain-C (with only word-internal information), and the full MorphoChain model which is trained on (word-external) word embeddings from English Wikipedia and the BOUN corpus (.", "labels": [], "entities": [{"text": "AGMorph", "start_pos": 38, "end_pos": 45, "type": "DATASET", "confidence": 0.89042729139328}, {"text": "BOUN corpus", "start_pos": 216, "end_pos": 227, "type": "DATASET", "confidence": 0.9314539730548859}]}, {"text": "MorphoChain-C presents the best direct comparison to our model since we do not consider word-external data.", "labels": [], "entities": [{"text": "MorphoChain-C", "start_pos": 0, "end_pos": 13, "type": "DATASET", "confidence": 0.9197930097579956}]}, {"text": "Nevertheless, our model outperforms both implementations.", "labels": [], "entities": []}, {"text": "The output of each algorithm is scored according to the MorphoChain metric.", "labels": [], "entities": []}, {"text": "Precision, recall, and F1 are calculated across segmentation points.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.994927167892456}, {"text": "recall", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.9990631937980652}, {"text": "F1", "start_pos": 23, "end_pos": 25, "type": "METRIC", "confidence": 0.999788224697113}]}, {"text": "For example, walking segmented as walking contains one incorrect segmentation point after wal and is missing a correct segmentation point in king.", "labels": [], "entities": []}, {"text": "However, walking contains a correct segmentation point and no incorrect ones.", "labels": [], "entities": []}, {"text": "First, we report the contribution from each of our algorithm's component processes.", "labels": [], "entities": []}, {"text": "Base is only the initial Bayesian segmentation step.", "labels": [], "entities": [{"text": "Base", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9769136309623718}, {"text": "Bayesian segmentation", "start_pos": 25, "end_pos": 46, "type": "TASK", "confidence": 0.6528684496879578}]}, {"text": "Suff extends the Bayesian model with a final re-estimation based on suffix frequencies.", "labels": [], "entities": []}, {"text": "Trans implements the above plus segmentation.", "labels": [], "entities": []}, {"text": "Comp extends Trans with compound splitting.", "labels": [], "entities": [{"text": "compound splitting", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.7090844213962555}]}, {"text": "Prune implements paradigm pruning as well, and Freq considers root frequencies in initial segmentation.: Contribution of each algorithm component Segmentation on English performs the best when all optional processes are enforced in the model.", "labels": [], "entities": []}, {"text": "This is not the case for Turkish however, which achieves its peak performance at Trans.", "labels": [], "entities": [{"text": "Turkish", "start_pos": 25, "end_pos": 32, "type": "DATASET", "confidence": 0.8483027219772339}, {"text": "Trans.", "start_pos": 81, "end_pos": 87, "type": "DATASET", "confidence": 0.8867672085762024}]}, {"text": "This discrepancy has to do with the relative availability of bare roots in the languages.", "labels": [], "entities": []}, {"text": "English has limited affixation, and it can be assumed that many bare roots will appear in any reasonable English dataset.", "labels": [], "entities": []}, {"text": "This is not the case for Turkish, however, in which nearly all noun and verb tokens have at least one affix.", "labels": [], "entities": []}, {"text": "Therefore, processes which rely on the presence of unaffixed bare roots in the corpus cannot function.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Vowel co-occurrences are taken from corpus orthographies. Marginal vowels (e.g. Finnish\u00e5Finnish\u02daFinnish\u00e5  and German y) are automatically detected and removed. Corpora are from MorphoChallenge (Kurimo  et al., 2010) when available. Uyghur and Hungarian were provided for the DARPA LORELEI project.  Warlpiri is from (Swartz, 1997).", "labels": [], "entities": [{"text": "Warlpiri", "start_pos": 309, "end_pos": 317, "type": "DATASET", "confidence": 0.8614593148231506}]}, {"text": " Table 4: Contribution of each algorithm compo- nent", "labels": [], "entities": []}, {"text": " Table 5: All numbers except for ours are reported  in (Narasimhan et al., 2015). All scoring was per- formed using the MorphoChain metric. Best re- sults are reported for English and Turkish.", "labels": [], "entities": []}]}