{"title": [{"text": "Neural Paraphrase Identification of Questions with Noisy Pretraining", "labels": [], "entities": [{"text": "Neural Paraphrase Identification of Questions", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.8620256066322327}]}], "abstractContent": [{"text": "We present a solution to the problem of paraphrase identification of questions.", "labels": [], "entities": [{"text": "paraphrase identification of questions", "start_pos": 40, "end_pos": 78, "type": "TASK", "confidence": 0.9563218206167221}]}, {"text": "We focus on a recent dataset of question pairs annotated with binary paraphrase labels and show that a variant of the decompos-able attention model (Parikh et al., 2016) results in accurate performance on this task, while being far simpler than many competing neural architectures.", "labels": [], "entities": []}, {"text": "Furthermore, when the model is pretrained on a noisy dataset of automatically collected question paraphrases, it obtains the best reported performance on the dataset.", "labels": [], "entities": []}], "introductionContent": [{"text": "Question paraphrase identification is a widely useful NLP application.", "labels": [], "entities": [{"text": "Question paraphrase identification", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8736041585604349}]}, {"text": "For example, in question-andanswer (QA) forums ubiquitous on the Web, there are vast numbers of duplicate questions.", "labels": [], "entities": []}, {"text": "Identifying these duplicates and consolidating their answers increases the efficiency of such QA forums.", "labels": [], "entities": []}, {"text": "Moreover, identifying questions with the same semantic content could help Web-scale question answering systems that are increasingly concentrating on retrieving focused answers to users' queries.", "labels": [], "entities": [{"text": "Web-scale question answering", "start_pos": 74, "end_pos": 102, "type": "TASK", "confidence": 0.5562878847122192}]}, {"text": "Here, we focus on a recent dataset published by the QA website Quora.com containing over 400K annotated question pairs containing binary paraphrase labels.", "labels": [], "entities": [{"text": "QA website Quora.com", "start_pos": 52, "end_pos": 72, "type": "DATASET", "confidence": 0.7109241485595703}]}, {"text": "We believe that this dataset presents a great opportunity to the NLP research community and practitioners due to its scale and quality; it can result in systems that accurately identify duplicate questions, thus increasing the quality of many QA forums.", "labels": [], "entities": []}, {"text": "We examine a simple model family, the decomposable attention model of, that has shown promise in modeling natural language inference and has inspired recent work on similar tasks.", "labels": [], "entities": []}, {"text": "First, to mitigate data sparsity, we modify the input representation of the decomposable attention model to use sums of character n-gram embeddings instead of word embeddings.", "labels": [], "entities": []}, {"text": "We show that this model trained on the Quora dataset produces comparable or better results with respect to several complex neural architectures, all using pretrained word embeddings.", "labels": [], "entities": [{"text": "Quora dataset", "start_pos": 39, "end_pos": 52, "type": "DATASET", "confidence": 0.9525257349014282}]}, {"text": "Second, to significantly improve our model performance, we pretrain all our model parameters on the noisy, automatically collected question-paraphrase corpus, followed by fine-tuning the parameters on the Quora dataset.", "labels": [], "entities": [{"text": "Quora dataset", "start_pos": 205, "end_pos": 218, "type": "DATASET", "confidence": 0.9784372448921204}]}, {"text": "This two-stage training procedure achieves the best result on the Quora dataset to date, and is also significantly better than learning only the character n-gram embeddings during the pretraining stage.", "labels": [], "entities": [{"text": "Quora dataset", "start_pos": 66, "end_pos": 79, "type": "DATASET", "confidence": 0.9694140255451202}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Example wins and losses from the DECATT glove , DECATT char and the pt-DECATT char models.", "labels": [], "entities": [{"text": "DECATT glove", "start_pos": 43, "end_pos": 55, "type": "DATASET", "confidence": 0.8359459638595581}, {"text": "DECATT", "start_pos": 58, "end_pos": 64, "type": "DATASET", "confidence": 0.8436707258224487}]}, {"text": " Table 2: Results on the Quora development and  test sets in terms of accuracy. The first six rows are  taken from (", "labels": [], "entities": [{"text": "Quora development and  test sets", "start_pos": 25, "end_pos": 57, "type": "DATASET", "confidence": 0.7935903787612915}, {"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9992115497589111}]}]}