{"title": [{"text": "Semisupervied Data Driven Word Sense Disambiguation for Resource-poor Languages", "labels": [], "entities": [{"text": "Semisupervied Data Driven Word Sense Disambiguation", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.6444381922483444}]}], "abstractContent": [{"text": "In this paper, we present a generic semi-supervised Word Sense Disambiguation (WSD) method.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 52, "end_pos": 83, "type": "TASK", "confidence": 0.7455846418937048}]}, {"text": "Currently, the existing WSD methods extensively use domain resources and linguistic knowledge.", "labels": [], "entities": [{"text": "WSD", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.9364725351333618}]}, {"text": "Our proposed method extracts context based lists from a small sense-tagged and un-tagged training data without using domain knowledge.", "labels": [], "entities": []}, {"text": "Experiments on Hindi and Marathi Tourism and Health domains show that it gives good performance without using any language specific linguistic information except the sense IDs present in the sense-tagged training set and works well even with small training data by handling the data sparsity issue.", "labels": [], "entities": []}, {"text": "Other advantages are that domain expertise is not needed for crafting and selecting features to build the WSD model and it can handle the problem of nonavailability of matching contexts in sense-tagged training set.", "labels": [], "entities": []}, {"text": "It also finds sense IDs of those test words which are not present in sense-tagged training set but their associated sense IDs are present.", "labels": [], "entities": []}, {"text": "This feature can help human annotators while preparing sense-tagged corpus fora language by suggesting them probable senses of unknown words.", "labels": [], "entities": []}, {"text": "These properties make the method generic and especially suitable for resource-poor languages and it can be used for various languages without requiring a large sense-tagged corpus.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word Sense Disambiguation (WSD) is considered as one of the most challenging Natural Language Processing (NLP) task and is described as an AI-complete problem.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7790050854285558}]}, {"text": "This is a classification task which involves determining the correct meaning of each word in a sentence/phrase based on the neighboring context words.", "labels": [], "entities": []}, {"text": "Humans are very good at judging meaning of words in different contexts but when it comes to automate this task, it becomes very tough.", "labels": [], "entities": [{"text": "judging meaning of words", "start_pos": 24, "end_pos": 48, "type": "TASK", "confidence": 0.8753707855939865}]}, {"text": "Design of automated WSD methods, both supervised and unsupervised, requires the intuitive knowledge transfer from humans to WSD algorithms via knowledge structures like WordNet), machine readable dictionaries and sense-tagged training corpus.", "labels": [], "entities": [{"text": "WSD", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9523067474365234}]}, {"text": "Creation of such knowledge structures is a costly and time taking process which requires extensive amount of domain resources and linguistic expertise.", "labels": [], "entities": []}, {"text": "Along with this, domain expertise is also needed to create and select hand crafted features and rules from the training data which are required in the automated methods.", "labels": [], "entities": []}, {"text": "These requirements make it difficult to design a WSD algorithm for (6500+)) \"resourcepoor\" languages.", "labels": [], "entities": []}, {"text": "The existing literature on WSD methods report that the naive Most Frequent Sense (MFS) baseline obtained from a sense-tagged corpus is very hard to beat).", "labels": [], "entities": [{"text": "WSD", "start_pos": 27, "end_pos": 30, "type": "TASK", "confidence": 0.9857869148254395}]}, {"text": "When () tried to refine the selection of most frequent sense by using supplementary linguistic resources like POS tagger and Lemmatizer of the concerned language they found that performance of such a system is limited by the performance of used linguistic resources.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 110, "end_pos": 120, "type": "TASK", "confidence": 0.577869176864624}]}, {"text": "This observation shows that for resourcepoor languages use of other linguistic resources is not much beneficial in WSD task, since their performances are also dependent on the availability of tagged/knowledge corpus.", "labels": [], "entities": [{"text": "WSD task", "start_pos": 115, "end_pos": 123, "type": "TASK", "confidence": 0.9024091958999634}]}, {"text": "This inspires us to explore methods for WSD which do not rely on other linguistic resources and can take advantage of contextual information about words and 503 senses present in the sense-tagged and raw untagged training sets.", "labels": [], "entities": [{"text": "WSD", "start_pos": 40, "end_pos": 43, "type": "TASK", "confidence": 0.9901109337806702}]}, {"text": "Also, the challenges of requiring domain expertise and nonavailability of large sets of sense-tagged data motivated us to develop semi-supervised methods for WSD task.", "labels": [], "entities": [{"text": "WSD task", "start_pos": 158, "end_pos": 166, "type": "TASK", "confidence": 0.9339330792427063}]}, {"text": "The semi-supervised methods can take advantage of raw untagged data and would require only a moderate or small amount of sense-tagged training data.", "labels": [], "entities": []}, {"text": "In semi-supervised scenario, WSD method builds its disambiguation model from a corpus of untagged raw sentences and a set of sense-tagged sentences and is formally defined as: Here, we propose a semi-supervised WSD method which uses the concept of context based list ( to build the WSD model from a set of sense-tagged and raw untagged training corpus.", "labels": [], "entities": []}, {"text": "Our proposed method is also influenced by the one sense per collocation hypothesis of which tells that the sense of a word in a document is effectively determined by its context.", "labels": [], "entities": []}, {"text": "Our approach takes help of raw untagged data and expands the notions of context and context based list ( to tackle the data sparsity issue.", "labels": [], "entities": []}, {"text": "Our method does not require any preprocessing such as, stop/noncontent word removal and feature generation and selection from the sense-tagged training corpus.", "labels": [], "entities": [{"text": "word removal", "start_pos": 71, "end_pos": 83, "type": "TASK", "confidence": 0.7218846082687378}, {"text": "feature generation", "start_pos": 88, "end_pos": 106, "type": "TASK", "confidence": 0.7169782817363739}]}, {"text": "It works without using any additional knowledge structure like dictionary etc., other than the small sense-tagged corpus and moderate sized raw untagged data.", "labels": [], "entities": []}, {"text": "This is easily obtainable even for resource-poor languages.", "labels": [], "entities": []}, {"text": "The obtained results show that our method performs well even with very small sized sensetagged training data for Hindi and Marathi languages and its performance is better than the Random Baseline which selects a random sense for each polysemous test word, comparable to the Most Frequent Sense (MFS) baseline that selects the most frequent sense available in the sense-tagged training corpus for each polysemous word and at par with the reported results on the used datasets (.", "labels": [], "entities": []}, {"text": "Rest of the paper is organized as follows: Section 2 presents related work.", "labels": [], "entities": []}, {"text": "Section 3 describes our proposed approach.", "labels": [], "entities": []}, {"text": "Section 4 presents and discusses the results and Section 5 concludes the paper and mentions future work directions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Average 4-fold cross validation results  obtained by our algorithm for polysemous test  words NOT present in the sense-tagged training  corpus.", "labels": [], "entities": []}, {"text": " Table 2: Statistics of sense tagged and raw untagged datasets.", "labels": [], "entities": []}, {"text": " Table 3: Average 4-fold cross validation results obtained for polysemous test words.", "labels": [], "entities": []}, {"text": " Table 4: Average 4-fold cross validation F-Score (%) results obtained for polysemous test words of  various datasets by our approach and other WSD algorithms.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 42, "end_pos": 49, "type": "METRIC", "confidence": 0.947878360748291}]}, {"text": " Table 5: Results obtained for polysemous test words for various sense-tagged training set sizes ( \u2264  100 \u00d7 10 3 words).", "labels": [], "entities": []}]}