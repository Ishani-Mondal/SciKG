{"title": [{"text": "Towards Harnessing Memory Networks for Coreference Resolution", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.9662309288978577}]}], "abstractContent": [{"text": "Coreference resolution task demands comprehending a discourse, especially for anaphoric mentions which require semantic information for resolving antecedents.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8926729559898376}]}, {"text": "We investigate into how memory networks can be helpful for coreference resolution when posed as question answering problem.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 59, "end_pos": 81, "type": "TASK", "confidence": 0.9796221256256104}, {"text": "question answering", "start_pos": 96, "end_pos": 114, "type": "TASK", "confidence": 0.7600280940532684}]}, {"text": "The comprehension capability of memory networks assists corefer-ence resolution, particularly for the mentions those require semantic and context information.", "labels": [], "entities": [{"text": "corefer-ence resolution", "start_pos": 56, "end_pos": 79, "type": "TASK", "confidence": 0.8932645916938782}]}, {"text": "We experiment memory networks for coreference resolution, with 4 synthetic datasets generated for corefer-ence resolution with varying difficulty levels.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 34, "end_pos": 56, "type": "TASK", "confidence": 0.965431809425354}, {"text": "corefer-ence resolution", "start_pos": 98, "end_pos": 121, "type": "TASK", "confidence": 0.8272036910057068}]}, {"text": "Our system's performance is compared with a traditional coreference resolution system to show why memory networks can be promising for coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 56, "end_pos": 78, "type": "TASK", "confidence": 0.8869640231132507}, {"text": "coreference resolution", "start_pos": 135, "end_pos": 157, "type": "TASK", "confidence": 0.936352550983429}]}], "introductionContent": [{"text": "Coreference resolution resolves anaphoric mentions against the co-referring entities by integrating syntactic, semantic and pragmatic knowledge.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8863539695739746}]}, {"text": "Even when syntactic knowledge has a crucial role in resolving many coreferential mentions, semantic knowledge is a much more challenging aspect of coreference (.", "labels": [], "entities": []}, {"text": "This makes the attempts to bring significant improvement to the state-of-the-art results difficult.", "labels": [], "entities": []}, {"text": "There has been quite a few research in coreference resolution to bring in semantic knowledge through identification of semantic class of the entities and incorporating world knowledge with the help of sources like Wikipedia ().", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.960836261510849}]}, {"text": "The semantic analysis approach for coreference resolution discussed by takes semantics into consideration.", "labels": [], "entities": [{"text": "semantic analysis", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.7532890141010284}, {"text": "coreference resolution", "start_pos": 35, "end_pos": 57, "type": "TASK", "confidence": 0.975165456533432}]}, {"text": "Vincent Ng (2007b) discusses a pattern-based feature to identify corefering expressions through extracted patterns.", "labels": [], "entities": []}, {"text": "make use of predicateargument statistics based on co-occurrence to resolve coreference.", "labels": [], "entities": []}, {"text": "Despite these significant contributions, the achieved results show the incapability to emulate the human process of coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 116, "end_pos": 138, "type": "TASK", "confidence": 0.9700488448143005}]}, {"text": "The potential of memory networks) towards comprehending the context of a discourse motivates this initiative.", "labels": [], "entities": [{"text": "comprehending the context of a discourse", "start_pos": 42, "end_pos": 82, "type": "TASK", "confidence": 0.8093753159046173}]}, {"text": "A few psycholinguistic studies on memory based processing of anaphora, investigate the processing of antecedent information from a memory representation of the discourse).", "labels": [], "entities": []}, {"text": "Experiments by verify the interaction between the recognition memory network and the canonical frontal-temporal language network in the human process of coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 153, "end_pos": 175, "type": "TASK", "confidence": 0.9800302982330322}]}, {"text": "These insights confirm the applicability of memory networks for the task.", "labels": [], "entities": []}, {"text": "Memory networks integrate a memory component and inference capability which are jointly used to comprehend a discourse and perform reasoning based on that (.", "labels": [], "entities": []}, {"text": "Variants of memory networks, specially designed for question answering tasks, read from the external memory multiple times before delivering the answer.", "labels": [], "entities": [{"text": "question answering tasks", "start_pos": 52, "end_pos": 76, "type": "TASK", "confidence": 0.8449484705924988}]}, {"text": "Internally, they compute a representation for the input story and the question.", "labels": [], "entities": []}, {"text": "The question representation initiates a search through the memory representation of the input and extracts relevant facts.", "labels": [], "entities": []}, {"text": "In the subsequent step, the answer module generates the answer based on the information got from the memory module ().", "labels": [], "entities": []}, {"text": "We utilize memory networks for coreference resolution, modeling it as a question answering task.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 31, "end_pos": 53, "type": "TASK", "confidence": 0.9734527170658112}, {"text": "question answering task", "start_pos": 72, "end_pos": 95, "type": "TASK", "confidence": 0.8136974175771078}]}, {"text": "The context of the mentions and its relative salience in a discourse are beneficial to resolve coreference.", "labels": [], "entities": [{"text": "coreference", "start_pos": 95, "end_pos": 106, "type": "TASK", "confidence": 0.9456089735031128}]}, {"text": "In practice, there are 2 ways in which coreference resolution can be as-sisted by memory networks, viz.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.972469300031662}]}, {"text": "(i) for end-to-end coreference resolution, identifying the antecedents for the anaphoric mentions (ii) for identifying the relevant sentences for resolving anaphoric mentions using attention mechanism.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 19, "end_pos": 41, "type": "TASK", "confidence": 0.9085326194763184}]}, {"text": "End-to-end memory networks proposed by for question answering is taken for our experiments.", "labels": [], "entities": [{"text": "question answering", "start_pos": 43, "end_pos": 61, "type": "TASK", "confidence": 0.8408174216747284}]}, {"text": "They performed question answering experiments with Facebook's synthetic dataset bAbI ( ).", "labels": [], "entities": [{"text": "question answering", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.7674307525157928}, {"text": "Facebook's synthetic dataset bAbI", "start_pos": 51, "end_pos": 84, "type": "DATASET", "confidence": 0.7832365274429322}]}, {"text": "For our experiments we create another set of synthetic data with varying difficulty levels, targeting coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 102, "end_pos": 124, "type": "TASK", "confidence": 0.7561567425727844}]}, {"text": "Here, each instance is a discourse and the question is on an anaphoric mention in the discourse, with answer as its antecedent.", "labels": [], "entities": []}, {"text": "Experiment results with memory networks on bAbI dataset is reported in terms of the accuracy of the answers whereas, our experiments also evaluate attention mechanism accuracy.", "labels": [], "entities": [{"text": "bAbI dataset", "start_pos": 43, "end_pos": 55, "type": "DATASET", "confidence": 0.9124861359596252}, {"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9987903237342834}, {"text": "accuracy", "start_pos": 167, "end_pos": 175, "type": "METRIC", "confidence": 0.8177890181541443}]}, {"text": "We compare the prediction accuracy of memory networks with an existing state-of-the-art coreference resolution system on the same synthetic dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.8881669640541077}, {"text": "coreference resolution", "start_pos": 88, "end_pos": 110, "type": "TASK", "confidence": 0.8629859983921051}]}, {"text": "We also report results on a few modifications on memory networks.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments are designed to see how memory networks can help the task of coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 77, "end_pos": 99, "type": "TASK", "confidence": 0.9825465381145477}]}, {"text": "All the experiments are carried outwith the synthetic data.", "labels": [], "entities": []}, {"text": "Most existing memory networks based question answering research depend on synthetic dataset inorder to reduce the adverse effect of noise in real-world data ( ) . On similar lines, we generate 4 sets of data with different difficulty levels, keeping the vocabulary size minimal and maintaining an uniform syntactic structure.", "labels": [], "entities": [{"text": "question answering", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.7514104247093201}]}, {"text": "It is difficult to make valid observations with a dataset like Ontonotes ( considering the diversity in sentence structure and the vocabulary size.", "labels": [], "entities": [{"text": "Ontonotes", "start_pos": 63, "end_pos": 72, "type": "DATASET", "confidence": 0.9409213066101074}]}, {"text": "Since the task is posed as a question answering problem each data instance has one pronominal reference to the one of the entities in the discourse.", "labels": [], "entities": [{"text": "question answering", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.7804320156574249}]}, {"text": "The question here is on the anaphoric mention and the answer is the antecedent mention.", "labels": [], "entities": []}, {"text": "The 4 datasets are generated from 4 different templates randomizing the names and verbs.", "labels": [], "entities": []}, {"text": "This synthetic data is constructed in away such that, resolution of anaphoric mentions requires semantic knowledge to be available from the context.", "labels": [], "entities": [{"text": "resolution of anaphoric mentions", "start_pos": 54, "end_pos": 86, "type": "TASK", "confidence": 0.8597934246063232}]}, {"text": "Each generated discourse has different names, actions and locations randomly picked from a pre-defined set of names, actions and locations.", "labels": [], "entities": []}, {"text": "From the generated instances, 20% are taken for testing resulting in 11520 training instances and 2880 test instances in each dataset 1 .  All the results are reported on the test data from 4 synthetic datasets.", "labels": [], "entities": []}, {"text": "One of the state-of-the-art coreference resolution systems,) is chosen to compare with end-toend memory networks (MemN2N).", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.9184035062789917}]}, {"text": "All the results reported with MemN2N are averaged across 10 different executions with different seeds used for training data shuffling.", "labels": [], "entities": [{"text": "MemN2N", "start_pos": 30, "end_pos": 36, "type": "DATASET", "confidence": 0.8915966153144836}, {"text": "training data shuffling", "start_pos": 111, "end_pos": 134, "type": "TASK", "confidence": 0.6717335482438406}]}, {"text": "This is done to make the results independent of data-shuffling during training.", "labels": [], "entities": []}, {"text": "The hyper-parameters are fixed as embedding size=20, hops=3 under the training configuration as optimizer=Adam, #epochs=100, batch size=32, learning rate=0.01.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 140, "end_pos": 153, "type": "METRIC", "confidence": 0.9076701998710632}]}, {"text": "To make the results of Cort comparable with the answer prediction accuracy of memory networks, accuracy of Cort is computed based on the number of correctly identified coreferent mentions, instead of CoNLL score ().", "labels": [], "entities": [{"text": "answer prediction", "start_pos": 48, "end_pos": 65, "type": "TASK", "confidence": 0.6827486306428909}, {"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.999413251876831}, {"text": "Cort", "start_pos": 107, "end_pos": 111, "type": "METRIC", "confidence": 0.7938610911369324}, {"text": "CoNLL score", "start_pos": 200, "end_pos": 211, "type": "METRIC", "confidence": 0.927924394607544}]}, {"text": "This evaluation is valid since there is only one coreferent chain comprising 2 mentions in each synthetic dataset instance.", "labels": [], "entities": []}, {"text": "We experiment Cort with the available pre-trained coreference model and with the model trained on training data from the corresponding synthetic dataset.", "labels": [], "entities": []}, {"text": "We also check for the effectiveness of attention mechanism in memory networks to aid coreference resolution, through attention mechanism accuracy.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 85, "end_pos": 107, "type": "TASK", "confidence": 0.9540342688560486}, {"text": "accuracy", "start_pos": 137, "end_pos": 145, "type": "METRIC", "confidence": 0.9781333804130554}]}, {"text": "Attention mechanism accuracy indicates, given an anaphoric mention, how capable the memory networks approach approach is in identifying the probable sentences to find the antecedent.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.8142231702804565}]}, {"text": "The synthetic dataset has information about sentences those are relevant to the answer for each discourse instance.", "labels": [], "entities": []}, {"text": "Attention weights obtained from memory networks are analyzed to get the sentences from the input discourse with higher attention, which in turn is used to compute attention accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 173, "end_pos": 181, "type": "METRIC", "confidence": 0.8990229964256287}]}, {"text": "compares the antecedent prediction accuracy between Cort and MemN2N.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9173160195350647}, {"text": "MemN2N", "start_pos": 61, "end_pos": 67, "type": "DATASET", "confidence": 0.8810873627662659}]}, {"text": "The results shows the superiority of memory networks over Cort (on both pre-trained and synthetic data trained models) in considering the context while resolving coreference.", "labels": [], "entities": []}, {"text": "The existing feature based approaches have an inclination towards syntactical clues.", "labels": [], "entities": []}, {"text": "discusses prediction accuracy and attention accuracy with MemN2N and the modifications described in Section 3.1.", "labels": [], "entities": [{"text": "prediction", "start_pos": 10, "end_pos": 20, "type": "TASK", "confidence": 0.9052824378013611}, {"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9019860029220581}, {"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.818354606628418}, {"text": "MemN2N", "start_pos": 58, "end_pos": 64, "type": "DATASET", "confidence": 0.9524126648902893}]}, {"text": "We observe that most of the mis-predictions stem from attention errors, i.e. a wrong answer usually comes from a wrongly high-weighted sentence.", "labels": [], "entities": []}, {"text": "This shows the strong dependence of the answer module on the attention mechanism.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Antecedent prediction accuracy (pred. acc.) and attention accuracy (att. acc.) with MemN2N  and its modifications. (Accuracy in %. Best results shown in bold.)", "labels": [], "entities": [{"text": "Antecedent prediction", "start_pos": 10, "end_pos": 31, "type": "METRIC", "confidence": 0.7535648047924042}, {"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.520296573638916}, {"text": "pred. acc.", "start_pos": 42, "end_pos": 52, "type": "METRIC", "confidence": 0.8838689625263214}, {"text": "attention accuracy (att. acc.", "start_pos": 58, "end_pos": 87, "type": "METRIC", "confidence": 0.7023720979690552}, {"text": "Accuracy", "start_pos": 126, "end_pos": 134, "type": "METRIC", "confidence": 0.9993374943733215}]}]}