{"title": [{"text": "Converting the T \u00a8 uBa-D/Z treebank of German to Universal Dependencies", "labels": [], "entities": [{"text": "T \u00a8 uBa-D/Z treebank of German to Universal Dependencies", "start_pos": 15, "end_pos": 71, "type": "DATASET", "confidence": 0.9025574705817483}]}], "abstractContent": [{"text": "This paper describes the conversion of T\u00fcBa-D/Z, one of the major German constituency treebanks, to Universal Dependencies.", "labels": [], "entities": [{"text": "T\u00fcBa-D/Z", "start_pos": 39, "end_pos": 47, "type": "DATASET", "confidence": 0.740246057510376}, {"text": "German constituency treebanks", "start_pos": 66, "end_pos": 95, "type": "DATASET", "confidence": 0.7348019480705261}]}, {"text": "Besides the automatic conversion process, we describe manual annotation of a small part of the treebank based on the UD annotation scheme for the purposes of evaluating the automatic conversion.", "labels": [], "entities": []}, {"text": "The automatic conversion shows fairly high agreement with the manual annotations .", "labels": [], "entities": []}], "introductionContent": [{"text": "During the past decade, dependency annotations have become the primary means of syntactic annotation in treebanks.", "labels": [], "entities": [{"text": "dependency annotations", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.7944343090057373}]}, {"text": "Compared to more traditional constituency annotations, the increasing popularity of dependency annotations has multiple reasons, including the easy interpretation of dependency annotations by non-experts, more successful applications of the dependency parses to NLP tools, faster parsing methods, and the community formed around successive dependency parsing shared tasks.", "labels": [], "entities": [{"text": "dependency parses", "start_pos": 241, "end_pos": 258, "type": "TASK", "confidence": 0.6708083152770996}, {"text": "parsing", "start_pos": 280, "end_pos": 287, "type": "TASK", "confidence": 0.9746801257133484}, {"text": "dependency parsing shared tasks", "start_pos": 340, "end_pos": 371, "type": "TASK", "confidence": 0.8036215305328369}]}, {"text": "In recent years, we have seen a surge of interest towards unified tagsets and annotation guidelines for various types of annotations found in (dependency) treebanks).", "labels": [], "entities": []}, {"text": "The Universal Dependencies (UD) project) is a largescale community effort to build unified tagsets and annotation guidelines across many languages.", "labels": [], "entities": []}, {"text": "Despite the growing popularity of UD, and the growing number of new treebanks using the UD annotation scheme, many of the large treebanks with high-quality annotations are still constituency treebanks.", "labels": [], "entities": [{"text": "UD", "start_pos": 34, "end_pos": 36, "type": "DATASET", "confidence": 0.7366943955421448}, {"text": "UD annotation scheme", "start_pos": 88, "end_pos": 108, "type": "DATASET", "confidence": 0.8246092200279236}]}, {"text": "Since Collins (1999), a wellknown solution for obtaining high-quality dependency annotations is automatically converting the constituency annotations to dependency annotations, which includes some of the present UD treebanks which were converted from constituency treebanks or dependency treebanks with different annotation schemes.", "labels": [], "entities": [{"text": "UD treebanks", "start_pos": 212, "end_pos": 224, "type": "DATASET", "confidence": 0.8207738399505615}]}, {"text": "In this paper, we describe our efforts of automatically converting one of the major German treebanks, T\u00fcBa-D/Z (), to UD annotation scheme version 2.", "labels": [], "entities": [{"text": "German treebanks", "start_pos": 84, "end_pos": 100, "type": "DATASET", "confidence": 0.8286381661891937}]}, {"text": "German is one of the few languages with multiple large hand-annotated treebanks.", "labels": [], "entities": []}, {"text": "Apart from the T\u00fcBa-D/Z, the TIGER treebank () is another large constituency treebank of German, as well as the NEGRA treebank (.", "labels": [], "entities": [{"text": "TIGER treebank", "start_pos": 29, "end_pos": 43, "type": "DATASET", "confidence": 0.8238739967346191}, {"text": "NEGRA treebank", "start_pos": 112, "end_pos": 126, "type": "DATASET", "confidence": 0.956952691078186}]}, {"text": "Another large German treebank is the Hamburg dependency treebank (HDT; Foth (2006),), which is natively annotated as a dependency treebank.", "labels": [], "entities": [{"text": "Hamburg dependency treebank (HDT; Foth (2006),)", "start_pos": 37, "end_pos": 84, "type": "DATASET", "confidence": 0.950997281074524}]}, {"text": "The Universal Dependencies distribution also includes a German dependency treebank (UD German), which is based on the Google Universal Dependencies treebanks, and converted to Universal Dependencies annotation scheme by the UD contributors.", "labels": [], "entities": [{"text": "Universal Dependencies distribution", "start_pos": 4, "end_pos": 39, "type": "DATASET", "confidence": 0.7763716777165731}, {"text": "German dependency treebank (UD German)", "start_pos": 56, "end_pos": 94, "type": "DATASET", "confidence": 0.7806452853339059}, {"text": "Google Universal Dependencies treebanks", "start_pos": 118, "end_pos": 157, "type": "DATASET", "confidence": 0.6483760997653008}]}, {"text": "The dependency and POS tag annotations in the UD German treebank were based on manual annotations, while other annotation layers, e.g., morphological features and lemmas, are automatically annotated.", "labels": [], "entities": [{"text": "POS tag annotations", "start_pos": 19, "end_pos": 38, "type": "METRIC", "confidence": 0.8622713486353556}, {"text": "UD German treebank", "start_pos": 46, "end_pos": 64, "type": "DATASET", "confidence": 0.9552481969197592}]}, {"text": "Besides being the smallest of the treebanks listed above, and despite continuous improvements over the previous UD versions, UD German does not yet seem to have the same level of annotation quality as the other German treebanks listed above.", "labels": [], "entities": [{"text": "UD German", "start_pos": 125, "end_pos": 134, "type": "DATASET", "confidence": 0.7494125366210938}]}, {"text": "An overview of the treebanks with the indication of their sizes is presented in.", "labels": [], "entities": []}, {"text": "In this study we focus only on conversion of T\u00fcBa-D/Z, but note that the present effort maybe a precursor to obtaining a very large dependency treebank of German annotated uniformly using the UD scheme.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows: in the next section we provide a brief description of our source treebank, and review the earlier constituency-to-dependency conversion efforts of German treebanks.", "labels": [], "entities": [{"text": "constituency-to-dependency conversion", "start_pos": 151, "end_pos": 188, "type": "TASK", "confidence": 0.6503862738609314}]}, {"text": "Section 3 describes the automatic conversion process.", "labels": [], "entities": [{"text": "automatic conversion", "start_pos": 24, "end_pos": 44, "type": "TASK", "confidence": 0.5133073925971985}]}, {"text": "Section 4 describes the manual annotation of the evaluation set, and compares the automatic conversion with human annotations.", "labels": [], "entities": []}, {"text": "We conclude in Section 5 after a brief discussion.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the accuracy of the automatic conversion, we annotated a selection of 200 sentences from T\u00fcBa-D/Z.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.999381422996521}]}, {"text": "About half of the sentences (116) were selected manually to cover a wide range of syntactic constructions, while the remaining sentences are randomly sampled.", "labels": [], "entities": []}, {"text": "In total, the selection includes 3134 tokens.", "labels": [], "entities": []}, {"text": "The overall average tokens per sentence is 15.67.", "labels": [], "entities": []}, {"text": "However, the hand- picked sentences are shorter on average (12.05) than the randomly sampled sentences (20.67).", "labels": [], "entities": []}, {"text": "We used WebAnno (Eckart de) for the annotation process.", "labels": [], "entities": [{"text": "WebAnno (Eckart de)", "start_pos": 8, "end_pos": 27, "type": "DATASET", "confidence": 0.8702988624572754}]}, {"text": "Only the dependency relations were annotated manually.", "labels": [], "entities": []}, {"text": "In manual annotations, we did not use sub-types of the UD relations.", "labels": [], "entities": []}, {"text": "The additional information required for all sub-types we use (Table 3) is unambiguously available in the original T\u00fcBa-D/Z annotations.", "labels": [], "entities": [{"text": "T\u00fcBa-D/Z annotations", "start_pos": 114, "end_pos": 134, "type": "DATASET", "confidence": 0.8641505241394043}]}, {"text": "We compare the gold-standard annotations from the human annotators with the automatic conversion on the 200 sentences described above.", "labels": [], "entities": []}, {"text": "The labeled and unlabeled attachment agreements on 3134 tokens are 83.55 % and 87.13 % respectively.", "labels": [], "entities": []}, {"text": "The agreement values are slightly better for handpicked linguistic examples, which are also shorter.", "labels": [], "entities": []}, {"text": "A closer look at the disagreements reveal only a few general tendencies.", "labels": [], "entities": []}, {"text": "For the attachment disagreements, the annotators seem to be less consistent in attaching punctuation.", "labels": [], "entities": []}, {"text": "All cases of punctuation disagreements are annotator mistakes.", "labels": [], "entities": []}, {"text": "If we disregard punctuation, the agreement values increase by about three percent.", "labels": [], "entities": []}, {"text": "Other headassignment errors do not follow a clear pattern.", "labels": [], "entities": []}, {"text": "The ones we inspected manually correspond to either ambiguous cases like prepositional phrase or adverbial attachment, or annotator errors.", "labels": [], "entities": [{"text": "prepositional phrase or adverbial attachment", "start_pos": 73, "end_pos": 117, "type": "TASK", "confidence": 0.6851516723632812}]}, {"text": "As noted in Section 3, the head of parataxis relation is ambiguous.", "labels": [], "entities": []}, {"text": "As a result, the direction of parataxis relation often disagrees between the automatic conversion and the manual annotations.", "labels": [], "entities": []}, {"text": "For example, for the sentence in, the human annotator marked the head of the second sentence as the head of the dependency tree, while automatic annotation picks the first one.", "labels": [], "entities": []}, {"text": "This is also visible in, where parataxis and root labels seem to be confused rather frequently.", "labels": [], "entities": []}, {"text": "The confusions between dependency types are presented in.", "labels": [], "entities": []}, {"text": "The most common mismatch in label assignment occurs with the appos dependency.", "labels": [], "entities": [{"text": "label assignment", "start_pos": 28, "end_pos": 44, "type": "TASK", "confidence": 0.669255942106247}]}, {"text": "As noted earlier, the automatic conversion assigns the label appos in all non-head-marked dependencies between two noun phrases.", "labels": [], "entities": []}, {"text": "A large number of dependencies that are labeled as appos by the automatic conversion are labeled flat or nmod by the human annotators.", "labels": [], "entities": []}, {"text": "Besides the attachment ambiguity discussed above, parataxis is another frequently confused label, which is often marked as list by the human annotators.", "labels": [], "entities": []}, {"text": "This is one of the cases where T\u00fcBa-D/Z annotations do allow distinguishing between two dependency relations (in this case, UD parataxis and list dependencies).", "labels": [], "entities": []}, {"text": "Other notable label confusions in include nmod and obl which is often an annotator error, and expl and nsubj which is often a difficult annotation decision.", "labels": [], "entities": []}, {"text": "In general, we found the cross-tabulation in Table 4 useful.", "labels": [], "entities": []}, {"text": "Besides revealing some of the inherent ambiguities for the conversion process, we discovered some of the converter errors, and some of the errors in the original T\u00fcBa-D/Z annotations.", "labels": [], "entities": []}, {"text": "The remaining items indicate annotation errors, some of which are indications of difficult annotation decisions (such as punctuation attachment) for manual annotation with the UD scheme.: Label agreement between automatic conversion and manual annotation.", "labels": [], "entities": []}, {"text": "The row labels are the labels assigned by the human annotator.", "labels": [], "entities": []}, {"text": "The columns correspond to the labels assigned by the automatic conversion.", "labels": [], "entities": []}, {"text": "The automatic conversion does not use vocative, list, and goeswith relations, it did not find any discourse relation according to its head-finding rules, dep relation was not used since the head-finding heuristics did not fail in this set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: An overview of large-scale (mostly)  hand-annotated German treebanks. The number  of sentences and tokens are from the latest ver- sions of the treebanks as of this writing, namely,  T\u00fcBa-D/Z version 10.0, TIGER version 2.2, NE- GRA version 2, HDT version 1.0.1 (counting only  the hand-annotated parts A and B), and UD Ger- man version 2.0.", "labels": [], "entities": [{"text": "German treebanks", "start_pos": 62, "end_pos": 78, "type": "DATASET", "confidence": 0.7634483873844147}, {"text": "T\u00fcBa-D/Z version 10.0", "start_pos": 193, "end_pos": 214, "type": "DATASET", "confidence": 0.8652088642120361}, {"text": "NE- GRA version", "start_pos": 235, "end_pos": 250, "type": "TASK", "confidence": 0.41718485206365585}, {"text": "UD Ger- man version 2.0", "start_pos": 327, "end_pos": 350, "type": "DATASET", "confidence": 0.7323002219200134}]}, {"text": " Table 3: Number and percentage of dependencies  in the converted T\u00fcBa-D/Z treebank.", "labels": [], "entities": [{"text": "Number", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9510186910629272}, {"text": "T\u00fcBa-D/Z treebank", "start_pos": 66, "end_pos": 83, "type": "DATASET", "confidence": 0.9129302203655243}]}, {"text": " Table 4: Label agreement between automatic conversion and manual annotation. The row labels are the  labels assigned by the human annotator. The columns correspond to the labels assigned by the automatic  conversion. The automatic conversion does not use vocative, list, and goeswith relations, it did  not find any discourse relation according to its head-finding rules, dep relation was not used since the  head-finding heuristics did not fail in this set.", "labels": [], "entities": []}]}