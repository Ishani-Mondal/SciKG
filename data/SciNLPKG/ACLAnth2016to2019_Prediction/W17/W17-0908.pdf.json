{"title": [{"text": "LSDSem 2017: Exploring Data Generation Methods for the Story Cloze Test", "labels": [], "entities": [{"text": "Exploring Data Generation", "start_pos": 13, "end_pos": 38, "type": "TASK", "confidence": 0.6179793377717336}, {"text": "Story Cloze Test", "start_pos": 55, "end_pos": 71, "type": "DATASET", "confidence": 0.9612610340118408}]}], "abstractContent": [{"text": "The Story Cloze test (Mostafazadeh et al., 2016) is a recent effort in providing a common test scenario for text understanding systems.", "labels": [], "entities": [{"text": "text understanding", "start_pos": 108, "end_pos": 126, "type": "TASK", "confidence": 0.8896041512489319}]}, {"text": "As part of the LSDSem 2017 shared task, we present a system based on a deep learning architecture combined with a rich set of manually-crafted linguistic features.", "labels": [], "entities": [{"text": "LSDSem 2017 shared task", "start_pos": 15, "end_pos": 38, "type": "DATASET", "confidence": 0.7902937531471252}]}, {"text": "The system outperforms all known baselines for the task, suggesting that the chosen approach is promising.", "labels": [], "entities": []}, {"text": "We additionally present two methods for generating further training data based on stories from the ROCStories corpus.", "labels": [], "entities": [{"text": "ROCStories corpus", "start_pos": 99, "end_pos": 116, "type": "DATASET", "confidence": 0.954502135515213}]}, {"text": "Our system and generated data are publicly available on GitHub 1 .", "labels": [], "entities": []}], "introductionContent": [{"text": "The goal of the Story Cloze testis to provide a common ground for the evaluation of systems on language understanding.", "labels": [], "entities": [{"text": "Story Cloze testis", "start_pos": 16, "end_pos": 34, "type": "DATASET", "confidence": 0.8214348753293356}, {"text": "language understanding", "start_pos": 95, "end_pos": 117, "type": "TASK", "confidence": 0.7052726149559021}]}, {"text": "Given four sentences of a story on everyday life events, a system has to identify the correct ending from a set of two predefined ending sentences.", "labels": [], "entities": []}, {"text": "The \"correct\" ending in this case is the one which most humans would choose as the closing sentence for the story context.", "labels": [], "entities": []}, {"text": "We first report the discoveries we made while exploring the provided datasets (Section 2) followed by a description of our system (Section 3).", "labels": [], "entities": []}, {"text": "We present and discuss its results (Sections 4 and 5) and come to a close in the conclusion (Section 6).", "labels": [], "entities": []}, {"text": "provide a validation and 1 github.com/UKPLab/lsdsem2017-story-cloze a test set for the Story Cloze test, both of which contain around 1800 stories 2 . Each of those stories consists of four context sentences and two endings to choose from.", "labels": [], "entities": [{"text": "UKPLab", "start_pos": 38, "end_pos": 44, "type": "DATASET", "confidence": 0.9795252084732056}, {"text": "Story Cloze test", "start_pos": 87, "end_pos": 103, "type": "DATASET", "confidence": 0.8350524306297302}]}, {"text": "Additionally, two ROCStories datasets were made available with close to 100 000 stories in total.", "labels": [], "entities": [{"text": "ROCStories datasets", "start_pos": 18, "end_pos": 37, "type": "DATASET", "confidence": 0.9078732132911682}]}, {"text": "Stories from these datasets also cover everyday life events but consist of a fixed number of five sentences without ending candidates.", "labels": [], "entities": []}], "datasetContent": [{"text": "To gain an overview of the task, we categorized two hundred stories from the validation set based on how their correct ending can be identified.", "labels": [], "entities": []}, {"text": "We noticed that a large set of stories can indeed be solved via text understanding and logical inference.", "labels": [], "entities": [{"text": "text understanding", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.7497284114360809}]}, {"text": "We infer from these observations that an approach focusing exclusively on text understanding should perform well.", "labels": [], "entities": [{"text": "text understanding", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.8426350653171539}]}, {"text": "However, the dataset suggests that an approach which (additionally) exploits how humans write and perceive stories could also lead to respectable results, albeit not in the way originally intended for the Story Cloze test.", "labels": [], "entities": [{"text": "Story Cloze test", "start_pos": 205, "end_pos": 221, "type": "DATASET", "confidence": 0.8719043930371603}]}, {"text": "Because our presented approach conducts supervised learning, it requires training data in the same form as testing data.", "labels": [], "entities": []}, {"text": "Up to this point, the only dataset available in this form is the Story Cloze validation set which consists of comparably few instances for training.", "labels": [], "entities": [{"text": "Story Cloze validation set", "start_pos": 65, "end_pos": 91, "type": "DATASET", "confidence": 0.923162654042244}]}, {"text": "We experimented with ways to automatically create larger training datasets.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: ROCStories with wrong endings as generated by the KDE sampling technique", "labels": [], "entities": []}, {"text": " Table 2: System accuracies on the Story Cloze  datasets. Results marked by * are statistically  significant according to McNemar's test with a  p-value \u2264 0.05.", "labels": [], "entities": [{"text": "Story Cloze  datasets", "start_pos": 35, "end_pos": 56, "type": "DATASET", "confidence": 0.9773150682449341}]}]}