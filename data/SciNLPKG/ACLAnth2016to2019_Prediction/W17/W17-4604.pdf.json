{"title": [], "abstractContent": [{"text": "We present an analysis of parser performance on speech data, comparing word type and token frequency distributions with written data, and evaluating parse accuracy by length of input string.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 155, "end_pos": 163, "type": "METRIC", "confidence": 0.9025266766548157}]}, {"text": "We find that parser performance tends to deteriorate with increasing length of string, more so for spoken than for written texts.", "labels": [], "entities": []}, {"text": "We train an alternative parsing model with added speech data and demonstrate improvements inaccuracy on speech-units, with no deterioration in performance on written text.", "labels": [], "entities": []}], "introductionContent": [{"text": "Relatively little attention has been paid to parsing spoken language compared to parsing written language.", "labels": [], "entities": [{"text": "parsing spoken language", "start_pos": 45, "end_pos": 68, "type": "TASK", "confidence": 0.91082235177358}, {"text": "parsing written language", "start_pos": 81, "end_pos": 105, "type": "TASK", "confidence": 0.8939074873924255}]}, {"text": "The majority of parsers are built using newswire training data and The Wall Street Journal section 21 of the Penn Treebank is a ubiquitous test set.", "labels": [], "entities": [{"text": "The Wall Street Journal section 21 of the Penn Treebank", "start_pos": 67, "end_pos": 122, "type": "DATASET", "confidence": 0.8872372508049011}]}, {"text": "However, the parsing of speech is of no little importance, since it's the primary mode of communication worldwide, and human computer interaction through the spoken modality is increasingly common.", "labels": [], "entities": [{"text": "parsing of speech", "start_pos": 13, "end_pos": 30, "type": "TASK", "confidence": 0.9071674346923828}]}, {"text": "In this paper we first describe the morphosyntactic characteristics of spoken language and point out some key distributional differences with written language, and the implications for parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 185, "end_pos": 192, "type": "TASK", "confidence": 0.9652338624000549}]}, {"text": "We then investigate how well a commonlyused open source parser performs on a corpus of spoken language and corpora of written language, showing that performance deteriorates sooner for speech as the length of input string increases.", "labels": [], "entities": []}, {"text": "We demonstrate that anew parsing model trained on both written and spoken data brings improved performance, making this model freely available  nally we consider a modification to deal with long input strings in spoken language, a preprocessing step which we plan to implement in future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used the Stanford CoreNLP toolkit () to tokenize, tag and parse input strings from a range of corpora.", "labels": [], "entities": [{"text": "Stanford CoreNLP toolkit", "start_pos": 12, "end_pos": 36, "type": "DATASET", "confidence": 0.8873306512832642}]}, {"text": "This includes the 766k token section of the Switchboard Corpus of telephone conversations (SWB) distributed as part of Penn Treebank 3 (), and English treebanks from the Universal Dependencies release 2 (.", "labels": [], "entities": [{"text": "Switchboard Corpus of telephone conversations (SWB)", "start_pos": 44, "end_pos": 95, "type": "DATASET", "confidence": 0.7636963948607445}, {"text": "Penn Treebank 3", "start_pos": 119, "end_pos": 134, "type": "DATASET", "confidence": 0.9822109142939249}, {"text": "English treebanks from the Universal Dependencies release 2", "start_pos": 143, "end_pos": 202, "type": "DATASET", "confidence": 0.8675465658307076}]}, {"text": "All treebanks are in CoNLL format 2 and we measure performance through unlabelled attachment scores (UAS) which indicate the proportion of tokens with correctly identified heads in the output of the parser, compared with gold-standard annotations ().", "labels": [], "entities": [{"text": "unlabelled attachment scores (UAS)", "start_pos": 71, "end_pos": 105, "type": "METRIC", "confidence": 0.7966200311978658}]}, {"text": "In we report UAS scores overall for each corpus, along with corpus sizes in terms of tokens and sentence or speech units.", "labels": [], "entities": []}, {"text": "It is apparent that (a) parser performance for speech units is much poorer than for written units, and that (b) performance across written corpora is broadly similar, though TLE (surprisingly) has the highest UAS score -possibly reflective of a tendency for language learners to write in syntactically more con-  Closer inspection of UAS scores by speech unit in SWB shows that parser performance is not uniformly worse than it is for written language.", "labels": [], "entities": [{"text": "UAS score", "start_pos": 209, "end_pos": 218, "type": "METRIC", "confidence": 0.9553723335266113}]}, {"text": "If we sort the input units into bins by unit length, we see that the parser is as accurate for shorter units of transcribed speech as it is for written units of similar lengths . Indeed for speech units of 1-10 tokens in SWB, mean UAS is similar to that for sentence units of 1-10 tokens in EWT.", "labels": [], "entities": [{"text": "UAS", "start_pos": 231, "end_pos": 234, "type": "METRIC", "confidence": 0.9864778518676758}, {"text": "EWT", "start_pos": 291, "end_pos": 294, "type": "DATASET", "confidence": 0.9746290445327759}]}, {"text": "However, the main difference in UAS scores over increasingly long inputs is the rate of deterioration in parser performance: for speech units the dropoff in UAS scores is much steeper.", "labels": [], "entities": []}, {"text": "Even with strings up to 40 tokens in length, mean UAS remains within 10 points of that for the 1-10 token bin in the three written corpora.", "labels": [], "entities": [{"text": "UAS", "start_pos": 50, "end_pos": 53, "type": "METRIC", "confidence": 0.6669818162918091}]}, {"text": "But for SWB, mean UAS by that point is less than 50%.", "labels": [], "entities": [{"text": "SWB", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.5964108109474182}, {"text": "UAS", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.9982814788818359}]}, {"text": "In fact in the 11-20 token bin we already see a steep drop-off in parser performance compared to the shortest class of speech unit.", "labels": [], "entities": []}, {"text": "It is only above 50 tokens that EWT and LinES UAS means fall by more than 10 percentage points compared to the 1-10 token score; for TLE this is true above 60 tokens.", "labels": [], "entities": [{"text": "EWT", "start_pos": 32, "end_pos": 35, "type": "METRIC", "confidence": 0.6559851765632629}, {"text": "LinES", "start_pos": 40, "end_pos": 45, "type": "METRIC", "confidence": 0.9799889326095581}, {"text": "UAS", "start_pos": 46, "end_pos": 49, "type": "METRIC", "confidence": 0.6090281009674072}, {"text": "TLE", "start_pos": 133, "end_pos": 136, "type": "METRIC", "confidence": 0.765182375907898}]}, {"text": "By this stage we are dealing with small proportions of the written corpora: 96.9% of the units in EWT and 98.1% in LinES are of length 50 tokens or fewer, whilst 99.8% of units in TLE are 60 tokens or shorter.", "labels": [], "entities": [{"text": "EWT", "start_pos": 98, "end_pos": 101, "type": "DATASET", "confidence": 0.9580028057098389}, {"text": "LinES", "start_pos": 115, "end_pos": 120, "type": "DATASET", "confidence": 0.8365170359611511}]}, {"text": "For SWB the problem is more acute, with 25.5% of units at least 11 tokens long and scoring mean UAS 50% or less.", "labels": [], "entities": [{"text": "SWB", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9386840462684631}, {"text": "scoring mean", "start_pos": 83, "end_pos": 95, "type": "METRIC", "confidence": 0.8675385117530823}, {"text": "UAS", "start_pos": 96, "end_pos": 99, "type": "METRIC", "confidence": 0.47743284702301025}]}, {"text": "illustrates the disparity with boxplots showing UAS medians (thick line), first and third quartiles ('hinges' at bottom and top of box), \u00b11.5 inter-quartile range from the hinge (whiskers), and outliers beyond this range.", "labels": [], "entities": [{"text": "UAS medians", "start_pos": 48, "end_pos": 59, "type": "METRIC", "confidence": 0.6750834137201309}]}, {"text": "It is apparent that parser performance deteriorates as the unit length increases, for all corpora, but especially so for the speech corpus SWB.", "labels": [], "entities": []}, {"text": "What can be done to address this problem?", "labels": [], "entities": []}, {"text": "One approach is to train anew parsing model on more appropriate training data, since general-purpose open-source parsers are usually trained on sections of The Wall Street Journal (WSJ) in Treebank 3 ().", "labels": [], "entities": [{"text": "Wall Street Journal (WSJ) in Treebank 3", "start_pos": 160, "end_pos": 199, "type": "DATASET", "confidence": 0.9205283787515428}]}, {"text": "Training NLP tools with data appropriate to the medium, genre, or domain, is generally thought to be sensible and helpful to the task ().", "labels": [], "entities": []}, {"text": "We do not claim this to be a groundbreaking proposal therefore, but instead present the results of such a step here for three reasons: (i) To demonstrate how much improvement can be gained with a domain-appropriate parsing model; (ii) To make the speech parsing model publicly available for other researchers; (iii) To call for greater availability of speech transcript treebanks.", "labels": [], "entities": [{"text": "speech parsing", "start_pos": 247, "end_pos": 261, "type": "TASK", "confidence": 0.705110713839531}]}, {"text": "With regard to point (iii), to the best of our knowledge, the Switchboard portion of the Penn Treebank (PTB) is the only substantial, readilyavailable 4 treebank for spoken English.", "labels": [], "entities": [{"text": "Penn Treebank (PTB)", "start_pos": 89, "end_pos": 108, "type": "DATASET", "confidence": 0.9509750008583069}]}, {"text": "We welcome feedback to the contrary, and efforts to pro-    duce new treebanks.", "labels": [], "entities": []}, {"text": "Furthermore, if this is the situation for as well-resourced a language as English, we assume that the need for treebanks of speech corpora is even greater for other languages.", "labels": [], "entities": []}, {"text": "In point (ii) we don't imagine we're making a definitive statement on the best model for parsing speech -rather we think of it as a baseline against which future models can be compared.", "labels": [], "entities": [{"text": "parsing speech", "start_pos": 89, "end_pos": 103, "type": "TASK", "confidence": 0.9073910117149353}]}, {"text": "We welcome contributions in this respect.", "labels": [], "entities": []}, {"text": "As for point (i), we trained two new parsing models using the Stanford Parser ().", "labels": [], "entities": [{"text": "Stanford Parser", "start_pos": 62, "end_pos": 77, "type": "DATASET", "confidence": 0.7478176951408386}]}, {"text": "These were based on the WSJ sections of PTB as is standard, with added training data from SWB setting the maximum unit length first at 40 tokens -which appears to be the standard length for the models distributed with the parser -and secondly at an increased maximum of 80 tokens.", "labels": [], "entities": [{"text": "WSJ sections of PTB", "start_pos": 24, "end_pos": 43, "type": "DATASET", "confidence": 0.8802573084831238}, {"text": "SWB", "start_pos": 90, "end_pos": 93, "type": "DATASET", "confidence": 0.8568400740623474}]}, {"text": "Both were probabilistic context-free grammars.", "labels": [], "entities": []}, {"text": "We refer to them as PCFG WSJ SWB 40 and PCFG WSJ SWB 80.", "labels": [], "entities": [{"text": "PCFG WSJ SWB 40", "start_pos": 20, "end_pos": 35, "type": "DATASET", "confidence": 0.871923953294754}, {"text": "PCFG WSJ SWB 80", "start_pos": 40, "end_pos": 55, "type": "DATASET", "confidence": 0.9089950323104858}]}, {"text": "In we show overall UAS scores for our four target English corpora, for three parsing models: the standard model distributed with CoreNLP, and our two new models, PCFG WSJ SWB 40 and PCFG WSJ SWB 80.", "labels": [], "entities": [{"text": "CoreNLP", "start_pos": 129, "end_pos": 136, "type": "DATASET", "confidence": 0.9510963559150696}, {"text": "PCFG WSJ SWB 40", "start_pos": 162, "end_pos": 177, "type": "DATASET", "confidence": 0.8582733422517776}, {"text": "PCFG WSJ SWB 80", "start_pos": 182, "end_pos": 197, "type": "DATASET", "confidence": 0.8923688381910324}]}, {"text": "It is apparent that the new models bring a large performance gain in parsing speech, as expected, plus a small performance gain in parsing writing -presumably because they can deal better than predominantly newswire trained models can with the less canonical syntactic structures contained in the written English obtained from the web and from learners.", "labels": [], "entities": [{"text": "parsing speech", "start_pos": 69, "end_pos": 83, "type": "TASK", "confidence": 0.9028917551040649}, {"text": "parsing writing", "start_pos": 131, "end_pos": 146, "type": "TASK", "confidence": 0.9348825812339783}]}, {"text": "There is no apparent difference between PCFG WSJ SWB 40 and PCFG WSJ SWB 80 (therefore the latter does no harm and we make both available), presumably because there are relatively few units greater than 40 tokens and so any performance gain here has little bearing on the overall scores.", "labels": [], "entities": [{"text": "PCFG WSJ SWB 40", "start_pos": 40, "end_pos": 55, "type": "DATASET", "confidence": 0.7725846022367477}, {"text": "PCFG WSJ SWB 80", "start_pos": 60, "end_pos": 75, "type": "DATASET", "confidence": 0.8615446239709854}]}, {"text": "Or, CoreNLP and PCFG WSJ SWB 40 are able to generalise to long strings as well as the PCFG WSJ SWB 80 model which has been presented with long string exemplars in training.: Overall unlabelled attachment scores for four English corpora and three parsing models In we show the difference between the CoreNLP and PCFG models in terms of UAS delta for each input unit.", "labels": [], "entities": [{"text": "PCFG WSJ SWB 40", "start_pos": 16, "end_pos": 31, "type": "DATASET", "confidence": 0.8124258667230606}, {"text": "PCFG WSJ SWB 80", "start_pos": 86, "end_pos": 101, "type": "DATASET", "confidence": 0.8516196757555008}, {"text": "UAS delta", "start_pos": 335, "end_pos": 344, "type": "METRIC", "confidence": 0.9927839040756226}]}, {"text": "These are again binned by string length, and facetted by corpus.", "labels": [], "entities": []}, {"text": "It is apparent that the alteration for the smallest units is somewhat volatile.", "labels": [], "entities": []}, {"text": "This is understandable  given that a 1-token string which was correctly or incorrectly parsed by CoreNLP might now be incorrectly or correctly parsed by the PCFG models, leading to a delta of +1 or -1.", "labels": [], "entities": [{"text": "CoreNLP", "start_pos": 97, "end_pos": 104, "type": "DATASET", "confidence": 0.9130850434303284}, {"text": "PCFG", "start_pos": 157, "end_pos": 161, "type": "DATASET", "confidence": 0.9547076225280762}]}, {"text": "Nevertheless the majority of short tokens are unaffected -shown by the median and hinges of the 1-10 token boxplot centring on y=0.", "labels": [], "entities": []}, {"text": "Where the added SWB training data seems to help is in units longer than 10 tokens, where the UAS delta median and hinges are consistently above zero, indicating improved performance.", "labels": [], "entities": [{"text": "UAS delta median", "start_pos": 93, "end_pos": 109, "type": "METRIC", "confidence": 0.8316226998964945}]}, {"text": "The boxplots tend to centre around zero for the written corpora, except for the 71-80 bin in LinES for which the boxplot is above zero, albeit fora small sample size of 5).", "labels": [], "entities": [{"text": "LinES", "start_pos": 93, "end_pos": 98, "type": "DATASET", "confidence": 0.927693784236908}]}, {"text": "The pattern for both PCFG models is broadly the same.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The most frequently occurring tokens in  selected corpora of English speech (the Switch- board Corpus in Penn Treebank 3) and writing  (EWT, LinES, TLE), normalised to counts per mil- lion.", "labels": [], "entities": [{"text": "Switch- board Corpus in Penn Treebank 3", "start_pos": 91, "end_pos": 130, "type": "DATASET", "confidence": 0.8290451839566231}]}, {"text": " Table 2: Vocabulary sizes in selected corpora  of English speech and writing (* sampled from  766,560 tokens in SWB corpus; ** mean of 100  samples, st.dev=45.5).", "labels": [], "entities": [{"text": "SWB corpus", "start_pos": 113, "end_pos": 123, "type": "DATASET", "confidence": 0.9075067639350891}]}, {"text": " Table 3: The most frequently occurring bigrams  in selected corpora of English speech (the Switch- board Corpus in Penn Treebank 3) and writing  (EWT, LinES, TLE), normalised to counts per mil- lion.", "labels": [], "entities": [{"text": "Switch- board Corpus in Penn Treebank 3", "start_pos": 92, "end_pos": 131, "type": "DATASET", "confidence": 0.8108751252293587}]}, {"text": " Table 4: The most frequently occurring part-of- speech tag dependency pairs in selected corpora of  English speech (the Switchboard Corpus in Penn  Treebank 3) and writing (EWT, LinES, TLE), nor- malised to counts per million. The first tag in the  pair is the head of the relation; the second is the  dependent (Penn Treebank tagset).", "labels": [], "entities": [{"text": "Switchboard Corpus in Penn  Treebank 3", "start_pos": 121, "end_pos": 159, "type": "DATASET", "confidence": 0.825158566236496}, {"text": "Penn Treebank tagset", "start_pos": 314, "end_pos": 334, "type": "DATASET", "confidence": 0.9951827724774679}]}, {"text": " Table 5:  Corpus sizes and overall unla- belled attachment scores using Stanford Core  NLP; SWB=Switchboard, EWT=English Web  Treebank,  LinES=English section LinES,  TLE=Treebank of Learner English", "labels": [], "entities": [{"text": "unla- belled attachment scores", "start_pos": 36, "end_pos": 66, "type": "METRIC", "confidence": 0.733091127872467}, {"text": "Stanford Core  NLP", "start_pos": 73, "end_pos": 91, "type": "DATASET", "confidence": 0.9778719743092855}, {"text": "English Web  Treebank", "start_pos": 114, "end_pos": 135, "type": "DATASET", "confidence": 0.8556376496950785}, {"text": "TLE", "start_pos": 168, "end_pos": 171, "type": "METRIC", "confidence": 0.9348662495613098}]}, {"text": " Table 6: Unlabelled attachment scores by unit length in four English corpora (number of units in paren- theses).", "labels": [], "entities": []}, {"text": " Table 7: Overall unlabelled attachment scores for  four English corpora and three parsing models", "labels": [], "entities": []}]}