{"title": [{"text": "A Comparison of Neural Models for Word Ordering", "labels": [], "entities": [{"text": "Word Ordering", "start_pos": 34, "end_pos": 47, "type": "TASK", "confidence": 0.6862266361713409}]}], "abstractContent": [{"text": "We compare several language models for the word-ordering task and propose anew bag-to-sequence neural model based on attention-based sequence-to-sequence models.", "labels": [], "entities": []}, {"text": "We evaluate the model on a large German WMT data set where it significantly outperforms existing models.", "labels": [], "entities": [{"text": "German WMT data set", "start_pos": 33, "end_pos": 52, "type": "DATASET", "confidence": 0.7733364254236221}]}, {"text": "We also describe a novel search strategy for LM-based word ordering and report results on the English Penn Treebank.", "labels": [], "entities": [{"text": "LM-based word ordering", "start_pos": 45, "end_pos": 67, "type": "TASK", "confidence": 0.7207804222901663}, {"text": "English Penn Treebank", "start_pos": 94, "end_pos": 115, "type": "DATASET", "confidence": 0.9142487645149231}]}, {"text": "Our best model setup outperforms prior work both in terms of speed and quality.", "labels": [], "entities": [{"text": "speed", "start_pos": 61, "end_pos": 66, "type": "METRIC", "confidence": 0.9859979152679443}]}], "introductionContent": [{"text": "Finding the best permutation of a multi-set of words is a non-trivial task due to linguistic aspects such as \"syntactic structure, selective restrictions, subcategorization, and discourse considerations\".", "labels": [], "entities": []}, {"text": "This makes the word-ordering task useful for studying and comparing different kinds of models that produce text in tasks such as general natural language generation, image caption generation (, or machine translation (.", "labels": [], "entities": [{"text": "general natural language generation", "start_pos": 129, "end_pos": 164, "type": "TASK", "confidence": 0.6225036382675171}, {"text": "image caption generation", "start_pos": 166, "end_pos": 190, "type": "TASK", "confidence": 0.832248866558075}, {"text": "machine translation", "start_pos": 197, "end_pos": 216, "type": "TASK", "confidence": 0.7918982803821564}]}, {"text": "Since plausible word order is an essential criterion of output fluency for all of these tasks, progress on the wordordering problem is likely to have a positive impact on these tasks as well.", "labels": [], "entities": []}, {"text": "Word ordering has often been addressed as syntactic linearization which is a strategy that involves using syntactic structures or partof-speech and dependency labels (.", "labels": [], "entities": [{"text": "Word ordering", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.7258099317550659}]}, {"text": "It has also been addressed as LM-based linearization which relies solely on language models and obtains better Work partially supported by U.K. EPSRC grant EP/L027623/1.", "labels": [], "entities": [{"text": "LM-based linearization", "start_pos": 30, "end_pos": 52, "type": "TASK", "confidence": 0.7707464396953583}, {"text": "U.K. EPSRC grant EP/L027623/1", "start_pos": 139, "end_pos": 168, "type": "DATASET", "confidence": 0.8128683380782604}]}, {"text": "scores (de. Recently, showed that recurrent neural network language models with long short-term memory, LSTM) cells are very effective for word ordering even without any explicit syntactic information.", "labels": [], "entities": [{"text": "word ordering", "start_pos": 139, "end_pos": 152, "type": "TASK", "confidence": 0.769424170255661}]}, {"text": "We continue this line of work and make the following contributions.", "labels": [], "entities": []}, {"text": "We compare several language models on the word-ordering task and propose a bag-to-sequence neural architecture that equips an LSTM decoder with explicit context of the bag-ofwords (BOW) to be ordered.", "labels": [], "entities": []}, {"text": "This model performs particularly strongly on WMT data and is complementary to an RNNLM: combining both yields large BLEU gains even for small beam sizes.", "labels": [], "entities": [{"text": "WMT", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.9157736301422119}, {"text": "RNNLM", "start_pos": 81, "end_pos": 86, "type": "DATASET", "confidence": 0.8237913250923157}, {"text": "BLEU", "start_pos": 116, "end_pos": 120, "type": "METRIC", "confidence": 0.9987849593162537}]}, {"text": "We also propose a novel search strategy which outperforms a previous heuristic.", "labels": [], "entities": []}, {"text": "Both techniques together surpass prior work on the Penn Treebank at \u223c4x the speed.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 51, "end_pos": 64, "type": "DATASET", "confidence": 0.9935056865215302}]}], "datasetContent": [{"text": "We evaluate using data from the English-German news translation task (Bojar et al., 2015, WMT) and using the English Penn Treebank data.", "labels": [], "entities": [{"text": "English-German news translation task", "start_pos": 32, "end_pos": 68, "type": "TASK", "confidence": 0.669635646045208}, {"text": "WMT", "start_pos": 90, "end_pos": 93, "type": "DATASET", "confidence": 0.9135846495628357}, {"text": "English Penn Treebank data", "start_pos": 109, "end_pos": 135, "type": "DATASET", "confidence": 0.7473113313317299}]}, {"text": "Since additional knowledge sources are often available in practice, such as access to the source sentence in a translation scenario, we also report on bilingual experiments for the WMT task.", "labels": [], "entities": [{"text": "WMT task", "start_pos": 181, "end_pos": 189, "type": "TASK", "confidence": 0.9147222340106964}]}, {"text": "The WMT parallel training data includes Europarl v7, Common Crawl, and News Commentary v10.", "labels": [], "entities": [{"text": "WMT parallel training data", "start_pos": 4, "end_pos": 30, "type": "DATASET", "confidence": 0.6812438517808914}, {"text": "Europarl", "start_pos": 40, "end_pos": 48, "type": "DATASET", "confidence": 0.9685854911804199}, {"text": "Common Crawl", "start_pos": 53, "end_pos": 65, "type": "DATASET", "confidence": 0.8977711200714111}]}, {"text": "We use news-test2013 for tuning model combinations and news-test2015 for testing.", "labels": [], "entities": []}, {"text": "All monolingual models for the WMT task were trained on the German news2015 corpus (\u223c51.3M sentences).", "labels": [], "entities": [{"text": "WMT task", "start_pos": 31, "end_pos": 39, "type": "TASK", "confidence": 0.9169847667217255}, {"text": "German news2015 corpus", "start_pos": 60, "end_pos": 82, "type": "DATASET", "confidence": 0.9113258520762125}]}, {"text": "For PTB, we use preprocessed data by fora fair comparison (\u223c40k sentences for training).", "labels": [], "entities": [{"text": "PTB", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.6235552430152893}]}, {"text": "We evaluate using the multi-bleu.perl script for WMT and mteval-v13.pl for PTB.", "labels": [], "entities": [{"text": "WMT", "start_pos": 49, "end_pos": 52, "type": "DATASET", "confidence": 0.7372213006019592}, {"text": "PTB", "start_pos": 75, "end_pos": 78, "type": "DATASET", "confidence": 0.9628567099571228}]}], "tableCaptions": [{"text": " Table 1: German word ordering on news-test2015  with beam=12, single models/combinations. Mono- lingual models use heuristic f (\u00b7), bag2seq as a sin- gle model and bilingual models use no heuristic.", "labels": [], "entities": [{"text": "German word ordering", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.5408218105634054}]}, {"text": " Table 2: BLEU scores for PTB word-ordering task  (test). NGRAM-512 and LSTM-512 are quoted from", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9983225464820862}, {"text": "NGRAM-512", "start_pos": 58, "end_pos": 67, "type": "DATASET", "confidence": 0.8887112140655518}]}, {"text": " Table 3: BLEU scores for PTB word-ordering task  for different search heuristics and beam sizes (test).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9992246627807617}]}]}