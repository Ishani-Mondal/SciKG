{"title": [{"text": "Weighted Set-Theoretic Alignment of Comparable Sentences", "labels": [], "entities": [{"text": "Weighted Set-Theoretic Alignment of Comparable Sentences", "start_pos": 0, "end_pos": 56, "type": "TASK", "confidence": 0.7041357308626175}]}], "abstractContent": [{"text": "This article presents the STACC w system for the BUCC 2017 shared task on parallel sentence extraction from comparable corpora.", "labels": [], "entities": [{"text": "STACC w", "start_pos": 26, "end_pos": 33, "type": "METRIC", "confidence": 0.5881842076778412}, {"text": "BUCC 2017 shared task", "start_pos": 49, "end_pos": 70, "type": "DATASET", "confidence": 0.8782675266265869}, {"text": "parallel sentence extraction from comparable corpora", "start_pos": 74, "end_pos": 126, "type": "TASK", "confidence": 0.7114056547482809}]}, {"text": "The original STACC approach , based on set-theoretic operations over bags of words, had been previously shown to be efficient and portable across domains and alignment scenarios.", "labels": [], "entities": [{"text": "STACC", "start_pos": 13, "end_pos": 18, "type": "TASK", "confidence": 0.8924904465675354}]}, {"text": "We describe an extension of this approach with anew weighting scheme and show that it provides significant improvements on the datasets provided for the shared task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Parallel corpora are an essential resource for the development of multilingual natural language processing applications, in particular statistical and neural machine translation ().", "labels": [], "entities": [{"text": "statistical and neural machine translation", "start_pos": 135, "end_pos": 177, "type": "TASK", "confidence": 0.6477155566215516}]}, {"text": "Since the professional translations that are necessary to build quality bitexts are expensive and time-consuming, the exploitation of monolingual corpora that address similar topics, known as comparable corpora, has been extensively explored in the last two decades (.", "labels": [], "entities": []}, {"text": "A critical part of the process when building parallel resources from comparable data is the alignment of sentences in monolingual corpora.", "labels": [], "entities": [{"text": "alignment of sentences in monolingual corpora", "start_pos": 92, "end_pos": 137, "type": "TASK", "confidence": 0.7873371342817942}]}, {"text": "Over the years, several methods have been developed and evaluated for this task, including maximum likelihood (), suffix trees (), binary classification (), cosine similarity (), reference metrics over statistical machine translations, and feature-based approaches), among others.", "labels": [], "entities": [{"text": "binary classification", "start_pos": 131, "end_pos": 152, "type": "TASK", "confidence": 0.6900461465120316}]}, {"text": "For comparable sentence alignment, we followed the STACC approach in , which is based on seed lexical translations, simple set expansion operations and the Jaccard similarity coefficient.", "labels": [], "entities": [{"text": "sentence alignment", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.7240127921104431}]}, {"text": "This method has been shown to outperform state-of-the-art alternatives on a large range of alignment tasks and provides a simple yet effective procedure that can be applied across domains and corpora with minimal adaptation and deployment costs.", "labels": [], "entities": []}, {"text": "In this paper, we describe STACC w , an extension of the approach with a word weighting scheme, and show that it provides significant improvements on the datasets provided for the BUCC 2017 shared task, while maintaining the portability of the original approach.", "labels": [], "entities": [{"text": "STACC w", "start_pos": 27, "end_pos": 34, "type": "TASK", "confidence": 0.44258128106594086}, {"text": "BUCC 2017 shared task", "start_pos": 180, "end_pos": 201, "type": "DATASET", "confidence": 0.8659207820892334}]}], "datasetContent": [{"text": "Both STACC and STACC w require lexical translation tables to compute similarity, the only external source of information needed in this approach.", "labels": [], "entities": []}, {"text": "In previous work , GIZA tables had been created from the JRC corpora only.", "labels": [], "entities": [{"text": "JRC corpora", "start_pos": 57, "end_pos": 68, "type": "DATASET", "confidence": 0.9109064340591431}]}, {"text": "In order to extend lexical coverage, we opted fora different approach and created generic translation tables from varied corpora.", "labels": [], "entities": []}, {"text": "In each corpus, parallel sentence pairs were first sorted by increasing perplexity scores according to language models trained on the monolingual side of each parallel corpus, where the score was taken to be the mean of source and target perplexities.", "labels": [], "entities": []}, {"text": "A portion of each corpus was then selected to compose the final corpus, with an upper selection https://comparable.limsi.fr/bucc2017/bucc2017-task.html 5 There were 7 and 1 duplicates in the train and sample sets, respectively, for DE-EN, and 6 in the FR-EN train set.", "labels": [], "entities": [{"text": "DE-EN", "start_pos": 232, "end_pos": 237, "type": "DATASET", "confidence": 0.9418079257011414}, {"text": "FR-EN train set", "start_pos": 252, "end_pos": 267, "type": "DATASET", "confidence": 0.9810022910435995}]}, {"text": "bound taken to be either the median average perplexity score or the top n pairs if selecting up to median perplexity would result in over representing the corpus.", "labels": [], "entities": []}, {"text": "describes the number of sentence pairs selected for each language pair, the lexical translation tables being extracted from the GENERIC datasets.", "labels": [], "entities": [{"text": "GENERIC datasets", "start_pos": 128, "end_pos": 144, "type": "DATASET", "confidence": 0.9780573546886444}]}, {"text": "Regarding hyper-parameters, k-best lexical translations were limited to a maximum of 4 and the minimal prefix length for longest common prefix matching was set to 4.", "labels": [], "entities": []}, {"text": "Lucene indexing was based on words with length of 4 or more characters, and a maximum of 100 candidates were retrieved for each source sentence.", "labels": [], "entities": [{"text": "Lucene", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9020634293556213}]}, {"text": "For each language pair, English was set to be the target language.", "labels": [], "entities": []}, {"text": "We experimented with different values of \u03b1 to control the smoothness of the weighting function and different values for the alignment threshold th used to discard low-confidence alignments.", "labels": [], "entities": []}, {"text": "Since up to three different runs could be submitted for the task, we prepared three variants of the system, where parameters \u03b1 and th were set according to the best f-measure, precision and recall scores, respectively, obtained on the training set.", "labels": [], "entities": [{"text": "precision", "start_pos": 176, "end_pos": 185, "type": "METRIC", "confidence": 0.9991236329078674}, {"text": "recall", "start_pos": 190, "end_pos": 196, "type": "METRIC", "confidence": 0.9831860065460205}]}, {"text": "Each of these variants was submitted to the task, in order to evaluate the behaviour of our system when targeting for precision, recall and f-measure.", "labels": [], "entities": [{"text": "precision", "start_pos": 118, "end_pos": 127, "type": "METRIC", "confidence": 0.9995778203010559}, {"text": "recall", "start_pos": 129, "end_pos": 135, "type": "METRIC", "confidence": 0.99893718957901}, {"text": "f-measure", "start_pos": 140, "end_pos": 149, "type": "METRIC", "confidence": 0.9577435851097107}]}, {"text": "Although not submitted to the shared task, the original STACC method was also evaluated on the train and sample sets.", "labels": [], "entities": [{"text": "STACC", "start_pos": 56, "end_pos": 61, "type": "METRIC", "confidence": 0.5112305283546448}]}], "tableCaptions": [{"text": " Table 1: Task data statistics (number of sentences)", "labels": [], "entities": []}, {"text": " Table 2: Generic data (number of sentences)", "labels": [], "entities": []}, {"text": " Table 3: Results for DE-EN", "labels": [], "entities": [{"text": "DE-EN", "start_pos": 22, "end_pos": 27, "type": "TASK", "confidence": 0.47626885771751404}]}, {"text": " Table 4: Results for FR-EN", "labels": [], "entities": [{"text": "FR-EN", "start_pos": 22, "end_pos": 27, "type": "TASK", "confidence": 0.41599106788635254}]}]}