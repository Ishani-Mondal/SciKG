{"title": [{"text": "Transfer Learning for Speech Recognition on a Budget", "labels": [], "entities": [{"text": "Speech Recognition", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.7294798791408539}]}], "abstractContent": [{"text": "End-to-end training of automated speech recognition (ASR) systems requires massive data and compute resources.", "labels": [], "entities": [{"text": "automated speech recognition (ASR)", "start_pos": 23, "end_pos": 57, "type": "TASK", "confidence": 0.8105168143908182}]}, {"text": "We explore transfer learning based on model adaptation as an approach for training ASR models under constrained GPU memory, throughput and training data.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.9291713535785675}]}, {"text": "We conduct several systematic experiments adapting a Wav2Letter convo-lutional neural network originally trained for English ASR to the German language.", "labels": [], "entities": [{"text": "ASR", "start_pos": 125, "end_pos": 128, "type": "TASK", "confidence": 0.8168116211891174}]}, {"text": "We show that this technique allows faster training on consumer-grade resources while requiring less training data in order to achieve the same accuracy, thereby lowering the cost of training ASR models in other languages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 143, "end_pos": 151, "type": "METRIC", "confidence": 0.9982459545135498}, {"text": "ASR", "start_pos": 191, "end_pos": 194, "type": "TASK", "confidence": 0.9624160528182983}]}, {"text": "Model introspection revealed that small adaptations to the network's weights were sufficient for good performance, especially for inner layers.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automated speech recognition (ASR) is the task of translating spoken language to text in real-time.", "labels": [], "entities": [{"text": "Automated speech recognition (ASR)", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.798405647277832}]}, {"text": "Recently, end-to-end deep learning approaches have surpassed previously predominant solutions based on Hidden Markov Models.", "labels": [], "entities": []}, {"text": "In an influential paper, used convolutional neural networks (CNNs) and recurrent neural networks (RNNs) to redefine the state of the art.", "labels": [], "entities": []}, {"text": "However, also highlighted the shortcomings of the deep learning approach.", "labels": [], "entities": []}, {"text": "Performing forward and backward propagation on complex deep networks in a reasonable amount of time requires expensive specialized hardware.", "labels": [], "entities": []}, {"text": "Additionally, in order to set the large number of parameters of a deep network properly, one needs to train on large amounts of audio recordings.", "labels": [], "entities": []}, {"text": "Most of the time, the recordings need to be transcribed by hand.", "labels": [], "entities": []}, {"text": "Such data in adequate quantities is currently available for few languages other than English.", "labels": [], "entities": []}, {"text": "We propose an approach combining two methodologies to address these shortcomings.", "labels": [], "entities": []}, {"text": "Firstly, we use a simpler model with a lower resource footprint.", "labels": [], "entities": []}, {"text": "Secondly, we apply a technique called transfer learning to significantly reduce the amount of non-English training data needed to achieve competitive accuracy in an ASR task.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.9011502265930176}, {"text": "accuracy", "start_pos": 150, "end_pos": 158, "type": "METRIC", "confidence": 0.950014591217041}, {"text": "ASR task", "start_pos": 165, "end_pos": 173, "type": "TASK", "confidence": 0.9338338971138}]}, {"text": "We investigate the efficacy of this approach on the specific example of adapting a CNN-based end-to-end model originally trained on English to recognize German speech.", "labels": [], "entities": []}, {"text": "In particular, we freeze the parameters of its lower layers while retraining the upper layers on a German corpus which is smaller than its English counterpart.", "labels": [], "entities": []}, {"text": "We expect this approach to yield the following three improvements.", "labels": [], "entities": []}, {"text": "Taking advantage of the representation learned by the English model will lead to shorter training times compared to training from scratch.", "labels": [], "entities": []}, {"text": "Relatedly, the model trained using transfer learning requires less data for an equivalent score than a German-only model.", "labels": [], "entities": []}, {"text": "Finally, the more layers we freeze the fewer layers we need to back-propagate through during training.", "labels": [], "entities": []}, {"text": "Thus we expect to see a decrease in GPU memory usage since we do not have to maintain gradients for all layers.", "labels": [], "entities": []}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 gives an overview of other transfer learning approaches to ASR tasks.", "labels": [], "entities": [{"text": "ASR tasks", "start_pos": 69, "end_pos": 78, "type": "TASK", "confidence": 0.9449492990970612}]}, {"text": "Details about our implementation of the Wav2Letter model and how we trained it can be found in Section 3.", "labels": [], "entities": []}, {"text": "The data we used and how we preprocessed it is described in Section 4.", "labels": [], "entities": []}, {"text": "After a short introduction of the performed experiments in Section 5 we present and discuss the results in Section 6 followed by a conclusion in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "For training the English model, we used the LibriSpeech corpus (.", "labels": [], "entities": [{"text": "LibriSpeech corpus", "start_pos": 44, "end_pos": 62, "type": "DATASET", "confidence": 0.9638182520866394}]}, {"text": "This dataset consists of about 1000 hours of read speech, sampled at 16 kHz, from the domain of audio books.", "labels": [], "entities": []}, {"text": "This is the same dataset that was used to train the original Wav2Letter model.", "labels": [], "entities": []}, {"text": "The German models were trained on several corpora taken from the Bavarian Archive for Speech Signals (BAS) as well as the dataset described in, which will be referred to as \"RADECK\" from now on.", "labels": [], "entities": [{"text": "Bavarian Archive for Speech Signals (BAS)", "start_pos": 65, "end_pos": 106, "type": "DATASET", "confidence": 0.9261711463332176}, {"text": "RADECK", "start_pos": 174, "end_pos": 180, "type": "METRIC", "confidence": 0.8730483055114746}]}, {"text": "Overall, we had a total of 383 hours of training data, which is only slightly more than one third of the English corpus.", "labels": [], "entities": [{"text": "English corpus", "start_pos": 105, "end_pos": 119, "type": "DATASET", "confidence": 0.9395515620708466}]}, {"text": "Additional quantitative information regarding each corpus, as well as any available references, is given in.", "labels": [], "entities": []}, {"text": "Information about the kind of recording contained in each corpus is given in.", "labels": [], "entities": []}, {"text": "It is also important to point out that some of the corpora pose additional challenges for speech recognition like partially intoxicated people, recordings over telephone, and different dialects.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 90, "end_pos": 108, "type": "TASK", "confidence": 0.7412270307540894}]}, {"text": "Each German corpus was split into training and test sets.", "labels": [], "entities": [{"text": "German corpus", "start_pos": 5, "end_pos": 18, "type": "DATASET", "confidence": 0.762730062007904}]}, {"text": "We grouped the audio by speakers and used 10% of the groups for testing.", "labels": [], "entities": []}, {"text": "Therefore, no speaker appears in both training and test set ensuring that results are not due to overfitting to certain speakers.", "labels": [], "entities": []}, {"text": "Exceptions to this procedure are: The VM corpora, which were used exclusively for training because obtaining a split based on speakers was not trivial here; SC10, which was used only for testing because it consists of recordings of speakers with German as a second language and strong foreign accents with only 5.8 hours in size; and RADECK, where we used the original splits.", "labels": [], "entities": [{"text": "RADECK", "start_pos": 334, "end_pos": 340, "type": "METRIC", "confidence": 0.6125532388687134}]}, {"text": "We also rely on text corpora for the KenLM decoding step.", "labels": [], "entities": [{"text": "KenLM decoding", "start_pos": 37, "end_pos": 51, "type": "TASK", "confidence": 0.8258765935897827}]}, {"text": "For the English corpus (, the provided 4-gram model based on all training transcriptions was used like in the original Wav2Letter implementation.", "labels": [], "entities": []}, {"text": "For the German corpus, our n-gram model came from a preprocessed version of the German Wikipedia, the European Parliament Proceedings Parallel Corpus 1 , and all the training transcriptions.", "labels": [], "entities": [{"text": "German corpus", "start_pos": 8, "end_pos": 21, "type": "DATASET", "confidence": 0.822816789150238}, {"text": "European Parliament Proceedings Parallel Corpus 1", "start_pos": 102, "end_pos": 151, "type": "DATASET", "confidence": 0.8614517251650492}]}, {"text": "Validation and test sets were carefully excluded.", "labels": [], "entities": [{"text": "Validation", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.7962046265602112}]}, {"text": "Given the English model, we froze k of the lower layers and trained all 11 \u2212 k layers above with the German corpora.", "labels": [], "entities": []}, {"text": "This means the gradient was only calculated for the weights of those 11\u2212k layers and gradient descent was then applied to update those as usual.", "labels": [], "entities": []}, {"text": "The process of freezing k layers is visualized in.", "labels": [], "entities": []}, {"text": "The transfer training was performed based on both the original weights as well as anew random initialization for comparison.", "labels": [], "entities": []}, {"text": "Except for changing the training data, the German corpora introduce four new class labels\u00e4\u00f6\u00fc\u00dflabels\u00a8labels\u00e4\u00f6\u00fc\u00df in addition to the original 28 labels.", "labels": [], "entities": []}, {"text": "We set the initial weights and biases of the final softmax layer for these labels to zero.", "labels": [], "entities": []}, {"text": "Additionally, as a baseline for the performance of a Wav2Letter based German ASR, we trained one model from scratch on all German training corpora.", "labels": [], "entities": []}, {"text": "For all experiments we used a batch size of 64, both during training as well as evaluation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Quantitative information on the corpora used to train the German model. References to individual  corpora are given where available. Size and number of speakers refer only to the subsets we used (including  training and test sets). Test set LER and WER are reported for the best transfer learning (TL) model and the  model from scratch (S) after 103h of training.", "labels": [], "entities": [{"text": "WER", "start_pos": 259, "end_pos": 262, "type": "METRIC", "confidence": 0.987877368927002}]}]}