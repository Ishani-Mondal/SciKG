{"title": [{"text": "A Geometric Method for Detecting Semantic Coercion", "labels": [], "entities": [{"text": "Detecting Semantic Coercion", "start_pos": 23, "end_pos": 50, "type": "TASK", "confidence": 0.8618387579917908}]}], "abstractContent": [{"text": "In this paper we present state-of-the-art results on the computational classification of semantic type coercion, accomplished using a novel geometric method which is both context-sensitive and generalisable.", "labels": [], "entities": [{"text": "computational classification of semantic type coercion", "start_pos": 57, "end_pos": 111, "type": "TASK", "confidence": 0.7560003697872162}]}, {"text": "We show that this method improves accuracy on a SemEval dataset over previous work, and gives promising results on anew more challenging experimental setup involving the same data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9985690116882324}, {"text": "SemEval dataset", "start_pos": 48, "end_pos": 63, "type": "DATASET", "confidence": 0.8224057555198669}]}, {"text": "In addition to a description of our distributional semantic methodology and the results obtained on an established dataset, we offer an overview of the linguistic phenomenon of coercion and an analysis of the geometric features by which our results are achieved.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "We train a model for the identification of coercion based on a logistic regression of features of the subspaces described in the previous section.", "labels": [], "entities": [{"text": "identification of coercion", "start_pos": 25, "end_pos": 51, "type": "TASK", "confidence": 0.852276066939036}]}, {"text": "We generate JOINT, INDY, and ZIPPED type subspaces for each verb-object pair in the training portion of the dataset described in Section 2 (, extracting the 16 geometric features identified in Section 3, illustrated in, and enumerated again in in Section 5.", "labels": [], "entities": [{"text": "INDY", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.8930310606956482}]}, {"text": "We also experiment with three other feature extraction techniques: Verb Select only the k co-occurrence dimensions with the highest values for the verb's word-vector; Object Select only the k co-occurrence dimensions with the highest value for the object's word-vector; Merged Take the average feature values for the VERB and OBJECT methods.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.7922480404376984}]}, {"text": "In the case of each subspace selection technique, we generate a 993 x 16 matrix, expressing 16 geometric features for each sentence in the training data (38 examples were withheld because the targeted argument was a multi-word token, and at this point our model has only been trained for single words).", "labels": [], "entities": [{"text": "subspace selection", "start_pos": 20, "end_pos": 38, "type": "TASK", "confidence": 0.7203189432621002}]}, {"text": "We perform mean-zero, std-one normalisation on this matrix, and then perform a logistic regression trained to classify selectionality versus coerciveness.", "labels": [], "entities": []}, {"text": "We apply L2 regularisation to the regression coefficients, with a relatively strong regularisation strength of 1.67, determined experimentally.", "labels": [], "entities": []}, {"text": "We then similarly extract data from the testing data (here 40 examples are withheld), in this case, crucially, normalising the data reusing the mean and standard deviation from the training data in order to test the generality of this method and our ability to apply it arbitrarily to any given input.", "labels": [], "entities": []}, {"text": "We apply the model learned from the training data to the normalised test matrix, evaluating each verb-object pair as either coercive or non-coercive.", "labels": [], "entities": []}, {"text": "We experiment with models based on co-occurrence windows of both 2 and 5 words on either side of a vocabulary word as observed in the underlying corpus (Wikipedia), and with projected subspaces consisting of 20 and 200 dimensions.", "labels": [], "entities": []}, {"text": "Results for these experiments are reported in, with the 200 dimensional subspaces outperforming the 20 dimensional subspaces across the board, and the 5x5 word co-occurrence window models generally doing better, but only slightly better, than the 2x2 window models.", "labels": [], "entities": []}, {"text": "The INDY subspace selection technique outperforms all other techniques, and its strong performance is particularly pronounced in terms of f-scores, indicating that this method, in addition to learning that most instance of word-pairs are not coercive, is also learning something about when to positively indicate coercion.", "labels": [], "entities": [{"text": "INDY subspace selection", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.6884482304255167}]}, {"text": "The stronger performance of higher dimensional spaces suggests that significant information is available across a wider We implement the regression using the scikit-learn LogisticRegression module for python.: F-score/accuracy results for coercion classification using various subspace selection techniques, adjusting parameters for co-occurrence window size (2x2 and 5x5) and subspace dimensionality.", "labels": [], "entities": [{"text": "F-score", "start_pos": 210, "end_pos": 217, "type": "METRIC", "confidence": 0.9960829019546509}, {"text": "accuracy", "start_pos": 218, "end_pos": 226, "type": "METRIC", "confidence": 0.8444363474845886}, {"text": "coercion classification", "start_pos": 239, "end_pos": 262, "type": "TASK", "confidence": 0.7332591414451599}]}, {"text": "Baseline scores and scores from other studies are reported in range of co-occurrence profiles fora given target word, and inclusion of this information is desirable, but it's also interesting to note this dimensional gain deteriorates for smaller co-occurrence windows as information in our base matrix becomes sparser.", "labels": [], "entities": []}, {"text": "We use the top performing 5x5 co-occurrence window, 200 dimensional subspaces in the rest of our experiments below.", "labels": [], "entities": []}, {"text": "In order to test the hypothesis that coercion is always ultimately contextually determined, we add information about the sentential context of the examples provided in the data.", "labels": [], "entities": []}, {"text": "We do this by parsing each sentence in the data and then creating two additional sets of features: we generate new subspaces based on the other words in the sentence, and then extract features of the verb/object vector geometry as above; we do this first using only content words (other verbs, nouns, adjectives, and adverbs in the sentence), and then using only function words.", "labels": [], "entities": []}, {"text": "We extract the geometric features from these spaces as described above, normalise them, and then concatenate them with the original features extracted using the corresponding technique.", "labels": [], "entities": []}, {"text": "In the rare instances where no appropriate sentential analysis is available, we concatenate a feature vector of zeros, reasoning that, given the application of zero-mean normalisation, this should have relatively little impact on our model while maintaining the shape of the data.", "labels": [], "entities": []}, {"text": "Results for the logistic regression experiment run on this enhanced data are reported in.", "labels": [], "entities": []}, {"text": "The results from the INDY type space in particular are notable in that they outperform a number of other methods which we will now describe, and moreover return an improvement inaccuracy on the non-contextual results of 0.014 and in f-score of 0.021.", "labels": [], "entities": [{"text": "INDY type space", "start_pos": 21, "end_pos": 36, "type": "DATASET", "confidence": 0.7881105740865072}, {"text": "f-score", "start_pos": 233, "end_pos": 240, "type": "METRIC", "confidence": 0.9855162501335144}]}, {"text": "More generally, while accuracy scores don't admit significant improvement, f-scores are generally up in the range of about 0.040 points, indicating a particular increase in the models' abilities to detect coercion with increased contextual data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9988617897033691}]}, {"text": "We report a minority class baseline where all verb-object pairs are classified as coercive and a majority class where all are considered non-coercive.", "labels": [], "entities": []}, {"text": "We also test an example based learning method in which we learn a single rule for each surface form of the five verb stems found in the data, and discover that fairly good results can be achieved by simply assuming a given verb is either coercive or not.", "labels": [], "entities": []}, {"text": "(In practice, all verbs other than finish are observed to be typically non-coercive in the training data.)", "labels": [], "entities": [{"text": "finish", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9641302227973938}]}, {"text": "Because many of the objects also occur multiple times in both the training and testing data, we can learn an object-based rule for guessing coercion, resorting to the verb-based rule in cases where we encounter an object which hasn't been observed in the training data.", "labels": [], "entities": []}, {"text": "The very strong results achieved using this method, designated EBL* in, which take tagged observations of word combinations into account, can bethought of as something of a ceiling for models such as ours: where the EBL and EBL* methods learn to predict semantic relationships between priorly observed words based on the actual identity of the words, our method simply learns something about the geometry that indicates a particular semantic relationship.", "labels": [], "entities": []}, {"text": "We also report results from two models defined by static lexical representations: a principle component model built using singular value decomposition, 7 and a model constructed using the skip-gram methodology described by.", "labels": [], "entities": []}, {"text": "In the case of the former, we factorised our 5x5 word co-occurrence window base space and extrapolated a 200 dimensional matrix in which each dimension is orthogonal, capturing an optimal degree of variance between word-vectors (see, fora classic overview of this approach).", "labels": [], "entities": []}, {"text": "For the latter, we built a likewise 200 dimensional space of word-vectors derived over 10 traversals of our corpus, applying negative sampling at a rate of: Coercion identification scores on test data, based on a logistic regression on various dimension selection techniques in a 5x5 word co-occurrence window, 200 dimensional model built from training data, as well as scores for baselines.", "labels": [], "entities": [{"text": "Coercion identification", "start_pos": 157, "end_pos": 180, "type": "TASK", "confidence": 0.6728893220424652}]}, {"text": "Methods using information about the identity of words priorly observed in selectional or coercive relationships are reported in italics.", "labels": [], "entities": []}, {"text": "both cases, we consider cosine distance between the word-vectors in the spaces as the singular metric of relationships between words, inline with results reported through the NLP literature.", "labels": [], "entities": []}, {"text": "The method described by Roberts and Harabagiu (2010) learns classes for nouns based on analysis of entailment relationships within WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 131, "end_pos": 138, "type": "DATASET", "confidence": 0.9547225832939148}]}, {"text": "Combined with a statistical analysis of word and named entity co-occurrences, this approach essentially seeks to recapitulate the semantic class information available in knowledge bases in order to identify instances where coercion is indicated by verb-object class mismatches.", "labels": [], "entities": []}, {"text": "We take as our main point of comparison the results reported on this dataset by, who develop a probabilistic model for coercion detection based within the latent Dirichlet allocation paradigm (.", "labels": [], "entities": [{"text": "coercion detection", "start_pos": 119, "end_pos": 137, "type": "TASK", "confidence": 0.7457010746002197}]}, {"text": "In this later work the authors establish probability distributions for classes that can betaken as an argument by a verb V , and likewise for classes that can be assigned to an object N , and then calculate the summation of the joint probabilities of V taking a word of the same class as N as an argument, learning a threshold below which the value of this summation indicates coercion.", "labels": [], "entities": []}, {"text": "The distributions themselves are learned through observations of predicate-argument pairings in a large-scale textual corpus, and so one might argue that here, again, there is an element of example based learning.", "labels": [], "entities": []}, {"text": "To briefly compare our different dimension selection techniques, the INDY technique seems to do the best job of capturing the semantic interaction between verb-object pair under analysis: the way that these terms intermingle across independently salient co-occurrence dimensions is most predictive of the alignment of semantic classes, while delineating subspaces based on joint or semi-joint co-occurrence profiles through the JOINT and ZIPPED techniques is less informative.", "labels": [], "entities": [{"text": "JOINT", "start_pos": 428, "end_pos": 433, "type": "DATASET", "confidence": 0.8546730279922485}]}, {"text": "In general the tendency towards stronger precision versus recall results indicates a tendency of our regression model to learn caution in predicting the minority class, an observation which may indicate future directions for experimenting with modelling techniques.", "labels": [], "entities": [{"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9982665777206421}, {"text": "recall", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.9978753328323364}]}, {"text": "It's also interesting to note that the VERB technique, focusing on the cooccurrence profile of the predicate in a sentence, outperforms the argument-oriented OBJECT technique, arguably supporting the hypothesis outlined in Section 2 that certain verbs tend to be more coercive than others.", "labels": [], "entities": [{"text": "VERB", "start_pos": 39, "end_pos": 43, "type": "METRIC", "confidence": 0.9270933866500854}]}, {"text": "In terms of comparison with results from elsewhere, we significantly outperform baselines and event the EBL technique on all counts, and do slightly better than Roberts and Harabagiu (2011) on accuracy (f-scores weren't provided by those authors).", "labels": [], "entities": [{"text": "EBL", "start_pos": 104, "end_pos": 107, "type": "METRIC", "confidence": 0.9298567771911621}, {"text": "accuracy", "start_pos": 193, "end_pos": 201, "type": "METRIC", "confidence": 0.9995808005332947}]}, {"text": "In terms of comparing with the fully recorded statistics for the abstract distributional approaches, it is interesting to note that, like with our context sensitive models, the static models also achieve higher precision than recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 211, "end_pos": 220, "type": "METRIC", "confidence": 0.9980795383453369}, {"text": "recall", "start_pos": 226, "end_pos": 232, "type": "METRIC", "confidence": 0.9951586127281189}]}, {"text": "In fact, the effect is even more obvious here, leading to relatively low f-scores as lower recall drags down the harmonic mean of model performance: combined with fairly high accuracy scores, this suggests that these models are learning a conservative strategy of favouring the more likely classification of selection over coercion.", "labels": [], "entities": [{"text": "recall", "start_pos": 91, "end_pos": 97, "type": "METRIC", "confidence": 0.9974773526191711}, {"text": "accuracy", "start_pos": 175, "end_pos": 183, "type": "METRIC", "confidence": 0.996968686580658}]}, {"text": "Regardless, the results of our experiment present context sensitive approaches in a relatively favourable light compared to two other general approaches to lexical semantic modelling.", "labels": [], "entities": [{"text": "lexical semantic modelling", "start_pos": 156, "end_pos": 182, "type": "TASK", "confidence": 0.729544997215271}]}, {"text": "Testing on Unseen Examples In order to test the generalisability of our approach, we reshuffled the data in such away that the model could be trained on one set of verb-object pairs and then could be tested on a different set of word pairs where neither the verbs nor the objects had been observed in any of the pairings throughout the training data.", "labels": [], "entities": []}, {"text": "The new arrangement of the data would be uninterpretable to the EBL techniques and the method of Roberts and Harabagiu, all of which rely on prior observations of the words being analysed tagged for either selection or coercion.", "labels": [], "entities": []}, {"text": "We found that by taking all objects paired with forms of the verbs arrive, cancel, and deny that weren't also paired with forms of the verbs finish and hear as training data, and then considering all pairings involving cancel and deny as test data, we could reshuffle the data such that we have 895 training sentences, 191 of which are instances of coercion, and 865 test sentences, 355 of which are instances of coercion.", "labels": [], "entities": []}, {"text": "In order to maintain the generality of our results, we once again normalise the test data based on the mean and standard deviation of the training data.", "labels": [], "entities": []}, {"text": "Results for this version of the test are reported in.", "labels": [], "entities": []}, {"text": "Accuracy scores are affected negatively by this data reshuffling, though this decrease should be understood in the context of the new balance of noncoercion and coercion in the data, likewise reflected in the new baselines-and in fact the improvement from our method over the majority class accuracy score is at least as substantial here.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9938406944274902}, {"text": "accuracy score", "start_pos": 291, "end_pos": 305, "type": "METRIC", "confidence": 0.9460918009281158}]}, {"text": "More notably, f-scores are also negatively impacted, but the effect here is considerably more marginal.", "labels": [], "entities": []}, {"text": "From this we can infer that, in the case of classifying data on completely unseen word pairs, the model to some extent learns to usually err on the side of guessing for the majority class of argument type selection over coercion, but the gains in identifying coercion over the minority class baseline are still significant, and accuracy is likewise substantially improved from both baselines.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 328, "end_pos": 336, "type": "METRIC", "confidence": 0.9993940591812134}]}, {"text": "In other words, in the case of the INDY subspace projection technique, the model seems to generalise very nicely.", "labels": [], "entities": [{"text": "INDY subspace projection", "start_pos": 35, "end_pos": 59, "type": "TASK", "confidence": 0.6500905056794485}]}, {"text": "presents the coefficients corresponding to geometric features learned by our logistic regression on the 5x5 co-occurrence window, 200 dimensional projections using the INDY method to analyse verbobject pair input, in this case without taking sentential context into account, as concatenating different contexts would complicate the visual analysis of the geometry of the subspace.", "labels": [], "entities": [{"text": "INDY", "start_pos": 168, "end_pos": 172, "type": "METRIC", "confidence": 0.7189363241195679}]}, {"text": "An examination of these coefficients reveals the geometric tendencies that correspond to the slide from selection to coercion.", "labels": [], "entities": []}, {"text": "One interesting outcome of the projection of coercion classification onto a logistic curve is the implication that coercion is a gradable as opposed to a binary phenomenon, something which is not necessarily taken for granted in the theoretical literature.", "labels": [], "entities": [{"text": "projection of coercion classification", "start_pos": 31, "end_pos": 68, "type": "TASK", "confidence": 0.6504830792546272}]}, {"text": "Our regression is modelled to associate coercion with positive values and selection with negative values, so a positive coefficient indicates a positive correlation with the tendency towards coercion in a given subspace.", "labels": [], "entities": []}, {"text": "The angular values used in the model are cosines, so a positive correlation here indicates a move towards coercion as the angle between two vectors becomes smaller.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Coercion Shifts in the English SemEval data set", "labels": [], "entities": [{"text": "Coercion Shifts", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.7904990911483765}, {"text": "English SemEval data set", "start_pos": 33, "end_pos": 57, "type": "DATASET", "confidence": 0.8248257040977478}]}, {"text": " Table 2: F-score/accuracy results for coercion classification using various subspace selection techniques,  adjusting parameters for co-occurrence window size (2x2 and 5x5) and subspace dimensionality (20 and  200). Baseline scores and scores from other studies are reported in", "labels": [], "entities": [{"text": "F-score", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9974073767662048}, {"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9311656951904297}, {"text": "coercion classification", "start_pos": 39, "end_pos": 62, "type": "TASK", "confidence": 0.7751429677009583}]}, {"text": " Table 3: Coercion identification scores on test data, based on a logistic regression on various dimension  selection techniques in a 5x5 word co-occurrence window, 200 dimensional model built from training  data, as well as scores for baselines. Methods using information about the identity of words priorly  observed in selectional or coercive relationships are reported in italics.", "labels": [], "entities": [{"text": "Coercion identification", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.8733847737312317}]}, {"text": " Table 4: Coercion identification scores based on a logistic regression on the INDY selection technique  in a 5x5 word co-occurrence window, 200 dimensional model, as well as scores for baselines, when the  model was tested on words which were never seen in the training phase.", "labels": [], "entities": [{"text": "Coercion identification", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.8502070903778076}]}, {"text": " Table 5: Coefficients assigned to various geometric features based on a logistic regression of a 5x5 word  co-occurrence window, 200 dimensional INDY type space.", "labels": [], "entities": []}]}