{"title": [{"text": "Contextual Hyperedge Replacement Grammars for Abstract Meaning Representations", "labels": [], "entities": [{"text": "Contextual Hyperedge Replacement Grammars", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.6992313861846924}, {"text": "Abstract Meaning Representations", "start_pos": 46, "end_pos": 78, "type": "TASK", "confidence": 0.6395909090836843}]}], "abstractContent": [{"text": "We show how contextual hyperedge replacement grammars can be used to generate abstract meaning representations (AMRs), and argue that they are more suitable for this purpose than hyperedge replacement grammars.", "labels": [], "entities": [{"text": "contextual hyperedge replacement grammars", "start_pos": 12, "end_pos": 53, "type": "TASK", "confidence": 0.6872343420982361}]}, {"text": "Contextual hyper-edge replacement turns out to have two advantages over plain hyperedge replacement: it can completely cover the language of all AMRs over a given domain of concepts, and at the same time its grammars become both smaller and simpler.", "labels": [], "entities": [{"text": "Contextual hyper-edge replacement", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.6666923960049947}, {"text": "plain hyperedge replacement", "start_pos": 72, "end_pos": 99, "type": "TASK", "confidence": 0.7004784742991129}]}], "introductionContent": [{"text": "Natural language processing applications that receive sentences as input mainly make use of lexical and syntactic properties of the input sentences.", "labels": [], "entities": []}, {"text": "Even though these properties are an important basis for the analysis of a sentence, one is usually more interested in the meaning of a sentence, i.e., its semantics.", "labels": [], "entities": []}, {"text": "This is particularly true in the case of machine translation where a semantic error can cause far more bewilderment than a syntactic one.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.7771051824092865}]}, {"text": "Thus, a general-purpose formalism for modelling the semantics of sentences in away that allows for efficient analysis would be widely useful in natural language processing.", "labels": [], "entities": []}, {"text": "This study focuses on the generation of a semantic representation that was proposed some years ago, the abstract meaning representation (AMR)).", "labels": [], "entities": [{"text": "abstract meaning representation (AMR))", "start_pos": 104, "end_pos": 142, "type": "TASK", "confidence": 0.7166174054145813}]}, {"text": "An AMR 1 is a directed, rooted, acyclic, nodeand edge-labelled graph that represents the se-mantics of an English sentence ; the nodes and edges represent concepts and their relations, respectively.", "labels": [], "entities": []}, {"text": "A corpus of AMRs over a limited domain can be found in ().", "labels": [], "entities": []}, {"text": "As in the case of syntax trees, where tree grammars and tree automata) provide a model for distinguishing structurally correct trees from incorrect ones, the algorithmic processing of AMRs would benefit from the existence of appropriate formal models for their generation or recognition.", "labels": [], "entities": [{"text": "generation or recognition", "start_pos": 261, "end_pos": 286, "type": "TASK", "confidence": 0.6323318680127462}]}, {"text": "Here, we focus on the generation of AMRs by graph grammars, which have previously been proposed as formal models for this very task.", "labels": [], "entities": [{"text": "generation of AMRs", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.6038393378257751}]}, {"text": "The usefulness of two types of hyperedge replacement grammar;) for AMR generation was investigated by (see also), namely the predictive top-down (PTD) parsable grammar ( ) and the restricted directed acyclic graph (rDAG) grammar.", "labels": [], "entities": [{"text": "hyperedge replacement grammar", "start_pos": 31, "end_pos": 60, "type": "TASK", "confidence": 0.8241947094599406}, {"text": "AMR generation", "start_pos": 67, "end_pos": 81, "type": "TASK", "confidence": 0.9927865564823151}, {"text": "predictive top-down (PTD) parsable grammar", "start_pos": 125, "end_pos": 167, "type": "TASK", "confidence": 0.6232129335403442}]}, {"text": "Both are of particular interest because their study was, among other possible application areas, motivated by AMR generation.", "labels": [], "entities": [{"text": "AMR generation", "start_pos": 110, "end_pos": 124, "type": "TASK", "confidence": 0.9736250042915344}]}, {"text": "A specific advantage of these special cases of HRGs is that their membership problem is solvable in polynomial time.", "labels": [], "entities": []}, {"text": "concludes that neither of them is able to generate the complete set of AMRs over a given concept domain.", "labels": [], "entities": []}, {"text": "Unrestricted HRGs allow for better coverage at the expense of greater computational complexity.", "labels": [], "entities": []}, {"text": "However, a general disadvantage of hyperedge replacement remains.", "labels": [], "entities": [{"text": "hyperedge replacement", "start_pos": 35, "end_pos": 56, "type": "TASK", "confidence": 0.777932196855545}]}, {"text": "The nonterminal items in an HRG are hyperedges -edges that maybe attached to more (or fewer) than two nodes.", "labels": [], "entities": []}, {"text": "Replacement of a hyperedge inserts anew subgraph in its place, connecting it to the host graph via the nodes the replaced hyperedge was incident on.", "labels": [], "entities": []}, {"text": "Intuitively, nonterminal hyperedges keep track of a number of potentially relevant nodes for the purpose of being able to attach new edges to them later on in the derivation.", "labels": [], "entities": []}, {"text": "This process is well known (and easily seen) to generate graph languages of bounded treewidth.", "labels": [], "entities": []}, {"text": "As shall be illustrated in Section 6 the ability of hyperedges to keep track of a bounded number of previously generated nodes can be used to ensure structural properties such as those caused by control verbs.", "labels": [], "entities": []}, {"text": "However, it appears that other types of reentrancies, like those arising from the use of pronouns, are of a different nature.", "labels": [], "entities": []}, {"text": "If, for example, several instances of the concept boy have been generated, any of them can in principle be referred to from anywhere else in the AMR.", "labels": [], "entities": [{"text": "AMR", "start_pos": 145, "end_pos": 148, "type": "DATASET", "confidence": 0.9052145481109619}]}, {"text": "As a consequence, there is no reasonable a priori bound on the treewidth of the graph.", "labels": [], "entities": []}, {"text": "Nonterminal hyperedges generating other parts of the AMR would have to keep track of all boy instances to accomplish full coverage.", "labels": [], "entities": [{"text": "AMR", "start_pos": 53, "end_pos": 56, "type": "DATASET", "confidence": 0.834007203578949}]}, {"text": "On the one hand, this is not possible in an HRG.", "labels": [], "entities": []}, {"text": "On the other hand, it does not seem to be desirable either, because keeping track of every boy instance individually would enable a level of control far beyond what is needed.", "labels": [], "entities": []}, {"text": "Here we consider contextual hyperedge replacement grammars (CHRGs) () to learn whether they can be used to overcome these disadvantages.", "labels": [], "entities": [{"text": "contextual hyperedge replacement grammars (CHRGs)", "start_pos": 17, "end_pos": 66, "type": "TASK", "confidence": 0.7567547559738159}]}, {"text": "CHRGs are also based on hyperedge replacement, but the left-hand side of a rule can contain socalled contextual nodes.", "labels": [], "entities": [{"text": "hyperedge replacement", "start_pos": 24, "end_pos": 45, "type": "TASK", "confidence": 0.7626142203807831}]}, {"text": "This provides access to nodes other than those immediately controlled by the nonterminal hyperedge, thus enabling rules to establish connections of the type discussed in the previous paragraph.", "labels": [], "entities": []}, {"text": "The additional ability is severely limited, far below true context-sensitivity in power, because nodes are terminal items and derivation steps cannot distinguish between contextual nodes with the same label.", "labels": [], "entities": []}, {"text": "For instance, in the situation sketched above a rule application would just pick any occurrence of boy elsewhere in the host graph.", "labels": [], "entities": []}, {"text": "As a consequence, however, the treewidth of generated graphs is not necessarily bounded anymore.", "labels": [], "entities": []}, {"text": "In the present paper we study and illustrate the advantages of CHRGs over HRGs for AMR generation by looking at an example concept domain in a theoretical case study.", "labels": [], "entities": [{"text": "AMR generation", "start_pos": 83, "end_pos": 97, "type": "TASK", "confidence": 0.9871809780597687}]}, {"text": "To this end, we build a CHRG that generates AMRs over a restricted domain and argue that it exhibits perfect coverage.", "labels": [], "entities": []}, {"text": "The baseline domain is the one introduced by, consisting of the concepts boy, girl, want and believe along with two basic relations (called arg0 and arg1) that are used to bind the concepts together and correspond to the agent and patient of a want or believe event.", "labels": [], "entities": [{"text": "arg0", "start_pos": 140, "end_pos": 144, "type": "METRIC", "confidence": 0.9846503138542175}, {"text": "arg1", "start_pos": 149, "end_pos": 153, "type": "METRIC", "confidence": 0.8361172676086426}]}, {"text": "We also consider the construction of CHRGs for more general AMRs to explore the advantages of the more generous rule format.", "labels": [], "entities": []}, {"text": "Therefore we add a small set of possible modifiers, allow an arbitrary number of boys and girls to appear in an AMR, and discuss how to handle control verbs.", "labels": [], "entities": []}, {"text": "The conclusion of our study is that contextual hyperedge replacement is indeed a promising formalism for describing sets of AMRs.", "labels": [], "entities": [{"text": "contextual hyperedge replacement", "start_pos": 36, "end_pos": 68, "type": "TASK", "confidence": 0.6137019693851471}]}, {"text": "On the one hand, AMRs contain the mentioned local structures that must satisfy certain well-formedness constraints, such as in the case of control verbs.", "labels": [], "entities": []}, {"text": "This can be implemented like it would in an HRG, using a nonterminal hyperedge to keep track of the involved nodes.", "labels": [], "entities": []}, {"text": "On the other hand, contextual nodes can be used to implement the kinds of coreferences which may occur anywhere without following strict local rules, such as those relating to the use of pronouns.", "labels": [], "entities": []}, {"text": "As discussed above, the latter creates problems in HRGs because nonterminal hyperedges would have to keep track of potential antecedents, which seems inappropriate for various reasons: it is restricted by the rank of hyperedges, provides an unnecessarily detailed level of control (thus creating the risk of overfitting), and leads to a huge number of rules to account explicitly for all the possible nondeterministic choices arising from the (exponentially) many ways in which coreferences can be inserted.", "labels": [], "entities": []}, {"text": "The obvious downside of using CHRGs is that computational problems may potentially become more difficult.", "labels": [], "entities": []}, {"text": "However, recent results on shift-reduce parsing for both HRGs and CHRGs ( indicate that this may not be the case.", "labels": [], "entities": []}, {"text": "In fact, as the rank of hyperedges and the number of rules are central parameters in the complexity of membership algorithms for both unrestricted HRGs and CHRGs, it may even payoff to turn to CHRGs since this leads to smaller ranks and much fewer rules, the latter because the use of contextual nodes removes the necessity to implement nondeterministic choices explicitly by creating a separate rule for each.", "labels": [], "entities": []}, {"text": "In Section 2, we lay the ground for the rest of the paper with some basic definitions.", "labels": [], "entities": []}, {"text": "The CHRG is defined in Section 3, and the subset of AMR to be considered here is discussed in Section 4.", "labels": [], "entities": [{"text": "CHRG", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.8205114603042603}]}, {"text": "The construction of a CHRG for this domain is described in Section 5.", "labels": [], "entities": []}, {"text": "In Section 6, we indicate how to generalise it to larger domains, and in particular how control verbs can be added.", "labels": [], "entities": []}, {"text": "Finally, the results are discussed in Section 7 followed by the conclusions and future work in Section 8.", "labels": [], "entities": []}, {"text": "Acknowledgement We thank the reviewers for useful comments that helped us clarify the line of argumentation (as we hope).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}