{"title": [{"text": "Beyond Bilingual: Multi-sense Word Embeddings using Multilingual Context", "labels": [], "entities": []}], "abstractContent": [{"text": "Word embeddings, which represent a word as a point in a vector space, have become ubiquitous to several NLP tasks.", "labels": [], "entities": []}, {"text": "A recent line of work uses bilingual (two languages) corpora to learn a different vector for each sense of a word, by exploiting crosslingual signals to aid sense identification.", "labels": [], "entities": [{"text": "sense identification", "start_pos": 157, "end_pos": 177, "type": "TASK", "confidence": 0.7269973158836365}]}, {"text": "We present a multi-view Bayesian non-parametric algorithm which improves multi-sense word embeddings by (a) using multilingual (i.e., more than two languages) corpora to significantly improve sense embeddings beyond what one achieves with bilingual information, and (b) uses a principled approach to learn a variable number of senses per word, in a data-driven manner.", "labels": [], "entities": []}, {"text": "Ours is the first approach with the ability to leverage multilingual corpora efficiently for multi-sense representation learning.", "labels": [], "entities": [{"text": "multi-sense representation learning", "start_pos": 93, "end_pos": 128, "type": "TASK", "confidence": 0.7917617559432983}]}, {"text": "Experiments show that multilingual training significantly improves performance over monolingual and bilingual training, by allowing us to combine different parallel corpora to leverage multilingual context.", "labels": [], "entities": []}, {"text": "Multilingual training yields comparable performance to a state of the art mono-lingual model trained on five times more training data.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word embeddings (, inter alia) represent a word as a point in a vector space.", "labels": [], "entities": []}, {"text": "This space is able to capture semantic relationships: vectors of words with similar meanings have high cosine similarity).", "labels": [], "entities": []}, {"text": "Use of embeddings as features has been shown to benefit several NLP tasks and serve as good initializations for deep architectures ranging from dependency parsing () to named entity recognition (.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 144, "end_pos": 162, "type": "TASK", "confidence": 0.7743598818778992}, {"text": "named entity recognition", "start_pos": 169, "end_pos": 193, "type": "TASK", "confidence": 0.6044100721677145}]}, {"text": "Although these representations are now ubiquitous in NLP, most algorithms for learning wordembeddings do not allow a word to have different meanings in different contexts, a phenomenon known as polysemy.", "labels": [], "entities": []}, {"text": "For example, the word bank assumes different meanings in financial (eg. \"bank pays interest\") and geographical contexts (eg. \"river bank\") and which cannot be represented adequately with a single embedding vector.", "labels": [], "entities": []}, {"text": "Unfortunately, there are no large sense-tagged corpora available and such polysemy must be inferred from the data during the embedding process.", "labels": [], "entities": []}, {"text": "My interest lies in History.", "labels": [], "entities": []}, {"text": "Several attempts have been made to infer multi-sense word representations by modeling the sense as a latent variable in a Bayesian non-parametric framework.", "labels": [], "entities": [{"text": "multi-sense word representations", "start_pos": 41, "end_pos": 73, "type": "TASK", "confidence": 0.6143686473369598}]}, {"text": "These approaches rely on the \"one-sense per collocation\" heuristic, which assumes that presence of nearby words correlate with the sense of the word of interest.", "labels": [], "entities": []}, {"text": "This heuristic provides only a weak signal for sense identification, and such algorithms require large amount of training data to achieve competitive perfor-mance.", "labels": [], "entities": [{"text": "sense identification", "start_pos": 47, "end_pos": 67, "type": "TASK", "confidence": 0.727284237742424}]}], "datasetContent": [{"text": "We first describe the datasets and the preprocessing methods used to prepare them.", "labels": [], "entities": []}, {"text": "We also describe the Word Sense Induction task that we used to compare and evaluate our method.", "labels": [], "entities": [{"text": "Word Sense Induction task", "start_pos": 21, "end_pos": 46, "type": "TASK", "confidence": 0.7560908421874046}]}, {"text": "We use parallel corpora in English (En), French (Fr), Spanish (Es), Russian (Ru) and Chinese (Zh) in our experiments.", "labels": [], "entities": []}, {"text": "Corpus statistics for all datasets used in our experiments are shown in.", "labels": [], "entities": []}, {"text": "For En-Zh, we use the FBIS parallel corpus (LDC2003E14).", "labels": [], "entities": [{"text": "FBIS parallel corpus (LDC2003E14", "start_pos": 22, "end_pos": 54, "type": "DATASET", "confidence": 0.807184374332428}]}, {"text": "For En-Fr, we use the first 10M lines from the Giga-EnFr corpus released as part of the WMT shared task).", "labels": [], "entities": [{"text": "Giga-EnFr corpus released", "start_pos": 47, "end_pos": 72, "type": "DATASET", "confidence": 0.9018322229385376}, {"text": "WMT shared task", "start_pos": 88, "end_pos": 103, "type": "DATASET", "confidence": 0.7016583283742269}]}, {"text": "Note that the domain from which parallel corpus has been derived can affect the final result.", "labels": [], "entities": []}, {"text": "To understand what choice of languages provide suitable disambiguation signal, it is necessary to control for domain in all parallel corpora.", "labels": [], "entities": []}, {"text": "To this end, we also used the En-Fr, En-Es, En-Zh and En-Ru sections of the MultiUN parallel corpus.", "labels": [], "entities": [{"text": "MultiUN parallel corpus", "start_pos": 76, "end_pos": 99, "type": "DATASET", "confidence": 0.8236811955769857}]}, {"text": "Word alignments were generated using fast_align tool () in the symmetric intersection mode.", "labels": [], "entities": [{"text": "Word alignments", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.6427111178636551}]}, {"text": "Tokenization and other preprocessing were performed using cdec 3 toolkit.", "labels": [], "entities": []}, {"text": "Stanford Segmenter () was used to preprocess the Chinese corpora.", "labels": [], "entities": [{"text": "Stanford Segmenter", "start_pos": 0, "end_pos": 18, "type": "DATASET", "confidence": 0.9298084080219269}]}, {"text": "Word Sense Induction (WSI).", "labels": [], "entities": [{"text": "Word Sense Induction (WSI)", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7524798264106115}]}, {"text": "We evaluate our approach on word sense induction task.", "labels": [], "entities": [{"text": "word sense induction", "start_pos": 28, "end_pos": 48, "type": "TASK", "confidence": 0.81650177637736}]}, {"text": "In this task, we are given several sentences showing usages of the same word, and are required to cluster all sentences which use the same sense).", "labels": [], "entities": []}, {"text": "The predicted clustering is then compared against a provided gold clustering.", "labels": [], "entities": []}, {"text": "Note that WSI is a harder task than Word Sense Disambiguation (WSD), as unlike WSD, this task does not involve any supervision or explicit human knowledge about senses of words.", "labels": [], "entities": [{"text": "WSI", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.9748708009719849}, {"text": "Word Sense Disambiguation (WSD)", "start_pos": 36, "end_pos": 67, "type": "TASK", "confidence": 0.76481893658638}]}, {"text": "We use the disambiguation approach in eq. to predict the sense given the target word and four context words.", "labels": [], "entities": []}, {"text": "To allow for fair comparison with earlier work, we use the same benchmark datasets as ( and Wikipedia Word Sense Induction (WWSI).", "labels": [], "entities": [{"text": "Wikipedia Word Sense Induction (WWSI)", "start_pos": 92, "end_pos": 129, "type": "DATASET", "confidence": 0.7678906576974052}]}, {"text": "We report Adjusted Rand Index (ARI) in the experiments, as ARI is a more strict and precise metric than F-score and V-measure.", "labels": [], "entities": [{"text": "Adjusted Rand Index (ARI)", "start_pos": 10, "end_pos": 35, "type": "METRIC", "confidence": 0.920278936624527}, {"text": "ARI", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.9819927215576172}, {"text": "F-score", "start_pos": 104, "end_pos": 111, "type": "METRIC", "confidence": 0.9597830772399902}]}, {"text": "For fairness, we used five context words on either side to update each English word-vectors in all the experiments.", "labels": [], "entities": []}, {"text": "In the monolingual setting, all five words are English; in the multilingual settings, we used four neighboring English words plus the one foreign word aligned to the word being updated (d = 4, d = 0 in Algorithm 1).", "labels": [], "entities": []}, {"text": "We also analyze effect of varying d , the context window size in the foreign sentence on the model performance.", "labels": [], "entities": []}, {"text": "We tune the parameters \u03b1 and T by maximizing the log-likelihood of a held out English text.", "labels": [], "entities": []}, {"text": "The parameters were chosen from the following values \u03b1 = {0.05, 0.1, .., 0.25}, T = {5, 10, .., 30}.", "labels": [], "entities": [{"text": "T", "start_pos": 80, "end_pos": 81, "type": "METRIC", "confidence": 0.9908695220947266}]}, {"text": "All models were trained for 10 iteration with a decay-ing learning rate of 0.025, decayed to 0.", "labels": [], "entities": [{"text": "decay-ing learning rate", "start_pos": 48, "end_pos": 71, "type": "METRIC", "confidence": 0.7153885960578918}]}, {"text": "Unless otherwise stated, all embeddings are 100 dimensional.", "labels": [], "entities": []}, {"text": "Under various choice of \u03b1 and T , we identify only about 10-20% polysemous words in the vocabulary using monolingual training and 20-25% polysemous using multilingual training.", "labels": [], "entities": []}, {"text": "It is evident using the non-parametric prior has led to substantially more efficient representation compared to previous methods with fixed number of senses per word.", "labels": [], "entities": []}, {"text": "We performed extensive experiments to evaluate the benefit of leveraging bilingual and multilingual information during training.", "labels": [], "entities": []}, {"text": "We also analyze how the different choices of language family (i.e. using more distant vs more similar languages) affect performance of the embeddings.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Corpus Statistics (in millions). Horizontal lines de- marcate corpora from the same domain.", "labels": [], "entities": [{"text": "Corpus Statistics", "start_pos": 10, "end_pos": 27, "type": "DATASET", "confidence": 0.8176857829093933}]}, {"text": " Table 2: Results on word sense induction (left four columns)  in ARI and contextual word similarity (last column) in per- cent correlation. Language pairs are separated by horizontal  lines. Best results shown in bold.", "labels": [], "entities": [{"text": "word sense induction", "start_pos": 21, "end_pos": 41, "type": "TASK", "confidence": 0.7745371063550314}]}, {"text": " Table 3: Effect (in ARI) of language family distance on WSI task. Best results for each column is shown in bold. The  improvement from MONO to FULL is also shown as (3) -(1). Note that this is not comparable to results in Table 2, as we use a  different training corpus to control for the domain.", "labels": [], "entities": [{"text": "WSI task", "start_pos": 57, "end_pos": 65, "type": "TASK", "confidence": 0.7749392986297607}, {"text": "FULL", "start_pos": 144, "end_pos": 148, "type": "METRIC", "confidence": 0.9840996265411377}]}]}