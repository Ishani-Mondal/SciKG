{"title": [{"text": "From Clickbait to Fake News Detection: An Approach based on Detecting the Stance of Headlines to Articles", "labels": [], "entities": [{"text": "Fake News Detection", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.564487099647522}]}], "abstractContent": [{"text": "We present a system for the detection of the stance of headlines with regard to their corresponding article bodies.", "labels": [], "entities": [{"text": "detection of the stance of headlines", "start_pos": 28, "end_pos": 64, "type": "TASK", "confidence": 0.7765931785106659}]}, {"text": "The approach can be applied in fake news, especially clickbait detection scenarios.", "labels": [], "entities": [{"text": "clickbait detection", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.71656633913517}]}, {"text": "The component is part of a larger platform for the curation of digital content; we consider veracity and relevancy an increasingly important part of curating online information.", "labels": [], "entities": []}, {"text": "We want to contribute to the debate on how to deal with fake news and related online phenomena with technological means, by providing means to separate related from unrelated headlines and further classifying the related headlines.", "labels": [], "entities": []}, {"text": "On a publicly available data set annotated for the stance of headlines with regard to their corresponding article bodies, we achieve a (weighted) accuracy score of 89.59.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.9762479662895203}]}], "introductionContent": [{"text": "With the advent of social media and its increasingly important role as a provider and amplifier of news, basically anyone, anywhere, can produce and help circulate content for other people to read.", "labels": [], "entities": []}, {"text": "Traditional barriers to publishing content (like a press to print newspapers or broadcasting time for radio or television) have disappeared, and with this, at least part of traditional quality control procedures have disappeared as well.", "labels": [], "entities": []}, {"text": "Basic journalistic principles like source verification, fact checking and accountability can be easily bypassed or simply ignored by individuals or organisations publishing content on Twitter, Facebook or other social networks.", "labels": [], "entities": [{"text": "source verification", "start_pos": 35, "end_pos": 54, "type": "TASK", "confidence": 0.7587555050849915}, {"text": "fact checking", "start_pos": 56, "end_pos": 69, "type": "TASK", "confidence": 0.8108640611171722}]}, {"text": "The impact of this situation is illustrated by the predominance of terms like \"trolls\", \"fake news\", \"post-truth media\" and \"alternative facts\".", "labels": [], "entities": []}, {"text": "There is evidence that these developments and their effects are not harmless but can have a significant impact on real-world events, which is illustrated by a description of the role of social media in the 2016 US presidential election by, and by a study on the effectiveness and debunking strategies of rumours surrounding the Affordable Care Act by.", "labels": [], "entities": [{"text": "Affordable Care Act", "start_pos": 328, "end_pos": 347, "type": "DATASET", "confidence": 0.7392150561014811}]}, {"text": "While the cause of this situation may have its roots in many different aspects of modern society, and hence needs to be approached from several different angles, we aim to make a contribution from the angle of Language Technology and Natural Language Processing.", "labels": [], "entities": [{"text": "Natural Language Processing", "start_pos": 234, "end_pos": 261, "type": "TASK", "confidence": 0.6579896608988444}]}, {"text": "We consider fullyautomated procedures for fact-checking, clickbait detection or fake news classification not feasible at this point, but aim to support the community by providing means of detecting articles or pieces of news that need to be approached with caution, where a human has to make final decisions (on credibility, legitimacy etc.), but is aided by a set of tools.", "labels": [], "entities": [{"text": "clickbait detection", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.7269371896982193}, {"text": "fake news classification", "start_pos": 80, "end_pos": 104, "type": "TASK", "confidence": 0.695844034353892}]}, {"text": "The approach described in this paper can serve as the back-end of such a smart set of tooling around fact-checking and can augment news coming from both traditional and non-traditional (social media) sources.", "labels": [], "entities": []}, {"text": "We envision the resulting set of tools as a collection of expert tools for specific job profiles (like a journalist or a news editor), or in the shape of a simple browser plug-in, flagging unverified or dubious content to the end user.", "labels": [], "entities": []}, {"text": "The work presented in this paper was carried out under the umbrella of a two-year research and technology transfer project, in which a research centre collaborates with four SME partners that face the challenge of having to process, analyse and make sense of large amounts of digital content.", "labels": [], "entities": [{"text": "SME", "start_pos": 174, "end_pos": 177, "type": "TASK", "confidence": 0.859443187713623}]}, {"text": "The companies cover four different use cases and sectors including journalism.", "labels": [], "entities": []}, {"text": "For these partners we develop a plat-form that provides access to language and knowledge technologies (.", "labels": [], "entities": []}, {"text": "The services are integrated by the SME partners into their own in-house systems or those of clients.", "labels": [], "entities": [{"text": "SME", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.945814847946167}]}, {"text": "In this paper, we aim to contribute to a first step in battling fake news, often referred to as stance detection, where the challenge is to detect the stance of a claim with regard to another piece of content.", "labels": [], "entities": [{"text": "stance detection", "start_pos": 96, "end_pos": 112, "type": "TASK", "confidence": 0.7945363223552704}]}, {"text": "Our experiments are based on the setup of the first Fake News Challenge (FNC1).", "labels": [], "entities": [{"text": "Fake News Challenge (FNC1)", "start_pos": 52, "end_pos": 78, "type": "DATASET", "confidence": 0.7589980562527975}]}, {"text": "In FNC1, the claim comes in the form of a headline, and the other piece of content is an article body.", "labels": [], "entities": [{"text": "FNC1", "start_pos": 3, "end_pos": 7, "type": "DATASET", "confidence": 0.9134950637817383}]}, {"text": "This step may seem, and, in fact, is, along way from automatically checking the veracity of apiece of content with regard to some kind of ground truth.", "labels": [], "entities": []}, {"text": "But the problem lies exactly in the definition of the truth, and the fact that it is sensitive to bias.", "labels": [], "entities": []}, {"text": "Additionally, and partly because of this, annotated corpora, allowing training and experimental evaluation, are hard to come by and also often (in the case of fact checker archives) not freely available.", "labels": [], "entities": []}, {"text": "We argue that detecting whether apiece of content is related or not related to another piece of content (e. g., headline vs. article body) is an important first step, which would perhaps best be described as clickbait detection (i. e., a headline not related to the actual article is more likely to be clickbait).", "labels": [], "entities": [{"text": "detecting whether apiece of content is related or not related to another piece of content", "start_pos": 14, "end_pos": 103, "type": "TASK", "confidence": 0.76560085217158}, {"text": "clickbait detection", "start_pos": 208, "end_pos": 227, "type": "TASK", "confidence": 0.7167965322732925}]}, {"text": "Following the FNC1 setup, the further classification of related pieces of content into more fine-grained classes provides valuable information once the \"truth\" (in the form of a collection of facts) has been established, so that particular pieces of content can be classified as \"fake\" or, rather, \"false\".", "labels": [], "entities": [{"text": "FNC1", "start_pos": 14, "end_pos": 18, "type": "DATASET", "confidence": 0.7399393320083618}, {"text": "classification of related pieces of content", "start_pos": 38, "end_pos": 81, "type": "TASK", "confidence": 0.8072989086310068}]}, {"text": "Since this definitive, resolving collection of facts is usually hard to come by, the challenge of stance detection can be put to use combining the outcome with credibility or reputation scores of news outlets, where several high-credibility outlets disagreeing with a particular piece of content point towards a false claim.", "labels": [], "entities": [{"text": "stance detection", "start_pos": 98, "end_pos": 114, "type": "TASK", "confidence": 0.8678934574127197}]}, {"text": "Stance detection can also prove relevant for detecting political bias: if authors on the same end of the political spectrum are more likely to agree with each other, the (political) preference of one author can be induced once the preference of the other author is known.", "labels": [], "entities": [{"text": "Stance detection", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.9413186013698578}, {"text": "detecting political bias", "start_pos": 45, "end_pos": 69, "type": "TASK", "confidence": 0.8120654026667277}]}, {"text": "Additionally, the stances of utterances towards a specific piece of content can provide hints on its veracity.", "labels": [], "entities": []}, {"text": "( show that the propagation of tweets regarding crisis situations (like natural disasters) differs based on their content: tweets spreading news are affirmed by related tweets, whereas tweets spreading rumours are mostly questioned or denied.", "labels": [], "entities": []}, {"text": "In this paper we propose a solution that involves the human-in-the-loop.", "labels": [], "entities": []}, {"text": "We think that our approach can be a valuable part of solving the problem described above.", "labels": [], "entities": []}, {"text": "The rest of this paper is divided into five sections.", "labels": [], "entities": []}, {"text": "Section 2 reviews related work, Section 3 describes the data set used, Section 4 explains our approach in detail and Section 5 provides an evaluation.", "labels": [], "entities": []}, {"text": "Our conclusions are presented in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "The first step of deciding whether a headline/article pair is related or not is done based on n-gram matching (of lemmatised n-grams).", "labels": [], "entities": []}, {"text": "This procedure is rule-based and only relies on finding an optimal value for the threshold, based on the data.", "labels": [], "entities": []}, {"text": "To arrive at an optimal value, we used all data and did not separate it into training and test sets.", "labels": [], "entities": []}, {"text": "Since the subsequent classification methods are based on machine learning, the following evaluation figures are the result of 50-fold crossvalidation, with a 90-10 division of training and test data, respectively.", "labels": [], "entities": []}, {"text": "Considering that the combination of headlines and article bodies has been performed randomly with many obviously unrelated combinations, the relatedness score of 93.27 can be considered relatively low.", "labels": [], "entities": [{"text": "relatedness score", "start_pos": 141, "end_pos": 158, "type": "METRIC", "confidence": 0.9222707748413086}]}, {"text": "Upon manual investigation of the cases classified as \"unrelated\" (but that were in fact of the \"agree\", \"disagree\" or \"discuss\" class), we found that the vast majority had headlines with different wordings that were not matching after lemmatisation.", "labels": [], "entities": []}, {"text": "One concrete example with the headline \"Small Meteorite Hits Managua\" in its article body mentions \"the Nicaraguan capital\" but not \"Managua\" and \"a chunk of an Earth-passing asteroid\" instead of \"small meteorite\".", "labels": [], "entities": []}, {"text": "To improve the approach for cases such as this one, we propose to include more sophisticated techniques to capture word relatedness in a knowledge-rich way as an important part of future work.", "labels": [], "entities": []}, {"text": "The other way round, cases classified as related that were in fact annotated as \"unrelated\" contained words in the headline that were frequently mentioned in the article body.", "labels": [], "entities": []}, {"text": "One example with the headline \"SHOCK CLAIM: PGA Golfer Says Tiger Woods Is Suspended For Failed Drug Test\" was combined  with an article body about the divorce of Tiger Woods and Elin Nordegren.", "labels": [], "entities": [{"text": "SHOCK CLAIM", "start_pos": 31, "end_pos": 42, "type": "METRIC", "confidence": 0.7310730516910553}, {"text": "PGA Golfer Says Tiger Woods", "start_pos": 44, "end_pos": 71, "type": "DATASET", "confidence": 0.9028489589691162}]}, {"text": "Here, we suggest, as part of future work, to include event detection, to move away from entity-based representations and put more focus on the event actually reported.", "labels": [], "entities": [{"text": "event detection", "start_pos": 53, "end_pos": 68, "type": "TASK", "confidence": 0.775185763835907}]}, {"text": "After deciding on relatedness, we are left with (on average) 1,320 instances.", "labels": [], "entities": []}, {"text": "For the three-class classification of this set, we obtained (on average) 686 cases that scored above the scoring difference threshold and were assigned their class by this three-class Logistic Regression classifier.", "labels": [], "entities": [{"text": "scoring difference threshold", "start_pos": 105, "end_pos": 133, "type": "METRIC", "confidence": 0.8011446396509806}]}, {"text": "Of these, 642 were correct, resulting in an accuracy of 93.64 for this portion of the data set (i. e., \"related\").", "labels": [], "entities": [{"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9995297193527222}]}, {"text": "The average number of cases where the scoring difference was below the threshold (634) were classified using the three binary classifiers.", "labels": [], "entities": []}, {"text": "This resulted in 544 correctly classified instances, and a score of 85.83 for this section of the data set.", "labels": [], "entities": []}, {"text": "Putting these scores together, the weighted score and the individual components are shown in, i. e., the relatedness score for the binary decision \"related\" or \"unrelated\" (25% of the weighted score) and the three-class score for the classification of \"related\" instances into \"agree\", \"disagree\" or \"discuss\" (75% of the weighted score).", "labels": [], "entities": []}, {"text": "To get an idea of the effect of the first stage's error rate on the second stage of processing, we re-ran the experiments taking the \"related\" vs. \"unrelated\" information from the annotations directly.", "labels": [], "entities": []}, {"text": "This resulted in a three-class score of 89.82, i. e., a 1.46 drop inaccuracy due to classification errors in the first stage.", "labels": [], "entities": [{"text": "1.46 drop inaccuracy", "start_pos": 56, "end_pos": 76, "type": "METRIC", "confidence": 0.6012834012508392}]}, {"text": "While these numbers look promising for initial steps towards tackling the challenge that fake news poses globally, we acknowledge that at least the 25% of the score (the relatedness score of 93.27) is not directly applicable in areal world scenario, since the data set was artificially boosted by randomly combining headlines and article bodiesa headline such as \"Isis claims to behead US journalist\" is combined with an article on who is going to be the main actor in a biopic on Steve Jobs.", "labels": [], "entities": []}, {"text": "Although this headline/article pair was (obviously) tagged as \"unrelated\", this is not something that is usually encountered in a real-world scenario.", "labels": [], "entities": []}, {"text": "For the more fine-grained classification of articles that have been classified as \"related\", the threeway classification is a relevant first step, but other classes may need to be added to the set, or a more detailed division may need to be made in order to take the next steps in tackling the fake news challenge.", "labels": [], "entities": []}, {"text": "Additionally, we seethe integration of known facts and general discourse knowledge (possibly through Linked Data), and the incorporation of source credibility information as important and promising suggestions for future research.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Key figures of the FNC-1 data set", "labels": [], "entities": [{"text": "FNC-1 data set", "start_pos": 29, "end_pos": 43, "type": "DATASET", "confidence": 0.9409779906272888}]}, {"text": " Table 2: Results of 50-fold cross-validation", "labels": [], "entities": []}]}