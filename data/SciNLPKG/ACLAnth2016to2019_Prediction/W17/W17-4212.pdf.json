{"title": [{"text": "Semantic Storytelling, Cross-lingual Event Detection and other Semantic Services fora Newsroom Content Curation Dashboard", "labels": [], "entities": [{"text": "Cross-lingual Event Detection", "start_pos": 23, "end_pos": 52, "type": "TASK", "confidence": 0.6776344478130341}]}], "abstractContent": [{"text": "We present a prototypical content curation dashboard, to be used in the newsroom, and several of its underlying semantic content analysis components (such as named entity recognition, entity linking, sum-marisation and temporal expression analysis).", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 158, "end_pos": 182, "type": "TASK", "confidence": 0.6903434495131174}, {"text": "entity linking", "start_pos": 184, "end_pos": 198, "type": "TASK", "confidence": 0.7296461760997772}, {"text": "temporal expression analysis", "start_pos": 219, "end_pos": 247, "type": "TASK", "confidence": 0.6532688438892365}]}, {"text": "The idea is to enable journalists (a) to process incoming content (agency reports, twitter feeds, reports, blog posts, social media etc.) and (b) to create new articles more easily and more efficiently.", "labels": [], "entities": []}, {"text": "The prototype system also allows the automatic annotation of events in incoming content for the purpose of supporting journalists in identifying important, relevant or meaningful events and also to adapt the content currently in production accordingly in a semi-automatic way.", "labels": [], "entities": []}, {"text": "One of our long-term goals is to support journalists building up entire storylines with automatic means.", "labels": [], "entities": [{"text": "journalists building up entire storylines", "start_pos": 41, "end_pos": 82, "type": "TASK", "confidence": 0.7452494382858277}]}, {"text": "In the present prototype they are generated in a backend service using clustering methods that operate on the extracted events.", "labels": [], "entities": []}], "introductionContent": [{"text": "Journalists write and distribute news articles based on information collected from different sources (news agencies, media streams, other news articles etc.).", "labels": [], "entities": []}, {"text": "In order to produce a high-quality piece, a fair bit of research is needed on the topic and domain at hand.", "labels": [], "entities": []}, {"text": "Facts have to be checked, requiring at least basic domain knowledge, different view points considered and information from multiple sources combined in a sensible way.", "labels": [], "entities": []}, {"text": "In short, much research is needed to arrive at apiece of content that combines new and surprising information with a decent context of the event reported upon.", "labels": [], "entities": []}, {"text": "While the amount of available, especially digital information is increasing on a daily basis, the journalist's ability to read all this information is decreasing in the little time available.", "labels": [], "entities": []}, {"text": "This calls for tools that support journalists in processing large amounts of incoming information.", "labels": [], "entities": []}, {"text": "There are differences in journalistic reporting, depending on the event being covered.", "labels": [], "entities": []}, {"text": "News about a event with global relevance, such as a war, differs from news about the inauguration of a local cultural centre.", "labels": [], "entities": []}, {"text": "When looking at the available source material, the amount of background information, also its diversity, differs significantly in both cases.", "labels": [], "entities": []}, {"text": "Coverage for the global event depends on a much larger amount of readily available information while the local event coverage depends on smaller amounts of data that may need a bit of effort in tracking them down (the name of local news sources for example).", "labels": [], "entities": []}, {"text": "To address this difference in research requirements we describe a prototypical approach for cross-lingual semantic analysis, especially event detection, ultimately aimed at supporting journalists through semantic storytelling, based on two data sets.", "labels": [], "entities": [{"text": "cross-lingual semantic analysis", "start_pos": 92, "end_pos": 123, "type": "TASK", "confidence": 0.744026909271876}, {"text": "event detection", "start_pos": 136, "end_pos": 151, "type": "TASK", "confidence": 0.7598307728767395}]}, {"text": "Section 2 briefly describes the content curation dashboard, while Section 3 focuses upon semantic storytelling.", "labels": [], "entities": [{"text": "semantic storytelling", "start_pos": 89, "end_pos": 110, "type": "TASK", "confidence": 0.6978213936090469}]}, {"text": "Section 4 describes the use cases and sketches the results of initial experiments on news data.", "labels": [], "entities": []}, {"text": "Section 5 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "We performed a qualitative evaluation of several generated storylines (clusters).", "labels": [], "entities": []}, {"text": "We apply the storytelling generation approach in two journalistic use cases: domain-specific web-crawled global news and general domain regional news.", "labels": [], "entities": [{"text": "storytelling generation", "start_pos": 13, "end_pos": 36, "type": "TASK", "confidence": 0.7255005538463593}]}, {"text": "While the basic steps in both cases are the same (collecting relevant information, checking facts, writing an article, etc.), there are differences that make these two cases special: the \"global news\" articles are in English and were collected online while the \"regional news\" articles are in German, distributed by a news agency, so language usage and also register/style is different.", "labels": [], "entities": []}, {"text": "We applied several clustering algorithms to both data sets using fixed and free cluster sizes; EM provides a rather balanced distribution along clusters.", "labels": [], "entities": []}, {"text": "Considering the topic diversity, this approach seems to bean interesting initial point for the automatic generation of semantic content for stories in large collections with topic heterogeneity.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Using the frequencies of extracted events as features for a clustering algorithm", "labels": [], "entities": []}]}