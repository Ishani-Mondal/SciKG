{"title": [{"text": "Predicting Success in Goal-Driven Human-Human Dialogues", "labels": [], "entities": [{"text": "Predicting Success in Goal-Driven Human-Human Dialogues", "start_pos": 0, "end_pos": 55, "type": "TASK", "confidence": 0.6423338949680328}]}], "abstractContent": [{"text": "In goal-driven dialogue systems, success is often defined based on a structured definition of the goal.", "labels": [], "entities": []}, {"text": "This requires that the dialogue system be constrained to handle a specific class of goals and that there be a mechanism to measure success with respect to that goal.", "labels": [], "entities": []}, {"text": "However, in many human-human dialogues the diversity of goals makes it infeasible to define success in such away.", "labels": [], "entities": []}, {"text": "To address this scenario , we consider the task of automatically predicting success in goal-driven human-human dialogues using only the information communicated between participants in the form of text.", "labels": [], "entities": [{"text": "predicting success in goal-driven human-human dialogues", "start_pos": 65, "end_pos": 120, "type": "TASK", "confidence": 0.6763303528229395}]}, {"text": "We build a dataset from stackoverflow.com which consists of exchanges between two users in the technical domain where ground-truth success labels are available.", "labels": [], "entities": []}, {"text": "We then propose a turn-based hierarchical neural network model that can be used to predict success without requiring a structured goal definition.", "labels": [], "entities": []}, {"text": "We show this model out-performs rule-based heuristics and other baselines as it is able to detect patterns over the course of a dialogue and capture notions such as gratitude.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper, we investigate goal-driven dialogues in large open-ended domains where one participant engages in a conversation with another participant in order to gain information or complete some task.", "labels": [], "entities": []}, {"text": "Such dialogues are common in online communication channels where users help each other complete tasks with various requirements.", "labels": [], "entities": []}, {"text": "For instance, many corporations have online chat systems where users can talk to a representative, and there are countless online forums (both technical and non-technical) where people go for help.", "labels": [], "entities": []}, {"text": "Current dialogue agents learn to assist users to complete tasks in relatively constrained domains such as restaurant reservation booking (see of  fora list of these domains).", "labels": [], "entities": [{"text": "restaurant reservation booking", "start_pos": 106, "end_pos": 136, "type": "TASK", "confidence": 0.8058960636456808}]}, {"text": "In such domains, agents can measure success by referring to a structured goal definition or ontology and learn to maximize this score (.", "labels": [], "entities": []}, {"text": "However, in less-constrained domains, success can be difficult to define as it is often dependent on the specific dialogue and participants.", "labels": [], "entities": []}, {"text": "One difficulty arises when participants enter a conversation with intrinsically different goals which we cannot anticipate in advance.", "labels": [], "entities": []}, {"text": "For example, on stackoverflow, a popular forum for programming-related help, users can ask for help fixing a bug (in which case success occurs when the bug is resolved), or ask fora recommendation (in which case success occurs when the user is satisfied with a recommendation).", "labels": [], "entities": []}, {"text": "On top of this, different users may have differing definitions of success (e.g., a novice may require more information than an expert).", "labels": [], "entities": []}, {"text": "The aforementioned difficulties suggest that the definition of success is highly specific to the user who initiates the dialogue.", "labels": [], "entities": []}, {"text": "Even in constrained domains it has been observed that a user's perception of success is more indicative of user satisfaction than an objective measure ().", "labels": [], "entities": []}, {"text": "Thus, we aim to let the original participant be the judge of success and build models that can predict success based on information communicated rather than enforcing a rigorous definition in our models.", "labels": [], "entities": []}, {"text": "An impediment in building models that predict success (or interactive agents) in these domains is the lack of success labels in current datasets ().", "labels": [], "entities": []}, {"text": "These labels can be difficult to collect as forums often do not pro-vide any structured process of indicating whether a problem was solved or not.", "labels": [], "entities": []}, {"text": "Our model is trained to predict success in these interactions using only the dialogue text, which can then be used as automatic feedback to improve the quality of the dialogues and enable automatic dialogue agents to learn from large, previously unlabeled corpora.", "labels": [], "entities": []}, {"text": "We address the challenge of predicting success in goal-driven human-human dialogues with three contributions.", "labels": [], "entities": []}, {"text": "First, we present anew dataset of human-human goal-driven dialogues in the technical domain.", "labels": [], "entities": []}, {"text": "The use of human-human dialogues allows our dataset to reach a size needed to work in and be representative of large domains.", "labels": [], "entities": []}, {"text": "We focus on dialogues from stackoverflow.com, where we have success labels available.", "labels": [], "entities": []}, {"text": "These dialogues consist of one participant asking a programmingrelated question and other participants interacting with them to come up with a solution.", "labels": [], "entities": []}, {"text": "This dataset will allow the community to work in an openended domain with success labels.", "labels": [], "entities": []}, {"text": "Our second contribution consists of an investigation of new models to predict success using only the raw text of the dialogue history.", "labels": [], "entities": []}, {"text": "Our most successful model is a turn-based hierarchical recurrent neural network.", "labels": [], "entities": []}, {"text": "This model is inspired by the observation that dialogues consist of multi-level sequences.", "labels": [], "entities": []}, {"text": "At the higher-level, we have a sequence of turns, which is commonly abstracted as a dialogue act, or intent ().", "labels": [], "entities": []}, {"text": "For each turn, we also have a lower-level sequence of words which area natural language realization of the dialogue act.", "labels": [], "entities": []}, {"text": "We show that the H-RNN outperforms alternative models, and in particular can capture the semantics of a user expressing their gratitude.", "labels": [], "entities": []}, {"text": "Our final contribution is an analysis of the salient features for success prediction.", "labels": [], "entities": [{"text": "success prediction", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.7711242735385895}]}, {"text": "We show that our models' performances significantly increase when they explicitly model the entire dialogue history (and learn more complicated indicators of success along with gratitude).", "labels": [], "entities": []}, {"text": "Although our models only use each turn in their raw text form (as opposed to the dialogue act type such as Confirmation or Rejection), they implicitly benefit from this natural structure that arises in dialogue.", "labels": [], "entities": [{"text": "Confirmation or Rejection", "start_pos": 107, "end_pos": 132, "type": "TASK", "confidence": 0.6317530274391174}]}], "datasetContent": [{"text": "Our first contribution is a dataset from stackoverflow.com curated to allow training a success prediction function.", "labels": [], "entities": []}, {"text": "Stackoverflow is a communitybased website where users post programmingrelated questions and other users can respond with answers.", "labels": [], "entities": []}, {"text": "Multiple users can provide answers to the same question and users can comment on any potential answer.", "labels": [], "entities": []}, {"text": "This format allows us to extract dialogues from the website that consist of the aforementioned exchange.", "labels": [], "entities": []}, {"text": "To limit the complexity, we restrict our dataset to dialogues between two users.", "labels": [], "entities": []}, {"text": "These dialogues are goal-driven as each is an attempt to solve the question initially posted. is an example of a question, answer, and comment found on stackoverflow.", "labels": [], "entities": []}, {"text": "In addition, the user who posed a question can mark an answer as accepted if that answer successfully solved their problem.", "labels": [], "entities": []}, {"text": "Only the original user can mark an answer as accepted and they can only mark a single answer.", "labels": [], "entities": []}, {"text": "Any user can vote (+1 or \u22121) on answers based on how helpful they are.", "labels": [], "entities": []}, {"text": "Our goal when creating the dataset is to collect a label for dialogue success that is representative of the original user's goal.", "labels": [], "entities": []}, {"text": "Note that their true goal may differ slightly from what they express in their question (for example, due to a poor explanation).", "labels": [], "entities": []}, {"text": "Votes have a high variance that depend on how popular a question is and the difficulty of the question.", "labels": [], "entities": []}, {"text": "Furthermore, users who vote for an answer may not be experiencing the exact same problem as the original user.", "labels": [], "entities": []}, {"text": "For this reason, we do not use the vote count alone to judge dialogue success (only to ensure a high quality dataset as described below).", "labels": [], "entities": []}, {"text": "We performed multiple experiments to gain intuition about what our models are learning and their performance at predicting dialogue success.", "labels": [], "entities": []}, {"text": "We divided our dataset into training, validation, and testing sets using a 60%/20%/20% split (there is equal class imbalance across sets).", "labels": [], "entities": []}, {"text": "We present precision, recall, and F1 metrics for each class.", "labels": [], "entities": [{"text": "precision", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.9995548129081726}, {"text": "recall", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9987201690673828}, {"text": "F1 metrics", "start_pos": 34, "end_pos": 44, "type": "METRIC", "confidence": 0.9693328738212585}]}, {"text": "For the RNN models, we used the crossvalidation set to optimize the model parameters.: 95% confidence intervals for Precision, Recall, and F1 for both classes for models trained using the entire dialogue.", "labels": [], "entities": [{"text": "Precision", "start_pos": 116, "end_pos": 125, "type": "METRIC", "confidence": 0.9888426065444946}, {"text": "Recall", "start_pos": 127, "end_pos": 133, "type": "METRIC", "confidence": 0.9575510621070862}, {"text": "F1", "start_pos": 139, "end_pos": 141, "type": "METRIC", "confidence": 0.9995712637901306}]}, {"text": "The highest metrics are bolded.", "labels": [], "entities": []}, {"text": "word embeddings of dimension 50, turn-level hidden states of dimension 100, and dialogue-level hidden states of dimension 200.", "labels": [], "entities": []}, {"text": "We can seethe performance of various models and feature sets in.", "labels": [], "entities": []}, {"text": "Confidence intervals were calculated using the bootstrap method.", "labels": [], "entities": [{"text": "Confidence intervals", "start_pos": 0, "end_pos": 20, "type": "METRIC", "confidence": 0.957893431186676}]}], "tableCaptions": [{"text": " Table 2: 95% confidence intervals for Precision, Recall, and F1 for both classes for models trained using  the entire dialogue. The highest metrics are bolded.", "labels": [], "entities": [{"text": "Precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9794859886169434}, {"text": "Recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9379710555076599}, {"text": "F1", "start_pos": 62, "end_pos": 64, "type": "METRIC", "confidence": 0.9997503161430359}]}, {"text": " Table 3: Example comments from the lower right cluster and everywhere else in the t-SNE plot. Com- ments are sampled at random from their respective clusters.", "labels": [], "entities": []}, {"text": " Table 4: 95 % confidence intervals for Precision, Recall, and F1 for models trained using subsets of the  dialogue that include or exclude the last turn by the initial user.", "labels": [], "entities": [{"text": "Precision", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9917660355567932}, {"text": "Recall", "start_pos": 51, "end_pos": 57, "type": "METRIC", "confidence": 0.9728214144706726}, {"text": "F1", "start_pos": 63, "end_pos": 65, "type": "METRIC", "confidence": 0.9997106194496155}]}]}