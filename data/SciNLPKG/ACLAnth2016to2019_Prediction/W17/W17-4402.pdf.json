{"title": [{"text": "Towards the Understanding of Gaming Audiences by Modeling Twitch Emotes", "labels": [], "entities": [{"text": "Understanding of Gaming Audiences", "start_pos": 12, "end_pos": 45, "type": "TASK", "confidence": 0.8250896036624908}]}], "abstractContent": [{"text": "Videogame streaming platforms have become a paramount example of noisy user-generated text.", "labels": [], "entities": []}, {"text": "These are websites where gaming is broadcasted, and allows interaction with viewers via integrated chat-rooms.", "labels": [], "entities": []}, {"text": "Probably the best known platform of this kind is Twitch, which has more than 100 million monthly viewers.", "labels": [], "entities": [{"text": "Twitch", "start_pos": 49, "end_pos": 55, "type": "DATASET", "confidence": 0.9500396847724915}]}, {"text": "Despite these numbers, and unlike other platforms featuring short messages (e.g. Twit-ter), Twitch has not received much attention from the Natural Language Processing community.", "labels": [], "entities": []}, {"text": "In this paper we aim at bridging this gap by proposing two important tasks specific to the Twitch platform , namely (1) Emote prediction; and (2) Trolling detection.", "labels": [], "entities": [{"text": "Emote prediction", "start_pos": 120, "end_pos": 136, "type": "TASK", "confidence": 0.8609851002693176}, {"text": "Trolling detection", "start_pos": 146, "end_pos": 164, "type": "TASK", "confidence": 0.9396642446517944}]}, {"text": "In our experiments, we evaluate three models: a BOW base-line, a logistic supervised classifiers based on word embeddings, and a bidirectional long short-term memory recurrent neural network (LSTM).", "labels": [], "entities": []}, {"text": "Our results show that the LSTM model outperforms the other two models, where explicit features with proven effectiveness for similar tasks were encoded.", "labels": [], "entities": []}], "introductionContent": [{"text": "Understanding the language of social media is a mature research area in Natural Language Processing (NLP) and Artificial Intelligence.", "labels": [], "entities": [{"text": "Understanding the language of social media", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.844006210565567}]}, {"text": "Not only for the challenges it poses from a linguistic perspective, but also for being a task with a direct impact in relevant sectors like politics, stock market or health.", "labels": [], "entities": []}, {"text": "The notion of understanding in social media contexts maybe divided in more specific AI tasks, including, among others, Sentiment Analysis (, Irony Detection (), or Event Summarization via Twitter Streams (, as well as other subtasks such as Event () or Stance Detection () in Twitter.", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 119, "end_pos": 137, "type": "TASK", "confidence": 0.8970554172992706}, {"text": "Event Summarization", "start_pos": 164, "end_pos": 183, "type": "TASK", "confidence": 0.7544211745262146}]}, {"text": "While the study of language in social media typically involves blog posts, comments or product reviews, one of the most interesting areas of research concerns those highly restrictive platforms, e.g. enforcing character limits in each message.", "labels": [], "entities": []}, {"text": "One of these platforms, Twitter, has attracted much attention due to its large user base as well as the linguistic idiosyncrasies of its language.", "labels": [], "entities": []}, {"text": "It is interesting, therefore, to focus on another growing platform (in number of users) which shares some of the features that made Twitter popular in NLP.", "labels": [], "entities": []}, {"text": "This platform is TWITCH.TV (henceforth, Twitch), the largest videogame video streaming service, currently a subsidiary of Amazon.", "labels": [], "entities": [{"text": "TWITCH.TV", "start_pos": 17, "end_pos": 26, "type": "DATASET", "confidence": 0.8561692237854004}]}, {"text": "Twitch is used by a large community of individual gamers to broadcast themselves playing a game (, but also by companies to broadcast live videogame and electronic sports (competitive video gaming) events, as well as releasing footage of new products, such as consoles or games.", "labels": [], "entities": [{"text": "Twitch", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8313726186752319}]}, {"text": "An outstanding feature of Twitch broadcasts is that they run alongside a permanent chat platform.", "labels": [], "entities": [{"text": "Twitch broadcasts", "start_pos": 26, "end_pos": 43, "type": "DATASET", "confidence": 0.8882482647895813}]}, {"text": "Properly analyzing the content of Twitch chat messages can be useful for understanding the opinion of the community towards any industry product or stakeholder, in addition to its industrial relevance (.", "labels": [], "entities": []}, {"text": "Moreover, analyzing this platform is fundamental for informing a number of AI-related applications such as behaviour prediction or Information Retrieval.", "labels": [], "entities": [{"text": "behaviour prediction", "start_pos": 107, "end_pos": 127, "type": "TASK", "confidence": 0.9010964930057526}, {"text": "Information Retrieval", "start_pos": 131, "end_pos": 152, "type": "TASK", "confidence": 0.8274237215518951}]}, {"text": "Interpreting Twitch language, however, is a challenging problem, as it features avast amount of Internet memes, slang and gaming-related lingo.", "labels": [], "entities": [{"text": "Interpreting Twitch language", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8374835848808289}]}, {"text": "In addition, Twitch language is characterized by combining short text messages with small pictures known as emotes.", "labels": [], "entities": []}, {"text": "These emotes generally serve a different communicative purpose than most visual aids (e.g. Twitter emojis), and therefore require specific modeling.", "labels": [], "entities": []}, {"text": "In this paper, we put forward an approach for the understanding of Twitch messages by means of modeling the underlying semantics of Twitch emotes, and a dataset of Twitch chat messages.", "labels": [], "entities": [{"text": "understanding of Twitch messages", "start_pos": 50, "end_pos": 82, "type": "TASK", "confidence": 0.7722392827272415}]}, {"text": "Building upon previous research on predicting paralinguistic elements (e.g. emojis) (, we target the Emote Prediction problem, i.e. the task of, given a collection of chatroom messages, predicting which emote the user is more likely to use.", "labels": [], "entities": [{"text": "Emote Prediction", "start_pos": 101, "end_pos": 117, "type": "TASK", "confidence": 0.6954636871814728}]}, {"text": "Second, Trolling Detection, which we reformulate as the task to detect a specific set of emotes which are broadly used by Twitch users in troll messages.", "labels": [], "entities": [{"text": "Trolling Detection", "start_pos": 8, "end_pos": 26, "type": "TASK", "confidence": 0.8365073800086975}]}, {"text": "For both tasks, we evaluate models which consider sequences of words (bidirectional recurrent neural networks), and compare against order-agnostic baselines which have proven to be highly competitive in similar tasks.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe the experimental setup for each of the tasks, and present the results of our proposed model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Precision, Recall and F-Measure of the  two models in the 30 emotes prediction experi- ment.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9988999366760254}, {"text": "Recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9982958436012268}, {"text": "F-Measure", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9988586902618408}]}, {"text": " Table 3: Detailed results for each class in the  Emote prediction experiment. We report the re- sults of the B-LSTMs model. We report Precision,  Recall, F-Measure, Rank and thousand of occur- rences in the Test (Te) and in the Train (Tr) for  each emote.", "labels": [], "entities": [{"text": "Emote prediction", "start_pos": 50, "end_pos": 66, "type": "TASK", "confidence": 0.7808704078197479}, {"text": "Precision", "start_pos": 135, "end_pos": 144, "type": "METRIC", "confidence": 0.9980623126029968}, {"text": "Recall", "start_pos": 147, "end_pos": 153, "type": "METRIC", "confidence": 0.9930111765861511}, {"text": "F-Measure", "start_pos": 155, "end_pos": 164, "type": "METRIC", "confidence": 0.9818659424781799}, {"text": "Rank", "start_pos": 166, "end_pos": 170, "type": "METRIC", "confidence": 0.9865798354148865}, {"text": "thousand of occur- rences", "start_pos": 175, "end_pos": 200, "type": "METRIC", "confidence": 0.7565507292747498}]}, {"text": " Table 4: Results of the trolling prediction exper- iments. The classes are two, trolling and non- trolling.", "labels": [], "entities": []}, {"text": " Table 5: Results of the multi 'kappa' prediction  experiment.", "labels": [], "entities": [{"text": "multi 'kappa' prediction", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.631503802537918}]}]}