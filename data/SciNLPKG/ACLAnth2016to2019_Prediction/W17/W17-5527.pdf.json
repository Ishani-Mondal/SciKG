{"title": [{"text": "Towards a General, Continuous Model of Turn-taking in Spoken Dialogue using LSTM Recurrent Neural Networks", "labels": [], "entities": []}], "abstractContent": [{"text": "Previous models of turn-taking have mostly been trained for specific turn-taking decisions, such as discriminating between turn shifts and turn retention in pauses.", "labels": [], "entities": []}, {"text": "In this paper, we present a predictive, continuous model of turn-taking using Long Short-Term Memory (LSTM) Recurrent Neural Networks (RNN).", "labels": [], "entities": []}, {"text": "The model is trained on human-human dialogue data to predict upcoming speech activity in a future time window.", "labels": [], "entities": []}, {"text": "We show how this general model can be applied to two different tasks that it was not specifically trained for.", "labels": [], "entities": []}, {"text": "First, to predict whether a turn-shift will occur or not in pauses, where the model achieves a better performance than human observers, and better than results achieved with more traditional models.", "labels": [], "entities": []}, {"text": "Second, to make a prediction at speech onset whether the utterance will be a short backchannel or a longer utterance.", "labels": [], "entities": []}, {"text": "Finally , we show how the hidden layer in the network can be used as a feature vector for turn-taking decisions in a human-robot interaction scenario.", "labels": [], "entities": []}], "introductionContent": [{"text": "One of the most fundamental aspects of dialogue is the organization of speaking between the participants.", "labels": [], "entities": []}, {"text": "Since it is difficult to speak and listen at the same time, the interlocutors need to take turns speaking, and this turn-taking has to be coordinated somehow.", "labels": [], "entities": []}, {"text": "This poses a challenge for spoken dialogue systems, where the system needs to coordinate its speaking with the user to avoid interruptions and (inappropriate) gaps and overlaps.", "labels": [], "entities": []}, {"text": "For a full account of turn-taking, there are many different aspects that need to be modelled.", "labels": [], "entities": []}, {"text": "For example, the system should be able to detect whether the user is likely to continue speaking after a brief silence, or whether the system should respond ().", "labels": [], "entities": []}, {"text": "Another related issue is to detect places where it is appropriate to give brief feedback (socalled backchannels) while the user is speaking).", "labels": [], "entities": []}, {"text": "If the user starts speaking, it is also important to estimate whether the user is most likely initiating a longer utterance, or a shorter listener response ().", "labels": [], "entities": []}, {"text": "When the system is speaking, it is important to assess whether the user will interpret pauses in the system's speech as turn-yielding (an opportunity to take the turn) or not, depending on how the system's utterance is synthesized).", "labels": [], "entities": []}, {"text": "So far, these different problems have mostly been addressed as separate issues, using different models.", "labels": [], "entities": []}, {"text": "In this paper, we present a general, continuous model of turn-taking, trained on dialogue data.", "labels": [], "entities": []}, {"text": "The model is general, in that we do not train it for specific turn-taking decisions, but instead train it to forecast the probability that the speakers will continue speaking over a future time window.", "labels": [], "entities": []}, {"text": "The model is continuous, in that it does this at every time step, and not at certain events (such as when someone stopped speaking).", "labels": [], "entities": []}, {"text": "We argue that this predictive model is potentially useful fora number of different types of predictions and decisions that are relevant for spoken dialogue systems.", "labels": [], "entities": []}, {"text": "A similar approach was taken by.", "labels": [], "entities": []}, {"text": "However, their experiments only yielded modest improvements over the baseline.", "labels": [], "entities": []}, {"text": "An explanation for this might be that turn-taking is a highly context-dependent phenomenon, and that representation of dialogue context is a challenging task, typically involving a lot of heuristics and feature engineering.", "labels": [], "entities": []}, {"text": "To address this problem, and make as few assumptions as possible, we train the model using Long Short-Term Memory (LSTM) Recurrent Neural Networks (RNN), where the context-modelling is left to the net-work, and we feed it with fairly basic features representing cues known to be relevant for turntaking.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "We start with a review of related work on the problem of turn-taking in dialogue, and give a brief overview of RNNs.", "labels": [], "entities": [{"text": "turn-taking in dialogue", "start_pos": 57, "end_pos": 80, "type": "TASK", "confidence": 0.7333371241887411}]}, {"text": "We then describe the proposed model in more detail, how it was applied in this study, and how features were extracted.", "labels": [], "entities": []}, {"text": "Using the HCRC Map Task Corpus (, we then present two experiments on turntaking predictions, both at pauses and at speech onset.", "labels": [], "entities": [{"text": "HCRC Map Task Corpus", "start_pos": 10, "end_pos": 30, "type": "DATASET", "confidence": 0.9759977608919144}]}, {"text": "Finally we investigate how the model can be applied to make predictions on humancomputer dialogue data.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Prediction performance of turn-shifts at  pauses for the Full model, depending on pause length.", "labels": [], "entities": [{"text": "Prediction", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9477592706680298}]}, {"text": " Table 2: Summary of F-score comparisons for pre- dicting turn-shifts at 500ms pauses.", "labels": [], "entities": [{"text": "F-score", "start_pos": 21, "end_pos": 28, "type": "METRIC", "confidence": 0.9901224970817566}]}]}