{"title": [{"text": "Hypothesis Testing based Intrinsic Evaluation of Word Embeddings", "labels": [], "entities": [{"text": "Intrinsic Evaluation of Word Embeddings", "start_pos": 25, "end_pos": 64, "type": "TASK", "confidence": 0.734222149848938}]}], "abstractContent": [{"text": "We introduce the cross-match test-an exact, distribution free, high-dimensional hypothesis test as an intrinsic evaluation metric for word embeddings.", "labels": [], "entities": []}, {"text": "We show that cross-match is an effective means of measuring distributional similarity between different vector representations and of evaluating the statistical significance of different vector embedding models.", "labels": [], "entities": []}, {"text": "Additionally , we find that cross-match can be used to provide a quantitative measure of linguistic similarity for selecting bridge languages for machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 146, "end_pos": 165, "type": "TASK", "confidence": 0.7610080540180206}]}, {"text": "We demonstrate that the results of the hypothesis test align with our expectations and note that the framework of two sample hypothesis testing is not limited to word em-beddings and can be extended to all vector representations.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word embeddings obtained via specialized models () or neural networks) have been successfully used to address various natural language processing tasks (.", "labels": [], "entities": []}, {"text": "These embeddings provide a nuanced representation of words that can capture various syntactic and semantic properties of natural language ().", "labels": [], "entities": []}, {"text": "Despite their effectiveness in downstream applications, embeddings have limited practical value as standalone items.", "labels": [], "entities": []}, {"text": "Consequently, an intrinsic evaluation metric must provide insight on the downstream task the embeddings are designed for.", "labels": [], "entities": []}, {"text": "In this work, we use Cross-match) -an exact, distribution free, high-dimensional hypothesis test to propose a novel approach for intrinsic evaluation of word embeddings, one that provides insight on tasks that depend on linguistic similarity.", "labels": [], "entities": []}, {"text": "Evaluating general purpose vector representations is difficult.", "labels": [], "entities": [{"text": "Evaluating general purpose vector representations", "start_pos": 0, "end_pos": 49, "type": "TASK", "confidence": 0.8513585925102234}]}, {"text": "They are trained using simple objectives and applied to a variety of downstream tasks, thus making no single extrinsic evaluation definitive.", "labels": [], "entities": []}, {"text": "Often, due to computational constraints, direct downstream evaluations are also impractical.", "labels": [], "entities": []}, {"text": "In the case of word embeddings, these constraints have led to the development of dedicated evaluation tasks like similarity and analogy () which are not directly related to training objectives or to downstream tasks.", "labels": [], "entities": []}, {"text": "Despite their ease of interpretability,  have shown that these tasks do not correlate well with downstream performance.", "labels": [], "entities": [{"text": "interpretability", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.9650260806083679}]}, {"text": "In related work,  propose an evaluation measure QVEC-CCA that is shown to correlate well with downstream semantic tasks where the objective is to quantify the linguistic content of word embeddings by maximizing the correlation with a manually annotated linguistic resource.", "labels": [], "entities": []}, {"text": "In this work, we use the Cross-match hypothesis test) to measure distributional similarity between different word vector representations.", "labels": [], "entities": []}, {"text": "Cross-match is an adjacency based test traditionally used in clinical settings where the goal is to assess no treatment effect on a high-dimensional outcome in a randomized experiment.", "labels": [], "entities": []}, {"text": "In our setting, we assume there exists some unknown distribution W from which our constructed word embeddings {w 1 , . .", "labels": [], "entities": []}, {"text": ", w n } are \"sampled\" from.", "labels": [], "entities": []}, {"text": "Given two sets of word embeddings, cross-match tests whether the underlying distribution from which the embeddings were \"sampled\" are identical or not.", "labels": [], "entities": []}, {"text": "The test uses optimal non-bipartite matching to pair vectors from both sets of embeddings based on distance (e.g. a vector will be paired with it's nearest neighbor based on some distance metric).", "labels": [], "entities": []}, {"text": "The cross-match test statistic C is the number of times that a vector from one set is paired with a vector from another.", "labels": [], "entities": []}, {"text": "The null hypothesis assumes that the vectors were sampled from the same distribution and rejects for small values of C.", "labels": [], "entities": []}, {"text": "Thus, a large number of cross-matches between two sets of word embeddings suggests that they are from the same embedding distribution.", "labels": [], "entities": []}, {"text": "Using cross-match, we propose two illustrative examples of intrinsic evaluation.", "labels": [], "entities": []}, {"text": "First, we use pretrained word vectors (trained on Wikipedia using the skip-gram model in) from Facebook's fastText library for several languages to calculate the cross-match statistic for several language pairs.", "labels": [], "entities": []}, {"text": "We hypothesize that for linguistically similar languages, a larger statistic will be observed.", "labels": [], "entities": []}, {"text": "Secondly, we use cross-match to assess the statistical significant of word embedding models.", "labels": [], "entities": []}, {"text": "We consider several well known models trained on the same corpus and use crossmatch to assess whether the respective word vector representations are statistically significantly different.", "labels": [], "entities": []}, {"text": "We hypothesize that the number of crossmatches between two different embedding models is small, thus suggesting that they capture fundamentally different linguistic aspects of the corpus.", "labels": [], "entities": []}, {"text": "This paper is organized as follows: Section 2 introduces the cross-match test in detail.", "labels": [], "entities": []}, {"text": "Experiments on embedding similarity and evaluation are described in Section 3.", "labels": [], "entities": []}, {"text": "We discuss extensions and conclude in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the following experiments, we demonstrate two different illustrative examples of the cross-match test.", "labels": [], "entities": []}, {"text": "Our objective is to show the effectiveness of cross-match as a general tool for intrinsic evaluation of word embedding vectors.", "labels": [], "entities": []}, {"text": "In this experiment, we use cross-match to assess the statistical significance of word embedding models.", "labels": [], "entities": []}, {"text": "Despite the popularity of various different embedding models) it is not always clear whether one model represents a statistically significant improvement to other existing models (it maybe that all of them capture largely similar features of the text).", "labels": [], "entities": []}, {"text": "We consider four popular word embedding models: word2vec Skip-gram, word2vec CBOW, Glove and fastText all trained on the same English wikipedia corpus.", "labels": [], "entities": []}, {"text": "Once again we take samples of size 200 from each method, caluclate the p-value between two pairs of methods using cross-match and then report the average p-value across 500 repeated iterations.", "labels": [], "entities": []}, {"text": "The results in 3 show low p-values across all pairs of word embedding methods thus suggesting that they all seem to capture different aspects of the corpus they are modeling.", "labels": [], "entities": []}, {"text": "In other words, using cross-match we have evidence to reject the null hypothesis that the vectors derived from any pair of models come from the same word embedding distribution.", "labels": [], "entities": []}, {"text": "Lastly, we note that there are at present some computational constraints in performing the crossmatch test.", "labels": [], "entities": []}, {"text": "There exists a bottleneck in the calculation of the optimal non-bipartite matching and this makes performing the test for larger sample sizes currently intractable.", "labels": [], "entities": []}, {"text": "However, we feel confident that this software issue can be easily overcome by writing custom routines (as opposed to using existing open-source code) and parallelizing the problem.", "labels": [], "entities": []}, {"text": "As a result of our limited sample size, we not that it is possible that the power of our hypothesis testis low and thus we maybe making type I errors (falsely rejecting the null).", "labels": [], "entities": []}, {"text": "Nonetheless our initial results seem promising and are inline with our expectations.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: fastText vectors cross-match statistics  for English-pair languages", "labels": [], "entities": [{"text": "fastText", "start_pos": 10, "end_pos": 18, "type": "DATASET", "confidence": 0.7236444354057312}]}, {"text": " Table 2: fastText vectors cross-match statistics  for Maltese-pair languages", "labels": [], "entities": [{"text": "fastText", "start_pos": 10, "end_pos": 18, "type": "DATASET", "confidence": 0.7510784864425659}]}, {"text": " Table 3: p-values calculated using Cross-match", "labels": [], "entities": [{"text": "Cross-match", "start_pos": 36, "end_pos": 47, "type": "DATASET", "confidence": 0.5475969314575195}]}]}