{"title": [{"text": "N-gram Model for Chinese Grammatical Error Diagnosis", "labels": [], "entities": [{"text": "Chinese Grammatical Error Diagnosis", "start_pos": 17, "end_pos": 52, "type": "TASK", "confidence": 0.8273481577634811}]}], "abstractContent": [{"text": "Detection and correction of Chinese grammatical errors have been two of major challenges for Chinese automatic grammatical error diagnosis.", "labels": [], "entities": [{"text": "Detection and correction of Chinese grammatical errors", "start_pos": 0, "end_pos": 54, "type": "TASK", "confidence": 0.6893499493598938}, {"text": "Chinese automatic grammatical error diagnosis", "start_pos": 93, "end_pos": 138, "type": "TASK", "confidence": 0.66863232254982}]}, {"text": "This paper presents an N-gram model for automatic detection and correction of Chinese grammatical errors in NLPTEA 2017 task.", "labels": [], "entities": [{"text": "automatic detection and correction of Chinese grammatical errors", "start_pos": 40, "end_pos": 104, "type": "TASK", "confidence": 0.7913668267428875}, {"text": "NLPTEA 2017 task", "start_pos": 108, "end_pos": 124, "type": "DATASET", "confidence": 0.9101468324661255}]}, {"text": "The experiment results show that the proposed method is good at correction of Chinese grammatical errors.", "labels": [], "entities": [{"text": "correction of Chinese grammatical errors", "start_pos": 64, "end_pos": 104, "type": "TASK", "confidence": 0.8409942626953125}]}], "introductionContent": [{"text": "The goal of the NLPTEA 2017 shared task   Our work in this paper uses an N-gram LM to detect and correct possible spelling errors.", "labels": [], "entities": [{"text": "NLPTEA 2017 shared task", "start_pos": 16, "end_pos": 39, "type": "DATASET", "confidence": 0.7594272047281265}]}, {"text": "And we also do word segmentation in a pre-processing stage which can improve the system performance.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.7642775475978851}]}, {"text": "In our model, we first make word and character segmentation of the text.", "labels": [], "entities": [{"text": "word and character segmentation", "start_pos": 28, "end_pos": 59, "type": "TASK", "confidence": 0.6480808779597282}]}, {"text": "Second, the processed  The N-gram model () is one of the most common mathematical models in natural language processing.", "labels": [], "entities": []}, {"text": "It is defined as: the assump- and then the probability of an element W i is only related to the preceding N-1 elements: Therefore, the N-gram model can be regarded as an N-1 Markov chain.", "labels": [], "entities": []}, {"text": "According to Markov stochastic process, the probability of symbol string S = W 1 W 2 \u00b7 \u00b7 \u00b7 W n can be calculated by the initial probability distribution and the transfer probability as follows: where P(W 1 ) can be considered as an initial prob- can be regarded as a state transition probability.", "labels": [], "entities": []}, {"text": "It can be seen that the bigger the N is, the closer the word order is to the real word, which produces better results.", "labels": [], "entities": []}, {"text": "However, in practical ap-", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}