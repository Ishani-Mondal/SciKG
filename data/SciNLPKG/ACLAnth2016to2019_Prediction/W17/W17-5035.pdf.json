{"title": [{"text": "Simplifying metaphorical language for young readers: A corpus study on news text", "labels": [], "entities": [{"text": "Simplifying metaphorical language", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.9297093351682028}]}], "abstractContent": [{"text": "The paper presents first results of an ongoing project on text simplification focus-ing on linguistic metaphors.", "labels": [], "entities": [{"text": "text simplification focus-ing on linguistic metaphors", "start_pos": 58, "end_pos": 111, "type": "TASK", "confidence": 0.7609299023946127}]}, {"text": "Based on an analysis of a parallel corpus of news text professionally simplified for different grade levels, we identify six types of simplification choices falling into two broad categories: preserving metaphors or dropping them.", "labels": [], "entities": []}, {"text": "An annotation study on almost 300 source sentences with metaphors (grade level 12) and their simplified counterparts (grade 4) is conducted.", "labels": [], "entities": []}, {"text": "The results show that most metaphors are preserved and when they are dropped, the semantic content tends to be preserved rather than dropped, however, it is reworded without metaphorical language.", "labels": [], "entities": []}, {"text": "In general , some of the expected tendencies in complexity reduction, measured with psy-cholinguistic variables linked to metaphor comprehension, are observed, suggesting good prospect for machine learning-based metaphor simplification.", "labels": [], "entities": [{"text": "complexity reduction", "start_pos": 48, "end_pos": 68, "type": "TASK", "confidence": 0.6922920495271683}, {"text": "machine learning-based metaphor simplification", "start_pos": 189, "end_pos": 235, "type": "TASK", "confidence": 0.7039447575807571}]}, {"text": "1 Motivation and problem statement Text simplification is the process of meaning preserving reduction of discourse complexity whose purpose is to adapt text for specific populations of readers, for instance, children or language learners.", "labels": [], "entities": [{"text": "Text simplification", "start_pos": 35, "end_pos": 54, "type": "TASK", "confidence": 0.7221237272024155}, {"text": "meaning preserving reduction of discourse complexity", "start_pos": 73, "end_pos": 125, "type": "TASK", "confidence": 0.8032839198907217}]}, {"text": "The idea has been around since \"My Weekly Reader\" in the 1920s and Palmer's work (1932) and over the past 20 years has attracted attention of the computational linguistics community.", "labels": [], "entities": [{"text": "My Weekly Reader\"", "start_pos": 32, "end_pos": 49, "type": "DATASET", "confidence": 0.9226708561182022}]}, {"text": "While broadly interpreted \"lexical simplification\"-in general understood as substitution of \"difficult\" words with \"simpler\" ones-is a common component of automated simplification systems (see, for instance, (Siddharthan, 2014)), studies of text simplification dedicated to specific lexis-related semantic phenomena are lacking.", "labels": [], "entities": [{"text": "lexical simplification\"-", "start_pos": 27, "end_pos": 51, "type": "TASK", "confidence": 0.8237646420796713}, {"text": "text simplification", "start_pos": 241, "end_pos": 260, "type": "TASK", "confidence": 0.6945046186447144}]}, {"text": "One class of such understudied phenomena are those related to figurative language; a surprising gap in the simplification research considering that metaphors have been shown to cause difficulties in text comprehension and that developing metaphor interpretation competence is a complex developmental process (for an overview, see, for instance, (Winner, 1997)).", "labels": [], "entities": [{"text": "metaphor interpretation competence", "start_pos": 238, "end_pos": 272, "type": "TASK", "confidence": 0.7843553225199381}]}, {"text": "Since automated systems are trained on corpora of simplified text, understanding patterns of metaphor simplification based on corpus data could help improve simplification models.", "labels": [], "entities": []}, {"text": "In this paper we present a study that is our first step in this direction.", "labels": [], "entities": []}, {"text": "We analyze linguistic metaphors in a corpus of news texts professionally simplified for different grade levels.", "labels": [], "entities": []}, {"text": "While editors' guidelines instructed to avoid vivid metaphors, such as \"paint into a corner\", our goal was to find out whether, and if so, how, linguistic metaphors in general are simplified by professional editors.", "labels": [], "entities": []}, {"text": "Since ultimately we want to build automated metaphor simplification models, the purpose of this study is to investigate whether metaphors in a corpus of professionally simplified text, that is, potential training data, are simplified in systematic ways.", "labels": [], "entities": []}, {"text": "Specifically, we were interested in two questions: 1) What types of discourse modifications do editors perform when simplifying metaphorical language?", "labels": [], "entities": []}, {"text": "(in other words, whether a well-defined set of classes for the metaphor simplification task can be specified).", "labels": [], "entities": []}, {"text": "2) Do professional editors simplify metaphor phenomena in systematic ways?", "labels": [], "entities": []}, {"text": "(if not, training simplification models using machine learning based on corpus data may not be promising).", "labels": [], "entities": []}, {"text": "The paper's structure follows the data-driven methodology adopted for this study: We first define the criteria used to identify the phenomenon in question: linguistic metaphor.", "labels": [], "entities": [{"text": "linguistic metaphor", "start_pos": 156, "end_pos": 175, "type": "TASK", "confidence": 0.7409377694129944}]}, {"text": "Next, we present 313 the setup of an annotation study and a typology of simplification choices derived based on an analysis of a corpus of simplified news text.", "labels": [], "entities": []}, {"text": "Finally, we present results of an exploratory analysis of the annotated data.", "labels": [], "entities": []}, {"text": "2 Data 2.1 The source corpus Our data comes from Newsela, 1 a company producing professionally simplified news articles in English and Spanish intended for classroom use.", "labels": [], "entities": []}, {"text": "Each Newsela article is available at 5 reading levels spanning grades 2 through 12 of the US school system (elementary school (grades K-4), middle school (grades 5-8), and high school (grades 9-12)).", "labels": [], "entities": [{"text": "Newsela article", "start_pos": 5, "end_pos": 20, "type": "DATASET", "confidence": 0.929756373167038}]}, {"text": "Two levels were used for this first study: the source articles (we will refer to this version as V0) and the most simplified version (V4), since between these versions we expect to see most differences.", "labels": [], "entities": []}, {"text": "2 Documents were sampled from a subset of Newsela compiled by Xu et al.", "labels": [], "entities": [{"text": "Newsela compiled", "start_pos": 42, "end_pos": 58, "type": "DATASET", "confidence": 0.942939817905426}]}, {"text": "This is a parallel corpus of 1130 documents from the English portion of Newsela where each article has been automatically aligned sentence-wise with the four simplified versions using Jaccard similarity; for details on the aligned corpus see (Xu et al., 2015).", "labels": [], "entities": [{"text": "English portion of Newsela", "start_pos": 53, "end_pos": 79, "type": "DATASET", "confidence": 0.7331317514181137}]}, {"text": "2.2 Sample selection The sample of V0 (source) and V4 (simplified) sentences was drawn from the Xu et al.'s corpus as follows: As shown in Figure 1, different Newsela versions span multiple unevenly distributed grade levels.", "labels": [], "entities": [{"text": "Xu et al.'s corpus", "start_pos": 96, "end_pos": 114, "type": "DATASET", "confidence": 0.830318291982015}]}, {"text": "In order to avoid effects due to differences between grade levels within versions, from V0 only articles at grade level 12 were used and from V4 only articles at grade level 4 (the largest subsets).", "labels": [], "entities": []}, {"text": "One sentence from each V0 document was selected with its corresponding V4 sentence(s); only sentences that were not identical between V0 and V4 were included in the sample.", "labels": [], "entities": []}, {"text": "Sampling was randomized across all documents to avoid effects due to specific editors' decisions.", "labels": [], "entities": [{"text": "Sampling", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.9609975218772888}]}, {"text": "This resulted in 582 V0 sentences.", "labels": [], "entities": [{"text": "V0", "start_pos": 21, "end_pos": 23, "type": "METRIC", "confidence": 0.7928136587142944}]}, {"text": "Automatic sentence alignments between the versions were manually checked and corrected where necessary; for instance , unaligned V4 sentences were linked appropriately , as in the following example (\"i\" marks 1 https://newsela.com 2 Analysis of metaphor simplification across other levels is planned as further work.", "labels": [], "entities": [{"text": "sentence alignments", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.7535068094730377}]}], "introductionContent": [], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Metaphor simplification types.", "labels": [], "entities": []}, {"text": " Table 3: Distribution of simplification types", "labels": [], "entities": []}]}