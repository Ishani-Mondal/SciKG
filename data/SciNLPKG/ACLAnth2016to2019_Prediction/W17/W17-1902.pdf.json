{"title": [{"text": "Automated WordNet Construction Using Word Embeddings", "labels": [], "entities": [{"text": "Automated WordNet Construction", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.6207071244716644}]}], "abstractContent": [{"text": "We present a fully unsupervised method for automated construction of WordNets based upon recent advances in distribu-tional representations of sentences and word-senses combined with readily available machine translation tools.", "labels": [], "entities": []}, {"text": "The approach requires very few linguistic resources and is thus extensible to multiple target languages.", "labels": [], "entities": []}, {"text": "To evaluate our method we construct two 600-word test sets for word-to-synset matching in French and Russian using native speakers and evaluate the performance of our method along with several other recent approaches.", "labels": [], "entities": [{"text": "word-to-synset matching", "start_pos": 63, "end_pos": 86, "type": "TASK", "confidence": 0.6945428550243378}]}, {"text": "Our method exceeds the best language-specific and multilingual automated WordNets in F-score for both languages.", "labels": [], "entities": [{"text": "F-score", "start_pos": 85, "end_pos": 92, "type": "METRIC", "confidence": 0.9961702227592468}]}, {"text": "The databases we construct for French and Russian, both languages without large publicly available manually constructed WordNets, will be publicly released along with the test sets.", "labels": [], "entities": []}], "introductionContent": [{"text": "A WordNet is a lexical database for languages based upon a structure introduced by the Princeton WordNet (PWN) for English in which sets of cognitive synonyms, or synsets, are interconnected with arcs standing for semantic and lexical relations between them.", "labels": [], "entities": [{"text": "Princeton WordNet (PWN)", "start_pos": 87, "end_pos": 110, "type": "DATASET", "confidence": 0.9013980031013489}]}, {"text": "WordNets are widely used in computational linguistics, information retrieval, and machine translation.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 55, "end_pos": 76, "type": "TASK", "confidence": 0.8224719762802124}, {"text": "machine translation", "start_pos": 82, "end_pos": 101, "type": "TASK", "confidence": 0.8152004778385162}]}, {"text": "Constructing one by hand is time-consuming and difficult, motivating a search for automated or semiautomated methods.", "labels": [], "entities": []}, {"text": "We present an unsupervised method based on word embeddings and wordsense induction and build and evaluate WordNets for French and Russian.", "labels": [], "entities": []}, {"text": "Our approach needs only a large unannotated corpus like Wikipedia in the target language and machine translation (MT) between that language and English.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 93, "end_pos": 117, "type": "TASK", "confidence": 0.8165128588676452}]}, {"text": "A standard minimal WordNet design is to have synsets connected by hyponym-hypernym relations and linked back to PWN.", "labels": [], "entities": []}, {"text": "This allows for applications to cross-lingual tasks and rests on the assumption that synsets and their relations are invariant across languages.", "labels": [], "entities": []}, {"text": "For example, while all senses of English word tie may not lineup with all senses of French word cravate, the sense \"necktie\" will exist in both languages and be represented by the same synset.", "labels": [], "entities": []}, {"text": "Thus MT is often used for automated WordNets to generate a set of candidate synsets for each word win the target language by getting a set of English translations of wand using them to query PWN (we will refer to this as MT+PWN).", "labels": [], "entities": [{"text": "MT", "start_pos": 5, "end_pos": 7, "type": "TASK", "confidence": 0.6812295913696289}]}, {"text": "The number of candidate synsets produced may not be small, even as large as a hundred for some polysemous verbs.", "labels": [], "entities": []}, {"text": "Thus one needs away to select from the candidates of w those synsets that are its true senses.", "labels": [], "entities": []}, {"text": "The main contributions of this paper is anew word embedding-based method for matching words to synsets and the release of two large wordsynset matching test sets for French and Russian.", "labels": [], "entities": []}, {"text": "Though there has been some work using wordvectors for WordNets (see Section 2), the resulting databases have been small, containing less than 1000 words.", "labels": [], "entities": [{"text": "WordNets", "start_pos": 54, "end_pos": 62, "type": "DATASET", "confidence": 0.9322672486305237}]}, {"text": "Using embeddings for this task is challenging due to the need for good ways to use PWN synset information and account for the breakdown of cosine-similarity for polysemous words.", "labels": [], "entities": []}, {"text": "We approach the first issue by representing synset information using recent work on sentenceembeddings by.", "labels": [], "entities": []}, {"text": "To handle polysemy we devise a sense clustering scheme based on Word Sense Induction (WSI) via linear alge-bra over word-vectors ().", "labels": [], "entities": [{"text": "sense clustering", "start_pos": 31, "end_pos": 47, "type": "TASK", "confidence": 0.7089904397726059}, {"text": "Word Sense Induction (WSI)", "start_pos": 64, "end_pos": 90, "type": "TASK", "confidence": 0.5624005744854609}]}, {"text": "We demonstrate how this sense purification procedure effectively combines clustering with embeddings, thus being applicable to many word-sense disambiguation (WSD) and induction-related tasks.", "labels": [], "entities": [{"text": "sense purification", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.6978848427534103}, {"text": "word-sense disambiguation (WSD)", "start_pos": 132, "end_pos": 163, "type": "TASK", "confidence": 0.8141873002052307}]}, {"text": "Using both techniques yields a WordNet method that outperforms other language-independent methods as well as language-specific approaches such as WOLF, the French WordNet used by the Natural Language ToolKit.", "labels": [], "entities": []}, {"text": "Our second contribution is the creation of two new 600-word test sets in French and Russian that are larger and more comprehensive than any currently available, containing 200 each of nouns, verbs, and adjectives.", "labels": [], "entities": []}, {"text": "They are constructed by presenting native speakers with all candidate synsets produced as above by MT+PWN and treating the senses they pick out as \"ground truth\" for measuring precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 176, "end_pos": 185, "type": "METRIC", "confidence": 0.9976117610931396}, {"text": "recall", "start_pos": 190, "end_pos": 196, "type": "METRIC", "confidence": 0.9896193146705627}]}, {"text": "The motivation behind separating by part-of-speech (POS) is that nouns are often easier than adjectives and verbs, so reporting one number -as done by some past work -allows high noun performance to mask low performance on adjectives and verbs.", "labels": [], "entities": [{"text": "separating by part-of-speech (POS)", "start_pos": 22, "end_pos": 56, "type": "TASK", "confidence": 0.8973544736703237}]}, {"text": "Using these test sets, we can begin addressing the difficulties of evaluation for non-English automated WordNets due to the use of different and unreported test data, incompatible metrics (e.g. matching synsets to words vs. retrieving words for synsets), and differing cross-lingual dictionaries.", "labels": [], "entities": []}, {"text": "In this paper we use the test sets to evaluate our method and several other automated WordNets.", "labels": [], "entities": [{"text": "WordNets", "start_pos": 86, "end_pos": 94, "type": "DATASET", "confidence": 0.9384893178939819}]}], "datasetContent": [{"text": "We evaluate our method's accuracy and coverage by constructing and testing WordNets for French and Russian.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9991476535797119}, {"text": "coverage", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9837424755096436}]}, {"text": "For both we train 300-dimensional SN word embeddings (Arora et al., 2016b) on co-occurrences of words occurring at least 1000 times, or having candidate PWN synsets and occurring at least 100 times, in the lemmatized Wikipedia corpus.", "labels": [], "entities": [{"text": "Wikipedia corpus", "start_pos": 217, "end_pos": 233, "type": "DATASET", "confidence": 0.8342313468456268}]}, {"text": "This yields |V | \u2248 50000.", "labels": [], "entities": []}, {"text": "For Linear-WSI we run sparse coding with sparsity s = 4 and basis-size k = 2000 and use set-size n = 5 for purification.", "labels": [], "entities": []}, {"text": "To get candidate synsets we use Google and Microsoft Translators and the dictionary of the translation company ECTACO, while for sentence-length MT we use Microsoft.", "labels": [], "entities": [{"text": "ECTACO", "start_pos": 111, "end_pos": 117, "type": "DATASET", "confidence": 0.8721157908439636}, {"text": "MT", "start_pos": 145, "end_pos": 147, "type": "TASK", "confidence": 0.8107442855834961}]}, {"text": "We report the evaluation of methods in Section 3 in alongside evaluations of UWN (, OWM, and WOLF.", "labels": [], "entities": [{"text": "UWN", "start_pos": 77, "end_pos": 80, "type": "DATASET", "confidence": 0.8879947662353516}, {"text": "WOLF", "start_pos": 93, "end_pos": 97, "type": "DATASET", "confidence": 0.602947473526001}]}, {"text": "Parameters \u03b1 and \u03b2 were tuned to maximize the micro-averaged F .5 -score .25\u00b7Precision+Recall , used instead of F 1 to prioritize precision, which is often more important for application purposes.", "labels": [], "entities": [{"text": "F .5 -score", "start_pos": 61, "end_pos": 72, "type": "METRIC", "confidence": 0.9436476826667786}, {"text": "Precision+Recall", "start_pos": 77, "end_pos": 93, "type": "METRIC", "confidence": 0.8876778880755106}, {"text": "precision", "start_pos": 130, "end_pos": 139, "type": "METRIC", "confidence": 0.9986129999160767}]}, {"text": "Our synset representation method (Section 3.2) exceeds the similarity baseline by 6% in F .5 -score for French and 10% for Russian.", "labels": [], "entities": [{"text": "similarity baseline", "start_pos": 59, "end_pos": 78, "type": "METRIC", "confidence": 0.9474436044692993}, {"text": "F .5 -score", "start_pos": 88, "end_pos": 99, "type": "METRIC", "confidence": 0.9627466559410095}]}, {"text": "For French it is competitive with the best other WordNet (WOLF) and in both languages exceeds both multi-lingual WordNets.", "labels": [], "entities": [{"text": "WordNet (WOLF)", "start_pos": 49, "end_pos": 63, "type": "DATASET", "confidence": 0.8159074783325195}]}, {"text": "Improving this method via Linear-WSI (Section 3.3) leads to 2% improvement in F .5 -score for French and 1% for Russian.", "labels": [], "entities": [{"text": "F .5 -score", "start_pos": 78, "end_pos": 89, "type": "METRIC", "confidence": 0.9864355683326721}]}, {"text": "Our methods also perform best in F 1 -score and Core coverage.", "labels": [], "entities": [{"text": "F 1 -score", "start_pos": 33, "end_pos": 43, "type": "METRIC", "confidence": 0.9556874632835388}]}, {"text": "As expected from a Wiktionary-scraping method, OMW achieves the best precision across languages, although it and UWN have low recall and Core coverage.", "labels": [], "entities": [{"text": "precision", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9988046884536743}, {"text": "UWN", "start_pos": 113, "end_pos": 116, "type": "DATASET", "confidence": 0.8986064195632935}, {"text": "recall", "start_pos": 126, "end_pos": 132, "type": "METRIC", "confidence": 0.9992576241493225}]}, {"text": "The performance of our best method for French exceeds that of WOLF in F .5 -score across POS while achieving similar coverage.", "labels": [], "entities": [{"text": "WOLF", "start_pos": 62, "end_pos": 66, "type": "METRIC", "confidence": 0.6240327954292297}, {"text": "F .5 -score", "start_pos": 70, "end_pos": 81, "type": "METRIC", "confidence": 0.9548614144325256}, {"text": "coverage", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.963351845741272}]}, {"text": "WOLF's recall performance is markedly lower than the evaluation in); we believe this stems from our use of words matched to Core synsets, not random words, leading to a more difficult test set as common words are more-polysemous and have more synsets to retrieve.", "labels": [], "entities": [{"text": "recall", "start_pos": 7, "end_pos": 13, "type": "METRIC", "confidence": 0.9961493015289307}]}, {"text": "There is no comparable automated Russian-only WordNet, with only semi-automated and incomplete efforts).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 46, "end_pos": 53, "type": "DATASET", "confidence": 0.7100404500961304}]}, {"text": "Comparing across POS, we do best on nouns and worst on verbs, likely due to the greater polysemy of verbs.", "labels": [], "entities": []}, {"text": "Between languages, performance is similar for adjectives but slightly worse on Russian nouns and much worse on Russian verbs.", "labels": [], "entities": []}, {"text": "The discrepancy in verbs can be explained by a difference in treating the reflexive case and aspectual variants due to the grammatical complexity of Russian verbs.", "labels": [], "entities": []}, {"text": "In French, making a verb reflexive requires adding a word while in Russian the verb itself changes, e.g. to wash\u2192to wash oneself is laver\u2192se laver in French but \u043c\u044b\u0442\u044c\u2192\u043c\u044b\u0442\u044c\u0441\u044f in Russian.", "labels": [], "entities": []}, {"text": "Thus we do not distinguish the reflexive case for French as the token found is the same but for Russian we do, so both \u043c\u044b\u0442\u044c and \u043c\u044b\u0442\u044c-\u0441\u044f may appear and have distinct synset matches.", "labels": [], "entities": []}, {"text": "Thus matching Russian verbs is challenging as the reflexive usage of a verb is often contextually similar to the non-reflexive usage.", "labels": [], "entities": []}, {"text": "Another complication for Russian verbs is due to aspectual verb pairs; thus to do has aspects (\u0434\u0435\u043b\u0430\u0442\u044c, \u0441\u0434\u0435\u043b\u0430\u0442\u044c) in Russian that are treated as distinct verbs while in French these are just different tenses of the verb faire.", "labels": [], "entities": []}, {"text": "Both factors pose challenges for differentiating Russian verb senses by a distributional model.", "labels": [], "entities": []}, {"text": "Overall however the method is shown to be robust to how close the target language is to English, with nouns and adjectives performing well in both languages and the difference for verbs stemming from an intrinsic quality rather than dissimilarity with English.", "labels": [], "entities": []}, {"text": "This can be further examined by testing the method on a non-European language.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: French WordNet Results", "labels": [], "entities": [{"text": "French WordNet", "start_pos": 10, "end_pos": 24, "type": "DATASET", "confidence": 0.8979245722293854}]}, {"text": " Table 2: Russian WordNet Results", "labels": [], "entities": [{"text": "Russian WordNet", "start_pos": 10, "end_pos": 25, "type": "DATASET", "confidence": 0.7931619584560394}]}]}