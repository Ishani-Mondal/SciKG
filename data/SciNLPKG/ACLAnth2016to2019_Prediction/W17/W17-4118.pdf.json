{"title": [{"text": "A General-Purpose Tagger with Convolutional Neural Networks", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a general-purpose tagger based on convolutional neural networks (CNN), used for both composing word vectors and encoding context information.", "labels": [], "entities": []}, {"text": "The CNN tagger is robust across different tagging tasks: without task-specific tuning of hyper-parameters, it achieves state-of-the-art results in part-of-speech tagging, morphological tagging and supertagging.", "labels": [], "entities": [{"text": "CNN tagger", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.7402882874011993}, {"text": "part-of-speech tagging", "start_pos": 147, "end_pos": 169, "type": "TASK", "confidence": 0.7385467886924744}, {"text": "morphological tagging", "start_pos": 171, "end_pos": 192, "type": "TASK", "confidence": 0.7203173041343689}]}, {"text": "The CNN tagger is also robust against the out-of-vocabulary problem; it performs well on artificially unnormalized texts.", "labels": [], "entities": [{"text": "CNN tagger", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.6664919853210449}]}], "introductionContent": [{"text": "Recently, character composition models have shown great success in many NLP tasks, mainly because of their robustness in dealing with outof-vocabulary (OOV) words by capturing subword informations.", "labels": [], "entities": []}, {"text": "Among the character composition models, bidirectional long short-term memory (LSTM) models and convolutional neural networks (CNN) are widely applied in many tasks, e.g. part-of-speech (POS) tagging, named entity recognition (dos, language modeling (, machine translation and dependency parsing.", "labels": [], "entities": [{"text": "character composition", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.7525268197059631}, {"text": "part-of-speech (POS) tagging", "start_pos": 170, "end_pos": 198, "type": "TASK", "confidence": 0.6119053900241852}, {"text": "named entity recognition", "start_pos": 200, "end_pos": 224, "type": "TASK", "confidence": 0.6463801562786102}, {"text": "language modeling", "start_pos": 231, "end_pos": 248, "type": "TASK", "confidence": 0.6878947168588638}, {"text": "machine translation", "start_pos": 252, "end_pos": 271, "type": "TASK", "confidence": 0.767788290977478}, {"text": "dependency parsing", "start_pos": 276, "end_pos": 294, "type": "TASK", "confidence": 0.7260155975818634}]}, {"text": "In this paper, we present a state-of-the-art general-purpose tagger that uses CNNs both to compose word representations from characters and to encode context information for tagging.", "labels": [], "entities": []}, {"text": "We show that the CNN model is more capable than the LSTM model for both functions, and more stable for unseen or unnormalized words, which is the main benefit of character composition models.", "labels": [], "entities": []}, {"text": "compared the performance of CNN and LSTM as character composition model for dependency parsing, and concluded that CNN performs better than LSTM.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.8535263538360596}]}, {"text": "In this paper, we show that this is also the case for POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 54, "end_pos": 65, "type": "TASK", "confidence": 0.8308809697628021}]}, {"text": "Furthermore, we extend the scope to morphological tagging and supertagging, in which the tag set is much larger or long-distance dependencies between words are more important.", "labels": [], "entities": [{"text": "morphological tagging", "start_pos": 36, "end_pos": 57, "type": "TASK", "confidence": 0.657795637845993}]}, {"text": "In these three tagging tasks, we compare our tagger with the bilstm-aux tagger) and the CRF-based morphological tagger MarMot) as baselines.", "labels": [], "entities": [{"text": "CRF-based morphological tagger MarMot", "start_pos": 88, "end_pos": 125, "type": "TASK", "confidence": 0.43826813250780106}]}, {"text": "The CNN tagger shows robust performance across the three tasks, and achieves the highest average accuracies in all tasks.", "labels": [], "entities": [{"text": "CNN tagger", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.8880108892917633}, {"text": "accuracies", "start_pos": 97, "end_pos": 107, "type": "METRIC", "confidence": 0.9211525917053223}]}, {"text": "It considerably outperforms the LSTM tagger in morphological tagging and both baselines in supertagging.", "labels": [], "entities": [{"text": "LSTM tagger", "start_pos": 32, "end_pos": 43, "type": "TASK", "confidence": 0.6493939161300659}, {"text": "morphological tagging", "start_pos": 47, "end_pos": 68, "type": "TASK", "confidence": 0.6371084898710251}]}, {"text": "To test the robustness of the taggers against the OOV problem, we also conduct experiments on unnormalized text by artificially corrupting words in the normal dev sets.", "labels": [], "entities": []}, {"text": "With the increasing degree of unnormalization, the performance of the CNN tagger degrades much slower than the other two, which suggests that the CNN tagger is more robust against unnormalized text.", "labels": [], "entities": []}, {"text": "Therefore we conclude that our CNN tagger is a robust state-of-the-art general-purpose tagger that can effectively compose word representation from characters and encode context information.", "labels": [], "entities": [{"text": "CNN tagger", "start_pos": 31, "end_pos": 41, "type": "TASK", "confidence": 0.6863808184862137}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Tagging accuracies of the three taggers in the three tasks on the test sets of UD 1.2, the highest  accuracy for each task on each language is marked in boldface.", "labels": [], "entities": [{"text": "test sets of UD 1.2", "start_pos": 76, "end_pos": 95, "type": "DATASET", "confidence": 0.6701331436634064}, {"text": "accuracy", "start_pos": 110, "end_pos": 118, "type": "METRIC", "confidence": 0.9981811046600342}]}, {"text": " Table 2: Tagging accuracy on the WSJ test set.", "labels": [], "entities": [{"text": "Tagging", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9820043444633484}, {"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9884063005447388}, {"text": "WSJ test set", "start_pos": 34, "end_pos": 46, "type": "DATASET", "confidence": 0.9553847710291544}]}]}