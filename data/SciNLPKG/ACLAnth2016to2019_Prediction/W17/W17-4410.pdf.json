{"title": [{"text": "The Effect of Error Rate in Artificially Generated Data for Automatic Preposition and Determiner Correction", "labels": [], "entities": [{"text": "Error Rate", "start_pos": 14, "end_pos": 24, "type": "METRIC", "confidence": 0.895137757062912}]}], "abstractContent": [{"text": "In this research we investigate the impact of mismatches in the density and type of error between training and test data on a neural system correcting preposition and determiner errors.", "labels": [], "entities": []}, {"text": "We use synthetically produced training data to control error density and type, and \"real\" error data for testing.", "labels": [], "entities": []}, {"text": "Our results show it is possible to combine error types, although prepositions and determiners behave differently in terms of how much error should be artificially introduced into the training data in order to get the best results.", "labels": [], "entities": []}], "introductionContent": [{"text": "The field of Grammatical Error Correction (GEC) is currently dominated by neural translation models, specifically sequence-to-sequence translation.", "labels": [], "entities": [{"text": "Grammatical Error Correction (GEC)", "start_pos": 13, "end_pos": 47, "type": "TASK", "confidence": 0.8384178827206293}, {"text": "neural translation", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.7614522278308868}, {"text": "sequence-to-sequence translation", "start_pos": 114, "end_pos": 146, "type": "TASK", "confidence": 0.7142304182052612}]}, {"text": "However, despite offering substantial improvements on the well-established statistical machine translation approach to GEC, neural networks come with their own challenges.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 75, "end_pos": 106, "type": "TASK", "confidence": 0.625430683294932}]}, {"text": "Firstly, neural models require a large amount of training data, however the amount of annotated learner English consisting of source (original text) and target (corrected text) is low.", "labels": [], "entities": []}, {"text": "Models are at risk of overfitting, simply because the volume of data is not high enough.", "labels": [], "entities": []}, {"text": "Secondly, the data that has been used up until now does not generalise very well across different test sets.", "labels": [], "entities": []}, {"text": "This means that there has been some success in correcting errors, but only from test sets that are in some sense similar to the training data.", "labels": [], "entities": [{"text": "correcting", "start_pos": 47, "end_pos": 57, "type": "TASK", "confidence": 0.9212700724601746}]}, {"text": "Thirdly, it is generally unknown how erroneous the test data is, and if the training data has a different distribution of errors, it is likely that unwanted corrections will be made, or required corrections will be missed.", "labels": [], "entities": []}, {"text": "Currently, there is research into generating artificial data for training neural models, specifically data that resembles learner English (.", "labels": [], "entities": []}, {"text": "The artificial data is generated from monolingual sentences of grammatical English by systematically introducing noise into it.", "labels": [], "entities": []}, {"text": "This way, training data consisting of sentences with both \"incorrect\" and \"correct\" versions can be generated from monolingual data, which is easily accessible.", "labels": [], "entities": []}, {"text": "There is also evidence that artificially generated data can generalise a GEC system better than simply using manually procured correction data.", "labels": [], "entities": []}, {"text": "A third advantage of synthetically introducing noise into a corpus is the ability to control how much noise, and which noise, is introduced.", "labels": [], "entities": []}, {"text": "The first main question of our research is how the amount of noise introduced into the corpus affects a neural model's behaviour attest time with respect to mismatches in error density and error type between training and test data.", "labels": [], "entities": []}, {"text": "Artificial data lends itself to this kind of research, thanks to the control over the corpus.", "labels": [], "entities": []}, {"text": "Up until now, the effect of the amount of errors in the training corpus has only been explored with prepositions specifically.", "labels": [], "entities": []}, {"text": "We begin by extending this line of research to determiners.", "labels": [], "entities": []}, {"text": "The second research question is then: how do two different types of error interact?", "labels": [], "entities": []}, {"text": "It is quite possible that introducing many types of frequent grammatical errors one after the other would not create convincing artificial learner data, because several types of error can affect the same word, and a neural model may not be able to learn to combine them in this way.", "labels": [], "entities": []}], "datasetContent": [{"text": "Cahill et al. have made their revision data extracted from Wikipedia available for download, which is why it is appropriate to compare it to the revision data which is extracted from Lang-8.", "labels": [], "entities": [{"text": "Lang-8", "start_pos": 183, "end_pos": 189, "type": "DATASET", "confidence": 0.9675707221031189}]}, {"text": "Both sets of revision data are used to create two separate confusion sets for prepositions.", "labels": [], "entities": []}, {"text": "They are then used to create two sets of error corpora in which 20%, 40%, 60% and 80% of prepositions are altered according to the error introduction procedure detailed above.", "labels": [], "entities": []}, {"text": "To compare, revision data extracted from Lang-8 is also used to create error corpora containing the same amounts of prepositional error.", "labels": [], "entities": [{"text": "Lang-8", "start_pos": 41, "end_pos": 47, "type": "DATASET", "confidence": 0.8870078325271606}]}, {"text": "It is worth noting that Cahill et al.'s research does not include the empty \"NULL\" preposition, meaning that errors in which a preposition is missing are not accounted for.", "labels": [], "entities": []}, {"text": "By contrast, in our work we include every casein which a preposition is inserted, as well as replaced, although we do not deal with deletions.", "labels": [], "entities": []}, {"text": "Deleting prepositions which were inserted in the revision data simply follows the same procedure as replacements, where a preposition is replaced with the null preposition.", "labels": [], "entities": []}, {"text": "Inserting prepositions which were deleted in the revision data is much more difficult, as it is not clear wherein a sentence each preposition should be.", "labels": [], "entities": []}, {"text": "The use of context words before and after a deletion is being explored in more current research, but does not feature in these experiments.", "labels": [], "entities": []}, {"text": "This is nevertheless a major contribution, because insertions and deletions makeup a significant part of the errors.", "labels": [], "entities": []}, {"text": "In Lang-8, for example, there were 10054 corrections of prepositions, of which 4274 were insertions, and 2657 were deletions.", "labels": [], "entities": []}, {"text": "This means that replacements only consist of 31% percent of the errors.", "labels": [], "entities": []}, {"text": "We also use determiner revision data extracted from Lang-8 to create determiner errors in a similar fashion, with 20%, 40%, 60% and 80% of errors.", "labels": [], "entities": [{"text": "determiner revision", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.7219096422195435}]}, {"text": "A final set of synthetic error data is then generated where both prepositions and determiners are introduced into the same corpus, containing 20%, 40%, 60% and 80% of both kinds of error.", "labels": [], "entities": []}, {"text": "This is to investigate whether the GEC system is capable of dealing with two types of error at once.", "labels": [], "entities": [{"text": "GEC", "start_pos": 35, "end_pos": 38, "type": "DATASET", "confidence": 0.7862502932548523}]}, {"text": "In order to test the effects of mismatching error density and type between training and test data, each model is tested on specially created test sets with varying amounts of error in them.", "labels": [], "entities": []}, {"text": "found that the highest scores came from models both trained and tested on similar error rates.", "labels": [], "entities": []}, {"text": "Our research aims to build on this finding.", "labels": [], "entities": []}, {"text": "The first test set is made from Lang-8, which is also used to create the confusion sets for the training data.", "labels": [], "entities": []}, {"text": "Specifically, only the sentences with prepositions, determiners, and a mix of both in the revisions are used.", "labels": [], "entities": []}, {"text": "No other types of error are included.", "labels": [], "entities": [{"text": "error", "start_pos": 18, "end_pos": 23, "type": "METRIC", "confidence": 0.9684092402458191}]}, {"text": "These sentences are mixed with corrected sentences (where the revised sentence is used as both source and target) to varying degrees.", "labels": [], "entities": []}, {"text": "In each case, 1000 sentences of erroneous data are mixed with either 4000, 1500, 666, or 250 sentences of \"correct\" English, also taken from Lang-8.", "labels": [], "entities": [{"text": "Lang-8", "start_pos": 141, "end_pos": 147, "type": "DATASET", "confidence": 0.9671091437339783}]}, {"text": "This is in order to create test sets in which 20%, 40%, 60%, and 80% of sentences are erroneous, similar to the training data.", "labels": [], "entities": []}, {"text": "shows the test sets created out of the Lang-8 corpus.", "labels": [], "entities": [{"text": "Lang-8 corpus", "start_pos": 39, "end_pos": 52, "type": "DATASET", "confidence": 0.9674094617366791}]}, {"text": "The NUCLE corpus () was used as training and test sets for the) on GEC, and since then has been commonly used in the field for comparison with previous work.", "labels": [], "entities": [{"text": "NUCLE corpus", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.9606806933879852}, {"text": "GEC", "start_pos": 67, "end_pos": 70, "type": "DATASET", "confidence": 0.8024404644966125}]}, {"text": "The NUCLE corpus is used in our research in order to generate test sets from a different domain, despite those test sets being smaller.", "labels": [], "entities": [{"text": "NUCLE corpus", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.9527955651283264}]}, {"text": "Again, prepositions, determiners and a combination of both are extracted and mixed with corrected sentences from the same corpus.", "labels": [], "entities": []}, {"text": "Due to the smaller amount of relevant errors, as many sentences containing each error as possible are taken.", "labels": [], "entities": []}, {"text": "For prepositions, this amounts 332 sentences, for determiners, 595 sentences, and for both, 169 sentences.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Lang-8 Corpus test sets", "labels": [], "entities": [{"text": "Lang-8 Corpus test sets", "start_pos": 10, "end_pos": 33, "type": "DATASET", "confidence": 0.7059413269162178}]}, {"text": " Table 2: NUCLE Corpus test sets", "labels": [], "entities": [{"text": "NUCLE Corpus test sets", "start_pos": 10, "end_pos": 32, "type": "DATASET", "confidence": 0.7744746506214142}]}, {"text": " Table 3: GLEU score according to how much  preposition error in training data informed by  Lang-8, tested on test sets with varying amounts  of error from Lang-8 and NUCLE.", "labels": [], "entities": [{"text": "GLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9973083734512329}, {"text": "NUCLE", "start_pos": 167, "end_pos": 172, "type": "DATASET", "confidence": 0.96826171875}]}, {"text": " Table 5: GLEU score according to how much  combined preposition and determiner error in  training data informed by Lang-8, tested on test  sets with varying amounts of error from Lang-8  and NUCLE.", "labels": [], "entities": [{"text": "GLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9976356029510498}, {"text": "determiner error", "start_pos": 69, "end_pos": 85, "type": "METRIC", "confidence": 0.9501109719276428}, {"text": "NUCLE", "start_pos": 192, "end_pos": 197, "type": "DATASET", "confidence": 0.968342661857605}]}, {"text": " Table 6: GLEU score according to how much  combined preposition and determiner error in  training data informed by Lang-8, tested sepa- rately on NUCLE test sets with varying amounts  of determiner error, and then preposition error.", "labels": [], "entities": [{"text": "GLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.997678816318512}, {"text": "sepa- rately", "start_pos": 131, "end_pos": 143, "type": "METRIC", "confidence": 0.8362760742505392}, {"text": "NUCLE test sets", "start_pos": 147, "end_pos": 162, "type": "DATASET", "confidence": 0.9695941011110941}]}, {"text": " Table 7: GLEU score according to how much  preposition error (first 4 rows) or determiner er- ror (last 4 rows) in training data informed by Lang- 8, tested on test sets with varying amounts of com- bined determiner/preposition error from NUCLE.", "labels": [], "entities": [{"text": "GLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.997982382774353}, {"text": "determiner er- ror (last 4 rows)", "start_pos": 80, "end_pos": 112, "type": "METRIC", "confidence": 0.9224167002571954}, {"text": "Lang- 8", "start_pos": 142, "end_pos": 149, "type": "DATASET", "confidence": 0.7143846352895101}, {"text": "NUCLE", "start_pos": 240, "end_pos": 245, "type": "DATASET", "confidence": 0.9796517491340637}]}, {"text": " Table 8: GLEU score according to how much  preposition error in training data informed by  Wikipedia (first 4 rows) and Lang-8 (last 4 rows),  tested on test sets with varying amounts of prepo- sition error from Lang-8.", "labels": [], "entities": [{"text": "GLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9972636699676514}, {"text": "Wikipedia", "start_pos": 92, "end_pos": 101, "type": "DATASET", "confidence": 0.9498848915100098}, {"text": "Lang-8", "start_pos": 121, "end_pos": 127, "type": "DATASET", "confidence": 0.9243097305297852}]}]}