{"title": [{"text": "An open-source tool for negation detection: a maximum-margin approach", "labels": [], "entities": [{"text": "negation detection", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.9935977756977081}]}], "abstractContent": [{"text": "This paper presents an open-source toolkit for negation detection.", "labels": [], "entities": [{"text": "negation detection", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.9908508956432343}]}, {"text": "It identifies negation cues and their corresponding scope in either raw or parsed text using maximum-margin classification.", "labels": [], "entities": []}, {"text": "The system design draws on best practice from the existing literature on negation detection, aiming fora simple and portable system that still achieves competitive performance.", "labels": [], "entities": [{"text": "negation detection", "start_pos": 73, "end_pos": 91, "type": "TASK", "confidence": 0.9836703836917877}]}, {"text": "Pre-trained models and experimental results are provided for English.", "labels": [], "entities": []}], "introductionContent": [{"text": "The task of negation detection has recently seen quite a bit of interest in the NLP community, in part spurred by the availability of annotated data and evaluation software introduced by the shared tasks at and.", "labels": [], "entities": [{"text": "negation detection", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.9930612742900848}]}, {"text": "While many research-based systems have been developed, with the aim of exploring features and algorithms to advance the state-of-the-art in terms of performance), many of them are difficult to employ in practice, due to layered architectures and many dependencies, and furthermore, most are simply not made publicly available in the first place.", "labels": [], "entities": []}, {"text": "In this paper, we present an open-source portable toolkit for automatic negation detection, with experimental results reported for English.", "labels": [], "entities": [{"text": "negation detection", "start_pos": 72, "end_pos": 90, "type": "TASK", "confidence": 0.8840378224849701}]}, {"text": "The system is implemented in Python on top of PyStruct), a library for structured prediction based on a maximum-margin approach.", "labels": [], "entities": [{"text": "structured prediction", "start_pos": 71, "end_pos": 92, "type": "TASK", "confidence": 0.6733049005270004}]}, {"text": "The system implements two stages of negation analysis, namely cue detection, which detects words that signal negation, such as no, not and unfortunate, and scope resolution, which identifies the span of the sentence that is affected by the negation.", "labels": [], "entities": [{"text": "negation analysis", "start_pos": 36, "end_pos": 53, "type": "TASK", "confidence": 0.9760842025279999}, {"text": "cue detection", "start_pos": 62, "end_pos": 75, "type": "TASK", "confidence": 0.6815817356109619}, {"text": "scope resolution", "start_pos": 156, "end_pos": 172, "type": "TASK", "confidence": 0.6756981909275055}]}, {"text": "Our negation toolkit builds on existing libraries that are actively maintained and easy to install, and the source 1 is made freely available (GPL).", "labels": [], "entities": []}, {"text": "While we make pre-trained classifiers available (for English), users will also be able to train their own models.", "labels": [], "entities": []}, {"text": "The system design is based on best practices from previous work, in particular systems from the 2012 *SEM shared task.", "labels": [], "entities": [{"text": "SEM shared task", "start_pos": 102, "end_pos": 117, "type": "TASK", "confidence": 0.5160458286603292}]}, {"text": "In particular, we adopt the practice of solving scope resolution as a sequence labeling task) based on syntactic features (.", "labels": [], "entities": [{"text": "solving scope resolution", "start_pos": 40, "end_pos": 64, "type": "TASK", "confidence": 0.7148436009883881}]}, {"text": "In contrast to many of the previous systems that have used constituency-based representations), we base our syntactic features on dependency representations, similar to the approach of.", "labels": [], "entities": []}, {"text": "For cue detection, on the other hand, simply using surfaceoriented lexical features have been shown to be sufficient, and we here largely build on the specific approach described by , using a binary SVM classifier.", "labels": [], "entities": [{"text": "cue detection", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.864797443151474}]}, {"text": "The main goal of this work is to arrive at a lean and light-weight system with minimal use of extra heuristics beyond machine learned models.", "labels": [], "entities": []}, {"text": "While achieving the highest performance was not our main goal, the results are competitive with previously reported SoA results in the literature.", "labels": [], "entities": []}, {"text": "Moreover, the system can be employed with both raw and parsed input data.", "labels": [], "entities": []}], "datasetContent": [{"text": "The Conan Doyle corpus The data set we use for training and testing is the Conan Doyle cor-pus as used in the 2012 *SEM shared task, based on a CoNLL-style format.", "labels": [], "entities": [{"text": "Conan Doyle corpus", "start_pos": 4, "end_pos": 22, "type": "DATASET", "confidence": 0.7367726961771647}]}, {"text": "While the shared task also included detection of events and focus, we only focus on cues and scopes in this work.", "labels": [], "entities": []}, {"text": "We use the same splits for training, development testing and held-out evaluation as supplied for the shared task.", "labels": [], "entities": []}, {"text": "Examples (1)-(2) below show two examples taken from the corpus, where negation cues are in bold and their scopes are underlined.", "labels": [], "entities": []}, {"text": "In (1), the cue is the adverb not, whereas provides an example of the affixal cue un.", "labels": [], "entities": []}, {"text": "(1) And yet it was not quite the last.", "labels": [], "entities": []}, {"text": "(2) Since we have been so unfortunate as to miss him and have no notion The Conan Doyle corpus provides phrase structure trees produced by the Charniak and Johnson (2005) parser, and we have used the Stanford Parser ( ) to convert these to Stanford basic dependency representations (de) prior to training.", "labels": [], "entities": [{"text": "Doyle corpus", "start_pos": 82, "end_pos": 94, "type": "DATASET", "confidence": 0.7674144804477692}]}, {"text": "Evaluation We use the evaluation script of the 2012 *SEM shared task (Morante and Blanco, 2012) for measuring precision, recall and F-score.", "labels": [], "entities": [{"text": "2012 *SEM shared task (Morante and Blanco, 2012)", "start_pos": 47, "end_pos": 95, "type": "DATASET", "confidence": 0.6866374885042509}, {"text": "precision", "start_pos": 110, "end_pos": 119, "type": "METRIC", "confidence": 0.9993195533752441}, {"text": "recall", "start_pos": 121, "end_pos": 127, "type": "METRIC", "confidence": 0.9994961023330688}, {"text": "F-score", "start_pos": 132, "end_pos": 139, "type": "METRIC", "confidence": 0.9967040419578552}]}, {"text": "For scopes, it provides two different measures; token-level and scope-level.", "labels": [], "entities": []}, {"text": "For the token-level measure the evaluation is defined similarly as for cues, simply checking whether each token in the scope sequence is correctly labeled.", "labels": [], "entities": []}, {"text": "For scopes on the other hand, a true positive requires both the entire scope sequence and cue to be correct.", "labels": [], "entities": []}, {"text": "Note that for the held-out results, our system is trained on both the development and training data combined.", "labels": [], "entities": []}, {"text": "System comparison In addition to providing baseline results for both cues and scopes, we also include the results for the UiO 2 system of from the *SEM shared task.", "labels": [], "entities": []}, {"text": "Achieving the best results for both cue and scope resolution in the open track, it has guided much of the design of the current system.", "labels": [], "entities": [{"text": "scope resolution", "start_pos": 44, "end_pos": 60, "type": "TASK", "confidence": 0.7199519127607346}]}, {"text": "The cue classification component of UiO 2 was the same as for UiO 1 (run 1) (Read et al., 2012) -the system that was ranked first in the shared task overall (though not for cue detection in isolation).", "labels": [], "entities": [{"text": "cue classification", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.81423020362854}, {"text": "cue detection", "start_pos": 173, "end_pos": 186, "type": "TASK", "confidence": 0.7819616794586182}]}, {"text": "Maximum-margin learning for cues and scopes While cue detection is here approached as a tokenwise classification problem and scope resolution as sequence classification, they are both modeled using a maximum-margin approach.", "labels": [], "entities": [{"text": "cue detection", "start_pos": 50, "end_pos": 63, "type": "TASK", "confidence": 0.7637108862400055}, {"text": "scope resolution", "start_pos": 125, "end_pos": 141, "type": "TASK", "confidence": 0.6769234538078308}, {"text": "sequence classification", "start_pos": 145, "end_pos": 168, "type": "TASK", "confidence": 0.7264456003904343}]}, {"text": "Cue detection is solved using a binary Support Vector Machine (SVM) classifier.", "labels": [], "entities": [{"text": "Cue detection", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.9069132506847382}]}, {"text": "As is fairly common, scope resolution is solved as a sequence labeling task, applying a discriminative linear-chain Conditional Random Fields (CRF) model.However, in a conventional CRF, the parameters are learned through maximum likelihood estimation.", "labels": [], "entities": [{"text": "scope resolution", "start_pos": 21, "end_pos": 37, "type": "TASK", "confidence": 0.9481053054332733}, {"text": "sequence labeling task", "start_pos": 53, "end_pos": 75, "type": "TASK", "confidence": 0.7232579390207926}]}, {"text": "In PyStruct on the other hand, the parameters are estimated through maximum-margin learning based on SVMs, resulting in what maybe called a maximum-margin CRF.", "labels": [], "entities": []}, {"text": "System requirements The input given to the system can either be raw running text or parsed data in the CoNLL-X format).", "labels": [], "entities": [{"text": "CoNLL-X format", "start_pos": 103, "end_pos": 117, "type": "DATASET", "confidence": 0.8670549094676971}]}, {"text": "If the user inputs raw text, we need to tokenize, tag and parse the text before we can classify the sentences.", "labels": [], "entities": []}, {"text": "Because our training data uses PTB PoS-tags and Stanford dependencies (following conversion), we need a pipeline providing the same standard, and hence use the CoreNLP tool ( ).", "labels": [], "entities": [{"text": "PTB PoS-tags", "start_pos": 31, "end_pos": 43, "type": "DATASET", "confidence": 0.8521969616413116}]}, {"text": "Beyond Python 2.7 or newer, the negation tool has the following dependencies: scikit-learn, PyStruct, NumPy, and NetworkX (in addition to CoreNLP unless pre-parsed input is provided).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Scope resolution, for both gold and predicted cues.", "labels": [], "entities": [{"text": "resolution", "start_pos": 16, "end_pos": 26, "type": "METRIC", "confidence": 0.5928730964660645}]}]}