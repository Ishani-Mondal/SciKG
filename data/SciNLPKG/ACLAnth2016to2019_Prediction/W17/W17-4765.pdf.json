{"title": [{"text": "Feature-Enriched Character-Level Convolutions for Text Regression", "labels": [], "entities": [{"text": "Text Regression", "start_pos": 50, "end_pos": 65, "type": "TASK", "confidence": 0.7280608862638474}]}], "abstractContent": [{"text": "We present anew model for text regression that seamlessly combine engineered features and character-level information through deep parallel convolution stacks, multi-layer perceptrons and multi-task learning.", "labels": [], "entities": [{"text": "text regression", "start_pos": 26, "end_pos": 41, "type": "TASK", "confidence": 0.8171057105064392}]}, {"text": "We use these models to create the SHEF/CNN systems for the sentence-level Quality Estimation task of WMT 2017 and Emotion Intensity Analysis task of WASSA 2017.", "labels": [], "entities": [{"text": "sentence-level Quality Estimation task of WMT 2017", "start_pos": 59, "end_pos": 109, "type": "TASK", "confidence": 0.6208500691822597}, {"text": "Emotion Intensity Analysis task of WASSA 2017", "start_pos": 114, "end_pos": 159, "type": "TASK", "confidence": 0.7328486272266933}]}, {"text": "Our experiments reveal that combining character-level clues and engineered features offers noticeable performance improvements over using only one of these sources of information in isolation.", "labels": [], "entities": []}], "introductionContent": [{"text": "Text regression consists in estimating a numeric label based on information available from the text.", "labels": [], "entities": [{"text": "Text regression", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7254697680473328}]}, {"text": "The label can represent any abstract property of said text: its appropriateness, sentiment, fluency, simplicity, quality, etc.", "labels": [], "entities": [{"text": "simplicity", "start_pos": 101, "end_pos": 111, "type": "METRIC", "confidence": 0.991719126701355}]}, {"text": "Due to their wide applicability in both research and industry, some of these tasks have been gaining a lot of attention.", "labels": [], "entities": []}, {"text": "These include Quality Estimation and Emotion Intensity Analysis, which are the subjects of shared tasks held at the WMT 2017 conference and WASSA 2017 workshop 2, respectively.", "labels": [], "entities": [{"text": "Quality Estimation", "start_pos": 14, "end_pos": 32, "type": "TASK", "confidence": 0.7203220129013062}, {"text": "Emotion Intensity Analysis", "start_pos": 37, "end_pos": 63, "type": "TASK", "confidence": 0.8602761824925741}, {"text": "WMT 2017 conference", "start_pos": 116, "end_pos": 135, "type": "DATASET", "confidence": 0.7779119809468588}, {"text": "WASSA 2017 workshop 2", "start_pos": 140, "end_pos": 161, "type": "DATASET", "confidence": 0.682135209441185}]}, {"text": "In Quality Estimation (QE), one attempts to estimate the quality of a machine translated text based on the information that can be extracted from the original sentence and its translation.", "labels": [], "entities": [{"text": "Quality Estimation (QE)", "start_pos": 3, "end_pos": 26, "type": "TASK", "confidence": 0.7602808356285096}]}, {"text": "The task has many variants, given that the quality of a translation can be estimated at word, phrase, sentence or even document level.", "labels": [], "entities": []}, {"text": "Quality estimates can be incorporated in Machine Translation (MT) decoding or used for re-ranking of top candidates, for example, allowing fora more intelligently guided translation process, or they can be used to help human translators decide which automatic translations are worth post-editing, and which should be re-translated from scratch (.", "labels": [], "entities": [{"text": "Machine Translation (MT) decoding", "start_pos": 41, "end_pos": 74, "type": "TASK", "confidence": 0.8746178348859152}]}, {"text": "Sentence-level QE is the most popular variant, mostly due the fact that most modern statistical and neural MT systems translate one sentence at a time.", "labels": [], "entities": [{"text": "Sentence-level QE", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7068504691123962}]}, {"text": "In this task, the input is the original-translated sentence pair and the output is some numeric label that represents quality.", "labels": [], "entities": []}, {"text": "The most commonly used label is HTER, which measures the human post-editing effort required to fix the translation in question).", "labels": [], "entities": [{"text": "HTER", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.8346592783927917}]}, {"text": "As shown in, the performance of QE approaches submitted to the WMT shared tasks have steadily improved in recent years.", "labels": [], "entities": [{"text": "WMT shared tasks", "start_pos": 63, "end_pos": 79, "type": "TASK", "confidence": 0.7578625281651815}]}, {"text": "However, the nature of these approaches have not changed much: most of the top ranking systems employ well-known regression methods and extensive feature engineering.", "labels": [], "entities": []}, {"text": "Some of the most notable examples are the RTM systems of WMT 2014 and 15, which managed to reach the top of the ranks by employing Referential Translation Machines trained with SVMs for regression.", "labels": [], "entities": [{"text": "WMT 2014 and 15", "start_pos": 57, "end_pos": 72, "type": "DATASET", "confidence": 0.886750265955925}, {"text": "Referential Translation Machines", "start_pos": 131, "end_pos": 163, "type": "TASK", "confidence": 0.7678254644076029}]}, {"text": "The LORIA and YSDA () systems of WMT 2015 and 2016, respectively, achieved similar performance by also pairing SVMs with many resource-heavy features.", "labels": [], "entities": [{"text": "LORIA", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.9090908765792847}, {"text": "WMT", "start_pos": 33, "end_pos": 36, "type": "DATASET", "confidence": 0.8417976498603821}]}, {"text": "Neural Networks for sentence-level QE were introduced in WMT 2016 with the SimpleNets ( and POSTECH systems.", "labels": [], "entities": [{"text": "WMT", "start_pos": 57, "end_pos": 60, "type": "DATASET", "confidence": 0.6978600025177002}]}, {"text": "While the SimpleNets system uses sequence-to-label LSTMs to predict the quality of a translation's n-grams and then combines them, the POSTECH system learns quality labels at word-level using a sequence-tosequence model, and then combines them with a sequence-to-label model to predict quality at sentence-level.", "labels": [], "entities": []}, {"text": "Though very interesting and distinct strategies, neither of them managed to outperform the best scoring SVM-based approach of WMT 2016.", "labels": [], "entities": [{"text": "WMT 2016", "start_pos": 126, "end_pos": 134, "type": "DATASET", "confidence": 0.8451250791549683}]}, {"text": "In the task of Emotion Intensity Analysis (EIA), Neural Networks have not yet been successfully employed.", "labels": [], "entities": [{"text": "Emotion Intensity Analysis (EIA)", "start_pos": 15, "end_pos": 47, "type": "TASK", "confidence": 0.844222957889239}]}, {"text": "Unlike typical Sentiment Analysis tasks, which are setup as either binary or multiclass classification problems that require one to determine the opinion or sentiment in a given text, EIA aims at quantifying a certain emotion in a text, such as fear, anger, joy, sadness, etc.", "labels": [], "entities": [{"text": "Sentiment Analysis tasks", "start_pos": 15, "end_pos": 39, "type": "TASK", "confidence": 0.9401976664861044}]}, {"text": "In the Emotion Intensity shared task of SemEval 2016, which is the first of its kind, none of the five systems submitted employ neural regressors.", "labels": [], "entities": [{"text": "Emotion Intensity shared task of SemEval 2016", "start_pos": 7, "end_pos": 52, "type": "TASK", "confidence": 0.8073484301567078}]}, {"text": "We were also unable to find any other contributions outside the SemEval 2016 task that explore neural approaches to EIA.", "labels": [], "entities": [{"text": "SemEval 2016 task", "start_pos": 64, "end_pos": 81, "type": "TASK", "confidence": 0.8050723671913147}]}, {"text": "Given the volume of opportunities available when it comes to neural solutions for text regression, we introduce anew neural approach for the task.", "labels": [], "entities": [{"text": "text regression", "start_pos": 82, "end_pos": 97, "type": "TASK", "confidence": 0.7808771133422852}]}, {"text": "We innovate by using deep convolutional networks and multi-task learning to combine character-level information from the texts at hand with engineered features.", "labels": [], "entities": []}, {"text": "Using this approach, we create the SHEF/CNN systems for the sentence-level QE task of WMT 2017 and the Emotion Intensity Analysis task of WASSA 2017.", "labels": [], "entities": [{"text": "SHEF/CNN", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.6433406074841818}, {"text": "WMT", "start_pos": 86, "end_pos": 89, "type": "DATASET", "confidence": 0.6336960792541504}, {"text": "Emotion Intensity Analysis task of WASSA 2017", "start_pos": 103, "end_pos": 148, "type": "TASK", "confidence": 0.7673230852399554}]}, {"text": "In what follows, we describe our approach in detail.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Dataset sizes for the Emotion Intensity  Analysis task of WASSA 2017", "labels": [], "entities": [{"text": "Emotion Intensity  Analysis task", "start_pos": 32, "end_pos": 64, "type": "TASK", "confidence": 0.9461723268032074}]}, {"text": " Table 3: Results for the EIA task of WASSA 2017", "labels": [], "entities": [{"text": "EIA task of WASSA 2017", "start_pos": 26, "end_pos": 48, "type": "DATASET", "confidence": 0.6458787083625793}]}]}