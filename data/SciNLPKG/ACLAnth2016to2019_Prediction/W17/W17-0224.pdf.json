{"title": [{"text": "Cross-lingual Learning of Semantic Textual Similarity with Multilingual Word Representations", "labels": [], "entities": []}], "abstractContent": [{"text": "Assessing the semantic similarity between sentences in different languages is challenging.", "labels": [], "entities": []}, {"text": "We approach this problem by leveraging multilingual distributional word representations, where similar words in different languages are close to each other.", "labels": [], "entities": []}, {"text": "The availability of parallel data allows us to train such representations on a large amount of languages.", "labels": [], "entities": []}, {"text": "This allows us to leverage semantic similarity data for languages for which no such data exists.", "labels": [], "entities": []}, {"text": "We train and evaluate on five language pairs, including English, Spanish, and Arabic.", "labels": [], "entities": []}, {"text": "We are able to train well-performing systems for several language pairs, without any labelled data for that language pair.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semantic Textual Similarity (STS) is the task of assessing the degree to which two sentences are semantically similar.", "labels": [], "entities": [{"text": "Semantic Textual Similarity (STS)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8211836715539297}]}, {"text": "Within the SemEval STS shared tasks, this is measured on a scale ranging from 0 (no semantic similarity) to 5 (complete semantic similarity) (.", "labels": [], "entities": [{"text": "SemEval STS shared tasks", "start_pos": 11, "end_pos": 35, "type": "TASK", "confidence": 0.8413577079772949}]}, {"text": "Monolingual STS is an important task, for instance for evaluation of machine translation (MT) systems, where estimating the semantic similarity between a system's translation and the gold translation can aid both system evaluation and development.", "labels": [], "entities": [{"text": "Monolingual STS", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8246605098247528}, {"text": "evaluation of machine translation (MT)", "start_pos": 55, "end_pos": 93, "type": "TASK", "confidence": 0.7557463901383537}]}, {"text": "The task is already a challenging one in a monolingual setting, e.g., when estimating the similarity between two English sentences.", "labels": [], "entities": [{"text": "estimating the similarity between two English sentences", "start_pos": 75, "end_pos": 130, "type": "TASK", "confidence": 0.7843662926128933}]}, {"text": "In this paper, we tackle the more difficult case of cross-lingual STS, e.g., estimating the similarity between an English and an Arabic sentence.", "labels": [], "entities": [{"text": "cross-lingual STS", "start_pos": 52, "end_pos": 69, "type": "TASK", "confidence": 0.7118955254554749}]}, {"text": "Previous approaches to this problem have focussed on two main approaches.", "labels": [], "entities": []}, {"text": "On the one hand, MT approaches have been attempted (e.g.), which allow for monolingual similarity assessment, but suffer from the fact that involving a fully-fledged MT system severely increases system complexity.", "labels": [], "entities": [{"text": "MT", "start_pos": 17, "end_pos": 19, "type": "TASK", "confidence": 0.9836408495903015}, {"text": "monolingual similarity assessment", "start_pos": 75, "end_pos": 108, "type": "TASK", "confidence": 0.5723235110441843}]}, {"text": "Applying bilingual word representations, on the other hand, bypasses this issue without inducing such complexity (e.g.).", "labels": [], "entities": []}, {"text": "However, bilingual approaches do not allow for taking advantage of the increasing amount of STS data available for more than one language pair.", "labels": [], "entities": []}, {"text": "Currently, there are several methods available for obtaining high quality multilingual word representations.", "labels": [], "entities": []}, {"text": "It is therefore interesting to investigate whether language can be ignored entirely in an STS system after mapping words to their respective representations.", "labels": [], "entities": []}, {"text": "We investigate the utility of multilingual word representations in a crosslingual STS setting.", "labels": [], "entities": []}, {"text": "We approach this by combining multilingual word representations with a deep neural network, in which all parameters are shared, regardless of language combinations.", "labels": [], "entities": []}, {"text": "The contributions of this paper can be summed as follows: i) we show that multilingual input representations can be used to train an STS system without access to training data fora given language; ii) we show that access to data from other languages improves system performance fora given language.", "labels": [], "entities": []}], "datasetContent": [{"text": "We aim to investigate whether using a multilingual input representation and shared weights allow us to ignore languages in STS.", "labels": [], "entities": []}, {"text": "We first train and evaluate single-source trained systems (i.e. on a single language pair), and evaluate this both using the same language pair as target, and on all other target language pairs.", "labels": [], "entities": []}, {"text": "1 Secondly, we investigate the effect of bundling training data together, investigating which language pairings are helpful for each other.", "labels": [], "entities": []}, {"text": "We measure performance between gold similarities and system output using the Pearson correlation measure, as this is standard in the SemEval STS shared tasks.", "labels": [], "entities": [{"text": "Pearson correlation measure", "start_pos": 77, "end_pos": 104, "type": "METRIC", "confidence": 0.9434667030970255}, {"text": "SemEval STS shared tasks", "start_pos": 133, "end_pos": 157, "type": "TASK", "confidence": 0.7352914810180664}]}], "tableCaptions": [{"text": " Table 1: Available data for (cross-lingual) STS  from the SemEval shared task series.  Language pair  N sentences", "labels": [], "entities": []}, {"text": " Table 2: Single-source training results (Pearson  correlations). Columns indicate training language  pairs, and rows indicate testing language pairs.  Bold numbers indicate best results per row.", "labels": [], "entities": [{"text": "Pearson  correlations", "start_pos": 42, "end_pos": 63, "type": "METRIC", "confidence": 0.8954967260360718}]}, {"text": " Table 3: Training results with one source in ad- dition to in-language data (Pearson correlations).  Columns indicate added training language pairs,  and rows indicate testing language pairs. Bold  numbers indicate best results per row.", "labels": [], "entities": [{"text": "Pearson correlations)", "start_pos": 78, "end_pos": 99, "type": "METRIC", "confidence": 0.9333416819572449}]}, {"text": " Table 4: Ablation results (Pearson correlations).  Columns indicate ablated language pairs, and rows  indicate testing language pairs. The none column  indicates no ablation, i.e., training on all three  monolingual pairs. Bold indicates results when  not training on the language pair evaluated on.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.998427152633667}, {"text": "Pearson correlations", "start_pos": 28, "end_pos": 48, "type": "METRIC", "confidence": 0.9151621758937836}]}]}