{"title": [{"text": "Use Generalized Representations, But Do Not Forget Surface Features", "labels": [], "entities": []}], "abstractContent": [{"text": "Only a year ago, all state-of-the-art coref-erence resolvers were using an extensive amount of surface features.", "labels": [], "entities": [{"text": "coref-erence resolvers", "start_pos": 38, "end_pos": 60, "type": "TASK", "confidence": 0.7321462333202362}]}, {"text": "Recently, there was a paradigm shift towards using word embeddings and deep neural networks , where the use of surface features is very limited.", "labels": [], "entities": []}, {"text": "In this paper, we show that a simple SVM model with surface features outperforms more complex neural models for detecting anaphoric mentions.", "labels": [], "entities": [{"text": "detecting anaphoric mentions", "start_pos": 112, "end_pos": 140, "type": "TASK", "confidence": 0.8656991720199585}]}, {"text": "Our analysis suggests that using generalized representations and surface features have different strength that should be both taken into account for improving corefer-ence resolution.", "labels": [], "entities": [{"text": "corefer-ence resolution", "start_pos": 159, "end_pos": 182, "type": "TASK", "confidence": 0.8819692134857178}]}], "introductionContent": [{"text": "Coreference resolution is the task of finding different mentions that refer to the same entity in a given text.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9211663901805878}]}, {"text": "Anaphoricity detection is an important step for coreference resolution.", "labels": [], "entities": [{"text": "Anaphoricity detection", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7281167358160019}, {"text": "coreference resolution", "start_pos": 48, "end_pos": 70, "type": "TASK", "confidence": 0.9871149957180023}]}, {"text": "An anaphoricity detection module discriminates mentions that are coreferent with one of the previous mentions.", "labels": [], "entities": []}, {"text": "If a system recognizes mention m as non-anaphoric, it does not need to make any coreferent links for the pairs in which m is the anaphor.", "labels": [], "entities": []}, {"text": "The current state-of-the-art coreference resolvers (, as well as their anaphoricity detection modules, use deep neural networks, word embeddings and a small set of features describing surface properties of mentions.", "labels": [], "entities": [{"text": "coreference resolvers", "start_pos": 29, "end_pos": 50, "type": "TASK", "confidence": 0.8840711116790771}]}, {"text": "While it is shown that this small set of features has significant impact on the overall performance, their use is very limited in the state-of-the-art systems in comparison to the embedding features.", "labels": [], "entities": []}, {"text": "In this paper, we first introduce anew neural model for anaphoricity detection that considerably outperforms the anaphoricity detection of the state-of-the-art coreference resolver, i.e. deepcoref introduced by.", "labels": [], "entities": [{"text": "anaphoricity detection", "start_pos": 56, "end_pos": 78, "type": "TASK", "confidence": 0.7024211883544922}, {"text": "coreference resolver", "start_pos": 160, "end_pos": 180, "type": "TASK", "confidence": 0.810998797416687}]}, {"text": "However, we show that a simple SVM model that is adapted from our coreferent mention detection approach, significantly outperforms the more complex neural models.", "labels": [], "entities": [{"text": "coreferent mention detection", "start_pos": 66, "end_pos": 94, "type": "TASK", "confidence": 0.6579600075880686}]}, {"text": "We show that the SVM model also generalizes better than the neural model on anew domain other than the CoNLL dataset.", "labels": [], "entities": [{"text": "CoNLL dataset", "start_pos": 103, "end_pos": 116, "type": "DATASET", "confidence": 0.9691264629364014}]}], "datasetContent": [{"text": "We evaluate the anaphoricity models on the CoNLL 2012 dataset.", "labels": [], "entities": [{"text": "CoNLL 2012 dataset", "start_pos": 43, "end_pos": 61, "type": "DATASET", "confidence": 0.9836804866790771}]}, {"text": "It is worth noting that all of the examined anaphoricity detectors in this section use the same mention detection module and results are reported using system detected mentions.", "labels": [], "entities": []}, {"text": "The performance of the mention detection module is of crucial importance for anaphoricity detection.", "labels": [], "entities": [{"text": "mention detection", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.7510676980018616}, {"text": "anaphoricity detection", "start_pos": 77, "end_pos": 99, "type": "TASK", "confidence": 0.8454342782497406}]}, {"text": "Therefore, it is important that the compared anaphoricity detectors use the same mention detection.", "labels": [], "entities": []}, {"text": "The LSTM model that is described in Section 3.2 is denoted as LSTM in.", "labels": [], "entities": []}, {"text": "In order to investigate the effect of the used surface features, we also report the results of the LSTM model without using these features (LSTM * ).", "labels": [], "entities": []}, {"text": "The following observations can be drawn from the results of (1) our LSTM model outperforms the joint model while using less features and being trained independently, (2) the results of the LSTM * model is considerably lower than those of LSTM, especially for recognizing anaphoric mentions, and (3) the simple SVM model outperforms the neural models in detecting both anaphoric and non-anaphoric mentions.", "labels": [], "entities": []}, {"text": "In order to investigate the generalization on new domains, we evaluate the LSTM and SVM models on the WikiCoref dataset (.", "labels": [], "entities": [{"text": "WikiCoref dataset", "start_pos": 102, "end_pos": 119, "type": "DATASET", "confidence": 0.9769094288349152}]}, {"text": "The WikiCoref dataset is annotated according to the same annotation guideline as that of CoNLL.", "labels": [], "entities": [{"text": "WikiCoref dataset", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.9632733464241028}, {"text": "CoNLL", "start_pos": 89, "end_pos": 94, "type": "DATASET", "confidence": 0.9371582865715027}]}, {"text": "Therefore, it is an appropriate dataset for performing out-of-domain evaluations when CoNLL is used for training.", "labels": [], "entities": []}, {"text": "For the experiments of, all models are trained on the CoNLL 2012 training data and tested on the WikiCoref dataset.", "labels": [], "entities": [{"text": "CoNLL 2012 training data", "start_pos": 54, "end_pos": 78, "type": "DATASET", "confidence": 0.9720960408449173}, {"text": "WikiCoref dataset", "start_pos": 97, "end_pos": 114, "type": "DATASET", "confidence": 0.9743578135967255}]}, {"text": "The word dictionary that is used for the LSTM model is built based on the CoNLL 2012 training data.", "labels": [], "entities": [{"text": "CoNLL 2012 training data", "start_pos": 74, "end_pos": 98, "type": "DATASET", "confidence": 0.9695492088794708}]}, {"text": "All words that are not included in this dictionary are treated as out of vocabulary words with randomly initialized word embeddings.", "labels": [], "entities": []}, {"text": "We further improve the performance of LSTM on WikiCoref, by adding the words from the WikiCoref dataset into its dictionary.", "labels": [], "entities": [{"text": "WikiCoref dataset", "start_pos": 86, "end_pos": 103, "type": "DATASET", "confidence": 0.9076998233795166}]}, {"text": "The LSTM model trained with this extended dictionary is denoted as LSTM \u2020 in.", "labels": [], "entities": []}, {"text": "LSTM \u2020 results are still lower than those of the SVM model while SVM does not use any information from the test dataset.", "labels": [], "entities": [{"text": "LSTM \u2020", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.776002049446106}]}, {"text": "Pruning rare lexical features from the training data along the incorporation of part of speech tags, which are far more generalizable than lexical features, could explain the generalizability of the SVM model on the new domain.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results on the CoNLL 2012 test set.", "labels": [], "entities": [{"text": "CoNLL 2012 test set", "start_pos": 25, "end_pos": 44, "type": "DATASET", "confidence": 0.9589766263961792}]}, {"text": " Table 2. LSTM  \u2020 results are still lower  than those of the SVM model while SVM does not  use any information from the test dataset. Pruning  rare lexical features from the training data along  the incorporation of part of speech tags, which are  far more generalizable than lexical features, could  explain the generalizability of the SVM model on  the new domain.", "labels": [], "entities": [{"text": "LSTM  \u2020", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.8635811507701874}]}, {"text": " Table 2: Results on the WikiCoref dataset.", "labels": [], "entities": [{"text": "WikiCoref dataset", "start_pos": 25, "end_pos": 42, "type": "DATASET", "confidence": 0.9677185416221619}]}, {"text": " Table 4. As can be seen from Ta- ble 4, while deep-coref is significantly better than  cort for resolving common nouns and specially  pronouns, its result does not go far beyond that of  cort when it comes to resolving proper names.", "labels": [], "entities": [{"text": "resolving proper names", "start_pos": 210, "end_pos": 232, "type": "TASK", "confidence": 0.8197983900705973}]}, {"text": " Table 3: Anaphoricity results for each mention  type on the CoNLL 2012 test set.", "labels": [], "entities": [{"text": "Anaphoricity", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.9322323799133301}, {"text": "CoNLL 2012 test set", "start_pos": 61, "end_pos": 80, "type": "DATASET", "confidence": 0.9713657945394516}]}, {"text": " Table 4: Coreference error analysis.", "labels": [], "entities": [{"text": "Coreference error analysis", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.8395448525746664}]}]}