{"title": [{"text": "A study of N-gram and Embedding Representations for Native Language Identification", "labels": [], "entities": [{"text": "Native Language Identification", "start_pos": 52, "end_pos": 82, "type": "TASK", "confidence": 0.7010277708371481}]}], "abstractContent": [{"text": "We report on our experiments with N-gram and embedding based feature representations for Native Language Identification (NLI) as apart of the NLI Shared Task 2017 (team name: NLI-ISU).", "labels": [], "entities": [{"text": "Native Language Identification (NLI)", "start_pos": 89, "end_pos": 125, "type": "TASK", "confidence": 0.8023470441500345}]}, {"text": "Our best performing system on the test set for written essays had a macro F1 of 0.8264 and was based on word uni, bi and tri-gram features.", "labels": [], "entities": [{"text": "F1", "start_pos": 74, "end_pos": 76, "type": "METRIC", "confidence": 0.7166211009025574}]}, {"text": "We explored n-grams covering word, character, POS and word-POS mixed representations for this task.", "labels": [], "entities": []}, {"text": "For embedding based feature representations, we employed both word and document embeddings.", "labels": [], "entities": []}, {"text": "We had a relatively poor performance with all embedding representations compared to n-grams, which could be because of the fact that embeddings capture semantic similarities whereas L1 differences are more stylistic in nature.", "labels": [], "entities": []}], "introductionContent": [{"text": "Native Language Identification (NLI) refers to the task of identifying the native language (L1) of a writer based on their writings in another language (L2).", "labels": [], "entities": [{"text": "Native Language Identification (NLI)", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.7713488439718882}]}, {"text": "Identifying the L1 of a writer is useful in applications such as authorship attribution, forensic linguistics, language instruction and Second Language Acquisition (SLA) (.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.728878989815712}, {"text": "Second Language Acquisition (SLA)", "start_pos": 136, "end_pos": 169, "type": "TASK", "confidence": 0.7756480177243551}]}, {"text": "While early work on this problem began at the beginning of this century), there has been an increased interest in this task since 2012, with the availability of some publicly accessible corpora.", "labels": [], "entities": []}, {"text": "The First NLI Shared Task (  and the release of large corpora such as TOEFL11 corpus of non-native English and EFCAMDAT corpus) resulted in a surge of research in this area in the past few years.", "labels": [], "entities": [{"text": "TOEFL11 corpus of non-native English", "start_pos": 70, "end_pos": 106, "type": "DATASET", "confidence": 0.900306248664856}, {"text": "EFCAMDAT corpus", "start_pos": 111, "end_pos": 126, "type": "DATASET", "confidence": 0.8732480406761169}]}, {"text": "While most of the NLI research has been on English, there is a significant amount of work on other language texts such as Chinese,.", "labels": [], "entities": []}, {"text": "Starting form surface linguistic forms such as words and characters to deeper syntactic structures, a range of features have been explored for this task in the past five years.", "labels": [], "entities": []}, {"text": "The last few years saw the field of NLI advance in both the directions of feature engineering and modeling.", "labels": [], "entities": [{"text": "feature engineering", "start_pos": 74, "end_pos": 93, "type": "TASK", "confidence": 0.7893402576446533}]}, {"text": "However, irrespective of what modeling choices were made, results seem to show that word level features still are the most predictive ones as a single group (e.g.,) for this data.", "labels": [], "entities": []}, {"text": "So, in this paper, we take a step back from complex feature and model engineering, and explore how far can we get by doing classification using simpler feature representations based on words, characters and POS tags.", "labels": [], "entities": []}, {"text": "While our current experiments (team name: NLI-ISU), done as apart of the NLI Shared Task 2017 ( , do not result in any improvements over existing approaches, we believe they provide insights into the nature of the task and why n-grams may still be needed for this task despite the presence of more compact embedding representations for texts.", "labels": [], "entities": [{"text": "NLI Shared Task 2017", "start_pos": 73, "end_pos": 93, "type": "DATASET", "confidence": 0.7623973786830902}]}, {"text": "The rest of this paper is organized as follows: The next section describes some of the related work and puts our experiments in context.", "labels": [], "entities": []}, {"text": "Section 3 briefly describes the corpus used.", "labels": [], "entities": []}, {"text": "We describe our methodology including feature description in Section 4.", "labels": [], "entities": [{"text": "feature description", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.7720862627029419}]}, {"text": "Our experiments and results are discussed in Section 5.", "labels": [], "entities": []}, {"text": "Section 6 concludes the paper with pointers to future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1 shows the results on test set for our sub- mitted systems using Logistic Regression.", "labels": [], "entities": []}, {"text": " Table 2: Results for the ESSAY track with Em- bedding Features on Development data", "labels": [], "entities": [{"text": "ESSAY", "start_pos": 26, "end_pos": 31, "type": "METRIC", "confidence": 0.6130267381668091}]}]}