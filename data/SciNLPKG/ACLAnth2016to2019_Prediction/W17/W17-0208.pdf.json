{"title": [{"text": "Acoustic Model Compression with MAP adaptation", "labels": [], "entities": []}], "abstractContent": [{"text": "Speaker adaptation is an important step in optimization and personalization of the performance of automatic speech recognition (ASR) for individual users.", "labels": [], "entities": [{"text": "Speaker adaptation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8634065985679626}, {"text": "automatic speech recognition (ASR)", "start_pos": 98, "end_pos": 132, "type": "TASK", "confidence": 0.8042713503042856}]}, {"text": "While many applications target in rapid adaptation by various global transformations, slower adaptation to obtain a higher level of personalization would be useful for many active ASR users, especially for those whose speech is not recognized well.", "labels": [], "entities": [{"text": "ASR", "start_pos": 180, "end_pos": 183, "type": "TASK", "confidence": 0.9570565223693848}]}, {"text": "This paper studies the outcome of combinations of maximum a posterior (MAP) adaptation and compression of Gaussian mixture models.", "labels": [], "entities": [{"text": "maximum a posterior (MAP) adaptation", "start_pos": 50, "end_pos": 86, "type": "METRIC", "confidence": 0.7785636101450238}]}, {"text": "An important result that has not received much previous attention is how MAP adaptation can be utilized to radically decrease the size of the models as they get tuned to a particular speaker.", "labels": [], "entities": [{"text": "MAP adaptation", "start_pos": 73, "end_pos": 87, "type": "TASK", "confidence": 0.9605474770069122}]}, {"text": "This is particularly relevant for small personal devices which should provide accurate recognition in real-time despite a low memory, computation, and electricity consumption.", "labels": [], "entities": []}, {"text": "With our method we are able to decrease the model complexity with MAP adaptation while increasing the accuracy.", "labels": [], "entities": [{"text": "MAP adaptation", "start_pos": 66, "end_pos": 80, "type": "TASK", "confidence": 0.8159742057323456}, {"text": "accuracy", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9986932873725891}]}], "introductionContent": [{"text": "Speaker adaptation is one of the most important techniques to improve automatic speech recognition (ASR) performance.", "labels": [], "entities": [{"text": "Speaker adaptation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.873601496219635}, {"text": "automatic speech recognition (ASR)", "start_pos": 70, "end_pos": 104, "type": "TASK", "confidence": 0.7885300119717916}]}, {"text": "While today many out-of-the-box ASR systems work fairly well, in noisy real-world conditions the accuracy and speed are often insufficient for large-vocabulary open-domain dictation.", "labels": [], "entities": [{"text": "ASR", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.9863042235374451}, {"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9993595480918884}]}, {"text": "This is particularly annoying for people who have temporary or permanent mobility limitations and cannot utilize other input modalities.", "labels": [], "entities": []}, {"text": "A feasible solution to improve the recognition performance is to personalize the system by recording adaptation data.", "labels": [], "entities": []}, {"text": "Speech recognition systems require high computational capacity and the recognition is typically run in the cloud instead of locally in the device.", "labels": [], "entities": [{"text": "Speech recognition", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8007420599460602}]}, {"text": "Computation requirements are due to large speaker independent (SI) acoustic and language models which slow the recognition process.", "labels": [], "entities": []}, {"text": "Transferring data between the user end device and the cloud causes latency, particularly, when fast network is unavailable, hence it would be better if models were small enough to run the recognition locally.", "labels": [], "entities": []}, {"text": "Speech recognition is typically used on devices which have only a single user, hence a large SI model contains a lot of unnecessary information.", "labels": [], "entities": [{"text": "Speech recognition", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.834977775812149}]}, {"text": "Speaker dependent (SD) models require only a fraction of the SI model size and are more accurate), hence they would bean ideal solution for smaller systems.", "labels": [], "entities": []}, {"text": "A SD model, however, needs several hours of transcribed training data from the user which is often not possible in practice.", "labels": [], "entities": [{"text": "SD", "start_pos": 2, "end_pos": 4, "type": "TASK", "confidence": 0.9618278741836548}]}, {"text": "Therefore, the large SI models are more commonly used.", "labels": [], "entities": []}, {"text": "There are many compression methods for the acoustic models.", "labels": [], "entities": []}, {"text": "Popular approaches are vector quantization) and compression of Hidden Markov model (HMM) parameters.", "labels": [], "entities": [{"text": "vector quantization", "start_pos": 23, "end_pos": 42, "type": "TASK", "confidence": 0.7878260314464569}]}, {"text": "The HMM parameters can be clustered by sharing parameters between the states.", "labels": [], "entities": []}, {"text": "Typical clustering methods are subspace compression), tying and clustering the Gaussian mixture models (GMMs)).", "labels": [], "entities": [{"text": "subspace compression", "start_pos": 31, "end_pos": 51, "type": "TASK", "confidence": 0.8632386922836304}]}, {"text": "The compression methods, however, do not aim to improve the accuracy, as they have been developed to save memory and boost the recognition speed.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9994004964828491}]}, {"text": "The accuracy of the SI model can be improved by speaker adaptation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9993714690208435}, {"text": "speaker adaptation", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.8043732941150665}]}, {"text": "Adaptation is a common technique for adjusting parameters of a general acoustic model fora specific acoustic situation.", "labels": [], "entities": []}, {"text": "It can significantly improve performance for speakers that are not well represented in the training data.", "labels": [], "entities": []}, {"text": "However, the conventional adaptation meth-ods do not resolve the issue with the model size.", "labels": [], "entities": []}, {"text": "In this paper we introduce speaker adaptation for GMM-HMM ASR system which also reduces the model size.", "labels": [], "entities": [{"text": "speaker adaptation", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.8452895879745483}, {"text": "GMM-HMM ASR", "start_pos": 50, "end_pos": 61, "type": "DATASET", "confidence": 0.7115056812763214}]}, {"text": "MAP adaptation () is one of the most common supervised speaker adaptation methods.", "labels": [], "entities": [{"text": "MAP adaptation", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8727020621299744}, {"text": "speaker adaptation", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.756924957036972}]}, {"text": "The MAP adaptation requires at least several minutes of adaptation data, but as the amount of data increases, the MAP estimation converges towards the ML estimation of a SD model.", "labels": [], "entities": [{"text": "MAP adaptation", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.9204571843147278}]}, {"text": "An advantage in MAP adaptation is that it can be applied along with the compression methods and even with other adaptation methods such as the maximum likelihood linear regression (MLLR) (.", "labels": [], "entities": [{"text": "MAP adaptation", "start_pos": 16, "end_pos": 30, "type": "TASK", "confidence": 0.983191192150116}]}, {"text": "In this paper we propose a modification to the MAP adaptation that also reduces the model complexity.", "labels": [], "entities": [{"text": "MAP adaptation", "start_pos": 47, "end_pos": 61, "type": "TASK", "confidence": 0.9531433582305908}]}, {"text": "The acoustic model is simplified by merging Gaussian components that are the least relevant in the adaptation and improved by adapting the means of the components.", "labels": [], "entities": []}, {"text": "Merging preserves some of the information merged Gaussians had which would be lost if the least relevant Gaussian components were simply removed.", "labels": [], "entities": []}, {"text": "Recently, it has been shown that deep neural network (DNN) acoustic models can clearly outperform GMMs in ASR (.", "labels": [], "entities": []}, {"text": "In theory, a corresponding adaptation procedure as in this work could also be applied to DNNs to cutoff connections and units that are the least relevant in the adaptation data and re-train the remaining network.", "labels": [], "entities": []}, {"text": "However, it is much more complicated to re-train and to analyze the modified DNN model than a GMM.", "labels": [], "entities": [{"text": "GMM", "start_pos": 94, "end_pos": 97, "type": "DATASET", "confidence": 0.9718528389930725}]}, {"text": "This is the reason we started to develop this new version of the MAP adaptation combined with model reduction using first the simple GMMs.", "labels": [], "entities": [{"text": "MAP adaptation", "start_pos": 65, "end_pos": 79, "type": "TASK", "confidence": 0.9345783889293671}, {"text": "model reduction", "start_pos": 94, "end_pos": 109, "type": "TASK", "confidence": 0.6659403592348099}]}, {"text": "If it is successful, the next step is to see how much it can benefit the DNNs.", "labels": [], "entities": []}, {"text": "This paper introduces a modified MAP adaptation.", "labels": [], "entities": [{"text": "MAP adaptation", "start_pos": 33, "end_pos": 47, "type": "TASK", "confidence": 0.920659601688385}]}, {"text": "In the following section the MAP adaptation and the Gaussian split and merge operations are described.", "labels": [], "entities": [{"text": "MAP adaptation", "start_pos": 29, "end_pos": 43, "type": "TASK", "confidence": 0.8907983303070068}]}, {"text": "Initial experimental results are presented in Section 3 to show effectiveness of the method in our Finnish large vocabulary continuous speech recognition (LVCSR) system.", "labels": [], "entities": [{"text": "Finnish large vocabulary continuous speech recognition (LVCSR)", "start_pos": 99, "end_pos": 161, "type": "TASK", "confidence": 0.7049165566762289}]}, {"text": "The results are discussed in Section 4, and the final conclusions are drawn in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "The modified MAP adatation is evaluated in a speaker adaptation task.", "labels": [], "entities": [{"text": "speaker adaptation task", "start_pos": 45, "end_pos": 68, "type": "TASK", "confidence": 0.8316794037818909}]}, {"text": "The corpus for the task included three Finnish audio books each recorded by a different speaker.", "labels": [], "entities": []}, {"text": "In addition to the variable readers also the style of reading varied significantly between the books.", "labels": [], "entities": []}, {"text": "For example, the task of the first reader \"Speaker1\" was to avoid any interpretation of the text, because the book was intended for the blind audience.", "labels": [], "entities": [{"text": "interpretation of the text", "start_pos": 70, "end_pos": 96, "type": "TASK", "confidence": 0.8035811483860016}]}, {"text": "The two other readers \"Speaker2\" and \" Speaker3\" described everyday matters in a very lively reading style.", "labels": [], "entities": []}, {"text": "The same value for the MAP hyperparameter \u03c4 was used for all speakers with no speaker-specific optimization.", "labels": [], "entities": [{"text": "MAP hyperparameter \u03c4", "start_pos": 23, "end_pos": 43, "type": "METRIC", "confidence": 0.4972117344538371}]}, {"text": "The length of the adaptation sets was 25 minutes for all speakers.", "labels": [], "entities": []}, {"text": "The evaluation set was 90 minutes long for \"Speaker1\" and 30 minutes for \"Speaker2\" and \"Speaker3\".", "labels": [], "entities": []}, {"text": "The training set for an SD reference model for \"Speaker1\" had 90 minutes of speech, and the resulting Gaussian mixture model had 4500 Gaussian components.", "labels": [], "entities": []}, {"text": "The baseline SI model with 40 032 Gaussians was ML trained with Finnish Speecon corpus () including 90 hours of speech.", "labels": [], "entities": [{"text": "ML", "start_pos": 48, "end_pos": 50, "type": "METRIC", "confidence": 0.7029283046722412}, {"text": "Finnish Speecon corpus", "start_pos": 64, "end_pos": 86, "type": "DATASET", "confidence": 0.8841158151626587}]}, {"text": "This model was also used as the initial model to be adapted in the experiments.", "labels": [], "entities": []}, {"text": "The language model used for all experiment was trained with Finnish news texts.", "labels": [], "entities": []}, {"text": "Because Finnish is an agglutinative language, the n-gram language model was based on statistical morphs instead of words to avoid outof-vocabulary words.", "labels": [], "entities": []}, {"text": "The experiments were conducted by the morphbased LVCSR system, AaltoASR) developed at Aalto University.", "labels": [], "entities": [{"text": "AaltoASR", "start_pos": 63, "end_pos": 71, "type": "DATASET", "confidence": 0.5004222989082336}, {"text": "Aalto University", "start_pos": 86, "end_pos": 102, "type": "DATASET", "confidence": 0.8704536259174347}]}, {"text": "The source codes of the recognizer were recently published as open source 1 . The acoustic features were 39 dimensional MFCCs normalized by cepstral mean subtraction.", "labels": [], "entities": []}, {"text": "The Gaussians had diagonal covariances and a global diagonalising transform was used.", "labels": [], "entities": []}, {"text": "The acoustic models were based on decision-tree-tied triphones with GMMs.", "labels": [], "entities": [{"text": "GMMs", "start_pos": 68, "end_pos": 72, "type": "DATASET", "confidence": 0.9308585524559021}]}, {"text": "In this paper the recognition accuracy is measured by using the word error rate (WER).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9425709247589111}, {"text": "word error rate (WER)", "start_pos": 64, "end_pos": 85, "type": "METRIC", "confidence": 0.8902124762535095}]}, {"text": "It is noteworthy that in agglutinative languages, such as Finnish, words are often quite long.", "labels": [], "entities": []}, {"text": "It means that sometimes one misrecognized phoneme in a word such as \"kahvinjuojallekin\" leads to 100% WER, whereas the same mistake in English \"also fora coffee drinker\" gives only 20%.", "labels": [], "entities": [{"text": "WER", "start_pos": 102, "end_pos": 105, "type": "METRIC", "confidence": 0.9592326879501343}]}, {"text": "Thus, the WER numbers in Finnish are typically high and 10% WER means already very good ASR.", "labels": [], "entities": [{"text": "WER", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9802764654159546}, {"text": "WER", "start_pos": 60, "end_pos": 63, "type": "METRIC", "confidence": 0.995210587978363}, {"text": "ASR", "start_pos": 88, "end_pos": 91, "type": "METRIC", "confidence": 0.8891291618347168}]}, {"text": "Because the adaptation set is much smaller than the training set for the initial SI model, the occupancy will not accumulate for every Gaussian component.", "labels": [], "entities": [{"text": "occupancy", "start_pos": 95, "end_pos": 104, "type": "METRIC", "confidence": 0.9717609882354736}]}, {"text": "Whenever a Gaussian does not gain sufficient occupancy, it is merged into another Gaussian distribution as explained in the previous section.", "labels": [], "entities": []}, {"text": "In the experiments for \"Speaker1\", for example, this extended MAP adaptation reduced the model size from 40 032 to the 26 224 Gaussian components after one iteration.", "labels": [], "entities": []}, {"text": "The results in show that the MAP adaptation improves the SI model for \"Speaker1\", even if the model size is also reduced.", "labels": [], "entities": []}, {"text": "The blue bars represent WER after the normal MAP adaptation when the model size remains unchanged.", "labels": [], "entities": [{"text": "WER", "start_pos": 24, "end_pos": 27, "type": "METRIC", "confidence": 0.998458743095398}, {"text": "MAP", "start_pos": 45, "end_pos": 48, "type": "METRIC", "confidence": 0.6970546245574951}]}, {"text": "The red bars show WER when the model is compressed during the adaptation.", "labels": [], "entities": [{"text": "WER", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.9990172386169434}]}, {"text": "The purple horizontal line represents the performance of the base-: WER comparison of the normally MAP adapted (40k) and compressed model (20k) for \"Speaker 1\", where the numbers indicate the number of Gaussian components.", "labels": [], "entities": [{"text": "WER", "start_pos": 68, "end_pos": 71, "type": "METRIC", "confidence": 0.9956498742103577}]}, {"text": "line SI model without any adaptations.", "labels": [], "entities": []}, {"text": "The WER for the baseline was 19.93%.", "labels": [], "entities": [{"text": "WER", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.999382495880127}]}, {"text": "shows that as the adaptation set increases the accuracy improves with both methods and the difference in WER between the compressed and the uncompressed model reduces.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.999601423740387}, {"text": "WER", "start_pos": 105, "end_pos": 108, "type": "METRIC", "confidence": 0.9969383478164673}]}, {"text": "The results were similar with the other speakers as well, as can be seen from the tables 1 and 2.", "labels": [], "entities": []}, {"text": "The improvement of the compressed models could be explained by the MAP estimates converging towards the SD model estimates as the adaptation data increases.", "labels": [], "entities": [{"text": "MAP", "start_pos": 67, "end_pos": 70, "type": "METRIC", "confidence": 0.8994923233985901}]}, {"text": "The WER for \"Speaker1\" with the SD model was 10.02%.", "labels": [], "entities": [{"text": "WER", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9996510744094849}]}, {"text": "The results also imply that all the SI model components are not necessary for all users.", "labels": [], "entities": []}, {"text": "It was also experimented with the \"Speaker1\" if similar results could be achieved by using the ML estimates instead of the MAP estimates in compression.", "labels": [], "entities": []}, {"text": "However, as can be seen from, the ML estimates do not improve the accuracy of the SI model, which had WER 19.93%, until the adaptation data has reached 25 minutes.", "labels": [], "entities": [{"text": "ML", "start_pos": 34, "end_pos": 36, "type": "METRIC", "confidence": 0.6681451201438904}, {"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9996834993362427}, {"text": "WER", "start_pos": 102, "end_pos": 105, "type": "METRIC", "confidence": 0.9951091408729553}]}], "tableCaptions": [{"text": " Table 1: Uncompressed MAP (WER).", "labels": [], "entities": [{"text": "Uncompressed MAP (WER", "start_pos": 10, "end_pos": 31, "type": "METRIC", "confidence": 0.790986493229866}]}, {"text": " Table 2: Compressed MAP (WER).", "labels": [], "entities": [{"text": "Compressed MAP (WER)", "start_pos": 10, "end_pos": 30, "type": "METRIC", "confidence": 0.8773962974548339}]}, {"text": " Table 3: WER for \"Speaker1\" after adapting with  ML estimates.", "labels": [], "entities": [{"text": "WER", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9986862540245056}]}]}