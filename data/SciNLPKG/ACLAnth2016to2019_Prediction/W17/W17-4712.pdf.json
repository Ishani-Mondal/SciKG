{"title": [{"text": "Effective Domain Mixing for Neural Machine Translation", "labels": [], "entities": [{"text": "Neural Machine Translation", "start_pos": 28, "end_pos": 54, "type": "TASK", "confidence": 0.7398985226949056}]}], "abstractContent": [{"text": "Neural Machine Translation (NMT) models are often trained on heterogeneous mixtures of domains, from news to parliamentary proceedings, each with unique distributions and language.", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7980485459168752}]}, {"text": "In this work we show that training NMT systems on naively mixed data can degrade performance versus models fit to each constituent domain.", "labels": [], "entities": []}, {"text": "We demonstrate that this problem can be circumvented, and propose three models that do so by jointly learning domain discrimination and translation.", "labels": [], "entities": []}, {"text": "We demonstrate the efficacy of these techniques by merging pairs of domains in three languages: Chinese, French, and Japanese.", "labels": [], "entities": []}, {"text": "After training on composite data, each approach out-performs its domain-specific counterparts , with a model based on a discrim-inator network doing so most reliably.", "labels": [], "entities": []}, {"text": "We obtain consistent performance improvements and an average increase of 1.1 BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 77, "end_pos": 81, "type": "METRIC", "confidence": 0.998775064945221}]}], "introductionContent": [{"text": "Neural Machine Translation (NMT)) is an end-to-end approach for automated translation.", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT))", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7682106246550878}, {"text": "automated translation", "start_pos": 64, "end_pos": 85, "type": "TASK", "confidence": 0.7107643187046051}]}, {"text": "NMT has shown impressive results ( often surpassing those of phrase-based systems while addressing shortcomings such as the need for hand-engineered features.", "labels": [], "entities": [{"text": "NMT", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8155849575996399}]}, {"text": "In many translation settings (e.g. web translation, assistant translators), input may * Equal Contribution.", "labels": [], "entities": [{"text": "web translation", "start_pos": 35, "end_pos": 50, "type": "TASK", "confidence": 0.6961500644683838}]}, {"text": "come from more than one domain.", "labels": [], "entities": []}, {"text": "Each domain has unique properties that could confound models not explicitly fitted to it.", "labels": [], "entities": []}, {"text": "Thus, an important problem is to effectively mix a diversity of training data in a multi-domain setting.", "labels": [], "entities": []}, {"text": "Our problem space is as follows: how can we train a translation model on multi-domain data to improve test-time performance in each constituent domain?", "labels": [], "entities": []}, {"text": "This setting differs from the majority of work in domain adaptation, which explores how models trained on some source domain can be effectively applied to outside target domains.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 50, "end_pos": 67, "type": "TASK", "confidence": 0.7313507944345474}]}, {"text": "This setting is important, because previous research has shown that both standard NMT and adaptation methods degrade performance on the original source domain(s).", "labels": [], "entities": []}, {"text": "We seek to prove that this problem can be overcome, and hypothesize that leveraging the heterogeneity of composite data rather than dampening it will allow us to do so.", "labels": [], "entities": []}, {"text": "To this extent, we propose three new models for multi-domain machine translation.", "labels": [], "entities": [{"text": "multi-domain machine translation", "start_pos": 48, "end_pos": 80, "type": "TASK", "confidence": 0.6212531626224518}]}, {"text": "These models are based on discriminator networks, adversarial learning, and target-side domain tokens.", "labels": [], "entities": []}, {"text": "We evaluate on pairs of linguistically disparate corpora in three translation tasks (EN-JA, EN-ZH, EN-FR), and observe that unlike naively training on mixed data (as per current best practices), the proposed techniques consistently improve translation quality in each individual setting.", "labels": [], "entities": []}, {"text": "The most significant of these tasks is EN-JA, where we obtain state-of-the-art performance in the process of examining the ASPEC corpus ( of scientific papers and SubCrawl, anew corpus based on an anonymous manuscript.", "labels": [], "entities": [{"text": "ASPEC corpus", "start_pos": 123, "end_pos": 135, "type": "DATASET", "confidence": 0.8406564295291901}]}, {"text": "In summary, our contributions are as follows: \u2022 We show that mixing data from heterogenous domains leads to suboptimal results compared to the single-domain setting, and that the more distant these domains are, the more their merger degrades downstream translation quality.", "labels": [], "entities": []}, {"text": "\u2022 We demonstrate that this problem can be circumvented and propose novel, generalpurpose techniques that do so.", "labels": [], "entities": []}], "datasetContent": [{"text": "For the Japanese translation task we evaluate our domain mixing techniques on the standard ASPEC corpus () consisting of 3M scientific document sentence pairs, and the SubCrawl corpus, consisting of 3.2M colloquial sentence pairs harvested from freely available subtitle repositories on the World Wide Web.", "labels": [], "entities": [{"text": "Japanese translation", "start_pos": 8, "end_pos": 28, "type": "TASK", "confidence": 0.7288744151592255}, {"text": "ASPEC corpus", "start_pos": 91, "end_pos": 103, "type": "DATASET", "confidence": 0.7727814018726349}]}, {"text": "We use standard train/dev/test splits (3M, 1.8k, and 1.8k examples, respectively) and preprocess the data using subword units to learn a shared English-Japanese vocabulary of size 32,000.", "labels": [], "entities": []}, {"text": "To allow for fair comparisons, we use the same vocabulary and sentence segmentation for all experiments, including singledomain models.", "labels": [], "entities": [{"text": "sentence segmentation", "start_pos": 62, "end_pos": 83, "type": "TASK", "confidence": 0.7623236775398254}]}, {"text": "To prove its generality, we also evaluate our techniques on a small set of about 200k/1k/1k training/dev/test examples of English Chinese (EN-ZH) and English-French (EN-FR) language pairs.", "labels": [], "entities": []}, {"text": "For EN-ZH, we use a news commentary corpus from WMT'17 2 and a 2012 database dump of TED talk subtitles).", "labels": [], "entities": [{"text": "EN-ZH", "start_pos": 4, "end_pos": 9, "type": "DATASET", "confidence": 0.849968671798706}, {"text": "news commentary corpus from WMT'17 2", "start_pos": 20, "end_pos": 56, "type": "DATASET", "confidence": 0.7046826680501302}]}, {"text": "For EN-FR, we use professional translations of European Parliament Proceedings () and a 2016 dump of the OpenSubtitles database (.", "labels": [], "entities": [{"text": "European Parliament Proceedings", "start_pos": 47, "end_pos": 78, "type": "DATASET", "confidence": 0.8887878855069479}]}, {"text": "The premise of evaluating on mixed-domain data is that the domains undergoing mixing are in fact disparate.", "labels": [], "entities": []}, {"text": "We need to quantifiably measure the disparity therein to obtain fair, valid, and explainable results.", "labels": [], "entities": []}, {"text": "Thus, we measured the distances between the domains of each language pair with A-distance, an important part of the upper generalization bounds for domain adaptation.", "labels": [], "entities": [{"text": "A-distance", "start_pos": 79, "end_pos": 89, "type": "METRIC", "confidence": 0.9814764857292175}, {"text": "domain adaptation", "start_pos": 148, "end_pos": 165, "type": "TASK", "confidence": 0.7609502971172333}]}, {"text": "Due to the intractability of computing A-distances, we instead compute a proxy for A-distance, \u02c6 d A , which is given theoretical justification in Ben- and used to measure domain distance in;.", "labels": [], "entities": []}, {"text": "The proxy A-distance is obtained by measuring the generalization error \u03f5 of a linear bag-of-words SVM classifier trained to discriminate between the two domains, and setting\u02c6dsetting\u02c6 setting\u02c6d A = 2(1\u22122\u03f5).", "labels": [], "entities": [{"text": "A-distance", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.8420157432556152}]}, {"text": "Note that by nature of its formulation, \u02c6 d A is only useful in comparative settings, and means little in isolation.", "labels": [], "entities": []}, {"text": "However, it has a minimum value of 1, implying exact domain match, and a maximum of 2, implying that domains are polar opposites.", "labels": [], "entities": [{"text": "exact domain match", "start_pos": 47, "end_pos": 65, "type": "METRIC", "confidence": 0.74252716700236}]}, {"text": "All models are implemented using the Tensorflow framework and based on the Sequenceto-Sequence implementation of 3 . We use a 4-layer bidirectional LSTM encoder with 512 units, and a 4-layer LSTM decoder.", "labels": [], "entities": []}, {"text": "Recall from Section 3 that we use Bahdanau-style attention.", "labels": [], "entities": []}, {"text": "Dropout of 0.2 (0.8 keep probability) is applied to the input of each cell.", "labels": [], "entities": [{"text": "Dropout", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9511162042617798}, {"text": "keep probability)", "start_pos": 20, "end_pos": 37, "type": "METRIC", "confidence": 0.9768682916959127}]}, {"text": "We optimize using Adam and a learning rate of 0.0001 ( During training, we save model checkpoints every hour and choose the best one using the BLEU score on the validation set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 143, "end_pos": 147, "type": "METRIC", "confidence": 0.998974084854126}]}, {"text": "To calculate BLEU scores for the EN-JA task, we follow the instruction from WAT 4 and use the KyTea tokenizer).", "labels": [], "entities": [{"text": "BLEU scores", "start_pos": 13, "end_pos": 24, "type": "METRIC", "confidence": 0.9717719554901123}]}, {"text": "For the EN-FR and EN-ZH tasks, we follow the WMT '16 guidlines and tokenize with the Moses tokenizer.perl script ().", "labels": [], "entities": [{"text": "WMT '16 guidlines", "start_pos": 45, "end_pos": 62, "type": "DATASET", "confidence": 0.9393995553255081}]}], "tableCaptions": [{"text": " Table 2: BLEU scores for models trained on  various domains and languages (both mixed  and unmixed). Rows correspond to train- ing domains and columns correspond to test  domains. Note that our single-domain AS- PEC results are state-of-the-art, indicating the  strength of these baselines.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9986977577209473}, {"text": "AS- PEC", "start_pos": 209, "end_pos": 216, "type": "TASK", "confidence": 0.5856412251790365}]}]}