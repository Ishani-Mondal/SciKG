{"title": [{"text": "OCR and post-correction of historical Finnish texts", "labels": [], "entities": [{"text": "OCR", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.5115814805030823}]}], "abstractContent": [{"text": "This paper presents experiments on Optical character recognition (OCR) as a combination of Ocropy software and data-driven spelling correction that uses Weighted Finite-State Methods.", "labels": [], "entities": [{"text": "Optical character recognition (OCR)", "start_pos": 35, "end_pos": 70, "type": "TASK", "confidence": 0.8329959909121195}, {"text": "spelling correction", "start_pos": 123, "end_pos": 142, "type": "TASK", "confidence": 0.8306056559085846}]}, {"text": "Both model training and testing were done on Finnish corpora of historical newspaper text and the best combination of OCR and post-processing models give 95.21% character recognition accuracy.", "labels": [], "entities": [{"text": "character recognition", "start_pos": 161, "end_pos": 182, "type": "TASK", "confidence": 0.9057750403881073}, {"text": "accuracy", "start_pos": 183, "end_pos": 191, "type": "METRIC", "confidence": 0.9185386896133423}]}], "introductionContent": [{"text": "In recent years, optical character recognition of printed text has reached high accuracy rates for modern fonts.", "labels": [], "entities": [{"text": "optical character recognition of printed text", "start_pos": 17, "end_pos": 62, "type": "TASK", "confidence": 0.7483498603105545}, {"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9989520311355591}]}, {"text": "However, historical documents still pose a challenge for character recognition and OCR of those documents still does not yield satisfying results.", "labels": [], "entities": [{"text": "character recognition", "start_pos": 57, "end_pos": 78, "type": "TASK", "confidence": 0.9829000234603882}, {"text": "OCR", "start_pos": 83, "end_pos": 86, "type": "TASK", "confidence": 0.5478468537330627}]}, {"text": "This is a problem for all researchers who would like to use those documents as apart of their research.", "labels": [], "entities": []}, {"text": "The main reasons why historical documents still pose a challenge for OCR are: fonts differ in different materials, lack of orthographic standard (same words spelled differently), material quality (some documents can have deformations) and a lexicon of known historical spelling variants is not available (although if they were, they might not give any OCR advantage for morphologically rich languages as noted by, but they can be useful in the post-processing phase).", "labels": [], "entities": [{"text": "OCR", "start_pos": 69, "end_pos": 72, "type": "TASK", "confidence": 0.9635059237480164}]}, {"text": "The leading software frameworks for OCR are commercial ABBYY FineReader and two open source frameworks: Ocropy 2 (previously known as OCRopus) and Tesseract . experiment with these three and compare https://www.abbyy.com 2 https://github.com/tmbdev/ocropy 3 https://github.com/tesseract-ocr their performance on five pages of historical printings of Latin texts.", "labels": [], "entities": [{"text": "OCR", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.9644132256507874}, {"text": "ABBYY FineReader", "start_pos": 55, "end_pos": 71, "type": "DATASET", "confidence": 0.9427462816238403}]}, {"text": "The mean character accuracy they achieve is 81.66% for Ocropy, 80.57% for ABBYY FineReader, and 78.77% for Tesseract.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9869619607925415}, {"text": "Ocropy", "start_pos": 55, "end_pos": 61, "type": "DATASET", "confidence": 0.8570687174797058}, {"text": "ABBYY FineReader", "start_pos": 74, "end_pos": 90, "type": "DATASET", "confidence": 0.6988696753978729}, {"text": "Tesseract", "start_pos": 107, "end_pos": 116, "type": "DATASET", "confidence": 0.8813568949699402}]}, {"text": "However, Finnish historical documents are mainly written in Gothic (Fraktur) font, which is harder to recognize.", "labels": [], "entities": []}, {"text": "The National Library of Finland has scanned, segmented and performed OCR on their historical newspaper corpus with ABBYY FineReader.", "labels": [], "entities": [{"text": "historical newspaper corpus", "start_pos": 82, "end_pos": 109, "type": "DATASET", "confidence": 0.7174711028734843}, {"text": "ABBYY FineReader", "start_pos": 115, "end_pos": 131, "type": "DATASET", "confidence": 0.7731471359729767}]}, {"text": "On a test set that is representative of the bulk of the Finnish material, AB-BYY FineReader's recognition accuracy is only 90.16%.", "labels": [], "entities": [{"text": "Finnish material", "start_pos": 56, "end_pos": 72, "type": "DATASET", "confidence": 0.8553611934185028}, {"text": "AB-BYY FineReader", "start_pos": 74, "end_pos": 91, "type": "METRIC", "confidence": 0.686265617609024}, {"text": "recognition", "start_pos": 94, "end_pos": 105, "type": "TASK", "confidence": 0.7379382848739624}, {"text": "accuracy", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9326158165931702}]}, {"text": "In this work we test how Ocropy performs optical character recognition on historical Finnish documents.", "labels": [], "entities": [{"text": "character recognition on historical Finnish documents", "start_pos": 49, "end_pos": 102, "type": "TASK", "confidence": 0.7087588310241699}]}, {"text": "We achieve a character accuracy of 93.50% with Ocropy when training with Finnish historical data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.990833580493927}, {"text": "Ocropy", "start_pos": 47, "end_pos": 53, "type": "DATASET", "confidence": 0.7250241637229919}, {"text": "Finnish historical data", "start_pos": 73, "end_pos": 96, "type": "DATASET", "confidence": 0.6520345111687978}]}, {"text": "Additionally, we also wanted to find out whether any further improvement in the OCR quality could be achieved by performing OCR post-correction with an unstructured classifier and a lexicon on the Ocropy output.", "labels": [], "entities": [{"text": "Ocropy output", "start_pos": 197, "end_pos": 210, "type": "DATASET", "confidence": 0.9107135832309723}]}, {"text": "Our experiments show that already with a relatively small training set (around 10,000 lines) we can get over 93% accuracy with Ocropy and with additional post-correction, the accuracy goes beyond 94%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.9994217157363892}, {"text": "Ocropy", "start_pos": 127, "end_pos": 133, "type": "METRIC", "confidence": 0.7261865735054016}, {"text": "accuracy", "start_pos": 175, "end_pos": 183, "type": "METRIC", "confidence": 0.9995311498641968}]}, {"text": "With two training sets combined (around 60,000 lines), we get accuracy even over 95%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9996695518493652}]}], "datasetContent": [{"text": "During both the prediction and evaluation phases, we measured the performance of the system by using character accuracy rate (CAR), which is essentially the percentage of correct characters in the system output and is a common metric in OCR-related tasks.", "labels": [], "entities": [{"text": "character accuracy rate (CAR)", "start_pos": 101, "end_pos": 130, "type": "METRIC", "confidence": 0.8416414757569631}, {"text": "OCR-related tasks", "start_pos": 237, "end_pos": 254, "type": "TASK", "confidence": 0.8990715146064758}]}, {"text": "It is the number of correct characters divided by the sum of correct characters and errors in the system output: The number of errors is the overall Levenshtein distance between the system output and the ground truth and includes deletions and insertions.", "labels": [], "entities": [{"text": "Levenshtein distance", "start_pos": 149, "end_pos": 169, "type": "METRIC", "confidence": 0.884765088558197}]}, {"text": "For languages with relatively long words such as Finnish, character accuracy rates and character error rates are arguably better indicators of the overall quality of the text than, for instance, word error rate, since longer words are more likely to contain multiple errors and are thus more difficult to correct.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.7842879891395569}, {"text": "character error rates", "start_pos": 87, "end_pos": 108, "type": "METRIC", "confidence": 0.7731101314226786}, {"text": "word error rate", "start_pos": 195, "end_pos": 210, "type": "METRIC", "confidence": 0.7297916014989217}]}, {"text": "The legibility of a text may actually improve considerably without any notable change in its word error rate.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 93, "end_pos": 108, "type": "METRIC", "confidence": 0.733934760093689}]}], "tableCaptions": [{"text": " Table 3: A confusion matrix for the DIGI test  set after recognition with the DIGI model (before  post-correction)", "labels": [], "entities": [{"text": "DIGI test  set", "start_pos": 37, "end_pos": 51, "type": "DATASET", "confidence": 0.8275631467501322}]}, {"text": " Table 5: Number of mistakes per line after recog- nition on DIGI test set (before post correction)  with both models. The first column shows the  number of mistakes per line, the second column  the frequency of lines after recognition with the  DIGI-model and the third column the frequency  of lines after recognition with the NATLIB-model", "labels": [], "entities": [{"text": "DIGI test set", "start_pos": 61, "end_pos": 74, "type": "DATASET", "confidence": 0.9202771385510763}, {"text": "DIGI-model", "start_pos": 246, "end_pos": 256, "type": "DATASET", "confidence": 0.9010230898857117}, {"text": "NATLIB-model", "start_pos": 329, "end_pos": 341, "type": "DATASET", "confidence": 0.8509554862976074}]}]}