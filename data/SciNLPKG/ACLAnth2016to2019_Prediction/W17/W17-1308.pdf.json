{"title": [{"text": "CAT: Credibility Analysis of Arabic Content on Twitter", "labels": [], "entities": [{"text": "Credibility Analysis of Arabic Content", "start_pos": 5, "end_pos": 43, "type": "TASK", "confidence": 0.7135831654071808}]}], "abstractContent": [{"text": "Data generated on Twitter has become a rich source for various data mining tasks.", "labels": [], "entities": [{"text": "data mining", "start_pos": 63, "end_pos": 74, "type": "TASK", "confidence": 0.718700036406517}]}, {"text": "Those data analysis tasks that are dependent on the tweet semantics, such as sentiment analysis, emotion mining, and rumor detection among others, suffer considerably if the tweet is not credible, not real, or spam.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 77, "end_pos": 95, "type": "TASK", "confidence": 0.9652602970600128}, {"text": "emotion mining", "start_pos": 97, "end_pos": 111, "type": "TASK", "confidence": 0.7301263511180878}, {"text": "rumor detection", "start_pos": 117, "end_pos": 132, "type": "TASK", "confidence": 0.7557565271854401}]}, {"text": "In this paper, we perform an extensive analysis on credibility of Arabic content on Twitter.", "labels": [], "entities": []}, {"text": "We also build a classification model (CAT) to automatically predict the credibility of a given Arabic tweet.", "labels": [], "entities": []}, {"text": "Of particular originality is the inclusion of features extracted directly or indirectly from the au-thor's profile and timeline.", "labels": [], "entities": []}, {"text": "To train and test CAT, we annotated for credibility a data set of 9, 000 Arabic tweets that are topic independent.", "labels": [], "entities": [{"text": "CAT", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.9667346477508545}]}, {"text": "CAT achieved consistent improvements in predicting the credibility of the tweets when compared to several baselines and when compared to the state-of-the-art approach with an improvement of 21% in weighted average F-measure.", "labels": [], "entities": [{"text": "CAT", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.5499452352523804}, {"text": "F-measure", "start_pos": 214, "end_pos": 223, "type": "METRIC", "confidence": 0.8397298455238342}]}, {"text": "We also conducted experiments to highlight the importance of the user-based features as opposed to the content-based features.", "labels": [], "entities": []}, {"text": "We conclude our work with a feature reduction experiment that highlights the best indicative features of credibility.", "labels": [], "entities": [{"text": "feature reduction", "start_pos": 28, "end_pos": 45, "type": "TASK", "confidence": 0.6765723377466202}]}], "introductionContent": [{"text": "The Web has become a treasured source of opinions, news and information about current events.", "labels": [], "entities": []}, {"text": "Twitter, Facebook, Instagram, and others play a vital role in publishing such information.", "labels": [], "entities": []}, {"text": "This immense data has become a vital and rich source for tasks such as popularity index, elections, opinion mining, pro/con classification, emotion recognition, rumor detection, etc.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 100, "end_pos": 114, "type": "TASK", "confidence": 0.7732495665550232}, {"text": "pro/con classification", "start_pos": 116, "end_pos": 138, "type": "TASK", "confidence": 0.7215169370174408}, {"text": "emotion recognition", "start_pos": 140, "end_pos": 159, "type": "TASK", "confidence": 0.7526005804538727}, {"text": "rumor detection", "start_pos": 161, "end_pos": 176, "type": "TASK", "confidence": 0.933368444442749}]}, {"text": "With the large scale of data generated on these outlets, it is inevitable that the credibility of the generated information would highly vary.", "labels": [], "entities": []}, {"text": "This would in turn influence the opinions of the readers and the accuracy of the tasks performed on such data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9990087747573853}]}, {"text": "A recent study by indicated that fake news published on social media during and before the American presidential elections in November 2016, did have an effect on voters, but was not the reason behind the victory of Trump.", "labels": [], "entities": []}, {"text": "Others suggest otherwise and confirm that fake news made Trump president.", "labels": [], "entities": []}, {"text": "Take for instance an interview with the Washington Post, when fake news writer and promoter Paul Horner said that \"I think Trump is in the White House because of me\", hinting that his fake news were believed by the voters and even adopted and shared . In this paper, we focus on tweets, being a main source of news and opinions, and propose a model, called CAT, that best classifies tweets as credible or not.", "labels": [], "entities": []}, {"text": "We adopt the Merriam Webster definition of credibility that states: credibility is the quality of being believed or accepted as true, real or honest.", "labels": [], "entities": [{"text": "Merriam Webster definition", "start_pos": 13, "end_pos": 39, "type": "DATASET", "confidence": 0.9108402927716573}, {"text": "credibility", "start_pos": 68, "end_pos": 79, "type": "METRIC", "confidence": 0.9635067582130432}]}, {"text": "CAT uses a binary classifier that classifies a given tweet as either credible or not.", "labels": [], "entities": [{"text": "CAT", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.6791183948516846}]}, {"text": "CAT is built on top of an exhaustive set of features which includes both content based and user-based features.", "labels": [], "entities": [{"text": "CAT", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8162541389465332}]}, {"text": "Content-based features are features extracted from the tweet itself, for instance, sentiment, language, and text cues, whereas user-based features are extracted from the tweet author, for instance, exper-tise of the user generating the tweet, and the number of followers.", "labels": [], "entities": []}, {"text": "In particular, we use 26 contentbased features and 22 user-based features.", "labels": [], "entities": []}, {"text": "To train and test our classifier, we extracted over 9, 000 Arabic tweets and annotated them with the help of six well-paid human judges using a custom crowd-sourcing platform.", "labels": [], "entities": []}, {"text": "The 9, 000 tweets were divided among the judges to obtain three annotations for each tweet.", "labels": [], "entities": []}, {"text": "The judges annotated each tweet as either \"credible\", \"non-credible\" or \"can't decide\".", "labels": [], "entities": []}, {"text": "To assist the annotators in accurately assessing the credibility of a given tweet, they were provided with useful cues such as the tweet itself and its author.", "labels": [], "entities": []}, {"text": "While we based our experiments on Arabic content, our credibility model is general enough to predict the credibility of tweets in any language provided that the necessary resources for extracting some of the language dependent features such as sentiment are available.", "labels": [], "entities": []}, {"text": "Predicting the credibility of tweets has been previously studied to some extent.", "labels": [], "entities": []}, {"text": "However, to the best of our knowledge, none of the previous work considered features from timeline or profilepicture face detection to assess the credibility of a given tweet.", "labels": [], "entities": [{"text": "profilepicture face detection", "start_pos": 102, "end_pos": 131, "type": "TASK", "confidence": 0.5636813243230184}]}, {"text": "For example, relies on some features including the presence of a profile picture to perform credibility assessment.", "labels": [], "entities": [{"text": "credibility assessment", "start_pos": 92, "end_pos": 114, "type": "TASK", "confidence": 0.7856623530387878}]}, {"text": "However, in our approach, we do not only evaluate the presence of a profile picture, we also take this feature one step further by using Google cloud vision API to perform face detection and extract textual information that might be available in the picture.", "labels": [], "entities": [{"text": "face detection", "start_pos": 172, "end_pos": 186, "type": "TASK", "confidence": 0.7684073746204376}]}, {"text": "We compared CAT to several baselines and to a recent state of-the-art approach, namely, TweetCred ().", "labels": [], "entities": [{"text": "CAT", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.9525312185287476}]}, {"text": "CAT consistently surpassed the accuracy of the baseline approaches.", "labels": [], "entities": [{"text": "CAT", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.6844423413276672}, {"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9996985197067261}]}, {"text": "It also outperformed TweetCred with an improvement of 16.7% in Weighted Average F-measure.", "labels": [], "entities": [{"text": "Weighted Average F-measure", "start_pos": 63, "end_pos": 89, "type": "METRIC", "confidence": 0.864407499631246}]}, {"text": "While TweetCred relies in its classification on real-time features only, CAT utilizes the authors history for any clues that might be helpful in deciding on the credibility of the tweet.", "labels": [], "entities": []}, {"text": "Finally, most of the previous work on predicting the credibility of tweets have been based on annotated English tweets.", "labels": [], "entities": [{"text": "predicting the credibility of tweets", "start_pos": 38, "end_pos": 74, "type": "TASK", "confidence": 0.8643593311309814}]}, {"text": "In this paper, we propose a robust credibility classifier (CAT) that can work for tweets in any language and we test it on a relatively big data set of Arabic tweets.", "labels": [], "entities": [{"text": "credibility classifier (CAT)", "start_pos": 35, "end_pos": 63, "type": "TASK", "confidence": 0.6966658771038056}]}, {"text": "Our annotated data set of 9, 000 Arabic tweets is made public to act as a valuable resource for future research in this area.", "labels": [], "entities": []}, {"text": "Another credibility data set exists, but it is smaller and topic dependent).", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we present the credibility classifier (CAT) and evaluate it vs. multiple baselines and another well-known method.", "labels": [], "entities": [{"text": "credibility classifier (CAT)", "start_pos": 32, "end_pos": 60, "type": "TASK", "confidence": 0.7325568854808807}]}, {"text": "We used the annotated data and the extracted features to train a random forest decision tree classifier using scikitlearn python library 3 . A majority vote was used to decide on the labels of the tweets.", "labels": [], "entities": []}, {"text": "We validate the applicability of our classifier (CAT) by doing two different experimental setups.", "labels": [], "entities": []}, {"text": "First, we compare CAT to three baselines.", "labels": [], "entities": [{"text": "CAT", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.9158703088760376}]}, {"text": "Then, we compare CAT to a state-of-the-art tweet credibility classifier -TweetCred ().", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: CAT's against baseline classifiers", "labels": [], "entities": [{"text": "CAT", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.940592885017395}]}, {"text": " Table 3: CAT's against TweetCred Classifier", "labels": [], "entities": []}, {"text": " Table 4: CAT's evaluation using different feature  sets", "labels": [], "entities": [{"text": "CAT", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.9755814075469971}]}]}