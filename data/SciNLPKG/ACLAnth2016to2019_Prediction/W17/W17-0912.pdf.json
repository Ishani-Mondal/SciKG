{"title": [{"text": "IIT (BHU): System Description for LSDSem'17 Shared Task", "labels": [], "entities": [{"text": "IIT (BHU)", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.8376761674880981}]}], "abstractContent": [{"text": "This paper describes an ensemble system submitted as part of the LSDSem Shared Task 2017-the Story Cloze Test.", "labels": [], "entities": [{"text": "LSDSem Shared Task 2017-the Story Cloze Test", "start_pos": 65, "end_pos": 109, "type": "DATASET", "confidence": 0.8085581575121198}]}, {"text": "The main conclusion from our results is that an approach based on semantic similarity alone may not be enough for this task.", "labels": [], "entities": []}, {"text": "We test various approaches and compare them with two ensemble systems.", "labels": [], "entities": []}, {"text": "One is based on voting and the other on logistic regression based classifier.", "labels": [], "entities": []}, {"text": "Our final system is able to outperform the previous state of the art for the Story Cloze test.", "labels": [], "entities": [{"text": "Story Cloze test", "start_pos": 77, "end_pos": 93, "type": "DATASET", "confidence": 0.8729180494944254}]}, {"text": "Another very interesting observation is the performance of sentiment based approach which works almost as well on its own as our final ensemble system.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Story Cloze Test) is a recently introduced framework to evaluate story understanding and script learning.", "labels": [], "entities": [{"text": "story understanding", "start_pos": 69, "end_pos": 88, "type": "TASK", "confidence": 0.7766178250312805}, {"text": "script learning", "start_pos": 93, "end_pos": 108, "type": "TASK", "confidence": 0.7963346242904663}]}, {"text": "Representation of commonsense knowledge is major theme in Natural Language Processing and is also important for this task.", "labels": [], "entities": [{"text": "Representation of commonsense knowledge", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.8486365526914597}, {"text": "Natural Language Processing", "start_pos": 58, "end_pos": 85, "type": "TASK", "confidence": 0.6251756151517233}]}, {"text": "The organizers provide a training corpus called the ROCStories dataset (we will refer to it as the Story Cloze corpus or dataset).", "labels": [], "entities": [{"text": "ROCStories dataset", "start_pos": 52, "end_pos": 70, "type": "DATASET", "confidence": 0.8971402645111084}, {"text": "Story Cloze corpus or dataset", "start_pos": 99, "end_pos": 128, "type": "DATASET", "confidence": 0.9073663234710694}]}, {"text": "It consists of very simple 98161 everyday life stories (combining the spring and winter training sets).", "labels": [], "entities": []}, {"text": "All stories consist of five sentences which capture 'causal and temporal commonsense relations between daily events'.", "labels": [], "entities": []}, {"text": "The validation and test sets contain 1871 samples each, where each sample contains the first four sentences (the context) of the story, and the system has to complete the story by choosing the fifth sentence (the correct ending) out of the two alternatives provided.", "labels": [], "entities": []}, {"text": "Some of the approaches described in) are used as it is in our system, while some approaches not tried before in the context of this task (to the best of our knowledge) also form parts of our final ensemble models.", "labels": [], "entities": []}, {"text": "Most approaches tried before and also in our experiments rely directly or indirectly on the idea of using semantic similarity of the context and the ending to make the decision.", "labels": [], "entities": []}, {"text": "The results point to the conclusion that semantic similarity (at least on its own) maybe inadequate as an approach for the Story Cloze test.", "labels": [], "entities": [{"text": "semantic similarity", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.7436626553535461}, {"text": "Story Cloze test", "start_pos": 123, "end_pos": 139, "type": "DATASET", "confidence": 0.8651832739512125}]}, {"text": "Our final system is an ensemble combining the different approaches we tried.", "labels": [], "entities": []}, {"text": "It achieves an accuracy of 60.45 on the test set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9997003078460693}]}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "The next section describes various experiments and approaches we tried.", "labels": [], "entities": []}, {"text": "Section 3 describes how the different approaches come together to form the system we submitted.", "labels": [], "entities": []}, {"text": "Section 4 looks at the various results and draws inferences to make our point.", "labels": [], "entities": []}, {"text": "Section 5 presents a small error analysis.", "labels": [], "entities": []}, {"text": "Finally, Section 6 presents the conclusions and discusses possible future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results for individual approaches (last row represents results on the test set for corresponding  approach in (Mostafazadeh et al., 2016)", "labels": [], "entities": []}, {"text": " Table 2: Results for the best ensemble models", "labels": [], "entities": []}]}