{"title": [{"text": "Hybrid Approach for Marathi Named Entity Recognition", "labels": [], "entities": [{"text": "Approach", "start_pos": 7, "end_pos": 15, "type": "METRIC", "confidence": 0.9524081349372864}, {"text": "Marathi Named Entity Recognition", "start_pos": 20, "end_pos": 52, "type": "TASK", "confidence": 0.80034239590168}]}], "abstractContent": [], "introductionContent": [{"text": "Named Entity Recognition (NER) is information extraction task which can play significant role in many different natural language processing tasks such as information retrieval, machine translation, question answering systems etc.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7601317117611567}, {"text": "information extraction task", "start_pos": 34, "end_pos": 61, "type": "TASK", "confidence": 0.8135482867558798}, {"text": "information retrieval", "start_pos": 154, "end_pos": 175, "type": "TASK", "confidence": 0.7633418142795563}, {"text": "machine translation", "start_pos": 177, "end_pos": 196, "type": "TASK", "confidence": 0.800190657377243}, {"text": "question answering", "start_pos": 198, "end_pos": 216, "type": "TASK", "confidence": 0.8333080410957336}]}, {"text": "Predefined entities in text such as people, organizations, locations, events, expressions such as amount, percentage, numbers, date, time are named entities (NEs).", "labels": [], "entities": []}, {"text": "Identification of NEs from unstructured text and their classification into suitable NE class is known as NER.", "labels": [], "entities": [{"text": "Identification of NEs", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8277458747227987}]}, {"text": "This paper describes a hybrid model based on Hidden Markov Model (HMM), handcrafted rules and gazetteers to recognize named entities in Marathi.", "labels": [], "entities": []}, {"text": "The difficulties of unseen probabilities are handled by pseudo word replacement and poor probabilities caused due to sparse data are handled using smoothing techniques.", "labels": [], "entities": [{"text": "pseudo word replacement", "start_pos": 56, "end_pos": 79, "type": "TASK", "confidence": 0.5967527031898499}]}, {"text": "Viterbi alogirithm is used for decoding and word disambiguation.", "labels": [], "entities": [{"text": "word disambiguation", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.764133483171463}]}, {"text": "The performance of the system is improved using gazetteers.", "labels": [], "entities": []}, {"text": "Linguistic rules are used to generate patterns that can recognize dates, time and numerical expressions.", "labels": [], "entities": []}, {"text": "Following MUC specifications twelve types of NE are considered in recognition problem they are Person, Organization, Location, Miscellaneous, Amount, Number, Date, Time, Year, Month, reported the NER system based on trigram HMM model trained using pre-processed data for the Marathi language.", "labels": [], "entities": [{"text": "MUC", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.8145071864128113}, {"text": "Amount", "start_pos": 142, "end_pos": 148, "type": "METRIC", "confidence": 0.9663984179496765}]}, {"text": "The system uses Viterbi decoding to generate the optimal tag sequence for the test data.", "labels": [], "entities": []}, {"text": "The system implemented using lemma model with trigram HMM has performed well in NE recognition, but it has further scope for improvement.", "labels": [], "entities": [{"text": "NE recognition", "start_pos": 80, "end_pos": 94, "type": "TASK", "confidence": 0.9740654230117798}]}, {"text": "Numerical NEs generally follow some fixed patterns, hence linguistic knowledge based recognition could be the better choice than probability based recognition.", "labels": [], "entities": [{"text": "Numerical NEs", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.7633231580257416}, {"text": "linguistic knowledge based recognition", "start_pos": 58, "end_pos": 96, "type": "TASK", "confidence": 0.6107313856482506}]}, {"text": "The study aims to improve NE recognition rate by combining effectiveness of statistical model with goodness of rule and gazetteer based technique for Marathi NER.", "labels": [], "entities": [{"text": "NE recognition", "start_pos": 26, "end_pos": 40, "type": "TASK", "confidence": 0.9839965403079987}, {"text": "Marathi NER", "start_pos": 150, "end_pos": 161, "type": "TASK", "confidence": 0.5438538640737534}]}, {"text": "The paper is organized in five main sections.", "labels": [], "entities": []}, {"text": "Introduction and literature survey is discussed in first and second section.", "labels": [], "entities": []}, {"text": "Supervised learning method for Marathi NER that uses HMM is described in third section.", "labels": [], "entities": [{"text": "Marathi NER", "start_pos": 31, "end_pos": 42, "type": "TASK", "confidence": 0.5364334583282471}, {"text": "HMM", "start_pos": 53, "end_pos": 56, "type": "DATASET", "confidence": 0.6924558281898499}]}, {"text": "Fourth section briefs about rules and gazetteer based Marathi named entity recognition and the fifth section of the paper describes proposed hybrid model for development of Marathi NER system.", "labels": [], "entities": [{"text": "Marathi named entity recognition", "start_pos": 54, "end_pos": 86, "type": "TASK", "confidence": 0.6096536964178085}, {"text": "Marathi NER", "start_pos": 173, "end_pos": 184, "type": "TASK", "confidence": 0.4452512413263321}]}], "datasetContent": [{"text": "FIRE-2010 corpus is used to develop NE annotated corpus by manually tagging 12 types of NEs.", "labels": [], "entities": [{"text": "FIRE-2010 corpus", "start_pos": 0, "end_pos": 16, "type": "DATASET", "confidence": 0.98001629114151}]}, {"text": "27,177 sentences of Marathi text have been annotated using IOBES scheme.", "labels": [], "entities": [{"text": "IOBES", "start_pos": 59, "end_pos": 64, "type": "METRIC", "confidence": 0.6833453178405762}]}, {"text": "Training data developed for Marathi NER consists of 4,01,295 word forms that comprise of 12,303 person names, 7,440 organization, 10,015 location, 3,242 miscellaneous, 7,093 number, 1,500 amount, 2,967 measure, 1,549 date, 369 time, 197 month, 456 weekdays, and 395 year named entities.", "labels": [], "entities": [{"text": "Marathi NER", "start_pos": 28, "end_pos": 39, "type": "TASK", "confidence": 0.6270904541015625}]}, {"text": "The rich morphology of the Marathi language allows adding suffixes and prefixes to a morpheme to add semantic to a word and to create meaningful context.", "labels": [], "entities": []}, {"text": "It is observed during corpus annotation that almost all NE instances are present in inflected form.", "labels": [], "entities": []}, {"text": "Although the dataset is large enough, frequency count of word is found to be lower since inflections result in same word appearing in different forms.", "labels": [], "entities": [{"text": "frequency count", "start_pos": 38, "end_pos": 53, "type": "METRIC", "confidence": 0.9466686546802521}]}, {"text": "This further results in poor probabilities and sparse data problem in MLE estimates.", "labels": [], "entities": [{"text": "MLE estimates", "start_pos": 70, "end_pos": 83, "type": "TASK", "confidence": 0.9134878516197205}]}, {"text": "Lemmatization based preprocessing deals with such inflections and is used in the preprocessing of training and testing datasets.", "labels": [], "entities": []}, {"text": "Preparation Two sets of training and testing datasets is created by dividing the NE annotated corpus preprocessed using lemmatization in 80:20 and 90:10 percent proportions.", "labels": [], "entities": [{"text": "Preparation", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9482929706573486}]}, {"text": "The actual number of sentences in the corpus are computed, 20% of the total sentences in the corpus were randomly selected and removed from the corpus.  is termed as Held-out dataset1.", "labels": [], "entities": []}, {"text": "The remaining sentences (80%) in the corpus (training dataset1) were used to train the NER system.", "labels": [], "entities": [{"text": "NER", "start_pos": 87, "end_pos": 90, "type": "TASK", "confidence": 0.6481339335441589}]}, {"text": "Similarly, 10% of the total sentences in the corpus were randomly selected, removed and stored in Held-out dataset2.", "labels": [], "entities": [{"text": "Held-out dataset2", "start_pos": 98, "end_pos": 115, "type": "DATASET", "confidence": 0.8494083285331726}]}, {"text": "The remaining sentences (90%) in the corpus (training dataset2) were used to train the NER system.", "labels": [], "entities": [{"text": "NER", "start_pos": 87, "end_pos": 90, "type": "TASK", "confidence": 0.6467094421386719}]}, {"text": "The total number of NE instances found in the training dataset1, training dataset2, held-out dataset1 and held-out dataset2 are shown in  Unseen dataset1 is a dataset composed of news items taken from online eSakal newspaper in October 2016.", "labels": [], "entities": [{"text": "training dataset2", "start_pos": 65, "end_pos": 82, "type": "DATASET", "confidence": 0.7426627278327942}, {"text": "Unseen dataset1 is a dataset composed of news items taken from online eSakal newspaper in October 2016", "start_pos": 138, "end_pos": 240, "type": "DATASET", "confidence": 0.8656081364435309}]}, {"text": "Unseen dataset2 is a dataset composed of news items taken from online eSakal newspaper in February 2017.", "labels": [], "entities": [{"text": "Unseen dataset2 is a dataset composed of news items taken from online eSakal newspaper in February 2017", "start_pos": 0, "end_pos": 103, "type": "DATASET", "confidence": 0.865917724721572}]}, {"text": "Both the unseen datasets were tokenized and preprocessed using lemmatization.", "labels": [], "entities": []}, {"text": "The total number of NE instances found in the unseen dataset1 and unseen dataset2 is shown in table 4.", "labels": [], "entities": []}, {"text": "The NE annotated corpus pre-processed using lemmatization consisting of 27,177 sentences mentioned in the dataset preparation section is used to train the NER system.", "labels": [], "entities": [{"text": "NE annotated corpus pre-processed", "start_pos": 4, "end_pos": 37, "type": "DATASET", "confidence": 0.7493754327297211}]}, {"text": "The performance of the Marathi NER based on hybrid approach is evaluated using four varying size datasets containing varying number of NEs.", "labels": [], "entities": [{"text": "Marathi NER", "start_pos": 23, "end_pos": 34, "type": "TASK", "confidence": 0.6044171899557114}]}, {"text": "Out of them two datasets were held out and remaining two datasets were unknown datasets.", "labels": [], "entities": []}, {"text": "The system is trained on dataset(s) preprocessed using lemmatization.", "labels": [], "entities": []}, {"text": "The performance of the system using held out datasets is shown in table 5 and 6.", "labels": [], "entities": []}, {"text": "The overall NE identification accuracy reported by the system for held out dataset1 and 2 is 93.35% and 98.14% respectively.", "labels": [], "entities": [{"text": "NE identification", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.907987654209137}, {"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9431232810020447}]}, {"text": "The average NE classification accuracy reported is 95.24% and 97.79% respectively.", "labels": [], "entities": [{"text": "NE classification", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.8186840116977692}, {"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9689551591873169}]}, {"text": "The overall NE identification accuracy reported by the system for unseen dataset1 and 2 is 81.37% and 83.33% respectively which is relatively satisfactory.", "labels": [], "entities": [{"text": "NE identification", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.9078250527381897}, {"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9461746215820312}]}, {"text": "The average NE classification accuracy reported for unseen dataset1 and 2 is 83.09% and 84.23% respectively.", "labels": [], "entities": [{"text": "NE classification", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.7920179665088654}, {"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9448611736297607}]}, {"text": "The NE recognition accuracy for organization NE is relatively less result in unsatisfactory average NE classification accuracy for unseen dataset2.", "labels": [], "entities": [{"text": "NE recognition", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.8684518337249756}, {"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.6468235850334167}, {"text": "NE classification", "start_pos": 100, "end_pos": 117, "type": "TASK", "confidence": 0.7075483202934265}, {"text": "accuracy", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.5759566426277161}]}, {"text": "Numeric NEs in this dataset were accurately recognized than the enamex type of NEs by the system.", "labels": [], "entities": []}, {"text": "The performance of the system using unseen datasets is shown in       The cumulative performance of Marathi NER system based on Hybrid approach for held out and unseen test datasets is shown in table 9.", "labels": [], "entities": [{"text": "Marathi NER system", "start_pos": 100, "end_pos": 118, "type": "DATASET", "confidence": 0.8149154583613077}]}, {"text": "NE identification and classification reported by this system is 90% approximately, which is satisfactory for Marathi language.", "labels": [], "entities": [{"text": "NE identification", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9294898509979248}]}], "tableCaptions": [{"text": " Table 1: Part of Unseen Bigram Tag Combi- nations", "labels": [], "entities": [{"text": "Unseen Bigram Tag Combi- nations", "start_pos": 18, "end_pos": 50, "type": "DATASET", "confidence": 0.6339992036422094}]}, {"text": " Table 2: Comparison between Tp Computa- tions for Two Solutions  106", "labels": [], "entities": []}, {"text": " Table 3: Held Out Training and Testing Dataset Details", "labels": [], "entities": [{"text": "Held Out Training and Testing Dataset Details", "start_pos": 10, "end_pos": 55, "type": "DATASET", "confidence": 0.5228342371327537}]}, {"text": " Table 4: Unseen Test Dataset Details", "labels": [], "entities": [{"text": "Unseen Test Dataset Details", "start_pos": 10, "end_pos": 37, "type": "DATASET", "confidence": 0.6326659843325615}]}, {"text": " Table 5: NER System Performance on Held- out Dataset1", "labels": [], "entities": [{"text": "NER", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.78923499584198}, {"text": "Held- out Dataset1", "start_pos": 36, "end_pos": 54, "type": "DATASET", "confidence": 0.5935783758759499}]}, {"text": " Table 6: NER System Performance on Held- out Dataset2", "labels": [], "entities": [{"text": "Held- out Dataset2", "start_pos": 36, "end_pos": 54, "type": "DATASET", "confidence": 0.5999402105808258}]}, {"text": " Table 7: NER System Performance on Unseen  Dataset1", "labels": [], "entities": [{"text": "NER", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.8555511236190796}]}, {"text": " Table 8: NER System Performance on Unseen  Dataset2", "labels": [], "entities": []}, {"text": " Table 9: Average Performance of NER", "labels": [], "entities": [{"text": "Average", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9935688972473145}, {"text": "NER", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.9523181915283203}]}]}