{"title": [{"text": "Automatic classification of doctor-patient questions fora virtual patient record query task", "labels": [], "entities": []}], "abstractContent": [{"text": "We present the work-in-progress of automating the classification of doctor-patient questions in the context of a simulated consultation with a virtual patient.", "labels": [], "entities": [{"text": "classification of doctor-patient questions", "start_pos": 50, "end_pos": 92, "type": "TASK", "confidence": 0.7652560323476791}]}, {"text": "We classify questions according to the computational strategy (rule-based or other) needed for looking up data in the clinical record.", "labels": [], "entities": []}, {"text": "We compare 'tradi-tional' machine learning methods (Gaus-sian and Multinomial Naive Bayes, and Support Vector Machines) and a neural network classifier (FastText).", "labels": [], "entities": []}, {"text": "We obtained the best results with the SVM using semantic annotations, but the neural classi-fier achieved promising results without it.", "labels": [], "entities": []}], "introductionContent": [{"text": "Previous work on question classification has mostly been undertaken within the framework of question answering (hereafter, QA) tasks, where classification is but one step of the overall process.", "labels": [], "entities": [{"text": "question classification", "start_pos": 17, "end_pos": 40, "type": "TASK", "confidence": 0.854820042848587}, {"text": "question answering", "start_pos": 92, "end_pos": 110, "type": "TASK", "confidence": 0.7780383229255676}]}, {"text": "Other steps are linguistic/semantic question processing, answer retrieval and generation by integrating data; indeed, these make QA a different task to that of standard information retrieval.", "labels": [], "entities": [{"text": "linguistic/semantic question processing", "start_pos": 16, "end_pos": 55, "type": "TASK", "confidence": 0.617874276638031}, {"text": "answer retrieval", "start_pos": 57, "end_pos": 73, "type": "TASK", "confidence": 0.9149234592914581}, {"text": "information retrieval", "start_pos": 169, "end_pos": 190, "type": "TASK", "confidence": 0.7465435564517975}]}, {"text": "Biomedical QA has mostly focused on questions that aim to obtain knowledge to help diagnose or cure diseases, by medical doctors or by patients (, or to obtain knowledge on biology (.", "labels": [], "entities": [{"text": "Biomedical QA", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.7828151881694794}]}, {"text": "Clinical questions to obtain data from patient records have also been addressed (.", "labels": [], "entities": []}, {"text": "Herein, we address a question classification task from a different perspective to existing research.", "labels": [], "entities": [{"text": "question classification task", "start_pos": 21, "end_pos": 49, "type": "TASK", "confidence": 0.8406261006991068}]}, {"text": "Our task is set in a simulated consultation scenario where a user (a medical doctor trainee) asks questions to a virtual patient (hereafter, VP) (Jaffe et al.,) during the anamnesis stage, i.e. the interview to the patient to obtain diagnostic information.", "labels": [], "entities": []}, {"text": "Question types need accurate classification to search the data in the clinical record.", "labels": [], "entities": []}, {"text": "In this context, question classification has aimed at identifying detailed question types (.", "labels": [], "entities": [{"text": "question classification", "start_pos": 17, "end_pos": 40, "type": "TASK", "confidence": 0.8726712167263031}]}, {"text": "In contrast, we consider a situation where we already have a rule-based question analysis system that classifies questions according to the semantic function or content (in order to restrict the search for data in the patient record and reply coherently).", "labels": [], "entities": []}, {"text": "This strategy works well as long as questions remain within its specifications; other questions should be handled by a different strategy.", "labels": [], "entities": []}, {"text": "What is needed in this context is away to determine whether a given question should be transmitted to the rule-based system or to a fallback strategy.", "labels": [], "entities": []}, {"text": "This is the goal of the present research, which is tackled as a binary classification task. is a schema of the processing steps we address in this work (note that we do not represent other stages such as dialogue management).", "labels": [], "entities": [{"text": "dialogue management", "start_pos": 204, "end_pos": 223, "type": "TASK", "confidence": 0.8087854385375977}]}, {"text": "Guiding the processing of input questions is a common step in QA systems.", "labels": [], "entities": [{"text": "Guiding the processing of input questions", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.8395852347215017}]}, {"text": "Questions maybe filtered through an upfront classifier based on machine-learning techniques, parsing), regular expressions and syntactic rules, or hybrid methods ().", "labels": [], "entities": []}, {"text": "To achieve that, a question analysis process might precede, which may involve detecting lexical answer types, question targets or the question focus.", "labels": [], "entities": [{"text": "question analysis", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.7766952216625214}]}, {"text": "Our VP system relies on named entity recognition and domain semantic labels in the question analysis.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 24, "end_pos": 48, "type": "TASK", "confidence": 0.686996191740036}]}, {"text": "The results we report seem to show that leveraging this semantic information was beneficial for the classification step.", "labels": [], "entities": [{"text": "classification", "start_pos": 100, "end_pos": 114, "type": "TASK", "confidence": 0.976598858833313}]}, {"text": "We also tested a neural method without the semantic information, and indeed did not achieve the best performance (despite having promising results).", "labels": [], "entities": []}, {"text": "We suggest: Schema of the question processing and search for data in the virtual patient record that using a linear SVM classifier with the semantic information defined for the task (together with features such as token frequency and 3-grams) is a reliable technique for question triage in a rulebased system similar to the one we present.", "labels": [], "entities": [{"text": "question processing", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.7238866686820984}, {"text": "question triage", "start_pos": 271, "end_pos": 286, "type": "TASK", "confidence": 0.7753747701644897}]}, {"text": "We report results of the classification task and compare traditional machine-learning and a neural-network supervised classifiers ( . We briefly review approaches to question classification ( \u00a72) and outline our task ( \u00a73).", "labels": [], "entities": [{"text": "question classification", "start_pos": 166, "end_pos": 189, "type": "TASK", "confidence": 0.7902195453643799}]}, {"text": "Then, we explain the sources of our data and describe them ( \u00a74).", "labels": [], "entities": []}, {"text": "We present our methods ( \u00a75) and give our results ( \u00a76) then conclude ( \u00a77).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Distribution of experimental data (stdev  = standard deviation)", "labels": [], "entities": []}, {"text": " Table 3: Avg. F1 of non-neural classifiers with the best tested features in training and test sets", "labels": [], "entities": [{"text": "Avg. F1", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.8702764908472697}]}, {"text": " Table 4: Results of the best tested models (neural approach)", "labels": [], "entities": []}]}