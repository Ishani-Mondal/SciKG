{"title": [{"text": "One Representation per Word -Does it make Sense for Composition?", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we investigate whether an a priori disambiguation of word senses is strictly necessary or whether the meaning of a word in context can be disambiguated through composition alone.", "labels": [], "entities": []}, {"text": "We evaluate the performance of off-the-shelf single-vector and multi-sense vector models on a benchmark phrase similarity task and a novel task for word-sense discrimination.", "labels": [], "entities": [{"text": "word-sense discrimination", "start_pos": 148, "end_pos": 173, "type": "TASK", "confidence": 0.8044725358486176}]}, {"text": "We find that single-sense vector models perform as well or better than multi-sense vector models despite arguably less clean elementary representations.", "labels": [], "entities": []}, {"text": "Our findings furthermore show that simple composition functions such as pointwise addition are able to recover sense specific information from a single-sense vector model remarkably well.", "labels": [], "entities": []}], "introductionContent": [{"text": "Distributional word representations based on counting co-occurrences have along history in natural language processing and have successfully been applied to numerous tasks such as sentiment analysis, recognising textual entailment, wordsense disambiguation and many other important problems.", "labels": [], "entities": [{"text": "Distributional word representations", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.6446714103221893}, {"text": "natural language processing", "start_pos": 91, "end_pos": 118, "type": "TASK", "confidence": 0.6815037528673807}, {"text": "sentiment analysis", "start_pos": 180, "end_pos": 198, "type": "TASK", "confidence": 0.9643324613571167}, {"text": "recognising textual entailment", "start_pos": 200, "end_pos": 230, "type": "TASK", "confidence": 0.7397603392601013}, {"text": "wordsense disambiguation", "start_pos": 232, "end_pos": 256, "type": "TASK", "confidence": 0.7545307278633118}]}, {"text": "More recently low-dimensional and dense neural word embeddings have received a considerable amount of attention in the research community and have become ubiquitous in numerous NLP pipelines in academia and industry.", "labels": [], "entities": []}, {"text": "One fundamental simplifying assumption commonly made in distributional semantic models, however, is that every word can be encoded by a single representation.", "labels": [], "entities": []}, {"text": "Combining polysemous lexemes into a single vector has the consequence of essentially creating a weighted average of all observed meanings of a lexeme in a given text corpus.", "labels": [], "entities": []}, {"text": "Therefore a number of proposals have been made to overcome the issue of conflating several different senses of an individual lexeme into a single representation.", "labels": [], "entities": []}, {"text": "One approach) is to try directly inferring a predefined number of senses from data and subsequently label any occurrences of a polysemous lexeme with the inferred inventory.", "labels": [], "entities": []}, {"text": "Similar approaches are proposed by and who show that appropriate sense selection or disambiguation typically improves performance for composition of noun phrases) and verb phrases (.", "labels": [], "entities": []}, {"text": "proposed a model that represents the meaning of a word as a probability distribution over latent senses which is modulated based on contextualisation, and report improved performance on a word similarity task and the lexical substitution task.", "labels": [], "entities": [{"text": "word similarity task", "start_pos": 188, "end_pos": 208, "type": "TASK", "confidence": 0.7659580409526825}, {"text": "lexical substitution task", "start_pos": 217, "end_pos": 242, "type": "TASK", "confidence": 0.7692649761835734}]}, {"text": "Other approaches leverage an existing lexical resource such as BabelNet or WordNet to obtain sense labels a priori to creating word representations (, or as a postprocessing step after obtaining initial word representations.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 75, "end_pos": 82, "type": "DATASET", "confidence": 0.9576034545898438}]}, {"text": "While these approaches have exhibited strong performance on benchmark word similarity tasks () and some downstream processing tasks such as part-of-speech tagging and relation identification (, they have been weaker than the single-vector representations at predicting the compositionality of multi-word expressions (, and at tasks which require the meaning of a word to be considered in context; e.g, word sense disambiguation) and word similarity in context (.", "labels": [], "entities": [{"text": "benchmark word similarity tasks", "start_pos": 60, "end_pos": 91, "type": "TASK", "confidence": 0.660473644733429}, {"text": "part-of-speech tagging", "start_pos": 140, "end_pos": 162, "type": "TASK", "confidence": 0.7151842415332794}, {"text": "relation identification", "start_pos": 167, "end_pos": 190, "type": "TASK", "confidence": 0.8114131391048431}, {"text": "word sense disambiguation", "start_pos": 402, "end_pos": 427, "type": "TASK", "confidence": 0.6104936500390371}]}, {"text": "In this paper we consider what happens when distributional representations are composed to form representations for larger units of meaning.", "labels": [], "entities": []}, {"text": "Ina compositional phrase, the meaning of the whole can be inferred from the meaning of its parts.", "labels": [], "entities": []}, {"text": "Thus, assuming compositionality, the representation of a phrase such as black mood, should be directly inferable from the representations for black and for mood.", "labels": [], "entities": []}, {"text": "Further, one might suppose that composing the correct senses of the individual lexemes would result in a more accurate representation of that phrase.", "labels": [], "entities": []}, {"text": "However, our counterhypothesis is that the act of composition contextualises or disambiguates each of the lexemes thereby making the representations of individual senses redundant.", "labels": [], "entities": []}, {"text": "We investigate this hypothesis by evaluating the performance of single-vector representations and multi-sense representations at both a benchmark phrase similarity task and at a novel word-sense discrimination task.", "labels": [], "entities": [{"text": "word-sense discrimination task", "start_pos": 184, "end_pos": 214, "type": "TASK", "confidence": 0.7918491760889689}]}, {"text": "Our contributions in this work are thus as follows.", "labels": [], "entities": []}, {"text": "First, we provide quantitative and qualitative evidence that even simple composition functions have the ability to recover sense-specific information from a single-vector representation of a polysemous lexeme in context.", "labels": [], "entities": []}, {"text": "Second, we introduce a novel word-sense discrimination task 1 , which can be seen as the first stage of word-sense disambiguation.", "labels": [], "entities": [{"text": "word-sense discrimination task", "start_pos": 29, "end_pos": 59, "type": "TASK", "confidence": 0.8011011282602946}, {"text": "word-sense disambiguation", "start_pos": 104, "end_pos": 129, "type": "TASK", "confidence": 0.7460153102874756}]}, {"text": "The goal is to find whether the occurrences of a lexeme in two or more sentential contexts belong to the same sense or not, without necessarily labelling the senses.", "labels": [], "entities": []}, {"text": "While it has received relatively little attention in recent years, it is an important natural language understanding problem and can provide important insights into the process of semantic composition.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 86, "end_pos": 116, "type": "TASK", "confidence": 0.6516643762588501}, {"text": "semantic composition", "start_pos": 180, "end_pos": 200, "type": "TASK", "confidence": 0.7239260673522949}]}], "datasetContent": [{"text": "In this paper we compare the compositional models outlined earlier with two baselines, a random baseline and a word-overlap baseline of the extracted contexts.", "labels": [], "entities": []}, {"text": "For the single-vector representations, we composed the target lexeme with all of the words in the context window and compared it with the equivalent representation of each of the options (lexeme plus context words).", "labels": [], "entities": []}, {"text": "The option with the highest cosine similarity was deemed to be the selected sense.", "labels": [], "entities": []}, {"text": "For SENSEMBED, we composed all sense vectors of a target lexeme with the given context and then used the closest sense strategy () on composed representations to choose the predicted sense . The wordoverlap baseline is simply the number of words in common between the context window for the target and each of the options.", "labels": [], "entities": [{"text": "SENSEMBED", "start_pos": 4, "end_pos": 13, "type": "TASK", "confidence": 0.9453045725822449}]}, {"text": "We experimented with symmetric linear bagof-words contexts of size 1, 2 and 4 around the target lexeme.", "labels": [], "entities": []}, {"text": "We also experimented with dependency contexts, where first-order dependency contexts performed almost identical to using a 2-word bag-of-words context window (results not reported).", "labels": [], "entities": []}, {"text": "We excluded stop words prior to extracting the context window in order to maximise the number of content words.", "labels": [], "entities": []}, {"text": "We break ties for any of the methods -including the baselinesby randomly picking one of the options with the highest similarity to the composed representation of the target lexeme with its context.", "labels": [], "entities": []}, {"text": "Statistical significance between the best performing model and the word overlap baseline is computed by using a randomised pairwise permutation test.", "labels": [], "entities": []}, {"text": "shows the results for all context window sizes across all parts-of-speech and number of senses.", "labels": [], "entities": []}, {"text": "All models substantially outperform the random baseline for any number of senses.", "labels": [], "entities": []}, {"text": "Interestingly the word overlap baseline is competitive for all context window sizes.", "labels": [], "entities": []}, {"text": "While it is a very simple method, it has already been found to be a strong baseline for paraphrase detection and semantic textual similarity (.", "labels": [], "entities": [{"text": "paraphrase detection", "start_pos": 88, "end_pos": 108, "type": "TASK", "confidence": 0.9483263492584229}]}, {"text": "One possible explanation for its robust performance on our task is an occurrence of the one-sense-per-collocation hypothesis.", "labels": [], "entities": []}, {"text": "The performance of all other models is roughly in the same ballpark for all parts-ofspeech and number of senses, suggesting that they form robust baselines for future models.", "labels": [], "entities": []}, {"text": "While the results are relatively mixed for adjectives, word2vec appears to be the strongest model for polysemous nouns and verbs.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1  Results for the Mitchell and Laptata (2010) dataset.", "labels": [], "entities": [{"text": "Mitchell and Laptata (2010) dataset", "start_pos": 26, "end_pos": 61, "type": "DATASET", "confidence": 0.8368253026689801}]}, {"text": " Table 2  Tendency of SENSEMBED (SE) to overestimate the similarity  on phrase pairs with low average human similarity when the  closest sense strategy is used.", "labels": [], "entities": [{"text": "SENSEMBED (SE)", "start_pos": 22, "end_pos": 36, "type": "METRIC", "confidence": 0.8616997450590134}]}, {"text": " Table 4: Number of examples per part-of-speech and number  of senses (#dev examples/#train examples).", "labels": [], "entities": []}, {"text": " Table 5  Performance overview for all parts-of-speech and number of senses,  \u2021 statistically significant at the p < 0.01 level in com- parison to the Word Overlap baseline;  \u2020 statistically significant at the p < 0.05 level in comparison to the Word Overlap  baseline.", "labels": [], "entities": [{"text": "Word Overlap baseline", "start_pos": 151, "end_pos": 172, "type": "DATASET", "confidence": 0.878019114335378}, {"text": "Word Overlap  baseline", "start_pos": 246, "end_pos": 268, "type": "DATASET", "confidence": 0.9116120537122091}]}, {"text": " Table 6  Results on the 5-sense noun subtask with SENSEMBED hav- ing access to Babelfy sense labels at test time.", "labels": [], "entities": [{"text": "SENSEMBED", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9912992119789124}]}, {"text": " Table 7  Results on a subsample of the 2-sense noun subtask across  frequency bands.", "labels": [], "entities": []}]}