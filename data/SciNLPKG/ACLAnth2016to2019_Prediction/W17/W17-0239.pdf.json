{"title": [{"text": "Redefining Context Windows for Word Embedding Models: An Experimental Study", "labels": [], "entities": []}], "abstractContent": [{"text": "Distributional semantic models learn vector representations of words through the contexts they occur in.", "labels": [], "entities": []}, {"text": "Although the choice of context (which often takes the form of a sliding window) has a direct influence on the resulting embeddings, the exact role of this model component is still not fully understood.", "labels": [], "entities": []}, {"text": "This paper presents a systematic analysis of context windows based on a set of four distinct hyper-parameters.", "labels": [], "entities": []}, {"text": "We train continuous Skip-Gram models on two English-language corpora for various combinations of these hyper-parameters, and evaluate them on both lexical similarity and analogy tasks.", "labels": [], "entities": []}, {"text": "Notable experimental results are the positive impact of cross-sentential contexts and the surprisingly good performance of right-context windows.", "labels": [], "entities": []}], "introductionContent": [{"text": "Distributional semantic models represent words through real-valued vectors of fixed dimensions, based on the distributional properties of these words observed in large corpora.", "labels": [], "entities": []}, {"text": "Recent approaches such as prediction-based models () and GloVe () have shown that it is possible to estimate dense, low-dimensional vectors (often called embeddings) able to capture various functional or topical relations between words.", "labels": [], "entities": [{"text": "GloVe", "start_pos": 57, "end_pos": 62, "type": "METRIC", "confidence": 0.7991257309913635}]}, {"text": "These embeddings are used in a wide range of NLP tasks, including part-of-speech tagging, syntactic parsing, named entity recognition and semantic role labelling; see;), among others.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 66, "end_pos": 88, "type": "TASK", "confidence": 0.6965123564004898}, {"text": "syntactic parsing", "start_pos": 90, "end_pos": 107, "type": "TASK", "confidence": 0.7058573216199875}, {"text": "named entity recognition", "start_pos": 109, "end_pos": 133, "type": "TASK", "confidence": 0.624700516462326}, {"text": "semantic role labelling", "start_pos": 138, "end_pos": 161, "type": "TASK", "confidence": 0.5957536399364471}]}, {"text": "As recently shown by (, the empirical variations between embedding models are largely due to differences in hyper-parameters (many of which are tied to the underlying definition of context) rather than differences in the embedding algorithms themselves.", "labels": [], "entities": []}, {"text": "In this paper, we further develop their findings with a comprehensive analysis of the role played by context window parameters when learning word embeddings.", "labels": [], "entities": []}, {"text": "Four specific aspects are investigated: 1.", "labels": [], "entities": []}, {"text": "The maximum size of the context window; 2.", "labels": [], "entities": []}, {"text": "The weighting scheme of context words according to their distance to the focus word; 3.", "labels": [], "entities": []}, {"text": "The relative position of the context window (symmetric, left or right side); 4.", "labels": [], "entities": []}, {"text": "The treatment of linguistic boundaries such as end-of-sentence markers.", "labels": [], "entities": []}, {"text": "The next section 2 provides a brief overview on word embeddings and context windows.", "labels": [], "entities": []}, {"text": "Section 3 describes the experimental setup used to evaluate the influence of these four aspects.", "labels": [], "entities": []}, {"text": "Finally, Section 4 presents and discusses the results.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate how context windows affect the embeddings, we trained Continuous Skip-gram with Negative Sampling (SGNS) embeddings for various configurations of hyper-parameters, whose values are detailed in.", "labels": [], "entities": []}, {"text": "In particular, the \"weighting scheme\" encodes how the context words should be weighted according to their distance with the focus word.", "labels": [], "entities": []}, {"text": "This hyperparameter is given two possible values: a linear weighting scheme corresponding to the default word2vec weights, or an alternative scheme using the squared root of the distance.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Average performance across all models  with and without cross-sentential contexts.", "labels": [], "entities": []}, {"text": " Table 4: Average performance across all models  depending on the removal of stop words.", "labels": [], "entities": []}]}