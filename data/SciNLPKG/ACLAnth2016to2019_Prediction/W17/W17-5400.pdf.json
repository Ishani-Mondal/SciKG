{"title": [{"text": "The BLGNLP Organizers, Massively Multilingual Neural Grapheme-to-Phoneme Conversion BIBI System Description: Building with CNNs and Breaking with Deep Reinforcement Learning Breaking NLP: Using Morphosyntax, Semantics, Pragmatics and World Knowledge to Fool Sentiment Analysis Systems An Adaptable Lexical Simplification Architecture for Major Ibero-Romance Languages", "labels": [], "entities": [{"text": "BLGNLP", "start_pos": 4, "end_pos": 10, "type": "DATASET", "confidence": 0.6964558959007263}, {"text": "Massively Multilingual Neural Grapheme-to-Phoneme Conversion BIBI System Description", "start_pos": 23, "end_pos": 107, "type": "TASK", "confidence": 0.6535356901586056}]}], "abstractContent": [], "introductionContent": [{"text": "While the field of natural language processing has made tremendous strides as a result of machine learning techniques, systems trained within this traditional model typically do not generalize well beyond the characteristics of their training data.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 19, "end_pos": 46, "type": "TASK", "confidence": 0.6823926170667013}]}, {"text": "Especially with the influx of deep learning approaches in NLP, it is increasingly the case not only that systems are restricted in the conditions under which they work well-but also that we have little idea what exactly those conditions are.", "labels": [], "entities": []}, {"text": "We believe that linguistic knowledge will be instrumental to addressing these issues, so for this workshop we designed a special shared task, with the goal of bringing together researchers from NLP and linguistics to test the true linguistic generalization capacities of NLP systems.", "labels": [], "entities": []}, {"text": "In addition to the shared task, the workshop also welcomed research contribution papers on the topic of linguistically generalizable NLP systems.", "labels": [], "entities": []}, {"text": "This volume contains an overview paper describing the workshop and shared task, in addition to Shared Task Description papers from our task participants, and several Research Contribution papers.", "labels": [], "entities": []}, {"text": "We received 13 paper submissions, including 9 in the Research Contribution track and 4 Shared Task Description track.", "labels": [], "entities": []}, {"text": "We accepted 9 submissions: 5 Research Contributions, and 4 Shared Task Descriptions.", "labels": [], "entities": []}, {"text": "We are grateful to our program committee, our participants, and all authors who submitted papers for consideration, for making possible the first iteration of this workshop and shared task.", "labels": [], "entities": []}, {"text": "We also thank the EMNLP 2017 organizers for their support.", "labels": [], "entities": [{"text": "EMNLP 2017 organizers", "start_pos": 18, "end_pos": 39, "type": "DATASET", "confidence": 0.874311645825704}]}], "datasetContent": [], "tableCaptions": []}