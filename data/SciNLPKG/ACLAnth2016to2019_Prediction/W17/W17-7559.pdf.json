{"title": [{"text": "Neural Morphological Disambiguation Using Surface and Contextual Morphological Awareness", "labels": [], "entities": [{"text": "Neural Morphological Disambiguation", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8466359575589498}]}], "abstractContent": [{"text": "Morphological disambiguation, particularly for morphologically rich languages , is a crucial step in many NLP tasks.", "labels": [], "entities": [{"text": "Morphological disambiguation", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.9209349453449249}]}, {"text": "Morphological analyzers provide multiple analyses of a word, only one of which is true in context.", "labels": [], "entities": [{"text": "Morphological analyzers", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8307404518127441}]}, {"text": "We present a language-agnostic deep neural system for morphological disambiguation, with experiments on Hindi.", "labels": [], "entities": [{"text": "morphological disambiguation", "start_pos": 54, "end_pos": 82, "type": "TASK", "confidence": 0.7213817536830902}]}, {"text": "We achieve accuracies of around 95.22% without the use of any language-specific features or heuristics, which outperforms the existing state of the art.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 11, "end_pos": 21, "type": "METRIC", "confidence": 0.995863676071167}]}, {"text": "One contribution through this work is building the first morphological disambigua-tion system for Hindi.", "labels": [], "entities": []}, {"text": "We also show that using phonological features can improve performance.", "labels": [], "entities": []}, {"text": "On using phono-logical features and pre-trained word vectors, we report an accuracy of 97.02% for Hindi.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9996826648712158}]}], "introductionContent": [{"text": "Morphologically inflected words are derived from a root by modifying it (e.g., by applying prefixes, suffixes and infixes) based on linguistic features (manifested as the inflection tagset).", "labels": [], "entities": []}, {"text": "Morphological analysis involves extracting this root word and the set of features that describe the inflected form.", "labels": [], "entities": [{"text": "Morphological analysis", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9119000732898712}]}, {"text": "These analyses contain syntactic and semantic information about inflected words.", "labels": [], "entities": []}, {"text": "shows an example for the Hindi word '\u092a\u0942 \u0930\u0947 ' 1 . Existing morphological analyzers typically work in isolation, meaning that they generate multiple analyses of a word, purely based on surface structure.", "labels": [], "entities": [{"text": "Existing morphological analyzers", "start_pos": 49, "end_pos": 81, "type": "TASK", "confidence": 0.6408216456572214}]}, {"text": "For many NLP tasks like machine We use the Roman notation popularly known as WX for representing Hindi words translation and topic modeling, however, it is essential to know which morphological analysis is correct in the context of the sentence.", "labels": [], "entities": [{"text": "Hindi words translation", "start_pos": 97, "end_pos": 120, "type": "TASK", "confidence": 0.6417057812213898}, {"text": "topic modeling", "start_pos": 125, "end_pos": 139, "type": "TASK", "confidence": 0.7855801582336426}]}, {"text": "Morphological disambiguation aims to solve this problem.", "labels": [], "entities": [{"text": "Morphological disambiguation", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.9244732856750488}]}, {"text": "The task of disambiguation is non-trivial and is complicated by the dependencies of the correct analysis on the surface structure of the inflected word, on the surface structures of the neighboring words, and on the analyses of neighboring words.", "labels": [], "entities": []}, {"text": "We present a deep neural morphological disambiguation system that leverages context information as well as surface structure.", "labels": [], "entities": []}, {"text": "While we have experimented on Hindi in our work, we report accuracies without employing any language-specific features to show that our system can generalize across different languages.", "labels": [], "entities": []}, {"text": "We also show performance boost by using phonological features and pre-training of word vectors.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this is the first ever non-naive morphological disambiguation system to be built for Hindi.", "labels": [], "entities": []}, {"text": "Like other Indo-Aryan languages, Hindi is morphologically rich and a word form may have over 40 morphological analyses.", "labels": [], "entities": []}, {"text": "Though the inflectional morphology of Hindi is not agglutinative, the derivational suffixes are.", "labels": [], "entities": []}, {"text": "This leads to an explosion in the number of inflectional root forms ().", "labels": [], "entities": []}, {"text": "One of the reasons for our focus on Hindi is that it has a wide coverage of speaking population, with over 260 million speakers across 5 countries 2 and is the fifth most spoken language in the world . We present four neural architectures for this task, each different from the others by the nature of context information used as disambiguating", "labels": [], "entities": []}], "datasetContent": [{"text": "We use a manually annotated Hindi Dependency TreeBank 7 , which is part of the HindiUrdu Dependency TreeBank (HUTB) 8 as the source of the correct morphological analysis of words in the context of their sentences.", "labels": [], "entities": [{"text": "Hindi Dependency TreeBank 7", "start_pos": 28, "end_pos": 55, "type": "DATASET", "confidence": 0.9035891592502594}, {"text": "HindiUrdu Dependency TreeBank (HUTB) 8", "start_pos": 79, "end_pos": 117, "type": "DATASET", "confidence": 0.9188149571418762}]}, {"text": "The treebank annotates words from sentences taken from news articles and textual conversations.", "labels": [], "entities": []}, {"text": "Each word in every sentence of the treebank is annotated with the correct morphological analysis.", "labels": [], "entities": []}, {"text": "We use a morphological analyzer for Hindi 9 , which was developed earlier, but is now used for the Sampark MT system and other purposes.", "labels": [], "entities": [{"text": "Hindi 9", "start_pos": 36, "end_pos": 43, "type": "DATASET", "confidence": 0.9182549715042114}, {"text": "Sampark MT system", "start_pos": 99, "end_pos": 116, "type": "DATASET", "confidence": 0.6318491895993551}]}, {"text": "We use it to generate the different possible morphological analyses for each word (in isolation) in the treebank.", "labels": [], "entities": []}, {"text": "For each word in the treebank, the candidate analysis matching the word's treebank-annotated morphological analysis is labeled as true while all other candidate analyses are labeled as false.", "labels": [], "entities": []}, {"text": "In the entire dataset, we ensure that out of all the candidate analyses of a word, there is one that matches the treebank annotation for that word.", "labels": [], "entities": []}, {"text": "provides specific statistics about the dataset used.", "labels": [], "entities": []}, {"text": "We would like to mention here that since our system is built to pick the correct analysis from the morphological analyses generated by the analyzer, it assumes that every word has a set of candidate analyses.", "labels": [], "entities": []}, {"text": "In the context of our task, it is not relevant to discuss the case when the morphological analyzer itself fails to provide candidate analyses.", "labels": [], "entities": []}, {"text": "shows the number of ambiguous words and the total number of words used for training, development and testing.", "labels": [], "entities": []}, {"text": "The test set is held-out and is used solely for reporting final results.", "labels": [], "entities": []}, {"text": "The development set is used to validate and tune model hyperparameters.", "labels": [], "entities": []}, {"text": "During testing, the model is provided with only the different candidate morphological analysis outputs from the morphological analyzer, for each word.", "labels": [], "entities": []}, {"text": "The correct analyses (also referred to as annotations in the follow-", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Morphological analyses of the word`\u092a\u0942word`\u092a\u0942 \u0930\u0947 ' [pUre] (A '-' indicates that the feature is not  applicable and an 'any' indicates that it can take any value in the domain for that feature)", "labels": [], "entities": []}, {"text": " Table 4: Word counts in training, development  and test splits", "labels": [], "entities": []}, {"text": " Table 5: Performance of different models (all  accuracies are percentages). S-O-T-A stands  for state-of-the-art, which is the full-context  model of Shen et al. (2016). The accuracy  gain we have achieved over S-O-T-A is 2.8%  on ambiguous words and 3.43% on all words.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 175, "end_pos": 183, "type": "METRIC", "confidence": 0.9989416003227234}]}, {"text": " Table 6: Performance with language-specific  enhancements", "labels": [], "entities": []}]}