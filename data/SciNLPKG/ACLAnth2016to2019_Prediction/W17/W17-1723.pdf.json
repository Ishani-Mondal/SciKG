{"title": [{"text": "Identification of Ambiguous Multiword Expressions Using Sequence Models and Lexical Resources", "labels": [], "entities": [{"text": "Identification of Ambiguous Multiword Expressions", "start_pos": 0, "end_pos": 49, "type": "TASK", "confidence": 0.8483811259269715}]}], "abstractContent": [{"text": "We present a simple and efficient tagger capable of identifying highly ambiguous multiword expressions (MWEs) in French texts.", "labels": [], "entities": [{"text": "identifying highly ambiguous multiword expressions (MWEs) in French texts", "start_pos": 52, "end_pos": 125, "type": "TASK", "confidence": 0.7542012333869934}]}, {"text": "It is based on conditional random fields (CRF), using local context information as features.", "labels": [], "entities": []}, {"text": "We show that this approach can obtain results that, in some cases, approach more sophisticated parser-based MWE identification methods without requiring syntactic trees from a tree-bank.", "labels": [], "entities": [{"text": "MWE identification", "start_pos": 108, "end_pos": 126, "type": "TASK", "confidence": 0.8158287405967712}]}, {"text": "Moreover, we study how well the CRF can take into account external information coming from a lexicon.", "labels": [], "entities": []}], "introductionContent": [{"text": "Identifying multiword expressions (MWEs) in running text with the help of a lexicon is often considered as a trivial task.", "labels": [], "entities": [{"text": "Identifying multiword expressions (MWEs) in running text", "start_pos": 0, "end_pos": 56, "type": "TASK", "confidence": 0.8961717420154147}]}, {"text": "In theory, one could simply scan the text once and mark (e.g. join with an underscore) all sequences of tokens that appear in the MWE lexicon.", "labels": [], "entities": [{"text": "MWE lexicon", "start_pos": 130, "end_pos": 141, "type": "DATASET", "confidence": 0.8074782192707062}]}, {"text": "Direct matching and projection of lexical entries onto the corpus can be employed as a preprocessing step in parsing and MT (.", "labels": [], "entities": [{"text": "parsing", "start_pos": 109, "end_pos": 116, "type": "TASK", "confidence": 0.9699428677558899}, {"text": "MT", "start_pos": 121, "end_pos": 123, "type": "TASK", "confidence": 0.9823713898658752}]}, {"text": "Afterward, MWEs can be retokenized and treated as words with spaces, improving parsing and MT quality.", "labels": [], "entities": [{"text": "MT", "start_pos": 91, "end_pos": 93, "type": "TASK", "confidence": 0.9802700281143188}]}, {"text": "However, this simple pipeline does notwork for many categories of MWEs, since variability and inflection may pose problems.", "labels": [], "entities": []}, {"text": "For instance, if a lexicon contains the idiom to make a face, string matching will fail to identify it in children are always making faces.", "labels": [], "entities": []}, {"text": "Since lexicons contain canonical (lemmatized) forms, matching must take inflection into account.", "labels": [], "entities": []}, {"text": "This can be carried out by (a) pre-analysing the text and matching lemmas and POS tags instead of word forms) or (b) using lexicons of inflected MWEs (.", "labels": [], "entities": []}, {"text": "Things get more complicated when the target MWEs are ambiguous, though.", "labels": [], "entities": []}, {"text": "An MWE is ambiguous when its member words can cooccur without forming an expression.", "labels": [], "entities": []}, {"text": "For instance, to make a face is an idiom meaning 'to show a funny facial expression', but it can also be used literally when someone is making a snowman.", "labels": [], "entities": []}, {"text": "Additionally, the words of the expression can cooccur by chance, not forming a phrase.", "labels": [], "entities": []}, {"text": "For example, up to is an MWE in they accepted up to 100 candidates but not in you should look it up to avoid making typos.", "labels": [], "entities": []}, {"text": "This paper focuses on a specific category of highly frequent and ambiguous MWEs in French.", "labels": [], "entities": []}, {"text": "Indeed, in French some of the most recurrent function words are ambiguous MWEs.", "labels": [], "entities": []}, {"text": "For instance, some conjunctions are formed by combining adverbs like ainsi (likewise) and maintenant (now) with subordinate conjunctions like que (that).", "labels": [], "entities": [{"text": "maintenant", "start_pos": 90, "end_pos": 100, "type": "METRIC", "confidence": 0.9549737572669983}]}, {"text": "However, they may also cooccur by chance when the adverb modifies a verb followed by a subordinate clause, as in the example taken from 1.", "labels": [], "entities": []}, {"text": "Je mange bien que je n'aie pas faim I eat although I am not hungry 2.", "labels": [], "entities": []}, {"text": "Je pense bien que je n'ai pas faim I think indeed that I am not hungry The same happens for determiners like de la (partitive some), which coincides with preposition de (of ) and determiner la (the).", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our approach in two experimental setups.", "labels": [], "entities": []}, {"text": "First, we perform feature selection using the dev/test split of the MORPH dataset, both regarding coarse groups (4.1) and individual features (4.2).", "labels": [], "entities": [{"text": "feature selection", "start_pos": 18, "end_pos": 35, "type": "TASK", "confidence": 0.678223729133606}, {"text": "MORPH dataset", "start_pos": 68, "end_pos": 81, "type": "DATASET", "confidence": 0.9493380188941956}]}, {"text": "Then, we apply the best configuration to the whole MORPH dataset in order to compare our results with the state of the art (4.3).", "labels": [], "entities": [{"text": "MORPH dataset", "start_pos": 51, "end_pos": 64, "type": "DATASET", "confidence": 0.8684612214565277}]}], "tableCaptions": [{"text": " Table 1: First feature selection, removing coarse-grained feature groups.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 16, "end_pos": 33, "type": "TASK", "confidence": 0.636478990316391}]}, {"text": " Table 2: Second feature selection, removing fine-grained feature groups.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 17, "end_pos": 34, "type": "TASK", "confidence": 0.6521159708499908}]}, {"text": " Table 3: Impact of subcat features (SF) on sepa- rate dev sets per construction.", "labels": [], "entities": []}, {"text": " Table 4: Comparison with baseline and state of the art.", "labels": [], "entities": []}, {"text": " Table 5: Performance of the BEST configuration  broken down by expression.", "labels": [], "entities": [{"text": "BEST", "start_pos": 29, "end_pos": 33, "type": "METRIC", "confidence": 0.5396718382835388}]}]}