{"title": [{"text": "Automatic Focus Annotation: Bringing Formal Pragmatics Alive in Analyzing the Information Structure of Authentic Data", "labels": [], "entities": [{"text": "Automatic Focus Annotation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6240336696306864}]}], "abstractContent": [{"text": "Analyzing language in context, both from a theoretical and from a computational perspective , is receiving increased interest.", "labels": [], "entities": []}, {"text": "Complementing the research in linguistics on discourse and information structure, in computational linguistics identifying discourse concepts was also shown to improve the performance of certain applications, for example, Short Answer Assessment systems (Ziai and Meurers, 2014).", "labels": [], "entities": [{"text": "computational linguistics identifying discourse concepts", "start_pos": 85, "end_pos": 141, "type": "TASK", "confidence": 0.7641122579574585}, {"text": "Short Answer Assessment", "start_pos": 222, "end_pos": 245, "type": "TASK", "confidence": 0.7404573957125345}]}, {"text": "Building on the research that established detailed annotation guidelines for manual annotation of information structural concepts for written (Dipper et al., 2007; Ziai and Meur-ers, 2014) and spoken language data (Calhoun et al., 2010), this paper presents the first approach automating the analysis of focus in authentic written data.", "labels": [], "entities": []}, {"text": "Our classification approach combines a range of lexical, syntactic, and semantic features to achieve an accuracy of 78.1% for identifying focus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.9994390606880188}]}], "introductionContent": [{"text": "The interpretation of language is well known to depend on context.", "labels": [], "entities": []}, {"text": "Both in theoretical and computational linguistics, discourse and information structure of sentences are thus receiving increased interest: attention has shifted from the analysis of isolated sentences to the question how sentences are structured in discourse and how information is packaged in sentences analyzed in context.", "labels": [], "entities": []}, {"text": "As a consequence, a rich landscape of approaches to discourse and information structure has been developed.", "labels": [], "entities": []}, {"text": "Among these perspectives, the Focus-Background dichotomy provides a particularly valuable structuring of the information in a sentence in relation to the discourse.", "labels": [], "entities": []}, {"text": "(1) is an example question-answer pair from Krifka and Musan where the focus in the answer is marked by brackets.", "labels": [], "entities": []}, {"text": "In the answer in (1), the NP the pictures is focussed and hence indicates that there are alternative things that John could show Mary.", "labels": [], "entities": []}, {"text": "It is commonly assumed that focus here typically indicates the presence of alternative denotations (denotation focus,, making it a semantic notion.", "labels": [], "entities": []}, {"text": "Depending on the language, different devices are used to mark focus, such as prosodic focus marking or different syntactic constructions (e.g. clefts).", "labels": [], "entities": [{"text": "prosodic focus marking", "start_pos": 77, "end_pos": 99, "type": "TASK", "confidence": 0.669546882311503}]}, {"text": "In this paper, we adopt a notion of focus based on alternatives, as advanced by and more recently,, who define focus as indicating \"the presence of alternatives that are relevant for the interpretation of linguistic expressions\" (.", "labels": [], "entities": []}, {"text": "Formal semantics has tied the notion of alternatives to an explicit relationship between questions and answers called QuestionAnswer Congruence, where the idea is that an answer is congruent to a question if both evoke the same set of alternatives.", "labels": [], "entities": [{"text": "Formal semantics", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8187699615955353}]}, {"text": "Questions can thus be seen as away of making alternatives explicit in the discourse, an idea also taken up by the Question-Under-Discussion (QUD) approach to discourse organization.", "labels": [], "entities": []}, {"text": "Complementing the theoretical linguistic approaches, in the last decade corpus-based approaches started exploring which information structural notions can reliably be annotated in what kind of language data.", "labels": [], "entities": []}, {"text": "While the information status (Given-New) dimension can be annotated successfully () and even automated (, the inter-annotator agreement results for FocusBackground ( show that it is difficult to obtain high levels of agreement, especially due to disagreement about the extent or size of the focused unit.", "labels": [], "entities": [{"text": "FocusBackground", "start_pos": 148, "end_pos": 163, "type": "DATASET", "confidence": 0.9071861505508423}]}, {"text": "More recently, showed that for data collected in task contexts including explicit questions, such as answers to reading comprehension questions, reliable focus annotation is possible.", "labels": [], "entities": []}, {"text": "In addition, an option for externally validating focus annotation was established by showing that such focus annotation improves the performance of Short Answer Assessment (SAA) systems.", "labels": [], "entities": [{"text": "Short Answer Assessment (SAA)", "start_pos": 148, "end_pos": 177, "type": "TASK", "confidence": 0.6562454005082449}]}, {"text": "Focus enables the system to zoom in on the part of the answer addressing the question instead of considering all parts of the answer as equal.", "labels": [], "entities": []}, {"text": "In this paper, we want to build on this strand of research and develop an approach for automatically identifying focus in authentic data including explicit question contexts.", "labels": [], "entities": []}, {"text": "In contrast to and, who make use of prosodic properties to tackle the identification of focus for content words in spoken language data, we target the analysis of written texts.", "labels": [], "entities": [{"text": "identification of focus for content words in spoken language", "start_pos": 70, "end_pos": 130, "type": "TASK", "confidence": 0.8076515396436056}]}, {"text": "We start in section 2 by discussing relevant related work before introducing the gold standard focus annotation we are using as foundation of our work in section 3.", "labels": [], "entities": []}, {"text": "Section 4 then presents the different types of features used for predicting which tokens form apart of the focus.", "labels": [], "entities": []}, {"text": "In section 5 we employ a supervised machine learning setup to evaluate the perspective and specific features in terms of the ability to predict the gold standard focus labeling.", "labels": [], "entities": []}, {"text": "Building on these intermediate results and the analysis thereof in section 6, in section 7 we then present two additional feature groups which lead to our final focus detection model.", "labels": [], "entities": [{"text": "focus detection", "start_pos": 161, "end_pos": 176, "type": "TASK", "confidence": 0.7799874842166901}]}, {"text": "Finally, section 8 explores options for extrinsically showing the value of the automatic focus annotation for the automatic meaning assessment of short answers.", "labels": [], "entities": [{"text": "automatic meaning assessment of short answers", "start_pos": 114, "end_pos": 159, "type": "TASK", "confidence": 0.7581114520629247}]}, {"text": "It confirms that focus analysis pays off when aiming to generalize assessment to previously unseen data and contexts.", "labels": [], "entities": [{"text": "focus analysis", "start_pos": 17, "end_pos": 31, "type": "TASK", "confidence": 0.862995833158493}]}], "datasetContent": [{"text": "Complementing the intrinsic evaluation above, in this section we demonstrate how focus can be successfully used to improve performance in an authentic CL task, namely Short Answer Assessment (SAA).", "labels": [], "entities": [{"text": "Short Answer Assessment (SAA)", "start_pos": 167, "end_pos": 196, "type": "TASK", "confidence": 0.5797964284817377}]}], "tableCaptions": [{"text": " Table 1: Initial focus detection model", "labels": [], "entities": [{"text": "Initial focus detection", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.7164195577303568}]}, {"text": " Table 2: Final focus detection performance", "labels": [], "entities": [{"text": "focus detection", "start_pos": 16, "end_pos": 31, "type": "TASK", "confidence": 0.8185896277427673}]}, {"text": " Table 4: CoMiC results on different test sets using standard and focus-augmented features", "labels": [], "entities": []}]}