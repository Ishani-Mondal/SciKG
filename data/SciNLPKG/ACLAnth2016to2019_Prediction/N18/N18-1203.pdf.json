{"title": [{"text": "Learning to Map Context-Dependent Sentences to Executable Formal Queries", "labels": [], "entities": [{"text": "Learning to Map Context-Dependent Sentences to Executable Formal Queries", "start_pos": 0, "end_pos": 72, "type": "TASK", "confidence": 0.7167626089519925}]}], "abstractContent": [{"text": "We propose a context-dependent model to map utterances within an interaction to executable formal queries.", "labels": [], "entities": []}, {"text": "To incorporate interaction history , the model maintains an interaction-level encoder that updates after each turn, and can copy sub-sequences of previously predicted queries during generation.", "labels": [], "entities": []}, {"text": "Our approach combines implicit and explicit modeling of references between utterances.", "labels": [], "entities": []}, {"text": "We evaluate our model on the ATIS flight planning interactions , and demonstrate the benefits of model-ing context and explicit references.", "labels": [], "entities": [{"text": "ATIS flight planning interactions", "start_pos": 29, "end_pos": 62, "type": "DATASET", "confidence": 0.608222559094429}]}], "introductionContent": [{"text": "The meaning of conversational utterances depends strongly on the history of the interaction.", "labels": [], "entities": []}, {"text": "Consider a user querying a flight database using natural language).", "labels": [], "entities": []}, {"text": "Given a user utterance, the system must generate a query, execute it, and display results to the user, who then provides the next request.", "labels": [], "entities": []}, {"text": "Key to correctly mapping utterances to executable queries is resolving references.", "labels": [], "entities": []}, {"text": "For example, the second utterance implicitly depends on the first, and the reference ones in the third utterance explicitly refers to the response to the second utterance.", "labels": [], "entities": []}, {"text": "Within an interactive system, this information needs to be composed with mentions of database entries (e.g., Seattle, next Monday) to generate a formal executable representation.", "labels": [], "entities": []}, {"text": "In this paper, we propose encoder-decoder models that directly map user utterances to executable queries, while considering the history of the interaction, including both previous utterances and their generated queries.", "labels": [], "entities": []}, {"text": "Reasoning about how the meaning of an utterance depends on the history of the interaction is critical to correctly respond to user requests.", "labels": [], "entities": []}, {"text": "As interactions progress, users may omit previouslymentioned constraints and entities, and an increas-.", "labels": [], "entities": []}, {"text": "Each request is followed by a description of the system response.", "labels": [], "entities": []}, {"text": "ing portion of the utterance meaning must be derived from the interaction history.", "labels": [], "entities": []}, {"text": "shows SQL queries for the utterances in.", "labels": [], "entities": []}, {"text": "As the interaction progresses, the majority of the generated query is derived from the interaction history (underlined), rather than from the current utterance.", "labels": [], "entities": []}, {"text": "A key challenge is resolving what past information is incorporated and how.", "labels": [], "entities": []}, {"text": "For example, in the figure, the second utterance depends on the set of flights defined by the first, while adding anew constraint.", "labels": [], "entities": []}, {"text": "The third utterance further refines this set by adding a constraint to the constraints from both previous utterances.", "labels": [], "entities": []}, {"text": "In contrast, the fourth utterance refers only to the first one, and skips the two utterances in between.", "labels": [], "entities": []}, {"text": "Correctly generating the fourth query requires understanding that the time constraint (at 7pm) can be ignored as it follows an airline constraint that has been replaced.", "labels": [], "entities": [{"text": "time constraint", "start_pos": 70, "end_pos": 85, "type": "METRIC", "confidence": 0.9567074477672577}]}, {"text": "We study complementary methods to enable this type of reasoning.", "labels": [], "entities": []}, {"text": "The first set of methods implicitly reason about references by modifying the encoder-decoder architecture to encode information from previous utterances for generation decisions.", "labels": [], "entities": []}, {"text": "We experiment with attending over previous utterances and using an interaction-level recurrent encoder.", "labels": [], "entities": []}, {"text": "We also study explicitly maintaining a set of referents using segments from pre- Figure 2: Annotated SQL queries (\u00af y 1 ,.", "labels": [], "entities": []}, {"text": ",\u00af y 4 ) in the ATIS () domain for utterances (\u00af x 1 ,.", "labels": [], "entities": [{"text": "ATIS", "start_pos": 16, "end_pos": 20, "type": "DATASET", "confidence": 0.7478247880935669}]}, {"text": ",\u00af x 4 ) from.", "labels": [], "entities": []}, {"text": "Underlining (not part of the annotation) indicates segments originating from the interaction context.", "labels": [], "entities": [{"text": "Underlining", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9030566811561584}]}, {"text": "At each step, the decoder chooses whether to output a token or select a segment from the set, which is appended to the output in a single decoding step.", "labels": [], "entities": []}, {"text": "In addition to enabling references to previously mentioned entities, sets, and constraints, this method also reduces the number of generation steps required, illustrated by the underlined segments in.", "labels": [], "entities": []}, {"text": "For example, the query \u00af y 2 will require 17 steps instead of 94.", "labels": [], "entities": []}, {"text": "We evaluate our approach using the ATIS ( task, where a user interacts with a SQL flight database using natural language requests, and almost all queries require joins across multiple tables.", "labels": [], "entities": [{"text": "ATIS", "start_pos": 35, "end_pos": 39, "type": "METRIC", "confidence": 0.9391729235649109}]}, {"text": "In addition to reasoning about contextual phenomena, we design our system to effectively resolve database values, including resolution of time expressions (e.g., next monday in) using an existing semantic parser.", "labels": [], "entities": []}, {"text": "Our evaluation shows that reasoning about the history of the interaction is necessary, relatively increasing performance by 28.6% over a baseline with no access to this information, and that combining the implicit and explicit methods provides the best performance.", "labels": [], "entities": []}, {"text": "Furthermore, our analysis shows that our full approach maintains its performance as interaction length increases, while the performance of systems without explicit modeling deteriorates.", "labels": [], "entities": []}, {"text": "Our code is available at https://github.com/clic-lab/atis.", "labels": [], "entities": []}], "datasetContent": [{"text": "Hyperparameters, architecture details, and other experimental choices are detailed in the supplementary material.", "labels": [], "entities": []}, {"text": "Data We use ATIS () to evaluate our approach.", "labels": [], "entities": [{"text": "ATIS", "start_pos": 12, "end_pos": 16, "type": "METRIC", "confidence": 0.8721663951873779}]}, {"text": "The data was originally collected using wizard-of-oz experiments, and annotated with SQL queries.", "labels": [], "entities": []}, {"text": "Each interaction was based on a scenario given to a user.", "labels": [], "entities": []}, {"text": "We observed that the original data split shares scenarios between the train, development, and test splits.", "labels": [], "entities": []}, {"text": "This introduces biases, where travel patterns that appeared during training repeat in testing.", "labels": [], "entities": []}, {"text": "For example, a model trained on the original data split often correctly resolves the exact referenced by on Saturday with no pre-processing or access to the document date.", "labels": [], "entities": []}, {"text": "We evaluate this overfitting empirically in the supplementary material.", "labels": [], "entities": []}, {"text": "We re-split the data to avoid this bias.", "labels": [], "entities": []}, {"text": "We evenly distribute scenarios across splits so that each split contains both scenarios with many and few representative interactions.", "labels": [], "entities": []}, {"text": "The new split follows the original split sizes with 1148/380/130 train/dev/test interactions.", "labels": [], "entities": []}, {"text": "The system uses a SQL database of 27 tables and 162K entries.", "labels": [], "entities": []}, {"text": "96.6% of the queries require at least one join, and 93% at least two joins.", "labels": [], "entities": []}, {"text": "The most related work on ATIS to ours is, which we discuss in Section 3.", "labels": [], "entities": [{"text": "ATIS", "start_pos": 25, "end_pos": 29, "type": "TASK", "confidence": 0.6238284111022949}]}, {"text": "The most related corpora to ATIS are SCONE ( and SequentialQA (.", "labels": [], "entities": [{"text": "ATIS", "start_pos": 28, "end_pos": 32, "type": "DATASET", "confidence": 0.6731639504432678}]}, {"text": "In contrast, ATIS uses a significantly larger database, requires generating complex queries with multiple joins, includes longer interactions, and was collected through interaction with users.", "labels": [], "entities": [{"text": "ATIS", "start_pos": 13, "end_pos": 17, "type": "DATASET", "confidence": 0.7796959280967712}]}, {"text": "The supplementary material contains analysis of the contextual phenomena observed in ATIS.", "labels": [], "entities": []}, {"text": "Pre-processing We pre-process the data to identify and anonymize entities (e.g., cities), numbers, times, and dates.", "labels": [], "entities": []}, {"text": "We use string matching heuristics to identify entities and numbers, and identify and resolve times and dates using UWTime ().", "labels": [], "entities": [{"text": "UWTime", "start_pos": 115, "end_pos": 121, "type": "DATASET", "confidence": 0.9541199207305908}]}, {"text": "When resolving dates we use the original interaction date as the document time.", "labels": [], "entities": []}, {"text": "The supplementary material details this process.", "labels": [], "entities": []}, {"text": "Metrics We evaluate using query accuracy, strict denotation accuracy, and relaxed denotation accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.8637884259223938}, {"text": "strict denotation accuracy", "start_pos": 42, "end_pos": 68, "type": "METRIC", "confidence": 0.665219803651174}, {"text": "relaxed denotation accuracy", "start_pos": 74, "end_pos": 101, "type": "METRIC", "confidence": 0.723550041516622}]}, {"text": "Query accuracy is the percentage of predicted queries that match the reference query.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 6, "end_pos": 14, "type": "METRIC", "confidence": 0.9433823823928833}]}, {"text": "Strict denotation accuracy is the percentage of predicted queries that execute to exactly the same table as the reference query.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.8540014028549194}]}, {"text": "In contrast to strict, relaxed gives credit to a prediction query that fails to execute if the reference table is empty.", "labels": [], "entities": []}, {"text": "In cases when the utterance is ambiguous and there are multiple gold queries, we consider the query or table correct if they match any of the gold labels.", "labels": [], "entities": []}, {"text": "Systems We evaluate four systems: (a) the baseline encoder-decoder model (Section 4.1); (b) SEQ2SEQ-H: encoderdecoder with attention on current and previous utterances (Section 4.2); (c) S2S+ANON: encoderdecoder with attention on previous utterances and anonymization scoring (Section 6); and (d) FULL: the complete approach including segment copying (Section 4.4).", "labels": [], "entities": [{"text": "ANON", "start_pos": 191, "end_pos": 195, "type": "METRIC", "confidence": 0.9182906746864319}, {"text": "FULL", "start_pos": 297, "end_pos": 301, "type": "METRIC", "confidence": 0.9940786361694336}, {"text": "segment copying", "start_pos": 335, "end_pos": 350, "type": "TASK", "confidence": 0.7675579488277435}]}, {"text": "For FULL, we evaluate with predicted and gold (FULL-GOLD) previous queries, and without attention on previous utterances (FULL-0).", "labels": [], "entities": [{"text": "FULL", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.5467167496681213}, {"text": "FULL-GOLD", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.9526605606079102}, {"text": "FULL-0", "start_pos": 122, "end_pos": 128, "type": "METRIC", "confidence": 0.9471308588981628}]}, {"text": "All models except SEQ2SEQ-0 and FULL-0 use h = 3 previous utterances.", "labels": [], "entities": [{"text": "SEQ2SEQ-0", "start_pos": 18, "end_pos": 27, "type": "DATASET", "confidence": 0.9182469248771667}, {"text": "FULL-0", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.9687437415122986}]}, {"text": "We limit segment copying to segments that appear in the most recent query only.", "labels": [], "entities": [{"text": "segment copying", "start_pos": 9, "end_pos": 24, "type": "TASK", "confidence": 0.7441560924053192}]}, {"text": "Unless specifically ablated, all experiments use pre-processing.", "labels": [], "entities": []}, {"text": "strates the need for context in this task.", "labels": [], "entities": []}, {"text": "Attending on recent history significantly increases performance.", "labels": [], "entities": [{"text": "Attending", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9812125563621521}]}, {"text": "Both SEQ2SEQ models score anonymized tokens as regular vocabulary tokens.", "labels": [], "entities": []}, {"text": "Adding anonymized token scoring further increases performance (S2S+ANON).", "labels": [], "entities": [{"text": "ANON", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.9896534085273743}]}, {"text": "FULL-0 and FULL add segment copying and the turn-level encoder.", "labels": [], "entities": [{"text": "FULL-0", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.6130549907684326}, {"text": "FULL", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.7350160479545593}, {"text": "segment copying", "start_pos": 20, "end_pos": 35, "type": "TASK", "confidence": 0.8397170901298523}]}, {"text": "The relatively high performance of FULL-0 shows that substituting segment copying with attention maintains and even improves the system effectiveness.", "labels": [], "entities": [{"text": "FULL-0", "start_pos": 35, "end_pos": 41, "type": "DATASET", "confidence": 0.4905065596103668}, {"text": "segment copying", "start_pos": 66, "end_pos": 81, "type": "TASK", "confidence": 0.7277252078056335}]}, {"text": "However, the best performance is provided with FULL, which combines both.", "labels": [], "entities": [{"text": "FULL", "start_pos": 47, "end_pos": 51, "type": "METRIC", "confidence": 0.994307816028595}]}, {"text": "This shows the benefit of redundancy in accessing contextual information.", "labels": [], "entities": []}, {"text": "Unlike the other systems, both FULL and FULL-0 suffer from cascading errors due to selecting query segments from previously incorrect predictions.", "labels": [], "entities": [{"text": "FULL", "start_pos": 31, "end_pos": 35, "type": "METRIC", "confidence": 0.4834434986114502}, {"text": "FULL-0", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.6011600494384766}]}, {"text": "The higher FULL-GOLD performance illustrates the influence of error propagation.", "labels": [], "entities": [{"text": "FULL-GOLD", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.9808508157730103}, {"text": "error propagation", "start_pos": 62, "end_pos": 79, "type": "TASK", "confidence": 0.6993936151266098}]}, {"text": "While part of this error can be mitigated by having both attention and segment copying, this behavior is unlikely to be learned from supervised learning, where errors are never observed.", "labels": [], "entities": [{"text": "segment copying", "start_pos": 71, "end_pos": 86, "type": "TASK", "confidence": 0.6797876209020615}]}], "tableCaptions": [{"text": " Table 1: ATIS data statistics.", "labels": [], "entities": [{"text": "ATIS data statistics", "start_pos": 10, "end_pos": 30, "type": "DATASET", "confidence": 0.9543412327766418}]}, {"text": " Table 3: Results on the original split of the data.", "labels": [], "entities": []}]}