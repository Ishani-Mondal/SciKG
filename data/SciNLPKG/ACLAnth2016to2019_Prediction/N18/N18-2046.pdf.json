{"title": [{"text": "Near Human-Level Performance in Grammatical Error Correction with Hybrid Machine Translation", "labels": [], "entities": [{"text": "Grammatical Error Correction", "start_pos": 32, "end_pos": 60, "type": "TASK", "confidence": 0.7936486601829529}, {"text": "Hybrid Machine Translation", "start_pos": 66, "end_pos": 92, "type": "TASK", "confidence": 0.7974921862284342}]}], "abstractContent": [{"text": "We combine two of the most popular approaches to automated Grammatical Error Correction (GEC): GEC based on Statistical Machine Translation (SMT) and GEC based on Neural Machine Translation (NMT).", "labels": [], "entities": [{"text": "automated Grammatical Error Correction (GEC)", "start_pos": 49, "end_pos": 93, "type": "TASK", "confidence": 0.7663073071411678}, {"text": "Statistical Machine Translation (SMT)", "start_pos": 108, "end_pos": 145, "type": "TASK", "confidence": 0.7825639645258585}, {"text": "Neural Machine Translation (NMT)", "start_pos": 163, "end_pos": 195, "type": "TASK", "confidence": 0.803725908199946}]}, {"text": "The hybrid system achieves new state-of-the-art results on the CoNLL-2014 and JFLEG benchmarks.", "labels": [], "entities": [{"text": "CoNLL-2014", "start_pos": 63, "end_pos": 73, "type": "DATASET", "confidence": 0.9124576449394226}, {"text": "JFLEG benchmarks", "start_pos": 78, "end_pos": 94, "type": "DATASET", "confidence": 0.8794260919094086}]}, {"text": "This GEC system preserves the accuracy of SMT output and, at the same time, generates more fluent sentences as it typical for NMT.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9993786811828613}, {"text": "SMT output", "start_pos": 42, "end_pos": 52, "type": "TASK", "confidence": 0.9000388979911804}]}, {"text": "Our analysis shows that the created systems are closer to reaching human-level performance than any other GEC system reported so far.", "labels": [], "entities": []}], "introductionContent": [{"text": "Currently, the most effective GEC systems are based on phrase-based statistical machine translation (.", "labels": [], "entities": [{"text": "GEC", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.9704392552375793}, {"text": "phrase-based statistical machine translation", "start_pos": 55, "end_pos": 99, "type": "TASK", "confidence": 0.6251334920525551}]}, {"text": "Systems that rely on neural machine translation are not yet able to achieve as high performance as SMT systems according to automatic evaluation metrics (see for comparison on the CoNLL-2014 test set).", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 21, "end_pos": 47, "type": "TASK", "confidence": 0.7561007539431254}, {"text": "SMT", "start_pos": 99, "end_pos": 102, "type": "TASK", "confidence": 0.9870727062225342}, {"text": "CoNLL-2014 test set", "start_pos": 180, "end_pos": 199, "type": "DATASET", "confidence": 0.9672200282414755}]}, {"text": "However, it has been shown that the neural approach can produce more fluent output, which might be desirable by human evaluators (.", "labels": [], "entities": []}, {"text": "In this work, we combine both MT flavors within a hybrid GEC system.", "labels": [], "entities": [{"text": "MT", "start_pos": 30, "end_pos": 32, "type": "TASK", "confidence": 0.9306924343109131}]}, {"text": "Such a GEC system preserves the accuracy of SMT output and at the same time generates more fluent sentences achieving new state-of-the-art results on two different benchmarks: the annotationbased CoNLL-2014 and the fluency-based JFLEG benchmark.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9989805817604065}, {"text": "SMT output", "start_pos": 44, "end_pos": 54, "type": "TASK", "confidence": 0.8927762806415558}, {"text": "JFLEG benchmark", "start_pos": 229, "end_pos": 244, "type": "DATASET", "confidence": 0.8370955586433411}]}, {"text": "Moreover, comparison with human gold standards shows that the created systems are closer to reaching human-level performance than any other GEC system described in the literature so far.", "labels": [], "entities": []}, {"text": "Using consistent training data and preprocessing ( \u00a7 2), we first create strong SMT ( \u00a7 3) and NMT ( \u00a7 4) baseline systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 80, "end_pos": 83, "type": "TASK", "confidence": 0.9320884943008423}, {"text": "NMT", "start_pos": 95, "end_pos": 98, "type": "DATASET", "confidence": 0.8390870094299316}]}, {"text": "Then, we experiment with system combinations through pipelining and reranking ( \u00a7 5).", "labels": [], "entities": []}, {"text": "Finally, we compare the performance with human annotations and identify issues with current state-of-the-art systems ( \u00a7 6).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Statistics for training and testing data sets.", "labels": [], "entities": []}, {"text": " Table 2: Results for SMT baseline systems on the  CoNLL-2014 (M 2 ) and JFLEG Test (GLEU) sets.", "labels": [], "entities": [{"text": "SMT", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.9898880124092102}, {"text": "CoNLL-2014 (M 2 ) and JFLEG Test (GLEU) sets", "start_pos": 51, "end_pos": 95, "type": "DATASET", "confidence": 0.814959799249967}]}, {"text": " Table 3: Results for NMT systems on the CoNLL-2014  (M 2 ) and JFLEG Test (GLEU) sets.", "labels": [], "entities": [{"text": "CoNLL-2014  (M 2 ) and JFLEG Test (GLEU) sets", "start_pos": 41, "end_pos": 86, "type": "DATASET", "confidence": 0.8008086606860161}]}, {"text": " Table 4: Results for hybrid SMT-NMT systems on the  CoNLL-2014 (M 2 ) and JFLEG Test (GLEU) sets.", "labels": [], "entities": [{"text": "SMT-NMT", "start_pos": 29, "end_pos": 36, "type": "TASK", "confidence": 0.9847779273986816}, {"text": "CoNLL-2014 (M 2 )", "start_pos": 53, "end_pos": 70, "type": "DATASET", "confidence": 0.8217347502708435}, {"text": "JFLEG Test (GLEU) sets", "start_pos": 75, "end_pos": 97, "type": "DATASET", "confidence": 0.8474834611018499}]}]}