{"title": [{"text": "Leveraging Context Information for Natural Question Generation", "labels": [], "entities": [{"text": "Natural Question Generation", "start_pos": 35, "end_pos": 62, "type": "TASK", "confidence": 0.6717468897501627}]}], "abstractContent": [{"text": "The task of natural question generation is to generate a corresponding question given the input passage (fact) and answer.", "labels": [], "entities": [{"text": "natural question generation", "start_pos": 12, "end_pos": 39, "type": "TASK", "confidence": 0.7010667324066162}]}, {"text": "It is useful for enlarging the training set of QA systems.", "labels": [], "entities": []}, {"text": "Previous work has adopted sequence-to-sequence models that take a passage with an additional bit to indicate answer position as input.", "labels": [], "entities": []}, {"text": "However , they do not explicitly model the information between answer and other context within the passage.", "labels": [], "entities": []}, {"text": "We propose a model that matches the answer with the passage before generating the question.", "labels": [], "entities": []}, {"text": "Experiments show that our model outperforms the existing state of the art using rich features.", "labels": [], "entities": []}], "introductionContent": [{"text": "The task of natural question generation (NQG) is to generate a fluent and relevant question given a passage and a target answer.", "labels": [], "entities": [{"text": "natural question generation (NQG)", "start_pos": 12, "end_pos": 45, "type": "TASK", "confidence": 0.8179596761862437}]}, {"text": "Recently NQG has received increasing attention from both the industrial and academic communities because of its values for improving QA systems by automatically increasing the training data.", "labels": [], "entities": [{"text": "NQG", "start_pos": 9, "end_pos": 12, "type": "DATASET", "confidence": 0.9687367081642151}, {"text": "QA", "start_pos": 133, "end_pos": 135, "type": "TASK", "confidence": 0.9529030919075012}]}, {"text": "It can also be used for educational purposes such as language learning.", "labels": [], "entities": [{"text": "language learning", "start_pos": 53, "end_pos": 70, "type": "TASK", "confidence": 0.8160737454891205}]}, {"text": "One example is shown in, where a question \"when was nikola tesla born ?\" is generated given a passage and a fact \"1856\".", "labels": [], "entities": []}, {"text": "Existing work for NQG uses a sequence-to-sequence model), which takes a passage as input for generating a question.", "labels": [], "entities": [{"text": "NQG", "start_pos": 18, "end_pos": 21, "type": "DATASET", "confidence": 0.9181811809539795}]}, {"text": "They either entirely ignore the target answer (, or directly hard-code answer positions (.", "labels": [], "entities": []}, {"text": "These methods can neglect rich potential * Work done during an internship at IBM.", "labels": [], "entities": []}, {"text": "Passage: nikola tesla ( serbian cyrillic : Nikola Tesla ; 10 july 1856 -7 january 1943 ) was a serbian american inventor , electrical engineer , mechanical engineer , physicist , and futurist best known for his contributions to the design of the modern alternating current ( ac ) electricity supply system . Question: when was nikola tesla born ? interactions between the passage and the target answer.", "labels": [], "entities": []}, {"text": "In addition, they fail when the target answer does not occur in the passage verbatim.", "labels": [], "entities": []}, {"text": "In the answer \"1856\" is the year when nikola tesla was born.", "labels": [], "entities": []}, {"text": "This can be easily determined by leveraging the contextual information of \"10 july 1856 -7 january 1943\", while it is relatively hard when only the answer position information is adopted.", "labels": [], "entities": [{"text": "\"10 july 1856 -7 january 1943\"", "start_pos": 74, "end_pos": 104, "type": "DATASET", "confidence": 0.8636155856980218}]}, {"text": "We investigate explicit interaction between the target answer and the passage, so that contextual information can be better considered by the encoder.", "labels": [], "entities": []}, {"text": "In particular, matching is used between the target answer and the passage for collecting relevant contextual information.", "labels": [], "entities": []}, {"text": "We adopt the multiperspective context matching (MPCM) algorithm (, which takes two texts as input before producing a vector of numbers, representing similarity under different perspectives.", "labels": [], "entities": [{"text": "multiperspective context matching (MPCM)", "start_pos": 13, "end_pos": 53, "type": "TASK", "confidence": 0.7659176389376322}]}, {"text": "Results on SQuAD ( show that our model gives better BLEU scores than the state of the art.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 52, "end_pos": 56, "type": "METRIC", "confidence": 0.999270498752594}]}, {"text": "Furthermore, the questions generated by our model help to improve a strong extractive QA system.", "labels": [], "entities": []}, {"text": "Our code is available at https://github.com/freesunshine0316/MPQG.", "labels": [], "entities": [{"text": "MPQG", "start_pos": 61, "end_pos": 65, "type": "DATASET", "confidence": 0.8968217372894287}]}], "datasetContent": [{"text": "Matching strategies In, we analyze the importance of each matching strategy by performing an ablation experiment on the devset according to the data split of.", "labels": [], "entities": []}, {"text": "We can see that there is a performance decrease when removing each of the three matching strategies, which means that all three strategies are complementary.", "labels": [], "entities": []}, {"text": "In addition, w/o max-attentive-matching shows the least performance decrease.", "labels": [], "entities": []}, {"text": "One likely reason is that max-attentive-matching considers only the most similar hidden state of the answer, while the other two consider all hidden states.", "labels": [], "entities": []}, {"text": "Finally, w/o full-matching shows more performance decrease than w/o attentive-matching.", "labels": [], "entities": []}, {"text": "A reason  maybe that full-matching captures word order information, while attentive-matching does not.", "labels": [], "entities": []}, {"text": "shows the performance changes with different numbers of perspectives.", "labels": [], "entities": []}, {"text": "There is a large performance improvement when increasing the number from 1 to 3, which becomes small when further increasing the number from 3 to 5.", "labels": [], "entities": []}, {"text": "This shows that our multiperspective matching algorithm is effective, as we do not need a large number of perspectives for reaching our reported performance.", "labels": [], "entities": [{"text": "multiperspective matching", "start_pos": 20, "end_pos": 45, "type": "TASK", "confidence": 0.6341770589351654}]}], "tableCaptions": [{"text": " Table 2: Ablation results for matching strategies.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9952316880226135}]}, {"text": " Table 5: Results on improving extractive QA with automatically generated questions.", "labels": [], "entities": [{"text": "extractive QA", "start_pos": 31, "end_pos": 44, "type": "TASK", "confidence": 0.6159272342920303}]}]}