{"title": [{"text": "Learning Word Embeddings for Data Sparse and Sentiment Rich Data Sets", "labels": [], "entities": []}], "abstractContent": [{"text": "This research proposal describes two algorithms that are aimed at learning word embeddings for data sparse and sentiment rich data sets.", "labels": [], "entities": []}, {"text": "The goal is to use word embeddings adapted for domain specific data sets in downstream applications such as sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 108, "end_pos": 132, "type": "TASK", "confidence": 0.9566967785358429}]}, {"text": "The first approach learns word embed-dings in a supervised fashion via SWESA (Supervised Word Embeddings for Sentiment Analysis), an algorithm for sentiment analysis on data sets that are of modest size.", "labels": [], "entities": [{"text": "Sentiment Analysis)", "start_pos": 109, "end_pos": 128, "type": "TASK", "confidence": 0.7970427672068278}, {"text": "sentiment analysis", "start_pos": 147, "end_pos": 165, "type": "TASK", "confidence": 0.8980979919433594}]}, {"text": "SWESA leverages document labels to jointly learn polarity-aware word embeddings and a classifier to classify unseen documents.", "labels": [], "entities": []}, {"text": "In the second approach domain adapted (DA) word embeddings are learned by exploiting the specificity of domain specific data sets and the breadth of generic word embeddings.", "labels": [], "entities": []}, {"text": "The new embeddings are formed by aligning corresponding word vectors using Canoni-cal Correlation Analysis (CCA) or the related nonlinear Kernel CCA.", "labels": [], "entities": []}, {"text": "Experimental results on binary sentiment classification tasks using both approaches for standard data sets are presented.", "labels": [], "entities": [{"text": "binary sentiment classification tasks", "start_pos": 24, "end_pos": 61, "type": "TASK", "confidence": 0.7849901914596558}]}], "introductionContent": [{"text": "Generic word embeddings such as Glove and word2vec) which are pre-trained on large sets of raw text, in addition to having desirable structural properties have demonstrated remarkable success when used as features to a supervised learner in various applications such as the sentiment classification of text documents.", "labels": [], "entities": [{"text": "sentiment classification of text documents", "start_pos": 274, "end_pos": 316, "type": "TASK", "confidence": 0.9358018040657043}]}, {"text": "There are, however, many applications with domain specific vocabularies and relatively small amounts of data.", "labels": [], "entities": []}, {"text": "The performance of word embedding approaches in such applications is limited, since word embeddings pre-trained on generic corpora do not capture domain specific semantics/knowledge, while embeddings trained on small data sets are of low quality.", "labels": [], "entities": []}, {"text": "Since word embeddings are used to initialize most algorithms for sentiment analysis etc, generic word embeddings further make for poor initialization of algorithms for tasks on domain specific data sets.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 65, "end_pos": 83, "type": "TASK", "confidence": 0.9526280462741852}]}, {"text": "A concrete example of a small-sized domain specific corpus is the Substances User Disorders (SUDs) data set (, which contains messages from discussion forums for people with substance addictions.", "labels": [], "entities": [{"text": "Substances User Disorders (SUDs) data set", "start_pos": 66, "end_pos": 107, "type": "TASK", "confidence": 0.7241938635706902}]}, {"text": "These forums are part of mobile health intervention treatments that encourages participants to engage in sobriety-related discussions.", "labels": [], "entities": []}, {"text": "The aim with digital intervention treatments is to analyze the daily content of participants' messages and predicit relapse risk.", "labels": [], "entities": []}, {"text": "This data is both domain specific and limited in size.", "labels": [], "entities": []}, {"text": "Other examples include customer support tickets reporting issues with taxi-cab services, reviews of restaurants and movies, discussions by special interest groups, and political surveys.", "labels": [], "entities": []}, {"text": "In general they are common in fields where words have different sentiments from what they would have elsewhere.", "labels": [], "entities": []}, {"text": "Such data sets present significant challenges for algorithms based on word embeddings.", "labels": [], "entities": []}, {"text": "First, the data is on specific topics and has a very different distribution from generic corpora, so pre-trained generic word embeddings such as those trained on Common Crawl or Wikipedia are unlikely to yield accurate results in downstream tasks.", "labels": [], "entities": []}, {"text": "When performing sentiment classification using pre-trained word embeddings, differences in domains of training and test data sets limit the applicability of the embedding algorithm.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 16, "end_pos": 40, "type": "TASK", "confidence": 0.9603698253631592}]}, {"text": "For example, in SUDs, dis-cussions are focused on topics related to recovery and addiction; the sentiment behind the word 'party' maybe very different in a dating context than in a substance abuse context.", "labels": [], "entities": [{"text": "SUDs", "start_pos": 16, "end_pos": 20, "type": "TASK", "confidence": 0.9749099612236023}]}, {"text": "Similarly seemingly neutral words such as 'holidays', 'alcohol' etc are indicative of stronger negative sentiment in these domains, while words like 'clean' are indicative of stronger positive sentiment.", "labels": [], "entities": []}, {"text": "Thus domain specific vocabularies and word semantics maybe a problem for pre-trained sentiment classification models.", "labels": [], "entities": [{"text": "word semantics", "start_pos": 38, "end_pos": 52, "type": "TASK", "confidence": 0.6872791200876236}, {"text": "sentiment classification", "start_pos": 85, "end_pos": 109, "type": "TASK", "confidence": 0.86016446352005}]}, {"text": "Second, there is insufficient data to completely train a word embedding.", "labels": [], "entities": []}, {"text": "The SUD data set consists of a few hundred people and only a fraction of these are active ( and.", "labels": [], "entities": [{"text": "SUD data set", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.9269201159477234}]}, {"text": "This results in a small data set of text messages available for analysis.", "labels": [], "entities": []}, {"text": "Furthermore, the content is generated spontaneously on a day today basis, and language use is informal and unstructured.", "labels": [], "entities": []}, {"text": "Running the generic word embedding constructions algorithms on such a data set leads to very noisy outputs that are not suitable as input for downstream applications like sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 171, "end_pos": 195, "type": "TASK", "confidence": 0.9541310667991638}]}, {"text": "Fine-tuning the generic word embedding also leads to noisy outputs due to the highly nonconvex training objective and the small amount of the data.", "labels": [], "entities": []}, {"text": "This proposal briefly describes two possible solutions to address this problem.", "labels": [], "entities": []}, {"text": "Section 3 describes a Canonical Correlation Analysis (CCA) based approach to obtain domain adapted word embeddings.", "labels": [], "entities": []}, {"text": "Section 2 describes an biconvex optimization algorithm that jointly learns polarity aware word embeddings and a classifier.", "labels": [], "entities": []}, {"text": "Section 4 discusses results from both approaches and outlines potential future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "SWESA is evaluated against the following baselines and data sets, Datasets: 3 balanced data sets () of 1000 reviews from Amazon, IMDB and Yelp with binary 'positive' and 'negative' sentiment labels are considered.", "labels": [], "entities": [{"text": "SWESA", "start_pos": 0, "end_pos": 5, "type": "TASK", "confidence": 0.6946951150894165}, {"text": "Yelp", "start_pos": 138, "end_pos": 142, "type": "DATASET", "confidence": 0.7720338106155396}]}, {"text": "One imbalanced data set with 2500 text messages obtained from a study involving subjects with alcohol addiction is considered.", "labels": [], "entities": []}, {"text": "Only 8% of the messages are indicative of 'relapse risk' while the rest are 'benign'.", "labels": [], "entities": []}, {"text": "Note that this imbalance influences the performance metrics and can be seen by comparing against the scores achieved by the balanced data sets.", "labels": [], "entities": []}, {"text": "Additional information such as number of word tokens etc can  be found in the supplemental section.", "labels": [], "entities": []}, {"text": "\u2022 Naive Bayes: This is a standard baseline that is best suited for classification in small sized data sets.", "labels": [], "entities": []}, {"text": "\u2022 Recursive Neural Tensor Network: RNTN is a dependency parser based sentiment analysis algorithm.", "labels": [], "entities": [{"text": "Recursive Neural Tensor", "start_pos": 2, "end_pos": 25, "type": "TASK", "confidence": 0.6076942682266235}, {"text": "dependency parser based sentiment analysis", "start_pos": 45, "end_pos": 87, "type": "TASK", "confidence": 0.8032022833824157}]}, {"text": "Both pre-trained RNTN and the RNTN algorithm retrained on the data sets considered here are used to obtain classification accuracy.", "labels": [], "entities": [{"text": "classification", "start_pos": 107, "end_pos": 121, "type": "TASK", "confidence": 0.9538317918777466}, {"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9090865254402161}]}, {"text": "Note that with the RNTN we do not get probabilities for classes hence we do not compute AUC.", "labels": [], "entities": [{"text": "RNTN", "start_pos": 19, "end_pos": 23, "type": "DATASET", "confidence": 0.5556474328041077}, {"text": "AUC", "start_pos": 88, "end_pos": 91, "type": "METRIC", "confidence": 0.9490634799003601}]}, {"text": "\u2022 Two-Step (TS): In this setup, embeddings obtained via word2vec on the test data sets and LSA are used to obtain document representation via weighted averaging.", "labels": [], "entities": []}, {"text": "Documents are then classified using a Logistic Regressor.", "labels": [], "entities": []}, {"text": "Hyperparameters: Parameters such as dimension of word embeddings, regularization on the logistic regressor etc are determined via 10-fold cross validation.", "labels": [], "entities": []}, {"text": "Results: Average Precision and AUC are reported in table 2.", "labels": [], "entities": [{"text": "Average", "start_pos": 9, "end_pos": 16, "type": "METRIC", "confidence": 0.9468140006065369}, {"text": "Precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9391556978225708}, {"text": "AUC", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.9975390434265137}]}, {"text": "Note that, the word2vec embeddings used in TS are obtained by retraining the word2vec algorithm on the test data sets.", "labels": [], "entities": [{"text": "TS", "start_pos": 43, "end_pos": 45, "type": "TASK", "confidence": 0.8640291690826416}]}, {"text": "To reinforce the point that retraining neural network based algorithms on sparse data sets depreciates their performance, results from pre-trained and retrained RNTN are presented to further support this fact.", "labels": [], "entities": []}, {"text": "Since SWESA makes use of document labels when learning word embeddings, resulting word embeddings are polarity aware.", "labels": [], "entities": []}, {"text": "Using cosine similarity, word antonym pairs are observed.", "labels": [], "entities": []}, {"text": "Given words 'Good,''fair' and 'Awful,' the antonym pair 'Good/Awful' is determined via cosine similarity between w Good and w Awf ul . shows a small sample of word embeddings learned on the Amazon data set by SWESA and word2vec.", "labels": [], "entities": [{"text": "Awful", "start_pos": 31, "end_pos": 36, "type": "METRIC", "confidence": 0.9872232675552368}, {"text": "Awful", "start_pos": 62, "end_pos": 67, "type": "METRIC", "confidence": 0.9542625546455383}, {"text": "Amazon data set", "start_pos": 190, "end_pos": 205, "type": "DATASET", "confidence": 0.8675481081008911}]}, {"text": "The cosine similarity (angle) between the most dissimilar words is calculated and words are depicted as points on the unit circle.", "labels": [], "entities": [{"text": "cosine similarity (angle)", "start_pos": 4, "end_pos": 29, "type": "METRIC", "confidence": 0.8593843579292297}]}, {"text": "These examples illustrate that SWESA captures sentiment polarity at word embedding level despite limited data.", "labels": [], "entities": [{"text": "SWESA", "start_pos": 31, "end_pos": 36, "type": "TASK", "confidence": 0.9483397006988525}]}, {"text": "DA embeddings are evaluated in binary sentiment classification tasks on four data sets described in Section 2.2.", "labels": [], "entities": [{"text": "binary sentiment classification", "start_pos": 31, "end_pos": 62, "type": "TASK", "confidence": 0.6984607875347137}]}, {"text": "Document embeddings are obtained via i)a standard framework that expresses documents as weighted combination of their constituent word embeddings and ii) by initializing a state of the art sentence encoding algorithm InferSent () with word embeddings to obtain sentence embeddings.", "labels": [], "entities": [{"text": "Document embeddings", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8296754360198975}]}, {"text": "Encoded sentences are then classified using a Logistic Regressor.", "labels": [], "entities": []}, {"text": "Word embeddings and baselines: \u2022 Generic word embeddings: Generic word embeddings used are GloVe 1 from both Wikipedia and common crawl and the word2vec (Skip-gram) embeddings 2 . These generic embeddings will be denoted as Glv, GlvCC and w2v.", "labels": [], "entities": []}, {"text": "\u2022 DS word embeddings: DS embeddings are obtained via Latent Semantic Analysis (LSA) and via retraining word2vec on the test data sets using the implementation in gensim 3 . DS embeddings via LSA are denoted by LSA and DS embeddings via word2vec are denoted by DSw2v.", "labels": [], "entities": []}, {"text": "\u2022 concatenation-SVD baseline: Generic and DS embeddings are concatenated to form a single embeddings matrix.", "labels": [], "entities": []}, {"text": "SVD is performed on this matrix and the resulting singular vectors are projected onto the d largest singular values to form resultant word embeddings.", "labels": [], "entities": []}, {"text": "These meta-embeddings proposed by) have demonstrated considerable success in intrinsic tasks such as similarities, analogies etc.", "labels": [], "entities": []}, {"text": "Details about dimensions of the word embeddings and kernel hyperparameter tuning are found in the supplemental material.", "labels": [], "entities": []}, {"text": "Note that InferSent is fine-tuned with a combination of GloVe common crawl embeddings and DA embeddings, and concSVD.", "labels": [], "entities": []}, {"text": "Since the data sets at hand do not contain all the tokens required to retrain InferSent, we replace word tokens that are common across our test data sets and InferSent training data with the DA embeddings and concSVD.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: This table shows results from a standard  sentiment classification task on all four data sets.  Results from SWESA are in boldface and results  from pre-trained RNTN are in blue.", "labels": [], "entities": [{"text": "sentiment classification task", "start_pos": 52, "end_pos": 81, "type": "TASK", "confidence": 0.9148234923680624}, {"text": "SWESA", "start_pos": 119, "end_pos": 124, "type": "DATASET", "confidence": 0.6165648102760315}]}, {"text": " Table 2: This table shows results from the classi- fication task using sentence embeddings obtained  from weighted averaging of word embeddings.  Metrics reported are average Precision, F-score  and AUC and the corresponding standard devia- tions (STD). Best results are attained by KCCA  (GlvCC, LSA) and are highlighted in boldface.", "labels": [], "entities": [{"text": "Precision", "start_pos": 176, "end_pos": 185, "type": "METRIC", "confidence": 0.9981825351715088}, {"text": "F-score", "start_pos": 187, "end_pos": 194, "type": "METRIC", "confidence": 0.9912880063056946}, {"text": "AUC", "start_pos": 200, "end_pos": 203, "type": "METRIC", "confidence": 0.9950062036514282}, {"text": "standard devia- tions (STD)", "start_pos": 226, "end_pos": 253, "type": "METRIC", "confidence": 0.753506852047784}, {"text": "KCCA  (GlvCC, LSA)", "start_pos": 284, "end_pos": 302, "type": "DATASET", "confidence": 0.7393660495678583}]}, {"text": " Table 3: This table shows results obtained by us- ing sentence embeddings from the InferSent en- coder in the sentiment classification task. Met- rics reported are average Precision, F-score and  AUC along with the corresponding standard devi- ations (STD). Best results are obtained by KCCA  (GlvCC, LSA) and are highlighted in boldface.", "labels": [], "entities": [{"text": "sentiment classification task", "start_pos": 111, "end_pos": 140, "type": "TASK", "confidence": 0.9276507496833801}, {"text": "Precision", "start_pos": 173, "end_pos": 182, "type": "METRIC", "confidence": 0.9982323050498962}, {"text": "F-score", "start_pos": 184, "end_pos": 191, "type": "METRIC", "confidence": 0.9913995265960693}, {"text": "AUC", "start_pos": 197, "end_pos": 200, "type": "METRIC", "confidence": 0.9959035515785217}, {"text": "standard devi- ations (STD)", "start_pos": 230, "end_pos": 257, "type": "METRIC", "confidence": 0.691033946616309}, {"text": "KCCA  (GlvCC, LSA)", "start_pos": 288, "end_pos": 306, "type": "DATASET", "confidence": 0.7250293890635172}]}]}