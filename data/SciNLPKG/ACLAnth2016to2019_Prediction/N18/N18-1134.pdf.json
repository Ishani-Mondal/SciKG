{"title": [{"text": "Multimodal Frame Identification with Multilingual Evaluation", "labels": [], "entities": [{"text": "Multimodal Frame Identification", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.6542571981747946}]}], "abstractContent": [{"text": "An essential step in FrameNet Semantic Role Labeling is the Frame Identification (FrameId) task, which aims at disambiguating a situation around a predicate.", "labels": [], "entities": [{"text": "FrameNet Semantic Role Labeling", "start_pos": 21, "end_pos": 52, "type": "TASK", "confidence": 0.7265207916498184}, {"text": "Frame Identification (FrameId) task", "start_pos": 60, "end_pos": 95, "type": "TASK", "confidence": 0.7783652693033218}]}, {"text": "Whilst current FrameId methods rely on textual representations only, we hypothesize that FrameId can profit from a richer understanding of the situational context.", "labels": [], "entities": []}, {"text": "Such contextual information can be obtained from commonsense knowledge, which is more present in images than in text.", "labels": [], "entities": []}, {"text": "In this paper, we extend a state-of-the-art FrameId system in order to effectively leverage multi-modal representations.", "labels": [], "entities": []}, {"text": "We conduct a comprehensive evaluation on the English FrameNet and its German counterpart SALSA.", "labels": [], "entities": [{"text": "English FrameNet", "start_pos": 45, "end_pos": 61, "type": "DATASET", "confidence": 0.8641377985477448}]}, {"text": "Our analysis shows that for the German data, tex-tual representations are still competitive with multimodal ones.", "labels": [], "entities": [{"text": "German data", "start_pos": 32, "end_pos": 43, "type": "DATASET", "confidence": 0.8898824155330658}]}, {"text": "However on the English data, our multimodal FrameId approach out-performs its unimodal counterpart, setting anew state of the art.", "labels": [], "entities": [{"text": "English data", "start_pos": 15, "end_pos": 27, "type": "DATASET", "confidence": 0.8878886103630066}]}, {"text": "Its benefits are particularly apparent in dealing with ambiguous and rare instances, the main source of errors of current systems.", "labels": [], "entities": []}, {"text": "For research purposes, we release (a) the implementation of our system, (b) our evaluation splits for SALSA 2.0, and (c) the em-beddings for synsets and IMAGINED words.", "labels": [], "entities": []}], "introductionContent": [{"text": "FrameNet Semantic Role Labeling analyzes sentences with respect to frame-semantic structures based on FrameNet (.", "labels": [], "entities": [{"text": "FrameNet Semantic Role Labeling analyzes sentences", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.6838693916797638}, {"text": "FrameNet", "start_pos": 102, "end_pos": 110, "type": "DATASET", "confidence": 0.916111946105957}]}, {"text": "Typically, this involves two steps: First, Frame Identification (FrameId), capturing the context around a predicate (frame evoking element) and assigning a frame, basically a word sense label fora prototypical situation, to it.", "labels": [], "entities": [{"text": "Frame Identification (FrameId)", "start_pos": 43, "end_pos": 73, "type": "TASK", "confidence": 0.6848785579204559}]}, {"text": "Second, Role Labeling, i.e. identifying the participants (fillers) of the predicate and connecting them with predefined frame- * named alphabetically 1 https://github.com/UKPLab/ naacl18-multimodal-frame-identification specific role labels.", "labels": [], "entities": [{"text": "Role Labeling", "start_pos": 8, "end_pos": 21, "type": "TASK", "confidence": 0.7798838913440704}, {"text": "UKPLab", "start_pos": 171, "end_pos": 177, "type": "DATASET", "confidence": 0.9850152134895325}]}, {"text": "FrameId is crucial to the success of Semantic Role Labeling as FrameId errors account for most wrong predictions in current systems (.", "labels": [], "entities": [{"text": "Semantic Role Labeling", "start_pos": 37, "end_pos": 59, "type": "TASK", "confidence": 0.8947641650835673}]}, {"text": "Consequently, improving FrameId is of major interest.", "labels": [], "entities": [{"text": "FrameId", "start_pos": 24, "end_pos": 31, "type": "DATASET", "confidence": 0.6556574106216431}]}, {"text": "The main challenge and source of prediction errors of FrameId systems are ambiguous predicates, which can evoke several frames, e.g., the verb sit evokes the frame Change posture in a context like 'a person is sitting back on a bench', while it evokes Being located when 'a company is sitting in a city'.", "labels": [], "entities": []}, {"text": "Understanding the predicate context, and thereby the context of the situation (here, 'Who / what is sitting where?'), is crucial to identifying the correct frame for ambiguous cases.", "labels": [], "entities": []}, {"text": "State-of-the-art FrameId systems model the situational context using pretrained distributed word embeddings (see).", "labels": [], "entities": []}, {"text": "Hence, it is assumed that the context of the situation is explicitly expressed in words.", "labels": [], "entities": []}, {"text": "However, language understanding involves implicit knowledge, which is not mentioned but still seems obvious to humans, e.g., 'people can sit back on a bench, but companies cannot', 'companies are in cities'.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 9, "end_pos": 31, "type": "TASK", "confidence": 0.7081452310085297}]}, {"text": "Such implicit commonsense knowledge is obvious enough to be rarely expressed in sentences, but is more likely to be present in images.", "labels": [], "entities": []}, {"text": "how images can provide access to implicit commonsense knowledge crucial to FrameId.", "labels": [], "entities": []}, {"text": "When looking at the semantics of events, FrameId has commonalities with event prediction tasks.", "labels": [], "entities": [{"text": "event prediction tasks", "start_pos": 72, "end_pos": 94, "type": "TASK", "confidence": 0.7759343683719635}]}, {"text": "These aim at linking events and their participants to script knowledge and at predicting events in narrative chains.", "labels": [], "entities": []}, {"text": "argue that knowing about the participants helps to identify the event, which suggests the need for implicit context knowledge also for FrameId.", "labels": [], "entities": [{"text": "FrameId", "start_pos": 135, "end_pos": 142, "type": "DATASET", "confidence": 0.7946874499320984}]}, {"text": "This specifically applies to images, which can reflect properties of the participants of a situation in a inherently different way, see.", "labels": [], "entities": []}, {"text": "We analyze whether multimodal representations grounded in images can encode commonsense knowledge to improve FrameId.", "labels": [], "entities": [{"text": "FrameId", "start_pos": 109, "end_pos": 116, "type": "DATASET", "confidence": 0.7338277697563171}]}, {"text": "To that end, we extend SimpleFrameId (, a recent FrameId model based on distributed word embeddings, to the multimodal case and evaluate for English and German.", "labels": [], "entities": []}, {"text": "Note that there is a general lack of evaluation of FrameId systems for languages other than English.", "labels": [], "entities": []}, {"text": "This is problematic as they yield different challenges; German, for example, due to long distance dependencies.", "labels": [], "entities": []}, {"text": "Also, word embeddings trained on different languages have different strengths in ambiguous words.", "labels": [], "entities": []}, {"text": "We elaborate on insights from using different datasets by language.", "labels": [], "entities": []}, {"text": "(1) We propose a pipeline and architecture of a FrameId system, extending stateof-the-art methods with the option of using implicit multimodal knowledge.", "labels": [], "entities": []}, {"text": "It is flexible toward modality and language, reaches state-of-the-art accuracy on English FrameId data, clearly outperforming several baselines, and sets anew state of the art on German FrameId data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9989297986030579}, {"text": "English FrameId data", "start_pos": 82, "end_pos": 102, "type": "DATASET", "confidence": 0.749324639638265}, {"text": "German FrameId data", "start_pos": 179, "end_pos": 198, "type": "DATASET", "confidence": 0.8530702193578085}]}, {"text": "(2) We discuss properties of language and meaning with respect to implicit knowledge, as well as the potential of multimodal representations for FrameId.", "labels": [], "entities": [{"text": "FrameId", "start_pos": 145, "end_pos": 152, "type": "DATASET", "confidence": 0.7760106325149536}]}, {"text": "(3) We perform a detailed analysis of FrameId systems.", "labels": [], "entities": []}, {"text": "First, we develop anew strong baseline.", "labels": [], "entities": []}, {"text": "Second, we suggest novel evaluation metrics that are essential for assessing ambiguous and rare frame instances.", "labels": [], "entities": []}, {"text": "We show our system's advantage over the strong baseline in this regard and by this improve upon the main source of errors.", "labels": [], "entities": []}, {"text": "Third, we analyze gold annotated datasets for English and German showing their different strengths.", "labels": [], "entities": []}, {"text": "Finally, we release the implementation of our system, our evaluation splits for SALSA 2.0, and the embeddings for synsets and IMAGINED words.", "labels": [], "entities": []}], "datasetContent": [{"text": "To better understand the influence of the dataset on the prediction errors, we further analyze the errors of our approach (see.", "labels": [], "entities": []}, {"text": "A wrong prediction can either be a normal classification error, or it can be the result of an instance that was unseen at training time, which means that the error is due to the training set.", "labels": [], "entities": []}, {"text": "The instance can either be completely unseen or unseen with the target label.", "labels": [], "entities": []}, {"text": "We observe that FrameNet has larger issues with unseen data compared to SALSA, especially data that was unseen with one specific label but seen with another label.", "labels": [], "entities": [{"text": "FrameNet", "start_pos": 16, "end_pos": 24, "type": "DATASET", "confidence": 0.7948934435844421}]}, {"text": "This is due to the uneven split of the documents in FrameNet, leading to data from different source documents and domains in the training and test split.", "labels": [], "entities": [{"text": "FrameNet", "start_pos": 52, "end_pos": 60, "type": "DATASET", "confidence": 0.8669971823692322}]}, {"text": "SALSA does not suffer from this problem as much since the split was performed differently.", "labels": [], "entities": [{"text": "SALSA", "start_pos": 0, "end_pos": 5, "type": "TASK", "confidence": 0.4829470217227936}]}, {"text": "It would be worth considering the same splitting method for FrameNet.", "labels": [], "entities": [{"text": "FrameNet", "start_pos": 60, "end_pos": 68, "type": "DATASET", "confidence": 0.8696921467781067}]}], "tableCaptions": [{"text": " Table 1: Lexicon statistics for FrameNet 1.5 and for  SALSA 2.0: the total number of distinct frames and  lexical units LUs (distinct predicate-frame combina- tions), the number of frames a predicate can evoke on  average avg, and the % of ambiguous predicates.", "labels": [], "entities": []}, {"text": " Table 2: Dataset statistics for FrameNet 1.5 fulltext  with Das split and for SALSA 2.0 with our split: num- ber of sentences and frames (as used in our experi- ments). Right half (only used in further investigations):  number of sentences when reduced to only those hav- ing synsets in the visual and in the linguistic AutoEx- tend embeddings.", "labels": [], "entities": []}, {"text": " Table 3: FrameId results (in %) on English (upper) and German (lower) with and without using the lexicon.", "labels": [], "entities": [{"text": "FrameId", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.666635274887085}]}, {"text": " Table 4: Error analysis of best uni-and multimodal systems. correct, errors: unseen, unseen label and normal.", "labels": [], "entities": [{"text": "Error", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9641448855400085}, {"text": "correct", "start_pos": 61, "end_pos": 68, "type": "METRIC", "confidence": 0.9973465204238892}]}]}