{"title": [{"text": "Spotting Spurious Data with Neural Networks", "labels": [], "entities": [{"text": "Spotting Spurious Data", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8777463436126709}]}], "abstractContent": [{"text": "Automatic identification of spurious instances (those with potentially wrong labels in datasets) can improve the quality of existing language resources, especially when annotations are obtained through crowdsourc-ing or automatically generated based on coded rankings.", "labels": [], "entities": []}, {"text": "In this paper, we present an effective approach inspired by queueing theory and psychology of learning to automatically identify spurious instances in datasets.", "labels": [], "entities": []}, {"text": "Our approach discriminates instances based on their \"difficulty to learn,\" determined by a downstream learner.", "labels": [], "entities": []}, {"text": "Our method can be applied to any dataset assuming the existence of a neural network model for the target task of the dataset.", "labels": [], "entities": []}, {"text": "Our best approach outper-forms competing state-of-the-art baselines and has a MAP of 0.85 and 0.22 in identifying spurious instances in synthetic and carefully-crowdsourced real-world datasets respectively.", "labels": [], "entities": [{"text": "MAP", "start_pos": 78, "end_pos": 81, "type": "METRIC", "confidence": 0.9994350075721741}]}], "introductionContent": [{"text": "The importance of error-free language resources cannot be overstated as errors can inversely affect interpretations of the data, models developed from the data, and decisions made based on the data.", "labels": [], "entities": []}, {"text": "Although the quality of language resources can be improved through good annotation guidelines, test questions, etc., annotation noise still exists (.", "labels": [], "entities": []}, {"text": "For example, shows sample spurious instances (those with potentially wrong labels) in CIFAR-10 ( which is a benchmark dataset for object classification.", "labels": [], "entities": [{"text": "CIFAR-10", "start_pos": 86, "end_pos": 94, "type": "DATASET", "confidence": 0.9130197167396545}, {"text": "object classification", "start_pos": 130, "end_pos": 151, "type": "TASK", "confidence": 0.7917254567146301}]}, {"text": "Spurious instances can mislead systems, and, if available in test data, lead to unrealistic comparison among competing systems.", "labels": [], "entities": []}, {"text": "Previous works either directly identify noise in datasets (, or develop models that are more robust against noise ().", "labels": [], "entities": []}, {"text": "Furthermore, recent works on adversarial perturbation have tackled this problem (.", "labels": [], "entities": []}, {"text": "However, most previous approaches require either annotations generated by each individual annotator (Guan et al., 2017), or both task-specific and instance-type (genuine or adversarial) labels for training, or noise-free data (.", "labels": [], "entities": []}, {"text": "Such information is often not available in the final release of most datasets.", "labels": [], "entities": []}, {"text": "Current approaches utilize prediction probability/loss of instances to tackle the above challenges in identifying spurious instances.", "labels": [], "entities": []}, {"text": "This is because prediction probability/loss of spurious instances tend to be lower than that of genuine instances).", "labels": [], "entities": []}, {"text": "In particular, the Bayesian Uncertainty model) defines spurious instances as those that have greater uncertainty (variance) in their stochastic predictions, and the Variational Inference model) expects greater posterior entropy in predictions made for spurious instances.", "labels": [], "entities": []}, {"text": "In this paper, our hypothesis is that spurious instances are frequently found to be difficult to learn during training process.", "labels": [], "entities": []}, {"text": "This difficulty in learning stems from the intrinsic discrepancy between spurious and the cohort of genuine instances which frequently makes a learner less confident in predicting the wrong labels of spurious instances.", "labels": [], "entities": []}, {"text": "Based on this hypothesis, we present two frameworks which are inspired by findings in queueing theory and psychology, namely Leitner queue network and Curriculum Learning ().", "labels": [], "entities": []}, {"text": "Our frameworks can be considered as schedulers that schedule instances to train a downstream learner (e.g. a neural network) with respect to \"easiness\"/\"difficulty\" of instances -determined by the extent to which the learner can correctly label (e.g. classify) instances during the training process.", "labels": [], "entities": []}, {"text": "The two frameworks, however, differ in their views on the theory of learning as we describe below: Curriculum learning is inspired by the learning principle that humans can learn more effectively when training starts with easier concepts and gradually proceeds with more difficult ones).", "labels": [], "entities": []}, {"text": "On the other hand, Leitner system is inspired by spaced repetition), the learning principle that effective and efficient learning can be achieved by working more on difficult concepts and lesson easier ones.", "labels": [], "entities": []}, {"text": "Both frameworks are effective, conceptually simple, and easy to implement.", "labels": [], "entities": []}, {"text": "The contributions of this paper are as follows: (a) we develop a cognitively-motivated and effective algorithm for identifying spurious instances in datasets, (b) our approach can be applied to any dataset without modification if there exists a neural network architecture for the target task of the dataset, and (c) we release a tool that can be easily used to generate a ranked list of spurious instances in datasets.", "labels": [], "entities": []}, {"text": "Our tool requires a dataset and its corresponding network architecture to generate a ranked list of spurious instances in the dataset.", "labels": [], "entities": []}, {"text": "Our best approach (Leitner model) has a mean average precision (MAP) of 0.85 and 0.22 in identifying spurious instances on real-world and synthetic datasets and outperforms competing stateof-the-art baselines.", "labels": [], "entities": [{"text": "mean average precision (MAP)", "start_pos": 40, "end_pos": 68, "type": "METRIC", "confidence": 0.9174177547295889}]}], "datasetContent": [{"text": "We employ a TREC-like evaluation setting to compare models against each other.", "labels": [], "entities": []}, {"text": "For this, we create a pool of K most spurious instances identified by different models.", "labels": [], "entities": []}, {"text": "If needed, e.g. in case of real-world datasets, we manually label all instances in the pool and come to agreement about their labels.", "labels": [], "entities": []}, {"text": "Then, we compare the resulting labels with the original labels in the dataset to determine spurious/genuine instances.", "labels": [], "entities": []}, {"text": "We compare models based on the standard TREC evaluation measures, namely mean average precision (MAP), precision after r instances are retrieved (P@r), and, only for synthetic data, precision after all spurious instances are retrieved (Rprec).", "labels": [], "entities": [{"text": "mean average precision (MAP)", "start_pos": 73, "end_pos": 101, "type": "METRIC", "confidence": 0.9381475746631622}, {"text": "precision", "start_pos": 103, "end_pos": 112, "type": "METRIC", "confidence": 0.9988841414451599}, {"text": "precision", "start_pos": 182, "end_pos": 191, "type": "METRIC", "confidence": 0.9991112351417542}, {"text": "Rprec", "start_pos": 236, "end_pos": 241, "type": "METRIC", "confidence": 0.9202293157577515}]}, {"text": "We use the trec-eval toolkit to compute performance of different models.", "labels": [], "entities": []}, {"text": "3  We develop synthetic and real-world datasets for our experiments.", "labels": [], "entities": []}, {"text": "Since, in contrast to real-world datasets, (most 4 ) synthetic datasets do not contain any noisy instances, we can conduct largescale evaluation by injecting spurious instances into such datasets.", "labels": [], "entities": []}, {"text": "shows detail information about our datasets.: Dataset Information.", "labels": [], "entities": []}, {"text": "\"SpRatio\" shows the fraction of spurious instances in the TREC pool; size of the pool for Addition is 10K instances with no limit on the top K retrieved instances; the corresponding value for Twitter and Reddit datasets are 198 and 152 posts respectively for top K = 50.", "labels": [], "entities": [{"text": "TREC pool", "start_pos": 58, "end_pos": 67, "type": "DATASET", "confidence": 0.73006272315979}, {"text": "Reddit datasets", "start_pos": 204, "end_pos": 219, "type": "DATASET", "confidence": 0.8407174348831177}]}, {"text": "The Addition dataset, initially developed by, is a synthetic dataset in which an input instance is a pair of non-negative integers smaller than 10 land the corresponding output is the arithmetic sum of the input; we set l = 4 in our experiments.", "labels": [], "entities": [{"text": "Addition dataset", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.7026835530996323}]}, {"text": "Since this dataset contains only genuine instances, we create noisy datasets by injecting \u03b1 \u00d7 N spurious instances into (1 \u2212 \u03b1) \u00d7 N genuine instances, where N = 10K is the total number of training instances and \u03b1 \u2264 0.5 indicates the noise level in the dataset.", "labels": [], "entities": []}, {"text": "We create spurious instances as follows: given three random numbers xi , x j , x k \u2208 [0, 10 l ) such that x j = x k , the wrong sum (output) for the pair (x i , x j ) is computed as: where o is a random variable that takes values from O = {1, 2} with equal probability.", "labels": [], "entities": []}, {"text": "We crowdsource annotations for two real-world datasets, namely Twitter and Reddit posts (see).", "labels": [], "entities": []}, {"text": "For quality control, we carefully develop annotation schemas as well as high quality test questions (see below) to minimize the chances of spurious labels in the resulting annotations.", "labels": [], "entities": [{"text": "quality control", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.7124844044446945}]}, {"text": "The Twitter dataset contains tweets about a telecommunication brand.", "labels": [], "entities": []}, {"text": "Tweets contain brand name or its products and services.", "labels": [], "entities": []}, {"text": "Annotators are instructed to label tweets as positive/negative if they describe positive/negative sentiment about the target brand.", "labels": [], "entities": []}, {"text": "We use 500 labeled instances for annotation quality assurance and ignore data generated by annotators who have less than 80% accuracy on these instances.", "labels": [], "entities": [{"text": "annotation quality assurance", "start_pos": 33, "end_pos": 61, "type": "TASK", "confidence": 0.690646102031072}, {"text": "accuracy", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.9981008172035217}]}, {"text": "The resulting Fleiss' kappa) is \u03ba = 0.66 on our Twitter dataset which indicates substantial agreement.", "labels": [], "entities": [{"text": "Fleiss' kappa)", "start_pos": 14, "end_pos": 28, "type": "METRIC", "confidence": 0.7205794850985209}, {"text": "Twitter dataset", "start_pos": 48, "end_pos": 63, "type": "DATASET", "confidence": 0.7809041440486908}]}, {"text": "The Reddit dataset includes posts about colon, breast, or brain cancer.", "labels": [], "entities": [{"text": "Reddit dataset", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.7607594728469849}]}, {"text": "These posts contain phrases like colon cancer, breast cancer, or brain cancer.", "labels": [], "entities": []}, {"text": "Annotators are instructed to label a post as \"relevant\" if it describes a patient's experience (including sign and symptoms, treatments, etc.,) with respect to the cancer.", "labels": [], "entities": []}, {"text": "In contrast, \"irrelevant\" posts are defined as generic texts (such as scientific papers, news, etc.,) that discuss cancer in general without describing areal patient experience.", "labels": [], "entities": []}, {"text": "We use 300 labeled instances for annotation quality assurance and ignore annotations generated by users who have less than 80% accuracy on these instances.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 127, "end_pos": 135, "type": "METRIC", "confidence": 0.9975554943084717}]}, {"text": "The resulting Fleiss' kappa is \u03ba = 0.48 for the Reddit dataset which indicates moderate agreement.", "labels": [], "entities": [{"text": "Reddit dataset", "start_pos": 48, "end_pos": 62, "type": "DATASET", "confidence": 0.936102956533432}]}, {"text": "The overall mean average precisions (MAPs) of different models on synthetic and real-world datasets are reported in.", "labels": [], "entities": [{"text": "mean average precisions (MAPs)", "start_pos": 12, "end_pos": 42, "type": "METRIC", "confidence": 0.9058111806710561}]}, {"text": "For the synthetic dataset (Addition), we report average MAP across all noise levels, and for real-world datasets (Twitter and Reddit), we report average MAP at their corresponding noise levels obtained from corresponding TREC pools.", "labels": [], "entities": [{"text": "MAP", "start_pos": 56, "end_pos": 59, "type": "METRIC", "confidence": 0.9719244241714478}, {"text": "MAP", "start_pos": 153, "end_pos": 156, "type": "METRIC", "confidence": 0.9526367783546448}]}, {"text": "We use t-test for significance testing and asterisk mark (*) to indicate significant difference at \u03c1 = 0.05 between top two competing systems.", "labels": [], "entities": [{"text": "significance", "start_pos": 18, "end_pos": 30, "type": "METRIC", "confidence": 0.9338521361351013}, {"text": "asterisk mark", "start_pos": 43, "end_pos": 56, "type": "METRIC", "confidence": 0.9583918750286102}]}, {"text": "The results show that Leitner (Lit) and Bayesian uncertainty (BU) models considerably outperform prediction probability (PP) and curriculum learning (CL) on both synthetic and real-world datasets.", "labels": [], "entities": [{"text": "Bayesian uncertainty (BU)", "start_pos": 40, "end_pos": 65, "type": "METRIC", "confidence": 0.8790984392166138}]}, {"text": "In case of real-world datasets, we didn't find significant difference between top two models perhaps because of the small size of corresponding TREC pools (198 Twitter posts and 152 Reddit posts, see).", "labels": [], "entities": []}, {"text": "Overall, BU and Lit show average MAP of 0.81, and 0.85 on the synthetic dataset and 0.15, 0.22 on real-world datasets respectively.", "labels": [], "entities": [{"text": "BU", "start_pos": 9, "end_pos": 11, "type": "METRIC", "confidence": 0.9803832173347473}, {"text": "MAP", "start_pos": 33, "end_pos": 36, "type": "METRIC", "confidence": 0.9994601607322693}]}, {"text": "The higher performance of Lit indicates that spurious instances often appear in q 0 . The lower performance of CL, however, can be attributed to its training strategy which may label spurious instances as easy instances if their loss values are smaller than the loss threshold (section 2.1).", "labels": [], "entities": []}, {"text": "The large difference between the performances of Lit and CL (two methods based on repeated scoring across training epochs) shows that the way that repetition is utilized by different methods largely affects their final performance in spotting spurious instances.", "labels": [], "entities": [{"text": "spotting spurious instances", "start_pos": 234, "end_pos": 261, "type": "TASK", "confidence": 0.8832761446634928}]}, {"text": "In addition, VI shows lower performance than BU and Lit on synthetic data, but comparable performance to BU on real-world datasets.", "labels": [], "entities": [{"text": "VI", "start_pos": 13, "end_pos": 15, "type": "METRIC", "confidence": 0.9499913454055786}, {"text": "BU", "start_pos": 45, "end_pos": 47, "type": "METRIC", "confidence": 0.9952998161315918}, {"text": "BU", "start_pos": 105, "end_pos": 107, "type": "METRIC", "confidence": 0.9788594245910645}]}, {"text": "Furthermore, the results show that the performance of all models are considerably lower on real-world datasets than the synthetic dataset.", "labels": [], "entities": []}, {"text": "This could be attributed to the more complex nature of our real-world datasets which leads to weaker generalizability of downstream learners on these datasets (see next section for discussion on training performance).", "labels": [], "entities": []}, {"text": "This can in turn inversely affect the performance of different spotters, e.g. by en-  couraging most instances to be considered as hard and thus placed in lower queues of Lit or in the hard batch of CL, or by increasing the prediction uncertainty and entropy in case of BU and VI respectively.", "labels": [], "entities": [{"text": "BU", "start_pos": 270, "end_pos": 272, "type": "METRIC", "confidence": 0.7321572303771973}]}, {"text": "In addition, as we mentioned before, we carefully setup the annotation task to minimize the chances of spurious labels in the resulting annotations.", "labels": [], "entities": []}, {"text": "Therefore, we expect a considerably smaller fraction of spurious instances in our realworld datasets.", "labels": [], "entities": []}, {"text": "Figures 4(a) and 4(d) report MAP and precision after all spurious instances have been retrieved (Rprec) on Addition at different noise levels respectively; note that \u03b1 = 0.5 means equal number of spurious and genuine instances in training data (here, we do not report the performance of CL due to its lower performance and for better presentation).", "labels": [], "entities": [{"text": "MAP", "start_pos": 29, "end_pos": 32, "type": "METRIC", "confidence": 0.9891989827156067}, {"text": "precision", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9994779229164124}, {"text": "Rprec)", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.9709029197692871}]}, {"text": "First, the results show that Lit and BU considerably outperform PP and VI.", "labels": [], "entities": [{"text": "Lit", "start_pos": 29, "end_pos": 32, "type": "METRIC", "confidence": 0.9972425699234009}, {"text": "BU", "start_pos": 37, "end_pos": 39, "type": "METRIC", "confidence": 0.9970492720603943}]}, {"text": "Furthermore, BU shows considerably high performance at lower noise levels, \u03b1 \u2264 0.2, while Lit considerably outperforms BU at greater noise levels, \u03b1 > 0.2.", "labels": [], "entities": [{"text": "BU", "start_pos": 13, "end_pos": 15, "type": "METRIC", "confidence": 0.8059003353118896}]}, {"text": "The lower performance of BU at higher noise levels might be because of the poor generalizability of LSTM in the context of greater noise which may increase the variance in the prediction probabilities of most instances (see section 3.6 for our note on training performance).", "labels": [], "entities": [{"text": "BU", "start_pos": 25, "end_pos": 27, "type": "METRIC", "confidence": 0.9243801832199097}]}, {"text": "In terms of average Rprec, the overall performance of PP, CL, VI, BU, and Lit models is 0.62, 0.57, 0.65, 0.70, and 0.74 respectively on the Addition dataset across all noise levels (see the corresponding values for MAP in).", "labels": [], "entities": [{"text": "Rprec", "start_pos": 20, "end_pos": 25, "type": "METRIC", "confidence": 0.9923704862594604}, {"text": "Addition dataset", "start_pos": 141, "end_pos": 157, "type": "DATASET", "confidence": 0.6577648371458054}]}, {"text": "The lower Rprec values than MAP indicate that some spurious instances are ranked very low by models.", "labels": [], "entities": [{"text": "Rprec", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9694300293922424}]}, {"text": "These are perhaps the most difficult spurious instances to identify.", "labels": [], "entities": []}, {"text": "For the real-world datasets, we only report MAP and P@r (precision at rank r) as spurious/genuine labels are only available for those instances that make it to the TREC pool but not for all instances.", "labels": [], "entities": [{"text": "MAP", "start_pos": 44, "end_pos": 47, "type": "METRIC", "confidence": 0.9523186087608337}, {"text": "precision", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.9240655303001404}, {"text": "TREC pool", "start_pos": 164, "end_pos": 173, "type": "DATASET", "confidence": 0.7339045703411102}]}, {"text": "els, but VI and BU show comparable MAP (in contrast to their performance on Addition).", "labels": [], "entities": [{"text": "BU", "start_pos": 16, "end_pos": 18, "type": "METRIC", "confidence": 0.9812238216400146}, {"text": "MAP", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.9992709755897522}]}, {"text": "Furthermore,(e) shows that Lit generates a more accurate ranked list of spurious instances and consistently outperforms other models at almost all ranks.", "labels": [], "entities": []}, {"text": "In particular, it maintains a MAP of around 60% at rank 20, while other models have consistently lower MAP than 50% at all ranks.", "labels": [], "entities": [{"text": "MAP", "start_pos": 30, "end_pos": 33, "type": "METRIC", "confidence": 0.9989609718322754}, {"text": "MAP", "start_pos": 103, "end_pos": 106, "type": "METRIC", "confidence": 0.9976130723953247}]}, {"text": "The results on the Twitter dataset,(c) and 4(f), show that Lit outperforms other models.", "labels": [], "entities": [{"text": "Twitter dataset", "start_pos": 19, "end_pos": 34, "type": "DATASET", "confidence": 0.9216589033603668}]}, {"text": "However, interestingly, PP outperforms BU in terms of both MAP and P@r across almost all ranks.", "labels": [], "entities": [{"text": "BU", "start_pos": 39, "end_pos": 41, "type": "METRIC", "confidence": 0.996793806552887}, {"text": "MAP", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.9616968035697937}, {"text": "P@r", "start_pos": 67, "end_pos": 70, "type": "METRIC", "confidence": 0.8138532837231954}]}, {"text": "This result could be attributed to the substantial annotation agreement on Twitter dataset (Fleiss' \u03ba = 0.66 ) which could make network predictions/loss values more representative of gold labels.(f) also shows that Lit is the most precise model in identifying spurious instances.", "labels": [], "entities": [{"text": "Twitter dataset", "start_pos": 75, "end_pos": 90, "type": "DATASET", "confidence": 0.9126056432723999}]}, {"text": "Note that P@5 is an important metric in search applications and as Figures 4(e) and 4(f) show, at rank 5, Lit is 2-3 times more precise than the bestperforming baseline on our real-world datasets.", "labels": [], "entities": [{"text": "precise", "start_pos": 128, "end_pos": 135, "type": "METRIC", "confidence": 0.959740161895752}]}, {"text": "Given any dataset and its corresponding neural network, our Leitner model simultaneously trains the network and generates a ranked list of spurious instances in the dataset.", "labels": [], "entities": []}, {"text": "For this purpose, the model tracks loss values and occurrences of instances in the lower Leitner queue during training.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Dataset Information. \"SpRatio\" shows the  fraction of spurious instances in the TREC pool; size of  the pool for Addition is 10K instances with no limit on  the top K retrieved instances; the corresponding value  for Twitter and Reddit datasets are 198 and 152 posts  respectively for top K = 50.", "labels": [], "entities": [{"text": "TREC pool", "start_pos": 90, "end_pos": 99, "type": "DATASET", "confidence": 0.7186100780963898}, {"text": "Reddit datasets", "start_pos": 239, "end_pos": 254, "type": "DATASET", "confidence": 0.8600253760814667}]}, {"text": " Table 2: Average overall MAP performance across  datasets and noise levels.", "labels": [], "entities": [{"text": "MAP", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.9545826315879822}]}]}