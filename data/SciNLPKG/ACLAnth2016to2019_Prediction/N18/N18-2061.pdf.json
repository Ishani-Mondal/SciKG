{"title": [{"text": "Syntactically Aware Neural Architectures for Definition Extraction", "labels": [], "entities": [{"text": "Definition Extraction", "start_pos": 45, "end_pos": 66, "type": "TASK", "confidence": 0.7035455852746964}]}], "abstractContent": [{"text": "Automatically identifying definitional knowledge in text corpora (Definition Extraction or DE) is an important task with direct applications in, among others, Automatic Glossary Generation, Taxonomy Learning, Question Answering and Semantic Search.", "labels": [], "entities": [{"text": "Automatically identifying definitional knowledge in text corpora", "start_pos": 0, "end_pos": 64, "type": "TASK", "confidence": 0.7735258000237601}, {"text": "Definition Extraction or DE)", "start_pos": 66, "end_pos": 94, "type": "TASK", "confidence": 0.5934812963008881}, {"text": "Automatic Glossary Generation", "start_pos": 159, "end_pos": 188, "type": "TASK", "confidence": 0.6734069287776947}, {"text": "Taxonomy Learning", "start_pos": 190, "end_pos": 207, "type": "TASK", "confidence": 0.8679161667823792}, {"text": "Question Answering", "start_pos": 209, "end_pos": 227, "type": "TASK", "confidence": 0.8919939994812012}, {"text": "Semantic Search", "start_pos": 232, "end_pos": 247, "type": "TASK", "confidence": 0.848754495382309}]}, {"text": "It is generally cast as a binary classification problem between definitional and non-definitional sentences.", "labels": [], "entities": []}, {"text": "In this paper we present a set of neural architectures combining Convolutional and Recurrent Neural Networks, which are further enriched by incorporating linguistic information via syntactic dependencies.", "labels": [], "entities": []}, {"text": "Our experimental results in the task of sentence classification , on two benchmarking DE datasets (one generic, one domain-specific), show that these models obtain consistent state of the art results.", "labels": [], "entities": [{"text": "sentence classification", "start_pos": 40, "end_pos": 63, "type": "TASK", "confidence": 0.7467963099479675}]}, {"text": "Furthermore, we demonstrate that models trained on clean Wikipedia-like definitions can successfully be applied to more noisy domain-specific corpora.", "labels": [], "entities": []}], "introductionContent": [{"text": "Dictionaries and glossaries are among the most important sources of meaning for humankind.", "labels": [], "entities": []}, {"text": "Compiling, updating and translating them has traditionally been left mostly to domain experts and professional lexicographers.", "labels": [], "entities": []}, {"text": "However, the last two decades have witnessed a growing interest in automating the construction of lexicographic resources.", "labels": [], "entities": []}, {"text": "Analogously, in Natural Language Processing (NLP), lexicographic resources have proven useful fora myriad of tasks, for example Word Sense Disambiguation (), Taxonomy Learning () or Information Extraction (.", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 128, "end_pos": 153, "type": "TASK", "confidence": 0.5614538689454397}, {"text": "Information Extraction", "start_pos": 182, "end_pos": 204, "type": "TASK", "confidence": 0.8151323199272156}]}, {"text": "Moreover, lexicographic information such as definitions constitutes the cornerstone of important language resources for NLP, such as WordNet (,,) and basically any Wikipedia-derived resource.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 133, "end_pos": 140, "type": "DATASET", "confidence": 0.9210959672927856}]}, {"text": "In this context, systems able to address the problem of Definition Extraction (DE), i.e., identifying definitional information spanning in free text, are of great value both for computational lexicography and for NLP.", "labels": [], "entities": [{"text": "Definition Extraction (DE)", "start_pos": 56, "end_pos": 82, "type": "TASK", "confidence": 0.8319199979305267}, {"text": "identifying definitional information spanning in free text", "start_pos": 90, "end_pos": 148, "type": "TASK", "confidence": 0.7231178113392421}]}, {"text": "In the early days of DE, rulebased approaches leveraged linguistic cues observed in definitional data).", "labels": [], "entities": [{"text": "DE", "start_pos": 21, "end_pos": 23, "type": "TASK", "confidence": 0.977169930934906}]}, {"text": "However, in order to deal with problems like language dependence and domain specificity, machine learning was incorporated in more recent contributions (Del, which focused on encoding informative lexico-syntactic patterns in feature vectors (, both in supervised and semi-supervised settings.", "labels": [], "entities": [{"text": "language dependence", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.7072295248508453}]}, {"text": "On the other hand, while encoding definitional information using deep learning techniques has been addressed in the past (, to the best of our knowledge no previous work has tackled the problem of DE by reconciling both the linguistic lessons learned in the past decades (e.g., the importance of lexico syntactic patterns or long-distance relations between definiendum and definiens) 1 and the processing potential of neural networks.", "labels": [], "entities": [{"text": "DE", "start_pos": 197, "end_pos": 199, "type": "TASK", "confidence": 0.942693829536438}]}, {"text": "Thus, we propose to bridge this gap by learning high level features over candidate definitions via convolutional filters, and then apply recurrent neural networks to learn long term dependencies over these feature maps.", "labels": [], "entities": []}, {"text": "Without preprocessing and only taking pretrained embeddings as input, it is already possible to consistently obtain state of the art results in two benchmarking datasets for DE (one generic, one domain-specific).", "labels": [], "entities": []}, {"text": "Further improvements over this simple model are obtained by incorporating syntactic information by composing and embedding head-modifier syntactic dependencies and dependency labels.", "labels": [], "entities": []}, {"text": "One interesting side result of our experiments is the observation that a model trained only on canonical wikipedia-like definitions performs significantly better in a domain-specific academic setting than a model that has been trained on that domain, which somewhat contradicts previously assumed notions about the creativity of academic authors when presenting and describing novel terminology.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this experiment we assess the performance of a cross-domain model on the W00 dataset (cf. Section 3.1).", "labels": [], "entities": [{"text": "W00 dataset", "start_pos": 76, "end_pos": 87, "type": "DATASET", "confidence": 0.9783609509468079}]}, {"text": "The main goal is to verify to what extent a model trained only on Wikipedia-like definitions can do well in a domain-specific setting.", "labels": [], "entities": []}, {"text": "To this end, we apply our best performing configuration trained on the whole WCL corpus to the W00 dataset (WCL>W00), and compare it with the performance of our best configuration as per 10-fold CV (C-BLSTM100 d , see).", "labels": [], "entities": [{"text": "WCL corpus", "start_pos": 77, "end_pos": 87, "type": "DATASET", "confidence": 0.735058918595314}, {"text": "W00 dataset", "start_pos": 95, "end_pos": 106, "type": "DATASET", "confidence": 0.9509045481681824}]}, {"text": "This experiment is important, for example, for learning what would be more appropriate if we were to aim at constructing domain-specific glossaries or at extracting highly specific semantic relations from a domain terminology.", "labels": [], "entities": []}, {"text": "We run our best performing model over a subset of the ACL-ARC anthology (), specifically the subcorpus described in (EspinosaAnke et al., 2016a), which removed noisy sentences as produced by the pdf to text conversion.", "labels": [], "entities": [{"text": "ACL-ARC anthology", "start_pos": 54, "end_pos": 71, "type": "DATASET", "confidence": 0.9078157842159271}]}, {"text": "In we show three high quality definitions discovered by our model, as well as three false positives.", "labels": [], "entities": []}, {"text": "We may highlight the somewhat surprising remarkable capacity of the model to identify definitions beyond the is-a pattern (e.g., using the verb 'mean') and with long-distance dependencies between subject and object.", "labels": [], "entities": []}, {"text": "As for the incorrect cases, we find that for this model to be used in the automatic glossary construction task, in addition to further refinement, it would have to be coupled with a term extraction system so that only definitions associated to meaningful domain terms are extracted.", "labels": [], "entities": [{"text": "automatic glossary construction", "start_pos": 74, "end_pos": 105, "type": "TASK", "confidence": 0.7008584141731262}, {"text": "term extraction", "start_pos": 182, "end_pos": 197, "type": "TASK", "confidence": 0.6952214986085892}]}], "tableCaptions": [{"text": " Table 1, show that a fairly simple CNN ar- chitecture with no preprocessing already achieves  remarkably strong results, especially for the WCL  dataset. Among our proposed systems, the overall  best performance in Wikipedia definitions is ob- tained by the CNN l configuration. However, in- corporating a BLSTM layer contributes towards  the best performing model on the NLP-specific", "labels": [], "entities": [{"text": "WCL  dataset", "start_pos": 141, "end_pos": 153, "type": "DATASET", "confidence": 0.8758083283901215}]}]}