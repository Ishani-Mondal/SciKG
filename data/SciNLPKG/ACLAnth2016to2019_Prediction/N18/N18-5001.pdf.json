{"title": [{"text": "NLP Lean Programming Framework: Developing NLP Applications More Effectively", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents NLP Lean Programming framework (NLPf), anew framework for creating custom natural language processing (NLP) models and pipelines by utilizing common software development build systems.", "labels": [], "entities": []}, {"text": "This approach allows developers to train and integrate domain-specific NLP pipelines into their applications seamlessly.", "labels": [], "entities": []}, {"text": "Additionally, NLPf provides an annotation tool which improves the annotation process significantly by providing a well-designed GUI and sophisticated way of using input devices.", "labels": [], "entities": []}, {"text": "Due to NLPf's properties developers and domain experts are able to build domain-specific NLP applications more efficiently.", "labels": [], "entities": []}, {"text": "NLPf is Open-source software and available at https:// gitlab.com/schrieveslaach/NLPf.", "labels": [], "entities": [{"text": "NLPf", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9648880362510681}]}], "introductionContent": [{"text": "Nowadays more and more business models rely on the processing of natural language data, e. g. companies extract relevant eCommerce data from domain-specific documents.", "labels": [], "entities": []}, {"text": "The required eCommerce data could be related to various domains, e. g. life-science, public utilities, or social media, depending on the companies' business models.", "labels": [], "entities": []}, {"text": "Furthermore, the World Wide Web (WWW) provides a huge amount of natural language data that provides a wide variety of knowledge to human readers.", "labels": [], "entities": [{"text": "World Wide Web (WWW)", "start_pos": 17, "end_pos": 37, "type": "DATASET", "confidence": 0.6730994383494059}]}, {"text": "This amount of knowledge is unmanageable for humans and applications try to make this knowledge more accessible to humans, e. g. Treude and Robillard (2016) make natural language text about software programming more accessible through a natural language processing (NLP) application.", "labels": [], "entities": []}, {"text": "All these approaches have in common that they require domain-specific NLP models that have been trained on a domain-specific and annotated corpus.", "labels": [], "entities": []}, {"text": "These models will be trained by using different NLP frameworks and these models have to be evaluated for every annotation layer.", "labels": [], "entities": []}, {"text": "For example, named entity recognition (NER) of Stanford CoreNLP () might work better than NER of OpenNLP (Reese, 2015, Chapter 1); the chosen segmentation tool, e. g. UDPipe (, might work better than Stanford CoreNLP's segmentation tool, and soon.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 13, "end_pos": 43, "type": "TASK", "confidence": 0.7137109289566675}, {"text": "Stanford CoreNLP", "start_pos": 47, "end_pos": 63, "type": "DATASET", "confidence": 0.8612538874149323}]}, {"text": "Existing studies show that domain specific training and evaluation is a common approach in the NLP community to determine the best-performing NLP pipeline (.", "labels": [], "entities": []}, {"text": "Developers of NLP applications are forced to create domain-specific corpora to determine the best-performing NLP pipeline among many NLP frameworks.", "labels": [], "entities": []}, {"text": "During this process they face various obstacles: \u2022 The training and evaluation of different NLP frameworks requires a lot of effort of scripting or programming because of incompatible APIs.", "labels": [], "entities": []}, {"text": "\u2022 Domain experts who annotate domainspecific documents with a GUI tool struggle with an insufficient user experience.", "labels": [], "entities": []}, {"text": "\u2022 There are too many combinations how developers can combine these NLP tools into NLP pipelines.", "labels": [], "entities": []}, {"text": "\u2022 The generated NLP models as a build artifact have to be integrated manually into the application code.", "labels": [], "entities": []}, {"text": "NLP Lean Programming framework (NLPf) addresses these issues.", "labels": [], "entities": [{"text": "NLP Lean Programming framework (NLPf)", "start_pos": 0, "end_pos": 37, "type": "DATASET", "confidence": 0.9118927036012922}]}, {"text": "NLPf provides a standardized project structure for domain-specific corpora (see Section 2), an improved user experience for annotators (see Section 3), a common build process to train and evaluate NLP models in conjunc-1 tion with the determination of the best-performing NLP pipeline (see Section 4), and a convenient API to integrate the best-performing NLP pipeline into the application code (see Section 5).", "labels": [], "entities": [{"text": "NLPf", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9399420619010925}]}], "datasetContent": [], "tableCaptions": []}