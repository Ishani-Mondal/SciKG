{"title": [{"text": "Hierarchical Structured Model for Fine-to-coarse Manifesto Text Analysis", "labels": [], "entities": [{"text": "Manifesto Text Analysis", "start_pos": 49, "end_pos": 72, "type": "TASK", "confidence": 0.6153389712174734}]}], "abstractContent": [{"text": "Election manifestos document the intentions, motives, and views of political parties.", "labels": [], "entities": []}, {"text": "They are often used for analysing a party's fine-grained position on a particular issue, as well as for coarse-grained positioning of a party on the left-right spectrum.", "labels": [], "entities": []}, {"text": "In this paper we propose a two-stage model for automatically performing both levels of analysis over manifestos.", "labels": [], "entities": []}, {"text": "In the first step we employ a hierarchical multi-task structured deep model to predict fine-and coarse-grained positions, and in the second step we perform post-hoc calibration of coarse-grained positions using proba-bilistic soft logic.", "labels": [], "entities": []}, {"text": "We empirically show that the proposed model outperforms state-of-art approaches at both granularities using manifestos from twelve countries, written in ten different languages.", "labels": [], "entities": []}], "introductionContent": [{"text": "The adoption of NLP methods has led to significant advances in the field of computational social science, including political science).", "labels": [], "entities": []}, {"text": "Among a myriad of data sources, election manifestos area core artifact in political analysis.", "labels": [], "entities": []}, {"text": "One of the most widely used datasets by political scientists is the Comparative Manifesto Project (CMP) dataset, which contains manifestos in various languages, covering over 1000 parties across 50 countries, from elections dating back to 1945.", "labels": [], "entities": [{"text": "Comparative Manifesto Project (CMP) dataset", "start_pos": 68, "end_pos": 111, "type": "DATASET", "confidence": 0.5125069958823067}]}, {"text": "In CMP, a subset of the manifestos has been manually annotated at the sentence-level with one of 57 political themes, divided into 7 major categories.", "labels": [], "entities": [{"text": "CMP", "start_pos": 3, "end_pos": 6, "type": "DATASET", "confidence": 0.8606973886489868}]}, {"text": "Such categories capture party positions (FAVORABLE, UNFAVORABLE or NEITHER) on fine-grained policy themes, and are also useful for downstream tasks including calculating manifesto-level (policy-based) left-right position scores ().", "labels": [], "entities": [{"text": "FAVORABLE", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9471667408943176}, {"text": "NEITHER", "start_pos": 67, "end_pos": 74, "type": "METRIC", "confidence": 0.6757715344429016}]}, {"text": "An example sentence from the Green Party of England and Wales 2015 election manifesto where they take an UNFAVOR-ABLE position on MILITARY is: We would: Ensure that ...", "labels": [], "entities": [{"text": "England and Wales 2015 election manifesto", "start_pos": 44, "end_pos": 85, "type": "DATASET", "confidence": 0.7722798188527426}, {"text": "MILITARY", "start_pos": 130, "end_pos": 138, "type": "TASK", "confidence": 0.42794203758239746}]}, {"text": "less is spent on military research.", "labels": [], "entities": []}, {"text": "Elsewhere, they take a FAVORABLE position on WELFARE STATE: Double Child Benefit.", "labels": [], "entities": [{"text": "FAVORABLE", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9963796734809875}, {"text": "WELFARE STATE: Double Child Benefit", "start_pos": 45, "end_pos": 80, "type": "DATASET", "confidence": 0.5600927819808325}]}, {"text": "Such manual annotations are labor-intensive and prone to annotation inconsistencies ( . In order to overcome these challenges, supervised sentence classification approaches have been proposed.", "labels": [], "entities": [{"text": "sentence classification", "start_pos": 138, "end_pos": 161, "type": "TASK", "confidence": 0.7194534689188004}]}, {"text": "Other than the sentence-level labels, the manifesto text also has a document-level score that quantifies its position on the left-right spectrum.", "labels": [], "entities": []}, {"text": "Different approaches have been proposed to derive this score, based on alternate definitions of \"left-right\".", "labels": [], "entities": []}, {"text": "Among these, the RILE index is the most widely adopted (, and has been shown to correlate highly with other popular scores).", "labels": [], "entities": [{"text": "RILE index", "start_pos": 17, "end_pos": 27, "type": "METRIC", "confidence": 0.9842712581157684}]}, {"text": "RILE is defined as the difference between RIGHT and LEFT positions on (pre-determined) policy themes across sentences in a manifesto (; for instance, UNFAVORABLE position on MILITARY is categorized as LEFT.", "labels": [], "entities": [{"text": "RILE", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9712719917297363}, {"text": "RIGHT", "start_pos": 42, "end_pos": 47, "type": "METRIC", "confidence": 0.9695433378219604}, {"text": "LEFT", "start_pos": 52, "end_pos": 56, "type": "METRIC", "confidence": 0.7574383616447449}]}, {"text": "RILE is popular in CMP in particular, as mapping individual sentences to LEFT/RIGHT/NEUTRAL categories has been shown to be less sensitive to systematic errors than other sentence-level class sets.", "labels": [], "entities": [{"text": "RILE", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9609257578849792}]}, {"text": "Finally, expert survey scores are gaining popularity as a means of capturing manifesto-level political positions, and are considered to be contextand time-specific, unlike RILE (.", "labels": [], "entities": [{"text": "RILE", "start_pos": 172, "end_pos": 176, "type": "METRIC", "confidence": 0.6482563018798828}]}, {"text": "We use the Chapel Hill Expert Survey (CHES) (, which comprises aggregated expert surveys on the ideological position of various political parties.", "labels": [], "entities": [{"text": "Chapel Hill Expert Survey (CHES)", "start_pos": 11, "end_pos": 43, "type": "DATASET", "confidence": 0.960019554410662}]}, {"text": "Although CHES is more subjective than RILE, the CHES scores are considered to be the gold-standard in the political science domain.", "labels": [], "entities": [{"text": "RILE", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.9630182981491089}]}, {"text": "In this work, we address both fine-and coarsegrained multilingual manifesto text policy position analysis, through joint modeling of sentence-level classification and document-level positioning (or ranking) tasks.", "labels": [], "entities": [{"text": "multilingual manifesto text policy position analysis", "start_pos": 53, "end_pos": 105, "type": "TASK", "confidence": 0.6739402562379837}, {"text": "sentence-level classification", "start_pos": 133, "end_pos": 162, "type": "TASK", "confidence": 0.701538011431694}, {"text": "document-level positioning (or ranking)", "start_pos": 167, "end_pos": 206, "type": "TASK", "confidence": 0.7812312593062719}]}, {"text": "We employ a two-level structured model, in which the first level captures the structure within a manifesto, and the second level captures context and temporal dependencies across manifestos.", "labels": [], "entities": []}, {"text": "Our contributions are as follows: \u2022 we employ a hierarchical sequential deep model that encodes the structure in manifesto text for the sentence classification task; \u2022 we capture the dependency between the sentence-and document-level tasks, and also utilize additional label structure (categorization into LEFT/RIGHT/NEUTRAL:) using a joint-structured model; \u2022 we incorporate contextual information (such as political coalitions) and encode temporal dependencies to calibrate the coarse-level manifesto position using probabilistic soft logic (, which we evaluate on the prediction of the RILE index or expert survey party position score.", "labels": [], "entities": [{"text": "sentence classification task", "start_pos": 136, "end_pos": 164, "type": "TASK", "confidence": 0.792477548122406}, {"text": "RILE index", "start_pos": 589, "end_pos": 599, "type": "METRIC", "confidence": 0.9305952489376068}]}], "datasetContent": [{"text": "As our dataset, we use manifestos from CMP for European countries only, as in Section 5.5 we will validate the manifesto's overall position on the left-right spectrum, using the Chapel Hill Expert Survey (CHES), which is only available for European countries (.", "labels": [], "entities": [{"text": "Chapel Hill Expert Survey (CHES)", "start_pos": 178, "end_pos": 210, "type": "DATASET", "confidence": 0.9576195904186794}]}, {"text": "In this, we sample 1004 manifestos from 12 European countries, written in 10 different languages -Danish (Denmark), Dutch (Netherlands), English (Ireland, United Kingdom), Finnish (Finland), French (France), German (Austria, Germany), Italian (Italy), Portuguese (Portugal), Spanish (Spain), and Swedish (Sweden).", "labels": [], "entities": []}, {"text": "Out of the 1004 manifestos, 272 are annotated with both sentence-level labels and RILE scores, and the remainder only have RILE scores (see for further statistics).", "labels": [], "entities": [{"text": "RILE scores", "start_pos": 82, "end_pos": 93, "type": "METRIC", "confidence": 0.9744988083839417}, {"text": "RILE scores", "start_pos": 123, "end_pos": 134, "type": "METRIC", "confidence": 0.9770567119121552}]}, {"text": "There are (less) scenarios where a natural sentence is segmented into sub-sentences and annotated with different classes).", "labels": [], "entities": []}, {"text": "Hence we use NLTK sentence tokenizer followed by heuristics from to obtain sub-sentences.", "labels": [], "entities": [{"text": "NLTK sentence tokenizer", "start_pos": 13, "end_pos": 36, "type": "TASK", "confidence": 0.6454775234063467}]}, {"text": "Consistent with previous work, we present results with manually segmented and annotated test documents.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Micro-Averaged F-measure for sentence classification. Best scores are given in bold.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.8035520911216736}, {"text": "sentence classification", "start_pos": 39, "end_pos": 62, "type": "TASK", "confidence": 0.8296193480491638}]}, {"text": " Table 4: RILE score prediction performance. Best  scores are given in bold.", "labels": [], "entities": [{"text": "RILE", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9865409731864929}]}, {"text": " Table 5: Micro-averaged F-measure for manifestos re- leased after 2008-09. Best scores are given in bold.", "labels": [], "entities": [{"text": "Micro-averaged", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.8788782358169556}, {"text": "F-measure", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.7743371725082397}]}, {"text": " Table 6: Manifesto regression task using the two-stage  approach. Best scores are given in bold.", "labels": [], "entities": []}]}