{"title": [{"text": "Filling Missing Paths: Modeling Co-occurrences of Word Pairs and Dependency Paths for Recognizing Lexical Semantic Relations", "labels": [], "entities": [{"text": "Recognizing Lexical Semantic Relations", "start_pos": 86, "end_pos": 124, "type": "TASK", "confidence": 0.8206072300672531}]}], "abstractContent": [{"text": "Recognizing lexical semantic relations between word pairs is an important task for many applications of natural language processing.", "labels": [], "entities": [{"text": "Recognizing lexical semantic relations between word pairs", "start_pos": 0, "end_pos": 57, "type": "TASK", "confidence": 0.9200219852583749}, {"text": "natural language processing", "start_pos": 104, "end_pos": 131, "type": "TASK", "confidence": 0.6577114562193552}]}, {"text": "One of the mainstream approaches to this task is to exploit the lexico-syntactic paths connecting two target words, which reflect the semantic relations of word pairs.", "labels": [], "entities": []}, {"text": "However, this method requires that the considered words co-occur in a sentence.", "labels": [], "entities": []}, {"text": "This requirement is hardly satisfied because of Zipf's law, which states that most content words occur very rarely.", "labels": [], "entities": []}, {"text": "In this paper, we propose novel methods with a neural model of P (path|w 1 , w 2) to solve this problem.", "labels": [], "entities": []}, {"text": "Our proposed model of P (path|w 1 , w 2) can be learned in an un-supervised manner and can generalize the co-occurrences of word pairs and dependency paths.", "labels": [], "entities": []}, {"text": "This model can be used to augment the path data of word pairs that do not co-occur in the corpus, and extract features capturing re-lational information from word pairs.", "labels": [], "entities": []}, {"text": "Our experimental results demonstrate that our methods improve on previous neural approaches based on dependency paths and successfully solve the focused problem.", "labels": [], "entities": []}], "introductionContent": [{"text": "The semantic relations between words are important for many natural language processing tasks, such as recognizing textual entailment () and question answering (.", "labels": [], "entities": [{"text": "recognizing textual entailment", "start_pos": 103, "end_pos": 133, "type": "TASK", "confidence": 0.8477709492047628}, {"text": "question answering", "start_pos": 141, "end_pos": 159, "type": "TASK", "confidence": 0.8917253613471985}]}, {"text": "Moreover, these relations have been also used as features for neural methods in machine translation and relation extraction (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.8231407105922699}, {"text": "relation extraction", "start_pos": 104, "end_pos": 123, "type": "TASK", "confidence": 0.8234858810901642}]}, {"text": "This type of information is provided by manually-created semantic taxonomies, such as WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 86, "end_pos": 93, "type": "DATASET", "confidence": 0.9714672565460205}]}, {"text": "However, these resources are expensive to expand manually and have limited domain coverage.", "labels": [], "entities": []}, {"text": "Thus, the automatic detection of lexicosemantic relations has been studied for several decades.", "labels": [], "entities": []}, {"text": "One of the most popular approaches is based on patterns that encode a specific kind of relationship) between adjacent words.", "labels": [], "entities": []}, {"text": "This type of approach is called a pathbased method.", "labels": [], "entities": []}, {"text": "Lexico-syntactic patterns between two words provide information on semantic relations.", "labels": [], "entities": []}, {"text": "For example, if we seethe pattern, \"animals such as a dog\" in a corpus, we can infer that animal is a hypernym of dog.", "labels": [], "entities": []}, {"text": "On the basis of this assumption, Hearst (1992) detected the hypernymy relation of two words from a corpus based on several handcrafted lexico-syntactic patterns, e.g., X such as Y. used as features indicative dependency paths, in which target word pairs co-occurred, and trained a classifier with data to detect hypernymy relations.", "labels": [], "entities": []}, {"text": "In recent studies,  proposed a neural path-based model that encoded dependency paths between two words into lowdimensional dense vectors with recurrent neural networks (RNN) for hypernymy detection.", "labels": [], "entities": [{"text": "hypernymy detection", "start_pos": 178, "end_pos": 197, "type": "TASK", "confidence": 0.7845091223716736}]}, {"text": "This method can prevent sparse feature space and generalize indicative dependency paths for detecting lexico-semantic relations.", "labels": [], "entities": []}, {"text": "Their model outperformed the previous state-of-the-art path-based method.", "labels": [], "entities": []}, {"text": "Moreover, they demonstrated that these dense path representations capture complementary information with word embeddings that contain individual word features.", "labels": [], "entities": []}, {"text": "This was indicated by the experimental result that showed the combination of path representations and word embeddings improved classification performance.", "labels": [], "entities": []}, {"text": "In addition,  showed that the neural path-based approach, combined with word embeddings, is effective in recognizing multiple semantic relations.", "labels": [], "entities": []}, {"text": "Although path-based methods can capture the relational information between two words, these methods can obtain clues only for word pairs that co-occur in a corpus.", "labels": [], "entities": []}, {"text": "Even with a very large corpus, it is almost impossible to observe a cooccurrence of arbitrary word pairs.", "labels": [], "entities": []}, {"text": "Thus, pathbased methods are still limited in terms of the number of word pairs that are correctly classified.", "labels": [], "entities": []}, {"text": "To address this problem, we propose a novel method with modeling P (path|w 1 , w 2 ) in a neural unsupervised manner, where w 1 and w 2 are the two target words, and path is a dependency path that can connect the joint co-occurrence of w 1 and w 2 . A neural model of P (path|w 1 , w 2 ) can generalize co-occurrences of word pairs and dependency paths, and infer plausible dependency paths which connect two words that do not co-occur in a corpus.", "labels": [], "entities": []}, {"text": "After unsupervised learning, this model can be used in two ways: \u2022 Path data augmentation through predicting dependency paths that are most likely to cooccur with a given word pair.", "labels": [], "entities": [{"text": "Path data augmentation", "start_pos": 67, "end_pos": 89, "type": "TASK", "confidence": 0.7216549317042033}]}, {"text": "\u2022 Feature extraction of word pairs, capturing the information of dependency paths as contexts where two words co-occur.", "labels": [], "entities": [{"text": "Feature extraction of word pairs", "start_pos": 2, "end_pos": 34, "type": "TASK", "confidence": 0.8523111581802368}]}, {"text": "While previous supervised path-based methods used only a small portion of a corpus, combining our models makes it possible to use an entire corpus for learning process.", "labels": [], "entities": []}, {"text": "Experimental results for four common datasets of multiple lexico-semantic relations show that our methods improve the classification performance of supervised neural path-based models.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we examine how our method improves path-based models on several datasets for recognizing lexical semantic relations.", "labels": [], "entities": [{"text": "recognizing lexical semantic relations", "start_pos": 94, "end_pos": 132, "type": "TASK", "confidence": 0.8144773691892624}]}, {"text": "In this paper, we focus on major noun relations, such as hypernymy, co-hypernymy, and meronymy.", "labels": [], "entities": []}, {"text": "We relied on the datasets used in Shwartz and Dagan (2016); K&H+N (.", "labels": [], "entities": []}, {"text": "BLESS (), EVALution (, and ROOT09 (.", "labels": [], "entities": [{"text": "BLESS", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9689424633979797}, {"text": "EVALution", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.6336491703987122}, {"text": "ROOT09", "start_pos": 27, "end_pos": 33, "type": "METRIC", "confidence": 0.9793261289596558}]}, {"text": "These datasets were constructed with knowledge resources (e.g., WordNet, Wikipedia), crowd-sourcing, or both.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 64, "end_pos": 71, "type": "DATASET", "confidence": 0.9377766251564026}]}, {"text": "We used noun pair instances of these datasets.", "labels": [], "entities": []}, {"text": "1 displays the relations in each dataset used in our experiments.", "labels": [], "entities": []}, {"text": "Note that we removed the two relations Entails and MemberOf with few instances from EVALution following . For data splitting, we used the presplitted train/val/test sets from Shwartz and Dagan (2016) after removing all but the noun pairs from each set.", "labels": [], "entities": [{"text": "data splitting", "start_pos": 110, "end_pos": 124, "type": "TASK", "confidence": 0.739265114068985}]}], "tableCaptions": [{"text": " Table 1: The relation types in each dataset.", "labels": [], "entities": []}, {"text": " Table 3: Classification performance of the neural path-based model (NPB) and that with the path data augmentation  (NPB+Aug).", "labels": [], "entities": []}, {"text": " Table 4: Classification performance of the integrated model, LexNET and LexNET h, and those with our methods,  +Aug and +Rep.", "labels": [], "entities": [{"text": "LexNET", "start_pos": 62, "end_pos": 68, "type": "DATASET", "confidence": 0.9367550611495972}, {"text": "LexNET", "start_pos": 73, "end_pos": 79, "type": "DATASET", "confidence": 0.8933762311935425}, {"text": "Rep", "start_pos": 122, "end_pos": 125, "type": "METRIC", "confidence": 0.8968791961669922}]}]}