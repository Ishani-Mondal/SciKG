{"title": [{"text": "From dictations to clinical reports using machine translation", "labels": [], "entities": [{"text": "machine translation", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.7035500705242157}]}], "abstractContent": [{"text": "A typical workflow to document clinical encounters entails dictating a summary, running speech recognition, and post-processing the resulting text into a formatted letter.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 88, "end_pos": 106, "type": "TASK", "confidence": 0.7333918362855911}]}, {"text": "Post-processing entails a host of transformations including punctuation restoration, true-casing, marking sections and headers, converting dates and numerical expressions, parsing lists, etc.", "labels": [], "entities": [{"text": "punctuation restoration", "start_pos": 60, "end_pos": 83, "type": "TASK", "confidence": 0.796807050704956}]}, {"text": "In conventional implementations, most of these tasks are accomplished by individual modules.", "labels": [], "entities": []}, {"text": "We introduce a novel holis-tic approach to post-processing that relies on machine callytranslation.", "labels": [], "entities": []}, {"text": "We show how this technique outperforms an alternative conventional system-even learning to correct speech recognition errors during post-processing-while being much simpler to maintain.", "labels": [], "entities": []}], "introductionContent": [{"text": "Medical dictation is one of the most common ways of documenting clinical encounters).", "labels": [], "entities": [{"text": "Medical dictation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6703527122735977}]}, {"text": "The dictated material needs to be transformed into a textual representation to be printed as a clinical letter or inserted into electronic medical record (EMR) systems.", "labels": [], "entities": []}, {"text": "This can be done using one of the following techniques (): 1) the speech recording is manually transcribed by a third party and returned to the physician for sign-off at a later point in time; 2) the recording is processed by a medical speech recognizer, controlled and corrected by a quality assurance team (mostly an external entity), and returned to the physician; 3) while the physician is dictating, a medical speech recognizer transforms the speech into text which is subject to immediate correction and sign-off by the physician.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the text processing that follows the application of automated speech recognition (ASR) in Techniques 2 and 3.", "labels": [], "entities": [{"text": "text processing", "start_pos": 31, "end_pos": 46, "type": "TASK", "confidence": 0.7730370759963989}, {"text": "automated speech recognition (ASR)", "start_pos": 79, "end_pos": 113, "type": "TASK", "confidence": 0.8134681880474091}]}, {"text": "The role of ASR is simply to transform spoken words into plain text, as exemplified in the excerpt of a medical dictation in: ASR output is typi case insensitive and contains only alphabetic characters, transcribed verbatim including command words, repetitions, grammatical errors, etc.", "labels": [], "entities": [{"text": "ASR", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.9744798541069031}, {"text": "ASR", "start_pos": 126, "end_pos": 129, "type": "TASK", "confidence": 0.9619086384773254}]}, {"text": "In contrast, clinical letters follow rigorous formatting standards which require a sophisticated post-processor to transform the ASR output into a full-fledged letter.", "labels": [], "entities": [{"text": "ASR", "start_pos": 129, "end_pos": 132, "type": "TASK", "confidence": 0.9056693315505981}]}, {"text": "Major responsibilities of the post-processor include: truecasing, punctuation restoration, carrying out dictated commands (e.g., 'new paragraph', 'scratch that'), converting numerical and temporal expressions, formatting acronyms and abbreviations, numbering itemized lists, separating sections and section headers, and inserting physician \"normals\" (sections of boilerplate text or templates).", "labels": [], "entities": [{"text": "punctuation restoration", "start_pos": 66, "end_pos": 89, "type": "TASK", "confidence": 0.7036333233118057}, {"text": "formatting acronyms and abbreviations", "start_pos": 210, "end_pos": 247, "type": "TASK", "confidence": 0.8148316890001297}, {"text": "separating sections and section headers", "start_pos": 275, "end_pos": 314, "type": "TASK", "confidence": 0.7764006137847901}, {"text": "inserting physician \"normals\" (sections of boilerplate text or templates)", "start_pos": 320, "end_pos": 393, "type": "TASK", "confidence": 0.8078398658679082}]}, {"text": "shows a post-processed version of the raw ASR output of.", "labels": [], "entities": [{"text": "ASR", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.9101972579956055}]}, {"text": "This example makes clear that many of the tokens of the ASR output need to be altered in order to create a properly formatted output document.", "labels": [], "entities": [{"text": "ASR", "start_pos": 56, "end_pos": 59, "type": "TASK", "confidence": 0.9294770956039429}]}, {"text": "In fact, informal experiments indicated that, on average, more than half of spoken tokens are subject to modification when preparing a clinical report from a dictation.", "labels": [], "entities": []}, {"text": "Conventional implementations of postprocessors comprise a multitude of predominantly rule-based techniques, mostly covering subsets of the operations listed above.", "labels": [], "entities": []}, {"text": "There has been a fair amount of machine learning research on punctuation restoration (PR), which does constitute a significant component of post-processing, over the last two decades).", "labels": [], "entities": [{"text": "punctuation restoration (PR)", "start_pos": 61, "end_pos": 89, "type": "TASK", "confidence": 0.8433910846710205}]}, {"text": "PR has even been addressed for medical ASR specifically, using methods such as finite state models for punctuation insertion, or identifying punctuated tokens using recurrent neural networks.", "labels": [], "entities": [{"text": "PR", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9470914006233215}, {"text": "ASR", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.9012957215309143}, {"text": "punctuation insertion", "start_pos": 103, "end_pos": 124, "type": "TASK", "confidence": 0.778533011674881}]}, {"text": "Of course, PR is only one necessary module of a post-processing system.", "labels": [], "entities": [{"text": "PR", "start_pos": 11, "end_pos": 13, "type": "TASK", "confidence": 0.9820055961608887}]}, {"text": "Typical modular approaches, especially those that are predominantly rule based, are subject to serious disadvantages in practical use.", "labels": [], "entities": []}, {"text": "For one, the task may grow in complexity overtime through the introduction of specific rules for certain hospitals or physicians.", "labels": [], "entities": []}, {"text": "Another issue is that these systems must follow an ASR stage, where unforeseen errors) may interfere destructively with postprocessing, for which rules or models are typically designed or trained for idealized transcriptions.", "labels": [], "entities": [{"text": "ASR", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.9616218209266663}]}, {"text": "In this paper, we present a holistic, data-driven approach to post-processing which makes use of recent advances in statistical machine translation, covering most of the aforementioned operations in a single shot and exhibiting accuracy superior to an existing modular system.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 116, "end_pos": 147, "type": "TASK", "confidence": 0.713719924290975}, {"text": "accuracy", "start_pos": 228, "end_pos": 236, "type": "METRIC", "confidence": 0.9992048144340515}]}, {"text": "After a brief introduction to machine translation in Section 2, we describe methods, data sets, and evaluation in Section 3 and experimental results in Section 4.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.7982634603977203}]}], "datasetContent": [{"text": "We assess performance of all models in two text domains: the MT target domain, which is the text format described in Section 3.2 in which numerals are split into individual digits, headers are surrounded by dummy tokens, and case is ignored; and the post-processor error rate (PER) domain.", "labels": [], "entities": [{"text": "MT target", "start_pos": 61, "end_pos": 70, "type": "TASK", "confidence": 0.6835371255874634}, {"text": "post-processor error rate (PER)", "start_pos": 250, "end_pos": 281, "type": "METRIC", "confidence": 0.795423890153567}]}, {"text": "The latter is used to estimate the manual effort required to correct errors in the hypothesis report.", "labels": [], "entities": []}, {"text": "PER can only be calculated from final outputs of a post-processor, and thus depends upon the integration described in Section 3.4.", "labels": [], "entities": [{"text": "PER", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9801966547966003}]}, {"text": "PER is calculated similarly to WER except that it considers punctuation, newlines, and tabs as separate tokens, and it excludes any detected preamble from consideration (keeping the preamble leads to a slight increase in PER globally).", "labels": [], "entities": [{"text": "PER", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9803161025047302}, {"text": "WER", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.4049794375896454}, {"text": "PER", "start_pos": 221, "end_pos": 224, "type": "METRIC", "confidence": 0.9923710823059082}]}, {"text": "PER is an especially harsh metric in real-world use, as it penalizes ASR errors, post-processing errors, and any other source of distance between the post-processor's output and the final letter following multiple rounds of manual review.", "labels": [], "entities": [{"text": "PER", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9898645281791687}, {"text": "ASR", "start_pos": 69, "end_pos": 72, "type": "TASK", "confidence": 0.9371989369392395}]}, {"text": "We measure PER of the MTPP against a baseline system, which was also developed internally within EMR.AI for specific use with clinical dictations.", "labels": [], "entities": [{"text": "PER", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.9984733462333679}, {"text": "MTPP", "start_pos": 22, "end_pos": 26, "type": "DATASET", "confidence": 0.6161072850227356}, {"text": "EMR.AI", "start_pos": 97, "end_pos": 103, "type": "DATASET", "confidence": 0.9089841246604919}]}, {"text": "The baseline system employs a modular pipeline, where each module is responsible fora particular transformation-for instance, one detects a metadata-heavy \"preamble\" in the dictation (; another converts spelledout numbers to numerals, dates, etc.", "labels": [], "entities": []}, {"text": "Some components of the system are rule based, while others rely on machine learning.", "labels": [], "entities": []}, {"text": "This system had been the focus of significant development previously and was in regular production use prior to the advent of the MTPP.", "labels": [], "entities": [{"text": "MTPP", "start_pos": 130, "end_pos": 134, "type": "DATASET", "confidence": 0.8619409799575806}]}], "tableCaptions": [{"text": " Table 1: Statistics of the data sets used for training,  tuning, development, and test.", "labels": [], "entities": []}, {"text": " Table 2: Evaluation of test set on different training and  tuning configurations with BLEU, WER, and CDER.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 87, "end_pos": 91, "type": "METRIC", "confidence": 0.9984135627746582}, {"text": "WER", "start_pos": 93, "end_pos": 96, "type": "METRIC", "confidence": 0.993396520614624}]}, {"text": " Table 3: Evaluation of the test set on different training  and tuning configurations in terms of PER.", "labels": [], "entities": [{"text": "PER", "start_pos": 98, "end_pos": 101, "type": "METRIC", "confidence": 0.9981219172477722}]}, {"text": " Table 4: Comparison of PER in several conditions. Re- sults are reported using ASR hypotheses as input (\"In:  hyp.\"), as in our other experiments, as well as using  manual transcriptions as input (\"In: tra.\").", "labels": [], "entities": [{"text": "PER", "start_pos": 24, "end_pos": 27, "type": "METRIC", "confidence": 0.9113231897354126}]}]}