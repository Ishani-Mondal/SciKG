{"title": [{"text": "Dialog Generation Using Multi-turn Reasoning Neural Networks", "labels": [], "entities": [{"text": "Dialog Generation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9488888084888458}, {"text": "Multi-turn Reasoning Neural Networks", "start_pos": 24, "end_pos": 60, "type": "TASK", "confidence": 0.7251218780875206}]}], "abstractContent": [{"text": "In this paper, we propose a generalizable dialog generation approach that adapts multi-turn reasoning, one recent advancement in the field of document comprehension, to generate responses (\"answers\") by taking current conversation session context as a \"document\" and current query as a \"question\".", "labels": [], "entities": [{"text": "dialog generation", "start_pos": 42, "end_pos": 59, "type": "TASK", "confidence": 0.7586467266082764}]}, {"text": "The major idea is to represent a conversation session into memories upon which attention-based memory reading mechanism can be performed multiple times, so that (1) user's query is properly extended by contextual clues and (2) optimal responses are step-by-step generated.", "labels": [], "entities": []}, {"text": "Considering that the speakers of one conversation are not limited to be one, we separate the single memory used for document comprehension into different groups for speaker-specific topic and opinion embedding.", "labels": [], "entities": []}, {"text": "Namely, we utilize the queries' memory, the responses' memory, and their unified memory, following the time sequence of the conversation session.", "labels": [], "entities": []}, {"text": "Experiments on Japanese 10-sentence (5-round) conversation modeling show impressive results on how multi-turn reasoning can produce more diverse and acceptable responses than state-of-the-art single-turn and non-reasoning base-lines.", "labels": [], "entities": []}], "introductionContent": [{"text": "Dialogue systems such as chatbots area thriving topic that is attracting increasing attentions from researchers (.", "labels": [], "entities": []}, {"text": "Recent achievements, such as deep neural networks for text generating, user profiling (), and natural language understanding, have accelerated the progresses of this field, which was historically approached by conventional rule-based and/or statistical response ranking strategies.", "labels": [], "entities": [{"text": "text generating", "start_pos": 54, "end_pos": 69, "type": "TASK", "confidence": 0.8277044296264648}, {"text": "user profiling", "start_pos": 71, "end_pos": 85, "type": "TASK", "confidence": 0.7646814584732056}, {"text": "natural language understanding", "start_pos": 94, "end_pos": 124, "type": "TASK", "confidence": 0.6528845528761545}, {"text": "statistical response ranking", "start_pos": 241, "end_pos": 269, "type": "TASK", "confidence": 0.5866651833057404}]}, {"text": "Response ranking models retrieve the most suitable response(s) from a fixed set of (question, answer) pairs given a dialogue context and current query from a user (.", "labels": [], "entities": []}, {"text": "Learning-to-rank approaches were applied to compute the similarity scores of between (query, context) and indexed candidate (question, answer) pairs to return the optimal \"answer\" to the user.", "labels": [], "entities": []}, {"text": "These ranking-based retrieval strategies have been well-applied as an important approach to dialogue systems, yet the set of scripted responses are limited and are short at generalization.", "labels": [], "entities": []}, {"text": "On the other hand, statistical machine translation (SMT) systems have been applied to dialogue systems (), taking user's query as a source language sentence and the chatbot's response as a target language sentence.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 19, "end_pos": 56, "type": "TASK", "confidence": 0.786154160896937}]}, {"text": "Labeled data for learning-to-ranking training will not be necessary anymore and all we need is the largescale (question, answer) pairs.", "labels": [], "entities": []}, {"text": "The sequence-to-sequence model proposed in) applied end-to-end training of neural networks to text generation.", "labels": [], "entities": [{"text": "text generation", "start_pos": 94, "end_pos": 109, "type": "TASK", "confidence": 0.8155348598957062}]}, {"text": "This model, further enhanced by an attention mechanism ( , was generic and allowed its application to numerous sequenceto-sequence learning tasks such as neural machine translation (NMT) (), image captioning (, speech recognition () and constituency parsing ( . The simplicity of these models makes them attractive, since \"translation\" and \"alignment\" are learned jointly on the fly.", "labels": [], "entities": [{"text": "neural machine translation (NMT)", "start_pos": 154, "end_pos": 186, "type": "TASK", "confidence": 0.8234593570232391}, {"text": "image captioning", "start_pos": 191, "end_pos": 207, "type": "TASK", "confidence": 0.7786830067634583}, {"text": "speech recognition", "start_pos": 211, "end_pos": 229, "type": "TASK", "confidence": 0.7392097264528275}, {"text": "constituency parsing", "start_pos": 237, "end_pos": 257, "type": "TASK", "confidence": 0.8651385009288788}]}, {"text": "Specially,  applied the sequence-to-sequence model to conversational modeling and achieved impressive results on various datasets.", "labels": [], "entities": [{"text": "conversational modeling", "start_pos": 54, "end_pos": 77, "type": "TASK", "confidence": 0.8414954245090485}]}, {"text": "Their model was trained to predict a response given the previous sentence (s).", "labels": [], "entities": []}, {"text": "combined local and global attentions and reported better results than retrieval based systems.", "labels": [], "entities": []}, {"text": "explored three different end-to-end approaches for the problem of predicting the response given a query attached with a single message context.", "labels": [], "entities": [{"text": "predicting the response given a query attached with a single message context", "start_pos": 66, "end_pos": 142, "type": "TASK", "confidence": 0.7196916391452154}]}, {"text": "Multi-turn conversation modeling is considered to be more difficult than machine translation, since there are many more acceptable responses fora given (context, query) input and these often rely on external knowledge and/or contextual reasoning.", "labels": [], "entities": [{"text": "Multi-turn conversation modeling", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7647305925687155}, {"text": "machine translation", "start_pos": 73, "end_pos": 92, "type": "TASK", "confidence": 0.7421471625566483}]}, {"text": "Dialogue systems trained with a maximum likelihood estimation (MLE) objective function, as most SMT utilizes, often learn to reply generic sentences as \"I don't know\" or \"sounds good\", which have a high incidence in the \"answer\" part of (question, answer) style training datasets.", "labels": [], "entities": [{"text": "SMT", "start_pos": 96, "end_pos": 99, "type": "TASK", "confidence": 0.9880263805389404}]}, {"text": "There have been various attempts at diversifying the responses () but the lack of variations in the responses remains as an essential challenge.", "labels": [], "entities": []}, {"text": "We wonder that if this stress can be relieved by modeling the prior context in a rather fine-grained way.", "labels": [], "entities": []}, {"text": "In document comprehension fields, multi-turn reasoning (also called multi-hop reasoning) has delivered impressive results by assimilating various pieces of information to produce an unified answer (.", "labels": [], "entities": [{"text": "multi-hop reasoning", "start_pos": 68, "end_pos": 87, "type": "TASK", "confidence": 0.7059773057699203}]}, {"text": "Through multi-turn reading the document's memory using attention models, current question can be extended with much richer knowledge.", "labels": [], "entities": []}, {"text": "This makes it easier to figure out the correct answer from that document.", "labels": [], "entities": []}, {"text": "Different documents need to be read different times to yield out the correct answer for the input question.", "labels": [], "entities": []}, {"text": "Specially, use a dynamic number of turns by introducing a termination gate to control the number of iterations of reading and reasoning.", "labels": [], "entities": []}, {"text": "Motivated by the reasoning network for document comprehension, we propose multi-turn reasoning neural networks that generate the proper response (or, \"answer\") by attention-based reasoning from current conversation session (\"document\") and current query (identical to \"question\" in document comprehension) from the user.", "labels": [], "entities": []}, {"text": "In particular, our networks utilize conversation context and explicitly separate speakers' interventions into sentence-level and conversation-level memories.", "labels": [], "entities": []}, {"text": "Our first model uses plain single-turn attention to integrate all the memories, and the second approach integrates multi-turn reasoning.", "labels": [], "entities": []}, {"text": "The formulation of our proposed approach is designed in a generalized way, allowing for inclusion of additional information such as external knowledge bases or emotional memories (.", "labels": [], "entities": []}, {"text": "Moreover, our approach for two-speaker scenario can be easily extended to group chatting by a further speaker-specific memory splitting.", "labels": [], "entities": []}, {"text": "We evaluate the performances of our methods by comparing three configurations trained on a Japanese twitter conversation session dataset.", "labels": [], "entities": [{"text": "Japanese twitter conversation session dataset", "start_pos": 91, "end_pos": 136, "type": "DATASET", "confidence": 0.6360148310661315}]}, {"text": "Each conversation session contains 10 sentences which are 5-round between two real-world speakers.", "labels": [], "entities": []}, {"text": "The results provide evidences that multi-turn reasoning neural networks can help improving the consistency and diversity of multi-turn conversation modeling.", "labels": [], "entities": [{"text": "consistency", "start_pos": 95, "end_pos": 106, "type": "METRIC", "confidence": 0.9650519490242004}, {"text": "multi-turn conversation modeling", "start_pos": 124, "end_pos": 156, "type": "TASK", "confidence": 0.7007460792859396}]}, {"text": "This paper is structured as follows: Section 2 gives a general description of multi-turn conversation modeling; Section 3 describes background neural language modeling, text generation, and attention mechanisms; Section 4.1 first introduces a model with multiple attention modules and then explains how the multi-turn reasoning mechanism can be further integrated into the previous models; Sections 5, 6 and 7 describe the experimental settings and results using automatic evaluation metrics, detailed human-evaluation based analysis, and conclusions, respectively.", "labels": [], "entities": [{"text": "multi-turn conversation modeling", "start_pos": 78, "end_pos": 110, "type": "TASK", "confidence": 0.6779500246047974}, {"text": "text generation", "start_pos": 169, "end_pos": 184, "type": "TASK", "confidence": 0.7250088453292847}]}], "datasetContent": [{"text": "In our experiments, we used a dataset consisting of Japanese twitter conversations.", "labels": [], "entities": []}, {"text": "Each conversation contains 10 sentences from two real-world alternating speakers.", "labels": [], "entities": []}, {"text": "Given the origin of the dataset, it is quite noisy, containing misspelled words, slang and kaomoji (multi-character sequences of facial emoticons) among meaningful words and characters.", "labels": [], "entities": []}, {"text": "Preliminary experiments by using a wordbased approach resulted in the vocabulary size being too big and with too many word breaking errors, we instead used a character-based approach.", "labels": [], "entities": []}, {"text": "shows a sample 10-sentence conversation in which original Japanese sentences were translated into English and similar spelling patterns were kept in a sense (such as boooring for boring and whyyy for why).", "labels": [], "entities": []}, {"text": "We kept the conversations in which all sentences were no more than 20 characters.", "labels": [], "entities": []}, {"text": "This filtering strategy resulted in a dataset of 254K conversations from which 100 (1K sentences) where taken out for testing and another 100 for validat-  ing and hyper-parameter tuning.", "labels": [], "entities": []}, {"text": "The training set contains 6,214 unique characters, which are used as our vocabulary with the addition of two special symbols, an UNK (out-of-vocabulary unknown word) and an EOS (end-of-sentence).", "labels": [], "entities": [{"text": "UNK", "start_pos": 129, "end_pos": 132, "type": "METRIC", "confidence": 0.8999489545822144}, {"text": "EOS", "start_pos": 173, "end_pos": 176, "type": "METRIC", "confidence": 0.9596399068832397}]}, {"text": "shows major statistics of the dataset.", "labels": [], "entities": []}, {"text": "The training minimizes negative log-likelihood (NLL) per character on the nine sentences s 2,...,10 of each conversation.", "labels": [], "entities": [{"text": "negative log-likelihood (NLL)", "start_pos": 23, "end_pos": 52, "type": "METRIC", "confidence": 0.7346695542335511}]}, {"text": "One configuration in MULTI and REASON is that, we respectively use the reference contexts (instead of former automatically generated sentences) to generate current sentence.", "labels": [], "entities": [{"text": "MULTI", "start_pos": 21, "end_pos": 26, "type": "DATASET", "confidence": 0.5952402949333191}]}, {"text": "That is, when generating s i , we use the golden contextual sentences of from s 1 to s i\u22121 . These three systems were respectively trained 3 epochs (10,000 iterations) on an AdaDelta optimizer.", "labels": [], "entities": []}, {"text": "Character embedding matrix was shared by both the encoder and the decoder parts.", "labels": [], "entities": []}, {"text": "All the hidden layers, in the encoding/decoding parts and the attention models, were of size 200 and the character embeddings were of size 100.", "labels": [], "entities": []}, {"text": "The recurrent units that we used were GRU.", "labels": [], "entities": [{"text": "GRU", "start_pos": 38, "end_pos": 41, "type": "METRIC", "confidence": 0.6713545322418213}]}, {"text": "The gradients were clipped at the maximum gradient norm of 1.", "labels": [], "entities": []}, {"text": "The reasoning module's maximum steps T max was set to be 5.", "labels": [], "entities": []}, {"text": "The data was iterated on mini-batches of less than 1,500 symbols each.", "labels": [], "entities": []}, {"text": "We initialized the recurrent weight matrices in GRUs as random orthogonal matrices.", "labels": [], "entities": []}, {"text": "Unless specially mentioned, all the elements of the 0-indexed vectors and all bias vectors were initialized to be zero.", "labels": [], "entities": []}, {"text": "Any other weight matrices were initialized by sampling from the Gaussian distribution of mean 0 and variance 0.01.", "labels": [], "entities": []}, {"text": "shows the progression of the NLLs per  character during training.", "labels": [], "entities": []}, {"text": "The validation costs begun converging in the third epoch for the three models.", "labels": [], "entities": [{"text": "validation", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.9607985019683838}]}, {"text": "The plot roughly shows lower cost for more complex models.", "labels": [], "entities": []}, {"text": "obtained better correlation with human evaluation when using BLEU-2 rather than BLEU-4.", "labels": [], "entities": [{"text": "BLEU-2", "start_pos": 61, "end_pos": 67, "type": "METRIC", "confidence": 0.9904300570487976}, {"text": "BLEU-4", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.9937378168106079}]}, {"text": "We thus report both of these scores for automatic evaluation and comparison.", "labels": [], "entities": []}, {"text": "The character-level BLEU-4 and BLEU-2 scores for the trained models are reported in.", "labels": [], "entities": [{"text": "BLEU-4", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.9835141897201538}, {"text": "BLEU-2", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9982182383537292}]}, {"text": "The REASON model achieved consistently better BLEU-2 and BLEU-4 scores in the three datasets.", "labels": [], "entities": [{"text": "REASON", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.8707320094108582}, {"text": "BLEU-2", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.9995070695877075}, {"text": "BLEU-4", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.9985610842704773}]}, {"text": "MULTI performed slightly better than SIMPLE on the validation set yet that performance is less stable than REASON.", "labels": [], "entities": [{"text": "MULTI", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.6037307977676392}, {"text": "REASON", "start_pos": 107, "end_pos": 113, "type": "METRIC", "confidence": 0.7800958752632141}]}, {"text": "also reflects that, (1) the final training costs of SIMPLE and MULTI are quite close with each other at iteration 10,000; (2) there is a big margin of between the final training cost of REASON and that of SIMPLE or MULTI; and (3) the validation costs exactly follows an order of SIMPLE > MULTI > REASON.", "labels": [], "entities": [{"text": "REASON", "start_pos": 186, "end_pos": 192, "type": "METRIC", "confidence": 0.894704282283783}]}, {"text": "illustrates an English translation of a conversation and the responses suggested by each of the described models.", "labels": [], "entities": []}, {"text": "This conversation is extracted from the test set.", "labels": [], "entities": []}, {"text": "The three responses are different from the reference response, but the one from REASON looks the most consistent with the given context.", "labels": [], "entities": [{"text": "REASON", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.5796462893486023}]}, {"text": "The response from MULTI is contradicting the context of speaker B as he/she said Not at all in a former sentence.", "labels": [], "entities": [{"text": "MULTI", "start_pos": 18, "end_pos": 23, "type": "DATASET", "confidence": 0.6461688280105591}]}], "tableCaptions": [{"text": " Table 1: Statistics of the filtered datasets.", "labels": [], "entities": []}, {"text": " Table 2: Character-level BLEU-2/4 (%) scores.", "labels": [], "entities": [{"text": "BLEU-2/4", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9387625455856323}]}, {"text": " Table 3: Human evaluation of the responses generated  by the three models.  \u2020 Percentage over the conversa- tions that had at least one response accepted.  \u2021 From  the cases where any of both compared models was ac- ceptable. > = \"better than\".", "labels": [], "entities": []}, {"text": " Table 4: N-gram diversity metrics of between (1) the  responses generated to the test set and (2) their refer- ence responses.", "labels": [], "entities": []}]}