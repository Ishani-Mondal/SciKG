{"title": [{"text": "Predicting Human Trustfulness from Facebook Language", "labels": [], "entities": [{"text": "Predicting Human Trustfulness", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8355810642242432}]}], "abstractContent": [{"text": "Trustfulness-one's general tendency to have confidence in unknown people or situations-predicts many important real-world outcomes such as mental health and likelihood to cooperate with others such as clinicians.", "labels": [], "entities": []}, {"text": "While data-driven measures of interpersonal trust have previously been introduced, here, we develop the first language-based assessment of the personality trait of trustfulness by fitting one's language to an accepted questionnaire-based trust score.", "labels": [], "entities": []}, {"text": "Further, using trustfulness as a type of case study, we explore the role of questionnaire size as well as word count in developing language-based predictive models of users' psychological traits.", "labels": [], "entities": []}, {"text": "We find that lever-aging a longer questionnaire can yield greater test set accuracy, while, for training, we find it beneficial to include users who took smaller questionnaires which offers more observations for training.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9824752807617188}]}, {"text": "Similarly, after noting a decrease in individual prediction error as word count increased, we found a word count-weighted training scheme was helpful when there were very few users in the first place.", "labels": [], "entities": []}], "introductionContent": [{"text": "Trust, in general, indicates confidence that an entity or entities will behave in an expected manner.", "labels": [], "entities": []}, {"text": "While trust has been computationally explored as a property of relationships between people, i.e. interpersonal trust (, few have considered trustfulness -a personality trait of an individual indicating their tendency, outside of any other context, to trust in people, institutions, and situations.", "labels": [], "entities": []}, {"text": "Trustfulness is tied to many real world and social outcomes.", "labels": [], "entities": []}, {"text": "For example, it predicts individual health, and how likely one is to join or to cooperate in diverse social groups, and individual mental health and well-being (.", "labels": [], "entities": []}, {"text": "The importance of trustfulness is thought to be increasing as modern societies are increasingly interacting online with unknown people.", "labels": [], "entities": []}, {"text": "This suggests it could be increasingly important in a clinical domain where has been shown to be essential in securing a strong and effective patient-client bond ().", "labels": [], "entities": []}, {"text": "Trait trustfulness also relates to selfdisclosure which in turn greatly aids the clinician in her provision of care.", "labels": [], "entities": []}, {"text": "Provider trust also likely is important to effectively treat a patient, especially in online therapeutic sessions, as it signals trustworthiness and care, but research on this topic remains sparse.", "labels": [], "entities": []}, {"text": "Unfortunately, traditional trustfulness measurement options (e.g. surveys) are expensive to scale to large populations and repeated assessment (i.e. in clinical practice) and they carry biases (.", "labels": [], "entities": []}, {"text": "Researchers are actively searching for alternative behavior-based methods of measurement.", "labels": [], "entities": []}, {"text": "Language use in social media offers a behavior from which one can measure psychological traits like trust.", "labels": [], "entities": []}, {"text": "Over the last five years, more and more researchers are turning to Facebook or Twitter language to develop psychological trait predictors, fitting user language to psychological scores from questionnaires ( . According to standard psychometric validity tests, such language-based approaches have been found to rival other accepted measures, such as questionnaires and assessments from friends (.", "labels": [], "entities": []}, {"text": "However, while language-based predictive models for many traits now exist, none have considered a model for trustfulness-a trait which some have argued is now of marked importance as modern societies are increasingly interacting online with unknown people.", "labels": [], "entities": []}, {"text": "Further, across such trait prediction work, little attention has been paid to the role of (1) questionnaire-size -how many questions are used to assess an individual's trait, and (2) word counthow many words the user has written from which the language-based predictions are made.", "labels": [], "entities": [{"text": "trait prediction", "start_pos": 21, "end_pos": 37, "type": "TASK", "confidence": 0.7567216753959656}]}, {"text": "Here, we answer the call for more behaviorbased trait measurement (, by developing languagebased (a behavior) predictive model of trustfulness fit to questionnaire scores, and we seek to draw insights into the role of word count and questionnaire size in predictive modeling.", "labels": [], "entities": [{"text": "predictive modeling", "start_pos": 255, "end_pos": 274, "type": "TASK", "confidence": 0.9076886475086212}]}, {"text": "This work makes several key contributions.", "labels": [], "entities": []}, {"text": "First, we introduce the first language-based assessment of trustfulness (henceforth \"trust\"), evaluated over out-of-sample trust questionnaires, enabling large-scale or frequently repeated trust measurement.", "labels": [], "entities": []}, {"text": "We also (2) study the number of questions in the psychological survey to which one fits our model (in other words, finding which one matters more: number of questions in questionnaires or number of users who took it?), (3) explore the relationship between users' word count and model error, and (4) introduce a weighting scheme to train on low word count users.", "labels": [], "entities": []}, {"text": "All together, we add trustfulness, an important trait for clinical care, to an increasing battery of languagebased assessments.", "labels": [], "entities": []}], "datasetContent": [{"text": "We focus on evaluating our language model by comparing the performance of our model on prediction of 10-question trust vs. 3-question trust labels.", "labels": [], "entities": []}, {"text": "We did this comparison in 3 settings: (1) train and test on 10-question trust score, (2) train and test on 3-question trust score, and (3) train on 3-question and test on 10-question trust score.", "labels": [], "entities": []}, {"text": "For the first setting, where all users answered the same number of questions, we performed a 10-fold cross-validation.", "labels": [], "entities": []}, {"text": "For the second and third settings, we consider all users with 10-question trust score as our test group and the remaining users which only had 3-question trust score but not the 10-question trust as the train group.", "labels": [], "entities": []}, {"text": "This enables us to first determine how well a model trained on 3-question trust performs in not only predicting 3-question trust itself, but also the 10-question trust, and compare the later with the model which is trained on small group of users with 10-question trust.", "labels": [], "entities": []}, {"text": "In all these three experiments, we considered 1, 000 as the threshold for word count, and used the same group of users as the test group.", "labels": [], "entities": []}, {"text": "We present result as both mean squared error and disattenuated correlation which accounts for measurement error: where r a,a = .70 the reliability of the trust questionnaire ( and r b,b = .70 the expected reliability of the trust language-based measurement based on evaluations of language-based personality assessment reliability () (every r on the right-hand side of the equation is a Pearson product-moment correlation coefficient).", "labels": [], "entities": [{"text": "mean squared error", "start_pos": 26, "end_pos": 44, "type": "METRIC", "confidence": 0.8911728461583456}, {"text": "reliability", "start_pos": 135, "end_pos": 146, "type": "METRIC", "confidence": 0.9812713265419006}]}, {"text": "As shown in table 2, our model's r dis with only limited 10-item data is 0.259, suggesting we cannot learn a very accurate model by training on such a small number of users.", "labels": [], "entities": [{"text": "r dis", "start_pos": 33, "end_pos": 38, "type": "METRIC", "confidence": 0.9074144959449768}]}, {"text": "Comparing the second and third settings, we seethe result of testing on 10-question trust score outperforms the 3-question trust score by 0.07 margin in dissattenuated Pearson rand MSE by a margin of 0.11.", "labels": [], "entities": [{"text": "Pearson rand MSE", "start_pos": 168, "end_pos": 184, "type": "DATASET", "confidence": 0.8843958775202433}]}, {"text": "To further understand why 10-question trust seems to be easier to predict, we calculate the variance for both 3-question and 10-question trust, yielding \u03c3 2 = 0.85 and \u03c3 2 = 0.72 respectively.", "labels": [], "entities": []}, {"text": "This suggests that 10-question trust has less noise than 3-question trust.", "labels": [], "entities": []}, {"text": "Due to these results, in all of the following experi-  ments we only train on 3-question trust labels and test on 10-question trust labels.", "labels": [], "entities": []}, {"text": "We next evaluate the performance of our trust model by comparing to two baseline models.", "labels": [], "entities": []}, {"text": "Because positiveness is associated with trust, we consider a baseline of sentiment scores using the NRC hashtag sentiment lexicon, an integral part of the best system participating in).", "labels": [], "entities": [{"text": "NRC hashtag sentiment lexicon", "start_pos": 100, "end_pos": 129, "type": "DATASET", "confidence": 0.9164184182882309}]}, {"text": "We also compare it to clusters of words derived from word2vec embeddings () using spectral clustering (Preot\u00b8iucPreot\u00b8iuc-Pietro et al., 2015).", "labels": [], "entities": []}, {"text": "demonstrates the predictive performance of our model in comparison to the sentiment and word2vec baselines.", "labels": [], "entities": []}, {"text": "Our best model (ngr r + ngr b + topics) had an 8% reduction in mean squared error over sentiment, and achieved a Pearson correlation coefficient of r dis = .494 which is considered a large relationship between a behavior (language use) and a psychological trait () and just below state-ofthe-art language-based assessments of other personality traits.", "labels": [], "entities": [{"text": "mean squared error", "start_pos": 63, "end_pos": 81, "type": "METRIC", "confidence": 0.8241121570269266}, {"text": "Pearson correlation coefficient", "start_pos": 113, "end_pos": 144, "type": "METRIC", "confidence": 0.9793056646982828}]}, {"text": "In the next experiment we present how the error rate changes as a function of word count per user using various combinations of features.", "labels": [], "entities": [{"text": "error rate", "start_pos": 42, "end_pos": 52, "type": "METRIC", "confidence": 0.9229338467121124}]}, {"text": "We trained 4 models using (1) relative-ngrams, (2) binary-ngrams, (3) topics, and (4) all features together.", "labels": [], "entities": []}, {"text": "We predict the 10-question trust score of our test users and plot the test users error rate with respect to their word count, which is shown in.", "labels": [], "entities": [{"text": "error rate", "start_pos": 81, "end_pos": 91, "type": "METRIC", "confidence": 0.9561687111854553}]}, {"text": "Overall, users' trust score is more predictable as they use more words flattening out after 1000 words.", "labels": [], "entities": []}, {"text": "Additionally, for users with few words, relative-ngrams and binary-ngrams are equally predictive and better than topics.", "labels": [], "entities": []}, {"text": "For users with many words, the prediction power of binaryngrams fades out, likely reflecting features being primarily ones.", "labels": [], "entities": []}, {"text": "Similarly, topic-based models perform better for talkative users, likely because more words means better topic estimation.: Effect of increasing the number of training users, who have more than 1, 000 word count, while there are 6, 590 users with less than 1, 000 word count in train set: \"Threshold-1000\" is training ridge-regression on users with at least 1, 000 words, \"threshold-200\" is training ridge-regression on users with at least 200 words, \"linear\" is training weighted ridge-regression on users with at least 200 words, and finally \"logistic\" is training weighted ridge-regression on users with at least 200 words.", "labels": [], "entities": [{"text": "topic estimation.", "start_pos": 105, "end_pos": 122, "type": "TASK", "confidence": 0.7132459431886673}, {"text": "Threshold-1000", "start_pos": 290, "end_pos": 304, "type": "METRIC", "confidence": 0.9825909733772278}]}, {"text": "Now that we know word count is correlated with prediction error, we explore a word count weighting scheme that enables us to include 6, 590 users with fewer than 1, 000 words in training.", "labels": [], "entities": []}, {"text": "Such users are included in three different ways, (1) without using any weight, (2) using linear weighting, and (3) using logistic weighting.", "labels": [], "entities": []}, {"text": "In we compare the various model training setups at different training sizes.", "labels": [], "entities": []}, {"text": "As shown, when we have just a few users with more than 1, 000 words, including more users, but with low word count, improves the performance, no matter which models we exploit.", "labels": [], "entities": []}, {"text": "However, as the number of users with more than 1, 000 word count increases, injecting low word count users hurts the performance.", "labels": [], "entities": []}, {"text": "In addition, the weighting scheme does not seem to help at all in this situation.", "labels": [], "entities": []}, {"text": "To get an idea of the type of features signalling high and low trust predictions, we ran a differential language analysis () to identify the top 50, independently, most predictive features.", "labels": [], "entities": []}, {"text": "show the word-clouds of both positively correlated and negatively correlated with 3-question trust score, limited to those passing a Benjamini-Hochberg False Discovery rate alpha of 0.01 ().", "labels": [], "entities": [{"text": "False Discovery rate alpha", "start_pos": 152, "end_pos": 178, "type": "METRIC", "confidence": 0.9207569807767868}]}, {"text": "Many of the ngrams correspond with the definition of trustfulness, such as the pro-social words in the positive predictors (e.g. 'friends' 'family', 'thanks').", "labels": [], "entities": []}, {"text": "On the other hand, many curse words can be seen among negative predictors.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of users who filled the long or  short version questionnaire based on their word counts.  Threshold-X means setting word count threshold to  X. Long version represents users who had 10-question  trust score, and short version includes users who had  3-question trust score.", "labels": [], "entities": [{"text": "Threshold-X", "start_pos": 107, "end_pos": 118, "type": "METRIC", "confidence": 0.9984475374221802}]}, {"text": " Table 2: Comparing the language model performance  on 3-question trust score vs. 10-question trust score.  Pearson r dis is dissattenuated Pearson r and MSE is  the mean squared error.", "labels": [], "entities": [{"text": "Pearson r dis", "start_pos": 108, "end_pos": 121, "type": "METRIC", "confidence": 0.9619667728741964}, {"text": "Pearson r", "start_pos": 140, "end_pos": 149, "type": "METRIC", "confidence": 0.9123191833496094}, {"text": "MSE", "start_pos": 154, "end_pos": 157, "type": "METRIC", "confidence": 0.9801687002182007}]}, {"text": " Table 3: Comparing the performance of our language  model with sentiment as baseline, using different fea- ture sets: ngr r: ngrams as relative frequencie, ngr b:  ngrams as boolean variables. Bold indicates the best  performance. Pearson r dis is dissattenuated Pearson r  and MSE is the mean squared error.", "labels": [], "entities": [{"text": "Pearson r", "start_pos": 264, "end_pos": 273, "type": "METRIC", "confidence": 0.9304267168045044}, {"text": "MSE", "start_pos": 279, "end_pos": 282, "type": "METRIC", "confidence": 0.9861234426498413}]}]}