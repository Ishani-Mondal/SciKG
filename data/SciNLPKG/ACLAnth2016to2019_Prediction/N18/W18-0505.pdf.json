{"title": [{"text": "Estimating Linguistic Complexity for Science Texts", "labels": [], "entities": [{"text": "Estimating Linguistic Complexity", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8531848192214966}]}], "abstractContent": [{"text": "Evaluation of text difficulty is important both for downstream tasks like text simplification, and for supporting educators in classrooms.", "labels": [], "entities": [{"text": "text simplification", "start_pos": 74, "end_pos": 93, "type": "TASK", "confidence": 0.7859978377819061}]}, {"text": "Existing work on automated text complexity analysis uses linear models with engineered knowledge-driven features as inputs.", "labels": [], "entities": [{"text": "automated text complexity analysis", "start_pos": 17, "end_pos": 51, "type": "TASK", "confidence": 0.7013329789042473}]}, {"text": "While this offers interpretability, these models have lower accuracy for shorter texts.", "labels": [], "entities": [{"text": "interpretability", "start_pos": 18, "end_pos": 34, "type": "TASK", "confidence": 0.971352756023407}, {"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9990823268890381}]}, {"text": "Traditional readability metrics have the additional drawback of not generalizing to informational texts such as science.", "labels": [], "entities": []}, {"text": "We propose a neural approach , training on science and other informa-tional texts, to mitigate both problems.", "labels": [], "entities": []}, {"text": "Our results show that neural methods outperform knowledge-based linear models for short texts, and have the capacity to generalize to genres not present in the training data.", "labels": [], "entities": []}], "introductionContent": [{"text": "A typical classroom presents a diverse set of students in terms of their reading comprehension skills, particularly in the case of English language learners (ELLs).", "labels": [], "entities": []}, {"text": "Supporting these students often requires educators to estimate accessibility of instructional texts.", "labels": [], "entities": []}, {"text": "To address this need, several automated systems have been developed to estimate text difficulty, including readability metrics like, the end-toend system TextEvaluator (, and linear models ().", "labels": [], "entities": []}, {"text": "These systems leverage knowledgebased features to train regression or classification models.", "labels": [], "entities": []}, {"text": "Most systems are trained on literary and generic texts, since analysis of text difficulty is usually tied to language teaching.", "labels": [], "entities": []}, {"text": "Existing approaches for automated text complexity analysis pose two issues: 1) systems using knowledge based features typically work better for longer texts, and 2) complexity estimates are less accurate for informational texts such as science ().", "labels": [], "entities": [{"text": "text complexity analysis", "start_pos": 34, "end_pos": 58, "type": "TASK", "confidence": 0.7641212145487467}]}, {"text": "In the context of science, technology and engineering (STEM) education, both problems are significant.", "labels": [], "entities": []}, {"text": "Teachers in these areas have less expertise in identifying appropriate reading material for students as opposed to language teachers, and shorter texts become important when dealing with assessment questions and identifying the most difficult parts of instructional texts to modify for supporting students who are ELLs.", "labels": [], "entities": []}, {"text": "Our work specifically looks at ways to address these two problems.", "labels": [], "entities": []}, {"text": "First, we propose recurrent neural network (RNN) architectures for estimating linguistic complexity, using text as input without feature engineering.", "labels": [], "entities": [{"text": "estimating linguistic complexity", "start_pos": 67, "end_pos": 99, "type": "TASK", "confidence": 0.8233877420425415}]}, {"text": "Second, we specifically train on science and other informational texts, using the grade level of text as a proxy for linguistic complexity and dividing grades k-12 into 6 groups.", "labels": [], "entities": []}, {"text": "We explore four different RNN architectures in order to identify aspects of text which contribute more to complexity, with a novel structure introduced to account for cross-sentence context.", "labels": [], "entities": []}, {"text": "Experimental results show that when specifically trained for informational texts, RNNs can accurately predict text difficulty for shorter science texts.", "labels": [], "entities": []}, {"text": "The models also generalize to other types of texts, but perform slightly worse than feature-based regression models on a mix of genres for texts longer than 100 words.", "labels": [], "entities": []}, {"text": "We use attention with all models, both to improve accuracy, and as a tool to visualize important elements of text contributing to linguistic complexity.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9979937076568604}]}, {"text": "The key contributions of the work include new neural network architectures for characterizing documents and experimental results demonstrating good performance for predicting reading level of short science texts.", "labels": [], "entities": [{"text": "predicting reading level of short science texts", "start_pos": 164, "end_pos": 211, "type": "TASK", "confidence": 0.6519130212920052}]}, {"text": "The rest of the paper is organized as follows: section 2 looks at existing work on automated readability analysis and introduces RNN architec-tures we build on for this work.", "labels": [], "entities": [{"text": "readability analysis", "start_pos": 93, "end_pos": 113, "type": "TASK", "confidence": 0.727071538567543}]}, {"text": "Section 3 lays out the data sources, section 4 covers proposed models, and section 5 presents results.", "labels": [], "entities": []}, {"text": "Discussion and concluding remarks follow in sections 6 and 7.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Chapter-based test data split", "labels": [], "entities": []}, {"text": " Table 2: Training data (D 1 ) with mean length of text in  words", "labels": [], "entities": []}, {"text": " Table 3: Results (Spearman Rank Correlation)", "labels": [], "entities": []}]}