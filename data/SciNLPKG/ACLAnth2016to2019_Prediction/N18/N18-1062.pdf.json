{"title": [{"text": "Querying Word Embeddings for Similarity and Relatedness", "labels": [], "entities": [{"text": "Similarity and Relatedness", "start_pos": 29, "end_pos": 55, "type": "TASK", "confidence": 0.7716375390688578}]}], "abstractContent": [{"text": "Word embeddings obtained from neural network models such as Word2Vec Skipgram have become popular representations of word meaning and have been evaluated on a variety of word similarity and relatedness norm-ing data.", "labels": [], "entities": [{"text": "Word2Vec Skipgram", "start_pos": 60, "end_pos": 77, "type": "DATASET", "confidence": 0.9590376019477844}]}, {"text": "Skipgram generates a set of word and context embeddings, the latter typically discarded after training.", "labels": [], "entities": []}, {"text": "We demonstrate the usefulness of context embeddings in predicting asymmetric association between words from a recently published dataset of production norms (Jouravlev and McRae, 2016).", "labels": [], "entities": []}, {"text": "Our findings suggest that humans respond with words closer to the cue within the context embedding space (rather than the word embedding space), when asked to generate thematically related words.", "labels": [], "entities": []}], "introductionContent": [{"text": "Modern distributional semantic models such as,b) and GloVe () have been evaluated on a variety of word similarity and relatedness datasets.", "labels": [], "entities": [{"text": "GloVe", "start_pos": 53, "end_pos": 58, "type": "METRIC", "confidence": 0.8189488649368286}]}, {"text": "A considerable amount of attention has been paid to what models and, more recently, what parameter settings and input data produce embedding representations that better reflect similarity/relatedness between words, taking human normative judgments as the gold standard (.", "labels": [], "entities": []}, {"text": "Similarity between two words is often assumed to be a direction-less measure (e.g., car and truck are similar due to feature overlap), whereas relatedness is inherently directional (e.g., broom and floor share a functional relationship).", "labels": [], "entities": []}, {"text": "In addition, it is well established inhuman behavioral data that similarity and relatedness judgments are both asymmetric.", "labels": [], "entities": []}, {"text": "For example, humans judge leopard to be much more similar to tiger than tiger is to leopard.", "labels": [], "entities": []}, {"text": "A concordant asymmetry is seen in relation tasks: in free association data, baby is a much more likely response when cued with stork than stork would be as a response when cued with baby ().", "labels": [], "entities": []}, {"text": "The distinction between similarity and relatedness, and the asymmetry of the judgments have typically been ignored in recent evaluations of popular embedding models.", "labels": [], "entities": []}, {"text": "There is ample experimental evidence in the psycholinguistic literature that similarity and relatedness are both well represented inhuman behavior (see, fora review), and are qualitatively distinct representations or processes.", "labels": [], "entities": []}, {"text": "In semantic priming paradigms, a target word is processed more efficiently when briefly preceded by a related or similar word (e.g., honey-bee or wasp-bee) relative to a neutral or unrelated prime (e.g., chair-bee).", "labels": [], "entities": []}, {"text": "Facilitation is seen for word pairs that are purely category coordinates (lawyersurgeon) or purely associates (scalpel-surgeon), and pairs that share both types of relations (nursesurgeon) tend to see an additive processing benefit that reflects the privilege of both similarity and relatedness, an effect generally referred to as the \"associative boost\" ().", "labels": [], "entities": []}, {"text": "Asymmetries are the norm in semantic priming data, leading to the early theoretical prominence of spreading activation models to account for human data.", "labels": [], "entities": []}, {"text": "Free association data provide complimentary evidence of the qualitative distinction between relatedness and similarity inhuman memory.", "labels": [], "entities": []}, {"text": "Ina free association task, participants are provided with a cue word and are asked to rapidly respond with a word that comes to mind first.", "labels": [], "entities": []}, {"text": "Huge norms of human responses have been collected over the years; for example, () early norms contain three-quarters of a million responses to over 5,000 cue words across 6,000 par-ticipants.", "labels": [], "entities": []}, {"text": "More recently, have more than doubled the size of Nelsons norms in multiple languages by gamifying the task 1 . The majority of responses in free association data are based on thematic relatedness rather than similarity per se.", "labels": [], "entities": []}, {"text": "As with semantic priming, free association norms are dominated by asymmetric relations: While stork has a very high probability of eliciting baby as a response across participants, cuing with baby brings so many competitors to mind that it is extremely unlikely to respond with stork.", "labels": [], "entities": []}, {"text": "The difficulty of accounting for similarity and relatedness with a single vector representation for each word has led to the suggestion that distinct representations, and perhaps even distinct learning models, are needed for optimal performance on these distinct tasks (.", "labels": [], "entities": []}, {"text": "It maybe unrealistic to expect a single vector representation to account for qualitatively distinct similarity and relatedness data.", "labels": [], "entities": []}, {"text": "Further, asymmetries inhuman similarity and relatedness tasks have been used as strong evidence against spatial models of semantics such as word embedding models, and in favor of Bayesian models (; but see ( ).", "labels": [], "entities": []}, {"text": "The cosine between two word vectors is inherently symmetric: leopard-tiger has the same cosine as tiger-leopard.", "labels": [], "entities": []}, {"text": "In order to understand how distributional representation of words reflect similarity and relatedness one should study the algorithms.", "labels": [], "entities": []}, {"text": "Each cell of a word vector in a count model indicates the firstorder association between the target word and a context word, document, or topic.", "labels": [], "entities": []}, {"text": "Dimensionality reduction algorithms are applied to obtain denser representations that can demonstrate second-order relatedness/similarity between words (e.g. applying SVD to PMI matrix).", "labels": [], "entities": [{"text": "Dimensionality reduction", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.807798445224762}]}, {"text": "Relative to these classic models, predictive distributional models such as Word2Vec are generally more complicated.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 75, "end_pos": 83, "type": "DATASET", "confidence": 0.972615122795105}]}, {"text": "Decomposition and interpretation of the neural word embeddings is less straightforward because the final vectors incrementally converge from a predict-and-update process based on a local objective function rather than by global counting or a batch abstraction process.", "labels": [], "entities": []}, {"text": "Most evaluative studies of predictive distributional semantics have viewed these models as a black box, considering only at the output vectors.", "labels": [], "entities": [{"text": "predictive distributional semantics", "start_pos": 27, "end_pos": 62, "type": "TASK", "confidence": 0.8562912940979004}]}, {"text": "For example, the Word2Vec Skipgram architecture has easily taken 1 https://smallworldofwords.org the lead and become representative of the predictive distributional semantic models, but little attention has been paid to what statistical information is best represented in the two resulting embedding sets.", "labels": [], "entities": [{"text": "Word2Vec Skipgram", "start_pos": 17, "end_pos": 34, "type": "DATASET", "confidence": 0.9244973957538605}]}, {"text": "The Skipgram is a feed-forward network with localist input and output layers, and one hidden layer which determines the dimensionality of the final vectors.", "labels": [], "entities": [{"text": "Skipgram", "start_pos": 4, "end_pos": 12, "type": "DATASET", "confidence": 0.9384817481040955}]}, {"text": "It is trained on word-context pairs with an objective function trying to minimize the error of predicting context words within a specific window around the center word.", "labels": [], "entities": []}, {"text": "At the end of training, two matrices are produced, one representing word embeddings and the other representing context embeddings for each and every vocabulary word.", "labels": [], "entities": []}, {"text": "While word embeddings have been used as the output of Skipgram in many previous studies, little attention has been paid to the context embeddings and the usefulness of these vectors in performing lexical semantic tasks (.", "labels": [], "entities": []}, {"text": "Recently, used an artificial language to evaluate how hyperparameter settings affected the Skipgrams representation of first-vs. second-order statistical sources.", "labels": [], "entities": []}, {"text": "In natural languages, paradigmatic and syntagmatic information sources are non-independent, confounding similarity and relatedness judgments.", "labels": [], "entities": []}, {"text": "Words that are more similar tend to also share functional, script, or thematic relations); e.g., surgeon-nurse.", "labels": [], "entities": []}, {"text": "Asr and Jones artificial language was engineered to disentangle the two sources of statistical information.", "labels": [], "entities": []}, {"text": "Following on suggestions by, Asr and Jones found that averaging context vectors with the word vectors (w+c post-processing) produced optimal organization of the semantic space for both paradigmatic and syntagmatic structure.", "labels": [], "entities": []}, {"text": "The goal of the current work is to more systematically explore the integration of word and context vectors in similarity and relatedness data; our two core objectives are: 1.", "labels": [], "entities": []}, {"text": "To evaluate the Skipgram model on thematic relatedness production norms, which implicitly manifests asymmetric relations between words compared to the typical evaluation on direction-less similarity/relatedness.", "labels": [], "entities": []}, {"text": "2. To explore novel ways of computing relatedness scores by contributing both word and context embeddings produced by Word2Vecs Skipgram architecture.", "labels": [], "entities": [{"text": "Word2Vecs Skipgram architecture", "start_pos": 118, "end_pos": 149, "type": "DATASET", "confidence": 0.9086819688479105}]}], "datasetContent": [{"text": "SimLex and ProNorm provide complementary scores on similarity and relatedness between words.", "labels": [], "entities": []}, {"text": "In order to demonstrate and examine how word embeddings should be used in asymmetric relatedness measurement, we designed two experiments.", "labels": [], "entities": [{"text": "asymmetric relatedness measurement", "start_pos": 74, "end_pos": 108, "type": "TASK", "confidence": 0.6305918594201406}]}, {"text": "In both experiments word and context embeddings were obtained from Skipgram models trained on a tokenized English Wikipedia dump . We slightly modified the original Word2Vec Skipgram implementation by to save both word and context vectors.", "labels": [], "entities": [{"text": "Word2Vec Skipgram", "start_pos": 165, "end_pos": 182, "type": "DATASET", "confidence": 0.930499941110611}]}, {"text": "We tested vector spaces with varying dimensionalities (dim=100/200/300) and number of context words (win=3/6/10), as well as minimum occurrence cutoff (min=1/5), negative samples (neg=1/5) and iterations (iter=1/5).", "labels": [], "entities": []}, {"text": "These variations were tested to ensure the observed patterns reported in the experiments, but we report numerical results only for best performing models.", "labels": [], "entities": []}, {"text": "In particular, higher dimensional vectors with dim=300 produced consistently better alignment with human scoring data.", "labels": [], "entities": []}, {"text": "We also found min=1, neg=5 and iter=5 to be the optimal parameter settings across all experiments.", "labels": [], "entities": [{"text": "iter", "start_pos": 31, "end_pos": 35, "type": "METRIC", "confidence": 0.9752041101455688}]}, {"text": "Our first experiment follows an established evaluation strategy by computing the Spearman correlation coefficient between the set of similarity measures produced by the word embedding model (WW/CC/WC/CW/AA) and the similarity/relatedness scores taken from the SimLex and ProNorm datasets.", "labels": [], "entities": [{"text": "Spearman correlation coefficient", "start_pos": 81, "end_pos": 113, "type": "METRIC", "confidence": 0.6313425203164419}, {"text": "ProNorm datasets", "start_pos": 271, "end_pos": 287, "type": "DATASET", "confidence": 0.9196835160255432}]}, {"text": "As ProNorm score of a word pair (w 1 , w 2 ), we simply use the total number of times a response word w 2 was produced by all subjects given w 1 as a cue word.", "labels": [], "entities": []}, {"text": "Interested readers are encouraged to see for more details on the data collection procedure.", "labels": [], "entities": [{"text": "data collection", "start_pos": 65, "end_pos": 80, "type": "TASK", "confidence": 0.6486333906650543}]}, {"text": "Our hypothesis is that for taxonomic similarity judgment the classic WW measure, i.e., the cosine of the word vectors of w 1 and w 2 would perform best, especially given the fact that in collection of similarity norms the direction between two words was not a factor.", "labels": [], "entities": [{"text": "taxonomic similarity judgment", "start_pos": 27, "end_pos": 56, "type": "TASK", "confidence": 0.8391421039899191}]}, {"text": "For explicit relatedness judgment, on the other hand, we expect one of the asymmetric measures to be the best predictor.", "labels": [], "entities": [{"text": "relatedness judgment", "start_pos": 13, "end_pos": 33, "type": "TASK", "confidence": 0.7504643797874451}]}, {"text": "WC, which is the cosine between the word embedding of the cue w 1 and the context embedding of the response w 2 tells us how likely we would see w 2 and similar words in the context of w 1 . CW reflects the opposite way relatedness, meaning how likely it is to see w 1 and similar words in the context of w 2 . Note that these two quantities are different both mathematically and conceptually, because they are obtained from generalization over word occurrences in many different contexts.", "labels": [], "entities": []}, {"text": "We hypothesize that WC should be the best predictor for the ProNorm score of (w 1 , w 2 ) given that production in the constrained setup of the ProNorm experiment was guided by thematic relatedness, making it more like a non-syntactic language modeling task: guessing which other words/concepts might appear within the context of the current word.", "labels": [], "entities": [{"text": "guessing which other words/concepts might appear within the context of the current word", "start_pos": 259, "end_pos": 346, "type": "TASK", "confidence": 0.6884733120600383}]}, {"text": "SimLex and ProNorm collections have almost the same number of word pairs.", "labels": [], "entities": []}, {"text": "However, it is important to note that ordering ProNorm word pairs based on their relatedness scores is probably more difficult than ordering the SimLex list of word pairs.", "labels": [], "entities": []}, {"text": "This is because in the ProNorm data collection setup, all word pairs were basically generated based on relatedness, whereas in SimLex, experimental items were pre-designed in away they covered a wide range of closely similar to totally different word pairs.", "labels": [], "entities": [{"text": "ProNorm data collection", "start_pos": 23, "end_pos": 46, "type": "DATASET", "confidence": 0.9133239984512329}]}, {"text": "Ordering SimLex should in turn be harder than ordering words in the old WordSim353 similar and related word pair collections, because each of the latter subsets has a much smaller number of items compared to SimLex collection.", "labels": [], "entities": [{"text": "WordSim353", "start_pos": 72, "end_pos": 82, "type": "DATASET", "confidence": 0.9321652054786682}]}, {"text": "In order to demonstrate the difference between the tasks of ordering words based on similarity vs. relatedness in an explicit setup (SimLex and ProNorm) with an implicit, i.e., a mixed setup we include WordSim353 () in our experiment.", "labels": [], "entities": [{"text": "WordSim353", "start_pos": 202, "end_pos": 212, "type": "DATASET", "confidence": 0.9308837652206421}]}, {"text": "We hypothesize that the patterns of superiority of one vector-based measure to another in ranking word pairs based on their similarity and relatedness should come out even if people were not explicitly instructed to pay attention to a specific aspect.", "labels": [], "entities": []}, {"text": "significant at p < 0.001).", "labels": [], "entities": []}, {"text": "Results on models with dim=300 and win=3/6/10 are reported (see Appendix for supplementary results).", "labels": [], "entities": [{"text": "win", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.9924649000167847}, {"text": "Appendix", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9823847413063049}]}, {"text": "The WW measure exhibits consistently a better alignment with the human rating data compared to the all other measure.", "labels": [], "entities": [{"text": "WW measure", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.7421164512634277}]}, {"text": "This suggests that second-order cooccurrence information plays the main role in similarity between two words.", "labels": [], "entities": []}, {"text": "In collection of SimLex, subjects were asked explicitly not to rate similarity based on thematic relatedness.", "labels": [], "entities": []}, {"text": "It is likely that the human ratings were affected not only by co-occurrence information encoded in word embeddings but also in context embeddings.", "labels": [], "entities": []}, {"text": "As we expected, the best predictors of this data are the symmetric similarity measures, and in particular, WW.", "labels": [], "entities": [{"text": "WW", "start_pos": 107, "end_pos": 109, "type": "METRIC", "confidence": 0.9108031392097473}]}, {"text": "The last row of the table includes Spearman correlation between human similarity judgment and a linear regression model using all Skipgram measures as predictors.", "labels": [], "entities": [{"text": "human similarity judgment", "start_pos": 64, "end_pos": 89, "type": "TASK", "confidence": 0.6022317210833231}]}, {"text": "Thus, numbers in this row show an upper bound for Spearman scores of the individual measures (obtained from an optimal weighting of all individual measures).", "labels": [], "entities": [{"text": "Spearman scores", "start_pos": 50, "end_pos": 65, "type": "METRIC", "confidence": 0.8209399580955505}]}, {"text": "shows the Spearman correlation between ProNorm scores and the Skipgram measures (all significant at p < 0.001).", "labels": [], "entities": [{"text": "Skipgram", "start_pos": 62, "end_pos": 70, "type": "DATASET", "confidence": 0.899392306804657}]}, {"text": "As we hypothesized, WC stands out as the best predictor, suggesting that human responses to a cue word (when asked to name related words) are more likely to be found in the vicinity of the cue word within the context embedding space rather than within the word embedding space.", "labels": [], "entities": []}, {"text": "The correlation between the ProNorm scores with WC is larger than with WW or AA scores.", "labels": [], "entities": [{"text": "AA", "start_pos": 77, "end_pos": 79, "type": "METRIC", "confidence": 0.9860826134681702}]}, {"text": "This indicates the importance of the knowledge encoded in the context embeddings, but specifically the prediction power of the asymmetric similarity measure compared to the symmetric ones.", "labels": [], "entities": []}, {"text": "Interestingly, CW is not as good as WC in this task.", "labels": [], "entities": []}, {"text": "This reveals the importance of the direction in associative relatedness between words such as baby and stork, which seems to correlate with their vector representations.", "labels": [], "entities": []}, {"text": "Finally, the regression model, which applies an optimal weighing on different Skipgram measures finds the best fit, whereas AA which gives equal weights to symmetric and asymmetric measures fails to compete with WC alone.", "labels": [], "entities": [{"text": "AA", "start_pos": 124, "end_pos": 126, "type": "METRIC", "confidence": 0.9976012110710144}]}, {"text": "Comparisons between suggest that, similarity and relatedness are best approximated by symmetric and asymmetric measures, respectively.", "labels": [], "entities": [{"text": "similarity", "start_pos": 34, "end_pos": 44, "type": "METRIC", "confidence": 0.9700824022293091}]}, {"text": "Our first experiment focused on discovering the best vector-based predictor for similarity and relatedness between two words.", "labels": [], "entities": []}, {"text": "We found that considering context vectors in calculation of the similarity score produces a superior predictor, specially for relatedness, compared to the traditionally used measure (WW) based only on word vectors.", "labels": [], "entities": [{"text": "predictor", "start_pos": 101, "end_pos": 110, "type": "METRIC", "confidence": 0.963021993637085}]}, {"text": "The experiment in this section is a more tangible evaluation of the Word2Vec model in a relatedness task when a cue word is given.", "labels": [], "entities": []}, {"text": "The aim is to simulate the production experiment with which the ProNorm data were collected and to evaluate whether using the WC measure will give us more true responses than WW.", "labels": [], "entities": [{"text": "ProNorm data", "start_pos": 64, "end_pos": 76, "type": "DATASET", "confidence": 0.9719009697437286}]}, {"text": "For the purpose of this experiment, we use the Skipgram model with dim=300 and win=10 as these settings produced the best overall performance in the quantitative experiment on ProNorm data.", "labels": [], "entities": [{"text": "ProNorm data", "start_pos": 176, "end_pos": 188, "type": "DATASET", "confidence": 0.973778486251831}]}, {"text": "The simulation procedure is as follows: For each cue word w 1 in the ProNorm dataset, each model generates then most similar words in the vocabulary and we count how many of the human responses were contained in each set.", "labels": [], "entities": [{"text": "ProNorm dataset", "start_pos": 69, "end_pos": 84, "type": "DATASET", "confidence": 0.975500762462616}]}, {"text": "The first model looks up nearest neighbors of w 1 within the word space (thus using WW as the proximity measure) and the second model searches for the nearest neighbors of w 1 within the Context space (thus using WC as the proximity measure).", "labels": [], "entities": []}, {"text": "Variable n indicates the total number of guesses a model is allowed to make when responding to a given cue word.", "labels": [], "entities": []}, {"text": "In other words, n is the size of the subspace explored around the cue word within each distributional semantic space.", "labels": [], "entities": []}, {"text": "Since our previous experiment showed a higher correlation between WC and the relatedness norms, we expect that neighboring words within the context embedding space (in the vicinity of the cues word embedding) should be more populated with related words (i.e., human responses) compared to neighboring words within the word embedding space.", "labels": [], "entities": []}, {"text": "Regarding the above procedure, we first extract the word embedding of the cue w 1 and then consider all human responses for that cue, i.e. w 2 of all existing pairs (w 1 , w 2 ) in the dataset, within both the word and context embedding spaces.", "labels": [], "entities": []}, {"text": "If, as results of the previous experiment suggest, WC is a better measure of forward relatedness, then a larger portion of human responses should be found in neighboring words within the context space than within the word space surrounding the cue word.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Spearman correlation between human simi- larity judgments (SimLex) and Skipgram measures.", "labels": [], "entities": []}, {"text": " Table 2: Spearman correlation between forward relat- edness scores (ProNorm) and Skipgram measures.", "labels": [], "entities": [{"text": "forward relat- edness scores (ProNorm)", "start_pos": 39, "end_pos": 77, "type": "METRIC", "confidence": 0.8149741515517235}]}, {"text": " Table 3: Spearman correlation between scores from  WordSim353 subsets and Skipgram measures.", "labels": [], "entities": [{"text": "Spearman correlation", "start_pos": 10, "end_pos": 30, "type": "METRIC", "confidence": 0.8174455761909485}, {"text": "WordSim353 subsets", "start_pos": 52, "end_pos": 70, "type": "DATASET", "confidence": 0.906792014837265}]}, {"text": " Table 5: Spearman correlation between similarity  scores (SimLex) and Skipgram measures.", "labels": [], "entities": [{"text": "Spearman correlation between similarity  scores", "start_pos": 10, "end_pos": 57, "type": "METRIC", "confidence": 0.6581759750843048}]}, {"text": " Table 6: Spearman correlation between similarity  scores (ProNorm) and Skipgram measures.", "labels": [], "entities": [{"text": "Spearman correlation between similarity  scores (ProNorm)", "start_pos": 10, "end_pos": 67, "type": "METRIC", "confidence": 0.7075299620628357}]}, {"text": " Table 7: Spearman correlation between similarity  scores (SimLex) and GloVe measures.", "labels": [], "entities": [{"text": "similarity  scores", "start_pos": 39, "end_pos": 57, "type": "METRIC", "confidence": 0.863643079996109}, {"text": "GloVe", "start_pos": 71, "end_pos": 76, "type": "METRIC", "confidence": 0.987033486366272}]}]}