{"title": [{"text": "Simultaneously Self-Attending to All Mentions for Full-Abstract Biological Relation Extraction", "labels": [], "entities": [{"text": "Full-Abstract Biological Relation Extraction", "start_pos": 50, "end_pos": 94, "type": "TASK", "confidence": 0.7090767621994019}]}], "abstractContent": [{"text": "Most work in relation extraction forms a prediction by looking at a short span of text within a single sentence containing a single entity pair mention.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.9326933026313782}]}, {"text": "This approach often does not consider interactions across mentions, requires redundant computation for each mention pair, and ignores relationships expressed across sentence boundaries.", "labels": [], "entities": []}, {"text": "These problems are exacerbated by the document-(rather than sentence-) level annotation common in biological text.", "labels": [], "entities": []}, {"text": "In response, we propose a model which simultaneously predicts relationships between all mention pairs in a document.", "labels": [], "entities": []}, {"text": "We form pair-wise predictions over entire paper abstracts using an efficient self-attention encoder.", "labels": [], "entities": []}, {"text": "All-pairs mention scores allow us to perform multi-instance learning by aggregating over mentions to form entity pair representations.", "labels": [], "entities": []}, {"text": "We further adapt to settings without mention-level annotation by jointly training to predict named entities and adding a corpus of weakly labeled data.", "labels": [], "entities": []}, {"text": "In experiments on two Biocreative benchmark datasets, we achieve state of the art performance on the Biocreative V Chemical Disease Relation dataset for models without external KB resources.", "labels": [], "entities": [{"text": "Biocreative benchmark datasets", "start_pos": 22, "end_pos": 52, "type": "DATASET", "confidence": 0.7509619494279226}, {"text": "Biocreative V Chemical Disease Relation dataset", "start_pos": 101, "end_pos": 148, "type": "DATASET", "confidence": 0.7097229063510895}]}, {"text": "We also introduce anew dataset an order of magnitude larger than existing human-annotated biological information extraction datasets and more accurate than distantly supervised alternatives.", "labels": [], "entities": []}], "introductionContent": [{"text": "With few exceptions (, nearly all work in relation extraction focuses on classifying a short span of text within a single sentence containing a single entity pair mention.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.9309927523136139}]}, {"text": "However, relationships between entities are often expressed across sentence boundaries or otherwise require a larger context to disambiguate.", "labels": [], "entities": []}, {"text": "For example, 30% of relations in the Biocreative V CDR dataset ( \u00a73.1) are expressed across sentence boundaries, such as in the following excerpt expressing a relationship between the chemical azathioprine and the disease fibrosis: Treatment of psoriasis with azathioprine.", "labels": [], "entities": [{"text": "Biocreative V CDR dataset", "start_pos": 37, "end_pos": 62, "type": "DATASET", "confidence": 0.8491076976060867}]}, {"text": "Azathioprine treatment benefited 19 (66%) out of 29 patients suffering from severe psoriasis.", "labels": [], "entities": []}, {"text": "Haematological complications were not troublesome and results of biochemical liver function tests remained normal.", "labels": [], "entities": []}, {"text": "Minimal cholestasis was seen in two cases and portal fibrosis of a reversible degree in eight.", "labels": [], "entities": []}, {"text": "Liver biopsies should be undertaken at regular intervals if azathioprine therapy is continued so that structural liver damage maybe detected at an early and reversible stage.", "labels": [], "entities": []}, {"text": "Though the entities' mentions never occur in the same sentence, the above example expresses that the chemical entity azathioprine can cause the side effect fibrosis.", "labels": [], "entities": []}, {"text": "Relation extraction models which consider only within-sentence relation pairs cannot extract this fact without knowledge of the complicated coreference relationship between eight and azathioprine treatment, which, without features from a complicated pre-processing pipeline, cannot be learned by a model which considers entity pairs in isolation.", "labels": [], "entities": [{"text": "Relation extraction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8099358379840851}]}, {"text": "Making separate predictions for each mention pair also obstructs multi-instance learning (), a technique which aggregates entity representations from mentions in order to improve robustness to noise in the data.", "labels": [], "entities": []}, {"text": "Like the majority of relation extraction data, most annotation for biological relations is distantly supervised, and so we could benefit from a model which is amenable to multi-instance learning.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.7832887172698975}]}, {"text": "In addition to this loss of cross-sentence and cross-mention reasoning capability, traditional mention pair relation extraction models typically introduce computational inefficiencies by independently extracting features for and scoring every pair of mentions, even when those mentions occur in the same sentence and thus could share representations.", "labels": [], "entities": [{"text": "mention pair relation extraction", "start_pos": 95, "end_pos": 127, "type": "TASK", "confidence": 0.6746779754757881}]}, {"text": "In the CDR training set, this requires separately encoding and classifying each of the 5,318 candidate mention pairs independently, versus encoding each of the 500 abstracts once.", "labels": [], "entities": [{"text": "CDR training set", "start_pos": 7, "end_pos": 23, "type": "DATASET", "confidence": 0.8869296908378601}]}, {"text": "Though abstracts are longer than e.g. the text between mentions, many sentences contain multiple mentions, leading to redundant computation.", "labels": [], "entities": []}, {"text": "However, encoding long sequences in away which effectively incorporates long-distance context can be prohibitively expensive.", "labels": [], "entities": []}, {"text": "Long Short Term Memory (LSTM) networks) are among the most popular token encoders due to their capacity to learn high-quality representations of text, but their ability to leverage the fastest computing hardware is thwarted due to their computational dependence on the length of the sequence -each token's representation requires as input the representation of the previous token, limiting the extent to which computation can be parallelized.", "labels": [], "entities": []}, {"text": "Convolutional neural networks (CNNs), in contrast, can be executed entirely in parallel across the sequence, but the amount of context incorporated into a single token's representation is limited by the depth of the network, and very deep networks can be difficult to learn).", "labels": [], "entities": []}, {"text": "These problems are exacerbated by longer sequences, limiting the extent to which previous work explored full-abstract relation extraction.", "labels": [], "entities": [{"text": "full-abstract relation extraction", "start_pos": 104, "end_pos": 137, "type": "TASK", "confidence": 0.6306374172369639}]}, {"text": "To facilitate efficient full-abstract relation extraction from biological text, we propose Bi-affine Relation Attention Networks (BRANs), a combination of network architecture, multi-instance and multi-task learning designed to extract relations between entities in biological text without requiring explicit mention-level annotation.", "labels": [], "entities": [{"text": "relation extraction from biological text", "start_pos": 38, "end_pos": 78, "type": "TASK", "confidence": 0.8549532413482666}]}, {"text": "We synthesize convolutions and self-attention, a modification of the Transformer encoder introduced by, over sub-word tokens to efficiently incorporate into token representations rich context between distant mention pairs across the entire abstract.", "labels": [], "entities": []}, {"text": "We score all pairs of mentions in parallel using a bi-affine operator, and aggregate over mention pairs using a soft approximation of the max function in order to perform multi-instance learning.", "labels": [], "entities": []}, {"text": "We jointly train the model to predict relations and entities, further improving robustness to noise and lack of gold annotation at the mention level.", "labels": [], "entities": []}, {"text": "In extensive experiments on two benchmark biological relation extraction datasets, we achieve state of the art performance fora model using no external knowledge base resources in experiments on the Biocreative V CDR dataset, and outperform comparable baselines on the Biocreative VI ChemProt dataset.", "labels": [], "entities": [{"text": "biological relation extraction", "start_pos": 42, "end_pos": 72, "type": "TASK", "confidence": 0.6733043789863586}, {"text": "Biocreative V CDR dataset", "start_pos": 199, "end_pos": 224, "type": "DATASET", "confidence": 0.7925567477941513}, {"text": "Biocreative VI ChemProt dataset", "start_pos": 269, "end_pos": 300, "type": "DATASET", "confidence": 0.8017893135547638}]}, {"text": "We also introduce anew dataset which is an order of magnitude larger than existing goldannotated biological relation extraction datasets while covering a wider range of entity and relation types and with higher accuracy than distantly supervised datasets of the same size.", "labels": [], "entities": [{"text": "goldannotated biological relation extraction", "start_pos": 83, "end_pos": 127, "type": "TASK", "confidence": 0.6258237361907959}, {"text": "accuracy", "start_pos": 211, "end_pos": 219, "type": "METRIC", "confidence": 0.9971101880073547}]}, {"text": "We provide a strong baseline on this new dataset, and encourage its use as a benchmark for future biological relation extraction systems.", "labels": [], "entities": [{"text": "biological relation extraction", "start_pos": 98, "end_pos": 128, "type": "TASK", "confidence": 0.6125943660736084}]}], "datasetContent": [{"text": "The Biocreative V chemical disease relation extraction (CDR) dataset 4 () was derived from the Comparative Toxicogenomics Database (CTD), which curates interactions between genes, chemicals, and diseases (.", "labels": [], "entities": [{"text": "Biocreative V chemical disease relation extraction (CDR) dataset 4", "start_pos": 4, "end_pos": 70, "type": "TASK", "confidence": 0.7152789235115051}]}, {"text": "CTD annotations are only at the document level and do not contain mention annotations.", "labels": [], "entities": []}, {"text": "The CDR dataset is a subset of these original annotations, supplemented with human annotated, entity linked mention annotations.", "labels": [], "entities": [{"text": "CDR dataset", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.9609705209732056}]}, {"text": "The relation annotations in this dataset are also at the document level only.", "labels": [], "entities": []}, {"text": "To assess our model's performance in settings where cross-sentence relationships are not explicitly evaluated, we perform experiments on the Biocreative VI ChemProt dataset (CDR) (.", "labels": [], "entities": [{"text": "Biocreative VI ChemProt dataset (CDR)", "start_pos": 141, "end_pos": 178, "type": "DATASET", "confidence": 0.6980089034352984}]}, {"text": "This dataset is concerned with classifying into six relation types between chemicals and proteins, with nearly all annotated relationships occurring within the same sentence.", "labels": [], "entities": []}, {"text": "Token embeddings are pre-trained using skipgram) over a random subset of 10% of all PubMed abstracts with window size 10 and 20 negative samples.", "labels": [], "entities": []}, {"text": "We merge the train and development sets and randomly take 850 abstracts for training and 150 for early stopping.", "labels": [], "entities": []}, {"text": "Our reported results are averaged over 10 runs and using different splits.", "labels": [], "entities": []}, {"text": "All baselines train on both the train and development set.", "labels": [], "entities": []}, {"text": "Models took between 4 and 8 hours to train. was set to 1e-4, \u03b2 1 to .1, and \u03b2 2 to 0.9.", "labels": [], "entities": []}, {"text": "Gradient noise \u03b7 = .1.", "labels": [], "entities": [{"text": "Gradient noise \u03b7", "start_pos": 0, "end_pos": 16, "type": "METRIC", "confidence": 0.9627629121144613}]}, {"text": "Dropout was applied to the word embeddings with keep probability 0.85, internal layers with 0.95 and final bilinear projection with 0.35 for the standard CRD dataset experiments.", "labels": [], "entities": [{"text": "keep probability 0.85", "start_pos": 48, "end_pos": 69, "type": "METRIC", "confidence": 0.9670294920603434}, {"text": "CRD dataset", "start_pos": 154, "end_pos": 165, "type": "DATASET", "confidence": 0.7787061631679535}]}, {"text": "When adding the additional weakly labeled data: word embeddings with keep probability 0.95, internal layers with 0.95 and final bilinear projection with 0.5.", "labels": [], "entities": [{"text": "keep probability 0.95", "start_pos": 69, "end_pos": 90, "type": "METRIC", "confidence": 0.9589526057243347}]}, {"text": "We construct our byte-pair encoding vocabulary using a budget of 7500.", "labels": [], "entities": []}, {"text": "The dataset contains annotations fora larger set of relation types than are used in evaluation.", "labels": [], "entities": []}, {"text": "We train on only the relation types in the evaluation set and set the remaining types to the Null relation.", "labels": [], "entities": []}, {"text": "The embedding dimension is set to 200 and all embeddings are randomly initialized. was set to 1e-8, \u03b2 1 to .1, and \u03b2 2 to 0.9.", "labels": [], "entities": []}, {"text": "Gradient noise \u03b7 = 1.0.", "labels": [], "entities": [{"text": "Gradient noise \u03b7", "start_pos": 0, "end_pos": 16, "type": "METRIC", "confidence": 0.9616053501764933}]}, {"text": "Dropout was applied to the word embeddings with keep probability 0.5, internal layers with 1.0 and final bilinear projection with 0.85 for the standard CRD dataset experiments.", "labels": [], "entities": [{"text": "keep probability 0.5", "start_pos": 48, "end_pos": 68, "type": "METRIC", "confidence": 0.9655107855796814}, {"text": "CRD dataset", "start_pos": 152, "end_pos": 163, "type": "DATASET", "confidence": 0.7720228731632233}]}, {"text": "We tune separate decision boundaries for each relation type on the development set.", "labels": [], "entities": []}, {"text": "For each prediction, the relation type with the maximum probability is assigned.", "labels": [], "entities": []}, {"text": "If the probability is below the relation specific threshold, the prediction is set to NULL.", "labels": [], "entities": [{"text": "NULL", "start_pos": 86, "end_pos": 90, "type": "METRIC", "confidence": 0.9099578261375427}]}, {"text": "We use embedding dimension 128 with all embeddings randomly initialized.", "labels": [], "entities": []}, {"text": "Our byte pair encoding vocabulary is constructed with a budget of 50,000.", "labels": [], "entities": []}, {"text": "Models took 1 to 2 days to train. was set to 1e-4, \u03b2 1 to .1, and \u03b2 2 to 0.9.", "labels": [], "entities": [{"text": "\u03b2", "start_pos": 66, "end_pos": 67, "type": "METRIC", "confidence": 0.9634971618652344}]}, {"text": "Gradient noise \u03b7 = .1.Dropout was applied to the word embeddings with keep probability 0.95, internal layers with 0.95 and final bilinear projection with 0.5", "labels": [], "entities": [{"text": "keep probability 0.95", "start_pos": 70, "end_pos": 91, "type": "METRIC", "confidence": 0.9618447621663412}]}], "tableCaptions": [{"text": " Table 1: Data statistics for the CDR Dataset and  additional data from CTD. Shows the total num- ber of abstracts, positive examples, and negative  examples for each of the data set splits.", "labels": [], "entities": [{"text": "CDR Dataset", "start_pos": 34, "end_pos": 45, "type": "DATASET", "confidence": 0.9764537513256073}, {"text": "CTD", "start_pos": 72, "end_pos": 75, "type": "DATASET", "confidence": 0.944270133972168}]}, {"text": " Table 2: Precision, recall, and F1 results on the  Biocreative V CDR Dataset.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9987286925315857}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9991157650947571}, {"text": "F1", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.9997294545173645}, {"text": "Biocreative V CDR Dataset", "start_pos": 52, "end_pos": 77, "type": "DATASET", "confidence": 0.7784176170825958}]}, {"text": " Table 3: Results on the Biocreative V CDR Dataset  showing precision, recall, and F1 for various model  ablations.", "labels": [], "entities": [{"text": "Biocreative V CDR Dataset", "start_pos": 25, "end_pos": 50, "type": "DATASET", "confidence": 0.6644425541162491}, {"text": "precision", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9997027516365051}, {"text": "recall", "start_pos": 71, "end_pos": 77, "type": "METRIC", "confidence": 0.9996603727340698}, {"text": "F1", "start_pos": 83, "end_pos": 85, "type": "METRIC", "confidence": 0.9997997879981995}]}, {"text": " Table 4: Precision, recall, and F1 results on the  Biocreative VI Chem-Prot Dataset.  \u2020 denotes re- sults from Liu et al. (2017)", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9986864924430847}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9991934895515442}, {"text": "F1", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.9997507929801941}, {"text": "Biocreative VI Chem-Prot Dataset", "start_pos": 52, "end_pos": 84, "type": "DATASET", "confidence": 0.7374947220087051}]}, {"text": " Table 5: Data statistics for the new CTD dataset.", "labels": [], "entities": [{"text": "CTD dataset", "start_pos": 38, "end_pos": 49, "type": "DATASET", "confidence": 0.7786687910556793}]}, {"text": " Table 6: Data statistics for the new CTD dataset  broken down by relation type. The first column lists  relation types separated by the types of the entities.  Columns 2-4 show the number of positive examples  of that relation type. MP stands for metabolic  processing.", "labels": [], "entities": [{"text": "CTD dataset", "start_pos": 38, "end_pos": 49, "type": "DATASET", "confidence": 0.8531529605388641}]}, {"text": " Table 7: BRAN precision, recall and F1 results for  the full CTD dataset by relation type. The model  is optimized for micro F1 score across all types.", "labels": [], "entities": [{"text": "BRAN", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9972635507583618}, {"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.8540035486221313}, {"text": "recall", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.9996520280838013}, {"text": "F1", "start_pos": 37, "end_pos": 39, "type": "METRIC", "confidence": 0.9997195601463318}, {"text": "CTD dataset", "start_pos": 62, "end_pos": 73, "type": "DATASET", "confidence": 0.7804271876811981}, {"text": "F1 score", "start_pos": 126, "end_pos": 134, "type": "METRIC", "confidence": 0.8570745587348938}]}, {"text": " Table 8: Precision, recall, and F1 results for CTD  named entity recognition and relation extraction,  comparing BPE to word-level tokenization.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9932087063789368}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9971729516983032}, {"text": "F1", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.9997072815895081}, {"text": "CTD  named entity recognition", "start_pos": 48, "end_pos": 77, "type": "TASK", "confidence": 0.8314864784479141}, {"text": "relation extraction", "start_pos": 82, "end_pos": 101, "type": "TASK", "confidence": 0.7795371413230896}]}]}