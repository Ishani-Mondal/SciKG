{"title": [{"text": "Neural Machine Translation for Low Resource Languages using Bilingual Lexicon Induced from Comparable Corpora", "labels": [], "entities": [{"text": "Neural Machine Translation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.754459798336029}]}], "abstractContent": [{"text": "Resources for the non-English languages are scarce and this paper addresses this problem in the context of machine translation, by automatically extracting parallel sentence pairs from the multilingual articles available on the Internet.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 107, "end_pos": 126, "type": "TASK", "confidence": 0.7637294232845306}]}, {"text": "In this paper, we have used an end-to-end Siamese bidirectional recurrent neural network to generate parallel sentences from comparable multilingual articles in Wikipedia.", "labels": [], "entities": []}, {"text": "Subsequently, we have showed that using the harvested dataset improved BLEU scores on both NMT and phrase-based SMT systems for the low-resource language pairs: English-Hindi and English-Tamil, when compared to training exclusively on the limited bilingual corpora collected for these language pairs.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 71, "end_pos": 75, "type": "METRIC", "confidence": 0.9987659454345703}, {"text": "SMT", "start_pos": 112, "end_pos": 115, "type": "TASK", "confidence": 0.8156991600990295}]}], "introductionContent": [{"text": "Both neural and statistical machine translation approaches are highly reliant on the availability of large amounts of data and are known to perform poorly in low resource settings.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 16, "end_pos": 47, "type": "TASK", "confidence": 0.6197535196940104}]}, {"text": "Recent crowdsourcing efforts and workshops on machine translation have resulted in small amounts of parallel texts for building viable machine translation systems for low-resource pairs.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.8136676251888275}, {"text": "machine translation", "start_pos": 135, "end_pos": 154, "type": "TASK", "confidence": 0.7323483526706696}]}, {"text": "But, they have been shown to suffer from low accuracy (incorrect translation) and low coverage (high out-of-vocabulary rates), due to insufficient training data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9987228512763977}, {"text": "coverage", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9958081245422363}]}, {"text": "In this project, we try to address the high OOV rates in low-resource machine translation systems by leveraging the increasing amount of multilingual content available on the Internet for enriching the bilingual lexicon.", "labels": [], "entities": [{"text": "OOV rates", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9175824522972107}]}, {"text": "Comparable corpora such as Wikipedia, are collections of topic-aligned but non-sentence-aligned multilingual documents which are rich resources for extracting parallel sentences from.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 27, "end_pos": 36, "type": "DATASET", "confidence": 0.9433624148368835}]}, {"text": "For example, shows that there are equivalent sentences on the page about Donald Trump in Tamil and English, and the phrase alignment for an example sentence is shown in. shows that there are at least tens of thousands of bilingual articles on Wikipedia which could potentially have at least as many parallel sentences that could be mined to address the scarcity of parallel sentences as indicated in column 2 which shows the number of sentencepairs in the largest available bilingual corpora for xx-en 1 . As shown by, the illustrated data sparsity can be addressed by extending the scarce parallel sentence-pairs with those automatically extracted from Wikipedia and thereby improving the performance of statistical machine translation systems.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 705, "end_pos": 736, "type": "TASK", "confidence": 0.6229524910449982}]}, {"text": "In this paper, we will propose a neural approach to parallel sentence extraction and compare the BLEU scores of machine translation systems with and without the use of the extracted sentence pairs to justify the effectiveness of this method.", "labels": [], "entities": [{"text": "parallel sentence extraction", "start_pos": 52, "end_pos": 80, "type": "TASK", "confidence": 0.6192455987135569}, {"text": "BLEU", "start_pos": 97, "end_pos": 101, "type": "METRIC", "confidence": 0.9991028308868408}, {"text": "machine translation", "start_pos": 112, "end_pos": 131, "type": "TASK", "confidence": 0.6712228953838348}]}, {"text": "Compared to previous approaches which require spe-  cialized meta-data from document structure or significant amount of hand-engineered features, the neural model for extracting parallel sentences is learned end-to-end using only a small bootstrap set of parallel sentence pairs.", "labels": [], "entities": []}], "datasetContent": [{"text": "The parallel sentence extraction system needs a sentence aligned corpus which has been curated.", "labels": [], "entities": [{"text": "parallel sentence extraction", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.6245825489362081}]}, {"text": "These sentences were used as the ground truth pairs when we trained the model to classify parallel sentence pair from non-parallel pairs.", "labels": [], "entities": []}, {"text": "We experimented with two language pairs: English -Hindi (en-hi) and English -Tamil (en-ta).", "labels": [], "entities": []}, {"text": "The parallel sentence extraction systems for both en-ta and en-hi were trained using the architecture described in 3.2 on the following bootstrap set of parallel corpora: \u2022 An English-Tamil parallel corpus) containing a total of 169, 871 sentence pairs, composed of 3, 984, 038 English Tokens and 2, 776, 397 Tamil Tokens.", "labels": [], "entities": [{"text": "parallel sentence extraction", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.683342864116033}]}, {"text": "\u2022 An English-Hindi parallel corpus () containing a total of 1, 492, 827 sentence pairs, from which a set of 200, 000 sentence pairs were picked randomly.", "labels": [], "entities": []}, {"text": "Subsequently, we extracted parallel sentences using the trained model, and parallel articles collected from Wikipedia 2 . There were 67, 449 bilin-gual English-Tamil and 58, 802 English-Hindi titles on the Wikimedia dumps collected in December 2017.", "labels": [], "entities": [{"text": "Wikimedia dumps collected in December 2017", "start_pos": 206, "end_pos": 248, "type": "DATASET", "confidence": 0.9499734938144684}]}, {"text": "For the evaluation of the performance of our sentence extraction models, we looked at a few sentences manually, and have done a qualitative analysis, as there was no gold standard evaluation set for sentences extracted from Wikipedia.", "labels": [], "entities": [{"text": "sentence extraction", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.7214339375495911}]}, {"text": "In, we can seethe qualitative accuracy for some parallel sentences extracted from Tamil.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9884366989135742}]}, {"text": "The sentences extracted from Tamil, have been translated to English using Google Translate, so as to facilitate a comparison with the sentences extracted from English.", "labels": [], "entities": []}, {"text": "For the statistical machine translation and neural machine translation evaluation we use the BLEU score () as an evaluation metric, computed using the multi-bleu script from Moses ().", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 8, "end_pos": 39, "type": "TASK", "confidence": 0.651340107123057}, {"text": "neural machine translation evaluation", "start_pos": 44, "end_pos": 81, "type": "TASK", "confidence": 0.7664166688919067}, {"text": "BLEU score", "start_pos": 93, "end_pos": 103, "type": "METRIC", "confidence": 0.9807824790477753}]}], "tableCaptions": [{"text": " Table 1: Number of bilingual articles in Wikipedia  against the number of parallel sentences in the  largest xx-en corpora available.", "labels": [], "entities": []}, {"text": " Table 4: BLEU score results for en-hi and en-ta", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.96868696808815}]}]}