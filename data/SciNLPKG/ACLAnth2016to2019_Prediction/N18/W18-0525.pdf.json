{"title": [{"text": "Second Language Acquisition Modeling: An Ensemble Approach", "labels": [], "entities": [{"text": "Second Language Acquisition Modeling", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.6939583271741867}]}], "abstractContent": [{"text": "Accurate prediction of students knowledge is a fundamental building block of personalized learning systems.", "labels": [], "entities": [{"text": "Accurate prediction of students knowledge", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.7491233885288239}]}, {"text": "Here, we propose a novel ensemble model to predict student knowledge gaps.", "labels": [], "entities": []}, {"text": "Applying our approach to student trace data from the online educational platform Duolingo we achieved highest score on both evaluation metrics for all three datasets in the 2018 Shared Task on Second Language Acquisition Modeling.", "labels": [], "entities": [{"text": "Duolingo", "start_pos": 81, "end_pos": 89, "type": "DATASET", "confidence": 0.8137764930725098}, {"text": "Second Language Acquisition Modeling", "start_pos": 193, "end_pos": 229, "type": "TASK", "confidence": 0.62096057087183}]}, {"text": "We describe our model and discuss relevance of the task compared to how it would be setup in a production environment for personalized education.", "labels": [], "entities": []}], "introductionContent": [{"text": "Understanding how students learn overtime holds the key to unlock the full potential of adaptive learning.", "labels": [], "entities": []}, {"text": "Indeed, personalizing the learning experience, so that educational content is recommended based on individual need in real time, promises to continuously stimulate motivation and the learning process (.", "labels": [], "entities": []}, {"text": "Accurate detection of students' knowledge gaps is a fundamental building block of personalized learning systems (Bauman and Tuzhilin, 2014b) (.", "labels": [], "entities": []}, {"text": "A number of approaches exists for modeling student knowledge and predicting student performance on future exercises including IRT,) and DKT ().", "labels": [], "entities": [{"text": "IRT", "start_pos": 126, "end_pos": 129, "type": "TASK", "confidence": 0.6266322135925293}, {"text": "DKT", "start_pos": 136, "end_pos": 139, "type": "METRIC", "confidence": 0.45867258310317993}]}, {"text": "Here we propose an ensemble approach to predict student knowledge gaps which achieved highest score on both evaluation metrics for all three datasets in the 2018 Shared Task on Second Language Acquisition Modeling (SLAM) (.", "labels": [], "entities": [{"text": "Shared Task on Second Language Acquisition Modeling (SLAM)", "start_pos": 162, "end_pos": 220, "type": "TASK", "confidence": 0.7223229527473449}]}, {"text": "We analyze in what cases our models' predictions could be improved and discuss the relevance of the task setup for real-time delivery of personalized content within an educational setting.", "labels": [], "entities": []}], "datasetContent": [{"text": "The 2018 Shared Task on SLAM provides student trace data from users on the online educational platform Duolingo (.", "labels": [], "entities": [{"text": "SLAM", "start_pos": 24, "end_pos": 28, "type": "TASK", "confidence": 0.8253667950630188}, {"text": "Duolingo", "start_pos": 103, "end_pos": 111, "type": "DATASET", "confidence": 0.8454724550247192}]}, {"text": "Three different datasets are given representing users responses to exercises completed over the first 30 days of learning English, French and Spanish as a second language.", "labels": [], "entities": []}, {"text": "Common for all exercises is that the user responds with a sentence in the language learnt.", "labels": [], "entities": []}, {"text": "Importantly, the raw input sentence from the user is not available but instead the best matching sentence among a set of correct answer sentences.", "labels": [], "entities": []}, {"text": "The prediction task is to predict the word-level mistakes made by the user, given the best matching sentence and a number of additional features provided.", "labels": [], "entities": []}, {"text": "The matching between user response and correct sentence was derived by the finite-state transducer method.", "labels": [], "entities": []}, {"text": "All datasets were pre-partitioned into training, development and test subsets, where approximately the last 10 % of the events for each user is used for testing and the last 10 % of the remaining events used for development . Target labels for token level mistakes are provided for the training and development set but not for the test set.", "labels": [], "entities": []}, {"text": "Aggregated metrics for the test set were obtained by submitting predictions to an evaluation server provided by Duolingo.", "labels": [], "entities": [{"text": "Duolingo", "start_pos": 112, "end_pos": 120, "type": "DATASET", "confidence": 0.9628260135650635}]}, {"text": "The performance for this binary classification task is measured by area under the ROC curve (AUC) and F1-score.", "labels": [], "entities": [{"text": "binary classification task", "start_pos": 25, "end_pos": 51, "type": "TASK", "confidence": 0.7440165877342224}, {"text": "ROC curve (AUC)", "start_pos": 82, "end_pos": 97, "type": "METRIC", "confidence": 0.9643361806869507}, {"text": "F1-score", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9963961243629456}]}, {"text": "Although the dataset provided represents real user interactions on the Duolingo platform, the model evaluation setup does not represent a realistic scenario where the predictive modelling would be used for personalizing the content presented to a user.", "labels": [], "entities": []}, {"text": "The reason for this is threefold: Firstly, predictions are made given the best matching correct sentence which would not be known prior to the user answering the question for questions that have multiple correct answers.", "labels": [], "entities": []}, {"text": "Secondly, there area number of variables available at each point in time which represent information from the future creating a form of data leakage.", "labels": [], "entities": []}, {"text": "Finally, the fact that interactions from each student span all data partitions means that we can always train on the same users that the model is evaluated for and hence there are never first time users, where we would need to infer student mistakes solely from sequential behaviour.", "labels": [], "entities": []}, {"text": "To estimate prediction performance in an educational production setting where next-step recommendations must be inferred from past observations, the evaluation procedure would have to be adjusted accordingly.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3), the prediction diversity evidently suf- fices for the ensemble combination to outperform  the underlying models. This suggests that the  RNN and the GBDT differ in performance on dif- ferent word mistakes. Most likely, the temporal  dynamics modelled by the neural network model  complement the GBDT predictions enabling the  ensemble to generalise better to unseen user events  than its component parts. Notably, none of our in- dividual models would have yielded first place in  the Shared Task.", "labels": [], "entities": []}, {"text": " Table 2: Model F1 scores on the test partition for all  datasets.", "labels": [], "entities": [{"text": "F1", "start_pos": 16, "end_pos": 18, "type": "METRIC", "confidence": 0.9643234014511108}]}, {"text": " Table 3: Pearson correlations coefficients between the  GBDT and RNN predictions on the dev and test set for  all datasets.", "labels": [], "entities": [{"text": "Pearson correlations", "start_pos": 10, "end_pos": 30, "type": "METRIC", "confidence": 0.9337760210037231}, {"text": "GBDT", "start_pos": 57, "end_pos": 61, "type": "DATASET", "confidence": 0.7678441405296326}]}]}