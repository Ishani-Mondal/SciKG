{"title": [{"text": "Construction of the Literature Graph in Semantic Scholar", "labels": [], "entities": []}], "abstractContent": [{"text": "We describe a deployed scalable system for organizing published scientific literature into a heterogeneous graph to facilitate algorithmic manipulation and discovery.", "labels": [], "entities": [{"text": "algorithmic manipulation and discovery", "start_pos": 127, "end_pos": 165, "type": "TASK", "confidence": 0.6895141899585724}]}, {"text": "The resulting literature graph consists of more than 280M nodes, representing papers , authors, entities and various interactions between them (e.g., authorships, citations , entity mentions).", "labels": [], "entities": []}, {"text": "We reduce literature graph construction into familiar NLP tasks (e.g., entity extraction and linking), point out research challenges due to differences from standard formulations of these tasks, and report empirical results for each task.", "labels": [], "entities": [{"text": "literature graph construction", "start_pos": 10, "end_pos": 39, "type": "TASK", "confidence": 0.7603811621665955}, {"text": "entity extraction and linking)", "start_pos": 71, "end_pos": 101, "type": "TASK", "confidence": 0.7945169806480408}]}, {"text": "The methods described in this paper are used to enable semantic features in www.semanticscholar.org.", "labels": [], "entities": []}], "introductionContent": [{"text": "The goal of this work is to facilitate algorithmic discovery in the scientific literature.", "labels": [], "entities": [{"text": "algorithmic discovery", "start_pos": 39, "end_pos": 60, "type": "TASK", "confidence": 0.7730358242988586}]}, {"text": "Despite notable advances in scientific search engines, data mining and digital libraries (e.g.,, researchers remain unable to answer simple questions such as: What is the percentage of female subjects in depression clinical trials?", "labels": [], "entities": []}, {"text": "Which of my co-authors published one or more papers on coreference resolution?", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 55, "end_pos": 77, "type": "TASK", "confidence": 0.9731839299201965}]}, {"text": "Which papers discuss the effects of Ranibizumab on the Retina?", "labels": [], "entities": []}, {"text": "In this paper, we focus on the problem of extracting structured data from scientific documents, which can later be used in natural language interfaces (e.g.,) or to improve ranking of results in academic search (e.g., Xiong et al., 2017).", "labels": [], "entities": []}, {"text": "We describe methods used in a scalable deployed production system for extracting structured information from scientific documents into the literature graph (see).", "labels": [], "entities": []}, {"text": "The literature graph is a directed property graph which summarizes key information in the literature and can be used to answer the queries mentioned earlier as well as more complex queries.", "labels": [], "entities": []}, {"text": "For example, in order to compute the Erd\u02dd os number of an author X, the graph can be queried to find the number of nodes on the shortest undirected path between author X and Paul Erd\u02dd os such that all edges on the path are labeled \"authored\".", "labels": [], "entities": []}, {"text": "We reduce literature graph construction into familiar NLP tasks such as sequence labeling, entity linking and relation extraction, and address some of the impractical assumptions commonly made in the standard formulations of these tasks.", "labels": [], "entities": [{"text": "literature graph construction", "start_pos": 10, "end_pos": 39, "type": "TASK", "confidence": 0.7192209959030151}, {"text": "sequence labeling", "start_pos": 72, "end_pos": 89, "type": "TASK", "confidence": 0.6283579170703888}, {"text": "entity linking", "start_pos": 91, "end_pos": 105, "type": "TASK", "confidence": 0.8081624209880829}, {"text": "relation extraction", "start_pos": 110, "end_pos": 129, "type": "TASK", "confidence": 0.7943435311317444}]}, {"text": "For example, most research on named entity recognition tasks report results on large labeled datasets such as, and assume that entity types in the test set match those labeled in the training set (including work on domain adaptation, e.g.,.", "labels": [], "entities": [{"text": "named entity recognition tasks", "start_pos": 30, "end_pos": 60, "type": "TASK", "confidence": 0.7541184425354004}, {"text": "domain adaptation", "start_pos": 215, "end_pos": 232, "type": "TASK", "confidence": 0.7302730828523636}]}, {"text": "These assumptions, while useful for developing and benchmarking new methods, are unrealistic for many domains and applications.", "labels": [], "entities": []}, {"text": "The paper also serves as an overview of the approach we adopt at www.semanticscholar.org in a step towards more intelligent academic search engines.", "labels": [], "entities": []}, {"text": "In the next section, we start by describing our symbolic representation of the literature.", "labels": [], "entities": []}, {"text": "Then, we discuss how we extract metadata associated with a paper such as authors and references, then how we extract the entities mentioned in paper text.", "labels": [], "entities": []}, {"text": "Before we conclude, we briefly describe other research challenges we are actively working on in order to improve the quality of the literature graph.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results of the ScienceParse system.", "labels": [], "entities": []}, {"text": " Table 1. We  use a conservative evaluation where an instance is  correct if it exactly matches the gold annotation,  with no credit for partial matching.", "labels": [], "entities": []}]}