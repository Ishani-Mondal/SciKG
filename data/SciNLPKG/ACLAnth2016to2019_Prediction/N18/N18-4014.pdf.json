{"title": [{"text": "Japanese Predicate Conjugation for Neural Machine Translation", "labels": [], "entities": [{"text": "Predicate Conjugation", "start_pos": 9, "end_pos": 30, "type": "TASK", "confidence": 0.7945899367332458}, {"text": "Neural Machine Translation", "start_pos": 35, "end_pos": 61, "type": "TASK", "confidence": 0.8013628721237183}]}], "abstractContent": [{"text": "Neural machine translation (NMT) has a drawback in that can generate only high-frequency words owing to the computational costs of the softmax function in the output layer.", "labels": [], "entities": [{"text": "Neural machine translation (NMT)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8314277430375417}]}, {"text": "In Japanese-English NMT, Japanese predicate conjugation causes an increase in vocabulary size.", "labels": [], "entities": [{"text": "Japanese predicate conjugation", "start_pos": 25, "end_pos": 55, "type": "TASK", "confidence": 0.713224450747172}]}, {"text": "For example, one verb can have as many as 19 surface varieties.", "labels": [], "entities": []}, {"text": "In this research , we focus on predicate conjugation for compressing the vocabulary size in Japanese.", "labels": [], "entities": [{"text": "predicate conjugation", "start_pos": 31, "end_pos": 52, "type": "TASK", "confidence": 0.8380781710147858}]}, {"text": "The vocabulary list is filled with the various forms of verbs.", "labels": [], "entities": []}, {"text": "We propose methods using predicate conjugation information without discarding linguistic information.", "labels": [], "entities": []}, {"text": "The proposed methods can generate low-frequency words and deal with unknown words.", "labels": [], "entities": []}, {"text": "Two methods were considered to introduce conjugation information: the first considers it as a token (conjugation token) and the second considers it as an embedded vector (conjugation feature).", "labels": [], "entities": []}, {"text": "The results using these methods demonstrate that the vocabulary size can be compressed by approximately 86.1% (Tanaka corpus) and the NMT models can output the words not in the training data set.", "labels": [], "entities": [{"text": "Tanaka corpus", "start_pos": 111, "end_pos": 124, "type": "DATASET", "confidence": 0.8641752004623413}]}, {"text": "Furthermore, BLEU scores improved by 0.91 points in Japanese-to-English translation, and 0.32 points in English-to-Japanese translation with ASPEC.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 13, "end_pos": 17, "type": "METRIC", "confidence": 0.998547375202179}, {"text": "ASPEC", "start_pos": 141, "end_pos": 146, "type": "DATASET", "confidence": 0.807317852973938}]}], "introductionContent": [{"text": "Neural machine translation (NMT) is gaining significant attention in machine translation research because it produces high-quality translation ().", "labels": [], "entities": [{"text": "Neural machine translation (NMT)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8120019137859344}, {"text": "machine translation research", "start_pos": 69, "end_pos": 97, "type": "TASK", "confidence": 0.824929416179657}]}, {"text": "However, because NMT requires massive computational time to select output words, it is necessary to reduce the vocabulary in practice by using only high-frequency words in the training corpus.", "labels": [], "entities": [{"text": "NMT", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.9027743339538574}]}, {"text": "Therefore, NMT treated not only unknown words, which do not exist in the training corpus, but also OOV, which cannot consider words to NMT's computational ability, as unknown word token . Two approaches were proposed to address this problem: backoff dictionary ( and byte pair encoding, or BPE ( . However, because the backoff dictionary is a post-processing method to replace OOV, it is not a fundamental solution.", "labels": [], "entities": [{"text": "BPE", "start_pos": 290, "end_pos": 293, "type": "METRIC", "confidence": 0.854559600353241}]}, {"text": "BPE can eliminate unknown words by dividing a word into partial strings; however, there is a possibility of loss of linguistic information such as loss of the meaning of words.", "labels": [], "entities": []}, {"text": "In Japanese grammar, the surfaces of verb, adjective, and auxiliary verb change into different forms by the neighboring words.", "labels": [], "entities": []}, {"text": "This phenomenon is called \"conjugation,\" and 18 conjugation patterns can be formed at maximum for each word.", "labels": [], "entities": []}, {"text": "We consider the conjugation forms as the vocabulary of NMT using Japanese language because the Japanese morphological analyzer divides a sentence into words based on conjugation forms.", "labels": [], "entities": []}, {"text": "The vocabulary set in the NMT model must have all conjugation forms for generating fluent sentences.", "labels": [], "entities": []}, {"text": "In this research, we propose two methods using predicate conjugation information without discarding linguistic information.", "labels": [], "entities": []}, {"text": "These methods cannot only reduce OOV words, but also deal with unknown words.", "labels": [], "entities": []}, {"text": "In addition, we consider a method to introduce part-of-speech (POS) information other than predicate.", "labels": [], "entities": []}, {"text": "We found this method is related to source head information.", "labels": [], "entities": []}, {"text": "The main contributions of this paper are as follows: \u2022 The proposed NMT reduced the vocabulary size and improved BLEU scores particularly in small-and medium-sized corpora.", "labels": [], "entities": [{"text": "BLEU scores", "start_pos": 113, "end_pos": 124, "type": "METRIC", "confidence": 0.9756275117397308}]}, {"text": "\u2022 We found that conjugation features are best exploited as tokens rather than embeddings and suggested the connection between the position of the token and linguistic properties.", "labels": [], "entities": []}], "datasetContent": [{"text": "We experimented two baseline methods (with and without BPE) and two proposed methods.", "labels": [], "entities": [{"text": "BPE", "start_pos": 55, "end_pos": 58, "type": "METRIC", "confidence": 0.5951469540596008}]}, {"text": "Each experiment was conducted four times with different initializations.", "labels": [], "entities": []}, {"text": "We report the average performance overall experiments.", "labels": [], "entities": []}, {"text": "We used three data sets: NTCIR PatentMT Parallel Corpus -10 (), Asian Scientific Paper Excerpt Corpus (, and Tanaka Corpus (Excerpt, Preprocessed) . The details of each corpus are shown in: BLEU scores of each experiment (average of four runs).", "labels": [], "entities": [{"text": "NTCIR PatentMT Parallel Corpus -10", "start_pos": 25, "end_pos": 59, "type": "DATASET", "confidence": 0.8350448409716288}, {"text": "Asian Scientific Paper Excerpt Corpus", "start_pos": 64, "end_pos": 101, "type": "DATASET", "confidence": 0.7580228090286255}, {"text": "Tanaka Corpus", "start_pos": 109, "end_pos": 122, "type": "DATASET", "confidence": 0.8433877229690552}, {"text": "Preprocessed", "start_pos": 133, "end_pos": 145, "type": "METRIC", "confidence": 0.9392766952514648}, {"text": "BLEU", "start_pos": 190, "end_pos": 194, "type": "METRIC", "confidence": 0.9995450377464294}]}, {"text": "The best score in each corpus is made bold (expect for BPE \"both\" and \"only English\").", "labels": [], "entities": [{"text": "BPE", "start_pos": 55, "end_pos": 58, "type": "METRIC", "confidence": 0.4650669991970062}]}, {"text": "already lowercased; hence, truecase was not used.", "labels": [], "entities": []}, {"text": "As for ASPEC, we used only the first one million sentences sorted by sentence alignment confidence.", "labels": [], "entities": [{"text": "ASPEC", "start_pos": 7, "end_pos": 12, "type": "TASK", "confidence": 0.9138640761375427}, {"text": "sentence alignment", "start_pos": 69, "end_pos": 87, "type": "TASK", "confidence": 0.6715355962514877}]}, {"text": "Japanese sentences were tokenized by the morphological analyzer MeCab (IPADic), and English sentences were preprocessed by Moses 6 (tokenizer, truecaser).", "labels": [], "entities": []}, {"text": "As for the training corpus, we deleted sentences that exceeded the maximum number of tokens each sentence shown in.", "labels": [], "entities": []}, {"text": "We used our implementation  Byte pair encoding.", "labels": [], "entities": [{"text": "Byte pair encoding", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.6226912339528402}]}, {"text": "We conducted an experiment using BPE as the comparative method.", "labels": [], "entities": [{"text": "BPE", "start_pos": 33, "end_pos": 36, "type": "METRIC", "confidence": 0.5787546634674072}]}, {"text": "BPE was applied to the Japanese side only for making a fair comparison with the proposed method.", "labels": [], "entities": [{"text": "BPE", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.7493265271186829}]}, {"text": "The number of merge operations in both NTCIR and ASPEC was set to 16,000 and in Tanaka, the number was set to 2,000.", "labels": [], "entities": [{"text": "NTCIR", "start_pos": 39, "end_pos": 44, "type": "DATASET", "confidence": 0.9105766415596008}, {"text": "ASPEC", "start_pos": 49, "end_pos": 54, "type": "DATASET", "confidence": 0.48775333166122437}, {"text": "Tanaka", "start_pos": 80, "end_pos": 86, "type": "DATASET", "confidence": 0.9345180988311768}]}, {"text": "As a result, OOV did not exist in all corpora because the size of Japanese vocabulary is smaller than that of BPE.", "labels": [], "entities": [{"text": "OOV", "start_pos": 13, "end_pos": 16, "type": "METRIC", "confidence": 0.9147653579711914}, {"text": "BPE", "start_pos": 110, "end_pos": 113, "type": "DATASET", "confidence": 0.8911275863647461}]}, {"text": "Because the output of English-Japanese translation includes special tokens, we evaluate it by restoring the results with rules using IPADic.", "labels": [], "entities": []}, {"text": "The restoration accuracy is http://www.statmt.org/moses/ 7 http://github.com/yukio326/nmt-chainer 100%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9576881527900696}]}, {"text": "If the output has only a lemma, it is converted into the plain form, and if it has a conjugation token only, the token is deleted from the output.", "labels": [], "entities": []}, {"text": "Because this method can solely be adopted to the source side, only Japanese-to-English translation was performed.", "labels": [], "entities": [{"text": "Japanese-to-English translation", "start_pos": 67, "end_pos": 98, "type": "TASK", "confidence": 0.5531185269355774}]}, {"text": "To restrict the embed size to 512, the size of each feature was set to POS (coarse-grained): 4, POS (fine-grained): 8, conjugation form: 8, lemma: 492.", "labels": [], "entities": [{"text": "POS", "start_pos": 71, "end_pos": 74, "type": "METRIC", "confidence": 0.9128949642181396}]}, {"text": "We increased the output limit by 2.5 times in English-to-Japanese translation because of additional POS tokens attached to all words.", "labels": [], "entities": []}, {"text": "We used the same restoration rules as for Conjugation token to treat special tokens.", "labels": [], "entities": []}, {"text": "We evaluated POS features in only ASPEC and Tanaka owing to time constraints.", "labels": [], "entities": [{"text": "ASPEC", "start_pos": 34, "end_pos": 39, "type": "DATASET", "confidence": 0.8782979846000671}, {"text": "Tanaka", "start_pos": 44, "end_pos": 50, "type": "DATASET", "confidence": 0.877090334892273}]}], "tableCaptions": [{"text": " Table 2: Details of each corpus.", "labels": [], "entities": []}, {"text": " Table 3: BLEU scores of each experiment (average of four runs). The best score in each corpus is made bold  (expect for BPE \"both\" and \"only English\").", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9985633492469788}, {"text": "BPE", "start_pos": 121, "end_pos": 124, "type": "METRIC", "confidence": 0.5230977535247803}]}]}