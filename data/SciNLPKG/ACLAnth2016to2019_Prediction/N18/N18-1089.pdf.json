{"title": [{"text": "Robust Multilingual Part-of-Speech Tagging via Adversarial Training", "labels": [], "entities": [{"text": "Robust Multilingual Part-of-Speech Tagging", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.6660587340593338}]}], "abstractContent": [{"text": "Adversarial training (AT) 1 is a powerful reg-ularization method for neural networks, aiming to achieve robustness to input perturbations.", "labels": [], "entities": [{"text": "Adversarial training (AT)", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6930561065673828}]}, {"text": "Yet, the specific effects of the robust-ness obtained from AT are still unclear in the context of natural language processing.", "labels": [], "entities": []}, {"text": "In this paper, we propose and analyze a neural POS tagging model that exploits AT.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 47, "end_pos": 58, "type": "TASK", "confidence": 0.6520115882158279}, {"text": "AT", "start_pos": 79, "end_pos": 81, "type": "METRIC", "confidence": 0.8578075170516968}]}, {"text": "In our experiments on the Penn Treebank WSJ corpus and the Universal Dependencies (UD) dataset (27 languages), we find that AT not only improves the overall tagging accuracy, but also 1) prevents over-fitting well in low resource languages and 2) boosts tagging accuracy for rare / unseen words.", "labels": [], "entities": [{"text": "Penn Treebank WSJ corpus", "start_pos": 26, "end_pos": 50, "type": "DATASET", "confidence": 0.9813891053199768}, {"text": "Universal Dependencies (UD) dataset", "start_pos": 59, "end_pos": 94, "type": "DATASET", "confidence": 0.5971883287032446}, {"text": "AT", "start_pos": 124, "end_pos": 126, "type": "METRIC", "confidence": 0.9937366247177124}, {"text": "tagging", "start_pos": 157, "end_pos": 164, "type": "TASK", "confidence": 0.9468981027603149}, {"text": "accuracy", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.8585715293884277}, {"text": "tagging", "start_pos": 254, "end_pos": 261, "type": "TASK", "confidence": 0.9427608847618103}, {"text": "accuracy", "start_pos": 262, "end_pos": 270, "type": "METRIC", "confidence": 0.7726503014564514}]}, {"text": "We also demonstrate that 3) the improved tagging performance by AT contributes to the downstream task of dependency parsing, and that 4) AT helps the model to learn cleaner word representations.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 105, "end_pos": 123, "type": "TASK", "confidence": 0.843995213508606}, {"text": "AT", "start_pos": 137, "end_pos": 139, "type": "METRIC", "confidence": 0.9628556966781616}]}, {"text": "5) The proposed AT model is generally effective in different sequence labeling tasks.", "labels": [], "entities": [{"text": "sequence labeling tasks", "start_pos": 61, "end_pos": 84, "type": "TASK", "confidence": 0.6985534429550171}]}, {"text": "These positive results motivate further use of AT for natural language tasks.", "labels": [], "entities": [{"text": "AT", "start_pos": 47, "end_pos": 49, "type": "METRIC", "confidence": 0.6159573793411255}]}], "introductionContent": [{"text": "Recently, neural network-based approaches have become popular in many natural language processing (NLP) tasks including tagging, parsing, and translation.", "labels": [], "entities": [{"text": "tagging, parsing", "start_pos": 120, "end_pos": 136, "type": "TASK", "confidence": 0.5910977423191071}]}, {"text": "However, it has been shown that neural networks tend to be locally unstable and even tiny perturbations to the original inputs can mislead the models ().", "labels": [], "entities": []}, {"text": "Such maliciously perturbed inputs are called adversarial examples.", "labels": [], "entities": []}, {"text": "Adversarial training () aims to improve the robustness of a model to input perturbations by training on both unmodified examples and adversarial examples.", "labels": [], "entities": []}, {"text": "Previous work (Goodfellow: Illustration of our architecture for adversarial POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 76, "end_pos": 87, "type": "TASK", "confidence": 0.8044226467609406}]}, {"text": "Given a sentence, we input the normalized word embeddings (w 1 , w 2 , w 3 ) and character embeddings (showing c 1 , c 2 , c 3 for w 1 ).", "labels": [], "entities": []}, {"text": "Each word is represented by concatenating its word embedding and its character-level BiLSTM output.", "labels": [], "entities": []}, {"text": "They are fed into the main BiLSTM-CRF network for POS tagging.", "labels": [], "entities": [{"text": "BiLSTM-CRF network", "start_pos": 27, "end_pos": 45, "type": "DATASET", "confidence": 0.8816748559474945}, {"text": "POS tagging", "start_pos": 50, "end_pos": 61, "type": "TASK", "confidence": 0.7941516041755676}]}, {"text": "In adversarial training, we compute and add the worstcase perturbation \u03b7 to all the input embeddings for regularization.", "labels": [], "entities": []}, {"text": "et al.,) on image recognition has demonstrated the enhanced robustness of their models to unseen images via adversarial training and has provided theoretical explanations of the regularization effects.", "labels": [], "entities": [{"text": "image recognition", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.8352539539337158}]}, {"text": "Despite its potential as a powerful regularizer, adversarial training (AT) has yet to be explored extensively in natural language tasks.", "labels": [], "entities": [{"text": "adversarial training (AT)", "start_pos": 49, "end_pos": 74, "type": "TASK", "confidence": 0.6488214015960694}]}, {"text": "Recently, applied AT on text classification, achieving state-of-the-art accuracy.", "labels": [], "entities": [{"text": "AT", "start_pos": 18, "end_pos": 20, "type": "METRIC", "confidence": 0.9913220405578613}, {"text": "text classification", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.8564730286598206}, {"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9975197911262512}]}, {"text": "Yet, the specific effects of the robustness obtained from AT are still unclear in the context of NLP.", "labels": [], "entities": [{"text": "AT", "start_pos": 58, "end_pos": 60, "type": "METRIC", "confidence": 0.8167544603347778}]}, {"text": "For example, research studies have yet to answer questions such as 1) how can we interpret perturbations or robustness on natural language inputs?", "labels": [], "entities": []}, {"text": "2) how are they related to linguistic factors like vocabulary statis-tics?", "labels": [], "entities": []}, {"text": "3) are the effects of AT language-dependent?", "labels": [], "entities": []}, {"text": "Answering such questions is crucial to understand and motivate the application of adversarial training on natural language tasks.", "labels": [], "entities": []}, {"text": "In this paper, spotlighting a well-studied core problem of NLP, we propose and carefully analyze a neural part-of-speech (POS) tagging model that exploits adversarial training.", "labels": [], "entities": []}, {"text": "With a BiLSTM-CRF model as our baseline POS tagger, we apply adversarial training by considering perturbations to input word/character embeddings.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 40, "end_pos": 50, "type": "TASK", "confidence": 0.7565033435821533}]}, {"text": "In order to demystify the effects of adversarial training in the context of NLP, we conduct POS tagging experiments on multiple languages using the Penn Treebank WSJ corpus (Englsih) and the Universal Dependencies dataset, with thorough analyses of the following points: \u2022 Effects on different target languages \u2022 Vocabulary statistics and tagging accuracy \u2022 Influence on downstream tasks \u2022 Representation learning of words In our experiments, we find that our adversarial training model consistently outperforms the baseline POS tagger, and even achieves state-of-the-art results on 22 languages.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 92, "end_pos": 103, "type": "TASK", "confidence": 0.8376258015632629}, {"text": "Penn Treebank WSJ corpus (Englsih)", "start_pos": 148, "end_pos": 182, "type": "DATASET", "confidence": 0.9736356820378985}, {"text": "Universal Dependencies dataset", "start_pos": 191, "end_pos": 221, "type": "DATASET", "confidence": 0.6370441416899363}, {"text": "accuracy", "start_pos": 347, "end_pos": 355, "type": "METRIC", "confidence": 0.9323061108589172}, {"text": "Representation learning of words", "start_pos": 390, "end_pos": 422, "type": "TASK", "confidence": 0.9105601012706757}, {"text": "POS tagger", "start_pos": 525, "end_pos": 535, "type": "TASK", "confidence": 0.7173165082931519}]}, {"text": "Furthermore, our analyses reveal the following insights into adversarial training in the context of NLP: \u2022 The regularization effects of adversarial training (AT) are general across different languages.", "labels": [], "entities": []}, {"text": "AT can prevent overfitting especially well when training examples are scarce, providing an effective tool to process low resource languages.", "labels": [], "entities": [{"text": "AT", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.5905988812446594}]}, {"text": "\u2022 AT can boost the tagging performance for rare/ unseen words and increase the sentence-level accuracy.", "labels": [], "entities": [{"text": "AT", "start_pos": 2, "end_pos": 4, "type": "METRIC", "confidence": 0.9986520409584045}, {"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.976702094078064}]}, {"text": "This positively affects the performance of down-stream tasks such as dependency parsing, where low sentence-level POS accuracy can be a bottleneck).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 69, "end_pos": 87, "type": "TASK", "confidence": 0.8618068695068359}, {"text": "accuracy", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.6356475949287415}]}, {"text": "\u2022 AT helps the network learn cleaner word embeddings, showing stronger correlations with their POS tags.", "labels": [], "entities": [{"text": "AT", "start_pos": 2, "end_pos": 4, "type": "METRIC", "confidence": 0.9926913380622864}]}, {"text": "We argue that the effects of AT can be interpreted from the perspective of natural language.", "labels": [], "entities": []}, {"text": "Finally, we demonstrate that the proposed AT model is generally effective across different sequence labeling tasks.", "labels": [], "entities": []}, {"text": "This work therefore provides a strong motivation and basis for utilizing adversarial training in NLP tasks.", "labels": [], "entities": []}], "datasetContent": [{"text": "To fully analyze the effects of adversarial training, we train and evaluate our baseline/adversarial POS tagging models on both a standard English dataset and a multilingual dataset.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 101, "end_pos": 112, "type": "TASK", "confidence": 0.7217514514923096}]}, {"text": "As a standard English dataset, we use the Wall Street Journal (WSJ) portion of the Penn Treebank (PTB) (, containing 45 different POS tags.", "labels": [], "entities": [{"text": "Wall Street Journal (WSJ) portion of the Penn Treebank (PTB)", "start_pos": 42, "end_pos": 102, "type": "DATASET", "confidence": 0.9471812759126935}]}, {"text": "We adopt the standard split: sections 0-18 for training, 19-21 for development and 22-24 for testing 97.55 97.55 97.55 Ours -Baseline 97.54 Ours -Adversarial 97.58 Optimization.", "labels": [], "entities": []}, {"text": "We train the model parameters and word/character embeddings by the mini-batch stochastic gradient descent (SGD) with batch size 10, momentum 0.9, initial learning rate 0.01 and decay rate 0.05.", "labels": [], "entities": [{"text": "initial learning rate 0.01", "start_pos": 146, "end_pos": 172, "type": "METRIC", "confidence": 0.8883930295705795}]}, {"text": "We also use a gradient clipping of 5.0 ().", "labels": [], "entities": []}, {"text": "The models are trained with early stopping () based on the development performance.", "labels": [], "entities": [{"text": "early stopping", "start_pos": 28, "end_pos": 42, "type": "METRIC", "confidence": 0.8660824298858643}]}, {"text": "We evaluate per token tagging accuracy on test sets.", "labels": [], "entities": [{"text": "per token tagging", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.5665518144766489}, {"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9689498543739319}]}, {"text": "We repeat the experiment three times and report the statistical significance.", "labels": [], "entities": [{"text": "statistical significance", "start_pos": 52, "end_pos": 76, "type": "METRIC", "confidence": 0.8362993597984314}]}], "tableCaptions": [{"text": " Table 1: POS tagging accuracy on the PTB-WSJ test  set, with other top-performing systems.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.7426845729351044}, {"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9906678795814514}, {"text": "PTB-WSJ test  set", "start_pos": 38, "end_pos": 55, "type": "DATASET", "confidence": 0.9858203728993734}]}, {"text": " Table 1 shows the POS tag- ging results. As expected, our baseline (BiLSTM- CRF) model (accuracy 97.54%) performs on par  with other state-of-the-art systems. Built upon  this baseline, our adversarial training (AT) model  reaches accuracy 97.58% thanks to its regulariza- tion power, outperforming recent POS taggers ex- cept Ling et al. (2015). The improvement over the  baseline is statistically significant, with p-value <  0.05 on the t-test. We provide additional analysis  on this result in later sections.", "labels": [], "entities": [{"text": "POS tag- ging", "start_pos": 19, "end_pos": 32, "type": "TASK", "confidence": 0.7718792408704758}, {"text": "accuracy", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.9984771609306335}, {"text": "accuracy", "start_pos": 232, "end_pos": 240, "type": "METRIC", "confidence": 0.998918890953064}, {"text": "POS taggers", "start_pos": 307, "end_pos": 318, "type": "TASK", "confidence": 0.745401918888092}]}, {"text": " Table 2: POS tagging accuracy (test) for 27 UD v1.2  treebanks, with other recent works, Plank et al. (2016),  Berend (2017) and Nguyen et al. (2017). For Plank  et al. (2016), we include the traditional baselines TNT  and CRF, and their state-of-the-art model that employs  a multi-task BiLSTM. Languages with \u2022 are morpho- logically rich, and those at the bottom ('el' to 'ta') are  low-resource, containing less than 60k tokens in their  training sets.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.6918147206306458}, {"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9308676719665527}, {"text": "UD v1.2  treebanks", "start_pos": 45, "end_pos": 63, "type": "DATASET", "confidence": 0.6477182110150655}]}, {"text": " Table 3: POS tagging accuracy (test) on different sub- sets of words, categorized by their frequency of occur- rence in training. The second row shows the number  of tokens in the test set that are in each category. The  third and fourth rows show the performance of our two  models. Better scores are underlined. The biggest im- provement is in bold.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.7544107437133789}, {"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9459435939788818}, {"text": "occur- rence", "start_pos": 105, "end_pos": 117, "type": "METRIC", "confidence": 0.8848304351170858}]}, {"text": " Table 4: POS tagging accuracy (test) on neighboring  words. We cluster all words in the test set in the same  way as Table 3 and consider the tagging performance  on the neighbors (left and right) of these words in the  test text.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.6888677179813385}, {"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.820586085319519}]}, {"text": " Table 5: Sentence-level accuracy and downstream de- pendency parsing performance by our baseline / adver- sarial POS taggers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9880362749099731}, {"text": "de- pendency parsing", "start_pos": 49, "end_pos": 69, "type": "TASK", "confidence": 0.6218340247869492}]}, {"text": " Table 6: Cluster tightness evaluation for word embed- dings, based on the cosine similarity measure. Higher  scores indicate better clustering (cleaner word vector  distribution). Each row corresponds to word vectors 1)  at the beginning, 2) after baseline training, and 3) after  adversarial training.", "labels": [], "entities": []}, {"text": " Table 7: Average cluster tightness for word embed- dings trained with varied perturbation scale \u03b1 (0 indi- cates baseline training).", "labels": [], "entities": []}, {"text": " Table 8: Chunking F1 scores on the CoNLL-2000 task,  with other top performing models.", "labels": [], "entities": [{"text": "Chunking", "start_pos": 10, "end_pos": 18, "type": "TASK", "confidence": 0.9324747323989868}, {"text": "F1", "start_pos": 19, "end_pos": 21, "type": "METRIC", "confidence": 0.924290657043457}, {"text": "CoNLL-2000 task", "start_pos": 36, "end_pos": 51, "type": "DATASET", "confidence": 0.7948613166809082}]}, {"text": " Table 9: NER F1 scores on the CoNLL-2003 (English)  task, with other top performing models.", "labels": [], "entities": [{"text": "NER", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.6772301197052002}, {"text": "F1", "start_pos": 14, "end_pos": 16, "type": "METRIC", "confidence": 0.822510838508606}, {"text": "CoNLL-2003 (English)  task", "start_pos": 31, "end_pos": 57, "type": "DATASET", "confidence": 0.848889434337616}]}]}