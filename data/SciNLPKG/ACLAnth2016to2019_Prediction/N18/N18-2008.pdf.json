{"title": [{"text": "Automatic Dialogue Generation with Expressed Emotions", "labels": [], "entities": [{"text": "Automatic Dialogue Generation", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6082027653853098}]}], "abstractContent": [{"text": "Despite myriad efforts in the literature designing neural dialogue generation systems in recent years, very few consider putting restrictions on the response itself.", "labels": [], "entities": [{"text": "neural dialogue generation", "start_pos": 51, "end_pos": 77, "type": "TASK", "confidence": 0.7073372503121694}]}, {"text": "They learn from collections of past responses and generate one based on a given utterance without considering , speech act, desired style or emotion to be expressed.", "labels": [], "entities": []}, {"text": "In this research, we address the problem of forcing the dialogue generation to express emotion.", "labels": [], "entities": []}, {"text": "We present three models that either concatenate the desired emotion with the source input during the learning, or push the emotion in the decoder.", "labels": [], "entities": []}, {"text": "The results, evaluated with an emotion tagger, are encouraging with all three models, but present better outcome and promise with our model that adds the emotion vector in the decoder.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic dialogue generation () aims at generating human-like responses given a human-to-human dialogue history.", "labels": [], "entities": [{"text": "Automatic dialogue generation", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.721872866153717}]}, {"text": "Most conversational agents are specialized fora specific domain such as travel booking) and are typically finite state-based or template-based.", "labels": [], "entities": []}, {"text": "Open domain dialogue systems have seen a growing interest in recent years thanks to neural dialogue generation systems, based on deep learning models.", "labels": [], "entities": [{"text": "Open domain dialogue", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.6423951983451843}, {"text": "neural dialogue generation", "start_pos": 84, "end_pos": 110, "type": "TASK", "confidence": 0.711069236199061}]}, {"text": "These systems do not encode dialog structure and are entirely data-driven.", "labels": [], "entities": []}, {"text": "They learn to predict the maximum-likelihood estimation (MLE) based on a large training corpus.", "labels": [], "entities": [{"text": "maximum-likelihood estimation (MLE)", "start_pos": 26, "end_pos": 61, "type": "TASK", "confidence": 0.5449710488319397}]}, {"text": "The machine learning-based system basically learns to predict the words and the sentence to respond based on the previous utterances.", "labels": [], "entities": []}, {"text": "However, while such a system can generate grammatically correct and human-like answers, the responses are often generic and non-committal instead of being specific and emotionally intelligent.", "labels": [], "entities": []}, {"text": "For instance, we cannot dictate a particular emotion to express.", "labels": [], "entities": []}, {"text": "In this paper, we consider a model in which the wished emotion to be expressed is injected to direct the response generation.", "labels": [], "entities": [{"text": "response generation", "start_pos": 105, "end_pos": 124, "type": "TASK", "confidence": 0.7138623744249344}]}, {"text": "For example, if the user says: \"I just missed my deadline.\"", "labels": [], "entities": []}, {"text": "If we want the system to respond with sadness, it could be \"I am sorry to hear that.\", but we can also force the response to express anger: \"You should never do it again!\"", "labels": [], "entities": []}, {"text": "There are some challenges to tackle this task.", "labels": [], "entities": []}, {"text": "\u2022 The current neural dialogue models are not satisfactory in general.", "labels": [], "entities": []}, {"text": "\u2022 There is alack of dialogue corpora that are labeled with emotions.", "labels": [], "entities": []}, {"text": "\u2022 The evaluation is hard because emotion is subjective and sometimes ambiguous.", "labels": [], "entities": []}, {"text": "The idea is to use an emotion mining from text classifier () to predict the emotion or emotions expressed in the source utterance, then decide based on the detected emotions, which emotion e is expressed in the response.", "labels": [], "entities": []}, {"text": "The response is evaluated using the same emotion classifier and is declared successful if e is predicted from the response.", "labels": [], "entities": []}, {"text": "The emotion tagger we use is based on the work in () but uses a deep learning model and trains on 9 emotions: anger, disgust, fear, guilt, joy, love, sadness, surprise, and thankfulness.", "labels": [], "entities": []}, {"text": "These are based on the six basic emotions from Ekman's model, to which we added guilt, love and thankfulness in the context of an open ended conversational agent that we aim to be emotionally intelligent for companionship to elderly users.", "labels": [], "entities": []}, {"text": "In this paper, we proposed three approaches to make our model of our conversational agent generate responses expressing specific emotions.", "labels": [], "entities": []}, {"text": "The first two approaches add the emotion as a token with the input during the learning either before the utterance sentence or after, and the third approach injects the desired emotion directly in the decoder.", "labels": [], "entities": []}], "datasetContent": [{"text": "To train the dialogue models, we use the OpenSubtitles dataset.", "labels": [], "entities": [{"text": "OpenSubtitles dataset", "start_pos": 41, "end_pos": 62, "type": "DATASET", "confidence": 0.9702101349830627}]}, {"text": "Precisely, we use the pre-processed data by) and further removed duplicates.", "labels": [], "entities": []}, {"text": "The total amount of utterances is 11.3 million, each utterance has a minimal length of 6 words.", "labels": [], "entities": []}, {"text": "Since there is no existing dialogue data set labeled with emotions, we trained our own emotion classifier to tag the corpus.", "labels": [], "entities": []}, {"text": "We use the CBET dataset 1 (), it contains 9 emotions and 81k instances.", "labels": [], "entities": [{"text": "CBET dataset 1", "start_pos": 11, "end_pos": 25, "type": "DATASET", "confidence": 0.9272672931353251}]}, {"text": "Each instance is labeled with up to two emotions.", "labels": [], "entities": []}, {"text": "The emotions are anger, surprise, joy, love, sadness, fear, disgust, guilt, and thankfulness.", "labels": [], "entities": []}, {"text": "We train a bidirectional LSTM () model and achieve an F1-score of 68.4% with precision 49.1% and recall 52.9% on these emotions.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9996631145477295}, {"text": "precision", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9991198182106018}, {"text": "recall", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.9956756234169006}]}, {"text": "To tag the target utterances with higher confidence, we use a threshold to separate those utterances that do not express emotion.", "labels": [], "entities": []}, {"text": "34.01% are thus labeled as Non-emotion.", "labels": [], "entities": []}, {"text": "'Non-emotion' is treated as a special emotion when training the dialogue models, but it is not considered in the evaluation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Per class accuracy of generated response", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.5359997153282166}]}]}