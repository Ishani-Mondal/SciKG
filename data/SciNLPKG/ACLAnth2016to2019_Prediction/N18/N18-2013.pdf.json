{"title": [{"text": "Sentence Simplification with Memory-Augmented Neural Networks", "labels": [], "entities": [{"text": "Sentence Simplification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9540237784385681}]}], "abstractContent": [{"text": "Sentence simplification aims to simplify the content and structure of complex sentences, and thus make them easier to interpret for human readers, and easier to process for downstream NLP applications.", "labels": [], "entities": [{"text": "Sentence simplification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.921334445476532}]}, {"text": "Recent advances in neural machine translation have paved the way for novel approaches to the task.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 19, "end_pos": 45, "type": "TASK", "confidence": 0.7331186532974243}]}, {"text": "In this paper, we adapt an architecture with augmented memory capacities called Neural Semantic Encoders (Munkhdalai and Yu, 2017) for sentence simplification.", "labels": [], "entities": [{"text": "sentence simplification", "start_pos": 135, "end_pos": 158, "type": "TASK", "confidence": 0.7936743795871735}]}, {"text": "Our experiments demonstrate the effectiveness of our approach on different simplification datasets, both in terms of automatic evaluation measures and human judgments.", "labels": [], "entities": []}], "introductionContent": [{"text": "The goal of sentence simplification is to compose complex sentences into simpler ones so that they are more comprehensible and accessible, while still retaining the original information content and meaning.", "labels": [], "entities": [{"text": "sentence simplification", "start_pos": 12, "end_pos": 35, "type": "TASK", "confidence": 0.7159890532493591}]}, {"text": "Sentence simplification has a number of practical applications.", "labels": [], "entities": [{"text": "Sentence simplification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9629112780094147}]}, {"text": "On one hand, it provides reading aids for people with limited language proficiency (, or for patients with linguistic and cognitive disabilities).", "labels": [], "entities": []}, {"text": "On the other hand, it can improve the performance of other NLP tasks ().", "labels": [], "entities": []}, {"text": "Prior work has explored monolingual machine translation (MT) approaches, utilizing corpora of simplified texts, e.g., Simple English Wikipedia (SEW), and making use of statistical MT models, such as phrase-based MT (PBMT), tree-based MT (TBMT) (, or syntax-based MT (SBMT) ().", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 36, "end_pos": 60, "type": "TASK", "confidence": 0.8793537855148316}, {"text": "Simple English Wikipedia (SEW)", "start_pos": 118, "end_pos": 148, "type": "DATASET", "confidence": 0.755011702577273}]}, {"text": "Inspired by the success of neural MT), recent work has started exploring neural simplification with sequence to sequence (Seq2seq) models, also referred to as encoder-decoder models.", "labels": [], "entities": [{"text": "MT", "start_pos": 34, "end_pos": 36, "type": "TASK", "confidence": 0.8383730053901672}]}, {"text": "implemented a standard LSTM-based Seq2seq model and found that they outperform PBMT, SBMT, and unsupervised lexical simplification approaches.", "labels": [], "entities": []}, {"text": "viewed the encoder-decoder model as an agent and employed a deep reinforcement learning framework in which the reward has three components capturing key aspects of the target output: simplicity, relevance, and fluency.", "labels": [], "entities": [{"text": "simplicity", "start_pos": 183, "end_pos": 193, "type": "METRIC", "confidence": 0.9943766593933105}]}, {"text": "The common practice for Seq2seq models is to use recurrent neural networks (RNNs) with Long Short-Term Memory (LSTM, Hochreiter and Schmidhuber, 1997) or Gated Recurrent Unit (GRU,) for the encoder and decoder (.", "labels": [], "entities": []}, {"text": "These architectures were designed to be capable of memorizing long-term dependencies across sequences.", "labels": [], "entities": []}, {"text": "Nevertheless, their memory is typically small and might not be enough for the simplification task, where one is confronted with long and complicated sentences.", "labels": [], "entities": [{"text": "memory", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.9945617318153381}, {"text": "simplification task", "start_pos": 78, "end_pos": 97, "type": "TASK", "confidence": 0.8981195092201233}]}, {"text": "In this study, we go beyond the conventional LSTM/GRU-based Seq2seq models and propose to use a memory-augmented RNN architecture called Neural Semantic Encoders (NSE).", "labels": [], "entities": []}, {"text": "This architecture has been shown to be effective in a wide range of NLP tasks.", "labels": [], "entities": []}, {"text": "The contribution of this paper is twofold: (1) First, we present a novel simplification model which is, to the best of our knowledge, the first model that use memory-augmented RNN for the task.", "labels": [], "entities": []}, {"text": "We investigate the effectiveness of neural Seq2seq models when different neural architectures for the encoder are considered.", "labels": [], "entities": []}, {"text": "Our experiments reveal that the NSELSTM model that uses an: Attention-based encoder-decoder model.", "labels": [], "entities": []}, {"text": "The model may attend to relevant source information while decoding the simplification, e.g., to generate the target word won the model may attend to the source words received, nominated and Prize.", "labels": [], "entities": []}, {"text": "NSE as the encoder and an LSTM as the decoder performed the best among these models, improving over strong simplification systems.", "labels": [], "entities": [{"text": "NSE", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8834164142608643}]}, {"text": "(2) Second, we perform an extensive evaluation of various approaches proposed in the literature on different datasets.", "labels": [], "entities": []}, {"text": "Results of both automatic and human evaluation show that our approach is remarkably effective for the task, significantly reducing the reading difficulty of the input, while preserving grammaticality and the original meaning.", "labels": [], "entities": []}, {"text": "We further discuss some advantages and disadvantages of these approaches.", "labels": [], "entities": []}], "datasetContent": [{"text": "Following (, we experiment on three simplification datasets, namely: (1) Newsela (), a high-quality simplification corpus of news articles composed by Newsela 1 professional editors.", "labels": [], "entities": []}, {"text": "We used the split of the data in, a larger corpus in which the training set is a mixture of three Wikipedia datasets in (, and the development and test sests are complex sentences taken from WikiSmall, each has 8 simplifications written by Amazon Mechanical Turk workers (  We measured BLEU, and SARI at corpus-level following.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 286, "end_pos": 290, "type": "METRIC", "confidence": 0.998282790184021}, {"text": "SARI", "start_pos": 296, "end_pos": 300, "type": "METRIC", "confidence": 0.9713135957717896}]}, {"text": "In addition, we also evaluated system output by eliciting human judgments.", "labels": [], "entities": []}, {"text": "Specifically, we randomly selected 40 sentences from each test set, and included human reference simplifications and corresponding simplifications from the systems above 2 . We then asked three volunteers 3 to rate simplifications with respect to Fluency (the extent to which the output is grammatical English), Adequacy (the extent to which the output has the same meaning as the input sentence), and Simplicity (the extent to which the output is simpler than the input sentence) using a five point Likert scale.", "labels": [], "entities": [{"text": "Fluency", "start_pos": 247, "end_pos": 254, "type": "METRIC", "confidence": 0.9957386255264282}, {"text": "Simplicity", "start_pos": 402, "end_pos": 412, "type": "METRIC", "confidence": 0.8691343069076538}]}, {"text": "The results of the automatic evaluation are displayed in.", "labels": [], "entities": []}, {"text": "We first discuss the results on Newsela that contains high-quality simplifications composed by professional editors.", "labels": [], "entities": [{"text": "Newsela", "start_pos": 32, "end_pos": 39, "type": "DATASET", "confidence": 0.9563985466957092}]}, {"text": "In terms of BLEU, all neural models achieved much higher scores than PBMT-R and HYBRID.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 12, "end_pos": 16, "type": "METRIC", "confidence": 0.9986818432807922}]}, {"text": "NSELSTM-B scored highest with a BLEU score of 26.31.", "labels": [], "entities": [{"text": "NSELSTM-B", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9263115525245667}, {"text": "BLEU score", "start_pos": 32, "end_pos": 42, "type": "METRIC", "confidence": 0.9782377779483795}]}, {"text": "With regard to SARI, NSELSTM-S scored best among neural models   trained on a huge corpus of 106M sentence pairs and 2B words -scored highest on SARI with 39.96, followed by DRESS-LS (37.27), DRESS (37.08), and NSELSTM-S (36.88).", "labels": [], "entities": [{"text": "SARI", "start_pos": 15, "end_pos": 19, "type": "TASK", "confidence": 0.8710595369338989}, {"text": "DRESS-LS", "start_pos": 174, "end_pos": 182, "type": "METRIC", "confidence": 0.7251554131507874}, {"text": "DRESS", "start_pos": 192, "end_pos": 197, "type": "METRIC", "confidence": 0.5283989310264587}, {"text": "NSELSTM-S", "start_pos": 211, "end_pos": 220, "type": "DATASET", "confidence": 0.7763748168945312}]}], "tableCaptions": [{"text": " Table 1: Statistics for the training sets: the vocabulary  size (vocab size), and the average number of tokens per  sentence (#tokens/sent) of the source (src) and target  (tgt) language.", "labels": [], "entities": []}, {"text": " Table 2. We first discuss the results  on Newsela that contains high-quality simplifica- tions composed by professional editors. In terms  of BLEU, all neural models achieved much higher  scores than PBMT-R and HYBRID. NSELSTM-B  scored highest with a BLEU score of 26.31. With  regard to SARI, NSELSTM-S scored best among  neural models", "labels": [], "entities": [{"text": "Newsela", "start_pos": 43, "end_pos": 50, "type": "DATASET", "confidence": 0.9591005444526672}, {"text": "BLEU", "start_pos": 143, "end_pos": 147, "type": "METRIC", "confidence": 0.9981203675270081}, {"text": "BLEU", "start_pos": 253, "end_pos": 257, "type": "METRIC", "confidence": 0.9987598657608032}]}, {"text": " Table 5: Pearson correlation between the scores as- signed by humans and the automatic evaluation mea- sures. Scores marked  *  *  are significant at p < 0.01.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.8971537351608276}, {"text": "automatic evaluation mea- sures", "start_pos": 78, "end_pos": 109, "type": "METRIC", "confidence": 0.7338904500007629}]}]}