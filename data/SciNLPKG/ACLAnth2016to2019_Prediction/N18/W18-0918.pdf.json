{"title": [{"text": "Using Language Learner Data for Metaphor Detection", "labels": [], "entities": [{"text": "Metaphor Detection", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.7393113374710083}]}], "abstractContent": [{"text": "This article describes the system that participated in the shared task (ST) on metaphor detection (Leong et al., 2018) on the Vrije University Amsterdam Metaphor Corpus (VUA).", "labels": [], "entities": [{"text": "metaphor detection", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.8748562037944794}, {"text": "Vrije University Amsterdam Metaphor Corpus (VUA)", "start_pos": 126, "end_pos": 174, "type": "DATASET", "confidence": 0.7095225676894188}]}, {"text": "The ST was part of the workshop on processing figurative language at the 16th annual conference of the North American Chapter of the Association for Computational Linguistics (NAACL2018).", "labels": [], "entities": []}, {"text": "The system combines a small assertion of trending techniques, which implement matured methods from NLP and ML; in particular , the system uses word embeddings from standard corpora and from corpora representing different proficiency levels of language learners in a LSTM BiRNN architecture.", "labels": [], "entities": []}, {"text": "The system is available under the APLv2 open-source license.", "labels": [], "entities": [{"text": "APLv2 open-source", "start_pos": 34, "end_pos": 51, "type": "DATASET", "confidence": 0.8311744034290314}]}], "introductionContent": [{"text": "Ever since conceptual metaphor theory was laid out in, the most vexing question has remained a methodological one: how can conceptual metaphors be reliably identified in language use?", "labels": [], "entities": [{"text": "conceptual metaphor theory", "start_pos": 11, "end_pos": 37, "type": "TASK", "confidence": 0.8038217624028524}]}, {"text": "Although manual identification was put on a stronger methodological footing with the Metaphor Identification Procedure (MIP) and its elaboration into MIPVU (, fuzzy areas remain due to the fact that conceptual metaphors can vary between primary metaphors and complex metaphors (cf.).", "labels": [], "entities": [{"text": "manual identification", "start_pos": 9, "end_pos": 30, "type": "TASK", "confidence": 0.6371111422777176}]}, {"text": "Furthermore, highly conventionalized metaphorical expressions might not be processed in the same way as novel metaphors.", "labels": [], "entities": []}, {"text": "The core process of manual metaphor identification is not completely unproblematic either since it can be difficult to establish whether the meaning of a lexical unit in its context deviates from its basic meaning or not.", "labels": [], "entities": [{"text": "manual metaphor identification", "start_pos": 20, "end_pos": 50, "type": "TASK", "confidence": 0.7629387676715851}]}, {"text": "In the face of that slippery terrain, automatic metaphor identification emerges as an extremely challenging task.", "labels": [], "entities": [{"text": "automatic metaphor identification", "start_pos": 38, "end_pos": 71, "type": "TASK", "confidence": 0.6803587377071381}]}, {"text": "An increasing volume of research since the start of annual workshops at NAACL in 2013 has shown first promising results using different methods of automated metaphor identification (see for example and for previous events).", "labels": [], "entities": [{"text": "NAACL", "start_pos": 72, "end_pos": 77, "type": "DATASET", "confidence": 0.8902314305305481}, {"text": "metaphor identification", "start_pos": 157, "end_pos": 180, "type": "TASK", "confidence": 0.7797597646713257}]}, {"text": "The current shared task of metaphor identification provided a further opportunity to put the computational spotting of metaphors to the test.", "labels": [], "entities": [{"text": "metaphor identification", "start_pos": 27, "end_pos": 50, "type": "TASK", "confidence": 0.898572564125061}, {"text": "computational spotting of metaphors", "start_pos": 93, "end_pos": 128, "type": "TASK", "confidence": 0.8026176244020462}]}, {"text": "Our bid for this task combines (cf. Section 2) fastText word embeddings (WEs) with a single-layer long short-term memory bidirectional recurrent neural network (BiRNN) architecture.", "labels": [], "entities": []}, {"text": "The input, sequences of WE representations of words, is fed into the BiRNN which predicts metaphorical usage for each word.", "labels": [], "entities": [{"text": "BiRNN", "start_pos": 69, "end_pos": 74, "type": "METRIC", "confidence": 0.9604325294494629}]}, {"text": "The WEs were trained (cf. Section 4.2) on different large corpora (BNC, Wikipedia, enTenTen13, ukWaC) and on the Vienna-Oxford International Corpus of English (VOICE) as well as on the TOEFL11 Corpus of Non-Native English.", "labels": [], "entities": [{"text": "WEs", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.8873316645622253}, {"text": "Vienna-Oxford International Corpus of English (VOICE)", "start_pos": 113, "end_pos": 166, "type": "DATASET", "confidence": 0.9103484973311424}, {"text": "TOEFL11 Corpus of Non-Native English", "start_pos": 185, "end_pos": 221, "type": "DATASET", "confidence": 0.9657425165176392}]}, {"text": "The latter corpus was used, among others, in the First Native Language Identification Shared Task (  held at the 8th Workshop on Innovative Use of NLP for Building Educational Applications as part of NAACL-HLT 2013.", "labels": [], "entities": [{"text": "First Native Language Identification Shared Task", "start_pos": 49, "end_pos": 97, "type": "TASK", "confidence": 0.7486697236696879}, {"text": "NAACL-HLT 2013", "start_pos": 200, "end_pos": 214, "type": "DATASET", "confidence": 0.8291986584663391}]}, {"text": "We were led by the idea (cf. Section 2.3) that metaphorical language use changes while gaining proficiency in a language, and so we hoped to be able to utilise the information contained in corpora of different proficiency levels.", "labels": [], "entities": []}, {"text": "The paper is organised as follows: We present our system design with related work in Section 2, the implementation in Section 3, and the experimental setup with an evaluation in Section 4.", "labels": [], "entities": []}, {"text": "Section 5 concludes with an outlook on possible next steps.", "labels": [], "entities": []}], "datasetContent": [{"text": "Participants of the ST could either participate in the metaphor prediction tracks for verbs only, all content part-of-speech only, or both.", "labels": [], "entities": [{"text": "metaphor prediction", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.7111373394727707}]}, {"text": "For a given text in VUA, and for each sentence, the task was to predict metaphoricity for each verb or content word respectively, and submit the result to CodaLab 4 for evaluation.", "labels": [], "entities": [{"text": "VUA", "start_pos": 20, "end_pos": 23, "type": "DATASET", "confidence": 0.906438410282135}]}, {"text": "Results were calculated as the harmonic average of the precision and recall (F1-score) of the metaphoricity label.", "labels": [], "entities": [{"text": "precision", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.9995493292808533}, {"text": "recall", "start_pos": 69, "end_pos": 75, "type": "METRIC", "confidence": 0.9973351359367371}, {"text": "F1-score", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9880298972129822}]}, {"text": "We participated with our system in both tasks.", "labels": [], "entities": []}, {"text": "The remainder of this section introduces the official data set, our WE models and describes our fixed hyper-parameters.", "labels": [], "entities": []}, {"text": "The results of different combinations of WE models are shown in.", "labels": [], "entities": []}, {"text": "Also note that all results in this paper refer only to the all content part-of-speech task.", "labels": [], "entities": []}], "tableCaptions": []}