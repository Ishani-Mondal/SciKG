{"title": [{"text": "Document-based Recommender System for Job Postings using Dense Representations", "labels": [], "entities": []}], "abstractContent": [{"text": "Job boards and professional social networks heavily use recommender systems in order to better support users in exploring job advertisements.", "labels": [], "entities": []}, {"text": "Detecting the similarity between job advertisements is important for job recommendation systems as it allows, for example, the application of item-to-item based recommendations.", "labels": [], "entities": [{"text": "Detecting the similarity between job advertisements", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.7968402802944183}]}, {"text": "In this work, we research the usage of dense vector representations to enhance a large-scale job recommendation system and to rank German job advertisements regarding their similarity.", "labels": [], "entities": []}, {"text": "We follow a two-folded evaluation scheme: (1) we exploit historic user interactions to automatically create a dataset of similar jobs that enables an offline evaluation.", "labels": [], "entities": []}, {"text": "(2) In addition, we conduct an online A/B test and evaluate the best performing method on our platform reaching more than 1 million users.", "labels": [], "entities": [{"text": "A/B test", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.8792368769645691}]}, {"text": "We achieve the best results by combining job titles with full-text job descriptions.", "labels": [], "entities": []}, {"text": "In particular, this method builds dense document representation using words of the titles to weigh the importance of words of the full-text description.", "labels": [], "entities": []}, {"text": "In the online evaluation, this approach allows us to increase the click-through rate on job recommendations for active users by 8.0%.", "labels": [], "entities": [{"text": "click-through rate", "start_pos": 66, "end_pos": 84, "type": "METRIC", "confidence": 0.9280375838279724}]}], "introductionContent": [{"text": "Recommender systems aim at providing recommendations for services that are targeted to specific users.", "labels": [], "entities": []}, {"text": "The majority of such systems are applied in the field of e-commerce for e.g. product recommendations (.", "labels": [], "entities": []}, {"text": "In businessoriented networking platforms, recommender systems propose job recommendations to users.", "labels": [], "entities": []}, {"text": "In this deployment paper, we target the development of content-based methods for job recommendations focusing on German job advertisements.", "labels": [], "entities": []}, {"text": "Based on our social online platform for professionals, 45% of the traffic is driven by recommendation services for job postings.", "labels": [], "entities": []}, {"text": "Thus, improving the job recommendations is expected to result in higher user interactions.", "labels": [], "entities": []}, {"text": "Our online platform's infrastructure consists of several recommendation stages in order to recommend job postings to users.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the so-called More-Like-This (MLT) component that recommends job postings based on previous users interactions with other job postings.", "labels": [], "entities": []}, {"text": "Our current system consists of an ensemble of recommendation retrieval, filtering and re-ranking stages in order to recommend relevant job postings to users.", "labels": [], "entities": []}, {"text": "For this, it exploits metadata of a job posting like keywords, disciplines and industries in which the job is categorized.", "labels": [], "entities": []}, {"text": "There are multiple issues when using exact keywords or category matching for ranking job postings.", "labels": [], "entities": [{"text": "ranking job postings", "start_pos": 77, "end_pos": 97, "type": "TASK", "confidence": 0.7981242537498474}]}, {"text": "First, the document collection, with over 1 million job postings, is fairly huge and too diverse to fit into the small number of available categories, e.g. 22 disciplines such as Law or Media.", "labels": [], "entities": []}, {"text": "Second, strict word matching leads to recall issues, for instance, J2EE Developer will not be similar to Software Engineer.", "labels": [], "entities": [{"text": "word matching", "start_pos": 15, "end_pos": 28, "type": "TASK", "confidence": 0.7162957638502121}, {"text": "recall", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.998089611530304}, {"text": "J2EE Developer", "start_pos": 67, "end_pos": 81, "type": "DATASET", "confidence": 0.8878524899482727}]}, {"text": "Thus, employing a sparse vector representation is not appropriate for retrieving similarities between job postings.", "labels": [], "entities": []}, {"text": "In addition, due to the cold start problem (), using solely metadata of job postings or users is not suitable, especially for new users, for which only marginal or no information exists.", "labels": [], "entities": []}, {"text": "Furthermore, metadata can be entirely missing or incorrect (e.g. outdated or on purpose).", "labels": [], "entities": []}, {"text": "Consequently, we will compute similarities between job postings based on dense vector representations.", "labels": [], "entities": []}, {"text": "Recent document embedding techniques learn meaningful syntactic and semantic relationships based on word occurrences in the text.", "labels": [], "entities": []}, {"text": "In this paper, we use dense vector representation of documents to score similarities between job postings based on their full-text descriptions and titles.", "labels": [], "entities": []}, {"text": "First, we create a dataset for an offline eval-uation consisting of similar job postings based on user co-interactions.", "labels": [], "entities": []}, {"text": "Then, we construct an evaluation metric based on the classification of similar and non-similar items.", "labels": [], "entities": []}, {"text": "Testing multiple embedding models and weighting functions, the best performance is achieved when building embeddings based on the job description with an increased weight for words that appear in the job title.", "labels": [], "entities": []}, {"text": "Finally, the model is used in an online A/B test to assert its performance on live data.", "labels": [], "entities": [{"text": "A/B", "start_pos": 40, "end_pos": 43, "type": "METRIC", "confidence": 0.7117788791656494}]}], "datasetContent": [{"text": "The two jobs with the titles Java Developer, Hamburg and Java Backend Developer, Stuttgart are examples of two very similar job postings with different locations.", "labels": [], "entities": [{"text": "Hamburg", "start_pos": 45, "end_pos": 52, "type": "DATASET", "confidence": 0.8350099921226501}]}, {"text": "Due to the location difference they fit to two different types of users: those who live close to Stuttgart and those close to Hamburg.", "labels": [], "entities": []}, {"text": "For the creation of our dataset we consider the following: if there is no user co-interaction between two jobs, they will not be considered similar in the dataset.", "labels": [], "entities": []}, {"text": "The same applies to similar jobs postings with large creation timestamp differences.", "labels": [], "entities": []}, {"text": "For example, users that have been interested in jobs posted in 2014, might not be interested in similar jobs posted in 2017.", "labels": [], "entities": []}, {"text": "Inspired by the information retrieval-based evaluation approach by, we created our dataset.", "labels": [], "entities": [{"text": "information retrieval-based evaluation", "start_pos": 16, "end_pos": 54, "type": "TASK", "confidence": 0.7751432855923971}]}, {"text": "In their approach, they created triples (s, p, n) that consists of a paragraphs, a similar paragraph p and a non-similar randomly sampled paragraph n.", "labels": [], "entities": []}, {"text": "Inspired by this dataset, negative sampling in Word2Vec and cross validation, we extended the approach to construct a dataset of positive and negative samples as described in Algorithm 1.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 47, "end_pos": 55, "type": "DATASET", "confidence": 0.9757168889045715}]}, {"text": "For each job, we create 10 folds of 10 similar and 40 non-similar jobs.", "labels": [], "entities": []}, {"text": "This algorithm returns a list of triplets consisting of the job j, a list of similar jobs P os f and a F old f .append(n i ) shuffle(F old f ) output.append((j, P os f , F old f )) return output A list of triplets shuffled list F old f of similar and non similar job postings to the job j.", "labels": [], "entities": []}, {"text": "During evaluation, every job posting in the shuffled F old f is compared to the corresponding job j to compute a similarity score, which is used to rearrange F old f . The precision measure is used to compare the list cutout at 10 (retrieved), and the relevant job postings in P os f . Sampling \"negative job postings\" from the entire dataset, we reduce the chance of fetching similar job postings that our dataset did not capture.", "labels": [], "entities": [{"text": "similarity score", "start_pos": 113, "end_pos": 129, "type": "METRIC", "confidence": 0.9453776180744171}, {"text": "precision", "start_pos": 172, "end_pos": 181, "type": "METRIC", "confidence": 0.999213695526123}]}, {"text": "To reduce the chance of false negatives, we increase the size of the dataset by randomly generating 10 lists for each job, resulting in a dataset of 112,000 distinct job postings and 12,000 shuffled lists.", "labels": [], "entities": []}, {"text": "In, we show the similarity between job titles (we translated them from German to English) based on a Doc2VecC model (500 dim vectors, 10 window size, 15 negative sampling, 20 iterations) using T-SNE.", "labels": [], "entities": []}, {"text": "The job colored in black (Lean Java Expert Munich) represents the job being evaluated, and the gray ones represent similar (positive) job postings sampled from our user interactions.", "labels": [], "entities": [{"text": "Lean Java Expert Munich)", "start_pos": 26, "end_pos": 50, "type": "DATASET", "confidence": 0.7214719176292419}]}, {"text": "The remaining jobs depict non-similar (negative) jobs sampled from the entire corpus.", "labels": [], "entities": []}, {"text": "Based on the figure we have three observations: first, most positive jobs are closest to the queried job and focus on the same topic, namely Java development.", "labels": [], "entities": []}, {"text": "Second, some of the \"negative\" jobs are relevant, e.g. FrontEnd developer and Teamleader in IT Development, and have a close distance to the queried job.", "labels": [], "entities": [{"text": "IT Development", "start_pos": 92, "end_pos": 106, "type": "TASK", "confidence": 0.6506136953830719}]}, {"text": "Third, we observe multiple clusters: for example, in the upper right corner we observe a \"media management\" cluster, and in the center a \"project management\" cluster.", "labels": [], "entities": []}, {"text": "In this section, we first report results that are computed based on full-text job descriptions.", "labels": [], "entities": []}, {"text": "Then, we exploit the performance using the job titles.", "labels": [], "entities": []}, {"text": "To complete our experiments we show results for the combination of job titles and job descriptions.", "labels": [], "entities": []}, {"text": "In our experiments, we use commonly used hyperparameters.", "labels": [], "entities": []}, {"text": "We tested different combinations of window size (2, 5, 10), model choice (skipgram vs. continuous bag of words) and number of dimensions (100, 250, 500) and picked the following hyperparameters for the rest of the experiments: skip-gram model with vector size of 500, window size of 10, 15 words for negative sampling, 20 iterations and a threshold for the minimum count of 5.", "labels": [], "entities": []}, {"text": "Due to the ranking nature of the task, we report results based on the precision at 10 (P@10) score considering the ten highest ranked jobs.", "labels": [], "entities": [{"text": "precision at 10 (P@10) score", "start_pos": 70, "end_pos": 98, "type": "METRIC", "confidence": 0.7890301280551486}]}, {"text": "Since we have 10 positive similar job postings in each list, the P@10 can be interpreted as an average percentage of jobs in the top 10 which are actually similar and can have a maximum value of 100%.", "labels": [], "entities": [{"text": "P@10", "start_pos": 65, "end_pos": 69, "type": "METRIC", "confidence": 0.9307952125867208}]}, {"text": "Full-Text Job Description: As a baseline we represent each job as a word vector of TF-IDF scores based on the job description and use the cosine similarity for re-ranking the jobs (see).", "labels": [], "entities": []}, {"text": "This baseline performs lowest with a P@10 score of 8.69% showing that such a sparse representation is insufficient to identify similarities between documents.: Precision scores of word embedding models using full-text description only.", "labels": [], "entities": [{"text": "P@10 score", "start_pos": 37, "end_pos": 47, "type": "METRIC", "confidence": 0.9346431642770767}, {"text": "Precision", "start_pos": 160, "end_pos": 169, "type": "METRIC", "confidence": 0.9758701324462891}]}, {"text": "The existing recommender system uses Elasticsearch 4 to retrieve job postings based on the user's 4 https://www.elastic.co metadata, then exploits the user's previous interactions with job postings to rank the recommendations in a doc-to-doc similarity fashion via TF-IDF.", "labels": [], "entities": []}, {"text": "This is used as a ranking baseline.", "labels": [], "entities": []}, {"text": "For our online evaluations, we use the retrieval module from Elasticsearch, and plug our fastest and best performing job representation (title weighted Doc2VecC) model into anew system to re-rank the retrieved documents.", "labels": [], "entities": []}, {"text": "Before we performed the online evaluation, we analyzed whether the results with the A/B test will differ using different semantic representation, to prove whether the A/B test will lead to any meaningful result.", "labels": [], "entities": []}, {"text": "For this, we re-rank the same retrieved recommendations for 2000 users sampled from the most active users on the platform.", "labels": [], "entities": []}, {"text": "As shown in, the intersected (common) recommendations (\u00b5) between the two systems does not exceed 36% for all K ranks in the recommendation lists, with a decreasing standard deviation (\u03c3).", "labels": [], "entities": [{"text": "intersected (common) recommendations (\u00b5)", "start_pos": 17, "end_pos": 57, "type": "METRIC", "confidence": 0.7939466685056686}, {"text": "standard deviation (\u03c3)", "start_pos": 165, "end_pos": 187, "type": "METRIC", "confidence": 0.8922753214836121}]}, {"text": "This reveals that the changes have huge impact on the rankings.", "labels": [], "entities": []}, {"text": "In addition, we analyze the average distance in kilometers (km) of the recommended job postings to the user's location.", "labels": [], "entities": []}, {"text": "The new model favors to rank jobs with closer distance at higher position: the top 4 recommendations are 30% closer and even 60% closer for the top 50 jobs.", "labels": [], "entities": []}, {"text": "This is an important finding, as we hypothesize that users prefer jobs that are closer to their location.", "labels": [], "entities": []}, {"text": "Job locations are usually included in the title, allowing vectors of cities to contribute higher in the title weighted averaging approach.", "labels": [], "entities": []}, {"text": "To perform the A/B test, we conduct a controlled experiment by selecting active users (with at least a single previous job interaction) and split them into two groups: one group gets job posting recommendations ranked by the Elasticsearch, and the second group gets job posting recommendations ranked by our best system (title weighted Doc2VecC model).", "labels": [], "entities": [{"text": "A/B", "start_pos": 15, "end_pos": 18, "type": "METRIC", "confidence": 0.788224438826243}]}, {"text": "First, we apply an A/A test () to test for any split bias: both groups get recommendations from the existing system for 30 days.", "labels": [], "entities": [{"text": "A/A test", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9056707918643951}]}, {"text": "Then, the A/B testis conducted over the period of 20 days.", "labels": [], "entities": [{"text": "A/B testis", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.8456471562385559}]}, {"text": "The success metric is the Click-ThroughRate (CTR), which is the percentage of clicked items considering all items that have been shown to the users.", "labels": [], "entities": [{"text": "Click-ThroughRate (CTR)", "start_pos": 26, "end_pos": 49, "type": "METRIC", "confidence": 0.7347192615270615}]}, {"text": "Thus, the more items users interact with, the higher the CTR and the more successful is the algorithm.", "labels": [], "entities": [{"text": "CTR", "start_pos": 57, "end_pos": 60, "type": "METRIC", "confidence": 0.9415218234062195}]}], "tableCaptions": [{"text": " Table 3: Pre-analysis for the A/B test. We show the  mean and standard deviation of common recom- mendations returned by the systems on different  ranks K, and the average distance of job postings  to the user in kilometers (km).", "labels": [], "entities": [{"text": "A/B", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.8349211613337199}, {"text": "standard deviation of common recom- mendations returned", "start_pos": 63, "end_pos": 118, "type": "METRIC", "confidence": 0.8359992355108261}]}]}