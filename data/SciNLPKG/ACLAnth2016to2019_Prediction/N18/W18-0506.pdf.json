{"title": [], "abstractContent": [{"text": "We present the task of second language acquisition (SLA) modeling.", "labels": [], "entities": [{"text": "second language acquisition (SLA) modeling", "start_pos": 23, "end_pos": 65, "type": "TASK", "confidence": 0.8120103904179165}]}, {"text": "Given a history of errors made by learners of a second language, the task is to predict errors that they are likely to make at arbitrary points in the future.", "labels": [], "entities": []}, {"text": "We describe a large corpus of more than 7M words produced by more than 6k learners of English, Spanish, and French using Duolingo, a popular online language-learning app.", "labels": [], "entities": []}, {"text": "Then we report on the results of a shared task challenge aimed studying the SLA task via this corpus, which attracted 15 teams and synthesized work from various fields including cognitive science, linguistics , and machine learning.", "labels": [], "entities": [{"text": "SLA task", "start_pos": 76, "end_pos": 84, "type": "TASK", "confidence": 0.9088813960552216}]}], "introductionContent": [{"text": "As computer-based educational apps increase in popularity, they generate vast amounts of student learning data which can be harnessed to drive personalized instruction.", "labels": [], "entities": []}, {"text": "While there have been some recent advances for educational software in domains like mathematics, learning a language is more nuanced, involving the interaction of lexical knowledge, morpho-syntactic processing, and several other skills.", "labels": [], "entities": []}, {"text": "Furthermore, most work that has applied natural language processing to language learner data has focused on intermediate-toadvanced students of English, particularly in assessment settings.", "labels": [], "entities": []}, {"text": "Much less work has been devoted to beginners, learners of languages other than English, or ongoing study overtime.", "labels": [], "entities": []}, {"text": "We propose second language acquisition (SLA) modeling as anew computational task to help broaden our understanding in this area.", "labels": [], "entities": [{"text": "second language acquisition (SLA) modeling", "start_pos": 11, "end_pos": 53, "type": "TASK", "confidence": 0.8118653127125331}]}, {"text": "First, we describe anew corpus of language learner data, containing more than 7.1M words, annotated for production errors that were made by more than 6.4k learners of English, Spanish, and French, during their first 30 days of learning with Duolingo (a popular online language-learning app).", "labels": [], "entities": []}, {"text": "Then we report on the results of a \"shared task\" challenge organized by the authors using this SLA modeling corpus, which brought together 15 research teams.", "labels": [], "entities": [{"text": "SLA modeling corpus", "start_pos": 95, "end_pos": 114, "type": "DATASET", "confidence": 0.7729605038960775}]}, {"text": "Our goal for this work is threefold: (1) to synthesize years of research in cognitive science, linguistics, and machine learning, (2) to facilitate cross-dialog among these disciplines through a common large-scale empirical task, and in so doing (3) to shed light on the most effective approaches to SLA modeling.", "labels": [], "entities": [{"text": "SLA modeling", "start_pos": 300, "end_pos": 312, "type": "TASK", "confidence": 0.985816478729248}]}], "datasetContent": [{"text": "We use area under the ROC curve (AUC) as the primary evaluation metric for SLA modeling).", "labels": [], "entities": [{"text": "ROC curve (AUC)", "start_pos": 22, "end_pos": 37, "type": "METRIC", "confidence": 0.8790251970291137}, {"text": "SLA modeling", "start_pos": 75, "end_pos": 87, "type": "TASK", "confidence": 0.9138563573360443}]}, {"text": "AUC is a common measure of ranking quality in classification tasks, and can be interpreted as the probability that the system will rank a randomly-chosen error above a randomlychosen non-error.", "labels": [], "entities": [{"text": "AUC", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.8403681516647339}]}, {"text": "We argue that this notion of ranking quality is particularly useful for evaluating systems that might be used for personalized learning, e.g., if we wish to prioritize words or exercises for an individual learner's review based on how likely they are to have forgotten or make errors at a given point in time.", "labels": [], "entities": []}, {"text": "We also report F1 score-the harmonic mean of precision and recall-as a secondary metric, since it is more common in similar skewed-class labeling tasks (e.g.,.", "labels": [], "entities": [{"text": "F1 score-the harmonic mean of", "start_pos": 15, "end_pos": 44, "type": "METRIC", "confidence": 0.945742666721344}, {"text": "precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.7482753396034241}, {"text": "recall-as", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9902825355529785}]}, {"text": "Note, however, that F1 can be significantly improved simply by tuning the classification threshold (fixed at 0.5 for our evaluations) without affecting AUC.", "labels": [], "entities": [{"text": "F1", "start_pos": 20, "end_pos": 22, "type": "METRIC", "confidence": 0.9992448091506958}, {"text": "AUC", "start_pos": 152, "end_pos": 155, "type": "METRIC", "confidence": 0.8536233901977539}]}], "tableCaptions": [{"text": " Table 2: Final results. Ranks (\u2191) are determined by statistical ties (see text). Markers indicate which systems  include recurrent neural architectures (\u2662), decision tree ensembles (\u2663), or a multitask model across all tracks ( \u2021).", "labels": [], "entities": []}, {"text": " Table 3: Mixed-effects analysis of learning algorithms.", "labels": [], "entities": []}, {"text": " Table 5: AUC results for the ensemble analysis.", "labels": [], "entities": [{"text": "AUC", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.8711163401603699}]}]}