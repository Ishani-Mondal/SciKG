{"title": [{"text": "Selecting Machine-Translated Data for Quick Bootstrapping of a Natural Language Understanding System", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper investigates the use of Machine Translation (MT) to bootstrap a Natural Language Understanding (NLU) system fora new language for the use case of a large-scale voice-controlled device.", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 35, "end_pos": 59, "type": "TASK", "confidence": 0.8715901732444763}]}, {"text": "The goal is to decrease the cost and time needed to get an annotated corpus for the new language, while still having a large enough coverage of user requests.", "labels": [], "entities": []}, {"text": "Different methods of filtering MT data in order to keep utterances that improve NLU performance and language-specific post-processing methods are investigated.", "labels": [], "entities": [{"text": "MT", "start_pos": 31, "end_pos": 33, "type": "TASK", "confidence": 0.8801791667938232}]}, {"text": "These methods are tested in a large-scale NLU task with translating around 10 millions training utterances from English to German.", "labels": [], "entities": []}, {"text": "The results show a large improvement for using MT data over a grammar-based and over an in-house data collection baseline, while reducing the manual effort greatly.", "labels": [], "entities": [{"text": "MT", "start_pos": 47, "end_pos": 49, "type": "TASK", "confidence": 0.984308660030365}]}, {"text": "Both filtering and post-processing approaches improve results further.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, there has been growing interest in voice-controlled devices, such as Amazon Alexa or Google home.", "labels": [], "entities": []}, {"text": "This success makes the quick bootstrapping of corresponding systems, including NLU models, for new languages a prioritised goal.", "labels": [], "entities": []}, {"text": "However, building anew NLU model for each language from scratch and gathering the necessary annotated corpora implies a significant amount of human time and effort both by annotators and scientists.", "labels": [], "entities": []}, {"text": "In addition, this procedure is not scalable to supporting an increasing number of languages.", "labels": [], "entities": []}, {"text": "On the other hand, a large amount of data is usually available for the language(s) that are already supported.", "labels": [], "entities": []}, {"text": "Leveraging this source of data seems an obvious solution.", "labels": [], "entities": []}, {"text": "In this paper, The author Rajen Chatterjee conducted the work for this paper during an internship at Amazon, Cambridge, UK we investigate the use of Machine Translation to translate existing data sources to anew target language and use them to bootstrap an NLU system for this target language.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 149, "end_pos": 168, "type": "TASK", "confidence": 0.7163567543029785}]}, {"text": "A common procedure for data gathering fora new language starts by some grammar-generated data.", "labels": [], "entities": [{"text": "data gathering", "start_pos": 23, "end_pos": 37, "type": "TASK", "confidence": 0.7381316721439362}]}, {"text": "Significant time and effort is consumed at this stage by language specialists to build grammars that offer a good coverage needed fora first working system.", "labels": [], "entities": []}, {"text": "Once this first system reaches a certain performance threshold, it can be shared with beta users.", "labels": [], "entities": []}, {"text": "This step allows more data that cover real user's queries to be generated.", "labels": [], "entities": []}, {"text": "All existing data sources are then used to train the system that will be released to the final customers, once anew higher performance threshold is reached.", "labels": [], "entities": []}, {"text": "Finally, when the system is released to the customers, customer data become available.", "labels": [], "entities": []}, {"text": "Beta and customer data better cover the user utterances than grammar-generated data and are, thus, valuable for the development of a good and generalisable NLU system.", "labels": [], "entities": []}, {"text": "However, it takes a significant amount of time and human annotation effort in order to have enough annotated beta, and later customer data, needed to build a good NLU system.", "labels": [], "entities": []}, {"text": "Furthermore, having a system robust to new domains and features is very challenging and requires data with a wide coverage.", "labels": [], "entities": []}, {"text": "Machine Translation can be a useful tool for the quick expansion to new languages by automatically translating customer data from existing resources to new languages.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7984414398670197}]}, {"text": "This could decrease significantly the time needed to develop an NLU system that replies well to customer queries and is robust to new features.", "labels": [], "entities": []}, {"text": "In this paper, we work with a large-scale system where around 10 millions annotated customer data are available for US English with a wide coverage of domains and features.", "labels": [], "entities": []}, {"text": "We use this corpus to augment the training data of anew language.", "labels": [], "entities": []}, {"text": "In particular, we will present our experiments on applying our technique to bootstrap a German NLU system based on existing US English training data.", "labels": [], "entities": [{"text": "US English training data", "start_pos": 124, "end_pos": 148, "type": "DATASET", "confidence": 0.5850585997104645}]}, {"text": "In addition, we explore ways to choose the \"good\" translations from the translated ones, i.e. the ones that improve the NLU performance.", "labels": [], "entities": []}, {"text": "The investigated methods fall in the following categories.", "labels": [], "entities": []}, {"text": "First, we investigate filtering based on MT quality.", "labels": [], "entities": [{"text": "MT", "start_pos": 41, "end_pos": 43, "type": "TASK", "confidence": 0.975650429725647}]}, {"text": "This method makes use of scores generated by the MT model to assign the quality of translations.", "labels": [], "entities": []}, {"text": "The second method explores improving the NLU performance by making sure the filtered translations keep the semantic information required by the NLU system.", "labels": [], "entities": []}, {"text": "In this case, the matching of the NLU labels after a backward translation task is used as the filtering criterion.", "labels": [], "entities": []}, {"text": "Lastly, some language-specific post-processing is applied on the translation output.", "labels": [], "entities": []}, {"text": "This includes resampling data with catalogues of the new language.", "labels": [], "entities": []}, {"text": "Another post-processing step applied is to keep the original (EN) version of certain slots that the users tend to leave untranslated.", "labels": [], "entities": []}, {"text": "This paper is organised as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we give an overview of related literature.", "labels": [], "entities": []}, {"text": "In Section 3, we present the methods for MT filtering for bootstrapping anew language while improving NLU performance.", "labels": [], "entities": [{"text": "MT filtering", "start_pos": 41, "end_pos": 53, "type": "TASK", "confidence": 0.9939253926277161}]}, {"text": "Next, we detail the experimental setup in section 4, including details on the used NLU and MT systems as well as the monolingual and bilingual corpora used.", "labels": [], "entities": []}, {"text": "Afterwards, we present results in Section 5 before concluding the paper in Section 6 .", "labels": [], "entities": []}], "datasetContent": [{"text": "We ran experiments using US English as the source and German as the target language.", "labels": [], "entities": []}, {"text": "Since we are interested in bootstrapping an NLU model fora new language which would first be deployed to beta customers, we evaluate our approach on German beta data.", "labels": [], "entities": [{"text": "German beta data", "start_pos": 149, "end_pos": 165, "type": "DATASET", "confidence": 0.834882398446401}]}, {"text": "In the following, we first briefly describe the MT and NLU systems and subsequently the datasets.", "labels": [], "entities": []}, {"text": "We translated 10M of training data utterances from a US English NLU system.", "labels": [], "entities": [{"text": "US English NLU system", "start_pos": 53, "end_pos": 74, "type": "DATASET", "confidence": 0.7307896092534065}]}, {"text": "Overall, the data cover several domains with a large number of different intents and slots/named entities.", "labels": [], "entities": []}, {"text": "We translated the data using the previously described MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 54, "end_pos": 56, "type": "TASK", "confidence": 0.8715100884437561}]}, {"text": "NLU labels were kept and aligned during the MT decoding to project them from the English source utterances to the corresponding German translations.", "labels": [], "entities": [{"text": "MT decoding", "start_pos": 44, "end_pos": 55, "type": "TASK", "confidence": 0.7707762122154236}]}, {"text": "The final training dataset comprised 9,963,624 utterances.", "labels": [], "entities": []}, {"text": "For testing, we created a dataset collected from German Beta users; German test data were manually transcribed and annotated with intents and slots/named entities.", "labels": [], "entities": []}, {"text": "The resulting test dataset comprised 119,772 utterances.", "labels": [], "entities": []}, {"text": "To create a baseline, we used an in-house data collection of 10k utterances, which were manually transcribed and annotated with intents and slots.", "labels": [], "entities": []}, {"text": "While in-house data collections are costly and time-consuming, they constitute a reasonable approach for bootstrapping a model from scratch when customer data are not yet available.", "labels": [], "entities": []}, {"text": "The data amounts are summarised in In addition, we created a grammar-based baseline.", "labels": [], "entities": []}, {"text": "In particular, we randomly sampled utterances from grammars and created a training dataset from them.", "labels": [], "entities": []}, {"text": "For this, we used around 200 grammars written by language experts covering (most) intents and slots supported by the NLU system.", "labels": [], "entities": []}, {"text": "However, one of the domains was not covered by grammars, because it supports very diverse features and requests, which are difficult to capture by a grammar.", "labels": [], "entities": []}, {"text": "We report results by means of a semantic error rate (SemER) which is computed based on the number of insertions, deletions and substitutions for slots and the intent in a recognised utterance compared to a reference utterance, i.e. SemER = # (slot + intent errors) # (slots + intents in reference)", "labels": [], "entities": [{"text": "semantic error rate (SemER)", "start_pos": 32, "end_pos": 59, "type": "METRIC", "confidence": 0.8246147086222967}]}], "tableCaptions": [{"text": " Table 3: Results of the filtering approaches. Relative changes with respect to the baseline are given in parentheses.", "labels": [], "entities": [{"text": "Relative", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9842081665992737}]}]}