{"title": [{"text": "Diverse Few-Shot Text Classification with Multiple Metrics", "labels": [], "entities": [{"text": "Diverse Few-Shot Text Classification", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.727201446890831}]}], "abstractContent": [{"text": "We study few-shot learning in natural language domains.", "labels": [], "entities": []}, {"text": "Compared to many existing works that apply either metric-based or optimization-based meta-learning to image domain with low inter-task variance, we consider a more realistic setting, where tasks are diverse.", "labels": [], "entities": []}, {"text": "However, it imposes tremendous difficulties to existing state-of-the-art metric-based algorithms since a single metric is insufficient to capture complex task variations in natural language domain.", "labels": [], "entities": []}, {"text": "To alleviate the problem , we propose an adaptive metric learning approach that automatically determines the best weighted combination from a set of met-rics obtained from meta-training tasks fora newly seen few-shot task.", "labels": [], "entities": []}, {"text": "Extensive quantitative evaluations on real-world sentiment analysis and dialog intent classification datasets demonstrate that the proposed method performs favorably against state-of-the-art few shot learning algorithms in terms of predictive accuracy.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.8284846842288971}, {"text": "dialog intent classification", "start_pos": 72, "end_pos": 100, "type": "TASK", "confidence": 0.7664307157198588}, {"text": "accuracy", "start_pos": 243, "end_pos": 251, "type": "METRIC", "confidence": 0.8208253979682922}]}, {"text": "We make our code and data available for further study.", "labels": [], "entities": []}], "introductionContent": [{"text": "Few-shot learning (FSL) () aims to learn classifiers from few examples per class.", "labels": [], "entities": [{"text": "Few-shot learning (FSL)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.779115104675293}]}, {"text": "Recently, deep learning has been successfully exploited for FSL via learning meta-models from a large number of meta-training tasks.", "labels": [], "entities": [{"text": "FSL", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.9884922504425049}]}, {"text": "These meta-models can be then used for rapid-adaptation for the target/meta-testing tasks that only have few training examples.", "labels": [], "entities": []}, {"text": "Examples of such metamodels include: (1) metric-/similarity-based models, which learn contextual, and task-specific similarity measures \u21e4 Equal contributions from the corresponding authors: yum@us.ibm.com, xiaoxiao.guo@ibm.com, jinfengy@us.ibm.com.", "labels": [], "entities": []}, {"text": "optimization-based models, which receive the input of gradients from a FSL task and predict either model parameters or parameter updates.", "labels": [], "entities": []}, {"text": "In the past, FSL has mainly considered image domains, where all tasks are often sampled from one huge collection of data, such as Omniglot (Lake et al., 2011) and ImageNet (, making tasks come from a single domain thus related.", "labels": [], "entities": [{"text": "FSL", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9663332104682922}]}, {"text": "Due to such a simplified setting, almost all previous works employ a common meta-model (metric-/optimization-based) for all few-shot tasks.", "labels": [], "entities": []}, {"text": "However, this setting is far from the realistic scenarios in many real-world applications of few-shot text classification.", "labels": [], "entities": [{"text": "text classification", "start_pos": 102, "end_pos": 121, "type": "TASK", "confidence": 0.6918674856424332}]}, {"text": "For example, on an enterprise AI cloud service, many clients submit various tasks to train text classification models for business-specific purposes.", "labels": [], "entities": []}, {"text": "The tasks could be classifying customers' comments or opinions on different products/services, monitoring public reactions to different policy changes, or determining users' intents in different types of personal assistant services.", "labels": [], "entities": [{"text": "classifying customers' comments or opinions", "start_pos": 19, "end_pos": 62, "type": "TASK", "confidence": 0.8103832960128784}]}, {"text": "As most of the clients cannot collect enough data, their submitted tasks form a few-shot setting.", "labels": [], "entities": []}, {"text": "Also, these tasks are significantly diverse, thus a common metric is insufficient to handle all these tasks.", "labels": [], "entities": []}, {"text": "We consider a more realistic FSL setting in this paper, where tasks are diverse.", "labels": [], "entities": [{"text": "FSL", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.9690157771110535}]}, {"text": "In such a scenario, the optimal meta-model may vary across tasks.", "labels": [], "entities": []}, {"text": "Our solution is based on the metric-learning approach () and the key idea is to maintain multiple metrics for FSL.", "labels": [], "entities": [{"text": "FSL", "start_pos": 110, "end_pos": 113, "type": "TASK", "confidence": 0.7337158918380737}]}, {"text": "The metalearner selects and combines multiple metrics for learning the target task using task clustering on the meta-training tasks.", "labels": [], "entities": []}, {"text": "During the meta-training, we propose to first partition the meta-training tasks into clusters, making the tasks in each cluster likely to be related.", "labels": [], "entities": []}, {"text": "Then within each cluster, we train a deep embedding function as the metric.", "labels": [], "entities": []}, {"text": "This ensures the common metric is only shared across tasks within the same cluster.", "labels": [], "entities": []}, {"text": "Further, during meta-testing, each target FSL task is assigned to a task-specific metric, which is a linear combination of the metrics defined by different clusters.", "labels": [], "entities": [{"text": "FSL task", "start_pos": 42, "end_pos": 50, "type": "TASK", "confidence": 0.8807290196418762}]}, {"text": "In this way, the diverse few-shot tasks can derive different metrics from the previous learning experience.", "labels": [], "entities": []}, {"text": "The key of the proposed FSL framework is the task clustering algorithm.", "labels": [], "entities": [{"text": "FSL", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.8254040479660034}, {"text": "task clustering", "start_pos": 45, "end_pos": 60, "type": "TASK", "confidence": 0.6800816506147385}]}, {"text": "Previous works) mainly focused on convex objectives, and assumed the number of classes is the same across different tasks (e.g. binary classification is often considered).", "labels": [], "entities": []}, {"text": "To make task clustering (i) compatible with deep networks and (ii) able to handle tasks with a various number of labels, we propose a matrix-completion based task clustering algorithm.", "labels": [], "entities": []}, {"text": "The algorithm utilizes task similarity measured by cross-task transfer performance, denoted by matrix S.", "labels": [], "entities": []}, {"text": "The (i, j)-entry of S is the estimated accuracy by adapting the learned representations on the i-th (source) task to the j-th (target) task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9970093965530396}]}, {"text": "We rely on matrix completion to deal with missing and unreliable entries in Sand finally apply spectral clustering to generate the task partitions.", "labels": [], "entities": [{"text": "matrix completion", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.7015547007322311}]}, {"text": "To the best of our knowledge, our work is the first one addressing the diverse few-shot learning problem and reporting results on real-world fewshot text classification problems.", "labels": [], "entities": [{"text": "fewshot text classification", "start_pos": 141, "end_pos": 168, "type": "TASK", "confidence": 0.6260084708531698}]}, {"text": "The experimental results show that the proposed algorithm provides significant gains on few-shot sentiment classification and dialog intent classification tasks.", "labels": [], "entities": [{"text": "few-shot sentiment classification", "start_pos": 88, "end_pos": 121, "type": "TASK", "confidence": 0.6963503162066141}, {"text": "dialog intent classification", "start_pos": 126, "end_pos": 154, "type": "TASK", "confidence": 0.80519038438797}]}, {"text": "It provides positive feedback on the idea of using multiple meta-models (metrics) to handle diverse FSL tasks, as well as the proposed task clustering algorithm on automatically detecting related tasks.", "labels": [], "entities": [{"text": "FSL tasks", "start_pos": 100, "end_pos": 109, "type": "TASK", "confidence": 0.8155476450920105}]}], "datasetContent": [{"text": "Due to the limited training resources, all the supervised-learning baselines perform poorly.", "labels": [], "entities": []}, {"text": "The two state-of-the-art metric-based FSL approaches, matching network (4) and prototypical network (5), do not perform better compared to the other baselines, since the single metric is not sufficient for all the diverse tasks.", "labels": [], "entities": []}, {"text": "On intent classification where tasks are further diverse, all the singlemetric or single-model methods perform worse compared to the single-task CNN baseline (1).", "labels": [], "entities": [{"text": "intent classification", "start_pos": 3, "end_pos": 24, "type": "TASK", "confidence": 0.8279511630535126}]}, {"text": "The convex combination of all the single training task models is the best performing baseline overall.", "labels": [], "entities": []}, {"text": "However, on intent classification it only performs on par with the single-task CNN (1), which does not use any meta-learning or transfer learning techniques, mainly for two reasons: (i) with the growth of the number of meta-training tasks, the model parameters grow linearly, making the number of parameters (165 in this case) in Eq.(6) too large for the few-shot tasks to fit; (ii) the meta-training tasks in intent classification usually contain less training data, making the single-task encoders not generalize well.", "labels": [], "entities": [{"text": "intent classification", "start_pos": 12, "end_pos": 33, "type": "TASK", "confidence": 0.752249002456665}]}, {"text": "In contrast, our ROBUSTTC-FSL gives consistently better results compared to all the baselines.", "labels": [], "entities": [{"text": "ROBUSTTC-FSL", "start_pos": 17, "end_pos": 29, "type": "METRIC", "confidence": 0.9364796280860901}]}, {"text": "It outperforms the baselines in previous work (1-5) by a large margin of more than 6% on the sentiment classification tasks, and more than 3% on the intent classification tasks.", "labels": [], "entities": [{"text": "sentiment classification tasks", "start_pos": 93, "end_pos": 123, "type": "TASK", "confidence": 0.9375614921251932}, {"text": "intent classification tasks", "start_pos": 149, "end_pos": 176, "type": "TASK", "confidence": 0.7487430274486542}]}, {"text": "It is also significantly better than our proposed baseline, showing the advantages of the usage of task clustering.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracy of FSL on sentiment classification (Sentiment) and dialog intent classification (Intent) tasks. The  target tasks of sentiment classification are 5-shot ones; and each intent target task contains one training example  per class and 20 random labeled examples.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9788175225257874}, {"text": "FSL", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.582888126373291}, {"text": "sentiment classification", "start_pos": 29, "end_pos": 53, "type": "TASK", "confidence": 0.8086762726306915}, {"text": "dialog intent classification (Intent) tasks", "start_pos": 70, "end_pos": 113, "type": "TASK", "confidence": 0.7115148178168705}, {"text": "sentiment classification", "start_pos": 136, "end_pos": 160, "type": "TASK", "confidence": 0.8672532141208649}]}, {"text": " Table 2: Visualization of clusters on the Amazon review domain. The top shows the training tasks assigned to the  10 clusters. Here the number N2 {2, 4, 5} refers to the threshold of stars for positive reviews. At the bottom we  show three tasks with largest improvement from ROBUSTTC-FSL. The top-3 most relevant task clusters (i.e. with  highest weights \u21b5s in Eq.6 ) are highlighted with blue bold font.", "labels": [], "entities": [{"text": "Amazon review domain", "start_pos": 43, "end_pos": 63, "type": "DATASET", "confidence": 0.8609432379404703}]}]}