{"title": [{"text": "Attentive Interaction Model: Modeling Changes in View in Argumentation", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a neural architecture for mod-eling argumentative dialogue that explicitly models the interplay between an Opinion Holder's (OH's) reasoning and a challenger's argument, with the goal of predicting if the argument successfully changes the OH's view.", "labels": [], "entities": []}, {"text": "The model has two components: (1) vulnerable region detection, an attention model that identifies parts of the OH's reasoning that are amenable to change, and (2) interaction encoding, which identifies the relationship between the content of the OH's reasoning and that of the challenger's argument.", "labels": [], "entities": [{"text": "vulnerable region detection", "start_pos": 34, "end_pos": 61, "type": "TASK", "confidence": 0.6554663081963857}]}, {"text": "Based on evaluation on discussions from the Change My View forum on Reddit, the two components work together to predict an OH's change in view, outperform-ing several baselines.", "labels": [], "entities": []}, {"text": "A posthoc analysis suggests that sentences picked out by the attention model are addressed more frequently by successful arguments than by unsuccessful ones.", "labels": [], "entities": []}], "introductionContent": [{"text": "Through engagement in argumentative dialogue, interlocutors present arguments with the goals of winning the debate or contributing to the joint construction of knowledge.", "labels": [], "entities": []}, {"text": "Especially modeling the knowledge co-construction process requires understanding of both the substance of viewpoints and how the substance of an argument connects with what it is arguing against.", "labels": [], "entities": []}, {"text": "Prior work on argumentation in the NLP community, however, has focused mainly on the first goal and has often reduced the concept of a viewpoint as a discrete side (e.g., pro vs against, or liberal vs conservative), missing more nuanced and complex details of viewpoints.", "labels": [], "entities": []}, {"text": "In addition, while the strength of the argument and the side it represents have been addressed relatively often, the dialogical aspects of argumentation have received less attention.", "labels": [], "entities": []}, {"text": "To bridge the gap, we present a model that jointly considers an Opinion Holder's (OH's) expressed viewpoint with a challenger's argument in order to predict if the argument succeeded in altering the OH's view.", "labels": [], "entities": []}, {"text": "The first component of the architecture, vulnerable region detection, aims to identify important parts in the OH's reasoning that are key to impacting their viewpoint.", "labels": [], "entities": [{"text": "vulnerable region detection", "start_pos": 41, "end_pos": 68, "type": "TASK", "confidence": 0.6246314545472463}]}, {"text": "The intuition behind our model is that addressing certain parts of the OH's reasoning often has little impact in changing the OH's view, even if the OH realizes the reasoning is flawed.", "labels": [], "entities": []}, {"text": "On the other hand, some parts of the OH's reasoning are more open to debate, and thus, it is reasonable for the model to learn and attend to parts that have a better chance to change an OH's view when addressed.", "labels": [], "entities": []}, {"text": "The second component of the architecture, interaction encoding, aims to identify the connection between the OH's sentences and the challenger's sentences.", "labels": [], "entities": [{"text": "interaction encoding", "start_pos": 42, "end_pos": 62, "type": "TASK", "confidence": 0.7096827030181885}]}, {"text": "Meaningful interaction in argumentation may include agreement/disagreement, topic relevance, or logical implication.", "labels": [], "entities": []}, {"text": "Our model encodes the interaction between every pair of the OH's and the challenger's sentences as interaction embeddings, which are then aggregated and used for prediction.", "labels": [], "entities": []}, {"text": "Intuitively, the interactions with the most vulnerable regions of the OH's reasoning are most critical.", "labels": [], "entities": []}, {"text": "Thus, in our complete model, the interaction embeddings are weighted by the vulnerability scores computed in the first component.", "labels": [], "entities": []}, {"text": "We evaluate our model on discussions from the Change My View forum on Reddit, where users (OHs) post their views on various issues, partic-ipate in discussion with challengers who try to change the OH's view, and acknowledge when their views have been impacted.", "labels": [], "entities": []}, {"text": "Particularly, we aim to answer the following questions: \u2022 RQ1.", "labels": [], "entities": [{"text": "RQ1", "start_pos": 58, "end_pos": 61, "type": "METRIC", "confidence": 0.6754021644592285}]}, {"text": "Does the architecture of vulnerable region detection and interaction encoding help to predict changes in view?", "labels": [], "entities": [{"text": "vulnerable region detection", "start_pos": 25, "end_pos": 52, "type": "TASK", "confidence": 0.6625823974609375}, {"text": "interaction encoding", "start_pos": 57, "end_pos": 77, "type": "TASK", "confidence": 0.7422846257686615}]}, {"text": "Can the model identify vulnerable sentences, which are more likely to change the OH's view when addressed?", "labels": [], "entities": []}, {"text": "If so, what properties constitute vulnerability?", "labels": [], "entities": []}, {"text": "What kinds of interactions between arguments are captured by the model?", "labels": [], "entities": []}, {"text": "We use our model to predict whether a challenger's argument has impacted the OH's view and compare the result with several baseline models.", "labels": [], "entities": []}, {"text": "We also present a posthoc analysis that illuminates the model's behavior in terms of vulnerable region detection and meaningful interaction.", "labels": [], "entities": [{"text": "vulnerable region detection", "start_pos": 85, "end_pos": 112, "type": "TASK", "confidence": 0.6596735517183939}]}, {"text": "For the remainder of the paper, we position our work in the literature (Section 2) and examine the data (Section 3).", "labels": [], "entities": []}, {"text": "Then we explain our model design (Section 4).", "labels": [], "entities": []}, {"text": "Next, we describe the experiment settings (Section 5), discuss the results (Section 6), and conclude the paper (Section 7).", "labels": [], "entities": []}], "datasetContent": [{"text": "Our task is to predict whether a comment would receive a \u2206, given the OH's initial post and the comment.", "labels": [], "entities": [{"text": "\u2206", "start_pos": 57, "end_pos": 58, "type": "METRIC", "confidence": 0.7132646441459656}]}, {"text": "We formulate this task as binary prediction of \u2206 \u2208 {0, 1}.", "labels": [], "entities": []}, {"text": "Since our data is highly skewed, we use as our evaluation metric the AUC score (Area Under the Receiver Operating Characteristic Curve), which measures the probability of a positive instance receiving a higher probability of \u2206 = 1 than a negative instance.", "labels": [], "entities": [{"text": "AUC score", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9712413251399994}]}], "tableCaptions": [{"text": " Table 1: Data statistics. (CD: cross-domain test)", "labels": [], "entities": []}, {"text": " Table 2: AUC scores. (ID: in-domain AUC (%), CD:  cross-domain AUC (%), LR: logistic regression, AIM:  Attention Interaction Model, (A)IM: AIM without at- tention.) *: p < 0.05 using the DeLong test compared  to LR with TFIDF.", "labels": [], "entities": []}]}