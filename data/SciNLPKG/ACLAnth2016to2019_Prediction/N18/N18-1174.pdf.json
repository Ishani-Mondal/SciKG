{"title": [{"text": "Human Needs Categorization of Affective Events Using Labeled and Unlabeled Data", "labels": [], "entities": []}], "abstractContent": [{"text": "We often talk about events that impact us positively or negatively.", "labels": [], "entities": []}, {"text": "For example \"I got a job\" is good news, but \"I lost my job\" is bad news.", "labels": [], "entities": []}, {"text": "When we discuss an event, we not only understand its affective polarity but also the reason why the event is beneficial or detrimental.", "labels": [], "entities": []}, {"text": "For example, getting or losing a job has affective polarity primarily because it impacts us financially.", "labels": [], "entities": []}, {"text": "Our work aims to categorize affective events based upon human need categories that often explain people's motivations and desires: PHYSIOLOGICAL, HEALTH, LEISURE, SOCIAL , FINANCIAL, COGNITION, and FREEDOM.", "labels": [], "entities": [{"text": "PHYSIOLOGICAL", "start_pos": 131, "end_pos": 144, "type": "METRIC", "confidence": 0.8569324612617493}, {"text": "HEALTH", "start_pos": 146, "end_pos": 152, "type": "METRIC", "confidence": 0.9582374691963196}, {"text": "LEISURE", "start_pos": 154, "end_pos": 161, "type": "METRIC", "confidence": 0.9878782629966736}, {"text": "FINANCIAL", "start_pos": 172, "end_pos": 181, "type": "METRIC", "confidence": 0.7918835878372192}, {"text": "FREEDOM", "start_pos": 198, "end_pos": 205, "type": "METRIC", "confidence": 0.6615126729011536}]}, {"text": "We create classification models based on event expressions as well as models that use contexts surrounding event mentions.", "labels": [], "entities": []}, {"text": "We also design a co-training model that learns from unlabeled data by simultaneously training event expression and event context classi-fiers in an iterative learning process.", "labels": [], "entities": []}, {"text": "Our results show that co-training performs well, producing substantially better results than the individual classifiers.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent research has focused on identifying affective events in text, which are activities or states that positively or negatively affect the people who experience them.", "labels": [], "entities": []}, {"text": "Recognizing affective events in text is challenging because they appear as factual expressions and their affective polarity is often implicit.", "labels": [], "entities": [{"text": "Recognizing affective events in text", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.8383328199386597}]}, {"text": "For example, \"I broke my arm\" and \"I got fired\" are usually negative experiences, while \"I broke a record\" and \"I went to a concert\" are typically positive experiences.", "labels": [], "entities": []}, {"text": "Several NLP techniques have been developed to recognize affective events, including patient polarity verb bootstrapping (, implicature rules, label propagation (, pattern-based learning (, and semantic consistency optimization . Our research aims to probe deeper and understand not just the polarity of affective events, but the reason for the polarity.", "labels": [], "entities": [{"text": "label propagation", "start_pos": 142, "end_pos": 159, "type": "TASK", "confidence": 0.7377993762493134}, {"text": "semantic consistency optimization", "start_pos": 193, "end_pos": 226, "type": "TASK", "confidence": 0.6701845427354177}]}, {"text": "Events can impact people in many ways, and understanding why an event is beneficial or detrimental is a fundamental aspect of language understanding and narrative text comprehension.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 126, "end_pos": 148, "type": "TASK", "confidence": 0.7225414961576462}]}, {"text": "Additionally, many applications could benefit from understanding the nature of affective events, including text summarization, conversational dialogue processing, and mental health therapy or counseling systems.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 107, "end_pos": 125, "type": "TASK", "confidence": 0.7707909345626831}, {"text": "conversational dialogue processing", "start_pos": 127, "end_pos": 161, "type": "TASK", "confidence": 0.6824964880943298}]}, {"text": "As an illustration, a mental health therapy system can benefit from understanding why someone is in a negative state.", "labels": [], "entities": []}, {"text": "If the triggering event for depression is \"I broke my leg\" then the reason is about the person's Health, but if the triggering event is \"I broke up with my girlfriend\" then the reason is based on Social relationships.", "labels": [], "entities": [{"text": "Health", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.9925500154495239}]}, {"text": "We hypothesize that the polarity of affective events can often be attributed to a relatively small set of human need categories.", "labels": [], "entities": []}, {"text": "Our work is motivated by theories in psychology that explain people's motivations, desires, and overall well-being in terms of categories associated with basic human needs, such as Maslow's Hierarchy of Needs ( and Fundamental Human Needs (.", "labels": [], "entities": []}, {"text": "Drawing upon these works, we propose that the polarity of affective events often arises from 7 types of human needs: PHYSIOLOGICAL, HEALTH, LEISURE, SOCIAL, FINANCIAL, COGNITION, and FREE-DOM.", "labels": [], "entities": [{"text": "PHYSIOLOGICAL", "start_pos": 117, "end_pos": 130, "type": "METRIC", "confidence": 0.9100732803344727}, {"text": "HEALTH", "start_pos": 132, "end_pos": 138, "type": "METRIC", "confidence": 0.982874870300293}, {"text": "LEISURE", "start_pos": 140, "end_pos": 147, "type": "METRIC", "confidence": 0.9922053217887878}, {"text": "FINANCIAL", "start_pos": 157, "end_pos": 166, "type": "METRIC", "confidence": 0.9519407749176025}, {"text": "FREE-DOM", "start_pos": 183, "end_pos": 191, "type": "METRIC", "confidence": 0.9836957454681396}]}, {"text": "For example, \"I broke my arm\" has negative polarity because it negatively impacts one's Health, \"I got fired\" is negative because it negatively impacts one's Finances, and \"I am confused\" is negative because it reflects a problem related to Cognition.", "labels": [], "entities": [{"text": "Health", "start_pos": 88, "end_pos": 94, "type": "METRIC", "confidence": 0.7836485505104065}]}, {"text": "We explore this hypothesis and tackle the chal-lenge of categorizing affective events in text with respect to these 7 human need categories.", "labels": [], "entities": []}, {"text": "As our evaluation data, we use events extracted from personal blog posts and manually labeled with affective polarity in previous work ).", "labels": [], "entities": []}, {"text": "These affective events were then subsequently annotated for the human need categories.", "labels": [], "entities": []}, {"text": "In this paper, we design several types of classification models that learn from both labeled and unlabeled data.", "labels": [], "entities": []}, {"text": "First, we present supervised learning models that use lexical and embedding features for the words in event expressions, as well as models that learn from the sentence contexts surrounding mentions of event expressions.", "labels": [], "entities": []}, {"text": "Next, we explore self-training and co-training models that exploit both labeled and unlabeled data for training.", "labels": [], "entities": []}, {"text": "The most effective system is a co-training model that uses two classifiers with two different views in an iterative learning process: one classifier only uses the words in an event expression, and the other classifier only uses the contexts surrounding instances of an event expression.", "labels": [], "entities": []}, {"text": "Our results show that this co-training model effectively uses unlabeled data to substantially improve results compared to classifiers trained only with labeled data, yielding gains in both precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 189, "end_pos": 198, "type": "METRIC", "confidence": 0.999438464641571}, {"text": "recall", "start_pos": 203, "end_pos": 209, "type": "METRIC", "confidence": 0.9975067973136902}]}], "datasetContent": [{"text": "We conducted experiments to evaluate the methods described in Section 4.", "labels": [], "entities": []}, {"text": "For all of our experiments, the results are reported based on 3-fold cross-validation on the 542 affective events manually labeled with human need categories.", "labels": [], "entities": []}, {"text": "We show the average results over 3-folds in the following sections.", "labels": [], "entities": []}, {"text": "For development, we used a distinct set of events labeled during preliminary studies.", "labels": [], "entities": []}, {"text": "We did not tune any of the models, using only their default parameter settings.", "labels": [], "entities": []}, {"text": "We present experimental results in terms of precision, recall, and F1 score, macro-averaged over the human need categories.", "labels": [], "entities": [{"text": "precision", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9997671246528625}, {"text": "recall", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9996156692504883}, {"text": "F1 score", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.983065128326416}]}, {"text": "shows the results 4 for the event expression classifiers.", "labels": [], "entities": []}, {"text": "We also evaluated the ability of the LIWC lexicon () to label the event expressions.", "labels": [], "entities": []}, {"text": "We manually aligned the relevant LIWC categories with our human need categories, as shown in.", "labels": [], "entities": []}, {"text": "Then we labeled each event by identifying the human need category of each word in the event phrase and assign-ing the most frequent category to the event.", "labels": [], "entities": []}, {"text": "If no words were assigned to our categories, we labeled the event as None.", "labels": [], "entities": []}, {"text": "The top row of shows that LIWC achieved 39% recall but only 47.7% precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.9996546506881714}, {"text": "precision", "start_pos": 66, "end_pos": 75, "type": "METRIC", "confidence": 0.9992801547050476}]}, {"text": "The reason is that some categories in LIWC are more generalized compared with the definitions of our corresponding categories.", "labels": [], "entities": []}, {"text": "For example, the words \"abandon\" and \"damage\" belong to the Affect category (corresponding to our Emotion category) in LIWC.", "labels": [], "entities": [{"text": "abandon", "start_pos": 24, "end_pos": 31, "type": "METRIC", "confidence": 0.9852259755134583}, {"text": "LIWC", "start_pos": 119, "end_pos": 123, "type": "DATASET", "confidence": 0.9486821293830872}]}, {"text": "However, based on our definition the event \"my house was damaged\" actually belongs to the Finance category.", "labels": [], "entities": []}, {"text": "In this way, the Emotion category is overly generalized which leads to low precision for this class.", "labels": [], "entities": [{"text": "precision", "start_pos": 75, "end_pos": 84, "type": "METRIC", "confidence": 0.9990444779396057}]}, {"text": "The LR and SVM rows in show the performance of the logistic regression (LR) and support vector machine (SVM) classifiers, respectively.", "labels": [], "entities": []}, {"text": "We evaluated classifiers with bag-of-words features (BOW) and classifiers with event embedding features (Embed), computed as the average of the embeddings for all words in the event expression.", "labels": [], "entities": [{"text": "BOW", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.9201351404190063}]}, {"text": "We also tried adding semantic category features from LIWC to each feature set, denoted as +SemCat.", "labels": [], "entities": []}, {"text": "The results show that the Embed features performed best for both the LR and SVM classifiers.", "labels": [], "entities": []}, {"text": "Adding the SemCat features improved upon the bag-of-word representations, but not the embeddings.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Performance of Event Expression Classifiers", "labels": [], "entities": []}, {"text": " Table 5: Performance of Event Context Classifiers", "labels": [], "entities": []}, {"text": " Table 6: Performance of Self-Training and Co-Training", "labels": [], "entities": []}, {"text": " Table 7: Breakdown of results across Human Need cat- egories. Each cell shows Precision, Recall, and F1.", "labels": [], "entities": [{"text": "Breakdown", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.6867314577102661}, {"text": "Precision", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.9995641112327576}, {"text": "Recall", "start_pos": 90, "end_pos": 96, "type": "METRIC", "confidence": 0.9957549571990967}, {"text": "F1", "start_pos": 102, "end_pos": 104, "type": "METRIC", "confidence": 0.9996682405471802}]}]}