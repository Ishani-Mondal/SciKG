{"title": [{"text": "Post-Specialisation: Retrofitting Vectors of Words Unseen in Lexical Resources", "labels": [], "entities": [{"text": "Retrofitting Vectors of Words Unseen in Lexical", "start_pos": 21, "end_pos": 68, "type": "TASK", "confidence": 0.875502714088985}]}], "abstractContent": [{"text": "Word vector specialisation (also known as retrofitting) is a portable, lightweight approach to fine-tuning arbitrary distributional word vector spaces by injecting external knowledge from rich lexical resources such as WordNet.", "labels": [], "entities": [{"text": "Word vector specialisation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6185023585955302}, {"text": "WordNet", "start_pos": 219, "end_pos": 226, "type": "DATASET", "confidence": 0.9561490416526794}]}, {"text": "By design, these post-processing methods only update the vectors of words occurring in external lexicons, leaving the representations of all unseen words intact.", "labels": [], "entities": []}, {"text": "In this paper, we show that constraint-driven vector space specialisation can be extended to unseen words.", "labels": [], "entities": []}, {"text": "We propose a novel post-specialisation method that: a) preserves the useful linguistic knowledge for seen words; while b) propagating this external signal to unseen words in order to improve their vector representations as well.", "labels": [], "entities": []}, {"text": "Our post-specialisation approach explic-its a non-linear specialisation function in the form of a deep neural network by learning to predict specialised vectors from their original distributional counterparts.", "labels": [], "entities": []}, {"text": "The learned function is then used to specialise vectors of unseen words.", "labels": [], "entities": []}, {"text": "This approach, applicable to any post-processing model, yields considerable gains over the initial specialisation models both in intrinsic word similarity tasks, and in two downstream tasks: dialogue state tracking and lexical text simplification.", "labels": [], "entities": [{"text": "dialogue state tracking", "start_pos": 191, "end_pos": 214, "type": "TASK", "confidence": 0.7509378592173258}, {"text": "lexical text simplification", "start_pos": 219, "end_pos": 246, "type": "TASK", "confidence": 0.6143883665402731}]}, {"text": "The positive effects persist across three languages, demonstrating the importance of specialising the full vocabulary of distributional word vector spaces.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word representation learning is a key research area in current Natural Language Processing (NLP), with its usefulness demonstrated across a range of tasks).", "labels": [], "entities": [{"text": "Word representation learning", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8305594722429911}, {"text": "Natural Language Processing (NLP)", "start_pos": 63, "end_pos": 96, "type": "TASK", "confidence": 0.7170030971368154}]}, {"text": "The standard techniques for inducing distributed word representations are grounded in the distributional hypothesis: they rely on co-occurrence information in large textual corpora.", "labels": [], "entities": []}, {"text": "As a result, these models tend to coalesce the notions of semantic similarity and (broader) conceptual relatedness, and cannot accurately distinguish antonyms from synonyms (.", "labels": [], "entities": []}, {"text": "Recently, we have witnessed arise of interest in representation models that move beyond stand-alone unsupervised learning: they leverage external knowledge in human-and automaticallyconstructed lexical resources to enrich the semantic content of distributional word vectors, in a process termed semantic specialisation.", "labels": [], "entities": []}, {"text": "This is often done as a post-processing (sometimes referred to as retrofitting) step: input word vectors are fine-tuned to satisfy linguistic constraints extracted from lexical resources such as WordNet or.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 195, "end_pos": 202, "type": "DATASET", "confidence": 0.9403569102287292}]}, {"text": "The use of external curated knowledge yields improved word vectors for the benefit of downstream applications.", "labels": [], "entities": []}, {"text": "At the same time, this specialisation of the distributional space distinguishes between true similarity and relatedness, and supports language understanding tasks (.", "labels": [], "entities": [{"text": "language understanding tasks", "start_pos": 134, "end_pos": 162, "type": "TASK", "confidence": 0.8237840930620829}]}, {"text": "While there is consensus regarding their benefits and ease of use, one property of the post-processing specialisation methods slips under the radar: most existing post-processors update word embeddings only for words which are present (i.e., seen) in the external constraints, while vectors of all other (i.e., unseen) words remain unaffected.", "labels": [], "entities": []}, {"text": "In this work, we propose anew approach that extends the specialisation framework to unseen words, relying on the transformation of the vector (sub)space of seen words.", "labels": [], "entities": []}, {"text": "Our intuition is that the process of finetuning seen words provides implicit information on how to leverage the external knowledge to unseen words.", "labels": [], "entities": []}, {"text": "The method should preserve the already injected knowledge for seen words, simultaneously propagating the external signal to unseen words in order to improve their vectors.", "labels": [], "entities": []}, {"text": "The proposed post-specialisation method can be seen as a two-step process, illustrated in: 1) We use a state-of-the-art specialisation model to transform the subspace of seen words from the input distributional space into the specialised subspace; 2) We learn a mapping function based on the transformation of the \"seen subspace\", and then apply it to the distributional subspace of unseen words.", "labels": [], "entities": []}, {"text": "We allow the proposed post-specialisation model to learn from large external linguistic resources by implementing the mapping as a deep feed-forward neural network with non-linear activations.", "labels": [], "entities": []}, {"text": "This allows the model to learn the generalisation of the fine-tuning steps taken by the initial specialisation model, itself based on a very large number (e.g., hundreds of thousands) of external linguistic constraints.", "labels": [], "entities": []}, {"text": "As indicated by the results on word similarity and two downstream tasks (dialogue state tracking and lexical text simplification) our postspecialisation method consistently outperforms state-of-the-art methods which specialise seen words only.", "labels": [], "entities": [{"text": "word similarity", "start_pos": 31, "end_pos": 46, "type": "TASK", "confidence": 0.752307653427124}, {"text": "dialogue state tracking", "start_pos": 73, "end_pos": 96, "type": "TASK", "confidence": 0.7123054067293803}]}, {"text": "We report improvements using three distinct input vector spaces for English and for three test languages (English, German, Italian), verifying the robustness of our approach.", "labels": [], "entities": []}], "datasetContent": [{"text": "Evaluation Protocol The first set of experiments evaluates vector spaces with different specialisation procedures intrinsically on word similarity benchmarks: we use the SimLex-999 dataset ( , and SimVerb-3500 (), a recent verb pair similarity dataset providing similarity ratings for 3,500 verb pairs.", "labels": [], "entities": [{"text": "SimLex-999 dataset", "start_pos": 170, "end_pos": 188, "type": "DATASET", "confidence": 0.9086138010025024}]}, {"text": "rank correlation is used as the evaluation metric.", "labels": [], "entities": []}, {"text": "We evaluate word vectors in two settings.", "labels": [], "entities": []}, {"text": "First, in a synthetic hold-out setting, we remove all linguistic constraints which contain words from the SimLex and SimVerb evaluation data, effectively forcing all SimLex and SimVerb words to be unseen by the AR specialisation model.", "labels": [], "entities": [{"text": "SimVerb evaluation data", "start_pos": 117, "end_pos": 140, "type": "DATASET", "confidence": 0.6993715862433115}]}, {"text": "The specialised vectors for these words are estimated by the learned non-linear DFFN mapping model.", "labels": [], "entities": []}, {"text": "Second, the all setting is a standard \"real-life\" scenario where some test (SimLex/SimVerb) words do occur in the constraints, while the mapping is learned for the remaining words.", "labels": [], "entities": []}, {"text": "The DST model is the first component of modern dialogue pipelines, which captures the users' goals at each dialogue turn and then updates the dialogue state.", "labels": [], "entities": []}, {"text": "Goals are represented as sets of constraints expressed as slot-value pairs (e.g., food=Chinese).", "labels": [], "entities": []}, {"text": "The set of slots and the set of values for each slot constitute the ontology of a dialogue domain.", "labels": [], "entities": []}, {"text": "The probability distribution over the possible states is the system's estimate of the user's goals, and it is used by the dialogue manager module to select the subsequent system response ( ).", "labels": [], "entities": []}, {"text": "An example in illustrates the DST pipeline.", "labels": [], "entities": [{"text": "DST", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.8946826457977295}]}, {"text": "For evaluation, we use the Neural Belief Tracker (NBT), a state-of-the-art DST model which was the first to reason purely over pre-trained word vectors . The NBT uses no hand-crafted semantic lexicons, instead composing word vectors into intermediate utterance and context representations.", "labels": [], "entities": []}, {"text": "For full model details, we refer the reader to the original paper.", "labels": [], "entities": []}, {"text": "The importance of word vector specialisation for the DST task (e.g., distinguishing between synonyms and antonyms by pulling northern and north closer in   the vector space while pushing north and south away) has been established . Again, as in prior work the DST evaluation is based on the Wizard-of-Oz (WOZ) v2.0 dataset , comprising 1,200 dialogues split into training (600 dialogues), development (200), and test data (400).", "labels": [], "entities": [{"text": "DST task", "start_pos": 53, "end_pos": 61, "type": "TASK", "confidence": 0.9269573390483856}, {"text": "DST evaluation", "start_pos": 260, "end_pos": 274, "type": "TASK", "confidence": 0.8858374953269958}, {"text": "Wizard-of-Oz (WOZ) v2.0 dataset", "start_pos": 291, "end_pos": 322, "type": "DATASET", "confidence": 0.5740086038907369}]}, {"text": "In all experiments, we report the standard DST performance measure: joint goal accuracy, and report scores as averages over 5 NBT training runs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.5980069041252136}]}, {"text": "Results and Analysis We again evaluate word vectors in two settings: 1) hold-out, where linguistic constraints with words appearing in the WOZ data are removed, making all WOZ words unseen by ATTRACT-REPEL; and 2) all.", "labels": [], "entities": [{"text": "WOZ data", "start_pos": 139, "end_pos": 147, "type": "DATASET", "confidence": 0.8012614548206329}, {"text": "ATTRACT-REPEL", "start_pos": 192, "end_pos": 205, "type": "METRIC", "confidence": 0.7834456562995911}]}, {"text": "The results for the English DST task with different GLOVE word vector variants are summarised in Tab.", "labels": [], "entities": [{"text": "DST task", "start_pos": 28, "end_pos": 36, "type": "TASK", "confidence": 0.7287558317184448}, {"text": "Tab.", "start_pos": 97, "end_pos": 101, "type": "DATASET", "confidence": 0.9506475031375885}]}, {"text": "3; similar trends in results are observed with two other word vector collections.", "labels": [], "entities": []}, {"text": "The scores maintain conclusions established in the word similarity task.", "labels": [], "entities": [{"text": "word similarity task", "start_pos": 51, "end_pos": 71, "type": "TASK", "confidence": 0.7917338212331136}]}, {"text": "First, semantic specialisation with ATTRACT-REPEL is again beneficial, and discerning between synonyms and antonyms improves DST performance.", "labels": [], "entities": [{"text": "semantic specialisation", "start_pos": 7, "end_pos": 30, "type": "TASK", "confidence": 0.8281667828559875}, {"text": "ATTRACT-REPEL", "start_pos": 36, "end_pos": 49, "type": "METRIC", "confidence": 0.6418823003768921}, {"text": "DST", "start_pos": 125, "end_pos": 128, "type": "TASK", "confidence": 0.9801223874092102}]}, {"text": "However, specialising unseen words (the final X u vector space) yields further improvements in both evaluation settings, supporting our claim that the specialisation signal can be propagated to unseen words.", "labels": [], "entities": []}, {"text": "This downstream evaluation again demonstrates the importance of non-linearity, as the peak scores are reported with the NONLINEAR-MM variant.", "labels": [], "entities": [{"text": "NONLINEAR-MM", "start_pos": 120, "end_pos": 132, "type": "DATASET", "confidence": 0.481620192527771}]}, {"text": "More substantial gains in the all setup are observed in the DST task compared to the word similarity task.", "labels": [], "entities": [{"text": "DST task", "start_pos": 60, "end_pos": 68, "type": "TASK", "confidence": 0.7218427360057831}]}, {"text": "This stems from a lower coverage of the WOZ data in the AR constraints: 36.3% of all WOZ words are unseen words.", "labels": [], "entities": [{"text": "WOZ data", "start_pos": 40, "end_pos": 48, "type": "DATASET", "confidence": 0.8472895920276642}]}, {"text": "Finally, the scores are higher on average in the all setup, since this setup uses more external constraints for AR, and consequently uses more training examples to learn the mapping.", "labels": [], "entities": []}, {"text": "Other Languages We test the portability of our framework to two other languages for which we have similar evaluation data: German (DE) and Italian (IT).", "labels": [], "entities": []}, {"text": "SimLex-999 has been translated and rescored in the two languages by, and the WOZ data were translated and adapted by Mrk\u0161i\u00b4c . Exactly the same setup is used as in our English experiments, without any additional language-specific fine-tuning.", "labels": [], "entities": [{"text": "WOZ data", "start_pos": 77, "end_pos": 85, "type": "DATASET", "confidence": 0.7345667630434036}]}, {"text": "Linguistic constraints were extracted from the same sources: synonyms from the PPDB, antonyms from BabelNet.", "labels": [], "entities": [{"text": "PPDB", "start_pos": 79, "end_pos": 83, "type": "DATASET", "confidence": 0.9168030023574829}]}, {"text": "Our starting distributional vector spaces are taken from prior work: IT vectors are from ( , DE vectors are from).", "labels": [], "entities": []}, {"text": "The results are summarised in Tab.", "labels": [], "entities": [{"text": "Tab.", "start_pos": 30, "end_pos": 34, "type": "DATASET", "confidence": 0.9645473062992096}]}, {"text": "4. Our post-specialisation approach yields consistent improvements over the initial distributional space and the AR specialisation model in both tasks and for both languages.", "labels": [], "entities": []}, {"text": "We do not observe any gain on IT SimLex in the all setup since IT constraints have almost complete coverage of all IT SimLex words (99.3%; the coverage is 64.8% in German).", "labels": [], "entities": []}, {"text": "As expected, the DST scores in the all setup are higher than in the hold-out setup due to a larger number of constraints and training examples.", "labels": [], "entities": [{"text": "DST", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.8457308411598206}]}, {"text": "Lower absolute scores for Italian and German compared to the ones reported for English are due to multiple factors, as discussed previously by : 1) the AR model uses less linguistic constraints for DE and IT; 2) distributional word vectors are induced from smaller corpora; 3) linguistic phenomena (e.g., cases and compounding in DE) contribute to data sparsity and also make the DST task more challenging.", "labels": [], "entities": [{"text": "DST task", "start_pos": 380, "end_pos": 388, "type": "TASK", "confidence": 0.8325448334217072}]}, {"text": "However, it is important to stress the consistent gains over the vector space specialised by the state-of-the-art ATTRACT-REPEL model across all three test languages.", "labels": [], "entities": []}, {"text": "This indicates that the proposed approach is languageagnostic and portable to multiple languages.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Spearman's \u03c1 correlation scores for three word vector collections on two English word similarity  datasets, SimLex-999 (SL) and SimVerb-3500 (SV), using different mapping variants, evaluation protocols,  and word vector spaces: from the initial distributional space X d to the fully specialised space X f . H = 5.", "labels": [], "entities": []}, {"text": " Table 2: Post-specialisation applied to two  other post-processing methods. SL: SimLex; SV:  SimVerb. Hold-out setting. NONLINEAR-MM.", "labels": [], "entities": [{"text": "NONLINEAR-MM", "start_pos": 121, "end_pos": 133, "type": "DATASET", "confidence": 0.526057779788971}]}, {"text": " Table 3: DST results in two evaluation settings  (hold-out and all) with different GLOVE variants.", "labels": [], "entities": [{"text": "DST", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.8575877547264099}]}, {"text": " Table 4: Results on word similarity (Spearman's \u03c1) and DST (joint goal accuracy) for German and Italian.", "labels": [], "entities": [{"text": "Spearman's \u03c1)", "start_pos": 38, "end_pos": 51, "type": "METRIC", "confidence": 0.7534695118665695}, {"text": "DST (joint goal accuracy)", "start_pos": 56, "end_pos": 81, "type": "METRIC", "confidence": 0.7014479140440623}]}, {"text": " Table 5: Lexical simplification performance with  post-specialisation applied on three input spaces.", "labels": [], "entities": [{"text": "Lexical simplification", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.9092428684234619}]}]}