{"title": [{"text": "End-to-end Graph-based TAG Parsing with Neural Networks", "labels": [], "entities": [{"text": "Graph-based TAG Parsing", "start_pos": 11, "end_pos": 34, "type": "TASK", "confidence": 0.6914228200912476}]}], "abstractContent": [{"text": "We present a graph-based Tree Adjoining Grammar (TAG) parser that uses BiL-STMs, highway connections, and character-level CNNs.", "labels": [], "entities": [{"text": "Tree Adjoining Grammar (TAG) parser", "start_pos": 25, "end_pos": 60, "type": "TASK", "confidence": 0.682636171579361}]}, {"text": "Our best end-to-end parser, which jointly performs supertagging, POS tagging , and parsing, outperforms the previously reported best results by more than 2.2 LAS and UAS points.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 65, "end_pos": 76, "type": "TASK", "confidence": 0.7920976281166077}, {"text": "parsing", "start_pos": 83, "end_pos": 90, "type": "TASK", "confidence": 0.9739482998847961}, {"text": "LAS", "start_pos": 158, "end_pos": 161, "type": "METRIC", "confidence": 0.9615678191184998}, {"text": "UAS", "start_pos": 166, "end_pos": 169, "type": "METRIC", "confidence": 0.4535321593284607}]}, {"text": "The graph-based parsing architecture allows for global inference and rich feature representations for TAG parsing, alleviating the fundamental trade-off between transition-based and graph-based parsing systems.", "labels": [], "entities": [{"text": "TAG parsing", "start_pos": 102, "end_pos": 113, "type": "TASK", "confidence": 0.8561210632324219}]}, {"text": "We also demonstrate that the proposed parser achieves state-of-the-art performance in the downstream tasks of Parsing Evaluation using Textual Entailments (PETE) and Unbounded Dependency Recovery.", "labels": [], "entities": [{"text": "Parsing Evaluation", "start_pos": 110, "end_pos": 128, "type": "TASK", "confidence": 0.9394996166229248}, {"text": "Unbounded Dependency Recovery", "start_pos": 166, "end_pos": 195, "type": "TASK", "confidence": 0.5926370720068613}]}, {"text": "This provides further support for the claim that TAG is a viable formalism for problems that require rich structural analysis of sentences.", "labels": [], "entities": []}], "introductionContent": [{"text": "Tree Adjoining Grammar) and Combinatory Categorial Grammar) are both mildly context-sensitive grammar formalisms that are lexicalized: every elementary structure (elementary tree for TAG and category for CCG) is associated with exactly one lexical item, and every lexical item of the language is associated with a finite set of elementary structures in the grammar (.", "labels": [], "entities": []}, {"text": "In TAG and CCG, the task of parsing can be decomposed into two phases (e.g. TAG: Bangalore and Joshi (1999); CCG:): supertagging, where elementary units or supertags are assigned to each lexical item and parsing where these supertags are combined together.", "labels": [], "entities": [{"text": "parsing", "start_pos": 28, "end_pos": 35, "type": "TASK", "confidence": 0.974100649356842}, {"text": "TAG: Bangalore and Joshi (1999)", "start_pos": 76, "end_pos": 107, "type": "DATASET", "confidence": 0.7411192879080772}]}, {"text": "The first phase of supertagging can be considered as \"almost parsing\" because supertags fora sentence almost always determine a unique parse).", "labels": [], "entities": []}, {"text": "This near uniqueness of a parse given a gold sequence of supertags has been confirmed empirically (TAG:;;; CCG:).", "labels": [], "entities": [{"text": "TAG", "start_pos": 99, "end_pos": 102, "type": "METRIC", "confidence": 0.901539146900177}]}, {"text": "We focus on TAG parsing in this work.", "labels": [], "entities": [{"text": "TAG parsing", "start_pos": 12, "end_pos": 23, "type": "TASK", "confidence": 0.979052722454071}]}, {"text": "TAG differs from CCG in having a more varied set of supertags.", "labels": [], "entities": [{"text": "TAG", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.6335176229476929}]}, {"text": "Concretely, the TAG-annotated version of the WSJ Penn Treebank () that we use) includes 4727 distinct supertags (2165 occur once) while the CCGannotated version only includes 1286 distinct supertags (439 occur once).", "labels": [], "entities": [{"text": "TAG-annotated version of the WSJ Penn Treebank", "start_pos": 16, "end_pos": 62, "type": "DATASET", "confidence": 0.7917265551430839}]}, {"text": "This large set of supertags in TAG presents a severe challenge in supertagging and causes a large discrepancy in parsing performance with gold supertags and predicted supertags.", "labels": [], "entities": [{"text": "TAG", "start_pos": 31, "end_pos": 34, "type": "DATASET", "confidence": 0.728390097618103}]}, {"text": "In this work, we present a supertagger and a parser that substantially improve upon previously reported results.", "labels": [], "entities": []}, {"text": "We propose crucial modifications to the bidirectional LSTM (BiLSTM) supertagger in.", "labels": [], "entities": []}, {"text": "First, we use character-level Convolutional Neural Networks (CNNs) for encoding morphological information instead of suffix embeddings.", "labels": [], "entities": []}, {"text": "Secondly, we perform concatenation after each BiLSTM layer.", "labels": [], "entities": []}, {"text": "Lastly, we explore the impact of adding additional BiLSTM layers and highway connections.", "labels": [], "entities": []}, {"text": "These techniques yield an increase of 1.3% inaccuracy.", "labels": [], "entities": []}, {"text": "For parsing, since the derivation tree in a lexicalized TAG is a type of dependency tree, we can directly apply dependency parsing models.", "labels": [], "entities": [{"text": "parsing", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9771268963813782}, {"text": "dependency parsing", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.7484145760536194}]}, {"text": "In particular, we use the biaffine graph-based parser proposed by together with our novel techniques for supertagging.", "labels": [], "entities": []}, {"text": "In addition to these architectural extensions for supertagging and parsing, we also explore multitask learning approaches for TAG parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 67, "end_pos": 74, "type": "TASK", "confidence": 0.9702818989753723}, {"text": "TAG parsing", "start_pos": 126, "end_pos": 137, "type": "TASK", "confidence": 0.9624664485454559}]}, {"text": "Specif-ically, we perform POS tagging, supertagging, and parsing using the same feature representations from the BiLSTMs.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 26, "end_pos": 37, "type": "TASK", "confidence": 0.7610069215297699}, {"text": "parsing", "start_pos": 57, "end_pos": 64, "type": "TASK", "confidence": 0.9758182764053345}, {"text": "BiLSTMs", "start_pos": 113, "end_pos": 120, "type": "DATASET", "confidence": 0.8970454335212708}]}, {"text": "This joint modeling has the benefit of avoiding a time-consuming and complicated pipeline process, and instead produces a full syntactic analysis, consisting of supertags and the derivation that combines them, simultaneously.", "labels": [], "entities": []}, {"text": "Moreover, this multi-task learning framework further improves performance in all three tasks.", "labels": [], "entities": []}, {"text": "We hypothesize that our multi-task learning yields feature representations in the LSTM layers that are more linguistically relevant and that generalize better.", "labels": [], "entities": []}, {"text": "We provide support for this hypothesis by analyzing syntactic analogies across induced vector representations of supertags (.", "labels": [], "entities": []}, {"text": "The end-to-end TAG parser substantially outperforms the previously reported best results.", "labels": [], "entities": [{"text": "TAG parser", "start_pos": 15, "end_pos": 25, "type": "TASK", "confidence": 0.7561440765857697}]}, {"text": "Finally, we apply our new parsers to the downstream tasks of Parsing Evaluation using Textual Entailements (PETE,) and Unbounded Dependency Recovery (.", "labels": [], "entities": [{"text": "Parsing Evaluation", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.9411406219005585}, {"text": "Unbounded Dependency Recovery", "start_pos": 119, "end_pos": 148, "type": "TASK", "confidence": 0.5885790685812632}]}, {"text": "We demonstrate that our end-to-end parser outperforms the best results in both tasks.", "labels": [], "entities": []}, {"text": "These results illustrate that TAG is a viable formalism for tasks that benefit from the assignment of rich structural descriptions to sentences.", "labels": [], "entities": [{"text": "TAG", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.8519777655601501}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Supertagging Results. Joint (Stag) and Joint  (POS+Stag) indicate joint parsing models that perform  supertagging, and POS tagging and supertagging re- spectively.", "labels": [], "entities": [{"text": "Joint", "start_pos": 49, "end_pos": 54, "type": "METRIC", "confidence": 0.9573695659637451}, {"text": "POS tagging", "start_pos": 129, "end_pos": 140, "type": "TASK", "confidence": 0.7917124330997467}]}, {"text": " Table 2: POS tagging results.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.7504673600196838}]}, {"text": " Table 3: Parsing results on the dev and test sets.", "labels": [], "entities": []}, {"text": " Table 4: Syntactic analogy test results on the 300 most  frequent supertags. Avg. rank is the average position  of the correct choice in the ranked list of the closest  neighbors; the top line indicates the result of using su- pertag embeddings that are trained jointly with a tran- sition based parser (Friedman et al., 2017).", "labels": [], "entities": [{"text": "Syntactic analogy", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.7600895166397095}, {"text": "Avg. rank", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.9817887941996256}]}, {"text": " Table 5: PETE test results. Precision (P), recall (R),  and F1 are calculated for \"entails.\"", "labels": [], "entities": [{"text": "Precision (P)", "start_pos": 29, "end_pos": 42, "type": "METRIC", "confidence": 0.957185834646225}, {"text": "recall (R)", "start_pos": 44, "end_pos": 54, "type": "METRIC", "confidence": 0.9684283286333084}, {"text": "F1", "start_pos": 61, "end_pos": 63, "type": "METRIC", "confidence": 0.9997851252555847}]}]}