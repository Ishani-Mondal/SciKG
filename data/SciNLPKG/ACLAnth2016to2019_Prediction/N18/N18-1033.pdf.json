{"title": [{"text": "Classical Structured Prediction Losses for Sequence to Sequence Learning", "labels": [], "entities": [{"text": "Sequence to Sequence Learning", "start_pos": 43, "end_pos": 72, "type": "TASK", "confidence": 0.8631687760353088}]}], "abstractContent": [{"text": "There has been much recent work on training neural attention models at the sequence-level using either reinforcement learning-style methods or by optimizing the beam.", "labels": [], "entities": []}, {"text": "In this paper, we survey a range of classical objective functions that have been widely used to train linear models for structured prediction and apply them to neural sequence to sequence models.", "labels": [], "entities": [{"text": "structured prediction", "start_pos": 120, "end_pos": 141, "type": "TASK", "confidence": 0.7306041419506073}]}, {"text": "Our experiments show that these losses can perform surprisingly well by slightly outperforming beam search optimization in alike for like setup.", "labels": [], "entities": [{"text": "beam search optimization", "start_pos": 95, "end_pos": 119, "type": "TASK", "confidence": 0.8395834167798361}]}, {"text": "We also report new state of the art results on both IWSLT'14 German-English translation as well as Giga-word abstractive summarization.", "labels": [], "entities": [{"text": "IWSLT'14 German-English translation", "start_pos": 52, "end_pos": 87, "type": "TASK", "confidence": 0.702414353688558}, {"text": "Giga-word abstractive summarization", "start_pos": 99, "end_pos": 134, "type": "TASK", "confidence": 0.7103689312934875}]}, {"text": "On the large WMT'14 English-French task, sequence-level training achieves 41.5 BLEU which is on par with the state of the art.", "labels": [], "entities": [{"text": "WMT'14 English-French task", "start_pos": 13, "end_pos": 39, "type": "DATASET", "confidence": 0.7403058012326559}, {"text": "BLEU", "start_pos": 79, "end_pos": 83, "type": "METRIC", "confidence": 0.9996204376220703}]}], "introductionContent": [{"text": "Sequence to sequence models are usually trained with a simple token-level likelihood loss.", "labels": [], "entities": []}, {"text": "However, attest time, these models do not produce a single token but a whole sequence.", "labels": [], "entities": []}, {"text": "In order to resolve this inconsistency and to potentially improve generation, recent work has focused on training these models at the sequence-level, for instance using REINFORCE (, actor-critic (, or with beam search optimization.", "labels": [], "entities": [{"text": "REINFORCE", "start_pos": 169, "end_pos": 178, "type": "METRIC", "confidence": 0.949010968208313}]}, {"text": "Before the recent work on sequence level training for neural networks, there has been a large body of research on training linear models at the * Equal contribution.", "labels": [], "entities": []}, {"text": "An implementation of the losses is available as part of fairseq at https://github.com/ facebookresearch/fairseq-py/tree/ classic_seqlevel sequence level.", "labels": [], "entities": []}, {"text": "For example, direct loss optimization has been popularized in machine translation with the Minimum Error Rate Training algorithm (MERT; Och 2003) and expected risk minimization has an extensive history in NLP ().", "labels": [], "entities": [{"text": "direct loss optimization", "start_pos": 13, "end_pos": 37, "type": "TASK", "confidence": 0.7444215019543966}, {"text": "machine translation", "start_pos": 62, "end_pos": 81, "type": "TASK", "confidence": 0.7041015177965164}, {"text": "Minimum Error Rate Training algorithm (MERT", "start_pos": 91, "end_pos": 134, "type": "METRIC", "confidence": 0.7312476464680263}, {"text": "expected risk minimization", "start_pos": 150, "end_pos": 176, "type": "TASK", "confidence": 0.6488798956076304}]}, {"text": "This paper revisits several objective functions that have been commonly used for structured prediction tasks in NLP ( and apply them to a neural sequence to sequence model () ( \u00a72).", "labels": [], "entities": []}, {"text": "Specifically, we consider likelihood training at the sequencelevel, a margin loss as well as expected risk training.", "labels": [], "entities": []}, {"text": "We also investigate several combinations of global losses with token-level likelihood.", "labels": [], "entities": []}, {"text": "This is, to our knowledge, the most comprehensive comparison of structured losses in the context of neural sequence to sequence models ( \u00a73).", "labels": [], "entities": []}, {"text": "We experiment on the IWSLT'14 GermanEnglish translation task () as well as the Gigaword abstractive summarization task (.", "labels": [], "entities": [{"text": "IWSLT'14 GermanEnglish translation task", "start_pos": 21, "end_pos": 60, "type": "TASK", "confidence": 0.7184801548719406}, {"text": "Gigaword abstractive summarization", "start_pos": 79, "end_pos": 113, "type": "TASK", "confidence": 0.7328988512357076}]}, {"text": "We achieve the best reported accuracy to date on both tasks.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9820305705070496}]}, {"text": "We find that the sequence level losses we survey perform similarly to one another and outperform beam search optimization) on a comparable setup.", "labels": [], "entities": []}, {"text": "On WMT'14 English-French, we also illustrate the effectiveness of risk minimization on a larger translation task.", "labels": [], "entities": [{"text": "WMT'14 English-French", "start_pos": 3, "end_pos": 24, "type": "DATASET", "confidence": 0.9373320937156677}, {"text": "translation task", "start_pos": 96, "end_pos": 112, "type": "TASK", "confidence": 0.8975806832313538}]}, {"text": "Classical losses for structured prediction are still very competitive and effective for neural models ( \u00a75, \u00a76).", "labels": [], "entities": [{"text": "structured prediction", "start_pos": 21, "end_pos": 42, "type": "TASK", "confidence": 0.8020390570163727}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Test accuracy in terms of BLEU on IWSLT'14  German-English translation with various loss functions  cf.", "labels": [], "entities": [{"text": "Test", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.8748297095298767}, {"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9370623826980591}, {"text": "BLEU", "start_pos": 36, "end_pos": 40, "type": "METRIC", "confidence": 0.9994242191314697}, {"text": "IWSLT'14  German-English translation", "start_pos": 44, "end_pos": 80, "type": "DATASET", "confidence": 0.8715204000473022}]}, {"text": " Table 2: Validation and test BLEU for loss combina- tion strategies. We either use token-level TokLS and  sequence-level Riskindividually or combine them as  a weighted combination, a constrained combination, a  random choice for each sample, cf.  \u00a73.3.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.9989088773727417}]}, {"text": " Table 3: Effect of initializing sequence-level training  (Risk) with parameters from token-level likelihood  (TokNLL) or label smoothing (TokLS).", "labels": [], "entities": []}, {"text": " Table 4: Generating candidates online or offline.", "labels": [], "entities": []}, {"text": " Table 5: Comparison to Beam Search Optimization.  We report the best likelihood (MLE) and BSO results  from Wiseman and Rush (2016), as well as results from  our MLE reimplementation and training with Risk.  Results based on unnormalized beam search (k = 5).", "labels": [], "entities": [{"text": "Beam Search Optimization", "start_pos": 24, "end_pos": 48, "type": "TASK", "confidence": 0.8791401187578837}, {"text": "best likelihood (MLE)", "start_pos": 65, "end_pos": 86, "type": "METRIC", "confidence": 0.8386310935020447}, {"text": "BSO", "start_pos": 91, "end_pos": 94, "type": "METRIC", "confidence": 0.929772675037384}]}, {"text": " Table 6: Accuracy on Gigaword abstractive sum- marization in terms of F-measure Rouge-1 (RG-1),  Rouge-2 (RG-2), and Rouge-L (RG-L) for token-level  label smoothing, and Risk optimization of all three  ROUGE F1 metrics.", "labels": [], "entities": [{"text": "Gigaword abstractive sum- marization", "start_pos": 22, "end_pos": 58, "type": "TASK", "confidence": 0.6946201801300049}, {"text": "token-level  label smoothing", "start_pos": 137, "end_pos": 165, "type": "TASK", "confidence": 0.6773033936818441}, {"text": "Risk optimization", "start_pos": 171, "end_pos": 188, "type": "TASK", "confidence": 0.7653531134128571}]}, {"text": " Table 7: Test and valid BLEU on WMT'14 English- French with and without decoder self-attention.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9639067053794861}, {"text": "WMT'14 English- French", "start_pos": 33, "end_pos": 55, "type": "DATASET", "confidence": 0.9346310496330261}]}]}