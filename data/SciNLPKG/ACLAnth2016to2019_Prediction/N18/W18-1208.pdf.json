{"title": [{"text": "Fast Query Expansion for an Accounting Corpus using Sub-word Embeddings", "labels": [], "entities": []}], "abstractContent": [{"text": "We present early results from a system underdevelopment which uses sub-word em-beddings for query expansion in the presence of misspelled words and other aberrations.", "labels": [], "entities": [{"text": "query expansion", "start_pos": 92, "end_pos": 107, "type": "TASK", "confidence": 0.7341201305389404}]}, {"text": "We work fora company which creates accounting software and the end goal is to improve customer experience when they search for help on our \"Customer Care\" portal.", "labels": [], "entities": []}, {"text": "Our customers use colloquial language, non-standard acronyms and sometimes misspell words when they use our Search portal or interact over other channels.", "labels": [], "entities": []}, {"text": "However , our Knowledge Base has curated content which leverages technical terms and is in language which is quite formal.", "labels": [], "entities": []}, {"text": "This results in the answer not being retrieved even though the answer might actually be present in the documentation (as assessed by a human).", "labels": [], "entities": []}, {"text": "We address this problem by creating equivalence classes of words with similar meanings (with the additional property that the map-pings to these equivalence classes are robust to mis-spellings) using sub-word embeddings and then use them to fine tune a Search index to improve recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 277, "end_pos": 283, "type": "METRIC", "confidence": 0.989483654499054}]}], "introductionContent": [{"text": "Accounting and taxation is a complex domainespecially for small businesses who might not have the necessary accounting skills but yet need to be compliant with regulations.", "labels": [], "entities": [{"text": "Accounting and taxation", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8700367410977682}]}, {"text": "Hence consumers of accounting software frequently seek advice both about accounting as well as about the product itself.", "labels": [], "entities": []}, {"text": "During an audit process when we started to analyze customers' queries with the help of internal experts, we realised that fora significant number of queries the answers were already available but not retrieved by the search engine because it relies only on keyword based search.", "labels": [], "entities": []}, {"text": "This is primarily due to the following reasons: 1.", "labels": [], "entities": []}, {"text": "Self employed and small business owners use colloquial language and terms like I didn't receive the money customer XYZ owes tome instead of I didn't receive my receivables from XYX 2.", "labels": [], "entities": []}, {"text": "Even when customers use accounting terms there are misspellings or structural variants (Form1040 vs Form1040-ES)", "labels": [], "entities": [{"text": "Form1040", "start_pos": 88, "end_pos": 96, "type": "DATASET", "confidence": 0.940150260925293}, {"text": "Form1040-ES", "start_pos": 100, "end_pos": 111, "type": "DATASET", "confidence": 0.9396336078643799}]}], "datasetContent": [{"text": "In this section we discuss the overall objective of the experiment and then mention details about the dataset, pre-processing, training and hyperparameter tuning.", "labels": [], "entities": []}, {"text": "We realised that the dataset for validating the benefit from this system had to have the following properties: 1.", "labels": [], "entities": []}, {"text": "For each query we had to know the matching answer.", "labels": [], "entities": []}, {"text": "This was to be used as ground truth.", "labels": [], "entities": []}, {"text": "2. We wanted the answer to be relevant to the matching query but did not want the words in the query to be a subset of words in the answer.", "labels": [], "entities": []}, {"text": "This is because had there been good word overlap there wouldn't be a need for query expansion.", "labels": [], "entities": [{"text": "query expansion", "start_pos": 78, "end_pos": 93, "type": "TASK", "confidence": 0.7801738381385803}]}, {"text": "After failing to find a well-researched corpus around accounting we decided to use, which is a manual written by the Internal Revenue Service (IRS), USA to provide information about personal income tax to taxpayers.", "labels": [], "entities": []}, {"text": "While we have also performed experiments on our proprietary knowledge base, for this paper we chose (IRS, 2017) because it is a widely used document and is also available in the public domain.", "labels": [], "entities": [{"text": "IRS, 2017)", "start_pos": 101, "end_pos": 111, "type": "DATASET", "confidence": 0.9026316851377487}]}, {"text": "This will enable the larger NLP community to verify and expand upon our findings.", "labels": [], "entities": []}, {"text": "shows the layout of atypical page in books like.", "labels": [], "entities": []}, {"text": "Our basic idea was to use perturbed versions of \"headings\" (see Section 3.2.1) as queries (perturbed to mimic mis-spellings/typos from real: Starting with raw data from), a skipgram model (see Section 3.3) was trained, followed by identifying and indexing 10 nearest neighbors per word.", "labels": [], "entities": []}, {"text": "This set of nearest neighbors was then provided to Elasticsearch (ES) as a \"Synonyms\" file which was internally incorporated into the ES index.", "labels": [], "entities": [{"text": "ES index", "start_pos": 134, "end_pos": 142, "type": "DATASET", "confidence": 0.807331383228302}]}, {"text": "users) and to use content in the \"body\" as documents.", "labels": [], "entities": []}, {"text": "Since several downstream models depend on tokenization, we wish to state that for all experiments in this paper we tokenized words using whitespace and using punctuation symbols.", "labels": [], "entities": []}], "tableCaptions": []}