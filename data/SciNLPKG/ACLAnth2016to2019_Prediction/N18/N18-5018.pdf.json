{"title": [{"text": "SMILEE: Symmetric Multi-modal Interactions with Language-gesture Enabled (AI) Embodiment", "labels": [], "entities": []}], "abstractContent": [{"text": "We demonstrate an intelligent conversational agent system designed for advancing human-machine collaborative tasks.", "labels": [], "entities": []}, {"text": "The agent is able to interpret a user's communicative intent from both their verbal utterances and non-verbal behaviors , such as gestures.", "labels": [], "entities": []}, {"text": "The agent is also itself able to communicate both with natural language and gestures, through its embodiment as an avatar thus facilitating natural symmetric multi-modal interactions.", "labels": [], "entities": []}, {"text": "We demonstrate two intelligent agents with specialized skills in the Blocks World as use-cases of our system.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent advances in speech recognition and natural language processing techniques have resulted in increasing use of intelligent assistants, such as Google Assistant, Siri, and Alexa, in our daily lives, replacing keyboard or touch interfaces.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.7442807257175446}]}, {"text": "However, the interactions with these assistants are still limited to just the verbal modality.", "labels": [], "entities": []}, {"text": "In this paper, we present an intelligent conversational agent system (SMILEE) designed to advance the state of the art in human-machine interaction.", "labels": [], "entities": []}, {"text": "The main idea underlying this system is the observation that non-verbal behavior (primarily gestures) encodes information that both complements and supplements speech in humanto-human communication.", "labels": [], "entities": []}, {"text": "Our studies in the Blocks-World (BW) have shown that gestures are frequently used with speech taking on both complementary roles (reinforcing the meaning) and supplementary roles (adding information to what was verbalized), and contribute towards facilitating communication).", "labels": [], "entities": []}, {"text": "Thus we assert that gestures need to betaken into account when deducing the meaning of complex ideas exchanged during communication and this has to be * amir.tamrakar@sri.com done in a joint-inferencing process along with the natural language understanding process.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 226, "end_pos": 256, "type": "TASK", "confidence": 0.6945229570070902}]}, {"text": "In the same vein, we also assert that communication between humans and computers should be symmetric and multi-modal in both directions for it to be truly natural.", "labels": [], "entities": []}, {"text": "Thus, in order to facilitate the communication of a machines complex ideas to the human, the machine's utterances also need to be embellished with appropriate non-verbal behaviors.", "labels": [], "entities": []}, {"text": "This argues for using a computer-generated avatar for embodying the machine.", "labels": [], "entities": []}, {"text": "Only then will humans be able to naturally communicate with machines, as they do with other humans.", "labels": [], "entities": []}, {"text": "Not only will this ease the communication but it also allow the communication to be more accurate.", "labels": [], "entities": []}, {"text": "In the following sections, we summarize various components of SMILEE and demonstrate two preliminary use-cases we have built.", "labels": [], "entities": [{"text": "SMILEE", "start_pos": 62, "end_pos": 68, "type": "TASK", "confidence": 0.7136130928993225}]}], "datasetContent": [], "tableCaptions": []}