{"title": [{"text": "What's in a Domain? Learning Domain-Robust Text Representations using Adversarial Training", "labels": [], "entities": [{"text": "Learning Domain-Robust Text Representations", "start_pos": 20, "end_pos": 63, "type": "TASK", "confidence": 0.5588748902082443}]}], "abstractContent": [{"text": "Most real world language problems require learning from heterogenous corpora, raising the problem of learning robust models which generalise well to both similar (in domain) and dissimilar (out of domain) instances to those seen in training.", "labels": [], "entities": []}, {"text": "This requires learning an underlying task, while not learning irrelevant signals and biases specific to individual domains.", "labels": [], "entities": []}, {"text": "We propose a novel method to optimise both in-and out-of-domain accuracy based on joint learning of a structured neural model with domain-specific and domain-general components , coupled with adversarial training for domain.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9904118180274963}]}, {"text": "Evaluating on multi-domain language identification and multi-domain sentiment analysis, we show substantial improvements over standard domain adaptation techniques , and domain-adversarial training.", "labels": [], "entities": [{"text": "multi-domain language identification", "start_pos": 14, "end_pos": 50, "type": "TASK", "confidence": 0.6440234879652659}, {"text": "multi-domain sentiment analysis", "start_pos": 55, "end_pos": 86, "type": "TASK", "confidence": 0.7529540956020355}, {"text": "domain adaptation", "start_pos": 135, "end_pos": 152, "type": "TASK", "confidence": 0.7407918274402618}]}], "introductionContent": [{"text": "Heterogeneity is pervasive in NLP, arising from corpora being constructed from different sources, featuring different topics, register, writing style, etc.", "labels": [], "entities": [{"text": "Heterogeneity", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.9196906685829163}]}, {"text": "An important, yet elusive, goal is to produce NLP tools that are capable of handling all types of texts, such that we can have, e.g., text classifiers that work well on texts from newswire to wikis to micro-blogs.", "labels": [], "entities": []}, {"text": "A key roadblock is application to new domains, unseen in training.", "labels": [], "entities": []}, {"text": "Accordingly, training needs to be robust to domain variation, such that domain-general concepts are learned in preference to domain-specific phenomena, which will not transfer well to out-of-domain evaluation.", "labels": [], "entities": []}, {"text": "To illustrate, report learning formatting quirks of specific reviewers in a review text regression task, which are unlikely to prove useful on other texts.", "labels": [], "entities": []}, {"text": "This classic problem in NLP has been tackled under the guise of \"domain adaptation\", also known as unsupervised transfer learning, using feature-based methods to support knowledge transfer over multiple domains).", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 65, "end_pos": 82, "type": "TASK", "confidence": 0.750699520111084}]}, {"text": "More recently, proposed a method to encourage domain-general text representations, which transfer better to new domains.", "labels": [], "entities": []}, {"text": "Inspired by the above methods, in this paper we propose a novel technique for multitask learning of domain-general representations.", "labels": [], "entities": []}, {"text": "Specifically, we propose deep learning architectures for multi-domain learning, featuring a shared representation, and domain private representation.", "labels": [], "entities": []}, {"text": "Our approach generalises the feature augmentation method of to convolutional neural networks, as part of a larger deep learning architecture.", "labels": [], "entities": []}, {"text": "Additionally, we use adversarial training such that the shared representation is explicitly discouraged from learning domain identifying information ().", "labels": [], "entities": []}, {"text": "We present two architectures which differ in whether domain is conditioned on or generated, and in terms of parameter sharing in forming private representations.", "labels": [], "entities": []}, {"text": "We primarily evaluate on the task of language identification), using the corpora of, which combine large training sets over a diverse range of text domains.", "labels": [], "entities": [{"text": "language identification", "start_pos": 37, "end_pos": 60, "type": "TASK", "confidence": 0.7675143182277679}]}, {"text": "Domain adaptation is an important problem for this task, where text resources are collected from numerous sources, and exhibit a wide variety of language use.", "labels": [], "entities": [{"text": "Domain adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7774211764335632}]}, {"text": "We show that while domain adversarial training overall improves over baselines, gains are modest.", "labels": [], "entities": []}, {"text": "The same applies to twin shared/private architectures, but when the two methods are combined, we observe substantial improvements.", "labels": [], "entities": []}, {"text": "Overall, our methods outperform the state-of-the-art) in terms of out-of-domain accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.990429699420929}]}, {"text": "As a secondary evaluation, we use the MultiDomain Sentiment Dataset (, where we once again observe a clear advantage for our approaches, illustrating the potential of our technique more broadly in NLP.", "labels": [], "entities": [{"text": "MultiDomain Sentiment Dataset", "start_pos": 38, "end_pos": 67, "type": "DATASET", "confidence": 0.5627415974934896}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Accuracy [%] of different models over five in- domain datasets using cross-validation evaluation and  macro-averaged accuracy (\"ALL in \").", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9850639700889587}, {"text": "accuracy", "start_pos": 127, "end_pos": 135, "type": "METRIC", "confidence": 0.9126424789428711}]}, {"text": " Table 3: Accuracy [%] of different models over 4 do- mains (B, D, E and K) under out-of-domain evalua- tions on Multi Domain Sentiment Dataset. Key: \u2663  from Blitzer et al. (2007); \u2666 from Ganin and Lempitsky  (2015).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9782716631889343}]}]}