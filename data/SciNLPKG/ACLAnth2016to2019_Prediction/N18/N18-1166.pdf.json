{"title": [{"text": "Inducing Temporal Relations from Time Anchor Annotation", "labels": [], "entities": [{"text": "Inducing Temporal Relations from Time Anchor Annotation", "start_pos": 0, "end_pos": 55, "type": "TASK", "confidence": 0.8353041069848197}]}], "abstractContent": [{"text": "Recognizing temporal relations among events and time expressions has been an essential but challenging task in natural language processing.", "labels": [], "entities": [{"text": "Recognizing temporal relations among events and time expressions", "start_pos": 0, "end_pos": 64, "type": "TASK", "confidence": 0.8707142248749733}, {"text": "natural language processing", "start_pos": 111, "end_pos": 138, "type": "TASK", "confidence": 0.6336241861184438}]}, {"text": "Conventional annotation of judging temporal relations puts a heavy load on annota-tors.", "labels": [], "entities": [{"text": "judging temporal relations", "start_pos": 27, "end_pos": 53, "type": "TASK", "confidence": 0.8371442755063375}]}, {"text": "In reality, the existing annotated corpora include annotations on only \"salient\" event pairs, or on pairs in a fixed window of sentences.", "labels": [], "entities": []}, {"text": "In this paper, we propose anew approach to obtain temporal relations from absolute time value (a.k.a. time anchors), which is suitable for texts containing rich temporal information such as news articles.", "labels": [], "entities": []}, {"text": "We start from time anchors for events and time expressions, and temporal relation annotations are induced automatically by computing relative order of two time anchors.", "labels": [], "entities": []}, {"text": "This proposal shows several advantages over the current methods for temporal relation annotation: it requires less annotation effort, can induce inter-sentence relations easily, and increases informativeness of temporal relations.", "labels": [], "entities": [{"text": "temporal relation annotation", "start_pos": 68, "end_pos": 96, "type": "TASK", "confidence": 0.652826597293218}]}, {"text": "We compare the empirical statistics and automatic recognition results with our data against a previous temporal relation corpus.", "labels": [], "entities": [{"text": "automatic recognition", "start_pos": 40, "end_pos": 61, "type": "TASK", "confidence": 0.6078010052442551}]}, {"text": "We also reveal that our data contributes to a significant improvement of the downstream time anchor prediction task, demonstrating 14.1 point increase in overall accuracy.", "labels": [], "entities": [{"text": "downstream time anchor prediction", "start_pos": 77, "end_pos": 110, "type": "TASK", "confidence": 0.6519863083958626}, {"text": "accuracy", "start_pos": 162, "end_pos": 170, "type": "METRIC", "confidence": 0.9980447292327881}]}], "introductionContent": [{"text": "Temporal information extraction is becoming an active research field in natural language processing (NLP) due to the rapidly growing need for NLP applications such as timeline generation and question answering (.", "labels": [], "entities": [{"text": "Temporal information extraction", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.9052814443906149}, {"text": "natural language processing (NLP)", "start_pos": 72, "end_pos": 105, "type": "TASK", "confidence": 0.7822083135445913}, {"text": "timeline generation", "start_pos": 167, "end_pos": 186, "type": "TASK", "confidence": 0.8909946382045746}, {"text": "question answering", "start_pos": 191, "end_pos": 209, "type": "TASK", "confidence": 0.9188846945762634}]}, {"text": "It has great potential to create many practical applications.", "labels": [], "entities": []}, {"text": "For example, collects news articles about a target entity and the task required participants automatically ordering the events involving that entity in a timeline.", "labels": [], "entities": []}, {"text": "The timeline representation of news can help people more easily comprehend amass of information.", "labels": [], "entities": []}, {"text": "This work aims to contribute to such timeline applications by extracting temporal information in specific domains like news articles.", "labels": [], "entities": []}, {"text": "TimeBank 1 () is the first widely used corpus with temporal information annotated in the NLP community.", "labels": [], "entities": [{"text": "TimeBank 1", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.8248886168003082}]}, {"text": "It contains 183 news articles that have been annotated with events, time expressions and temporal relations between events and time expressions.", "labels": [], "entities": []}, {"text": "The annotation follows the TimeML 2 specification ().", "labels": [], "entities": [{"text": "TimeML 2 specification", "start_pos": 27, "end_pos": 49, "type": "DATASET", "confidence": 0.9216709136962891}]}, {"text": "Along with the TimeBank and other temporal information corpora, a series of competitions on temporal information extraction (TempEval-1,2,3) () are attracting growing research efforts.", "labels": [], "entities": [{"text": "TimeBank", "start_pos": 15, "end_pos": 23, "type": "DATASET", "confidence": 0.9344520568847656}, {"text": "temporal information extraction", "start_pos": 92, "end_pos": 123, "type": "TASK", "confidence": 0.6375169257322947}]}, {"text": "A majority of temporal information corpora adopt temporal links (TLINKs) to encode temporal information in documents.", "labels": [], "entities": []}, {"text": "A TLINK denotes a temporal relation between mentions, i.e., events, time expressions and document creation time (DCT)).", "labels": [], "entities": []}, {"text": "However, annotating TLINKs is a painful work, because annotation candidates are quadratic to the number of mentions in a document.", "labels": [], "entities": [{"text": "annotating TLINKs", "start_pos": 9, "end_pos": 26, "type": "TASK", "confidence": 0.6882881820201874}]}, {"text": "The original TimeBank only annotated those \"salient\" mention pairs judged by annotators, while the definition of \"salient\" is not necessarily clear.", "labels": [], "entities": [{"text": "TimeBank", "start_pos": 13, "end_pos": 21, "type": "DATASET", "confidence": 0.9790589213371277}]}, {"text": "Annotators had to face a complicated task; identify \"salient\" mention pairs, and label temporal relations.", "labels": [], "entities": []}, {"text": "For solving this, many dense annotation schemata are proposed to force annotators to annotate more or even complete graph pairs.", "labels": [], "entities": []}, {"text": "However, dense annotation is time-consuming and unstable human judgments on \"salient\" pairs are not improved at all.", "labels": [], "entities": []}, {"text": "As a consequence, a high proportion of \"vague\" or \"nolink\" pairs appears in these dense corpora such as TimeBank-Dense ( ).", "labels": [], "entities": [{"text": "TimeBank-Dense", "start_pos": 104, "end_pos": 118, "type": "DATASET", "confidence": 0.9774088859558105}]}, {"text": "In this work, we propose anew approach to obtain temporal relations from time anchors, i.e. absolute time value, of all mentions.", "labels": [], "entities": []}, {"text": "We assume that a temporal relation can be induced by comparing the relative temporal order of two time anchors (e.g. YYYY-MM-DD) in a time axis.", "labels": [], "entities": []}, {"text": "We use pre-defined rules (Section 3) to generate temporal order (TORDER) relations (e.g. BEFORE, AFTER, SAME DAY, etc.) by taking two annotated time anchors as input.", "labels": [], "entities": [{"text": "TORDER", "start_pos": 65, "end_pos": 71, "type": "METRIC", "confidence": 0.650734007358551}, {"text": "BEFORE", "start_pos": 89, "end_pos": 95, "type": "METRIC", "confidence": 0.9881088137626648}, {"text": "AFTER", "start_pos": 97, "end_pos": 102, "type": "METRIC", "confidence": 0.7675361037254333}, {"text": "SAME DAY", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.6478034555912018}]}, {"text": "This proposal requires the annotation of time anchors, of which the annotation effort is linear with the number of mentions.", "labels": [], "entities": []}, {"text": "This is the first work to obtain temporal relations shifted from the annotation of individual mentions, which is distinguished from most annotation work of manually annotating mention pairs.", "labels": [], "entities": []}, {"text": "This approach brings several advantages over the current temporal relation annotation.", "labels": [], "entities": []}, {"text": "First, as long as time anchors of all mentions in a document are given, our pre-defined rules can induce the temporal relations for all the quadratic pairs.", "labels": [], "entities": []}, {"text": "This skips the step of identifying \"salient\" pairs.", "labels": [], "entities": []}, {"text": "Second, annotating the time anchors is relatively easy, as the annotation work is linear to the number of mentions.", "labels": [], "entities": [{"text": "annotating the time anchors", "start_pos": 8, "end_pos": 35, "type": "TASK", "confidence": 0.6459314227104187}]}, {"text": "Third, the automatic generation rules can provide flexible relation types based on our definition and this increased informativeness might contribute positively to downstream tasks.", "labels": [], "entities": []}, {"text": "In our first evaluation (Section 4), we compare the correspondence and difference between the new TORDERs and conventional TLINKs.", "labels": [], "entities": [{"text": "TORDERs", "start_pos": 98, "end_pos": 105, "type": "METRIC", "confidence": 0.4666285812854767}]}, {"text": "The comparison of empirical statistics shows the new data is label balanced, contains informative relations and reduces \"vague\" relations.", "labels": [], "entities": []}, {"text": "Besides, the classification performance suggests the new data achieve reasonable accuracy, although accuracy numbers are not directly comparable.", "labels": [], "entities": [{"text": "classification", "start_pos": 13, "end_pos": 27, "type": "TASK", "confidence": 0.9624879360198975}, {"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.999150276184082}, {"text": "accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.9990358352661133}]}, {"text": "Many text processing tasks are often requiring to know time anchors when events occurred in a timeline.", "labels": [], "entities": [{"text": "text processing", "start_pos": 5, "end_pos": 20, "type": "TASK", "confidence": 0.7902932465076447}, {"text": "know time anchors when events occurred in a timeline", "start_pos": 50, "end_pos": 102, "type": "TASK", "confidence": 0.7817533546023898}]}, {"text": "In Section 5, we evaluate the data in a downstream time anchor prediction task () by using the temporal relation recognizers separately trained with TORDERs or TLINKs.", "labels": [], "entities": [{"text": "time anchor prediction task", "start_pos": 51, "end_pos": 78, "type": "TASK", "confidence": 0.7285762131214142}, {"text": "temporal relation recognizers", "start_pos": 95, "end_pos": 124, "type": "TASK", "confidence": 0.6121225853761038}, {"text": "TORDERs", "start_pos": 149, "end_pos": 156, "type": "METRIC", "confidence": 0.9156039953231812}]}, {"text": "The main results show that the recognizer trained with our TORDERs significantly outperforms the recognizer trained with the TLINKs by 14.1 point exact match accuracy.", "labels": [], "entities": [{"text": "exact match accuracy", "start_pos": 146, "end_pos": 166, "type": "METRIC", "confidence": 0.7872474988301595}]}], "datasetContent": [{"text": "In this section, we describe a two-step system trained with the existing TLINKs and our data to challenge a downstream time anchor prediction task.", "labels": [], "entities": [{"text": "downstream time anchor prediction task", "start_pos": 108, "end_pos": 146, "type": "TASK", "confidence": 0.6993203938007355}]}, {"text": "The different performance can be seen as the evidence whether our auto-generated TORDERs can capture comparable temporal information to the human-annotated TLINKs.", "labels": [], "entities": []}, {"text": "In this work, we adopt a similar two-step architecture.", "labels": [], "entities": []}, {"text": "The first-step temporal order classifier is designed to provide the temporal relations of the mention pairs in a document.", "labels": [], "entities": []}, {"text": "The second-step selects the most precise time by taking all Event-Time and Event-DCT relations of a target event as input.", "labels": [], "entities": []}, {"text": "For instance in, the second-step received a set of relations e.g. (is included, DCT ), (is included, F riday) and (vague, January) of reported.", "labels": [], "entities": [{"text": "DCT", "start_pos": 80, "end_pos": 83, "type": "METRIC", "confidence": 0.7550075054168701}, {"text": "F", "start_pos": 101, "end_pos": 102, "type": "METRIC", "confidence": 0.9644957184791565}]}, {"text": "For the system trained with the TimeBank-Dense TLINKs, we adopt the same selection algorithm as described in: The comparison of the cross-validation performance in the time anchor prediction task.", "labels": [], "entities": [{"text": "TimeBank-Dense TLINKs", "start_pos": 32, "end_pos": 53, "type": "DATASET", "confidence": 0.8981187641620636}, {"text": "time anchor prediction task", "start_pos": 168, "end_pos": 195, "type": "TASK", "confidence": 0.8157212734222412}]}, {"text": "'Exact' and 'Partial' denote the two evaluation metrics: exact match and partial match accuracy.", "labels": [], "entities": [{"text": "exact match", "start_pos": 57, "end_pos": 68, "type": "METRIC", "confidence": 0.9191173613071442}, {"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.8093553185462952}]}, {"text": "'Gold' denotes the oracle performance of using the gold TORDERs or gold TLINKs as the input of the second-step.", "labels": [], "entities": [{"text": "TORDERs", "start_pos": 56, "end_pos": 63, "type": "METRIC", "confidence": 0.9781566858291626}]}, {"text": "We perform a 6-fold cross-validation strategy to predict all the TORDERs and TLINKs of the mention pairs in the 36 documents of the TimeBankDense corpus.", "labels": [], "entities": [{"text": "TORDERs", "start_pos": 65, "end_pos": 72, "type": "METRIC", "confidence": 0.998204231262207}, {"text": "TLINKs", "start_pos": 77, "end_pos": 83, "type": "METRIC", "confidence": 0.7311798930168152}, {"text": "TimeBankDense corpus", "start_pos": 132, "end_pos": 152, "type": "DATASET", "confidence": 0.9758380651473999}]}, {"text": "In each run, we split 30 documents for training and validation to predict the other 6 test documents.", "labels": [], "entities": []}, {"text": "We define two evaluation metrics, i.e. Exact Match accuracy and Partial Match accuracy to measure the performance in this task as follows: exact match = #Number of the exact match predictions #Total number of the test samples partial match = #Number of the partial match predictions #Total number of the test samples We define two partial match cases: 1) a precise (1998-02-06) is partial match with an imprecise (after 1998-02-06), if the date values are the same.", "labels": [], "entities": [{"text": "Exact Match accuracy", "start_pos": 39, "end_pos": 59, "type": "METRIC", "confidence": 0.7636052568753561}, {"text": "Partial Match accuracy", "start_pos": 64, "end_pos": 86, "type": "METRIC", "confidence": 0.45008009672164917}, {"text": "exact match", "start_pos": 139, "end_pos": 150, "type": "METRIC", "confidence": 0.96539306640625}]}, {"text": "2) (after 1998-02-06) is partial match with (after 1998-02-06, before 1998-02-21), if one is apart of the other.", "labels": [], "entities": []}, {"text": "summarizes the main results of the twostep time anchor prediction system trained with TORDER and TLINK data.", "labels": [], "entities": [{"text": "twostep time anchor prediction", "start_pos": 35, "end_pos": 65, "type": "TASK", "confidence": 0.5584337264299393}, {"text": "TORDER", "start_pos": 86, "end_pos": 92, "type": "METRIC", "confidence": 0.9295752644538879}, {"text": "TLINK", "start_pos": 97, "end_pos": 102, "type": "METRIC", "confidence": 0.9137288331985474}]}, {"text": "'Precise', 'Imprecise' and 'Overall' denote the results of predicting time anchors of precise events, imprecise events, and overall performance.", "labels": [], "entities": [{"text": "Precise", "start_pos": 1, "end_pos": 8, "type": "METRIC", "confidence": 0.9876285791397095}, {"text": "Imprecise", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.9795007705688477}, {"text": "predicting time anchors of precise events", "start_pos": 59, "end_pos": 100, "type": "TASK", "confidence": 0.8588802516460419}]}, {"text": "'Event-DCT' or 'EventTime' denotes the second-step selection takes only Event-DCT or Event-Time pairs as input, which helps us to investigate how much information is provided by the different types of pairs for predicting the final time anchors.", "labels": [], "entities": [{"text": "predicting the final time anchors", "start_pos": 211, "end_pos": 244, "type": "TASK", "confidence": 0.7318607449531556}]}, {"text": "The new TORDERs show significantly superior out-performance in all three settings (i.e. only Event-DCT pairs, only Event-Time pairs, or Event-DCT + Event-Time), compared to the TLINKs.", "labels": [], "entities": [{"text": "TORDERs", "start_pos": 8, "end_pos": 15, "type": "METRIC", "confidence": 0.6989446878433228}]}, {"text": "With both Event-DCT and Event-Time temporal order information, the system achieves the highest overall exact match and partial match accuracy.", "labels": [], "entities": [{"text": "exact match", "start_pos": 103, "end_pos": 114, "type": "METRIC", "confidence": 0.8512726426124573}, {"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.8542579412460327}]}], "tableCaptions": [{"text": " Table 3: The comparison of the numbers of TORDER  and TLINK annotations for the same mention  pairs. b:before, a:after, s:simultaneous, i:includes,  ii:is included, v:vague.", "labels": [], "entities": [{"text": "TORDER", "start_pos": 43, "end_pos": 49, "type": "METRIC", "confidence": 0.6341350078582764}]}, {"text": " Table 4: The classification results of Event-Event,  Event-DCT and Event-Time F1-measure on individual  relation types and weighted overall F1. 'N' denotes the  number of the relations in the test split.", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 79, "end_pos": 89, "type": "METRIC", "confidence": 0.6859052777290344}, {"text": "F1", "start_pos": 141, "end_pos": 143, "type": "METRIC", "confidence": 0.9966033697128296}]}, {"text": " Table 5: The comparison of the cross-validation performance in the time anchor prediction task. 'Exact' and  'Partial' denote the two evaluation metrics: exact match and partial match accuracy. 'Gold' denotes the oracle  performance of using the gold TORDERs or gold TLINKs as the input of the second-step.", "labels": [], "entities": [{"text": "time anchor prediction task", "start_pos": 68, "end_pos": 95, "type": "TASK", "confidence": 0.7365601435303688}, {"text": "accuracy", "start_pos": 185, "end_pos": 193, "type": "METRIC", "confidence": 0.5178188681602478}, {"text": "TORDERs", "start_pos": 252, "end_pos": 259, "type": "METRIC", "confidence": 0.7892643213272095}]}, {"text": " Table 6: The comparison to the state-of-the-art dense  TLINK classifier", "labels": [], "entities": []}]}