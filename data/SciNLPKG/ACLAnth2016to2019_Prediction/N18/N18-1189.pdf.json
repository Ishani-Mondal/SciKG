{"title": [{"text": "EMR Coding with Semi-Parametric Multi-Head Matching Networks", "labels": [], "entities": [{"text": "EMR Coding", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.7405200898647308}]}], "abstractContent": [{"text": "Coding EMRs with diagnosis and procedure codes is an indispensable task for billing, secondary data analyses, and monitoring health trends.", "labels": [], "entities": [{"text": "billing", "start_pos": 76, "end_pos": 83, "type": "TASK", "confidence": 0.9626398086547852}]}, {"text": "Both speed and accuracy of coding are critical.", "labels": [], "entities": [{"text": "speed", "start_pos": 5, "end_pos": 10, "type": "METRIC", "confidence": 0.9950904846191406}, {"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9995352029800415}, {"text": "coding", "start_pos": 27, "end_pos": 33, "type": "TASK", "confidence": 0.9520029425621033}]}, {"text": "While coding errors could lead to more patient-side financial burden and misinterpretation of a patient's well-being, timely coding is also needed to avoid backlogs and additional costs for the healthcare facility.", "labels": [], "entities": []}, {"text": "In this paper, we present anew neural network architecture that combines ideas from few-shot learning matching networks, multi-label loss functions, and convolutional neural networks for text classification to significantly outper-form other state-of-the-art models.", "labels": [], "entities": [{"text": "text classification", "start_pos": 187, "end_pos": 206, "type": "TASK", "confidence": 0.8188072443008423}]}, {"text": "Our evaluations are conducted using a well known de-identified EMR dataset (MIMIC) with a variety of multi-label performance measures.", "labels": [], "entities": [{"text": "EMR dataset (MIMIC)", "start_pos": 63, "end_pos": 82, "type": "DATASET", "confidence": 0.796093887090683}]}], "introductionContent": [{"text": "Electronic medical record (EMR) coding is the process of extracting diagnosis and procedure codes from the digital record (the EMR) pertaining to a patient's visit.", "labels": [], "entities": [{"text": "Electronic medical record (EMR) coding", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.5709701946803502}]}, {"text": "The digital record is mostly composed of multiple textual narratives (e.g., discharge summaries, pathology reports, progress notes) authored by healthcare professionals, typically doctors, nurses, and lab technicians.", "labels": [], "entities": []}, {"text": "Hospitals heavily invest in training and retaining professional EMR coders to manually annotate all patient visits by reviewing EMRs.", "labels": [], "entities": []}, {"text": "Proprietary commercial software tools often termed as computerassisted coding (CAC) systems are already in use in many healthcare facilities and were found to be helpful in increasing medical coder productivity ().", "labels": [], "entities": [{"text": "computerassisted coding (CAC)", "start_pos": 54, "end_pos": 83, "type": "TASK", "confidence": 0.7795981764793396}]}, {"text": "Thus progress in automated EMR coding methods is expected to directly impact real world operations.", "labels": [], "entities": [{"text": "EMR coding", "start_pos": 27, "end_pos": 37, "type": "TASK", "confidence": 0.9488048851490021}]}, {"text": "In the US, the diagnosis and procedure codes used in EMR coding are from the International Classification of Diseases (ICD) terminology (specifically the ICD-10-CM variant) as required by the Health Insurance Portability and Accountability Act (HIPPA).", "labels": [], "entities": [{"text": "EMR coding", "start_pos": 53, "end_pos": 63, "type": "TASK", "confidence": 0.9742684960365295}]}, {"text": "ICD codes facilitate billing activities, retrospective epidemiological studies, and also enable researchers to aggregate health statistics and monitor health trends.", "labels": [], "entities": [{"text": "ICD", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.599583625793457}, {"text": "billing", "start_pos": 21, "end_pos": 28, "type": "TASK", "confidence": 0.9708597660064697}]}, {"text": "To code EMRs effectively, medical coders are expected to have thorough knowledge of ICD-10-CM and follow a complex set of guidelines to code EMRs.", "labels": [], "entities": [{"text": "ICD-10-CM", "start_pos": 84, "end_pos": 93, "type": "DATASET", "confidence": 0.8016231656074524}]}, {"text": "For example, if a coder accidentally uses the code \"heart failure\" (ICD-10-CM code I50) instead of \"acute systolic (congestive) heart failure\" (ICD-10-CM code I50.21), then the patient maybe charged substantially more 1 causing significant unfair burden.", "labels": [], "entities": [{"text": "ICD-10-CM code I50", "start_pos": 68, "end_pos": 86, "type": "DATASET", "confidence": 0.9142758846282959}, {"text": "ICD-10-CM code I50.21", "start_pos": 144, "end_pos": 165, "type": "DATASET", "confidence": 0.9074307680130005}]}, {"text": "Therefore, it is important for coders to have better tools at their disposal to find the most appropriate codes.", "labels": [], "entities": []}, {"text": "Additionally, if coders become more efficient, hospitals may hire fewer coders to reduce their operating costs.", "labels": [], "entities": []}, {"text": "Thus automated coding methods are expected to help with expedited coding, cost savings, and error control.", "labels": [], "entities": []}, {"text": "In this paper, we treat medical coding of EMR narratives as a multi-label text classification problem.", "labels": [], "entities": [{"text": "medical coding of EMR narratives", "start_pos": 24, "end_pos": 56, "type": "TASK", "confidence": 0.8285080432891846}, {"text": "multi-label text classification", "start_pos": 62, "end_pos": 93, "type": "TASK", "confidence": 0.6822939117749532}]}, {"text": "Multi-label classification (MLC) is a machine learning task that assigns a set of labels (typically from a fixed terminology) to an instance.", "labels": [], "entities": [{"text": "Multi-label classification (MLC)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8930244088172913}]}, {"text": "MLC is different from multi-class problems, which assign a single label to each example from a set of labels.", "labels": [], "entities": [{"text": "MLC", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9369555711746216}]}, {"text": "Compared to general multi-label problems, EMR coding has three distinct challenges.", "labels": [], "entities": [{"text": "EMR coding", "start_pos": 42, "end_pos": 52, "type": "TASK", "confidence": 0.974991112947464}]}, {"text": "First, with thousands of ICD codes, the label space is large and the label distribution is extremely unbalanced -most codes occur very infrequently with a few codes occurring several orders of magnitude more than others.", "labels": [], "entities": []}, {"text": "Second and more importantly, a patient may have a large number of diagnoses and procedures.", "labels": [], "entities": []}, {"text": "On average, coders annotate an EMR with more than 20 such codes and hence predicting the top one or two codes is not sufficient for EMR coding.", "labels": [], "entities": [{"text": "EMR coding", "start_pos": 132, "end_pos": 142, "type": "TASK", "confidence": 0.9560359418392181}]}, {"text": "Third, EMR narratives maybe very long (e.g., discharge summaries may have over 1000 words), which may result in a needle in a haystack situation when attempting to seek evidence for particular codes.", "labels": [], "entities": [{"text": "EMR", "start_pos": 7, "end_pos": 10, "type": "TASK", "confidence": 0.935444712638855}]}, {"text": "Recent advances in extreme multi-label classification have proven to work well for large label spaces.", "labels": [], "entities": [{"text": "multi-label classification", "start_pos": 27, "end_pos": 53, "type": "TASK", "confidence": 0.7242406010627747}]}, {"text": "Many of these methods () focus on creating efficient multi-label models that can handle 10 4 to 10 6 labels.", "labels": [], "entities": []}, {"text": "While these models perform well in large label spaces, they don't necessarily focus on improving prediction of infrequent labels.", "labels": [], "entities": []}, {"text": "Typically, they optimize for the top 1, 3, or 5 ranked labels by focusing on the P@1, P@3, and P@5 evaluation measures.", "labels": [], "entities": []}, {"text": "The labels ranked at the top usually occur frequently in the dataset and it is not obvious how to handle infrequent labels.", "labels": [], "entities": []}, {"text": "One solution would be to ignore the rare labels.", "labels": [], "entities": []}, {"text": "However, when the majority of medical codes are infrequent, this solution is unsatisfactory.", "labels": [], "entities": []}, {"text": "While neural networks have shown great promise for text classification, the label imbalances associated with EMR coding hinder their performance.", "labels": [], "entities": [{"text": "text classification", "start_pos": 51, "end_pos": 70, "type": "TASK", "confidence": 0.8688519895076752}]}, {"text": "Imagine if a dataset contains only one training example for every class leading to one-shot learning, a subtask of few-shot learning.", "labels": [], "entities": []}, {"text": "How can we classify anew instance?", "labels": [], "entities": [{"text": "classify anew instance", "start_pos": 11, "end_pos": 33, "type": "TASK", "confidence": 0.8837965130805969}]}, {"text": "A trivial solution would be to use a non-parametric 1-NN (1 nearest neighbor) classifier.", "labels": [], "entities": []}, {"text": "1-NN does not require learning any label specific parameters and we only need to define features to represent our data and a distance metric.", "labels": [], "entities": []}, {"text": "Unfortunately, defining good features and picking the best distance metric is nontrivial.", "labels": [], "entities": []}, {"text": "Instead of manually defining the feature set and distance metric, neural network training procedures have been developed to learn them automatically (.", "labels": [], "entities": []}, {"text": "For example, matching networks ( can automatically learn discriminative feature representations and a useful distance metric.", "labels": [], "entities": []}, {"text": "Therefore, using a 1-NN prediction method, matching networks work well for infrequent labels.", "labels": [], "entities": []}, {"text": "However, researchers typically evaluate matching networks on multi-class problems without label imbalance.", "labels": [], "entities": []}, {"text": "For EMR coding with extreme label imbalance with several labels occurring thousands of times, traditional parametric neural networks should work very well on the frequent labels.", "labels": [], "entities": [{"text": "EMR coding", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.951289713382721}]}, {"text": "In this paper, we introduce anew variant of matching networks ( to address the EMR coding problem.", "labels": [], "entities": [{"text": "EMR coding", "start_pos": 79, "end_pos": 89, "type": "TASK", "confidence": 0.6196057498455048}]}, {"text": "Specifically, we combine the non-parametric idea of k-NN and matching networks with traditional neural network text classification methods to handle both frequent and infrequent labels encountered in EMR coding.", "labels": [], "entities": [{"text": "text classification", "start_pos": 111, "end_pos": 130, "type": "TASK", "confidence": 0.7694366276264191}, {"text": "EMR coding", "start_pos": 200, "end_pos": 210, "type": "TASK", "confidence": 0.84654101729393}]}, {"text": "Overall, we make the following contributions in this paper: \u2022 We propose a novel semi-parametric neural matching network for diagnosis/procedure code prediction from EMR narratives.", "labels": [], "entities": [{"text": "diagnosis/procedure code prediction", "start_pos": 125, "end_pos": 160, "type": "TASK", "confidence": 0.8421073317527771}]}, {"text": "Our architecture employs ideas from matching networks (), multiple attention (, multi-label loss functions (, and convolutional neural networks (CNNs) for text classification to produce a state-ofthe-art EMR coding model.", "labels": [], "entities": [{"text": "text classification", "start_pos": 155, "end_pos": 174, "type": "TASK", "confidence": 0.7798380553722382}, {"text": "EMR coding", "start_pos": 204, "end_pos": 214, "type": "TASK", "confidence": 0.8761248290538788}]}, {"text": "\u2022 We evaluate our model on publicly available EMR datasets to ensure reproducibility and benchmarking; we also compare against prior state-of-the-art methods in EMR coding and demonstrate robustness across multiple standard evaluation measures.", "labels": [], "entities": [{"text": "EMR datasets", "start_pos": 46, "end_pos": 58, "type": "DATASET", "confidence": 0.7166448682546616}, {"text": "EMR coding", "start_pos": 161, "end_pos": 171, "type": "TASK", "confidence": 0.8986610770225525}]}, {"text": "\u2022 We analyze and measure how each component of our model affects the performance using ablation experiments.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we compare our work with prior state-of-the-art medical coding methods.", "labels": [], "entities": []}, {"text": "In Section 4.1 we discuss the two publicly available datasets we use.", "labels": [], "entities": []}, {"text": "Next, Section 4.2 describes the implementation details of our model.", "labels": [], "entities": []}, {"text": "We summarize the various baselines and models we compare against in Section 4.3.", "labels": [], "entities": []}, {"text": "The evaluation metrics are described in Section 4.4.", "labels": [], "entities": []}, {"text": "Finally, we discuss how our method performs in Section 4.5..", "labels": [], "entities": []}, {"text": "For comparison purposes, we use the same MIMIC II train/test splits as.", "labels": [], "entities": [{"text": "MIMIC II train/test splits", "start_pos": 41, "end_pos": 67, "type": "DATASET", "confidence": 0.7691226104895273}]}, {"text": "Specifically, we use discharge reports collected from 2001 to 2008 from the intensive care unit (ICU) of the Beth Israel Deaconess Medical Center.", "labels": [], "entities": []}, {"text": "Following, the labels for each discharge summary are extended using the parent of each label in label set.", "labels": [], "entities": []}, {"text": "The parents are based on the ICD-9-CM hierarchy.", "labels": [], "entities": [{"text": "ICD-9-CM hierarchy", "start_pos": 29, "end_pos": 47, "type": "DATASET", "confidence": 0.7435078024864197}]}, {"text": "We use the hierarchical label expansion to maximize the prior work we can compare against.", "labels": [], "entities": []}, {"text": "The MIMIC III dataset has been extended to include health records of patients admitted to the Beth Israel Deaconess Medical Center from 2001 to 2012 and hence provides a test bed for more advanced learning methods.", "labels": [], "entities": [{"text": "MIMIC III dataset", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.74946262439092}]}, {"text": "Unfortunately, it does not have a standard train/test split to compare against prior work given we believe we are the first to look at it for this purpose.", "labels": [], "entities": []}, {"text": "Hence, we use both MIMIC II and MIMIC III for comparison purposes.", "labels": [], "entities": []}, {"text": "Furthermore, we do not use the hierarchical label expansion on the MIMIC III dataset.", "labels": [], "entities": [{"text": "MIMIC III dataset", "start_pos": 67, "end_pos": 84, "type": "DATASET", "confidence": 0.887480636437734}]}, {"text": "Before we present our results, we discuss an essential distinction between the MIMIC II and MIMIC III datasets.", "labels": [], "entities": [{"text": "MIMIC II and MIMIC III datasets", "start_pos": 79, "end_pos": 110, "type": "DATASET", "confidence": 0.7025571217139562}]}, {"text": "Particularly, we are interested in the differences concerning label imbalance.", "labels": [], "entities": []}, {"text": "From, we find that MIMIC III has almost twice as many examples compared to MIMIC II in the dataset.", "labels": [], "entities": [{"text": "MIMIC III", "start_pos": 19, "end_pos": 28, "type": "TASK", "confidence": 0.6148432493209839}]}, {"text": "However, MIMIC II on average has more instances per label.", "labels": [], "entities": [{"text": "MIMIC II", "start_pos": 9, "end_pos": 17, "type": "TASK", "confidence": 0.5396304428577423}]}, {"text": "Thus, although MIMIC III has more examples, each label is used fewer times on average compared to MIMIC II.", "labels": [], "entities": []}, {"text": "The reason for this is because of how the label sets for each instance were extended using the ICD-9 hierarchy in MIMIC II.", "labels": [], "entities": [{"text": "ICD-9 hierarchy", "start_pos": 95, "end_pos": 110, "type": "DATASET", "confidence": 0.9356470704078674}]}, {"text": "We evaluate our method using a wide variety of standard multi-label evaluation metrics.", "labels": [], "entities": []}, {"text": "We use the popular micro and macro averaged F1 measures to assess how our model (with the MetaL-    abeler) performs when thresholding predictions.", "labels": [], "entities": [{"text": "F1", "start_pos": 44, "end_pos": 46, "type": "METRIC", "confidence": 0.9295997619628906}]}, {"text": "For problems with large labels spaces that suffer from significant imbalances in label distributions, the default threshold of 0.5 generally performs poorly (hence our use of MetaLabeler).", "labels": [], "entities": []}, {"text": "To remove the thresholding effect bias, we also report different versions of the area under the precision-recall (PR) and receiver operating characteristic (ROC) curves.", "labels": [], "entities": [{"text": "precision-recall (PR)", "start_pos": 96, "end_pos": 117, "type": "METRIC", "confidence": 0.9435307085514069}, {"text": "receiver operating characteristic (ROC)", "start_pos": 122, "end_pos": 161, "type": "METRIC", "confidence": 0.8953365882237753}]}, {"text": "Finally, in a real-world setting, our system would not be expected to replace medical coders.", "labels": [], "entities": []}, {"text": "We would expect medical coders to use our system to become more efficient in coding EMRs.", "labels": [], "entities": [{"text": "coding EMRs", "start_pos": 77, "end_pos": 88, "type": "TASK", "confidence": 0.8440154194831848}]}, {"text": "Therefore, we would rank the labels based on model confidence and medical coders would choose the correct labels from the top few.", "labels": [], "entities": []}, {"text": "To understand if our system would be useful in a real-world setting, we evaluate with precision at k (P@k) and recall at k (R@k).", "labels": [], "entities": [{"text": "precision", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9991046786308289}, {"text": "recall", "start_pos": 111, "end_pos": 117, "type": "METRIC", "confidence": 0.9984673857688904}]}, {"text": "Having high P@k and R@k are critical to effectively encourage the human coders to use and benefit from the system.", "labels": [], "entities": [{"text": "P@k", "start_pos": 12, "end_pos": 15, "type": "METRIC", "confidence": 0.9516234993934631}, {"text": "R@k", "start_pos": 20, "end_pos": 23, "type": "METRIC", "confidence": 0.9595977663993835}]}], "tableCaptions": [{"text": " Table 1: This table presents the number of training  examples (# Train), the number of test examples (#  Test), label cardinality (LC), and the average number  of instances per label (AI/L) for the MIMIC II and  MIMIC III datasets.", "labels": [], "entities": [{"text": "label cardinality (LC)", "start_pos": 113, "end_pos": 135, "type": "METRIC", "confidence": 0.8260516166687012}, {"text": "MIMIC III datasets", "start_pos": 213, "end_pos": 231, "type": "DATASET", "confidence": 0.7318702141443888}]}, {"text": " Table 2: Results for the MIMIC II dataset. Models marked with * represent our custom implementations.", "labels": [], "entities": [{"text": "MIMIC II dataset", "start_pos": 26, "end_pos": 42, "type": "DATASET", "confidence": 0.7157243291536967}]}, {"text": " Table 3: Results for the MIMIC III dataset. Models marked with * represent our custom implementations.", "labels": [], "entities": [{"text": "MIMIC III dataset", "start_pos": 26, "end_pos": 43, "type": "DATASET", "confidence": 0.7292153636614481}]}, {"text": " Table 4: Ablation results for the MIMIC III dataset.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9956088662147522}, {"text": "MIMIC III dataset", "start_pos": 35, "end_pos": 52, "type": "DATASET", "confidence": 0.8546542525291443}]}]}