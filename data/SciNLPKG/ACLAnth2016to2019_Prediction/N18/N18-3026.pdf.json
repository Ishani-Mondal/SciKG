{"title": [{"text": "Personalized neural language models for real-world query auto completion", "labels": [], "entities": []}], "abstractContent": [{"text": "Query auto completion (QAC) systems area standard part of search engines in industry, helping users formulate their query.", "labels": [], "entities": [{"text": "Query auto completion (QAC)", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7462222625811895}]}, {"text": "Such systems update their suggestions after the user types each character, predicting the user's intent using various signals-one of the most common being popularity.", "labels": [], "entities": []}, {"text": "Recently, deep learning approaches have been proposed for the QAC task, to specifically address the main limitation of previous popularity-based methods: the inability to predict unseen queries.", "labels": [], "entities": [{"text": "QAC task", "start_pos": 62, "end_pos": 70, "type": "TASK", "confidence": 0.8757210075855255}]}, {"text": "In this work we improve previous methods based on neural language modeling, with the goal of building an end-to-end system.", "labels": [], "entities": [{"text": "neural language modeling", "start_pos": 50, "end_pos": 74, "type": "TASK", "confidence": 0.702153205871582}]}, {"text": "We particularly focus on using real-world data by integrating user information for personalized suggestions when possible.", "labels": [], "entities": []}, {"text": "We also make use of time information and study how to increase diversity in the suggestions while studying the impact on scalability.", "labels": [], "entities": []}, {"text": "Our empirical results demonstrate a marked improvement on two separate datasets over previous best methods in both accuracy and scalability, making a step towards neural query auto-completion in production search engines.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.9988850951194763}]}], "introductionContent": [{"text": "Predicting the next characters or words following a prefix has had multiple uses from helping handicapped people ( to, more recently, helping search engine users.", "labels": [], "entities": [{"text": "Predicting the next characters or words following a prefix", "start_pos": 0, "end_pos": 58, "type": "TASK", "confidence": 0.8502851525942484}]}, {"text": "In practice, most search engines today use query auto completion (QAC) systems, consisting of suggesting queries as users type in the search box ().", "labels": [], "entities": [{"text": "query auto completion (QAC)", "start_pos": 43, "end_pos": 70, "type": "TASK", "confidence": 0.6362988402446111}]}, {"text": "The task suffers from high dimensionality, because the number of possible solutions increases as the length of the target query increases.", "labels": [], "entities": []}, {"text": "Historically, the query prediction task has been addressed by relying on query logs, particularly the popularity of past queries).", "labels": [], "entities": [{"text": "query prediction task", "start_pos": 18, "end_pos": 39, "type": "TASK", "confidence": 0.8998958865801493}]}, {"text": "The idea is to rely on the wisdom of the crowd, as popular queries matching a typed prefix are more likely to be the user's intent.", "labels": [], "entities": []}, {"text": "This traditional approach is usually referred to as MostPopularCompletion (MPC)).", "labels": [], "entities": []}, {"text": "However, the performance of MPC is skewed: it is very high for popular queries and very low for rare queries.", "labels": [], "entities": [{"text": "MPC", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.8084260821342468}]}, {"text": "At the extreme, MPC simply cannot predict a query it has never seen.", "labels": [], "entities": [{"text": "MPC", "start_pos": 16, "end_pos": 19, "type": "DATASET", "confidence": 0.6947345733642578}]}, {"text": "This becomes a bigger problem in academic search (, where systems are typically less used, with a wider range of possible queries.", "labels": [], "entities": []}, {"text": "Recent advances in deep learning, particularly in semantic modeling ( and neural language modeling showed promising results for predicting rare queries.", "labels": [], "entities": [{"text": "semantic modeling", "start_pos": 50, "end_pos": 67, "type": "TASK", "confidence": 0.8626197874546051}, {"text": "predicting rare queries", "start_pos": 128, "end_pos": 151, "type": "TASK", "confidence": 0.8958588242530823}]}, {"text": "In this work, we propose to improve the state-of-the-art approaches in neural QAC by integrating personalization and time sensitivity information as well as addressing current MPC limitations by diversifying the suggestions, thus approaching a production-ready architecture.", "labels": [], "entities": []}], "datasetContent": [{"text": "The AOL query logs () are commonly used to evaluate the quality of QAC systems.", "labels": [], "entities": [{"text": "AOL query logs", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.7390787402788798}]}, {"text": "We rely on a background dataset for the NN; training and validation datasets for lambdaMART integrations; and a test dataset for evaluations.", "labels": [], "entities": [{"text": "NN", "start_pos": 40, "end_pos": 42, "type": "DATASET", "confidence": 0.7791848182678223}]}, {"text": "Some adaptations are done to the AOL background dataset as in, such as removing the queries appearing less than 3 times or longer that 100 characters.", "labels": [], "entities": [{"text": "AOL background dataset", "start_pos": 33, "end_pos": 55, "type": "DATASET", "confidence": 0.9042896628379822}]}, {"text": "For each query in the training, validation and test datasets, we use all possible prefixes starting after the first word as in  Systems are evaluated using the traditional Mean Reciprocal Rank (MRR) metric.", "labels": [], "entities": [{"text": "Mean Reciprocal Rank (MRR) metric", "start_pos": 172, "end_pos": 205, "type": "METRIC", "confidence": 0.8476138710975647}]}, {"text": "This metric assesses the quality of suggestions by identifying the rank of the real query in the suggestions given one of its prefixes.", "labels": [], "entities": []}, {"text": "We also tested PMRR as introduced in) and observed the same trends in results as MRR, so we do not show them due to space limitation.", "labels": [], "entities": [{"text": "MRR", "start_pos": 81, "end_pos": 84, "type": "METRIC", "confidence": 0.7711905241012573}]}, {"text": "Given the set of prefixes P in the test dataset, MRR is defined as follows: where r p represent the rank of the match.", "labels": [], "entities": [{"text": "MRR", "start_pos": 49, "end_pos": 52, "type": "METRIC", "confidence": 0.6509577035903931}]}, {"text": "Paired t-tests measure the significance of score variations among systems and are reported in the Results section.", "labels": [], "entities": [{"text": "Paired", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9363972544670105}]}, {"text": "We also evaluate prediction time as this is an important parameter for building production systems.", "labels": [], "entities": [{"text": "prediction", "start_pos": 17, "end_pos": 27, "type": "TASK", "confidence": 0.9297155737876892}]}, {"text": "The prediction time is averaged over 10 runs on the test set, on the same hardware for all models.", "labels": [], "entities": []}, {"text": "We do not evaluate throughput but rather compare the time required by all approaches to process one prefix.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: MRR results for all tested models on the AOL and biomedical datasets with their average prediction time  in seconds.", "labels": [], "entities": [{"text": "MRR", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.6988539099693298}, {"text": "AOL and biomedical datasets", "start_pos": 51, "end_pos": 78, "type": "DATASET", "confidence": 0.8568947911262512}]}]}