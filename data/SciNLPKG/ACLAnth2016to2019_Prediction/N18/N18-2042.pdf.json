{"title": [{"text": "Letting Emotions Flow: Success Prediction by Modeling the Flow of Emotions in Books", "labels": [], "entities": [{"text": "Success Prediction", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.639981135725975}]}], "abstractContent": [{"text": "Books have the power to make us feel happiness , sadness, pain, surprise, or sorrow.", "labels": [], "entities": []}, {"text": "An author's dexterity in the use of these emotions captivates readers and makes it difficult for them to put the book down.", "labels": [], "entities": []}, {"text": "In this paper, we model the flow of emotions over a book using recurrent neural networks and quantify its usefulness in predicting success in books.", "labels": [], "entities": []}, {"text": "We obtained the best weighted F1-score of 69% for predicting books' success in a multitask setting (simultaneously predicting success and genre of books).", "labels": [], "entities": [{"text": "F1-score", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9931457042694092}]}], "introductionContent": [{"text": "Books have the power to evoke a multitude of emotions in their readers.", "labels": [], "entities": []}, {"text": "They can make readers laugh at a comic scene, cry at a tragic scene and even feel pity or hate for the characters.", "labels": [], "entities": []}, {"text": "Specific patterns of emotion flow within books can compel the reader to finish the book, and possibly pursue similar books in the future.", "labels": [], "entities": []}, {"text": "Like a musical arrangement, the right emotional rhythm can arouse readers, but even a slight variation in the composition might turn them away.", "labels": [], "entities": []}, {"text": "discussed the potential of plotting emotions in stories on the \"Beginning-End\" and the \"Ill Fortune-Great Fortune\" axes.", "labels": [], "entities": []}, {"text": "used mathematical tools like Singular Value Decomposition, agglomerative clustering, and Self Organizing Maps () to generate basic shapes of stories.", "labels": [], "entities": []}, {"text": "They found that stories are dominated by six different shapes.", "labels": [], "entities": []}, {"text": "They even correlated these different shapes to the success of books.", "labels": [], "entities": []}, {"text": "Mohammad (2011) visualized emotion densities across books of different genres.", "labels": [], "entities": []}, {"text": "He found that the progression of emotions varies with the genre.", "labels": [], "entities": []}, {"text": "For example, there is a stronger progression into darkness in horror stories than in comedy.", "labels": [], "entities": []}, {"text": "Likewise, showed that movies having similar flow of emotions across their plot synopses were assigned similar set of tags by the viewers.", "labels": [], "entities": []}, {"text": "As an example, in, we draw the flow of emotions across the book: Alice in Wonderland.", "labels": [], "entities": [{"text": "Alice in Wonderland", "start_pos": 65, "end_pos": 84, "type": "DATASET", "confidence": 0.8163925806681315}]}, {"text": "The plot shows continuous change in trust, fear, and sadness, which relates to the main character's getting into and out of trouble.", "labels": [], "entities": []}, {"text": "These patterns present the emotional arcs of the story.", "labels": [], "entities": []}, {"text": "Even though they do not reveal the actual plot, they indicate major events happening in the story.", "labels": [], "entities": []}, {"text": "In this paper, we hypothesize that readers enjoy emotional rhythm and thus modeling emotion flows will help predicting a book's potential success.", "labels": [], "entities": []}, {"text": "In addition, we show that using the entire content of the book yields better results.", "labels": [], "entities": []}, {"text": "Considering only a fragment, as done in earlier work that focuses mainly on style (, disregards important emotional changes.", "labels": [], "entities": []}, {"text": "Similar to, we also find that adding genre as an auxiliary task improves success prediction.", "labels": [], "entities": []}], "datasetContent": [{"text": "We experimented with the dataset introduced by.", "labels": [], "entities": []}, {"text": "The dataset consists of 1,003 books from eight different genres collected from Project Gutenberg 1 . The authors considered only those books that were at least reviewed by ten reviewers.", "labels": [], "entities": []}, {"text": "They categorized these books into two classes, Successful (654 books) and Unsuccessful (349 books), based on the average rating for the books in Goodreads 2 website.", "labels": [], "entities": [{"text": "Goodreads 2 website", "start_pos": 145, "end_pos": 164, "type": "DATASET", "confidence": 0.9542105793952942}]}, {"text": "They considered only the first 1K sentences from each book.", "labels": [], "entities": []}, {"text": "We experimented with the same random stratified splits of 70:30 training to test ratio as used by.", "labels": [], "entities": []}, {"text": "We use the SVM algorithm for the baselines and RNN for our proposed emotion flow method.", "labels": [], "entities": [{"text": "RNN", "start_pos": 47, "end_pos": 50, "type": "METRIC", "confidence": 0.7984272241592407}, {"text": "emotion flow", "start_pos": 68, "end_pos": 80, "type": "TASK", "confidence": 0.7720034420490265}]}, {"text": "We tuned the C hyperparameter of the SVM classifier by performing grid search on the values..,4}), using threefold cross validation on the training split.", "labels": [], "entities": []}, {"text": "For the experiments with RNNs, we first took a random stratified split of 20% from the training data as validation set.", "labels": [], "entities": []}, {"text": "We then tuned the RNN hyperparameters by running 20 different experiments with a random selection of different values for the hyperparameters.", "labels": [], "entities": []}, {"text": "We tuned the weight initialization, LeCun Uniform (), learning rate with Adam (Kingma and Ba, 2015) {1e-4,.", "labels": [], "entities": []}, {"text": ",1e-1}, dropout rates {0.2,0.4,0.5}, attention and recurrent units {32, 64}, and batch-size {1, 4, 8} with early stopping criteria.: Weighted F1-scores for success classification in single task (ST) and multitask (MT) settings with varying chunk sequences when using all the book or only the first 1K sentences.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 142, "end_pos": 151, "type": "METRIC", "confidence": 0.9521524906158447}, {"text": "success classification", "start_pos": 156, "end_pos": 178, "type": "TASK", "confidence": 0.6527295261621475}]}, {"text": "* p < 0.05 (McNemar significance test between Emotion Flow (chunks 50, MT, All) and NRC+SVM (chunk 10, MT, All)) presents the results.", "labels": [], "entities": [{"text": "McNemar significance test", "start_pos": 12, "end_pos": 37, "type": "METRIC", "confidence": 0.8083913723627726}]}, {"text": "Our proposed method performs better than different baseline methods and obtains the highest weighted F1-score of 0.690.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 101, "end_pos": 109, "type": "METRIC", "confidence": 0.9928416013717651}]}, {"text": "The results highlight the importance of taking into account the sequential flow of emotions across books to predict how much readers will like a book.", "labels": [], "entities": []}, {"text": "We obtain better performance when we use an RNN to feed the sequences of emotion chunk vectors.", "labels": [], "entities": []}, {"text": "The performance decreases with the SVM classifier, which discards this sequential information by treating each feature independently of each other.", "labels": [], "entities": []}, {"text": "Moreover, increasing the granularity of the emotions by increasing the number of chunks seems to be helpful for success prediction.", "labels": [], "entities": [{"text": "success prediction", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.6347121596336365}]}, {"text": "However, we see a slight decrease in performance beyond 50 chunks (weighted F1 score of 0.662 and 0.664 for 60 and 100 chunks, respectively).", "labels": [], "entities": [{"text": "F1 score", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9852851331233978}]}], "tableCaptions": [{"text": " Table 1: Weighted F1-scores for success classification  in single task (ST) and multi task (MT) settings with  varying chunk sequences when using all the book or  only the first 1K sentences.  * p < 0.05 (McNemar sig- nificance test between Emotion Flow (chunks 50, MT,  All) and NRC+SVM (chunk 10, MT, All))", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.8591452836990356}, {"text": "success classification", "start_pos": 33, "end_pos": 55, "type": "TASK", "confidence": 0.6540613323450089}]}, {"text": " Table 2: Mean (\u00b5) and standard deviation (\u03c3) for eight type of emotions for the last chunk.", "labels": [], "entities": [{"text": "Mean (\u00b5)", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9581063985824585}, {"text": "standard deviation (\u03c3)", "start_pos": 23, "end_pos": 45, "type": "METRIC", "confidence": 0.9663033723831177}]}]}