{"title": [{"text": "How Time Matters: Learning Time-Decay Attention for Contextual Spoken Language Understanding in Dialogues", "labels": [], "entities": [{"text": "Learning Time-Decay Attention for Contextual Spoken Language Understanding in Dialogues", "start_pos": 18, "end_pos": 105, "type": "TASK", "confidence": 0.6544831573963166}]}], "abstractContent": [{"text": "Spoken language understanding (SLU) is an essential component in conversational systems.", "labels": [], "entities": [{"text": "Spoken language understanding (SLU)", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8841461439927419}]}, {"text": "Most SLU components treat each utterance independently, and then the following components aggregate the multi-turn information in the separate phases.", "labels": [], "entities": []}, {"text": "In order to avoid error propagation and effectively utilize contexts , prior work leveraged history for con-textual SLU.", "labels": [], "entities": [{"text": "error propagation", "start_pos": 18, "end_pos": 35, "type": "TASK", "confidence": 0.740870863199234}]}, {"text": "However, most previous models only paid attention to the related content in history utterances, ignoring their temporal information.", "labels": [], "entities": []}, {"text": "In the dialogues, it is intuitive that the most recent utterances are more important than the least recent ones, in other words, time-aware attention should be in a decaying manner.", "labels": [], "entities": []}, {"text": "Therefore, this paper designs and investigates various types of time-decay attention on the sentence-level and speaker-level, and further proposes a flexible universal time-decay attention mechanism.", "labels": [], "entities": []}, {"text": "The experiments on the benchmark Dialogue State Tracking Challenge (DSTC4) dataset show that the proposed time-decay attention mechanisms significantly improve the state-of-the-art model for contex-tual understanding performance 1 .", "labels": [], "entities": [{"text": "Dialogue State Tracking Challenge (DSTC4) dataset", "start_pos": 33, "end_pos": 82, "type": "DATASET", "confidence": 0.7802248448133469}]}], "introductionContent": [{"text": "Spoken dialogue systems that can help users to solve complex tasks such as booking a movie ticket have become an emerging research topic in artificial intelligence and natural language processing areas.", "labels": [], "entities": []}, {"text": "With a well-designed dialogue system as an intelligent personal assistant, people can accomplish certain tasks more easily via natural language interactions.", "labels": [], "entities": []}, {"text": "Today, there are several virtual intelligent assistants, such as Apple's Siri, Google's Home, Microsoft's Cortana, and Amazon's Echo.", "labels": [], "entities": []}, {"text": "Recent advance of deep learning has inspired many applications of neural models to dialogue systems.", "labels": [], "entities": []}, {"text": "A key component of a dialogue system is a spoken language understanding (SLU) moduleit parses user utterances into semantic frames that capture the core meaning.", "labels": [], "entities": [{"text": "spoken language understanding (SLU) moduleit parses user utterances into semantic frames", "start_pos": 42, "end_pos": 130, "type": "TASK", "confidence": 0.8436125975388747}]}, {"text": "A typical pipeline of SLU is to first decide the domain given the input utterance, and based on the domain, to predict the intent and to fill associated slots corresponding to a domainspecific semantic template, where each utterance is treated independently.", "labels": [], "entities": []}, {"text": "To overcome the error propagation and further improve understanding performance, the contextual information has been shown useful (.", "labels": [], "entities": []}, {"text": "Prior work incorporated the dialogue history into the recurrent neural networks (RNN) for improving domain classification, intent prediction, and slot filling ().", "labels": [], "entities": [{"text": "domain classification", "start_pos": 100, "end_pos": 121, "type": "TASK", "confidence": 0.7694844305515289}, {"text": "intent prediction", "start_pos": 123, "end_pos": 140, "type": "TASK", "confidence": 0.7336031794548035}, {"text": "slot filling", "start_pos": 146, "end_pos": 158, "type": "TASK", "confidence": 0.7536596655845642}]}, {"text": "Recently,  and demonstrated that modeling speaker role information can learn the notable variance in speaking habits during conversations in order to benefit understanding.", "labels": [], "entities": []}, {"text": "In addition, neural models incorporating attention mechanisms have had great successes in machine translation (), image captioning (, and various tasks.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 90, "end_pos": 109, "type": "TASK", "confidence": 0.7953156232833862}, {"text": "image captioning", "start_pos": 114, "end_pos": 130, "type": "TASK", "confidence": 0.7678482234477997}]}, {"text": "Attentional models have been successful because they separate two different concerns: 1) deciding which input contexts are most relevant to the output and 2) actually predicting an output given the most relevant inputs.", "labels": [], "entities": []}, {"text": "For example, the highlighted current utterance from the tourist, \"uh on august\", in the conversation of is to respond the question about WHEN, and the content-Guide: and you were saying that you wanted to come to singapore Guide: uh maybe can i have a little bit more details like uh when will you becoming Guide: and like who will you becoming with Tourist: uh yes Tourist: um i'm actually planning to visit Tourist: uh on august aware contexts that can help current understanding are the first two utterances from the guide \"and you were saying that you wanted to come to singapore\" and \"un maybe can i have a little bit more details like uh when will you be coming\".", "labels": [], "entities": [{"text": "WHEN", "start_pos": 137, "end_pos": 141, "type": "METRIC", "confidence": 0.6694912910461426}]}, {"text": "Previous work proposed an end-to-end time-aware attention network to leverage both contextual and temporal information for spoken language understanding and achieved the significant improvement, showing that the temporal attention can guide the attention effectively . However, the time-aware attention function is an inflexible hand-crafted setting, which is a fixed function of time for assessing the attention.", "labels": [], "entities": [{"text": "spoken language understanding", "start_pos": 123, "end_pos": 152, "type": "TASK", "confidence": 0.7105773091316223}]}, {"text": "This paper focuses on investigating various flexible time-aware attention mechanism in neural models with contextual information and speaker role modeling for language understanding.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 159, "end_pos": 181, "type": "TASK", "confidence": 0.743715763092041}]}, {"text": "The contributions are three-fold: \u2022 This paper investigates different time-aware attention mechanisms and provides guidance for the future research about designing the time-aware attention function.", "labels": [], "entities": []}, {"text": "\u2022 This paper proposes an end-to-end learnable universal time-decay mechanism with great flexibility of modeling temporal information for diverse dialogue contexts.", "labels": [], "entities": []}, {"text": "\u2022 The proposed model achieves the state-ofthe-art understanding performance in the dialogue benchmark DSTC dataset.", "labels": [], "entities": [{"text": "DSTC dataset", "start_pos": 102, "end_pos": 114, "type": "DATASET", "confidence": 0.8313020765781403}]}], "datasetContent": [{"text": "To evaluate the proposed model, we conduct the language understanding experiments on humanhuman conversational data.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 47, "end_pos": 69, "type": "TASK", "confidence": 0.7378325015306473}]}], "tableCaptions": [{"text": " Table 1: The understanding performance reported on F-measure in DSTC4, where the context length is 7 for each  speaker (%).  \u2020 indicates the significant improvement compared to all baseline methods. Hand: hand-crafted; E2E:  end-to-end trainable.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.8668739795684814}, {"text": "DSTC4", "start_pos": 65, "end_pos": 70, "type": "DATASET", "confidence": 0.8564411401748657}]}, {"text": " Table 2: The sentence-level performance reported on  F1 of the proposed universal time-decay attention un- der different context length settings (%). The symbols  '+' and '-' indicate the performance trends.", "labels": [], "entities": [{"text": "F1", "start_pos": 54, "end_pos": 56, "type": "METRIC", "confidence": 0.9982665777206421}]}, {"text": " Table 3: The converged values of end-to-end trainable  parameters from the proposed universal time-decay at- tention models. The values are averaged over five runs.", "labels": [], "entities": []}]}