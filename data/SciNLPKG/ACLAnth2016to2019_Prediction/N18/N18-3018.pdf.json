{"title": [{"text": "Fast and Scalable Expansion of Natural Language Understanding Functionality for Intelligent Agents", "labels": [], "entities": []}], "abstractContent": [{"text": "Fast expansion of natural language functional-ity of intelligent virtual agents is critical for achieving engaging and informative interactions.", "labels": [], "entities": []}, {"text": "However, developing accurate models for new natural language domains is a time and data intensive process.", "labels": [], "entities": []}, {"text": "We propose efficient deep neural network architectures that maximally re-use available resources through transfer learning.", "labels": [], "entities": []}, {"text": "Our methods are applied for expanding the understanding capabilities of a popular commercial agent and are evaluated on hundreds of new domains, designed by internal or external developers.", "labels": [], "entities": []}, {"text": "We demonstrate that our proposed methods significantly increase accuracy in low resource settings and enable rapid development of accurate models with less data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9976951479911804}]}], "introductionContent": [{"text": "Voice powered artificial agents have become widespread among consumer devices, with agents like Amazon Alexa, Google Now and Apple Siri being popular and widely used.", "labels": [], "entities": []}, {"text": "Their success relies not only on accurately recognizing user requests, but also on continuously expanding the range of requests that they can understand.", "labels": [], "entities": []}, {"text": "An ever growing set of functionalities is critical for creating an agent that is engaging, useful and human-like.", "labels": [], "entities": []}, {"text": "This presents significant scalability challenges regarding rapidly developing the models at the heart of the natural language understanding (NLU) engines of such agents.", "labels": [], "entities": []}, {"text": "Building accurate models for new functionality typically requires collection and manual annotation of new data resources, an expensive and lengthy process, often requiring highly skilled teams.", "labels": [], "entities": []}, {"text": "In addition, data collected from real user interactions is very valuable for developing accurate models but without an accurate model already in place, the agent will not enjoy widespread use thereby hindering collection of high quality data.", "labels": [], "entities": []}, {"text": "Presented with this challenge, our goal is to speedup the natural language expansion process for Amazon Alexa, a popular commercial artificial agent, through methods that maximize re-usability of resources across areas of functionality.", "labels": [], "entities": [{"text": "natural language expansion", "start_pos": 58, "end_pos": 84, "type": "TASK", "confidence": 0.6897621750831604}]}, {"text": "Each area of Alexa's functionality, e.g., Music, Calendar, is called a domain.", "labels": [], "entities": []}, {"text": "Our focus is to a) increase accuracy of low resource domains b) rapidly build new domains such that the functionality can be made available to Alexa's users as soon as possible, and thus start benefiting from user interaction data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9984081387519836}]}, {"text": "To achieve this, we adapt recent ideas at the intersection of deep learning and transfer learning that enable us to leverage available user interaction data from other areas of functionality.", "labels": [], "entities": []}, {"text": "To summarize our contributions, we describe data efficient deep learning architectures for NLU that facilitate knowledge transfer from similar tasks.", "labels": [], "entities": []}, {"text": "We evaluate our methods at a much larger scale than related transfer learning work in NLU, for fast and scalable expansion of hundreds of new natural language domains of Amazon Alexa, a commercial artificial agent.", "labels": [], "entities": []}, {"text": "We show that our methods achieve significant performance gains in low resource settings and enable building accurate functionality faster during early stages of model development by reducing reliance on large annotated datasets.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the transfer learning methods of Section 4.2 for both custom and built-in domains, and compare with baselines that do not benefit from knowledge transfer (Sections 4.1, 4.3).", "labels": [], "entities": []}, {"text": "We experiment with around 200 developer defined custom domains, whose statistics are presented in.", "labels": [], "entities": []}, {"text": "Looking at the median numbers, which are less influenced by a few large custom domains compared to mean values, we note that typically developers provide just a few tens of example phrases and few tens of values per gazetteer (slot gazetteer size).", "labels": [], "entities": []}, {"text": "Therefore, most custom domains are significantly under-resourced.", "labels": [], "entities": []}, {"text": "We also select three new built-in domains, and evaluate them at various early stages of domain development.", "labels": [], "entities": []}, {"text": "Here, we assume that variable amounts of training data grad-ually become available, including bootstrap and user interaction data.", "labels": [], "entities": []}, {"text": "We pre-train DNN models using millions of annotated utterances from existing mature built-in domains.", "labels": [], "entities": []}, {"text": "Each annotated utterance has an associated domain label, which we use to make sure that the pre-training data does not contain utterances labeled as any of the custom or built-in target domains.", "labels": [], "entities": []}, {"text": "After excluding the target domains, the pre-training data is randomly selected from a variety of mature Alexa domains covering hundreds of intents and slots across a wide range of natural language functionality.", "labels": [], "entities": []}, {"text": "For all experiments, we use L1 and L2 to regularize our DNN, CRF and MaxEnt models, while DNNs are additionally regularized with dropout.", "labels": [], "entities": []}, {"text": "The test sets contain user data, annotated for each custom or built-in domain.", "labels": [], "entities": []}, {"text": "For custom domains, test set size is a few hundred utterances per domain, while for built-in domains it is a few thousand utterances per domain.", "labels": [], "entities": []}, {"text": "Our metrics include standard F1 scores for the SC and IC tasks, and a sentence error rate (SER) defined as the ratio of utterances with at least one IC or ST error overall utterances.", "labels": [], "entities": [{"text": "F1", "start_pos": 29, "end_pos": 31, "type": "METRIC", "confidence": 0.999211311340332}, {"text": "sentence error rate (SER)", "start_pos": 70, "end_pos": 95, "type": "METRIC", "confidence": 0.8812153736750284}]}, {"text": "The latter metric combines IC and ST errors per utterance and reflects how many utterances we could not understand correctly.", "labels": [], "entities": [{"text": "IC", "start_pos": 27, "end_pos": 29, "type": "METRIC", "confidence": 0.9447159171104431}, {"text": "ST errors", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9013700783252716}]}], "tableCaptions": [{"text": " Table 1: Statistics of data for around 200 developer de- fined custom domains", "labels": [], "entities": []}, {"text": " Table 2: Results for around 200 custom developer domains. For F1, higher values are better, while for SER lower  values are better. * denotes statistically significant SER difference compared to both baselines.", "labels": [], "entities": [{"text": "F1", "start_pos": 63, "end_pos": 65, "type": "METRIC", "confidence": 0.9988387227058411}, {"text": "SER", "start_pos": 103, "end_pos": 106, "type": "METRIC", "confidence": 0.9932056665420532}, {"text": "SER difference", "start_pos": 169, "end_pos": 183, "type": "METRIC", "confidence": 0.868621826171875}]}, {"text": " Table 3: Results on domains A, B and C for the  proposed pretrained DNN method and the baseline  CRF/MaxEnt method during experimental early stages  of domain development. * denotes statistically signifi- cant SER difference between proposed and baseline", "labels": [], "entities": [{"text": "statistically signifi- cant SER difference", "start_pos": 183, "end_pos": 225, "type": "METRIC", "confidence": 0.632240042090416}]}]}