{"title": [{"text": "Bootstrapping a Neural Conversational Agent with Dialogue Self-Play, Crowdsourcing and On-Line Reinforcement Learning", "labels": [], "entities": []}], "abstractContent": [{"text": "End-to-end neural models show great promise towards building conversational agents that are trained from data and on-line experience using supervised and reinforcement learning.", "labels": [], "entities": []}, {"text": "However , these models require a large corpus of dialogues to learn effectively.", "labels": [], "entities": []}, {"text": "For goal-oriented dialogues, such datasets are expensive to collect and annotate, since each task involves a separate schema and database of entities.", "labels": [], "entities": []}, {"text": "Further , the Wizard-of-Oz approach commonly used for dialogue collection does not provide sufficient coverage of salient dialogue flows, which is critical for guaranteeing an acceptable task completion rate in consumer-facing conversational agents.", "labels": [], "entities": [{"text": "dialogue collection", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.7657280266284943}]}, {"text": "In this paper, we study a recently proposed approach for building an agent for arbitrary tasks by combining dialogue self-play and crowd-sourcing to generate fully-annotated dialogues with diverse and natural utterances.", "labels": [], "entities": []}, {"text": "We discuss the advantages of this approach for industry applications of conversational agents, wherein an agent can be rapidly bootstrapped to deploy in front of users and further optimized via interactive learning from actual users of the system.", "labels": [], "entities": []}], "introductionContent": [{"text": "Goal-oriented conversational agents enable users to complete specific tasks like restaurant reservations, buying movie tickets or booking a doctor's appointment, through natural language dialogue via a spoken or a text-based chat interface, instead of operating a graphical user interface on a device.", "labels": [], "entities": []}, {"text": "Each task is based on a database schema which defines the domain of interest.", "labels": [], "entities": []}, {"text": "Developing an agent to effectively handle all user interactions in a given domain requires properly dealing with variations in the dialogue flows (what information the users choose to convey in each utterance), surface forms (choice of words to convey the same information), * * Work done while the author was an intern at database states (what entities are available for satisfying the user's request), and noise conditions (whether the user's utterances are correctly recognized by the agent).", "labels": [], "entities": []}, {"text": "Moreover, the number of potential tasks is proportional to the number of transactional websites on the Web, which is in the order of millions.", "labels": [], "entities": []}, {"text": "Popular consumer-facing conversational assistants approach this by enabling third-party developers to build dialogue \"experiences\" or \"skills\" focusing on individual tasks (e.g. DialogFlow , Alexa Skills (), wit.ai 2 ).", "labels": [], "entities": []}, {"text": "The platform provides a parse of the user utterance into a developer defined intent, and the developer provides a policy which maps user intents to system actions, usually modeled as flow charts . This gives the developer full control over how a particular task is handled, allowing her to incrementally add new features to that task.", "labels": [], "entities": []}, {"text": "However, some limitations are that (i) the developer must anticipate all ways in which users might interact with the agent, and (ii) since the programmed dialogue flows are not \"differentiable\", the agent's dialogue policy cannot be improved automatically with experience and each improvement requires human intervention to add logic to support anew dialogue flow or revise an existing flow.", "labels": [], "entities": []}, {"text": "Recently proposed neural conversational models () are trained with supervision over a large corpus of dialogues; ) or with reinforcement to optimize along term reward ().", "labels": [], "entities": []}, {"text": "End-to-end neural conversational models for task-oriented dialogues;) leverage annotated dialogues collected with an expert to embed the expert's dialogue policy fora given task in the weights of a neural network.", "labels": [], "entities": []}, {"text": "However, training such models requires a large corpus of annotated dialogues in a specific domain, which is expensive to collect.", "labels": [], "entities": []}, {"text": "Approaches that use reinforcement learning to find the optimal policy also rely on a pre-training step of supervised learning over expert dialogues in order to reduce the exploration space to make the policy learning tractable;;).", "labels": [], "entities": []}, {"text": "A further issue with application of reinforcement learning techniques is that the user simulator used for the policy training step may not entirely mimic the behavior of actual users of the system.", "labels": [], "entities": []}, {"text": "This can be mitigated by continuously improving the deployed agent from interactions with actual users via on-line learning;).", "labels": [], "entities": []}, {"text": "The Wizard-of-Oz setup (;) is a popular approach to collect and annotate task-oriented dialogues via crowd-sourcing for training neural conversational models;).", "labels": [], "entities": []}, {"text": "However, this is an expensive and lossy process as the free-form dialogues collected from crowd-workers might contain dialogues unfit for use as training data, for instance if the crowd workers use language that is either too simplistic or too convoluted, or may have errors in dialogue act annotations requiring an expensive manual filtering and cleaning step.", "labels": [], "entities": []}, {"text": "Further, the corpus might not coverall the interactions that the dialogue developer expects the agent to handle.", "labels": [], "entities": []}, {"text": "In contrast, the recently proposed Machines Talking To Machines (M2M) approach) is a functionality-driven process for training dialogue agents, which combines a dialogue self-play step and a crowd-sourcing step to obtain a higher quality of dialogues in terms of (i) diversity of surface forms as well as dialogue flows, (ii) coverage of all expected user behaviors, and (iii) correctness of annotations.", "labels": [], "entities": [{"text": "correctness", "start_pos": 377, "end_pos": 388, "type": "METRIC", "confidence": 0.9373653531074524}]}, {"text": "To apply these recent neural approaches to consumer-facing agents that must rapidly scale to new tasks, we propose the following recipe (: (1) exhaustively generate dialogue templates fora given task using dialogue self-play between a simulated user and a task-independent programmed system agent, (2) obtain natural language rewrites of these templates using crowd sourcing, (3) train an end-to-end conversational agent on this fully annotated dataset, achieving a reasonable task completion rate, and (4) deploy this agent to interact with users and collect user feedback, which serves as a reward value to continuously improve the agent's policy with on-line reinforcement learning updates.", "labels": [], "entities": []}, {"text": "Consequently, a programmed dialogue agent's policy is distilled into a differentiable neural model which sustains a minimum task completion rate through guaranteed coverage of the interactions anticipated by the developer.", "labels": [], "entities": []}, {"text": "Such an agent is safely deployable in front of actual users while also continuously improving from user feedback via lifelong learning.", "labels": [], "entities": []}, {"text": "The main contribution of this paper is two-fold: 1.", "labels": [], "entities": []}, {"text": "an approach combining dialogue self-play, crowd-sourcing, and on-line reinforcement learning to rapidly scale consumer-facing conversational agents to new tasks.", "labels": [], "entities": []}, {"text": "2. discussion of practical solutions for improving user simulation and crowd-sourcing setups to guarantee coverage of salient dialogue flows and diversity of surface forms.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have released 4 two datasets totaling 3000 dialogues collected using M2M for the tasks of buying a movie ticket (Sim-M) and reserving a restaurant table (Sim-R).", "labels": [], "entities": []}, {"text": "We present some experiments with these datasets.", "labels": [], "entities": []}, {"text": "To evaluate the subjective quality of the M2M datasets, we showed the final dialogues to human judges recruited via a crowd-sourcing service, and asked them to rate each user and system turn between 1 to 5 on multiple dimensions.", "labels": [], "entities": [{"text": "M2M datasets", "start_pos": 42, "end_pos": 54, "type": "DATASET", "confidence": 0.8036159873008728}]}, {"text": "in the Appendix provides the UI shown to crowd workers for this task.", "labels": [], "entities": [{"text": "Appendix", "start_pos": 7, "end_pos": 15, "type": "METRIC", "confidence": 0.871903121471405}, {"text": "UI", "start_pos": 29, "end_pos": 31, "type": "METRIC", "confidence": 0.9373547434806824}]}, {"text": "Each dialogue was shown to 3 judges.", "labels": [], "entities": []}, {"text": "shows the average ratings aggregated overall turns for the two datasets.", "labels": [], "entities": []}, {"text": "To evaluate the proposed method of bootstrapping neural conversational agents from a programmed system agent, we trained an end-to-end conversa- tional model ( ) using supervised learning (SL) on the Sim-M training set.", "labels": [], "entities": [{"text": "Sim-M training set", "start_pos": 200, "end_pos": 218, "type": "DATASET", "confidence": 0.9139639735221863}]}, {"text": "This model is further trained with RL for 10K episodes with the user simulator as described in Section 2.2 (SL+RL).", "labels": [], "entities": [{"text": "RL", "start_pos": 35, "end_pos": 37, "type": "METRIC", "confidence": 0.9963628649711609}]}, {"text": "We performed two separate evaluations of these models: We evaluate the neural agents in the user simulation environment for 100 episodes.", "labels": [], "entities": []}, {"text": "We asked crowd-sourced judges to read dialogues between the agent and the user simulator and rate each system turn on a scale of 1 (frustrating) to 5 (optimal way to help the user).", "labels": [], "entities": []}, {"text": "Each turn was rated by 3 different judges.", "labels": [], "entities": []}, {"text": "shows the average scores for both agents.", "labels": [], "entities": []}, {"text": "End-toend optimization with RL improves the quality of the agent according to human judges, compared to an agent trained with only supervised learning on the dataset.", "labels": [], "entities": []}, {"text": "We evaluate the neural agents in live interactions with human judges for 100 episodes each.", "labels": [], "entities": []}, {"text": "The human judges are given scenarios fora movie booking task and asked to talk with the agent to complete the booking according to the constraints.", "labels": [], "entities": [{"text": "movie booking task", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.7573070724805196}]}, {"text": "After the dialogue finishes, the judge is asked to rate each system turn on the same scale of 1 to 5.", "labels": [], "entities": []}, {"text": "shows the average scores for both agents.", "labels": [], "entities": []}, {"text": "End-to-end optimization with RL improves the agent's interactions with human users.", "labels": [], "entities": []}, {"text": "The interactions with human users are of lower quality than those with the user simulator as human users may use utterances or dialogue flows unseen by the agent.", "labels": [], "entities": []}, {"text": "Continual training of the agent with on-line reinforcement learning can close this gap with more experience.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Comparing DSTC2 and M2M Restaurants  datasets on diversity of language and dialogue flows.", "labels": [], "entities": [{"text": "M2M Restaurants  datasets", "start_pos": 30, "end_pos": 55, "type": "DATASET", "confidence": 0.7916810909907023}]}]}