{"title": [{"text": "SystemT: Declarative Text Understanding for Enterprise", "labels": [], "entities": [{"text": "SystemT", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.7498632669448853}, {"text": "Declarative Text Understanding", "start_pos": 9, "end_pos": 39, "type": "TASK", "confidence": 0.7131390372912089}]}], "abstractContent": [{"text": "The rise of enterprise applications over unstructured and semi-structured documents poses new challenges to text understanding systems across multiple dimensions.", "labels": [], "entities": [{"text": "text understanding", "start_pos": 108, "end_pos": 126, "type": "TASK", "confidence": 0.8460738658905029}]}, {"text": "We present SystemT, a declarative text understanding system that addresses these challenges and has been deployed in a wide range of enterprise applications.", "labels": [], "entities": [{"text": "text understanding", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.6814554333686829}]}, {"text": "We highlight the design considerations and decisions behind SystemT in addressing the needs of the enterprise setting.", "labels": [], "entities": []}, {"text": "We also summarize the impact of SystemT on business and education.", "labels": [], "entities": [{"text": "SystemT", "start_pos": 32, "end_pos": 39, "type": "TASK", "confidence": 0.9299197793006897}]}], "introductionContent": [{"text": "With the proliferation of information in unstructured and semi-structured form, text understanding (TU) is becoming a fundamental building block in enterprise applications.", "labels": [], "entities": [{"text": "text understanding (TU)", "start_pos": 80, "end_pos": 103, "type": "TASK", "confidence": 0.8440479934215546}]}, {"text": "Numerous tools, algorithms and APIs have been developed to address various text understanding sub-tasks, ranging from low-level text tasks (e.g., tokenization) and core natural language processing (e.g., syntactic and semantic parsing) to higher-level tasks such as document classification, entity and relation extraction, and sentiment analysis.", "labels": [], "entities": [{"text": "text understanding", "start_pos": 75, "end_pos": 93, "type": "TASK", "confidence": 0.713819295167923}, {"text": "tokenization)", "start_pos": 146, "end_pos": 159, "type": "TASK", "confidence": 0.9169991910457611}, {"text": "syntactic and semantic parsing)", "start_pos": 204, "end_pos": 235, "type": "TASK", "confidence": 0.6583403527736664}, {"text": "document classification", "start_pos": 266, "end_pos": 289, "type": "TASK", "confidence": 0.7587223649024963}, {"text": "entity and relation extraction", "start_pos": 291, "end_pos": 321, "type": "TASK", "confidence": 0.5914309173822403}, {"text": "sentiment analysis", "start_pos": 327, "end_pos": 345, "type": "TASK", "confidence": 0.9443812668323517}]}, {"text": "Real world applications usually require several such components.", "labels": [], "entities": []}, {"text": "As an example, consider a Financial Investment Research Analysis application, which leverages financial market analyst reports such as the one in to inform automatic trading and financial recommendations.", "labels": [], "entities": [{"text": "Financial Investment Research Analysis", "start_pos": 26, "end_pos": 64, "type": "TASK", "confidence": 0.6378162428736687}]}, {"text": "Information is conveyed in both natural language (e.g., \"We thus downgrade US and global HY credits\") and tabular form, requiring both natural language understanding primitives (e.g., syntactic or semantic parsing) and document structure understanding primitives (e.g., table titles, row and column headers, and the association of table cells and headers).", "labels": [], "entities": [{"text": "syntactic or semantic parsing", "start_pos": 184, "end_pos": 213, "type": "TASK", "confidence": 0.7569817155599594}]}, {"text": "Furthermore, the business problem involves higher-level tasks such as financial entity extraction (e.g., equities, bonds, currencies) in natural language and tabular forms, and sentiment analysis for such entities.", "labels": [], "entities": [{"text": "financial entity extraction (e.g., equities, bonds, currencies)", "start_pos": 70, "end_pos": 133, "type": "TASK", "confidence": 0.7325428277254105}, {"text": "sentiment analysis", "start_pos": 177, "end_pos": 195, "type": "TASK", "confidence": 0.8271571397781372}]}, {"text": "While approaches for solving individual TU sub-tasks have proliferated, considerably less effort has been dedicated to developing systems that enable building end-to-end TU applications in a principled, systematic and replicable fashion.", "labels": [], "entities": []}, {"text": "In the absence of such systems, building a TU application involves piecing together individual components in an ad hoc fashion, usually requiring custom code to address the impedance mismatch in data models between the different components, and to bridge gaps in functionality.", "labels": [], "entities": []}, {"text": "Different implementations of the same application may yield vastly different runtime performance characteristics as well as, even more worryingly, different output semantics.", "labels": [], "entities": []}, {"text": "For example, two developers may make disparate assumptions implementing even such a seemingly simple text operation as dictionary matching: Should dictionary terms match the input text only on token boundaries, or is matching allowed in the middle of a token?", "labels": [], "entities": [{"text": "dictionary matching", "start_pos": 119, "end_pos": 138, "type": "TASK", "confidence": 0.6935258954763412}]}, {"text": "Which tokenization approach should be used?", "labels": [], "entities": [{"text": "tokenization", "start_pos": 6, "end_pos": 18, "type": "TASK", "confidence": 0.9712197780609131}]}, {"text": "Is matching case sensitive or insensitive?", "labels": [], "entities": []}, {"text": "In an enter-prise environment, such ad-hoc approaches produce code repositories that are difficult to understand, maintain, reuse in new applications, or optimize for runtime performance.", "labels": [], "entities": []}, {"text": "This paper presents SystemT, an industrialstrength system for developing end-to-end TU applications in a declarative fashion.", "labels": [], "entities": []}, {"text": "SystemT was developed at IBM Research and has been widely adopted inside and outside IBM (Sec.", "labels": [], "entities": []}, {"text": "4) Borrowing ideas from database systems, commonly used text operations are abstracted away as built-in operators with clean, well-specified semantics and highly optimized internal implementations, and exposed through a formal declarative language called AQL (Annotation Query Language).", "labels": [], "entities": []}, {"text": "illustrates a fragment of AQL for extracting financial entities and associated sentiment from financial reports as in.", "labels": [], "entities": [{"text": "extracting financial entities and associated sentiment from financial reports", "start_pos": 34, "end_pos": 111, "type": "TASK", "confidence": 0.8163024584452311}]}, {"text": "The snippet illustrates several types of declarative TU structures (or rules) expressible in AQL, including sequential structures (AssetClass), semantic understanding structures (RecommendationNU), and table understanding structures (RecommendationTable).", "labels": [], "entities": []}, {"text": "The rules leverage built-in text operators readily available in AQL, including dictionary matching (AssetClassSuffixes), core NLP operators such as Semantic Role Labeling (SRL) (Verbs, Arguments), and document structure operators such as table structure understanding (AllCells).", "labels": [], "entities": [{"text": "dictionary matching", "start_pos": 79, "end_pos": 98, "type": "TASK", "confidence": 0.7065008580684662}, {"text": "Semantic Role Labeling (SRL) (Verbs, Arguments)", "start_pos": 148, "end_pos": 195, "type": "TASK", "confidence": 0.7378631288355048}, {"text": "table structure understanding", "start_pos": 238, "end_pos": 267, "type": "TASK", "confidence": 0.7108027637004852}]}, {"text": "3 details the data model and semantics of AQL.", "labels": [], "entities": []}, {"text": "As illustrated in, SystemT consists of two major components: the Compiler and the Runtime.", "labels": [], "entities": []}, {"text": "The Compiler takes as input a TU program specified in AQL and compiles it into an execution plan.", "labels": [], "entities": []}, {"text": "AQL is a purely declarative language: the developer specifies what should be extracted, but not how to do it.", "labels": [], "entities": []}, {"text": "The Optimizer computes the how automatically by enumerating multiple logical equivalent plans, and choosing a plan with the least estimated cost.", "labels": [], "entities": []}, {"text": "Since each operator has wellspecified semantics, the Optimizer can automatically determine when operators can be reordered, merged, or even discarded without affecting the output semantics, while significantly increasing the runtime performance of the TU program.", "labels": [], "entities": []}, {"text": "The Operator Graph captures the execution plan generated by the Optimizer and is used by the Runtime to decide the actual sequence of operations.", "labels": [], "entities": []}, {"text": "The Runtime is a lightweight engine that loads the Operator Graph and then processes inputs  This DAAT model speeds up join and aggregation operations within a document, as the entire document's data is in memory.", "labels": [], "entities": []}, {"text": "It also simplifies scaleout processing and can be scaled up by utilizing multithreading and multiple processes, as well as various cluster and cloud environments.", "labels": [], "entities": []}, {"text": "SystemT's declarative approach is a departure from other rule-based TU systems.", "labels": [], "entities": []}, {"text": "Early systems () are based on the Common Pattern Specification Language (CPSL)), a cas-cading grammar formalism where the input text is viewed as a sequence of annotations, and extraction rules are written as pattern/action rules over the lexical features of these annotations.", "labels": [], "entities": []}, {"text": "Each grammar consists of a set of rules evaluated in a left-to-right fashion over the input annotations, with multiple grammars cascaded together and evaluated bottom-up.", "labels": [], "entities": []}, {"text": "As discussed in (), grammar-based systems suffer from two fundamental limitations: expressivity and performance.", "labels": [], "entities": []}, {"text": "Formal studies of AQL semantics have shown that AQL is strictly more expressive than regular expression-based languages such as CPSL (Sec. 3.2.5).", "labels": [], "entities": []}, {"text": "Furthermore, the rigid evaluation order imposed in grammar-based systems has significant runtime performance implications, as the system is effectively forced into a fixed pipeline execution strategy, leaving little opportunity for global optimization.", "labels": [], "entities": []}, {"text": "While the expressivity of grammar-based systems has been extended in different ways, such as additional built-in constructs), or allowing a mix of sequential patterns and rules over dependency parse trees, such extensions do not fundamentally address the inherent expressivity and performance limitations due to the intertwining of rule language semantics and execution strategy.", "labels": [], "entities": []}, {"text": "In contrast, SystemT's declarative approach enables the optimizer to explore a variety of execution plans, resulting in orders of magnitude higher throughput and a lower memory footprint ().", "labels": [], "entities": []}], "datasetContent": [{"text": "In addition to theoretical studies of AQL expressivity and runtime performance, we have also evaluated SystemT empirically on multiple TU tasks.", "labels": [], "entities": [{"text": "AQL expressivity", "start_pos": 38, "end_pos": 54, "type": "TASK", "confidence": 0.7944954037666321}]}, {"text": "We show that extractors builtin AQL yield results of comparable quality to the best published results Extracting entities and relations from natural language and tables in material science literature to speedup the discovery for new materials Security and privacy Personal information extraction and redaction for security and privacy Social media Sentiment analysis over social media for indepth understanding of social behavior Travel Extracting information and sentiment from online reviews to build AI assist for travel: Partial list of SystemT applications", "labels": [], "entities": [{"text": "Extracting entities and relations from natural language and tables", "start_pos": 102, "end_pos": 168, "type": "TASK", "confidence": 0.8046244978904724}, {"text": "Personal information extraction", "start_pos": 264, "end_pos": 295, "type": "TASK", "confidence": 0.6183115343252817}, {"text": "Social media Sentiment analysis", "start_pos": 335, "end_pos": 366, "type": "TASK", "confidence": 0.6836804747581482}, {"text": "understanding of social behavior Travel Extracting information and sentiment from online reviews", "start_pos": 397, "end_pos": 493, "type": "TASK", "confidence": 0.7303778429826101}]}], "tableCaptions": []}