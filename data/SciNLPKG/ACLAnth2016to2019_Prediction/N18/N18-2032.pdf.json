{"title": [{"text": "Introducing two Vietnamese Datasets for Evaluating Semantic Models of (Dis-)Similarity and Relatedness", "labels": [], "entities": [{"text": "Vietnamese Datasets", "start_pos": 16, "end_pos": 35, "type": "DATASET", "confidence": 0.9318010807037354}]}], "abstractContent": [{"text": "We present two novel datasets for the low-resource language Vietnamese to assess models of semantic similarity: ViCon comprises pairs of synonyms and antonyms across word classes, thus offering data to distinguish between similarity and dissimilarity.", "labels": [], "entities": []}, {"text": "ViSim-400 provides degrees of similarity across five semantic relations, as rated by human judges.", "labels": [], "entities": []}, {"text": "The two datasets are verified through standard co-occurrence and neural network models , showing results comparable to the respective English datasets.", "labels": [], "entities": []}], "introductionContent": [{"text": "Computational models that distinguish between semantic similarity and semantic relatedness) are important for many NLP applications, such as the automatic generation of dictionaries, thesauri, and ontologies), and machine translation (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 214, "end_pos": 233, "type": "TASK", "confidence": 0.7972180843353271}]}, {"text": "In order to evaluate these models, gold standard resources with word pairs have to be collected (typically across semantic relations such as synonymy, hypernymy, antonymy, co-hyponymy, meronomy, etc.) and annotated for their degree of similarity via human judgements.", "labels": [], "entities": []}, {"text": "The most prominent examples of gold standard similarity resources for English are the Rubenstein & Goodenough (RG) dataset, the TOEFL test questions), WordSim-353 (), MEN (), SimLex-999 (, and the lexical contrast datasets by.", "labels": [], "entities": [{"text": "Rubenstein & Goodenough (RG) dataset", "start_pos": 86, "end_pos": 122, "type": "DATASET", "confidence": 0.636562487908772}, {"text": "TOEFL test questions", "start_pos": 128, "end_pos": 148, "type": "DATASET", "confidence": 0.7938730915387472}, {"text": "WordSim-353", "start_pos": 151, "end_pos": 162, "type": "DATASET", "confidence": 0.941769540309906}]}, {"text": "For other languages, resource examples are the translation of the RG dataset to German, the German dataset of paradigmatic relations (, and the translation of.", "labels": [], "entities": [{"text": "RG dataset", "start_pos": 66, "end_pos": 76, "type": "DATASET", "confidence": 0.7773703932762146}, {"text": "German dataset", "start_pos": 92, "end_pos": 106, "type": "DATASET", "confidence": 0.7851829826831818}]}, {"text": "However, for lowresource languages there is still alack of such datasets, which we aim to fill for Vietnamese, a language without morphological marking such as case, gender, number, and tense, thus differing strongly from Western European languages.", "labels": [], "entities": []}, {"text": "We introduce two novel datasets for Vietnamese: a dataset of lexical contrast pairs ViCon to distinguish between similarity (synonymy) and dissimilarity (antonymy), and a dataset of semantic relation pairs ViSim-400 to reflect the continuum between similarity and relatedness.", "labels": [], "entities": []}, {"text": "The two datasets are publicly available.", "labels": [], "entities": []}, {"text": "1 Moreover, we verify our novel datasets through standard and neural co-occurrence models, in order to show that we obtain a similar behaviour as for the corresponding English datasets, and the lexical contrast dataset (henceforth LexCon), cf..", "labels": [], "entities": [{"text": "English datasets", "start_pos": 168, "end_pos": 184, "type": "DATASET", "confidence": 0.7523844540119171}, {"text": "LexCon", "start_pos": 231, "end_pos": 237, "type": "DATASET", "confidence": 0.9441232681274414}]}], "datasetContent": [{"text": "In this section, we verify our novel datasets ViCon and ViSim-400 through standard and neural co-occurrence models, in order to show that we obtain a similar behaviour as for the corresponding English datasets.", "labels": [], "entities": [{"text": "ViCon", "start_pos": 46, "end_pos": 51, "type": "DATASET", "confidence": 0.9033175706863403}, {"text": "English datasets", "start_pos": 193, "end_pos": 209, "type": "DATASET", "confidence": 0.6971209496259689}]}], "tableCaptions": [{"text": " Table 1: Inter-annotator agreements measured by  Spearman's \u03c1, Krippendorff's \u03b1, and the average stan- dard deviation (STD) of all pairs across word classes.", "labels": [], "entities": [{"text": "stan- dard deviation (STD)", "start_pos": 98, "end_pos": 124, "type": "METRIC", "confidence": 0.8334597093718392}]}, {"text": " Table 3: AUC scores for distinguishing antonyms from  synonyms in ViSim-400.", "labels": [], "entities": [{"text": "AUC", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9786213040351868}, {"text": "ViSim-400", "start_pos": 67, "end_pos": 76, "type": "DATASET", "confidence": 0.9126757383346558}]}, {"text": " Table 4: AP evaluation of co-occurrence models on Vi- Con in comparison to", "labels": [], "entities": []}]}