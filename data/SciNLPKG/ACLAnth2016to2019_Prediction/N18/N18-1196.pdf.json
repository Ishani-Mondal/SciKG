{"title": [], "abstractContent": [{"text": "Contextual influences on language often exhibit substantial cross-lingual regularities; for example, we are more verbose in situations that require finer distinctions.", "labels": [], "entities": []}, {"text": "However, these regularities are sometimes obscured by semantic and syntactic differences.", "labels": [], "entities": []}, {"text": "Using a newly-collected dataset of color reference games in Mandarin Chinese (which we release to the public), we confirm that a variety of constructions display the same sensitivity to contextual difficulty in Chinese and English.", "labels": [], "entities": []}, {"text": "We then show that a neural speaker agent trained on bilingual data with a simple multitask learning approach displays more human-like patterns of context dependence and is more pragmatically informative than its monolingual Chi-nese counterpart.", "labels": [], "entities": []}, {"text": "Moreover, this is not at the expense of language-specific semantic understanding: the resulting speaker model learns the different basic color term systems of En-glish and Chinese (with noteworthy cross-lingual influences), and it can identify synonyms between the two languages using vector analogy operations on its output layer, despite having no exposure to parallel data.", "labels": [], "entities": []}], "introductionContent": [{"text": "In grounded communication tasks, speakers face pressures in choosing referential expressions that distinguish their targets from others in the context, leading to many kinds of pragmatic meaning enrichment.", "labels": [], "entities": []}, {"text": "For example, the harder a target is to identify, the more the speaker will feel the need to refer implicitly and explicitly to alternatives to draw subtle contrasts).", "labels": [], "entities": []}, {"text": "However, the ways in which these contrasts are expressed depend heavily on language-specific syntax and semantics.", "labels": [], "entities": []}, {"text": "xx x xi\u00af an l ` \u00a8 u 'bright green' xx x bul\u00ec ang de ch\u00e9ngs\u00e8 'not-bright orange' xx x z\u02c7\u0131z\u02c7\u0131 h\u00f3ngs\u00e8 'purple-red' Figure 1: Reference game contexts and utterances from our Chinese corpus.", "labels": [], "entities": []}, {"text": "The boxed color is the target.", "labels": [], "entities": []}, {"text": "Some color terms show differences between Chinese and English, such as l ` \u00a8 u 'green' in the first example fora color that might be referred to In this paper, we seek to develop a model of contextual language production that captures language-specific syntax and semantics while also exhibiting responsiveness to contextual differences.", "labels": [], "entities": []}, {"text": "We focus on a color reference game) played in both English and Mandarin Chinese.", "labels": [], "entities": []}, {"text": "A reference game () involves two agents, one designated the \"speaker\" and the other the \"listener\".", "labels": [], "entities": []}, {"text": "The speaker and listener are shown the same set of k colors C = {c 1 , . .", "labels": [], "entities": []}, {"text": ", ck } (in our experiments, k = 3), and one of these colors ct is indicated secretly to the speaker as the \"target\".", "labels": [], "entities": []}, {"text": "Both players share the same goal: that the listener correctly guesses the target color.", "labels": [], "entities": []}, {"text": "The speaker may communicate with the listener in free-form naturallanguage dialogue to achieve this goal.", "labels": [], "entities": []}, {"text": "Thus, a model of the speaker must process representations of the colors in the context and produce an utterance to distinguish the target color from the others.", "labels": [], "entities": []}, {"text": "We evaluate a sequence-to-sequence speaker agent based on that of, who also collected the English data we use; our Chinese data are new and were collected according to the same protocols.", "labels": [], "entities": []}, {"text": "While English and Chinese both use fairly similar syntax for color descriptions, our reference game is designed to elicit constructions that make reference to the context, and these constructionsparticularly comparatives and negation-differ morpho-syntactically and pragmatically between the two languages.", "labels": [], "entities": []}, {"text": "Additionally, Chinese is considered to have a smaller number of basic color terms (, which predicts markedness of more specific descriptions.", "labels": [], "entities": []}, {"text": "Our primary goal is to examine the effects of bilingual training: building one speaker trained on both English and Chinese data with a shared vocabulary, so that it can produce utterances in either language.", "labels": [], "entities": []}, {"text": "The reference game setting offers an objective measure of success on the grounded language task, namely, the speaker's ability to guide the listener to the target.", "labels": [], "entities": []}, {"text": "We use this to address the tricky problem of speaker evaluation.", "labels": [], "entities": [{"text": "speaker evaluation", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.8850353360176086}]}, {"text": "Specifically, we use the speaker model and an application of Bayes' rule to infer the most likely target color given a human utterance, and we report the accuracy of that process at identifying the target color.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 154, "end_pos": 162, "type": "METRIC", "confidence": 0.9991229176521301}]}, {"text": "We refer to this metric as pragmatic informativeness because it requires not only accuracy but also effectiveness at meeting the players' shared goal.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.9975833892822266}]}, {"text": "A more formal definition and a discussion of alternatives are given in Section 4.1.", "labels": [], "entities": []}, {"text": "We show that a bilingually-trained model produces distributions over Chinese utterances that have higher pragmatic informativeness than a monolingual model.", "labels": [], "entities": []}, {"text": "An analysis of the learned word embeddings reveals that the bilingual model learns color synonyms between the two languages without being directly exposed to labeled pairs.", "labels": [], "entities": []}, {"text": "However, using a context-independent color term elicitation task from on our models, we show that the learned lexical meanings are largely faithful to each language's basic color system, with only minor cross-lingual influences.", "labels": [], "entities": []}, {"text": "This suggests that the improvements due to adding English data are not primarily due to better representations of the input colors or lexical semantics alone.", "labels": [], "entities": []}, {"text": "The bilingual model does better resemble human patterns of utterance length as a function of contextual difficulty, suggesting the pragmatic level as one possible area of cross-lingual generalization.", "labels": [], "entities": []}], "datasetContent": [{"text": "Pragmatic informativeness of the models on English and Chinese data is shown in.", "labels": [], "entities": []}, {"text": "The main result is that training a bilingual model helps compared to a Chinese monolingual one; however, the benefit is asymmetrical, as training on monolingual English data is superior for English data to training on a mix of Chinese and English.", "labels": [], "entities": []}, {"text": "All differences in), except for the decrease on the English dev set, which is significant at p < 0.05.", "labels": [], "entities": []}, {"text": "An important difference between our corpora is that the English dataset is an order of magnitude larger than the Chinese.", "labels": [], "entities": [{"text": "English dataset", "start_pos": 56, "end_pos": 71, "type": "DATASET", "confidence": 0.8759213387966156}]}, {"text": "Intuitively, we expect adding more training data on the same task will improve the model, regardless of language.", "labels": [], "entities": []}, {"text": "However, we find that the effect of dataset size is not so straightforward.", "labels": [], "entities": []}, {"text": "In fact, the differences in training set size convey a non-linear benefit.", "labels": [], "entities": []}, {"text": "shows the pragmatic informativeness of the monolingual and bilingual speakers on the development set as a function of dataset size (number of English and Chinese utterances).", "labels": [], "entities": []}, {"text": "The blue curves (circles) in the plots on the left, Figure 5a Overall, we see that adding all English data consistently helps the Chinese monolingual model, whereas adding all Chinese data consistently hurts the English monolingual model (though with diminishing effects as the amount of English data increases).", "labels": [], "entities": []}, {"text": "Adding small amounts of English dataespecially amounts comparable to the size of the Chinese dataset-decreases accuracy of the Chinese model dramatically.", "labels": [], "entities": [{"text": "Chinese dataset-decreases", "start_pos": 85, "end_pos": 110, "type": "DATASET", "confidence": 0.6866897940635681}, {"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.980156660079956}]}, {"text": "This suggests an interaction between the total amount of data and the effect of bilingual training: a model trained on a moderately small number of in-language examples can benefit from a much larger training set in another language, but combining data in two languages is detrimental when both datasets are very small and has very little effect when the in-", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Pragmatic informativeness scores (%) for  monolingual and bilingual speakers.", "labels": [], "entities": [{"text": "Pragmatic informativeness scores", "start_pos": 10, "end_pos": 42, "type": "METRIC", "confidence": 0.8859800895055135}]}]}