{"title": [{"text": "Leveraging Intra-User and Inter-User Representation Learning for Automated Hate Speech Detection", "labels": [], "entities": [{"text": "Hate Speech Detection", "start_pos": 75, "end_pos": 96, "type": "TASK", "confidence": 0.746975322564443}]}], "abstractContent": [{"text": "Hate speech detection is a critical, yet challenging problem in Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "Hate speech detection", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8485085765520731}, {"text": "Natural Language Processing (NLP)", "start_pos": 64, "end_pos": 97, "type": "TASK", "confidence": 0.7209871212641398}]}, {"text": "Despite the existence of numerous studies dedicated to the development of NLP hate speech detection approaches, the accuracy is still poor.", "labels": [], "entities": [{"text": "NLP hate speech detection", "start_pos": 74, "end_pos": 99, "type": "TASK", "confidence": 0.7855912446975708}, {"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9995287656784058}]}, {"text": "The central problem is that social media posts are short and noisy, and most existing hate speech detection solutions take each post as an isolated input instance, which is likely to yield high false positive and negative rates.", "labels": [], "entities": [{"text": "hate speech detection", "start_pos": 86, "end_pos": 107, "type": "TASK", "confidence": 0.6465207934379578}]}, {"text": "In this paper, we radically improve automated hate speech detection by presenting a novel model that leverages intra-user and inter-user representation learning for robust hate speech detection on Twitter.", "labels": [], "entities": [{"text": "hate speech detection", "start_pos": 46, "end_pos": 67, "type": "TASK", "confidence": 0.6874467134475708}, {"text": "hate speech detection", "start_pos": 172, "end_pos": 193, "type": "TASK", "confidence": 0.6427305936813354}]}, {"text": "In addition to the target Tweet, we collect and analyze the user's historical posts to model intra-user Tweet representations.", "labels": [], "entities": []}, {"text": "To suppress the noise in a single Tweet, we also model the similar Tweets posted by all other users with reinforced inter-user representation learning techniques.", "labels": [], "entities": []}, {"text": "Experimentally, we show that leverag-ing these two representations can significantly improve the f-score of a strong bidirectional LSTM baseline model by 10.1%.", "labels": [], "entities": [{"text": "f-score", "start_pos": 97, "end_pos": 104, "type": "METRIC", "confidence": 0.9543818235397339}]}], "introductionContent": [{"text": "The rapid rise in user-generated web content has not only yielded avast increase in information accessibility, but has also given individuals an easy platform on which to share their beliefs and to publicly communicate with others.", "labels": [], "entities": []}, {"text": "Unfortunately, this has also led to nefarious uses of online spaces, for instance for the propagation of hate speech.", "labels": [], "entities": [{"text": "propagation of hate speech", "start_pos": 90, "end_pos": 116, "type": "TASK", "confidence": 0.801509290933609}]}, {"text": "An extensive body of work has focused on the development of automatic hate speech classifiers.", "labels": [], "entities": [{"text": "hate speech classifiers", "start_pos": 70, "end_pos": 93, "type": "TASK", "confidence": 0.6679446001847585}]}, {"text": "A recent survey outlined eight categories of features used in hate speech detection (: simple surface (, word generalization (Warner and: Our hate speech classifier.", "labels": [], "entities": [{"text": "hate speech detection", "start_pos": 62, "end_pos": 83, "type": "TASK", "confidence": 0.7533424496650696}, {"text": "word generalization", "start_pos": 105, "end_pos": 124, "type": "TASK", "confidence": 0.7083104699850082}]}, {"text": "In contrast to existing methods that focus on a single target Tweet as input (center), we incorporate intra-user (right) and interuser (left) representations to enhance performance., sentiment analysis, lexical resources and linguistic features, knowledge-based features (, meta-information (, and multi-modal information (.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 183, "end_pos": 201, "type": "TASK", "confidence": 0.9452517330646515}]}, {"text": "Closely related to our work is research that leverages user attributes in the classification process such as history of participation in hate speech and usage of profanity (.", "labels": [], "entities": []}, {"text": "Both and collect user history to enhance detection accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9341146349906921}]}, {"text": "The former requires the user history to be labeled instances.", "labels": [], "entities": []}, {"text": "However, labeling user history requires significant human effort.", "labels": [], "entities": [{"text": "labeling user history", "start_pos": 9, "end_pos": 30, "type": "TASK", "confidence": 0.8623517155647278}]}, {"text": "The latter models the user with manually selected features.", "labels": [], "entities": []}, {"text": "In contrast, our approach leverages unlabeled user history to automatically model the user.", "labels": [], "entities": []}, {"text": "In this paper, we focus on augmenting hate speech classification models by first performing: The overview of our proposed model.", "labels": [], "entities": [{"text": "hate speech classification", "start_pos": 38, "end_pos": 64, "type": "TASK", "confidence": 0.7434935371081034}]}, {"text": "t is the input target Tweet, z denotes intra-user Tweets, and x a is the selected inter-user Tweet.", "labels": [], "entities": []}, {"text": "r ie is the inter-user representation, r ia is the intra-user representation, and r ta is the representation of the target Tweet.", "labels": [], "entities": []}, {"text": "These three branches respectively correspond to the three branches illustrated in. y i is the prediction at the time step i and s i is the state input for the agent at the time step i.", "labels": [], "entities": []}, {"text": "The computing process is detailed in representation learning to model user history without supervision.", "labels": [], "entities": []}, {"text": "The hypothesis is that, by analyzing a corpus of the user's past Tweets, our system will better understand the language and behavior of the user, leading to better hate speech detection accuracy.", "labels": [], "entities": [{"text": "hate speech detection", "start_pos": 164, "end_pos": 185, "type": "TASK", "confidence": 0.7289506395657858}, {"text": "accuracy", "start_pos": 186, "end_pos": 194, "type": "METRIC", "confidence": 0.8438741564750671}]}, {"text": "Another issue is that using a single Tweet as input is often noisy for any machine learning classifier.", "labels": [], "entities": []}, {"text": "For example, the Tweet \"I'm not sexist but I cannot stand women commentators\" is actually an instance of hate speech, even though the first half is misleading.", "labels": [], "entities": []}, {"text": "To minimize noise, we also consider semantically similar Tweets posted by other users.", "labels": [], "entities": []}, {"text": "To do so, we propose a reinforced bidirectional long shortterm memory network (LSTM)) to interactively leverage the similar Tweets from a large Twitter dataset to enhance the performance of the hate speech classifier.", "labels": [], "entities": [{"text": "hate speech classifier", "start_pos": 194, "end_pos": 216, "type": "TASK", "confidence": 0.628326952457428}]}, {"text": "An overview of our approach is shown in.", "labels": [], "entities": []}, {"text": "The main contributions of our work are: \u2022 We provide a novel perspective on hate speech detection by modeling intra-user Tweet representations.", "labels": [], "entities": [{"text": "hate speech detection", "start_pos": 76, "end_pos": 97, "type": "TASK", "confidence": 0.7314507961273193}]}, {"text": "\u2022 To improve robustness, we leverage similar Tweets from a large unlabeled corpus with reinforced inter-user representations.", "labels": [], "entities": []}, {"text": "\u2022 We integrate target Tweets, intra-user and inter-user representations in a unified framework, outperforming strong baselines.", "labels": [], "entities": []}, {"text": "illustrates the architecture of our model.", "labels": [], "entities": []}, {"text": "It includes three branches, whose details will be described in the following subsections.", "labels": [], "entities": []}], "datasetContent": [{"text": "Dataset: We use the dataset published by.", "labels": [], "entities": [{"text": "Dataset", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.7621378898620605}]}, {"text": "This dataset contains 16,907 Tweets.", "labels": [], "entities": []}, {"text": "The original dataset only contains the Tweet ID and the label for each Tweet.", "labels": [], "entities": []}, {"text": "We expand the dataset with user ID and Tweet text.", "labels": [], "entities": []}, {"text": "After deleting the Tweets that are no longer accessible, the dataset we use contains 15,781 Tweets from 1,808 users.", "labels": [], "entities": []}, {"text": "The published dataset has three labels: racism, sexism and none.", "labels": [], "entities": []}, {"text": "Since we consider a binary classification setting, we union the first two sets.", "labels": [], "entities": []}, {"text": "In the final dataset, 67% are labeled as non-hate speech, and 33% are labeled as hate speech.", "labels": [], "entities": []}, {"text": "1000 Tweets are randomly selected for  Combining with Inter-user Representation: The inter-user Tweet set is collected from the dataset via Locality Sensitive Hashing (LSH).", "labels": [], "entities": []}, {"text": "In our experiments, we use a set size of either 50, 100 or 200 Tweets.", "labels": [], "entities": []}, {"text": "At each time step, one Tweet is selected from the inter-user Tweet set by the policy agent.", "labels": [], "entities": []}, {"text": "We also experimented with a second setting, in which we replace the agent by random selection.", "labels": [], "entities": []}, {"text": "At each time step, an inter-user Tweet is randomly selected from X and fed into the interuser branch.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Experimental results. Prec.: precision. Rec.:  recall. F1: F measure. Bi-LSTM: the baseline bidi- rectional LSTM model. Bi-LSTM + attention: an at- tentional bidirectional LSTM model. The experimen- tal settings of the last three rows are illustrated in Sec- tion 3.1. + Intra. Rep.: the model consists of the tar- get Tweet branch and the intra-user branch. + Intra.  + Randomized Inter. Rep. incorporates randomly se- lected inter-user Tweets while + Intra. + Reinforced  Inter. Rep. further incorporates the reinforced inter- user branch. The best results are in bold.", "labels": [], "entities": [{"text": "Prec.", "start_pos": 32, "end_pos": 37, "type": "METRIC", "confidence": 0.9617626070976257}, {"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.998144268989563}, {"text": "recall", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.9985173344612122}, {"text": "F1", "start_pos": 65, "end_pos": 67, "type": "METRIC", "confidence": 0.9958906173706055}, {"text": "F measure", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9794115424156189}]}]}