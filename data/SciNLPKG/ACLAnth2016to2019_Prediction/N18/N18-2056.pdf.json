{"title": [{"text": "Improve Neural Entity Recognition via Multi-Task Data Selection and Constrained Decoding", "labels": [], "entities": [{"text": "Improve Neural Entity Recognition", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.870734766125679}]}], "abstractContent": [{"text": "Entity recognition is a widely benchmarked task in natural language processing due to its massive applications.", "labels": [], "entities": [{"text": "Entity recognition", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8897272050380707}]}, {"text": "The state-of-the-art solution applies a neural architecture named BiLSTM-CRF to model the language sequences.", "labels": [], "entities": [{"text": "BiLSTM-CRF", "start_pos": 66, "end_pos": 76, "type": "METRIC", "confidence": 0.7999417185783386}]}, {"text": "In this paper, we propose an entity recognition system that improves this neural architecture with two novel techniques.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.7556537091732025}]}, {"text": "The first technique is Multi-Task Data Selection, which ensures the consistency of data distribution and labeling guidelines between source and target datasets.", "labels": [], "entities": [{"text": "Multi-Task Data Selection", "start_pos": 23, "end_pos": 48, "type": "TASK", "confidence": 0.651719739039739}, {"text": "consistency", "start_pos": 68, "end_pos": 79, "type": "METRIC", "confidence": 0.9666945338249207}]}, {"text": "The other one is constrained decoding using knowledge base.", "labels": [], "entities": []}, {"text": "The decoder of the model operates at the document level, and leverages global and external information sources to further improve performance.", "labels": [], "entities": []}, {"text": "Extensive experiments have been conducted to show the advantages of each technique.", "labels": [], "entities": []}, {"text": "Our system achieves state-of-the-art results on the English entity recognition task in KBP 2017 official evaluation, and it also yields very strong results in other languages.", "labels": [], "entities": [{"text": "English entity recognition task", "start_pos": 52, "end_pos": 83, "type": "TASK", "confidence": 0.6920641660690308}, {"text": "KBP 2017 official evaluation", "start_pos": 87, "end_pos": 115, "type": "DATASET", "confidence": 0.8972049802541733}]}], "introductionContent": [{"text": "Entity Recognition (ER) is a fundamental task in Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "Entity Recognition (ER)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8389293432235718}]}, {"text": "The task includes named entity recognition and nominal entity recognition.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 18, "end_pos": 42, "type": "TASK", "confidence": 0.6252893209457397}, {"text": "nominal entity recognition", "start_pos": 47, "end_pos": 73, "type": "TASK", "confidence": 0.6165250837802887}]}, {"text": "ER is the building blocks for higher level applications such as natural language understanding, question answering, machine reading comprehension, etc.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 64, "end_pos": 94, "type": "TASK", "confidence": 0.6362227300802866}, {"text": "question answering", "start_pos": 96, "end_pos": 114, "type": "TASK", "confidence": 0.9184647798538208}]}, {"text": "They are usually treated as sequence labeling problems.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 28, "end_pos": 45, "type": "TASK", "confidence": 0.6635003685951233}]}, {"text": "Although the topics have been studied extensively for the past several decades, development of neural network and deep learning based methods in recent years ( significantly improves the previous state-of-the-art.", "labels": [], "entities": []}, {"text": "* Work was done while doing internship at Alibaba.", "labels": [], "entities": [{"text": "Alibaba", "start_pos": 42, "end_pos": 49, "type": "DATASET", "confidence": 0.9651736617088318}]}, {"text": "A popular neural architecture for ER is BiLSTM-CRF ().", "labels": [], "entities": []}, {"text": "The architecture has been shown to achieve best performance on many sequence labeling tasks.", "labels": [], "entities": [{"text": "sequence labeling tasks", "start_pos": 68, "end_pos": 91, "type": "TASK", "confidence": 0.7617441217104594}]}, {"text": "In addition, the architecture can be easily extended to model different sources of training data.", "labels": [], "entities": []}, {"text": "In real world applications, it is important to include external data sources for model training, because using only domain-specific data for training is usually not enough to achieve best performance.", "labels": [], "entities": []}, {"text": "For example, in the case of KBP 2016 tracks, both the 1st and the 2nd teams (ranking in the NERC evaluation) use external data source () for model training.", "labels": [], "entities": [{"text": "KBP 2016 tracks", "start_pos": 28, "end_pos": 43, "type": "DATASET", "confidence": 0.9105204145113627}, {"text": "NERC evaluation", "start_pos": 92, "end_pos": 107, "type": "DATASET", "confidence": 0.9093852937221527}]}, {"text": "The challenge here is to transfer knowledge from external data source to target data source.", "labels": [], "entities": []}, {"text": "Multi-Task (MT) BiLSTM-CRF architecture ( ) is designed for this knowledge transfer.", "labels": [], "entities": [{"text": "knowledge transfer", "start_pos": 65, "end_pos": 83, "type": "TASK", "confidence": 0.779927521944046}]}, {"text": "In this work, we develop an ER model based on the MT BiLSTM-CRF architecture, with additional entity embeddings and domain adaption.", "labels": [], "entities": [{"text": "MT BiLSTM-CRF architecture", "start_pos": 50, "end_pos": 76, "type": "DATASET", "confidence": 0.662964920202891}]}, {"text": "Two novel methods are proposed to further improve the model performance.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section presents experiments results of our methods on the KBP 2016 and 2017 evaluation datasets.", "labels": [], "entities": [{"text": "KBP 2016 and 2017 evaluation datasets", "start_pos": 64, "end_pos": 101, "type": "DATASET", "confidence": 0.9446428020795187}]}, {"text": "We focus on Engilsh (ENG) and Mandarin Chinese (CMN) ER tasks, which include both named entity recognition (NAM) and nominal entity recognition (NOM).", "labels": [], "entities": [{"text": "named entity recognition (NAM)", "start_pos": 82, "end_pos": 112, "type": "TASK", "confidence": 0.7767936885356903}, {"text": "nominal entity recognition (NOM)", "start_pos": 117, "end_pos": 149, "type": "TASK", "confidence": 0.7602436492840449}]}, {"text": "The neural models are implemented using).", "labels": [], "entities": []}, {"text": "Dropout and gradient clipping are applied when necessary to avoid numerical issues during training.", "labels": [], "entities": [{"text": "gradient clipping", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.6975427716970444}]}, {"text": "Performance numbers are reported using the NERC F 1 score as defined in ().", "labels": [], "entities": [{"text": "NERC", "start_pos": 43, "end_pos": 47, "type": "DATASET", "confidence": 0.6763842701911926}, {"text": "F 1 score", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.8970349828402201}]}, {"text": "KBP 2015 data is used for evaluation on the 2016 evaluation dataset.", "labels": [], "entities": [{"text": "KBP 2015 data", "start_pos": 0, "end_pos": 13, "type": "DATASET", "confidence": 0.9652124047279358}, {"text": "2016 evaluation dataset", "start_pos": 44, "end_pos": 67, "type": "DATASET", "confidence": 0.652038445075353}]}, {"text": "Both datasets are used for training for KBP 2017 evaluation.", "labels": [], "entities": [{"text": "KBP 2017 evaluation", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.5829096833864847}]}, {"text": "We also leverage external data sources to improve model performance.", "labels": [], "entities": []}, {"text": "Unlike (, manual annotation is not feasible to us due to budget limit, we instead use ACE ( () entity annotations as source datasets.", "labels": [], "entities": []}, {"text": "It is worth noting that annotation guidelines are different from one dataset to another, especially for nominal entity annotations.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Effectiveness of additional entity embeddings  (EE) in model embedding layer.", "labels": [], "entities": []}, {"text": " Table 2: Effectiveness of Multi-Task Data Selection  (MTDS).", "labels": [], "entities": [{"text": "Multi-Task Data Selection  (MTDS)", "start_pos": 27, "end_pos": 60, "type": "TASK", "confidence": 0.7256611486275991}]}, {"text": " Table 3: Effectiveness of Constrained Decoding (CD)  using Knowledge Base.", "labels": [], "entities": []}, {"text": " Table 4: Performance comparison between 2016 and  2017 datasets.", "labels": [], "entities": []}]}