{"title": [], "abstractContent": [{"text": "This paper presents the first AMR parser built on the Chinese AMR bank.", "labels": [], "entities": [{"text": "AMR parser", "start_pos": 30, "end_pos": 40, "type": "TASK", "confidence": 0.7127419710159302}, {"text": "Chinese AMR bank", "start_pos": 54, "end_pos": 70, "type": "DATASET", "confidence": 0.8355857133865356}]}, {"text": "By applying a transition-based AMR parsing framework to Chinese, we first investigate how well the transitions first designed for English AMR parsing generalize to Chinese and provide a comparative analysis between the transitions for En-glish and Chinese.", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 31, "end_pos": 42, "type": "TASK", "confidence": 0.9005340933799744}, {"text": "AMR parsing", "start_pos": 138, "end_pos": 149, "type": "TASK", "confidence": 0.8796020746231079}]}, {"text": "We then perform a detailed error analysis to identify the major challenges in Chinese AMR parsing that we hope will inform future research in this area.", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 86, "end_pos": 97, "type": "TASK", "confidence": 0.8447873890399933}]}], "introductionContent": [{"text": "Abstract Meaning Representation (AMR) () is a semantic representation where the meaning of a sentence is encoded as a rooted, directed and acyclic graph.", "labels": [], "entities": [{"text": "Abstract Meaning Representation (AMR)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8820303380489349}]}, {"text": "AMR parsing has received a significant amount of attention in the NLP research community.", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.8996203243732452}]}, {"text": "Since the release of the AMR bank a number of AMR parsers have been developed in recent years (.", "labels": [], "entities": [{"text": "AMR bank", "start_pos": 25, "end_pos": 33, "type": "DATASET", "confidence": 0.8475722968578339}]}, {"text": "The initial benefit of AMR parsing has also been demonstrated in various downstream applications such as Information Extraction (, Machine Comprehension, and Natural Language Generation (.", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 23, "end_pos": 34, "type": "TASK", "confidence": 0.9574932754039764}, {"text": "Information Extraction", "start_pos": 105, "end_pos": 127, "type": "TASK", "confidence": 0.8446494936943054}, {"text": "Natural Language Generation", "start_pos": 158, "end_pos": 185, "type": "TASK", "confidence": 0.6498487989107767}]}, {"text": "In this paper, we present the first AMR parser built using the Chinese AMR Bank ( . We adopt the transition-based parsing framework first proposed for English (, where AMR parsing is modeled as a dependency tree to AMR graph transformation using a set of linguistically motivated actions.", "labels": [], "entities": [{"text": "AMR parser", "start_pos": 36, "end_pos": 46, "type": "TASK", "confidence": 0.85692498087883}, {"text": "Chinese AMR Bank", "start_pos": 63, "end_pos": 79, "type": "DATASET", "confidence": 0.7937001784642538}, {"text": "AMR parsing", "start_pos": 168, "end_pos": 179, "type": "TASK", "confidence": 0.7583895623683929}, {"text": "AMR graph transformation", "start_pos": 215, "end_pos": 239, "type": "TASK", "confidence": 0.6391510963439941}]}, {"text": "We briefly describe the Chinese AMR Bank in Section 2, present the transition-based Chinese AMR parsing model in Section 3, report and analyze experimental results in Section 4, and conclude our paper in Section 5.", "labels": [], "entities": [{"text": "Chinese AMR Bank", "start_pos": 24, "end_pos": 40, "type": "DATASET", "confidence": 0.9244542916615804}, {"text": "AMR parsing", "start_pos": 92, "end_pos": 103, "type": "TASK", "confidence": 0.694773256778717}]}], "datasetContent": [{"text": "In this section, we present experiments designed to probe the behavior of our Chinese AMR parser, and where appropriate, compare it to its English counterpart.", "labels": [], "entities": []}, {"text": "We also devise several ablation tests to further investigate the errors produced by our Chinese AMR parser to gain insight that can be used to guide future research.", "labels": [], "entities": [{"text": "Chinese AMR parser", "start_pos": 88, "end_pos": 106, "type": "DATASET", "confidence": 0.75758163134257}]}, {"text": "We use the 10,149 sentences from the Chinese AMR Bank and split the data according to their original CTB8.0 document IDs, where articles 5061-5558 are used as the training set, articles 5000-5030 are used as the development set and articles 5031-5060 are used as the test set.", "labels": [], "entities": [{"text": "Chinese AMR Bank", "start_pos": 37, "end_pos": 53, "type": "DATASET", "confidence": 0.8809660871823629}, {"text": "CTB8.0 document IDs", "start_pos": 101, "end_pos": 120, "type": "DATASET", "confidence": 0.8865179816881815}]}, {"text": "The train/development/test ratio in this dataset is 7608/1264/1277.", "labels": [], "entities": []}, {"text": "As the data are drawn from the Chinese Treebank where words are manually segmented, we will simply use the gold segmentation in our experiments.", "labels": [], "entities": [{"text": "Chinese Treebank", "start_pos": 31, "end_pos": 47, "type": "DATASET", "confidence": 0.982398509979248}]}, {"text": "We then process the whole Chinese dataset using the Stanford CoreNLP () toolkit to get the POS and Named Entity tags.", "labels": [], "entities": [{"text": "Chinese dataset", "start_pos": 26, "end_pos": 41, "type": "DATASET", "confidence": 0.9188791811466217}, {"text": "Stanford CoreNLP", "start_pos": 52, "end_pos": 68, "type": "DATASET", "confidence": 0.9208315312862396}]}, {"text": "To get the dependency parse for the Chinese data, we use the transition-based constituent parser in () to first parse the Chinese sentences into constituent trees, which are then transformed into dependency trees using the converter in the Stanford CoreNLP toolkit.", "labels": [], "entities": [{"text": "dependency parse", "start_pos": 11, "end_pos": 27, "type": "TASK", "confidence": 0.7069897949695587}, {"text": "Stanford CoreNLP toolkit", "start_pos": 240, "end_pos": 264, "type": "DATASET", "confidence": 0.8270591894785563}]}, {"text": "Note that this Chinese constituent parser also uses the Chinese Treebank 8.0 to train its model.", "labels": [], "entities": [{"text": "Chinese Treebank 8.0", "start_pos": 56, "end_pos": 76, "type": "DATASET", "confidence": 0.9198626478513082}]}, {"text": "To avoid training on the parser on AMR test set, we train the constituent parser using a 10-fold cross-validation with each fold parsed using a model trained on the other 9 folds.", "labels": [], "entities": [{"text": "AMR test set", "start_pos": 35, "end_pos": 47, "type": "DATASET", "confidence": 0.9573897322018942}]}, {"text": "In order to compare results between Chinese and English, we also train an English AMR parsing model on the LDC2015E86 dataset used in SemEval 2016 Task 8 with the standard split 16833/1368/1371 and the English AMR parser, CAMR, is utilized to train the English model.", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 82, "end_pos": 93, "type": "TASK", "confidence": 0.6383114457130432}, {"text": "LDC2015E86 dataset", "start_pos": 107, "end_pos": 125, "type": "DATASET", "confidence": 0.9361615777015686}, {"text": "SemEval 2016 Task 8", "start_pos": 134, "end_pos": 153, "type": "TASK", "confidence": 0.494878888130188}]}, {"text": "All the AMR parsing results are evaluated by the Smatch toolkit .", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 8, "end_pos": 19, "type": "TASK", "confidence": 0.8958818912506104}]}], "tableCaptions": []}