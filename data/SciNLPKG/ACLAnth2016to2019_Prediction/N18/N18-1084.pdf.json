{"title": [{"text": "Monte Carlo Syntax Marginals for Exploring and Using Dependency Parses", "labels": [], "entities": []}], "abstractContent": [{"text": "Dependency parsing research, which has made significant gains in recent years, typically fo-cuses on improving the accuracy of single-tree predictions.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8422776460647583}, {"text": "accuracy", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.9975010752677917}]}, {"text": "However, ambiguity is inherent to natural language syntax, and communicating such ambiguity is important for error analysis and better-informed downstream applications.", "labels": [], "entities": [{"text": "error analysis", "start_pos": 109, "end_pos": 123, "type": "TASK", "confidence": 0.6716681271791458}]}, {"text": "In this work, we propose a transition sampling algorithm to sample from the full joint distribution of parse trees defined by a transition-based parsing model, and demonstrate the use of the samples in probabilistic dependency analysis.", "labels": [], "entities": []}, {"text": "First, we define the new task of dependency path prediction, inferring syntactic substructures over part of a sentence, and provide the first analysis of performance on this task.", "labels": [], "entities": [{"text": "dependency path prediction", "start_pos": 33, "end_pos": 59, "type": "TASK", "confidence": 0.7998680075009664}]}, {"text": "Second, we demonstrate the usefulness of our Monte Carlo syntax marginal method for parser error analysis and calibration.", "labels": [], "entities": [{"text": "parser error analysis", "start_pos": 84, "end_pos": 105, "type": "TASK", "confidence": 0.8461400667826334}]}, {"text": "Finally, we use this method to propagate parse uncertainty to two downstream information extraction applications: identifying persons killed by police and semantic role assignment.", "labels": [], "entities": [{"text": "parse uncertainty", "start_pos": 41, "end_pos": 58, "type": "TASK", "confidence": 0.8673284947872162}, {"text": "information extraction", "start_pos": 77, "end_pos": 99, "type": "TASK", "confidence": 0.765045553445816}, {"text": "semantic role assignment", "start_pos": 155, "end_pos": 179, "type": "TASK", "confidence": 0.7142701546351115}]}], "introductionContent": [{"text": "Dependency parsers typically predict a singletree fora sentence to be used in downstream applications, and most work on dependency parsers seeks to improve accuracy of such single-tree predictions.", "labels": [], "entities": [{"text": "Dependency parsers", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7859282195568085}, {"text": "accuracy", "start_pos": 156, "end_pos": 164, "type": "METRIC", "confidence": 0.997628390789032}]}, {"text": "Despite tremendous gains in the last few decades of parsing research, accuracy is far from perfect-but perfect accuracy maybe impossible since syntax models by themselves do not incorporate the discourse, pragmatic, or world knowledge necessary to resolve many ambiguities.", "labels": [], "entities": [{"text": "parsing", "start_pos": 52, "end_pos": 59, "type": "TASK", "confidence": 0.9707238078117371}, {"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9986404776573181}, {"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9612942934036255}]}, {"text": "In fact, although relatively unexamined, substantial ambiguity already exists within commonly used discriminative probabilistic parsing models, which define a parse forest-a probability distribution p(y | x) over possible dependency trees y \u2208 Y(x) for an input sentence x.", "labels": [], "entities": []}, {"text": "For example, the top of shows the predicted parse y (greedy) from such a parser, which resolves a prepositional (PP) attachment ambiguity in one manner; this prediction was selected by a standard greedy transition-based algorithm ( \u00a72.1).", "labels": [], "entities": []}, {"text": "However, the bottom of shows marginal probabilities of individual (relation, governor, child) edges under this same model.", "labels": [], "entities": []}, {"text": "These denote our estimated probabilities, across all possible parse structures, that a pair of words are connected with a particular relation ( \u00a72.4).", "labels": [], "entities": []}, {"text": "For example, the two different PP attachment readings both exist within this parse forest with marginal probabilities p( nmod(saw 2 , telescope 7 ) | x) = 0.72 (1) p( nmod(man 4 , telescope ) | x) = 0.28, where (1) implies she used a telescope to seethe man, and (2) implies she saw a man who had a telescope.", "labels": [], "entities": []}, {"text": "These types of irreducible syntactic ambiguities exist and should betaken into consideration when analyzing syntactic information; for instance, one could transmit multiple samples () or confidence scores over ambiguous readings to downstream analysis components.", "labels": [], "entities": []}, {"text": "In this work, we introduce a simple transition sampling algorithm for transition-based dependency parsing ( \u00a72.2), which, by yielding exact samples from the full joint distribution over trees, makes it possible to infer probabilities of long-distance or other arbitrary structures over the parse distribution ( \u00a72.4).", "labels": [], "entities": [{"text": "transition-based dependency parsing", "start_pos": 70, "end_pos": 105, "type": "TASK", "confidence": 0.6711725294589996}]}, {"text": "We implement transition sampling-a very simple change to pre-existing parsing software-and use it to demonstrate several applications of probabilistic dependency analysis: \u2022 Motivated by how dependency parses are typically used in feature-based machine learning, we introduce anew parsing-related task-dependency path prediction.", "labels": [], "entities": [{"text": "dependency analysis", "start_pos": 151, "end_pos": 170, "type": "TASK", "confidence": 0.7581642270088196}, {"text": "parsing-related task-dependency path prediction", "start_pos": 281, "end_pos": 328, "type": "TASK", "confidence": 0.9015306085348129}]}, {"text": "This task involves inference over variable length dependency paths, syntactic substructures over only parts of a sentence.", "labels": [], "entities": []}, {"text": "\u2022 To accomplish this task, we define a Monte Carlo syntax marginal inference method which exploits information across samples of the entire parse forest.", "labels": [], "entities": []}, {"text": "It achieves higher accuracy predictions than a traditional greedy parsing algorithm, and allows tradeoffs between precision and recall ( \u00a74).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9964937567710876}, {"text": "precision", "start_pos": 114, "end_pos": 123, "type": "METRIC", "confidence": 0.9991546869277954}, {"text": "recall", "start_pos": 128, "end_pos": 134, "type": "METRIC", "confidence": 0.9976143836975098}]}, {"text": "\u2022 We provide a quantitative measure of the model's inherent uncertainty in the parse, whole-tree entropy, and show how it can be used for error analysis ( \u00a73).", "labels": [], "entities": [{"text": "error analysis", "start_pos": 138, "end_pos": 152, "type": "TASK", "confidence": 0.6378506869077682}]}, {"text": "\u2022 We demonstrate the method's (surprisingly) reasonable calibration ( \u00a75).", "labels": [], "entities": []}, {"text": "\u2022 Finally, we demonstrate the utility of our method to propagate uncertainty to downstream applications.", "labels": [], "entities": []}, {"text": "Our method improves performance forgiving probabilistic semantics to a rule-based event extractor to identify civilians killed by police ( \u00a76), as well as semantic role assignment ( \u00a77).", "labels": [], "entities": [{"text": "semantic role assignment", "start_pos": 155, "end_pos": 179, "type": "TASK", "confidence": 0.733226478099823}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Example sentences from the UD development set and summaries of their Monte Carlo parse distributions.  Domain Size gives | \u02dc  Y 100 |, the number of unique parse structures in 100 samples. Top 3 Freq. gives the frequencies  of the 3 most probable structures i\u00f1  Y 100 . Entropy is calculated according to Eq. 7; its upper bound is log(100) =  4.605.", "labels": [], "entities": [{"text": "UD development set", "start_pos": 37, "end_pos": 55, "type": "DATASET", "confidence": 0.7258110841115316}, {"text": "Freq", "start_pos": 205, "end_pos": 209, "type": "METRIC", "confidence": 0.9779744148254395}, {"text": "Entropy", "start_pos": 280, "end_pos": 287, "type": "METRIC", "confidence": 0.9473522305488586}, {"text": "Eq. 7", "start_pos": 315, "end_pos": 320, "type": "DATASET", "confidence": 0.911524494489034}]}]}