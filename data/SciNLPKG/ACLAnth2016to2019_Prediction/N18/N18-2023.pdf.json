{"title": [{"text": "A Transition-based Algorithm for Unrestricted AMR Parsing", "labels": [], "entities": [{"text": "AMR Parsing", "start_pos": 46, "end_pos": 57, "type": "TASK", "confidence": 0.9102424085140228}]}], "abstractContent": [{"text": "Non-projective parsing can be useful to handle cycles and reentrancy in AMR graphs.", "labels": [], "entities": []}, {"text": "We explore this idea and introduce a greedy left-to-right non-projective transition-based parser.", "labels": [], "entities": []}, {"text": "At each parsing configuration, an oracle decides whether to create a concept or whether to connect a pair of existing concepts.", "labels": [], "entities": []}, {"text": "The algorithm handles reentrancy and arbitrary cycles natively, i.e. within the transition system itself.", "labels": [], "entities": []}, {"text": "The model is evaluated on the LDC2015E86 corpus, obtaining results close to the state of the art, including a Smatch of 64%, and showing good behavior on reentrant edges.", "labels": [], "entities": [{"text": "LDC2015E86 corpus", "start_pos": 30, "end_pos": 47, "type": "DATASET", "confidence": 0.9813308715820312}, {"text": "Smatch", "start_pos": 110, "end_pos": 116, "type": "METRIC", "confidence": 0.9968649744987488}]}], "introductionContent": [{"text": "Abstract Meaning Representation (AMR) is a semantic representation language to map the meaning of English sentences into directed, cycled, labeled graphs ().", "labels": [], "entities": [{"text": "Abstract Meaning Representation (AMR)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8511899610360464}]}, {"text": "Graph vertices are concepts inferred from words.", "labels": [], "entities": []}, {"text": "The concepts can be represented by the words themselves (e.g. dog), PropBank framesets () (e.g. eat-01), or keywords (like named entities or quantities).", "labels": [], "entities": []}, {"text": "The edges denote relations between pairs of concepts (e.g. eat-01 :ARG0 dog).", "labels": [], "entities": [{"text": "ARG0 dog", "start_pos": 67, "end_pos": 75, "type": "DATASET", "confidence": 0.8222247064113617}]}, {"text": "AMR parsing integrates tasks that have usually been addressed separately in natural language processing (NLP), such as named entity recognition (, semantic role labeling () or co-reference resolution (.", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9216749966144562}, {"text": "named entity recognition", "start_pos": 119, "end_pos": 143, "type": "TASK", "confidence": 0.6153777043024699}, {"text": "semantic role labeling", "start_pos": 147, "end_pos": 169, "type": "TASK", "confidence": 0.6486831804116567}, {"text": "co-reference resolution", "start_pos": 176, "end_pos": 199, "type": "TASK", "confidence": 0.7335337847471237}]}, {"text": "shows an example of an AMR graph.", "labels": [], "entities": []}, {"text": "Several transition-based dependency parsing algorithms have been extended to generate AMR.", "labels": [], "entities": [{"text": "transition-based dependency parsing", "start_pos": 8, "end_pos": 43, "type": "TASK", "confidence": 0.5959573686122894}]}, {"text": "describe a two-stage model, where they first obtain the dependency parse of a sentence and then transform it into a graph.", "labels": [], "entities": []}, {"text": "propose a variant of the ARC-EAGER algorithm to identify labeled edges between concepts.", "labels": [], "entities": []}, {"text": "These concepts are identified Words can refer to concepts by themselves (green), be mapped to PropBank framesets (red) or be broken down into multiple-term/non-literal concepts (blue).", "labels": [], "entities": [{"text": "PropBank framesets", "start_pos": 94, "end_pos": 112, "type": "DATASET", "confidence": 0.9105390310287476}]}, {"text": "Prince plays different semantic roles.", "labels": [], "entities": []}, {"text": "using a lookup table and a set of rules.", "labels": [], "entities": []}, {"text": "A restricted subset of reentrant edges are supported by an additional classifier.", "labels": [], "entities": []}, {"text": "A similar configuration is used in ( , but relying on a cache data structure to handle reentrancy, cycles and restricted non-projectivity.", "labels": [], "entities": []}, {"text": "A feed-forward network and additional hooks are used to build the concepts.", "labels": [], "entities": []}, {"text": "Ballesteros and AlOnaizan (2017) use a modified ARC-STANDARD algorithm, where the oracle is trained using stackLSTMs (.", "labels": [], "entities": []}, {"text": "Reentrancy is handled through SWAP (Nivre, 2009) and they define additional transitions intended to detect concepts, entities and polarity nodes.", "labels": [], "entities": []}, {"text": "This paper explores unrestricted non-projective AMR parsing and introduces AMR-COVINGTON, inspired by.", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 48, "end_pos": 59, "type": "TASK", "confidence": 0.8361341059207916}, {"text": "AMR-COVINGTON", "start_pos": 75, "end_pos": 88, "type": "DATASET", "confidence": 0.7905817627906799}]}, {"text": "It handles arbitrary non-projectivity, cycles and reentrancy in a natural way, as there is no need for specific transitions, but just the removal of restrictions from the original algorithm.", "labels": [], "entities": []}, {"text": "The algorithm has full coverage and keeps transitions simple, which is a matter of concern in recent studies ( ).", "labels": [], "entities": []}], "datasetContent": [{"text": "Corpus We use the LDC2015E86 corpus and its official splits: 16 833 graphs for training, 1 368 for development and 1 371 for testing.", "labels": [], "entities": [{"text": "LDC2015E86 corpus", "start_pos": 18, "end_pos": 35, "type": "DATASET", "confidence": 0.9831221103668213}]}, {"text": "The final model is only trained on the training split.", "labels": [], "entities": []}, {"text": "Metrics We use Smatch  and the metrics from.", "labels": [], "entities": []}, {"text": "Sources The code and the pretrained model used in this paper can be found at https:// github.com/aghie/tb-amr.", "labels": [], "entities": []}, {"text": "shows accuracy of Tc on the development set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 6, "end_pos": 14, "type": "METRIC", "confidence": 0.9997594952583313}, {"text": "Tc", "start_pos": 18, "end_pos": 20, "type": "METRIC", "confidence": 0.9507038593292236}]}, {"text": "CONFIRM and REDUCE are the easiest transitions, as local information such as POS-tags and words are discriminative to distinguish between content and function words.", "labels": [], "entities": [{"text": "REDUCE", "start_pos": 12, "end_pos": 18, "type": "METRIC", "confidence": 0.8846830725669861}]}, {"text": "BREAKDOWN is the hardest action.", "labels": [], "entities": [{"text": "BREAKDOWN", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.8857749700546265}]}, {"text": "In early stages of this work, we observed that this transition could learn to correctly generate multiple-term concepts for namedentities that are not sparse (e.g. countries or people), but failed with sparse entities (e.g. dates or percent quantities).", "labels": [], "entities": []}, {"text": "Low performance on identifying them negatively affects the edge metrics, which require both concepts of an edge to be correct.", "labels": [], "entities": []}, {"text": "Because of this and to identify them properly, we use the mentioned complementary rules to handle named entities.", "labels": [], "entities": []}, {"text": "RIGHT-ARCs are harder than LEFT-ARCs, although the reason for this issue remains as an open question for us.", "labels": [], "entities": [{"text": "RIGHT-ARCs", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.6689581871032715}]}, {"text": "The performance for NO-ARCs is high, but it would be interesting to achieve a higher recall at a cost of a lower precision, as predicting NO-ARCs makes the transition sequence longer, but could help identify more distant reentrancy.", "labels": [], "entities": [{"text": "recall", "start_pos": 85, "end_pos": 91, "type": "METRIC", "confidence": 0.9992510676383972}, {"text": "precision", "start_pos": 113, "end_pos": 122, "type": "METRIC", "confidence": 0.9940556287765503}]}, {"text": "The accuracy of Tc is \u223c86%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997954964637756}, {"text": "Tc", "start_pos": 16, "end_pos": 18, "type": "METRIC", "confidence": 0.6838630437850952}]}, {"text": "not show the detailed results since the number of classes is too high.", "labels": [], "entities": []}, {"text": "C c was trained on concepts occurring more than 1 time in the training set, obtaining an accuracy of \u223c83%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.9996638298034668}]}, {"text": "The accuracy on the development set with all concepts was \u223c77%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997995495796204}]}, {"text": "compares the performance of our systems with state-of-the-art models on the test set.", "labels": [], "entities": []}, {"text": "AMR-COVINGTON obtains state-of-the-art results for all the standard metrics.", "labels": [], "entities": [{"text": "AMR-COVINGTON", "start_pos": 0, "end_pos": 13, "type": "DATASET", "confidence": 0.7334907054901123}]}, {"text": "It outperforms the rest of the models when handling reentrant edges.", "labels": [], "entities": []}, {"text": "It is worth noting that D requires an additional classifier to handle a restricted set of reentrancy and P uses up to five classifiers to build the graph.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: T c scores on the development set.", "labels": [], "entities": [{"text": "T c", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9425391852855682}, {"text": "development set", "start_pos": 28, "end_pos": 43, "type": "DATASET", "confidence": 0.7075334787368774}]}, {"text": " Table 4: F-score comparison with F (Flanigan et al.,  2014), W (Wang et al., 2015), F' (Flanigan et al., 2016),  D (Damonte et al., 2017), P (Peng et al., 2018). D, P  and our system are left-to-right transition-based.", "labels": [], "entities": [{"text": "F-score", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9622762799263}]}, {"text": " Table 5: Set of proposed features for each classifier.  POS, W, C, ENTITY are part-of-speech tag, word, con- cept and entity embeddings. EW are pre-trained exter- nal word embeddings, fine-tuned during the training  phase (http://nlp.stanford.edu/data/glove.6B.zip, 100  dimensions). LM and RM are the leftmost and the right- most function; and h, c, cc represent head, child and  grand-child concepts of a concept; so, for example,  LM c stands for the leftmost child of the concept. NH  and NC are the number of heads and children of a con- cept. NPUNKT indicates the number of '.', ';', ':', '?',  '!' that have already been processed. HL denotes the  labels of the last assigned head. CT indicates the type  of concept (constant, propbank frameset, other). G in- dicates if a concept was generated using a CONFIRM or  BREAKDOWN. D denotes the dependency label exist- ing in the dependency tree between the word at the jth  position in \u03b2 and the kth last in \u03bb 1 and vice versa. The  word that generated a concept is still accessible after  creating the concept.", "labels": [], "entities": []}]}