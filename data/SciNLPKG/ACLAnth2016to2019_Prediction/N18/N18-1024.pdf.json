{"title": [{"text": "Neural Automated Essay Scoring and Coherence Modeling for Adversarially Crafted Input", "labels": [], "entities": [{"text": "Neural Automated Essay Scoring and Coherence Modeling", "start_pos": 0, "end_pos": 53, "type": "TASK", "confidence": 0.6734336146286556}]}], "abstractContent": [{"text": "We demonstrate that current state-of-the-art approaches to Automated Essay Scoring (AES) are not well-suited to capturing adver-sarially crafted input of grammatical but incoherent sequences of sentences.", "labels": [], "entities": [{"text": "Automated Essay Scoring (AES)", "start_pos": 59, "end_pos": 88, "type": "TASK", "confidence": 0.7872408976157507}]}, {"text": "We develop a neural model of local coherence that can effectively learn connectedness features between sentences, and propose a framework for integrating and jointly training the local coherence model with a state-of-the-art AES model.", "labels": [], "entities": []}, {"text": "We evaluate our approach against a number of baselines and experimentally demonstrate its effectiveness on both the AES task and the task of flagging adversarial input, further contributing to the development of an approach that strengthens the validity of neural essay scoring models.", "labels": [], "entities": [{"text": "AES", "start_pos": 116, "end_pos": 119, "type": "METRIC", "confidence": 0.6857282519340515}]}], "introductionContent": [{"text": "Automated Essay Scoring (AES) focuses on automatically analyzing the quality of writing and assigning a score to the text.", "labels": [], "entities": [{"text": "Automated Essay Scoring (AES)", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7219058920939764}]}, {"text": "Typically, AES models exploit a wide range of manually-tuned shallow and deep linguistic features.", "labels": [], "entities": []}, {"text": "Recent advances in deep learning have shown that neural approaches to AES achieve state-of-the-art results () with the additional advantage of utilizing features that are automatically learned from the data.", "labels": [], "entities": [{"text": "AES", "start_pos": 70, "end_pos": 73, "type": "TASK", "confidence": 0.9369064569473267}]}, {"text": "In order to facilitate interpretability of neural models, a number of visualization techniques have been proposed to identify textual (superficial) features that contribute to model performance (.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, however, no prior work has investigated the robustness of neural AES systems to adversarially crafted input that is designed to trick the model into assigning desired missclassifications; for instance, a high score to a low quality text.", "labels": [], "entities": []}, {"text": "Examining and addressing such validity issues is critical and imperative for AES deployment.", "labels": [], "entities": [{"text": "AES deployment", "start_pos": 77, "end_pos": 91, "type": "TASK", "confidence": 0.8700746595859528}]}, {"text": "Previous work has primarily focused on assessing the robustness of \"standard\" machine learning approaches that rely on manual feature engineering; for example,; have shown that such AES systems, unless explicitly designed to handle adversarial input, can be susceptible to subversion by writers who understand something of the systems' workings and can exploit this to maximize their score.", "labels": [], "entities": []}, {"text": "In this paper, we make the following contributions: i.", "labels": [], "entities": []}, {"text": "We examine the robustness of state-of-the-art neural AES models to adversarially crafted input, 1 and specifically focus on input related to local coherence; that is, grammatical but incoherent sequences of sentences.", "labels": [], "entities": []}, {"text": "In addition to the superiority in performance of neural approaches against \"standard\" machine learning models (, such a setup allows us to investigate their potential superiority / capacity in handling adversarial input without being explicitly designed to do so. ii.", "labels": [], "entities": []}, {"text": "We demonstrate that state-of-the-art neural AES is not well-suited to capturing adversarial input of grammatical but incoherent sequences of sentences, and develop a neural model of local coherence that can effectively learn connectedness features between sentences. iii.", "labels": [], "entities": []}, {"text": "A local coherence model is typically evaluated based on its ability to rank coherently ordered sequences of sentences higher than their incoherent / permuted counterparts (e.g.,).", "labels": [], "entities": []}, {"text": "We focus on a stricter evaluation setting in which the model is tested on its ability to rank coherent sequences of sentences higher than any incoherent / permuted set of sentences, and not just its own permuted counterparts.", "labels": [], "entities": []}, {"text": "This supports a more rigorous evaluation that facilitates development of more robust models. iv. We propose a framework for integrating and jointly training the local coherence model with a state-of-the-art AES model.", "labels": [], "entities": []}, {"text": "We evaluate our approach against a number of baselines and experimentally demonstrate its effectiveness on both the AES task and the task of flagging adversarial input, further contributing to the development of an approach that strengthens AES validity.", "labels": [], "entities": [{"text": "AES task", "start_pos": 116, "end_pos": 124, "type": "TASK", "confidence": 0.7247836291790009}, {"text": "AES validity", "start_pos": 241, "end_pos": 253, "type": "TASK", "confidence": 0.6675870567560196}]}, {"text": "At the outset, our goal is to develop a framework that strengthens the validity of state-of-the-art neural AES approaches with respect to adversarial input related to local aspects of coherence.", "labels": [], "entities": []}, {"text": "For our experiments, we use the Automated Student Assessment Prize (ASAP) dataset, 3 which contains essays written by students ranging from Grade 7 to Grade 10 in response to a number of different prompts (see Section 4).", "labels": [], "entities": [{"text": "Automated Student Assessment Prize (ASAP) dataset", "start_pos": 32, "end_pos": 81, "type": "DATASET", "confidence": 0.566536370664835}]}], "datasetContent": [{"text": "We use the ASAP dataset, which contains 12, 976 essays written by students ranging from Grade 7 to We note that, during training, the scores are mapped to a range between 0 and 1 (similarly to), and then scaled back to their original range during evaluation.", "labels": [], "entities": [{"text": "ASAP dataset", "start_pos": 11, "end_pos": 23, "type": "DATASET", "confidence": 0.8740476369857788}]}, {"text": "Grade 10 in response to 8 different prompts.", "labels": [], "entities": []}, {"text": "We follow the ASAP data split by, and apply 5-fold cross validation in all experiments using the same train/dev/test splits.", "labels": [], "entities": [{"text": "ASAP data split", "start_pos": 14, "end_pos": 29, "type": "DATASET", "confidence": 0.8527249892552694}]}, {"text": "For each prompt, the fold predictions are aggregated and evaluated together.", "labels": [], "entities": []}, {"text": "In order to calculate the overall system performance, the results are averaged across the 8 prompts.", "labels": [], "entities": []}, {"text": "To create adversarial input, we select high scoring essays per prompt (given a pre-defined score threshold, Table 1) 10 that are assumed coherent, and create 10 permutations per essay by randomly shuffling its sentences.", "labels": [], "entities": []}, {"text": "In the joint learning setup, we augment the original ASAP dataset with a subset of the synthetic essays.", "labels": [], "entities": [{"text": "ASAP dataset", "start_pos": 53, "end_pos": 65, "type": "DATASET", "confidence": 0.7516099810600281}]}, {"text": "Specifically, we randomly select 4 permutations per essay to include in the training set, 11 but include all 10 permutations in the test set.", "labels": [], "entities": []}, {"text": "presents the details of the datasets.", "labels": [], "entities": []}, {"text": "We test performance on the ASAP dataset using Quadratic Weighted Kappa (QWK), which was the official evaluation metric in the ASAP competition, while we test performance on the synthetic dataset using pairwise ranking accuracy (PRA) between an original non-permuted essay and its permuted counterparts.", "labels": [], "entities": [{"text": "ASAP dataset", "start_pos": 27, "end_pos": 39, "type": "DATASET", "confidence": 0.945013165473938}, {"text": "Quadratic Weighted Kappa (QWK)", "start_pos": 46, "end_pos": 76, "type": "METRIC", "confidence": 0.8388619422912598}, {"text": "ASAP competition", "start_pos": 126, "end_pos": 142, "type": "TASK", "confidence": 0.5041483342647552}, {"text": "pairwise ranking accuracy (PRA)", "start_pos": 201, "end_pos": 232, "type": "METRIC", "confidence": 0.7698661386966705}]}, {"text": "PRA is typically used as an evaluation metric on coherence assessment tasks on other domains (, and is based on the fraction of correct pairwise rankings in the test data (i.e., a coherent essay should be ranked higher than its permuted counterpart).", "labels": [], "entities": []}, {"text": "Herein, we extend this metric and furthermore evaluate the models by comparing each original essay to all adversarial / permuted essays in the test data, and not just its own permuted counterparts -we refer to this metric as total pairwise ranking accuracy (TPRA).", "labels": [], "entities": [{"text": "total pairwise ranking accuracy (TPRA)", "start_pos": 225, "end_pos": 263, "type": "METRIC", "confidence": 0.7294949761458805}]}], "tableCaptions": [{"text": " Table 1: Statistics for each dataset per prompt. For the synthetic dataset, the high scoring ASAP essays are selected  based on the indicated score threshold (inclusive). \"total size\" refers to the number of the ASAP essays selected +  their 10 different permutations.", "labels": [], "entities": []}, {"text": " Table 2: Model performance on ASAP and synthetic  test data. Evaluation is based on the average QWK,  PRA and TRPA across the 8 prompts. * indicates  significantly different results compared to LSTM T&N  (two-tailed test with p < 0.01).", "labels": [], "entities": [{"text": "ASAP", "start_pos": 31, "end_pos": 35, "type": "TASK", "confidence": 0.8392631411552429}, {"text": "QWK", "start_pos": 97, "end_pos": 100, "type": "METRIC", "confidence": 0.8757033944129944}, {"text": "PRA", "start_pos": 103, "end_pos": 106, "type": "METRIC", "confidence": 0.9779461622238159}, {"text": "TRPA", "start_pos": 111, "end_pos": 115, "type": "METRIC", "confidence": 0.9769811034202576}]}, {"text": " Table 3: Evaluation of different Joint Learning model  parameters. * indicates significantly different results  compared to our Joint Learning approach.", "labels": [], "entities": []}]}