{"title": [{"text": "A Neural Layered Model for Nested Named Entity Recognition", "labels": [], "entities": [{"text": "Nested Named Entity Recognition", "start_pos": 27, "end_pos": 58, "type": "TASK", "confidence": 0.586109958589077}]}], "abstractContent": [{"text": "Entity mentions embedded in longer entity mentions are referred to as nested entities.", "labels": [], "entities": []}, {"text": "Most named entity recognition (NER) systems deal only with the flat entities and ignore the inner nested ones, which fails to capture finer-grained semantic information in underlying texts.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 5, "end_pos": 35, "type": "TASK", "confidence": 0.8081954022248586}]}, {"text": "To address this issue, we propose a novel neural model to identify nested entities by dynamically stacking flat NER layers.", "labels": [], "entities": []}, {"text": "Each flat NER layer is based on the state-of-the-art flat NER model that captures sequential context representation with bidirectional long short-term memory (LSTM) layer and feeds it to the cascaded CRF layer.", "labels": [], "entities": []}, {"text": "Our model merges the output of the LSTM layer in the current flat NER layer to build new representation for detected entities and subsequently feeds them into the next flat NER layer.", "labels": [], "entities": []}, {"text": "This allows our model to extract outer entities by taking full advantage of information encoded in their corresponding inner entities, in an inside-to-outside way.", "labels": [], "entities": []}, {"text": "Our model dynamically stacks the flat NER layers until no outer entities are extracted.", "labels": [], "entities": []}, {"text": "Extensive evaluation shows that our dynamic model outperforms state-of-the-art feature-based systems on nested NER, achieving 74.7% and 72.2% on GENIA and ACE2005 datasets, respectively, in terms of F-score.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 145, "end_pos": 150, "type": "DATASET", "confidence": 0.9483821392059326}, {"text": "ACE2005 datasets", "start_pos": 155, "end_pos": 171, "type": "DATASET", "confidence": 0.8857247233390808}, {"text": "F-score", "start_pos": 199, "end_pos": 206, "type": "METRIC", "confidence": 0.9979706406593323}]}], "introductionContent": [{"text": "The task of named entity recognition (NER) involves the extraction from text of names of entities pertaining to semantic types such as person (PER), location (LOC) and geo-political entity (GPE).", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 12, "end_pos": 42, "type": "TASK", "confidence": 0.8391527136166891}]}, {"text": "NER has drawn the attention of many researchers as the first step towards NLP applications such as entity linking, relation extraction, event extraction) and co-reference resolution.", "labels": [], "entities": [{"text": "NER", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.7363370656967163}, {"text": "entity linking", "start_pos": 99, "end_pos": 113, "type": "TASK", "confidence": 0.7957484424114227}, {"text": "relation extraction", "start_pos": 115, "end_pos": 134, "type": "TASK", "confidence": 0.7831904888153076}, {"text": "event extraction", "start_pos": 136, "end_pos": 152, "type": "TASK", "confidence": 0.6979488134384155}, {"text": "co-reference resolution", "start_pos": 158, "end_pos": 181, "type": "TASK", "confidence": 0.7252460420131683}]}, {"text": "Due to the properties of natural language, many named entities contain nested entities: embedded names which are included in other entities, illustrated in.", "labels": [], "entities": []}, {"text": "This phenomenon is quite common in many domains (.", "labels": [], "entities": []}, {"text": "However, much of the work on NER copes only with non-nested entities which are also called flat entities and neglects nested entities.", "labels": [], "entities": [{"text": "NER", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.9557140469551086}]}, {"text": "This leads to loss of potentially important information, with negative impacts on subsequent tasks.", "labels": [], "entities": []}, {"text": "Traditional approaches to NER mainly involve two types of approaches: supervised learning ( and hybrid approaches () that combine supervised learning with rules.", "labels": [], "entities": [{"text": "NER", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.9843892455101013}]}, {"text": "Such approaches require either domain knowledge or heavy featureengineering.", "labels": [], "entities": []}, {"text": "Recent advances in neural networks enable NER without depending on external knowledge resources through automated learning highlevel and abstract features from text (.", "labels": [], "entities": [{"text": "NER", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.9884087443351746}]}, {"text": "In this paper, we propose a novel dynamic neural model for nested entity recognition, without relying on any external knowledge resources or linguistics features.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.7078572809696198}]}, {"text": "Our model enables sequentially  stacking flat NER layers from bottom to up and identifying entities in an end-to-end manner.", "labels": [], "entities": []}, {"text": "The number of stacked layers depends on the level of entity nesting and dynamically adjusts to the input sequences as the nested level varies from different sequences.", "labels": [], "entities": []}, {"text": "Given a sequence of words, our model first represents each word using a low-dimensional vector concatenated from its corresponding word and character sequence embeddings.", "labels": [], "entities": []}, {"text": "Taking the sequence of the word representation as input, our flat NER layer enables capturing context representation by along short-term memory (LSTM) layer.", "labels": [], "entities": []}, {"text": "The context representation is then fed to a CRF layer for label prediction.", "labels": [], "entities": [{"text": "label prediction", "start_pos": 58, "end_pos": 74, "type": "TASK", "confidence": 0.7629381716251373}]}, {"text": "Subsequently, the context representation from the LSTM layer is merged to build representation for each detected entity, which is used as the input for the next flat NER layer.", "labels": [], "entities": []}, {"text": "Our model stops detecting entities if no entities are predicted by the current flat NER layer.", "labels": [], "entities": []}, {"text": "Through stacking flat NER layers in order, we are able to extract entities from inside to outside with sharing parameters among the different LSTM layers and CRF layers.", "labels": [], "entities": []}, {"text": "We gain 3.9 and 9.1 percentage point improvements regarding F-score over the state-of-the-art feature-based model on two nested entity corpora: GENIA () and ACE2005 (), and analyze contributions of inner entities to outer entity detection, drawing several key conclusions.", "labels": [], "entities": [{"text": "F-score", "start_pos": 60, "end_pos": 67, "type": "METRIC", "confidence": 0.9989286065101624}, {"text": "GENIA", "start_pos": 144, "end_pos": 149, "type": "DATASET", "confidence": 0.9215661883354187}, {"text": "ACE2005", "start_pos": 157, "end_pos": 164, "type": "DATASET", "confidence": 0.8647043704986572}, {"text": "outer entity detection", "start_pos": 216, "end_pos": 238, "type": "TASK", "confidence": 0.651512086391449}]}, {"text": "In addition, experiments are conducted on a flatly annotated corpora JNLPBA ().", "labels": [], "entities": [{"text": "JNLPBA", "start_pos": 69, "end_pos": 75, "type": "DATASET", "confidence": 0.9017112255096436}]}, {"text": "Our model can be a complete NER model as well for flat entities, on the condition that it is trained on annotations that do not account for nested entities.", "labels": [], "entities": []}, {"text": "We obtain 75.55% in terms of Fscore that is comparable to the state-of-the-art performance.", "labels": [], "entities": [{"text": "Fscore", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.9949793219566345}]}], "datasetContent": [{"text": "We employed three datasets for evaluation: GE-NIA 3), ACE2005 4 () and JNLPBA).", "labels": [], "entities": [{"text": "GE-NIA", "start_pos": 43, "end_pos": 49, "type": "DATASET", "confidence": 0.8396379947662354}, {"text": "JNLPBA", "start_pos": 71, "end_pos": 77, "type": "DATASET", "confidence": 0.8096370100975037}]}, {"text": "We briefly explain the data and task settings and then introduce model and experimental settings.", "labels": [], "entities": []}, {"text": "Our model was implemented with Chainer).", "labels": [], "entities": []}, {"text": "We initialized word embeddings in GENIA and JNLPBA with the pretrained embeddings trained on MEDLINE abstracts ().", "labels": [], "entities": [{"text": "GENIA", "start_pos": 34, "end_pos": 39, "type": "DATASET", "confidence": 0.9631041288375854}, {"text": "JNLPBA", "start_pos": 44, "end_pos": 50, "type": "DATASET", "confidence": 0.8983147740364075}, {"text": "MEDLINE abstracts", "start_pos": 93, "end_pos": 110, "type": "DATASET", "confidence": 0.8680864870548248}]}, {"text": "For ACE2005, we initialized each word with the pretrained embeddings which are trained by.", "labels": [], "entities": [{"text": "ACE2005", "start_pos": 4, "end_pos": 11, "type": "DATASET", "confidence": 0.931747317314148}]}, {"text": "Except for the word embeddings, parameters of word embeddings were initialized with a normal distribution.", "labels": [], "entities": []}, {"text": "For LSTM, we initialized hidden states, cell state and all the bias terms as 0 except for the forget gate bias that was set as 1.", "labels": [], "entities": []}, {"text": "For other hyper-parameters, we chose the best hyper-parameters via Bayesian optimization.", "labels": [], "entities": []}, {"text": "We refer the readers to the supplemental material for the settings of the hyperparameters of the models and Bayesian optimization.", "labels": [], "entities": []}, {"text": "For ablation tests, we compared with our layered-BiLSTM-CRF model with two models that produce the input for next flat NER layer in different ways.", "labels": [], "entities": []}, {"text": "The first model is called layeredBiLSTM-CRF w/o layered out-of-entities which uses the input of the current flat NER layer for out-of-entity words.", "labels": [], "entities": []}, {"text": "We name the second model as layered-BiLSTM-CRF w/o layered LSTM as it skips all intermediate LSTM layers and only uses output of embedding layer to build the input for the next flat NER layer.", "labels": [], "entities": []}, {"text": "Please refer to supplemental material for the introduced two models.", "labels": [], "entities": []}, {"text": "To investigate the effectiveness of our model on different nested levels of entities, we evaluated the model performance on each flat NER layer on GE-NIA and ACE2005 test datasets.", "labels": [], "entities": [{"text": "GE-NIA", "start_pos": 147, "end_pos": 153, "type": "DATASET", "confidence": 0.9751527309417725}, {"text": "ACE2005 test datasets", "start_pos": 158, "end_pos": 179, "type": "DATASET", "confidence": 0.8946799635887146}]}, {"text": "8 When calculating precision and recall measurements, we collected the predictions and gold entities from the corresponding flat NER layer.", "labels": [], "entities": [{"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9985626339912415}, {"text": "recall", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.9975488781929016}]}, {"text": "Since predicted entities on a specific flat NER layer might be from other flat NER layers, we defined extended precision (EP), extended recall (ER) and extended Fscore (EF) to measure the performance.", "labels": [], "entities": [{"text": "extended precision (EP)", "start_pos": 102, "end_pos": 125, "type": "METRIC", "confidence": 0.8484197378158569}, {"text": "recall (ER)", "start_pos": 136, "end_pos": 147, "type": "METRIC", "confidence": 0.9586935192346573}, {"text": "extended Fscore (EF)", "start_pos": 152, "end_pos": 172, "type": "METRIC", "confidence": 0.8706532835960388}]}, {"text": "We calculated EP by comparing the predicted entities in a specific flat NER layer with all the gold entities, and ER by comparing the gold entities in a specific flat NER layer with all the predicted entities.", "labels": [], "entities": [{"text": "EP", "start_pos": 14, "end_pos": 16, "type": "METRIC", "confidence": 0.9391187429428101}, {"text": "ER", "start_pos": 114, "end_pos": 116, "type": "METRIC", "confidence": 0.9949593544006348}]}, {"text": "EF was calculated in the same way with F.", "labels": [], "entities": [{"text": "EF", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.9709022641181946}]}, {"text": "In addition to experiments on nested GENIA and ACE2005 datasets, flat entity recognition was conducted on the JNLPBA dataset.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 37, "end_pos": 42, "type": "DATASET", "confidence": 0.9314640760421753}, {"text": "ACE2005 datasets", "start_pos": 47, "end_pos": 63, "type": "DATASET", "confidence": 0.8860927522182465}, {"text": "flat entity recognition", "start_pos": 65, "end_pos": 88, "type": "TASK", "confidence": 0.6199282010396322}, {"text": "JNLPBA dataset", "start_pos": 110, "end_pos": 124, "type": "DATASET", "confidence": 0.9820123016834259}]}, {"text": "We trained our flat model that only kept the first flat NER layer and removed the following stacking layers.", "labels": [], "entities": []}, {"text": "We follow the hyper-parameters settings by for this evaluation.", "labels": [], "entities": []}, {"text": "We examined the contributions of predicted labels of the current flat NER layer to the next flat NER layer.", "labels": [], "entities": []}, {"text": "For this, we introduced label embeddings into each test by combining the embedding with context representation.", "labels": [], "entities": []}, {"text": "Experiments show that appending label embedding hurts the performance of our model while gain slight improvements in the rest 2 models on development datasets.", "labels": [], "entities": []}, {"text": "We removed entities which were predicted in previous flat NER layers during evaluation.", "labels": [], "entities": []}, {"text": "presents the comparisons of our model with related work including the state-of-the-art feature-based model by.", "labels": [], "entities": []}, {"text": "Our model outperforms the state-of-the-art models with 74.7% and 72.2% in terms of F-score, achieving the new state-of-the-art in the nested NER tasks.", "labels": [], "entities": [{"text": "F-score", "start_pos": 83, "end_pos": 90, "type": "METRIC", "confidence": 0.9985053539276123}]}, {"text": "For GENIA, our model gained more improvement in terms of recall with enabling extract more nested entities without reducing precision.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 4, "end_pos": 9, "type": "DATASET", "confidence": 0.8612562417984009}, {"text": "recall", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.9993703961372375}, {"text": "precision", "start_pos": 124, "end_pos": 133, "type": "METRIC", "confidence": 0.997018575668335}]}, {"text": "On ACE2005, we improved recall with 12.2 percentage points and obtained 5.1% relative error reductions.", "labels": [], "entities": [{"text": "ACE2005", "start_pos": 3, "end_pos": 10, "type": "DATASET", "confidence": 0.8854857087135315}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9997362494468689}, {"text": "relative error reductions", "start_pos": 77, "end_pos": 102, "type": "METRIC", "confidence": 0.8393623431523641}]}, {"text": "Compared with GENIA, our model gained more improvements in ACE2005 in terms of F-score.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 14, "end_pos": 19, "type": "DATASET", "confidence": 0.9361146092414856}, {"text": "ACE2005", "start_pos": 59, "end_pos": 66, "type": "DATASET", "confidence": 0.6021090745925903}, {"text": "F-score", "start_pos": 79, "end_pos": 86, "type": "METRIC", "confidence": 0.996880292892456}]}, {"text": "Two possible reasons account for it.", "labels": [], "entities": []}, {"text": "One reason is that ACE2005 contains more deeper nested entities (maximum nested level is 5) than GENIA (maximum nested level is 3) on the test dataset.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 97, "end_pos": 102, "type": "DATASET", "confidence": 0.757419764995575}]}, {"text": "This allows our model to capture the potentially 'nested' relations among nested entities.", "labels": [], "entities": []}, {"text": "The other reason is that ACE2005 has more nested entities (37.45%) compared with GENIA (21.56%).", "labels": [], "entities": [{"text": "ACE2005", "start_pos": 25, "end_pos": 32, "type": "DATASET", "confidence": 0.8547724485397339}, {"text": "GENIA", "start_pos": 81, "end_pos": 86, "type": "DATASET", "confidence": 0.8992631435394287}]}, {"text": "shows the results of models on the development datasets of GENIA and ACE2005, respectively.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 59, "end_pos": 64, "type": "DATASET", "confidence": 0.9345920085906982}, {"text": "ACE2005", "start_pos": 69, "end_pos": 76, "type": "DATASET", "confidence": 0.8884490728378296}]}, {"text": "From this table, we can see that our model, which only utilizes context representation for preparation of input for the next flat NER layer, performs better than the rest two models.", "labels": [], "entities": []}, {"text": "This demonstrates that introducing input of the current flat NER layer such as skipping either representation for any non-entity or words or all intermediate LSTM layers hurts performance.", "labels": [], "entities": []}, {"text": "Compared with the layered-BiLSTM-CRF model, the drop of the performance in the layered-BiLSTM-CRF w/o layered out-of-entities model reflects the skip of representation for out-of-entity words leads to the decline in performance.", "labels": [], "entities": []}, {"text": "This is because the representation of non-entity words didn't incorporate the current context representation as we used the input rather than the output to represent them.", "labels": [], "entities": []}, {"text": "By analogy, the layered BiLSTM-CRF w/o layer LSTM model skips representation for both entities and non-entity words, resulting in worse performance.", "labels": [], "entities": []}, {"text": "This is because, when skipping all intermediate LSTM layers, input of the first flat NER layer, i.e., word embeddings, is passed to the remaining flat NER layers.", "labels": [], "entities": []}, {"text": "Since word embeddings do not contain context representation, we fail to incorporate the context representation when we use Settings GENIA ACE2005 P (%) R (%) F (%) P (%) R (%) F (%) Finkel and Manning     the word embeddings as the input for the flat NER layers.", "labels": [], "entities": [{"text": "GENIA ACE2005", "start_pos": 132, "end_pos": 145, "type": "DATASET", "confidence": 0.7767576575279236}]}, {"text": "Therefore, we have no chance to take advantage of the context representation and instead we only manage to use the word embeddings as the input for flat NER layers in this case.", "labels": [], "entities": []}, {"text": "describe the performance for each entity type in GENIA and ACE2005 test datasets, respectively.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 49, "end_pos": 54, "type": "DATASET", "confidence": 0.9621815085411072}, {"text": "ACE2005 test datasets", "start_pos": 59, "end_pos": 80, "type": "DATASET", "confidence": 0.9378793636957804}]}, {"text": "In GENIA, our model performed best in recognizing entities with type RNA.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 3, "end_pos": 8, "type": "DATASET", "confidence": 0.8697040677070618}]}, {"text": "This is because most of the entities pertaining to RNA mainly end up either with \"mRNA\" or RNA.", "labels": [], "entities": []}, {"text": "These two words are informative indicators of RNA entities.", "labels": [], "entities": []}, {"text": "For entities in rest entity types, their performances are close to the overall performance.", "labels": [], "entities": []}, {"text": "One possible reason is that there are many instances to model them.", "labels": [], "entities": []}, {"text": "This also accounts for the high performances of entity types such as PER, GPE in ACE2005.", "labels": [], "entities": [{"text": "PER", "start_pos": 69, "end_pos": 72, "type": "METRIC", "confidence": 0.9269459843635559}, {"text": "GPE", "start_pos": 74, "end_pos": 77, "type": "METRIC", "confidence": 0.950667142868042}, {"text": "ACE2005", "start_pos": 81, "end_pos": 88, "type": "DATASET", "confidence": 0.9499928951263428}]}, {"text": "The small amounts of instances of entity types like FAC in ACE2005 is one reason for their under overall performances.", "labels": [], "entities": [{"text": "ACE2005", "start_pos": 59, "end_pos": 66, "type": "DATASET", "confidence": 0.5104479789733887}]}, {"text": "We refer readers to supplemental material for statistics details.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparisons of our model with the state-of-the-art models on nested NER.", "labels": [], "entities": []}, {"text": " Table 2: Performances of ablation tests on development datasets.", "labels": [], "entities": []}, {"text": " Table 3: Results of all entities for each type in GENIA  test dataset.", "labels": [], "entities": [{"text": "GENIA  test dataset", "start_pos": 51, "end_pos": 70, "type": "DATASET", "confidence": 0.9627637465794882}]}, {"text": " Table 4: Results of all entities for each type in  ACE2005 test dataset.", "labels": [], "entities": [{"text": "ACE2005 test dataset", "start_pos": 52, "end_pos": 72, "type": "DATASET", "confidence": 0.964276929696401}]}, {"text": " Table 5: Results of layer evaluation on GENIA test dataset.", "labels": [], "entities": [{"text": "GENIA test dataset", "start_pos": 41, "end_pos": 59, "type": "DATASET", "confidence": 0.9701863129933676}]}, {"text": " Table 6: Results of layer evaluation on ACE2005 test dataset.", "labels": [], "entities": [{"text": "ACE2005 test dataset", "start_pos": 41, "end_pos": 61, "type": "DATASET", "confidence": 0.9763715863227844}]}, {"text": " Table 7: Statistics of GENIA.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 24, "end_pos": 29, "type": "DATASET", "confidence": 0.8791974782943726}]}, {"text": " Table 8: Statistics of ACE2005.", "labels": [], "entities": [{"text": "ACE2005", "start_pos": 24, "end_pos": 31, "type": "DATASET", "confidence": 0.5201693177223206}]}, {"text": " Table 9: Statistics of JNLPBA.", "labels": [], "entities": [{"text": "JNLPBA", "start_pos": 24, "end_pos": 30, "type": "DATASET", "confidence": 0.7901015877723694}]}, {"text": " Table 10: Value range and best value of tuned hyper  parameters in GENIA.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 68, "end_pos": 73, "type": "DATASET", "confidence": 0.945701539516449}]}, {"text": " Table 11: Value range and best value of tuned hyper  parameters in ACE2005.", "labels": [], "entities": [{"text": "ACE2005", "start_pos": 68, "end_pos": 75, "type": "DATASET", "confidence": 0.9580370783805847}]}, {"text": " Table 12: Hyper parameters used of Bayesian Opti- mization.", "labels": [], "entities": [{"text": "Bayesian Opti- mization", "start_pos": 36, "end_pos": 59, "type": "TASK", "confidence": 0.47625668346881866}]}]}