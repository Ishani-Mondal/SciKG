{"title": [{"text": "Multi-Reward Reinforced Summarization with Saliency and Entailment", "labels": [], "entities": [{"text": "Multi-Reward Reinforced Summarization", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.403754860162735}]}], "abstractContent": [{"text": "ive text summarization is the task of compressing and rewriting along document into a short summary while maintaining saliency, directed logical entailment, and non-redundancy.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.6276135742664337}]}, {"text": "In this work, we address these three important aspects of a good summary via a reinforcement learning approach with two novel reward functions: ROUGE-Sal and Entail, on top of a coverage-based baseline.", "labels": [], "entities": [{"text": "ROUGE-Sal", "start_pos": 144, "end_pos": 153, "type": "METRIC", "confidence": 0.9967472553253174}]}, {"text": "The ROUGESal reward modifies the ROUGE metric by up-weighting the salient phrases/words detected via a keyphrase clas-sifier.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 33, "end_pos": 38, "type": "METRIC", "confidence": 0.968761682510376}]}, {"text": "The Entail reward gives high (length-normalized) scores to logically-entailed summaries using an entailment classifier.", "labels": [], "entities": []}, {"text": "Further, we show superior performance improvement when these rewards are combined with traditional metric (ROUGE) based rewards, via our novel and effective multi-reward approach of optimizing multiple rewards simultaneously in alternate mini-batches.", "labels": [], "entities": []}, {"text": "Our method achieves the new state-of-the-art results on CNN/Daily Mail dataset as well as strong improvements in a test-only transfer setup on DUC-2002.", "labels": [], "entities": [{"text": "CNN/Daily Mail dataset", "start_pos": 56, "end_pos": 78, "type": "DATASET", "confidence": 0.9285210967063904}, {"text": "DUC-2002", "start_pos": 143, "end_pos": 151, "type": "DATASET", "confidence": 0.9796673059463501}]}], "introductionContent": [{"text": "Abstractive summarization, the task of generating a natural short summary of along document, is more challenging than the extractive paradigm, which only involves selection of important sentences or grammatical sub-sentences).", "labels": [], "entities": [{"text": "Abstractive summarization", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6673158705234528}]}, {"text": "Advent of sequence-to-sequence deep neural networks and large human summarization datasets () made the abstractive summarization task more feasible and accurate, with recent ideas ranging from copypointer mechanism and redundancy coverage, to metric reward based reinforcement learning.", "labels": [], "entities": []}, {"text": "A good abstractive summary requires several important properties, e.g., it should choose the most salient information from the input document, be logically entailed by it, and avoid redundancy.", "labels": [], "entities": []}, {"text": "Coverage-based models address the latter redundancy issue), but there is still a lot of scope to teach current state-of-the-art models about saliency and logical entailment.", "labels": [], "entities": []}, {"text": "Towards this goal, we improve the task of abstractive summarization via a reinforcement learning approach with the introduction of two novel rewards: 'ROUGESal' and 'Entail', and also demonstrate that these saliency and entailment skills allow for better generalizability and transfer.", "labels": [], "entities": [{"text": "abstractive summarization", "start_pos": 42, "end_pos": 67, "type": "TASK", "confidence": 0.4861512631177902}, {"text": "ROUGESal", "start_pos": 151, "end_pos": 159, "type": "METRIC", "confidence": 0.9946128129959106}]}, {"text": "Our ROUGESal reward gives higher weight to the important, salient words in the summary, in contrast to the traditional ROUGE metric which gives equal weight to all tokens.", "labels": [], "entities": [{"text": "ROUGE metric", "start_pos": 119, "end_pos": 131, "type": "METRIC", "confidence": 0.9047617316246033}]}, {"text": "These weights are obtained from a novel saliency scorer, which is trained on a reading comprehension dataset's answer spans to give a saliency-based probability score to every token in the sentence.", "labels": [], "entities": []}, {"text": "Our Entail reward gives higher weight to summaries whose sentences logically follow from the ground-truth summary.", "labels": [], "entities": []}, {"text": "Further, we also add a length normalization constraint to our Entail reward, to importantly avoid misleadingly high entailment scores to very short sentences.", "labels": [], "entities": [{"text": "Entail reward", "start_pos": 62, "end_pos": 75, "type": "DATASET", "confidence": 0.6107465922832489}]}, {"text": "Empirically, we show that our new rewards with policy gradient approaches perform significantly better than a cross-entropy based state-of-the-art pointer-coverage baseline.", "labels": [], "entities": []}, {"text": "We show further performance improvements by combining these rewards via our novel multi-reward optimization approach, where we optimize multiple rewards simultaneously in alternate mini-batches (hence avoiding complex scaling and weighting issues in reward combination), inspired from how humans take multiple concurrent types of rewards (feedback) to learn a task.", "labels": [], "entities": []}, {"text": "Overall, our methods achieve the new state-of-the-art on the CNN/Daily Mail dataset as well as strong improvements in a testonly transfer setup on DUC-2002.", "labels": [], "entities": [{"text": "CNN/Daily Mail dataset", "start_pos": 61, "end_pos": 83, "type": "DATASET", "confidence": 0.9367993354797364}, {"text": "DUC-2002", "start_pos": 147, "end_pos": 155, "type": "DATASET", "confidence": 0.9807661771774292}]}, {"text": "Lastly, we present several analyses of our model's saliency, entailment, and abstractiveness skills.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the standard ROUGE package", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 20, "end_pos": 25, "type": "METRIC", "confidence": 0.8891843557357788}]}], "tableCaptions": [{"text": " Table 1:  Results on CNN/Daily Mail (non- anonymous). represents previous work on anony- mous version. 'XE': cross-entropy loss, 'RL': reinforce  mixed loss (XE+RL). Columns 'R': ROUGE, 'M':  METEOR.", "labels": [], "entities": [{"text": "CNN/Daily Mail", "start_pos": 22, "end_pos": 36, "type": "DATASET", "confidence": 0.8538721948862076}, {"text": "ROUGE", "start_pos": 180, "end_pos": 185, "type": "METRIC", "confidence": 0.9836044907569885}, {"text": "METEOR", "start_pos": 193, "end_pos": 199, "type": "METRIC", "confidence": 0.980064332485199}]}, {"text": " Table 2: ROUGE F1 full length scores of our models  on test-only DUC-2002 generalizability setup.", "labels": [], "entities": [{"text": "ROUGE F1 full length scores", "start_pos": 10, "end_pos": 37, "type": "METRIC", "confidence": 0.8486362218856811}]}, {"text": " Table 3: Abstractiveness: novel n-gram percentage.", "labels": [], "entities": [{"text": "Abstractiveness", "start_pos": 10, "end_pos": 25, "type": "METRIC", "confidence": 0.9917123317718506}]}]}