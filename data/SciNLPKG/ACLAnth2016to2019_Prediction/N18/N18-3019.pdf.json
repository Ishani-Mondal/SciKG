{"title": [{"text": "Bag of Experts Architectures for Model Reuse in Conversational Language Understanding", "labels": [], "entities": [{"text": "Model Reuse in Conversational Language Understanding", "start_pos": 33, "end_pos": 85, "type": "TASK", "confidence": 0.6735240171353022}]}], "abstractContent": [{"text": "Slot tagging, the task of detecting entities in input user utterances, is a key component of natural language understanding systems for personal digital assistants.", "labels": [], "entities": [{"text": "Slot tagging", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.8811420798301697}, {"text": "natural language understanding", "start_pos": 93, "end_pos": 123, "type": "TASK", "confidence": 0.6825262506802877}]}, {"text": "Since each new domain requires a different set of slots, the annotation costs for labeling data for training slot tagging models increases rapidly as the number of domains grow.", "labels": [], "entities": [{"text": "training slot tagging", "start_pos": 100, "end_pos": 121, "type": "TASK", "confidence": 0.6970392465591431}]}, {"text": "To tackle this, we describe Bag of Experts (BoE) architec-tures for model reuse for both LSTM and CRF based models.", "labels": [], "entities": []}, {"text": "Extensive experimentation over a dataset of 10 domains drawn from data relevant to our commercial personal digital assistant shows that our BoE models outperform the baseline models with a statistically significant average margin of 5.06% in absolute F1-score when training with 2000 instances per domain, and achieve an even higher improvement of 12.16% when only 25% of the training data is used.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 251, "end_pos": 259, "type": "METRIC", "confidence": 0.9521236419677734}]}], "introductionContent": [{"text": "Natural language understanding (NLU) is a key component of dialog systems for commercial personal digital assistants (PDAs) such as Amazon Alexa, Google Home, Microsoft Cortana and Apple Siri.", "labels": [], "entities": [{"text": "Natural language understanding (NLU)", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.7421435465415319}]}, {"text": "The task of the NLU component is to map input user utterances into a semantic frame consisting of domain, intent and slots (.", "labels": [], "entities": []}, {"text": "The semantic frame is used by the dialog manager for state tracking and action selection.", "labels": [], "entities": [{"text": "state tracking", "start_pos": 53, "end_pos": 67, "type": "TASK", "confidence": 0.7258186638355255}, {"text": "action selection", "start_pos": 72, "end_pos": 88, "type": "TASK", "confidence": 0.710878998041153}]}, {"text": "Slot tagging can be formulated as a sequence classification task where each input word in the user utterance must be classified as belonging to one of the slot types in a predefined schema (.", "labels": [], "entities": [{"text": "Slot tagging", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.9558781683444977}, {"text": "sequence classification", "start_pos": 36, "end_pos": 59, "type": "TASK", "confidence": 0.7473899126052856}]}, {"text": "Ina standard NLU architecture, each new domain defines anew domainspecific schema for its slots.", "labels": [], "entities": []}, {"text": "shows examples of annotated queries from three different domains relevant to atypical commercial digital assistant.", "labels": [], "entities": []}, {"text": "Since the schemas for different domains can vary, the usual strategy is to train a separate slot tagging model for each new domain.", "labels": [], "entities": [{"text": "slot tagging", "start_pos": 92, "end_pos": 104, "type": "TASK", "confidence": 0.7066656351089478}]}, {"text": "However, the number of domains increases rapidly as the PDAs are required to support new scenarios and training a separate slot tagging model for each new domain becomes prohibitively expensive in terms of annotation costs.", "labels": [], "entities": [{"text": "slot tagging", "start_pos": 123, "end_pos": 135, "type": "TASK", "confidence": 0.704331248998642}]}, {"text": "Even though different domains have different slot tagging schemas, some classes of slots appear across a number of domains, as suggested by the examples in.", "labels": [], "entities": [{"text": "slot tagging", "start_pos": 45, "end_pos": 57, "type": "TASK", "confidence": 0.7089642435312271}]}, {"text": "Both travel and flight status have date and time related slots, and all three domains have the location slot.", "labels": [], "entities": []}, {"text": "Reusing annotated data for these common slots would allow us to train models with better accuracy using less data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.9975461363792419}]}, {"text": "However, since both the input distribution and the label distribution are different across domains, we must use domain adaptation methods to train on the joint data  2016c;).", "labels": [], "entities": []}], "datasetContent": [{"text": "We want to verify if BoE models can improve slot tagging performance by using the information from reusable domains.", "labels": [], "entities": [{"text": "slot tagging", "start_pos": 44, "end_pos": 56, "type": "TASK", "confidence": 0.8855224251747131}]}, {"text": "To simulate the low data scenario for the initial model training, we create three training datasets by sampling 2000, 1000 and 500 training examples from every domain.", "labels": [], "entities": []}, {"text": "We use stratified sampling to maintain the input distribution of the intents across the three training datasets.", "labels": [], "entities": []}, {"text": "For each training dataset, we train the four models as described in Section 2 and compute the precision, recall and F1-score on the test data.", "labels": [], "entities": [{"text": "precision", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.9997691512107849}, {"text": "recall", "start_pos": 105, "end_pos": 111, "type": "METRIC", "confidence": 0.9981322884559631}, {"text": "F1-score", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9990963935852051}]}, {"text": "Fixed seeds are used when training all models to make the results reproducible.", "labels": [], "entities": []}, {"text": "summarizes these results, with only F1-scores reported to save space.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9989392161369324}]}, {"text": "We describe these results in Section 4.3.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: List of target domains used for our experiments, along with some statistics and example ut- terances. The test and development data sets are sampled at 10% of the total annotated data. \"Flight  Stat.\" stands for \"Flight Status\", \"Soc. Net.\" stands for \"Social Network\", and \"Transport.\" stands for  \"Transportation\".", "labels": [], "entities": []}, {"text": " Table 2: Average absolute F1-score improvement  on the dev data for different LSTM variations.  *   indicates the improvement is statistically signifi- cant with p-value < 0.05.", "labels": [], "entities": [{"text": "F1-score improvement", "start_pos": 27, "end_pos": 47, "type": "METRIC", "confidence": 0.9585840404033661}]}, {"text": " Table 3: F1-scores obtained by each of the four models for the 10 domains, with the highest score in each  row marked as bold. Table (a) reports the results for 2000 training instances, and Table (b) reports the  results for 500 and 1000 training instances. The average improvement is computed over the CRF model,  with the ones marked  *  being statistically significant with p-value < 0.05. The average improvement  of LSTM-BoE over LSTM is +1.92  *  , +1.70 and +4.63  *  for 2000, 1000, and 500 training instances  respectively.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9979222416877747}]}, {"text": " Table 4: Percentange of queries with timex and lo- cation slots in each of our target domains.", "labels": [], "entities": [{"text": "timex", "start_pos": 38, "end_pos": 43, "type": "METRIC", "confidence": 0.9599435925483704}]}]}