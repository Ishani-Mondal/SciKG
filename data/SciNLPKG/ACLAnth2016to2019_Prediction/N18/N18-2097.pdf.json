{"title": [{"text": "A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents", "labels": [], "entities": [{"text": "Abstractive Summarization of Long Documents", "start_pos": 38, "end_pos": 81, "type": "TASK", "confidence": 0.7978654980659485}]}], "abstractContent": [{"text": "Neural abstractive summarization models have led to promising results in summarizing relatively short documents.", "labels": [], "entities": [{"text": "Neural abstractive summarization", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6074650784333547}, {"text": "summarizing relatively short documents", "start_pos": 73, "end_pos": 111, "type": "TASK", "confidence": 0.8400207757949829}]}, {"text": "We propose the first model for abstractive summarization of single, longer-form documents (e.g., research papers).", "labels": [], "entities": [{"text": "abstractive summarization of single, longer-form documents (e.g., research papers)", "start_pos": 31, "end_pos": 113, "type": "TASK", "confidence": 0.8418242839666513}]}, {"text": "Our approach consists of anew hierarchical encoder that models the discourse structure of a document, and an attentive discourse-aware decoder to generate the summary.", "labels": [], "entities": []}, {"text": "Empirical results on two large-scale datasets of scientific papers show that our model significantly out-performs state-of-the-art models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Existing large-scale summarization datasets consist of relatively short documents.", "labels": [], "entities": []}, {"text": "For example, articles in the CNN/Daily Mail dataset) are on average about 600 words long.", "labels": [], "entities": [{"text": "CNN/Daily Mail dataset", "start_pos": 29, "end_pos": 51, "type": "DATASET", "confidence": 0.9030507326126098}]}, {"text": "Similarly, existing neural summarization models have focused on summarizing sentences and short documents.", "labels": [], "entities": [{"text": "summarizing sentences and short documents", "start_pos": 64, "end_pos": 105, "type": "TASK", "confidence": 0.8712761402130127}]}, {"text": "In this work, we propose a model for effective abstractive summarization of longer documents.", "labels": [], "entities": [{"text": "abstractive summarization of longer documents", "start_pos": 47, "end_pos": 92, "type": "TASK", "confidence": 0.7854527235031128}]}, {"text": "Scientific papers are an example of documents that are significantly longer than news articles (see).", "labels": [], "entities": []}, {"text": "They also follow a standard discourse structure describing the problem, methodology, experiments/results, and finally conclusions.", "labels": [], "entities": []}, {"text": "Most summarization works in the literature focus on extractive summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 5, "end_pos": 18, "type": "TASK", "confidence": 0.9780364632606506}]}, {"text": "Examples of prominent approaches include frequency-based methods (, graph-based methods (), topic modeling (, and neural models (.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 92, "end_pos": 106, "type": "TASK", "confidence": 0.820625513792038}]}, {"text": "Abstractive summarization is an alternative approach where the generated summary may contain novel words and phrases and is more similar to how humans summarize documents.", "labels": [], "entities": [{"text": "Abstractive summarization", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.5862859487533569}]}, {"text": "Recently, neural methods have led to encouraging results in abstractive summarization (.", "labels": [], "entities": [{"text": "abstractive summarization", "start_pos": 60, "end_pos": 85, "type": "TASK", "confidence": 0.6205431222915649}]}, {"text": "These approaches employ a general framework of sequence-to-sequence (seq2seq) models) where the document is fed to an encoder network and another (recurrent) network learns to decode the summary.", "labels": [], "entities": []}, {"text": "While promising, these methods focus on summarizing news articles which are relatively short.", "labels": [], "entities": [{"text": "summarizing news articles", "start_pos": 40, "end_pos": 65, "type": "TASK", "confidence": 0.93291042248408}]}, {"text": "Many other document types, however, are longer and structured.", "labels": [], "entities": []}, {"text": "Seq2seq models tend to struggle with longer sequences because at each decoding step, the decoder needs to learn to construct a context vector capturing relevant information from all the tokens in the source sequence (.", "labels": [], "entities": []}, {"text": "Our main contribution is an abstractive model for summarizing scientific papers which are an example of long-form structured document types.", "labels": [], "entities": [{"text": "summarizing scientific papers", "start_pos": 50, "end_pos": 79, "type": "TASK", "confidence": 0.9148223201433817}]}, {"text": "Our model includes a hierarchical encoder, capturing the discourse structure of the document and a discourse-aware decoder that generates the summary.", "labels": [], "entities": []}, {"text": "Our decoder attends to different discourse sections and allows the model to more accurately represent important information from the source resulting in a better context vector.", "labels": [], "entities": []}, {"text": "We also introduce two large-scale datasets of long and structured scientific papers obtained from arXiv and PubMed to support both training and evaluating models on the task of long document summarization.", "labels": [], "entities": [{"text": "arXiv", "start_pos": 98, "end_pos": 103, "type": "DATASET", "confidence": 0.7864888310432434}, {"text": "long document summarization", "start_pos": 177, "end_pos": 204, "type": "TASK", "confidence": 0.6057324012120565}]}, {"text": "Evaluation results show that our method outperforms state-of-the-art summarization models 1 .", "labels": [], "entities": []}], "datasetContent": [{"text": "Setup Similar to the majority of published research in the summarization literature (, evaluation was done using the ROUGE automatic summarization evaluation metric) with full-length F-1 ROUGE scores.", "labels": [], "entities": [{"text": "summarization", "start_pos": 59, "end_pos": 72, "type": "TASK", "confidence": 0.9829177260398865}, {"text": "F-1 ROUGE scores", "start_pos": 183, "end_pos": 199, "type": "METRIC", "confidence": 0.8608584801355997}]}, {"text": "We lowercase all tokens and perform sentence and word tokenization using spaCy.", "labels": [], "entities": []}, {"text": "Implementation details We use Tensorflow 1.4 for implementing our models.", "labels": [], "entities": []}, {"text": "We use the hyperparameters suggested by.", "labels": [], "entities": []}, {"text": "In particular, we use two bidirectional LSTMs with cell size of 256 and embedding dimensions of 128.", "labels": [], "entities": []}, {"text": "Embeddings are trained from scratch and we did not find any gain using pre-trained embeddings.", "labels": [], "entities": []}, {"text": "The vocabulary size is constrained to 50,000; using larger vocabulary size did not result in any improvement.", "labels": [], "entities": []}, {"text": "We use mini-batches of size 16 and we limit the document length to 2000 and section length to 500 tokens, and number of sections to 4.", "labels": [], "entities": []}, {"text": "We use batch-padding and dynamic unrolling to handle variable sequence lengths in LSTMs.", "labels": [], "entities": []}, {"text": "Training was done using Adagrad optimizer with learning rate 0.15 and an initial accumulator value of 0.1.", "labels": [], "entities": [{"text": "learning rate 0.15", "start_pos": 47, "end_pos": 65, "type": "METRIC", "confidence": 0.9512670040130615}, {"text": "accumulator", "start_pos": 81, "end_pos": 92, "type": "METRIC", "confidence": 0.9212431311607361}]}, {"text": "The maximum decoder size was 210 tokens which is inline with average abstract length in our datasets.", "labels": [], "entities": []}, {"text": "We first train the model without coverage and added it at the last two epochs to help the model converge faster.", "labels": [], "entities": []}, {"text": "We train the models on NVIDIA Titan X Pascal GPUs.), Attn-Seq2Seq (, Pntr-Gen-Seq2Seq (.", "labels": [], "entities": [{"text": "Attn-Seq2Seq", "start_pos": 53, "end_pos": 65, "type": "METRIC", "confidence": 0.6711435914039612}]}, {"text": "The first three are extractive models and last two are abstractive.", "labels": [], "entities": []}, {"text": "Pntr-GenSeq2Seq extends Attn-Seq2Seq by using a joint pointer network during decoding.", "labels": [], "entities": []}, {"text": "For Pntr-GenSeq2Seq we use their reported hyperparameters to ensure that the result differences are not due to hyperparameter tuning.", "labels": [], "entities": []}, {"text": "Results Our main results are shown in.", "labels": [], "entities": []}, {"text": "Our model significantly outperforms the state-of-the-art abstractive methods, showing its effectiveness on both datasets.", "labels": [], "entities": []}, {"text": "We observe that in our ROUGE-1 score is respectively about 4 and 3 points higher than the abstractive model PntrGen-Seq2Seq for the arXiv and PubMed datasets, providing a significant improvement.", "labels": [], "entities": [{"text": "ROUGE-1 score", "start_pos": 23, "end_pos": 36, "type": "METRIC", "confidence": 0.9528684318065643}, {"text": "PubMed datasets", "start_pos": 142, "end_pos": 157, "type": "DATASET", "confidence": 0.9443005621433258}]}, {"text": "Our method also outperforms most of the extractive methods except for LexRank in one of the ROUGE scores.", "labels": [], "entities": [{"text": "LexRank", "start_pos": 70, "end_pos": 77, "type": "DATASET", "confidence": 0.8619834780693054}, {"text": "ROUGE", "start_pos": 92, "end_pos": 97, "type": "METRIC", "confidence": 0.9884828925132751}]}, {"text": "We note that since extractive methods copy salient sentences from the document, it is usually easier Our method: cascade hash tables area common data structure used in large set of data storage and retrieval . such a time variation is essentially caused by possibly many collisions during keys hashing . in this paper , we present a set of hash schemes called cascade hash tables which consist of several levels ( @xmath2 ) of hash tables with different size . after constant probes , if an item ca 'nt find a free slot in limited probes in any hash table , it will try to find a cell in the second level , or subsequent lower levels . with this simple strategy , these hash tables will have descendant load factors , therefore lower collision probabilities . Figure 2: Example of a generated summary for them to achieve higher ROUGE scores.", "labels": [], "entities": [{"text": "ROUGE scores", "start_pos": 828, "end_pos": 840, "type": "METRIC", "confidence": 0.963839054107666}]}, {"text": "illustrates the effectiveness of our model extensions in capturing various discourse information from the papers.", "labels": [], "entities": []}, {"text": "It can be observed that the state-of-the-art Pntr-Gen-Seq2Seq model generates a summary that mostly focuses on introducing the problem, whereas our model generates a summary that includes more information about the methodology and impacts of the target paper.", "labels": [], "entities": []}, {"text": "This indicates that the context vector in our model compared with Pntr-Gen-Seq2Seq is better able to capture important information from the source by attending to various discourse sections.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of our arXiv and PubMed datasets  compared with existing large-scale summarization cor- pora, CNN and Daily Mail (Nallapati et al., 2016) and  NY Times (Paulus et al., 2017).", "labels": [], "entities": [{"text": "PubMed datasets", "start_pos": 38, "end_pos": 53, "type": "DATASET", "confidence": 0.9189434051513672}, {"text": "NY Times", "start_pos": 164, "end_pos": 172, "type": "DATASET", "confidence": 0.9165566265583038}]}, {"text": " Table 2: Results on the arXiv dataset, RG: ROUGE. For our", "labels": [], "entities": [{"text": "arXiv dataset", "start_pos": 25, "end_pos": 38, "type": "DATASET", "confidence": 0.8009009063243866}, {"text": "RG", "start_pos": 40, "end_pos": 42, "type": "METRIC", "confidence": 0.8216217756271362}, {"text": "ROUGE", "start_pos": 44, "end_pos": 49, "type": "METRIC", "confidence": 0.8848510980606079}]}, {"text": " Table 3: Results on PubMed dataset, RG:ROUGE. For", "labels": [], "entities": [{"text": "PubMed dataset", "start_pos": 21, "end_pos": 35, "type": "DATASET", "confidence": 0.9702130556106567}, {"text": "ROUGE", "start_pos": 40, "end_pos": 45, "type": "METRIC", "confidence": 0.8014494776725769}]}]}