{"title": [], "abstractContent": [{"text": "In large-scale educational assessments, the use of automated scoring has recently become quite common.", "labels": [], "entities": []}, {"text": "While the majority of student responses can be processed and scored without difficulty, there area small number of responses that have atypical characteristics that make it difficult for an automated scoring system to assign a correct score.", "labels": [], "entities": []}, {"text": "We describe a pipeline that detects and processes these kinds of responses at run-time.", "labels": [], "entities": []}, {"text": "We present the most frequent kinds of what are called non-scorable responses along with effective filtering models based on various NLP and speech processing technologies.", "labels": [], "entities": []}, {"text": "We give an overview of two operational automated scoring systems-one for essay scoring and one for speech scoring-and describe the filtering models they use.", "labels": [], "entities": [{"text": "essay scoring", "start_pos": 73, "end_pos": 86, "type": "TASK", "confidence": 0.7596506774425507}, {"text": "speech scoring-and", "start_pos": 99, "end_pos": 117, "type": "TASK", "confidence": 0.7842007875442505}]}, {"text": "Finally , we present an evaluation and analysis of filtering models used for spoken responses in an assessment of language proficiency.", "labels": [], "entities": []}], "introductionContent": [{"text": "An automated scoring system can assess constructed responses such as essays to open-ended questions faster than human raters, often at lower cost, with the resulting scores being consistent overtime.", "labels": [], "entities": []}, {"text": "These advantages have prompted strong demand for high-performing automated scoring systems for various educational applications.", "labels": [], "entities": []}, {"text": "However, even state-of-the-art automated scoring systems face numerous challenges when used in a large-scale operational setting.", "labels": [], "entities": []}, {"text": "For instance, some responses have atypical characteristics that make it difficult for an automated scoring system to provide a valid score.", "labels": [], "entities": []}, {"text": "A spoken response, for example, with a lot of background noise may suffer from frequent errors in automated speech recognition (ASR), and the linguistic features generated from the erroneous ASR word hypotheses maybe inaccurate.", "labels": [], "entities": [{"text": "automated speech recognition (ASR)", "start_pos": 98, "end_pos": 132, "type": "TASK", "confidence": 0.8046940664450327}]}, {"text": "As a result, the automated score based on the inaccurate features may differ greatly from the score a human expert would assign.", "labels": [], "entities": []}, {"text": "Furthermore, it may substantially weaken the validity of the automated scoring system.", "labels": [], "entities": []}, {"text": "More recently, some studies have systematically evaluated the impact of atypical inputs, particularly gaming responses, on the validity of automated scoring of essays () and short-answers).", "labels": [], "entities": []}, {"text": "They showed that automated scoring systems tend to be more vulnerable than human raters to students trying to game the system.", "labels": [], "entities": []}, {"text": "Consistent with these findings, argued that the ability to detect abnormal performance is one of the most important requirements of a high-stakes automated scoring system.", "labels": [], "entities": []}, {"text": "However, despite its importance, and compared to the large body of work describing the empirical performance of automated scoring systems, there has been little discussion of how NLP tools and techniques can contribute to improving the detection of atypical inputs.", "labels": [], "entities": []}, {"text": "In this paper we present atypical processing pipeline for automated scoring of essay and spoken responses and describe the points in the process where handling of atypical inputs and system failures can occur.", "labels": [], "entities": [{"text": "automated scoring of essay and spoken responses", "start_pos": 58, "end_pos": 105, "type": "TASK", "confidence": 0.7200532640729632}]}, {"text": "In particular, we describe some of the NLP technologies used at each of these points and the role of NLP components as filters in an automated scoring pipeline.", "labels": [], "entities": []}, {"text": "We present a case study on building automated filters to detect problematic responses in an assessment of spoken English.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Frequency of different kinds of filters in high- stakes e-rater deployment with the average final score  assigned to the responses flagged by each filter.", "labels": [], "entities": []}, {"text": " Table 2: Performance of FMs in detecting non- scorable.", "labels": [], "entities": [{"text": "detecting non- scorable", "start_pos": 32, "end_pos": 55, "type": "TASK", "confidence": 0.8704173266887665}]}, {"text": " Table 3: Average human-machine score differences.", "labels": [], "entities": [{"text": "Average human-machine score differences", "start_pos": 10, "end_pos": 49, "type": "METRIC", "confidence": 0.7108506038784981}]}]}