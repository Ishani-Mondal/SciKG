{"title": [{"text": "Generating topic-oriented summaries using neural attention", "labels": [], "entities": [{"text": "Generating topic-oriented summaries", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.7781096895535787}]}], "abstractContent": [{"text": "Summarizing a document requires identifying the important parts of the document with an objective of providing a quick overview to a reader.", "labels": [], "entities": []}, {"text": "However, along article can span several topics and a single summary cannot do justice to all the topics.", "labels": [], "entities": []}, {"text": "Further, the interests of readers can vary and the notion of importance can change across them.", "labels": [], "entities": []}, {"text": "Existing sum-marization algorithms generate a single summary and are not capable of generating multiple summaries tuned to the interests of the readers.", "labels": [], "entities": []}, {"text": "In this paper, we propose an attention based RNN framework to generate multiple summaries of a single document tuned to different topics of interest.", "labels": [], "entities": []}, {"text": "Our method outper-forms existing baselines and our results suggest that the attention of generative networks can be successfully biased to look at sentences relevant to a topic and effectively used to generate topic-tuned summaries.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic text summarization is the task of generating/extracting short text snippet that embodies the content of a larger document or a collection of documents in a concise fashion.", "labels": [], "entities": [{"text": "Automatic text summarization is the task of generating/extracting short text snippet that embodies the content of a larger document or a collection of documents in a concise fashion", "start_pos": 0, "end_pos": 181, "type": "Description", "confidence": 0.7487433175245921}]}, {"text": "Traditionally, researchers have used extractive methods for summarization -where a set of sentences is selected from an article and concatenated as-is to form the summary.", "labels": [], "entities": [{"text": "summarization", "start_pos": 60, "end_pos": 73, "type": "TASK", "confidence": 0.9798846244812012}]}, {"text": "Extractive methods are limited by their inability to paraphrase the content of the article using new sentences and hence are very different from the summaries created by humans, who paraphrase a given article to generate summaries.", "labels": [], "entities": []}, {"text": "Recent works on summarization have come up with sequence-to-sequence models for generating summaries in a word-by-word fashion, thus 'generating' new sentences.", "labels": [], "entities": [{"text": "summarization", "start_pos": 16, "end_pos": 29, "type": "TASK", "confidence": 0.9848504066467285}]}, {"text": "As articles get longer, it might span several topics and therefore, a single summary is often insufficient to satisfy the interests of the reader.", "labels": [], "entities": []}, {"text": "In these cases, it is desirable to produce summaries that are aligned to the topical interests of reader to enable better consumption.", "labels": [], "entities": []}, {"text": "Extractive summarization uses sentence-level features) that have been leveraged for producing query-focused or topic-based summaries.", "labels": [], "entities": [{"text": "Extractive summarization", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8020197153091431}]}, {"text": "However, for RNN-based frameworks, such tuned summary generation is non-obvious due to the absence of explicit content based features.", "labels": [], "entities": [{"text": "summary generation", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.7443891167640686}]}, {"text": "To extend the advantages of abstractive summarization and generate topic-tuned summaries, we propose a neural encoder-decoder based framework which takes an article along with a topic of interest as input and generates a summary tuned to the target topic of interest.", "labels": [], "entities": [{"text": "summarization", "start_pos": 40, "end_pos": 53, "type": "TASK", "confidence": 0.6528606414794922}]}, {"text": "Our method works by training a neural framework to pay higher attention to parts of the input articles relevant to given topic.", "labels": [], "entities": []}, {"text": "To overcome the lack of dataset containing articles with multiple topic-oriented summaries, we use a novel approach to artificially create a topic-centric training corpus from the CNN/Dailymail dataset () for training our model.", "labels": [], "entities": [{"text": "CNN/Dailymail dataset", "start_pos": 180, "end_pos": 201, "type": "DATASET", "confidence": 0.9239055216312408}]}, {"text": "shows an article with different summaries generated by the proposed approach tuned towards the topics of politics, finance and social aspects.", "labels": [], "entities": []}, {"text": "It can be seen that the business oriented summary talks about IMF's estimates about increase in taxes and the summary for politics talks about how it relates to the government's upcoming budget.", "labels": [], "entities": [{"text": "IMF", "start_pos": 62, "end_pos": 65, "type": "DATASET", "confidence": 0.7041528820991516}]}, {"text": "The summary for the social topic elaborates on universal basic income and social security.", "labels": [], "entities": []}, {"text": "Thus, for the same article, the proposed approach is capable of generating different summaries tuned to the input topic of interest.", "labels": [], "entities": []}, {"text": "Title: IMF backs Universal Basic Income in India, serves Modi govt apolitical opportunity Article: Ahead of Union Budget 2018, the Narendra Modi-led governments last full-year budget to be presented in February, the International Monetary Fund (IMF) has made a strong case for India adopting a fiscally neutral Universal Basic Income by eliminating both food and fuel subsidies ...", "labels": [], "entities": []}, {"text": "Business: imf claim eliminating energy \" tax subsidies \" would require a increase in fuel taxes and retail fuel prices such as petrol prices and tax of rs400 ($ 6) per tonne on coal consumption ...", "labels": [], "entities": []}, {"text": "Politics: narendra modi-led government 's last full-year budget to be presented in february.", "labels": [], "entities": []}, {"text": "the international monetary fund has made a strong case for india adopting a fiscally neutral universal basic income by eliminating both food and fuel subsidies ...", "labels": [], "entities": []}, {"text": "Social: universal basic income is a form of social security guaranteed to citizens and transferred directly to their bank accounts and is being debated globally ...: Topic oriented summaries generated by our method for an article (from LiveMint) touching multiple topics", "labels": [], "entities": []}], "datasetContent": [{"text": "To position our method against existing works, we use the following summarizers as our baselines.", "labels": [], "entities": []}, {"text": "Our first baseline is the vanilla pointer generator (PG) described in the original work of.", "labels": [], "entities": []}, {"text": "This method does not consider the desired topic of summary when generating a summary.", "labels": [], "entities": []}, {"text": "For an unbiased evaluation, we use exactly those unmerged article-summary pairs of the CNN/Dailymail dataset for training and validation which were eventually incorporated in the final dataset.", "labels": [], "entities": [{"text": "CNN/Dailymail dataset", "start_pos": 87, "end_pos": 108, "type": "DATASET", "confidence": 0.9335367381572723}]}, {"text": "Then the trained model is applied to generate summaries of the test set of the final dataset.", "labels": [], "entities": []}, {"text": "Our next baseline is a frequency-based extraction method that selects lines from the input article which are strongly aligned to the desired topic u t . For each sentence, the relevance to each of the predefined topics is calculated using a dot product between their vector representations.", "labels": [], "entities": []}, {"text": "The sentence is designated to the topic having the maximum relevance score, and the strength of alignment is the ratio of the the highest and the second highest relevance scores.", "labels": [], "entities": []}, {"text": "We extract all the sentences in the article which are aligned to the target topic, and run it through the pointer-generator network to create the summary.", "labels": [], "entities": []}, {"text": "We refer to this baseline as abstractive summarizer with frequency based extraction (Freq-Abs).", "labels": [], "entities": []}, {"text": "Alternatively, we take k sentences which have the highest strength of alignment with the target topic to create a purely extractive summary.", "labels": [], "entities": []}, {"text": "k was set to 3 in accordance with the average number of sentences in the summaries of the training set (2.83).", "labels": [], "entities": []}, {"text": "We call this method extractive summarizer with frequency based extraction (Freq-Ext).", "labels": [], "entities": [{"text": "extractive summarizer", "start_pos": 20, "end_pos": 41, "type": "TASK", "confidence": 0.6227615177631378}, {"text": "Freq-Ext", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.6169278025627136}]}, {"text": "Our last baseline is a topic-signature based approach which also works by extracting sentences from the article which are aligned to the target topic.", "labels": [], "entities": []}, {"text": "However, the selection of sentences is based on topic signatures as described by and instead of word frequencies.", "labels": [], "entities": []}, {"text": "A topic signature is a set of words relevant to the topic.", "labels": [], "entities": []}, {"text": "For any given sentence, the number of signature terms of each topic is computed.", "labels": [], "entities": []}, {"text": "The sentence is designated to belong to the topic which has the highest number of its signature terms occurring in it.", "labels": [], "entities": []}, {"text": "The topic signature is determined based a set of documents T relevant to the topic, and a set of background documents T that is indicative of general topics.", "labels": [], "entities": []}, {"text": "It is assumed that in T and T , the occurrence of each word w follows a binomial distribution with probability of occurrence p.", "labels": [], "entities": []}, {"text": "The likelihood of observing T and T is calculated under two hypotheses -one where the probability of occurrence of w is p 1 in T and p 2 in T such that p 1 > p 2 , and the other where it is pin both T and T . The ratio of likelihoods is calculated and words for which this ratio is the highest are included as part of the topic's signature.", "labels": [], "entities": []}, {"text": "We extracted topic signatures using the summaries of the training dataset as our corpus.", "labels": [], "entities": []}, {"text": "For each topic t, the corresponding summaries form the topic specific corpus T , and the remaining summaries make the background corpus.", "labels": [], "entities": []}, {"text": "shows a subset of the topic signatures.", "labels": [], "entities": []}, {"text": "We used the 3, 974 article-topic-summary tuples from our final dataset to evaluate the performance of the summarizers.", "labels": [], "entities": []}, {"text": "The models were given the input article and topic and the generated summary was compared with the ground truth summary.", "labels": [], "entities": []}, {"text": "We use ROUGE scores to measure the quality of summaries.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 7, "end_pos": 12, "type": "METRIC", "confidence": 0.9797107577323914}]}, {"text": "ROUGE scores measure the precision, recall and f-measure for the occurrence of n-grams in the generated summary with respect to the reference human generated summary.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.8174235224723816}, {"text": "precision", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9996227025985718}, {"text": "recall", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9994276165962219}, {"text": "f-measure", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.9938219785690308}]}, {"text": "We use the ROUGE-1, ROUGE-2 and ROUGE-L variants () which look at unigram, bigram and longest common subsequence overlaps between generated and reference summaries.", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 11, "end_pos": 18, "type": "METRIC", "confidence": 0.7657877802848816}]}, {"text": "Table 3 shows the ROUGE F1 scores for the topicbased summaries generated by different methods.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 18, "end_pos": 23, "type": "METRIC", "confidence": 0.9832587242126465}, {"text": "F1", "start_pos": 24, "end_pos": 26, "type": "METRIC", "confidence": 0.5592103004455566}]}, {"text": "It is easy to see that the proposed method yields the best performance across all the baselines.", "labels": [], "entities": []}, {"text": "Further, we also observed that the summaries generated by our system show abstractive nature as noted in. shows some instances where our model used new words unseen in the article.", "labels": [], "entities": []}, {"text": "Article: spain 's 2-0 defeat by holland on tuesday brought back bitter memories of their disastrous 2014 world cup , but coach vicente del bosque will not be too worried ...", "labels": [], "entities": []}, {"text": "Summary: holland beat spain 2-0 at the amsterdam arena on tuesday night Article: it 's 11 years since arsenal won the title.", "labels": [], "entities": [{"text": "amsterdam arena", "start_pos": 39, "end_pos": 54, "type": "DATASET", "confidence": 0.9229122996330261}, {"text": "Article", "start_pos": 72, "end_pos": 79, "type": "METRIC", "confidence": 0.8568410277366638}]}, {"text": "they went from invincibles to incapables ...", "labels": [], "entities": []}, {"text": "Summary: arsene wenger 's side have 15 wins in 17 appearances: Summaries where our model uses new words not seen in the input article  Finally, we performed human evaluations of summaries to compare the quality of our method against the baselines.", "labels": [], "entities": []}, {"text": "We restrict ourselves to  the best performing baseline -the topic signature based abstractive summarizer (Sign-Abs), and the vanilla pointer-generator.", "labels": [], "entities": [{"text": "topic signature based abstractive summarizer", "start_pos": 60, "end_pos": 104, "type": "TASK", "confidence": 0.5886725187301636}]}, {"text": "We fetched articles touching multiple topics using the NYTimes Search API 1 , which allows to search for articles on NYTimes which appear in the news desk fora topic (the major topic) and are tagged with another topic (the minor topic).", "labels": [], "entities": [{"text": "NYTimes Search API 1", "start_pos": 55, "end_pos": 75, "type": "DATASET", "confidence": 0.9074730575084686}, {"text": "NYTimes", "start_pos": 117, "end_pos": 124, "type": "DATASET", "confidence": 0.9624922275543213}]}, {"text": "For different pairs of topics, we retrieved relevant articles using the API and randomly selected few of them to generate summaries tuned to the two topics using our method and the baselines.", "labels": [], "entities": []}, {"text": "We retrieved 18 total articles for the evaluation.", "labels": [], "entities": []}, {"text": "Each article had two topics leading to 36 (article,topic) pairs for the summary generation.", "labels": [], "entities": []}, {"text": "For each (article,topic) pair, annotators were shown two summaries -one generated by our method and the other by one of the baselines.", "labels": [], "entities": []}, {"text": "The task was to choose the summary more relevant to the topic.", "labels": [], "entities": []}, {"text": "Each such task was annotated by 10 different annotators.", "labels": [], "entities": []}, {"text": "Every annotator was assigned 9 tasks and 1 extra dummy task to check if they were paying attention.", "labels": [], "entities": []}, {"text": "Annotations from evaluators who answered incorrectly to the dummy task were discarded.", "labels": [], "entities": []}, {"text": "We had a total of 720 annotations from the human evaluation and their summary is shown in.", "labels": [], "entities": []}, {"text": "The value under \"Overall annotations\" refers to the fraction of all human responses across all 1 https://developer.nytimes.com/ documents which rated the summary produced by our method better than the alternate summary produced by the compared baseline method.", "labels": [], "entities": []}, {"text": "Understandably, the proposed approach is comparable in the preference to both the baselines for the major topic (0.5667) -since most standard summaries will cover the primary topic of the input.", "labels": [], "entities": []}, {"text": "However, for the minor topic, it can be seen that the proposed approach is better than the baselines.", "labels": [], "entities": []}, {"text": "The value under \"Document annotations\" indicates the fraction of times the proposed method was preferred by half or more of the annotators fora document-topic pair.", "labels": [], "entities": []}, {"text": "It is easy to see that the proposed approach clearly outperforms the baselines under this scenario.", "labels": [], "entities": []}, {"text": "The difference in performance is even more significant for summaries generated for the non-major topic since our approach is capable of efficiently generating tuned summaries for minor topics as well.", "labels": [], "entities": [{"text": "summaries generated", "start_pos": 59, "end_pos": 78, "type": "TASK", "confidence": 0.9220296144485474}]}], "tableCaptions": [{"text": " Table 3: ROUGE F1 scores obtained by various meth- ods on the final test set", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.992347240447998}, {"text": "F1", "start_pos": 16, "end_pos": 18, "type": "METRIC", "confidence": 0.8261462450027466}]}, {"text": " Table 6: Evaluation of summaries of the proposed approach against Pointer Generator Framework and Topic  Signature based Summarizer by human annotators", "labels": [], "entities": []}]}