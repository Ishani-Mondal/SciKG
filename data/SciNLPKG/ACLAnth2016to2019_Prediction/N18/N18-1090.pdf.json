{"title": [{"text": "Universal Dependency Parsing for Hindi-English Code-switching", "labels": [], "entities": [{"text": "Code-switching", "start_pos": 47, "end_pos": 61, "type": "TASK", "confidence": 0.2968737483024597}]}], "abstractContent": [{"text": "Code-switching is a phenomenon of mixing grammatical structures of two or more languages under varied social constraints.", "labels": [], "entities": []}, {"text": "The code-switching data differ so radically from the benchmark corpora used in NLP community that the application of standard technologies to these data degrades their performance sharply.", "labels": [], "entities": []}, {"text": "Unlike standard corpora, these data often need to go through additional processes such as language identification, nor-malization and/or back-transliteration for their efficient processing.", "labels": [], "entities": [{"text": "language identification", "start_pos": 90, "end_pos": 113, "type": "TASK", "confidence": 0.7292056083679199}]}, {"text": "In this paper, we investigate these indispensable processes and other problems associated with syntactic parsing of code-switching data and propose methods to mitigate their effects.", "labels": [], "entities": [{"text": "syntactic parsing of code-switching data", "start_pos": 95, "end_pos": 135, "type": "TASK", "confidence": 0.8081235408782959}]}, {"text": "In particular, we study dependency parsing of code-switching data of Hindi and English multilingual speakers from Twitter.", "labels": [], "entities": []}, {"text": "We present a treebank of Hindi-English code-switching tweets under Universal Dependencies scheme and propose a neural stacking model for parsing that efficiently leverages part-of-speech tag and syntactic tree annotations in the code-switching treebank and the preexisting Hindi and En-glish treebanks.", "labels": [], "entities": [{"text": "parsing", "start_pos": 137, "end_pos": 144, "type": "TASK", "confidence": 0.9668935537338257}]}, {"text": "We also present normaliza-tion and back-transliteration models with a decoding process tailored for code-switching data.", "labels": [], "entities": []}, {"text": "Results show that our neural stacking parser is 1.5% LAS points better than the augmented parsing model and our decoding process improves results by 3.8% LAS points over the first-best normalization and/or back-transliteration.", "labels": [], "entities": [{"text": "neural stacking parser", "start_pos": 22, "end_pos": 44, "type": "TASK", "confidence": 0.7488423784573873}, {"text": "LAS", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.9861369132995605}, {"text": "LAS", "start_pos": 154, "end_pos": 157, "type": "METRIC", "confidence": 0.9566228985786438}]}], "introductionContent": [{"text": "Code-switching 1 (henceforth CS) is the juxtaposition, within the same speech utterance, of grammatical units such as words, phrases, and clauses Code-mixing is another term in the linguistics literature used interchangeably with code-switching.", "labels": [], "entities": []}, {"text": "Both terms are often used to refer to the same or similar phenomenon of mixed language use.", "labels": [], "entities": []}, {"text": "belonging to two or more different languages.", "labels": [], "entities": []}, {"text": "The phenomenon is prevalent in multilingual societies where speakers share more than one language and is often prompted by multiple social factors.", "labels": [], "entities": []}, {"text": "Moreover, code-switching is mostly prominent in colloquial language use in daily conversations, both online and offline.", "labels": [], "entities": []}, {"text": "Most of the benchmark corpora used in NLP for training and evaluation are based on edited monolingual texts which strictly adhere to the norms of a language related, for example, to orthography, morphology, and syntax.", "labels": [], "entities": []}, {"text": "Social media data in general and CS data, in particular, deviate from these norms implicitly set forth by the choice of corpora used in the community.", "labels": [], "entities": []}, {"text": "This is the reason why the current technologies often perform miserably on social media data, be it monolingual or mixed language data; C \u00b8 etino\u02d8 glu et al.,).", "labels": [], "entities": []}, {"text": "CS data offers additional challenges over the monolingual social media data as the phenomenon of codeswitching transforms the data in many ways, for example, by creating new lexical forms and syntactic structures by mixing morphology and syntax of two languages making it much more diverse than any monolingual corpora (C \u00b8 etino\u02d8 glu et al., 2016).", "labels": [], "entities": []}, {"text": "As the current computational models fail to cater to the complexities of CS data, there is often a need for dedicated techniques tailored to its specific characteristics.", "labels": [], "entities": []}, {"text": "Given the peculiar nature of CS data, it has been widely studied in linguistics literature, and more recently, there has been a surge in studies concerning CS data in NLP as well.", "labels": [], "entities": []}, {"text": "Besides the individual computational works, a series of shared-tasks and workshops on preprocessing and shallow syntactic analysis of CS data have also been conducted at multiple venues such as Empirical Methods in NLP, International Conference on NLP and Forum for Information Retrieval Evaluation).", "labels": [], "entities": [{"text": "International Conference on NLP", "start_pos": 220, "end_pos": 251, "type": "DATASET", "confidence": 0.8326198011636734}, {"text": "Information Retrieval Evaluation", "start_pos": 266, "end_pos": 298, "type": "TASK", "confidence": 0.8378853797912598}]}, {"text": "Most of these works have attempted to address preliminary tasks such as language identification, normalization and/or back-transliteration as these data often need to go through these additional processes for their efficient processing.", "labels": [], "entities": [{"text": "language identification", "start_pos": 72, "end_pos": 95, "type": "TASK", "confidence": 0.7669185400009155}]}, {"text": "In this paper, we investigate these indispensable processes and other problems associated with syntactic parsing of code-switching data and propose methods to mitigate their effects.", "labels": [], "entities": [{"text": "syntactic parsing of code-switching data", "start_pos": 95, "end_pos": 135, "type": "TASK", "confidence": 0.8081235408782959}]}, {"text": "In particular, we study dependency parsing of HindiEnglish code-switching data of multilingual Indian speakers from Twitter.", "labels": [], "entities": [{"text": "HindiEnglish code-switching data", "start_pos": 46, "end_pos": 78, "type": "DATASET", "confidence": 0.7626305818557739}]}, {"text": "Hindi-English codeswitching presents an interesting scenario for the parsing community.", "labels": [], "entities": [{"text": "parsing", "start_pos": 69, "end_pos": 76, "type": "TASK", "confidence": 0.9704596996307373}]}, {"text": "Mixing among typologically diverse languages will intensify structural variations which will make parsing more challenging.", "labels": [], "entities": []}, {"text": "For example, there will be many sentences containing: (1) both SOV and SVO word orders 2 , (2) both head-initial and head-final genitives, (3) both prepositional and postpositional phrases, etc.", "labels": [], "entities": []}, {"text": "More importantly, none among the Hindi and English treebanks would provide any training instance for these mixed structures within individual sentences.", "labels": [], "entities": []}, {"text": "In this paper, we present the first codeswitching treebank that provides syntactic annotations required for parsing mixed-grammar syntactic structures.", "labels": [], "entities": [{"text": "parsing mixed-grammar syntactic structures", "start_pos": 108, "end_pos": 150, "type": "TASK", "confidence": 0.8596796691417694}]}, {"text": "Moreover, we present a parsing pipeline designed explicitly for Hindi-English CS data.", "labels": [], "entities": [{"text": "parsing", "start_pos": 23, "end_pos": 30, "type": "TASK", "confidence": 0.9633068442344666}]}, {"text": "The pipeline comprises of several modules such as a language identification system, a backtransliteration system, and a dependency parser.", "labels": [], "entities": [{"text": "language identification", "start_pos": 52, "end_pos": 75, "type": "TASK", "confidence": 0.7069200277328491}]}, {"text": "The gist of these modules and our overall research contributions are listed as follows: \u2022 back-transliteration and normalization models based on encoder-decoder frameworks with sentence decoding tailored for codeswitching data; \u2022 a dependency treebank of Hindi-English code-switching tweets under Universal Dependencies scheme; and 2 Order of Subject, Object and Verb in transitive sentences.", "labels": [], "entities": []}, {"text": "\u2022 a neural parsing model which learns POS tagging and parsing jointly and also incorporates knowledge from the monolingual treebanks using neural stacking.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 38, "end_pos": 49, "type": "TASK", "confidence": 0.7581138908863068}]}], "datasetContent": [{"text": "We train all of our POS tagging and parsing models on training sets of the Hindi and English UDv2 treebanks and our Hindi-English CS treebank.", "labels": [], "entities": [{"text": "POS tagging and parsing", "start_pos": 20, "end_pos": 43, "type": "TASK", "confidence": 0.7576553970575333}, {"text": "Hindi and English UDv2 treebanks", "start_pos": 75, "end_pos": 107, "type": "DATASET", "confidence": 0.5776397883892059}, {"text": "Hindi-English CS treebank", "start_pos": 116, "end_pos": 141, "type": "DATASET", "confidence": 0.7884828050931295}]}, {"text": "For tuning and evaluation, we use the development and evaluation sets from.", "labels": [], "entities": []}, {"text": "We conduct multiple experiments in gold and predicted settings to measure the effectiveness of the sub-modules of our parsing pipeline.", "labels": [], "entities": [{"text": "parsing pipeline", "start_pos": 118, "end_pos": 134, "type": "TASK", "confidence": 0.9123201370239258}]}, {"text": "In predicted settings, we use the POS taggers separately trained on the Hindi, English and CS training sets.", "labels": [], "entities": [{"text": "POS taggers", "start_pos": 34, "end_pos": 45, "type": "TASK", "confidence": 0.6489504277706146}, {"text": "CS training sets", "start_pos": 91, "end_pos": 107, "type": "DATASET", "confidence": 0.7320965727170309}]}, {"text": "All of our models use word embeddings from transformed Hindi and English embedding spaces to address the problem of lexical differences prevalent in CS sentences.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Language Identification results on CS test set.", "labels": [], "entities": [{"text": "Language Identification", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.7166771292686462}, {"text": "CS test set", "start_pos": 45, "end_pos": 56, "type": "DATASET", "confidence": 0.9185466766357422}]}, {"text": " Table 2: Normalization accuracy based on the number  of noisy tokens in the evaluation set. FB = First Best,  and FW = Fragment Wise", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.957368016242981}, {"text": "FB", "start_pos": 93, "end_pos": 95, "type": "METRIC", "confidence": 0.9970303773880005}, {"text": "First Best", "start_pos": 98, "end_pos": 108, "type": "METRIC", "confidence": 0.9571440517902374}, {"text": "FW", "start_pos": 115, "end_pos": 117, "type": "METRIC", "confidence": 0.9601486921310425}]}, {"text": " Table 3: Data Statistics. Dev set is used for tuning  model parameters, while Test set is used for evaluation.", "labels": [], "entities": []}, {"text": " Table 4: Accuracy of different parsing models on the  evaluation set. POS tags are jointly predicted with  parsing. LID = Language tag, TRN = Translitera- tion/normalization.", "labels": [], "entities": [{"text": "LID", "start_pos": 117, "end_pos": 120, "type": "METRIC", "confidence": 0.9513247013092041}, {"text": "TRN", "start_pos": 137, "end_pos": 140, "type": "METRIC", "confidence": 0.9267069697380066}]}, {"text": " Table 5: POS and parsing results for Hindi and En- glish monolingual test sets using pipeline and stack- prop models.", "labels": [], "entities": []}, {"text": " Table 7:  Accuracy of different parsing mod- els on the test set using predicted language tags,  normalized/back-transliterated words and predicted  POS tags. POS tags are predicted separately be- fore parsing. In Neural Stacking model, only parsing  knowledge from the Bilingual model is transferred.", "labels": [], "entities": []}]}