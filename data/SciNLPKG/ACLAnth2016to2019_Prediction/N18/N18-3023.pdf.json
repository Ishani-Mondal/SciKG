{"title": [{"text": "Practical Application of Domain Dependent Confidence Measurement for Spoken Language Understanding Systems", "labels": [], "entities": [{"text": "Domain Dependent Confidence Measurement", "start_pos": 25, "end_pos": 64, "type": "TASK", "confidence": 0.7115380764007568}, {"text": "Spoken Language Understanding", "start_pos": 69, "end_pos": 98, "type": "TASK", "confidence": 0.814882218837738}]}], "abstractContent": [{"text": "Spoken Language Understanding (SLU), which extracts semantic information from speech, is not flawless, specially in practical applications.", "labels": [], "entities": [{"text": "Spoken Language Understanding (SLU)", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8565533757209778}]}, {"text": "The reliability of the output of an SLU system can be evaluated using a semantic confidence measure.", "labels": [], "entities": []}, {"text": "Confidence measures area solution to improve the quality of spoken dialogue systems, by rejecting low-confidence SLU results.", "labels": [], "entities": []}, {"text": "In this study we discuss real-world applications of confidence scoring in a customer service scenario.", "labels": [], "entities": [{"text": "confidence scoring", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.7153823524713516}]}, {"text": "We build confidence models for three major types of dialogue states that are considered as different domains: how may I help you, number capture , and confirmation.", "labels": [], "entities": [{"text": "number capture", "start_pos": 130, "end_pos": 144, "type": "TASK", "confidence": 0.8761752843856812}]}, {"text": "Practical challenges to train domain-dependent confidence models, including data limitations, are discussed, and it is shown that feature engineering plays an important role to improve performance.", "labels": [], "entities": []}, {"text": "We explore a wide variety of predictor features based on speech recognition, intent classification , and high-level domain knowledge, and find the combined feature set with the best rejection performance for each application.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 57, "end_pos": 75, "type": "TASK", "confidence": 0.7237609326839447}, {"text": "intent classification", "start_pos": 77, "end_pos": 98, "type": "TASK", "confidence": 0.6930872648954391}]}], "introductionContent": [{"text": "The purpose of an SLU system is to interpret the meaning of a speech signal.", "labels": [], "entities": [{"text": "interpret the meaning of a speech signal", "start_pos": 35, "end_pos": 75, "type": "TASK", "confidence": 0.818440454346793}]}, {"text": "SLU systems use Automatic Speech Recognition (ASR) to convert speech signal to the text of what was spoken (hypothesis), followed by semantic meaning extraction from the ASR hypothesis using Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "Automatic Speech Recognition (ASR)", "start_pos": 16, "end_pos": 50, "type": "TASK", "confidence": 0.7873392502466837}, {"text": "semantic meaning extraction", "start_pos": 133, "end_pos": 160, "type": "TASK", "confidence": 0.6707585056622823}]}, {"text": "Semantic information that can be extracted from an utterance include the intent of speaker, as well as any entities such as names, products, numbers, places, etc., where depending on the application, one or more of these information are of importance.", "labels": [], "entities": []}, {"text": "While SLU systems have achieved considerable success during the past few decades, errors are in- * This work was done while at Interactions LLC.", "labels": [], "entities": []}, {"text": "evitable in real applications due to a number of factors including noisy speech conditions, speaker variations such as accent, speaking style, inherent ambiguity of human language, lack of enough indomain training data, etc.", "labels": [], "entities": []}, {"text": "With the rise of virtual assistants and their increasing utilization from everyday voice inquiries on smart phones and voice commands in smart home scenarios to customer service applications, it is crucial to keep the accuracy of SLU systems above an acceptable threshold.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 218, "end_pos": 226, "type": "METRIC", "confidence": 0.9992960691452026}]}, {"text": "Therefore, to keep the natural flow of conversation between human and automatic agent, using human agents when automatic system fails to provide an accurate response improves user satisfaction.", "labels": [], "entities": []}, {"text": "However, the question is: \"how do we know that SLU system failed?\"", "labels": [], "entities": []}, {"text": "A confidence score is a scalar quantity that measures the reliability of an automatic system.", "labels": [], "entities": []}, {"text": "In the literature, several studies have applied ASRbased feature vectors to train statistical models that predict word and/or utterance level confidence scores for ASR systems (, and SLU systems ().", "labels": [], "entities": [{"text": "ASR", "start_pos": 164, "end_pos": 167, "type": "TASK", "confidence": 0.9254850745201111}]}, {"text": "Furthermore, semanticbased features have been applied in predicting confidence measures for spoken dialogue systems, as well as other applications such as machine translation ().", "labels": [], "entities": [{"text": "machine translation", "start_pos": 155, "end_pos": 174, "type": "TASK", "confidence": 0.8158363997936249}]}, {"text": "The purpose of this study, is to show the importance of confidence modeling in real-world SLU applications, discuss practical challenges to train confidence models, and create a guideline to build efficient confidence models.", "labels": [], "entities": [{"text": "confidence modeling", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.7837898433208466}]}, {"text": "We build domaindependent semantic confidence models to improve the rejection of unreliable SLU results.", "labels": [], "entities": []}, {"text": "Such rejection process is designed to maintain a high accuracy, while minimizing the number of rejected utterances.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.998731791973114}]}, {"text": "Our experiments are based on improving rejection performance for three different types of dialogue states in a customer service scenario: opening (i.e., how may I help you), number capture (e.g., phone or account number), and confirmation (i.e., yes/no).", "labels": [], "entities": [{"text": "number capture (e.g., phone or account number)", "start_pos": 174, "end_pos": 220, "type": "TASK", "confidence": 0.6718351393938065}]}, {"text": "The contributions of this study are: 1.", "labels": [], "entities": []}, {"text": "Building efficient confidence models based on domain-dependent feature engineering with limited labeled data for training, which makes confidence modeling process scalable for real applications.", "labels": [], "entities": []}, {"text": "2. Proposing an evaluation methodology for practical applications of rejection confidence scoring, based on which an operating point can be selected to balance cost vs. accuracy.", "labels": [], "entities": [{"text": "rejection confidence scoring", "start_pos": 69, "end_pos": 97, "type": "TASK", "confidence": 0.830294132232666}, {"text": "accuracy", "start_pos": 169, "end_pos": 177, "type": "METRIC", "confidence": 0.9985913634300232}]}, {"text": "3. Comparing linear and nonlinear confidence models with limited training data, and proposing time-efficient nonlinear features that improve performance.", "labels": [], "entities": []}], "datasetContent": [{"text": "The performance of SLU system with an accept/reject backend, shown in, cannot simply be evaluated based on the accuracy of the output.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9962894916534424}]}, {"text": "An essential component of such system, is rejection confidence scoring, which depends on both confidence score and confidence threshold.", "labels": [], "entities": [{"text": "rejection confidence scoring", "start_pos": 42, "end_pos": 70, "type": "METRIC", "confidence": 0.889273464679718}]}, {"text": "Confidence modeling can be formulated as a binary classification problem, and be evaluated using standard measures such as Receiver Operating Characteristic (ROC) curve, or area under the curve (AUC).", "labels": [], "entities": [{"text": "Confidence modeling", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9046808183193207}, {"text": "Receiver Operating Characteristic (ROC) curve", "start_pos": 123, "end_pos": 168, "type": "METRIC", "confidence": 0.5958367500986371}, {"text": "area under the curve (AUC)", "start_pos": 173, "end_pos": 199, "type": "METRIC", "confidence": 0.6682080158165523}]}, {"text": "However, in a practical application, business objectives have to be considered in performance evaluations.", "labels": [], "entities": []}, {"text": "Ina virtual intelligent customer service scenario, it is important to maximize customer satisfaction while minimizing the cost.", "labels": [], "entities": []}, {"text": "Customer satisfaction is directly related to the accuracy, and accuracy can be improved by using higher confidence threshold.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9995197057723999}, {"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9994871616363525}]}, {"text": "Nevertheless, with a higher confidence threshold, more utterances that are labeled by the automated system are rejected and this will increase the cost of manual labeling.", "labels": [], "entities": []}, {"text": "Therefore, there is a trade-off between cost (i.e., the number of rejected utterances) and precision (i.e., the accuracy of accepted utterances).", "labels": [], "entities": [{"text": "precision", "start_pos": 91, "end_pos": 100, "type": "METRIC", "confidence": 0.9994860887527466}, {"text": "accuracy", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.99812251329422}]}, {"text": "In this study, we focus on improving the confidence measurement to maintain the accuracy while reducing the rejection rate.", "labels": [], "entities": [{"text": "confidence measurement", "start_pos": 41, "end_pos": 63, "type": "METRIC", "confidence": 0.9299303293228149}, {"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9996316432952881}, {"text": "rejection rate", "start_pos": 108, "end_pos": 122, "type": "METRIC", "confidence": 0.8965536952018738}]}, {"text": "To evaluate different confidence measures, we plot False Accept (FA) percentage on accepted utterances versus the rejection percentage.", "labels": [], "entities": [{"text": "False Accept (FA) percentage", "start_pos": 51, "end_pos": 79, "type": "METRIC", "confidence": 0.9364447295665741}]}, {"text": "For the remaining of this study we call these plots FA-Rej.", "labels": [], "entities": [{"text": "FA-Rej", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9861741065979004}]}, {"text": "In production system, confidence threshold is set based on the required semantic accuracy for each application, and generally the higher the rejection, the lower is the error rate.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9334621429443359}]}, {"text": "If a FA-Rej plot has lower rejection rates at all FA rates compared to another plot, it shows a performance improvement.", "labels": [], "entities": [{"text": "rejection", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.9510384202003479}, {"text": "FA", "start_pos": 50, "end_pos": 52, "type": "METRIC", "confidence": 0.9919547438621521}]}], "tableCaptions": []}