{"title": [{"text": "Corpus Creation and Emotion Prediction for Hindi-English Code-Mixed Social Media Text", "labels": [], "entities": [{"text": "Corpus Creation", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7533932030200958}]}], "abstractContent": [{"text": "Emotion Prediction is a Natural Language Processing (NLP) task dealing with detection and classification of emotions in various monolin-gual and bilingual texts.", "labels": [], "entities": [{"text": "Emotion Prediction", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8767406940460205}, {"text": "detection and classification of emotions", "start_pos": 76, "end_pos": 116, "type": "TASK", "confidence": 0.7417044937610626}]}, {"text": "While some work has been done on code-mixed social media text and in emotion prediction separately, our work is the first attempt which aims at identifying the emotion associated with Hindi-English code-mixed social media text.", "labels": [], "entities": [{"text": "emotion prediction", "start_pos": 69, "end_pos": 87, "type": "TASK", "confidence": 0.7445056140422821}]}, {"text": "In this paper , we analyze the problem of emotion identification in code-mixed content and present a Hindi-English code-mixed corpus extracted from twitter and annotated with the associated emotion.", "labels": [], "entities": [{"text": "emotion identification", "start_pos": 42, "end_pos": 64, "type": "TASK", "confidence": 0.733649268746376}]}, {"text": "For every tweet in the dataset, we annotate the source language of all the words present, and also the causal language of the expressed emotion.", "labels": [], "entities": []}, {"text": "Finally, we propose a supervised classification system which uses various machine learning techniques for detecting the emotion associated with the text using a variety of character level, word level, and lexicon based features.", "labels": [], "entities": []}], "introductionContent": [{"text": "Micro-blogging sites like Twitter and Facebook encourage users to express their daily thoughts in real time, which often result in millions of emotional statements being posted online, everyday.", "labels": [], "entities": []}, {"text": "Identification and analysis of emotions in social-media texts are of great significance in understanding the trends, reviews, events and human behaviour.", "labels": [], "entities": []}, {"text": "Emotion prediction aims to identify fine-grained emotions, i.e., Happy, Anger, Fear, Sadness, Surprise, Disgust, if any present in the text.", "labels": [], "entities": [{"text": "Emotion prediction", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8799887597560883}]}, {"text": "Previous research related to this task has mainly been focused only on the monolingual text () due to the availability of large-scale monolingual resources.", "labels": [], "entities": []}, {"text": "However, usage of code mixed language in online posts is very common, especially in multilingual societies like India, for expressing one's emotions * These authors contributed equally to this work. and thoughts, particularly when the communication is informal.", "labels": [], "entities": []}, {"text": "Code-Mixing (CM) is a natural phenomenon of embedding linguistic units such as phrases, words or morphemes of one language into an utterance of another.", "labels": [], "entities": [{"text": "Code-Mixing (CM)", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.5797700509428978}]}, {"text": "Following are some instances from a Twitter corpus of Hindi-English code-mixed texts also transliterated in English.", "labels": [], "entities": []}, {"text": "T1 : \"I don't want to go to school today, teacher se dar lagta hai mujhe.\"", "labels": [], "entities": []}, {"text": "Translation : \"I don't want to go to school today, I am afraid of teacher.\"", "labels": [], "entities": []}, {"text": "T2 : \"Finally India away series jeetne mein successful ho hi gayi :D\" Translation : \"Finally India got success in winning the away series :D\" T3 : \"This is a big surprise that Rahul Gandhi congress ke naye president hain.\"", "labels": [], "entities": []}, {"text": "Translation : \"This is a big surprise that Rahul Gandhi is the new president of Congress.\"", "labels": [], "entities": []}, {"text": "The above examples contain both English and Hindi texts.", "labels": [], "entities": []}, {"text": "T1 expresses fear through Hindi phrase \"dar lagta hai mujhe\", happiness is expressed in T2 through a Hindi-English mixed phrase \"jeetne mein successful ho hi gayi\", while in T3, surprise is expressed through English phrase \"This is a big surprise\".", "labels": [], "entities": []}, {"text": "Since very few resources are available for HindiEnglish code-mixed text, in this paper we present our initial efforts in constructing the corpus and annotating the code-mixed tweets with associated emotion and the causal language for that emotion.", "labels": [], "entities": []}, {"text": "We strongly believe that our initial efforts in constructing the annotated code-mixed emotion corpus will prove to be extremely valuable for researchers working on various natural processing tasks on social media.", "labels": [], "entities": []}, {"text": "The structure of the paper is as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we review related research in the area of code mixing and emotion prediction.", "labels": [], "entities": [{"text": "code mixing", "start_pos": 56, "end_pos": 67, "type": "TASK", "confidence": 0.7679883241653442}, {"text": "emotion prediction", "start_pos": 72, "end_pos": 90, "type": "TASK", "confidence": 0.781235009431839}]}, {"text": "In Section 3, we describe the corpus creation and annotation scheme.", "labels": [], "entities": [{"text": "corpus creation", "start_pos": 30, "end_pos": 45, "type": "TASK", "confidence": 0.7159991413354874}]}, {"text": "In Section 4, we discuss the data statistics.", "labels": [], "entities": []}, {"text": "In Section 5, we summarize our classification system which includes the pre-processing steps and construction of feature vector.", "labels": [], "entities": []}, {"text": "In Section 6, we present the results of experiments conducted using various character-level, word-level and lexicon features.", "labels": [], "entities": []}, {"text": "In the last section, we conclude our paper, followed by future work and the references.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to determine the effect of each feature on classification, we performed several experiments by elimination one feature at a time.", "labels": [], "entities": [{"text": "classification", "start_pos": 52, "end_pos": 66, "type": "TASK", "confidence": 0.9628094434738159}]}, {"text": "In all the experiments, we carried out 10-fold cross-validation.", "labels": [], "entities": []}, {"text": "We performed experiments using SVM classifier with radial basis function.", "labels": [], "entities": [{"text": "SVM classifier", "start_pos": 31, "end_pos": 45, "type": "TASK", "confidence": 0.6083483994007111}]}, {"text": "The results of the experiments performed after eliminating one feature at a time (i.e., Ablation test to test interaction of feature sets) and using the above-mentioned classifier are mentioned in.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.970866858959198}]}, {"text": "Since the size of feature vectors formed are very large, we applied chi-square feature selection algorithm which reduces the size of our feature vector to 1600 7 . In our system, we have used SVM with RBF kernel as they perform efficiently in case of high dimensional feature vectors.", "labels": [], "entities": []}, {"text": "For training our system classifier, we have used Scikit-learn).", "labels": [], "entities": []}, {"text": "The results from shows that Character N-Grams, Punctuation Marks, Word NGrams, Emoticons and Upper Case Words are the features which affect the accuracy most.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 144, "end_pos": 152, "type": "METRIC", "confidence": 0.9992259740829468}]}, {"text": "We were able to achieve the best accuracy of 58.2% using the Character N-Grams, Word N-grams, Punctuation Marks and Emoticons as features trained with SVM classifier.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9994934797286987}]}], "tableCaptions": [{"text": " Table 1: Inter Annotator Agreement.", "labels": [], "entities": [{"text": "Inter Annotator Agreement", "start_pos": 10, "end_pos": 35, "type": "DATASET", "confidence": 0.8146729469299316}]}, {"text": " Table 4: Weights assigned to classes", "labels": [], "entities": []}, {"text": " Table 5: Impact of each feature on the classification  accuracy of emotion in the text calculated by eliminat- ing one feature at a time.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9602609276771545}]}]}