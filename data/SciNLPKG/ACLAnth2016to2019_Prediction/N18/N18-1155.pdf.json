{"title": [{"text": "Higher-order Syntactic Attention Network for Long Sentence Compression", "labels": [], "entities": [{"text": "Syntactic Attention", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.7431885600090027}]}], "abstractContent": [{"text": "Sentence compression methods based on LSTM can generate fluent compressed sentences.", "labels": [], "entities": [{"text": "Sentence compression", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8864859938621521}]}, {"text": "However, the performance of these methods is significantly degraded when compressing long sentences since it does not explicitly handle syntactic features.", "labels": [], "entities": []}, {"text": "To solve this problem, we propose a higher-order syntactic attention network (HiSAN) that can handle higher-order dependency features as an attention distribution on LSTM hidden states.", "labels": [], "entities": []}, {"text": "Furthermore , to avoid the influence of incorrect parse results, we train HiSAN by maximizing the probability of a correct output together with the attention distribution.", "labels": [], "entities": []}, {"text": "Experiments on the Google sentence compression dataset show that our method achieved the best performance in terms of F 1 as well as ROUGE-1,2 and L scores, 83.2, 82.9, 75.8 and 82.7, respectively.", "labels": [], "entities": [{"text": "Google sentence compression dataset", "start_pos": 19, "end_pos": 54, "type": "DATASET", "confidence": 0.7849377542734146}, {"text": "F 1", "start_pos": 118, "end_pos": 121, "type": "METRIC", "confidence": 0.9827921390533447}, {"text": "ROUGE-1,2 and L scores", "start_pos": 133, "end_pos": 155, "type": "METRIC", "confidence": 0.7555860951542854}]}, {"text": "In subjective evaluations, HiSAN outper-formed baseline methods in both readabil-ity and informativeness.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sentence compression is the task of compressing long sentences into short and concise ones by deleting words.", "labels": [], "entities": [{"text": "Sentence compression", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9081381559371948}]}, {"text": "To generate compressed sentences that are grammatical, many researchers) have adopted tree trimming methods.", "labels": [], "entities": [{"text": "tree trimming", "start_pos": 86, "end_pos": 99, "type": "TASK", "confidence": 0.800316721200943}]}, {"text": "Even though Filippova and reported the best results on this task, automatic parse errors greatly degrade the performances of these tree trimming methods.", "labels": [], "entities": [{"text": "tree trimming", "start_pos": 131, "end_pos": 144, "type": "TASK", "confidence": 0.7482390701770782}]}, {"text": "We used an LSTM-based sentence compression method () in the evaluation setting as described in Section 4.1.", "labels": [], "entities": [{"text": "LSTM-based sentence compression", "start_pos": 11, "end_pos": 42, "type": "TASK", "confidence": 0.6492207149664561}]}, {"text": "Recently, proposed an LSTM sequence-to-sequence (Seq2Seq) based sentence compression method that can generate fluent sentences without utilizing any syntactic features.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 64, "end_pos": 84, "type": "TASK", "confidence": 0.7434272170066833}]}, {"text": "Therefore, Seq2Seq based sentence compression is a promising alternative to tree trimming.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 25, "end_pos": 45, "type": "TASK", "confidence": 0.717502698302269}, {"text": "tree trimming", "start_pos": 76, "end_pos": 89, "type": "TASK", "confidence": 0.7178787291049957}]}, {"text": "However, as reported fora machine translation task (, the longer the input sentences are, the worse the Seq2Seq performances become.", "labels": [], "entities": [{"text": "machine translation task", "start_pos": 26, "end_pos": 50, "type": "TASK", "confidence": 0.7592519819736481}]}, {"text": "We also observed this problem in the sentence compression task.", "labels": [], "entities": [{"text": "sentence compression task", "start_pos": 37, "end_pos": 62, "type": "TASK", "confidence": 0.839604119459788}]}, {"text": "As shown in, the performance of Seq2Seq is degraded when compressing long sentences.", "labels": [], "entities": []}, {"text": "In particular, the performance significantly falls if sentence length exceeds 26 words.", "labels": [], "entities": []}, {"text": "This is an important problem, because sentences longer than the average sentence length (=28 words) accounts for 42% of the Google sentence compression dataset.", "labels": [], "entities": [{"text": "Google sentence compression dataset", "start_pos": 124, "end_pos": 159, "type": "DATASET", "confidence": 0.7201428115367889}]}, {"text": "As shown in, long sentences have deep Pakistan signed a resolution on Monday to import 1,300 MW of electricity from Kyrgyz Republic and Tajikistan to overcome power shortage in summer season ...", "labels": [], "entities": []}, {"text": "dependency trees, which have long distances from root node to words at leaf nodes.", "labels": [], "entities": []}, {"text": "Therefore, improving compression performance for sentences with such deep dependency trees can help to compress longer sentences.", "labels": [], "entities": []}, {"text": "To deal with sentences that have deep dependency trees, we focus on the chains of dependency relationships.", "labels": [], "entities": []}, {"text": "shows an example of a compressed sentence with its dependency tree.", "labels": [], "entities": []}, {"text": "The topic of this sentence is import agreement related to electricity.", "labels": [], "entities": []}, {"text": "Thus, to generate informative compression, the compressed sentence must retain the country name.", "labels": [], "entities": [{"text": "informative compression", "start_pos": 18, "end_pos": 41, "type": "TASK", "confidence": 0.7958120107650757}]}, {"text": "In this example, the compressed sentence should keep the phrase \"from Kyrgyz Republic and Tajikistan\".", "labels": [], "entities": []}, {"text": "Thus, the compressed sentence must also keep the dependency chain \"import\", \"resolution\" and \"signed\" because the phrase is a child of this chain.", "labels": [], "entities": []}, {"text": "By considering such higher-order dependency chains, the system can implement informative compression.", "labels": [], "entities": [{"text": "informative compression", "start_pos": 77, "end_pos": 100, "type": "TASK", "confidence": 0.7420859634876251}]}, {"text": "As can be seen from the example in, tracking a higher-order dependency chain for each word would help to compress long sentences.", "labels": [], "entities": []}, {"text": "This paper refers to such dependency relationships by the expression \"d-length dependency chains\".", "labels": [], "entities": []}, {"text": "To handle a d-length dependency chain for sentence compression with LSTM, we propose the higher-order syntactic attention network (HiSAN).", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 42, "end_pos": 62, "type": "TASK", "confidence": 0.7242022603750229}]}, {"text": "HiSAN computes the deletion probability fora given word based on the d-length dependency chain starting from the word.", "labels": [], "entities": [{"text": "HiSAN", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.853693962097168}]}, {"text": "The d-length dependency chain is represented as an attention distribution, learned using automatic parse trees.", "labels": [], "entities": []}, {"text": "To alleviate the influence of parse errors in automatic parse trees, we learn the attention distribution together with deletion probability.", "labels": [], "entities": []}, {"text": "Evaluation results on the Google sentence compression dataset show that HiSAN achieved the best F 1 , ROUGE-1,2 and L scores 83.2, 82.9, 75.8 and 82.7, respectively.", "labels": [], "entities": [{"text": "Google sentence compression dataset", "start_pos": 26, "end_pos": 61, "type": "DATASET", "confidence": 0.7293046563863754}, {"text": "HiSAN", "start_pos": 72, "end_pos": 77, "type": "DATASET", "confidence": 0.7801501154899597}, {"text": "F 1", "start_pos": 96, "end_pos": 99, "type": "METRIC", "confidence": 0.9840752184391022}, {"text": "ROUGE-1,2 and L scores 83.2", "start_pos": 102, "end_pos": 129, "type": "METRIC", "confidence": 0.7903915822505951}]}, {"text": "In particular, HiSAN attained remarkable compression performance with long sentences.", "labels": [], "entities": [{"text": "HiSAN", "start_pos": 15, "end_pos": 20, "type": "DATASET", "confidence": 0.7270051836967468}]}, {"text": "In human evaluations, HiSAN also outperformed the baseline methods.", "labels": [], "entities": []}], "datasetContent": [{"text": "This evaluation used the Google sentence compression dataset . This dataset contains information of compression labels, part-of-speech (POS) tags, dependency parents and dependency relation labels for each sentence.", "labels": [], "entities": [{"text": "Google sentence compression dataset", "start_pos": 25, "end_pos": 60, "type": "DATASET", "confidence": 0.7009542286396027}]}, {"text": "We used the first and last 1,000 sentences of comp-data.eval.json as our test and development datasets, respectively.", "labels": [], "entities": []}, {"text": "Note that our test dataset is compatible wth that used in previous studies (.", "labels": [], "entities": []}, {"text": "In this paper, we trained the following baselines and HiSAN on all sentences of sent-comp.train * .json (total 200,000 sentences) 6,7,8 . In our experiments, we replaced rare words that appear fewer than 10 times in our training dataset with a special token \u27e8UNK\u27e9.", "labels": [], "entities": [{"text": "HiSAN", "start_pos": 54, "end_pos": 59, "type": "METRIC", "confidence": 0.5152487754821777}]}, {"text": "After this filtering, the input vocabulary size was 23, 168.", "labels": [], "entities": []}, {"text": "In the automatic evaluation, we used token level F 1 -measure (F 1 ) as well as recall of ROUGE-1, ROUGE-2 and ROUGE-L ( as evaluation measures.", "labels": [], "entities": [{"text": "token level F 1 -measure (F 1 )", "start_pos": 37, "end_pos": 68, "type": "METRIC", "confidence": 0.7815369576215744}, {"text": "recall", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.9988532066345215}, {"text": "ROUGE-1", "start_pos": 90, "end_pos": 97, "type": "METRIC", "confidence": 0.8024706244468689}]}, {"text": "We used \u2206C = system compression ratio \u2212 gold compression ratio to evaluate how close the compression ratio of system outputs was to that of gold compressed sentences.", "labels": [], "entities": [{"text": "gold compression ratio", "start_pos": 40, "end_pos": 62, "type": "METRIC", "confidence": 0.6915969451268514}]}, {"text": "The average compression ratio of the gold compression for input sentence was 39.8.", "labels": [], "entities": [{"text": "compression ratio", "start_pos": 12, "end_pos": 29, "type": "METRIC", "confidence": 0.9755612015724182}]}, {"text": "We used micro-average for F 1 -measure and compression ratio 10 , and macroaverage for ROUGE scores, respectively.", "labels": [], "entities": [{"text": "F 1 -measure", "start_pos": 26, "end_pos": 38, "type": "METRIC", "confidence": 0.9805040061473846}, {"text": "compression ratio 10", "start_pos": 43, "end_pos": 63, "type": "METRIC", "confidence": 0.978428304195404}, {"text": "macroaverage", "start_pos": 70, "end_pos": 82, "type": "METRIC", "confidence": 0.8842827677726746}, {"text": "ROUGE", "start_pos": 87, "end_pos": 92, "type": "METRIC", "confidence": 0.9962115287780762}]}, {"text": "To verify the benefits of our methods on long sentences, we additionally report scores on sentences longer than the average sentence length) in the test set.", "labels": [], "entities": []}, {"text": "The average compression ratio of the gold compression for longer input sentences was 31.4.", "labels": [], "entities": [{"text": "compression ratio", "start_pos": 12, "end_pos": 29, "type": "METRIC", "confidence": 0.9749023616313934}]}, {"text": "All results are reported as the average scores of five trials.", "labels": [], "entities": []}, {"text": "In each trial, different random choices were used to generate the initial values of the embeddings and the order of mini-batch processing.: Results of automatic evaluation.", "labels": [], "entities": []}, {"text": "ALL and LONG represent, respectively, the results in all sentences and long sentences (longer than average length 28) in the test dataset.", "labels": [], "entities": [{"text": "ALL", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9709964394569397}, {"text": "LONG", "start_pos": 8, "end_pos": 12, "type": "METRIC", "confidence": 0.9932577610015869}]}, {"text": "d represents the groups of d-length dependency chains.", "labels": [], "entities": []}, {"text": "* indicates the model that achieved the best score among the same methods with different din the development dataset . Bold values indicate the best scores.", "labels": [], "entities": []}, {"text": "ROUGE, and \u2206C in all settings.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9685385227203369}]}, {"text": "The F 1 scores of HiSAN (ALL) were higher than the current stateof-the-art score of .82, reported by.", "labels": [], "entities": [{"text": "F 1", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9909737408161163}, {"text": "HiSAN (ALL)", "start_pos": 18, "end_pos": 29, "type": "METRIC", "confidence": 0.5742999687790871}]}, {"text": "The improvements in F 1 and ROUGE scores from the baselines methods in the LONG setting are larger than those in the ALL setting.", "labels": [], "entities": [{"text": "F 1", "start_pos": 20, "end_pos": 23, "type": "METRIC", "confidence": 0.9916359782218933}, {"text": "ROUGE", "start_pos": 28, "end_pos": 33, "type": "METRIC", "confidence": 0.9847598671913147}, {"text": "LONG setting", "start_pos": 75, "end_pos": 87, "type": "DATASET", "confidence": 0.7079073488712311}]}, {"text": "\u00bfFrom these results, we can conclude that d-length dependency chains are effective for sentence compression, especially in the case of longer than average sentences.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 87, "end_pos": 107, "type": "TASK", "confidence": 0.7463187426328659}]}, {"text": "HiSAN (d = {1}) outperformed HiSAN-Dep in F 1 scores in ALL and LONG settings.", "labels": [], "entities": [{"text": "HiSAN", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9017998576164246}, {"text": "F 1 scores", "start_pos": 42, "end_pos": 52, "type": "METRIC", "confidence": 0.9351300398508707}]}, {"text": "This result shows the effectiveness of joint learning the dependency parse tree and the output labels.", "labels": [], "entities": []}, {"text": "In the human evaluation, we compared the baselines with our method, which achieved the highest F 1 score in the automatic evaluations.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 95, "end_pos": 104, "type": "METRIC", "confidence": 0.9921756386756897}]}, {"text": "We used the first 100 sentences that were longer than the average sentence length (= 28) in the test set for human evaluation.", "labels": [], "entities": []}, {"text": "Similar to, the compressed sentence was rated by five raters who were asked to select a rating on a five-point Likert scale, ranging from one to five for readability (Read) and for informativeness (Info).", "labels": [], "entities": []}, {"text": "We report the average of these scores from the five raters.", "labels": [], "entities": []}, {"text": "To investigate the differences between the methods, we also compared the baseline meth-: Results of human evaluations.", "labels": [], "entities": []}, {"text": "All denotes results for all sentences in the test set, and Diff denotes results for the sentences for which the methods yielded different compressed sentences.", "labels": [], "entities": [{"text": "Diff", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.9922343492507935}]}, {"text": "Parentheses ( ) denote sentence size.", "labels": [], "entities": [{"text": "Parentheses", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9269633889198303}]}, {"text": "CR denotes the compression ratio.", "labels": [], "entities": [{"text": "CR", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.9575302004814148}, {"text": "compression ratio", "start_pos": 15, "end_pos": 32, "type": "METRIC", "confidence": 0.9884807467460632}]}, {"text": "The average gold compression ratio for input sentence in All and Diff were 32.1 and 31.5, respectively.", "labels": [], "entities": [{"text": "gold compression ratio", "start_pos": 12, "end_pos": 34, "type": "METRIC", "confidence": 0.8092471162478129}]}, {"text": "Other notations are similar to those in ods and HiSAN using the sentences for which the methods yielded different compressed sentences.", "labels": [], "entities": [{"text": "HiSAN", "start_pos": 48, "end_pos": 53, "type": "DATASET", "confidence": 0.8860034346580505}]}, {"text": "HiSAN (d = {1, 2, 4}) achieved better results than the baselines in terms of both readability and informativeness.", "labels": [], "entities": [{"text": "HiSAN", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.871222972869873}]}, {"text": "The results agree with those obtained from the automatic evaluations.", "labels": [], "entities": []}, {"text": "\u00bfFrom the results on the sentences whose compressed sentences were different between Base and HiSAN (d = {1, 2, 4}), we can clearly observe the improvement attained by) in informativeness.", "labels": [], "entities": [{"text": "HiSAN", "start_pos": 94, "end_pos": 99, "type": "DATASET", "confidence": 0.8670637011528015}]}], "tableCaptions": [{"text": " Table 1: Results of automatic evaluation. ALL and LONG represent, respectively, the results in all  sentences and long sentences (longer than average length 28) in the test dataset. d represents the groups  of d-length dependency chains.  *  indicates the model that achieved the best score among the same  methods with different d in the development dataset", "labels": [], "entities": [{"text": "ALL", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.9795183539390564}, {"text": "LONG", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.9846706390380859}]}, {"text": " Table 2: Results of human evaluations. All de- notes results for all sentences in the test set, and  Diff denotes results for the sentences for which the  methods yielded different compressed sentences.  Parentheses ( ) denote sentence size. CR denotes  the compression ratio. The average gold compres- sion ratio for input sentence in All and Diff were  32.1 and 31.5, respectively. Other notations are  similar to those in", "labels": [], "entities": [{"text": "CR", "start_pos": 243, "end_pos": 245, "type": "METRIC", "confidence": 0.9626454710960388}]}, {"text": " Table 4: Results of automatic evaluation using  sentences with deep dependency trees (deeper than  average depth 8). Bold results indicate the best  scores.", "labels": [], "entities": []}]}