{"title": [{"text": "Neural Particle Smoothing for Sampling from Conditional Sequence Models", "labels": [], "entities": [{"text": "Neural Particle Smoothing", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6744955579439799}, {"text": "Sampling from Conditional Sequence", "start_pos": 30, "end_pos": 64, "type": "TASK", "confidence": 0.8142892867326736}]}], "abstractContent": [{"text": "We introduce neural particle smoothing, a sequential Monte Carlo method for sampling annotations of an input string from a given probability model.", "labels": [], "entities": [{"text": "neural particle smoothing", "start_pos": 13, "end_pos": 38, "type": "TASK", "confidence": 0.6754429936408997}]}, {"text": "In contrast to conventional particle filtering algorithms, we train a proposal distribution that looks ahead to the end of the input string by means of a right-to-left LSTM.", "labels": [], "entities": [{"text": "particle filtering", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.737069845199585}]}, {"text": "We demonstrate that this innovation can improve the quality of the sample.", "labels": [], "entities": []}, {"text": "To motivate our formal choices, we explain how our neural model and neural sampler can be viewed as low-dimensional but nonlinear approximations to working with HMMs over very large state spaces.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many structured prediction problems in NLP can be reduced to labeling a length-T input string x with a length-T sequence y of tags.", "labels": [], "entities": [{"text": "structured prediction", "start_pos": 5, "end_pos": 26, "type": "TASK", "confidence": 0.7045521140098572}]}, {"text": "In some cases, these tags are annotations such as syntactic parts of speech.", "labels": [], "entities": []}, {"text": "In other cases, they represent actions that incrementally build an output structure: IOB tags build a chunking of the input), shift-reduce actions build a tree, and finite-state transducer arcs build an output string.", "labels": [], "entities": []}, {"text": "One may wish to score the possible taggings using a recurrent neural network, which can learn to be sensitive to complex patterns in the training data.", "labels": [], "entities": []}, {"text": "A globally normalized conditional probability model is particularly valuable because it quantifies uncertainty and does not suffer from label bias (); also, such models often arise as the predictive conditional distribution p(y | x) corresponding to some well-designed generative model p(x, y) for the domain.", "labels": [], "entities": []}, {"text": "In the neural case, however, inference in such models becomes intractable.", "labels": [], "entities": []}, {"text": "It is hard to know what the model actually predicts and hard to compute gradients to improve its predictions.", "labels": [], "entities": []}, {"text": "In such intractable settings, one generally falls back on approximate inference or sampling.", "labels": [], "entities": []}, {"text": "In the NLP community, beam search and importance sampling are common.", "labels": [], "entities": [{"text": "beam search", "start_pos": 22, "end_pos": 33, "type": "TASK", "confidence": 0.8818255066871643}, {"text": "importance sampling", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.7219837605953217}]}, {"text": "Unfortunately, beam search considers only the approximate-top-k taggings from an exponential set (, and importance sampling requires the construction of a good proposal distribution (.", "labels": [], "entities": [{"text": "beam search", "start_pos": 15, "end_pos": 26, "type": "TASK", "confidence": 0.9628548622131348}]}, {"text": "In this paper we exploit the sequential structure of the tagging problem to do sequential importance sampling, which resembles beam search in that it constructs its proposed samples incrementally-one tag at a time, taking the actual model into account at every step.", "labels": [], "entities": [{"text": "beam search", "start_pos": 127, "end_pos": 138, "type": "TASK", "confidence": 0.768132358789444}]}, {"text": "This method is known as particle filtering.", "labels": [], "entities": [{"text": "particle filtering", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.9414885640144348}]}, {"text": "We extend it hereto take advantage of the fact that the sampler has access to the entire input string as it constructs its tagging, which allows it to look ahead or-as we will showto use a neural network to approximate the effect of lookahead.", "labels": [], "entities": []}, {"text": "Our resulting method is called neural particle smoothing.", "labels": [], "entities": [{"text": "neural particle smoothing", "start_pos": 31, "end_pos": 56, "type": "TASK", "confidence": 0.6378101507822672}]}], "datasetContent": [{"text": "To evaluate our methods, we needed pre-trained models p \u03b8 . We experimented on several models.", "labels": [], "entities": []}, {"text": "In each case, we trained a generative model p \u03b8 (x, y), so that we could try sampling from its posterior distribution p \u03b8 (y | x).", "labels": [], "entities": []}, {"text": "This is a very common setting where particle smoothing should be able to help.", "labels": [], "entities": [{"text": "particle smoothing", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.8698429763317108}]}, {"text": "Details for replication are given in Appendix C. tural\" goal of sampling.", "labels": [], "entities": [{"text": "replication", "start_pos": 12, "end_pos": 23, "type": "TASK", "confidence": 0.835928201675415}]}, {"text": "This objective can tolerate inaccurate local proposal distributions in cases where the algorithm could recover from them through resampling.", "labels": [], "entities": []}, {"text": "Looking even farther downstream, we might merely want\u02c6pwant\u02c6 want\u02c6p-which is typically used to compute expectations-to provide accurate guidance to some decision or training process (see Appendix E).", "labels": [], "entities": []}, {"text": "This might not require fully matching the model, and might even make it desirable to deviate from an inaccurate model.", "labels": [], "entities": []}, {"text": "Training a single approximation q \u03c6 for all x is known as amortized inference.", "labels": [], "entities": []}, {"text": "The normalizing constant of p from (1) can be ignored because the gradient of a constant is 0.", "labels": [], "entities": []}, {"text": "In our experiments, we are given a pre-trained scoring model p \u03b8 , and we train the parameters \u03c6 of a particle smoothing algorithm.", "labels": [], "entities": [{"text": "particle smoothing", "start_pos": 102, "end_pos": 120, "type": "TASK", "confidence": 0.673650935292244}]}, {"text": "We now show that our proposed neural particle smoothing sampler does better than the particle filtering sampler.", "labels": [], "entities": []}, {"text": "To define \"better,\" we evaluate samplers on the offset KL divergence from the true posterior.", "labels": [], "entities": [{"text": "offset KL divergence", "start_pos": 48, "end_pos": 68, "type": "METRIC", "confidence": 0.7873063087463379}]}, {"text": "Given x, the \"natural\" goal of conditional sampling is for the sample distribution\u02c6pdistribution\u02c6 distribution\u02c6p(y) to approximate the true distribution p \u03b8 (y | x) = exp G T / exp H 0 from (1).", "labels": [], "entities": []}, {"text": "We will therefore report-averaged overall held-out test examples x-the KL divergence where\u02dcpwhere\u02dc where\u02dcp(y | x) denotes the unnormalized distribution given by exp G T in, and Z(x) denotes its normalizing constant, exp H 0 = y \u02dc p(y | x).", "labels": [], "entities": [{"text": "KL divergence", "start_pos": 71, "end_pos": 84, "type": "TASK", "confidence": 0.6943119764328003}]}, {"text": "As we are unable to compute log Z(x) in practice, we replace it with an estimate z(x) to obtain an offset KL divergence.", "labels": [], "entities": []}, {"text": "This change of constant does not change the measured difference between two samplers, KL(\u02c6 p 1 ||p) \u2212 KL(\u02c6 p 2 ||p).", "labels": [], "entities": []}, {"text": "Nonetheless, we try to use a reasonable estimate so that the reported KL divergence is interpretable in an absolute sense.", "labels": [], "entities": [{"text": "KL divergence", "start_pos": 70, "end_pos": 83, "type": "TASK", "confidence": 0.6728747487068176}]}, {"text": "Specifically, we take z(x) = log y\u2208Y\u02dcpy\u2208Y\u02dc y\u2208Y\u02dcp(y | x) \u2264 log Z, where Y is the full set of distinct particles y that we ever drew for input x, including samples from the beam search models, while constructing the experimental results graph.", "labels": [], "entities": []}, {"text": "Thus, the offset KL divergence is a \"best effort\" lower bound on the true exclusive KL divergence KL(\u02c6 p||p).", "labels": [], "entities": []}], "tableCaptions": []}