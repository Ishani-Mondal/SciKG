{"title": [{"text": "Deconfounded Lexicon Induction for Interpretable Social Science", "labels": [], "entities": [{"text": "Deconfounded Lexicon Induction", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7179871400197347}, {"text": "Interpretable Social Science", "start_pos": 35, "end_pos": 63, "type": "TASK", "confidence": 0.622398853302002}]}], "abstractContent": [{"text": "NLP algorithms are increasingly used in computational social science to take linguistic observations and predict outcomes like human preferences or actions.", "labels": [], "entities": []}, {"text": "Making these social models transparent and interpretable often requires identifying features in the input that predict outcomes while also controlling for potential confounds.", "labels": [], "entities": []}, {"text": "We formalize this need as anew task: inducing a lexicon that is predic-tive of a set of target variables yet uncorre-lated to a set of confounding variables.", "labels": [], "entities": []}, {"text": "We introduce two deep learning algorithms for the task.", "labels": [], "entities": []}, {"text": "The first uses a bifurcated architecture to separate the explanatory power of the text and confounds.", "labels": [], "entities": []}, {"text": "The second uses an adversarial discriminator to force confound-invariant text encodings.", "labels": [], "entities": []}, {"text": "Both elicit lexicons from learned weights and attentional scores.", "labels": [], "entities": []}, {"text": "We use them to induce lexicons that are predictive of timely responses to consumer complaints (controlling for product), enrollment from course descriptions (controlling for subject), and sales from product descriptions (controlling for seller).", "labels": [], "entities": []}, {"text": "In each domain our algorithms pick words that are associated with narrative persuasion; more predictive and less confound-related than those of standard feature weighting and lexicon induction techniques like regression and log odds.", "labels": [], "entities": []}], "introductionContent": [{"text": "Applications of NLP to computational social science and data science increasingly use lexical features (words, prefixes, etc) to help predict nonlinguistic outcomes like sales, stock prices, hospital readmissions, and other human actions or preferences.", "labels": [], "entities": []}, {"text": "Lexical features are useful beyond predictive performance.", "labels": [], "entities": []}, {"text": "They enhance interpretability in machine learning because practitioners know why their system works.", "labels": [], "entities": []}, {"text": "Lexical features can also be used to understand the subjective properties of a text.", "labels": [], "entities": []}, {"text": "For social models, we need to be able to select lexical features that predict the desired outcome(s) while also controlling for potential confounders.", "labels": [], "entities": []}, {"text": "For example, we might want to know which words in a product description lead to greater sales, regardless of the item's price.", "labels": [], "entities": []}, {"text": "Words in a description like \"luxury\" or \"bargain\" might increase sales but also interact with our confound (price).", "labels": [], "entities": []}, {"text": "Such words don't reflect the unique part of text's effect on sales and should not be selected.", "labels": [], "entities": []}, {"text": "Similarly, we might want to know which words in a consumer complaint lead to speedy administrative action, regardless of the product being complained about; which words in a course description lead to higher student enrollment, regardless of the course topic.", "labels": [], "entities": []}, {"text": "These instances are associated with narrative persuasion: language that is responsible for altering cognitive responses or attitudes.", "labels": [], "entities": []}, {"text": "In general, we want words which are predictive of their targets yet decorrelated from confounding information.", "labels": [], "entities": []}, {"text": "The lexicons constituted by these words are useful in their own right (to develop causal domain theories or for linguistic analysis) but also as interpretable features for down-stream modeling.", "labels": [], "entities": [{"text": "linguistic analysis", "start_pos": 112, "end_pos": 131, "type": "TASK", "confidence": 0.7203467786312103}]}, {"text": "Such work could help widely in applications of NLP to tasks like linking text to sales figures (), to voter preference, to moral belief (, to police respect (, to financial outlooks (, to stock prices (, and even to restaurant health inspections (.", "labels": [], "entities": []}, {"text": "Identifying linguistic features that are indicative of such outcomes and decorrelated with confounds is a common activity among social scientists, data scientists, and other machine learning practitioners.", "labels": [], "entities": []}, {"text": "Indeed, it is essential for developing transpar-ent and interpretable machine learning NLP models.", "labels": [], "entities": []}, {"text": "Yet there is no generally accepted and rigorously evaluated procedure for the activity.", "labels": [], "entities": []}, {"text": "Practitioners have conducted it on a largely ad-hoc basis, applying various forms of logistic and linear regression, confound-matching, or association quantifiers like mutual information or log-odds to achieve their aims, all of which have known drawbacks.", "labels": [], "entities": []}, {"text": "We propose to overcome these drawbacks via two new algorithms that consider the causal structure of the problem.", "labels": [], "entities": []}, {"text": "The first uses its architecture to learn the part of the text's effect which the confounds cannot explain.", "labels": [], "entities": []}, {"text": "The second uses an adversarial objective function to match text encoding distributions regardless of confound treatment.", "labels": [], "entities": []}, {"text": "Both elicit lexicons by considering learned weights or attentional scores.", "labels": [], "entities": []}, {"text": "In summary, we 1.", "labels": [], "entities": []}, {"text": "Formalize the problem into anew task.", "labels": [], "entities": []}, {"text": "2. Propose a pair of well-performing neural network based algorithms.", "labels": [], "entities": []}, {"text": "3. Conduct the first systematic comparison of algorithms in the space, spanning three domains: consumer complaints, course enrollments, and e-commerce product descriptions.", "labels": [], "entities": []}, {"text": "The techniques presented in this paper will help scientists (1) better interpret the relationship between words and real-world phenomena, and (2) render their NLP models more interpretable 1 .", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the approaches described in Sections 3 and 5 by generating and evaluating deconfounded lexicons in three domains: financial complaints, e-commerce product descriptions, and course descriptions.", "labels": [], "entities": []}, {"text": "In each case the goal is to find words which can always help someone net a positive outcome (fulfillment, sales, enrollment), regardless of their situation.", "labels": [], "entities": []}, {"text": "This involves finding words associated with narrative persuasion: predictive of human decisions or preferences but decorrelated from non-linguistic information which could also explain things.", "labels": [], "entities": []}, {"text": "We analyze the resulting lexicons, especially with respect to the classic Aristotelian modes of persuasion: logos, pathos, and ethos.", "labels": [], "entities": []}, {"text": "We compare the following algorithms: Regression (R), Regression with Confound features (RC), Mixed effects Regression (M), Residualizing Regressions (RR), Log-Odds Ratio (OR), Mutual Information (MI), and MI/OR with regresssion (R+MI and R+OR).", "labels": [], "entities": [{"text": "Residualizing Regressions (RR)", "start_pos": 123, "end_pos": 153, "type": "METRIC", "confidence": 0.800268828868866}, {"text": "Log-Odds Ratio (OR)", "start_pos": 155, "end_pos": 174, "type": "METRIC", "confidence": 0.6700983941555023}]}, {"text": "See Section 5 fora discussion of these baselines, and the online supplementary information for implementation details.", "labels": [], "entities": []}, {"text": "We also compare the proposed algorithms: Deep Residualization using word frequencies (DR+BOW) and embeddings (DR+ATTN), and Adversarial Selection using word frequencies (A+BOW) and embeddings (A+ATTN).", "labels": [], "entities": [{"text": "Deep Residualization", "start_pos": 41, "end_pos": 61, "type": "TASK", "confidence": 0.7718045711517334}, {"text": "ATTN", "start_pos": 113, "end_pos": 117, "type": "METRIC", "confidence": 0.5723898410797119}]}, {"text": "In Section 2 we observed that I(L) measures the improvement in predictive power that L(T ) affords a model already having access to C.", "labels": [], "entities": [{"text": "I(L)", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.9340832531452179}]}, {"text": "Thus, we evaluate each algorithm by (1) regressing C on Y , (2) drawing a lexicon L, (3) regressing C + L(T ) on Y , and (4) measuring the size of gap in test prediction error between the models of step (1) and (3).", "labels": [], "entities": []}, {"text": "For classification problems, we measured error with cross-entropy (XE): And for regression, we computed the mean squared error (MSE): Because we fix lexicon size but vary lexicon content, lexicons with good words will score highly under this metric, yielding the large performance improvements when combined with C.", "labels": [], "entities": [{"text": "mean squared error (MSE)", "start_pos": 108, "end_pos": 132, "type": "METRIC", "confidence": 0.8993209799130758}]}, {"text": "We also report the average strength of association between words in Land C. For categorical confounds, we measure Cramer's V (V ), and for continuous confounds, we use the point-biserial correlation coefficient (r pb ) (.", "labels": [], "entities": [{"text": "point-biserial correlation coefficient", "start_pos": 172, "end_pos": 210, "type": "METRIC", "confidence": 0.660541315873464}]}, {"text": "Note that r pb is mathematically equivalent to Pearson correlation in bivariate settings.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 47, "end_pos": 66, "type": "METRIC", "confidence": 0.8616705536842346}]}, {"text": "Here the best lexicons will score the lowest.", "labels": [], "entities": []}, {"text": "We implemented neural models with the Tensorflow framework () and optimized using Adam ().", "labels": [], "entities": []}, {"text": "We implemented linear models with the scikit learn package).", "labels": [], "entities": []}, {"text": "We implemented mixed models with the lme4 R package ().", "labels": [], "entities": []}, {"text": "We refer to the online supplementary materials for per-experiment hyperparameters.", "labels": [], "entities": []}, {"text": "For each dataset, we constructed vocabularies from the 10,000 most frequently occurring tokens, and randomly selected 2,000 examples for evaluation.", "labels": [], "entities": []}, {"text": "We then conducted a wide hyperparameter search and used lexicon performance on the evaluation set to select final model parameters.", "labels": [], "entities": []}, {"text": "We then used these parameters to induce lexicons from 500 random train/test splits.", "labels": [], "entities": []}, {"text": "Significance is estimated with a bootstrap procedure: we counted the number of trials each algorithm \"won\" (i.e. had the largest error C \u2212 error L(T ),C ).", "labels": [], "entities": []}, {"text": "We also report the average performance and correlation of all the lexicons generated from each split.", "labels": [], "entities": [{"text": "correlation", "start_pos": 43, "end_pos": 54, "type": "METRIC", "confidence": 0.9898165464401245}]}, {"text": "We ran these experiments using lexicon sizes of k = 50, 150, 250, and 500 and observed similar behavior.", "labels": [], "entities": []}, {"text": "The results reported in the following sections are fork = 150, and the words in are from randomly selected lexicons (other lexicons had similar characteristics).", "labels": [], "entities": [{"text": "fork", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.9965023994445801}]}], "tableCaptions": []}