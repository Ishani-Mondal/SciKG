{"title": [{"text": "Enhanced Word Representations for Bridging Anaphora Resolution", "labels": [], "entities": [{"text": "Enhanced Word Representations", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7176010012626648}, {"text": "Bridging Anaphora Resolution", "start_pos": 34, "end_pos": 62, "type": "TASK", "confidence": 0.9077075521151224}]}], "abstractContent": [{"text": "Most current models of word representations (e.g., GloVe) have successfully captured fine-grained semantics.", "labels": [], "entities": []}, {"text": "However, semantic similarity exhibited in these word embeddings is not suitable for resolving bridging anaphora, which requires the knowledge of associative similarity (i.e., relatedness) instead of semantic similarity information between synonyms or hypernyms.", "labels": [], "entities": []}, {"text": "We create word embeddings (embeddings PP) to capture such relatedness by exploring the syntactic structure of noun phrases.", "labels": [], "entities": []}, {"text": "We demonstrate that using embed-dings PP alone achieves around 30% of accuracy for bridging anaphora resolution on the ISNotes corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9994332194328308}, {"text": "bridging anaphora resolution", "start_pos": 83, "end_pos": 111, "type": "TASK", "confidence": 0.6660360097885132}, {"text": "ISNotes corpus", "start_pos": 119, "end_pos": 133, "type": "DATASET", "confidence": 0.9719476997852325}]}, {"text": "Furthermore, we achieve a substantial gain over the state-of-the-art system (Hou et al., 2013b) for bridging antecedent selection.", "labels": [], "entities": []}], "introductionContent": [{"text": "Bridging) establishes entity coherence in a text by linking anaphors and antecedents via various nonidentity relations.", "labels": [], "entities": []}, {"text": "In Example 1, the link between the bridging anaphor (the chief cabinet secretary) and the antecedent (Japan) establish local (entity) coherence.", "labels": [], "entities": []}, {"text": "(1) Yet another political scandal is racking Japan.", "labels": [], "entities": []}, {"text": "On Friday, the chief cabinet secretary announced that eight cabinet ministers had received five million yen from the industry.", "labels": [], "entities": []}, {"text": "Choosing the right antecedents for bridging anaphors is a subtask of bridging resolution.", "labels": [], "entities": [{"text": "bridging resolution", "start_pos": 69, "end_pos": 88, "type": "TASK", "confidence": 0.863696962594986}]}, {"text": "For this substask, most previous work () calculate semantic relatedness between an anaphor and its antecedent based on word co-occurrence count using certain syntactic patterns.", "labels": [], "entities": []}, {"text": "Most recently, word embeddings gain a lot popularity in NLP community because they reflect human intuitions about semantic similarity and relatedness.", "labels": [], "entities": []}, {"text": "Most word representation models explore the distributional hypothesis which states that words occurring in similar contexts have similar meanings.", "labels": [], "entities": [{"text": "word representation", "start_pos": 5, "end_pos": 24, "type": "TASK", "confidence": 0.7322477549314499}]}, {"text": "State-of-theart word representations such as word2vec skipgram ( and GloVe) have been shown to perform well across a variety of NLP tasks, including textual entailment (, reading comprehension (, and information status classification.", "labels": [], "entities": [{"text": "information status classification", "start_pos": 200, "end_pos": 233, "type": "TASK", "confidence": 0.7550445795059204}]}, {"text": "However, these word embeddings capture both \"genuine\" similarity and relatedness, and they may in some cases be detrimental to downstream performance (.", "labels": [], "entities": []}, {"text": "Bridging anaphora resolution is one of such cases which requires lexical association knowledge instead of semantic similarity information between synonyms or hypernyms.", "labels": [], "entities": [{"text": "Bridging anaphora resolution", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8823415835698446}]}, {"text": "In Example 1, among all antecedent candidates, \"the chief cabinet secretary\" is the most similar word to the bridging anaphor \"eight cabinet ministers\" but obviously it is not the antecedent for the latter.", "labels": [], "entities": []}, {"text": "In this paper, we explore the syntactic structure of noun phrases (NPs) to derive contexts for nouns in the GloVe model.", "labels": [], "entities": []}, {"text": "We find that the prepositional structure (e.g., X of Y) and the possessive structure (e.g., Y's X) area useful context source for the representation of nouns in terms of relatedness for bridging relations.", "labels": [], "entities": []}, {"text": "We demonstrate that using our word embeddings based on PP contexts (embeddings PP) alone achieves around 30% of accuracy on bridging anaphora resolution in the ISNotes corpus, which is 12% better than the original GloVe word embeddings.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.999276340007782}, {"text": "ISNotes corpus", "start_pos": 160, "end_pos": 174, "type": "DATASET", "confidence": 0.9128675162792206}]}, {"text": "Moreover, adding an additional feature based on embeddings PP leads to a significant improvement over a state-of-the-art system on 1 bridging anaphora resolution ().", "labels": [], "entities": []}], "datasetContent": [{"text": "For the task of bridging anaphora resolution, we use the dataset ISNotes 2 released by.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.7172921299934387}]}, {"text": "This dataset contains around 11,000 NPs annotated for information status including 663 bridging NPs and their antecedents in 50 texts taken from the WSJ portion of the OntoNotes corpus ().", "labels": [], "entities": [{"text": "WSJ portion of the OntoNotes corpus", "start_pos": 149, "end_pos": 184, "type": "DATASET", "confidence": 0.8821067015329996}]}, {"text": "It is notable that bridging anaphors in ISNotes are not limited to definite NPs as in previous work).", "labels": [], "entities": []}, {"text": "The semantic relations between anaphor and antecedent in the corpus are quite diverse: only 14% of anaphors have a part-of/attribute-of relation with the antecedent and only 7% of anaphors stand in a set relationship to the antecedent.", "labels": [], "entities": []}, {"text": "79% of anaphors have \"other\" relation with their antecedents, without further distinction.", "labels": [], "entities": []}, {"text": "This includes encyclopedic relations such as the waiter -restaurant as well as context-specific relations such as the thieves -palms.", "labels": [], "entities": []}, {"text": "We follow's experimental setup and reimplement MLN model II as our baseline.", "labels": [], "entities": []}, {"text": "We first test the effectiveness of embeddings PP alone to resolve bridging anaphors.", "labels": [], "entities": []}, {"text": "Then we show that incorporating embeddings PP into MLN model II significantly improves the result.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Target words and their top five nearest neighbors in embeddings PP and GloVe Giga", "labels": [], "entities": []}, {"text": " Table 3: Results of integrating embeddings PP into MLN model II for bridging anaphora resolution compared  to the baselines. Bold indicates statistically significant differences over the baselines using randomization test  (p < 0.01).", "labels": [], "entities": []}]}