{"title": [], "abstractContent": [{"text": "Inferring missing links in knowledge graphs (KG) has attracted a lot of attention from the research community.", "labels": [], "entities": [{"text": "Inferring missing links in knowledge graphs (KG)", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.8083200984530978}]}, {"text": "In this paper, we tackle a practical query answering task involving predicting the relation of a given entity pair.", "labels": [], "entities": [{"text": "query answering task", "start_pos": 37, "end_pos": 57, "type": "TASK", "confidence": 0.8303975661595663}]}, {"text": "We frame this prediction problem as an inference problem in a probabilistic graphical model and aim at resolving it from a variational inference perspective.", "labels": [], "entities": []}, {"text": "In order to model the relation between the query entity pair, we assume that there exists an underlying latent variable (paths connecting two nodes) in the KG, which carries the equivalent semantics of their relations.", "labels": [], "entities": []}, {"text": "However, due to the intractability of connections in large KGs, we propose to use variation inference to maximize the evidence lower bound.", "labels": [], "entities": []}, {"text": "More specifically, our framework (DIVA) is composed of three modules, i.e. a posterior approximator, a prior (path finder), and a likelihood (path reasoner).", "labels": [], "entities": []}, {"text": "By using variational inference, we are able to incorporate them closely into a unified architecture and jointly optimize them to perform KG reasoning.", "labels": [], "entities": [{"text": "KG reasoning", "start_pos": 137, "end_pos": 149, "type": "TASK", "confidence": 0.8105934858322144}]}, {"text": "With active interactions among these sub-modules, DIVA is better at handling noise and coping with more complex reasoning scenarios.", "labels": [], "entities": []}, {"text": "In order to evaluate our method, we conduct the experiment of the link prediction task on multiple datasets and achieve state-of-the-art performances on both datasets.", "labels": [], "entities": [{"text": "link prediction task", "start_pos": 66, "end_pos": 86, "type": "TASK", "confidence": 0.8154502312342325}]}], "introductionContent": [{"text": "Large-scaled knowledge graph supports a lot of downstream natural language processing tasks like question answering, response generation, etc.", "labels": [], "entities": [{"text": "question answering", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.8685020804405212}, {"text": "response generation", "start_pos": 117, "end_pos": 136, "type": "TASK", "confidence": 0.7656262218952179}]}, {"text": "However, there are large amount of important facts missing in existing KG, which has significantly limited the capability of KG's application.", "labels": [], "entities": []}, {"text": "Therefore, automated reasoning, or the ability for computing systems to make new inferences from the observed evidence, has attracted lots of attention from the research community.", "labels": [], "entities": [{"text": "automated reasoning", "start_pos": 11, "end_pos": 30, "type": "TASK", "confidence": 0.7039512246847153}]}, {"text": "In recent years, there are surging interests in designing machine learning algorithms for complex reasoning tasks, especially in large knowledge graphs (KGs) where the countless entities and links have posed great challenges to traditional logic-based algorithms.", "labels": [], "entities": []}, {"text": "Specifically, we situate our study in this large KG multi-hop reasoning scenario, where the goal is to design an automated inference model to complete the missing links between existing entities in large KGs.", "labels": [], "entities": [{"text": "KG multi-hop reasoning", "start_pos": 49, "end_pos": 71, "type": "TASK", "confidence": 0.6388288935025533}]}, {"text": "For examples, if the KG contains a fact like president(BarackObama, USA) and spouse(Michelle, BarackObama), then we would like the machines to complete the missing link livesIn(Michelle, USA) automatically.", "labels": [], "entities": []}, {"text": "Systems for this task are essential to complex question answering applications.", "labels": [], "entities": [{"text": "question answering", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.8507178425788879}]}, {"text": "To tackle the multi-hop link prediction problem, various approaches have been proposed.", "labels": [], "entities": [{"text": "multi-hop link prediction", "start_pos": 14, "end_pos": 39, "type": "TASK", "confidence": 0.7074342966079712}]}, {"text": "Some earlier works like PRA () use bounded-depth random walk with restarts to obtain paths.", "labels": [], "entities": []}, {"text": "More recently, DeepPath ( and MIN-ERVA (, frame the path-finding problem as a Markov Decision Process (MDP) and utilize reinforcement learning (RL) to maximize the expected return.", "labels": [], "entities": []}, {"text": "Another line of work along with ours are Chain-of-Reasoning ( and Compositional Reasoning (, which take multi-hop chains learned by PRA as input and aim to infer its relation.", "labels": [], "entities": []}, {"text": "Here we frame the KG reasoning task as a two sub-steps, i.e. \"Path-Finding\" and \"PathReasoning\".", "labels": [], "entities": [{"text": "KG reasoning task", "start_pos": 18, "end_pos": 35, "type": "TASK", "confidence": 0.8768108487129211}]}, {"text": "We found that most of the related research is only focused on one step, which leads to major drawbacks-lack of interactions between these two steps.", "labels": [], "entities": []}, {"text": "More specifically, DeepPath () and MINERVA ( can be interpreted as enhancing the \"Path-Finding\" step while compositional reasoning () and chains of rea-soning ( can be interpreted as enhancing the \"Path-Reasoning\" step.", "labels": [], "entities": [{"text": "MINERVA", "start_pos": 35, "end_pos": 42, "type": "METRIC", "confidence": 0.7666082978248596}]}, {"text": "DeepPath is trained to find paths more efficiently between two given entities while being agnostic to whether the entity pairs are positive or negative, whereas MIN-ERVA learns to reach target nodes given an entityquery pair while being agnostic to the quality of the searched path . In contrast, chains of reasoning and compositional reasoning only learn to predict relation given paths while being agnostic to the path-finding procedure.", "labels": [], "entities": [{"text": "DeepPath", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8992094397544861}]}, {"text": "The lack of interaction prevents the model from understanding more diverse inputs and make the model very sensitive to noise and adversarial samples.", "labels": [], "entities": []}, {"text": "In order to increase the robustness of existing KG reasoning model and handle noisier environments, we propose to combine these two steps together as a whole from the perspective of the latent variable graphic model.", "labels": [], "entities": [{"text": "KG reasoning", "start_pos": 48, "end_pos": 60, "type": "TASK", "confidence": 0.5916315317153931}]}, {"text": "This graphic model views the paths as discrete latent variables and relation as the observed variables with a given entity pair as the condition, thus the path-finding module can be viewed as a prior distribution to infer the underlying links in the KG.", "labels": [], "entities": []}, {"text": "In contrast, the pathreasoning module can be viewed as the likelihood distribution, which classifies underlying links into multiple classes.", "labels": [], "entities": []}, {"text": "With this assumption, we introduce an approximate posterior and design a variational auto-encoder ( algorithm to maximize the evidence lower-bound.", "labels": [], "entities": []}, {"text": "This variational framework closely incorporates two modules into a unified framework and jointly train them together.", "labels": [], "entities": []}, {"text": "By active cooperations and interactions, the pathfinder can take into account the value of searched path and resort to the more meaningful paths.", "labels": [], "entities": []}, {"text": "Meanwhile, the path reasoner can receive more diverse paths from the pathfinder and generalizes better to unseen scenarios.", "labels": [], "entities": [{"text": "path reasoner", "start_pos": 15, "end_pos": 28, "type": "TASK", "confidence": 0.744828999042511}]}, {"text": "Our contributions are three-fold: \u2022 We introduce a variational inference framework for KG reasoning, which tightly integrates the path-finding and path-reasoning processes to perform joint reasoning.", "labels": [], "entities": [{"text": "KG reasoning", "start_pos": 87, "end_pos": 99, "type": "TASK", "confidence": 0.8847272992134094}]}, {"text": "\u2022 We have successfully leveraged negative samples into training and increase the robustness of existing KG reasoning model.", "labels": [], "entities": [{"text": "KG reasoning", "start_pos": 104, "end_pos": 116, "type": "TASK", "confidence": 0.8085143268108368}]}, {"text": "\u2022 We show that our method can scale up to large KG and achieve state-of-the-art results on two popular datasets.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follow.", "labels": [], "entities": []}, {"text": "In Section 2 we will outline related work on KG embedding, multi-hop reasoning, and variational auto-encoder.", "labels": [], "entities": []}, {"text": "We describe our variational knowledge reasoner DIVA in Section 3.", "labels": [], "entities": [{"text": "variational knowledge reasoner DIVA", "start_pos": 16, "end_pos": 51, "type": "TASK", "confidence": 0.7053974121809006}]}, {"text": "Experimental results are presented in Section 4, and we conclude in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the performance of DIVA, we explore the standard link prediction task on two differentsized KG datasets and compare with the state-ofthe-art algorithms.", "labels": [], "entities": [{"text": "link prediction", "start_pos": 61, "end_pos": 76, "type": "TASK", "confidence": 0.7187962681055069}, {"text": "KG datasets", "start_pos": 104, "end_pos": 115, "type": "DATASET", "confidence": 0.8103870451450348}]}, {"text": "Link prediction is to rank a list of target entities (e \u2212 1 , e \u2212 2 , \u00b7 \u00b7 \u00b7 , e + n ) given a query entity e q and query relation r q . The dataset is arranged in the format of (e q , r q , , and the evaluation score (Mean Averaged Precision, MAP) is based on the ranked position of the positive sample.", "labels": [], "entities": [{"text": "Link prediction", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.9013001918792725}, {"text": "Mean Averaged Precision, MAP)", "start_pos": 218, "end_pos": 247, "type": "METRIC", "confidence": 0.8973349531491598}]}, {"text": "We perform experiments on two datasets, and the details of the statistics are described in Table 1.", "labels": [], "entities": []}, {"text": "The samples of are sampled from), here we follow DeepPath () to select 20 relations including Sports, Locations, Film, etc.", "labels": [], "entities": [{"text": "DeepPath", "start_pos": 49, "end_pos": 57, "type": "DATASET", "confidence": 0.9245771169662476}]}, {"text": "Our NELL dataset is downloaded from the released dataset 2 , which contains 12 relations for evaluation.", "labels": [], "entities": [{"text": "NELL dataset", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.7802717387676239}]}, {"text": "Besides, both datasets contain negative samples obtained by using the PRA code released by.", "labels": [], "entities": [{"text": "PRA code", "start_pos": 70, "end_pos": 78, "type": "DATASET", "confidence": 0.6942368149757385}]}, {"text": "For each query r q , we remove all the triples with r q and r \u22121 q during reasoning.", "labels": [], "entities": []}, {"text": "During training, we set number of rollouts to 20 for each training sample and update the posterior distribution using Monte-Carlo REINFORCE algorithm.", "labels": [], "entities": [{"text": "REINFORCE", "start_pos": 130, "end_pos": 139, "type": "METRIC", "confidence": 0.9535130262374878}]}, {"text": "During testing, we use abeam of 5 to approximate the whole search space for pathfinder.", "labels": [], "entities": []}, {"text": "We follow MINERVA () to set the maximum reasoning length to 3, which lowers the burden for the path-reasoner model.", "labels": [], "entities": [{"text": "MINERVA", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.8309682607650757}]}, {"text": "For both datasets, we set the embedding size E to 200, the history embedding size H to 200, the convolution kernel feature size D to 128, we set the hidden size of MLP for both pathfinder and path reasoner to 400.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: MAP results on the NELL dataset. Since  MINERVA (Das et al., 2018) only takes 9 relations out  of the original 12 relations, we report the known results  for both version of NELL-995 dataset.", "labels": [], "entities": [{"text": "MAP", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.7157129049301147}, {"text": "NELL dataset", "start_pos": 29, "end_pos": 41, "type": "DATASET", "confidence": 0.7893597185611725}, {"text": "MINERVA", "start_pos": 50, "end_pos": 57, "type": "METRIC", "confidence": 0.6539707183837891}, {"text": "NELL-995 dataset", "start_pos": 184, "end_pos": 200, "type": "DATASET", "confidence": 0.8386054933071136}]}, {"text": " Table 3: Results on the FB15k dataset, please note that  MINERVA's result is obtained based on our own imple- mentation.", "labels": [], "entities": [{"text": "FB15k dataset", "start_pos": 25, "end_pos": 38, "type": "DATASET", "confidence": 0.9805847406387329}, {"text": "MINERVA", "start_pos": 58, "end_pos": 65, "type": "METRIC", "confidence": 0.9352036118507385}]}, {"text": " Table 4: HITS@N results on the FB15k dataset", "labels": [], "entities": [{"text": "HITS", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9054688215255737}, {"text": "FB15k dataset", "start_pos": 32, "end_pos": 45, "type": "DATASET", "confidence": 0.9816549122333527}]}, {"text": " Table 5: The three samples separately indicates three frequent error types, the first one belongs to \"duplicate  entity\", the second one belongs to \"missing entity\", while the last one is due to \"wrong reasoning\". Please note  that the parenthesis terms denote relations while the non-parenthesis terms denote entities.", "labels": [], "entities": []}]}