{"title": [{"text": "A Laypeople Study on Terminology Identification across Domains and Task Definitions", "labels": [], "entities": [{"text": "Terminology Identification", "start_pos": 21, "end_pos": 47, "type": "TASK", "confidence": 0.8925519585609436}]}], "abstractContent": [{"text": "This paper introduces anew dataset of term annotation.", "labels": [], "entities": []}, {"text": "Given that even experts vary significantly in their understanding of termhood, we offer a novel perspective to explore the common , natural understanding of what constitutes a term: Laypeople annotate single-word and multi-word terms, across four domains and across four task definitions.", "labels": [], "entities": []}, {"text": "Analyses based on inter-annotator agreement offer insights into differences in term specificity, term granular-ity and subtermhood.", "labels": [], "entities": []}], "introductionContent": [{"text": "Terms are linguistic units which characterize a specific topic domain, and their identification is relevant fora number of NLP tasks, such as information retrieval and automatic translation.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 142, "end_pos": 163, "type": "TASK", "confidence": 0.7955309450626373}, {"text": "automatic translation", "start_pos": 168, "end_pos": 189, "type": "TASK", "confidence": 0.7105278074741364}]}, {"text": "Not only the automatic extraction of terms is a challenging task, but also their manual definition and identification: while we find a range of gold standard corpora for the evaluation of term extraction systems for English ( and to a lesser extent also for German (, these benchmark datasets vary hugely in terms of granularity of term definition, topic and thematic focus.", "labels": [], "entities": [{"text": "term extraction", "start_pos": 188, "end_pos": 203, "type": "TASK", "confidence": 0.724055290222168}]}, {"text": "All datasets have in common that they have been annotated by domain experts and/or by terminologists, which is considered a necessary requirement for term evaluation.", "labels": [], "entities": []}, {"text": "However, shows that even experts with different perspectives on terminology (e.g., terminologists, domain experts, translators and documentalists) vary significantly in their annotation of terms.", "labels": [], "entities": []}, {"text": "Moreover, although individual studies describe different layers of terminology, there is alack of empirical studies.", "labels": [], "entities": []}, {"text": "This raises the question whether there is a common, natural understanding of what constitutes a term, and to what extent this term is associated to a domain.", "labels": [], "entities": []}, {"text": "In this study, we examine the concept of terminology from anew perspective.", "labels": [], "entities": []}, {"text": "Differently to previous annotation studies, we investigate judgments of laypeople, rather than experts, and specify on analyzing their (dis-)agreements on common assumptions and core issues in term identification: the word classes of terms, the identification of ambiguous terms, and the relations between complex terms and possibly included subterms.", "labels": [], "entities": [{"text": "term identification", "start_pos": 193, "end_pos": 212, "type": "TASK", "confidence": 0.7521167993545532}]}, {"text": "To ensure abroad understanding of term identification, we designed four different tasks to address the granularities of term concepts, and we performed all annotations across four different domains in German: diy, cooking, hunting, chess.", "labels": [], "entities": [{"text": "term identification", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.7218659073114395}]}, {"text": "Finally, we compare the annotations to the output of an unsupervised hybrid term extraction system.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Number of identified terms per task.", "labels": [], "entities": [{"text": "Number", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9557682871818542}]}, {"text": " Table 2: Annotation of compounds and MWTs.", "labels": [], "entities": []}, {"text": " Table 3: Annotation of compound and MWT subterms.", "labels": [], "entities": []}, {"text": " Table 4: Average agreement on ambiguous words.", "labels": [], "entities": [{"text": "Average", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9886307716369629}, {"text": "agreement", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.6272579431533813}]}]}