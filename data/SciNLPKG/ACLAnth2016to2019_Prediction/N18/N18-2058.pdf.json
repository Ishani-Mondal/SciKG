{"title": [{"text": "Semi-Supervised Event Extraction with Paraphrase Clusters", "labels": [], "entities": [{"text": "Semi-Supervised Event Extraction", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.5796449879805247}]}], "abstractContent": [{"text": "Supervised event extraction systems are limited in their accuracy due to the lack of available training data.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 11, "end_pos": 27, "type": "TASK", "confidence": 0.7762783765792847}, {"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9986870884895325}]}, {"text": "We present a method for self-training event extraction systems by boot-strapping additional training data.", "labels": [], "entities": [{"text": "self-training event extraction", "start_pos": 24, "end_pos": 54, "type": "TASK", "confidence": 0.6594444513320923}]}, {"text": "This is done by taking advantage of the occurrence of multiple mentions of the same event instances across newswire articles from multiple sources.", "labels": [], "entities": []}, {"text": "If our system can make a high-confidence extraction of some mentions in such a cluster, it can then acquire diverse training examples by adding the other mentions as well.", "labels": [], "entities": []}, {"text": "Our experiments show significant performance improvements on multiple event ex-tractors over ACE 2005 and TAC-KBP 2015 datasets.", "labels": [], "entities": [{"text": "ACE 2005", "start_pos": 93, "end_pos": 101, "type": "DATASET", "confidence": 0.9315235912799835}, {"text": "TAC-KBP 2015 datasets", "start_pos": 106, "end_pos": 127, "type": "DATASET", "confidence": 0.8561603824297587}]}], "introductionContent": [{"text": "Event extraction is a challenging task, which aims to discover event triggers in a sentence and classify them by type.", "labels": [], "entities": [{"text": "Event extraction", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7398627400398254}]}, {"text": "Training an event extraction system requires a large dataset of annotated event triggers and their types in a sentence.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 12, "end_pos": 28, "type": "TASK", "confidence": 0.719246044754982}]}, {"text": "Unfortunately, because of the large amount of different event types, each with its own set of annotation rules, such manual annotation is both time-consuming and expensive.", "labels": [], "entities": []}, {"text": "As a result, popular event datasets, such as ACE () and TAC-KBP (, are small (e.g., the median number of positive examples per subtype is only 65 and 86, respectively) and biased towards frequent event types, such as Attack.", "labels": [], "entities": [{"text": "ACE", "start_pos": 45, "end_pos": 48, "type": "DATASET", "confidence": 0.7995593547821045}, {"text": "TAC-KBP", "start_pos": 56, "end_pos": 63, "type": "METRIC", "confidence": 0.6581345200538635}]}, {"text": "When an event occurs, there are often multiple parallel descriptions of that event) available somewhere on the Web due to the large number of different news sources.", "labels": [], "entities": []}, {"text": "Some descriptions are simple, explaining in basic language the event that occurred.", "labels": [], "entities": []}, {"text": "These are often easier for existing extraction systems to identify.", "labels": [], "entities": []}, {"text": "Meanwhile, 1) LSU fires head coach Les Miles after 12 seasons.", "labels": [], "entities": []}, {"text": "2) Les Miles is out at LSU after 12 seasons in Baton Rouge.", "labels": [], "entities": []}, {"text": "3) On Sunday morning, LSU athletic director Joe Alleva told Les Miles that the coach would no longer represent Louisiana State.", "labels": [], "entities": []}, {"text": "other descriptions might use more complex language that falls outside the scope of typical event extractors, but which, if identified, could serve as valuable training data for said systems.", "labels": [], "entities": [{"text": "event extractors", "start_pos": 91, "end_pos": 107, "type": "TASK", "confidence": 0.7026680409908295}]}, {"text": "We automatically generate labeled training data for event trigger identification leveraging this wealth of event descriptions 1 . Specifically, we first group together paraphrases of event mentions.", "labels": [], "entities": [{"text": "event trigger identification", "start_pos": 52, "end_pos": 80, "type": "TASK", "confidence": 0.7368783156077067}]}, {"text": "We then use the simple examples in each cluster to assign a label to the entire cluster.", "labels": [], "entities": []}, {"text": "This simplifies the task of extracting events from difficult examples; rather than having to identify whether an event occurs, and which word serves as a trigger for that event, our system needs only to identify the most likely trigger for the given event.", "labels": [], "entities": []}, {"text": "Finally, we combine the new examples with the original training set and retrain the event extractor.", "labels": [], "entities": [{"text": "event extractor", "start_pos": 84, "end_pos": 99, "type": "TASK", "confidence": 0.6554072350263596}]}, {"text": "Our experiments show that this data can be used with limited amounts of gold data to achieve significant improvement over both standard and neural event extraction systems.", "labels": [], "entities": [{"text": "neural event extraction", "start_pos": 140, "end_pos": 163, "type": "TASK", "confidence": 0.6947829723358154}]}, {"text": "In particular, it achieves 1.1 and 1.3 point F1 improvements over a state-of-the-art system in trigger identification on TAC-KBP and ACE data respectively.", "labels": [], "entities": [{"text": "F1", "start_pos": 45, "end_pos": 47, "type": "METRIC", "confidence": 0.9995487332344055}, {"text": "trigger identification", "start_pos": 95, "end_pos": 117, "type": "TASK", "confidence": 0.8062712252140045}, {"text": "ACE data", "start_pos": 133, "end_pos": 141, "type": "DATASET", "confidence": 0.8967470824718475}]}, {"text": "Moreover, we show how the benefit of our method varies as a function of the amount of fully-supervised training data and the number of additional heuristicallylabeled examples.", "labels": [], "entities": []}], "datasetContent": [{"text": "Evaluation We report the micro-averaged F1 scores overall events.", "labels": [], "entities": [{"text": "F1", "start_pos": 40, "end_pos": 42, "type": "METRIC", "confidence": 0.9721603989601135}]}, {"text": "A trigger is considered correctly labeled if both its offsets and event type match those of a reference trigger.", "labels": [], "entities": []}, {"text": "Implementation details For creating the automatically-generated data, we set thresholds \u03b8 event and \u03b8 sim to 2 and 0.4 respectively, which were selected according to validation data.", "labels": [], "entities": []}, {"text": "We use CoreNLP () for named entity recognition, and we use a pre-trained Word2Vec model ( prediction with hidden layer size of 300.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 22, "end_pos": 46, "type": "TASK", "confidence": 0.6326403915882111}]}, {"text": "Finally, for training, We apply the stochastic gradient descent algorithm with mini-batches of size 50 and the AdaDelta update rule (Zeiler, 2012) with L 2 regularization.", "labels": [], "entities": []}, {"text": "For the CRF model, we maximize the conditional log likelihood of the training data with a loss function via softmax-margin (.", "labels": [], "entities": [{"text": "conditional log likelihood", "start_pos": 35, "end_pos": 61, "type": "METRIC", "confidence": 0.6280582646528879}]}, {"text": "We optimize using AdaGrad (Duchi et al., 2011) with L 2 regularization.", "labels": [], "entities": [{"text": "AdaGrad (Duchi et al., 2011)", "start_pos": 18, "end_pos": 46, "type": "DATASET", "confidence": 0.8749755471944809}]}, {"text": "Varying Amounts of Additional Data In this section we show that the addition of automatically-generated training examples improves the performance of both systems we tested it on.", "labels": [], "entities": [{"text": "Amounts", "start_pos": 8, "end_pos": 15, "type": "METRIC", "confidence": 0.9611113667488098}]}, {"text": "We sample examples from the automatically-generated data, limiting the total number of positive examples to a specific number.", "labels": [], "entities": []}, {"text": "In order to avoid biasing the system in favor of a specific event type, we ensure that the additional data has a uniform distribution of event types.", "labels": [], "entities": []}, {"text": "We run 10 trials at each point, and report average results.", "labels": [], "entities": []}, {"text": "reports the results of adding varying amounts of our generated data to both CRF and JRNN systems.", "labels": [], "entities": [{"text": "JRNN", "start_pos": 84, "end_pos": 88, "type": "DATASET", "confidence": 0.7295043468475342}]}, {"text": "We observe that that adding any amount of heuristically-generated data improves performance.", "labels": [], "entities": []}, {"text": "Optimal performance, however, is achieved fairly early in both datasets.", "labels": [], "entities": []}, {"text": "This is likely due to the domain mismatch between the gold and additional data.", "labels": [], "entities": []}, {"text": "For reference purposes, we also include the result of using the HNN model from) and the SSED system from: Adding a reasonable amount (200 examples per event) of semi-supervised data on top of limited amounts of gold training data improves performance across the board, but the gain is dramatic when the number of supervised examples is extremely small.", "labels": [], "entities": []}, {"text": "(, which are the best reported results on the ACE-2005 and TAC-KBP 2015 corpora respectively.", "labels": [], "entities": [{"text": "ACE-2005", "start_pos": 46, "end_pos": 54, "type": "DATASET", "confidence": 0.9653027057647705}, {"text": "TAC-KBP 2015 corpora", "start_pos": 59, "end_pos": 79, "type": "DATASET", "confidence": 0.8434093793233236}]}, {"text": "These systems could also benefit from our additional data since our approach is system independent.", "labels": [], "entities": []}, {"text": "Varying Amounts of Supervised Data In this section we evaluate how the benefit of adding semi-supervised data varies given different amounts of gold (supervised) data to start.", "labels": [], "entities": []}, {"text": "We conjecture that semi-supervision will be more beneficial when gold data is very limited, but the conclusion isn't obvious, since semi-supervision is more likely to add noisy examples in this case.", "labels": [], "entities": []}, {"text": "Specifically, we limit the number of positive gold examples for each event by randomly sampling the overall set.", "labels": [], "entities": []}, {"text": "We then add in the same amount of automatically-generated data to each trial.", "labels": [], "entities": []}, {"text": "We again run 10 trials for each size, and report the average.", "labels": [], "entities": []}, {"text": "The results for this experiment using the CRF model can be seen in: training with large amounts of semi-supervised data improves performance considerably when limited gold training data is available, but those gains diminish with more high-quality supervised data.", "labels": [], "entities": []}, {"text": "We observe the same trend for the JRNN system as well.", "labels": [], "entities": [{"text": "JRNN system", "start_pos": 34, "end_pos": 45, "type": "DATASET", "confidence": 0.9649074375629425}]}, {"text": "Discussion We randomly selected 100 examples from the automatically-generated data and manually annotated them.", "labels": [], "entities": []}, {"text": "For each example that did not contain a correctly labeled event mention, we further annotated wherein the pipeline an error occurred to cause the incorrect labeling.", "labels": [], "entities": []}, {"text": "This breakdown can be seen in table 2.", "labels": [], "entities": []}, {"text": "As observed in the table, the errors are mainly due to the incorrect event identification or trigger assignment.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results after adding varying amounts of  automatically-generated news data. Percentages indi- cate the amount of additional data relative to the size  of the gold training data. Using a modest amount of  semi-supervised data improves extractor performance  on both ACE & TAC-KBP events. * indicates that the  difference in F1 relative to training with just the gold  data is statistically significant (p < 0.05).", "labels": [], "entities": [{"text": "F1", "start_pos": 333, "end_pos": 335, "type": "METRIC", "confidence": 0.9994592070579529}]}]}