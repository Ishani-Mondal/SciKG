{"title": [{"text": "A Meaning-based Statistical English Math Word Problem Solver", "labels": [], "entities": [{"text": "Meaning-based Statistical English Math Word Problem Solver", "start_pos": 2, "end_pos": 60, "type": "TASK", "confidence": 0.625890348638807}]}], "abstractContent": [{"text": "We introduce MeSys, a meaning-based approach , for solving English math word problems (MWPs) via understanding and reasoning in this paper.", "labels": [], "entities": [{"text": "solving English math word problems (MWPs)", "start_pos": 51, "end_pos": 92, "type": "TASK", "confidence": 0.7730341926217079}]}, {"text": "It first analyzes the text, transforms both body and question parts into their corresponding logic forms, and then performs inference on them.", "labels": [], "entities": []}, {"text": "The associated context of each quantity is represented with proposed role-tags (e.g., nsubj, verb, etc.), which provides the flexibility for annotating an extracted math quantity with its associated context information (i.e., the physical meaning of this quantity).", "labels": [], "entities": []}, {"text": "Statistical models are proposed to select the operator and operands.", "labels": [], "entities": []}, {"text": "A noisy dataset is designed to assess if a solver solves MWPs mainly via understanding or mechanical pattern matching.", "labels": [], "entities": [{"text": "solver solves MWPs", "start_pos": 43, "end_pos": 61, "type": "TASK", "confidence": 0.9237356384595236}]}, {"text": "Experimental results show that our approach outperforms existing systems on both benchmark datasets and the noisy da-taset, which demonstrates that the proposed approach understands the meaning of each quantity in the text more.", "labels": [], "entities": []}], "introductionContent": [{"text": "The math word problem (MWP) (see) is frequently chosen to study natural language understanding and simulate human problem solving) for the following reasons: (1) the answer to the MWP cannot be simply extracted by performing keyword/pattern matching.", "labels": [], "entities": [{"text": "math word problem (MWP)", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.6709518333276113}, {"text": "natural language understanding and simulate human problem solving", "start_pos": 64, "end_pos": 129, "type": "TASK", "confidence": 0.7514249831438065}]}, {"text": "It thus shows the merit of understanding and inference.", "labels": [], "entities": []}, {"text": "(2) An MWP usually possesses less complicated syntax and requires less amount of domain knowledge, so the researchers can focus on the task of understanding and reasoning.", "labels": [], "entities": []}, {"text": "(3) The body part of MWP that provides the given information for solving the problem consists of only a few sentences.", "labels": [], "entities": []}, {"text": "The understanding and reasoning procedures thus could be more efficiently checked.", "labels": [], "entities": []}, {"text": "The MWP solver has its own applications such as Computer Math Tutor (for students in primary school) and Helper for Math in Daily Life (for adults who are not good in solving mathematics related real problems).", "labels": [], "entities": [{"text": "MWP solver", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.7377734184265137}]}, {"text": "According to the approaches used to identify entities, quantities, and to select operations and operands, previous MWP solvers can be classified into: (1) Rule-based approaches), which make all related decisions based on a set of rules; (2) Purely statistics-based approaches, in which all related decisions are done via a statistical classifier; (3) DNNbased approaches (, which map the given text into the corresponding math operation/equation via a DNN; and (4) Mixed approaches, which identify entities and quantities with rules, yet, decide operands and operations via statistical/DNN classifiers.", "labels": [], "entities": [{"text": "MWP solvers", "start_pos": 115, "end_pos": 126, "type": "TASK", "confidence": 0.8931867182254791}]}, {"text": "This category can be further divided into two subtypes: (a) Without understanding (), which does not check the entity-attribute consistency between each quantity and the target of the given question; and (b) With understanding (, which also checks the entity-attribute consistency while solving the problem.", "labels": [], "entities": []}, {"text": "It is a survey paper which reviews most of the rule-based approaches before 2008.", "labels": [], "entities": []}], "datasetContent": [{"text": "The AI2 dataset provided by and the IL dataset released by Roy and Roth (2015) are adopted to compare our approach with other state-of-the-art methods.", "labels": [], "entities": [{"text": "AI2 dataset", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.9070580005645752}, {"text": "IL dataset released by Roy and Roth (2015)", "start_pos": 36, "end_pos": 78, "type": "DATASET", "confidence": 0.9256764650344849}]}, {"text": "The AI2 dataset has 395 MWPs on addition and subtraction, with 121 MWPs containing irrelevant information ().", "labels": [], "entities": [{"text": "AI2 dataset", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.9511903822422028}]}, {"text": "It is the most popular one for comparing different approaches.", "labels": [], "entities": []}, {"text": "On the other hand, the IL dataset consists of 562 elementary MWPs which can be solved by one of the four arithmetic operations (i.e., +, \u2212, \u00d7, and \u00f7) without any irrelevant quantity.", "labels": [], "entities": [{"text": "IL dataset", "start_pos": 23, "end_pos": 33, "type": "DATASET", "confidence": 0.8194032311439514}]}, {"text": "It is the first publicly available dataset for comparing performances that covers all four arithmetic operations.", "labels": [], "entities": []}, {"text": "However, the difficulty of solving an MWP depends not only on the number of arithmetic operations required, but also on how many irrelevant quantities inside, and even on how the quantities are described.", "labels": [], "entities": []}, {"text": "One way to test if a proposed approach solves the MWPs with understanding is to check whether it is robust to those irrelevant quantities.", "labels": [], "entities": []}, {"text": "Therefore, it is desirable to have a big enough dataset that contains irrelevant quantities which are created under different situations (e.g., confusing with an irrelevant agent, entity, or modifier, etc.) and allow us to probe the system weakness from different angles.", "labels": [], "entities": []}, {"text": "We thus create anew dataset with more irrelevant quantities 8 . But before we do that, we need to know how difficult the task of solving the given MWPs is.", "labels": [], "entities": []}, {"text": "Therefore, we first propose away to measure how easy that a system solves the problem by simply guessing.", "labels": [], "entities": []}, {"text": "Human Math/Science tests have been considered more suitable for judging AI progress than Turing test.", "labels": [], "entities": []}, {"text": "In our task, solving MWPs is mainly regarded as a test for intelligence (not just for creating a Math Solver package).", "labels": [], "entities": [{"text": "solving MWPs", "start_pos": 13, "end_pos": 25, "type": "TASK", "confidence": 0.7985898554325104}]}, {"text": "By injecting various irrelevant quantities into original MWPs, a noisy dataset is thus created to assess if a solver solves the MWPs mainly via understanding or via mechanical/statistical pattern matching.", "labels": [], "entities": [{"text": "solver solves the MWPs", "start_pos": 110, "end_pos": 132, "type": "TASK", "confidence": 0.7322054505348206}]}, {"text": "If a system solves an MWP mainly via pattern matching, it would have difficulty in solving a similar MWP augmented from the original one with some irrelevant quantities.", "labels": [], "entities": []}, {"text": "Therefore, we first create a noisy dataset by selecting some MWPs that can be correctly solved, and then augmenting each of them with an additional noisy sentence which involves an irrelevant quantity.", "labels": [], "entities": []}, {"text": "This dataset is created to examine if the solver knows that this newly added quantity is irrelevant.", "labels": [], "entities": []}, {"text": "shows how we inject noise into an MWP (a).", "labels": [], "entities": []}, {"text": "(a.1) is created by associating an irrelevant quantity to anew subject (i.e., Mary).", "labels": [], "entities": []}, {"text": "Here the ellipse symbol \"\u2026\" denotes unchanged text.", "labels": [], "entities": []}, {"text": "(a.2) is obtained by associating an irrelevant quantity to anew entity (i.e., books).", "labels": [], "entities": []}, {"text": "In addition, we also change modifiers (such as yellow, red, \u2026) to add new noisy sentence (not shown here).", "labels": [], "entities": []}, {"text": "Since the noisy dataset is not designed to assess the lexicon coverage rate of a solver, we reuse the words in the original dataset as much as possible while adding new subjects, entities and modifiers.", "labels": [], "entities": []}, {"text": "136 MWPs that both Illinois Math Solver 12 (Roy and Roth, 2016) and our system can correctly solve are selected from the AI2 and IL datasets.", "labels": [], "entities": [{"text": "Illinois Math Solver 12 (Roy and Roth, 2016)", "start_pos": 19, "end_pos": 63, "type": "DATASET", "confidence": 0.8808982534842058}, {"text": "AI2 and IL datasets", "start_pos": 121, "end_pos": 140, "type": "DATASET", "confidence": 0.712039515376091}]}, {"text": "This subset is denoted as OSS (Original Sub-Set).", "labels": [], "entities": []}, {"text": "Afterwards, based on the 136 MWPs of OSS, we create a noisy dataset of 396 MWPs by adding irrelevant quantities.", "labels": [], "entities": [{"text": "OSS", "start_pos": 37, "end_pos": 40, "type": "DATASET", "confidence": 0.794788658618927}]}, {"text": "This noisy dataset is named as NDS . lists the size of MWPs, Perplexities (PP), and the average numbers of quantities in each MWP of these two datasets.", "labels": [], "entities": []}, {"text": "We compare our approach with (  and (Roy and Roth, 2017) because they achieved the state-of-the-art performance on the IL dataset.", "labels": [], "entities": [{"text": "IL dataset", "start_pos": 119, "end_pos": 129, "type": "DATASET", "confidence": 0.9667730927467346}]}, {"text": "In the approach of ( , each quantity in the MWP was associated with a quantity schema whose attributes are extracted from the context of the quantity.", "labels": [], "entities": []}, {"text": "Based on the attributes, several statistical classifiers were used to select operands and determine the operator.", "labels": [], "entities": []}, {"text": "They also reported the performances on the AI2 dataset to compare their approach with those of others (e.g.,, which is a purely statistical approach that aligns the text with various pre-extracted equation templates).", "labels": [], "entities": [{"text": "AI2 dataset", "start_pos": 43, "end_pos": 54, "type": "DATASET", "confidence": 0.9240595400333405}]}, {"text": "further introduced the concept of Unit Dependency Graphs to reinforce the consistency of physical units among selected operands associated with the same operator.", "labels": [], "entities": []}, {"text": "To compare the performance of the statistical method with the DNN approach, we only implement a Bi-directional RNN-based Solution Type Identifier (as our original statistical Operand Selector is relatively much better).", "labels": [], "entities": [{"text": "Bi-directional RNN-based Solution Type Identifier", "start_pos": 96, "end_pos": 145, "type": "METRIC", "confidence": 0.8375506639480591}]}, {"text": "It consists of a word embedding layer (for both body and question parts), and a bidirectional GRU layer as an encoder.", "labels": [], "entities": []}, {"text": "We apply the attention mechanism to scan all hidden state sequence of body by the last hidden state of question to pay more attention to those more important (i.e., more similar between the body and the question) words.", "labels": [], "entities": []}, {"text": "Lastly, it outputs the solution type by a softmax function.", "labels": [], "entities": []}, {"text": "We train it for 100 epochs, with mini-batch-size = 128 and learning-rate = 0.001; the number of nodes in the hidden layer is 200, and the drop-out rate is 0.7 . We follow the same n-fold cross-validation evaluation setting adopted in  exactly.", "labels": [], "entities": []}, {"text": "Therefore, various performances could be directly compared.", "labels": [], "entities": []}, {"text": "lists the accuracies of different systems in solving the MWPs Since the dataset is not large enough for splitting a development set, we choose those hyper parameters based on the test set in coarse grain.", "labels": [], "entities": []}, {"text": "Therefore, the DNN performance we show here might be a bit optimistic.", "labels": [], "entities": [{"text": "DNN performance", "start_pos": 15, "end_pos": 30, "type": "DATASET", "confidence": 0.9265530109405518}]}, {"text": "78.0 73.9 ( 64.0 73.7  . The results show that our performances of the statistical approach significantly outperform that of our DNN approach and other systems on every dataset.", "labels": [], "entities": []}, {"text": "The performances of STI and LFT modules are listed in.", "labels": [], "entities": []}, {"text": "As described in section 2, the benchmark for both solution type and the operand selection benchmark are automatically determined by weakly supervised learning.", "labels": [], "entities": []}, {"text": "The first and second rows of show the solution type accuracies of our statistical and DNN approaches, respectively.", "labels": [], "entities": []}, {"text": "The third row shows the operand selection accuracy obtained by given the solution type benchmark.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9703304767608643}]}, {"text": "Basically, LFT accuracies are from 92% to 95%, and the system accuracies are dominated by STI.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 15, "end_pos": 25, "type": "METRIC", "confidence": 0.5879004001617432}]}, {"text": "We analyzed errors resulted from our statistical STI on AI2 and IL datasets, respectively.", "labels": [], "entities": [{"text": "STI", "start_pos": 49, "end_pos": 52, "type": "METRIC", "confidence": 0.8303682208061218}, {"text": "AI2 and IL datasets", "start_pos": 56, "end_pos": 75, "type": "DATASET", "confidence": 0.659986101090908}]}, {"text": "For AI2, major errors come from: (1) failure of ruling out some irrelevant quantities (40%), and (2) making confusion between TVQ-F and Sum these two solution types (20%) for those cases that only involve addition operation (however, both types would return the same answer).", "labels": [], "entities": [{"text": "TVQ-F", "start_pos": 126, "end_pos": 131, "type": "DATASET", "confidence": 0.9760880470275879}]}, {"text": "For IL, major errors come from: (1) requiring additional information (35%), and (2) not knowing PartWhole relation (17%).", "labels": [], "entities": []}, {"text": "shows a few examples for different STI error types.", "labels": [], "entities": []}, {"text": "The left-half of shows the performances on the OSS and NDS datasets.", "labels": [], "entities": [{"text": "OSS and NDS datasets", "start_pos": 47, "end_pos": 67, "type": "DATASET", "confidence": 0.8066708296537399}]}, {"text": "Recall that OSS is created by selecting some MWPs which both Illinois Math Solver (Roy and Roth, 2016) and our system 16 can correctly solve.", "labels": [], "entities": [{"text": "OSS", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.9022502899169922}, {"text": "Illinois Math Solver", "start_pos": 61, "end_pos": 81, "type": "DATASET", "confidence": 0.9477441509564718}]}, {"text": "Therefore, both systems have 100% accuracy in solving the OSS dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9995490908622742}, {"text": "OSS dataset", "start_pos": 58, "end_pos": 69, "type": "DATASET", "confidence": 0.7512742280960083}]}, {"text": "However, these two systems behave very differently while solving the noisy dataset.", "labels": [], "entities": []}, {"text": "The much higher accuracy of our system on the noisy dataset shows that our meaning-based approach understands the meaning of each quantity more.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9993529915809631}]}, {"text": "Therefore, it is less confused 17 with the irrelevant quantities.", "labels": [], "entities": []}, {"text": "One MWP in the noisy dataset that confuses Illinois Math Solver (IMS) is \"Tom has 9 yellow balloons.", "labels": [], "entities": [{"text": "Illinois Math Solver (IMS)", "start_pos": 43, "end_pos": 69, "type": "TASK", "confidence": 0.6671674648920695}]}, {"text": "Sara has 8 yellow balloons.", "labels": [], "entities": []}, {"text": "Bob has 5 yellow flowers.", "labels": [], "entities": []}, {"text": "How many yellow balloons do they have in total?\", where the underlined sentence is the added noisy sentence.", "labels": [], "entities": []}, {"text": "The solver sums all quantities and gives the wrong answer 22, which reveals that IMS cannot understand that the quantity \"5 yellow flowers\" is irrelevant to the question \"How many yellow balloons?\".", "labels": [], "entities": [{"text": "solver", "start_pos": 4, "end_pos": 10, "type": "TASK", "confidence": 0.9569379687309265}, {"text": "IMS", "start_pos": 81, "end_pos": 84, "type": "DATASET", "confidence": 0.7722002267837524}]}, {"text": "On the contrary, our system avoids this mistake.", "labels": [], "entities": []}, {"text": "Although the meaning of each quantity is explicitly checked in our LFT module, our system still cannot correctly solve all MWPs in NDS.", "labels": [], "entities": []}, {"text": "The error analysis reveals that the top-4 error sources are STI, LFT, CoreNLP and incorrect problem construction (for 27%, 27%, 18%, 18%), which indicates that our STI and LFT still cannot completely prevent the damage caused from the noisy sentences (which implies that more consistency check for quantity meaning should be done).", "labels": [], "entities": []}, {"text": "The remaining errors are due to incorrect quantity extraction, lacking common-sense or not knowing entailment relationship between two entities.", "labels": [], "entities": [{"text": "quantity extraction", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.6930206716060638}]}, {"text": "A similar experiment is performed to check if the DNN approach will be affected by the noisy information more.", "labels": [], "entities": []}, {"text": "We first select 124 MWPs (denoted as OSS\u2032) from OSS that can be correctly solved by both our statistical and DNN approaches and then filter out 350 derived MWPs (denotes as NDS\u2032) from NDS.", "labels": [], "entities": []}, {"text": "The right-half of shows that the performance of the DNN approach drops more than the statistical approach does in the noisy dataset, which indicates that our statistical approach is less sensitive to the irrelevant quantities and more close to human's approach.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Performances of different STIs and LFT", "labels": [], "entities": []}, {"text": " Table 2: Performances of various approaches", "labels": [], "entities": []}, {"text": " Table 5: Performances on the OSS and NDS", "labels": [], "entities": [{"text": "OSS", "start_pos": 30, "end_pos": 33, "type": "DATASET", "confidence": 0.8774885535240173}, {"text": "NDS", "start_pos": 38, "end_pos": 41, "type": "DATASET", "confidence": 0.5645619630813599}]}, {"text": " Table 4: Examples for different STI error types", "labels": [], "entities": []}]}