{"title": [{"text": "Detecting and Resolving Shell Nouns in German", "labels": [], "entities": [{"text": "Detecting and Resolving Shell Nouns", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8385728478431702}]}], "abstractContent": [{"text": "This paper describes the design and evaluation of a system for the automatic detection and resolution of shell nouns in German.", "labels": [], "entities": [{"text": "automatic detection and resolution of shell nouns in German", "start_pos": 67, "end_pos": 126, "type": "TASK", "confidence": 0.8487211598290337}]}, {"text": "Shell nouns are general nouns, such as fact, question , or problem, whose full interpretation relies on a content phrase located elsewhere in a text, which these nouns simultaneously serve to characterize and encapsulate.", "labels": [], "entities": []}, {"text": "To accomplish this, the system uses a series of lexico-syntactic patterns in order to extract shell noun candidates and their content in parallel.", "labels": [], "entities": []}, {"text": "Each pattern has its own classifier, which makes the final decision as to whether or not a link is to be established and the shell noun resolved.", "labels": [], "entities": []}, {"text": "Overall, about 26.2% of the annotated shell noun instances were correctly identified by the system, and of these cases, about 72.5% are assigned the correct content phrase.", "labels": [], "entities": []}, {"text": "Though it remains difficult to identify shell noun instances reliably (recall is accordingly low in this regard), this system usually assigns the right content to correctly classified cases.", "labels": [], "entities": [{"text": "recall", "start_pos": 71, "end_pos": 77, "type": "METRIC", "confidence": 0.9989845156669617}]}], "introductionContent": [{"text": "The term shell noun refers to the way in which particular general nouns are used to characterize and encapsulate a complex chunk of information for later reference, which might ordinarily be realized by a verb phrase or a sentence).", "labels": [], "entities": []}, {"text": "Example (1) below represents atypical shell noun instance.", "labels": [], "entities": []}, {"text": "(1) Ich finde die Tatsache, dass es keine Dinosaurier mehr gibt, sehr traurig.", "labels": [], "entities": [{"text": "Tatsache", "start_pos": 18, "end_pos": 26, "type": "TASK", "confidence": 0.8840180039405823}]}, {"text": "'I find the fact that there are no more dinosaurs very sad.'", "labels": [], "entities": []}, {"text": "As this encapsulation of information coincides with an ability to link information across sentences, shell nouns are an important means of text Shell nouns are in boldface, content phrases underlined. or discourse coherence.", "labels": [], "entities": []}, {"text": "They are also relatively common: observes that many of the English nouns that can function as shell nouns are among the hundred most frequent nouns in the English language.", "labels": [], "entities": []}, {"text": "However, the complete interpretation of a particular shell noun instance is only possible together with the complex content to which it, in one way or another, 'refers'.", "labels": [], "entities": []}, {"text": "Shell nouns must be resolved to be properly interpreted.", "labels": [], "entities": []}, {"text": "Thus, the resolution of shell nouns and their content forms an essential part of any NLP system for which a degree of natural language understanding is necessary, including summarization, question answering, and sentiment analysis.", "labels": [], "entities": [{"text": "resolution of shell nouns and their content", "start_pos": 10, "end_pos": 53, "type": "TASK", "confidence": 0.8157705409186227}, {"text": "summarization", "start_pos": 173, "end_pos": 186, "type": "TASK", "confidence": 0.9842138290405273}, {"text": "question answering", "start_pos": 188, "end_pos": 206, "type": "TASK", "confidence": 0.854806125164032}, {"text": "sentiment analysis", "start_pos": 212, "end_pos": 230, "type": "TASK", "confidence": 0.9510254263877869}]}, {"text": "This paper will describe a system that was implemented with the aim of identifying which nouns in a given text act as shell nouns and establishing a link between these instances and the content they refer to and serve to characterize.", "labels": [], "entities": []}, {"text": "In contrast to previous attempts to resolve shell nouns, in which it was known which noun instances were to be considered shell nouns, the current system does not know a priori which nouns may act as shell nouns, and it does not know which of these potential shell noun instances actually require resolution.", "labels": [], "entities": []}, {"text": "The system therefore must simultaneously decide whether a given noun instance is acting as a shell noun and resolve it to its content.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to better understand the performance of this system, I will employ two baseline systems.", "labels": [], "entities": []}, {"text": "The Constant baseline uses a classifier that always accepts any shell noun candidate that matches some pattern.", "labels": [], "entities": [{"text": "Constant baseline", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.7106135785579681}]}, {"text": "It gives us an idea of what the maximum recall could be, given the current pattern set, and it also shows how far we can get using patterns alone.", "labels": [], "entities": [{"text": "recall", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.9979234933853149}]}, {"text": "The Stratified baseline approves, at random, a number of candidate cases proportional to the frequency of positive instances in its training data.", "labels": [], "entities": []}, {"text": "This baseline gives us an idea of the maximum precision and accuracy we can expect to achieve simply by choosing fewer positive cases.", "labels": [], "entities": [{"text": "precision", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.9991077780723572}, {"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9960391521453857}]}, {"text": "Here I measure two main aspects of the system's performance: To what degree are the noun instances classified correctly (regardless of the content assigned)?", "labels": [], "entities": []}, {"text": "(2) Of the instances that are correctly classified, how many are also assigned the correct content phrase?", "labels": [], "entities": []}, {"text": "Since the first question concerns classification performance, I use precision, recall, and F 1 score to answer this question.", "labels": [], "entities": [{"text": "classification", "start_pos": 34, "end_pos": 48, "type": "TASK", "confidence": 0.9578506350517273}, {"text": "precision", "start_pos": 68, "end_pos": 77, "type": "METRIC", "confidence": 0.9997099041938782}, {"text": "recall", "start_pos": 79, "end_pos": 85, "type": "METRIC", "confidence": 0.9994471669197083}, {"text": "F 1 score", "start_pos": 91, "end_pos": 100, "type": "METRIC", "confidence": 0.9929911692937216}]}, {"text": "As for the second question, since the patterns always suggest a content phrase and this can only be corrector incorrect, I only measure accuracy with respect to content phrases (\"Res\" in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 136, "end_pos": 144, "type": "METRIC", "confidence": 0.9992191791534424}]}, {"text": "The performance of the Constant baseline shows that the patterns alone cover only about half of the cases in the test data.", "labels": [], "entities": [{"text": "Constant baseline", "start_pos": 23, "end_pos": 40, "type": "DATASET", "confidence": 0.6949754804372787}]}, {"text": "This system correctly classifies about half of the instances matched by some pattern, resulting in a recall of 24.2%.", "labels": [], "entities": [{"text": "recall", "start_pos": 101, "end_pos": 107, "type": "METRIC", "confidence": 0.998728334903717}]}, {"text": "At the same time, the Naive Bayes classifier allows the system to produce significantly fewer false positives, and the resulting precision 56.4% is a significant improvement over both baselines.", "labels": [], "entities": [{"text": "precision", "start_pos": 129, "end_pos": 138, "type": "METRIC", "confidence": 0.9992938041687012}]}, {"text": "The improvement in the system's accuracy over the baseline (72.5% vs. 57.7%) also shows that the correct pattern classifiers, rather than simply the first matching patterns, tend to approve each instance, suggesting that the system has some ability to handle such confusing cases as in example (3).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9993114471435547}]}], "tableCaptions": [{"text": " Table 3: Comparing various feature sets.", "labels": [], "entities": []}]}