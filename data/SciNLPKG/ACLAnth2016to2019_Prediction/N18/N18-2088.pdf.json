{"title": [{"text": "Contextualized Word Representations for Reading Comprehension", "labels": [], "entities": [{"text": "Contextualized Word Representations", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.7658348878224691}]}], "abstractContent": [{"text": "Reading a document and extracting an answer to a question about its content has attracted substantial attention recently.", "labels": [], "entities": [{"text": "extracting an answer to a question about its content", "start_pos": 23, "end_pos": 75, "type": "TASK", "confidence": 0.5576918952994876}]}, {"text": "While most work has focused on the interaction between the question and the document, in this work we evaluate the importance of context when the question and document are processed independently.", "labels": [], "entities": []}, {"text": "We take a standard neural architecture for this task, and show that by providing rich contextualized word representations from a large pre-trained language model as well as allowing the model to choose between context-dependent and context-independent word representations , we can obtain dramatic improvements and reach performance comparable to state-of-the-art on the competitive SQUAD dataset.", "labels": [], "entities": [{"text": "SQUAD dataset", "start_pos": 383, "end_pos": 396, "type": "DATASET", "confidence": 0.8360502123832703}]}], "introductionContent": [{"text": "Reading comprehension (RC) is a high-level task in natural language understanding that requires reading a document and answering questions about its content.", "labels": [], "entities": [{"text": "Reading comprehension (RC)", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7794912695884705}, {"text": "natural language understanding", "start_pos": 51, "end_pos": 81, "type": "TASK", "confidence": 0.6348087092240652}]}, {"text": "RC has attracted substantial attention over the last few years with the advent of large annotated datasets (, computing resources, and neural network models and optimization procedures.", "labels": [], "entities": [{"text": "RC", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9366224408149719}]}, {"text": "Reading comprehension models must invariably represent word tokens contextually, as a function of their encompassing sequence (document or question).", "labels": [], "entities": []}, {"text": "The vast majority of RC systems encode contextualized representations of words in both the document and question as hidden states of bidirectional RNNs;), and focus model design and capacity around question-document interaction, carrying out calculations where information from both is available ().", "labels": [], "entities": []}, {"text": "Analysis of current RC models has shown that models tend to react to simple word-matching between the question and document, as well as benefit from explicitly providing matching information in model inputs (.", "labels": [], "entities": []}, {"text": "In this work, we hypothesize that the stillrelatively-small size of RC datasets drives this behavior, which leads to models that make limited use of context when representing word tokens.", "labels": [], "entities": []}, {"text": "To illustrate this idea, we take a model that carries out only basic question-document interaction and prepend to it a module that produces token embeddings by explicitly gating between contextual and non-contextual representations (for both the document and question).", "labels": [], "entities": []}, {"text": "This simple addition already places the model's performance on par with recent work, and allows us to demonstrate the importance of context.", "labels": [], "entities": []}, {"text": "Motivated by these findings, we turn to a semisupervised setting in which we leverage a language model, pre-trained on large amounts of data, as a sequence encoder which forcibly facilitates context utilization.", "labels": [], "entities": [{"text": "context utilization", "start_pos": 191, "end_pos": 210, "type": "TASK", "confidence": 0.7072257846593857}]}, {"text": "We find that model performance substantially improves, reaching accuracy comparable to state-of-the-art on the competitive SQuAD dataset, showing that contextual word representations captured by the language model are beneficial for reading comprehension.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9995560050010681}, {"text": "SQuAD dataset", "start_pos": 123, "end_pos": 136, "type": "DATASET", "confidence": 0.8753657341003418}]}], "datasetContent": [{"text": "We evaluate our contextualization scheme on the SQuAD dataset () which consists of 100,000+ paragraph-question-answer examples, crowdsourced from Wikipedia articles.", "labels": [], "entities": [{"text": "SQuAD dataset", "start_pos": 48, "end_pos": 61, "type": "DATASET", "confidence": 0.9073878228664398}]}, {"text": "Importance of context We are interested in evaluating the effect of our RNN-based reembedding scheme on the performance of the downstream base model.", "labels": [], "entities": []}, {"text": "However, the addition of the re-embedding module incurs additional depth and capacity for the resultant model.", "labels": [], "entities": []}, {"text": "We therefore compare this model, termed RaSoR + TR, to a setting in which re-embedding is non-contextual, referred to as RaSoR + TR(MLP).", "labels": [], "entities": []}, {"text": "Here we set u t = MLP(x t ), a multi-layered perceptron on x t , allowing for the additional computation to be carried out on word-level representations without any context and matching the model size and hyperparameter search budget of RaSoR + TR.", "labels": [], "entities": [{"text": "MLP", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.9252442121505737}]}, {"text": "In we compare these two variants over the development set and observe superior performance by the contextual one, illustrating the benefit of contextualization and specifically per-sequence contextualization which is done separately for the question and for the passage.", "labels": [], "entities": []}, {"text": "Context complements rare words Our formulation lends itself to an inspection of the different dynamic weightings computed by the model for interpolating between contextual and noncontextual terms.", "labels": [], "entities": []}, {"text": "In we plot the average gate value gt for each word-type, where the average is taken across entries of the gate vector and across all occurrences of the word in both passages: Results on SQuAD's development set.", "labels": [], "entities": [{"text": "SQuAD's development set", "start_pos": 186, "end_pos": 209, "type": "DATASET", "confidence": 0.6600418165326118}]}, {"text": "The EM metric measures an exact-match between a predicted answer and a correct one and the F1 metric measures the overlap between their bag of words. and questions.", "labels": [], "entities": [{"text": "EM metric", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.8869503140449524}, {"text": "F1 metric", "start_pos": 91, "end_pos": 100, "type": "METRIC", "confidence": 0.9862436354160309}]}, {"text": "This inspection reveals the following: On average, the less frequent a word-type is, the smaller are its gate activations, i.e., the reembedded representation of a rare word places less weight on its fixed word-embedding and more on its contextual representation, compared to a common word.", "labels": [], "entities": []}, {"text": "This highlights a problem with maintaining fixed word representations: albeit pretrained on extremely large corpora, the embeddings of rare words need to be complemented with information emanating from their context.", "labels": [], "entities": []}, {"text": "Our specific parameterization allows observing this directly, but it may very well bean implicit burden placed on any contextualizing encoder such as a vanilla BiLSTM.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results on SQuAD's development set. The  EM metric measures an exact-match between a pre- dicted answer and a correct one and the F1 metric mea- sures the overlap between their bag of words.", "labels": [], "entities": [{"text": "SQuAD's development set", "start_pos": 21, "end_pos": 44, "type": "DATASET", "confidence": 0.7084477245807648}, {"text": "EM metric", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9144347906112671}, {"text": "exact-match", "start_pos": 73, "end_pos": 84, "type": "METRIC", "confidence": 0.9706178903579712}, {"text": "F1 metric mea- sures", "start_pos": 140, "end_pos": 160, "type": "METRIC", "confidence": 0.8413761973381042}]}]}