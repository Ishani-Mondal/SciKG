{"title": [{"text": "Metric for Automatic Machine Translation Evaluation based on Universal Sentence Representations", "labels": [], "entities": [{"text": "Automatic Machine Translation Evaluation", "start_pos": 11, "end_pos": 51, "type": "TASK", "confidence": 0.7365030273795128}, {"text": "Universal Sentence Representations", "start_pos": 61, "end_pos": 95, "type": "TASK", "confidence": 0.5584892630577087}]}], "abstractContent": [{"text": "Sentence representations can capture a wide range of information that cannot be captured by local features based on character or word N-grams.", "labels": [], "entities": []}, {"text": "This paper examines the usefulness of universal sentence representations for evaluating the quality of machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 103, "end_pos": 122, "type": "TASK", "confidence": 0.7470449507236481}]}, {"text": "Although it is difficult to train sentence representations using small-scale translation datasets with manual evaluation, sentence representations trained from large-scale data in other tasks can improve the automatic evaluation of machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 232, "end_pos": 251, "type": "TASK", "confidence": 0.7222689092159271}]}, {"text": "Experimental results of the WMT-2016 dataset show that the proposed method achieves state-of-the-art performance with sentence representation features only.", "labels": [], "entities": [{"text": "WMT-2016 dataset", "start_pos": 28, "end_pos": 44, "type": "DATASET", "confidence": 0.9751747846603394}]}], "introductionContent": [{"text": "This paper describes a segment-level metric for automatic machine translation evaluation.", "labels": [], "entities": [{"text": "machine translation evaluation", "start_pos": 58, "end_pos": 88, "type": "TASK", "confidence": 0.8389742573102316}]}, {"text": "MTE metrics having a high correlation with human evaluation enable the continuous integration and deployment of a machine translation (MT) system.", "labels": [], "entities": [{"text": "MTE", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.902326762676239}, {"text": "machine translation (MT)", "start_pos": 114, "end_pos": 138, "type": "TASK", "confidence": 0.8466234683990479}]}, {"text": "Various MTE metrics have been proposed in the metrics task of the Workshops on Statistical Machine Translation (WMT) that was started in 2008.", "labels": [], "entities": [{"text": "MTE", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.9617867469787598}, {"text": "Statistical Machine Translation (WMT)", "start_pos": 79, "end_pos": 116, "type": "TASK", "confidence": 0.7625564833482107}]}, {"text": "However, most MTE metrics are obtained by computing the similarity between an MT hypothesis and a reference translation based on character N-grams or word N-grams, such as SentBLEU (), which is a smoothed version of BLEU (), Blend (, MEANT 2.0 (, and chrF++, which achieved excellent results in the WMT-2017 Metrics task).", "labels": [], "entities": [{"text": "MTE", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.9796883463859558}, {"text": "MT hypothesis", "start_pos": 78, "end_pos": 91, "type": "TASK", "confidence": 0.8866158127784729}, {"text": "BLEU", "start_pos": 216, "end_pos": 220, "type": "METRIC", "confidence": 0.9958303570747375}, {"text": "Blend", "start_pos": 225, "end_pos": 230, "type": "METRIC", "confidence": 0.729917585849762}, {"text": "WMT-2017 Metrics task", "start_pos": 299, "end_pos": 320, "type": "DATASET", "confidence": 0.8243603905042013}]}, {"text": "Therefore, they can exploit only limited information for segment-level MTE.", "labels": [], "entities": [{"text": "MTE", "start_pos": 71, "end_pos": 74, "type": "TASK", "confidence": 0.8000149726867676}]}, {"text": "In other words, MTE metrics based on character N-grams or word N-grams cannot make full use of sentence representations; they only check for word matches.", "labels": [], "entities": [{"text": "MTE", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.9380736351013184}]}, {"text": "We propose a segment-level MTE metric by using universal sentence representations capable of capturing information that cannot be captured by local features based on character or word Ngrams.", "labels": [], "entities": [{"text": "MTE", "start_pos": 27, "end_pos": 30, "type": "TASK", "confidence": 0.9109391570091248}]}, {"text": "The results of an experiment in segmentlevel MTE conducted using the datasets for toEnglish language pairs on WMT-2016 indicated that the proposed regression model using sentence representations achieves the best performance.", "labels": [], "entities": [{"text": "segmentlevel MTE", "start_pos": 32, "end_pos": 48, "type": "TASK", "confidence": 0.6295581758022308}, {"text": "toEnglish language pairs on WMT-2016", "start_pos": 82, "end_pos": 118, "type": "DATASET", "confidence": 0.7906325221061706}]}, {"text": "The main contributions of the study are summarized below: \u2022 We propose a novel supervised regression model for segment-level MTE based on universal sentence representations.", "labels": [], "entities": [{"text": "MTE", "start_pos": 125, "end_pos": 128, "type": "TASK", "confidence": 0.86372971534729}]}, {"text": "\u2022 We achieved state-of-the-art performance on the WMT-2016 dataset for to-English language pairs without using any complex features and models.", "labels": [], "entities": [{"text": "WMT-2016 dataset", "start_pos": 50, "end_pos": 66, "type": "DATASET", "confidence": 0.9705621302127838}]}], "datasetContent": [{"text": "We performed experiments using evaluation datasets of the WMT Metrics task to verify the performance of the proposed metric.", "labels": [], "entities": [{"text": "WMT Metrics task", "start_pos": 58, "end_pos": 74, "type": "TASK", "confidence": 0.5784871876239777}]}], "tableCaptions": []}