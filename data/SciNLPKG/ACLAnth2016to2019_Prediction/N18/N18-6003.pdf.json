{"title": [{"text": "Scalable Construction and Reasoning of Massive Knowledge Bases -Proposal fora Tutorial at NAACL 2018", "labels": [], "entities": [{"text": "NAACL 2018", "start_pos": 90, "end_pos": 100, "type": "DATASET", "confidence": 0.9282454550266266}]}], "abstractContent": [{"text": "In today's information-based society, there is abundant knowledge out there carried in the form of natural language texts (e.g., news articles, social media posts, scientific publications), which spans across various domains (e.g., corporate documents, advertisements, legal acts, medical reports), and grows at an astonishing rate.", "labels": [], "entities": []}, {"text": "How to turn such massive and unstructured text data into structured, actionable knowledge for computational machines, and furthermore , how to teach machines learn to reason and complete the extracted knowledge is a grand challenge to the research community.", "labels": [], "entities": []}, {"text": "Traditional IE systems assume abundant human annotations for training high quality machine learning models, which is impractical when trying to deploy IE systems to abroad range of domains , settings and languages.", "labels": [], "entities": []}, {"text": "In the first part of the tutorial, we introduce how to extract structured facts (i.e., entities and their relations of different types) from text corpora to construct knowledge bases, with a focus on methods that are minimally-supervised and domain-independent for timely knowledge base construction across various application domains.", "labels": [], "entities": []}, {"text": "In the second part, we introduce how to leverage other knowledge, such as the distributional statistics of characters and words, the annotations for other tasks and other domains, and the linguistics and problem structures, to combat the problem of inadequate supervision , and conduct low-resource information extraction.", "labels": [], "entities": [{"text": "low-resource information extraction", "start_pos": 286, "end_pos": 321, "type": "TASK", "confidence": 0.6723652680714926}]}, {"text": "In the third part, we describe recent advances in knowledge base reasoning.", "labels": [], "entities": [{"text": "knowledge base reasoning", "start_pos": 50, "end_pos": 74, "type": "TASK", "confidence": 0.6160355806350708}]}, {"text": "We start with the gentle introduction to the literature, focusing on path-based and embedding based methods.", "labels": [], "entities": []}, {"text": "We then describe DeepPath, a recent attempt of using deep reinforcement learning to combine the best of both worlds for knowledge base reasoning.", "labels": [], "entities": [{"text": "knowledge base reasoning", "start_pos": 120, "end_pos": 144, "type": "TASK", "confidence": 0.6191994150479635}]}], "introductionContent": [{"text": "The success of data mining and artificial intelligence technology is largely attributed to the efficient and effective analysis of structured data.", "labels": [], "entities": [{"text": "data mining", "start_pos": 15, "end_pos": 26, "type": "TASK", "confidence": 0.7357998043298721}]}, {"text": "The construction of a well-structured, machine-actionable knowledge base (KB) from raw (unstructured or loosely-structured) data sources is often the premise of consequent applications.", "labels": [], "entities": []}, {"text": "Although the majority of existing data generated in our society is unstructured, big data leads to big opportunities to uncover structures of real-world entities (e.g., person, product), attributes (e.g., age, weight), relations (e.g., employee of, manufacture) from massive text corpora.", "labels": [], "entities": []}, {"text": "By integrating these semantic structures, one can construct a powerful KB as a conceptual abstraction of the original corpus.", "labels": [], "entities": []}, {"text": "The constructed knowledge base will facilitate browsing information and inferring knowledge that are otherwise widely scattered in the text corpora.", "labels": [], "entities": []}, {"text": "Computational machines can effectively perform algorithmic analysis at a large scale over these KBs, and apply the new insights to improve human productivity in various downstream tasks.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}