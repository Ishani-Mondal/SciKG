{"title": [], "abstractContent": [], "introductionContent": [{"text": "Every year, as we send out the call for papers for the Workshop on Innovative Use of NLP for Building Educational Applications, we wonder which subfield of educational applications will be prevalent in the submissions.", "labels": [], "entities": []}, {"text": "One year it is speech recognition for automated evaluation, the next it maybe grammatical error correction, another year the focus maybe on automated scoring of textual assessments.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.7769254148006439}, {"text": "grammatical error correction", "start_pos": 78, "end_pos": 106, "type": "TASK", "confidence": 0.5563244124253591}]}, {"text": "Inevitably, even with more than 130 Program Committee members, we find ourselves scrambling to recruit more reviewers for that year's hot topic.", "labels": [], "entities": []}, {"text": "There was no clear winner this year.", "labels": [], "entities": []}, {"text": "The majority of the 2018 submissions were primarily automated writing assessment, automated test generation, and reading.", "labels": [], "entities": [{"text": "automated test generation", "start_pos": 82, "end_pos": 107, "type": "TASK", "confidence": 0.6716140111287435}]}, {"text": "Overall, there was a nice mix of all of the topics above and more.", "labels": [], "entities": []}, {"text": "This year we received 41 submissions and accepted 8 papers as oral presentations and 18 as poster presentations, for an overall acceptance rate of 63 percent.", "labels": [], "entities": [{"text": "acceptance rate", "start_pos": 128, "end_pos": 143, "type": "METRIC", "confidence": 0.9618589282035828}]}, {"text": "Each paper was reviewed by three members of the Program Committee who were believed to be most appropriate for each paper.", "labels": [], "entities": []}, {"text": "We continue to have a strong policy to deal with conflicts of interest.", "labels": [], "entities": []}, {"text": "First, we made a concerted effort to not assign papers to reviewers to evaluate if the paper had an author from their institution.", "labels": [], "entities": []}, {"text": "Second, organizing committee members recused themselves from discussions of papers when there was a conflict of interest.", "labels": [], "entities": []}, {"text": "We do recognize that there is a core group of institutions and researchers who work in this area.", "labels": [], "entities": []}, {"text": "With a higher acceptance rate, we were able to include papers from a wider variety of topics and institutions.", "labels": [], "entities": [{"text": "acceptance", "start_pos": 14, "end_pos": 24, "type": "METRIC", "confidence": 0.8792348504066467}]}, {"text": "The papers accepted were selected on the basis of several factors, including the relevance to a core educational problem space, the novelty of the approach or domain, and the strength of the research.", "labels": [], "entities": []}, {"text": "The accepted papers were highly diverse -an indicator of the growing variety of foci in this field.", "labels": [], "entities": []}, {"text": "We continue to believe that the workshop framework designed to introduce work in progress and new ideas needs to be revived, and we hope that we have achieved this with the breadth and variety of research accepted for this workshop, a brief description of which is presented below.", "labels": [], "entities": []}, {"text": "The BEA13 workshop has presentations on automated writing evaluation, item generation, readability, dialogue, annotation, speech and grammatical error correction (GEC), annotation and resources:", "labels": [], "entities": [{"text": "BEA13", "start_pos": 4, "end_pos": 9, "type": "DATASET", "confidence": 0.7963753938674927}, {"text": "item generation", "start_pos": 70, "end_pos": 85, "type": "TASK", "confidence": 0.7016367316246033}, {"text": "speech and grammatical error correction (GEC)", "start_pos": 122, "end_pos": 167, "type": "TASK", "confidence": 0.6430250443518162}]}], "datasetContent": [{"text": "Zhang and Litman present an investigation of using a co-attention based neural network for scoring essays.", "labels": [], "entities": []}, {"text": "Horbach et al. investigate the feasibility of cross-lingual content scoring.", "labels": [], "entities": [{"text": "cross-lingual content scoring", "start_pos": 46, "end_pos": 75, "type": "TASK", "confidence": 0.6864853103955587}]}, {"text": "Gao et al. examine how and why automated content analysis can be used to assess precis writing by university students.", "labels": [], "entities": [{"text": "assess precis writing", "start_pos": 73, "end_pos": 94, "type": "TASK", "confidence": 0.648968517780304}]}, {"text": "Zhang et al. use other texts written by an examinee, in the same test, as extra references in an automated scoring system.", "labels": [], "entities": []}], "tableCaptions": []}