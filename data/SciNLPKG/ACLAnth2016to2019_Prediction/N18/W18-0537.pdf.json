{"title": [{"text": "SB@GU at the Complex Word Identification 2018 Shared Task", "labels": [], "entities": [{"text": "Complex Word Identification 2018 Shared Task", "start_pos": 13, "end_pos": 57, "type": "TASK", "confidence": 0.6623586565256119}]}], "abstractContent": [{"text": "In this paper, we describe our experiments for the Shared Task on Complex Word Identification (CWI) 2018 (Yimam et al., 2018), hosted by the 13 th Workshop on Innovative Use of NLP for Building Educational Applications (BEA) at NAACL 2018.", "labels": [], "entities": [{"text": "Shared Task on Complex Word Identification (CWI) 2018", "start_pos": 51, "end_pos": 104, "type": "TASK", "confidence": 0.7462122827768326}, {"text": "Building Educational Applications (BEA) at NAACL 2018", "start_pos": 185, "end_pos": 238, "type": "TASK", "confidence": 0.6690811084376441}]}, {"text": "Our system for English builds on previous work for Swedish concerning the classification of words into proficiency levels.", "labels": [], "entities": []}, {"text": "We investigate different features for English and compare their usefulness using feature selection methods.", "labels": [], "entities": []}, {"text": "For the German, Spanish and French data we use simple systems based on character n-gram models and show that sometimes simple models achieve comparable results to fully feature-engineered systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "The task of identifying complex words consists of automatically detecting lexical items that might be hard to understand fora certain audience.", "labels": [], "entities": []}, {"text": "Once identified, text simplification systems can substitute these complex words by simpler equivalents to increase the comprehensibility (readability) of a text.", "labels": [], "entities": []}, {"text": "Readable texts can facilitate information processing for language learners and people with reading difficulties.", "labels": [], "entities": [{"text": "information processing", "start_pos": 30, "end_pos": 52, "type": "TASK", "confidence": 0.7815695106983185}]}, {"text": "Building on previous work for classifying Swedish words into different language proficiency levels, we extend our pipeline with English resources.", "labels": [], "entities": []}, {"text": "We explore a large number of features for English based on, among others, length information, parts of speech, word embeddings and language model probabilities.", "labels": [], "entities": []}, {"text": "In contrast to this feature-engineered approach, we use a word-length and n-gram probability based approach for the German, Spanish and French data.", "labels": [], "entities": []}, {"text": "Our interest for participation in this shared task is connected to the ongoing development of a complexity prediction system for Swedish.", "labels": [], "entities": [{"text": "complexity prediction", "start_pos": 96, "end_pos": 117, "type": "TASK", "confidence": 0.6796125322580338}]}, {"text": "In contrast to this shared task, we perform a five-way classification corresponding to the first five levels of the CEFR scale of language proficiency).", "labels": [], "entities": [{"text": "CEFR scale", "start_pos": 116, "end_pos": 126, "type": "DATASET", "confidence": 0.6988787353038788}]}, {"text": "We adapted the pipeline to English, and included some freely available English resources to see how well these would perform on the CWI 2018 task and to gain insights into how we could improve our own system.", "labels": [], "entities": [{"text": "CWI 2018 task", "start_pos": 132, "end_pos": 145, "type": "DATASET", "confidence": 0.894542396068573}]}], "datasetContent": [{"text": "We tried three different configurations for the English data set, namely context-free, context-only and context-sensitive.", "labels": [], "entities": [{"text": "English data set", "start_pos": 48, "end_pos": 64, "type": "DATASET", "confidence": 0.7870367268721262}]}, {"text": "For context-free, we use the features described above, excluding word embedding context.", "labels": [], "entities": []}, {"text": "For context-only, we only use the word embedding context vectors.For contextsensitive, we concatenate the context-free and context-only features.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of instances per language", "labels": [], "entities": []}, {"text": " Table 3: Results of best classifiers", "labels": [], "entities": []}, {"text": " Table 5: Results of 2016/2018 comparison", "labels": [], "entities": []}]}