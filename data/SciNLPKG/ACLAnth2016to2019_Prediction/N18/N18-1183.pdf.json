{"title": [{"text": "The Timing of Lexical Memory Retrievals in Language Production", "labels": [], "entities": [{"text": "Timing of Lexical Memory Retrievals in Language Production", "start_pos": 4, "end_pos": 62, "type": "TASK", "confidence": 0.7973583564162254}]}], "abstractContent": [{"text": "This paper explores the time course of lexical memory retrieval by modeling fluent language production.", "labels": [], "entities": [{"text": "lexical memory retrieval", "start_pos": 39, "end_pos": 63, "type": "TASK", "confidence": 0.6134527822335561}]}, {"text": "The duration of retrievals is predicted using the ACT-R cognitive architecture.", "labels": [], "entities": []}, {"text": "Ina large-scale observational study of a spoken corpus, we find that language production at a time point preceding a word is sped up or slowed down depending on activation of that word.", "labels": [], "entities": []}, {"text": "This computational analysis has consequences for the theoretical model of language production.", "labels": [], "entities": []}, {"text": "The results point to interference between lexical and phonological stages as well as a quantifiable buffer for lexical information that opens up the possibility of non-sequential retrievals.", "labels": [], "entities": []}], "introductionContent": [{"text": "Speech varies greatly in fluency, and some of its speed variation can be traced to the utterance spoken.", "labels": [], "entities": [{"text": "speed", "start_pos": 50, "end_pos": 55, "type": "METRIC", "confidence": 0.9650710821151733}]}, {"text": "Low-frequency words, for instance, are known to slowdown speech (e.g.,.", "labels": [], "entities": []}, {"text": "Variables correlated with fluency give valuable cues to the architecture of the language processing system.", "labels": [], "entities": []}, {"text": "However, a model to explain these data has yet to emerge.", "labels": [], "entities": []}, {"text": "In this paper, we propose a cognitive model of fluency, in which lexical memory retrievals may explain some of the variability in speech rates.", "labels": [], "entities": []}, {"text": "In particular, frequency, context and recent uses together have the potential to quantify retrieval delays through activation.", "labels": [], "entities": []}, {"text": "Activation, in its most common usage, refers to the way nodes in semantic networks become easier to retrieve after adjacent nodes have been activated, typically through a presentation).", "labels": [], "entities": []}, {"text": "In particular, activation makes a direct claim that more highly activated words require less time to retrieve, and vice versa.", "labels": [], "entities": []}, {"text": "The language production process as a whole likely requires some amount of sequential processing.", "labels": [], "entities": [{"text": "language production", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.7330094873905182}]}, {"text": "For instance, the standard model proposes that an idea is generated, lexicalized, grammatically and morphologically encoded, and only then phonologically encoded).", "labels": [], "entities": []}, {"text": "Still, most models of language production presuppose some amount of planning of output (e.g.,, so we could instead divide language production into planning this output and the actual process of outputting.", "labels": [], "entities": []}, {"text": "The overlap and relationship of these processes is not fully understood, but given that most output is likely planned, the scale at which the planning takes place and the amount of time between planned output and the actual process of outputting remains unclear.", "labels": [], "entities": []}, {"text": "However, if interactions between processes are observed, then we can likewise see when they overlap in time.", "labels": [], "entities": []}, {"text": "To summarize, we are suggesting that some of the variance in speech rate is not due to the linguistic properties of the words currently or about to be outputted, but the words still in the planning phase.", "labels": [], "entities": []}, {"text": "We propose a model that uses a buffer of several words between initial retrieval and output, during which grammatical and morphological encoding take place.", "labels": [], "entities": []}, {"text": "We examine this by calculating retrieval activation fora word and evaluating the influence of that activation on the empirical speech timing several words beforehand, using the Switchboard corpus.", "labels": [], "entities": [{"text": "Switchboard corpus", "start_pos": 177, "end_pos": 195, "type": "DATASET", "confidence": 0.9044941365718842}]}, {"text": "The effect of activation is distributed over preceding words in away that is characteristic of a shared-resource, buffer-based account of language production.", "labels": [], "entities": []}], "datasetContent": [{"text": "Data were analyzed with two related models.", "labels": [], "entities": []}, {"text": "Initially, we tested an interaction model in order to test our hypothesis of the interaction between delay and offset (see).", "labels": [], "entities": []}, {"text": "From this information, we use exploratory data analysis in the form of a discrete model, in order to explore the critical regions of the graph (see).", "labels": [], "entities": []}, {"text": "From this exploratory data analysis, we present the pooled version of the discrete model for easier interpretation of our found effects (see).", "labels": [], "entities": []}, {"text": "For both models, the activation of a target word and its expected retrieval time burden was computed, as were the delays for then words preceding the target word.", "labels": [], "entities": []}, {"text": "Importantly, note that in both models, when we refer to the expected retrieval time or activation, we are referring to the target word, not any of the preceding words.", "labels": [], "entities": []}, {"text": "Both models are concerned with the word offset (i), which refers to the number of interceding words between the given delay and the target word, such that i = 0 refers to the word immediately before the target word.", "labels": [], "entities": [{"text": "word offset (i)", "start_pos": 35, "end_pos": 50, "type": "METRIC", "confidence": 0.83586345911026}]}, {"text": "In the interaction model, we are interested in the interaction term between word offset and delay: its goal is to show how the correlation changes with offset.", "labels": [], "entities": []}, {"text": "In this model, every observation only uses a single offset, chosen randomly, for each target word.", "labels": [], "entities": []}, {"text": "All of the other observations for that word are discarded.", "labels": [], "entities": []}, {"text": "This is to ensure the observations are independent.", "labels": [], "entities": []}, {"text": "The correlation coefficients of interest are the correlation of delay as a whole, and its interaction effect with offset.", "labels": [], "entities": []}, {"text": "In general, the coefficient of offset by itself is likely capturing some distributional information about the data, rather than anything interesting with how it relates to memory retrievals.", "labels": [], "entities": []}, {"text": "As a linear model: Meanwhile, the discrete model's observations consist of a word's expected retrieval time and the delays from previous words.", "labels": [], "entities": []}, {"text": "Then, we make a linear model using each of the delays as a predictor.", "labels": [], "entities": []}, {"text": "Note that in this notation, delay i refers to the delay of offset word i.", "labels": [], "entities": []}, {"text": "To reiterate, i represents how many interceding words there are between that offset word and the target word.", "labels": [], "entities": []}, {"text": "As a linear model, this would be: The goal of the interaction model is to show the robustness of the slope associated with index, while the goal of the discrete model is to allow fora non-linear relationship between offset and the effect of delay on activation, examining up to 25 previous words.", "labels": [], "entities": [{"text": "offset", "start_pos": 216, "end_pos": 222, "type": "METRIC", "confidence": 0.9611353874206543}]}, {"text": "Exploring this non-linear relationship allowed us to infer the critical regions of this effect.", "labels": [], "entities": []}, {"text": "Importantly, the discrete model's goal was to explore the significant relationship found in the interaction model more deeply, rather than to itself justify the effect.", "labels": [], "entities": []}, {"text": "Under the model shown in, we expect that longer retrieval times of the target word are associated with slowdowns of speech production at sometime before the target word is spoken.", "labels": [], "entities": []}, {"text": "Earlier than that point, the target word should have no influence on speech production.: The linear effects model relating each discrete delay term with expected retrieval time.", "labels": [], "entities": []}, {"text": "A higher number on the delay term signifies the number of words between the delayed word and the target word.", "labels": [], "entities": []}, {"text": "This exploratory data analysis was done to inform the pooled model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Linear regression predicting expected retrieval  time of a target word as a function of the delay in speak- ing of a previous word at that offset.", "labels": [], "entities": [{"text": "Linear regression predicting expected retrieval", "start_pos": 10, "end_pos": 57, "type": "TASK", "confidence": 0.7145520091056824}]}, {"text": " Table 2: The linear effects model relating each discrete  delay term with expected retrieval time. A higher num- ber on the delay term signifies the number of words  between the delayed word and the target word. This ex- ploratory data analysis was done to inform the pooled  model. Also see", "labels": [], "entities": []}, {"text": " Table 3: Pooled version of discrete linear model, based  on critical regions from the graph. Regions are broken  at 3, 5, and 14 respectively.", "labels": [], "entities": []}, {"text": " Table 3: 0-2 appear  significant and negative, 3-4 are not significant (slightly neg- ative), 5-14 are significant and positive, 15+ is not significant.", "labels": [], "entities": []}]}