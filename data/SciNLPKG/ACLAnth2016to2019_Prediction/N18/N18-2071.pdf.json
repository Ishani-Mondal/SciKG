{"title": [{"text": "Object Ordering with Bidirectional Matchings for Visual Reasoning", "labels": [], "entities": [{"text": "Object Ordering", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8784922063350677}]}], "abstractContent": [{"text": "Visual reasoning with compositional natural language instructions, e.g., based on the newly-released Cornell Natural Language Visual Reasoning (NLVR) dataset, is a challenging task, where the model needs to have the ability to create an accurate mapping between the diverse phrases and the several objects placed in complex arrangements in the image.", "labels": [], "entities": [{"text": "Visual reasoning", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7792806327342987}, {"text": "Cornell Natural Language Visual Reasoning (NLVR) dataset", "start_pos": 101, "end_pos": 157, "type": "DATASET", "confidence": 0.7135226395395067}]}, {"text": "Further, this mapping needs to be processed to answer the question in the statement given the ordering and relationship of the objects across three similar images.", "labels": [], "entities": []}, {"text": "In this paper, we propose a novel end-to-end neural model for the NLVR task, where we first use joint bidirectional attention to build a two-way conditioning between the visual information and the language phrases.", "labels": [], "entities": []}, {"text": "Next, we use an RL-based pointer network to sort and process the varying number of unordered objects (so as to match the order of the statement phrases) in each of the three images and then pool over the three decisions.", "labels": [], "entities": []}, {"text": "Our model achieves strong improvements (of 4-6% absolute) over the state-of-the-art on both the structured representation and raw image versions of the dataset.", "labels": [], "entities": []}], "introductionContent": [{"text": "Visual Reasoning () requires a sophisticated understanding of the compositional language instruction and its relationship with the corresponding image.", "labels": [], "entities": [{"text": "Visual Reasoning", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.6538629233837128}]}, {"text": "recently proposed a challenging new NLVR task and dataset in this direction with natural and complex language statements that have to be classified as true or false given a multi-image set (shown in).", "labels": [], "entities": []}, {"text": "Specifically, each task instance consists of an image with three sub-images and a statement which describes the image.", "labels": [], "entities": []}, {"text": "The model is asked to answer the question whether the given statement is consistent with the image or not.", "labels": [], "entities": []}, {"text": "To solve the task, the designed model needs to fuse the information from two different domains, There is at least one tower which has blocks of all three colors There is a box with a yellow circle, a yellow square and two black items.", "labels": [], "entities": []}, {"text": "At least one of tower with exactly three blocks has a blue block in the middle", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our model on the NLVR dataset (Suhr et al., 2017), for both the structured and raw-image versions.", "labels": [], "entities": [{"text": "NLVR dataset", "start_pos": 29, "end_pos": 41, "type": "DATASET", "confidence": 0.9725062847137451}]}, {"text": "All model tuning was performed on the dev set.", "labels": [], "entities": []}, {"text": "Given the fact that the dataset is balanced (the number of true labels and false labels are roughly the same), the accuracy of the whole corpus is used as the metric.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.9992207288742065}]}, {"text": "We only use the raw features of the statement and the objects with minimal standard preprocessing (e.g., tokenization and UNK replacement; see appendix for reproducibility training details).", "labels": [], "entities": [{"text": "UNK replacement", "start_pos": 122, "end_pos": 137, "type": "TASK", "confidence": 0.7324618995189667}]}], "tableCaptions": [{"text": " Table 1: Dev, Test-P (public), and Test-U (unreleased) results of our model on the structured-representation and  raw-image datasets, compared to the previous SotA results and other reimplemented baselines.", "labels": [], "entities": []}]}