{"title": [{"text": "Leveraging Syntactic Constructions for Metaphor Identification", "labels": [], "entities": [{"text": "Metaphor Identification", "start_pos": 39, "end_pos": 62, "type": "TASK", "confidence": 0.7151347547769547}]}], "abstractContent": [{"text": "Identification of metaphoric language in text is critical for generating effective semantic representations for natural language understanding.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 112, "end_pos": 142, "type": "TASK", "confidence": 0.686406413714091}]}, {"text": "Computational approaches to metaphor identification have largely relied on heuristic based models or feature-based machine learning , using hand-crafted lexical resources coupled with basic syntactic information.", "labels": [], "entities": [{"text": "metaphor identification", "start_pos": 28, "end_pos": 51, "type": "TASK", "confidence": 0.929113507270813}]}, {"text": "However , recent work has shown the predictive power of syntactic constructions in determining metaphoric source and target domains (Sullivan, 2013).", "labels": [], "entities": []}, {"text": "Our work intends to explore syntactic constructions and their relation to metaphoric language.", "labels": [], "entities": []}, {"text": "We undertake a corpus-based analysis of predicate-argument constructions and their metaphoric properties, and attempt to effectively represent syntactic constructions as features for metaphor processing , both in identifying source and target domains and in distinguishing metaphoric words from non-metaphoric.", "labels": [], "entities": [{"text": "metaphor processing", "start_pos": 183, "end_pos": 202, "type": "TASK", "confidence": 0.7620231807231903}]}], "introductionContent": [], "datasetContent": [{"text": "As a baseline, we began with using the embedding of the word to be classified.", "labels": [], "entities": []}, {"text": "We concatenated this with the embeddings of the single previous and following words, as this proved the best context in our validation.", "labels": [], "entities": []}, {"text": "This creates a representation of lexical semantics and a word's context, without any specific knowledge of the syntactic relations the word is involved in.", "labels": [], "entities": []}, {"text": "We then added each syntactic representation.", "labels": [], "entities": []}, {"text": "These experiments were done using a training-validation-test split of 76/12/12.", "labels": [], "entities": []}, {"text": "We experimented with Maximum Entropy, Naive Bayes, Random Forest and Support Vector Machine classifiers, and through validation chose a SVM with a linear kernel, L2 regularization and squared hinge loss.", "labels": [], "entities": []}, {"text": "We then ran the classifier using our baseline, and added each feature separately.", "labels": [], "entities": []}, {"text": "Finally, we combined the best feature set for each classification task, judged by the improved performance of each feature over the baseline.", "labels": [], "entities": []}, {"text": "The classification was split into three tasks: identifying source items, identifying target items, and identifying metaphoric (either source or target) from non-metaphoric.", "labels": [], "entities": []}, {"text": "The results of these experiments are in table 2.", "labels": [], "entities": []}, {"text": "From these results we can see that classifying source-domain words in the LCC data is harder than classifying target-domain words.", "labels": [], "entities": [{"text": "LCC data", "start_pos": 74, "end_pos": 82, "type": "DATASET", "confidence": 0.949601948261261}]}, {"text": "This maybe because of the broad range of domains, as the corpus contains 114 possible source domains.", "labels": [], "entities": []}, {"text": "Target items are much easier to classify, likely because the dataset contains only a limited number (32) of target domains.", "labels": [], "entities": []}, {"text": "Embeddings are effective at representing semantics, and they can accurately determine the domain of lexical items, allowing for easy classification of target items.", "labels": [], "entities": []}, {"text": "Our syntactic features show mixed results.", "labels": [], "entities": []}, {"text": "Adding sentential context is consistently effective, showing that naive contextual approaches are helpful.", "labels": [], "entities": []}, {"text": "Adding dependency embeddings is also consistently effective, supporting our hypothesis that knowledge of syntactic properties can be helpful in metaphor classification.", "labels": [], "entities": [{"text": "metaphor classification", "start_pos": 144, "end_pos": 167, "type": "TASK", "confidence": 0.9201470613479614}]}, {"text": "Other syntactic features are inconsistent, especially in predicting the metaphoricity of verbs.", "labels": [], "entities": [{"text": "predicting the metaphoricity of verbs", "start_pos": 57, "end_pos": 94, "type": "TASK", "confidence": 0.8138973236083984}]}, {"text": "Selecting only the feature sets that showed improvement over the baseline yields the best results for most categories.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: % Metaphor by Construction (LCC). For each predicate, the count of source (SRC), target (TRG), and  non-metaphoric (-MET) instances are counted, as well as those for all of each construction's defining arguments.", "labels": [], "entities": []}, {"text": " Table 2: Classification of Source and Target elements in the LCC Corpus. Metaphor (MET) is the classification  of a word as either Source or Target against non-metaphoric words.", "labels": [], "entities": [{"text": "LCC Corpus", "start_pos": 62, "end_pos": 72, "type": "DATASET", "confidence": 0.9526610672473907}]}, {"text": " Table 3: % Metaphor by Construction (VUAMC). For each predicate, the count of metaphoric (+M) and non- metaphoric (-M) instances are counted, as well as those for all of each construction's defining arguments.", "labels": [], "entities": []}, {"text": " Table 4: Results of adding different syntactic models  for VUAMC verb classification.", "labels": [], "entities": [{"text": "VUAMC verb classification", "start_pos": 60, "end_pos": 85, "type": "TASK", "confidence": 0.6627988914648691}]}]}