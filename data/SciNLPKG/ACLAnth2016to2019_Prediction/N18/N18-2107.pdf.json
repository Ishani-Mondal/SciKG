{"title": [], "abstractContent": [{"text": "Emojis are small images that are commonly included in social media text messages.", "labels": [], "entities": []}, {"text": "The combination of visual and textual content in the same message builds up a modern way of communication, that automatic systems are not used to deal with.", "labels": [], "entities": []}, {"text": "In this paper we extend recent advances in emoji prediction by putting forward a multimodal approach that is able to predict emojis in Instagram posts.", "labels": [], "entities": [{"text": "emoji prediction", "start_pos": 43, "end_pos": 59, "type": "TASK", "confidence": 0.9172415733337402}]}, {"text": "Instagram posts are composed of pictures together with texts which sometimes include emojis.", "labels": [], "entities": []}, {"text": "We show that these emojis can be predicted by using the text, but also using the picture.", "labels": [], "entities": []}, {"text": "Our main finding is that incorporating the two syn-ergistic modalities, in a combined model, improves accuracy in an emoji prediction task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9987596273422241}, {"text": "emoji prediction task", "start_pos": 117, "end_pos": 138, "type": "TASK", "confidence": 0.8902955253918966}]}, {"text": "This result demonstrates that these two modalities (text and images) encode different information on the use of emojis and therefore can complement each other.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the past few years the use of emojis in social media has increased exponentially, changing the way we communicate.", "labels": [], "entities": []}, {"text": "The combination of visual and textual content poses new challenges for information systems which need not only to deal with the semantics of text but also that of images.", "labels": [], "entities": []}, {"text": "Recent work ( has shown that textual information can be used to predict emojis associated to text.", "labels": [], "entities": []}, {"text": "In this paper we show that in the current context of multimodal communication where texts and images are combined in social networks, visual information should be combined with texts in order to obtain more accurate emojiprediction models.", "labels": [], "entities": []}, {"text": "We explore the use of emojis in the social media platform Instagram.", "labels": [], "entities": []}, {"text": "We put forward a multimodal approach to predict the emojis associated to an Instagram post, given its picture and text . Our task and experimental framework are similar to), however, we use different data (Instagram instead of Twitter) and, in addition, we rely on images to improve the selection of the most likely emojis to associate to a post.", "labels": [], "entities": []}, {"text": "We show that a multimodal approach (textual and visual content of the posts) increases the emoji prediction accuracy compared to the one that only uses textual information.", "labels": [], "entities": [{"text": "emoji prediction", "start_pos": 91, "end_pos": 107, "type": "TASK", "confidence": 0.8815004825592041}, {"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.8724710941314697}]}, {"text": "This suggests that textual and visual content embed different but complementary features of the use of emojis.", "labels": [], "entities": []}, {"text": "In general, an effective approach to predict the emoji to be associated to apiece of content may help to improve natural language processing tasks), such as information retrieval, generation of emoji-enriched social media content, suggestion of emojis when writing text messages or sharing pictures online.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 157, "end_pos": 178, "type": "TASK", "confidence": 0.8085162043571472}, {"text": "generation of emoji-enriched social media content", "start_pos": 180, "end_pos": 229, "type": "TASK", "confidence": 0.7411621908346812}]}, {"text": "Given that emojis may also mislead humans, the automated prediction of emojis may help to achieve better language understanding.", "labels": [], "entities": []}, {"text": "As a consequence, by modeling the semantics of emojis, we can improve highly-subjective tasks like sentiment analysis, emotion recognition and irony detection).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 99, "end_pos": 117, "type": "TASK", "confidence": 0.9563150405883789}, {"text": "emotion recognition", "start_pos": 119, "end_pos": 138, "type": "TASK", "confidence": 0.7109263688325882}, {"text": "irony detection", "start_pos": 143, "end_pos": 158, "type": "TASK", "confidence": 0.8361472487449646}]}], "datasetContent": [{"text": "Dataset: We gathered Instagram posts published between July 2016 and October 2016, and geolocalized in the United States of America.", "labels": [], "entities": []}, {"text": "We considered only posts that contained a photo together with the related user description of at least 4 words and exactly one emoji.", "labels": [], "entities": []}, {"text": "Moreover, as done by, we considered only the posts which include one and only one of the 20 most frequent emojis (the most frequent emojis are shown in).", "labels": [], "entities": []}, {"text": "Our dataset is composed of 299,809 posts, each containing a picture, the text associated to it and only one emoji.", "labels": [], "entities": []}, {"text": "In the experiments we also considered the subsets of the 10 (238,646 posts) and 5 most frequent emojis (184,044 posts) (similarly to the approach followed by).", "labels": [], "entities": []}, {"text": "Task: We extend the experimental scheme of, by considering also visual information when modeling posts.", "labels": [], "entities": []}, {"text": "We cast the emoji prediction problem as a classification task: given an image or a text (or both inputs in the multimodal scenario) we select the most likely emoji that could be added to (thus used to label) such contents.", "labels": [], "entities": [{"text": "emoji prediction", "start_pos": 12, "end_pos": 28, "type": "TASK", "confidence": 0.9121119678020477}]}, {"text": "The task for our machine learning models is, given the visual and textual content of a post, to predict the single emoji that appears in the input comment.", "labels": [], "entities": []}, {"text": "In order to study the relation between Instagram posts and emojis, we performed two different experiments.", "labels": [], "entities": []}, {"text": "In the first experiment (Section 4.", "labels": [], "entities": []}, {"text": "Finally we discuss the contribution of each modality to the prediction task.", "labels": [], "entities": [{"text": "prediction task", "start_pos": 60, "end_pos": 75, "type": "TASK", "confidence": 0.9124143421649933}]}, {"text": "We use 80% of our dataset (introduced in Section 2) for training, 10% to tune our models, and 10% for testing (selecting the sets randomly).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison of B-LSTM with word mod- eling (BW), B-LSTM with character modeling (BC),  and FastText (FT) on the same Twitter emoji predic- tion tasks proposed by Barbieri et al. (2017), using the  same Twitter dataset.", "labels": [], "entities": [{"text": "FastText (FT)", "start_pos": 100, "end_pos": 113, "type": "METRIC", "confidence": 0.8853126168251038}]}, {"text": " Table 2: Prediction results of top-5, top-10 and top- 20 most frequent emojis in the Instagram dataset: Pre- cision (P), Recall (R), F-measure (F1). Experimental  settings: majority baseline, weighted random, visual,  textual and multimodal systems. In the last line we  report the percentage improvement of the multimodal  over the textual system.", "labels": [], "entities": [{"text": "Instagram dataset", "start_pos": 86, "end_pos": 103, "type": "DATASET", "confidence": 0.8845379650592804}, {"text": "Pre- cision (P)", "start_pos": 105, "end_pos": 120, "type": "METRIC", "confidence": 0.9555730521678925}, {"text": "Recall (R)", "start_pos": 122, "end_pos": 132, "type": "METRIC", "confidence": 0.9519803524017334}, {"text": "F-measure (F1)", "start_pos": 134, "end_pos": 148, "type": "METRIC", "confidence": 0.9432122260332108}]}, {"text": " Table 3: F-measure in the test set of the 20 most fre- quent emojis using the three different models. \"%\" in- dicates the percentage of the class in the test set", "labels": [], "entities": [{"text": "F-measure", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9969196319580078}]}]}