{"title": [{"text": "Optimizing Statistical Machine Translation for Text Simplification", "labels": [], "entities": [{"text": "Optimizing Statistical Machine Translation", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.7114800661802292}, {"text": "Text Simplification", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.7555480897426605}]}], "abstractContent": [{"text": "Most recent sentence simplification systems use basic machine translation models to learn lexical and syntactic paraphrases from a manually simplified parallel corpus.", "labels": [], "entities": [{"text": "sentence simplification", "start_pos": 12, "end_pos": 35, "type": "TASK", "confidence": 0.7610102891921997}]}, {"text": "These methods are limited by the quality and quantity of manually simplified corpora, which are expensive to build.", "labels": [], "entities": []}, {"text": "In this paper, we conduct an in-depth adaptation of statistical machine translation to perform text simplification, taking advantage of large-scale paraphrases learned from bilingual texts and a small amount of manual simplifications with multiple references.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 52, "end_pos": 83, "type": "TASK", "confidence": 0.6270653605461121}, {"text": "text simplification", "start_pos": 95, "end_pos": 114, "type": "TASK", "confidence": 0.7694811224937439}]}, {"text": "Our work is the first to design automatic metrics that are effective for tuning and evaluating simplification systems, which will facilitate iterative development for this task.", "labels": [], "entities": []}], "introductionContent": [{"text": "The goal of text simplification is to rewrite an input text so that the output is more readable.", "labels": [], "entities": [{"text": "text simplification", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.7511348128318787}]}, {"text": "Text simplification has applications for reducing input complexity for natural language processing () and providing reading aids for people with limited language skills or language impairments such as dyslexia (), autism (, and aphasia.", "labels": [], "entities": [{"text": "Text simplification", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7628602683544159}]}, {"text": "It is widely accepted that sentence simplification can be implemented by three major types of operations: splitting, deletion and paraphrasing.", "labels": [], "entities": [{"text": "sentence simplification", "start_pos": 27, "end_pos": 50, "type": "TASK", "confidence": 0.7646243870258331}]}, {"text": "The splitting operation decomposes along sentence into a sequence of shorter sentences.", "labels": [], "entities": []}, {"text": "Deletion removes less important parts of a sentence.", "labels": [], "entities": []}, {"text": "The paraphrasing operation includes reordering, lexical substitutions and syntactic transformations.", "labels": [], "entities": []}, {"text": "While sentence splitting) and deletion; and others) have been intensively studied, there has been considerably less research on developing new paraphrasing models for text simplification -most previous work has used off-the-shelf statistical machine translation (SMT) technology and achieved reasonable results.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 6, "end_pos": 24, "type": "TASK", "confidence": 0.7983726561069489}, {"text": "text simplification", "start_pos": 167, "end_pos": 186, "type": "TASK", "confidence": 0.7848485112190247}, {"text": "statistical machine translation (SMT)", "start_pos": 230, "end_pos": 267, "type": "TASK", "confidence": 0.800459086894989}]}, {"text": "However, they have either treated the judgment technology as a black) or they have been limited to modifying only one aspect of it, such as the translation model () or the reranking component (.", "labels": [], "entities": []}, {"text": "In this paper, we present a complete adaptation of a syntax-based machine translation framework to perform simplification.", "labels": [], "entities": [{"text": "syntax-based machine translation", "start_pos": 53, "end_pos": 85, "type": "TASK", "confidence": 0.6757606863975525}]}, {"text": "Our methodology poses text simplification as a paraphrasing problem: given an input text, rewrite it subject to the constraints that the output should be simpler than the input, while preserving as much meaning of the input as possible, and maintaining the well-formedness of the text.", "labels": [], "entities": [{"text": "text simplification", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.716928094625473}]}, {"text": "Going beyond previous work, we make di-401 rect modifications to four key components in the SMT pipeline: 1 1) two novel simplification-specific tunable metrics; 2) large-scale paraphrase rules automatically derived from bilingual parallel corpora, which are more naturally and abundantly available than manually simplified texts; 3) rich rule-level simplification features; and 4) multiple reference simplifications collected via crowdsourcing for tuning and evaluation.", "labels": [], "entities": [{"text": "SMT", "start_pos": 92, "end_pos": 95, "type": "TASK", "confidence": 0.9924368262290955}]}, {"text": "In particular, we report the first study that shows promising correlations of automatic metrics with human evaluation.", "labels": [], "entities": []}, {"text": "Our work answers the call made in a recent TACL paper () to address problems in current simplification research -we amend human evaluation criteria, develop automatic metrics, and generate an improved multiple reference dataset.", "labels": [], "entities": [{"text": "TACL paper", "start_pos": 43, "end_pos": 53, "type": "DATASET", "confidence": 0.8087162375450134}]}, {"text": "Our work is primarily focused on lexical simplification (rewriting words or phrases with simpler versions), and to a lesser extent on syntactic rewrite rules that simplify the input.", "labels": [], "entities": []}, {"text": "It largely ignores the important subtasks of sentence splitting and deletion.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.7412107139825821}]}, {"text": "Our focus on lexical simplification does not affect the generality of the presented work, since deletion or sentence splitting could be applied as pre-or post-processing steps.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 108, "end_pos": 126, "type": "TASK", "confidence": 0.7205201685428619}]}], "datasetContent": [{"text": "We implemented all the proposed adaptations into the open source syntactic machine translation decoder Joshua (  end-to-end sentence simplification systems use a basic phrase-based MT model trained on parallel Wikipedia data using the Moses decoder.", "labels": [], "entities": []}, {"text": "One of the best systems is PBMT-R by, which reranks Moses' n-best outputs based on their dissimilarity to the input to promote simplification.", "labels": [], "entities": []}, {"text": "We also build a baseline by using BLEU as the tuning metric in our adapted MT framework.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 34, "end_pos": 38, "type": "METRIC", "confidence": 0.9980766773223877}, {"text": "MT", "start_pos": 75, "end_pos": 77, "type": "TASK", "confidence": 0.8768645524978638}]}, {"text": "We conduct both human and automatic evaluation to demonstrate the advantage of the proposed simplification systems.", "labels": [], "entities": []}, {"text": "We also show the effectiveness of the two new metrics in tuning and automatic evaluation.", "labels": [], "entities": []}, {"text": "shows a representative example of the simplification results.", "labels": [], "entities": []}, {"text": "The PBMT-R model failed to learn any good substitutions for the word ablebodied or the phrase are required to from the manually simplified corpora of limited size.", "labels": [], "entities": [{"text": "PBMT-R", "start_pos": 4, "end_pos": 10, "type": "DATASET", "confidence": 0.8031653165817261}]}, {"text": "In contrast, our proposed method can make use of more para-407 Sentence  For the human evaluation, participants were shown the original English Wikipedia sentence as a reference and asked to judge a set of simplifications that were displayed in random order.", "labels": [], "entities": []}, {"text": "They evaluated a simplification from each system, the Simple Wikipedia version, and a Turker simplification.", "labels": [], "entities": [{"text": "Simple Wikipedia version", "start_pos": 54, "end_pos": 78, "type": "DATASET", "confidence": 0.9026036461194357}]}, {"text": "Judges rated each simplification on two 5-point scales of meaning retention and grammaticality (0 is the worst and 4 is the best).", "labels": [], "entities": []}, {"text": "We also ask participants to rate Simplicity Gain (Simplicity+) by counting how many successful lexical or syntactic paraphrases occurred in the simplification.", "labels": [], "entities": []}, {"text": "We found this makes the judgment easier and that it is more informative than rating the simplicity directly on 5-point scale, since the original sentences have very different readability levels to start with.", "labels": [], "entities": []}, {"text": "More importantly, using simplicity gain avoids over-punishment of errors, which are already penalized for poor meaning retention and grammaticality, and thus reduces the bias towards very conservative models.", "labels": [], "entities": []}, {"text": "We collect judgments on these three criteria from five different annotators and report the average scores.", "labels": [], "entities": []}, {"text": "shows that our best system, a syntacticbased MT system (SBMT) using PPDB as the source of paraphrase rules and tuning towards the SARI metric, achieves better performance in all three simplification measurements than the state-ofthe-art system PBMT-R.", "labels": [], "entities": [{"text": "PBMT-R", "start_pos": 244, "end_pos": 250, "type": "DATASET", "confidence": 0.900006115436554}]}, {"text": "The relatively small values of simplicity gain, even for the two human references (Simple Wikipedia and Mechanical Turk), clearly show the major challenge of simplification, which is the need of not only generating paraphrases but also ensuring the generated paraphrases are simpler while fitting the contexts.", "labels": [], "entities": [{"text": "simplicity", "start_pos": 31, "end_pos": 41, "type": "METRIC", "confidence": 0.9922389984130859}, {"text": "Simple Wikipedia", "start_pos": 83, "end_pos": 99, "type": "DATASET", "confidence": 0.7530668675899506}]}, {"text": "Although many researchers have noticed this difficulty, PBMT-R is one of the few that tried to address it by promoting   outputs that are dissimilar to the input.", "labels": [], "entities": []}, {"text": "Our best system is able to make more effective paraphrases (better Simplicity+) while introducing less errors (better Grammar and Meaning).", "labels": [], "entities": [{"text": "Grammar", "start_pos": 118, "end_pos": 125, "type": "METRIC", "confidence": 0.8598219752311707}]}, {"text": "An encouraging fact is that SARI metric ranks all 5 different systems and 3 human references in the same order as human assessment.", "labels": [], "entities": [{"text": "SARI metric", "start_pos": 28, "end_pos": 39, "type": "METRIC", "confidence": 0.47567759454250336}]}, {"text": "Most systems achieve similar FK readability as human editors, using fewer words or words with fewer syllables.", "labels": [], "entities": []}, {"text": "Tuning towards BLEU with all 8 references results in no transformation (same as input), as this can get a nearperfect BLEU score of 99.05 (out of 100).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 15, "end_pos": 19, "type": "METRIC", "confidence": 0.9612990617752075}, {"text": "BLEU", "start_pos": 118, "end_pos": 122, "type": "METRIC", "confidence": 0.9926087260246277}]}, {"text": "shows the correlation of automatic metrics with human judgment.", "labels": [], "entities": []}, {"text": "There are several interesting observations.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Human evaluation (Grammar, Meaning, Simplicity+) and basic statistics of our proposed systems (SBMTs)  and baselines. PBMT-R is an reimplementation of the state-of-the-art system by Wubben et al. (2012). Newly proposed  metrics FKBLEU and SARI show advantages for tuning.", "labels": [], "entities": [{"text": "FKBLEU", "start_pos": 238, "end_pos": 244, "type": "DATASET", "confidence": 0.5115242004394531}, {"text": "SARI", "start_pos": 249, "end_pos": 253, "type": "METRIC", "confidence": 0.8211201429367065}]}, {"text": " Table 5: Automatic evaluation of different simplification systems. Most systems achieve similar FK readability scores  as human. The SARI metric ranks all 5 different systems and 3 human references in the same order as human assess- ment. Tuning towards BLEU with all 8 references results in identical transformation (same as Normal Wikipedia),  as this can get a near-perfect BLEU score of 99.05 (out of 100).", "labels": [], "entities": [{"text": "SARI metric", "start_pos": 134, "end_pos": 145, "type": "METRIC", "confidence": 0.6297330558300018}, {"text": "BLEU", "start_pos": 255, "end_pos": 259, "type": "METRIC", "confidence": 0.9903410077095032}, {"text": "BLEU", "start_pos": 378, "end_pos": 382, "type": "METRIC", "confidence": 0.9990004897117615}]}, {"text": " Table 6: Average computation time of different metrics  per candidate sentence.", "labels": [], "entities": []}]}