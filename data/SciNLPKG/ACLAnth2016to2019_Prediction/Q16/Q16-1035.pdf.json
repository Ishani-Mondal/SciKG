{"title": [{"text": "The Galactic Dependencies Treebanks: Getting More Data by Synthesizing New Languages", "labels": [], "entities": []}], "abstractContent": [{"text": "We release Galactic Dependencies 1.0-a large set of synthetic languages not found on Earth, but annotated in Universal Dependencies format.", "labels": [], "entities": []}, {"text": "This new resource aims to provide training and development data for NLP methods that aim to adapt to unfamiliar languages.", "labels": [], "entities": []}, {"text": "Each synthetic treebank is produced from areal treebank by stochastically permut-ing the dependents of nouns and/or verbs to match the word order of other real languages.", "labels": [], "entities": []}, {"text": "We discuss the usefulness, realism, parsabil-ity, perplexity, and diversity of the synthetic languages.", "labels": [], "entities": [{"text": "realism", "start_pos": 27, "end_pos": 34, "type": "METRIC", "confidence": 0.9635365605354309}]}, {"text": "As a simple demonstration of the use of Galactic Dependencies, we consider single-source transfer, which attempts to parse areal target language using a parser trained on a \"nearby\" source language.", "labels": [], "entities": [{"text": "single-source transfer", "start_pos": 75, "end_pos": 97, "type": "TASK", "confidence": 0.7251686155796051}]}, {"text": "We find that including synthetic source languages somewhat increases the diversity of the source pool, which significantly improves results for most target languages.", "labels": [], "entities": []}, {"text": "1 Motivation Some potential NLP tasks have very sparse data by machine learning standards, as each of the IID training examples is an entire language.", "labels": [], "entities": []}, {"text": "For instance: \u2022 typological classification of a language on various dimensions; \u2022 adaptation of any existing NLP system to new, low-resource languages; \u2022 induction of a syntactic grammar from text; \u2022 discovery of a morphological lexicon from text; \u2022 other types of unsupervised discovery of linguistic structure.", "labels": [], "entities": [{"text": "typological classification of a language", "start_pos": 16, "end_pos": 56, "type": "TASK", "confidence": 0.804766446352005}]}, {"text": "Given a corpus or other data about a language, we might aim to predict whether it is an SVO language , or to learn to pick out its noun phrases.", "labels": [], "entities": []}, {"text": "For such problems, a single training or test example corresponds to an entire human language.", "labels": [], "entities": []}, {"text": "Unfortunately, we usually have only from 1 to 40 languages to work with.", "labels": [], "entities": []}, {"text": "In contrast, machine learning methods thrive on data, and recent AI successes have mainly been on tasks where one can train richly parameterized predictors on a huge set of IID (input, output) examples.", "labels": [], "entities": []}, {"text": "Even 7,000 training examples-one for each language or dialect on Earth-would be a small dataset by contemporary standards.", "labels": [], "entities": []}, {"text": "As a result, it is challenging to develop systems that will discover structure in new languages in the same way that an image segmentation method, for example, will discover structure in new images.", "labels": [], "entities": [{"text": "image segmentation", "start_pos": 120, "end_pos": 138, "type": "TASK", "confidence": 0.7383325695991516}]}, {"text": "The limited resources even make it challenging to develop methods that handle new languages by un-supervised, semi-supervised, or transfer learning.", "labels": [], "entities": []}, {"text": "Some such projects evaluate their methods on new sentences of the same languages that were used to develop the methods in the first place-which leaves one worried that the methods maybe inadvertently tuned to the development languages and may not be able to discover correct structure in other languages.", "labels": [], "entities": []}, {"text": "Other projects take care to holdout languages for evaluation (Spitkovsky, 2013; Cotterell et al., 2015), but then are left with only a few development languages on which to experiment with different unsu-pervised methods and their hyperparameters.", "labels": [], "entities": []}, {"text": "If we had many languages, then we could develop better unsupervised language learners.", "labels": [], "entities": []}, {"text": "Even better, we could treat linguistic structure discovery as a supervised learning problem.", "labels": [], "entities": [{"text": "linguistic structure discovery", "start_pos": 28, "end_pos": 58, "type": "TASK", "confidence": 0.7708408435185751}]}, {"text": "That is, we could train a system to extract features from the surface of a language that are predictive of its deeper structure.", "labels": [], "entities": []}, {"text": "Principles & Parameters theory (Chomsky, 1981) conjectures that such features exist and that the juvenile human brain is adapted to extract them.", "labels": [], "entities": []}, {"text": "Our goal in this paper is to release a set of about 50,000 high-resource languages that could be used to train supervised learners, or to evaluate less-supervised learners during development.", "labels": [], "entities": []}, {"text": "These \"un-earthly\" languages are intended to beat least sim-491", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "We now illustrate the use of GD by studying how expanding the set of available treebanks can improve a simple NLP method, related to Figure 4.", "labels": [], "entities": []}, {"text": "We evaluate single-source transfer when the pool of m source languages consists of n real UD languages, plus m \u2212 n synthetic GD languages derived by \"remixing\" just these real languages.", "labels": [], "entities": [{"text": "single-source transfer", "start_pos": 12, "end_pos": 34, "type": "TASK", "confidence": 0.7423934042453766}]}, {"text": "We try various values of n and m, where n can be as large as 10 (training languages from) and m can be as large as n \u00d7 (n + 1) \u00d7 (n + 1) \u2264 1210 (see \u00a75).", "labels": [], "entities": []}, {"text": "Given areal target language T from outside the pool, we select a single source language S from the pool, and try to parse UD sentences of T with a parser trained on S.", "labels": [], "entities": []}, {"text": "We evaluate the results on T by measuring the unlabeled attachment score (UAS), The m \u2212 n GD treebanks are comparatively impoverished because-in the current GD release-they include only projective sentences).", "labels": [], "entities": [{"text": "unlabeled attachment score (UAS)", "start_pos": 46, "end_pos": 78, "type": "METRIC", "confidence": 0.7829325397809347}, {"text": "GD treebanks", "start_pos": 90, "end_pos": 102, "type": "DATASET", "confidence": 0.7943450212478638}]}, {"text": "The n UD treebanks are unfiltered. that is, the fraction of word tokens that were assigned their correct parent.", "labels": [], "entities": []}, {"text": "In these experiments (unlike those of \u00a76), we always evaluate fairly on T 's full dev or test set from UD-not just the sentences we kept for its GD version (cf.).", "labels": [], "entities": []}, {"text": "The hope is that a large pool will contain at least one language-real or synthetic-that is \"close\" to T . We have two ways of trying to select a source S with this property: Supervised selection selects the S whose parser achieves the highest UAS on 100 training sentences of language T . This requires 100 good trees for T , which could be obtained with a modest investment-a single annotator attempting to follow the UD annotation standards in a consistent way on 100 sentences of T , without writing out formal Tspecific guidelines.", "labels": [], "entities": [{"text": "UAS", "start_pos": 243, "end_pos": 246, "type": "METRIC", "confidence": 0.9962967038154602}]}, {"text": "(There is no guarantee that selecting a parser on training data will choose well for the test sentences of T . We are using a small amount of data to select among many dubious parsers, many of which achieve similar results on the training sentences of T . Furthermore, in the UD treebanks, the test sentences of T are sometimes drawn from a different distribution than the training sentences.)", "labels": [], "entities": [{"text": "UD treebanks", "start_pos": 276, "end_pos": 288, "type": "DATASET", "confidence": 0.9094423055648804}]}, {"text": "Unsupervised selection selects the S whose training sentences had the best \"coverage\" of the POS tag sequences in the actual data from T that we aim to parse.", "labels": [], "entities": []}, {"text": "More precisely, we choose the S that maximizes p S (tag sequences from T )-in other words, the maximum-likelihood S-where p S is our trigram language model for the tag sequences of S.", "labels": [], "entities": []}, {"text": "This approach is loosely inspired by S\u00f8gaard (2011).", "labels": [], "entities": [{"text": "S\u00f8gaard (2011)", "start_pos": 37, "end_pos": 51, "type": "TASK", "confidence": 0.7088415771722794}]}], "tableCaptions": [{"text": " Table 2: Some statistics on the 10 real training lan- guages. When two numbers are separated by \"/\", the sec- ond represents the full UD treebank, and the first comes  from our GD version, which discards non-projective trees  and high-fanout trees (n \u2265 8). UAS is the language's  parsability: the unlabeled attachment score on its dev  sentences after training on its train sentences. T is the  percentage of GD tokens that are touched by reordering  (namely N, V, and their dependents). R \u2208 [0, 1] measures  the freeness of the language's word order, as the condi- tional cross-entropy of our trained ordering model p \u03b8 rel- ative to that of a uniform distribution:", "labels": [], "entities": []}, {"text": " Table 4: Tagging accuracy on the 10 dev languages, and  UAS of the selected source parser with these noisy target- language tag sequences. The results are formatted as in", "labels": [], "entities": [{"text": "Tagging", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9515584111213684}, {"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9763937592506409}, {"text": "UAS", "start_pos": 57, "end_pos": 60, "type": "METRIC", "confidence": 0.9929373860359192}]}]}