{"title": [{"text": "Multilingual Projection for Parsing Truly Low-Resource Language\u0161", "labels": [], "entities": [{"text": "Parsing Truly Low-Resource Language\u0161", "start_pos": 28, "end_pos": 64, "type": "TASK", "confidence": 0.8248339891433716}]}], "abstractContent": [{"text": "We propose a novel approach to cross-lingual part-of-speech tagging and dependency parsing for truly low-resource languages.", "labels": [], "entities": [{"text": "cross-lingual part-of-speech tagging", "start_pos": 31, "end_pos": 67, "type": "TASK", "confidence": 0.6289917826652527}, {"text": "dependency parsing", "start_pos": 72, "end_pos": 90, "type": "TASK", "confidence": 0.7398441135883331}]}, {"text": "Our annotation projection-based approach yields tagging and parsing models for over 100 languages.", "labels": [], "entities": []}, {"text": "All that is needed are freely available parallel texts, and taggers and parsers for resource-rich languages.", "labels": [], "entities": []}, {"text": "The empirical evaluation across 30 test languages shows that our method consistently provides top-level accuracies , close to established upper bounds, and outperforms several competitive baselines.", "labels": [], "entities": []}], "introductionContent": [{"text": "State-of-the-art approaches to inducing part-ofspeech (POS) taggers and dependency parsers only scale to a small fraction of the world's \u223c6,900 languages.", "labels": [], "entities": [{"text": "part-ofspeech (POS) taggers and dependency parsers", "start_pos": 40, "end_pos": 90, "type": "TASK", "confidence": 0.6082549765706062}]}, {"text": "The major bottleneck is the lack of manually annotated resources for the vast majority of these languages, including languages spoken by millions, such as Marathi (73m), Hausa (50m), and Kurdish (30m).", "labels": [], "entities": []}, {"text": "Cross-lingual transfer learning-or simply cross-lingual learning-refers to work on using annotated resources in other (source) languages to induce models for such low-resource (target) languages.", "labels": [], "entities": [{"text": "Cross-lingual transfer learning-or simply cross-lingual learning-refers", "start_pos": 0, "end_pos": 71, "type": "TASK", "confidence": 0.7626178115606308}]}, {"text": "Even simple cross-lingual learning techniques outperform unsupervised grammar induction by a large margin.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 70, "end_pos": 87, "type": "TASK", "confidence": 0.7057098895311356}]}, {"text": "Most work in cross-lingual learning, however, makes assumptions about the availability of linguistic resources that do not hold for the majority of low-resource languages.", "labels": [], "entities": []}, {"text": "The best cross-lingual dependency parsing results reported to date were presented by.", "labels": [], "entities": [{"text": "cross-lingual dependency parsing", "start_pos": 9, "end_pos": 41, "type": "TASK", "confidence": 0.6880746483802795}]}, {"text": "They use the intersection of languages covered in the Google dependency treebanks project and those contained in the Europarl corpus.", "labels": [], "entities": [{"text": "Google dependency treebanks project", "start_pos": 54, "end_pos": 89, "type": "DATASET", "confidence": 0.7204132229089737}, {"text": "Europarl corpus", "start_pos": 117, "end_pos": 132, "type": "DATASET", "confidence": 0.9907179772853851}]}, {"text": "Consequently, they only consider closely related Indo-European languages for which high-quality tokenization can be obtained with simple heuristics.", "labels": [], "entities": []}, {"text": "In other words, we argue that recent approaches to cross-lingual POS tagging and dependency parsing are biased toward Indo-European languages, in particular the Germanic and Romance families.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 65, "end_pos": 76, "type": "TASK", "confidence": 0.8517561554908752}, {"text": "dependency parsing", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.8158902823925018}]}, {"text": "The bias is not hard to explain: treebanks, as well as large volumes of parallel data, are readily available for many Germanic and Romance languages.", "labels": [], "entities": []}, {"text": "Several factors make cross-lingual learning between these languages easier: (i) We have large volumes of relatively representative, translated texts available for all language pairs; (ii) It is relatively easy to segment and tokenize Germanic and Romance texts; (iii) These languages all have very similar word order, making the alignments much more reliable.", "labels": [], "entities": [{"text": "tokenize Germanic and Romance texts", "start_pos": 225, "end_pos": 260, "type": "TASK", "confidence": 0.8235352039337158}]}, {"text": "Therefore, it is more straightforward to train and evaluate cross-lingual transfer models for these languages.", "labels": [], "entities": []}, {"text": "However, this bias means that we possibly overestimate the potential of cross-lingual learning for truly low-resource languages, i.e., languages with no supporting tools or resources for segmentation, POS tagging, or dependency parsing.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 201, "end_pos": 212, "type": "TASK", "confidence": 0.8694278001785278}, {"text": "dependency parsing", "start_pos": 217, "end_pos": 235, "type": "TASK", "confidence": 0.8157471120357513}]}, {"text": "The aim of this work is to experiment with crosslingual learning via annotation projection, making minimal assumptions about the available linguistic resources.", "labels": [], "entities": []}, {"text": "We only want to assume what we can in fact assume for truly low-resource languages.", "labels": [], "entities": []}, {"text": "Thus, for the target languages, we do not assume the avail-ability of any labeled data, tag dictionaries, typological information, etc.", "labels": [], "entities": [{"text": "avail-ability", "start_pos": 53, "end_pos": 66, "type": "METRIC", "confidence": 0.9872035384178162}]}, {"text": "For annotation projection, we need a parallel corpus, and we therefore have to rely on resources such as the Bible (parts of which are available in 1,646 languages), and publications from the Watchtower Society (up to 583 languages).", "labels": [], "entities": [{"text": "annotation projection", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.8995168507099152}, {"text": "Watchtower Society", "start_pos": 192, "end_pos": 210, "type": "DATASET", "confidence": 0.9645121097564697}]}, {"text": "These texts have the advantage of being translated both conservatively and into hundreds of languages (massively multi-parallel).", "labels": [], "entities": []}, {"text": "However, the Bible and the Watchtower are religious texts and are more biased than the corpora that have been assumed to be available inmost previous work.", "labels": [], "entities": []}, {"text": "In order to induce high-quality cross-lingual transfer models from noisy and very limited data, we exploit the fact that the available resources are massively multi-parallel.", "labels": [], "entities": []}, {"text": "We also present a novel multilingual approach to the projection of dependency structures, projecting edge weights (rather than edges) via word alignments from multiple sources (rather than a single source).", "labels": [], "entities": [{"text": "projection of dependency structures", "start_pos": 53, "end_pos": 88, "type": "TASK", "confidence": 0.8356149941682816}]}, {"text": "Our approach enables us to project more information than previous approaches: (i) by postponing dependency tree decoding to after the projection, and (ii) by exploiting multiple information sources.", "labels": [], "entities": []}, {"text": "Our contributions are as follows: (i) We present the first results on cross-lingual learning of POS taggers and dependency parsers, assuming only linguistic resources that are available for most of the world's written languages, specifically, Bible excerpts and translations of the Watchtower.", "labels": [], "entities": [{"text": "POS taggers and dependency parsers", "start_pos": 96, "end_pos": 130, "type": "TASK", "confidence": 0.730461585521698}, {"text": "Bible excerpts and translations of the Watchtower", "start_pos": 243, "end_pos": 292, "type": "DATASET", "confidence": 0.5901648444788796}]}, {"text": "(ii) We extend annotation projection of syntactic dependencies across parallel text to the multisource scenario, introducing anew, heuristicsfree projection algorithm that projects weight matrices from multiple sources, rather than dependency trees or individual dependencies from a single source.", "labels": [], "entities": [{"text": "annotation projection of syntactic dependencies across parallel text", "start_pos": 15, "end_pos": 83, "type": "TASK", "confidence": 0.8393203243613243}]}, {"text": "(iii) We show that our approach performs significantly better than commonly used heuristics for annotation projection, as well as than delexicalized transfer baselines.", "labels": [], "entities": [{"text": "annotation projection", "start_pos": 96, "end_pos": 117, "type": "TASK", "confidence": 0.7511181533336639}]}, {"text": "Moreover, in comparison to these systems, our approach performs particularly well on truly low-resource non-Indo-European languages.", "labels": [], "entities": []}, {"text": "All code and data are made freely available for general use.", "labels": [], "entities": []}], "datasetContent": [{"text": "Outline For each sentence in a target language corpus, we retrieve the aligned sentences in the source corpora.", "labels": [], "entities": []}, {"text": "Then, for each of these source-target sentence pairs, we project POS tags and dependency edge scores via word alignments, aggregating the contributions of individual sources.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 105, "end_pos": 120, "type": "TASK", "confidence": 0.6825879961252213}]}, {"text": "Once all contributions are collected, we perform a per-token majority vote on POS tags and DMST decoding on the summed edge scores.", "labels": [], "entities": []}, {"text": "This results in a POS-tagged and dependency parsed target sentence ready to contribute in training a tagger and parser.", "labels": [], "entities": []}, {"text": "We remove target language sentences that contain word tokens without POS labels.", "labels": [], "entities": []}, {"text": "This may happen due to unaligned sentences and words.", "labels": [], "entities": []}, {"text": "We then proceed to train models.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: POS tagging accuracies and UAS parsing scores for the models built using WTC data. The results are  split for source and target languages. All baselines and upper bounds use IBM1 POS taggers, while our MULTI-PROJ  systems use their respective IBM1 or IBM2 taggers.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.7163393497467041}, {"text": "UAS parsing", "start_pos": 37, "end_pos": 48, "type": "TASK", "confidence": 0.8161512017250061}, {"text": "WTC data", "start_pos": 83, "end_pos": 91, "type": "DATASET", "confidence": 0.8701173365116119}]}]}