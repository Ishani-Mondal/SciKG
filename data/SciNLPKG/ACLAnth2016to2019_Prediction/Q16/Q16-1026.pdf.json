{"title": [{"text": "Named Entity Recognition with Bidirectional LSTM-CNNs", "labels": [], "entities": [{"text": "Entity Recognition", "start_pos": 6, "end_pos": 24, "type": "TASK", "confidence": 0.7028605937957764}]}], "abstractContent": [{"text": "Named entity recognition is a challenging task that has traditionally required large amounts of knowledge in the form of feature engineering and lexicons to achieve high performance.", "labels": [], "entities": [{"text": "Named entity recognition", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7365349332491556}]}, {"text": "In this paper, we present a novel neural network architecture that automatically detects word-and character-level features using a hybrid bidirectional LSTM and CNN architecture , eliminating the need for most feature engineering.", "labels": [], "entities": []}, {"text": "We also propose a novel method of encoding partial lexicon matches in neu-ral networks and compare it to existing approaches.", "labels": [], "entities": []}, {"text": "Extensive evaluation shows that, given only tokenized text and publicly available word embeddings, our system is competitive on the CoNLL-2003 dataset and surpasses the previously reported state of the art performance on the OntoNotes 5.0 dataset by 2.13 F1 points.", "labels": [], "entities": [{"text": "CoNLL-2003 dataset", "start_pos": 132, "end_pos": 150, "type": "DATASET", "confidence": 0.9809844493865967}, {"text": "OntoNotes 5.0 dataset", "start_pos": 225, "end_pos": 246, "type": "DATASET", "confidence": 0.9200558463732401}, {"text": "F1", "start_pos": 255, "end_pos": 257, "type": "METRIC", "confidence": 0.9868257641792297}]}, {"text": "By using two lexicons constructed from publicly-available sources, we establish new state of the art performance with an F1 score of 91.62 on CoNLL-2003 and 86.28 on OntoNotes, surpassing systems that employ heavy feature engineering, proprietary lexicons, and rich entity linking information.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 121, "end_pos": 129, "type": "METRIC", "confidence": 0.9827032685279846}, {"text": "CoNLL-2003", "start_pos": 142, "end_pos": 152, "type": "DATASET", "confidence": 0.9101583361625671}, {"text": "OntoNotes", "start_pos": 166, "end_pos": 175, "type": "DATASET", "confidence": 0.8964460492134094}]}], "introductionContent": [{"text": "Named entity recognition is an important task in NLP.", "labels": [], "entities": [{"text": "Named entity recognition", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7217520674069723}]}, {"text": "High performance approaches have been dominated by applying CRF, SVM, or perceptron models to hand-crafted features).", "labels": [], "entities": []}, {"text": "However, proposed an effective neural network model that requires little feature engineering and instead learns important features from word embeddings trained on large quantities of unlabelled text -an approach made possible by recent advancements in unsupervised learning of word embeddings on massive amounts of data) and neural network training algorithms permitting deep architectures (.", "labels": [], "entities": []}, {"text": "Unfortunately there are many limitations to the model proposed by.", "labels": [], "entities": []}, {"text": "First, it uses a simple feed-forward neural network, which restricts the use of context to a fixed sized window around each word -an approach that discards useful long-distance relations between words.", "labels": [], "entities": []}, {"text": "Second, by depending solely on word embeddings, it is unable to exploit explicit character level features such as prefix and suffix, which could be useful especially with rare words where word embeddings are poorly trained.", "labels": [], "entities": []}, {"text": "We seek to address these issues by proposing a more powerful neural network model.", "labels": [], "entities": []}, {"text": "A well-studied solution fora neural network to process variable length input and have long term memory is the recurrent neural network (RNN).", "labels": [], "entities": []}, {"text": "Recently, RNNs have shown great success in diverse NLP tasks such as speech recognition (, machine translation (, and language modeling).", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 69, "end_pos": 87, "type": "TASK", "confidence": 0.83243128657341}, {"text": "machine translation", "start_pos": 91, "end_pos": 110, "type": "TASK", "confidence": 0.8375190794467926}, {"text": "language modeling", "start_pos": 118, "end_pos": 135, "type": "TASK", "confidence": 0.7279451489448547}]}, {"text": "The long-short term memory (LSTM) unit with the forget gate allows highly non-trivial long-distance dependencies to be easily learned ().", "labels": [], "entities": []}, {"text": "For sequential labelling tasks such as NER and speech recognition, a bi-directional LSTM model can take into account an effectively infinite amount of context on both sides of a word and eliminates the problem of limited context that applies to any feed-forward model (.", "labels": [], "entities": [{"text": "NER", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.9594773650169373}, {"text": "speech recognition", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.715832844376564}]}, {"text": "While LSTMs have been studied in the past for the NER task by, the lack of computational power (which led to the use  of very small models) and quality word embeddings limited their effectiveness.", "labels": [], "entities": [{"text": "NER task", "start_pos": 50, "end_pos": 58, "type": "TASK", "confidence": 0.9427681863307953}]}, {"text": "Convolutional neural networks (CNN) have also been investigated for modeling character-level information, among other NLP tasks. and successfully employed CNNs to extract character-level features for use in NER and POS-tagging respectively.", "labels": [], "entities": []}, {"text": "also applied CNNs to semantic role labeling, and variants of the architecture have been applied to parsing and other tasks requiring tree structures ().", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 21, "end_pos": 43, "type": "TASK", "confidence": 0.7140605847040812}, {"text": "parsing", "start_pos": 99, "end_pos": 106, "type": "TASK", "confidence": 0.972875714302063}]}, {"text": "However, the effectiveness of character-level CNNs has not been evaluated for English NER.", "labels": [], "entities": [{"text": "character-level CNNs", "start_pos": 30, "end_pos": 50, "type": "TASK", "confidence": 0.6078478991985321}, {"text": "English NER", "start_pos": 78, "end_pos": 89, "type": "TASK", "confidence": 0.4163985848426819}]}, {"text": "While we considered using character-level bi-directional LSTMs, which was recently proposed by for POStagging, preliminary evaluation shows that it does not perform significantly better than CNNs while being more computationally expensive to train.", "labels": [], "entities": []}, {"text": "Our main contribution lies in combining these neural network models for the NER task.", "labels": [], "entities": [{"text": "NER task", "start_pos": 76, "end_pos": 84, "type": "TASK", "confidence": 0.9394000172615051}]}, {"text": "We present a hybrid model of bi-directional LSTMs and CNNs  that learns both character-and word-level features, presenting the first evaluation of such an architecture on well-established English language evaluation datasets.", "labels": [], "entities": []}, {"text": "Furthermore, as lexicons are crucial to NER performance, we propose anew lexicon encoding scheme and matching algorithm that can make use of partial matches, and we compare it to the simpler approach of.", "labels": [], "entities": [{"text": "NER", "start_pos": 40, "end_pos": 43, "type": "TASK", "confidence": 0.9766685366630554}]}, {"text": "Extensive evaluation shows that our proposed method establishes anew state of the art on both the CoNLL-2003 NER shared task and the OntoNotes 5.0 datasets.", "labels": [], "entities": [{"text": "CoNLL-2003 NER shared task", "start_pos": 98, "end_pos": 124, "type": "DATASET", "confidence": 0.8243611603975296}, {"text": "OntoNotes 5.0 datasets", "start_pos": 133, "end_pos": 155, "type": "DATASET", "confidence": 0.8447164495786031}]}], "datasetContent": [{"text": "Evaluation was performed on the well-established CoNLL-2003 NER shared task dataset) and the much larger but less-studied OntoNotes 5.0 dataset (.", "labels": [], "entities": [{"text": "CoNLL-2003 NER shared task dataset", "start_pos": 49, "end_pos": 83, "type": "DATASET", "confidence": 0.8596222519874572}, {"text": "OntoNotes 5.0 dataset", "start_pos": 122, "end_pos": 143, "type": "DATASET", "confidence": 0.8529192209243774}]}, {"text": "gives an overview of these two different datasets.", "labels": [], "entities": []}, {"text": "For each experiment, we report the average and standard deviation of 10 successful trials.", "labels": [], "entities": [{"text": "standard deviation", "start_pos": 47, "end_pos": 65, "type": "METRIC", "confidence": 0.9566953182220459}]}, {"text": "Adding dropout to inputs seems to have an adverse effect.", "labels": [], "entities": []}, {"text": "For all datasets, we performed the following preprocessing: \u2022 All digit sequences are replaced by a single \"0\".", "labels": [], "entities": []}, {"text": "\u2022 Before training, we group sentences byword length into mini-batches and shuffle them.", "labels": [], "entities": []}, {"text": "In addition, for the OntoNotes dataset, in order to handle the Date, Time, Money, Percent, Quantity, Ordinal, and Cardinal named entity tags, we split tokens before and after every digit.", "labels": [], "entities": [{"text": "OntoNotes dataset", "start_pos": 21, "end_pos": 38, "type": "DATASET", "confidence": 0.9445523917675018}]}, {"text": "The CoNLL-2003 dataset consists of newswire from the Reuters RCV1 corpus tagged with four types of named entities: location, organization, person, and miscellaneous.", "labels": [], "entities": [{"text": "CoNLL-2003 dataset", "start_pos": 4, "end_pos": 22, "type": "DATASET", "confidence": 0.9514375329017639}, {"text": "Reuters RCV1 corpus tagged", "start_pos": 53, "end_pos": 79, "type": "DATASET", "confidence": 0.9364785254001617}]}, {"text": "As the dataset is small compared to OntoNotes, we trained the model on both the training and development sets after performing hyperparameter optimization on the development set.", "labels": [], "entities": [{"text": "OntoNotes", "start_pos": 36, "end_pos": 45, "type": "DATASET", "confidence": 0.8733837604522705}]}, {"text": "(2013) compiled a core portion of the OntoNotes 5.0 dataset for the CoNLL-2012 shared task and described a standard train/dev/test split, which we use for our evaluation.", "labels": [], "entities": [{"text": "OntoNotes 5.0 dataset", "start_pos": 38, "end_pos": 59, "type": "DATASET", "confidence": 0.8726929426193237}, {"text": "CoNLL-2012 shared task", "start_pos": 68, "end_pos": 90, "type": "DATASET", "confidence": 0.7450939019521078}]}, {"text": "Following, we applied our model to the portion of the dataset with gold-standard named entity annotations; the New Testaments portion was excluded for lacking gold-standard annotations.", "labels": [], "entities": []}, {"text": "This dataset is much larger than CoNLL-2003 and consists of text from a wide variety of sources, such as broadcast conversation, broadcast news, newswire, magazine, telephone conversation, and Web text.", "labels": [], "entities": [{"text": "CoNLL-2003", "start_pos": 33, "end_pos": 43, "type": "DATASET", "confidence": 0.9181076288223267}]}], "tableCaptions": [{"text": " Table 1: Number of entries for each category in the  SENNA lexicon and our DBpedia lexicon.", "labels": [], "entities": [{"text": "SENNA lexicon", "start_pos": 54, "end_pos": 67, "type": "DATASET", "confidence": 0.9289483428001404}, {"text": "DBpedia lexicon", "start_pos": 76, "end_pos": 91, "type": "DATASET", "confidence": 0.9751949906349182}]}, {"text": " Table 2: Dataset sizes in number of tokens (entities)", "labels": [], "entities": []}, {"text": " Table 3: Hyper-parameter search space and final values used for all experiments", "labels": [], "entities": []}, {"text": " Table 5: Results of our models, with various feature sets, compared to other published results. The three sections  are, in order, our models, published neural network models, and published non-neural network models. For the  features, emb = Collobert word embeddings, caps = capitalization feature, lex = lexicon features from both SENNA  and DBpedia lexicons. For F1 scores, standard deviations are in parentheses.", "labels": [], "entities": [{"text": "DBpedia lexicons", "start_pos": 345, "end_pos": 361, "type": "DATASET", "confidence": 0.7810098528862}, {"text": "F1 scores", "start_pos": 367, "end_pos": 376, "type": "METRIC", "confidence": 0.9717113077640533}]}, {"text": " Table 8: F1 score results with various dropout values. Models were trained using only the training set for each dataset.  All other experiments use dropout = 0.68 for CoNLL-2003 and dropout = 0.63 for OntoNotes 5.0.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.975911945104599}, {"text": "CoNLL-2003", "start_pos": 168, "end_pos": 178, "type": "DATASET", "confidence": 0.930390477180481}]}, {"text": " Table 10: Per genre F1 scores on OntoNotes. BC = broadcast conversation, BN = broadcast news, MZ = magazine,  NW = newswire, TC = telephone conversation, WB = blogs and newsgroups", "labels": [], "entities": [{"text": "OntoNotes", "start_pos": 34, "end_pos": 43, "type": "DATASET", "confidence": 0.9101451635360718}, {"text": "BN", "start_pos": 74, "end_pos": 76, "type": "METRIC", "confidence": 0.9729374051094055}]}]}