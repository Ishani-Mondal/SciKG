{"title": [{"text": "Word Embeddings as Metric Recovery in Semantic Spaces", "labels": [], "entities": []}], "abstractContent": [{"text": "Continuous word representations have been remarkably useful across NLP tasks but remain poorly understood.", "labels": [], "entities": []}, {"text": "We ground word embeddings in semantic spaces studied in the cognitive-psychometric literature, taking these spaces as the primary objects to recover.", "labels": [], "entities": []}, {"text": "To this end, we relate log co-occurrences of words in large corpora to semantic similarity assessments and show that co-occurrences are indeed consistent with an Euclidean semantic space hypothesis.", "labels": [], "entities": []}, {"text": "Framing word embedding as metric recovery of a semantic space unifies existing word embedding algorithms, ties them to manifold learning, and demonstrates that existing algorithms are consistent metric recovery methods given co-occurrence counts from random walks.", "labels": [], "entities": []}, {"text": "Furthermore, we propose a simple, principled, direct metric recovery algorithm that performs on par with the state-of-the-art word embedding and manifold learning methods.", "labels": [], "entities": [{"text": "metric recovery", "start_pos": 53, "end_pos": 68, "type": "TASK", "confidence": 0.7188393771648407}]}, {"text": "Finally, we complement recent focus on analogies by constructing two new in-ductive reasoning datasets-series completion and classification-and demonstrate that word embeddings can be used to solve them as well.", "labels": [], "entities": []}], "introductionContent": [{"text": "Continuous space models of words, objects, and signals have become ubiquitous tools for learning rich representations of data, from natural language processing to computer vision.", "labels": [], "entities": []}, {"text": "Specifically, there has been particular interest in word embeddings, largely due to their intriguing semantic properties ( and their success as features for downstream natural language processing tasks, such as named entity recognition () and parsing.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 211, "end_pos": 235, "type": "TASK", "confidence": 0.6515219310919443}]}, {"text": "The empirical success of word embeddings has prompted a parallel body of work that seeks to better understand their properties, associated estimation algorithms, and explore possible revisions.", "labels": [], "entities": []}, {"text": "Recently, showed that linear linguistic regularities first observed with word2vec extend to other embedding methods.", "labels": [], "entities": []}, {"text": "In particular, explicit representations of words in terms of cooccurrence counts can be used to solve analogies in the same way.", "labels": [], "entities": []}, {"text": "In terms of algorithms, demonstrated that the global minimum of the skip-gram method with negative sampling of implicitly factorizes a shifted version of the pointwise mutual information (PMI) matrix of word-context pairs.", "labels": [], "entities": []}, {"text": "explored links between random walks and word embeddings, relating them to contextual (probability ratio) analogies, under specific (isotropic) assumptions about word vectors.", "labels": [], "entities": []}, {"text": "In this work, we take semantic spaces studied in the cognitive-psychometric literature as the prototypical objects that word embedding algorithms estimate.", "labels": [], "entities": []}, {"text": "Semantic spaces are vector spaces over concepts where Euclidean distances between points are assumed to indicate semantic similarities.", "labels": [], "entities": []}, {"text": "We link such semantic spaces to word co-occurrences through semantic similarity assessments, and demonstrate that the observed cooccurrence counts indeed possess statistical properties that are consistent with an underlying Euclidean space where distances are linked to semantic similarity.", "labels": [], "entities": []}, {"text": "Figure 1: Inductive reasoning in semantic space proposed in.", "labels": [], "entities": [{"text": "Inductive reasoning", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.7443828284740448}]}, {"text": "A, B, C are given, I is the ideal point and Dare the choices.", "labels": [], "entities": []}, {"text": "The correct answer is shaded green.", "labels": [], "entities": []}, {"text": "Formally, we view word embedding methods as performing metric recovery.", "labels": [], "entities": [{"text": "metric recovery", "start_pos": 55, "end_pos": 70, "type": "TASK", "confidence": 0.7155413627624512}]}, {"text": "This perspective is significantly different from current approaches.", "labels": [], "entities": []}, {"text": "Instead of aiming for representations that exhibit specific semantic properties or that perform well at a particular task, we seek methods that recover the underlying metric of the hypothesized semantic space.", "labels": [], "entities": []}, {"text": "The clearer foundation afforded by this perspective enables us to analyze word embedding algorithms in a principled task-independent fashion.", "labels": [], "entities": []}, {"text": "In particular, we ask whether word embedding algorithms are able to recover the metric under specific scenarios.", "labels": [], "entities": []}, {"text": "To this end, we unify existing word embedding algorithms as statistically consistent metric recovery methods under the theoretical assumption that cooccurrences arise from (metric) random walks over semantic spaces.", "labels": [], "entities": []}, {"text": "The new setting also suggests a simple and direct recovery algorithm which we evaluate and compare against other embedding methods.", "labels": [], "entities": []}, {"text": "The main contributions of this work can be summarized as follows: \u2022 We ground word embeddings in semantic spaces via log co-occurrence counts.", "labels": [], "entities": []}, {"text": "We show that PMI (pointwise mutual information) relates linearly to human similarity assessments, and that nearest-neighbor statistics (centrality and reciprocity) are consistent with an Euclidean space hypothesis (Sections 2 and 3).", "labels": [], "entities": []}, {"text": "\u2022 In contrast to prior work (, we take metric recovery as the key object of study, unifying existing algorithms as consistent metric recovery methods based on cooccurrence counts from simple Markov random walks over graphs and manifolds.", "labels": [], "entities": [{"text": "metric recovery", "start_pos": 39, "end_pos": 54, "type": "TASK", "confidence": 0.8035315275192261}]}, {"text": "This strong link to manifold estimation opens a promising direction for extensions of word embedding methods (Sections and 4 and 5).", "labels": [], "entities": []}, {"text": "\u2022 We propose and evaluate anew principled direct metric recovery algorithm that performs comparably to the existing state of the art on both word embedding and manifold learning tasks, and show that GloVe () is closely related to the second-order Taylor expansion of our objective.", "labels": [], "entities": [{"text": "direct metric recovery", "start_pos": 42, "end_pos": 64, "type": "TASK", "confidence": 0.6991127332051595}, {"text": "GloVe", "start_pos": 199, "end_pos": 204, "type": "METRIC", "confidence": 0.948395311832428}]}, {"text": "\u2022 We construct and make available two new inductive reasoning datasets 1 -series completion and classification-to extend the evaluation of word representations beyond analogies, and demonstrate that these tasks can be solved with vector operations on word embeddings as well (Examples in).", "labels": [], "entities": []}], "datasetContent": [{"text": "Corpus and training: We used three different corpora for training: a Wikipedia snapshot of 03/2015 (2.4B tokens), the original word2vec corpus () (6.4B tokens), and a combination of Wikipedia with Gigaword5 emulating GloVe's corpus () (5.8B tokens).", "labels": [], "entities": [{"text": "Wikipedia snapshot of 03/2015", "start_pos": 69, "end_pos": 98, "type": "DATASET", "confidence": 0.8476533790429434}, {"text": "word2vec corpus", "start_pos": 127, "end_pos": 142, "type": "DATASET", "confidence": 0.803045004606247}]}, {"text": "We preprocessed all corpora by removing punctuation, numbers and lower-casing all the text.", "labels": [], "entities": []}, {"text": "The vocabulary was restricted to the 100K most frequent words in each corpus.", "labels": [], "entities": []}, {"text": "We trained embeddings using four methods: word2vec, GloVe, randomized SVD, and metric regression (referred to as regression).", "labels": [], "entities": []}, {"text": "Full implementation details are provided in the Appendix.", "labels": [], "entities": [{"text": "Appendix", "start_pos": 48, "end_pos": 56, "type": "DATASET", "confidence": 0.7457120418548584}]}, {"text": "For fairness we fix all hyperparameters, and develop and test the code for metric regression exclusively on the first 1GB subset of the wiki dataset.", "labels": [], "entities": []}, {"text": "For open-vocabulary tasks, we restrict the set of answers to the top 30K words, since this improves performance while covering the majority of the questions.", "labels": [], "entities": []}, {"text": "In the following, we show performance for the GloVe corpus throughout but include results for all corpora along with our code package.", "labels": [], "entities": [{"text": "GloVe corpus", "start_pos": 46, "end_pos": 58, "type": "DATASET", "confidence": 0.9562723636627197}]}, {"text": "Evaluation tasks: We test the quality of the word embeddings on three types of inductive tasks: analogies, sequence completion and classification (.", "labels": [], "entities": [{"text": "sequence completion", "start_pos": 107, "end_pos": 126, "type": "TASK", "confidence": 0.7153021991252899}]}, {"text": "For the analogies, we used the standard openvocabulary analogy task of (henceforth denoted Google), consisting of 19,544 semantic and syntactic questions.", "labels": [], "entities": []}, {"text": "In addition, we use the more difficult SAT analogy dataset (version 3) (, which contains 374 questions from actual exams and guidebooks.", "labels": [], "entities": [{"text": "SAT analogy dataset", "start_pos": 39, "end_pos": 58, "type": "DATASET", "confidence": 0.7517965336640676}]}, {"text": "Each question consists of 5 exemplar pairs of words word1:word2, where the same relation holds for all pairs.", "labels": [], "entities": []}, {"text": "The task is to pick from among another five pairs of words the one that best fits the category implicitly defined by the exemplars.", "labels": [], "entities": []}, {"text": "Inspired by, we propose two new difficult inductive reasoning tasks beyond analogies to verify the semantic space hypothesis: sequence completion and classification.", "labels": [], "entities": [{"text": "sequence completion", "start_pos": 126, "end_pos": 145, "type": "TASK", "confidence": 0.7815004587173462}]}, {"text": "As described in Section 2, the former involves choosing the next step in a semantically coherent sequence of words (e.g. hour, minute, . .", "labels": [], "entities": []}, {"text": ".), and the latter consists of selecting an element within the same category out of five possible choices.", "labels": [], "entities": []}, {"text": "Given the lack of publicly available datasets, we generated our own questions using WordNet relations and word-word PMI values.", "labels": [], "entities": []}, {"text": "These datasets were constructed before training the embeddings, so as to avoid biasing them towards anyone method.", "labels": [], "entities": []}, {"text": "For the classification task, we created in-category words by selecting words from WordNet relations associated to root words, from which we pruned to four words based on PMI-similarity to the other words in the class.", "labels": [], "entities": [{"text": "PMI-similarity", "start_pos": 170, "end_pos": 184, "type": "METRIC", "confidence": 0.8909748196601868}]}, {"text": "Additional options for the multiple choice questions were created searching over words related to the root by a different relation type, and selecting those most similar to the root.", "labels": [], "entities": []}, {"text": "For the sequence completion task, we obtained WordNet trees of various relation types, and pruned these based on similarity to the root word to obtain the sequence.", "labels": [], "entities": [{"text": "sequence completion", "start_pos": 8, "end_pos": 27, "type": "TASK", "confidence": 0.7756941020488739}, {"text": "WordNet trees", "start_pos": 46, "end_pos": 59, "type": "DATASET", "confidence": 0.9056046903133392}]}, {"text": "For the multiple-choice questions, we proceeded as before to select additional (incorrect) options of a different relation type to the root.", "labels": [], "entities": []}, {"text": "After pruning, we obtain 215 classification questions and 220 sequence completion questions, of which 51 are open-vocabulary and 169 are multiple choice.", "labels": [], "entities": []}, {"text": "These two new datasets are available 9 .", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Semantic similarity data derived from mul- tiple sources show evidence of embeddability", "labels": [], "entities": []}, {"text": " Table 3: Accuracies on Google, SAT analogies and on two new inductive reasoning tasks.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9942399263381958}, {"text": "Google", "start_pos": 24, "end_pos": 30, "type": "DATASET", "confidence": 0.9186030626296997}]}, {"text": " Table 4: Semantic similarity alone can solve the  Google analogy tasks", "labels": [], "entities": []}]}