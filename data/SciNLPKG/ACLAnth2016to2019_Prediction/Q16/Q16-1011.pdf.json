{"title": [{"text": "Concept Grounding to Multiple Knowledge Bases via Indirect Supervision", "labels": [], "entities": []}], "abstractContent": [{"text": "We consider the problem of disambiguating concept mentions appearing in documents and grounding them in multiple knowledge bases, where each knowledge base addresses some aspects of the domain.", "labels": [], "entities": []}, {"text": "This problem poses a few additional challenges beyond those addressed in the popular Wikification problem.", "labels": [], "entities": [{"text": "Wikification problem", "start_pos": 85, "end_pos": 105, "type": "TASK", "confidence": 0.6624315083026886}]}, {"text": "Key among them is that most knowledge bases do not contain the rich textual and structural information Wikipedia does; consequently, the main supervision signal used to train Wik-ification rankers does not exist anymore.", "labels": [], "entities": []}, {"text": "In this work we develop an algorithmic approach that, by carefully examining the relations between various related knowledge bases, generates an indirect supervision signal it uses to train a ranking model that accurately chooses knowledge base entries fora given mention; moreover, it also induces prior knowledge that can be used to support a global coherent mapping of all the concepts in a given document to the knowledge bases.", "labels": [], "entities": []}, {"text": "Using the biomedical domain as our application , we show that our indirectly supervised ranking model outperforms other unsu-pervised baselines and that the quality of this indirect supervision scheme is very close to a supervised model.", "labels": [], "entities": []}, {"text": "We also show that considering multiple knowledge bases together has an advantage over grounding concepts to each knowledge base individually.", "labels": [], "entities": []}], "introductionContent": [{"text": "Grounding entities and concepts appearing in text documents to a knowledge base (KB) has become a popular method for contextually disambiguating them and can be used also for focused knowledge acquisition.", "labels": [], "entities": [{"text": "Grounding entities and concepts appearing in text documents to a knowledge base (KB)", "start_pos": 0, "end_pos": 84, "type": "TASK", "confidence": 0.6690726617972056}, {"text": "focused knowledge acquisition", "start_pos": 175, "end_pos": 204, "type": "TASK", "confidence": 0.6351993282636007}]}, {"text": "It has been shown a valuable component for several natural language processing and information extraction tasks across different domains.", "labels": [], "entities": [{"text": "natural language processing and information extraction", "start_pos": 51, "end_pos": 105, "type": "TASK", "confidence": 0.6443260113398234}]}, {"text": "In the news domain, the task is often called Wikification or Entity Linking and has been studied extensively recently (.", "labels": [], "entities": [{"text": "Entity Linking", "start_pos": 61, "end_pos": 75, "type": "TASK", "confidence": 0.6728804558515549}]}, {"text": "Wikipedia is widely used as the target KB due to its broad coverage and detailed information of concepts.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9209098219871521}]}, {"text": "While Wikipedia is an excellent general purpose encyclopedic resource, when the text is domain specific, it may not be the single ideal resource; the text could be better \"covered\" by multiple ontological or encyclopedic resources.", "labels": [], "entities": []}, {"text": "This is clearly the case for scientific text which is often covered by multiple ontologies, each addressing some aspects of the domain.", "labels": [], "entities": []}, {"text": "For example, in the biological domain there are multiple ontologies: Entrez Gene ( focuses on genomes that have been completely sequenced; Gene Ontology () more broadly describes gene product characteristics; and ChEBI, is a dictionary of molecular entities focused on \"small\" chemical compounds.", "labels": [], "entities": []}, {"text": "The ontologies provide complementary information, but they overlap and, in these cases, make use of different vocabulary and provide different relevant information.", "labels": [], "entities": []}, {"text": "In this paper, we consider the problem of grounding concepts appearing in documents to multiple KBs.", "labels": [], "entities": []}, {"text": "We use the biomedical domain as our appli-cation domain, both due to its importance and to the fact that thousands of person-years have been spent on putting together a large number of relevant KBs.", "labels": [], "entities": []}, {"text": "We discuss other potential applications in the end of the paper.", "labels": [], "entities": []}, {"text": "The challenges in this problem are due both to ambiguity and variability in expressing concepts: a given mention in text can be used to express different concepts in the KBs, and a KB (ontology) concept maybe expressed in text in multiple ways, such as synonyms or nicknames.", "labels": [], "entities": []}, {"text": "In the case of using multiple KBs, an additional challenge is due to the overlap between KBs: a mention can refer to multiple concepts in different KBs and we want to ground the mention to all of them.", "labels": [], "entities": []}, {"text": "shows an example of concept annotations from the CRAFT corpus ().", "labels": [], "entities": [{"text": "CRAFT corpus", "start_pos": 49, "end_pos": 61, "type": "DATASET", "confidence": 0.9565792977809906}]}, {"text": "The mention BRCA2 refers both to \"breast cancer type 2 susceptibility protein (PR:000004804)\" from the Protein Ontology and to \"BRCA2 (EG:675)\" from the Entrez Gene database, which has more than one hundred genes across different species that can be referred to as BRCA2.", "labels": [], "entities": [{"text": "Protein Ontology", "start_pos": 103, "end_pos": 119, "type": "DATASET", "confidence": 0.880122721195221}, {"text": "Entrez Gene database", "start_pos": 153, "end_pos": 173, "type": "DATASET", "confidence": 0.8633381923039755}]}, {"text": "In the context of Wikification, people often train a ranking model to score how relevant a KB concept is to a mention.", "labels": [], "entities": []}, {"text": "It is straightforward to use Wikipedia to supervise this model, since the hyperlink structure in Wikipedia text indicates which title a mention refers to.", "labels": [], "entities": []}, {"text": "However, other KBs may not have such useful information.", "labels": [], "entities": []}, {"text": "An entry in atypical biological KB only consists of a name, a few sentences of definition, synonyms, and a few relations).", "labels": [], "entities": [{"text": "atypical biological KB", "start_pos": 12, "end_pos": 34, "type": "TASK", "confidence": 0.626943051815033}]}, {"text": "In addition, it is relatively difficult to obtain human annotations in the biomedical domain due to the high level of expertise required and to highly ambiguous concepts.", "labels": [], "entities": []}, {"text": "Our key contribution in this paper is to show that, by exploring the overlap and the relationship between KBs, we can obtain high quality indirect supervision signals for sufficiently many examples, and thus train a ranking model.", "labels": [], "entities": []}, {"text": "Without using any document in training and no annotated supervision, our approach achieves better ranking results than all previous approaches tried on this problem.", "labels": [], "entities": []}, {"text": "We then explore another advantage of using multiple KBs; we show that, since concepts are represented in different ways in different KBs, there are some natural constraints between these representations.", "labels": [], "entities": []}, {"text": "In the above example, if we determine that a gene mention is relevant to the human genome and should therefore be grounded to human concepts in the NCBI Taxonomy, we can easily rule out all the candidate genes from other species, which are not mentioned in the document; we can develop these constraints since genes in the Entrez Gene KB have NCBI Taxonomy IDs as species attributes.", "labels": [], "entities": [{"text": "NCBI Taxonomy", "start_pos": 148, "end_pos": 161, "type": "DATASET", "confidence": 0.9549163281917572}, {"text": "Entrez Gene KB", "start_pos": 323, "end_pos": 337, "type": "DATASET", "confidence": 0.917450487613678}]}, {"text": "If we do not use the NCBI Taxonomy as a knowledge source to ground concepts but rather only focus on disambiguating gene names in a document, we may lose this valuable information.", "labels": [], "entities": [{"text": "NCBI Taxonomy", "start_pos": 21, "end_pos": 34, "type": "DATASET", "confidence": 0.9642387330532074}]}, {"text": "Our final model combines this kind of prior knowledge with our ranker scores using a Constrained Conditional Model (CCM) () to enforce a coherent global mapping of all mentions in a given document to their corresponding concepts.", "labels": [], "entities": []}, {"text": "The proposed system, CCMIS (CCM with Indirect Supervision), performs significantly better than the best unsupervised baseline and is competitive with a directly supervised model we use to assess the quality of the automatically generated indirect supervision.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we compare the proposed CCMIS with five other approaches on the CRAFT dataset.", "labels": [], "entities": [{"text": "CRAFT dataset", "start_pos": 81, "end_pos": 94, "type": "DATASET", "confidence": 0.9500817954540253}]}, {"text": "In addition, we present experimental analysis designed to evaluate the candidate generation method, features of the ranking model, the quality of indirect supervision, and the benefit of using multiple KBs.", "labels": [], "entities": [{"text": "candidate generation", "start_pos": 71, "end_pos": 91, "type": "TASK", "confidence": 0.7829986214637756}]}, {"text": "The Colorado Richly Annotated Full-Text (CRAFT) corpus () is the largest gold standard corpus with high-quality annotations from multiple KBs: the Cell Type Ontology (CL), the Chemical Entities of Biological Interest ontology (CHEBI), the NCBI Taxonomy (NCBITaxon), the Protein Ontology (PR), the Sequence Ontology (SO), the Entrez Gene database (EG), and the Gene Ontology (GO).", "labels": [], "entities": [{"text": "Colorado Richly Annotated Full-Text (CRAFT) corpus", "start_pos": 4, "end_pos": 54, "type": "DATASET", "confidence": 0.5758247897028923}]}, {"text": "It identifies nearly all concepts from 67 full text of biomedical journal articles.", "labels": [], "entities": []}, {"text": "We use the ontologies released along with the annotated documents in CRAFT-1.0 except EG which is not included in the package.", "labels": [], "entities": [{"text": "CRAFT-1.0", "start_pos": 69, "end_pos": 78, "type": "DATASET", "confidence": 0.9488872289657593}]}, {"text": "We use the version which was available on October 30th, 2014.", "labels": [], "entities": []}, {"text": "The CRAFT corpus consists of 82,634 concept mentions in total.", "labels": [], "entities": [{"text": "CRAFT corpus", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.9566736817359924}]}, {"text": "The total number of concepts and unique concepts from each ontology is shown in the total number of gold annotations (99,932 the last row of the third column) is larger than the number of mentions which indicates that a mention may refer to more than one concepts across multiple ontologies.", "labels": [], "entities": []}, {"text": "The interannotator-agreement of concept annotations is above 90% F1 score for all the ontologies ().", "labels": [], "entities": [{"text": "F1 score", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9878867268562317}]}, {"text": "We mainly use the mean area under the precisionrecall curve (AUC of PR-curve) () as the evaluation metric.", "labels": [], "entities": [{"text": "precisionrecall curve (AUC", "start_pos": 38, "end_pos": 64, "type": "METRIC", "confidence": 0.9475860893726349}]}, {"text": "Each mention has a ranked concept list as an output, and a set of gold concepts.", "labels": [], "entities": []}, {"text": "We calculate the precision and recall at every ranking position, forming a PR-curve.", "labels": [], "entities": [{"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9997102618217468}, {"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9995680451393127}]}, {"text": "Note that the recall is calculated using the total number of gold concepts, not just the total number of golds in the output list.", "labels": [], "entities": [{"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9986795783042908}]}, {"text": "This way we ensure this metric reflects the fact that some gold concepts are missing in the output.", "labels": [], "entities": []}, {"text": "The AUC of the PR-curves of all mentions are averaged to get a final single number.", "labels": [], "entities": [{"text": "AUC", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9980511665344238}]}, {"text": "We also report a hierarchical version of the AUC.", "labels": [], "entities": [{"text": "AUC", "start_pos": 45, "end_pos": 48, "type": "DATASET", "confidence": 0.4794066548347473}]}, {"text": "The intuition is that if a concept is the parent or child of the gold concept, it should be penalized less than a concept which is faraway from the gold in the hierarchy.", "labels": [], "entities": []}, {"text": "We calculate hierarchical precision and recall using the method proposed in, which replaces each concept by its ancestors (including itself), and then calculates the precision and recall at every ranking position by matching the ancestors of a concept candidate with the ancestors of the gold concepts.", "labels": [], "entities": [{"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9872047901153564}, {"text": "recall", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.9983906745910645}, {"text": "precision", "start_pos": 166, "end_pos": 175, "type": "METRIC", "confidence": 0.999110996723175}, {"text": "recall", "start_pos": 180, "end_pos": 186, "type": "METRIC", "confidence": 0.9961766004562378}]}, {"text": "If a predicted concept has more common ancestors with the gold concepts, the score will be higher.", "labels": [], "entities": []}, {"text": "We use a public linear ranking SVM package () with default parameters to learn the ranking model.", "labels": [], "entities": []}, {"text": "Feature engineering is done by doing cross validation on the indirect supervision examples, therefore, we can use all documents as the test set for all approaches.", "labels": [], "entities": [{"text": "Feature engineering", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7889975607395172}]}, {"text": "shows the overall performance of each approach.", "labels": [], "entities": []}, {"text": "The results of graphbased approaches are consistent with the results in Agirre and Soroa: Ppr w2w performs better than Ppr, and these two Personalized PageRank approaches outperform the static PageRank method.", "labels": [], "entities": []}, {"text": "However, given the large size of KBs and the number of mentions in the CRAFT corpus, Ppr w2w requires two days to run on a 3.0GHz CPU, whereas Ppr only takes two hours and other methods can be done within an hour.", "labels": [], "entities": [{"text": "CRAFT corpus", "start_pos": 71, "end_pos": 83, "type": "DATASET", "confidence": 0.9430062770843506}]}, {"text": "TF-IDF does not performs well since the definitions of concepts are very short and concise, which makes them hard to be matched with any context words.", "labels": [], "entities": [{"text": "TF-IDF", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.5898429751396179}]}, {"text": "Our algorithm CCMIS gets 2 points higher than Ppr w2w in terms of mean AUC, even though no additional external information is being used; specifically, no annotated document is needed to train the ranking model.", "labels": [], "entities": [{"text": "AUC", "start_pos": 71, "end_pos": 74, "type": "METRIC", "confidence": 0.8287433981895447}]}, {"text": "Regarding the relaxed metric, mean hierarchical AUC (hAUC), the relative performance is the same but the gaps between hAUC and AUC indicate that many concept candidates are the ancestors or descendants of the gold concept, which might be proven good enough in practice.", "labels": [], "entities": [{"text": "mean hierarchical AUC (hAUC)", "start_pos": 30, "end_pos": 58, "type": "METRIC", "confidence": 0.7865481774012247}]}, {"text": "shows a feature ablation study of CCMIS.", "labels": [], "entities": [{"text": "CCMIS", "start_pos": 34, "end_pos": 39, "type": "DATASET", "confidence": 0.8906603455543518}]}, {"text": "The initial ranking of candidates is according to the static PageRank score.", "labels": [], "entities": [{"text": "PageRank score", "start_pos": 61, "end_pos": 75, "type": "DATASET", "confidence": 0.8695196509361267}]}, {"text": "Training an indirectly supervised ranker with local features adds almost 3 points of mean AUC.", "labels": [], "entities": [{"text": "AUC", "start_pos": 90, "end_pos": 93, "type": "METRIC", "confidence": 0.910221517086029}]}, {"text": "Without adding the two constraints to enforce species coherence, the ranking scores from our ranker already perform better than other approaches.", "labels": [], "entities": []}, {"text": "Using these constraints adds about 1.9 points of mean AUC overall.", "labels": [], "entities": [{"text": "AUC", "start_pos": 54, "end_pos": 57, "type": "METRIC", "confidence": 0.5590090751647949}]}, {"text": "The candidate generation method plays an important role in getting good ranking performance.", "labels": [], "entities": [{"text": "candidate generation", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.7950641810894012}]}, {"text": "In CCMIS, we include the top 10 candidates from word matching only when synonym matching fails to generate any candidate since candidates generated byword matching are nosier.", "labels": [], "entities": [{"text": "word matching", "start_pos": 48, "end_pos": 61, "type": "TASK", "confidence": 0.735549807548523}]}, {"text": "This way covers 68.11% of the gold concepts, which indicates that the ceiling of the ranking performance is close to 68.11.", "labels": [], "entities": []}, {"text": "To    show how the candidate generation method affects ranking performance we add candidates from word matching to mentions so that each mention has at least k concept candidates.", "labels": [], "entities": [{"text": "candidate generation", "start_pos": 19, "end_pos": 39, "type": "TASK", "confidence": 0.7308184802532196}]}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "The last row of shows the percentage of gold concepts included as candidates.", "labels": [], "entities": []}, {"text": "We can see that after k = 20, the gold coverage merely increases.", "labels": [], "entities": [{"text": "gold coverage", "start_pos": 34, "end_pos": 47, "type": "METRIC", "confidence": 0.9117708802223206}]}, {"text": "This indicates that lexical level matching is not sufficient for generating more gold concepts into the candidate set.", "labels": [], "entities": []}, {"text": "From k = 0 to 10, the performance of each approach drops a lot.", "labels": [], "entities": []}, {"text": "CCMIS is more robust when there are more irrelevant candidates.", "labels": [], "entities": [{"text": "CCMIS", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8443455100059509}]}, {"text": "It is also interesting to see that simply increasing the gold coverage may result in worse overall performance.", "labels": [], "entities": [{"text": "gold coverage", "start_pos": 57, "end_pos": 70, "type": "METRIC", "confidence": 0.7690055072307587}]}, {"text": "We need a more powerful ranking algorithm to handle larger number of candidates.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the concepts in the ontologies and  the CRAFT corpus. We use \"concepts\" to refer to the  entires in the ontologies, and \"annotations\" are concepts  which are associated with mentions in the text. The sec- ond column shows the total number of concepts in each  ontology. The third and fourth columns show the number  of annotations and unique annotations of each ontology  in the CRAFT corpus.", "labels": [], "entities": [{"text": "CRAFT corpus", "start_pos": 64, "end_pos": 76, "type": "DATASET", "confidence": 0.9347119033336639}, {"text": "CRAFT corpus", "start_pos": 403, "end_pos": 415, "type": "DATASET", "confidence": 0.9413280785083771}]}, {"text": " Table 2: A comparison of CCMIS and other five unsuper- vised approaches on the CRAFT corpus. The evaluation  metrics are mean AUC of PR-curve and its hierarchical  version. CCMIS outperforms other methods significantly  in both metrics (using bootstrapped t-test with p-value  < 0.05", "labels": [], "entities": [{"text": "CRAFT corpus", "start_pos": 80, "end_pos": 92, "type": "DATASET", "confidence": 0.959914356470108}, {"text": "AUC", "start_pos": 127, "end_pos": 130, "type": "METRIC", "confidence": 0.8755412697792053}]}, {"text": " Table 3: Feature ablation study of the proposed method,  CCMIS. The initial ranking of candidates is according to  the PageRank score. Training an indirectly supervised  ranker with local and global features improves the per- formance by 3.3 points of mean AUC. Doing global in- ference with constraints improves almost 2 points overall.", "labels": [], "entities": [{"text": "AUC", "start_pos": 258, "end_pos": 261, "type": "METRIC", "confidence": 0.9583404660224915}]}, {"text": " Table 4: Comparing ranking performance by changing  the parameter in the candidate generation algorithm. Be- sides synonym matching, we use word matching to make  sure each mention has at least k candidates. Note that in  the setting of Table 2, word matching is only applied if  synonym matching fails to generate any candidates. The  gold coverage is the percentage of gold annotations in- cluded in the candidate list, a performance upper bound.  The metric is mean AUC.", "labels": [], "entities": [{"text": "Be- sides synonym matching", "start_pos": 106, "end_pos": 132, "type": "TASK", "confidence": 0.579427856206894}, {"text": "AUC", "start_pos": 470, "end_pos": 473, "type": "METRIC", "confidence": 0.962680459022522}]}, {"text": " Table 5: Evaluating the quality of indirectly supervised  examples. The only difference between these three ap- proaches is the way we obtain training examples. That is,  only the ranking model is changed. Concept candidates,  features, and learning algorithm are stay the same.", "labels": [], "entities": []}, {"text": " Table 7: The overall performance of using KBs individ- ually and jointly. Note that the numbers are averaged  AUC of mentions across different KBs' datasets, a dif- ferent evaluation metric from Table 2. Using multiple  KBs jointly always yields a better result and the gain of  CCMIS is the largest.", "labels": [], "entities": [{"text": "AUC", "start_pos": 111, "end_pos": 114, "type": "METRIC", "confidence": 0.9964070916175842}, {"text": "CCMIS", "start_pos": 280, "end_pos": 285, "type": "METRIC", "confidence": 0.6310805082321167}]}]}