{"title": [{"text": "Transforming Dependency Structures to Logical Forms for Semantic Parsing", "labels": [], "entities": [{"text": "Semantic Parsing", "start_pos": 56, "end_pos": 72, "type": "TASK", "confidence": 0.7117608785629272}]}], "abstractContent": [{"text": "The strongly typed syntax of grammar formalisms such as CCG, TAG, LFG and HPSG offers asynchronous framework for deriving syntactic structures and semantic logical forms.", "labels": [], "entities": [{"text": "HPSG", "start_pos": 74, "end_pos": 78, "type": "DATASET", "confidence": 0.8740190267562866}]}, {"text": "In contrast-partly due to the lack of a strong type system-dependency structures are easy to annotate and have become a widely used form of syntactic analysis for many languages.", "labels": [], "entities": [{"text": "syntactic analysis", "start_pos": 140, "end_pos": 158, "type": "TASK", "confidence": 0.7533362209796906}]}, {"text": "However, the lack of a type system makes a formal mechanism for deriving logical forms from dependency structures challenging.", "labels": [], "entities": []}, {"text": "We address this by introducing a robust system based on the lambda calculus for deriving neo-Davidsonian logical forms from dependency trees.", "labels": [], "entities": []}, {"text": "These logical forms are then used for semantic parsing of natural language to Free-base.", "labels": [], "entities": [{"text": "semantic parsing of natural language", "start_pos": 38, "end_pos": 74, "type": "TASK", "confidence": 0.8236318051815033}]}, {"text": "Experiments on the Free917 and Web-Questions datasets show that our representation is superior to the original dependency trees and that it outperforms a CCG-based representation on this task.", "labels": [], "entities": [{"text": "Free917 and Web-Questions datasets", "start_pos": 19, "end_pos": 53, "type": "DATASET", "confidence": 0.7430478781461716}]}, {"text": "Compared to prior work, we obtain the strongest result to date on Free917 and competitive results on WebQuestions.", "labels": [], "entities": [{"text": "Free917", "start_pos": 66, "end_pos": 73, "type": "DATASET", "confidence": 0.940224826335907}, {"text": "WebQuestions", "start_pos": 101, "end_pos": 113, "type": "DATASET", "confidence": 0.9397443532943726}]}], "introductionContent": [{"text": "Semantic parsers map sentences ontological forms that can be used to query databases), instruct robots (), extract information (, or describe visual scenes.", "labels": [], "entities": [{"text": "Semantic parsers map sentences ontological forms", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.7781224846839905}]}, {"text": "Current systems accomplish this by learning task-specific grammars, by using strongly-typed CCG grammars (, or by eschewing the use of a grammar entirely ().", "labels": [], "entities": []}, {"text": "a Work carried out during an internship at Google.", "labels": [], "entities": []}, {"text": "b On leave from Columbia University.", "labels": [], "entities": []}, {"text": "In recent years, there have been significant advances in developing fast and accurate dependency parsers for many languages.", "labels": [], "entities": []}, {"text": "Motivated by the desire to carry these advances over to semantic parsing tasks, we present a robust method for mapping dependency trees to logical forms that represent underlying predicate-argument structures.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 56, "end_pos": 72, "type": "TASK", "confidence": 0.7229133397340775}]}, {"text": "We empirically validate the utility of these logical forms for question answering from databases.", "labels": [], "entities": [{"text": "question answering", "start_pos": 63, "end_pos": 81, "type": "TASK", "confidence": 0.8247076272964478}]}, {"text": "Since our approach uses dependency trees as input, we hypothesize that it will generalize better to domains that are well covered by dependency parsers than methods that induce semantic grammars from scratch.", "labels": [], "entities": []}], "datasetContent": [{"text": "We next verify empirically that our proposed approach derives a useful logical compositional semantic representation from dependency syntax.", "labels": [], "entities": []}, {"text": "Below, we give details on the evaluation datasets and baselines used for comparison.", "labels": [], "entities": []}, {"text": "We also describe the model features and provide implementation details.", "labels": [], "entities": []}, {"text": "We evaluated our approach on the Free917  We examine the different representations for question answering along two axes.", "labels": [], "entities": [{"text": "Free917", "start_pos": 33, "end_pos": 40, "type": "DATASET", "confidence": 0.9856875538825989}, {"text": "question answering", "start_pos": 87, "end_pos": 105, "type": "TASK", "confidence": 0.8119808733463287}]}, {"text": "First, we compare their expressiveness in terms of answer reachability assuming a perfect model.", "labels": [], "entities": [{"text": "answer reachability", "start_pos": 51, "end_pos": 70, "type": "TASK", "confidence": 0.7692292332649231}]}, {"text": "Second, we compare their performance with a learned model.", "labels": [], "entities": []}, {"text": "Finally, we conduct a detailed error analysis of DEPLAMBDA, with a comparison to the errors made by CCGGRAPH.", "labels": [], "entities": [{"text": "DEPLAMBDA", "start_pos": 49, "end_pos": 58, "type": "DATASET", "confidence": 0.49815112352371216}, {"text": "CCGGRAPH", "start_pos": 100, "end_pos": 108, "type": "DATASET", "confidence": 0.9745635986328125}]}, {"text": "For WebQuestions evaluation is in terms of the average F 1 -score across questions, while for Free917, evaluation is in terms of exact answer accuracy.", "labels": [], "entities": [{"text": "F 1 -score", "start_pos": 55, "end_pos": 65, "type": "METRIC", "confidence": 0.9781127870082855}, {"text": "Free917", "start_pos": 94, "end_pos": 101, "type": "DATASET", "confidence": 0.9637662768363953}, {"text": "accuracy", "start_pos": 142, "end_pos": 150, "type": "METRIC", "confidence": 0.7930434346199036}]}, {"text": "CCGGRAPH and DEPLAMBDA align much more closely to Freebase and achieve similar oracle F 1 scores with far less spurious ambiguity.", "labels": [], "entities": [{"text": "CCGGRAPH", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9646354913711548}]}, {"text": "SIMPLE-GRAPH, which cannot represent any compositional semantics, is competitive with these syntax-based representations.", "labels": [], "entities": []}, {"text": "This might come as a surprise, but it simply reflects the fact that the dataset does not contain questions that require compositional reasoning.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Oracle statistics and accuracies on the Web-", "labels": [], "entities": []}, {"text": " Table 2: Oracle statistics and accuracies on the Free917", "labels": [], "entities": [{"text": "Free917", "start_pos": 50, "end_pos": 57, "type": "DATASET", "confidence": 0.9624317288398743}]}, {"text": " Table 3: Question-answering results on the WebQuestions", "labels": [], "entities": [{"text": "WebQuestions", "start_pos": 44, "end_pos": 56, "type": "DATASET", "confidence": 0.9123415946960449}]}]}