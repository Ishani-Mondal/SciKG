{"title": [{"text": "Comparing Apples to Apple: The Effects of Stemmers on Topic Models", "labels": [], "entities": []}], "abstractContent": [{"text": "Rule-based stemmers such as the Porter stem-mer are frequently used to preprocess English corpora for topic modeling.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 102, "end_pos": 116, "type": "TASK", "confidence": 0.8567682206630707}]}, {"text": "In this work, we train and evaluate topic models on a variety of corpora using several different stemming algorithms.", "labels": [], "entities": []}, {"text": "We examine several different quantitative measures of the resulting models, including likelihood, coherence, model stability, and entropy.", "labels": [], "entities": [{"text": "likelihood", "start_pos": 86, "end_pos": 96, "type": "METRIC", "confidence": 0.984836757183075}]}, {"text": "Despite their frequent use in topic modeling, we find that stemmers produce no meaningful improvement in likelihood and coherence and in fact can degrade topic stability.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 30, "end_pos": 44, "type": "TASK", "confidence": 0.8245642483234406}, {"text": "likelihood", "start_pos": 105, "end_pos": 115, "type": "METRIC", "confidence": 0.9752713441848755}]}], "introductionContent": [{"text": "Stemming is a popular way to reduce the size of a vocabulary in natural language tasks by conflating words with related meanings.", "labels": [], "entities": []}, {"text": "Specifically, stemming aims to convert words with the same \"stem\" or root (e.g \"creative\" and \"creator\") to a single word type (\"create\").", "labels": [], "entities": []}, {"text": "Though originally developed in the context of information retrieval (IR) systems, stemmers are now commonly used as a preprocessing step in unsupervised machine learning tasks.", "labels": [], "entities": [{"text": "information retrieval (IR)", "start_pos": 46, "end_pos": 72, "type": "TASK", "confidence": 0.8608967185020446}]}, {"text": "It this work we consider one such application, topic modeling.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 47, "end_pos": 61, "type": "TASK", "confidence": 0.8561857640743256}]}, {"text": "Although stemmers are commonly used in topic models (, we find no empirical benefits for the practice.", "labels": [], "entities": []}, {"text": "One could conjecture several reasons to stem for semantic models.", "labels": [], "entities": []}, {"text": "First, conflating semantically related words into one word type could improve model fit by intelligently reducing the space of possible models.", "labels": [], "entities": []}, {"text": "Given that reducing the feature space randomly is already known to be potentially beneficial (, doing so in a semantically-inspired way might be even better.", "labels": [], "entities": []}, {"text": "Second, stemmers could reduce the effect of small morphological differences on the stability of a learned model.", "labels": [], "entities": []}, {"text": "Reducing the words \"happy\", \"happily\", and \"happier\" to one token may result in fewer possible models with divergent \"happy\" topics.", "labels": [], "entities": []}, {"text": "Third, stemmers approximate intuitive word equivalence classes, so language models based on stemmed corpora inherit that semantic similarity, which may improve interpretability as perceived by human evaluators.", "labels": [], "entities": []}, {"text": "However, stemmers have the potential to be confusing, unreliable, and possibly even harmful in language models.", "labels": [], "entities": []}, {"text": "First, many stemmers produce terms that are not recognizable English words and maybe difficult to map back to a valid original word, such as \"stai\" as the Porter stem of \"stay\".", "labels": [], "entities": []}, {"text": "Second, although stemming aids document retrieval for many languages, English is a notorious exception.", "labels": [], "entities": []}, {"text": "In English, the complexity of compound affixes with meaning can lead to overstemming, such as \"recondition,\" a word sharing a stem but not a root meaning with \"recondite.\"", "labels": [], "entities": []}, {"text": "These complexities can also lead to the incorrect conflation of words with the same root but divergent meaning such as \"absolutely\" and \"absolution\".", "labels": [], "entities": []}, {"text": "Third, and most troubling, there are cases in which morphological variants of the same stem carry significantly different meanings.", "labels": [], "entities": []}, {"text": "Conflating \"apple\" and \"apples\" is uncontroversial, but loses the distinction between a device manufacturer and a type of fruit.", "labels": [], "entities": []}, {"text": "Topic modeling is sensitive to preprocessing because of its dependence on a sparse vocabulary.", "labels": [], "entities": [{"text": "Topic modeling", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7968281209468842}]}, {"text": "In practice, however, preprocessing methods are typically neither detailed nor justified, leading to problems in reproducibility ().", "labels": [], "entities": []}, {"text": "We believe investigating the effects of stemming will inform researchers outside the core natural language processing community as to how to best preprocess their texts.", "labels": [], "entities": []}, {"text": "While stemmers are used in topic modeling, we know of no analysis focused on their effect.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 27, "end_pos": 41, "type": "TASK", "confidence": 0.7952544391155243}]}, {"text": "We draw inspiration from prior studies of the effects of stemming for other tasks and models) to apply rule-based stemmers to a variety of corpora to test their effect on topic models.", "labels": [], "entities": []}, {"text": "We evaluate the quantitative fit of the models generated and the qualitative differences between differentlystemmed corpora to investigate the effects each stemmer has on a corpus.", "labels": [], "entities": []}, {"text": "We hope that these results help guide future researchers as to how to select and evaluate stemmers fora given task and corpus.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to evaluate the differences between conflation treatments of these corpora, we want to look at a variety of different types of evaluation of topic models.", "labels": [], "entities": []}, {"text": "Unfortunately, as described later, standard evaluations of topic quality such as held-out likelihood and coherence are implicitly affected by the size of the vocabulary.", "labels": [], "entities": [{"text": "likelihood", "start_pos": 90, "end_pos": 100, "type": "METRIC", "confidence": 0.9413744807243347}]}, {"text": "To be able to compare different treatments without simply favoring the maximum possible vocabulary reduction, we create modified versions of several existing classic evaluations as well as new metrics for understanding differences in models at the level of word types instead of topics.", "labels": [], "entities": []}], "tableCaptions": []}