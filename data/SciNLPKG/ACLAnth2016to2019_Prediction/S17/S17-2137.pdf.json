{"title": [{"text": "ECNU at SemEval-2017 Task 4: Evaluating Effective Features on Machine Learning Methods for Twitter Message Polarity Classification", "labels": [], "entities": [{"text": "ECNU at SemEval-2017 Task 4", "start_pos": 0, "end_pos": 27, "type": "DATASET", "confidence": 0.739619505405426}, {"text": "Twitter Message Polarity Classification", "start_pos": 91, "end_pos": 130, "type": "TASK", "confidence": 0.636195957660675}]}], "abstractContent": [{"text": "This paper reports our submission to sub-task A of task 4 (Sentiment Analysis in Twitter, SAT) in SemEval 2017, i.e., Message Polarity Classification.", "labels": [], "entities": [{"text": "Sentiment Analysis in Twitter, SAT)", "start_pos": 59, "end_pos": 94, "type": "TASK", "confidence": 0.7957123177392142}, {"text": "Message Polarity Classification", "start_pos": 118, "end_pos": 149, "type": "TASK", "confidence": 0.8270876804987589}]}, {"text": "We investigated several traditional Natural Language Processing (NLP) features, domain specific features and word embedding features together with supervised machine learning methods to address this task.", "labels": [], "entities": []}, {"text": "Officially released results showed that our system ranked above average.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, with the emergence of social media, more and more users have shared and obtained information through microblogging websites, such as Twitter.", "labels": [], "entities": []}, {"text": "The study on this platform is increasingly drawing attention of many researchers and organizations.", "labels": [], "entities": []}, {"text": "SemEval 2017 provides a universal platform for researchers to explore sentiment analysis in Twitter () (Task 4, Sentiment Analysis in Twitter, SAT) which includes five subtasks, and we participated in subtask A: Message Polarity Classification.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 70, "end_pos": 88, "type": "TASK", "confidence": 0.8429603576660156}, {"text": "Message Polarity Classification", "start_pos": 212, "end_pos": 243, "type": "TASK", "confidence": 0.6987551550070444}]}, {"text": "It aims at sentiment polarity classification of the whole tweet on a three-point scale(i.e., Positive, Negative and Neutral).", "labels": [], "entities": [{"text": "sentiment polarity classification", "start_pos": 11, "end_pos": 44, "type": "TASK", "confidence": 0.8530417482058207}]}, {"text": "Given the character limitations on tweets, the sentiment orientation classification on tweets can be regarded as a sentence-level sentiment analysis task.", "labels": [], "entities": [{"text": "sentiment orientation classification", "start_pos": 47, "end_pos": 83, "type": "TASK", "confidence": 0.8348729014396667}, {"text": "sentence-level sentiment analysis", "start_pos": 115, "end_pos": 148, "type": "TASK", "confidence": 0.7037982443968455}]}, {"text": "Following previous work), we adopted a rich set of traditional NLP features, i.e., linguistic features (e.g., word n-gram, partof-speech (POS) tags, etc), sentiment lexicon features (i.e., the scores calculated from eight sentiment lexicons), and domain content features (e.g., emoticons, capital words, elongated words, etc).", "labels": [], "entities": []}, {"text": "In consideration of rich information in the metadata of tweets, we also extracted metadata features from tweets.", "labels": [], "entities": []}, {"text": "Moreover, several word embeddings (including general word embeddings and sentiment word vectors) were adopted.", "labels": [], "entities": []}, {"text": "We performed a series of experiments to explore the effectiveness of each type of features and supervised machine learning algorithms.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the system performance, the official evaluation criterion is macro-averaged recall, which is calculated among three classes (i.e., positive, negative and neutral) as follows: 3 Experiments  For training set, the organizers provided only the list of tweet ID and a script for all participants to collect tweets and their corresponding metadata.", "labels": [], "entities": [{"text": "recall", "start_pos": 88, "end_pos": 94, "type": "METRIC", "confidence": 0.9321058988571167}]}, {"text": "However, since not all tweets and their metadata are available when downloading, participants may collect slightly different numbers of tweets for training data.", "labels": [], "entities": []}, {"text": "shows the statistics of the tweets we collected in our experiments.", "labels": [], "entities": []}, {"text": "Similarly, due to missing tweets or metadata and system errors when downloading, the metadata of training, development and test set is not complete.", "labels": [], "entities": []}, {"text": "Specifically, approximately 21% training, 18% development and 39% test sets lost their metadata information.: The statistics of data sets in training, development and test data.", "labels": [], "entities": []}, {"text": "The numbers in brackets are the percentages of different classes in each data set.", "labels": [], "entities": []}, {"text": "Firstly, in order to explore the effectiveness of each feature type, we performed a series of experiments.", "labels": [], "entities": []}, {"text": "lists the comparison of different contributions made by different features on development set with Logistic Regression algorithm.", "labels": [], "entities": []}, {"text": "We observe the following findings.", "labels": [], "entities": []}, {"text": "(1) All feature types make contributions to sentiment polarity classification.", "labels": [], "entities": [{"text": "sentiment polarity classification", "start_pos": 44, "end_pos": 77, "type": "TASK", "confidence": 0.8866817951202393}]}, {"text": "Their combination achieves the best performance (i.e., 63.14%).", "labels": [], "entities": []}, {"text": "(2) Linguistic features act as baseline and have shown their effectiveness for sentiment polarity prediction.", "labels": [], "entities": [{"text": "sentiment polarity prediction", "start_pos": 79, "end_pos": 108, "type": "TASK", "confidence": 0.9078854918479919}]}, {"text": "Besides, SentiLexi makes more contributes than other domain-specific and word embeddings features.", "labels": [], "entities": []}, {"text": "Since sentiment lexicons are constructed by expert knowledge, it is beneficial for tweet sentiment polarity prediction.", "labels": [], "entities": [{"text": "tweet sentiment polarity prediction", "start_pos": 83, "end_pos": 118, "type": "TASK", "confidence": 0.8758972138166428}]}, {"text": "(3) The domain-specific metadata is not as effective as expected.", "labels": [], "entities": []}, {"text": "One possible reason results from the missing metadata downloaded by Twitter API.", "labels": [], "entities": []}, {"text": "Secondly, we also explored the performance of different learning algorithms.", "labels": [], "entities": []}, {"text": "lists the comparison of different supervised learning algorithms with all above features.", "labels": [], "entities": []}, {"text": "Clearly, Logistic Regression algorithm outperformed other algorithms.", "labels": [], "entities": [{"text": "Logistic Regression", "start_pos": 9, "end_pos": 28, "type": "TASK", "confidence": 0.7546591460704803}]}, {"text": "Therefore, the system configuration for submission is all features and LR algorithm.", "labels": [], "entities": [{"text": "submission", "start_pos": 40, "end_pos": 50, "type": "TASK", "confidence": 0.9662376642227173}, {"text": "LR", "start_pos": 71, "end_pos": 73, "type": "METRIC", "confidence": 0.9605259299278259}]}, {"text": "shows the results of our system and the top-ranked systems provided by organizers for this sentiment classification task.", "labels": [], "entities": [{"text": "sentiment classification task", "start_pos": 91, "end_pos": 120, "type": "TASK", "confidence": 0.9498530824979147}]}, {"text": "Compared with the top ranked systems, there is much room for improvement in our work.", "labels": [], "entities": []}, {"text": "There are several possible reasons for this performance lag.", "labels": [], "entities": []}, {"text": "First, although the linguistic features are effective, the dimensionality of word RF n-gram features is quite huge (approximately 79K n-grams), which dominates the performance of classification rather than other low dimension features.", "labels": [], "entities": []}, {"text": "Second, the usage of word embeddings is simple and straightforward, which neglects the word sequence and sentence structure.", "labels": [], "entities": []}, {"text": "Third, the effects of metadata maybe reduced due to lots of missing metadata.: Performance of our system and the topranked systems.", "labels": [], "entities": []}, {"text": "The numbers in the brackets are the official rankings.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Performance of different features on de- velopment data. \".+\" means to add current fea- tures to the previous feature set. The numbers in  the brackets are the performance increments com- pared with the previous results.", "labels": [], "entities": []}, {"text": " Table 3: Performance of different learning algo- rithms on development data.", "labels": [], "entities": []}]}