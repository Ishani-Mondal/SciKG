{"title": [{"text": "UIT-DANGNT-CLNLP at SemEval-2017 Task 9: Building Scientific Concept Fixing Patterns for Improving CAMR", "labels": [], "entities": [{"text": "UIT-DANGNT-CLNLP", "start_pos": 0, "end_pos": 16, "type": "DATASET", "confidence": 0.8142529129981995}, {"text": "CAMR", "start_pos": 99, "end_pos": 103, "type": "TASK", "confidence": 0.4308485686779022}]}], "abstractContent": [{"text": "This paper describes the improvements that we have applied on CAMR baseline parser (Wang et al., 2016) at Task 8 of SemEval-2016.", "labels": [], "entities": []}, {"text": "Our objective is to increase the performance of CAMR when parsing sentences from scientific articles, especially articles of biology domain more accurately.", "labels": [], "entities": [{"text": "CAMR", "start_pos": 48, "end_pos": 52, "type": "TASK", "confidence": 0.974053144454956}, {"text": "parsing sentences from scientific articles", "start_pos": 58, "end_pos": 100, "type": "TASK", "confidence": 0.878519332408905}]}, {"text": "To achieve this goal, we built two wrapper layers for CAMR.", "labels": [], "entities": [{"text": "CAMR", "start_pos": 54, "end_pos": 58, "type": "TASK", "confidence": 0.7830018401145935}]}, {"text": "The first layer, which covers the input data, will normalize, add necessary information to the input sentences to make the input dependency parser and the aligner better handle reference citations, scientific figures , formulas, etc.", "labels": [], "entities": []}, {"text": "The second layer, which covers the output data, will modify and standardize output data based on a list of scientific concept fixing patterns.", "labels": [], "entities": []}, {"text": "This will help CAMR better handle biological concepts which are not in the training dataset.", "labels": [], "entities": [{"text": "CAMR", "start_pos": 15, "end_pos": 19, "type": "TASK", "confidence": 0.9676694273948669}]}, {"text": "Finally, after applying our approach , CAMR has scored 0.65 F-score 1 on the test set of Biomedical training data 2 and 0.61 F-score on the official blind test dataset.", "labels": [], "entities": [{"text": "CAMR", "start_pos": 39, "end_pos": 43, "type": "DATASET", "confidence": 0.801876962184906}, {"text": "F-score 1", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9823144674301147}, {"text": "Biomedical training data", "start_pos": 89, "end_pos": 113, "type": "DATASET", "confidence": 0.7103752295176188}, {"text": "F-score", "start_pos": 125, "end_pos": 132, "type": "METRIC", "confidence": 0.9975379705429077}, {"text": "official blind test dataset", "start_pos": 140, "end_pos": 167, "type": "DATASET", "confidence": 0.7124324589967728}]}], "introductionContent": [{"text": "Since Abstract Meaning Representation (AMR) was published by for the first time in, it has been considered by many researchers in Natural Language Processing domain.", "labels": [], "entities": [{"text": "Abstract Meaning Representation (AMR)", "start_pos": 6, "end_pos": 43, "type": "TASK", "confidence": 0.8326984544595083}]}, {"text": "In this trend, the task of AMR has been held continuously for two years in.", "labels": [], "entities": [{"text": "AMR", "start_pos": 27, "end_pos": 30, "type": "TASK", "confidence": 0.8350751399993896}]}, {"text": "There have been many parsers shown its outstanding performance for high Fscore points like RIGA (, CAMR, CU-NLP (), etc.", "labels": [], "entities": [{"text": "Fscore", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9838076233863831}, {"text": "RIGA", "start_pos": 91, "end_pos": 95, "type": "METRIC", "confidence": 0.9132232666015625}]}, {"text": "Inspired by the performance of CAMR in SemEval-2016 Task 8, we selected it as our baseline parser for SemEval-2017 Task 9 -Subtask 1: Parsing Biomedical Data.", "labels": [], "entities": [{"text": "SemEval-2016 Task 8", "start_pos": 39, "end_pos": 58, "type": "TASK", "confidence": 0.6705061395963033}, {"text": "SemEval-2017 Task 9", "start_pos": 102, "end_pos": 121, "type": "TASK", "confidence": 0.8095802466074625}]}, {"text": "The parsing task of 2017 has a particular domain but there are many scientific terms, formulas, reference quotations, numbers, etc.", "labels": [], "entities": [{"text": "parsing task", "start_pos": 4, "end_pos": 16, "type": "TASK", "confidence": 0.9149076342582703}]}, {"text": "That makes the task of 2017 very challenging.", "labels": [], "entities": []}, {"text": "According to, the accuracy of CAMR depends greatly on the accuracy of input dependency parser.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9995424747467041}, {"text": "CAMR", "start_pos": 30, "end_pos": 34, "type": "TASK", "confidence": 0.9560171961784363}, {"text": "accuracy", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.9990874528884888}]}, {"text": "When we conduct training and testing on Biomedical training data used for SemEval-2017, we have found that CAMR is not good in handling the reference citations, scientific figures, formulas, etc which are commonly used in scientific papers.", "labels": [], "entities": [{"text": "Biomedical training data", "start_pos": 40, "end_pos": 64, "type": "DATASET", "confidence": 0.5883854627609253}]}, {"text": "This is partly due to the dependency parser not correctly handling this kind of information.", "labels": [], "entities": []}, {"text": "And also, the aligner cannot fulfill its mission.", "labels": [], "entities": []}, {"text": "We have built the first wrapper to support solving the problem related to these information in input data.", "labels": [], "entities": []}, {"text": "At the same time, we found CAMR can memorize very well AMR structure of concepts which have appeared in the training data.", "labels": [], "entities": [{"text": "CAMR", "start_pos": 27, "end_pos": 31, "type": "TASK", "confidence": 0.8497106432914734}]}, {"text": "However, when parsing testing sentences which have unknown concepts (concepts which are not in training corpus), the parser will not be able to parse and return a single node to indicate the unknown concept (the first error form described in Subsection 3.1).", "labels": [], "entities": [{"text": "parsing testing sentences", "start_pos": 14, "end_pos": 39, "type": "TASK", "confidence": 0.859663724899292}]}, {"text": "Another weakness of CAMR is the terminal condition.", "labels": [], "entities": [{"text": "CAMR", "start_pos": 20, "end_pos": 24, "type": "TASK", "confidence": 0.9315854907035828}, {"text": "terminal", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9846144318580627}]}, {"text": "The parser will finish parsing the sentence when the number of elements in the queue has run out.", "labels": [], "entities": []}, {"text": "In the output result, we found that many AMR structures of concepts are not in good form (the second error form described in Subsection 3.1).", "labels": [], "entities": [{"text": "AMR structures of concepts", "start_pos": 41, "end_pos": 67, "type": "TASK", "confidence": 0.786395400762558}]}, {"text": "Therefore, we proposed to build a second wrap-per to fix the parsing error on output data, which will help CAMR deal with these issues better.", "labels": [], "entities": [{"text": "CAMR", "start_pos": 107, "end_pos": 111, "type": "TASK", "confidence": 0.8916451930999756}]}], "datasetContent": [{"text": "We used the Biomedical training data which have been split into training, develop and test set for experiments.", "labels": [], "entities": [{"text": "Biomedical training data", "start_pos": 12, "end_pos": 36, "type": "DATASET", "confidence": 0.7875884175300598}]}, {"text": "About CAMR, we used the version which was described in () as a baseline parser with its default configurations.", "labels": [], "entities": []}, {"text": "But, we have not used named entity tags and semantic role labels in the experiment stage.", "labels": [], "entities": []}, {"text": "To evaluate the output result, we used the Smatch tool ) at version 16.11.14.", "labels": [], "entities": []}, {"text": "Firstly, we implemented the first wrapper layer as the proposed method in Section 2.", "labels": [], "entities": []}, {"text": "Then, we started training on two systems.", "labels": [], "entities": []}, {"text": "The training data is the collection of all sentences in training set and develop set of Biomedical training data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of successfully aligned node be- fore and after the application of the first wrapper", "labels": [], "entities": []}]}