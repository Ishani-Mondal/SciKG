{"title": [{"text": "SentiHeros at SemEval-2017 Task 5: An application of Sentiment Analysis on Financial Tweets", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.8729095160961151}]}], "abstractContent": [{"text": "Sentiment analysis is the process of identifying the opinion expressed in text.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9480394721031189}]}, {"text": "Recently it has been used to study behavioral finance, and in particular the effect of opinions and emotions on economic or financial decisions.", "labels": [], "entities": [{"text": "behavioral finance", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.7576736807823181}]}, {"text": "SemEval-2017 task 5 focuses on the financial market as the domain for sentiment analysis of text; specifically , task 5, subtask 1 focuses on financial tweets about stock symbols.", "labels": [], "entities": [{"text": "sentiment analysis of text", "start_pos": 70, "end_pos": 96, "type": "TASK", "confidence": 0.9010257422924042}]}, {"text": "In this paper, we describe a machine learning classifier for binary classification of financial tweets.", "labels": [], "entities": [{"text": "binary classification of financial tweets", "start_pos": 61, "end_pos": 102, "type": "TASK", "confidence": 0.7746428728103638}]}, {"text": "We used natural language processing techniques and the random forest algorithm to train our model, and tuned it for the training dataset of Task 5, subtask 1.", "labels": [], "entities": []}, {"text": "Our system achieves the 7th rank on the leaderboard of the task.", "labels": [], "entities": []}], "introductionContent": [{"text": "The recent explosion of textual data creates an unprecedented opportunity for investigating people's emotions and opinions, and for understanding human behavior.", "labels": [], "entities": []}, {"text": "Although there are several methods to do this, sentiment analysis is an especially effective method of text categorization that assigns emotions to text (positive, negative, neutral, etc.).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.9394941031932831}]}, {"text": "Sentiment analysis methods have been used widely on blogs, news, documents and microblogging platforms such as Twitter.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9232764542102814}]}, {"text": "Although social media and blogging are popular and widely used platforms to discuss many different topics, they are challenging to analyze.", "labels": [], "entities": []}, {"text": "This is to large extent due to the specific of vocabulary and syntax, which are dependent on topics, with the same words possibly expressing different sentiments in different contexts.", "labels": [], "entities": []}, {"text": "For example, a word in a casual context might have positive or neutral sentiment (e.g., crush), while the same word generally has a negative sentiment in finance.", "labels": [], "entities": []}, {"text": "Therefore, with the absence of general natural language understanding, context-dependent and domain-specific approaches allow us to increase the accuracy of sentiment analysis at a relatively low implementation cost.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 145, "end_pos": 153, "type": "METRIC", "confidence": 0.9989190101623535}, {"text": "sentiment analysis", "start_pos": 157, "end_pos": 175, "type": "TASK", "confidence": 0.9114587604999542}]}, {"text": "Domain-specific sentiment analysis is being used to analyze or investigate various areas in finance, such as corporate finance and financial markets, investment and banking, asset and derivative pricing.", "labels": [], "entities": [{"text": "Domain-specific sentiment analysis", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7625830471515656}, {"text": "asset and derivative pricing", "start_pos": 174, "end_pos": 202, "type": "TASK", "confidence": 0.6318507865071297}]}, {"text": "Ultimately, the goal is to understand the impact of social media and news on financial markets and to predict the future prices of assets and stocks.", "labels": [], "entities": []}, {"text": "The proposed task in SemEval-2017 targets a sentiment analysis task, which we should identify a range of negative to positive affect on the stock of certain companies.", "labels": [], "entities": [{"text": "sentiment analysis task", "start_pos": 44, "end_pos": 67, "type": "TASK", "confidence": 0.9111435413360596}]}, {"text": "The objective of the task was to predict the sentiment associated with companies and stock with floating point values in the interval from -1 to 1.", "labels": [], "entities": []}, {"text": "Previous research on textual analysis in a financial context has primarily relied on the use of bag of words methods, to measure tone) which is one of the prominent efforts to improve sentiment analysis in financial domain, showed that using non-financial word lists for sentiment analysis will produce misclassifications and misleading results.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 184, "end_pos": 202, "type": "TASK", "confidence": 0.9033295810222626}, {"text": "sentiment analysis", "start_pos": 271, "end_pos": 289, "type": "TASK", "confidence": 0.9234000742435455}]}, {"text": "To illustrate this, they used the Harvard-IV-4 list on financial reports, and found that 73.8% of the negative word counts were attributable to words that were not actually negative in a financial context.", "labels": [], "entities": [{"text": "Harvard-IV-4 list", "start_pos": 34, "end_pos": 51, "type": "DATASET", "confidence": 0.9796119630336761}]}, {"text": "Recently, there has been an increasing interest towards the use of machine learning techniques to get better sentiment result; e.g., na\u00efve Bayesian classifier (Saif, He and Alani 2012) with various features got the accuracy of 83.90%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 215, "end_pos": 223, "type": "METRIC", "confidence": 0.9993865489959717}]}, {"text": "Other reported results include the use of support vector machines (SVMs) with the accuracy of 59.4% (O', and multiple-classifier voting systems with the 72% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.9993919134140015}, {"text": "O'", "start_pos": 101, "end_pos": 103, "type": "METRIC", "confidence": 0.9674499034881592}, {"text": "accuracy", "start_pos": 157, "end_pos": 165, "type": "METRIC", "confidence": 0.9971092343330383}]}, {"text": "In this paper, we describe our approach to building a supervised classifier predicting the sentiment scores of financial tweets provided by.", "labels": [], "entities": []}, {"text": "The classifier is fed preprocessed tweets as input and it predicts the binary labels of the tweets.", "labels": [], "entities": []}, {"text": "Once tweets were preprocess and features were extracted, various classification models were applied using Weka tool (.", "labels": [], "entities": [{"text": "Weka tool", "start_pos": 106, "end_pos": 115, "type": "DATASET", "confidence": 0.9333214163780212}]}, {"text": "This environment contains a collection of machine learning-based algorithms for data mining tasks, such as, classification, regression, clustering, association rules, and visualization.", "labels": [], "entities": []}, {"text": "We ultimately used Random Forest as our classifier as in our various tests it showed the best and accuracy in classifying the tweets.", "labels": [], "entities": [{"text": "Random Forest", "start_pos": 19, "end_pos": 32, "type": "DATASET", "confidence": 0.8957134485244751}, {"text": "accuracy", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9993588328361511}]}, {"text": "After predicting the binary labels, we then use the probability of the tweets being correctly classified to create a range of predictions from -1 to 1 as it was requested in the task.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have done several other experiments first to find a promising approach, and to gauge alternative methods of classification and data preprocessing.", "labels": [], "entities": [{"text": "data preprocessing", "start_pos": 130, "end_pos": 148, "type": "TASK", "confidence": 0.6770866960287094}]}, {"text": "In our initial experiment, after pre-processing the tweets, we first ran the tweets on WEKA to classify using only the feature vector, WEKA's StringToWordVector which is a term document matrix.", "labels": [], "entities": [{"text": "WEKA", "start_pos": 87, "end_pos": 91, "type": "DATASET", "confidence": 0.983922004699707}, {"text": "WEKA's StringToWordVector", "start_pos": 135, "end_pos": 160, "type": "DATASET", "confidence": 0.8952340483665466}]}, {"text": "Random forest and Logistic regression had the highest accuracy of 83.3% and 85.3% respectively.", "labels": [], "entities": [{"text": "Logistic regression", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.7887111604213715}, {"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9994482398033142}]}, {"text": "This experiment shows the impact of our additional features to be around 6%.", "labels": [], "entities": []}, {"text": "Before deciding on the final features of the model, we tried other types of features.", "labels": [], "entities": []}, {"text": "Although many of them did not improve the model, we still thought they were worth mentioning, with description of them following: Bigrams: In the first experiment, bigrams were used.", "labels": [], "entities": []}, {"text": "showed that using unigrams and bigrams are effective in improving sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.9650771617889404}]}, {"text": "( reported that bigrams and trigrams worked better than unigrams for polarity classification of product reviews.", "labels": [], "entities": [{"text": "polarity classification of product reviews", "start_pos": 69, "end_pos": 111, "type": "TASK", "confidence": 0.8500645875930786}]}, {"text": "Unfortunately, bigrams reduced accuracy of Random Forest and Logistic regression to 76.7% and 73.9% respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.999729573726654}]}, {"text": "We imagine that with a larger data set, bigrams might be valuable.", "labels": [], "entities": []}, {"text": "Feature selection using logistic regression: In another experiment, we used logistic regression to produce a list of words with the higher odds ratio.", "labels": [], "entities": [{"text": "Feature selection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7716984450817108}]}, {"text": "We then removed other words from tweets, in an attempt to amplify the stronger signals.", "labels": [], "entities": []}, {"text": "However, applying filtered tweets, with various ranges of odds ratio did not help with improving the results.", "labels": [], "entities": []}, {"text": "The best result was when words only with odds ratio of] stayed in our training set; this gave us the accuracy of 83.5%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 101, "end_pos": 109, "type": "METRIC", "confidence": 0.9997157454490662}]}, {"text": "Using word embedding (GloVe vectors): GloVe vectors are vector representations of the words.", "labels": [], "entities": []}, {"text": "In two separate experiments, we used vectors based on the Common Crawl (840B tokens, 2.2M vocab, cased, 300 dimensions), and the pre-trained word vectors for Twitter (2B tweets, 27B tokens, 1.2M vocab, 200 dimensions).", "labels": [], "entities": [{"text": "Common Crawl", "start_pos": 58, "end_pos": 70, "type": "DATASET", "confidence": 0.9329507946968079}]}, {"text": "We represented every word in each tweet by a corresponding vector.", "labels": [], "entities": []}, {"text": "We then calculated the tweet vector, using the mean of word vectors of the tweet.", "labels": [], "entities": []}, {"text": "In this expe-riment,) positive and negative wordlist again were used.", "labels": [], "entities": []}, {"text": "That is, we created a positive and negative vector using words in those lists.", "labels": [], "entities": []}, {"text": "Comparing the cosine similarity of tweet vectors with positive and negative vector, we classified the tweets.", "labels": [], "entities": []}, {"text": "The accuracy of this method was 72% and 73.8% for tweet and common crawl respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9996985197067261}]}], "tableCaptions": [{"text": " Table 3. Example of the word couples and their  replacements used to normalize the data (tweets).  (See full list in Appendix B.)", "labels": [], "entities": []}, {"text": " Table 4. Results of different Weka classifiers us- ing 10-fold cross validation and default settings.", "labels": [], "entities": []}]}