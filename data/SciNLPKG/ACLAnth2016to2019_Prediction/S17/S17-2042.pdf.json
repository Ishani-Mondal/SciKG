{"title": [{"text": "Wild Devs' at SemEval-2017 Task 2: Using Neural Networks to Discover Word Similarity", "labels": [], "entities": [{"text": "Discover Word Similarity", "start_pos": 60, "end_pos": 84, "type": "TASK", "confidence": 0.7324991822242737}]}], "abstractContent": [{"text": "This paper presents Wild Devs' participation in the SemEval-2017 Task 2 \"Multi-lingual and Cross-lingual Semantic Word Similarity\", which tries to automatically measure the semantic similarity between two words.", "labels": [], "entities": [{"text": "SemEval-2017 Task 2", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.8712348540623983}, {"text": "Cross-lingual Semantic Word Similarity", "start_pos": 91, "end_pos": 129, "type": "TASK", "confidence": 0.5087727308273315}]}, {"text": "The system was build using neural networks, having as input a collection of word pairs, whereas the output consists of a list of scores, from 0 to 4, corresponding to the degree of similarity between the word pairs.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Wild Dev's team participated this year in SemEval 2017 Task 2, subtask 1, in the evaluation for the English language.", "labels": [], "entities": [{"text": "Wild Dev's team", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.873192086815834}, {"text": "SemEval 2017 Task", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.7639612555503845}]}, {"text": "The system is based on a neural network, trained on an enriched corpus of word pairs.", "labels": [], "entities": []}, {"text": "The paper is structured in 4 sections: this section discusses existing approaches to similarity using word embedding, before presenting the architecture of our system in Section 2.", "labels": [], "entities": []}, {"text": "The next section briefly analyses the results, while Section 4 drafts some conclusions and further work.", "labels": [], "entities": []}, {"text": "In natural language processing, one of the most important challenges is to understand the meaning of words.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 3, "end_pos": 30, "type": "TASK", "confidence": 0.6727104385693868}]}, {"text": "The organizers of Task 2 (Task2, 2017) state that this task \"provides a reliable benchmark for the development, evaluation and analysis\" of: \uf0b7 Word embeddings, monolingual word embeddings, as well as bilingual and multilingual word embeddings which have a unified semantic space for the languages; \uf0b7 Similarity measures that use lexical resources; \uf0b7 Supervised systems that combine multiple measures.", "labels": [], "entities": []}, {"text": "Our initial option was word embedding.", "labels": [], "entities": [{"text": "word embedding", "start_pos": 23, "end_pos": 37, "type": "TASK", "confidence": 0.7989699244499207}]}, {"text": "The most prominent word embedding software tools are: 1.", "labels": [], "entities": []}, {"text": "Word2Vec () is an algorithm with the explicit goal of producing word embeddings that encode general semantic relations).", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9049997925758362}]}, {"text": "2. GloVe () has a similar aim as Word2Vec.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 33, "end_pos": 41, "type": "DATASET", "confidence": 0.9582403898239136}]}, {"text": "Its authors present GloVe mainly as an unsupervised learning algorithm, also offering an implementation.", "labels": [], "entities": []}, {"text": "3. Deeplearning4j is an open source deep learning library for Java which implements both Word2Vec and GloVe, among other algorithms (Deeplearning4j, 2017). and T-Distributed Stochastic Neighbor Embedding (van der Maaten 2008) are two algorithms that reduce the dimensionality of already generated word embedding vectors.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 89, "end_pos": 97, "type": "DATASET", "confidence": 0.9427602291107178}]}], "datasetContent": [{"text": "We performed an internal evaluation of our system on the training data and obtained a score of 0.372 (Pearson: 0.385, Spearman: 0.357).", "labels": [], "entities": [{"text": "Pearson: 0.385", "start_pos": 102, "end_pos": 116, "type": "METRIC", "confidence": 0.9411066969235738}, {"text": "Spearman: 0.357", "start_pos": 118, "end_pos": 133, "type": "METRIC", "confidence": 0.9406595826148987}]}, {"text": "The results show that we have managed to accomplish the main objective of this project, to outperform the random strategy.", "labels": [], "entities": []}, {"text": "The lower scores have been obtained for named entities and multiword expressions, instances which do not exist in our gold standard, for which we plan to add dedicated modules.", "labels": [], "entities": []}, {"text": "Our team participated in task 1 for English, and was officially evaluated with a Pearson score of 0.459 and a Spearman score of 0.477, giving a total of 0.468.", "labels": [], "entities": [{"text": "Pearson score", "start_pos": 81, "end_pos": 94, "type": "METRIC", "confidence": 0.9823712706565857}, {"text": "Spearman score", "start_pos": 110, "end_pos": 124, "type": "METRIC", "confidence": 0.9365972876548767}]}], "tableCaptions": []}