{"title": [{"text": "SZTE-NLP at SemEval-2017 Task 10: A High Precision Sequence Model for Keyphrase Extraction Utilizing Sparse Coding for Feature Generation", "labels": [], "entities": [{"text": "Keyphrase Extraction Utilizing Sparse Coding", "start_pos": 70, "end_pos": 114, "type": "TASK", "confidence": 0.8381870746612549}, {"text": "Feature Generation", "start_pos": 119, "end_pos": 137, "type": "TASK", "confidence": 0.6924406290054321}]}], "abstractContent": [{"text": "In this paper we introduce our system participating at the 2017 SemEval shared task on keyphrase extraction from scientific documents.", "labels": [], "entities": [{"text": "SemEval shared task", "start_pos": 64, "end_pos": 83, "type": "TASK", "confidence": 0.8097161849339803}, {"text": "keyphrase extraction from scientific documents", "start_pos": 87, "end_pos": 133, "type": "TASK", "confidence": 0.8463748455047607}]}, {"text": "We aimed at the creation of a keyphrase extraction approach which relies on as little external resources as possible.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 30, "end_pos": 50, "type": "TASK", "confidence": 0.840763658285141}]}, {"text": "Without applying any hand-crafted external resources, and only utilizing a transformed version of word embeddings trained at Wikipedia, our proposed system manages to perform among the best participating systems in terms of precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 224, "end_pos": 233, "type": "METRIC", "confidence": 0.997952938079834}]}], "introductionContent": [{"text": "The sheer amount of scientific publications makes intelligent processing of papers increasingly important.", "labels": [], "entities": [{"text": "intelligent processing of papers", "start_pos": 50, "end_pos": 82, "type": "TASK", "confidence": 0.7637933641672134}]}, {"text": "Automated keyphrase extraction techniques can mitigate the severe difficulties arising when navigating in massive document collections.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.8007204532623291}]}, {"text": "Hence, extracting keyphrases from scientific literature has generated substantial academic interest over the past years (.", "labels": [], "entities": []}, {"text": "Continuous word representations such as word2vec () has gained increasing popularity recently.", "labels": [], "entities": []}, {"text": "These representations assign some semantically meaningful low dimensional vector w i to the vocabulary entries of large text corpora.", "labels": [], "entities": []}, {"text": "We demonstrated previously) that useful features can be derived for various sequence labeling tasks by performing a sparse decomposition of the word embedding matrix.", "labels": [], "entities": [{"text": "sequence labeling tasks", "start_pos": 76, "end_pos": 99, "type": "TASK", "confidence": 0.7383865316708883}]}, {"text": "In this paper, we investigate the generalization properties of our proposed approach for the task of keyphrase extraction.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 101, "end_pos": 121, "type": "TASK", "confidence": 0.8230220973491669}]}], "datasetContent": [{"text": "In this section we report our evaluations on the SemEval-2017 Task 10 dataset which consists of 350 training, 50 development and 100 test text passages, respectively.", "labels": [], "entities": [{"text": "SemEval-2017 Task 10 dataset", "start_pos": 49, "end_pos": 77, "type": "DATASET", "confidence": 0.6655043885111809}]}, {"text": "Each text passage originates from either Computer Science, Material Sciences or Physics publications and the task was to identify and classify keyphrases into the types of Material, Process and Task.", "labels": [], "entities": []}, {"text": "The shared task included both a keyphrase type insensitive (Subtask A) and sensitive (Subtask B) evaluation.", "labels": [], "entities": []}, {"text": "Further details about the dataset and the description of the keyphrase types can be accessed in.", "labels": [], "entities": []}, {"text": "The only preprocessing we performed on the shared task data was sentence splitting and tokenization of input sentences.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.7636011838912964}, {"text": "tokenization of input sentences", "start_pos": 87, "end_pos": 118, "type": "TASK", "confidence": 0.8584772199392319}]}, {"text": "These steps were executed relying on spacy 3 . In order the sparse word embedding and Brown clustering-based features to work effectively, it is important that the a substantial amount of tokens from the shared task data have word representation determined for, i.e. the coverage of the word representations is satisfactory.", "labels": [], "entities": []}, {"text": "includes the coverage of the word representations for the training, development and test sets.", "labels": [], "entities": []}, {"text": "provides a more detailed breakdown of the coverages of word representations for the different keyphrase types also.", "labels": [], "entities": []}, {"text": "As subsequent results illustrate, higher word coverage fora certain type of keyphrase does not necessarily imply better performance on that type as e.g. Task-type keyphrases have the highest token coverage, nevertheless, scores are the lowest on that particular type (cf.).", "labels": [], "entities": []}, {"text": "illustrates the effect of varying the K and \u03bb hyperparameters of sparse coding when not relying on orthographic or Brown clustering derived features.: Results on the test set with all features used except for the sparse coding-derived ones.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Coverages of the word embeddings.", "labels": [], "entities": []}, {"text": " Table 2: Results of the official submission on the  test data with K = 128, \u03bb = 0.9.", "labels": [], "entities": []}, {"text": " Table 4: Ablation experiments on the development set. P=Precision, R=Recall, F=F-scores.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9597666263580322}, {"text": "Precision", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.9690979719161987}, {"text": "Recall", "start_pos": 70, "end_pos": 76, "type": "METRIC", "confidence": 0.6769313216209412}, {"text": "F-scores", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.5860437154769897}]}]}