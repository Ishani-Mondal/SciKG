{"title": [{"text": "SemEval-2017 Task 6: #HashtagWars: Learning a Sense of Humor", "labels": [], "entities": [{"text": "Learning a Sense of Humor", "start_pos": 35, "end_pos": 60, "type": "TASK", "confidence": 0.6015478074550629}]}], "abstractContent": [{"text": "This paper describes anew shared task for humor understanding that attempts to es-chew the ubiquitous binary approach to humor detection and focus on comparative humor ranking instead.", "labels": [], "entities": [{"text": "humor understanding", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.8592151701450348}, {"text": "humor detection", "start_pos": 121, "end_pos": 136, "type": "TASK", "confidence": 0.7188631743192673}]}, {"text": "The task is based on anew dataset of funny tweets posted in response to shared hashtags, collected from the 'Hashtag Wars' segment of the TV show @midnight.", "labels": [], "entities": []}, {"text": "The results are evaluated in two subtasks that require the participants to generate either the correct pair-wise comparisons of tweets (subtask A), or the correct ranking of the tweets (subtask B) in terms of how funny they are.", "labels": [], "entities": []}, {"text": "7 teams participated in subtask A, and 5 teams participated in subtask B.", "labels": [], "entities": []}, {"text": "The best accuracy in subtask A was 0.675.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9996771812438965}, {"text": "A", "start_pos": 29, "end_pos": 30, "type": "METRIC", "confidence": 0.7998759746551514}]}, {"text": "The best (lowest) rank edit distance for subtask B was 0.872.", "labels": [], "entities": [{"text": "edit distance", "start_pos": 23, "end_pos": 36, "type": "METRIC", "confidence": 0.8907167315483093}]}], "introductionContent": [{"text": "Most work on humor detection approaches the problem as binary classification: humor or not humor.", "labels": [], "entities": [{"text": "humor detection", "start_pos": 13, "end_pos": 28, "type": "TASK", "confidence": 0.8564688563346863}]}, {"text": "While this is a reasonable initial step, in practice humor is continuous, so we believe it is interesting to evaluate different degrees of humor, particularly as it relates to a given person's sense of humor.", "labels": [], "entities": []}, {"text": "To further such research, we propose a dataset based on humorous responses submitted to a Comedy Central TV show, allowing for computational approaches to comparative humor ranking.", "labels": [], "entities": [{"text": "comparative humor ranking", "start_pos": 155, "end_pos": 180, "type": "TASK", "confidence": 0.8431236545244852}]}, {"text": "Debuting in Fall 2013, the Comedy Central show @midnight 1 is a late-night \"game-show\" that presents a modern outlook on current events by focusing on content from social media.", "labels": [], "entities": [{"text": "Comedy Central show @midnight 1", "start_pos": 27, "end_pos": 58, "type": "DATASET", "confidence": 0.9394497871398926}]}, {"text": "The show's contestants (generally professional comedians or actors) are awarded points based on how funny their answers are.", "labels": [], "entities": []}, {"text": "The segment of the show that best illustrates this attitude is the Hashtag Wars (HW).", "labels": [], "entities": [{"text": "Hashtag Wars (HW)", "start_pos": 67, "end_pos": 84, "type": "TASK", "confidence": 0.5265520572662353}]}, {"text": "Every episode the show's host proposes a topic in the form of a hashtag, and the show's contestants must provide tweets that would have this hashtag.", "labels": [], "entities": []}, {"text": "Viewers are encouraged to tweet their own responses.", "labels": [], "entities": []}, {"text": "From the viewers' tweets, we are able to apply labels that determine how relatively humorous the show finds a given tweet.", "labels": [], "entities": []}, {"text": "Because of the contest's format, it provides an adequate method for addressing the selection bias often present in machine learning techniques.", "labels": [], "entities": []}, {"text": "Since each tweet is intended for the same hashtag, each tweet is effectively drawn from the same sample distribution.", "labels": [], "entities": []}, {"text": "Consequently, tweets are seen not as humor/nonhumor, but rather varying degrees of wit and cleverness.", "labels": [], "entities": []}, {"text": "Moreover, given the subjective nature of humor, labels in the dataset are only \"gold\" with respect to the show's sense of humor.", "labels": [], "entities": []}, {"text": "This concept becomes more grounded when considering the use of supervised systems for the dataset.", "labels": [], "entities": []}, {"text": "The idea of the dataset is to learn to characterize the sense of humor represented in this show.", "labels": [], "entities": []}, {"text": "Given a set of hashtags, the goal is to predict which tweets the show will find funnier within each hashtag.", "labels": [], "entities": []}, {"text": "The degree of humor in a given tweet is determined by the labels provided by the show.", "labels": [], "entities": []}, {"text": "We propose two subtasks to evaluate systems on the dataset.", "labels": [], "entities": []}, {"text": "The first subtask is pairwise comparison: given two tweets, select the funnier tweet, and the pairs will be derived from the labels assigned by the show to individual tweets.", "labels": [], "entities": []}, {"text": "The second subtask is to rank the the tweets based on the comparative labels provided by the show.", "labels": [], "entities": []}, {"text": "This is a semiranking task because most labels are applied to more than one tweet.", "labels": [], "entities": []}, {"text": "Seen as a classification task, the labels are comparative, because there is a notion of distance.", "labels": [], "entities": []}, {"text": "We introduce anew edit distance-49 inspired metric for this subtask.", "labels": [], "entities": []}, {"text": "A number of different computational approaches to humor have been proposed within the last decade ().", "labels": [], "entities": []}, {"text": "In particular,; Raz (2012);; focus on recognizing humor in Twitter.", "labels": [], "entities": []}, {"text": "However, the majority of this work focuses on distinguishing humor from non-humor.", "labels": [], "entities": []}, {"text": "This representation has two shortcomings: (1) it ignores the continuous nature of humor, and (2) it does not take into account the subjectivity in humor perception.", "labels": [], "entities": [{"text": "humor perception", "start_pos": 147, "end_pos": 163, "type": "TASK", "confidence": 0.6824048608541489}]}, {"text": "Regarding the first issue, we believe that shifting away from the binary approach to humor detection as done in the present task is a good pathway towards advancing this work.", "labels": [], "entities": [{"text": "humor detection", "start_pos": 85, "end_pos": 100, "type": "TASK", "confidence": 0.8512236177921295}]}, {"text": "Regarding the second issue, consider a humour annotation task done by, in which the annotators looked at pairs of captions from the New Yorker Caption Content 2 , report that \"Only 35% of the unique pairs that were ranked by at least five people achieved 80% agreement...\"", "labels": [], "entities": [{"text": "New Yorker Caption Content 2", "start_pos": 132, "end_pos": 160, "type": "DATASET", "confidence": 0.8118229031562805}, {"text": "agreement", "start_pos": 259, "end_pos": 268, "type": "METRIC", "confidence": 0.9718683958053589}]}, {"text": "In contrast, the goal of the present task is to not to identify humour that is universal, but rather, to capture the specific sense of humour represented in the show.", "labels": [], "entities": []}], "datasetContent": [{"text": "Data collection occurred for roughly eight months, producing a total of 12,734 tweets for 112 hashtags.", "labels": [], "entities": []}, {"text": "The resulting dataset is what we used for the task.", "labels": [], "entities": []}, {"text": "The distribution of the number of tweets per hashtag is represented in.", "labels": [], "entities": []}, {"text": "For 71% of hashtags, we have at least 90 tweets.", "labels": [], "entities": []}, {"text": "The files of the individual hashtags are formatted so that the individual hashtag tokens are easily recoverable.", "labels": [], "entities": []}, {"text": "Specifically, tokens are separated by the ' ' character.", "labels": [], "entities": []}, {"text": "For example, the hashtag FastFoodBooks has the filename \"fast food books.tsv\".", "labels": [], "entities": []}, {"text": "serve that this hashtag requires external knowledge about fast food and books in order to understand the humor.", "labels": [], "entities": []}, {"text": "Furthermore, this hashtag illustrates how prevalent puns are in the dataset, especially related to certain target hashtags.", "labels": [], "entities": []}, {"text": "In contrast, the hashtag IfIWerePresident (see 3) does not require external knowledge and the tweets are understandable without awareness of any specific concepts.", "labels": [], "entities": []}, {"text": "For the purpose of our task, we released 5 files/660 tweets as the trial data, 101 files/11,325 tweets (separate from the trial data) as the training data, and 6 files/749 tweets as the evaluation data.", "labels": [], "entities": []}, {"text": "The 6 evaluation files were chosen based on the following logic: first, we examined the results of our own systems on individual hashtags using leave-one-out evaluation (.", "labels": [], "entities": []}, {"text": "We looked fora mixture of hashtags that had high, average, and low performance.", "labels": [], "entities": []}, {"text": "Secondly, we wanted a mixture of hashtags that promote different types of humor, such as puns that use external knowledge (for example the hashtag FastFoodBooks in2), or hashtags that seek to express more general humor (for example the hashtag IfIWerePresident in2).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The official results for the subtask A broken down by hashtag. Bold indicates the best run  for the given hashtag. \"Christmas\" corresponds to the hashtag RuinAChristmasMovie, \"Shakespeare\"  corresponds to ModernShakespeare, \"Bad Job\" to BadJobIn5Words, \"Break Up\" to BreakUpIn5Words,  \"Broadway\" to BroadwayACeleb, and \"Cereal\" to CerealSongs.", "labels": [], "entities": [{"text": "ModernShakespeare", "start_pos": 215, "end_pos": 232, "type": "DATASET", "confidence": 0.9724912047386169}, {"text": "BroadwayACeleb", "start_pos": 309, "end_pos": 323, "type": "DATASET", "confidence": 0.915968120098114}]}, {"text": " Table 3: Unofficial results for the subtask A on the released evaluation set reported by the participating  teams", "labels": [], "entities": []}]}