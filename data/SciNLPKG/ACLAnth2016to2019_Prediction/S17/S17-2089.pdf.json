{"title": [{"text": "SemEval-2017 Task 5: Fine-Grained Sentiment Analysis on Financial Microblogs and News", "labels": [], "entities": [{"text": "Fine-Grained Sentiment Analysis", "start_pos": 21, "end_pos": 52, "type": "TASK", "confidence": 0.6278285284837087}, {"text": "Financial Microblogs and News", "start_pos": 56, "end_pos": 85, "type": "DATASET", "confidence": 0.7185457050800323}]}], "abstractContent": [{"text": "This paper discusses the \"Fine-Grained Sentiment Analysis on Financial Mi-croblogs and News\" task as part of SemEval-2017, specifically under the \"Detecting sentiment, humour, and truth\" theme.", "labels": [], "entities": [{"text": "Sentiment Analysis on Financial Mi-croblogs and News\" task", "start_pos": 39, "end_pos": 97, "type": "TASK", "confidence": 0.6498385502232445}, {"text": "Detecting sentiment, humour, and truth", "start_pos": 147, "end_pos": 185, "type": "TASK", "confidence": 0.83478958266122}]}, {"text": "This task contains two tracks, where the first one concerns Microblog messages and the second one covers News Statements and Headlines.", "labels": [], "entities": []}, {"text": "The main goal behind both tracks was to predict the sentiment score for each of the mentioned companies/stocks.", "labels": [], "entities": []}, {"text": "The sentiment scores for each text instance adopted floating point values in the range of-1 (very negative/bearish) to 1 (very positive/bullish), with 0 designating neutral sentiment.", "labels": [], "entities": []}, {"text": "This task attracted a total of 32 participants, with 25 participating in Track 1 and 29 in Track 2.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "The Evaluation of the participating systems was based on cosine similarity, in a spirit similar to.", "labels": [], "entities": []}, {"text": "As the sentiment scores to be predicted by systems lie on a continuous scale between -1 and 1 (cp.", "labels": [], "entities": []}, {"text": "Section 2.5), cosine enables us to compare the proximity between gold standard and predicted results (conceptualized as vectors), while not requiring exact correspondence between the gold and predicted score fora given instance.", "labels": [], "entities": []}, {"text": "An instance is a message or headline which can include several entities (companies or cashtags).", "labels": [], "entities": []}, {"text": "Cosine similarity is calculated according to equation, where G is the vector of gold standard scores and P is the vector of corresponding scores predicted by the system: In order to reward systems which attempt to answer all problems in the gold standard, the final score is obtained by weighting the cosine similarity from (1) with the ratio of answered problems (scored instances), given in (2) inline with.", "labels": [], "entities": []}, {"text": "The equation for the final score is the product of the cosine similarity (1) and the weight (2), given in (3).", "labels": [], "entities": [{"text": "cosine similarity (1)", "start_pos": 55, "end_pos": 76, "type": "METRIC", "confidence": 0.8945051074028015}]}, {"text": "final score = cos weight \u00d7 cosine(G, P ) (3)  Based on the evaluation metric as stated in Section 4, another evaluation metric has been developed during the competition.", "labels": [], "entities": []}, {"text": "The intention to propose a modified way of evaluation was based on the fact that the cosine similarity (1) is treating all predicted scores with the same weight.", "labels": [], "entities": [{"text": "cosine similarity (1)", "start_pos": 85, "end_pos": 106, "type": "METRIC", "confidence": 0.9096298933029174}]}, {"text": "This approach is not exploiting all information given in the data set, in specific it is not taking the link between entities and instances into consideration.", "labels": [], "entities": []}], "tableCaptions": []}