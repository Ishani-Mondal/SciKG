{"title": [{"text": "Adullam at SemEval-2017 Task 4: Sentiment Analyzer based on Lexicon Integrated Convolutional Neural Networks with Attention", "labels": [], "entities": [{"text": "SemEval-2017 Task 4", "start_pos": 11, "end_pos": 30, "type": "TASK", "confidence": 0.8119487166404724}, {"text": "Sentiment Analyzer", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.9130255579948425}]}], "abstractContent": [{"text": "We propose a sentiment analyzer for the prediction of document-level sentiments of English micro-blog messages from Twit-ter.", "labels": [], "entities": [{"text": "prediction of document-level sentiments of English micro-blog messages from Twit-ter", "start_pos": 40, "end_pos": 124, "type": "TASK", "confidence": 0.6656634092330933}]}, {"text": "The proposed method is based on lexicon integrated convolutional neural networks with attention (LCA).", "labels": [], "entities": []}, {"text": "Its performance was evaluated using the datasets provided by SemEval competition (Task 4).", "labels": [], "entities": []}, {"text": "The proposed sentiment analyzer obtained an average F1 of 55.2%, an average recall of 58.9% and an accuracy of 61.4%.", "labels": [], "entities": [{"text": "sentiment analyzer", "start_pos": 13, "end_pos": 31, "type": "TASK", "confidence": 0.9484761953353882}, {"text": "F1", "start_pos": 52, "end_pos": 54, "type": "METRIC", "confidence": 0.9995715022087097}, {"text": "recall", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9761983156204224}, {"text": "accuracy", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9996490478515625}]}], "introductionContent": [{"text": "Sentiment analysis is necessary to interpret the vast number of online opinions on social media platforms such as Twitter.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9666910767555237}]}, {"text": "This will allow governments and corporations to manage public relations and policies effectively.", "labels": [], "entities": []}, {"text": "Existing sentiment analyzers are based on na\u00efve bayes, SVM, RNN) and in particular convolutional neural networks (CNNs).", "labels": [], "entities": [{"text": "sentiment analyzers", "start_pos": 9, "end_pos": 28, "type": "TASK", "confidence": 0.8838527798652649}]}, {"text": "In order to improve on existing CNN based sentiment analyzer, lexicon embedding and attention embedding were integrated into the proposed sentiment analyzer.", "labels": [], "entities": [{"text": "sentiment analyzer", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.6306108832359314}, {"text": "sentiment analyzer", "start_pos": 138, "end_pos": 156, "type": "TASK", "confidence": 0.7560625374317169}]}, {"text": "Lexicon embedding allows extraction of sentimental score for each word and attention embedding enables the global view of the sentence.", "labels": [], "entities": []}, {"text": "The proposed LCA was both trained and evaluated using corpus from Twitter 2013 to 2016 provided by the SemEval-2017.", "labels": [], "entities": []}, {"text": "shows the overview of the proposed sentiment analyzer.", "labels": [], "entities": [{"text": "sentiment analyzer", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.9214524328708649}]}, {"text": "It consists of embedding, CNNs, concatenation, fully connected and softmax layer.", "labels": [], "entities": []}], "datasetContent": [{"text": "The evaluation metric consisted of (i) macro-averaged F1 measure, (ii) recall (iii) and accuracy in the competition across the positive, negative and neutral classes.", "labels": [], "entities": [{"text": "F1 measure", "start_pos": 54, "end_pos": 64, "type": "METRIC", "confidence": 0.9695340692996979}, {"text": "recall", "start_pos": 71, "end_pos": 77, "type": "METRIC", "confidence": 0.9992989301681519}, {"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9993509650230408}]}], "tableCaptions": [{"text": " Table 1: Overview of datasets", "labels": [], "entities": [{"text": "Overview of datasets", "start_pos": 10, "end_pos": 30, "type": "DATASET", "confidence": 0.700329601764679}]}, {"text": " Table 2: F1 scores corresponding  to the dimension of word embedding", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9991552829742432}]}]}