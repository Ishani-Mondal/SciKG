{"title": [{"text": "SCIR-QA at SemEval-2017 Task 3: CNN Model Based on Similar and Dissimilar Information between Keywords for Question Similarity", "labels": [], "entities": [{"text": "Question Similarity", "start_pos": 107, "end_pos": 126, "type": "TASK", "confidence": 0.5914240777492523}]}], "abstractContent": [{"text": "We describe a method of calculating the similarity between questions in community QA.", "labels": [], "entities": []}, {"text": "Questions in cQA are usually very long and there area lot of useless information about calculating the similarity between questions.", "labels": [], "entities": [{"text": "cQA", "start_pos": 13, "end_pos": 16, "type": "DATASET", "confidence": 0.9520266056060791}]}, {"text": "Therefore, we implement a CNN model based on similar and dissimilar information on questions keywords.", "labels": [], "entities": []}, {"text": "We extract the keywords of questions , and then model the similar and dissimilar information between the keywords , and use the CNN model to calculate the similarity.", "labels": [], "entities": []}], "introductionContent": [{"text": "We participate in) on Community Question Answering.", "labels": [], "entities": [{"text": "Community Question Answering", "start_pos": 22, "end_pos": 50, "type": "TASK", "confidence": 0.6021322210629781}]}, {"text": "In this task, we are given a question from community forum (named original question) and 10 related questions.", "labels": [], "entities": []}, {"text": "We need to re-rank the related questions according to their similarity between the origin question.", "labels": [], "entities": []}, {"text": "Both the original question and the related question have question subject and question body.", "labels": [], "entities": []}, {"text": "The body is long and contains a lot of useless information.", "labels": [], "entities": []}, {"text": "In our system, we try to use keywords to replace questions to locate more important information on the question, so we use a keyword extraction algorithm that combines syntactic information to get more accurate keywords.", "labels": [], "entities": [{"text": "keyword extraction", "start_pos": 125, "end_pos": 143, "type": "TASK", "confidence": 0.7406942248344421}]}, {"text": "Then we use a CNN model based on similar and dissimilar information between questions to calculate the similarity of questions.", "labels": [], "entities": []}, {"text": "The model can make good use of similar information and dissimilar information between questions to get better results.", "labels": [], "entities": []}, {"text": "The paper is organized as follows: Section 2 introduces our system.", "labels": [], "entities": []}, {"text": "Section 3 introduces the experiment.", "labels": [], "entities": []}, {"text": "And in section 4, there are the conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We experimented with the corpus provided by SemEval-2017 task3.", "labels": [], "entities": []}, {"text": "Training set has 267 questions, each question has 10 related questions, a total of 2670 question pairs.", "labels": [], "entities": []}, {"text": "Development set has 50 questions, 500 question pairs.", "labels": [], "entities": [{"text": "Development set", "start_pos": 0, "end_pos": 15, "type": "DATASET", "confidence": 0.8953700363636017}]}, {"text": "The test set has 88 questions, 880 question pairs.", "labels": [], "entities": []}, {"text": "We do the experiment without preprocessing.", "labels": [], "entities": []}, {"text": "We use Stanfod Parser to parse sentences.", "labels": [], "entities": [{"text": "Stanfod Parser", "start_pos": 7, "end_pos": 21, "type": "DATASET", "confidence": 0.905344694852829}]}, {"text": "And we use the keyword extraction algorithm described in 2.1, for each sub-sentence we extract 1/3 of the words as keywords and set b = 1.4, d = 0.8.", "labels": [], "entities": [{"text": "keyword extraction", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.7725157737731934}]}, {"text": "In the CNN model, we setup the filter shape is 3*300.", "labels": [], "entities": []}, {"text": "The number of filters is 500.", "labels": [], "entities": []}, {"text": "We set the similarity threshold of 0.5, that is, a score greater than 0.5 is considered a positive case.", "labels": [], "entities": [{"text": "similarity threshold", "start_pos": 11, "end_pos": 31, "type": "METRIC", "confidence": 0.9849512875080109}]}, {"text": "And we set the learning rate as 0.001.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 15, "end_pos": 28, "type": "METRIC", "confidence": 0.9653708934783936}]}, {"text": "After 20 rounds of training, we got the result in devlopment set and test set.", "labels": [], "entities": []}, {"text": "The results in test set are shown in, the first two lines are the baseline, the next two lines are the best results, the last line is our result.", "labels": [], "entities": []}, {"text": "And results in development set are shown in.", "labels": [], "entities": []}, {"text": "In test set, our results are better than the baseline, but there is still some distance from the best results.", "labels": [], "entities": []}, {"text": "In development set, our result is all not so good.", "labels": [], "entities": []}, {"text": "We think that because we do the experiment without preprocessing, there exists too many unknown words in word embeddings, which results in poor system performance.", "labels": [], "entities": []}, {"text": "On the other hand, because the training corpus is too small, the neural network cannot be well trained and cannot find meaningful features.", "labels": [], "entities": []}, {"text": "Therefore, in the future work, we will add features of artificial extraction into neural network to improve performance.", "labels": [], "entities": []}, {"text": "And we will add features of artificial extraction into neural network to improve performance.", "labels": [], "entities": []}], "tableCaptions": []}