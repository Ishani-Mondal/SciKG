{"title": [{"text": "SVNIT @ SemEval 2017 Task-6: Learning a Sense of Humor Using Supervised Approach", "labels": [], "entities": [{"text": "SVNIT @ SemEval 2017 Task-6", "start_pos": 0, "end_pos": 27, "type": "DATASET", "confidence": 0.9065711855888366}, {"text": "Learning a Sense of Humor", "start_pos": 29, "end_pos": 54, "type": "TASK", "confidence": 0.616562694311142}]}], "abstractContent": [{"text": "This paper describes the system developed for SemEval 2017 task 6: #HashTagWars-Learning a Sense of Humor.", "labels": [], "entities": [{"text": "SemEval 2017 task 6", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.9136292040348053}, {"text": "HashTagWars-Learning a Sense of Humor", "start_pos": 68, "end_pos": 105, "type": "TASK", "confidence": 0.787768816947937}]}, {"text": "Learning to recognize sense of humor is the important task for language understanding applications.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 63, "end_pos": 85, "type": "TASK", "confidence": 0.7983104288578033}]}, {"text": "Different set of features based on frequency of words, structure of tweets and semantics are used in this system to identify the presence of humor in tweets.", "labels": [], "entities": []}, {"text": "Supervised machine learning approaches, Multilayer perceptron and Na\u00efve Bayes are used to classify the tweets in to three levels of sense of humor.", "labels": [], "entities": [{"text": "Na\u00efve Bayes", "start_pos": 66, "end_pos": 77, "type": "METRIC", "confidence": 0.7554082572460175}]}, {"text": "For given Hashtag, the system finds the funniest tweet and predicts the amount of funniness of all the other tweets.", "labels": [], "entities": []}, {"text": "In official submitted runs, we have achieved 0.506 accuracy using multi-layer perceptron in subtask-A and 0.938 distance in subtask-B.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.997180700302124}, {"text": "distance", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.9582782983779907}]}, {"text": "Using Na\u00efve bayes in subtask-B, the system achieved 0.949 distance.", "labels": [], "entities": [{"text": "distance", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.9626748561859131}]}, {"text": "Apart from official runs, this system have scored 0.751 accuracy in sub-task-A using SVM.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9994679093360901}, {"text": "SVM", "start_pos": 85, "end_pos": 88, "type": "DATASET", "confidence": 0.8437491655349731}]}], "introductionContent": [{"text": "Humor is an integral aspect of human beings that requires self-awareness, spontaneity, linguistic sophistication and empathy.", "labels": [], "entities": [{"text": "Humor", "start_pos": 0, "end_pos": 5, "type": "TASK", "confidence": 0.9546496868133545}]}, {"text": "Generating and recognizing humor is not an easy task to be carried out by machines.", "labels": [], "entities": [{"text": "Generating and recognizing humor", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7908260077238083}]}, {"text": "Generating and understanding humor can be useful in many NLP tasks.) have described the use of humor as the pedagogical tool for language learners, as it helps to keep students interested and motivated.", "labels": [], "entities": []}, {"text": "Moreover, recognizing humor is also important in sentiment analysis and opinion mining because it can be useful to get the actual meaning out of figurative sentence.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.9771267771720886}, {"text": "opinion mining", "start_pos": 72, "end_pos": 86, "type": "TASK", "confidence": 0.8002983331680298}]}, {"text": "Research on modeling humor such as))is focused on classifying humor into binary classes as humor and non-humor.", "labels": [], "entities": []}, {"text": "In), humor is modeled by a binary classifier as well as by a multi-class classifier.", "labels": [], "entities": []}, {"text": "It classifies different figurative sentences into humor, irony, politics, technology and general sentences.", "labels": [], "entities": []}, {"text": "But all these approaches ignore the continuous nature of humor.", "labels": [], "entities": []}, {"text": "Hence in task 6 of SemEval 2017 HashTag Wars: Learning a sense of humor, humor in tweet should be modeled in its continuous form instead of binary.", "labels": [], "entities": [{"text": "SemEval 2017 HashTag Wars", "start_pos": 19, "end_pos": 44, "type": "TASK", "confidence": 0.7752847075462341}]}, {"text": "The participating groups are asked to predict the amount of funniness of the tweet for particular hashtag according to gold labels of tweet.", "labels": [], "entities": []}, {"text": "Tweets are labeled with 0, 1, or 2.", "labels": [], "entities": []}, {"text": "0 corresponds to tweet not in top 10. 1 corresponds to tweet in top 10 but not winning tweet and 2 corresponds to winning tweet.", "labels": [], "entities": []}, {"text": "There are two subtasks: A) pairwise comparison-a task of predicting which tweet is funnier from given two tweets according to gold labels of tweets.", "labels": [], "entities": []}, {"text": "In given pair of tweets, the tweet with higher label is said to be funnier.", "labels": [], "entities": []}, {"text": "B) Semi-ranking-a task to predict ranking of tweets from funniest to least funny forgiven file of tweets fora hashtag.", "labels": [], "entities": []}, {"text": "The remainder of this paper is structured as follows: In section 2, description about overall system architecture is given.", "labels": [], "entities": []}, {"text": "It covers pre-processing stage, feature extraction, simple machine learnings approaches for classification and comparator for ranking of tweets.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.7732090950012207}]}, {"text": "Section 3 describes the results of experiments carried out for subtask A and subtask B by our system followed by conclusion in section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe the experiment carried out for the different subtasks and the datasets provided by the organizers.", "labels": [], "entities": []}, {"text": "The dataset is composed of 9658 tweets for 86 hashtags roughly collected over seven months of period.", "labels": [], "entities": []}, {"text": "represents the comparison of result of our system with other systems in subtask A and subtask B as per the results declared on SemEval portal.", "labels": [], "entities": [{"text": "SemEval portal", "start_pos": 127, "end_pos": 141, "type": "DATASET", "confidence": 0.8541311025619507}]}, {"text": "Scores with bold are best scores of respective system in that subtask.", "labels": [], "entities": []}, {"text": "Our system has scored average in subtask A using Multilayer perceptron classifier with 0.506 accuracy in official submitted runs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.9984573125839233}]}, {"text": "In the same subtask our system scored 0.751 accuracy, when evaluated with given evaluation script, which is higher than the highest scoring system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9989871382713318}]}, {"text": "In subtask B, our system have ranked the tweets with 0.938 distance using multilayer perceptron and with 0.949 distance using Na\u00efve Bayes classifier.", "labels": [], "entities": []}, {"text": "This edit distance should be as low as possible because it evaluate the system according to how many moves for each tweet need to be occur for placing it at right place.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2:  . For each POS tagged word in tweet written- spoken frequency, written frequency and spoken  frequency is calculated respectively as below from", "labels": [], "entities": [{"text": "written frequency", "start_pos": 74, "end_pos": 91, "type": "METRIC", "confidence": 0.8845890462398529}]}]}