{"title": [{"text": "OMAM at SemEval-2017 Task 4: Evaluation of English State-of-the-Art Sentiment Analysis Models for Arabic and a New Topic-based Model", "labels": [], "entities": [{"text": "OMAM at SemEval-2017 Task 4", "start_pos": 0, "end_pos": 27, "type": "DATASET", "confidence": 0.8168305277824401}, {"text": "English State-of-the-Art Sentiment Analysis", "start_pos": 43, "end_pos": 86, "type": "TASK", "confidence": 0.5214092433452606}]}], "abstractContent": [{"text": "While sentiment analysis in English has achieved significant progress, it remains a challenging task in Arabic given the rich morphology of the language.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 6, "end_pos": 24, "type": "TASK", "confidence": 0.9621927738189697}]}, {"text": "It becomes more challenging when applied to Twitter data that comes with additional sources of noise including dialects, misspellings, grammatical mistakes, code switching and the use of non-textual objects to express sentiments.", "labels": [], "entities": []}, {"text": "This paper describes the \"OMAM\" systems that we developed as part of SemEval-2017 task 4.", "labels": [], "entities": [{"text": "SemEval-2017 task 4", "start_pos": 69, "end_pos": 88, "type": "TASK", "confidence": 0.8454876144727071}]}, {"text": "We evaluate English state-of-the-art methods on Arabic tweets for subtask A.", "labels": [], "entities": []}, {"text": "As for the remaining subtasks, we introduce a topic-based approach that accounts for topic specificities by predicting topics or domains of upcoming tweets, and then using this information to predict their sentiment.", "labels": [], "entities": []}, {"text": "Results indicate that applying the English state-of-the-art method to Ara-bic has achieved solid results without significant enhancements.", "labels": [], "entities": []}, {"text": "Furthermore, the topic-based method ranked 1 st in subtasks C and E, and 2 nd in subtask D.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sentiment Analysis (SA) is a fundamental problem aiming to allow machines to automatically extract subjectivity information from text), whether at the sentence or the document level.", "labels": [], "entities": [{"text": "Sentiment Analysis (SA)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8976317524909974}]}, {"text": "This field has been attracting attention in the research and business communities due to the complexity of human language, and given the range of applications that are interested in harvesting public opinion in different domains such as politics, stocks and marketing.", "labels": [], "entities": []}, {"text": "The interest in SA from Arabic tweets has increased since Arabic has become a key source of the Internet content, with Twitter being one of the most expressive social media platforms.", "labels": [], "entities": [{"text": "SA from Arabic tweets", "start_pos": 16, "end_pos": 37, "type": "TASK", "confidence": 0.8720503747463226}]}, {"text": "While models for SA from English tweets have achieved significant success, Arabic methods continue to lag.", "labels": [], "entities": [{"text": "SA", "start_pos": 17, "end_pos": 19, "type": "TASK", "confidence": 0.9848098158836365}]}, {"text": "Opinion mining in Arabic (OMA) is a challenging task given: (1) the morphological complexity of Arabic, (2) the excessive use of dialects that vary significantly across the Arab world, (3) the significant amounts of misspellings and grammatical errors due to length restriction in Twitter, (4) the variations in writing styles, topics and expressions used across the Arab world due to cultural diversity (, and (5) the existence of Twitter-specific tokens (hashtags, mentions, multimedia objects) that may have subjective information embedded in them.", "labels": [], "entities": [{"text": "Opinion mining in Arabic (OMA)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.9176633528300694}]}, {"text": "Further details on challenging issues in Arabic SA are discussed in.", "labels": [], "entities": [{"text": "Arabic SA", "start_pos": 41, "end_pos": 50, "type": "TASK", "confidence": 0.6696439981460571}]}, {"text": "In this paper, we present the different systems we developed as part of our participation in SemEval-2017 Task 4 on Sentiment Analysis in Twitter (.", "labels": [], "entities": [{"text": "SemEval-2017 Task 4 on Sentiment Analysis in Twitter", "start_pos": 93, "end_pos": 145, "type": "TASK", "confidence": 0.7612966522574425}]}, {"text": "This task covers both English and Arabic languages.", "labels": [], "entities": []}, {"text": "Our systems work on Arabic, but is submitted as part of the OMAM (Opinion Mining for Arabic and More) team that also submitted a system that analyzes sentiment in English ().", "labels": [], "entities": []}, {"text": "The first system extends English state-of-theart feature engineering methods, and is based on training sentiment classifiers with different choices of surface, syntactic and semantic features.", "labels": [], "entities": []}, {"text": "The second is based on clustering the data into groups of semantically-related tweets and developing a sentiment classifier for each cluster.", "labels": [], "entities": []}, {"text": "The third extends recent advances in deep learning methods.", "labels": [], "entities": []}, {"text": "The fourth is a topic-based approach for twitter SA that introduces a mechanism to predict the topics of tweets, and then use this information to predict their sentiment polarity.", "labels": [], "entities": [{"text": "twitter SA", "start_pos": 41, "end_pos": 51, "type": "TASK", "confidence": 0.5099126994609833}]}, {"text": "It further allows operating at the domain-level as a form of generalization from topics.", "labels": [], "entities": []}, {"text": "We evaluate these models for message polarity classification (subtask A), topicbased polarity classification (subtasks B-C) and tweet quantification (subtasks D-E).", "labels": [], "entities": [{"text": "message polarity classification", "start_pos": 29, "end_pos": 60, "type": "TASK", "confidence": 0.8643746972084045}, {"text": "topicbased polarity classification", "start_pos": 74, "end_pos": 108, "type": "TASK", "confidence": 0.6952606836954752}, {"text": "tweet quantification", "start_pos": 128, "end_pos": 148, "type": "TASK", "confidence": 0.7133591175079346}]}, {"text": "Experimental results show that English state-of-the-art methods achieved reasonable results in Arabic without any customization, with results being in the middle of the group in subtask A.", "labels": [], "entities": []}, {"text": "For the remaining subtasks, the topic-based approach ranked 2 nd in subtask D and 1 st in subtasks C and E.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes previous efforts on the given task.", "labels": [], "entities": []}, {"text": "Section 3 presents the details of the Arabic OMAM systems.", "labels": [], "entities": []}, {"text": "Section 4 illustrates the performances achieved for each subtask.", "labels": [], "entities": []}, {"text": "We conclude in Section 5 with remarks on future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe the experiments and results we achieved as part of our participation in SemEval-2017 Task 4.", "labels": [], "entities": [{"text": "SemEval-2017 Task 4", "start_pos": 101, "end_pos": 120, "type": "TASK", "confidence": 0.7526751160621643}]}, {"text": "We describe the datasets we used, the preprocessing steps we applied and the performance of the different systems for each subtask.", "labels": [], "entities": []}, {"text": "illustrates the design of the evaluation experiments, highlighting the systems that were evaluated for each subtask.", "labels": [], "entities": []}, {"text": "The system that achieved the best evaluation results, for each subtask, was then used to submit the test results.", "labels": [], "entities": []}, {"text": "To run our experiments, we used datasets provided by the task organizers () as follows.", "labels": [], "entities": []}, {"text": "During evaluation, we trained our models on the TRAIN set, and evaluated our different systems on the DEV set.", "labels": [], "entities": [{"text": "TRAIN set", "start_pos": 48, "end_pos": 57, "type": "DATASET", "confidence": 0.8173023164272308}, {"text": "DEV set", "start_pos": 102, "end_pos": 109, "type": "DATASET", "confidence": 0.9599728882312775}]}, {"text": "During testing, the system that achieved the best development results is trained using the combination of TRAIN and DEV sets, and tested the model on the TEST set.", "labels": [], "entities": [{"text": "TRAIN", "start_pos": 106, "end_pos": 111, "type": "METRIC", "confidence": 0.9395851492881775}, {"text": "TEST set", "start_pos": 154, "end_pos": 162, "type": "DATASET", "confidence": 0.8059451878070831}]}, {"text": "For the English state-of-the-art approach (System 1), tweets are preprocessed by (1) replacing mentions and URLs with special tokens, (2) extracting emoticons and emojis and replacing them with special tokens using the emojis sentiment lexicon () and a in-home emoticons lexicon, (3) normalizing hashtags by removing the # symbol and the underscores that connect words in composite hashtags, and (4) normalizing letter repetitions (elongations).", "labels": [], "entities": []}, {"text": "Then features are extracted by performing lemmatization and POS tagging using MADAMIRA v2.1, the state-of-the-art morphological analyzer and disambiguator in Arabic (, that uses the Standard Arabic Morphological Analyzer (SAMA) (.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 60, "end_pos": 71, "type": "TASK", "confidence": 0.7637080252170563}]}, {"text": "We only included n-grams that occurred more than a pre-defined threshold t, where t \u2208 is tuned on the \"DEV\" set.", "labels": [], "entities": [{"text": "DEV\" set", "start_pos": 103, "end_pos": 111, "type": "DATASET", "confidence": 0.8475973606109619}]}, {"text": "For the cluster-based SA approach (System 2), we trained the skip-gram word embedding model using a collection of datasets including the TRAIN and the DEV tweets provided by the organizers, the Qatar Arabic Language Bank (QALB) and several Arabic Twitter corpora from).", "labels": [], "entities": [{"text": "TRAIN", "start_pos": 137, "end_pos": 142, "type": "METRIC", "confidence": 0.9822575449943542}, {"text": "Qatar Arabic Language Bank (QALB)", "start_pos": 194, "end_pos": 227, "type": "DATASET", "confidence": 0.8544300454003471}]}, {"text": "We also used the k-means algorithm to cluster the embedding space into k clusters, with k ranging between 1 (no clustering) and 12.", "labels": [], "entities": []}, {"text": "Best results during development were obtained using k = 4 and 5.", "labels": [], "entities": []}, {"text": "For the RAE approach (System 3), tweets are processed similar to System 1.", "labels": [], "entities": [{"text": "RAE", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.8962477445602417}]}, {"text": "We used MADAMIRA v2.1 to perform morphological tokenization following the ATB scheme).", "labels": [], "entities": []}, {"text": "We also used the Stanford parser to generate the syntactic parse trees.", "labels": [], "entities": []}, {"text": "Since the resulting trees are not necessarily binary, and hence cannot be used to train recursive models, we used left-factoring to transform the trees to the Chomsky Normal Form (CNF) grammar that only contains unary and binary production rules.", "labels": [], "entities": []}, {"text": "For the topic-based approach (System 4), tweets are preprocessed by applying normalization and stemming using the NLTK ISRI stemmer () and stopword removal.", "labels": [], "entities": [{"text": "NLTK ISRI stemmer", "start_pos": 114, "end_pos": 131, "type": "DATASET", "confidence": 0.7867867549260458}]}, {"text": "Then, n-grams are extracted using SKlearn TFiDFvectorizer (Pedregosa et al., 2011), with a variance threshold for feature reduction.", "labels": [], "entities": [{"text": "SKlearn TFiDFvectorizer", "start_pos": 34, "end_pos": 57, "type": "DATASET", "confidence": 0.7103777825832367}, {"text": "feature reduction", "start_pos": 114, "end_pos": 131, "type": "TASK", "confidence": 0.6593072861433029}]}, {"text": "The tweets in the training set that is provided by the task organizers pertain to 34 topics.", "labels": [], "entities": []}, {"text": "We came up with a list of 8 generic domains that correspond to these topics, as shown in", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Results for subtask A (rank: #5/8).", "labels": [], "entities": []}, {"text": " Table 4: Results for subtask B (rank: #4/4).", "labels": [], "entities": []}, {"text": " Table 5: Results for subtask C (rank: #1/2).", "labels": [], "entities": []}, {"text": " Table 6: Results for subtask D (rank: #2/3).", "labels": [], "entities": []}, {"text": " Table 7: Results for subtask E (rank: #1/2).", "labels": [], "entities": []}]}