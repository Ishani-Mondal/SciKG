{"title": [{"text": "SINAI at SemEval-2017 Task 4: User based classification", "labels": [], "entities": [{"text": "User based classification", "start_pos": 30, "end_pos": 55, "type": "TASK", "confidence": 0.6504612763722738}]}], "abstractContent": [{"text": "This document describes our participation in SemEval-2017 Task 4: Sentiment Analysis in Twitter.", "labels": [], "entities": [{"text": "SemEval-2017 Task 4", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.8836414217948914}, {"text": "Sentiment Analysis", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.9149709641933441}]}, {"text": "We have only reported results for subtask B-English, determining the polarity towards a topic on a two point scale (positive or negative sentiment).", "labels": [], "entities": []}, {"text": "Our main contribution is the integration of user information in the classification process.", "labels": [], "entities": [{"text": "classification process", "start_pos": 68, "end_pos": 90, "type": "TASK", "confidence": 0.9000980854034424}]}, {"text": "A SVM model is trained with Word2Vec vectors from user's tweets extracted from his timeline.", "labels": [], "entities": []}, {"text": "The obtained results show that user-specific classifiers trained on tweets from user timeline can introduce noise as they are error prone because they are classified by an imperfect system.", "labels": [], "entities": []}, {"text": "This encourages us to explore further integration of user information for author-based Sentiment Analysis.", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 87, "end_pos": 105, "type": "TASK", "confidence": 0.8694336414337158}]}], "introductionContent": [{"text": "Task 4 of SemEval 2017, Sentiment Analysis in Twitter (, has included some new subtasks this year.", "labels": [], "entities": [{"text": "Sentiment Analysis in Twitter", "start_pos": 24, "end_pos": 53, "type": "TASK", "confidence": 0.898220881819725}]}, {"text": "One of these subtasks considers user information to be also integrated in proposed systems.", "labels": [], "entities": []}, {"text": "We have participated in subtask B consisting of, given a message and a topic, classify the message on a two-point scale (positive or negative sentiment towards that topic).", "labels": [], "entities": []}, {"text": "Actually, organizers provide scripts to download user profile information such as age, location, followers...", "labels": [], "entities": []}, {"text": "We have taken advantage of this information to expand a SVM model trained with Word2Vec vectors from user publications on this social media.", "labels": [], "entities": []}, {"text": "In this paper, we present our approach to classify tweets in a two point scale (positive and negative) by combining Support Vector Machine (SVM),) and user information.", "labels": [], "entities": []}, {"text": "We have decided to combine these technologies for several reasons.", "labels": [], "entities": []}, {"text": "Firstly, we have applied SVM many different tasks including tweet polarity classification with good results).", "labels": [], "entities": [{"text": "SVM", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.8386968374252319}, {"text": "tweet polarity classification", "start_pos": 60, "end_pos": 89, "type": "TASK", "confidence": 0.8506356279055277}]}, {"text": "Secondly, after a revision of the systems presented in the last year for the same task (, it seems that better results are achieved by using word embeddings representations, so we have decided to test how it works on user modeling.", "labels": [], "entities": []}, {"text": "Finally, this year for the first time, organizers include user information.", "labels": [], "entities": []}, {"text": "We consider that it is very interesting to integrate this contextual information to improve tweets sentiment classification.", "labels": [], "entities": [{"text": "tweets sentiment classification", "start_pos": 92, "end_pos": 123, "type": "TASK", "confidence": 0.8269986311594645}]}, {"text": "Actually, polarity classification on a per-user basis has been found to be useful in tasks like collaborative filtering.", "labels": [], "entities": [{"text": "polarity classification", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.7608323693275452}, {"text": "collaborative filtering", "start_pos": 96, "end_pos": 119, "type": "TASK", "confidence": 0.7163352519273758}]}, {"text": "Besides, the generation of user profiles in Twitter has attracted the attention of many researches in recent years, enabling the prediction of user behavior as in election processes ().", "labels": [], "entities": []}, {"text": "In Section 2 we explain the data used in our approach.", "labels": [], "entities": []}, {"text": "Section 3 presents the system description.", "labels": [], "entities": []}, {"text": "Experiments and results are expounded in Section 4 and they are analyzed in Section 5.", "labels": [], "entities": []}, {"text": "Finally, in Section 6, conclusions and future work are commented.", "labels": [], "entities": []}], "datasetContent": [{"text": "Three different experiments were conducted over the development set as follows (): \u2022 Experiment 1: a general SVM model on Word2Vec representations of training tweets was generated.", "labels": [], "entities": []}, {"text": "Each tweet of the development set was vectorized using Word2Vec and classified with the model obtained previously.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 55, "end_pos": 63, "type": "DATASET", "confidence": 0.9827237129211426}]}, {"text": "\u2022 Experiment 2: each tweet vector was expanded with a user vector.", "labels": [], "entities": []}, {"text": "A general SVM model was also generated, but on both the Word2Vec representation of the training tweets and user timeline.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 56, "end_pos": 64, "type": "DATASET", "confidence": 0.9647367596626282}]}, {"text": "For every user in the training tweets, the last 200 tweets from his timeline were downloaded.", "labels": [], "entities": []}, {"text": "These tweets were used to enrich the vector of each individual tweet.", "labels": [], "entities": []}, {"text": "Each tweet of the development set along with user timeline who posted it were vectorized using Word2Vec and the tweet was classified with the model.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 95, "end_pos": 103, "type": "DATASET", "confidence": 0.9750257730484009}]}, {"text": "\u2022 Experiment 3: the general SVM model of experiment 1 was used but one model per user was also defined.", "labels": [], "entities": []}, {"text": "In order to define the user model, the last 200 tweets published by the user were retrieved and each of them was vectorized and classified using the general SVM model.", "labels": [], "entities": []}, {"text": "Each tweet of the development set was vectorized using Word2Vec and classified according to the following approach: if the model corresponding to the user contains positive and negative tweets and the leaveone-out cross-validation reports an accuracy over 0.7%, the tweet is classified with the user model; if not, it is classified with the general SVM model.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 55, "end_pos": 63, "type": "DATASET", "confidence": 0.9774560332298279}, {"text": "accuracy", "start_pos": 242, "end_pos": 250, "type": "METRIC", "confidence": 0.9911652207374573}]}, {"text": "The results obtained in the development phase are shown in.", "labels": [], "entities": []}, {"text": "Although experiment 1 was the one that provided the best results, for our participation in the task, we selected the approach developed in experiment 3 because it takes into account user information, one of the challenges of this year.", "labels": [], "entities": []}, {"text": "Experiment 2 also considers user information and got better results than experiment: Results for SemEval-2017 Task 4, subtask B -English.", "labels": [], "entities": [{"text": "SemEval-2017 Task 4", "start_pos": 97, "end_pos": 116, "type": "TASK", "confidence": 0.8091349403063456}]}, {"text": "3 in the development phase, but we did not select it because we considered that the fact of adding tweets without more sense was not a good idea.", "labels": [], "entities": []}, {"text": "Experiment 3 makes more sense, since it defines a personal model for each user based on the way he thinks.", "labels": [], "entities": []}, {"text": "The results for all participants in the test phase can be seen in and the detailed report of the results for all participants can be found at).", "labels": [], "entities": []}, {"text": "Once the gold standard corresponding to the test phase was released, we also conducted other experiments that we defined in the development phase.", "labels": [], "entities": []}, {"text": "The results related to the test set in all the experiments are shown in.", "labels": [], "entities": []}, {"text": "Following, in the next section, an in-depth analysis of the results obtained is performed.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of tweets provided for experi- mentation and testing.", "labels": [], "entities": []}, {"text": " Table 2: Results for the development phase.", "labels": [], "entities": []}, {"text": " Table 3: Results for SemEval-2017 Task 4, subtask B -English.", "labels": [], "entities": [{"text": "SemEval-2017 Task 4", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.862586259841919}]}, {"text": " Table 4. Following, in  the next section, an in-depth analysis of the results  obtained is performed.", "labels": [], "entities": []}, {"text": " Table 4: Results for the test phase.", "labels": [], "entities": []}]}