{"title": [{"text": "NILC-USP at SemEval-2017 Task 4: A Multi-view Ensemble for Twitter Sentiment Analysis", "labels": [], "entities": [{"text": "NILC-USP at SemEval-2017 Task 4", "start_pos": 0, "end_pos": 31, "type": "DATASET", "confidence": 0.701952588558197}, {"text": "Twitter Sentiment Analysis", "start_pos": 59, "end_pos": 85, "type": "TASK", "confidence": 0.6476826270421346}]}], "abstractContent": [{"text": "This paper describes our multi-view ensemble approach to SemEval-2017 Task 4 on Sentiment Analysis in Twitter, specifically , the Message Polarity Classification subtask for English (subtask A).", "labels": [], "entities": [{"text": "SemEval-2017 Task 4 on Sentiment Analysis", "start_pos": 57, "end_pos": 98, "type": "TASK", "confidence": 0.7528644154469172}]}, {"text": "Our system is a voting ensemble, where each base classifier is trained in a different feature space.", "labels": [], "entities": []}, {"text": "The first space is a bag-of-words model and has a Linear SVM as base clas-sifier.", "labels": [], "entities": []}, {"text": "The second and third spaces are two different strategies of combining word em-beddings to represent sentences and use a Linear SVM and a Logistic Regressor as base classifiers.", "labels": [], "entities": []}, {"text": "The proposed system was ranked 18th out of 38 systems considering F1 score and 20th considering recall.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9809365570545197}, {"text": "recall", "start_pos": 96, "end_pos": 102, "type": "METRIC", "confidence": 0.9979763627052307}]}], "introductionContent": [{"text": "Twitter is a microblogging service that has 313 million monthly active users . In this social media platform, users interact through short messages, so-called tweets.", "labels": [], "entities": []}, {"text": "The company estimates that over 500 million tweets are sent each day 2 . Despite of their size, at most 140 characters, these messages provide rich data because users generally write about their thoughts, opinions and sentiments.", "labels": [], "entities": []}, {"text": "Therefore, applications in several domains, such as commercial () and political (, may benefit from the automatic classification of sentiment in tweets.", "labels": [], "entities": [{"text": "classification of sentiment in tweets", "start_pos": 114, "end_pos": 151, "type": "TASK", "confidence": 0.804877233505249}]}, {"text": "In this paper we show that a multi-view ensemble approach that leverages simple representations of texts may achieve good results in the task of message polarity classification.", "labels": [], "entities": [{"text": "message polarity classification", "start_pos": 145, "end_pos": 176, "type": "TASK", "confidence": 0.8532252709070841}]}, {"text": "The proposed system consists of three base classifiers, each of them 1 https://about.twitter.com/company 2 https://business.twitter.com/en/basics.html with a specific text representation technique (bagof-words or word embeddings combination).", "labels": [], "entities": []}, {"text": "As base classifiers, we use Support Vector Machines (SVM) and Logistic Regression.", "labels": [], "entities": []}, {"text": "The proposed approach was evaluated on the SemEval-2017 Task 4 Subtask A for English and was ranked 18th out of 38 participating systems considering F1 score and 20th considering recall.", "labels": [], "entities": [{"text": "SemEval-2017 Task 4 Subtask A", "start_pos": 43, "end_pos": 72, "type": "DATASET", "confidence": 0.6093626081943512}, {"text": "F1 score", "start_pos": 149, "end_pos": 157, "type": "METRIC", "confidence": 0.9867282211780548}, {"text": "recall", "start_pos": 179, "end_pos": 185, "type": "METRIC", "confidence": 0.9979683756828308}]}, {"text": "This paper is organized as follows: Section 2 describes our system, the feature spaces and the classifiers we employed.", "labels": [], "entities": []}, {"text": "The training and evaluation datasets are presented in Section 3.", "labels": [], "entities": []}, {"text": "In addition, Section 3 also describes the preprocessing steps and some details about the word embeddings.", "labels": [], "entities": []}, {"text": "We present our results in Section 4.", "labels": [], "entities": []}, {"text": "Finally, Section 5 outlines our conclusions and remarks on future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the Twitter2016-test evaluation, only Twitter2016-train and Twitter2016-dev were used in training.", "labels": [], "entities": [{"text": "Twitter2016-train", "start_pos": 41, "end_pos": 58, "type": "DATASET", "confidence": 0.9444658756256104}]}, {"text": "In the rest of the evaluations, Twitter2016-train, Twitter2016-dev, Twitter2016-test were used.", "labels": [], "entities": [{"text": "Twitter2016-train", "start_pos": 32, "end_pos": 49, "type": "DATASET", "confidence": 0.9533148407936096}, {"text": "Twitter2016-dev", "start_pos": 51, "end_pos": 66, "type": "DATASET", "confidence": 0.9308957457542419}, {"text": "Twitter2016-test", "start_pos": 68, "end_pos": 84, "type": "DATASET", "confidence": 0.9233579039573669}]}, {"text": "Despite of the availability of other datasets for training, we chose to use only the three.", "labels": [], "entities": []}, {"text": "The results obtained by our system are summarized in.", "labels": [], "entities": []}, {"text": "From the results it is possible to notice that the system is impaired in datasets of different origin, such as SMS2013, this may occur due to the use of a distinct and specific vocabulary.", "labels": [], "entities": [{"text": "SMS2013", "start_pos": 111, "end_pos": 118, "type": "DATASET", "confidence": 0.9464004635810852}]}, {"text": "In the case of Tw2014-sarcasm, the major problem is that our representations do not consider the order of words in the sentence which can make it difficult to identify sarcasm or modifiers.", "labels": [], "entities": []}, {"text": "In the LiveJournal2014 dataset the system remained stable even though it is a dataset of another domain, probably because it is similar to the Twitter datasets.", "labels": [], "entities": [{"text": "LiveJournal2014 dataset", "start_pos": 7, "end_pos": 30, "type": "DATASET", "confidence": 0.9742430150508881}, {"text": "Twitter datasets", "start_pos": 143, "end_pos": 159, "type": "DATASET", "confidence": 0.8465457856655121}]}], "tableCaptions": [{"text": " Table 1: Datasets used in the training and evalua- tion of the system.", "labels": [], "entities": []}, {"text": " Table 2: Results obtained by our systems in dif- ferent evaluation datasets.", "labels": [], "entities": []}]}