{"title": [{"text": "SSN MLRG1 at SemEval-2017 Task 4: Sentiment Analysis in Twitter Using Multi-Kernel Gaussian Process Classifier", "labels": [], "entities": [{"text": "SemEval-2017 Task 4", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.7465493679046631}, {"text": "Sentiment Analysis", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.9675155282020569}]}], "abstractContent": [{"text": "The SSN MLRG1 team for Semeval-2017 task 4 has applied Gaussian Process, with bag of words feature vectors and fixed rule multi-kernel learning, for sentiment analysis of tweets.", "labels": [], "entities": [{"text": "Semeval-2017 task 4", "start_pos": 23, "end_pos": 42, "type": "TASK", "confidence": 0.6449044942855835}, {"text": "sentiment analysis of tweets", "start_pos": 149, "end_pos": 177, "type": "TASK", "confidence": 0.9293897598981857}]}, {"text": "Since tweets on the same topic, made at different times, may exhibit different emotions, their properties such as smoothness and periodicity also vary with time.", "labels": [], "entities": []}, {"text": "Our experiments show that, compared to single kernel, multiple kernels are effective in learning the simultaneous presence of multiple properties.", "labels": [], "entities": []}], "introductionContent": [{"text": "Twitter is a huge microblogging service with more than 500 million tweets per day from different locations of the world and in different languages.", "labels": [], "entities": []}, {"text": "The sentiment analysis in Twitter has been applied in various domains such as commerce, disaster management) and health.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.8776565790176392}, {"text": "disaster management", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.7478785216808319}]}, {"text": "The task is challenging because of the informal writing style, the semantic diversity of content as well as the \"unconventional\" grammar.", "labels": [], "entities": []}, {"text": "These challenges in building a classification model can be handled by using proper approaches to feature generation and machine learning.", "labels": [], "entities": [{"text": "feature generation", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.7400162220001221}]}, {"text": "The heart of every Gaussian process model is a covariance kernel.", "labels": [], "entities": []}, {"text": "Multi Kernel Learning (MKL)-using multiple kernels instead of a single one-can be useful in two ways: \u2022 Different kernels correspond to different notions of similarity, and instead of trying to find which works best, a learning method does the picking for us, or may use a combination of them.", "labels": [], "entities": [{"text": "Multi Kernel Learning (MKL)-", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7291863958040873}]}, {"text": "Using a specific kernel maybe a source of bias which is avoided by allowing the learner to choose from among a set of kernels.", "labels": [], "entities": []}, {"text": "\u2022 Different kernels may use inputs coming from different representations, possibly from different sources or modalities.", "labels": [], "entities": []}, {"text": "( and) explain how multiple kernels definitely give a powerful performance.", "labels": [], "entities": []}, {"text": "(Gonen and Alpaydn, 2011) also describe in detail various methodologies to combine kernels.) introduces simple closed form kernels that can be used with Gaussian Processes to discover patterns and enable extrapolation.", "labels": [], "entities": []}, {"text": "The kernels support abroad class of stationary covariances, but Gaussian Process inference remains simple and analytic.", "labels": [], "entities": []}, {"text": "We studied the possibility of using multiple kernels to explain the relation between the input data and the labels.", "labels": [], "entities": []}, {"text": "While there is a body of work on using Multi Kernel Learning (MKL) on numerical data and images, yet applying MKL on text is still an exploration.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our system scored a macro-averaged recall of 0.431 and was ranked 35 for subtask A, macroaveraged recall of 0.586 and was ranked 20 for subtask B, and macro-averaged mean absolute error of 1.325 and was ranked 15 for subtask C.", "labels": [], "entities": [{"text": "recall", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9808980822563171}, {"text": "recall", "start_pos": 98, "end_pos": 104, "type": "METRIC", "confidence": 0.941276490688324}, {"text": "macro-averaged mean absolute error", "start_pos": 151, "end_pos": 185, "type": "METRIC", "confidence": 0.5966941118240356}]}], "tableCaptions": [{"text": " Table 1. The evaluation  was done on SemEval-2017 labeled test dataset.  Only 1000 tweets were used to train the model due  to the time-complexity of GP and hardware limita- tions, and from among the remaining 9551 tweets  test set was taken.", "labels": [], "entities": [{"text": "SemEval-2017 labeled test dataset", "start_pos": 38, "end_pos": 71, "type": "DATASET", "confidence": 0.9285144209861755}]}, {"text": " Table 1: A Performance Evaluation based on  Recall, F-measure and Precision (all macro- averaged) for subtask B", "labels": [], "entities": [{"text": "Recall", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.9973258972167969}, {"text": "F-measure", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9886906147003174}, {"text": "Precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9979991316795349}]}]}