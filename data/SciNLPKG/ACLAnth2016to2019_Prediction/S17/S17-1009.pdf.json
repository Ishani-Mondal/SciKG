{"title": [{"text": "Mapping the Paraphrase Database to WordNet", "labels": [], "entities": [{"text": "WordNet", "start_pos": 35, "end_pos": 42, "type": "DATASET", "confidence": 0.8204108476638794}]}], "abstractContent": [{"text": "WordNet has facilitated important research in natural language processing but its usefulness is somewhat limited by its relatively small lexical coverage.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9215113520622253}, {"text": "natural language processing", "start_pos": 46, "end_pos": 73, "type": "TASK", "confidence": 0.6693253318468729}]}, {"text": "The Paraphrase Database (PPDB) covers 650 times more words, but lacks the semantic structure of WordNet that would make it more directly useful for downstream tasks.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 96, "end_pos": 103, "type": "DATASET", "confidence": 0.9446777701377869}]}, {"text": "We present a method for mapping words from PPDB to WordNet synsets with 89% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9982535243034363}]}, {"text": "The mapping also lays important groundwork for incorporating Word-Net's relations into PPDB so as to increase its utility for semantic reasoning in applications .", "labels": [], "entities": []}], "introductionContent": [{"text": "WordNet) is one of the most important resources for natural language processing research.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9227808713912964}, {"text": "natural language processing research", "start_pos": 52, "end_pos": 88, "type": "TASK", "confidence": 0.7192646116018295}]}, {"text": "Despite its utility, WordNet 1 is manually compiled and therefore relatively small.", "labels": [], "entities": [{"text": "WordNet 1", "start_pos": 21, "end_pos": 30, "type": "DATASET", "confidence": 0.9035500288009644}]}, {"text": "It contains roughly 155k words, which does not approach web scale, and very few informal or colloquial words, domain-specific terms, new word uses, or named entities.", "labels": [], "entities": []}, {"text": "Researchers have compiled several larger, automatically-generated thesaurus-like resources (.", "labels": [], "entities": []}, {"text": "One of these is the Paraphrase Database (PPDB) ().", "labels": [], "entities": [{"text": "Paraphrase Database (PPDB)", "start_pos": 20, "end_pos": 46, "type": "DATASET", "confidence": 0.7028957962989807}]}, {"text": "With over 100 million paraphrase pairs, PPDB dwarfs WordNet in size but it lacks WordNet's semantic structure.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 52, "end_pos": 59, "type": "DATASET", "confidence": 0.9494002461433411}]}, {"text": "Paraphrases fora given word are indistinguishable by sense, and PPDB's only inherent semantic relational information is predicted entailment relations between word types).", "labels": [], "entities": []}, {"text": "Several earlier studies attempted to incorporate se- In this work we refer specifically to WordNet version 3.0 RULE-PRESCRIPT: imperative*, demand*, duty*, request, gun, decree, ranking RULE-REGULATION: constraint*, limit*, derogation*, notion RULE-FORMULA: method*, standard*, plan*, proceeding RULE-LINGUISTIC RULE: notion: Example of our model's top-ranked paraphrases for three WordNet synsets for rule (n).", "labels": [], "entities": []}, {"text": "Starred paraphrases have a predicted likelihood of attachment of at least 95%; others have predicted likelihood of at least 50%.", "labels": [], "entities": []}, {"text": "Bold text indicates paraphrases that match the correct sense of rule.", "labels": [], "entities": []}, {"text": "mantic awareness into PPDB, either by clustering its paraphrases byword sense) or choosing appropriate PPDB paraphrases fora given context.", "labels": [], "entities": []}, {"text": "In this work, we aim to marry the rich semantic knowledge in WordNet with the massive scale of PPDB by predicting WordNet synset membership for PPDB paraphrases that do not appear in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 61, "end_pos": 68, "type": "DATASET", "confidence": 0.9619873762130737}, {"text": "WordNet", "start_pos": 183, "end_pos": 190, "type": "DATASET", "confidence": 0.9494467377662659}]}, {"text": "Our goal is to increase the lexical coverage of WordNet and incorporate some of the rich relational information from WordNet into PPDB.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 48, "end_pos": 55, "type": "DATASET", "confidence": 0.966831624507904}, {"text": "WordNet", "start_pos": 117, "end_pos": 124, "type": "DATASET", "confidence": 0.9429835081100464}, {"text": "PPDB", "start_pos": 130, "end_pos": 134, "type": "DATASET", "confidence": 0.779462456703186}]}, {"text": "Table 1 shows our model's top-ranked outputs mapping PPDB paraphrases for the word rule onto their corresponding WordNet synsets.", "labels": [], "entities": []}, {"text": "Our overall objective in this work is to map PPDB paraphrases fora target word to the WordNet synsets of the target.", "labels": [], "entities": []}, {"text": "This work has two parts.", "labels": [], "entities": []}, {"text": "In the first part (Section 4), we train and evaluate a binary lemma-synset membership classifier.", "labels": [], "entities": []}, {"text": "The training and evaluation data comes from lemma-synset pairs with known class (member/non-member) from WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 105, "end_pos": 112, "type": "DATASET", "confidence": 0.9761559367179871}]}, {"text": "In the second part (Section 5), we predict membership for lemma-synset pairs where the lemma appears in PPDB, but not in WordNet, using the model trained in part one.", "labels": [], "entities": [{"text": "PPDB", "start_pos": 104, "end_pos": 108, "type": "DATASET", "confidence": 0.9072518944740295}, {"text": "WordNet", "start_pos": 121, "end_pos": 128, "type": "DATASET", "confidence": 0.9602325558662415}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Precision, recall, F1, and accuracy results over the training set (normal 10-fold Cross-Validation,  and lexical split 20-fold Cross-Validation-LexSplit) and test set for predicting paraphrase-synset attach- ment.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.999250590801239}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9993327260017395}, {"text": "F1", "start_pos": 29, "end_pos": 31, "type": "METRIC", "confidence": 0.9996976852416992}, {"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9996802806854248}, {"text": "predicting paraphrase-synset attach- ment", "start_pos": 181, "end_pos": 222, "type": "TASK", "confidence": 0.7736852288246154}]}, {"text": " Table 3: Absolute decrease in mean cross- validation F1 with different feature types ablated.  Higher numbers indicate greater feature impor- tance.", "labels": [], "entities": [{"text": "Absolute", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9904727339744568}, {"text": "F1", "start_pos": 54, "end_pos": 56, "type": "METRIC", "confidence": 0.6564898490905762}, {"text": "feature impor- tance", "start_pos": 128, "end_pos": 148, "type": "METRIC", "confidence": 0.841305211186409}]}]}