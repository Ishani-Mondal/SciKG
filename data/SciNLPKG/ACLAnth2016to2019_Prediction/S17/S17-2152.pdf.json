{"title": [{"text": "ECNU at SemEval-2017 Task 5: An Ensemble of Regression Algorithms with Effective Features for Fine-Grained Sentiment Analysis in Financial Domain", "labels": [], "entities": [{"text": "ECNU at SemEval-2017 Task 5", "start_pos": 0, "end_pos": 27, "type": "DATASET", "confidence": 0.794540810585022}, {"text": "Sentiment Analysis", "start_pos": 107, "end_pos": 125, "type": "TASK", "confidence": 0.8744985163211823}]}], "abstractContent": [{"text": "This paper describes our systems submitted to the Fine-Grained Sentiment Analysis on Financial Microblogs and News task (i.e., Task 5) in SemEval-2017.", "labels": [], "entities": []}, {"text": "This task includes two subtasks in microblogs and news headline domain respectively.", "labels": [], "entities": []}, {"text": "To settle this problem, we extract four types of effective features, including linguistic features, sentiment lexicon features, domain-specific features and word embedding features.", "labels": [], "entities": []}, {"text": "Then we employ these features to construct models by using ensemble regression algorithms.", "labels": [], "entities": []}, {"text": "Our submissions rank 1st and rank 5th in subtask 1 and subtask 2 respectively.", "labels": [], "entities": []}], "introductionContent": [{"text": "SemEval-2017 Task 5 is Fine-Grained Sentiment Analysis on Financial Microblogs and News(, focusing on identifying positive (bullish; believing that the stock price will increase) and negative (bearish; believing that the stock price will decline) sentiment associated with stocks and companies from microblogs and news domains.", "labels": [], "entities": []}, {"text": "Unlike previous sentiment analysis, in this task, the fine-grained sentiment analysis not only contains sentiment orientation (i.e., positive or negative of the sentiment score) but also sentiment strength (i.e., the value of the sentiment score) attached to a particular company or stock explicitly or implicitly expressed in given texts.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.9115775227546692}]}, {"text": "Given a text instance (a microblog message from Twitter or StockTwits in subtask 1, a news statement or a headline in subtask 2), the goal of participants is to predict the sentiment score for each of the stocks and companies mentioned.", "labels": [], "entities": []}, {"text": "The sentiment score is a floating value in the range of -1 (very negative) to 1 (very positive), with 0 designating neutral sentiment.", "labels": [], "entities": []}, {"text": "Each microblog instance contains the following 5 items: \"id\", \"source\" (i.e., Twitter or StockTwits), \"cashtag\" (i.e., the company stock symbols to be predicted, e.g. \"$AAPL\"), \"spans\" and \"sentiment score\".", "labels": [], "entities": [{"text": "AAPL", "start_pos": 169, "end_pos": 173, "type": "METRIC", "confidence": 0.9383054375648499}, {"text": "sentiment score", "start_pos": 190, "end_pos": 205, "type": "METRIC", "confidence": 0.8705001771450043}]}, {"text": "And each news headline instance contains 4 items: \"id\", \"company\" (i.e., the company to be predicted), \"title\" and \"sentiment score\".", "labels": [], "entities": [{"text": "title", "start_pos": 104, "end_pos": 109, "type": "METRIC", "confidence": 0.9370966553688049}, {"text": "sentiment score", "start_pos": 116, "end_pos": 131, "type": "METRIC", "confidence": 0.8119010329246521}]}, {"text": "There are several differences between the spans in subtask 1 and the title in subtask 2: (1) The spans are sentence fragments related to the cashtag to be predicted, whereas the title is a complete sentence; (2) The spans almost regard one cashtag while the title usually contains one or more companies; (3) Due to (1) and (2), the spans contain less words but more effective information and less noises, which is contrary to the title.", "labels": [], "entities": []}, {"text": "In this work, the similar method is adopted for two subtasks.", "labels": [], "entities": []}, {"text": "We extract a series of elaborately designed features.", "labels": [], "entities": []}, {"text": "In addition to linguistic features, sentiment lexicon features and word embedding features, we also extract some domainspecific features for this task.", "labels": [], "entities": []}, {"text": "Besides, we examine multiple different regression algorithms and ensemble methods are used to improve the performance of our models.", "labels": [], "entities": []}, {"text": "The rest of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes our system in details, including data preprocessing, feature engineering, learning algorithms and evaluation measure.", "labels": [], "entities": []}, {"text": "Section 3 reports datasets, experiments and results discussion.", "labels": [], "entities": []}, {"text": "Finally, Section 4 concludes our work.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the performance of different systems, the official evaluation measure weighted cosine similarity (WCS) is adopted for two subtasks.", "labels": [], "entities": [{"text": "evaluation measure weighted cosine similarity (WCS)", "start_pos": 63, "end_pos": 114, "type": "METRIC", "confidence": 0.7350742146372795}]}, {"text": "Cosine similarity and cosine weight will be calculated according the equation 1 and 2 respectively, where G is the vector of gold standard scores and P is the vector of scores predicted by the system.", "labels": [], "entities": [{"text": "cosine weight", "start_pos": 22, "end_pos": 35, "type": "METRIC", "confidence": 0.7778280675411224}]}, {"text": "The final score is the product of the cosine and the weight (i.e., W CS = cosine weight * cosine(G, P )).", "labels": [], "entities": []}, {"text": "3 Experiment  We conduct the experiments on the official datasets constructed by SSIX project (, which consist of microblog messages (from Twitter or StockTwits) in subtask 1 and news headlines in subtask 2.: Results of algorithm selection experiments for two subtasks in terms of WCS on training datasets.", "labels": [], "entities": []}, {"text": "From, we find that for both subtasks, SVR outperforms other algorithms and LASSO performs the worst among all algorithms.", "labels": [], "entities": [{"text": "LASSO", "start_pos": 75, "end_pos": 80, "type": "METRIC", "confidence": 0.9629022479057312}]}, {"text": "Other algorithms perform differently on two subtasks.", "labels": [], "entities": []}, {"text": "Therefore, we also perform experiments using an ensemble method.", "labels": [], "entities": []}, {"text": "The last two rows in list the results of using the top two and top four algorithms to build the ensemble regression models (named EN(2) and EN), which average the output scores of all regression algorithm.", "labels": [], "entities": []}, {"text": "From, we find that the ensemble classifier greatly increased the performance on both subtasks.", "labels": [], "entities": []}, {"text": "Specifically, for subtask 1, the ensemble with top 4 algorithms improve 4% and for subtask 2, ensemble with top 2 improved 2% compared with the top score using a single regression algorithm.", "labels": [], "entities": []}, {"text": "Therefore, we chose the EN(4) for subtask 1 and EN for subtask 2 as the regression algorithm in following experiments.", "labels": [], "entities": [{"text": "EN", "start_pos": 24, "end_pos": 26, "type": "METRIC", "confidence": 0.9268343448638916}]}, {"text": "shows the best feature sets for two subtasks.", "labels": [], "entities": []}, {"text": "Based on previous ensemble algorithms, we adopt hill climbing algorithm to select best features.", "labels": [], "entities": []}, {"text": "That is, keep adding one type of feature at a time until no further improvement can be achieved.", "labels": [], "entities": []}, {"text": "From, we find that: (1) The RF N-grams, Verb, Word Cluster, SentiLexi, Number, Punctuation and GoogleW2V features are beneficial for both subtasks; (2) Specially, the NER features and Keyword+Number features are more effective in subtask 1 than subtask 2.", "labels": [], "entities": [{"text": "GoogleW2V", "start_pos": 95, "end_pos": 104, "type": "DATASET", "confidence": 0.8631784319877625}]}], "tableCaptions": [{"text": " Table 1: Statistics of training and test datasets of  two subtasks. Positive, Negative and Neural stand  for the number of corresponding instances whose  sentiment score is positive, negative and zero.", "labels": [], "entities": []}, {"text": " Table 2: Results of algorithm selection experi- ments for two subtasks in terms of WCS on train- ing datasets.", "labels": [], "entities": []}, {"text": " Table 5: Performance of our systems and the top- ranked systems for two subtasks in terms of WCS  on test datasets.", "labels": [], "entities": []}]}