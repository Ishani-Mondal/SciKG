{"title": [{"text": "GW QA at SemEval-2017 Task 3: Question Answer Re-ranking on Arabic Fora", "labels": [], "entities": [{"text": "GW QA", "start_pos": 0, "end_pos": 5, "type": "TASK", "confidence": 0.5664689540863037}, {"text": "SemEval-2017 Task", "start_pos": 9, "end_pos": 26, "type": "TASK", "confidence": 0.5055447071790695}, {"text": "Question Answer Re-ranking", "start_pos": 30, "end_pos": 56, "type": "TASK", "confidence": 0.7160295943419138}, {"text": "Arabic Fora", "start_pos": 60, "end_pos": 71, "type": "DATASET", "confidence": 0.8586028814315796}]}], "abstractContent": [{"text": "This paper describes our submission to SemEval-2017 Task 3 Subtask D, \"Ques-tion Answer Ranking in Arabic Community Question Answering\".", "labels": [], "entities": [{"text": "SemEval-2017 Task 3 Subtask D", "start_pos": 39, "end_pos": 68, "type": "TASK", "confidence": 0.6774401187896728}, {"text": "Ques-tion Answer Ranking in Arabic Community Question Answering", "start_pos": 71, "end_pos": 134, "type": "TASK", "confidence": 0.5492954850196838}]}, {"text": "In this work, we applied a supervised machine learning approach to automatically re-rank a set of QA pairs according to their relevance to a given question.", "labels": [], "entities": []}, {"text": "We employ features based on latent semantic models, namely WTMF, as well as a set of lexical features based on string length and surface level matching.", "labels": [], "entities": [{"text": "WTMF", "start_pos": 59, "end_pos": 63, "type": "DATASET", "confidence": 0.8473740220069885}]}, {"text": "The proposed system ranked first out of 3 submissions, with a MAP score of 61.16%.", "labels": [], "entities": [{"text": "MAP score", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9797698259353638}]}], "introductionContent": [{"text": "Nowadays Community Question Answering (CQA) websites provide a virtual place for users to share and exchange knowledge about different topics.", "labels": [], "entities": [{"text": "Community Question Answering (CQA)", "start_pos": 9, "end_pos": 43, "type": "TASK", "confidence": 0.7588722358147303}]}, {"text": "In most cases, users freely express their concerns and hope for some reliable answers from specialists or other users.", "labels": [], "entities": []}, {"text": "In addition, they can search for an answer from previously posted question-answers (QA) that are similar to their question.", "labels": [], "entities": []}, {"text": "Although posting a question and looking fora director related answer in CQA sounds appealing, the number of unanswered questions are relatively high.", "labels": [], "entities": [{"text": "CQA", "start_pos": 72, "end_pos": 75, "type": "DATASET", "confidence": 0.9641733765602112}]}, {"text": "According to the number of unanswered questions in Stack Overflow and Yahoo!", "labels": [], "entities": []}, {"text": "Answers 2 are approximately 10.9% and 15%, respectively.", "labels": [], "entities": []}, {"text": "Interestingly, as noted in, the high percentage of unanswered questions is due to the duplicate question problem, i.e. the existence of a similar question that had been addressed before, which A programming CQA forum 2 A community-driven question-and-answer site makes users not re-address the question again.", "labels": [], "entities": []}, {"text": "Hence, it is the asker's role to review the site looking for an answer before posting anew question.", "labels": [], "entities": []}, {"text": "This is a task that requires searching related questions from a hundred others posted on a daily basis.", "labels": [], "entities": []}, {"text": "Thus, in a good forum there should bean automatic search functionality to retrieve the set of QA that are more likely to be related to the new question being asked.", "labels": [], "entities": []}, {"text": "As a result, the number of duplications and unanswered questions will be limited.", "labels": [], "entities": []}, {"text": "In order to find a solution to this and other problems in CQA, the have been dedicated to dealing with \"Answer Selection in Community Question Answering\".", "labels": [], "entities": [{"text": "Answer Selection in Community Question Answering", "start_pos": 104, "end_pos": 152, "type": "TASK", "confidence": 0.82123530904452}]}, {"text": "There are 5 different subtasks, one of which has been proposed for Arabic.", "labels": [], "entities": []}, {"text": "The specific task for Arabic in the, subtask D, was to re-rank the possible related question-answer pairs to a given question.", "labels": [], "entities": []}, {"text": "The Arabic task is especially difficult due to its challenging characteristics.", "labels": [], "entities": []}, {"text": "Arabic is one of the most complex languages to process due to its morphological richness, with relative free word order, and its diglossic nature (where the standard and the dialects mix inmost genres of data).", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows: Section 2 gives an overview of the task and data, Section 3 describes the proposed system, Section 4 presents a discussion of the experiments and results, Section 5 outlines the error analysis, and Section 6 concludes.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our ranking system is a supervised model using SV M rank , a variation of SVM () for ranking.", "labels": [], "entities": []}, {"text": "We tested different types of kernels, and the best result was obtained using a linear kernel, which we used to train our model.", "labels": [], "entities": []}, {"text": "Furthermore, we tuned the cost factor parameter C of the linear kernel on the development set and we obtained the best result with C=3, which we set during the testing of our model.", "labels": [], "entities": []}, {"text": "The outputs of the SV M rank are mainly used for ordering and they do not have any meaning of relatedness.", "labels": [], "entities": []}, {"text": "For binary classification, \"Direct\" and \"Relevant\" are mapped to \"True\" and \"Irrelevant\" is mapped to \"False\" for the classification task.", "labels": [], "entities": [{"text": "binary classification", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.664610743522644}]}, {"text": "We employed a logistic regression (LR) classifier, LI-BLINEAR classifier with the default parameters, implemented using WEKA package).", "labels": [], "entities": [{"text": "WEKA package", "start_pos": 120, "end_pos": 132, "type": "DATASET", "confidence": 0.9421301782131195}]}, {"text": "We report results on the development tuning set, DEV, and TEST set.", "labels": [], "entities": [{"text": "DEV", "start_pos": 49, "end_pos": 52, "type": "METRIC", "confidence": 0.8986622095108032}, {"text": "TEST", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.9900435209274292}]}, {"text": "Furthermore, we report the results of different experimental setups to show the performance over different feature sets.", "labels": [], "entities": []}, {"text": "We report results using lexical features (LEX), using WTMF features (WTMF), and with combined features (WTMF+LEX).", "labels": [], "entities": []}, {"text": "The latter is our primary submission to the SemEval-2017 subtask D.", "labels": [], "entities": [{"text": "SemEval-2017 subtask D", "start_pos": 44, "end_pos": 66, "type": "DATASET", "confidence": 0.7215802669525146}]}, {"text": "It is worth noting that we only officially participated in the ranking task.", "labels": [], "entities": []}, {"text": "In addition, we report the binary classification results, which we did not officially submit.", "labels": [], "entities": []}, {"text": "Furthermore, we compare our results to subtask D baselines and we report the results using the official metrics.", "labels": [], "entities": []}, {"text": "As can be seen in, the combined WTMF+LEX setting outperformed the other settings, WTMF and LEX, individually.", "labels": [], "entities": [{"text": "WTMF+LEX setting", "start_pos": 32, "end_pos": 48, "type": "DATASET", "confidence": 0.6129638403654099}, {"text": "WTMF", "start_pos": 82, "end_pos": 86, "type": "DATASET", "confidence": 0.8321732878684998}, {"text": "LEX", "start_pos": 91, "end_pos": 94, "type": "METRIC", "confidence": 0.9038844108581543}]}, {"text": "This indicates that the combination of LEX features with WTMF provide complementary information about the relatedness at the explicit matching level for the model.", "labels": [], "entities": []}, {"text": "Specifically, the WTMF+LEX based system improved the MAP by about 1% increase from the WTMF and the LEX based system.", "labels": [], "entities": [{"text": "MAP", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.9063147306442261}, {"text": "WTMF", "start_pos": 87, "end_pos": 91, "type": "DATASET", "confidence": 0.9356616139411926}]}, {"text": "Furthermore, we obtain a significant improvement over the baselines for the DEV set and relatively modest improvements in the TEST set, with MAP 45.73 and 61.16, respectively.", "labels": [], "entities": [{"text": "DEV set", "start_pos": 76, "end_pos": 83, "type": "DATASET", "confidence": 0.9532420337200165}, {"text": "TEST set", "start_pos": 126, "end_pos": 134, "type": "DATASET", "confidence": 0.8663298189640045}, {"text": "MAP 45.73", "start_pos": 141, "end_pos": 150, "type": "METRIC", "confidence": 0.9470308721065521}]}], "tableCaptions": [{"text": " Table 1: Statistic of the raw Arabic corpora used  for building the WTMF model", "labels": [], "entities": [{"text": "WTMF", "start_pos": 69, "end_pos": 73, "type": "DATASET", "confidence": 0.7620440721511841}]}, {"text": " Table 2: Ranking Results on the development and test sets using official metrics", "labels": [], "entities": []}, {"text": " Table 3: Binary Classification Results us- ing our LR classifier with combined features  WTMF+LEN on the Test set", "labels": [], "entities": [{"text": "Binary Classification", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.8997877836227417}, {"text": "WTMF+LEN", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.714032252629598}]}]}