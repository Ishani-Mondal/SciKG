{"title": [{"text": "What Analogies Reveal about Word Vectors and their Compositionality", "labels": [], "entities": [{"text": "Compositionality", "start_pos": 51, "end_pos": 67, "type": "TASK", "confidence": 0.5034908056259155}]}], "abstractContent": [{"text": "Analogy completion via vector arithmetic has become a common means of demonstrating the compositionality of word em-beddings.", "labels": [], "entities": [{"text": "Analogy completion", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9155963063240051}]}, {"text": "Previous work have shown that this strategy works more reliably for certain types of analogical word relationships than for others, but these studies have not offered a convincing account for why this is the case.", "labels": [], "entities": []}, {"text": "We arrive at such an account through an experiment that targets a wide variety of analogy questions and defines a baseline condition to more accurately measure the efficacy of our system.", "labels": [], "entities": []}, {"text": "We find that the most reliably solvable analogy categories involve either 1) the application of a morpheme with clear syntactic effects, 2) male-female alternations, or 3) named entities.", "labels": [], "entities": []}, {"text": "These broader types do not pattern cleanly along a syntactic-semantic divide.", "labels": [], "entities": []}, {"text": "We suggest instead that their commonality is distributional, in that the difference between the distributions of two words in any given pair encompasses a relatively small number of word types.", "labels": [], "entities": []}, {"text": "Our study offers a needed explanation for why analogy tests succeed and fail where they do and provides nuanced insight into the relationship between word distributions and the theoretical linguistic domains of syntax and semantics.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, low-dimensional vectors have proven an efficient and fruitful means of representing words for numerous computational applications, from calculating semantic similarity to serv- * This work was done while the first author was a postdoctoral research associate at the University of ing as an early layer in deep learning architectures (.", "labels": [], "entities": []}, {"text": "Despite these advances, however, strategies for representing meaning compositionally with a vector model remain limited.", "labels": [], "entities": []}, {"text": "Given the difficulties in training representations of composed meaning (for example, most possible phrases will be rare or unattested in training data), achieving an accurate means of building complex lexical or phrasal representations from lower-order ones would be a decisive coup in computational semantics.", "labels": [], "entities": []}, {"text": "Another promising avenue of compositional semantics is the representation of concepts that do not map easily to lexemes.", "labels": [], "entities": []}, {"text": "A simple averaging of two vectors may yield a concept that is semantically akin to both, and the arithmetic difference between word vectors has been said to represent the relationship between two terms.", "labels": [], "entities": []}, {"text": "The ability to model knowledge unbounded by linguistic labels is an exciting prospect for natural language processing and artificial intelligence more broadly.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 90, "end_pos": 117, "type": "TASK", "confidence": 0.6852522293726603}]}, {"text": "A common test of the compositional properties of word vectors is complete-the-analogy questions.", "labels": [], "entities": []}, {"text": "Word vector arithmetic has achieved surprisingly high accuracy on this type of task.", "labels": [], "entities": [{"text": "Word vector arithmetic", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.5990925927956899}, {"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9992208480834961}]}, {"text": "A flurry of recent studies have applied this test under various conditions, but there has been limited focus on defining precisely what types of relations vectors can capture, and less still on explaining these differences.", "labels": [], "entities": []}, {"text": "As such, there remains a major gap in our understanding of distributional semantics.", "labels": [], "entities": []}, {"text": "Our original experimental work improves upon prior methods by 1) targeting a wide variety of analogy questions drawn from several available resources and 2) defining a baseline condition to control for differences in \"difficulty\" between questions.", "labels": [], "entities": []}, {"text": "These considerations enable an analysis that constitutes a major step towards a comprehensive, theoretically grounded account for the 1 observed phenomena.", "labels": [], "entities": []}, {"text": "To begin, however, we present a brief review of the analogy problem as usually posed.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Summary of test data sources.", "labels": [], "entities": []}, {"text": " Table 2: Summary of regression model for reciprocal rank gain as a function of analogy supercategory.  All starred levels are highly significant (p .01).", "labels": [], "entities": []}]}