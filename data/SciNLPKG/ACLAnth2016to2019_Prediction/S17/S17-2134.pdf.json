{"title": [{"text": "YNU-HPCC at SemEval 2017 Task 4: Using A Multi-Channel CNN-LSTM Model for Sentiment Classification", "labels": [], "entities": [{"text": "Sentiment Classification", "start_pos": 74, "end_pos": 98, "type": "TASK", "confidence": 0.9597860872745514}]}], "abstractContent": [{"text": "In this paper, we propose a multi-channel convolutional neural network-long short-term memory (CNN-LSTM) model that consists of two parts: multi-channel CNN and LSTM to analyze the sentiments of short English messages from Twitter.", "labels": [], "entities": []}, {"text": "Unlike a conventional CNN, the proposed model applies a multi-channel strategy that uses several filters of different length to extract active local n-gram features in different scales.", "labels": [], "entities": []}, {"text": "This information is then sequentially composed using LSTM.", "labels": [], "entities": []}, {"text": "By combining both CNN and LSTM, we can consider both local information within tweets and long-distance dependency across tweets in the classification process.", "labels": [], "entities": [{"text": "CNN", "start_pos": 18, "end_pos": 21, "type": "DATASET", "confidence": 0.9189038276672363}]}, {"text": "Officially released results show that our system outper-forms the baseline algorithm.", "labels": [], "entities": []}], "introductionContent": [{"text": "Social network services (SNSs) such as Twitter, Facebook, and Weibo are used daily to express thoughts, opinions, and emotions.", "labels": [], "entities": []}, {"text": "In Twitter, 6000 short messages (tweets) are posted by users every second . Therefore, Twitter is considered as one of the most concentrated opinion-expressing venues on the Internet.", "labels": [], "entities": []}, {"text": "Subjective analysis of this type of user-generated content has become a vital task for politics, social networking, marketing, and advertising.", "labels": [], "entities": [{"text": "Subjective analysis", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8538838922977448}]}, {"text": "The potential application of sentiment analysis has been the motivation behind the SemEval 2017 Task 4, which is a competition involving a series of subtasks that focus on Twitter sentiment classifications.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.9437205791473389}, {"text": "SemEval 2017 Task 4", "start_pos": 83, "end_pos": 102, "type": "TASK", "confidence": 0.7244611382484436}, {"text": "Twitter sentiment classifications", "start_pos": 172, "end_pos": 205, "type": "TASK", "confidence": 0.66144660115242}]}, {"text": "Subtask A involves message polarity classification, which requires a system to classify 1 http://www.internetlivestats.com/twitter-statistics/ whether a message is of positive, negative, or neutral sentiment.", "labels": [], "entities": [{"text": "Subtask A", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.8680405616760254}, {"text": "message polarity classification", "start_pos": 19, "end_pos": 50, "type": "TASK", "confidence": 0.7954402963320414}]}, {"text": "Subtasks B and C involve topicbased message polarity classification, which require a system to classify a message on two-and five-point scales toward a certain topic.", "labels": [], "entities": [{"text": "topicbased message polarity classification", "start_pos": 25, "end_pos": 67, "type": "TASK", "confidence": 0.6874481365084648}]}, {"text": "Various approaches have been proposed to analyze sentiment of text, and deep neural network has achieved state-of-the-art results in recent years.", "labels": [], "entities": [{"text": "analyze sentiment of text", "start_pos": 41, "end_pos": 66, "type": "TASK", "confidence": 0.7764167487621307}]}, {"text": "Proven successful text classification methods include convolutional neural networks (CNN) ( and Long Short-Term Memory (LSTM).", "labels": [], "entities": [{"text": "text classification", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.7936787009239197}]}, {"text": "In general, CNN applies a convolutional layer to extract active local n-gram features, but lost the order of words.", "labels": [], "entities": []}, {"text": "By contrast, LSTM can sequentially model texts.", "labels": [], "entities": []}, {"text": "However, it focuses only on past information and draws conclusions from the tail part of texts.", "labels": [], "entities": []}, {"text": "It fails to capture the local response from temporal data.", "labels": [], "entities": []}, {"text": "In this paper, we propose a multi-channel CNN-LSTM model for sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 61, "end_pos": 85, "type": "TASK", "confidence": 0.9662421643733978}]}, {"text": "It consists of two parts: multi-channel CNN, and LSTM.", "labels": [], "entities": [{"text": "CNN", "start_pos": 40, "end_pos": 43, "type": "DATASET", "confidence": 0.6226699948310852}, {"text": "LSTM", "start_pos": 49, "end_pos": 53, "type": "DATASET", "confidence": 0.6267592310905457}]}, {"text": "Unlike a conventional CNN model, we apply a multi-channel strategy that uses several filters of different length.", "labels": [], "entities": []}, {"text": "The model is thus able to extract active n-gram features of different scales.", "labels": [], "entities": []}, {"text": "LSTM is then applied to compose those features sequentially.", "labels": [], "entities": []}, {"text": "By combining both CNN and LSTM, both local information within tweets and long-distance dependency across tweets can be considered in the classification process.", "labels": [], "entities": [{"text": "CNN", "start_pos": 18, "end_pos": 21, "type": "DATASET", "confidence": 0.9085260033607483}]}, {"text": "To train the proposed neural model effectively using many parameters, we pretrained the model using a distant supervision approach (.", "labels": [], "entities": []}, {"text": "In our experiment, we presented our participation of the proposed model for the SemEval 2017 Task 4 Subtasks A, B, and C (.", "labels": [], "entities": [{"text": "SemEval 2017 Task 4 Subtasks A", "start_pos": 80, "end_pos": 110, "type": "TASK", "confidence": 0.8539935052394867}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we detail the architecture and multi-channel strategy of our model.", "labels": [], "entities": []}, {"text": "Section 3 summarizes the comparative results of our proposed model against the baseline algorithm.", "labels": [], "entities": []}, {"text": "Section 4 offers a conclusion.", "labels": [], "entities": []}, {"text": "shows the architecture of our model.", "labels": [], "entities": []}, {"text": "The model consists of six types of layers: embedding, convolution, max-pooling, LSTM, dense, and softmax.", "labels": [], "entities": []}, {"text": "First, a tweet is input as a series of vectors of constituent words and transformed into a feature matrix by an embedding layer.", "labels": [], "entities": []}, {"text": "The feature matrix is then passed into three parallel CNNs having different filter lengths.", "labels": [], "entities": []}, {"text": "The max pooling layer extracts the max-over different CNNs results that are intended to be the salient features, and input them to the LSTM layer.", "labels": [], "entities": []}, {"text": "Then, normal dense and softmax layers use outputs from LSTM and output the final classification result.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated our system on Subtasks A, B, and C.", "labels": [], "entities": []}, {"text": "Subtask A was a message polarity classification of three points.", "labels": [], "entities": [{"text": "message polarity classification", "start_pos": 16, "end_pos": 47, "type": "TASK", "confidence": 0.8176334500312805}]}, {"text": "Subtasks B and C involved ordinal sentiment classification of two and five points.", "labels": [], "entities": [{"text": "ordinal sentiment classification", "start_pos": 26, "end_pos": 58, "type": "TASK", "confidence": 0.655033141374588}]}, {"text": "Metrics of Subtasks A and B were average F1-score, http://nlp.stanford.edu/projects/glove/ average recall, and accuracy.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.999484658241272}, {"text": "average", "start_pos": 91, "end_pos": 98, "type": "METRIC", "confidence": 0.924246072769165}, {"text": "recall", "start_pos": 99, "end_pos": 105, "type": "METRIC", "confidence": 0.8449771404266357}, {"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9990272521972656}]}, {"text": "The F1-score was calculated as: where 1 p F is the F1-score of one class (p denotes positive here as an example), p \uf070 and p \uf072 denote precision and recall, respectively.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9987789988517761}, {"text": "F1-score", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9973359704017639}, {"text": "precision", "start_pos": 133, "end_pos": 142, "type": "METRIC", "confidence": 0.9995166063308716}, {"text": "recall", "start_pos": 147, "end_pos": 153, "type": "METRIC", "confidence": 0.9991814494132996}]}, {"text": "Metrics of subtask C were MAE M and MAE \u03bc , which were calculated as: where yi is the true label of item xi, h(xi) is the predicted label, and Tej is the set of test documents whose true class is cj.", "labels": [], "entities": [{"text": "MAE", "start_pos": 26, "end_pos": 29, "type": "METRIC", "confidence": 0.9568455219268799}, {"text": "MAE \u03bc", "start_pos": 36, "end_pos": 41, "type": "METRIC", "confidence": 0.955743819475174}]}, {"text": "A higher F1-score, recall, accuracy, and a lower MAE \u03bc and MAE M value indicate more accurate forecasting performance.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9995983242988586}, {"text": "recall", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9997859597206116}, {"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9998001456260681}, {"text": "MAE \u03bc", "start_pos": 49, "end_pos": 54, "type": "METRIC", "confidence": 0.98719722032547}, {"text": "MAE M", "start_pos": 59, "end_pos": 64, "type": "METRIC", "confidence": 0.8644420504570007}]}], "tableCaptions": [{"text": " Table 2: The evaluation results on Subtask A, B, C of", "labels": [], "entities": []}]}