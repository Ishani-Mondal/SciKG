{"title": [{"text": "PKU ICL at SemEval-2017 Task 10: Keyphrase Extraction with Model Ensemble and External Knowledge", "labels": [], "entities": [{"text": "PKU ICL at SemEval-2017 Task 10", "start_pos": 0, "end_pos": 31, "type": "DATASET", "confidence": 0.8514885902404785}, {"text": "Keyphrase Extraction", "start_pos": 33, "end_pos": 53, "type": "TASK", "confidence": 0.8690835237503052}]}], "abstractContent": [{"text": "This paper presents a system that participated in SemEval 2017 Task 10 (subtask A and subtask B): Extracting Keyphrases and Relations from Scientific Publications (Augenstein et al., 2017).", "labels": [], "entities": [{"text": "SemEval 2017 Task 10", "start_pos": 50, "end_pos": 70, "type": "TASK", "confidence": 0.8533583879470825}, {"text": "Extracting Keyphrases and Relations from Scientific Publications (Augenstein et al., 2017)", "start_pos": 98, "end_pos": 188, "type": "TASK", "confidence": 0.7733212879725865}]}, {"text": "Our proposed approach utilizes external knowledge to enrich feature representation of candidate keyphrase, including Wikipedia, IEEE taxonomy and pre-trained word em-beddings etc.", "labels": [], "entities": []}, {"text": "Ensemble of unsupervised models, random forest and linear models are used for candidate keyphrase ranking and keyphrase type classification.", "labels": [], "entities": [{"text": "candidate keyphrase ranking", "start_pos": 78, "end_pos": 105, "type": "TASK", "confidence": 0.6175252497196198}, {"text": "keyphrase type classification", "start_pos": 110, "end_pos": 139, "type": "TASK", "confidence": 0.7782537937164307}]}, {"text": "Our system achieves the 3rd place in subtask A and 4th place in subtask B.", "labels": [], "entities": []}], "introductionContent": [{"text": "Keyphrases summarize the most important aspects of a document.", "labels": [], "entities": []}, {"text": "They can be helpful in many areas such as information retrieval, topic modeling and text classification.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 42, "end_pos": 63, "type": "TASK", "confidence": 0.8442021012306213}, {"text": "topic modeling", "start_pos": 65, "end_pos": 79, "type": "TASK", "confidence": 0.8680056631565094}, {"text": "text classification", "start_pos": 84, "end_pos": 103, "type": "TASK", "confidence": 0.8134133517742157}]}, {"text": "However, manually labeling keyphrase would be far too time-consuming, and unrealistic especially when dealing with web-scale collection of documents.", "labels": [], "entities": []}, {"text": "Therefore, automatic keyphrase extraction has drawn growing interests among NLP research communities for years.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 21, "end_pos": 41, "type": "TASK", "confidence": 0.7941671311855316}]}, {"text": "For state-of-the-art system on keyphrase extraction, presents a comprehensive survey.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 31, "end_pos": 51, "type": "TASK", "confidence": 0.8443162143230438}]}, {"text": "Their experiments demonstrate that unsupervised approaches including graph-based ranking and topic modeling techniques perform best on News and Blogs dataset.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 93, "end_pos": 107, "type": "TASK", "confidence": 0.7392590641975403}, {"text": "News and Blogs dataset", "start_pos": 135, "end_pos": 157, "type": "DATASET", "confidence": 0.8815883845090866}]}, {"text": "In) (, which also aims to tackle the challenge of keyphrase extraction in scientific area, a majority of the participants adopt supervised approaches, and especially the top 2 systems are both supervised.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 50, "end_pos": 70, "type": "TASK", "confidence": 0.8228799104690552}]}, {"text": "Thus, in our work, we argue that supervised approaches can enable combination of rich features, with parameters learned efficiently and automatically, while their unsupervised counterparts often involve simply designed features and manually fine-tuned hyperparameters.", "labels": [], "entities": []}, {"text": "Based on the consideration above, for SemEval 2017 Task 10, our system is designed as a supervised one which also explore unsupervised techniques as auxiliaries.", "labels": [], "entities": [{"text": "SemEval 2017 Task 10", "start_pos": 38, "end_pos": 58, "type": "TASK", "confidence": 0.801503136754036}]}, {"text": "It involves three steps: candidate generation, keyphrase ranking and keyphrase type classification.", "labels": [], "entities": [{"text": "candidate generation", "start_pos": 25, "end_pos": 45, "type": "TASK", "confidence": 0.7987315356731415}, {"text": "keyphrase ranking", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.7933958470821381}, {"text": "keyphrase type classification", "start_pos": 69, "end_pos": 98, "type": "TASK", "confidence": 0.717576781908671}]}, {"text": "For candidate generation, we use chunking-based approach to discover phrases that match a predefined part-of-speech pattern.", "labels": [], "entities": [{"text": "candidate generation", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.8068787157535553}]}, {"text": "Heuristic rules are manually designed by experience and applied to filter out those phrases which are unlikely to be keyphrases.", "labels": [], "entities": []}, {"text": "For keyphrase ranking in subtask A, we use a straightforward regression-based pointwise ranking method.", "labels": [], "entities": [{"text": "keyphrase ranking", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.8308801352977753}]}, {"text": "Here, two unsupervised algorithms TextRank ( are incorporated into random forest by providing their output as complementary features.", "labels": [], "entities": [{"text": "TextRank", "start_pos": 34, "end_pos": 42, "type": "DATASET", "confidence": 0.899106502532959}]}, {"text": "In our experiments, we find that stacking linear model upon random forest can provide extra performance gain.", "labels": [], "entities": []}, {"text": "For keyphrase type classification in subtask B, we model it as a three-way classification problem, with the same feature set and classifiers used in subtask A.", "labels": [], "entities": [{"text": "keyphrase type classification", "start_pos": 4, "end_pos": 33, "type": "TASK", "confidence": 0.8236496448516846}]}, {"text": "Feature engineering is a critical part for supervised model.", "labels": [], "entities": [{"text": "Feature engineering", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8326288759708405}]}, {"text": "The task of keyphrase extraction heavily relies on statistical features(such as TF-IDF) and semantic features.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 12, "end_pos": 32, "type": "TASK", "confidence": 0.86113640666008}]}, {"text": "However, due to the limited size of labeled dataset, it is hard to get reliable estimation of phrases' IDF value or semantic representation.", "labels": [], "entities": [{"text": "IDF", "start_pos": 103, "end_pos": 106, "type": "METRIC", "confidence": 0.9671311974525452}]}, {"text": "In this paper, we solve this problem by exploiting external knowledge resources such as Wikipedia and pre-trained word embeddings.", "labels": [], "entities": []}, {"text": "Experiments show the effectiveness of our proposed feature set.", "labels": [], "entities": []}], "datasetContent": [{"text": "For details about this shared task and dataset, please refer to SemEval 2017 Task 10 description paper ().", "labels": [], "entities": [{"text": "SemEval 2017 Task 10 description paper", "start_pos": 64, "end_pos": 102, "type": "DATASET", "confidence": 0.7865099857250849}]}, {"text": "Preprocessing We use nltk) to segment each paragraph into a list of sentences, tokenize every sentence and then get part-of-speech tag for every token.", "labels": [], "entities": []}, {"text": "Snowball Stemmer is used for stemming.", "labels": [], "entities": [{"text": "Snowball Stemmer", "start_pos": 0, "end_pos": 16, "type": "DATASET", "confidence": 0.8941859304904938}, {"text": "stemming", "start_pos": 29, "end_pos": 37, "type": "TASK", "confidence": 0.9825312495231628}]}, {"text": "Stop words, punctuations and digits are removed for feature engineering, but not for keyphrase candidate generation.", "labels": [], "entities": [{"text": "keyphrase candidate generation", "start_pos": 85, "end_pos": 115, "type": "TASK", "confidence": 0.6931855281194051}]}, {"text": "We use simple heuristics to parse the IEEE taxonomy pdf file and get 6978 phrases in total.", "labels": [], "entities": [{"text": "IEEE taxonomy pdf file", "start_pos": 38, "end_pos": 60, "type": "DATASET", "confidence": 0.9349033236503601}]}, {"text": "Configurations Library scikit-learn is used for implementation of our supervised models.", "labels": [], "entities": []}, {"text": "Random forest is set to have 200 trees and other parameters are set to default.", "labels": [], "entities": []}, {"text": "Parameters of linear SVM are all set to default.", "labels": [], "entities": []}, {"text": "We use 50-dimensional glove embeddings for calculating phrase representation.", "labels": [], "entities": [{"text": "phrase representation", "start_pos": 55, "end_pos": 76, "type": "TASK", "confidence": 0.7700198292732239}]}, {"text": "For subtask A, we choose threshold \u03b1 = 0.15 to balance recall and precision.: Official results on test set.", "labels": [], "entities": [{"text": "recall", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9994875192642212}, {"text": "precision.", "start_pos": 66, "end_pos": 76, "type": "METRIC", "confidence": 0.9995647072792053}]}], "tableCaptions": [{"text": " Table 2: Official results on test set.", "labels": [], "entities": []}, {"text": " Table 4: Performance with different combinations of features.", "labels": [], "entities": []}, {"text": " Table 5: Comparison of different models on test  data. (a) tf-idf output phrases with top 15 tf\u00b7idf score; (b)", "labels": [], "entities": []}]}