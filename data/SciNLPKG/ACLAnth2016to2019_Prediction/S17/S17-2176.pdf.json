{"title": [{"text": "Hitachi at SemEval-2017 Task 12: System for temporal information extraction from clinical notes", "labels": [], "entities": [{"text": "SemEval-2017 Task 12", "start_pos": 11, "end_pos": 31, "type": "TASK", "confidence": 0.8103194832801819}, {"text": "temporal information extraction from clinical", "start_pos": 44, "end_pos": 89, "type": "TASK", "confidence": 0.7685501217842102}]}], "abstractContent": [{"text": "This paper describes the system developed for the task of temporal information extraction from clinical narratives in the context of the 2017 Clinical TempE-val challenge.", "labels": [], "entities": [{"text": "temporal information extraction from clinical narratives", "start_pos": 58, "end_pos": 114, "type": "TASK", "confidence": 0.8010314603646597}, {"text": "Clinical TempE-val challenge", "start_pos": 142, "end_pos": 170, "type": "TASK", "confidence": 0.48170944054921466}]}, {"text": "Clinical TempEval 2017 addressed the problem of temporal reasoning in the clinical domain by providing annotated clinical notes, pathology and radiology reports inline with Clinical Tem-pEval challenges 2015/16, across two different evaluation phases focusing on cross domain adaptation.", "labels": [], "entities": [{"text": "cross domain adaptation", "start_pos": 263, "end_pos": 286, "type": "TASK", "confidence": 0.6502883931001028}]}, {"text": "Our team focused on subtasks involving extractions of temporal spans and relations for which the developed systems showed average F-score of 0.45 and 0.47 across the two phases of evaluations.", "labels": [], "entities": [{"text": "F-score", "start_pos": 130, "end_pos": 137, "type": "METRIC", "confidence": 0.9993935823440552}]}], "introductionContent": [{"text": "Temporal information extraction has been a widely explored topic of research interest in the field of information extraction during recent years.", "labels": [], "entities": [{"text": "Temporal information extraction", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.9046022295951843}, {"text": "information extraction", "start_pos": 102, "end_pos": 124, "type": "TASK", "confidence": 0.801271915435791}]}, {"text": "It is essential for improving the performance of applications such as question answering, search, text classification and systems that establish timelines from clinical narratives.", "labels": [], "entities": [{"text": "question answering", "start_pos": 70, "end_pos": 88, "type": "TASK", "confidence": 0.8994267582893372}, {"text": "text classification", "start_pos": 98, "end_pos": 117, "type": "TASK", "confidence": 0.7302335798740387}]}, {"text": "In this line over the years, research community challenges on clinical temporal information extraction have been organized; i.e., the 2012 Informatics for Integrating Biology and the Bedside (i2b2) challenge) the 2013/2014 CLEF/ShARe challenge, and the 2015/16 Clinical TempEval challenge (.", "labels": [], "entities": [{"text": "clinical temporal information extraction", "start_pos": 62, "end_pos": 102, "type": "TASK", "confidence": 0.61860441416502}, {"text": "CLEF/ShARe challenge", "start_pos": 223, "end_pos": 243, "type": "DATASET", "confidence": 0.7622951865196228}, {"text": "2015/16 Clinical TempEval challenge", "start_pos": 253, "end_pos": 288, "type": "TASK", "confidence": 0.5612632185220718}]}, {"text": "These challenges provide annotated corpora on temporal entities and relations, which facilitate comparisons of multiple systems and push the state of art in the development of clinical temporal information extraction methodologies.", "labels": [], "entities": [{"text": "clinical temporal information extraction", "start_pos": 176, "end_pos": 216, "type": "TASK", "confidence": 0.6185028478503227}]}, {"text": "The 2017 Clinical TempEval challenge is the most recent community challenge that addresses temporal information extraction from clinical notes.", "labels": [], "entities": [{"text": "Clinical TempEval challenge", "start_pos": 9, "end_pos": 36, "type": "TASK", "confidence": 0.6033993562062582}, {"text": "temporal information extraction from clinical notes", "start_pos": 91, "end_pos": 142, "type": "TASK", "confidence": 0.7993104557196299}]}, {"text": "The challenge was in inline with 2015/16 challenge in terms of subtasks.", "labels": [], "entities": [{"text": "2015/16 challenge", "start_pos": 33, "end_pos": 50, "type": "DATASET", "confidence": 0.7602789252996445}]}, {"text": "However this year's challenge focussed on cross domain adaptation across two phases of evaluation.", "labels": [], "entities": [{"text": "cross domain adaptation", "start_pos": 42, "end_pos": 65, "type": "TASK", "confidence": 0.6542408366998037}]}, {"text": "In phase one (unsupervised domain adaptation), the systems were evaluated on their results for all six sub-tasks on brain cancer notes given colon cancer notes (data of 2015/16 challenge) as inputs.", "labels": [], "entities": [{"text": "domain adaptation)", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.8112906416257223}]}, {"text": "In phase two (supervised domain adaptation), evaluation was carried out inline with phase one but a small number of annotations of brain cancer notes were also given as inputs.", "labels": [], "entities": [{"text": "supervised domain adaptation)", "start_pos": 14, "end_pos": 43, "type": "TASK", "confidence": 0.7472949922084808}]}, {"text": "In this paper, we describe an end-to-end system that addresses subtasks involving extractions of temporal spans and relations.", "labels": [], "entities": []}, {"text": "We designed the system by adapting various insights and techniques from previous work on temporal information extraction in the clinical domain and ensemble modelling (.", "labels": [], "entities": [{"text": "temporal information extraction", "start_pos": 89, "end_pos": 120, "type": "TASK", "confidence": 0.6696674327055613}]}, {"text": "The rest of the paper is organised as follows: In section 2, we discuss datasets, methods and feature sets used for each of the subtasks.", "labels": [], "entities": []}, {"text": "In section 3, we present the results for various subtasks and conclude our work in section 4 with some of our findings and possible implications on future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "The THYME corpus used in this task consists of clinical, pathology and radiology notes for colon/brain cancer patients from Mayo clinic (.", "labels": [], "entities": [{"text": "THYME corpus", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.7716341316699982}, {"text": "Mayo clinic", "start_pos": 124, "end_pos": 135, "type": "DATASET", "confidence": 0.9495570361614227}]}, {"text": "We designed an end-to-end pipeline consisting of four modules which process the input text in three stages: In stage one, the first and second modules extract time/event expressions and their spans.", "labels": [], "entities": []}, {"text": "In stage two, the third module predicts document time relations between the event and document creation time expressions.", "labels": [], "entities": []}, {"text": "Finally, all the outputs of stage one and two are used to extract container relations in stage three.", "labels": [], "entities": []}, {"text": "For phase one (unsupervised domain adaptation) we used train, dev and test colon cancer datasets to train and evaluated on the brain cancer test dataset.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 28, "end_pos": 45, "type": "TASK", "confidence": 0.7649814784526825}, {"text": "brain cancer test dataset", "start_pos": 127, "end_pos": 152, "type": "DATASET", "confidence": 0.6488359570503235}]}, {"text": "While in phase two we retrained models with a mixture of colon cancer and additional brain cancer notes, each of which are explained in upcoming sections.", "labels": [], "entities": []}, {"text": "For our temporal information extrac-  In this section, we present our system performance of various runs across two different phases for each of the participated subtasks.", "labels": [], "entities": []}, {"text": "show the results of temporal span extraction and tables 3-4 shows results of temporal relation extraction.", "labels": [], "entities": [{"text": "temporal span extraction", "start_pos": 20, "end_pos": 44, "type": "TASK", "confidence": 0.6451326310634613}, {"text": "temporal relation extraction", "start_pos": 77, "end_pos": 105, "type": "TASK", "confidence": 0.6207882662614187}]}, {"text": "Our systems showed average F-score of 0.45 for unsupervised runs and 0.47 for supervised runs across different sub-tasks.: Results of doctime relation expression", "labels": [], "entities": [{"text": "F-score", "start_pos": 27, "end_pos": 34, "type": "METRIC", "confidence": 0.9995367527008057}]}], "tableCaptions": [{"text": " Table 1: Results of time expression", "labels": [], "entities": []}, {"text": " Table 2: Results of event expression", "labels": [], "entities": []}, {"text": " Table 3: Results of doctime relation expression", "labels": [], "entities": [{"text": "doctime relation", "start_pos": 21, "end_pos": 37, "type": "TASK", "confidence": 0.7232966125011444}]}, {"text": " Table 4: Results of narrative container relations", "labels": [], "entities": [{"text": "narrative container relations", "start_pos": 21, "end_pos": 50, "type": "TASK", "confidence": 0.7823608915011088}]}]}