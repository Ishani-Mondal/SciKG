{"title": [{"text": "Parsing Graphs with Regular Graph Grammars", "labels": [], "entities": []}], "abstractContent": [{"text": "Recently, several datasets have become available which represent natural language phenomena as graphs.", "labels": [], "entities": []}, {"text": "Hyperedge Replacement Languages (HRL) have been the focus of much attention as a formalism to represent the graphs in these datasets.", "labels": [], "entities": [{"text": "Hyperedge Replacement Languages (HRL)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8363476892312368}]}, {"text": "(2013) prove that HRL graphs can be parsed in polynomial time with respect to the size of the input graph.", "labels": [], "entities": []}, {"text": "We believe that HRL are more expressive than is necessary to represent semantic graphs and we propose the use of Regular Graph Languages (RGL; Cour-celle 1991), which is a subfamily of HRL, as a possible alternative.", "labels": [], "entities": [{"text": "RGL; Cour-celle 1991)", "start_pos": 138, "end_pos": 159, "type": "DATASET", "confidence": 0.7176021814346314}]}, {"text": "We provide a top-down parsing algorithm for RGL that runs in time linear in the size of the input graph.", "labels": [], "entities": []}], "introductionContent": [{"text": "NLP systems for machine translation, summarization, paraphrasing, and other tasks often fail to preserve the compositional semantics of sentences and documents because they model language as bags of words, or at best syntactic trees.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 16, "end_pos": 35, "type": "TASK", "confidence": 0.7647253572940826}, {"text": "summarization, paraphrasing", "start_pos": 37, "end_pos": 64, "type": "TASK", "confidence": 0.672662099202474}]}, {"text": "To preserve semantics, they must model semantics.", "labels": [], "entities": []}, {"text": "In pursuit of this goal, several datasets have been produced which pair natural language with compositional semantic representations in the form of directed acyclic graphs (DAGs), including the Abstract Meaning Representation Bank (AMR;), the Prague Czech-English Dependency), Deepbank (, and the Universal Conceptual Cognitive Annotation.", "labels": [], "entities": []}, {"text": "To make use of this data, we require models of graphs.", "labels": [], "entities": []}, {"text": "Consider how we might use compositional semantic representations in machine translation (), a two-step process in which semantic analysis is followed by generation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 68, "end_pos": 87, "type": "TASK", "confidence": 0.7269451320171356}]}, {"text": "observe that this decomposition can be modeled with a pair of synchronous grammars, each defining a relation between strings and graphs.", "labels": [], "entities": []}, {"text": "Necessarily, one projection of this synchronous grammar produces strings, while the other produces graphs, i.e., is a graph grammar.", "labels": [], "entities": []}, {"text": "A consequence of this representation is that the complete translation process can be realized by parsing: to analyze a sentence, we parse the input string with the string-generating projection of the synchronous grammar, and read off the synchronous graph from the resulting parse.", "labels": [], "entities": []}, {"text": "To generate a sentence, we parse the graph, and read off the synchronous string from the resulting parse.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the latter problem: using graph grammars to parse input graphs.", "labels": [], "entities": []}, {"text": "We call this graph recognition to avoid confusion with other parsing problems.", "labels": [], "entities": [{"text": "graph recognition", "start_pos": 13, "end_pos": 30, "type": "TASK", "confidence": 0.7550448179244995}]}, {"text": "Recent work in NLP has focused primarily on hyperedge replacement grammar (HRG;), a context-free graph grammar formalism that has been studied in an NLP context by several researchers (.", "labels": [], "entities": [{"text": "hyperedge replacement grammar (HRG", "start_pos": 44, "end_pos": 78, "type": "TASK", "confidence": 0.7627728700637817}]}, {"text": "In particular, propose that HRG could be used to represent semantic graphs, and precisely characterize the complexity of a CKY-style algorithm for graph recognition from to be polynomial in the size of the input graph.", "labels": [], "entities": [{"text": "graph recognition", "start_pos": 147, "end_pos": 164, "type": "TASK", "confidence": 0.8039324879646301}]}, {"text": "HRGs are very expressive-they can generate graphs that simulate non-context-free string languages.", "labels": [], "entities": []}, {"text": "This means they are likely more expressive than we need to represent the linguistic phenomena that appear in existing semantic datasets.", "labels": [], "entities": []}, {"text": "In this paper, we propose the use of Regular Graph Grammars (RGG; Courcelle 1991) a subfamily of HRG that, like its regular counterparts among string and tree languages, is less expressive than context-free grammars but may admit more practical algorithms.", "labels": [], "entities": []}, {"text": "By analogy to Chiang's CKY-style algorithm for HRG.", "labels": [], "entities": []}, {"text": "We develop an Earley-style recognition algorithm for RGLs that is linear in the size of the input graph.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Productions of a HRG. The labels p, q, r, s, t, and u  label the productions so that we can refer to them in the text.  Note that Y can rewrite in two ways, either via production r  or s.", "labels": [], "entities": []}]}