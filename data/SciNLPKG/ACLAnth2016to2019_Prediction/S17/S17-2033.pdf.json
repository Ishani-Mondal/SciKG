{"title": [{"text": "HCCL at SemEval-2017 Task 2: Combining Multilingual Word Embeddings and Transliteration Model for Semantic Similarity", "labels": [], "entities": [{"text": "Similarity", "start_pos": 107, "end_pos": 117, "type": "TASK", "confidence": 0.532983124256134}]}], "abstractContent": [{"text": "In this paper, we introduce an approach to combining word embeddings and machine translation for multilingual semantic word similarity, the task2 of SemEval-2017.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 73, "end_pos": 92, "type": "TASK", "confidence": 0.7593667805194855}, {"text": "multilingual semantic word similarity", "start_pos": 97, "end_pos": 134, "type": "TASK", "confidence": 0.6142355278134346}]}, {"text": "Thanks to the unsupervised translit-eration model, our cross-lingual word em-beddings encounter decreased sums of OOVs.", "labels": [], "entities": [{"text": "OOVs", "start_pos": 114, "end_pos": 118, "type": "METRIC", "confidence": 0.9567139744758606}]}, {"text": "Our results are produced using only monolingual Wikipedia corpora and a limited amount of sentence-aligned data.", "labels": [], "entities": []}, {"text": "Although relatively little resources are utilized , our system ranked 3rd in the mono-lingual subtask and can be the 6th in the cross-lingual subtask.", "labels": [], "entities": []}], "introductionContent": [{"text": "With convenient word representation methods being proposed, word embeddings are successfully utilized in state-of-the-art systems ranging from text classification, opinion categorization (, machine translation (, to stock price prediction and soon.", "labels": [], "entities": [{"text": "text classification", "start_pos": 143, "end_pos": 162, "type": "TASK", "confidence": 0.7320257723331451}, {"text": "machine translation", "start_pos": 190, "end_pos": 209, "type": "TASK", "confidence": 0.7275422215461731}, {"text": "stock price prediction", "start_pos": 216, "end_pos": 238, "type": "TASK", "confidence": 0.6290404995282491}, {"text": "soon", "start_pos": 243, "end_pos": 247, "type": "METRIC", "confidence": 0.9663628935813904}]}, {"text": "In earlier studies, the latent semantic analysis (LSA) was introduced by.", "labels": [], "entities": [{"text": "latent semantic analysis (LSA)", "start_pos": 24, "end_pos": 54, "type": "TASK", "confidence": 0.6991999298334122}]}, {"text": "It is called topic model because terms are represented as the vectors of topics and was popularized by.", "labels": [], "entities": []}, {"text": "In 2003, researchers developed the topic model based on latent Dirichlet allocation(LDA) ().", "labels": [], "entities": [{"text": "latent Dirichlet allocation(LDA)", "start_pos": 56, "end_pos": 88, "type": "METRIC", "confidence": 0.7307982544104258}]}, {"text": "LDA did not widely spread until the Gibbs sampling was applied to the on-line training of LDA (.", "labels": [], "entities": []}, {"text": "Another traditional distributional method, pointwise mutual information metric was proposed by.", "labels": [], "entities": []}, {"text": "Recently, fast distributed embeddings like () and GloVe () are based on the assumption that the meaning of a word depends on its context.", "labels": [], "entities": []}, {"text": "As pointed out, there is no significant performance difference between them.", "labels": [], "entities": []}, {"text": "For cross-lingual word representation, there are generally four categories: Monolingual mapping (), pseudo-cross-lingual training, cross-lingual training () and joint optimization.", "labels": [], "entities": [{"text": "cross-lingual word representation", "start_pos": 4, "end_pos": 37, "type": "TASK", "confidence": 0.6782683432102203}, {"text": "Monolingual mapping", "start_pos": 76, "end_pos": 95, "type": "TASK", "confidence": 0.7401156425476074}, {"text": "joint optimization", "start_pos": 161, "end_pos": 179, "type": "TASK", "confidence": 0.7160642892122269}]}, {"text": "As presented in , the joint optimization method represents the state-ofthe-art level in cross-lingual text classification and translation.", "labels": [], "entities": [{"text": "cross-lingual text classification", "start_pos": 88, "end_pos": 121, "type": "TASK", "confidence": 0.6568922301133474}]}, {"text": "These methods train embeddings both on monolingual and parallel corpora by jointly optimizing the losses.", "labels": [], "entities": []}, {"text": "However, they are rarely used in word similarity due to the unsatisfying performance.", "labels": [], "entities": [{"text": "word similarity", "start_pos": 33, "end_pos": 48, "type": "TASK", "confidence": 0.764218807220459}]}, {"text": "In this task, we adopt different strategies for the two subtasks.", "labels": [], "entities": []}, {"text": "We use word2vec for subtask1, monolingual word similarity.", "labels": [], "entities": []}, {"text": "For the subtask2, cross-lingual word similarity, we use jointly optimized cross-lingual word representation in addition to transliteration model.", "labels": [], "entities": [{"text": "cross-lingual word similarity", "start_pos": 18, "end_pos": 47, "type": "TASK", "confidence": 0.6110493441422781}]}, {"text": "We build a crosslingual word embedding system and a special machine translation system.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.7320444881916046}]}, {"text": "Our approach has the following characteristics: \u2022 Fast and efficient.", "labels": [], "entities": [{"text": "Fast", "start_pos": 50, "end_pos": 54, "type": "METRIC", "confidence": 0.9780024886131287}]}, {"text": "Both word2vec and the cross-lingual word embeddgings tool have impressive speed and not need expensive annotated wordaligned data.", "labels": [], "entities": []}, {"text": "Our translation system is featured by its transliteration model that deal with OOVs outside the parallel corpus.", "labels": [], "entities": []}, {"text": "We constructed a naive system and did not tryout the parameters for embeddings and translation models in limited time.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conduct an experiment on English word embeddings to seethe performance of our vectors.", "labels": [], "entities": []}, {"text": "We use phrasing and positional context when training.", "labels": [], "entities": []}, {"text": "The phrasing is to extract phrased based on co-occurence and the threshold is 400.", "labels": [], "entities": []}, {"text": "Positional context treats the same word in different position as different words.", "labels": [], "entities": []}, {"text": "Our monolingual embeddings are trained with 500 dimension, 5 iterations, 15 negative samples, win=5 and mincount=10.", "labels": [], "entities": [{"text": "mincount", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.9630678296089172}]}, {"text": "We use similary part of WordSim353 (.", "labels": [], "entities": [{"text": "WordSim353", "start_pos": 24, "end_pos": 34, "type": "DATASET", "confidence": 0.9701131582260132}]}, {"text": "The performance of the submitted systems (extra resources are used) including ours (in bold) and RUFINO (the other system uses the same corpus) on all languages are listed in.", "labels": [], "entities": [{"text": "RUFINO", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.9262012243270874}]}, {"text": "In the cross-lingual word similarity subtask each word pair is composed by words in different languages.", "labels": [], "entities": []}, {"text": "This subtask consists often cross-lingual word similarity datasets: EN-DE, EN-ES, EN-FA, EN-IT, DE-ES, DE-FA, DE-IT, ES-FA, ES-IT, and FA-IT.", "labels": [], "entities": []}, {"text": "We define the OOVs as the words that can either be found in parallel data or word embeddings.", "labels": [], "entities": []}, {"text": "In this subtask, due to the limited amount of parallel data, OOVs occupy a large proportion in the test sets.", "labels": [], "entities": []}, {"text": "We show the statistics of OOVs in test sets before, after transliteration model and their final counts after looking up cross-lingual word embeddings in.", "labels": [], "entities": []}, {"text": "In subtask 2, for the sake of limited time, we did not use phrasing and positional context like in subtask1.", "labels": [], "entities": []}, {"text": "For phrases in test sets, we sum up the vectors of all word in the phrase as its embedding.", "labels": [], "entities": []}, {"text": "The results of random embeddings that equal to random guess without any semantics, correct results of our system and the top system (Luminoso2) are listed in", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance of English word embeddings on different test sets. sp is short for Spearman  correlation, pr is short for Pearson correlation.", "labels": [], "entities": [{"text": "Spearman  correlation", "start_pos": 89, "end_pos": 110, "type": "METRIC", "confidence": 0.6094335317611694}, {"text": "Pearson correlation", "start_pos": 128, "end_pos": 147, "type": "METRIC", "confidence": 0.9246553480625153}]}, {"text": " Table 2: Results on subtask1.", "labels": [], "entities": []}, {"text": " Table 3: Counts of OOVs after each steps.", "labels": [], "entities": [{"text": "Counts", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9946600794792175}, {"text": "OOVs", "start_pos": 20, "end_pos": 24, "type": "METRIC", "confidence": 0.5936208963394165}]}, {"text": " Table 4: Results on subtask2.", "labels": [], "entities": []}]}