{"title": [{"text": "IITP at SemEval-2017 Task 5: An Ensemble of Deep Learning and Feature Based Models for Financial Sentiment Analysis", "labels": [], "entities": [{"text": "IITP at SemEval-2017 Task 5", "start_pos": 0, "end_pos": 27, "type": "DATASET", "confidence": 0.7383222937583923}, {"text": "Financial Sentiment Analysis", "start_pos": 87, "end_pos": 115, "type": "TASK", "confidence": 0.6845381855964661}]}], "abstractContent": [{"text": "In this paper we propose an ensemble based model which combines state of the art deep learning sentiment analysis algorithms like Convolution Neural Network (CNN) and Long Short Term Memory (LSTM) along with feature based models to identify optimistic or pessimistic sentiments associated with companies and stocks in financial texts.", "labels": [], "entities": []}, {"text": "We build our system to participate in a competition organized by Semantic Evaluation 2017 International Workshop.", "labels": [], "entities": [{"text": "Semantic Evaluation 2017 International Workshop", "start_pos": 65, "end_pos": 112, "type": "TASK", "confidence": 0.8285583853721619}]}, {"text": "We combined predictions from various models using an artificial neural network to determine the opinion towards an entity in (a) Microblog Messages and (b) News Headlines data.", "labels": [], "entities": [{"text": "News Headlines data", "start_pos": 156, "end_pos": 175, "type": "DATASET", "confidence": 0.917120118935903}]}, {"text": "Our models achieved a cosine similarity score of 0.751 and 0.697 for the above two tracks giving us the rank of 2nd and 7th best team respectively.", "labels": [], "entities": [{"text": "cosine similarity score", "start_pos": 22, "end_pos": 45, "type": "METRIC", "confidence": 0.7899942994117737}]}], "introductionContent": [{"text": "Sentiment analysis of financial text is an important area of research.", "labels": [], "entities": [{"text": "Sentiment analysis of financial text", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.9362225770950318}]}, {"text": "It has been shown that sentiments and opinions can affect market dynamics (.", "labels": [], "entities": []}, {"text": "Social media has created anew world of venting customer voice.", "labels": [], "entities": []}, {"text": "People tend to express their personal sentiment about the stock market through tweets.", "labels": [], "entities": []}, {"text": "On the other hand, news presents the macroeconomic factors, company-specific or political information.", "labels": [], "entities": []}, {"text": "Positive news tend to bring optimism and lift the market whereas negative news effect the market in opposite direction (Van de.", "labels": [], "entities": []}, {"text": "Sentiment analysis gives organizations the ability to observe the various social media sites in real time and then act accordingly.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9539962708950043}]}, {"text": "Twitter is considered to bean ocean of sentiment data.", "labels": [], "entities": []}, {"text": "A study indicates that sentiment analysis of public mood derived from Twitter feeds can be used to eventually forecast movements of individual stock prices).", "labels": [], "entities": [{"text": "sentiment analysis of public mood", "start_pos": 23, "end_pos": 56, "type": "TASK", "confidence": 0.8733643174171448}]}, {"text": "All these evidences show us that financial sentiment analysis has a lot of untapped power and extensive research in the field can help us gain great insight about the financial market.", "labels": [], "entities": [{"text": "financial sentiment analysis", "start_pos": 33, "end_pos": 61, "type": "TASK", "confidence": 0.8685794075330099}]}, {"text": "The fundamental problem with classifying financial tweets is the presence of noise.", "labels": [], "entities": [{"text": "classifying financial tweets", "start_pos": 29, "end_pos": 57, "type": "TASK", "confidence": 0.9141202370325724}]}, {"text": "The natural use of short, informal languages, emoticons, hashtag and sarcasm in tweets makes the sentiment analysis problem especially challenging.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.9698066413402557}]}, {"text": "News headlines usually use limited number of words to summarize the article.", "labels": [], "entities": []}, {"text": "Moreover, aspects like language patterns, writing style, irony usage differs notably among different news categories and articles.", "labels": [], "entities": []}, {"text": "Use of articles, verb form of 'to be', conjunction are very rare in practice.", "labels": [], "entities": []}, {"text": "In this paper we describe our proposed system as part of the 'SemEval-2017 Task 5 on FineGrained Sentiment Analysis for Financial.", "labels": [], "entities": [{"text": "SemEval-2017 Task 5 on FineGrained Sentiment Analysis", "start_pos": 62, "end_pos": 115, "type": "TASK", "confidence": 0.6412422912461417}]}, {"text": "We propose a multilayer perceptron (MLP) based ensemble method that leverages the combination of deep learning and feature based models for the prediction.", "labels": [], "entities": []}, {"text": "Our system produces 4th and 8th best cosine similarity score for microblogs messages and news headline respectively.", "labels": [], "entities": [{"text": "cosine similarity score", "start_pos": 37, "end_pos": 60, "type": "METRIC", "confidence": 0.7222205797831217}]}, {"text": "A total of 25 teams participated for the microblogs messages task while 29 teams submitted their systems for the news headline track.", "labels": [], "entities": []}, {"text": "The task defines sentiment score prediction in two separate tracks i.e. microblogs and news headlines.", "labels": [], "entities": [{"text": "sentiment score prediction", "start_pos": 17, "end_pos": 43, "type": "TASK", "confidence": 0.8583537340164185}]}, {"text": "The objective of the task is to predict a sentiment score associated with a company/cashtag in the text.", "labels": [], "entities": []}, {"text": "The sentiment score lies in a continuous range of -1(very bearish) to +1(very bullish).", "labels": [], "entities": []}, {"text": "Cashtag refers to a stock symbol that uniquely identifies a company.", "labels": [], "entities": [{"text": "Cashtag", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8224843144416809}]}, {"text": "For e.g. $AAPL represents stock symbol for the company Apple Inc.", "labels": [], "entities": [{"text": "AAPL", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9898834824562073}]}, {"text": "Every instance of microblogs messages also include a span which indicates apart of text from where prediction should be derived.", "labels": [], "entities": []}, {"text": "This rest of the paper is organized as follows: Section 2 illustrates our system architecture in detail.", "labels": [], "entities": []}, {"text": "We present our experimental results in Section 3.", "labels": [], "entities": []}, {"text": "Finally, Section 4 presents our conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "The training datasets comprises of 1700 and 1142 instances of microblogs messages and news headlines respectively.", "labels": [], "entities": []}, {"text": "We used the span in microblogs message track and the title in news headlines track as the textual feature for all our experiments described in this paper.", "labels": [], "entities": []}, {"text": "For validation we did a 80:20, train:development split of the full datasets.", "labels": [], "entities": []}, {"text": "The split was done such that the relative percentage of sources (twitter and stocktwits), mean and standard deviation of sentiment scores were same in the training and development data.", "labels": [], "entities": [{"text": "standard deviation of sentiment scores", "start_pos": 99, "end_pos": 137, "type": "METRIC", "confidence": 0.8403205275535583}]}, {"text": "We trained our model on the train data and selected models for ensembling, based on results on development data.", "labels": [], "entities": []}, {"text": "shows the distribution of sentiment scores for the two datasets.", "labels": [], "entities": []}, {"text": "We used python based neural network package Keras 3 for the implementation.", "labels": [], "entities": []}, {"text": "We use ReLU activations for the intermediate layers and tanh activation for the final layer.", "labels": [], "entities": []}, {"text": "Dropout () is a very effective regularization technique to prevent over-fitting of a network.", "labels": [], "entities": []}, {"text": "It restrict convergence of weights to identical positions by randomly turning off the neurons during forward propagation.", "labels": [], "entities": []}, {"text": "We use 15% dropout and 'Adam' optimizer () for regularization and optimization.", "labels": [], "entities": [{"text": "regularization", "start_pos": 47, "end_pos": 61, "type": "TASK", "confidence": 0.9644267559051514}]}, {"text": "shows our results of deep learning models (D), feature based model (F) and vector averaging models (V) on the validation set.", "labels": [], "entities": []}, {"text": "It also depicts the results of our ensemble model (E) on the development set.", "labels": [], "entities": []}, {"text": "It should be observed that use of ensemble improves the performance by a margin of 2-3%.", "labels": [], "entities": []}, {"text": "We submitted the E1 and E6 systems for the final evaluation and got a test cosine similarity score of 0.751 and 0.697 for microblogs messages and news headlines tracks respectively.", "labels": [], "entities": [{"text": "cosine similarity score", "start_pos": 75, "end_pos": 98, "type": "METRIC", "confidence": 0.7196677923202515}]}, {"text": "reports cosine similarity of our system.", "labels": [], "entities": [{"text": "similarity", "start_pos": 15, "end_pos": 25, "type": "METRIC", "confidence": 0.6059434413909912}]}], "tableCaptions": [{"text": " Table 1: Cosine similarity score on validation set.", "labels": [], "entities": [{"text": "Cosine similarity score", "start_pos": 10, "end_pos": 33, "type": "METRIC", "confidence": 0.8181300759315491}]}, {"text": " Table 2: Cosine similarity score on test dataset.", "labels": [], "entities": [{"text": "Cosine similarity score", "start_pos": 10, "end_pos": 33, "type": "METRIC", "confidence": 0.8507041136423746}]}]}