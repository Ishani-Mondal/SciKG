{"title": [{"text": "Lump at SemEval-2017 Task 1: Towards an Interlingua Semantic Similarity", "labels": [], "entities": [{"text": "Similarity", "start_pos": 61, "end_pos": 71, "type": "TASK", "confidence": 0.4647805690765381}]}], "abstractContent": [{"text": "This is the Lump team participation at Se-mEval 2017 Task 1 on Semantic Textual Similarity.", "labels": [], "entities": [{"text": "Semantic Textual Similarity", "start_pos": 63, "end_pos": 90, "type": "TASK", "confidence": 0.7200647989908854}]}, {"text": "Our supervised model relies on features which are multilingual or interlin-gual in nature.", "labels": [], "entities": []}, {"text": "We include lexical similarities , cross-language explicit semantic analysis, internal representations of multilingual neural networks and interlingual word embeddings.", "labels": [], "entities": [{"text": "cross-language explicit semantic analysis", "start_pos": 34, "end_pos": 75, "type": "TASK", "confidence": 0.7339199334383011}]}, {"text": "Our representations allow to use large datasets in language pairs with many instances to better classify instances in smaller language pairs avoiding the necessity of translating into a single language.", "labels": [], "entities": []}, {"text": "Hence we can deal with all the languages in the task: Arabic, English, Spanish, and Turkish.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Semantic Textual Similarity (STS) task poses the following challenge.", "labels": [], "entities": [{"text": "Semantic Textual Similarity (STS) task", "start_pos": 4, "end_pos": 42, "type": "TASK", "confidence": 0.8149344750813076}]}, {"text": "Let sand t be two text snippets.", "labels": [], "entities": []}, {"text": "Determine the degree of equivalence \u03b1(s, t) | \u03b1 \u2208.", "labels": [], "entities": []}, {"text": "Whereas 0 represents complete independence, 5 reflects semantic equivalence.", "labels": [], "entities": []}, {"text": "The current edition) includes the monolingual ar-ar, en-en, and eses, as well as the cross-language ar-en, esen, and tr-enlanguage pairs.", "labels": [], "entities": []}, {"text": "We use the twoletter ISO 639-1 codes: ar=Arabic, en=English, es=Spanish, and tr=Turkish.", "labels": [], "entities": []}, {"text": "Multilinguality is the premise of the Lump approach: we use representations which lie towards language-independence as we aim to be able to approach similar tasks on other languages, paying the least possible effort.", "labels": [], "entities": []}, {"text": "Our regression model relies on different kinds of features, from simple length-based and lexical similarities to more sophisticated embeddings and deep neural net internal representations.", "labels": [], "entities": []}], "datasetContent": [{"text": "For training, we used all the annotated datasets released both in the current and in previous editions.", "labels": [], "entities": []}, {"text": "shows the size of the different language collections.", "labels": [], "entities": []}, {"text": "Note the important imbalance: there are more than ten times more instances available in en only than in the rest of languages.", "labels": [], "entities": []}, {"text": "We used the test set from the 2016 edition (only in English) as our internal test set.", "labels": [], "entities": []}, {"text": "Using the features in Sections 2.1 to 2.6, we train two regressors by: Sys1 learning one SVM per each language pair Sys2 learning one single SVM for all the language pairs together.", "labels": [], "entities": []}, {"text": "We experiment with a third system using all the extensions of Section 2.7 on XGBoost.", "labels": [], "entities": [{"text": "XGBoost", "start_pos": 77, "end_pos": 84, "type": "DATASET", "confidence": 0.9443688988685608}]}, {"text": "The purpose of this system is to analyse and compare different assumptions made for Sys1 and Sys2: Sys3 learning one single XGB for all the language pairs with an extended set of features.", "labels": [], "entities": []}, {"text": "shows the results of the three settings; including the average Pearson correlation for mono-and cross-language tracks.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 63, "end_pos": 82, "type": "METRIC", "confidence": 0.980960339307785}]}, {"text": "Comparing Sys1 and Sys2, we see that in the case of enen the best performance is obtained when training on en only.", "labels": [], "entities": []}, {"text": "Adding instances in other languages slightly confuses our regressor, but differences are small; the number of examples added is only a 30%.", "labels": [], "entities": []}, {"text": "Nevertheless, considering together different language pairs does help when dealing with less-represented pairs.", "labels": [], "entities": []}, {"text": "This is the case of ar-ar, es-es, and es-en where the inclusion of more than ten times more instances in other languages boosts the performance.", "labels": [], "entities": []}, {"text": "We did not observe this behaviour in the rest of language pairs.", "labels": [], "entities": []}, {"text": "The worst case is that of the surprise pair tr-en.", "labels": [], "entities": []}, {"text": "The reason could be that we could not compute all the features for these instances and instead, we used equivalents for en.", "labels": [], "entities": []}, {"text": "Regarding the performance of our models on mono-and cross-language pairs, considering one single classifier versus one per language pair makes no difference when dealing with monolingual instances.", "labels": [], "entities": []}, {"text": "This reflects the nature of the data: 82% of the training set is monolingual.", "labels": [], "entities": []}, {"text": "The story is different when dealing with crosslanguage instances.", "labels": [], "entities": []}, {"text": "Further experiments are necessary using one classifier with cross-language instances only.", "labels": [], "entities": []}, {"text": "Regarding Sys3, we observe a lost in performance with respect to Sys1 and Sys2, except for the tracks involving es.", "labels": [], "entities": []}, {"text": "The system introduces three variations with respect to Sys2: the learning model, the addition of several similarity measures for each representation, and the addition of new representations obtained after translating the input into en (es).", "labels": [], "entities": []}, {"text": "A deeper analysis shows that the performance drop is due to the learning algorithm.", "labels": [], "entities": []}, {"text": "XGBoost is performing better than SVM in our cross-validation.", "labels": [], "entities": [{"text": "XGBoost", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9099685549736023}]}, {"text": "However, the loss function we use is a mean squared error and the evaluation is done via Pearson correlation.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 89, "end_pos": 108, "type": "METRIC", "confidence": 0.9130156338214874}]}, {"text": "We attribute the discrepancy to this fact.", "labels": [], "entities": []}, {"text": "Still, except for en-en, the inclusion of the two families of features improves the results of the basic features set.", "labels": [], "entities": []}, {"text": "Gradient boosting methods allow to estimate the importance of each feature in a very natural way: the more a feature is used to take the decisions in the construction of the boosted trees, the more important it is.", "labels": [], "entities": []}, {"text": "The complete analysis is out of the scope of this paper, but some comments and remarks can be made in the light of their relative importance.", "labels": [], "entities": []}, {"text": "shows the relative importance of the features given by three XGBoost regressors: one trained only with en monolingual data, one for en-es cross-language data, and one for all the languages trained together.", "labels": [], "entities": []}, {"text": "The concrete distribution of features depends on the specific language pair, but the set {len, 2grm, (CL)ESA, lN MT , wN MT , BN sub, BN all} stands out among the full set.", "labels": [], "entities": []}, {"text": "Notice that language identifiers are not relevant at all for the joint model and the regressor practically neglects them.", "labels": [], "entities": []}, {"text": "In general, the internal representation of the neural network is more important for crosslanguage pairs and Babel embeddings are more relevant for monolingual pairs.", "labels": [], "entities": []}, {"text": "In the latter, we observe almost no difference between the relative importance of BN sub and BN all, confirming the assumption of the interlinguality of the embeddings.", "labels": [], "entities": []}, {"text": "(CL-)ESA is always among the most informative features.", "labels": [], "entities": []}, {"text": "Finally, the high contribution of two simple scores is worth noting: len and 2grm.", "labels": [], "entities": []}, {"text": "This comes at no surprise for len).", "labels": [], "entities": []}, {"text": "Regarding the n-grams similarity, in general {3, 4}-grams perform better in similar tasks (e.g., comparable corpora parallelisation (), but no important difference exist with respect to using 2-grams.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Instances provided in the history of STS. (  *  No", "labels": [], "entities": [{"text": "Instances", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9655324816703796}, {"text": "STS", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.729030430316925}]}, {"text": " Table 2: Official Pearson correlation performance for our", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 19, "end_pos": 38, "type": "METRIC", "confidence": 0.7280147969722748}]}]}