{"title": [{"text": "Oxford at SemEval-2017 Task 9: Neural AMR Parsing with Pointer-Augmented Attention", "labels": [], "entities": [{"text": "Neural AMR Parsing", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.7436031103134155}]}], "abstractContent": [{"text": "We present an end-to-end neural encoder-decoder AMR parser that extends an attention-based model by predicting the alignment between graph nodes and sentence tokens explicitly with a pointer mechanism.", "labels": [], "entities": [{"text": "AMR parser", "start_pos": 48, "end_pos": 58, "type": "TASK", "confidence": 0.7349784970283508}]}, {"text": "Candidate lemmas are predicted as a pre-processing step so that the lemmas of lexical concepts, as well as constant strings, are factored out of the graph linearization and recovered through the predicted alignments.", "labels": [], "entities": []}, {"text": "The approach does not rely on syntactic parses or extensive external resources.", "labels": [], "entities": []}, {"text": "Our parser obtained 59% Smatch on the SemEval test set.", "labels": [], "entities": [{"text": "Smatch", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9964068531990051}, {"text": "SemEval test set", "start_pos": 38, "end_pos": 54, "type": "DATASET", "confidence": 0.8812759319941202}]}], "introductionContent": [{"text": "The task of parsing sentences to Abstract Meaning Representation (AMR) ( has recently received increased attention.", "labels": [], "entities": [{"text": "parsing sentences to Abstract Meaning Representation (AMR)", "start_pos": 12, "end_pos": 70, "type": "TASK", "confidence": 0.7966286407576667}]}, {"text": "AMR represents sentence meaning with directed acyclic graphs (DAGs) with labelled nodes and edges.", "labels": [], "entities": []}, {"text": "No assumptions are made about the relation between an AMR and the structure of the sentence it represents: the representation is not assumed to have any relation to the sentence syntax, no alignments are given and no distinction is made between concepts that correspond directly to lexemes in the input sentences and those that don't.", "labels": [], "entities": []}, {"text": "This underspecification creates significant challenges for training an end-to-end AMR parser, which are exacerbated by the relatively small sizes of available training sets.", "labels": [], "entities": [{"text": "AMR parser", "start_pos": 82, "end_pos": 92, "type": "TASK", "confidence": 0.8760249018669128}]}, {"text": "Consequently most AMR parsers are pipelines that make extensive use of additional resources.", "labels": [], "entities": [{"text": "AMR parsers", "start_pos": 18, "end_pos": 29, "type": "TASK", "confidence": 0.9111526608467102}]}, {"text": "Neural encoder-decoders have previously been proposed for AMR parsing, but reported accuracies are well below the state-of-the-art (, even with sophisticated pre-processing and categorization (.", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 58, "end_pos": 69, "type": "TASK", "confidence": 0.9693410098552704}, {"text": "accuracies", "start_pos": 84, "end_pos": 94, "type": "METRIC", "confidence": 0.969299852848053}]}, {"text": "The end-to-end neural approach contrasts with approaches based on a pipeline of multiple LSTMs) or neural network classifiers inside a feature-and resource-rich parser (, which have performed competitively.", "labels": [], "entities": []}, {"text": "Our approach addresses these challenges in two ways: This first is to utilize (noisy) alignments, aligning each graph node to an input token.", "labels": [], "entities": []}, {"text": "The alignments are predicted explicitly by the neural decoder with a pointer network (, in addition to a standard attention mechanism.", "labels": [], "entities": []}, {"text": "Our second contribution is to introduce more structure in the AMR linearization by distinguishing between lexical and non-lexical concepts, noting that lexical concepts (excluding sense labels) can be predicted with high accuracy from their lemmas.", "labels": [], "entities": [{"text": "AMR linearization", "start_pos": 62, "end_pos": 79, "type": "TASK", "confidence": 0.9153530299663544}, {"text": "accuracy", "start_pos": 221, "end_pos": 229, "type": "METRIC", "confidence": 0.9821834564208984}]}, {"text": "The decoder predicts only delexicalized concepts, recovering the lexicalization through the lemmas corresponding to the predicted alignments.", "labels": [], "entities": []}, {"text": "Experiments show that our extensions increase parsing accuracy by a large margin over a standard attention-based model.", "labels": [], "entities": [{"text": "parsing", "start_pos": 46, "end_pos": 53, "type": "TASK", "confidence": 0.9785457849502563}, {"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9458506107330322}]}], "datasetContent": [{"text": "We train our models with the two AMR datasets provided for the shared task: LDC2016E25, a large corpus of newswire, weblog and discussion forum text with a training set of 35,498 sentences, and a smaller dataset in the biomedical domain (Bio AMR Corpus) with 5,542 training sentences.", "labels": [], "entities": [{"text": "AMR datasets", "start_pos": 33, "end_pos": 45, "type": "DATASET", "confidence": 0.7376981675624847}, {"text": "Bio AMR Corpus)", "start_pos": 238, "end_pos": 253, "type": "DATASET", "confidence": 0.7967884838581085}]}, {"text": "When training a parser for the biomedical domain with minibatch SGD, we sample Bio AMR sentences with a weight of 7 to each LDC sentence to balance the two sources in sampled minibatches.", "labels": [], "entities": []}, {"text": "Our models are implemented in TensorFlow (.", "labels": [], "entities": []}, {"text": "We train models with Adam ( with learning rate 0.01 and minibatch size 64.", "labels": [], "entities": [{"text": "learning rate 0.01", "start_pos": 33, "end_pos": 51, "type": "METRIC", "confidence": 0.9433773557345072}]}, {"text": "Gradients norms are clipped to 5.0 (.", "labels": [], "entities": [{"text": "Gradients", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9762360453605652}]}, {"text": "We use single-layer LSTMs with hidden state size 256, with dropout 0.3 on the input and output connections.", "labels": [], "entities": []}, {"text": "The encoder takes word embeddings of size 512, initialized (in the first 100 dimensions) with embeddings trained with a structured skip-gram model (, and POS and NE embeddings of size 32.", "labels": [], "entities": []}, {"text": "Singleton tokens are replaced with an unknown word symbol with probability 0.5 during training.", "labels": [], "entities": []}, {"text": "We compare our pointer-based architecture against an attention-based encoder-decoder that does not make use of alignments or external lexical resources.", "labels": [], "entities": []}, {"text": "We report results for two versions of this baseline: In the first, the input is purely word-based.", "labels": [], "entities": []}, {"text": "The second embeds named entity and POS embeddings in the encoder, and utilizes pre-trained word embeddings.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Resources used to predict candidate lemmas for different types of AMR outputs. The left-most  resource that has a prediction available is used.", "labels": [], "entities": [{"text": "AMR outputs", "start_pos": 76, "end_pos": 87, "type": "TASK", "confidence": 0.8395083844661713}]}, {"text": " Table 2: Development set results for the Bio AMR  corpus.", "labels": [], "entities": [{"text": "Bio AMR  corpus", "start_pos": 42, "end_pos": 57, "type": "DATASET", "confidence": 0.7153331637382507}]}, {"text": " Table 3: SemEval test set results on various met- rics, reported as rounded to the nearest percentage.", "labels": [], "entities": []}, {"text": " Table 4: Test set results for the Bio AMR and  LDC2016E25 corpora.", "labels": [], "entities": [{"text": "Bio AMR and  LDC2016E25 corpora", "start_pos": 35, "end_pos": 66, "type": "DATASET", "confidence": 0.7122874915599823}]}]}