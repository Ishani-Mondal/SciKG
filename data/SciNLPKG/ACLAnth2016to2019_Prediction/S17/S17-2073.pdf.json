{"title": [{"text": "JU_CSE_NLP at SemEval 2017 Task 7: Employing Rules to Detect and Interpret English Puns", "labels": [], "entities": [{"text": "JU_CSE_NLP at SemEval 2017 Task 7", "start_pos": 0, "end_pos": 33, "type": "DATASET", "confidence": 0.8103456258773803}, {"text": "Detect and Interpret English Puns", "start_pos": 54, "end_pos": 87, "type": "TASK", "confidence": 0.6629491090774536}]}], "abstractContent": [{"text": "The problem of detection and interpretation of English puns falls under the area of word sense disambiguation in natural language processing, which deals with the sense of a word used in a sentence from the readers' perspective.", "labels": [], "entities": [{"text": "detection and interpretation of English puns", "start_pos": 15, "end_pos": 59, "type": "TASK", "confidence": 0.7817225356896719}, {"text": "word sense disambiguation", "start_pos": 84, "end_pos": 109, "type": "TASK", "confidence": 0.7193355957667033}]}, {"text": "We have tried to design a system to identify puns from a sentence by developing a cyclic dependency-based system which is implemented based on some rules which are actually statistical inferences taken from a set of random data collected from the Web.", "labels": [], "entities": []}], "introductionContent": [{"text": "Extensive research has been done in the field of modelling and detecting puns.", "labels": [], "entities": [{"text": "modelling and detecting puns", "start_pos": 49, "end_pos": 77, "type": "TASK", "confidence": 0.8000770136713982}]}, {"text": "The context or the sense depends largely on the perspective and knowledge of the reader about a particular language.", "labels": [], "entities": []}, {"text": "For example, in the sentence, 'I was a banker but I lost interest,' the word in italics conveys two different meanings or 'senses' in the sentence.", "labels": [], "entities": []}, {"text": "So, the word 'interest' could be called a pun.", "labels": [], "entities": []}, {"text": "A pun is the exploitation of the various meanings of a word or words with phonetic similarity but different meanings.", "labels": [], "entities": []}, {"text": "Our system is a rule-based implementation of a dependency network and a hidden Markov model.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the present shared task, participants are provided with atrial dataset and a test dataset.", "labels": [], "entities": []}, {"text": "No training data was supplied due to the large cardinality of such words or contexts in general.", "labels": [], "entities": []}, {"text": "In case of the subtask on pun detection (Subtask 1), the test data was subdivided into two sets: a homographic set containing 2250 contexts, and a heterographic set containing 1780 contexts.", "labels": [], "entities": [{"text": "pun detection", "start_pos": 26, "end_pos": 39, "type": "TASK", "confidence": 0.707634761929512}]}, {"text": "On the other hand, in case of Subtask 2, another set of data was provided and that set was also subdivided into homographic and heterographic sets.", "labels": [], "entities": []}, {"text": "For training purposes, or rather to analyze the contexts statistically, a dataset was collected from random sources, mostly form Project Gutenberg and used in our present experiments.", "labels": [], "entities": []}, {"text": "This dataset contains 413 sentences and is not subdivided into homographic and heterographic subsets.", "labels": [], "entities": []}, {"text": "The given data containing English contexts is preprocessed and each word of a sentence is tagged with its part of speech using NLTK, an open-source package for NLP written in Python.", "labels": [], "entities": []}, {"text": "For example, the sentence, 'I was a banker but I lost interest.' is tagged using the Stanford NLP parser as follows: [('I', 'PRP'), ('was', 'VBD'), ('a', 'DT'), ('banker', 'NN'), ('but', 'CC'), ('I', 'PRP'), ('lost', 'VBD'), ('interest', 'NN'), ('.', '.')]", "labels": [], "entities": []}, {"text": "We also generate the parse tree for the sentence, which looks as in.", "labels": [], "entities": []}, {"text": "Using such parse trees, the clauses are identified and used for our further tasks.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Pun probability by part of speech.", "labels": [], "entities": [{"text": "Pun probability", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.7328571081161499}]}, {"text": " Table 2: Pun probability by POS of previous word.", "labels": [], "entities": [{"text": "Pun probability", "start_pos": 10, "end_pos": 25, "type": "METRIC", "confidence": 0.9341292679309845}, {"text": "POS", "start_pos": 29, "end_pos": 32, "type": "METRIC", "confidence": 0.9752829074859619}]}, {"text": " Table 3: Pun probability by POS of next word.", "labels": [], "entities": [{"text": "Pun probability", "start_pos": 10, "end_pos": 25, "type": "METRIC", "confidence": 0.9282256364822388}, {"text": "POS", "start_pos": 29, "end_pos": 32, "type": "METRIC", "confidence": 0.9861109256744385}]}, {"text": " Table 4: Results on Subtask 1.", "labels": [], "entities": [{"text": "Subtask 1", "start_pos": 21, "end_pos": 30, "type": "TASK", "confidence": 0.9453049004077911}]}, {"text": " Table 5: Results on Subtask 2.", "labels": [], "entities": [{"text": "Subtask 2", "start_pos": 21, "end_pos": 30, "type": "TASK", "confidence": 0.9167483150959015}]}]}