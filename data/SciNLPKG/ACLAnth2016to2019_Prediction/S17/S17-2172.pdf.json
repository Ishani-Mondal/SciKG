{"title": [{"text": "Investigating Embeddings for End-to-End Relation Extraction from Scientific Papers", "labels": [], "entities": [{"text": "End-to-End Relation Extraction", "start_pos": 29, "end_pos": 59, "type": "TASK", "confidence": 0.7763246595859528}]}], "abstractContent": [{"text": "This paper describes our TTI-COIN system that participated in SemEval-2017 Task 10.", "labels": [], "entities": [{"text": "SemEval-2017 Task 10", "start_pos": 62, "end_pos": 82, "type": "TASK", "confidence": 0.8438171943028768}]}, {"text": "We investigated appropriate em-beddings to adapt a neural end-to-end entity and relation extraction system LSTM-ER to this task.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.7130979150533676}]}, {"text": "We participated in the full task setting of the entity segmentation, entity classification and relation classification (scenario 1) and the setting of relation classification only (scenario 3).", "labels": [], "entities": [{"text": "entity segmentation", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.7275053262710571}, {"text": "entity classification", "start_pos": 69, "end_pos": 90, "type": "TASK", "confidence": 0.7602546215057373}, {"text": "relation classification", "start_pos": 95, "end_pos": 118, "type": "TASK", "confidence": 0.7469727993011475}, {"text": "relation classification", "start_pos": 151, "end_pos": 174, "type": "TASK", "confidence": 0.7499010860919952}]}, {"text": "The system was directly applied to the scenario 1 without modifying the codes thanks to its generality and flexibility.", "labels": [], "entities": []}, {"text": "Our evaluation results show that the choice of appropriate pre-trained embeddings affected the performance significantly.", "labels": [], "entities": []}, {"text": "With the best em-beddings, our system was ranked third in the scenario 1 with the micro F1 score of 0.38.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.8685034215450287}]}, {"text": "We also confirm that our system can produce the micro F1 score of 0.48 for the scenario 3 on the test data, and this score is close to the score of the 3rd ranked system in the task.", "labels": [], "entities": [{"text": "micro F1 score", "start_pos": 48, "end_pos": 62, "type": "METRIC", "confidence": 0.8075078129768372}]}], "introductionContent": [{"text": "Semantic relationships between entities are useful for building knowledge bases and semantic search engines.", "labels": [], "entities": []}, {"text": "Their automatic extraction has been widely studied in the natural language processing (NLP) field (.) deals with relation extraction from scientific papers.", "labels": [], "entities": [{"text": "automatic extraction", "start_pos": 6, "end_pos": 26, "type": "TASK", "confidence": 0.7677704393863678}, {"text": "relation extraction from scientific papers", "start_pos": 113, "end_pos": 155, "type": "TASK", "confidence": 0.8827644109725952}]}, {"text": "While entity detection and relation extraction have often been treated as separate tasks, several studies show that joint treatment of these tasks can improve extraction performance on both tasks ().", "labels": [], "entities": [{"text": "entity detection", "start_pos": 6, "end_pos": 22, "type": "TASK", "confidence": 0.8303150832653046}, {"text": "relation extraction", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.8221676051616669}]}, {"text": "We employed the state-of-the-art neural network-based end-to-end entity and relation extraction system LSTM-ER 1.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 76, "end_pos": 95, "type": "TASK", "confidence": 0.7322506010532379}]}, {"text": "The model of the system is built on pre-trained word embeddings, and it has a tree-structured bidirectional long short-term memory-based recurrent neural network (LSTM-RNN) layer stacked on a sequential bidirectional LSTM-RNN layer.", "labels": [], "entities": []}, {"text": "It predicts entities and relations in an end-to-end manner with shared parameters, and the parameters in word embeddings and both LSTM-RNNs are updated simultaneously during training.", "labels": [], "entities": []}, {"text": "We first checked the applicability of the system in our evaluation.", "labels": [], "entities": []}, {"text": "The system was originally developed for ACE (automatic content extraction) corpora, but it does not depend on specific tasks and has high configurability) since it prepares a separate configuration file, where task specific settings like hyperparameters can be specified.", "labels": [], "entities": [{"text": "ACE (automatic content extraction) corpora", "start_pos": 40, "end_pos": 82, "type": "TASK", "confidence": 0.6642306787627084}]}, {"text": "The system was successfully applied to the end-to-end relation extraction setting (scenario 1 in the task) without modifying the original codes in our experiments, although small modifications to the inputs were required.", "labels": [], "entities": [{"text": "relation extraction setting", "start_pos": 54, "end_pos": 81, "type": "TASK", "confidence": 0.7829559842745463}]}, {"text": "This shows the generality of the system.", "labels": [], "entities": []}, {"text": "Using this system, we also investigated how the pre-trained word embeddings affect the overall performance.", "labels": [], "entities": []}, {"text": "mostly focused on the model architectures and paid little attention to the differences in pre-trained embeddings.", "labels": [], "entities": []}, {"text": "Our results show that selecting the appropriate initial embeddings is crucial since changing the pre-trained embeddings greatly affected the overall performance.", "labels": [], "entities": []}], "datasetContent": [{"text": "Pre-trained word embeddings: We obtained pretrained word embeddings by the skip-gram model and the structured skip-gram model with the same setting.", "labels": [], "entities": []}, {"text": "We set the window size to 2, the number of negative samples to 10, the down-sampling rate to 1e-4.", "labels": [], "entities": []}, {"text": "We also ignored the words that appear less than 26 times.", "labels": [], "entities": []}, {"text": "Other parameters are kept as the default of the original word2vec toolkit . POS tagging and dependency parsing: To deal with the data with the LSTM-ER system, we obtained POS tags and dependency trees for all training, development and test data sets by using the Stanford parser).", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 76, "end_pos": 87, "type": "TASK", "confidence": 0.7822778820991516}, {"text": "dependency parsing", "start_pos": 92, "end_pos": 110, "type": "TASK", "confidence": 0.7060522586107254}]}, {"text": "Since the texts contained Unicode, we processed the data as Unicode texts.", "labels": [], "entities": []}, {"text": "Relation modification: We treated each relation as a directed relation.", "labels": [], "entities": [{"text": "Relation modification", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9435254037380219}]}, {"text": "The Synonym-of relations are undirected, but we treated them as they always have left-to-right directions.", "labels": [], "entities": []}, {"text": "Out-of-vocabulary words: For the robustness, we treated out-of-vocabulary words as follows.", "labels": [], "entities": []}, {"text": "We first counted the frequencies of words in the training dataset.", "labels": [], "entities": []}, {"text": "We then picked up words that only appear once in the training dataset and replaced 1% of them with a symbol word \"UNK\" randomly.", "labels": [], "entities": [{"text": "training dataset", "start_pos": 53, "end_pos": 69, "type": "DATASET", "confidence": 0.6646588891744614}, {"text": "UNK", "start_pos": 114, "end_pos": 117, "type": "METRIC", "confidence": 0.489906370639801}]}, {"text": "Embeddings for the words that do not appear in the vocabulary of pre-trained embed-: Micro F1 scores on the development and the test dataset for three task settings: subtask A, subtask A,B, and subtask C.", "labels": [], "entities": [{"text": "Micro", "start_pos": 85, "end_pos": 90, "type": "METRIC", "confidence": 0.8876034617424011}, {"text": "F1", "start_pos": 91, "end_pos": 93, "type": "METRIC", "confidence": 0.5147644281387329}]}, {"text": "The number in the parentheses for Rel (PubMed) shows our official score.: Results on the end-to-end model with several pre-trained word vectors.", "labels": [], "entities": [{"text": "Rel (PubMed)", "start_pos": 34, "end_pos": 46, "type": "DATASET", "confidence": 0.830013632774353}]}], "tableCaptions": [{"text": " Table 1: Dimensions of layers.", "labels": [], "entities": []}, {"text": " Table 2: Micro F1 scores on the development and the test dataset for three task settings: subtask A,  subtask A,B, and subtask C. The number in the parentheses for Rel (PubMed) shows our official score.", "labels": [], "entities": [{"text": "F1", "start_pos": 16, "end_pos": 18, "type": "METRIC", "confidence": 0.7908163070678711}, {"text": "Rel (PubMed)", "start_pos": 165, "end_pos": 177, "type": "DATASET", "confidence": 0.8736879676580429}]}, {"text": " Table 3: Results on the end-to-end model with several pre-trained word vectors.", "labels": [], "entities": []}]}