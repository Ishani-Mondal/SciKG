{"title": [{"text": "Logical Metonymy in a Distributional Model of Sentence Comprehension", "labels": [], "entities": [{"text": "Distributional Model of Sentence Comprehension", "start_pos": 22, "end_pos": 68, "type": "TASK", "confidence": 0.7084929466247558}]}], "abstractContent": [{"text": "In theoretical linguistics, logical metonymy is defined as the combination of an event-subcategorizing verb with an entity-denoting direct object (e.g., The author began the book), so that the interpretation of the VP requires the retrieval of a covert event (e.g., writing).", "labels": [], "entities": []}, {"text": "Psycholinguistic studies have revealed extra processing costs for logical metonymy, a phenomenon generally explained with the introduction of new semantic structure.", "labels": [], "entities": []}, {"text": "In this paper, we present a general distributional model for sentence comprehension inspired by the Memory, Unification and Control model by Hagoort (2013, 2016).", "labels": [], "entities": []}, {"text": "We show that our distributional framework can account for the extra processing costs of logical metonymy and can identify the covert event in a classification task.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "We used two datasets created for previous psycholinguistic studies: the McElree dataset) and the Traxler dataset ().", "labels": [], "entities": [{"text": "McElree dataset", "start_pos": 72, "end_pos": 87, "type": "DATASET", "confidence": 0.9717782139778137}, {"text": "Traxler dataset", "start_pos": 97, "end_pos": 112, "type": "DATASET", "confidence": 0.856653094291687}]}, {"text": "Each dataset compared three different experimental conditions, by contrasting constructions requiring a type-shift with constructions requiring normal composition: a.", "labels": [], "entities": []}, {"text": "The author was starting the book. b. The author was writing the book. c. The author was reading the book.", "labels": [], "entities": []}, {"text": "Sentence (2-a) corresponds to the metonymic condition (MET), while sentences (2-b) and (2-c) correspond to non-metonymic constructions, with the difference that (2-b) represents atypical event given the subject and the object (HIGH TYP), whereas (2-c) expresses a plausible but less typical event (LOW TYP).", "labels": [], "entities": [{"text": "metonymic condition (MET)", "start_pos": 34, "end_pos": 59, "type": "METRIC", "confidence": 0.6325221717357635}, {"text": "HIGH TYP)", "start_pos": 227, "end_pos": 236, "type": "METRIC", "confidence": 0.8746950626373291}, {"text": "LOW TYP)", "start_pos": 298, "end_pos": 306, "type": "METRIC", "confidence": 0.9292113184928894}]}, {"text": "The McElree dataset was created for the self-paced reading study by, and includes 99 sentences (33 triplets), while the Traxler dataset was used in the eye-tracking experiment by and contains 108 sentences (36 triplets).", "labels": [], "entities": [{"text": "McElree dataset", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.9839804470539093}, {"text": "Traxler dataset", "start_pos": 120, "end_pos": 135, "type": "DATASET", "confidence": 0.9376033842563629}]}], "tableCaptions": [{"text": " Table 4: Accuracy of model components and random base- line on the binary classification task for covert event retrieval.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9741743803024292}, {"text": "covert event retrieval", "start_pos": 99, "end_pos": 121, "type": "TASK", "confidence": 0.7636540134747823}]}]}