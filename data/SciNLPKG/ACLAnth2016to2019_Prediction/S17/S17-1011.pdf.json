{"title": [{"text": "Frame-Based Continuous Lexical Semantics through Exponential Family Tensor Factorization and Semantic Proto-Roles", "labels": [], "entities": [{"text": "Exponential Family Tensor Factorization", "start_pos": 49, "end_pos": 88, "type": "TASK", "confidence": 0.7029631957411766}]}], "abstractContent": [{"text": "We study how different frame annotations complement one another when learning continuous lexical semantics.", "labels": [], "entities": []}, {"text": "We learn the representations from a tensorized skip-gram model that consistently encodes syntactic-semantic content better, with multiple 10% gains over baselines.", "labels": [], "entities": []}], "introductionContent": [{"text": "Consider \"Bill\" in: what is his involvement with the words \"would try,\" and what does this involvement mean?", "labels": [], "entities": []}, {"text": "Word embeddings represent such meaning as points in a real-valued vector space).", "labels": [], "entities": []}, {"text": "These representations are often learned by exploiting the frequency that the word cooccurs with contexts, often within a user-defined window.", "labels": [], "entities": []}, {"text": "When built from large-scale sources, like Wikipedia or web crawls, embeddings capture general characteristics of words and allow for robust downstream applications.", "labels": [], "entities": []}, {"text": "Frame semantics generalize word meanings to that of analyzing structured and interconnected labeled \"concepts\" and abstractions.", "labels": [], "entities": []}, {"text": "These concepts, or roles, implicitly encode expected properties of that word.", "labels": [], "entities": []}, {"text": "Ina frame semantic analysis of, the segment \"would try\" triggers the ATTEMPT frame, filling the expected roles AGENT and GOAL with \"Bill\" and \"the same tactic,\" respectively.", "labels": [], "entities": [{"text": "ATTEMPT", "start_pos": 69, "end_pos": 76, "type": "METRIC", "confidence": 0.9724562764167786}, {"text": "AGENT", "start_pos": 111, "end_pos": 116, "type": "METRIC", "confidence": 0.9920469522476196}, {"text": "GOAL", "start_pos": 121, "end_pos": 125, "type": "METRIC", "confidence": 0.9499497413635254}, {"text": "Bill", "start_pos": 132, "end_pos": 136, "type": "METRIC", "confidence": 0.9239366054534912}]}, {"text": "While frame semantics provide a structured form for analyzing words with crisp, categorically-labeled concepts, the encoded properties and expectations are implicit.", "labels": [], "entities": []}, {"text": "What does it mean to fill a frame's role?", "labels": [], "entities": []}, {"text": "Semantic proto-role (SPR) theory, motivated by's thematic proto-role theory, offers an answer to this.", "labels": [], "entities": [{"text": "Semantic proto-role (SPR) theory", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.761541873216629}]}, {"text": "SPR replaces categorical roles ATTEMPT She said Bill would try the same tactic again. with judgements about multiple underlying properties about what is likely true of the entity filling the role.", "labels": [], "entities": [{"text": "SPR", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8426720499992371}, {"text": "ATTEMPT", "start_pos": 31, "end_pos": 38, "type": "METRIC", "confidence": 0.9857886433601379}]}, {"text": "For example, SPR talks about how likely it is for Bill to be a willing participant in the ATTEMPT.", "labels": [], "entities": [{"text": "SPR", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.7563179731369019}, {"text": "ATTEMPT", "start_pos": 90, "end_pos": 97, "type": "DATASET", "confidence": 0.4674093723297119}]}, {"text": "The answer to this and other simple judgments characterize Bill and his involvement.", "labels": [], "entities": []}, {"text": "Since SPR both captures the likelihood of certain properties and characterizes roles as groupings of properties, we can view SPR as representing a type of continuous frame semantics.", "labels": [], "entities": []}, {"text": "We are interested in capturing these SPR-based properties and expectations within word embeddings.", "labels": [], "entities": []}, {"text": "We present a method that learns frameenriched embeddings from millions of documents that have been semantically parsed with multiple different frame analyzers).", "labels": [], "entities": []}, {"text": "Our method leverages's formulation of's popular skip-gram model as exponential family principal component analysis (EPCA) and tensor factorization.", "labels": [], "entities": []}, {"text": "This paper's primary contributions are: (i) enriching learned word embeddings with multiple, automatically obtained frames from large, disparate corpora; and (ii) demonstrating these enriched embeddings better capture SPR-based properties.", "labels": [], "entities": []}, {"text": "In so doing, we also generalize Cotterell et al.'s method to arbitrary tensor dimensions.", "labels": [], "entities": []}, {"text": "This allows us to include an arbitrary amount of semantic information when learning embeddings.", "labels": [], "entities": []}, {"text": "Our variable-size tensor factorization code is available at https://github.com/ fmof/tensor-factorization.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our end goal is to use multiple kinds of automatically obtained, \"in-the-wild\" frame se-mantic parses in order to improve the semantic content-specifically SPR-type informationwithin learned lexical embeddings.", "labels": [], "entities": [{"text": "SPR-type informationwithin learned lexical embeddings", "start_pos": 156, "end_pos": 209, "type": "TASK", "confidence": 0.701342499256134}]}, {"text": "We utilize majority portions of the Concretely Annotated New York Times and Wikipedia corpora from.", "labels": [], "entities": [{"text": "Concretely Annotated New York Times and Wikipedia corpora", "start_pos": 36, "end_pos": 93, "type": "DATASET", "confidence": 0.7803597263991833}]}, {"text": "These have been annotated with three frame semantic parses: FrameNet from, and both FrameNet and PropBank from.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 97, "end_pos": 105, "type": "DATASET", "confidence": 0.8674089908599854}]}, {"text": "In total, we use nearly five million frame-annotated documents.", "labels": [], "entities": []}, {"text": "Extracting Counts The baseline extraction we consider is a standard sliding window: for each word w j seen \u2265 T times, extract all words w i two to the left and right of w j . These counts, forming a matrix, are then used within standard word2vec.", "labels": [], "entities": []}, {"text": "We also follow and augment the above with the signed number of tokens separating w i and w j , e.g., recording that w i appeared two to the left of w j ; these counts form a 3-tensor.", "labels": [], "entities": []}, {"text": "To turn semantic parses into tensor counts, we first identify relevant information from the parses.", "labels": [], "entities": []}, {"text": "We consider all parses that are triggered by the target word w j (seen \u2265 T times) and that have at least one role filled by some word in the sentence.", "labels": [], "entities": []}, {"text": "We organize the extraction around roles and what fills them.", "labels": [], "entities": []}, {"text": "We extract every word w r that fills all possible triggered frames; each of those frame and role labels; and the distance between filler w rand trigger w j . This process yields a 9-tensor X.", "labels": [], "entities": []}, {"text": "3 Although we always treat the trigger as the \"original\" word (e.g., word j, with vector w j ), later we consider (1) what to include from X, (2) what to predict (what to treat as the \"context\" word i), and what to treat as auxiliary features.", "labels": [], "entities": []}, {"text": "Data Discussion The baseline extraction methods result in roughly symmetric target and surrounding word counts.", "labels": [], "entities": []}, {"text": "This is not the case for the frame extraction.", "labels": [], "entities": [{"text": "frame extraction", "start_pos": 29, "end_pos": 45, "type": "TASK", "confidence": 0.8538237512111664}]}, {"text": "Our target words must trigger some semantic parse, so our target words are actually target triggers.", "labels": [], "entities": []}, {"text": "However, the surrounding context words are those words that fill semantic roles.", "labels": [], "entities": []}, {"text": "As shown in, there are an order-of-magnitude fewer triggers than target words, but up to an order-of-magnitude more surrounding words.", "labels": [], "entities": []}, {"text": "Implementation We generalize to enable any arbitrary dimensional tensor factorization, as described in \u00a73.2.", "labels": [], "entities": []}, {"text": "We learn 100-dimensional embeddings for words that appear at least 100 times from 15 negative samples.", "labels": [], "entities": []}, {"text": "The implementation is available at https://github.", "labels": [], "entities": []}, {"text": "com/fmof/tensor-factorization.", "labels": [], "entities": []}, {"text": "Metric We evaluate our learned (trigger) embeddings w via QVEC ().", "labels": [], "entities": []}, {"text": "QVEC uses canonical correlation analysis to measure the Pearson correlation between wand a collection of oracle lexical vectors o.", "labels": [], "entities": [{"text": "QVEC", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9486377239227295}, {"text": "Pearson correlation", "start_pos": 56, "end_pos": 75, "type": "METRIC", "confidence": 0.9654538035392761}]}, {"text": "These oracle vectors are derived from a human-annotated resource.", "labels": [], "entities": []}, {"text": "For QVEC, higher is better: a higher score indicates w more closely correlates (positively) with o.  relations nsubj, dobj, iobj and nsubjpass-result in 80-dimensional oracle vectors.", "labels": [], "entities": []}, {"text": "Since SPR judgments are between predicates and arguments, we predict the words filling the roles, and treat all other frame information as auxiliary features.", "labels": [], "entities": [{"text": "SPR judgments", "start_pos": 6, "end_pos": 19, "type": "TASK", "confidence": 0.9322764277458191}]}, {"text": "SPR annotations were originally based off of (gold-standard) PropBank annotations, so we also train a model to predict PropBank frames and roles, thereby treating role-filling text and all other frame information as auxiliary features.", "labels": [], "entities": [{"text": "SPR annotations", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.9137563407421112}]}, {"text": "In early experiments, we found it beneficial to treat the FrameNet annotations additively and not distinguish one system's output from another.", "labels": [], "entities": []}, {"text": "Treating the annotations additively serves as a type of collapsing operation.", "labels": [], "entities": []}, {"text": "Although X started as a 9-tensor, we only consider up to 6-tensors: trigger, role filler, token separation between the trigger and filler, PropBank frame and role, FrameNet frame, and FrameNet role.", "labels": [], "entities": []}, {"text": "Results shows the overall percent change for SPR-QVEC from the filler and role prediction models, on newswire and Wikipedia, across different ablation models.", "labels": [], "entities": [{"text": "SPR-QVEC", "start_pos": 45, "end_pos": 53, "type": "TASK", "confidence": 0.756122887134552}, {"text": "role prediction", "start_pos": 74, "end_pos": 89, "type": "TASK", "confidence": 0.6753907650709152}]}, {"text": "We indicate additional contextual features being used with a +: sep uses the token separation distance between the frame and role filler, fn-frame uses FrameNet frames, fn-role uses FrameNet roles, filler uses the tokens filling the frame role, and none indicates no additional information is used when predicting.", "labels": [], "entities": []}, {"text": "The 0 line represents a plain word2vec baseline and the dashed line represents the 3-tensor baseline of.", "labels": [], "entities": []}, {"text": "Both of these baselines are windowed: they are restricted to a local context and cannot take advantage of frames or any lexical signal that can be derived from frames.", "labels": [], "entities": []}, {"text": "Overall, we notice that we obtain large improvements from models trained on lexical signals that have been derived from frame output (sep and none), even if the model itself does not incorporate any frame labels.", "labels": [], "entities": []}, {"text": "The embeddings that predict the role filling lexical items (the green triangles) correlate higher with SPR oracles than the embeddings that predict PropBank frames and roles (red circles)., we see that both model types outperform both the baselines in nearly all model configurations and ablations.", "labels": [], "entities": []}, {"text": "We seethe highest improvement when predicting role fillers given the frame trigger and the number of tokens separating the two (the green triangles in the sep rows).", "labels": [], "entities": [{"text": "predicting role fillers", "start_pos": 35, "end_pos": 58, "type": "TASK", "confidence": 0.7311115165551504}]}, {"text": "Comparing to, we see newswire is more amenable to predicting PropBank frames and roles.", "labels": [], "entities": [{"text": "predicting PropBank frames", "start_pos": 50, "end_pos": 76, "type": "TASK", "confidence": 0.661733349164327}]}, {"text": "We posit this is a type of out-ofdomain error, as the PropBank parser was trained on newswire.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 54, "end_pos": 62, "type": "DATASET", "confidence": 0.9225693941116333}]}, {"text": "We also find that newswire is overall more amenable to incorporating limited framebased features, particularly when predicting PropBank using lexical role fillers as part of the con-  textual features.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 127, "end_pos": 135, "type": "DATASET", "confidence": 0.7387229800224304}]}, {"text": "We hypothesize this is due to the significantly increased vocabulary size of the Wikipedia role fillers (c.f., Tab. 1).", "labels": [], "entities": []}, {"text": "Note, however, that by using all available schema information when predicting PropBank, we are able to compensate for the increased vocabulary.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 78, "end_pos": 86, "type": "DATASET", "confidence": 0.8484469652175903}]}, {"text": "In we display the ten nearest neighbors for three randomly sampled trigger words according to two of the highest performing newswire models.", "labels": [], "entities": []}, {"text": "They each condition on the trigger and the role filler/trigger separation; these correspond to the sep rows of.", "labels": [], "entities": [{"text": "role filler/trigger separation", "start_pos": 43, "end_pos": 73, "type": "TASK", "confidence": 0.6809948444366455}]}, {"text": "The left column of predicts the role filler, while the right column predicts PropBank annotations.", "labels": [], "entities": [{"text": "role filler", "start_pos": 32, "end_pos": 43, "type": "TASK", "confidence": 0.8529960811138153}, {"text": "PropBank", "start_pos": 77, "end_pos": 85, "type": "DATASET", "confidence": 0.9264312386512756}]}, {"text": "We see that while both models learn inflectional relations, this quality is prominent in the model that predicts PropBank information while the model predicting role fillers learns more non-inflectional paraphrases.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 113, "end_pos": 121, "type": "DATASET", "confidence": 0.7944786548614502}]}], "tableCaptions": [{"text": " Table 1: Vocabulary sizes, in thousands, extracted from Fer- raro et al. (2014)'s data with both the standard sliding context  window approach ( \u00a73) and the frame-based approach ( \u00a74).  Upper numbers (Roman) are for newswire; lower numbers  (italics) are Wikipedia. For both corpora, 800 total FrameNet  frame types and 5100 PropBank frame types are extracted.", "labels": [], "entities": []}]}