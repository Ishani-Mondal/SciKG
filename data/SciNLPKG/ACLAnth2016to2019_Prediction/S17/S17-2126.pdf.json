{"title": [{"text": "DataStories at SemEval-2017 Task 4: Deep LSTM with Attention for Message-level and Topic-based Sentiment Analysis", "labels": [], "entities": [{"text": "Topic-based Sentiment Analysis", "start_pos": 83, "end_pos": 113, "type": "TASK", "confidence": 0.6483228405316671}]}], "abstractContent": [{"text": "In this paper we present two deep-learning systems that competed at SemEval-2017 Task 4 \"Sentiment Analysis in Twitter\".", "labels": [], "entities": [{"text": "SemEval-2017 Task 4", "start_pos": 68, "end_pos": 87, "type": "TASK", "confidence": 0.8242502411206564}, {"text": "Sentiment Analysis in Twitter", "start_pos": 89, "end_pos": 118, "type": "TASK", "confidence": 0.8577041476964951}]}, {"text": "We participated in all subtasks for En-glish tweets, involving message-level and topic-based sentiment polarity classification and quantification.", "labels": [], "entities": [{"text": "topic-based sentiment polarity classification", "start_pos": 81, "end_pos": 126, "type": "TASK", "confidence": 0.6353369131684303}]}, {"text": "We use Long Short-Term Memory (LSTM) networks augmented with two kinds of attention mechanisms, on top of word embeddings pre-trained on a big collection of Twitter messages.", "labels": [], "entities": []}, {"text": "Also, we present a text processing tool suitable for social network messages , which performs tokenization, word normalization, segmentation and spell correction.", "labels": [], "entities": [{"text": "word normalization", "start_pos": 108, "end_pos": 126, "type": "TASK", "confidence": 0.763303816318512}, {"text": "spell correction", "start_pos": 145, "end_pos": 161, "type": "TASK", "confidence": 0.7227697372436523}]}, {"text": "Moreover, our approach uses no hand-crafted features or sentiment lexicons.", "labels": [], "entities": []}, {"text": "We ranked 1 st (tie) in Subtask A, and achieved very competitive results in the rest of the Subtasks.", "labels": [], "entities": []}, {"text": "Both the word embeddings and our text processing tool 1 are available to the research community.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sentiment analysis is an area in Natural Language Processing (NLP), studying the identification and quantification of the sentiment expressed in text.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9466032981872559}, {"text": "Natural Language Processing (NLP)", "start_pos": 33, "end_pos": 66, "type": "TASK", "confidence": 0.6810367852449417}, {"text": "identification and quantification of the sentiment expressed in text", "start_pos": 81, "end_pos": 149, "type": "TASK", "confidence": 0.87400750319163}]}, {"text": "Sentiment analysis in Twitter is a particularly challenging task, because of the informal and \"creative\" writing style, with improper use of grammar, figurative language, misspellings and slang.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9581795930862427}]}, {"text": "In previous runs of the Task, sentiment analysis was usually tackled using hand-crafted features and/or sentiment lexicons (, feeding them to classifiers such as Naive Bayes or Support Vector Machines (SVM).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.9565182030200958}]}, {"text": "These approaches require a laborious github.com/cbaziotis/ekphrasis feature-engineering process, which may also need domain-specific knowledge, usually resulting both in redundant and missing features.", "labels": [], "entities": []}, {"text": "Whereas, artificial neural networks () which perform feature learning, last year () achieved very good results, outperforming the competition.", "labels": [], "entities": []}, {"text": "In this paper, we present two deep-learning systems that competed at).", "labels": [], "entities": []}, {"text": "Our first model is designed for addressing the problem of messagelevel sentiment analysis.", "labels": [], "entities": [{"text": "messagelevel sentiment analysis", "start_pos": 58, "end_pos": 89, "type": "TASK", "confidence": 0.8828240434328715}]}, {"text": "We employ a 2-layer Bidirectional LSTM, equipped with an attention mechanism ().", "labels": [], "entities": []}, {"text": "For the topic-based sentiment analysis tasks, we propose a Siamese Bidirectional LSTM with a contextaware attention mechanism (.", "labels": [], "entities": [{"text": "topic-based sentiment analysis", "start_pos": 8, "end_pos": 38, "type": "TASK", "confidence": 0.6622182528177897}]}, {"text": "In contrast to top-performing systems of previous years, we do not rely on hand-crafted features, sentiment lexicons and we do not use model ensembles.", "labels": [], "entities": []}, {"text": "We make the following contributions: \u2022 A text processing tool for text tokenization, word normalization, word segmentation and spell correction, geared towards Twitter.", "labels": [], "entities": [{"text": "text tokenization", "start_pos": 66, "end_pos": 83, "type": "TASK", "confidence": 0.6527417004108429}, {"text": "word normalization", "start_pos": 85, "end_pos": 103, "type": "TASK", "confidence": 0.7865096032619476}, {"text": "word segmentation", "start_pos": 105, "end_pos": 122, "type": "TASK", "confidence": 0.7788963913917542}, {"text": "spell correction", "start_pos": 127, "end_pos": 143, "type": "TASK", "confidence": 0.705274224281311}]}, {"text": "\u2022 A deep learning system for short-text sentiment analysis using an attention mechanism, in order to enforce the contribution of words that determine the sentiment of a message.", "labels": [], "entities": [{"text": "short-text sentiment analysis", "start_pos": 29, "end_pos": 58, "type": "TASK", "confidence": 0.7972104748090109}]}, {"text": "\u2022 A deep learning system for topic-based sentiment analysis, with a context-aware attention mechanism utilizing the topic information.", "labels": [], "entities": [{"text": "topic-based sentiment analysis", "start_pos": 29, "end_pos": 59, "type": "TASK", "confidence": 0.8216786980628967}]}], "datasetContent": [{"text": "Our official ranking () is 1/38 (tie) in Subtask A, 2/24 in Subtask B, 2/16 in Subtask C, 2/16 in Subtask D and 11/12 in Subtask E. All of our models performed very good, with the exception of Subtask E. Since the quantification was performed on top of the classifier of Subtask C, which came in 2 nd place, we conclude that our quantification approach was the reason for the bad results for Subtask E. Attention Mechanism.", "labels": [], "entities": []}, {"text": "In order to assess the impact of the attention mechanisms, we evaluated the performance of each model, with and without attention.", "labels": [], "entities": []}, {"text": "We report) the average scores of 10 runs for each system, on the official test set.", "labels": [], "entities": [{"text": "official test set", "start_pos": 65, "end_pos": 82, "type": "DATASET", "confidence": 0.8059668143590292}]}, {"text": "The attention-based models performed better, but only by a small margin.", "labels": [], "entities": []}, {"text": "To get a better insight into the quantification approaches, we compare the performance of CC and PCC.", "labels": [], "entities": []}, {"text": "It is inconclusive as to which quantification approach is better.", "labels": [], "entities": []}, {"text": "PCC outperformed CC in () but underperformed CC in (.", "labels": [], "entities": [{"text": "PCC", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9238214492797852}]}, {"text": "Following the results from (, which are reported on sentiment analysis in twitter, we decided to use PCC for both of our 3 \u03c1 is the average recall and F 1 pn the macro-average F1 score of the positive and negative classes quantification submissions.", "labels": [], "entities": [{"text": "recall", "start_pos": 140, "end_pos": 146, "type": "METRIC", "confidence": 0.9792363047599792}, {"text": "F1 score", "start_pos": 176, "end_pos": 184, "type": "METRIC", "confidence": 0.9532889127731323}]}, {"text": "shows the performance of our models.", "labels": [], "entities": []}, {"text": "PCC performed better than CC for Subtask D but far worse than CC for Subtask E. We hypothesize that two possible reasons for the difference in performance between D and E, might be (1) the difference in the number of classes and (2) the big change in the ratio of posto-neg classes between the training and test sets.", "labels": [], "entities": [{"text": "PCC", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8296690583229065}]}], "tableCaptions": [{"text": " Table 2: Dataset statistics. Notice the difference in the ratio of positive-negative classes this year.", "labels": [], "entities": []}, {"text": " Table 3: Results of the impact of attention 3 .", "labels": [], "entities": []}, {"text": " Table 4: Results of the quantification approaches 4 .", "labels": [], "entities": []}]}