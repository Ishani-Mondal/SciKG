{"title": [{"text": "HCS at SemEval-2017 Task 5: Sentiment Detection in Business News Using Convolutional Neural Networks", "labels": [], "entities": [{"text": "Sentiment Detection in Business News", "start_pos": 28, "end_pos": 64, "type": "TASK", "confidence": 0.93548024892807}]}], "abstractContent": [{"text": "Task 5 of SemEval-2017 involves fine-grained sentiment analysis on financial microblogs and news.", "labels": [], "entities": [{"text": "fine-grained sentiment analysis", "start_pos": 32, "end_pos": 63, "type": "TASK", "confidence": 0.6702099243799845}]}, {"text": "Our solution for determining the sentiment score extends an earlier convolutional neural network for sentiment analysis in several ways.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 101, "end_pos": 119, "type": "TASK", "confidence": 0.9423578083515167}]}, {"text": "We explicitly encode a focus on a particular company, we apply a data augmentation scheme, and use a larger data collection to complement the small training data provided by the task organizers.", "labels": [], "entities": []}, {"text": "The best results were achieved by training a model on an external dataset and then tuning it using the provided training dataset.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes our approach to Task 5 of the SemEval-2017 Challenge-fine-grained sentiment analysis on financial microblogs and news.", "labels": [], "entities": [{"text": "SemEval-2017 Challenge-fine-grained sentiment analysis", "start_pos": 51, "end_pos": 105, "type": "TASK", "confidence": 0.9298971146345139}]}, {"text": "The task is to determine the sentiment score (positive or negative) of a mention of a given company in a business-related text document-a microblog message (Track 1) or a news headline (Track 2).", "labels": [], "entities": []}, {"text": "Our solution, \"HCS,\" is a convolutional neural network to classify sentiment scores.", "labels": [], "entities": [{"text": "classify sentiment", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.762116014957428}]}, {"text": "The model's input takes two kinds of information: an article text, a list of focus points-positions in the text where a given company is mentioned.", "labels": [], "entities": []}, {"text": "Foci allow the model to distinguish company mentions within the text, and to assign different scores to them.", "labels": [], "entities": []}, {"text": "The data provided by the task organisers, (, is short, one-sentence messages, with a given focus company.", "labels": [], "entities": []}, {"text": "To train the model on additional data, we use the Named Entity (NE) recognition module of PULS), a news monitoring system, to find company mentions in arbitrary text.", "labels": [], "entities": [{"text": "Named Entity (NE) recognition", "start_pos": 50, "end_pos": 79, "type": "TASK", "confidence": 0.6086344172557195}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: A selection of best-performing models. Legend: Au-augmentation, FP-number of focus  points per instance, CL-number of convolution layers, Fi-number of filters (of each size).", "labels": [], "entities": [{"text": "FP-number", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.9963918328285217}, {"text": "Fi-number", "start_pos": 148, "end_pos": 157, "type": "METRIC", "confidence": 0.9719336628913879}]}, {"text": " Table 3: Official results for SemEval 2017 Task 5:  cosine similarity.", "labels": [], "entities": [{"text": "SemEval 2017 Task", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.8907491167386373}]}]}