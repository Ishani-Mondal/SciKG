{"title": [{"text": "SRHR at SemEval-2017 Task 6: Word Associations for Humour Recognition", "labels": [], "entities": [{"text": "SRHR", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.5282235145568848}, {"text": "SemEval-2017 Task", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.5558287799358368}, {"text": "Humour Recognition", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.9298442602157593}]}], "abstractContent": [{"text": "This paper explores the role of semantic relatedness features, such as word associations , in humour recognition.", "labels": [], "entities": [{"text": "humour recognition", "start_pos": 94, "end_pos": 112, "type": "TASK", "confidence": 0.8653769493103027}]}, {"text": "Specifically , we examine the task of inferring pairwise humour judgments in Twit-ter hashtag wars.", "labels": [], "entities": [{"text": "pairwise humour judgments in Twit-ter hashtag wars", "start_pos": 48, "end_pos": 98, "type": "TASK", "confidence": 0.5875018111297062}]}, {"text": "We examine a variety of word association features derived from the University of Southern Florida Free Association Norms (USF) (Nelson et al., 2004) and the Edinburgh Associative Thesaurus (EAT) (Kiss et al., 1973) and find that word association-based features outperform Word2Vec similarity , a popular semantic relatedness measure.", "labels": [], "entities": [{"text": "Edinburgh Associative Thesaurus (EAT)", "start_pos": 157, "end_pos": 194, "type": "DATASET", "confidence": 0.8789346317450205}]}, {"text": "Our system achieves an accuracy of 56.42% using a combination of unigram perplexity, bigram perplex-ity, EAT tweet-avg difference , USF max forward , EAT word-avg difference , USF word-avg difference , EAT min forward , USF tweet-max difference , and EAT min backward .", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9994503855705261}, {"text": "EAT tweet-avg difference", "start_pos": 105, "end_pos": 129, "type": "METRIC", "confidence": 0.7137045661608378}, {"text": "EAT min backward", "start_pos": 251, "end_pos": 267, "type": "METRIC", "confidence": 0.9095982313156128}]}], "introductionContent": [{"text": "Humour is very personal; what is funny to one person may not be funny to another.", "labels": [], "entities": [{"text": "Humour", "start_pos": 0, "end_pos": 6, "type": "TASK", "confidence": 0.9783825278282166}]}, {"text": "Yet, there are still certain works which seem to have widespread appeal, from comedian Louis C.K. to sitcom The Big Bang Theory.", "labels": [], "entities": []}, {"text": "What makes these works more humorous to the average person than similar ones?", "labels": [], "entities": []}, {"text": "A good place to start might be with the show @midnight and their nightly Hashtag Wars segment.", "labels": [], "entities": [{"text": "Hashtag Wars segment", "start_pos": 73, "end_pos": 93, "type": "TASK", "confidence": 0.802629292011261}]}, {"text": "Each night viewers are given a prompt in the form of a Twitter hashtag and asked to tweet their funniest responses.", "labels": [], "entities": []}, {"text": "Given two such tweets, how can we decide which is funnier?", "labels": [], "entities": []}, {"text": "This paper largely focuses on semantic relatedness-based features and their application in humour recognition.", "labels": [], "entities": [{"text": "humour recognition", "start_pos": 91, "end_pos": 109, "type": "TASK", "confidence": 0.8841657042503357}]}, {"text": "It is reasonable to assume that a punchline should be related to a setup; that is to say, a tweet's relevance to its hashtag prompt should be apparent.", "labels": [], "entities": []}, {"text": "Similarly, it is reasonable to assume that punchlines should have a certain amount of unexpectedness; in other words, funnier tweets should be harder to guess.", "labels": [], "entities": []}, {"text": "As such, it follows that semantic relation strength in general should serve as a barometer for humour where weaker relations are less understandable and stronger relations are more obvious.", "labels": [], "entities": []}, {"text": "Moreover, we hypothesize that the interplay between this understandability and unexpectedness should provide an even more powerful indication of humour.", "labels": [], "entities": []}], "datasetContent": [{"text": "We performed all training and testing on the dataset introduced in specifically for this task.", "labels": [], "entities": []}, {"text": "The dataset consists of response tweets to 112 hashtags created by @midnight.", "labels": [], "entities": []}, {"text": "The tweets are separated into files according to their respective hashtags, each hashtag file containing an average of 114 tweets.", "labels": [], "entities": []}, {"text": "Each tweet includes a label specifying whether it was deemed to be funniest, in the top ten, or neither for that particular hashtag according to the @midnight staff.", "labels": [], "entities": []}, {"text": "further divides the hashtags into three sets: Trial, Training, and Evaluation containing five, 101, and six hashtags, respectively.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracy by feature on Trial and Evalu- ation data", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9991682767868042}]}]}