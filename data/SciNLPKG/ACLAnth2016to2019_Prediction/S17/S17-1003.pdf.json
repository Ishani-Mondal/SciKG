{"title": [{"text": "Decoding Sentiment from Distributed Representations of Sentences", "labels": [], "entities": [{"text": "Decoding Sentiment from Distributed Representations of Sentences", "start_pos": 0, "end_pos": 64, "type": "TASK", "confidence": 0.8137805376734052}]}], "abstractContent": [{"text": "Distributed representations of sentences have been developed recently to represent their meaning as real-valued vectors.", "labels": [], "entities": []}, {"text": "However , it is not clear how much information such representations retain about the polarity of sentences.", "labels": [], "entities": []}, {"text": "To study this question, we decode sentiment from unsupervised sentence representations learned with different architectures (sensitive to the order of words, the order of sentences, or none) in 9 typologically diverse languages.", "labels": [], "entities": []}, {"text": "Sentiment results from the (recursive) composition of lexical items and grammatical strategies such as negation and concession.", "labels": [], "entities": [{"text": "Sentiment", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9551308751106262}]}, {"text": "The results are manifold: we show that there is no 'one-size-fits-all' representation architecture outperforming the others across the board.", "labels": [], "entities": []}, {"text": "Rather, the top-ranking archi-tectures depend on the language and data at hand.", "labels": [], "entities": []}, {"text": "Moreover, we find that in several cases the additive composition model based on skip-gram word vectors may surpass supervised state-of-art architectures such as bidirectional LSTMs.", "labels": [], "entities": []}, {"text": "Finally, we provide a possible explanation of the observed variation based on the type of negative constructions in each language.", "labels": [], "entities": []}], "introductionContent": [{"text": "Distributed representations of sentences are usually acquired in an unsupervised fashion from raw texts.", "labels": [], "entities": []}, {"text": "Those inferred from different algorithms are prone to grasp parts of their meaning and disregard others.", "labels": [], "entities": []}, {"text": "Representations have been evaluated thoroughly, both intrinsically (interpretation through distance measures) and extrinsically (performance on downstream tasks).", "labels": [], "entities": []}, {"text": "Moreover, several methods have been considered, based on both the composition of word embeddings () and direct generation ().", "labels": [], "entities": []}, {"text": "The evaluation was focused solely on English, and it rarely concerned other languages (.", "labels": [], "entities": []}, {"text": "As a consequence, many 'core' methods to learn distributed sentence representations are largely under-explored in a variety of typologically diverse languages, and still lack a demonstration of their usefulness in actual downstream tasks.", "labels": [], "entities": []}, {"text": "In this work, we study how well distributed sentence representations capture the polarity of a sentence.", "labels": [], "entities": []}, {"text": "To this end, we choose the Sentiment Analysis task as an extrinsic evaluation protocol: it directly detects the polarity of a text, where polarity is defined as the attitude of the speaker with respect to the whole content of the string or one of the entities mentioned therein.", "labels": [], "entities": [{"text": "Sentiment Analysis task", "start_pos": 27, "end_pos": 50, "type": "TASK", "confidence": 0.9454107284545898}]}, {"text": "This attitude is measured quantitatively on a scale spanning from negative to positive with arbitrary granularity.", "labels": [], "entities": []}, {"text": "As such, polarity consists in a crucial part of the meaning of a sentence, which should not be lost.", "labels": [], "entities": []}, {"text": "The polarity of a sentence depends heavily on a complex interaction between lexical items endowed with an intrinsic polarity, and morphosyntactic constructions altering polarity, most notably negation and concession.", "labels": [], "entities": []}, {"text": "The interaction is deemed to be recursive, hence some approaches take into account word order and phrase boundaries in order to apply the correct composition.", "labels": [], "entities": []}, {"text": "However, some languages lack continuous constituents: contiguous spans of words do not correspond to syntactic subtrees, making composition unreliable.", "labels": [], "entities": []}, {"text": "Moreover, the expression of negation varies across languages, as demonstrated by works in Linguistic Typology, inter alia).", "labels": [], "entities": []}, {"text": "In particular, negation can appear as a bounded morpheme or a free morpheme; it can precede or follow the verb; it can 'agree' or not in polarity with indefinite pronouns; it can alter the expression of verbal categories (e.g. tense, aspect, or modality).", "labels": [], "entities": [{"text": "negation", "start_pos": 15, "end_pos": 23, "type": "TASK", "confidence": 0.9651609063148499}]}, {"text": "We explore a series of methods endowed with different features: some hinge upon word order, others on sentence order, others on neither.", "labels": [], "entities": []}, {"text": "We evaluate these unsupervised representations using a Multi-Layer Perceptron which uses the generated sentence representations as input and predicts sentiment classes (positive vs. negative) as output.", "labels": [], "entities": []}, {"text": "Training and evaluation are based on a collection of annotated databases.", "labels": [], "entities": []}, {"text": "Owing to the variety of methods and languages, we expect to observe a variation in the performance correlated with the properties of both.", "labels": [], "entities": []}, {"text": "Moreover, we establish a ceiling to the possible performances of our method based on decoding unsupervised distributed representations.", "labels": [], "entities": []}, {"text": "In fact, we offer a comparison between this and supervised deep learning architectures that achieve state-of-art scores in the Sentiment Analysis task.", "labels": [], "entities": [{"text": "Sentiment Analysis task", "start_pos": 127, "end_pos": 150, "type": "TASK", "confidence": 0.956343392531077}]}, {"text": "In particular, we also evaluate a bi-directional LSTM ( on the same task.", "labels": [], "entities": []}, {"text": "These models have advantage over distributed representations as: i) they are specialised on a single task rather than built as general-purpose representations; ii) their recurrent nature allows to capture the sequential composition of polarity in a sentence.", "labels": [], "entities": []}, {"text": "However, since training these models requires large amounts of annotated data, resource scarcity in other languages hampers their portability.", "labels": [], "entities": []}, {"text": "The aim of this work is to assess which algorithm for distributed sentence representations is the most appropriate for capturing polarity in a given language.", "labels": [], "entities": []}, {"text": "Moreover, we study how languagespecific properties have an impact on performance, finding an explanation in Language Typology.", "labels": [], "entities": []}, {"text": "We also provide an in-depth analysis of the most relevant features by visualising the activation of hidden neurons.", "labels": [], "entities": []}, {"text": "This will hopefully contribute to advancing the Sentiment Analysis task in the multilingual scenarios.", "labels": [], "entities": [{"text": "Sentiment Analysis task", "start_pos": 48, "end_pos": 71, "type": "TASK", "confidence": 0.9574400981267294}]}, {"text": "In \u00a7 2, we survey prior work on multilingual sentiment analysis.", "labels": [], "entities": [{"text": "multilingual sentiment analysis", "start_pos": 32, "end_pos": 63, "type": "TASK", "confidence": 0.7881552378336588}]}, {"text": "Afterwards, we present the tested algorithms for generating distributed representations of sentences in \u00a7 3.", "labels": [], "entities": []}, {"text": "In \u00a7 4, we sketch the dataset and the experimental setup.", "labels": [], "entities": []}, {"text": "Finally, \u00a7 5 examines the results in light of the sensitivity of the algorithms and the typology of negation.", "labels": [], "entities": [{"text": "negation", "start_pos": 100, "end_pos": 108, "type": "TASK", "confidence": 0.9721706509590149}]}], "datasetContent": [{"text": "Now, we evaluate the quality of the distributed sentence representations from \u00a7 3 on Sentiment Analysis.", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 85, "end_pos": 103, "type": "TASK", "confidence": 0.8947602808475494}]}, {"text": "In \u00a7 4.1 we introduce the datasets of all the considered languages, and the evaluation protocol in \u00a7 4.2.", "labels": [], "entities": []}, {"text": "Finally, to provide a potential performance ceiling, we compare the obtained results with those of a deep, state-of-art classifier, outlined in \u00a7 4.3.", "labels": [], "entities": []}, {"text": "The data for training and testing are sourced from the SemEval 2016: Task 5 ().", "labels": [], "entities": [{"text": "SemEval 2016: Task 5", "start_pos": 55, "end_pos": 75, "type": "DATASET", "confidence": 0.8227026224136352}]}, {"text": "These datasets provide customer reviews in 8 languages labelled with Aspect-Based Sentiment, i.e., opinions about specific entities or attributes rather than generic stances.", "labels": [], "entities": []}, {"text": "The languages include Arabic (hotels domain), Chinese (electronics), Dutch (restaurants and electronics), English (restaurants and electronics), French, Russian, Spanish, and Turkish (restaurants all).", "labels": [], "entities": []}, {"text": "We mapped the labels to an overall polarity class (positive or negative) by selecting the majority class among the aspectbased sentiment classes fora given sentence.", "labels": [], "entities": []}, {"text": "Note that no general sentiment for the sentence was included in this pool.", "labels": [], "entities": []}, {"text": "Moreover, we added data for Italian (tweets) from the SENTIPOLC shared task in EVALITA 2016 ().", "labels": [], "entities": [{"text": "SENTIPOLC shared task in EVALITA 2016", "start_pos": 54, "end_pos": 91, "type": "DATASET", "confidence": 0.6280480027198792}]}, {"text": "We discarded neutral stances from the corpus, and retained only positive and negative ones.", "labels": [], "entities": []}, {"text": "shows the final size of the dataset partitions and the Wikipedia dumps.", "labels": [], "entities": []}, {"text": "We discuss the impact of the variation of these percentages on the results in \u00a7 5.: Size of the data partitions (# sentences).", "labels": [], "entities": []}, {"text": "After mapping each sentence in the dataset to its distributed representation, we fed them to a MultiLayer Perceptron (MLP), trained to detect the sentence polarity.", "labels": [], "entities": []}, {"text": "In the MLP, a logistic regression layer is stacked onto a 60-dimensional hidden layer with a hyperbolic tangent activation.", "labels": [], "entities": [{"text": "MLP", "start_pos": 7, "end_pos": 10, "type": "TASK", "confidence": 0.850578784942627}]}, {"text": "The weights were initialised from the random xavier distribution.", "labels": [], "entities": []}, {"text": "The cross-entropy loss was normalised with the L2-norm of the weights scaled by \u03bb = 10 \u22123 . The optimisation with gradient descent ran for 20 epochs with early stopping.", "labels": [], "entities": []}, {"text": "Batch size was 10 and the learning rate 10 \u22122 .", "labels": [], "entities": [{"text": "Batch size", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.8449702858924866}, {"text": "learning rate", "start_pos": 26, "end_pos": 39, "type": "METRIC", "confidence": 0.977265864610672}]}], "tableCaptions": [{"text": " Table 2: Size of the data partitions (# sentences).", "labels": [], "entities": []}]}