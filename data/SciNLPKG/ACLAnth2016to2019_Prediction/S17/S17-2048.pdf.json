{"title": [{"text": "A ThRee Embeddings Recurrent Neural Network for Question Answering", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.8113631010055542}]}], "abstractContent": [{"text": "In this paper we present ThReeNN, a model for Community Question Answering , Task 3, of SemEval-2017.", "labels": [], "entities": [{"text": "ThReeNN", "start_pos": 25, "end_pos": 32, "type": "METRIC", "confidence": 0.8359367847442627}, {"text": "Community Question Answering", "start_pos": 46, "end_pos": 74, "type": "TASK", "confidence": 0.615773876508077}]}, {"text": "The proposed model exploits both syntactic and semantic information to build a single and meaningful embedding space.", "labels": [], "entities": []}, {"text": "Using a dependency parser in combination with word embeddings, the model creates sequences of inputs fora Recurrent Neural Network, which are then used for the ranking purposes of the Task.", "labels": [], "entities": []}, {"text": "The score obtained on the official test data shows promising results .", "labels": [], "entities": []}], "introductionContent": [{"text": "Community Question Answering (cQA) systems have proven to be useful fora longtime and they still are an invaluable source of information.", "labels": [], "entities": [{"text": "Community Question Answering (cQA)", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7114865730206171}]}, {"text": "However, due to their rapid growth and to the large amount of data provided it is not easy to find a relevant answer or a good related question amongst all the others.", "labels": [], "entities": []}, {"text": "For these reasons we present a model which tries to tackle these problems.", "labels": [], "entities": []}, {"text": "The subtasks we have worked on can be described as follows: A) Question-Comment Similarity -Given a question q and 10 comments c 1 , . .", "labels": [], "entities": []}, {"text": ", c 10 , rank such comments from the most relevant to the least one with respect to q, and assign to each one a label which can be \"Good\" or \"Bad\".", "labels": [], "entities": []}, {"text": "B) Question-Question Similarity -Given a question q and a set of 10 related questions q 1 , . .", "labels": [], "entities": [{"text": "Question-Question Similarity", "start_pos": 3, "end_pos": 31, "type": "TASK", "confidence": 0.6957884430885315}]}, {"text": ", q 10 , rank the 10 questions from \"Relevant\" to \"Irrelevant\", according to q.", "labels": [], "entities": []}, {"text": "A more detailed description of the task can be found in (.", "labels": [], "entities": []}, {"text": "Our work has been inspired by studies regarding embedding spaces.", "labels": [], "entities": []}, {"text": "Indeed, in (  GloVe embeddings () are used to solve the same subtasks as ours, achieving good results using just word embeddings which encode semantic information into a vector.", "labels": [], "entities": []}, {"text": "Moreover, the model proposed in (, where autoencoders are used to build an embedding space, has been exploited to propose an approach that mixes semantic and syntactic information through the use of word embeddings and dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 219, "end_pos": 237, "type": "TASK", "confidence": 0.7208722829818726}]}, {"text": "These are then put together and become an input for the neural network.", "labels": [], "entities": []}, {"text": "In this way we try to enhance the capability of the learning system.", "labels": [], "entities": []}, {"text": "In principle, our approach aims at enriching semantic information with syntactic relations holding between elements of the couples (questioncomment or question-question).", "labels": [], "entities": []}, {"text": "This should serve well for both subtasks A and B, since the model will learn relations between a question and a comment or between a question and another one.", "labels": [], "entities": []}, {"text": "However, further research would be useful to understand to what extent there exist differences in the kind of relations learnt, and therefore in the subtasks.", "labels": [], "entities": []}, {"text": "The paper is organised as follows: Section 2 outlines the preprocessing and additional features used by the model, while Section 3 describes the key models used.", "labels": [], "entities": [{"text": "preprocessing", "start_pos": 58, "end_pos": 71, "type": "METRIC", "confidence": 0.9538698196411133}]}, {"text": "Section 4 shows the model selection strategy and the alternatives we explored with respect to word embeddings and their combination.", "labels": [], "entities": []}, {"text": "Finally, Section 5 reports performances on different models and Section 6 wraps up everything and discusses about future works.", "labels": [], "entities": []}, {"text": "From now on, we will refer to \"comment\" for indicating both a comment (Subtask A) or a related question (Subtask B), since our model does not make distinctions between them.", "labels": [], "entities": []}, {"text": "We participated to Semeval 2017, ranking 8th in Subtask A and 10th in Subtask B. In this example the first input x(t) of the RNN is going to be: <\"is\",SUBJ,\"there\",\"is\",SUBJ,\"It\">.", "labels": [], "entities": []}], "datasetContent": [{"text": "To perform model selection we merged training and development files provided by Semeval organisers, then we shuffled and extracted a training and a validation set.", "labels": [], "entities": [{"text": "model selection", "start_pos": 11, "end_pos": 26, "type": "TASK", "confidence": 0.7913627922534943}]}, {"text": "We selected various hyperparameters, shown with their values in, such as learning rate, number of hidden units and hidden layers for the recurrent and feedforward layers, dropout), L2 regularization, activation functions (i.e. ReLu, sigmoid and hyperbolic tangent), optimization algorithms (i.e. adam) and rmsprop (Tieleman and Hinton, 2012)).", "labels": [], "entities": [{"text": "rmsprop", "start_pos": 306, "end_pos": 313, "type": "METRIC", "confidence": 0.9250438809394836}]}, {"text": "The length threshold for the number of triples in input to the RNN as been also added as hyper-parameter (i.e., Max length); if the comment/question is shorter, it is filled up with zeros (\"null triples\").", "labels": [], "entities": [{"text": "Max length)", "start_pos": 112, "end_pos": 123, "type": "METRIC", "confidence": 0.9392982522646586}]}, {"text": "Since each training required quite a large amount of time, we opted fora random search technique.", "labels": [], "entities": []}, {"text": "The embeddings layer uses pretrained embeddings which are fixed during the training phase.", "labels": [], "entities": []}, {"text": "We tried to update them together with the entire network during training but the resulting network always ended up to over-fit.", "labels": [], "entities": []}, {"text": "Two different types of embeddings have been evaluated:), which are trained using Wikipedia, and embeddings trained directly with questions and answers extracted from the Qatar Living forum ( . However, in our model both embeddings worked well, thus with the latter we did not obtained any particular improvements.", "labels": [], "entities": [{"text": "Qatar Living forum", "start_pos": 170, "end_pos": 188, "type": "DATASET", "confidence": 0.956103245417277}]}], "tableCaptions": [{"text": " Table 1: Hyper-parameters used during model se- lection. The selected parameters for Subtask A are  in bold, and underlined for Subtask B.", "labels": [], "entities": []}, {"text": " Table 2. The primary  submission uses LSTM for subtask A and GRU  for subtask B. Instead, the contrastive model uses  SUM as aggregation and it has been submitted just  for the subtask A. Using the SUM model, which  is computationally less expensive than RNN, we  obtained just a slightly worst MAP (i.e. around  0.5%), which suggests we could further improve  the performance by making the RNN exploit better  the sequence in input. Moreover, there is a trade- off between representation length and computa- tional costs, achieved with the use of the length  threshold; this may be regarded as a crucial choice  for our model.", "labels": [], "entities": [{"text": "GRU", "start_pos": 62, "end_pos": 65, "type": "METRIC", "confidence": 0.9349838495254517}, {"text": "MAP", "start_pos": 296, "end_pos": 299, "type": "METRIC", "confidence": 0.9923627376556396}]}, {"text": " Table 2: Summary of the results of the submitted  model on subtask A and B", "labels": [], "entities": []}]}