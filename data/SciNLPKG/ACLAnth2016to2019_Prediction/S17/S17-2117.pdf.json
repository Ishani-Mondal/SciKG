{"title": [{"text": "DUTH at SemEval-2017 Task 4: A Voting Classification Approach for Twitter Sentiment Analysis", "labels": [], "entities": [{"text": "Voting Classification Approach", "start_pos": 31, "end_pos": 61, "type": "TASK", "confidence": 0.7640439669291178}, {"text": "Twitter Sentiment Analysis", "start_pos": 66, "end_pos": 92, "type": "TASK", "confidence": 0.7050153315067291}]}], "abstractContent": [{"text": "This report describes our participation to SemEval-2017 Task 4: Sentiment Analysis in Twitter, specifically in subtasks A, B, and C.", "labels": [], "entities": [{"text": "SemEval-2017 Task 4", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.8342541257540385}, {"text": "Sentiment Analysis", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.8861472606658936}]}, {"text": "The approach for text sentiment classification is based on a Majority Vote scheme and combined supervised machine learning methods with classical linguistic resources, including bag-of-words and sentiment lexicon features.", "labels": [], "entities": [{"text": "text sentiment classification", "start_pos": 17, "end_pos": 46, "type": "TASK", "confidence": 0.8766391078631083}]}], "introductionContent": [{"text": "For millions of users, microblogging services such as Twitter, a popular service where users can post no more than 140 characters status messages, have become an elemental part of daily life.", "labels": [], "entities": []}, {"text": "By using tools and techniques from Natural Language Processing (NLP) and machine learning, Sentiment analysis is defined as the process to identify and analyze polarity from short texts, sentences, and documents (.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 91, "end_pos": 109, "type": "TASK", "confidence": 0.9404853880405426}]}, {"text": "In the last few years, people from different research disciplines are interested in Sentiment Analysis, and the SemEval workshop offers an opportunity to compete and work in this field.", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 84, "end_pos": 102, "type": "TASK", "confidence": 0.9628937840461731}]}, {"text": "Our team has participated in SemEval-2017 task 4 on Sentiment Analysis in Twitter, more specifically on subtasks A (Message Polarity Classification), B, and C (Tweet Classification in either two-point or five-point scale respectively) (.", "labels": [], "entities": [{"text": "SemEval-2017 task 4", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.839069147904714}, {"text": "Sentiment Analysis", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.8757205307483673}]}, {"text": "In this report, we present an ensemble text sentiment classification scheme, based on an extensive empirical analysis of several classifiers and other related works, e.g..", "labels": [], "entities": [{"text": "ensemble text sentiment classification", "start_pos": 30, "end_pos": 68, "type": "TASK", "confidence": 0.7347631007432938}]}, {"text": "A voting scheme combines learning algorithms to identify and select an optimal set of base learning algorithms.", "labels": [], "entities": []}, {"text": "These components were carefully combined and optimized to create a separate version of the system for each of the tackled subtasks.", "labels": [], "entities": []}, {"text": "The rest of this report is organized as follows.", "labels": [], "entities": []}, {"text": "The description of proposed system we used and its feature extraction are presented in Section 2.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.7165350317955017}]}, {"text": "Section 3 reports our experiments.", "labels": [], "entities": []}, {"text": "Conclusions and directions for further work/research are summarized in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, after the feature extraction, we analyse the classification process with the learning methods and classification algorithms that used in our system.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.7166452258825302}]}, {"text": "The datasets were provided by the organizers and contained all datasets of the previous years with the addition of anew.", "labels": [], "entities": []}, {"text": "For Subtask A the available datasets were all the training, development, and testing data from the years 2013 to 2016.", "labels": [], "entities": []}, {"text": "For Subtask B the available datasets were from the years 2015 to 2016, and for Subtask C from the year 2016.", "labels": [], "entities": []}, {"text": "We used a portion of the data for development and the rest for training.", "labels": [], "entities": []}, {"text": "We present them in   As we can observe from the tables, the testing data that were provided by the organizers have different ratio among the classes, especially between the positives and negatives.", "labels": [], "entities": []}, {"text": "For Subtask A, we use the macro-average recall, which is the recall averaged across the three classes R macro = . Subtask B maintains the same measure, but among the two classes R macro = Rpos+Rneg 2 . For Subtask C, the official metrics are the macro-averaged mean absolute error and the extension of macro-averaged recall for ordinal regression (Rosenthal et al., 2017) among 5 predefined classes.", "labels": [], "entities": [{"text": "recall", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.9161004424095154}, {"text": "recall", "start_pos": 61, "end_pos": 67, "type": "METRIC", "confidence": 0.991487979888916}, {"text": "macro-averaged mean absolute error", "start_pos": 246, "end_pos": 280, "type": "METRIC", "confidence": 0.605395957827568}]}], "tableCaptions": [{"text": " Table 3: Number of tweets in training (train), development (dev), testing (test) data for subtask C.", "labels": [], "entities": []}, {"text": " Table 4: DUTH's results for SemEval-2017 Task  4 on Sentiment Analysis in Twitter (Rosenthal  et al., 2017).", "labels": [], "entities": [{"text": "SemEval-2017 Task  4", "start_pos": 29, "end_pos": 49, "type": "TASK", "confidence": 0.8132594029108683}, {"text": "Sentiment Analysis in Twitter", "start_pos": 53, "end_pos": 82, "type": "TASK", "confidence": 0.8589656502008438}]}]}