{"title": [{"text": "SwissAlps at SemEval-2017 Task 3: Attention-based Convolutional Neural Network for Community Question Answering", "labels": [], "entities": [{"text": "SwissAlps", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9438897967338562}, {"text": "Community Question Answering", "start_pos": 83, "end_pos": 111, "type": "TASK", "confidence": 0.6419136027495066}]}], "abstractContent": [{"text": "In this paper we propose a system for re-ranking answers fora given question.", "labels": [], "entities": []}, {"text": "Our method builds on a siamese CNN architecture which is extended by two attention mechanisms.", "labels": [], "entities": []}, {"text": "The approach was evaluated on the datasets of the SemEval-2017 competition for Community Question Answering (cQA), where it achieved 7 th place obtaining a MAP score of 86.24 points on the Question-Comment Similarity subtask.", "labels": [], "entities": [{"text": "SemEval-2017 competition for Community Question Answering (cQA)", "start_pos": 50, "end_pos": 113, "type": "TASK", "confidence": 0.6352202163802253}, {"text": "MAP", "start_pos": 156, "end_pos": 159, "type": "METRIC", "confidence": 0.9965938925743103}]}], "introductionContent": [{"text": "Community Question Answering (cQA) describes the task of finding a relevant answer to a neverbefore seen question (.", "labels": [], "entities": [{"text": "Community Question Answering (cQA)", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7277190436919531}]}, {"text": "The cQA task in SemEval-2017 is subdivided into three subtasks: (a) Question-Comment Similarity, (b) Question-Question Similarity, and (c) Question-External Comment Similarity.", "labels": [], "entities": [{"text": "Question-Question Similarity", "start_pos": 101, "end_pos": 129, "type": "TASK", "confidence": 0.7191057056188583}, {"text": "Question-External Comment Similarity", "start_pos": 139, "end_pos": 175, "type": "TASK", "confidence": 0.6203362147013346}]}, {"text": "We participated at the Question-Comment Similarity subtask, which consists of re-ranking a set of 10 answers to a given question, such that all the relevant answers are ranked higher than the irrelevant answers.", "labels": [], "entities": [{"text": "Question-Comment Similarity", "start_pos": 23, "end_pos": 50, "type": "TASK", "confidence": 0.6643377542495728}]}, {"text": "We evaluated this system on the dataset provided by SemEval-2017 for the Question-Comment Similarity subtask, wich consits of approximately 2000 questions with 10 answers each.", "labels": [], "entities": []}, {"text": "Our system ranked 7 th place, achieving a MAP score of 86.2 which was outperformed by 2 points by the 1 st ranked system.", "labels": [], "entities": [{"text": "MAP score", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9850248992443085}]}, {"text": "In this paper we describe the implementation details of our system, which follows a siamese CNN architecture based on ( extended by the attention mechanisms introduced by.", "labels": [], "entities": []}, {"text": "Siamese Architecture Siamese architectures usually consist of two parallel CNNs, each processing one sentence and then using the representations for the classification.", "labels": [], "entities": []}, {"text": "Siamese architectures have been proposed for various tasks, e.g. () used the structure for signature verification, and they have been shown to be very useful for modelling sentence pairs:,, and () used the siamese architecture to generate representations for both sentences which then are used for classification.", "labels": [], "entities": [{"text": "signature verification", "start_pos": 91, "end_pos": 113, "type": "TASK", "confidence": 0.7387454509735107}]}, {"text": "Attention Mechanisms Recently the notion of attention has been introduced in neural network architectures to mimic human behaviour, as we tend to focus on key parts of the sentences to extract relevant parts.", "labels": [], "entities": [{"text": "Attention Mechanisms", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7133250832557678}]}, {"text": "Most of the work on attention mechanisms is focused on LSTMs: for instance in () the authors use an attention mechanism for language translation, and in () the authors use it for generating parse trees.", "labels": [], "entities": [{"text": "language translation", "start_pos": 124, "end_pos": 144, "type": "TASK", "confidence": 0.7118998765945435}]}, {"text": "Regarding attention mechanisms for CNNs, we are only aware of (, on which our system is based on.", "labels": [], "entities": []}, {"text": "The rest of the paper is structured as follows: in Section 2 we present our model showing the siamese architecture augmented with two different attention mechanisms.", "labels": [], "entities": []}, {"text": "In Section 3 we describe our experimental setup and show the results obtained with our system.", "labels": [], "entities": []}, {"text": "We conclude our discussion in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "For the experiments we compared the three different architectures: (i) the siamese architecture without the attention mechanism; we refer to this as siamese CNN (sCNN) (ii) the ABCNN 1 architecture, and (iii) the ABCNN 2 architecture.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Hyperparameters of the system. lr: learn- ing rate,\u03c1 and : AdaDelta hyperparameters , h:  filter width, m: number of filters", "labels": [], "entities": [{"text": "learn- ing rate,\u03c1", "start_pos": 45, "end_pos": 62, "type": "METRIC", "confidence": 0.8870555460453033}]}, {"text": " Table 2: Overview of the datasets used for training  and validation.", "labels": [], "entities": [{"text": "validation", "start_pos": 58, "end_pos": 68, "type": "TASK", "confidence": 0.9598553776741028}]}, {"text": " Table 3: Resutls on the Test 2016 set.", "labels": [], "entities": [{"text": "Resutls", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9511351585388184}, {"text": "Test 2016 set", "start_pos": 25, "end_pos": 38, "type": "DATASET", "confidence": 0.976445217927297}]}, {"text": " Table 4: Resutls on the Test 2017 set.", "labels": [], "entities": [{"text": "Resutls", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9595369696617126}, {"text": "Test 2017 set", "start_pos": 25, "end_pos": 38, "type": "DATASET", "confidence": 0.9766448338826498}]}]}