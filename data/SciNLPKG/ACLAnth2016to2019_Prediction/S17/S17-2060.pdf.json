{"title": [{"text": "ECNU at SemEval-2017 Task 3: Using Traditional and Deep Learning Methods to Address Community Question Answering Task", "labels": [], "entities": [{"text": "ECNU at SemEval-2017 Task", "start_pos": 0, "end_pos": 25, "type": "DATASET", "confidence": 0.9079306125640869}, {"text": "Address Community Question Answering", "start_pos": 76, "end_pos": 112, "type": "TASK", "confidence": 0.7483201920986176}]}], "abstractContent": [{"text": "This paper describes the systems we submitted to the task 3 (Community Question Answering) in SemEval 2017 which contains three subtasks on english corpora, i.e., subtask A: Question-Comment Similarity , subtask B: Question-Question Similarity , and subtask C: Question-External Comment Similarity.", "labels": [], "entities": [{"text": "Community Question Answering) in SemEval 2017", "start_pos": 61, "end_pos": 106, "type": "TASK", "confidence": 0.7198944645268577}, {"text": "Question-Question Similarity", "start_pos": 215, "end_pos": 243, "type": "TASK", "confidence": 0.6629267185926437}, {"text": "Question-External Comment Similarity", "start_pos": 261, "end_pos": 297, "type": "TASK", "confidence": 0.6014298697312673}]}, {"text": "For subtask A, we combined two different methods to represent question-comment pair, i.e., supervised model using traditional features and Convolutional Neural Network.", "labels": [], "entities": []}, {"text": "For sub-task B, we utilized the information of snippets returned from Search Engine with question subject as query.", "labels": [], "entities": []}, {"text": "For subtask C, we ranked the comments by multiplying the probability of the pair \"related question \u00f5 comment\" being Good by the reciprocal rank of the related question.", "labels": [], "entities": []}], "introductionContent": [{"text": "The purpose of Community Question Answering task in) is to provide a platform for finding good answers to new questions in a community-created discussion forum, where the main task (subtask C) is defined as follows: given anew question and a large collection of question-comment threads created by a user community, participants are required to rank the comments that are most useful for answering the new question.", "labels": [], "entities": [{"text": "Community Question Answering task", "start_pos": 15, "end_pos": 48, "type": "TASK", "confidence": 0.7080205529928207}]}, {"text": "Obviously, this main task consists of two optional subtasks, i.e., Question-Comment Similarity (subtask A, also known as answer ranking), which is to re-rank comments/answers according to their relevance with respect to the question, and QuestionQuestion Similarity (i.e., subtask B, also known as question retrieval), which is to retrieve the similar questions according to their semantic similarity with respect to the original question.", "labels": [], "entities": [{"text": "question retrieval", "start_pos": 298, "end_pos": 316, "type": "TASK", "confidence": 0.7038705199956894}]}, {"text": "More, anew subtask: Multi-Domain Duplicate Detection Subtask (i.e., subtask E) which is to identify duplicate questions in StackExchange has been added to SemEval 2017 task 3.", "labels": [], "entities": [{"text": "SemEval 2017 task", "start_pos": 155, "end_pos": 172, "type": "TASK", "confidence": 0.8120664159456888}]}, {"text": "To address subtask A, we explored a traditional machine learning method which uses multiple types of features, e.g., Word Match Features, Topic Model-based Features, and Lexical Semantic Similarity Features.", "labels": [], "entities": []}, {"text": "Additionally, for subtask A, we also built a Convolutional Neural Network (CNN) model to learn joint representation for question-comment (Q-C) pair.", "labels": [], "entities": []}, {"text": "For subtask B, we utilized the information of snippets returned from Search Engine with question subject as query, e.g., we counted the frequency of each word in each snippets list and added the words which appear in the subject of original question and the frequency is more than 1 to the subject of related question.", "labels": [], "entities": []}, {"text": "Since subtask C can be regarded as a joint work of the two above-mentioned subtasks, we ranked the comments by multiplying the probability of the pair /related question \u00f5 comment0 being Good by the reciprocal rank of the related question.", "labels": [], "entities": []}, {"text": "As for subtask E, we did not submit the results because of the large amount of dataset.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes our system.", "labels": [], "entities": []}, {"text": "Section 3 describes experimental setting.", "labels": [], "entities": []}, {"text": "Section 4 and 5 report results on training and test sets.", "labels": [], "entities": []}, {"text": "Finally, Section 6 concludes this work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Based on above experimental results, we find that (1) For subtask A, all the features (e.g., WM, TMB, MD, CI and LSS) make contribution to the improvement of performance.", "labels": [], "entities": [{"text": "LSS", "start_pos": 113, "end_pos": 116, "type": "METRIC", "confidence": 0.9847016930580139}]}, {"text": "The CNN based model achieves comparable performance with traditional method and with the average value of scores returned by two methods as ranking score achieves the best performance.", "labels": [], "entities": []}, {"text": "(2) For subtask B, three algorithms such as Logistic Regression, AdaBoost and Random Forest achieve comparable results with traditional NLP features.", "labels": [], "entities": []}, {"text": "Specially, LR with all features achieve the best performance.", "labels": [], "entities": []}, {"text": "(3) For subtask C, AdaBoost with all features (excluding MD feature) makes the best result compared with Random Forest and Logistic Regression.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of datasets.", "labels": [], "entities": []}, {"text": " Table 2: Results of subtask A with two differen- t methods. \"All\" means to all features and \"-\"  means to exclude some feature groups.", "labels": [], "entities": []}, {"text": " Table 3: Results of subtask B.", "labels": [], "entities": [{"text": "subtask B", "start_pos": 21, "end_pos": 30, "type": "TASK", "confidence": 0.7466412484645844}]}, {"text": " Table 4: Results of subtask C.", "labels": [], "entities": []}, {"text": " Table 5: Our results and the best results on three  subtasks test sets. The numbers in the brackets are  the official ranking.", "labels": [], "entities": []}]}