{"title": [{"text": "Neobility at SemEval-2017 Task 1: An Attention-based Sentence Similarity Model", "labels": [], "entities": [{"text": "Sentence Similarity", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.7426511943340302}]}], "abstractContent": [{"text": "This paper describes a neural-network model which performed competitively (top 6) at the SemEval 2017 cross-lingual Semantic Textual Similarity (STS) task.", "labels": [], "entities": [{"text": "SemEval 2017 cross-lingual Semantic Textual Similarity (STS) task", "start_pos": 89, "end_pos": 154, "type": "TASK", "confidence": 0.8565121054649353}]}, {"text": "Our system employs an attention-based recurrent neural network model that optimizes the sentence similarity.", "labels": [], "entities": []}, {"text": "In this paper, we describe our participation in the multilingual STS task which measures similarity across English, Spanish, and Arabic.", "labels": [], "entities": [{"text": "multilingual STS task", "start_pos": 52, "end_pos": 73, "type": "TASK", "confidence": 0.7243545949459076}]}], "introductionContent": [{"text": "Semantic textual similarity (STS) measures the degree of equivalence between the meanings of two text sequences (.", "labels": [], "entities": [{"text": "Semantic textual similarity (STS", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.5534072577953338}]}, {"text": "The similarity of the text pair can be represented as discrete or continuous values ranging from irrelevance (1) to exact semantic equivalence (5).", "labels": [], "entities": []}, {"text": "It is widely applicable to many NLP tasks including summarization), generation and question answering (, paraphrase detection, and machine translation.", "labels": [], "entities": [{"text": "summarization", "start_pos": 52, "end_pos": 65, "type": "TASK", "confidence": 0.9883937835693359}, {"text": "generation and question answering", "start_pos": 68, "end_pos": 101, "type": "TASK", "confidence": 0.7088883146643639}, {"text": "paraphrase detection", "start_pos": 105, "end_pos": 125, "type": "TASK", "confidence": 0.9090669751167297}, {"text": "machine translation", "start_pos": 131, "end_pos": 150, "type": "TASK", "confidence": 0.8010895550251007}]}, {"text": "In this paper, we describe a system that is able to learn context-sensitive features within the sentences.", "labels": [], "entities": []}, {"text": "Further, we encode the sequential information with Recurrent Neural Network (RNN) and perform attention mechanism () on RNN outputs for both sentences.", "labels": [], "entities": []}, {"text": "Attention mechanism was performed to increase sensitivity of the system to words of similarity significance.", "labels": [], "entities": []}, {"text": "We also optimize directly on the Pearson correlation score as part of our neural-based approach.", "labels": [], "entities": [{"text": "Pearson correlation score", "start_pos": 33, "end_pos": 58, "type": "METRIC", "confidence": 0.8467516104380289}]}, {"text": "Moreover, we include a pair feature adapter module that could be used to include more features to further improve performance.", "labels": [], "entities": []}, {"text": "However, for this competition we include merely the TakeLab features ( \u02c7 Sari\u00b4cSari\u00b4c et al., 2012).", "labels": [], "entities": [{"text": "TakeLab", "start_pos": 52, "end_pos": 59, "type": "DATASET", "confidence": 0.7441169023513794}]}], "datasetContent": [{"text": "In the experiment, the size of output of GRU is set to be H = 200.", "labels": [], "entities": []}, {"text": "We use ADAM algorithm to optimize the parameters with mini-batches of 125.", "labels": [], "entities": []}, {"text": "The learning rate is set to 10 \u22124 at the beginning and reduced by half for every 5 epochs.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 4, "end_pos": 17, "type": "METRIC", "confidence": 0.952284961938858}]}, {"text": "We trained the network for 15 epochs.", "labels": [], "entities": []}, {"text": "Word embeddings In, we demonstrate that the system performs better with pretrained word vectors (WI) than randomly initialized (RI).: System performance with different dimensions of word embeddings, using either randomly initialized or pre-trained word embedding.", "labels": [], "entities": []}, {"text": "Loss function We display performances with systems optimized with KLD, MSE, and PCC.", "labels": [], "entities": [{"text": "PCC", "start_pos": 80, "end_pos": 83, "type": "DATASET", "confidence": 0.9189913272857666}]}, {"text": "It shows that when using L PCC as the training objective, our system not only performs the best but also converges the fastest.", "labels": [], "entities": []}, {"text": "As shown in and.: Influence of different loss objectives on the system performance measured using PCC on our validation set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Example of lower MSE and KLD not  indicating higher PCC.", "labels": [], "entities": [{"text": "KLD", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.6251780390739441}]}, {"text": " Table 3: System performance with different di- mensions of word embeddings, using either ran- domly initialized or pre-trained word embedding.", "labels": [], "entities": []}, {"text": " Table 5: Final system results and statistics of the  number of OOV words within a pair", "labels": [], "entities": []}]}