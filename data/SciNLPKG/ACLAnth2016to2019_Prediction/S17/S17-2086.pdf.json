{"title": [{"text": "ECNU at SemEval-2017 Task 8: Rumour Evaluation Using Effective Features and Supervised Ensemble Models", "labels": [], "entities": [{"text": "ECNU at SemEval-2017 Task 8", "start_pos": 0, "end_pos": 27, "type": "DATASET", "confidence": 0.8737248420715332}, {"text": "Rumour Evaluation", "start_pos": 29, "end_pos": 46, "type": "TASK", "confidence": 0.9759962260723114}]}], "abstractContent": [{"text": "This paper describes our submissions to task 8 in SemEval 2017, i.e., Determining rumour veracity and support for rumours.", "labels": [], "entities": [{"text": "Determining rumour veracity", "start_pos": 70, "end_pos": 97, "type": "TASK", "confidence": 0.8686268925666809}]}, {"text": "Given a rumoured tweet and a plethora of replied tweets, subtask A is to label whether these tweets are support, deny , query or comment, and subtask B aims to predict the veracity (i.e., true, false, and unverified) with a confidence (in range of 0-1) of the given rumoured tweet.", "labels": [], "entities": []}, {"text": "For both subtasks, we adopted supervised machine learning methods incorporating rich features.", "labels": [], "entities": []}, {"text": "Since the training data is imbal-anced, we specifically designed a two-step classifier to address subtask A .", "labels": [], "entities": []}], "introductionContent": [{"text": "With the rapid development of social media in recent years, people cannot only stay abreast of ongoing events and breaking news, but also express their own views freely.", "labels": [], "entities": []}, {"text": "News can spread quickly in social media platforms through a large amount of users, whilst those pieces of unverified information often spawn rumours.", "labels": [], "entities": []}, {"text": "The RumourEval () task aims to identify how users in social media networks regard the originating rumours and reply to them, as well as analysis and determining veracity of rumoured tweets.", "labels": [], "entities": []}, {"text": "The organizer provides tree-structured conversations that are associated with breaking news and consisting of originating rumoured tweets and tweets replying to them.", "labels": [], "entities": []}, {"text": "There are two subtasks in RumourEval.", "labels": [], "entities": []}, {"text": "The propose of subtask A is, given the related breaking news, to predict the class (i.e., support, deny, query, and comment) of the originating rumoured tweet (i.e., source tweet) and reactions (i.e., replied tweets).", "labels": [], "entities": []}, {"text": "The goal of subtask B is to determine the veracity and confidence of the given rumoured tweet, participants are required to return a label of rumour as true, false or unverified, with a confidence value in the range of 0-1.", "labels": [], "entities": [{"text": "veracity", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9498658180236816}]}, {"text": "We treated the two subtasks as multiclassification problems, and designed multiple effective natural language processing (NLP) features to build classifiers to make predictions.", "labels": [], "entities": []}, {"text": "Besides, rumour detection is relevant to sentiment analysis, for example, support and deny can be viewed as positive and negative sentiment respectively.", "labels": [], "entities": [{"text": "rumour detection", "start_pos": 9, "end_pos": 25, "type": "TASK", "confidence": 0.8994455337524414}, {"text": "sentiment analysis", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.9499964118003845}]}, {"text": "Therefore, we solved the problem with the aid of a number of sentiment-related features.", "labels": [], "entities": []}, {"text": "Due to the imbalanced characteristic of the training data, we specifically adopted a two-step classifier to deal with subtask A.", "labels": [], "entities": []}, {"text": "Firstly, tweets would be separated into two categories: comment and non-comment, then the tweets labeled as non-comment would be classified as support, deny or query.", "labels": [], "entities": []}, {"text": "On the other hand, we directly adopted a three-classification system for subtask B to label rumoured tweets as true, false or unverified along with confidence.", "labels": [], "entities": []}], "datasetContent": [{"text": "Based on above multiple features, we explored several learning algorithms to build classification models, e.g., Logistic Regression (LR), supplied in liblinear tools 6 , Support Vector Machines (SVM), Decision Trees (DT), Random Forests (R-F), AdaBoost (ADB), and Gradient Tree Boosting (GDB), implemented in scikit-learn . We also ensembled the effective learning algorithms using majority vote strategy.", "labels": [], "entities": []}, {"text": "The official evaluation measure for both subtasks is accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9989193677902222}]}, {"text": "The statistics of the datasets provided by SemEval 2017 task 8 are shown in The train and dev sets are associated with eight different breaking news in English, i.e., charliehebdo, ebola-essien, ferguson, germanwingscrash, ottawashooting, prince-toronto, putinmissing, and sydneysiege.", "labels": [], "entities": [{"text": "SemEval 2017 task 8", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.5667588487267494}]}, {"text": "They are made up of 297 Twitter conversations including 4, 519 tweets in total.", "labels": [], "entities": []}, {"text": "Apart from the eight original breaking news, the test set adds two new, i.e., hillaryshealth and save-marinajoyce, and it contains 28 conversations and 1, 049 tweets.", "labels": [], "entities": []}, {"text": "This corpus is collected using the method described in ().", "labels": [], "entities": []}, {"text": "The lists the results of the best feature set with respect to top learning algorithms on two subtasks.", "labels": [], "entities": []}, {"text": "Note that for subtask A, we adopted a two-step classification.", "labels": [], "entities": []}, {"text": "The accuracy of 1-step is calculated on two classes (i.e., comment and noncomment ), and that of 2-step is calculated on four classes (i.e., support, deny, query and comment).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9994193315505981}]}, {"text": "Since the dev set of subtask B is not enough (only 25 samples), we combined train and dev sets and performed a 2-fold cross-validation.", "labels": [], "entities": []}, {"text": "Furthermore, we also performed ensemble to combine the results of top learning algorithms with their optimum feature sets, which are shown as the last row in.", "labels": [], "entities": []}, {"text": "From, we observe the findings as follows: (1) Among 7 algorithms, LR and SVM consistently perform well in the three classifications.", "labels": [], "entities": []}, {"text": "Besides, ADB does a good job in two classifications in subtask A, RF and GBD have a good perfor-mance in 2-step of subtask A and subtask B.", "labels": [], "entities": [{"text": "ADB", "start_pos": 9, "end_pos": 12, "type": "DATASET", "confidence": 0.7306942939758301}, {"text": "RF", "start_pos": 66, "end_pos": 68, "type": "METRIC", "confidence": 0.8841018080711365}]}, {"text": "(2) Generally, Tweet domain, metadata and Wordcluster features make a considerable contribution for both subtasks, and they can achieve promising performance with different algorithms.", "labels": [], "entities": [{"text": "Wordcluster", "start_pos": 42, "end_pos": 53, "type": "DATASET", "confidence": 0.9168604016304016}]}, {"text": "The possible reasons are: (a) Tweet domain features not only contain sentiment information (e.g., Punctuation and Emoticon), but also include topic information (e.g., Hashtag, Mentioned entity, and Event).", "labels": [], "entities": []}, {"text": "(b) The numerical characteristic (e.g, tweet favorite count, retweet count, etc) of metadata can indicate that whether a tweet is being closely watched and worthy of commenting.", "labels": [], "entities": [{"text": "retweet count", "start_pos": 61, "end_pos": 74, "type": "METRIC", "confidence": 0.9476044774055481}]}, {"text": "Binary features (e.g., friends count, is-verified, isprotected, etc) reveal that whether the author of a tweet is trustworthy.", "labels": [], "entities": []}, {"text": "(c) The Word-cluster feature provides semantic information.", "labels": [], "entities": []}, {"text": "(3) The performance of Linguistic-informed and Word vector features in three classifications is mixed.", "labels": [], "entities": []}, {"text": "The Linguistic-informed features do notwork in the 1-step, however they contribute to the 2-step classification and subtask B.", "labels": [], "entities": []}, {"text": "By observation, the lemmatization and stem n-gram outperform the original n-gram probably because that lemmatization and stem unify the form of words, thus reducing the dimension of feature and unnecessary noise.", "labels": [], "entities": []}, {"text": "For Word vector, GloVe slightly outperforms other word vectors.", "labels": [], "entities": [{"text": "Word vector", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.6599057018756866}, {"text": "GloVe", "start_pos": 17, "end_pos": 22, "type": "METRIC", "confidence": 0.9178499579429626}]}, {"text": "(4) From the algorithm comparison experiments, the ensemble models for 1-step of subtask A and subtask B are superior to the models using single algorithms, different learning algorithms contribute differently to the classification performance, that is why we conduct majority vote to ensemble those effective learning algorithms.", "labels": [], "entities": []}, {"text": "However, we directly use the LR algorithm in 2-step on account of its best performance.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results of feature and algorithm selection experiments for both Subtask A and Subtask B.  1-step, 2-step represent the first and second classification of subtask A respectively,", "labels": [], "entities": []}]}