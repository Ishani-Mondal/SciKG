{"title": [{"text": "SentiME++ at SemEval-2017 Task 4: Stacking State-of-the-Art Classifiers to Enhance Sentiment Classification", "labels": [], "entities": [{"text": "Sentiment Classification", "start_pos": 83, "end_pos": 107, "type": "TASK", "confidence": 0.8416359722614288}]}], "abstractContent": [{"text": "In this paper, we describe the participation of the SentiME++ system to the Se-mEval 2017 Task 4A \"Sentiment Analysis in Twitter\" that aims to classify whether English tweets are of positive, neutral or negative sentiment.", "labels": [], "entities": []}, {"text": "SentiME++ is an ensemble approach to sentiment analysis that leverages stacked generalization to automatically combine the predictions of five state-of-the-art sentiment classifiers.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.9325564503669739}]}, {"text": "Sen-tiME++ achieved officially 61.30% F1-score, ranking 12 th out of 38 participants.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9995142221450806}]}], "introductionContent": [{"text": "The SemEval-2017 Task 4 () focuses on the classification of tweets into positive, neutral and negative sentiment classes.", "labels": [], "entities": []}, {"text": "In 2015, the Webis system ( showed the effectiveness of ensemble methods for sentiment classification by winning the SemEval-2015 Task 10 \"polarity detection\" challenge through the combination of four classifiers that had participated to previous editions of SemEval.", "labels": [], "entities": [{"text": "Webis system", "start_pos": 13, "end_pos": 25, "type": "DATASET", "confidence": 0.9279949069023132}, {"text": "sentiment classification", "start_pos": 77, "end_pos": 101, "type": "TASK", "confidence": 0.924707293510437}, {"text": "SemEval-2015 Task 10 \"polarity detection\" challenge", "start_pos": 117, "end_pos": 168, "type": "TASK", "confidence": 0.8315010592341423}]}, {"text": "In 2016, we have combined the original public release of the Webis system with the Stanford Sentiment System () using bagging, creating the SentiME system (Sygkounas et al., 2016b,a) which won the ESWC2016 Semantic Sentiment Analysis challenge.", "labels": [], "entities": [{"text": "ESWC2016 Semantic Sentiment Analysis challenge", "start_pos": 197, "end_pos": 243, "type": "TASK", "confidence": 0.6706633508205414}]}, {"text": "In bagging, the predictions of the classifiers trained on different bootstrap samples (bags) are simply averaged to obtained a final prediction.", "labels": [], "entities": []}, {"text": "In this paper, we propose SentiME++, an enhanced version of the SentiME system that combines the predictions of the base classifiers through stacked generalization.", "labels": [], "entities": []}, {"text": "In Section 2, we detail our approach to stack a meta-learner on top of five state-of-the-art sentiment classifiers to combine their predictions.", "labels": [], "entities": []}, {"text": "In Section 3, we describe the experimental setup of our participation to SemEval and we report the results we obtained in Section 4.", "labels": [], "entities": []}, {"text": "Finally, we conclude the paper in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe the experimental setup of the SentiME++ system for the participation to the SemEval2017 Task4A challenge.", "labels": [], "entities": [{"text": "SemEval2017 Task4A challenge", "start_pos": 105, "end_pos": 133, "type": "TASK", "confidence": 0.8725040753682455}]}], "tableCaptions": [{"text": " Table 1: Lexicons used by each sub-classifier included into SentiME++", "labels": [], "entities": []}, {"text": " Table 2: Comparison among trained models on  SemEval2016-test dataset for SentiME and Sen- tiME++ according to F1 scores", "labels": [], "entities": [{"text": "SemEval2016-test dataset", "start_pos": 46, "end_pos": 70, "type": "DATASET", "confidence": 0.7644562423229218}, {"text": "F1", "start_pos": 112, "end_pos": 114, "type": "METRIC", "confidence": 0.9983538389205933}]}, {"text": " Table 3:  Comparison among runs on  SemEval2017-dev and SemEval2017-test dataset  for SentiME++ according to F1 scores.", "labels": [], "entities": [{"text": "SemEval2017-test dataset", "start_pos": 57, "end_pos": 81, "type": "DATASET", "confidence": 0.8123380839824677}, {"text": "F1", "start_pos": 110, "end_pos": 112, "type": "METRIC", "confidence": 0.9968107342720032}]}]}