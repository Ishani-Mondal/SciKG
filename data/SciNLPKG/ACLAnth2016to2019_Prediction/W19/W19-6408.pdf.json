{"title": [{"text": "FinTOC-2019 Shared Task: Finding Title in Text Blocks", "labels": [], "entities": [{"text": "FinTOC-2019", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.6069141030311584}, {"text": "Finding Title in Text Blocks", "start_pos": 25, "end_pos": 53, "type": "TASK", "confidence": 0.8177290678024292}]}], "abstractContent": [{"text": "As part of FNP Workshop Series, \"Title Detec-tion\" is one of the two shared tasks proposed on Financial Document Structure Extraction.", "labels": [], "entities": [{"text": "FNP Workshop Series", "start_pos": 11, "end_pos": 30, "type": "DATASET", "confidence": 0.9364715417226156}, {"text": "Title Detec-tion", "start_pos": 33, "end_pos": 49, "type": "TASK", "confidence": 0.7869476974010468}, {"text": "Financial Document Structure Extraction", "start_pos": 94, "end_pos": 133, "type": "TASK", "confidence": 0.6220124661922455}]}, {"text": "The objective of the task was to classify a given text block, that had been extracted from financial prospectuses in pdf format, as a title.", "labels": [], "entities": []}, {"text": "Our DNN-based approach scored a weighted F1 of 97.16% on the test data.", "labels": [], "entities": [{"text": "F1", "start_pos": 41, "end_pos": 43, "type": "METRIC", "confidence": 0.9968164563179016}]}], "introductionContent": [{"text": "The Portable Document Format, also known as pdf, is an electronic document format from Adobe Inc.", "labels": [], "entities": []}, {"text": "Launched in early 1990s, this format has now become the de-facto means of sharing information across the Internet.", "labels": [], "entities": []}, {"text": "However, given the lack of \"basic high level logical structure information\" (), the process of layout and content extraction from a pdf is difficult.", "labels": [], "entities": [{"text": "layout and content extraction", "start_pos": 95, "end_pos": 124, "type": "TASK", "confidence": 0.646037794649601}]}, {"text": "The obstacles in extracting information from a pdf, as enumerated by, are: \u2022 absence of information regarding structure \u2022 disagreement of the render order with the \"reading order\" \u2022 overlap of object blocks \u2022 myriad layouts and fonts Consider the process of automating the information extraction from financial documents.", "labels": [], "entities": [{"text": "information extraction from financial documents", "start_pos": 273, "end_pos": 320, "type": "TASK", "confidence": 0.8372142672538757}]}, {"text": "Not being able to recognize where a paragraph begins or ends in a financial report can be a strain on many levels: a) it not only blurs important information, but b) can also be misleading in decisions taken based on said report.", "labels": [], "entities": []}, {"text": "Though a number of open-source and commercial tools are available, the goal of establishing correctly a semantic unit (paragraphs, tables) and ascertaining its role (title, header) is far from being complete.", "labels": [], "entities": []}, {"text": "The FinTOC-2019 Shared Task: \"Financial Document Structure Extraction\" of Financial Narrative Processing Workshop comprises two shared-tasks: \u2022 Title detection In this paper, we propose and evaluate three methods to detect titles (Shared Task 1).", "labels": [], "entities": [{"text": "Financial Document Structure Extraction", "start_pos": 30, "end_pos": 69, "type": "TASK", "confidence": 0.6185828670859337}, {"text": "Financial Narrative Processing Workshop", "start_pos": 74, "end_pos": 113, "type": "TASK", "confidence": 0.697778545320034}, {"text": "Title detection", "start_pos": 144, "end_pos": 159, "type": "TASK", "confidence": 0.8151037991046906}]}, {"text": "Since text comes in many different formats, this problem can become exponentially heavy to treat.", "labels": [], "entities": []}, {"text": "For that purpose, our experiment is concerned with identifying only titles in pdf reports.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our first approach was to use a standard SVM classifier to understand the data and evaluate their non-linearity.", "labels": [], "entities": []}, {"text": "The second and third approaches are based on deep learning classifiers.", "labels": [], "entities": []}, {"text": "The second design is inspired by a BiLSTM recurrent neural network (RNN) model with attention ().", "labels": [], "entities": []}, {"text": "The third model is a convolutional neural network (CNN) with character embedding ().", "labels": [], "entities": []}, {"text": "For the given training data set, approximately 1 in 6 text blocks was a title.", "labels": [], "entities": []}, {"text": "Thus, it was a case of class imbalance.", "labels": [], "entities": []}, {"text": "A classifier which labels every text block as 'non-title' scored a weighted F1 of 80.12 %.", "labels": [], "entities": [{"text": "F1", "start_pos": 76, "end_pos": 78, "type": "METRIC", "confidence": 0.9977276921272278}]}, {"text": "Our objective was to improve this score.", "labels": [], "entities": []}, {"text": "The performance of the three models on train and leaderboard sets are listed in.", "labels": [], "entities": []}, {"text": "In this Table, the scores we obtained locally (F1 (home)) are compared with the final score on competition test set (F1 (lboard)).", "labels": [], "entities": [{"text": "F1", "start_pos": 47, "end_pos": 49, "type": "METRIC", "confidence": 0.9978106617927551}, {"text": "competition test set", "start_pos": 95, "end_pos": 115, "type": "DATASET", "confidence": 0.7573586304982504}, {"text": "F1", "start_pos": 117, "end_pos": 119, "type": "METRIC", "confidence": 0.99434494972229}]}, {"text": "The experiment 1 corresponds to the results sent by the first deadline and the second one refers to the extended deadline submission.", "labels": [], "entities": []}, {"text": "As the Deep Learning models originally had been trained on different GPU, we also added a comparative table on the model with best performances (CNN) with same architecture and parameters as the one provided for leaderboard results, so the influence of the architecture is clarified (Table 2).", "labels": [], "entities": [{"text": "CNN)", "start_pos": 145, "end_pos": 149, "type": "METRIC", "confidence": 0.953628271818161}]}], "tableCaptions": [{"text": " Table 1: Comparative table of results provided for leaderboard", "labels": [], "entities": [{"text": "Comparative", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9247379899024963}]}, {"text": " Table 2: Compared results for CNN, GPU dependent", "labels": [], "entities": [{"text": "CNN", "start_pos": 31, "end_pos": 34, "type": "DATASET", "confidence": 0.8587004542350769}, {"text": "GPU", "start_pos": 36, "end_pos": 39, "type": "DATASET", "confidence": 0.9090843796730042}]}]}