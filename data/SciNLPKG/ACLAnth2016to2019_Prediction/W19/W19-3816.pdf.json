{"title": [{"text": "On GAP coreference resolution shared task: insights from the 3rd place solution", "labels": [], "entities": [{"text": "GAP coreference resolution shared task", "start_pos": 3, "end_pos": 41, "type": "TASK", "confidence": 0.9118195295333862}]}], "abstractContent": [{"text": "This paper presents the 3rd-place-winning solution to the GAP coreference resolution shared task.", "labels": [], "entities": [{"text": "GAP coreference resolution shared task", "start_pos": 58, "end_pos": 96, "type": "TASK", "confidence": 0.9306062579154968}]}, {"text": "The approach adopted consists of two key components: fine-tuning the BERT language representation model (Devlin et al., 2018) and the usage of external datasets during the training process.", "labels": [], "entities": [{"text": "BERT language representation", "start_pos": 69, "end_pos": 97, "type": "TASK", "confidence": 0.5794070363044739}]}, {"text": "The model uses hidden states from the intermediate BERT layers instead of the last layer.", "labels": [], "entities": [{"text": "BERT", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.9207696914672852}]}, {"text": "The resulting system almost eliminates the difference in log loss per gender during the cross-validation, while providing high performance.", "labels": [], "entities": [{"text": "log loss", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9018961489200592}]}], "introductionContent": [{"text": "The GAP coreference resolution shared task promotes gender fair modelling with its GAP dataset.", "labels": [], "entities": [{"text": "GAP coreference resolution shared task", "start_pos": 4, "end_pos": 42, "type": "TASK", "confidence": 0.7707759380340576}, {"text": "gender fair modelling", "start_pos": 52, "end_pos": 73, "type": "TASK", "confidence": 0.6356204648812612}, {"text": "GAP dataset", "start_pos": 83, "end_pos": 94, "type": "DATASET", "confidence": 0.9645184874534607}]}, {"text": "GAP is a coreference dataset for the resolution of ambiguous pronounname pairs in real-world context.", "labels": [], "entities": [{"text": "resolution of ambiguous pronounname pairs", "start_pos": 37, "end_pos": 78, "type": "TASK", "confidence": 0.885691511631012}]}, {"text": "GAP has a particular focus on the balance of masculine and feminine pronouns and allows for gender-specific evaluation.", "labels": [], "entities": []}, {"text": "The challenge was hosted by Kaggle and consisted of two stages.", "labels": [], "entities": [{"text": "Kaggle", "start_pos": 28, "end_pos": 34, "type": "DATASET", "confidence": 0.9035962224006653}]}, {"text": "Stage 1 attracted 838 participants, and stage 2 involved 263 participants.", "labels": [], "entities": []}, {"text": "GAP training examples look the following way: Burnett Stone (Peter Fonda) is Lily's grandfather and Lady's caretaker.", "labels": [], "entities": [{"text": "GAP training", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.805354654788971}]}, {"text": "He keeps her in Muffle Mountain.", "labels": [], "entities": [{"text": "Muffle Mountain", "start_pos": 16, "end_pos": 31, "type": "DATASET", "confidence": 0.9444363713264465}]}, {"text": "where her is ambiguous pronoun, Lily is candidate mention A, and Lady is the candidate mention B.", "labels": [], "entities": []}, {"text": "The data was extracted from Wikipedia, so, in addition to the text, the source URL of the article is given.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 28, "end_pos": 37, "type": "DATASET", "confidence": 0.9560855031013489}]}, {"text": "The goal is to predict whether the ambiguous pronoun refers to the mention A, to the mention B or to NEITHER of them.", "labels": [], "entities": [{"text": "NEITHER", "start_pos": 101, "end_pos": 108, "type": "METRIC", "confidence": 0.9775562882423401}]}, {"text": "The problem was treated as gold-two-mention task, where the model has the access to the position of the mentions.", "labels": [], "entities": []}], "datasetContent": [{"text": "Class distributions shows the class distributions for the three final datasets used: GAP train, which includes all GAP data, warm-up train, which includes Ontonotes 5.0, Winogdender, DPR and warm-up validation, which is Winobias.", "labels": [], "entities": [{"text": "Ontonotes 5.0", "start_pos": 155, "end_pos": 168, "type": "DATASET", "confidence": 0.8276306986808777}]}, {"text": "As can be seen, warm-up train has the most balanced distribution of classes, while GAP train has a lower portion of the category NEITHER.", "labels": [], "entities": [{"text": "GAP", "start_pos": 83, "end_pos": 86, "type": "METRIC", "confidence": 0.4812960922718048}, {"text": "NEITHER", "start_pos": 129, "end_pos": 136, "type": "METRIC", "confidence": 0.9378185868263245}]}, {"text": "Evaluation metrics Solutions were evaluated using the multi-class logarithmic loss.", "labels": [], "entities": []}, {"text": "For each pronoun, the participants had to provide the probabilities of it belonging to A, B, or NEITHER.", "labels": [], "entities": [{"text": "NEITHER", "start_pos": 96, "end_pos": 103, "type": "METRIC", "confidence": 0.8898006677627563}]}, {"text": "The formula to evaluate the performance of the model is: where N is the number of samples in the test set, M is number of classes, 3, log is the natural logarithm, y ij is 1 if observation i belongs to class j and 0 otherwise, and p ij is the predicted probability that observation i belongs to class j.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Confusion matrix on the whole stage 1 data  with 10 fold cross validation.", "labels": [], "entities": []}, {"text": " Table 3: Performance of the models on the test stage 2  data.", "labels": [], "entities": []}, {"text": " Table 4: Number of mislabelled examples in the  datasets per gender.", "labels": [], "entities": []}]}