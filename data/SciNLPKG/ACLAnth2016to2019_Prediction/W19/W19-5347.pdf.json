{"title": [], "abstractContent": [{"text": "In this paper, we present the University of Helsinki submissions to the WMT 2019 shared task on news translation in three language pairs: English-German, English-Finnish and Finnish-English.", "labels": [], "entities": [{"text": "WMT 2019 shared task", "start_pos": 72, "end_pos": 92, "type": "TASK", "confidence": 0.5607848465442657}, {"text": "news translation", "start_pos": 96, "end_pos": 112, "type": "TASK", "confidence": 0.6571836918592453}]}, {"text": "This year, we focused first on cleaning and filtering the training data using multiple data-filtering approaches, resulting in much smaller and cleaner training sets.", "labels": [], "entities": []}, {"text": "For English-German, we trained both sentence-level transformer models and compared different document-level translation approaches.", "labels": [], "entities": [{"text": "document-level translation", "start_pos": 93, "end_pos": 119, "type": "TASK", "confidence": 0.6950134336948395}]}, {"text": "For Finnish-English and English-Finnish we focused on different segmentation approaches, and we also included a rule-based system for English-Finnish.", "labels": [], "entities": []}], "introductionContent": [{"text": "The University of Helsinki participated in the WMT 2019 news translation task with four primary submissions.", "labels": [], "entities": [{"text": "WMT 2019 news translation task", "start_pos": 47, "end_pos": 77, "type": "TASK", "confidence": 0.8572817444801331}]}, {"text": "We submitted neural machine translation systems for English-to-Finnish, Finnish-to-English and English-to-German, and a rule-based machine translation system for English-to-Finnish.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 13, "end_pos": 39, "type": "TASK", "confidence": 0.7081618110338846}, {"text": "rule-based machine translation", "start_pos": 120, "end_pos": 150, "type": "TASK", "confidence": 0.6508757074673971}]}, {"text": "Most of our efforts for this year's WMT focused on data selection and pre-processing (Section 2), sentence-level translation models for Englishto-German, English-to-Finnish and Finnish-toEnglish (Section 3), document-level translation models for English-to-German (Section 4), and a comparison of different word segmentation approaches for Finnish (Section 3.3).", "labels": [], "entities": [{"text": "WMT", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.7456923723220825}, {"text": "sentence-level translation", "start_pos": 98, "end_pos": 124, "type": "TASK", "confidence": 0.6409042775630951}, {"text": "word segmentation", "start_pos": 307, "end_pos": 324, "type": "TASK", "confidence": 0.7397485971450806}]}, {"text": "The final submitted NMT systems are summarized in Section 5, while the rule-based machine translation system is described in Section 3.4. 2 Pre-processing, data filtering and back-translation It is well known that data pre-processing and selection has a huge effect on translation quality in neural machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 82, "end_pos": 101, "type": "TASK", "confidence": 0.7235184907913208}, {"text": "data filtering", "start_pos": 156, "end_pos": 170, "type": "TASK", "confidence": 0.820042222738266}, {"text": "neural machine translation", "start_pos": 292, "end_pos": 318, "type": "TASK", "confidence": 0.653010348478953}]}, {"text": "We spent substantial effort on filtering data in order to reduce noiseespecially in the web-crawled data sets-and to match the target domain of news data.", "labels": [], "entities": []}, {"text": "The resulting training sets, after applying the steps described below, are for 15.7M sentence pairs for English-German, 8.5M sentence pairs for English-Finnish, and 12.3M-26.7M sentence pairs (different samplings of back-translations) for Finnish-English.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Basic heuristics for filtering -percentage of  lines removed. For English-Finnish the statistics for  ParaCrawl are not available because the cleanup script  was applied after other filters.", "labels": [], "entities": [{"text": "ParaCrawl", "start_pos": 112, "end_pos": 121, "type": "DATASET", "confidence": 0.8701024651527405}]}, {"text": " Table 2: Percentage of lines rejected by each filter for  English-German data sets. Each line can be rejected  by several filters. The total of rejected lines is the last  row of the table.", "labels": [], "entities": []}, {"text": " Table 3: Percentage of lines rejected by each filter for  English-Finnish data sets. The strict version is the  same as for English-German, and the relax version ap- plies relaxed thresholds.", "labels": [], "entities": []}, {"text": " Table 5: English-German results from individual Mar- ianNMT transformer models and their combinations  (cased BLEU).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 111, "end_pos": 115, "type": "METRIC", "confidence": 0.9978553652763367}]}, {"text": " Table 7: BLEU scores comparison between Sentence- Piece and Omorfi+BPE-segmented models.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9975712895393372}, {"text": "BPE-segmented", "start_pos": 68, "end_pos": 81, "type": "METRIC", "confidence": 0.7913159728050232}]}, {"text": " Table 8: Results from individual MarianNMT trans- former models and their combinations for English to  Finnish (cased BLEU). The top matrix result refers to  the best system reported in the on-line evaluation ma- trix (accessed on May 16, 2019).", "labels": [], "entities": [{"text": "MarianNMT trans- former", "start_pos": 34, "end_pos": 57, "type": "DATASET", "confidence": 0.8348542004823685}, {"text": "BLEU", "start_pos": 119, "end_pos": 123, "type": "METRIC", "confidence": 0.9922415018081665}]}, {"text": " Table 9: Results from individual MarianNMT trans- former models and their combinations for Finnish to  English (cased BLEU). Results denoted as top refer to  the top systems reported at the on-line evaluation ma- trix (accessed on May 16, 2019), one trained with the  2019 data sets and one with 2017 data.", "labels": [], "entities": [{"text": "MarianNMT trans- former", "start_pos": 34, "end_pos": 57, "type": "DATASET", "confidence": 0.8267349749803543}, {"text": "BLEU", "start_pos": 119, "end_pos": 123, "type": "METRIC", "confidence": 0.9847338795661926}]}, {"text": " Table 10: Comparison of concatenation approaches for  English-German document-level translation.", "labels": [], "entities": [{"text": "English-German document-level translation", "start_pos": 55, "end_pos": 96, "type": "TASK", "confidence": 0.5660625000794729}]}, {"text": " Table 11: Results (case-sensitive BLEU) of the hierar- chical attention models on the coherent newstest 2018  dataset.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 35, "end_pos": 39, "type": "METRIC", "confidence": 0.9756504893302917}, {"text": "coherent newstest 2018  dataset", "start_pos": 87, "end_pos": 118, "type": "DATASET", "confidence": 0.7667367458343506}]}, {"text": " Table 12: Final results (case-sensitive BLEU scores)  on the 2019 news test set; partially obtained after the  deadline.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 41, "end_pos": 45, "type": "METRIC", "confidence": 0.975266695022583}, {"text": "news test set", "start_pos": 67, "end_pos": 80, "type": "DATASET", "confidence": 0.8181700507799784}]}]}