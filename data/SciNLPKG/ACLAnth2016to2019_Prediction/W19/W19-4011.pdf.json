{"title": [{"text": "A Framework for Annotating 'Related Works' to Support Feedback to Novice Writers", "labels": [], "entities": []}], "abstractContent": [{"text": "Understanding what is expected of academic writing can be difficult for novice writers to assimilate, and recent years have seen several automated tools become available to support academic writing.", "labels": [], "entities": []}, {"text": "Our work presents a framework for annotating features of the Related Work section of academic writing, that supports writer feedback.", "labels": [], "entities": []}], "introductionContent": [{"text": "Learning the skill of academic writing is critical for post-graduate students to be successful, yet many struggle to master the standard of quality expected of them (.", "labels": [], "entities": []}, {"text": "Beyond the surface characteristics of grammar and spelling, students must grasp aspects of style and content structure expected within their discipline.", "labels": [], "entities": []}, {"text": "Automated recognition of content features in academic writing has become a popular approach to assist students in recent years.", "labels": [], "entities": [{"text": "Automated recognition of content features in academic writing", "start_pos": 0, "end_pos": 61, "type": "TASK", "confidence": 0.8558003604412079}]}, {"text": "Previous work has focused on identifying rhetoric intentions, such as those described by that can be found in an Introduction (; Anthony and V. or in PhD summaries).", "labels": [], "entities": [{"text": "identifying rhetoric intentions", "start_pos": 29, "end_pos": 60, "type": "TASK", "confidence": 0.8487313191095988}]}, {"text": "Other approaches have focused on identifying argument components and relations and how these relate to essay scores ().", "labels": [], "entities": []}, {"text": "The one aspect that these approaches have in common is the need for annotated data based on taskorientated annotation schemes.", "labels": [], "entities": []}, {"text": "Our focus is on building an annotation schema which can help writers recognise appropriate intentions in writing their Related Work section, and indicate when these are missing.", "labels": [], "entities": []}, {"text": "Annotating intention in academic writing is challenging as the language and author intentions differ across the typical sections found in a paper (Introduction, Methods, Results, Discussion) and within disciplines.", "labels": [], "entities": [{"text": "Annotating intention in academic writing", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.7980695724487304}]}, {"text": "We focus on one section of scientific text that has, for the most part, been ignored in the past -the Related Work section.", "labels": [], "entities": []}, {"text": "Currently no annotation schema specifically focuses on Related Work.", "labels": [], "entities": []}, {"text": "There are schemas that capture some, but not all, elements of intentions we seek, such as those that consider citation function ( or argument zones reflecting rhetoric intentions).", "labels": [], "entities": []}, {"text": "However, these are designed for different purposes, such as understanding citation relations, summarisation or information extraction (e.g gene relations, knowledge claims).", "labels": [], "entities": [{"text": "understanding citation relations", "start_pos": 60, "end_pos": 92, "type": "TASK", "confidence": 0.8226303259531657}, {"text": "summarisation", "start_pos": 94, "end_pos": 107, "type": "TASK", "confidence": 0.9832562208175659}, {"text": "information extraction", "start_pos": 111, "end_pos": 133, "type": "TASK", "confidence": 0.7266463190317154}]}, {"text": "Thus, they also have labels that are irrelevant to Related Work, e.g. 'Conclusion', which may make the annotation task more difficult.", "labels": [], "entities": []}, {"text": "Since previous work has shown that annotation schemes benefit from being designed for their specific goal (, we propose a specific annotation framework to support automated writing feedback on Related Work.", "labels": [], "entities": []}, {"text": "This paper describes our framework for annotating the discourse of Related Work in such away that it supports feedback on writing.", "labels": [], "entities": []}, {"text": "The framework reflects qualities that both theory and experiments have shown to be important.", "labels": [], "entities": []}, {"text": "We discuss how these qualities have motivated our design along with those existing schemes that are most closely related to ours.", "labels": [], "entities": []}, {"text": "We report results that show reliable annotation for this framework.", "labels": [], "entities": []}, {"text": "Future work will investigate the degree to which such annotation can be automated.", "labels": [], "entities": []}], "datasetContent": [{"text": "Initial experiments were carried out on a preannotated dataset) consisting of 266 published scientific papers from the ACL anthology ().", "labels": [], "entities": [{"text": "ACL anthology", "start_pos": 119, "end_pos": 132, "type": "DATASET", "confidence": 0.9686664938926697}]}, {"text": "The dataset was extracted from PDF by commercial OCR software, sentence-tokenised and then manually annotated, using MMAX2).", "labels": [], "entities": [{"text": "MMAX2", "start_pos": 117, "end_pos": 122, "type": "DATASET", "confidence": 0.9496868848800659}]}, {"text": "Papers were annotated for co-reference to cited papers and to the authors' own work.", "labels": [], "entities": []}, {"text": "All the papers were 6 to 8 pages long.", "labels": [], "entities": []}, {"text": "This is important, as shortconference papers (4 pages) would have considerably shorter Related Work sections.", "labels": [], "entities": []}, {"text": "Initially, we processed the full data set, and then only those papers with Related Work sections were extracted.", "labels": [], "entities": []}, {"text": "This resulted in a data set of 113 papers.", "labels": [], "entities": []}, {"text": "Our final dataset comprised of the 95 Related Work sections that remained after we removed papers with OCR problems.", "labels": [], "entities": []}, {"text": "Authors do not always signal the relevance of a paper in its citing sentence: often it will come in the next or subsequent sentence.", "labels": [], "entities": []}, {"text": "Although we are only assigning a label to a sentence, in future work it will be necessary to look at all sentences related to a citation to determine what feedback to give.", "labels": [], "entities": []}, {"text": "This was our reason for choosing a dataset that was already marked for co-references to citations.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Author Label Agreement Matrix. The letter A  (Author) at the beginning of each entry was omitted for  the sake of clarity.", "labels": [], "entities": [{"text": "A  (Author)", "start_pos": 52, "end_pos": 63, "type": "METRIC", "confidence": 0.7909995466470718}]}, {"text": " Table 4: Cited Work and Background Label Agreement  Matrix", "labels": [], "entities": []}]}