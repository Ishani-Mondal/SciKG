{"title": [{"text": "Blackbox meets blackbox: Representational Similarity and Stability Analysis of Neural Language Models and Brains", "labels": [], "entities": [{"text": "Representational Similarity and Stability Analysis of Neural Language Models and Brains", "start_pos": 25, "end_pos": 112, "type": "TASK", "confidence": 0.7959560237147592}]}], "abstractContent": [{"text": "In this paper, we define and apply represen-tational stability analysis (ReStA), an intuitive way of analyzing neural language models.", "labels": [], "entities": [{"text": "represen-tational stability analysis (ReStA)", "start_pos": 35, "end_pos": 79, "type": "METRIC", "confidence": 0.8676648934682211}]}, {"text": "ReStA is a variant of the popular repre-sentational similarity analysis (RSA) in cog-nitive neuroscience.", "labels": [], "entities": [{"text": "repre-sentational similarity analysis (RSA)", "start_pos": 34, "end_pos": 77, "type": "TASK", "confidence": 0.7187657654285431}]}, {"text": "While RSA can be used to compare representations in models, model components, and human brains, ReStA compares instances of the same model, while systematically varying single model parameter.", "labels": [], "entities": []}, {"text": "Using ReStA, we study four recent and successful neural language models, and evaluate how sensitive their internal representations are to the amount of prior context.", "labels": [], "entities": []}, {"text": "Using RSA, we perform a systematic study of how similar the representational spaces in the first and second (or higher) layers of these models are to each other and to patterns of activation in the human brain.", "labels": [], "entities": [{"text": "RSA", "start_pos": 6, "end_pos": 9, "type": "TASK", "confidence": 0.9074024558067322}]}, {"text": "Our results reveal surprisingly strong differences between language models, and give insights into where the deep linguistic processing, that integrates information over multiple sentences, is happening in these models.", "labels": [], "entities": []}, {"text": "The combination of ReStA and RSA on models and brains allows us to start addressing the important question of what kind of linguistic processes we can hope to observe in fMRI brain imaging data.", "labels": [], "entities": [{"text": "ReStA", "start_pos": 19, "end_pos": 24, "type": "METRIC", "confidence": 0.7702562808990479}]}, {"text": "In particular, our results suggest that the data on story reading from Wehbe et al.", "labels": [], "entities": [{"text": "story reading", "start_pos": 52, "end_pos": 65, "type": "TASK", "confidence": 0.7677029371261597}]}, {"text": "(2014) contains a signal of shallow linguistic processing, but show no evidence on the more interesting deep linguistic processing.", "labels": [], "entities": []}, {"text": "1 Representational Similarity Representational similarity analysis (RSA) is a technique which allows us to compare heterogeneous representational spaces (Laakso and Cot-trell, 2000).", "labels": [], "entities": [{"text": "1 Representational Similarity Representational similarity analysis (RSA)", "start_pos": 0, "end_pos": 72, "type": "TASK", "confidence": 0.7547922995355394}]}, {"text": "It is very common in cognitive neuro-science because it allows researchers to study the relation between patterns of activation in the brain and representations of stimuli in a computational model (Kriegeskorte et al., 2008).", "labels": [], "entities": []}, {"text": "The key idea is simple: instead of directly trying to map models to brains, we first construct two similarity matrices that record how similar brain responses are to each other for different stimuli, and how similar the computational model's representations for each stimulus are to each other.", "labels": [], "entities": []}, {"text": "The representa-tional similarity score is then defined as the similarity (typically: Pearson's correlation) of the two similarity matrices (or equivalently: the similarity of two distance matrices).", "labels": [], "entities": [{"text": "representa-tional similarity score", "start_pos": 4, "end_pos": 38, "type": "METRIC", "confidence": 0.6641999880472819}, {"text": "similarity", "start_pos": 62, "end_pos": 72, "type": "METRIC", "confidence": 0.9706354141235352}, {"text": "Pearson's correlation)", "start_pos": 85, "end_pos": 107, "type": "METRIC", "confidence": 0.8784519731998444}]}, {"text": "RSA can also be applied to deep learning models (Laakso and Cottrell, 2000; Dharmaretnam and Fyshe, 2018; Alvarez-Melis and Jaakkola, 2018; Wang et al., 2018; Chrupa\u0142a and Alishahi, 2019).", "labels": [], "entities": [{"text": "RSA", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8510894179344177}]}, {"text": "In this paper, we present a large-scale study and comparison of both neural language models and fMRI data from brain imaging experiments with human subjects, using RSA.", "labels": [], "entities": []}, {"text": "However, we extend standard RSA using an approach we call Repre-sentational Stability Analysis (ReStA).", "labels": [], "entities": [{"text": "RSA", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.9371881484985352}, {"text": "Repre-sentational Stability Analysis (ReStA)", "start_pos": 58, "end_pos": 102, "type": "TASK", "confidence": 0.7577864577372869}]}, {"text": "The idea is again simple: we apply RSA to compare instances of the same model, while systematically varying a model parameter.", "labels": [], "entities": []}, {"text": "We focus on a single parameter: the length of the prior context presented to the model.", "labels": [], "entities": []}, {"text": "Varying the amount of context allows us to quantify the degree of context-dependence of different neu-ral language models, and different components of those models.", "labels": [], "entities": []}, {"text": "If internal representations are similarly organized regardless of how much additional context is presented to the model, context-dependence is low.", "labels": [], "entities": []}, {"text": "If, on the other hand, representations change with each additional amount of context included, context-dependence is high.", "labels": [], "entities": []}, {"text": "Using this approach, we find intriguing differences between some recent, successful neural language models (GoogleLM, ELMO, BERT and the Universal Sentence Encoder; Table 1), and between the first and deeper layers of those models.", "labels": [], "entities": [{"text": "GoogleLM", "start_pos": 108, "end_pos": 116, "type": "DATASET", "confidence": 0.9106327891349792}, {"text": "BERT", "start_pos": 124, "end_pos": 128, "type": "METRIC", "confidence": 0.9944490194320679}]}, {"text": "Context-dependence, in turn, gives us a handle on an important question in the research that tries", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Statistics of the Harry Potter dataset.", "labels": [], "entities": [{"text": "Harry Potter dataset", "start_pos": 28, "end_pos": 48, "type": "DATASET", "confidence": 0.6537317037582397}]}]}