{"title": [{"text": "Detecting Paraphrases of Standard Clause Titles in Insurance Contracts", "labels": [], "entities": [{"text": "Detecting Paraphrases of Standard Clause Titles in Insurance Contracts", "start_pos": 0, "end_pos": 70, "type": "TASK", "confidence": 0.8681165112389458}]}], "abstractContent": [{"text": "For the analysis of contract texts, validated model texts, such as model clauses, can be used to identify used contract clauses.", "labels": [], "entities": []}, {"text": "This paper investigates how the similarity between titles of model clauses and headings extracted from contracts can be computed, and which similarity measure is most suitable for this.", "labels": [], "entities": []}, {"text": "For the calculation of the similarities between title pairs we tested various variants of string similarity and token based similarity.", "labels": [], "entities": []}, {"text": "We also compare two additional semantic similarity measures based on word embeddings using pre-trained embeddings and word embeddings trained on contract texts.", "labels": [], "entities": []}, {"text": "The identification of the model clause title can be used as a starting point for the mapping of clauses found in contracts to verified clauses.", "labels": [], "entities": []}], "introductionContent": [{"text": "The calculation of text similarities is a key factor in the analysis of texts that consist of recurring text parts or that have to correspond to formulation patterns.", "labels": [], "entities": []}, {"text": "In the insurance industry, there is a multitude of individual contracts between companies and insurance companies, or between insurance companies and reinsurance companies.", "labels": [], "entities": []}, {"text": "However, most contracts more or less standardized clauses and text templates.", "labels": [], "entities": []}, {"text": "In order to find the structure of a contract and to support the contract review, it is important to find all parts in the contract that are based on standardized clauses.", "labels": [], "entities": []}, {"text": "In our work, we compare a heading in the contract to be analyzed with all clause titles in a collection of model clauses.", "labels": [], "entities": []}, {"text": "We have two reasons to do this title-based comparison: in the first place we work with scanned PDF texts.", "labels": [], "entities": []}, {"text": "Thus we have to reconstruct the often complicated layout structure of the contract text.", "labels": [], "entities": []}, {"text": "For the extraction of text we apply pdfminer, a Python PDF parser . We use a trained classifier to identify headers, footers, enumeration elements, headings, stamps and hand-written remarks.", "labels": [], "entities": []}, {"text": "We describe our procedure of layout-based structure recognition and analysis in.", "labels": [], "entities": [{"text": "layout-based structure recognition and analysis", "start_pos": 29, "end_pos": 76, "type": "TASK", "confidence": 0.694536691904068}]}, {"text": "Once we can identify titles of model clauses, we know what type of formatting is used for clause titles, and we can split up the main part of the contract text into a list of clause text blocks.", "labels": [], "entities": []}, {"text": "Second, comparing the text of the clause bodies with all possible candidate model clauses requires less effort, if our system identifies the model clause candidate(s) based on their titles.", "labels": [], "entities": []}, {"text": "An overview of the work presented here and its place in the overall project workflow is given in.", "labels": [], "entities": []}, {"text": "The subject of this paper concerns the first point from, the similarity calculation of the model clauses.", "labels": [], "entities": []}, {"text": "In some cases, the title found in a contract is identical to the title of a model clause.", "labels": [], "entities": []}, {"text": "In many cases, however the titles differ.", "labels": [], "entities": []}, {"text": "We can identify many patterns of variation, such as addition or omission of  the word Clause, addition of a colon at the end, a number in the beginning, etc.", "labels": [], "entities": []}, {"text": "Some examples of such variations are given in.", "labels": [], "entities": []}, {"text": "In addition, we have OCR errors and errors in the extraction of the headings, especially when the headings consist of several lines and are placed in the left margin, which is quite normal for insurance contracts.", "labels": [], "entities": [{"text": "OCR", "start_pos": 21, "end_pos": 24, "type": "METRIC", "confidence": 0.8786003589630127}]}, {"text": "If we manually defined a number of patterns of allowed variations, we would risk overfitting on the clauses we have seen and missing many unseen variations.", "labels": [], "entities": []}, {"text": "Instead, we would like to use a simple similarity measure to compare the clause titles.", "labels": [], "entities": []}, {"text": "The rest of the paper deals with the selection of the best similarity measure for this task.", "labels": [], "entities": []}, {"text": "In order to evaluate similarity measures we constructed two sets of clause titles.", "labels": [], "entities": []}, {"text": "The first set contains pairs of corresponding and non-corresponding titles.", "labels": [], "entities": []}, {"text": "The task here is to predict whether two titles correspond or not.", "labels": [], "entities": []}, {"text": "The second set contains a large number of extracted headings from contracts.", "labels": [], "entities": []}, {"text": "The task is to predict which headings correspond to the title of a model clause.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the first experiment we evaluate the various distance measures on a classification task in which equivalent pairs of titles have to be distinguished from non-equivalent pairs of titles.", "labels": [], "entities": []}, {"text": "The second experiment is a retrieval experiment in which all titles corresponding to the title of a model clause have to be found in a set of all headings extracted from a number of contracts.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Results for Retrieval-Evaluation (Experiment 2). Average precision (AP), Area under the curve  (AUC)", "labels": [], "entities": [{"text": "Average precision (AP)", "start_pos": 59, "end_pos": 81, "type": "METRIC", "confidence": 0.8708603739738464}, {"text": "Area under the curve  (AUC)", "start_pos": 83, "end_pos": 110, "type": "METRIC", "confidence": 0.8909563166754586}]}, {"text": " Table 5: Incorrectly classified title pairs from experiment 1. Cells contain the computed similarity. In case  the computed similarity leads to wrong classification (using the optimal threshold as given in the second  line of the table), the cell has a red background.", "labels": [], "entities": []}]}