{"title": [{"text": "One-to-X analogical reasoning on word embeddings: a case for diachronic armed conflict prediction from news texts", "labels": [], "entities": [{"text": "One-to-X analogical reasoning", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.642959992090861}, {"text": "diachronic armed conflict prediction from news", "start_pos": 61, "end_pos": 107, "type": "TASK", "confidence": 0.7143101493517557}]}], "abstractContent": [{"text": "We extend the well-known word analogy task to a one-to-X formulation, including one-to-none cases, when no correct answer exists.", "labels": [], "entities": [{"text": "word analogy task", "start_pos": 25, "end_pos": 42, "type": "TASK", "confidence": 0.804942766825358}]}, {"text": "The task is cast as a relation discovery problem and applied to historical armed conflicts datasets, attempting to predict new relations of type 'location:armed-group' based on data about past events.", "labels": [], "entities": [{"text": "relation discovery", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.8033129274845123}]}, {"text": "As the source of semantic information, we use diachronic word embedding models trained on English news texts.", "labels": [], "entities": []}, {"text": "A simple technique to improve diachronic performance in such task is demonstrated, using a threshold based on a function of cosine distance to decrease the number of false positives; this approach is shown to be beneficial on two different corpora.", "labels": [], "entities": []}, {"text": "Finally, we publish a ready-to-use test set for one-to-X analogy evaluation on historical armed conflicts data.", "labels": [], "entities": []}, {"text": "Performance on the task of analogical inference (or 'word analogies') is one of the most widespread means to evaluate distributional word representation models, with 'KING is to QUEEN as MAN is to ? (WOMAN)' being a famous example.", "labels": [], "entities": [{"text": "KING", "start_pos": 167, "end_pos": 171, "type": "METRIC", "confidence": 0.9899369478225708}]}, {"text": "It also has deep connections to the relational similarity task (Jurgens et al., 2012).", "labels": [], "entities": [{"text": "relational similarity task", "start_pos": 36, "end_pos": 62, "type": "TASK", "confidence": 0.8634444872538248}]}, {"text": "Most often, ana-logical inference is formulated as a strict proportion , and the model has to provide exactly one best answer for each question (assuming that it is impossible that, e.g., WOMAN and GIRL are equally correct answers for the question above).", "labels": [], "entities": []}, {"text": "We reformulate the analogical inference task and extend it to include multiple-ended or one-to-X relations: one-to-one, one-to-many and one-to-none cases when an entity is not included in this particular relation type, so there is no correct answer for it.", "labels": [], "entities": []}, {"text": "This way, the model has to provide as many correct answers as possible, while providing as few incorrect answers as possible.", "labels": [], "entities": []}, {"text": "More formally , the task is as follows: fora given vocabulary V , a relation of a type z, and an entity x \u2208 V , identify any pairs x; i \u2208 V such that z holds between x and i.", "labels": [], "entities": []}, {"text": "Note that this task has been tackled in NLP using a number of methods, and not necessarily using analogical reasoning; however, in this work we employ a supervised approach implying learning from 'example' or 'prototypical' pairs (similar to analogies).", "labels": [], "entities": []}, {"text": "Our method also does not require providing i candidates: they are inferred automatically from an embedding model.", "labels": [], "entities": []}, {"text": "Proper analogy test sets are difficult to compile , especially when the complex structure described above is desired.", "labels": [], "entities": []}, {"text": "Thus, we limit ourselves to one particular type of semantic relations, on which objective data can be gathered from extra-linguistic sources: those between a geographical location (country) and an insurgent group involved in an armed conflict against the government of the country in a given time period.", "labels": [], "entities": []}, {"text": "We use the historical armed conflicts data provided publicly by the UCDP project (Gleditsch et al., 2002).", "labels": [], "entities": [{"text": "UCDP project", "start_pos": 68, "end_pos": 80, "type": "DATASET", "confidence": 0.9436264336109161}]}, {"text": "These datasets contain the needed relations: several armed groups can operate in one location, one group can operate in several locations, and obviously some locations lack any insurgents to speak of.", "labels": [], "entities": []}, {"text": "At the same time, news corpora contain a lot of information about armed conflicts, while being comparatively easy to obtain and train distri-butional word embedding models on.", "labels": [], "entities": []}, {"text": "Since the UCDP data provides exact dates for all the conflicts, we cast our one-to-X analogical reasoning task in a diachronic setup.", "labels": [], "entities": [{"text": "UCDP data", "start_pos": 10, "end_pos": 19, "type": "DATASET", "confidence": 0.9749349355697632}, {"text": "analogical reasoning task", "start_pos": 85, "end_pos": 110, "type": "TASK", "confidence": 0.8535411357879639}]}, {"text": "We attempt to find out whether a distributional vector space retains enough structure to trace the relation after the model was additionally trained with a comparable amount of new in-domain texts created in the subsequent time period.", "labels": [], "entities": []}, {"text": "The contributions of this work are: (1) We re-formulate the well-known word analogy task such that multiple correct answers or no correct answer at all become possible (one-to-X relations).", "labels": [], "entities": [{"text": "word analogy task", "start_pos": 71, "end_pos": 88, "type": "TASK", "confidence": 0.8065659801165262}]}], "introductionContent": [], "datasetContent": [{"text": "Conflict relation data The armed conflict data comes from the UCDP/PRIO Armed Conflict Dataset 5 (ver. 18.1) ( \"Islamic State\"]').", "labels": [], "entities": [{"text": "UCDP/PRIO Armed Conflict Dataset 5 (ver. 18.1", "start_pos": 62, "end_pos": 107, "type": "DATASET", "confidence": 0.9250625908374787}]}, {"text": "Entities occurring less than 25 times in the corresponding yearly corpora were filtered out, since it is difficult for distributional models to learn meaningful embeddings for such rare words.", "labels": [], "entities": []}, {"text": "We create one such conflict relation dataset for each news corpus; one corresponding to the time span of NOW and another for Gigaword.", "labels": [], "entities": [{"text": "NOW", "start_pos": 105, "end_pos": 108, "type": "DATASET", "confidence": 0.9529091715812683}, {"text": "Gigaword", "start_pos": 125, "end_pos": 133, "type": "DATASET", "confidence": 0.9602282643318176}]}, {"text": "shows various statistics across these UCDP subsets, including the important 'new pairs share' parameter, showing what part of the conflict pairs in the years n + 1 was not seen in the years n (how much new data to guess).", "labels": [], "entities": []}, {"text": "The NoW dataset features 102 unique Location: Insurgent pairs, with 42 unique locations and 78 unique armed groups.", "labels": [], "entities": [{"text": "NoW dataset", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.9765059649944305}]}, {"text": "On average, each year 56% of these 42 locations were involved in armed conflicts, based on the UCDP data.", "labels": [], "entities": [{"text": "UCDP data", "start_pos": 95, "end_pos": 104, "type": "DATASET", "confidence": 0.9711125791072845}]}, {"text": "The remaining (different each year) serve as 'negative examples' to test the ability of our approach to detect cases when no predictions have to be made.", "labels": [], "entities": []}, {"text": "For the areas involved in conflicts, the average number of active insurgents per location is about 1.5, with the maximum number being 5 6 . A replication experiment In we replicate the experiments from ( on both sets.", "labels": [], "entities": []}, {"text": "It follows their evaluation scheme, where only the presence of the correct armed group name in the k nearest neighbours of th\u00ea i mattered, and only conflict areas were present in the yearly test sets.", "labels": [], "entities": []}, {"text": "Essentially, it measures the recall @k, without penalizing the models for yielding incorrect answers along with the correct ones, and never asking questions having no correct answer at all (e.g., peaceful locations).", "labels": [], "entities": [{"text": "recall @k", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.9502716263135275}]}, {"text": "The performance is very similar on both sets, ensuring that the NOW set conveys the same signal as the Gigaword set; however, in the next section we make Gigaword 0.356 0.555 0.610 NOW 0.442 0.557 0.578: Average recall of diachronic analogy inference the task more realistic by extending the evaluation schema to the one-to-X scenario described above.", "labels": [], "entities": [{"text": "NOW set", "start_pos": 64, "end_pos": 71, "type": "DATASET", "confidence": 0.8742546141147614}, {"text": "recall", "start_pos": 212, "end_pos": 218, "type": "METRIC", "confidence": 0.9958122372627258}]}, {"text": "In our workflow, each yearly test set contains all locations, but whether a particular location is associated with any armed groups, can vary from year to year.", "labels": [], "entities": []}, {"text": "Conceptually, the task of the model is to predict correct sets of active armed groups for conflict locations and to predict the empty set for peaceful locations.", "labels": [], "entities": []}, {"text": "For a test year, an 'armed conflict projection' \u02c6 i is produced for each location using the learned transformation T n . The k nearest neighbors of\u00eeof\u00ee in M n+1 become armed group candidates (k is a hyperparameter).", "labels": [], "entities": []}, {"text": "We calculate the number of true positives (correctly predicted armed groups), false positives (incorrectly predicted armed groups), and false negatives (armed groups present in the gold data, but not predicted by the system).", "labels": [], "entities": []}, {"text": "These counts are accumulated and for each year standard precision, recall and F1 score are calculated.", "labels": [], "entities": [{"text": "precision", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9995482563972473}, {"text": "recall", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.9996994733810425}, {"text": "F1 score", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9870388805866241}]}, {"text": "These metrics are then averaged across all years in the test set.", "labels": [], "entities": []}, {"text": "Using false negatives ensures that we penalize the systems for yielding predictions for peaceful locations.", "labels": [], "entities": []}, {"text": "For the experiments, we chose k = 2, to be closer to the average number of armed groups per location in our sets.", "labels": [], "entities": []}, {"text": "shows the diachronic performance of our system in the setup when the matrix T n and the threshold r n are applied to the yearn + 1.", "labels": [], "entities": []}, {"text": "For both Gigaword and NOW datasets (and the corresponding embeddings), using the cosinebased threshold decreases recall and increases precision (differences are statistically significant with t-test, p < 0.05).", "labels": [], "entities": [{"text": "NOW datasets", "start_pos": 22, "end_pos": 34, "type": "DATASET", "confidence": 0.9293246865272522}, {"text": "recall", "start_pos": 113, "end_pos": 119, "type": "METRIC", "confidence": 0.9995359182357788}, {"text": "precision", "start_pos": 134, "end_pos": 143, "type": "METRIC", "confidence": 0.9992884397506714}]}, {"text": "At the same time, the integral  metrics of F1 consistently improves (p < 0.01).", "labels": [], "entities": [{"text": "F1", "start_pos": 43, "end_pos": 45, "type": "METRIC", "confidence": 0.9982170462608337}]}, {"text": "Thus, the thresholding reduces prediction noise in the one-to-X analogy task without sacrificing too many correct answers.", "labels": [], "entities": []}, {"text": "In our particular case, this helps to more precisely detect events of armed conflicts termination (where no insurgents should be predicted fora location), not only their start.", "labels": [], "entities": [{"text": "armed conflicts termination", "start_pos": 70, "end_pos": 97, "type": "TASK", "confidence": 0.6204467614491781}]}, {"text": "As a sanity check, we also evaluated it synchronically, that is when T n and r n are tested on the locations from the same year (including peaceful ones).", "labels": [], "entities": []}, {"text": "In this easier setup, we observed exactly the same trends).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparative statistics of UCDP data subsets", "labels": [], "entities": [{"text": "UCDP data subsets", "start_pos": 36, "end_pos": 53, "type": "DATASET", "confidence": 0.8441668152809143}]}, {"text": " Table 3: Average diachronic performance", "labels": [], "entities": []}, {"text": " Table 4: Average synchronic performance", "labels": [], "entities": []}]}