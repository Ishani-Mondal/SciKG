{"title": [], "abstractContent": [{"text": "This paper describes the neural machine translation systems developed at the RWTH Aachen University for the De\u2192En, Zh\u2192En and Kk\u2192En news translation tasks of the Fourth Conference on Machine Translation (WMT19).", "labels": [], "entities": [{"text": "machine translation", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.7469641268253326}, {"text": "Kk\u2192En news translation tasks of the Fourth Conference on Machine Translation (WMT19)", "start_pos": 125, "end_pos": 209, "type": "TASK", "confidence": 0.7806371711194515}]}, {"text": "For all tasks, the final submitted system is based on the Transformer architecture.", "labels": [], "entities": []}, {"text": "We focus on improving data filtering and fine-tuning as well as systematically evaluating interesting approaches like unigram language model segmentation and transfer learning.", "labels": [], "entities": [{"text": "data filtering", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.7765478491783142}, {"text": "unigram language model segmentation", "start_pos": 118, "end_pos": 153, "type": "TASK", "confidence": 0.6528546586632729}, {"text": "transfer learning", "start_pos": 158, "end_pos": 175, "type": "TASK", "confidence": 0.9084886908531189}]}, {"text": "For the De\u2192En task, none of the tested methods gave a significant improvement over last years winning system and we end up with the same performance, resulting in 39.6% BLEU on newstest2019.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 169, "end_pos": 173, "type": "METRIC", "confidence": 0.9995507597923279}, {"text": "newstest2019", "start_pos": 177, "end_pos": 189, "type": "DATASET", "confidence": 0.9680047035217285}]}, {"text": "In the Zh\u2192En task, we show 1.3% BLEU improvement over our last year's submission, which we mostly attribute to the splitting of long sentences during translation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.9996492862701416}]}, {"text": "We further report results on the Kk\u2192En task where we gain improvements of 11.1% BLEU over our baseline system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 80, "end_pos": 84, "type": "METRIC", "confidence": 0.9995429515838623}]}, {"text": "On the same task we present a recent transfer learning approach, which uses half of the free parameters of our submission system and performs on par with it.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.9083127081394196}]}], "introductionContent": [{"text": "The RWTH Aachen University developed three systems for the German\u2192English, Chinese\u2192English and Kazakh\u2192English WMT19 news translation tasks.", "labels": [], "entities": [{"text": "RWTH Aachen University", "start_pos": 4, "end_pos": 26, "type": "DATASET", "confidence": 0.7831389307975769}, {"text": "Kazakh\u2192English WMT19 news translation tasks", "start_pos": 95, "end_pos": 138, "type": "TASK", "confidence": 0.6665729326861245}]}, {"text": "For the language pairs De\u2192En and Zh\u2192En there is a lot of training data available, however it consists partially of low quality data.", "labels": [], "entities": []}, {"text": "Therefore we improve our data filtering techniques and the preprocessing of the data.", "labels": [], "entities": [{"text": "data filtering", "start_pos": 25, "end_pos": 39, "type": "TASK", "confidence": 0.7724632024765015}]}, {"text": "We also studied different settings for the fine-tuning and ensembling steps of the final models.", "labels": [], "entities": []}, {"text": "For the low resource Kk\u2192En task we furthermore make use of additional Ru\u2212En/Kk parallel data, exploiting the similarities between the Russian and Kazakh languages.", "labels": [], "entities": []}, {"text": "This paper is organized as follows: In Section 2, we describe our data preprocessing.", "labels": [], "entities": []}, {"text": "Our translation software and baseline setups are explained in Section 3.", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.967279851436615}]}, {"text": "The results of the experiments for the various language pairs are summarized in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we present our results on the three translation tasks in which we participated.", "labels": [], "entities": [{"text": "translation tasks", "start_pos": 53, "end_pos": 70, "type": "TASK", "confidence": 0.8971002101898193}]}, {"text": "We report case-sensitive BLEU () scores as well as results on the TER () and CTER () measures.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9820950627326965}, {"text": "TER", "start_pos": 66, "end_pos": 69, "type": "METRIC", "confidence": 0.9972749352455139}, {"text": "CTER", "start_pos": 77, "end_pos": 81, "type": "METRIC", "confidence": 0.964108943939209}]}, {"text": "All reported scores are given in percentage and the specific options of the tools are set to be consistent with the calculations of the organizers.: Results in percentage of our comparison of the ULM-BPE to pure BPE on the De\u2192En task.", "labels": [], "entities": []}, {"text": "If not stated otherwise the operations are learned jointly.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results in percentage of our comparison of  the ULM-BPE to pure BPE on the De\u2192En task. If not  stated otherwise the operations are learned jointly.", "labels": [], "entities": [{"text": "ULM-BPE", "start_pos": 58, "end_pos": 65, "type": "DATASET", "confidence": 0.7559040784835815}]}, {"text": " Table 2: Main results for the German\u2192English task measured in BLEU [%], TER [%] and CTER [%]  \u2020: Submitted  system.", "labels": [], "entities": [{"text": "Main", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9816329479217529}, {"text": "BLEU", "start_pos": 63, "end_pos": 67, "type": "METRIC", "confidence": 0.9993029832839966}, {"text": "TER", "start_pos": 73, "end_pos": 76, "type": "METRIC", "confidence": 0.9952883720397949}, {"text": "CTER", "start_pos": 85, "end_pos": 89, "type": "METRIC", "confidence": 0.9914855360984802}]}, {"text": " Table 3: Results for Zh\u2192En measured in BLEU [%], TER [%] and CTER [%]. The development set is the concate- nation of newsdev2017 and newstest2017. TER computation fails on newstest2018.   \u2020: Submitted systems.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.9989155530929565}, {"text": "TER", "start_pos": 50, "end_pos": 53, "type": "METRIC", "confidence": 0.9969018697738647}, {"text": "CTER", "start_pos": 62, "end_pos": 66, "type": "METRIC", "confidence": 0.9937599301338196}, {"text": "newsdev2017", "start_pos": 118, "end_pos": 129, "type": "DATASET", "confidence": 0.9450880289077759}]}, {"text": " Table 4: Results measured in BLEU [%], TER [%] and CTER [%] for Kk\u2192En.  \u2020: Submitted systems.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.9991753697395325}, {"text": "TER", "start_pos": 40, "end_pos": 43, "type": "METRIC", "confidence": 0.9964290261268616}, {"text": "CTER", "start_pos": 52, "end_pos": 56, "type": "METRIC", "confidence": 0.9962337613105774}]}]}