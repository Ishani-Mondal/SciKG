{"title": [{"text": "The meaning of \"most\" for visual question answering models", "labels": [], "entities": [{"text": "visual question answering", "start_pos": 26, "end_pos": 51, "type": "TASK", "confidence": 0.6690720518430074}]}], "abstractContent": [{"text": "The correct interpretation of quantifier statements in the context of a visual scene requires non-trivial inference mechanisms.", "labels": [], "entities": []}, {"text": "For the example of \"most\", we discuss two strategies which rely on fundamentally different cogni-tive concepts.", "labels": [], "entities": []}, {"text": "Our aim is to identify what strategy deep learning models for visual question answering learn when trained on such questions.", "labels": [], "entities": [{"text": "visual question answering", "start_pos": 62, "end_pos": 87, "type": "TASK", "confidence": 0.6899261971314748}]}, {"text": "To this end, we carefully design data to replicate experiments from psycholinguis-tics where the same question was investigated for humans.", "labels": [], "entities": []}, {"text": "Focusing on the FiLM visual question answering model, our experiments indicate that a form of approximate number system emerges whose performance declines with more difficult scenes as predicted by We-ber's law.", "labels": [], "entities": [{"text": "FiLM visual question answering", "start_pos": 16, "end_pos": 46, "type": "TASK", "confidence": 0.6070118397474289}]}, {"text": "Moreover, we identify confounding factors, like spatial arrangement of the scene, which impede the effectiveness of this system.", "labels": [], "entities": []}], "introductionContent": [{"text": "Deep learning methods have been very successful in many natural language processing tasks, ranging from syntactic parsing to machine translation to image captioning.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 104, "end_pos": 121, "type": "TASK", "confidence": 0.7375407814979553}, {"text": "machine translation", "start_pos": 125, "end_pos": 144, "type": "TASK", "confidence": 0.7444471716880798}, {"text": "image captioning", "start_pos": 148, "end_pos": 164, "type": "TASK", "confidence": 0.7032730430364609}]}, {"text": "However, despite significantly raised performance scores on benchmark datasets, researchers increasingly worry about interpretability and indeed quality of model decisions.", "labels": [], "entities": []}, {"text": "We see two distinct research endeavors here, one being more pragmatic, forward-oriented, and guided by the question \"Can a system solve this task?\", the other being more analytic, reflective, and motivated by the question \"How does a system solve this task?\".", "labels": [], "entities": []}, {"text": "In other words, the former aspires to improve performance, while the latter aims to increase our understanding of deep learning models.", "labels": [], "entities": []}, {"text": "By 'understanding' here we mean observing a reasoning mechanism that, if not human-like, at least is cognitively plausible.", "labels": [], "entities": []}, {"text": "This is by no paired random partitioned \"More than half the shapes are red shapes?\"", "labels": [], "entities": []}, {"text": "Figure 1: Three types of spatial arrangement of objects which mayor may not affect the performance of a mechanism for verifying \"most\" statements.", "labels": [], "entities": []}, {"text": "Going from left to right, a strategy based on pairing entities of each set and identifying the remainder presumably gets more difficult, while a strategy based on comparing set cardinalities does not.", "labels": [], "entities": []}, {"text": "means necessary for practically solving a task, however, we highlight two reasons why being able to explain model behavior is nonetheless important: On the one hand, cognitive plausibility increases confidence in the abilities of a systemone is generally more willing to rely on a reasonable than an incomprehensible mechanism.", "labels": [], "entities": []}, {"text": "On the other hand, pointing out systematic shortcomings inspires systematic improvements and hence can guide progress.", "labels": [], "entities": []}, {"text": "Moreover, particularly in the case of a human-centered domain like natural language, ultimately, some degree of comparability to human performance is indispensable.", "labels": [], "entities": []}, {"text": "In this paper we are inspired by experimental practice in psycholinguistics to shed light on the question how deep learning models for visual question answering (VQA) learn to interpret statements involving the quantifier \"most\".", "labels": [], "entities": [{"text": "visual question answering (VQA)", "start_pos": 135, "end_pos": 166, "type": "TASK", "confidence": 0.8240545094013214}]}, {"text": "We follow in designing abstract visual scenes where we control the ratio of the objects quantified over and their spatial arrangement, to identify whether VQA models exhibit a preferred strategy of verifying whether \"most\" applies.", "labels": [], "entities": []}, {"text": "Figure 1 illustrates how visual scenes can be configured to favor one over another mechanism.", "labels": [], "entities": []}, {"text": "We want to emphasize the experimental approach and its difference to mainstream machine learning practice.", "labels": [], "entities": []}, {"text": "For different verification strategies, conditions are identified that should or should not affect their performance, and test instances are designed accordingly.", "labels": [], "entities": []}, {"text": "By comparing the accuracy of subjects on various instance patterns, predictions about a subject's performance for these mechanisms can be verified and the most likely explanation identified.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9974843263626099}]}, {"text": "Note that our advocated evaluation methodology is entirely extrinsic and does not constrain the system in anyway (like requiring attention maps) or require a specific framework (like being probabilistic).", "labels": [], "entities": []}, {"text": "Psychology as a discipline has focused entirely on questions around how humans process situations and arrive at decisions, and consequently has the potential to inspire a lot of experiments (like ours) for investigating the same questions in the context of machine learning.", "labels": [], "entities": []}, {"text": "Similar to psychology, we advocate the preference of an artificial experimentation environment which can be controlled in detail, over the importance of data originating from the real world, to arrive at more convincing and thus meaningful results.", "labels": [], "entities": []}, {"text": "It is less common recently to evaluate deep learning models on artificial data tailored to a specific problem, as opposed to big real-world datasets.", "labels": [], "entities": []}, {"text": "However, artificial data has a history in deep learning of establishing new techniques -most prominently, LSTMs were introduced by showing their ability to handle various formal grammars) -and our higher-level goal with this paper is to demonstrate the potential for more informative evaluation of machine learning models in general.", "labels": [], "entities": []}, {"text": "This is motivated by our belief that, in the long term, true progress can only be made if we do not just rely on the narrative of neural networks \"learning to understand/solve\" a task, but can actually confirm our theories experimentally.", "labels": [], "entities": []}, {"text": "Taking inspiration from psychology seems particularly appropriate in the context of powerful deep learning models, which recently are not infrequently described by anthropomorphizing words like \"understanding\", and compared to \"human-level\" performance.", "labels": [], "entities": []}], "datasetContent": [{"text": "The setup in this paper closely resembles the psychological experiments conducted by, but aimed at a state-of-the-art VQA model and its interpretation of \"most\".", "labels": [], "entities": []}, {"text": "We use the ShapeWorld framework as starting point to generate appropriate data.", "labels": [], "entities": []}, {"text": "ShapeWorld is a configurable generation system for abstract, visually grounded language data.", "labels": [], "entities": []}, {"text": "A data point consists of an image, an accompanying caption, and an agreement value indicating whether the caption is true given the image.", "labels": [], "entities": []}, {"text": "The underlying task, image caption agreement, essentially corresponds to yes/no questions and as such is a type of visual question answering.", "labels": [], "entities": [{"text": "image caption agreement", "start_pos": 21, "end_pos": 44, "type": "TASK", "confidence": 0.8162951370080312}, {"text": "question answering", "start_pos": 122, "end_pos": 140, "type": "TASK", "confidence": 0.790578305721283}]}, {"text": "Internally, the system samples an abstract world description from which a semantic caption representation is extracted.", "labels": [], "entities": []}, {"text": "Both are then turned into 'natural' (but still abstract) representations as image and natural language statement, respectively.", "labels": [], "entities": []}, {"text": "The latter transformation is based on a semantic grammar formalism (see the paper for details).", "labels": [], "entities": []}, {"text": "We refer to the unrestricted version as Q-full, the other one \u2022 Exactly two squares are yellow.", "labels": [], "entities": []}, {"text": "\u2022 Exactly no square is red.", "labels": [], "entities": []}, {"text": "\u2022 More than half the red shapes are squares.", "labels": [], "entities": []}, {"text": "\u2022 More than a third of the shapes are cyan.", "labels": [], "entities": []}, {"text": "\u2022 Less than half the shapes are green.", "labels": [], "entities": []}, {"text": "\u2022 Exactly all magenta shapes are squares.", "labels": [], "entities": []}, {"text": "\u2022 At most five shapes are magenta.", "labels": [], "entities": []}, {"text": "\u2022 At least one triangle is gray.", "labels": [], "entities": []}, {"text": "shows two images together with potential Q-full captions.", "labels": [], "entities": []}, {"text": "We also use the default world generator to produce training data (up to 15 randomly positioned objects, as seen in.", "labels": [], "entities": []}, {"text": "However, all of the pre-implemented generator modules are too generic for our evaluation purposes, since they do not allow to control attributes and positioning of objects to the desired degree.", "labels": [], "entities": []}, {"text": "We thus implemented our own custom generator module with the following functionality to produce test data.", "labels": [], "entities": []}, {"text": "Attribute contrast: For each instance, either the attribute 'shape' or 'color' is picked 4 , and subsequently two values for this attribute and one value for the other is randomly chosen.", "labels": [], "entities": []}, {"text": "This means that the only relevant difference between objects in every image is either one of two shape or color values (for instance, red vs blue squares, or red squares vs circles).", "labels": [], "entities": []}, {"text": "Contrast ratios: A list of valid ratios between the contrasted attributes can be specified, from which one will randomly be chosen per instance.", "labels": [], "entities": []}, {"text": "For instance, a ratio of 2:3 means that there are 50% more objects with the second than the first attribute.", "labels": [], "entities": []}, {"text": "We look at values close to 1:1, that is, 1:2, 2:3, 3:4, 4:5, etc.", "labels": [], "entities": []}, {"text": "The increasing difficulty (for humans) resulting from closer ratios is illustrated in.", "labels": [], "entities": []}, {"text": "Multiples of the smaller-valued ratios are also generated (e.g., 2:4 or 6:9), within the limit of up to 15 objects overall.", "labels": [], "entities": []}, {"text": "Area-controlled (vs size-controlled): If this option is set, object sizes are not chosen uniformly across the entire valid range, but size ranges for the two contrasting object types are adapted to the given contrast ratio and size of the chosen shape(s), so that both attributes cover the same image area on average.", "labels": [], "entities": []}, {"text": "This means that the more numerous attribute will generally be represented by Note that we chose the examples in figures to always vary in color only, for clarity.", "labels": [], "entities": [{"text": "clarity", "start_pos": 154, "end_pos": 161, "type": "METRIC", "confidence": 0.9683523774147034}]}, {"text": "smaller objects, and the difference in covered area between, for instance, squares and triangles is taken into account.", "labels": [], "entities": []}, {"text": "While objects are still positioned randomly in the basic version of this new generator module, we define two modes which control this aspect as well.", "labels": [], "entities": []}, {"text": "The captions of these evaluation instances are always of the form \"More/less than half the shapes are X\". with \"X\" being the attribute in question, for instance, \"squares\" or \"red shapes\".", "labels": [], "entities": []}, {"text": "Note that this is an even more constrained captioner than the one used for Q-half.", "labels": [], "entities": []}, {"text": "We also emphasize that, in contrast to this new evaluation generator module, the default generator configuration of the 'quantification' dataset pre-specified in ShapeWorld is used to generate the training instances in Q-half and Q-full.", "labels": [], "entities": []}, {"text": "So these images generally contain many more than just two contrasted attributes, and ratios between attributes tend to be accordingly smaller.", "labels": [], "entities": []}, {"text": "The examples in are chosen to illustrate this fact: the second example contains a \"half\" statement with ratio 7:8, and the first contains one about a 0:4 ratio, while the image would also allow fora more 'interesting' 3:4 ratio (color of semicircles).", "labels": [], "entities": []}, {"text": "While we generally try to stay close to the experimental setup of, in the following we point out some differences.", "labels": [], "entities": []}, {"text": "Most importantly, instead of just using yellow and blue dots, we use all eight shapes and seven colors that ShapeWorld provides.", "labels": [], "entities": []}, {"text": "This increases the visual variety of the instances and thus encourages the system to actually learn the fact that shape and color are attributes that can be combined in anyway, instead of just straightforward binary pattern matching.", "labels": [], "entities": []}, {"text": "Note that the humans in the psychological experiments have learned language in even more complex situations, which we cannot hope to approximate here.", "labels": [], "entities": []}, {"text": "Moreover, our data does not contain yes/no questions but true/false captions, and \"most\"-equivalent variations \"more/less than half\".", "labels": [], "entities": []}, {"text": "Since the model is trained from scratch on such data, this should not affect results.", "labels": [], "entities": []}, {"text": "We do not implement the 'column pairs mixed/sorted' modes since they would require comparatively big and mostly empty images, hence require bigger networks and might cause practical learning problems due to sparseness, which we do not want to address here.", "labels": [], "entities": []}, {"text": "In contrast, our 'partitioned' mode is more difficult than the ones investigated by, at least fora pairing-based mechanism.", "labels": [], "entities": []}], "tableCaptions": []}