{"title": [{"text": "Conceptor Debiasing of Word Representations Evaluated on WEAT", "labels": [], "entities": [{"text": "Debiasing of Word Representations Evaluated", "start_pos": 10, "end_pos": 53, "type": "TASK", "confidence": 0.7244615077972412}, {"text": "WEAT", "start_pos": 57, "end_pos": 61, "type": "DATASET", "confidence": 0.6460723280906677}]}], "abstractContent": [{"text": "Bias in word embeddings such as Word2Vec has been widely investigated, and many efforts made to remove such bias.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 32, "end_pos": 40, "type": "DATASET", "confidence": 0.9507279992103577}]}, {"text": "We show how to use conceptors debiasing to post-process both traditional and contextualized word em-beddings.", "labels": [], "entities": []}, {"text": "Our conceptor debiasing can simultaneously remove racial and gender biases and, unlike standard debiasing methods, can make effect use of heterogeneous lists of biased words.", "labels": [], "entities": []}, {"text": "We show that conceptor debiasing diminishes racial and gender bias of word representations as measured using the Word Embedding Association Test (WEAT) of Caliskan et al.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word embeddings capture distributional similarities and thus inherit demographic stereotypes (.", "labels": [], "entities": []}, {"text": "Such embedding biases tend to track statistical regularities such as the percentage of people with a given occupation (Nikhil Garg and Zou, 2018) but sometimes deviate from them.", "labels": [], "entities": []}, {"text": "Recent work has shown that gender bias exists in contextualized embeddings (.", "labels": [], "entities": []}, {"text": "Here, we provide a quantitative analysis of bias in traditional and contextual word embeddings and introduce a method of mitigating bias (i.e., debiasing) using the debiasing conceptor, a clean mathematical representation of subspaces that can be operated on and composed by logic-based manipulations.", "labels": [], "entities": []}, {"text": "Specifically, conceptor negation is a soft damping of the principal components of the target subspace (e.g., the subset of words being debiased) () (See) Key to our method is how it treats wordassociation lists (sometimes called target lists), which define the bias subspace.", "labels": [], "entities": []}, {"text": "These lists include pre-chosen words associated with a target (a) The original space (b) After applying the debiasing conceptor: BERT word representations of the union of the set of contextualized word representations of relatives, executive, wedding, salary projected onto the first two principal components of the WEAT gender first names, which capture the primary component of gender.", "labels": [], "entities": [{"text": "BERT", "start_pos": 129, "end_pos": 133, "type": "METRIC", "confidence": 0.9958998560905457}, {"text": "WEAT gender first names", "start_pos": 316, "end_pos": 339, "type": "TASK", "confidence": 0.5859866142272949}]}, {"text": "Note how the debiasing conceptor collapses relatives and wedding, and executive and salary once the bias is removed.", "labels": [], "entities": []}, {"text": "demographic group (often referred to as a \"protected class\").", "labels": [], "entities": []}, {"text": "For example, he / she or Mary / John have been used for gender.", "labels": [], "entities": []}, {"text": "More generally, conceptors can combine multiple subspaces defined byword lists.", "labels": [], "entities": []}, {"text": "Unlike most current methods, conceptor debiasing uses a soft, rather than a hard projection.", "labels": [], "entities": []}, {"text": "We test the debiasing conceptor on a range of traditional and contextualized word embeddings and examine whether they remove stereotypical demographic biases.", "labels": [], "entities": []}, {"text": "All tests have been performed on English word embeddings.", "labels": [], "entities": []}, {"text": "This paper contributes the following: \u2022 Introduces debiasing conceptors along with a formal definition and mathematical relation to the Word Embedding Association Test.", "labels": [], "entities": [{"text": "Word Embedding Association Test", "start_pos": 136, "end_pos": 167, "type": "DATASET", "confidence": 0.6843649446964264}]}, {"text": "\u2022 Demonstrates the effectiveness of the debiasing conceptor on both traditional and contextualized word embeddings.", "labels": [], "entities": []}], "datasetContent": [{"text": "As described in section 3.1, WEAT assumes as its null hypothesis that there is no relative bias between the pair of concepts defined as the target words and attribute words.", "labels": [], "entities": [{"text": "WEAT", "start_pos": 29, "end_pos": 33, "type": "TASK", "confidence": 0.8448809385299683}]}, {"text": "In our experiments, we measure the effect size (the WEAT score normalized by the standard deviation of differences of attribute words w.r.t target words) (d) and the onesided p-value of the permutation test.", "labels": [], "entities": [{"text": "WEAT score", "start_pos": 52, "end_pos": 62, "type": "METRIC", "confidence": 0.9467642903327942}]}, {"text": "A higher absolute value of effect size indicates larger bias between words in the target set with respect to the words in the attribute set.", "labels": [], "entities": []}, {"text": "We would like the absolute value of the effect size to be zero.", "labels": [], "entities": []}, {"text": "Since the p-value measures the likelihood that a random permutation of the attribute words would produce at least the observed test statistic, it should be high (at least 0.05) to indicate lack of bias in the positive direction.", "labels": [], "entities": []}, {"text": "Conceptually, the conceptor should be a soft projection matrix on the linear subspace representing the bias direction.", "labels": [], "entities": []}, {"text": "For instance, the subspace representing gender must consist of words which are specific to or in some sense related to gender.", "labels": [], "entities": []}, {"text": "A gender word list might be a set of pronouns which are specific to a particular gender such as he / she or himself / herself and gender specific words representing relationships like brother / sister or uncle / aunt.", "labels": [], "entities": []}, {"text": "We test conceptor debiasing both using the list of such pronouns used by      Caliskan et al. and using a more comprehensive list of gender-specific words that includes gender specific terms related to occupations, relationships and other commonly used words such as prince / princess and host / hostess 10 . We further tested conceptor debiasing using male and female names such as Aaron / Alice or Chris / Clary 11 . We also tested our method with the combination of all lists.", "labels": [], "entities": []}, {"text": "The combination of the subspace was done in two ways -either by taking the union of all word lists or by applying the OR operator on the three conceptor matrices computed independently.", "labels": [], "entities": [{"text": "OR", "start_pos": 118, "end_pos": 120, "type": "METRIC", "confidence": 0.9694926738739014}]}, {"text": "The subspace for racial bias was determined using list of European American and African American names.", "labels": [], "entities": []}, {"text": "We tested target pairs of Science vs. Arts, Math vs. Arts, and Career vs. Family word lists with the attribute of the male vs. female names to test gender debiasing.", "labels": [], "entities": []}, {"text": "Similarly, we examined European American names vs. African American names as target pairs with the attribute of pleasant vs. unpleasant to test racial debiasing.", "labels": [], "entities": []}, {"text": "Our findings indicate that expanded lists give better debiasing for word embeddings; however, the results are not as clear for contextualized embeddings.", "labels": [], "entities": []}, {"text": "The OR operator on two conceptors describing subspaces of pronouns/nouns and names generally outperforms a union of these words.", "labels": [], "entities": [{"text": "OR", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.9790674448013306}]}, {"text": "This further motivates the use of the debiasing conceptor.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Gender Debiasing non-contextualized embeddings: (Career, Family) vs (Male, Female)", "labels": [], "entities": [{"text": "Gender Debiasing non-contextualized embeddings", "start_pos": 10, "end_pos": 56, "type": "TASK", "confidence": 0.7206241264939308}]}, {"text": " Table 2: Gender Debiasing Contextualized embeddings: (Career, Family) vs (Male, Female)", "labels": [], "entities": []}, {"text": " Table 3: Gender Debiasing non-contextualized embeddings: (Math, Arts) vs (Male, Female)", "labels": [], "entities": [{"text": "Gender Debiasing non-contextualized embeddings", "start_pos": 10, "end_pos": 56, "type": "TASK", "confidence": 0.7411634549498558}]}, {"text": " Table 4: Gender Debiasing contextualized embeddings: (Math, Arts) vs (Male, Female)", "labels": [], "entities": [{"text": "Gender Debiasing contextualized embeddings", "start_pos": 10, "end_pos": 52, "type": "TASK", "confidence": 0.7347843199968338}]}, {"text": " Table 5: Gender Debiasing non-cotextualized embeddings: (Science, Arts) vs (Male, Female)", "labels": [], "entities": [{"text": "Gender Debiasing non-cotextualized embeddings", "start_pos": 10, "end_pos": 55, "type": "TASK", "confidence": 0.7287636771798134}]}, {"text": " Table 6: Gender Debiasing cotextualized embeddings: (Science, Arts) vs (Male, Female)", "labels": [], "entities": [{"text": "Gender Debiasing cotextualized embeddings", "start_pos": 10, "end_pos": 51, "type": "TASK", "confidence": 0.6945972889661789}]}, {"text": " Table 7: Racial Debiasing: (European American  Names, African American Names) vs (Pleasant, Un- pleasant)", "labels": [], "entities": [{"text": "Racial Debiasing", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.9281233847141266}]}, {"text": " Table 8: Word Similarity comparison with conceptor  debiased embeddings using all gender words as con- ceptor subspace.", "labels": [], "entities": [{"text": "Word Similarity", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.603809118270874}]}]}