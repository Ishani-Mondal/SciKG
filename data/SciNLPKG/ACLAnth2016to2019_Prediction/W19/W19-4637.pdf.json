{"title": [{"text": "No Army, No Navy: BERT Semi-Supervised Learning of Arabic Dialects *", "labels": [], "entities": [{"text": "BERT", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.9900857210159302}, {"text": "Semi-Supervised Learning of Arabic Dialects", "start_pos": 23, "end_pos": 66, "type": "TASK", "confidence": 0.4637785792350769}]}], "abstractContent": [{"text": "We present our deep leaning system submitted to MADAR shared task 2 focused on twitter user dialect identification.", "labels": [], "entities": [{"text": "MADAR shared task", "start_pos": 48, "end_pos": 65, "type": "TASK", "confidence": 0.5150976677735647}, {"text": "twitter user dialect identification", "start_pos": 79, "end_pos": 114, "type": "TASK", "confidence": 0.5549604222178459}]}, {"text": "We develop tweet-level identification models based on GRUs and BERT in supervised and semi-supervised settings.", "labels": [], "entities": [{"text": "tweet-level identification", "start_pos": 11, "end_pos": 37, "type": "TASK", "confidence": 0.8102073073387146}, {"text": "BERT", "start_pos": 63, "end_pos": 67, "type": "METRIC", "confidence": 0.9940723776817322}]}, {"text": "We then introduce a simple, yet effective , method of porting tweet-level labels at the level of users.", "labels": [], "entities": []}, {"text": "Our system ranks top 1 in the competition, with 71.70% macro F 1 score and 77.40% accuracy.", "labels": [], "entities": [{"text": "macro F 1 score", "start_pos": 55, "end_pos": 70, "type": "METRIC", "confidence": 0.8180203586816788}, {"text": "accuracy", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.9986989498138428}]}], "introductionContent": [{"text": "Language identification (LID) is an important NLP task that usually acts as an enabling technology in a pipeline involving another downstream task such as machine translation) or sentiment analysis.", "labels": [], "entities": [{"text": "Language identification (LID)", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8246594309806824}, {"text": "machine translation", "start_pos": 155, "end_pos": 174, "type": "TASK", "confidence": 0.7219462245702744}, {"text": "sentiment analysis", "start_pos": 179, "end_pos": 197, "type": "TASK", "confidence": 0.9230410754680634}]}, {"text": "Although several works have focused on detecting languages in global settings (see fora survey), there has not been extensive research on teasing apart similar languages or language varieties ( . This is the case for Arabic, the term used to collectively refer to a large number of varieties with avast population of native speakers (\u223c 300 million).", "labels": [], "entities": []}, {"text": "For this reason, we focus on detecting fine-grained Arabic dialect as part of our contribution to the MADAR shared task 2, twitter user dialect identification (.", "labels": [], "entities": [{"text": "MADAR shared task", "start_pos": 102, "end_pos": 119, "type": "TASK", "confidence": 0.534524659315745}, {"text": "twitter user dialect identification", "start_pos": 123, "end_pos": 158, "type": "TASK", "confidence": 0.5001669898629189}]}, {"text": "Previous works on Arabic (e.g.,;;) have primarily targeted cross-country regional varieties such as Egyptian, Gulf, and Levantine, in addition to Modern Standard Arabic (MSA).", "labels": [], "entities": [{"text": "Modern Standard Arabic (MSA)", "start_pos": 146, "end_pos": 174, "type": "DATASET", "confidence": 0.7120126237471899}]}, {"text": "These * The title is wordplay on the Yiddish linguist Max Weinreich much quoted metaphor (in Yiddish) \"A language is a dialect with an army and navy\".", "labels": [], "entities": []}, {"text": "See: https: //en.wikipedia.org/wiki/A_language_is_a_ dialect_with_an_army_and_navy.", "labels": [], "entities": []}, {"text": "works exploited social data from blogs (), the general Web (Al-Sabbagh and Girju, 2012), online news sites comments sections).", "labels": [], "entities": []}, {"text": "Other works have used translated data (e.g.,), or speech transcripts (e.g.,.", "labels": [], "entities": []}, {"text": "More recently, other works reporting larger-scale datasets at the country-level were undertaken.", "labels": [], "entities": []}, {"text": "These include data spanning 10-to-17 different countries ().", "labels": [], "entities": []}, {"text": "To solve Arabic dialect identification, many researchers developed models based on computational linguistics and machine learning), and deep learning . In this paper, we focus on using state-of-the-arts deep learning architectures to identify Arabic dialects of Twitter users at the country level.", "labels": [], "entities": [{"text": "Arabic dialect identification", "start_pos": 9, "end_pos": 38, "type": "TASK", "confidence": 0.7148127555847168}]}, {"text": "We use the MADAR twitter corpus), comprising 21 country-level dialect labels.", "labels": [], "entities": [{"text": "MADAR twitter corpus", "start_pos": 11, "end_pos": 31, "type": "DATASET", "confidence": 0.8713251749674479}]}, {"text": "Namely, we employ unidirectional Gated Recurrent Unit (GRU) ( ) as our baseline and pre-trained Multilingual Bidirectional Encoder Representations from Transformers (BERT) to identify dialect classes for individual tweets (which we then port at user level).", "labels": [], "entities": []}, {"text": "We also apply semi-supervised learning to augment our training data, with a goal to improve model performance.", "labels": [], "entities": []}, {"text": "Our system ranks top 1 in the shared task.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: data are described in Section 2.", "labels": [], "entities": []}, {"text": "Section 3 introduces our methods, follow by experiments in Section 4.", "labels": [], "entities": []}, {"text": "We conclude in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We illustrate our four main sets of experiment.", "labels": [], "entities": []}, {"text": "We present (i) our baseline model, GRU (Section 4.1), (ii) fine-tuning on BERT-Base, Multilingual Cased model for dialect identification (Section 4.2), (iii) semi-supervised learning with unlabeled data 4.3, (iv) user-level dialect identification (DID) 4.4.", "labels": [], "entities": [{"text": "GRU", "start_pos": 35, "end_pos": 38, "type": "DATASET", "confidence": 0.6485021114349365}, {"text": "BERT-Base", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.9662164449691772}, {"text": "dialect identification", "start_pos": 114, "end_pos": 136, "type": "TASK", "confidence": 0.742488220334053}, {"text": "user-level dialect identification (DID)", "start_pos": 213, "end_pos": 252, "type": "TASK", "confidence": 0.7277410825093588}]}], "tableCaptions": [{"text": " Table 1 shows statistics of the  data.", "labels": [], "entities": []}, {"text": " Table 2: Model performance. Baseline is a unidirec- tional 500-unit, one-layered GRU. Baseline and BERT- A are trained on TRAIN-A. BERT-B is trained on  TRAIN-B.", "labels": [], "entities": [{"text": "BERT- A", "start_pos": 100, "end_pos": 107, "type": "METRIC", "confidence": 0.9674438238143921}, {"text": "BERT-B", "start_pos": 132, "end_pos": 138, "type": "METRIC", "confidence": 0.9915447235107422}]}, {"text": " Table 3: Data splits for our emi-supervised learning  experiments. New: The new dataset confidently pre- dicted with semi-supervised learning that are added to  TRAIN-B.", "labels": [], "entities": [{"text": "TRAIN-B", "start_pos": 162, "end_pos": 169, "type": "METRIC", "confidence": 0.6318104267120361}]}, {"text": " Table 4: Semi-supervised learning. All models are  evaluated on DEV, with TRAIN-B as training data. Re- sults higher than BERT-B are underlined. Best result is  in bold.", "labels": [], "entities": [{"text": "DEV", "start_pos": 65, "end_pos": 68, "type": "DATASET", "confidence": 0.8664906024932861}, {"text": "TRAIN-B", "start_pos": 75, "end_pos": 82, "type": "METRIC", "confidence": 0.9880576133728027}, {"text": "Re- sults", "start_pos": 101, "end_pos": 110, "type": "METRIC", "confidence": 0.9606107870737711}, {"text": "BERT-B", "start_pos": 123, "end_pos": 129, "type": "METRIC", "confidence": 0.9972489476203918}]}, {"text": " Table 5: User-level results. TEST results come from  the official leaderboard of the shared task. B-25%CS=  BERT-25% Class SEMI.", "labels": [], "entities": [{"text": "TEST", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.9947538375854492}, {"text": "B-25", "start_pos": 99, "end_pos": 103, "type": "METRIC", "confidence": 0.9832337498664856}, {"text": "BERT-25", "start_pos": 109, "end_pos": 116, "type": "METRIC", "confidence": 0.9913327097892761}, {"text": "SEMI", "start_pos": 124, "end_pos": 128, "type": "METRIC", "confidence": 0.5415840148925781}]}]}