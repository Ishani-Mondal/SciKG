{"title": [{"text": "Simple Construction of Mixed-Language Texts for Vocabulary Learning", "labels": [], "entities": [{"text": "Vocabulary Learning", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.7902081906795502}]}], "abstractContent": [{"text": "We present a machine foreign-language teacher that takes documents written in a student's native language and detects situations where it can replace words with their foreign glosses such that new foreign vocabulary can be learned simply through reading the resulting mixed-language text.", "labels": [], "entities": []}, {"text": "We show that it is possible to design such a machine teacher without any supervised data from (human) students.", "labels": [], "entities": []}, {"text": "We accomplish this by modifying a cloze language model to incrementally learn new vocabulary items, and use this language model as a proxy for the word guessing and learning ability of real students.", "labels": [], "entities": [{"text": "word guessing", "start_pos": 147, "end_pos": 160, "type": "TASK", "confidence": 0.7392084300518036}]}, {"text": "Our machine foreign-language teacher decides which subset of words to replace by consulting this language model.", "labels": [], "entities": []}, {"text": "We evaluate three variants of our student proxy language models through a study on Amazon Mechanical Turk (MTurk).", "labels": [], "entities": [{"text": "Amazon Mechanical Turk (MTurk)", "start_pos": 83, "end_pos": 113, "type": "DATASET", "confidence": 0.9068727294603983}]}, {"text": "We find that MTurk \"students\" were able to guess the meanings of foreign words introduced by the machine teacher with high accuracy for both function words as well as content words in two out of the three models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.9985526204109192}]}, {"text": "In addition, we show that students are able to retain their knowledge about the foreign words after they finish reading the document.", "labels": [], "entities": []}], "introductionContent": [{"text": "Proponents of using extensive reading for language acquisition, such as, argue that much of language acquisition takes place through incidental learning , where a reader infers the meaning of unfamiliar vocabulary or structures using the surrounding (perhaps more familiar) context.", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 42, "end_pos": 62, "type": "TASK", "confidence": 0.7237310111522675}]}, {"text": "Unfortunately, when it comes to learning a foreign language (L2), considerable fluency is required before seeing the benefits of incidental learning.", "labels": [], "entities": []}, {"text": "But it maybe possible to use a student's native language (L1) fluency to introduce new L2 vocabulary.", "labels": [], "entities": []}, {"text": "The student's L1 fluency can provide sufficient \"scaffolding\", which we intend to exploit by finding the \"zone of proximal development\") in which the learner is able to comprehend the text but only by stretching their L2 capacity.", "labels": [], "entities": []}, {"text": "As an example of such mixed-language incidental learning, consider a native speaker of English (learning German) presented with the following sentence: Der Nile is a Fluss in Africa.", "labels": [], "entities": []}, {"text": "With a little effort, one would hope a student can infer the meaning of the German words because there is sufficient contextual information.", "labels": [], "entities": []}, {"text": "Perhaps with repeated exposure, the student may eventually learn the German words.", "labels": [], "entities": []}, {"text": "Our goal is to create a machine teacher that can detect and exploit situations where incidental learning can occur in narrative text (stories, articles etc.).", "labels": [], "entities": []}, {"text": "The machine teacher will take a sentence in the student's native language (L1) and replace certain words with their foreign-language (L2) translations, resulting in a mixed-language sentence.", "labels": [], "entities": []}, {"text": "We hope that reading mixed-language documents does not feel like a traditional vocabulary learning drill even though novel L2 words can be picked up overtime.", "labels": [], "entities": []}, {"text": "We envision our method being used alongside traditional foreign-language instruction.", "labels": [], "entities": []}, {"text": "Typically, a machine teacher would require supervised data, meaning data on student behaviors and capabilities).", "labels": [], "entities": []}, {"text": "This step is expensive, not only from a data collection point of view, but also from the point of view of students, as they would have to give feedback (i.e. generate labeled data) on the actions of an initially untrained machine teacher.", "labels": [], "entities": []}, {"text": "However, our machine teacher requires no supervised data from human students.", "labels": [], "entities": []}, {"text": "Instead, it uses a cloze language model trained on corpora from the student's native language as a proxy fora human student.", "labels": [], "entities": []}, {"text": "Our machine teacher consults this proxy to guide its construction of mixed-language data.", "labels": [], "entities": []}, {"text": "Moreover, we create an evaluation dataset that allows us to determine whether students can actually: An example English (L1) sentence with German (L2) glosses.", "labels": [], "entities": []}, {"text": "Using the glosses, several possible mixed-language configurations are possible.", "labels": [], "entities": []}, {"text": "Note that the glosses do not form fluent L2 sentences.", "labels": [], "entities": []}, {"text": "understand our generated texts and learn from them.", "labels": [], "entities": []}, {"text": "We present three variants of our machine teacher, by varying the underlying language models, and study the differences in the mixed-language documents they generate.", "labels": [], "entities": []}, {"text": "We evaluate these systems by asking participants on Amazon Mechanical Turk (MTurk) to read these documents and guess the meanings of L2 words as and when they appear (the participants are expected to use the surrounding words to make their guesses).", "labels": [], "entities": [{"text": "Amazon Mechanical Turk (MTurk)", "start_pos": 52, "end_pos": 82, "type": "DATASET", "confidence": 0.9242891371250153}]}, {"text": "Furthermore, we select the best performing variant and evaluate if participants can actually learn the L2 words by letting participants read a mixed-language passage and give a L2 vocabulary quiz at the end of passage, where the L2 words are presented in isolation.", "labels": [], "entities": []}], "datasetContent": [{"text": "We first investigate the patterns of word replacement produced by the machine teacher under the influence of the different student proxy models and how these replacements affect the guessability of L2 words.", "labels": [], "entities": [{"text": "word replacement", "start_pos": 37, "end_pos": 53, "type": "TASK", "confidence": 0.7282737493515015}]}, {"text": "To this end, we used the machine teacher to generate mixed-language documents and asked MTurk participants to guess the foreign words.", "labels": [], "entities": []}, {"text": "shows an example screenshot of our guessing interface.", "labels": [], "entities": []}, {"text": "The words in blue are L2 words whose meaning (in English) is guessed by MTurk participants.", "labels": [], "entities": [{"text": "MTurk", "start_pos": 72, "end_pos": 77, "type": "DATASET", "confidence": 0.7062970399856567}]}, {"text": "For our study, we created a synthetic L2 language by randomly replacing characters from English word types.", "labels": [], "entities": []}, {"text": "This step lets us safely assume that all MTurk participants are \"absolute beginners.\"", "labels": [], "entities": [{"text": "MTurk", "start_pos": 41, "end_pos": 46, "type": "TASK", "confidence": 0.8331976532936096}]}, {"text": "We tried to ensure that the resulting synthetic words are pronounceable by replacing vowels with vowels, stop-consonants with other stop-consonants, etc.", "labels": [], "entities": []}, {"text": "We also inserted or deleted one character from some of the words to prevent the reader from using the length of the synthetic word as a clue.", "labels": [], "entities": []}, {"text": "While our evaluation required use of a synthetic foreign language, we provide as an example mixed-language documents with real L2 languages in Appendix A.1.", "labels": [], "entities": [{"text": "Appendix A.1", "start_pos": 143, "end_pos": 155, "type": "DATASET", "confidence": 0.8642603158950806}]}, {"text": "We studied the three student proxy models (cLM , uLM , and DP ) while keeping the rest of the machine teacher's components fixed (i.e. same scoring function and search algorithms).", "labels": [], "entities": []}, {"text": "All three models were constructed to have roughly the same number of L1 parameters (\u2248 20M ).", "labels": [], "entities": []}, {"text": "The uLM model used 2 unidirectional LSTM layers instead of a single bidirectional layer.", "labels": [], "entities": []}, {"text": "The L1 and L2 word embedding size and the number of recurrent units D were set to 300 for all three models (to match the size of FastText's pretrained embeddings).", "labels": [], "entities": []}, {"text": "We trained the three models on the Wikipedia-103 corpus (.", "labels": [], "entities": [{"text": "Wikipedia-103 corpus", "start_pos": 35, "end_pos": 55, "type": "DATASET", "confidence": 0.9634184539318085}]}, {"text": "All models were trained for 8 epochs using the Adam optimizer ().", "labels": [], "entities": []}, {"text": "We limit the L1 vocabulary to the 60k most frequent English types.", "labels": [], "entities": []}, {"text": "We generated 9 mixed-language versions (3 models {cLM ,uLM ,DP } in combination with 3 rank Model rmax = 1 rmax = 8 cLM Hu Nile (''an-n \u00af il'') ev a river um Africa.", "labels": [], "entities": []}, {"text": "Up is hu longest river i\u00f1 Earth (about 6,650 km or 4,132 miles), though other rivers carry more water...", "labels": [], "entities": []}, {"text": "Many ozvolomb types iv emoner live in or near hu waters iv hu Nile, including crocodiles, birds, fish\u00f1bfish\u00f1b many others.", "labels": [], "entities": []}, {"text": "Not only do animals depend i\u00f1 hu Nile for survival, but also people who live there need up zi everyday use like washing, as u jopi supply, keeping crops watered\u00f1bwatered\u00f1b other jobs...", "labels": [], "entities": []}, {"text": "Hu Nile (''an-n \u00af il'') ev u river um Africa.", "labels": [], "entities": []}, {"text": "Up ev the longest river on Earth (about 6,650 km or 4,132 miles), though other rivers carry more water...", "labels": [], "entities": []}, {"text": "Emu ozvolomb types of emoner live um or iul the waters of hu Uro, including crocodiles, ultf, yvh and emu others.", "labels": [], "entities": []}, {"text": "Ip only do animals depend i\u00f1 the Nile zi survival, but also daudr who live there need up zi everyday use like washing, ez a jopi supply, keeping crops watered\u00f1bwatered\u00f1b other jobs...", "labels": [], "entities": []}, {"text": "Our mixed-language based approach relies on incidental learning, which states that if a novel word is repeatedly presented to a student with sufficient context, the student will eventually be able to learn the novel word.", "labels": [], "entities": []}, {"text": "So far our experiments test MTurk participants on the \"guessability\" of novel words in context, but not learning.", "labels": [], "entities": []}, {"text": "To study if students can actually learn the L2 words, we conduct an MTurk experiment where participants are simply required to read a mixed-language document (one sentence at a time).", "labels": [], "entities": []}, {"text": "At the end of the document an L2 vocabulary quiz is given.", "labels": [], "entities": []}, {"text": "Participants must enter the meaning of every L2 word type they have seen during the reading phase.", "labels": [], "entities": []}, {"text": "Once again, we compare our cLM (r max = 4) model against a random baseline using the 6 Simple Wikipedia documents.", "labels": [], "entities": [{"text": "Simple Wikipedia documents", "start_pos": 87, "end_pos": 113, "type": "DATASET", "confidence": 0.8078533808390299}]}, {"text": "47 HITs were obtained from 45 MTurk participants for this experiment.", "labels": [], "entities": [{"text": "HITs", "start_pos": 3, "end_pos": 7, "type": "METRIC", "confidence": 0.9804264307022095}]}, {"text": "Participants were made aware that there would be a vocabulary quiz at the end of the document.", "labels": [], "entities": []}, {"text": "Our findings are summarized in.", "labels": [], "entities": []}, {"text": "We find the accuracy of guesses for the vocabulary quiz at the end of the document is considerably lower than guesses with context.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9995244741439819}]}, {"text": "However, subjects still managed to retain 35.53% and 27.77% of closed-class and open-class L2 word types respectively.", "labels": [], "entities": []}, {"text": "On the other hand, when a random mixed-language document was presented to participants, their guess accuracy dropped to 9.86% and 4.28% for closed and open class words respectively.", "labels": [], "entities": [{"text": "guess", "start_pos": 94, "end_pos": 99, "type": "METRIC", "confidence": 0.9398857355117798}, {"text": "accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.591630220413208}]}, {"text": "Thus, even though more word types were exposed by the random baseline, fewer words were retained.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Results from MTurk data. The first section  shows the percentage of tokens that were replaced  with L2 glosses under each condition. The Accuracy  section shows the percentage token accuracy of MTurk  participants' guesses along with 95% confidence  interval calculated via bootstrap resampling.", "labels": [], "entities": [{"text": "MTurk data", "start_pos": 23, "end_pos": 33, "type": "DATASET", "confidence": 0.7900872826576233}, {"text": "Accuracy", "start_pos": 147, "end_pos": 155, "type": "METRIC", "confidence": 0.9989668130874634}, {"text": "accuracy", "start_pos": 192, "end_pos": 200, "type": "METRIC", "confidence": 0.9409993886947632}]}, {"text": " Table 5: Results comparing our student proxy based  approach to a random baseline. The first part shows  the number of L2 word types exposed by each model  for each word-class. The second part shows the  average guess accuracy percentage for each model and  word-class. 95% confidence intervals (in brackets)  were computed using bootstrap resampling.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 219, "end_pos": 227, "type": "METRIC", "confidence": 0.5432924032211304}]}]}