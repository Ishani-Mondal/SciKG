{"title": [{"text": "Some steps towards the generation of diachronic WordNets", "labels": [], "entities": [{"text": "WordNets", "start_pos": 48, "end_pos": 56, "type": "DATASET", "confidence": 0.7313767075538635}]}], "abstractContent": [{"text": "We apply hyperbolic embeddings to trace the dynamics of change of conceptual-semantic relationships in a large di-achronic scientific corpus (200 years).", "labels": [], "entities": []}, {"text": "Our focus is on emerging scientific fields and the increasingly specialized terminology establishing around them.", "labels": [], "entities": []}, {"text": "Reproducing high-quality hierarchical structures such as WordNet on a diachronic scale is a very difficult task.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 57, "end_pos": 64, "type": "DATASET", "confidence": 0.944846510887146}]}, {"text": "Hyperbolic embeddings can map partial graphs into low dimensional, continuous hierarchical spaces, making more explicit the latent structure of the input.", "labels": [], "entities": []}, {"text": "We show that starting from simple lists of word pairs (rather than a list of entities with directional links) it is possible to build diachronic hierarchical semantic spaces which allow us to model a process towards specialization for selected scientific fields.", "labels": [], "entities": []}], "introductionContent": [{"text": "Knowledge of how conceptual structures changeover time and how the hierarchical relations among their components evolve is key to the comprehension of language evolution.", "labels": [], "entities": []}, {"text": "Recently, the distributional modelling of relationships between concepts has allowed the community to move a bit further in understanding the true mechanisms of semantic organization (, as well as in better mapping language change in terms of shifts in continuous semantic values).", "labels": [], "entities": []}, {"text": "In the past decades, extensive work has also gone into creating databases of hierarchical conceptual-semantic relationships, the most famous of these ontologies probably being WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 176, "end_pos": 183, "type": "DATASET", "confidence": 0.967333197593689}]}, {"text": "These hand-made resources are tools of high quality and precision, but they are difficult to reproduce on a diachronic scale (), due to word form changes) and shifts in meaning, which always make it hard to determine \"when\", over a period of time, anew lexical hierarchy is in place.", "labels": [], "entities": []}, {"text": "A recent attempt to integrate hierarchical structures, typical of lexical ontologies, and the commutative nature of semantic spaces are hyperbolic embeddings.", "labels": [], "entities": []}, {"text": "Hyperbolic embeddings have shown to be able to learn hierarchically structured, continuous, and lowdimensional semantic spaces from ordered lists of words: it is easy to see how such technology can be of interest for the construction of diachronic dynamic ontologies.", "labels": [], "entities": []}, {"text": "In contrast to hand-made resources, they can be built quickly from historical corpora, while retaining a hierarchical structure absent in traditional semantic spaces.", "labels": [], "entities": []}, {"text": "In their work have extensively evaluated hyperbolic embeddings on various tasks (taxonomies, link prediction in networks, lexical entailment), evaluating in particular the ability of these embeddings to infer hierarchical relationships without supervision.", "labels": [], "entities": [{"text": "link prediction in networks", "start_pos": 93, "end_pos": 120, "type": "TASK", "confidence": 0.8214011639356613}]}, {"text": "This paper is a first attempt in the direction of using hyperbolic semantic spaces to generate diachronic lexical ontologies.", "labels": [], "entities": []}, {"text": "While count-based and neural word embeddings have often been applied to historical data sets, and the temporal dimension has even solicited innovative kinds of distributional spaces (, this is to the best of our knowledge the first attempt to model a diachronic corpus through hierarchical, non-euclidean semantic spaces.", "labels": [], "entities": []}, {"text": "The literature on hyperbolic embeddings has until now mainly focused on reproducing lexical and social networks from contemporary data (.", "labels": [], "entities": []}, {"text": "We demonstrate that these kinds of word embeddings, while far from perfect, can capture relevant changes in large scale lexico-semantic relations.", "labels": [], "entities": []}, {"text": "These relations are on the \"vertical\" axis, defining a super-subordinate structure latent in the data.", "labels": [], "entities": []}, {"text": "But we also show that meaningful relations between words are preserved on the \"horizontal\" axis (similarity of meaning, common semantic belonging) as typically captured by distributional spaces and topic models.", "labels": [], "entities": []}, {"text": "While distributional semantic spaces can be built from unconstrained texts, the main conceptual limitation of hyperbolic embeddings probably lies in the fact the user always needs to precompose (and so pre-interpret) their input in the form of a list of entities linked by a set of parentchildren relations; we thus show a simple system to collect undirected relations between entities that require less pre-interpretation of the texts at hand and a broader lexical coverage, giving more value to the information provided by the spaces.", "labels": [], "entities": []}, {"text": "Our main contributions are thus two.", "labels": [], "entities": []}, {"text": "First, we apply hyperbolic embeddings to a diachronic setting, for which hand-crafted hierarchical resources are extremely difficult to create.", "labels": [], "entities": []}, {"text": "Second, we introduce a system to design training inputs that do not rely on directional lists of related word pairs as in previous works.", "labels": [], "entities": []}, {"text": "This is particularly advantageous as the system does not need a pre-interpretation nor a pre-formulation of the data in terms of explicit hierarchy and it allows a wider terminological coverage than the previous systems.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Corpus statistics of the RSC per decade.", "labels": [], "entities": [{"text": "Corpus statistics of the RSC", "start_pos": 10, "end_pos": 38, "type": "DATASET", "confidence": 0.5687063932418823}]}, {"text": " Table 4: Average norm for the 30 elements with the highest (H) and lowest (L) norm and percentage of  elements with norm higher than .3 for each period and discipline.", "labels": [], "entities": [{"text": "Average norm", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.9694900810718536}]}, {"text": " Table 5: Average number of WordNet senses for  the 30 terms with the lowest norm (column 2) and  for the 30 terms with the highest norm (column 3)  in the space of Physiology.", "labels": [], "entities": []}, {"text": " Table 6: Pearson correlation between WordNet senses and word's norm per period per topic.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.941784530878067}]}]}