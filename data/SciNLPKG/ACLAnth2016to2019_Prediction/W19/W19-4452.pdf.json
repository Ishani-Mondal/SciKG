{"title": [{"text": "Rubric Reliability and Annotation of Content and Argument in Source-Based Argument Essays", "labels": [], "entities": [{"text": "Rubric Reliability", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8564033806324005}]}], "abstractContent": [{"text": "We present a unique dataset of student source-based argument essays to facilitate research on the relations between content, argumentation skills, and assessment.", "labels": [], "entities": []}, {"text": "Two classroom writing assignments were given to college students in a STEM major, accompanied by a carefully designed rubric.", "labels": [], "entities": []}, {"text": "The paper presents a reliability study of the rubric, showing it to be highly reliable, and initial annotation on content and argumentation annotation of the essays.", "labels": [], "entities": []}], "introductionContent": [{"text": "Researchers in education have long recommended the use of rubrics to assess student writing and to inform instruction, especially regarding feedback to students.", "labels": [], "entities": []}, {"text": "Writing is important not only as a means to demonstrate knowledge, but also to acquire understanding of subject matter, including in STEM (.", "labels": [], "entities": []}, {"text": "Argumentative writing plays a key role in such learning (.", "labels": [], "entities": []}, {"text": "It is difficult, however, for instructors in subject areas to provide writing instruction alongside the disciplinary content ().", "labels": [], "entities": []}, {"text": "We are investigating the use of rubrics to support instruction in argumentation writing, with two goals in mind.", "labels": [], "entities": [{"text": "argumentation writing", "start_pos": 66, "end_pos": 87, "type": "TASK", "confidence": 0.9012942612171173}]}, {"text": "Our first goal is to investigate effective instruction of argument writing skills, including the design and application of rubrics.", "labels": [], "entities": [{"text": "argument writing", "start_pos": 58, "end_pos": 74, "type": "TASK", "confidence": 0.8849879205226898}]}, {"text": "Our second goal is to investigate how natural language processing techniques can facilitate instructors' use of rubrics.", "labels": [], "entities": []}, {"text": "The study described here is a collaboration among three computer science faculty: one specializing in educational technology, and two in natural language processing (NLP), who apply NLP to educational data.", "labels": [], "entities": []}, {"text": "To investigate how a rubric can support instruction in argument writing, we designed a sequence of two argument essay assignments and rubrics.", "labels": [], "entities": [{"text": "argument writing", "start_pos": 55, "end_pos": 71, "type": "TASK", "confidence": 0.7689257860183716}]}, {"text": "The collaborator in educational technology gave the assignments to college freshman enrolled in her academic skills class in their first semester.", "labels": [], "entities": []}, {"text": "Both assignments asked students to do a critical analysis of source material, and write an argumentative essay in response to a prompt by stating a claim, providing arguments in support of their claim, as well as counterarguments, before reaching a conclusion.", "labels": [], "entities": []}, {"text": "The instruction, and therefore the rubrics, emphasized students' ability to understand source material (content), to write a coherent essay (coherence), and to construct an argument (argumentation).", "labels": [], "entities": []}, {"text": "The assignments asked students to summarize the source material before writing the argument.", "labels": [], "entities": []}, {"text": "To support a fine-grained analysis of the students' essays and provide data for evaluating NLP techniques, the students' essays are manually annotated for content and argument.", "labels": [], "entities": []}, {"text": "The following sections present the assignments and rubrics, the essay data set, the reliability study, and the annotation methods for content and argumentation.", "labels": [], "entities": []}, {"text": "We present initial findings on the comparison of grades assigned in the class to those assigned by reliable raters, and on the relation of the annotation to the reliable grades.", "labels": [], "entities": []}, {"text": "We discuss questions that can be investigated about student learning, and about the interdependence of students' ability to articulate content and construct an argument.", "labels": [], "entities": []}], "datasetContent": [{"text": "The composition of the dataset supports simultaneous investigation of summary content analysis and argumentation mining: the former reflects the skills of reading comprehension and summarization, and the latter includes logical reasoning, argumentation, and writing skills.", "labels": [], "entities": [{"text": "summary content analysis", "start_pos": 70, "end_pos": 94, "type": "TASK", "confidence": 0.6875845193862915}, {"text": "argumentation mining", "start_pos": 99, "end_pos": 119, "type": "TASK", "confidence": 0.816474974155426}]}, {"text": "While summary and argument serve distinct roles, the combination into a single writing assignment allows us to assess the interdependence between reading comprehension and argument writing.", "labels": [], "entities": [{"text": "argument writing", "start_pos": 172, "end_pos": 188, "type": "TASK", "confidence": 0.748154491186142}]}, {"text": "Below, we present descriptive statistics of the dataset.", "labels": [], "entities": []}, {"text": "shows the sample sizes for essays on the given topics Cybercrime (CyberCri) with 44, Autonomous Vehicles (AutoV) with 42, and CryptoCurrencies (CrypCurr) with 37.", "labels": [], "entities": []}, {"text": "In the second assignment, there are 101 essays about AI.", "labels": [], "entities": []}, {"text": "shows that the second assignment had a higher average of tokens per sentence across summary, argument and overall.", "labels": [], "entities": []}, {"text": "The vocabulary size of the whole dataset is 5,923.", "labels": [], "entities": []}, {"text": "In contrast to other data sets investigated for argument mining, here the assignments are from a single course with the same set of students.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 48, "end_pos": 63, "type": "TASK", "confidence": 0.9516181945800781}]}, {"text": "The size of our data set is comparable to one used in () (TOEFL essays), but smaller than those used in).", "labels": [], "entities": [{"text": "TOEFL essays", "start_pos": 58, "end_pos": 70, "type": "DATASET", "confidence": 0.7704292833805084}]}, {"text": "In addition, the data set we collected has multiple essays for four topics, based on source readings.", "labels": [], "entities": []}, {"text": "This gives us the opportunity to investigate students' reliance on source material in their argumentation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Sample size given each assignment and topic;  the total number of essays is 224.", "labels": [], "entities": []}, {"text": " Table 2: Dataset statistics of average numbers of  sentences (Sents) and average tokens per sentence  (Tk/Sents) from summaries (Sum) and arguments  (Arg) across topics. The total vocabulary size is also  given.", "labels": [], "entities": []}, {"text": " Table 3: Correlations of the reliable grades with the tutors' grades", "labels": [], "entities": []}, {"text": " Table 4: Distributions of SCUs with weights from man- ual pyramids annotation of Cryptocurrencies and Au- tonomous Vehicle", "labels": [], "entities": []}, {"text": " Table 7: Correlation of LR (5 fold CV) with argument  quality scores.", "labels": [], "entities": [{"text": "LR", "start_pos": 25, "end_pos": 27, "type": "METRIC", "confidence": 0.5844486355781555}]}]}