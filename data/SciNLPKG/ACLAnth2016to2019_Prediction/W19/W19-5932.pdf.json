{"title": [{"text": "Dialog State Tracking: A Neural Reading Comprehension Approach", "labels": [], "entities": [{"text": "Dialog State Tracking", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8652921120325724}]}], "abstractContent": [{"text": "Dialog state tracking is used to estimate the current belief state of a dialog given all the preceding conversation.", "labels": [], "entities": [{"text": "Dialog state tracking", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7356700499852499}]}, {"text": "Machine reading comprehension , on the other hand, focuses on building systems that read passages of text and answer questions that require some understanding of passages.", "labels": [], "entities": [{"text": "Machine reading comprehension", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8208703597386678}]}, {"text": "We formulate dialog state tracking as a reading comprehension task to answer the question what is the state of the current dialog?", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 13, "end_pos": 34, "type": "TASK", "confidence": 0.7137988209724426}]}, {"text": "In contrast to traditional state tracking methods where the dialog state is often predicted as a distribution over a closed set of all the possible slot values within an ontology, our method uses a simple attention-based neu-ral network to point to the slot values within the conversation.", "labels": [], "entities": [{"text": "state tracking", "start_pos": 27, "end_pos": 41, "type": "TASK", "confidence": 0.7451415359973907}]}, {"text": "Experiments on MultiWOZ-2.0 cross-domain dialog dataset show that our simple system can obtain similar accuracies compared to the previous more complex methods.", "labels": [], "entities": []}, {"text": "By exploiting recent advances in contex-tual word embeddings, adding a model that explicitly tracks whether a slot value should be carried over to the next turn, and combining our method with a traditional joint state tracking method that relies on closed set vocabulary , we can obtain a joint-goal accuracy of 47.33% on the standard test split, exceeding current state-of-the-art by 11.75%**.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 300, "end_pos": 308, "type": "METRIC", "confidence": 0.8308162689208984}]}], "introductionContent": [{"text": "A task-oriented spoken dialog system involves continuous interaction with a machine agent and a human who wants to accomplish a predefined task through speech.", "labels": [], "entities": []}, {"text": "Broadly speaking, the system has *Authors contributed equally.", "labels": [], "entities": []}, {"text": "**We note that after publication, anew state-of-the-art can now be obtained with a similar attention mechanism followed by a enoder-decoder architecture ( four components, the Automatic Speech Recognition (ASR) module, the Natural Language Understanding (NLU) module, the Natural Language Generation (NLG) module, and the Dialog Manager.", "labels": [], "entities": []}, {"text": "The dialog manager has two primary missions: dialog state tracking (DST) and decision making.", "labels": [], "entities": [{"text": "dialog state tracking (DST)", "start_pos": 45, "end_pos": 72, "type": "TASK", "confidence": 0.7729759414990743}, {"text": "decision making", "start_pos": 77, "end_pos": 92, "type": "TASK", "confidence": 0.8519054651260376}]}, {"text": "At each dialog turn, the state tracker updates the belief state based on the information received from the ASR and the NLU modules.", "labels": [], "entities": []}, {"text": "Subsequently, the dialog manager chooses the action based on the dialog state, the dialog policy and the backend results produced from previously executed actions.", "labels": [], "entities": []}, {"text": "shows an example conversation with the associated dialog state.", "labels": [], "entities": []}, {"text": "Typical dialog state tracking system combines user speech, NLU output, and context from previous turns to track what has happened in a dialog.", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 8, "end_pos": 29, "type": "TASK", "confidence": 0.8128063281377157}]}, {"text": "More specifically, the dialog state at each turn is defined as a distribution over a set of predefined variables ().", "labels": [], "entities": []}, {"text": "The distributions output by a dialog state tracker are sometimes referred to as the tracker's belief or the belief state.", "labels": [], "entities": []}, {"text": "Typically, the tracker has complete access to the history of the dialog up to the current turn.", "labels": [], "entities": []}, {"text": "Traditional machine learning approaches to dialog state tracking have two forms, generative and discriminative.", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 43, "end_pos": 64, "type": "TASK", "confidence": 0.8507912158966064}]}, {"text": "In generative approaches, a dialog is modeled as a dynamic Bayesian network where true dialog state and true user action are unobserved random variables; whereas the discriminative approaches are directly modeling the distribution over the dialog state given arbitrary input features.", "labels": [], "entities": []}, {"text": "Despite the popularity of these approaches, they often suffer from a common yet overlooked problem -relying on fixed ontologies.", "labels": [], "entities": []}, {"text": "These systems, therefore, have trouble handling previously unseen mentions.", "labels": [], "entities": []}, {"text": "On the other hand, reading comprehension tasks) require us to find the answer spans within the given passage and hence state-of-the-art models are developed in such away that a fixed vocabulary for an answer is usually not required.", "labels": [], "entities": []}, {"text": "Motivated by the limitations of previous dialog state tracking methods and the recent advances in reading comprehension, we propose a reading comprehension based approach to dialog state tracking.", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 41, "end_pos": 62, "type": "TASK", "confidence": 0.7371314366658529}, {"text": "dialog state tracking", "start_pos": 174, "end_pos": 195, "type": "TASK", "confidence": 0.8321705857912699}]}, {"text": "In our approach, we view the dialog as a passage and ask the question what is the state of the current dialog?", "labels": [], "entities": []}, {"text": "We use a simple attention-based neural network model to find answer spans by directly pointing to the tokens within the dialog, which is similar to.", "labels": [], "entities": []}, {"text": "In addition to this attentive reading model, we also introduce two simple models into our dialog state tracking pipeline, a slot carryover model to help the tracker make a binary decision whether the slot values from the previous turn should be used; a slot type model to predict whether the answer is {Yes, No, DontCare, Span}, which is similar to.", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 90, "end_pos": 111, "type": "TASK", "confidence": 0.6316142876942953}]}, {"text": "To summarize our contributions: \u2022 We formulate dialog state tracking as a reading comprehension task and propose a simple attention-based neural network to find the state answer as a span over tokens within the dialog.", "labels": [], "entities": [{"text": "formulate dialog state tracking", "start_pos": 37, "end_pos": 68, "type": "TASK", "confidence": 0.6722588390111923}]}, {"text": "Our approach overcomes the limitations of fixed-vocabulary issue in previous approaches and can generalize to unseen state values.", "labels": [], "entities": []}, {"text": "\u2022 We present the task of dialog state tracking as making three sequential decisions: i) a binary carryover decision by a simple slot carryover model ii) a slot type decision by a slot type model iii) a slot span decision by an attentive reading comprehension model.", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 25, "end_pos": 46, "type": "TASK", "confidence": 0.7778803507486979}]}, {"text": "We show effectiveness of this approach.", "labels": [], "entities": []}, {"text": "\u2022 We adopt recent progress in large pretrained contextual word embeddings, i.e., BERT (Devlin et al., 2018) into dialog state tracking, and get considerable improvement.", "labels": [], "entities": [{"text": "BERT", "start_pos": 81, "end_pos": 85, "type": "METRIC", "confidence": 0.9904292821884155}, {"text": "dialog state tracking", "start_pos": 113, "end_pos": 134, "type": "TASK", "confidence": 0.778442899386088}]}, {"text": "\u2022 We show our proposed model outperforms more complex previously published methods on the recently released MultiWOZ-2.0 corpus (.", "labels": [], "entities": [{"text": "MultiWOZ-2.0 corpus", "start_pos": 108, "end_pos": 127, "type": "DATASET", "confidence": 0.9081143438816071}]}, {"text": "Our approach achieves a jointgoal accuracy of 42.12%, resulting in a 6.5% absolute improvement over previous state-ofUser: I need to book a hotel in the east that has 4 stars.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9052981734275818}]}, {"text": "Hotel area=east, stars=4 Agent: I can help you with that.", "labels": [], "entities": []}, {"text": "What is your price range?", "labels": [], "entities": []}, {"text": "User: That doesn't matter if it has free wifi and parking.", "labels": [], "entities": []}, {"text": "Hotel parking=yes, internet=yes price=dontcare, stars=4, area=east Agent: If you'd like something cheap, I recommend Allenbell User: That sounds good, I would also like a taxi to the hotel from cambridge Hotel parking=yes, internet=yes price=dontcare, area=east, stars=4 Taxi departure=Cambridge destination=Allenbell the-art.", "labels": [], "entities": [{"text": "Allenbell", "start_pos": 117, "end_pos": 126, "type": "DATASET", "confidence": 0.9352531433105469}, {"text": "Cambridge", "start_pos": 286, "end_pos": 295, "type": "DATASET", "confidence": 0.896251380443573}, {"text": "Allenbell", "start_pos": 308, "end_pos": 317, "type": "DATASET", "confidence": 0.9331064224243164}]}, {"text": "Furthermore, if we combine our results with the traditional joint state tracking method in, we achieve a joint-goal accuracy of 47.33%, further advancing the state-of-the-art by 11.75%.", "labels": [], "entities": [{"text": "joint state tracking", "start_pos": 60, "end_pos": 80, "type": "TASK", "confidence": 0.6306272447109222}, {"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9483791589736938}]}, {"text": "\u2022 We provide an in-depth error analysis of our methods on the MultiWOZ-2.0 dataset and explain to what extent an attention-based reading comprehension model can be effective for dialog state tracking and inspire future improvements on this model.", "labels": [], "entities": [{"text": "MultiWOZ-2.0 dataset", "start_pos": 62, "end_pos": 82, "type": "DATASET", "confidence": 0.9265996813774109}, {"text": "dialog state tracking", "start_pos": 178, "end_pos": 199, "type": "TASK", "confidence": 0.9148603479067484}]}], "datasetContent": [{"text": "We train our three models independently without sharing the dialog context.", "labels": [], "entities": []}, {"text": "For all the three models, we encode the word tokens with BERT (Devlin et al., 2018) followed by an affine layer with 200 hidden units.", "labels": [], "entities": [{"text": "BERT", "start_pos": 57, "end_pos": 61, "type": "METRIC", "confidence": 0.9989790916442871}]}, {"text": "This output is then fed into a one-layer bi-directional LSTM with 50 hidden units to obtain the contextual representation as show in.", "labels": [], "entities": []}, {"text": "In all our experiments, we keep the parameters of the BERT embeddings frozen.", "labels": [], "entities": [{"text": "BERT", "start_pos": 54, "end_pos": 58, "type": "METRIC", "confidence": 0.8593934178352356}]}, {"text": "For slot carryover model, we predict a binary vector over 37 slots jointly to get the decisions of whether to carryover values for each slot.", "labels": [], "entities": []}, {"text": "For slot type and slot span models, we treat dialogquestion pairs (D t , q i ) as separate prediction tasks for each slot.", "labels": [], "entities": []}, {"text": "We use the learning rate of 0.001 with ADAM optimizer and batch size equal to 32 for all three models.", "labels": [], "entities": []}, {"text": "We stop training our models when the loss on the development set has not been decreasing for ten epochs.", "labels": [], "entities": []}, {"text": "presents our results on MultiWOZ-2.0 test dataset.", "labels": [], "entities": [{"text": "MultiWOZ-2.0 test dataset", "start_pos": 24, "end_pos": 49, "type": "DATASET", "confidence": 0.8850195209185282}]}, {"text": "We compare our methods with global-local self-attention model (GLAD) (, global-conditioned encoder model (GCE), and hybrid joint state tracking model (OV ST+JST) (.", "labels": [], "entities": []}, {"text": "As in previous work, we report joint goal accuracy as our metric.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.8559771776199341}]}, {"text": "For each user turn, joint goal accuracy checks whether all predicted states exactly matches the ground truth state for all slots.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.762381374835968}]}, {"text": "We can see that our system with single model can achieve 39.41% joint goal accuracy, and with the ensemble model we can achieve 42.12% joint goal accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.8464513421058655}, {"text": "accuracy", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.8060635924339294}]}, {"text": "shows the accuracy for each slot type for both our method and the joint state tracking approach with fix vocabulary in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9995947480201721}]}], "tableCaptions": [{"text": " Table 2: Joint goal accuracy on MultiWOZ-2.0. We  present both single and ensemble results for our ap- proach.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9698615670204163}]}, {"text": " Table 4: Ablation study on our model components for  MultiWOZ-2.0 on development set for joint goal accu- racy.", "labels": [], "entities": []}, {"text": " Table 5: Error categorization and percentage distribution: representative example from each category and an  estimate breakdown of the error types on development set, based on the analysis of 200 error samples produced by  our model. Numbers of the first category is exact because we are able to summarize this error category statistically.", "labels": [], "entities": []}, {"text": " Table 6: Analyzing the different types of context fea- tures for Slot Carryover Model", "labels": [], "entities": []}, {"text": " Table 7: Analyzing the overall model robustness for  conversation depth for MultiWOZ-2.0", "labels": [], "entities": [{"text": "conversation depth", "start_pos": 54, "end_pos": 72, "type": "TASK", "confidence": 0.7999158501625061}]}]}