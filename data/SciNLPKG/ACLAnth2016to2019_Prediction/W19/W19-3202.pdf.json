{"title": [{"text": "Lexical Normalization of User-Generated Medical Forum Data", "labels": [], "entities": [{"text": "Lexical Normalization of User-Generated Medical Forum", "start_pos": 0, "end_pos": 53, "type": "TASK", "confidence": 0.8265322943528494}]}], "abstractContent": [{"text": "In the medical domain, user-generated social media text is increasingly used as a valuable complementary knowledge source to scientific medical literature.", "labels": [], "entities": []}, {"text": "The extraction of this knowledge is complicated by colloquial language use and misspellings.", "labels": [], "entities": []}, {"text": "Yet, lexical nor-malization of such data has not been addressed properly.", "labels": [], "entities": []}, {"text": "This paper presents an unsuper-vised, data-driven spelling correction module for medical social media.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 50, "end_pos": 69, "type": "TASK", "confidence": 0.8260030448436737}]}, {"text": "Our method outper-forms state-of-the-art spelling correction and can detect mistakes with an F 0.5 of 0.888.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.8762189149856567}, {"text": "F 0.5", "start_pos": 93, "end_pos": 98, "type": "METRIC", "confidence": 0.9822633564472198}]}, {"text": "Additionally, we present a novel corpus for spelling mistake detection and correction on a medical patient forum.", "labels": [], "entities": [{"text": "spelling mistake detection and correction", "start_pos": 44, "end_pos": 85, "type": "TASK", "confidence": 0.8222299456596375}]}], "introductionContent": [{"text": "In recent years, user-generated data from social media that contains information about health, such as patient forum posts or health-related tweets, has been used extensively for medical text mining and information retrieval (IR) (.", "labels": [], "entities": [{"text": "medical text mining", "start_pos": 179, "end_pos": 198, "type": "TASK", "confidence": 0.6094269851843516}, {"text": "information retrieval (IR)", "start_pos": 203, "end_pos": 229, "type": "TASK", "confidence": 0.8545768976211547}]}, {"text": "This user-generated data encapsulates avast amount of knowledge, which has been used fora range of health-related applications, such as the tracking of public health trends and the detection of adverse drug responses ( . However, the extraction of this knowledge is complicated by nonstandard and colloquial language use, typographical errors, phonetic substitutions, and misspellings ().", "labels": [], "entities": []}, {"text": "Thus, social media text is generally noisy and this is only aggravated by the complex medical domain (.", "labels": [], "entities": []}, {"text": "Despite these challenges, text normalization for medical social media has not been explored thoroughly.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.8104617297649384}]}, {"text": "Medical lexical normalization methods (i.e. abbreviation expansion and spelling correction) have mostly been developed for clinical records or notes, as these also contain an abundance of domain-specific abbreviations and misspellings.", "labels": [], "entities": [{"text": "Medical lexical normalization", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6332444349924723}, {"text": "abbreviation expansion", "start_pos": 44, "end_pos": 66, "type": "TASK", "confidence": 0.74620720744133}, {"text": "spelling correction", "start_pos": 71, "end_pos": 90, "type": "TASK", "confidence": 0.7707780301570892}]}, {"text": "However, social media text presents distinct challenges, such as colloquial language use, ( that cannot be tackled with these methods.", "labels": [], "entities": []}, {"text": "The most comprehensive benchmark for general-domain social media text normalization is the ACL W-NUT 2015 shared task 1.", "labels": [], "entities": [{"text": "general-domain social media text normalization", "start_pos": 37, "end_pos": 83, "type": "TASK", "confidence": 0.6033986508846283}, {"text": "ACL W-NUT 2015 shared task 1", "start_pos": 91, "end_pos": 119, "type": "DATASET", "confidence": 0.8259664674599966}]}, {"text": "The current state-of-the-art system for this task is a modular pipeline with a hybrid approach to spelling, developed by.", "labels": [], "entities": []}, {"text": "Their pipeline also includes a customizable back-end module for domain-specific normalization.", "labels": [], "entities": [{"text": "domain-specific normalization", "start_pos": 64, "end_pos": 93, "type": "TASK", "confidence": 0.6145516932010651}]}, {"text": "However, this back-end module relies, on the one hand, on a standard dictionary supplemented manually with domain-specific terms to detect mistakes and, on the other hand, on a language model of generic Twitter data to correct these mistakes.", "labels": [], "entities": []}, {"text": "For domains that have many out-of-vocabulary (OOV) terms compared to the available dictionaries and language models, such as medical social media, this is problematic.", "labels": [], "entities": []}, {"text": "Manual creation of specialized dictionaries is an unfeasible alternative: medical social media can be devoted to a wide range of different medical conditions and developing dictionaries for each condition (including laymen terms) would be very labor-intensive.", "labels": [], "entities": []}, {"text": "Additionally, there are many different ways of expressing the same information and the language use in the forum evolves overtime.", "labels": [], "entities": []}, {"text": "Consequently, hand-made lexicons may get outdated (.", "labels": [], "entities": []}, {"text": "In this paper, we present an alternative: a corpusdriven spelling correction approach.", "labels": [], "entities": [{"text": "corpusdriven spelling correction", "start_pos": 44, "end_pos": 76, "type": "TASK", "confidence": 0.6262412071228027}]}, {"text": "We address two research questions: 1.", "labels": [], "entities": []}, {"text": "To what extent can corpus-driven spelling correction reduce the out-of-vocabulary rate in medical social media text?", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.816148191690445}]}, {"text": "2. To what extent can our corpus-driven spelling correction improve accuracy of health-related classification tasks with social media text?", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.7663193941116333}, {"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9975226521492004}]}, {"text": "Our contributions are (1) an unsupervised datadriven spelling correction method that works well on specialized domains with many OOV terms without the need fora specialized dictionary and (2) the first corpus for evaluating mistake detection and correction in a medical patient forum.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.7460070848464966}, {"text": "mistake detection and correction in a medical patient forum", "start_pos": 224, "end_pos": 283, "type": "TASK", "confidence": 0.7900258302688599}]}, {"text": "Our method is designed to be conservative and to focus on precision to mitigate one of the major challenges of correcting errors in domain-specific data: the loss of information due to the 'correction' of already correct domain-specific terms.", "labels": [], "entities": [{"text": "precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.99920254945755}]}, {"text": "We hypothesize that a dictionary-based method is able to retrieve more mistakes than a data-driven method, because all terms not included in the dictionary are classified as mistakes, which will probably include all non-word errors.", "labels": [], "entities": []}, {"text": "However, we also expect that a dictionary-based method will misclassify more correct terms as mistakes, because any domain-specific terms not present in the dictionary will be classified incorrectly.", "labels": [], "entities": []}], "datasetContent": [{"text": "As can been seen in  ter Health classification task, the improvement is significant with a p-value of 0.041 according to a paired t-test.", "labels": [], "entities": [{"text": "ter Health classification task", "start_pos": 21, "end_pos": 51, "type": "TASK", "confidence": 0.6845459043979645}]}, {"text": "In general, these changes are of the same order of magnitude as those made by the normalization pipeline of.", "labels": [], "entities": []}, {"text": "Moreover, the % of alterations due to spelling correction is comparable to that of the two cancer-related forums (see.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.8470785021781921}]}, {"text": "Although the overall classification accuracy on Task 1 of the SMM4H workshop is low, this is inline with the low F 1 score (0.522) of the best performing system on the comparable task in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.8853883743286133}, {"text": "SMM4H workshop", "start_pos": 62, "end_pos": 76, "type": "TASK", "confidence": 0.7723716795444489}, {"text": "F 1 score (0.522)", "start_pos": 113, "end_pos": 130, "type": "METRIC", "confidence": 0.9351576864719391}]}, {"text": "Neither the goal of the task, the relative amount of corrections nor the initial result seem to correlate with the change in F 1 score.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 125, "end_pos": 134, "type": "METRIC", "confidence": 0.9869202574094137}]}, {"text": "Unlike in Sarker (2017), the improvements also do not seem to increase with the size of the data.", "labels": [], "entities": []}, {"text": "The imbalance of the data maybe associated with the change inaccuracy to some extent: the two most balanced data sets show the largest increase (see).", "labels": [], "entities": []}, {"text": "Further experiments would be necessary to elucidate if this is truly the case.", "labels": [], "entities": []}, {"text": "As can be seen in, our method does not perform well on generic social media text.", "labels": [], "entities": []}, {"text": "In comparison, Sarker (2017)'s method attained state-ofthe-art results with a F 1 of 0.836 on the ACL W-NUT 2015, but functioned poorly for medical social media (see).", "labels": [], "entities": [{"text": "F 1", "start_pos": 78, "end_pos": 81, "type": "METRIC", "confidence": 0.9967729151248932}, {"text": "ACL W-NUT 2015", "start_pos": 98, "end_pos": 112, "type": "DATASET", "confidence": 0.8983921806017557}]}, {"text": "Thus, the success on one does not imply success on the other and consequently, normalisation of generic social media text and of domain-specific social media text appear different to the extent that they necessitate different approaches.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Raw data without punctuation. IQR: Inter- quartile range", "labels": [], "entities": [{"text": "IQR", "start_pos": 40, "end_pos": 43, "type": "METRIC", "confidence": 0.9888732433319092}]}, {"text": " Table 2: Six classification data sets of health-related Twitter data. *SMM4H: Social Media Mining 4 Health  workshop", "labels": [], "entities": []}, {"text": " Table 3: Accuracy of spelling correction methods", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9968796968460083}, {"text": "spelling correction", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.8461876809597015}]}, {"text": " Table 5: Results for mistake detection methods on the  test set", "labels": [], "entities": [{"text": "mistake detection", "start_pos": 22, "end_pos": 39, "type": "TASK", "confidence": 0.7823129594326019}]}, {"text": " Table 7: Analysis of 50 most frequent remaining OOV  in two cancer forums", "labels": [], "entities": [{"text": "Analysis", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9391829371452332}]}, {"text": " Table 8: Mean classification accuracy before normalization (prenorm), after normalization (postnorm) and after  spelling correction (postspell) for six health-related classification tasks. Only the results for the best performing  classifier per data set are reported. MNB: Multinomial Naive Bayes; SVC: Linear Support Vector Classification.  + Absolute change compared to prenorm.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9741671681404114}, {"text": "Absolute change", "start_pos": 346, "end_pos": 361, "type": "METRIC", "confidence": 0.9735534489154816}]}, {"text": " Table 9: Results for unconstrained systems of ACL W-NUT 2015", "labels": [], "entities": [{"text": "ACL W-NUT 2015", "start_pos": 47, "end_pos": 61, "type": "DATASET", "confidence": 0.7875044941902161}]}]}