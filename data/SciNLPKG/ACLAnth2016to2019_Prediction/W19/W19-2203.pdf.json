{"title": [{"text": "The Extent of Repetition in Contract Language", "labels": [], "entities": [{"text": "Extent of Repetition in Contract Language", "start_pos": 4, "end_pos": 45, "type": "TASK", "confidence": 0.8050925731658936}]}], "abstractContent": [{"text": "Contract language is repetitive (Anderson and Manns, 2017), but so is all language (Zipf, 1949).", "labels": [], "entities": []}, {"text": "In this paper, we measure the extent to which contract language in English is repetitive compared with the language of other En-glish language corpora.", "labels": [], "entities": []}, {"text": "Contracts have much smaller vocabulary sizes compared with similarly sized non-contract corpora across multiple contract types, contain 1/5 th as many ha-pax legomena, pattern differently on a log-log plot, use fewer pronouns, and contain sentences that are about 20% more similar to one another than in other corpora.", "labels": [], "entities": []}, {"text": "These suggest that the study of contracts in natural language processing controls for some linguistic phenomena and allows for more in depth study of others.", "labels": [], "entities": []}], "introductionContent": [{"text": "Among attorneys and those in the legal professions, contract language is considered \"repetitive,\" but the same can be said about natural language in general.", "labels": [], "entities": []}, {"text": "largely attribute the repetitive nature of contract language to drafting methodologies.", "labels": [], "entities": []}, {"text": "Attorneys rarely start contracts or provisions from a blank document.", "labels": [], "entities": []}, {"text": "showed that attorneys typically select a precedent contracts and fit them to the parameters of anew relationship with a counterparty.", "labels": [], "entities": []}, {"text": "The same is true when an attorney drafts anew contract provision, beginning with an old provision from an existing agreement.", "labels": [], "entities": []}, {"text": "As a result, new or novel language is infrequent as compared to other kinds of natural language.", "labels": [], "entities": []}, {"text": "They assessed these similarities using Levenshtein distance, which is somewhat unusual with respect to the methods and statistics typically used in natural language processing and corpus linguistics, and they did not compare their corpus of contracts against data of the sort typically used in natural language processing and corpus linguistics-for our purposes, the Brown Corpus ( and Wikipedia.", "labels": [], "entities": [{"text": "Levenshtein distance", "start_pos": 39, "end_pos": 59, "type": "METRIC", "confidence": 0.6975120604038239}, {"text": "Brown Corpus", "start_pos": 367, "end_pos": 379, "type": "DATASET", "confidence": 0.9824761152267456}]}, {"text": "This paper seeks to describe quantitatively the extent to which contract language is more repetitive than the language found in these corpora.", "labels": [], "entities": []}, {"text": "We aim this paper at multiple audiences.", "labels": [], "entities": []}, {"text": "Our own motivation was to more deeply understand the driving linguistic and distributional factors behind technology that developed, and we hope those in industry who work with or are evaluating legal technology can read this work to understand how this repetition uniquely supports the automation of work involving contract language.", "labels": [], "entities": []}, {"text": "We hope the computational linguist working on contract or legal texts can use the findings hereto justify certain decisions and positions made in their own work, as a basic foundation of facts can help reduce exponentially the tree of decisions made in practice.", "labels": [], "entities": []}, {"text": "We hope the computational linguistics community at large can take from this paper that contract language has properties advantageous for problems that prefer more constrained-but still natural-language.", "labels": [], "entities": []}, {"text": "In this paper, we present analyses of contract language in English, juxtaposing them against two other English language corpora.", "labels": [], "entities": []}, {"text": "In Section (2), we discuss prior work toward this end.", "labels": [], "entities": []}, {"text": "In Section (3), we discuss the data used in this study: a set of contract corpora containing 1,737 documents and two baseline corpora for comparison.", "labels": [], "entities": []}, {"text": "In Section (4), we discuss the distribution of tokens in our contract corpus compared with the baseline corpora and look more closely at the data to affirm the meaning of those distributions.", "labels": [], "entities": []}, {"text": "In Section (5), we step up from the token level to look at similarity at the sentential level through a nearest neighbors analysis.", "labels": [], "entities": []}, {"text": "In Sections, we discuss these findings broadly and conclude.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Document and Token Counts per Category.", "labels": [], "entities": []}, {"text": " Table 2: Raw Statistics on Subsamples of Corpora Investigated. |C| indicates the size of the whole corpus; |S|  indicates the size of the subcorpus investigated.", "labels": [], "entities": []}, {"text": " Table 4: Statistics of the Distribution of Scores by  Number of Docs. \"Average\" refers to the average of all  scores at that point. \"Frac Max\" refers to the fraction  of scores in the highest bin between 0.98 and 1.", "labels": [], "entities": [{"text": "Average", "start_pos": 72, "end_pos": 79, "type": "METRIC", "confidence": 0.9475554823875427}, {"text": "Frac Max\"", "start_pos": 134, "end_pos": 143, "type": "METRIC", "confidence": 0.9288872083028158}]}]}