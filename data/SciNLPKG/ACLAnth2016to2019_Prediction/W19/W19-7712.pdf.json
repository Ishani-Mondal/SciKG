{"title": [{"text": "Identifying grammar rules for language education with dependency parsing in German", "labels": [], "entities": [{"text": "Identifying grammar", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8969748914241791}, {"text": "dependency parsing", "start_pos": 54, "end_pos": 72, "type": "TASK", "confidence": 0.7155647873878479}]}], "abstractContent": [{"text": "We propose a method of determining the syntactic difficulty of a sentence, using syntactic patterns that identify grammatical rules on dependency parses.", "labels": [], "entities": []}, {"text": "We have constructed a novel query language based on constraint-based dependency grammars and a grammar of German rules (rel-evant to primary school education) with patterns in our language.", "labels": [], "entities": []}, {"text": "We annotated these rules with a difficulty score and grammatical prerequisites and built a matching algorithm that matches the dependency parse of a sentence in CoNLL-U format with its relevant syntactic patterns.", "labels": [], "entities": []}, {"text": "We achieved 96% precision and 95% recall on a manually annotated set of sentences, and our best results on using parses from four parsers are 88% and 84% respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9996060729026794}, {"text": "recall", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.9994409680366516}]}], "introductionContent": [{"text": "Language teaching on beginner and elementary levels, even for native speakers, brings the challenge of presenting grammatical phenomena which are familiar, unconsciously familiar or unknown to the learner, in a formal and repetitive way so that the learner will be able to understand and remember them.", "labels": [], "entities": []}, {"text": "The presentation of these phenomena to the learner should be consistent, to establish correct patterns, repeated, to facilitate learning, and of gradual difficulty and infrequency, to ensure that the easier structures are acquired before the more difficult ones.", "labels": [], "entities": []}, {"text": "The iRead project, in which we are scientific partners, aims to create learning applications for children in primary education, in which the user will be able to read and play with language content tailored to their learning needs, e.g. games that require the user to choose the correct morpheme, phoneme or part-of-speech to complete a pattern.", "labels": [], "entities": []}, {"text": "Our roles are, first, to provide learning resources for native German primary school learners (ages 6-9) and, second, to provide a syntactic tool for the analysis of sentences and texts (a CoNLL-U multilingual dependency parser) and a formalism that can be used to represent grammatic phenomena and query them from dependency parses.", "labels": [], "entities": [{"text": "CoNLL-U multilingual dependency parser", "start_pos": 189, "end_pos": 227, "type": "TASK", "confidence": 0.7533569633960724}]}, {"text": "In this paper, we will be focusing on how we created our syntactic pattern formalism, the algorithm to match patterns with sentences, and the language resources that we used alongside our pattern matching tool, in order to find the grammatical rules that are applicable in a sentence.", "labels": [], "entities": []}, {"text": "The reason we decided to create our own query language was the need to be able to create very restrictive patterns that would almost never be found in the text erroneously or overzealously; these patterns express grammatical phenomena taught in school to young learners, and our margin for incorrect matches of a grammar rule with text is very limited.", "labels": [], "entities": []}, {"text": "In addition, our language should be very descriptive but also human readable, so that our partners will be able to create grammatical patterns for other languages without extensive knowledge on logical operators and regular expressions.", "labels": [], "entities": []}, {"text": "Finally, we opted to create a query language whose search relies on dependency parsing, and not on the surface structure of a clause.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.7233682572841644}]}, {"text": "We will present our query language and the grammatical rule patterns that we have created for German primary school learners, and we will also present the matching algorithm we built to match these rule patterns to sentences from our corpus of children's texts.", "labels": [], "entities": []}, {"text": "Moreover, we will be evaluating our matching algorithm's performance on this corpus with parses from our and other parsers; the reason we are not using more complex text is because our patterns are made to reflect syntactic phenomena appropriate for child learners.", "labels": [], "entities": []}, {"text": "We are aware that many query languages have been created over the years, in which the researcher can create a pattern to extract one or multiple words with specific syntactic, morphological, orthographic etc.", "labels": [], "entities": []}, {"text": "However, most of them do not support queries from dependency parses, but require annotated text with parts-of-speech, and only a few such as ANNIS () allow for patterns to look for relationships between two nodes of a syntactic tree.", "labels": [], "entities": []}, {"text": "Other languages require the position of extra words given explicitly relative to the first word), or rely on neighbouring words without capturing any dependencies (Poliqarp; ().", "labels": [], "entities": []}, {"text": "In addition, these query languages require a certain level of expertise with regular expressions and the syntax of the language; efforts have been made to simplify the syntax of these languages, for example Coral () is a controlled natural language that translates natural language queries to the ANNIS syntax.", "labels": [], "entities": []}, {"text": "Query languages tailored for use with dependency parses also have existed fora while; for example PML-TQ () contains a very robust query language which is able to search for one, two or multiple constituents of a syntactic tree, either terminal non-terminal nodes.", "labels": [], "entities": [{"text": "dependency parses", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.7730287611484528}]}, {"text": "It is versatile and dynamic, and it would allow us to define patterns between words and phrases to cover the simplest rules (e.g. the presence of predicate) to more complex (e.g. constituents of a question clause), but its syntax is very complex for us to use throughout our project.", "labels": [], "entities": []}, {"text": "T\u00fcNDRA (Martens, 2012) is another query language which also supports queries of one or multiple words based on annotation, deep or surface structure, negation, etc. and uses a similar syntax and the TIGERSearch annotation schema).", "labels": [], "entities": [{"text": "T\u00fcNDRA (Martens, 2012)", "start_pos": 0, "end_pos": 22, "type": "DATASET", "confidence": 0.7631022532780966}]}, {"text": "For our intents and purposes, it would be a fairly complete approach for our task of querying grammatical rules; however, we still wanted to attempt an approach that would be inspired by the successes of the predecessors and offer even better readability and adherence to the theory of dependency parsing, instead of also offering a search for serialized words, syntactically meaningless strings etc.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 286, "end_pos": 304, "type": "TASK", "confidence": 0.7849836349487305}]}, {"text": "To create the queries for the grammatical rules, as explained in Section 1, we avoided the use of an automatic method to extract syntactic patterns automatically from text.", "labels": [], "entities": []}, {"text": "Pattern induction would not be accurate and informative enough to create patterns for the specific grammatic rules that we have declared.", "labels": [], "entities": [{"text": "Pattern induction", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8983547687530518}]}, {"text": "For example, a statistical extraction that created pairs of a dependent and headword from dependency parses of English sentences would probably not be sufficient in capturing all the constituents of a grammatical rule, and in any case would require human annotation to the corresponding grammatical rule and its difficulty and frequency.", "labels": [], "entities": []}, {"text": "A statistic approach close to our needs involves extracting syntactic patterns based on syntax trees from a large English corpus and scoring their difficulty based on a Zipfian distribution (.", "labels": [], "entities": []}, {"text": "However, as they discuss in their paper and in previous research), frequency is a solid but not determining factor to the difficulty of a pattern, and surface syntactic structure is not sufficient to describe a grammatical phenomenon.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 8. Some of the patterns for the rules can be found in Tables 4, 5 and 6. The matcher  also returns the position of the head_word and the comp_word if applicable. As shown, the matches are  mostly correct for all three types of patterns, meaning that our query language and our patterns are robust  enough to describe and find the syntactic phenomena that we aimed to identify.", "labels": [], "entities": []}, {"text": " Table 8: Seven sentences from our test set, their ideal matches and the matches that the algorithm re- turned. Rules that were incorrectly matched/not matched are marked in bold.", "labels": [], "entities": []}, {"text": " Table 9: Matcher results on the development  set with gold standard parses and parse results  from the parsers.", "labels": [], "entities": []}, {"text": " Table 10: Matcher results on the test set with  gold standard parses and parse results from the  parsers.", "labels": [], "entities": [{"text": "Matcher", "start_pos": 11, "end_pos": 18, "type": "METRIC", "confidence": 0.9305347800254822}]}]}