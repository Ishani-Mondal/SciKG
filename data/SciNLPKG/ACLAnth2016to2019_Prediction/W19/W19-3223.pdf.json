{"title": [{"text": "MIDAS@SMM4H-2019: Identifying Adverse Drug Reactions and Personal Health Experience Mentions from Twitter", "labels": [], "entities": [{"text": "MIDAS@SMM4H-2019", "start_pos": 0, "end_pos": 16, "type": "DATASET", "confidence": 0.5613756974538168}, {"text": "Identifying Adverse Drug Reactions", "start_pos": 18, "end_pos": 52, "type": "TASK", "confidence": 0.7867852598428726}]}], "abstractContent": [{"text": "In this paper, we present our approach and the system description for the Social Media Mining for Health Applications (SMM4H) Shared Task 1,2 and 4 (2019).", "labels": [], "entities": [{"text": "Social Media Mining for Health Applications (SMM4H) Shared Task 1,2", "start_pos": 74, "end_pos": 141, "type": "TASK", "confidence": 0.7076272492607435}]}, {"text": "Our main contribution is to show the effectiveness of Transfer Learning approaches like BERT and ULM-FiT, and how they generalize for the classification tasks like identification of adverse drug reaction mentions and reporting of personal health problems in tweets.", "labels": [], "entities": [{"text": "Transfer Learning", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.9160566329956055}, {"text": "BERT", "start_pos": 88, "end_pos": 92, "type": "METRIC", "confidence": 0.9956105351448059}, {"text": "identification of adverse drug reaction mentions", "start_pos": 164, "end_pos": 212, "type": "TASK", "confidence": 0.8586499790350596}]}, {"text": "We show the use of stacked embeddings combined with BLSTM+CRF tagger for identifying spans mentioning adverse drug reactions in tweets.", "labels": [], "entities": [{"text": "BLSTM", "start_pos": 52, "end_pos": 57, "type": "METRIC", "confidence": 0.9237474799156189}]}, {"text": "We also show that these approaches perform well even with imbalanced dataset in comparison to undersampling and oversampling.", "labels": [], "entities": []}], "introductionContent": [{"text": "Drugs administered for alleviating common sufferings are the fourth biggest cause of death in US, following cancer and heart diseases, making it one of the most important medical problems for the human society.", "labels": [], "entities": []}, {"text": "While heart diseases and cancer are commonly reported and studied, adverse reactions to drugs either goes unreported or is confused or lost within other narratives.", "labels": [], "entities": []}, {"text": "While it is the onus of the government and the society as a whole to tackle the first task, the second one is an overwhelmingly computational task.", "labels": [], "entities": []}, {"text": "With the advent of universal internet and smartphones, reportrage of incidents is generally increasing, thanks to a host of social media platforms like Twitter, Facebook, Instagram, etc.", "labels": [], "entities": [{"text": "reportrage of incidents", "start_pos": 55, "end_pos": 78, "type": "TASK", "confidence": 0.6383195519447327}]}, {"text": "Hence, this unique situation presents a challenging as well as rewarding opportunity to improve our current computational systems for dealing with the existing incidents more sensibly and increase their reportage with the use of electronic media.", "labels": [], "entities": []}, {"text": "With this motivation, four shared tasks were conducted as part of Social Media Mining for Health Applications (SMM4H).", "labels": [], "entities": [{"text": "Social Media Mining for Health Applications (SMM4H)", "start_pos": 66, "end_pos": 117, "type": "TASK", "confidence": 0.7002757920159234}]}, {"text": "Our team particpated in Tasks -1, 2 and 4 of the workshop.", "labels": [], "entities": []}, {"text": "The problems for these tasks were: Problem Definition Sub-task 1: Given a labeled dataset D of tweets, the objective of the task is to learn a classification/prediction function that can predict a label l fora given tweet t, where l \u2208 {reporting adverse effects of drugs (ADR) -1, no adverse effects of drugs (non-ADR) -0}.", "labels": [], "entities": []}, {"text": "Example of tweets mentioning adverse drug reactions: \u2022 I feel siiiiiiiiiiiiiiick.", "labels": [], "entities": []}, {"text": "\u2022 Who need alcohol when you have gabapentin and tramadol that makes you feel drunk at 12oclock.", "labels": [], "entities": []}, {"text": "Problem Definition Sub-task 2: The motive of this sub-task is to first discern ADR tweets from the non-ADR ones and then identify the span of a tweet where an adverse drug effect is reported.", "labels": [], "entities": []}, {"text": "An example of a span from a tweet that represents the mention of adverse drug reactions: \u2022 losing it. could not remember the word power strip.", "labels": [], "entities": []}, {"text": "wonder which drug is doing this memory lapse thing.", "labels": [], "entities": []}, {"text": "#helps, where not remember is the adverse drug reaction that needs to be identified and extracted from the tweet, which is most likely caused by the intake of the drug named cymbalta.", "labels": [], "entities": []}, {"text": "Problem Definition Sub-task 4: Given a labeled dataset D of tweets, the objective of the task is to learn a classification/prediction function that can predict a label l fora given tweet t, where l \u2208 {reporting personal health experience -1, no mention of personal health experience -0}.", "labels": [], "entities": []}, {"text": "Example of tweets reporting personal health experience mentions: \u2022 This flu shot got my arm killing me.", "labels": [], "entities": []}, {"text": "\u2022 man i am so sick i feel terrible i got all the symptoms of the swine flu i am scared.", "labels": [], "entities": []}, {"text": "Our Contributions: Towards the objectives of the tasks as described above, we present some of our contributions in this paper: 1.", "labels": [], "entities": []}, {"text": "We train ULMFit and BERT models for Tasks 1 and 4, and show that these models are agnostic to the effects of undersampling and oversampling, given a highly imbalanced dataset.", "labels": [], "entities": [{"text": "BERT", "start_pos": 20, "end_pos": 24, "type": "METRIC", "confidence": 0.9958305954933167}]}, {"text": "2. We make an initial attempt in studying the effectiveness of transfer learning using ULMFit and BERT for the problems in the domain of healthcare pertaining to the shared tasks.", "labels": [], "entities": [{"text": "BERT", "start_pos": 98, "end_pos": 102, "type": "METRIC", "confidence": 0.9965566396713257}]}, {"text": "3. We show the use of stacked embeddings combined with BLSTM+CRF tagger for identifying spans mentioning adverse drug reactions in tweets.", "labels": [], "entities": [{"text": "BLSTM+CRF tagger", "start_pos": 55, "end_pos": 71, "type": "METRIC", "confidence": 0.8871107697486877}]}, {"text": "4. We also show the use of combining pretrained BERT embeddings with Glove embeddings fed to a BLSTM text classifier for sub-task-1 and sub-task-4.", "labels": [], "entities": []}], "datasetContent": [{"text": "The dataset for the shared tasks was collected from the social networking website, Twitter.", "labels": [], "entities": []}, {"text": "It consists of mentions of drug effects and other health related issues.", "labels": [], "entities": []}, {"text": "1. For the shared task 1, a total of 25,672 tweets are made available for training, out of which 2,374 contain adverse drug reaction (ADR) mention and the rest (23,298) do not.", "labels": [], "entities": []}, {"text": "Only training data was provided by the organizers.", "labels": [], "entities": []}, {"text": "For performing our experiments we segmented the provided dataset into train and validation splits.", "labels": [], "entities": []}, {"text": "shows the distribution of data in the training and validation splits.", "labels": [], "entities": []}, {"text": "The evaluation metric for this task was the F-score for the ADR class.", "labels": [], "entities": [{"text": "F-score", "start_pos": 44, "end_pos": 51, "type": "METRIC", "confidence": 0.998813271522522}]}, {"text": "Due to appreciable data bias, for the various experiments for this subtask, we oversample ADR tweets and undersample non-ADR tweets.", "labels": [], "entities": []}, {"text": "For oversampling, we just copy the ADR tweets and for undersampling, we randomly select a set of tweets such that the total number of tweets in both the sets becomes equal.", "labels": [], "entities": []}, {"text": "For instance \"feeling a little dizzy from the quetiapine i just popped!\" represents a positive sample from the dataset while \"don't say no to pills!", "labels": [], "entities": []}, {"text": "latuda won't kill!\" is a non-ADR tweet.", "labels": [], "entities": []}, {"text": "We also try imbalanced proportions such as from 1:2 to 1:10 as well.", "labels": [], "entities": []}, {"text": "2. For the shared task 2, we got a total of 2,367 tweets out of which 1,212 were positive and 1,155 were negative.", "labels": [], "entities": []}, {"text": "In the positive samples, the ADR portion was marked.", "labels": [], "entities": [{"text": "ADR", "start_pos": 29, "end_pos": 32, "type": "METRIC", "confidence": 0.8712615966796875}]}, {"text": "For instance, the tweet \"friends!", "labels": [], "entities": []}, {"text": "(antibiotic) complications??", "labels": [], "entities": []}, {"text": "big side effect is tendon rupture...figured my dr would know better?\" is an ADR tweet and the portion \"tendon rupture\" is where the author of the tweet mentions about ADR.", "labels": [], "entities": []}, {"text": "3. For the shared task 4, we were given a total of 10,876 tweets out of which only 7,388( 67.9%) of the tweets were available on twitter for downloading.", "labels": [], "entities": []}, {"text": "A total of 3,598 were positive and the rest were negative in original data.", "labels": [], "entities": []}, {"text": "The positive tweets in this case contained a personal mention of ones health (for example, sharing health status or opinion) whereas negative samples contained a generic discussion of the health issue, or some unrelated mention of the word.", "labels": [], "entities": []}, {"text": "For instance, 9,832 is an example of tweet which contains flu-vaccination context in original data.", "labels": [], "entities": []}, {"text": "Similarly, in the tweet 1,046, the author tries to discuss disease context of flu.", "labels": [], "entities": []}, {"text": "For the available data we had 2,426 positive combined and 4,962 negative samples where the author is initiating general health discussion as opposed to mentioning any particular context of flu.", "labels": [], "entities": []}, {"text": "For performing our experiments we segmented the provided dataset into train and validation splits.", "labels": [], "entities": []}, {"text": "shows the distribution of data in the training and validation splits.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results for Task-1: Identifying Tweets Men- tioning Adverse Drug Reactions", "labels": [], "entities": [{"text": "Identifying Tweets Men- tioning Adverse Drug Reactions", "start_pos": 30, "end_pos": 84, "type": "TASK", "confidence": 0.9156493917107582}]}, {"text": " Table 3: Results for Task-2: Extracting spans of text  expressing adverse drug reactions in Tweets", "labels": [], "entities": [{"text": "Extracting spans of text  expressing adverse drug reactions in Tweets", "start_pos": 30, "end_pos": 99, "type": "TASK", "confidence": 0.8275965332984925}]}, {"text": " Table 4: Results for Task-4: Generalized identification  of personal health experience mentions", "labels": [], "entities": [{"text": "Generalized identification  of personal health experience", "start_pos": 30, "end_pos": 87, "type": "TASK", "confidence": 0.8737472295761108}]}]}