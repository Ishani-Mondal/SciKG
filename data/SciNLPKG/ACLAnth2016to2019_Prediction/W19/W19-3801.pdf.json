{"title": [], "abstractContent": [{"text": "The 1st ACL workshop on Gender Bias in Natural Language Processing included a shared task on gendered ambiguous pronoun (GAP) resolution.", "labels": [], "entities": [{"text": "ACL workshop on Gender Bias in Natural Language Processing", "start_pos": 8, "end_pos": 66, "type": "TASK", "confidence": 0.6841627028253343}, {"text": "gendered ambiguous pronoun (GAP) resolution", "start_pos": 93, "end_pos": 136, "type": "TASK", "confidence": 0.685321501323155}]}, {"text": "This task was based on the coref-erence challenge defined in Webster et al.", "labels": [], "entities": []}, {"text": "(2018), designed to benchmark the ability of systems to resolve pronouns in real-world contexts in a gender-fair way.", "labels": [], "entities": []}, {"text": "263 teams competed via a Kaggle competition, with the winning system achieving logloss of 0.13667 and near gender parity.", "labels": [], "entities": []}, {"text": "We review the approaches of eleven systems with accepted description papers, noting their effective use of BERT (De-vlin et al., 2019), both via fine-tuning and for feature extraction, as well as ensembling.", "labels": [], "entities": [{"text": "BERT", "start_pos": 107, "end_pos": 111, "type": "METRIC", "confidence": 0.9981254935264587}, {"text": "feature extraction", "start_pos": 165, "end_pos": 183, "type": "TASK", "confidence": 0.737327516078949}]}], "introductionContent": [{"text": "Gender bias is one of the typologies of social bias (e.g. race, politics) that is alarming the Natural Language Processing (NLP) community.", "labels": [], "entities": []}, {"text": "An illustration of the problematic behaviour are the recurrently appearing occupational stereotypes that homemaker is to woman as programmer is to man.", "labels": [], "entities": []}, {"text": "Recent studies have aimed to detect, analyse and mitigate gender bias in different NLP tools and applications including word embeddings (, coreference resolution (, sentiment analysis and machine translation (Vanmassenhove et al.,.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 139, "end_pos": 161, "type": "TASK", "confidence": 0.9423344731330872}, {"text": "sentiment analysis", "start_pos": 165, "end_pos": 183, "type": "TASK", "confidence": 0.9134704172611237}, {"text": "machine translation", "start_pos": 188, "end_pos": 207, "type": "TASK", "confidence": 0.8189429640769958}]}, {"text": "One of the main sources of gender bias is believed to be societal artefacts in the data from which our algorithms learn.", "labels": [], "entities": []}, {"text": "To address this, many have created gender-labelled and gender-balanced datasets.", "labels": [], "entities": []}, {"text": "We present the results of a shared task evaluation conducted at the 1st Workshop on Gender Bias in Natural Language Processing at the ACL 2019 conference.", "labels": [], "entities": [{"text": "Gender Bias in Natural Language Processing at the ACL 2019 conference", "start_pos": 84, "end_pos": 153, "type": "TASK", "confidence": 0.7275594906373457}]}, {"text": "The shared task is based on the gender-balanced GAP coreference dataset and allows us to test the hypothesis that fair datasets would be enough to solve the gender bias challenge in NLP.", "labels": [], "entities": [{"text": "GAP coreference dataset", "start_pos": 48, "end_pos": 71, "type": "DATASET", "confidence": 0.663454939921697}]}, {"text": "The strong results of submitted systems tend to support this hypothesis and gives the community a great starting point for mitigating bias in models.", "labels": [], "entities": []}, {"text": "Indeed, the enthusiastic participation we saw for this shared task has yielded systems which achieve near-human accuracy while achieving near gender-parity at 0.99, measured by the ratio between F1 scores on feminine and masculine examples.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.9979088306427002}, {"text": "F1", "start_pos": 195, "end_pos": 197, "type": "METRIC", "confidence": 0.9988289475440979}]}, {"text": "We are excited for future work extending this success to more languages, domains, and tasks.", "labels": [], "entities": []}, {"text": "However, we especially note future work in algorithms which achieve fair outcomes given biased data, given the wealth of information from existing unbalanced datasets.", "labels": [], "entities": []}], "datasetContent": [{"text": "The original GAP work defined two official evaluation metrics, F1 score and Bias, the ratio between the F1 scores on feminine and masculine examples.", "labels": [], "entities": [{"text": "GAP work", "start_pos": 13, "end_pos": 21, "type": "DATASET", "confidence": 0.7797803580760956}, {"text": "F1 score", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9865893721580505}, {"text": "Bias", "start_pos": 76, "end_pos": 80, "type": "METRIC", "confidence": 0.9980785846710205}, {"text": "F1", "start_pos": 104, "end_pos": 106, "type": "METRIC", "confidence": 0.9917632341384888}]}, {"text": "Bias takes a value of 1 at gender parity; a value below 1 indicates that masculine entities are resolved more accurately than feminine ones.", "labels": [], "entities": [{"text": "Bias", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.8195188641548157}]}, {"text": "In contrast, the official evaluation metric of the competition was the logloss of the submitted probability estimates: where N is the number of samples in the test set, M = 3 is the number of classes to be predicted, y i j is 1 if observation i belongs to class j according to the gold-standard annotations and 0 otherwise, and pi j is the probability estimated by the system that observation i belongs to class j. tabulates results based on the original and shared task metrics.", "labels": [], "entities": []}, {"text": "Logloss and GAP F1 both place the winners in the same order.", "labels": [], "entities": [{"text": "Logloss", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9790751338005066}, {"text": "GAP", "start_pos": 12, "end_pos": 15, "type": "DATASET", "confidence": 0.8491882085800171}, {"text": "F1", "start_pos": 16, "end_pos": 18, "type": "METRIC", "confidence": 0.5406530499458313}]}], "tableCaptions": [{"text": " Table 1: Performance of prize-winning submissions on  the blind Kaggle evaluation set. logloss was the official  task metric, and correlates well with F1 score, which  was used in the original GAP work.", "labels": [], "entities": [{"text": "Kaggle evaluation set", "start_pos": 65, "end_pos": 86, "type": "DATASET", "confidence": 0.8198465903600057}, {"text": "F1 score", "start_pos": 152, "end_pos": 160, "type": "METRIC", "confidence": 0.9922548830509186}]}, {"text": " Table 2: Teams with accepted system description papers. *Note the two teams placing 5 and 22 submitted a  combined system description paper.", "labels": [], "entities": []}, {"text": " Table 3: Highlights of systems with accepted description papers. *Note the two teams placing 5 and 22 submitted  a combined system description paper.", "labels": [], "entities": []}]}