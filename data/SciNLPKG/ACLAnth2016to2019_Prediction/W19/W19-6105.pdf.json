{"title": [{"text": "A larger-scale evaluation resource of terms and their shift direction for diachronic lexical semantics", "labels": [], "entities": [{"text": "diachronic lexical semantics", "start_pos": 74, "end_pos": 102, "type": "TASK", "confidence": 0.6896752516428629}]}], "abstractContent": [{"text": "Determining how words have changed their meaning is an important topic in Natural Language Processing.", "labels": [], "entities": [{"text": "Determining how words have changed their meaning", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.7908151575497219}, {"text": "Natural Language Processing", "start_pos": 74, "end_pos": 101, "type": "TASK", "confidence": 0.6587222417195638}]}, {"text": "However, evaluations of methods to characterise such change have been limited to small, hand-crafted resources.", "labels": [], "entities": []}, {"text": "We introduce an En-glish evaluation set which is larger, more varied, and more realistic than seen to date, with terms derived from a historical thesaurus.", "labels": [], "entities": []}, {"text": "Moreover, the dataset is unique in that it represents change as a shift from the term of interest to a WordNet synset.", "labels": [], "entities": []}, {"text": "Using the synset lemmas, we can use this set to evaluate (standard) methods that detect change between word pairs, as well as (adapted) methods that detect the change between a term and a sense overall.", "labels": [], "entities": []}, {"text": "We show that performance on the new data set is much lower than earlier reported findings , setting anew standard.", "labels": [], "entities": []}], "introductionContent": [{"text": "Determining how words have changed their meaning is an important topic in Natural Language Processing.", "labels": [], "entities": [{"text": "Determining how words have changed their meaning", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.7908151575497219}, {"text": "Natural Language Processing", "start_pos": 74, "end_pos": 101, "type": "TASK", "confidence": 0.6587222417195638}]}, {"text": "Using large diachronic corpora, computational linguistics has provided methods that can detector qualitatively explain semantic change automatically.", "labels": [], "entities": []}, {"text": "In particular, several approaches have been introduced that use distributional semantic models representing different time periods in diachronic corpora (, e.g.).", "labels": [], "entities": []}, {"text": "Researchers have illustrated through compelling examples that these methods can detect semantic shift, like cell obtaining the meaning of 'phone' and gay shifting from 'cheerful' to 'homosexual', e.g.) and have reported high accuracy on small evaluation sets of selected examples.", "labels": [], "entities": [{"text": "cell obtaining the meaning of 'phone'", "start_pos": 108, "end_pos": 145, "type": "TASK", "confidence": 0.7477146871387959}, {"text": "accuracy", "start_pos": 225, "end_pos": 233, "type": "METRIC", "confidence": 0.9989922642707825}]}, {"text": "even report 100% accuracy in detecting known change on 28 word pairs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9996125102043152}]}, {"text": "As a result, these approaches have been enthusiastically adopted (, e.g.).", "labels": [], "entities": []}, {"text": "However, it has been called into question how reliable these methods really are.", "labels": [], "entities": []}, {"text": "These developments show that there is both a wide interest in using distributional semantic models to assess semantic change and an urgent need for better insight into the possibilities and limitations of these methods.", "labels": [], "entities": []}, {"text": "It is therefore unsurprising that three recent survey papers on the topic all list the lack of proper evaluation and, in particular, the absence of large-scale evaluation sets, as a key challenge for this line of research.", "labels": [], "entities": []}, {"text": "In this paper, we automatically derive HiT, the largest English evaluation set to date, from a historical thesaurus.", "labels": [], "entities": [{"text": "HiT", "start_pos": 39, "end_pos": 42, "type": "DATASET", "confidence": 0.8284823298454285}]}, {"text": "HiT consists of terms linked to WordNet entries that represent senses they gained or lost.", "labels": [], "entities": []}, {"text": "We introduce sense shift assessment as a task, enabled by this dataset, that identifies whether a sense of a term of interest was coming in our out of use, based on its changed relationship with all lemmas of the sense.", "labels": [], "entities": [{"text": "sense shift assessment", "start_pos": 13, "end_pos": 35, "type": "TASK", "confidence": 0.7784615953763326}]}, {"text": "This is a variation of a task introduced by that assesses the relationship of the terms of interest with individual other terms.", "labels": [], "entities": []}, {"text": "The sense shift assessment instead uncovers the conceptual change that explains multiple observed trends between word pairs.", "labels": [], "entities": []}, {"text": "Cross-checking and summarising individual observations also means drawing more informed conclusions.", "labels": [], "entities": [{"text": "summarising individual observations", "start_pos": 19, "end_pos": 54, "type": "TASK", "confidence": 0.8510944644610087}]}, {"text": "Furthermore, the use of WordNet sense representations allows for the dataset entries to be automatically derived rather than manually (expert) collected, hence limiting the effect of bias.", "labels": [], "entities": []}, {"text": "We use HiT to answer two main research questions.", "labels": [], "entities": []}, {"text": "First, how well can current methods detect sense shift on a larger and more varied evaluation set?", "labels": [], "entities": []}, {"text": "Second, how, by taking a full synset as a representation of meaning, does the task of detecting sense shift compare to studying word pairs in isolation?", "labels": [], "entities": [{"text": "detecting sense shift", "start_pos": 86, "end_pos": 107, "type": "TASK", "confidence": 0.7758429050445557}]}, {"text": "The main contributions of this paper are as follows.", "labels": [], "entities": []}, {"text": "First, the new evaluation set, consisting of 756 target words and 3624 word pairs.", "labels": [], "entities": []}, {"text": "Second, we show that current methods perform quite poorly on this more challenging set, thus confirming that this set introduces anew benchmark.", "labels": [], "entities": []}, {"text": "We also identify lexical factors that contribute to these differences.", "labels": [], "entities": []}], "datasetContent": [{"text": "The thesaurus-derived dataset, HiT, qualitatively differs from existing evaluation sets in its automated construction and in its representation of senses by a synset rather than selected terms.", "labels": [], "entities": []}, {"text": "In order to compare this set to previously used datasets, we adapt two standard evaluation sets semi-automatically to link the target words they contain to synsets representing the given old or new senses.", "labels": [], "entities": []}, {"text": "HistWords (Hamilton et al., 2016) (HW) contains 28 word pairs that saw their similarity increase or decrease overtime, based on 9 target terms.", "labels": [], "entities": [{"text": "HistWords (Hamilton et al., 2016) (HW)", "start_pos": 0, "end_pos": 38, "type": "DATASET", "confidence": 0.915284660729495}]}, {"text": "HistWords states the onset of the changeno end date -and the gold standard shift direction.", "labels": [], "entities": [{"text": "HistWords", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.926423966884613}]}, {"text": "For instance, since 1800, awful has moved towards mess and disgusting and away from impressive.", "labels": [], "entities": []}, {"text": "The Word Sense Change Testset (WSCT) ( lists terms that acquired anew sense and unchanged control words.", "labels": [], "entities": [{"text": "Word Sense Change Testset (WSCT)", "start_pos": 4, "end_pos": 36, "type": "DATASET", "confidence": 0.7083316487925393}]}, {"text": "It gives the type of change the term underwent (no change, new, broader, or narrower sense), a short explanation of the change and the onset date of the change.", "labels": [], "entities": []}, {"text": "For instance, memory acquires anew related sense 'digital memory' in 1960 whilst keeping its existing sense 'human memory'.", "labels": [], "entities": []}, {"text": "From HW to HW+ and from WSCT to WSCT+.", "labels": [], "entities": [{"text": "HW", "start_pos": 5, "end_pos": 7, "type": "DATASET", "confidence": 0.9457746744155884}, {"text": "WSCT", "start_pos": 24, "end_pos": 28, "type": "DATASET", "confidence": 0.9358676075935364}, {"text": "WSCT+", "start_pos": 32, "end_pos": 37, "type": "DATASET", "confidence": 0.8432168960571289}]}, {"text": "Every entry from WSCT and HW is treated as a separate change event, with an onset date and a description; some target terms have more than one change event.", "labels": [], "entities": [{"text": "WSCT", "start_pos": 17, "end_pos": 21, "type": "DATASET", "confidence": 0.8264436721801758}, {"text": "HW", "start_pos": 26, "end_pos": 28, "type": "DATASET", "confidence": 0.5651625990867615}]}, {"text": "For each such event, the affected sense(s) are selected out of all candidate senses, i.e. all WordNet synsets that correspond to the target lemma (in the correct part of speech).", "labels": [], "entities": []}, {"text": "This synset selection process happened manually, by comparing the lexical information in WordNet against the change description in the source data.", "labels": [], "entities": [{"text": "synset selection", "start_pos": 5, "end_pos": 21, "type": "TASK", "confidence": 0.7913609445095062}, {"text": "WordNet", "start_pos": 89, "end_pos": 96, "type": "DATASET", "confidence": 0.9735448956489563}]}, {"text": "More details about the annotation process are given below.", "labels": [], "entities": []}, {"text": "The outcomes determine the change type listed for the combination of target term and synset in the enriched datasets WSCT+ and HW+.", "labels": [], "entities": [{"text": "WSCT", "start_pos": 117, "end_pos": 121, "type": "DATASET", "confidence": 0.7350934147834778}]}, {"text": "The target term is thought to move towards any synset (and towards all terms of the synset) that captures an increasingly commonsense, and away from any synset that expresses an increasingly uncommon sense.", "labels": [], "entities": []}, {"text": "For any synset that does not capture any described change, its relation to the target term is described as unchanged or unknown.", "labels": [], "entities": []}, {"text": "The selection was carried out by the first author; this was then evaluated by two co-authors for HW+ and one co-author for WSCT+.", "labels": [], "entities": [{"text": "HW+", "start_pos": 97, "end_pos": 100, "type": "DATASET", "confidence": 0.899450421333313}, {"text": "WSCT+", "start_pos": 123, "end_pos": 128, "type": "DATASET", "confidence": 0.8783172369003296}]}, {"text": "In the case of three raters, we used Fleiss' extension of Cohen's method.", "labels": [], "entities": []}, {"text": "The raters judged the shift direction of the target term with respect to all candidate concepts (synsets): towards (+1), away from (-1) one another, or no change (0).", "labels": [], "entities": []}, {"text": "The evaluation set of word-sense combinations was larger than the final dataset, as it included synsets with just the target term.", "labels": [], "entities": []}, {"text": "The raters were given the following data: the change description and the time of change, given in HW or WSCT; the (given or inferred) part of speech; the candidate WordNet concept that connects the two terms; and corresponding WordNet data such as the definition and the set of terms in the synset.", "labels": [], "entities": [{"text": "HW or WSCT", "start_pos": 98, "end_pos": 108, "type": "DATASET", "confidence": 0.6693550149599711}]}, {"text": "For WSCT+ (N=129 target-sense pairs), the two raters agreed by 88.4 percent, which, chance-normalised (Cohen's \u03ba = 0.63, z = 7.26, p < 0.01) is thought to be 'substantial'.", "labels": [], "entities": [{"text": "WSCT", "start_pos": 4, "end_pos": 8, "type": "TASK", "confidence": 0.4501030445098877}]}, {"text": "The raters then agreed on the final set of gold standard labels.", "labels": [], "entities": []}, {"text": "On HW+ (N=70 target-sense pairs), the three raters agreed almost perfectly (Fleiss' \u03ba = 0.83, z = 16, p < 0.01), and the ratings by the first author were taken as the gold standard.", "labels": [], "entities": []}, {"text": "Resulting datasets The evaluation sets all provide two types of pairings: target terms paired with reference terms and target terms with synsets.", "labels": [], "entities": []}, {"text": "The gold standard for the individual word pairstarget word and synonym -corresponds to the gold standard for the whole synset.", "labels": [], "entities": []}, {"text": "After the inter-rater evaluation, synsets with just one term (the target target POS sense (WN synset) t shift term reference term memory n. memory.n.03 1960 0 retention, retentiveness, retentivity memory n. memory.n.04 1960 1 computer memory, storage, computer storage, store, memory board: Excerpts from two entries of WSCT+.", "labels": [], "entities": [{"text": "retention", "start_pos": 159, "end_pos": 168, "type": "METRIC", "confidence": 0.9058929085731506}]}, {"text": "Shift label 0 means we have no evidence the word changed with respect to the given sense.", "labels": [], "entities": []}, {"text": "Label 1 means a shift towards the indicated meaning (and its associated terms).", "labels": [], "entities": []}, {"text": "term) were omitted, as the experiment requires reference terms.", "labels": [], "entities": []}, {"text": "Two tasks are addressed in the experiment.", "labels": [], "entities": []}, {"text": "Word shift assessment (WordShiftAssess) () is summarised as follows: given a target term, a reference term, and a time period, did the two terms become closer in meaning (gold standard label 1) or did their meanings move apart (label -1)?", "labels": [], "entities": []}, {"text": "Sense shift assessment (SenseShiftAssess) goes as follows: given a target term, a WordNet synset, and a time period, did the target term in the given period move towards or away from the given sense?", "labels": [], "entities": []}, {"text": "To be comparable to previous findings, we evaluate the datasets on both tasks.", "labels": [], "entities": []}, {"text": "This section outlines the methods and the experimental setup.", "labels": [], "entities": []}, {"text": "We apply word shift assessment on HW, HW+, WSCT+, and HiT.", "labels": [], "entities": [{"text": "word shift assessment", "start_pos": 9, "end_pos": 30, "type": "TASK", "confidence": 0.6735467910766602}, {"text": "HW", "start_pos": 34, "end_pos": 36, "type": "DATASET", "confidence": 0.9142717719078064}, {"text": "HiT", "start_pos": 54, "end_pos": 57, "type": "DATASET", "confidence": 0.8987208008766174}]}, {"text": "The reference terms of HW+, WSCT+ and HiT come from WordNet; those in HW are readily taken from the source.", "labels": [], "entities": [{"text": "HiT", "start_pos": 38, "end_pos": 41, "type": "DATASET", "confidence": 0.7607702612876892}, {"text": "WordNet", "start_pos": 52, "end_pos": 59, "type": "DATASET", "confidence": 0.9751256108283997}]}, {"text": "illustrates how the term awful from HW+ compares with its individual WordNet synonyms overtime.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 69, "end_pos": 76, "type": "DATASET", "confidence": 0.9208742380142212}]}, {"text": "Sense shift assessment is applied to WSCT+, HW+ and HiT, i.e. all sets that could be enriched with sense information.", "labels": [], "entities": [{"text": "Sense shift assessment", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7544797360897064}, {"text": "HiT", "start_pos": 52, "end_pos": 55, "type": "DATASET", "confidence": 0.8515934944152832}]}, {"text": "To continue with the example in, sense shift assessment translates the word-based observations into a single as- sessment of the changed relation of awful with respect to the whole synset.", "labels": [], "entities": []}, {"text": "We use word embeddings provided by of size 300, trained through skip-gram with negative sampling (SGNS) for every decade separately on three corpora: the Corpus of Historical American English (Davies, 2015) (COHA), the complete English Google N-Gram corpus, and the English Fiction corpus, a subset of the Google N-Gram corpus.", "labels": [], "entities": [{"text": "Corpus of Historical American English (Davies, 2015) (COHA)", "start_pos": 154, "end_pos": 213, "type": "DATASET", "confidence": 0.5752590184028332}, {"text": "Google N-Gram corpus", "start_pos": 236, "end_pos": 256, "type": "DATASET", "confidence": 0.6357850929101309}, {"text": "English Fiction corpus", "start_pos": 266, "end_pos": 288, "type": "DATASET", "confidence": 0.6315499742825826}, {"text": "Google N-Gram corpus", "start_pos": 306, "end_pos": 326, "type": "DATASET", "confidence": 0.7149851520856222}]}, {"text": "The embeddings are not (part of speech) disambiguated, and can stand for several lemmas at once.", "labels": [], "entities": []}, {"text": "We employ the embeddings for every decade from the attested onset of change up to and including the last available embedding, trained on the 1990s subcorpus.", "labels": [], "entities": []}, {"text": "Handling of missing and infrequent data.", "labels": [], "entities": []}, {"text": "Some terms appear infrequently in some slices of the corpus.", "labels": [], "entities": []}, {"text": "The code that accompanies Hamilton et al.", "labels": [], "entities": []}, {"text": "(2016) deals with these cases by padding the cosine time series with a zero for the dimension (i.e. time slice) in which either or both of the terms was insufficiently frequent (under 500 times, except for COHA).", "labels": [], "entities": []}, {"text": "However, this biases the outcome, since zero is the smallest cosine similarity value.", "labels": [], "entities": []}, {"text": "Given that low word frequencies are more common in the corpora of the first few decades, this setting makes it more likely to find: Similarity values based on infrequent data must not be padded with zero as this biases the correlation value towards a positive value.", "labels": [], "entities": []}, {"text": "In the word pair delimit-define, padding the values for decades t1 (in fact, 1850) through to t11 (1940) with zeros would lead to a conclusion opposite to the ground truth stating that these terms move away from each other; hence these observations are treated as missing data (NA) instead.", "labels": [], "entities": []}, {"text": "a rising trend in cosine similarities.", "labels": [], "entities": []}, {"text": "As this is an unwanted effect, we treated cosine values based on low-frequency numbers as missing values.", "labels": [], "entities": []}, {"text": "Table 4 illustrates the difference between the caveat explained here and the approach taken.", "labels": [], "entities": []}, {"text": "A further count filter ensures that all results (correlations) are based on at least five cosine values.", "labels": [], "entities": []}, {"text": "shows the proportion of word pair observations (WordShiftAssess) displaying the expected trend in cosine similarities for every dataset and training corpus.", "labels": [], "entities": [{"text": "WordShiftAssess", "start_pos": 48, "end_pos": 63, "type": "DATASET", "confidence": 0.8828902840614319}]}, {"text": "The significance reported is the proportion of correct findings (i.e. with an upper limit of 100%) with a Spearman \u03c1 significant on the 0.05 level.", "labels": [], "entities": [{"text": "Spearman \u03c1 significant", "start_pos": 106, "end_pos": 128, "type": "METRIC", "confidence": 0.980878750483195}]}, {"text": "Whether the correlation coefficient is significant depends on its magnitude as well as the number of cosine values considered.", "labels": [], "entities": [{"text": "correlation coefficient", "start_pos": 12, "end_pos": 35, "type": "METRIC", "confidence": 0.9763683378696442}]}, {"text": "The latter in turn depends on the change onset -the longer the time series, the more observations -minus observations that were based on too little data and were left out (see Section 4.3).", "labels": [], "entities": []}, {"text": "N expresses how many of the word pair entries from the datasets which displayed areal shift (unchanged words were not used) resulted in a cosine time series of at least five observations (see Section 4.3).", "labels": [], "entities": []}, {"text": "This depends in part on the corpus, some of which have much greater coverage than other ones, particularly the complete English corpus, eng-all.", "labels": [], "entities": [{"text": "complete English corpus", "start_pos": 111, "end_pos": 134, "type": "DATASET", "confidence": 0.634988933801651}]}, {"text": "For instance, the results for HiT for eng-all are based on 1461 word pairs as opposed to a mere 746 for COHA and 772 for English fiction, out of a dataset total of 3624 shifted terms.", "labels": [], "entities": []}, {"text": "Moreover, eng-all resulted in more statistically significant correct outcomes than COHA and eng-fic.", "labels": [], "entities": []}, {"text": "We therefore focus on the results based on eng-all in particular.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Example excerpt from an entry of HiT. Shift label", "labels": [], "entities": [{"text": "HiT", "start_pos": 43, "end_pos": 46, "type": "DATASET", "confidence": 0.8820918798446655}]}, {"text": " Table 2: Excerpts from two entries of WSCT+. Shift label 0", "labels": [], "entities": [{"text": "WSCT+", "start_pos": 39, "end_pos": 44, "type": "DATASET", "confidence": 0.8128335177898407}]}, {"text": " Table 3: Contents of the evaluation sets, which come in two", "labels": [], "entities": []}, {"text": " Table 4: Similarity values based on infrequent data must", "labels": [], "entities": []}, {"text": " Table 5: Results of determining the shift direction of a target word with respect to a reference word (WordShiftAssess).", "labels": [], "entities": [{"text": "WordShiftAssess", "start_pos": 104, "end_pos": 119, "type": "DATASET", "confidence": 0.9130100011825562}]}, {"text": " Table 6: Results of determining the shift direction of a target word with respect to a reference word (SenseShiftAssess).", "labels": [], "entities": []}, {"text": " Table 7: WordShiftEval results broken down by the frequency, centrality, and polysemy of the terms that make up the entries.", "labels": [], "entities": []}]}