{"title": [{"text": "Influence of Time and Risk on Response Acceptability in a Simple Spoken Dialogue System", "labels": [], "entities": []}], "abstractContent": [{"text": "We describe a longitudinal user study conducted in the context of a Spoken Dialogue System fora household robot, where we examined the influence of time displacement and situational risk on users' preferred responses.", "labels": [], "entities": []}, {"text": "To this effect, we employed a corpus of spoken requests that asked a robot to fetch or move objects in a room.", "labels": [], "entities": []}, {"text": "In the first stage of our study, participants selected among four response types to these requests under two risk conditions: low and high.", "labels": [], "entities": []}, {"text": "After sometime, the same participants rated several responses to the previous requests-these responses were instantiated from the four response types.", "labels": [], "entities": []}, {"text": "Our results show that participants did not rate highly their own response types; moreover, they rated their own response types similarly to different ones.", "labels": [], "entities": []}, {"text": "This suggests that, at least in this context, people's preferences at a particular point in time may not reflect their general attitudes, and that various reasonable response types maybe equally acceptable.", "labels": [], "entities": []}, {"text": "Our study also reveals that situational risk influences the acceptability of some response types.", "labels": [], "entities": []}], "introductionContent": [{"text": "Spoken Dialogue Systems (SDSs) must often engage in follow-up interactions to deal with Automatic Speech Recognizer (ASR) errors or elucidate ambiguous or inaccurate requests (which are exacerbated by ASR errors): \u2022 ASR errors, although significantly reduced in recent times, 1 may produce wrong entities or actions, or ungrammatical utterances that cannot be processed by a Spoken Language Understanding (SLU) system (e.g., \"the plate inside the microwave\" being misheard as \"of plating sight the microwave\").", "labels": [], "entities": [{"text": "Automatic Speech Recognizer (ASR)", "start_pos": 88, "end_pos": 121, "type": "TASK", "confidence": 0.742094079653422}]}, {"text": "\u2022 People often express themselves ambiguously or inaccurately ().", "labels": [], "entities": []}, {"text": "An ambiguous reference to an object matches several objects well, while an inaccurate reference matches one or more objects partially.", "labels": [], "entities": []}, {"text": "For instance, a reference to a \"big blue mug\" is ambiguous if there is more than one big blue mug, and inaccurate if there are two mugs -one big and red, and one small and blue.", "labels": [], "entities": []}, {"text": "In the last two decades, research in response generation has focused on techniques that generate response policies that optimize dialogue completion, using Markov Decision Processes (MDPs), e.g.,, and Partially Observable MDPs (POMDPs), e.g.,.", "labels": [], "entities": [{"text": "response generation", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.9425058364868164}, {"text": "dialogue completion", "start_pos": 129, "end_pos": 148, "type": "TASK", "confidence": 0.7323538213968277}]}, {"text": "Recently, deep-learning algorithms have been used to generate dialogue responses on the basis of request-response pairs, e.g., ().", "labels": [], "entities": []}, {"text": "Human and simulation-based evaluations of MDP and POMDP systems focus on dialogue completion, while evaluations of deep-learning algorithms focus on individual responses.", "labels": [], "entities": [{"text": "dialogue completion", "start_pos": 73, "end_pos": 92, "type": "TASK", "confidence": 0.8627820014953613}]}, {"text": "In this paper, we draw inspiration from research in Recommender Systems, where and showed that overtime, users gave inconsistent ratings to items, leading to the \"magic barrier\" to prediction accuracy in Recommender Systems (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 192, "end_pos": 200, "type": "METRIC", "confidence": 0.8567476272583008}]}, {"text": "This prompted us to posit that people may also be inconsistent when assessing responses in a dialogue at different times, which may affect the results of human evaluations.", "labels": [], "entities": []}, {"text": "To investigate this claim, we conducted a longitudinal study in the context of an SDS fora household robot.", "labels": [], "entities": []}, {"text": "We first collected a corpus of spoken requests that asked a robot to fetch or move objects in a room.", "labels": [], "entities": []}, {"text": "Our participants were shown the top ASR outputs for these requests (the intention was to replicate the information available to an SDS, without the extra information people can glean from what they hear).", "labels": [], "entities": [{"text": "ASR", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.8781699538230896}]}, {"text": "They were also told that these requests had to be executed under two risk conditions: low risk, where the consequences of performing the wrong action are trivial, and high risk, where performing the wrong action could significantly inconvenience the speaker.", "labels": [], "entities": []}, {"text": "The participants had to choose among four response types: DO the request without further interaction, CONFIRM the intended object, ask the requester to CHOOSE between a few candidate objects, or ask the requester to REPHRASE all or part of the request.", "labels": [], "entities": [{"text": "DO", "start_pos": 58, "end_pos": 60, "type": "METRIC", "confidence": 0.9043290615081787}]}, {"text": "After 1.5-2 years, the same participants were shown the original requests and ASR outputs, and were asked to rate responses generated from their previously selected response types and from other sources, in particular response types selected by one of the authors and by a classifier trained on the author's chosen response types.", "labels": [], "entities": [{"text": "ASR outputs", "start_pos": 78, "end_pos": 89, "type": "TASK", "confidence": 0.8299878537654877}]}, {"text": "Our findings show that (1) participants downrated responses sourced from their previously chosen response types; and (2) these responses were liked as much as different responses sourced from the response types selected by one of the authors or by the above-mentioned classifier.", "labels": [], "entities": []}, {"text": "The first result indicates that, at least in the context of oneshot dialogues with an SDS fora household robot, people's preferred response types at a particular point in time may not reflect their general attitudes.", "labels": [], "entities": []}, {"text": "The second result suggests that, instead of one best response type, several reasonable response types maybe acceptable, including those selected by a classifier trained on a non-target but relevant corpus.", "labels": [], "entities": []}, {"text": "We also investigated the influence of situational risk on the acceptability of response types.", "labels": [], "entities": []}, {"text": "We found that (3) as expected, under the high-risk condition, the preferred response types were generally more conservative than under the low-risk condition; but (4) surprisingly, participants' attitudes toward certain response types, e.g., CONFIRM, were not affected by risk.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In the next section, we discuss related work.", "labels": [], "entities": []}, {"text": "Our experimental setup is described in Section 3.", "labels": [], "entities": []}, {"text": "In Section 4, we present our classifier and the features used to train it.", "labels": [], "entities": []}, {"text": "The results of our experiment are described in Section 5, and concluding remarks appear in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiment comprises two main stages: (1) responding to requests, and (2) rating responses to the same requests.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Response type distribution under high-and  low-risk conditions", "labels": [], "entities": []}, {"text": " Table 4: Per-class and overall classifier performance", "labels": [], "entities": []}]}