{"title": [{"text": "Weighted posets: Learning surface order from dependency trees", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents a novel algorithm for generating a surface word order fora sentence given its dependency tree using a two-stage process.", "labels": [], "entities": []}, {"text": "Using dependency-based word embeddings and a Graph Neural Network, the algorithm first learns how to rewrite a dependency tree as a partially ordered set (poset) with edge-weights representing dependency distance.", "labels": [], "entities": []}, {"text": "The subsequent topo-logical sort of this poset reflects a surface word order.", "labels": [], "entities": []}, {"text": "The algorithm is evaluated against a naive baseline of average dependency distances across 14 languages, performing well in terms of rank correlation and resulting rate of projectivity based on Universal Dependencies corpora.", "labels": [], "entities": []}], "introductionContent": [{"text": "Ina tradition dating at least back to, the words in a phrase or sentence can bethought of as a set of heads and dependents.", "labels": [], "entities": []}, {"text": "Each word save the root is a dependent of another word, its head, and heads and dependents exist in a one-to-many relationship.", "labels": [], "entities": []}, {"text": "This arrangement of heads and their dependents forms a tree, or more formally an unordered directed acyclic graph (DAG), in which words are nodes and edges are the dependency relations.", "labels": [], "entities": []}, {"text": "A sentence is one possible linearization or surface order of the DAG.", "labels": [], "entities": []}, {"text": "This paper describes a method for learning how to generate a valid 1 surface order from a dependency tree.", "labels": [], "entities": []}, {"text": "Determining the underlying dependency tree from a surface order is the rather extensively studied task of parsing; this paper concerns the opposite task.", "labels": [], "entities": [{"text": "parsing", "start_pos": 106, "end_pos": 113, "type": "TASK", "confidence": 0.9782842993736267}]}, {"text": "The key insight of the paper is that rather than learning to directly convert a dependency tree to surface order, the target is instead an edge-weighted partially ordered set (poset).", "labels": [], "entities": []}, {"text": "The poset's edge direction represents linear precedence in the surface order, while edge weight represents dependency distance, the number of words intervening between dependent and head in the surface order.", "labels": [], "entities": []}, {"text": "The topological sort or linear extension of this poset-performed such that nodes connected by edges with smaller weights are placed closest to each other-reflects the surface order of the dependency tree.", "labels": [], "entities": []}, {"text": "For example, shows (a) the dependency tree, (b) edge-weighted poset, and (c) surface order of the sentence Personally I recommend you take your money elsewhere.", "labels": [], "entities": []}, {"text": "Rather than attempting to learn how to convert (a) directly into (c), the approach outlined here rewrites (a) to (b) by learning edge directions and weights, then rewrites (b) to (c) via topological sort.", "labels": [], "entities": []}, {"text": "Given examples of dependency trees and their corpus-attested surface orders, a neural network can learn to convert previously unseen dependency trees into surface orders byway of a weighted poset.", "labels": [], "entities": []}, {"text": "Implemented as a Graph Neural Network, the machine-learning algorithm treats inputs, targets, and outputs as directed graphs.", "labels": [], "entities": []}, {"text": "Further, by representing words with their dependency-based embeddings-that is, embeddings trained on syntactic rather than linear contexts-the model generates a linearized surface order as the final step only, performing all other analysis within a graph framework.", "labels": [], "entities": []}, {"text": "In this way surface order is treated as an emergent consequence of topologically sorting an edge-weighted poset, the weights of which represent learned dependency distances.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the performance of the GNN algorithm compared to the AVG baseline in an automated way across various languages, we must unfortunately use a single target reference to compare the generated sentences.", "labels": [], "entities": [{"text": "AVG baseline", "start_pos": 65, "end_pos": 77, "type": "DATASET", "confidence": 0.8884535133838654}]}, {"text": "Thus the reference for each sentence is the attested version in the source UD corpus; the generated sentences from both AVG and GNN will be measured for similarity to the attested version.", "labels": [], "entities": [{"text": "UD corpus", "start_pos": 75, "end_pos": 84, "type": "DATASET", "confidence": 0.8546269536018372}]}, {"text": "The algorithm is attempting to order a set of words as closely as possible to their original surface realization in the corpus.", "labels": [], "entities": []}, {"text": "Because words may repeat in the sentence, each order is instead represented by a list of integers, and it is these lists of integers which are compared.", "labels": [], "entities": []}, {"text": "For example, assuming a target reference order of for the red horse, the generated order of red the horse would be.", "labels": [], "entities": []}, {"text": "An obvious way to quantify how similar these integer lists are is with the widely used Spearman's rank correlation coefficient, also known as Spearman's \u03c1 (rho), which non-parametrically measures the similarity of two rankings.", "labels": [], "entities": [{"text": "Spearman's rank correlation coefficient", "start_pos": 87, "end_pos": 126, "type": "METRIC", "confidence": 0.6301899731159211}, {"text": "Spearman's \u03c1 (rho)", "start_pos": 142, "end_pos": 160, "type": "METRIC", "confidence": 0.7338718771934509}]}, {"text": "It ranges from -1, indicating that one order is the reverse of the other, to 1, for perfect correlation.", "labels": [], "entities": []}, {"text": "The example of [2,1,3] returns a \u03c1 of 0.5, since in the second order 1 and 2 both precede 3, but 1 does not precede 2.", "labels": [], "entities": []}, {"text": "This measure tells us which approach, AVG or GNN, generates orders closest to the attested UD order, as well as a loose gauge of overall effectiveness for both the general approach as well as each algorithm.", "labels": [], "entities": []}, {"text": "Further, to address the question of projectivity, the percentage of projective dependency arcs generated by the AVG baseline, the GNN algorithm, and the attested sentences is evaluated.", "labels": [], "entities": [{"text": "AVG baseline", "start_pos": 112, "end_pos": 124, "type": "DATASET", "confidence": 0.8915346264839172}]}, {"text": "In each case, projectivity is calculated as the number of instances in which a word appearing between ahead hand dependent dis not dominated by h.", "labels": [], "entities": []}, {"text": "This measure allows us to explore how dependency distance might result in known rates of projectivity in natural language.", "labels": [], "entities": []}, {"text": "shows the results of running both the AVG baseline and GNN algorithm on 14 v2.4 UD corpora representing a range of language families.", "labels": [], "entities": [{"text": "AVG baseline", "start_pos": 38, "end_pos": 50, "type": "DATASET", "confidence": 0.8748928308486938}]}, {"text": "These are relatively small corpora-between 500 and 2000 training sentences-and as a consequence their small vocabularies result in embedding vector dimensions between 14 and 22 due to the use of twice the fourth root of vocabulary size ( \u00a72.4, \u00a73.1).", "labels": [], "entities": []}, {"text": "While smaller than the more usual 50-or 300-element vectors, tying dimensionality to corpus vocabulary size seemed to avoid instability in the embedding space, though perhaps not in every case.", "labels": [], "entities": []}, {"text": "Further, experiments with larger dimensions resulted in poor generalization to the testing set, possibly due to alack of correlation between embeddings seen and unseen during training.", "labels": [], "entities": []}, {"text": "Results from Spearman's \u03c1 rank correlation show that both AVG and GNN were able to positively correlate surface order with the source UD corpora.", "labels": [], "entities": [{"text": "\u03c1 rank correlation", "start_pos": 24, "end_pos": 42, "type": "METRIC", "confidence": 0.9088839888572693}, {"text": "AVG", "start_pos": 58, "end_pos": 61, "type": "METRIC", "confidence": 0.883718729019165}]}, {"text": "Because Spearman's \u03c1 ranges from -1 to 1, positive values are better than chance; values above 0.5 seem rather promising.", "labels": [], "entities": []}, {"text": "A large part of surface order can apparently be predicted based on dependency distance, averaged or learned.", "labels": [], "entities": []}, {"text": "In all cases the GNN was able to approach AVG, exceeding it 10 out of 14 times.", "labels": [], "entities": [{"text": "GNN", "start_pos": 17, "end_pos": 20, "type": "DATASET", "confidence": 0.904448926448822}, {"text": "AVG", "start_pos": 42, "end_pos": 45, "type": "DATASET", "confidence": 0.7227097749710083}]}, {"text": "For many languages, the GNN achieved its peak value before training was complete, probably indicating overfitting.", "labels": [], "entities": []}, {"text": "In the cases in which the GNN did not best AVG, the sparkline trends for Czech, Hungarian, and Latin suggest problems during training, perhaps due to overzealous learning rates or unstable embeddings, while Uyghur came very close.", "labels": [], "entities": [{"text": "AVG", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.7354090809822083}, {"text": "sparkline", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.9795023798942566}]}], "tableCaptions": [{"text": " Table 1: Results. Each language is listed by its corpus; number of training and testing sentences; embed- ding dimension; Spearman's \u03c1 rank correlation coefficient for AVG and GNN; and rate of projectivity  for AVG, GNN, and as attested in the UD corpus. Boldfaced numbers indicate cases in which GNN per- formed better than AVG. Sparklines show trends over 10K iterations with horizontal gray lines indicating  AVG performance and black dots showing peak performance of GNN.", "labels": [], "entities": [{"text": "embed- ding dimension", "start_pos": 100, "end_pos": 121, "type": "METRIC", "confidence": 0.8582497984170914}, {"text": "Spearman's \u03c1 rank correlation coefficient", "start_pos": 123, "end_pos": 164, "type": "METRIC", "confidence": 0.7572755416234335}, {"text": "UD corpus", "start_pos": 245, "end_pos": 254, "type": "DATASET", "confidence": 0.9209071099758148}]}]}