{"title": [{"text": "A Cascade Model for Proposition Extraction in Argumentation", "labels": [], "entities": [{"text": "Proposition Extraction", "start_pos": 20, "end_pos": 42, "type": "TASK", "confidence": 0.9273275136947632}]}], "abstractContent": [{"text": "We present a model to tackle a fundamental but understudied problem in computational ar-gumentation: proposition extraction.", "labels": [], "entities": [{"text": "proposition extraction", "start_pos": 101, "end_pos": 123, "type": "TASK", "confidence": 0.7694185674190521}]}, {"text": "Propositions are the basic units of an argument and the primary building blocks of most argument mining systems.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 88, "end_pos": 103, "type": "TASK", "confidence": 0.7306990325450897}]}, {"text": "However, they are usually substituted by argumentative discourse units obtained via surface-level text segmentation, which may yield text segments that lack semantic information necessary for subsequent argument mining processes.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 203, "end_pos": 218, "type": "TASK", "confidence": 0.7407442033290863}]}, {"text": "In contrast, our cascade model aims to extract complete propositions by handling anaphora resolution, text segmentation, reported speech, questions, imperatives , missing subjects, and revision.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 81, "end_pos": 100, "type": "TASK", "confidence": 0.7422139942646027}, {"text": "text segmentation", "start_pos": 102, "end_pos": 119, "type": "TASK", "confidence": 0.6966186463832855}]}, {"text": "We formulate each task as a computational problem and test various models using a corpus of the 2016 U.S. presidential debates.", "labels": [], "entities": []}, {"text": "We show promising performance for some tasks and discuss main challenges in proposition extraction.", "labels": [], "entities": [{"text": "proposition extraction", "start_pos": 76, "end_pos": 98, "type": "TASK", "confidence": 0.8470065295696259}]}], "introductionContent": [{"text": "Most argument mining models for identifying the argumentative structure of a text build upon elementary text spans that serve argumentative functions, such as premise and conclusion.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 5, "end_pos": 20, "type": "TASK", "confidence": 0.7652439475059509}, {"text": "identifying the argumentative structure of a text", "start_pos": 32, "end_pos": 81, "type": "TASK", "confidence": 0.7809699262891497}]}, {"text": "In argumentation theory, it is commonly accepted that these building blocks are propositions, i.e., statements that are either true or false.", "labels": [], "entities": [{"text": "argumentation theory", "start_pos": 3, "end_pos": 23, "type": "TASK", "confidence": 0.83153435587883}]}, {"text": "Despite the foundational role of propositions, however, proposition extraction from text has been little studied in computational argumentation.", "labels": [], "entities": [{"text": "proposition extraction from text", "start_pos": 56, "end_pos": 88, "type": "TASK", "confidence": 0.8420249223709106}]}, {"text": "Instead, most models rely on argumentative discourse units (ADUs) obtained by surface-level text segmentation (.", "labels": [], "entities": [{"text": "surface-level text segmentation", "start_pos": 78, "end_pos": 109, "type": "TASK", "confidence": 0.6799152294794718}]}, {"text": "In what follows, we discuss limitations of ADUs that potentially impinge upon subsequent argument mining processes, and then describe our approach.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 89, "end_pos": 104, "type": "TASK", "confidence": 0.735650971531868}]}, {"text": "One limitation of ADUs is that they may lack important semantic information, such as the referents of anaphors and the subject of an incomplete sentence, necessary for subsequent argument mining steps.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 179, "end_pos": 194, "type": "TASK", "confidence": 0.7320734262466431}]}, {"text": "For example, for two consecutive text segments Alice complained to Bob and He is upset, if we do not know he refers to Bob, it would be confusing whether the first segment supports the second or vice versa.", "labels": [], "entities": []}, {"text": "In another example, suppose Alice was faithful to Bob, keeping the secret is split into two propositions, each associated with the main clause and the adverbial participle, respectively.", "labels": [], "entities": []}, {"text": "While mere text segmentation leaves the subject of the participle (Alice) missing, tracing and reconstructing the subject makes it clear that the participle supports the main clause.", "labels": [], "entities": []}, {"text": "As illustrated in these examples, anaphora resolution and subject reconstruction recover semantic information that has potential benefits for argument mining systems.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.8085501790046692}, {"text": "subject reconstruction", "start_pos": 58, "end_pos": 80, "type": "TASK", "confidence": 0.7276746034622192}, {"text": "argument mining", "start_pos": 142, "end_pos": 157, "type": "TASK", "confidence": 0.7666632831096649}]}, {"text": "Moreover, ADUs may completely miss implicit propositions.", "labels": [], "entities": []}, {"text": "For instance, questions and imperatives do not convey explicit propositions, but they are important argumentative components that often imply propositional content in dialogical argumentation.", "labels": [], "entities": []}, {"text": "Suppose an arguer asks, why would you waste your money on tax?, and someone responds, tax is a waste of money.", "labels": [], "entities": []}, {"text": "It is not straightforward for an argument mining system to tell whether the response agrees or disagrees with the arguer, without knowing what is implied by the question.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 33, "end_pos": 48, "type": "TASK", "confidence": 0.7879471182823181}]}, {"text": "Implicit propositions occur in reported speech as well.", "labels": [], "entities": []}, {"text": "Suppose an arguer says, the doctor said we need more magnesium.", "labels": [], "entities": []}, {"text": "The arguer is not only claiming the report event having happened, but also bringing the content of the doctor's speech as a proposition into the argumentation structure or even maybe asserting it using authority.", "labels": [], "entities": []}, {"text": "These examples show the significance of recovering implicit propositions for argument mining systems.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 77, "end_pos": 92, "type": "TASK", "confidence": 0.7314513772726059}]}, {"text": "To overcome these limitations, we present a cascade model that aims to extract propositions from argumentative dialogues, with important semantic information and implicit propositional content recovered.", "labels": [], "entities": []}, {"text": "Our model consists of 7 modules, namely, anaphora resolution, locution extraction, reported speech, question, imperative, subject reconstruction, and revision ().", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.7093387842178345}, {"text": "locution extraction", "start_pos": 62, "end_pos": 81, "type": "TASK", "confidence": 0.7185016721487045}, {"text": "subject reconstruction", "start_pos": 122, "end_pos": 144, "type": "TASK", "confidence": 0.722007542848587}]}, {"text": "For each module, we formulate the task as a computational problem and test various models to solve it, except for the question and imperative modules, for which we present experimental sketches.", "labels": [], "entities": []}, {"text": "Our analyses and evaluation are based on the transcripts of the 2016 U.S. presidential debates and reaction on social media that are manually annotated with propositions (.", "labels": [], "entities": []}, {"text": "1. We introduce the problem of proposition extraction as seven tasks.", "labels": [], "entities": [{"text": "proposition extraction", "start_pos": 31, "end_pos": 53, "type": "TASK", "confidence": 0.842110276222229}]}, {"text": "2. We present various models to tackle each task and evaluate performance.", "labels": [], "entities": []}, {"text": "3. We analyze challenges facing our computational methods and suggest future directions.", "labels": [], "entities": []}, {"text": "For the remainder of the paper, we first review prior work on ADU segmentation and a theoretical framework for obtaining propositions from ADUs ( \u00a72).", "labels": [], "entities": [{"text": "ADU segmentation", "start_pos": 62, "end_pos": 78, "type": "TASK", "confidence": 0.8115454912185669}]}, {"text": "We then explain the annotated data of propositions ( \u00a73).", "labels": [], "entities": []}, {"text": "Next, we describe our cascade model ( \u00a74) and formulation of each task, along with experiments ( \u00a75).", "labels": [], "entities": []}, {"text": "We conclude the paper by discussing the challenges and future directions ( \u00a76).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Performance of anaphora resolution. (1S:  1st-person singular, 2S: 2nd-person singular, 3SG:  3rd-person singular gender, 3SN: 3rd-person singular  gender-neutral, Dep: Dependency, Dep-SO: Depen- dency for subjects and objects.)", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.6997625529766083}]}, {"text": " Table 2: F1-score of locution extraction.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9994133710861206}, {"text": "locution extraction", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.835371732711792}]}, {"text": " Table 3: Breakdown of locution types that are separated  by a comma or that are back-to-back (total 293 pairs).", "labels": [], "entities": []}, {"text": " Table 4: Accuracy of reported speech detection.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9969148635864258}, {"text": "reported speech detection", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.5746489465236664}]}, {"text": " Table 5: Accuracy of speech identification.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9866611361503601}, {"text": "speech identification", "start_pos": 22, "end_pos": 43, "type": "TASK", "confidence": 0.7395824939012527}]}, {"text": " Table 6: Accuracy of question detection.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9939379692077637}, {"text": "question detection", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.8317851126194}]}, {"text": " Table 7: Results of subject identification.", "labels": [], "entities": [{"text": "subject identification", "start_pos": 21, "end_pos": 43, "type": "TASK", "confidence": 0.8555124998092651}]}, {"text": " Table 8: Performance of revision.", "labels": [], "entities": [{"text": "revision", "start_pos": 25, "end_pos": 33, "type": "TASK", "confidence": 0.9739842414855957}]}, {"text": " Table 10: Accuracy of reported speech detection.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.9965819716453552}, {"text": "reported speech detection", "start_pos": 23, "end_pos": 48, "type": "TASK", "confidence": 0.5801294644673666}]}, {"text": " Table 12: Accuracy of question detection.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.992820680141449}, {"text": "question detection", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.8326557278633118}]}]}