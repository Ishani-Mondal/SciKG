{"title": [{"text": "The Unbearable Weight of Generating Artificial Errors for Grammatical Error Correction", "labels": [], "entities": [{"text": "Grammatical Error Correction", "start_pos": 58, "end_pos": 86, "type": "TASK", "confidence": 0.7616457343101501}]}], "abstractContent": [{"text": "In recent years, sequence-to-sequence models have been very effective for end-to-end grammatical error correction (GEC).", "labels": [], "entities": [{"text": "end-to-end grammatical error correction (GEC)", "start_pos": 74, "end_pos": 119, "type": "TASK", "confidence": 0.7106615773269108}]}, {"text": "As creating human-annotated parallel corpus for GEC is expensive and time-consuming, there has been work on artificial corpus generation with the aim of creating sentences that contain realistic grammatical errors from grammatically correct sentences.", "labels": [], "entities": [{"text": "artificial corpus generation", "start_pos": 108, "end_pos": 136, "type": "TASK", "confidence": 0.7815025448799133}]}, {"text": "In this paper, we investigate the impact of using recent neural models for generating errors to help neural models to correct errors.", "labels": [], "entities": []}, {"text": "We conduct a battery of experiments on the effect of data size, models, and comparison with a rule-based approach.", "labels": [], "entities": []}], "introductionContent": [{"text": "Grammatical error correction (GEC) is the task of automatically identifying and correcting the grammatical errors in the written text.", "labels": [], "entities": [{"text": "Grammatical error correction (GEC)", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8228418131669363}]}, {"text": "Recent work treats GEC as a translation task that use sequenceto-sequence models) to rewrite sentences with grammatical errors to grammatically correct sentences.", "labels": [], "entities": [{"text": "GEC", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.9056169986724854}]}, {"text": "As with machine translation models, GEC models benefit largely from the amount of parallel training data.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 8, "end_pos": 27, "type": "TASK", "confidence": 0.7727207839488983}, {"text": "GEC", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.8969839215278625}]}, {"text": "Since it is expensive and time-consuming to create annotated parallel corpus for training, there is research into generating sentences with artificial errors from grammatically correct sentences with the goal of simulating human-annotated data in a cost-effective way.", "labels": [], "entities": []}, {"text": "Recent work in artificial error generation (AEG) is inspired by the back-translation approach of machine translation systems (.", "labels": [], "entities": [{"text": "artificial error generation (AEG)", "start_pos": 15, "end_pos": 48, "type": "TASK", "confidence": 0.8091243356466293}, {"text": "machine translation", "start_pos": 97, "end_pos": 116, "type": "TASK", "confidence": 0.7111658155918121}]}, {"text": "In this framework, an intermediate model is trained to translate correct sentences into errorful sentences.", "labels": [], "entities": []}, {"text": "A new parallel cor- * Work done during internship at Grammarly pus is created using the largely available grammatically correct sentences and the corresponding synthetic data generated by this intermediate model.", "labels": [], "entities": []}, {"text": "The newly created corpus with the artificial errors is then used to train a GEC model.", "labels": [], "entities": [{"text": "GEC", "start_pos": 76, "end_pos": 79, "type": "DATASET", "confidence": 0.9207341074943542}]}, {"text": "To date, there is no work that compares how different base model architectures perform in the AEG task.", "labels": [], "entities": [{"text": "AEG task", "start_pos": 94, "end_pos": 102, "type": "TASK", "confidence": 0.7120695114135742}]}, {"text": "In this paper, we investigate how effective are different model architectures in generating artificial, parallel data to improve a GEC model.", "labels": [], "entities": []}, {"text": "Specifically, we train four recent neural models (and one rule-based model), including two new syntax-based models, for generating as well as correcting errors.", "labels": [], "entities": []}, {"text": "We analyze which models are effective in the AEG and correction conditions as well as by data size.", "labels": [], "entities": [{"text": "AEG", "start_pos": 45, "end_pos": 48, "type": "METRIC", "confidence": 0.8435144424438477}, {"text": "correction", "start_pos": 53, "end_pos": 63, "type": "METRIC", "confidence": 0.8139644861221313}]}, {"text": "Essentially, we seek to understand how effective are recent sequence-to-sequence (seq2seq) neural model as AEG mechanisms \"out of the box.\"", "labels": [], "entities": []}], "datasetContent": [{"text": "We performed a manual analysis of the generated error sentences and found that many of the errors did not always resemble those produced by humans.", "labels": [], "entities": []}, {"text": "For example, The situation with other types is not much (better \u2192 downward).", "labels": [], "entities": []}, {"text": "This shows that despite the noisiness of the error-generated data, some models (namely MLCONV and Transformer) were robust enough to improve.", "labels": [], "entities": [{"text": "MLCONV", "start_pos": 87, "end_pos": 93, "type": "DATASET", "confidence": 0.8620346784591675}]}, {"text": "This also suggests that we may achieve better improvement by controlling artificial errors to resemble the errors produced by humans.", "labels": [], "entities": []}, {"text": "The performance of syntax-based models goes down significantly with the addition of artificial errors, which indicates that these models maybe sensitive to poor artificial data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: (Exp2) Evaluating the impact of MLCONV, Transformer and the rule-based AEG systems. NUCLE-CLC  column represents the F0.5 score of GEC models trained on the base NUCLE-CLC data. 10K, 50K, 100K, 500K,  1M, and 2M represents the amount of artificial data added to the NUCLE-CLC during training.", "labels": [], "entities": [{"text": "F0.5 score", "start_pos": 127, "end_pos": 137, "type": "METRIC", "confidence": 0.9775253534317017}, {"text": "NUCLE-CLC data", "start_pos": 172, "end_pos": 186, "type": "DATASET", "confidence": 0.7891813814640045}]}, {"text": " Table 2: (Exp3) Using only NUCLE as base train- ing for correction. The AEG models are trained using  NUCLE-CLC data as in other experiments.", "labels": [], "entities": []}]}