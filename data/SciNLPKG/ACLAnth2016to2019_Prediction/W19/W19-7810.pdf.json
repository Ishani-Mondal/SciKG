{"title": [{"text": "Dependency Parser for Bengali-English Code-Mixed Data enhanced with a Synthetic Treebank", "labels": [], "entities": []}], "abstractContent": [{"text": "The development of code-mixing (CM) NLP systems has significantly gained importance in recent times due to an upsurge in the usage of CM data by multilingual speakers.", "labels": [], "entities": []}, {"text": "However, this proves to be a challenging task due to the complexities created by the presence of multiple languages together.", "labels": [], "entities": []}, {"text": "The complexities get further compounded by the inconsistencies present in the raw data on social media and other platforms.", "labels": [], "entities": []}, {"text": "In this paper, we present a neural stack based dependency parser for CM data of Bengali and English by utilizing pre-existing resources for closely related Hindi and English CM treebank as well as monolingual treebanks for Bengali, Hindi and English.", "labels": [], "entities": []}, {"text": "To address the issue of scarcity of annotated resources for Bengali-English CM pair, we present a rule based system to computationally generate a synthetic code-mixing treebank for Bengali and English (Syn-BE) which is used to further improve the accuracy of our dependency parser.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 247, "end_pos": 255, "type": "METRIC", "confidence": 0.9986168146133423}]}, {"text": "For evaluation purpose, we present a dataset of 500 Bengali-English tweets annotated under Universal Dependencies scheme.", "labels": [], "entities": []}], "introductionContent": [{"text": "Code-mixing refers to the mixing of various linguistic units (morphemes, words, modifiers, phrases, clauses and sentences) primarily from two participating grammatical systems within a sentence.", "labels": [], "entities": [{"text": "Code-mixing refers to the mixing of various linguistic units (morphemes, words, modifiers, phrases, clauses and sentences) primarily from two participating grammatical systems within a sentence", "start_pos": 0, "end_pos": 193, "type": "Description", "confidence": 0.822499429987323}]}, {"text": "This is essentially different from code-switching which refers to the co-occurrence of speech extracts belonging to two different grammatical systems.", "labels": [], "entities": []}, {"text": "The occurrence can be both inter-sentential or intra-sentential, however there are strict phrasal boundaries and within one lexical unit, the syntax of only one language is maintained.", "labels": [], "entities": []}, {"text": "Since the more recent works have not focused on the differences between the two phenomena, we will use these two terms interchangeably.", "labels": [], "entities": []}, {"text": "Recently, code-mixing which was often only observed in speech, has pervaded almost all forms of communication due to the growing popularity and usage of social media platforms by multilingual speakers (.", "labels": [], "entities": []}, {"text": "Therefore, there has been considerable effort in building CM NLP systems such as language identification), normalization and back-transliteration (.", "labels": [], "entities": [{"text": "language identification", "start_pos": 81, "end_pos": 104, "type": "TASK", "confidence": 0.7589504420757294}]}, {"text": "Part-ofspeech (POS) and chunk tagging for code-mixing data for various South Asian languages with English have been attempted with promising results (.", "labels": [], "entities": [{"text": "chunk tagging", "start_pos": 24, "end_pos": 37, "type": "TASK", "confidence": 0.752509742975235}]}, {"text": "developed a single multilingual parser trained on multilingual set of treebanks that outperformed monolingually-trained parsers for several target languages.", "labels": [], "entities": []}, {"text": "In the CoNLL 2018 shared task, several participating teams developed multilingual dependency parsers that integrated cross-lingual learning for resource-poor languages and were evaluated on monolingual treebanks belonging to 82 unique languages (.", "labels": [], "entities": [{"text": "CoNLL 2018 shared task", "start_pos": 7, "end_pos": 29, "type": "DATASET", "confidence": 0.769798994064331}]}, {"text": "However, none of these multilingual parsers have been evaluated on code-mixed data or adapted specifically for CM parsing.", "labels": [], "entities": [{"text": "CM parsing", "start_pos": 111, "end_pos": 121, "type": "TASK", "confidence": 0.8826519846916199}]}, {"text": "The Bengali-English code-mixing is found in abundance as Bengali is widely spoken in India and Bangladesh.", "labels": [], "entities": []}, {"text": "It is the second most widely spoken language in India after Hindi.", "labels": [], "entities": []}, {"text": "Because of inherent structural and semantic similarity between Bengali and Hindi, we observe a close proximity between Bengali-English and Hindi-English code-mixing as well.", "labels": [], "entities": []}, {"text": "Both of these language pairs deal with the challenges of mixing different typologically diverse languages; SOV word order 1 for Hindi/Bengali and SVO word order for English.", "labels": [], "entities": []}, {"text": "A dependency parser for Hindi-English code-mixing has been presented by . In comparison, Bengali-English code-mixing is left relatively unexplored barring significant works on language identification) and POS tagging () which serve as preliminary tasks for more advanced parsing applications down the pipeline.", "labels": [], "entities": [{"text": "language identification", "start_pos": 176, "end_pos": 199, "type": "TASK", "confidence": 0.7058448940515518}, {"text": "POS tagging", "start_pos": 205, "end_pos": 216, "type": "TASK", "confidence": 0.7915213108062744}]}, {"text": "The main hindrance to the development of parsing technologies for Bengali-English stem from the lack of annotated resources for the code-mixing of this language pair.", "labels": [], "entities": []}, {"text": "In this paper, we try to utilize the preexisting resources for widely available monolingual Bengali, Hindi and English as well as Hindi-English code-mixing and adapt them for Bengali-English dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 191, "end_pos": 209, "type": "TASK", "confidence": 0.77223140001297}]}, {"text": "We also propose a rule based system to synthetically generate Bengali-English code-mixing data.", "labels": [], "entities": []}, {"text": "An attempt has been made to generate code-mixing data for the Spanish-English language pair () but none for the HindiEnglish or Bengali-English language pair as these pairs pose special challenges due to their different word orders which commonly violate most code-mixing theories.", "labels": [], "entities": []}, {"text": "We further present a method to project dependency annotations to our Bengali-English CM data from monolingual Bengali and Hindi-English CM treebank and generate a synthetic treebank for Bengali-English (Syn-BE) which helps improve the accuracy of our dependency parser.", "labels": [], "entities": [{"text": "Bengali-English CM data from monolingual Bengali and Hindi-English CM treebank", "start_pos": 69, "end_pos": 147, "type": "DATASET", "confidence": 0.6130291491746902}, {"text": "accuracy", "start_pos": 235, "end_pos": 243, "type": "METRIC", "confidence": 0.9985901713371277}]}, {"text": "For evaluation purpose, we present a dataset of 500 Bengali-English tweets annotated under Universal Dependencies scheme.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our models are trained on English and Hindi UD-v2 treebanks.", "labels": [], "entities": [{"text": "UD-v2 treebanks", "start_pos": 44, "end_pos": 59, "type": "DATASET", "confidence": 0.7246849834918976}]}, {"text": "Due to the absence of a Bengali UD treebank, we converted the Paninian annotation scheme () present in the Bengali treebank to UD by slightly modifying the rules (Tandon et al., 2016) for Hindi.", "labels": [], "entities": []}, {"text": "The characters are represented by 32-dimensional character embeddings while the words in each language are represented by 64 dimensional word2vec vectors () learned using the skip-gram model.", "labels": [], "entities": []}, {"text": "The hidden dimensions and learning hyperparameters are consistent with those in . For our baseline model, we train the neural stacking model ) for Bengali-English by training the source model on both Bengali and English treebanks and stacking it on a CM model trained on 140 Bengali-English CM (Gold-BE) sentences in our training set.", "labels": [], "entities": [{"text": "neural stacking", "start_pos": 119, "end_pos": 134, "type": "TASK", "confidence": 0.7244110405445099}]}, {"text": "Even though the size of the training set is limited, we benefit from the presence of unique CM grammar as well as syntactic information of social media elements.", "labels": [], "entities": []}, {"text": "Our bilingual source model serves to transfer both POS tagging and parsing information to the CM model.", "labels": [], "entities": [{"text": "POS tagging and parsing information", "start_pos": 51, "end_pos": 86, "type": "TASK", "confidence": 0.726844847202301}]}, {"text": "In our next experiment, we train the CM stacking model with 1448 Hindi-English CM data (Gold-HE) as provided by  in addition to our 140 Gold-BE sentences.", "labels": [], "entities": [{"text": "CM stacking", "start_pos": 37, "end_pos": 48, "type": "TASK", "confidence": 0.7887323796749115}]}, {"text": "In order to fully capture the Hindi syntactic information in the CM data, we fortify the bilingual source model with the Hindi treebank resulting in a trilingual source model.", "labels": [], "entities": [{"text": "CM data", "start_pos": 65, "end_pos": 72, "type": "DATASET", "confidence": 0.7917395532131195}, {"text": "Hindi treebank", "start_pos": 121, "end_pos": 135, "type": "DATASET", "confidence": 0.7085178643465042}]}, {"text": "We try to reduce the differences in data representations belonging to Hindi and Bengali by using: 1.", "labels": [], "entities": []}, {"text": "Cross Lingual Word Embeddings for Hindi and Bengali by projecting the word2vec embeddings for the two languages into the same space by using the projection algorithm of and using a bilingual lexicon from ILCI parallel corpora.", "labels": [], "entities": []}, {"text": "2. WX notation 8 to represent words from the two languages and using a common 32-dimensional character embedding space.", "labels": [], "entities": []}, {"text": "For our final experiment, we augment our Synthetic Code-Mixed Bengali-English Treebank to the trilingual source model generated in the previous experiment and stack that on our CM model.", "labels": [], "entities": [{"text": "Synthetic Code-Mixed Bengali-English Treebank", "start_pos": 41, "end_pos": 86, "type": "DATASET", "confidence": 0.521723248064518}]}], "tableCaptions": [{"text": " Table 2: POS and parsing results of neural- stacking model for different languages", "labels": [], "entities": [{"text": "neural- stacking", "start_pos": 37, "end_pos": 53, "type": "TASK", "confidence": 0.6895479361216227}]}, {"text": " Table 3: Effect of embeddings on POS and Parser  results for the Trilingual + Gold-(HE + BE) model", "labels": [], "entities": [{"text": "Trilingual + Gold-(HE + BE)", "start_pos": 66, "end_pos": 93, "type": "METRIC", "confidence": 0.44601113349199295}]}]}