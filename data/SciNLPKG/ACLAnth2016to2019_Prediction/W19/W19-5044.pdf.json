{"title": [{"text": "WTMED at MEDIQA 2019: A Hybrid Approach to Biomedical Natural Language Inference", "labels": [], "entities": [{"text": "WTMED at MEDIQA 2019", "start_pos": 0, "end_pos": 20, "type": "DATASET", "confidence": 0.7676374465227127}, {"text": "Biomedical Natural Language Inference", "start_pos": 43, "end_pos": 80, "type": "TASK", "confidence": 0.6049745753407478}]}], "abstractContent": [{"text": "Natural language inference (NLI) is challenging , especially when it is applied to technical domains such as biomedical settings.", "labels": [], "entities": [{"text": "Natural language inference (NLI)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7915806323289871}]}, {"text": "In this paper, we propose a hybrid approach to biomedical NLI where different types of information are exploited for this task.", "labels": [], "entities": []}, {"text": "Our base model includes a pre-trained text en-coder as the core component, and a syntax en-coder and a feature encoder to capture syntactic and domain-specific information.", "labels": [], "entities": []}, {"text": "Then we combine the output of different base models to form more powerful ensemble models.", "labels": [], "entities": []}, {"text": "Finally, we design two conflict resolution strategies when the test data contain multiple (premise, hypothesis) pairs with the same premise.", "labels": [], "entities": [{"text": "conflict resolution", "start_pos": 23, "end_pos": 42, "type": "TASK", "confidence": 0.8502389192581177}]}, {"text": "We train our models on the MedNLI dataset, yielding the best performance on the test set of the MEDIQA 2019 Task 1.", "labels": [], "entities": [{"text": "MedNLI dataset", "start_pos": 27, "end_pos": 41, "type": "DATASET", "confidence": 0.9851978719234467}, {"text": "MEDIQA 2019 Task 1", "start_pos": 96, "end_pos": 114, "type": "DATASET", "confidence": 0.735843300819397}]}], "introductionContent": [{"text": "Natural language inference (NLI), also known as textual entailment, is an important natural language processing (NLP) task that has long been studied.", "labels": [], "entities": [{"text": "Natural language inference (NLI)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7925448765357336}, {"text": "natural language processing (NLP) task", "start_pos": 84, "end_pos": 122, "type": "TASK", "confidence": 0.7847360968589783}]}, {"text": "It aims to capture the relationship between two sentences, identifying whether a given premise entails, contradicts, or is neutral to a given hypothesis.", "labels": [], "entities": []}, {"text": "Success in NLI is crucial for achieving semantic comprehension of human language, which in turn is a prerequisite to accomplish natural language understanding (NLU).", "labels": [], "entities": [{"text": "natural language understanding (NLU)", "start_pos": 128, "end_pos": 164, "type": "TASK", "confidence": 0.8175337811311086}]}, {"text": "In general, accurate NLI systems facilitate many downstream tasks, such as commonsense reasoning) and question answering).", "labels": [], "entities": [{"text": "commonsense reasoning", "start_pos": 75, "end_pos": 96, "type": "TASK", "confidence": 0.8453042209148407}, {"text": "question answering", "start_pos": 102, "end_pos": 120, "type": "TASK", "confidence": 0.9067806601524353}]}, {"text": "Most of existing NLI studies are conducted in the general domain, with limited attention paid to domain-specific scenarios.", "labels": [], "entities": []}, {"text": "Nevertheless, there has been increasing demand for information processing in the biomedical domain such as biomedical question answering  and cohort selection ().", "labels": [], "entities": [{"text": "information processing", "start_pos": 51, "end_pos": 73, "type": "TASK", "confidence": 0.7642634809017181}, {"text": "biomedical question answering", "start_pos": 107, "end_pos": 136, "type": "TASK", "confidence": 0.6175644099712372}, {"text": "cohort selection", "start_pos": 142, "end_pos": 158, "type": "TASK", "confidence": 0.6854507178068161}]}, {"text": "Many biomedical NLP applications require automatic understanding of symptom descriptions and examination reports ( and therefore can greatly benefit from accurate biomedical NLI systems.", "labels": [], "entities": [{"text": "biomedical NLP", "start_pos": 5, "end_pos": 19, "type": "TASK", "confidence": 0.6524999141693115}]}, {"text": "In this study, we propose a hybrid approach to biomedical NLI, which includes three main components, as illustrated in.", "labels": [], "entities": []}, {"text": "The main component is the base model (the largest box in the figure), which includes three encoders: an MT-DNN () based text encoder, a syntax encoder that captures structural information, and a feature encoder which injects some degree of domain knowledge into the model (see \u00a73).", "labels": [], "entities": []}, {"text": "We conduct unsupervised pre-training for the text encoder on biomedical corpora to compensate for the lack of domain-specific supervision (.", "labels": [], "entities": []}, {"text": "To enhance our model, we also use model ensemble and conflict resolution strategies, corresponding to the two top dashed boxes in and are explained in \u00a74.", "labels": [], "entities": [{"text": "conflict resolution", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.8606994152069092}]}, {"text": "The datasets and implementation detail are described in \u00a75.", "labels": [], "entities": []}, {"text": "The experimental results on the MedNLI dataset) and the MEDIQA 2019 shared task 1 ) are reported in \u00a76.", "labels": [], "entities": [{"text": "MedNLI dataset", "start_pos": 32, "end_pos": 46, "type": "DATASET", "confidence": 0.9715797007083893}, {"text": "MEDIQA 2019 shared task 1", "start_pos": 56, "end_pos": 81, "type": "DATASET", "confidence": 0.8355372071266174}]}], "datasetContent": [{"text": "For our experiments, we first find the best configuration fora single base model, and then apply ensemble and conflict resolution on top of it.", "labels": [], "entities": [{"text": "conflict resolution", "start_pos": 110, "end_pos": 129, "type": "TASK", "confidence": 0.7273067533969879}]}, {"text": "We run all these experiments with MT-DNN base for faster iterations.", "labels": [], "entities": [{"text": "MT-DNN base", "start_pos": 34, "end_pos": 45, "type": "DATASET", "confidence": 0.8400396704673767}]}, {"text": "In order to maximally leverage the MedNLI dataset, unless otherwise specified, all experiments use the MedNLI training and development sets as the training data, and evaluate the performance directly on the MedNLI test set.", "labels": [], "entities": [{"text": "MedNLI dataset", "start_pos": 35, "end_pos": 49, "type": "DATASET", "confidence": 0.9646113514900208}, {"text": "MedNLI training and development sets", "start_pos": 103, "end_pos": 139, "type": "DATASET", "confidence": 0.8199357509613037}, {"text": "MedNLI test set", "start_pos": 207, "end_pos": 222, "type": "DATASET", "confidence": 0.9757026235262553}]}, {"text": "After obtaining the best configuration according to the development set performance, we retrain the whole system with that configuration on MT-DNN large using the whole MedNLI dataset (i.e. training+development+test).", "labels": [], "entities": [{"text": "MT-DNN", "start_pos": 140, "end_pos": 146, "type": "DATASET", "confidence": 0.7982449531555176}, {"text": "MedNLI dataset", "start_pos": 169, "end_pos": 183, "type": "DATASET", "confidence": 0.9783411920070648}]}, {"text": "We run it on the MEDIQA Task 1 test set for the final submission ( \u00a76.4).", "labels": [], "entities": [{"text": "MEDIQA Task 1 test set", "start_pos": 17, "end_pos": 39, "type": "DATASET", "confidence": 0.8229286193847656}]}], "tableCaptions": [{"text": " Table 1: Key statistics of the MedNLI dataset. We tok- enize the sentences with NLTK (Loper and Bird, 2002).", "labels": [], "entities": [{"text": "MedNLI dataset", "start_pos": 32, "end_pos": 46, "type": "DATASET", "confidence": 0.9341530501842499}]}, {"text": " Table 2: Performance of the base model with differ- ent configurations of the three encoders: text encoder  (TE), syntax encoder (SE), and feature encoder (FE).  We use GloVe (Embedding I) for Tree-LSTM initial- ization, and the experiments do not include language  model fine-tuning and conflict resolution.", "labels": [], "entities": [{"text": "FE", "start_pos": 157, "end_pos": 159, "type": "METRIC", "confidence": 0.6068357825279236}, {"text": "conflict resolution", "start_pos": 289, "end_pos": 308, "type": "TASK", "confidence": 0.7117753028869629}]}, {"text": " Table 4: Effect of different embeddings for Tree- LSTM initialization in the syntax encoder. The first  row is the best result from Table 3. The last two rows  are the same system but with different embeddings.", "labels": [], "entities": []}, {"text": " Table 5: The ablation results on top of the best base  model. LMFT denotes language model fine tuning.", "labels": [], "entities": [{"text": "ablation", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9758589267730713}, {"text": "LMFT", "start_pos": 63, "end_pos": 67, "type": "METRIC", "confidence": 0.9394344091415405}]}, {"text": " Table 6: The performance of different ensemble combinations and conflict resolution strategies on our develop- ment set (i.e., the original MedNLI test set) and on the MEDIQA shared task test set. All our models in this table  (i.e. the Base Model and Ensemble sections) use MedNLI training and development sets as the training set, while", "labels": [], "entities": [{"text": "conflict resolution", "start_pos": 65, "end_pos": 84, "type": "TASK", "confidence": 0.7643765211105347}, {"text": "MedNLI test set", "start_pos": 141, "end_pos": 156, "type": "DATASET", "confidence": 0.9550525943438212}, {"text": "MEDIQA shared task test set", "start_pos": 169, "end_pos": 196, "type": "DATASET", "confidence": 0.8189164400100708}]}]}