{"title": [{"text": "Argument Component Classification by Relation Identification by Neural Network and TextRank", "labels": [], "entities": [{"text": "Argument Component Classification by Relation Identification", "start_pos": 0, "end_pos": 60, "type": "TASK", "confidence": 0.6902795284986496}, {"text": "TextRank", "start_pos": 83, "end_pos": 91, "type": "DATASET", "confidence": 0.7317202091217041}]}], "abstractContent": [{"text": "In recent years, argumentation mining, which automatically extracts the structure of argu-mentation from unstructured documents such as essays and debates, is gaining attention.", "labels": [], "entities": [{"text": "argumentation mining", "start_pos": 17, "end_pos": 37, "type": "TASK", "confidence": 0.9738966524600983}]}, {"text": "For argumentation mining applications, argument-component classification is an important sub-task.", "labels": [], "entities": [{"text": "argumentation mining", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.946427583694458}, {"text": "argument-component classification", "start_pos": 39, "end_pos": 72, "type": "TASK", "confidence": 0.7440641224384308}]}, {"text": "The existing methods can be classified into supervised methods and unsupervised methods.", "labels": [], "entities": []}, {"text": "Many existing supervised methods use a clas-sifier to identify the roles of argument components , such as claim or premise , but many of them use information of a single sentence without relying on the whole document.", "labels": [], "entities": []}, {"text": "On the other hand, existing unsupervised document classification has the advantage of being able to use the whole document, but accuracy of these methods is not so high.", "labels": [], "entities": [{"text": "document classification", "start_pos": 41, "end_pos": 64, "type": "TASK", "confidence": 0.7519130110740662}, {"text": "accuracy", "start_pos": 128, "end_pos": 136, "type": "METRIC", "confidence": 0.9994307160377502}]}, {"text": "In this paper, we propose a method for argument-component classification that combines relation identification by neural networks and TextRank to integrate relation infor-mations (i.e. the strength of the relation).", "labels": [], "entities": [{"text": "argument-component classification", "start_pos": 39, "end_pos": 72, "type": "TASK", "confidence": 0.7612341046333313}, {"text": "relation identification", "start_pos": 87, "end_pos": 110, "type": "TASK", "confidence": 0.7526156902313232}]}, {"text": "This method can use argumentation-specific knowledge by employing supervised learning on a corpus while maintaining the advantage of using the whole document.", "labels": [], "entities": []}, {"text": "Experiments on two corpora, one consisting of student essays and the other of Wikipedia articles , show the effectiveness of this method.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, argumentation mining, which automatically extracts the structure of argumentation from unstructured documents such as essays and debates, is gaining attention.", "labels": [], "entities": [{"text": "argumentation mining", "start_pos": 17, "end_pos": 37, "type": "TASK", "confidence": 0.9709413051605225}]}, {"text": "Argumentation mining consists of the following four subtasks ().", "labels": [], "entities": [{"text": "Argumentation mining", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8243055939674377}]}], "datasetContent": [{"text": "In this section, we explain the corpus we use, experimental setting, and results.", "labels": [], "entities": []}, {"text": "For the comparison between our method and TextRank-TFIDF/TextRank-W2V, we used Claim@k and MajorClaim@k as evaluation metrics.", "labels": [], "entities": [{"text": "TextRank-W2V", "start_pos": 57, "end_pos": 69, "type": "DATASET", "confidence": 0.6941540241241455}]}, {"text": "In MajorClaim@k, the result is considered correct if the top k according to the ranking includes the target major claim.", "labels": [], "entities": [{"text": "MajorClaim", "start_pos": 3, "end_pos": 13, "type": "DATASET", "confidence": 0.8542636632919312}]}, {"text": "In Claim@k, the result is considered correct if the top k according to the ranking includes the target claim and major claim.", "labels": [], "entities": []}, {"text": "In Student Essay, MajorClaim@k and Claim@k were evalueted fork = 1, 2, 3.", "labels": [], "entities": []}, {"text": "Wikipedia Article does not include major claim, so the evaluation was done only for Claim@k.", "labels": [], "entities": [{"text": "Wikipedia Article", "start_pos": 0, "end_pos": 17, "type": "DATASET", "confidence": 0.954541802406311}]}, {"text": "The number of ACs varies significantly, and the minimum is 2, so we report Claim@k fork = 2 to evaluate all the ACs.", "labels": [], "entities": [{"text": "Claim@k fork", "start_pos": 75, "end_pos": 87, "type": "METRIC", "confidence": 0.9183489084243774}]}, {"text": "The number of articles that had two ACs was 24 out of 102.", "labels": [], "entities": []}, {"text": "This means that these 24 articles are considered correct regardless of the output of the classifier when evaluating at Claim@2.", "labels": [], "entities": []}, {"text": "So we should be careful that there is possibility of overestimation.", "labels": [], "entities": []}, {"text": "For component classification, we employed the precision, recall, and F-score as evaluation met-  rics that are often used in text classification.", "labels": [], "entities": [{"text": "component classification", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.8468478620052338}, {"text": "precision", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.9996542930603027}, {"text": "recall", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.9973205924034119}, {"text": "F-score", "start_pos": 69, "end_pos": 76, "type": "METRIC", "confidence": 0.9988264441490173}, {"text": "text classification", "start_pos": 125, "end_pos": 144, "type": "TASK", "confidence": 0.8053002953529358}]}, {"text": "Our method obtains a rank of the ACs.", "labels": [], "entities": []}, {"text": "For comparison, we set a threshold; if the rank was higher than the threshold, we considered the AC to be a major claim or claim.", "labels": [], "entities": []}, {"text": "We used 1-3 as the threshold for Student Essay.", "labels": [], "entities": [{"text": "Student Essay", "start_pos": 33, "end_pos": 46, "type": "TASK", "confidence": 0.65406933426857}]}, {"text": "The number of ACs varies more for Wikipedia Article, ranging from a minimum of 2 to maximum of 103, with an average of 11.12.", "labels": [], "entities": []}, {"text": "Thus, if we were to employ a small, fixed threshold, the recall would get smaller for an article with many ACs.", "labels": [], "entities": [{"text": "recall", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.9995941519737244}]}, {"text": "In order to resolve this problem, we employed a linear regression to predict the number of claims from the number of ACs and used the prediction as a threshold.", "labels": [], "entities": []}, {"text": "We call this \"@adaptive.\"", "labels": [], "entities": []}, {"text": "For the regression on Wikipedia Article, the regression coefficient was 0.232, and the intercept was 0.873 with R-squared as 0.846.", "labels": [], "entities": [{"text": "Wikipedia Article", "start_pos": 22, "end_pos": 39, "type": "DATASET", "confidence": 0.9249702990055084}, {"text": "regression coefficient", "start_pos": 45, "end_pos": 67, "type": "METRIC", "confidence": 0.9810536503791809}, {"text": "intercept", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.9931710958480835}, {"text": "R-squared", "start_pos": 112, "end_pos": 121, "type": "METRIC", "confidence": 0.9912652373313904}]}, {"text": "The fitted line is drawn in.", "labels": [], "entities": []}, {"text": "For Student Essay, we evaluated a case wherein only major claims is considered and one wherein both major claims and claims are considered.", "labels": [], "entities": [{"text": "Student Essay", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.6521539688110352}]}, {"text": "show the results using our method and TextRank-TFIDF/TextRank-W2V to Student Essay and Wikipedia Article.", "labels": [], "entities": []}, {"text": "For Student Essay, our proposed method outperformed the previous TextRank-TFIDF/TextRank-W2V.", "labels": [], "entities": [{"text": "Student Essay", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.6464052349328995}, {"text": "TextRank-W2V", "start_pos": 80, "end_pos": 92, "type": "DATASET", "confidence": 0.705446183681488}]}, {"text": "In particular, our method achieved 0.542, which is significantly better than the 0.289 of TextRank-TFIDF, for major claims.", "labels": [], "entities": [{"text": "TextRank-TFIDF", "start_pos": 90, "end_pos": 104, "type": "DATASET", "confidence": 0.8924338817596436}]}, {"text": "Simply employing word vectors alone did not improve the performance; MajorClaim@1 was 0.197 for TextRank-W2V while it was 0.289 for TextRank-TFIDF.", "labels": [], "entities": [{"text": "MajorClaim@1", "start_pos": 69, "end_pos": 81, "type": "METRIC", "confidence": 0.7255976398785909}, {"text": "TextRank-W2V", "start_pos": 96, "end_pos": 108, "type": "DATASET", "confidence": 0.9309495091438293}, {"text": "TextRank-TFIDF", "start_pos": 132, "end_pos": 146, "type": "DATASET", "confidence": 0.9602113366127014}]}, {"text": "shows the averaged rank of major claims, claims and premises.", "labels": [], "entities": []}, {"text": "For TextRank-TFIDF/TextRank-W2V, the difference in the averaged ranks for major claims, claims, premises is small, and they are not well separated.", "labels": [], "entities": [{"text": "TextRank-TFIDF", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.907720685005188}, {"text": "TextRank-W2V", "start_pos": 19, "end_pos": 31, "type": "DATASET", "confidence": 0.8026224970817566}]}, {"text": "In our proposed method, the averaged ranks of major claims, claims, and premises are 3.883, 6.664, and 10.263, respectively, and they are well articulated.", "labels": [], "entities": []}, {"text": "For Wikipedia Article, our method correctly assigns a higher rank to claims while TextRank-TFIDF/TextRank-W2V incorrectly assign a higher rank to premises.", "labels": [], "entities": [{"text": "TextRank-TFIDF", "start_pos": 82, "end_pos": 96, "type": "DATASET", "confidence": 0.9324577450752258}]}, {"text": "show the result of comparison of our method to the neural network classifiers.", "labels": [], "entities": []}, {"text": "Our method ranks ACs into specified types of AC: major claim, claim, or premise for Student Essay.", "labels": [], "entities": []}, {"text": "Because the neural network classifiers are classifiers, in order to make a comparison, we set a threshold on the rank to make classification.", "labels": [], "entities": []}, {"text": "For Wikipedia Article, because the number of ACs varies, we use an adaptive threshold explained in Section 4.5.", "labels": [], "entities": []}, {"text": "For Student Essay, our method was the best in F-Score for major claim with 3 as the threshold,  and also for claim with 7 as seen in.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 46, "end_pos": 53, "type": "METRIC", "confidence": 0.9981390237808228}]}, {"text": "This shows the effectiveness of our method for classifying AC into major claim and claim.", "labels": [], "entities": [{"text": "classifying AC", "start_pos": 47, "end_pos": 61, "type": "TASK", "confidence": 0.8837206959724426}]}, {"text": "For Student Essay, our method is better than the neural network classifier.", "labels": [], "entities": [{"text": "Student Essay", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.6619527041912079}]}, {"text": "shows the Fscore for three-way classifier.", "labels": [], "entities": [{"text": "Fscore", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9835561513900757}]}, {"text": "In this table, LSTM and biLSTM are slightly better than CNN, but the difference is small.", "labels": [], "entities": [{"text": "CNN", "start_pos": 56, "end_pos": 59, "type": "DATASET", "confidence": 0.8006193041801453}]}, {"text": "It is notable that the score is high for premise, but it is low for major claim and claim.", "labels": [], "entities": []}, {"text": "shows the confusion matrix for LSTM.", "labels": [], "entities": [{"text": "confusion", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9605430960655212}, {"text": "LSTM", "start_pos": 31, "end_pos": 35, "type": "DATASET", "confidence": 0.5941243171691895}]}, {"text": "The table shows this more clearly.", "labels": [], "entities": []}, {"text": "Our method is effective for discriminating major claim and claim because major claim and claim are separated by ranking, For Wikipedia Article, the neural network classifier marked better F-Scores.", "labels": [], "entities": [{"text": "Wikipedia Article", "start_pos": 125, "end_pos": 142, "type": "DATASET", "confidence": 0.9166934192180634}, {"text": "F-Scores", "start_pos": 188, "end_pos": 196, "type": "METRIC", "confidence": 0.9876466989517212}]}, {"text": "This can be understood that the argumentation structure of Wikipedia Article is more controlled and can be extracted just by the neural network classifier.", "labels": [], "entities": [{"text": "Wikipedia Article", "start_pos": 59, "end_pos": 76, "type": "DATASET", "confidence": 0.8981937170028687}]}, {"text": "We show the confusion matrix for LSTM of Wikipedia Article at.", "labels": [], "entities": []}, {"text": "However our method is better than the neural network classifier in the precision of @1 in.", "labels": [], "entities": [{"text": "precision", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.9974619150161743}]}, {"text": "If one want to find out not all the claim but main claim, our method can serve better.", "labels": [], "entities": []}, {"text": "In summary, our method outperformed the previous methods for Student Essay.", "labels": [], "entities": [{"text": "Student Essay", "start_pos": 61, "end_pos": 74, "type": "TASK", "confidence": 0.7316458523273468}]}, {"text": "For Wikipedia Article, our method was slightly worse than the neural network classifiers.", "labels": [], "entities": [{"text": "Wikipedia Article", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.9118269681930542}]}], "tableCaptions": [{"text": " Table 3: Results of Claim Detection using TextRank in Student Essay", "labels": [], "entities": [{"text": "Claim Detection", "start_pos": 21, "end_pos": 36, "type": "TASK", "confidence": 0.7053684443235397}]}, {"text": " Table 4: Results of Claim detection using TextRank in Wikipedia Article", "labels": [], "entities": [{"text": "Claim detection", "start_pos": 21, "end_pos": 36, "type": "TASK", "confidence": 0.852397233247757}]}, {"text": " Table 5: Averaged Rank of Major Claim, Claim, and  Premise in Student Essay", "labels": [], "entities": [{"text": "Averaged Rank", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9522182643413544}, {"text": "Major Claim, Claim", "start_pos": 27, "end_pos": 45, "type": "METRIC", "confidence": 0.8057361841201782}, {"text": "Premise", "start_pos": 52, "end_pos": 59, "type": "METRIC", "confidence": 0.9819079041481018}]}, {"text": " Table 6: Average Rank of Claim and Premise in  Wikipedia Article", "labels": [], "entities": [{"text": "Average Rank of Claim", "start_pos": 10, "end_pos": 31, "type": "METRIC", "confidence": 0.9334042370319366}, {"text": "Wikipedia Article", "start_pos": 48, "end_pos": 65, "type": "DATASET", "confidence": 0.9556840360164642}]}, {"text": " Table 7: Precision and Recall detecting Claim in Stu- dent Essay", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9255942702293396}, {"text": "Recall detecting Claim", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.7356457312901815}]}, {"text": " Table 8: Precision and Recall detecting Major Claim in  Student Essay", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.938332200050354}, {"text": "Recall detecting Major Claim", "start_pos": 24, "end_pos": 52, "type": "TASK", "confidence": 0.603557750582695}]}, {"text": " Table 9: Precision and Recall detecting Claim in  Wikipedia Corpus", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9819100499153137}, {"text": "Recall detecting Claim", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.7753666838010153}, {"text": "Wikipedia Corpus", "start_pos": 51, "end_pos": 67, "type": "DATASET", "confidence": 0.9833086133003235}]}, {"text": " Table 10: F-Score of three-way Classification of Ma- jorClaim, Claim, and Premise of Student Essay", "labels": [], "entities": [{"text": "F-Score", "start_pos": 11, "end_pos": 18, "type": "METRIC", "confidence": 0.9972655773162842}, {"text": "Ma- jorClaim", "start_pos": 50, "end_pos": 62, "type": "METRIC", "confidence": 0.7313532829284668}]}, {"text": " Table 11: Confusion Matrix of three-way Classifica- tion of MajorClaim, Claim, and Premise using LSTM  of Student Essay for 20% test set of Table 1", "labels": [], "entities": [{"text": "MajorClaim", "start_pos": 61, "end_pos": 71, "type": "METRIC", "confidence": 0.8174705505371094}, {"text": "Premise", "start_pos": 84, "end_pos": 91, "type": "METRIC", "confidence": 0.9250432848930359}]}, {"text": " Table 12: Confusion Matrix of Classification of Claim,  and Premise using LSTM of Wikipedia Article for 20%  test set of Table 2", "labels": [], "entities": [{"text": "Premise", "start_pos": 61, "end_pos": 68, "type": "METRIC", "confidence": 0.9754993915557861}]}]}