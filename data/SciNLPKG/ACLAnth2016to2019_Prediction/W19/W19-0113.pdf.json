{"title": [{"text": "Learnability and Overgeneration in Computational Syntax", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper addresses the hypothesis that unnatural patterns generated by grammar formalisms can be eliminated on the grounds that they are unlearnable.", "labels": [], "entities": []}, {"text": "I consider three examples of formal languages thought to represent dependencies unattested in natural language syntax, and show that all three can be learned by grammar induction algorithms following the Distributional Learning paradigm of Clark and Eyraud (2007).", "labels": [], "entities": []}, {"text": "While learnable language classes are restrictive by necessity (Gold, 1967), these facts suggest that learn-ability alone maybe insufficient for addressing concerns of overgeneration in syntax.", "labels": [], "entities": []}], "introductionContent": [{"text": "A longstanding debate in linguistics concerns the division of labor in language acquisition between innate universal assumptions about natural language and the learner's ability to recognize patterns in data.", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 71, "end_pos": 91, "type": "TASK", "confidence": 0.7524304687976837}]}, {"text": "The rationalist position, famously championed by the Principles and Parameters framework, follows the Poverty of the Stimulus argument in assuming a rich Universal Grammar (UG) that allows individual languages to vary along a narrow range of dimensions.", "labels": [], "entities": []}, {"text": "On the other hand, the Distributional Learning paradigm of grammatical inference) has shown that it is possible to create empiricist representations of grammar optimized for extracting generalizations from data with theoretical guarantees of convergence.", "labels": [], "entities": []}, {"text": "Recent advances in mathematical linguistics have suggested that the rationalist-empiricist debate maybe of interest to the program of formally characterizing the typology of syntax.", "labels": [], "entities": []}, {"text": "argument that Swiss German is not context-free shows that substantial expressive power is needed in order to adequately describe syntactic phenomena.", "labels": [], "entities": []}, {"text": "At the same time, the class of context-free languages and its extensions include pathological dependencies unattested in natural language., for instance, shows that the context-free Merge operation allows Minimalist Grammars (MGs) to define languages that require every syntactically well-formed sentence to have at least one semantic type conflict.", "labels": [], "entities": [{"text": "Minimalist Grammars (MGs)", "start_pos": 205, "end_pos": 230, "type": "TASK", "confidence": 0.7319784164428711}]}, {"text": "In light of this overgeneration problem, learnability has been proposed as a possible way to refine existing language classes so as to better align with empirical facts.", "labels": [], "entities": []}, {"text": "Under such an approach, UG specifies the formalism in which grammars are represented, while language acquisition is modelled by a grammar induction algorithm that correctly converges on a subset of the possible grammars.", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 92, "end_pos": 112, "type": "TASK", "confidence": 0.7245835363864899}]}, {"text": "Since no strict superclass of the finite languages admits a general learning procedure, there necessarily exist languages that are permitted by UG but that cannot be learned by the language acquisition algorithm.", "labels": [], "entities": []}, {"text": "This paper takes some preliminary steps toward evaluating the potential of learnability to produce restricted language classes that exclude unnatural patterns.", "labels": [], "entities": []}, {"text": "Recent work in Distributional Learning has produced a hierarchy of context-free and multiple context-free language classes defined by learning algorithms.", "labels": [], "entities": [{"text": "Distributional Learning", "start_pos": 15, "end_pos": 38, "type": "TASK", "confidence": 0.9029985070228577}]}, {"text": "I examine three examples of unnatural patterns-structure-independent constraints on sentence length, free word order with unbounded crossing dependencies, and unlimited copying of deep context-free structure-and show that these patterns appear in small classes of the learnable hierarchy.", "labels": [], "entities": []}, {"text": "This suggests that current approaches to grammar induction for syntax may fail to yield learnability-based accounts for the absence of these patterns in syntactic typology.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 41, "end_pos": 58, "type": "TASK", "confidence": 0.7445949614048004}]}, {"text": "After basic definitions and notation are presented in Section 2, Section 3 introduces the learnable language classes considered in this paper.", "labels": [], "entities": []}, {"text": "The three unnatural patterns, drawn from Graf's (2013) discussion of overgeneration in MGs, are defined in Section 4.", "labels": [], "entities": []}, {"text": "There, it will be shown that the three patterns exist within the language classes from Section 3.", "labels": [], "entities": []}, {"text": "Section 5 concludes with a discussion of these facts and their relationship with the rationalist-empiricist debate.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}