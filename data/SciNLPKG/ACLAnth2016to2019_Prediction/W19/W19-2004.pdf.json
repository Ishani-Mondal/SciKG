{"title": [{"text": "How Well Do Embedding Models Capture Non-compositionality? A View from Multiword Expressions", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we apply various embedding methods to multiword expressions to study how well they capture the nuances of non-compositional data.", "labels": [], "entities": []}, {"text": "Our results from a range of word-, character-, and document-level em-bbedings suggest that word2vec performs the best, followed by fastText and infersent.", "labels": [], "entities": []}, {"text": "Moreover, we find that recently-proposed con-textualised embedding models such as BERT and ELMo are not adept at handling non-compositionality in multiword expressions.", "labels": [], "entities": [{"text": "BERT", "start_pos": 82, "end_pos": 86, "type": "METRIC", "confidence": 0.9545214176177979}]}], "introductionContent": [{"text": "Modern embedding models, including contextual embeddings, have been shown to work impressively well across a range of tasks (.", "labels": [], "entities": []}, {"text": "However, study of their performance on data with a mix of compositionality levels, whose meaning is often not easily predicted from that of its constituent words, has been limited (.", "labels": [], "entities": []}, {"text": "At present, there exists no definitive metric to measure the modelling capabilities of an embedding technique across a spectrum of noncompositionality, especially in the case of newer, contextualised representations, such as ELMo and BERT.", "labels": [], "entities": [{"text": "BERT", "start_pos": 234, "end_pos": 238, "type": "METRIC", "confidence": 0.7980358600616455}]}, {"text": "In this study, we apply various embedding methods to the task of determining the compositionality of English multiword expressions (\"MWEs\"), specifically noun-noun and adjectivenoun pairs, to test their performance on data representing a range of compositionality ().", "labels": [], "entities": []}, {"text": "Compositionality prediction can be modeled as a regression task ( that involves mapping an MWE onto a continuous scale, representing its compositionality as a whole or with respect to each of its components.", "labels": [], "entities": [{"text": "Compositionality prediction", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.9412834346294403}]}, {"text": "For example, application form can be considered to be quite compositional, while sitting duck 1 is considered to be idiomatic or non-compositional.", "labels": [], "entities": []}, {"text": "Close shave 2 could be seen as partially compositional, heavily compositional with regards to the first word and less compositional with regards to the second.", "labels": [], "entities": []}, {"text": "In this study, we focus on predicting the compositionality of the MWE as a whole.", "labels": [], "entities": []}, {"text": "Although we conduct our experiments on English datasets, they can be applied to other languages with ease as we do not perform any kind of language-specific manipulation of the data.", "labels": [], "entities": []}, {"text": "The main contributions of this paper are: (i) we compare embeddings over 3 different MWE datasets, focusing on noun-noun and adjective-noun pairs; (ii) we experiment with 7 character-, word-, and document-level embedding models, including contextualised models; (iii) we show that, despite their success on a range of other tasks, recent embedding learning methods lag behind simple word2vec in capturing MWE non-compositionality.", "labels": [], "entities": [{"text": "MWE datasets", "start_pos": 85, "end_pos": 97, "type": "DATASET", "confidence": 0.7258546948432922}]}], "datasetContent": [{"text": "We used three datasets for our experiments, evaluating each model's performance using Pearson's correlation coefficient (r) to compare the similarity scores obtained with the annotated compositionality scores provided in the dataset.", "labels": [], "entities": [{"text": "Pearson's correlation coefficient (r)", "start_pos": 86, "end_pos": 123, "type": "METRIC", "confidence": 0.9137119650840759}]}, {"text": "DISCO ADJ The English dataset from the DiSCo shared task (Biemann and Giesbrecht, 2011) containing a total of 348 binary phrases, comprising adjective-noun, verb-noun subj , and verb-noun obj pairs, along with their overall compositionality rating ranging from 0 to 100.", "labels": [], "entities": [{"text": "DISCO ADJ", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.8828293681144714}, {"text": "DiSCo shared task", "start_pos": 39, "end_pos": 56, "type": "DATASET", "confidence": 0.7642801801363627}]}, {"text": "The phrases were extracted semi-automatically and their relations were assigned by patterns and checked manually.", "labels": [], "entities": []}, {"text": "The compositionality scores were collected from Amazon Mechanical Turk, where workers were presented 4-5 randomly sampled sentences from the UK English WACKy corpora.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk", "start_pos": 48, "end_pos": 70, "type": "DATASET", "confidence": 0.9737425645192465}, {"text": "UK English WACKy corpora", "start_pos": 141, "end_pos": 165, "type": "DATASET", "confidence": 0.7351236641407013}]}, {"text": "We focus on the 144 adjective-noun pairs in this study.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Mean (\u00b5) and standard deviation (\u03c3) of the  compositionality scores for the three datasets used in  this research, over a normalised range [0, 100].", "labels": [], "entities": [{"text": "Mean (\u00b5)", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9551060199737549}, {"text": "standard deviation (\u03c3)", "start_pos": 23, "end_pos": 45, "type": "METRIC", "confidence": 0.9635622382164002}]}, {"text": " Table 2: Pearson correlation coefficient for compositionality prediction results on the RAMISCH dataset.", "labels": [], "entities": [{"text": "Pearson correlation coefficient", "start_pos": 10, "end_pos": 41, "type": "METRIC", "confidence": 0.9303238193194071}, {"text": "compositionality prediction", "start_pos": 46, "end_pos": 73, "type": "TASK", "confidence": 0.9125041663646698}, {"text": "RAMISCH dataset", "start_pos": 89, "end_pos": 104, "type": "DATASET", "confidence": 0.9162181317806244}]}, {"text": " Table 3: Pearson correlation coefficient for composi- tionality prediction results on the REDDY dataset.", "labels": [], "entities": [{"text": "Pearson correlation coefficient", "start_pos": 10, "end_pos": 41, "type": "METRIC", "confidence": 0.9296236435572306}, {"text": "composi- tionality prediction", "start_pos": 46, "end_pos": 75, "type": "TASK", "confidence": 0.6096797063946724}, {"text": "REDDY dataset", "start_pos": 91, "end_pos": 104, "type": "DATASET", "confidence": 0.9211209416389465}]}, {"text": " Table 4: Pearson correlation coefficient for composi- tionality prediction results on the DISCO ADJ dataset.", "labels": [], "entities": [{"text": "Pearson correlation coefficient", "start_pos": 10, "end_pos": 41, "type": "METRIC", "confidence": 0.9277867674827576}, {"text": "composi- tionality prediction", "start_pos": 46, "end_pos": 75, "type": "TASK", "confidence": 0.6061234772205353}, {"text": "DISCO ADJ dataset", "start_pos": 91, "end_pos": 108, "type": "DATASET", "confidence": 0.9544695019721985}]}]}