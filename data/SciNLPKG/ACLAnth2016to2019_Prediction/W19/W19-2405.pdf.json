{"title": [], "abstractContent": [{"text": "Story infilling involves predicting words to go into a missing span from a story.", "labels": [], "entities": [{"text": "Story infilling", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.6108545511960983}]}, {"text": "This challenging task has the potential to transform interactive tools for creative writing.", "labels": [], "entities": []}, {"text": "However, state-of-the-art conditional language models have trouble balancing fluency and coherence with novelty and diversity.", "labels": [], "entities": []}, {"text": "We address this limitation with a hierarchical model which first selects a set of rare words and then generates text conditioned on that set.", "labels": [], "entities": []}, {"text": "By relegating the high entropy task of picking rare words to a word-sampling model, the second-stage model conditioned on those words can achieve high fluency and coherence by searching for likely sentences, without sacrificing diversity.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent advances in language modeling have made considerable progress towards the automatic generation of fluent text.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.7137473076581955}, {"text": "automatic generation of fluent text", "start_pos": 81, "end_pos": 116, "type": "TASK", "confidence": 0.7895934581756592}]}, {"text": "This evolution has sparked the development of tools to assist human writers.", "labels": [], "entities": []}, {"text": "For instance, suggest generating short stories from high-level prompts, study the interaction of human and language models for creative writing, and propose an interactive control of story lines.", "labels": [], "entities": []}, {"text": "In addition, products such as Grammarly offer suggestions to improve grammar and wording.", "labels": [], "entities": []}, {"text": "Our work is concerned with story infilling.", "labels": [], "entities": [{"text": "story infilling", "start_pos": 27, "end_pos": 42, "type": "TASK", "confidence": 0.716762900352478}]}, {"text": "We envision this task as a step towards a suggestion tool to help writers interactively replace text spans.", "labels": [], "entities": []}, {"text": "Text infilling, a form of cloze task, involves removing sequences of words from text and asking fora replacement.", "labels": [], "entities": []}, {"text": "Compared to traditional left-to-right language modeling, automatic infilling interacts well with human text revision * Work performed while a Google Student Researcher.", "labels": [], "entities": [{"text": "human text revision", "start_pos": 97, "end_pos": 116, "type": "TASK", "confidence": 0.7011953790982565}]}, {"text": "['dew he found it in the mountain, and all the while he saw upon the green grass, and upon the top of all he found it in the morning, and gathered it up in the dew of the fountain, and it was ...", "labels": [], "entities": []}, {"text": "In the morning when he awoke, he began to search over hill and dale for this pretty flower; and eight long days he sought for it in vain: but on the ninth day , early in the morning, he found the beautiful purple flower; and in the middle of it was a large dewdrop, as big as a costly pearl.", "labels": [], "entities": []}, {"text": "Then he plucked the flower, and set out and travelled day and night, till he came again to the castle.", "labels": [], "entities": []}], "datasetContent": [{"text": "Experimental Setup We train on the Toronto Book Corpus (TBC) concatenated with Project Gutenberg, fora total of over 1.2 billion words after filtering our exact duplicate books.", "labels": [], "entities": [{"text": "Toronto Book Corpus (TBC)", "start_pos": 35, "end_pos": 60, "type": "DATASET", "confidence": 0.9680090645949045}]}, {"text": "We withheld 5% of all books for validation and test.", "labels": [], "entities": []}, {"text": "Training examples consist of a 5 to 50 tokenlong target sequence, with 50 tokens of context on each side.", "labels": [], "entities": []}, {"text": "We experimented with longer context windows but did not observe strong improvement on automated metrics.", "labels": [], "entities": []}, {"text": "We do not force any alignment along linguistic boundaries, so context windows and gaps may start or end in the middle of a  sentence or even word.", "labels": [], "entities": []}, {"text": "Evaluation Automatic evaluation is performed on 10,000 spans of length 15-30 from our validation set.", "labels": [], "entities": []}, {"text": "We report the sub-token perplexity of the reference and evaluate generation diversity with distk, the total number of distinct k-grams, divided by the total number of tokens produced overall examples in the validation set.", "labels": [], "entities": []}, {"text": "Three children's books were chosen from the validation set for human evaluation.", "labels": [], "entities": []}, {"text": "We hoped that the more concise prose in children's literature would make it easier for evaluators to quickly spot mistakes.", "labels": [], "entities": []}, {"text": "We selected paragraphs of length 50 to 130 subwords, and randomly replaced a span of 15 to 30 subwords from anywhere in the paragraph.", "labels": [], "entities": []}, {"text": "Human raters were shown two instances of each paragraph, identical except for the selected span, which may have come from one model or another.", "labels": [], "entities": []}, {"text": "The modified span was highlighted in each paragraph, and evaluators were asked which highlighted excerpt seemed better (more on-topic, exciting, and/or coherent) given the context.", "labels": [], "entities": []}, {"text": "Further details about the task are in the the Appendix.", "labels": [], "entities": [{"text": "Appendix", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.6806405186653137}]}, {"text": "Results As our motivation is to generate diverse text without compromising on coherence and fluency, we evaluate the baseline non-hierarchical approach at different level of diversity by considering different decoding strategies.", "labels": [], "entities": []}, {"text": "Conditional language models generate text word-by-word, either through beam search, i.e. approximating the maximum-a-posteriori sequence), or through sampling.", "labels": [], "entities": []}, {"text": "Beam search often leads to repetitive, \"safe\" outputs, while random sampling results in more diverse outputs that mat suffer from fluency and coherence issues.", "labels": [], "entities": [{"text": "Beam search", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.7915658354759216}]}, {"text": "While some work has incorporated a temperature parameter during random sampling to control the tradeoff between diversity and quality, we instead consider restricting sampling to the top-10 next words (sampling10)) as preliminary experiments indicated this method produces higher quality outputs for equivalent levels of diversity.", "labels": [], "entities": []}, {"text": "shows that as expected, sampling results in the richest diversity, beam search the poorest, and sampling10 falls between the two.", "labels": [], "entities": []}, {"text": "In human evaluation, sampling10 and beam outperform or perform equivalently to our Hier-3 method, but have lower diversity.", "labels": [], "entities": []}, {"text": "Unrestricted sampling performs much worse.", "labels": [], "entities": []}, {"text": "In our hierarchical approach (HIER), we achieve both diverse and fluent generation by using random sampling for the word prediction model, where diversity is more critical than fluency, and beam search for the second-stage model.", "labels": [], "entities": [{"text": "word prediction", "start_pos": 116, "end_pos": 131, "type": "TASK", "confidence": 0.7989839911460876}]}, {"text": "evaluates HIER in two settings, conditioning on all words from the word prediction model or conditioned only on the first three predicted words.", "labels": [], "entities": []}, {"text": "Human raters strongly prefer the model conditioned on only three words.", "labels": [], "entities": []}, {"text": "We also show that humans rate generation of HIER-3 comparably to BASE/sampling10 while our model achieves much higher diversity (dist-1 and dist-2).", "labels": [], "entities": [{"text": "BASE", "start_pos": 65, "end_pos": 69, "type": "METRIC", "confidence": 0.9989845156669617}]}, {"text": "Our model therefore achieves its goal of diverse and fluent outputs for story infilling.", "labels": [], "entities": [{"text": "story infilling", "start_pos": 72, "end_pos": 87, "type": "TASK", "confidence": 0.727750837802887}]}], "tableCaptions": [{"text": " Table 2: Automated and human evaluation for our method (Hier) against baseline (base). Human evaluation reports  A/B testing against Hier-3, along with chi-square test p-values.", "labels": [], "entities": []}]}