{"title": [{"text": "Predicates as Boxes in Bayesian Semantics for Natural Language", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we present a Bayesian approach to natural language semantics.", "labels": [], "entities": [{"text": "natural language semantics", "start_pos": 49, "end_pos": 75, "type": "TASK", "confidence": 0.6425383985042572}]}, {"text": "Our main focus is on the inference task in an environment where judgments require probabilistic reasoning.", "labels": [], "entities": []}, {"text": "We treat nouns, verbs, adjectives, etc.", "labels": [], "entities": []}, {"text": "as unary predicates, and we model them as boxes in a bounded domain.", "labels": [], "entities": []}, {"text": "We apply Bayesian learning to satisfy constraints expressed as premises.", "labels": [], "entities": []}, {"text": "In this way we construct a model, by specifying boxes for the predicates.", "labels": [], "entities": []}, {"text": "The probability of the hypothesis (the conclusion) is evaluated against the model that incorporates the premises as constraints.", "labels": [], "entities": []}], "introductionContent": [{"text": "interpret natural language expressions as probabilistic programs, which are evaluated through Markov chain Monte Carlo (MCMC) methods.", "labels": [], "entities": []}, {"text": "This technique assigns meanings to various phenomena, including graded adjectives.", "labels": [], "entities": []}, {"text": "combine this approach with the idea (present in much recent computational linguistic literature) (but which can be traced back to) that individuals are encoded as points in a multidimensional space.", "labels": [], "entities": []}, {"text": "Using this approach they construct Bayesian models of inference for natural language.", "labels": [], "entities": []}, {"text": "While these models work well for many cases, they generate serious complexity problems for others.", "labels": [], "entities": []}, {"text": "In this paper we propose a simplified geometric model that allows us to reduce the need for sampling, and the complexity that it can create.", "labels": [], "entities": []}, {"text": "In certain cases we eliminate sampling altogether.", "labels": [], "entities": []}, {"text": "We model properties as (unions of) boxes, and we identify individuals as points.", "labels": [], "entities": []}, {"text": "To estimate the probability of a predication being true, we determine the likelihood that an individual, a set of individuals, or another property is contained in a box corresponding to a predicate.", "labels": [], "entities": []}, {"text": "This framework gives us a more tractable procedure for evaluating the probability of sentences exhibiting the same syntactic and semantic constructions that the approaches proposed by cover, but it extends to all representations of predicates in a probabilistic language.", "labels": [], "entities": []}, {"text": "The alternative system for evaluating arguments that we propose brings us closer to the prospect of a wide coverage probabilistic natural language inference system.", "labels": [], "entities": []}, {"text": "Such a system will be useful for the Recognising Textual Entailment task (, which encompasses non-logical arguments based on real world knowledge and lexical semantics.", "labels": [], "entities": [{"text": "Recognising Textual Entailment task", "start_pos": 37, "end_pos": 72, "type": "TASK", "confidence": 0.8664373159408569}]}, {"text": "It can also be applied in other NLP tasks that rely on probabilistic assessment of inference.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}