{"title": [{"text": "Distributional semantics in the real world: building word vector representations from a truth-theoretic model", "labels": [], "entities": []}], "abstractContent": [{"text": "Distributional semantics models (DSMs) are known to produce excellent representations of word meaning, which correlate with a range of behavioural data.", "labels": [], "entities": []}, {"text": "As lexical representations, they have been said to be fundamentally different from truth-theoretic models of semantics, where meaning is defined as a correspondence relation to the world.", "labels": [], "entities": []}, {"text": "There are two main aspects to this difference: a) DSMs are built over corpus data which mayor may not reflect 'what is in the world'; b) they are built from word co-occurrences, that is, from lexical types rather than entities and sets.", "labels": [], "entities": []}, {"text": "In this paper, we inspect the properties of a distributional model built over a set-theoretic approximation of 'the real world'.", "labels": [], "entities": []}, {"text": "To achieve this, we take the annotation a large database of images marked with objects, attributes and relations, convert the data into a representation akin to first-order logic and build several distributional models using various combinations of features.", "labels": [], "entities": []}, {"text": "We evaluate those models over both relatedness and similarity datasets, demonstrating their effectiveness in standard evaluations.", "labels": [], "entities": []}, {"text": "This allows us to conclude that, despite prior claims, truth-theoretic models are good candidates for building graded lexical representations of meaning.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, distributional semantics models (DSMs) have received close attention from the linguistic community.", "labels": [], "entities": []}, {"text": "One reason for this is that they are known to produce excellent representations of lexical meaning, which account for similarity and polysemy and correlate well with a range of behavioural data.", "labels": [], "entities": [{"text": "similarity", "start_pos": 118, "end_pos": 128, "type": "METRIC", "confidence": 0.9668497443199158}]}, {"text": "DSMs are built on the basis of word co-occurrences in large corpora, stemming from the hypothesis that words cooccurring in similar contexts tend to share their meaning.", "labels": [], "entities": []}, {"text": "As such, they are fundamentally different from truth-theoretic models of semantics, where meaning is defined as a correspondence relation between predicates and the world.", "labels": [], "entities": []}, {"text": "This difference can be explicated further by noting two features of DSMs.", "labels": [], "entities": []}, {"text": "First, they are built over corpus data which mayor may not reflect 'what is in the world') -and consequently does not reflect human experience gained from real world data ().", "labels": [], "entities": []}, {"text": "Second, they are built from word co-occurrences, that is, from lexical types rather than entities and sets.", "labels": [], "entities": []}, {"text": "In contrast, formal models account for denotation and set-theoretic aspects of language, but they are often said to lack the ability to account for lexical similarity and gradedness.", "labels": [], "entities": []}, {"text": "This has been the basis for wanting to combine formal and distributional semantics in the past (: the role of DSMs, it is claimed, is to bring the lexicon to denotational approaches to meaning.", "labels": [], "entities": []}, {"text": "In the present paper, we build a large set-theoretic model as an approximation of \"the real world\", and show that quality vector representations can in fact be extracted from it.", "labels": [], "entities": []}, {"text": "To obtain our model, we take the annotation of the Visual Genome (henceforth VG), a large database of images annotated with objects, attributes and relations (, and regard this data as an informative, although incomplete, description of the world.", "labels": [], "entities": []}, {"text": "We convert the annotated data into a representation akin to some underspecified first-order logic.", "labels": [], "entities": []}, {"text": "From this representation, we build several DSMs from various aspects of the representation and inspect the properties of the created spaces.", "labels": [], "entities": []}, {"text": "We evaluate our models with both relatedness and similarity datasets).", "labels": [], "entities": []}, {"text": "Our work fits into attempts to bridge the gap between distributional and formal semantics.", "labels": [], "entities": []}, {"text": "The subfield of Formal Distributional Semantics (FDS,) includes efforts to a) investigate the mapping from distributional models to formal semantic models; b) enrich formal semantics with distributional data (; and c) account for particular logical phenomena in vector spaces, including composition amongst many others).", "labels": [], "entities": [{"text": "Formal Distributional Semantics (FDS", "start_pos": 16, "end_pos": 52, "type": "TASK", "confidence": 0.7274796605110169}]}, {"text": "We also note the relevance of the work on constructing distributional spaces from syntactically or semantically parsed data (e.g., which echoes the way we construct vector spaces from various types of predicative contexts.", "labels": [], "entities": []}, {"text": "In contrast to those efforts, however, our data is not a standard corpus reflecting word usage but a collection of logical forms expressing true sentences with respect to a model of the world.", "labels": [], "entities": []}, {"text": "Most similar to our endeavour is the work by, who also take multimodal datasets as a basis to learn denotations.", "labels": [], "entities": []}, {"text": "Their model is however created for the task of semantic inference and takes the extension of a word to be the set of situations it applies to.", "labels": [], "entities": [{"text": "semantic inference", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.7383965253829956}]}, {"text": "We introduce notions of entities and properties in our own model.", "labels": [], "entities": []}], "datasetContent": [{"text": "To measure the quality of constructed models, we evaluate them on two standard datasets: MEN and SimLex-999.", "labels": [], "entities": [{"text": "MEN", "start_pos": 89, "end_pos": 92, "type": "DATASET", "confidence": 0.8846306204795837}, {"text": "SimLex-999", "start_pos": 97, "end_pos": 107, "type": "DATASET", "confidence": 0.8916730880737305}]}, {"text": "The MEN dataset is supposed to capture the relatedness notion, which is defined as the relation between pairs of entities that are associated but not actually similar.", "labels": [], "entities": [{"text": "MEN dataset", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.8590272665023804}]}, {"text": "SimLex-999 accounts for similarity, which is defined as the relation between words which share physical or functional features, as well as categorical information (.", "labels": [], "entities": []}, {"text": "Both datasets are structured in the same way: they consist of word pairs human-coded for their level of association.", "labels": [], "entities": []}, {"text": "They respectively include 3000 (MEN) and 999 (SimLex) word pairs.", "labels": [], "entities": []}, {"text": "To evaluate our DSMs, we follow standard practice and compute the Spearman \u03c1 correlation between the cosine similarity scores given by the model and the gold annotation.", "labels": [], "entities": [{"text": "Spearman \u03c1 correlation", "start_pos": 66, "end_pos": 88, "type": "METRIC", "confidence": 0.9706061283747355}, {"text": "cosine similarity scores", "start_pos": 101, "end_pos": 125, "type": "METRIC", "confidence": 0.7329601049423218}]}, {"text": "To maximise comparability between different spaces and with text corpora, scores are given for raw co-occurrence matrices, and no dimensionality reduction or other optimization of the space is conducted.", "labels": [], "entities": []}, {"text": "Note that due to the size of VG, we cannot evaluate on all pairs in the datasets.", "labels": [], "entities": []}, {"text": "We show actual coverage in brackets next to the correlation scores.", "labels": [], "entities": [{"text": "coverage", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9789405465126038}, {"text": "correlation", "start_pos": 48, "end_pos": 59, "type": "METRIC", "confidence": 0.994814932346344}]}, {"text": "Trends are similar both for MEN and SimLex-999.", "labels": [], "entities": [{"text": "MEN", "start_pos": 28, "end_pos": 31, "type": "DATASET", "confidence": 0.9349536299705505}]}, {"text": "We get overall best results (highlighted in bold) for the models built using relations, situational information, and relations together with situations.", "labels": [], "entities": []}, {"text": "Other models have significantly lower quality, both for single features and for their combinations.", "labels": [], "entities": []}, {"text": "It should be noted that taking all the features together does not improve the quality of the space.", "labels": [], "entities": []}, {"text": "In the last column of we report the total number of co-occurrences in each variation of the world-based model.", "labels": [], "entities": []}, {"text": "They are included in order to make sure that we do not observe solely the effect of increasing the amount of data.", "labels": [], "entities": []}, {"text": "Indeed, models with the greatest number of co-occurrences show medium quality, and for some combinations of features the score even decreases with more data (e.g., compare the Hyp and Hyp + Sit models, where the MEN score stays more or less the same and the SimLex score  becomes lower).", "labels": [], "entities": []}, {"text": "Moreover, the Rel model shows the highest score on a moderately small amount of data for the MEN dataset, and for the SimLex-999 dataset the score is a bit lower, whereas the Rel + Hyp model becomes the best (though hypernyms come from outside the model).", "labels": [], "entities": [{"text": "MEN dataset", "start_pos": 93, "end_pos": 104, "type": "DATASET", "confidence": 0.9791338741779327}, {"text": "SimLex-999 dataset", "start_pos": 118, "end_pos": 136, "type": "DATASET", "confidence": 0.9502542018890381}]}, {"text": "To compare performance of our truth-theoretic models with traditional DSMs built from text corpora, we create count-based models from the English Wikipedia using a window of \u00b1 2 words around a target.", "labels": [], "entities": []}, {"text": "We modulate corpus size to roughly match the number of co-occurrences extracted from VG.", "labels": [], "entities": [{"text": "VG", "start_pos": 85, "end_pos": 87, "type": "DATASET", "confidence": 0.8579021692276001}]}, {"text": "Additionally, we train predictive models with Word2Vec () with the same number of co-occurrences as in the count-based variants.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 46, "end_pos": 54, "type": "DATASET", "confidence": 0.9451740980148315}]}, {"text": "We use the same window size of 2, and the dimensionality of vectors is set to 300.", "labels": [], "entities": []}, {"text": "The evaluation scores for different corpora sizes are shown in.", "labels": [], "entities": []}, {"text": "We can see that, in contrast with the VG models, the score for count-based models is dependent on the amount of data provided to the DSM, and generally lower for similar numbers of co-occurrences (scores are consistent with results reported by).", "labels": [], "entities": [{"text": "DSM", "start_pos": 133, "end_pos": 136, "type": "DATASET", "confidence": 0.9348579049110413}]}, {"text": "Predictive models are simply notable to construct high-quality word representations from such amount of data.", "labels": [], "entities": []}, {"text": "When we try to improve the quality of our best world-based model (Rel) by applying normalisation, dimensionality reduction (to 300 dimensions) and PPMI weighting, we reach scores of 0.6539 on MEN (847 pairs are evaluated because not all of the pairs in the evaluation dataset are present in the VG space) and 0.3353 on SimLex-999 (216 pairs evaluated).", "labels": [], "entities": [{"text": "MEN", "start_pos": 192, "end_pos": 195, "type": "DATASET", "confidence": 0.7571303844451904}, {"text": "VG space", "start_pos": 295, "end_pos": 303, "type": "DATASET", "confidence": 0.8956587612628937}, {"text": "SimLex-999", "start_pos": 319, "end_pos": 329, "type": "DATASET", "confidence": 0.9118807315826416}]}, {"text": "Whilst results are not directly comparable, we nevertheless note that the MEN score is close to the figure of 0.68 reported for the inter-annotator correlation on the full 3000 pairs.", "labels": [], "entities": [{"text": "MEN score", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.8562575578689575}]}, {"text": "5 It is also only a few points lower than the best score of 0.72 obtained by over 2.6B words (around 1600 times more data than in Rel on the basis of a \u00b12 word window size).", "labels": [], "entities": [{"text": "Rel", "start_pos": 130, "end_pos": 133, "type": "DATASET", "confidence": 0.8735935688018799}]}, {"text": "The SimLex figure is also well above the figure of 0.233 reported by on an SVD model trained over 150M words (\u2248 100 times more data).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Spearman \u03c1 correlation for various models on MEN and SimLex-999.", "labels": [], "entities": [{"text": "Spearman \u03c1 correlation", "start_pos": 10, "end_pos": 32, "type": "METRIC", "confidence": 0.7954853177070618}, {"text": "MEN", "start_pos": 55, "end_pos": 58, "type": "DATASET", "confidence": 0.9562920331954956}, {"text": "SimLex-999", "start_pos": 63, "end_pos": 73, "type": "DATASET", "confidence": 0.5734668970108032}]}, {"text": " Table 2: Spearman correlation on MEN and SimLex-999 datasets (Wikipedia spaces)", "labels": [], "entities": [{"text": "correlation", "start_pos": 19, "end_pos": 30, "type": "METRIC", "confidence": 0.5482404828071594}, {"text": "MEN and SimLex-999 datasets", "start_pos": 34, "end_pos": 61, "type": "DATASET", "confidence": 0.7790815681219101}]}]}