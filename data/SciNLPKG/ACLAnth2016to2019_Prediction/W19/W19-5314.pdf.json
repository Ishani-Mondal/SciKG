{"title": [{"text": "The University of Sydney's Machine Translation System for WMT19", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.7433108687400818}, {"text": "WMT19", "start_pos": 58, "end_pos": 63, "type": "TASK", "confidence": 0.8820421695709229}]}], "abstractContent": [{"text": "This paper describes the University of Syd-ney's submission of the WMT 2019 shared news translation task.", "labels": [], "entities": [{"text": "WMT 2019 shared news translation task", "start_pos": 67, "end_pos": 104, "type": "TASK", "confidence": 0.6634193162123362}]}, {"text": "We participated in the Finnish\u2192English direction and got the best BLEU(33.0) score among all the participants.", "labels": [], "entities": [{"text": "Finnish\u2192English direction", "start_pos": 23, "end_pos": 48, "type": "TASK", "confidence": 0.45923949778079987}, {"text": "BLEU(33.0) score", "start_pos": 66, "end_pos": 82, "type": "METRIC", "confidence": 0.8600666880607605}]}, {"text": "Our system is based on the self-attentional Transformer networks, into which we integrated the most recent effective strategies from academic research (e.g., BPE, back translation , multi-features data selection, data augmentation , greedy model ensemble, rerank-ing, ConMBR system combination, and post-processing).", "labels": [], "entities": [{"text": "BPE", "start_pos": 158, "end_pos": 161, "type": "METRIC", "confidence": 0.6726532578468323}, {"text": "back translation", "start_pos": 163, "end_pos": 179, "type": "TASK", "confidence": 0.6925669610500336}]}, {"text": "Furthermore, we propose a novel augmentation method Cycle Translation and a data mixture strategy Big/Small parallel construction to entirely exploit the synthetic corpus.", "labels": [], "entities": [{"text": "Cycle Translation", "start_pos": 52, "end_pos": 69, "type": "TASK", "confidence": 0.7155881375074387}]}, {"text": "Extensive experiments show that adding the above techniques can make continuous improvements of the BLEU scores, and the best result outperforms the baseline (Transformer ensemble model trained with the original parallel corpus) by approximately 5.3 BLEU score, achieving the state-of-the-art performance.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 100, "end_pos": 104, "type": "METRIC", "confidence": 0.9990890026092529}, {"text": "BLEU", "start_pos": 250, "end_pos": 254, "type": "METRIC", "confidence": 0.9985294342041016}]}], "introductionContent": [{"text": "Neural machine translation (NMT), as a succinct end-to-end paradigm, has resulted in massive leap in state-of-the-art performances for many language pairs).", "labels": [], "entities": [{"text": "Neural machine translation (NMT)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.828245202700297}]}, {"text": "Among these encoder-decoder networks, the Transformer (, which solely uses along attention mechanism and eschews the recurrent or convolutional networks, leads to state-of-the-art translation quality and fast convergence speed (.", "labels": [], "entities": []}, {"text": "Although many Transformer-based variants are proposed (e.g.,, sparse-transformer (), our preliminary experiments show that their performances are unstable compared to the traditional # cycle translated sample sentence pair 1 She stuck to her principles even when some suggest that in an environment often considered devoid of such thing there are little point.", "labels": [], "entities": []}, {"text": "2 She insists on her own principles, even if some people think that it doesn't make sense in an environment that is often considered to be absent.", "labels": [], "entities": []}, {"text": "Example of difference between original sentence (line 1) and cycle translated result (line 2).", "labels": [], "entities": []}, {"text": "Pretrained BERT model using all available English corpora show that the Loss decreased from 6.98 to 1.52.", "labels": [], "entities": [{"text": "BERT", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.9900845289230347}, {"text": "the", "start_pos": 68, "end_pos": 71, "type": "METRIC", "confidence": 0.9782688021659851}, {"text": "Loss", "start_pos": 72, "end_pos": 76, "type": "METRIC", "confidence": 0.7005152106285095}]}, {"text": "Traditional Transformer therefore was employed as our baseline system.", "labels": [], "entities": []}, {"text": "In this paper, we summarize the USYD NMT systems for the WMT 2019 Finnish\u2192English (FI\u2192EN) translation task.", "labels": [], "entities": [{"text": "USYD NMT", "start_pos": 32, "end_pos": 40, "type": "DATASET", "confidence": 0.8815006017684937}, {"text": "WMT 2019 Finnish\u2192English (FI\u2192EN) translation task", "start_pos": 57, "end_pos": 106, "type": "TASK", "confidence": 0.6324512834350268}]}, {"text": "As the limitation of time and computation resources, we only participated in one challenging task FI\u2192EN, which lags behind other language pairs in translation performance (.", "labels": [], "entities": [{"text": "FI", "start_pos": 98, "end_pos": 100, "type": "METRIC", "confidence": 0.8931382298469543}]}, {"text": "We introduce our system with three parts.", "labels": [], "entities": []}, {"text": "First, at data level, we find that the data quality of both parallel and monolingual is unbalanced (i.e., contains a large number of low quality sentences).", "labels": [], "entities": []}, {"text": "Thus, we apply several features to select the data after pre-processing, for example, language models, alignment scores etc.", "labels": [], "entities": []}, {"text": "Meanwhile, in order to fully utilize monolingual corpus, not only back translation () is adopted to back translate the high quality monolingual sentences with target-to-source(T2S) model, we also propose Cycle Translation to improve the low-quality sentences, in turn resulting in corresponding high-quality back translation results.", "labels": [], "entities": [{"text": "Cycle Translation", "start_pos": 204, "end_pos": 221, "type": "TASK", "confidence": 0.6895143240690231}]}, {"text": "Note that unlike text style transfer task which transfers text to specific style (e.g., political: The schematic structure of the three main stages of the USYD-NMT.", "labels": [], "entities": [{"text": "text style transfer", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.6198752125104269}, {"text": "USYD-NMT", "start_pos": 155, "end_pos": 163, "type": "DATASET", "confidence": 0.9384421706199646}]}, {"text": "They are data preparation stage, model training stage and inference phrase.", "labels": [], "entities": [{"text": "data preparation", "start_pos": 9, "end_pos": 25, "type": "TASK", "confidence": 0.7841319739818573}]}, {"text": "For brevity, here Mono, Para, and Valid represent the monolingual, parallel and validation data respectively.", "labels": [], "entities": [{"text": "Para", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.9369882941246033}]}, {"text": "slant, gender), we aim to improve the fluency of sentences, for instance, through cycle translation, low quality sentence in becomes more fluent in terms of language model score.", "labels": [], "entities": [{"text": "cycle translation", "start_pos": 82, "end_pos": 99, "type": "TASK", "confidence": 0.7041414976119995}]}, {"text": "The top diagram of depicts data preparation process concretely.", "labels": [], "entities": [{"text": "data preparation", "start_pos": 27, "end_pos": 43, "type": "TASK", "confidence": 0.729767382144928}]}, {"text": "As to model training in the middle part of, we empirically introduced Big/Small parallel construction strategy to construct training data for different models.", "labels": [], "entities": []}, {"text": "The intuition is all the data are advantageous and can be fully exploited by different models, thus we train 8 Transformer base models (M small \u00d7 8) by using different small scale corpus constructed by small parallel construction method and a Transformer big model (M big \u00d7 1) based on the big parallel construction method.", "labels": [], "entities": []}, {"text": "In the meantime, a right-to-left model (M r2l ) is trained.", "labels": [], "entities": []}, {"text": "In addition, in inference phrase, we comprehensively consider the ensemble strategies at model level, sentence level and word level.", "labels": [], "entities": []}, {"text": "For model level ensemble, while brutal ensemble top-N or last-M models may improve translation performance, it is difficult to obtain the optimal result.", "labels": [], "entities": [{"text": "translation", "start_pos": 83, "end_pos": 94, "type": "TASK", "confidence": 0.962186872959137}]}, {"text": "Hence we employ Greedy Model Selection based Ensembling (GMSE) ().", "labels": [], "entities": [{"text": "Greedy Model Selection based Ensembling (GMSE)", "start_pos": 16, "end_pos": 62, "type": "METRIC", "confidence": 0.7872650995850563}]}, {"text": "For sentence level ensemble, we keep top n-best for multi-features reranking.", "labels": [], "entities": []}, {"text": "And for word aspect, we adopt the confusion network decoding () with using the consensus network minimum Bayes risk (MBR) criterion (.", "labels": [], "entities": [{"text": "word aspect", "start_pos": 8, "end_pos": 19, "type": "TASK", "confidence": 0.7857265174388885}, {"text": "consensus network minimum Bayes risk (MBR) criterion", "start_pos": 79, "end_pos": 131, "type": "METRIC", "confidence": 0.7477711935838064}]}, {"text": "After combination, a postprocessing algorithm is employed to correct inconsistent number and years between the source and target sentences.", "labels": [], "entities": []}, {"text": "The bottom part of shows the inference process.", "labels": [], "entities": []}, {"text": "Our omnivorous model achieved the best BLEU () scores among submitted systems, demonstrating the effectiveness of the proposed approach.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 39, "end_pos": 43, "type": "METRIC", "confidence": 0.9992712140083313}]}, {"text": "Theoretically, our approach is not specific to the Finnish\u2192English language pair, i.e., it is universal and effective for any language pairs.", "labels": [], "entities": []}, {"text": "The remainder of this article is organized as follows: Section 2 will describe each component of the system.", "labels": [], "entities": []}, {"text": "In Section 3, we introduce the data preparing details.", "labels": [], "entities": []}, {"text": "Then, the experimental results are showed in Section 4.", "labels": [], "entities": []}, {"text": "Finally, we conclude in Section 5.: Model differences between base and big.", "labels": [], "entities": []}], "datasetContent": [{"text": "The metric we employed is detokenized casesensitive BLEU score.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 52, "end_pos": 62, "type": "METRIC", "confidence": 0.9855025112628937}]}, {"text": "news-test2018 is utilized as validation set and test set is officially released news-test2019.", "labels": [], "entities": [{"text": "news-test2018", "start_pos": 0, "end_pos": 13, "type": "DATASET", "confidence": 0.9319448471069336}]}, {"text": "Training set, validation set and test set are processed consistently.", "labels": [], "entities": []}, {"text": "Both Finnish and English sentences are performed tokenization and truecasing with Moses scripts (.", "labels": [], "entities": []}, {"text": "In order to limit the size of vocabulary of NMT models, we adopted byte pair encoding (BPE) () with 50k operations for each side.", "labels": [], "entities": [{"text": "byte pair encoding (BPE)", "start_pos": 67, "end_pos": 91, "type": "METRIC", "confidence": 0.64735047519207}]}, {"text": "All the model we trained are optimized with Adam ().", "labels": [], "entities": []}, {"text": "Larger beam size may worsen translation quality, thus we set beam size=10 for each model.", "labels": [], "entities": [{"text": "translation", "start_pos": 28, "end_pos": 39, "type": "TASK", "confidence": 0.9570717811584473}]}, {"text": "All models were trained on 4 NVIDIA V100 GPUs.", "labels": [], "entities": []}, {"text": "In order to find the optimal threshold in cycle translation procedure, we first report our experimental results on validation data set with different thresholds, which ranges from [0%, 25%, 50%, 75%].", "labels": [], "entities": [{"text": "cycle translation", "start_pos": 42, "end_pos": 59, "type": "TASK", "confidence": 0.6720695197582245}]}, {"text": "Intuitively, the quality improvement of monolingual sentences afforded by cycle translation could bring better synthetic parallel data, subsequently leading to more accurate translation model.", "labels": [], "entities": [{"text": "cycle translation", "start_pos": 74, "end_pos": 91, "type": "TASK", "confidence": 0.7640688419342041}]}, {"text": "Thus, this ablation experiment was trained with synthetic parallel corpus only with different cycle translation ratios on Transformer base model.", "labels": [], "entities": []}, {"text": "As is shown in, when cycle translation threshold is 50%, the model could achieve the relatively best performance.", "labels": [], "entities": []}, {"text": "We therefore set the cycle translation ratio to 50% in our following main experiment.", "labels": [], "entities": []}, {"text": "Our main experiment is shown in, our baseline system is developed with the M small configuration using the original parallel corpus and last-20 ensemble strategy.", "labels": [], "entities": []}, {"text": "Unsurprisingly, the baseline system relatively performs the worst in.", "labels": [], "entities": []}, {"text": "The M small configuration trained with selected parallel data improves BLEU by +0.7 points.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 71, "end_pos": 75, "type": "METRIC", "confidence": 0.9996830224990845}]}, {"text": "According to exp., adding these components can lead to continuous improvements.", "labels": [], "entities": []}, {"text": "Notably, with Cycle Translation and Big/Small parallel construction strategy, our system could obtains +3.55 significant improvement.", "labels": [], "entities": [{"text": "Cycle Translation", "start_pos": 14, "end_pos": 31, "type": "TASK", "confidence": 0.7599412500858307}]}, {"text": "show that with performing GMSE, multi-features reranking, ConMBR system combination and post-processing, our system further improved the BLEU score from 30.9 to 33.0 on the official data set news-test2019, which substantially outperforms the baseline by 5.3 BLEU score.", "labels": [], "entities": [{"text": "GMSE", "start_pos": 26, "end_pos": 30, "type": "METRIC", "confidence": 0.8652873039245605}, {"text": "ConMBR", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.7017068862915039}, {"text": "BLEU score", "start_pos": 137, "end_pos": 147, "type": "METRIC", "confidence": 0.9847760796546936}, {"text": "official data set news-test2019", "start_pos": 173, "end_pos": 204, "type": "DATASET", "confidence": 0.8738230615854263}, {"text": "BLEU", "start_pos": 258, "end_pos": 262, "type": "METRIC", "confidence": 0.9990190267562866}]}], "tableCaptions": [{"text": " Table 2: Model differences between base and big.", "labels": [], "entities": []}, {"text": " Table 6: FI\u2192EN Results on newstest2018 and newstest2019. The submitted system is the last one.", "labels": [], "entities": [{"text": "FI", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9461013078689575}, {"text": "newstest2018", "start_pos": 27, "end_pos": 39, "type": "DATASET", "confidence": 0.9598590135574341}, {"text": "newstest2019", "start_pos": 44, "end_pos": 56, "type": "DATASET", "confidence": 0.9142661690711975}]}, {"text": " Table 7: Different experimental settings that employed  different cycle translation thresholds. Val. denotes that  the results are reported on validation set.", "labels": [], "entities": [{"text": "Val", "start_pos": 97, "end_pos": 100, "type": "METRIC", "confidence": 0.969651997089386}]}]}