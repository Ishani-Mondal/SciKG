{"title": [], "abstractContent": [{"text": "Ellipsis is very common in language.", "labels": [], "entities": []}, {"text": "It's necessary for natural language processing to restore the elided elements in a sentence.", "labels": [], "entities": []}, {"text": "However , there's only a few corpora annotating the ellipsis, which draws back the automatic detection and recovery of the ellipsis.", "labels": [], "entities": []}, {"text": "This paper introduces the annotation of ellipsis in Chi-nese sentences, using a novel graph-based representation Abstract Meaning Representation (AMR), which has a good mechanism to restore the elided elements manually.", "labels": [], "entities": [{"text": "Abstract Meaning Representation (AMR)", "start_pos": 113, "end_pos": 150, "type": "TASK", "confidence": 0.6141581187645594}]}, {"text": "We annotate 5,000 sentences selected from Chinese TreeBank (CTB).", "labels": [], "entities": [{"text": "Chinese TreeBank (CTB)", "start_pos": 42, "end_pos": 64, "type": "DATASET", "confidence": 0.9757554650306701}]}, {"text": "We find that 54.98% of sentences have ellipses.", "labels": [], "entities": []}, {"text": "92% of the ellipses are restored by copying the antecedents' concepts. and 12.9% of them are the new added concepts.", "labels": [], "entities": []}, {"text": "In addition, we find that the elided element is a word or phrase inmost cases, but sometimes only the head of a phrase or parts of a phrase, which is rather hard for the automatic recovery of ellipsis.", "labels": [], "entities": []}], "introductionContent": [{"text": "With the rapid development of artificial intelligence (AI), natural language progressing is one of significant applications of AI, and it has made outstanding progress in several basic techniques, such as syntactic analysis and semantic analysis.", "labels": [], "entities": [{"text": "natural language progressing", "start_pos": 60, "end_pos": 88, "type": "TASK", "confidence": 0.6743023792902628}, {"text": "syntactic analysis", "start_pos": 205, "end_pos": 223, "type": "TASK", "confidence": 0.7221274673938751}, {"text": "semantic analysis", "start_pos": 228, "end_pos": 245, "type": "TASK", "confidence": 0.7736838459968567}]}, {"text": "The former is relatively mature, while the latter needs more efforts ().", "labels": [], "entities": []}, {"text": "For example, in the SRL(Semantic Role Labeling)-only task of the CoNLL 2009, the highest score in English is 86.2% and in Chinese it is 78.6%.", "labels": [], "entities": [{"text": "SRL(Semantic Role Labeling)-", "start_pos": 20, "end_pos": 48, "type": "TASK", "confidence": 0.7453242689371109}, {"text": "CoNLL 2009", "start_pos": 65, "end_pos": 75, "type": "DATASET", "confidence": 0.8984460830688477}]}, {"text": "In addition, a common issue for the current semantic parser is that they ignore the elided element which is not overt in the surface form, but necessary in the understanding of the sentence.", "labels": [], "entities": []}, {"text": "That elided element is more often referred as ellipsis in linguistic.", "labels": [], "entities": []}, {"text": "Ellipsis is a common linguistic phenomenon across languages.", "labels": [], "entities": []}, {"text": "The traditional linguistic researches pay more attention to the formal construction, and don't regard ellipsis as an important factor.", "labels": [], "entities": []}, {"text": "Although some theoretical achievements have been made in the classifications and restrictions of ellipsis.", "labels": [], "entities": []}, {"text": "There are still debates in the definition of ellipsis, the identity constraint between antecedents and the elided element etc.", "labels": [], "entities": []}, {"text": "Most current corpora don't annotate the elided element.", "labels": [], "entities": []}, {"text": "A few corpora view ellipsis as an expediency for some irregular sentences, and annotate the elided element roughly.", "labels": [], "entities": []}, {"text": "Such as Penn Treebank (PTB for short), Chinese Treebank (CTB) (), Prague Dependency TreeBank (PDT) () and Universal.", "labels": [], "entities": [{"text": "Penn Treebank (PTB", "start_pos": 8, "end_pos": 26, "type": "DATASET", "confidence": 0.9662805944681168}, {"text": "Chinese Treebank (CTB)", "start_pos": 39, "end_pos": 61, "type": "DATASET", "confidence": 0.9574135184288025}, {"text": "Prague Dependency TreeBank (PDT)", "start_pos": 66, "end_pos": 98, "type": "DATASET", "confidence": 0.9133944014708201}, {"text": "Universal", "start_pos": 106, "end_pos": 115, "type": "DATASET", "confidence": 0.87911456823349}]}, {"text": "It is noticeable that build a treebank with focusing on ellipsis in context for Chinese.", "labels": [], "entities": []}, {"text": "But the corpus only contains 572 sentences from a microblog corpus, and the annotations exclude the elided words which can't be said but play an important role in the understanding of the sentence.", "labels": [], "entities": []}, {"text": "This paper uses a novel framework to restore the elided elements in the sentence, which is named Abstract Meaning Representation (AMR)(.", "labels": [], "entities": [{"text": "Abstract Meaning Representation (AMR)(", "start_pos": 97, "end_pos": 135, "type": "METRIC", "confidence": 0.7042886316776276}]}, {"text": "AMR represents the whole sentence meaning with concepts, which are mainly abstracted from its corresponding words occurring in the sentence.", "labels": [], "entities": []}, {"text": "Based on AMR, Chinese AMR (CAMR) makes some adaptations to accommodate Chinese better.", "labels": [], "entities": [{"text": "Chinese AMR (CAMR)", "start_pos": 14, "end_pos": 32, "type": "DATASET", "confidence": 0.7598306059837341}]}, {"text": "What's more, CAMR develops corresponding restoration methods for different types of ellipses, which makes the restoration more reasonable and complete.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we discuss the definition of ellipsis and gives a broader definition, which refers to all phenomena wherein the elided elements are necessary for the meaning of the sentence but not overt in the sentence.", "labels": [], "entities": []}, {"text": "In addition, we introduce the representation for ellipsis in PTB, PDT.", "labels": [], "entities": [{"text": "PTB", "start_pos": 61, "end_pos": 64, "type": "DATASET", "confidence": 0.9516239762306213}, {"text": "PDT", "start_pos": 66, "end_pos": 69, "type": "DATASET", "confidence": 0.8947760462760925}]}, {"text": "In Section 3, we describe three methods to restore ellipsis in CAMR.", "labels": [], "entities": [{"text": "CAMR", "start_pos": 63, "end_pos": 67, "type": "TASK", "confidence": 0.7131029963493347}]}, {"text": "And in Section 4 , we introduce the Chinese AMR corpus which includes 5,000 sentences from the newspaper portion of CTB. and we present some statistics and analysis based on this corpus.", "labels": [], "entities": [{"text": "Chinese AMR corpus", "start_pos": 36, "end_pos": 54, "type": "DATASET", "confidence": 0.914594034353892}, {"text": "newspaper portion of CTB.", "start_pos": 95, "end_pos": 120, "type": "DATASET", "confidence": 0.6690559536218643}]}, {"text": "Then we conclude our paper with a summary of our contribution in Section 5.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Proportion of ellipsis in Chinese AMR Corpus", "labels": [], "entities": [{"text": "Chinese AMR", "start_pos": 36, "end_pos": 47, "type": "DATASET", "confidence": 0.8562971353530884}]}, {"text": " Table 2: Frequency of three methods for ellipsis", "labels": [], "entities": []}, {"text": " Table 3: Average token count and concept count in per  sentence", "labels": [], "entities": [{"text": "Average token count", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.8384128212928772}]}, {"text": " Table 4: The added concept for ellipsis", "labels": [], "entities": []}]}