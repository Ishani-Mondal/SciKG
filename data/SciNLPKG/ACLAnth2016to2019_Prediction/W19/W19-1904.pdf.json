{"title": [], "abstractContent": [{"text": "In the medical domain and other scientific areas , it is often important to recognize different levels of hierarchy in entity mentions, such as those related to specific symptoms or diseases associated with different anatomical regions.", "labels": [], "entities": []}, {"text": "Unlike previous approaches, we build a transition-based parser that explicitly models an arbitrary number of hierarchical and nested mentions, and propose a loss that encourages correct predictions of higher-level mentions.", "labels": [], "entities": []}, {"text": "We further propose a set of modifier classes which introduces certain concepts that change the meaning of an entity, such as absence, or uncertainty about a given disease.", "labels": [], "entities": []}, {"text": "Our model achieves state-of-the-art results in medical entity recognition datasets, using both nested and hierarchical mentions.", "labels": [], "entities": [{"text": "medical entity recognition", "start_pos": 47, "end_pos": 73, "type": "TASK", "confidence": 0.6202190121014913}]}], "introductionContent": [{"text": "One of the most common studied tasks in NLP lies in extracting semantic information from unstructured text in the form of entities and detecting entity mentions across a single document, in particular where the mention is located (its span) and its corresponding classification or entity semantic type, such as person (PER), location (LOC), organization (ORG), etc.", "labels": [], "entities": []}, {"text": "The task of entity recognition has long been studied and applied to different higher level tasks such as question answering), coreference resolution, relation extraction (, entity linking () and event extraction).", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.7728916704654694}, {"text": "question answering", "start_pos": 105, "end_pos": 123, "type": "TASK", "confidence": 0.8219878375530243}, {"text": "coreference resolution", "start_pos": 126, "end_pos": 148, "type": "TASK", "confidence": 0.9514822959899902}, {"text": "relation extraction", "start_pos": 150, "end_pos": 169, "type": "TASK", "confidence": 0.8053691983222961}, {"text": "entity linking", "start_pos": 173, "end_pos": 187, "type": "TASK", "confidence": 0.7081346809864044}, {"text": "event extraction", "start_pos": 195, "end_pos": 211, "type": "TASK", "confidence": 0.7571207880973816}]}, {"text": "Most of the existing work in Named Entity Recognition and Classification focuses on flat mentions, usually corresponding to the longest outer mention (, or using nested mentions that can capture overlapping mentions within different nested levels (;.", "labels": [], "entities": [{"text": "Named Entity Recognition and Classification", "start_pos": 29, "end_pos": 72, "type": "TASK", "confidence": 0.7491840660572052}]}, {"text": "One of the main disadvantages of using simple independent classes to model different hierarchies is that there is no information that conveys an explicit hierarchical nature, in away that lower level classes help to disambiguate the nature of higher level classes.", "labels": [], "entities": []}, {"text": "The most common approach to circumvent this issue involves projecting each lower level class to an individual label throwing away all of the inherent structure of the ontology.", "labels": [], "entities": []}, {"text": "This approach is limited, since it does not propagate information to higher level classes and it does not use common information of all children in the ontology.", "labels": [], "entities": []}, {"text": "The ability to identify hierarchical entities is very useful in many fields, in particular in the medical domain, where we associate medication, symptoms and other pathological conditions with more specific subtypes giving a more refined classification.", "labels": [], "entities": []}, {"text": "Additionally, we introduce the concept of modifier classes that can alter the meaning of a given class.", "labels": [], "entities": []}, {"text": "Often, in medical records, the doctor states either the absence or presence of a particular condition, for that purpose we created a modifier level that acts on a particular class and is associated with the degree of relevance of that class, for example in the medical domain it may identify the absence or probability of certain symptoms/diseases, or refer to their duration (chronic, acute), etc.", "labels": [], "entities": []}, {"text": "This concept is of particular use if we consider a hierarchical model to identify where this modifier actuates.", "labels": [], "entities": []}, {"text": "We test our model against other state-of-the-art methods modelling nested mentions whose classification is defined by their projected lower levels.", "labels": [], "entities": []}, {"text": "We make use of hierarchical datasets in the medical field, where these notions are of extreme importance.", "labels": [], "entities": []}, {"text": "We evaluate our model using the GENIA () dataset, a bigger and more complex proprietary medical corpus (MED18) with higher hierarchical dependencies and modifier classes.", "labels": [], "entities": [{"text": "GENIA () dataset", "start_pos": 32, "end_pos": 48, "type": "DATASET", "confidence": 0.8765634695688883}]}, {"text": "To summarize, this paper makes the following contributions: \u2022 we introduce a novel Hierarchical and Nested Named Entity Recognition (HNNER) model based on a neural transition based approach, that is able to handle different levels of nested mentions and hierarchy, \u2022 we further propose a model that can learn from modifier classes, allowing to model more complex and fine grained relations, such as degree of importance/variants of each class.", "labels": [], "entities": [{"text": "Hierarchical and Nested Named Entity Recognition (HNNER)", "start_pos": 83, "end_pos": 139, "type": "TASK", "confidence": 0.7148536973529391}]}, {"text": "\u2022 we obtain state-of-the-art performance when compared with existing nested models with lower level projected labels (corresponding to the same hierarchical levels).", "labels": [], "entities": []}], "datasetContent": [{"text": "Datasets: We compare our HNNER model using different nested and hierarchical scenarios.", "labels": [], "entities": []}, {"text": "First, we compare against standard baselines for flat NER using the splits and the JNLPBA dataset, considering only flat and the topmost entities in the GENIA dataset (), following the same splits and entity types used by.", "labels": [], "entities": [{"text": "JNLPBA dataset", "start_pos": 83, "end_pos": 97, "type": "DATASET", "confidence": 0.971977949142456}, {"text": "GENIA dataset", "start_pos": 153, "end_pos": 166, "type": "DATASET", "confidence": 0.9772731065750122}]}, {"text": "We used the GENIA dataset (), consisting of 2000 MEDLINE abstracts with 36 finegrained entity categories.", "labels": [], "entities": [{"text": "GENIA dataset", "start_pos": 12, "end_pos": 25, "type": "DATASET", "confidence": 0.9643954038619995}]}, {"text": "We also employed the same conversion to the main 5 entity types (and left the DNA and RNA subtypes the hierarchical experiments).", "labels": [], "entities": []}, {"text": "We used pretrained word embeddings for GENIA using PUBMED dataset.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 39, "end_pos": 44, "type": "DATASET", "confidence": 0.8489980697631836}, {"text": "PUBMED dataset", "start_pos": 51, "end_pos": 65, "type": "DATASET", "confidence": 0.8672472536563873}]}, {"text": "We further tested on a more complex medical dataset MED18, 3 comprising 3000 documents of annotated clinical reports in Portuguese.", "labels": [], "entities": [{"text": "medical dataset MED18, 3", "start_pos": 36, "end_pos": 60, "type": "DATASET", "confidence": 0.818313193321228}]}, {"text": "We consider 4 levels of hierarchy and 531 fine-grained entity categories.", "labels": [], "entities": []}, {"text": "We trained word embeddings for this dataset using word2vec) on over around 10M documents of clinical records.", "labels": [], "entities": []}, {"text": "in 5 shows a description of the datasets.", "labels": [], "entities": []}, {"text": "The MED18 dataset is larger and more complex than GENIA, containing a total of 509869 mentions, 531 different hierarchical classes with 4 levels of hierarchy, while GENIA altough initialy contains 36 fine-grained classes, we only report on 23 different classes with 2 levels of hierarchy.", "labels": [], "entities": [{"text": "MED18 dataset", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.9316712319850922}, {"text": "GENIA", "start_pos": 50, "end_pos": 55, "type": "DATASET", "confidence": 0.9345760345458984}, {"text": "GENIA altough initialy", "start_pos": 165, "end_pos": 187, "type": "DATASET", "confidence": 0.8508184353510538}]}, {"text": "nested mentions: a CRF-based constituency parser (; a nested NER model using mention hypergraphs (; a multigraph representation with mention separators for overlapping mentions; a neural layered model for each nested layer (; and a neural shift-reduce neural parser for nested mentions ().", "labels": [], "entities": [{"text": "CRF-based constituency parser", "start_pos": 19, "end_pos": 48, "type": "TASK", "confidence": 0.5586651961008707}]}, {"text": "We also, evaluated HNNER against the non-hierarchical nested version with the same number of hierarchical levels projected as a different independent class (HNNER+SUB).", "labels": [], "entities": [{"text": "HNNER", "start_pos": 19, "end_pos": 24, "type": "DATASET", "confidence": 0.7908884286880493}]}, {"text": "We train our model using Adam gradient updates) using a learning rate of 0.001 and a batch size of 32 sentences.", "labels": [], "entities": []}, {"text": "We employed dropout of 0.1 on all input layers ().", "labels": [], "entities": []}, {"text": "We used \u03b2 = 0.8 for GENIA and \u03b2 = 1.0 for MED18.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 20, "end_pos": 25, "type": "DATASET", "confidence": 0.9206265211105347}, {"text": "MED18", "start_pos": 42, "end_pos": 47, "type": "DATASET", "confidence": 0.9583105444908142}]}, {"text": "For higher level datasets this value should be closer to one in order to not overshadow the effect of lower hierarchies, which are often the most frequent ones.", "labels": [], "entities": []}, {"text": "Results Our HNNER model obtains state-ofthe-art results when compared with other flat (Table 1) and nested NER models.", "labels": [], "entities": []}, {"text": "Learning hierarchical mentions explicitly using our model (HNNER) achieves better performance than using a set of projected subcategories independently, (HNNER+SUB) in.", "labels": [], "entities": []}, {"text": "The proposed approach is still able to perform well when we deal with higher levels of hierarchy and more nested classes, which we can observe in the results using the MED18 dataset.", "labels": [], "entities": [{"text": "MED18 dataset", "start_pos": 168, "end_pos": 181, "type": "DATASET", "confidence": 0.9741411209106445}]}, {"text": "As we progress towards higher level hierarchies the gap performance increases between projected subclasses and explicit hierarchical modeling.", "labels": [], "entities": []}, {"text": "The performance of level L3 drops when compared with lower level levels, because of the scarce number of existing mentions for this level (see \u00a75).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results on JNLPBA with flat mentions.", "labels": [], "entities": [{"text": "JNLPBA", "start_pos": 21, "end_pos": 27, "type": "DATASET", "confidence": 0.832061767578125}]}, {"text": " Table 2: Dataset description: total number of mentions,  sentences, words and actions. Number of mentions and  types of actions per hierarchical layer", "labels": [], "entities": []}, {"text": " Table 3: Results on GENIA with nested mentions.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 21, "end_pos": 26, "type": "DATASET", "confidence": 0.7466744780540466}]}, {"text": " Table 4: Results on GENIA and MED18 with nested  mentions with all the subcategories, and performance  per hierarchical layer.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 21, "end_pos": 26, "type": "DATASET", "confidence": 0.9215893149375916}, {"text": "MED18", "start_pos": 31, "end_pos": 36, "type": "DATASET", "confidence": 0.6335313320159912}]}]}