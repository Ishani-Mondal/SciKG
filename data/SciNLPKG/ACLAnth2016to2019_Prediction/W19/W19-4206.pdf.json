{"title": [{"text": "Multi-Team: A Multi-attention, Multi-decoder Approach to Morphological Analysis", "labels": [], "entities": [{"text": "Morphological Analysis", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.8657690584659576}]}], "abstractContent": [{"text": "This paper describes our submission to SIG-MORPHON 2019 Task 2: Morphological analysis and lemmatization in context.", "labels": [], "entities": [{"text": "SIG-MORPHON 2019 Task 2", "start_pos": 39, "end_pos": 62, "type": "TASK", "confidence": 0.613362118601799}, {"text": "Morphological analysis", "start_pos": 64, "end_pos": 86, "type": "TASK", "confidence": 0.9601230621337891}]}, {"text": "Our model is a multi-task sequence to sequence neural network, which jointly learns morphological tagging and lemmatization.", "labels": [], "entities": []}, {"text": "On the encoding side, we exploit character-level as well as contextual information.", "labels": [], "entities": []}, {"text": "We introduce a multi-attention decoder to selectively focus on different parts of character and word sequences.", "labels": [], "entities": []}, {"text": "To further improve the model, we train on multiple datasets simultaneously and use external embeddings for initialization.", "labels": [], "entities": []}, {"text": "Our final model reaches an average morphological tagging F1 score of 94.54 and a lemma accuracy of 93.91 on the test data, ranking respectively 3rd and 6th out of 13 teams in the SIG-MORPHON 2019 shared task.", "labels": [], "entities": [{"text": "morphological tagging", "start_pos": 35, "end_pos": 56, "type": "TASK", "confidence": 0.6354323774576187}, {"text": "F1 score", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9553540050983429}, {"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9131034016609192}, {"text": "SIG-MORPHON 2019 shared task", "start_pos": 179, "end_pos": 207, "type": "TASK", "confidence": 0.5585080906748772}]}], "introductionContent": [{"text": "This paper presents our model for the SIGMOR-PHON 2019 Task 2 on morphological analysis and lemmatization in context (.", "labels": [], "entities": [{"text": "SIGMOR-PHON 2019 Task 2", "start_pos": 38, "end_pos": 61, "type": "TASK", "confidence": 0.7383754700422287}, {"text": "morphological analysis", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.8444700241088867}]}, {"text": "The task is to generate a lemma and a sequence of morphological tags, which are called morphosyntactic descriptions (MSD), for each word in a given sentence.", "labels": [], "entities": []}, {"text": "This task is important because it can be used to improve several downstream NLP applications such as grammatical error correction (), machine translation (Conforti et al., 2018) and multilingual parsing (.", "labels": [], "entities": [{"text": "grammatical error correction", "start_pos": 101, "end_pos": 129, "type": "TASK", "confidence": 0.6840014457702637}, {"text": "machine translation", "start_pos": 134, "end_pos": 153, "type": "TASK", "confidence": 0.8407321870326996}, {"text": "multilingual parsing", "start_pos": 182, "end_pos": 202, "type": "TASK", "confidence": 0.7334885001182556}]}, {"text": "shows the lemma and morphological tags of: Johnny likes cats.", "labels": [], "entities": []}, {"text": "The first sub-task, Lemmatization, is to transform an inflected word form to its lemma which is its base-form (or dictionary form), as in the example of likes to like.", "labels": [], "entities": []}, {"text": "The second sub-task, morphological tagging, is to predict morphological properties of words as a sequence of tags, including apart of speech tag.", "labels": [], "entities": [{"text": "morphological tagging", "start_pos": 21, "end_pos": 42, "type": "TASK", "confidence": 0.7435522377490997}]}, {"text": "These morphological tags specify the inflections encoded in example sentence, the word likes is annotated with a morphological tag set of {V,SG,3,IND,PRS}.", "labels": [], "entities": []}, {"text": "Both tasks are dependent on context.", "labels": [], "entities": []}, {"text": "For example, while walking is annotated with the lemma walk and tag set {N,SG} in the sentence: The beach is within walking distance; it is annotated with walking and {V.PTCP;PRS;V} in: I was walking.", "labels": [], "entities": []}, {"text": "These two tasks have a clear relation; inmost languages the categories found in the morphological tags indicate how the lemma of the word was inflected to the word-form.", "labels": [], "entities": []}, {"text": "In other words, syntactic inflections have a strong correlation with the morphological properties of the words.", "labels": [], "entities": []}, {"text": "Our approach to solve both of these tasks consists of an encoder and two separate decoders within a multi-task architecture based on a sequence-to-sequence network.", "labels": [], "entities": []}, {"text": "The shared encoder reads words and sentences to learn character-level and word-level representations.", "labels": [], "entities": []}, {"text": "The decoders then separately generate lemmas and morphological tags using these representations by using multiple attention mechanisms.", "labels": [], "entities": []}, {"text": "Our contributions are threefold: \u2022 We introduce the use of multiple attention mechanisms that selectively focus character and word sequences in the sentence context.", "labels": [], "entities": []}, {"text": "\u2022 We evaluate the effect of a variety of types of external embeddings for lemmatization and morphological tagging.", "labels": [], "entities": [{"text": "morphological tagging", "start_pos": 92, "end_pos": 113, "type": "TASK", "confidence": 0.6002734303474426}]}, {"text": "\u2022 We evaluate the effect of combining annotated datasets from related languages for both tasks using dataset embeddings.", "labels": [], "entities": []}], "datasetContent": [{"text": "To test whether the dataset embeddings are necessary, we compare them with a naive approach to combine datasets: simply training on the concatenation of both datasets.", "labels": [], "entities": []}, {"text": "The average results on 4 small datasets and 4 large datasets which are given in, are compared separately in.", "labels": [], "entities": []}, {"text": "In both small and large settings, using dataset embeddings improves the performance in both morphological tagging and lemmatization, however the effect of dataset embeddings is higher on small datasets, especially in the morphological tagging task.", "labels": [], "entities": [{"text": "morphological tagging", "start_pos": 92, "end_pos": 113, "type": "TASK", "confidence": 0.6936671733856201}, {"text": "morphological tagging task", "start_pos": 221, "end_pos": 247, "type": "TASK", "confidence": 0.8045864701271057}]}, {"text": "For the detailed results on our tune datasets, we refer to Appendix C.  In this section, we will describe the data used in our experiments as well as evaluate the effectiveness of our external embeddings setup and the dataset embeddings within a variety of settings.", "labels": [], "entities": [{"text": "Appendix", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9053322076797485}]}, {"text": "In all experiments we use +E and -E to indicate the model with and without external embeddings, and +D and -D for dataset embeddings.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: The datasets which we used to tune our mod- els, with data properties based on the training split. IE:  Indo-European", "labels": [], "entities": []}, {"text": " Table 7: Average results for all evaluation metrics  for development and test data. +E: use external em- beddings for initialization, +D: use dataset embedding  strategy. On the development data, we report the aver- age over the datasets where predictions of all settings  were available.", "labels": [], "entities": [{"text": "aver- age", "start_pos": 211, "end_pos": 220, "type": "METRIC", "confidence": 0.8735159436861674}]}, {"text": " Table 6: All four evaluation metrics for the test data of our best system. E: use of external embeddings. D: use of  dataset embeddings. Results might be different compared to the ones in the overview paper, as we did not have  enough time to run all experiments before the deadline. +E: whether external embeddings were used. +D: whether  dataset embeddings were used.", "labels": [], "entities": []}]}