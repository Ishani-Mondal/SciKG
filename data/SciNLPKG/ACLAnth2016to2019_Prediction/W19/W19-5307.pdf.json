{"title": [{"text": "LIUM's Contributions to the WMT2019 News Translation Task: Data and Systems for German\u2194French Language Pairs", "labels": [], "entities": [{"text": "WMT2019 News Translation Task", "start_pos": 28, "end_pos": 57, "type": "TASK", "confidence": 0.7969247400760651}]}], "abstractContent": [{"text": "This paper describes the neural machine translation (NMT) systems of the LIUM Laboratory developed for the French \u2194 German news translation task of the Fourth Conference on Machine Translation (WMT 2019).", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 25, "end_pos": 51, "type": "TASK", "confidence": 0.7564526597658793}, {"text": "French \u2194 German news translation task of the Fourth Conference on Machine Translation (WMT 2019)", "start_pos": 107, "end_pos": 203, "type": "TASK", "confidence": 0.7762866844149197}]}, {"text": "The chosen language pair is included for the first time in the WMT news translation task.", "labels": [], "entities": [{"text": "WMT news translation task", "start_pos": 63, "end_pos": 88, "type": "TASK", "confidence": 0.823946624994278}]}, {"text": "We describe how the training and the evaluation data was created.", "labels": [], "entities": []}, {"text": "We also present our participation in the French \u2194 German translation directions using self-attentional Transformer networks with small and big architectures.", "labels": [], "entities": []}], "introductionContent": [{"text": "Since the start of the WMT translation shared tasks in 2006, English has been involved in the majority of translation directions.", "labels": [], "entities": [{"text": "WMT translation shared tasks", "start_pos": 23, "end_pos": 51, "type": "TASK", "confidence": 0.9226681441068649}]}, {"text": "Few exceptions have been seen in 2012 and 2013 where Czech was also proposed as source and target for several language pairs.", "labels": [], "entities": []}, {"text": "This overwhelming disparity is due to the fact that English is available in large quantity, in both monolingual and bilingual corpora.", "labels": [], "entities": []}, {"text": "We think that this maybe problematic for research purposes since considering English (either as source or target language) may hide many linguistic problems.", "labels": [], "entities": []}, {"text": "For example, considering gender agreement, which does not exist in English, translating from English is harder because of the lack of source side information, and translating towards English is simpler since the agreement should be ignored.", "labels": [], "entities": [{"text": "translating from English", "start_pos": 76, "end_pos": 100, "type": "TASK", "confidence": 0.8978460431098938}]}, {"text": "Generally speaking, English is a rather morphologically impoverished language, for instance having few gender agreement cases or conjugated verb forms.", "labels": [], "entities": []}, {"text": "This contrasts with French and German where number and gender agreements are very frequent.", "labels": [], "entities": []}, {"text": "That is why we introduced two new translation directions involving two European languages, namely French and German.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we first present the results for German to French translation direction followed by the French to German direction.", "labels": [], "entities": []}, {"text": "We use BLEU as evaluation metric () and all reported scores are calculated using case-sensitive detokenized BLEU with multi-bleu.pl.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 7, "end_pos": 11, "type": "METRIC", "confidence": 0.9898339509963989}, {"text": "BLEU", "start_pos": 108, "end_pos": 112, "type": "METRIC", "confidence": 0.9662978053092957}]}, {"text": "All results use beam search with abeam width of 12 and length penalty of 1.", "labels": [], "entities": [{"text": "length penalty", "start_pos": 55, "end_pos": 69, "type": "METRIC", "confidence": 0.9876316785812378}]}], "tableCaptions": [{"text": " Table 1: Training corpora statistics (number of sentences) for FR\u2194DE News translation shared task. The second  line of each cell corresponds to the number of tokens in French followed by the number of tokens in German.", "labels": [], "entities": [{"text": "FR\u2194DE News translation shared task", "start_pos": 64, "end_pos": 98, "type": "TASK", "confidence": 0.6382752060890198}]}, {"text": " Table 2: FR-DE dev and test set statistics.", "labels": [], "entities": [{"text": "FR-DE", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.6825459599494934}]}, {"text": " Table 3: Training corpora statistics for FR\u2194DE sys- tems after the cleaning process.", "labels": [], "entities": [{"text": "FR", "start_pos": 42, "end_pos": 44, "type": "METRIC", "confidence": 0.7507829666137695}]}, {"text": " Table 4: BLEU results for DE\u2192FR NMT systems us- ing all training data but ParaCrawl corpus.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9989711046218872}, {"text": "DE\u2192FR NMT", "start_pos": 27, "end_pos": 36, "type": "TASK", "confidence": 0.4633159711956978}, {"text": "ParaCrawl corpus", "start_pos": 75, "end_pos": 91, "type": "DATASET", "confidence": 0.9490121006965637}]}, {"text": " Table 5: BLEU results for DE \u2192FR NMT systems with  all training data including ParaCrawl.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.998954176902771}, {"text": "FR", "start_pos": 31, "end_pos": 33, "type": "METRIC", "confidence": 0.7112734913825989}, {"text": "ParaCrawl", "start_pos": 80, "end_pos": 89, "type": "DATASET", "confidence": 0.909507155418396}]}, {"text": " Table 6: BLEU results for DE \u2192FR NMT systems with  back-translation training data and without ParaCrawl  parallel data.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.998944103717804}]}, {"text": " Table 7: Results in terms of BLEU for FR \u2192DE NMT  systems using all the available training data except the  ParaCrawl corpus.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.9986422657966614}, {"text": "ParaCrawl corpus", "start_pos": 109, "end_pos": 125, "type": "DATASET", "confidence": 0.9648098647594452}]}, {"text": " Table 8: Results in terms of BLEU for FR \u2192DE NMT  systems using all the available training data including  ParaCrawl corpus.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.9986795783042908}, {"text": "ParaCrawl corpus", "start_pos": 108, "end_pos": 124, "type": "DATASET", "confidence": 0.9599509239196777}]}, {"text": " Table 9: Results in terms of BLEU for the FR\u2192DE  NMT systems with back-translation training data but  without ParaCrawl parallel data.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.998908281326294}, {"text": "FR\u2192DE  NMT", "start_pos": 43, "end_pos": 53, "type": "DATASET", "confidence": 0.6927612721920013}]}]}