{"title": [{"text": "What does BERT look at? An Analysis of BERT's Attention", "labels": [], "entities": [{"text": "BERT's Attention", "start_pos": 39, "end_pos": 55, "type": "TASK", "confidence": 0.5456361869970957}]}], "abstractContent": [{"text": "Large pre-trained neural networks such as BERT have had great recent success in NLP, motivating a growing body of research investigating what aspects of language they are able to learn from unlabeled data.", "labels": [], "entities": [{"text": "BERT", "start_pos": 42, "end_pos": 46, "type": "METRIC", "confidence": 0.9731395840644836}, {"text": "NLP", "start_pos": 80, "end_pos": 83, "type": "TASK", "confidence": 0.9582156538963318}]}, {"text": "Most recent analysis has focused on model outputs (e.g., language model surprisal) or internal vector representations (e.g., probing classifiers).", "labels": [], "entities": []}, {"text": "Complementary to these works, we propose methods for analyzing the attention mechanisms of pre-trained models and apply them to BERT.", "labels": [], "entities": [{"text": "BERT", "start_pos": 128, "end_pos": 132, "type": "METRIC", "confidence": 0.6156575679779053}]}, {"text": "BERT's attention heads exhibit patterns such as attending to delimiter tokens, specific po-sitional offsets, or broadly attending over the whole sentence, with heads in the same layer often exhibiting similar behaviors.", "labels": [], "entities": []}, {"text": "We further show that certain attention heads correspond well to linguistic notions of syntax and coref-erence.", "labels": [], "entities": []}, {"text": "For example, we find heads that attend to the direct objects of verbs, determiners of nouns, objects of prepositions, and corefer-ent mentions with remarkably high accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 164, "end_pos": 172, "type": "METRIC", "confidence": 0.9962582588195801}]}, {"text": "Lastly, we propose an attention-based probing classifier and use it to further demonstrate that substantial syntactic information is captured in BERT's attention.", "labels": [], "entities": [{"text": "BERT", "start_pos": 145, "end_pos": 149, "type": "METRIC", "confidence": 0.6323819756507874}]}], "introductionContent": [{"text": "Large pre-trained language models achieve very high accuracy when fine-tuned on supervised tasks), but it is not fully understood why.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9974440336227417}]}, {"text": "The strong results suggest pre-training teaches the models about the structure of language, but what specific linguistic features do they learn?", "labels": [], "entities": []}, {"text": "Recent work has investigated this question by examining the outputs of language models on carefully chosen input sentences ( or examining the internal vector representations of the model through methods such as probing classifiers.", "labels": [], "entities": []}, {"text": "Complementary to these approaches, we study 1 the attention maps of a pre-trained model.", "labels": [], "entities": []}, {"text": "Attention () has been a highly successful neural network component.", "labels": [], "entities": []}, {"text": "It is naturally interpretable because an attention weight has a clear meaning: how much a particular word will be weighted when computing the next representation for the current word.", "labels": [], "entities": []}, {"text": "Our analysis focuses on the 144 attention heads in BERT, a large pre-trained Transformer ( network that has demonstrated excellent performance on many tasks.", "labels": [], "entities": [{"text": "BERT", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.9527855515480042}]}, {"text": "We first explore generally how the attention heads behave.", "labels": [], "entities": []}, {"text": "We find that there are common patterns in their behavior, such as attending to fixed positional offsets or attending broadly over the whole sentence.", "labels": [], "entities": []}, {"text": "A surprisingly large amount of BERT's attention focuses on the deliminator token, which we argue is used by the model as a sort of no-op.", "labels": [], "entities": [{"text": "BERT", "start_pos": 31, "end_pos": 35, "type": "METRIC", "confidence": 0.9830439686775208}]}, {"text": "Generally we find that attention heads in the same layer tend to behave similarly.", "labels": [], "entities": []}, {"text": "We next probe each attention head for linguistic phenomena.", "labels": [], "entities": []}, {"text": "In particular, we treat each attention head as a simple no-training-required classifier that, given a word as input, outputs the mostattended-to other word.", "labels": [], "entities": []}, {"text": "We then evaluate the ability of the heads to classify various syntactic relations.", "labels": [], "entities": []}, {"text": "While no single head performs well at many relations, we find that particular heads correspond remarkably well to particular relations.", "labels": [], "entities": []}, {"text": "For example, we find heads that find direct objects of verbs, determiners of nouns, objects of prepositions, and objects of possesive pronouns with >75% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 153, "end_pos": 161, "type": "METRIC", "confidence": 0.9977273344993591}]}, {"text": "We perform a similar analysis for coreference resolution, also finding a BERT head that performs quite well.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 34, "end_pos": 56, "type": "TASK", "confidence": 0.9754030406475067}, {"text": "BERT", "start_pos": 73, "end_pos": 77, "type": "METRIC", "confidence": 0.9975244402885437}]}, {"text": "These results are intriguing because the behavior of the attention heads emerges purely from self-supervised training on unlabeled data, without explicit supervision for syntax or coreference.", "labels": [], "entities": []}, {"text": "Our findings show that particular heads specialize to specific aspects of syntax.", "labels": [], "entities": []}, {"text": "To get a more overall measure of the attention heads' syntactic ability, we propose an attention-based probing classifier that takes attention maps as input.", "labels": [], "entities": []}, {"text": "The classifier achieves 77 UAS at dependency parsing, showing BERT's attention captures a substantial amount about syntax.", "labels": [], "entities": [{"text": "UAS", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.9658704400062561}, {"text": "dependency parsing", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.7700402140617371}, {"text": "BERT", "start_pos": 62, "end_pos": 66, "type": "METRIC", "confidence": 0.9890590310096741}]}, {"text": "Several recent works have proposed incorporating syntactic information to improve attention (.", "labels": [], "entities": []}, {"text": "Our work suggests that to an extent this kind of syntax-aware attention already exists in BERT, which maybe one of the reason for its success.", "labels": [], "entities": [{"text": "BERT", "start_pos": 90, "end_pos": 94, "type": "METRIC", "confidence": 0.8506448864936829}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: The best performing attentions heads of  BERT on WSJ dependency parsing by dependency  type. Numbers after baseline accuracies show the best  offset found (e.g., (1) means the word to the right is  predicted as the head). We show the 10 most common  relations as well as 5 other ones attention heads did well  on. Bold highlights particularly effective heads.", "labels": [], "entities": [{"text": "BERT", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.8955894708633423}, {"text": "WSJ dependency parsing", "start_pos": 59, "end_pos": 81, "type": "TASK", "confidence": 0.7822948296864828}]}, {"text": " Table 2: Accuracies (%) for different mention types of  systems selecting a correct antecedent given a corefer- ent mention in the CoNLL-2012 data. One of BERT's  attention heads performs fairly well at coreference.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9990931749343872}, {"text": "CoNLL-2012 data", "start_pos": 132, "end_pos": 147, "type": "DATASET", "confidence": 0.9724801480770111}, {"text": "BERT", "start_pos": 156, "end_pos": 160, "type": "METRIC", "confidence": 0.4762110412120819}]}, {"text": " Table 3: Results of attention-based probing tasks on  dependency parsing. A simple model taking BERT at- tention maps and GloVe word embeddings as input per- forms quite well at dependency parsing. *Not directly  comparable to our numbers; see text.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.9184751510620117}, {"text": "BERT", "start_pos": 97, "end_pos": 101, "type": "METRIC", "confidence": 0.9928364157676697}, {"text": "dependency parsing", "start_pos": 179, "end_pos": 197, "type": "TASK", "confidence": 0.8531056642532349}]}]}