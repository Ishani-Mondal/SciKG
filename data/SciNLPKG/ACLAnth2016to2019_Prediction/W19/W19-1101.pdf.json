{"title": [{"text": "Distribution is not enough: going Firther", "labels": [], "entities": [{"text": "Firther", "start_pos": 34, "end_pos": 41, "type": "DATASET", "confidence": 0.7711437344551086}]}], "abstractContent": [{"text": "Much work in contemporary computational semantics follows the distributional hypothesis (DH), which is understood as an approach to semantics according to which the meaning of a word is a function of its distribution over contexts which is represented as vectors (word embeddings) within a multi-dimensional semantic space.", "labels": [], "entities": [{"text": "distributional hypothesis (DH)", "start_pos": 62, "end_pos": 92, "type": "TASK", "confidence": 0.735872894525528}]}, {"text": "In practice, use is identified with occurrence in text corpora, though there are some efforts to use corpora containing multi-modal information.", "labels": [], "entities": []}, {"text": "In this paper we argue that the distributional hypothesis is intrinsically misguided as a self-supporting basis for semantics, as Firth was entirely aware.", "labels": [], "entities": []}, {"text": "We mention philosophical arguments concerning the lack of normativity within DH data.", "labels": [], "entities": [{"text": "DH data", "start_pos": 77, "end_pos": 84, "type": "DATASET", "confidence": 0.8281737267971039}]}, {"text": "Furthermore, we point out the shortcomings of DH as a model of learning, by discussing a variety of linguistic classes that cannot be learnt on a distributional basis, including indexicals, proper names, and wh-phrases.", "labels": [], "entities": []}, {"text": "Instead of pursuing DH, we sketch an account of the problematic learning cases by integrating a rich, Firthian notion of dialogue context with interactive learning in signalling games backed by in probabilistic Type Theory with Records.", "labels": [], "entities": [{"text": "DH", "start_pos": 20, "end_pos": 22, "type": "TASK", "confidence": 0.8838335275650024}]}, {"text": "We conclude that the success of the DH in computational semantics rests on a post hoc effect: DS presupposes a referential semantics on the basis of which utterances can be produced, comprehended and analysed in the first place.", "labels": [], "entities": []}], "introductionContent": [{"text": "Much work in contemporary computational semantics follows the distributional hypothesis (DH), attributed to and, which is understood as an approach to semantics according to which the meaning of a word is a function of its distribution over contexts which is represented as vectors (word embeddings) within a multi-dimensional semantic space.", "labels": [], "entities": []}, {"text": "In practice, use is identified with occurrence in text corpora, though there are some efforts to use corpora containing multi-modal information (e.g).", "labels": [], "entities": []}, {"text": "The appealing prospect of distributional semantics (DS) is to provide a self-supporting semantic theory according to which semantic representations can be bootstrapped from corpora in an entirely empirical fashion: Word space models constitute a purely descriptive approach to semantic modelling; it does not require any previous linguistic or semantic knowledge, and it only detects what is actually therein the data.", "labels": [], "entities": [{"text": "distributional semantics (DS)", "start_pos": 26, "end_pos": 55, "type": "TASK", "confidence": 0.7612069368362426}, {"text": "semantic modelling", "start_pos": 277, "end_pos": 295, "type": "TASK", "confidence": 0.7669116258621216}]}, {"text": "In this paper we argue that the distributional hypothesis is intrinsically misguided as a self-supporting basis for semantics (for such a claim, see; also argue in that direction), as-somewhat surprisingly-Firth was entirely aware.", "labels": [], "entities": []}, {"text": "Note that our discussion points at reference and interaction as semantic building blocks, not to inferential and compositional properties which are often mentioned as motivating factors behind engaging in Formal Distributional Semantics (FDS; or distributional probabilistic inference.", "labels": [], "entities": []}, {"text": "In section 2 we begin with mentioning pertinent philosophical arguments concerning the lack of normativity within DH data due to.", "labels": [], "entities": [{"text": "DH data", "start_pos": 114, "end_pos": 121, "type": "DATASET", "confidence": 0.9196924269199371}]}, {"text": "These argument show that collections of past uses do not allow to deduce a notion of veridicality, since the regularities within any collection of data do not project to semantic norms.", "labels": [], "entities": []}, {"text": "Using supervised models (where target data or a so-called 'ground truth' are spelled out in advance), DS might try to implement normative knowledge nonetheless.", "labels": [], "entities": []}, {"text": "But this move amounts to a circular approach: semantic knowledge is needed in order to apply distributional semantic methods in the first place.", "labels": [], "entities": []}, {"text": "Thus, we observe a bootstrapping problem here.", "labels": [], "entities": []}, {"text": "This problem is conceded within DS in general: 'The results suggest that, while distributional semantic vectors can be used \"as-is\" to capture generic word similarity, with some supervision it is also possible to extract other kinds of information from them [.", "labels": [], "entities": []}, {"text": "Obviously, the bootstrapping problem completely undermines the DH's claim to provide a semantic theory.", "labels": [], "entities": [{"text": "DH", "start_pos": 63, "end_pos": 65, "type": "DATASET", "confidence": 0.9176434278488159}]}, {"text": "However, work that aims at accounting for such 'higher order' phenomena in distributional terms but drawing on additional resources or annotations-like, who map distributional information onto quantified sentences,, who map distributions to knowledge base information, or, who employ distributional semantics on character annotations within a specifically designed network model-puts its emphasis not on distributional semantic representation, but on how to learn these representations.", "labels": [], "entities": []}, {"text": "We observe a further, de facto construal of DH here, a construal that draws on the notion of supervised learning, triggered by the procedures of data extraction or machine learning.", "labels": [], "entities": []}, {"text": "Accordingly, in section 3 we discuss a variety of linguistic classes that cannot be learnt on the basis of the distributional hypothesis, including indexicals (), proper names, and wh-phrases.", "labels": [], "entities": []}, {"text": "In section 5 we sketch an account of these problematic cases that integrates a rich notion of dialogue context) with interactive learning in signalling games backed by a probabilistic Type Theory with Records (, which lays the foundations for spreading probabilities over situations.", "labels": [], "entities": []}, {"text": "This diagnosis of DS can be related to two different notions of semantics as a theory of meaning (cf..", "labels": [], "entities": [{"text": "diagnosis of DS", "start_pos": 5, "end_pos": 20, "type": "TASK", "confidence": 0.6187795996665955}]}, {"text": ", namely semantic theory as a specification of the meanings of words and sentences (vector spaces), and a foundational theory of meaning identify the facts in virtue of which words and sentences do have the meaning they have (learning) We point at struggles of the DH with both of these respects here.", "labels": [], "entities": []}, {"text": "We will even, for the most part, put aside one of the intrinsic issues confronting the DH-the sentential denotation issue: how to get distributional vectors to denote/represent/correspond to events or propositions or questions.", "labels": [], "entities": [{"text": "DH-the sentential denotation", "start_pos": 87, "end_pos": 115, "type": "TASK", "confidence": 0.674534797668457}]}, {"text": "Nor do we deal with compositionality.", "labels": [], "entities": []}, {"text": "We deal primarily with lexical semantic issues (though not entirely, given the discussion of wh-phrases . .", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}