{"title": [{"text": "NLP@UNED at SMM4H 2019: Neural Networks Applied to Automatic Classifications of Adverse Effects Mentions in Tweets", "labels": [], "entities": [{"text": "NLP@UNED at SMM4H 2019", "start_pos": 0, "end_pos": 22, "type": "DATASET", "confidence": 0.6882615089416504}]}], "abstractContent": [{"text": "This paper describes a system for automatically classifying adverse effects mentions in tweets developed for the task 1 at Social Media Mining for Health Applications (SMM4H) Shared Task 2019.", "labels": [], "entities": [{"text": "Social Media Mining for Health Applications (SMM4H) Shared Task 2019", "start_pos": 123, "end_pos": 191, "type": "TASK", "confidence": 0.6472371419270834}]}, {"text": "We have developed a system based on LSTM neural networks inspired by the excellent results obtained by deep learning classifiers in the last edition of this task.", "labels": [], "entities": []}, {"text": "The network is trained along with Twitter GloVe pre-trained word embeddings.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Shared Task ( of the 2019 Social Media Mining for Health Applications (SMM4H) Workshop proposed several Natural Language Processing (NLP) tasks using social media mining for health monitoring.", "labels": [], "entities": [{"text": "Social Media Mining for Health Applications (SMM4H) Workshop", "start_pos": 30, "end_pos": 90, "type": "TASK", "confidence": 0.7213653266429901}]}, {"text": "Since these tasks involve NLP techniques, they are as interesting as difficult to solve because these systems should be able to work with many linguistics variations and model the different ways people express medical-related concepts in social media.", "labels": [], "entities": []}, {"text": "In addition, we must take into account the level of noise caused by creative sentences, misspellings or ambiguous and sarcastic expressions which makes hard to tackle these tasks.", "labels": [], "entities": []}, {"text": "For this shared task we decided to participate in the first task.", "labels": [], "entities": []}, {"text": "This task proposes to find tweets mentioning Adverse Drug Reactions (ADR), taking into account the linguistic variations between ADRs and indications (the reason to use the medication).", "labels": [], "entities": [{"text": "Adverse Drug Reactions (ADR)", "start_pos": 45, "end_pos": 73, "type": "TASK", "confidence": 0.7795322835445404}]}, {"text": "We have developed a system based on LSTM networks due to their latest achievements in the last edition of this task).", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we describe the dataset of the task 1 and the applied pre-processing.", "labels": [], "entities": []}, {"text": "This task proposes to find tweets mentioning ADRs, therefore we have to deal with raw text extracted from Twitter.", "labels": [], "entities": []}, {"text": "The publicly available dataset contains for each tweet: (i) the user ID, (ii) the tweet ID, and (iii) the binary annotation indicating the presence or absence of ADRs.", "labels": [], "entities": []}, {"text": "The dataset contains 24606 tweets manually tagged, being around 10% (2358) of tweets mentioning ADRs, and around the remaining 90% (22248) are tweets without ADRs.", "labels": [], "entities": []}, {"text": "For the implementation of the system we chose) while for the pre-processing of the data we used Scikitlearn (Pedregosa et al., 2011), in particular for padding and split the dataset into validation, train and test sets.", "labels": [], "entities": []}, {"text": "In order to test the functioning of our system we used the evaluation script provided by the organizers.", "labels": [], "entities": []}, {"text": "Several experiments are shown in Table 2.", "labels": [], "entities": []}, {"text": "In these experiments we used a network without embeddings (Base) and with two types of embeddings, one pre-trained on Wikipedia pages (Wikipedia GloVe) and the other one based on tweets (Twitter GloVe).", "labels": [], "entities": []}, {"text": "Due to the better performance shown by the configuration that used Twitter GloVe pre-trained embeddings, we decided to use it for the runs that we submitted to the task.", "labels": [], "entities": []}, {"text": "shows the official results for the three runs that we submitted to the task 1 and the task average score provided by the organizers.", "labels": [], "entities": []}, {"text": "According to the results obtained, it could be said that a greater number of epochs provides better results although the recall begins to fall.", "labels": [], "entities": [{"text": "recall", "start_pos": 121, "end_pos": 127, "type": "METRIC", "confidence": 0.9995325803756714}]}], "tableCaptions": [{"text": " Table 1: Hyper parameter tunning used in the 3 runs  submitted for task 1.", "labels": [], "entities": []}, {"text": " Table 2: System results according the Precision (P),  Recall (R) and F-Measure (F1) scores.", "labels": [], "entities": [{"text": "Precision (P)", "start_pos": 39, "end_pos": 52, "type": "METRIC", "confidence": 0.9454177916049957}, {"text": "Recall (R)", "start_pos": 55, "end_pos": 65, "type": "METRIC", "confidence": 0.945886954665184}, {"text": "F-Measure (F1) scores", "start_pos": 70, "end_pos": 91, "type": "METRIC", "confidence": 0.9180671691894531}]}, {"text": " Table 3: Official results for the three runs that partici- pated in task 1 and task average score provided by or- ganizers.", "labels": [], "entities": []}]}