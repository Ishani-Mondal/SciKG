{"title": [{"text": "UDS-DFKI Submission to the WMT2019 Similar Language Translation Shared Task", "labels": [], "entities": [{"text": "WMT2019 Similar Language Translation Shared Task", "start_pos": 27, "end_pos": 75, "type": "TASK", "confidence": 0.7653429806232452}]}], "abstractContent": [{"text": "In this paper we present the UDS-DFKI system submitted to the Similar Language Translation shared task at WMT 2019.", "labels": [], "entities": [{"text": "Similar Language Translation shared task at WMT 2019", "start_pos": 62, "end_pos": 114, "type": "TASK", "confidence": 0.7907932586967945}]}, {"text": "The first edition of this shared task featured data from three pairs of similar languages: Czech and Polish, Hindi and Nepali, and Portuguese and Spanish.", "labels": [], "entities": []}, {"text": "Participants could choose to participate in any of these three tracks and submit system outputs in any translation direction.", "labels": [], "entities": []}, {"text": "We report the results obtained by our system in translating from Czech to Polish and comment on the impact of out-of-domain test data in the performance of our system.", "labels": [], "entities": []}, {"text": "UDS-DFKI achieved competitive performance ranking second among ten teams in Czech to Polish translation.", "labels": [], "entities": [{"text": "UDS-DFKI", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8324812650680542}, {"text": "Czech to Polish translation", "start_pos": 76, "end_pos": 103, "type": "TASK", "confidence": 0.5545556023716927}]}], "introductionContent": [{"text": "The shared tasks organized annually at WMT provide important benchmarks used in the MT community.", "labels": [], "entities": [{"text": "WMT", "start_pos": 39, "end_pos": 42, "type": "DATASET", "confidence": 0.781042754650116}, {"text": "MT community", "start_pos": 84, "end_pos": 96, "type": "TASK", "confidence": 0.918950766324997}]}, {"text": "Most of these shared tasks include English data, which contributes to make English the most resource-rich language in MT and NLP.", "labels": [], "entities": [{"text": "MT", "start_pos": 118, "end_pos": 120, "type": "TASK", "confidence": 0.9501782655715942}]}, {"text": "In the most popular WMT shared task for example, the News task, MT systems have been trained to translate texts from and to.", "labels": [], "entities": [{"text": "WMT shared task", "start_pos": 20, "end_pos": 35, "type": "TASK", "confidence": 0.7819048563639323}]}, {"text": "This year, we have observed a shift on the dominant role that English on the WMT shared tasks.", "labels": [], "entities": [{"text": "WMT shared tasks", "start_pos": 77, "end_pos": 93, "type": "TASK", "confidence": 0.5252237518628439}]}, {"text": "The News task featured for the first time two language pairs which did not include English: German-Czech and French-German.", "labels": [], "entities": []}, {"text": "In addition to that, the Similar Language Translation was organized for the first time at WMT 2019 with the purpose of evaluating the performance of MT systems on three pairs of similar languages from three different language families: Ibero-Romance, Indo-Aryan, and Slavic.", "labels": [], "entities": [{"text": "Similar Language Translation", "start_pos": 25, "end_pos": 53, "type": "TASK", "confidence": 0.8689757386843363}, {"text": "WMT 2019", "start_pos": 90, "end_pos": 98, "type": "DATASET", "confidence": 0.8335928916931152}, {"text": "MT", "start_pos": 149, "end_pos": 151, "type": "TASK", "confidence": 0.9893355965614319}]}, {"text": "The Similar Language Translation () task provided participants with training, development, and testing data from the following language pairs: Spanish -Portuguese (Romance languages), Czech -Polish (Slavic languages), and Hindi -Nepali (Indo-Aryan languages).", "labels": [], "entities": [{"text": "Similar Language Translation", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.852453867594401}]}, {"text": "Participant could submit system outputs to any of the three language pairs in any direction.", "labels": [], "entities": []}, {"text": "The shared task attracted a good number of participants and the performance of all entries was evaluated using popular MT automatic evaluation metrics, namely BLEU () and TER ().", "labels": [], "entities": [{"text": "MT automatic evaluation", "start_pos": 119, "end_pos": 142, "type": "TASK", "confidence": 0.7456744114557902}, {"text": "BLEU", "start_pos": 159, "end_pos": 163, "type": "METRIC", "confidence": 0.9986845850944519}, {"text": "TER", "start_pos": 171, "end_pos": 174, "type": "METRIC", "confidence": 0.996311366558075}]}, {"text": "In this paper we describe the UDS-DFKI system to the WMT 2019 Similar Language Translation task.", "labels": [], "entities": [{"text": "WMT 2019 Similar Language Translation task", "start_pos": 53, "end_pos": 95, "type": "TASK", "confidence": 0.7361958821614584}]}, {"text": "The system achieved competitive performance and ranked second among ten entries in Czech to Polish translation in terms of BLEU score.", "labels": [], "entities": [{"text": "Czech to Polish translation", "start_pos": 83, "end_pos": 110, "type": "TASK", "confidence": 0.5638135299086571}, {"text": "BLEU score", "start_pos": 123, "end_pos": 133, "type": "METRIC", "confidence": 0.9796186089515686}]}], "datasetContent": [{"text": "We explore our transference model -a twoencoder based transformer architecture, in CS-PL similar language translation task.", "labels": [], "entities": [{"text": "language translation", "start_pos": 97, "end_pos": 117, "type": "TASK", "confidence": 0.7836045324802399}]}, {"text": "For transferenceALL, we initially train on the complete out-of-domain dataset (General).", "labels": [], "entities": [{"text": "transferenceALL", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.9692249298095703}]}, {"text": "The General data is sorted based on their in-domain similarities as described in Equation 1.", "labels": [], "entities": [{"text": "General data", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.7816580832004547}]}, {"text": "transferenceALLmodels are then fine-tuned towards the 500K (in-domain-like) data.", "labels": [], "entities": []}, {"text": "Finally, we perform checkpoint averaging using the 8 best checkpoints.", "labels": [], "entities": [{"text": "checkpoint averaging", "start_pos": 20, "end_pos": 40, "type": "TASK", "confidence": 0.7485273778438568}]}, {"text": "We report the results on the provided development set, which we use as a test set before the submission.", "labels": [], "entities": []}, {"text": "Additionally we also report the official test set result.", "labels": [], "entities": []}, {"text": "To handle out-of-vocabulary words and to reduce the vocabulary size, instead of considering words, we consider subword units () by using byte-pair encoding (BPE).", "labels": [], "entities": []}, {"text": "In the preprocessing step, instead of learning an explicit mapping between BPEs in the Czech (CS) and Polish (PL), we define BPE tokens by jointly processing all parallel data.", "labels": [], "entities": []}, {"text": "Thus, CS and PL derive a single BPE vocabulary.", "labels": [], "entities": []}, {"text": "Since CS and PL belong to the similar language, they naturally share a good fraction of BPE tokens, which reduces the vocabulary size.", "labels": [], "entities": [{"text": "BPE", "start_pos": 88, "end_pos": 91, "type": "METRIC", "confidence": 0.8811536431312561}]}, {"text": "We password level information on the first encoder and the BPE information to the second one.", "labels": [], "entities": [{"text": "BPE", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.9291326403617859}]}, {"text": "On the decoder side of the transference model we pass only BPE text.", "labels": [], "entities": [{"text": "transference", "start_pos": 27, "end_pos": 39, "type": "TASK", "confidence": 0.9706481099128723}, {"text": "BPE text", "start_pos": 59, "end_pos": 67, "type": "DATASET", "confidence": 0.6424102634191513}]}, {"text": "We evaluate our approach with development data which is used as test case before submission.", "labels": [], "entities": []}, {"text": "We use BLEU () and TER ().", "labels": [], "entities": [{"text": "BLEU", "start_pos": 7, "end_pos": 11, "type": "METRIC", "confidence": 0.9992376565933228}, {"text": "TER", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.9987433552742004}]}], "tableCaptions": [{"text": " Table 1: Results for CS-PL Translation; * averaging 8  best checkpoints.", "labels": [], "entities": [{"text": "CS-PL Translation", "start_pos": 22, "end_pos": 39, "type": "TASK", "confidence": 0.7659555971622467}]}, {"text": " Table 2: Rank table for Czech to Polish Translation", "labels": [], "entities": [{"text": "Rank", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.959618330001831}, {"text": "Czech to Polish Translation", "start_pos": 25, "end_pos": 52, "type": "TASK", "confidence": 0.5615009441971779}]}]}