{"title": [{"text": "Classifying the reported ability in clinical mobility descriptions", "labels": [], "entities": []}], "abstractContent": [{"text": "Assessing how individuals perform different activities is key information for modeling health states of individuals and populations.", "labels": [], "entities": [{"text": "Assessing", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.958024263381958}]}, {"text": "Descriptions of activity performance in clinical free text are complex, including syntactic negation and similarities to textual entailment tasks.", "labels": [], "entities": []}, {"text": "We explore a variety of methods for the novel task of classifying four types of assertions about activity performance: Able, Unable , Unclear, and None (no information).", "labels": [], "entities": [{"text": "Able", "start_pos": 119, "end_pos": 123, "type": "METRIC", "confidence": 0.9701303839683533}, {"text": "None", "start_pos": 147, "end_pos": 151, "type": "METRIC", "confidence": 0.9594770669937134}]}, {"text": "We find that ensembling an SVM trained with lexical features and a CNN achieves 77.9% macro F1 score on our task, and yields nearly 80% recall on the rare Unclear and Unable samples.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9512972831726074}, {"text": "recall", "start_pos": 136, "end_pos": 142, "type": "METRIC", "confidence": 0.9995952248573303}]}, {"text": "Finally, we highlight several challenges in classifying performance assertions, including capturing information about sources of assistance , incorporating syntactic structure and negation scope, and handling new modalities attest time.", "labels": [], "entities": []}, {"text": "Our findings establish a strong baseline for this novel task, and identify intriguing areas for further research.", "labels": [], "entities": []}], "introductionContent": [{"text": "Information on how individuals perform activities and participate in social roles informs conceptualizations of quality of life, disability, and social well-being.", "labels": [], "entities": []}, {"text": "Importantly, activity performance and role participation are highly dependent on the environment in which they occur; for example, one individual maybe able to walk around an office without issue, but experience severe difficulty walking along mountain paths.", "labels": [], "entities": []}, {"text": "Thus, determining what level of performance an individual can achieve for activities in different environments is critical for identifying ability to meet work requirements, and designing public policy to support the participation of all people.", "labels": [], "entities": []}, {"text": "However, the interaction between individuals and environments makes modeling performance * These authors contributed equally to this work.", "labels": [], "entities": []}, {"text": "Assessments of activity performance within clinical healthcare settings are typically recorded in free text, and exhibit high flexibility in structure.", "labels": [], "entities": []}, {"text": "Syntactic negation can be present, but is not necessarily indicative of inability to perform an action; for example, Patient can walk with rolling walker and Patient cannot walk without rolling walker are both likely to be used to assert the ability of the patient to walk with the use of an assistive device.", "labels": [], "entities": []}, {"text": "Information about performance may also be given without a clear assertion, as in the cane makes it difficult to walk.", "labels": [], "entities": []}, {"text": "Thus, extraction of performance information must not only distinguish between positive and negative assertions, but also those which cannot be clearly evaluated.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this is the first work to explore assertions of activity performance in health data.", "labels": [], "entities": []}, {"text": "We explore a variety of methods for classifying assertion types, including rulebased approaches, statistical methods using common text features, and convolutional neural networks.", "labels": [], "entities": []}, {"text": "We find that machine learning approaches set a strong baseline for discriminating between four assertion types, including rare negative assertions.", "labels": [], "entities": []}, {"text": "While this work focuses on a relatively constrained and homogeneous corpus, error analysis suggests several broader directions for future research on classifying performance assertions.", "labels": [], "entities": [{"text": "error analysis", "start_pos": 76, "end_pos": 90, "type": "TASK", "confidence": 0.6409637629985809}, {"text": "classifying performance assertions", "start_pos": 150, "end_pos": 184, "type": "TASK", "confidence": 0.8283284902572632}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Number of samples with each Polarity label in  train and test data.", "labels": [], "entities": []}, {"text": " Table 3: Macro F1 over Polarity classes in 5-fold cross  validation feature selection experiments. All experi- ments start with binary unigram features using con- text words alone, and add Action words, embedding  features from context words, or both (i.e., unigrams  and embedding features from context and Action words  combined). The best performing model configurations  are marked in bold.", "labels": [], "entities": [{"text": "cross  validation feature selection", "start_pos": 51, "end_pos": 86, "type": "TASK", "confidence": 0.7274506241083145}]}, {"text": " Table 4: Five-fold cross validation results (F1) by class  with best configurations of learned baselines. All indi- cates using unigrams, embeddings, and Action mention  features; Uni indicates using unigram features from  context words only, and Uni+Emb indicates both uni- gram and embedding features from context words. The  best result in each column is marked in bold.", "labels": [], "entities": [{"text": "F1", "start_pos": 46, "end_pos": 48, "type": "METRIC", "confidence": 0.9856487512588501}]}, {"text": " Table 5: CNN performance using different inputs.", "labels": [], "entities": [{"text": "CNN", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.9731718301773071}]}, {"text": " Table 6: Precision (Pr), Recall (Rec), and F1 for each model evaluated on the test set. Top rows are individual  models, bottom rows are ensembled results. The best result in each column is marked in bold.", "labels": [], "entities": [{"text": "Precision (Pr)", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.9463517218828201}, {"text": "Recall (Rec)", "start_pos": 26, "end_pos": 38, "type": "METRIC", "confidence": 0.9544098824262619}, {"text": "F1", "start_pos": 44, "end_pos": 46, "type": "METRIC", "confidence": 0.9997437596321106}]}]}