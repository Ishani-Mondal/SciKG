{"title": [{"text": "How to Use Gazetteers for Entity Recognition with Neural Models", "labels": [], "entities": [{"text": "Entity Recognition", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.7685026526451111}]}], "abstractContent": [{"text": "Although the use of end-to-end neural archi-tectures has been proven to be effective on several sequence labeling tasks, the use of gazetteers in these architectures is still rather unexplored.", "labels": [], "entities": [{"text": "sequence labeling tasks", "start_pos": 96, "end_pos": 119, "type": "TASK", "confidence": 0.7185138960679373}]}, {"text": "We investigate several options, aiming at exploiting gazetteers to extract relevant features, and then at integrating these features in a neural model for entity recognition.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 155, "end_pos": 173, "type": "TASK", "confidence": 0.7844333648681641}]}, {"text": "We provide experimental evidences on two datasets (named entities and nominal entities) and two languages (English and Italian), showing that extracting features from a rich model of the gazetteer and then concatenating such features with the input embeddings of a neural model is the best strategy in all our experimental settings, significantly outperform-ing more conventional approaches.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the recent years a number of neural architectures have been successfully applied to several sequence labelling tasks, including, among others, part-of-speech tagging, named entity recognition (, and semantic role labeling (.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 146, "end_pos": 168, "type": "TASK", "confidence": 0.7414467334747314}, {"text": "named entity recognition", "start_pos": 170, "end_pos": 194, "type": "TASK", "confidence": 0.614208330710729}, {"text": "semantic role labeling", "start_pos": 202, "end_pos": 224, "type": "TASK", "confidence": 0.676168312629064}]}, {"text": "It has been shown that these architectures can achieve state-of-art performance with an end-to-end configuration, i.e. without recurring either to linguistic features or to external knowledge sources (e.g. gazetteers).", "labels": [], "entities": []}, {"text": "However, experiments have been often conducted over datasets with large amount of training data and in a rather limited spectrum of experimental conditions.", "labels": [], "entities": []}, {"text": "Overall, we think that there has not been much discussion about the use of gazetteers together with neural models, and that a deeper investigation is necessary.", "labels": [], "entities": []}, {"text": "In this paper we focus on the role of gazetteers for entity recognition.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.8166068196296692}]}, {"text": "The following are our two main research questions: (i) As neural networks architectures are highly modular, which is the best way to integrate information from gazetteers?", "labels": [], "entities": []}, {"text": "(ii) What is the impact of the size of both training data and gazetteers over the performance of a neural model for entity recognition?", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 116, "end_pos": 134, "type": "TASK", "confidence": 0.7555772960186005}]}, {"text": "As mentioned, we focus on entity recognition and refer to the Automatic Content Extraction program -ACE ().", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.8111869394779205}, {"text": "Automatic Content Extraction", "start_pos": 62, "end_pos": 90, "type": "TASK", "confidence": 0.5373910864194235}]}, {"text": "In this context, entity recognition has been approached as a sequence labeling task.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.8600684404373169}, {"text": "sequence labeling task", "start_pos": 61, "end_pos": 83, "type": "TASK", "confidence": 0.7533726692199707}]}, {"text": "Given an utterance U = {t 1 , t 2 , ..., tn } and a set of entity categories C = {c 1 , c 2 , ..., cm }, the task is to label the tokens in U that refer to entities belonging to the categories in C.", "labels": [], "entities": []}, {"text": "As an example, using the IOB format (Inside-Outside-Beginning,), the sentence \"I would like to order a salami pizza and two mozzarella cheese sandwiches\" could be labeled as shown in.", "labels": [], "entities": []}, {"text": "ACE distinguishes two main entity classes: named entities and nominal entities, and we consider both of them for our experiments.", "labels": [], "entities": [{"text": "ACE", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8685303926467896}]}, {"text": "The first entity class, named entities, roughly corresponds to proper names, and named entities recognition (NER) tools for frequent categories (i.e. persons as \"Barack Obama\", locations as \"New York\", and organizations as \"IBM\") have been developed for many languages.", "labels": [], "entities": [{"text": "named entities recognition (NER)", "start_pos": 81, "end_pos": 113, "type": "TASK", "confidence": 0.7938942114512125}]}, {"text": "Several datasets are available for training purposes (e.g. the Conll-2003 datasets).", "labels": [], "entities": [{"text": "Conll-2003 datasets", "start_pos": 63, "end_pos": 82, "type": "DATASET", "confidence": 0.963023841381073}]}, {"text": "It has been a common practice of NER systems to make use of gazetteers (i.e. lists of entity names), considering the presence of a token in certain gazetteer as an additional feature for the classifier (see, for instance, the use of the Stanford NER useGazettes parameter for the CRF classifier ().", "labels": [], "entities": []}, {"text": "Nominal entities, on the other hand, are noun phrase expressions describing an entity.", "labels": [], "entities": []}, {"text": "Differently from named entities, nominal entities are typically compositional, as they do allow morphological and syntactic variations (e.g. for food names, spanish baked salmon, roasted salmon and hot smoked salmon), which makes it possible to combine tokens of one entity name with tokens of another entity name to generate new names (e.g. for food names, salmon tacos is a potential food name given the existence of salmon and tacos).", "labels": [], "entities": []}, {"text": "In the framework of the ACE program there have been several attempts to develop supervised systems for nominal entities (; these systems, however, had to face the problem of the scarcity of annotated data, and, for this reason, were developed for few entity types.", "labels": [], "entities": []}, {"text": "In this paper we make use of an end-to-end state-of-art entity recognition system (described in Section 2), and investigate the combination with gazetteers under several integration methods, which are described in Section 3 and 4.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 56, "end_pos": 74, "type": "TASK", "confidence": 0.7275078743696213}]}, {"text": "Datasets for our experiments are described in Section 5, while results are presented and discussed in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experimental results for the various approaches that use gazetteers as features in the context of a neural entity recognition system, are discussed in this Section.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 111, "end_pos": 129, "type": "TASK", "confidence": 0.7598163485527039}]}, {"text": "For all experiments, the hyper-parameters of the neural model for both NN g and NeuroNLP2 are the same as in (  and) respectively.", "labels": [], "entities": []}, {"text": "show the results of gazetteer integration as embedding and as CRF features, respectively.", "labels": [], "entities": []}, {"text": "The NeuroNLP2 model benefits significantly from the gazetteer representation of NN g , especially for the DPD dataset (with an increment of 2.54 in terms of F1).", "labels": [], "entities": [{"text": "DPD dataset", "start_pos": 106, "end_pos": 117, "type": "DATASET", "confidence": 0.9075216054916382}, {"text": "F1", "start_pos": 157, "end_pos": 159, "type": "METRIC", "confidence": 0.9964414238929749}]}, {"text": "The combination of NeuData Set Gaz.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Statistics about data sets used for our experi- ments.", "labels": [], "entities": []}, {"text": " Table 3: Unique entities overlap between various sets.  The percentage refers to the count of unique entities in  the first dataset.", "labels": [], "entities": []}, {"text": " Table 4: Gazetteers used in the experiments. Description is provided in terms of number of entity names, total  number of tokens, average length and standard deviation (SD) of entities, type-token ratio (norm obtained by  repeated sampling of 200 tokens), type1 and type2 unique tokens ratio and sub-entity ratio.", "labels": [], "entities": [{"text": "average length and standard deviation (SD)", "start_pos": 131, "end_pos": 173, "type": "METRIC", "confidence": 0.8110793270170689}]}, {"text": " Table 5: Experimental results using gazetteers as features together with embeddings.", "labels": [], "entities": []}, {"text": " Table 6: Experimental results using gazetteers as features for CRF.", "labels": [], "entities": [{"text": "CRF", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.9318513870239258}]}, {"text": " Table 7: Learning Curve on the CONLL 2003 dataset.  Columns report the number of sentences in the training  dataset.", "labels": [], "entities": [{"text": "CONLL 2003 dataset", "start_pos": 32, "end_pos": 50, "type": "DATASET", "confidence": 0.9827664295832316}]}, {"text": " Table 8: Learning Curve on the DPD dataset. Columns  report the number of sentences in the training dataset.", "labels": [], "entities": [{"text": "DPD dataset", "start_pos": 32, "end_pos": 43, "type": "DATASET", "confidence": 0.9580385386943817}]}, {"text": " Table 9: Results of reducing gazetteer size on a less  common principle; in the columns, the first number is  the gazetteer size, while the second element represents  the minimum number of occurrences for the tokens in  the FOOD gazetteer.", "labels": [], "entities": [{"text": "reducing gazetteer size", "start_pos": 21, "end_pos": 44, "type": "TASK", "confidence": 0.6721314291159312}, {"text": "FOOD gazetteer", "start_pos": 225, "end_pos": 239, "type": "DATASET", "confidence": 0.9804794490337372}]}]}