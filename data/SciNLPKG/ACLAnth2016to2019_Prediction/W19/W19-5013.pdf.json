{"title": [{"text": "Query selection methods for automated corpora construction with a use casein food-drug interactions", "labels": [], "entities": [{"text": "automated corpora construction", "start_pos": 28, "end_pos": 58, "type": "TASK", "confidence": 0.6478018164634705}]}], "abstractContent": [{"text": "In this paper, we address the problem of automatically constructing a relevant corpus of scientific articles about food-drug interactions.", "labels": [], "entities": []}, {"text": "There is a growing number of scientific publications that describe food-drug interactions but currently building a high-coverage corpus that can be used for information extraction purposes is not trivial.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 157, "end_pos": 179, "type": "TASK", "confidence": 0.7554408609867096}]}, {"text": "We investigate several methods for automating the query selection process using an expert-curated corpus of food-drug interactions.", "labels": [], "entities": [{"text": "query selection process", "start_pos": 50, "end_pos": 73, "type": "TASK", "confidence": 0.7822658022244772}]}, {"text": "Our experiments show that index terms features along with a decision tree classifier are the best approach for this task and that feature selection approaches and in particular gain ratio outperform frequency-based methods for query selection.", "labels": [], "entities": [{"text": "query selection", "start_pos": 227, "end_pos": 242, "type": "TASK", "confidence": 0.758309930562973}]}], "introductionContent": [{"text": "Unexpected Food-Drug Interactions (FDIs) occasionally result in treatment failure, toxicity and an increased risk of side-effects.", "labels": [], "entities": [{"text": "Unexpected Food-Drug Interactions (FDIs)", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.7396557231744131}]}, {"text": "While drug-drug interactions can be investigated systematically, there is a much larger number of possible FDIs.", "labels": [], "entities": []}, {"text": "Therefore, these interactions are generally discovered and reported only after a drug is administered on a wide scale during post-marketing surveillance.", "labels": [], "entities": []}, {"text": "A notable example is the discovery that grapefruit contains bioactive furocoumarins and flavonoids that activate or deactivate many drugs in ways that can be life-threatening ().", "labels": [], "entities": []}, {"text": "This effect was first noticed accidentally during a test for drug interactions with alcohol that used grapefruit juice to hide the taste of ethanol.", "labels": [], "entities": []}, {"text": "Currently, information about FDIs is available to medical practitioners from online databases such as DrugBank and compendia such as the Stockley's Drug Interactions (, but these resources have to be regularly 1 https://www.drugbank.ca updated to keep up with a growing body of evidence from biomedical articles.", "labels": [], "entities": [{"text": "FDIs", "start_pos": 29, "end_pos": 33, "type": "TASK", "confidence": 0.7416505813598633}, {"text": "DrugBank", "start_pos": 102, "end_pos": 110, "type": "DATASET", "confidence": 0.9824589490890503}, {"text": "Stockley's Drug Interactions", "start_pos": 137, "end_pos": 165, "type": "DATASET", "confidence": 0.962953582406044}]}, {"text": "Recent advances in information extraction area promising direction to partially automate this work by extracting information about drug interactions.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 19, "end_pos": 41, "type": "TASK", "confidence": 0.8247775733470917}]}, {"text": "This approach has already shown promising results in the context of drug-drug interactions) but in the case of FDIs, similar progress is currently hindered by alack of annotated corpora.", "labels": [], "entities": [{"text": "FDIs", "start_pos": 111, "end_pos": 115, "type": "TASK", "confidence": 0.5848840475082397}]}, {"text": "The work presented in for inferring interactions between drugs and world cuisine is based on a largely manual effort of extracting food-drug interactions from descriptions provided in DrugBank.", "labels": [], "entities": [{"text": "DrugBank", "start_pos": 184, "end_pos": 192, "type": "DATASET", "confidence": 0.9455519914627075}]}, {"text": "Although a first corpus of MEDLINE abstracts about FDIs called POMELO was recently made available (, this corpus has a low coverage of relevant documents for FDIs.", "labels": [], "entities": [{"text": "POMELO", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.8607034683227539}]}, {"text": "The authors made use of PubMed to retrieve all the articles indexed with the Food-Drug Interactions term from the MeSH thesaurus 2 , but the challenge is that while articles annotated with Drug Interactions are abundant, there is a much smaller number of documents indexed with Food-Drug Interactions.", "labels": [], "entities": [{"text": "PubMed", "start_pos": 24, "end_pos": 30, "type": "DATASET", "confidence": 0.9700412154197693}, {"text": "MeSH thesaurus 2", "start_pos": 114, "end_pos": 130, "type": "DATASET", "confidence": 0.9336514870325724}]}, {"text": "A bibliographic analysis of the references cited in the Stockley's Drug Interactions in relation to foods shows that only 11% of these articles are indexed with the MeSH term Food-Drug Interactions, while almost 70% of the articles are available in MEDLINE (.", "labels": [], "entities": [{"text": "Stockley's Drug Interactions", "start_pos": 56, "end_pos": 84, "type": "DATASET", "confidence": 0.9523353725671768}, {"text": "MeSH", "start_pos": 165, "end_pos": 169, "type": "DATASET", "confidence": 0.8150550127029419}, {"text": "MEDLINE", "start_pos": 249, "end_pos": 256, "type": "DATASET", "confidence": 0.9449988007545471}]}, {"text": "Constructing a high-coverage corpus of FDIs using MeSH terms and PubMed is not trivial because there is a large number of articles that describe food interactions that were published before the introduction of the Food-Drug Interactions MeSH term in the early nineties.", "labels": [], "entities": [{"text": "PubMed", "start_pos": 65, "end_pos": 71, "type": "DATASET", "confidence": 0.9494146108627319}]}, {"text": "At the same time, MeSH terms are assigned to scientific articles based on their main topics of interest, miss- ing a considerable amount of articles that briefly mention interactions with food.", "labels": [], "entities": []}, {"text": "Furthermore, the POMELO corpus has an even more narrow focus on articles related to adverse effects, therefore it covers only 3% of the references provided in the Stockley compendium.", "labels": [], "entities": [{"text": "POMELO corpus", "start_pos": 17, "end_pos": 30, "type": "DATASET", "confidence": 0.924140214920044}, {"text": "Stockley compendium", "start_pos": 163, "end_pos": 182, "type": "DATASET", "confidence": 0.9838104248046875}]}, {"text": "shows a comparison of scientific articles cited in a reference compendium, with the articles annotated with the FoodDrug Interactions MeSH term and the Herb-Drug Interactions MeSH term (FDI+HDI).", "labels": [], "entities": []}, {"text": "It is worth noticing the overall ascending trend of scientific articles that address FDIs, showing an increased interest in this type of interactions.", "labels": [], "entities": [{"text": "FDIs", "start_pos": 85, "end_pos": 89, "type": "TASK", "confidence": 0.7164373397827148}]}, {"text": "This makes increasingly more costly the effort to manually summarise related information in specialised compendia.", "labels": [], "entities": [{"text": "summarise related information", "start_pos": 59, "end_pos": 88, "type": "TASK", "confidence": 0.8912513057390848}]}, {"text": "The figure also shows the timeline of the articles gathered in the official POMELO corpus (POMELO Official) and a more recent retrieval result of the POMELO query.", "labels": [], "entities": [{"text": "POMELO corpus (POMELO Official)", "start_pos": 76, "end_pos": 107, "type": "DATASET", "confidence": 0.8990305960178375}, {"text": "POMELO query", "start_pos": 150, "end_pos": 162, "type": "DATASET", "confidence": 0.8654107749462128}]}, {"text": "We address these limitations by considering several approaches for automatically selecting queries that can be used to retrieve domainspecific documents using an existing search engine.", "labels": [], "entities": []}, {"text": "The approach takes as input a sample set of relevant documents that are cited in the Stockley compendium.", "labels": [], "entities": [{"text": "Stockley compendium", "start_pos": 85, "end_pos": 104, "type": "DATASET", "confidence": 0.9901294112205505}]}, {"text": "In this way, the problem of FDI discovery from biomedical literature is limited to the task of interaction candidates search, that is the task of finding documents that describe FDIs from a large bibliographic database.", "labels": [], "entities": [{"text": "FDI discovery", "start_pos": 28, "end_pos": 41, "type": "TASK", "confidence": 0.9940602481365204}]}, {"text": "We make use of a large corpus of relevant publications to investigate index terms used to annotate articles about FDIs and we propose an automated method for query selection that increases recall.", "labels": [], "entities": [{"text": "FDIs", "start_pos": 114, "end_pos": 118, "type": "TASK", "confidence": 0.5714108943939209}, {"text": "recall", "start_pos": 189, "end_pos": 195, "type": "METRIC", "confidence": 0.9981204867362976}]}, {"text": "The main contributions of this work are: \u2022 a discriminative model for automatically constructing high-coverage and domain-specific corpora for information extraction, \u2022 an approach for automatically selecting queries using index terms as candidates, \u2022 an automated method to evaluate queries based on a sample corpus.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 143, "end_pos": 165, "type": "TASK", "confidence": 0.7577250301837921}]}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "We begin by discussing several design decisions for the subtask of classifying documents based on relevance, adopting a discriminative model for information retrieval in Section 3.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 145, "end_pos": 166, "type": "TASK", "confidence": 0.7653789222240448}]}, {"text": "In Section 4, we introduce the subtask of query selection discussing candidate term selection and several methods for scoring queries.", "labels": [], "entities": [{"text": "query selection", "start_pos": 42, "end_pos": 57, "type": "TASK", "confidence": 0.830106645822525}, {"text": "candidate term selection", "start_pos": 69, "end_pos": 93, "type": "TASK", "confidence": 0.6682642499605814}]}, {"text": "Section 5 describes the datasets used: Workflow for automated corpus construction using a collection of sample documents and a search engine to evaluate our approach for automatically constructing a corpus for FDIs and Section 6 presents the results of an empirical evaluation.", "labels": [], "entities": [{"text": "corpus construction", "start_pos": 62, "end_pos": 81, "type": "TASK", "confidence": 0.7232847958803177}]}, {"text": "Then we provide an overview of related work for this task in Section 7 and we discuss a formal definition for the problem at hand in Section 2.", "labels": [], "entities": []}, {"text": "We conclude this work in Section 8.", "labels": [], "entities": []}], "datasetContent": [{"text": "The corpus used in our experiments is manually constructed through a bibliographic analysis of the references provided in the Stockley compendium on drug interactions in relation to food.", "labels": [], "entities": [{"text": "Stockley compendium", "start_pos": 126, "end_pos": 145, "type": "DATASET", "confidence": 0.9578550159931183}]}, {"text": "These are considered as positives examples that are used to train a discriminative classifier.", "labels": [], "entities": []}, {"text": "The problem of finding negative examples is more challenging because of the problem of unbalanced data and because we aim to train a classifier that is sensitive enough to distinguish between scientific articles that are closely related in topic (i.e., published in the same journals) but that do not describe FDIs.", "labels": [], "entities": []}, {"text": "We manually identify references from pages listed in the index under individual foodstuffs and Foods, fora total of 912 references and 460 references, respectively.", "labels": [], "entities": []}, {"text": "Using the title and the year of each reference, we retrieve 802 unique PubMed identifiers for references that are available in MEDLINE.", "labels": [], "entities": [{"text": "MEDLINE", "start_pos": 127, "end_pos": 134, "type": "DATASET", "confidence": 0.9567832946777344}]}, {"text": "In our experiments, we make use of corpora built from MEDLINE abstracts published before 2008 since the version of the Stockley compendium that is available to us was published at this date.", "labels": [], "entities": [{"text": "MEDLINE abstracts", "start_pos": 54, "end_pos": 71, "type": "DATASET", "confidence": 0.8220184743404388}, {"text": "Stockley compendium", "start_pos": 119, "end_pos": 138, "type": "DATASET", "confidence": 0.9683640003204346}]}, {"text": "Starting from this collection, several subsets of abstracts are constructed as follows: From the first and third subsets, we analyse the list of journals where the articles have been published and all the abstracts published in those journals.", "labels": [], "entities": []}, {"text": "In that respect, we have two additional abstract subsets jrnlAbstracts() from Stockley2008 and jrnlAbstracts() from DRUGFOOD respectively.", "labels": [], "entities": [{"text": "Stockley2008", "start_pos": 78, "end_pos": 90, "type": "DATASET", "confidence": 0.9808407425880432}, {"text": "DRUGFOOD", "start_pos": 116, "end_pos": 124, "type": "DATASET", "confidence": 0.9630438685417175}]}, {"text": "In our experiments, the set of positive abstracts is the union of Stockley's references with the results of the FDI-HDI queries.", "labels": [], "entities": []}, {"text": "presents the size of the subsets.", "labels": [], "entities": []}, {"text": "The problem of constructing a domain-specific corpus for FDIs is characterised by unbalanced training sets with the non-relevant class representing a large portion of all the examples, while the relevant class has only a small percent of the examples.", "labels": [], "entities": [{"text": "FDIs", "start_pos": 57, "end_pos": 61, "type": "TASK", "confidence": 0.9083852171897888}]}, {"text": "Dealing with unbalanced class distributions is inherently challenging for discriminative: Overview of different corpora used in our experiments and their size in number of documents algorithms resulting in trivial classifiers that completely ignore the minority class.", "labels": [], "entities": []}, {"text": "We deal with the problem of unbalanced data by under-sampling the majority class such that the training examples in both classes are equal.", "labels": [], "entities": []}, {"text": "For the purpose of selecting relevant documents regarding food-drug interactions, we evaluate several configurations to construct an efficient classification model.", "labels": [], "entities": []}, {"text": "Three sets of experiments are designed around the three training datasets described in the previous section.", "labels": [], "entities": []}, {"text": "For each case, we evaluate the models using average of Precision (P), Recall (R) and F1-score (F1) using 10-fold crossvalidation.", "labels": [], "entities": [{"text": "Precision (P)", "start_pos": 55, "end_pos": 68, "type": "METRIC", "confidence": 0.9586516916751862}, {"text": "Recall (R)", "start_pos": 70, "end_pos": 80, "type": "METRIC", "confidence": 0.9646804481744766}, {"text": "F1-score (F1)", "start_pos": 85, "end_pos": 98, "type": "METRIC", "confidence": 0.8556673973798752}]}, {"text": "shows the cross-validation results for different word-based features described in Section 3.", "labels": [], "entities": []}, {"text": "The best results in terms of F1-score are obtained across all datasets for TF-IDF features with an SVM classifier.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.999083399772644}]}, {"text": "TF-IDF of unigram features combined with SVM classifier produce the best F1-score on all datasets.", "labels": [], "entities": [{"text": "TF-IDF", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.6001614928245544}, {"text": "F1-score", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9982681274414062}]}, {"text": "Focusing on these configurations, results are detailed in where we can notice that the recall is higher for the third dataset.", "labels": [], "entities": [{"text": "recall", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.9996911287307739}]}, {"text": "The best F1-score presents a low standard deviation, which shows that the obtained model is relatively stable.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9991008043289185}]}, {"text": "We conclude that results are better on datasets that use a more restrictive filter for selecting the negative examples (Experiment 3).", "labels": [], "entities": []}, {"text": "This demonstrates that the random sampling approach for the majority class can benefit from using a more informed strategy than selecting documents from the full collection.", "labels": [], "entities": []}, {"text": "The next set of experiments is focused on evaluating the performance of features based on index terms as can be seen in.", "labels": [], "entities": []}, {"text": "All the index terms that are used to annotate at least 10 documents from our collection are considered as features, ignoring the less frequent index terms.", "labels": [], "entities": []}, {"text": "In general, the results are comparable or better than the best results using word features in terms of F1-score.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 103, "end_pos": 111, "type": "METRIC", "confidence": 0.9970231652259827}]}, {"text": "In the case of index terms features, the best results are obtained for the decision tree classifier that outperforms the linear SVM classifier on all three datasets.", "labels": [], "entities": []}, {"text": "The same conclusion can be drawn from these experiments in relation to the random sampling approach as the best results are obtained again for the third experiment.", "labels": [], "entities": []}, {"text": "The challenge for evaluating queries is that it is preferable to rely on the training examples alone for evaluation.", "labels": [], "entities": []}, {"text": "But each selected query will retrieve documents that might be relevant but that are not contained in the provided dataset.", "labels": [], "entities": []}, {"text": "To address this issue, we use the best performing classification approach described in the previous section to predict the relevance of retrieved documents instead of computing precision based on the docu-: Results of 10-fold cross-validation using different classifiers: decision tree (DTree), linear SVM (LSVC), multinomial Naive Bayes (MNB), logistic regression (LogReg), and RandomForest (RFC) with index terms features.", "labels": [], "entities": [{"text": "precision", "start_pos": 177, "end_pos": 186, "type": "METRIC", "confidence": 0.9943119287490845}]}, {"text": "The overall best results are marked with a star ments known to be relevant alone.", "labels": [], "entities": []}, {"text": "Our assumption is that the high performance achieved by the classifier allows us to compute a reliable estimate of precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 115, "end_pos": 124, "type": "METRIC", "confidence": 0.9979070425033569}]}, {"text": "Although not perfect, this evaluation strategy allows us to avoid the need for further manual annotation or relevant documents.", "labels": [], "entities": []}, {"text": "Recall is calculated fora limited number of retrieved documents as some of the MeSH index terms such as Humans and Animals are broad enough to be used for annotating most of the documents in the test collection.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9933241009712219}]}, {"text": "Word-based query candidates are not further considered at this stage because the best classification performance is achieved for 1-gram features which are deemed to be too ambiguous for our purposes.", "labels": [], "entities": []}, {"text": "gives an overview of the top 30 1-gram features selected using the SVM classifier.", "labels": [], "entities": []}, {"text": "Several names of drugs such as aminophylline, cyclosporine, and ephedrine that are known to have interactions with foods are among the highest ranked features.", "labels": [], "entities": []}, {"text": "Foods such as caffeine, coffee, cola and grapefruit are also known for their high potential of interactions with drugs.", "labels": [], "entities": []}, {"text": "Among these features, names of plants with drug interactions are present including biloba and kava.", "labels": [], "entities": []}, {"text": "Although interesting on their own, we conclude that these features are too generic to be used as queries to extract articles about FDIs without further combining them with other features or index terms.", "labels": [], "entities": []}, {"text": "On the other hand, index term candidates are much more precise, including many terms that refer to food-drug interaction mechanisms such ingestion phytotherapy as Biological Availability and Cytochrome P-450 CYP3A.", "labels": [], "entities": [{"text": "Biological Availability", "start_pos": 163, "end_pos": 186, "type": "TASK", "confidence": 0.6271074861288071}]}, {"text": "Also included in this list are chemical compounds such as Flavanones and Furocoumarins that are contained in certain foods such as grapefruit and that interact with many drugs.", "labels": [], "entities": [{"text": "Flavanones", "start_pos": 58, "end_pos": 68, "type": "METRIC", "confidence": 0.9957429766654968}, {"text": "Furocoumarins", "start_pos": 73, "end_pos": 86, "type": "METRIC", "confidence": 0.9851374626159668}]}, {"text": "gives an overview of the results obtained by each scoring function discussed in the previous section.", "labels": [], "entities": []}, {"text": "Performance is computed for the top 20 ranked queries for each method.", "labels": [], "entities": []}, {"text": "All the methods score high the Food-Drug interactions MeSH term but we remove this term from the results because it was used to construct the FDIs corpus.", "labels": [], "entities": [{"text": "MeSH", "start_pos": 54, "end_pos": 58, "type": "METRIC", "confidence": 0.6616033315658569}, {"text": "FDIs corpus", "start_pos": 142, "end_pos": 153, "type": "DATASET", "confidence": 0.8766185641288757}]}, {"text": "Overall, the best performance is obtained by the Gain ratio scoring function.", "labels": [], "entities": [{"text": "Gain ratio scoring function", "start_pos": 49, "end_pos": 76, "type": "METRIC", "confidence": 0.9690160006284714}]}, {"text": "Selected queries using this approach include: Biological Availability, Drug Interactions, and Intestinal Absorption.", "labels": [], "entities": [{"text": "Biological Availability", "start_pos": 46, "end_pos": 69, "type": "TASK", "confidence": 0.6398752927780151}]}, {"text": "Gain ratio outperforms other approaches because it penalizes high frequency terms that are too broad, such as Adult, Aged, and Female.", "labels": [], "entities": [{"text": "Gain ratio", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.8399788737297058}]}], "tableCaptions": [{"text": " Table 3: Overview of different corpora used in our ex- periments and their size in number of documents", "labels": [], "entities": []}, {"text": " Table 4: Results of 10-fold cross-validation on the three  datasets using an SVM classifier and 1-gram TF-IDF  features. The best result is marked with a star", "labels": [], "entities": []}, {"text": " Table 5: Results of 10-fold cross-validation using dif- ferent classifiers: decision tree (DTree), linear SVM  (LSVC), multinomial Naive Bayes (MNB), logistic re- gression (LogReg), and RandomForest (RFC) with in- dex terms features. The overall best results are marked  with a star", "labels": [], "entities": []}, {"text": " Table 7: Scoring functions evaluated for the top 20", "labels": [], "entities": [{"text": "Scoring", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.975737988948822}]}]}