{"title": [{"text": "Dependency distance minimization: facts, theory and predictions Short bio", "labels": [], "entities": [{"text": "Dependency distance minimization", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8360611995061239}]}], "abstractContent": [{"text": "Quantitative linguistics is a branch of linguistics concerned about the study of statistical facts about languages and their explanation aiming at constructing a general theory of language.", "labels": [], "entities": [{"text": "Quantitative linguistics", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8643908798694611}]}, {"text": "The quantitative study of syntax has become central to this branch of linguistics.", "labels": [], "entities": []}, {"text": "The fact that the distance between syntactically related words is smaller than expected by chance in many languages led to the formulation of a dependency distance minimization (DDm) principle.", "labels": [], "entities": [{"text": "dependency distance minimization (DDm)", "start_pos": 144, "end_pos": 182, "type": "TASK", "confidence": 0.6974979639053345}]}, {"text": "From a theoretical standpoint, DDm is in conflict with another word order principle: surprisal minimization (Sm).", "labels": [], "entities": [{"text": "surprisal minimization (Sm)", "start_pos": 85, "end_pos": 112, "type": "TASK", "confidence": 0.7658790588378906}]}, {"text": "In single head structures, DDm predicts that the head should be put at the center of the linear arrangement, while Sm predicts that it should be put atone of the ends.", "labels": [], "entities": []}, {"text": "In spite of the massive evidence of the action of DDm and the trendy claim that languages are optimized, attempts to quantify the degree of optimization of languages according to DDm have been rather scarce.", "labels": [], "entities": []}, {"text": "Here we present anew optimality measure indicating that languages are optimized to a 70We confirm two old theoretical predictions: that the action of DDm is stronger in longer sentences and that DDm is more likely to be beaten by Sm in short sequences (resulting in an anti-DDm effect), while shedding new light on the kind of tree structures where DDm is more likely to be shadowed.", "labels": [], "entities": []}, {"text": "Finally, we review various theoretical predictions of DDm focusing on the scarcity of crossing dependencies.", "labels": [], "entities": [{"text": "DDm", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.8974305391311646}]}, {"text": "We challenge the belief that formal constraints on dependency trees (e.g., projectivity or relaxed versions) are real rather than epiphenomenal.", "labels": [], "entities": []}, {"text": "The talk is a summary of joint work with-i-Cancho is associate professor at Universitat Polit\u00e8cnica de Catalunya and the head of the Complexity and Quantitative Linguistics Lab.", "labels": [], "entities": []}, {"text": "He is a language researcher in abroad sense.", "labels": [], "entities": []}, {"text": "His research covers different levels of the organization of life: from human language to animal behavior and down farther to the molecular level.", "labels": [], "entities": []}, {"text": "One of his main research objectives is the development of a parsimonious but general theory of language and communication integrating insights from probability theory, information theory and the theory of spatial networks.", "labels": [], "entities": []}, {"text": "In the context of syntax, he pioneered the study of dependency lengths from a statistical standpoint putting forward the first baselines and the principle of dependency distance minimization.", "labels": [], "entities": [{"text": "dependency distance minimization", "start_pos": 158, "end_pos": 190, "type": "TASK", "confidence": 0.6623406012852987}]}, {"text": "He also introduced the hypothesis that projectivity, the scarcity of crossings dependencies and consistent branching are epiphenomena of that principle.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}