{"title": [{"text": "Numbers Normalisation in the Inflected Languages: a Case Study of Polish", "labels": [], "entities": [{"text": "Numbers Normalisation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7959604263305664}]}], "abstractContent": [{"text": "Text normalisation in Text-to-Speech systems is a process of converting written expressions to their spoken forms.", "labels": [], "entities": [{"text": "Text normalisation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7667539119720459}]}, {"text": "This task is complicated because in many cases the normalised form depends on the context.", "labels": [], "entities": []}, {"text": "Furthermore, when we analysed languages like Croatian, Lithuanian, Polish, Russian or Slovak there is additional difficulty related to their inflected nature.", "labels": [], "entities": []}, {"text": "In this paper we want to show how to deal with this problem for one of these languages: Polish , without having a large dedicated data set and using solutions prepared for other NLP tasks.", "labels": [], "entities": []}, {"text": "We limited our study to only numbers expressions, which are the most common non-standard words to normalise.", "labels": [], "entities": []}, {"text": "The proposed solution is a combination of morphological tag-ger and transducer supported by a dictionary of numbers in their spoken forms.", "labels": [], "entities": []}, {"text": "The data set used for evaluation is based on the part of 1-million word subset of the National Corpus of Polish.", "labels": [], "entities": [{"text": "National Corpus of Polish", "start_pos": 86, "end_pos": 111, "type": "DATASET", "confidence": 0.9669881016016006}]}, {"text": "The accuracy of the described approach is presented with a comparison to a simple baseline and two commercial systems: Google Cloud Text-to-Speech and Amazon Polly.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9984015822410583}]}], "introductionContent": [{"text": "In Text-to-Speech (TTS) or automatic speech recognition (ASR) text normalisation is a task of converting written expressions to their spoken equivalents.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR) text normalisation", "start_pos": 27, "end_pos": 80, "type": "TASK", "confidence": 0.8287101350724697}]}, {"text": "For example in English, sentence \"I have 3 dogs\" will be normalised to \"I have three dogs\".", "labels": [], "entities": []}, {"text": "In inflected languages, like Polish, this task is much harder as presented in.", "labels": [], "entities": []}, {"text": "We can see that for English sentences number \"2\" is always normalised to \"two\", but for Polish, this is more complicated.", "labels": [], "entities": []}, {"text": "Each of the Polish sentences has a different normalised form of number \"2\" (dw\u00f3ch, dwie, dwaj).", "labels": [], "entities": []}, {"text": "These forms are only a small part of all possible forms of this number which is one of the reasons why text normalisation for the Polish language is more complicated than for English.", "labels": [], "entities": [{"text": "text normalisation", "start_pos": 103, "end_pos": 121, "type": "TASK", "confidence": 0.782608151435852}]}, {"text": "This paper presents the solution for this specific problem -normalising number expressions in the Polish language.", "labels": [], "entities": []}, {"text": "The rest of the paper is organised as follows.", "labels": [], "entities": []}, {"text": "Section 2 briefly shows the related work and our motivation.", "labels": [], "entities": []}, {"text": "Next, we describe the architecture of our system.", "labels": [], "entities": []}, {"text": "Section 4 elaborates on experiments and evaluation.", "labels": [], "entities": []}, {"text": "It presents the prepared data set and the results of two experiments.", "labels": [], "entities": []}, {"text": "Finally, Section 5 concludes our work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We prepared two experiments to evaluate the correctness of our system.", "labels": [], "entities": []}, {"text": "The first experiment was only for the transducer, second for the whole system with the comparison to baseline and two commercial systems: Google Cloud Text-to-Speech  and Amazon Polly.", "labels": [], "entities": []}, {"text": "The above experiments used the data set of sentences with their spoken forms and additional information like morphological tags and classes.", "labels": [], "entities": []}, {"text": "Details about the data set and experiments are shown in the next subsections.", "labels": [], "entities": []}, {"text": "In the first experiment, we tested the hypothesis that having a class and morphological tags is sufficient to normalise a token properly.", "labels": [], "entities": []}, {"text": "For this pur-   pose, we examined the transducer component.", "labels": [], "entities": []}, {"text": "Results of this experiment are presented in.", "labels": [], "entities": []}, {"text": "The transducer achieved 95.75% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9992528557777405}]}, {"text": "We observed several types of problems.", "labels": [], "entities": []}, {"text": "Firstly, there were situations where the cardinal number had two possible forms fora given case and gender (e.g. \"trzej\", \"trzech\") and the transducer did not know which of these forms to chose (in the presented example it chose \"trzech\").", "labels": [], "entities": []}, {"text": "The second problem was related with messy data which were unexpected by the transducer (e.g. \"5--letni\").", "labels": [], "entities": []}, {"text": "The Accuracy on the FRACTION class was caused by cases when the fraction did not have an inflected form (e.g. 1/3 sometimes should be normalised to \"jedn \u02db a trzeci \u02db a\" not to \"jedna trzecia\").", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9993504881858826}, {"text": "FRACTION", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9962379932403564}]}, {"text": "For the DE-CIMAL class individual tokens should be replaced not directly but in a context-sensitive manner (e.g. 0.5 should be normalised to \"p\u00f3\u0142\").", "labels": [], "entities": []}, {"text": "However, we assumed that the results of this component are acceptable and it can be used in the designed system.", "labels": [], "entities": []}, {"text": "To estimate how well our system works we compared it with three solutions: baseline that does not rely on morphological tags and two commercial systems: Google Cloud Text-to-Speech 2 and Amazon Polly 3 . For this experiment, we selected 250 sentences with 407 tokens for normalisation.", "labels": [], "entities": []}, {"text": "We reduced the number of sentences for this experiment because of two reasons.", "labels": [], "entities": []}, {"text": "First of all most of the sentences in the data set represent the same context and difference is only in the number value which does not bring anything interesting to the DECIMAL class, our system had the worst accuracy which was the consequence of the transducer behaviour.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 210, "end_pos": 218, "type": "METRIC", "confidence": 0.99916672706604}]}, {"text": "For almost all classes our system achieves the best results; for the others, it does not standout significantly.", "labels": [], "entities": []}, {"text": "Accuracy for the TELEPHONE class results from the specific reading of the telephone numbers (e.g. four digits numbers like 7128 are read in pairs so correct normalised form will be \"siedemdziesi \u02db at jeden dwadzie\u00b4sciadwadzie\u00b4scia osiem\").", "labels": [], "entities": [{"text": "TELEPHONE", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9621119499206543}]}], "tableCaptions": [{"text": " Table 1: The difference between text normalization for Polish and English language.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 33, "end_pos": 51, "type": "TASK", "confidence": 0.7471061050891876}]}, {"text": " Table 2: Classes of tokens with examples.", "labels": [], "entities": []}, {"text": " Table 3: The distribution of numerical token classes in  the data set.", "labels": [], "entities": []}, {"text": " Table 4: The accuracy of the transducer component.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.999640941619873}]}, {"text": " Table 5: Our system evaluation with comparison to baseline, Google Cloud Text-to-Speech and Amazon Polly.  Bold values indicate the highest scores in the category.", "labels": [], "entities": []}]}