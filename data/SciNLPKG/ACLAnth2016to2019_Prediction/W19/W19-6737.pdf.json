{"title": [{"text": "Incremental Adaptation of NMT for Professional Post-editors: A User Study", "labels": [], "entities": [{"text": "Incremental Adaptation of NMT", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8398262560367584}]}], "abstractContent": [{"text": "A common use of machine translation in the industry is providing initial translation hypotheses, which are later supervised and post-edited by a human expert.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 16, "end_pos": 35, "type": "TASK", "confidence": 0.7515475451946259}]}, {"text": "During this revision process, new bilingual data are continuously generated.", "labels": [], "entities": []}, {"text": "Machine translation systems can benefit from these new data, incrementally updating the underlying models under an online learning paradigm.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7990396618843079}]}, {"text": "We conducted a user study on this scenario, fora neural machine translation system.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.7387298345565796}]}, {"text": "The experimentation was carried out by professional translators, with avast experience in machine translation post-editing.", "labels": [], "entities": [{"text": "machine translation post-editing", "start_pos": 90, "end_pos": 122, "type": "TASK", "confidence": 0.7855827808380127}]}, {"text": "The results showed a reduction in the required amount of human effort needed when post-editing the outputs of the system, improvements in the translation quality and a positive perception of the adaptive system by the users.", "labels": [], "entities": [{"text": "translation", "start_pos": 142, "end_pos": 153, "type": "TASK", "confidence": 0.9534327387809753}]}], "introductionContent": [{"text": "Translation post-editing is a common use case of machine translation (MT) in the industrial environment.", "labels": [], "entities": [{"text": "Translation post-editing", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8878124356269836}, {"text": "machine translation (MT)", "start_pos": 49, "end_pos": 73, "type": "TASK", "confidence": 0.8403533697128296}]}, {"text": "Post-editing consists of the supervision by a human agent of outputs generated by an MT system, who corrects the errors made by the MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 85, "end_pos": 87, "type": "TASK", "confidence": 0.8613219857215881}]}, {"text": "As MT systems are continuously improving their capabilities, translation post-editing has acquired major relevance in the translation market.", "labels": [], "entities": [{"text": "MT", "start_pos": 3, "end_pos": 5, "type": "TASK", "confidence": 0.9659061431884766}, {"text": "translation post-editing", "start_pos": 61, "end_pos": 85, "type": "TASK", "confidence": 0.9184965193271637}, {"text": "translation", "start_pos": 122, "end_pos": 133, "type": "TASK", "confidence": 0.9657580256462097}]}, {"text": "As a byproduct of this process, new data are continuously generated.", "labels": [], "entities": []}, {"text": "These data have valuable properties: they are domain-specific training samples, which can be leveraged for adapting the system towards a given domain or post-editor.", "labels": [], "entities": []}, {"text": "Moreover, an adaptive system can learn from its mistakes.", "labels": [], "entities": []}, {"text": "In other words, it can avoid making the same errors again.", "labels": [], "entities": []}, {"text": "A typical way of profiting from these post-edits consists in updating the system following an online learning paradigm: as the user validates a postedit, the system is incrementally updated, by taking into account this sample.", "labels": [], "entities": []}, {"text": "Hence, when the system generates the next translation, it will consider the previous user post-edits.", "labels": [], "entities": []}, {"text": "It is expected that better translations (or more suited to the human posteditor preferences) will be produced.", "labels": [], "entities": []}, {"text": "In this paper, we evaluate this strategy in an industrial scenario.", "labels": [], "entities": []}, {"text": "We study the enhancements brought about by an adaptive system via online learning, and the effects on the post-editing process of data generated by a neural machine translation (NMT) system.", "labels": [], "entities": []}, {"text": "To that end, we firstly evaluate our system under laboratory conditions.", "labels": [], "entities": []}, {"text": "Next, we conduct the evaluation of the system on a production environment.", "labels": [], "entities": []}, {"text": "This experiment involved professional translators, who regularly rely on MT post-editing in their workflow.", "labels": [], "entities": [{"text": "MT post-editing", "start_pos": 73, "end_pos": 88, "type": "TASK", "confidence": 0.8782139718532562}]}, {"text": "The results show improvements of adaptive systems in terms of productivity and translation quality.", "labels": [], "entities": [{"text": "translation", "start_pos": 79, "end_pos": 90, "type": "TASK", "confidence": 0.9513669610023499}]}], "datasetContent": [{"text": "We now describe the experimental conditions arranged in our study: the translation systems and environment, the main features of the tasks understudy and the evaluation criteria considered.", "labels": [], "entities": []}, {"text": "We evaluated our systems on areal task from our production scenario.", "labels": [], "entities": []}, {"text": "This task consisted in a small corpus belonging to a medico-technical domain (description of medical equipments), and was conformed by two documents of 150 sentences each, containing 1.7 and 2.7 thousand words respectively.", "labels": [], "entities": []}, {"text": "The translation direction was from English to Spanish.", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9649830460548401}]}, {"text": "Since we lacked an in-domain corpus, we trained a general system with the data from the translation task from WMT'13 (, consisting in 15 million parallel segments.", "labels": [], "entities": [{"text": "translation task", "start_pos": 88, "end_pos": 104, "type": "TASK", "confidence": 0.9066706895828247}, {"text": "WMT'13", "start_pos": 110, "end_pos": 116, "type": "DATASET", "confidence": 0.8825961947441101}]}, {"text": "Next, we applied the FDA data selection technique for selecting related instances from our general corpus and a medical (UFAL, Bojar et al., 2017) and technological 2 ones.", "labels": [], "entities": [{"text": "UFAL, Bojar et al., 2017)", "start_pos": 121, "end_pos": 146, "type": "DATASET", "confidence": 0.8974208980798721}]}, {"text": "We selected 8 million additional segments, which were used for fine-tuning the general system.", "labels": [], "entities": []}, {"text": "The effects of adaptivity were assessed according to the post-editing time and to two common MT metrics: (h)BLEU () and (h)TER).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 108, "end_pos": 112, "type": "METRIC", "confidence": 0.9969504475593567}, {"text": "TER", "start_pos": 123, "end_pos": 126, "type": "METRIC", "confidence": 0.998387336730957}]}, {"text": "For ensuring consistent BLEU scores, we used sacreBLEU.", "labels": [], "entities": [{"text": "BLEU scores", "start_pos": 24, "end_pos": 35, "type": "METRIC", "confidence": 0.9589529037475586}]}, {"text": "Since we computed per-sentence BLEU scores, we used exponential BLEU smoothing.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 31, "end_pos": 35, "type": "METRIC", "confidence": 0.9796800017356873}, {"text": "BLEU", "start_pos": 64, "end_pos": 68, "type": "METRIC", "confidence": 0.9539954662322998}]}, {"text": "In order to determine whether two systems presented statistically significant differences, we applied approximate randomization tests (), with 10, 000 repetitions and a p-value of 0.05.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results of the simulated experiments. Static sys- tems stand for conventional post-editing, without adaptation.  Adaptive systems refer to post-editing in an environment with  online learning. TER and BLEU were computed against the  reference sentences.  \u2020 indicates statistically significant differ- ences between the static and the adaptive systems.", "labels": [], "entities": [{"text": "TER", "start_pos": 203, "end_pos": 206, "type": "METRIC", "confidence": 0.9958574175834656}, {"text": "BLEU", "start_pos": 211, "end_pos": 215, "type": "METRIC", "confidence": 0.9902178645133972}]}, {"text": " Table 3: Results of the user experiments. Static systems stand  for conventional post-editing, without adaptation. Adaptive  systems refer to post-editing in an environment with online  learning. Time corresponds to the average post-editing time  per sentence, in seconds. hTER and hBLEU refer to the TER  and BLEU of the system hypothesis computed against the  post-edited sentences.  \u2020 indicates statistically significant dif- ferences between the static and the adaptive systems.", "labels": [], "entities": [{"text": "TER", "start_pos": 302, "end_pos": 305, "type": "METRIC", "confidence": 0.9951536655426025}, {"text": "BLEU", "start_pos": 311, "end_pos": 315, "type": "METRIC", "confidence": 0.9611898064613342}]}]}