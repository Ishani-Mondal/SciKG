{"title": [{"text": "Abstract Meaning Representation for Human-Robot Dialogue", "labels": [], "entities": [{"text": "Abstract Meaning Representation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7896805306275686}]}], "abstractContent": [{"text": "In this research, we begin to tackle the challenge of natural language understanding (NLU) in the context of the development of a robot dialogue system.", "labels": [], "entities": [{"text": "natural language understanding (NLU)", "start_pos": 54, "end_pos": 90, "type": "TASK", "confidence": 0.8186263541380564}]}, {"text": "We explore the adequacy of Abstract Meaning Representation (AMR) as a conduit for NLU.", "labels": [], "entities": [{"text": "Abstract Meaning Representation (AMR)", "start_pos": 27, "end_pos": 64, "type": "TASK", "confidence": 0.810590922832489}, {"text": "NLU", "start_pos": 82, "end_pos": 85, "type": "DATASET", "confidence": 0.7986621856689453}]}, {"text": "First, we consider the feasibility of using existing AMR parsers for automatically creating meaning representations for robot-directed transcribed speech data.", "labels": [], "entities": []}, {"text": "We evaluate the quality of output of two parsers on this data against a manually annotated gold-standard data set.", "labels": [], "entities": []}, {"text": "Second, we evaluate the semantic coverage and distinctions made in AMR overall: how well does it capture the meaning and distinctions needed in our collaborative human-robot dialogue do-main?", "labels": [], "entities": [{"text": "AMR", "start_pos": 67, "end_pos": 70, "type": "TASK", "confidence": 0.7221750020980835}]}, {"text": "We find that AMR has gaps that align with linguistic information critical for effective human-robot collaboration in search and navigation tasks, and we present task-specific modifications to AMR to address the deficiencies .", "labels": [], "entities": [{"text": "AMR", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.8595069050788879}, {"text": "search and navigation tasks", "start_pos": 117, "end_pos": 144, "type": "TASK", "confidence": 0.7646292895078659}]}], "introductionContent": [{"text": "A central challenge in human-agent collaboration is that robots (or their virtual counterparts) do not have sufficient linguistic or world knowledge to communicate in a timely and effective manner with their human collaborators ( . We address this challenge in ongoing research directed at analyzing robotdirected communication in collaborative humanagent exploration tasks, with the ultimate goal of enabling robots to adapt to domain-specific language.", "labels": [], "entities": []}, {"text": "The latter motivation is especially important given that our human-robot dialogue is physically situated.", "labels": [], "entities": []}, {"text": "This stands in contrast to many other dialogue systems, such as taskoriented chat bots, which do not require establishing and acting upon a shared understanding of the physical environment and often do not require any intermediate semantic representation (see \u00a76 for further comparison to related work).", "labels": [], "entities": []}, {"text": "Our paper is structured as follows: First, we present background both on the corpus of humanrobot dialogue we are leveraging ( \u00a72), and on AMR ( \u00a73).", "labels": [], "entities": [{"text": "AMR", "start_pos": 139, "end_pos": 142, "type": "DATASET", "confidence": 0.7379744648933411}]}, {"text": "\u00a74 discusses the implementation and results of two AMR parsers on the human-robot dialogue data.", "labels": [], "entities": [{"text": "AMR parsers", "start_pos": 51, "end_pos": 62, "type": "TASK", "confidence": 0.7810701727867126}]}, {"text": "\u00a75 assesses the semantic coverage of AMR for the human-robot dialogue data in particular.", "labels": [], "entities": [{"text": "AMR", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.8369594812393188}]}, {"text": "We then discuss related work that informs the current research in \u00a76.", "labels": [], "entities": []}, {"text": "Finally, \u00a77 concludes and presents ideas for future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Example of a Transaction Unit (TU) in the existing corpus dialogue annotation, which contains an instruction initiated", "labels": [], "entities": []}, {"text": " Table 2: Parser performance on human-robot dialogue data.", "labels": [], "entities": []}]}