{"title": [{"text": "Apertium-fin-eng-Rule-based shallow machine translation for WMT 2019 shared task", "labels": [], "entities": [{"text": "Apertium-fin-eng-Rule-based shallow machine translation", "start_pos": 0, "end_pos": 55, "type": "TASK", "confidence": 0.6454024463891983}, {"text": "WMT", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.8427973389625549}]}], "abstractContent": [{"text": "In this paper I describe a rule-based, bi-directional machine translation system for the Finnish-English language pair.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.7505050003528595}]}, {"text": "The original system is based on the existing data of FinnWordNet, omorfi and apertium-eng.", "labels": [], "entities": [{"text": "FinnWordNet", "start_pos": 53, "end_pos": 64, "type": "DATASET", "confidence": 0.9911829233169556}]}, {"text": "I have built the disambiguation, lexical selection and translation rules by hand.", "labels": [], "entities": []}, {"text": "The dictionaries and rules have been developed based on the shared task data.", "labels": [], "entities": []}, {"text": "I describe in this article the use of the shared task data as a kind of a test-driven development workflow in RBMT development and show that it suits perfectly to a modern software engineering continuous integration workflow of RBMT and yields big increases to BLEU scores with minimal effort.", "labels": [], "entities": [{"text": "RBMT development", "start_pos": 110, "end_pos": 126, "type": "TASK", "confidence": 0.9156428575515747}, {"text": "BLEU scores", "start_pos": 261, "end_pos": 272, "type": "METRIC", "confidence": 0.9767301082611084}]}, {"text": "The system described in the article is mainly developed during shared tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes our submission for FinnishEnglish language pair to the machine translation shared task of the Fourth conference on machine translation (WMT19) at ACL 2019.", "labels": [], "entities": [{"text": "machine translation shared task of the Fourth conference on machine translation (WMT19) at ACL 2019", "start_pos": 76, "end_pos": 175, "type": "TASK", "confidence": 0.7827998049118939}]}, {"text": "Traditionally rule-based machine translation (RBMT) is not in the focus for WMT shared tasks, however, there are two reasons I experimented with this system this year.", "labels": [], "entities": [{"text": "rule-based machine translation (RBMT)", "start_pos": 14, "end_pos": 51, "type": "TASK", "confidence": 0.7664271493752798}, {"text": "WMT shared tasks", "start_pos": 76, "end_pos": 92, "type": "TASK", "confidence": 0.9118224779764811}]}, {"text": "One is that we have had an extensively large amount of lesser used resources for this pair: omorfi 1 (Pirinen, 2015) has well over 400,000 lexemes 2 , apertium-eng 3 has over 40,000 lexemes and apertium-fin-eng 4 over 160,000 lexeme-tolexeme translations.", "labels": [], "entities": []}, {"text": "One of our key interests in the shared task like this is that it provides an ideal data for test-driven development of lexical resources.", "labels": [], "entities": []}, {"text": "One concept I experimented with the shared task is various degrees of automation-expert supervision for the lexical data enrichment.", "labels": [], "entities": []}, {"text": "In this experiment I used automatic methods to refine the lexical selection of the machine translation, and semi-automatised workflows for the generation of the lexical data, as well as some expert-driven development of the more grammatical rules like noun phrase chunking and determiner generation.", "labels": [], "entities": [{"text": "noun phrase chunking", "start_pos": 252, "end_pos": 272, "type": "TASK", "confidence": 0.6969117522239685}, {"text": "determiner generation", "start_pos": 277, "end_pos": 298, "type": "TASK", "confidence": 0.8046731054782867}]}, {"text": "It might be noteworthy that this machine translator I describe in the article is not actively developed outside the shared tasks, so the article is moreso motivated as an exploration of the workflow and methods on semi-automatically generated shallow RBMT than a description of a fully developed RBMT.", "labels": [], "entities": []}, {"text": "The rest of the article is organised as follows: In Section 2 I describe the components of our RBMT pipeline, in Section 3 I describe the development workflow and in Section 4 I show the shared task results and I perform error analysis and discuss the results and finally in Section 5 we summarise the findings.", "labels": [], "entities": []}], "datasetContent": [{"text": "The automatic measurements as used by the shared task are given in the table 5.", "labels": [], "entities": []}, {"text": "I show here the BLEU () and the CharacTER scores.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 16, "end_pos": 20, "type": "METRIC", "confidence": 0.9993288516998291}, {"text": "CharacTER scores", "start_pos": 32, "end_pos": 48, "type": "DATASET", "confidence": 0.6208896338939667}]}, {"text": "BLEU, as it is a kind of industry standard, and CharacTER ( as it is maybe more suited for morphologically complex languages.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9784212112426758}]}, {"text": "As the automatic scores show, the rule-based system has still room for improvement.", "labels": [], "entities": []}, {"text": "I find that a linguistic error analysis is one of the most interesting part of this experiment.", "labels": [], "entities": [{"text": "linguistic error analysis", "start_pos": 14, "end_pos": 39, "type": "TASK", "confidence": 0.6451541483402252}]}, {"text": "The reason for this is is that the experiment's scientific contribution lies more in the extension of linguistic resources and workflows than machine learning algorithm design.", "labels": [], "entities": [{"text": "machine learning algorithm design", "start_pos": 142, "end_pos": 175, "type": "TASK", "confidence": 0.6594829112291336}]}, {"text": "It is noteworthy, that in the sustainable workflow I demonstrate in this article, error analysis is apart of the workflow, namely, adding of the lexical data and rules follows the: Progress of apertium-fin-eng over the years using only the WMT shared task driven development method.", "labels": [], "entities": [{"text": "WMT shared task driven development", "start_pos": 240, "end_pos": 274, "type": "TASK", "confidence": 0.5712739646434783}]}, {"text": "layout given in Section 3 and is the same for development and error analysis phase.", "labels": [], "entities": []}, {"text": "I have, to that effect, categorised the errors in translations along the workflow: 1.", "labels": [], "entities": []}, {"text": "OOV in source language dictionary (including typos and non-words) 2.", "labels": [], "entities": [{"text": "OOV", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.45400121808052063}]}, {"text": "OOV in bilingual dictionary 3.", "labels": [], "entities": [{"text": "OOV in bilingual dictionary", "start_pos": 0, "end_pos": 27, "type": "DATASET", "confidence": 0.6810678467154503}]}, {"text": "OOV in target language dictionary 4.", "labels": [], "entities": []}, {"text": "disambiguation or lexical selection fail 5.", "labels": [], "entities": []}, {"text": "structural failure or higher level The OOV's can be calculated automatically from the corpus data, but the higher level failures need human annotation.", "labels": [], "entities": [{"text": "OOV", "start_pos": 39, "end_pos": 42, "type": "METRIC", "confidence": 0.8466452956199646}]}, {"text": "A summary of the errors can be seen in the table 6, this is based on the errors that were fixed as apart of error analysis process.", "labels": [], "entities": []}, {"text": "As a result of this workflow, I have improved the BLEU points of apertium-fin-eng over the years, as can be seen in the table 7.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 50, "end_pos": 54, "type": "METRIC", "confidence": 0.9981163740158081}, {"text": "apertium-fin-eng", "start_pos": 65, "end_pos": 81, "type": "METRIC", "confidence": 0.9006982445716858}]}, {"text": "The OOV numbers might look moderately large but a major part falls under proper nouns, which are generally low frequency and do not cause a large problem in translation pipeline, the untranslated proper noun is recognisable and the mapping of adpositions and case inflections will fail where applicable.", "labels": [], "entities": [{"text": "translation pipeline", "start_pos": 157, "end_pos": 177, "type": "TASK", "confidence": 0.914606362581253}]}, {"text": "The task of adding proper nouns to the dictionaries is also simplest, they are easy to gather from the text, and for English and bilingual dictionaries no further classification is necessary; for the Finnish dictionary entry generation, paradigm guessing is necessary, although the paradigms used in foreign names are much more limited than with other parts-of-speech to be added.", "labels": [], "entities": [{"text": "Finnish dictionary entry generation", "start_pos": 200, "end_pos": 235, "type": "TASK", "confidence": 0.5919313952326775}, {"text": "paradigm guessing", "start_pos": 237, "end_pos": 254, "type": "TASK", "confidence": 0.7661086916923523}]}, {"text": "In the newstest 2019 data there was a number of words that I decided not to add to our dictionaries, unlike our usual workflow where I aim at virtual 100 % coverage with gold corpora.", "labels": [], "entities": [{"text": "newstest 2019 data", "start_pos": 7, "end_pos": 25, "type": "DATASET", "confidence": 0.9270858764648438}]}, {"text": "The unadded words were for example words like \"Toimiluvanmuodossatoteutettavajulkisenjayksityisensektorinkumppanuus\", which seems to have a large number of missing spaces and extra hyphen, these as well as extraneous spaces were quite common in the data in our error analysis as well as 'words' like 'OIet', 'OIi', 'OIin', 'OIisi', 'OIIut', i.e. forms of 'olla' (to be) where lowercase L has been replaced with uppercase I.", "labels": [], "entities": []}, {"text": "While I do account for common spelling mistakes in our dictionaries, these kind of errors are probably more suited for robustness testing and implemented with spelling correction methods for specific problematic generated text, such as OCR.", "labels": [], "entities": []}, {"text": "We will look into implementing spelling correction into our pipeline in the future.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.9488687217235565}]}, {"text": "Comparing the performance of RBMT to NMT, it can be clearly seen that contemporary NMT is better suited for error tolerance, in part because it can be more character-based than token-based, in part because any large training data set will actually have some OCR errors and run-in tokens.", "labels": [], "entities": [{"text": "error tolerance", "start_pos": 108, "end_pos": 123, "type": "TASK", "confidence": 0.669221505522728}]}, {"text": "After OOV-errors one of the biggest easily solvable problems is ambiguity, so word sense disambiguation and lexical selection.", "labels": [], "entities": []}, {"text": "For lexical selection I found about 200 lexical translations that were still badly wrong and could be solved without coming up complex context conditions.", "labels": [], "entities": [{"text": "lexical selection", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.8247985541820526}]}, {"text": "For disambiguation problems, a surprisingly common problem was sentence-initial proper noun that is a common noun as well, as a high frequency example, for the word 'trump' meaning a winning suit in card games (= Finnish 'valtti') would get selected over the POTUS, plausibly when most of the training and development before WMT 2019 did not contain so many proper noun Trumps.", "labels": [], "entities": [{"text": "POTUS", "start_pos": 259, "end_pos": 264, "type": "DATASET", "confidence": 0.6563445925712585}, {"text": "WMT 2019", "start_pos": 325, "end_pos": 333, "type": "DATASET", "confidence": 0.8132641017436981}]}, {"text": "Also rather common problem still is the ambiguity in English verb forms, and between English zero derivations.", "labels": [], "entities": []}, {"text": "In the structural transfer a large number of errors are caused by long-distance re-ordering.", "labels": [], "entities": [{"text": "structural transfer", "start_pos": 7, "end_pos": 26, "type": "TASK", "confidence": 0.7811919450759888}]}, {"text": "For example for Finnish to English proper noun phrases regardless of length of the phrase, the Finnish shows casein last word or postposition after the last word, English has preposition before the word, but when phrase gets chunked partially the adpositions or case suffixes end up in the middle with a rather jarring effect to the translated sentence.", "labels": [], "entities": []}, {"text": "The same applies for other effects where generating correct language depends on correct chunk detection, e.g. the article generation is very limited in the current code because the articles need to be generated from nothing, when translating from Finnish to English, only at the very beginning of specific noun phrases.", "labels": [], "entities": [{"text": "article generation", "start_pos": 114, "end_pos": 132, "type": "TASK", "confidence": 0.7156480848789215}]}, {"text": "Finally a number of problems were caused for such grammatical differences between languages that do not have a good solution in lexical rulebased machine translation, such as difference between English noun phrases and corresponding Finnish compound nouns or for example the common English class of -able suffixed adjectives that does not have accurate lexical Finnish translation at all.", "labels": [], "entities": [{"text": "lexical rulebased machine translation", "start_pos": 128, "end_pos": 165, "type": "TASK", "confidence": 0.6440684497356415}]}, {"text": "In terms of where RBMT is perhaps more usable than NMT, one important factor is how predictable and systematic the errors are when they appear.", "labels": [], "entities": []}, {"text": "For further research in the problems of NMT for real-world use, see for example.", "labels": [], "entities": [{"text": "NMT", "start_pos": 40, "end_pos": 43, "type": "TASK", "confidence": 0.795438826084137}]}, {"text": "In comparison to neural and statistical systems, the rule-based approach does not generally farewell as measured with automatic metrics like BLEU, fora human evaluation refer to).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 141, "end_pos": 145, "type": "METRIC", "confidence": 0.9973819851875305}]}, {"text": "However, the experiment I describe here is also not the most actively developed machine translators, rather I use the experiment to http://matrix.statmt.org/matrix/ output/1903?score_id=39757 gauge the effects the described workflow has to quality of semi-automatically generated RBMT, to see how more developed systems fare on the same task you should also refer to.", "labels": [], "entities": [{"text": "machine translators", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.7364951372146606}]}], "tableCaptions": [{"text": " Table 1: Sizes of dictionaries. The numbers are num- bers of unique word entries or translation entries as  defined in the dictionary, e.g., homonymy judgements  have been made by the dictionary writers. The rule  counts are combined counts of all sorts of linguistic  rules: disambiguation, lexical selection, transfer and so  forth.", "labels": [], "entities": []}, {"text": " Table 2: Ambiguity influencing RBMT Finnish-to-English and English-to-Finnish", "labels": [], "entities": [{"text": "Ambiguity influencing RBMT Finnish-to-English", "start_pos": 10, "end_pos": 55, "type": "TASK", "confidence": 0.6078144013881683}]}, {"text": " Table 5: automatic scores from http://matrix.  statmt.org, we show our scores (boldfaced), the  highest ranking RBMT and the highest ranking NMT  for reference.", "labels": [], "entities": [{"text": "RBMT", "start_pos": 113, "end_pos": 117, "type": "DATASET", "confidence": 0.6590272784233093}, {"text": "NMT", "start_pos": 142, "end_pos": 145, "type": "DATASET", "confidence": 0.8796787858009338}]}, {"text": " Table 6: Classification of mainly lexical errors in  apertium-fin-eng submissions for 2019", "labels": [], "entities": []}, {"text": " Table 7: Progress of apertium-fin-eng over the years  using only the WMT shared task driven development  method.", "labels": [], "entities": [{"text": "WMT shared task driven development", "start_pos": 70, "end_pos": 104, "type": "TASK", "confidence": 0.5625789880752563}]}]}