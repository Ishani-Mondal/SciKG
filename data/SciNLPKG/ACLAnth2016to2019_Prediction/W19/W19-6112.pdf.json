{"title": [{"text": "Unsupervised Inference of Object Affordance from Text Corpora", "labels": [], "entities": [{"text": "Unsupervised Inference of Object Affordance from Text Corpora", "start_pos": 0, "end_pos": 61, "type": "TASK", "confidence": 0.7203645594418049}]}], "abstractContent": [{"text": "Affordances denote actions that can be performed in the presence of different objects, or possibility of action in an environment.", "labels": [], "entities": [{"text": "Affordances", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9129104614257812}]}, {"text": "In robotic systems, affordances and actions may suffer from poor semantic generalization capabilities due to the high amount of required hand-crafted specifications.", "labels": [], "entities": [{"text": "semantic generalization", "start_pos": 65, "end_pos": 88, "type": "TASK", "confidence": 0.704006627202034}]}, {"text": "To alleviate this issue, we propose a method to mine for object-action pairs in free text corpora, successively training and evaluating different prediction models of affordance based on word em-beddings.", "labels": [], "entities": []}], "introductionContent": [{"text": "The term \"affordance\" was introduced by the American psychologist to describe what an animal can do in a given environment.", "labels": [], "entities": []}, {"text": "It has since then been extensively utilized, interpreted, and re-defined (see (C \u00b8 akmak Mehmet R. for an overview) in fields such as robotics (, human-computer-interaction () or human-robot-interaction (HRI) (E..", "labels": [], "entities": []}, {"text": "Several interpretations for affordance exist in the literature, we use the term in a loose way to denote actions that can be performed with objects.", "labels": [], "entities": []}, {"text": "As a simplified first approach we assume a one-to-many mapping G: Objects \u2192 Affordances.", "labels": [], "entities": []}, {"text": "The object \"door\" may, for example, be used to perform the actions \"open\", \"close\", and \"lock\".", "labels": [], "entities": []}, {"text": "This paper presents how G maybe learned from free-text corpora.", "labels": [], "entities": []}, {"text": "The results show how it is possible to learn a generative model G that, given an object name, generates affordances according to a probability distribution that matches the used training data.", "labels": [], "entities": []}, {"text": "Qualitatively results also indicate that the model manages to generalize, both to previously unseen objects and actions.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section II and III we give a brief literature review on affordances from different fields.", "labels": [], "entities": []}, {"text": "The developed method is described in Section IV, and results from the evaluation are presented in Section V. The paper is finalized by conclusions in Section VI.", "labels": [], "entities": []}], "datasetContent": [{"text": "The words in each generated pair <object, action> were converted to wordvectors to provide numeric data to be used in the subsequent experiments.", "labels": [], "entities": []}, {"text": "All data was divided into a training set comprising of 734,002 pairs, and a test set comprising 314,572 pairs.", "labels": [], "entities": []}, {"text": "Special care was taken to include different objects in training and test data sets.", "labels": [], "entities": []}, {"text": "This would allow us to test in a more aggressive way the generalization capabilities of the trained models.", "labels": [], "entities": []}, {"text": "The data contained N O = 33,655 distinct object names and N A = 11,923 distinct action names.", "labels": [], "entities": [{"text": "O", "start_pos": 21, "end_pos": 22, "type": "METRIC", "confidence": 0.9461367130279541}, {"text": "A", "start_pos": 60, "end_pos": 61, "type": "METRIC", "confidence": 0.7492390871047974}]}, {"text": "By sampling the model, we obtain names of possible actions A.", "labels": [], "entities": []}, {"text": "As described above, the sampling follows the estimated conditional probabilities P (A|O).", "labels": [], "entities": []}, {"text": "Hence, actions with high probability are generated more frequently than actions with low probability.", "labels": [], "entities": []}, {"text": "Since the CVAE outputs actions in numeric wordvector format, these actions are \"rounded\" to the closest action word appearing in the dictionary.", "labels": [], "entities": []}, {"text": "This is equivalent to a K-NN classification with K = 1.", "labels": [], "entities": []}, {"text": "A few examples of the most probable generated actions for CVAE are shown in.5.2.", "labels": [], "entities": []}, {"text": "Evaluation of generative models is in general seen as a difficult task (, and one suggestion is that they should be evaluated directly with respect to the intended usage (.", "labels": [], "entities": []}, {"text": "In that spirit we evaluated how often our models produced affordances that were correct in the sense that they exactly matched test data with unseen objects.", "labels": [], "entities": []}, {"text": "For a model P k (A|O) we define an accuracy measure as follows: s \u2190 size(test set) 3: Output of the k-th model, sampled m times, with m >> This measure tests how good a model replicates test data, and is meant to be a quantitative evaluation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9981673955917358}, {"text": "Output", "start_pos": 86, "end_pos": 92, "type": "METRIC", "confidence": 0.9840355515480042}]}, {"text": "Two different CVAEs are evaluated, the first with data encoded with GloVe-200 embeddings, the second with word2vec embeddings obtained over YAMC.", "labels": [], "entities": [{"text": "YAMC", "start_pos": 140, "end_pos": 144, "type": "DATASET", "confidence": 0.8797012567520142}]}, {"text": "We evaluated CVAE, K-NN and a baseline model by the described procedure.", "labels": [], "entities": []}, {"text": "As baseline model we used a prior P (A|O) = P (A), that is the probability distribution of actions overall objects.", "labels": [], "entities": []}, {"text": "For every action a, P (a) = Na /N tot , where Na is the number of times a appeared in the dataset.", "labels": [], "entities": []}, {"text": "Accuracy computed on the test set for the different models are presented in.", "labels": [], "entities": []}, {"text": "The K-NN model fails to generalize the task: jumping to the closest object and outputting the empirical probability for it yield performances just above zero, also lower to the baseline.", "labels": [], "entities": []}, {"text": "We explain the K-NN performance as being this low due to the fact that similarity of objects (using cosine distance) does not encode similarity of associated actions.", "labels": [], "entities": []}, {"text": "Supporting this hypothesis there is also the necessity of having nonlinear layers in the autoencoder in order to achieve high accuracy values.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 126, "end_pos": 134, "type": "METRIC", "confidence": 0.9932085871696472}]}, {"text": "From this consideration we conclude that in word embedding space the mapping object-action is non-linear using the offthe-shelf embedding features.", "labels": [], "entities": []}, {"text": "The two CVAEs performance is higher, reaching a score of 0.35 with the off-the-shelf wordvectors.", "labels": [], "entities": []}, {"text": "Additionally, we observed that training word2vec embeddings over the corpus lead to overfitting: performance computed over the test set comprising unseen objects is lower than the performance obtained with general purpose wordvectors.", "labels": [], "entities": []}], "tableCaptions": []}