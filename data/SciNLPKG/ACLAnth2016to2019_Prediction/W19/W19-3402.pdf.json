{"title": [{"text": "\"My Way of Telling a Story\": Persona based Grounded Story Generation", "labels": [], "entities": [{"text": "My Way of Telling a Story", "start_pos": 1, "end_pos": 26, "type": "TASK", "confidence": 0.7382232844829559}]}], "abstractContent": [{"text": "Visual storytelling is the task of generating stories based on a sequence of images.", "labels": [], "entities": [{"text": "Visual storytelling", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7344468533992767}]}, {"text": "Inspired by the recent works in neural generation focus-ing on controlling the form of text, this paper explores the idea of generating these stories in different personas.", "labels": [], "entities": []}, {"text": "However, one of the main challenges of performing this task is the lack of a dataset of visual stories in different per-sonas.", "labels": [], "entities": []}, {"text": "Having said that, there are independent datasets for both visual storytelling and annotated sentences for various persona.", "labels": [], "entities": []}, {"text": "In this paper we describe an approach to overcome this by getting labelled persona data from a different task and leveraging those annotations to perform persona based story generation.", "labels": [], "entities": [{"text": "persona based story generation", "start_pos": 154, "end_pos": 184, "type": "TASK", "confidence": 0.653477318584919}]}, {"text": "We inspect various ways of incorporating personality in both the encoder and the decoder representations to steer the generation in the target direction.", "labels": [], "entities": []}, {"text": "To this end, we propose five models which are incremental extensions to the base-line model to perform the task at hand.", "labels": [], "entities": []}, {"text": "In our experiments we use five different personas to guide the generation process.", "labels": [], "entities": []}, {"text": "We find that the models based on our hypotheses perform better at capturing words while generating stories in the target persona.", "labels": [], "entities": []}], "introductionContent": [{"text": "Storytelling through pictures has been dated back to prehistoric times -around 30,000 years ago, paintings of herds of animals like bisons, rhinos and gazelles were made in a cave in Southern France.", "labels": [], "entities": []}, {"text": "However, these were not merely paintings, they were stories about the heroic adventures of humans.", "labels": [], "entities": []}, {"text": "Since then visual storytelling has evolved from paintings to photography to motion pictures to video games.", "labels": [], "entities": [{"text": "visual storytelling", "start_pos": 11, "end_pos": 30, "type": "TASK", "confidence": 0.8433069288730621}]}, {"text": "With respect to its timeline, neural generative storytelling has gained traction only recently.", "labels": [], "entities": [{"text": "neural generative storytelling", "start_pos": 30, "end_pos": 60, "type": "TASK", "confidence": 0.8016080458958944}]}, {"text": "Recent research has focused on challenges in generating longer documents as well as on predicting the next events in the story (.", "labels": [], "entities": []}, {"text": "Contemporary research has focused on using deep generative models to capture high-level plots and structures in stories.", "labels": [], "entities": []}, {"text": "Recent years have also seen some work hinging on the event structures and scripts.", "labels": [], "entities": []}, {"text": "Generating an appropriate ending of a story was also studied by and.", "labels": [], "entities": [{"text": "Generating an appropriate ending of a story", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.6811381450721196}]}, {"text": "Research on generating stories from a sequence of images is anew (.", "labels": [], "entities": []}, {"text": "have stressed the importance of expressing emotions in the believability of the automated storytelling system.", "labels": [], "entities": []}, {"text": "Adapting a personality trait hence becomes crucial to capture and maintain interest of the audience.", "labels": [], "entities": []}, {"text": "Associating the narrative to a personality instigates a sense of empathy and relatedness.", "labels": [], "entities": []}, {"text": "Although there has been research in generating persona based dialog responses and generating stylistic sentences, generating persona based stories with different personality types narrating them has been unexplored.", "labels": [], "entities": []}, {"text": "In this paper, we focus on generating a story from a sequence of images as if the agent belongs to a particular personality type.", "labels": [], "entities": []}, {"text": "In specific, we choose to perform experimentations on visual storytelling (.", "labels": [], "entities": []}, {"text": "This paper introduces a novel approach to generating visual stories in five different personality types.", "labels": [], "entities": []}, {"text": "A key challenge to this end is the lack of large scale persona annotated stories.", "labels": [], "entities": []}, {"text": "We address this by transferring knowledge from annotated data in dialog domain to the storytelling domain.", "labels": [], "entities": []}, {"text": "We base our visual story generator model on and propose multiple techniques to induce the personalities in the latent representations of both the encoder and the decoder.", "labels": [], "entities": []}, {"text": "The goal of our work is to learn the mapping between the latent representations of the images and the tokens of the story such that we encourage our generative model to generate tokens of a particular personality.", "labels": [], "entities": []}, {"text": "We evaluate our generative models using the automatic metric of ROUGE) which takes into account the sentence level similarity in structure and thus roughly evaluates the matching of content.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 64, "end_pos": 69, "type": "METRIC", "confidence": 0.9488565325737}]}, {"text": "We acknowledge that there is a drop in this metric since our model is not trying to optimize generation alone but also adapt personality from a different dataset.", "labels": [], "entities": []}, {"text": "We also evaluate the success of generating the story in the target personality type using automatic and qualitative analysis.", "labels": [], "entities": []}, {"text": "The automatic metrics comprise of the classification accuracies rooted from the annotated data.", "labels": [], "entities": []}, {"text": "We observe that one of the proposed models (LEPC, described in Section 3 performs slightly better at classification accuracies for most of the personas while retaining similar ROUGE scores.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 176, "end_pos": 181, "type": "METRIC", "confidence": 0.9981295466423035}]}, {"text": "The main contribution of this paper is showing simple yet effective approaches to narrative visual stories in different personality types.", "labels": [], "entities": []}, {"text": "The paper also displays an effective way of using annotated data in the dialog domain to guide the generative models to a specified target personality.", "labels": [], "entities": []}], "datasetContent": [{"text": "Coalescing the segments of personality and sequential generation together, our task is to generate a grounded sequential story from the view of a personality.", "labels": [], "entities": []}, {"text": "To bring this to action, we describe the two sources of data we use to generate personality based stories in this section.", "labels": [], "entities": []}, {"text": "The first source of data is focussed on generic story generation from a sequence of images and the second source of data includes annotations for personality types for sentences.", "labels": [], "entities": [{"text": "generic story generation", "start_pos": 40, "end_pos": 64, "type": "TASK", "confidence": 0.8469362854957581}]}, {"text": "We tailor a composition of these two sources to obtain a dataset for personality based visual storytelling.", "labels": [], "entities": [{"text": "personality based visual storytelling", "start_pos": 69, "end_pos": 106, "type": "TASK", "confidence": 0.6391518265008926}]}, {"text": "Here, we note that the techniques described above can be applied for unimodal story generation as well.", "labels": [], "entities": [{"text": "unimodal story generation", "start_pos": 69, "end_pos": 94, "type": "TASK", "confidence": 0.6357346673806509}]}, {"text": "Visual Story Telling: Visual Storytelling is the task of generating stories from a sequence of images.", "labels": [], "entities": [{"text": "Visual Story Telling", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.6561825176080068}]}, {"text": "A dataset for this grounded sequential generation problem was collected by and an effort fora shared task 2 was led in 2018.", "labels": [], "entities": [{"text": "sequential generation", "start_pos": 28, "end_pos": 49, "type": "TASK", "confidence": 0.7090248763561249}]}, {"text": "The dataset includes 40,155 training sequences of stories.", "labels": [], "entities": []}, {"text": "It comprises of a sequence of images, descriptions of images in isolation and stories of images in sequences.", "labels": [], "entities": []}, {"text": "We randomly divide the dataset into 5 segments (comprising of 8031 stories each) and each segment is associated with a personality.", "labels": [], "entities": []}, {"text": "Personality Dialog: have provided a dataset of 401k dialog utterances, each of which belong to one of 215 different personalities.", "labels": [], "entities": []}, {"text": "The dataset was collected through image grounded human-human conversations.", "labels": [], "entities": []}, {"text": "Humans were asked to play the role of a given personality.", "labels": [], "entities": []}, {"text": "This makes this dataset very pertinent for our task as it was collected through engaging image chat between two humans enacting their personalities.", "labels": [], "entities": []}, {"text": "For our task, we wanted to choose a set of five distinct personality types.", "labels": [], "entities": []}, {"text": "Let the set of utterances that belong to each personality type be U p = {u 1 p , . .", "labels": [], "entities": []}, {"text": ", u n p } where p \u2208 {1, . .", "labels": [], "entities": []}, {"text": "We first calculate the pooled BERT representation) of each of the utterances.", "labels": [], "entities": [{"text": "BERT representation", "start_pos": 30, "end_pos": 49, "type": "METRIC", "confidence": 0.9720094799995422}]}, {"text": "To get the representation of the personality P, we simply average the BERT representations of all the utterances that belong to that personality.", "labels": [], "entities": [{"text": "BERT", "start_pos": 70, "end_pos": 74, "type": "METRIC", "confidence": 0.9989627599716187}]}, {"text": "The representation of each personality is given by: This representation is calculated only on the train set of.", "labels": [], "entities": []}, {"text": "Since our goal is to pick five most distinct personality types, we have the daunting task of filtering the 215 personality types to 5.", "labels": [], "entities": []}, {"text": "To make our task easier we want to group similar personalities together.", "labels": [], "entities": []}, {"text": "Hence, we use K-Means Clustering to cluster the representations of the personalities into 40 clusters 3 . We get well formed and meaningful clusters which look like [Impersonal, Aloof (Detached, Distant), Apathetic (Uncaring, Disinterested), Blunt, Cold, Stiff];;; [Calm, Gentle, Peaceful, Relaxed, Mellow (Soothing, Sweet)] etc.", "labels": [], "entities": []}, {"text": "We then build a classifier using the technique described in Section 3.1 to classify the utterances to belong to one of the 40 clusters.", "labels": [], "entities": []}, {"text": "We pick the top five clusters that give the highest accuracy for the 40-way classification.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.999257504940033}]}, {"text": "The five personality clusters selected are: \u2022 Cluster 1 (C1): Arrogant, Conceited, Egocentric, Lazy, Money-minded, Narcissistic, Pompous and Resentful \u2022 Cluster 2 (C2): Skeptical and Paranoid \u2022 Cluster 3 (C3): Energetic, Enthusiastic, Exciting, Happy, Vivacious, Excitable \u2022 Cluster 4 (C4): Bland and Uncreative \u2022 Cluster 5 (C5): Patriotic We build five separate classifiers, one for each personality cluster.", "labels": [], "entities": [{"text": "Bland", "start_pos": 291, "end_pos": 296, "type": "METRIC", "confidence": 0.9377174973487854}]}, {"text": "Note that these clusters are also associated with personalities and hence are later referred as P followed by the cluster id in the following sections.", "labels": [], "entities": []}, {"text": "To build the five binary classifiers, we create label balanced datasets for each cluster i.e we randomly select as many negative samples from the remaining 4 clusters as there are positive samples in that cluster.", "labels": [], "entities": []}, {"text": "We use the train, dev and test split as is from Note that all the datasets have a balanced distribution of labels 0 and 1.", "labels": [], "entities": []}, {"text": "For our experiments it does not matter that distribution of the number of samples is different because we build separate classifiers for each of the cluster and their output is treated as independent from one another.", "labels": [], "entities": []}, {"text": "As seen in  We finally calculate the representation P for each of the five clusters and the representation S of stories using equation 9.", "labels": [], "entities": []}, {"text": "Note that S is calculated over the visual story tellind dataset.", "labels": [], "entities": [{"text": "story tellind dataset", "start_pos": 42, "end_pos": 63, "type": "DATASET", "confidence": 0.7048538029193878}]}, {"text": "These representations are used by our generative models LEPC, LEPD, SEPC, and SEPD.", "labels": [], "entities": []}, {"text": "This section presents the experimental setup for the models described in Section 3.", "labels": [], "entities": []}, {"text": "Each of the models are incremental extensions over the baseline glocal model.", "labels": [], "entities": []}, {"text": "The hyperparameters used for this are as follows.", "labels": [], "entities": []}, {"text": "Hyperparameters: The hidden size of the Bi-LSTM encoder of the story to capture context is 1024.", "labels": [], "entities": []}, {"text": "The dimensionality of the glocal context vector z k is 2048.", "labels": [], "entities": []}, {"text": "A dropout layer of 50% is applied post the fully connected layer to obtain the image features and after the global features obtained from Bi-LSTM which is 2 layered.", "labels": [], "entities": []}, {"text": "The word embedding dimension used is 256.", "labels": [], "entities": []}, {"text": "The learning rate is 1e-3 with a weight decay of 1e-5.", "labels": [], "entities": []}, {"text": "Adam optimizer is used with batch normalization and a momentum of 0.01.", "labels": [], "entities": []}, {"text": "Weighting the loss functions differently is done to penalize the model more if the decoding is at fault as compared to not predicting the personality of the story.", "labels": [], "entities": []}, {"text": "\u03b1 is set to 0.5 and each of the individual personality losses are weighted by a factor of 0.1.", "labels": [], "entities": []}, {"text": "The rest of the 5 models use the same hyperparameter setting with an exception to word embedding dimension.", "labels": [], "entities": []}, {"text": "The average personality (P) and the average story (S) representations are obtained from pre-trained BERT model.Hence this is a 768 dimensional vector.", "labels": [], "entities": [{"text": "BERT", "start_pos": 100, "end_pos": 104, "type": "METRIC", "confidence": 0.9906684756278992}]}, {"text": "In order to perform the stripping of the story feature and adding the personality features to the word embeddings in the decoder, the word embedding dimension is matched to 768 in the SEPD model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of data belonging to each of the per- sona clusters", "labels": [], "entities": []}, {"text": " Table 2: Performance of classifiers for each of the per- sona clusters", "labels": [], "entities": []}, {"text": " Table 3: Performance (in terms of accuracy) of gener- ated stories to capture persona", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9976426959037781}]}]}