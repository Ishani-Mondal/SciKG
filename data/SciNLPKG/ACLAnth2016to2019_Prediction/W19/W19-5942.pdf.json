{"title": [{"text": "A Crowd-based Evaluation of Abuse Response Strategies in Conversational Agents", "labels": [], "entities": []}], "abstractContent": [{"text": "How should conversational agents respond to verbal abuse through the user?", "labels": [], "entities": []}, {"text": "To answer this question, we conduct a large-scale crowd-sourced evaluation of abuse response strategies employed by current state-of-the-art systems.", "labels": [], "entities": []}, {"text": "Our results show that some strategies, such as \"polite refusal\" score highly across the board, while for other strategies demographic factors, such as age, as well as the severity of the preceding abuse influence the user's perception of which response is appropriate.", "labels": [], "entities": [{"text": "polite refusal\"", "start_pos": 48, "end_pos": 63, "type": "TASK", "confidence": 0.7612003286679586}]}, {"text": "In addition, we find that most data-driven models lag behind rule-based or commercial systems in terms of their perceived appropriateness.", "labels": [], "entities": []}], "introductionContent": [{"text": "Ethical challenges related to dialogue systems and conversational agents raise novel research questions, such as learning from biased data sets, and how to handle verbal abuse from the user's side.", "labels": [], "entities": []}, {"text": "As highlighted by a recent UNESCO report, appropriate responses to abusive queries are vital to prevent harmful gender biases: the often submissive and flirty responses by the femalegendered systems reinforce ideas of women as subservient.", "labels": [], "entities": []}, {"text": "In this paper, we investigate the appropriateness of possible strategies by gathering responses from current state-of-the-art systems and ask crowd-workers to rate them.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to assess the perceived appropriateness of system responses we conduct a human study using crowd-sourcing on the FigureEight platform.", "labels": [], "entities": []}, {"text": "We define appropriateness as \"acceptable behaviour in a work environment\" and the participants were made aware that the conversations took place between a human and a system.", "labels": [], "entities": []}, {"text": "Ungrammatical (1a) and incoherent (1b) responses are excluded from this study.", "labels": [], "entities": []}, {"text": "We collect appropriateness ratings given a stimulus (the prompt) and four randomly sampled responses from our corpus that the worker is to label following the methodology described in (, where each utterance is rated relatively to a reference on a userdefined scale.", "labels": [], "entities": []}, {"text": "Ratings are then normalised on a scale from.", "labels": [], "entities": []}, {"text": "This methodology was shown to produce more reliable user ratings than commonly used Likert Scales.", "labels": [], "entities": []}, {"text": "In addition, we collect demographic information, including gender and age group.", "labels": [], "entities": []}, {"text": "In total we collected 9960 HITs from 472 crowd workers.", "labels": [], "entities": [{"text": "HITs", "start_pos": 27, "end_pos": 31, "type": "METRIC", "confidence": 0.9049481749534607}]}, {"text": "In order to identify spammers and unsuitable ratings, we use the responses from the adult-only bots as test questions: We remove users who give high ratings to sexual bot responses the majority (more than 55%) of the time.18,826 scores remain -resulting in an average of 7.7 ratings per individual system reply and 1568.8 ratings per response type as listed in.Due to missing demographic data -and after removing malicious crowdworkers -we only consider a subset of 190 raters for our demographic study.", "labels": [], "entities": []}, {"text": "The group is composed of 130 men and 60 women.", "labels": [], "entities": []}, {"text": "Most raters (62.6%) are under the age of 44, with similar proportions across age groups for men and women.", "labels": [], "entities": [{"text": "raters", "start_pos": 5, "end_pos": 11, "type": "METRIC", "confidence": 0.9465837478637695}]}, {"text": "This is in-line with our target population: 57% of users of smart speakers are male and the majority are under 44).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Full annotation scheme for system response types after user abuse. Categories (1a) and (1b) are excluded  from this study.", "labels": [], "entities": []}, {"text": " Table 3: Response ranking, mean and standard deviation for age groups with (*) p < .05, (**) p < .01 wrt. other  groups.", "labels": [], "entities": [{"text": "Response ranking", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.921015202999115}, {"text": "mean", "start_pos": 28, "end_pos": 32, "type": "METRIC", "confidence": 0.9564853310585022}, {"text": "standard deviation", "start_pos": 37, "end_pos": 55, "type": "METRIC", "confidence": 0.9105981886386871}]}, {"text": " Table 4: Ranks and mean scores per prompt contexts  (A) Gender and Sexuality, (B) Sexualised Comments,  (C) Sexualised Insults and (D) Sexualised Requests and  Demands.", "labels": [], "entities": []}, {"text": " Table 5: System clusters according to Trueskill and  \"appropriateness\" average score. Note that systems  within a cluster are not significantly different.", "labels": [], "entities": [{"text": "Trueskill", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.7793847918510437}]}]}