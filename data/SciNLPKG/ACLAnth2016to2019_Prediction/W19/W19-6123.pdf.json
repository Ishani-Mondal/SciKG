{"title": [], "abstractContent": [{"text": "NER is the task of recognizing and de-marcating the segments of a document that are part of a name and which type of name it is.", "labels": [], "entities": [{"text": "NER is the task of recognizing and de-marcating the segments of a document that are part of a name and which type of name it is", "start_pos": 0, "end_pos": 127, "type": "Description", "confidence": 0.7948614313052251}]}, {"text": "We use 4 different categories of names: Locations (LOC), miscellaneous (MISC), organizations (ORG), and persons (PER).", "labels": [], "entities": []}, {"text": "Even though we employ state of the art methods-including sub-word embeddings-that work well for En-glish, we are unable to reproduce the same success for the Norwegian written forms.", "labels": [], "entities": []}, {"text": "However, our model performs better than any previous research on Norwegian text.", "labels": [], "entities": []}, {"text": "The study also presents the first NER for Nynorsk.", "labels": [], "entities": [{"text": "NER", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.957344114780426}, {"text": "Nynorsk", "start_pos": 42, "end_pos": 49, "type": "DATASET", "confidence": 0.9213460683822632}]}, {"text": "Lastly, we find that by combining Nynorsk and Bokm\u00e5l into one training corpus we improve the performance of our model on both languages.", "labels": [], "entities": [{"text": "Nynorsk", "start_pos": 34, "end_pos": 41, "type": "DATASET", "confidence": 0.9219646453857422}, {"text": "Bokm\u00e5l", "start_pos": 46, "end_pos": 52, "type": "DATASET", "confidence": 0.6607478857040405}]}], "introductionContent": [{"text": "NER is the task of recognizing and demarcating the segments of a document that are part of a name and which type of name it is.", "labels": [], "entities": [{"text": "NER is the task of recognizing and demarcating the segments of a document that are part of a name and which type of name it is", "start_pos": 0, "end_pos": 126, "type": "Description", "confidence": 0.7262823455608808}]}, {"text": "We use 4 different categories of names: Locations (LOC), miscellaneous (MISC), organizations (ORG), and persons (PER).", "labels": [], "entities": []}, {"text": "Even though we employ state of the art methodsincluding sub-word embeddings-that work well for English, we are unable to reproduce the same success for the Norwegian written forms.", "labels": [], "entities": []}, {"text": "However, our model performs better than any previous research on Norwegian text.", "labels": [], "entities": []}, {"text": "We also find that when we train on a combined corpus of Nynorsk and Bokm\u00e5l, which we call Helnorsk, we get significantly better results (+5 percentage points) than if we train the models separately.", "labels": [], "entities": [{"text": "Nynorsk and Bokm\u00e5l", "start_pos": 56, "end_pos": 74, "type": "DATASET", "confidence": 0.7626047929128011}, {"text": "Helnorsk", "start_pos": 90, "end_pos": 98, "type": "DATASET", "confidence": 0.8110253810882568}]}, {"text": "We believe that this shows us, together with evidence provided by that it is possible to use the similarities in the two written forms to produce better models than we would otherwise be able to when the models are trained separately.", "labels": [], "entities": []}, {"text": "We discuss this further in section 7 and 8.", "labels": [], "entities": []}, {"text": "Previous research on NER for Norwegian has chosen a more granular approach to the categories of names and have included the categories \"works\" and \"events\".", "labels": [], "entities": []}, {"text": "The reason we chose to exclude these two categories was firstly that international research on English and other languages mainly focus on the same categories as us-that means that it is easier for us to compare our research to what has been done for other languages.", "labels": [], "entities": []}, {"text": "Secondly, previous research on Norwegian NER does not implement the same type of model that we and international researchers have implemented.", "labels": [], "entities": [{"text": "Norwegian NER", "start_pos": 31, "end_pos": 44, "type": "DATASET", "confidence": 0.8996819853782654}]}, {"text": "They focus solely on the task of recognizing what type of name an already segmented name is categorized as.", "labels": [], "entities": [{"text": "recognizing what type of name an already segmented name", "start_pos": 33, "end_pos": 88, "type": "TASK", "confidence": 0.6654577487044864}]}, {"text": "Our research also includes the segmentation of the names as well.", "labels": [], "entities": [{"text": "segmentation of the names", "start_pos": 31, "end_pos": 56, "type": "TASK", "confidence": 0.8643114566802979}]}, {"text": "This makes it difficult to compare our research directly with theirs.", "labels": [], "entities": []}, {"text": "Using their tools would also prevent us from using the NER directly on new documents if we wanted to build new research on top of such a NER model.", "labels": [], "entities": []}, {"text": "We would have to first segment the text through Named-Entity Chunking (NEC) and then run the their recognizer on the result from the NEC.", "labels": [], "entities": [{"text": "NEC", "start_pos": 133, "end_pos": 136, "type": "DATASET", "confidence": 0.9155378341674805}]}, {"text": "Johansen (2015) does provide a chunker that performs well (>95% F \u03b2=1 score) However, we want to see how well a model that use state-of-the-art algorithms developed for English will perform on Norwegian.", "labels": [], "entities": [{"text": "F \u03b2", "start_pos": 64, "end_pos": 67, "type": "METRIC", "confidence": 0.9428306221961975}]}, {"text": "These algorithms usually do chunking as an implicit step of the NER process.", "labels": [], "entities": []}, {"text": "In our study we show that our model performs better than all previous attempts at a Bokm\u00e5l NER (> +5 percentage points).", "labels": [], "entities": [{"text": "Bokm\u00e5l NER", "start_pos": 84, "end_pos": 94, "type": "DATASET", "confidence": 0.8227958083152771}]}, {"text": "There are no other NER models for Nynorsk that we are aware of.", "labels": [], "entities": [{"text": "Nynorsk", "start_pos": 34, "end_pos": 41, "type": "DATASET", "confidence": 0.944206714630127}]}, {"text": "We show that by combining Nynorsk and Bokm\u00e5l, into what we call Helnorsk in our study, we get better results than if we train separate models for the two written forms.", "labels": [], "entities": [{"text": "Bokm\u00e5l", "start_pos": 38, "end_pos": 44, "type": "DATASET", "confidence": 0.6344806551933289}, {"text": "Helnorsk", "start_pos": 64, "end_pos": 72, "type": "DATASET", "confidence": 0.8279625773429871}]}, {"text": "\"Helnorsk\" translates to \"The whole of Norwegian\", which is fitting as it combines both of the official written forms.", "labels": [], "entities": []}, {"text": "The steps we take to present our study are to 1.", "labels": [], "entities": []}, {"text": "Present related research on NER in section 2. 2. Introduce anew corpus which is tagged with named entities and their types in section 3. 3. Develop a sub-word embedding model for Nynorsk, Bokm\u00e5l, and Helnorsk and implement a deep learning system designed to train a NER model based on a state-of-the-art English model in section 4.", "labels": [], "entities": [{"text": "Nynorsk", "start_pos": 179, "end_pos": 186, "type": "DATASET", "confidence": 0.9204906225204468}]}], "datasetContent": [{"text": "Helnorsk to show how the model performs in section 5. 5. Discuss the results of the experiments in section 6. 6. Conclude on what we believe the experiments show us in section 7. 7. Present future research that we believe should be explored to answer some of the questions that we found at the end of this study in section 8.", "labels": [], "entities": [{"text": "Helnorsk", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.8270992636680603}]}], "tableCaptions": [{"text": " Table 1: Description of data set.", "labels": [], "entities": []}, {"text": " Table 2: Number of names for each data set.", "labels": [], "entities": []}, {"text": " Table 4: Hyperparameter configuration of the  model training.", "labels": [], "entities": []}, {"text": " Table 5: Results of NER experiments. (CBOW =  continous-bag-of-words, SG = skipgram, SG-g =  skipgram with smaller gazetteer)", "labels": [], "entities": [{"text": "NER", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.9583600759506226}]}, {"text": " Table 6: Per name precision, recall, and F 1 score  for the best performing Helnorsk model.", "labels": [], "entities": [{"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9913777112960815}, {"text": "recall", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.9998486042022705}, {"text": "F 1 score", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9873539606730143}]}]}