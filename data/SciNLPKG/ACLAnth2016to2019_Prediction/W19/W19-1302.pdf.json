{"title": [{"text": "A Soft Label Strategy for Target-Level Sentiment Classification", "labels": [], "entities": [{"text": "Target-Level Sentiment Classification", "start_pos": 26, "end_pos": 63, "type": "TASK", "confidence": 0.6674820284048716}]}], "abstractContent": [{"text": "In this paper, we propose a soft label approach to target-level sentiment classification task, in which a history-based soft labeling model is proposed to measure the possibility of a context word as an opinion word.", "labels": [], "entities": [{"text": "target-level sentiment classification task", "start_pos": 51, "end_pos": 93, "type": "TASK", "confidence": 0.7340946868062019}]}, {"text": "We also apply a convolution layer to extract local active features , and introduce positional weights to take relative distance information into consideration.", "labels": [], "entities": []}, {"text": "In addition, we obtain more informative target representation by training with context tokens together to make deeper interaction between target and context tokens.", "labels": [], "entities": []}, {"text": "We conduct experiments on SemEval 2014 datasets and the experimental results show that our approach significantly outperforms previous models and gives state-of-the-art results on these datasets.", "labels": [], "entities": [{"text": "SemEval 2014 datasets", "start_pos": 26, "end_pos": 47, "type": "DATASET", "confidence": 0.7732201317946116}]}], "introductionContent": [{"text": "Target-level sentiment classification aims to identify the sentiment polarities towards given targets by analyzing sentence context.", "labels": [], "entities": [{"text": "Target-level sentiment classification", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.7787995338439941}]}, {"text": "For example, in the sentence \"The food is good but service is bad.\", there are two targets \"food\" and \"service\" mentioned.", "labels": [], "entities": []}, {"text": "The sentiment towards \"food\" and \"service\" are positive and negative respectively.", "labels": [], "entities": []}, {"text": "Neural network models (;) have achieved high accuracy on this task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9990386962890625}]}, {"text": "Most of the neural network models introduce attention mechanism to find the correlation between target and context tokens.", "labels": [], "entities": []}, {"text": "However, the combination of word-level features computed by attention weights may introduce noise into model.", "labels": [], "entities": []}, {"text": "For instance, in \"The dish tastes bad but its vegetable is delicious though it looks ugly.\", these attentionbased models tend to highlight some involve some other words such as \"bad\" and \"ugly\".", "labels": [], "entities": []}, {"text": "Instead of using the attention mechanism, we propose a soft label approach for the target-level sentiment classification task.", "labels": [], "entities": [{"text": "target-level sentiment classification task", "start_pos": 83, "end_pos": 125, "type": "TASK", "confidence": 0.7310332357883453}]}, {"text": "Intuitively, the task could be treated as a two-step process.", "labels": [], "entities": []}, {"text": "Firstly the sentiment words that are related to the given target, called opinion words, are labeled and extracted.", "labels": [], "entities": []}, {"text": "Then the final decision on the sentiment polarity would be made by taking all the extracted opinion words into account.", "labels": [], "entities": [{"text": "sentiment polarity", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.7267309129238129}]}, {"text": "However, this kind of hard label strategy, which directly determines whether a token is an opinion word or not, for labeling opinion words is non-differentiable and hinders training through normal back-propagation.", "labels": [], "entities": []}, {"text": "Thus we use a soft labeling model to avoid the hard decision and make sure the model works in an end-toend way.", "labels": [], "entities": []}, {"text": "Specifically, the soft label model is used to measure the likelihood of a context word as an opinion word at each time step.", "labels": [], "entities": []}, {"text": "The larger the value of one word's soft label, the greater its effect on target sentiment.", "labels": [], "entities": []}, {"text": "In fact, given a target, people are accustomed to going through a sentence from beginning to end, and to judge whether current word is highly related to the target sentiment at each step with comparison of history information till the current word in the reading process.", "labels": [], "entities": []}, {"text": "Therefore, we implement an LSTM-based soft labeling model by a history-based approach, which utilizes history information (previous soft labels and cell states) together with representation of the current word, to decide how to pay attention to history information or current word representation based on their correlation with target representation.", "labels": [], "entities": [{"text": "LSTM-based soft labeling", "start_pos": 27, "end_pos": 51, "type": "TASK", "confidence": 0.7630745768547058}]}, {"text": "Moreover, since the convolution layer () does better in capturing local active features than other neural networks do and these extracted features are proved to be beneficial to text classification, we apply a convolution based encoder to extract these features.", "labels": [], "entities": [{"text": "text classification", "start_pos": 178, "end_pos": 197, "type": "TASK", "confidence": 0.8294565677642822}]}, {"text": "The distance of the features to target is also essential as texts maybe long and contain several targets.", "labels": [], "entities": []}, {"text": "The closer tokens are more likely to affect on the targets.", "labels": [], "entities": []}, {"text": "Therefore, we adopt positional weights to scale the features with relative distance information between context tokens and the target.", "labels": [], "entities": []}, {"text": "Target representation is also critical to this task.", "labels": [], "entities": [{"text": "Target representation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7882152497768402}]}, {"text": "Previous works, such as, simply take the average of target embeddings as target representation.", "labels": [], "entities": []}, {"text": "In fact, this kind of representation does not incorporate contextual information.", "labels": [], "entities": []}, {"text": "Words in a sentence have strong dependencies on each other.", "labels": [], "entities": []}, {"text": "Thus it is necessary to train target representation together with context tokens to obtain more informative representation dependent on contextual information.", "labels": [], "entities": []}, {"text": "In summary, our contributions are as follows: \u2022 Our model uses a soft label approach to evaluating the likelihood of a context word as an opinion word based on the history information.", "labels": [], "entities": []}, {"text": "\u2022 Our model leverages convolution layer, which is seldom used in the task, to extract features, and these features are accordingly weighed by positional information.", "labels": [], "entities": []}, {"text": "\u2022 Our model learns more informative representation of the target, instead of the average of target embeddings, and strengthens the interaction between target and context tokens in soft label computation process.", "labels": [], "entities": []}, {"text": "\u2022 We conduct experiments on benchmark datasets and the experimental results show that our approach significantly outperforms previous models and achieves state-of-the-art results on these datasets.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conduct experiments using the benchmark datasets of) with learning rate 0.003.", "labels": [], "entities": [{"text": "learning rate 0.003", "start_pos": 61, "end_pos": 80, "type": "METRIC", "confidence": 0.9609437386194865}]}, {"text": "The batch size is set to 128.", "labels": [], "entities": []}, {"text": "In order to alleviate overfitting, we set the dropout rate to 0.5 and the coefficient of L 2 regularization to 0.00001.", "labels": [], "entities": [{"text": "dropout rate", "start_pos": 46, "end_pos": 58, "type": "METRIC", "confidence": 0.9216550886631012}, {"text": "L 2 regularization", "start_pos": 89, "end_pos": 107, "type": "METRIC", "confidence": 0.8000526030858358}]}, {"text": "The hyperparameter \u03b2 used to calculate positional weights is set to 40.", "labels": [], "entities": []}, {"text": "We choose the model with the minimum loss on testing set among 100 epochs.", "labels": [], "entities": []}, {"text": "Besides, since there exists class imbalance in SemEval dataset, we additionally show the Macro-F1 scores of each model together with accuracy metric to further investigate the effectiveness and robustness of our model.", "labels": [], "entities": [{"text": "SemEval dataset", "start_pos": 47, "end_pos": 62, "type": "DATASET", "confidence": 0.7504464387893677}, {"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.9990774393081665}]}], "tableCaptions": [{"text": " Table 1: Statistics of benchmark datasets.", "labels": [], "entities": []}, {"text": " Table 2: Comparisons with baselines and ablation experiments (%). The best results are in bold. The model with   *  means its result is the average value of 5 runs. The result with  \u2020 means statistical significant at the level of 0.05  with the baselines tagged by  * .", "labels": [], "entities": []}, {"text": " Table 3: The results of ablation tests (%). The best results are in bold. w/o History Information indicates the  soft label approach without consideration of history information. with AVG indicates the target representation is  replaced by the averaged target embeddings. The result with  \u2021 means statistical significant at the level of 0.05.", "labels": [], "entities": [{"text": "AVG", "start_pos": 185, "end_pos": 188, "type": "METRIC", "confidence": 0.9964762330055237}]}]}