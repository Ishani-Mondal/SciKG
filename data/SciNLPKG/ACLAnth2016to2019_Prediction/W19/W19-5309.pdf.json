{"title": [{"text": "DBMS-KU Interpolation for WMT19 News Translation Task", "labels": [], "entities": [{"text": "WMT19 News Translation", "start_pos": 26, "end_pos": 48, "type": "TASK", "confidence": 0.8324069182078043}]}], "abstractContent": [{"text": "This paper presents the participation of DBMS-KU Interpolation system in WMT19 shared task, namely, Kazakh-English language pair.", "labels": [], "entities": [{"text": "WMT19 shared task", "start_pos": 73, "end_pos": 90, "type": "TASK", "confidence": 0.5510185559590658}]}, {"text": "We examine the use of interpolation method using a different language model order.", "labels": [], "entities": []}, {"text": "Our Interpolation system combines a direct translation with Russian as a pivot language.", "labels": [], "entities": []}, {"text": "We use 3-gram and 5-gram language model orders to perform the language translation in this work.", "labels": [], "entities": [{"text": "language translation", "start_pos": 62, "end_pos": 82, "type": "TASK", "confidence": 0.7301475405693054}]}, {"text": "To reduce noise in the pivot translation process, we prune the phrase table of source-pivot and pivot-target.", "labels": [], "entities": [{"text": "pivot translation", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.6790274083614349}]}, {"text": "Our experimental results show that our Interpolation system outperforms the Baseline in terms of BLEU-cased score by +0.5 and +0.1 points in Kazakh-English and English-Kazakh, respectively.", "labels": [], "entities": [{"text": "BLEU-cased score", "start_pos": 97, "end_pos": 113, "type": "METRIC", "confidence": 0.9847247302532196}]}, {"text": "In particular, using the 5-gram language model order in our system could obtain better BLEU-cased score than utilizing the 3-gram one.", "labels": [], "entities": [{"text": "BLEU-cased score", "start_pos": 87, "end_pos": 103, "type": "METRIC", "confidence": 0.9843185245990753}]}, {"text": "Interestingly, we found that by employing the Interpolation system could reduce the perplexity score of English-Kazakh when using 3-gram language model order.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes our participation in the WMT19 shared task.", "labels": [], "entities": [{"text": "WMT19 shared task", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.7304548621177673}]}, {"text": "We call our system DBMS-KU (Database Management System -Kumamoto University) Interpolation as we use our laboratory and university name, as well as we utilize Interpolation method in our experiments.", "labels": [], "entities": []}, {"text": "We choose news translation task and focus on KazakhEnglish (and vice versa) language pair.", "labels": [], "entities": [{"text": "news translation task", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.7667648196220398}]}, {"text": "Kazakh-English is anew shared task for this year, that is, no experience system description from previous WMT.", "labels": [], "entities": [{"text": "WMT", "start_pos": 106, "end_pos": 109, "type": "DATASET", "confidence": 0.8441608548164368}]}, {"text": "Kazakh-English could be considered as low resource language pair due to the limitation of parallel corpora and morphological tools.", "labels": [], "entities": []}, {"text": "Another challenge is the difference in the writing system between Kazakh and English languages.", "labels": [], "entities": []}, {"text": "Kazakh uses Cyrillic letters, while English uses the alphabet.", "labels": [], "entities": []}, {"text": "Different writing system between language pair needs specific attention in the tokenization step because of its segmentation results that affect the BLEU-cased score.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 79, "end_pos": 91, "type": "TASK", "confidence": 0.9747604131698608}, {"text": "BLEU-cased score", "start_pos": 149, "end_pos": 165, "type": "METRIC", "confidence": 0.9745406806468964}]}, {"text": "Thus, we are motivated to solve this intriguing and challenging task.", "labels": [], "entities": []}, {"text": "Kazakh to English machine translation has been explored in Statistical Machine Translation (SMT) and Neural Machine Translation (NMT).", "labels": [], "entities": [{"text": "Kazakh to English machine translation", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.6600696444511414}, {"text": "Statistical Machine Translation (SMT)", "start_pos": 59, "end_pos": 96, "type": "TASK", "confidence": 0.7650069693724314}, {"text": "Neural Machine Translation (NMT)", "start_pos": 101, "end_pos": 133, "type": "TASK", "confidence": 0.8196058372656504}]}, {"text": "have shown an interesting result that different n-gram and neural LSTM-based language models were able to reduce the perplexity score, i.e., giving better translation result.", "labels": [], "entities": []}, {"text": "For this reason, we consider investigating different n-gram language model order in this work.", "labels": [], "entities": []}, {"text": "Interpolation has been used in Language Model (LM) ( and in Translation Model (TM).", "labels": [], "entities": [{"text": "Translation Model (TM)", "start_pos": 60, "end_pos": 82, "type": "TASK", "confidence": 0.9031894326210022}]}, {"text": "Also, the interpolation has been used in pivot language as a strategy to overcome the limitation of parallel corpora.", "labels": [], "entities": []}, {"text": "Pivot strategy arises as a preliminary assumption that there are enough parallel corpora between source-pivot (SRC-PVT) and pivot-target (PVT-TRG) languages.", "labels": [], "entities": []}, {"text": "Currently, English as lingua franca has more datasets compared to other languages.", "labels": [], "entities": []}, {"text": "Thus, pivot researchers commonly use English as abridge between source to target (.", "labels": [], "entities": []}, {"text": "However, and have shown that using non-English as pivot language could be a better option to improve the translation results for particular language pair.", "labels": [], "entities": []}, {"text": "Since Kazakh-English is categorized as low resource language pair, we adopt the pivot and interpolation strategies in our translation model.", "labels": [], "entities": []}, {"text": "In this work, we consider examining two systems, namely, Baseline and Interpolation.", "labels": [], "entities": []}, {"text": "The Baseline system is a direct translation between each language pair, while Interpolation one is a combination of pivot and direct translation models.", "labels": [], "entities": []}, {"text": "We use Russian as our pivot language with 3-gram and 5-gram language model orders in each system.", "labels": [], "entities": []}, {"text": "Our experimental results are encouraging and indicate that using Interpolation system could obtain better BLEU-cased score than employing Baseline one when translating both Kazakh to English (KK-EN) and English to.", "labels": [], "entities": [{"text": "BLEU-cased score", "start_pos": 106, "end_pos": 122, "type": "METRIC", "confidence": 0.9796139299869537}]}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 explains the data preprocessing and experiment setup for each system.", "labels": [], "entities": []}, {"text": "Section 3 shows and discusses the obtained results.", "labels": [], "entities": []}, {"text": "Section 4 provides the conclusion and future direction of this work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe the case study, dataset, and experiment of this study.", "labels": [], "entities": []}, {"text": "We used open source Moses decoder ( and Giza++ for word alignment, Ken-LM (Heafield, 2011) for language model, and MERT for tuning the weight.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 51, "end_pos": 65, "type": "TASK", "confidence": 0.8124051988124847}, {"text": "MERT", "start_pos": 115, "end_pos": 119, "type": "METRIC", "confidence": 0.9496452808380127}]}, {"text": "The translation results were measured by five automatic evaluations provided by the organizer, namely BLEU, BLEU-cased, TER, BEER 2.0, and CharacTER.", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9590402245521545}, {"text": "BLEU", "start_pos": 102, "end_pos": 106, "type": "METRIC", "confidence": 0.9987132549285889}, {"text": "BLEU-cased", "start_pos": 108, "end_pos": 118, "type": "METRIC", "confidence": 0.9975184202194214}, {"text": "TER", "start_pos": 120, "end_pos": 123, "type": "METRIC", "confidence": 0.9940142035484314}, {"text": "BEER 2.0", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.9685743749141693}]}, {"text": "However, in this paper, we used the BLEU-cased because it is the main comparison metric in the evaluation system . We built two systems, namely, Baseline and Interpolation.", "labels": [], "entities": [{"text": "BLEU-cased", "start_pos": 36, "end_pos": 46, "type": "METRIC", "confidence": 0.9980016350746155}]}, {"text": "The Baseline system is a direct translation between KK-EN and vice versa.", "labels": [], "entities": []}, {"text": "Meanwhile, the Interpolation system is the combination of direct translation with pivot phrase table.", "labels": [], "entities": []}, {"text": "Pivot phrase table was produced by merging the source to pivot (SRC-PVT) and pivot to target (PVT-TRG) by using Triangulation method.", "labels": [], "entities": []}, {"text": "We built the Interpolation phrase table as follows: \u2022 Constructing a phrase table from SRC-PVT and PVT-TRG systems and pruning the phrase table with filter-pt ().", "labels": [], "entities": [{"text": "SRC-PVT", "start_pos": 87, "end_pos": 94, "type": "DATASET", "confidence": 0.9509605169296265}]}, {"text": "The pruning activity was intended to minimize the noise of SRC-PVT and PVT-TRG phrase tables.", "labels": [], "entities": [{"text": "SRC-PVT", "start_pos": 59, "end_pos": 66, "type": "DATASET", "confidence": 0.8068020939826965}]}, {"text": "\u2022 Merging two pruned phrase tables by using the Triangulation method", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Dataset statistic for Baseline and Interpolation systems", "labels": [], "entities": []}, {"text": " Table 2: BLEU-cased score results", "labels": [], "entities": [{"text": "BLEU-cased score", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.972892552614212}]}]}