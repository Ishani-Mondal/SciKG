{"title": [], "abstractContent": [{"text": "Most existing relation extraction models assume a fixed set of relations and are unable to adapt to exploit newly available supervision data to extract new relations.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 14, "end_pos": 33, "type": "TASK", "confidence": 0.749138355255127}]}, {"text": "In order to alleviate such problems, there is the need to develop approaches that make relation extraction models capable of continuous adaptation and learning.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 87, "end_pos": 106, "type": "TASK", "confidence": 0.8249135911464691}]}, {"text": "We investigate and present results for such an approach, based on a combination of ideas from lifelong learning and optimization-based meta-learning.", "labels": [], "entities": []}, {"text": "We evaluate the proposed approach on two recent lifelong relation extraction benchmarks, and demonstrate that it markedly outperforms current state-of-the-art approaches.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.7872753739356995}]}], "introductionContent": [{"text": "The majority of existing supervised relation extraction models can only extract a fixed set of relations which has been specified at training time.", "labels": [], "entities": [{"text": "supervised relation extraction", "start_pos": 25, "end_pos": 55, "type": "TASK", "confidence": 0.6512489716211954}]}, {"text": "They are unable to detect an evolving set of novel relations observed after training without substantial retraining, which can be computationally expensive and may lead to catastrophic forgetting of previously learned relations.", "labels": [], "entities": []}, {"text": "Zero-shot relation extraction approaches can extract unseen relations, but at lower performance levels, and are unable to continually exploit newly available supervision to improve performance without considerable retraining.", "labels": [], "entities": [{"text": "Zero-shot relation extraction", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6808451414108276}]}, {"text": "These limitations also extend to approaches to extracting relations in other limited supervision settings, for instance in the oneshot setting.", "labels": [], "entities": []}, {"text": "It is therefore desirable for relation extraction models to have the capability to learn continuously without catastrophic forgetting of previously learned relations.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.8701770603656769}]}, {"text": "This would enable them exploit newly available supervision to both identify novel relations and improve performance without substantial retraining.", "labels": [], "entities": []}, {"text": "Recently, introduced an embedding alignment approach to enable continual learning for relation extraction models.", "labels": [], "entities": [{"text": "embedding alignment", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.6786461025476456}, {"text": "relation extraction", "start_pos": 86, "end_pos": 105, "type": "TASK", "confidence": 0.889051616191864}]}, {"text": "They consider a setting with streaming tasks, where each task consists of a number of distinct relations, and proposed to align the representation of relation instances in the embedding space to enable continual learning of new relations without forgetting knowledge from past relations.", "labels": [], "entities": []}, {"text": "While they obtained promising results, a key weakness of the approach is that the use of an alignment model introduces additional parameters to already overparameterized relation extraction models, which may in turn lead to an increase in the quantity of supervision required for training.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 170, "end_pos": 189, "type": "TASK", "confidence": 0.7229734361171722}]}, {"text": "In addition, the approach can only align embeddings between observed relations, and does not have any explicit objective that encourages the model to transfer and exploit knowledge gathered from previously observed relations to facilitate the efficient learning of yet to be observed relations.", "labels": [], "entities": []}, {"text": "In this work, we extend the work of by exploiting ideas from both lifelong learning and meta-learning.", "labels": [], "entities": []}, {"text": "We propose to consider lifelong relation extraction as a metalearning challenge, to which the machinery of current optimization-based meta-learning algorithms can be applied.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.8056780695915222}]}, {"text": "Unlike the use of a separate alignment model as proposed in, the proposed approach does not introduce additional parameters.", "labels": [], "entities": []}, {"text": "In addition, the proposed approach is more data efficient since it explicitly optimizes for the transfer of knowledge from past relations, while avoiding the catastrophic forgetting of previously learned relations.", "labels": [], "entities": []}, {"text": "Empirically, we evaluate on lifelong versions of the datasets by and and demonstrate con-siderable performance improvements over prior state-of-the-art approaches.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conduct experiments on Lifelong FewRel and Lifelong SimpleQuestions datasets, both introduced in.", "labels": [], "entities": [{"text": "Lifelong FewRel", "start_pos": 26, "end_pos": 41, "type": "DATASET", "confidence": 0.8313741981983185}, {"text": "Lifelong SimpleQuestions datasets", "start_pos": 46, "end_pos": 79, "type": "DATASET", "confidence": 0.8466289440790812}]}, {"text": "Lifelong FewRel is derived from the FewRel) dataset, by partitioning its 80 relations into 10 distinct clusters made up of 8 relations each, with each cluster serving as a task where a sentence must be labeled with the correct relation.", "labels": [], "entities": [{"text": "FewRel) dataset", "start_pos": 36, "end_pos": 51, "type": "DATASET", "confidence": 0.8873107433319092}]}, {"text": "The 8 relations in each cluster were obtained by clustering the averaged Glove word embeddings of the relation names in the FewRel dataset.", "labels": [], "entities": [{"text": "FewRel dataset", "start_pos": 124, "end_pos": 138, "type": "DATASET", "confidence": 0.9896652102470398}]}, {"text": "Each instance of the dataset contains a sentence, the relation it expresses and a set of randomly sampled negative relations.", "labels": [], "entities": []}, {"text": "Lifelong SimpleQuestions was similarly obtained from the SimpleQuestions () dataset, and is made up of 20 clusters of relations, with each cluster serving as a task.", "labels": [], "entities": [{"text": "SimpleQuestions () dataset", "start_pos": 57, "end_pos": 83, "type": "DATASET", "confidence": 0.7020743588606516}]}, {"text": "We report two measures, ACC whole and ACC avg , both introduced in.", "labels": [], "entities": [{"text": "ACC whole", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.7558268010616302}, {"text": "ACC avg", "start_pos": 38, "end_pos": 45, "type": "METRIC", "confidence": 0.8897894620895386}]}, {"text": "ACC whole measures accuracy on the test set of all tasks and gives a balanced measure of model performance on both observed (seen) and unobserved (unseen) tasks, and is the primary metric we report for all experiments.", "labels": [], "entities": [{"text": "ACC whole", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.7344850897789001}, {"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9943640232086182}]}, {"text": "We also report ACC avg , which measures the average accuracy on the test set of only observed (seen) tasks.", "labels": [], "entities": [{"text": "ACC avg", "start_pos": 15, "end_pos": 22, "type": "METRIC", "confidence": 0.9039126336574554}, {"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9966526627540588}]}], "tableCaptions": [{"text": " Table 1: Accuracy on the test set of all tasks ACC whole  (denoted ACC w. ) and average accuracy on the test  set of only observed tasks ACC avg (denoted ACC a. )  on the Lifelong FewRel and Lifelong SimpleQuestions  datasets. Best results are in bold. Except for MLLRE,  results for other models are obtained from Wang et al.  (2019).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9980605244636536}, {"text": "accuracy", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.9880530834197998}, {"text": "Lifelong FewRel", "start_pos": 172, "end_pos": 187, "type": "DATASET", "confidence": 0.8495256006717682}, {"text": "Lifelong SimpleQuestions  datasets", "start_pos": 192, "end_pos": 226, "type": "DATASET", "confidence": 0.8093896309534708}, {"text": "MLLRE", "start_pos": 265, "end_pos": 270, "type": "DATASET", "confidence": 0.6625227928161621}]}]}