{"title": [{"text": "Improving Cuneiform Language Identification with BERT", "labels": [], "entities": [{"text": "Improving Cuneiform Language Identification", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.8880459368228912}, {"text": "BERT", "start_pos": 49, "end_pos": 53, "type": "METRIC", "confidence": 0.996121346950531}]}], "abstractContent": [{"text": "We describe the systems developed by the National Research Council Canada for the Cuneiform Language Identification (CLI) shared task at the 2019 VarDial evaluation campaign.", "labels": [], "entities": [{"text": "Cuneiform Language Identification (CLI) shared task at the 2019 VarDial evaluation", "start_pos": 82, "end_pos": 164, "type": "TASK", "confidence": 0.7145195259497716}]}, {"text": "We compare a state-of-the-art base-line relying on character n-grams and a traditional statistical classifier, a voting ensemble of classifiers, and a deep learning approach using a Transformer network.", "labels": [], "entities": []}, {"text": "We describe how these systems were trained, and analyze the impact of some preprocessing and model estimation decisions.", "labels": [], "entities": []}, {"text": "The deep neural network achieved 77% accuracy on the test data, which turned out to be the best performance at the CLI evaluation, establishing anew state-of-the-art for cuneiform language identification.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9994316697120667}, {"text": "cuneiform language identification", "start_pos": 170, "end_pos": 203, "type": "TASK", "confidence": 0.6344102422396342}]}], "introductionContent": [{"text": "The goal of the Cuneiform Language Identification (CLI) shared task () was to predict the language or language variety of a short segment of text written using cuneiform symbols.", "labels": [], "entities": [{"text": "Cuneiform Language Identification (CLI) shared task", "start_pos": 16, "end_pos": 67, "type": "TASK", "confidence": 0.7892150394618511}, {"text": "predict the language or language variety of a short segment of text written", "start_pos": 78, "end_pos": 153, "type": "TASK", "confidence": 0.6629934356762812}]}, {"text": "These language varieties include Sumerian (SUX) and 6 different dialects of Akkadian: Old Babylonian (OLB), Middle Babylonian peripheral (MPB), Standard Babylonian (STB), Neo Babylonian (NEB), Late Babylonian (LTB), and Neo Assyrian (NEA).", "labels": [], "entities": []}, {"text": "The dataset for the shared task was built from the Open Richly Annotated Cuneiform Corpus, 1 as described by . The NRC-CNRC team submitted 3 systems to the CLI shared task.", "labels": [], "entities": [{"text": "Open Richly Annotated Cuneiform Corpus, 1", "start_pos": 51, "end_pos": 92, "type": "DATASET", "confidence": 0.7230647419180188}, {"text": "CLI shared task", "start_pos": 156, "end_pos": 171, "type": "TASK", "confidence": 0.6464093327522278}]}, {"text": "The first one is a standard approach using Support Vector Machines (SVM) trained on character n-grams.", "labels": [], "entities": []}, {"text": "The second one is an ensemble using plurality voting among several classifiers trained on different feature sets.", "labels": [], "entities": []}, {"text": "This is essentially the approach that reached state-of-theart on previous discriminating similar languages [http://oracc.museum.upenn.edu] (DSL) shared tasks (.", "labels": [], "entities": []}, {"text": "Our last submission is a deep learning approach based on character embeddings and a Transformer network, similar to BERT.", "labels": [], "entities": [{"text": "BERT", "start_pos": 116, "end_pos": 120, "type": "METRIC", "confidence": 0.859920084476471}]}, {"text": "The following section quickly reviews related work.", "labels": [], "entities": []}, {"text": "We then describe the dataset and data processing (Section 3) and the systems we built for the shared task (Section 4), before presenting the experimental results in Section 5.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Number of segments per class (train+dev), be- fore (raw) and after (dedup) deduplication.", "labels": [], "entities": []}, {"text": " Table 2. Our best scores  were achieved by the deep learning approach. This  run was ranked first overall. Our voting ensemble  would have been ranked 2nd, and our single SVM  would have been ranked 3rd.", "labels": [], "entities": []}, {"text": " Table 2: Results of our 3 official runs on the CLI test  set. For comparison, best F-score from (Jauhiainen  et al., 2019)", "labels": [], "entities": [{"text": "CLI test  set", "start_pos": 48, "end_pos": 61, "type": "DATASET", "confidence": 0.9844855467478434}, {"text": "F-score", "start_pos": 84, "end_pos": 91, "type": "METRIC", "confidence": 0.9976724982261658}]}, {"text": " Table 3: Class-wise F-score of our 3 official runs on the CLI test set.", "labels": [], "entities": [{"text": "Class-wise", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9439291954040527}, {"text": "F-score", "start_pos": 21, "end_pos": 28, "type": "METRIC", "confidence": 0.9145386815071106}, {"text": "CLI test set", "start_pos": 59, "end_pos": 71, "type": "DATASET", "confidence": 0.9899330735206604}]}, {"text": " Table 4: Impact of estimating model performance  (macro F1) on the cross-validation (CV) estimator vs.  dev set, and impact of deduplicating the training data  on the resulting performance. char", "labels": [], "entities": [{"text": "macro F1)", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.7025221188863119}]}, {"text": " Table 5: BERT ablation test results: mean F1 (macro) with 95% confidence interval. Retrain means the 2nd phase  of pre-training (MLM only), which includes the unlabeled dev and test data.", "labels": [], "entities": [{"text": "BERT ablation test", "start_pos": 10, "end_pos": 28, "type": "METRIC", "confidence": 0.8798398772875468}, {"text": "F1", "start_pos": 43, "end_pos": 45, "type": "METRIC", "confidence": 0.9640494585037231}, {"text": "Retrain", "start_pos": 84, "end_pos": 91, "type": "METRIC", "confidence": 0.9981414079666138}]}]}