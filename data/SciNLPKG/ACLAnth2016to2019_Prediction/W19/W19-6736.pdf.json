{"title": [{"text": "Raising the TM Threshold in Neural MT Post-Editing: a Case-Study on Two Datasets", "labels": [], "entities": [{"text": "Neural MT Post-Editing", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.6374666889508566}]}], "abstractContent": [{"text": "This study intends to determine whether replacing fuzzy TM matches by suggestions from neural machine translation (NMT) can decrease the post-editing effort.", "labels": [], "entities": []}, {"text": "We compare the post-editing distance of TM fuzzy matches and of NMT suggestions based on two datasets.", "labels": [], "entities": []}, {"text": "We found that in one of the datasets MT was consistently more useful than TM matches, but in the other dataset it was not.", "labels": [], "entities": [{"text": "MT", "start_pos": 37, "end_pos": 39, "type": "TASK", "confidence": 0.9463733434677124}]}, {"text": "We argue that it is necessary to collect extensive data on PED in TM matches in order to be able to easily optimize the TM threshold for any given project.", "labels": [], "entities": []}], "introductionContent": [{"text": "TransPerfect is a large language service provider (LSP) translating about two billion words each year with a strong focus on technology, including machine translation (MT).", "labels": [], "entities": [{"text": "TransPerfect", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.8743323087692261}, {"text": "machine translation (MT)", "start_pos": 147, "end_pos": 171, "type": "TASK", "confidence": 0.8329202055931091}]}, {"text": "We provide a variety of different MT services, most of which involve MT post-editing (MTPE).", "labels": [], "entities": [{"text": "MT", "start_pos": 34, "end_pos": 36, "type": "TASK", "confidence": 0.9796817302703857}, {"text": "MT post-editing (MTPE)", "start_pos": 69, "end_pos": 91, "type": "TASK", "confidence": 0.8168846487998962}]}, {"text": "In the past few years, we experienced a steady growth of the share of translations produced with MTPE workflows.", "labels": [], "entities": []}, {"text": "This growth can be attributed to the implementation of proprietary neural MT technology (NMT), which has improved the average quality of MT, and consequently increased its benefits and acceptance among our linguist experts community.", "labels": [], "entities": [{"text": "MT", "start_pos": 137, "end_pos": 139, "type": "TASK", "confidence": 0.986783504486084}]}, {"text": "On average, switching from our previous statistical MT framework to the current neural one decreased the post-editing distance by 9.2%, which means an improvement in quality of approximately 29%.", "labels": [], "entities": [{"text": "MT", "start_pos": 52, "end_pos": 54, "type": "TASK", "confidence": 0.9237669110298157}]}, {"text": "Our MTPE workflow, similarly to the majority of LSPs, combines translation memory (TM) leverage and MT suggestions.", "labels": [], "entities": []}, {"text": "We use the 75% TM threshold, which means that only TM matches of The authors.", "labels": [], "entities": [{"text": "TM threshold", "start_pos": 15, "end_pos": 27, "type": "METRIC", "confidence": 0.9498471617698669}]}, {"text": "This article is licensed under a Creative Commons 4.0 license, no derivative works, attribution, CCBY-ND.", "labels": [], "entities": [{"text": "CCBY-ND", "start_pos": 97, "end_pos": 104, "type": "DATASET", "confidence": 0.983306884765625}]}, {"text": "75% and above are shown to the linguists as draft translations during post-editing, and the rest of the segments are pre-translated by an MT system.", "labels": [], "entities": []}, {"text": "This study intends to investigate if the threshold has to be raised considering the increase in MT quality, and if so where the new threshold should lie.", "labels": [], "entities": [{"text": "MT", "start_pos": 96, "end_pos": 98, "type": "TASK", "confidence": 0.897144615650177}]}, {"text": "In other words, we want to know if the linguists' performance will increase if we use MT suggestions instead of the so-called high fuzzy matches, and what it depends on.", "labels": [], "entities": [{"text": "MT", "start_pos": 86, "end_pos": 88, "type": "TASK", "confidence": 0.8950631618499756}]}, {"text": "We approached this task by measuring the post-editing distance (PED) between the TM matches and the final translation and comparing it to the PED between NMT suggestions and the same final translations.", "labels": [], "entities": [{"text": "post-editing distance (PED)", "start_pos": 41, "end_pos": 68, "type": "METRIC", "confidence": 0.8547707080841065}, {"text": "PED", "start_pos": 142, "end_pos": 145, "type": "METRIC", "confidence": 0.9717687368392944}]}, {"text": "This will show whether the amount of editing that has to be applied to the TM fuzzy matches is greater or smaller than that of NMT output.", "labels": [], "entities": []}, {"text": "For this study we selected two different datasets, which are very similar in regards to their content but differ by language pair: EnglishChinese and English-Spanish.", "labels": [], "entities": [{"text": "EnglishChinese", "start_pos": 131, "end_pos": 145, "type": "DATASET", "confidence": 0.917280375957489}]}, {"text": "This study is intended as an initial stage of a large-scale study that will allow us to draw broader conclusions and create best practices on establishing TM thresholds in NMT post-editing projects.", "labels": [], "entities": []}], "datasetContent": [{"text": "The datasets used for this study included only translation units (TUs) that, at the moment of their translation, matched with the existing segments in the TMs.", "labels": [], "entities": []}, {"text": "We retrieved the source segment, the target segment suggestions from the TM, and the final translation of the same segment.", "labels": [], "entities": []}, {"text": "In addition, we produced an NMT suggestion for each of the source segments.", "labels": [], "entities": []}, {"text": "For each TU, we compared the target segment from the TM with the final translation and calculated the PED between them.", "labels": [], "entities": [{"text": "PED", "start_pos": 102, "end_pos": 105, "type": "METRIC", "confidence": 0.997962474822998}]}, {"text": "We will refer to these values as PED-TM.", "labels": [], "entities": [{"text": "PED-TM", "start_pos": 33, "end_pos": 39, "type": "DATASET", "confidence": 0.48444992303848267}]}, {"text": "We also compared the target produced by the NMT systems with the final translated segment to obtain the values of PED-MT.", "labels": [], "entities": [{"text": "PED-MT", "start_pos": 114, "end_pos": 120, "type": "METRIC", "confidence": 0.8828845024108887}]}, {"text": "1 PED is a standard MT quality metric used at TransPerfect and is very common in the translation industry in general.", "labels": [], "entities": [{"text": "1 PED", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.7305247783660889}, {"text": "MT", "start_pos": 20, "end_pos": 22, "type": "TASK", "confidence": 0.976883053779602}]}, {"text": "It evaluates the quality of MT from the point of view of the postediting effort, in other words it shows how many changes the linguists make in the initial draft translation in order to produce final translation.", "labels": [], "entities": [{"text": "MT", "start_pos": 28, "end_pos": 30, "type": "TASK", "confidence": 0.9871455430984497}]}, {"text": "It is based on the Levenshtein edit distance, is character-based, and is presented as a percentage of edited characters overall the characters in the sentence.", "labels": [], "entities": []}, {"text": "Lower PED means that less postediting effort required and thus better MT quality.", "labels": [], "entities": [{"text": "PED", "start_pos": 6, "end_pos": 9, "type": "METRIC", "confidence": 0.994694173336029}, {"text": "MT", "start_pos": 70, "end_pos": 72, "type": "TASK", "confidence": 0.9843810796737671}]}, {"text": "When talking about the amount of work involved in post-editing, it is common to distinguish technical, temporal and cognitive postediting effort).", "labels": [], "entities": []}, {"text": "Even though PED as a method of evaluating post-editing effort is limited only to the technical post-editing effort (i.e. it does not account for the cognitive load of the post-editors, or for the time needed to per-form post-editing), it allows to obtain objective data on the actual amount of editing needed to reach the final translation, and this is a critical factor in improving translators' performance).", "labels": [], "entities": []}, {"text": "For this experiment we selected post-edited texts from past post-editing projects, two different accounts.", "labels": [], "entities": []}, {"text": "Dataset ENES contained post-edited files from English into Spanish from the online fashion retail domain.", "labels": [], "entities": [{"text": "Dataset ENES", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.7636714279651642}]}, {"text": "The projects included in the study dated from the time period of January 2018 to March 2019 and were post-edited by 6 different linguists.", "labels": [], "entities": []}, {"text": "Dataset ENZH contained data from a different online fashion retail account, post-edited from English into Chinese by 21 different linguists in the time period of February 2018 to March 2019.", "labels": [], "entities": [{"text": "Dataset ENZH", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.666673868894577}]}, {"text": "The data in the two datasets comes from two different accounts, however, the content is very similar (short fashion product descriptions).", "labels": [], "entities": []}, {"text": "We deliberately chose the same content type in order to minimize the impact of different content types on the results, but at the same time we were able to compare the results for two different language pairs.", "labels": [], "entities": []}, {"text": "From both datasets we gathered only the translation units (TUs) that are considered high fuzzy matches, i.e. at the time the file was analyzed against a TM, the leverage score of the segments was from 75% to 99% (both included).", "labels": [], "entities": []}, {"text": "The number of TUs in the dataset ENES was 8183, with an average source segment length of 5.6 words.", "labels": [], "entities": [{"text": "ENES", "start_pos": 33, "end_pos": 37, "type": "DATASET", "confidence": 0.6884040236473083}]}, {"text": "The number of TUs in the dataset ENZH was 7521 with an equal average of 5.6 words per source segment.", "labels": [], "entities": [{"text": "ENZH", "start_pos": 33, "end_pos": 37, "type": "DATASET", "confidence": 0.6614040732383728}]}, {"text": "We distributed the TUs in five groups by ranges of TM match scores, a break-down of all the TUs is shown in The biggest range in terms of segment count is the lowest range of 75-79%.", "labels": [], "entities": []}, {"text": "In the ENES dataset, it constitutes 40% of all segments, and in the ENZH it constitutes 37% of all segments.", "labels": [], "entities": [{"text": "ENES dataset", "start_pos": 7, "end_pos": 19, "type": "DATASET", "confidence": 0.9831236898899078}, {"text": "ENZH", "start_pos": 68, "end_pos": 72, "type": "DATASET", "confidence": 0.9446485042572021}]}], "tableCaptions": [{"text": " Table 1. Breakdown of TM match scores in the experi- ment data.", "labels": [], "entities": [{"text": "Breakdown", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9075443744659424}, {"text": "TM", "start_pos": 23, "end_pos": 25, "type": "TASK", "confidence": 0.8312360644340515}]}, {"text": " Table 3. Average PED-MT and average source seg- ment length in different TM ranges in the ENZH da- taset.", "labels": [], "entities": [{"text": "PED-MT", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9540272355079651}, {"text": "source seg- ment length", "start_pos": 37, "end_pos": 60, "type": "METRIC", "confidence": 0.7194925606250763}, {"text": "ENZH da- taset", "start_pos": 91, "end_pos": 105, "type": "DATASET", "confidence": 0.9518485367298126}]}]}