{"title": [], "abstractContent": [{"text": "In this paper, we propose a white-box attack algorithm called \"Global Search\" method and compare it with a simple misspelling noise and a more sophisticated and common white-box attack approach called \"Greedy Search\".", "labels": [], "entities": []}, {"text": "The attack methods are evaluated on the Convolutional Neural Network (CNN) sentiment classi-fier trained on the IMDB movie review dataset.", "labels": [], "entities": [{"text": "Convolutional Neural Network (CNN) sentiment classi-fier", "start_pos": 40, "end_pos": 96, "type": "DATASET", "confidence": 0.7226474471390247}, {"text": "IMDB movie review dataset", "start_pos": 112, "end_pos": 137, "type": "DATASET", "confidence": 0.9172859191894531}]}, {"text": "The attack success rate is used to evaluate the effectiveness of the attack methods and the perplexity of the sentences is used to measure the degree of distortion of the generated adversarial examples.", "labels": [], "entities": []}, {"text": "The experiment results show that the proposed \"Global Search\" method generates more powerful adversarial examples with less distortion or less modification to the source text.", "labels": [], "entities": [{"text": "Global Search\"", "start_pos": 47, "end_pos": 61, "type": "TASK", "confidence": 0.743848184744517}]}], "introductionContent": [{"text": "In the past few decades, machine learning and deep learning techniques have been successful in several applications.", "labels": [], "entities": [{"text": "machine learning", "start_pos": 25, "end_pos": 41, "type": "TASK", "confidence": 0.7294877469539642}]}, {"text": "However, these techniques developed so far are proven to be vulnerable given some manipulated inputs, which are called adversarial examples, that human can easily distinguish but algorithms cannot (.", "labels": [], "entities": []}, {"text": "Current research have shown successful results in producing adversarial images that cause the algorithms to completely fail in computer vision (.", "labels": [], "entities": []}, {"text": "Studies of adversarial examples in the applications of natural language processing such as sentiment analysis, fake news detection and machine translation remain relatively low.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 91, "end_pos": 109, "type": "TASK", "confidence": 0.9386540949344635}, {"text": "fake news detection", "start_pos": 111, "end_pos": 130, "type": "TASK", "confidence": 0.7368691166241964}, {"text": "machine translation", "start_pos": 135, "end_pos": 154, "type": "TASK", "confidence": 0.810011237859726}]}, {"text": "Nonetheless, it is an emerging field that is worth exploring and has increased attention recently due to the success of adversarial learning in images.", "labels": [], "entities": []}, {"text": "When generating an adversarial example, if the adversary does not have knowledge of the classifier or the training data, we call this a blackbox setting.", "labels": [], "entities": []}, {"text": "On the other hand, if the adversary has full knowledge of the classifier and the training data, we call this a white-box setting.", "labels": [], "entities": []}, {"text": "Ina black-box setting, Belinkov and Bisk introduces a simple attack method by randomly replacing characters with their nearby key on the keyboard, which is similar to keyboard typos, to attack a machine translation system.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 195, "end_pos": 214, "type": "TASK", "confidence": 0.7022808939218521}]}, {"text": "Similar idea can be found in the work of Hosseini et al., the authors generate adversaries that deceive Google Perspective API by misspelling the abusive words or adding punctuation to the letters ().", "labels": [], "entities": []}, {"text": "Another work from Alzantot et al. attempts to generate semantically and syntactically similar adversarial examples byword replacement.", "labels": [], "entities": [{"text": "syntactically similar adversarial examples byword replacement", "start_pos": 72, "end_pos": 133, "type": "TASK", "confidence": 0.7090775469938914}]}, {"text": "They develop an genetic algorithm that uses population-based gradient-free optimization, inspired by the process of natural selection.", "labels": [], "entities": []}, {"text": "In the black-box setting, the adversary tries different perturbations and evaluates the quality of perturbations by querying the model to get the classification result or the output score.", "labels": [], "entities": []}, {"text": "The adversary continues to altered the sentence until the model fails or until score reduces significantly.", "labels": [], "entities": [{"text": "score", "start_pos": 79, "end_pos": 84, "type": "METRIC", "confidence": 0.989774227142334}]}, {"text": "In the white-box setting, the adversary has access to the model and thus is capable of generating more sophisticated adversarial examples.", "labels": [], "entities": []}, {"text": "show that adversarial examples generated in a white-box setting achieve a higher success rate than examples generated in a blackbox setting.", "labels": [], "entities": []}, {"text": "The authors introduce a white-box adversary against differentiable classifiers that substitutes characters (\"flips\") in a sentence.", "labels": [], "entities": []}, {"text": "When operating in a white-box setting, the adversary has full access to the gradients of the classifier, giv-ing the adversary important information to find the classifier's weak points.", "labels": [], "entities": []}, {"text": "Because white-box adversary has access to the gradients of the model, the adversary does not have to query the output score from the classifier every time.", "labels": [], "entities": []}, {"text": "Using the gradients as a surrogate loss, the white-box adversary can efficiently find the best changes that maximize the surrogate loss simply by backpropagation.", "labels": [], "entities": []}, {"text": "Other white-box adversary includes word-level substitution.", "labels": [], "entities": [{"text": "word-level substitution", "start_pos": 35, "end_pos": 58, "type": "TASK", "confidence": 0.7745489776134491}]}, {"text": "Kuleshov et al. try to replace 10-30% of words in the source text by solving an optimization problem that maximizes a surrogate loss subject using a greedy approach, which is similar to the \"Greedy Search\" baseline used in the experiment.", "labels": [], "entities": []}, {"text": "A similar idea can be found in Samanta and Mehta where the authors apply different rules (insertion, replacement and deletion of words) to generate adversarial examples.", "labels": [], "entities": []}, {"text": "Liang et al. later combine the strategies above and try to avoid introducing excessive modification or insertion to the original source text.", "labels": [], "entities": []}, {"text": "In this paper, we consider the task of white-box attack where the adversary has full knowledge of the model under attack.", "labels": [], "entities": []}, {"text": "We propose a \"Global Search\" attack method that mitigates some of the problems faced in the commonly used greedy approach.", "labels": [], "entities": []}, {"text": "Avery simple misspelling noise baseline is also reported to show the effectiveness of the 2 white-box attack methods in the experiment.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use a dataset of 25,000 informal movie reviews from the Internet Movie Database (IMDB) (Maas et al., 2011) and randomly select 80% of the dataset to include in the training set, and 20% in the testing set 1 .   We conduct a survey and propose two criteria to measure the performance of the adversarial examples from three attack methods.", "labels": [], "entities": [{"text": "Internet Movie Database (IMDB)", "start_pos": 59, "end_pos": 89, "type": "DATASET", "confidence": 0.8363003730773926}]}, {"text": "The first criteria is the sentiment classification accuracy of the adversarial examples which is predicted by human, and the second is the similarity between the adversarial examples and the original sentence.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 26, "end_pos": 50, "type": "TASK", "confidence": 0.8967751860618591}, {"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9219965934753418}]}, {"text": "Unlike adversarial examples in the context of image classification, natural language perturbation is generally perceptible since words are deleted, added, or re- placed.", "labels": [], "entities": [{"text": "image classification", "start_pos": 46, "end_pos": 66, "type": "TASK", "confidence": 0.7266136556863785}]}, {"text": "Thus, we need to redefine imperceptibility in the context of natural language.", "labels": [], "entities": []}, {"text": "Since we are crafting adversarial example to fool the sentiment classifier, we define it as imperceptible if human can still correctly classify without being fooled by the perturbation.", "labels": [], "entities": []}, {"text": "Therefore, we ask some volunteers to evaluate adversarial examples and look at the percentage of responses that match the original classification.", "labels": [], "entities": []}, {"text": "In addition to classification accuracy, we also care about how similar the generated adversaries examples are to the original unaltered sentences.", "labels": [], "entities": [{"text": "classification", "start_pos": 15, "end_pos": 29, "type": "TASK", "confidence": 0.9555397629737854}, {"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9328704476356506}]}, {"text": "we ask volunteers to rate the similarity, from 1 to 5, which means less similar to very similar between the adversarial sentence and original sentence.", "labels": [], "entities": [{"text": "similarity", "start_pos": 30, "end_pos": 40, "type": "METRIC", "confidence": 0.9934198260307312}]}, {"text": "We choose two sentences which originally classified as positive comment and negative comment, and then flipped to opposite sentiment result after applying three attack methods.", "labels": [], "entities": []}, {"text": "After asking 15 volunteers and analyzing the survey data, we found that the adversarial example from Global Search is most similar to the original sentence, with an average similarity of 4.4, while the example from Greedy Search is less similar, with the score of 2.9.", "labels": [], "entities": []}, {"text": "Refer to human prediction accuracy, Global Search method also reaches the highest accuracy, which is 0.83.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9559234976768494}, {"text": "Global Search", "start_pos": 36, "end_pos": 49, "type": "TASK", "confidence": 0.5494982898235321}, {"text": "accuracy", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.9987179040908813}]}, {"text": "It means that although sentiment classifier make the wrong prediction on the Global Search adversarial examples, human could still classify sentiment correctly.", "labels": [], "entities": [{"text": "Global Search adversarial examples", "start_pos": 77, "end_pos": 111, "type": "DATASET", "confidence": 0.9078308641910553}]}, {"text": "However, greedy search only has 0.30 accuracy because it alter too many words to fool the sentiment classifier.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9992510676383972}]}, {"text": "In this survey, some of the volunteers feel that the adversarial sentences from Greedy Search are hard to read and cannot tell the sentiment of the senetence.", "labels": [], "entities": []}, {"text": "Examples of adversarial text generated Original reviews: as long as you go into this movie knowing that it 's terrible : bad acting , bad \" effects , \" bad story , bad ...", "labels": [], "entities": []}, {"text": "everything , then you 'll love it . this is one of my favorite \" goof on \" movies ; watch it as a comedy and have a dozen good laughs ! Global Search: as long as you go into this movie knowing that it 's terrible : worse acting , bad \" effects , \" bad story , bad ...", "labels": [], "entities": []}, {"text": "everything , then you 'll love it . this is one of my favorite \" goof on \" movies ; watch it as a comedy and have a dozen good laughs yes Greedy Search: as long as you leave into this blockbuster telling whether it 's horrendous : bad acting , bad \" effects , \" bad story , bad ...", "labels": [], "entities": []}, {"text": "everything , then you 'll love it . this is one of my favorite \" goof on \" movies ; watch it as ...", "labels": [], "entities": []}, {"text": "Misspelling Noise: as lnog as you go into this mvoie knowing that it's terirble : bad atcing , bad \" effects , \" bad sotry , bad ...", "labels": [], "entities": []}, {"text": "everything , then you 'll lvoe it . this is one of my favorite \" goof on \" movies ; watch it as a comedy and hvae a dzoen good laguhs !", "labels": [], "entities": []}], "tableCaptions": []}