{"title": [{"text": "Can neural networks understand monotonicity reasoning?", "labels": [], "entities": []}], "abstractContent": [{"text": "Monotonicity reasoning is one of the important reasoning skills for any intelligent natural language inference (NLI) model in that it requires the ability to capture the interaction between lexical and syntactic structures.", "labels": [], "entities": [{"text": "Monotonicity reasoning", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8637258410453796}]}, {"text": "Since no test set has been developed for monotonic-ity reasoning with wide coverage, it is still unclear whether neural models can perform monotonicity reasoning in a proper way.", "labels": [], "entities": []}, {"text": "To investigate this issue, we introduce the Mono-tonicity Entailment Dataset (MED).", "labels": [], "entities": [{"text": "Mono-tonicity Entailment Dataset (MED)", "start_pos": 44, "end_pos": 82, "type": "DATASET", "confidence": 0.6501541435718536}]}, {"text": "Performance by state-of-the-art NLI models on the new test set is substantially worse, under 55%, especially on downward reasoning.", "labels": [], "entities": []}, {"text": "In addition , analysis using a monotonicity-driven data augmentation method showed that these models might be limited in their generalization ability in upward and downward reasoning.", "labels": [], "entities": []}], "introductionContent": [{"text": "Natural language inference (NLI), also known as recognizing textual entailment (RTE), has been proposed as a benchmark task for natural language understanding.", "labels": [], "entities": [{"text": "Natural language inference (NLI)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.761970266699791}, {"text": "recognizing textual entailment (RTE)", "start_pos": 48, "end_pos": 84, "type": "TASK", "confidence": 0.7098853141069412}, {"text": "natural language understanding", "start_pos": 128, "end_pos": 158, "type": "TASK", "confidence": 0.6586160262425741}]}, {"text": "Given a premise P and a hypothesis H, the task is to determine whether the premise semantically entails the hypothesis (.", "labels": [], "entities": []}, {"text": "A number of recent works attempt to test and analyze what type of inferences an NLI model maybe performing, focusing on various types of lexical inferences () and logical inferences.", "labels": [], "entities": []}, {"text": "Concerning logical inferences, monotonicity reasoning, which is a type of reasoning based on word replacement, requires the ability to capture the interaction between lexical and syntactic structures.", "labels": [], "entities": [{"text": "monotonicity reasoning", "start_pos": 31, "end_pos": 53, "type": "TASK", "confidence": 0.744361162185669}, {"text": "word replacement", "start_pos": 93, "end_pos": 109, "type": "TASK", "confidence": 0.7473393082618713}]}, {"text": "Consider examples in (1) and (2).", "labels": [], "entities": []}, {"text": "A context is upward entailing (shown by) that allows an inference from (1a) to (1b), where French dinner is replaced by a more general concept dinner.", "labels": [], "entities": []}, {"text": "On the other hand, a downward entailing context (shown by) allows an inference from (1a) to (1c), where workers is replaced by a more specific concept new workers.", "labels": [], "entities": []}, {"text": "Interestingly, the direction of monotonicity can be reversed again by embedding yet another downward entailing context (e.g., not in), as witness the fact that (2a) entails (2b).", "labels": [], "entities": []}, {"text": "To properly handle both directions of monotonicity, NLI models must detect monotonicity operators (e.g., all, not) and their arguments from the syntactic structure.", "labels": [], "entities": []}, {"text": "For previous datasets containing monotonicity inference problems, and the GLUE diagnostic dataset () are manually-curated datasets for testing a wide range of linguistic phenomena.", "labels": [], "entities": [{"text": "GLUE diagnostic dataset", "start_pos": 74, "end_pos": 97, "type": "DATASET", "confidence": 0.8413318395614624}]}, {"text": "However, monotonicity problems are limited to very small sizes (FraCaS: 37/346 examples and GLUE: 93/1650 examples).", "labels": [], "entities": [{"text": "FraCaS", "start_pos": 64, "end_pos": 70, "type": "DATASET", "confidence": 0.9179703593254089}, {"text": "GLUE", "start_pos": 92, "end_pos": 96, "type": "METRIC", "confidence": 0.8674769401550293}]}, {"text": "The limited syntactic patterns and vocabularies in previous test sets are obstacles in accurately evaluating NLI models on monotonicity reasoning.", "labels": [], "entities": []}, {"text": "To tackle this issue, we present anew evaluation dataset 1 that covers a wide range of monotonicity reasoning that was created by crowdsourcing and collected from linguistics publications (Section 3).", "labels": [], "entities": []}, {"text": "Compared with manual or automatic construction, we can collect naturally-occurring examples by crowdsourcing and well-designed ones from linguistics publications.", "labels": [], "entities": []}, {"text": "To enable the evaluation of skills required for monotonicity reasoning, we annotate each example in our dataset with linguistic tags associated with monotonicity reasoning.", "labels": [], "entities": [{"text": "monotonicity reasoning", "start_pos": 48, "end_pos": 70, "type": "TASK", "confidence": 0.8782646059989929}]}, {"text": "We measure the performance of state-of-the-art NLI models on monotonicity reasoning and investigate their generalization ability in upward and downward reasoning (Section 4).", "labels": [], "entities": []}, {"text": "The results show that all models trained with SNLI) and MultiNLI ( perform worse on downward inferences than on upward inferences.", "labels": [], "entities": [{"text": "MultiNLI", "start_pos": 56, "end_pos": 64, "type": "DATASET", "confidence": 0.5681359767913818}]}, {"text": "In addition, we analyzed the performance of models trained with an automatically created monotonicity dataset, HELP ().", "labels": [], "entities": [{"text": "HELP", "start_pos": 111, "end_pos": 115, "type": "METRIC", "confidence": 0.8463739156723022}]}, {"text": "The analysis with monotonicity data augmentation shows that models tend to perform better in the same direction of monotonicity with the training set, while they perform worse in the opposite direction.", "labels": [], "entities": []}, {"text": "This indicates that the accuracy on monotonicity reasoning depends solely on the majority direction in the training set, and models might lack the ability to capture the structural relations between monotonicity operators and their arguments.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9968932867050171}]}], "datasetContent": [{"text": "To create monotonicity inference problems, we should satisfy three requirements: (a) detect the monotonicity operators and their arguments; (b) based on the syntactic structure, induce the polarity of the argument positions; and (c) replace the phrase in the argument position with a more general or specific phrase in natural and various ways (e.g., by using lexical knowledge or logical connectives).", "labels": [], "entities": []}, {"text": "For (a) and (b), we first conduct polarity computation on a syntactic structure for each sentence, and then select premises involving upward/downward expressions.", "labels": [], "entities": []}, {"text": "For (c), we use crowdsourcing to narrow or broaden the arguments.", "labels": [], "entities": []}, {"text": "The motivation for using crowdsourcing is to collect naturally alike monotonicity inference problems that include various expressions.", "labels": [], "entities": []}, {"text": "One problem here is that it is un- clear how to instruct workers to create monotonicity inference problems without knowledge of natural language syntax and semantics.", "labels": [], "entities": []}, {"text": "We must make tasks simple for workers to comprehend and provide sound judgements.", "labels": [], "entities": []}, {"text": "Moreover, recent studies ( point out that previous crowdsourced datasets, such as SNLI () and MultiNLI (, include hidden biases.", "labels": [], "entities": [{"text": "MultiNLI", "start_pos": 94, "end_pos": 102, "type": "DATASET", "confidence": 0.8123602867126465}]}, {"text": "As these previous datasets are motivated by approximated entailments, workers are asked to freely write hypotheses given a premise, which does not strictly restrict them to creating logically complex inferences.", "labels": [], "entities": []}, {"text": "Taking these concerns into consideration, we designed two-step tasks to be performed via crowdsourcing for creating a monotonicity test set; (i) a hypothesis creation task and (ii) a validation task.", "labels": [], "entities": [{"text": "hypothesis creation task", "start_pos": 147, "end_pos": 171, "type": "TASK", "confidence": 0.7569114168485006}]}, {"text": "The task (i) is to create a hypothesis by making some polarized part of an original sentence more specific.", "labels": [], "entities": []}, {"text": "Instead of writing a complete sentence from scratch, workers are asked to rewrite only a relatively short sentence.", "labels": [], "entities": []}, {"text": "By restricting workers to rewrite only a polarized part, we can effectively collect monotonicity inference examples.", "labels": [], "entities": []}, {"text": "The task (ii) is to annotate an entailment label for the premise-hypothesis pair generated in (i).", "labels": [], "entities": []}, {"text": "summarizes the overview of our human-oriented dataset creation.", "labels": [], "entities": []}, {"text": "We used the crowdsourcing platform Figure Eight for both tasks.", "labels": [], "entities": []}, {"text": "We also collect monotonicity inference problems from previous manually curated datasets and linguistics publications.", "labels": [], "entities": []}, {"text": "The motivation is that previous linguistics publications related to monotonicity reasoning are expected to contain welldesigned inference problems, which might be challenging problems for NLI models.", "labels": [], "entities": [{"text": "monotonicity reasoning", "start_pos": 68, "end_pos": 90, "type": "TASK", "confidence": 0.7661333680152893}]}, {"text": "We collected 1,184 examples from 11 linguistics publications (   Both the GLUE diagnostic dataset and FraCaS categorize problems by their types of monotonicity reasoning, but we found that each dataset has different classification criteria.", "labels": [], "entities": [{"text": "GLUE diagnostic dataset", "start_pos": 74, "end_pos": 97, "type": "DATASET", "confidence": 0.8815189599990845}, {"text": "FraCaS", "start_pos": 102, "end_pos": 108, "type": "DATASET", "confidence": 0.8926132321357727}]}, {"text": "Thus, following GLUE, we reclassified problems into three types of monotone reasoning (upward, downward, and non-monotone) by checking if they include (i) the target monotonicity operator in both the premise and the hypothesis and (ii) the phrase replacement in its argument position.", "labels": [], "entities": [{"text": "GLUE", "start_pos": 16, "end_pos": 20, "type": "DATASET", "confidence": 0.8741269111633301}]}, {"text": "In the GLUE diagnostic dataset, there are several problems whose gold labels are contradiction.", "labels": [], "entities": [{"text": "GLUE diagnostic dataset", "start_pos": 7, "end_pos": 30, "type": "DATASET", "confidence": 0.8524402578671774}]}, {"text": "We regard them as nonentailment in that the premise does not semantically entail the hypothesis.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Examples in the MED dataset. Crowd: problems collected through crowdsourcing, Paper: problems  collected from linguistics publications, up: upward monotone, down: downward monotone, non: non-monotone,  cond: condisionals, rev: reverse, conj: conjunction, disj: disjunction, lex: lexical knowledge, E: entailment, NE:  non-entailment.", "labels": [], "entities": [{"text": "MED dataset", "start_pos": 26, "end_pos": 37, "type": "DATASET", "confidence": 0.7518889307975769}]}, {"text": " Table 5: Statistics for the MED dataset.", "labels": [], "entities": [{"text": "MED dataset", "start_pos": 29, "end_pos": 40, "type": "DATASET", "confidence": 0.9070162773132324}]}, {"text": " Table 6: Accuracies (%) for different models and train- ing datasets.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9993295669555664}]}, {"text": " Table 7: Evaluation results on types of monotonicity  reasoning. -Hyp: Hypothesis-only model.", "labels": [], "entities": []}, {"text": " Table 8: Evaluation results by genre. Paper: problems  collected from linguistics publications, Crowd: prob- lems via crowdsourcing.", "labels": [], "entities": []}, {"text": " Table 9: Evaluation results by linguistic phenomenon  type. (non-)Lexical: problems that (do not) require lex- ical relations. Numbers in parentheses are numbers of  problems.", "labels": [], "entities": []}]}