{"title": [{"text": "Cross-Domain Sentiment Classification using Vector Embedded Domain Representations", "labels": [], "entities": [{"text": "Cross-Domain Sentiment Classification", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.7369642655054728}]}], "abstractContent": [{"text": "Due to the differences between reviews in different product categories, creating a general model for cross-domain sentiment classification can be a difficult task.", "labels": [], "entities": [{"text": "cross-domain sentiment classification", "start_pos": 101, "end_pos": 138, "type": "TASK", "confidence": 0.7707970937093099}]}, {"text": "This paper proposes an architecture that incorporates domain knowledge into a neural sentiment classification model.", "labels": [], "entities": [{"text": "neural sentiment classification", "start_pos": 78, "end_pos": 109, "type": "TASK", "confidence": 0.6963692406813303}]}, {"text": "In addition to providing a cross-domain model, this also provides a quantifiable representation of the domains as numeric vectors.", "labels": [], "entities": []}, {"text": "We show that it is possible to cluster the domain vectors and provide qualitative insights into the inter-domain relations.", "labels": [], "entities": []}, {"text": "We also a) present anew data set for sentiment classification that includes a domain parameter and preprocessed data points, and b) perform an ablation study in order to determine whether some word groups impact performance.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 37, "end_pos": 61, "type": "TASK", "confidence": 0.9592487215995789}]}], "introductionContent": [{"text": "In recent years the amount of text data has been growing exponentially.", "labels": [], "entities": []}, {"text": "With the growth of social media and the success of ecommerce, large websites such as Amazon have developed great interest in online user reviews, which the users are able to write about every product.", "labels": [], "entities": []}, {"text": "The task of classifying review sentiments poses little challenge for humans.", "labels": [], "entities": [{"text": "classifying review sentiments", "start_pos": 12, "end_pos": 41, "type": "TASK", "confidence": 0.9131881793340048}]}, {"text": "However, with large amount of data comes the necessity of automating such tedious classification tasks, which proves to be a challenge that needs careful development and consideration.", "labels": [], "entities": []}, {"text": "This challenge arises because reviewers use different registers when writing reviews across product domains.", "labels": [], "entities": []}, {"text": "Consequently, machines are not well equipped to catch those differences.", "labels": [], "entities": []}, {"text": "The differences are easy to detect when users reference domain-specific words or other products in the same category.", "labels": [], "entities": []}, {"text": "This belongs to a domain-specific knowledge that a neural network needs to learn in order to fully understand the differences and the similarities within the context of the reviews.", "labels": [], "entities": []}, {"text": "Thus, fora classifier to perform well at this task, it maybe important to include away for it to represent these domains.", "labels": [], "entities": []}, {"text": "In this paper, we propose a novel, yet effective way of representing domains in sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 80, "end_pos": 104, "type": "TASK", "confidence": 0.9347124099731445}]}, {"text": "Using this representation we will show that it is possible to visualize relations between domains.", "labels": [], "entities": []}, {"text": "This will allow clustering of similar product categories in the feature space of the domain representations.", "labels": [], "entities": []}, {"text": "We also attempt to evaluate whether these groupings are similar to those made by humans.", "labels": [], "entities": []}, {"text": "Implementing the domain representations as a vector embedding provides a simple and elegant solution compared to previous solutions like and.", "labels": [], "entities": []}, {"text": "The aim of this paper is to develop a cross-domain sentiment classification model achieving comparable performance to those of existing methods, with the added benefit of insights into the inter-domain relations.", "labels": [], "entities": [{"text": "cross-domain sentiment classification", "start_pos": 38, "end_pos": 75, "type": "TASK", "confidence": 0.69102676709493}]}, {"text": "Additionally we have developed a small but interesting data set building on top of.", "labels": [], "entities": []}, {"text": "Our main contribution being balancing and preprocessing the data, as well as adding the domain in an easy to parse way.", "labels": [], "entities": []}, {"text": "The data set is available at https://static.nfz.dk/data.zip.", "labels": [], "entities": []}], "datasetContent": [{"text": "We analyze the relevance that the domain embedding has in our model by testing our model twice, once with the Domain Encoder and once without.", "labels": [], "entities": []}, {"text": "These two experiments are run 4 times and the mean is reported.", "labels": [], "entities": [{"text": "mean", "start_pos": 46, "end_pos": 50, "type": "METRIC", "confidence": 0.9868005514144897}]}, {"text": "Furthermore, we test the proposed architecture by ablating adjectives and stop words separately.", "labels": [], "entities": []}, {"text": "In total we conduct 4 different experiments on the model.", "labels": [], "entities": []}, {"text": "We split the data set such that we have around 2 million reviews for training, 200,000 for validation and 200,000 as a hidden test set.", "labels": [], "entities": []}, {"text": "In all four cases we run 10 epochs of training while validating in between epochs.", "labels": [], "entities": []}, {"text": "Finally, we evaluate on the hidden test set.", "labels": [], "entities": []}, {"text": "The experiments are executed on a machine with an NVIDIA Tesla T4 GPU, 8 CPUs, 16GB of RAM, Keras 2.2.4 and TensorFlow 1.13.1.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Model performance with and without  the domain encoder", "labels": [], "entities": []}, {"text": " Table 4.  These performance metrics are calculated on  an unseen test set after training each model.  For comparison the model without domain en- coder is included as well.", "labels": [], "entities": []}, {"text": " Table 4: Final performance on hidden test set  in ablation studies", "labels": [], "entities": []}, {"text": " Table 5: Per domain accuracy performance  with and without the domain encoder", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.8186632394790649}]}]}