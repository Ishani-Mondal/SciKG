{"title": [{"text": "Domain Adaptation of SRL Systems for Biological Processes", "labels": [], "entities": [{"text": "Domain Adaptation of SRL", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6748815625905991}]}], "abstractContent": [{"text": "Domain adaptation remains one of the most challenging aspects in the widespread use of Semantic Role Labeling (SRL) systems.", "labels": [], "entities": [{"text": "Domain adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8117519319057465}, {"text": "Semantic Role Labeling (SRL)", "start_pos": 87, "end_pos": 115, "type": "TASK", "confidence": 0.7718897809584936}]}, {"text": "Current state-of-the-art methods are typically trained on large-scale datasets, but their performances do not directly transfer to low-resource domain-specific settings.", "labels": [], "entities": []}, {"text": "In this paper, we propose two approaches for domain adaptation in biological domain that involve pre-training LSTM-CRF based on existing large-scale datasets and adapting it fora low-resource corpus of biological processes.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 45, "end_pos": 62, "type": "TASK", "confidence": 0.7097722589969635}]}, {"text": "Our first approach defines a mapping between the source labels and the target labels, and the other approach modifies the final CRF layer in sequence-labeling neural network architecture.", "labels": [], "entities": []}, {"text": "We perform our experiments on Pro-cessBank (Berant et al., 2014) dataset which contains less than 200 paragraphs on biological processes.", "labels": [], "entities": [{"text": "Pro-cessBank (Berant et al., 2014) dataset", "start_pos": 30, "end_pos": 72, "type": "DATASET", "confidence": 0.8765093286832174}]}, {"text": "We improve over the previous state-of-the-art system on this dataset by 21 F1 points.", "labels": [], "entities": [{"text": "F1", "start_pos": 75, "end_pos": 77, "type": "METRIC", "confidence": 0.9905027151107788}]}, {"text": "We also show that, by incorporating event-event relationship in ProcessBank, we are able to achieve an additional 2.6 F1 gain, giving us possible insights into how to improve SRL systems for biological process using richer annotations.", "labels": [], "entities": [{"text": "F1", "start_pos": 118, "end_pos": 120, "type": "METRIC", "confidence": 0.9973775148391724}, {"text": "SRL", "start_pos": 175, "end_pos": 178, "type": "TASK", "confidence": 0.9903923273086548}]}], "introductionContent": [{"text": "Semantic Role Labeling (SRL) is shallow semantic representation of a sentence, that allows us to capture the roles of arguments that anchor around an event.", "labels": [], "entities": [{"text": "Semantic Role Labeling (SRL)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8158238132794698}]}, {"text": "Despite significant recent progress in Deep SRL systems, there has been limited work in adapting such systems to low resource domain-specific scenarios where the label space of both domains are completely different.", "labels": [], "entities": [{"text": "Deep SRL", "start_pos": 39, "end_pos": 47, "type": "TASK", "confidence": 0.5764342248439789}]}, {"text": "Additionally, existing domain adaptation for SRL requires an overhead of annotating the new corpus using guidelines similar * * Both authors equally contributed to the paper.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.7814471125602722}, {"text": "SRL", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.9700091481208801}]}, {"text": "to the source dataset, and every domain-specific corpora might not necessarily adhere to the same label structure and similar annotation guidelines.", "labels": [], "entities": []}, {"text": "We present two different domain adaptation strategies that rely on training the model on a large corpora (source dataset) and fine-tuning on a lowresource domain-specific corpus (target dataset), more specifically biological processes domain.", "labels": [], "entities": []}, {"text": "The first approach uses mappings from the source label space to the target label space.", "labels": [], "entities": []}, {"text": "For this, we present DeepSRL-CRF, which incorporates a CRF layer over the DeepSRL model with an intermediate step of mapping labels from source to target domain.", "labels": [], "entities": []}, {"text": "For the second approach, we use a CNN-LSTM-CRF model to pre-train the neural network weights on the source domain, and adapt the final CRF layer of the network based on the target label space.", "labels": [], "entities": []}, {"text": "We then fine-tune the model on the target dataset.", "labels": [], "entities": []}, {"text": "For empirical evaluation, we explore the challenge of SRL in ProcessBank dataset, where the target domain (biological processes) is drastically different compared to the source domain (news).", "labels": [], "entities": [{"text": "SRL", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.9908291101455688}, {"text": "ProcessBank dataset", "start_pos": 61, "end_pos": 80, "type": "DATASET", "confidence": 0.8366079032421112}]}, {"text": "Both of our approaches are effective for adapting SRL systems for biological processes.", "labels": [], "entities": [{"text": "SRL", "start_pos": 50, "end_pos": 53, "type": "TASK", "confidence": 0.9517140984535217}]}, {"text": "Compared to the previous best system, we get an improvement of about 24 F1 points when we use label-mapping approach, and about 21 F1 point improvement when we adapt the final CRF layer.", "labels": [], "entities": [{"text": "F1", "start_pos": 72, "end_pos": 74, "type": "METRIC", "confidence": 0.9985533356666565}, {"text": "F1", "start_pos": 131, "end_pos": 133, "type": "METRIC", "confidence": 0.9964646100997925}]}, {"text": "Our contributions can be summarized as follows: 1.", "labels": [], "entities": []}, {"text": "Two different approaches for domain adaptation of SRL for biological processes, with our code and models publicly available 2.", "labels": [], "entities": [{"text": "SRL", "start_pos": 50, "end_pos": 53, "type": "TASK", "confidence": 0.8626593947410583}]}, {"text": "An in-depth analysis for each of the domain adaptation strategies, both perform significantly better in low-resource SRL for biological processes 3.", "labels": [], "entities": [{"text": "SRL", "start_pos": 117, "end_pos": 120, "type": "TASK", "confidence": 0.9632247686386108}]}, {"text": "Analysis of the model performance when the target corpus is annotated with event-event relationships to the SRL corpus", "labels": [], "entities": [{"text": "SRL corpus", "start_pos": 108, "end_pos": 118, "type": "DATASET", "confidence": 0.764629989862442}]}], "datasetContent": [{"text": "Experimental Setup : For evaluation, we use the and) datasets as our primary large-scale datasets with the standard splits.", "labels": [], "entities": []}, {"text": "For the domain adaptation scenario, we use the ProcessBank dataset) 2 . We used 134 annotated paragraphs for training, 19 for development and 50 for testing.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.80457803606987}, {"text": "ProcessBank dataset", "start_pos": 47, "end_pos": 66, "type": "DATASET", "confidence": 0.9173702299594879}]}, {"text": "Each passage in the ProcessBank dataset describes a process, defined by a directed graph (T, A, E tt , E ta ), where nodes T denote event triggers and A denote their corresponding arguments.", "labels": [], "entities": [{"text": "ProcessBank dataset", "start_pos": 20, "end_pos": 39, "type": "DATASET", "confidence": 0.8070095181465149}]}, {"text": "E tt represents labeled edges event-event relations and E ta describe event-argument relations.", "labels": [], "entities": []}, {"text": "The edges E ta are annotated with semantic roles AGENT, THEME, SOURCE, DESTINA-TION, LOCATION, RESULT and OTHER.", "labels": [], "entities": [{"text": "AGENT", "start_pos": 49, "end_pos": 54, "type": "METRIC", "confidence": 0.9949012994766235}, {"text": "THEME", "start_pos": 56, "end_pos": 61, "type": "METRIC", "confidence": 0.9736497402191162}, {"text": "SOURCE", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.9487173557281494}, {"text": "DESTINA-TION", "start_pos": 71, "end_pos": 83, "type": "METRIC", "confidence": 0.8898683190345764}, {"text": "LOCATION", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9418957233428955}, {"text": "RESULT", "start_pos": 95, "end_pos": 101, "type": "METRIC", "confidence": 0.9927729964256287}, {"text": "OTHER", "start_pos": 106, "end_pos": 111, "type": "METRIC", "confidence": 0.9682168960571289}]}, {"text": "Each E tt edge between event and another event is annotated with the relations CAUSE, ENABLE and PREVENT.", "labels": [], "entities": [{"text": "CAUSE", "start_pos": 79, "end_pos": 84, "type": "METRIC", "confidence": 0.9928128123283386}, {"text": "ENABLE", "start_pos": 86, "end_pos": 92, "type": "METRIC", "confidence": 0.9919133186340332}, {"text": "PREVENT", "start_pos": 97, "end_pos": 104, "type": "METRIC", "confidence": 0.8140142560005188}]}, {"text": "Our experiments primarily focus on the prediction of the event-argument structures E ta since the source datasets that we use for domain adaption do not contain any event-event relationship annotation.", "labels": [], "entities": []}, {"text": "Baselines : In our first set of baselines, we compare our models on the tasks.", "labels": [], "entities": []}, {"text": "We use the previous state-of-the-art SRL system from He et al.", "labels": [], "entities": []}, {"text": "(2018) as our baseline.", "labels": [], "entities": []}, {"text": "Since our model is based on LSTM-CRF hybrid architecture, we implement two other baselines for our approach.", "labels": [], "entities": []}, {"text": "We use a standard BiLSTM-CRF model (, and a model based on the structured attention proposed in which uses CRF style structure in the intermediate layer.", "labels": [], "entities": []}, {"text": "For a fair comparison, we augmented this structured attention based network with a CRF layer on top.", "labels": [], "entities": []}, {"text": "We use 300D GLoVe embeddings () across all models.", "labels": [], "entities": []}, {"text": "For domain adaptation, we use the original system from as the baseline.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.8394611477851868}]}, {"text": "It uses the approach in, where for each trigger, a set of argument candidates are first determined, and then a binary classifier uses argument identification features to prune", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: SRL results for CoNLL-2005 and CoNLL-2012 datasets. DeepSRL-ELMo resuls from He et al. (2018)", "labels": [], "entities": [{"text": "SRL", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.7698668241500854}, {"text": "CoNLL-2005", "start_pos": 26, "end_pos": 36, "type": "DATASET", "confidence": 0.9177817702293396}, {"text": "CoNLL-2012 datasets", "start_pos": 41, "end_pos": 60, "type": "DATASET", "confidence": 0.9076147377490997}, {"text": "DeepSRL-ELMo resuls from He et al", "start_pos": 62, "end_pos": 95, "type": "DATASET", "confidence": 0.9025557736555735}]}, {"text": " Table 3: SRL results for ProcessBank dataset -Domain adaptation using label mapping.", "labels": [], "entities": [{"text": "SRL", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.6024527549743652}, {"text": "ProcessBank dataset", "start_pos": 26, "end_pos": 45, "type": "DATASET", "confidence": 0.8247988224029541}, {"text": "Domain adaptation", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.7441989183425903}]}, {"text": " Table 4: Results for ProcessBank -Domain adaption  by replacing the CRF layer", "labels": [], "entities": [{"text": "ProcessBank -Domain adaption", "start_pos": 22, "end_pos": 50, "type": "TASK", "confidence": 0.5427635759115219}]}, {"text": " Table 5: Best performing CNN-LSTM-CRF model's breakdown of true (rows) and predicted (columns) B tags with  BIO tagging scheme. (Agt.=Agent; Dest.=Destination; Loc.=Location; Oth.=Other; Res.=Result; Src.=Source;  The.=Theme; O=O tag in BIO tagging)", "labels": [], "entities": [{"text": "BIO tagging", "start_pos": 238, "end_pos": 249, "type": "TASK", "confidence": 0.5877264142036438}]}, {"text": " Table 6: Best performing CNN-LSTM-CRF model's breakdown of true (rows) and predicted (columns) I tags with  BIO tagging scheme. (Agt.=Agent; Dest.=Destination; Loc.=Location; Oth.=Other; Res.=Result; Src.=Source;  The.=Theme; O=Otag in BIO tagging)", "labels": [], "entities": [{"text": "O", "start_pos": 227, "end_pos": 228, "type": "METRIC", "confidence": 0.9557453989982605}, {"text": "Otag", "start_pos": 229, "end_pos": 233, "type": "METRIC", "confidence": 0.841073215007782}, {"text": "BIO tagging", "start_pos": 237, "end_pos": 248, "type": "TASK", "confidence": 0.600189208984375}]}]}