{"title": [{"text": "A System to Monitor Cyberbullying based on Message Classification and Social Network Analysis", "labels": [], "entities": [{"text": "Message Classification", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.7316462695598602}, {"text": "Social Network Analysis", "start_pos": 70, "end_pos": 93, "type": "TASK", "confidence": 0.6736100514729818}]}], "abstractContent": [{"text": "Social media platforms like Twitter and Insta-gram face a surge in cyberbullying phenomena against young users and need to develop scalable computational methods to limit the negative consequences of this kind of abuse.", "labels": [], "entities": []}, {"text": "Despite the number of approaches recently proposed in the Natural Language Processing (NLP) research area for detecting different forms of abusive language, the issue of identifying cyberbullying phenomena at scale is still an unsolved problem.", "labels": [], "entities": []}, {"text": "This is because of the need to couple abusive language detection on textual message with network analysis, so that repeated attacks against the same person can be identified.", "labels": [], "entities": [{"text": "abusive language detection", "start_pos": 38, "end_pos": 64, "type": "TASK", "confidence": 0.7899573842684428}]}, {"text": "In this paper, we present a system to monitor cyberbullying phenomena by combining message classification and social network analysis.", "labels": [], "entities": [{"text": "message classification", "start_pos": 83, "end_pos": 105, "type": "TASK", "confidence": 0.7931811511516571}]}, {"text": "We evaluate the classification module on a data set built on Instagram messages, and we describe the cyberbullying monitoring user interface.", "labels": [], "entities": []}], "introductionContent": [{"text": "The presence on social networks like Twitter, Facebook and Instagram is of main importance for teenagers, but this may also lead to undesirable and harmful situations.", "labels": [], "entities": []}, {"text": "We refer to these forms of harassment as cyberbullying, i.e., 'an aggressive, intentional act carried out by a group or an individual, using electronic forms of contact, repeatedly and overtime against a victim who cannot easily defend him or herself' (.", "labels": [], "entities": []}, {"text": "In online social media, each episode of online activity aimed at offending, menacing, harassing or stalking another person can be classified as a cyberbullying phenomenon.", "labels": [], "entities": []}, {"text": "This is connected even with concrete public health issues, since recent studies show that victims are more likely to suffer from psycho-social difficulties and affective disorders.", "labels": [], "entities": []}, {"text": "Given its societal impact, the implementation of cyberbullying detection systems, combining abusive language detection and social network analysis, has attracted a lot of attention in the last years (.", "labels": [], "entities": [{"text": "cyberbullying detection", "start_pos": 49, "end_pos": 72, "type": "TASK", "confidence": 0.7306489944458008}, {"text": "abusive language detection", "start_pos": 92, "end_pos": 118, "type": "TASK", "confidence": 0.7020837267239889}]}, {"text": "However, the adoption of such systems in real life is not straightforward and their use in a black box scenario is not desirable, given the negative effects misleading analyses could have on potential abusers and victims.", "labels": [], "entities": []}, {"text": "A more transparent approach should be adopted, in which cyberbullying identification should be mediated by human judgment.", "labels": [], "entities": [{"text": "cyberbullying identification", "start_pos": 56, "end_pos": 84, "type": "TASK", "confidence": 0.7588018178939819}]}, {"text": "In this paper, we present a system for the monitoring of cyberbullying phenomena on social media.", "labels": [], "entities": []}, {"text": "The system aims at supporting supervising persons (e.g., educators) at identifying potential cases of cyberbullying through an intuitive, easyto-use interface.", "labels": [], "entities": []}, {"text": "This displays both the outcome of a hate speech detection system and the network in which the messages are exchanged.", "labels": [], "entities": [{"text": "hate speech detection", "start_pos": 36, "end_pos": 57, "type": "TASK", "confidence": 0.757530947526296}]}, {"text": "Supervising persons can therefore monitor the escalation of hateful online exchanges and decide whether to intervene or not, similar to the workflow introduced in.", "labels": [], "entities": []}, {"text": "We evaluate the NLP classifier on a set of manually annotated data from Instagram, and detail the network extraction algorithm starting from 10 Manchester high schools.", "labels": [], "entities": [{"text": "Instagram", "start_pos": 72, "end_pos": 81, "type": "DATASET", "confidence": 0.914909839630127}, {"text": "network extraction", "start_pos": 98, "end_pos": 116, "type": "TASK", "confidence": 0.7407454252243042}, {"text": "Manchester high schools", "start_pos": 144, "end_pos": 167, "type": "DATASET", "confidence": 0.9471128980318705}]}, {"text": "However, this is only one possible use case of the system, which can be employed over different kinds of data.", "labels": [], "entities": []}, {"text": "In this demo, we focus on high-schools, but the approach can be extended to other communities of interest.", "labels": [], "entities": []}, {"text": "Our case study concerns the network of Manchester high-school students, and we choose to focus on Instagram, since it is widely used by teenagers of that age.", "labels": [], "entities": [{"text": "Manchester high-school students", "start_pos": 39, "end_pos": 70, "type": "DATASET", "confidence": 0.9032978216807047}]}, {"text": "Reconstructing local communities on Instagram is a challenging task.", "labels": [], "entities": [{"text": "Reconstructing local communities", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8891324202219645}]}, {"text": "Indeed, differently from how other social networks operate (e.g., Facebook), Instagram does not provide a page for institutions such as High Schools, that therefore need to be inferred.", "labels": [], "entities": []}, {"text": "To overcome this issue, and to identify local communities of students, we proceed in two steps that can be summarised as follow: \u2022 Expansion stage.", "labels": [], "entities": [{"text": "Expansion", "start_pos": 131, "end_pos": 140, "type": "METRIC", "confidence": 0.8857367634773254}]}, {"text": "We start from few users that are very likely to be part of the local high school community, and we use them to identify an increasing number of other possible members expanding our network coverage.", "labels": [], "entities": []}, {"text": "We identify, within the large network, smaller communities of users and we isolate the ones composed by students.", "labels": [], "entities": []}, {"text": "For these, we retrieve the exchanged messages in a given period of time (in our case, the ongoing school year), which will be used to identify abusive messages.", "labels": [], "entities": []}], "datasetContent": [{"text": "Although our use case focuses on Instagram messages, we could not find available datasets from this social network with annotated comments.", "labels": [], "entities": []}, {"text": "The widely used dataset used by) has indeed annotations at thread level.", "labels": [], "entities": []}, {"text": "We therefore train our classification algorithm using the dataset described in (, containing 16k English tweets manually annotated for hate speech.", "labels": [], "entities": []}, {"text": "More precisely, 1,924 are annotated as containing racism, 3,082 as containing sexism, while 10,884 tweets are annotated as not containing offensive language.", "labels": [], "entities": []}, {"text": "We merge the sexist and racist tweets in a single class, so that 5,006 tweets are considered as positive instances of hate speech.", "labels": [], "entities": []}, {"text": "As a test set, we manually annotate 900 Instagram comments, randomly extracted from the Manchester network, labeling them as hate speech or not.", "labels": [], "entities": [{"text": "Manchester network", "start_pos": 88, "end_pos": 106, "type": "DATASET", "confidence": 0.9821437001228333}]}, {"text": "Overall, the test set contains 787 non-offensive and 113 offensive messages.", "labels": [], "entities": []}, {"text": "We preprocess both data sets, given that hashtags, user mentions, links to external media and emojis are common in social media interactions.", "labels": [], "entities": []}, {"text": "To normalize the text as much as possible while retaining all relevant semantic information, we first replace URLs with the word \"url\" and \"@\" user mentions with \"username\" by using regular expressions.", "labels": [], "entities": []}, {"text": "We also use the Ekphrasis tool () to split hashtags into sequences of words, when possible.", "labels": [], "entities": []}, {"text": "The system obtained on the test set a microaveraged F1 of 0.823.", "labels": [], "entities": [{"text": "F1", "start_pos": 52, "end_pos": 54, "type": "METRIC", "confidence": 0.8209128379821777}]}, {"text": "We then run the classifier on all messages extracted for the Manchester network, and make the output available through the platform interface.", "labels": [], "entities": [{"text": "Manchester network", "start_pos": 61, "end_pos": 79, "type": "DATASET", "confidence": 0.9801190197467804}]}], "tableCaptions": []}