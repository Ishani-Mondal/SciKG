{"title": [{"text": "At the Lower End of Language- Exploring the Vulgar and Obscene Side of German", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we describe a workflow for the data-driven acquisition and semantic scaling of a lexicon that covers lexical items from the lower end of the German language register-terms typically considered as rough, vulgar or obscene.", "labels": [], "entities": [{"text": "data-driven acquisition and semantic scaling of a lexicon", "start_pos": 46, "end_pos": 103, "type": "TASK", "confidence": 0.7375149242579937}]}, {"text": "Since the fine semantic representation of grades of obscenity can only inadequately be captured at the categorical level (e.g., obscene vs. non-obscene, or rough vs. vulgar), our main contribution lies in applying best-worst scaling, a rating methodology that has already been shown to be useful for emotional language, to capture the relative strength of obscenity of lexical items.", "labels": [], "entities": []}, {"text": "We describe the empirical foundations for bootstrapping such a low-end lexicon for German by starting from manually supplied lexicographic categoriza-tions of a small seed set of rough and vulgar lexical items and automatically enlarging this set by means of distributional semantics.", "labels": [], "entities": []}, {"text": "We then determine the degrees of obscenity for the full set of all acquired lexical items by letting crowdworkers comparatively assess their pejorative grade using best-worst scaling.", "labels": [], "entities": []}, {"text": "This semi-automatically enriched lexicon already comprises 3,300 lexical items and incorporates 33,000 vulgarity ratings.", "labels": [], "entities": []}, {"text": "Using it as a seed lexicon for fully automatic lexical acquisition , we were able to raise its coverage up to slightly more than 11,000 entries.", "labels": [], "entities": [{"text": "automatic lexical acquisition", "start_pos": 37, "end_pos": 66, "type": "TASK", "confidence": 0.7454131841659546}]}], "introductionContent": [{"text": "With the rapid diffusion of social media in our daily lives, we currently experience (and many of us foster) a fundamental change of social communication habits.", "labels": [], "entities": []}, {"text": "A main feature of this new era is an unprecedented degree of public exposure and visibility of individuals via (very) large and intentionally open networks of \"friends\" or \"followers.\"", "labels": [], "entities": []}, {"text": "Blogs, chat rooms and online fora constitute even looser connected social networks with lots of personally weakly acquainted or even unknown interlocutors engaged in digital discourses.", "labels": [], "entities": []}, {"text": "Unfortunately, the chance for malicious interactions is promoted by the sheer mass of players in these networks and easy ways of hiding real individual identities via nick names or technically slightly more advanced means of camouflage, such as fake Web identities, including non-benevolent software agents and chatbots).", "labels": [], "entities": []}, {"text": "These promiscuous communication groups face a high risk of anti-social behavior by aggressive, ruthless or entirely hostile actors.", "labels": [], "entities": []}, {"text": "The phenomena encountered range from (political, religious, ethnic, sexual) harassment, flaming, cybertrolling, and cyberbullying to extremely evaluative (derogatory, hurtful, rough, rude, offensive, abusive, vulgar, taboo, obscene) language use (for a typological clarification attempt, cf.).", "labels": [], "entities": [{"text": "flaming, cybertrolling, and cyberbullying to extremely evaluative (derogatory, hurtful, rough, rude, offensive, abusive, vulgar, taboo, obscene) language use", "start_pos": 88, "end_pos": 245, "type": "Description", "confidence": 0.7985863149166107}]}, {"text": "NLP research has recently directed its attention towards these unwarranted effects of social media activities and targets the automatic recognition of toxic language for the purpose of alerting and warning (), filtering and blocking (, or reformulating suspicious contents of this type by non-obtrusive paraphrases ().", "labels": [], "entities": []}, {"text": "Yet, how can we distinguish sloppy colloquial language we all use here and therefrom explicitly abusive and inacceptable wording, the topic we focus on in this paper, i.e., the kind of linguistic behavior typically socially banned from civilized discourse?", "labels": [], "entities": []}, {"text": "The standard way to deal with this challenge is to define category systems (binary ones, such as obscene vs. non-obscene, or staged ones, as illustrated by pejorative vs. rough vs. vulgar) and letting people decide on the assignment of lexical items to these discrete categories.", "labels": [], "entities": []}, {"text": "Once such categorical features are available, these lexical resources can be exploited for analytic purposes.", "labels": [], "entities": []}, {"text": "Traditionally, these decisions were made by few lexicographers but this approach suffers from subjectivity and lack of flexibility, since this lexicon of improper words is rapidly growing due to the productiveness of language and thus changing almost everyday.", "labels": [], "entities": []}, {"text": "Alternatively, a larger number of crowdworkers can be hired to provide such category assignments which increases the level of objectivity (on the basis of inter-worker consensus) and currency (campaigns can be run without delay, on demand, with low budgets).", "labels": [], "entities": []}, {"text": "Yet, crowdsourced assessments, as with lexicographers' judgments, inherently suffer from the problems of permeable and soft category boundaries-what is rough for one person maybe vulgar for another and vice versa.", "labels": [], "entities": []}, {"text": "We challenge the established view that the representation of obscenity of language is a discrete categorical classification problem-no matter which category system is chosen-but rather assume that it is a matter of differential degree.", "labels": [], "entities": []}, {"text": "Accordingly, we describe the empirical foundations for bootstrapping and scaling such a lexicon from the low end of stylistic conventions on degrees of obscenity.", "labels": [], "entities": []}, {"text": "We start from expert-level lexicographic categorizations of a small set of pejorative/rough/vulgar lexical items, enlarge this set by distributional semantics methods and, then, determine the degree of obscenity of the items assembled this way by letting crowdworkers make individual assessments relative to the semantic poles \"neutral\" and \"vulgar\" using a best-worst scaling approach).", "labels": [], "entities": []}, {"text": "The resulting lexicon targeting that lower end of German language comprises already 3,300 lexical items, incorporates 33,000 human ratings, and serves as a seed lexicon for fully automatically acquiring and scoring new lexical items from the same register.", "labels": [], "entities": []}, {"text": "After several iterations, we finally come up with VULGER, a lexicon of VULgar GERman, totalling slightly more than 11,000 entries.", "labels": [], "entities": [{"text": "VULGER", "start_pos": 50, "end_pos": 56, "type": "DATASET", "confidence": 0.6545060873031616}, {"text": "VULgar GERman", "start_pos": 71, "end_pos": 84, "type": "DATASET", "confidence": 0.8382043540477753}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Averaged Pearson correlation (10-fold cross  validation) and p-value (two-sided t-test) for Linear  Regression (LinReg) and Ridge Regression (Ridge- Reg)", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 19, "end_pos": 38, "type": "METRIC", "confidence": 0.8542921841144562}]}, {"text": " Table 2: Averaged Pearson correlation (10-fold cross  validation) for different embeddings with Ridge Re- gression, with significance difference to best perform- ing embeddings (p-value from two-sided t-test)", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 19, "end_pos": 38, "type": "METRIC", "confidence": 0.8929639458656311}, {"text": "Ridge Re- gression", "start_pos": 97, "end_pos": 115, "type": "METRIC", "confidence": 0.8379295170307159}]}]}