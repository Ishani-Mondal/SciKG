{"title": [{"text": "An Intelligent Testing Strategy for Vocabulary Assessment of Chinese Second Language Learners", "labels": [], "entities": [{"text": "Vocabulary Assessment of Chinese Second Language Learners", "start_pos": 36, "end_pos": 93, "type": "TASK", "confidence": 0.8497375590460641}]}], "abstractContent": [{"text": "Testing is an important tool to monitor learning effects.", "labels": [], "entities": []}, {"text": "However, it usually costs a large amount of time and human labor to build an item bank and to test large number of students.", "labels": [], "entities": []}, {"text": "In this paper, we propose a novel testing strategy by combining automatic item generation (AIG) and computerized adaptive testing (CAT) in vocabulary assessment for Chinese L2 learners.", "labels": [], "entities": [{"text": "vocabulary assessment", "start_pos": 139, "end_pos": 160, "type": "TASK", "confidence": 0.7826821208000183}]}, {"text": "Firstly, we generate three types of vocabulary questions by modeling both the vocabulary knowledge and learners' writing error data.", "labels": [], "entities": []}, {"text": "After evaluation and calibration, we construct a balanced item pool with automatically generated items, and implement a three-parameter computerized adaptive test.", "labels": [], "entities": []}, {"text": "We conduct manual item evaluation and online student tests in the experiments.", "labels": [], "entities": []}, {"text": "The results show that the combination of AIG and CAT can construct test items efficiently and reduce test cost significantly.", "labels": [], "entities": []}, {"text": "Also, the test result of CAT can provide valuable feedback to AIG algorithms .", "labels": [], "entities": [{"text": "CAT", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.964891254901886}]}], "introductionContent": [{"text": "Vocabulary is one of the most important parts of language competence.", "labels": [], "entities": []}, {"text": "Testing of vocabulary knowledge is central to research on reading and language).", "labels": [], "entities": []}, {"text": "However, it usually costs a large amount of time and human labor to build an item bank and to test large number of students.", "labels": [], "entities": []}, {"text": "To enhance the testing efficiency and convenience, we propose a novel testing strategy by combining automatic item generation (AIG) and computerized adaptive testing (CAT).", "labels": [], "entities": []}, {"text": "Based on this strategy, we build an online testing system to evaluate vocabulary knowledge of Chinese second language learners: http://test.aihanyu. org.", "labels": [], "entities": []}, {"text": "The pipeline of our method is illustrated in: Step 1.", "labels": [], "entities": []}, {"text": "Generate vocabulary questions automatically by modeling both the vocabulary knowledge and learners' writing error data.", "labels": [], "entities": []}, {"text": "Construct a balanced item pool by sampling questions from different difficulty levels, and implement an online vocabulary test with these items.", "labels": [], "entities": []}, {"text": "Conduct student tests in which students with different language proficiencies take both the online AIG test and a traditional student placement test developed by experts.", "labels": [], "entities": []}, {"text": "Build an improved three-parameter CAT model with these items, and estimate the students' abilities.", "labels": [], "entities": [{"text": "CAT", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.9596620798110962}]}, {"text": "In the experiments, the student tests demonstrate desirable results.", "labels": [], "entities": []}, {"text": "Firstly, the scores of the online AIG test are strongly correlated with that of the placement test (\u03c1=0.8395).", "labels": [], "entities": []}, {"text": "Secondly, the student abilities estimated by our CAT model reaches even stronger correlation with the placement test (\u03c1=0.8715).", "labels": [], "entities": [{"text": "placement test", "start_pos": 102, "end_pos": 116, "type": "METRIC", "confidence": 0.7867685556411743}]}, {"text": "Meanwhile, the average test length decreases greatly by 81% (from 140 to 26).", "labels": [], "entities": [{"text": "length", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.5878521203994751}]}, {"text": "The experiments show that our strategy can construct test items efficiently and reduce test cost significantly for both test developers and test takers.", "labels": [], "entities": []}, {"text": "Also, the test result of CAT can provide valuable feedback to question generation and selection algorithms.", "labels": [], "entities": [{"text": "CAT", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.9643441438674927}, {"text": "question generation", "start_pos": 62, "end_pos": 81, "type": "TASK", "confidence": 0.7680419087409973}]}], "datasetContent": [{"text": "We evaluate our method via three experiments: (1) Evaluate the automatically generated items manually.", "labels": [], "entities": []}, {"text": "(2) Conduct student test with both an online AIG test and a traditional written test developed by CSL teachers.", "labels": [], "entities": []}, {"text": "(3) Use CAT model to estimate the students' abilities.", "labels": [], "entities": []}, {"text": "To assess the students' vocabulary knowledge, we generate three types and totally 93764 test items.", "labels": [], "entities": []}, {"text": "After that, we randomly sample 100 items for each type of question, resulting in 300 items in total.", "labels": [], "entities": []}, {"text": "These questions are used for manual evaluation.", "labels": [], "entities": []}, {"text": "Original Acceptance Rate (OAR) and Adjustable Acceptance Rate (AAR) are calculated.", "labels": [], "entities": [{"text": "Original Acceptance Rate (OAR)", "start_pos": 0, "end_pos": 30, "type": "METRIC", "confidence": 0.9397895435492197}, {"text": "Adjustable Acceptance Rate (AAR)", "start_pos": 35, "end_pos": 67, "type": "METRIC", "confidence": 0.884967565536499}]}, {"text": "An item can be originally accepted if two professional CSL teachers both agree that this item can be directly used in a vocabulary test.", "labels": [], "entities": []}, {"text": "And it can bean adjustable item if the teachers both agree that it only needs a few simple modifications, i.e. the replacement or deletion of less than 2 words.", "labels": [], "entities": []}, {"text": "The evaluation results are shown in.", "labels": [], "entities": []}, {"text": "The question generation method performs well with the average OAR of 53% and the AAR of 81.67%.", "labels": [], "entities": [{"text": "question generation", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.8026894927024841}, {"text": "OAR", "start_pos": 62, "end_pos": 65, "type": "METRIC", "confidence": 0.9984220266342163}, {"text": "AAR", "start_pos": 81, "end_pos": 84, "type": "METRIC", "confidence": 0.9995388984680176}]}, {"text": "It is noteworthy that the acceptance rate varies a lot among three types of questions.", "labels": [], "entities": [{"text": "acceptance rate", "start_pos": 26, "end_pos": 41, "type": "METRIC", "confidence": 0.9726887345314026}]}, {"text": "Word pro- break while end if end while return\u02c6\u03b8return\u02c6 return\u02c6\u03b8 nunciation question performs best since it focuses only on the pinyin label, and its generation module is very simple.", "labels": [], "entities": []}, {"text": "The generation of word selection questions is much more complicated.", "labels": [], "entities": [{"text": "generation of word selection questions", "start_pos": 4, "end_pos": 42, "type": "TASK", "confidence": 0.7513345241546631}]}, {"text": "It involves appropriate selection of sentences, target words and distractors.", "labels": [], "entities": []}, {"text": "Word collocation question can be considered as a simplified version of word selection question.", "labels": [], "entities": [{"text": "word selection question", "start_pos": 71, "end_pos": 94, "type": "TASK", "confidence": 0.7857820590337118}]}, {"text": "We further analyze the feedback of the teachers, and find that the distractor selection works very well, indicating that our vocabulary knowledge base has a high quality.", "labels": [], "entities": []}, {"text": "Meanwhile, the stem sentence selection and target word selection algorithms needs further improvement on both difficulty control and semantic analysis.", "labels": [], "entities": [{"text": "stem sentence selection", "start_pos": 15, "end_pos": 38, "type": "TASK", "confidence": 0.6419441799322764}, {"text": "target word selection", "start_pos": 43, "end_pos": 64, "type": "TASK", "confidence": 0.672664741675059}, {"text": "semantic analysis", "start_pos": 133, "end_pos": 150, "type": "TASK", "confidence": 0.8124340176582336}]}], "tableCaptions": [{"text": " Table 1: Results of Expert Evaluation", "labels": [], "entities": [{"text": "Expert Evaluation", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.7024314850568771}]}]}