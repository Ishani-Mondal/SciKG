{"title": [{"text": "Automatic Alignment and Annotation Projection for Literary Texts", "labels": [], "entities": [{"text": "Automatic Alignment and Annotation Projection", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.7391693353652954}]}], "abstractContent": [{"text": "This paper presents a modular NLP pipeline for the creation of a parallel literature corpus , followed by annotation transfer from the source to the target language.", "labels": [], "entities": []}, {"text": "The test case we use to evaluate our pipeline is the automatic transfer of quote and speaker mention annotations from English to German.", "labels": [], "entities": []}, {"text": "We evaluate the different components of the pipeline and discuss challenges specific to literary texts.", "labels": [], "entities": []}, {"text": "Our experiments show that after applying a reasonable amount of semi-automatic postprocessing we can obtain high-quality aligned and annotated resources fora new language.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent years have seen an increasing interest in using computational and mixed method approaches for literary studies.", "labels": [], "entities": [{"text": "literary studies", "start_pos": 101, "end_pos": 117, "type": "TASK", "confidence": 0.8119035065174103}]}, {"text": "A casein point is the analysis of literary characters using social network analysis (.", "labels": [], "entities": []}, {"text": "While the first networks have been created manually, follow-up studies have tried to automatically extract the information needed to fill the network with life.", "labels": [], "entities": []}, {"text": "The manual construction of such networks can yield high quality analyses, however, the amount of time needed for manually extracting the information is huge.", "labels": [], "entities": []}, {"text": "The second approach based on automatic information extraction is more adequate for large scale investigations of literary texts.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.7106492221355438}]}, {"text": "However, due to the difficulty of the task the quality of the resulting network is often seriously hampered.", "labels": [], "entities": []}, {"text": "In some studies, the extraction of character information is limited to explicit mentions in the text, and relations between characters in the network are often based on their co-occurence in a predefined text window, missing out on the more interesting but harder-to-get features encoded in the novel.", "labels": [], "entities": []}, {"text": "A more meaningful analysis requires the identification of character entities and their mentions in the text, as well as the attribution of quotes to their respective speakers.", "labels": [], "entities": []}, {"text": "Unfortunately, this is not an easy task.", "labels": [], "entities": []}, {"text": "Characters in novels are mostly referred to by anaphoric mentions, such as personal pronouns or nominal descriptors (e.g. \"the old women\" or \"the hard-headed lawyer\"), and these have to be traced back to the respective entity to whom they refer, i.e. the speaker.", "labels": [], "entities": []}, {"text": "For English, automatic approaches based on machine learning) or rule-based systems () have been developed for this task, and a limited amount of annotated resources already exists.", "labels": [], "entities": []}, {"text": "For most other languages, however, such resources are not yet available.", "labels": [], "entities": []}, {"text": "To make progress towards the fully automatic identification of speakers and quotes in literary texts, we need more training data.", "labels": [], "entities": [{"text": "identification of speakers and quotes in literary texts", "start_pos": 45, "end_pos": 100, "type": "TASK", "confidence": 0.8403205275535583}]}, {"text": "As the fully manual annotation of such resources is time-consuming and costly, we present a method for the automatic transfer of annotations from English to other languages where resources for speaker attribution and quote detection are sparse.", "labels": [], "entities": [{"text": "speaker attribution", "start_pos": 193, "end_pos": 212, "type": "TASK", "confidence": 0.7126047611236572}, {"text": "quote detection", "start_pos": 217, "end_pos": 232, "type": "TASK", "confidence": 0.7841549217700958}]}, {"text": "We test our approach for German, making use of publically available literary translations of English novels.", "labels": [], "entities": []}, {"text": "We first create a parallel EnglishGerman literature corpus and then project existing annotations from English to German.", "labels": [], "entities": [{"text": "EnglishGerman literature corpus", "start_pos": 27, "end_pos": 58, "type": "DATASET", "confidence": 0.9467508594195048}]}, {"text": "The main contributions of our work are the following: \u2022 We present a modular pipeline for creating parallel literary corpora and for annotation transfer.", "labels": [], "entities": [{"text": "annotation transfer", "start_pos": 133, "end_pos": 152, "type": "TASK", "confidence": 0.7166047990322113}]}, {"text": "\u2022 We evaluate the impact of semi-automatic postprocessing on the quality of the different components in our pipeline.", "labels": [], "entities": []}, {"text": "\u2022 We show how the choice of translation impacts the quality of the annotation transfer and present a method for determining the best translation for this task.", "labels": [], "entities": []}], "datasetContent": [{"text": "We compare two different settings in our experiments, (i) a fully-automatic setting and (ii) a semiautomatic setting.", "labels": [], "entities": []}, {"text": "In the fully-automatic setting, the texts are extracted from the annotated XML files and directly fed into the pipeline, passing through sentence splitting, tokenisation, MT translation, sentence alignment, word alignment and annotation transfer without any intervention or correction by the user.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 137, "end_pos": 155, "type": "TASK", "confidence": 0.7234272509813309}, {"text": "MT translation", "start_pos": 171, "end_pos": 185, "type": "TASK", "confidence": 0.98443603515625}, {"text": "sentence alignment", "start_pos": 187, "end_pos": 205, "type": "TASK", "confidence": 0.7707665860652924}, {"text": "word alignment", "start_pos": 207, "end_pos": 221, "type": "TASK", "confidence": 0.7844472229480743}]}, {"text": "In the semi-automatic setting, the texts have been subject to a number of genre-dependent preand post-processing steps which are described below.", "labels": [], "entities": []}, {"text": "These processing steps are adjusted to the text genre and translation specifics and probably need modification and further adaptation when transferred to other literary texts from potentially different domains.", "labels": [], "entities": []}, {"text": "P1: Sentence segmentation Before sentence segmentation, we automatically harmonised punctuation (e.g. \" \" \" to \").", "labels": [], "entities": [{"text": "Sentence segmentation", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.8667305409908295}, {"text": "sentence segmentation", "start_pos": 33, "end_pos": 54, "type": "TASK", "confidence": 0.725081130862236}]}, {"text": "After segmentation, incorrectly split sentences were merged again, e.g. splits after short exclamations (Oh! to be sure) and after quotes (e.g. \"To be sure!\" cried she playfully).", "labels": [], "entities": []}, {"text": "We merged the segmented parts with their preceding or subsequent sentence, based on regular expressions.", "labels": [], "entities": []}, {"text": "We also harmonised punctuation (e.g. in the English version, commas are inside quotes while in the German translation, commas were put outside the quote: \"It is one thing,\" said she vs. \"It is one thing\", said she).", "labels": [], "entities": []}, {"text": "These task-and genrespecific processing steps could be done automatically, without manual effort.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Annotations of quotes, speaker mentions and  entities in the QuoteLi3 corpus (Emma and Pride and  Prejudice).", "labels": [], "entities": [{"text": "QuoteLi3 corpus", "start_pos": 71, "end_pos": 86, "type": "DATASET", "confidence": 0.9256897866725922}]}, {"text": " Table 3: N-gram statistics for mention words (raw fre- quencies) in the corpus.", "labels": [], "entities": []}]}