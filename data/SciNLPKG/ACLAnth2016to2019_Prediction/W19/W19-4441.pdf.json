{"title": [{"text": "Content Modeling for Automated Oral Proficiency Scoring System", "labels": [], "entities": [{"text": "Content Modeling", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.672335296869278}, {"text": "Automated Oral Proficiency Scoring", "start_pos": 21, "end_pos": 55, "type": "TASK", "confidence": 0.6956550478935242}]}], "abstractContent": [{"text": "We developed an automated oral proficiency scoring system for non-native English speak-ers' spontaneous speech.", "labels": [], "entities": []}, {"text": "Automated systems that score holistic proficiency are expected to assess a wide range of performance categories, and the content is one of the core performance categories.", "labels": [], "entities": []}, {"text": "In order to assess the quality of the content, we trained a Siamese convolutional neural network (Siamese CNN) to model the semantic relationship between key points generated by experts and a test response.", "labels": [], "entities": []}, {"text": "The correlation between human scores and Siamese CNN scores was comparable to human-human agreement (r = 0.63), and it was higher than the baseline content features.", "labels": [], "entities": []}, {"text": "The inclusion of Siamese CNN-based feature to the existing state-of-the-art automated scoring model achieved a small but statistically significant improvement.", "labels": [], "entities": []}, {"text": "However, the new model suffered from score inflation for long atypical responses with serious content issues.", "labels": [], "entities": [{"text": "score inflation", "start_pos": 37, "end_pos": 52, "type": "METRIC", "confidence": 0.7718256115913391}]}, {"text": "We investigated the reasons of this score inflation by analyzing the associations with linguistic features and identifying areas strongly associated with the score errors.", "labels": [], "entities": []}], "introductionContent": [{"text": "We developed an automated scoring model for an oral proficiency assessment of non-native English speakers.", "labels": [], "entities": []}, {"text": "In particular, the system was designed to score spontaneous speech, elicited using questions where the test takers summarized the core content of a reading and/or listening passages.", "labels": [], "entities": []}, {"text": "A system for scoring holistic proficiency of spontaneous speech is expected to assess a wide range of areas such as fluency (), pronunciation, prosody, grammar and vocabulary (.", "labels": [], "entities": []}, {"text": "Content is also one of the core performance categories in holistic oral proficiency scoring.", "labels": [], "entities": [{"text": "holistic oral proficiency scoring", "start_pos": 58, "end_pos": 91, "type": "TASK", "confidence": 0.6478985771536827}]}, {"text": "In particular, automated scoring systems without content scoring capabilities may show sub-optimal performance when scoring responses with mismatched proficiency levels between content and other areas.", "labels": [], "entities": []}, {"text": "For instance, some responses have critical content issues but good delivery skills, while some responses have good content but issues in other areas.", "labels": [], "entities": []}, {"text": "Furthermore, in large-scale oral proficiency assessments, some responses may have sub-optimal characteristics.", "labels": [], "entities": []}, {"text": "The types of these problematic responses (hereafter, atypical responses) for the tests eliciting spontaneous speech frequently have severe content issues.", "labels": [], "entities": []}, {"text": "For instance, some test takers may try to game the system by citing memorized responses for unrelated topics (e.g., off-topic responses).", "labels": [], "entities": []}, {"text": "Even state-of-the-art automated scoring systems face challenges in scoring these atypical responses, and automated scoring systems without content scoring capability may assign inaccurate scores for these responses.", "labels": [], "entities": []}, {"text": "To address these issues, more researchers started to actively explore content scoring in the context of oral proficiency scoring (.", "labels": [], "entities": [{"text": "content scoring", "start_pos": 70, "end_pos": 85, "type": "TASK", "confidence": 0.7235931903123856}]}, {"text": "Recently, deep neural networks (DNN) and word embeddings have been applied successfully to various natural language processing tasks.", "labels": [], "entities": []}, {"text": "In the automated scoring area, several researchers have explored the use of diverse neural networks for essay scoring and spontaneous speech scoring,b) and they achieved comparable or superior performance to the sophisticated linguistic feature-based system.", "labels": [], "entities": [{"text": "essay scoring", "start_pos": 104, "end_pos": 117, "type": "TASK", "confidence": 0.812942385673523}, {"text": "spontaneous speech scoring,b", "start_pos": 122, "end_pos": 150, "type": "TASK", "confidence": 0.7098760406176249}]}, {"text": "In particular, trained an automated scoring model covering the content aspect and achieved a further improvement over the generic model without content modeling.", "labels": [], "entities": []}, {"text": "The content relevance of a response is a concept relative to the question, and thus, it is important that the neural network learns the semantic relevance between a question-response pair.", "labels": [], "entities": []}, {"text": "Siamese networks are characterized by shared weights between two subnetworks modeling inputs and are effective in calculating semantic similarity between sentence pairs.", "labels": [], "entities": []}, {"text": "In order to address the strong need for content scoring and based on the promising performance of the Siamese CNN in the semantic relevance modeling, we developed a Siamese CNN-based content model.", "labels": [], "entities": [{"text": "content scoring", "start_pos": 40, "end_pos": 55, "type": "TASK", "confidence": 0.7248976528644562}, {"text": "semantic relevance modeling", "start_pos": 121, "end_pos": 148, "type": "TASK", "confidence": 0.7411149442195892}]}, {"text": "In particular, we make the following two contributions: \u2022 We developed anew feature, based on the Siamese CNN by modeling the semantic distance between the core content and the test takers' responses.", "labels": [], "entities": [{"text": "Siamese CNN", "start_pos": 98, "end_pos": 109, "type": "DATASET", "confidence": 0.8390293717384338}]}, {"text": "The new Siamese CNNbased feature outperformed the baseline content features, and the inclusion of the new feature further improved the performance of a state-of-the-art automated speech scoring model.", "labels": [], "entities": []}, {"text": "\u2022 We examined whether the automated scoring model including the new Siamese CNNbased feature could assign accurate scores for atypical responses.", "labels": [], "entities": []}, {"text": "Differing from previous studies) using synthesized atypical responses in their evaluations, we used authentic atypical responses collected from a large number of test administrations.", "labels": [], "entities": []}], "datasetContent": [{"text": "We generated transcriptions of a spoken response using an ASR system composed of a genderindependent acoustic model and a trigram language model trained on 800 hours of spoken responses extracted from the same English proficiency test using the Kaldi toolkit).", "labels": [], "entities": []}, {"text": "The ASR system achieved a Word Error Rate of 23% on 600 held-out responses (.", "labels": [], "entities": [{"text": "ASR", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9376254081726074}, {"text": "Word Error Rate", "start_pos": 26, "end_pos": 41, "type": "METRIC", "confidence": 0.748787522315979}]}, {"text": "Next, we normalized both key points and ASRbased transcriptions by tokenizing and removing stop words and disfluencies.", "labels": [], "entities": [{"text": "ASRbased transcriptions", "start_pos": 40, "end_pos": 63, "type": "TASK", "confidence": 0.5741318464279175}]}, {"text": "After the normalization process, the length of the key points and responses were reduced to 60% and 40% of the original texts.", "labels": [], "entities": [{"text": "length", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.9671510457992554}]}, {"text": "We trained a Siamese CNN model using the normalized texts of the Train partition and the keypoints.", "labels": [], "entities": []}, {"text": "The model was implemented using Tensorflow ().", "labels": [], "entities": []}, {"text": "The parameters were optimized using the hyperopt software, and the final model used L = 100, d = 300, d1 = 256, w = 4, and the learning rate l = 0.0001.", "labels": [], "entities": [{"text": "learning rate l", "start_pos": 127, "end_pos": 142, "type": "METRIC", "confidence": 0.8982897599538168}]}, {"text": "In addition, the automated scoring system using the same ASR engine generated 38 features.", "labels": [], "entities": []}, {"text": "Finally, we trained linear regression models on the LR Train partition.", "labels": [], "entities": [{"text": "LR Train partition", "start_pos": 52, "end_pos": 70, "type": "DATASET", "confidence": 0.9403951168060303}]}], "tableCaptions": [{"text": " Table 2: Correlations, quadratic weighted kappas (\u03ba),  and root mean squared error (RMSE) between the au- tomated scores and human scores", "labels": [], "entities": [{"text": "root mean squared error (RMSE)", "start_pos": 60, "end_pos": 90, "type": "METRIC", "confidence": 0.8914036921092442}]}, {"text": " Table 3: Comparison of the automated scores for the  atypical responses", "labels": [], "entities": []}, {"text": " Table 4: Correlation of the Siamese CNN score with  the features from the oral proficiency scoring system:  Pearson correlation coefficients in absolute values", "labels": [], "entities": [{"text": "Siamese CNN", "start_pos": 29, "end_pos": 40, "type": "TASK", "confidence": 0.6871746480464935}, {"text": "Pearson correlation", "start_pos": 109, "end_pos": 128, "type": "METRIC", "confidence": 0.9120572507381439}]}]}