{"title": [{"text": "Look Again at the Syntax: Relational Graph Convolutional Network for Gendered Ambiguous Pronoun Resolution", "labels": [], "entities": [{"text": "Gendered Ambiguous Pronoun Resolution", "start_pos": 69, "end_pos": 106, "type": "TASK", "confidence": 0.6478889659047127}]}], "abstractContent": [{"text": "Gender bias has been found in existing coref-erence resolvers.", "labels": [], "entities": [{"text": "coref-erence resolvers", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.7373608946800232}]}, {"text": "In order to eliminate gender bias, a gender-balanced dataset Gendered Ambiguous Pronouns (GAP) has been released and the best baseline model achieves only 66.9% F1.", "labels": [], "entities": [{"text": "F1", "start_pos": 161, "end_pos": 163, "type": "METRIC", "confidence": 0.9995505213737488}]}, {"text": "Bidirectional Encoder Representations from Transformers (BERT) has broken several NLP task records and can be used on GAP dataset.", "labels": [], "entities": [{"text": "Bidirectional Encoder Representations from Transformers (BERT", "start_pos": 0, "end_pos": 61, "type": "TASK", "confidence": 0.6977987970624652}, {"text": "GAP dataset", "start_pos": 118, "end_pos": 129, "type": "DATASET", "confidence": 0.8230710327625275}]}, {"text": "However, fine-tune BERT on a specific task is computationally expensive.", "labels": [], "entities": [{"text": "BERT", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.9863240122795105}]}, {"text": "In this paper, we propose an end-to-end resolver by combining pre-trained BERT with Relational Graph Convolutional Network (R-GCN).", "labels": [], "entities": [{"text": "BERT", "start_pos": 74, "end_pos": 78, "type": "METRIC", "confidence": 0.9918705224990845}]}, {"text": "R-GCN is used for digesting structural syntactic information and learning better task-specific embeddings.", "labels": [], "entities": []}, {"text": "Empirical results demonstrate that, under explicit syntactic supervision and without the need to fine tune BERT, R-GCN's embeddings outperform the original BERT embeddings on the coref-erence task.", "labels": [], "entities": [{"text": "BERT", "start_pos": 107, "end_pos": 111, "type": "METRIC", "confidence": 0.9787217974662781}]}, {"text": "Our work significantly improves the snippet-context baseline F1 score on GAP dataset from 66.9% to 80.3%.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.8981977105140686}, {"text": "GAP dataset", "start_pos": 73, "end_pos": 84, "type": "DATASET", "confidence": 0.8238518536090851}]}], "introductionContent": [{"text": "Coreference resolution aims to find the linguistic mentions that refer to the same real-world entity in natural language ().", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8975467681884766}]}, {"text": "Ambiguous gendered pronoun resolution is a subtask of coreference resolution, where we try to resolve gendered ambiguous pronouns in English such as \"he\" and \"she\".", "labels": [], "entities": [{"text": "Ambiguous gendered pronoun resolution", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.5925692766904831}, {"text": "coreference resolution", "start_pos": 54, "end_pos": 76, "type": "TASK", "confidence": 0.9569815695285797}]}, {"text": "This is an important task for natural language understanding and a longstanding challenge.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 30, "end_pos": 60, "type": "TASK", "confidence": 0.6578154762585958}]}, {"text": "According to, there are two main approaches: heuristics-based approaches and learning-based approaches, such as mention-pair models, mention-ranking models, and clustering models).", "labels": [], "entities": []}, {"text": "Learning-based approaches, especially deep-learning-based methods, have shown significant improvement over heuristics-based approaches.", "labels": [], "entities": []}, {"text": "However, most state-of-art deep-learning-based resolvers utilize one-directional Transformers (, limiting the ability to handle long-range inferences and the use of cataphors.", "labels": [], "entities": []}, {"text": "Bidirectional Encoder Representations from Transformers, or BERT () learns a bidirectional contextual embedding and has the potential to overcome these problems using both the previous and next context.", "labels": [], "entities": [{"text": "Bidirectional Encoder Representations", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.6479046642780304}, {"text": "BERT", "start_pos": 60, "end_pos": 64, "type": "METRIC", "confidence": 0.9823957085609436}]}, {"text": "However, fine-tuning BERT fora specific task is computationally expensive and time-consuming.", "labels": [], "entities": [{"text": "BERT", "start_pos": 21, "end_pos": 25, "type": "METRIC", "confidence": 0.9639335870742798}]}, {"text": "Syntax information has always been a strong tool for semantic tasks.", "labels": [], "entities": []}, {"text": "Most heuristics-based methods use syntax-based rules).", "labels": [], "entities": []}, {"text": "Many of learning based models also rely on syntactic parsing for mention or entity extraction algorithms and compute hand-crafted features as input.", "labels": [], "entities": [{"text": "mention or entity extraction", "start_pos": 65, "end_pos": 93, "type": "TASK", "confidence": 0.6598307862877846}]}, {"text": "Can we learn better word embeddings than BERT on the coreference task with the help of syntactic information and without computationally expensive fine-tuning of BERT?", "labels": [], "entities": [{"text": "BERT", "start_pos": 41, "end_pos": 45, "type": "METRIC", "confidence": 0.9818529486656189}, {"text": "BERT", "start_pos": 162, "end_pos": 166, "type": "METRIC", "confidence": 0.9792160391807556}]}, {"text": "Marcheggiani and successfully use Graph Convolutional Networks (GCNs)) to learn word embeddings for the semantic role labeling task and outperform the original LSTM contextual embeddings.", "labels": [], "entities": [{"text": "semantic role labeling task", "start_pos": 104, "end_pos": 131, "type": "TASK", "confidence": 0.717233806848526}]}, {"text": "Inspired by, we create a 'Look-again' mechanism which combines BERT with Gated Relational Graph Convolutional Networks (R-GCN) by using BERT embeddings as initial hidden states of vertices in R-GCN.", "labels": [], "entities": [{"text": "BERT", "start_pos": 63, "end_pos": 67, "type": "METRIC", "confidence": 0.983721137046814}]}, {"text": "R-GCN's structure is derived from a sentence's syntactic dependencies graph.", "labels": [], "entities": []}, {"text": "This architecture allows contextual embeddings to be further learned and encoded into better task-specific embeddings without fine tuning BERT which is computationally expensive.", "labels": [], "entities": [{"text": "BERT", "start_pos": 138, "end_pos": 142, "type": "METRIC", "confidence": 0.9975618124008179}]}], "datasetContent": [{"text": "In the experiment, it shows that, with the explicit syntactic supervision by syntactic structure, Gated R-GCN structure can learn better embeddings that improve performance on the coreference resolution task.", "labels": [], "entities": [{"text": "coreference resolution task", "start_pos": 180, "end_pos": 207, "type": "TASK", "confidence": 0.9407488703727722}]}, {"text": "Two sets of experiments were designed and conducted: Stage one experiments and Full GAP experiments.", "labels": [], "entities": [{"text": "Full GAP", "start_pos": 79, "end_pos": 87, "type": "TASK", "confidence": 0.4603646397590637}]}, {"text": "Stage one experiments used the same setting as stage one of shared-task competition, where we had 4454 data samples in total.", "labels": [], "entities": []}, {"text": "'Gapvalidation.tsv' and 'gap-test.tsv' were used as training dataset, while 'gap-development.tsv' was used for testing.", "labels": [], "entities": []}, {"text": "Full GAP experiments used full 8908 samples of Gendered Ambiguous Pronouns (GAP) dataset in order to compare with the baseline result from the GAP paper).", "labels": [], "entities": []}, {"text": "The dataset provided by the shared task is Google AI Language's Gendered Ambiguous Pronouns (GAP) dataset, which is a gender-balanced dataset containing 8,908 coreference-labeled pairs of (ambiguous pronoun, antecedent name), sampled from Wikipedia.", "labels": [], "entities": [{"text": "Google AI Language's Gendered Ambiguous Pronouns (GAP) dataset", "start_pos": 43, "end_pos": 105, "type": "DATASET", "confidence": 0.6504120962186293}]}, {"text": "In stage one of the shared task, only 2454 samples were used as the training dataset, and 2000 samples were used as the test dataset.", "labels": [], "entities": []}, {"text": "There are 4 different settings for Stage One experiments for comparisons (see): 1.", "labels": [], "entities": []}, {"text": "Only BERT embeddings are fed into an additional MLP for prediction.", "labels": [], "entities": [{"text": "BERT", "start_pos": 5, "end_pos": 9, "type": "METRIC", "confidence": 0.9787806272506714}]}, {"text": "2. Connect BERT with Gated R-GCN, but only feed Gated R-GCN's hidden states into MLP for prediction.", "labels": [], "entities": [{"text": "BERT", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.9817086458206177}]}, {"text": "3. Connect BERT with R-GCN, and the concatenation is fed into MLP for prediction.", "labels": [], "entities": [{"text": "BERT", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.997017502784729}]}, {"text": "The gate mechanism is not applied to R-GCN 4.", "labels": [], "entities": []}, {"text": "Connect BERT with Gated R-GCN, and the concatenation is fed into MLP for prediction.", "labels": [], "entities": [{"text": "BERT", "start_pos": 8, "end_pos": 12, "type": "METRIC", "confidence": 0.9945418238639832}]}, {"text": "The gate mechanism is applied.", "labels": [], "entities": []}, {"text": "The competition used multi-class log-loss as evaluation metrics.", "labels": [], "entities": []}, {"text": "where N is the number of samples in the test set, M is 3, log is the natural logarithm.", "labels": [], "entities": []}, {"text": "By comparing setting two and setting four, we can see that because graph convolution of the R-GCN model brings the potential problem of oversmoothing the information (, model without concatenation might lose some performance.", "labels": [], "entities": []}, {"text": "We also tested our model on the full GAP dataset which contains 8,908 samples.", "labels": [], "entities": [{"text": "GAP dataset", "start_pos": 37, "end_pos": 48, "type": "DATASET", "confidence": 0.8237220942974091}]}, {"text": "4908 samples were used as training data, and 4000 samples were used as test data.", "labels": [], "entities": []}, {"text": "We used micro F1 score as our metric.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9721750915050507}]}, {"text": "The GAP paper) introduced several baseline methods: (1) Off-the-shelf resolvers including a rule-based system of and three neural resolvers from,, and; (2) Baselines based on traditional cues for coreference; (3)Baselines based on structural cues: syntactic distance and Parallelism; (4) Baselines based on Wikipedia cues; (5) Transformer models (.", "labels": [], "entities": [{"text": "GAP paper", "start_pos": 4, "end_pos": 13, "type": "DATASET", "confidence": 0.8168560266494751}]}, {"text": "Three best models (, Parallelism, and Parallelism+URL) from above baselines were chosen for comparison.", "labels": [], "entities": []}, {"text": "We first used pre-trained BERT embeddings and fullyconnected layers for prediction (see).", "labels": [], "entities": [{"text": "BERT", "start_pos": 26, "end_pos": 30, "type": "METRIC", "confidence": 0.9338866472244263}, {"text": "prediction", "start_pos": 72, "end_pos": 82, "type": "TASK", "confidence": 0.9649725556373596}]}, {"text": "Not surprising, BERT embeddings outperformed all of the previous work.", "labels": [], "entities": [{"text": "BERT", "start_pos": 16, "end_pos": 20, "type": "METRIC", "confidence": 0.9917518496513367}]}], "tableCaptions": [{"text": " Table 2: GAP experiments results", "labels": [], "entities": [{"text": "GAP", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.8544454574584961}]}]}