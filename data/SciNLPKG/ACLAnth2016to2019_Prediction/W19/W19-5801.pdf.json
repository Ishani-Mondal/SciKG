{"title": [{"text": "LIAAD at SemDeep-5 Challenge: Word-in-Context (WiC)", "labels": [], "entities": [{"text": "LIAAD", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9519044756889343}]}], "abstractContent": [{"text": "This paper describes the LIAAD system that was ranked second place in the Word-in-Context challenge (WiC) featured in SemDeep-5.", "labels": [], "entities": [{"text": "Word-in-Context challenge (WiC)", "start_pos": 74, "end_pos": 105, "type": "TASK", "confidence": 0.4480643332004547}]}, {"text": "Our solution is based on a novel system for Word Sense Disambiguation (WSD) using contextual embeddings and full-inventory sense embeddings.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 44, "end_pos": 75, "type": "TASK", "confidence": 0.7590858638286591}]}, {"text": "We adapt this WSD system, in a straightforward manner , for the present task of detecting whether the same sense occurs in a pair of sentences.", "labels": [], "entities": [{"text": "WSD", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.8584597706794739}, {"text": "detecting whether the same sense occurs in a pair of sentences", "start_pos": 80, "end_pos": 142, "type": "TASK", "confidence": 0.7291190190748735}]}, {"text": "Additionally, we show that our solution is able to achieve competitive performance even without using the provided training or development sets, mitigating potential concerns related to task overfitting.", "labels": [], "entities": []}, {"text": "1 Task Overview The Word-in-Context (WiC) (Pilehvar and Camacho-Collados, 2019) task aims to evaluate the ability of word embedding models to accurately represent context-sensitive words.", "labels": [], "entities": [{"text": "Word-in-Context (WiC) (Pilehvar and Camacho-Collados, 2019) task", "start_pos": 20, "end_pos": 84, "type": "TASK", "confidence": 0.5722343226273855}]}, {"text": "In particular, it focuses on polysemous words which have been hard to represent as embeddings due to the meaning conflation deficiency (Camacho-Collados and Pilehvar, 2018).", "labels": [], "entities": []}, {"text": "The task's objective is to detect if target words occurring in a pair of sentences carry the same meaning.", "labels": [], "entities": []}, {"text": "Recently, contextual word embeddings from ELMo (Peters et al., 2018) or BERT (Devlin et al., 2019) have emerged as the successors to traditional embeddings.", "labels": [], "entities": [{"text": "BERT", "start_pos": 72, "end_pos": 76, "type": "METRIC", "confidence": 0.9875208139419556}]}, {"text": "With this development, word embeddings have become context-sensitive by design and thus more suitable for representing poly-semous words.", "labels": [], "entities": []}, {"text": "However, as shown by the experiments of (Pilehvar and Camacho-Collados, 2019), they are still insufficient by themselves to reliably detect meaning shifts.", "labels": [], "entities": []}, {"text": "In this work, we propose a system designed for the larger task of Word Sense Disambigua-tion (WSD), where words are matched with specific senses, that can detect meaning shifts without being trained explicitly to do so.", "labels": [], "entities": [{"text": "Word Sense Disambigua-tion (WSD)", "start_pos": 66, "end_pos": 98, "type": "TASK", "confidence": 0.7377778689066569}]}, {"text": "Our WSD system uses contextual word embeddings to produce sense embeddings, and has full-coverage of all senses present in WordNet 3.0 (Fellbaum, 1998).", "labels": [], "entities": [{"text": "WordNet 3.0 (Fellbaum, 1998)", "start_pos": 123, "end_pos": 151, "type": "DATASET", "confidence": 0.8371759908539909}]}, {"text": "In Loureiro and Jorge (2019) we provide more details about this WSD system, called LMMS (Language Modelling Makes Sense), and demonstrate that it's currently state-of-the-art for WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 179, "end_pos": 182, "type": "TASK", "confidence": 0.9245760440826416}]}, {"text": "For this challenge, we employ LMMS in two straightforward approaches: checking if the dis-ambiguated senses are equal, and training a clas-sifier based on the embedding similarities.", "labels": [], "entities": []}, {"text": "Both approaches perform competitively, with the latter taking the second position in the challenge ranking, and the former trailing close behind even though it's tested directly on the challenge, forgo-ing the training and development sets.", "labels": [], "entities": []}, {"text": "2 System Description LMMS has two useful properties: 1) uses con-textual word embeddings to produce sense em-beddings, and 2) covers a large set of over 117K senses from WordNet 3.0.", "labels": [], "entities": [{"text": "2 System Description LMMS", "start_pos": 0, "end_pos": 25, "type": "DATASET", "confidence": 0.6584883779287338}]}, {"text": "The first property allows for comparing precomputed sense embed-dings against contextual word embeddings generated at test-time (using the same language model).", "labels": [], "entities": []}, {"text": "The second property makes the comparisons more meaningful by having a large selection of senses at disposal for comparison.", "labels": [], "entities": []}, {"text": "2.1 Sense Embeddings Given the meaning conflation deficiency issue with traditional word embeddings, several works have focused on adapting Neural Language Models (NLMs) to produce word embeddings that are more sense-specific.", "labels": [], "entities": []}, {"text": "In this work, we start producing sense embeddings from the approach used by recent works in contextual word embeddings, particularly context2vec (Melamud et al., 2016) and", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Challenge results at the end of the evaluation  period. Bottom results correspond to baselines.", "labels": [], "entities": []}, {"text": " Table 2: Accuracy of our different models. M0 wasn't  trained on WiC data, the other models were trained  on different sets of similarites. We submitted M3, but  achieved slightly improved results with M4.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9910592436790466}]}]}