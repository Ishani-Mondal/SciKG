{"title": [{"text": "Discriminating between Mandarin Chinese and Swiss-German varieties using adaptive language models", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes the language identification systems used by the SUKI team in the Discriminating between the Mainland and Taiwan variation of Mandarin Chinese (DMT) and the German Dialect Identification (GDI) shared tasks which were held as part of the third Var-Dial Evaluation Campaign.", "labels": [], "entities": [{"text": "language identification", "start_pos": 25, "end_pos": 48, "type": "TASK", "confidence": 0.7133383750915527}, {"text": "Discriminating between the Mainland and Taiwan variation of Mandarin Chinese (DMT)", "start_pos": 86, "end_pos": 168, "type": "TASK", "confidence": 0.6288981552307422}, {"text": "German Dialect Identification (GDI) shared tasks", "start_pos": 177, "end_pos": 225, "type": "TASK", "confidence": 0.7229361720383167}]}, {"text": "The DMT shared task included two separate tracks, one for the simplified Chinese script and one for the traditional Chinese script.", "labels": [], "entities": []}, {"text": "We submitted three runs on both tracks of the DMT task as well as on the GDI task.", "labels": [], "entities": [{"text": "DMT task", "start_pos": 46, "end_pos": 54, "type": "TASK", "confidence": 0.6423635482788086}]}, {"text": "We won the traditional Chinese track using Naive Bayes with language model adaptation, came second on GDI with an adap-tive version of the HeLI 2.0 method, and third on the simplified Chinese track using again the adaptive Naive Bayes.", "labels": [], "entities": []}], "introductionContent": [{"text": "The third VarDial Evaluation Campaign () included three shared tasks on language, dialect, and language variety identification.", "labels": [], "entities": [{"text": "language, dialect, and language variety identification", "start_pos": 72, "end_pos": 126, "type": "TASK", "confidence": 0.5875203311443329}]}, {"text": "The Discriminating between Mainland and Taiwan variation of Mandarin Chinese (DMT) concentrated on finding differences between the varieties of Mandarin Chinese written on mainland China and Taiwan.", "labels": [], "entities": [{"text": "Discriminating between Mainland and Taiwan variation of Mandarin Chinese (DMT)", "start_pos": 4, "end_pos": 82, "type": "TASK", "confidence": 0.49498820304870605}]}, {"text": "The task included two tracks, one for the simplified script and another for the traditional one.", "labels": [], "entities": []}, {"text": "The German Dialect Identification (GDI) task was already the third of its kind (.", "labels": [], "entities": [{"text": "German Dialect Identification (GDI) task", "start_pos": 4, "end_pos": 44, "type": "TASK", "confidence": 0.7853904494217464}]}, {"text": "In GDI 2019, the task was to distinguish between four SwissGerman dialects.", "labels": [], "entities": [{"text": "SwissGerman dialects", "start_pos": 54, "end_pos": 74, "type": "DATASET", "confidence": 0.9714939296245575}]}, {"text": "The third task was that of Cuneiform Language Identification (CLI), but we did not participate in that as we were partly responsible for creating its dataset ().", "labels": [], "entities": [{"text": "Cuneiform Language Identification (CLI)", "start_pos": 27, "end_pos": 66, "type": "TASK", "confidence": 0.7634838173786799}]}, {"text": "We evaluated several language identification methods using the development sets of the DMT and GDI tasks.", "labels": [], "entities": [{"text": "language identification", "start_pos": 21, "end_pos": 44, "type": "TASK", "confidence": 0.7244427651166916}, {"text": "DMT", "start_pos": 87, "end_pos": 90, "type": "DATASET", "confidence": 0.785333514213562}]}, {"text": "Our best submissions were created using a similar language model (LM) adaptation technique to the one we used in the second VarDial Evaluation Campaign (.", "labels": [], "entities": [{"text": "VarDial Evaluation Campaign", "start_pos": 124, "end_pos": 151, "type": "DATASET", "confidence": 0.7968299190203348}]}, {"text": "In that Evaluation Campaign, we used the HeLI language identification method) together with anew LM adaptation approach, winning the Indo-Aryan Language Identification (ILI) and the GDI 2018 shared tasks with a wide margin (.", "labels": [], "entities": [{"text": "HeLI language identification", "start_pos": 41, "end_pos": 69, "type": "TASK", "confidence": 0.6183085640271505}, {"text": "Indo-Aryan Language Identification (ILI)", "start_pos": 133, "end_pos": 173, "type": "TASK", "confidence": 0.710094670454661}, {"text": "GDI 2018 shared", "start_pos": 182, "end_pos": 197, "type": "DATASET", "confidence": 0.7773236632347107}]}, {"text": "After the second Evaluation Campaign, we had developed anew version of the HeLI method and further refined the LM adaptation technique).", "labels": [], "entities": [{"text": "HeLI", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.5945659279823303}, {"text": "LM adaptation", "start_pos": 111, "end_pos": 124, "type": "TASK", "confidence": 0.8719225823879242}]}, {"text": "With the HeLI 2.0 method and the refined adaptation technique, we came second in the GDI 2019 shared task using only character 4-grams as features.", "labels": [], "entities": [{"text": "GDI 2019 shared task", "start_pos": 85, "end_pos": 105, "type": "TASK", "confidence": 0.5505494773387909}]}, {"text": "Furthermore, we had implemented several baseline language identifiers for the CLI shared task).", "labels": [], "entities": []}, {"text": "One of them was a Naive Bayes (NB) identifier using variable length character n-grams, which fared better than the HeLI method on the CLI dataset.", "labels": [], "entities": [{"text": "CLI dataset", "start_pos": 134, "end_pos": 145, "type": "DATASET", "confidence": 0.8867190778255463}]}, {"text": "We modified our LM adaptation technique to be used with the NB classifier and this fared better than the adaptive HeLI 2.0 method on both of the Chinese datasets.", "labels": [], "entities": [{"text": "LM adaptation", "start_pos": 16, "end_pos": 29, "type": "TASK", "confidence": 0.872167319059372}, {"text": "Chinese datasets", "start_pos": 145, "end_pos": 161, "type": "DATASET", "confidence": 0.8289968967437744}]}, {"text": "With the adaptive NB identifier, we won the traditional Chinese track and came third on the simplified one.", "labels": [], "entities": []}, {"text": "In this paper, we first go through some related work in Section 2, after which we introduce the datasets and the evaluation setup used in the DMT and the GDI shared tasks (Section 3).", "labels": [], "entities": [{"text": "DMT", "start_pos": 142, "end_pos": 145, "type": "DATASET", "confidence": 0.729917585849762}]}, {"text": "We then use the training and the development sets to evaluate our baseline methods (Sections 4.1 and 4.2) and the HeLI 2.0 method (Section 4.3), after which we evaluate the efficiency of our LM adaptation procedure with the HeLI 2.0 and NB methods in Sections 4.4 and 4.5.", "labels": [], "entities": [{"text": "LM adaptation", "start_pos": 191, "end_pos": 204, "type": "TASK", "confidence": 0.9370589852333069}]}, {"text": "Finally we introduce and discuss the results of our official submissions (Section 5) as well as give some conclusions and ideas for future work (Section 6).", "labels": [], "entities": []}], "datasetContent": [{"text": "The scripts commonly used in mainland China and Taiwan are different.", "labels": [], "entities": []}, {"text": "In Taiwan, the traditional Chinese script is commonly used whereas in mainland China, the simplified version is the official one).", "labels": [], "entities": []}, {"text": "In order to be able to concentrate on the non-scriptual differences of the two varieties of Mandarin Chinese, Putonghua (Mainland China) and Guoyo (Taiwan), the texts used for the DMT task had been transformed to use the same script.", "labels": [], "entities": [{"text": "DMT task", "start_pos": 180, "end_pos": 188, "type": "TASK", "confidence": 0.9020344018936157}]}, {"text": "In the simplified track, the Taiwanese texts originally written in the traditional script had been converted into the simplified script and in the traditional track the texts from mainland China originally in the simplified script had been converted to the traditional script.", "labels": [], "entities": []}, {"text": "The conversion had been made using a tool called \"OpenCC\".", "labels": [], "entities": []}, {"text": "The texts used as the source for the datasets were news articles from mainland China and from Taiwan.", "labels": [], "entities": []}, {"text": "The participants were provided with training and development sets for both simplified and traditional scripts.", "labels": [], "entities": []}, {"text": "Both datasets had been tokenized by inserting whitespace characters between individual words.", "labels": [], "entities": []}, {"text": "Furthermore, all punctuation had been removed.", "labels": [], "entities": []}, {"text": "The average length of words in all DMT training sets was c.", "labels": [], "entities": [{"text": "DMT training", "start_pos": 35, "end_pos": 47, "type": "TASK", "confidence": 0.7544620335102081}]}, {"text": "The training sets contained 9,385 sentences and the development sets consisted of additional 1,000 sentences for each variety.", "labels": [], "entities": []}, {"text": "The test sets had 1,000 sentences as well for each variety.", "labels": [], "entities": []}, {"text": "The GDI dataset consisted of transcribed speech utterances in four Swiss German dialects.", "labels": [], "entities": [{"text": "GDI dataset", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.8298466801643372}]}, {"text": "More detailed information about the source of the texts for the GDI datasets, the ArchiMob corpus, are provided by Samard\u017ei\u00b4.", "labels": [], "entities": [{"text": "GDI datasets", "start_pos": 64, "end_pos": 76, "type": "DATASET", "confidence": 0.8626694977283478}, {"text": "ArchiMob corpus", "start_pos": 82, "end_pos": 97, "type": "DATASET", "confidence": 0.8829924464225769}]}, {"text": "In 2018, the GDI dataset included additional unknown dialects, which were left out in 2019.", "labels": [], "entities": [{"text": "GDI dataset", "start_pos": 13, "end_pos": 24, "type": "DATASET", "confidence": 0.9178310930728912}]}, {"text": "The sizes of the training and the development sets can be seen in Table 1.", "labels": [], "entities": []}, {"text": "The average length of words in the training set was 5.5 characters.", "labels": [], "entities": []}, {"text": "The test set contained 4,743 utterances comprising 42,699 words.", "labels": [], "entities": []}, {"text": "As of this writing, we are not aware of the distribution of the dialects in the test set.", "labels": [], "entities": []}, {"text": "The training, development, and test sets included two files in addition to the speech transcriptions.", "labels": [], "entities": []}, {"text": "The first file included normalized forms for each dialectal form in the data.", "labels": [], "entities": []}, {"text": "The second file included 400-dimensional iVectors representing the acoustic features of the original speech data, as the text data was transliterated speech.", "labels": [], "entities": []}, {"text": "We did not use either of the two additional files in our experiments.", "labels": [], "entities": []}, {"text": "We set out to tackle the GDI and the DMT shared tasks with the system based on the HeLI 2.0 method and LM adaptation that we had used for the and ILI datasets between the 2018 and 2019 VarDial Evaluation Campaigns (Jauhiainen et al., 2019b).", "labels": [], "entities": [{"text": "ILI datasets between the 2018 and 2019 VarDial Evaluation Campaigns", "start_pos": 146, "end_pos": 213, "type": "DATASET", "confidence": 0.7077901422977447}]}, {"text": "For the CLI shared task, we had implemented three new baseline identifiers, one of which, a Naive Bayes identifier, managed to overcome the traditional HeLI method when distinguishing between Sumerian and six Akkadian dialects).", "labels": [], "entities": []}, {"text": "We were, hence, also interested to see how well these baseline identifiers would perform in the DMT and GDI tasks.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: List of the Swiss German varieties used in the  datasets distributed for the 2019 GDI shared task. The  sizes are in words.", "labels": [], "entities": [{"text": "Swiss German varieties", "start_pos": 22, "end_pos": 44, "type": "DATASET", "confidence": 0.8766023317972819}, {"text": "GDI shared task", "start_pos": 92, "end_pos": 107, "type": "TASK", "confidence": 0.5344596207141876}]}, {"text": " Table 2: Simplified Chinese. The macro F1-scores attained by different methods on the development set. A max  in column indicating the number of splits means that k was equal to the number of lines in the evaluation data.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.7202740907669067}]}, {"text": " Table 3: Traditional Chinese. The macro F1-scores attained by different methods on the development set. A max  in column indicating the number of splits means that k was equal to the number of lines in the evaluation data.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.6481618285179138}]}, {"text": " Table 4: GDI 2019. The macro F1-scores attained by different methods on the development set. A max in column  indicating the number of splits means that k was equal to the number of lines in the evaluation data.", "labels": [], "entities": [{"text": "GDI 2019", "start_pos": 10, "end_pos": 18, "type": "DATASET", "confidence": 0.8269112706184387}, {"text": "F1-scores", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.7060257196426392}]}, {"text": " Table 5: Simplified Chinese. The macro F1-scores attained by submitted methods on the test set. The results of  our submissions are bolded.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.7826955914497375}]}, {"text": " Table 6: Traditional Chinese. The macro F1-scores attained by different methods on the test set. The results of  our submissions are bolded.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.7116159200668335}]}, {"text": " Table 7: GDI 2019. The macro F1-scores attained by different methods on the test set. The results of our  submissions are bolded.", "labels": [], "entities": [{"text": "GDI 2019", "start_pos": 10, "end_pos": 18, "type": "DATASET", "confidence": 0.8308246433734894}, {"text": "F1-scores", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.8262578845024109}]}]}