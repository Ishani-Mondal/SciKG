{"title": [{"text": "Translator2Vec: Understanding and Representing Human Post-Editors", "labels": [], "entities": []}], "abstractContent": [{"text": "The combination of machines and humans for translation is effective, with many studies showing productivity gains when humans post-edit machine-translated output instead of translating from scratch.", "labels": [], "entities": [{"text": "translation", "start_pos": 43, "end_pos": 54, "type": "TASK", "confidence": 0.9738962650299072}]}, {"text": "To take full advantage of this combination, we need a fine-grained understanding of how human translators work, and which post-editing styles are more effective than others.", "labels": [], "entities": []}, {"text": "In this paper, we release and analyze anew dataset with document-level post-editing action sequences, including edit operations from keystrokes, mouse actions , and waiting times.", "labels": [], "entities": []}, {"text": "Our dataset comprises 66,268 full document sessions post-edited by 332 humans, the largest of the kind released to date.", "labels": [], "entities": []}, {"text": "We show that action sequences are informative enough to identify post-editors accurately, compared to baselines that only look at the initial and final text.", "labels": [], "entities": []}, {"text": "We build on this to learn and visualize continuous representations of post-editors, and we show that these representations improve the downstream task of predicting post-editing time.", "labels": [], "entities": [{"text": "predicting post-editing", "start_pos": 154, "end_pos": 177, "type": "TASK", "confidence": 0.8726834058761597}]}], "introductionContent": [{"text": "Computer-aided translation platforms for interactive translation and post-editing are now commonly used in professional translation services (.", "labels": [], "entities": [{"text": "interactive translation", "start_pos": 41, "end_pos": 64, "type": "TASK", "confidence": 0.689062625169754}]}, {"text": "With the increasing quality of machine translation (Bahdanau et al.,, the translation industry is going through a transformation, progressively shifting gears from \"computer-aided\" (where MT is used as an instrument to help professional translators) towards human-aided translation, where there is a human in the loop who only intervenes when needed to ensure final quality, and whose productivity is to be optimized.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.7368529438972473}, {"text": "human-aided translation", "start_pos": 258, "end_pos": 281, "type": "TASK", "confidence": 0.6826932430267334}]}, {"text": "A deep, data-driven understanding of the human post-editing process is key to achieve the best trade-offs in translation efficiency and quality.", "labels": [], "entities": [{"text": "translation", "start_pos": 109, "end_pos": 120, "type": "TASK", "confidence": 0.9611963033676147}]}, {"text": "What makes a \"good\" post-editor?", "labels": [], "entities": []}, {"text": "What kind of behaviour shall an interface promote?", "labels": [], "entities": []}, {"text": "There is a string of prior work that relates the difficulty of translating text with the cognitive load of human translators and post-editors, based on indicators such as editing times, pauses, keystroke logs, and eye tracking, see also \u00a76).", "labels": [], "entities": []}, {"text": "Most of these studies, however, have been performed in controlled environments on a very small scale, with a limited number of professional translators and only a few sessions.", "labels": [], "entities": []}, {"text": "A direct use of human activity data for understanding and representing human post-editors, towards improving their productivity, is still missing, arguably due to the lack of large-scale data.", "labels": [], "entities": []}, {"text": "Understanding how human post-editors work could open the door to the design of better interfaces, smarter allocation of human translators to content, and automatic post-editing.", "labels": [], "entities": []}, {"text": "In this paper, we study the behaviour of human post-editors \"in the wild\" by automatically examining tens of thousands of post-editing sessions at a document level.", "labels": [], "entities": []}, {"text": "We show that these detailed editor activities (which we call action sequences, \u00a72) encode useful additional information besides just the initial machine-translated text and the final post-edited text.", "labels": [], "entities": []}, {"text": "This is aligned to recent findings in other domains: and have recently shown that Wikipedia page edits can represent interesting linguistic phenomena in language modeling and discourse.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 153, "end_pos": 170, "type": "TASK", "confidence": 0.7365580797195435}]}, {"text": "While prior work analyzed the cognitive behaviour of post-editors and their productivity by collecting a few statistics, we take a step forward in this paper, using state-of-the-art machine learning techniques to represent editors in a vector space ( \u00a74).", "labels": [], "entities": []}, {"text": "These representations are obtained by training a model to identify the editor based on his action sequences ( \u00a73).", "labels": [], "entities": []}, {"text": "This model achieves high accuracy in predicting the editor's identity, and the learned representations exhibit interesting correlations with the editors' behaviour and their productivity, being effective when plugged as features for predicting the post-editing time ( \u00a75).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9966230392456055}]}, {"text": "Overall, we use our action sequence dataset to address the following research questions: 1.", "labels": [], "entities": []}, {"text": "Editor identification ( \u00a73): are the posteditors' activities (their action sequences) informative enough to allow discriminating their identities from one another (compared to just using the initial machine-translated text and the final post-edited one)?", "labels": [], "entities": [{"text": "Editor identification", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7197937071323395}]}, {"text": "2. Editor representation ( \u00a74): can the posteditors' activities be used to learn meaningful vector representations, such that similar editors are clustered together?", "labels": [], "entities": []}, {"text": "Can we interpret these embeddings to understand which activity patterns characterize \"good\" editors (in terms of translation quality and speed)?", "labels": [], "entities": []}, {"text": "3. Downstream tasks ( \u00a75): do the learned editor vector representations provide useful information for downstream tasks, such as predicting the time to translate a document, compared to pure text-based approaches that do not use them?", "labels": [], "entities": [{"text": "predicting the time to translate a document", "start_pos": 129, "end_pos": 172, "type": "TASK", "confidence": 0.7884566017559597}]}, {"text": "We base our study on editor-labeled action sequences for two language pairs, English-French and English-German, which we make available for future research.", "labels": [], "entities": []}, {"text": "In both cases, we obtain positive answers to the three questions above.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Number of documents, sentences, and words in En- glish source text per dataset. There are 149 unique editors  across all En-Fr datasets, and 183 in En-De.", "labels": [], "entities": [{"text": "En-Fr datasets", "start_pos": 131, "end_pos": 145, "type": "DATASET", "confidence": 0.8710051774978638}]}, {"text": " Table 4: Results of model and baselines for editor identifica- tion. Reported are average test set accuracies of 5 runs, with  7 editors for En-De and 6 editors for En-Fr.", "labels": [], "entities": [{"text": "En-De", "start_pos": 142, "end_pos": 147, "type": "DATASET", "confidence": 0.9506509900093079}]}, {"text": " Table 5: Ablations studies for editor identification. Reported  are average development set accuracies of 5 runs, with 7 edi- tors for En-De and 6 editors for En-Fr.", "labels": [], "entities": [{"text": "Ablations", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.958350419998169}, {"text": "editor identification", "start_pos": 32, "end_pos": 53, "type": "TASK", "confidence": 0.7587197422981262}, {"text": "En-De", "start_pos": 136, "end_pos": 141, "type": "DATASET", "confidence": 0.9288697838783264}]}, {"text": " Table 7: Pearson correlation between real and predicted log- arithm of time per word in source text.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.9372329711914062}, {"text": "predicted log- arithm of time", "start_pos": 47, "end_pos": 76, "type": "METRIC", "confidence": 0.6936961313088735}]}]}