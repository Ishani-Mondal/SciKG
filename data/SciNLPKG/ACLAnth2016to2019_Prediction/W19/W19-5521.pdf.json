{"title": [{"text": "PolyU CBS-CFA at the FinSBD task: Sentence Boundary Detection of Financial Data with Domain Knowledge Enhancement and Bilingual Training", "labels": [], "entities": [{"text": "PolyU CBS-CFA", "start_pos": 0, "end_pos": 13, "type": "DATASET", "confidence": 0.8963781297206879}, {"text": "FinSBD", "start_pos": 21, "end_pos": 27, "type": "DATASET", "confidence": 0.9393734931945801}, {"text": "Sentence Boundary Detection of Financial Data", "start_pos": 34, "end_pos": 79, "type": "TASK", "confidence": 0.9195848405361176}]}], "abstractContent": [{"text": "Sentence Boundary Detection is a basic requirement in Natural Language Processing and remains a challenge to language processing for specific purposes especially with noisy source documents.", "labels": [], "entities": [{"text": "Sentence Boundary Detection", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8985368013381958}]}, {"text": "In this paper, we deal with the processing of scanned financial prospectuses with a feature-oriented and knowledge-enriched approach.", "labels": [], "entities": [{"text": "processing of scanned financial prospectuses", "start_pos": 32, "end_pos": 76, "type": "TASK", "confidence": 0.8012122988700867}]}, {"text": "Feature engineering and knowledge enrichment are conducted with the participation of domain experts and for the detection of sentence boundaries in both English and French.", "labels": [], "entities": [{"text": "Feature engineering", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7707532048225403}, {"text": "knowledge enrichment", "start_pos": 24, "end_pos": 44, "type": "TASK", "confidence": 0.7016607373952866}]}, {"text": "Two versions of the detection system are implemented with a Random Forest Classifier and a Neural Network.", "labels": [], "entities": []}, {"text": "We engineer a fused feature set of punctuation, digital number, capitalization, acronym, letter and POS tag for model fitting.", "labels": [], "entities": [{"text": "POS", "start_pos": 100, "end_pos": 103, "type": "METRIC", "confidence": 0.891681432723999}, {"text": "model fitting", "start_pos": 112, "end_pos": 125, "type": "TASK", "confidence": 0.6443301886320114}]}, {"text": "For knowledge enhancement , we implement a rule-based validation by extracting a keyword dictionary from the out-of-vocabulary sequences in FinSBD's datasets.", "labels": [], "entities": [{"text": "knowledge enhancement", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.8076779842376709}, {"text": "FinSBD's datasets", "start_pos": 140, "end_pos": 157, "type": "DATASET", "confidence": 0.9297469854354858}]}, {"text": "Bilingual training on both English and French training sets are conducted to ensure the multilingual robustness of the system and to extend the relatively small training data.", "labels": [], "entities": []}, {"text": "Without using any extra data, our system achieves fair results on both tracks in the shared task.", "labels": [], "entities": []}, {"text": "Our results (English 1 : F1-Mean = 0.835; French: F1-Mean = 0.86) as well as a post-task quick improvement with self-adaptive knowledge enhancement based on testing data demonstrate the effectiveness and robustness of bilingual training with multi-feature mining and knowledge enhancement for domain-specific SBD task.", "labels": [], "entities": [{"text": "F1-Mean", "start_pos": 25, "end_pos": 32, "type": "METRIC", "confidence": 0.9888338446617126}, {"text": "F1-Mean", "start_pos": 50, "end_pos": 57, "type": "METRIC", "confidence": 0.8200130462646484}, {"text": "SBD task", "start_pos": 309, "end_pos": 317, "type": "TASK", "confidence": 0.8575240969657898}]}], "introductionContent": [{"text": "Sentence Boundary Detection (SBD), which aims at detecting/disambiguating sentence boundaries of texts, is a fundamental step in many Natural Language Processing (NLP) applications.", "labels": [], "entities": [{"text": "Sentence Boundary Detection (SBD)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8413488864898682}, {"text": "detecting/disambiguating sentence boundaries of texts", "start_pos": 49, "end_pos": 102, "type": "TASK", "confidence": 0.841629649911608}]}, {"text": "It should be carried out before other critical components of NLP, e.g. part-of-speech (POS) tagging, syntactic-semantic-discourse parsing, information extraction or machine translation.", "labels": [], "entities": [{"text": "part-of-speech (POS) tagging", "start_pos": 71, "end_pos": 99, "type": "TASK", "confidence": 0.6461426317691803}, {"text": "syntactic-semantic-discourse parsing", "start_pos": 101, "end_pos": 137, "type": "TASK", "confidence": 0.7333190143108368}, {"text": "information extraction", "start_pos": 139, "end_pos": 161, "type": "TASK", "confidence": 0.8463233113288879}, {"text": "machine translation", "start_pos": 165, "end_pos": 184, "type": "TASK", "confidence": 0.7616040110588074}]}, {"text": "Existing SBD approaches have shown promising results for languages that have dependable orthographic conventions to mark beginning and ending of sentences, such as in English and many Europeans languages.", "labels": [], "entities": []}, {"text": "Relevant recent work include (e.g.).", "labels": [], "entities": []}, {"text": "However, previous work in SBD mainly dealt with well-formed and clean data such as articles from the Brown corpus or Wall Street Journal.", "labels": [], "entities": [{"text": "SBD", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.954756498336792}, {"text": "Brown corpus or Wall Street Journal", "start_pos": 101, "end_pos": 136, "type": "DATASET", "confidence": 0.8446013132731119}]}, {"text": "SBD remains challenging in two scenarios.", "labels": [], "entities": [{"text": "SBD", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9611310958862305}]}, {"text": "The first involves documents encoded in non-text formats, such as Adobe PDF format, or other image formats.", "labels": [], "entities": []}, {"text": "They provide the exact layout of a human readable document on a wide range of machines.", "labels": [], "entities": []}, {"text": "However, texts converted from PDF documents by OCR software are usually noisy and potentially with the loss of substantial formatting features.", "labels": [], "entities": []}, {"text": "This chaos leads to difficulties in SBD, and so far has been under-researched.", "labels": [], "entities": [{"text": "SBD", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.9889278411865234}]}, {"text": "The second involves languages whose orthography does not mark sentence boundary conventionally.", "labels": [], "entities": []}, {"text": "For instance, shows that using the period punctuation will lead to significant divergence from sentence boundaries.", "labels": [], "entities": []}, {"text": "What they proposed are followed by in their Menzerath-Altamann based power relations between a clause and its constituent words (instead of between sentences and words).", "labels": [], "entities": []}, {"text": "In this current paper, we deal with the first challenge.", "labels": [], "entities": []}, {"text": "There area number of issues to be addressed when applying SBD to financial documents.", "labels": [], "entities": [{"text": "SBD to financial documents", "start_pos": 58, "end_pos": 84, "type": "TASK", "confidence": 0.7905739843845367}]}, {"text": "Unlike passages of formal texts, financial documents are often heavily populated with rich tables of data-sometimes stretching over multiple pages-and figures, titles, dates and keywords of various types.", "labels": [], "entities": []}, {"text": "The presence of such non-textual information is admittedly not unique to financial documents, but it should be noted that many financial documents also do not come in clean/easily machine readable structures.", "labels": [], "entities": []}, {"text": "Detecting sentence boundaries on the basis of periods/stops may also be less straightforward, for example the presence of company tickers in a document may introduce some difficulties in cleanly identifying sentence boundaries, especially if appended with exchange, for example the full ticker for China Light and Power (CLP) company listed in Hong Kong can be written as '0002.hk'.", "labels": [], "entities": [{"text": "Detecting sentence boundaries", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8759519457817078}, {"text": "China Light and Power (CLP) company listed in Hong Kong", "start_pos": 298, "end_pos": 353, "type": "DATASET", "confidence": 0.8648396879434586}]}, {"text": "Additionally, sentences may contain various financial terms/acronyms, including company name abbreviations, that may impact the syntactic structure and hence generate sentence confusion.", "labels": [], "entities": []}, {"text": "As such financial documents present a range of challenges that result in the need to use a hybrid of language processing tools in combination with knowledge enrichment specific to the financial domain.", "labels": [], "entities": []}, {"text": "With such endeavors, we can expect chances of achieving SBD with reasonable levels of accuracy.", "labels": [], "entities": [{"text": "SBD", "start_pos": 56, "end_pos": 59, "type": "TASK", "confidence": 0.9264708757400513}, {"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9978393316268921}]}, {"text": "In the following sections, we will review some related work in Section 2, describe the features and methodology in Section 3, show and discuss the results in Section 4 and finally conclude this work in Section 5.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Performance of feature mining in the English Dev  set with RFC", "labels": [], "entities": [{"text": "feature mining", "start_pos": 25, "end_pos": 39, "type": "TASK", "confidence": 0.738146036863327}, {"text": "English Dev  set", "start_pos": 47, "end_pos": 63, "type": "DATASET", "confidence": 0.8008481661478678}, {"text": "RFC", "start_pos": 69, "end_pos": 72, "type": "DATASET", "confidence": 0.44422659277915955}]}, {"text": " Table 2: Performance of RFC in the French Dev and Test  sets in terms of keyword validation", "labels": [], "entities": [{"text": "RFC", "start_pos": 25, "end_pos": 28, "type": "DATASET", "confidence": 0.8904834389686584}, {"text": "French Dev and Test  sets", "start_pos": 36, "end_pos": 61, "type": "DATASET", "confidence": 0.9452408671379089}]}, {"text": " Table 3: Performance of RFC w.r.t. knowledge adaptation", "labels": [], "entities": [{"text": "RFC w.r.t. knowledge", "start_pos": 25, "end_pos": 45, "type": "DATASET", "confidence": 0.8704118728637695}]}]}