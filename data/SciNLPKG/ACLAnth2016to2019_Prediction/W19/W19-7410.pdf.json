{"title": [{"text": "A Probabilistic Approach for Confidence Scoring in Speech Recognition", "labels": [], "entities": [{"text": "Confidence Scoring in Speech Recognition", "start_pos": 29, "end_pos": 69, "type": "TASK", "confidence": 0.6944284558296203}]}], "abstractContent": [{"text": "This paper discusses a method to derive a meaningful confidence score fora speech segment at the phoneme level, using a frame clas-sifier.", "labels": [], "entities": []}, {"text": "Multiple functions, which capture various aspects of the frame classifier output, are first introduced.", "labels": [], "entities": []}, {"text": "The ability of these functions to discriminate between different phonemes is shown.", "labels": [], "entities": []}, {"text": "A probabilistic approach is formulated to combine the functions to get a meaningful confidence score, which reflects the precision of the predicted phoneme chunk.", "labels": [], "entities": [{"text": "precision", "start_pos": 121, "end_pos": 130, "type": "METRIC", "confidence": 0.9987038373947144}]}, {"text": "Relevant real-world datasets are used to demonstrate the effectiveness of the proposed confidence scoring mechanism.", "labels": [], "entities": []}], "introductionContent": [{"text": "In speech recognition, it is desirable to have a confidence score which has a strong correlation with the correctness of recognition.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 3, "end_pos": 21, "type": "TASK", "confidence": 0.8474701941013336}, {"text": "confidence score", "start_pos": 49, "end_pos": 65, "type": "METRIC", "confidence": 0.9404378235340118}]}, {"text": "A low confidence score should imply wrong recognition, and a high score should signal correct recognition.", "labels": [], "entities": []}, {"text": "For this, the confidence score should be derived out of features which are not directly used or overlooked, in the speech recognition.", "labels": [], "entities": [{"text": "confidence score", "start_pos": 14, "end_pos": 30, "type": "METRIC", "confidence": 0.9798584580421448}, {"text": "speech recognition", "start_pos": 115, "end_pos": 133, "type": "TASK", "confidence": 0.8087143003940582}]}, {"text": "Modern automatic speech recognition is done in a multi-level manner.", "labels": [], "entities": [{"text": "automatic speech recognition", "start_pos": 7, "end_pos": 35, "type": "TASK", "confidence": 0.6259502172470093}]}, {"text": "The bottom level corresponds to frame recognition.", "labels": [], "entities": [{"text": "frame recognition", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.9051634967327118}]}, {"text": "Next levels are phoneme, word and sentence recognition respectively.", "labels": [], "entities": [{"text": "sentence recognition", "start_pos": 34, "end_pos": 54, "type": "TASK", "confidence": 0.7069539576768875}]}, {"text": "In the sentence level, language model plays a key role in the overall word error.", "labels": [], "entities": []}, {"text": "The relationship between the frame level accuracy and the word level accuracy follows more of an S-curve.", "labels": [], "entities": [{"text": "frame level accuracy", "start_pos": 29, "end_pos": 49, "type": "METRIC", "confidence": 0.7415845195452372}, {"text": "word level accuracy", "start_pos": 58, "end_pos": 77, "type": "METRIC", "confidence": 0.5316296815872192}]}, {"text": "Word accuracy increases gradually as the frame accuracy increases, then it shoots up exponentially, and then gradually slows down.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 5, "end_pos": 13, "type": "METRIC", "confidence": 0.9105713963508606}, {"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.8627123832702637}]}, {"text": "An error in frame level classification can be forgiving than an error in phoneme detection, especially in the case of large vocabulary speech recognition task.", "labels": [], "entities": [{"text": "frame level classification", "start_pos": 12, "end_pos": 38, "type": "TASK", "confidence": 0.6162910560766856}, {"text": "phoneme detection", "start_pos": 73, "end_pos": 90, "type": "TASK", "confidence": 0.7443425953388214}, {"text": "large vocabulary speech recognition task", "start_pos": 118, "end_pos": 158, "type": "TASK", "confidence": 0.7124940276145935}]}, {"text": "Ideally, the confidence scoring should be using low level features which are raw compared to higher level features.", "labels": [], "entities": []}, {"text": "Confidence scoring in speech recognition has a rich literature.", "labels": [], "entities": [{"text": "Confidence scoring", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8992092609405518}, {"text": "speech recognition", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.762307196855545}]}, {"text": "A general survey for confidence scoring can be found in (.", "labels": [], "entities": [{"text": "confidence scoring", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.7090989202260971}]}, {"text": "Confidence scoring was treated as a classification problem with features derived from trained acoustic and language models along with derived word level features ().", "labels": [], "entities": [{"text": "Confidence scoring", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.917429506778717}]}, {"text": "Another approach is using backward language models (.", "labels": [], "entities": []}, {"text": "A trained generic confidence scoring mechanism can be recalibrated to output a more meaningful confidence score, by taking into account the end application specific scenarios ().", "labels": [], "entities": []}, {"text": "Another approach used for confidence scoring is by using word lattices ( ) and N-best lists).", "labels": [], "entities": [{"text": "confidence scoring", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.8774620294570923}]}, {"text": "Multilayer perceptrons(mlp) based posteriors () has been extensively used for confidence scoring.", "labels": [], "entities": [{"text": "confidence scoring", "start_pos": 78, "end_pos": 96, "type": "TASK", "confidence": 0.8802255392074585}]}, {"text": "mlp posterior based score has the benefit of being at the frame level, rather than at the phoneme level.", "labels": [], "entities": [{"text": "mlp posterior based score", "start_pos": 0, "end_pos": 25, "type": "METRIC", "confidence": 0.6736943200230598}]}, {"text": "We propose a confidence scoring mechanism at the phoneme level, using a set of new features derived from an mlp based frame classifier.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "First, the frame classifier details and datasets used are explained.", "labels": [], "entities": []}, {"text": "Certain measures computed from the frame classifier output is explored.", "labels": [], "entities": []}, {"text": "Then a set of phoneme level features are derived for confidence scoring.", "labels": [], "entities": [{"text": "confidence scoring", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.7563260495662689}]}, {"text": "A probabilistic confidence scoring mechanism is formulated using the features derived.", "labels": [], "entities": []}, {"text": "And finally, the approach is benchmarked using a test dataset.", "labels": [], "entities": []}, {"text": "This is a meta-learning approach, as the confidence scoring stage depends on the output from a trained frame classifier.", "labels": [], "entities": []}, {"text": "Datasets & Definitions: Voxforge data is used for all the experiments.", "labels": [], "entities": []}, {"text": "The foremost reason for using Voxforge data is that it is recorded in an uncontrolled environment by people with different accents, mother tongue, etc.", "labels": [], "entities": [{"text": "Voxforge data", "start_pos": 30, "end_pos": 43, "type": "DATASET", "confidence": 0.9020217955112457}]}, {"text": "This will give the necessary variability in the data and any confidence scoring mechanism derived out of this data will be applicable to a real-world speech based information access.", "labels": [], "entities": []}, {"text": "The whole Voxforge dataset is divided into 3 subsets, d 1 , d 2 and d 3 . d 1 is used to train the frame classifier.", "labels": [], "entities": [{"text": "Voxforge dataset", "start_pos": 10, "end_pos": 26, "type": "DATASET", "confidence": 0.943378210067749}]}, {"text": "d 2 is fed to the frame classifier to get the output dubbed as d m , which is eventually used for making distributions and functions needed for confidence scoring.", "labels": [], "entities": [{"text": "confidence scoring", "start_pos": 144, "end_pos": 162, "type": "TASK", "confidence": 0.7808884978294373}]}, {"text": "d 3 is used for benchmarking the proposed confidence scoring approach.", "labels": [], "entities": []}], "datasetContent": [{"text": "As this approach focuses on confidence scoring fora detected phone, it is the precision that has to be tested.", "labels": [], "entities": [{"text": "precision", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.9990816116333008}]}, {"text": "Models P (k|p), P (k|\u00acp), P (s|k, p), P (s|k, \u00acp), P (n|p), and P (n|\u00acp) are built from d m . For chunk size k \u2265 10, where the number of instances are less for \u00acp, data is pooled together and the skew normal distribution is fit.", "labels": [], "entities": []}, {"text": "This makes sense as fork \u2265 10, the average softmax probability of the phoneme chunk varies gradually, as is shown in Testing is done on the subset d 3 . the posterior ratio vs true positives and false positives fora selected phoneme /p/.", "labels": [], "entities": []}, {"text": "Each point (x, y) in the true positive curve means the following.", "labels": [], "entities": []}, {"text": "For posterior odds ratio greater than x, there are y instances of the Based on the use case, the best operating point can be selected.", "labels": [], "entities": [{"text": "posterior odds ratio", "start_pos": 4, "end_pos": 24, "type": "METRIC", "confidence": 0.8231989741325378}]}, {"text": "The difference between this approach and a direct posterior based confidence scoring approach () is in the additional assumptions made on the softmax probability.", "labels": [], "entities": []}, {"text": "Characteristics of the posteriors for the true positive and false positives, associated with a phoneme, is incorporated into the probabilistic framework.", "labels": [], "entities": []}, {"text": "The focus here is on the precision of the phoneme detection.", "labels": [], "entities": [{"text": "precision", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9991148114204407}, {"text": "phoneme detection", "start_pos": 42, "end_pos": 59, "type": "TASK", "confidence": 0.8688504695892334}]}], "tableCaptions": []}