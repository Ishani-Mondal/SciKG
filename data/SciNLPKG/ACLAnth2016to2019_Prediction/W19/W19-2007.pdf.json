{"title": [{"text": "Classification of Semantic Paraphasias: Optimization of a Word Embedding Model", "labels": [], "entities": []}], "abstractContent": [{"text": "In clinical assessment of people with aphasia, impairment in the ability to recall and produce words for objects (anomia) is assessed using a confrontation naming task, where a target stimulus is viewed and a corresponding label is spoken by the participant.", "labels": [], "entities": [{"text": "recall and produce words for objects (anomia)", "start_pos": 76, "end_pos": 121, "type": "TASK", "confidence": 0.5412863261169858}, {"text": "confrontation naming task", "start_pos": 142, "end_pos": 167, "type": "TASK", "confidence": 0.7945364316304525}]}, {"text": "Vector space word embedding models have had inital results in assessing semantic similarity of target-production pairs in order to automate scoring of this task; however, the resulting models are also highly dependent upon training parameters.", "labels": [], "entities": []}, {"text": "To select an optimal family of models, we fit a beta regression model to the distribution of performance metrics on a set of 2,880 grid search models and evaluate the resultant first-and second-order effects to explore how parameterization affects model performance.", "labels": [], "entities": []}, {"text": "Comparing to SimLex-999, we show that clinical data can be used in an evaluation task with comparable optimal parameter settings as standard NLP evaluation datasets.", "labels": [], "entities": [{"text": "SimLex-999", "start_pos": 13, "end_pos": 23, "type": "DATASET", "confidence": 0.8999618291854858}]}], "introductionContent": [{"text": "In clinical assessment of people with aphasia, impairment in the ability to recall and produce words for objects (anomia) is assessed using a confrontation naming task, where a target stimulus is viewed and a corresponding label is spoken by the participant.", "labels": [], "entities": [{"text": "recall and produce words for objects (anomia)", "start_pos": 76, "end_pos": 121, "type": "TASK", "confidence": 0.5412868161996206}, {"text": "confrontation naming task", "start_pos": 142, "end_pos": 167, "type": "TASK", "confidence": 0.7945364713668823}]}, {"text": "Semantic impairment is measured by a clinician's rating of semantic similarity between the target-production pairs, and involves a defined similarity criteria involving synonymy, association, and hypernymy.", "labels": [], "entities": []}, {"text": "Research into word embedding models has shown that different window parameterization settings capture different semantic relations of association/relatedness vs synonymy, functional properties vs topicality, and word embedding models have been adapted to synonymy, association, and hypernymy (.", "labels": [], "entities": []}, {"text": "A central question in NLP research is how to use extrinsic evaluation to measure what semantic relations are encoded by a model.", "labels": [], "entities": []}, {"text": "In this paper, we engage in the interdiscplinary question of how semantic relations can be modeled in a clinical domain, and present an application of word embedding models for assessing semantic impairment.", "labels": [], "entities": []}, {"text": "The Philadelphia Naming Test (PNT) implements one such naming task that was developed for psycholinguistic and clinical research; the scoring of this test involves a large taxonomy of coding responses based on phonological and semantic similarity of the response to the target object ().", "labels": [], "entities": [{"text": "Philadelphia Naming Test (PNT)", "start_pos": 4, "end_pos": 34, "type": "DATASET", "confidence": 0.8683673441410065}]}, {"text": "The taxonomy is motivated by Dell's two-step model of aphasia, where anomia results from a disruption in accessing both the phonological representation as well as semantic properties of the object.", "labels": [], "entities": []}, {"text": "PNT scoring is time-intensive due to the high number of items, and there have been successful attempts to both shorten the number of items on the test via computer adaptive assessment () as well as automate the scoring of the PNT via automated classification of paraphasias to facilitate the use of the PNT as a tool in clinical practice.", "labels": [], "entities": [{"text": "PNT scoring", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9569387137889862}]}, {"text": "Our work is part of a broader goal to develop an end-to-end automation of the PNT, from presentation of target items to an individual error profile.", "labels": [], "entities": [{"text": "PNT", "start_pos": 78, "end_pos": 81, "type": "TASK", "confidence": 0.8723899126052856}]}, {"text": "In this paper, we present results of a classification task that identifies semantic paraphasias (errors) on the PNT, using a word embedding model to measure semantic similiarity of a production to the target item.", "labels": [], "entities": []}, {"text": "We present results of parameter optimization tasks and post-hoc analysis of the resulting vector space in optimal and non-optimal models for the downstream application of classifying semantic paraphasias on the PNT, using a novel application of the beta regression model to evaluate grid search parameters.", "labels": [], "entities": []}, {"text": "We then compare the evaluation metric of psycholinguistic aphasic data with SimLex-999, a standard NLP evaluation tasks with measured controls for synonymy and association, and explore best practices for adapting models to psycholinguistic, clinical environments.", "labels": [], "entities": [{"text": "SimLex-999", "start_pos": 76, "end_pos": 86, "type": "DATASET", "confidence": 0.8955132961273193}]}], "datasetContent": [{"text": "Canonical word embedding tasks strive to model semantic relations that are similar to those used in the definition of PNT semantic errors such as synonymy and association (e.g.; ), and thus should be well suited for the classification of semantic errors in the PNT.", "labels": [], "entities": []}, {"text": "Conventional scoring of the PNT defines a criteria for semantic errors that involves areal word noun production that is in one of six semantic relations with the target word; see (.", "labels": [], "entities": []}, {"text": "The PNT consists of 175 items, represented by a set of black-and-white images, and were selected based on a series of controls, involving varying word frequency based on, word length (1 to 4 syllables), and high name performance by control participants (.", "labels": [], "entities": []}, {"text": "Items in the PNT come from several semantic categories, and avoid landmarks or other recognizable individuals).", "labels": [], "entities": []}, {"text": "The Moss Aphasia Psycholinguistic Project Database (MAPPD) contains transcribed responses from over 300 administrations of the PNT, and is often used in aphasiological research; in this work, we use a subsample of 152 administrations selected on the basis of clinical characteristics.", "labels": [], "entities": [{"text": "Moss Aphasia Psycholinguistic Project Database (MAPPD)", "start_pos": 4, "end_pos": 58, "type": "DATASET", "confidence": 0.7259826846420765}]}, {"text": "The 152 administrations of the PNT are from 99 subjects from 1-195 months post onset of aphasia.", "labels": [], "entities": [{"text": "PNT", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.7944256067276001}]}, {"text": "Five different sub-types of aphasia were present among the subjects (anomic, Broca, conduction, transcortical sensory, and Wernicke).", "labels": [], "entities": [{"text": "Broca", "start_pos": 77, "end_pos": 82, "type": "METRIC", "confidence": 0.9900385141372681}, {"text": "Wernicke", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.8583657145500183}]}, {"text": "Some subjects had multiple administrations of the PNT at different months post onset; the range is 1-6 administrations per subject.", "labels": [], "entities": []}, {"text": "The frequency and length controls for targets on the PNT, in addition to the semantic relations that define paraphasic errors on the naming test, establish a paradigm for target-production word pairs that is quite similar to the structure of certain external evaluation datasets developed for word embedding models.", "labels": [], "entities": []}, {"text": "For example, SimLex-999 () is a benchmark dataset for assessing semantic similarity that is based on human ratings of word pairs on a scale of synonymy, as opposed to association/relatedness.", "labels": [], "entities": []}, {"text": "SimLex-999 balances word association strength using the USF Free Association norms, samples from both associated and unassociated word pairs, and controls for features such as the concreteness and part-ofspeech of the word pairs.", "labels": [], "entities": [{"text": "USF Free Association norms", "start_pos": 56, "end_pos": 82, "type": "DATASET", "confidence": 0.9639701545238495}]}, {"text": "Additionally, the PNT involves human evaluation of these semantic relations -in this case, two trained clinicianswith instructions that train evaluators to look for specific dimensions of semantic similiarity when evaluating whether a word pair is semantically similar (the instructions are very similar to those used by.", "labels": [], "entities": [{"text": "PNT", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.9384099841117859}]}, {"text": "Comparing results from MAPPD, which depends on a clinician's identification of a word pair as semantically similar, with results from SimLex-999 should establish whether clinical data is a reliable evaluation metric for embedding models.", "labels": [], "entities": []}, {"text": "Optimization over the SimLex dataset shows similar parameter settings as MAPPD for dimensionality and window size.", "labels": [], "entities": [{"text": "SimLex dataset", "start_pos": 22, "end_pos": 36, "type": "DATASET", "confidence": 0.9359615743160248}]}, {"text": "Skipgram models are optimal, and a similar pattern of performance across window sizes is observed for Skipgram and CBOW models.", "labels": [], "entities": []}, {"text": "Key differences in frequency threshold are related to differences in outof-vocabulary items.", "labels": [], "entities": []}, {"text": "Stemming is dispreferred across the SimLex dataset, which differs from the MAPPD CBOW models.", "labels": [], "entities": [{"text": "SimLex dataset", "start_pos": 36, "end_pos": 50, "type": "DATASET", "confidence": 0.9458777904510498}, {"text": "MAPPD CBOW", "start_pos": 75, "end_pos": 85, "type": "DATASET", "confidence": 0.7921207845211029}]}, {"text": "As MAPPD utilizes only a limited vocabulary of nouns, the stemmed corpus might have a smaller effect than on the more morphologically varied SimLex word pairs.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Table of Estimates for Beta Regression for Mean (\u00b5) and Precision (\u03c6). 'x' denotes second-order effects.   * p < .05/  *   * p < .01/  *   *   *  p < .001", "labels": [], "entities": [{"text": "Mean (\u00b5)", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9263667315244675}, {"text": "Precision (\u03c6)", "start_pos": 66, "end_pos": 79, "type": "METRIC", "confidence": 0.9171950817108154}]}]}