{"title": [{"text": "Neural Cross-Lingual Transfer and Limited Annotated Data for Named Entity Recognition in Danish", "labels": [], "entities": [{"text": "Neural Cross-Lingual Transfer", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6777142783006033}, {"text": "Named Entity Recognition", "start_pos": 61, "end_pos": 85, "type": "TASK", "confidence": 0.6439745426177979}]}], "abstractContent": [{"text": "Named Entity Recognition (NER) has greatly advanced by the introduction of deep neural architectures.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7702464411656061}]}, {"text": "However , the success of these methods depends on large amounts of training data.", "labels": [], "entities": []}, {"text": "The scarcity of publicly-available human-labeled datasets has resulted in limited evaluation of existing NER systems, as is the case for Danish.", "labels": [], "entities": [{"text": "NER", "start_pos": 105, "end_pos": 108, "type": "TASK", "confidence": 0.9638479948043823}]}, {"text": "This paper studies the effectiveness of cross-lingual transfer for Danish, evaluates its complementarity to limited gold data, and sheds light on performance of Danish NER.", "labels": [], "entities": [{"text": "cross-lingual transfer", "start_pos": 40, "end_pos": 62, "type": "TASK", "confidence": 0.7415859699249268}, {"text": "Danish NER", "start_pos": 161, "end_pos": 171, "type": "DATASET", "confidence": 0.8496905565261841}]}], "introductionContent": [{"text": "Named entity recognition is a key step for natural language understanding (NLU), and important for information extraction, relation extraction, question answering and even privacy protection.", "labels": [], "entities": [{"text": "Named entity recognition", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6821140646934509}, {"text": "natural language understanding (NLU)", "start_pos": 43, "end_pos": 79, "type": "TASK", "confidence": 0.8226080238819122}, {"text": "information extraction", "start_pos": 99, "end_pos": 121, "type": "TASK", "confidence": 0.8027324080467224}, {"text": "relation extraction", "start_pos": 123, "end_pos": 142, "type": "TASK", "confidence": 0.8684602975845337}, {"text": "question answering", "start_pos": 144, "end_pos": 162, "type": "TASK", "confidence": 0.9131585657596588}, {"text": "privacy protection", "start_pos": 172, "end_pos": 190, "type": "TASK", "confidence": 0.6887475997209549}]}, {"text": "However, the scarcity of publicly-available human annotated datasets has resulted in alack of evaluation for languages beyond a selected set (e.g., those covered in early shared tasks like Dutch, German, English, Spanish), despite the fact that NER tools exists or recently emerged for other languages.", "labels": [], "entities": []}, {"text": "One such case is Danish, for which NER dates back as early as) and tools exist; Al-Rfou et al.,) but lack empirical evaluation.", "labels": [], "entities": [{"text": "Danish", "start_pos": 17, "end_pos": 23, "type": "DATASET", "confidence": 0.8724218010902405}, {"text": "NER", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.9517533183097839}]}, {"text": "Contemporarily, there exists a surge of interest in porting NLU components quickly and cheaply to new languages.", "labels": [], "entities": []}, {"text": "This includes cross-lingual transfer methods that exploit resources from existing high-resource languages for zero-shot or few-shot learning.", "labels": [], "entities": []}, {"text": "This line of research is blooming, particularly since the advent of neural NER, which holds the state of the art.", "labels": [], "entities": []}, {"text": "However, neither neural tagging nor crosslingual transfer has been explored for Danish NER, a gap we seek to fill in this paper.", "labels": [], "entities": [{"text": "neural tagging", "start_pos": 17, "end_pos": 31, "type": "TASK", "confidence": 0.6736444979906082}, {"text": "crosslingual transfer", "start_pos": 36, "end_pos": 57, "type": "TASK", "confidence": 0.6990280151367188}, {"text": "Danish NER", "start_pos": 80, "end_pos": 90, "type": "DATASET", "confidence": 0.8800169825553894}]}, {"text": "Contributions We present a) publiclyavailable evaluation data to encourage research on Danish NER; b) an empirical comparison of two existing NER systems for Danish to a neural model; c) an empirical evaluation of learning an effective NER tagger for Danish via cross-lingual transfer paired with very little labeled data.", "labels": [], "entities": [{"text": "Danish NER", "start_pos": 87, "end_pos": 97, "type": "DATASET", "confidence": 0.7019593119621277}]}], "datasetContent": [{"text": "As  Cross-lingual mapping We map the existing Danish Polyglot embeddings to the English embedding space by using an unsupervised alignment method which does not require parallel data.", "labels": [], "entities": [{"text": "Danish Polyglot embeddings", "start_pos": 46, "end_pos": 72, "type": "DATASET", "confidence": 0.8938315510749817}]}, {"text": "In particular, we use character-identical words as seeds for the Procrustes rotation method introduced in MUSE ().", "labels": [], "entities": [{"text": "MUSE", "start_pos": 106, "end_pos": 110, "type": "DATASET", "confidence": 0.6463975310325623}]}, {"text": "Cross-lingual transfer is powerful (RQ1).", "labels": [], "entities": [{"text": "Cross-lingual transfer", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7005569934844971}, {"text": "RQ1", "start_pos": 36, "end_pos": 39, "type": "METRIC", "confidence": 0.8080470561981201}]}, {"text": "Zero-shot learning reaches an F1 score of 58% in the MEDIUM setup, which outperforms training the neural tagger on very limited gold data (plain).", "labels": [], "entities": [{"text": "F1 score", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9880073666572571}]}, {"text": "Neural NER is better than traditional HMM-based tagging (TnT) and greatly improves by unsupervised word embedding initialization (+Poly).", "labels": [], "entities": [{"text": "Neural NER", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.7000166177749634}, {"text": "HMM-based tagging (TnT)", "start_pos": 38, "end_pos": 61, "type": "TASK", "confidence": 0.7993442058563233}]}, {"text": "It is noteworthy that zero-shot transfer benefits only to a limiting degree from more source data (F1 increases by 3% when training on all English CoNLL data).", "labels": [], "entities": [{"text": "zero-shot transfer", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.8492254018783569}, {"text": "F1", "start_pos": 99, "end_pos": 101, "type": "METRIC", "confidence": 0.999660849571228}, {"text": "English CoNLL data", "start_pos": 139, "end_pos": 157, "type": "DATASET", "confidence": 0.6810855468114217}]}], "tableCaptions": [{"text": " Table 2: Overview of the annotated Danish  NER data. Around 35%-39% of the sentences  contain NEs. TTR: type-token ratio.", "labels": [], "entities": [{"text": "Danish  NER data", "start_pos": 36, "end_pos": 52, "type": "DATASET", "confidence": 0.9303086002667745}, {"text": "TTR", "start_pos": 100, "end_pos": 103, "type": "METRIC", "confidence": 0.9924218058586121}]}, {"text": " Table 3: F 1 score on the development set for low-resource training setups (none, tiny 5k or  small 10k labeled Danish sentences). Transfer via multilingual embeddings from MEDIUM  (3.2k sentences, 51k tokens) or LARGE English source data (14k sentences/203k tokens).", "labels": [], "entities": [{"text": "F", "start_pos": 10, "end_pos": 11, "type": "METRIC", "confidence": 0.9936072826385498}, {"text": "LARGE English source data", "start_pos": 214, "end_pos": 239, "type": "DATASET", "confidence": 0.8473998159170151}]}, {"text": " Table 4: F 1 score on the Danish dev set.", "labels": [], "entities": [{"text": "F", "start_pos": 10, "end_pos": 11, "type": "METRIC", "confidence": 0.9909712076187134}, {"text": "Danish dev set", "start_pos": 27, "end_pos": 41, "type": "DATASET", "confidence": 0.9792799552281698}]}]}