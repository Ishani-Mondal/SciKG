{"title": [{"text": "Correcting Whitespace Errors in Digitized Historical Texts", "labels": [], "entities": [{"text": "Correcting Whitespace Errors in Digitized Historical Texts", "start_pos": 0, "end_pos": 58, "type": "TASK", "confidence": 0.6289644922528949}]}], "abstractContent": [{"text": "Whitespace errors are common to digitized archives.", "labels": [], "entities": []}, {"text": "This paper describes a lightweight unsupervised technique for recovering the original whitespace.", "labels": [], "entities": []}, {"text": "Our approach is based on count statistics from Google n-grams, which are converted into a likelihood ratio test computed from interpolated trigram and bigram probabilities.", "labels": [], "entities": []}, {"text": "To evaluate this approach, we annotate a small corpus of whitespace errors in a digitized corpus of newspapers from the 19th century United States.", "labels": [], "entities": []}, {"text": "Our technique identifies and corrects most whitespace errors while introducing a minimal amount of oversegmen-tation: it achieves 77% recall at a false positive rate of less than 1%, and 91% recall at a false positive rate of less than 3%.", "labels": [], "entities": [{"text": "recall", "start_pos": 134, "end_pos": 140, "type": "METRIC", "confidence": 0.9983103275299072}, {"text": "recall", "start_pos": 191, "end_pos": 197, "type": "METRIC", "confidence": 0.9972604513168335}]}], "introductionContent": [{"text": "The application of natural language processing to digitized archives has the potential for significant impact in the humanities.", "labels": [], "entities": []}, {"text": "However, to realize this potential, it is necessary to ensure that digitization produces accurate representations of the original texts.", "labels": [], "entities": []}, {"text": "Most large-scale digital corpora are produced by optical character recognition (OCR; e.g.,, but even the best current methods yield substantial amounts of noise when applied to historical texts, such as the nineteenth-century newspaper shown in.", "labels": [], "entities": [{"text": "optical character recognition", "start_pos": 49, "end_pos": 78, "type": "TASK", "confidence": 0.6386675337950388}]}, {"text": "Alternatively, with substantial effort, digitization can be performed manually, or by manual correction of OCR output).", "labels": [], "entities": [{"text": "digitization", "start_pos": 40, "end_pos": 52, "type": "TASK", "confidence": 0.9629082083702087}]}, {"text": "However, even for manually \"keyed-in\" corpora, noise can be introduced due to errors in workflow (.", "labels": [], "entities": []}, {"text": "Whitespace is a particularly common source of digitization errors in both OCR and manually digitized corpora.", "labels": [], "entities": []}, {"text": "Such errors, also known as word segmentation errors or spacing errors, can arise during OCR as well as during the postdigitization handling of the data (Kissos and Der- showitz, 2016).", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.6975682526826859}]}, {"text": "These errors can result in the elimination of whitespace between words, leading to out-of-vocabulary items like senatoradmits and endowedwith.", "labels": [], "entities": []}, {"text": "This paper presents a set of unsupervised techniques for the identification and correction of such errors.", "labels": [], "entities": [{"text": "identification and correction", "start_pos": 61, "end_pos": 90, "type": "TASK", "confidence": 0.7012367049853007}]}, {"text": "To resolve these errors, we apply large-scale ngram counts from Google Books ().", "labels": [], "entities": [{"text": "Google Books", "start_pos": 64, "end_pos": 76, "type": "DATASET", "confidence": 0.8875182569026947}]}, {"text": "The basic premise of this approach is that additional whitespace should be introduced in cases where a token is out-ofvocabulary, yet can be decomposed into two or more in-vocabulary tokens.", "labels": [], "entities": []}, {"text": "By using bigram and unigram counts, it is possible to distinguish these cases, without treating membership in a predefined vocabulary as the sole and determinative indicator of whether a token should be segmented.", "labels": [], "entities": []}, {"text": "Furthermore, by using higher-order ngram counts, it is possible to make a contextualized judgment about whether and how whitespace should be introduced.", "labels": [], "entities": []}, {"text": "We show that contextualization yields significant improvements in segmentation accuracy.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 66, "end_pos": 78, "type": "TASK", "confidence": 0.9532047510147095}, {"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9508710503578186}]}, {"text": "Our research is motivated by our own experience working with historical texts.", "labels": [], "entities": []}, {"text": "We were fortunate to obtain access to a manually-digitized corpus of nineteenth-century newspapers from the United States.", "labels": [], "entities": []}, {"text": "1 However, the digitization process introduced whitespace errors, and the original tokenization was unrecoverable.", "labels": [], "entities": []}, {"text": "These errors were sufficiently frequent as to substantially impact downstream analyses such as topic models and word embeddings.", "labels": [], "entities": []}, {"text": "We undertook this research to solve this practical problem, but because we believe it generalizes beyond our specific case, we systematically analyze the performance of our solution, and release a trained system for whitespace recovery.", "labels": [], "entities": [{"text": "whitespace recovery", "start_pos": 216, "end_pos": 235, "type": "TASK", "confidence": 0.8136205077171326}]}, {"text": "To summarize our contributions: \u2022 We present anew method for correcting common whitespace errors in digitized archives.", "labels": [], "entities": []}, {"text": "\u2022 We evaluate on new annotations of manual whitespace error corrections in a digitized historical corpus.", "labels": [], "entities": []}, {"text": "\u2022 We release a trained system for other researchers who face similar problems.", "labels": [], "entities": []}], "datasetContent": [{"text": "We apply the segmentation techniques from the previous section to the Accessible Archives corpus, a dataset of manually digitized articles from newspapers in the nineteenth-century United States.", "labels": [], "entities": [{"text": "Accessible Archives corpus", "start_pos": 70, "end_pos": 96, "type": "DATASET", "confidence": 0.7731302579243978}]}, {"text": "As noted in the introduction, whitespace errors were introduced during the digitization process, likely by deleting newline characters when moving the files across operating systems.", "labels": [], "entities": []}, {"text": "As a result, the dataset contains a relatively large number of concatenated terms, such as andsaw, daythe, dreamsof, manufactureof, onlytwo, returningto, showsthe, theboys, thelevel, and thesea.", "labels": [], "entities": []}, {"text": "To measure segmentation accuracy, two of the authors manually annotated a randomly-selected subset of 200 terms that occur in at least 5 contexts in the corpus.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 11, "end_pos": 23, "type": "TASK", "confidence": 0.9624309539794922}, {"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.8794349431991577}]}, {"text": "In each case, the annotator either provides the correct segmentation or indicates that no segmentation is necessary.", "labels": [], "entities": []}, {"text": "The annotators indicated that 33 % of the terms needed a segmentation and agreed on all segmentation decisions, indicating that this problem is unambiguous for human readers.", "labels": [], "entities": []}, {"text": "Although a high proportion of terms required segmentation, these terms were all concentrated in the long tail of the distribution of the terms by frequency.", "labels": [], "entities": []}, {"text": "This indicates that the segmentation errors are spread across several terms in the corpus but are still rare and may not adversely affect the readability of the corpus.", "labels": [], "entities": []}, {"text": "We tested the ability of likelihood ratio scores to recover the true segmentations.", "labels": [], "entities": [{"text": "likelihood ratio scores", "start_pos": 25, "end_pos": 48, "type": "METRIC", "confidence": 0.9169220129648844}]}, {"text": "The evaluation is based on the following counts: True positive: The system proposes a segmentation, and it matches the annotated segmentation.", "labels": [], "entities": []}, {"text": "False positive: The system proposes a segmentation, and either it does not match the annotated segmentation or the annotators marked the term as unsegmented.", "labels": [], "entities": [{"text": "False", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9600973725318909}]}, {"text": "False negative: A segmentation was annotated, and the system does not propose it.", "labels": [], "entities": [{"text": "False", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9762387871742249}, {"text": "segmentation", "start_pos": 18, "end_pos": 30, "type": "TASK", "confidence": 0.9716522097587585}]}, {"text": "True negative: A segmentation was not annotated, and the system does not propose one.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 17, "end_pos": 29, "type": "TASK", "confidence": 0.9158197045326233}]}, {"text": "The recall is computed as TP/(TP + FN), and the false positive rate is computed as FP/(FP + TN).", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9996687173843384}, {"text": "TP/(TP + FN", "start_pos": 26, "end_pos": 37, "type": "METRIC", "confidence": 0.7419864058494567}, {"text": "false positive rate", "start_pos": 48, "end_pos": 67, "type": "METRIC", "confidence": 0.8423228065172831}, {"text": "FP/(FP + TN", "start_pos": 83, "end_pos": 94, "type": "METRIC", "confidence": 0.7961003541946411}]}], "tableCaptions": [{"text": " Table 1: Maximum segmentation recall at various false positive rates.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 18, "end_pos": 30, "type": "TASK", "confidence": 0.9554152488708496}, {"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9568520188331604}]}]}