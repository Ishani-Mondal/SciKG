{"title": [{"text": "Assessing Back-Translation as a Corpus Generation Strategy for non-English Tasks: A Study in Reading Comprehension and Word Sense Disambiguation", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 119, "end_pos": 144, "type": "TASK", "confidence": 0.6792995830376943}]}], "abstractContent": [{"text": "Corpora curated by experts have sustained Natural Language Processing mainly in En-glish, but the expensiveness of corpora creation is a barrier for the development in further languages.", "labels": [], "entities": []}, {"text": "Thus, we propose a corpus generation strategy that only requires a machine translation system between English and the target language in both directions, where we filter the best translations by computing automatic translation metrics and the task performance score.", "labels": [], "entities": [{"text": "corpus generation", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.7302674651145935}]}, {"text": "By studying Reading Comprehension in Spanish and Word Sense Disam-biguation in Portuguese, we identified that a more quality-oriented metric has high potential in the corpora selection without degrading the task performance.", "labels": [], "entities": [{"text": "Word Sense Disam-biguation", "start_pos": 49, "end_pos": 75, "type": "TASK", "confidence": 0.5676634709040324}]}, {"text": "We conclude that it is possible to systematise the building of quality corpora using machine translation and automatic metrics, besides some prior effort to clean and process the data.", "labels": [], "entities": []}], "introductionContent": [{"text": "Available data has allowed a steady improvement in Natural Language Processing (NLP) tasks for English.", "labels": [], "entities": []}, {"text": "Nevertheless, English is not the broadest native language spoken in the world.", "labels": [], "entities": []}, {"text": "According to, English ranks third, behind Chinese (Mandarin) and Spanish, and is only one of the approximately 7000 currently spoken languages.", "labels": [], "entities": []}, {"text": "The relevance of English as the academically universal language has allowed its growth in computational linguistic resources.", "labels": [], "entities": []}, {"text": "Even in languages with a large number of speakers, such as Spanish, it is difficult to find specific NLP tools that match the quality and performance as in English.", "labels": [], "entities": []}, {"text": "If we want to replicate the development of state-of-the-art models for other languages, we would need large and high-quality * Equal contribution corpora analogous to the English ones, and their creation cost would be prohibitive.", "labels": [], "entities": []}, {"text": "In this context, there is a very compelling tool that has reached several languages in commercial systems: Machine Translation (MT).", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 107, "end_pos": 131, "type": "TASK", "confidence": 0.874264371395111}]}, {"text": "However, it is worth noting that MT works for language-pairs, and therefore, most of the commercial MT tools have obtained excellent results mostly with English as the source or target language.", "labels": [], "entities": [{"text": "MT", "start_pos": 33, "end_pos": 35, "type": "TASK", "confidence": 0.9665961861610413}, {"text": "MT", "start_pos": 100, "end_pos": 102, "type": "TASK", "confidence": 0.9751423001289368}]}, {"text": "Thus, we still need English in search of robust NLP tools, but at least there is potential for obtaining new data for new languages using high-quality MT systems.", "labels": [], "entities": []}, {"text": "As other studies have been focusing on (see \u00a72), we can translate task-specific corpora from English to other languages to leverage an NLP tool without the need of experts in the target language.", "labels": [], "entities": []}, {"text": "Under those circumstances, the next question arises: how can we guarantee the quality of the new corpus by using automatic translations and without recurring to manual validation?", "labels": [], "entities": []}, {"text": "Previous work used quality estimation metrics from machine translation, mostly BLEU (), by applying back-translation and performing the quality evaluation in English.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 79, "end_pos": 83, "type": "METRIC", "confidence": 0.979415774345398}]}, {"text": "However, we are concerned about the deficiency of using only BLEU as a measurement of a correct translation) or text generation in general (, and currently there are other proposed metrics to cover the correlation gap between BLEU and a human assessment.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 61, "end_pos": 65, "type": "METRIC", "confidence": 0.9961269497871399}, {"text": "text generation", "start_pos": 112, "end_pos": 127, "type": "TASK", "confidence": 0.7978691458702087}, {"text": "BLEU", "start_pos": 226, "end_pos": 230, "type": "METRIC", "confidence": 0.9871079325675964}]}, {"text": "Therefore, we believe there is space for improvement in the quality assessment of a back-translation application to the generation of new corpora.", "labels": [], "entities": []}, {"text": "Our study and contribution are not focused in obtaining state-of-the-art results for new languages, but to obtain anew quality corpus that could be used to build state-of-the-art models, such as deep neural networks), in new languages.", "labels": [], "entities": []}, {"text": "However, we also managed to surpass previous methods on the target languages in monolingual scenarios.", "labels": [], "entities": []}, {"text": "More details about related works are described in \u00a72.", "labels": [], "entities": []}, {"text": "Then, we present our methodology for corpus generation in \u00a73, where we also introduce our case studies in Word Sense Disambiguation for Portuguese and Reading Comprehension for Spanish.", "labels": [], "entities": [{"text": "corpus generation", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.7635723352432251}, {"text": "Word Sense Disambiguation", "start_pos": 106, "end_pos": 131, "type": "TASK", "confidence": 0.6571062703927358}]}, {"text": "Furthermore, \u00a74 contains an extrinsic evaluation of the corpora in their respective task.", "labels": [], "entities": []}, {"text": "Also, we make publicly available specific code and guidelines to build the new corpora from the original sources 1 . The obtained results enlightens a potential systematisation of new corpora generation for many language-related tasks and opens further work on generalisation and truly low-resource settings.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate each generated corpus by measuring the task performance in a specific test set for the target language.", "labels": [], "entities": []}, {"text": "We restrict our experiments in monolingual setups to control the identification of potential results.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Corpus size for Reading Comprehension.  SQuAD 1.1 (en) is translated into Spanish (es), ques- tions without explicit answers are dropped, and the cor- pus is split to generate a new test.", "labels": [], "entities": []}, {"text": " Table 2: Size of development and test sets for the eval- uation of Reading Comprehension in Spanish", "labels": [], "entities": []}, {"text": " Table 3: Corpus size details for the Unified Evaluation  Framework or UEF (en)", "labels": [], "entities": []}, {"text": " Table 5: Reading Comprehension (es): Results from  our model trained with the selected threshold versus the  method of Vicedo et al. (2004) in all test partitions", "labels": [], "entities": []}, {"text": " Table 6: Results for the Lexical sample task in WSD", "labels": [], "entities": [{"text": "WSD", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.6102244853973389}]}]}