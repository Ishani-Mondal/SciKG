{"title": [{"text": "Scalable, Semi-Supervised Extraction of Structured Information from Scientific Literature", "labels": [], "entities": [{"text": "Extraction of Structured Information from Scientific Literature", "start_pos": 26, "end_pos": 89, "type": "TASK", "confidence": 0.7403641854013715}]}], "abstractContent": [{"text": "As scientific communities grow and evolve, there is a high demand for improved methods for finding relevant papers, comparing papers on similar topics and studying trends in the research community.", "labels": [], "entities": []}, {"text": "All these tasks involve the common problem of extracting structured information from scientific articles.", "labels": [], "entities": [{"text": "extracting structured information from scientific articles", "start_pos": 46, "end_pos": 104, "type": "TASK", "confidence": 0.85859215259552}]}, {"text": "In this paper, we propose a novel, scal-able, semi-supervised method for extracting relevant structured information from the vast available raw scientific literature.", "labels": [], "entities": []}, {"text": "We extract the fundamental concepts of aim, method and result from scientific articles and use them to construct a knowledge graph.", "labels": [], "entities": [{"text": "aim", "start_pos": 39, "end_pos": 42, "type": "METRIC", "confidence": 0.9656512141227722}]}, {"text": "Our algorithm makes use of domain-based word embedding and the bootstrap framework.", "labels": [], "entities": []}, {"text": "Our experiments show the domain independence of our algorithm and that our system achieves precision and recall comparable to the state of the art.", "labels": [], "entities": [{"text": "precision", "start_pos": 91, "end_pos": 100, "type": "METRIC", "confidence": 0.9994439482688904}, {"text": "recall", "start_pos": 105, "end_pos": 111, "type": "METRIC", "confidence": 0.9989683628082275}]}, {"text": "We also show the research trends of two distinct communities-computational linguistics and computer vision.", "labels": [], "entities": []}], "introductionContent": [{"text": "With the tremendous amount of research publications available online, there is an increasing demand to automatically process this information to facilitate easy navigation through this enormous literature for researchers.", "labels": [], "entities": []}, {"text": "Whenever researchers start working on a problem, they are interested to know if the problem has been solved previously, methods used to solve this problem, the importance of the problem and the applications of that problem.", "labels": [], "entities": []}, {"text": "This leads to the requirement of finding automatic ways of extracting such structured information from the vast available raw scientific literature which can help summarize the research paper as well as the research community and can help in finding relevant papers.", "labels": [], "entities": [{"text": "summarize", "start_pos": 163, "end_pos": 172, "type": "TASK", "confidence": 0.9694883227348328}]}, {"text": "Organizing scientific information into structured knowledge bases requires information extraction (IE) about scientific entities and their relationships.", "labels": [], "entities": [{"text": "information extraction (IE) about scientific entities", "start_pos": 75, "end_pos": 128, "type": "TASK", "confidence": 0.8514496833086014}]}, {"text": "However, the challenges associated with scientific information extraction are greater than fora general domain.", "labels": [], "entities": [{"text": "scientific information extraction", "start_pos": 40, "end_pos": 73, "type": "TASK", "confidence": 0.6262118915716807}]}, {"text": "General methods of information extraction cannot be applied to research papers due to their semistructured nature and also the new and unique terminologies used in them.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 19, "end_pos": 41, "type": "TASK", "confidence": 0.7660937607288361}]}, {"text": "Secondly, annotation of scientific text requires domain expertise which makes annotation costly and limits resources.", "labels": [], "entities": [{"text": "annotation of scientific text", "start_pos": 10, "end_pos": 39, "type": "TASK", "confidence": 0.8372600376605988}]}, {"text": "There is a considerable amount of previous and ongoing work in this direction, starting from keyword extraction)) and textual summarization (.", "labels": [], "entities": [{"text": "keyword extraction", "start_pos": 93, "end_pos": 111, "type": "TASK", "confidence": 0.8039233088493347}, {"text": "textual summarization", "start_pos": 118, "end_pos": 139, "type": "TASK", "confidence": 0.5702747702598572}]}, {"text": "Other research has focused on unsupervised approaches such as bootstrapping)(), where they introduced hand-designed templates to extract scientific keyphrases and categorize them into different concepts, and then more templates are added automatically through bootstrapping.", "labels": [], "entities": []}, {"text": "Hand-designed templates limit their generalization to all the different domains present within the scientific literature.", "labels": [], "entities": []}, {"text": "A recent challenge on Scientific Information Extraction (ScienceIE)) provided a dataset consisting of 500 scientific paragraphs with keyphrase annotations for three categories: TASK, PROCESS, MA-TERIAL across three scientific domains, Computer Science, Material Science, and Physics.", "labels": [], "entities": [{"text": "Scientific Information Extraction (ScienceIE))", "start_pos": 22, "end_pos": 68, "type": "TASK", "confidence": 0.7554100056489309}, {"text": "TASK", "start_pos": 177, "end_pos": 181, "type": "METRIC", "confidence": 0.987280011177063}, {"text": "MA-TERIAL", "start_pos": 192, "end_pos": 201, "type": "METRIC", "confidence": 0.8882026076316833}]}, {"text": "This invited many supervised and semi-supervised techniques in this field.", "labels": [], "entities": []}, {"text": "Although all these techniques can help extract important concepts of a research paper in a particular domain, we need more general and scalable methods which can summarize the complete research community.", "labels": [], "entities": []}, {"text": "In this work, we propose anew technique to extract key concepts from the research publications.", "labels": [], "entities": []}, {"text": "Our main insight is that a paper cites another paper either for its aim, or method, or result.", "labels": [], "entities": []}, {"text": "Therefore, key contribution of paper in the research community can be best summarized by its aim, the method used to solve the problem and the final result.", "labels": [], "entities": []}, {"text": "We define these concepts as: Aim: Target or primary focus of the paper.", "labels": [], "entities": [{"text": "Aim", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.8822137713432312}]}, {"text": "Method: Techniques used to achieve the aim.", "labels": [], "entities": []}, {"text": "Result: well-defined output of the experiments or contribution which can be directly used by the research community.", "labels": [], "entities": [{"text": "Result", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9813195466995239}]}, {"text": "Example: \"The support-vector network (Result) is anew learning machine for two-group classification (Aim) problems.", "labels": [], "entities": [{"text": "two-group classification (Aim)", "start_pos": 75, "end_pos": 105, "type": "TASK", "confidence": 0.8144770264625549}]}, {"text": "The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very highdimension feature space (Method).", "labels": [], "entities": []}, {"text": "In this feature space, a linear decision surface is constructed.\"", "labels": [], "entities": []}, {"text": "We extract these concepts from Title, Abstract and Citation Contexts of a research paper.", "labels": [], "entities": [{"text": "Abstract", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9560802578926086}]}, {"text": "These sections can be accurately automatically extracted from research papers.", "labels": [], "entities": []}, {"text": "Title and Abstract work as a short and to the point summary of work done in the paper.", "labels": [], "entities": []}, {"text": "They are an essential place to find the exact phrases for these concepts without the introduction of too much noise.", "labels": [], "entities": []}, {"text": "Citation context is the text around the citation marker.", "labels": [], "entities": []}, {"text": "This text serves as \"micro summaries\" of a cited paper and phrases in this text are important candidates for aim, method or result of the cited paper.", "labels": [], "entities": [{"text": "aim", "start_pos": 109, "end_pos": 112, "type": "METRIC", "confidence": 0.9863806366920471}]}, {"text": "We combine data mining and natural language techniques to solve the problem scalably in a semi-supervised manner.", "labels": [], "entities": []}, {"text": "Graph representations like knowledge graph that link the information of a large body of publications can reveal patterns and lead to the discovery of new information that would not be apparent from the analysis of just one publication.", "labels": [], "entities": []}, {"text": "Analysis on top of these representations can lead to new scientific insights and discovery of trends in a research area.", "labels": [], "entities": []}, {"text": "They can also facilitate some other tasks like assigning reviewers, recommending relevant papers or improving scientific search engines.", "labels": [], "entities": []}, {"text": "Therefore, we propose to build graphical representation by extracting phrases representing the concepts Aim, Method and Result from scientific publications.", "labels": [], "entities": []}, {"text": "We introduce these phrases as additional nodes and connect them to their corresponding paper nodes in the citation graph.", "labels": [], "entities": []}, {"text": "We argue that the citation network is an integral part of scientific knowledge graph and the proposed representation can adequately summarize the research community.", "labels": [], "entities": []}, {"text": "Proposed graph is shown in.", "labels": [], "entities": []}, {"text": "Contributions: Our key contributions are: (i) We propose a novel, scalable, semi-supervised and domain-independent method for extracting concepts, aim, method and result from the vast available raw scientific literature by using domain- based word embeddings and data mining techniques.", "labels": [], "entities": []}, {"text": "Our approach also takes Citation Context into account apart from Title and Abstract on which most of the work relied till now.", "labels": [], "entities": [{"text": "Abstract", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.7809703350067139}]}, {"text": "(ii) We experimentally validate our approach and show statistically significant improvements over existing state-of-the-art models.", "labels": [], "entities": []}, {"text": "(iii) We show how the extracted concepts and the available citation graph can be used to represent the research community as a knowledge graph.", "labels": [], "entities": []}, {"text": "(iv) We demonstrate our method on a large multi-domain dataset built with the help of DBLP citation network.", "labels": [], "entities": [{"text": "DBLP citation network", "start_pos": 86, "end_pos": 107, "type": "DATASET", "confidence": 0.8291338682174683}]}, {"text": "Our dataset consists of 332,793 papers and 1,508,560 links between them.", "labels": [], "entities": []}, {"text": "(v) We present a case study on the computational linguistics community and computer vision community using the three concepts extracted from its articles, for verifying the results of our system and for showing domain independence of our approach.", "labels": [], "entities": []}, {"text": "Our research background, hypothesis, and motivation were presented in this section.", "labels": [], "entities": []}, {"text": "In the following section, we describe proposed approach in detail.", "labels": [], "entities": []}, {"text": "Finally, we present our datasets, experiments, and results and briefly summarize state-ofthe-art approaches before concluding the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "Dataset Creation: All the experiments were conducted on DBLP Citation Network (version 7) dataset.", "labels": [], "entities": [{"text": "Dataset Creation", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.6966263949871063}, {"text": "DBLP Citation Network (version 7) dataset", "start_pos": 56, "end_pos": 97, "type": "DATASET", "confidence": 0.9343971014022827}]}, {"text": "This dataset is an extensive collection of computer science papers.", "labels": [], "entities": []}, {"text": "DBLP only provides citation-link information, abstract, and paper titles.", "labels": [], "entities": [{"text": "DBLP", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.966566264629364}]}, {"text": "For the full text of these papers, we use the same dataset as have been used by.", "labels": [], "entities": []}, {"text": "This dataset is partly noisy with some duplicate paper information, and there is alack of unique one-to-one mapping from the DBLP paper ids to the actual text of that paper.", "labels": [], "entities": [{"text": "DBLP paper ids", "start_pos": 125, "end_pos": 139, "type": "DATASET", "confidence": 0.9050470193227133}]}, {"text": "During the creation of our final dataset, we either pruned out ambiguous papers or manually resolved the conflicts.", "labels": [], "entities": []}, {"text": "We came up with a final set of 465,355 papers from the DBLP corpus for which we have full text available.", "labels": [], "entities": [{"text": "DBLP corpus", "start_pos": 55, "end_pos": 66, "type": "DATASET", "confidence": 0.9655396044254303}]}, {"text": "Since we need papers that are connected via citation relations, we prune our dataset by taking only the largest connected component in the citation network while considering the links to be bidirectional.", "labels": [], "entities": []}, {"text": "We get 332,793 papers having 1,508,560 citation links.", "labels": [], "entities": []}, {"text": "For extraction of citation context, we used Parscit ().", "labels": [], "entities": [{"text": "extraction", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.9661855101585388}, {"text": "Parscit", "start_pos": 44, "end_pos": 51, "type": "METRIC", "confidence": 0.9009162783622742}]}, {"text": "For RESULT, we manually annotated titles and abstracts of 100 research publications in computer science domain.", "labels": [], "entities": [{"text": "RESULT", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.5150884985923767}]}, {"text": "(b) While generating vector encoding for context phrases, we limit the length of the context phrase to 25 in-order to handle very long sentences.", "labels": [], "entities": []}, {"text": "We used cosine distance to measure distance between vector representation of the phrases.", "labels": [], "entities": []}, {"text": "(c) It maybe possible that there are more than one concept mention in a sentence.", "labels": [], "entities": []}, {"text": "To nullify the effect of other concept mentions, we generated the seed features list in two ways: \u2022   before generating their embedding.", "labels": [], "entities": []}, {"text": "This is called as masked feature list.", "labels": [], "entities": []}, {"text": "Experiments were done for masked and unmasked feature lists separately.", "labels": [], "entities": []}, {"text": "(d) As number of phrases added per iteration decreased substantially after iteration 5, we ran only 5 iterations of bootstrapping algorithm for all the experiments.", "labels": [], "entities": []}, {"text": "(e) We experimented with different values of distance rand k.", "labels": [], "entities": [{"text": "distance rand k", "start_pos": 45, "end_pos": 60, "type": "METRIC", "confidence": 0.8752869168917338}]}, {"text": "We observed that in general precision increases with increase in value of k and recall increases with decrease in value of r.", "labels": [], "entities": [{"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9989718198776245}, {"text": "recall", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.9995951056480408}]}, {"text": "Evaluation: For evaluating our results, we use the labeled dataset made available by.", "labels": [], "entities": []}, {"text": "We used 197 out of 474 papers for evaluation purpose.", "labels": [], "entities": []}, {"text": "We calculate precision, recall and f1 score for each class.", "labels": [], "entities": [{"text": "precision", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.9998238682746887}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9996861219406128}, {"text": "f1 score", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9689342081546783}]}, {"text": "However, as Result phrases were not annotated in that dataset, we could evaluate only for Aim and Method.", "labels": [], "entities": []}, {"text": "We compare our proposed approach with) which ran the bootstrapping algorithm fora similar problem but used n-gram based features.", "labels": [], "entities": []}, {"text": "They reported results for ACL Anthopology Network(AAN) Corpus ().", "labels": [], "entities": [{"text": "ACL Anthopology Network(AAN) Corpus", "start_pos": 26, "end_pos": 61, "type": "DATASET", "confidence": 0.8606669562203544}]}, {"text": "We ran their algorithm on our dataset with parameter tuning as mentioned by them.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: f1, precision & recall score for AIM concept", "labels": [], "entities": [{"text": "precision", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9997031092643738}, {"text": "recall score", "start_pos": 26, "end_pos": 38, "type": "METRIC", "confidence": 0.9772657155990601}, {"text": "AIM", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.9198037385940552}]}, {"text": " Table 2: f1, precision & recall score for METHOD  concept", "labels": [], "entities": [{"text": "precision", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9997369647026062}, {"text": "recall score", "start_pos": 26, "end_pos": 38, "type": "METRIC", "confidence": 0.977961391210556}, {"text": "METHOD", "start_pos": 43, "end_pos": 49, "type": "DATASET", "confidence": 0.6731318831443787}]}, {"text": " Table 3:  Comparison with state-of-the-art for  METHOD Concept", "labels": [], "entities": [{"text": "METHOD", "start_pos": 49, "end_pos": 55, "type": "DATASET", "confidence": 0.7811641097068787}]}, {"text": " Table 4: Comparison with state-of-the-art for AIM  Concept on DBLP dataset", "labels": [], "entities": [{"text": "DBLP dataset", "start_pos": 63, "end_pos": 75, "type": "DATASET", "confidence": 0.8510794937610626}]}]}