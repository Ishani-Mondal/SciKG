{"title": [{"text": "An evaluation of Czech word embeddings", "labels": [], "entities": []}], "abstractContent": [{"text": "We present an evaluation of Czech low-dimensional distributed word representations , also known as word embeddings.", "labels": [], "entities": []}, {"text": "We describe five different approaches to training the models and three different corpora used in training.", "labels": [], "entities": []}, {"text": "We evaluate the resulting models on five different datasets, report the results and provide their further analysis.", "labels": [], "entities": []}], "introductionContent": [{"text": "Distributed word representations, often referred to as word embeddings, have received a lot of attention in recent years, and they have been used to improve results in many NLP tasks.", "labels": [], "entities": []}, {"text": "The term itself refers to representing words as low-dimensional real-valued vectors (usually with dimensionality of 50-1000), and is opposed to explicit sparse representations, i.e. representing words as highdimensional vectors of 0s and 1s (usually with dimensionality in the tens of thousands).", "labels": [], "entities": []}, {"text": "Many different models have been proposed (see section 2).", "labels": [], "entities": []}, {"text": "By their nature, these models are language-independent (given the language can be tokenized) but usually the reported results are measured using only English.", "labels": [], "entities": []}, {"text": "This is encouraged not only by English being the standard scientific language, but also by the availability of English text corpora and, even more importantly, English datasets to evaluate the models on.", "labels": [], "entities": []}, {"text": "We have decided to perform an intrinsic evaluation of embedding models on Czech.", "labels": [], "entities": [{"text": "Czech", "start_pos": 74, "end_pos": 79, "type": "DATASET", "confidence": 0.9676869511604309}]}, {"text": "We have identified several successful models to evaluate, collected existing datasets to evaluate them on and designed two more datasets to extend the evaluation.", "labels": [], "entities": []}, {"text": "We should note that we do not perform downstream-task evaluation, even though it might not correlate well with the intrinsic evaluation ().", "labels": [], "entities": []}, {"text": "We also use the models with their default parameters and only try changing the corpus they are trained on.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: first, we describe related work (section 2).", "labels": [], "entities": []}, {"text": "We continue with a description of selected models (section 3), corpora used in training (section 4) and the datasets (section 5).", "labels": [], "entities": []}, {"text": "Finally, we present the results (section 6).", "labels": [], "entities": []}], "datasetContent": [{"text": "We describe the existing (as well as no-longerexisting) datasets suitable for the evaluation of Czech word embeddings.", "labels": [], "entities": [{"text": "evaluation of Czech word embeddings", "start_pos": 82, "end_pos": 117, "type": "TASK", "confidence": 0.6366499066352844}]}], "tableCaptions": [{"text": " Table 1: Results on syntactic analogies; numbers were always kept in place; both Word2Vec and fastText  were trained using CBOW architecture", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 82, "end_pos": 90, "type": "DATASET", "confidence": 0.9637157917022705}, {"text": "fastText", "start_pos": 95, "end_pos": 103, "type": "DATASET", "confidence": 0.9027994275093079}]}, {"text": " Table 2: Results on semantic analogies;", "labels": [], "entities": []}, {"text": " Table 3: Results on extended analogies; all models were trained using Word2Vec with CBOW architec- ture, corpus was always lemmatized", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 71, "end_pos": 79, "type": "DATASET", "confidence": 0.9610933065414429}]}, {"text": " Table 4: Results (Spearman correlation coefficient) on similarity tasks; All models were trained on  lemmatized corpus; fastText was trained using CBOW architecture", "labels": [], "entities": [{"text": "Spearman correlation coefficient", "start_pos": 19, "end_pos": 51, "type": "METRIC", "confidence": 0.6531110803286234}, {"text": "fastText", "start_pos": 121, "end_pos": 129, "type": "DATASET", "confidence": 0.9184261560440063}]}, {"text": " Table 5: Results on synonym retrieval; Models  were trained using Word2Vec/CBOW on lemma- tized CNC", "labels": [], "entities": [{"text": "synonym retrieval", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.9590776860713959}, {"text": "Word2Vec/CBOW", "start_pos": 67, "end_pos": 80, "type": "DATASET", "confidence": 0.8319175640741984}]}, {"text": " Table 6: Approximation of parameter volatility given by the distribution of performance differences  (percent points) when altering the parameter with all remaining parameters fixed; Minimum difference  is always 0; similarity objective is only taken into account on analogy tasks; * line refers to values when  skipping noun plural, past tense, pronouns and gradation which are by nature unsolvable by lemmata- based models", "labels": [], "entities": [{"text": "Approximation", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.989932656288147}, {"text": "Minimum difference", "start_pos": 184, "end_pos": 202, "type": "METRIC", "confidence": 0.9741027653217316}]}]}