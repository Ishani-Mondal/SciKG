{"title": [], "abstractContent": [], "introductionContent": [{"text": "This is the second edition of the Workshop on Computational Models of Reference, Anaphora and Coreference (CRAC), which was first held in New Orleans last year in conjunction with NAACL HLT 2018.", "labels": [], "entities": [{"text": "NAACL HLT 2018", "start_pos": 180, "end_pos": 194, "type": "DATASET", "confidence": 0.8512551387151083}]}, {"text": "CRAC and its predecessor, the Coreference Resolution Beyond OntoNotes (CORBON) workshop series that started in 2016, have arguably become the primary forum for coreference researchers to present their latest results since the demise of the Discourse Anaphora and Anaphor Resolution Colloquium series in 2011.", "labels": [], "entities": [{"text": "CRAC", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.884885847568512}, {"text": "Coreference Resolution Beyond OntoNotes (CORBON) workshop series", "start_pos": 30, "end_pos": 94, "type": "TASK", "confidence": 0.8797996838887533}]}, {"text": "While CORBON focuses on under-investigated coreference phenomena, CRAC has a broader scope, covering all cases of computational modeling of reference, anaphora, and coreference.", "labels": [], "entities": []}, {"text": "The workshop received 10 submissions: half of them were from Europe, two were from the U.S., and the remaining three were from India.", "labels": [], "entities": []}, {"text": "We are pleased to see that the submissions covered not only a variety of less-studied languages in the coreference community (e.g., Basque, French, German, Malayalam or Tamil) but also many under-investigated topics in coreference resolution (e.g., feature representation, coreference for low-resource languages, coreference in specialized domains, and evaluation of coreference resolvers).", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 219, "end_pos": 241, "type": "TASK", "confidence": 0.9319685697555542}, {"text": "feature representation", "start_pos": 249, "end_pos": 271, "type": "TASK", "confidence": 0.7955032289028168}]}, {"text": "While it is perhaps not surprising to receive submissions focusing on the design and use of neural models for coreference resolution given the recent popularity of deep learning for natural language processing, it is interesting to see that the most popular topic among the submitted papers is cross-lingual coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 110, "end_pos": 132, "type": "TASK", "confidence": 0.9405035078525543}, {"text": "cross-lingual coreference resolution", "start_pos": 294, "end_pos": 330, "type": "TASK", "confidence": 0.7184888323148092}]}, {"text": "In fact, one of the workshop sessions will be devoted entirely to this topic.", "labels": [], "entities": []}, {"text": "As in previous years, each submission was rigorously reviewed by three to five programme committee members.", "labels": [], "entities": []}, {"text": "We would like to thank the 18 programme committee members for their hard work.", "labels": [], "entities": []}, {"text": "Based on their recommendations, we initially accepted four papers and conditionally accepted two papers.", "labels": [], "entities": []}, {"text": "Both conditionally accepted papers were eventually accepted to the workshop after we made sure that the authors adequately addressed the reviewers' comments in the final camera-ready version.", "labels": [], "entities": []}, {"text": "All of the accepted papers will be presented orally.", "labels": [], "entities": []}, {"text": "We are grateful to Amir Zeldes for accepting our invitation to be this year's invited speaker.", "labels": [], "entities": []}, {"text": "Amir will give a talk on coreference, discourse structure and coherence.", "labels": [], "entities": []}, {"text": "Finally, we would like to thank the workshop participants for joining in.", "labels": [], "entities": []}, {"text": "We look forward to an exciting workshop in Minneapolis.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}