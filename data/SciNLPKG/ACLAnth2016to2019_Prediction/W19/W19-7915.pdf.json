{"title": [{"text": "What can we learn from natural and artificial dependency trees", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper is centered around two main contributions : the first one consists in introducing several procedures for generating random dependency trees with constraints; we later use these artificial trees to compare their properties with the properties of natural trees (i.e trees extracted from treebanks) and analyze the relationships between these properties in natural and artificial settings in order to find out which relationships are formally constrained and which are linguistically motivated.", "labels": [], "entities": []}, {"text": "We take into consideration five metrics: tree length, height, maximum arity, mean dependency distance and mean flux weight, and also look into the distribution of local configurations of nodes.", "labels": [], "entities": []}, {"text": "This analysis is based on UD treebanks (version 2.3, Nivre et al.", "labels": [], "entities": [{"text": "UD treebanks", "start_pos": 26, "end_pos": 38, "type": "DATASET", "confidence": 0.8622137606143951}]}, {"text": "2018) for four languages: Chinese, English, French and Ja-panese.", "labels": [], "entities": []}], "introductionContent": [{"text": "We are interested in looking at the linguistic constraints on syntactic dependency trees to understand what makes certain structures plausible while others are not so plausible.", "labels": [], "entities": []}, {"text": "To effectively do this kind of work, we need to observe natural trees (syntactic trees that are the results of linguistic analysis) to see what this population looks like.", "labels": [], "entities": []}, {"text": "Similar work has been done for example by on the relation between sentence length, dependency distance and dependency direction.", "labels": [], "entities": []}, {"text": "But observing natural trees only has its limits : we cannot see what is special about them and their properties, and we cannot distinguish the effects of the various constraints that affect them.", "labels": [], "entities": []}, {"text": "We can only observe the structures that are the result of all these constraints and their interactions.", "labels": [], "entities": []}, {"text": "On the other hand, if we start from a blank canvas, randomly generated trees, and incrementally add constraints on these trees, we might be able to study one by one the effects of each constraint, and to progressively add them to get closer to natural trees.", "labels": [], "entities": []}, {"text": "Using artificially generated trees can also be insightful to determine which constraints are formally motivated (they area result of the mathematical structure of the tree) and which constraints are linguistically or cognitively motivated.", "labels": [], "entities": []}, {"text": "Research in the line of who have used random and optimal linearisations to study dependency length and its varying degrees of minimization can help us to discover constraints that would be helpful to explain why we only find a small subset of all potential trees in syntactic analyses on real data.", "labels": [], "entities": []}, {"text": "Our objective is therefore twofold: first we want to see how different properties of syntactic dependency trees correlate, in particular properties that are related to syntactic complexity such as height, mean dependency distance and mean flux weight, then we want to find out if these properties can allow us to distinguish between artificial dependency trees (trees that have been manipulated using random components and constraints), and dependency trees from real data.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}