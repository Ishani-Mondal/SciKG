{"title": [{"text": "Multiple Admissibility in Language Learning: Judging Grammaticality Using Unlabeled Data", "labels": [], "entities": [{"text": "Judging Grammaticality", "start_pos": 45, "end_pos": 67, "type": "TASK", "confidence": 0.892348974943161}]}], "abstractContent": [{"text": "We present our work on the problem of detection Multiple Admissibility (MA) in language learning.", "labels": [], "entities": [{"text": "detection Multiple Admissibility (MA)", "start_pos": 38, "end_pos": 75, "type": "TASK", "confidence": 0.7588962117830912}]}, {"text": "Multiple Admissibility occurs when more than one grammatical form of a word fits syntactically and semantically in a given context.", "labels": [], "entities": []}, {"text": "In second-language education-in particular , in intelligent tutoring systems/computer-aided language learning (ITS/CALL), systems generate exercises automatically.", "labels": [], "entities": []}, {"text": "MA implies that multiple alternative answers are possible.", "labels": [], "entities": [{"text": "MA", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.9678198099136353}]}, {"text": "We treat the problem as a grammatical-ity judgement task.", "labels": [], "entities": []}, {"text": "We train a neural network with an objective to label sentences as grammatical or ungrammatical, using a \"simulated learner corpus\": a dataset with correct text and with artificial errors, generated automatically.", "labels": [], "entities": []}, {"text": "While MA occurs commonly in many languages, this paper focuses on learning Rus-sian.", "labels": [], "entities": [{"text": "MA", "start_pos": 6, "end_pos": 8, "type": "TASK", "confidence": 0.9733951091766357}]}, {"text": "We present a detailed classification of the types of constructions in Russian, in which MA is possible, and evaluate the model using a test set built from answers provided by users of the Revita language learning system.", "labels": [], "entities": [{"text": "MA", "start_pos": 88, "end_pos": 90, "type": "METRIC", "confidence": 0.7565343976020813}, {"text": "Revita language learning system", "start_pos": 188, "end_pos": 219, "type": "DATASET", "confidence": 0.8860642313957214}]}], "introductionContent": [{"text": "The problem of Multiple Admissibility (MA) occurs in the context of language learning.", "labels": [], "entities": [{"text": "Multiple Admissibility (MA)", "start_pos": 15, "end_pos": 42, "type": "TASK", "confidence": 0.794324541091919}]}, {"text": "In \"cloze\" exercises (fill-in-the-blank), the learner receives a text with some word removed, and abase form 1 of the removed word as a hint.", "labels": [], "entities": []}, {"text": "The task is to produce the correct grammatical form of the missing word, given the context.", "labels": [], "entities": []}, {"text": "The answer given by the user is checked automatically by the language learning system.", "labels": [], "entities": []}, {"text": "Therefore, the system should be able to accept more than one answer, if there are grammatically and semantically valid alternatives in the given context.", "labels": [], "entities": []}, {"text": "Otherwise, the language learning system returns negative (actually incorrect) feedback to the learner.", "labels": [], "entities": []}, {"text": "This is a problem, because negative feedback for an acceptable answer misleads and discourages the learner.", "labels": [], "entities": []}, {"text": "We examine MA in the context of our language learning system, Revita (.", "labels": [], "entities": [{"text": "MA", "start_pos": 11, "end_pos": 13, "type": "TASK", "confidence": 0.9467088580131531}, {"text": "Revita", "start_pos": 62, "end_pos": 68, "type": "DATASET", "confidence": 0.972313642501831}]}, {"text": "Revita is available online 2 for second language (L2) learning beyond the beginner level.", "labels": [], "entities": [{"text": "Revita", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9299241900444031}]}, {"text": "It is in use in official university-level curricula at several major universities.", "labels": [], "entities": []}, {"text": "It covers several languages, many of which are highly inflectional, with rich morphology.", "labels": [], "entities": []}, {"text": "Revita creates a variety of exercises based on input text materials, which are selected by the users.", "labels": [], "entities": []}, {"text": "It generates exercises and assesses the users' answers automatically.", "labels": [], "entities": []}, {"text": "For example, consider the sentence in Finnish: \"Ilmoitus vaaleista tulee kotiin postissa .\" (\"Notice about elections comes to the house in the mail.\")", "labels": [], "entities": []}, {"text": "In practice mode, Revita presents the text to the learner in small pieces-\"snippets\" (about 1 paragraph each)-with all generated exercises.", "labels": [], "entities": []}, {"text": "This is important, because grammatical forms in exercises usually depend on a wider context.", "labels": [], "entities": []}, {"text": "For the given example, Revita can generate cloze exercises hiding several tokens (surface forms) and providing their lemmas as hints: \"Ilmoitus vaali tulla koti posti .\" (\"Notice election come house mail .\").", "labels": [], "entities": []}, {"text": "For the verb \"tulla\" (\"come\") and nouns \"vaali\" (\"election\"), \"koti\" (\"home\") and \"posti\" (\"mail\") the learner should insert the correct grammatical forms.", "labels": [], "entities": []}, {"text": "Revita expects them to be the same as the forms in the original text, and will return negative feedback otherwise.", "labels": [], "entities": [{"text": "Revita", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9260191917419434}]}, {"text": "However, in this example, postitse (\"via email\") is also acceptable, although it is not in the original text.", "labels": [], "entities": []}, {"text": "The MA problem is also relevant in the context of exercises that require a free-form answer, such as an answer to a question or an essay.", "labels": [], "entities": [{"text": "MA problem", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.9096078872680664}]}, {"text": "The learner can produce \"unexpected\" but nevertheless valid grammatical forms.", "labels": [], "entities": []}, {"text": "In the current work, we restrict our focus to MA of multiple surface forms of the same lemma, given the context; we do not consider synonyms, which can also fit the same context.", "labels": [], "entities": []}, {"text": "The latter topic is part of the future work.", "labels": [], "entities": []}, {"text": "The structure of the paper is as follows: In section 2 we formulate the problem and provide a detailed classification of the types of MA found in the learner data.", "labels": [], "entities": []}, {"text": "In section 3 we describe our approach, in particular, the procedure for generating artificial grammatical errors and creating test sets.", "labels": [], "entities": []}, {"text": "Section 4 presents previous work on artificial error generation.", "labels": [], "entities": [{"text": "artificial error generation", "start_pos": 36, "end_pos": 63, "type": "TASK", "confidence": 0.6520365178585052}]}, {"text": "Section 5 describes our model and experimental setup.", "labels": [], "entities": []}, {"text": "In section 6 we discuss the results and error analysis, and conclude in section 7.", "labels": [], "entities": [{"text": "error analysis", "start_pos": 40, "end_pos": 54, "type": "METRIC", "confidence": 0.9092797636985779}]}], "datasetContent": [{"text": "Data: For generating the training/validation datasets, we use the open-source \"Taiga\" Russian corpus, 16 which is arranged by genre into several segments.", "labels": [], "entities": [{"text": "Taiga\" Russian corpus", "start_pos": 79, "end_pos": 100, "type": "DATASET", "confidence": 0.682296633720398}]}, {"text": "We used all news segments, and part of the literary text segment, fora total of 809M words.", "labels": [], "entities": []}, {"text": "We exclude social media, film subtitles, and poems, because their language has more deviations from the literary standard.", "labels": [], "entities": []}, {"text": "All documents were lowercased, tokenized, and morphologically analyzed using Crosslator ().", "labels": [], "entities": [{"text": "Crosslator", "start_pos": 77, "end_pos": 87, "type": "DATASET", "confidence": 0.8922907114028931}]}, {"text": "We replace all punctuation marks with a special token, to preserve information about sentence/clause boundaries.", "labels": [], "entities": []}, {"text": "The size of the training vocabulary was around 1.2M words (after removing words with frequency less than 2).", "labels": [], "entities": []}, {"text": "For validation, we randomly chose 5% of all generated data.", "labels": [], "entities": [{"text": "validation", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.975447416305542}]}, {"text": "Model architecture: our baseline neural network (NN) is implemented in TensorFlow.", "labels": [], "entities": []}, {"text": "Its architecture is a one-layer bidirectional LSTM with dropout (0.2), which has 512 hidden units.", "labels": [], "entities": []}, {"text": "The hidden state of the BiLSTM is then fed to an Multi-layer Perceptron (MLP).", "labels": [], "entities": []}, {"text": "The MLP uses one hidden layer with 1024 neurons, and Leaky ReLU activation function.", "labels": [], "entities": [{"text": "Leaky ReLU activation", "start_pos": 53, "end_pos": 74, "type": "METRIC", "confidence": 0.5266598562399546}]}, {"text": "The size of the output layer is 1, since we have only two classes to predict.", "labels": [], "entities": []}, {"text": "The output of the MLP is then fed to a sigmoid activation function to obtain a prediction for the entire input sequence.", "labels": [], "entities": []}, {"text": "To encode words, we use the FastText 300-dimensional pre-trained embeddings.", "labels": [], "entities": []}, {"text": "The network and the word embeddings were trained in an end-to-end fashion.", "labels": [], "entities": []}, {"text": "Optimization was done using Adam, dropout, and early stopping based on the loss on the validation set.", "labels": [], "entities": []}, {"text": "We trained the network over only half of an epoch, since it was showing signs of overfitting-because we use a sliding window, the number of training instances was over 90M.", "labels": [], "entities": []}, {"text": "The averaged accuracy on the validation set was 95 %.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9974935054779053}, {"text": "validation", "start_pos": 29, "end_pos": 39, "type": "TASK", "confidence": 0.9592827558517456}]}, {"text": "reports the accuracy on the test sets, averaged across 5 runs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9997342228889465}]}, {"text": "shows the results of our experiments in terms of accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9995937943458557}]}, {"text": "85.9% accuracy was achieved across all types of MA.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 6, "end_pos": 14, "type": "METRIC", "confidence": 0.9995803236961365}, {"text": "MA", "start_pos": 48, "end_pos": 50, "type": "TASK", "confidence": 0.8961775302886963}]}, {"text": "However, we should stress that in the test set marked Multi-admissible (MA), the majority of the instances belong to the MA types of Present/Past tense and Singular/Plural.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Data we annotated for verification and testing: (1) subset of the set of errors automatically generated for  training (randomly sampled and manually annotated), (2) learners' answers (randomly sampled), marked by the  System as incorrect, (3) subset of learner' incorrect answers-for advanced learners only (CEFR level C1/C2).  \"Broken\": discarded instances (technical problems, too many unknown words, numbers, punctuation marks, etc.)", "labels": [], "entities": []}, {"text": " Table 2: Percent accuracy of our NN model. Random  correct: test set built from sentences which were not in- cluded in the training and validation sets and did not ap- pear in Revita's database, randomly selected sentences  from normal texts. Grammatically incorrect: test set  with real grammatical errors from students' data. Prag- matic errors: test set with real pragmatic errors from  students' data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9772869348526001}, {"text": "Revita's database", "start_pos": 177, "end_pos": 194, "type": "DATASET", "confidence": 0.9345287879308065}]}, {"text": " Table 3: Percent accuracy of our NN model for dif- ferent MA contexts. Case combines all types of MA  contexts listed in the Subsection 2.1 which differ by  case (Nominative/Instrumental, Genitive/Accusative  and others).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.952098548412323}]}]}