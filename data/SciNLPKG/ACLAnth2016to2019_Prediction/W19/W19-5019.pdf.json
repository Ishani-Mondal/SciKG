{"title": [{"text": "BioRelEx 1.0: Biological Relation Extraction Benchmark", "labels": [], "entities": [{"text": "Biological Relation Extraction Benchmark", "start_pos": 14, "end_pos": 54, "type": "TASK", "confidence": 0.751295693218708}]}], "abstractContent": [{"text": "Automatic extraction of relations and interactions between biological entities from scientific literature remains an extremely challenging problem in biomedical information extraction and natural language processing in general.", "labels": [], "entities": [{"text": "Automatic extraction of relations and interactions between biological entities from scientific literature", "start_pos": 0, "end_pos": 105, "type": "TASK", "confidence": 0.8800315707921982}, {"text": "biomedical information extraction", "start_pos": 150, "end_pos": 183, "type": "TASK", "confidence": 0.6200332144896189}, {"text": "natural language processing", "start_pos": 188, "end_pos": 215, "type": "TASK", "confidence": 0.6706874370574951}]}, {"text": "One of the reasons for slow progress is the relative scarcity of standardized and publicly available benchmarks.", "labels": [], "entities": []}, {"text": "In this paper we introduce BioRelEx, anew dataset of fully annotated sentences from biomedical literature that capture binding interactions between proteins and/or biomolecules.", "labels": [], "entities": []}, {"text": "To foster reproducible research on the interaction extraction task, we define a precise and transparent evaluation process, tools for error analysis and significance tests.", "labels": [], "entities": [{"text": "interaction extraction task", "start_pos": 39, "end_pos": 66, "type": "TASK", "confidence": 0.7921741406122843}, {"text": "error analysis", "start_pos": 134, "end_pos": 148, "type": "TASK", "confidence": 0.663231760263443}]}, {"text": "Finally, we conduct extensive experiments to evaluate several baselines, including SciIE, a recently introduced neural multi-task architecture that has demonstrated state-of-the-art performance on several tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "Biological interaction databases capture a small portion of knowledge depicted in biomedical papers, due to time consuming nature of manual information extraction.", "labels": [], "entities": []}, {"text": "As experimental methodologies to identify such interactions tend to increase in scale and throughput, the problem stands to rapidly update these databases for relevant applications ().", "labels": [], "entities": []}, {"text": "The long-term aim of our efforts is to provide bases for filling this gap automatically.", "labels": [], "entities": []}, {"text": "Despite significant progress in recent years, extracting relationships and interactions between different biological entities is still an extremely chellenging problem.", "labels": [], "entities": [{"text": "extracting relationships and interactions between different biological entities", "start_pos": 46, "end_pos": 125, "type": "TASK", "confidence": 0.7573076039552689}]}, {"text": "Some of those challenges are due to objective reasons such as lack of very large annotated datasets for training complex models, or wide variability in biomedical literature which can lead to domain mismatch and poor generalization.", "labels": [], "entities": []}, {"text": "Another important challenge, which is the main focus of the present paper, is the scarcity of publicly available datasets.", "labels": [], "entities": []}, {"text": "Indeed, with despite some notable exceptions (, there is a relative lack of adequate, highquality benchmark datasets which would facilitate reproducible research and allow for robust comparative evaluation of existing approaches.", "labels": [], "entities": []}, {"text": "Here we have processed biological texts to annotate biological entities and interaction pairs.", "labels": [], "entities": []}, {"text": "In contrast to other related databases, our efforts were focused on delineation of biological entities from experimental ones, and on distinguishing between indirect regulatory interactions and direct physical interactions.", "labels": [], "entities": []}, {"text": "Furthermore, we have performed grounding via cross-reference of annotated entities with external databases.", "labels": [], "entities": []}, {"text": "This allows for merging interactions from different sources into a single network of biomolecular interactions.", "labels": [], "entities": []}, {"text": "The main contributions of this work are: 1.", "labels": [], "entities": []}, {"text": "We publish a dataset of 2010 sentences with complete annotations of biological entities and binding interactions between the entities, 2.", "labels": [], "entities": []}, {"text": "We propose a benchmark task with a welldefined evaluation system, which follows the best practices of machine learning research, 3.", "labels": [], "entities": []}, {"text": "We perform extensive evaluation of several competing methods on the dataset and report the results.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have annotated 2010 sentences for binding interactions between biological entities.", "labels": [], "entities": []}, {"text": "Those sentences came from a much larger set of 40,000 sentences that were automatically extracted from var-ious biomedical journals and underwent minimal manual post-processing.", "labels": [], "entities": []}, {"text": "While the original set contained numerous interaction types, here our focus is on binding interactions only.", "labels": [], "entities": []}, {"text": "The text of the sentences are mostly copied from the journal websites and can include uncommon Unicode symbols.", "labels": [], "entities": []}, {"text": "In rare cases we had to copy the sentences from PDF versions of the papers and manually fix incorrect characters.", "labels": [], "entities": []}, {"text": "As stated above, the current version of the dataset is focused on binding interactions.", "labels": [], "entities": []}, {"text": "All sentences in the dataset contain one of the following words: \"bind\", \"binds\", \"binding\", \"bound\".", "labels": [], "entities": []}, {"text": "This will potentially limit the applicability of the models trained on this dataset on other sentences that contain information about binding interactions.", "labels": [], "entities": []}, {"text": "The lengths of sentences vary from 3 to 138.", "labels": [], "entities": []}, {"text": "The median length is 29, the mean is around 30. 95% of all sentences have less than 50.", "labels": [], "entities": [{"text": "mean", "start_pos": 29, "end_pos": 33, "type": "METRIC", "confidence": 0.9918743968009949}]}, {"text": "The average number of entity clusters per sentence is 3.92, while the average number of entity mentions per sentence is 4.91.", "labels": [], "entities": []}, {"text": "On average, there are 1.61 interaction per sentence.", "labels": [], "entities": []}, {"text": "We used Cytoscape () to construct a graph based on positive interactions annotated from our dataset.", "labels": [], "entities": []}, {"text": "It has 2248 nodes (entities) and 3235 edges (interactions) (see in Appendix A.5).", "labels": [], "entities": []}, {"text": "The graph had a large connected component, containing 65% (1475) of nodes and 81% (2635) of edges.", "labels": [], "entities": []}, {"text": "Many interactions were annotated multiple times, with 67% (2177) of unique interactions, and up to 11 duplications per entity pair.", "labels": [], "entities": []}, {"text": "The graph showed smallworld properties, with average shortest path between any pairs of nodes being 5, and with very few hub nodes.", "labels": [], "entities": []}, {"text": "Degrees range from 1 to 83 with median 1.", "labels": [], "entities": [{"text": "median 1", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.918419599533081}]}, {"text": "compares BioRelEx 1.0 with the popular related datasets.", "labels": [], "entities": []}, {"text": "The original version of AIMed has similar number of sentences to BioRelEx, but the number of annotated relations is significantly lower due to different annotation guidelines and choice of sentences.", "labels": [], "entities": []}, {"text": "BioInfer contains fewer sentences with a lot more detailed annotations, which is not suitable for the current machine learning techniques, hence most of the models designed for BioInfer simply ignore the details of annotations.", "labels": [], "entities": [{"text": "BioInfer", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8864300847053528}]}, {"text": "Both datasets do not have corresponding well-defined benchmarks.", "labels": [], "entities": []}, {"text": "The five datasets in a unified format from (Pyysalo et al., 2008a) suit better for machine learning research, but they are limited to relation classification tasks.", "labels": [], "entities": [{"text": "relation classification tasks", "start_pos": 134, "end_pos": 163, "type": "TASK", "confidence": 0.8794954021771749}]}, {"text": "The dataset for BioCreative VI Precision Medicine Track has 6.5 times more sentences than BioRelEx 1.0, but has two times less relations, as it is focused on a more rare kind of interactions.", "labels": [], "entities": [{"text": "BioCreative VI Precision Medicine Track", "start_pos": 16, "end_pos": 55, "type": "TASK", "confidence": 0.5990221500396729}]}, {"text": "GENIA corpus is the closest in spirit to ours.", "labels": [], "entities": [{"text": "GENIA corpus", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.9635915160179138}]}, {"text": "It has more detailed annotations and covers more relation types.", "labels": [], "entities": []}, {"text": "As a result, the density of binding interactions in GENIA is much lower (only 2448 binding interactions in 9372 sentences).", "labels": [], "entities": [{"text": "GENIA", "start_pos": 52, "end_pos": 57, "type": "DATASET", "confidence": 0.865122377872467}]}, {"text": "Also, there is a slight difference in the goals of GENIA and BioRelEx.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 51, "end_pos": 56, "type": "DATASET", "confidence": 0.9279370903968811}, {"text": "BioRelEx", "start_pos": 61, "end_pos": 69, "type": "DATASET", "confidence": 0.8857032656669617}]}, {"text": "GENIA is best suited for functional annotation and biomedical search optimization.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9487534165382385}, {"text": "biomedical search optimization", "start_pos": 51, "end_pos": 81, "type": "TASK", "confidence": 0.7318928440411886}]}, {"text": "We however, had a different aim in mindto retrieve interactions in away to make them useful for interaction network generation.", "labels": [], "entities": [{"text": "interaction network generation", "start_pos": 96, "end_pos": 126, "type": "TASK", "confidence": 0.6399942835172018}]}, {"text": "This difference affected the way we have designed the annotation guidelines, as described in the previous subsections.", "labels": [], "entities": []}, {"text": "Because of these differences we did not use the ontologies developed in GENIA.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 72, "end_pos": 77, "type": "DATASET", "confidence": 0.9431977272033691}]}, {"text": "In contrast to all mentioned datasets, BioRelEx includes grounding information for most of the labeled entities.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison of BioRelEx 1.0 with the most popular protein-protein interaction datasets. The ones men- tioned by asterisk are the unified versions from (Pyysalo et al., 2008a)", "labels": [], "entities": []}]}