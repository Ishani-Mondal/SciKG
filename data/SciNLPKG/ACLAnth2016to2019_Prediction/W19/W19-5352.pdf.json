{"title": [{"text": "A Test Suite and Manual Evaluation of Document-Level NMT at WMT19", "labels": [], "entities": [{"text": "WMT19", "start_pos": 60, "end_pos": 65, "type": "DATASET", "confidence": 0.8529382944107056}]}], "abstractContent": [{"text": "As the quality of machine translation rises and neural machine translation (NMT) is moving from sentence to document level translations, it is becoming increasingly difficult to evaluate the output of translation systems.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.7291807532310486}, {"text": "neural machine translation (NMT)", "start_pos": 48, "end_pos": 80, "type": "TASK", "confidence": 0.8199981053670248}]}, {"text": "We provide a test suite for WMT19 aimed at assessing discourse phenomena of MT systems participating in the News Translation Task.", "labels": [], "entities": [{"text": "WMT19", "start_pos": 28, "end_pos": 33, "type": "DATASET", "confidence": 0.6822654008865356}, {"text": "MT", "start_pos": 76, "end_pos": 78, "type": "TASK", "confidence": 0.9569029211997986}, {"text": "News Translation Task", "start_pos": 108, "end_pos": 129, "type": "TASK", "confidence": 0.7887274026870728}]}, {"text": "We have manually checked the outputs and identified types of translation errors that are relevant to document-level translation.", "labels": [], "entities": [{"text": "document-level translation", "start_pos": 101, "end_pos": 127, "type": "TASK", "confidence": 0.6290106922388077}]}], "introductionContent": [{"text": "Currently, the level of machine translation systems can be very good or excellent.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.8106387555599213}]}, {"text": "For some languages, the systems are on par with humans when evaluated at the level of individual sentences, see for Chinese-toEnglish and for English-toCzech translation at WMT18.", "labels": [], "entities": [{"text": "WMT18", "start_pos": 173, "end_pos": 178, "type": "DATASET", "confidence": 0.9769854545593262}]}, {"text": "The main criterion for distinguishing MT systems' quality thus has to shift from evaluating individual sentences to larger units.", "labels": [], "entities": [{"text": "MT", "start_pos": 38, "end_pos": 40, "type": "TASK", "confidence": 0.9234400391578674}]}, {"text": "Ideally, the translated text should be now evaluated as a whole.", "labels": [], "entities": []}, {"text": "We believe that the fundamental criterion of the quality of manual or automatic translation is the extent to which the translation is functional inhuman communication.", "labels": [], "entities": []}, {"text": "These days, the critical basic level in this criterion has been already reached by multiple machine translation systems covering a wide range of language pairs.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 92, "end_pos": 111, "type": "TASK", "confidence": 0.7456332445144653}]}, {"text": "While the reader of an automatically translated text maybe groping at some points in the text, the overall quality of the translation is already so high that the main content of the text and the author's communicative intention is mostly conveyed.", "labels": [], "entities": []}, {"text": "Still, the reader of an MT output takes a higher effort to understand the translated text.", "labels": [], "entities": [{"text": "MT output", "start_pos": 24, "end_pos": 33, "type": "TASK", "confidence": 0.8846968412399292}]}, {"text": "For example, morphological errors, shortcomings in the word order, incorrect syntactic relations, failure in translating terminology, or the choice of inappropriate synonyms can hinder the speed and accuracy of text understanding.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 199, "end_pos": 207, "type": "METRIC", "confidence": 0.9942907094955444}, {"text": "text understanding", "start_pos": 211, "end_pos": 229, "type": "TASK", "confidence": 0.6439026147127151}]}, {"text": "In this paper, we first provide a test suite for WMT19 aimed at assessing translation quality of English to Czech NMT systems regarding document-level language phenomena.", "labels": [], "entities": [{"text": "WMT19", "start_pos": 49, "end_pos": 54, "type": "DATASET", "confidence": 0.830451488494873}]}, {"text": "As qualitative analyses of document-level errors in MT outputs are up-to-date quite rare, this paper further aims at identification, manual annotation and linguistic description of these types of errors relevant to English-Czech NMT and a comparison of performance of the submitted systems in the given areas.", "labels": [], "entities": [{"text": "MT outputs", "start_pos": 52, "end_pos": 62, "type": "TASK", "confidence": 0.8988369703292847}]}, {"text": "We compare NMT systems that translate one sentence at a time with systems that have more than one sentence on input and therefore have potential to translate document-level phenomena better.", "labels": [], "entities": []}, {"text": "After an overview of detected translation errors from various levels of language description, the paper zooms in on three document-level, or coherence-related, phenomena: topic-focus articulation (information structure), discourse connectives and alternative lexicalizations of connectives.", "labels": [], "entities": []}, {"text": "We assume that translation systems might have difficulties with these phenomena, as they are related to the previous context and go beyond (or are affected by the phenomena across) the sentence boundary.", "labels": [], "entities": []}, {"text": "In this way, they contribute to the overall coherence of the text that should (as a whole) function as an independent unit of human communication.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Results for connectives annotations. The columns are: (a) adequate and correctly placed, (ax) adequate  but incorrectly placed, (m) omitted and it does not harm the output, and (n) not adequate. Each represents 20 %  and the results are rounded to the nearest half-star.", "labels": [], "entities": [{"text": "connectives annotations", "start_pos": 22, "end_pos": 45, "type": "TASK", "confidence": 0.7621751129627228}]}]}