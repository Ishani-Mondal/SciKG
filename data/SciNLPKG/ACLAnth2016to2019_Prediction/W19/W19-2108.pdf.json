{"title": [{"text": "Stance Classification, Outcome Prediction, and Impact Assessment: NLP Tasks for Studying Group Decision-Making", "labels": [], "entities": [{"text": "Stance Classification", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8185804188251495}, {"text": "Outcome Prediction", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.7728614211082458}, {"text": "Impact Assessment", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.6467166244983673}]}], "abstractContent": [{"text": "In group decision-making, the nuanced process of conflict and resolution that leads to consensus formation is closely tied to the quality of decisions made.", "labels": [], "entities": []}, {"text": "Behavioral scientists rarely have rich access to process variables, though, as unstructured discussion transcripts are difficult to analyze.", "labels": [], "entities": []}, {"text": "Here, we define ways for NLP researchers to contribute to the study of groups and teams.", "labels": [], "entities": []}, {"text": "We introduce three tasks alongside a large new corpus of over 400,000 group debates on Wikipedia.", "labels": [], "entities": []}, {"text": "We describe the tasks and their importance, then provide base-lines showing that BERT contextualized word embeddings consistently outperform other language representations.", "labels": [], "entities": [{"text": "BERT", "start_pos": 81, "end_pos": 85, "type": "METRIC", "confidence": 0.8791002035140991}]}], "introductionContent": [{"text": "In the study of groups and teams, measuring discussion quality -plainly, what makes a group debate good?", "labels": [], "entities": []}, {"text": "-is an open research area.", "labels": [], "entities": []}, {"text": "Controlled behavioral studies have shown, for instance, that creativity, diversity, and conflict have major roles to play in the quality of teamwork.", "labels": [], "entities": []}, {"text": "But the value of diverse discussion and open conflict is complicated, with along history of positive, negative, and null results, depending on the narrow construct being studied (.", "labels": [], "entities": []}, {"text": "What is clear is that the particulars of how teams are composed and how teammates interact with each other matters a great deal for effective group work ().", "labels": [], "entities": []}, {"text": "In behavioral science, questions are often explored through structured equation modeling and multivariate regressions, allowing behavior scientists sophisticated control over exogenous (fixed, external) variables, like demographics and task conditions, as well as process variables that describe observable behaviors in the groups being studied.", "labels": [], "entities": []}, {"text": "Reducing team dynamics from text transcripts to quantitative process variables is computationally complex; in practice, text data is often ignored in favor of proxies like count statistics or, more frequently, participant survey responses (.", "labels": [], "entities": []}, {"text": "These proxies are reliable and effective as stand-ins, but put a limit on the types of questions that can be asked.", "labels": [], "entities": []}, {"text": "Scientists studying teams may wish to evaluate which voices truly influenced a conversation, gauge the diversity of people or ideas represented in those influential roles, and measure observed conflicts and consensusbuilding.", "labels": [], "entities": []}, {"text": "They may also want to assess whether any particular participant impacted the discussion and use these variables in aggregate to find which processes impact quality.", "labels": [], "entities": []}, {"text": "This data is difficult to extract from discussion transcripts.", "labels": [], "entities": []}, {"text": "Of course, large-scale corpus analysis is common in natural language processing, with many efficient representations of the complex underlying meaning of texts.", "labels": [], "entities": []}, {"text": "In this work, we use these methods in the domain of group decision-making research, with three tasks for studying groups: \u2022 Stance 1 classification, a fine-grained, fully supervised classification task for individual contributions to a discussion.", "labels": [], "entities": [{"text": "Stance 1 classification", "start_pos": 124, "end_pos": 147, "type": "TASK", "confidence": 0.6493141055107117}]}, {"text": "\u2022 Outcome prediction, a distantly supervised task requiring far less annotated training data for new domains.", "labels": [], "entities": [{"text": "Outcome prediction", "start_pos": 2, "end_pos": 20, "type": "TASK", "confidence": 0.9234135746955872}]}, {"text": "\u2022 Individual impact assessment, an unsupervised extension of outcome prediction to quantify how individual contributions or users influenced debate.", "labels": [], "entities": [{"text": "Individual impact assessment", "start_pos": 2, "end_pos": 30, "type": "TASK", "confidence": 0.744597315788269}, {"text": "outcome prediction", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.7375060021877289}]}, {"text": "In the rest of this work, we demonstrate that these tasks are tractable for NLP researchers to-day, especially with modern language representations like BERT ().", "labels": [], "entities": [{"text": "BERT", "start_pos": 153, "end_pos": 157, "type": "METRIC", "confidence": 0.7937982082366943}]}, {"text": "This contextual representation is highly accurate in both supervised tasks and produces interpretable results for the unsupervised task, suggesting it is ready for immediate application in social science research.", "labels": [], "entities": []}, {"text": "Alongside these results, we also introduce a real-world corpus of over 423,000 debates from Wikipedia, preprocessed and released under an open source license.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate an offline database of all Articles for Deletion discussions . The snapshot contains approximately 19 million pages.", "labels": [], "entities": []}, {"text": "Over one third of the pages in the administrative Wikipedia: namespace are archives related to AfD.", "labels": [], "entities": [{"text": "AfD", "start_pos": 95, "end_pos": 98, "type": "DATASET", "confidence": 0.9307089447975159}]}, {"text": "We include all data from January 1, 2005 to December 31, 2018.", "labels": [], "entities": []}, {"text": "Prior to 2005, traffic was low and decisionmaking dynamics were erratic, while data from 2019 is (as yet) incomplete.", "labels": [], "entities": []}, {"text": "This 14-year window includes over 423,000 discussions.", "labels": [], "entities": []}, {"text": "For all machine learning results, we train a logistic regression classifier implemented in ScikitLearn (Pedregosa et al., 2011) with L2 regularization and the LIBLINEAR solver.", "labels": [], "entities": [{"text": "LIBLINEAR solver", "start_pos": 159, "end_pos": 175, "type": "TASK", "confidence": 0.5365981161594391}]}, {"text": "Experiments represent average results of 10-fold cross-validation.", "labels": [], "entities": []}, {"text": "All instances from a particular discussion appear in only one fold; there is never crossover from the same debate between train and test data.", "labels": [], "entities": []}, {"text": "We report results on a randomized subset of 5% of the corpus, approximately 20,000 discussions.", "labels": [], "entities": []}, {"text": "In preliminary evaluation, a 20x growth in training data increased computational resources beyond what is practical for social scientists, for model accuracy improvements of less than 1%; we exclude full analyses here but provide training splits (for potential future approaches that benefit from larger corpora) in the released data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 149, "end_pos": 157, "type": "METRIC", "confidence": 0.944688618183136}]}, {"text": "For further details on data release and corpus preprocessing, including how free-form preference labels were collapsed, see Appendix A.  The prior two tasks were supervised, with labeled outcomes that could be measured for performance accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 235, "end_pos": 243, "type": "METRIC", "confidence": 0.9339907169342041}]}, {"text": "Impact assessment has no specific ground truth to compare against.", "labels": [], "entities": [{"text": "Impact assessment", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8314981162548065}]}, {"text": "In this scenario, other NLP research has provided justifications fora mix of quantitative and qualitative evaluations, as well as validation with human annotators and evaluation based on performance improvement in downstream tasks.", "labels": [], "entities": []}, {"text": "We present a mix of qualitative analysis and downstream tasks, while leaving room for future validation studies.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Distribution of preference labels in votes and  final outcomes in our corpus.", "labels": [], "entities": [{"text": "Distribution of preference labels", "start_pos": 10, "end_pos": 43, "type": "TASK", "confidence": 0.8285673558712006}]}, {"text": " Table 2: Accuracy of stance classification models for  individual contributions, based on rationale text alone.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9647643566131592}, {"text": "stance classification", "start_pos": 22, "end_pos": 43, "type": "TASK", "confidence": 0.9082420766353607}]}, {"text": " Table 3: Accuracy of outcome prediction models, for  full discussions and in real-time predictions.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.982014000415802}, {"text": "outcome prediction", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.8412845730781555}]}, {"text": " Table 4: Accuracy of outcome prediction, split by final  outcome and total debate length (as in", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9948521256446838}, {"text": "outcome prediction", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.7683247327804565}]}]}