{"title": [{"text": "Improving UD processing via satellite resources for morphology", "labels": [], "entities": [{"text": "UD processing", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.835665374994278}]}], "abstractContent": [{"text": "This paper presents the conversion of the reference language resources for Croatian and Slove-nian morphology processing to UD morphological specifications.", "labels": [], "entities": [{"text": "Slove-nian morphology processing", "start_pos": 88, "end_pos": 120, "type": "TASK", "confidence": 0.5889037052790324}]}, {"text": "We show that the newly available training corpora and inflectional dictionaries improve the baseline stanfordnlp performance obtained on officially released UD datasets for lemmatization, morphology prediction and dependency parsing, illustrating the potential value of such satellite UD resources for languages with rich morphology.", "labels": [], "entities": [{"text": "UD datasets", "start_pos": 157, "end_pos": 168, "type": "DATASET", "confidence": 0.6995564997196198}, {"text": "morphology prediction", "start_pos": 188, "end_pos": 209, "type": "TASK", "confidence": 0.7996188104152679}, {"text": "dependency parsing", "start_pos": 214, "end_pos": 232, "type": "TASK", "confidence": 0.7183900028467178}]}], "introductionContent": [{"text": "Many treebanks and tools are nowadays available for natural language processing tasks based on the Universal Dependencies (UD) framework, aimed at cross-linguistically consistent treebank annotation to facilitate multilingual parser development, cross-lingual learning, and parsing research (.", "labels": [], "entities": [{"text": "multilingual parser development", "start_pos": 213, "end_pos": 244, "type": "TASK", "confidence": 0.6865691741307577}, {"text": "parsing research", "start_pos": 274, "end_pos": 290, "type": "TASK", "confidence": 0.9127739667892456}]}, {"text": "As shown by the two successive CoNLL shared tasks on multilingual parsing from raw text to UD, existing UD systems achieve state-of-the-art results both in terms of dependency parsing and lower levels of grammatical annotation.", "labels": [], "entities": [{"text": "multilingual parsing from raw text", "start_pos": 53, "end_pos": 87, "type": "TASK", "confidence": 0.7827412784099579}, {"text": "dependency parsing", "start_pos": 165, "end_pos": 183, "type": "TASK", "confidence": 0.7266478538513184}]}, {"text": "However, in addition to the officially released UD treebanks with complete syntactic and morphological annotations, the rapidly emerging UD tools would benefit from other language resources, as well.", "labels": [], "entities": [{"text": "UD treebanks", "start_pos": 48, "end_pos": 60, "type": "DATASET", "confidence": 0.8276128768920898}]}, {"text": "This is especially true for morphological annotation (lemmatization, PoS tagging and morphological feature prediction), as many languages employ much larger morphology-annotated corpora than the costly (sub)corpora annotated for syntax, as well as morphological lexicons, essential for high-quality processing of languages with complex morphology.", "labels": [], "entities": [{"text": "PoS tagging", "start_pos": 69, "end_pos": 80, "type": "TASK", "confidence": 0.7759789824485779}, {"text": "morphological feature prediction", "start_pos": 85, "end_pos": 117, "type": "TASK", "confidence": 0.7403470079104105}]}, {"text": "Examples of such cases are Croatian and Slovenian, two South Slavic languages with rich inflection.", "labels": [], "entities": []}, {"text": "Their official UD releases include the conversions of the largest syntactically annotated corpora available for each language), however, other manually created resources, such as the larger morphologically annotated corpora ( and inflectional lexicons, have also been developed to support the development of related NLP tools () in the past.", "labels": [], "entities": []}, {"text": "The aim of this paper is to present the conversion of these resources to the UD formalism and explore their potential contribution to the state-of-the-art in UD processing for both languages, from lemmatization to morphology and syntax prediction.", "labels": [], "entities": [{"text": "UD processing", "start_pos": 158, "end_pos": 171, "type": "TASK", "confidence": 0.9039231538772583}, {"text": "syntax prediction", "start_pos": 229, "end_pos": 246, "type": "TASK", "confidence": 0.7216217964887619}]}, {"text": "Using the stanfordnlp tool, we investigate the impact of newly available data on all three tasks by (1) retraining the tagging and lemmatization models on larger training sets and (2) performing a simple lexicon lookup intervention in the lemmatization procedure.", "labels": [], "entities": []}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "We first briefly describe the creation and the content of the newly released resources for both languages in Section 2, followed by the presentation of the experiments for their evaluation in Section 3.", "labels": [], "entities": []}, {"text": "We present the corresponding results in Section 4 and conclude in Section 5 by a short discussion of their wider implications for related UD languages and the UD community in general.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments in this paper are organised in two parts: the experiments with an extended training corpus on the level of morphosyntax and lemma and the experiments on adding an inflectional lexicon to the lemmatization process.", "labels": [], "entities": []}, {"text": "While we perform experiments on the levels of morphosyntax, lemma and dependency syntax, we use gold segmentation to simplify our experiments as different tokenisers and sentence splitters are available for the two languages in question.", "labels": [], "entities": [{"text": "sentence splitters", "start_pos": 170, "end_pos": 188, "type": "TASK", "confidence": 0.7574671804904938}]}, {"text": "Performing different preprocessing on the two languages would blur our experiments.", "labels": [], "entities": []}, {"text": "On the other hand, applying the out-of-the box segmentation of stanfordnlp would produce results that are detrimental to those of our rule-based tokenizers and sentence splitters.", "labels": [], "entities": [{"text": "sentence splitters", "start_pos": 160, "end_pos": 178, "type": "TASK", "confidence": 0.724688246846199}]}, {"text": "Overall, our previous experiments show that true segmentation deteriorates the results slightly on all levels of annotation, but that relations between results of different systems or setups hold regardless of whether gold or true segmentation is used.", "labels": [], "entities": []}, {"text": "When performing training and evaluation on levels of lemmatization and dependency syntax, we preannotate all the three data portions (train, dev and test) with the models from the upstream levels.", "labels": [], "entities": []}, {"text": "We therefore apply morphosyntactic models on the data to be used for training and evaluating lemmatization, and we apply morphosyntactic tagging and lemmatization before training and evaluating dependency parsing models.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 194, "end_pos": 212, "type": "TASK", "confidence": 0.7661750316619873}]}, {"text": "While it is to be expected that training and applying the models on the training data will give an unrealistically good automatic annotation of the training data, our intuition is that, given that development data can be considered realistically annotated, the final impact of this simplifying solution (jack-knifing, i.e. annotating the training data via cross-validation would bean alternative) on the quality of annotation of the test (or any other) data will be minimal, if any.", "labels": [], "entities": []}, {"text": "Simply preannotating training data with the model trained on that same data was also the approach taken by the developers of stanfordnlp during the CoNLL 2018 shared task (.", "labels": [], "entities": [{"text": "CoNLL 2018 shared task", "start_pos": 148, "end_pos": 170, "type": "DATASET", "confidence": 0.8410187363624573}]}, {"text": "The experiments on using a larger dataset for training the morphosyntactic tagging and lemmatization models, for which we expect to have a positive impact on the parsing quality, are split into two main parts: (1) training and evaluating morphosyntactic tagging and lemmatization models on the UD data and on all the available data, and (2) applying both models as pre-processing for training and evaluating models for dependency parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 162, "end_pos": 169, "type": "TASK", "confidence": 0.9711830019950867}, {"text": "UD data", "start_pos": 294, "end_pos": 301, "type": "DATASET", "confidence": 0.8129760921001434}, {"text": "dependency parsing", "start_pos": 419, "end_pos": 437, "type": "TASK", "confidence": 0.8236706554889679}]}, {"text": "The experiments on using the inflectional lexicon for improving lemmatization by extending the lookup method on the external lexicon, consist, similarly, of the experiments on training and evaluating the lemmatization models based on UD and all the available data, both with and without the lexicon, and inspecting the impact of the improved lemmatization on the parsing quality.", "labels": [], "entities": []}, {"text": "We evaluate all approaches with the evaluation script of the CoNLL 2018 shared task (, reporting F1 on all relevant levels, these being LEMMA, UPOS, XPOS, FEATS scores for morphology.", "labels": [], "entities": [{"text": "CoNLL 2018 shared task", "start_pos": 61, "end_pos": 83, "type": "DATASET", "confidence": 0.8871262669563293}, {"text": "F1", "start_pos": 97, "end_pos": 99, "type": "METRIC", "confidence": 0.9864115715026855}, {"text": "LEMMA", "start_pos": 136, "end_pos": 141, "type": "METRIC", "confidence": 0.954168975353241}, {"text": "XPOS", "start_pos": 149, "end_pos": 153, "type": "METRIC", "confidence": 0.7241992354393005}, {"text": "FEATS", "start_pos": 155, "end_pos": 160, "type": "METRIC", "confidence": 0.9931661486625671}]}, {"text": "For dependency syntax, the standard unlabelled (UAS) and labelled (LAS) attachment scores are complemented with the recently proposed morphology-aware labelled attachment score (MLAS), which also takes part-of-speech tags and morphological features into account and treats function words as features of content words, and bi-lexical dependency score (BLEX), which is similar to MLAS, but also incorporates lemmatization.", "labels": [], "entities": [{"text": "morphology-aware labelled attachment score (MLAS)", "start_pos": 134, "end_pos": 183, "type": "METRIC", "confidence": 0.7458892124039787}, {"text": "bi-lexical dependency score (BLEX)", "start_pos": 322, "end_pos": 356, "type": "METRIC", "confidence": 0.7656850020090739}]}, {"text": "For evaluation, we use only the UD portions of the test datasets to keep the numbers obtained on the UD data and the extended data as comparable as possible.", "labels": [], "entities": [{"text": "UD data", "start_pos": 101, "end_pos": 108, "type": "DATASET", "confidence": 0.8146858513355255}]}], "tableCaptions": [{"text": " Table 1: Size of newly available corpora for UD morphology.", "labels": [], "entities": [{"text": "UD morphology", "start_pos": 46, "end_pos": 59, "type": "TASK", "confidence": 0.9669970571994781}]}, {"text": " Table 2: Size of newly available lexica for UD morphology.", "labels": [], "entities": [{"text": "UD morphology", "start_pos": 45, "end_pos": 58, "type": "TASK", "confidence": 0.9639920592308044}]}, {"text": " Table 3: The benchmarking data split of the ssj500k and hr500k corpora and their officially released UD  subsets.", "labels": [], "entities": []}, {"text": " Table 4: Improvements in baseline stanfordnlp lemmatization, tagging and parsing performance for  Croatian and Slovenian through a larger training set for UD morphology.", "labels": [], "entities": [{"text": "tagging", "start_pos": 62, "end_pos": 69, "type": "TASK", "confidence": 0.9541037678718567}, {"text": "UD morphology", "start_pos": 156, "end_pos": 169, "type": "TASK", "confidence": 0.927256852388382}]}, {"text": " Table 5: Improvements in baseline stanfordnlp lemmatization, tagging and parsing performance for  Croatian and Slovenian through a simple lexicon lookup for lemmatization.", "labels": [], "entities": []}]}