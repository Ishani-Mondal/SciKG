{"title": [{"text": "English-Czech Systems in WMT19: Document-Level Transformer", "labels": [], "entities": [{"text": "WMT19", "start_pos": 25, "end_pos": 30, "type": "DATASET", "confidence": 0.880713164806366}]}], "abstractContent": [{"text": "We describe our NMT systems submitted to the WMT19 shared task in English\u2192Czech news translation.", "labels": [], "entities": [{"text": "WMT19 shared task", "start_pos": 45, "end_pos": 62, "type": "TASK", "confidence": 0.6188928286234537}, {"text": "Czech news translation", "start_pos": 74, "end_pos": 96, "type": "TASK", "confidence": 0.6368675529956818}]}, {"text": "Our systems are based on the Transformer model implemented in either Tensor2Tensor (T2T) or Marian framework.", "labels": [], "entities": [{"text": "Marian framework", "start_pos": 92, "end_pos": 108, "type": "DATASET", "confidence": 0.928578108549118}]}, {"text": "We aimed at improving the adequacy and coherence of translated documents by enlarging the context of the source and target.", "labels": [], "entities": []}, {"text": "Instead of translating each sentence independently , we split the document into possibly overlapping multi-sentence segments.", "labels": [], "entities": []}, {"text": "In case of the T2T implementation, this \"document-level\"-trained system achieves a +0.6 BLEU improvement (p < 0.05) relative to the same system applied on isolated sentences.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 88, "end_pos": 92, "type": "METRIC", "confidence": 0.9973498582839966}]}, {"text": "To assess the potential effect document-level models might have on lexical coherence, we performed a semi-automatic analysis, which revealed only a few sentences improved in this aspect.", "labels": [], "entities": []}, {"text": "Thus, we cannot draw any conclusions from this week evidence.", "labels": [], "entities": []}], "introductionContent": [{"text": "Neural machine translation has reached a point, where the quality of automatic translation measured on isolated sentences is similar on average to the quality of professional human translations.", "labels": [], "entities": [{"text": "Neural machine translation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8214503725369772}]}, {"text": "report achieving a \"human parity\" on Chinese\u2192English news translation.", "labels": [], "entities": [{"text": "Chinese\u2192English news translation", "start_pos": 37, "end_pos": 69, "type": "TASK", "confidence": 0.6120929837226867}]}, {"text": "report that our last year's English\u2192Czech system was evaluated as significantly better (p < 0.05) than the human reference.", "labels": [], "entities": []}, {"text": "However, it has been shown () that evaluating the quality of translation of news articles on isolated sentences without the context of the whole document is not sufficient.", "labels": [], "entities": [{"text": "translation of news articles on isolated sentences", "start_pos": 61, "end_pos": 111, "type": "TASK", "confidence": 0.8606750113623483}]}, {"text": "It can bias the evaluation results because systems that ignore the context are not penalized in the evaluation for these context-related errors; and vice versa: systems (or humans) that take the context into account maybe unfairly penalized.", "labels": [], "entities": []}, {"text": "show that while the difference between human and machine translation inadequacy is not significant when evaluated on isolated sentences, it is significant (humans are better) when evaluated on whole documents.", "labels": [], "entities": []}, {"text": "This suggests that there are some inter-sentential phenomena where MT applied on isolated sentences is lacking.", "labels": [], "entities": [{"text": "MT", "start_pos": 67, "end_pos": 69, "type": "TASK", "confidence": 0.9902693033218384}]}, {"text": "Since assessing the performance of documentlevel systems is one of the goals of WMT19 (, we decided to build NMT systems trained for translation of longer segments than single sentences.", "labels": [], "entities": [{"text": "WMT19", "start_pos": 80, "end_pos": 85, "type": "DATASET", "confidence": 0.8728144764900208}, {"text": "translation of longer segments", "start_pos": 133, "end_pos": 163, "type": "TASK", "confidence": 0.8619345426559448}]}, {"text": "In this paper, we describe our five NMT systems submitted to WMT19 English\u2192Czech news translation task (see Table 1).", "labels": [], "entities": [{"text": "WMT19 English\u2192Czech news translation task", "start_pos": 61, "end_pos": 102, "type": "TASK", "confidence": 0.6775636928422111}]}, {"text": "They are based on the Transformer model () and on our submission from WMT18.", "labels": [], "entities": [{"text": "WMT18", "start_pos": 70, "end_pos": 75, "type": "DATASET", "confidence": 0.9258034825325012}]}, {"text": "Our new contributions are (i) adaptation of the baseline single-sentence models to translate multiple adjacent sentences in a document at once, so the Transformer can attend to inter-sentence relations and achieve better document-level translation quality, as was already showed to be effective by; and (ii) reimplementation of our last year's submission in the Marian framework.", "labels": [], "entities": []}, {"text": "This paper is organized as follows: In Section 2, we describe our training data and its augmentation to overlapping multi-sentence sequences.", "labels": [], "entities": []}, {"text": "We describe also the hyper-parameters of our models in the two frameworks.", "labels": [], "entities": []}, {"text": "Section 3 follows with a description of the document-level decoding strategies.", "labels": [], "entities": []}, {"text": "Section 4 reports and discusses the results of automatic (BLEU) evaluation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.6825165748596191}]}], "datasetContent": [{"text": "Our training data (see) are constrained to the data allowed in the WMT2019 shared task.", "labels": [], "entities": [{"text": "WMT2019 shared task", "start_pos": 67, "end_pos": 86, "type": "TASK", "confidence": 0.6898391246795654}]}, {"text": "\"Transformer T2T 2018\" and \"Transformer Marian\" use only the data allowed in WMT2018, which does not include CS NewsCrawl 2018 and WikiTitles.", "labels": [], "entities": [{"text": "Transformer Marian", "start_pos": 28, "end_pos": 46, "type": "DATASET", "confidence": 0.6495075970888138}, {"text": "WMT2018", "start_pos": 77, "end_pos": 84, "type": "DATASET", "confidence": 0.9737027883529663}, {"text": "CS NewsCrawl 2018", "start_pos": 109, "end_pos": 126, "type": "DATASET", "confidence": 0.7733606497446696}]}, {"text": "All the data were preprocessed, filtered and backtranslated by the same process as in.", "labels": [], "entities": []}, {"text": "We selected the originally English part of newstest2016 for validation, following the idea of CZ/nonCZ tuning in Popel (2018), but excluding the CZ tuning because the WMT2019 test set was announced to contain only original English sentences and no translationese.", "labels": [], "entities": [{"text": "Popel (2018)", "start_pos": 113, "end_pos": 125, "type": "DATASET", "confidence": 0.918755367398262}, {"text": "WMT2019 test set", "start_pos": 167, "end_pos": 183, "type": "DATASET", "confidence": 0.9666258096694946}]}, {"text": "We hypothesized that by providing the translation model with larger attendable context, the resulting translations display larger lexical consistency.", "labels": [], "entities": []}, {"text": "We could demonstrate it by finding less examples where an English polysemous word is translated to two or more Czech non-synonymous lemmata within one document.", "labels": [], "entities": []}, {"text": "To evaluate the hypothesis, we word-aligned the source and target sentences using fast_align (.", "labels": [], "entities": []}, {"text": "We then lemmatized the aligned words (both English and Czech) using MorphoDiTa () and considered all instances where a single English lemma was aligned to at least two Czech lemmata in a single document.", "labels": [], "entities": []}, {"text": "Since our focus was on evaluating the difference between non-context and document-level models, we selected only the English lemmata with different number of aligned Czech lemmata in the two types of systems.", "labels": [], "entities": []}, {"text": "Two pairs of models were compared: \"DocTransformer T2T\" vs. \"Transformer T2T 2019\" and \"DocTransformer Marian\" vs. \"Transformer Marian\".", "labels": [], "entities": [{"text": "DocTransformer T2T", "start_pos": 36, "end_pos": 54, "type": "DATASET", "confidence": 0.8837359547615051}, {"text": "DocTransformer Marian", "start_pos": 88, "end_pos": 109, "type": "DATASET", "confidence": 0.9314165115356445}, {"text": "Transformer Marian", "start_pos": 116, "end_pos": 134, "type": "DATASET", "confidence": 0.5710206925868988}]}, {"text": "The final pool of examples was evaluated manually.", "labels": [], "entities": []}, {"text": "We found only one and three instances for the Marian and T2T models, respectively, where the document-level variant performed better than the non-context variant.", "labels": [], "entities": [{"text": "Marian", "start_pos": 46, "end_pos": 52, "type": "DATASET", "confidence": 0.8982202410697937}]}, {"text": "The examples are shown in.", "labels": [], "entities": []}, {"text": "We also found a possible counterexample where the document-level model performed worse than the non-context model, but the evaluation is not clear-cut.", "labels": [], "entities": []}, {"text": "The example is shown in.", "labels": [], "entities": []}, {"text": "Because there are too few examples for any meaningful quantitative analysis, we conclude more data is needed to evaluate the potential benefit a document-level model could have on lexical consistency.", "labels": [], "entities": []}, {"text": "By doing manual evaluation, we found the cases where the inter-sentential context is necessary for determining the correct meaning of a polysemous word are rare.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Brief descriptions of our WMT19 systems. In the rest of the paper, we omit the CUNI (Charles University)  prefix for brevity.", "labels": [], "entities": [{"text": "WMT19", "start_pos": 36, "end_pos": 41, "type": "TASK", "confidence": 0.6160730719566345}, {"text": "CUNI (Charles University)  prefix", "start_pos": 89, "end_pos": 122, "type": "DATASET", "confidence": 0.8760557969411215}]}, {"text": " Table 2: Training data sizes (in thousands).", "labels": [], "entities": []}, {"text": " Table 3: Hardware used for our systems.", "labels": [], "entities": []}, {"text": " Table 4: Automatic evaluation on newstest2019.  Significantly different BLEU scores (p < 0.05 boot- strap resampling) are separated by a horizontal line.", "labels": [], "entities": [{"text": "BLEU scores (p < 0.05 boot- strap resampling", "start_pos": 73, "end_pos": 117, "type": "METRIC", "confidence": 0.733384782075882}]}]}