{"title": [{"text": "Dissecting Content and Context in Argumentative Relation Analysis", "labels": [], "entities": [{"text": "Dissecting Content and Context in Argumentative Relation Analysis", "start_pos": 0, "end_pos": 65, "type": "TASK", "confidence": 0.7928929999470711}]}], "abstractContent": [{"text": "When assessing relations between argumentative units (e.g., support or attack), computational systems often exploit disclosing indicators or markers that are not part of elementary argumentative units (EAUs) themselves, but are gained from their context (position in paragraph , preceding tokens, etc.).", "labels": [], "entities": []}, {"text": "We show that this dependency is much stronger than previously assumed.", "labels": [], "entities": []}, {"text": "In fact, we show that by completely masking the EAU text spans and only feeding information from their context, a competitive system may function even better.", "labels": [], "entities": []}, {"text": "We argue that an argument analysis system that relies more on discourse context than the argu-ment's content is unsafe, since it can easily be tricked.", "labels": [], "entities": [{"text": "argument analysis", "start_pos": 17, "end_pos": 34, "type": "TASK", "confidence": 0.7732132077217102}]}, {"text": "To alleviate this issue, we separate argumentative units from their context such that the system is forced to model and rely on an EAU's content.", "labels": [], "entities": []}, {"text": "We show that the resulting classification system is more robust, and argue that such models are better suited for predicting argumentative relations across documents.", "labels": [], "entities": [{"text": "predicting argumentative relations across documents", "start_pos": 114, "end_pos": 165, "type": "TASK", "confidence": 0.8259227037429809}]}], "introductionContent": [{"text": "In recent years we have witnessed a great surge in activity in the area of computational argument analysis (e.g.;;;), and the emergence of dedicated venues such as the ACL Argument Mining workshop series starting in 2014 (.", "labels": [], "entities": [{"text": "computational argument analysis", "start_pos": 75, "end_pos": 106, "type": "TASK", "confidence": 0.6514673829078674}, {"text": "ACL Argument Mining workshop series", "start_pos": 168, "end_pos": 203, "type": "TASK", "confidence": 0.7038960933685303}]}, {"text": "Argumentative relation classification is a subtask of argument analysis that aims to determine relations between argumentative units A and B, for example, A supports B; A attacks B.", "labels": [], "entities": [{"text": "Argumentative relation classification", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.7218674619992574}, {"text": "argument analysis", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.7105872482061386}]}, {"text": "Consider the following argumentative units (1) and (2), given the topic (0) \"Marijuana should be legalized\": (1) Legalizing marijuana can increase use by teens, with harmful results.", "labels": [], "entities": []}, {"text": "(2) Legalization allows the government to set age restrictions on buyers.", "labels": [], "entities": []}, {"text": "This example is modeled in.", "labels": [], "entities": []}, {"text": "It is clear that (1) has a negative stance towards the topic and (2) has a positive stance towards the topic.", "labels": [], "entities": []}, {"text": "Moreover, we can say that (2) attacks (1).", "labels": [], "entities": []}, {"text": "In discourse, such a relation is often made explicit through discourse markers: (1).", "labels": [], "entities": []}, {"text": "However, (2); On the one hand (1), on the other (2); (1), although (2); Admittedly, (2); etc.", "labels": [], "entities": []}, {"text": "In the absence of such markers we must determine this relation by assessing the semantics of the individual argumentative units, including (often implicit) world knowledge about how they are related to each other.", "labels": [], "entities": []}, {"text": "In this work, we show that argumentative relation classifiers -when provided with textual context surrounding an argumentative unit's spanare very prone to neglect the actual textual content of the EAU span.", "labels": [], "entities": []}, {"text": "Instead they heavily rely on contextual markers, such as conjunctions or adverbials, as a basis for prediction.", "labels": [], "entities": []}, {"text": "We argue that a system's capacity of predicting the correct relation based on the argumentative units' content is important in many circumstances, e.g., when an argumentative debate crosses document boundaries.", "labels": [], "entities": []}, {"text": "For example, the prohibition of marijuana debate extends across populations and countries -argumentative units for this debate can be recovered from thousands of documents scattered across the worldwide web.", "labels": [], "entities": [{"text": "prohibition of marijuana debate", "start_pos": 17, "end_pos": 48, "type": "TASK", "confidence": 0.8045189529657364}]}, {"text": "As a consequence, argumentative relation classification systems should not be (immensely) dependent on contextual clues -in the discussed cross-document setting these clues may even be misleading for such a system, since source and target arguments can be embedded in different textual contexts (e.g., when (1) and (2) stem from different documents it is easy to imagine a textual context where (2) is not introduced by however but instead by an 'inverse' form such as e.g. moreover).", "labels": [], "entities": [{"text": "argumentative relation classification", "start_pos": 18, "end_pos": 55, "type": "TASK", "confidence": 0.7144673268000284}]}, {"text": "Contributions In Section \u00a73 we describe argumentative relation classification systems and their features.", "labels": [], "entities": [{"text": "argumentative relation classification", "start_pos": 40, "end_pos": 77, "type": "TASK", "confidence": 0.7279435197512308}]}, {"text": "Then, to assess the systems' dependency on context, we propose a three-way feature grouping: (i) features which access only the EAU span; (ii) features which access only the context of an EAU; (iii) features which access both EAU span and its context.", "labels": [], "entities": []}, {"text": "Our experimental results ( \u00a74) indicate that systems, when given the option, tend to focus on the context of an EAU, while neglecting its content.", "labels": [], "entities": []}, {"text": "On the one hand, this leads to strong performance when EAUs appear sequentially in a rhetorically well structured argumentative monologue.", "labels": [], "entities": []}, {"text": "Yet, on the other hand, we show that such systems can easily be fooled, e.g., when EAUs are extracted from different documents.", "labels": [], "entities": []}], "datasetContent": [{"text": "Data and pre-processing We use the corpus of 402 persuasive essays which were annotated with argumentative units, their stances towards the topic and argumentative relations).", "labels": [], "entities": []}, {"text": "The data is suited for our experiments because the annotators were explicitly asked to provide annotations on a clausal level.", "labels": [], "entities": []}, {"text": "This entails that contextual clues tend not to be contained in the annotated span (e.g., only people should not smoke is annotated as EAU in the sentence Therefore, people should not smoke.).", "labels": [], "entities": [{"text": "EAU", "start_pos": 134, "end_pos": 137, "type": "METRIC", "confidence": 0.9220793843269348}]}, {"text": "In this work, we are concerned with classifying relations between argumentative units into support or attack and thus do not consider other annotations.", "labels": [], "entities": []}, {"text": "For feature extraction, we process all documents with Stanford CoreNLP ( ) with the following annotation layers: sentence tokenize, word tokenize, constituency parse and constituency-sentiment.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.746476024389267}, {"text": "Stanford CoreNLP", "start_pos": 54, "end_pos": 70, "type": "DATASET", "confidence": 0.8640397191047668}, {"text": "constituency parse", "start_pos": 147, "end_pos": 165, "type": "TASK", "confidence": 0.6313452571630478}]}, {"text": "For extraction of the discourse-features, we proceed by parsing all documents with the PDTB-parser 7 developed by.", "labels": [], "entities": []}, {"text": "For the joint task of predicting three link classes (including a non-linked class), we extract as non-linked EAU pairs all EAU pairs which are not linked on a document level.", "labels": [], "entities": []}, {"text": "Data set statistics are displayed in.", "labels": [], "entities": []}, {"text": "Setup As explained in \u00a73, we are interested in three distinct configurations of the argumentative relation classifier: content-based (CB), contentignorant (CI) and full-access (FA).", "labels": [], "entities": []}, {"text": "Naturally, we would expect the latter to perform best and perhaps we would also expect CB to outperform CI -a system which has no access to the argumentative unit internals whatsoever should not be able to confidently determine relations between them.Note that some features are only available to FA, which is the case when features cross con-   text and argumentative unit spans (e.g., some of the discourse features), thereby resisting a clear categorization into CB or CI.", "labels": [], "entities": []}, {"text": "Same as most prior work, we use an SVM to learn the feature weights.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Data set statistics.", "labels": [], "entities": []}, {"text": " Table 2: Baseline system replication results.", "labels": [], "entities": [{"text": "Baseline system replication", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.6637807786464691}]}, {"text": " Table 3: Argumentative relation classification models  h, f, g with different access to content and context;  models of type CI (content-ignorant) have no access to  the EAU span.  \u2020: significantly better than mfs baseline  (p < 0.005);  \u2021 significantly better than content-based  (p < 0.005).", "labels": [], "entities": []}]}