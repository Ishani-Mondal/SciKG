{"title": [{"text": "Modeling Word Emotion in Historical Language: Quantity Beats Supposed Stability in Seed Word Selection", "labels": [], "entities": [{"text": "Modeling Word Emotion", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8319403131802877}, {"text": "Quantity Beats Supposed Stability", "start_pos": 46, "end_pos": 79, "type": "TASK", "confidence": 0.7674242705106735}, {"text": "Seed Word Selection", "start_pos": 83, "end_pos": 102, "type": "TASK", "confidence": 0.5857254465421041}]}], "abstractContent": [{"text": "To understand historical texts, we must be aware that language-including the emotional connotation attached to words-changes overtime.", "labels": [], "entities": []}, {"text": "In this paper, we aim at estimating the emotion which is associated with a given word in former language stages of English and German.", "labels": [], "entities": []}, {"text": "Emotion is represented following the popular Valence-Arousal-Dominance (VAD) annotation scheme.", "labels": [], "entities": [{"text": "Valence-Arousal-Dominance (VAD", "start_pos": 45, "end_pos": 75, "type": "METRIC", "confidence": 0.7547780275344849}]}, {"text": "While being more expressive than polarity alone, existing word emotion induction methods are typically not suited for addressing it.", "labels": [], "entities": [{"text": "word emotion induction", "start_pos": 58, "end_pos": 80, "type": "TASK", "confidence": 0.6697633465131124}]}, {"text": "To overcome this limitation, we present adaptations of two popular algorithms to VAD.", "labels": [], "entities": [{"text": "VAD", "start_pos": 81, "end_pos": 84, "type": "TASK", "confidence": 0.7356293201446533}]}, {"text": "To measure their effectiveness in diachronic settings, we present the first gold standard for historical word emotions, which was created by scholars with proficiency in the respective language stages and covers both English and German.", "labels": [], "entities": []}, {"text": "In contrast to claims in previous work, our findings indicate that hand-selecting small sets of seed words with supposedly stable emotional meaning is actually harm-rather than helpful.", "labels": [], "entities": []}], "introductionContent": [{"text": "Language change is ubiquitous and, perhaps, most evident in lexical semantics.", "labels": [], "entities": []}, {"text": "In this work, we focus on changes in the affective meaning of words overtime.", "labels": [], "entities": []}, {"text": "Although this problem has been occasionally addressed in previous work (see Section 2.3), most contributions in this area are limited to a rather shallow understanding of human emotion, typically in terms of semantic * These authors contributed equally to this work.", "labels": [], "entities": []}, {"text": "Johannes Hellrich was responsible for selecting historical text corpora and training embedding models.", "labels": [], "entities": []}, {"text": "Sven Buechel selected existing emotion lexicons and was responsible for modeling word emotions.", "labels": [], "entities": []}, {"text": "The adaptation of polarity-based algorithms (Section 3), the creation of the German and English historical gold standard lexicons (Section 5.1), as well as the overall study design were done jointly.", "labels": [], "entities": []}, {"text": "polarity (feelings being either positive, negative or neutral).", "labels": [], "entities": []}, {"text": "Another major shortcoming of this area is the lack of appropriate data and methodologies for evaluation.", "labels": [], "entities": []}, {"text": "As a result, the aptness of algorithmic contributions has so far only been assessed in terms of face validity rather than quantitative performance figures.", "labels": [], "entities": [{"text": "aptness", "start_pos": 17, "end_pos": 24, "type": "METRIC", "confidence": 0.9555612802505493}]}, {"text": "To tackle those shortcomings, we first introduce adaptations of algorithms for word polarity induction to vectorial emotion annotation formats, thus enabling a more fine-grained analysis.", "labels": [], "entities": [{"text": "word polarity induction", "start_pos": 79, "end_pos": 102, "type": "TASK", "confidence": 0.8019228676954905}]}, {"text": "Second, to put the evaluation of these methods on safer ground, we present two datasets of affective word ratings for English and German, respectively.", "labels": [], "entities": []}, {"text": "1 These have been annotated by scholars in terms of language-stage-specific emotional connotations.", "labels": [], "entities": []}, {"text": "We ran synchronic as well as diachronic experiments to compare different algorithms for modeling historical word emotions-the latter kind of evaluation employs our newly created gold standard.", "labels": [], "entities": []}, {"text": "In particular, one prominent claim from previous work has been that full-sized emotion lexicons of contemporary language are ill-suited for inducing historical word emotion.", "labels": [], "entities": []}, {"text": "Rather, it would be much more beneficial to select a small, limited set of seed words of supposedly invariant emotional meaning ().", "labels": [], "entities": []}, {"text": "In contrast, our experiments indicate that larger sets of seed words perform better than manually selected ones despite the fact that some of their entries may not be accurate for the target language stage.", "labels": [], "entities": []}, {"text": "Our unique historical gold standard is thus an important step towards firmer methodological underpinnings for the computational analysis of textually encoded historical emotions.", "labels": [], "entities": [{"text": "computational analysis of textually encoded historical emotions", "start_pos": 114, "end_pos": 177, "type": "TASK", "confidence": 0.8031865613801139}]}], "datasetContent": [{"text": "In general, native speakers fluent in the respective (sub)language are the only viable option for acquiring a gold standard lexicon of emotional meaning for any language or domain.", "labels": [], "entities": []}, {"text": "In the case of historical language older than about a century, this option is off the table due to biological reasons-we simply lack native speakers competent for that specific language period.", "labels": [], "entities": []}, {"text": "As the best conceivable surrogate, we rely on historical language experts for constructing our dataset.", "labels": [], "entities": []}, {"text": "The gold standard consists of two parts, an English and a German one, each with 100 words.", "labels": [], "entities": []}, {"text": "We recruited three annotators for German and two for English, all doctoral students experienced in interpreting 19th century texts.", "labels": [], "entities": [{"text": "interpreting 19th century texts", "start_pos": 99, "end_pos": 130, "type": "TASK", "confidence": 0.8936680108308792}]}, {"text": "We selected high-frequency words for the annotation to ensure high quality of the associated word embeddings.", "labels": [], "entities": []}, {"text": "The selection was done by, first, extracting adjectives, common nouns and lexical verbs from the 1830s COHA and the 1810-1839 DTA subcorpus and then, second, randomly sampling 100 words out of the 1000 most frequent ones.", "labels": [], "entities": [{"text": "COHA and the 1810-1839 DTA subcorpus", "start_pos": 103, "end_pos": 139, "type": "DATASET", "confidence": 0.6354257265726725}]}, {"text": "We manually excluded two cases of ordinal numerals misclassified as adjectives.", "labels": [], "entities": []}, {"text": "The actual rating process was setup as a questionnaire study following established designs from psychological research).", "labels": [], "entities": []}, {"text": "The participants were requested to put themselves in the position of a person living between 1810 and 1839 for the German data set, or a person living in the 1830s for the English one.", "labels": [], "entities": [{"text": "German data set", "start_pos": 115, "end_pos": 130, "type": "DATASET", "confidence": 0.903156042098999}]}, {"text": "They were then presented with stimulus words and used the so-called SelfAssessment Manikin (SAM; to judge the kind of feeling evoked by these lexical items.", "labels": [], "entities": []}, {"text": "SAM consists of three individual nine-point scales, one for each VAD dimension.", "labels": [], "entities": [{"text": "SAM", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.82942134141922}]}, {"text": "Each of the 27 rating points is illustrated by an cartoon-like anthropomorphic figure serving as a non-verbal description of the scale.", "labels": [], "entities": []}, {"text": "Moreover, these figures are supplemented by verbal anchors for the low and high end points of the scales e.g., the rating point \"9\" of the Valence scale represents \"complete happiness\".", "labels": [], "entities": [{"text": "Valence scale", "start_pos": 139, "end_pos": 152, "type": "DATASET", "confidence": 0.7169371247291565}]}, {"text": "They were not provided with or instructed to use any further material or references, e.g., dictionaries.", "labels": [], "entities": []}, {"text": "The final ratings for each word were derived by averaging the individual ratings of the annotators.", "labels": [], "entities": []}, {"text": "We measure inter-annotator agreement (IAA) by calculating the standard deviation (SD) for each word and dimension and averaging these, first, for each dimension alone, and then over these aggregate values, thus constituting an error-based score (the lower the better).", "labels": [], "entities": [{"text": "inter-annotator agreement (IAA)", "start_pos": 11, "end_pos": 42, "type": "METRIC", "confidence": 0.7884873628616333}, {"text": "standard deviation (SD)", "start_pos": 62, "end_pos": 85, "type": "METRIC", "confidence": 0.9710747361183166}]}, {"text": "In comparison with the lexicon by, our gold standard displays higher rating consistency.", "labels": [], "entities": [{"text": "consistency", "start_pos": 76, "end_pos": 87, "type": "METRIC", "confidence": 0.6865758299827576}]}, {"text": "As average overall three VAD dimensions, our lexicon displays an IAA of 1.23 and 1.86 for English and German, respectively, compared to 2.05 as reported by.", "labels": [], "entities": [{"text": "VAD dimensions", "start_pos": 25, "end_pos": 39, "type": "METRIC", "confidence": 0.8414704203605652}, {"text": "IAA", "start_pos": 65, "end_pos": 68, "type": "METRIC", "confidence": 0.9993441700935364}]}, {"text": "This suggests that experts show higher consensus, even when judging word emotions fora historical language period, than crowdworkers for contemporary language.", "labels": [], "entities": [{"text": "consensus", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9745740294456482}]}, {"text": "An alternative explanation might be differences in word material, i.e., our random sample of frequent words.", "labels": [], "entities": []}, {"text": "Next, we provide a short comparison of historical and modern emotion ratings.", "labels": [], "entities": []}, {"text": "This analysis is restricted to the English language, because the overlap of the historical and modern German lexicons is really small (13 words compared to 97 for English).", "labels": [], "entities": [{"text": "overlap", "start_pos": 65, "end_pos": 72, "type": "METRIC", "confidence": 0.9712114930152893}]}, {"text": "This difference is most likely due to the fact that the English modern lexicon is more than an order of magnitude larger than the German one.: Illustrative example words with large deviation between historical and modern affective meaning; Valence-Arousal-Dominance (VAD) of newly created gold standard compared to.", "labels": [], "entities": [{"text": "Valence-Arousal-Dominance (VAD)", "start_pos": 240, "end_pos": 271, "type": "METRIC", "confidence": 0.914744421839714}]}, {"text": "The Pearson correlation between modern and historical lexicons is 0.66, 0.51, and 0.31 for Valence, Arousal, and Dominance, respectively.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 4, "end_pos": 23, "type": "METRIC", "confidence": 0.963485449552536}, {"text": "Valence", "start_pos": 91, "end_pos": 98, "type": "METRIC", "confidence": 0.9251026511192322}, {"text": "Arousal", "start_pos": 100, "end_pos": 107, "type": "METRIC", "confidence": 0.8805559873580933}]}, {"text": "displays illustrative examples from our newly created gold standard where historical and modern affective meaning differ strongly.", "labels": [], "entities": []}, {"text": "We conducted a post-facto interview on annotator motivation for those cases.", "labels": [], "entities": []}, {"text": "Explanations-which match observations described in common reference textbooks (e.g.,)-range from the influence of feminism leading to an increase in Valence for \"daughter\" up to secularization that might explain a drop in Arousal and rise in Dominance for \"divine\".", "labels": [], "entities": [{"text": "Valence", "start_pos": 149, "end_pos": 156, "type": "METRIC", "confidence": 0.9956670999526978}, {"text": "Arousal", "start_pos": 222, "end_pos": 229, "type": "METRIC", "confidence": 0.9924347400665283}, {"text": "Dominance", "start_pos": 242, "end_pos": 251, "type": "METRIC", "confidence": 0.8020907044410706}]}, {"text": "The annotation for \"strange\" was motivated by several now obsolete senses indicating foreignness or alienness.", "labels": [], "entities": []}, {"text": "In summary, we recruited historical language experts as best conceivable surrogate to compensate for the lack of actual native speakers in order to create a gold standard for historical word emotions.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, no comparable dataset is elsewhere available, making this contribution unique and hopefully valuable for future research, despite its obvious size limitation.", "labels": [], "entities": []}, {"text": "Our first evaluation of lexicon induction algorithms compares the ability of the three different algorithms described in Section 3 to predict ratings of a modern, contemporary VAD lexicon, i.e., the one by, using two different types of seed sets (see below).", "labels": [], "entities": []}, {"text": "For this experiment, we used word embeddings trained on the 2000s COHA subcorpus.", "labels": [], "entities": [{"text": "COHA subcorpus", "start_pos": 66, "end_pos": 80, "type": "DATASET", "confidence": 0.9172167778015137}]}, {"text": "We call this evaluation setup synchronic in the linguistic sense, since seed lexicon, target lexicon and word embeddings belong to the same language period.", "labels": [], "entities": []}, {"text": "A unique feature of our work here is that we also take into account possible interaction effects between lexicon induction algorithms and word embedding algorithms, i.e., SGNS and SVD PPMI . We use two different seed lexicons, both are based on the word ratings by.", "labels": [], "entities": []}, {"text": "The full seed lexicon corresponds to all the entries of words which are also present in ANEW (about 1,000 words; see Section 2).", "labels": [], "entities": [{"text": "ANEW", "start_pos": 88, "end_pos": 92, "type": "DATASET", "confidence": 0.8887578248977661}]}, {"text": "In contrast, the limited seed lexicon is restricted to 19 words 6 which were identified as temporally stable by.", "labels": [], "entities": []}, {"text": "The first setup is thus analogous to the polarity experiments performed by, whereas the second one corresponds to the settings from.", "labels": [], "entities": []}, {"text": "We use Pearson's r between actual and predicted values for each emotion dimension (Valence, Arousal and Dominance) for quantifying performance 7 and a One of the 20 words given by, \"hated\", is not present in the Warriner lexicon and was therefore eliminated.", "labels": [], "entities": [{"text": "Valence", "start_pos": 83, "end_pos": 90, "type": "METRIC", "confidence": 0.9748859405517578}, {"text": "Arousal and Dominance)", "start_pos": 92, "end_pos": 114, "type": "METRIC", "confidence": 0.8402412235736847}, {"text": "Warriner lexicon", "start_pos": 212, "end_pos": 228, "type": "DATASET", "confidence": 0.9035569727420807}]}, {"text": "7 Some other studies use the rank correlation coefficient Kendall's \u03c4 . We found that for our experiments the results are overall consistent between both metrics.", "labels": [], "entities": [{"text": "rank correlation coefficient Kendall's \u03c4", "start_pos": 29, "end_pos": 69, "type": "METRIC", "confidence": 0.9032470186551412}]}, {"text": "In the following we only report Pearson's r as it is specifically designed for: Results of the diachronic evaluation in Pearson's r averaged overall three VAD dimensions.", "labels": [], "entities": [{"text": "Pearson's r", "start_pos": 32, "end_pos": 43, "type": "DATASET", "confidence": 0.8226411938667297}, {"text": "VAD", "start_pos": 155, "end_pos": 158, "type": "METRIC", "confidence": 0.9981352090835571}]}, {"text": "The best system for each language and seed selection strategy (full vs. limited) is in bold.", "labels": [], "entities": []}, {"text": "Only the system marked with ' ' is significantly different from the best system (p < 0.05).", "labels": [], "entities": []}, {"text": "Fisher transformation followed by a Z-test for significance testing.", "labels": [], "entities": [{"text": "significance testing", "start_pos": 47, "end_pos": 67, "type": "TASK", "confidence": 0.8267978429794312}]}, {"text": "provides the average values of these VAD correlations for each seed lexicon, embedding method and induction algorithm.", "labels": [], "entities": [{"text": "VAD correlations", "start_pos": 37, "end_pos": 53, "type": "METRIC", "confidence": 0.9263458847999573}]}, {"text": "SGNS embeddings are worse than SVD PPMI embeddings for both full and limited seed lexicons.", "labels": [], "entities": []}, {"text": "SVD PPMI embeddings seem to be better suited for induction based on the full seed set, leading to the highest observed correlation with PARASIMNUM.", "labels": [], "entities": [{"text": "PARASIMNUM", "start_pos": 136, "end_pos": 146, "type": "METRIC", "confidence": 0.8087926506996155}]}, {"text": "However, results with other induction algorithms are not significantly different.", "labels": [], "entities": []}, {"text": "For the limited seed set, consistent with claims by, RANDOMWALKNUM is significantly better than all alternative approaches.", "labels": [], "entities": [{"text": "RANDOMWALKNUM", "start_pos": 53, "end_pos": 66, "type": "METRIC", "confidence": 0.9490816593170166}]}, {"text": "However, all results with the limited seed set are far (and significantly) worse than those with the full seed lexicon.", "labels": [], "entities": []}, {"text": "Performance is known to differ between VAD dimensions, i.e., Valence is usually the easiest one to predict.", "labels": [], "entities": [{"text": "Valence", "start_pos": 61, "end_pos": 68, "type": "METRIC", "confidence": 0.9932378530502319}]}, {"text": "For the full seed lexicon and the best induction method, PARASIMNUM with SVD PPMI embeddings, we found Pearson's r correlation to range between 0.679 for Valence, 0.445 for Arousal and 0.547 for Dominance.", "labels": [], "entities": [{"text": "PARASIMNUM", "start_pos": 57, "end_pos": 67, "type": "METRIC", "confidence": 0.987992525100708}, {"text": "Pearson's r correlation", "start_pos": 103, "end_pos": 126, "type": "METRIC", "confidence": 0.9124752879142761}, {"text": "Arousal", "start_pos": 173, "end_pos": 180, "type": "METRIC", "confidence": 0.9734529256820679}, {"text": "Dominance", "start_pos": 195, "end_pos": 204, "type": "DATASET", "confidence": 0.8089548945426941}]}, {"text": "The second evaluation set-up utilizes our historical gold standard described in Section 5.1.", "labels": [], "entities": []}, {"text": "In contrast, Kendall's \u03c4 only captures ordinal information and is therefore less suited for VAD.", "labels": [], "entities": [{"text": "VAD", "start_pos": 92, "end_pos": 95, "type": "TASK", "confidence": 0.9357995986938477}]}, {"text": "this set-up diachronic, since the emotion lexicons generated in our experiments aim to match word use of historical language stages, whereas the seed values used for this process stem from contemporary language.", "labels": [], "entities": []}, {"text": "This approach allows us to test the recent claim that artificially limiting seed lexicons to words assumed to be semantically stable overlong time spans is beneficial for generating historical emotion lexicons).", "labels": [], "entities": []}, {"text": "We used Pearson's r correlation and the Z-test, as in Section 6.2.", "labels": [], "entities": [{"text": "Pearson's r correlation", "start_pos": 8, "end_pos": 31, "type": "METRIC", "confidence": 0.5953834354877472}]}, {"text": "Again, we investigate interactions between lexicon induction algorithms and embedding types.", "labels": [], "entities": []}, {"text": "For English, we evaluate with both full and limited seed lexicons, whereas for German, we evaluate only using the full seed lexicon (ANGST, see Section 2) since most entries of the English limited lexicon have no corresponding entry in ANGST.", "labels": [], "entities": [{"text": "ANGST", "start_pos": 133, "end_pos": 138, "type": "DATASET", "confidence": 0.7206609845161438}, {"text": "ANGST", "start_pos": 236, "end_pos": 241, "type": "DATASET", "confidence": 0.9361847043037415}]}, {"text": "Embeddings are based on the 1830s COHA subcorpus for English and on the 1810-1839 DTA subcorpus for German, thus matching the time frames featured by our gold standard.", "labels": [], "entities": [{"text": "COHA subcorpus", "start_pos": 34, "end_pos": 48, "type": "DATASET", "confidence": 0.8427495360374451}, {"text": "DTA subcorpus", "start_pos": 82, "end_pos": 95, "type": "DATASET", "confidence": 0.8429300487041473}]}, {"text": "The results of this experiment are given in.", "labels": [], "entities": []}, {"text": "For English, using the full seed lexicons, we achieve performance figures around r = .35.", "labels": [], "entities": []}, {"text": "In contrast, using the limited seed lexicon we find that the performance is markedly weaker in each of our six conditions compared to using the full seed lexicon.", "labels": [], "entities": []}, {"text": "This observation directly opposes the claims from who argued that their hand selected set of emotionally stable seed words would boost performance relative to using the full, contemporary dataset as seeds.", "labels": [], "entities": []}, {"text": "Our finding is statistically significant in only one of all cases (the combination of SGNS and RANDOMWALKNUM).", "labels": [], "entities": [{"text": "SGNS", "start_pos": 86, "end_pos": 90, "type": "DATASET", "confidence": 0.5182223916053772}, {"text": "RANDOMWALKNUM", "start_pos": 95, "end_pos": 108, "type": "METRIC", "confidence": 0.8654815554618835}]}, {"text": "However, the fact that we get the identical outcomes for all the other five combinations of embedding and induction algorithm strongly indicates that using the full seed set is virtually superior, even though the differences are not statistically significant when looking at the individual conditions in isolation, due to the size 8 of our gold standard.", "labels": [], "entities": []}, {"text": "Note that this outcome is also consistent with our results from the synchronic evaluation where we did find significant differences.", "labels": [], "entities": []}, {"text": "German results with the full seed lexicon are similar to those for English.", "labels": [], "entities": []}, {"text": "Here, however, the SGNS embeddings are outperformed by SVD PPMI , whereas for English both are competitive.", "labels": [], "entities": []}, {"text": "A possible explanation for this result might be differences in pre-processing between the two data sets which were necessary due to the more complex morphology of the German language.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Sample Valence-Arousal-Dominance (VAD)  ratings from the emotion lexicon by", "labels": [], "entities": [{"text": "Sample Valence-Arousal-Dominance (VAD)", "start_pos": 10, "end_pos": 48, "type": "METRIC", "confidence": 0.771044647693634}]}, {"text": " Table 2: Inter-annotator agreement for our English  (goldEN) and German (goldDE) gold standard, as  well as the lexicon by Warriner et al. (2013) for  comparision; Averaged standard deviation of ratings  for each VAD dimension and mean over all dimensions.", "labels": [], "entities": [{"text": "English  (goldEN) and German (goldDE) gold standard", "start_pos": 44, "end_pos": 95, "type": "DATASET", "confidence": 0.6256778050552715}, {"text": "VAD", "start_pos": 214, "end_pos": 217, "type": "METRIC", "confidence": 0.5962055921554565}]}, {"text": " Table 3: Illustrative example words with large devia- tion between historical and modern affective meaning;  Valence-Arousal-Dominance (VAD) of newly created  gold standard compared to", "labels": [], "entities": [{"text": "Valence-Arousal-Dominance (VAD)", "start_pos": 110, "end_pos": 141, "type": "METRIC", "confidence": 0.9479269236326218}]}, {"text": " Table 4: Results of the synchronic evaluation in Pearson's r averaged over all three VAD dimensions. The best  system for each seed lexicon and those with statistically non-significant differences (p \u2265 0.05) are in bold.", "labels": [], "entities": [{"text": "Pearson's r", "start_pos": 50, "end_pos": 61, "type": "DATASET", "confidence": 0.9434531529744467}, {"text": "VAD", "start_pos": 86, "end_pos": 89, "type": "METRIC", "confidence": 0.9687370657920837}]}, {"text": " Table 5: Results of the diachronic evaluation in Pearson's r averaged over all three VAD dimensions. The best  system for each language and seed selection strategy (full vs. limited) is in bold. Only the system marked with ' '  is significantly different from the best system (p < 0.05).", "labels": [], "entities": [{"text": "Pearson's r", "start_pos": 50, "end_pos": 61, "type": "DATASET", "confidence": 0.9587626258532206}, {"text": "VAD", "start_pos": 86, "end_pos": 89, "type": "METRIC", "confidence": 0.695381760597229}]}]}