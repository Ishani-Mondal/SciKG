{"title": [{"text": "Is It Worth the Attention? A Comparative Evaluation of Attention Layers for Argument Unit Segmentation", "labels": [], "entities": [{"text": "Argument Unit Segmentation", "start_pos": 76, "end_pos": 102, "type": "TASK", "confidence": 0.6924540201822916}]}], "abstractContent": [{"text": "Attention mechanisms have seen some success for natural language processing downstream tasks in recent years and generated new state-of-the-art results.", "labels": [], "entities": []}, {"text": "A thorough evaluation of the attention mechanism for the task of Argu-mentation Mining is missing.", "labels": [], "entities": [{"text": "Argu-mentation Mining", "start_pos": 65, "end_pos": 86, "type": "TASK", "confidence": 0.6776598691940308}]}, {"text": "With this paper, we report a comparative evaluation of attention layers in combination with a bidirectional long short-term memory network, which is the current state-of-the-art approach for the unit segmentation task.", "labels": [], "entities": [{"text": "unit segmentation task", "start_pos": 195, "end_pos": 217, "type": "TASK", "confidence": 0.7989639441172282}]}, {"text": "We also compare sentence-level contextualized word embeddings to pre-generated ones.", "labels": [], "entities": []}, {"text": "Our findings suggest that for this task, the additional attention layer does not improve the performance.", "labels": [], "entities": []}, {"text": "In most cases, contextualized embeddings do also not show an improvement on the score achieved by pre-defined embeddings.", "labels": [], "entities": []}], "introductionContent": [{"text": "Argumentation Mining (AM) is increasingly applied in different fields of research like fake-news detection  and political argumentation and network analysis (.", "labels": [], "entities": [{"text": "Argumentation Mining (AM)", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8907883048057557}, {"text": "fake-news detection", "start_pos": 87, "end_pos": 106, "type": "TASK", "confidence": 0.7695320546627045}, {"text": "network analysis", "start_pos": 140, "end_pos": 156, "type": "TASK", "confidence": 0.732667475938797}]}, {"text": "One crucial part of the AM pipeline is to segment written text into argumentative and nonargumentative units.", "labels": [], "entities": []}, {"text": "Recent research in the area of unit segmentation) has lead to promising results with F1-scores of up to 0.90 for in-domain segmentation.", "labels": [], "entities": [{"text": "unit segmentation", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.7201673686504364}, {"text": "F1-scores", "start_pos": 85, "end_pos": 94, "type": "METRIC", "confidence": 0.9993867874145508}]}, {"text": "Nevertheless, there is still a need for more robust approaches.", "labels": [], "entities": []}, {"text": "Given the recent progress of attention-based models in Neural Machine Translation (NMT), this paper evaluates the effectiveness of seperate attention layers for the task of argumentative unit segmentation.", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT)", "start_pos": 55, "end_pos": 87, "type": "TASK", "confidence": 0.819739451011022}, {"text": "argumentative unit segmentation", "start_pos": 173, "end_pos": 204, "type": "TASK", "confidence": 0.6488882303237915}]}, {"text": "The idea of the attention layers added * The first two authors contributed equally.", "labels": [], "entities": []}, {"text": "Their listing order is random.", "labels": [], "entities": [{"text": "listing order", "start_pos": 6, "end_pos": 19, "type": "TASK", "confidence": 0.8788221478462219}]}, {"text": "to the recurrent networks is to preprocess the input data and enable the model to prioritize those parts of the input sequence that are important for the current prediction ().", "labels": [], "entities": []}, {"text": "This can be achieved by learning additional parameters during the training of the model.", "labels": [], "entities": []}, {"text": "With the additional information gained, the model learns a better internal representation which improves performance.", "labels": [], "entities": []}, {"text": "Additionally, we evaluate the impact of contextualized distributed term representations (also referred to as word embeddings hereinafter) on all our models.", "labels": [], "entities": []}, {"text": "The goal of word embeddings is to represent a word as a high-dimensional vector that encodes its approximate meaning.", "labels": [], "entities": []}, {"text": "This vector will be generated by a model trained on a language modeling task, like next-word prediction, fora given text corpus.", "labels": [], "entities": [{"text": "next-word prediction", "start_pos": 83, "end_pos": 103, "type": "TASK", "confidence": 0.7615830302238464}]}, {"text": "The representation is based on the word's surrounding context in the corpus.", "labels": [], "entities": []}, {"text": "Words with a similar semantic meaning should then also have similar vector representations, as measured by their distance in the vector space.", "labels": [], "entities": []}, {"text": "Different methods to pre-compute the embeddings include word2vec (), FastText () and GloVe ().", "labels": [], "entities": [{"text": "word2vec", "start_pos": 56, "end_pos": 64, "type": "DATASET", "confidence": 0.9102046489715576}]}, {"text": "To make use of the capabilities of pre-trained Language Models (LMs), such as BERT () or Flair (, we evaluate how well their semantic representations perform, by using contextualized word embeddings.", "labels": [], "entities": [{"text": "BERT", "start_pos": 78, "end_pos": 82, "type": "METRIC", "confidence": 0.9877899885177612}, {"text": "Flair", "start_pos": 89, "end_pos": 94, "type": "METRIC", "confidence": 0.6151648163795471}]}, {"text": "Those are, in contrast to previously mentioned methods, specific to the context of the word in the input sequence.", "labels": [], "entities": []}, {"text": "One major benefit is the fact that the time-consuming feature engineering could become obsolete since the features are implicitly encoded in the word embeddings.", "labels": [], "entities": []}, {"text": "Furthermore, a better semantic representation of the input could lead to better generalization capabilities of the model and, therefore, to better cross-domain performance.", "labels": [], "entities": []}, {"text": "This paper answers the following research questions, which will help to assess the importance of the attention layers and contextualized word embeddings for the argument unit segmentation task: \u2022 RQ1: To what extent can seperate attention layers help the model focus on the, for the task of unit segmentation relevant, sequence parts and how much do they influence the predictions?", "labels": [], "entities": [{"text": "argument unit segmentation task", "start_pos": 161, "end_pos": 192, "type": "TASK", "confidence": 0.7633944749832153}, {"text": "RQ1", "start_pos": 196, "end_pos": 199, "type": "METRIC", "confidence": 0.8525053262710571}]}, {"text": "\u2022 RQ2: What is the impact of contextualized distributed term representations like BERT () and Flair (Akbik et al., 2018) on the task of unit segmentation and do they improve upon pre-defined representations like GloVe?", "labels": [], "entities": [{"text": "BERT", "start_pos": 82, "end_pos": 86, "type": "METRIC", "confidence": 0.9673348665237427}, {"text": "Flair", "start_pos": 94, "end_pos": 99, "type": "METRIC", "confidence": 0.9633823037147522}, {"text": "unit segmentation", "start_pos": 136, "end_pos": 153, "type": "TASK", "confidence": 0.7152958661317825}]}, {"text": "The contributions of this paper are as follows: first, we present and evaluate new attention-based architectures for the task of argumentative text segmentation.", "labels": [], "entities": [{"text": "argumentative text segmentation", "start_pos": 129, "end_pos": 160, "type": "TASK", "confidence": 0.6252421438694}]}, {"text": "Second, we review the effectiveness of recently proposed contextualized word embedding approaches in regard to AM.", "labels": [], "entities": [{"text": "AM", "start_pos": 111, "end_pos": 113, "type": "TASK", "confidence": 0.9519568681716919}]}, {"text": "We will continue by presenting the previous work on this specific task, followed by a description of the different architectures used, the data set and the generation of the word embeddings.", "labels": [], "entities": []}, {"text": "Afterwards, we will report the results, followed by a discussion and the limitations.", "labels": [], "entities": []}, {"text": "We will finish with a conclusion and an outlook on possible future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: The weighted F1-scores for the Baseline and  all four variations. Results are shown per variation  and embedding. Each row shows the performance of  one architecture with different word embeddings as in- put vector. The highest score for each architecture is  marked in bold.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9873272776603699}]}]}