{"title": [{"text": "Saliency-driven Word Alignment Interpretation for Neural Machine Translation", "labels": [], "entities": [{"text": "Saliency-driven Word Alignment Interpretation", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.7835198193788528}, {"text": "Neural Machine Translation", "start_pos": 50, "end_pos": 76, "type": "TASK", "confidence": 0.6803775330384573}]}], "abstractContent": [{"text": "Despite their original goal to jointly learn to align and translate, Neural Machine Translation (NMT) models, especially Transformer, are often perceived as not learning inter-pretable word alignments.", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT)", "start_pos": 69, "end_pos": 101, "type": "TASK", "confidence": 0.8155885934829712}]}, {"text": "In this paper, we show that NMT models do learn interpretable word alignments, which could only be revealed with proper interpretation methods.", "labels": [], "entities": [{"text": "interpretable word alignments", "start_pos": 48, "end_pos": 77, "type": "TASK", "confidence": 0.6249951918919882}]}, {"text": "We propose a series of such methods that are model-agnostic, are able to be applied either offline or online, and do not require parameter update or architectural change.", "labels": [], "entities": []}, {"text": "We show that under the force decoding setup, the alignments induced by our interpretation method are of better quality than fast-align for some systems, and when performing free decoding, they agree well with the alignments induced by automatic alignment tools.", "labels": [], "entities": []}], "introductionContent": [{"text": "Neural Machine Translation (NMT) has made lots of advancements since its inception.", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8368270794550577}]}, {"text": "One of the key innovations that led to the largest improvements is the introduction of the attention mechanism (, which jointly learns word alignment and translation.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 135, "end_pos": 149, "type": "TASK", "confidence": 0.7205372899770737}]}, {"text": "Since then, the attention mechanism has gradually become a general technique in various NLP tasks, including summarization (, natural language inference () and speech recognition (.", "labels": [], "entities": [{"text": "summarization", "start_pos": 109, "end_pos": 122, "type": "TASK", "confidence": 0.9946659803390503}, {"text": "speech recognition", "start_pos": 160, "end_pos": 178, "type": "TASK", "confidence": 0.7835622131824493}]}, {"text": "Although word alignment is no longer a integral step like the case for Statistical Machine Translation (SMT) systems, there is a resurgence of interest in the community to study word alignment for NMT models.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 9, "end_pos": 23, "type": "TASK", "confidence": 0.8282691538333893}, {"text": "Statistical Machine Translation (SMT)", "start_pos": 71, "end_pos": 108, "type": "TASK", "confidence": 0.7856389135122299}, {"text": "word alignment", "start_pos": 178, "end_pos": 192, "type": "TASK", "confidence": 0.7608732581138611}]}, {"text": "Even for NMT, word alignments are useful for error analysis, inserting external vocabularies, and providing guidance for human translators   in computer-aided translation.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 14, "end_pos": 29, "type": "TASK", "confidence": 0.7620586454868317}, {"text": "error analysis", "start_pos": 45, "end_pos": 59, "type": "TASK", "confidence": 0.7001257389783859}, {"text": "computer-aided translation", "start_pos": 144, "end_pos": 170, "type": "TASK", "confidence": 0.6792611181735992}]}, {"text": "When aiming for the most accurate alignments, the state-of-the-art tools include GIZA++ ( and fast-align (, which are all external models invented in SMT era and need to be run as a separate post-processing step after the full sentence translation is complete.", "labels": [], "entities": [{"text": "GIZA", "start_pos": 81, "end_pos": 85, "type": "METRIC", "confidence": 0.8099828958511353}, {"text": "SMT", "start_pos": 150, "end_pos": 153, "type": "TASK", "confidence": 0.9712119102478027}]}, {"text": "As a direct result, they are not suitable for analyzing the internal decision processes of the neural machine translation models.", "labels": [], "entities": []}, {"text": "Besides, these models are hard to apply in the online fashion, i.e. in the middle of left-to-right translation process, such as the scenario in certain constrained decoding algorithms and in computeraided translation).", "labels": [], "entities": [{"text": "computeraided translation", "start_pos": 191, "end_pos": 216, "type": "TASK", "confidence": 0.6432978361845016}]}, {"text": "For these cases, the current common practice is to simply generate word alignments from attention weights between the encoder and decoder.", "labels": [], "entities": []}, {"text": "However, there are problems with this practice.", "labels": [], "entities": []}, {"text": "showed that attention-based word alignment interpretation maybe subject to \"off-by-one\" errors.;; pointed out that the attention-induced alignment is particularly noisy with Transformer models.", "labels": [], "entities": [{"text": "word alignment interpretation", "start_pos": 28, "end_pos": 57, "type": "TASK", "confidence": 0.7793635229269663}]}, {"text": "Because of this, some studies, such as; proposed either to add extra modules to generate higher quality word alignments, or to use these modules to further improve the model performance or interpretability.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 104, "end_pos": 119, "type": "TASK", "confidence": 0.7272356599569321}]}, {"text": "This paper is a step towards interpreting word alignments from NMT without relying on external models.", "labels": [], "entities": [{"text": "interpreting word alignments", "start_pos": 29, "end_pos": 57, "type": "TASK", "confidence": 0.8919206857681274}]}, {"text": "We argue that using only attention weights is insufficient for generating clean word alignment interpretations, which we demonstrate both conceptually and empirically.", "labels": [], "entities": [{"text": "word alignment interpretations", "start_pos": 80, "end_pos": 110, "type": "TASK", "confidence": 0.8117772241433462}]}, {"text": "We propose to use the notion of saliency to obtain word alignment interpretation of NMT predictions.", "labels": [], "entities": [{"text": "word alignment interpretation of NMT predictions", "start_pos": 51, "end_pos": 99, "type": "TASK", "confidence": 0.7567836741606394}]}, {"text": "Different from previous alignment models, our proposal is a pure interpretation method and does not require any parameter update or architecture change.", "labels": [], "entities": []}, {"text": "Nevertheless, we are able to reduce Alignment Error Rate (AER) by 10-20 points over the attention weight baseline under two evaluation settings we adopt (see for an example), and beat fast-align ( by as much as 8.7 points.", "labels": [], "entities": [{"text": "Alignment Error Rate (AER)", "start_pos": 36, "end_pos": 62, "type": "METRIC", "confidence": 0.96877521276474}]}, {"text": "Not only have we proposed a superior model interpretation method, but our empirical results also uncover that, contrary to common beliefs, architectures such as convolutional sequenceto-sequence models) have already implicitly learned highly interpretable word alignments, which sheds light on how future improvement should be made on these architectures.", "labels": [], "entities": [{"text": "model interpretation", "start_pos": 37, "end_pos": 57, "type": "TASK", "confidence": 0.7875185906887054}]}], "datasetContent": [{"text": "The best evaluation method would compare predicted word alignments against manually labeled word alignments between source sentences and NMT output sentences, but this is too costly for our study.", "labels": [], "entities": []}, {"text": "Instead, we conduct two automatic evaluations for our proposed method using resources available: \u2022 force decoding: take a human-annotated corpus, run NMT models to force-generate the target side of the corpus and measure AER against the human alignment; \u2022 free decoding: take the NMT prediction, obtain reasonably clean reference alignments between the prediction and the source and measure AER against this reference.", "labels": [], "entities": [{"text": "AER", "start_pos": 221, "end_pos": 224, "type": "METRIC", "confidence": 0.9924699664115906}, {"text": "AER", "start_pos": 391, "end_pos": 394, "type": "METRIC", "confidence": 0.9959632158279419}]}, {"text": "3 Notice that both automatic evaluation methods have their respective limitation: the force decoding method may force the model to predict something it deems unlikely, and thus generating noisy alignment; whereas the free decoding method lacks authentic references.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Alignment Error Rate (AER) with different saliency methods, under force decoding setting. GIZA++  and fast-align Offline results are quoted from Zenkel et al. (2019), whereas fast-align Online stands for our online  alignment result (c.f. Section 5.2). bidir refers to the symmetrized alignment results. Best results for each architec- ture are marked with underlines, and best interpretation/alignment results are respectively marked with boldface.  Numbers affected by hyper-parameter tuning are marked with *.", "labels": [], "entities": [{"text": "Alignment Error Rate (AER", "start_pos": 10, "end_pos": 35, "type": "METRIC", "confidence": 0.7857951819896698}, {"text": "GIZA", "start_pos": 100, "end_pos": 104, "type": "METRIC", "confidence": 0.8000187873840332}]}, {"text": " Table 2: Alignment Error Rate (AER) with different saliency models, under free decoding setting. See the caption  of Table 1 for notations.", "labels": [], "entities": [{"text": "Alignment Error Rate (AER)", "start_pos": 10, "end_pos": 36, "type": "METRIC", "confidence": 0.9372248550256094}]}, {"text": " Table 3: Alignment distribution entropy for selected de- en models. att stands for attention in", "labels": [], "entities": [{"text": "Alignment distribution entropy", "start_pos": 10, "end_pos": 40, "type": "TASK", "confidence": 0.8709977666536967}]}]}