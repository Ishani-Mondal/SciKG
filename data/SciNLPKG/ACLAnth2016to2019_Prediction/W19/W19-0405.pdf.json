{"title": [{"text": "An Improved Approach for Semantic Graph Composition with CCG", "labels": [], "entities": [{"text": "Semantic Graph Composition", "start_pos": 25, "end_pos": 51, "type": "TASK", "confidence": 0.7237040201822916}]}], "abstractContent": [{"text": "This paper builds on previous work using Combinatory Categorial Grammar (CCG) to derive a transparent syntax-semantics interface for Abstract Meaning Representation (AMR) parsing.", "labels": [], "entities": [{"text": "Abstract Meaning Representation (AMR) parsing", "start_pos": 133, "end_pos": 178, "type": "TASK", "confidence": 0.7543304860591888}]}, {"text": "We define new semantics for the CCG combinators that is better suited to deriving AMR graphs.", "labels": [], "entities": []}, {"text": "In particular, we define relation-wise alternatives for the application and composition combinators: these require that the two constituents being combined overlap in one AMR relation.", "labels": [], "entities": []}, {"text": "We also provide anew semantics for type raising, which is necessary for certain constructions.", "labels": [], "entities": [{"text": "type raising", "start_pos": 35, "end_pos": 47, "type": "TASK", "confidence": 0.8301654160022736}]}, {"text": "Using these mechanisms, we suggest an analysis of eventive nouns, which present a challenge for deriving AMR graphs.", "labels": [], "entities": []}, {"text": "Our theoretical analysis will facilitate future work on robust and transparent AMR parsing using CCG.", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 79, "end_pos": 90, "type": "TASK", "confidence": 0.9511559009552002}]}], "introductionContent": [{"text": "At the heart of semantic parsing are two goals: the disambiguation of linguistic forms that can have multiple meanings, and the normalization of morphological and syntactic variation.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 16, "end_pos": 32, "type": "TASK", "confidence": 0.7345629930496216}]}, {"text": "Among many techniques for semantic parsing, one profitable direction exploits computational linguistic grammar formalisms that make explicit the correspondence between the linguistic form of a sentence and the semantics (e.g., broad-coverage logical forms, or database queries in a domain-specific query language).", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 26, "end_pos": 42, "type": "TASK", "confidence": 0.7883789837360382}]}, {"text": "In particular, English semantic parsers using Combinatory Categorial Grammar) have been quite successful thanks to the CCGBank resource) and the broad-coverage statistical parsing models trained on it (e.g.,.", "labels": [], "entities": [{"text": "English semantic parsers", "start_pos": 15, "end_pos": 39, "type": "TASK", "confidence": 0.6114827891190847}, {"text": "CCGBank resource", "start_pos": 119, "end_pos": 135, "type": "DATASET", "confidence": 0.9719594717025757}, {"text": "broad-coverage statistical parsing", "start_pos": 145, "end_pos": 179, "type": "TASK", "confidence": 0.5747228761514028}]}, {"text": "The CCG formalism assumes that all language-specific grammatical information is stored in a lexicon: each word in the lexicon is associated with a structured syntactic category and a semantic form, such that the compositional potentials of the category and the semantics are isomorphic.", "labels": [], "entities": []}, {"text": "A small universal set of combinators are responsible for assembling constituents into a full syntactic derivation; each combinator operates on adjacent constituents with appropriate categories to produce anew constituent and its compositional semantics, subject to constraints.", "labels": [], "entities": []}, {"text": "A full grammar thus allows wellformed sentences to be transduced into semantic structures.", "labels": [], "entities": []}, {"text": "The categories and combinators cooperate to license productive syntactic constructions like control and wh-questions, requiring the correct word order and producing the correct semantic dependencies.", "labels": [], "entities": []}, {"text": "For example, consider the sentence \"Who did John seem to forget to invite to attend?\": the correct logical form-in propositional logic, something like seem(forget(John i , invite(John i , who j , attend(who j ))))-is nontrivial, requiring a precise account of several constructions that conspire to produce long-range dependencies.", "labels": [], "entities": []}, {"text": "Whereas CCG traditionally uses some version of lambda calculus for its semantics, there has also been initial work using CCG to build parsers for Abstract Meaning Representation (AMR;, a standard with which a large \"sembank\" of English sentences 1 has been manually annotated.", "labels": [], "entities": [{"text": "Abstract Meaning Representation", "start_pos": 146, "end_pos": 177, "type": "TASK", "confidence": 0.5920734802881876}]}, {"text": "To date, dozens of publications have used the corpus to train and evaluate semantic parsers-most using graph-based or transition-based parsing methods (e.g., to transform the sentence string or syntactic parse into a semantic graph via a learned statistical model, without any explicit characterization of the syntax-semantics interface.", "labels": [], "entities": []}, {"text": "There is good reason to apply CCG to the AMR parsing task: apart from transparency of the syntax-semantics interface, state-of-the-art AMR parsers are known to be weak at reentrancy (e.g.,, which presumably can be partially attributed to syntactic reentrancy in control constructions, for example.", "labels": [], "entities": [{"text": "AMR parsing task", "start_pos": 41, "end_pos": 57, "type": "TASK", "confidence": 0.9375226696332296}]}, {"text": "Prior work applying CCG to AMR parsing has begun to address this, but some of the important mechanisms that make CCG a linguistically powerful and robust theory have yet to be incorporated into these approaches.", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 27, "end_pos": 38, "type": "TASK", "confidence": 0.9515783786773682}]}, {"text": "In this paper, we build on a core insight of previous work (e.g.,) that AMR fragments can be directly represented as the semantics of CCG lexical entries.", "labels": [], "entities": []}, {"text": "With appropriate definitions of the lexical items and combinatorial rules of CCG, the compositionality of CCG gives a derivation of a full AMR \"for free\".", "labels": [], "entities": []}, {"text": "In other words, AMR parsing can be reduced to CCG parsing (plus some additional semantic disambiguation and postprocessing).", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 16, "end_pos": 27, "type": "TASK", "confidence": 0.9212681651115417}, {"text": "CCG parsing", "start_pos": 46, "end_pos": 57, "type": "TASK", "confidence": 0.6656792312860489}]}, {"text": "On a practical level, this should allow us to take advantage of existing CCG datasets and parsing methods for AMR parsing.", "labels": [], "entities": [{"text": "CCG datasets", "start_pos": 73, "end_pos": 85, "type": "DATASET", "confidence": 0.8861517310142517}, {"text": "parsing", "start_pos": 90, "end_pos": 97, "type": "TASK", "confidence": 0.9528123140335083}, {"text": "AMR parsing", "start_pos": 110, "end_pos": 121, "type": "TASK", "confidence": 0.9564469456672668}]}, {"text": "In addition, explicitly storing AMR fragments in the CCG lexicon would provide a level of interpretability not seen inmost statistical AMR parsers: the transparent syntax-semantics interface would decouple errors in the grammar from errors in the parsing model.", "labels": [], "entities": [{"text": "CCG lexicon", "start_pos": 53, "end_pos": 64, "type": "DATASET", "confidence": 0.850453794002533}]}, {"text": "As a prerequisite for building a CCG-based AMR parser, or inducing a broad-coverage grammar (CCG lexicon) from data, we consider in this paper the formal mechanisms that would be necessary to derive AMRs with linguistic robustness.", "labels": [], "entities": []}, {"text": "In particular, we address a variety of challenging syntactic phenomena with respect to AMR, showing the semantic fragments, associated syntactic categories, and combinators that will facilitate parsing of constructions including control, wh-questions, relative clauses, case marking, nonconstituent coordination, eventive nouns, and light verbs.", "labels": [], "entities": [{"text": "AMR", "start_pos": 87, "end_pos": 90, "type": "TASK", "confidence": 0.8424217104911804}, {"text": "case marking", "start_pos": 270, "end_pos": 282, "type": "TASK", "confidence": 0.7852078974246979}]}, {"text": "In so doing, we offer new semantics of combinators for semantic graphs beyond the proposals of previous work.", "labels": [], "entities": []}, {"text": "After an overview of related work ( \u00a72), we introduce our formalism for AMR graph semantics in CCG ( \u00a73).", "labels": [], "entities": [{"text": "AMR graph semantics", "start_pos": 72, "end_pos": 91, "type": "TASK", "confidence": 0.8495113650957743}, {"text": "CCG", "start_pos": 95, "end_pos": 98, "type": "DATASET", "confidence": 0.9394080638885498}]}, {"text": "\u00a74 gives example derivations for well-known linguistic phenomena including control, complex coordination, and eventive nouns.", "labels": [], "entities": []}, {"text": "\u00a75 discusses some implications of our approach.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}