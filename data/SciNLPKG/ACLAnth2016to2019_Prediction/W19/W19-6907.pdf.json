{"title": [{"text": "Adapting Term Recognition to an Under-Resourced Language: the Case of Irish", "labels": [], "entities": [{"text": "Adapting Term Recognition", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.9466141064961752}, {"text": "Irish", "start_pos": 70, "end_pos": 75, "type": "DATASET", "confidence": 0.7277417778968811}]}], "abstractContent": [{"text": "Automatic Term Recognition (ATR) is an important method for the summarization and analysis of large corpora, and normally requires a significant amount of linguistic input, in particular the use of part-of-speech taggers.", "labels": [], "entities": [{"text": "Automatic Term Recognition (ATR)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8337661226590475}, {"text": "summarization and analysis of large corpora", "start_pos": 64, "end_pos": 107, "type": "TASK", "confidence": 0.8492338160673777}]}, {"text": "For an under-resourced language such as Irish, the resources necessary for this maybe scarce or entirely absent.", "labels": [], "entities": []}, {"text": "We evaluate two methods for the automatic extraction of terms, based on the small part-of-speech-tagged corpora that are available for Irish and on a large terminology list, and show that both methods can produce viable term extractors.", "labels": [], "entities": [{"text": "automatic extraction of terms", "start_pos": 32, "end_pos": 61, "type": "TASK", "confidence": 0.7803661674261093}]}, {"text": "We evaluate this with a newly constructed corpus that is the first available corpus for term extraction in Irish.", "labels": [], "entities": [{"text": "term extraction in Irish", "start_pos": 88, "end_pos": 112, "type": "TASK", "confidence": 0.7303794324398041}]}, {"text": "Our results shine some light on the challenge of adapting natural language processing systems to under-resourced scenarios.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic term recognition (ATR) is the task of identifying relevant and interesting terms from a text corpus.", "labels": [], "entities": [{"text": "Automatic term recognition (ATR)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7972277800242106}]}, {"text": "This can be useful fora wide range of text understanding tasks, however most of the work on this task has to date focused on term extraction for English.", "labels": [], "entities": [{"text": "text understanding", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.8251972496509552}, {"text": "term extraction", "start_pos": 125, "end_pos": 140, "type": "TASK", "confidence": 0.7361646741628647}]}, {"text": "In contrast, there are up to 7,000 languages spoken in the world, most of which are severely under-resourced, and the task of adapting Natural Language Processing (NLP) tools to such languages is still not well explored.", "labels": [], "entities": []}, {"text": "The principle issue for these language is the lack of resources available and as such they are called under-resourced languages.", "labels": [], "entities": []}, {"text": "In this paper, we will focus on the development of automatic term recognition for the Irish language, an under-resourced Celtic language spoken primarily on the island of Ireland.", "labels": [], "entities": [{"text": "automatic term recognition", "start_pos": 51, "end_pos": 77, "type": "TASK", "confidence": 0.629005511601766}]}, {"text": "In particular, we will base our work on the previously developed Saffron system ().", "labels": [], "entities": []}, {"text": "The main requirements for this are the development of a partof-speech tagger, a lemmatizer and a large background corpus and we will detail in this paper how we constructed these models for Irish.", "labels": [], "entities": [{"text": "partof-speech tagger", "start_pos": 56, "end_pos": 76, "type": "TASK", "confidence": 0.72641322016716}]}, {"text": "In particular, the largest challenge was the construction of a part-of-speech tagger and we base our work on two main systems that have been developed based on annotated corpora.", "labels": [], "entities": []}, {"text": "Firstly, we look at the system of U\u00ed Dhonnchadha and van, which was developed on a general language domain and secondly we refer to the system of, which was developed specifically for tweets.", "labels": [], "entities": [{"text": "U\u00ed Dhonnchadha and van", "start_pos": 34, "end_pos": 56, "type": "DATASET", "confidence": 0.8736672550439835}]}, {"text": "We then looked at an alternative approach using the terminology database, Tearma 1 , to provide an annotation over the Irish Wikipedia, 'An Vicip\u00e9id' 2 . For both the systems trained on part-of-speech corpora and those on the terminology database, we compare them for the challenge of recognizing terms.", "labels": [], "entities": [{"text": "Irish Wikipedia", "start_pos": 119, "end_pos": 134, "type": "DATASET", "confidence": 0.9518658518791199}, {"text": "An Vicip\u00e9id' 2", "start_pos": 137, "end_pos": 151, "type": "DATASET", "confidence": 0.782963253557682}]}, {"text": "We show how we incorporate into our term recognition system morphology information extracted from Pota Focal.", "labels": [], "entities": [{"text": "term recognition", "start_pos": 36, "end_pos": 52, "type": "TASK", "confidence": 0.7309462428092957}, {"text": "Pota Focal", "start_pos": 98, "end_pos": 108, "type": "DATASET", "confidence": 0.8687792718410492}]}, {"text": "To analyse this we developed a small gold standard dataset of Wikipedia articles and compared the two methods on this dataset . We then describe the construction of the automatic term recognition system and compare the results of these two methods on a small corpus of discussion related to the future of the National University of Ireland Galway.", "labels": [], "entities": [{"text": "term recognition", "start_pos": 179, "end_pos": 195, "type": "TASK", "confidence": 0.7260655015707016}, {"text": "National University of Ireland Galway", "start_pos": 309, "end_pos": 346, "type": "DATASET", "confidence": 0.93458993434906}]}, {"text": "Our results show that both methods provide a viable method of constructing a term extraction system, however there is still a need for significant language specific knowledge in the development of such a system and that new generic methods would be necessary to scale this to more under-resourced languages.", "labels": [], "entities": [{"text": "term extraction", "start_pos": 77, "end_pos": 92, "type": "TASK", "confidence": 0.7213410586118698}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Analysis of part-of-speech Corpora used in this  work. #POS refers to the number of distinct top-level part  of speech categories.", "labels": [], "entities": [{"text": "POS", "start_pos": 66, "end_pos": 69, "type": "METRIC", "confidence": 0.9472628235816956}]}, {"text": " Table 4: Per-class performance of term extraction for various training inputs evaluated on the gold standard.", "labels": [], "entities": [{"text": "term extraction", "start_pos": 35, "end_pos": 50, "type": "TASK", "confidence": 0.7061024904251099}, {"text": "gold standard", "start_pos": 96, "end_pos": 109, "type": "DATASET", "confidence": 0.8979761898517609}]}]}