{"title": [{"text": "Context is Key: Grammatical Error Detection with Contextual Word Representations", "labels": [], "entities": [{"text": "Grammatical Error Detection", "start_pos": 16, "end_pos": 43, "type": "TASK", "confidence": 0.7487794558207194}]}], "abstractContent": [{"text": "Grammatical error detection (GED) in non-native writing requires systems to identify a wide range of errors in text written by language learners.", "labels": [], "entities": [{"text": "Grammatical error detection (GED)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8239292204380035}]}, {"text": "Error detection as a purely supervised task can be challenging, as GED datasets are limited in size and the label distributions are highly imbalanced.", "labels": [], "entities": [{"text": "Error detection", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7760213911533356}, {"text": "GED datasets", "start_pos": 67, "end_pos": 79, "type": "DATASET", "confidence": 0.8187025189399719}]}, {"text": "Contextual-ized word representations offer a possible solution , as they can efficiently capture composi-tional information in language and can be optimized on large amounts of unsupervised data.", "labels": [], "entities": []}, {"text": "In this paper, we perform a systematic comparison of ELMo, BERT and Flair embeddings (Peters et al., 2017; Devlin et al., 2018; Akbik et al., 2018) on a range of public GED datasets, and propose an approach to effectively integrate such representations in current methods, achieving anew state of the art on GED.", "labels": [], "entities": [{"text": "BERT", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.9872463941574097}, {"text": "GED datasets", "start_pos": 169, "end_pos": 181, "type": "DATASET", "confidence": 0.687328577041626}]}, {"text": "We further analyze the strengths and weaknesses of different contextual embeddings for the task at hand, and present detailed analyses of their impact on different types of errors.", "labels": [], "entities": []}], "introductionContent": [{"text": "Detecting errors in text written by language learners is a key component of pedagogical applications for language learning and assessment.", "labels": [], "entities": [{"text": "Detecting errors in text written by language learners", "start_pos": 0, "end_pos": 53, "type": "TASK", "confidence": 0.8881087079644203}]}, {"text": "Supervised learning approaches to the task exploit public error-annotated corpora) that are, however, limited in size, in addition to having a biased distribution of labels: the number of correct tokens in a text far outweighs the incorrect ().", "labels": [], "entities": []}, {"text": "As such, Grammatical Error Detection (GED) can be considered a low-/mid-resource task.", "labels": [], "entities": [{"text": "Grammatical Error Detection (GED)", "start_pos": 9, "end_pos": 42, "type": "TASK", "confidence": 0.8683764835198721}]}, {"text": "The current state of the art explores error detection within a semi-supervised, multi-task learning framework, using a neural sequence labeler optimized to detect errors as well as predict their surrounding context.", "labels": [], "entities": [{"text": "error detection", "start_pos": 38, "end_pos": 53, "type": "TASK", "confidence": 0.729509174823761}]}, {"text": "To further improve GED performance, recent work has investigated the use of artificially generated training data ().", "labels": [], "entities": [{"text": "GED", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.992871105670929}]}, {"text": "On the related task of grammatical error correction (GEC), explore transfer learning approaches to tackle the low-resource bottleneck of the task and, among others, find substantially improved performance when incorporating pre-trained word embeddings (, and importing network weights from a language model trained on a large unlabeled corpus.", "labels": [], "entities": [{"text": "grammatical error correction (GEC)", "start_pos": 23, "end_pos": 57, "type": "TASK", "confidence": 0.8142450749874115}]}, {"text": "Herein, we extend the current state of the art for error detection to effectively incorporate contextual embeddings: word representations that are constructed based on the context in which the words appear.", "labels": [], "entities": [{"text": "error detection", "start_pos": 51, "end_pos": 66, "type": "TASK", "confidence": 0.7437970042228699}]}, {"text": "These embeddings are typically the output of a set of hidden layers of a large language modelling network, trained on large volumes of unlabeled and general domain data.", "labels": [], "entities": []}, {"text": "As such, they are able to capture detailed information regarding language and composition from a wide range of data sources, and can help overcome resource limitations for supervised learning.", "labels": [], "entities": []}, {"text": "We evaluate the use of contextual embeddings in the form of Bidirectional Encoder Representations from Transformers (BERT), embeddings from Language Models (ELMo) ( and Flair embeddings.", "labels": [], "entities": [{"text": "BERT", "start_pos": 117, "end_pos": 121, "type": "METRIC", "confidence": 0.7832720875740051}]}, {"text": "To the best of our knowledge, this is the first evaluation of the use of contextual embeddings for the task of GED.", "labels": [], "entities": [{"text": "GED", "start_pos": 111, "end_pos": 114, "type": "TASK", "confidence": 0.8850936889648438}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Error detection precision, recall, and F 0.5 on the FCE and CoNLL-2014 test sets: test 1 and test 2 refer to  the two different CoNLL annotators. 'Baseline' refers to our own re-training of the model by Rei (2017).", "labels": [], "entities": [{"text": "Error detection precision", "start_pos": 10, "end_pos": 35, "type": "METRIC", "confidence": 0.7811053196589152}, {"text": "recall", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.9993795156478882}, {"text": "F 0.5", "start_pos": 49, "end_pos": 54, "type": "METRIC", "confidence": 0.9922178983688354}, {"text": "FCE and CoNLL-2014 test sets", "start_pos": 62, "end_pos": 90, "type": "DATASET", "confidence": 0.830574119091034}]}, {"text": " Table 2: Error detection precision, recall, and F 0.5 on the JFLEG test set and BEA 2019 GEC Shared Task devel- opment and test sets.", "labels": [], "entities": [{"text": "Error detection", "start_pos": 10, "end_pos": 25, "type": "METRIC", "confidence": 0.8530413210391998}, {"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.51320880651474}, {"text": "recall", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.9994481205940247}, {"text": "F 0.5", "start_pos": 49, "end_pos": 54, "type": "METRIC", "confidence": 0.9871051013469696}, {"text": "JFLEG test set", "start_pos": 62, "end_pos": 76, "type": "DATASET", "confidence": 0.965011994043986}, {"text": "BEA 2019 GEC Shared Task devel- opment", "start_pos": 81, "end_pos": 119, "type": "DATASET", "confidence": 0.8804426714777946}]}, {"text": " Table 3: Error detection F 0.5 of different embedding integration strategies ('input' vs. 'output') per model on all  datasets.", "labels": [], "entities": [{"text": "Error", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9369601607322693}]}, {"text": " Table 1: Overall recall of each model over all datasets broken out by ERRANT-induced POS-based error type,  with frequency of occurrence of each error type.", "labels": [], "entities": [{"text": "recall", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.99858558177948}, {"text": "ERRANT-induced POS-based error type", "start_pos": 71, "end_pos": 106, "type": "METRIC", "confidence": 0.8305913507938385}]}, {"text": " Table 2: Overall recall of each model over all datasets broken out by ERRANT-induced edit operation error type,  with frequency of occurrence of each error type.", "labels": [], "entities": [{"text": "recall", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9989639520645142}, {"text": "ERRANT-induced edit operation error type", "start_pos": 71, "end_pos": 111, "type": "METRIC", "confidence": 0.8938389658927918}]}]}