{"title": [{"text": "Content Customization for Micro Learning using Human Augmented AI Techniques", "labels": [], "entities": []}], "abstractContent": [{"text": "Visual content has been proven to be effective for micro-learning compared to other media.", "labels": [], "entities": []}, {"text": "In this paper, we discuss leveraging this observation in our efforts to build audiovisual content for young learners' vocabulary learning.", "labels": [], "entities": [{"text": "vocabulary learning", "start_pos": 118, "end_pos": 137, "type": "TASK", "confidence": 0.7393865287303925}]}, {"text": "We attempt to tackle two major issues in the process of traditional visual curation tasks.", "labels": [], "entities": []}, {"text": "Generic learning videos do not necessarily satisfy the unique context of a learner and/or an educator, and hence may not result in maximal learning outcomes.", "labels": [], "entities": []}, {"text": "Also, manual video cura-tion by educators is a highly labor-intensive process.", "labels": [], "entities": []}, {"text": "To this end, we present a customiz-able micro-learning audiovisual content cura-tion tool that is designed to reduce the human (educator) effort in creating just-in-time learning videos from a textual description (learn-ing script).", "labels": [], "entities": []}, {"text": "This provides educators with control of the content while preparing the learning scripts.", "labels": [], "entities": []}, {"text": "As a use case, we automatically generate learning videos with British National Corpus' (BNC) frequently spoken vocabulary words and evaluate them with experts.", "labels": [], "entities": [{"text": "British National Corpus' (BNC) frequently spoken vocabulary words", "start_pos": 62, "end_pos": 127, "type": "DATASET", "confidence": 0.9572362244129181}]}, {"text": "They positively recommended the generated learning videos with an average rating of 4.25 on a Likert scale of 5 points.", "labels": [], "entities": []}, {"text": "The inter-annotator agreement between the experts for the video quality was substantial (Fleiss Kappa=0.62) with an overall agreement of 81%.", "labels": [], "entities": [{"text": "Fleiss Kappa=0.62", "start_pos": 89, "end_pos": 106, "type": "METRIC", "confidence": 0.9747804552316666}]}], "introductionContent": [{"text": "Various studies have shown that learning with audio-visual content leads to better retention and engagement than just reading text or listening to spoken content).", "labels": [], "entities": [{"text": "retention", "start_pos": 83, "end_pos": 92, "type": "METRIC", "confidence": 0.9699621200561523}]}, {"text": "The flipped-classroom model) makes a case for increased use of videos in learning, where students can use audiovisual content to learn concepts at their own pace, freeing up the educator's time to prepare for other personalized one-on-one interactions with their students.", "labels": [], "entities": []}, {"text": "This approach is especially attractive for micro-learning that deals with relatively small learning units and short-term learning activities.", "labels": [], "entities": []}, {"text": "As much as educators (including parents and caregivers) desire to use audio-visual content to make learning more engaging, customized content production is often difficult to scale and cost prohibitive.", "labels": [], "entities": []}, {"text": "While instructors could create their own customized content, this is labor-intensive, given the wide variety of concepts and domain areas children need to be exposed to.", "labels": [], "entities": []}, {"text": "Every educator may have a different learning-objective in mind.", "labels": [], "entities": []}, {"text": "To teach a vocabulary word, instructors provide a definition of the word highlighting the important characteristics of it along with some contextual information).", "labels": [], "entities": []}, {"text": "For instance, if a teacher wants to teach about \"Elephant\" focusing on its habitat she may want to show Elephant in Forests, and Grasslands.", "labels": [], "entities": []}, {"text": "However, a generic video obtained from the web may emphasize on the different body parts of the Elephant.", "labels": [], "entities": []}, {"text": "Moreover, the student's age is an important factor.", "labels": [], "entities": []}, {"text": "If teaching a concept to a small child, educators would want to avoid violent or inappropriate images.", "labels": [], "entities": []}, {"text": "Similarly, a slightly grownup learner may not resonate with cartoons being shown for learning.", "labels": [], "entities": []}, {"text": "Hence, the educator should have an option to customize scripts to reflect their intended learning objective and be able to control the appropriateness of visuals.", "labels": [], "entities": []}, {"text": "To this end, we explore a humanaugmented approach that leverages AI techniques for creating customized content by a just-in-time combination of contextual image content mined from the Internet, along with appropriate voiceover.", "labels": [], "entities": []}, {"text": "This human-machine semi-automated approach has high potential to address the instructional needs of young learners who are in the process of acquiring basic conceptual ideas across domains for the first time, particularly in areas that need identification and recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 260, "end_pos": 266, "type": "METRIC", "confidence": 0.9875282645225525}]}, {"text": "The trade-off between the agility of content production and content customization exposes a wide design space (as depicted in).", "labels": [], "entities": []}, {"text": "Most learner-oblivious content falls into the bottom left quadrant, which works well when the content does not require customization (like content including hard facts such as the place or year an event occurred, the name of an inventor etc.).", "labels": [], "entities": []}, {"text": "Solutions in the bottom right quadrant enable flexible and efficient creation of content at run-time, allowing for more flexibility of content presentation, although it requires upfront planning of all the content.", "labels": [], "entities": []}, {"text": "Solutions in the top left quadrant require content to be curated upfront for many possible customized scenarios (which could be prohibitively expensive), so that they can be just selected at run-time.", "labels": [], "entities": []}, {"text": "For young learners, especially, high content customization is desirable, which often cannot be generated upfront since the context in which a learning moment occurs cannot be known a priori.", "labels": [], "entities": []}, {"text": "Our ideal goal is to be able to operate in the top right quadrant to ensure maximal learning outcomes.", "labels": [], "entities": []}, {"text": "To this end, we explore a solution that enables just-in-time production of audio-visual content for vocabulary learning when supplied with learning scripts.", "labels": [], "entities": [{"text": "vocabulary learning", "start_pos": 100, "end_pos": 119, "type": "TASK", "confidence": 0.8587705790996552}]}, {"text": "Our system processes a learning script in natural language (selected by the educator based on their learning requirements), along with an image library, to semi-automatically generate a multi-modal learning video: with voice-over and contextual images synchronized in away that the video is coherent and easily comprehended by young children.", "labels": [], "entities": []}, {"text": "A learning-script is the textual manuscript for the learning-video.", "labels": [], "entities": []}, {"text": "The voice-over is generated using a text-to-speech engine and hence can be customized to different requirements of a friendly or familiar speech model (e.g. that of a favourite cartoon character) fora child to maximize engagement.", "labels": [], "entities": []}, {"text": "Using an audio-visual format, the same concept can be presented in a multitude of ways customized to each child's unique learning trajectory, context, and interests.", "labels": [], "entities": []}, {"text": "Educators are familiar with a child's learning trajectory and areas of interest, and hence our solution allows customizing a default textual script or write anew script.", "labels": [], "entities": []}, {"text": "The system takes this customized textual script, uses NLP techniques to extract relevant features and their representative images, uses human assistance to verify images, and finally creates a video.", "labels": [], "entities": []}, {"text": "Since this content is created for children, human verification process is critical to ensure that no inappropriate image content has inadvertently crept in as the system automatically pulls relevant images from the image repository based on textual features of the script.", "labels": [], "entities": []}, {"text": "As automatic safe image search becomes more readily feasible, human assistance could be reduced further.", "labels": [], "entities": [{"text": "automatic safe image search", "start_pos": 3, "end_pos": 30, "type": "TASK", "confidence": 0.5735834091901779}]}, {"text": "More importantly, this approach achieves our main goal of reducing the content creation load for educators because it is much easier to verify created content than to create new content from scratch.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "We review the related work in Section 2.", "labels": [], "entities": []}, {"text": "In Section 3, we explain our proposed system and all the system components.", "labels": [], "entities": []}, {"text": "In Section 4, we describe the experiment and evaluation results of our model.", "labels": [], "entities": []}, {"text": "In Section 5, we present the future work and finally, we conclude in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we first present the setup of the experiment we conducted for evaluating our approach.", "labels": [], "entities": []}, {"text": "The result & discussion follows in the further subsections.", "labels": [], "entities": []}, {"text": "We selected ten vocabulary words from the British National Corpus (BNC) frequently spoken list.", "labels": [], "entities": [{"text": "British National Corpus (BNC) frequently spoken list", "start_pos": 42, "end_pos": 94, "type": "DATASET", "confidence": 0.9624869359864129}]}, {"text": "The words were: Barrier, Clinic, Commute, Customer, Facility, Pedestrian, Serve, Steer, Stir, and Weave.", "labels": [], "entities": []}, {"text": "We obtained the definitions and usage sentences from Simple English Wiktionary.", "labels": [], "entities": []}, {"text": "These were combined to form sample scripts.", "labels": [], "entities": []}, {"text": "For Example, the script for Steer derived was: \"To steer is use a rudder, wheel, or paddle to decide which way something will travel.", "labels": [], "entities": [{"text": "Steer derived", "start_pos": 28, "end_pos": 41, "type": "TASK", "confidence": 0.8445077836513519}]}, {"text": "The driver gripped the wheel tightly to steer the car around a corner.\"", "labels": [], "entities": []}, {"text": "As described in the Approach Section, we derived the Prioritized Search Terms from the NLP Layer.", "labels": [], "entities": [{"text": "Approach", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.5876691341400146}, {"text": "NLP Layer", "start_pos": 87, "end_pos": 96, "type": "DATASET", "confidence": 0.8866806328296661}]}, {"text": "These Search Terms were then used to search for images from Shuterstock.", "labels": [], "entities": [{"text": "Shuterstock", "start_pos": 60, "end_pos": 71, "type": "DATASET", "confidence": 0.9683756232261658}]}, {"text": "These images were sent for human verification using our authoring tool.", "labels": [], "entities": []}, {"text": "The verified images constituted the verified image library.", "labels": [], "entities": []}, {"text": "These were then combined using our approach to generate learning videos for all ten words.", "labels": [], "entities": []}, {"text": "The layer-wise outputs for Steer is shown in.", "labels": [], "entities": []}, {"text": "In our experiment, we sent out Google Forms to participants, asking them to rate the generated videos and provide comments.", "labels": [], "entities": []}, {"text": "The participants were proficient in using the English language and included native and non-native English speakers.", "labels": [], "entities": []}, {"text": "The study included diverse professionals; including educators, college students, engineers, doc- tors and information technology researchers.", "labels": [], "entities": []}, {"text": "Each form took feedback on one of the ten generated videos.", "labels": [], "entities": []}, {"text": "The participants were allowed to provide feedback on as many words as they liked.", "labels": [], "entities": []}, {"text": "We posed the same question for every word.", "labels": [], "entities": []}, {"text": "For example, for the word 'steer' we asked 'Would you recommend this video to someone who does not know \"steer\"?'", "labels": [], "entities": []}, {"text": "The responses were taken on a Likert scale of five points, where five indicated strong affirmation, and one indicated strong reluctance.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Likert Score distribution for learning videos", "labels": [], "entities": []}, {"text": " Table 2. Also,  the overall average Likert rating was 4.25 out of  5 when combined across all videos.", "labels": [], "entities": []}, {"text": " Table 2: Feedback on learning videos", "labels": [], "entities": []}]}