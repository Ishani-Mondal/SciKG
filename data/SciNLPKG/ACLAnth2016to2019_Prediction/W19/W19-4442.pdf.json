{"title": [{"text": "Learning Outcomes and Their Relatedness in a Medical Curriculum", "labels": [], "entities": [{"text": "Learning Outcomes and Their Relatedness", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.5950339376926422}]}], "abstractContent": [{"text": "A typical medical curriculum is organized in a hierarchy of instructional objectives called Learning Outcomes (LOs); a few thousand LOs span five years of study.", "labels": [], "entities": []}, {"text": "Gaining a thorough understanding of the curriculum requires learners to recognize and apply related LOs across years, and across different parts of the curriculum.", "labels": [], "entities": []}, {"text": "However, given the large scope of the curriculum, manually labeling related LOs is tedious, and almost impossible to scale.", "labels": [], "entities": []}, {"text": "In this paper, we build a system that learns relationships between LOs, and we achieve up to human-level performance in the LO relationship extraction task.", "labels": [], "entities": [{"text": "LO relationship extraction task", "start_pos": 124, "end_pos": 155, "type": "TASK", "confidence": 0.8359437882900238}]}, {"text": "We then present an application where the proposed system is employed to build a map of related LOs and Learning Resources (LRs) pertaining to a virtual patient case.", "labels": [], "entities": []}, {"text": "We believe that our system enables building educational tools to help medical students grasp the curriculum better, within classroom and Intelligent Tutoring Systems (ITS) settings.", "labels": [], "entities": []}], "introductionContent": [{"text": "Learning Outcomes (LOs) encapsulate discrete knowledge components and provide a framework for curriculum planning, teaching, learning, and assessment.", "labels": [], "entities": []}, {"text": "In this work, we study the curriculum of the Lee Kong Chian School of Medicine, Nanyang Technological University, Singapore.", "labels": [], "entities": [{"text": "Nanyang Technological University", "start_pos": 80, "end_pos": 112, "type": "DATASET", "confidence": 0.8670462767283121}]}, {"text": "At the highest level, their curriculum is organized into major Themes, which branch into Fundamentals, and further into Fundamental Units.", "labels": [], "entities": []}, {"text": "A Fundamental Unit is comprised of multiple related Topics, and each topic constitutes several LOs.", "labels": [], "entities": []}, {"text": "Thus, related LOs get grouped together at multiple levels of increasing granularity.", "labels": [], "entities": []}, {"text": "This hierarchy is handcurated by medical experts and represents a wellformed, well-understood body of knowledge.", "labels": [], "entities": []}, {"text": "However, qualitative evidence suggests that sig- nificant relationships exist between LOs placed far apart in the curriculum; these relationships cannot be uncovered without explicit expert intervention.", "labels": [], "entities": []}, {"text": "illustrates one such instance, where LOs drawn from disjoint sections of the curriculum hierarchy are related as they address multiple aspects of HIV treatment.", "labels": [], "entities": []}, {"text": "Our main motivation in this work is to automatically discover LO relationships that cannot be accessed by a straightforward navigation of the curriculum.", "labels": [], "entities": []}, {"text": "Extracting such LO relationships can help build a knowledge-base that can be foundational to various educational tools.", "labels": [], "entities": []}, {"text": "To this end, we propose looking into the semantic content of disparate LOs, in addition to their relatedness specified by the curriculum hierarchy.", "labels": [], "entities": []}, {"text": "We formulate this as a three-class classification task.", "labels": [], "entities": []}, {"text": "Given a pair of LOs, they are categorized as being either strongly related or weakly related, or unrelated.", "labels": [], "entities": []}, {"text": "Although the current study is limited to a medical curriculum, our approach is general.", "labels": [], "entities": []}, {"text": "Techniques reported in this paper would extend to any curricula that take a 'design down' approach, where related LOs are nested in a hierarchical order.", "labels": [], "entities": []}, {"text": "An LO-relationship extraction tool that utilizes both semantic and curricu-lum cues, can be exploited by Intelligent Tutoring Systems (ITS) to suggest useful interventions to both learners and instructors.", "labels": [], "entities": [{"text": "LO-relationship extraction", "start_pos": 3, "end_pos": 29, "type": "TASK", "confidence": 0.694025307893753}]}, {"text": "Potential applications include: a) improved content recommendation, by proactively suggesting pre-requisites or guiding the learner to discover LOs that are related across disjoint sections of the curriculum; b) designing better assessment items which test a learner on closely related LOs; and c) accurate learner modeling, by taking into account all related LOs when tracking the progress of a learner's mastery of an LO.", "labels": [], "entities": []}, {"text": "Building upon these motivations, this work documents our efforts to answer the following research questions : RQ1: Which features determine relatedness between LOs?", "labels": [], "entities": [{"text": "RQ1", "start_pos": 110, "end_pos": 113, "type": "METRIC", "confidence": 0.8075035810470581}]}, {"text": "Information available to us is both structured (by way of a well-defined curriculum hierarchy), as well as unstructured (by way of free text descriptions of LOs).", "labels": [], "entities": []}, {"text": "We aim to devise a method to appropriately integrate the two in order to compare two LOs.", "labels": [], "entities": []}, {"text": "RQ2: By design, LOs are crisp and compact.", "labels": [], "entities": [{"text": "RQ2", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7593533992767334}, {"text": "crisp", "start_pos": 24, "end_pos": 29, "type": "METRIC", "confidence": 0.9745420813560486}]}, {"text": "A drawback of their conciseness is that they do not provide enough information to ascertain relatedness with other, similarly concise LOs.", "labels": [], "entities": []}, {"text": "So, we ask, can the resources linked to LOs be suitably leveraged to improve the quality of LO-relationship extraction?", "labels": [], "entities": [{"text": "LO-relationship extraction", "start_pos": 92, "end_pos": 118, "type": "TASK", "confidence": 0.8150277137756348}]}, {"text": "RQ3: Are there any latent factors beyond curriculum and semantic similarity establishing relatedness among LOs?", "labels": [], "entities": [{"text": "RQ3", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8557081818580627}]}, {"text": "If so, are they exploited by the proposed approach?", "labels": [], "entities": []}, {"text": "RQ4: Can LO relatedness be used to understand a virtual patient case?", "labels": [], "entities": [{"text": "RQ4", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8577552437782288}, {"text": "LO relatedness", "start_pos": 9, "end_pos": 23, "type": "TASK", "confidence": 0.6429397761821747}]}, {"text": "Disparate LOs of disease and symptoms could be related in the context of a case.", "labels": [], "entities": []}, {"text": "We leverage the LO relationship extraction system to understand the context of a case, and build a case map from relevant concepts.", "labels": [], "entities": [{"text": "LO relationship extraction", "start_pos": 16, "end_pos": 42, "type": "TASK", "confidence": 0.6481618583202362}]}], "datasetContent": [{"text": "In all our experiments, we use NLTK for stopword removal and scikit-learn for the classifiers.", "labels": [], "entities": [{"text": "stopword removal", "start_pos": 40, "end_pos": 56, "type": "TASK", "confidence": 0.730722039937973}]}, {"text": "We use N = 20 bins for HoPS features and set similarity threshold \u03b4 = 0.6 for embedding-based features.", "labels": [], "entities": [{"text": "similarity threshold \u03b4", "start_pos": 45, "end_pos": 67, "type": "METRIC", "confidence": 0.9461498061815897}]}, {"text": "We trained an SVM and Random Forest model for our task.", "labels": [], "entities": []}, {"text": "Owing to space constraints and sub-par performance of the SVM, we report results fora Random Forest classifier with 100 estimators; all other parameters of the model are tuned using 5-fold cross validation on the training data.", "labels": [], "entities": []}, {"text": "We use macro-F1 of the classifier on held out test data as our metric.", "labels": [], "entities": []}, {"text": "Mean and standard deviations of macro-F1 are reported over 10 runs of the random forest.", "labels": [], "entities": []}, {"text": "We use BioNLP( word-embeddings.", "labels": [], "entities": [{"text": "BioNLP", "start_pos": 7, "end_pos": 13, "type": "DATASET", "confidence": 0.6487648487091064}]}, {"text": "For a subset of 552 LO-pairs, we obtain separate annotations from two SMEs.", "labels": [], "entities": []}, {"text": "Inter-annotator performance on this held-out test set serves as a skyline for comparative evaluation.", "labels": [], "entities": []}, {"text": "Owing to data-labeling constraints, only a subset of LOs could be linked to respective LRs by the SMEs.", "labels": [], "entities": []}, {"text": "Similarly, tagging LOs with one of several possible physiologic/pathologic states entails significant cognitive engagement, and could be done only fora subset of LOs.", "labels": [], "entities": []}, {"text": "For uniformity, we ensured that both subsets have a class label distribution identical to the total distribution in.", "labels": [], "entities": []}, {"text": "We perform three sets of experiments to 1) evaluate the effectiveness of the proposed approach, 2) evaluate the utility of LRs, and 3) evaluate utility of expert medical codes (EMC).", "labels": [], "entities": []}, {"text": "We compare five feature variants in an ablated study.", "labels": [], "entities": []}, {"text": "Since the proposed approach stipulates curriculum and semantic features (CR+SM), we perform a comparison when individual curriculum (CR) or semantic features (SM) are used.", "labels": [], "entities": []}, {"text": "To gauge the efficacy of tf-idf based features, experiments are performed using these features alone (TF), and along with curriculum features (CR+TF).", "labels": [], "entities": []}, {"text": "For each feature variant, we contrast results obtained with a baseline 3-way monolithic classifier, and the proposed cascaded classifier.", "labels": [], "entities": []}, {"text": "In the monolithic classifier, we ensure that the misclassification penalty for each class is inversely proportional to its frequency in the training data.", "labels": [], "entities": []}, {"text": "This accounts for class imbalance, and ensures fair comparison against the cascaded classifier.", "labels": [], "entities": []}, {"text": "Results of experiments are reported in.", "labels": [], "entities": []}, {"text": "Our the key observations are : Exact vs Embedding-based Features: Tf-idf features (TF) perform exact token matching which gets derailed whenever similar concepts are addressed differently (such as myocardial and cardiac).", "labels": [], "entities": []}, {"text": "Instead, embedding-based features (SM) are more adept at capturing semantic relatedness as by construction, context vectors for related con- Inter-annotator agreement: 69.9  cepts are closely located in the embedding space.", "labels": [], "entities": []}, {"text": "Similarly, CR+SM outperforms CR+TF.", "labels": [], "entities": []}, {"text": "Importance of Feature Concatenation: A combination of both curriculum and semantic features (CR+SM) significantly outperforms their individual performance.", "labels": [], "entities": [{"text": "Importance", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.8831790089607239}]}, {"text": "Answering RQ1, we conclude that curriculum and semantics encode distinct aspects of an LO-pair's relatedness, and our system improves when information encoded in each feature class is jointly represented.", "labels": [], "entities": [{"text": "RQ1", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.7487688660621643}]}, {"text": "Effectiveness of Cascaded Classifier: For all feature combinations, the cascaded classifier outperforms the monolithic baseline.", "labels": [], "entities": []}, {"text": "This supports our hypothesis that the decision boundary between Related (Strong + Weak) and Unrelated pairs is more discernible than the decision boundary between Strong and Weak.", "labels": [], "entities": []}, {"text": "For the rest of our experiments, we utilize CR+SM features with a cascaded classifier, since this combination yields best results, and approaches near human performance (refer).", "labels": [], "entities": []}, {"text": "The proposed pipeline can now be used to establish LO relationships on the whole curriculum.", "labels": [], "entities": []}, {"text": "This effectively circumvents the scale problem that manual annotation of all LO-pairs (\u223c1 million) in the curriculum entails, while maintaining the accuracy of an expert.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 148, "end_pos": 156, "type": "METRIC", "confidence": 0.9990935325622559}]}], "tableCaptions": [{"text": " Table 2: Inter-Annotator agreement between two ex- perts on the test set (note the substantial disagreement  in annotating LO pairs as Strong and Weak).", "labels": [], "entities": []}, {"text": " Table 4: Macro-F1 (mean\u00b1std) values on the test set  for two classifier variants and different features.", "labels": [], "entities": []}, {"text": " Table 5: Macro-F1 (mean\u00b1std) on LR-linked test set.", "labels": [], "entities": [{"text": "LR-linked test set", "start_pos": 33, "end_pos": 51, "type": "DATASET", "confidence": 0.8679422736167908}]}, {"text": " Table 6: Macro-F1 (mean\u00b1std) values on ten random  splits comparing the baseline, and inclusion of EMCs.", "labels": [], "entities": []}]}