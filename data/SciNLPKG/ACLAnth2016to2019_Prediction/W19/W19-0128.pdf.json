{"title": [{"text": "On Evaluating the Generalization of LSTM Models in Formal Languages", "labels": [], "entities": [{"text": "Generalization of LSTM Models", "start_pos": 18, "end_pos": 47, "type": "TASK", "confidence": 0.8478782474994659}]}], "abstractContent": [{"text": "Recurrent Neural Networks (RNNs) are theoretically Turing-complete and established themselves as a dominant model for language processing.", "labels": [], "entities": [{"text": "Recurrent Neural Networks (RNNs)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6741515596707662}]}, {"text": "Yet, there still remains an uncertainty regarding their language learning capabilities.", "labels": [], "entities": []}, {"text": "In this paper, we empirically evaluate the inductive learning capabilities of Long Short-Term Memory networks, a popular extension of simple RNNs, to learn simple formal languages, in particular an b n , an b n c n , and an b n c n d n.", "labels": [], "entities": []}, {"text": "We investigate the influence of various aspects of learning, such as training data regimes and model capacity, on the generalization to unobserved samples.", "labels": [], "entities": []}, {"text": "We find striking differences in model performances under different training settings and highlight the need for careful analysis and assessment when making claims about the learning capabilities of neural network models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recurrent Neural Networks (RNNs) are powerful machine learning models that can capture and exploit sequential data.", "labels": [], "entities": []}, {"text": "They have become standard in important natural language processing tasks such as machine translation) and speech recognition ().", "labels": [], "entities": [{"text": "machine translation", "start_pos": 81, "end_pos": 100, "type": "TASK", "confidence": 0.784187376499176}, {"text": "speech recognition", "start_pos": 106, "end_pos": 124, "type": "TASK", "confidence": 0.8244406282901764}]}, {"text": "Despite the ubiquity of various RNN architectures in natural language processing, there still lies an unanswered fundamental question: What classes of languages can, empirically or theoretically, be learned by neural networks?", "labels": [], "entities": []}, {"text": "This question has drawn much attention in the study of formal languages, with previous results on both the theoretical ( and empirical capabilities of RNNs, showing that different RNN architectures can learn certain regular (, context-free, and context-sensitive languages).", "labels": [], "entities": []}, {"text": "Ina common experimental setup for investigating whether a neural network can learn a formal language, one formulates a supervised learning problem where the network is presented one character at a time and predicts the next possible character(s).", "labels": [], "entities": []}, {"text": "The performance of the network can then be evaluated based on its ability to recognize sequences shown in the training set and -more importantly -to generalize to unseen sequences.", "labels": [], "entities": []}, {"text": "There are, however, various methods of evaluation in a language learning task.", "labels": [], "entities": []}, {"text": "In order to define the generalization of a network, one may consider the length of the shortest sequence in a language whose output was incorrectly produced by the network, or the size of the largest accepted test set, or the accuracy on a fixed test set ().", "labels": [], "entities": [{"text": "accuracy", "start_pos": 226, "end_pos": 234, "type": "METRIC", "confidence": 0.9993404746055603}]}, {"text": "These formulations follow narrow and bounded evaluation schemes though: They often define a length threshold in the test set and report the performance of the model on this fixed set.", "labels": [], "entities": []}, {"text": "We acknowledge three unsettling issues with these formulations.", "labels": [], "entities": []}, {"text": "First, the sequences in the training set are usually assumed to be uniformly or geometrically distributed, with little regard to the nature and complexity of the language.", "labels": [], "entities": []}, {"text": "This assumption may undermine any conclusions drawn from empirical investigations, especially given that natural language is not uniformly distributed, an aspect that is known to affect learning in modern RNN architectures (.", "labels": [], "entities": []}, {"text": "Second, in a test set where the sequences are enumerated by their lengths, if a network makes an error on a sequence of, say, length 7, but correctly recognizes longer sequences of length up to 1000, would we consider the model's gener-alization as good or bad?", "labels": [], "entities": []}, {"text": "Ina setting where we monitor only the shortest sequence that was incorrectly predicted by the network, this scheme clearly misses the potential success of the model after witnessing a failure, thereby misportraying the capabilities of the network.", "labels": [], "entities": []}, {"text": "Third, the test sets are often bounded in these formulations, making it challenging to compare and contrast the performance of models if they attain full accuracy on their fixed test sets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 154, "end_pos": 162, "type": "METRIC", "confidence": 0.9887750148773193}]}, {"text": "In the present work, we address these limitations by providing a more nuanced evaluation of the learning capabilities of RNNs.", "labels": [], "entities": []}, {"text": "In particular, we investigate the effects of three different aspects of a network's generalization: data distribution, length-window, and network capacity.", "labels": [], "entities": []}, {"text": "We define an informative protocol for assessing the performance of RNNs: Instead of training a single network until it has learned its training set and then evaluating it on its test set, as Gers and Schmidhuber do in their study, we monitor and test the network's performance at each epoch during the entire course of training.", "labels": [], "entities": []}, {"text": "This approach allows us to study the stability of the solutions reached by the network.", "labels": [], "entities": []}, {"text": "Furthermore, we do not restrict ourselves to a test set of sequences of fixed lengths during testing.", "labels": [], "entities": []}, {"text": "Rather, we exhaustively enumerate all the sequences in a language by their lengths and then go through the sequences in the test set one by one until our network errs k times, thereby providing a more fine-grained evaluation criterion of its generalization capabilities.", "labels": [], "entities": []}, {"text": "Our experimental evaluation is focused on the Long Short-Term Memory (LSTM) network), a particularly popular RNN variant.", "labels": [], "entities": []}, {"text": "We consider three formal languages, namely an b n , an b n c n , and an b n c n d n , and investigate how LSTM networks learn these languages under different training regimes.", "labels": [], "entities": []}, {"text": "Our investigation leads to the following insights: (1) The data distribution has a significant effect on generalization capability, with discrete uniform and U-shaped distributions often leading to the best generalization amongst all the four distributions in consideration.", "labels": [], "entities": []}, {"text": "(2) Widening the training length-window, naturally, enables LSTM models to generalize better to longer sequences, and interestingly, the networks seem to learn to generalize to shorter sequences when trained on long sequences.", "labels": [], "entities": []}, {"text": "(3) Higher model capacity -having more hidden units -leads to better stability, but not necessarily better generalization levels.", "labels": [], "entities": []}, {"text": "In other words, over-parameterized models are more stable than models with theoretically sufficient but far fewer parameters.", "labels": [], "entities": []}, {"text": "We explain this phenomenon by conjecturing that a collaborative counting mechanism arises in over-parameterized networks.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}