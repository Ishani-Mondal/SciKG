{"title": [{"text": "Subversive Toxicity Detection using Sentiment Information\u00c9loi", "labels": [], "entities": [{"text": "Subversive Toxicity Detection", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8458813031514486}]}], "abstractContent": [{"text": "The presence of toxic content has become a major problem for many online communities.", "labels": [], "entities": []}, {"text": "Moderators try to limit this problem by implementing more and more refined comment filters, but toxic users are constantly finding new ways to circumvent them.", "labels": [], "entities": []}, {"text": "Our hypothesis is that while modifying toxic content and keywords to fool filters can be easy, hiding sentiment is harder.", "labels": [], "entities": [{"text": "hiding sentiment", "start_pos": 95, "end_pos": 111, "type": "TASK", "confidence": 0.853597491979599}]}, {"text": "In this paper, we explore various aspects of sentiment detection and their correlation to toxicity, and use our results to implement a toxicity detection tool.", "labels": [], "entities": [{"text": "sentiment detection", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.9070360958576202}, {"text": "toxicity detection", "start_pos": 135, "end_pos": 153, "type": "TASK", "confidence": 0.7077399045228958}]}, {"text": "We then test how adding the sentiment information helps detect toxicity in three different real-world datasets, and incorporate subver-sion to these datasets to simulate a user trying to circumvent the system.", "labels": [], "entities": []}, {"text": "Our results show sentiment information has a positive impact on toxicity detection.", "labels": [], "entities": [{"text": "toxicity detection", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.7875277698040009}]}], "introductionContent": [{"text": "Online communities abound today, forming on social networks, on webforums, within videogames, and even in the comments sections of articles and videos.", "labels": [], "entities": []}, {"text": "While this increased international contact and exchange of ideas has been a net positive, it has also been matched with an increase in the spread of high-risk and toxic content, a category which includes cyberbullying, racism, sexual predation, and other negative behaviors that are not tolerated in society.", "labels": [], "entities": []}, {"text": "The two main strategies used by online communities to moderate themselves and stop the spread of toxic comments are automated filtering and human surveillance.", "labels": [], "entities": []}, {"text": "However, given the sheer number of messages sent online everyday, human moderation simply cannot keep up, and either leads to a severe slowdown of the conversation (if messages are pre-moderated before posting) or allows toxic messages to be seen and shared thousands of times before they are deleted (if they are post-moderated after being posted and reported).", "labels": [], "entities": []}, {"text": "In (, the authors show how minor changes can elude even complex systems.", "labels": [], "entities": []}, {"text": "These attempts to bypass the toxicity detection system are called subverting the system, and toxic users doing it are referred to as subversive users.", "labels": [], "entities": []}, {"text": "In this paper, we consider an alternative strategy for toxic message filtering.", "labels": [], "entities": [{"text": "toxic message filtering", "start_pos": 55, "end_pos": 78, "type": "TASK", "confidence": 0.6380579173564911}]}, {"text": "Our intuition is that, while high-risk keywords can easily be disguised, the negative emotional tone of the message cannot.", "labels": [], "entities": []}, {"text": "Consequently, we will study the correlation between sentiment and toxicity and its usefulness for toxic message detection both in subversive and non-subversive contexts.", "labels": [], "entities": [{"text": "toxic message detection", "start_pos": 98, "end_pos": 121, "type": "TASK", "confidence": 0.6831878622372946}]}, {"text": "It is important to note that toxicity is a very abstract term that can have different definitions depending on context, and each dataset described in Section 4 has its own.", "labels": [], "entities": []}, {"text": "They all gravitate around negative messages such as insults, bullying, vulgarity and hate speech, therefore these types of toxic behavior are the ones we focus on, as opposed to other types such as fraud or grooming that would use more positive messages.", "labels": [], "entities": []}, {"text": "The rest of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "After a review of the relevant literature in the next section, we will consider the problem of sentiment detection in online messages in Section 3.", "labels": [], "entities": [{"text": "sentiment detection in online messages", "start_pos": 95, "end_pos": 133, "type": "TASK", "confidence": 0.8859648466110229}]}, {"text": "We will study the measure of toxicity and its correlation to message sentiment in Section 4.", "labels": [], "entities": [{"text": "message sentiment", "start_pos": 61, "end_pos": 78, "type": "TASK", "confidence": 0.7721733748912811}]}, {"text": "Finally, we will draw some concluding remarks in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments have four main objectives: (1) to determine whether the \"All words\" or the \"Top words\" strategy is preferable; (2) to determine whether the inclusion of \"Negation\" and \"Frequency\" modifiers is useful; (3) to determine which of the six lexicons is most accurate; and to determine whether a weighted combination of the six lexicons can outperform anyone lexicon.", "labels": [], "entities": []}, {"text": "To conduct our experiments, we used the corpus of annotated news comments available from the Yahoo Webscope program . The comments in this dataset are annotated by up to three professional, trained editors to label various attributes, including type, sentiment and tone.", "labels": [], "entities": []}, {"text": "Using these three attributes, we split the dataset into two categories, sarcastic and non-sarcastic, and then again into five categories, clear negative, slight negative, neutral, slight positive, and clear positive.", "labels": [], "entities": []}, {"text": "Finally, we kept only the non-sarcastic comments where all annotators agreed to reduce noise.", "labels": [], "entities": []}, {"text": "This gives us a test corpus of 2,465 comments.", "labels": [], "entities": []}, {"text": "To evaluate our results, we compute the sentiment score of each comment in our test corpus using our various methods, and we then compute the average sentiment score of comments in each of the five sentiment categories.", "labels": [], "entities": []}, {"text": "For ease of presentation, we give a simplified set of results in, with only the average score of the two negative and the two positive labels combined, along with the overlap of the two distributions.", "labels": [], "entities": []}, {"text": "The overlap is obtained by taking two normal distributions with the the means and standard deviations of the positive and the negative sets, and calculating the area in common under both curves.", "labels": [], "entities": [{"text": "overlap", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9769986271858215}]}, {"text": "It gives us a measure of the ambiguous region where comments maybe positive or negative.", "labels": [], "entities": []}, {"text": "A good sentiment classifier will thus have very distant positive and negative scores and a very low overlap.", "labels": [], "entities": [{"text": "overlap", "start_pos": 100, "end_pos": 107, "type": "METRIC", "confidence": 0.9509440064430237}]}, {"text": "These results show that there are important differences between the lexicons.", "labels": [], "entities": []}, {"text": "Three of the six are rather poor at picking out negative sentiments, namely Subjectivity Clues (where negative messages are on average detected as more positive than the positive messages), General Inquirer, and NRC.", "labels": [], "entities": [{"text": "General Inquirer", "start_pos": 190, "end_pos": 206, "type": "DATASET", "confidence": 0.8766469061374664}, {"text": "NRC", "start_pos": 212, "end_pos": 215, "type": "DATASET", "confidence": 0.967858076095581}]}, {"text": "This bias for positivity is an issue fora study on toxicity, which we expect to be expressed using negative sentiments.", "labels": [], "entities": []}, {"text": "The other three lexicons give a good difference between positive and negative messages.", "labels": [], "entities": []}, {"text": "For these three lexicons, we find that using All words increases the gap between positive and negative scores but greatly increases the standard deviation of each sentiment class, meaning the sentiment of the messages becomes ambiguous.", "labels": [], "entities": []}, {"text": "On the other hand, using Top words reduces the overlap between the distributions and thus gives a better separation of positive and negative sentiments.", "labels": [], "entities": []}, {"text": "And while adding frequency information or negations does not cause a major change in the results, it does give a small reduction in overlap.", "labels": [], "entities": [{"text": "overlap", "start_pos": 132, "end_pos": 139, "type": "METRIC", "confidence": 0.967703104019165}]}, {"text": "To study combinations of lexicons, we decided to limit our scope to SentiWordNet, Afinn, and Bing Liu, the three lexicons that could accurately pick out negative sentiments, and on the Top words strategy.", "labels": [], "entities": []}, {"text": "We consider three common strategies to combine the results of independent classifiers: majority voting, picking the one classifier with the maximum score (which is assumed to be the one with the highest confidence in its classification), and taking the average of the scores of all three classifiers.", "labels": [], "entities": []}, {"text": "For the average, we tried using a weighted average of the lexicons and performed a grid search to find the optimal combination.", "labels": [], "entities": []}, {"text": "However, the best results were obtained when the three lexicons were taken equally.", "labels": [], "entities": []}, {"text": "For the majority vote, we likewise take the average score of the two or three classifiers in the majority sentiment.", "labels": [], "entities": []}, {"text": "presents the results we obtain with all three strategies.", "labels": [], "entities": []}, {"text": "It can be seen that combining the three classifiers outperforms taking anyone classifier alone, in the sense that it creates a wider gap between the positive and negative messages and a smaller overlap.", "labels": [], "entities": []}, {"text": "It can also be seen that the addition of negation and frequency information gives a very small improvement in the results in all three cases.", "labels": [], "entities": [{"text": "negation", "start_pos": 41, "end_pos": 49, "type": "TASK", "confidence": 0.9546726942062378}]}, {"text": "Comparing the three strategies, it can be seen that the maximum strategy gives the biggest gap in between positive and negative distribution, which was to be expected since the highest positive or negative sentiment is selected each time while it gets averaged out in the other two classifiers.", "labels": [], "entities": []}, {"text": "However, the average score strategy creates a significantly smaller standard deviation of sentiment scores and a lower overlap between the distributions of positive and negative messages.", "labels": [], "entities": []}, {"text": "For that reason, we find the average score to be the best of the three combination strategies.", "labels": [], "entities": []}, {"text": "In all cases, we find that most misclassified messages in our system are due to the lack of insults in the vocabulary.", "labels": [], "entities": []}, {"text": "For example, none of the lexicons include colorful insults like \"nut job\" and \"fruitcake\", so messages where they appear cannot be recognized as negative.", "labels": [], "entities": []}, {"text": "Likewise, some words, such as the word \"gay\", are often used as insults online, but have positive meanings informal English; this actually leads to labeling insult messages as positive.", "labels": [], "entities": []}, {"text": "This issue stems from the fact that these lexicons were designed for sentiment analysis in longer and more traditional documents, such as customer reviews and editorials.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 69, "end_pos": 87, "type": "TASK", "confidence": 0.953863799571991}]}, {"text": "One will seldom, if ever, find insults (especially politically-incorrect ones such as the previous examples) in these documents.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Sentiment of words per lexicon", "labels": [], "entities": [{"text": "Sentiment of words per lexicon", "start_pos": 10, "end_pos": 40, "type": "TASK", "confidence": 0.8570719599723816}]}, {"text": " Table 6: Accuracy, precision and recall on regular and subversive datasets, with and without sentiment, along with  the t-test p-value when comparing accuracy result distribution", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9983446598052979}, {"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9995594620704651}, {"text": "recall", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.9994322657585144}, {"text": "accuracy", "start_pos": 151, "end_pos": 159, "type": "METRIC", "confidence": 0.9826653003692627}]}]}