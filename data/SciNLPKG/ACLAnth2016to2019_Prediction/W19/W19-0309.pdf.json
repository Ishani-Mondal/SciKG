{"title": [{"text": "Neural and rule-based Finnish NLP models-expectations, experiments and experiences", "labels": [], "entities": []}], "abstractContent": [{"text": "In this article I take a critical look at some recent results in the field of neural language modeling of Finnish in terms of popular shared tasks.", "labels": [], "entities": [{"text": "neural language modeling of Finnish", "start_pos": 78, "end_pos": 113, "type": "TASK", "confidence": 0.7576426148414612}]}, {"text": "One novel point of view I present is comparing the neural methods' results to traditional rule-based systems for the given tasks, since most of the shared tasks have concentrated on the supervised learning concept.", "labels": [], "entities": []}, {"text": "The shared task results I re-evaluate, are morphological regeneration by SIGMORPHON 2016, universal dependency parsing by CONLL-2018 and a machine translation application that imitates WMT 2018 for German instead of English.", "labels": [], "entities": [{"text": "morphological regeneration", "start_pos": 43, "end_pos": 69, "type": "TASK", "confidence": 0.7246265113353729}, {"text": "universal dependency parsing", "start_pos": 90, "end_pos": 118, "type": "TASK", "confidence": 0.5878065526485443}, {"text": "CONLL-2018", "start_pos": 122, "end_pos": 132, "type": "DATASET", "confidence": 0.9053754806518555}, {"text": "machine translation", "start_pos": 139, "end_pos": 158, "type": "TASK", "confidence": 0.6862963736057281}]}, {"text": "The Uralic language used throughout is Finnish.", "labels": [], "entities": []}, {"text": "I use out of the box, best performing neural systems and rule-based systems and evaluate their results.", "labels": [], "entities": []}, {"text": "Tiivistelm\u00e4 T\u00e4ss\u00e4 artikkelissa tarkastelemme joitain hiljattaisia tuloksia niinkutsutuissa shared task-kilpailuissa suomen kielen hemroverkkomallien osalta.", "labels": [], "entities": [{"text": "Tiivistelm\u00e4 T\u00e4ss\u00e4 artikkelissa tarkastelemme joitain hiljattaisia tuloksia niinkutsutuissa shared task-kilpailuissa suomen kielen hemroverkkomallien osalta", "start_pos": 0, "end_pos": 155, "type": "TASK", "confidence": 0.5129233258111137}]}, {"text": "Yksi t\u00e4m\u00e4n artikkelin kontribuutioista on hermoverkkomallien tuottamien tulosten vertailu perinteisiin s\u00e4\u00e4nt\u00f6pohjaisiin kielimallituloksiin, sill\u00e4 shared task-kisailut p\u00e4\u00e4osin keskittyv\u00e4t t\u00e4ysin tai osittain hallitsemattomien mallien oppimisen konseptiin.", "labels": [], "entities": []}, {"text": "Shared taskit joita t\u00e4ss\u00e4 artikkelissa tarkastelemme ovat SIGMORPHONin 2016 morfologisen uudelleengeneroinnin kisa, CONLL:n 2018 j\u00e4sennyskilpailu sek\u00e4 WMT 2018:n konek\u00e4\u00e4nn\u00f6skilpailu uudelleensovellettuna saksan kielelle.", "labels": [], "entities": [{"text": "CONLL", "start_pos": 116, "end_pos": 121, "type": "DATASET", "confidence": 0.7598502039909363}]}, {"text": "Uralilai-nen kieli jota k\u00e4yt\u00e4mme kaikissa kokeissa on suomi.", "labels": [], "entities": []}, {"text": "J\u00e4rjestelm\u00e4t joita k\u00e4ytet\u00e4\u00e4n ovat avoimen l\u00e4hdekoodin j\u00e4rjestelmi\u00e4 jotka ovat olleet parhaita n\u00e4iss\u00e4 kilpai-luissa.", "labels": [], "entities": []}], "introductionContent": [{"text": "The popularity of the neural networks in natural language processing is at the moment climbing very rapidly to the extent that we commonly get to hear that non-neural methods should be abandoned.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 41, "end_pos": 68, "type": "TASK", "confidence": 0.6645495394865671}]}, {"text": "While naturally the majority of this hype is based on English-centric or mostly European NLP, there are some reports of good successes within the less resourced and more morphological languages, including Uralic languages.", "labels": [], "entities": []}, {"text": "In this paper I compare directly the state-of-the-art methods between the neural and rule-based language processing for Finnish.", "labels": [], "entities": []}, {"text": "I specifically devised experiments based on the following shared tasks and popular systems: \u2022 Generating morphology: Sigmorphon 2016 results ( vs. omorfi \u2022 Parsing of morphosyntax: Turku neural parser ( vs. omorfi \u2022 Machine translation between Finnish and German: OpenNMT ( vs. apertium-fin-deu Comparing a few different tasks gives us a good overview of the state of the art in the neural processing of Finnish.", "labels": [], "entities": [{"text": "Turku neural parser", "start_pos": 181, "end_pos": 200, "type": "TASK", "confidence": 0.5734358032544454}, {"text": "Machine translation between Finnish and German", "start_pos": 216, "end_pos": 262, "type": "TASK", "confidence": 0.8355702261130015}]}, {"text": "Parsing tasks give an idea of the potential usability of the language models in various linguistic tasks, such as corpus annotation, whereas the machine translation task provides an important view on the full capacity of the models fora more wide-ranging language understanding task.", "labels": [], "entities": [{"text": "corpus annotation", "start_pos": 114, "end_pos": 131, "type": "TASK", "confidence": 0.7023770213127136}, {"text": "machine translation task", "start_pos": 145, "end_pos": 169, "type": "TASK", "confidence": 0.8088955481847128}, {"text": "language understanding task", "start_pos": 255, "end_pos": 282, "type": "TASK", "confidence": 0.805321216583252}]}, {"text": "One of the contributions of this paper is to gain more insight of the similarities and differences of the traditional rule-based systems for the given tasks, since the shared tasks are virtually always earmarked for more or less supervised language learning, any evaluations between the neural and the rule-based systems are not so commonly found in the literature.", "labels": [], "entities": []}], "datasetContent": [{"text": "Omorfi 1 is a lexical database of Finnish, that can be compiled into a finite-state automaton for efficient parsing.", "labels": [], "entities": [{"text": "Omorfi 1", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8670362532138824}]}, {"text": "Omorfi has wide support for morphological analysis and generation (matching the SIGMORPHON task of morphological regeneration) and parsing (matching the CONLL task for parsing).", "labels": [], "entities": [{"text": "Omorfi", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8645038604736328}, {"text": "morphological analysis and generation", "start_pos": 28, "end_pos": 65, "type": "TASK", "confidence": 0.7916478514671326}, {"text": "morphological regeneration", "start_pos": 99, "end_pos": 125, "type": "TASK", "confidence": 0.7291072756052017}, {"text": "parsing", "start_pos": 131, "end_pos": 138, "type": "TASK", "confidence": 0.9889218807220459}, {"text": "parsing", "start_pos": 168, "end_pos": 175, "type": "TASK", "confidence": 0.953224778175354}]}, {"text": "Apertium-fin-deu 2 is a handcrafted rule-based machine translation system based on omorfi, with an addition of a bilingual dictionary and some sets of bilingual rules.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.7154992371797562}]}, {"text": "This can be used with the apertium tools to translate between German and Finnish.", "labels": [], "entities": []}, {"text": "The default mode of operation in a rule-based system is often based on the concept of all possible hypotheses, this is in contrast to shared tasks, which are based on 1-best parsing instead; measuring the results is based on only a single hypothesis per token.", "labels": [], "entities": []}, {"text": "To bridge this gap between rule-based morphology and shared tasks, I have used a combination of popular strategies implemented with python scripting language.", "labels": [], "entities": []}, {"text": "3 These strategies build in principle on both constraint grammar and my previous experiences with unigram models in rule-based morphologies (, it may, however, be noteworthy that at the time of the writing the solution described is very much a work in progress, so it should not be understood as having any specific advances over the above-referred previous experiments yet.", "labels": [], "entities": []}, {"text": "Furthermore, to perform the SIGMORPHON and CONLL tasks I have written small python scripts to analyse and map the analyses between omorfi's formats and theirs.", "labels": [], "entities": [{"text": "SIGMORPHON", "start_pos": 28, "end_pos": 38, "type": "TASK", "confidence": 0.6089166402816772}]}, {"text": "For machine translation I use the apertium command and discard the debugging symbols.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.8090179860591888}]}, {"text": "Examples of the output mangling we perform can be seen in listing 1.", "labels": [], "entities": []}, {"text": "As can be seen in the example, the token 7 (2017) has no rule-based dependency analysis, since it is not covered by the very basic dependency labeling script we use.", "labels": [], "entities": []}, {"text": "Some statistics of the rule-based dictionaries can be seen in the table 1.", "labels": [], "entities": []}, {"text": "The Turku neural parsing pipeline (refered from now onto as TNPP) is a recent, popular parser fora language-independent parsing of the dependency structures.", "labels": [], "entities": [{"text": "Turku neural parsing pipeline", "start_pos": 4, "end_pos": 33, "type": "TASK", "confidence": 0.787805050611496}]}, {"text": "They ranked highly in the 2018 CONLL shared task.", "labels": [], "entities": [{"text": "CONLL shared task", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.6235028107961019}]}, {"text": "For the experiments of this paper, I have downloaded the system following the instructions and have not changed any hyperparametres.", "labels": [], "entities": []}, {"text": "The model used is fi_tdt.", "labels": [], "entities": []}, {"text": "OpenNMT 5 is one of the many popular neural systems for machine translation.", "labels": [], "entities": [{"text": "OpenNMT 5", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.8984467387199402}, {"text": "machine translation", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.7903981506824493}]}, {"text": "For these experiments I chose it because it provides usable python bindings and it seemed most robust in our early experiments.", "labels": [], "entities": []}, {"text": "The training was performed based on the instructions in the OpenNMT README 6  An interesting part of this experiment is the setup, since one of the aspects we present in this paper is usability testing of the neural vs. traditional methods for use of an average Computational Uralist, I also want to get a feel of the user experience (UX).", "labels": [], "entities": [{"text": "OpenNMT README 6", "start_pos": 60, "end_pos": 76, "type": "DATASET", "confidence": 0.8125301400820414}]}, {"text": "The system setup for all the systems is quite similar, all the free and open software used in these experiments are hosted by github.", "labels": [], "entities": []}, {"text": "After cloning, the traditional rulebased systems rely on classical command-line installations, this means that user is expected to install dependencies the best they see and then run compilation of the data using configure and make scripts, and neural systems use python equivalents.", "labels": [], "entities": []}, {"text": "In terms of dependencies, all systems are basically well covered with some easy way to install necessary dependencies with single command, such as pip or apt-get.", "labels": [], "entities": []}, {"text": "A bit like rule-based systems, the neural systems need to \"compile\" i.e. learn neural network binaries from large data, in practice the experience for the end user is the same, except for the wait time, which is slightly longer for the neural-based systems.", "labels": [], "entities": []}, {"text": "For Finnish analysers an option is provided to download readily compiled models, while for translation models there is no option.", "labels": [], "entities": [{"text": "translation", "start_pos": 91, "end_pos": 102, "type": "TASK", "confidence": 0.9603059887886047}]}, {"text": "This is equally true for both neural and rule-based models.", "labels": [], "entities": []}, {"text": "To parse or translate I have run the systems with default / suggested settings.", "labels": [], "entities": [{"text": "parse or translate", "start_pos": 3, "end_pos": 21, "type": "TASK", "confidence": 0.752879798412323}]}, {"text": "To get an idea of intended mode of use (instant, batch processing over the weekend) of the systems and steps, I have collected some of our usage times in the table 3.", "labels": [], "entities": []}, {"text": "The real bottleneck for our experiments was the neural machine translation training time, the multi-day training period is problematic in itself, but it is also fragile enough that minor impurities in parallel corpus may ruin the whole model which means that on typical use case user may need to train the model multiple times before reaching to a functional one.", "labels": [], "entities": [{"text": "neural machine translation training", "start_pos": 48, "end_pos": 83, "type": "TASK", "confidence": 0.6949529051780701}]}, {"text": "To know how much time to create a system takes from scratch it is also useful to know the amount of data is needed to build it; for rule-based systems this is the size of dictionary, and rule-sets, for neural system it is the training data set size.", "labels": [], "entities": []}, {"text": "Both of these factors are especially interesting for Uralistic usage, since the availability of free and open data is rather scarce.", "labels": [], "entities": [{"text": "Uralistic usage", "start_pos": 53, "end_pos": 68, "type": "TASK", "confidence": 0.9018743932247162}]}, {"text": "The dictionaries are summarised in For my OpenNMT setup I have created an autotools-based model builder / test runner, that is available in github for repeatability purposes  I present an evaluation of the systems using the standard metrics from the shared tasks.", "labels": [], "entities": []}, {"text": "For morphological generation, the shared task was evaluated by measuring average precisions overall languages, for this experiment I compare the results for Finnish on 1-best predictions only, as I am interested in specific comparison relevant fora single Uralic language.", "labels": [], "entities": [{"text": "morphological generation", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.8525343835353851}]}, {"text": "The results are summarized in table 4.", "labels": [], "entities": []}, {"text": "For morphosyntactic analysis the standard evaluations would be based on attachment scores, however, the rule-based system only creates partial dependency graphs with potentially ambiguous roots; this does notwork with the official evaluation scripts, so I provide instead a raw 1-best precision result for the specific fields in the CONLL-U format.", "labels": [], "entities": [{"text": "precision", "start_pos": 285, "end_pos": 294, "type": "METRIC", "confidence": 0.5846342444419861}, {"text": "CONLL-U format", "start_pos": 333, "end_pos": 347, "type": "DATASET", "confidence": 0.918270081281662}]}, {"text": "The results are shown in table 5; The lemma row corresponds 3rd CONLL-U column, UPOS 4th, Ufeats 6th, XPOS 5th, Dephead 7th, and Deplabel 8th.", "labels": [], "entities": [{"text": "CONLL-U", "start_pos": 64, "end_pos": 71, "type": "METRIC", "confidence": 0.8161167502403259}]}, {"text": "The match is made on strict equality on the string comparison of the whole content, i.e. no re-arranging or approximate matching is performed.", "labels": [], "entities": []}, {"text": "For machine translation the standard shared task evaluation method is to use wellknown metrics that compare translations to reference, specifically BLEU.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.8124286830425262}, {"text": "BLEU", "start_pos": 148, "end_pos": 152, "type": "METRIC", "confidence": 0.9886996150016785}]}, {"text": "In table 6 I measure the BLEU scores for europarl translations.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9990139007568359}, {"text": "europarl translations", "start_pos": 41, "end_pos": 62, "type": "TASK", "confidence": 0.7367148697376251}]}], "tableCaptions": [{"text": " Table 2: Size of the corpora in sentences", "labels": [], "entities": []}, {"text": " Table 3: Usage times of rule-based and neural systems, time-units are indicated in the  table. For TNPP I have found no documentation on how to repeat model building or  what time it has taken. Sents/s stands for average sentences per second. Model sizes  gives you the total size of binaries on disk in binary-prefixed bytes (by ls -h).", "labels": [], "entities": []}, {"text": " Table 4: 1-Best precisions for SIGMORPHON shared task 2016 in Finnish, the winning  Neural system and omorfi scores.", "labels": [], "entities": [{"text": "precisions", "start_pos": 17, "end_pos": 27, "type": "METRIC", "confidence": 0.9977536797523499}, {"text": "SIGMORPHON shared task", "start_pos": 32, "end_pos": 54, "type": "TASK", "confidence": 0.8227671980857849}]}, {"text": " Table 5: 1-best precisions of Turku neural parsing system and omorfi. The numbers  were measured with our script since the official test script does not handle partial  dependency graphs or multiple roots.", "labels": [], "entities": [{"text": "precisions", "start_pos": 17, "end_pos": 27, "type": "METRIC", "confidence": 0.9980207681655884}, {"text": "Turku neural parsing", "start_pos": 31, "end_pos": 51, "type": "TASK", "confidence": 0.8111112117767334}]}, {"text": " Table 6: Automatic translation evaluations, metrics from WMT shared tasks 2018 and  corpora from europarl evaluation section. BLEU scores have been measured with the  tool mteval-14.perl.", "labels": [], "entities": [{"text": "translation evaluations", "start_pos": 20, "end_pos": 43, "type": "TASK", "confidence": 0.8062355816364288}, {"text": "WMT shared tasks", "start_pos": 58, "end_pos": 74, "type": "TASK", "confidence": 0.5873308976491293}, {"text": "BLEU", "start_pos": 127, "end_pos": 131, "type": "METRIC", "confidence": 0.9971709847450256}]}, {"text": " Table 7: Rule-based morphology generation errors classified. .", "labels": [], "entities": [{"text": "Rule-based morphology generation", "start_pos": 10, "end_pos": 42, "type": "TASK", "confidence": 0.6763574679692587}]}]}