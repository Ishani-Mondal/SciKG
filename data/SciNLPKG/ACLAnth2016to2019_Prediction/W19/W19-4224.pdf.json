{"title": [{"text": "Encoder-decoder models for latent phonological representations of words", "labels": [], "entities": []}], "abstractContent": [{"text": "We use sequence-to-sequence networks trained on sequential phonetic encoding tasks to construct compositional phonological representations of words.", "labels": [], "entities": []}, {"text": "We show that the output of an encoder network can predict the phonetic durations of American English words better than a number of alternative forms.", "labels": [], "entities": []}, {"text": "We also show that the model's learned representations map onto existing measures of words' phonological structure (phonolog-ical neighborhood density and phonotactic probability).", "labels": [], "entities": []}], "introductionContent": [{"text": "The representation of linguistic categories is a fundamental problem in (psycho)linguistics and natural language processing.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 96, "end_pos": 123, "type": "TASK", "confidence": 0.6621738274892172}]}, {"text": "The formation of complex representations from more basic components is relevant at all levels of linguistic representation, semantic, syntactic, and phonological.", "labels": [], "entities": []}, {"text": "Finding good representations for words' phonological 1 structure is critical in psycholinguistics, where we wish to understand the phonological structure of the lexicon, which has been shown to be relevant for language comprehension and production.", "labels": [], "entities": []}, {"text": "The distributional hypothesis defines a word by the context in which it occurs.", "labels": [], "entities": []}, {"text": "This approach has been extended more recently to other types of compositional structures, for example in characterizing the meanings and forms of sentences (.", "labels": [], "entities": [{"text": "characterizing the meanings and forms of sentences", "start_pos": 105, "end_pos": 155, "type": "TASK", "confidence": 0.8553347757884434}]}, {"text": "In this paper we explore whether distributional approaches can capture important phonological dependencies.", "labels": [], "entities": []}, {"text": "Specifically, we test the extent to which recurrent encoder-decoder models () can learn representations that characterize the phonological structure of the lexicon while also having linguistic and psychological validity.", "labels": [], "entities": []}, {"text": "We propose that this approach can be used to learn viable lexical-level phonological representations.", "labels": [], "entities": []}, {"text": "The output of the encoder component of our model yields promising results in the prediction of phonetic duration, outperforming a number of alternate phonological representations of words.", "labels": [], "entities": []}], "datasetContent": [{"text": "As a preliminary investigation of the information encoded in the learned lexical representations, we assess their ability to model phonetic duration, which is known to be sensitive to phonotactic probability and phonological overlap (, in addition to other factors like contextual predictability (e.g.  Cohen.", "labels": [], "entities": []}, {"text": "We show that the encoder creates sequence representations that are useful for predicting word duration, and compare the success of the encoder to several other models, described below.", "labels": [], "entities": [{"text": "predicting word duration", "start_pos": 78, "end_pos": 102, "type": "TASK", "confidence": 0.8104514082272848}]}], "tableCaptions": [{"text": " Table 1: Ablation study. Effectiveness of features and combinations of features for predicting (log) phonetic  duration.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9942091703414917}]}]}