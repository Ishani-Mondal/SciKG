{"title": [{"text": "SpaceRefNet: a neural approach to spatial reference resolution in areal city environment", "labels": [], "entities": [{"text": "spatial reference resolution", "start_pos": 34, "end_pos": 62, "type": "TASK", "confidence": 0.715351402759552}]}], "abstractContent": [{"text": "Adding interactive capabilities to pedestrian wayfinding systems in the form of spoken dialogue will make them more natural to humans.", "labels": [], "entities": []}, {"text": "Such an interactive wayfinding system needs to continuously understand and interpret pedestrian's utterances referring to the spatial context.", "labels": [], "entities": []}, {"text": "Achieving this requires the system to identify exophoric referring expressions in the utterances, and link these expressions to the geographic entities in the vicinity.", "labels": [], "entities": []}, {"text": "This exophoric spatial reference resolution problem is difficult, as there are often several dozens of candidate referents.", "labels": [], "entities": [{"text": "exophoric spatial reference resolution", "start_pos": 5, "end_pos": 43, "type": "TASK", "confidence": 0.7549000233411789}]}, {"text": "We present a neural network-based approach for identifying pedestrian's references (using a network called RefNet) and resolving them to appropriate geographic objects (using a network called Space-RefNet).", "labels": [], "entities": []}, {"text": "Both methods show promising results beating the respective baselines and earlier reported results in the literature.", "labels": [], "entities": []}], "introductionContent": [{"text": "Remember yourself being lost in a completely unfamiliar city without knowing the local language or acquaintances that can help?", "labels": [], "entities": []}, {"text": "Being close to desperate, you ask a passerby fora help and get an answer similar to the following: Just go forward until you see a McDonald's on the corner.", "labels": [], "entities": []}, {"text": "There you turn right and keep straight until the old Gothic style church.", "labels": [], "entities": []}, {"text": "A tall glass building near it is exactly what you need.", "labels": [], "entities": []}, {"text": "Such wayfinding instruction is atypical example of how humans guide each other in a city, relying mostly on landmarks in the vicinity (.", "labels": [], "entities": []}, {"text": "On the contrary, a current generation of navigation systems aiding pedestrian wayfinding generally makes use of quantitative information based on GPS signals, e.g. distances, cardinal directions and street names.", "labels": [], "entities": []}, {"text": "The same instruction rephrased by such system would sound as follows: Head north on West Avenue.", "labels": [], "entities": [{"text": "West Avenue", "start_pos": 84, "end_pos": 95, "type": "DATASET", "confidence": 0.9766140580177307}]}, {"text": "Turn right at the corner.", "labels": [], "entities": []}, {"text": "Continue 150 meters straight until East Avenue 29.", "labels": [], "entities": [{"text": "East Avenue 29", "start_pos": 35, "end_pos": 49, "type": "DATASET", "confidence": 0.9492246508598328}]}, {"text": "You've reached your destination.", "labels": [], "entities": []}, {"text": "Such instructions are presented to a pedestrian as a sequence on a screen (possibly voiced as well) supplemented by a map with a moving marker indicating pedestrian's position.", "labels": [], "entities": []}, {"text": "The approach presented above, referred to as turn-by-turn navigation, does not resemble a human wayfinding process and thus can be perceived as unnatural and more complicated than it should.", "labels": [], "entities": [{"text": "turn-by-turn navigation", "start_pos": 45, "end_pos": 68, "type": "TASK", "confidence": 0.731837660074234}]}, {"text": "In our opinion, making pedestrian's experience more natural should be based on the following two observations.", "labels": [], "entities": []}, {"text": "First, a wayfinding is an inherently interactive process, e.g. we need to know if a person is lost, if the instruction is not clear enough, etc.", "labels": [], "entities": []}, {"text": "Human guide guarantees such interactivity, since wayfinding happens in a dialogue, hence a wayfinding system should interact with a pedestrian by means of a spoken dialogue.", "labels": [], "entities": []}, {"text": "Second, humans have difficulties understanding instructions based on quantitative characteristics of a spatial environment (such as distance or angles) (),.", "labels": [], "entities": []}, {"text": "Such instructions make humans less confident in their ability to reach the goal correctly.", "labels": [], "entities": []}, {"text": "Hence, they tend to rely more on qualitative ones, such as salient geographical objects (landmarks), by simply referring to them.", "labels": [], "entities": []}, {"text": "Such approach can be called landmark-by-landmark navigation.", "labels": [], "entities": [{"text": "landmark-by-landmark navigation", "start_pos": 28, "end_pos": 59, "type": "TASK", "confidence": 0.7128795981407166}]}, {"text": "Furthermore, landmarks can be used not only when giving route descriptions, i.e. serving as a guide, but also when being guided.", "labels": [], "entities": []}, {"text": "For instance, when giving a reassuring confirmation to the guide, such as \"Yes, I can see a tall glass building that you've mentioned before\", or describing the proximal surroundings when got lost (\"I believe I'm lost, but I see a pizzeria to my right\").", "labels": [], "entities": []}, {"text": "A prerequisite for providing such interaction capabilities is being able to identify the landmarks referred to by phrases as \"a tall glass building\" or \"a pizzeria to my right\".", "labels": [], "entities": []}, {"text": "Such kind of phrases is called referring expressions (RE) and the landmarks these phrases refer to are called referents.", "labels": [], "entities": []}, {"text": "A task of matching a referring expression with its referent(s) is called reference resolution (RR).", "labels": [], "entities": [{"text": "reference resolution (RR)", "start_pos": 73, "end_pos": 98, "type": "TASK", "confidence": 0.7215424537658691}]}, {"text": "Guiding humans in areal city environment requires resolving exophoric spatial references, i.e. those referring to spatial objects outside of the discourse.", "labels": [], "entities": []}, {"text": "The focus of this paper is on designing the method for solving this task.", "labels": [], "entities": []}, {"text": "The main contribution of this paper is anew method for resolving exophoric spatial REs, consisting of two substeps: \u2022 a method for identifying exophoric spatial REs in spoken utterances; \u2022 a method for resolving exophoric spatial REs to the appropriate referents, represented as 0, 1, or more geographic entities.", "labels": [], "entities": [{"text": "resolving exophoric spatial REs", "start_pos": 55, "end_pos": 86, "type": "TASK", "confidence": 0.7512618899345398}, {"text": "identifying exophoric spatial REs in spoken utterances", "start_pos": 131, "end_pos": 185, "type": "TASK", "confidence": 0.7261842148644584}]}], "datasetContent": [{"text": "In all experiments the networks were trained fora maximum of 100 epochs with the early stopping (patience of 5 epochs).", "labels": [], "entities": [{"text": "patience", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9742092490196228}]}], "tableCaptions": [{"text": " Table 1: Performance of different methods for solving  spatial referring expression identification (sREI) task  on the test set", "labels": [], "entities": [{"text": "solving  spatial referring expression identification (sREI) task", "start_pos": 47, "end_pos": 111, "type": "TASK", "confidence": 0.7273043228520287}]}, {"text": " Table 2: Performance of different methods for solving  spatial reference resolution (sRR) task on the test set  (\"(p)\" stands for positives, \"(n)\" stands for negatives),  \"WAC\" stands for words-as-classifiers method (results  reported in", "labels": [], "entities": [{"text": "solving  spatial reference resolution (sRR) task", "start_pos": 47, "end_pos": 95, "type": "TASK", "confidence": 0.7460941597819328}]}]}