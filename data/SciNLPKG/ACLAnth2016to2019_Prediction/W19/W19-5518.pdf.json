{"title": [{"text": "mhirano at the FinSBD Task: Pointwise Prediction Based on Multi-layer Perceptron for Sentence Boundary Detection", "labels": [], "entities": [{"text": "FinSBD Task", "start_pos": 15, "end_pos": 26, "type": "DATASET", "confidence": 0.9014773070812225}, {"text": "Sentence Boundary Detection", "start_pos": 85, "end_pos": 112, "type": "TASK", "confidence": 0.8680988748868307}]}], "abstractContent": [{"text": "This paper proposes a pointwise prediction fora sentence boundary detection task.", "labels": [], "entities": [{"text": "sentence boundary detection task", "start_pos": 48, "end_pos": 80, "type": "TASK", "confidence": 0.7444327473640442}]}, {"text": "The proposed pointwise prediction is combined with our original word embedding method and three-layered percep-tron.", "labels": [], "entities": []}, {"text": "It predicts whether the targeted words have the role of the beginning/end of a sentence or not by using word features around the targeted words.", "labels": [], "entities": []}, {"text": "We tested our model by changing some parameters in our model and then ensembled these models with various parameters.", "labels": [], "entities": []}, {"text": "Consequently, the ensembled model achieved 0.88 and 0.84 averaged f1-score by testing the data both in English and French, and it also obtained 0.84 in English and 0.86 in French as the final results of this shared task.", "labels": [], "entities": [{"text": "f1-score", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9608992338180542}]}, {"text": "In addition, we developed a baseline model, that is, a rule-based prediction model, for comparison.", "labels": [], "entities": []}, {"text": "The result shows that the proposed pointwise prediction model out-performed the rule-based prediction model in any index.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper presents the application technique 1 of the pointwise prediction to a shared task of Sentence Boundary Detection in PDF Noisy Text in the Financial Domain for the FinSBD 2019 shared task . We address the sentence boundary detection problem in PDF Noisy Text using a type of approach referred to as \"pointwise\" prediction.", "labels": [], "entities": [{"text": "Sentence Boundary Detection", "start_pos": 96, "end_pos": 123, "type": "TASK", "confidence": 0.9100450476010641}, {"text": "FinSBD 2019 shared task", "start_pos": 174, "end_pos": 197, "type": "DATASET", "confidence": 0.9093794971704483}, {"text": "sentence boundary detection", "start_pos": 215, "end_pos": 242, "type": "TASK", "confidence": 0.6614660024642944}]}, {"text": "Pointwise prediction is an approach used to make every single independent decision at each point by using only the features around a single point.", "labels": [], "entities": [{"text": "Pointwise prediction", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.6825459003448486}]}, {"text": "In this task, a pointwise prediction indicates predicting whether each word has a role as the beginning/end of the sentence or not by using only the features around that word.", "labels": [], "entities": []}, {"text": "This type of approach was also used in Japanese morphological analysis, which is a task to detect boundaries of the smallest meaningful units because Japanese text has no spacing between each word.", "labels": [], "entities": [{"text": "Japanese morphological analysis", "start_pos": 39, "end_pos": 70, "type": "TASK", "confidence": 0.7433481613794962}]}, {"text": "The pointwise prediction for Japanese morphological analysis achieved high results.", "labels": [], "entities": [{"text": "Japanese morphological analysis", "start_pos": 29, "end_pos": 60, "type": "TASK", "confidence": 0.8074851632118225}]}, {"text": "The advantages of this pointwise prediction are its robustness and adaptiveness.", "labels": [], "entities": []}, {"text": "Presently, many prediction techniques based on machine learning exist.", "labels": [], "entities": []}, {"text": "Machine learning, specifically recurrent neural network (RNN), remarkably depends on features, and when one of the features is wrong, the results through these machine learning can also be wrong.", "labels": [], "entities": []}, {"text": "However, the effect of the wrong feature or missing feature information is supposed to be local when this type of pointwise prediction is used.", "labels": [], "entities": []}, {"text": "In addition, prediction using machine learning techniques apart from the pointwise prediction, particularly RNN, requires many training data, but the training data in this task are limited.", "labels": [], "entities": [{"text": "prediction", "start_pos": 13, "end_pos": 23, "type": "TASK", "confidence": 0.9720721244812012}]}, {"text": "Nevertheless, by using the pointwise prediction, the training data become more abundant than that of other machine learning techniques because the number of sentences is limited and much less than the number of candidates for sentence boundaries.", "labels": [], "entities": []}, {"text": "We supposed that the pointwise prediction has some advantages on this prediction task, that is, sentence boundary detection with noise.", "labels": [], "entities": [{"text": "sentence boundary detection", "start_pos": 96, "end_pos": 123, "type": "TASK", "confidence": 0.6953365206718445}]}, {"text": "For this shared task, we submitted two test predictions, one of which is the result of our pointwise model and the other one is that of a simple rule-based model only.", "labels": [], "entities": []}, {"text": "Here, we focused on describing the first one, and the latter is treated as a baseline model.", "labels": [], "entities": []}, {"text": "In addition, we used the script that was distributed by the organizer of this shared task for evaluations.", "labels": [], "entities": []}], "datasetContent": [{"text": "We were provided with the data by the organizers of this shared task, containing the \"training data\" and \"development data\" for two languages, i.e., English and French.", "labels": [], "entities": []}, {"text": "We performed the same experiments on each language.", "labels": [], "entities": []}, {"text": "In addition, we treated the \"training data\" as training data and the \"development data\" as test data.", "labels": [], "entities": []}, {"text": "(Actually, the organizers provided also the \"test data\" to form the leaderboard of this shared task, but we ignored these data in this paper other than final results.)", "labels": [], "entities": []}, {"text": "These data contain sentences from the PDF Noisy Text but were split well for each word, symbols, or something, the list of the beginning of the sentences, and the list of the beginning of the sentences . Using these data, we tested our model.", "labels": [], "entities": [{"text": "PDF Noisy Text", "start_pos": 38, "end_pos": 52, "type": "DATASET", "confidence": 0.8810263872146606}]}, {"text": "In our model, several unfixed hyperparameters are the following: 1.", "labels": [], "entities": []}, {"text": "NW : window size; 2.", "labels": [], "entities": []}, {"text": "ND : the dimension for word2vec; and 3.", "labels": [], "entities": []}, {"text": "NH : the number of nodes on every single hidden layer in the three-layered perceptron.", "labels": [], "entities": [{"text": "NH", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.9859053492546082}]}, {"text": "We modified these hyperparameters as in Apart from these parameter sets, we ensembled the results of all models.", "labels": [], "entities": []}, {"text": "In the ensembling process, only the words that two-thirds of all models agree with become the beginning/ending of the sentences.", "labels": [], "entities": []}, {"text": "Each result for each parameter sets using pointwise prediction model are shown in        the beginning/ending of the sentences and others.", "labels": [], "entities": []}, {"text": "F1-score denotes the harmonic average of precision and recall.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.99036705493927}, {"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9940642714500427}, {"text": "recall", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9968157410621643}]}, {"text": "shows the comparison between the results of the pointwise prediction model with ensembling and the results of the baseline model, i.e., rule-based model.", "labels": [], "entities": []}, {"text": "In both English and French, our pointwise prediction model outperformed our baseline model in any index.", "labels": [], "entities": []}, {"text": "shows the test results from and the final results from this shared task's leaderboard.", "labels": [], "entities": []}, {"text": "Predictions for the French language in the test and final results have a slight difference, whereas those for the English language have significant gaps.", "labels": [], "entities": []}, {"text": "Specifically, the rule-based model in English performs worse in the final results.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results of the English language using the pointwise pre- diction model and its hyperparameter sets. Here, BS/ES indicates  f1-score for the prediction of the beginning/ending of the sentences  and Ave. denotes the average of BS and ES.", "labels": [], "entities": [{"text": "BS/ES", "start_pos": 116, "end_pos": 121, "type": "METRIC", "confidence": 0.8263826966285706}, {"text": "prediction of the beginning/ending of the sentences", "start_pos": 150, "end_pos": 201, "type": "TASK", "confidence": 0.8388771480984158}, {"text": "BS", "start_pos": 235, "end_pos": 237, "type": "METRIC", "confidence": 0.9840899109840393}, {"text": "ES", "start_pos": 242, "end_pos": 244, "type": "METRIC", "confidence": 0.958670973777771}]}, {"text": " Table 3: Detailed results for English using the pointwise prediction  ensemble model.", "labels": [], "entities": []}, {"text": " Table 4: Results of the French language using the pointwise predic- tion model and its each hyperparameter sets. Here, BS/ES indicates  f1-score for the prediction of the beginning/ending of the sentences  and Ave. denotes the average of BS and ES.", "labels": [], "entities": [{"text": "BS/ES", "start_pos": 120, "end_pos": 125, "type": "METRIC", "confidence": 0.7817754546801249}, {"text": "prediction of the beginning/ending of the sentences", "start_pos": 154, "end_pos": 205, "type": "TASK", "confidence": 0.8315613336033292}, {"text": "BS", "start_pos": 239, "end_pos": 241, "type": "METRIC", "confidence": 0.9710744023323059}, {"text": "ES", "start_pos": 246, "end_pos": 248, "type": "METRIC", "confidence": 0.9744346737861633}]}, {"text": " Table 5: Detailed results for French using the pointwise prediction  ensemble model.", "labels": [], "entities": []}, {"text": " Table 6: Comparing the results of pointwise prediction with ensem- bling and the results of the baseline model, i.e., rule-based model.", "labels": [], "entities": [{"text": "ensem- bling", "start_pos": 61, "end_pos": 73, "type": "METRIC", "confidence": 0.7935380339622498}]}, {"text": " Table 7: Test and final results of all models and languages. The final  result is the result of this shared task and was on the leaderboard.", "labels": [], "entities": []}, {"text": " Table 8: Top of the results in various parameters. Here, Ave. denotes  the average of the results of both English and French.", "labels": [], "entities": []}, {"text": " Table 9: Parameters for three-layered perceptron", "labels": [], "entities": [{"text": "Parameters", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9111317992210388}]}]}