{"title": [{"text": "An Analysis of Source-Side Grammatical Errors in NMT", "labels": [], "entities": [{"text": "NMT", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.4350948631763458}]}], "abstractContent": [{"text": "The quality of Neural Machine Translation (NMT) has been shown to significantly degrade when confronted with source-side noise.", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT)", "start_pos": 15, "end_pos": 47, "type": "TASK", "confidence": 0.7556691666444143}]}, {"text": "We present the first large-scale study of state-of-the-art English-to-German NMT on real grammatical noise, by evaluating on several Grammar Correction corpora.", "labels": [], "entities": []}, {"text": "We present methods for evaluating NMT robustness without true references, and we use them for extensive analysis of the effects that different grammatical errors have on the NMT output.", "labels": [], "entities": []}, {"text": "We also introduce a technique for visualizing the divergence distribution caused by a source-side error, which allows for additional insights.", "labels": [], "entities": []}], "introductionContent": [{"text": "Neural Machine Translation (NMT) has become the de facto option for industrial systems in high-resource settings ( while dominating public benchmarks (.", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.810607115427653}]}, {"text": "However, as several works have shown, it has a notable shortcoming (among others, see for relevant discussion) in dealing with source-side noise, during both training and inference.", "labels": [], "entities": []}, {"text": "as well as pointed out the degraded performance of character-and subword-level NMT models when confronted with synthetic character-level noise -like swaps and scrambling-on French, German, and Czech to English MT. and also studied synthetic errors from word swaps extracted from Wikipedia edits.", "labels": [], "entities": [{"text": "word swaps extracted from Wikipedia edits", "start_pos": 253, "end_pos": 294, "type": "TASK", "confidence": 0.8035218268632889}]}, {"text": "focused on a small subset of grammatical errors (article, preposition, noun number, and subject-verb agreement) and evaluated on English-to-Spanish synthetic and natural data.", "labels": [], "entities": []}, {"text": "However, no previous work has extensively studied the behavior of a state-of-the-art (SOTA) model on natural occurring data.", "labels": [], "entities": []}, {"text": "only trained their systems on about 200K parallel instances, while and trained on about 2M parallel sentences from the WMT'16 data.", "labels": [], "entities": [{"text": "WMT'16 data", "start_pos": 119, "end_pos": 130, "type": "DATASET", "confidence": 0.969628632068634}]}, {"text": "Importantly, though, none of them utilized vast monolingual resources through backtranslation, a technique that has been consistently shown to lead to impressively better results.", "labels": [], "entities": []}, {"text": "In this work, we perform an extensive analysis of the performance of a state-of-the-art EnglishGerman NMT system, with regards to its robustness against real grammatical noise.", "labels": [], "entities": [{"text": "EnglishGerman NMT system", "start_pos": 88, "end_pos": 112, "type": "DATASET", "confidence": 0.8718156019846598}]}, {"text": "We propose a method for robustness evaluation without goldstandard translation references, and perform experiments and extensive analysis on all available English Grammar Error Correction (GEC) corpora.", "labels": [], "entities": [{"text": "English Grammar Error Correction (GEC) corpora", "start_pos": 155, "end_pos": 201, "type": "DATASET", "confidence": 0.4596632048487663}]}, {"text": "Finally, we introduce a visualization technique for performing further analysis.", "labels": [], "entities": []}], "datasetContent": [{"text": "To our knowledge, there are six publicly available corpora of non-native or erroneous English that are annotated with corrections and which have been widely used for research in GEC.", "labels": [], "entities": [{"text": "GEC", "start_pos": 178, "end_pos": 181, "type": "DATASET", "confidence": 0.5393471717834473}]}, {"text": "The NUS Corpus of Learner English (NUCLE) contains essays written by students at the National University of Singapore ().", "labels": [], "entities": [{"text": "NUS Corpus of Learner English (NUCLE)", "start_pos": 4, "end_pos": 41, "type": "DATASET", "confidence": 0.9583899304270744}]}, {"text": "It has become the main benchmark for GEC, as it was used in the CoNLL GEC Shared Tasks ().", "labels": [], "entities": [{"text": "GEC", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.5044033527374268}, {"text": "CoNLL GEC Shared Tasks", "start_pos": 64, "end_pos": 86, "type": "DATASET", "confidence": 0.8459315896034241}]}, {"text": "The Cambridge Learner Corpus First Certificate in English FCE corpus 1) consists of essays collected from learners taking the Cambridge Assessment's English as a Second or Other Language (ESOL) exams.", "labels": [], "entities": [{"text": "Cambridge Learner Corpus First Certificate in English FCE corpus 1", "start_pos": 4, "end_pos": 70, "type": "DATASET", "confidence": 0.9368062198162079}, {"text": "Cambridge Assessment's English as a Second or Other Language (ESOL) exams", "start_pos": 126, "end_pos": 199, "type": "DATASET", "confidence": 0.9174301326274872}]}, {"text": "The Lang-8 corpus () was harvested from user-provided corrections in an online learner forum.", "labels": [], "entities": [{"text": "Lang-8 corpus", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.9753186702728271}]}, {"text": "Both have also been widely used for the GEC Shared Tasks.", "labels": [], "entities": [{"text": "GEC Shared Tasks", "start_pos": 40, "end_pos": 56, "type": "DATASET", "confidence": 0.8204163511594137}]}, {"text": "Another small corpus developed for evaluation purposes is the JHU FLuency-Extended GUG corpus (JFLEG) ( with correction annotations that include extended fluency edits rather than just minimal grammatical ones.", "labels": [], "entities": [{"text": "JHU FLuency-Extended GUG corpus (JFLEG)", "start_pos": 62, "end_pos": 101, "type": "DATASET", "confidence": 0.8294210987431663}]}, {"text": "The Cambridge English Write & Improve (W&I) corpus) is collected from an online platform where English learners submit text and professional annotators correct them, also assigning a CEFR level of proficiency (of Europe.", "labels": [], "entities": [{"text": "Cambridge English Write & Improve (W&I) corpus", "start_pos": 4, "end_pos": 50, "type": "DATASET", "confidence": 0.648543040860783}, {"text": "CEFR", "start_pos": 183, "end_pos": 187, "type": "METRIC", "confidence": 0.5847527384757996}]}, {"text": "Lastly, we use a portion of the LOCNESS corpus, 3 a collection of essays written by native English speakers.", "labels": [], "entities": [{"text": "LOCNESS corpus", "start_pos": 32, "end_pos": 46, "type": "DATASET", "confidence": 0.870051920413971}]}, {"text": "50 essays from LOCNESS were annotated by W&I annotators for grammatical errors, so we will jointly refer to these two corpora as WI+loc.", "labels": [], "entities": []}, {"text": "All datasets were consistently annotated for errors with ERRANT (, an automatic tool that categorizes correction edits.", "labels": [], "entities": [{"text": "ERRANT", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.9934307932853699}]}, {"text": "This allows us to consistently aggregate results and analysis across all datasets.", "labels": [], "entities": []}, {"text": "Throughout this work, we use the following notations: \u2022 x: the original, noisy, potentially ungrammatical English sentence.", "labels": [], "entities": []}, {"text": "Its tokens will be denoted as xi . \u2022 \u02dc x: the English sentence with the correction annotations applied to the original sentence x, which is deemed fluent and grammatical.", "labels": [], "entities": []}, {"text": "Again, its tokens will be denoted as\u02dcxas\u02dc as\u02dcx i . \u2022 y: the output of the NMT system when x is provided as input (tokens: y j ).", "labels": [], "entities": []}, {"text": "\u2022 \u02dc y: the output of the NMT system whe\u00f1 x is provided as input (tokens: \u02dc y j ).", "labels": [], "entities": [{"text": "NMT", "start_pos": 25, "end_pos": 28, "type": "DATASET", "confidence": 0.8246235251426697}]}, {"text": "For the sake of readability, we use the terms grammatical errors, noise, or edits interchangeably.", "labels": [], "entities": []}, {"text": "In the context of this work, they will all denote the annotated grammatical errors in the source sentences (x).", "labels": [], "entities": []}, {"text": "We also define the number of errors, or the amount of noise in the source, to be equivalent to the number of annotated necessary edits that the source x requires to be deemed grammatical (\u02dc x), as per standard GEC literature.", "labels": [], "entities": [{"text": "GEC literature", "start_pos": 210, "end_pos": 224, "type": "DATASET", "confidence": 0.9141855537891388}]}, {"text": "The main focus of our work is the performance analysis of the NMT system, so our experimental design is fairly simple.", "labels": [], "entities": []}, {"text": "We use the SOTA NMT system of for translating both the original and the corrected English sentences for all our GEC corpora.", "labels": [], "entities": [{"text": "SOTA NMT", "start_pos": 11, "end_pos": 19, "type": "DATASET", "confidence": 0.5565267503261566}, {"text": "GEC corpora", "start_pos": 112, "end_pos": 123, "type": "DATASET", "confidence": 0.850820392370224}]}, {"text": "The system achieved the best performance in the WMT 2018 evaluation campaign, using an ensemble of 6 deep transformer models trained with slightly different backtranslated data.", "labels": [], "entities": [{"text": "WMT 2018 evaluation campaign", "start_pos": 48, "end_pos": 76, "type": "DATASET", "confidence": 0.64295893907547}]}], "tableCaptions": [{"text": " Table 1: Aggregate results across all datasets. As expected, the NMT system's performance deteriorates as input  noise increases. For all metrics except NR, higher scores are better.", "labels": [], "entities": []}]}