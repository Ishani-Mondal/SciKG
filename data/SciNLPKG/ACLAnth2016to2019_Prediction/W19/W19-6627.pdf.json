{"title": [], "abstractContent": [{"text": "Post-editing (PE) machine translation (MT) is widely used for dissemination because it leads to higher productivity than human translation from scratch (HT).", "labels": [], "entities": [{"text": "Post-editing (PE) machine translation (MT)", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.6558338403701782}, {"text": "human translation from scratch (HT)", "start_pos": 121, "end_pos": 156, "type": "TASK", "confidence": 0.7753864186150687}]}, {"text": "In addition, PE translations are found to be of equal or better quality than HTs.", "labels": [], "entities": [{"text": "PE translations", "start_pos": 13, "end_pos": 28, "type": "TASK", "confidence": 0.942797839641571}]}, {"text": "However, most such studies measure quality solely as the number of errors.", "labels": [], "entities": []}, {"text": "We conduct a set of computational analyses in which we compare PE against HT on three different datasets that cover five translation directions with measures that address different translation universals and laws of translation: simplification, normalisation and interference.", "labels": [], "entities": []}, {"text": "We find out that PEs are simpler and more normalised and have a higher degree of interference from the source language than HTs.", "labels": [], "entities": [{"text": "PEs", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.9295222163200378}]}], "introductionContent": [{"text": "Machine translation (MT) is nowadays widely used in industry for dissemination purposes by means of post-editing (PE, also referred to as PEMT in the literature), a machine-assisted approach to translation that results in notable increases in translation productivity compared to unaided human translation (HT), as shown in numerous research studies, e.g. Plitt and Masselot.", "labels": [], "entities": [{"text": "Machine translation (MT)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8894476413726806}, {"text": "unaided human translation (HT)", "start_pos": 280, "end_pos": 310, "type": "TASK", "confidence": 0.8131446142991384}]}, {"text": "In theory, one would claim that HTs 1 and PE translations are clearly different, since, in the c 2019 The authors.", "labels": [], "entities": []}, {"text": "This article is licensed under a Creative Commons 4.0 licence, no derivative works, attribution, CC-BY-ND.", "labels": [], "entities": []}, {"text": "By HT we refer to translations produced by a human from scratch, i.e. without the assistance of an MT system or any other computer-assisted technology, e.g. translation memories.", "labels": [], "entities": []}, {"text": "translation workflow of the latter, the translator is primed by the output of an MT system (, resulting in a translation that should then contain, to some extent, the footprint of that MT system.", "labels": [], "entities": []}, {"text": "Because of this, one would conclude that HT should be preferred over PE, as the former should be more natural and adhere more closely to the norms of the target language.", "labels": [], "entities": [{"text": "HT", "start_pos": 41, "end_pos": 43, "type": "TASK", "confidence": 0.8071403503417969}]}, {"text": "However, many research studies have shown that the quality of PE is comparable to that of HT or even better, e.g., and, according to one study, native speakers do not have a clear preference for HT over PE.", "labels": [], "entities": []}, {"text": "In this paper we conduct a set of computational analyses on several datasets that contain HTs and PEs, involving different language directions and domains as well as PE performed according to different guidelines (e.g. full versus light).", "labels": [], "entities": []}, {"text": "Our aim is to find out whether HT and PE differ significantly in terms of different phenomena.", "labels": [], "entities": [{"text": "HT", "start_pos": 31, "end_pos": 33, "type": "TASK", "confidence": 0.8387340903282166}]}, {"text": "Since previous research has proven the existence of translationese, i.e. the fact that HT and original text exhibit different characteristics, our current research can be framed as a quest to find out whether there is evidence of post-editese, i.e. the fact that HT (or translationese) and PE would be different.", "labels": [], "entities": []}, {"text": "The characteristics of translationese can be grouped along the so-called universal features of translation or translation universals, namely simplification, normalisation (also referred to as homogeneisation) and explicitation.", "labels": [], "entities": []}, {"text": "In addition to these three, interference is recognised as a fundamental law of translation: \"phenomena pertaining to the make-up of the source text tend to be transferred to the target text\".", "labels": [], "entities": [{"text": "translation", "start_pos": 79, "end_pos": 90, "type": "TASK", "confidence": 0.968496561050415}]}, {"text": "Ina nutshell, compared to original texts, translations tend to be simpler, more standardised, and more explicit and they retain some characteristics that pertain to the source language.", "labels": [], "entities": []}, {"text": "In this study then we study the existence of posteditese by conducting a set of computational analyses that fall into three 2 out of these four categories.", "labels": [], "entities": []}, {"text": "With these analyses we aim to answer a number of research questions: \u2022 RQ1.", "labels": [], "entities": [{"text": "RQ1", "start_pos": 71, "end_pos": 74, "type": "DATASET", "confidence": 0.5014092326164246}]}, {"text": "I.e. is there evidence that PE exhibits different characteristics than HT?", "labels": [], "entities": [{"text": "PE", "start_pos": 28, "end_pos": 30, "type": "TASK", "confidence": 0.6102941632270813}]}, {"text": "If the answer to RQ1 is yes, then which are the main characteristics of PE?", "labels": [], "entities": [{"text": "RQ1", "start_pos": 17, "end_pos": 20, "type": "METRIC", "confidence": 0.6617077589035034}]}, {"text": "I.e. how does it differ from HT?", "labels": [], "entities": [{"text": "HT", "start_pos": 29, "end_pos": 31, "type": "DATASET", "confidence": 0.6526089310646057}]}, {"text": "If the answer to RQ1 is yes, then, are there different post-editeses?", "labels": [], "entities": [{"text": "RQ1", "start_pos": 17, "end_pos": 20, "type": "DATASET", "confidence": 0.5886316299438477}]}, {"text": "I.e. are there any characteristics that distinguish the posteditese produced by MT systems that follow different paradigms (rule-based, statistical phrase-based and neural)?", "labels": [], "entities": [{"text": "MT", "start_pos": 80, "end_pos": 82, "type": "TASK", "confidence": 0.9441913962364197}]}, {"text": "The rest of this paper is organised as follows.", "labels": [], "entities": []}, {"text": "Section 2 provides an overview of the related work.", "labels": [], "entities": []}, {"text": "Section 3 covers the experimental setup and the experiments conducted.", "labels": [], "entities": []}, {"text": "Finally, Section 4 presents our conclusions and suggests lines of future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we first describe the datasets used (Section 3.1), and then report on each of the experiments that we carried out in the subsequent subsections: lexical variety (Section 3.2), lexical density (Section 3.3), length ratio (Section 3.4) and part-of-speech sequences (Section 3.5).", "labels": [], "entities": [{"text": "length ratio", "start_pos": 223, "end_pos": 235, "type": "METRIC", "confidence": 0.8621297180652618}]}, {"text": "We make use of three datasets in all our experiments: Tarax\u00fc (Avramidis et al., 2014), IWSLT ( and Microsoft \"Human Parity\" (, henceforth referred to as MS.", "labels": [], "entities": [{"text": "IWSLT", "start_pos": 87, "end_pos": 92, "type": "DATASET", "confidence": 0.7243644595146179}, {"text": "MS.", "start_pos": 153, "end_pos": 156, "type": "DATASET", "confidence": 0.9103688299655914}]}, {"text": "These datasets cover five different translation directions that involve five languages: 7 English\u2194German, English\u2192French, Spanish\u2192German and Chinese\u2192English.", "labels": [], "entities": []}, {"text": "In addition, this choice of datasets allows us to include a longitudinal aspect into the analyses since there are state-of-the-art MT systems from almost one decade ago (in, from three and four years ago (IWSLT) and from just one year ago (MS).", "labels": [], "entities": [{"text": "MT", "start_pos": 131, "end_pos": 133, "type": "TASK", "confidence": 0.984198808670044}]}, {"text": "shows detailed information about each dataset, namely its translation direction(s), type of PE done, paradigm of the MT system(s) used, number of sentence pairs and domain of its text.", "labels": [], "entities": [{"text": "MT", "start_pos": 117, "end_pos": 119, "type": "TASK", "confidence": 0.9424399733543396}]}, {"text": "We note the following two limitations in some of the datasets: \u2022 Mismatch of translator competence.", "labels": [], "entities": []}, {"text": "Both PE and HT are carried out by professional translators in two of the datasets (Tarax\u00fc and MS).", "labels": [], "entities": [{"text": "PE", "start_pos": 5, "end_pos": 7, "type": "METRIC", "confidence": 0.7114027738571167}, {"text": "Tarax\u00fc", "start_pos": 83, "end_pos": 89, "type": "DATASET", "confidence": 0.890748143196106}]}, {"text": "However, in the remaining one, IWSLT, professional translators do PE, while the translators doing HT are not necessarily professionals 8 . Thus, if we find differences between PEs and HTs, for this dataset this may not be (entirely) due to the two translations procedures leading to different translations but (also) to the different translations being produced by translators with different levels of proficiency.", "labels": [], "entities": [{"text": "IWSLT", "start_pos": 31, "end_pos": 36, "type": "DATASET", "confidence": 0.9276704788208008}]}, {"text": "In the tables and experiments we will refer to languages with their ISO-2 codes.", "labels": [], "entities": []}, {"text": "For directions with more than one MT system, the result shown in rows PE and MT uses the average score of all the PEs or MT outputs, respectively.", "labels": [], "entities": [{"text": "MT", "start_pos": 34, "end_pos": 36, "type": "TASK", "confidence": 0.9493298530578613}]}, {"text": "The best result (highest TTR) in each group of rows is shown in bold.", "labels": [], "entities": [{"text": "TTR)", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9921994805335999}]}, {"text": "If a \u2020 is not shown then the TTR for HT is significantly higher than the TTRs for all the translations in that cell (the 95% confidence interval of the TTR of HT, obtained with bootstrap resampling, is higher and there is no overlap).", "labels": [], "entities": [{"text": "TTR", "start_pos": 29, "end_pos": 32, "type": "METRIC", "confidence": 0.9934913516044617}, {"text": "TTRs", "start_pos": 73, "end_pos": 77, "type": "METRIC", "confidence": 0.9451330900192261}]}, {"text": "\u2022 Source language being translationese.", "labels": [], "entities": []}, {"text": "In two of the datasets (MS and IWSLT), the source language and the language in which those texts were originally written is the same.", "labels": [], "entities": [{"text": "MS", "start_pos": 24, "end_pos": 26, "type": "DATASET", "confidence": 0.9265540242195129}, {"text": "IWSLT", "start_pos": 31, "end_pos": 36, "type": "DATASET", "confidence": 0.6354086399078369}]}, {"text": "This is not the case however for Tarax\u00fc, for which the original language of the source texts is Czech.", "labels": [], "entities": []}, {"text": "We can still compare MT to PE although we need to take into account that these texts are easier for MT than original texts (.", "labels": [], "entities": [{"text": "MT", "start_pos": 21, "end_pos": 23, "type": "TASK", "confidence": 0.9854959845542908}, {"text": "MT", "start_pos": 100, "end_pos": 102, "type": "TASK", "confidence": 0.9880595803260803}]}, {"text": "However the comparison between PE (or MT) and HT is problematic since the HT was not translated from the source language but from another language (Czech).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Information about the datasets used in the experiments", "labels": [], "entities": []}, {"text": " Table 5: Perplexity difference scores for HT and relative differences for PE and MT. For directions with more than one MT  system, the result shown in rows PE and MT uses the average score of all the PEs or MT outputs, respectively. The best result  (highest perplexity) in each group of rows is shown in bold.", "labels": [], "entities": [{"text": "MT", "start_pos": 82, "end_pos": 84, "type": "TASK", "confidence": 0.6845394372940063}]}]}