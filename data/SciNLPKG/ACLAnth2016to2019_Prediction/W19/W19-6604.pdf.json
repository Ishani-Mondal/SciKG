{"title": [{"text": "Debiasing Word Embeddings Improves Multimodal Machine Translation", "labels": [], "entities": [{"text": "Debiasing Word Embeddings Improves Multimodal Machine Translation", "start_pos": 0, "end_pos": 65, "type": "TASK", "confidence": 0.8404058473450797}]}], "abstractContent": [{"text": "In recent years, pretrained word embed-dings have proved useful for multimodal neural machine translation (NMT) models to address the shortage of available datasets.", "labels": [], "entities": [{"text": "multimodal neural machine translation (NMT)", "start_pos": 68, "end_pos": 111, "type": "TASK", "confidence": 0.7434406450816563}]}, {"text": "However, the integration of pretrained word embeddings has not yet been explored extensively.", "labels": [], "entities": []}, {"text": "Further, pre-trained word embeddings in high dimensional spaces have been reported to suffer from the hubness problem.", "labels": [], "entities": []}, {"text": "Although some debiasing techniques have been proposed to address this problem for other natural language processing tasks, they have seldom been studied for multimodal NMT models.", "labels": [], "entities": []}, {"text": "In this study, we examine various kinds of word embeddings and introduce two debiasing techniques for three mul-timodal NMT models and two language pairs-English-German translation and English-French translation.", "labels": [], "entities": []}, {"text": "With our optimal settings, the overall performance of multimodal models was improved by up to +1.62 BLEU and +1.14 METEOR for English-German translation and +1.40 BLEU and +1.13 METEOR for English-French translation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 100, "end_pos": 104, "type": "METRIC", "confidence": 0.9991362690925598}, {"text": "METEOR", "start_pos": 115, "end_pos": 121, "type": "METRIC", "confidence": 0.9962342381477356}, {"text": "BLEU", "start_pos": 163, "end_pos": 167, "type": "METRIC", "confidence": 0.9981452226638794}, {"text": "METEOR", "start_pos": 178, "end_pos": 184, "type": "METRIC", "confidence": 0.988399863243103}]}], "introductionContent": [{"text": "In multimodal machine translation, a target sentence is translated from a source sentence together with related nonlinguistic information such as visual information.", "labels": [], "entities": [{"text": "multimodal machine translation", "start_pos": 3, "end_pos": 33, "type": "TASK", "confidence": 0.635737806558609}]}, {"text": "Recently, neural machine translation (NMT) has superseded traditional statistical machine translation owing to the introduction established word embeddings and introduce debiasing techniques for multimodal NMT models.", "labels": [], "entities": [{"text": "neural machine translation (NMT)", "start_pos": 10, "end_pos": 42, "type": "TASK", "confidence": 0.8304494818051656}, {"text": "statistical machine translation", "start_pos": 70, "end_pos": 101, "type": "TASK", "confidence": 0.673432062069575}]}, {"text": "The main contributions of this study are as follows: 1.", "labels": [], "entities": []}, {"text": "We show that GloVe word embeddings are useful for various multimodal NMT models irrespective of the extent to which visual features are used in them.", "labels": [], "entities": []}, {"text": "2. We introduce All-but-the-Top debiasing technique for pretrained word embeddings to further improve multimodal NMT models.", "labels": [], "entities": []}], "datasetContent": [{"text": "We train, validate, and test all multimodal NMT models using the dataset.", "labels": [], "entities": []}, {"text": "English is selected as the source language, and German/French are selected as target languages.", "labels": [], "entities": []}, {"text": "All sentences in all languages are preprocessed by lower-casing, tokenizing, and normalizing the punctuation.", "labels": [], "entities": []}, {"text": "We run experiments without byte pair encoding (BPE) () for all models as BPE breaks a word into subwords, resulting in an increase in OOV words for word2vec and GloVe embeddings.", "labels": [], "entities": []}, {"text": "In addition, we also run experiments using BPE with 10k merge operations to show the utility of pretrained word embeddings.", "labels": [], "entities": [{"text": "BPE", "start_pos": 43, "end_pos": 46, "type": "DATASET", "confidence": 0.565979540348053}]}, {"text": "The BPE subwords are shared for source and target languages and learnt from training dataset . shows the statistics of vocabularies in the Multi30K training data.", "labels": [], "entities": [{"text": "Multi30K training data", "start_pos": 139, "end_pos": 161, "type": "DATASET", "confidence": 0.9056018988291422}]}, {"text": "Visual features are extracted using pretrained ResNet-50 (.", "labels": [], "entities": []}, {"text": "We encode all images in the Multi30K dataset using ResNet-50 and pick out the hidden state in the res4f layer of 1024D for the doubly-attentive model, and that in the pool5  layer of 2048D for IMAGINATION and VAG-NET, respectively.", "labels": [], "entities": [{"text": "Multi30K dataset", "start_pos": 28, "end_pos": 44, "type": "DATASET", "confidence": 0.9464199244976044}, {"text": "VAG-NET", "start_pos": 209, "end_pos": 216, "type": "DATASET", "confidence": 0.5669393539428711}]}], "tableCaptions": [{"text": " Table 2: Statistics of vocabularies without BPE (upper) and  with BPE (lower) in Multi30K training data. \"Vocab\" denotes  the number of OOV words for the vocabulary. \"Embed\" de- notes the number of OOV words for embeddings. \"English \u2192  German\" shows statistics of the shared subwords for English- German translation, and \"English \u2192 French\" for English- French translation.", "labels": [], "entities": [{"text": "BPE", "start_pos": 45, "end_pos": 48, "type": "METRIC", "confidence": 0.9620538353919983}, {"text": "BPE", "start_pos": 67, "end_pos": 70, "type": "METRIC", "confidence": 0.9882235527038574}, {"text": "Multi30K training data", "start_pos": 82, "end_pos": 104, "type": "DATASET", "confidence": 0.6771097381909689}]}, {"text": " Table 3: Results obtained using Multi30K test2016 dataset for English-German translation. \"NMT\" shows the results of  Bahdanau et al. (2015). When the debiasing is \"None,\" we show the results obtained with raw pretrained word embeddings or  random values.", "labels": [], "entities": [{"text": "Multi30K test2016 dataset", "start_pos": 33, "end_pos": 58, "type": "DATASET", "confidence": 0.670622338851293}, {"text": "English-German translation", "start_pos": 63, "end_pos": 89, "type": "TASK", "confidence": 0.5300076007843018}]}, {"text": " Table 6: Results of VAG-NET with various settings obtained  using Multi30K test2016 dataset for English-German transla- tion (upper) and English-French translation (lower). \"BPE\"  denotes whether a model uses BPE. \"Init\" denotes the ini- tialization strategy: \"random,\" a model initialized using ran- dom values and \"GloVe,\" a model initialized using GloVe em- beddings with All-but-the-Top debiasing (English-German)  or without debiasing (English-French).", "labels": [], "entities": [{"text": "VAG-NET", "start_pos": 21, "end_pos": 28, "type": "DATASET", "confidence": 0.7959227561950684}, {"text": "Multi30K test2016 dataset", "start_pos": 67, "end_pos": 92, "type": "DATASET", "confidence": 0.8721460302670797}, {"text": "BPE", "start_pos": 175, "end_pos": 178, "type": "METRIC", "confidence": 0.9388508796691895}]}]}