{"title": [], "abstractContent": [{"text": "This paper describes a system developed for the Social Media Mining for Health (SMM4H) 2019 shared tasks.", "labels": [], "entities": [{"text": "Social Media Mining for Health (SMM4H) 2019 shared tasks", "start_pos": 48, "end_pos": 104, "type": "TASK", "confidence": 0.7759733958677812}]}, {"text": "Specifically, we participated in three tasks.", "labels": [], "entities": []}, {"text": "The goals of the first two tasks are to classify whether a tweet contains mentions of adverse drug reactions (ADR) and extract these mentions, respectively.", "labels": [], "entities": [{"text": "classify whether a tweet contains mentions of adverse drug reactions (ADR)", "start_pos": 40, "end_pos": 114, "type": "TASK", "confidence": 0.5590263307094574}]}, {"text": "The objective of the third task is to build an end-to-end solution: first, detect ADR mentions and then map these entities to concepts in a controlled vocabulary.", "labels": [], "entities": []}, {"text": "We investigate the use of a language representation model BERT trained to obtain semantic representations of social media texts.", "labels": [], "entities": [{"text": "BERT", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.9207163453102112}]}, {"text": "Our experiments on a dataset of user reviews showed that BERT is superior to state-of-the-art models based on recurrent neural networks.", "labels": [], "entities": [{"text": "BERT", "start_pos": 57, "end_pos": 61, "type": "METRIC", "confidence": 0.99595046043396}]}, {"text": "The BERT-based system for Task 1 obtained an F1 of 57.38%, with improvements up to +7.19% F1 over a score averaged across all 43 submissions.", "labels": [], "entities": [{"text": "BERT-based", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9977545142173767}, {"text": "F1", "start_pos": 45, "end_pos": 47, "type": "METRIC", "confidence": 0.9997573494911194}, {"text": "F1", "start_pos": 90, "end_pos": 92, "type": "METRIC", "confidence": 0.9997377991676331}]}, {"text": "The ensemble of neural networks with a voting scheme for named entity recognition ranked first among 9 teams at the SMM4H 2019 Task 2 and obtained a relaxed F1 of 65.8%.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 57, "end_pos": 81, "type": "TASK", "confidence": 0.6866089900334676}, {"text": "SMM4H 2019 Task 2", "start_pos": 116, "end_pos": 133, "type": "TASK", "confidence": 0.617616280913353}, {"text": "F1", "start_pos": 157, "end_pos": 159, "type": "METRIC", "confidence": 0.9990460276603699}]}, {"text": "The end-to-end model based on BERT for ADR normalization ranked first at the SMM4H 2019 Task 3 and obtained a relaxed F1 of 43.2%.", "labels": [], "entities": [{"text": "BERT", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.9977838397026062}, {"text": "ADR normalization", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.9130813479423523}, {"text": "SMM4H 2019 Task 3", "start_pos": 77, "end_pos": 94, "type": "DATASET", "confidence": 0.6398442387580872}, {"text": "F1", "start_pos": 118, "end_pos": 120, "type": "METRIC", "confidence": 0.9959805011749268}]}], "introductionContent": [{"text": "Short-text communication forms, such as Twitter microblogging, present a wide variety of facts and opinions on numerous topics, and this treasure trove of information is currently severely underexplored.", "labels": [], "entities": []}, {"text": "Here we focus on the problem of discovering adverse drug reaction (ADR) concepts in Twitter messages as part of the Social Media Mining for Health (SMM4H) 2019 shared tasks.", "labels": [], "entities": [{"text": "discovering adverse drug reaction (ADR) concepts in Twitter messages", "start_pos": 32, "end_pos": 100, "type": "TASK", "confidence": 0.7668529803102667}, {"text": "Social Media Mining for Health (SMM4H) 2019 shared tasks", "start_pos": 116, "end_pos": 172, "type": "TASK", "confidence": 0.6467544002966448}]}, {"text": "This work is based on the participation of our team, named KFU NLP, in the first three tasks.", "labels": [], "entities": [{"text": "KFU NLP", "start_pos": 59, "end_pos": 66, "type": "DATASET", "confidence": 0.8992748260498047}]}, {"text": "Organizers of SMM4H 2019 provided participants with datasets of English tweets annotated at the message level with binary annotation indicating the presence or absence of ADRs, text spans of reported ADRs, and their corresponding medical codes from the Medical Dictionary for Regulatory Activities (MedDRA).", "labels": [], "entities": [{"text": "SMM4H 2019", "start_pos": 14, "end_pos": 24, "type": "TASK", "confidence": 0.8892486095428467}]}, {"text": "The goal of Task 1 is to classify the tweets according to the presence of ADRs.", "labels": [], "entities": []}, {"text": "For the second task, named entity recognition (NER) aims to detect the mentions of ADRs.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 21, "end_pos": 51, "type": "TASK", "confidence": 0.7725963741540909}]}, {"text": "The third and final task is designed as an end-toend problem, intended to perform full evaluation of a system operating in real conditions: given a set of raw tweets, the system has to find the tweets that are mentioning ADRs, find the spans of the ADRs, and normalize them with respect to a given knowledge base (KB).", "labels": [], "entities": []}, {"text": "These tasks are especially challenging due to specific characteristics of usergenerated texts from social networks which are noisy, containing misspelled words, abbreviations, emojis, etc.", "labels": [], "entities": []}, {"text": "Motivated by the recent success of deep architectures in general and language representation networks in particular, we explore an application of Bidirectional Encoder Representations from Transformers (BERT) and its extension for biomedical domain BioBERT () to the SMM4H 2019 tasks.", "labels": [], "entities": [{"text": "BERT", "start_pos": 203, "end_pos": 207, "type": "METRIC", "confidence": 0.5889448523521423}, {"text": "SMM4H 2019", "start_pos": 267, "end_pos": 277, "type": "TASK", "confidence": 0.8764378428459167}]}, {"text": "For both ADR extraction and medical concept normalization, we conclude that BERT outperforms previous state-of-the-art baselines based on recurrent neural architectures (RNNs), including bidirectional Long Short-Term Memory (LSTM), and Gated Recurrent Units () paired with word2vec word embeddings.", "labels": [], "entities": [{"text": "ADR extraction", "start_pos": 9, "end_pos": 23, "type": "TASK", "confidence": 0.9775966107845306}, {"text": "medical concept normalization", "start_pos": 28, "end_pos": 57, "type": "TASK", "confidence": 0.6430863738059998}, {"text": "BERT", "start_pos": 76, "end_pos": 80, "type": "METRIC", "confidence": 0.9952104687690735}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we present the task description, machine learning baselines, and classification experiments for Task 1.", "labels": [], "entities": []}, {"text": "We describe our models for end-to-end extraction of ADR concepts in Sections 3 and 4.", "labels": [], "entities": [{"text": "end-to-end extraction of ADR", "start_pos": 27, "end_pos": 55, "type": "TASK", "confidence": 0.7582713216543198}]}, {"text": "Finally, 53 we discuss future directions in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "ADR mentions from the SMM4H 2019 dataset are mapped to Preferred Terms (PTs) of the Medical  Dictionary for Regulatory Activities (MedDRA).", "labels": [], "entities": [{"text": "SMM4H 2019 dataset", "start_pos": 22, "end_pos": 40, "type": "DATASET", "confidence": 0.7299134532610575}]}, {"text": "The training SMM4H 2019 set consists of 1,828 phrases mapped to 489 MedDRA codes.", "labels": [], "entities": [{"text": "training SMM4H 2019 set", "start_pos": 4, "end_pos": 27, "type": "DATASET", "confidence": 0.7275469154119492}]}, {"text": "The average number of ADR mentions mapped to a given concept is 3.74.", "labels": [], "entities": []}, {"text": "The minimum and maximum numbers of queries mapped to a given concept are 1 and 65, respectively.", "labels": [], "entities": []}, {"text": "shows a plot of the code frequency distribution of MedDRA concepts presented in the training set.", "labels": [], "entities": []}, {"text": "Additionally, we present statistics on the top 20 entity mentions from the training set in.", "labels": [], "entities": []}, {"text": "We trained the BERT model for 40 epochs, using batch size 96 and learning rate 5 * 10 \u22125 . In order to prevent neural networks from overfitting, we used a dropout of 0.2 to control the inputs and the softmax layer.", "labels": [], "entities": [{"text": "BERT", "start_pos": 15, "end_pos": 19, "type": "METRIC", "confidence": 0.9883881211280823}, {"text": "learning rate 5", "start_pos": 65, "end_pos": 80, "type": "METRIC", "confidence": 0.9462698896725973}]}, {"text": "We used the publicly available implementation of BERT 5 . The strict and relaxed evaluations proposed for Task 2 were also adopted for Task 3.", "labels": [], "entities": [{"text": "BERT", "start_pos": 49, "end_pos": 53, "type": "METRIC", "confidence": 0.8375701308250427}]}, {"text": "As in previous work, we evaluated our models on the CADEC corpus at the development stage using 5-fold cross-validation.", "labels": [], "entities": [{"text": "CADEC corpus", "start_pos": 52, "end_pos": 64, "type": "DATASET", "confidence": 0.787004679441452}]}, {"text": "The BERT model consistently outperformed attention-based bidirectional LSTM and GRU paired with pre-trained word embeddings in this set of experiments, showing a 6-9% improvement.", "labels": [], "entities": [{"text": "BERT", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.9974437952041626}, {"text": "GRU", "start_pos": 80, "end_pos": 83, "type": "METRIC", "confidence": 0.8547481894493103}]}, {"text": "We did not experiment with BioBERT for this task.", "labels": [], "entities": [{"text": "BioBERT", "start_pos": 27, "end_pos": 34, "type": "METRIC", "confidence": 0.523391842842102}]}, {"text": "For the final submission, we used the two-stage pipeline based on the ensemble of BioBERT-CRF for NER and BERT for normalization.", "labels": [], "entities": [{"text": "BioBERT-CRF", "start_pos": 82, "end_pos": 93, "type": "METRIC", "confidence": 0.9658785462379456}, {"text": "BERT", "start_pos": 106, "end_pos": 110, "type": "METRIC", "confidence": 0.9965674877166748}]}, {"text": "shows a comparison of our best model to the official average scores computed using the participants' submissions.", "labels": [], "entities": []}, {"text": "The end-to-end model ranked first at SMM4H 2019 Task 3 and obtained a relaxed F1 of 43.2%.", "labels": [], "entities": [{"text": "SMM4H 2019 Task 3", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.5595989674329758}, {"text": "F1", "start_pos": 78, "end_pos": 80, "type": "METRIC", "confidence": 0.9675434231758118}]}, {"text": "The strict recall of the endto-end system is 15% lower than the recall of the NER system: 42.7 vs 57.6.", "labels": [], "entities": [{"text": "recall", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.9224095940589905}, {"text": "recall", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.9992519021034241}]}, {"text": "Results in indicate that more than 80% of extracted ADR mentions have been correctly mapped to MedDRA concepts.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Text classification results on the Task 1 test  set.", "labels": [], "entities": [{"text": "Text classification", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.8004484474658966}, {"text": "Task 1 test  set", "start_pos": 45, "end_pos": 61, "type": "DATASET", "confidence": 0.7090909332036972}]}, {"text": " Table 2: The NER results on the Task 2 test set.", "labels": [], "entities": [{"text": "NER", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.7302093505859375}, {"text": "Task 2 test set", "start_pos": 33, "end_pos": 48, "type": "DATASET", "confidence": 0.7172171920537949}]}, {"text": " Table 3: The concept normalization results on the Task  3 test set.", "labels": [], "entities": [{"text": "concept normalization", "start_pos": 14, "end_pos": 35, "type": "TASK", "confidence": 0.6992556005716324}, {"text": "Task  3 test set", "start_pos": 51, "end_pos": 67, "type": "DATASET", "confidence": 0.7085132896900177}]}]}