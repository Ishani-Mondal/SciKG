{"title": [{"text": "Translating Terminologies: A Comparative Examination of NMT and PBSMT Systems", "labels": [], "entities": [{"text": "PBSMT", "start_pos": 64, "end_pos": 69, "type": "DATASET", "confidence": 0.7925712466239929}]}], "abstractContent": [{"text": "Terminology translation is a critical aspect in translation quality assurance, as it requires exact forms not typically expected of conventional translation.", "labels": [], "entities": [{"text": "Terminology translation", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9581971168518066}, {"text": "translation quality assurance", "start_pos": 48, "end_pos": 77, "type": "TASK", "confidence": 0.9035488963127136}]}, {"text": "Recent studies have examined the quality of machine translation, but little work has focused specifically on the translation of terms.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.7473814487457275}]}, {"text": "We present a comparative evaluation of the success of NMT and PBSMT systems in term translation.", "labels": [], "entities": [{"text": "term translation", "start_pos": 79, "end_pos": 95, "type": "TASK", "confidence": 0.7506048381328583}]}, {"text": "We selected eight language pairs among English, French, Ger-man, Finnish, and Romanian, taking into account their diverse language families and resource abundance.", "labels": [], "entities": []}, {"text": "Based on the evaluation of Exact Match (EM) and recall scores, we concluded that NMT, in general , performs better with context, but PB-SMT outperforms when translating without context, and found that significant differences often arise from language nature.", "labels": [], "entities": [{"text": "Exact Match (EM)", "start_pos": 27, "end_pos": 43, "type": "METRIC", "confidence": 0.9508733868598938}, {"text": "recall", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9901817440986633}]}], "introductionContent": [{"text": "Term translation is an important facet of translation quality assurance.", "labels": [], "entities": [{"text": "Term translation", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.9504522383213043}, {"text": "translation quality assurance", "start_pos": 42, "end_pos": 71, "type": "TASK", "confidence": 0.9236119190851847}]}, {"text": "Since terminologies are essential for communication among domain experts, term forms need to be consistent and contextindependent to maintain the integrity of the underlying conceptual system during knowledge exchange.", "labels": [], "entities": []}, {"text": "As such, term banks (collections of cross-lingual, cross-domain terminologies) ensure correct term usage across languages in the translation pipeline of humans.", "labels": [], "entities": []}, {"text": "The rise of machine learning in recent years has, for better or for worse, changed the landscape of translation forever.", "labels": [], "entities": [{"text": "translation", "start_pos": 100, "end_pos": 111, "type": "TASK", "confidence": 0.967287003993988}]}, {"text": "The typical evaluation of machine translation, due to a requirement of fast, automatic metrics during the training phase, typically involves the comparison with a set of human translation in what is calculated as the BLEU or the NIST scores of the translation ().", "labels": [], "entities": [{"text": "machine translation", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.8014297485351562}, {"text": "BLEU", "start_pos": 217, "end_pos": 221, "type": "METRIC", "confidence": 0.9983425140380859}, {"text": "NIST", "start_pos": 229, "end_pos": 233, "type": "DATASET", "confidence": 0.7955113053321838}]}, {"text": "These approaches run counter to widely accepted frameworks of translation quality assurance as the measures do not single out aspects of translation that humans traditionally attach importance.", "labels": [], "entities": [{"text": "translation quality assurance", "start_pos": 62, "end_pos": 91, "type": "TASK", "confidence": 0.9276016553243002}]}, {"text": "Machine translation in general does not produce the exactness in forms required in term translation.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7935294508934021}, {"text": "exactness", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.9511911273002625}, {"text": "term translation", "start_pos": 83, "end_pos": 99, "type": "TASK", "confidence": 0.712448462843895}]}, {"text": "Unlike translation of a text, where target text similar in meanings are equivalent as long as they fulfill the required functions, translated term forms must adhere to term banks (.", "labels": [], "entities": [{"text": "translation of a text", "start_pos": 7, "end_pos": 28, "type": "TASK", "confidence": 0.8856211304664612}]}, {"text": "Machine translation also has implications in terminology building during the human translation process, as it can provide an automatic way to generate and validate the terminology resource that is available to translators).", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7940390408039093}, {"text": "terminology building", "start_pos": 45, "end_pos": 65, "type": "TASK", "confidence": 0.9483756124973297}]}, {"text": "This is why we are also interested in learning how well the machine translation systems perform in term translation without context.", "labels": [], "entities": [{"text": "term translation", "start_pos": 99, "end_pos": 115, "type": "TASK", "confidence": 0.7170640528202057}]}, {"text": "Here we present a comparative evaluation in the effectiveness of machine translation for terminology transfer across multiple languages.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 65, "end_pos": 84, "type": "TASK", "confidence": 0.7476511597633362}, {"text": "terminology transfer", "start_pos": 89, "end_pos": 109, "type": "TASK", "confidence": 0.9146111607551575}]}, {"text": "We investigate language pairs of varying training resource abundance on different machine translation architecture to understand the underlying factors of the effectiveness of terminology translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 82, "end_pos": 101, "type": "TASK", "confidence": 0.7030878961086273}, {"text": "terminology translation", "start_pos": 176, "end_pos": 199, "type": "TASK", "confidence": 0.8911587595939636}]}, {"text": "We test systems with bidirectional translations and validate the terminology equivalence by referring to an established term bank.", "labels": [], "entities": []}], "datasetContent": [{"text": "Several studies examined the effectiveness of neural machine translation and statistical machine translation when applied to general text.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 46, "end_pos": 72, "type": "TASK", "confidence": 0.7167256077130636}, {"text": "statistical machine translation", "start_pos": 77, "end_pos": 108, "type": "TASK", "confidence": 0.6394321719805399}]}, {"text": "Wu et al. in their original paper describing Google's NMT system (2016) observed increased performance compared to their previous public PBSMT system.", "labels": [], "entities": []}, {"text": "conducted a comprehensive study on text translation and found NMT improved performances in multiple metrics as evaluated by humans.", "labels": [], "entities": [{"text": "text translation", "start_pos": 35, "end_pos": 51, "type": "TASK", "confidence": 0.7911596894264221}]}, {"text": "tested both NMT and SMT systems on a lowerresourced language that is Irish and found that a domain-specific SMT system in some cases outperform NMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9348576068878174}, {"text": "SMT", "start_pos": 108, "end_pos": 111, "type": "TASK", "confidence": 0.8344718813896179}]}, {"text": "Muzaffar and Behera, on the other hand, examined translation results in English-Urdu, a relatively resource-poor language pair, and concluded that NMT brings forward better comprehensibility and grammaticality.", "labels": [], "entities": [{"text": "translation", "start_pos": 49, "end_pos": 60, "type": "TASK", "confidence": 0.954616904258728}]}, {"text": "recruited professional translators and found that as a tool for translators, NMT results do not reduce post-editing time compared to PBSMT.", "labels": [], "entities": []}, {"text": "Work on specific genre includes (, which examine NMT vs. PBSMT performances on literary work, and found that NMT significantly increased the readability of the text for human readers.", "labels": [], "entities": []}, {"text": "examined the use of NMT and SMT in the translation of patent documents and concluded that NMT is superior in terms of human evaluations.", "labels": [], "entities": [{"text": "SMT", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.9677695631980896}]}, {"text": "We compare term occurrence in results coming from target text produced from Google's Translation APIs and those from the official, humantranslated target text.", "labels": [], "entities": []}, {"text": "We presume that in cases where the term bank entry is present in the humantranslated or machine-translated sentences, the term use in these cases are validated and considered correct usage.", "labels": [], "entities": []}, {"text": "Rather than using traditional measures of translation quality, in this work, we are mainly concerned with the success of different systems in their adequate reproduction of the relevant terminologies in the target text.", "labels": [], "entities": []}, {"text": "Exact Match (EM) scores is defined as the exact occurrence of the ground truth target terms in the translated target sentence.", "labels": [], "entities": [{"text": "Exact Match (EM) scores", "start_pos": 0, "end_pos": 23, "type": "METRIC", "confidence": 0.9148264427979788}]}, {"text": "2. Recall is defined as the fraction of known target term words that occur in the target text.", "labels": [], "entities": [{"text": "Recall", "start_pos": 3, "end_pos": 9, "type": "METRIC", "confidence": 0.9969550371170044}]}, {"text": "For our evaluation, we do not make a distinction between the infections of terms.", "labels": [], "entities": []}, {"text": "We chose this strict interpretation of exact match as we want to see how well these machine translation systems can fare in creating terminology resources for translators without context, in which case the exact form (including inflections) must be properly transferred across language barriers.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 84, "end_pos": 103, "type": "TASK", "confidence": 0.7215321063995361}]}, {"text": "The same scheme is also applied for with context translation We recognize that, since both MT systems and human translation do not include an annotation as to the exact location of the term translation in the sentence, we are unable to verify the precision of the term translation or the F1 score.", "labels": [], "entities": [{"text": "context translation", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.7136949598789215}, {"text": "MT", "start_pos": 91, "end_pos": 93, "type": "TASK", "confidence": 0.9594729542732239}, {"text": "precision", "start_pos": 247, "end_pos": 256, "type": "METRIC", "confidence": 0.999554455280304}, {"text": "F1 score", "start_pos": 288, "end_pos": 296, "type": "METRIC", "confidence": 0.986904501914978}]}, {"text": "Also, we argue that since terms, unlike most multi-worded expressions, are technical in nature and have specific forms, it is less likely to occur by random in the target sentence and not as a translation, justifying our automated approach to evaluation.", "labels": [], "entities": []}], "tableCaptions": []}