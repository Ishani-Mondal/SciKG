{"title": [{"text": "Towards End-to-End Learning for Efficient Dialogue Agent by Modeling Looking-ahead Ability", "labels": [], "entities": []}], "abstractContent": [{"text": "Learning an efficient manager of dialogue agent from data with little manual intervention is important, especially for goal-oriented dialogues.", "labels": [], "entities": []}, {"text": "However, existing methods either take too many manual efforts (e.g. reinforcement learning methods) or cannot guarantee the dialogue efficiency (e.g. sequence-to-sequence methods).", "labels": [], "entities": []}, {"text": "In this paper, we address this problem by proposing a novel end-to-end learning model to train a dialogue agent that can look ahead for several future turns and generate an optimal response to make the dialogue efficient.", "labels": [], "entities": []}, {"text": "Our method is data-driven and does not require too much manual work for intervention during system design.", "labels": [], "entities": []}, {"text": "We evaluate our method on two datasets of different scenarios and the experimental results demonstrate the efficiency of our model.", "labels": [], "entities": []}], "introductionContent": [{"text": "Research for dialogue system attracts a lot of attentions recently due to its potential huge value of reducing human cost in many commercial domains, such as restaurant reservation), travel planning ( and retail service (.", "labels": [], "entities": [{"text": "restaurant reservation", "start_pos": 158, "end_pos": 180, "type": "TASK", "confidence": 0.7926971614360809}, {"text": "travel planning", "start_pos": 183, "end_pos": 198, "type": "TASK", "confidence": 0.7403033077716827}]}, {"text": "The majority of dialogue agents with goals are expected to be efficient to complete tasks with as few as possible dialogue turns, in contrast with those chitchat counterparts).", "labels": [], "entities": []}, {"text": "The following two examples show the comparison of efficient and inefficient cases respectively.", "labels": [], "entities": []}, {"text": "The senarios is restaurant reservation and the agent's goal is to reserve a table at noon.", "labels": [], "entities": []}, {"text": "Efficient example: \"Human: We don't have empty tables at 11 o'clock tomorrow.", "labels": [], "entities": []}, {"text": "\"Agent: How about 12 o'clock?", "labels": [], "entities": []}, {"text": "We are also okay then.\"", "labels": [], "entities": []}, {"text": "* Xian-Ling Mao is the corresponding author.", "labels": [], "entities": []}, {"text": "Inefficient example: \"Human: We don't have empty tables at 11 o'clock tomorrow.", "labels": [], "entities": []}, {"text": "\"Agent: What else time is available?\"", "labels": [], "entities": []}, {"text": "\"Human: 12 o'clock is ok.\"", "labels": [], "entities": []}, {"text": "\"Agent: All right.", "labels": [], "entities": []}, {"text": "We want that time.\"", "labels": [], "entities": []}, {"text": "For expressing the same opinion, the inefficient example consumes four turns while the efficient example only needs two.", "labels": [], "entities": []}, {"text": "As it can be seen, the efficiency is important for goal-oriented dialogue systems to achieve goals in a rapid way.", "labels": [], "entities": []}, {"text": "Usually, a dialogue system consists of a pipeline of natural language understanding (NLU), dialogue management (DM) and natural language generation (NLG), where the DM part is treat as two separate components: dialogue state tracking (DST) and dialogue control (DC, i.e. dialogue policy selection).", "labels": [], "entities": [{"text": "dialogue management (DM)", "start_pos": 91, "end_pos": 115, "type": "TASK", "confidence": 0.7901831805706024}, {"text": "natural language generation", "start_pos": 120, "end_pos": 147, "type": "TASK", "confidence": 0.7452210386594137}, {"text": "dialogue state tracking (DST)", "start_pos": 210, "end_pos": 239, "type": "TASK", "confidence": 0.7696634232997894}, {"text": "dialogue policy selection)", "start_pos": 271, "end_pos": 297, "type": "TASK", "confidence": 0.719497412443161}]}, {"text": "The DM part is widely considered to be relevant to the dialogue's efficiency, because it makes decisions on what to say for the next turn.", "labels": [], "entities": []}, {"text": "Recently, methods based on reinforcement learning are proposed for the policy selection component to build efficient dialogue systems.", "labels": [], "entities": [{"text": "policy selection", "start_pos": 71, "end_pos": 87, "type": "TASK", "confidence": 0.7566273808479309}]}, {"text": "However, there are some drawbacks of reinforcement learning based methods.", "labels": [], "entities": []}, {"text": "For example, they requires lots of human work to design the learning strategy.", "labels": [], "entities": []}, {"text": "Also a real-world environment which is essential for the agent to learn from is expensive, such as from domain experts.", "labels": [], "entities": []}, {"text": "Moreover, training the dialogue manager as a two separate components could lead to error propagation issue.", "labels": [], "entities": [{"text": "error propagation", "start_pos": 83, "end_pos": 100, "type": "TASK", "confidence": 0.6609900444746017}]}, {"text": "In addition to reinforcement learning based methods, sequence-to-sequence based methods are also popular recently, because they can learn a dialogue agent purely from data and almost without too many human efforts.", "labels": [], "entities": []}, {"text": "The error propagation issue can also be reduced because they are end-to-end, and they have better scalability for different scenarios.", "labels": [], "entities": [{"text": "error propagation", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.6701028794050217}]}, {"text": "However, it is difficult to build efficient dialogue agents by those methods since their objective functions for training models are usually inclined to general responses, such as I don't know, yes and OK, or often generate the same response for totally different contexts because the contextual information is not wellmodeled by those methods.", "labels": [], "entities": []}, {"text": "In this paper, we address the problem of learning an efficient dialogue manager from the perspective of reducing manual intervention and error propagation, and propose anew sequence-tosequence based approach.", "labels": [], "entities": [{"text": "error propagation", "start_pos": 137, "end_pos": 154, "type": "TASK", "confidence": 0.7038018107414246}]}, {"text": "The proposed end-toend model contains a novel looking-ahead module for dialogue manager to learn the looking-ahead ability.", "labels": [], "entities": []}, {"text": "Our intuition is that by predicting the future several dialogue turns, the agent could make a better decision of what to say for current turn, and therefore goals could be sooner achieved in along run.", "labels": [], "entities": []}, {"text": "More specifically, our model includes three modules: (1) encoding module, (2) looking-ahead module, and (3) decoding module.", "labels": [], "entities": []}, {"text": "At each dialogue turn, three kinds of information, the goals, historical utterances and the current user utterance, are utilized.", "labels": [], "entities": []}, {"text": "First they are encoded by three separate Bidirectional Gated Recurrent Units (BiGRU) models.", "labels": [], "entities": []}, {"text": "Then the three encoded embeddings are concatenated to one vector, which is then sent to anew bidirectional neural network that can look ahead for several turns.", "labels": [], "entities": []}, {"text": "The decoding module will generate utterances for each turn through a learned language model.", "labels": [], "entities": []}, {"text": "At last, by considering all the predicted future utterances, anew real system utterance for the next turn is re-generated by using an attention model through the same language model.", "labels": [], "entities": []}, {"text": "Our proposed approach has several advantages.", "labels": [], "entities": []}, {"text": "First, it is an end-to-end model and does not take too many human efforts for system design.", "labels": [], "entities": [{"text": "system design", "start_pos": 78, "end_pos": 91, "type": "TASK", "confidence": 0.7184721529483795}]}, {"text": "Although the goals should be handcrafted for specific scenario, the number of goals is small and it is a relatively easy work.", "labels": [], "entities": []}, {"text": "Moreover, compared with naive sequence-to-sequence based models, our agent can make the dialogue more efficient by modeling the looking-ahead ability.", "labels": [], "entities": []}, {"text": "Experimental results show that our model performs better than baselines on two datasets from different domains, which could suggest that our model is also scalable to various domains.", "labels": [], "entities": []}, {"text": "The contributions in this paper include: \u2022 We identify the problem that how to make dialogues efficient by exploiting as little as possible manual intervention during system design from the perspective of end-to-end deep learning.", "labels": [], "entities": []}, {"text": "\u2022 We propose a novel end-to-end and datadriven model that enables the dialgoue agent to learn to look ahead and make efficient decisions of what to say for the next turn.", "labels": [], "entities": []}, {"text": "\u2022 Experiments conducted on two datasets demonstrate that our model performs better over baselines and can be applied to different domains.", "labels": [], "entities": []}], "datasetContent": [{"text": "Dataset 1 contains crowd-sourced dialogues between humans collected from Amazon Mechanical Turk platform ().", "labels": [], "entities": [{"text": "Amazon Mechanical Turk platform", "start_pos": 73, "end_pos": 104, "type": "DATASET", "confidence": 0.9623426645994186}]}, {"text": "The dataset is for object division task and both sides have separate goals of each object's value.", "labels": [], "entities": [{"text": "object division task", "start_pos": 19, "end_pos": 39, "type": "TASK", "confidence": 0.8189553022384644}]}, {"text": "We use the textual data and transform their goals to yes-no questions as our binary vectors.", "labels": [], "entities": []}, {"text": "The information of each dialogue session's final state, agree or disagree, is used for training the agent.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, there is no other public dataset for goal-oriented dialogues where the two sides have different goals.", "labels": [], "entities": []}, {"text": "To this end, we construct the Dataset 2 to testify the scalability of our model.", "labels": [], "entities": []}, {"text": "The common scenario of restaurant table reservation is chosen.", "labels": [], "entities": [{"text": "restaurant table reservation", "start_pos": 23, "end_pos": 51, "type": "TASK", "confidence": 0.678878923257192}]}, {"text": "In this dataset, the two agents are expected to have different goals and they dialogue with each other for looking for the intersection of their goals.", "labels": [], "entities": []}, {"text": "We denote Agent A as the role of a customer and Agent B as the restaurant server side.", "labels": [], "entities": []}, {"text": "At the beginning of each dialogue session, Agent A is given the available time slot, the number of people, and several other constraints (e.g. can sit at bar or not).", "labels": [], "entities": []}, {"text": "All the constraints are regarded as its goals represented by a binary vector.", "labels": [], "entities": []}, {"text": "Similarly, Agent B has itself constraints (e.g. whether bar tables are available or not), which are also treat as goals represented by a binary vector.", "labels": [], "entities": []}, {"text": "We predefine a pool of 'goals' and at the beginning of each dialogue session, the goals for two sides are randomly sampled separately from the pool.", "labels": [], "entities": []}, {"text": "The two agents cannot see each other's goals and they dialogue through natural language until a final decision, agreement or disagreement, is reached.", "labels": [], "entities": []}, {"text": "In summary, the objective of constructing this dataset is to see if our model can reach the intersection of the two agents' goals in a more efficient way.", "labels": [], "entities": []}, {"text": "To generate dialogues for Dataset 2, we resort to a rule-based method via AI planning search.", "labels": [], "entities": []}, {"text": "Watson AI platform 1 is leveraged for natural language understanding by defining intents and entities with examples.", "labels": [], "entities": [{"text": "Watson AI platform", "start_pos": 0, "end_pos": 18, "type": "DATASET", "confidence": 0.908800999323527}, {"text": "natural language understanding", "start_pos": 38, "end_pos": 68, "type": "TASK", "confidence": 0.6760891576608022}]}, {"text": "A planner is designed for the dialogue manager by defining several states and actions.", "labels": [], "entities": []}, {"text": "The goals are represented as part of the states, and the STRIPS algorithm is used to search the shortest path to goals at each turn and return the first planned action for generating the next response.", "labels": [], "entities": [{"text": "STRIPS", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.8055599927902222}]}, {"text": "Each action has several handcrafted utterances since the diversity of utterances is not our focus in this paper.", "labels": [], "entities": []}, {"text": "Ina dialogue system, it could be treat as efficient if it obtains more final goal achievement with as few as possible dialogue turns.", "labels": [], "entities": []}, {"text": "Thus we set two criteria for evaluating and comparing models adopted in our experiments: (1) the goal achievement ratio that means the ratio of the number of goal achieved dialogue over the number of attempted dialogues), and (2) the average dialogue turns.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistic on the two datasets.", "labels": [], "entities": []}, {"text": " Table 3: Performance on two datasets against the user simulator and human.", "labels": [], "entities": []}]}