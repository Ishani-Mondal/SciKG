{"title": [{"text": "CUNI System for the Building Educational Applications 2019 Shared Task: Grammatical Error Correction", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we describe our systems submitted to the Building Educational Applications (BEA) 2019 Shared Task (Bryant et al., 2019).", "labels": [], "entities": [{"text": "Building Educational Applications (BEA) 2019 Shared Task", "start_pos": 56, "end_pos": 112, "type": "TASK", "confidence": 0.6407224999533759}]}, {"text": "We participated in all three tracks.", "labels": [], "entities": []}, {"text": "Our models are NMT systems based on the Transformer model, which we improve by incorporating several enhancements: applying dropout to whole source and target words, weighting target subwords, averaging model checkpoints, and using the trained model iteratively for correcting the intermediate translations.", "labels": [], "entities": []}, {"text": "The system in the Restricted Track is trained on the provided corpora with oversampled \"cleaner\" sentences and reaches 59.39 F0.5 score on the test set.", "labels": [], "entities": [{"text": "F0.5 score", "start_pos": 125, "end_pos": 135, "type": "METRIC", "confidence": 0.9694128036499023}]}, {"text": "The system in the Low-Resource Track is trained from Wikipedia revision histories and reaches 44.13 F0.5 score.", "labels": [], "entities": [{"text": "F0.5 score", "start_pos": 100, "end_pos": 110, "type": "METRIC", "confidence": 0.9624133408069611}]}, {"text": "Finally, we finetune the system from the Low-Resource Track on restricted data and achieve 64.55 F0.5 score, placing third in the Unrestricted Track.", "labels": [], "entities": [{"text": "F0.5 score", "start_pos": 97, "end_pos": 107, "type": "METRIC", "confidence": 0.9541249871253967}]}], "introductionContent": [{"text": "Starting with the 2013 and 2014 CoNLL Shared Tasks on grammatical error correction (GEC), much progress has been done in this area.", "labels": [], "entities": [{"text": "CoNLL Shared Tasks on grammatical error correction (GEC)", "start_pos": 32, "end_pos": 88, "type": "TASK", "confidence": 0.6336604252457618}]}, {"text": "The need to correct a variety of error types lead most researchers to focus on models based on machine translation) rather than custom designed rule-based models or a combination of single error classifiers.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 95, "end_pos": 114, "type": "TASK", "confidence": 0.706870824098587}]}, {"text": "The machine translation systems turned out to be particularity effective when Junczys-Dowmunt and presented state-of-the-art statistical machine translation system.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.7566625475883484}, {"text": "statistical machine translation", "start_pos": 125, "end_pos": 156, "type": "TASK", "confidence": 0.6322896679242452}]}, {"text": "Currently, models based on statistical and neural machine translation achieve best results: in restricted settings with training limited to certain public training sets (; unrestricted settings with no restrictions on training data; and also in low-resource track where the training data should not come from any annotated corpora (.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 43, "end_pos": 69, "type": "TASK", "confidence": 0.7776217659314474}]}, {"text": "In this paper, we present our models and their results in the restricted, unrestricted, and lowresource tracks.", "labels": [], "entities": []}, {"text": "We start with a description of related work in Section 2.", "labels": [], "entities": []}, {"text": "We then describe our systems together with the implementation details in Section 3.", "labels": [], "entities": []}, {"text": "Section 4 is dedicated to our results and ablation experiments.", "labels": [], "entities": [{"text": "ablation", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9292119741439819}]}, {"text": "Finally, in Section 5 we conclude the paper with some proposals on future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Statistics of available datasets. The error  rate is computed as a ratio of non-matching alignment  edges.", "labels": [], "entities": [{"text": "error  rate", "start_pos": 48, "end_pos": 59, "type": "METRIC", "confidence": 0.9785332679748535}]}, {"text": " Table 2: Official shared task F 0.5 scores on the test set.", "labels": [], "entities": []}, {"text": " Table 3: Development combined F 0.5 score of incremental improvements of our system.", "labels": [], "entities": [{"text": "F 0.5 score", "start_pos": 31, "end_pos": 42, "type": "METRIC", "confidence": 0.9779800971349081}]}, {"text": " Table 4: The effect of source word dropout, target word  dropout, and MLE weight on development combined  F 0.5 score.", "labels": [], "entities": [{"text": "MLE weight", "start_pos": 71, "end_pos": 81, "type": "METRIC", "confidence": 0.974702924489975}, {"text": "F 0.5 score", "start_pos": 107, "end_pos": 118, "type": "METRIC", "confidence": 0.9803774356842041}]}, {"text": " Table 5: Maximum development combined F 0.5 score  achieved by averaging the given number of check- points.", "labels": [], "entities": [{"text": "F 0.5 score", "start_pos": 39, "end_pos": 50, "type": "METRIC", "confidence": 0.9864555795987447}]}, {"text": " Table 6: Development combined F 0.5 score achieved  with different models in the Low-Resource Track.", "labels": [], "entities": [{"text": "F 0.5 score", "start_pos": 31, "end_pos": 42, "type": "METRIC", "confidence": 0.9867052634557089}]}]}