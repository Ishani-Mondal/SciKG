{"title": [], "abstractContent": [{"text": "In this paper, we propose a novel model called Adversarial Multi-Task Network (AMTN) for jointly modeling Recognizing Question Entailment (RQE) and medical Question Answering (QA) tasks.", "labels": [], "entities": [{"text": "Recognizing Question Entailment (RQE) and medical Question Answering (QA) tasks", "start_pos": 106, "end_pos": 185, "type": "TASK", "confidence": 0.7310341319867543}]}, {"text": "AMTN utilizes a pre-trained BioBERT model and an Interactive Transformer to learn the shared semantic representations across different task through parameter sharing mechanism.", "labels": [], "entities": [{"text": "AMTN", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7842844724655151}]}, {"text": "Meanwhile, an adversarial training strategy is introduced to separate the private features of each task from the shared representations.", "labels": [], "entities": []}, {"text": "Experiments on BioNLP 2019 RQE and QA shared task datasets show that our model benefits from the shared representations of both tasks provided by multi-task learning and adversarial training, and obtains significant improvements upon the single-task models.", "labels": [], "entities": [{"text": "BioNLP 2019 RQE", "start_pos": 15, "end_pos": 30, "type": "DATASET", "confidence": 0.8175233205159506}, {"text": "QA shared task datasets", "start_pos": 35, "end_pos": 58, "type": "DATASET", "confidence": 0.7590892612934113}]}], "introductionContent": [{"text": "With the rapid development of Internet and medical care, online health queries are increasing at a high rate.", "labels": [], "entities": []}, {"text": "In 2012, 59% of U.S. adults looked for health information online . However, it is always difficult for search engines to return relevant and trustworthy health information every time if the symptoms are not accurately described (.", "labels": [], "entities": []}, {"text": "Therefore, many websites provide online doctor consultation services, which can answer questions or give advice from doctors or experts to the customers.", "labels": [], "entities": []}, {"text": "Unfortunately, manually answering some simple queries or answering similar questions multiple times is quite time-consuming and wasteful.", "labels": [], "entities": []}, {"text": "A Question Answering (QA) system that can automatically understand and answer the healthcare questions asked by customers is urgently needed.", "labels": [], "entities": [{"text": "Question Answering (QA)", "start_pos": 2, "end_pos": 25, "type": "TASK", "confidence": 0.8123127222061157}]}, {"text": "To this end, BioNLP 2019 () provides a series of challenging shared tasks, including: (1) Natural Language Inference (NLI) in the clinical domain; (2) Recognizing Question Entailment (RQE); (3) medical Question Answering (QA).", "labels": [], "entities": [{"text": "BioNLP 2019", "start_pos": 13, "end_pos": 24, "type": "DATASET", "confidence": 0.7683349251747131}, {"text": "Recognizing Question Entailment (RQE)", "start_pos": 151, "end_pos": 188, "type": "TASK", "confidence": 0.7866955200831095}, {"text": "medical Question Answering (QA)", "start_pos": 194, "end_pos": 225, "type": "TASK", "confidence": 0.7151885430018107}]}, {"text": "This paper mainly focuses on RQE and QA task.", "labels": [], "entities": [{"text": "RQE", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.7408099174499512}, {"text": "QA task", "start_pos": 37, "end_pos": 44, "type": "TASK", "confidence": 0.7704673111438751}]}, {"text": "RQE task aims at identifying entailment relation between two questions in the context of QA (, which can be represented as \"a question Q1 entails a question Q2 if every answer to Q2 is also a complete or partial answer to Q1\".", "labels": [], "entities": []}, {"text": "QA task aims at automatically filtering and improving the ranking of automatically retrieved answers (.", "labels": [], "entities": []}, {"text": "There are two targets for QA: (1) determining whether the given sentence could answer the given question; (2) ranking all the right answers according to their relevance to the question.", "labels": [], "entities": [{"text": "QA", "start_pos": 26, "end_pos": 28, "type": "TASK", "confidence": 0.9009661078453064}]}, {"text": "Neural networks and deep learning (DL) currently provide the best solutions for RQE and QA tasks.", "labels": [], "entities": []}, {"text": "Among various neural networks, such as traditional Convolutional Neural Networks (CNN) ( and Long Short-Term Memory (LSTM) networks),) has demonstrated superiority in multiple", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments are conducted on the BioNLP RQE and QA shared tasks.", "labels": [], "entities": [{"text": "BioNLP RQE and QA shared tasks", "start_pos": 37, "end_pos": 67, "type": "DATASET", "confidence": 0.7129441797733307}]}, {"text": "The QA dataset contains a total of 3042 question-answer pairs: 1701 for training, 234 for validation, and 1107 for test.", "labels": [], "entities": [{"text": "QA dataset", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.8902591168880463}]}, {"text": "The RQE dataset contains a total of 9120 question pairs: 8588 for training, 302 for validation, and 230 for test.", "labels": [], "entities": [{"text": "RQE dataset", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.9197621047496796}]}, {"text": "The statistic of the two datasets are shown in.", "labels": [], "entities": []}, {"text": "In the shared encoder module, we use the pretrained uncased BioBERTbase 3 for computational complexity considerations.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistic of sentence pairs in RQE and  QA datasets.", "labels": [], "entities": [{"text": "Statistic of sentence pairs", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.810120165348053}, {"text": "RQE and  QA datasets", "start_pos": 41, "end_pos": 61, "type": "DATASET", "confidence": 0.6739504709839821}]}, {"text": " Table 3. From the  table, we can see that single-task learning  achieves the worst results, which is probably due  to the simple model architecture. For the three  methods using different dataset in Single-task  learning, STN (QA+RQE) performs better than", "labels": [], "entities": []}, {"text": " Table 3: Effects of multi-task learning strategy. All the results are reported by accuracy (%). STN (QA),  STN (RQE) and STN (QA+RQE) represent STN trained on QA dataset, QRE dataset and both datasets,  respectively.   \u2020 indicates our submission results.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9990159273147583}, {"text": "QA dataset", "start_pos": 160, "end_pos": 170, "type": "DATASET", "confidence": 0.7754696309566498}, {"text": "QRE dataset", "start_pos": 172, "end_pos": 183, "type": "DATASET", "confidence": 0.8337804079055786}]}, {"text": " Table 4: Effects of adversarial multi-task learning strategy. All the results are reported by accuracy (%).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9995753169059753}]}, {"text": " Table 5: Effects of shared encoder. All the results  are reported by accuracy (%). Bold font indicates  the best performance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9993705153465271}]}]}