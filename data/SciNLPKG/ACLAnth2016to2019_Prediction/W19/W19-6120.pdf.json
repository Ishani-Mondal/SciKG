{"title": [], "abstractContent": [{"text": "Sentiment analysis has become very popular in both research and business due to the vast amount of opinionated text currently produced by Internet users.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9636620581150055}]}, {"text": "Standard sentiment analysis deals with classifying the overall sentiment of a text, but this doesn't include other important information such as towards which entity, topic or aspect within the text the sentiment is directed.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 9, "end_pos": 27, "type": "TASK", "confidence": 0.8666155636310577}]}, {"text": "Aspect-based sentiment analysis (ABSA) is a more complex task that consists in identifying both sentiments and aspects.", "labels": [], "entities": [{"text": "Aspect-based sentiment analysis (ABSA)", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.8365419805049896}]}, {"text": "This paper shows the potential of using the contextual word representations from the pre-trained language model BERT, together with a fine-tuning method with additional generated text, in order to solve out-of-domain ABSA and outperform previous state-of-the-art results on SemEval-2015 (task 12, subtask 2) and SemEval-2016 (task 5).", "labels": [], "entities": [{"text": "BERT", "start_pos": 112, "end_pos": 116, "type": "METRIC", "confidence": 0.9778438806533813}, {"text": "solve out-of-domain ABSA", "start_pos": 197, "end_pos": 221, "type": "TASK", "confidence": 0.6112293203671774}]}, {"text": "To the best of our knowledge , no other existing work has been done on out-of-domain ABSA for aspect classification.", "labels": [], "entities": [{"text": "ABSA", "start_pos": 85, "end_pos": 89, "type": "TASK", "confidence": 0.8146035075187683}, {"text": "aspect classification", "start_pos": 94, "end_pos": 115, "type": "TASK", "confidence": 0.917751669883728}]}], "introductionContent": [{"text": "Sentiment analysis, also known as opinion mining, is afield within natural language processing (NLP) that consists in automatically identifying the sentiment of a text, often in categories like negative, neutral and positive.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8994528949260712}, {"text": "opinion mining", "start_pos": 34, "end_pos": 48, "type": "TASK", "confidence": 0.7160130590200424}, {"text": "natural language processing (NLP)", "start_pos": 67, "end_pos": 100, "type": "TASK", "confidence": 0.7354945540428162}]}, {"text": "It has become a very popular field in both research and industry due to the large and increasing amount of opinionated usergenerated text in the Internet, for instance social media and product reviews.", "labels": [], "entities": []}, {"text": "Knowing how users feel or think about a certain brand, product, idea or topic is a valuable source of information for companies, organizations and researchers, but it can be a challenging task.", "labels": [], "entities": [{"text": "Knowing how users feel or think about a certain brand, product, idea or topic", "start_pos": 0, "end_pos": 77, "type": "TASK", "confidence": 0.6125461086630821}]}, {"text": "Natural language often contains ambiguity and figurative expressions that make the automated extraction of information in general very complex.", "labels": [], "entities": []}, {"text": "Traditional sentiment analysis focuses on classifying the overall sentiment expressed in a text without specifying what the sentiment is about.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.892096072435379}, {"text": "classifying the overall sentiment expressed in a text", "start_pos": 42, "end_pos": 95, "type": "TASK", "confidence": 0.7367330938577652}]}, {"text": "This may not be enough if the text is simultaneously referring to different topics or entities (also known as aspects), possibly expressing different sentiments towards different aspects.", "labels": [], "entities": []}, {"text": "Identifying sentiments associated to specific aspects in a text is a more complex task known as aspect-based sentiment analysis (ABSA).", "labels": [], "entities": [{"text": "Identifying sentiments associated to specific aspects in a text", "start_pos": 0, "end_pos": 63, "type": "TASK", "confidence": 0.8202503191100227}, {"text": "aspect-based sentiment analysis (ABSA)", "start_pos": 96, "end_pos": 134, "type": "TASK", "confidence": 0.8057369689146677}]}, {"text": "ABSA as a research topic gained special traction during) workshop, where it was first introduced as Task 4 and reappeared in the and workshops.", "labels": [], "entities": [{"text": "ABSA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.5978779196739197}]}, {"text": "In parallel, within NLP, there have been numerous developments in the field of pre-trained language models, for example ELMo () and BERT).", "labels": [], "entities": [{"text": "BERT", "start_pos": 132, "end_pos": 136, "type": "METRIC", "confidence": 0.9841282963752747}]}, {"text": "These language models are pre-trained on large amounts of unannotated text, and their use has shown to allow better performance with a reduced requirement for labeled data and also much faster training.", "labels": [], "entities": []}, {"text": "At SemEval-2016, there were no submissions that used such pre-trained language model as abase for the ABSA tasks.", "labels": [], "entities": [{"text": "ABSA tasks", "start_pos": 102, "end_pos": 112, "type": "TASK", "confidence": 0.8727136850357056}]}, {"text": "For this paper we will use BERT as the base model to improve ABSA models for the unconstrained evaluation, which permits using additional resources such as external training data, due to the pre-training of the base language model.", "labels": [], "entities": [{"text": "BERT", "start_pos": 27, "end_pos": 31, "type": "METRIC", "confidence": 0.9950664043426514}, {"text": "ABSA", "start_pos": 61, "end_pos": 65, "type": "TASK", "confidence": 0.8445711135864258}]}, {"text": "More precisely, the contributions of this paper are as follows: \u2022 It proposes the new ABSA task for out-ofdomain classification at both sentence and text levels.", "labels": [], "entities": [{"text": "ABSA task", "start_pos": 86, "end_pos": 95, "type": "TASK", "confidence": 0.8240245878696442}, {"text": "out-ofdomain classification", "start_pos": 100, "end_pos": 127, "type": "TASK", "confidence": 0.6699547469615936}]}, {"text": "\u2022 To solve this task, a general classifier model is proposed, which uses the pre-trained language model BERT as the base for the contextual word representations.", "labels": [], "entities": [{"text": "BERT", "start_pos": 104, "end_pos": 108, "type": "METRIC", "confidence": 0.9893825054168701}]}, {"text": "It makes use of the sentence pair classification model) to find semantic similarities between a text and an aspect.", "labels": [], "entities": [{"text": "sentence pair classification", "start_pos": 20, "end_pos": 48, "type": "TASK", "confidence": 0.6368241707483927}]}, {"text": "This method outperforms all of the previous submissions, except for one in SemEval-2016.", "labels": [], "entities": []}, {"text": "\u2022 It proposes a combined model, which uses only one sentence pair classifier model from BERT to solve both aspect classification and sentiment classification simultaneously.", "labels": [], "entities": [{"text": "BERT", "start_pos": 88, "end_pos": 92, "type": "METRIC", "confidence": 0.7236247062683105}, {"text": "aspect classification", "start_pos": 107, "end_pos": 128, "type": "TASK", "confidence": 0.7159728854894638}, {"text": "sentiment classification", "start_pos": 133, "end_pos": 157, "type": "TASK", "confidence": 0.8703028857707977}]}], "datasetContent": [{"text": "The models implemented in this paper are three: an aspect classification model, a sentiment polarity classification model, and a combined model for both aspect and sentiment classification.", "labels": [], "entities": [{"text": "aspect classification", "start_pos": 51, "end_pos": 72, "type": "TASK", "confidence": 0.6869748532772064}, {"text": "sentiment polarity classification", "start_pos": 82, "end_pos": 115, "type": "TASK", "confidence": 0.7283141116301218}, {"text": "sentiment classification", "start_pos": 164, "end_pos": 188, "type": "TASK", "confidence": 0.7573893368244171}]}, {"text": "The aspect classification model, described in Section 3.4, uses sentence pair classification from BERT (.", "labels": [], "entities": [{"text": "aspect classification", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.8365399241447449}, {"text": "sentence pair classification", "start_pos": 64, "end_pos": 92, "type": "TASK", "confidence": 0.6891667942206064}, {"text": "BERT", "start_pos": 98, "end_pos": 102, "type": "METRIC", "confidence": 0.9466126561164856}]}, {"text": "As it only predicts whether an aspect is related to a text or not, this model has the possibility to be used for out-of-scope aspects.", "labels": [], "entities": []}, {"text": "The sentiment polarity classifier, described in Section 3.3, is a classification model that is trained to determine the sentiment labels (positive, negative, neutral, conflict) fora given aspect and text input.", "labels": [], "entities": [{"text": "sentiment polarity classifier", "start_pos": 4, "end_pos": 33, "type": "TASK", "confidence": 0.7793464859326681}]}, {"text": "Finally, Section 3.5 explains the last model, which is a combination of both the sentiment and aspect classification models.", "labels": [], "entities": [{"text": "sentiment and aspect classification", "start_pos": 81, "end_pos": 116, "type": "TASK", "confidence": 0.653046265244484}]}, {"text": "It outputs a sentiment if the aspect is related, and otherwise it returns the unrelated label.", "labels": [], "entities": []}, {"text": "The evaluation is based on the SemEval-2016 Task 5, more specifically the subtasks: aspect categorization in subtask 1 & 2, slot 1 and sentiment polarity in subtask 1 & 2, slot 3.", "labels": [], "entities": [{"text": "SemEval-2016 Task 5", "start_pos": 31, "end_pos": 50, "type": "DATASET", "confidence": 0.6829186876614889}]}, {"text": "The results for each model implemented are presented in the tables in, with the previous state-ofthe-art models as baseline.", "labels": [], "entities": []}, {"text": "The Aspect Category Classifier, the Sentiment Classifier, and the Combined Classifier, have all been trained on each dataset described in Table 1.", "labels": [], "entities": []}, {"text": "This results in 18 models, where each of these models have been tested on every dataset described in.", "labels": [], "entities": []}, {"text": "However, the text-level Hotel dataset was generated by concatenating all the sentence-level input to a full text and labelling the text with all the aspects corresponding to the sentences, because the Hotel dataset only consisted of the sentence level.", "labels": [], "entities": [{"text": "Hotel dataset", "start_pos": 201, "end_pos": 214, "type": "DATASET", "confidence": 0.7964513897895813}]}, {"text": "For the results in the tables of this section, we only show the best performing model for model type, in-domain, out-of-domain, text-level and sentence-level model.", "labels": [], "entities": []}, {"text": "The dataset in which these models has been tested on can be found in the description of the tables.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Distribution of data in each training dataset.", "labels": [], "entities": []}, {"text": " Table 2: Best performance of aspect category clas- sifiers in sentence-level datasets", "labels": [], "entities": []}, {"text": " Table 3: Best performance of aspect category clas- sifiers in text-level datasets", "labels": [], "entities": []}, {"text": " Table 4: Best performance of sentiment classifiers  in sentence-level datasets", "labels": [], "entities": [{"text": "sentiment classifiers", "start_pos": 30, "end_pos": 51, "type": "TASK", "confidence": 0.8045943081378937}]}, {"text": " Table 5: Best performance of sentiment classifiers  in text-level datasets", "labels": [], "entities": [{"text": "sentiment classifiers", "start_pos": 30, "end_pos": 51, "type": "TASK", "confidence": 0.789961963891983}]}, {"text": " Table 6: Data distribution in test datasets.", "labels": [], "entities": [{"text": "Data distribution", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.6527728140354156}]}]}