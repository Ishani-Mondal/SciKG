{"title": [{"text": "Challenges and frontiers in abusive content detection", "labels": [], "entities": []}], "abstractContent": [{"text": "Online abusive content detection is an inherently difficult task.", "labels": [], "entities": [{"text": "Online abusive content detection", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6848731935024261}]}, {"text": "It has received considerable attention from academia, particularly within the computational linguistics community, and performance appears to have improved as the field has matured.", "labels": [], "entities": []}, {"text": "However, considerable challenges and unaddressed frontiers remain, spanning technical, social and ethical dimensions.", "labels": [], "entities": []}, {"text": "These issues constrain the performance, efficiency and generalizability of abusive content detection systems.", "labels": [], "entities": []}, {"text": "In this article we delineate and clarify the main challenges and frontiers in the field, critically evaluate their implications and discuss solutions.", "labels": [], "entities": []}, {"text": "We also highlight ways in which social scientific insights can advance research.", "labels": [], "entities": []}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "First, we outline three reasons why, from a research perspective, abusive content detection poses such a challenge (Section 2).", "labels": [], "entities": [{"text": "abusive content detection", "start_pos": 66, "end_pos": 91, "type": "TASK", "confidence": 0.6487830976645151}]}, {"text": "Second, we identify challenges facing", "labels": [], "entities": []}], "introductionContent": [{"text": "Developing robust systems to detect abuse is a crucial part of online content moderation and plays a fundamental role in creating an open, safe and accessible Internet.", "labels": [], "entities": [{"text": "online content moderation", "start_pos": 63, "end_pos": 88, "type": "TASK", "confidence": 0.6768896778424581}]}, {"text": "It is of growing interest to both host platforms and regulators, in light of recent public pressure.", "labels": [], "entities": []}, {"text": "Detection systems are also important for social scientific analyses, such as understanding the temporal and geographic dynamics of abuse.", "labels": [], "entities": []}, {"text": "Advances in machine learning and NLP have led to marked improvements in abusive content detection systems' performance.", "labels": [], "entities": [{"text": "abusive content detection", "start_pos": 72, "end_pos": 97, "type": "TASK", "confidence": 0.6734162469704946}]}, {"text": "For instance, in 2018 Pitsilis et al. trained a classification system on Waseem and Hovy's 16,000 tweet dataset and achieved an F-Score of 0.932, compared against Waseem and Hovy's original 0.739; a 20-point increase.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 128, "end_pos": 135, "type": "METRIC", "confidence": 0.9992865920066833}]}, {"text": "Key innovations include the use of deep learning and ensemble architectures, using contextual word embeddings, applying dependency parsing, and the inclusion of user-level variables within models.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 120, "end_pos": 138, "type": "TASK", "confidence": 0.773292750120163}]}, {"text": "Researchers have also addressed numerous tasks beyond binary abusive content classification, including identifying the target of abuse and its strength as well as automatically moderating content.", "labels": [], "entities": [{"text": "binary abusive content classification", "start_pos": 54, "end_pos": 91, "type": "TASK", "confidence": 0.6598207652568817}]}, {"text": "However, considerable challenges and unaddressed frontiers remain, spanning technical, social and ethical dimensions.", "labels": [], "entities": []}, {"text": "These issues constrain abusive content detection research, limiting its impact on the development of real-world detection systems.", "labels": [], "entities": [{"text": "content detection research", "start_pos": 31, "end_pos": 57, "type": "TASK", "confidence": 0.7564891080061594}]}, {"text": "We offer critical insights into the challenges and frontiers facing the use of computational methods to detect abusive content.", "labels": [], "entities": []}, {"text": "We differ from most previous research by taking an interdisciplinary approach, routed in both the computational and social sciences.", "labels": [], "entities": []}, {"text": "Broadly, we advocate that social science should be used in a complementary way to advance research in this field.", "labels": [], "entities": []}, {"text": "We also highlight the lack of support given to researchers and provide guidelines for working with abusive content.", "labels": [], "entities": []}, {"text": "the abusive content detection research community (Section 3).", "labels": [], "entities": [{"text": "abusive content detection research", "start_pos": 4, "end_pos": 38, "type": "TASK", "confidence": 0.6947076171636581}]}, {"text": "Third, we identify research frontiers; un-and under-addressed areas which would benefit from further investigation (Section 4).", "labels": [], "entities": []}], "datasetContent": [{"text": "Creating appropriate datasets for training hate detection systems is a crucial but time-consuming task (.", "labels": [], "entities": [{"text": "hate detection", "start_pos": 43, "end_pos": 57, "type": "TASK", "confidence": 0.826522558927536}]}, {"text": "Currently available datasets have several limitations.", "labels": [], "entities": []}, {"text": "With many datasets, including those from Twitter, content cannot be shared directly but, instead, IDs are shared and the dataset recreated each time.", "labels": [], "entities": []}, {"text": "This can lead to considerable degradations in the quality of datasets overtime.", "labels": [], "entities": []}, {"text": "For instance, Founta et al. shared a dataset of 80,000 tweets but soon after this was reduced to 70,000.", "labels": [], "entities": []}, {"text": "This not only decreases the quantity of data, reducing variety, but also the class distribution changes.", "labels": [], "entities": [{"text": "variety", "start_pos": 55, "end_pos": 62, "type": "METRIC", "confidence": 0.9872437119483948}]}, {"text": "This makes it difficult to compare performance of different models on even one dataset.", "labels": [], "entities": []}, {"text": "To address this issue, we encourage more collaborations with online platforms to make datasets available.", "labels": [], "entities": []}, {"text": "A successful example of this is Twitter's release of the IRA disinformation dataset.", "labels": [], "entities": [{"text": "IRA disinformation dataset", "start_pos": 57, "end_pos": 83, "type": "DATASET", "confidence": 0.9669845302899679}]}, {"text": "Annotation is a notoriously difficult task, reflected in the low levels of inter-annotator agreement reported by most publications, particularly on more complex multi-class tasks.", "labels": [], "entities": []}, {"text": "Noticeably, van Aken suggests that Davidson et al.'s widely used hate and offensive language dataset has up to 10% of its data mislabeled.", "labels": [], "entities": []}, {"text": "Few publications provide details of their annotation processor annotation guidelines.", "labels": [], "entities": []}, {"text": "Providing such information is the norm in social scientific research and is viewed as an integral part of verifying others' findings and robustness.", "labels": [], "entities": []}, {"text": "In line with the recommendations of Sabou et al., we advocate that annotation guidelines and processes are shared where possible and that the field also works to develop best practices.", "labels": [], "entities": []}, {"text": "The quality, size and class balance of datasets varies considerably.", "labels": [], "entities": []}, {"text": "Understanding the decisions behind dataset creation is crucial for identifying the biases and limitations of systems trained on them.", "labels": [], "entities": []}, {"text": "When creating datasets, researchers need to weigh up ensuring there are sufficient instances of abuse (by biased sampling through e.g. using abusive keywords) with making sure the variety of nonabusive content is great enough for the system to be applied in 'the wild' and avoid overfitting.", "labels": [], "entities": []}, {"text": "Wiegand et al. measure the impact of biased sampling on several widely used datasets).", "labels": [], "entities": []}, {"text": "They find it can lead to confounding whereby non-abusive terms serve as signals for identifying abuse as they are highly correlated -but such signals are unlikely to exist in the real world.", "labels": [], "entities": []}, {"text": "To enable greater research transparency, sampling methods should always be reported in accessible dataset documentation.", "labels": [], "entities": []}, {"text": "At present, the main goal of biased sampling is to increase the incidence of abusive content.", "labels": [], "entities": []}, {"text": "We propose that this should be adjusted to focus on dataset variety.", "labels": [], "entities": []}, {"text": "Datasets could be curated to include linguistically difficult instances, as well as 'edge cases': content which is non-abusive but very similar to abuse.", "labels": [], "entities": []}, {"text": "Three examples are: 1.", "labels": [], "entities": []}, {"text": "Most detection systems use the existence of profanities (also known as 'obscenities') as an input feature.", "labels": [], "entities": []}, {"text": "However, profanities are not inherently abusive and can be used to express other emotions.", "labels": [], "entities": []}, {"text": "Content which reports/comments on the abuse of others or aims to challenge/counter such abuse.", "labels": [], "entities": []}, {"text": "3. Same topic but non-abusive.", "labels": [], "entities": []}, {"text": "Content which is on the same topic as the abusive content but is non-abusive.", "labels": [], "entities": []}, {"text": "For instance, if the classification system detects xenophobia, then a suitable edge case is non-abusive content about foreigners.", "labels": [], "entities": []}], "tableCaptions": []}