{"title": [{"text": "Naver Labs Europe's Systems for the WMT19 Machine Translation Robustness Task", "labels": [], "entities": [{"text": "WMT19 Machine Translation Robustness", "start_pos": 36, "end_pos": 72, "type": "TASK", "confidence": 0.8352378606796265}]}], "abstractContent": [{"text": "This paper describes the systems that we submitted to the WMT19 Machine Translation robustness task.", "labels": [], "entities": [{"text": "WMT19 Machine Translation robustness task", "start_pos": 58, "end_pos": 99, "type": "TASK", "confidence": 0.8570329904556274}]}, {"text": "This task aims to improve MT's robustness to noise found on social media , like informal language, spelling mistakes and other orthographic variations.", "labels": [], "entities": [{"text": "MT", "start_pos": 26, "end_pos": 28, "type": "TASK", "confidence": 0.9958048462867737}]}, {"text": "The organizers provide parallel data extracted from asocial media website 1 in two language pairs: French-English and Japanese-English (in both translation directions).", "labels": [], "entities": []}, {"text": "The goal is to obtain the best scores on unseen test sets from the same source, according to automatic met-rics (BLEU) and human evaluation.", "labels": [], "entities": [{"text": "automatic met-rics (BLEU)", "start_pos": 93, "end_pos": 118, "type": "METRIC", "confidence": 0.7577842235565185}]}, {"text": "We proposed one single and one ensemble system for each translation direction.", "labels": [], "entities": []}, {"text": "Our ensemble models ranked first in all language pairs, according to BLEU evaluation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.9901362061500549}]}, {"text": "We discuss the pre-processing choices that we made, and present our solutions for robustness to noise and domain adaptation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 106, "end_pos": 123, "type": "TASK", "confidence": 0.739176332950592}]}], "introductionContent": [{"text": "Neural Machine Translation (NMT) has achieved impressive results in recent years, especially on high-resource language pairs (, and has even lead to some claims of human parity).", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8654170334339142}]}, {"text": "However, show that NMT is brittle, and very sensitive to simple character-level perturbations like letter swaps or keyboard typos.", "labels": [], "entities": []}, {"text": "They show that one can make an MT system more robust to these types of synthetic noise, by introducing similar noise on the source side of the training corpus.", "labels": [], "entities": [{"text": "MT", "start_pos": 31, "end_pos": 33, "type": "TASK", "confidence": 0.9864377975463867}]}, {"text": "do similar data augmentation, but at the word level and so as to make an MT model more robust to Automatic Speech Recognition errors (within a speech translation pipeline).", "labels": [], "entities": [{"text": "MT", "start_pos": 73, "end_pos": 75, "type": "TASK", "confidence": 0.9489688873291016}, {"text": "Automatic Speech Recognition", "start_pos": 97, "end_pos": 125, "type": "TASK", "confidence": 0.5644568502902985}]}, {"text": "propose an adversarial training approach https://www.reddit.com 2 These claims were discussed at WMT by to make an encoder invariant to word-level noise.", "labels": [], "entities": [{"text": "WMT", "start_pos": 97, "end_pos": 100, "type": "DATASET", "confidence": 0.8379813432693481}]}, {"text": "propose to inject aggressive synthetic noise on the source side of training corpora (with random char-level operations: deletion, insertion, substitution and swap), and show that this is helpful to deal with natural errors found in Wikipedia edit logs, in several language pairs.", "labels": [], "entities": []}, {"text": "release MTNT, a real-world noisy corpus, to help researchers develop MT systems that are robust to natural noise found on social media.", "labels": [], "entities": [{"text": "MT", "start_pos": 69, "end_pos": 71, "type": "TASK", "confidence": 0.9673530459403992}]}, {"text": "The same authors coorganized this task (, in which MTNT is the primary resource.", "labels": [], "entities": [{"text": "MTNT", "start_pos": 51, "end_pos": 55, "type": "DATASET", "confidence": 0.7176992297172546}]}, {"text": "show that back-translation (with a model trained on MTNT) and synthetic noise (that emulates errors found in MTNT) are useful to make NMT models more robust to MTNT noise.", "labels": [], "entities": []}, {"text": "This task aims at improving MT's robustness to noise found on social media, like informal language, spelling mistakes and other orthographic variations.", "labels": [], "entities": [{"text": "MT", "start_pos": 28, "end_pos": 30, "type": "TASK", "confidence": 0.9965433478355408}]}, {"text": "We present the task in more detail in Section 2.", "labels": [], "entities": []}, {"text": "Then, we describe our baseline models and pre-processing in Section 3.", "labels": [], "entities": []}, {"text": "We extend these baseline models with robustness and domain adaptation techniques that are presented in Section 4.", "labels": [], "entities": []}, {"text": "Finally, in Section 5, we present and discuss the results of our systems on this task.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Size of the MTNT training corpora. Word  counts by Moses (fr/en) and Kytea (ja) tokenizers.", "labels": [], "entities": [{"text": "MTNT training", "start_pos": 22, "end_pos": 35, "type": "TASK", "confidence": 0.7968223392963409}]}, {"text": " Table 2: Size of the authorized out-of-domain parallel  corpora in constrained submissions.", "labels": [], "entities": []}, {"text": " Table 3: Authorized monolingual data.", "labels": [], "entities": []}, {"text": " Table 4: Number of hallucinations and French- language outputs (according to langid.py) when  translating MTNT-test (FR\u2192EN). LID: language iden- tifier, Len: length filtering, CC: training data includes  CommonCrawl, Att: attention-based filtering.", "labels": [], "entities": [{"text": "MTNT-test", "start_pos": 107, "end_pos": 116, "type": "DATASET", "confidence": 0.490918904542923}, {"text": "LID", "start_pos": 126, "end_pos": 129, "type": "METRIC", "confidence": 0.9493376016616821}, {"text": "CommonCrawl", "start_pos": 205, "end_pos": 216, "type": "DATASET", "confidence": 0.9404711723327637}, {"text": "Att", "start_pos": 218, "end_pos": 221, "type": "METRIC", "confidence": 0.9508277177810669}]}, {"text": " Table 6: BLEU scores of the JA\u2192EN models on  MTNT-test, MTNT-valid and MTNT-blind.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9995056390762329}, {"text": "MTNT-test", "start_pos": 46, "end_pos": 55, "type": "DATASET", "confidence": 0.7724711298942566}, {"text": "MTNT-valid", "start_pos": 57, "end_pos": 67, "type": "DATASET", "confidence": 0.8264148831367493}, {"text": "MTNT-blind", "start_pos": 72, "end_pos": 82, "type": "DATASET", "confidence": 0.7601303458213806}]}, {"text": " Table 7: BLEU scores of the EN\u2192JA models.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9992833733558655}]}, {"text": " Table 8: BLEU scores of the FR\u2192EN models on  MTNT-test, news-test 2014 and MTNT-blind.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9995711445808411}, {"text": "MTNT-test", "start_pos": 46, "end_pos": 55, "type": "DATASET", "confidence": 0.905079185962677}, {"text": "MTNT-blind", "start_pos": 76, "end_pos": 86, "type": "DATASET", "confidence": 0.863898754119873}]}, {"text": " Table 9: BLEU scores of the EN\u2192FR models.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9994016885757446}, {"text": "FR", "start_pos": 32, "end_pos": 34, "type": "METRIC", "confidence": 0.8736870288848877}]}]}