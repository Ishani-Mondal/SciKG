{"title": [{"text": "Simple, Fast, Accurate Intent Classification and Slot Labeling for Goal-Oriented Dialogue Systems", "labels": [], "entities": [{"text": "Accurate Intent Classification", "start_pos": 14, "end_pos": 44, "type": "TASK", "confidence": 0.773020068804423}, {"text": "Slot Labeling", "start_pos": 49, "end_pos": 62, "type": "TASK", "confidence": 0.8099113702774048}]}], "abstractContent": [{"text": "With the advent of conversational assistants like Amazon Alexa, Google Now, etc., dialogue systems are gaining a lot of traction, especially in industrial settings.", "labels": [], "entities": []}, {"text": "These systems typically include a Spoken Language understanding component which consists of two tasks: Intent Classification (IC) and Slot Labeling (SL).", "labels": [], "entities": [{"text": "Spoken Language understanding", "start_pos": 34, "end_pos": 63, "type": "TASK", "confidence": 0.7709354162216187}, {"text": "Slot Labeling (SL)", "start_pos": 134, "end_pos": 152, "type": "TASK", "confidence": 0.8176938652992248}]}, {"text": "Generally, these two tasks are modeled together jointly to achieve best performance.", "labels": [], "entities": []}, {"text": "However, this joint modeling adds to model obfuscation.", "labels": [], "entities": []}, {"text": "In this work, we first design framework fora modularization of joint IC-SL task to enhance architecture transparency.", "labels": [], "entities": []}, {"text": "Then, we explore a number of self-attention, convolutional, and recurrent models, contributing a large-scale analysis of model-ing paradigms for IC+SL across two datasets.", "labels": [], "entities": [{"text": "IC+SL", "start_pos": 145, "end_pos": 150, "type": "TASK", "confidence": 0.8757906158765157}]}, {"text": "Finally, using this framework, we propose a class of 'label-recurrent' models that are non-recurrent apart from a 10-dimensional representation of the label history, and show that our proposed systems are highly accurate (achiev-ing over 30% error reduction in SL over the state-of-the-art on the Snips dataset), as well as fast, at 2x the inference and 2/3 to 1/2 the training time of comparable recurrent models, thus giving an edge in critical real-world systems.", "labels": [], "entities": [{"text": "Snips dataset", "start_pos": 297, "end_pos": 310, "type": "DATASET", "confidence": 0.9231655299663544}]}], "introductionContent": [{"text": "At the core of task-oriented dialogue systems are spoken language understanding (SLU) models, tasked with determining the intent of users' utterances and labeling semantically relevant words at each turn of the conversation.", "labels": [], "entities": [{"text": "spoken language understanding (SLU)", "start_pos": 50, "end_pos": 85, "type": "TASK", "confidence": 0.8225087424119314}]}, {"text": "Performance on these tasks, known as intent classification (IC) and slot labeling (SL), upper-bounds the utility of such dialogue systems.", "labels": [], "entities": [{"text": "intent classification (IC)", "start_pos": 37, "end_pos": 63, "type": "TASK", "confidence": 0.8463454663753509}, {"text": "slot labeling (SL)", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.7916394352912903}]}, {"text": "A large body of recent research has improved these models through the use of recurrent neural networks, encoder-decoder architectures, and attention mechanisms.", "labels": [], "entities": []}, {"text": "However, for * Equal Contribution \u2020 Work performed while at Amazon AI production dialogue systems in particular, system speed is at a premium, both during training and in real-time inference.", "labels": [], "entities": []}, {"text": "In this work, we propose fully non-recurrent and label-recurrent model paradigms including self-attention and convolution for comparison to state-of-the-art recurrent models in terms of accuracy and speed.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 186, "end_pos": 194, "type": "METRIC", "confidence": 0.9990847110748291}]}, {"text": "To achieve this, we design a framework for joint IC-SL models that is modularized into different components and makes the task agnostic to type of neural network used.", "labels": [], "entities": []}, {"text": "This, in turn, makes the model architecture simpler, easy to understand and renders the task network agnostic, allowing for easier plug and play using existing components, such as pre-trained contextual word embeddings, etc.", "labels": [], "entities": []}, {"text": "This is essential for easier model debugging and quicker experimentation, especially in industrial settings.", "labels": [], "entities": [{"text": "model debugging", "start_pos": 29, "end_pos": 44, "type": "TASK", "confidence": 0.7359172701835632}]}, {"text": "Using this framework, we identify three distinct model families of interest: fully recurrent, label-recurrent, and non-recurrent.", "labels": [], "entities": []}, {"text": "Recent stateof-the-art models fall into the first category, as encoder-decoder architectures have recurrent encoders to perform word context encoding, and predict slot label sequences using recurrent decoders that use both word and label information as they decode.", "labels": [], "entities": [{"text": "word context encoding", "start_pos": 128, "end_pos": 149, "type": "TASK", "confidence": 0.6494618852933248}]}, {"text": "In second category, we have 'non-recurrent' networks: fully feed-forward, attention-based, or convolutional models, for example.", "labels": [], "entities": []}, {"text": "Lastly, we have a class of label-recurrent models, inspired by structured sequential models like conditional random fields on top of nonrecurrent word contextualization components.", "labels": [], "entities": []}, {"text": "In this class of models, slot label decoding proceeds such that label sequences are encoded by a recurrent component, but word sequences are not.", "labels": [], "entities": [{"text": "slot label decoding", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.7121792833010355}]}, {"text": "Our contributions are: \u2022 A class of label-recurrent convolutional models that achieve state-of-the-art performance on Snips and competitive performance on ATIS while maintaining faster training and inference speeds than fully-recurrent models \u2022 A new modular framework for joint IC-SL models that permits the analysis of individual modeling components that decomposes these joint models into separate components for word context encoding, summarization of the sentence into a single vector for intent classification, and modeling of dependencies in the output space of slot label sequences.", "labels": [], "entities": [{"text": "Snips", "start_pos": 118, "end_pos": 123, "type": "DATASET", "confidence": 0.8867558240890503}, {"text": "ATIS", "start_pos": 155, "end_pos": 159, "type": "DATASET", "confidence": 0.8980255126953125}, {"text": "word context encoding", "start_pos": 416, "end_pos": 437, "type": "TASK", "confidence": 0.6673721472422282}, {"text": "summarization of the sentence", "start_pos": 439, "end_pos": 468, "type": "TASK", "confidence": 0.8908645361661911}, {"text": "intent classification", "start_pos": 494, "end_pos": 515, "type": "TASK", "confidence": 0.6975173801183701}]}, {"text": "\u2022 In-depth analysis of different word contextualizations for Spoken Language Understanding task (for instance, providing evidence for the intuition that explicitly focusing on local context is a useful architectural inductive prior for slot labeling)", "labels": [], "entities": [{"text": "Spoken Language Understanding task", "start_pos": 61, "end_pos": 95, "type": "TASK", "confidence": 0.8839986622333527}, {"text": "slot labeling", "start_pos": 236, "end_pos": 249, "type": "TASK", "confidence": 0.8828420042991638}]}], "datasetContent": [{"text": "We evaluate our framework and models on the ATIS data set () of spoken airline reservation requests and the Snips NLU Benchmark set ().", "labels": [], "entities": [{"text": "ATIS data set", "start_pos": 44, "end_pos": 57, "type": "DATASET", "confidence": 0.8109232087930044}, {"text": "Snips NLU Benchmark set", "start_pos": 108, "end_pos": 131, "type": "DATASET", "confidence": 0.8788387477397919}]}, {"text": "The ATIS training set contains 4978 utterances from the ATIS-2 and ATIS-3 corpora; the test set consists of 893 utterances from the ATIS-3 NOV93 and DEC94 data sets.", "labels": [], "entities": [{"text": "ATIS training set", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.891964852809906}, {"text": "ATIS-2", "start_pos": 56, "end_pos": 62, "type": "DATASET", "confidence": 0.9574314951896667}, {"text": "ATIS-3 corpora", "start_pos": 67, "end_pos": 81, "type": "DATASET", "confidence": 0.7842997610569}, {"text": "ATIS-3 NOV93", "start_pos": 132, "end_pos": 144, "type": "DATASET", "confidence": 0.7538555264472961}, {"text": "DEC94 data sets", "start_pos": 149, "end_pos": 164, "type": "DATASET", "confidence": 0.9044252236684164}]}, {"text": "The number of slot labels is 127, and the number of intent classes is 18.", "labels": [], "entities": []}, {"text": "Only the words themselves are used as input; no additional tags are used.", "labels": [], "entities": []}, {"text": "The Snips 2017 dataset is a collection of 16K crowdsourced queries, with about 2400 utterances per each of 7 intents.", "labels": [], "entities": [{"text": "Snips 2017 dataset", "start_pos": 4, "end_pos": 22, "type": "DATASET", "confidence": 0.8796409567197164}]}, {"text": "These intents range from 'Play Music' to 'Get Weather'.", "labels": [], "entities": [{"text": "Get Weather'", "start_pos": 42, "end_pos": 54, "type": "TASK", "confidence": 0.5186529358228048}]}, {"text": "Training data contains 13784 utterances and the test data consists of 700 utterances.", "labels": [], "entities": []}, {"text": "The utterance tokens are mixed case unlike the ATIS dataset, where all the tokens are lowercased.", "labels": [], "entities": [{"text": "ATIS dataset", "start_pos": 47, "end_pos": 59, "type": "DATASET", "confidence": 0.9760715663433075}]}, {"text": "Total number of slot labels are 72.", "labels": [], "entities": []}, {"text": "We use IOB tagging, and split 10% of the train set off to form a development set.", "labels": [], "entities": [{"text": "IOB tagging", "start_pos": 7, "end_pos": 18, "type": "TASK", "confidence": 0.6628270894289017}]}, {"text": "Utterances in Snips are, on average, short, with 9.15 words per utterance compared to ATIS' 11.2.", "labels": [], "entities": [{"text": "Utterances", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9530912637710571}, {"text": "ATIS", "start_pos": 86, "end_pos": 90, "type": "DATASET", "confidence": 0.6505282521247864}]}, {"text": "However, slot label sequences themselves are longer in Snips, averaging 1.8 tokens per span to ATIS' 1.2, making span-level slot labeling more difficult.", "labels": [], "entities": [{"text": "Snips", "start_pos": 55, "end_pos": 60, "type": "DATASET", "confidence": 0.8082278370857239}, {"text": "ATIS", "start_pos": 95, "end_pos": 99, "type": "DATASET", "confidence": 0.8250582218170166}, {"text": "slot labeling", "start_pos": 124, "end_pos": 137, "type": "TASK", "confidence": 0.743487149477005}]}, {"text": "For our development experiments, we use the casing and tokenization provided by Snips.", "labels": [], "entities": [{"text": "Snips", "start_pos": 80, "end_pos": 85, "type": "DATASET", "confidence": 0.9199234247207642}]}, {"text": "Co, but to compare to prior work, in one test experiment we use the lowercased, tokenized version of (Goo et al., 2018) 2 .  We evaluate multiple models from each of our model paradigms to help determine what modeling structures are necessary for SLU, and where the best accuracy-speed tradeoffs are.", "labels": [], "entities": [{"text": "SLU", "start_pos": 247, "end_pos": 250, "type": "TASK", "confidence": 0.9604176878929138}, {"text": "accuracy-speed", "start_pos": 271, "end_pos": 285, "type": "METRIC", "confidence": 0.965531051158905}]}, {"text": "First, we report extensive evaluation across the Snips and ATIS development sets, tracking inference speed and time to convergence along with the usual IC  accuracy and SL F1.", "labels": [], "entities": [{"text": "Snips and ATIS development sets", "start_pos": 49, "end_pos": 80, "type": "DATASET", "confidence": 0.7911001324653626}, {"text": "accuracy", "start_pos": 156, "end_pos": 164, "type": "METRIC", "confidence": 0.8987176418304443}, {"text": "SL F1", "start_pos": 169, "end_pos": 174, "type": "METRIC", "confidence": 0.8700947463512421}]}, {"text": "Second, we pick a small number of our best-performing models to evaluate on ATIS and Snips test sets, to compare against prior work.", "labels": [], "entities": [{"text": "ATIS and Snips test sets", "start_pos": 76, "end_pos": 100, "type": "DATASET", "confidence": 0.7777036786079407}]}, {"text": "For each experiment below, we train until convergence, where convergence is defined by an early stopping criterion with a patience of 30 epochs and an average of development set IC accuracy and token-level SL F1 used as the performance metric.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 181, "end_pos": 189, "type": "METRIC", "confidence": 0.6284315586090088}, {"text": "token-level SL F1", "start_pos": 194, "end_pos": 211, "type": "METRIC", "confidence": 0.6983367204666138}]}, {"text": "In our first category of experiments, we evaluate variants of each word contextualization paradigm introduced.", "labels": [], "entities": []}, {"text": "We evaluate one feed-forward word contextualization module (labeled as FEED-FORWARD) to provide a baseline performance.", "labels": [], "entities": [{"text": "FEED-FORWARD", "start_pos": 71, "end_pos": 83, "type": "METRIC", "confidence": 0.9933179616928101}]}, {"text": "As with all subsequent models, we evaluate this word contextualization module with and without our proposed label-recurrent decoder.", "labels": [], "entities": []}, {"text": "This baseline should help us determine the extent to which each dataset requires the modeling of context.", "labels": [], "entities": []}, {"text": "We evaluate 3 convolutional word contextualization modules.", "labels": [], "entities": []}, {"text": "The first has 1 layer with a kernel size of 5, and is intended to provide intuition as to whether a relatively large local context can sufficiently model SL behavior.", "labels": [], "entities": []}, {"text": "We label this model CNN, 5KERNEL, 1L, and name all other CNN models similarly.", "labels": [], "entities": [{"text": "CNN", "start_pos": 20, "end_pos": 23, "type": "DATASET", "confidence": 0.8622443675994873}]}, {"text": "The next model has 3 layers with kernel size 5, and is dilated.", "labels": [], "entities": []}, {"text": "This model incorporates long-distance context hierarchically, and is shorter and wider-per-layer than the otherwise-similar 3rd CNN model, with 4 layers and kernel size 3.", "labels": [], "entities": []}, {"text": "We evaluate 4 attention-based word contextualization modules.", "labels": [], "entities": []}, {"text": "The first is simple, with 1 attention head and 1 layer.", "labels": [], "entities": []}, {"text": "Unlike all others we analyze, it does not use relative position embeddings.", "labels": [], "entities": []}, {"text": "Thus, this model is word order-invariant except fora simple absolute position embedding.", "labels": [], "entities": []}, {"text": "If it improves over FEEDFORWARD, then, it provides strong evidence that semantic information from the context words, irrespective of order, is useful in making tagging decisions.", "labels": [], "entities": [{"text": "FEEDFORWARD", "start_pos": 20, "end_pos": 31, "type": "METRIC", "confidence": 0.9869333505630493}, {"text": "tagging", "start_pos": 160, "end_pos": 167, "type": "TASK", "confidence": 0.9590319991111755}]}, {"text": "We label this model with the flag NO-POS.", "labels": [], "entities": [{"text": "NO-POS", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.7526054382324219}]}, {"text": "To evaluate the utility of relative position embeddings, we also compare a model with 1 head and one layer, labeled ATTN, 1HEAD, 1L.", "labels": [], "entities": [{"text": "ATTN", "start_pos": 116, "end_pos": 120, "type": "METRIC", "confidence": 0.949370265007019}]}, {"text": "We then test two increasingly complex models, first with 3 layers and 1 head, the second with 3 layers and 2 heads per layer.", "labels": [], "entities": []}, {"text": "We evaluate 2 LSTM-based word contextualization modules; one uses a single LSTM layer, whereas the other stacks a second on top of the first.", "labels": [], "entities": []}, {"text": "As with all other models, we test these two models both with independent slot prediction and label-recurrent slot prediction.", "labels": [], "entities": [{"text": "label-recurrent slot prediction", "start_pos": 93, "end_pos": 124, "type": "TASK", "confidence": 0.5389627317587534}]}], "tableCaptions": [{"text": " Table 1: Development results on the Snips 2017 and ATIS datasets, comparing models from feed-forward, convolutional,", "labels": [], "entities": [{"text": "Snips 2017 and ATIS datasets", "start_pos": 37, "end_pos": 65, "type": "DATASET", "confidence": 0.8544702887535095}]}, {"text": " Table 2: Test set results on the Snips dataset. (*) indicates numbers reported by (Goo et al., 2018)", "labels": [], "entities": [{"text": "Snips dataset", "start_pos": 34, "end_pos": 47, "type": "DATASET", "confidence": 0.9630325436592102}]}, {"text": " Table 3: Test set results on the ATIS dataset, compared to recent recurrent models.", "labels": [], "entities": [{"text": "ATIS dataset", "start_pos": 34, "end_pos": 46, "type": "DATASET", "confidence": 0.9578971266746521}]}]}