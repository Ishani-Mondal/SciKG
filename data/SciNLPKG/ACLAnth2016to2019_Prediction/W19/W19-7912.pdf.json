{"title": [{"text": "Advantages of the flux-based interpretation of dependency length minimization", "labels": [], "entities": [{"text": "dependency length minimization", "start_pos": 47, "end_pos": 77, "type": "TASK", "confidence": 0.6592126290003458}]}], "abstractContent": [{"text": "Dependency length minimization (DLM, also called dependency distance minimization) is studied by many authors and identified as a property of natural languages.", "labels": [], "entities": [{"text": "Dependency length minimization", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7040020426114401}, {"text": "dependency distance minimization)", "start_pos": 49, "end_pos": 82, "type": "TASK", "confidence": 0.7089178264141083}]}, {"text": "In this paper we show that DLM can be interpreted as the flux size minimization and study the advantages of such a view.", "labels": [], "entities": []}, {"text": "First it allows us to understand why DLM is cognitively motivated and how it is related to the constraints on the processing of sentences.", "labels": [], "entities": []}, {"text": "Second, it opens the door to the definition of a big range of variations of DLM, taking into account other characteristics of the flux such as nested constructions and pro-jectivity.", "labels": [], "entities": []}], "introductionContent": [{"text": "The dependency flux between two words in a sentence is the set of dependencies that link a word on the left with a word on the right (.", "labels": [], "entities": []}, {"text": "The size of the flux in an inter-word position is the number of dependencies that cross this position.", "labels": [], "entities": []}, {"text": "The flux size of a sentence is the sum of the sizes of the inter-word fluxes.", "labels": [], "entities": []}, {"text": "On the top line, shows the size of the flux at each inter-word position.", "labels": [], "entities": []}, {"text": "In the first position, between A and global, there is only one dependency crossing (A <det tax); in the second position, between global and carbon, there are two dependencies (A <det tax; global <amod carbon).", "labels": [], "entities": []}, {"text": "On the bottom line, shows, for each word, the length of the dependency that links that word to its governor.", "labels": [], "entities": [{"text": "length", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.9587231278419495}]}, {"text": "For example, the first word A is linked to its governor tax by a dependency of length 3 because this dependency crosses 3 inter-word positions.", "labels": [], "entities": []}, {"text": "The dependency length of a sentence is the sum of the lengths of the dependencies of that sentence.", "labels": [], "entities": []}, {"text": "It can be verified, for the sentence in, that: Dependency flux size of the sentence = 1+2+2+1+2+2+3+1+2+2+2+2 = 21 Dependency length of the sentence = 3+1+1+2+1+0+1+2+1+2+1+4+1+1+3 = 21 It is easy to check that the dependency length is always equal to the dependency flux size.", "labels": [], "entities": []}, {"text": "Since the length of a dependency is the number of fluxes on which this dependency belongs, the size of the flux is the sum, on all the dependencies, of the number of fluxes they cross.", "labels": [], "entities": []}, {"text": "In other words, these two values are equal to the number of crossings between a dependency and an inter-word position.", "labels": [], "entities": []}, {"text": "Several studies have studied dependency length and shown that natural languages tend to minimize it (.", "labels": [], "entities": []}, {"text": "This property is called dependency length minimization (DLM) or dependency distance minimization (dependency lengths can be interpreted as distances between syntactically related words).", "labels": [], "entities": [{"text": "dependency length minimization (DLM)", "start_pos": 24, "end_pos": 60, "type": "TASK", "confidence": 0.7978852987289429}, {"text": "dependency distance minimization", "start_pos": 64, "end_pos": 96, "type": "TASK", "confidence": 0.6634834210077921}]}, {"text": "DLM is correlated with several properties of natural languages.", "labels": [], "entities": []}, {"text": "For instance, the fact that dependency structures in natural languages are much less non-projective than in randomly ordered trees can be explained by DLM.", "labels": [], "entities": []}, {"text": "It is also claimed that DLM is a factor affecting the grammar of languages and word order choices (.", "labels": [], "entities": []}, {"text": "Since the dependency length is equal to the dependency flux size, by trying to minimize the lengths of the dependencies, we also try to minimize the sizes of the inter-word fluxes.", "labels": [], "entities": []}, {"text": "This gives us two different views on DLM.", "labels": [], "entities": [{"text": "DLM", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.8485912680625916}]}, {"text": "The objective of this article is to show that thinking about DLM in terms of flux has several advantages.", "labels": [], "entities": []}, {"text": "In section 2, we will show that the interpretation of DLM in terms of flux makes it possible to highlight the cognitive relevance of this constraint.", "labels": [], "entities": []}, {"text": "In section 3, we will examine other fluxbased constraints related to DLM.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}