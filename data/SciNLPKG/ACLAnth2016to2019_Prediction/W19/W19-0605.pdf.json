{"title": [{"text": "Topological Data Analysis for Discourse Semantics?", "labels": [], "entities": [{"text": "Topological Data Analysis", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6515138645966848}]}], "abstractContent": [{"text": "In this paper we present new results on applying topological data analysis (TDA) to discourse structures.", "labels": [], "entities": [{"text": "topological data analysis (TDA)", "start_pos": 49, "end_pos": 80, "type": "TASK", "confidence": 0.745675394932429}]}, {"text": "We show that topological information, extracted from the relationships between sentences , can be used in inference, namely it can be applied to the very difficult legal entailment problem given in the COLIEE 2018 data set.", "labels": [], "entities": [{"text": "COLIEE 2018 data set", "start_pos": 202, "end_pos": 222, "type": "DATASET", "confidence": 0.954828292131424}]}, {"text": "Previous results of Doshi and Zadrozny (2018) and Gholizadeh et al.", "labels": [], "entities": []}, {"text": "(2018) show that topological features are useful for classification.", "labels": [], "entities": []}, {"text": "The applications of computational topology to entailment are novel, and in our view provide anew set of tools for discourse semantics: computational topology can perhaps provide abridge between the brittleness of logic and the regression of neural networks.", "labels": [], "entities": []}, {"text": "We discuss the advantages and disadvantages of using topological information, and some open problems such as explainability of the classifier decisions.", "labels": [], "entities": []}], "introductionContent": [{"text": "Topology is a classic branch of mathematics that deals with shape invariants such as the presence and numbers of holes.", "labels": [], "entities": []}, {"text": "More recently topological data analysis (TDA) was introduced as a branch of computational mathematics and data science, predicated on the observation that data points have implicit shapes (e.g.).", "labels": [], "entities": [{"text": "topological data analysis (TDA)", "start_pos": 14, "end_pos": 45, "type": "TASK", "confidence": 0.8489182591438293}]}, {"text": "Throughout the paper we will be using the word topology only in these two particular senses.", "labels": [], "entities": []}, {"text": "Both topology and TDA can be viewed as an abstraction mechanism, where we replace the original shape or cloud of data points by some numbers representing their mathematical properties, using a formal machinery derived from algebraic topology.", "labels": [], "entities": []}, {"text": "In case of TDA, we use software implementing these methods.", "labels": [], "entities": []}, {"text": "A natural question to ask is whether texts or discourse structures have shapes that can be measured using tools of topology. was the first to investigate this question and observed we can capture some information about discourse structures using topological structures, namely homological persistence (which we do not have space to define here, and we simply use it as a source of numerical features).", "labels": [], "entities": []}, {"text": "Zhu used a collection of nursery rhymes to illustrate how topology can be used to find certain patterns of repetition.", "labels": [], "entities": []}, {"text": "More recently, Doshi and Zadrozny (2018) applied Zhu's method in a larger setting showing its classification superiority on the task of assigning movie genres to user generated plot summaries, using the IMDB data set.", "labels": [], "entities": [{"text": "assigning movie genres to user generated plot summaries", "start_pos": 136, "end_pos": 191, "type": "TASK", "confidence": 0.767325721681118}, {"text": "IMDB data set", "start_pos": 203, "end_pos": 216, "type": "DATASET", "confidence": 0.9779430230458578}]}, {"text": "They improved on the early 2018 state of the art results of, which was achieved using deep learning on this large data set.", "labels": [], "entities": []}, {"text": "applied a different method for computing homological persistence to the task of authorship attribution, which is also a classification task, showing that the patterns of how authors introduce characters in novels can be captured to large extent using topological descriptors.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 80, "end_pos": 102, "type": "TASK", "confidence": 0.7915178537368774}]}, {"text": "Interestingly, neither of these works uses topological features to augments the usual tf/idf representations of documents: use counts of words (from a previously identified vocabularies) to form a matrix which is the only input to topological persistence, and then they make a rule based decision based only on the presence of barcodes; and use time series.", "labels": [], "entities": []}, {"text": "To use topological data analysis (TDA), assumes that text is implicitly coherent (SIFTS method), and so do.", "labels": [], "entities": [{"text": "topological data analysis (TDA)", "start_pos": 7, "end_pos": 38, "type": "TASK", "confidence": 0.6820257604122162}]}, {"text": "Namely, they assume implicit connection between consecutive sentences in each document.", "labels": [], "entities": []}, {"text": "While for movie plots this assumption makes sense, it might be more problematic in other contexts, such as entailment, especially when two passages are unrelated.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used tenfold cross-validation, setting a random sample of 22 cases aside from given 181 cases for the evaluation task.", "labels": [], "entities": []}, {"text": "From our first method where we used highly similar and relevant paragraphs for classification along with tf/idf feature vector, our best results were 0.28 precision score, 0.58 recall and 0.38 F-score for entailed class (see).", "labels": [], "entities": [{"text": "precision score", "start_pos": 155, "end_pos": 170, "type": "METRIC", "confidence": 0.9824211299419403}, {"text": "recall", "start_pos": 177, "end_pos": 183, "type": "METRIC", "confidence": 0.9953881502151489}, {"text": "F-score", "start_pos": 193, "end_pos": 200, "type": "METRIC", "confidence": 0.9958914518356323}]}, {"text": "We improved our precision score by 2.5%, recall by over 14% and F-score by over 5% using topological data analysis.", "labels": [], "entities": [{"text": "precision score", "start_pos": 16, "end_pos": 31, "type": "METRIC", "confidence": 0.981022834777832}, {"text": "recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.9996358156204224}, {"text": "F-score", "start_pos": 64, "end_pos": 71, "type": "METRIC", "confidence": 0.999257504940033}]}, {"text": "(Our aim was to achieve higher F-score for classification other than recall as a na\u00a8\u0131vena\u00a8\u0131ve implementation can give 1.0 recall by predicting all paragraphs as entailed).", "labels": [], "entities": [{"text": "F-score", "start_pos": 31, "end_pos": 38, "type": "METRIC", "confidence": 0.9986942410469055}, {"text": "recall", "start_pos": 69, "end_pos": 75, "type": "METRIC", "confidence": 0.988013505935669}, {"text": "recall", "start_pos": 122, "end_pos": 128, "type": "METRIC", "confidence": 0.9881064891815186}]}, {"text": "Using topological features, we could see reduction in predicting false positives, and more accurate predictions for true positives.", "labels": [], "entities": [{"text": "predicting false positives", "start_pos": 54, "end_pos": 80, "type": "TASK", "confidence": 0.8739054203033447}]}, {"text": "We experimented with three machine learning classifiers out of which we obtained the best results using Random Forest., but we do not have tools to understand precisely how.", "labels": [], "entities": [{"text": "Random Forest.", "start_pos": 104, "end_pos": 118, "type": "DATASET", "confidence": 0.8902665376663208}]}], "tableCaptions": [{"text": " Table 1: Results of the classification experiments using Random Forest (RF) with 10-fold validation; RF produced", "labels": [], "entities": [{"text": "RF", "start_pos": 102, "end_pos": 104, "type": "METRIC", "confidence": 0.9654037952423096}]}]}