{"title": [{"text": "Towards coherent and cohesive long-form text generation", "labels": [], "entities": []}], "abstractContent": [{"text": "Generating coherent and cohesive long-form texts is a challenging task.", "labels": [], "entities": []}, {"text": "Previous works relied on large amounts of human-generated texts to train neural language models.", "labels": [], "entities": []}, {"text": "However , few attempted to explicitly improve neu-ral language models from the perspectives of coherence and cohesion.", "labels": [], "entities": []}, {"text": "In this work, we propose anew neural language model that is equipped with two neural discriminators which provide feedback signals at the levels of sentence (cohesion) and paragraph (coher-ence).", "labels": [], "entities": []}, {"text": "Our model is trained using a simple yet efficient variant of policy gradient, called negative-critical sequence training, which is proposed to eliminate the need of training a separate critic for estimating baseline.", "labels": [], "entities": []}, {"text": "Results demonstrate the effectiveness of our approach, showing improvements over the strong base-line-recurrent attention-based bidirectional MLE-trained neural language model.", "labels": [], "entities": []}], "introductionContent": [{"text": "The terms coherence and cohesion in linguistics are commonly defined as follows.", "labels": [], "entities": []}, {"text": "\u2022 Cohesion: sentence pairs fitting together the way two pieces of a jigsaw puzzle do.", "labels": [], "entities": []}, {"text": "\u2022 Coherence: what all the sentences in apiece of writing add up to, the way all the pieces in a puzzle add up to the picture on the box.", "labels": [], "entities": []}, {"text": "In layman's terms, cohesion indicates that two consecutive sentences are locally well-connected, and coherence indicates that multiple sentences globally hold together.", "labels": [], "entities": []}, {"text": "Generating cohesive and coherent natural language texts that span multiple sentences is a challenging task for two principal reasons.", "labels": [], "entities": []}, {"text": "First, there is no formal specification of cross-sentence linguistic properties, such as coherence and cohesion of a text.", "labels": [], "entities": []}, {"text": "Secondly, there is no widely accepted model to measure the two properties.", "labels": [], "entities": []}, {"text": "Most state-of-the-art neural approaches to natural language generation rely on a large amount of human-generated text to train language models (.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 43, "end_pos": 70, "type": "TASK", "confidence": 0.6862072745958964}]}, {"text": "Although these models can generate sentences that, if judged individually, are similar to human-generated ones, they often fail to capture the local and global dependencies among sentences, resulting in a text that is neither coherent nor cohesive.", "labels": [], "entities": []}, {"text": "For example, neural language models based on Recurrent Neural Networks (RNNs) are widely applied to response generation for dialogue ().", "labels": [], "entities": [{"text": "response generation", "start_pos": 100, "end_pos": 119, "type": "TASK", "confidence": 0.7220000922679901}]}, {"text": "Although the responses by themselves look reasonable, they are detached from the whole dialogue session.", "labels": [], "entities": []}, {"text": "In this paper, we address the challenge in a principled manner, employing a pair of discriminators to score whether and to what extent a text is coherent or cohesive.", "labels": [], "entities": []}, {"text": "The coherence discriminator measures the compatibility among all sentences in a paragraph.", "labels": [], "entities": [{"text": "compatibility", "start_pos": 41, "end_pos": 54, "type": "METRIC", "confidence": 0.9761406183242798}]}, {"text": "The cohesion discriminator measures the compatibility of each pair of consecutive sentences.", "labels": [], "entities": [{"text": "compatibility", "start_pos": 40, "end_pos": 53, "type": "METRIC", "confidence": 0.9642465114593506}]}, {"text": "These models, given a conditional input text and multiple candidate output texts, are learned to score the candidates with respect to the criterion.", "labels": [], "entities": []}, {"text": "The scores are used as reward signals to train an RNN-based language model to generate (more) coherent and cohesive texts.", "labels": [], "entities": []}], "datasetContent": [{"text": "In contrast, our discriminator-guided model is able to generate a more interesting, and sentiment-consistent continuation.: An ablation study with automated evaluation metric scores: NLL, PPL, BLEU-n, intra/inter-unique-n, along with the length ratio with the length of corresponding true target sentences as 1.", "labels": [], "entities": [{"text": "BLEU-n", "start_pos": 193, "end_pos": 199, "type": "METRIC", "confidence": 0.9982320666313171}]}, {"text": "Significant numbers are highlighted in bold before rounding.", "labels": [], "entities": []}, {"text": "subsets of the two datasets that satisfy the following two conditions: (1) a review must have at least 10 sentences, and (2) each sentence has from 5 to 30 words.", "labels": [], "entities": []}, {"text": "This yields roughly 60,000 TripAdvisor reviews and 220,000 Yelp reviews, split into [0.8, 0.1, 0.1] ratio for train/dev/test sets.", "labels": [], "entities": []}, {"text": "We merge the source and target vocabularies, and limit it to the top 50,000 frequent words, excluding special tokens.", "labels": [], "entities": []}, {"text": "For each review, we use the first five sentences as the input S to G, and the next five sentences as the target output T from G.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Coherence and cohesion rewards on test data. The cohesion reward at the end of each line is computed  with its next sentence. This is an example of contradiction and inconsistent sentiment, suggestive of incoherence.", "labels": [], "entities": []}, {"text": " Table 2: Retrieval ratios for coherence and cohesion discriminators from a collection of 100 negative candidates  from the test data. The reported numbers are the averages over 20 evaluations. Notations: Conv 512  2,3,4,5 is a convo- lutional input encoder with filter sizes 2, 3, 4, and 5, and there are 512 filters for each filter size. GRU 1024", "labels": [], "entities": [{"text": "GRU 1024", "start_pos": 340, "end_pos": 348, "type": "DATASET", "confidence": 0.9425997138023376}]}, {"text": " Table 3: Sample generations from our MLE-trained baseline model, G MLE , and our discriminator-guided model  G MLE+RL(coherence, cohesion) . The red texts highlight a common problem in G MLE -it exhibits a repetition, and an  inconsistent opinion as a review. In contrast, our discriminator-guided model is able to generate a more interesting,  and sentiment-consistent continuation.", "labels": [], "entities": []}, {"text": " Table 4: An ablation study with automated evaluation metric scores: NLL, PPL, BLEU-n, intra/inter-unique-n,  along with the length ratio with the length of corresponding true target sentences as 1. Significant numbers are  highlighted in bold before rounding.", "labels": [], "entities": [{"text": "BLEU-n", "start_pos": 79, "end_pos": 85, "type": "METRIC", "confidence": 0.9989429116249084}]}, {"text": " Table 5: Results of Human Evaluation showing preferences (%) for our model G MLE+RL(coherence, cohesion) vis-a-vis  the baseline G MLE after adjustment for spamming. G MLE+RL(coherence, cohesion) is preferred over G MLE . For simplicity,  the 5-point Likert scale has been collapsed to a 3-point scale. See the Appendix for further details of distributions.", "labels": [], "entities": []}]}