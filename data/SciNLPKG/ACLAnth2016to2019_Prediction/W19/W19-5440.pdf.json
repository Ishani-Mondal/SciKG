{"title": [{"text": "Parallel Corpus Filtering based on Fuzzy String Matching", "labels": [], "entities": [{"text": "Fuzzy String Matching", "start_pos": 35, "end_pos": 56, "type": "TASK", "confidence": 0.6268568237622579}]}], "abstractContent": [{"text": "In this paper, we describe the IIT Patna's submission to WMT 2019 shared task on parallel corpus filtering.", "labels": [], "entities": [{"text": "IIT Patna's submission to WMT 2019 shared task", "start_pos": 31, "end_pos": 77, "type": "TASK", "confidence": 0.555703169769711}, {"text": "parallel corpus filtering", "start_pos": 81, "end_pos": 106, "type": "TASK", "confidence": 0.5956023633480072}]}, {"text": "This shared task asks the participants to develop methods for scoring each parallel sentence from a given noisy parallel corpus.", "labels": [], "entities": []}, {"text": "Quality of the scoring method is judged based on the quality of SMT and NMT systems trained on smaller set of high-quality parallel sentences sub-sampled from the original noisy corpus.", "labels": [], "entities": [{"text": "SMT", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.9542062878608704}]}, {"text": "This task has two language pairs.", "labels": [], "entities": []}, {"text": "We submit for both the Nepali-English and Sinhala-English language pairs.", "labels": [], "entities": []}, {"text": "We define fuzzy string matching score between En-glish and the translated (into English) source based on Levenshtein distance.", "labels": [], "entities": []}, {"text": "Based on the scores, we sub-sample two sets (having 1 million and 5 millions English tokens) of parallel sentences from each parallel corpus, and train SMT systems for development purpose only.", "labels": [], "entities": [{"text": "SMT", "start_pos": 152, "end_pos": 155, "type": "TASK", "confidence": 0.988714873790741}]}, {"text": "The organizers publish the official evaluation using both SMT and NMT on the final official test set.", "labels": [], "entities": [{"text": "SMT", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.9238370656967163}, {"text": "NMT", "start_pos": 66, "end_pos": 69, "type": "DATASET", "confidence": 0.8691501617431641}]}, {"text": "Total 10 teams participated in the shared task and according the official evaluation , our scoring method obtains 2nd position in the team ranking for 1-million Nepali-English NMT and 5-million Sinhala-English NMT categories.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper, we describe our submission to the WMT 2019 1 parallel corpus filtering task ( . The aim of this shared task is to extract two smaller sets of high-quality parallel sentences from a very noisy parallel corpus.", "labels": [], "entities": [{"text": "WMT 2019 1 parallel corpus filtering task", "start_pos": 49, "end_pos": 90, "type": "TASK", "confidence": 0.7427034463201251}]}, {"text": "This parallel corpus is crawled from the web as part of the Paracrawl project and contains all kinds of noise (wrong language in source and target, sentence pairs that are not translations of each other, bad language, incomplete or bad translations, etc.).", "labels": [], "entities": []}, {"text": "This task provides the participants two sets of such noisy parallel corpora: one is for Nepali-English with English token count of 40.6 million and another is for Sinhala-English with English token count of 59.6 million.", "labels": [], "entities": []}, {"text": "The participants are asked to submit score for each sentence in each of these two parallel corpora.", "labels": [], "entities": []}, {"text": "Based on the scores, two smaller sets of parallel sentences that amount to 1 million and 5 millions are extracted from each of those two parallel corpora.", "labels": [], "entities": []}, {"text": "The quality of the scoring method is judged based on the quality of the neural machine translation (NMT) and statistical machine translation (SMT) systems trained on these smaller corpora.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 109, "end_pos": 146, "type": "TASK", "confidence": 0.779708574215571}]}, {"text": "We participated in both language pair: Nepali-English and Sinhala-English.", "labels": [], "entities": []}, {"text": "Building machine translation (MT) systems, specifically NMT () systems, require supervision of huge amount of high-quality parallel training data.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 9, "end_pos": 33, "type": "TASK", "confidence": 0.8697267174720764}]}, {"text": "Though recently emerged unsupervised NMT ( has shown promising results on related language pairs, it does notwork for distant language pairs like Nepali-English and Sinhala-English ( . Also, avast majority of languages in the world fall in the category of low-resource languages as they have too little, if any, parallel data.", "labels": [], "entities": []}, {"text": "However, getting parallel training data is not easy as it takes time, money and expert translators.", "labels": [], "entities": []}, {"text": "Though we can have parallel data compiled from online sources, it is not reliable as it is often very noisy and poor in quality.", "labels": [], "entities": []}, {"text": "It has been found that MT systems are sensitive to noise.", "labels": [], "entities": [{"text": "MT", "start_pos": 23, "end_pos": 25, "type": "TASK", "confidence": 0.991894543170929}]}, {"text": "This necessitates to filter out noisy sentences from a large pool of parallel parallel sentences.", "labels": [], "entities": []}, {"text": "Parallel corpus filtering task of WMT 2019 focuses on two new low-resource languages pairs: Nepali-English and Sinhala-English for which we have very little amount of publicly available parallel corpora.", "labels": [], "entities": [{"text": "Parallel corpus filtering", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.613299290339152}, {"text": "WMT 2019", "start_pos": 34, "end_pos": 42, "type": "DATASET", "confidence": 0.7450042068958282}]}, {"text": "We use these parallel corpora for building our scoring scheme based on fuzzy string matching.", "labels": [], "entities": [{"text": "fuzzy string matching", "start_pos": 71, "end_pos": 92, "type": "TASK", "confidence": 0.6878832976023356}]}, {"text": "Total 10 teams participated in the shared task.", "labels": [], "entities": []}, {"text": "According the official evaluation, our scoring method obtains 2nd position in the team ranking in two categories: 1-million Nepali-English NMT and 5-million Sinhala-English NMT.", "labels": [], "entities": []}], "datasetContent": [{"text": "For our fuzzy string matching as well as evaluating the quality of the sub-sampled sets, we build XXEnglish (XX is Nepali or Sinhala) phrase-based SMT () system using the Moses tool ().", "labels": [], "entities": [{"text": "fuzzy string matching", "start_pos": 8, "end_pos": 29, "type": "TASK", "confidence": 0.7170037428538004}, {"text": "SMT", "start_pos": 147, "end_pos": 150, "type": "TASK", "confidence": 0.7668803334236145}]}, {"text": "For training the SMT system we keep the following settings: growdiag-final-and heuristics for word alignment, msdbidirectional-fe for reordering model, and 5-gram language model with modified Kneser-Ney smoothing) using KenLM).", "labels": [], "entities": [{"text": "SMT", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.9887654781341553}, {"text": "word alignment", "start_pos": 94, "end_pos": 108, "type": "TASK", "confidence": 0.7643725872039795}]}, {"text": "The BLEU 6 () scores for these SMT systems are 3.7 and 4.6 for Nepali-English and Sinhala-English, respectively.", "labels": [], "entities": [{"text": "BLEU 6", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9788011014461517}, {"text": "SMT", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.9938941597938538}]}], "tableCaptions": [{"text": " Table 1: Training data sources and number of sen- tences. These corpora are used to train SMT sys- tems used for fuzzy string matching. #Sents: Sentence  counts; #Tokens: English token counts.", "labels": [], "entities": [{"text": "SMT sys- tems", "start_pos": 91, "end_pos": 104, "type": "TASK", "confidence": 0.8715591132640839}, {"text": "fuzzy string matching", "start_pos": 114, "end_pos": 135, "type": "TASK", "confidence": 0.643779327472051}]}, {"text": " Table 2: Number of sentences in dev and devtest.", "labels": [], "entities": [{"text": "Number", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9679122567176819}]}, {"text": " Table 3: Official BLEU scores for 1-million and 5-million sub-sampled sets.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.9265305995941162}]}, {"text": " Table 4: Number of parallel sentences in the raw paral- lel corpora before and after applying language identifi- cation and sentence length based filtering.", "labels": [], "entities": []}, {"text": " Table 5: Number of sentences for 1-million and 5- million sub-sampled sets for two scoring schemes.", "labels": [], "entities": []}, {"text": " Table 6: BLEU scores on devtest for SMT systems  trained on two sub-sampled sets. Baseline is the of- ficial baseline as reported in shared task page. We use  sacreBLEU", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9993533492088318}, {"text": "SMT", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.9917968511581421}, {"text": "Baseline", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9480659365653992}]}]}