{"title": [{"text": "Few-Shot Dialogue Generation Without Annotated Data: A Transfer Learning Approach", "labels": [], "entities": [{"text": "Few-Shot Dialogue Generation", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.597417930761973}]}], "abstractContent": [{"text": "Learning with minimal data is one of the key challenges in the development of practical, production-ready goal-oriented dialogue systems.", "labels": [], "entities": []}, {"text": "Ina real-world enterprise setting where dialogue systems are developed rapidly and are expected to work robustly for an ever-growing variety of domains, products, and scenarios , efficient learning from a limited number of examples becomes indispensable.", "labels": [], "entities": []}, {"text": "In this paper, we introduce a technique to achieve state-of-the-art dialogue generation performance in a few-shot setup, without using any annotated data.", "labels": [], "entities": [{"text": "dialogue generation performance", "start_pos": 68, "end_pos": 99, "type": "TASK", "confidence": 0.831809401512146}]}, {"text": "We do this by lever-aging background knowledge from a larger, more highly represented dialogue source-namely, the MetaLWOz dataset.", "labels": [], "entities": [{"text": "MetaLWOz dataset", "start_pos": 114, "end_pos": 130, "type": "DATASET", "confidence": 0.8907791972160339}]}, {"text": "We evaluate our model on the Stanford Multi-Domain Dialogue Dataset, consisting of human-human goal-oriented dialogues in in-car navigation, appointment scheduling, and weather information domains.", "labels": [], "entities": [{"text": "Stanford Multi-Domain Dialogue Dataset", "start_pos": 29, "end_pos": 67, "type": "DATASET", "confidence": 0.8525749891996384}, {"text": "appointment scheduling", "start_pos": 141, "end_pos": 163, "type": "TASK", "confidence": 0.6625311970710754}]}, {"text": "We show that our few-shot approach achieves state-of-the art results on that dataset by consistently outperforming the previous best model in terms of BLEU and Entity F1 scores, while being more data-efficient by not requiring any data annotation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 151, "end_pos": 155, "type": "METRIC", "confidence": 0.9988528490066528}, {"text": "Entity F1 scores", "start_pos": 160, "end_pos": 176, "type": "METRIC", "confidence": 0.8212534387906393}]}], "introductionContent": [{"text": "Data-driven dialogue systems are becoming widely adopted in enterprise environments.", "labels": [], "entities": []}, {"text": "One of the key properties of a dialogue model in this setting is its data efficiency, i.e. whether it can attain high accuracy and good generalization properties when only trained from minimal data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.99652099609375}]}, {"text": "Recent deep learning-based approaches to training dialogue systems () put emphasis on collecting large amounts of data in order to account for numerous variations in the user inputs and to cover as many dialogue trajectories as possible.", "labels": [], "entities": []}, {"text": "However, in realworld production environments there isn't enough domain-specific data easily available throughout the development process.", "labels": [], "entities": []}, {"text": "In addition, it's important to be able to rapidly adjust a system's behavior according to updates in requirements and new product features in the domain.", "labels": [], "entities": []}, {"text": "Therefore, dataefficient training is a priority direction in dialogue system research.", "labels": [], "entities": []}, {"text": "In this paper, we build on a technique to train a dialogue model fora new domain in a 'zeroshot' setup (in terms of full dialogues in the target domain) only using annotated 'seed' utterances ( . We present an alternative, 'few-shot' approach to data-efficient dialogue system training: we douse complete in-domain dialogues while using approximately the same amount of training data as , with respect to utterances.", "labels": [], "entities": []}, {"text": "However, in our method, no annotation is required -we instead use a latent dialogue act annotation learned in an unsupervised way from a larger (multi-domain) data source, broadly following the model of . This approach is potentially more attractive for practical purposes because it is easier to collect unannotated dialogues than collecting utterances across various domains under a consistent annotation scheme.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the Stanford Multi-Domain (SMD) human-human goal-oriented dialogue dataset) in 3 domains: appointment scheduling, city navigation, and weather information.", "labels": [], "entities": [{"text": "Stanford Multi-Domain (SMD) human-human goal-oriented dialogue dataset", "start_pos": 11, "end_pos": 81, "type": "DATASET", "confidence": 0.6925407383177016}, {"text": "appointment scheduling", "start_pos": 97, "end_pos": 119, "type": "TASK", "confidence": 0.7465105056762695}, {"text": "city navigation", "start_pos": 121, "end_pos": 136, "type": "TASK", "confidence": 0.7217699587345123}]}, {"text": "Each dialogue comes with knowledge base snippet from the underlying domain-specific API.", "labels": [], "entities": []}, {"text": "For LAED training, we use MetaLWOz (), a human-human goal-oriented dialogue corpus specifically designed for various meta-learning and pre-training purposes.", "labels": [], "entities": [{"text": "LAED training", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.8502437472343445}]}, {"text": "It contains conversations in 51 domains with several tasks in each of those.", "labels": [], "entities": []}, {"text": "The dialogues are collected using the Wizard-of-Oz method where human participants were given a problem domain and a specific task.", "labels": [], "entities": []}, {"text": "No domain-specific APIs or knowledge bases were available for the participants, and in the actual dialogues they were free to use fictional names and entities in a consistent way.", "labels": [], "entities": []}, {"text": "The dataset totals more than 40, 000 dialogues, with the average length of 11.9 turns.", "labels": [], "entities": []}, {"text": "Our few-shot setup is as follows.", "labels": [], "entities": []}, {"text": "Given the target domain, we first train LAED models (a dialoguelevel DI-VST and an utterance-level DI-VAE, both of the size 10 \u00d7 5) on the MetaLWOz datasethere we exclude from training every domain that might overlap with the target one.", "labels": [], "entities": [{"text": "MetaLWOz datasethere", "start_pos": 139, "end_pos": 159, "type": "DATASET", "confidence": 0.8508253693580627}]}, {"text": "Next, using the LAED encoders, we train a Few-Shot Dialogue Generation model on all the SMD source domains.", "labels": [], "entities": [{"text": "SMD source domains", "start_pos": 88, "end_pos": 106, "type": "TASK", "confidence": 0.8845438758532206}]}, {"text": "We use a random sample (1% to 10%) of the target domain utterances together with their contexts as seed data.", "labels": [], "entities": []}, {"text": "We incorporate KB information into our model by simply serializing the records and prepending them to the dialogue context, ending up with a setup similar to CopyNet in (.", "labels": [], "entities": []}, {"text": "For the NLU ZSDG setup, we use 1000 random seed utterances from each source domain and 200 utterances from the target domain 2 . For evaluation, we follow the approach of  and report BLEU and Entity F1 scores -means/variances over 10 runs.", "labels": [], "entities": [{"text": "NLU ZSDG", "start_pos": 8, "end_pos": 16, "type": "DATASET", "confidence": 0.8134669661521912}, {"text": "BLEU", "start_pos": 183, "end_pos": 187, "type": "METRIC", "confidence": 0.9967251420021057}, {"text": "Entity F1 scores -means/variances", "start_pos": 192, "end_pos": 225, "type": "METRIC", "confidence": 0.8404110627514976}]}], "tableCaptions": []}