{"title": [{"text": "An Arabic Multi-Domain Spoken Language Understanding System", "labels": [], "entities": [{"text": "Arabic Multi-Domain Spoken Language Understanding", "start_pos": 3, "end_pos": 52, "type": "TASK", "confidence": 0.48207510113716123}]}], "abstractContent": [{"text": "In this paper, we suggest the generalization of an Arabic Spoken Language Understanding (SLU) system in a multi-domain human-machine dialog.", "labels": [], "entities": []}, {"text": "We are interested particularly in domain portability of SLU system related to both structured (DBMS) and unstructured data (Information Extraction), related to four domains.", "labels": [], "entities": [{"text": "domain portability", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.7007249593734741}]}, {"text": "In this work, we used the thematic approach for four domains which are School Management, Medical Diagnostics, Consultation domain and Question-Answering domain (DAWQAS).", "labels": [], "entities": []}, {"text": "We should note that two kinds of classifiers are used in our experiments: sta", "labels": [], "entities": []}], "introductionContent": [{"text": "With the increasing spread of internet content, there is a mutually growing number of web applications pushing human being in a race against time to exploit and to master all of these applications.", "labels": [], "entities": []}, {"text": "In such a situation, a human-machine dialogue system is needed to assist humans for acquiring information efficiently and accurately.", "labels": [], "entities": []}, {"text": "However, the existing dialogue systems cannot coverall application domains.", "labels": [], "entities": []}, {"text": "That is why, we tackle in this paper the multi-domain task.", "labels": [], "entities": []}, {"text": "We should note that a little initial work with regard to the multi-domain problem has been presented in, which remains an open issue.", "labels": [], "entities": []}, {"text": "We have witnessed recently a renewed interest in the extension of application domain, where some systems use Latent Semantic Mapping (LSM) for the identification of any abrupt change towards another application).", "labels": [], "entities": [{"text": "Latent Semantic Mapping (LSM)", "start_pos": 109, "end_pos": 138, "type": "TASK", "confidence": 0.7052321781714758}]}, {"text": "In other works, a Markovian decision-making process was considered for the selection of an application among several ones ( or the extension to anew application in the Web (.", "labels": [], "entities": []}, {"text": "While in ( ), a study related to comparable applications (within the same domain) has been conducted.", "labels": [], "entities": []}, {"text": "In the case of more than two applications, we can mention task-based applications (where the dialogue is finalized and specific to a given domain) as presented in ( ) or managing specific applications of the Web ().", "labels": [], "entities": []}, {"text": "In (), the principle of adaptation from application to another has been applied, where the system is trained in the first application and tested in the second one.", "labels": [], "entities": []}, {"text": "The majority of researches done on multi-domain are dealing with domains structured within DBMS() such as (Information on the schedules of trains, planes, tourism, car navigation, weather information, Guide of TV program, chat, etc).", "labels": [], "entities": [{"text": "DBMS", "start_pos": 91, "end_pos": 95, "type": "DATASET", "confidence": 0.9319597482681274}, {"text": "car navigation", "start_pos": 164, "end_pos": 178, "type": "TASK", "confidence": 0.7420816719532013}]}, {"text": "We aim to provide a portable system, with minimal intervention from experts, across four domains.", "labels": [], "entities": []}, {"text": "Three domains are based on information extraction, which are Medical Diagnostic, Diverse Consultation and Question-Answering (DAWQAS) 1 domains, in addition to the University Schooling Management domain which is based on database information retrieval.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 27, "end_pos": 49, "type": "TASK", "confidence": 0.7918654978275299}]}, {"text": "In this paper, we first present, in section 2, an SLU system based on thematic approach, followed by a description of the feature selection process as well as the dataset we prepared.", "labels": [], "entities": []}, {"text": "In section 3, we present experiments and the corresponding results, and we conclude in section 4.", "labels": [], "entities": []}, {"text": "Why talking about your weaknesses during a job interview is great for you: Samples of requests related to the four domains.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted experiments on SLU portability between two kinds of domains: DBMS Information Retrieval and Information Extraction.", "labels": [], "entities": [{"text": "SLU portability", "start_pos": 28, "end_pos": 43, "type": "TASK", "confidence": 0.9419126212596893}, {"text": "DBMS Information Retrieval", "start_pos": 74, "end_pos": 100, "type": "TASK", "confidence": 0.6785612305005392}, {"text": "Information Extraction", "start_pos": 105, "end_pos": 127, "type": "TASK", "confidence": 0.6804519295692444}]}, {"text": "The request is considered to be well understood if it is assigned a correct category.", "labels": [], "entities": []}, {"text": "We achieved a comparison between statistical methods (Pedregosa et al., 2011) and neural method   and 63%.", "labels": [], "entities": []}, {"text": "In addition, it is noticeable through results shown in tables 3, 4, 5 and 6 that it is unclear which features combination yields the best performance.", "labels": [], "entities": []}, {"text": "For instance, the absence of stop words gives the best performance for SGD while it doesn't for other classifiers.", "labels": [], "entities": [{"text": "SGD", "start_pos": 71, "end_pos": 74, "type": "TASK", "confidence": 0.8799163103103638}]}, {"text": "As shown in table 3, in the case of School application, the best performance was achieved by the Perceptron classifier, with a perfect result by using a word analyzer with or without Arabic stop words.", "labels": [], "entities": []}, {"text": "Whereas in table 4, for the medical application, the best result was performed by the SGD classifier, with an F1-score of 54% by also using the word analyzer and without removing the Arabic stop words.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 110, "end_pos": 118, "type": "METRIC", "confidence": 0.9990014433860779}]}, {"text": "shows results for the Consultations domain.", "labels": [], "entities": [{"text": "Consultations domain", "start_pos": 22, "end_pos": 42, "type": "DATASET", "confidence": 0.838334709405899}]}, {"text": "Note that both SGD and Logistic Regression classifiers achieved the best F1-score of 74% by using word analyzer.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.999036431312561}]}, {"text": "The SGD has performed equally by using either a unigram or bigram as input for the word analyzer, where the Logistic Regression has performed better with the trigram as an input.", "labels": [], "entities": [{"text": "word analyzer", "start_pos": 83, "end_pos": 96, "type": "TASK", "confidence": 0.6801437735557556}]}, {"text": "For the last application related to DAWQAS corpus, the best results have been achieved with both LSVC and Passive Aggressive classifiers with F1-score of 63%.", "labels": [], "entities": [{"text": "DAWQAS corpus", "start_pos": 36, "end_pos": 49, "type": "DATASET", "confidence": 0.8831872642040253}, {"text": "LSVC", "start_pos": 97, "end_pos": 101, "type": "METRIC", "confidence": 0.8848438262939453}, {"text": "F1-score", "start_pos": 142, "end_pos": 150, "type": "METRIC", "confidence": 0.9995536208152771}]}, {"text": "The first one has achieved equally by either filtering or not the Arabic stop words in plus to applying the word analyzer with a unigram as input.", "labels": [], "entities": []}, {"text": "For the latter classifier, the same analyzer was used but without filtering the     By comparing the performance of the different classifiers for the four domains, we can conclude that (i) the Arabic Stop words change the meaning or intent of utterance according the task and the domain.", "labels": [], "entities": []}, {"text": "(ii) There is no perfect classifier to perform an acceptable SLU portability across domains, especially for the Arabic language, which is known for its richness at the lexical level.(iii) There is not a perfect size fora corpus to be considered when porting to anew domain.", "labels": [], "entities": [{"text": "SLU portability", "start_pos": 61, "end_pos": 76, "type": "TASK", "confidence": 0.7868429720401764}]}, {"text": "Indeed, performance for Consult domain is better than DAWQAS though the Consult corpus is smaller.", "labels": [], "entities": [{"text": "DAWQAS", "start_pos": 54, "end_pos": 60, "type": "DATASET", "confidence": 0.8561198115348816}, {"text": "Consult corpus", "start_pos": 72, "end_pos": 86, "type": "DATASET", "confidence": 0.8973451852798462}]}], "tableCaptions": [{"text": " Table 2: Description of the four used corpora.", "labels": [], "entities": []}, {"text": " Table 3: Best performance for the School domain", "labels": [], "entities": []}, {"text": " Table 4: Best performance for the Medical domain", "labels": [], "entities": [{"text": "Medical domain", "start_pos": 35, "end_pos": 49, "type": "DATASET", "confidence": 0.9653274714946747}]}, {"text": " Table 5: Best performance for the Consult domain", "labels": [], "entities": []}, {"text": " Table 6: Best performance for the DAWQAS domain", "labels": [], "entities": [{"text": "DAWQAS", "start_pos": 35, "end_pos": 41, "type": "DATASET", "confidence": 0.8401313424110413}]}]}