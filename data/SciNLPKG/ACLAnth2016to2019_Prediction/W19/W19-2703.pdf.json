{"title": [{"text": "Acquiring Annotated Data with Cross-lingual Explicitation for Implicit Discourse Relation Classification", "labels": [], "entities": [{"text": "Acquiring", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.8137692809104919}, {"text": "Implicit Discourse Relation Classification", "start_pos": 62, "end_pos": 104, "type": "TASK", "confidence": 0.8490018993616104}]}], "abstractContent": [{"text": "Implicit discourse relation classification is one of the most challenging and important tasks in discourse parsing, due to the lack of con-nectives as strong linguistic cues.", "labels": [], "entities": [{"text": "Implicit discourse relation classification", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.8552979379892349}, {"text": "discourse parsing", "start_pos": 97, "end_pos": 114, "type": "TASK", "confidence": 0.709058091044426}]}, {"text": "A principle bottleneck to further improvement is the shortage of training data (ca. 18k instances in the Penn Discourse Treebank (PDTB)).", "labels": [], "entities": [{"text": "Penn Discourse Treebank (PDTB))", "start_pos": 105, "end_pos": 136, "type": "DATASET", "confidence": 0.95341424147288}]}, {"text": "(2017) proposed to acquire additional data by exploiting connectives in translation: human translators mark discourse relations which are implicit in the source language explicitly in the translation.", "labels": [], "entities": []}, {"text": "Using back-translations of such explicitated connectives improves discourse relation parsing performance.", "labels": [], "entities": [{"text": "discourse relation parsing", "start_pos": 66, "end_pos": 92, "type": "TASK", "confidence": 0.6505880554517111}]}, {"text": "This paper addresses the open question of whether the choice of the translation language matters, and whether multiple translations into different languages can be effectively used to improve the quality of the additional data.", "labels": [], "entities": []}], "introductionContent": [{"text": "Discourse relations connect two sentences/clauses to each other.", "labels": [], "entities": []}, {"text": "The identification of discourse relations is an important step in natural language understanding and is beneficial to various downstream NLP applications such as text summarization (), question answering (), machine translation (, and soon.", "labels": [], "entities": [{"text": "identification of discourse relations", "start_pos": 4, "end_pos": 41, "type": "TASK", "confidence": 0.813750609755516}, {"text": "natural language understanding", "start_pos": 66, "end_pos": 96, "type": "TASK", "confidence": 0.6474838753541311}, {"text": "text summarization", "start_pos": 162, "end_pos": 180, "type": "TASK", "confidence": 0.7569101750850677}, {"text": "question answering", "start_pos": 185, "end_pos": 203, "type": "TASK", "confidence": 0.8867758214473724}, {"text": "machine translation", "start_pos": 208, "end_pos": 227, "type": "TASK", "confidence": 0.8321686089038849}]}, {"text": "Discourse relations can be marked explicitly using a discourse connective or discourse adverbial such as \"because\", \"but\", \"however\", see example 1.", "labels": [], "entities": []}, {"text": "Explicitly marked relations are relatively easy to classify automatically (.", "labels": [], "entities": []}, {"text": "In example 2, the causal relation is not marked explicitly, and can only be inferred from the texts.", "labels": [], "entities": []}, {"text": "This second type of case is empirically even more common than explicitly marked relations (), but is much harder to classify automatically.", "labels": [], "entities": []}, {"text": "The difficulty in classifying implicit discourse relations stems from the lack of strong indicative cues.", "labels": [], "entities": []}, {"text": "Early work has already shown that implicit relations cannot be learned from explicit ones by just removing the discourse markers, which may lead to a meaning shift in the examples, making human-annotated relations currently the only reliable source for training implicit discourse relation classification.", "labels": [], "entities": [{"text": "implicit discourse relation classification", "start_pos": 262, "end_pos": 304, "type": "TASK", "confidence": 0.6687132865190506}]}, {"text": "Due to the limited size of available training data, several approaches have been proposed for acquiring additional training data using automatic methods (.", "labels": [], "entities": []}, {"text": "The most promising approach so far, , exploits the fact that human translators sometimes insert a connective in their translation even when a relation was implicit in the original text.", "labels": [], "entities": []}, {"text": "Using a back-translation method, Shi et al. showed that such instances can be used for acquiring additional labeled text.", "labels": [], "entities": []}, {"text": "however only used a single target langauge (French), and had no control over the quality of the labels extracted from backtranslated connectives.", "labels": [], "entities": []}, {"text": "In this paper, we therefore systematically compare the contribution of three target translation languages from different language families: French (a Romance language), German (from the Germanic language family) and Czech (a Slavic language).", "labels": [], "entities": []}, {"text": "As all three of these languages are part of the EuroParl corpus, this also allows us to directly test whether higher quality can be achieved by using those instances that were consistently explicitated in several languages.", "labels": [], "entities": [{"text": "EuroParl corpus", "start_pos": 48, "end_pos": 63, "type": "DATASET", "confidence": 0.9912161827087402}]}, {"text": "We use cross-lingual explicitation to acquire more reliable implicit discourse relation instances with separate arguments that are from adjacent sentences in a document, and conducted experiments on PDTB benchmark with multiple conventional settings including cross validation.", "labels": [], "entities": []}, {"text": "The experimental results show that the performance has been improved significantly with the additional training data, compared with the baseline systems.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Performances with different sets of additional data. Average accuracy of 10 runs (5 for cross validations)  are shown here with standard deviation in the brackets. Numbers in bold are significantly (p<0.05) better than the  PDTB only baseline with unpaired t-test.", "labels": [], "entities": [{"text": "Average", "start_pos": 63, "end_pos": 70, "type": "METRIC", "confidence": 0.9440829157829285}, {"text": "accuracy", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.9219109416007996}, {"text": "PDTB", "start_pos": 234, "end_pos": 238, "type": "DATASET", "confidence": 0.7888017892837524}]}]}