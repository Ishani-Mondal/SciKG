{"title": [{"text": "TLR at BSNLP2019: A Multilingual Named Entity Recognition System", "labels": [], "entities": [{"text": "TLR at BSNLP2019", "start_pos": 0, "end_pos": 16, "type": "DATASET", "confidence": 0.7078183889389038}, {"text": "Multilingual Named Entity Recognition", "start_pos": 20, "end_pos": 57, "type": "TASK", "confidence": 0.6303205043077469}]}], "abstractContent": [{"text": "This paper presents our participation at the shared task on multilingual named entity recognition at BSNLP2019.", "labels": [], "entities": [{"text": "multilingual named entity recognition at BSNLP2019", "start_pos": 60, "end_pos": 110, "type": "TASK", "confidence": 0.6083879222472509}]}, {"text": "Our strategy is based on a standard neural architecture for sequence labeling.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 60, "end_pos": 77, "type": "TASK", "confidence": 0.6353348195552826}]}, {"text": "In particular, we use a mixed model which combines multilingual-contextual and language-specific embeddings.", "labels": [], "entities": []}, {"text": "Our only submitted run is based on a voting schema using multiple models, one for each of the four languages of the task (Bulgarian, Czech, Polish, and Russian) and another for English.", "labels": [], "entities": []}, {"text": "Results for named entity recognition are encouraging for all languages, varying from 60% to 83% in terms of Strict and Relaxed metrics, respectively.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 12, "end_pos": 36, "type": "TASK", "confidence": 0.7245548168818156}, {"text": "Relaxed", "start_pos": 119, "end_pos": 126, "type": "METRIC", "confidence": 0.9413160681724548}]}], "introductionContent": [{"text": "Correctly detecting mentions of entities in text documents in multiple languages is a challenging task (.", "labels": [], "entities": [{"text": "detecting mentions of entities in text documents in multiple languages", "start_pos": 10, "end_pos": 80, "type": "TASK", "confidence": 0.8824304103851318}]}, {"text": "This is especially true when documents relate to news because of the huge range of topics covered by newspapers.", "labels": [], "entities": []}, {"text": "In this context, the shared task on multilingual named entity recognition (NER) proposes to participants to test their system under a multilingual setup.", "labels": [], "entities": [{"text": "multilingual named entity recognition (NER)", "start_pos": 36, "end_pos": 79, "type": "TASK", "confidence": 0.7891712018421718}]}, {"text": "Four languages are addressed in BSNLP2019: Bulgarian (bg), Czech (cz), Polish (pl), and Russian (ru).", "labels": [], "entities": [{"text": "BSNLP2019", "start_pos": 32, "end_pos": 41, "type": "DATASET", "confidence": 0.8648526668548584}]}, {"text": "Similarly to the first edition of this task in 2017 (, participants are required to recognize, normalize, and link entities from raw texts written in multiple languages.", "labels": [], "entities": []}, {"text": "Our participation is focused on the sole recognition of entities while other steps will be covered in our future work.", "labels": [], "entities": []}, {"text": "In order to build a unique NER system for multiple languages, we decided to contribute a solution based on an end-to-end system without (or almost without) language specific pre-processing.", "labels": [], "entities": []}, {"text": "We explored an existing neural architecture, the LSTM-CNNs-CRF (, initially proposed for NER in English.", "labels": [], "entities": []}, {"text": "This neural model is based on word embeddings to represent each token in a sentence.", "labels": [], "entities": []}, {"text": "In order to have a unique embedding space, we propose to use a transformerbased () contextual embedding called BERT (.", "labels": [], "entities": [{"text": "BERT", "start_pos": 111, "end_pos": 115, "type": "METRIC", "confidence": 0.9918900728225708}]}, {"text": "This pre-trained model includes multilingual representations that are context-aware.", "labels": [], "entities": []}, {"text": "However, as noted by, contextual embeddings provide multiple layers that are challenging to combine together.", "labels": [], "entities": []}, {"text": "To overcome this problem, we used the weighted average strategy they successfully tested using (.", "labels": [], "entities": []}, {"text": "The results of our participation are quite encouraging.", "labels": [], "entities": []}, {"text": "Regarding the Relaxed Partial metric, our run achieves 80.26% in average for the four languages and the two topics that compose the test collection.", "labels": [], "entities": []}, {"text": "In order to present comparative results against the state of the art, we run experiments using two extra datasets under the standard CoNLL evaluation setup.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows: Section 2 introduces the related work while Section 3 presents the proposed multi-lingual model.", "labels": [], "entities": []}, {"text": "Section 4 presents the results while conclusions are drawn in Section 5.", "labels": [], "entities": []}, {"text": "have recently redrawn the landscape of models for sequence labelling such as NER: the proposal of new architectures, the use of contextualized embeddings (, or even, the use of both of them (.", "labels": [], "entities": []}, {"text": "The use of contextualized embeddings is a clear advantage for several kinds of neural-based NER systems, however as pointed out by Reimers and Gurevych (2019) the combination of multiples vectors proposed by these models is computationally expensive.", "labels": [], "entities": []}], "datasetContent": [{"text": "We follow the configuration setup proposed by the task organizers.", "labels": [], "entities": []}, {"text": "Two topics, \"nord stream\" and \"ryanair\", were used to test our models.", "labels": [], "entities": [{"text": "ryanair", "start_pos": 31, "end_pos": 38, "type": "METRIC", "confidence": 0.9014931321144104}]}, {"text": "These topics include 1100 documents in the four languages.", "labels": [], "entities": []}, {"text": "Further details can be found in the 2019 shared task overview paper ().", "labels": [], "entities": []}, {"text": "For training, we have used the documents provided for the task but also the ones in Czech, Polish, and Russian from the previous round of same task in 2017 (.", "labels": [], "entities": []}, {"text": "We additionally added the training example form the CoNLL2003 (Sang and De Meulder, 1837) collection in English (13879 train, 3235 dev, and 3422 test sentences).", "labels": [], "entities": [{"text": "CoNLL2003 (Sang and De Meulder, 1837) collection", "start_pos": 52, "end_pos": 100, "type": "DATASET", "confidence": 0.947199922800064}]}, {"text": "Used metrics include the officially proposed metrics and standard metrics for the CoNLL2003 dataset (F1 metric).", "labels": [], "entities": [{"text": "CoNLL2003 dataset", "start_pos": 82, "end_pos": 99, "type": "DATASET", "confidence": 0.9803949296474457}, {"text": "F1", "start_pos": 101, "end_pos": 103, "type": "METRIC", "confidence": 0.9464334845542908}]}], "tableCaptions": [{"text": " Table 1: Evaluation results of our TLR submission. We have added extra results for the strict metric using each  single model based on one of the four languages.", "labels": [], "entities": [{"text": "TLR submission", "start_pos": 36, "end_pos": 50, "type": "TASK", "confidence": 0.7716891765594482}]}, {"text": " Table 2: Evaluation results on the CoNLL 2003 dataset,  an English only dataset.", "labels": [], "entities": [{"text": "CoNLL 2003 dataset", "start_pos": 36, "end_pos": 54, "type": "DATASET", "confidence": 0.9724454085032145}]}, {"text": " Table 3: Evaluation results on the BSNLP2017 and  CoNLL 2003 datasets, a multilingual dataset. Each row  represents a model learned with a fastText language  specific embedding.", "labels": [], "entities": [{"text": "BSNLP2017 and  CoNLL 2003 datasets", "start_pos": 36, "end_pos": 70, "type": "DATASET", "confidence": 0.8087161839008331}]}]}