{"title": [], "abstractContent": [], "introductionContent": [{"text": "The last few years have seen a surge in attention to various forms of abuse such as cyberbullying, hate speech, and scapegoating occurring on online platforms.", "labels": [], "entities": []}, {"text": "At the same time, there has been arise in interest in using Natural Language Processing (NLP) to address these issues at scaale.", "labels": [], "entities": []}, {"text": "However, in order to develop robust, long-term solutions for this problem, we require perspectives from diverse disciplines ranging from psychology, law, gender studies, communications, and critical race theory.", "labels": [], "entities": [{"text": "critical race theory", "start_pos": 190, "end_pos": 210, "type": "TASK", "confidence": 0.6388309498627981}]}, {"text": "Our goal with the Abusive Language Workshop is to provide a platform to facilitate the interdisciplinary conversations and collaborations necessary to thoughtfully address the issue of abuse at scale.", "labels": [], "entities": []}, {"text": "Each year, we choose a theme for our workshop that guides the talks and panel discussions at the workshop.", "labels": [], "entities": []}, {"text": "In previous years we focused on the policy aspect of online abuse and the stories and experiences of those who have received large amounts of online abuse.", "labels": [], "entities": []}, {"text": "The themes do not limit the original research presented at the workshop, rather it helps frame the research presented through the lens of its potential to address the concerns of the theme.", "labels": [], "entities": []}, {"text": "For this year, we have chosen to focus on human content rating, the practice of annotating and moderating data -an aspect which is often unspoken, assumed, and often forms the basis of the research conducted.", "labels": [], "entities": [{"text": "human content rating", "start_pos": 42, "end_pos": 62, "type": "TASK", "confidence": 0.5946220854918162}]}, {"text": "Human judgments of online abuse are critical for building training data for automated models, human-in-the-loop solutions that rely on crowd workers' ratings along with automated moderation, and embedding the evaluations of models into the cultural fabric.", "labels": [], "entities": []}, {"text": "Thus, human ratings in the context of toxicity in language raise important questions around the various socio-cultural biases that affect those ratings, but also on the impact it has on the psychological safety of the raters themselves.", "labels": [], "entities": []}, {"text": "In order to situate our conversation around this theme, we have confirmed four keynote speakers and panelists who are leading experts on content moderation, crowd work, and the impact of algorithmic solutions on people: Katherine Lo, University of California, Irvine Kat Lois the Content Moderation Program Lead at Meedan and visiting researcher at the University of California, Irvine specializing in online moderation and harassment.", "labels": [], "entities": []}, {"text": "Lo consults with technology, social media, and game companies on platform policy and enforcement.", "labels": [], "entities": [{"text": "platform policy and enforcement", "start_pos": 65, "end_pos": 96, "type": "TASK", "confidence": 0.7190989181399345}]}, {"text": "She also serves on the advisory board for nonprofits and advocacy organizations that focus on online harassment and mental health.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}