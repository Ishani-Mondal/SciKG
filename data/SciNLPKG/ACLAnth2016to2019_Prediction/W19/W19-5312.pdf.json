{"title": [], "abstractContent": [{"text": "We describe here the experiments we performed for the news translation shared task of WMT 2019.", "labels": [], "entities": [{"text": "news translation shared task", "start_pos": 54, "end_pos": 82, "type": "TASK", "confidence": 0.7848054692149162}, {"text": "WMT 2019", "start_pos": 86, "end_pos": 94, "type": "DATASET", "confidence": 0.8094391524791718}]}, {"text": "We focused on the new German-to-French language direction, and mostly used current standard approaches to develop a Neu-ral Machine Translation system.", "labels": [], "entities": [{"text": "Neu-ral Machine Translation", "start_pos": 116, "end_pos": 143, "type": "TASK", "confidence": 0.7353363235791525}]}, {"text": "We make use of the Tensor2Tensor implementation of the Transformer model.", "labels": [], "entities": []}, {"text": "After carefully cleaning the data and noting the importance of the good use of recent monolingual data for the task, we obtain our final result by combining the output of a diverse set of trained models through the use of their \"checkpoint agreement\".", "labels": [], "entities": []}], "introductionContent": [{"text": "The 2019 edition of WMT's news translation shared tasks was proposing the German-French pair for the first time.", "labels": [], "entities": [{"text": "WMT's news translation shared tasks", "start_pos": 20, "end_pos": 55, "type": "TASK", "confidence": 0.8004296322663625}]}, {"text": "The inclusion of two not-soclosely related languages which both have a richer morphology than English is interesting and can in theory provide additional challenges to the more English-X pairs most frequently used for Machine Translation.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 218, "end_pos": 237, "type": "TASK", "confidence": 0.8323122262954712}]}, {"text": "Due to the rather large computation time investment required by the training of a modern Neural Machine Translation system, we focused on the German-to-French direction.", "labels": [], "entities": [{"text": "Neural Machine Translation", "start_pos": 89, "end_pos": 115, "type": "TASK", "confidence": 0.7613314191500345}]}, {"text": "Overall, our submission mostly relied on carefully following current best practices for Neural MT, while trying to analyze results and find simple ways to improve them.", "labels": [], "entities": [{"text": "Neural MT", "start_pos": 88, "end_pos": 97, "type": "TASK", "confidence": 0.8437624573707581}]}, {"text": "We used a Transformer sequence-to-sequence model () as our base system.", "labels": [], "entities": []}, {"text": "After cleaning and selecting data, we ran experiments with different settings, and finally tried to combine the results of all of these models.", "labels": [], "entities": []}, {"text": "In these combination, we tried to use what we dubbed \"checkpoint agreement\" as a proxy to measure the confidence of a system in its translation.", "labels": [], "entities": []}, {"text": "We could obtain a final improvement of more than +3.5 BLEU over the baseline trained only on bilingual data.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 54, "end_pos": 58, "type": "METRIC", "confidence": 0.9988033771514893}]}, {"text": "However, the greater part of this improvement was simply due to the addition of relevant monolingual data.", "labels": [], "entities": []}], "datasetContent": [{"text": "We ran a first baseline experiment using the setting described in section 2 and the cleaned bilingual data of section3.", "labels": [], "entities": []}, {"text": "We obtained a cased BLEU score of 33.18.", "labels": [], "entities": [{"text": "cased", "start_pos": 14, "end_pos": 19, "type": "METRIC", "confidence": 0.9325352907180786}, {"text": "BLEU score", "start_pos": 20, "end_pos": 30, "type": "METRIC", "confidence": 0.9520675539970398}]}, {"text": "Manual inspection of the results showed us that the trained model could have serious trouble translating terms or personal names who had only recently appeared in the news.", "labels": [], "entities": [{"text": "translating terms or personal names who had only recently appeared in the news", "start_pos": 93, "end_pos": 171, "type": "TASK", "confidence": 0.7127420397905203}]}, {"text": "A typical example would be the translation of German \"Gelbwesten\" (\"Yellow vests\") into French \"Gibiers jaunes\" (\"Yellow game 5 \"), instead of the correct \"Gilets jaunes\".", "labels": [], "entities": [{"text": "translation of German \"Gelbwesten", "start_pos": 31, "end_pos": 64, "type": "TASK", "confidence": 0.8238993167877198}]}, {"text": "The \"Yellow vests\" area French protest movement that appeared during 2018 fall, and has received much attention in news from that time into 2019.", "labels": [], "entities": []}, {"text": "The collocation \"Gilets jaunes\" is therefore unlikely to appear in the bilingual training data (which is typically older), which explains why the model seems to prefer the similar (in terms of subwords units) \"Gibiers jaunes\".", "labels": [], "entities": []}, {"text": "Another common problem was the literal translation of German terms that are normally quoted as-is in French News.", "labels": [], "entities": [{"text": "literal translation of German terms", "start_pos": 31, "end_pos": 66, "type": "TASK", "confidence": 0.7748874604701996}, {"text": "French News", "start_pos": 101, "end_pos": 112, "type": "DATASET", "confidence": 0.8045439720153809}]}, {"text": "For example, the German political Party \"Die Linke\" (\"The Left\") was translated as \"le parti de gauche\" (\"the left-wing party\"), even though French journalists usually refer to it with its German name (\"le parti Die Linke\").", "labels": [], "entities": []}, {"text": "We first evaluate this idea with the checkpoints of a single model.", "labels": [], "entities": []}, {"text": "The first thing to verify is whether different checkpoints actually produce different translations.", "labels": [], "entities": []}, {"text": "Using the same checkpoints as in section 4.3 (ie. 20 one-hour-spaced checkpoints), we compute the translations they generate for the development set.", "labels": [], "entities": []}, {"text": "We find that for 9% of the input sentences, the 20 checkpoints generate the same translation.", "labels": [], "entities": []}, {"text": "For 2% of the input sentences, they all produce distinct translations.", "labels": [], "entities": []}, {"text": "For the remaining 89% of inputs, there therefore exists at least one translation candidate generated by at least two checkpoints.", "labels": [], "entities": []}, {"text": "If, for each input, we select the most often generated translation candidate, we obtain a BLEU score improvement of +0.3 (\"selection by checkpoint agreement\" in table 1).", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 90, "end_pos": 100, "type": "METRIC", "confidence": 0.9717398583889008}]}, {"text": "This is a bit better than simply doing checkpoint averaging, but of course it takes 20 times more decoding time to obtain a translation.", "labels": [], "entities": []}], "tableCaptions": []}