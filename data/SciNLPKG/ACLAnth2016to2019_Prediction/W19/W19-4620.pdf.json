{"title": [{"text": "Arabic Tweet-Act: Speech Act Recognition for Arabic Asynchronous Conversations", "labels": [], "entities": [{"text": "Speech Act Recognition", "start_pos": 18, "end_pos": 40, "type": "TASK", "confidence": 0.5567388037840525}]}], "abstractContent": [{"text": "Speech acts are the actions that a speaker intends when performing an utterance within conversations.", "labels": [], "entities": []}, {"text": "In this paper, we proposed speech act classification for asynchronous conversations on Twitter using multiple machine learning methods including SVM and deep neural networks.", "labels": [], "entities": [{"text": "speech act classification", "start_pos": 27, "end_pos": 52, "type": "TASK", "confidence": 0.6474690238634745}]}, {"text": "We applied the proposed methods on the ArSAS tweets dataset.", "labels": [], "entities": [{"text": "ArSAS tweets dataset", "start_pos": 39, "end_pos": 59, "type": "DATASET", "confidence": 0.9252241452534994}]}, {"text": "The obtained results show that superiority of deep learning methods compared to SVMs, where Bi-LSTM managed to achieve an accuracy of 87.5% and a macro-averaged F1 score 61.5%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.999426007270813}, {"text": "F1 score", "start_pos": 161, "end_pos": 169, "type": "METRIC", "confidence": 0.9755446016788483}]}, {"text": "We believe that our results are the first to be reported on the task of speech-act recognition for asynchronous conversations on Ara-bic Twitter.", "labels": [], "entities": [{"text": "speech-act recognition", "start_pos": 72, "end_pos": 94, "type": "TASK", "confidence": 0.7336571216583252}, {"text": "Ara-bic Twitter", "start_pos": 129, "end_pos": 144, "type": "DATASET", "confidence": 0.8642737567424774}]}], "introductionContent": [{"text": "Speech act in linguistics is defined as the action that a speaker intends when performing an utterance such as asking question, recommending something, greeting or thanking, expressing a thought or making suggestion.", "labels": [], "entities": [{"text": "Speech act in linguistics is defined as the action that a speaker intends when performing an utterance such as asking question, recommending something, greeting or thanking, expressing a thought or making suggestion", "start_pos": 0, "end_pos": 215, "type": "Description", "confidence": 0.837774623291833}]}, {"text": "Knowing speakers intention within a conversation is considered the one of the recent active research in Natural Language Understanding (NLU); which is called speech act recognition/classification.", "labels": [], "entities": [{"text": "Knowing speakers intention within a conversation", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.7812604109446207}, {"text": "Natural Language Understanding (NLU)", "start_pos": 104, "end_pos": 140, "type": "TASK", "confidence": 0.7677772144476572}, {"text": "speech act recognition/classification", "start_pos": 158, "end_pos": 195, "type": "TASK", "confidence": 0.7527263760566711}]}, {"text": "Speech act classification has been utilized in different Natural Language Processing (NLP) applications, such as summarization (), rumors verification, hate speech or cyberbullying detection, and in the educational forum ().", "labels": [], "entities": [{"text": "Speech act classification", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6944532593091329}, {"text": "summarization", "start_pos": 113, "end_pos": 126, "type": "TASK", "confidence": 0.9935190081596375}, {"text": "rumors verification", "start_pos": 131, "end_pos": 150, "type": "TASK", "confidence": 0.7568652629852295}, {"text": "hate speech or cyberbullying detection", "start_pos": 152, "end_pos": 190, "type": "TASK", "confidence": 0.6365519881248474}]}, {"text": "Speech act classification task is usually treated as a multi-class classification problem.", "labels": [], "entities": [{"text": "Speech act classification task", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7459644377231598}, {"text": "multi-class classification", "start_pos": 55, "end_pos": 81, "type": "TASK", "confidence": 0.7426452040672302}]}, {"text": "Most of researchers tend to use machine learning (ML) paradigm for the task in order to analyze and utilize the massive amount of data that found in online conversations.", "labels": [], "entities": []}, {"text": "They usually apply their experiments to two type of conversations: 1) synchronous conversations, where the conversation is one-to-one, such as dialogues, chatting, meetings and transcribed phone conversations; and 2) asynchronous conversations, where the conversation is one-to-many such as emails, discussion forums and social media.", "labels": [], "entities": []}, {"text": "Existing work on speech act classification mostly focuses on English language, with some focus on other languages such as German, French and Korean.", "labels": [], "entities": [{"text": "speech act classification", "start_pos": 17, "end_pos": 42, "type": "TASK", "confidence": 0.7073246439297994}]}, {"text": "Moreover, these studies have been conducted for both synchronous and asynchronous conversations.", "labels": [], "entities": []}, {"text": "Limited studies have tackled this task for Arabic, and all focusing on synchronous conversations.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, there is no work so far for Arabic speech act classification for asynchronous conversations, such as that on social media.", "labels": [], "entities": [{"text": "Arabic speech act classification", "start_pos": 58, "end_pos": 90, "type": "TASK", "confidence": 0.5998072624206543}]}, {"text": "Twitter has become a communication medium containing a massive amount of data suitable for social and behavioural studies.", "labels": [], "entities": []}, {"text": "Communication between users in Twitter can be considered as asynchronous conversations, within which people post questions, express feelings, recommend, request, report, or claim; all of which can be considered speech acts.", "labels": [], "entities": []}, {"text": "Classifying the speech act of tweets can aid in understanding the intentions behind users posts, analyzing Twitter content, and understanding how users interact on social media.", "labels": [], "entities": [{"text": "Classifying the speech act of tweets", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.8115254342556}]}, {"text": "Recently, an Arabic speech-act and sentiment corpus (ArSAS) of tweets corpus was released.", "labels": [], "entities": [{"text": "ArSAS", "start_pos": 53, "end_pos": 58, "type": "METRIC", "confidence": 0.7989174127578735}]}, {"text": "It contains more than 21K tweets, annotated with six speech acts.", "labels": [], "entities": []}, {"text": "In this paper, this corpus is used to evaluate the effectiveness of different supervised ML approaches for speech act classification for Arabic tweets.", "labels": [], "entities": [{"text": "ML", "start_pos": 89, "end_pos": 91, "type": "TASK", "confidence": 0.9585728645324707}, {"text": "speech act classification", "start_pos": 107, "end_pos": 132, "type": "TASK", "confidence": 0.6290679375330607}]}, {"text": "In our work, we proposed two approaches based on SVM and multiple deep learning models to classify Arabic tweets into speech act labels.", "labels": [], "entities": [{"text": "classify Arabic tweets into speech act labels", "start_pos": 90, "end_pos": 135, "type": "TASK", "confidence": 0.7581929564476013}]}, {"text": "Our results show that Bi-LSTM models achieves the highest performance overall and over each of the individual speech-act classes, where it achieves an accuracy of 87.5% and a macro-F1 of 0.615.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 151, "end_pos": 159, "type": "METRIC", "confidence": 0.999414324760437}]}], "datasetContent": [{"text": "We utilized the recently published tweets corpus \"Arabic Speech Act and Sentiment\" (ArSAS) for our experimentation (.", "labels": [], "entities": [{"text": "Arabic Speech Act and Sentiment\" (ArSAS)", "start_pos": 50, "end_pos": 90, "type": "TASK", "confidence": 0.5685179829597473}]}, {"text": "ArSAS contains a large set of 21,081 Arabic tweets in different Arabic dialects and annotated by six speech act classes: Assertion, Recommendation, Expression, Question, Request, and Miscellaneous.", "labels": [], "entities": []}, {"text": "The tweets in the corpus covers 20 topics including long-standing topics, events and entities (celebrities or organization).", "labels": [], "entities": []}, {"text": "shows few examples of tweets in the corpus with their corresponding speech act label.", "labels": [], "entities": []}, {"text": "The size of samples in each speech acts class varies a lot in ArSAS corpus, ranging between 60 samples to 11.7K samples per class.", "labels": [], "entities": [{"text": "ArSAS corpus", "start_pos": 62, "end_pos": 74, "type": "DATASET", "confidence": 0.9153162837028503}]}, {"text": "The smallest two classes are miscellaneous and recommendation classes that have only 60 and 109 tweets respectively.", "labels": [], "entities": []}, {"text": "Therefore, we decided to merge these two classes into one and called it miscellaneous.", "labels": [], "entities": []}, {"text": "The final distribution of the five classes in the corpus is: expression (11734), assertion (8233), question (752), request (183), and miscellaneous (169).", "labels": [], "entities": []}, {"text": "For measuring the performance of our approaches, we split the data into five folds and applied 5-fold cross validation for training and testing.", "labels": [], "entities": []}, {"text": "Data are split into folds over the class level, where we insure that 20% of the samples of each class exists in each fold.", "labels": [], "entities": []}, {"text": "This was essential step to ensure the presence of samples from the small classes in each fold.", "labels": [], "entities": []}, {"text": "For evaluation, three scores are applied: accuracy, micro F-score, and macro F-score.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9997599720954895}, {"text": "micro F-score", "start_pos": 52, "end_pos": 65, "type": "METRIC", "confidence": 0.7353684902191162}, {"text": "F-score", "start_pos": 77, "end_pos": 84, "type": "METRIC", "confidence": 0.5548301339149475}]}, {"text": "Accuracy and micro-F1 should demonstrate the overall performance of the approaches, while macro-F1 would indicate the average performance of the approaches over each class individually.: Comparison between different deep learning architectures for Arabic speech act classification in term of macro-averaged F1, micro-F1 and accuracy reports the results obtained when applying SVM classifier for our task using different sets of features on the ArSAS dataset with 5-fold cross-validation.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9923581480979919}, {"text": "Arabic speech act classification", "start_pos": 248, "end_pos": 280, "type": "TASK", "confidence": 0.5875278860330582}, {"text": "accuracy", "start_pos": 324, "end_pos": 332, "type": "METRIC", "confidence": 0.9993423819541931}, {"text": "ArSAS dataset", "start_pos": 444, "end_pos": 457, "type": "DATASET", "confidence": 0.9361604154109955}]}, {"text": "As shown, the performance of different set of features is almost similar, and the performance when applying all the set of features achieves the best results of accuracy 86.5%, micro-F1 of 0.862, and macro-F1 of 0.532.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 161, "end_pos": 169, "type": "METRIC", "confidence": 0.9994472861289978}]}, {"text": "While the overall performance is relatively high, the performance for some of the classes is considerably low.", "labels": [], "entities": []}, {"text": "This could be explained as a reason to the high imbalance of our classes, where some of the classes (such as 'miscellaneous', 'requests', and 'questions') are tiny compared to the two major classes 'expression' and 'assertion'.", "labels": [], "entities": []}, {"text": "Actually, nearly 90% of the samples in the classes miscellaneous and request were incorrectly classified.", "labels": [], "entities": []}, {"text": "These results are comparable to the state-ofthe-art in other languages such as English.", "labels": [], "entities": []}, {"text": "Comparing our work to the work by (Vosoughi and Roy, 2016b) and (Zhang et al., 2011) for speech act classification for English tweets, they report in term of micro F1 (0.69 and 0.70) respectively, and they also explain this due to the high imbalance of classes.", "labels": [], "entities": [{"text": "speech act classification", "start_pos": 89, "end_pos": 114, "type": "TASK", "confidence": 0.672794500986735}, {"text": "F1", "start_pos": 164, "end_pos": 166, "type": "METRIC", "confidence": 0.7410333752632141}]}, {"text": "Our achieved micro-F1 is even higher 0.86.", "labels": [], "entities": []}, {"text": "This might indicate the suitability of using the same techniques -used for English speech act classification-for the Arabic task.", "labels": [], "entities": [{"text": "English speech act classification-for", "start_pos": 75, "end_pos": 112, "type": "TASK", "confidence": 0.5676152929663658}]}, {"text": "reports the results obtained when applying seven different architectures of RNN and CNN for Arabic speech act classification on the ArSAS dataset with 5-fold cross-validation.", "labels": [], "entities": [{"text": "RNN", "start_pos": 76, "end_pos": 79, "type": "DATASET", "confidence": 0.9160287976264954}, {"text": "Arabic speech act classification", "start_pos": 92, "end_pos": 124, "type": "TASK", "confidence": 0.5516109392046928}, {"text": "ArSAS dataset", "start_pos": 132, "end_pos": 145, "type": "DATASET", "confidence": 0.9275397062301636}]}, {"text": "As shown, the performance of most of the models is close to those obtained by the SVM models in terms of accuracy, but consistently higher when measured using macro-F1.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9995249509811401}]}, {"text": "The BiLSTM and the BiLSTM on top of CNN architectures achieved significantly higher results in terms of macro-F1 compared to all the other models, which indicates better performance on the class level.", "labels": [], "entities": []}, {"text": "The best performing model was the BiLSTM model with an accuracy of 87.5%, micro-F1 of 0.86, and macro-F1 of 0.615.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.999681830406189}, {"text": "micro-F1", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.950842559337616}]}, {"text": "This confirms the effectiveness of using the bidirectional LSTM to capture the context in the tweet, which the miscellaneous class actually need.", "labels": [], "entities": []}, {"text": "Additionally, BiLSTM succeeded in recognizing both question and request classes better than any other model.", "labels": [], "entities": []}, {"text": "shows the performance on the best performing model using BiLSTM on each of the classes individually.", "labels": [], "entities": []}, {"text": "As shown, the performance over the two large classes 'assertion' and 'expression' is high (0.9 and 0.87 F1 respectively) compared to the other classes.", "labels": [], "entities": [{"text": "F1", "start_pos": 104, "end_pos": 106, "type": "METRIC", "confidence": 0.9957630634307861}]}, {"text": "The 'request' class achieved the lowest performance (0.2 F1).", "labels": [], "entities": [{"text": "F1", "start_pos": 57, "end_pos": 59, "type": "METRIC", "confidence": 0.995189905166626}]}, {"text": "This shows the challenge of recognising the speech act in asynchronous conversations for some of the in-   While our performance is comparable to performance in other languages, we believe there is still large room for improving the performance.", "labels": [], "entities": []}, {"text": "We hope that our work would be considered as a baseline for future work on speech act classification for Arabic.", "labels": [], "entities": [{"text": "speech act classification", "start_pos": 75, "end_pos": 100, "type": "TASK", "confidence": 0.6958033939202627}]}], "tableCaptions": [{"text": " Table 2: Neural network hyper-parameters", "labels": [], "entities": []}, {"text": " Table 3: The performance of SVM for Arabic speech act classification using different sets of features", "labels": [], "entities": [{"text": "Arabic speech act classification", "start_pos": 37, "end_pos": 69, "type": "TASK", "confidence": 0.658342219889164}]}, {"text": " Table 4: Comparison between different deep learning architectures for Arabic speech act classification in term of  macro-averaged F1, micro-F1 and accuracy", "labels": [], "entities": [{"text": "Arabic speech act classification", "start_pos": 71, "end_pos": 103, "type": "TASK", "confidence": 0.6248369365930557}, {"text": "F1", "start_pos": 131, "end_pos": 133, "type": "METRIC", "confidence": 0.8740711212158203}, {"text": "accuracy", "start_pos": 148, "end_pos": 156, "type": "METRIC", "confidence": 0.9993793964385986}]}, {"text": " Table 5: The performance of best performing BiLSTM  model on each class", "labels": [], "entities": []}, {"text": " Table 6: The best performing SVM model and neural  network architecture on the ArSAS dataset", "labels": [], "entities": [{"text": "ArSAS dataset", "start_pos": 80, "end_pos": 93, "type": "DATASET", "confidence": 0.9525268077850342}]}]}