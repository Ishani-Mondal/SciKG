{"title": [{"text": "Learning to Explicitate Connectives with Seq2Seq Network for Implicit Discourse Relation Classification", "labels": [], "entities": [{"text": "Implicit Discourse Relation", "start_pos": 61, "end_pos": 88, "type": "TASK", "confidence": 0.7059646844863892}]}], "abstractContent": [{"text": "Implicit discourse relation classification is one of the most difficult steps in discourse parsing.", "labels": [], "entities": [{"text": "Implicit discourse relation classification", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.8320242762565613}, {"text": "discourse parsing", "start_pos": 81, "end_pos": 98, "type": "TASK", "confidence": 0.6990387141704559}]}, {"text": "The difficulty stems from the fact that the coherence relation must be inferred based on the content of the discourse relational arguments.", "labels": [], "entities": []}, {"text": "Therefore, an effective encoding of the relational arguments is of crucial importance.", "labels": [], "entities": []}, {"text": "We here propose anew model for implicit discourse relation classification, which consists of a classifier, and a sequence-to-sequence model which is trained to generate a representation of the discourse relational arguments by trying to predict the relational arguments including a suitable implicit connective.", "labels": [], "entities": [{"text": "implicit discourse relation classification", "start_pos": 31, "end_pos": 73, "type": "TASK", "confidence": 0.6736134588718414}]}, {"text": "Training is possible because such implicit connectives have been annotated as part of the PDTB corpus.", "labels": [], "entities": [{"text": "PDTB corpus", "start_pos": 90, "end_pos": 101, "type": "DATASET", "confidence": 0.9564688503742218}]}, {"text": "Along with a memory network, our model could generate more refined representations for the task.", "labels": [], "entities": []}, {"text": "And on the now standard 11-way classification, our method out-performs the previous state of the art systems on the PDTB benchmark on multiple settings including cross validation.", "labels": [], "entities": [{"text": "PDTB benchmark", "start_pos": 116, "end_pos": 130, "type": "DATASET", "confidence": 0.9512487053871155}]}], "introductionContent": [{"text": "Discourse relations describe the logical relation between two sentences/clauses.", "labels": [], "entities": []}, {"text": "When understanding a text, humans infer discourse relation between text segmentations.", "labels": [], "entities": []}, {"text": "They reveal the structural organization of text, and allow for additional inferences.", "labels": [], "entities": []}, {"text": "Many natural language processing tasks, such as machine translation, question-answering, automatic summarization, sentiment analysis, and sentence embedding learning, can also profit from having access to discourse relation information.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.7435632944107056}, {"text": "sentiment analysis", "start_pos": 114, "end_pos": 132, "type": "TASK", "confidence": 0.9435608685016632}, {"text": "sentence embedding learning", "start_pos": 138, "end_pos": 165, "type": "TASK", "confidence": 0.6786756912867228}]}, {"text": "Recent years have seen more and more works on this topic, including two CoNNL shared tasks (.", "labels": [], "entities": []}, {"text": "Penn Discourse Tree Bank (, PDTB) provides lexically-grounded annotations of discourse relations and their two discourse relational arguments (i.e., two text spans).", "labels": [], "entities": [{"text": "Penn Discourse Tree Bank (, PDTB)", "start_pos": 0, "end_pos": 33, "type": "DATASET", "confidence": 0.9583147242665291}]}, {"text": "Discourse relations are sometimes signaled by explicit discourse markers (e.g., because, but).", "labels": [], "entities": []}, {"text": "Example 1 shows an explicit discourse relation marked by \"because\"; the presence of the connective makes it possible to classify the discourse relation with high reliability: reported an accuracy of 93.09% for 4-way classification of explicits.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 187, "end_pos": 195, "type": "METRIC", "confidence": 0.999409556388855}]}, {"text": "Discourse relations are however not always marked by an explicit connective.", "labels": [], "entities": []}, {"text": "In fact, implicit discourse relations (i.e. relations not marked by an explicit discourse cue) outnumber explicit discourse relations in naturally occurring text.", "labels": [], "entities": []}, {"text": "Readers can still infer these implicit relations, but automatic classification becomes a lot more difficult in these cases, and represents the main bottleneck in discourse parsing today.", "labels": [], "entities": [{"text": "automatic classification", "start_pos": 54, "end_pos": 78, "type": "TASK", "confidence": 0.6800137460231781}, {"text": "discourse parsing", "start_pos": 162, "end_pos": 179, "type": "TASK", "confidence": 0.7061686217784882}]}, {"text": "Example 2 shows an implicit contrastive relation which can be inferred from the two text spans that have been marked Arg1 and Arg2.", "labels": [], "entities": [{"text": "Arg1", "start_pos": 117, "end_pos": 121, "type": "METRIC", "confidence": 0.9772918224334717}, {"text": "Arg2", "start_pos": 126, "end_pos": 130, "type": "METRIC", "confidence": 0.7336219549179077}]}, {"text": "When annotating implicit relations in the PDTB, annotators were asked to first insert a connective which expresses the relation, and then annotate the relation label.", "labels": [], "entities": []}, {"text": "This procedure was introduced to achieve higher inter-annotator agreement for implicit relations between human annotators.", "labels": [], "entities": []}, {"text": "In the approach taken in this paper, our model mimics this procedure by being trained to explicitate the discouse relation, i.e. to insert a connective as a secondary task.", "labels": [], "entities": []}, {"text": "The key in implicit discourse relation classification lies in extracting relevant information for the relation label from (the combination of) the discourse relational arguments.", "labels": [], "entities": [{"text": "implicit discourse relation classification", "start_pos": 11, "end_pos": 53, "type": "TASK", "confidence": 0.661608375608921}]}, {"text": "Informative signals can consist of surface cues, as well as the semantics of the relational arguments.", "labels": [], "entities": []}, {"text": "Statistical approaches have typically relied on linguistically informed features which capture both of these aspects, like temporal markers, polarity tags, Levin verb classes and sentiment lexicons, as well as the Cartesian products of the word tokens in the two arguments ().", "labels": [], "entities": []}, {"text": "More recent efforts use distributed representations with neural network architectures ().", "labels": [], "entities": []}, {"text": "The main question in designing neural networks for discourse relation classification is how to get the neural networks to effectively encode the discourse relational arguments such that all of the aspects relevant to the classification of the relation are represented, in particular in the face of very limited amounts of annotated training data, see e.g..", "labels": [], "entities": [{"text": "discourse relation classification", "start_pos": 51, "end_pos": 84, "type": "TASK", "confidence": 0.6698676745096842}]}, {"text": "The crucial intuition in the present paper is to make use of the annotated implicit connectives in the PDTB: in addition to the typical relation label classification task, we also train the model to encode and decode the discourse relational arguments, and at the same time predict the implicit connective.", "labels": [], "entities": [{"text": "relation label classification", "start_pos": 136, "end_pos": 165, "type": "TASK", "confidence": 0.7053977052370707}]}, {"text": "This novel secondary task forces the internal representation to more completely encode the semantics of the relational arguments (in order to allow the model to decode later), and to make a more fine-grained classification (predicting the implicit connective) than is necessary for the overall task.", "labels": [], "entities": []}, {"text": "This more fine-grained task thus aims to force the model to represent the discourse relational arguments in away that allows the model to also predict a suitable connective.", "labels": [], "entities": []}, {"text": "Our overall discourse relation classifier combines representations from the relational arguments as well as the hidden representations generated as part of the encoder-decoder architecture to predict relation labels.", "labels": [], "entities": []}, {"text": "What's more, with an explicit memory network, the network also has access to history representations and acquire more explicit context knowledge.", "labels": [], "entities": []}, {"text": "We show that our method outperforms previous approaches on the 11-way classification on the PDTB 2.0 benchmark.", "labels": [], "entities": [{"text": "PDTB 2.0 benchmark", "start_pos": 92, "end_pos": 110, "type": "DATASET", "confidence": 0.9502434531847636}]}, {"text": "The remaining of the paper is organized as follows: Section 2 discusses related work; Section 3 describes our proposed method; Section 4 gives the training details and experimental results, which is followed by conclusion and future work in section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We compare our models with six previous methods, as shown in.", "labels": [], "entities": []}, {"text": "The baselines contain featurebased methods (, state-of-the-art neural networks (, including the adversarial neural network that also exploits the annotated implicit connectives (, as well as the data extension method based on using explicitated connectives from translation to other languages ( . Additionally, we ablate our model by taking out the prediction of the implicit connective in the sequence to sequence model.", "labels": [], "entities": []}, {"text": "The resulting model is labeled Auto-Encoder in.", "labels": [], "entities": []}, {"text": "And seq2seq network without knowledge memory, which means we use the output of gated interaction layer to predict the label directly, as denoted as Seq2Seq w/o Mem Net.", "labels": [], "entities": [{"text": "Mem Net", "start_pos": 160, "end_pos": 167, "type": "DATASET", "confidence": 0.8088259100914001}]}, {"text": "Our proposed model outperforms the other models in each of the settings.", "labels": [], "entities": []}, {"text": "Compared with performances in, although we share the similar idea of extracting highly discriminative features by generating connective-augmented representations for implicit discourse relations, our method improves about 1.2% on setting PDTB-Lin and 1.6% on the PDTB-Ji setting.", "labels": [], "entities": [{"text": "PDTB-Lin", "start_pos": 238, "end_pos": 246, "type": "DATASET", "confidence": 0.8908497095108032}, {"text": "PDTB-Ji setting", "start_pos": 263, "end_pos": 278, "type": "DATASET", "confidence": 0.9240877628326416}]}, {"text": "The importance of the implicit connective is also illustrated by the fact that the \"Auto-Encoder\" model, which is identical to our model except it does not predict the implicit connective, performs worse than the model which does.", "labels": [], "entities": []}, {"text": "This confirms our initial hypothesis that training with implicit connectives helps to expose the latent discriminative features in the relational arguments, and generates more refined semantic representation.", "labels": [], "entities": []}, {"text": "It also means that, to some extent, purely increasing the size of tunable parameters is not always helpful in this task and trying to predict implicit connectives in the decoder does indeed help the model extract more discriminative features for this task.", "labels": [], "entities": []}, {"text": "What's more, we can also see that without the memory network, the performances are also worse, it shows that with the concatenation of knowledge vector, the training instance maybe capable of finding related instances to get common knowledge for predicting implicit relations.", "labels": [], "entities": [{"text": "predicting implicit relations", "start_pos": 246, "end_pos": 275, "type": "TASK", "confidence": 0.8567027648289999}]}, {"text": "As  argued that it is risky to conclude with testing on such small test set, we also run cross-validation on the whole PDTB.", "labels": [], "entities": [{"text": "PDTB", "start_pos": 119, "end_pos": 123, "type": "DATASET", "confidence": 0.9527941346168518}]}, {"text": "From, we have the same conclusion with the effectiveness of our method, which outperformed the baseline (Bi-LSTM) with more than 11% points and 3% compared with  even though they have used a very large extra corpus.", "labels": [], "entities": [{"text": "Bi-LSTM", "start_pos": 105, "end_pos": 112, "type": "METRIC", "confidence": 0.9312559962272644}]}, {"text": "For the sake of obtaining a better intuition on how the global attention works in our model, demonstrates the weights of different time-steps in attention layer from the decoder.", "labels": [], "entities": []}, {"text": "The weights show how much importance the word attached to the source words while predicting target words.", "labels": [], "entities": []}, {"text": "We can see that without the connective in the target side of test, the word filler still works as a connective to help predict the upcoming words.", "labels": [], "entities": []}, {"text": "For instance, the true discourse relation for the right-hand example is Expansion.Alternative, at the word filler's time-step, it attached more importance on the negation \"don't\" and \"tastefully appointed\".", "labels": [], "entities": [{"text": "Expansion.Alternative", "start_pos": 72, "end_pos": 93, "type": "METRIC", "confidence": 0.971961498260498}]}, {"text": "It means the current representation could grasp the key information and try to focus on the important words to help with the task.", "labels": [], "entities": []}, {"text": "Here we see plenty room for adapting this model to discourse connective prediction task, we would like to leave this to the future work.: Visualization of attention weights during predicting target sentence in train and test, x-axis denotes the source sentence and the y-axis is the targets.", "labels": [], "entities": [{"text": "discourse connective prediction", "start_pos": 51, "end_pos": 82, "type": "TASK", "confidence": 0.6611257195472717}]}, {"text": "First two figures are examples from training set with implicit connectives inside, while the following one, in which the implicit connective has been replaced by the word filler \"impl conn\", is from test.", "labels": [], "entities": []}, {"text": "In recent years, U.S. steelmakers have supplied about 80% of the 100 million tons of steel used annually by the nation.", "labels": [], "entities": []}, {"text": "(in addition,) Of the remaining 20% needed, the steel-quota negotiations allocate about 15% to foreign suppliers.", "labels": [], "entities": []}, {"text": "-Expansion.Conjunction   We also try to figure out which instances' representations have been chosen from the memory matrix while predicting.", "labels": [], "entities": []}, {"text": "shows two examples and their context instances with top 2 memory attentions among the whole training set.", "labels": [], "entities": []}, {"text": "We can see that both examples show that the memory attention attached more importance on the same relations.", "labels": [], "entities": []}, {"text": "This means that with the Context Memory, the model could facilitate the discourse relation prediction by choosing examples that share similar semantic representation and discourse relation during prediction.: Comparison of F 1 scores (%) and Accuracy (%) with the State-of-the-art Approaches for fourways and one-versus-all binary classification on PDTB.", "labels": [], "entities": [{"text": "discourse relation prediction", "start_pos": 72, "end_pos": 101, "type": "TASK", "confidence": 0.647442509730657}, {"text": "F 1 scores", "start_pos": 223, "end_pos": 233, "type": "METRIC", "confidence": 0.9766369660695394}, {"text": "Accuracy", "start_pos": 242, "end_pos": 250, "type": "METRIC", "confidence": 0.9985645413398743}, {"text": "PDTB", "start_pos": 349, "end_pos": 353, "type": "DATASET", "confidence": 0.9742509126663208}]}, {"text": "Comp., Cont., Expa. and Temp.", "labels": [], "entities": [{"text": "Expa.", "start_pos": 14, "end_pos": 19, "type": "DATASET", "confidence": 0.9587581157684326}, {"text": "Temp.", "start_pos": 24, "end_pos": 29, "type": "DATASET", "confidence": 0.7205674052238464}]}, {"text": "stand for Comparison, Contingency, Expansion and Temporal respectively.", "labels": [], "entities": [{"text": "Expansion", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.9655153751373291}]}], "tableCaptions": [{"text": " Table 1: Numbers of train, development and test set on different settings for 11-way classification task.  Instances annotated with two labels are double-counted and some relations with few instances have been  removed.", "labels": [], "entities": []}, {"text": " Table 3: Accuracy (%) of implicit discourse relations on PDTB-Lin, PDTB-Ji and Cross Validation  Settings for multi-class classification.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9898853302001953}, {"text": "PDTB-Lin", "start_pos": 58, "end_pos": 66, "type": "DATASET", "confidence": 0.9396268725395203}, {"text": "PDTB-Ji", "start_pos": 68, "end_pos": 75, "type": "DATASET", "confidence": 0.8814150094985962}, {"text": "multi-class classification", "start_pos": 111, "end_pos": 137, "type": "TASK", "confidence": 0.7425310909748077}]}, {"text": " Table 4: Example of attention in Context Knowledge Memory. The sentences in italic are from PDTB  test set and following 2 instances are the ones with top 2 attention weights from training set.", "labels": [], "entities": [{"text": "PDTB  test set", "start_pos": 93, "end_pos": 107, "type": "DATASET", "confidence": 0.9779008229573568}]}, {"text": " Table 5: Distribution of top-level implicit discourse relations in the PDTB.", "labels": [], "entities": [{"text": "PDTB", "start_pos": 72, "end_pos": 76, "type": "DATASET", "confidence": 0.8478659987449646}]}, {"text": " Table 6: Comparison of F 1 scores (%) and Accuracy (%) with the State-of-the-art Approaches for four- ways and one-versus-all binary classification on PDTB. Comp., Cont., Expa. and Temp. stand for  Comparison, Contingency, Expansion and Temporal respectively.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 24, "end_pos": 34, "type": "METRIC", "confidence": 0.957012673219045}, {"text": "Accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9992426633834839}, {"text": "Approaches", "start_pos": 82, "end_pos": 92, "type": "METRIC", "confidence": 0.8206270933151245}, {"text": "PDTB", "start_pos": 152, "end_pos": 156, "type": "DATASET", "confidence": 0.9341277480125427}]}]}