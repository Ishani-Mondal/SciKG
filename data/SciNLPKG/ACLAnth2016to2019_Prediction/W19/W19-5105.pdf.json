{"title": [{"text": "Learning to Predict Novel Noun-Noun Compounds", "labels": [], "entities": [{"text": "Learning to Predict Novel Noun-Noun Compounds", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.729228268067042}]}], "abstractContent": [{"text": "We introduce temporally and contextually-aware models for the novel task of predicting unseen but plausible concepts, as conveyed by noun-noun compounds in a time-stamped corpus.", "labels": [], "entities": [{"text": "predicting unseen but plausible concepts", "start_pos": 76, "end_pos": 116, "type": "TASK", "confidence": 0.8349921464920044}]}, {"text": "We train compositional models on observed compounds, more specifically the composed distributed representations of their constituents across a time-stamped corpus, while giving it corrupted instances (where head or modifier are replaced by a random constituent) as negative evidence.", "labels": [], "entities": []}, {"text": "The model captures generalisations over this data and learns what combinations give rise to plausible compounds and which ones do not.", "labels": [], "entities": []}, {"text": "After training, we query the model for the plausibility of automatically generated novel combinations and verify whether the classifications are accurate.", "labels": [], "entities": []}, {"text": "For our best model, we find that in around 85% of the cases, the novel compounds generated are attested in previously unseen data.", "labels": [], "entities": []}, {"text": "An additional estimated 5% are plausible despite not being attested in the recent corpus, based on judgments from independent human raters.", "labels": [], "entities": []}], "introductionContent": [{"text": "Compounding is defined as the process of combining two or more lexemes to form anew concept.", "labels": [], "entities": []}, {"text": "For most compounds in English, the first constituent is the modifier, whereas the second is the head.", "labels": [], "entities": []}, {"text": "The head usually determines the class to which the compound belongs, whereas the modifier adds specialisation, e.g apple cake is a type of cake.", "labels": [], "entities": []}, {"text": "Compounding is thought of as one of the simplest forms of concept formation 1 as it involves use of elements that are already part of the language and requires little or no morphological changes, particularly in English.", "labels": [], "entities": [{"text": "concept formation 1", "start_pos": 58, "end_pos": 77, "type": "TASK", "confidence": 0.8374746640523275}]}, {"text": "From the perspective of language acquisition, Berman found that children acquired compounding construction skills before the other forms of word formation.", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 24, "end_pos": 44, "type": "TASK", "confidence": 0.7304745018482208}, {"text": "compounding construction", "start_pos": 82, "end_pos": 106, "type": "TASK", "confidence": 0.7562582790851593}, {"text": "word formation", "start_pos": 140, "end_pos": 154, "type": "TASK", "confidence": 0.7217148095369339}]}, {"text": "Comparatively little effort has been put into investigating the productive word formation process of compounding computationally.", "labels": [], "entities": [{"text": "word formation", "start_pos": 75, "end_pos": 89, "type": "TASK", "confidence": 0.7372665405273438}]}, {"text": "Although compounding is a rather challenging process to model as it involves concepts of compositionality and plausibility along with an intricate blend of semantic and syntactic processes, it is, in our view, one of the best starting points for modeling linguistic creativity.", "labels": [], "entities": []}, {"text": "In contrast to relatively more studied topics in linguistics creativity, such as automatic poetry generation (, aesthetics are not involved.", "labels": [], "entities": [{"text": "automatic poetry generation", "start_pos": 81, "end_pos": 108, "type": "TASK", "confidence": 0.6564309398333231}]}, {"text": "Moreover, compounding is limited to phrase level processes, as it involves a combination of known lexemes.", "labels": [], "entities": [{"text": "compounding", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9618736505508423}]}, {"text": "In general, the creative power of language has been understudied in the field of natural language processing (NLP).", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 81, "end_pos": 114, "type": "TASK", "confidence": 0.8111692368984222}]}, {"text": "The main focus is indeed on processing, as the name suggests.", "labels": [], "entities": []}, {"text": "Creative thinking is a cognitive ability that fuels innovation.", "labels": [], "entities": []}, {"text": "Therefore, the modelling and understanding of the underlying processes of novel concept creation is relevant.", "labels": [], "entities": []}, {"text": "Ultimately, we aim to create tools that enhance peoples ability to interface more creatively with large data sets, to build tools that find inspiration in data.", "labels": [], "entities": []}, {"text": "Our main contributions are the introduction of anew task in NLP that sheds light on the basic mechanisms underlying conceptual creativity; an automatic way of evaluating newly generated language; a temporally-aware neural model that learns what are plausible new conceptual combinations by generalising over attested combinations and corrupted instances thereof.", "labels": [], "entities": []}], "datasetContent": [{"text": "In particular, we address the task of predicting novel noun-noun (N-N) compounds: compounds consisting of two constituents that are both nouns.", "labels": [], "entities": [{"text": "predicting novel noun-noun (N-N) compounds", "start_pos": 38, "end_pos": 80, "type": "TASK", "confidence": 0.7779274412563869}]}, {"text": "Our method is based on the generalisation power of machine learning.", "labels": [], "entities": []}, {"text": "We reason that by compressing the space in ways that are inline with distributional patterns found in observed data, estimates for unobserved yet plausible combinations should be close to the estimates gathered from attested examples.", "labels": [], "entities": []}, {"text": "For example, if we have seen glassbottom boats in corpora, but we have never seen the combination glass canoe (a recent invention), we can infer from the similarity between the components of the compounds that a glass canoe could be a plausible compound even though it has never been seen.", "labels": [], "entities": []}, {"text": "Evaluating plausibility prediction models for novel combinations is non-trivial and previous work has relied mainly on human judgments.", "labels": [], "entities": [{"text": "Evaluating plausibility prediction", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8449096083641052}]}, {"text": "We aim to find an automatic evaluation method to ease parameter optimisation and model comparison.", "labels": [], "entities": [{"text": "model comparison", "start_pos": 81, "end_pos": 97, "type": "TASK", "confidence": 0.6545505523681641}]}, {"text": "To this end, we use a time-stamped corpus divided into decades.", "labels": [], "entities": []}, {"text": "The last decade is used for testing, with the previous decades used for training the models.", "labels": [], "entities": []}, {"text": "This allows us to check whether the novel generated compounds are good predictions of compounds that might emerge in the future.", "labels": [], "entities": []}, {"text": "Because the future extends beyond the last decade of our corpus, and the results from our automatic evaluation are pessimistic, we ask human judges to rate the plausibility of a sample of automatically generated novel compounds that are not attested in the last decade (see Sections 7 and 9).", "labels": [], "entities": []}, {"text": "We evaluate our overall system in two ways: on the basis of corpus data, and by means of human judges, which we cover in Section 9.", "labels": [], "entities": []}, {"text": "For the automatic evaluation of our system, we measure how many of the compounds it predicts are attested among the previously unseen compounds in the last decade, the 2000s.", "labels": [], "entities": []}, {"text": "The 20 decades prior to the 2000s (1800s to 1990s) are used to train the models.", "labels": [], "entities": []}, {"text": "The constituents that exist only in the decade of the 2000s are therefore excluded from the training phase.", "labels": [], "entities": []}, {"text": "This way we make sure that the prediction of novel entities is dependent only on information derived from the prior decades.", "labels": [], "entities": [{"text": "prediction of novel entities", "start_pos": 31, "end_pos": 59, "type": "TASK", "confidence": 0.8945113122463226}]}, {"text": "Evaluation on corpus data does not guarantee full coverage.", "labels": [], "entities": []}, {"text": "In other words, if a novel compound generated by the system is not found in the contemporary corpus this does not mean per se that the compound is not plausible.", "labels": [], "entities": []}, {"text": "The compound might be plausible but not yet 'invented'.", "labels": [], "entities": []}, {"text": "We therefore also ran a small-scale manual annotation.", "labels": [], "entities": []}, {"text": "Taking our best model, which was NNM under CompoundCentric and DecadeCentric aspects, a subset of plausible compounds that were predicted by our system (but not found in test corpus and hence counted as incorrect) were annotated by human judges.", "labels": [], "entities": [{"text": "NNM", "start_pos": 33, "end_pos": 36, "type": "DATASET", "confidence": 0.8964788317680359}]}, {"text": "Following the annotation guidelines of, each annotator was asked to rate each candidate compound between 0 (makes no sense) and 4 (makes complete sense).", "labels": [], "entities": []}, {"text": "250 plausible compounds were annotated in total.", "labels": [], "entities": []}, {"text": "Each candidate compound was evaluated by at least three annotaters.", "labels": [], "entities": []}, {"text": "shows some of the annotation results.", "labels": [], "entities": []}, {"text": "We see that compounds such as art direction and service ramp, that are predicted by the system, but not found in the decades 2000s, is deemed plausible by the annotators.", "labels": [], "entities": [{"text": "art direction", "start_pos": 30, "end_pos": 43, "type": "TASK", "confidence": 0.6987114697694778}]}, {"text": "In fact, we found that around 5% of the test data set was rated 3 or higher, on average, by the annotators, indicating that we cannot just rely on a corpora for the evaluation of the novel compound predictor, and that the accuracies given in are pessimistic.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results of the Semantic Models, represented with accuracy and the standard deviation", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9997343420982361}, {"text": "standard deviation", "start_pos": 76, "end_pos": 94, "type": "METRIC", "confidence": 0.8865305483341217}]}]}