{"title": [{"text": "Predicting Metaphor Paraphrase Judgements in Context", "labels": [], "entities": [{"text": "Predicting Metaphor Paraphrase Judgements in Context", "start_pos": 0, "end_pos": 52, "type": "TASK", "confidence": 0.9133666157722473}]}], "abstractContent": [{"text": "We conduct two experiments to study the effect of context on metaphor paraphrase aptness judgments.", "labels": [], "entities": [{"text": "metaphor paraphrase aptness judgments", "start_pos": 61, "end_pos": 98, "type": "TASK", "confidence": 0.638789638876915}]}, {"text": "The first is an AMT crowd source task in which speakers rank metaphor-paraphrase candidate sentence pairs in short document contexts for paraphrase aptness.", "labels": [], "entities": [{"text": "AMT crowd source task", "start_pos": 16, "end_pos": 37, "type": "TASK", "confidence": 0.9000686556100845}]}, {"text": "In the second we train a composite DNN to predict these human judgments, first in binary classifier mode, and then as gradient ratings.", "labels": [], "entities": []}, {"text": "We found that for both mean human judgments and our DNN modeling, adding document context compresses the aptness scores towards the centre of the scale, raising low out of context ratings and decreasing high out of context scores.", "labels": [], "entities": []}, {"text": "We briefly consider two possible explanations for this compression effect.", "labels": [], "entities": []}], "introductionContent": [{"text": "A metaphor is away of forcing the normal boundaries of words' meaning in order to better express an experience, a concept or an idea.", "labels": [], "entities": []}, {"text": "At least to a native speaker's ear, some metaphors sound more conventional (like the usage of the words ear and sound in this sentence), others more original.", "labels": [], "entities": []}, {"text": "This is not the only way to judge a metaphor.", "labels": [], "entities": [{"text": "judge a metaphor", "start_pos": 28, "end_pos": 44, "type": "TASK", "confidence": 0.8111836512883505}]}, {"text": "One of the most important qualities of a metaphor is its appropriateness, its aptness.", "labels": [], "entities": []}, {"text": "This poses the question of how good a metaphor is for conveying a given experience or concept.", "labels": [], "entities": []}, {"text": "While a metaphor's degree of conventionality can be measured through probabilistic methods, like language models, it is harder to model its aptness.", "labels": [], "entities": []}, {"text": "define aptness as \"the extent to which a comparison captures important features of the topic\".", "labels": [], "entities": []}, {"text": "It is possible to express an opinion about some metaphors' and similes' aptness (at least to a degree) without previously knowing what they are trying to convey, or the context in which they appear . For example, we don't need a particular context or frame of reference to construe the simile She was screaming like a turtle as strange, and less apt for expressing the quality of a scream, than She was screaming like a banshee.", "labels": [], "entities": []}, {"text": "In this case, the reason why the simile in the second sentence works better is intuitive.", "labels": [], "entities": []}, {"text": "A salient characteristic of a banshee is a powerful scream.", "labels": [], "entities": []}, {"text": "Turtles are not known for screaming, and so it is harder to define the quality of a scream through such a comparison, except as a form of irony.", "labels": [], "entities": []}, {"text": "Other cases are more complicated.", "labels": [], "entities": []}, {"text": "The simile crying like afire in the sun (It's All Over Now, Baby Blue, Bob Dylan) is powerfully apt for many readers, but simply odd for others.", "labels": [], "entities": []}, {"text": "Fire and sun do not cry in anyway.", "labels": [], "entities": []}, {"text": "But at the same time the simile can express the association we draw between something strong and intense in other sensory modes, such as vision and touch, on one hand and aloud cry on the other.", "labels": [], "entities": []}, {"text": "Nevertheless, most metaphors and similes need some kind of context, or external reference point to be interpreted.", "labels": [], "entities": []}, {"text": "The sentence The old lady had a heart of stone is apt if the old lady is cruel or indifferent, but it is unreasonable as a description of a situation in which the old lady is kind and caring.", "labels": [], "entities": []}, {"text": "We assume that, to an average reader's sensibility, the sentence models only the first situation appropriately.", "labels": [], "entities": []}, {"text": "This is the view of metaphor aptness that we adopt in this paper.", "labels": [], "entities": []}, {"text": "Following, we treat a metaphor as apt in relation to a literal expression that it paraphrases.", "labels": [], "entities": []}, {"text": "If the metaphor is judged to be a good paraphrase, then it closely \"models\" the core information of the literal sentence through its metaphorical shift.", "labels": [], "entities": []}, {"text": "We refer to the prediction of readers' judgments on the aptness candidates for the literal paraphrase of a metaphor as the metaphor paraphrase aptness task (MPAT).", "labels": [], "entities": []}, {"text": "address the MPAT by using Amazon Mechanical Turk (AMT) to obtain crowd sourced annotations of metaphor-paraphrase candidate pairs.", "labels": [], "entities": []}, {"text": "They train a composite Deep Neural Network (DNN) on a portion of their annotated corpus, and test it on the remaining part.", "labels": [], "entities": []}, {"text": "Testing involves using the DNN as a binary classifier on paraphrase candidates.", "labels": [], "entities": []}, {"text": "They derive predictions of gradient paraphrase aptness for their test set, and assess them by Pearson coefficient correlation to the mean judgments of their crowd sourced annotation of this set.", "labels": [], "entities": [{"text": "Pearson coefficient correlation", "start_pos": 94, "end_pos": 125, "type": "METRIC", "confidence": 0.9715169668197632}]}, {"text": "Both training and testing are done independently of any document context for the metaphorical sentence and its literal paraphrase candidates.", "labels": [], "entities": []}, {"text": "In this paper we study the role of context on readers' judgments concerning the aptness of metaphor paraphrase candidates.", "labels": [], "entities": []}, {"text": "We look at the accuracy of's DNN when trained and tested on contextually embedded metaphor-paraphrase pairs for the MPAT.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9991108775138855}]}, {"text": "In Section 2 we describe an AMT experiment in which annotators judge metaphors and paraphrases embedded in small document contexts, and in Section 3 we discuss the results of this experiment.", "labels": [], "entities": [{"text": "AMT", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.9819526076316833}]}, {"text": "In Section 4 we describe our MPAT modeling experiment, and in Section 5 we discuss the results of this experiment.", "labels": [], "entities": [{"text": "MPAT modeling", "start_pos": 29, "end_pos": 42, "type": "TASK", "confidence": 0.8355702757835388}]}, {"text": "Section 6 surveys some work on metaphor aptness and computational methods to deal with it.", "labels": [], "entities": [{"text": "metaphor aptness", "start_pos": 31, "end_pos": 47, "type": "TASK", "confidence": 0.8178358674049377}]}, {"text": "In Section 7 we draw conclusions from the studies presented in this paper, and we indicate directions for future work in this area.", "labels": [], "entities": []}, {"text": "have recently produced a dataset of paraphrases containing metaphors designed to allow both supervised binary classification and gradient rankings.", "labels": [], "entities": []}, {"text": "This dataset contains several pairs of sentences, wherein each pair the first sentence contains a metaphor, and the second is a literal paraphrase candidate.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: F-score binary classification accuracy and Pearson correlation for three different regimens of  supervised learning. The * indicates results for a set of 10-fold cross-validation runs. This was necessary  in the first case, when training and testing are both on our small corpus of in-context pairs. In the second  and third rows, since we are using the full out-of-context and in-context dataset, we report single-run  results. The fourth row is", "labels": [], "entities": [{"text": "F-score", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9488545656204224}, {"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.7977101802825928}, {"text": "Pearson correlation", "start_pos": 53, "end_pos": 72, "type": "METRIC", "confidence": 0.8652276992797852}]}]}