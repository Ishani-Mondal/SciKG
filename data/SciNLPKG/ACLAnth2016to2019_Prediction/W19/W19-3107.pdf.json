{"title": [{"text": "Finite State Transducer Calculus for Whole Word Morphology", "labels": [], "entities": [{"text": "Whole Word Morphology", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.5847487847010294}]}], "abstractContent": [{"text": "The research on machine learning of morphology often involves formulating morphological descriptions directly on surface forms of words.", "labels": [], "entities": [{"text": "machine learning of morphology", "start_pos": 16, "end_pos": 46, "type": "TASK", "confidence": 0.7553827613592148}]}, {"text": "As the established two-level morphology paradigm requires the knowledge of the underlying structure, it is not widely used in such settings.", "labels": [], "entities": []}, {"text": "In this paper, we propose a formalism describing structural relationships between words based on theories of morphology that reject the notions of internal word structure and morpheme.", "labels": [], "entities": []}, {"text": "The formalism covers a wide variety of morphological phenomena (including non-concatenative ones like stem vowel alternation) without the need of workarounds and extensions.", "labels": [], "entities": []}, {"text": "Furthermore , we show that morphological rules formulated in such way can be easily translated to FSTs, which enables us to derive performant approaches to morphological analysis, generation and automatic rule discovery.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 156, "end_pos": 178, "type": "TASK", "confidence": 0.7328795790672302}, {"text": "automatic rule discovery", "start_pos": 195, "end_pos": 219, "type": "TASK", "confidence": 0.6537279983361562}]}], "introductionContent": [{"text": "In computational linguistics, morphological analysis is usually understood as segmenting words into smaller meaningful units, called morphs.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 30, "end_pos": 52, "type": "TASK", "confidence": 0.7223025113344193}]}, {"text": "There exists a well-established computational model for such analysis, called two-level morphology.", "labels": [], "entities": []}, {"text": "It models the mapping between the surface forms of words and the morph sequences using handwritten rules, which are compiled to Finite State Transducers.", "labels": [], "entities": []}, {"text": "This allows fora composition of lexicon and rules to an efficient morphological analyzer.", "labels": [], "entities": []}, {"text": "Examples of such analyzers include Omorfi for Finnish, Morphisto for German ( and TRMorph for Turkish (C \u00b8 \u00a8 oltekin, 2010).", "labels": [], "entities": []}, {"text": "However, the research coming from the machine learning side often requires models that describe string transformations between surface forms directly, without referring to any underlying structures which cannot be observed in the data and are difficult to infer by a learning algorithm.", "labels": [], "entities": []}, {"text": "Such transformations can also be described and implemented as finite-state transducers.", "labels": [], "entities": []}, {"text": "Despite that, a standardized model of this kind of morphological description seems to be lacking.", "labels": [], "entities": []}, {"text": "Instead, many authors develop their own models and implementations for the purpose of a concrete learning algorithm.", "labels": [], "entities": []}, {"text": "With some exceptions, the design, implementation and performance of the string processing algorithms is usually not described in detail and the approaches used for that are sometimes suboptimal.", "labels": [], "entities": []}, {"text": "In this paper, we present a finite-state computational model of string transformations on surface forms based on a linguistic theory called Whole Word Morphology.", "labels": [], "entities": [{"text": "Whole Word Morphology", "start_pos": 140, "end_pos": 161, "type": "TASK", "confidence": 0.6209392050902048}]}, {"text": "We first review research on machine learning of morphology which motivates the need for such a model (Sec. 2).", "labels": [], "entities": [{"text": "machine learning of morphology", "start_pos": 28, "end_pos": 58, "type": "TASK", "confidence": 0.7116982191801071}]}, {"text": "3, we describe the formalism and its linguistic foundations, and in Sec.", "labels": [], "entities": []}, {"text": "4, we present the implementation of the formalism within the FST calculus.", "labels": [], "entities": [{"text": "FST calculus", "start_pos": 61, "end_pos": 73, "type": "DATASET", "confidence": 0.6656332015991211}]}, {"text": "5 contains a procedure for automatic rule discovery from unannotated data, while in Sec.", "labels": [], "entities": [{"text": "automatic rule discovery from unannotated", "start_pos": 27, "end_pos": 68, "type": "TASK", "confidence": 0.7033206403255463}]}, {"text": "6, we measure the performance of our implementation of the model.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have implemented the algorithms described in the previous section using the HFST library).", "labels": [], "entities": [{"text": "HFST library", "start_pos": 79, "end_pos": 91, "type": "DATASET", "confidence": 0.9642901122570038}]}, {"text": "Furthermore, we conducted experiments realizing the algebraic operations described in Sec.", "labels": [], "entities": []}, {"text": "4 and the rule discovery procedure described in Sec.", "labels": [], "entities": [{"text": "rule discovery", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.8593621850013733}]}, {"text": "5. The results demonstrate that our model is suitable for building analyzers based on the Whole Word Morphology paradigm and the required computational resources are easily achievable.", "labels": [], "entities": []}, {"text": "First, we run the rule discovery procedure on word lists extracted from German Wikipedia.", "labels": [], "entities": [{"text": "rule discovery", "start_pos": 18, "end_pos": 32, "type": "TASK", "confidence": 0.8193725049495697}]}, {"text": "The generation of pairs of similar words and the subsequent rule extraction is implemented in a parallelized fashion.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 60, "end_pos": 75, "type": "TASK", "confidence": 0.7370980232954025}]}, {"text": "shows the computation times for various sizes of input vocabulary and numbers of processes.", "labels": [], "entities": []}, {"text": "The results demonstrate that this step is feasible for input data of as much as 150,000 words (and probably even somewhat larger).", "labels": [], "entities": []}, {"text": "In our view, this is enough to discover the vast majority of productive morphological rules.", "labels": [], "entities": []}, {"text": "We disjunct several thousand most frequent rules to construct a rule transducer T R , which is used in algebraic operations shown in.", "labels": [], "entities": []}, {"text": "Most operations are realized within at most several minutes, the longest one being the construction of the largest generator in slightly above 11 minutes.", "labels": [], "entities": []}, {"text": "Note that the computation times reported in Table 3 are much shorter than the ones in.", "labels": [], "entities": []}, {"text": "Moreover, the former appear to increase linearly in both |V | and |R|.", "labels": [], "entities": []}, {"text": "Thus, although the limits on the vocabulary size in the rule discovery procedure are quite tight, once we have discovered the rules (or obtained them in another way, e.g. manually written), we can apply the transducer to find pairs of related words in much larger lexica.", "labels": [], "entities": [{"text": "rule discovery", "start_pos": 56, "end_pos": 70, "type": "TASK", "confidence": 0.7261543869972229}]}, {"text": "Using 3-way composition) for computing TA \u2022T V could probably further improve the analysis of anew lexicon.", "labels": [], "entities": []}], "tableCaptions": []}