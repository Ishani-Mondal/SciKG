{"title": [{"text": "Analysing Rhetorical Structure as a Key Feature of Summary Coherence", "labels": [], "entities": [{"text": "Analysing Rhetorical Structure", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8109999696413676}, {"text": "Summary Coherence", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.8837381601333618}]}], "abstractContent": [{"text": "We present a model for automatic scoring of coherence based on comparing the rhetorical structure (RS) of college student summaries in L2 (English) against expert summaries.", "labels": [], "entities": [{"text": "rhetorical structure (RS)", "start_pos": 77, "end_pos": 102, "type": "METRIC", "confidence": 0.636142474412918}]}, {"text": "Coherence is conceptualised as a construct consisting of a rhetorical relation and its arguments.", "labels": [], "entities": []}, {"text": "Comparison with expert-assigned scores shows that RS scores correlate with both cohesion and coherence.", "labels": [], "entities": [{"text": "RS", "start_pos": 50, "end_pos": 52, "type": "METRIC", "confidence": 0.9573222398757935}]}, {"text": "Furthermore, RS scores improve the accuracy of a regression model for cohesion score prediction.", "labels": [], "entities": [{"text": "RS", "start_pos": 13, "end_pos": 15, "type": "METRIC", "confidence": 0.7637771368026733}, {"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9994317889213562}, {"text": "cohesion score prediction", "start_pos": 70, "end_pos": 95, "type": "TASK", "confidence": 0.6789083480834961}]}], "introductionContent": [{"text": "Assessment of text quality may benefit from automatic scoring as it is cognitively demanding and often requires much expertise (), especially in college-level expository writing.", "labels": [], "entities": []}, {"text": "One of the key aspects of text quality is writing coherence) which reflects students' ability to connect ideas in their mind and to convey the same message in essays or summaries.", "labels": [], "entities": []}, {"text": "Existing approaches to text quality predominantly focus on surface measures for assessment (e.g., number of cohesive devices), which sometimes have little relation either to human judgment, e.g., text length (, or to textspecific meaning (.", "labels": [], "entities": []}, {"text": "However, automatic scoring of coherence should ideally provide clear and reliable feedback ( ) based on features with cognitive validity, e.g.,.", "labels": [], "entities": []}, {"text": "One way to meet such requirements is to define coherence as the identification of relations between the text's ideas (.", "labels": [], "entities": []}, {"text": "Such a definition may best be analysed in summaries in which the key ideas of the source text are integrated into a rhetorical structure (RS).", "labels": [], "entities": []}, {"text": "In cognitive terms, writing summaries is an exercise in reading-for-understanding (RU) ) and gist reasoning).", "labels": [], "entities": [{"text": "writing summaries", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.5784807950258255}]}, {"text": "The result of such processes is the macrostructure of the source text constructed in the reader's mind, which consists of concepts and propositions, their mutual relations), and relations with prior knowledge.", "labels": [], "entities": []}, {"text": "Coherent summaries should express the intention of the source text (Hobbs, 1993) using linguistic devices (cohesion), which makes summarisation also a readingto-write (RW) task.", "labels": [], "entities": [{"text": "summarisation", "start_pos": 130, "end_pos": 143, "type": "TASK", "confidence": 0.9709241390228271}]}, {"text": "Moreover, summaries have a distinctive feature for annotation: a largely shared knowledge base, i.e., the source text(s) known both to the writer and to the rater(s), which assists raters in their judgment and helps develop a reliable text-specific scoring tool.", "labels": [], "entities": []}, {"text": "In this paper we present a model for automatic scoring of summaries based on analysing a rhetorical structure of a student's summary compared to that of reference summaries.", "labels": [], "entities": [{"text": "automatic scoring of summaries", "start_pos": 37, "end_pos": 67, "type": "TASK", "confidence": 0.6040104329586029}]}, {"text": "Our starting point is coherence conceptualized as a construct consisting of three elements: a rhetorical relation and its two arguments.", "labels": [], "entities": []}, {"text": "We posit that expository text has a rhetorical structure (RS) consisting of a series of text-specific rhetorical segments, the majority of which will be conveyed in a coherent summary if full text-level comprehension is achieved.", "labels": [], "entities": []}, {"text": "The model uses a discourse parser to extract rhetorical structures of summaries, and then compares similarity of these structures.", "labels": [], "entities": []}, {"text": "We show that the scores produced by the model correlate with the expertassigned cohesion and coherence scores as well as with surface indices of cohesion.", "labels": [], "entities": []}, {"text": "We also show that the model-produced scores can be used to improve cohesion score prediction.", "labels": [], "entities": [{"text": "cohesion score prediction", "start_pos": 67, "end_pos": 92, "type": "TASK", "confidence": 0.6835069755713145}]}], "datasetContent": [{"text": "For model evaluation, we adopt the dataset of (Sladoljev-Agejev and\u0160najderand\u02c7and\u0160najder, 2017 raters used a 4-point analytic scale (grades 0-3) to assess the summaries in terms of coherence (RU) and cohesion (RW).", "labels": [], "entities": [{"text": "cohesion (RW)", "start_pos": 200, "end_pos": 213, "type": "METRIC", "confidence": 0.7295539528131485}]}, {"text": "The scales were quantified by defining the number of coherence and cohesion breaks.", "labels": [], "entities": []}, {"text": "Descriptors for each grade included expressions such as \"meaningfully related ideas\" and \"logical sequencing\" (for coherence) and \"linguistically connected text segments\" (for cohesion).", "labels": [], "entities": []}, {"text": "Inter-rater reliability (weighted kappas) was 0.69 for coherence and 0.83 for cohesion.", "labels": [], "entities": [{"text": "Inter-rater reliability", "start_pos": 0, "end_pos": 23, "type": "METRIC", "confidence": 0.7568677365779877}]}, {"text": "The raters discussed and agreed on all the grades although reliability was adequate.", "labels": [], "entities": [{"text": "reliability", "start_pos": 59, "end_pos": 70, "type": "METRIC", "confidence": 0.9992396831512451}]}, {"text": "As expected, we observe a strong correlation between coherence and cohesion scores (Spearman correlation coefficient of 0.64).", "labels": [], "entities": [{"text": "Spearman correlation coefficient", "start_pos": 84, "end_pos": 116, "type": "METRIC", "confidence": 0.9302551945050558}]}, {"text": "All the summaries were checked for spelling and basic grammar.", "labels": [], "entities": [{"text": "basic grammar", "start_pos": 48, "end_pos": 61, "type": "TASK", "confidence": 0.6423544585704803}]}, {"text": "For the two articles from The Economist, two experts with considerable experience with business texts in English wrote 300-word summaries following the same instruction as the students.", "labels": [], "entities": [{"text": "The Economist", "start_pos": 26, "end_pos": 39, "type": "DATASET", "confidence": 0.935761421918869}]}, {"text": "To assess the validity of the summary scoring model, we measure the correlations of P, R, and F1 scores produced by the model against expert-provided coherence and cohesion scores, considering both Class and Type levels of PDTB relations.", "labels": [], "entities": [{"text": "F1 scores", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.9757292866706848}]}, {"text": "We can make several observations.", "labels": [], "entities": []}, {"text": "First, while all the scores correlate positively with both cohesion and coherence, correlation for coherence is consistently lower, possibly due to the role of the raters' prior knowledge, which is unavailable to the model (also note that interannotator agreement is lower for coherence than for cohesion).", "labels": [], "entities": []}, {"text": "Second, correlation for Type level is consistently lower than for Class level, which can probably be traced to the PDTB parser being less accurate on Type-level relations.", "labels": [], "entities": [{"text": "correlation", "start_pos": 8, "end_pos": 19, "type": "METRIC", "confidence": 0.9889386892318726}]}, {"text": "Lastly, we note that the highest correlation with both cohesion and coherence is achieved with the F1-score of the Class level model.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9990736246109009}]}, {"text": "These results suggest that the proposed summary scoring model is at least partially successful in modeling both cohesion and coherence -and this in spite of the unavoidable errors of the PDTB parser and errors in similarity computations.: Spearman correlation coefficients between expert-assigned cohesion (Chs) and coherence (Chr) scores and model-produced scores (P, R, and F1) for Class and Type levels of PDTB connectives.", "labels": [], "entities": [{"text": "F1", "start_pos": 376, "end_pos": 378, "type": "METRIC", "confidence": 0.994602382183075}]}, {"text": "The highest correlations for cohesion and correlation are shown in boldface.", "labels": [], "entities": [{"text": "correlation", "start_pos": 42, "end_pos": 53, "type": "METRIC", "confidence": 0.9458471536636353}]}, {"text": "All correlations except those shown in italics are statistically significant (p<0.05).", "labels": [], "entities": []}, {"text": "modest correlation between expert-assigned coherence/cohesion and indices for connectives (additive connectives -CNCAdd, logical connectivesCNCLogic, and all connectives -CNCAll) and referential cohesion indices (mean of noun/pronoun overlaps between two sentences -CRFAOa, and content word overlap -CRFCWOA).", "labels": [], "entities": []}, {"text": "It is therefore interesting to investigate to what extent these surface-level predictors correlate with the scores of our model.", "labels": [], "entities": []}, {"text": "gives Spearman correlation coefficients between the Coh-Metrix indices and expert-provided scores as well as the Classand Type-level F1-scores of the model.", "labels": [], "entities": [{"text": "Spearman correlation", "start_pos": 6, "end_pos": 26, "type": "METRIC", "confidence": 0.5568364262580872}, {"text": "F1-scores", "start_pos": 133, "end_pos": 142, "type": "METRIC", "confidence": 0.7777150273323059}]}, {"text": "The CohMetrix indices correlate positively with both the expert-assigned scores and the scores of our model.", "labels": [], "entities": []}, {"text": "However, while CNCLogic and CRFOAo indices mostly correlate with the expert-assigned cohesion and coherence scores, respectively, the scores of our model mostly correlate with the CNCAdd index.: Accuracy of cohesion (Chs) and coherence (Chr) scores predictions for the baseline and ridge regression models with Coh-Metrix (CM), rhetorical structure (RS), and combined (CM+RS) feature sets.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 195, "end_pos": 203, "type": "METRIC", "confidence": 0.9865055680274963}]}, {"text": "The best results are shown in bold.", "labels": [], "entities": []}, {"text": "The \"*\" indicates a statistically significant difference to baseline (p<0.05, Wilcoxon signed-rank test).", "labels": [], "entities": []}, {"text": "The differences between regression models with the CM feature set and models with RS and CM+RS feature sets are not statistically significant.", "labels": [], "entities": [{"text": "CM feature set", "start_pos": 51, "end_pos": 65, "type": "DATASET", "confidence": 0.8550745646158854}]}, {"text": "scoring as a multivariate regression task and use two regression models, one for cohesion and the other for coherence, each trained to predict the expert-assigned score on a 0-3 scale.", "labels": [], "entities": []}, {"text": "We use an L2-regularized linear regression model (ridge regression) and consider three sets of features: (1) five Coh-Metrix CNC and CRF indices (\"CM\"), (2) the F1-scores of the summary scoring model computed at Class and Type levels (\"RS\"), and (3) a combination of the two (\"CM+RS\").", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 161, "end_pos": 170, "type": "METRIC", "confidence": 0.9857251644134521}]}, {"text": "We evaluate the models using a nested 10\u00d75 cross-validation: the models' performance is measured in terms of accuracy averaged over the five outer folds, after rounding the predictions to closest integers and limiting the scores to the 0-3 range.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 109, "end_pos": 117, "type": "METRIC", "confidence": 0.9988062381744385}]}, {"text": "All the features are z-scored on the train set, and the same transformation is applied on the test set.", "labels": [], "entities": []}, {"text": "As baselines, we use the rounded average of the expert-assigned scores.", "labels": [], "entities": []}, {"text": "We can make three main observations.", "labels": [], "entities": []}, {"text": "Firstly, cohesion models outperform the corresponding coherence models.", "labels": [], "entities": []}, {"text": "Secondly, the only two models for which the differences against the baseline are statistically significant are the two cohesion models that use RS.", "labels": [], "entities": []}, {"text": "This suggests that our model does provide useful signals for predicting expert-assigned cohesion scores.", "labels": [], "entities": []}, {"text": "In the absence of statistical significance, the results for coherence are inconclusive, though we observe a similar trend.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Spearman correlation coefficients between  expert-assigned cohesion (Chs) and coherence (Chr)  scores and model-produced scores (P, R, and F1) for  Class and Type levels of PDTB connectives. The high- est correlations for cohesion and correlation are shown  in boldface. All correlations except those shown in ital- ics are statistically significant (p<0.05).", "labels": [], "entities": [{"text": "F1", "start_pos": 149, "end_pos": 151, "type": "METRIC", "confidence": 0.9881167411804199}]}, {"text": " Table 3: Accuracy of cohesion (Chs) and coherence  (Chr) scores predictions for the baseline and ridge  regression models with Coh-Metrix (CM), rhetorical  structure (RS), and combined (CM+RS) feature sets.  The best results are shown in bold. The \"*\" indicates a  statistically significant difference to baseline (p<0.05,  Wilcoxon signed-rank test). The differences between  regression models with the CM feature set and models  with RS and CM+RS feature sets are not statistically  significant.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9902412295341492}]}]}