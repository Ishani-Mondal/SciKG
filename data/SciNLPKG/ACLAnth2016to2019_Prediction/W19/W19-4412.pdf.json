{"title": [{"text": "The Unreasonable Effectiveness of Transformer Language Models in Grammatical Error Correction", "labels": [], "entities": []}], "abstractContent": [{"text": "Recent work on Grammatical Error Correction (GEC) has highlighted the importance of language modeling in that it is certainly possible to achieve good performance by comparing the probabilities of the proposed edits.", "labels": [], "entities": [{"text": "Grammatical Error Correction (GEC)", "start_pos": 15, "end_pos": 49, "type": "TASK", "confidence": 0.8200498620669047}, {"text": "language modeling", "start_pos": 84, "end_pos": 101, "type": "TASK", "confidence": 0.7184473127126694}]}, {"text": "At the same time, advancements in language modeling have managed to generate linguistic output, which is almost indistinguishable from that of human-generated text.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.7414062321186066}]}, {"text": "In this paper, we up the ante by exploring the potential of more sophisticated language models in GEC and offer some key insights on their strengths and weaknesses.", "labels": [], "entities": []}, {"text": "We show that, inline with recent results in other NLP tasks, Transformer architectures achieve consistently high performance and provide a competitive baseline for future machine learning models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Transformer models () trained on large-scale language modeling datasets have recently proved to be a very effective means of representing the meaning of a sentence, being put to effective use in fine-tuning both sentence-level tasks, such as the GLUE benchmark () and token-level tasks, such as Named Entity Recognition (.", "labels": [], "entities": [{"text": "representing the meaning of a sentence", "start_pos": 125, "end_pos": 163, "type": "TASK", "confidence": 0.8129468560218811}, {"text": "Named Entity Recognition", "start_pos": 295, "end_pos": 319, "type": "TASK", "confidence": 0.6271826128164927}]}, {"text": "Recent work has also found them to produce linguistically valid representations, as well as to display excellent performance across multiple downstream NLP tasks (e.g.,.", "labels": [], "entities": []}, {"text": "In this work, we explore how such models perform in the task of Grammatical Error Correction (GEC).", "labels": [], "entities": [{"text": "Grammatical Error Correction (GEC)", "start_pos": 64, "end_pos": 98, "type": "TASK", "confidence": 0.6054718991120657}]}, {"text": "While there is a substantial amount of work on statistical () and neural () machine translation methods for GEC, we follow the approach of and explore how such models would fare in this task when treated as simple language models.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 76, "end_pos": 95, "type": "TASK", "confidence": 0.7895378470420837}, {"text": "GEC", "start_pos": 108, "end_pos": 111, "type": "TASK", "confidence": 0.9198988080024719}]}, {"text": "More specifically, train a 5-gram language model on the One Billion Word Benchmark () dataset and find that it produces competitive baseline results without any supervised training.", "labels": [], "entities": [{"text": "One Billion Word Benchmark () dataset", "start_pos": 56, "end_pos": 93, "type": "DATASET", "confidence": 0.5779056300719579}]}, {"text": "In our work, we extend this work by substituting the n-gram model for several publicly available implementations of state-of-the-art Transformer language models trained on large linguistic corpora and assess their performance on GEC without any supervised training.", "labels": [], "entities": [{"text": "GEC", "start_pos": 229, "end_pos": 232, "type": "DATASET", "confidence": 0.8448159098625183}]}, {"text": "We find that Transformer language models produce results on par with supervised approaches providing a solid baseline system.", "labels": [], "entities": []}, {"text": "This finding is of particular importance in GEC, where data collection and annotation requires substantial manual effort.", "labels": [], "entities": [{"text": "GEC", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.8800048232078552}, {"text": "data collection", "start_pos": 55, "end_pos": 70, "type": "TASK", "confidence": 0.7613990902900696}]}], "datasetContent": [{"text": "We evaluate our method and report results on two standard publicly available datasets.", "labels": [], "entities": []}, {"text": "Our evaluation is aimed to stay as true to presents the results of our method comparing them against recent state-of-the-art supervised models and the simple n-gram language model used by. shows some qualitative examples on how each model corrects two sentences pulled from the FCE along with the gold annotations.", "labels": [], "entities": [{"text": "FCE", "start_pos": 278, "end_pos": 281, "type": "DATASET", "confidence": 0.9454850554466248}]}, {"text": "The reported results Source It will start by a speech from the Director of the conference, followed by a meal.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results of our Transformer-Language Model approach against similar approaches (Bryant and Briscoe", "labels": [], "entities": []}]}