{"title": [{"text": "Filling Gender & Number Gaps in Neural Machine Translation with Black-box Context Injection", "labels": [], "entities": [{"text": "Neural Machine Translation", "start_pos": 32, "end_pos": 58, "type": "TASK", "confidence": 0.6546905835469564}]}], "abstractContent": [{"text": "When translating from a language that does not morphologically mark information such as gender and number into a language that does, translation systems must \"guess\" this missing information, often leading to incorrect translations in the given context.", "labels": [], "entities": []}, {"text": "We propose a black-box approach for injecting the missing information to a pre-trained neural machine translation system, allowing to control the morphological variations in the generated translations without changing the underlying model or training data.", "labels": [], "entities": []}, {"text": "We evaluate our method on an English to Hebrew translation task, and show that it is effective in injecting the gender and number information and that supplying the correct information improves the translation accuracy in up to 2.3 BLEU on a female-speaker test set fora state-of-the-art online black-box system.", "labels": [], "entities": [{"text": "English to Hebrew translation task", "start_pos": 29, "end_pos": 63, "type": "TASK", "confidence": 0.710562115907669}, {"text": "accuracy", "start_pos": 210, "end_pos": 218, "type": "METRIC", "confidence": 0.9248259663581848}, {"text": "BLEU", "start_pos": 232, "end_pos": 236, "type": "METRIC", "confidence": 0.9983783960342407}]}, {"text": "Finally, we perform a fine-grained syntactic analysis of the generated translations that shows the effectiveness of our method.", "labels": [], "entities": []}], "introductionContent": [{"text": "A common way for marking information about gender, number, and casein language is morphology, or the structure of a given word in the language.", "labels": [], "entities": []}, {"text": "However, different languages mark such information in different ways -for example, in some languages gender maybe marked on the headword of a syntactic dependency relation, while in other languages it is marked on the dependent, on both, or on none of them.", "labels": [], "entities": []}, {"text": "This morphological diversity creates a challenge for machine translation, as there are ambiguous cases where more than one correct translation exists for the same source sentence.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.7875596880912781}]}, {"text": "For example, while the English sentence \"I love language\" is ambiguous with respect to the gender of the speaker, Hebrew marks verbs for the gender of their subject and does not allow gender-neutral translation.", "labels": [], "entities": []}, {"text": "This allows two possible Hebrew translations -one in a masculine and the other in a feminine form.", "labels": [], "entities": []}, {"text": "As a consequence, a sentence-level translator (either human or machine) must commit to the gender of the speaker, adding information that is not present in the source.", "labels": [], "entities": []}, {"text": "Without additional context, this choice must be done arbitrarily by relying on language conventions, world knowledge or statistical (stereotypical) knowledge.", "labels": [], "entities": []}, {"text": "Indeed, the English sentence \"I work as a doctor\" is translated into Hebrew by Google Translate using the masculine verb form oved, indicating a male speaker, while \"I work as a nurse\" is translated with the feminine form ovedet, indicating a female speaker (verified on March 2019).", "labels": [], "entities": []}, {"text": "While this is still an issue, there have been recent efforts to reduce it for specific language pairs.", "labels": [], "entities": [{"text": "it", "start_pos": 71, "end_pos": 73, "type": "METRIC", "confidence": 0.9769350290298462}]}, {"text": "We present a simple black-box method to influence the interpretation chosen by an NMT system in these ambiguous cases.", "labels": [], "entities": []}, {"text": "More concretely, we construct pre-defined textual hints about the gender and number of the speaker and the audience (the interlocutors), which we concatenate to a given input sentence that we would like to translate accordingly.", "labels": [], "entities": []}, {"text": "We then show that a black-box NMT system makes the desired morphological decisions according to the given hint, even when no other evidence is available on the source side.", "labels": [], "entities": []}, {"text": "While adding those hints results in additional text on the target side, we show that it is simple to remove, leaving only the desired translation.", "labels": [], "entities": []}, {"text": "Our method is appealing as it only requires simple pre-and-post processing of the inputs and outputs, without considering the system internals, or requiring specific annotated data and training procedure as in previous work.", "labels": [], "entities": []}, {"text": "We show that in spite of its simplicity, it is effective in resolving many of the ambiguities and improves the translation quality in up to 2.3 BLEU when given the correct hints, which maybe inferred from text metadata or other sources.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 144, "end_pos": 148, "type": "METRIC", "confidence": 0.998789370059967}]}, {"text": "Finally, we perform a fine-grained syntactic analysis of the translations generated using our method which shows its effectiveness.", "labels": [], "entities": []}], "datasetContent": [{"text": "To demonstrate our method in a black-box setting, we focus our experiments on Google's machine translation system (GMT), accessed through its Cloud API.", "labels": [], "entities": [{"text": "machine translation system (GMT)", "start_pos": 87, "end_pos": 119, "type": "TASK", "confidence": 0.6812020689249039}]}, {"text": "To test the method on real-world sentences, we consider a monologue from the standup comedy show \"Sarah Silverman: A Speck of Dust\".", "labels": [], "entities": []}, {"text": "We translate the monologue one sentence at a time through the Google Cloud API.", "labels": [], "entities": []}, {"text": "Eyeballing the results suggest that most of the translations use the incorrect, but default, masculine and singular forms for the speaker and the audience, respectively.", "labels": [], "entities": []}, {"text": "We expect that by adding the relevant condition of \"female speaking to an audience\" we will get better translations, affecting both the gender of the speaker and the number of the audience.", "labels": [], "entities": []}, {"text": "To verify this, we experiment with translating the sentences with the following variations: No Prefix-The baseline translation as returned by the GMT system.", "labels": [], "entities": [{"text": "GMT", "start_pos": 146, "end_pos": 149, "type": "DATASET", "confidence": 0.911102294921875}]}, {"text": "\"He said:\"-Signaling a male speaker.", "labels": [], "entities": []}, {"text": "We expect to further skew the system towards masculine forms.", "labels": [], "entities": []}, {"text": "\"She said:\"-Signaling a female speaker and unknown audience.", "labels": [], "entities": []}, {"text": "As this matches the actual speaker's gender, we expect an improvement in translation of first-person pronouns and verbs with first-person pronouns as subjects.", "labels": [], "entities": []}, {"text": "\"I said to them:\"-Signaling an unknown speaker and plural audience.", "labels": [], "entities": []}, {"text": "\"He said to them:\"-Masculine speaker and plural audience.", "labels": [], "entities": []}, {"text": "\"She said to them:\"-Female speaker and plural audience-the complete, correct condition.", "labels": [], "entities": []}, {"text": "We expect the best translation accuracy on this setup.", "labels": [], "entities": [{"text": "translation", "start_pos": 19, "end_pos": 30, "type": "TASK", "confidence": 0.9644497036933899}, {"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9467768669128418}]}, {"text": "\"He/she said to him/her\"-Here we set an (incorrect) singular gender-marked audience, to investigate our ability to control the audience morphology.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Comparison of our approach (using  Google Translate) to Vanmassenhove et al. (2018)  on their English-French gender corpus.", "labels": [], "entities": []}]}