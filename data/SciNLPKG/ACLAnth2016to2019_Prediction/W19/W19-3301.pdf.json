{"title": [{"text": "Cross-Lingual Semantic Annotation: Reconciling the Language-Specific and the Universal", "labels": [], "entities": [{"text": "Cross-Lingual Semantic Annotation", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.5956324140230814}]}], "abstractContent": [{"text": "Developers of cross-lingual semantic annotation schemes face a number of issues not encountered in monolingual annotation.", "labels": [], "entities": []}, {"text": "This paper discusses four such issues, related to the establishment of annotation labels, and the treatment of languages with more fine-grained, more coarse-grained, and cross-cutting categories.", "labels": [], "entities": []}, {"text": "We propose that a lattice-like architecture of the annotation categories can adequately handle all four issues, and at the same time remain both intuitive for annotators and faithful to typological insights.", "labels": [], "entities": []}, {"text": "This position is supported by a brief annotation experiment.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, the field of computational linguistics has become increasingly interested in annotation schemes with cross-lingual applicability ().", "labels": [], "entities": [{"text": "computational linguistics", "start_pos": 30, "end_pos": 55, "type": "TASK", "confidence": 0.7338679730892181}]}, {"text": "For syntactic annotation, the Universal Dependencies scheme for grammatical relations between constituents ( is probably the best-known representative of this new tendency.", "labels": [], "entities": [{"text": "syntactic annotation", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.8982762396335602}]}, {"text": "On the semantic side, various annotation schemes have been proposed for specific conceptual domains.", "labels": [], "entities": []}, {"text": "The Abstract Meaning Representation project () aims to provide a language-neutral representation of argument structure, and was shown by to have potential in this direction.", "labels": [], "entities": [{"text": "Abstract Meaning Representation", "start_pos": 4, "end_pos": 35, "type": "TASK", "confidence": 0.798568069934845}]}, {"text": "The Universal Conceptual Cognitive Annotation has the same objective.", "labels": [], "entities": []}, {"text": "Annotation schemes designed for cross-lingual application have also been proposed for such semantic domains as the meanings of discourse connectives, temporal information (), epistemicity (, modality in general (, and prepositionlike senses).", "labels": [], "entities": []}, {"text": "However, languages diverge widely in the semantic distinctions they conventionally express, and in the formal means they use to do so).", "labels": [], "entities": []}, {"text": "Therefore, devising a crosslingual annotation scheme poses challenges that developers of language-specific schemes need not face.", "labels": [], "entities": []}, {"text": "This paper discusses some crucial choices developers of cross-lingual semantic annotation schemes must make with regards to the granularity of linguistic categories.", "labels": [], "entities": []}, {"text": "To a large extent, these apply to syntactic annotation as well.", "labels": [], "entities": []}, {"text": "In particular, the following four issues need to be accounted for by any annotation scheme with cross-linguistic ambitions: 1.", "labels": [], "entities": []}, {"text": "What are the values of the basic labels of the semantic annotation scheme, i.e. which distinctions are annotators expected to make?", "labels": [], "entities": []}, {"text": "2. How are languages with more coarse-grained semantic distinctions accommodated?", "labels": [], "entities": []}, {"text": "3. How are languages with more fine-grained semantic distinctions accommodated?", "labels": [], "entities": []}, {"text": "4. How are languages with distinctions that cross-cut the categories distinguished in the base level annotation scheme treated?", "labels": [], "entities": []}, {"text": "Section 2 of this paper discusses these issues in more detail, exemplifying each of them with data from a range of semantic domains and a range of languages, and section 3 provides a brief overview of how previous cross-lingual annotation schemes have treated them.", "labels": [], "entities": []}, {"text": "In section 4, we survey a wider range of possible solutions for these challenges, each with their advantages and drawbacks, and make an argument in favour of establishing a lattice-like structure of hierarchically organized, typologically motivated categories.", "labels": [], "entities": []}, {"text": "We also propose a set of guidelines for annotators on which levels of this lattice to use.", "labels": [], "entities": []}, {"text": "Section 5 presents an exploratory cross-lingual annotation exercise using such an architecture.", "labels": [], "entities": []}], "datasetContent": [{"text": "We are aware of few previous experiments annotating multilingual parallel corpora with one set of semantic categories.", "labels": [], "entities": []}, {"text": "Closest to our pilot study is probably, who calculate agreement between annotations of a parallel corpus in English, French, German, Dutch, and Italian.", "labels": [], "entities": []}, {"text": "Pairwise agreement between English and every other language is reported for each level of the hierarchy in which their categories are structured.", "labels": [], "entities": []}, {"text": "The agreement values are given only in raw percentages.", "labels": [], "entities": [{"text": "agreement", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9510484933853149}]}, {"text": "We report pair-wise agreement between all pairs of languages in our pilot.", "labels": [], "entities": []}, {"text": "We report both the ex-act correspondence of annotations between languages, and the compatibility of these annotations.", "labels": [], "entities": [{"text": "compatibility", "start_pos": 83, "end_pos": 96, "type": "METRIC", "confidence": 0.9726786017417908}]}, {"text": "The first set of values is conceptualized as a measure of the discrepancies between the semantic categories of individual languages.", "labels": [], "entities": []}, {"text": "For example, an attachment scenario might be annotated as ATTACHMENT in Dutch (which has a preposition aan specialized for attachment), but as NON-CONTAINMENT in English, because of its more coarse-grained semantic structure.", "labels": [], "entities": [{"text": "ATTACHMENT", "start_pos": 58, "end_pos": 68, "type": "METRIC", "confidence": 0.9695895910263062}]}, {"text": "Under this first measure, these cases are counted as disagreements.", "labels": [], "entities": []}, {"text": "Under the second measure, they are seen as compatible.", "labels": [], "entities": []}, {"text": "Since ATTACHMENT is a subcategory of NON-CONTAINMENT, the Dutch annotation can be traced back in the lattice to NON-CONTAINMENT, and the two languages have equivalent annotations on this level.", "labels": [], "entities": [{"text": "ATTACHMENT", "start_pos": 6, "end_pos": 16, "type": "METRIC", "confidence": 0.7236328721046448}, {"text": "NON-CONTAINMENT", "start_pos": 37, "end_pos": 52, "type": "DATASET", "confidence": 0.9066932201385498}]}, {"text": "The difference between the exact correspondence score fora language pair and its compatibility score measures the portability of the lattice architecture, and its ability to abstract away from language-specific subdivisions of semantic space.", "labels": [], "entities": []}, {"text": "Both the exact correspondence measure and the compatibility measure are reported as agreement proportions, and as Cohen's Kappa scores).", "labels": [], "entities": [{"text": "exact correspondence measure", "start_pos": 9, "end_pos": 37, "type": "METRIC", "confidence": 0.845012346903483}, {"text": "compatibility measure", "start_pos": 46, "end_pos": 67, "type": "METRIC", "confidence": 0.9846276640892029}]}, {"text": "We believe that, even though we are calculating cross-lingual interannotator agreement rather than monolingual agreement between two annotators, the tasks performed by the annotators are still comparable.", "labels": [], "entities": []}, {"text": "Since we use a parallel corpus and the same set of annotation values, Cohen's Kappa provides a meaningful measure of how much the proposed annotation system improves labeling over a chance distribution.", "labels": [], "entities": []}, {"text": "reports cross-lingual interannotator agreement for identity between the chosen labels.", "labels": [], "entities": []}, {"text": "The raw proportions of agreement are high, ranging from 82% (Czech-English and Korean-English) to 93% (Czech-Dutch).", "labels": [], "entities": []}, {"text": "The Cohen's Kappa scores are also acceptable (between 0.64 and 0.86).", "labels": [], "entities": []}], "tableCaptions": []}