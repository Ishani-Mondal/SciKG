{"title": [{"text": "Can Greenbergian universals be induced from language networks?", "labels": [], "entities": []}], "abstractContent": [{"text": "Language networks have been proposed to be the underlying representation for syntactic knowledge (Roelofs, 1992; Pickering and Branigan, 1998).", "labels": [], "entities": []}, {"text": "Such networks are known to explain various word order related priming effects in psycholinguistics.", "labels": [], "entities": []}, {"text": "Under the assumption that word order information is encoded in these networks, we explore if Greenbergian word order universals (Greenberg, 1963) can be induced from such networks.", "labels": [], "entities": []}, {"text": "Language networks for 34 languages were constructed from the Universal Dependencies Treebank (Nivre et al., 2016) based on the assumptions in Roelofs (1992); Pickering and Branigan (1998).", "labels": [], "entities": []}, {"text": "We conducted a series of experiments to investigate if certain network parameters can be used to cluster various languages based on the word order typology proposed by Greenberg.", "labels": [], "entities": []}, {"text": "Our results show that some network parameters robustly cluster the languages correctly, thereby providing some support for language network as a valid representation for such linguistic generalizations.", "labels": [], "entities": []}], "introductionContent": [{"text": "Establishing connections and relations between objects is an important way of representing knowledge.", "labels": [], "entities": []}, {"text": "Such a representation lends itself to a succinct understanding of its structure and complexity.", "labels": [], "entities": []}, {"text": "Such network representations are routinely used to understand complex systems such as social systems, biological systems, economic systems and soon.", "labels": [], "entities": []}, {"text": "Language seems well suited for this type of representation; after all, the knowledge of language and its use, is primarily about establishing relations between different kinds of linguistic objects.", "labels": [], "entities": []}, {"text": "Indeed, the significance of such networks was appreciated quite early in the domain of meaning representation in terms of semantic relatedness).", "labels": [], "entities": [{"text": "meaning representation", "start_pos": 87, "end_pos": 109, "type": "TASK", "confidence": 0.7239997386932373}]}, {"text": "Such semantic networks have been shown to capture experimental results on lexical priming).", "labels": [], "entities": []}, {"text": "Additionally, various resources (e.g., Wordnet) and as well as models (e.g.,) have been proposed with the motivation of establishing relations between similar words.", "labels": [], "entities": [{"text": "Wordnet", "start_pos": 39, "end_pos": 46, "type": "DATASET", "confidence": 0.9686850309371948}]}, {"text": "A network-based representation has also been proposed to subserve syntactic knowledge in the mind).", "labels": [], "entities": []}, {"text": "Such a network has been claimed to correctly explain the syntactic priming effects in during language production/comprehension (.", "labels": [], "entities": []}, {"text": "Networks have also been used to quantify cognitive processes and representations related to various linguistic levels such as).", "labels": [], "entities": []}, {"text": "Network theory has been extensively used to understand (and visualize) such knowledge representations (.", "labels": [], "entities": []}, {"text": "Network theory formalizes a knowledge system as a network, which contains nodes and edges describing the entities and the relations between them.", "labels": [], "entities": [{"text": "Network theory", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.767315149307251}]}, {"text": "Network theory enables us to extract specific information related to the connectedness and relationships between various entities).", "labels": [], "entities": []}, {"text": "The primary attraction of representing a complex system in the form of a network lies in the ease with which various relations present in the data can be visualized.", "labels": [], "entities": []}, {"text": "In addition, it has the ability to abstract the relations at different levels, ranging from a single node, to viewing the properties of the entire network as a whole ().", "labels": [], "entities": []}, {"text": "The idea of language as a network has been gaining some traction in computational linguistics.", "labels": [], "entities": []}, {"text": "One approach, that we explore here, is to construct language networks from annotated dependency treebank to encode syntactic relationship between lexical items.", "labels": [], "entities": []}, {"text": "Previous works on such language representation have explored the properties of language networks formed through dependency treebanks), also see Cong and.", "labels": [], "entities": []}, {"text": "Relatedly,; used language network to successfully cluster languages into phylogenetic groups using network parameters.", "labels": [], "entities": []}, {"text": "As stated earlier, networks have also been hypothesized to be the representation that subserves syntactic knowledge in the mind).", "labels": [], "entities": []}, {"text": "In particular, it has been used to explain syntactic priming with respect to various word order choices during sentence comprehension and production.", "labels": [], "entities": []}, {"text": "This implies that networks can represent various syntactic rules (e.g., word order) in terms of nodes and their relationship with other nodes in the network.", "labels": [], "entities": []}, {"text": "In other words, the network as a representation of language should contain the same generalisations as present in a language.", "labels": [], "entities": []}, {"text": "Greenberg's universals area set of such generalisations that occur across languages.", "labels": [], "entities": []}, {"text": "These universals and their status in language networks is the focus of this article.", "labels": [], "entities": []}, {"text": "In this work 1 , we build a psycholinguistically motivated language network) for 34 languages to investigate if Greenberg's word order related language universals (GU) can be induced from the networks.", "labels": [], "entities": []}, {"text": "To do this, we conduct two experiments.", "labels": [], "entities": []}, {"text": "In the first experiment, we simply map the GUs onto a language network to see if a particular node property (percentage of outgoing arcs) leads to the desired classification across languages.", "labels": [], "entities": []}, {"text": "For example, for GU universal no.", "labels": [], "entities": []}, {"text": "3, we look at this parameter of the VSO nodes across all language networks and see if the parameter values cluster the respective languages as prepositional or postpositional.", "labels": [], "entities": []}, {"text": "In the second experiment, we automatically derive certain implicational universals stated by Greenberg.", "labels": [], "entities": []}, {"text": "For example, we see which word order node (e.g., SVO, SOV, etc) best classifies the order of adposition and noun phrase.", "labels": [], "entities": []}, {"text": "In effect, the first experiment is completely correlational and supervised -checking if a known node parameter leads to the correct language typology.", "labels": [], "entities": []}, {"text": "The second experiment, is unsupervised -checking which node (and its parameter) leads to the correct language typology.", "labels": [], "entities": []}, {"text": "Together, the two experiments shed light on whether language network can induce correct GU wrt word order and highlights the properties of the network where this information can be found.", "labels": [], "entities": []}, {"text": "The paper is arranged as follows.", "labels": [], "entities": []}, {"text": "We begin with a description of the data, tools and network formation in the Section 2.", "labels": [], "entities": []}, {"text": "In section 3 we present the two experiments and discuss the results.", "labels": [], "entities": []}, {"text": "Following this, in section 4 we conclude the paper and list out some future directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments discussed in this section assume that a large probability is related with a strong connection and more likelihood that the connected nodes show the 'combinatorial' property encapsulated by the concerned Layer 2 node.", "labels": [], "entities": []}, {"text": "Further, in order to do the network analysis, we used the sentential distance only as a weight to the edges.", "labels": [], "entities": [{"text": "network analysis", "start_pos": 28, "end_pos": 44, "type": "TASK", "confidence": 0.6821530312299728}]}, {"text": "For the connections between Layer 1 and Layer 2, we used the inverse of the probabilities as the edge weights so that the range is from.", "labels": [], "entities": []}, {"text": "All network analysis was performed using Cytoscape ().", "labels": [], "entities": []}, {"text": "In particular, Cytoscape provides a tool named Network Analyzer which was used to analyse the network with various parameters . All analysis reported below has been done on the network parameters corresponding to the nodes in layer 2.", "labels": [], "entities": []}, {"text": "In the first experiment, we simply map the GUs onto a language network to see if a particular node property (percentage of outgoing arc) leads to the desired classification across languages.", "labels": [], "entities": []}, {"text": "In the second experiment, we automatically derive certain implicational universal stated by.", "labels": [], "entities": []}, {"text": "For example, we see which word order node (e.g., SVO, SOV, etc) best classifies the order of adposition and noun phrase.", "labels": [], "entities": []}, {"text": "In order to map the Greenbergian universals wrt certain linguistic orders onto the network, we reduced the problem to only probing the node parameters of the layer 2 'combinatorial' nodes.", "labels": [], "entities": []}, {"text": "This was done because we are interested in word order generalizations related to the verb.", "labels": [], "entities": [{"text": "word order generalizations", "start_pos": 43, "end_pos": 69, "type": "TASK", "confidence": 0.651287704706192}]}, {"text": "In particular, we looked at each of the word-order based Greenbergian universal and translated them to a particular network parameter of various combinatorial nodes in layer 2.", "labels": [], "entities": []}, {"text": "The orders SOV, SVO, VSO etc. are believed to be encoded in the parameter 'Outperc' of the layer 2 nodes.", "labels": [], "entities": [{"text": "Outperc", "start_pos": 75, "end_pos": 82, "type": "METRIC", "confidence": 0.9399250149726868}]}, {"text": "'Outperc' is defined as the out-degree of the concerned node divided by the total no. of nodes in layer 2.", "labels": [], "entities": [{"text": "Outperc", "start_pos": 1, "end_pos": 8, "type": "METRIC", "confidence": 0.9622323513031006}]}, {"text": "A language is deemed to be SOV if the SOV node's 'Outperc' is high relative to other nodes in layer 2.", "labels": [], "entities": []}, {"text": "We investigate if the distribution of 'Outperc' across all language networks leads to the correct language typology clusters.", "labels": [], "entities": []}, {"text": "This experiment is intended as a supervised way of identifying language typology clusters based on Greenberg's word order universals.", "labels": [], "entities": []}, {"text": "The data available in WALS) was used to get the word order patterns related to the Greenbergian universals for various language.", "labels": [], "entities": []}, {"text": "Experiment 1 targetted a specific universal and mapped it onto the network using a prespecified node property (Outperc/Outdgree of SOV, VSO, SVO layer 2 nodes).", "labels": [], "entities": []}, {"text": "In experiment 2, we asked a more general question -which node parameter in different language networks leads to the best language typology classi-  fication based on Greenberg's universals?", "labels": [], "entities": []}, {"text": "The linguistic orders that we looked at were taken from WALS (Dryer and Haspelmath, 2013)]; these were, (a) Order of subject, verb and object, (b) Order of Adposition and Noun Phrase, (c) Order of Adjective and Noun, and (d) Position of Interrogative Phrase and Content Questions.", "labels": [], "entities": [{"text": "Position of Interrogative Phrase and Content Questions", "start_pos": 225, "end_pos": 279, "type": "TASK", "confidence": 0.6821791444505964}]}, {"text": "We investigate various parameters 8 for each node in layer 2 to see which node-parameter combinations across all the languages lead to the best language classification fora particular word order.", "labels": [], "entities": []}, {"text": "For example, consider \"Order of Adposition and Noun Phrase\".", "labels": [], "entities": []}, {"text": "In order to find which parameter of which layer 2 node can lead to the best classification of languages based on this order, we get a particular node-parameter values from all language networks, and check if this distribution leads to the correct classification of languages as given in the WALS data.", "labels": [], "entities": [{"text": "WALS data", "start_pos": 291, "end_pos": 300, "type": "DATASET", "confidence": 0.8565488159656525}]}, {"text": "The correlation between the node-parameter values and the correct language cluster (which is already known) is quantified by silhouette value.", "labels": [], "entities": [{"text": "silhouette", "start_pos": 125, "end_pos": 135, "type": "METRIC", "confidence": 0.9796903133392334}]}, {"text": "This silhouette value is obtained for all the (nodes \u00d7 parameters) node-parameter combinations and the highest score gives us the node-parameter that classifies the languages best based on the word order under consideration.", "labels": [], "entities": []}, {"text": "A greater silhouette value corresponds to better clustering.", "labels": [], "entities": [{"text": "silhouette", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9768148064613342}]}, {"text": "Intuitively, the silhouette value captures the cohesiveness of the data point with its cluster.", "labels": [], "entities": []}, {"text": "To summarize, experiment 2 discusses a method to induce the linguistic orders by probing all possible parameters for each verb-order nodes that are contained in layer 2.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Top 3 silhouette score for the clusters related to the 4 word order patterns. 81A: Order of subject,  verb and object; 85A: Order of adposition and noun phrase; 87A: Order of adjective and noun; 93A: position  of interrogative phrases in content question. Note: The results for 85A are based on manual evaluation as the  top silhouette scores failed to give the correct clusters. Closeness C = Closeness Centrality; Neighbourhood  C = Neighbourhood connectivity.", "labels": [], "entities": []}]}