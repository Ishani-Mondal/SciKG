{"title": [{"text": "Unsupervised Multi-Word Term Recognition in Welsh", "labels": [], "entities": [{"text": "Multi-Word Term Recognition", "start_pos": 13, "end_pos": 40, "type": "TASK", "confidence": 0.7491569817066193}, {"text": "Welsh", "start_pos": 44, "end_pos": 49, "type": "DATASET", "confidence": 0.7654658555984497}]}], "abstractContent": [{"text": "This paper investigates an adaptation of an existing system for multi-word term recognition, originally developed for English, for Welsh.", "labels": [], "entities": [{"text": "multi-word term recognition", "start_pos": 64, "end_pos": 91, "type": "TASK", "confidence": 0.6271374126275381}]}, {"text": "We overview the modifications required with a special focus on an important difference between the two representatives of two language families, Germanic and Celtic, which is concerned with the directionality of noun phrases.", "labels": [], "entities": []}, {"text": "We successfully modelled these differences by means of lexico-syntactic patterns, which represent parameters of the system and, therefore, required no re-implementation of the core algorithm.", "labels": [], "entities": []}, {"text": "The performance of the Welsh version was compared against that of the English version.", "labels": [], "entities": []}, {"text": "For this purpose, we assembled three parallel domain-specific corpora.", "labels": [], "entities": []}, {"text": "The results were compared in terms of precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9997085928916931}, {"text": "recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.999275267124176}]}, {"text": "Comparable performance was achieved across the three domains in terms of the two measures (P = 68.9%, R = 55.7%), but also in the ranking of automatically extracted terms measured by weighted kappa coefficient (\uf06b = 0.7758).", "labels": [], "entities": [{"text": "P", "start_pos": 91, "end_pos": 92, "type": "METRIC", "confidence": 0.9646565318107605}, {"text": "R", "start_pos": 102, "end_pos": 103, "type": "METRIC", "confidence": 0.9833253622055054}]}, {"text": "These early results indicate that our approach to term recognition can provide a basis for machine translation of multi-word terms.", "labels": [], "entities": [{"text": "term recognition", "start_pos": 50, "end_pos": 66, "type": "TASK", "confidence": 0.8737241625785828}, {"text": "machine translation of multi-word terms", "start_pos": 91, "end_pos": 130, "type": "TASK", "confidence": 0.8014771938323975}]}], "introductionContent": [{"text": "Terms are noun phrases) that are frequently used in specialised texts to refer to concepts specific to a given domain.", "labels": [], "entities": []}, {"text": "In other words, terms are linguistic representations of domain-specific concepts.", "labels": [], "entities": []}, {"text": "As such, terms are key means of communicating effectively in a scientific or technical discourse.", "labels": [], "entities": []}, {"text": "To ensure that terms conform to specific standards, they often undergo a process of standardisation.", "labels": [], "entities": []}, {"text": "Such standards are commonly based on the following principles.", "labels": [], "entities": []}, {"text": "First and foremost, a term should be linguistically correct and reflect the key characteristics of the concept it represents in concise manner.", "labels": [], "entities": []}, {"text": "There should only be one term per concept and all other variations (e.g. acronyms and inflected forms) should be derivatives of that term.", "labels": [], "entities": []}, {"text": "TermCymru, a terminology used by the Welsh Government translators, assigns a status to each term depending on the degree to which it has been standardised: fully standardised, partially standardised and linguistically verified.", "labels": [], "entities": [{"text": "TermCymru", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.6191900372505188}, {"text": "Welsh Government translators", "start_pos": 37, "end_pos": 65, "type": "DATASET", "confidence": 0.8472840587298075}]}, {"text": "Terms will still naturally vary in length and their level of fixedness, i.e. the strength of association between specific lexical items, which can be measured using mutual information, z-score or t-score.", "labels": [], "entities": []}, {"text": "Such variation of terms within a language may pose problems when attempting to translate term variants consistently into another language.", "labels": [], "entities": []}, {"text": "Verbatim translations also often deviate from the established terminology in the target language, e.g. TermCymru in Welsh.", "labels": [], "entities": [{"text": "Verbatim translations", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7550809681415558}]}, {"text": "Therefore, high-quality translations, performed by either humans or machines, require management of terminologies.", "labels": [], "entities": []}, {"text": "Specialised text requires consistent use of terminology, where the same term is used consistently throughout a discourse to refer to the same concept.", "labels": [], "entities": []}, {"text": "Very often, terms cannot be translated word for word.", "labels": [], "entities": []}, {"text": "Therefore, most machine translation systems maintain a term base in order to support translations that use established terminology in the target language.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 16, "end_pos": 35, "type": "TASK", "confidence": 0.7525524199008942}]}, {"text": "Given a potentially unlimited number of domains as well as a dynamic nature of many domains (e.g. computer science) where new terms get introduced regularly, manual maintenance of one-to-one term bases for each pair of languages may become unmanageable.", "labels": [], "entities": []}, {"text": "Where parallel corpora exist, automatic term recognition approaches can be used to extract terms and their translations, which can then be embedded into the term base to support machine translation of other document from the same domain.", "labels": [], "entities": [{"text": "term recognition", "start_pos": 40, "end_pos": 56, "type": "TASK", "confidence": 0.7077397406101227}]}, {"text": "To that end, we are focusing on comparing the performance of an unsupervised approach to automatic term recognition in two languages, Welsh and English, as an important step towards machine translation of specialised texts in the given languages.", "labels": [], "entities": [{"text": "term recognition", "start_pos": 99, "end_pos": 115, "type": "TASK", "confidence": 0.7401585429906845}, {"text": "machine translation of specialised texts", "start_pos": 182, "end_pos": 222, "type": "TASK", "confidence": 0.8276624917984009}]}], "datasetContent": [{"text": "We ran two versions of FlexiTerm against the three parallel corpora.", "labels": [], "entities": [{"text": "FlexiTerm", "start_pos": 23, "end_pos": 32, "type": "DATASET", "confidence": 0.8965480923652649}]}, {"text": "specifies the number of automatically recognised terms in each language.", "labels": [], "entities": []}, {"text": "The Welsh output was evaluated against the corresponding English output (used here as the silver standard) in terms of precision and recall (also specified in).", "labels": [], "entities": [{"text": "Welsh output", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.8584210276603699}, {"text": "precision", "start_pos": 119, "end_pos": 128, "type": "METRIC", "confidence": 0.9997071623802185}, {"text": "recall", "start_pos": 133, "end_pos": 139, "type": "METRIC", "confidence": 0.9996718168258667}]}, {"text": "In other words, to calculate precision, for every Welsh term candidate, we checked whether its equivalent (i.e. translation) appeared in the English output.", "labels": [], "entities": [{"text": "precision", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.9992732405662537}]}, {"text": "Vice versa, to calculate recall, for every English term candidate, we checked whether its equivalent appeared in the Welsh output.", "labels": [], "entities": [{"text": "recall", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9993341565132141}, {"text": "Welsh output", "start_pos": 117, "end_pos": 129, "type": "DATASET", "confidence": 0.9100081920623779}]}, {"text": "Across the three domains, the Welsh version of FlexiTerm performed more consistently in terms of precision, which was relatively high (i.e. >60%).", "labels": [], "entities": [{"text": "FlexiTerm", "start_pos": 47, "end_pos": 56, "type": "DATASET", "confidence": 0.6298703551292419}, {"text": "precision", "start_pos": 97, "end_pos": 106, "type": "METRIC", "confidence": 0.9996181726455688}]}, {"text": "However, the recall varied significantly across the three corpora ranging from as low as 46.3% to as high as 65.6%.", "labels": [], "entities": [{"text": "recall", "start_pos": 13, "end_pos": 19, "type": "METRIC", "confidence": 0.9978122711181641}]}], "tableCaptions": [{"text": " Table 3: Three parallel domain-specific corpora", "labels": [], "entities": []}]}