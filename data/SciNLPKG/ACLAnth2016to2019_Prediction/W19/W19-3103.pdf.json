{"title": [{"text": "Latent Variable Grammars for Discontinuous Parsing Invited Talk", "labels": [], "entities": []}], "abstractContent": [{"text": "Latent variable context-free grammars are powerful models for predicting the syntactic structure of sentences (Matsuzaki, Miyao, and Tsujii 2005; Petrov, Barrett, et al. 2006; Petrov and Klein 2007).", "labels": [], "entities": [{"text": "predicting the syntactic structure of sentences", "start_pos": 62, "end_pos": 109, "type": "TASK", "confidence": 0.8040855427583059}]}, {"text": "When trained on annotated corpora, the resulting latent variables can be shown to capture different distributions for, e.g., NPs in subject and object position.", "labels": [], "entities": []}, {"text": "Several languages (and in consequence also syntactic treebanks for these languages) such as Dutch (Lassy van Noord 2009), German (NeGra, Skut et al. 1997; TiGer Brants et al.", "labels": [], "entities": []}, {"text": "2004), but also English (Penn Treebank, Marcus, Santorini, and Marcinkiewicz 1993, Evang and Kallmeyer 2011) contain structures that cannot be adequately modelled by context-free grammars.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 25, "end_pos": 38, "type": "DATASET", "confidence": 0.9553591012954712}]}, {"text": "In consequence, a class of more power grammar formalisms called mildly context-sensitive has been studied (cf. Kallmeyer 2010).", "labels": [], "entities": []}, {"text": "Although parsing with these models is polynomial in the length of the input sentence (Seki et al.", "labels": [], "entities": []}, {"text": "1991), it has fora longtime been regarded prohibitively slow.", "labels": [], "entities": []}, {"text": "However, in recent years it was shown that the application of mildly-context sensitive grammars is feasible in coarse-to-fine parsing approaches (van Cranenburgh 2012; Ruprecht and Denkinger 2019).", "labels": [], "entities": []}, {"text": "In this talk I consider how both the latent variable approach and mildly context-sensitive grammars can be joined and applied to discontinuous treebanks: 1.", "labels": [], "entities": []}, {"text": "A large class of latent variable grammars can be captured as a probabilistic regular tree grammar combined with an algebra.", "labels": [], "entities": []}, {"text": "I show how the training methodology of latent variable PCFG can be generalized for this class.", "labels": [], "entities": []}, {"text": "2. I recall two mildly context-sensitive grammar formalisms: linear context-free rewriting systems (LCFRS, Vijay-Shanker, Weir, and Joshi 1987) and hybrid grammars (Neder-hof and Vogler 2014; Gebhardt, Nederhof, and Vogler 2017).", "labels": [], "entities": []}, {"text": "In particular, I consider the induction of hybrid grammars, which can be parametrized such that the polynomial complexity of parsing is of bounded degree.", "labels": [], "entities": []}, {"text": "This way also hybrid grammars that are structurally equivalent to finite state automata can be obtained.", "labels": [], "entities": []}, {"text": "3. I analyse different trends when training latent variable LCFRS and hybrid grammars on different discontinuous treebanks and applying them for parsing.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}