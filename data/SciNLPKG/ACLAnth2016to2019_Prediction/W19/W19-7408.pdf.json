{"title": [{"text": "Building a Speech Corpus based on Arabic Podcasts for Language and Dialect Identification", "labels": [], "entities": [{"text": "Language and Dialect Identification", "start_pos": 54, "end_pos": 89, "type": "TASK", "confidence": 0.7351564913988113}]}], "abstractContent": [{"text": "In this paper, we present ArPod, anew Arabic speech corpus made of Arabic audio podcasts.", "labels": [], "entities": []}, {"text": "We built this dataset, mainly for both speech-based multilingual and multi-dialectal identification tasks.", "labels": [], "entities": [{"text": "multi-dialectal identification tasks", "start_pos": 69, "end_pos": 105, "type": "TASK", "confidence": 0.784694770971934}]}, {"text": "It includes two languages: Modern Standard Arabic (MSA) and English, and four Arabic dialects: Saudi, Egyptian, Lebanese and Syrian.", "labels": [], "entities": []}, {"text": "A set of supervised classifiers have been used: Support Vector Machines (SVM), Multi Layer Perceptron (MLP), K-Nearest Neighbors (KNN), Ex-tratrees and Convolutional Neural Networks (CNN), using acoustic and spectral features.", "labels": [], "entities": []}, {"text": "For both tasks, SVM yielded encouraging results and outperformed the other classifiers.", "labels": [], "entities": []}], "introductionContent": [{"text": "The most popular researches on spoken audio language/dialects identification has been conducted based on acoustic information, Phonotactic and prosodic approaches and other techniques.", "labels": [], "entities": [{"text": "spoken audio language/dialects identification", "start_pos": 31, "end_pos": 76, "type": "TASK", "confidence": 0.668228859702746}]}, {"text": "Acoustic information is the lowest and nevertheless simplest level of features that can denote a speech waveform.", "labels": [], "entities": []}, {"text": "Indeed, in (, MFCC features have been extracted to study the impact of MFCC's coefficients on Indian language recognition . Phonotactic and prosodic information have been used in(  and . The authors applied a phonotactic approach to automatically detect Arabic dialects by using phone recognizer followed by dialect modeling using trigram models.", "labels": [], "entities": [{"text": "Indian language recognition", "start_pos": 94, "end_pos": 121, "type": "TASK", "confidence": 0.7039222915967306}]}, {"text": "They also examined the role of prosodic features (intonation and rhythm) for identification of dialects from four Arabic regions: Gulf, Iraq, Levantine and Egypt.", "labels": [], "entities": []}, {"text": "In other researches like in (Alshutayri and Albarhamtoshy, 2011), authors trained HMM to characterize part of speech, to implement a dialect identification system.", "labels": [], "entities": [{"text": "dialect identification", "start_pos": 133, "end_pos": 155, "type": "TASK", "confidence": 0.7141580879688263}]}, {"text": "In order to establish robust systems for Language/dialect identification, spoken corpora have been developed by research community for several languages, but many other languages still lack such resources such as Arabic.", "labels": [], "entities": [{"text": "Language/dialect identification", "start_pos": 41, "end_pos": 72, "type": "TASK", "confidence": 0.6080506294965744}]}, {"text": "That is why we developed anew speech corpus, Arpod-1.0, which is a Multilingual Arabic spoken dataset extracted from the web podcast.", "labels": [], "entities": []}, {"text": "This dataset is composed of more than 8 hours, devoted for Arabic and some of its dialects: Saudi, Lebanese, Egyptian and Syrian, in addition to English.", "labels": [], "entities": []}, {"text": "The dataset has been separated to two categories: Languages and dialects without code switching, and dialects with code switching.", "labels": [], "entities": []}, {"text": "We trained SVM, Extratrees and kNN using acoustic and spectral features, and CNN using spectorgram.", "labels": [], "entities": [{"text": "Extratrees", "start_pos": 16, "end_pos": 26, "type": "DATASET", "confidence": 0.9098581075668335}, {"text": "CNN", "start_pos": 77, "end_pos": 80, "type": "DATASET", "confidence": 0.7839657664299011}]}, {"text": "In addition, we conducted experiments to find the impact of duration on speech utterances language identification.", "labels": [], "entities": [{"text": "duration", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9490116238594055}, {"text": "speech utterances language identification", "start_pos": 72, "end_pos": 113, "type": "TASK", "confidence": 0.7482315972447395}]}, {"text": "Indeed, three duration values have been considered: 6 sec, 30 sec and 1 min.", "labels": [], "entities": [{"text": "duration", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9857321381568909}]}, {"text": "This paper is organized as follows, we present an overview of the works on speech based language identification in section 2.", "labels": [], "entities": [{"text": "speech based language identification", "start_pos": 75, "end_pos": 111, "type": "TASK", "confidence": 0.6270463243126869}]}, {"text": "In section 3 we give a description of the the collected dataset.", "labels": [], "entities": []}, {"text": "In section 4 and 5, we present the models used as well the experimental setup and results, respectively and we conclude in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We downloaded more than 8 hours of speech data from \"Arab podcast\" website 3 . This dataset covers MSA and some of its dialects from the following regions: Saudi Arabia (KSA), Syria (SYR), Egypt (EGY), Lebanon (LEB) in addition to English (ENG).", "labels": [], "entities": []}, {"text": "The language/dialects are of duration ranging from 50 min to 1 h 30 min.", "labels": [], "entities": [{"text": "duration", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9647197723388672}]}, {"text": "Note that LEB, EGY and KSA-E dialectal corpora include some English expressions along with the conversations.", "labels": [], "entities": [{"text": "LEB", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.8446588516235352}, {"text": "EGY", "start_pos": 15, "end_pos": 18, "type": "METRIC", "confidence": 0.5760999917984009}]}, {"text": "Accordingly this may cause performance degradation compared to the remaining corpora.", "labels": [], "entities": []}, {"text": "For training requirements and system design it was necessary to split the downloaded speech files into a smaller segments of around five minutes each, using MKVToolNix GUI v31.0.0 4 . The whole corpus is sampled at 44.1 khz and encoded on 16 bits.", "labels": [], "entities": [{"text": "MKVToolNix GUI v31.0.0", "start_pos": 157, "end_pos": 179, "type": "DATASET", "confidence": 0.8906436363855997}]}, {"text": "Each language/dialect involves conversations spoken by two speakers or more (male and female).", "labels": [], "entities": []}, {"text": "The targeted applications that will be trained using Arpod-1.0 are several and not only for the two aforementioned tasks.", "labels": [], "entities": []}, {"text": "Since it might be of great help for researchers, we will make it available next 5 .  In this study, we divided Arpod-1.0 dataset into two parts according to their content: the first one includes 3 hours and 40 minutes of speech, covering two languages: MSA and English (ENG) and two dialects: Saudi (KSA) and Syrian (SYR).", "labels": [], "entities": [{"text": "Arpod-1.0 dataset", "start_pos": 111, "end_pos": 128, "type": "DATASET", "confidence": 0.7514471113681793}]}, {"text": "The second part -4 hours 30 minutes-is composed of three dialects characterized by language alternation or code switching: Egyptian (EGY), Lebanese (LEB) and Saudi (KSA-E).", "labels": [], "entities": []}, {"text": "Note that, in this second part of dataset, speakers alternate between their dialects and English.", "labels": [], "entities": []}, {"text": "Experiments have been achieved on speech segments with different durations: 6, 30 and 60 sec.", "labels": [], "entities": []}], "tableCaptions": []}