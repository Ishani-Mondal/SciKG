{"title": [{"text": "Tweet Classification without the Tweet: An Empirical Examination of User versus Document Attributes", "labels": [], "entities": [{"text": "Tweet Classification", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8400412499904633}]}], "abstractContent": [{"text": "NLP naturally puts a primary focus on lever-aging document language, occasionally considering user attributes as supplemental.", "labels": [], "entities": []}, {"text": "However , as we tackle more social scientific tasks, it is possible user attributes might be of primary importance and the document supplemental.", "labels": [], "entities": []}, {"text": "Here, we systematically investigate the predictive power of user-level features alone versus document-level features for document level tasks.", "labels": [], "entities": []}, {"text": "We first show user attributes can sometimes carry more task-related information than the document itself.", "labels": [], "entities": []}, {"text": "For example , a tweet-level stance detection model using only 13 user-level attributes (i.e. features that did not depend on the specific tweet) was able to obtain a higher F1 than the top-performing SemEval participant.", "labels": [], "entities": [{"text": "tweet-level stance detection", "start_pos": 16, "end_pos": 44, "type": "TASK", "confidence": 0.6400871276855469}, {"text": "F1", "start_pos": 173, "end_pos": 175, "type": "METRIC", "confidence": 0.9992687106132507}]}, {"text": "We then consider multiple tasks and a wider range of user attributes, showing the performance of strong document-only models can often be improved (as instance, sentiment, and sarcasm) with user attributes, particularly benefiting tasks with stable \"trait-like\" outcomes (e.g. stance) most relative to frequently changing \"state-like\" outcomes (e.g. sentiment).", "labels": [], "entities": []}, {"text": "These results not only support the growing work on integrating user factors into predictive systems, but that some of our NLP tasks might be better cast primarily as user-level (or human) tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "Natural language processing is increasingly tackling new tasks over microblogs and social media, such as stance detection, sarcasm detection, and variations of sentiment analysis.", "labels": [], "entities": [{"text": "Natural language processing", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6639949878056844}, {"text": "stance detection", "start_pos": 105, "end_pos": 121, "type": "TASK", "confidence": 0.9474046528339386}, {"text": "sarcasm detection", "start_pos": 123, "end_pos": 140, "type": "TASK", "confidence": 0.8952870070934296}, {"text": "sentiment analysis", "start_pos": 160, "end_pos": 178, "type": "TASK", "confidence": 0.8738004267215729}]}, {"text": "Building on techniques used for traditional NLP, it is natural to attempt such tasks with inputs based solely on the content of the document (e.g. tweet) in question.", "labels": [], "entities": []}, {"text": "We present an empirical argument for why this text-only scope maybe a limiting view which inflates the value of document-only solutions.", "labels": [], "entities": []}, {"text": "Our work aims to answer the following questions: 1) What and how much information do user attributes alone carry for different social media tasks, particularly for predictive tasks that are more about the user than the document (e.g. stance)?", "labels": [], "entities": []}, {"text": "2) When are user attributes useful and what do language features contribute in these cases?", "labels": [], "entities": []}, {"text": "While there are multiple works that show that adding user attributes is useful for different prediction tasks, there is no single systematic study that answers these questions.", "labels": [], "entities": []}, {"text": "To this end we conduct a systematic evaluation of user attribute-only models on multiple tasks including stance detection, sarcasm detection, sentiment analysis, and prepositional phrase attachment.", "labels": [], "entities": [{"text": "stance detection", "start_pos": 105, "end_pos": 121, "type": "TASK", "confidence": 0.8638144731521606}, {"text": "sarcasm detection", "start_pos": 123, "end_pos": 140, "type": "TASK", "confidence": 0.902144581079483}, {"text": "sentiment analysis", "start_pos": 142, "end_pos": 160, "type": "TASK", "confidence": 0.9597562849521637}, {"text": "prepositional phrase attachment", "start_pos": 166, "end_pos": 197, "type": "TASK", "confidence": 0.6208856205145518}]}, {"text": "We evaluate the impact of user attribute-only models through a range of features derived from publicly available information about the users including: written profile bio, inferred demographics and personality, self-reported location, profile picture, who one follows in asocial network, and a background of users' past language.", "labels": [], "entities": []}, {"text": "The evaluations show that user attributes can have a large impact and, depending on the nature of the task, even outperform document-only features -inference on a document without even looking at its contents!", "labels": [], "entities": []}, {"text": "We conduct further evaluations comparing document contributions to an inference task relative to user-level features.", "labels": [], "entities": []}, {"text": "Recent research has explored how user-level attributes add value on top of document-level language ().", "labels": [], "entities": []}, {"text": "Instead we quantify how well user attributes alone can predict and then what document-level language can uniquely add, identifying cases where the document is essential.", "labels": [], "entities": []}, {"text": "Our specific contributions are three-fold: (1) We show that the stance of a tweet can be predicted with state-of-the-art F1 scores (better than all participant systems of the SemEval-2016 stance task) without even looking at the given tweet, suggesting such tasks might be better case as user-level (we outperform tweetspecific models that use thousands of features or complex neural networks using only 13 easilyderived features).", "labels": [], "entities": [{"text": "F1", "start_pos": 121, "end_pos": 123, "type": "METRIC", "confidence": 0.9966993927955627}]}, {"text": "(2) We put forth a theory that tasks which capture more \"trait-like\" human attributes (those that are stable overtime, e.g. stance) benefit more from user-level information as compared to \"state-like\" attributes (frequently changing, e.g. sentiment).", "labels": [], "entities": []}, {"text": "We evaluate this theory by looking at the role of user attributes across different predictive tasks.", "labels": [], "entities": []}, {"text": "(3) We provide a set of considerations and metrics, for task participants and designers alike, for the inclusion of user information within new social science-related tasks.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Number of tweets, users, and instances repre- sented in each task.", "labels": [], "entities": []}, {"text": " Table 3: Performance of stance prediction models trained only on user attributes, shown here for each of the  different stance targets. Bold indicates best in column for user attributes and inferred factors. The weighted F1  is shown for each target and the last column is the unweighted average across all targets.  \u2020 indicates statistical  significance at the 0.05 level compared to the MFC baseline.", "labels": [], "entities": [{"text": "stance prediction", "start_pos": 25, "end_pos": 42, "type": "TASK", "confidence": 0.8885669410228729}, {"text": "F1", "start_pos": 222, "end_pos": 224, "type": "METRIC", "confidence": 0.9637320637702942}, {"text": "MFC baseline", "start_pos": 390, "end_pos": 402, "type": "DATASET", "confidence": 0.8957482576370239}]}, {"text": " Table 4: Using user attributes to predict stance, sarcasm, sentiment, and PP-attachment. Bold indicates best in  column. Statistical significance (p < 0.05) is indicated in comparison with the MFC ( \u2020) and the tweet-only model  ( \u2021). *MFC computed by training a model only on the distance between the preposition and the candidate head.", "labels": [], "entities": [{"text": "Statistical significance", "start_pos": 122, "end_pos": 146, "type": "METRIC", "confidence": 0.939158022403717}]}]}