{"title": [{"text": "Contributions to Clinical Named Entity Recognition in Portuguese", "labels": [], "entities": [{"text": "Clinical Named Entity Recognition", "start_pos": 17, "end_pos": 50, "type": "TASK", "confidence": 0.5900984331965446}]}], "abstractContent": [{"text": "Having in mind that different languages might present different challenges, this paper presents the following contributions to the area of Information Extraction from clinical text, targeting the Portuguese language: a collection of 281 clinical texts in this language, with manually-annotated named entities; word em-beddings trained in a larger collection of similar texts; results of using BiLSTM-CRF neu-ral networks for named entity recognition on the annotated collection, including a comparison of using in-domain or out-of-domain word embeddings in this task.", "labels": [], "entities": [{"text": "Information Extraction from clinical text", "start_pos": 139, "end_pos": 180, "type": "TASK", "confidence": 0.8117773056030273}, {"text": "named entity recognition", "start_pos": 425, "end_pos": 449, "type": "TASK", "confidence": 0.6795785228411356}]}, {"text": "Although learned with much less data, performance is higher when using in-domain embeddings.", "labels": [], "entities": []}, {"text": "When tested in 20 independent clinical texts, this model achieved better results than a model using larger out-of-domain embeddings.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, much data has been produced on different areas, including healthcare, which, besides its general relation to well-being, is also economically-relevant (.", "labels": [], "entities": []}, {"text": "We focus on the clinical field, where valuable information is hidden on produced admission notes, diagnostic test reports, patient discharge letters or clinical case reports.", "labels": [], "entities": []}, {"text": "The latter contain information about patient clinical histories, such as their condition; diagnostic tests and respective results; or treatments and how they were administered.", "labels": [], "entities": []}, {"text": "Such data is very useful for clinical professionals in their future decisions about what diagnostic tests or therapies a patient has to do, based on past clinical information.", "labels": [], "entities": []}, {"text": "However, manually processing all available texts and looking for important information is impractical for humans.", "labels": [], "entities": []}, {"text": "To make it more tractable, Natural Language Processing (NLP) tools have been developed for automating tasks such as Information Extraction (IE), including Named Entity Recognition (NER), and ultimately store acquired information in relational databases, where queries should be more efficient.", "labels": [], "entities": [{"text": "Information Extraction (IE)", "start_pos": 116, "end_pos": 143, "type": "TASK", "confidence": 0.819316828250885}, {"text": "Named Entity Recognition (NER)", "start_pos": 155, "end_pos": 185, "type": "TASK", "confidence": 0.813126136859258}]}, {"text": "Similarly to many other NLP-related tasks, the field of clinical NLP has been growing.", "labels": [], "entities": []}, {"text": "This is both reflected in the organization of shared tasks, which made available several datasets, such as Informatics for Integrating Biology & the Bedside (i2b2); or in the adoption of deep neural network architectures that lead to state-of-the-art results, namely Bidirectional Long Short Term Memory with a stacked Conditional Random Fields layer (BiLSTM-CRF) (.", "labels": [], "entities": []}, {"text": "However, most of the work going on targets text written in English.", "labels": [], "entities": []}, {"text": "When it comes to other languages, such as Portuguese, the number of studies on this field is much lower.", "labels": [], "entities": []}, {"text": "This work aims to boost clinical NLP in Portuguese with three main contributions: (i) A collection of Portuguese clinical texts with manuallylabelled named entities; (ii) A model of word embeddings learned from a larger collection of Portuguese clinical text (i.e., Neurology clinical case descriptions); (iii) An analysis of the performance of state-of-the-art models in Portuguese clinical NER, namely BiLSTM-CRF neural networks (, tested on the labelled collection, either using the previous word embeddings or general-language word embeddings.", "labels": [], "entities": []}, {"text": "In the next section, we introduce deep learning architectures and word embedding (WE) models that have been used in NER.", "labels": [], "entities": []}, {"text": "Section 3 describes how texts were labelled and provides some figures on the resulting dataset and its revision.", "labels": [], "entities": []}, {"text": "Furthermore, we explain how the in-domain WE model was trained and its qualitative difference towards the pre-trained out-of-domain WE model used.", "labels": [], "entities": []}, {"text": "Finally, we explain the architecture of our deep learning model.", "labels": [], "entities": []}, {"text": "Section 4 reports the results for hyperparameters grid search.", "labels": [], "entities": [{"text": "hyperparameters grid search", "start_pos": 34, "end_pos": 61, "type": "TASK", "confidence": 0.5928388833999634}]}, {"text": "After choosing the best model for both in-domain and out-of-domain WEs, we tested it on an independent test set.", "labels": [], "entities": []}, {"text": "We report micro-averaged relaxed F1-score and strict F1-score of 70.41% and 62.71%, respectively.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.8662450313568115}, {"text": "F1-score", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9501189589500427}]}, {"text": "We conclude with a brief discussion.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section presents the textual data used, the guidelines followed for its annotation and characterizes the resulting dataset with some numbers on its contents and revision.", "labels": [], "entities": []}, {"text": "It further explains how the WE models used were learned and the architecture of the NER model, including how its hyperparameters grid search was made.", "labels": [], "entities": [{"text": "NER model", "start_pos": 84, "end_pos": 93, "type": "DATASET", "confidence": 0.8675437569618225}]}, {"text": "Three different datasets were used in different stages of this work: \u2022 For training and validation, 281 clinical case texts collected from the numbers 1 and 2 of volume 17 of the clinical journal Sinapse (Sinapse, 2017a,b), published by the Portuguese Society of Neurology.", "labels": [], "entities": []}, {"text": "Neurology texts were used because the testing texts, that originally motivated this work, were obtained from the Neurology service.", "labels": [], "entities": [{"text": "Neurology service", "start_pos": 113, "end_pos": 130, "type": "DATASET", "confidence": 0.8689679801464081}]}, {"text": "\u2022 For testing, a small set of 20 clinical texts obtained from the Neurology service of the Coimbra University Hospital Centre (CHUC), in Coimbra, Portugal.", "labels": [], "entities": [{"text": "Coimbra University Hospital Centre (CHUC)", "start_pos": 91, "end_pos": 132, "type": "DATASET", "confidence": 0.7504850370543343}]}, {"text": "These include admission notes, diagnostic test reports and patient discharge letters and were originally used in the development of the European Epilepsy Database ().", "labels": [], "entities": [{"text": "European Epilepsy Database", "start_pos": 136, "end_pos": 162, "type": "DATASET", "confidence": 0.9042984445889791}]}, {"text": "\u2022 For training the in-domain WE model, a total of 3,377 clinical texts were collected from all the volumes of the Sinapse journal, published between 2001 and 2018 1 . Although the journal contains clinical cases and experimental reports we just collected the clinical cases.", "labels": [], "entities": [{"text": "WE", "start_pos": 29, "end_pos": 31, "type": "TASK", "confidence": 0.9139957427978516}]}, {"text": "As all the texts used for training, validation and test were in a raw format, they were preprocessed with tools in NLPPort (), a NLP toolkit for Portuguese, based on OpenNLP -each text was tokenized with TokPort, PoS-tagged with TagPort, and lemmas for each token-PoS pair obtained with LemPort.", "labels": [], "entities": [{"text": "validation", "start_pos": 36, "end_pos": 46, "type": "TASK", "confidence": 0.963859498500824}]}, {"text": "After preprocessing, manual NE annotation was based on the guidelines described in Ferreira's PhD Thesis, originally developed with the help of physicians and linguists and used in the annotation of Ferreira's dataset.", "labels": [], "entities": [{"text": "NE annotation", "start_pos": 28, "end_pos": 41, "type": "TASK", "confidence": 0.9497300088405609}]}, {"text": "All the NEs in the guidelines were considered, with the exception of Location, because it represents geographical locations, e.g, \"Coimbra\" (a city) or \"domic\u00edlio\" (home, in Portuguese), which does not represent important clinical information.", "labels": [], "entities": [{"text": "Location", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9677850604057312}]}, {"text": "Although DateTime does not represent clinical information as well, it is important to know what temporal information is related to diseases or therapies, e.g., their frequency or duration.", "labels": [], "entities": [{"text": "duration", "start_pos": 179, "end_pos": 187, "type": "METRIC", "confidence": 0.8738718032836914}]}, {"text": "Furthermore, two new NE classes were introduced, namely Genetics and Additional Observations.", "labels": [], "entities": []}, {"text": "The former was used for information about genes related to diseases (e.g., \"...o estudo do gene PMP22 identificou...\"", "labels": [], "entities": []}, {"text": "(...study of the gene PMP22 identified...)), and the latter for all clinically-relevant information that did not suit any of the other classes (e.g. \"...medicada e ex-fumador, refere...\"", "labels": [], "entities": []}, {"text": "(...medicated and ex-smoker, states...).", "labels": [], "entities": []}, {"text": "The dataset thus considers 14 different tags, one for each NE class, plus the Out tag, for tokens not belonging to a NE.", "labels": [], "entities": []}, {"text": "For annotation, we adopted the Inside-Outside-Beginning (IOB) format, which allows to distinguish between tokens in the beginning and inside a NE.", "labels": [], "entities": []}, {"text": "This is essential to sequential classifiers and allows for better rules, which do not enable to tag a token as inside-NE before the beginning of the same NE.", "labels": [], "entities": []}, {"text": "provide a quantitative analysis of the training and validation datasets, while tables 3 and 5 a quantitative analysis of the independent test set.", "labels": [], "entities": []}, {"text": "quantify the tokens for each IOB tag (NT), the number of distinct tokens (NDT), and their ratios (NTR, NDTR).", "labels": [], "entities": []}, {"text": "Finally, tables 4 and 5 show the number of NE occurrences (O), the number of distinct NE occurrences (DO) and their ratios (OR, DOR).", "labels": [], "entities": [{"text": "number of distinct NE occurrences (DO)", "start_pos": 67, "end_pos": 105, "type": "METRIC", "confidence": 0.6353657469153404}, {"text": "OR, DOR)", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.7643114477396011}]}, {"text": "As the test set has only reports related to epilepsy, it does not have occurrences of the Genetics NE.", "labels": [], "entities": [{"text": "Genetics NE", "start_pos": 90, "end_pos": 101, "type": "DATASET", "confidence": 0.7814915180206299}]}, {"text": "The entire dataset was annotated by the first author of this paper, a last-year student of the MSc in Biomedical Engineering.", "labels": [], "entities": [{"text": "MSc in Biomedical Engineering", "start_pos": 95, "end_pos": 124, "type": "TASK", "confidence": 0.5523590743541718}]}, {"text": "After that, to validate the annotation, 30% of the dataset was revised by two MSc students in Biomedical Engineering, two PhD students in Data Science, one Computer Science Professor working on NLP and NER, and one Physiotherapist.", "labels": [], "entities": []}, {"text": "Each of the previous revised 15 texts.", "labels": [], "entities": []}, {"text": "Based on the revised subset, we calculated the agreement ratios as the ratio between the number of tokens which were annotated with the same tag as our annotation and the total number of tokens for each NE.", "labels": [], "entities": []}, {"text": "Although there were some tokens annotated with different tags, we did not change dataset labels.", "labels": [], "entities": []}, {"text": "Agreement ratios (ARs) for each NE, as well as the number of agreed (AT) and of not-agreed tags (NAT) are in table 6.", "labels": [], "entities": [{"text": "Agreement ratios (ARs)", "start_pos": 0, "end_pos": 22, "type": "METRIC", "confidence": 0.9661667823791504}, {"text": "number of agreed (AT) and of not-agreed tags (NAT)", "start_pos": 51, "end_pos": 101, "type": "METRIC", "confidence": 0.6790342239233164}]}, {"text": "The lowest ARs are for Additional Observations, Characterization and Results.", "labels": [], "entities": [{"text": "ARs", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.9951314926147461}, {"text": "Characterization", "start_pos": 48, "end_pos": 64, "type": "TASK", "confidence": 0.9344934821128845}]}, {"text": "They were also the classes whose original labelling raised more doubts.", "labels": [], "entities": []}, {"text": "Additional Observations is a general class which may include other NEs, for instance, in case it does not relate to the patient but to their family -e.g., \"...diagn\u00f3stico de doen\u00e7a neopl\u00e1stica no marido...\"", "labels": [], "entities": []}, {"text": "(...diagnosis of neoplastic disease in her husband...)", "labels": [], "entities": []}, {"text": "-, or information about the patient that is important but does not suit any other class -e.g. \"...abandono do acompanhamento m\u00e9dico...\"", "labels": [], "entities": []}, {"text": "(...abandonment of medical assistance...).", "labels": [], "entities": []}, {"text": "Characterization may have tokens from the Condition or Evolution classes, depending on the perspective of the reader -e.g., \"poss\u00edvel\" (possible) in \"poss\u00edvel processo vascular\" (possible vascular process) or \"hip\u00f3tese\" (hypothesis) in \"hip\u00f3tese de met\u00e1stase\" (hypothesis of metastasis), for Condition, and \"progressivo\" (progressive) in \"decl\u00ednio cognitivo progressivo\" (progressive cognitive decline) for Evolution.", "labels": [], "entities": []}, {"text": "Depending on their interpretation, results may also have tokens from Condition -e.g. \"nova les\u00e3o\" (new injury) in \"...RM-CE que documentou nova les\u00e3o...\"", "labels": [], "entities": []}, {"text": "(...RM-CE which documents anew injury...), or \"hematoma\" in \"...TAC-CE que mostrou aumento do hematoma...\"", "labels": [], "entities": []}, {"text": "(...TAC-CE which shown an increase of the hematoma...).", "labels": [], "entities": [{"text": "TAC-CE", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9478147625923157}]}, {"text": "Overall, the agreement for all the NE classes is above 90%, except for Characterization.", "labels": [], "entities": [{"text": "agreement", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.9587085843086243}, {"text": "Characterization", "start_pos": 71, "end_pos": 87, "type": "TASK", "confidence": 0.9602546691894531}]}, {"text": "This is high, especially considering the number of classes covered and that the used documents are not always easy to interpret, due to the high presence of medical terminology.", "labels": [], "entities": []}, {"text": "We recall that these numbers apply for only 30% of the dataset.", "labels": [], "entities": []}, {"text": "Due to lack of time, the remaining documents were not revised. and minimum word count (5) were the same as in the out-of-domain WE model.", "labels": [], "entities": [{"text": "minimum word count", "start_pos": 67, "end_pos": 85, "type": "METRIC", "confidence": 0.8159394860267639}]}, {"text": "Minimum char-grams length (1) was used for training the model with all the characters, thus enabling to recognize unknown words.", "labels": [], "entities": []}, {"text": "Finally, all the words in the dataset starting with an uppercase character were converted to lowercase, since they represent the same word but in the beginning of a sentence.", "labels": [], "entities": []}, {"text": "After preprocessing, only 7,312 tokens occur more than 5 times.", "labels": [], "entities": []}, {"text": "For the out-of-domain WEs, we used a general Portuguese WE model downloaded from the FastText website 2 , trained with billions of tokens from Wikipedia and Common Crawl (.", "labels": [], "entities": []}, {"text": "As it was trained with a character window of 5 characters, a total of 27 words and 80 lemmas in our dataset do not have an embedding vector in this model.", "labels": [], "entities": []}, {"text": "For them, we assign the embedding of the word 'UNK', meaning unknown, but not a Portuguese word, thus not introducing much noise to the embedding datasets.", "labels": [], "entities": []}, {"text": "This strategy was followed because simply putting out these words could influence the labelling of the network, as the classification of each word depends on the classification of the others around.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Example of dataset annotation. Sentence:  \"...de 66 anos, com antecedentes de dislipidemia e  s\u00edndrome depressiva, come\u00e7ou por...\"", "labels": [], "entities": [{"text": "Sentence", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.946077287197113}]}, {"text": " Table 2: Quantitative analysis of the training/validation dataset.", "labels": [], "entities": []}, {"text": " Table 3: Quantitative analysis of the test dataset", "labels": [], "entities": [{"text": "Quantitative analysis", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.9217612147331238}]}, {"text": " Table 5: NE Test Dataset Description", "labels": [], "entities": [{"text": "NE Test Dataset Description", "start_pos": 10, "end_pos": 37, "type": "DATASET", "confidence": 0.8974327445030212}]}, {"text": " Table 6: Agreement Ratios for all NEs and Non-Entity", "labels": [], "entities": [{"text": "Agreement", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.8768430352210999}]}, {"text": " Table 7: 10-fold Cross Validation Results with both WEs", "labels": [], "entities": [{"text": "Cross Validation", "start_pos": 18, "end_pos": 34, "type": "TASK", "confidence": 0.6726562827825546}, {"text": "WEs", "start_pos": 53, "end_pos": 56, "type": "TASK", "confidence": 0.3548407256603241}]}, {"text": " Table 9: Results of BiLSTM-CRF model using both WEs and of baseline CRF model on independent test set", "labels": [], "entities": []}]}