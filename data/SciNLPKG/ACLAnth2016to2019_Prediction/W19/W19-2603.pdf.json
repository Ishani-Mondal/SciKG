{"title": [{"text": "Understanding the Polarity of Events in the Biomedical Literature: Deep Learning vs. Linguistically-informed Methods", "labels": [], "entities": []}], "abstractContent": [{"text": "An important task in the machine reading of biochemical events expressed in biomed-ical texts is correctly reading the polarity, i.e., attributing whether the biochemical event is a promotion or an inhibition.", "labels": [], "entities": []}, {"text": "Here we present a novel dataset for studying polarity attribution accuracy.", "labels": [], "entities": [{"text": "polarity attribution accuracy", "start_pos": 45, "end_pos": 74, "type": "TASK", "confidence": 0.6529086331526438}]}, {"text": "We use this dataset to train and evaluate several deep learning models for polarity identification, and compare these to a linguistically-informed model.", "labels": [], "entities": [{"text": "polarity identification", "start_pos": 75, "end_pos": 98, "type": "TASK", "confidence": 0.7390259206295013}]}, {"text": "The best performing deep learning architecture achieves 0.968 average F1 performance in a five-fold cross-validation study, a considerable improvement over the linguistically informed model average F1 of 0.862.", "labels": [], "entities": [{"text": "F1", "start_pos": 70, "end_pos": 72, "type": "METRIC", "confidence": 0.9989830851554871}, {"text": "F1", "start_pos": 198, "end_pos": 200, "type": "METRIC", "confidence": 0.8373787999153137}]}], "introductionContent": [{"text": "Recent advances in information extraction (IE) have resulted in high-precision, high-throughput systems tailored to the reading of biomedical scientific publications.", "labels": [], "entities": [{"text": "information extraction (IE)", "start_pos": 19, "end_pos": 46, "type": "TASK", "confidence": 0.8631450653076171}]}, {"text": "This, in turn, has resulted in the use of machine reading systems as the foundation of more complex, higher-level inference applications in specific domains such as cancer research.", "labels": [], "entities": []}, {"text": "However, the presence of noise in pipelined systems that use IE as an initial component may seriously hinder the quality of downstream results.", "labels": [], "entities": []}, {"text": "In particular, biomedical research literature is prone to noise caused by the mischaracterization of the polarity (e.g., promotion vs. inhibition) of biochemical interactions.", "labels": [], "entities": []}, {"text": "This is the focus of this work.", "labels": [], "entities": []}, {"text": "The identification of polarity in the biomedical domain is complicated by the fact that the language used is often hedged through multiple negations to stay closer to the complex biology underneath.", "labels": [], "entities": []}, {"text": "For example, consider the statement: The inactivation of Bad is sufficient to antagonize p38 MAPK.", "labels": [], "entities": []}, {"text": "Under the (simplified but commonly used) representation of polarized interactions, a naive IE system would extract a negative interaction between the two proteins: Bad inhibits p38 MAPK, due to the presence of the negative predicate antagonize.", "labels": [], "entities": []}, {"text": "However, a more careful reading of this text indicates that the better representation for this extraction is a positive interaction: Bad promotes p38 MAPK, 1 due to the interaction of two predicates with negative semantics, inactivation and antagonize.", "labels": [], "entities": []}, {"text": "This situation is exacerbated by the fact that statements in this domain may contain three and even four inter-related predicates that affect polarity (as observed in Section 8).", "labels": [], "entities": []}, {"text": "This paper analyzes the identification of polarity of biomedical interactions, from the perspective of multiple possible methods.", "labels": [], "entities": [{"text": "identification of polarity of biomedical interactions", "start_pos": 24, "end_pos": 77, "type": "TASK", "confidence": 0.8065582116444906}]}, {"text": "In particular, the contributions of this work are: (1) We introduce a novel dataset that annotates the polarity of biomedical interactions.", "labels": [], "entities": []}, {"text": "The dataset comes in multiple variants.", "labels": [], "entities": []}, {"text": "A first variant was derived using distant supervision (DS) () by aligning a knowledge base (KB) of protein interactions ( with the outputs of a machine reader.", "labels": [], "entities": []}, {"text": "This dataset contains 52,779 promotion and 35,177 inhibition interactions.", "labels": [], "entities": []}, {"text": "To account for the noise introduced through the DS process, we provide a second variant of this dataset consisting of a sample of the full dataset that was manually curated by domain experts.", "labels": [], "entities": []}, {"text": "We divide this sample into an Easy partition where the IE system initially agreed with the KB, and a Challenge partition where the IE system's extractions conflicted with the KB.", "labels": [], "entities": []}, {"text": "These manuallycurated partitions contain 62 and 67 data points, respectively.", "labels": [], "entities": []}, {"text": "(2) We compare several approaches for polarity identification, including a linguistically-informed method, and several deep learning (DL) approaches.", "labels": [], "entities": [{"text": "polarity identification", "start_pos": 38, "end_pos": 61, "type": "TASK", "confidence": 0.7316102236509323}]}, {"text": "The DL methods incorporate: (a) multiple sequence models that capture the text before/after arguments/predicate, (b) attention models, and (c) explicit features from the linguistically-informed method.", "labels": [], "entities": []}, {"text": "Our analysis indicates that: (a) the simpler DL methods perform better than the more complicated ones, (b) all DL approaches outperform the standalone linguistically-informed method, and (c) the difference between the two strategies grows larger with the complexity of the text.", "labels": [], "entities": []}], "datasetContent": [{"text": "To analyze the performance of the above approaches, we assembled a dataset of sentences associated with protein-protein interaction events, as well as polarity labels.", "labels": [], "entities": []}, {"text": "The dataset was constructed through distant supervision (, by aligning events extracted from biomedical literature by Reach, a biomedical IE system, with polarity labels from the SIGNOR database (.", "labels": [], "entities": [{"text": "SIGNOR database", "start_pos": 179, "end_pos": 194, "type": "DATASET", "confidence": 0.8182595670223236}]}, {"text": "SIGNOR contains approximately 20,000 manually curated protein interactions, the majority of which are annotated with the polarity of the effect of the interaction on the downstream protein (activation or inhibition).", "labels": [], "entities": []}, {"text": "These signed interactions were used to establish the true polarities for each pair of proteins in the database.", "labels": [], "entities": []}, {"text": "A potential issue with this approach is that an interaction among proteins may have more than one possible polarity depending on the biological context: for example, protein A may activate protein B in cell type X, but inhibit protein B in cell type Y.", "labels": [], "entities": []}, {"text": "To mitigate this, we filtered the relations in SIGNOR for those annotated with only a single, unambiguous polarity, under the assumption that for the relatively well-characterized interactions prioritized for curation in a pathway database, the assignment of a single polarity would be a good indicator of \"ground truth\" for the majority of texts.", "labels": [], "entities": []}, {"text": "Processing the SIGNOR database in this way yielded 17,163 protein-protein interactions among with a single polarity, composed of the following interaction types: 13,302 interactions with positive polarity, and 3,861 interactions with negative polarity.", "labels": [], "entities": [{"text": "SIGNOR database", "start_pos": 15, "end_pos": 30, "type": "DATASET", "confidence": 0.7973619401454926}]}, {"text": "We extracted protein-protein-interaction events from text by running the Reach IE system overall full-text articles in PubMed Central 4 , the PubMed Central Author's Manuscript collection 5 , and MEDLINE 6 abstracts (for articles not included in the full-text datasets).", "labels": [], "entities": [{"text": "Reach IE system", "start_pos": 73, "end_pos": 88, "type": "DATASET", "confidence": 0.9252804319063822}, {"text": "PubMed Central 4", "start_pos": 119, "end_pos": 135, "type": "DATASET", "confidence": 0.9678782423337301}, {"text": "PubMed Central Author's Manuscript collection", "start_pos": 142, "end_pos": 187, "type": "DATASET", "confidence": 0.9646438658237457}]}, {"text": "We kept all information about the events (e.g., triggers, participants, overall interaction type), but discarded polarity information.", "labels": [], "entities": []}, {"text": "We assigned polarity labels by aligning these events with SIGNOR interactions that involved the same two proteins and the same overall interaction type, irrespective of sign (e.g., regulation of activity or regulation of phosphorylation).", "labels": [], "entities": []}, {"text": "From this dataset we removed: (a) duplicate sentences, and (b) sentences containing events whereat least one of the participating pro-tein names could not be grounded to an entry in the UniProt protein database . This process produced 68,935 polarity-labeled events (with supporting sentences).", "labels": [], "entities": [{"text": "UniProt protein database", "start_pos": 186, "end_pos": 210, "type": "DATASET", "confidence": 0.7977657119433085}]}, {"text": "For 54,105 of these events, the original polarity detector in Reach agreed with the SIGNOR polarity label (a strong indication that these sentences are easier to classify).", "labels": [], "entities": [{"text": "Reach", "start_pos": 62, "end_pos": 67, "type": "DATASET", "confidence": 0.9268443584442139}]}, {"text": "For 14,830 events, Reach's polarity disagreed with SIGNOR (an indication that these sentences are more challenging).", "labels": [], "entities": [{"text": "SIGNOR", "start_pos": 51, "end_pos": 57, "type": "METRIC", "confidence": 0.8971031308174133}]}, {"text": "We call this dataset the DS dataset (from distant supervision).", "labels": [], "entities": [{"text": "DS dataset", "start_pos": 25, "end_pos": 35, "type": "DATASET", "confidence": 0.9203211069107056}]}, {"text": "The distant supervision process is potentially noisy).", "labels": [], "entities": []}, {"text": "To control for this noise, we also created two smaller hand-curated datasets, as follows: 1.", "labels": [], "entities": []}, {"text": "We randomly sampled 100 sentences from the sentences where Reach agreed with SIG-NOR, and 100 from the sentences where Reach disagreed with SIGNOR.", "labels": [], "entities": []}, {"text": "Based on the intuition mentioned in the previous paragraph, we call these partitions Easy and Challenge.", "labels": [], "entities": [{"text": "Easy", "start_pos": 85, "end_pos": 89, "type": "METRIC", "confidence": 0.9712376594543457}]}, {"text": "2. Because the focus of this work is on polarity identification given a correct event, we eliminated the false positive events from both partitions, i.e., events extracted by Reach that were not supported by the corresponding underlying sentence.", "labels": [], "entities": [{"text": "polarity identification", "start_pos": 40, "end_pos": 63, "type": "TASK", "confidence": 0.7270374596118927}]}, {"text": "Further, we removed sentences containing events whereat least one of the participating protein names could not be grounded to UniProt.", "labels": [], "entities": []}, {"text": "This reduced the size of the dataset to 62 Easy and 67 Challenge examples.", "labels": [], "entities": []}, {"text": "firming our expectation that the latter partition is harder than the former.", "labels": [], "entities": []}, {"text": "To facilitate reproducibility, we will release all these datasets (and the software) upon acceptance.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Label distribution on the DS dataset.", "labels": [], "entities": [{"text": "DS dataset", "start_pos": 36, "end_pos": 46, "type": "DATASET", "confidence": 0.9747177064418793}]}, {"text": " Table 2: Deep learning scores from a five-fold cross-validation experiment on the larger DS dataset. The \"mask\"  option indicates that event participants have been masked (please see Section 7.3 for details).", "labels": [], "entities": [{"text": "DS dataset", "start_pos": 90, "end_pos": 100, "type": "DATASET", "confidence": 0.9779126346111298}]}, {"text": " Table 3: Performance of all approaches on the Easy partition. The \"mask\" option indicates that event participants  have been masked (please see Section 7.3 for details).", "labels": [], "entities": []}, {"text": " Table 4: Performance of all approaches on the Challenge partition. The \"mask\" option indicates that event partici- pants have been masked (please see Section 7.3 for details).", "labels": [], "entities": []}, {"text": " Table 5: Polarity classification results stratified by the number of polarity-carrying words in the corresponding  sentence.", "labels": [], "entities": [{"text": "Polarity classification", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.7431975156068802}]}, {"text": " Table 6: Polarity classification results stratified by the number of polarity-carrying words in the corresponding  sentence with masked participants.", "labels": [], "entities": [{"text": "Polarity classification", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.740764245390892}]}]}