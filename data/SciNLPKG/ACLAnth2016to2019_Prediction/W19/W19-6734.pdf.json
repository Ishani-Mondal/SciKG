{"title": [{"text": "Monolingual backtranslation in a medical speech translation system for diagnostic interviews -a NMT approach", "labels": [], "entities": []}], "abstractContent": [{"text": "BabelDr is a medical speech to speech translator, where the doctor has to approve the sentence that will be translated for the patient before translation; this step is done using monolingual backtranslation, which converts the speech recognition result into a core sentence.", "labels": [], "entities": [{"text": "medical speech to speech translator", "start_pos": 13, "end_pos": 48, "type": "TASK", "confidence": 0.6726498961448669}]}, {"text": "In this work, we model this step as a simplification task and propose to use neural networks to perform the backtranslation by generating and choosing the best core sentence.", "labels": [], "entities": []}, {"text": "Results of a task-based evaluation show that neural networks outperform previous versions of the system.", "labels": [], "entities": []}], "introductionContent": [{"text": "BabelDr 1 is a joint project between the Faculty of Translation and Interpreting of the University of Geneva and Geneva University Hospitals (HUG) (.", "labels": [], "entities": [{"text": "Translation and Interpreting", "start_pos": 52, "end_pos": 80, "type": "TASK", "confidence": 0.8679232398668925}, {"text": "Geneva University Hospitals (HUG)", "start_pos": 113, "end_pos": 146, "type": "DATASET", "confidence": 0.7580728232860565}]}, {"text": "The aim of the project is to build a speech to speech translation system for emergency settings which meets three criteria: reliability, data security and portability to low-resourced target languages relevant for the HUG.", "labels": [], "entities": [{"text": "speech to speech translation", "start_pos": 37, "end_pos": 65, "type": "TASK", "confidence": 0.6723968535661697}, {"text": "reliability", "start_pos": 124, "end_pos": 135, "type": "METRIC", "confidence": 0.9598696231842041}]}, {"text": "To ensure reliability, the system is based on a set of manually pre-translated sentences (around 30'000 core sentences) defined with the help of doctors and classified by anatomic domains (e.g. head, chest, abdomen, etc.).", "labels": [], "entities": [{"text": "reliability", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9626401662826538}]}, {"text": "The basic idea is that the doctor can speak freely and c 2019 The authors.", "labels": [], "entities": []}, {"text": "This article is licensed under a Creative Commons 4.0 licence, no derivative works, attribution, CC-BY-ND.", "labels": [], "entities": []}, {"text": "More information available at https://babeldr.unige.ch/ the system will map the recognised utterance to the closest core sentence.", "labels": [], "entities": []}, {"text": "The translation from source recognition result to target language is done in two steps: 1) mapping of the source recognition result to a core sentence (backtranslation,) and 2) look-up of the (human) translation of the core sentence for the relevant target language.", "labels": [], "entities": [{"text": "translation from source recognition", "start_pos": 4, "end_pos": 39, "type": "TASK", "confidence": 0.7483626753091812}]}, {"text": "Backtranslation is therefore an essential step in this type of architecture (see also.", "labels": [], "entities": []}, {"text": "The doctor has to approve the backtranslation of his utterance, ensuring awareness of the exact meaning of the translation produced for the patient.", "labels": [], "entities": []}, {"text": "Backtranslation can also be considered as a type of simplification task.", "labels": [], "entities": []}, {"text": "It translates the doctor's questions for the layman, reducing the vocabulary by 40%, removing medical jargon and making the meaning explicit both for the human translator and the patient.", "labels": [], "entities": []}, {"text": "The following are examples of such lexical, syntactic and semantic simplification processes: \u2022 Recognition result: c'est chaud (it is warm) \u2192 Backtranslation: la peau est-elle chaude ? (is the skin warm?)", "labels": [], "entities": [{"text": "Backtranslation", "start_pos": 142, "end_pos": 157, "type": "METRIC", "confidence": 0.9664784669876099}]}, {"text": "\u2022 Recognition result: o` u est-ce que se trouve la douleur (where is the pain) \u2192 Backtranslation: pouvez-vous me montrer avec le doigt o` u est la douleur ? (can you show with your finger where the pain is?)", "labels": [], "entities": [{"text": "o", "start_pos": 22, "end_pos": 23, "type": "METRIC", "confidence": 0.944980263710022}]}, {"text": "\u2022 Recognition result: avez-vous un h\u00e9matome (do you have a hematoma) \u2192 Backtranslation: avez-vous un bleu ? (do you have a bruise?)", "labels": [], "entities": [{"text": "Recognition", "start_pos": 2, "end_pos": 13, "type": "METRIC", "confidence": 0.8472181558609009}, {"text": "Backtranslation", "start_pos": 71, "end_pos": 86, "type": "METRIC", "confidence": 0.9944378137588501}]}, {"text": "In the current version of the system, backtranslation is performed by rule-based methods and methods borrowed from information retrieval.", "labels": [], "entities": []}, {"text": "In this paper, we investigate a backtranslation approach using neural machine translation (NMT) trained on the data generated from the existing grammar.", "labels": [], "entities": []}, {"text": "Our aim is to see whether it is possible to bootstrap the NMT from the rule-based system and how it will perform in comparison with the existing strategies used in BabelDr.", "labels": [], "entities": []}, {"text": "Section 2 describes BabelDr and the different strategies used for backtranslation in the current system.", "labels": [], "entities": []}, {"text": "We then explain how NMT was derived from the grammar to create different neural network versions (Section 3).", "labels": [], "entities": []}, {"text": "Section 4 describes the task-based evaluation and Section 5 presents the results.", "labels": [], "entities": []}], "datasetContent": [{"text": "We carried out an automatic evaluation to choose between the two neural MT architectures, adding N-Best sentence generation to each model.", "labels": [], "entities": [{"text": "N-Best sentence generation", "start_pos": 97, "end_pos": 123, "type": "TASK", "confidence": 0.609953761100769}]}, {"text": "We measured system performance on the test data using two standard metrics: BLEU () and TER), as shown in. shows that there was no significant difference between the results obtained with Transformer and with RNN.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 76, "end_pos": 80, "type": "METRIC", "confidence": 0.9993147850036621}, {"text": "TER", "start_pos": 88, "end_pos": 91, "type": "METRIC", "confidence": 0.9976969361305237}, {"text": "RNN", "start_pos": 209, "end_pos": 212, "type": "DATASET", "confidence": 0.8560304641723633}]}, {"text": "An intuitive explanation for this is that the sentences in our data set are rather short, with a mean sentence length of 10.37 words, and thus present no difficulties for the RNN approach.", "labels": [], "entities": []}, {"text": "Furthermore, the amount of training data might not be suitable fora transformer architecture ().", "labels": [], "entities": []}, {"text": "We also observe that adding the 2nd best sentence improves the performance of the model while adding a 3rd best does not bring an improvement.", "labels": [], "entities": []}, {"text": "Our main research question is to see if it is possible to bootstrap a NMT system from the data generated with the rule-based system.", "labels": [], "entities": []}, {"text": "To answer this, we will focus on the following sub-questions: 1)  will the system be able to generate core sentences, 2) does anon core sentence indicate an out-ofdomain (OOD) utterance, i.e. one that could not be associated with any of the core sentences, and 3) how will the system perform in comparison with the currently used approaches.", "labels": [], "entities": []}, {"text": "In order to answer these questions, we used the different versions of the system (described in Sections 2 and 3.5) to process utterances collected during diagnostic interviews.", "labels": [], "entities": []}, {"text": "These test data are the same as used in.", "labels": [], "entities": []}, {"text": "Results for system Versions 1-3 are therefore taken from this publication.", "labels": [], "entities": []}, {"text": "We want to compare the different versions at the task level, namely how many spoken utterances will result in a correct translation for the patient.", "labels": [], "entities": []}, {"text": "Since the system relies on human pre-translation (Section 1), a correct core sentence is equivalent to a correct translation.", "labels": [], "entities": []}, {"text": "We therefore measured the sentence error rate (SER), defined as the percentage of utterances for which the resulting core sentence is not identical to the annotated correct core sentence.", "labels": [], "entities": [{"text": "sentence error rate (SER)", "start_pos": 26, "end_pos": 51, "type": "METRIC", "confidence": 0.814100111524264}]}, {"text": "As input utterances we used the speech recognition results from the large vocabulary recogniser (speech) and the transcriptions (text, which simulates the case where recognition is perfect).", "labels": [], "entities": []}, {"text": "This metric and approach allows us to compare our results with those reported for system Versions 1-3 in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Comparison between models with N-Best (N=1,2,3)  sentences.", "labels": [], "entities": []}, {"text": " Table 5: SER for IC, OOC and ALL for in domain speech recognition results (Speech) and transcriptions (Text). No text results  are provided for the hybrid versions (3 and 5), since transcriptions are independent from the speech recogniser confidence score  threshold.", "labels": [], "entities": [{"text": "SER", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9982719421386719}, {"text": "IC", "start_pos": 18, "end_pos": 20, "type": "METRIC", "confidence": 0.721230685710907}, {"text": "OOC", "start_pos": 22, "end_pos": 25, "type": "METRIC", "confidence": 0.7675153613090515}, {"text": "in domain speech recognition", "start_pos": 38, "end_pos": 66, "type": "TASK", "confidence": 0.6548343822360039}, {"text": "speech recogniser confidence score  threshold", "start_pos": 222, "end_pos": 267, "type": "METRIC", "confidence": 0.6727099299430848}]}]}