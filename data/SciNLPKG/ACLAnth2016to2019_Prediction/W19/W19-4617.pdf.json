{"title": [{"text": "Translating Between Morphologically Rich Languages: An Arabic-to-Turkish Machine Translation System", "labels": [], "entities": [{"text": "Translating Between Morphologically Rich Languages", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.8421953678131103}, {"text": "Arabic-to-Turkish Machine Translation", "start_pos": 55, "end_pos": 92, "type": "TASK", "confidence": 0.7120503584543864}]}], "abstractContent": [{"text": "This paper introduces the work on building a machine translation system for Arabic-to-Turkish in the news domain.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.7314063608646393}]}, {"text": "Our work includes collecting parallel datasets in several ways fora new and low-resource language pair, building baseline systems with state-of-the-art architectures and developing language specific algorithms for better translation.", "labels": [], "entities": []}, {"text": "Parallel datasets are mainly collected three different ways; i) translating Arabic texts into Turk-ish by professional translators, ii) exploiting the web for open-source Arabic-Turkish parallel texts, iii) using back-translation.", "labels": [], "entities": []}, {"text": "We performed preliminary experiments for Arabic-to-Turkish machine translation with neural (Marian) machine translation tools with a novel morphologically motivated vocabulary reduction method.", "labels": [], "entities": [{"text": "Arabic-to-Turkish machine translation", "start_pos": 41, "end_pos": 78, "type": "TASK", "confidence": 0.6511451403299967}, {"text": "vocabulary reduction", "start_pos": 165, "end_pos": 185, "type": "TASK", "confidence": 0.720662459731102}]}], "introductionContent": [{"text": "It is a well-known fact that to develop robust systems with data-driven methods, it is crucial to have large amounts of data.", "labels": [], "entities": []}, {"text": "If the problem needs only raw monolingual data, the solution is straightforward; crawl the web and collect the data in the specific domain.", "labels": [], "entities": []}, {"text": "In cases of annotating the data (e.g., treebanks) or parallel data (e.g., for machine translation) collecting the needed data is a bit harder.", "labels": [], "entities": [{"text": "machine translation) collecting", "start_pos": 78, "end_pos": 109, "type": "TASK", "confidence": 0.842901200056076}]}, {"text": "Even though machine translation (MT) is one of the popular topics in natural language processing, most of the existing parallel texts include English as one of the languages (e.g., Europarl), Multi-UN ().", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 12, "end_pos": 36, "type": "TASK", "confidence": 0.8457942187786103}, {"text": "Europarl", "start_pos": 181, "end_pos": 189, "type": "DATASET", "confidence": 0.9657559394836426}]}, {"text": "For the rest of the languages, generating anew language pair from scratch is tough work that needs extensive human effort and substantial funding.", "labels": [], "entities": []}, {"text": "One way of translating languages with no parallel data is pivoting, which means one should find corpora for two language pairs such as sourceto-pivot and pivot-to-target with sufficient number of sentences in the same domain and then train and maintain two MT systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 257, "end_pos": 259, "type": "TASK", "confidence": 0.9722657799720764}]}, {"text": "Even though we can find such corpora in the expected domain for the given languages, the error propagation is the biggest problem of pivoting as the second system will try to translate erroneous output of the previous system.", "labels": [], "entities": [{"text": "error propagation", "start_pos": 89, "end_pos": 106, "type": "TASK", "confidence": 0.7474069595336914}]}, {"text": "In this work, our goal is building an ArabicTurkish machine translation on the news domain.", "labels": [], "entities": [{"text": "ArabicTurkish machine translation", "start_pos": 38, "end_pos": 71, "type": "TASK", "confidence": 0.75577445824941}]}, {"text": "The task is very interesting for several reasons; primarily, both the source and the target languages are morphologically rich which proves to be a quite challenging task.", "labels": [], "entities": []}, {"text": "Our attention on this language pair has both social and political grounds.", "labels": [], "entities": []}, {"text": "Arabic is the official language inmost of the Middle East countries that Turkey has relations with.", "labels": [], "entities": []}, {"text": "Moreover, there is a need for quick and cheap translation solutions in communicating with the increasing number of refugees in Turkish spoken areas.", "labels": [], "entities": []}, {"text": "The news domain is selected as it has several benefits such as the fact that at least one side of the parallel texts can be found publicly on the web (e.g. several news portals) and Arabic is written in Modern Standard Arabic format for the news domain which is common for all Arabic speakers.", "labels": [], "entities": []}, {"text": "To collect the data, both monolingual and bilingual data on the web is exploited.", "labels": [], "entities": []}, {"text": "Selected portion of a monolingual data is translated into Turkish by professional translators, the publicly available but out-of-domain parallel data is cleaned and used directly and, lastly, rest of the monolingual Turkish data is back-translated to train our systems.", "labels": [], "entities": []}, {"text": "Both unsupervised and supervised morphology reduction techniques are used to reduce the vocabulary size to a fixed number and let to fit our vocabulary into a given number of tokens while training the neural machine translation (NMT) systems . This paper is organized as follows; Section 2 gives brief information about the source and tar-get languages.", "labels": [], "entities": []}, {"text": "Section 3 describes the data obtaining methods, and Section 4 introduces the segmentation methods for Turkish to alleviate the morphological differences and explains generation of surface word forms as post-processing.", "labels": [], "entities": []}, {"text": "In section 5, we talk about our experimental setup including the data sizes and morphology abstraction/separation experiments with Marian (Junczys-Dowmunt et al., 2018) NMT tool.", "labels": [], "entities": [{"text": "morphology abstraction/separation", "start_pos": 80, "end_pos": 113, "type": "TASK", "confidence": 0.7918576672673225}, {"text": "Marian (Junczys-Dowmunt et al., 2018) NMT tool", "start_pos": 131, "end_pos": 177, "type": "DATASET", "confidence": 0.6454032391309739}]}, {"text": "Finally, we conclude in Section 6.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Time and cost spent to generate gold-standard  translations.", "labels": [], "entities": []}, {"text": " Table 5: Arabic-to-Turkish MT BLEU scores due to  the different traning corpora", "labels": [], "entities": [{"text": "MT", "start_pos": 28, "end_pos": 30, "type": "TASK", "confidence": 0.8805431723594666}, {"text": "BLEU", "start_pos": 31, "end_pos": 35, "type": "METRIC", "confidence": 0.9487504959106445}]}, {"text": " Table 6: Type and size of the corpora used in the ex- periments.", "labels": [], "entities": []}]}