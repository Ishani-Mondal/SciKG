{"title": [{"text": "A Dataset for Noun Compositionality Detection fora Slavic Language", "labels": [], "entities": [{"text": "Noun Compositionality Detection", "start_pos": 14, "end_pos": 45, "type": "TASK", "confidence": 0.8282578984896342}]}], "abstractContent": [{"text": "This paper presents the first gold-standard resource for Russian annotated with composi-tionality information of noun compounds.", "labels": [], "entities": []}, {"text": "The compound phrases are collected from the Universal Dependency treebanks according to part of speech patterns, such as ADJ+NOUN or NOUN+NOUN, using the gold-standard annotations.", "labels": [], "entities": [{"text": "Universal Dependency treebanks", "start_pos": 44, "end_pos": 74, "type": "DATASET", "confidence": 0.8959775368372599}, {"text": "ADJ+NOUN", "start_pos": 121, "end_pos": 129, "type": "METRIC", "confidence": 0.6482242345809937}]}, {"text": "Each compound phrase is annotated by two experts and a moderator according to the following schema: the phrase can be either compositional, non-compositional, or ambiguous (i.e., depending on the context it can be interpreted both as compositional or non-compositional).", "labels": [], "entities": []}, {"text": "We conduct an experimental evaluation of models and methods for predicting compositionality of noun compounds in unsupervised and supervised setups.", "labels": [], "entities": [{"text": "predicting compositionality of noun compounds", "start_pos": 64, "end_pos": 109, "type": "TASK", "confidence": 0.9064302206039428}]}, {"text": "We show that methods from previous work evaluated on the proposed Russian-language resource achieve the performance comparable with results on English corpora.", "labels": [], "entities": []}], "introductionContent": [{"text": "The quality of many natural language processing applications is heavily dependent on the quality of vector representations of text elements.", "labels": [], "entities": []}, {"text": "The streamline NLP research encompasses many works on building various distributional semantic models (DSMs), and on methods for combining vector representations of atomic elements like words into representations of bigger fragments: phrases, sentences, texts.", "labels": [], "entities": []}, {"text": "A simple but strong baseline for this task suggests averaging word embeddings of a text fragment (sometimes weighted, e.g., according to IDF).", "labels": [], "entities": [{"text": "IDF", "start_pos": 137, "end_pos": 140, "type": "METRIC", "confidence": 0.9185211062431335}]}, {"text": "Although the result vector representation is rough compared to results could be achieved by more elaborate neural network encoding methods, it was shown that this baseline has high performance in many tasks).", "labels": [], "entities": []}, {"text": "The main advantages of such methods are computational efficiency and an ability to use them in an unsupervised setting, while neural encoders would commonly require heavy computational power, labeled datasets, and substantial time for training.", "labels": [], "entities": []}, {"text": "However, simple averaging of word embeddings often is too na\u00a8\u0131vena\u00a8\u0131ve.", "labels": [], "entities": []}, {"text": "Idiomatic noun phrases are one of the cases where the averaging of the phrase parts would yield a wrong result since the meaning of such phrases is metaphorical and could not be directly \"summed up\" from meanings of its components.", "labels": [], "entities": []}, {"text": "Therefore, it would be beneficial to have a DSM that tackles this problem, by having a distinct embedding for the whole phrase.", "labels": [], "entities": []}, {"text": "In this work, we focus on the task of predicting compositionality of noun phrases in Russian language texts.", "labels": [], "entities": [{"text": "predicting compositionality of noun phrases in Russian language texts", "start_pos": 38, "end_pos": 107, "type": "TASK", "confidence": 0.9185884727372063}]}, {"text": "The goal is to develop a resource and methods for distinguishing compositional compounds, which meaning could be split into parts, from non-compositional ones that have a solid meaning, and for which we would like to have a dedicated embedding.", "labels": [], "entities": []}, {"text": "The ability to detect compositionality for noun compounds is considered beneficial for many tasks including machine translation, semantic parsing, as well as word sense disambiguation.", "labels": [], "entities": [{"text": "detect compositionality for noun compounds", "start_pos": 15, "end_pos": 57, "type": "TASK", "confidence": 0.7413904070854187}, {"text": "machine translation", "start_pos": 108, "end_pos": 127, "type": "TASK", "confidence": 0.7842889726161957}, {"text": "semantic parsing", "start_pos": 129, "end_pos": 145, "type": "TASK", "confidence": 0.7088160216808319}, {"text": "word sense disambiguation", "start_pos": 158, "end_pos": 183, "type": "TASK", "confidence": 0.7229511141777039}]}, {"text": "The contribution of this paper is two-fold: 1.", "labels": [], "entities": []}, {"text": "We present the first gold-standard dataset for Russian annotated with compositionality information of noun compounds.", "labels": [], "entities": []}, {"text": "We provide an experimental evaluation of models and methods for predicting compositionality of noun compounds.", "labels": [], "entities": [{"text": "predicting compositionality of noun compounds", "start_pos": 64, "end_pos": 109, "type": "TASK", "confidence": 0.8951990127563476}]}, {"text": "We show that the methods from the previous work trained on the proposed Russian-language resource achieve the performance comparable with results on English corpora.", "labels": [], "entities": []}], "datasetContent": [{"text": "The resulting dataset consists of 220 compound phrases with several full sentence contexts, collected from source texts.", "labels": [], "entities": []}, {"text": "The number of contexts is not fixed.", "labels": [], "entities": []}, {"text": "So far the contexts are not annotated.", "labels": [], "entities": []}, {"text": "A few examples are provided in. presents the cross-tabulation of compound pattern and compound compositionality.", "labels": [], "entities": []}, {"text": "Each compound is provided with a sentence context.", "labels": [], "entities": []}, {"text": "The number of contexts is not fixed as we extract all contexts that contain the compound from the UD treebanks.", "labels": [], "entities": [{"text": "UD treebanks", "start_pos": 98, "end_pos": 110, "type": "DATASET", "confidence": 0.9121585190296173}]}, {"text": "The contexts so far are not used in the experiments.", "labels": [], "entities": []}, {"text": "However, one of the possible directions for the future work would be compound disambiguation, based on the contexts.", "labels": [], "entities": [{"text": "compound disambiguation", "start_pos": 69, "end_pos": 92, "type": "TASK", "confidence": 0.7230496108531952}]}, {"text": "Examples of the compound contexts are presented in.", "labels": [], "entities": []}, {"text": "We evaluate various methods for detection of compositionality presented in the previous work.", "labels": [], "entities": []}, {"text": "For experiments, we train a distributional semantic model (DSM) that includes embeddings not just for single words but also for compounds.", "labels": [], "entities": []}, {"text": "We achieve this by replacing in the training corpora all occurrences of compounds from the proposed resource with single tokens composed of their parts.", "labels": [], "entities": []}, {"text": "We use two experimental setups in our work.", "labels": [], "entities": []}, {"text": "First, the unsupervised setup follows the method and evaluation pipeline presented in ( . In this setting, we rely solely on a similarity between a compound embedding and an embedding composed from its parts using an additive function.", "labels": [], "entities": []}, {"text": "The value of the similarity should correlate with annotators' judgments in the proposed resource.", "labels": [], "entities": []}, {"text": "Second, the supervised setup considers compositionality detection as a binary classification task.", "labels": [], "entities": [{"text": "compositionality detection", "start_pos": 39, "end_pos": 65, "type": "TASK", "confidence": 0.9731734395027161}]}, {"text": "We train various supervised machine learning methods on vector representations of a compound and its parts to predict compositionality class.", "labels": [], "entities": []}, {"text": "In this setup, we train an additional DSM that does not have any modifications (it does not contain embeddings for compounds).", "labels": [], "entities": []}, {"text": "In this setup, embeddings of compound parts are obtained from this unmodified supplementary model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: The number of compositional and non-compositional compounds in our dataset.", "labels": [], "entities": []}, {"text": " Table 4: Performance of the classifiers in the supervised setup (classifier metrics presented for class 0).", "labels": [], "entities": []}, {"text": " Table 5: Spearman correlation (\u03c1) of the metric with  annotator judgments in the unsupervised setup.", "labels": [], "entities": [{"text": "Spearman correlation (\u03c1)", "start_pos": 10, "end_pos": 34, "type": "METRIC", "confidence": 0.9320090651512146}]}, {"text": " Table 4. Of presented met- rics, L 1 , L 2 , and L \u221e present substantial negative  correlation. That can be explained by the na- ture of embedding vectors. The bigger the dis-", "labels": [], "entities": []}]}