{"title": [{"text": "A comparison of statistical association measures for identifying dependency-based collocations in various languages", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents an exploration of different statistical association measures to automatically identify collocations from corpora in English, Portuguese, and Spanish.", "labels": [], "entities": []}, {"text": "To evaluate the impact of the association measures we manually annotated corpora with three different syntactic patterns of colloca-tions (adjective-noun, verb-object and nominal compounds).", "labels": [], "entities": []}, {"text": "We took advantage of the PARSEME 1.1 Shared Task corpora by selecting a subset of 155k tokens in the three referred languages, in which we annotated 1, 526 collocations with their Lexical Functions according to the Meaning-Text Theory.", "labels": [], "entities": [{"text": "PARSEME 1.1 Shared Task corpora", "start_pos": 25, "end_pos": 56, "type": "DATASET", "confidence": 0.600566953420639}]}, {"text": "Using the resulting gold-standard, we have carried out a comparison between frequency data and several well-known association measures , both symmetric and asymmetric.", "labels": [], "entities": []}, {"text": "The results show that the combination of dependency triples with raw frequency information is as powerful as the best association measures inmost syntactic patterns and languages.", "labels": [], "entities": []}, {"text": "Furthermore, and despite the asym-metric behaviour of collocations, directional approaches perform worse than the symmetric ones in the extraction of these phraseological combinations.", "labels": [], "entities": []}], "introductionContent": [{"text": "Although there is no agreement about the linguistic properties of collocations, it is commonly accepted that the automatic identification of this type of multiword expressions (MWEs) is crucial for many natural language processing tasks such as natural language understanding, or machine translation (.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 245, "end_pos": 275, "type": "TASK", "confidence": 0.6661413411299387}, {"text": "machine translation", "start_pos": 280, "end_pos": 299, "type": "TASK", "confidence": 0.8145810067653656}]}, {"text": "From a statistical point of view collocations are recurrent co-occurrences of word pairs given a short span of text.", "labels": [], "entities": []}, {"text": "Thus, they are often identified by applying association measures (AMs, e.g., loglikelihood, pointwise mutual information, etc.) on co-occurrence counts in windows of different sizes.", "labels": [], "entities": []}, {"text": "However, the phraseological tradition states that collocations are idiosyncratic asymmetric combinations of syntactically related pairs of words.", "labels": [], "entities": []}, {"text": "In this regard, their asymmetry derives from the fact that one of the elements of a collocation (the BASE, e.g., cabin take a cab) is freely selected due to its meaning, while the choice of the other (the COLLOCATE, e.g., take in the previous example) is restricted by the former.", "labels": [], "entities": [{"text": "BASE", "start_pos": 101, "end_pos": 105, "type": "METRIC", "confidence": 0.9927690029144287}, {"text": "COLLOCATE", "start_pos": 205, "end_pos": 214, "type": "METRIC", "confidence": 0.88545823097229}]}, {"text": "Following this perspective, the process for extracting collocations should take advantage of syntactic parsing.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 93, "end_pos": 110, "type": "TASK", "confidence": 0.6846688538789749}]}, {"text": "Moreover, and with a view to capture the asymmetry of these expressions, directional AMs have been proposed.", "labels": [], "entities": [{"text": "directional AMs", "start_pos": 73, "end_pos": 88, "type": "TASK", "confidence": 0.5822640657424927}]}, {"text": "To evaluate the impact of each extraction method, some researchers perform a manual revision of a ranked list of collocation candidates (), while others collect a set of gold-standard collocations (from corpora or dictionaries) to evaluate their identification methods.", "labels": [], "entities": []}, {"text": "Notwithstanding, most studies focus only on one language or just on a collocation pattern, and most of them use very different gold-standards (e.g., considering idioms or proper nouns as a type of collocations), so that their results are not comparable and cannot be generalized to other languages or collocational schemes.", "labels": [], "entities": []}, {"text": "This paper presents a systematic evaluation of twelve AMs -both symmetric and directionalwhich have been proposed for collocation extraction.", "labels": [], "entities": []}, {"text": "The experiments are carried out us-ing three syntactic patterns (adjective-noun, verbobject, and nominal compounds) in English, Portuguese, and Spanish.", "labels": [], "entities": []}, {"text": "To obtain accurate recall and precision values, we have created goldstandard corpora containing 1, 526 collocations labeled in context in these languages.", "labels": [], "entities": [{"text": "recall", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9957633018493652}, {"text": "precision", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9981643557548523}]}, {"text": "The annotation was performed following a phraseological approach, which not only identifies each collocation but also classifies it according to a lexical function in the Meaning-Text Theory.", "labels": [], "entities": []}, {"text": "The results of the performed experiments show that, to extract these dependency-based collocations, frequency data behaves similarly to the best association measures, and that directional measures obtain worse results than symmetric ones.", "labels": [], "entities": []}, {"text": "Moreover, these findings are general tendencies in the three languages that have been evaluated.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "First, Section 2 introduces some related work on the use of AMs for extracting collocations.", "labels": [], "entities": []}, {"text": "Then, we briefly present the gold-standard corpora in Section 3.", "labels": [], "entities": []}, {"text": "The evaluation and discussion of the results are addressed in Sections 4 and 5, while some conclusions are drawn in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section describes the experiments carried out to evaluate the performance of the different AMs in our gold-standard corpora.", "labels": [], "entities": []}, {"text": "Besides raw frequency, we have evaluated eleven association measures which have been used for both dependency and ngram-based collocation extraction.", "labels": [], "entities": [{"text": "ngram-based collocation extraction", "start_pos": 114, "end_pos": 148, "type": "TASK", "confidence": 0.5338931779066721}]}, {"text": "As symmetric measures we used simplell, t-score, z-score, (pointwise) mutual information (MI), MI 2 , Dice, log-likelihood, and \u03c7 2.", "labels": [], "entities": [{"text": "simplell", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9921879768371582}, {"text": "mutual information (MI)", "start_pos": 70, "end_pos": 93, "type": "METRIC", "confidence": 0.6549914300441741}, {"text": "MI 2", "start_pos": 95, "end_pos": 99, "type": "METRIC", "confidence": 0.963350921869278}, {"text": "Dice", "start_pos": 102, "end_pos": 106, "type": "METRIC", "confidence": 0.9190371632575989}]}, {"text": "Also, we have included two directional AMs which have been proposed to model the asymmetry of collocations (see Section 3.1): DeltaP (Gries, 2013) in both directions (\u2206P (base|collocate) , and \u2206P (collocate|base) ), and NP MI c (.", "labels": [], "entities": [{"text": "DeltaP", "start_pos": 126, "end_pos": 132, "type": "METRIC", "confidence": 0.9127379059791565}, {"text": "NP MI c", "start_pos": 220, "end_pos": 227, "type": "METRIC", "confidence": 0.8610077699025472}]}, {"text": "See in Appendix A for the equations.", "labels": [], "entities": [{"text": "Appendix A", "start_pos": 7, "end_pos": 17, "type": "METRIC", "confidence": 0.8920961618423462}]}, {"text": "For each language and collocation pattern, we computed precision and recall values for every AM and plotted them into two dimensional precision-recall (PR) curves.", "labels": [], "entities": [{"text": "precision", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.9978795051574707}, {"text": "recall", "start_pos": 69, "end_pos": 75, "type": "METRIC", "confidence": 0.9632859230041504}, {"text": "precision-recall (PR)", "start_pos": 134, "end_pos": 155, "type": "METRIC", "confidence": 0.9493415951728821}]}, {"text": "PR curves allow us to compare the performance of the different measures, by looking at those curves closer to the top-right corner.", "labels": [], "entities": []}, {"text": "includes two examples of different PR curves in English and Portuguese (where x-axis is recall and y-axis precision).", "labels": [], "entities": [{"text": "PR", "start_pos": 35, "end_pos": 37, "type": "TASK", "confidence": 0.9383490681648254}, {"text": "recall", "start_pos": 88, "end_pos": 94, "type": "METRIC", "confidence": 0.9986094236373901}, {"text": "precision", "start_pos": 106, "end_pos": 115, "type": "METRIC", "confidence": 0.9437462091445923}]}, {"text": "These graphics are useful to rapidly observe those measures that are clearly better than others (i.e., they have higher precision inmost recall values), but the visualization maybe ambiguous if the curves cross each other along the plot (in those AMs which are better than others only in specific recall intervals).", "labels": [], "entities": [{"text": "precision", "start_pos": 120, "end_pos": 129, "type": "METRIC", "confidence": 0.9925475716590881}, {"text": "recall", "start_pos": 137, "end_pos": 143, "type": "METRIC", "confidence": 0.7999014258384705}]}, {"text": "To provide comparable results for the different scenarios we computed two single values in each experiment: area under curve (AUC), which measures the area below each PR curve (Davis   First, we will show the micro-average results of each AM per language, followed by the results for each dependency relation.", "labels": [], "entities": [{"text": "area under curve (AUC)", "start_pos": 108, "end_pos": 130, "type": "METRIC", "confidence": 0.9156628251075745}]}, {"text": "Finally, we will also present the AUC and MAP values for each language and relation.", "labels": [], "entities": [{"text": "AUC", "start_pos": 34, "end_pos": 37, "type": "METRIC", "confidence": 0.8671154975891113}, {"text": "MAP", "start_pos": 42, "end_pos": 45, "type": "METRIC", "confidence": 0.8741860389709473}]}], "tableCaptions": []}