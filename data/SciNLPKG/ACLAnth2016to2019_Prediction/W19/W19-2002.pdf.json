{"title": [{"text": "Characterizing the Impact of Geometric Properties of Word Embeddings on Task Performance", "labels": [], "entities": []}], "abstractContent": [{"text": "Analysis of word embedding properties to inform their use in downstream NLP tasks has largely been studied by assessing nearest neighbors.", "labels": [], "entities": []}, {"text": "However, geometric properties of the continuous feature space contribute directly to the use of embedding features in downstream models, and are largely unexplored.", "labels": [], "entities": []}, {"text": "We consider four properties of word embedding geometry, namely: position relative to the origin, distribution of features in the vector space, global pairwise distances , and local pairwise distances.", "labels": [], "entities": [{"text": "word embedding geometry", "start_pos": 31, "end_pos": 54, "type": "TASK", "confidence": 0.6780376136302948}]}, {"text": "We define a sequence of transformations to generate new embeddings that expose subsets of these properties to downstream models and evaluate change in task performance to understand the contribution of each property to NLP models.", "labels": [], "entities": []}, {"text": "We transform publicly available pre-trained embeddings from three popular toolk-its (word2vec, GloVe, and FastText) and evaluate on a variety of intrinsic tasks, which model linguistic information in the vector space, and extrinsic tasks, which use vectors as input to machine learning models.", "labels": [], "entities": []}, {"text": "We find that intrinsic evaluations are highly sensitive to absolute position, while extrinsic tasks rely primarily on local similarity.", "labels": [], "entities": []}, {"text": "Our findings suggest that future embedding models and post-processing techniques should focus primarily on similarity to nearby points in vector space.", "labels": [], "entities": []}], "introductionContent": [{"text": "Learned vector representations of words, known as word embeddings, have become ubiquitous throughout natural language processing (NLP) applications.", "labels": [], "entities": []}, {"text": "As a result, analysis of embedding spaces to understand their utility as input features has emerged as an important avenue of inquiry, in order to facilitate proper use of embeddings in downstream NLP tasks.", "labels": [], "entities": []}, {"text": "Many analyses have focused on nearest neighborhoods, as a viable proxy for semantic information (Rogers et al., * These authors contributed equally to this 2018;.", "labels": [], "entities": []}, {"text": "However, neighborhood-based analysis is limited by the unreliability of nearest neighborhoods.", "labels": [], "entities": []}, {"text": "Further, it is intended to evaluate the semantic content of embedding spaces, as opposed to characteristics of the feature space itself.", "labels": [], "entities": []}, {"text": "Geometric analysis offers another recent angle from which to understand the properties of word embeddings, both in terms of their distribution ( and correlation with downstream performance (.", "labels": [], "entities": [{"text": "Geometric analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7891764044761658}]}, {"text": "Through such geometric investigations, neighborhood-based semantic characterizations are augmented with information about the continuous feature space of an embedding.", "labels": [], "entities": []}, {"text": "Geometric features offer a more direct connection to the assumptions made by neural models about continuity in input spaces (, as well as the use of recent contextualized representation methods using continuous language models (.", "labels": [], "entities": []}, {"text": "In this work, we aim to bridge the gap between neighborhood-based semantic analysis and geometric performance analysis.", "labels": [], "entities": [{"text": "neighborhood-based semantic analysis", "start_pos": 47, "end_pos": 83, "type": "TASK", "confidence": 0.6487801770369211}, {"text": "geometric performance analysis", "start_pos": 88, "end_pos": 118, "type": "TASK", "confidence": 0.6740169525146484}]}, {"text": "We consider four components of the geometry of word embeddings, and transform pretrained embeddings to expose only subsets of these components to downstream models.", "labels": [], "entities": []}, {"text": "We transform three popular sets of embeddings, trained using word2vec (), 1 GloVe (), 2 and FastText (), and use the resulting embeddings in a battery of standard evaluations to measure changes in task performance.", "labels": [], "entities": [{"text": "GloVe", "start_pos": 76, "end_pos": 81, "type": "METRIC", "confidence": 0.9343456029891968}]}, {"text": "We find that intrinsic evaluations, which model linguistic information directly in the vector space,", "labels": [], "entities": []}], "datasetContent": [{"text": "We follow in evaluating on a set of five extrinsic tasks: \u2022 Relation classification: SemEval-2010 Task 8 (, using a CNN with word and distance embeddings ().", "labels": [], "entities": [{"text": "Relation classification", "start_pos": 60, "end_pos": 83, "type": "TASK", "confidence": 0.7410358488559723}]}, {"text": "\u2022 Sentence-level sentiment polarity classification: MR movie reviews (Pang and), with a simplified CNN model from).", "labels": [], "entities": [{"text": "Sentence-level sentiment polarity classification", "start_pos": 2, "end_pos": 50, "type": "TASK", "confidence": 0.7526217997074127}]}, {"text": "\u2022 Sentiment classification: IMDB movie reviews (Maas et al., 2011), with a single 100-d LSTM.", "labels": [], "entities": [{"text": "Sentiment classification", "start_pos": 2, "end_pos": 26, "type": "TASK", "confidence": 0.9060488939285278}, {"text": "LSTM", "start_pos": 88, "end_pos": 92, "type": "METRIC", "confidence": 0.9772335290908813}]}, {"text": "\u2022 Subjectivity/objectivity classification: Rotten Tomato snippets (), using a logistic regression over summed word embeddings ().", "labels": [], "entities": [{"text": "Subjectivity/objectivity classification", "start_pos": 2, "end_pos": 41, "type": "TASK", "confidence": 0.8196133822202682}]}, {"text": "\u2022 Natural language inference: SNLI (Bowman et al., 2015), using separate LSTMs for premise and hypothesis, combined with a feed-forward classifier.", "labels": [], "entities": [{"text": "Natural language inference", "start_pos": 2, "end_pos": 28, "type": "TASK", "confidence": 0.6188719769318899}]}, {"text": "presents the results of each intrinsic and extrinsic evaluation on the transformed versions of our three sets of word embeddings.", "labels": [], "entities": []}, {"text": "The largest drops in performance across all three sets for intrinsic tasks occur when explicit embedding features are removed with the CDE transformation.", "labels": [], "entities": []}, {"text": "While some cases of NNE-transformed embeddings recover a measure of this performance, they remain far under affine-transformed embeddings.", "labels": [], "entities": []}, {"text": "Extrinsic tasks are similarly affected by the CDE transformation; however, NNE-transformed embeddings recover the majority of performance.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Mean performance on intrinsic tasks under  different NNE settings.", "labels": [], "entities": []}]}