{"title": [{"text": "Neural Vector Conceptualization for Word Vector Space Interpretation", "labels": [], "entities": [{"text": "Neural Vector Conceptualization", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8183884421984354}, {"text": "Word Vector Space Interpretation", "start_pos": 36, "end_pos": 68, "type": "TASK", "confidence": 0.5642156675457954}]}], "abstractContent": [{"text": "Distributed word vector spaces are considered hard to interpret which hinders the understanding of natural language processing (NLP) models.", "labels": [], "entities": []}, {"text": "In this work, we introduce anew method to interpret arbitrary samples from a word vector space.", "labels": [], "entities": []}, {"text": "To this end, we train a neural model to conceptualize word vectors, which means that it activates higher order concepts it recognizes in a given vector.", "labels": [], "entities": []}, {"text": "Contrary to prior approaches, our model operates in the original vector space and is capable of learning non-linear relations between word vectors and concepts.", "labels": [], "entities": []}, {"text": "Furthermore, we show that it produces considerably less entropic concept activation profiles than the popular cosine similarity .", "labels": [], "entities": []}], "introductionContent": [{"text": "In the vast majority of state-of-the-art NLP models, as for instance in translation models or text classifiers, language is represented in distributed vector spaces.", "labels": [], "entities": []}, {"text": "Using distributed representations comes at the price of low interpretability as they are generally considered uninterpretable, without further means (.", "labels": [], "entities": []}, {"text": "In this work, we address this lack of interpretability with neural vector conceptualization (NVC), a neural mapping from a word vector space to a concept space (e.g. \"chair\" should activate the concept \"furniture\").", "labels": [], "entities": []}, {"text": "Using concepts to interpret distributed vector representations of language is inspired by the finding that \"humans understand languages through multi-step cognitive processes which involves building rich models of the world and making multi-level generalizations from the input text\").", "labels": [], "entities": []}, {"text": "We are not the first, however, to utilize concepts for this purpose.", "labels": [], "entities": []}, {"text": "* Shared first authorship., for instance, modify the objective function of GloVe () to align semantic concepts with word vector dimensions to create an interpretable space.", "labels": [], "entities": []}, {"text": "Their method does not, however, offer an interpretation of vectors in the original space., in contrast, do offer an interpretation of the original space: They propose a mapping of word vector dimensions to concepts.", "labels": [], "entities": []}, {"text": "This mapping, however, is linear and consequently, their method is incapable of modeling non-linear relations.", "labels": [], "entities": []}, {"text": "Our method offers an interpretation of the original space and is capable of modeling non-linear relations between the word and the concept space.", "labels": [], "entities": []}, {"text": "Furthermore, arguably, we interpret vectors similar to how a neural NLP model would, because a neural NLP model lies at the heart of our method.", "labels": [], "entities": []}, {"text": "In addition, by design, our model is able to conceptualize random continuous samples, drawn from the word vector space.", "labels": [], "entities": []}, {"text": "This is particularly important as word vectors are sparse in their vector space and vectors without a word representative do not have intrinsic meaning.", "labels": [], "entities": []}, {"text": "This hinders adapting methods from vision, such as activation maximization or generative adversarial networks), as in NLP these methods potentially produce vectors without word representations.", "labels": [], "entities": []}, {"text": "For introspection, one could map any vector onto its nearest neighbor with a word representative.", "labels": [], "entities": [{"text": "introspection", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.9825316071510315}]}, {"text": "However, nearest neighbor search does not necessarily find the closest semantic representative in the vector space (.", "labels": [], "entities": []}, {"text": "Moreover, we show that concept activation profiles produced with nearest neighbor search tend to be considerably more entropic than the activation profiles our method returns.", "labels": [], "entities": []}], "datasetContent": [{"text": "We filtered the MCG for concepts that have at least 100 instances with a rep value of at least \u221210.", "labels": [], "entities": []}, {"text": "This leaves 637 concepts with an average of 184 instances per concept and gives a class imbalance of 524 negative samples for every positive sample.", "labels": [], "entities": []}, {"text": "With the obtained data, we trained a three-layer FC network to map word vectors onto their concepts in the MCG.", "labels": [], "entities": []}, {"text": "The model returns independent sigmoid activations for each concept.", "labels": [], "entities": []}, {"text": "We trained with categorical cross entropy and applied weights regularization with a factor of 10 \u22127 . For all experiments, we optimized parameters with the ADAM optimizer ().", "labels": [], "entities": []}, {"text": "To estimate task complexity, lists the precision, recall and F 1 scores that our model achieved on a fixed, randomly sampled test set that contained 10 % of the data.", "labels": [], "entities": [{"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.999637246131897}, {"text": "recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9992398023605347}, {"text": "F 1 scores", "start_pos": 61, "end_pos": 71, "type": "METRIC", "confidence": 0.9873014489809672}]}, {"text": "The table contains the weighted average scores accomplished for all concepts as well as the scores the model achieved for selected individual concepts, grouped semantically.", "labels": [], "entities": []}, {"text": "juxtaposes the NVC and the baseline activation profile of the word vector of \"listening\", which was not encountered during training.", "labels": [], "entities": [{"text": "NVC", "start_pos": 15, "end_pos": 18, "type": "METRIC", "confidence": 0.6099655628204346}]}, {"text": "Several other NVCs can be found in the appendix (see 3, 4 and 5) as well as selected concept activations of continuous samples (see).", "labels": [], "entities": []}, {"text": "While shows a global perspective of the activation profiles, zooms in on the top 25 concepts, activated by the baseline method (first column) and our method (second column).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Precision (P), recall (R), F 1 Score (F), and  support (S) for all 637 concepts (F 1 Score weighted by  support) and selected individual concepts. Class mem- bership was determined by an activation threshold of  0.5.", "labels": [], "entities": [{"text": "Precision (P)", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9290608465671539}, {"text": "recall (R)", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.9433642327785492}, {"text": "F 1 Score (F)", "start_pos": 37, "end_pos": 50, "type": "METRIC", "confidence": 0.9735943178335825}, {"text": "support (S)", "start_pos": 57, "end_pos": 68, "type": "METRIC", "confidence": 0.9176419526338577}, {"text": "F 1 Score", "start_pos": 91, "end_pos": 100, "type": "METRIC", "confidence": 0.9345105290412903}]}]}