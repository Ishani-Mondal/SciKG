{"title": [{"text": "Towards Natural Language Story Understanding with Rich Logical Schemas", "labels": [], "entities": [{"text": "Natural Language Story Understanding", "start_pos": 8, "end_pos": 44, "type": "TASK", "confidence": 0.7302847504615784}]}], "abstractContent": [{"text": "Generating \"commonsense\" knowledge for intelligent understanding and reasoning is a difficult, long-standing problem, whose scale challenges the capacity of any approach driven primarily by human input.", "labels": [], "entities": []}, {"text": "Furthermore, approaches based on mining statistically repetitive patterns fail to produce the rich representations humans acquire, and fall far short of human efficiency in inducing knowledge from text.", "labels": [], "entities": []}, {"text": "The idea of our approach to this problem is to provide a learning system with a \"head start\" consisting of a semantic parser, some basic ontological knowledge, and most importantly, a small set of very general schemas about the kinds of patterns of events (often purposive, causal, or socially conventional) that even a one-or two-year-old could reasonably be presumed to possess.", "labels": [], "entities": []}, {"text": "We match these initial schemas to simple children's stories, obtaining concrete instances, and combining and abstracting these into new candidate schemas.", "labels": [], "entities": []}, {"text": "Both the initial and generated schemas are specified using a rich, expressive logical form.", "labels": [], "entities": []}, {"text": "Unlike the slot-and-filler structures often used in knowledge harvesting, this logical form allows us to specify complex relations and constraints over the slots.", "labels": [], "entities": [{"text": "knowledge harvesting", "start_pos": 52, "end_pos": 72, "type": "TASK", "confidence": 0.7365561127662659}]}, {"text": "Though formal, the representations are language-like, and as such readily relatable to NL text.", "labels": [], "entities": []}, {"text": "The agents, objects, and other roles in the schemas are represented by typed variables, and the event variables can be related through partial temporal ordering and causal relations.", "labels": [], "entities": []}, {"text": "To match natural language stories with existing schemas, we first parse the stories into an underspecified variant of the logical form used by the schemas, which is suitable for most concrete stories.", "labels": [], "entities": []}, {"text": "We include a walkthrough of matching a children's story to these schemas and generating inferences from these matches.", "labels": [], "entities": []}], "introductionContent": [{"text": "Artificial general intelligence research tends to fall into one of two broad categories: connectionism, which emphasizes the importance of neural architectures in the human brain, and computationalism, which models human intelligence at a more abstract level, making use of knowledge representations and reasoning procedures.", "labels": [], "entities": []}, {"text": "One common assumption in connectionist approaches is that an AI system can be trained from scratch, as a tabula rasa, once a suitable architecture has been specified.", "labels": [], "entities": []}, {"text": "No representational or inferential mechanisms are presupposed-perhaps inevitably, because of the \"black box\" character of neural net functioning.", "labels": [], "entities": []}, {"text": "We believe that the need for exposure to massive amounts of sensory data can be averted with a suitable \"head start\".", "labels": [], "entities": []}, {"text": "The basic knowledge representations, reasoning procedures, language abilities, and world knowledge of a 1-to 2-year-old human child must be attained in any general intelligence architecture, and we believe that learning from text, implemented atop a suitably powerful symbolic framework, will be easier than doing so using data-fitting methods alone.", "labels": [], "entities": []}, {"text": "Our approach is to generate knowledge in the form of abstract logical \"schemas\".", "labels": [], "entities": []}, {"text": "Our system's \"head start\" includes a semantic parser, a general inference system over a highly expressive logical form, and an initial set of simple schemas that a very young child could plausibly possess.", "labels": [], "entities": []}, {"text": "Our system parses natural language stories into a logical form, matches the story to existing schemas, draws inferences, and, upon recognition of patterns, generalizes new schemas, whose variable roles take the place of the individuals that vary from story to story.", "labels": [], "entities": []}, {"text": "Schematic knowledge representations have along history in artificial intelligence research; to underscore their usefulness, we will briefly outline that history and discuss some modern schema-oriented systems.", "labels": [], "entities": []}, {"text": "We'll then describe our schema model in detail, differentiating it from past approaches, and describe its basic inference and generalization procedures, along with some examples of those procedures at work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}