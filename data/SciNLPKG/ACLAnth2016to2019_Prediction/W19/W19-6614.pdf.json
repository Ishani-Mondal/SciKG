{"title": [{"text": "Improving Anaphora Resolution in Neural Machine Translation Using Curriculum Learning", "labels": [], "entities": [{"text": "Improving Anaphora Resolution", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.9100979367891947}, {"text": "Neural Machine Translation", "start_pos": 33, "end_pos": 59, "type": "TASK", "confidence": 0.7128402590751648}]}], "abstractContent": [{"text": "Modeling anaphora resolution is critical for proper pronoun translation in neural machine translation.", "labels": [], "entities": [{"text": "Modeling anaphora resolution", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8689728776613871}, {"text": "pronoun translation", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.7598623335361481}, {"text": "neural machine translation", "start_pos": 75, "end_pos": 101, "type": "TASK", "confidence": 0.6645637353261312}]}, {"text": "Recently it has been addressed by context-aware models with varying success.", "labels": [], "entities": []}, {"text": "In this work, we propose a carefully designed training curriculum that facilitates better anaphora resolution in context-aware NMT.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 90, "end_pos": 109, "type": "TASK", "confidence": 0.7049363255500793}]}, {"text": "As a baseline, we train context-aware models as was done in previous work.", "labels": [], "entities": []}, {"text": "We leverage oracle information specific to anaphora resolution during training.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.727735236287117}]}, {"text": "Following the intuition behind curriculum learning, we are able to train context-aware models which are improved with respect to coreference resolution , even though both the baseline and the improved system have access to exactly the same information attest time.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 129, "end_pos": 151, "type": "TASK", "confidence": 0.911294013261795}]}, {"text": "We test our approach using two pronoun-specific evaluation metrics for MT.", "labels": [], "entities": [{"text": "MT", "start_pos": 71, "end_pos": 73, "type": "TASK", "confidence": 0.9934343099594116}]}], "introductionContent": [{"text": "Modeling gender-pronoun agreement and anaphora resolution in machine translation is difficult because most models work on individual sentences.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.7717966437339783}, {"text": "machine translation", "start_pos": 61, "end_pos": 80, "type": "TASK", "confidence": 0.7281268686056137}]}, {"text": "In many cases the antecedent noun is not present in the sentence being translated, but is rather in a preceding sentence.", "labels": [], "entities": []}, {"text": "Sentence-external anaphora area problem in many domains (e.g., consider conversational texts).", "labels": [], "entities": [{"text": "Sentence-external anaphora area", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8449114958445231}]}, {"text": "NMT models can be extended to receive the previous sentences of a document as input.", "labels": [], "entities": []}, {"text": "Previous context-aware NMT models include (.", "labels": [], "entities": []}, {"text": "Previous work on evaluation has shown that context-aware NMT improves over sentence-level baselines, both in terms of BLEU and in terms of metrics tailored for pronoun evaluation (.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 118, "end_pos": 122, "type": "METRIC", "confidence": 0.9983730316162109}]}, {"text": "In this work, we propose a technique for improving the ability of context-aware models to handle anaphora resolution.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 97, "end_pos": 116, "type": "TASK", "confidence": 0.729477733373642}]}, {"text": "The technique is based on curriculum learning () which proposes to train neural networks in a similar fashion to how humans learn.", "labels": [], "entities": []}, {"text": "Curriculum learning is a method that proposes training neural networks by gradually feeding increasingly more complex data instead of training models by randomly showing data samples.", "labels": [], "entities": [{"text": "Curriculum learning", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.6948668211698532}]}, {"text": "We borrow on the intuition behind curriculum learning by initially training models with a form of \"training wheels\", where the anaphora relationships are made explicit.", "labels": [], "entities": []}, {"text": "We take the key idea from previous work, which is to use gold-standard reference pronouns as oracles.", "labels": [], "entities": []}, {"text": "We then gradually remove the oracles in consecutive fine-tuning steps, until we have a model working without oracle information.", "labels": [], "entities": []}, {"text": "We expect that explicitly showing the reference pronouns in the context will make it easier to model the gender of antecedent nouns and bias the model to do more aggressive anaphora resolution when encountering ambiguous pronouns in the source language (the translation of ambiguous pronouns depends on the antecedent).", "labels": [], "entities": []}, {"text": "We experimentally show the importance of the learning rate when training context-aware models with regards to our curriculum learning approach on both pronoun and overall translation performance.", "labels": [], "entities": []}, {"text": "For this reason we present experiments training contextaware models with low and high initial learning rates.", "labels": [], "entities": []}, {"text": "Note that our approach could be extended to other discourse-level phenomena, provided that useful oracles are easily obtainable.", "labels": [], "entities": []}, {"text": "Our main contributions are: 1) We propose a curriculum learning method that supplies oracle information in training (but not testing) to improve anaphora resolution in NMT.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 145, "end_pos": 164, "type": "TASK", "confidence": 0.7019399255514145}]}, {"text": "2) We show that our method works when training models with a low learning rate according to different metrics (measuring both MT quality overall and pronoun correctness).", "labels": [], "entities": [{"text": "MT", "start_pos": 126, "end_pos": 128, "type": "TASK", "confidence": 0.9609956741333008}]}, {"text": "3) We outline best practices for training and fine-tuning context-aware models.", "labels": [], "entities": []}], "datasetContent": [{"text": "Following, we conduct experiments on English\u2192German WMT17 data and use newstest2017 and newstest2018 as test sets in addition to the pronoun challenge set.", "labels": [], "entities": [{"text": "WMT17 data", "start_pos": 52, "end_pos": 62, "type": "DATASET", "confidence": 0.7772025465965271}]}, {"text": "In terms of preprocessing, we tokenize and truecase the data and apply BPE splitting () with 32000 merge operations.", "labels": [], "entities": [{"text": "BPE splitting", "start_pos": 71, "end_pos": 84, "type": "TASK", "confidence": 0.8532702028751373}]}, {"text": "We remove all samples where the source, target or context sentence has length over 50.", "labels": [], "entities": []}, {"text": "We train small Transformer models as outlined in with 6 encoder and decoder layers.", "labels": [], "entities": []}, {"text": "The source code for our models is publicly available 2 . We report mean scores across ten consecutive checkpoints with the lowest average perplexity on the development set (.", "labels": [], "entities": []}, {"text": "BLEU scores are computed on detokenized text.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9799422025680542}]}, {"text": "Evaluation of pronoun translation is done using two separate metrics.", "labels": [], "entities": [{"text": "pronoun translation", "start_pos": 14, "end_pos": 33, "type": "TASK", "confidence": 0.7774575054645538}]}, {"text": "First, we use the challenge set provided by and report the overall pronoun accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9966097474098206}]}, {"text": "We refer to this metric as challenge set accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9719209671020508}]}, {"text": "The other metric is an F 1 score for \"it\", which we refer to as reference F 1 . We predict translations and then compute micro-average F 1 for \"it\", using an alignment of the test set input to the reference.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9710675676663717}, {"text": "micro-average F 1", "start_pos": 121, "end_pos": 138, "type": "METRIC", "confidence": 0.793062150478363}]}, {"text": "We compute alignments using fastalign ().", "labels": [], "entities": [{"text": "fastalign", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9072697758674622}]}, {"text": "We use all of the training, development and test data for the computation of the alignments.", "labels": [], "entities": []}, {"text": "The evaluation was done using the script from.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: BLEU scores. * -initial learning rate is 10 -4 , ** - lr=10 -5 . ctx-base: context-aware baseline, pron-{0,25,50,75}:  percentage of samples with oracles. Each pron-{0,25} model  fine-tuned for 140K updates.  \u2020-improvements statistically  significant based on paired bootstrap resampling with p-value  < 0.01;  \u2021-p-value < 0.05", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.995093584060669}, {"text": "initial learning rate", "start_pos": 26, "end_pos": 47, "type": "METRIC", "confidence": 0.8861269354820251}]}]}