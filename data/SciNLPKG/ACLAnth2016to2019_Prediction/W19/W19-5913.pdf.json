{"title": [{"text": "Scoring Interactional Aspects of Human-Machine Dialog for Language Learning and Assessment using Text Features", "labels": [], "entities": [{"text": "Scoring Interactional Aspects of Human-Machine Dialog", "start_pos": 0, "end_pos": 53, "type": "TASK", "confidence": 0.8394708534081777}, {"text": "Language Learning and Assessment", "start_pos": 58, "end_pos": 90, "type": "TASK", "confidence": 0.6351092755794525}]}], "abstractContent": [{"text": "While there has been much work in the language learning and assessment literature on human and automated scoring of essays and short constructed responses, there is little to no work examining text features for scoring of dialog data, particularly interactional aspects thereof, to assess conversational proficiency over and above constructed response skills.", "labels": [], "entities": []}, {"text": "Our work bridges this gap by investigating both human and automated approaches towards scoring human-machine text dialog in the context of a real-world language learning application.", "labels": [], "entities": [{"text": "scoring human-machine text dialog", "start_pos": 87, "end_pos": 120, "type": "TASK", "confidence": 0.8224178552627563}]}, {"text": "We collected conversational data of human learners interacting with a cloud-based standards-compliant dialog system , triple-scored these data along multiple dimensions of conversational proficiency, and then analyzed the performance trends.", "labels": [], "entities": []}, {"text": "We further examined two different approaches to automated scoring of such data and show that these approaches are able to perform at or above par with human agreement fora majority of dimensions of the scoring rubric.", "labels": [], "entities": []}], "introductionContent": [{"text": "Learning and assessment solutions in today's educational marketplace are placing increasing importance and resources on developing technologies that are dialogic (as opposed to monologic) in nature.", "labels": [], "entities": []}, {"text": "Conversational proficiency is a crucial skill for success in today's workplace, which makes R&D on technologies that help develop and assess this skill important to complement our understanding from sociolinguistics (see for example.", "labels": [], "entities": [{"text": "Conversational proficiency", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8239563703536987}]}, {"text": "Dialog system technologies are one solution capable of addressing and automating this need by allowing learners to practice and improve their interactional compentence at scale (.", "labels": [], "entities": []}, {"text": "However, such conversational technologies need to be able to provide targeted and actionable feedback to users in order for them to be useful to learners and widely adopted.", "labels": [], "entities": []}, {"text": "Automated scoring of multiple aspects of conversational proficiency is one way to address this need.", "labels": [], "entities": []}, {"text": "While the automated scoring of text and speech data has been a well-explored topic for several years, particularly for essays and short constructed responses in the case of the former and monolog speech for the latter (, there has been a relative dearth of work on the interpretable automated scoring of dialog.", "labels": [], "entities": [{"text": "interpretable automated scoring of dialog", "start_pos": 269, "end_pos": 310, "type": "TASK", "confidence": 0.7562487363815308}]}, {"text": "examined the automatic scoring of pseudo-dialogues, i.e., there were no branching dialog states; the system's response was fixed and did not vary based on the learner's response.", "labels": [], "entities": []}, {"text": "(2016) developed a system to predict expert human rater scores based on audio signal and fluency features.", "labels": [], "entities": []}, {"text": "analyzed this scoring problem at the level of each response in the dialog (i.e., each turn) instead of the entire conversation and across multiple dimensions of speaking proficiency.", "labels": [], "entities": []}, {"text": "However, no study has performed a comprehensive examination of the automated scoring of content of whole dialog responses (with branching) based primarily on text features, based on a comprehensive multidimensional rubric and scoring paradigm designed specifically for dialog data, and interaction aspects in particular.", "labels": [], "entities": []}, {"text": "This study describes our contributions toward (i) developing a comprehensive rubric design: Human scoring rubric for interaction aspects of conversational proficiency.", "labels": [], "entities": []}, {"text": "Scores are assigned on a Likert scale from 1-4 ranging from low to high proficiency.", "labels": [], "entities": []}, {"text": "A score of 0 is assigned when there were issues with audio quality or system malfunction or off-topic or empty responses.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Human and machine score statistics", "labels": [], "entities": []}]}