{"title": [], "abstractContent": [{"text": "Financial and Economic Attitudes Revealed by Search (FEARS) index reflects the attention and sentiment of public investors and is an important factor for predicting stock price return.", "labels": [], "entities": [{"text": "Financial and Economic Attitudes Revealed by Search (FEARS) index", "start_pos": 0, "end_pos": 65, "type": "TASK", "confidence": 0.7089621885256334}, {"text": "predicting stock price", "start_pos": 154, "end_pos": 176, "type": "TASK", "confidence": 0.8236598173777262}]}, {"text": "In this paper, we take into account the semantics of the FEARS search terms by leveraging the Bidirectional En-coder Representations from Transformers (BERT), and further apply a self-attention deep learning model to our refined FEARS seamlessly for stock return prediction.", "labels": [], "entities": [{"text": "FEARS", "start_pos": 57, "end_pos": 62, "type": "DATASET", "confidence": 0.6191081404685974}, {"text": "BERT", "start_pos": 152, "end_pos": 156, "type": "METRIC", "confidence": 0.8788737058639526}, {"text": "FEARS", "start_pos": 229, "end_pos": 234, "type": "DATASET", "confidence": 0.7132222056388855}, {"text": "stock return prediction", "start_pos": 250, "end_pos": 273, "type": "TASK", "confidence": 0.6038473347822825}]}, {"text": "We demonstrate the practical benefits of our approach by comparing to baseline works.", "labels": [], "entities": []}], "introductionContent": [{"text": "Efficient Market Hypothesis proposed by Fama states that stock market prices are driven by all observable information.", "labels": [], "entities": [{"text": "Fama", "start_pos": 40, "end_pos": 44, "type": "DATASET", "confidence": 0.9047219157218933}]}, {"text": "In reality, it has been shown that investor sentiment can affect the asset prices due to the well-known psychological fact that investors with positive (negative) sentiment tend to make overly optimistic(pessimistic) judgments and decisions.", "labels": [], "entities": []}, {"text": "These two classic theories open the gate of financial forecasting.", "labels": [], "entities": [{"text": "financial forecasting", "start_pos": 44, "end_pos": 65, "type": "TASK", "confidence": 0.7744618058204651}]}, {"text": "More recently, numerous empirical studies also provide consistent evidence to support the theory that investor sentiment has a significant impact on asset prices.", "labels": [], "entities": []}, {"text": "For instance, Peng and Xiong show that limited investor attention leads to category-learning behavior, i.e., investors tend to process more market-wide information than firm-specific information.", "labels": [], "entities": []}, {"text": "present evidence that the investor sentiment has effects on stock price movements across different stocks.", "labels": [], "entities": []}, {"text": "They construct a novel investor sentiment index (BW index hereafter), and find that high investor sentiment predicts strongly low returns in the stock market.", "labels": [], "entities": [{"text": "BW index", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.851236879825592}]}, {"text": "Vozlyublennaia investigates a link between the performances of several security indices in broad investment categories with the exception of exchange rates.", "labels": [], "entities": []}, {"text": "He finds a significant short-term change in index returns following an increase in attention.", "labels": [], "entities": [{"text": "index returns", "start_pos": 44, "end_pos": 57, "type": "METRIC", "confidence": 0.9397761821746826}]}, {"text": "By analyzing the effect of attention on stock market, Yuan demonstrates that investor attention is one of the factors that inherently causes individual investors in aggregate to alter their stock positions dramatically, and he also suggests that the findings have implications for other research in finance.", "labels": [], "entities": []}, {"text": "In an influenced study, Da et al., build a list of search terms based on Google search volume in the U.S. market for various keywords that reveal sentiment toward economic conditions.", "labels": [], "entities": []}, {"text": "By constructing a Financial and Economic Attitudes Revealed by Search (FEARS) index as a measure of investor sentiment, they find that \"FEARS\" is able to predict both short-term return and temporary increases in volatility.", "labels": [], "entities": [{"text": "Financial and Economic Attitudes Revealed by Search (FEARS)", "start_pos": 18, "end_pos": 77, "type": "TASK", "confidence": 0.6993675798177719}, {"text": "FEARS", "start_pos": 136, "end_pos": 141, "type": "METRIC", "confidence": 0.932373046875}]}, {"text": "Tetlock shows that negative terms in English language are more useful for identifying sentiment compared to positive words.", "labels": [], "entities": [{"text": "identifying sentiment", "start_pos": 74, "end_pos": 95, "type": "TASK", "confidence": 0.9255952537059784}]}, {"text": "For this reason, the list consists of thirty negative search terms derived from words of economic sentiment in the Harvard and Lasswell dictionary which have had the largest negative correlation with the market.", "labels": [], "entities": [{"text": "Harvard and Lasswell dictionary", "start_pos": 115, "end_pos": 146, "type": "DATASET", "confidence": 0.95065538585186}]}, {"text": "The constructed list includes terms such as \"gold prices\" and \"recession\", which historically have had the largest daily correlation with the stock market.", "labels": [], "entities": []}, {"text": "Finally, the FEARS index is defined by simply aggregating the change of each term's search volume, which implies that each term contributes equally to the FEARS index.", "labels": [], "entities": [{"text": "FEARS index", "start_pos": 13, "end_pos": 24, "type": "METRIC", "confidence": 0.5783529877662659}, {"text": "FEARS index", "start_pos": 155, "end_pos": 166, "type": "DATASET", "confidence": 0.7606081068515778}]}, {"text": "However, it may not be appropriate to assume that each of the search terms has the same level of contribution to stock market forecasting.", "labels": [], "entities": [{"text": "stock market forecasting", "start_pos": 113, "end_pos": 137, "type": "TASK", "confidence": 0.6300585269927979}]}, {"text": "Since previous works have not taken into account the semantics of the search terms in modelling their effects on the price movements.", "labels": [], "entities": []}, {"text": "Moreover, the fluctuation of the volume of a search term may have a different effect on stock price movements on different days due to the complex dynamics of financial markets.", "labels": [], "entities": []}, {"text": "Therefore, we argue that the current method of calculating the index is far from optimal.", "labels": [], "entities": []}, {"text": "In this paper, instead of calculating index by simply aggregating the change of the thirty terms, FEARS index is refined by allocating different weights to different terms while the contribution is dynamic with the change of market.", "labels": [], "entities": [{"text": "index", "start_pos": 38, "end_pos": 43, "type": "METRIC", "confidence": 0.9176572561264038}, {"text": "FEARS index", "start_pos": 98, "end_pos": 109, "type": "METRIC", "confidence": 0.9309828877449036}]}, {"text": "Ina nutshell, investor attention has been corroborated to be statistically and economically significant in security markets, while little research has been undertaken in the influence of the semantic information.", "labels": [], "entities": []}, {"text": "To under the meaning of the search terms, Natural Language Processing (NLP) is leveraged.", "labels": [], "entities": []}, {"text": "The first key component in neural language understanding models is to find an approach to mathematically model words.", "labels": [], "entities": [{"text": "neural language understanding models", "start_pos": 27, "end_pos": 63, "type": "TASK", "confidence": 0.7420438975095749}]}, {"text": "A traditional method for representing words is the one-hot representation, where each word is represented as a binary vector with all but one entries of the vector are zero.", "labels": [], "entities": []}, {"text": "Each integer value is represented as a binary vector that is all zero values except the index of the target word.", "labels": [], "entities": []}, {"text": "However, there are two main shortcomings associated with such representations.", "labels": [], "entities": []}, {"text": "First, the dimension of a vector increases accordingly when the number of words.", "labels": [], "entities": []}, {"text": "Second, any two words represented by one-hot representation are isolated and cannot capture the information between words at the semantic level.", "labels": [], "entities": []}, {"text": "In comparison, the use of a pre-trained word embedding allows clustering of similar words in a latent space, where semantically similar words are closer in the latent space.", "labels": [], "entities": []}, {"text": "In recent years, language model pre-training has shown to be beneficial for improving downstream tasks of NLP.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments aim to demonstrate that the semantic information integrating with search volume is beneficial to predict the stock return.", "labels": [], "entities": []}, {"text": "In this section, we first introduce the procedure of the collecting the weekly search index and S&P500 return.", "labels": [], "entities": [{"text": "S&P500 return", "start_pos": 96, "end_pos": 109, "type": "DATASET", "confidence": 0.7049606740474701}]}, {"text": "Secondly, we discuss the loss function used in this paper.", "labels": [], "entities": []}, {"text": "Next, we will specify the hyper-parameters in Section 3.3.", "labels": [], "entities": []}, {"text": "Finally, we compare the performance of our method on S&P 500 index prediction to demonstrate the effect of self-attention mechanism with semantic information.", "labels": [], "entities": [{"text": "S&P 500 index prediction", "start_pos": 53, "end_pos": 77, "type": "TASK", "confidence": 0.6422616392374039}]}, {"text": "We use the Mean Square Error (MSE) to evaluate our model in stock return prediction.", "labels": [], "entities": [{"text": "Mean Square Error (MSE)", "start_pos": 11, "end_pos": 34, "type": "METRIC", "confidence": 0.9602597653865814}, {"text": "stock return prediction", "start_pos": 60, "end_pos": 83, "type": "TASK", "confidence": 0.6171991030375162}]}, {"text": "MSE is calculated as: Where n denotes the length of total test sets, \u00ed \u00b5\u00ed\u00b2\u0091 \u00ed \u00b5\u00ed\u00b2\u0095 is the true value of the S&P500 index while \u00ed \u00b5\u00ed\u00b2\u0091 \u00ed \u00b5\u00ed\u00b2\u0095 represents the output of our model at timestamp t.", "labels": [], "entities": [{"text": "\u00ed \u00b5\u00ed\u00b2\u0091 \u00ed \u00b5\u00ed\u00b2\u0095", "start_pos": 69, "end_pos": 82, "type": "METRIC", "confidence": 0.8340387940406799}, {"text": "S&P500 index", "start_pos": 108, "end_pos": 120, "type": "DATASET", "confidence": 0.6442824453115463}]}, {"text": "The hyper-parameters are shown in and are the same as in the model BERT-BASE.", "labels": [], "entities": [{"text": "BERT-BASE", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9709094166755676}]}, {"text": "Since the BERT-Base model we applied has 110M parameters.", "labels": [], "entities": [{"text": "BERT-Base", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.98312908411026}]}, {"text": "Hence, we change the terms embedding to non-trainable variables in our model.", "labels": [], "entities": []}, {"text": "That is, we train our two models separately in order to speedup the training process.", "labels": [], "entities": []}, {"text": "Experimental hyper-parameters of the prediction model are shown in.", "labels": [], "entities": []}, {"text": "In this section, we demonstrate the efficiency of our proposed model based on our experimental results.", "labels": [], "entities": []}, {"text": "We first reproduce the baseline work of , then we compare different ways of integrating the semantic information with the baseline work in terms of their performance on the weekly dataset we collected.", "labels": [], "entities": []}, {"text": "We evaluate our model using the onlinetraining strategy.", "labels": [], "entities": []}, {"text": "Since there are no previous attempts on adopting non-linear method based on the FEAR index, we just compare our method with the original strategy proposed by  in experiments.", "labels": [], "entities": [{"text": "FEAR index", "start_pos": 80, "end_pos": 90, "type": "METRIC", "confidence": 0.969867616891861}]}], "tableCaptions": [{"text": " Table 2: Hyper-parameters of Prediction Model", "labels": [], "entities": [{"text": "Hyper-parameters", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.8563491702079773}]}]}