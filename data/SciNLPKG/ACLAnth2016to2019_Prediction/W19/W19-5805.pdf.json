{"title": [{"text": "Using hyperbolic large-margin classifiers for biological link prediction", "labels": [], "entities": [{"text": "biological link prediction", "start_pos": 46, "end_pos": 72, "type": "TASK", "confidence": 0.6585564514001211}]}], "abstractContent": [{"text": "Recently proposed hyperbolic neural embed-dings naturally represent latent hierarchical semantic relations, and could provide a suitable bridge from the discrete world of biological networks to continuous geometric representations , enabling downstream machine learning tasks, such as link prediction.", "labels": [], "entities": [{"text": "link prediction", "start_pos": 285, "end_pos": 300, "type": "TASK", "confidence": 0.822386234998703}]}, {"text": "In some cases, however, link prediction is modeled by separating hyperbolic embeddings using classifiers that operate in a flat Euclidean space, thus un-derexploiting the inherently curved geometric space of embeddings.", "labels": [], "entities": [{"text": "link prediction", "start_pos": 24, "end_pos": 39, "type": "TASK", "confidence": 0.9292332231998444}]}, {"text": "Herein we present and analyze how recently introduced large-margin classifiers in hyperbolic space could be used in conjunction with hyperbolic embeddings, in order to perform biological link prediction, which exploits the curved geometry of complex biological information.", "labels": [], "entities": [{"text": "biological link prediction", "start_pos": 176, "end_pos": 202, "type": "TASK", "confidence": 0.6718178689479828}]}], "introductionContent": [{"text": "Link prediction is the task of finding missing or unknown links among inter-connected entities.", "labels": [], "entities": [{"text": "Link prediction", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8864353001117706}]}, {"text": "This assumes that entities and links can be represented as a graph, where entities are nodes and links are edges (if relationships are symmetric) or arcs (if relationships are asymmetric).", "labels": [], "entities": []}, {"text": "When dealing with link prediction in knowledge bases, the semantic information contained is usually encoded as a knowledge graph (KG).", "labels": [], "entities": [{"text": "link prediction", "start_pos": 18, "end_pos": 33, "type": "TASK", "confidence": 0.750906229019165}]}, {"text": "For the purposes of this work we simply treat a knowledge graph as a graph with labelled edges (arcs), meaning that two entities maybe connected with more than one link of different types.", "labels": [], "entities": []}, {"text": "In addition, we conform to the closed-world assumption.", "labels": [], "entities": []}, {"text": "This means that all the existing (asserted) links are considered positive, and all the links which are unknown are considered negative.", "labels": [], "entities": []}, {"text": "This separation into positive and negative links naturally allows us to treat the link prediction problem as a supervised classification problem with binary classifiers (one classifier for each relation type).", "labels": [], "entities": [{"text": "link prediction", "start_pos": 82, "end_pos": 97, "type": "TASK", "confidence": 0.746722936630249}]}, {"text": "However, while this separation makes it possible to use a wide array of wellstudied machine learning algorithms for link prediction, the main challenge is how to find the best representations for the links.", "labels": [], "entities": [{"text": "link prediction", "start_pos": 116, "end_pos": 131, "type": "TASK", "confidence": 0.7726563513278961}]}, {"text": "This is the core subject of the recent research trend in learning suitable representations for knowledge graphs, largely dominated by so-called neural embeddings.", "labels": [], "entities": []}, {"text": "Most commonly, neural embeddings are numeric representations of nodes and relations of the knowledge graph in some continuous space with vectorial structure.", "labels": [], "entities": []}, {"text": "An overview of state-of-the-art approaches can be found in (.", "labels": [], "entities": []}, {"text": "Predicting links is especially relevant in the biomedical domain, where biological knowledge lends itself naturally to be modelled with knowledge graphs.", "labels": [], "entities": []}, {"text": "Indeed, biological entities such as genes and gene functions can be modelled as nodes, and links among these entities as edges or arcs.", "labels": [], "entities": []}, {"text": "Neural embeddings \u0398 for these biological entities could be trained with embedding models.", "labels": [], "entities": []}, {"text": "And by training a binary classifier on these continuous numeric representations \u0398, we could, for example, estimate the probability Pl ((u, v) = 1 | \u0398) of having a link l = HAS-FUNCTION (e.g., labelled edge) between nodes u = TRIM28 GENE and v = NEGATIVE REGULATION OF TRAN-SCRIPTION BY RNA POLYMERASE II.", "labels": [], "entities": [{"text": "HAS-FUNCTION", "start_pos": 172, "end_pos": 184, "type": "METRIC", "confidence": 0.9923612475395203}, {"text": "TRIM28 GENE", "start_pos": 225, "end_pos": 236, "type": "DATASET", "confidence": 0.6013935804367065}, {"text": "TRAN-SCRIPTION BY RNA POLYMERASE", "start_pos": 268, "end_pos": 300, "type": "METRIC", "confidence": 0.7302774488925934}]}, {"text": "More recently, researchers in machine learning have turned their attention to hyperbolic space as a better candidate for continuous geometric representation of graph-based data.", "labels": [], "entities": []}, {"text": "This approach could be of special interest for the representation of complex biological networks, which were found to inherently exhibit a hyperbolic structure (.", "labels": [], "entities": []}, {"text": "However, as argued in (, in many situations hyperbolic embeddings are used in classification tasks (such as link prediction) that operate in ill-fitted Euclidean space.", "labels": [], "entities": [{"text": "link prediction", "start_pos": 108, "end_pos": 123, "type": "TASK", "confidence": 0.708752915263176}]}, {"text": "This leads to a situation where (flat) Euclidean classifiers misuse all the learned curved information that lives in hyperbolic embeddings.", "labels": [], "entities": []}, {"text": "In this work we compare hyperbolic and Euclidean large-margin classifiers when used for biological link prediction with the embeddings learned in flat and curved geometric spaces.", "labels": [], "entities": [{"text": "biological link prediction", "start_pos": 88, "end_pos": 114, "type": "TASK", "confidence": 0.6490337948004404}]}, {"text": "We believe that the lessons learned from this comparison will help in the identification of next steps required for end-to-end hyperbolic embedding training pipelines to adequately exploit inherently curved geometry, and to uncover latent hierarchical semantic relations of complex biological patterns.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}