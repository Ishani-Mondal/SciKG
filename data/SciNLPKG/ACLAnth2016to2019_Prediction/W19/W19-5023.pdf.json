{"title": [{"text": "Enhancing PIO Element Detection in Medical Text Using Contextualized Embedding", "labels": [], "entities": [{"text": "Enhancing PIO Element Detection", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7877040877938271}]}], "abstractContent": [{"text": "In this paper, we investigate anew approach to Population, Intervention and Outcome (PIO) element detection, a common task in Evidence Based Medicine (EBM).", "labels": [], "entities": [{"text": "Population, Intervention and Outcome (PIO) element detection", "start_pos": 47, "end_pos": 107, "type": "TASK", "confidence": 0.6175234258174896}, {"text": "Evidence Based Medicine (EBM)", "start_pos": 126, "end_pos": 155, "type": "TASK", "confidence": 0.6112062335014343}]}, {"text": "The purpose of this study is twofold: to build a training dataset for PIO element detection with minimum redundancy and ambiguity and to investigate possible options in utilizing state of the art embedding methods for the task of PIO element detection.", "labels": [], "entities": [{"text": "PIO element detection", "start_pos": 70, "end_pos": 91, "type": "TASK", "confidence": 0.8432172536849976}, {"text": "PIO element detection", "start_pos": 230, "end_pos": 251, "type": "TASK", "confidence": 0.8723057508468628}]}, {"text": "For the former purpose, we build anew and improved dataset by investigating the shortcomings of previously released datasets.", "labels": [], "entities": []}, {"text": "For the latter purpose, we leverage the state of the art text embedding, Bidirectional Encoder Representations from Transformers (BERT), and build a multi-label classifier.", "labels": [], "entities": [{"text": "BERT", "start_pos": 130, "end_pos": 134, "type": "METRIC", "confidence": 0.46159854531288147}]}, {"text": "We show that choosing a domain specific pre-trained embedding further optimizes the performance of the classifier.", "labels": [], "entities": []}, {"text": "Furthermore, we show that the model could be enhanced by using ensemble methods and boosting techniques provided that features are adequately chosen.", "labels": [], "entities": []}], "introductionContent": [{"text": "Evidence-based medicine (EBM) is of primary importance in the medical field.", "labels": [], "entities": [{"text": "Evidence-based medicine (EBM)", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8059770822525024}]}, {"text": "Its goal is to present statistical analyses of issues of clinical focus based on retrieving and analyzing numerous papers in the medical literature ().", "labels": [], "entities": []}, {"text": "The PubMed database is one of the most commonly used databases in EBM (.", "labels": [], "entities": [{"text": "PubMed database", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.9724420011043549}]}, {"text": "Biomedical papers, describing randomized controlled trials in medical intervention, are published at a high rate every year.", "labels": [], "entities": []}, {"text": "The volume of these publications makes it very challenging for physicians to find the best medical intervention fora given patient group and condition.", "labels": [], "entities": []}, {"text": "Computational methods and natural language processing (NLP) could be adopted in order to expedite the process of biomedical evidence synthesis.", "labels": [], "entities": [{"text": "biomedical evidence synthesis", "start_pos": 113, "end_pos": 142, "type": "TASK", "confidence": 0.6711748043696085}]}, {"text": "Specifically, NLP tasks applied to well structured documents and queries can help physicians extract appropriate information to identify the best available evidence in the context of medical treatment.", "labels": [], "entities": []}, {"text": "Clinical questions are formed using the PIO framework, where clinical issues are broken down into four components: Population/Problem (P), Intervention (I), Comparator (C), and Outcome (O).", "labels": [], "entities": []}, {"text": "We will refer to these categories as PIO elements, by using the common practice of merging the C and I categories.", "labels": [], "entities": []}, {"text": "In ( a literature screening performed in 10 systematic reviews was studied.", "labels": [], "entities": []}, {"text": "It was found that using the PIO framework can significantly improve literature screening efficacy.", "labels": [], "entities": []}, {"text": "Therefore, efficient extraction of PIO elements is a key feature of many EBM applications and could bethought of as a multilabel sentence classification problem.", "labels": [], "entities": [{"text": "sentence classification", "start_pos": 129, "end_pos": 152, "type": "TASK", "confidence": 0.7231818437576294}]}, {"text": "Previous works on PIO element extraction focused on classical NLP methods, such as Naive Bayes (NB), Support Vector Machines (SVM) and Conditional Random Fields (CRF)).", "labels": [], "entities": [{"text": "PIO element extraction", "start_pos": 18, "end_pos": 40, "type": "TASK", "confidence": 0.8945302367210388}]}, {"text": "These models are shallow and limited in terms of modeling capacity.", "labels": [], "entities": []}, {"text": "Furthermore, most of these classifiers are trained to extract PIO elements one by one which is suboptimal since this approach does not allow the use of shared structure among the individual classifiers.", "labels": [], "entities": []}, {"text": "Deep neural network models have increased in popularity in the field of NLP.", "labels": [], "entities": []}, {"text": "They have pushed the state of the art of text representation and information retrieval.", "labels": [], "entities": [{"text": "text representation", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.8188146948814392}, {"text": "information retrieval", "start_pos": 65, "end_pos": 86, "type": "TASK", "confidence": 0.8328615427017212}]}, {"text": "More specifically, these techniques enhanced NLP algorithms through the use of contextualized text embeddings at word, sentence, and paragraph levels (.", "labels": [], "entities": []}, {"text": "More recently, Jin and Szolovits (2018) proposed a bidirectional long short term memory (LSTM) model to simultaneously extract PIO components from PubMed abstracts.", "labels": [], "entities": []}, {"text": "To our knowledge, that study was the first in which a deep learning framework was used to extract PIO elements from PubMed abstracts.", "labels": [], "entities": [{"text": "PIO elements from PubMed abstracts", "start_pos": 98, "end_pos": 132, "type": "TASK", "confidence": 0.5452693343162537}]}, {"text": "In the present paper, we build a dataset of PIO elements by improving the methodology found in).", "labels": [], "entities": []}, {"text": "Furthermore, we built a multi-label PIO classifier, along with a boosting framework, based on the state of the art text embedding, BERT.", "labels": [], "entities": [{"text": "BERT", "start_pos": 131, "end_pos": 135, "type": "METRIC", "confidence": 0.9491904377937317}]}, {"text": "This embedding model has been proven to offer a better contextualization compared to a bidirectional LSTM model).", "labels": [], "entities": []}], "datasetContent": [{"text": "In this study, we introduce PICONET, a multilabel dataset consisting of sequences with labels Population/Problem (P), Intervention (I), and Outcome (O).", "labels": [], "entities": []}, {"text": "This dataset was created by collecting structured abstracts from PubMed and carefully choosing abstract headings representative of the desired categories.", "labels": [], "entities": []}, {"text": "The present approach is an improvement over a similar approach used in.", "labels": [], "entities": []}, {"text": "Our aim was to perform automatic labeling while removing as much ambiguity as possible.", "labels": [], "entities": [{"text": "labeling", "start_pos": 33, "end_pos": 41, "type": "TASK", "confidence": 0.6949642300605774}]}, {"text": "We performed a search on April 11, 2019 on PubMed for 363,078 structured abstracts with the following filters: Article Types (Clinical Trial), Species (Humans), and Languages (English).", "labels": [], "entities": [{"text": "PubMed", "start_pos": 43, "end_pos": 49, "type": "DATASET", "confidence": 0.9629526734352112}]}, {"text": "Structured abstract sections from PubMed have labels such as introduction, goals, study design, findings, or discussion; however, the majority of these labels are not useful for P, I, and O extraction since most are general (e.g. methods) and do not isolate a specific P, I, O sequence.", "labels": [], "entities": [{"text": "P, I, and O extraction", "start_pos": 178, "end_pos": 200, "type": "TASK", "confidence": 0.641831214938845}]}, {"text": "Therefore, in order to narrow down abstract sections that correspond to the P label, for example, we needed to find a subset of labels such as, but not limited to population, patients, and subjects.", "labels": [], "entities": []}, {"text": "We performed a lemmatization of the abstract section labels in order to cluster similar categories such as subject and subjects.", "labels": [], "entities": []}, {"text": "Using this approach, we carefully chose candidate labels for each P, I, and O, and manually looked at a small number of samples for each label to determine if text was representative.", "labels": [], "entities": []}, {"text": "Since our goal was to collect sequences that are uniquely representative of a description of Population, Intervention, and Outcome, we avoided a keyword-based approach such as in.", "labels": [], "entities": []}, {"text": "For example, using a keyword- based approach would yield a sequence labeled population and methods with the label P, but such abstract sections were not purely about the population and contained information about the interventions and study design making them poor candidates fora P label.", "labels": [], "entities": []}, {"text": "Thus, we were able to extract portions of abstracts pertaining to P, I, and O categories while minimizing ambiguity and redundancy.", "labels": [], "entities": []}, {"text": "Moreover, in the dataset from (Jin and Szolovits, 2018), a section labeled as P that contained more than one sentence would be split into multiple P sentences to be included in the dataset.", "labels": [], "entities": []}, {"text": "We avoided this approach and kept the full abstract sections.", "labels": [], "entities": []}, {"text": "The full abstracts were kept in conjunction with our belief that keeping the full section retains more feature-rich sequences for each sequence, and that individual sentences from long abstract sections can be poor candidates for the corresponding label.", "labels": [], "entities": []}, {"text": "For sections with labels such as population and intervention, we created a mutli-label.", "labels": [], "entities": []}, {"text": "We also included negative examples by taking sentences from sections with headings such as aim.", "labels": [], "entities": [{"text": "aim", "start_pos": 91, "end_pos": 94, "type": "METRIC", "confidence": 0.9545810222625732}]}, {"text": "Furthermore, we cleaned the remaining data with various approaches including, but not limited to, language identification, removal of missing values, cleaning unicode characters, and filtering for sequences between 5 and 200 words, inclusive.", "labels": [], "entities": [{"text": "language identification", "start_pos": 98, "end_pos": 121, "type": "TASK", "confidence": 0.7705913484096527}]}], "tableCaptions": [{"text": " Table 1: Number of occurrences of each category P, I  and O in abstracts.", "labels": [], "entities": []}, {"text": " Table 2: Performance of the classifiers in terms of  ROC AUC and F1 scores.", "labels": [], "entities": [{"text": "ROC AUC", "start_pos": 54, "end_pos": 61, "type": "METRIC", "confidence": 0.8310463726520538}, {"text": "F1 scores", "start_pos": 66, "end_pos": 75, "type": "METRIC", "confidence": 0.9682708382606506}]}]}