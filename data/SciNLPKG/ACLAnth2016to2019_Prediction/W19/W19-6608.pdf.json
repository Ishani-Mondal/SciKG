{"title": [{"text": "MAGMATic: A Multi-domain Academic Gold Standard with Manual Annotation of Terminology for Machine Translation Evaluation", "labels": [], "entities": [{"text": "MAGMATic", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.7257130146026611}, {"text": "Machine Translation Evaluation", "start_pos": 90, "end_pos": 120, "type": "TASK", "confidence": 0.8566777110099792}]}], "abstractContent": [{"text": "This paper presents MAGMATic (Multi-domain Academic Gold Standard with Manual Annotation of Terminology), a novel Italian-English benchmark which allows MT evaluation focused on terminology translation.", "labels": [], "entities": [{"text": "MAGMATic", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9315005540847778}, {"text": "MT evaluation", "start_pos": 153, "end_pos": 166, "type": "TASK", "confidence": 0.9327757656574249}, {"text": "terminology translation", "start_pos": 178, "end_pos": 201, "type": "TASK", "confidence": 0.8679861426353455}]}, {"text": "The data set comprises 2,056 parallel sentences extracted from institutional academic texts, namely course unit and degree program descriptions.", "labels": [], "entities": []}, {"text": "This text type is particularly interesting since it contains terminology from multiple domains , e.g. education and different academic disciplines described in the texts.", "labels": [], "entities": []}, {"text": "All terms in the English target side of the data set were manually identified and annotated with a domain label, fora total of 7,517 annotated terms.", "labels": [], "entities": [{"text": "English target side of the data set", "start_pos": 17, "end_pos": 52, "type": "DATASET", "confidence": 0.6799617239407131}]}, {"text": "Due to their peculiar features, institutional academic texts represent an interesting test bed for MT.", "labels": [], "entities": [{"text": "MT", "start_pos": 99, "end_pos": 101, "type": "TASK", "confidence": 0.9888778328895569}]}, {"text": "As a further contribution of this paper, we investigate the feasibility of exploiting MT for the translation of this type of documents.", "labels": [], "entities": [{"text": "MT", "start_pos": 86, "end_pos": 88, "type": "TASK", "confidence": 0.9637850522994995}, {"text": "translation", "start_pos": 97, "end_pos": 108, "type": "TASK", "confidence": 0.9777037501335144}]}, {"text": "To this aim, we evaluate two state-of-the-art Neural MT systems on MAG-MATic, focusing on their ability to translate domain-specific terminology.", "labels": [], "entities": [{"text": "Neural MT", "start_pos": 46, "end_pos": 55, "type": "TASK", "confidence": 0.5010579377412796}]}], "introductionContent": [{"text": "The availability of bilingual versions of course catalogues has started to play a major role for European universities after the Bologna Process and the resulting growth in students' mobility.", "labels": [], "entities": []}, {"text": "Course catalogues fall into the category of institutional aca- demic text collections and they usually include degree program and course unit descriptions, where information regarding degree courses and modules are provided to students.", "labels": [], "entities": []}, {"text": "Such texts have to be produced and published every year in each country language and in English.", "labels": [], "entities": []}, {"text": "Universities would thus undoubtedly benefit from the use of machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.7167599201202393}]}, {"text": "Further proof of the need for an MT engine able to translate course catalogues are two projects funded by the European Commission, namely the Bologna Translation Service), aimed at developing an MT system to translate course catalogues in 9 language combinations, and TraMOOC, 2 aimed at using MT for the translation of massive online open courses from English into eleven European and BRIC languages.", "labels": [], "entities": [{"text": "Bologna Translation Service", "start_pos": 142, "end_pos": 169, "type": "DATASET", "confidence": 0.793513298034668}]}, {"text": "Developing an engine in this field poses several challenges.", "labels": [], "entities": []}, {"text": "First, the fact that degree program and course unit descriptions are usually translated by non-native speakers of the target language) reduces the number of available high-quality and alignable bilingual texts.", "labels": [], "entities": []}, {"text": "Moreover, the lack of guidelines and best practices to draft these texts results in substantial unmotivated variation among course catalogues from different universities.", "labels": [], "entities": []}, {"text": "Finally, institutional academic texts usually contain terminology from different domains, with disciplinary terms, e.g. Hydrosilylation, Fotoredox catalysis, fora course on chemistry, appearing together with educational ones -e.g. ECTS, module.", "labels": [], "entities": [{"text": "ECTS", "start_pos": 231, "end_pos": 235, "type": "DATASET", "confidence": 0.8473843932151794}]}, {"text": "The potential and challenges mentioned so far make course catalogues an interesting test bed for neural MT (NMT)).", "labels": [], "entities": []}, {"text": "Indeed, in the last few years NMT has delivered considerable improvements in output quality in many respects (), yet not showing clear-cut progresses when it comes to lexis-related issues, e.g. lexical choices, omissions or mistranslations).", "labels": [], "entities": [{"text": "NMT", "start_pos": 30, "end_pos": 33, "type": "DATASET", "confidence": 0.7270331978797913}]}, {"text": "These issues are especially critical for texts rich in domain-specific terminology, or texts containing terms belonging to different domains.", "labels": [], "entities": []}, {"text": "Testing an MT engine on course catalogues can provide interesting information on domain-specific terminology handling and on results achievable with a relatively small amount of in-domain resources used to perform domain-adaptation of a neural model.", "labels": [], "entities": [{"text": "MT", "start_pos": 11, "end_pos": 13, "type": "TASK", "confidence": 0.9660627841949463}, {"text": "domain-specific terminology handling", "start_pos": 81, "end_pos": 117, "type": "TASK", "confidence": 0.6484152475992838}]}, {"text": "Whilst assessing systems' ability to correctly translate domain-specific terms is a crucial aspect in MT evaluation, research in the field has to cope with a dearth of publicly available resources specifically tailored to that task.", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 102, "end_pos": 115, "type": "TASK", "confidence": 0.9905571043491364}]}, {"text": "The main contribution of this paper is to provide the MT community with MAGMATic (Multi-domain Academic Gold standard with Manual Annotation of Terminology), a novel Italian-English benchmark which allows MT evaluation focused on terminology translation.", "labels": [], "entities": [{"text": "MT", "start_pos": 54, "end_pos": 56, "type": "TASK", "confidence": 0.9872831106185913}, {"text": "MAGMATic", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9266637563705444}, {"text": "MT evaluation", "start_pos": 205, "end_pos": 218, "type": "TASK", "confidence": 0.9138990640640259}, {"text": "terminology translation", "start_pos": 230, "end_pos": 253, "type": "TASK", "confidence": 0.8488762974739075}]}, {"text": "The data set comprises 2,056 sentences extracted from course unit and degree program descriptions from four different Italian universities and manually aligned to their English translations.", "labels": [], "entities": []}, {"text": "All terms in the English target side of the data set were manually identified and annotated with a domain label, fora total of 7,517 annotated terms, covering 20 different domains related to different disciplines -excluding humanities and with a focus on hard sciences -as well as education and education equipment.", "labels": [], "entities": [{"text": "English target side of the data set", "start_pos": 17, "end_pos": 52, "type": "DATASET", "confidence": 0.7517480679920742}]}, {"text": "These features make the data set a valuable resource to evaluate and analyze systems' performance on terminology translation, thus contributing to shed light on this crucial aspect for MT.", "labels": [], "entities": [{"text": "terminology translation", "start_pos": 101, "end_pos": 124, "type": "TASK", "confidence": 0.8883123397827148}, {"text": "MT", "start_pos": 185, "end_pos": 187, "type": "TASK", "confidence": 0.9938045740127563}]}, {"text": "MAGMATic is released under a Creative Commons Attribution -Non CommercialShare Alike 4.0 International license (CC BY-NC-SA 4.0), and is freely downloadable at: https://ict.fbk.eu/magmatic/ In the remainder of this paper we describe MAGMATic and illustrate its potential by using it to evaluate two state-of-the-art MT systems (Google Translate and ModernMT), both in terms of overall performance and focusing on their ability to translate domain-specific terminology.", "labels": [], "entities": [{"text": "MT", "start_pos": 316, "end_pos": 318, "type": "TASK", "confidence": 0.9597193002700806}, {"text": "ModernMT", "start_pos": 349, "end_pos": 357, "type": "DATASET", "confidence": 0.9712961316108704}]}, {"text": "After describing related work on term translation evaluation (Section 2), we introduce the main characteristics of MAGMATic (Section 3) and provide results from the evaluation study carried out on the two state-of-the-art MT systems (Section 4).", "labels": [], "entities": [{"text": "term translation evaluation", "start_pos": 33, "end_pos": 60, "type": "TASK", "confidence": 0.8620692094167074}, {"text": "MT", "start_pos": 222, "end_pos": 224, "type": "TASK", "confidence": 0.9670094847679138}]}], "datasetContent": [{"text": "Given the novelty of the application of MT to the translation of course catalogues, we are focusing on two scenarios that we deem realistic for one or more universities willing to use MT: \u2022 First scenario (GT, MMT-I).", "labels": [], "entities": [{"text": "MT", "start_pos": 40, "end_pos": 42, "type": "TASK", "confidence": 0.963232159614563}, {"text": "translation of course catalogues", "start_pos": 50, "end_pos": 82, "type": "TASK", "confidence": 0.8518376797437668}]}, {"text": "One or more universities want to use MT for the translation of their course catalogues for the first time, and have no translation memories.", "labels": [], "entities": [{"text": "MT", "start_pos": 37, "end_pos": 39, "type": "TASK", "confidence": 0.8293597102165222}, {"text": "translation", "start_pos": 48, "end_pos": 59, "type": "TASK", "confidence": 0.9689461588859558}]}, {"text": "At this point, no in-domain bilingual texts are available.", "labels": [], "entities": []}, {"text": "\u2022 Second scenario (GT, MMT-II).", "labels": [], "entities": []}, {"text": "A university consortium agrees to coordinate their communication strategies.", "labels": [], "entities": []}, {"text": "They use CAT tools for translating their course catalogues and produce a reasonable amount of translations, which can be leveraged as shared domainadaptation data.", "labels": [], "entities": []}, {"text": "In order to address the second scenario, we needed an in-domain data set to be exploited for MT adaptation.", "labels": [], "entities": [{"text": "MT adaptation", "start_pos": 93, "end_pos": 106, "type": "TASK", "confidence": 0.9951167404651642}]}, {"text": "To this effect, the parallel data collected from the 4 Italian universities but left out in the creation of MAGMATic (see Sect. 3.1) were used.", "labels": [], "entities": [{"text": "MAGMATic", "start_pos": 108, "end_pos": 116, "type": "DATASET", "confidence": 0.7318876385688782}]}, {"text": "Statistics for this data set are outlined in Table 4.", "labels": [], "entities": []}, {"text": "Since the online generic version of GT used in this work is not adaptive, it can be tested in the first evaluation scenario only.", "labels": [], "entities": []}, {"text": "As a SOTA system, GT provides an external validation of the quality of MMT.", "labels": [], "entities": [{"text": "MMT", "start_pos": 71, "end_pos": 74, "type": "TASK", "confidence": 0.9481134414672852}]}, {"text": "Differently, MMT is evaluated in both scenarios to analyse the impact of in-domain data on translation quality.", "labels": [], "entities": [{"text": "MMT", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9512261748313904}]}, {"text": "The MT systems were evaluated both in terms of overall performance and specifically targeting their ability to translate domain terminology.", "labels": [], "entities": [{"text": "MT", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.9692320227622986}, {"text": "translate domain terminology", "start_pos": 111, "end_pos": 139, "type": "TASK", "confidence": 0.8300307194391886}]}, {"text": "The bigger picture of the quality achieved with the setup described so far is provided through an automatic evaluation in terms of BLEU score).", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 131, "end_pos": 141, "type": "METRIC", "confidence": 0.982904702425003}]}, {"text": "The evaluation focused on terminology translation is based on the Term Hit Rate (THR) metric.", "labels": [], "entities": [{"text": "terminology translation", "start_pos": 26, "end_pos": 49, "type": "TASK", "confidence": 0.9245777428150177}, {"text": "Term Hit Rate (THR) metric", "start_pos": 66, "end_pos": 92, "type": "METRIC", "confidence": 0.9123783367020744}]}, {"text": "THR takes in a list of annotated terms in each reference sentence and looks for their occurrence in the MT output.", "labels": [], "entities": [{"text": "THR", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.5502253770828247}]}, {"text": "Then it computes the proportion of terms in the reference that are correctly translated by the MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 95, "end_pos": 97, "type": "TASK", "confidence": 0.7237720489501953}]}, {"text": "An upper bound of 1 match for each reference term is applied in order not to reward over-generated terms in the MT output.", "labels": [], "entities": [{"text": "MT", "start_pos": 112, "end_pos": 114, "type": "TASK", "confidence": 0.8743883967399597}]}, {"text": "Similarly to the approach adopted for interannotator agreement (see Sect.", "labels": [], "entities": [{"text": "interannotator agreement", "start_pos": 38, "end_pos": 62, "type": "TASK", "confidence": 0.9255157113075256}]}, {"text": "3.4), two THR types are computed: perfect THR -where a match is scored only if the whole reference term appears in the MT output -and partial THR, where the overlap between the reference terms and the MT output is calculated at the level of shared tokens.", "labels": [], "entities": [{"text": "perfect THR", "start_pos": 34, "end_pos": 45, "type": "METRIC", "confidence": 0.8288125395774841}]}, {"text": "In this case, function words are removed from the MW terms in the reference, so as to avoid false positives with other function words present in the MT output.", "labels": [], "entities": [{"text": "MT", "start_pos": 149, "end_pos": 151, "type": "TASK", "confidence": 0.7741466760635376}]}, {"text": "A general overview on the quality achieved by GT, MMT-I (first scenario) and MMT-II (second scenario) is provided in.: Perfect THR for GT and the 2 MMT systems.", "labels": [], "entities": [{"text": "MMT-I", "start_pos": 50, "end_pos": 55, "type": "DATASET", "confidence": 0.7409161925315857}, {"text": "MMT-II", "start_pos": 77, "end_pos": 83, "type": "DATASET", "confidence": 0.7491139769554138}, {"text": "THR", "start_pos": 127, "end_pos": 130, "type": "METRIC", "confidence": 0.9913884997367859}]}, {"text": "In addition to the overall scores, figures for SWs and MWs are given separately.", "labels": [], "entities": []}, {"text": "Results are provided (i) for the whole data set (All), (ii) split according to the domain category (Disc, Edu, Equip) and (iii) distinguishing between sure and possible terms.", "labels": [], "entities": []}, {"text": "The good results obtained by GT and MMT-I show that NMT can be helpful already in the first scenario, where only generic systems can be used.", "labels": [], "entities": []}, {"text": "The huge performance increase of MMT-II (+7.71 wrt MMT-I and +6.26 wrt GT) is even more encouraging in the long-term perspective.", "labels": [], "entities": [{"text": "MMT-II", "start_pos": 33, "end_pos": 39, "type": "DATASET", "confidence": 0.5353526473045349}]}, {"text": "Focusing on the evaluation of terminology translation, perfect and partial THR scores were computed on MAGMATic for GT and the two MMT systems.", "labels": [], "entities": [{"text": "terminology translation", "start_pos": 30, "end_pos": 53, "type": "TASK", "confidence": 0.8682230710983276}, {"text": "perfect", "start_pos": 55, "end_pos": 62, "type": "METRIC", "confidence": 0.9582576751708984}, {"text": "THR", "start_pos": 75, "end_pos": 78, "type": "METRIC", "confidence": 0.9648029804229736}]}, {"text": "presents results for Perfect THR.", "labels": [], "entities": [{"text": "Perfect", "start_pos": 21, "end_pos": 28, "type": "METRIC", "confidence": 0.9794095158576965}, {"text": "THR", "start_pos": 29, "end_pos": 32, "type": "METRIC", "confidence": 0.8240745663642883}]}, {"text": "Since MAGMATic contains both SW and MW terms, the table gives the scores for each set separately in addition to the overall score.", "labels": [], "entities": []}, {"text": "Also, to allow a more detailed analysis of the systems' behaviour on MAGMATic terms, results are provided by domain category (disciplinary, education, equipment) and in terms of the sure/possible distinction.", "labels": [], "entities": []}, {"text": "Considering the strict parameters used to calculate perfect THR, the results shown in are quite satisfactory.", "labels": [], "entities": [{"text": "THR", "start_pos": 60, "end_pos": 63, "type": "METRIC", "confidence": 0.9678983092308044}]}, {"text": "Regarding domain categories, all systems in all scenarios perform far better on disciplinary terms.", "labels": [], "entities": []}, {"text": "As for term length, SW terms are, as expected, easier to translate than MWs.", "labels": [], "entities": []}, {"text": "The most challenging terms for all MT systems are MWs in the education and equipment categories.", "labels": [], "entities": [{"text": "MT", "start_pos": 35, "end_pos": 37, "type": "TASK", "confidence": 0.992065966129303}]}, {"text": "Focusing on the first scenario, we see that GT and MMT have a similar behaviour, since the differences between the two systems (ranging between 2 and 4 THR points) are constant across all the different views of the data.", "labels": [], "entities": [{"text": "MMT", "start_pos": 51, "end_pos": 54, "type": "DATASET", "confidence": 0.7166979908943176}]}, {"text": "Two exceptions are represented by the education and education equipment MW terms, for which differences are less marked (respectively 1.", "labels": [], "entities": [{"text": "education equipment MW terms", "start_pos": 52, "end_pos": 80, "type": "DATASET", "confidence": 0.7422538846731186}]}, {"text": "translating the most difficult terms in the data set.", "labels": [], "entities": []}, {"text": "At the same time, GT outperforms MMT-I by 5.17 THR in the possible MW category, showing that MMT-I probably struggles more than GT for words that might not be terms.", "labels": [], "entities": []}, {"text": "Comparing MMT results in the two scenarios sheds light on the specific contributions that indomain data can bring to terminology translation.", "labels": [], "entities": [{"text": "MMT", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.9650735259056091}, {"text": "terminology translation", "start_pos": 117, "end_pos": 140, "type": "TASK", "confidence": 0.9219804108142853}]}, {"text": "First of all, in the second scenario there is an increase of the overall performance on the whole data set (+4.36 THR points).", "labels": [], "entities": [{"text": "THR", "start_pos": 114, "end_pos": 117, "type": "METRIC", "confidence": 0.9906850457191467}]}, {"text": "The difference with respect to the first scenario is particularly evident for MW terms (+5.75), suggesting that domain adaptation did not only influence lexical choices, but also helped the system to place terms in the correct position.", "labels": [], "entities": []}, {"text": "As a matter of fact, if we look at the partial THR results shown in, we see that the performance gap between the two systems is narrower.", "labels": [], "entities": [{"text": "THR", "start_pos": 47, "end_pos": 50, "type": "METRIC", "confidence": 0.9133147597312927}]}, {"text": "This means that the generic and the adapted MMT systems perform similarly in the generation of the SWs composing a MW, but adapted MMT is better at generating them in the Proceedings of MT Summit XVII, volume 1 Dublin, Aug. 19-23, 2019 | p.", "labels": [], "entities": [{"text": "MT Summit XVII, volume 1 Dublin, Aug. 19-23", "start_pos": 186, "end_pos": 229, "type": "TASK", "confidence": 0.6989660501480103}]}, {"text": "For example, in one of the segments the annotated MW classification of living beings was correctly generated in the second scenario, while in the first one the system produced the MW living classification, which is a match only in the partial THR evaluation.", "labels": [], "entities": []}, {"text": "Finally, the biggest improvement can be found for education and equipment MW terms, which -as we have seen above -are the most challenging for the MT systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 147, "end_pos": 149, "type": "TASK", "confidence": 0.9803853034973145}]}, {"text": "As a final observation holding for all systems in both THR evaluations, there is a clear drop in performance when progressing from the evaluation of sure terms to that of possible terms.", "labels": [], "entities": []}, {"text": "The remarkably higher performance obtained on the most reliable terms in the data set highlights the importance of having good quality, flexible gold standards to evaluate translation of terminology.", "labels": [], "entities": [{"text": "translation of terminology", "start_pos": 172, "end_pos": 198, "type": "TASK", "confidence": 0.8824512759844462}]}], "tableCaptions": [{"text": " Table 1: Size of the MAGMATic data set: number of sen- tences, number of tokens (i.e. running words) and vocabulary  (i.e. number of distinct word types).", "labels": [], "entities": [{"text": "MAGMATic data set", "start_pos": 22, "end_pos": 39, "type": "DATASET", "confidence": 0.8285215497016907}]}, {"text": " Table 2: Statistics of the terms annotated in the MAGMATic data sets. Terms in the three domain categories -Disciplinary,  Education, Education-equipment (here Equip.) -are further split into the Sure and Possible (Poss.) subcategories. For either  of these subcategories, the number of SWs and MWs, and the total number of terms are provided. In the two bottom rows, the  total number of terms and the vocabulary (i.e. the number of distinct terms) are given for each category.", "labels": [], "entities": [{"text": "MAGMATic data sets", "start_pos": 51, "end_pos": 69, "type": "DATASET", "confidence": 0.9572289784749349}]}, {"text": " Table 3: The 5 most populated and 5 least populated macro- domains covered in the data set and number of terms in each  of them (SW, MW and total).", "labels": [], "entities": []}, {"text": " Table 4: Size of the domain-adaptation data set: number of  sentences, number of tokens (i.e. running words) and vocab- ulary (i.e. number of distinct word types).", "labels": [], "entities": []}, {"text": " Table 6: Perfect THR for GT and the 2 MMT systems. In addition to the overall scores, figures for SWs and MWs are given  separately. Results are provided (i) for the whole data set (All), (ii) split according to the domain category (Disc, Edu, Equip)  and (iii) distinguishing between sure and possible terms.", "labels": [], "entities": [{"text": "THR", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.8491791486740112}]}]}