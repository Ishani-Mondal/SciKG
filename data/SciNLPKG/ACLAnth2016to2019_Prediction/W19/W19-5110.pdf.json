{"title": [{"text": "Without lexicons, multiword expression identification will never fly: A position statement", "labels": [], "entities": [{"text": "multiword expression identification", "start_pos": 18, "end_pos": 53, "type": "TASK", "confidence": 0.7946184277534485}]}], "abstractContent": [{"text": "Because most multiword expressions (MWEs), especially verbal ones, are semantically non-compositional, their automatic identification in running text is a prerequisite for semantically-oriented downstream applications.", "labels": [], "entities": [{"text": "multiword expressions (MWEs)", "start_pos": 13, "end_pos": 41, "type": "TASK", "confidence": 0.7092548251152039}]}, {"text": "However, recent developments, driven notably by the PARSEME shared task on automatic identification of verbal MWEs, show that this task is harder than related tasks, despite recent contributions both in multilingual corpus annotation and in computational models.", "labels": [], "entities": [{"text": "PARSEME shared task on automatic identification of verbal MWEs", "start_pos": 52, "end_pos": 114, "type": "TASK", "confidence": 0.6038711104128096}]}, {"text": "In this paper, we analyse possible reasons for this state of affairs.", "labels": [], "entities": []}, {"text": "They lie in the nature of the MWE phenomenon, as well as in its distributional properties.", "labels": [], "entities": [{"text": "MWE", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.8970283269882202}]}, {"text": "We also offer a comparative analysis of the state-of-the-art systems, which exhibit particularly strong sensitivity to unseen data.", "labels": [], "entities": []}, {"text": "On this basis, we claim that, in order to make strong headway in MWE identification, the community should bend its mind into coupling identification of MWEs with their discovery, via syntactic MWE lexicons.", "labels": [], "entities": [{"text": "MWE identification", "start_pos": 65, "end_pos": 83, "type": "TASK", "confidence": 0.9576534628868103}, {"text": "identification of MWEs", "start_pos": 134, "end_pos": 156, "type": "TASK", "confidence": 0.7564164797465006}]}, {"text": "Such lexicons need not necessarily achieve a linguistically complete modelling of MWEs' behavior, but they should provide minimal morphosyntactic information to cover some potential uses, so as to complement existing MWE-annotated corpora.", "labels": [], "entities": [{"text": "MWEs' behavior", "start_pos": 82, "end_pos": 96, "type": "TASK", "confidence": 0.8959247767925262}]}, {"text": "We define requirements for such a minimal NLP-oriented lexicon, and we propose a roadmap for the MWE community driven by these requirements.", "labels": [], "entities": []}], "introductionContent": [{"text": "Multiword expression (MWE) is a generic term which encompasses a large variety of linguistic objects: compounds (to and fro, crystal clear, a slam dunk 'an easily achieved victory') 1 , verbal idioms (to take pains 'to try hard'), light-verb constructions (to pay a visit ), verb-particle constructions (to takeoff ), institutionalized phrases (traffic light ), multiword terms (neural network ) and multiword named entities (Federal Bureau of Investigation).", "labels": [], "entities": [{"text": "Multiword expression (MWE)", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6989081859588623}, {"text": "verb-particle constructions (to takeoff )", "start_pos": 275, "end_pos": 316, "type": "TASK", "confidence": 0.7152136464913686}]}, {"text": "They all share the characteristic of exhibiting lexical, morphosyntactic, semantic, pragmatic and/or statistical idiosyncrasies (.", "labels": [], "entities": []}, {"text": "Most notably, they usually display non-compositional semantics, i.e. their meaning cannot be deduced from the meanings of their components and from their syntactic structure in away deemed regular for the given language.", "labels": [], "entities": []}, {"text": "Computational methods are, conversely, mostly compositional, therefore they often fail to model and process MWEs appropriately.", "labels": [], "entities": []}, {"text": "Special, MWE-dedicated, treatment can be envisaged, provided that we know which parts of the text are concerned, i.e. we should be able to perform MWE identification.", "labels": [], "entities": [{"text": "MWE-dedicated", "start_pos": 9, "end_pos": 22, "type": "TASK", "confidence": 0.9169039130210876}, {"text": "MWE identification", "start_pos": 147, "end_pos": 165, "type": "TASK", "confidence": 0.98160320520401}]}, {"text": "MWE identification (MWEI) consists in automatically annotating MWEs occurrences in running text.", "labels": [], "entities": [{"text": "MWE identification (MWEI)", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8470042109489441}]}, {"text": "In other words, we need to be able to distinguish MWEs (e.g. take pains) from regular word combinations (e.g. take gloves) in context.", "labels": [], "entities": []}, {"text": "This task proves very challenging for some categories of MWEs, as evidenced by two recent PARSEME shared tasks on automatic identification of verbal.", "labels": [], "entities": [{"text": "MWEs", "start_pos": 57, "end_pos": 61, "type": "TASK", "confidence": 0.9135250449180603}, {"text": "automatic identification of verbal", "start_pos": 114, "end_pos": 148, "type": "TASK", "confidence": 0.6446867883205414}]}, {"text": "We claim that the difficulty of this task lies in the nature of idiosyncrasies that various categories of MWEs exhibit with respect to regular word combinations.", "labels": [], "entities": []}, {"text": "Namely, whereas many constructions (e.g. named entities) have a good generalisation potential for machine learning NLP methods, other MWEs, e.g. verbal ones, are mostly regular at the level of tokens, so the generalisation power of mainstream machine learning is relatively weak for them.", "labels": [], "entities": []}, {"text": "However, they are idiosyncratic at the level of types (sets of surface realizations of the same ex-pression), therefore type-specific information, exploited by MWE discovery methods and encoded in lexicons, should be very helpful for MWEI.", "labels": [], "entities": [{"text": "MWE discovery", "start_pos": 160, "end_pos": 173, "type": "TASK", "confidence": 0.9224940538406372}, {"text": "MWEI", "start_pos": 234, "end_pos": 238, "type": "TASK", "confidence": 0.8680130839347839}]}, {"text": "This paper is a position statement based on an analysis of the state of the art in MWEI.", "labels": [], "entities": [{"text": "MWEI", "start_pos": 83, "end_pos": 87, "type": "DATASET", "confidence": 0.8119542002677917}]}, {"text": "We claim that, in order to make strong headway in MWEI, the community should bend its mind into coupling this task with MWE discovery via syntactic MWE lexicons.", "labels": [], "entities": [{"text": "MWE discovery", "start_pos": 120, "end_pos": 133, "type": "TASK", "confidence": 0.830937534570694}]}, {"text": "Such lexicons need not necessarily achieve a linguistically complete modelling of MWEs' behavior, but they should provide minimal morphosyntactic information to cover some potential uses, so as to complement existing MWE-annotated corpora.", "labels": [], "entities": [{"text": "MWEs' behavior", "start_pos": 82, "end_pos": 96, "type": "TASK", "confidence": 0.8959246575832367}]}, {"text": "This also implies that, in building such lexicons, we can take advantage of the rich body of works dedicated to MWE discovery methods, provided that they are extended, so as to: (i) cover most syntactic types of MWEs, (ii) produce not only lists of newly discovered MWE entries but also their type-specific morphosyntactic properties.", "labels": [], "entities": [{"text": "MWE discovery", "start_pos": 112, "end_pos": 125, "type": "TASK", "confidence": 0.9390675723552704}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "We discuss some linguistic properties of MWEs (Sec. 2) and state-of-the-art results (Sec. 3) relevant to our claims.", "labels": [], "entities": []}, {"text": "We propose a scenario for coupling MWEI with MWE discovery via syntactic MWE lexicons (Sec. 6).", "labels": [], "entities": [{"text": "MWEI", "start_pos": 35, "end_pos": 39, "type": "TASK", "confidence": 0.959798276424408}, {"text": "MWE discovery", "start_pos": 45, "end_pos": 58, "type": "TASK", "confidence": 0.9034276306629181}]}, {"text": "Finally, we conclude by proposing a roadmap for the future efforts of the MWE community (Sec. 7).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Sizes of the corpora (in thousands of anno- tated verbal MWEs), the ratio of unseen verbal MWEs  in the test corpora and the best system performance,  without (non-NN) and with neural networks (NN), in  the PARSEME shared task 1.1 for 6 languages with the  largest corpora.", "labels": [], "entities": [{"text": "PARSEME shared task", "start_pos": 217, "end_pos": 236, "type": "TASK", "confidence": 0.45712799827257794}]}, {"text": " Table 2: PARSEME shared task 1.1 identification scores on seen and unseen data for TRAVERSAL and SHOMA.  Verbal MWE categories are inherently reflexive verbs (IRVs), light-verb constructions (LVCs) and verbal idioms  (VIDs).", "labels": [], "entities": [{"text": "PARSEME", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.5600144267082214}, {"text": "SHOMA", "start_pos": 98, "end_pos": 103, "type": "DATASET", "confidence": 0.7889629006385803}]}, {"text": " Table 3: PARSEME shared task 1.1 identification  scores on identical-to-train and variant-of-train data for  TRAVERSAL and SHOMA.", "labels": [], "entities": [{"text": "PARSEME", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.39361608028411865}, {"text": "TRAVERSAL", "start_pos": 110, "end_pos": 119, "type": "DATASET", "confidence": 0.5678364634513855}, {"text": "SHOMA", "start_pos": 124, "end_pos": 129, "type": "DATASET", "confidence": 0.6611719131469727}]}]}