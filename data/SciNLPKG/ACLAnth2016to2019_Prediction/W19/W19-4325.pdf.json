{"title": [{"text": "On Committee Representations of Adversarial Learning Models for Question-Answer Ranking", "labels": [], "entities": []}], "abstractContent": [{"text": "Adversarial training is a process in Machine Learning that explicitly trains models on ad-versarial inputs (inputs designed to deceive or trick the learning process) in order to make it more robust or accurate.", "labels": [], "entities": []}, {"text": "In this paper we investigate how representing adversarial training models as committees can be used to effectively improve the performance of Question-Answer (QA) Ranking.", "labels": [], "entities": []}, {"text": "We start by empirically probing the effects of adversarial training over multiple QA ranking algorithms, including the state-of-the-art Multihop Attention Network model.", "labels": [], "entities": []}, {"text": "We evaluate these algorithms on several benchmark datasets and observe that, while adversarial training is beneficial to most baseline algorithms, there are cases where it may lead to overfitting and performance degradation.", "labels": [], "entities": []}, {"text": "We investigate the causes of such degradation, and then propose anew representation procedure for this adver-sarial learning problem, based on committee learning, that not only is capable of consistently improving all baseline algorithms, but also outperforms the previous state-of-the-art algorithm by as much as 6% in NDCG (Nor-malized Discounted Cumulative Gain).", "labels": [], "entities": []}], "introductionContent": [{"text": "Question Answer (QA) ranking, or the task of accurately ranking the best answers to an input question, has been a long-standing research pursuit with practical applications in a variety of domains.", "labels": [], "entities": [{"text": "Question Answer (QA) ranking", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8020261178414027}]}, {"text": "Popular examples of such applications are customer support chat-bots, community question answering portals, and digital assistants like Siri or Alexa.", "labels": [], "entities": [{"text": "community question answering portals", "start_pos": 70, "end_pos": 106, "type": "TASK", "confidence": 0.71629349142313}]}, {"text": "Early work on QA ranking relied heavily on linguistic knowledge (such as parse-trees), feature engineering or external resources (.", "labels": [], "entities": [{"text": "QA ranking", "start_pos": 14, "end_pos": 24, "type": "TASK", "confidence": 0.8969002664089203}]}, {"text": "constructed semantic features from WordNet and paired semantically related words based on these features and relations.; used syntactic matching between question and answer parse trees for answer selection.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 35, "end_pos": 42, "type": "DATASET", "confidence": 0.950441837310791}, {"text": "answer selection", "start_pos": 189, "end_pos": 205, "type": "TASK", "confidence": 0.7349761426448822}]}, {"text": "Other proposals used minimal edit sequences between dependency parse trees as a matching score between question and answer.", "labels": [], "entities": []}, {"text": "The majority of the recent developments for QA ranking algorithms are based on deep learning techniques, and fall into two different classes of models: representation-based or interactionbased.", "labels": [], "entities": [{"text": "QA ranking algorithms", "start_pos": 44, "end_pos": 65, "type": "TASK", "confidence": 0.9125518798828125}]}, {"text": "In representation-based models, both question and answer are mapped to the same representation space via network layers with shared weights, and a final relevance or matching score is computed from these representations.", "labels": [], "entities": []}, {"text": "In interactionbased models, the network attempts to capture multiple levels of interaction (or similarity) between question and answer ().", "labels": [], "entities": []}, {"text": "The final relevance/matching score can be computed out of the partial similarities derived from the multiple interactions.", "labels": [], "entities": []}, {"text": "Recent results have indicated that representation-based models, when used with attention layers to focus on relevant parts of the question and answer, tend to outperform interaction-based models).", "labels": [], "entities": []}, {"text": "The recently proposed Multihop Attention Network (MAN) model currently achieves state-ofthe-art performance on ranking tasks by using sequential attention () over multiple attention layers.", "labels": [], "entities": []}, {"text": "This model is discussed in detail in Section 2.2.", "labels": [], "entities": []}, {"text": "Adversarial training and Generative Adversarial Networks (GANs) ( have been successfully applied to Computer Vision ( and Natural Language Processing ( applications, but only sparsely studied in Information Retrieval tasks.", "labels": [], "entities": [{"text": "Information Retrieval tasks", "start_pos": 195, "end_pos": 222, "type": "TASK", "confidence": 0.875086228052775}]}, {"text": "As described by , adversarial training in Information Retrieval can be approached by having a generator model to sample difficult adversarial examples which are passed to a discriminator model that learns to rank on increasingly difficult adversarial examples.", "labels": [], "entities": [{"text": "Information Retrieval", "start_pos": 42, "end_pos": 63, "type": "TASK", "confidence": 0.7996410727500916}]}, {"text": "This adversarial training process in principle can lead to increased robustness and accuracy of the final ranking model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9992965459823608}]}, {"text": "We show that in general most models do benefit from adversarial training, with a clear increase in ranking metrics.", "labels": [], "entities": []}, {"text": "However, we also observed that not all types of models benefit from straightforward adversarial training.", "labels": [], "entities": []}, {"text": "For instance, Multihop Attention Network often displayed worse results with adversarial training.", "labels": [], "entities": [{"text": "Multihop Attention Network", "start_pos": 14, "end_pos": 40, "type": "TASK", "confidence": 0.7448715567588806}]}, {"text": "In such cases, we observed that the model was excessively compensating to the current adversarial training data batch and often forgetting previous batches, thus reducing its performance on test data.", "labels": [], "entities": []}, {"text": "To help address this issue, we propose a novel committee representation to adversarial modeling for QA ranking that can be applied to any underlying ranking algorithm.", "labels": [], "entities": [{"text": "QA ranking", "start_pos": 100, "end_pos": 110, "type": "TASK", "confidence": 0.8573298752307892}]}, {"text": "Not only does it address the observed \"overfitting\" that may occur during adversarial training, but provides an improvement to all baseline QA ranking models we tested.", "labels": [], "entities": []}, {"text": "In particular, we introduce anew state-of-the-art model AdvCom-MAN (Adversarial CommitteeMultihop Attention Network) for QA ranking that displays, to the best of our knowledge, state-ofthe-art results on four different datasets for QA Ranking.", "labels": [], "entities": [{"text": "QA ranking", "start_pos": 121, "end_pos": 131, "type": "TASK", "confidence": 0.7704978585243225}]}], "datasetContent": [{"text": "We use four datasets, belonging to factoid and non factoid categories to evaluate the proposed strategy.", "labels": [], "entities": []}, {"text": "WikiQA is an open domain question answering dataset that was introduced by and has now become a very popular benchmark dataset for QA ranking systems.", "labels": [], "entities": [{"text": "WikiQA", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9119342565536499}]}, {"text": "recently released a large nonfactoid QA dataset for insurance domain -Insurance QA.", "labels": [], "entities": [{"text": "Insurance QA", "start_pos": 70, "end_pos": 82, "type": "DATASET", "confidence": 0.7567618787288666}]}, {"text": "Like Tran and Niederee shows the size of these datasets in terms of QA pairs in the (train/ validation/ test) format.", "labels": [], "entities": []}, {"text": "We evaluate these datasets on different metrics.", "labels": [], "entities": []}, {"text": "For the datasets that have only 1 correct answer in the answer pool associated with every question, we use precision@1 since it the the most suitable metric.", "labels": [], "entities": [{"text": "precision", "start_pos": 107, "end_pos": 116, "type": "METRIC", "confidence": 0.9983265995979309}]}, {"text": "For datasets that have multiple correct answers, more comprehensive metrics such as Mean Reciprocal Rank (MRR) and NDCG@5 have been used that evaluate the model's ability to retrieve not only the most relevant, but all relevant answers.", "labels": [], "entities": [{"text": "Mean Reciprocal Rank (MRR)", "start_pos": 84, "end_pos": 110, "type": "METRIC", "confidence": 0.9737760027249655}, {"text": "NDCG@5", "start_pos": 115, "end_pos": 121, "type": "METRIC", "confidence": 0.9422058860460917}]}], "tableCaptions": [{"text": " Table 1: Experimental results of adversarial learning on different datasets; Models have been evaluated on  NDCG@5 and MRR for WikiQA and FiQA, and on Precision@1 for Insurance QA test sets 1 and 2, and Tax  Domain QA", "labels": [], "entities": [{"text": "NDCG@5", "start_pos": 109, "end_pos": 115, "type": "DATASET", "confidence": 0.7617805202802023}, {"text": "MRR", "start_pos": 120, "end_pos": 123, "type": "METRIC", "confidence": 0.9681508541107178}, {"text": "FiQA", "start_pos": 139, "end_pos": 143, "type": "DATASET", "confidence": 0.848135769367218}, {"text": "Insurance QA test sets 1", "start_pos": 168, "end_pos": 192, "type": "DATASET", "confidence": 0.7401161134243012}, {"text": "Tax  Domain QA", "start_pos": 204, "end_pos": 218, "type": "DATASET", "confidence": 0.7905373771985372}]}]}