{"title": [], "abstractContent": [{"text": "We address the issue of acquiring quality annotations of hedging words and phrases, linguistic phenomenona in which words, sounds, or other constructions are used to express ambiguity or uncertainty.", "labels": [], "entities": []}, {"text": "Due to the limited availability of existing corpora annotated for hedging, linguists and other language scientists have been constrained as to the extent they can study this phenomenon.", "labels": [], "entities": [{"text": "hedging", "start_pos": 66, "end_pos": 73, "type": "TASK", "confidence": 0.969878613948822}]}, {"text": "In this paper , we introduce anew method of acquiring hedging annotations via crowdsourcing, based on reformulating the task of labeling hedges as a simple word sense disambiguation task.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 156, "end_pos": 181, "type": "TASK", "confidence": 0.6230384409427643}]}, {"text": "We also introduce anew hedging corpus we have constructed by applying this method, a collection of forum posts annotated using Amazon Mechanical Turk.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk", "start_pos": 127, "end_pos": 149, "type": "DATASET", "confidence": 0.9151988625526428}]}, {"text": "We found that the crowdsourced judgments we obtained had an inter-annotator agreement of 92.89% (Fleiss' Kappa=0.751) and, when comparing a subset of these annotations to an expert-annotated gold standard, an accuracy of 96.65%.", "labels": [], "entities": [{"text": "Fleiss' Kappa=0.751)", "start_pos": 97, "end_pos": 117, "type": "METRIC", "confidence": 0.9610395908355713}, {"text": "accuracy", "start_pos": 209, "end_pos": 217, "type": "METRIC", "confidence": 0.9995003938674927}]}], "introductionContent": [{"text": "Hedging refers to the use of words, sounds, or constructions that add ambiguity or uncertainty to spoken or written language.", "labels": [], "entities": [{"text": "Hedging refers to the use of words, sounds, or constructions that add ambiguity or uncertainty to spoken or written language", "start_pos": 0, "end_pos": 124, "type": "Description", "confidence": 0.8330667018890381}]}, {"text": "Hedging can indicate a speaker's lack of commitment to what they are saying or an attempt to distance themselves from the proposition they are communicating.", "labels": [], "entities": [{"text": "Hedging", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.9775965213775635}]}, {"text": "Identifying hedging behavior in conversational speech and text can also reveal information about social and power relations between conversants.", "labels": [], "entities": []}, {"text": "Additionally, since hedging can be indicative of alack of speaker commitment, identifying hedging is of interest to the information extraction community, to determine the extent to which statements have been believed by the writer or speaker.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 120, "end_pos": 142, "type": "TASK", "confidence": 0.7188956290483475}]}, {"text": "A major challenge in identifying hedges is that many hedge words and phrases are ambiguous.", "labels": [], "entities": []}, {"text": "For example, in (1a), appear is used as a hedge word, but not in (1b).", "labels": [], "entities": []}, {"text": "The problem appears to be a bug in the software. b. A man suddenly appeared in the doorway.", "labels": [], "entities": []}, {"text": "Currently there are few corpora annotated for hedging, and these are available in a limited number of genres.", "labels": [], "entities": [{"text": "hedging", "start_pos": 46, "end_pos": 53, "type": "TASK", "confidence": 0.9761038422584534}]}, {"text": "In particular, there is currently no corpus of informal language annotated with hedge behavior.", "labels": [], "entities": []}, {"text": "Acquiring expert annotations on text in other genres can be time consuming and maybe cost prohibitive, which is an impediment to exploring how hedging can help with applications based on text in other genres.", "labels": [], "entities": []}, {"text": "To address these issues, we have developed a method of acquiring hedge annotations through crowdsourcing, by framing the hedge identification task as a simple word sense disambiguation problem.", "labels": [], "entities": [{"text": "hedge identification task", "start_pos": 121, "end_pos": 146, "type": "TASK", "confidence": 0.7747865617275238}, {"text": "word sense disambiguation", "start_pos": 159, "end_pos": 184, "type": "TASK", "confidence": 0.6372669835885366}]}, {"text": "In this paper, we describe this method and also our use of Amazon Mechanical Turk to construct a corpus of forum posts labeled with hedge information.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk", "start_pos": 59, "end_pos": 81, "type": "DATASET", "confidence": 0.8841279943784078}]}, {"text": "In Section 2, we discuss related work.", "labels": [], "entities": []}, {"text": "In Section 3, we describe how we constructed our dictionary of hedge terms and created the hedge and non-hedge definitions for each.", "labels": [], "entities": []}, {"text": "Section 4 describes the crowdsourcing task in more detail and discusses the resulting corpus.", "labels": [], "entities": []}, {"text": "We conclude in Section 5.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}