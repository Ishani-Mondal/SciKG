{"title": [{"text": "NUIG at the FinSBD Task: Sentence Boundary Detection for Noisy Financial PDFs in English and French", "labels": [], "entities": [{"text": "NUIG", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8561193943023682}, {"text": "FinSBD", "start_pos": 12, "end_pos": 18, "type": "DATASET", "confidence": 0.9439674019813538}, {"text": "Sentence Boundary Detection", "start_pos": 25, "end_pos": 52, "type": "TASK", "confidence": 0.8941966891288757}]}], "abstractContent": [{"text": "Portable Document Format (PDF) has become the industry-standard document as it is independent of the software, hardware or operating system.", "labels": [], "entities": [{"text": "Portable Document Format (PDF)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7408517996470133}]}, {"text": "Publicly listed companies annually publish a variety of reports and too take advantage of PDF.", "labels": [], "entities": []}, {"text": "This leads to the rise in PDF containing valuable financial information and the demand for approaches able to accurately extract this data.", "labels": [], "entities": []}, {"text": "Analyzing and mining information requires a challenging extraction phase, particularly with respect to document structure.", "labels": [], "entities": [{"text": "Analyzing and mining information", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.760112002491951}]}, {"text": "In this paper, we describe a sentence boundary detection approach capable of extracting complete sentences from unstructured lists of tokens.", "labels": [], "entities": [{"text": "sentence boundary detection", "start_pos": 29, "end_pos": 56, "type": "TASK", "confidence": 0.7428956031799316}, {"text": "extracting complete sentences from unstructured lists of tokens", "start_pos": 77, "end_pos": 140, "type": "TASK", "confidence": 0.7208930924534798}]}, {"text": "Our approach is based on the application of a language model and sequence classifier for both the English and the French language.", "labels": [], "entities": []}, {"text": "The results show a good performance, achieving F1 scores of 0.855 and 0.91, and placed our team in 3 rd and 5 th for the French and English language, respectively.", "labels": [], "entities": [{"text": "F1", "start_pos": 47, "end_pos": 49, "type": "METRIC", "confidence": 0.9997009038925171}]}], "introductionContent": [{"text": "At a time we face an information deluge, automated solutions tailored to different formats are crucial for the data interpretation.", "labels": [], "entities": [{"text": "data interpretation", "start_pos": 111, "end_pos": 130, "type": "TASK", "confidence": 0.7610388994216919}]}, {"text": "In industry, Portable Document Format (PDF) has become the standard document as it is independent of the software, hardware or operating system in use.", "labels": [], "entities": [{"text": "Portable Document Format (PDF)", "start_pos": 13, "end_pos": 43, "type": "TASK", "confidence": 0.6966568728288015}]}, {"text": "Publicly listed companies annually publish a variety of reports and too take advantage of PDF.", "labels": [], "entities": []}, {"text": "In addition to factual information and numerical data, such documents provide deeper knowledge which is conveyed through wording and linguistic structure.", "labels": [], "entities": []}, {"text": "With the rise in PDF containing valuable financial information, the demand for approaches able to accurately extract this data is also growing.", "labels": [], "entities": []}, {"text": "However, analyzing and mining information requires a challenging extraction phase reliant on the document structure.", "labels": [], "entities": []}, {"text": "Sentence boundary detection is vital to understand the document structure.", "labels": [], "entities": [{"text": "Sentence boundary detection", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.9204657872517904}]}, {"text": "Hence, this is the focus of the FinSB task and this paper.", "labels": [], "entities": []}, {"text": "Although not considered one of the grand challenges in natural language processing (NLP), sentence boundary detec- * Contact Author tion remains challenging particularly due to textual variation.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 55, "end_pos": 88, "type": "TASK", "confidence": 0.7626910706361135}]}, {"text": "Sentence boundary detection (SBD) aims at determining where a sentence begins and ends, in detail, it is the task of binary classifying text into boundary point or non-boundary point after each character.", "labels": [], "entities": [{"text": "Sentence boundary detection (SBD)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8919016619523367}]}, {"text": "SBD plays an important role in structuring textual data.", "labels": [], "entities": [{"text": "SBD", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8319612741470337}]}, {"text": "For example, machine translation needs correct sentence segmentation as it heavily impacts the translation performance, and speech recognition requires segmented sentences for the processing in downstream tasks as well as to improve human readability.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.8107312619686127}, {"text": "sentence segmentation", "start_pos": 47, "end_pos": 68, "type": "TASK", "confidence": 0.7839386165142059}, {"text": "speech recognition", "start_pos": 124, "end_pos": 142, "type": "TASK", "confidence": 0.7803728580474854}]}, {"text": "SBD is paramount for text extraction in PDF since a major \"problem in the conversion of PDF documents is the detection of the boundaries of common textual units such as paragraphs, sentences and words\".", "labels": [], "entities": [{"text": "SBD", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.7655475735664368}, {"text": "text extraction", "start_pos": 21, "end_pos": 36, "type": "TASK", "confidence": 0.7621135711669922}]}, {"text": "Although SBD is being researched for almost 20 years, the majority of works focus on structured texts (e.g. WSJ corpus, Brown corpus) and little attention is given to SBD in PDFs.", "labels": [], "entities": [{"text": "SBD", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.9688723087310791}, {"text": "WSJ corpus", "start_pos": 108, "end_pos": 118, "type": "DATASET", "confidence": 0.9578348100185394}, {"text": "Brown corpus", "start_pos": 120, "end_pos": 132, "type": "DATASET", "confidence": 0.9615186154842377}, {"text": "SBD", "start_pos": 167, "end_pos": 170, "type": "TASK", "confidence": 0.9604107737541199}]}, {"text": "In particular, research dealing with sentence boundary detection in financial PDFs is non-existing, to the best of our knowledge.", "labels": [], "entities": [{"text": "sentence boundary detection in financial PDFs", "start_pos": 37, "end_pos": 82, "type": "TASK", "confidence": 0.7710740069548289}]}, {"text": "The only related work found was the paper by Loughran and McDonald which deal with the readability of 10-k reports, however, the authors do not target sentence boundaries in their FOG index.", "labels": [], "entities": [{"text": "FOG", "start_pos": 180, "end_pos": 183, "type": "METRIC", "confidence": 0.9795485734939575}]}, {"text": "In this paper, we define SBD as the ternary classification of a token to identify the sentence beginning, sentence end, and other token.", "labels": [], "entities": []}, {"text": "Below, we outline that other token variations occur in the form of in-sentence-token or out-of-sentence-token.", "labels": [], "entities": []}, {"text": "Thus, our classification goes a step further and does not only aim at boundary points (i.e. sentence beginning and end) but is also able to determine a sentence within a list of tokens from its beginning to its end.", "labels": [], "entities": []}, {"text": "This becomes particularly important for cases in which a sentence does not follow another sentence (e.g. a headline followed by a sentence).", "labels": [], "entities": []}, {"text": "The paper is organized as follows: First, we present work related to this paper; second, we define the research problem, third, we explain our methodology to deal with sentence boundary detection for domain-specific texts in the English and French language; fourth, we present the results of the methodology application and analyze these; lastly, we conclude this work with a methodology and findings summary.: An illustration of our language modelling architecture.", "labels": [], "entities": [{"text": "sentence boundary detection for domain-specific texts in the English and French language", "start_pos": 168, "end_pos": 256, "type": "TASK", "confidence": 0.836339625219504}]}, {"text": "A bidirectional recurrent neural network, forward in red and backward in green, with LSTM mechanism retrieves the contextual embedding of each word at character-level.", "labels": [], "entities": []}, {"text": "The produced embedding is then merged with an external embedding to create the stacked embeddings.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the language model quality, we employed the sentence perplexity-based approach described in section 4.1.", "labels": [], "entities": []}, {"text": "Although the sentence perplexity is not used directly to refine the sequence classifiers output, it influences the quality of the stacked embeddings which we employ to train the sequence classifiers.", "labels": [], "entities": []}, {"text": "Thus, a good quality language model is imperative for the classification output.", "labels": [], "entities": []}, {"text": "The character-level forward language model was tested on 117 random sentences extracted from an additional annual report.", "labels": [], "entities": []}, {"text": "The model correctly identified 102 as original sentences and failed to detect 15; three sentence pair examples are shown in table 2, the top sentence is the original/correct version.", "labels": [], "entities": []}, {"text": "A lower sentence perplexity score indicates a higher probability for the sentence to appear in this form.", "labels": [], "entities": []}, {"text": "Considering these examples, in the first pair, we replaced since with from which rendered the sentence grammatically incorrect.", "labels": [], "entities": []}, {"text": "The difficulty in the second example consists in knowing the structure of French company names, specifically that SA stands for Soci\u00e9t\u00e9 anonyme, a company type; with the removal of GET the model failed to capture that this string/part of the company name is missing.", "labels": [], "entities": [{"text": "GET", "start_pos": 181, "end_pos": 184, "type": "DATASET", "confidence": 0.4800741374492645}]}, {"text": "However, we need to keep in mind that the English training data did not contain reports of French companies, thus, it is unlikely our language model has come across such names before.", "labels": [], "entities": [{"text": "English training data", "start_pos": 42, "end_pos": 63, "type": "DATASET", "confidence": 0.6526836554209391}]}, {"text": "In the third example, we removed the company name SNCF.", "labels": [], "entities": []}, {"text": "Although this mistake seems obvious to a human, the language model did not detect it.", "labels": [], "entities": []}, {"text": "Looking closely at the wrong sentence, one can also understand it as \"In cooperation with the Europorte 2, the rail [...]\" and, hence, only see a misplaced comma.", "labels": [], "entities": [{"text": "Europorte 2", "start_pos": 94, "end_pos": 105, "type": "DATASET", "confidence": 0.9628323614597321}]}], "tableCaptions": [{"text": " Table 1: Parameter selection values for the language models and the  sequence classifier training.", "labels": [], "entities": []}, {"text": " Table 3: sequence classifier evaluation results.The BS and ES tag  represent begin-sentence and end-sentence.", "labels": [], "entities": [{"text": "BS", "start_pos": 53, "end_pos": 55, "type": "METRIC", "confidence": 0.8274650573730469}, {"text": "ES", "start_pos": 60, "end_pos": 62, "type": "METRIC", "confidence": 0.8901923298835754}]}]}