{"title": [{"text": "The IIIT-H Gujarati-English Machine Translation system for WMT19", "labels": [], "entities": [{"text": "IIIT-H Gujarati-English Machine Translation", "start_pos": 4, "end_pos": 47, "type": "TASK", "confidence": 0.5682216733694077}, {"text": "WMT19", "start_pos": 59, "end_pos": 64, "type": "TASK", "confidence": 0.7869633436203003}]}], "abstractContent": [{"text": "This paper describes the Neural Machine Translation system of IIIT-Hyderabad for the Gujarati\u2192English news translation shared task of WMT19.", "labels": [], "entities": [{"text": "Neural Machine Translation", "start_pos": 25, "end_pos": 51, "type": "TASK", "confidence": 0.7197082042694092}, {"text": "IIIT-Hyderabad", "start_pos": 62, "end_pos": 76, "type": "DATASET", "confidence": 0.8776895999908447}, {"text": "Gujarati\u2192English news translation shared task", "start_pos": 85, "end_pos": 130, "type": "TASK", "confidence": 0.6882229447364807}, {"text": "WMT19", "start_pos": 134, "end_pos": 139, "type": "DATASET", "confidence": 0.8495148420333862}]}, {"text": "Our system is based on encoder-decoder framework with attention mechanism.", "labels": [], "entities": []}, {"text": "We experimented with Multilingual Neural MT models.", "labels": [], "entities": [{"text": "Multilingual Neural MT", "start_pos": 21, "end_pos": 43, "type": "TASK", "confidence": 0.4692117174466451}]}, {"text": "Our experiments show that Multilingual Neural Machine Translation leveraging parallel data from related language pairs helps in significant BLEU improvements upto 11.5, for low resource language pairs like Gujarati-English.", "labels": [], "entities": [{"text": "Multilingual Neural Machine Translation", "start_pos": 26, "end_pos": 65, "type": "TASK", "confidence": 0.6642476841807365}, {"text": "BLEU", "start_pos": 140, "end_pos": 144, "type": "METRIC", "confidence": 0.9979890584945679}]}], "introductionContent": [{"text": "Neural Machine Translation () has been receiving considerable attention in the recent years, given its superior performance without the demand of heavily hand crafted engineering efforts.", "labels": [], "entities": [{"text": "Neural Machine Translation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7868897914886475}]}, {"text": "NMT often outperforms Statistical Machine Translation (SMT) techniques but it still struggles if the parallel data is insufficient like in the case of Indian languages.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 22, "end_pos": 59, "type": "TASK", "confidence": 0.8381779591242472}]}, {"text": "The bulk of research on low resource NMT has focused on exploiting monolingual data or parallel data from other language pairs.", "labels": [], "entities": []}, {"text": "Some recent methods to improve NMT models that exploit monolingual data ranges from back-translation), dual NMT ( to Unsupervised MT models (.", "labels": [], "entities": []}, {"text": "Transfer Learning is also a promising approach for low resource NMT which exploits parallel data from other language pairs (.", "labels": [], "entities": [{"text": "Transfer Learning", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9552096724510193}]}, {"text": "Typically it is achieved by training a parent model in a high resource language pair, then using some of the trained weights as the initialization fora child model and further train it on the low-resource language pair.", "labels": [], "entities": []}, {"text": "Other promising approach for improving translation performance for low resource languages is Multilingual Neural Machine Translation.", "labels": [], "entities": [{"text": "translation", "start_pos": 39, "end_pos": 50, "type": "TASK", "confidence": 0.9637706875801086}, {"text": "Multilingual Neural Machine Translation", "start_pos": 93, "end_pos": 132, "type": "TASK", "confidence": 0.7128147035837173}]}, {"text": "It has been shown that exploiting data from other language pairs & joint training helps in improving the translation performance of NMT models.", "labels": [], "entities": [{"text": "translation", "start_pos": 105, "end_pos": 116, "type": "TASK", "confidence": 0.9690463542938232}]}, {"text": "(. This paper describes the NMT system of IIIT-H for WMT19 evaluation.", "labels": [], "entities": [{"text": "WMT19 evaluation", "start_pos": 53, "end_pos": 69, "type": "TASK", "confidence": 0.8939627707004547}]}, {"text": "We participated in the Gujarati\u2192English news translation task.", "labels": [], "entities": [{"text": "Gujarati\u2192English news translation task", "start_pos": 23, "end_pos": 61, "type": "TASK", "confidence": 0.7198525468508402}]}, {"text": "We used an attention-based encoder-decoder model as our baseline system and used Byte Pair Encoding (BPE) to enable open vocabulary translation.", "labels": [], "entities": [{"text": "open vocabulary translation", "start_pos": 116, "end_pos": 143, "type": "TASK", "confidence": 0.616945892572403}]}, {"text": "We then leverage Hindi-English parallel corpus in a multilingual setting so as to improve our baseline system.", "labels": [], "entities": []}, {"text": "We basically combined Hindi-English and Gujarati-English parallel corpus and use it as our training corpus.", "labels": [], "entities": []}, {"text": "Our multilingual system is similiar to but we don't use any artificial token at the start of source sentences to indicate the target language.", "labels": [], "entities": []}, {"text": "The reason is trivial, that is we have only English as our target language.", "labels": [], "entities": []}, {"text": "We also provide results of our experiments conducted post WMT19 shared task involving Transformer models.", "labels": [], "entities": [{"text": "WMT19 shared task", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.5745141307512919}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Statistics of our processed parallel data.", "labels": [], "entities": []}, {"text": " Table 3: Our Transformer models vs other systems at  WMT19", "labels": [], "entities": [{"text": "WMT19", "start_pos": 54, "end_pos": 59, "type": "DATASET", "confidence": 0.8117490410804749}]}]}