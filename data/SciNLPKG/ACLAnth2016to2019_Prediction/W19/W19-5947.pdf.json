{"title": [{"text": "Multi-Task Learning of System Dialogue Act Selection for Supervised Pretraining of Goal-Oriented Dialogue Policies", "labels": [], "entities": [{"text": "System Dialogue Act Selection", "start_pos": 23, "end_pos": 52, "type": "TASK", "confidence": 0.779678501188755}]}], "abstractContent": [{"text": "This paper describes the use of Multi-Task Neural Networks (NNs) for system dialogue act selection.", "labels": [], "entities": [{"text": "system dialogue act selection", "start_pos": 69, "end_pos": 98, "type": "TASK", "confidence": 0.7977528721094131}]}, {"text": "These models leverage the representations learned by the Natural Language Understanding (NLU) unit to enable robust initialization/bootstrapping of dialogue policies from medium sized initial data sets.", "labels": [], "entities": []}, {"text": "We evaluate the models on two goal-oriented dialogue corpora in the travel booking domain.", "labels": [], "entities": []}, {"text": "Results show the proposed models improve over models trained without knowledge of NLU tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "To be successful, goal-oriented dialogue systems must accurately determine the intent(s) of a user, identify and understand the relevant information they have provided, and based on that information, select the appropriate response at each turn in the conversation.", "labels": [], "entities": []}, {"text": "One way to model conversation is as a partially observable Markov decision process.", "labels": [], "entities": []}, {"text": "In this framework system response generation is modeled as a stochastic policy, and research into statistically optimizing dialogue policies with Reinforcement Learning (RL) is an active area of research.", "labels": [], "entities": [{"text": "system response generation", "start_pos": 18, "end_pos": 44, "type": "TASK", "confidence": 0.642841766277949}]}, {"text": "However, learning optimal dialogue policies with RL can be challenging since large state and action spaces require large amounts of training data to densely sample the space (.", "labels": [], "entities": []}, {"text": "Additionally, networks trained with RL learn in a trial-anderror process, guided by a potentially delayed reward function.", "labels": [], "entities": []}, {"text": "This exploration process can lead to poor performance in the early training stages, which in turn can lead to a negative user experience ( . To address these issues supervised learning has been used for pre-training of dialogue policies, however the previous approaches only considered one aspect of dialogue during training.", "labels": [], "entities": []}, {"text": "describe discourse structure as a composite of multiple aspects that interact and co-constrain one other.", "labels": [], "entities": []}, {"text": "This structure determines the meaning of a discourse and provides a framework for processing dialogue.", "labels": [], "entities": []}, {"text": "The question then arises whether it would be beneficial to view dialogue policy training as a multitask learning (MTL) problem.", "labels": [], "entities": [{"text": "dialogue policy training", "start_pos": 64, "end_pos": 88, "type": "TASK", "confidence": 0.8066635926564535}]}, {"text": "MTL is an active area of research and has been shown to improve performance on a number Natural Language Processing (NLP) tasks.", "labels": [], "entities": [{"text": "MTL", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8290944695472717}]}, {"text": "In this work we propose a method to use the training signals of related tasks during supervised pre-training of system dialogue act selection as part of dialogue policy initialization.", "labels": [], "entities": [{"text": "system dialogue act selection", "start_pos": 112, "end_pos": 141, "type": "TASK", "confidence": 0.6149013265967369}, {"text": "dialogue policy initialization", "start_pos": 153, "end_pos": 183, "type": "TASK", "confidence": 0.6894164482752482}]}, {"text": "We also experiment with multiple architectures across two data sets and evaluate against two basline architectures.", "labels": [], "entities": []}, {"text": "Specifically, we use slot-filling and user-intent classification as auxiliary tasks for the primary task of system dialogue act selection.", "labels": [], "entities": [{"text": "user-intent classification", "start_pos": 38, "end_pos": 64, "type": "TASK", "confidence": 0.7335229516029358}, {"text": "system dialogue act selection", "start_pos": 108, "end_pos": 137, "type": "TASK", "confidence": 0.8208726346492767}]}, {"text": "For many corpus trained dialogue systems slot-filling and user-intent classification are trained independently, separate from the dialogue manager.", "labels": [], "entities": [{"text": "user-intent classification", "start_pos": 58, "end_pos": 84, "type": "TASK", "confidence": 0.7499583661556244}]}, {"text": "We hypothesize that the features learned when training neural models for these tasks are also informative for the initialization of a robust dialogue policy network.", "labels": [], "entities": []}, {"text": "In MTL there can bean added cost of collecting labels for auxiliary tasks, but in the scenario in this paper the labels for user-intent and slot-filling that are needed to develop a complete dialogue system already exist; the framework we propose uses these labels as additional information to initialize the dialogue manager.", "labels": [], "entities": []}, {"text": "The next sections describe related work in MTL, including MTL for goal-oriented dialogue systems, the corpora used in our experiments, the architecture of: The number of slot types, user speech acts, and system dialogue acts for each corpus, as well as the average length of the user input utterances.", "labels": [], "entities": [{"text": "MTL", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.9089758396148682}]}, {"text": "the neural models we tested, and the results of the evaluation.", "labels": [], "entities": []}], "datasetContent": [{"text": "We completed three sets of experiments: two baseline experiments and a final experiment with the multi-task architecture.", "labels": [], "entities": []}, {"text": "Each of these experiments included three tasks: slot-filling, framed as sequence prediction, user-intent classification, and system dialogue act selection.", "labels": [], "entities": [{"text": "sequence prediction", "start_pos": 72, "end_pos": 91, "type": "TASK", "confidence": 0.6570954918861389}, {"text": "user-intent classification", "start_pos": 93, "end_pos": 119, "type": "TASK", "confidence": 0.8194545805454254}, {"text": "system dialogue act selection", "start_pos": 125, "end_pos": 154, "type": "TASK", "confidence": 0.7929809987545013}]}, {"text": "In the first baseline experiment the models described in  were extended to new corpora and new tasks using the software released by the authors.", "labels": [], "entities": []}, {"text": "In the second baseline experiment we trained single-task models for each of the three tasks individually, on each corpus.", "labels": [], "entities": []}, {"text": "Following the methodology suggested in Caruana (1998), these models were tuned for each corpus and architecture.", "labels": [], "entities": []}, {"text": "The Maluuba Frames and DARPA COM-MUNICATOR Corpora were used in baseline and multi-task experiments; the ATIS corpus does not contain annotations for system dialogue act selection and was therefore only used in the baseline experiments.", "labels": [], "entities": [{"text": "DARPA COM-MUNICATOR Corpora", "start_pos": 23, "end_pos": 50, "type": "DATASET", "confidence": 0.691626230875651}, {"text": "ATIS corpus", "start_pos": 105, "end_pos": 116, "type": "DATASET", "confidence": 0.8753142952919006}, {"text": "system dialogue act selection", "start_pos": 150, "end_pos": 179, "type": "TASK", "confidence": 0.7510253041982651}]}, {"text": "In this framework the input and output utterances become:  The majority of the multi-task models, as well as the Baseline B models on the Frames, BBN, and SRI corpora, achieved a higher F-measure than the Baseline A models.", "labels": [], "entities": [{"text": "BBN", "start_pos": 146, "end_pos": 149, "type": "DATASET", "confidence": 0.46530547738075256}, {"text": "SRI corpora", "start_pos": 155, "end_pos": 166, "type": "DATASET", "confidence": 0.7741606533527374}, {"text": "F-measure", "start_pos": 186, "end_pos": 195, "type": "METRIC", "confidence": 0.9988988637924194}]}, {"text": "(We did not test for statistical significance between the MTL models and the Baseline A).", "labels": [], "entities": []}, {"text": "The multi-task CNN models showed statistically significant improvement on three data sets and were faster to train than the BLSTM models, even when larger.", "labels": [], "entities": [{"text": "BLSTM", "start_pos": 124, "end_pos": 129, "type": "DATASET", "confidence": 0.7199679017066956}]}, {"text": "Half of the BLSTM models achieved significant improvement on the Frames corpus, but improvement was more sporadic on the COMMUNICATOR corpus.", "labels": [], "entities": [{"text": "BLSTM", "start_pos": 12, "end_pos": 17, "type": "DATASET", "confidence": 0.4997917115688324}, {"text": "Frames corpus", "start_pos": 65, "end_pos": 78, "type": "DATASET", "confidence": 0.9719962179660797}, {"text": "COMMUNICATOR corpus", "start_pos": 121, "end_pos": 140, "type": "DATASET", "confidence": 0.913476973772049}]}, {"text": "In the Frames corpus most input utterances are much longer since the user provides significant context at each turn.", "labels": [], "entities": [{"text": "Frames corpus", "start_pos": 7, "end_pos": 20, "type": "DATASET", "confidence": 0.9104894697666168}]}, {"text": "In the COMMUNICATOR corpus after the initial request most user utterances are limited to one or two word responses to questions presented by the system.", "labels": [], "entities": [{"text": "COMMUNICATOR corpus", "start_pos": 7, "end_pos": 26, "type": "DATASET", "confidence": 0.6928492337465286}]}, {"text": "This creates a dialogue that looks more like a system initiative dialogue, as compared to the more unconstrained Frames corpus.", "labels": [], "entities": [{"text": "Frames corpus", "start_pos": 113, "end_pos": 126, "type": "DATASET", "confidence": 0.9246906638145447}]}, {"text": "The CNN+BLSTM network improved performance on three data sets and is the largest of the proposed models.", "labels": [], "entities": [{"text": "CNN+BLSTM network", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.8307858258485794}]}], "tableCaptions": [{"text": " Table 1: The number of slot types, user speech acts, and system dialogue acts for each corpus, as well as the  average length of the user input utterances.", "labels": [], "entities": []}, {"text": " Table 3: The best F-measure achieved for each multi-task model on the system action classification task. Results  in bold indicate an improvement over the associated single-task baseline (BLSTM or CNN baseline). An asterisk  indicates a statistically significant improvement over the respective baseline.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9965128302574158}, {"text": "system action classification task", "start_pos": 71, "end_pos": 104, "type": "TASK", "confidence": 0.7508431226015091}, {"text": "BLSTM or CNN baseline", "start_pos": 189, "end_pos": 210, "type": "DATASET", "confidence": 0.6179755106568336}]}]}