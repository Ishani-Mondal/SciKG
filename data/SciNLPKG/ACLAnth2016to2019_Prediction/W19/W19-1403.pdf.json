{"title": [{"text": "Joint Approach to Deromanization of Code-mixed Texts", "labels": [], "entities": [{"text": "Deromanization of Code-mixed Texts", "start_pos": 18, "end_pos": 52, "type": "TASK", "confidence": 0.8481268733739853}]}], "abstractContent": [{"text": "The conversion of romanized texts back to the native scripts is a challenging task because of the inconsistent romanization conventions and non-standard language use.", "labels": [], "entities": [{"text": "conversion of romanized texts", "start_pos": 4, "end_pos": 33, "type": "TASK", "confidence": 0.8341808319091797}]}, {"text": "This problem is compounded by code-mixing, i.e., using words from more than one language within the same discourse.", "labels": [], "entities": []}, {"text": "In this paper, we propose a novel approach for handling these two problems together in a single system.", "labels": [], "entities": []}, {"text": "Our approach combines three components: language identification , back-transliteration, and sequence prediction.", "labels": [], "entities": [{"text": "language identification", "start_pos": 40, "end_pos": 63, "type": "TASK", "confidence": 0.8006038069725037}, {"text": "sequence prediction", "start_pos": 92, "end_pos": 111, "type": "TASK", "confidence": 0.80699223279953}]}, {"text": "The results of our experiments on Bengali and Hindi datasets establish the state of the art for the task of deromanization of code-mixed texts.", "labels": [], "entities": []}], "introductionContent": [{"text": "Ad-hoc romanization is the practice of using the Roman script to express messages in languages that have their own native scripts ().", "labels": [], "entities": [{"text": "Ad-hoc romanization", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7529042065143585}]}, {"text": "The phenomenon is observed in informal settings, such as social media, and is due to either unavailability of a native-script keyboard, or the writer's preference for using a Roman keyboard.", "labels": [], "entities": []}, {"text": "Rather than following any predefined inter-script mappings, romanized texts typically constitute an idiosyncratic mixture of phonetic spelling, ad-hoc transliterations, and abbreviations.", "labels": [], "entities": []}, {"text": "A great deal of information is lost in the romanization process due to the difficulty of representing native phonological distinctions in the Roman script.", "labels": [], "entities": []}, {"text": "This makes deromanization of such messages a challenging task (.", "labels": [], "entities": []}, {"text": "Another phenomenon that further complicates the task of deromanization is code-mixing, which occurs when words from another language (typically English) are introduced in the messages (e.g., the word decent in).", "labels": [], "entities": []}, {"text": "Code-mixing is particularly common in multi-lingual areas such as South Asia ( ).", "labels": [], "entities": []}, {"text": "In many cases, the English words have no transliterated equivalents in the native language and script.", "labels": [], "entities": []}, {"text": "In this paper, we address the task of deromanization of code-mixed texts.", "labels": [], "entities": []}, {"text": "This normalization process is necessary in order to take advantage of NLP resources and tools that are developed and trained on text corpora written in the standard form of the language, which in turn can facilitate tasks such as sentiment analysis and opinion mining in the social media.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 230, "end_pos": 248, "type": "TASK", "confidence": 0.960296630859375}, {"text": "opinion mining", "start_pos": 253, "end_pos": 267, "type": "TASK", "confidence": 0.7544485032558441}]}, {"text": "In addition, web-search queries are often expressed in a romanized form by speakers of languages that use non-Latin scripts, such as Arabic,.", "labels": [], "entities": []}, {"text": "The task of deromanization of code-mixed texts is related to the study of language variation.", "labels": [], "entities": []}, {"text": "Adhoc romanization represents a language variety, which resembles the usage of multiple scripts in some languages (e.g., Tajik).", "labels": [], "entities": [{"text": "Adhoc romanization", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7401552200317383}]}, {"text": "Code-mixing can also be considered a language variety, which exhibits similarities to dialects whose lexicons are strongly influenced by a different language (e.g., Upper Silesian).", "labels": [], "entities": []}, {"text": "The individual sub-tasks of deromanization of code-mixed texts have been investigated in prior work, but we are the first to incorporate them in a single system.", "labels": [], "entities": []}, {"text": "Workshops and shared tasks have been devoted to code-mixing, including the prob-lem of word-level language identification).", "labels": [], "entities": [{"text": "word-level language identification", "start_pos": 87, "end_pos": 121, "type": "TASK", "confidence": 0.607276995976766}]}, {"text": "Transliteration and back-transliteration is a wellunderstood problem, which also has been the topic of several shared tasks.", "labels": [], "entities": []}, {"text": "However, unlike romanization, transliteration is focused on names rather than dictionary words, and usually performed without considering the context of the word in a sentence.", "labels": [], "entities": []}, {"text": "Finally, a number of papers address the deromanization of social media contents and informal texts, but propose no effective way of handling the codemixing issue).", "labels": [], "entities": []}, {"text": "We show that this limitation leads to sub-optimal performance on deromanization.", "labels": [], "entities": []}, {"text": "In this paper, we propose a novel approach for tackling the problem of romanization and codemixing together in a single system.", "labels": [], "entities": []}, {"text": "Since sufficiently large annotated data sets for training an end-to-end approach are not available, we combine supervised models for the three main components of the complete task: (a) word-level language identification, (b) back-transliteration, and (c) word sequence prediction.", "labels": [], "entities": [{"text": "word-level language identification", "start_pos": 185, "end_pos": 219, "type": "TASK", "confidence": 0.6546795467535654}, {"text": "word sequence prediction", "start_pos": 255, "end_pos": 279, "type": "TASK", "confidence": 0.7401765187581381}]}, {"text": "These modules involve several diverse techniques, including neural networks, character-level and word-level language models, discriminative transduction, joint n-grams, and HMMs.", "labels": [], "entities": []}, {"text": "We perform experiments on three datasets that represent two languages, including anew dataset that we have collected and annotated ourselves.", "labels": [], "entities": []}, {"text": "The results show that our system is substantially more accurate than Google Translate, which is the only publicly available tool that can be applied to this task.", "labels": [], "entities": []}, {"text": "Our main contributions are: (1) a novel approach to deromanization of code-mixed texts through the combination of word-level language identification, back-transliteration, and sequence prediction; (2) a system that establishes the state of the art on the task; and (3) an annotated dataset of romanized Bengali messages.", "labels": [], "entities": [{"text": "word-level language identification", "start_pos": 114, "end_pos": 148, "type": "TASK", "confidence": 0.6004003385702769}, {"text": "sequence prediction", "start_pos": 176, "end_pos": 195, "type": "TASK", "confidence": 0.6864351034164429}]}, {"text": "We make our code and data publicly available.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we present the results for each of the three tasks.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: The language balance in the code-mixed  datasets (% of word tokens).", "labels": [], "entities": []}, {"text": " Table 3: Language identification accuracy (in %).", "labels": [], "entities": [{"text": "Language identification", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.667930468916893}, {"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9766799211502075}]}, {"text": " Table 4: Impact of manually created transliteration data  on the Bengali development set (in % word accuracy).", "labels": [], "entities": [{"text": "Bengali development set", "start_pos": 66, "end_pos": 89, "type": "DATASET", "confidence": 0.6120201249917349}, {"text": "accuracy", "start_pos": 101, "end_pos": 109, "type": "METRIC", "confidence": 0.8529777526855469}]}, {"text": " Table 5: Back-transliteration accuracy on the test sets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9620890021324158}]}, {"text": " Table 6: The results on deromanization of code-mixed  texts (in % word accuracy).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.8838628530502319}]}]}