{"title": [{"text": "CUNI System for the WMT19 Robustness Task", "labels": [], "entities": [{"text": "WMT19 Robustness", "start_pos": 20, "end_pos": 36, "type": "TASK", "confidence": 0.49048054218292236}]}], "abstractContent": [{"text": "We present our submission to the WMT19 Ro-bustness Task.", "labels": [], "entities": [{"text": "WMT19 Ro-bustness Task", "start_pos": 33, "end_pos": 55, "type": "TASK", "confidence": 0.5146984855333964}]}, {"text": "Our baseline system is the Charles University (CUNI) Transformer system trained for the WMT18 shared task on News Translation.", "labels": [], "entities": [{"text": "Charles University (CUNI) Transformer", "start_pos": 27, "end_pos": 64, "type": "DATASET", "confidence": 0.9415210882822672}, {"text": "WMT18 shared task on News Translation", "start_pos": 88, "end_pos": 125, "type": "TASK", "confidence": 0.571182131767273}]}, {"text": "Quantitative results show that the CUNI Transformer system is already far more robust to noisy input than the LSTM-based baseline provided by the task organizers.", "labels": [], "entities": []}, {"text": "We further improved the performance of our model by fine-tuning on the in-domain noisy data without influencing the translation quality on the news domain.", "labels": [], "entities": []}], "introductionContent": [{"text": "Machine translation (MT) is usually evaluated on text coming from news written by a professional journalist.", "labels": [], "entities": [{"text": "Machine translation (MT)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8942263722419739}]}, {"text": "However, in practice, MT should cover more domains, including informal and not carefully spelled text that we encounter in the online world.", "labels": [], "entities": [{"text": "MT", "start_pos": 22, "end_pos": 24, "type": "TASK", "confidence": 0.9862176775932312}]}, {"text": "Although machine translation quality increased dramatically in recent years ( , several studies ( has shown that the current systems are sensitive to the source-side noise.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 9, "end_pos": 28, "type": "TASK", "confidence": 0.8204727470874786}]}, {"text": "It is also an issue that was not studied intensively in the past because neural systems appear to be more noise-sensitive than the previously used statistical systems.", "labels": [], "entities": []}, {"text": "Recently, Michel and Neubig (2018) prepared a dataset called Machine Translation of Noisy Text (MTNT) that focuses exclusively on translating texts from the online environment.", "labels": [], "entities": [{"text": "Machine Translation of Noisy Text (MTNT)", "start_pos": 61, "end_pos": 101, "type": "TASK", "confidence": 0.8520821519196033}]}, {"text": "This dataset is used for the WMT19 Robustness Task.", "labels": [], "entities": [{"text": "WMT19 Robustness Task", "start_pos": 29, "end_pos": 50, "type": "TASK", "confidence": 0.5180587470531464}]}], "datasetContent": [{"text": "The MTNT dataset consists of sentences collected from Reddit 1 posts.", "labels": [], "entities": [{"text": "MTNT dataset", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.8489625155925751}, {"text": "Reddit 1 posts", "start_pos": 54, "end_pos": 68, "type": "DATASET", "confidence": 0.8851060668627421}]}, {"text": "Unlike the standard corpora 1 http://www.reddit.com which (in a major part) consist of formal language, often written by professionals, this dataset contains a substantial number of spelling errors, grammatical errors, emoticons, and profanities.", "labels": [], "entities": []}, {"text": "Manual translations are provided with the source sentences crawled from the web.", "labels": [], "entities": []}, {"text": "The translators were asked to keep all the noise-related properties of the source sentence.", "labels": [], "entities": []}, {"text": "There are two language pairs included in the dataset: English-French and English-Japanese in both directions.", "labels": [], "entities": []}, {"text": "The dataset comes in three splits, for training, validation, and testing.", "labels": [], "entities": [{"text": "validation", "start_pos": 49, "end_pos": 59, "type": "TASK", "confidence": 0.9585797190666199}]}, {"text": "The EnglishFrench part consists of 36k examples in the training split, 852 examples for validation, 1020 examples for testing in the En\u2192Fr direction, and 19k, 886, and 1022 examples for training, validation, and testing respectively in the opposite direction.", "labels": [], "entities": [{"text": "EnglishFrench part", "start_pos": 4, "end_pos": 22, "type": "DATASET", "confidence": 0.9504827558994293}]}, {"text": "For English-Japanese, the dataset is substantially smaller, with around 6k training examples in both directions.", "labels": [], "entities": []}, {"text": "In our experiments, we focus solely on the translation between French and English.", "labels": [], "entities": [{"text": "translation between French and English", "start_pos": 43, "end_pos": 81, "type": "TASK", "confidence": 0.8816564798355102}]}, {"text": "We noticed that the MTNT dataset as provided for the task has some peculiarities that were probably caused inadvertently during the dataset building.", "labels": [], "entities": [{"text": "MTNT dataset", "start_pos": 20, "end_pos": 32, "type": "DATASET", "confidence": 0.7822329699993134}]}, {"text": "Namely, the training and validation splits seem to come from a single alphabetically sorted file.", "labels": [], "entities": [{"text": "validation splits", "start_pos": 25, "end_pos": 42, "type": "TASK", "confidence": 0.9053367376327515}]}, {"text": "This means that all validation source sentences start with the letter \"Y\", and anything that comes after \"Y\" in the alphabetical order.", "labels": [], "entities": []}, {"text": "Because of this, the validation scores are unreliable.", "labels": [], "entities": []}, {"text": "Moreover, a system trained on the training split will have a difficult time translating sentences beginning with e.g. the word \"You\", which is a commonly seen instance in the online discussion domain.", "labels": [], "entities": [{"text": "translating sentences beginning with e.g. the word \"You\"", "start_pos": 76, "end_pos": 132, "type": "TASK", "confidence": 0.7120691120624543}]}, {"text": "This does not affect the test split.", "labels": [], "entities": []}, {"text": "The baseline system introduced with the dataset is a recurrent sequence-to-sequence model with attention ().", "labels": [], "entities": []}, {"text": "The encoder is a bidirectional LSTM with two layers.", "labels": [], "entities": []}, {"text": "The decoder is a two-layer LSTM.", "labels": [], "entities": []}, {"text": "The hidden state dimension in the LSTMs is 1,024 and the word embedding size is 512.", "labels": [], "entities": []}, {"text": "The model that was used as a baseline for the Robustness Task was trained on the WMT15 parallel data.", "labels": [], "entities": [{"text": "Robustness Task", "start_pos": 46, "end_pos": 61, "type": "TASK", "confidence": 0.9292618334293365}, {"text": "WMT15 parallel data", "start_pos": 81, "end_pos": 100, "type": "DATASET", "confidence": 0.8913706143697103}]}, {"text": "Additionally, simple fine-tuning using stochastic gradient descent on the MTNT data is shown to improve the translation quality by a large margin.", "labels": [], "entities": [{"text": "MTNT data", "start_pos": 74, "end_pos": 83, "type": "DATASET", "confidence": 0.8851064145565033}]}, {"text": "The translation quality of the system is tabulated among our systems in.", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9489620327949524}]}], "tableCaptions": [{"text": " Table 1: Overview of the data used to train the CUNI  Transformer baseline system.", "labels": [], "entities": [{"text": "CUNI  Transformer baseline", "start_pos": 49, "end_pos": 75, "type": "DATASET", "confidence": 0.7648246089617411}]}, {"text": " Table 2: BLEU scores of the baseline and CUNI models measured on several datasets.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.999174177646637}]}, {"text": " Table 3: Quantiative comparison of the CUNI Trans- former system + fine-tuning (this work) with other sub- mitted systems.", "labels": [], "entities": [{"text": "CUNI Trans- former system", "start_pos": 40, "end_pos": 65, "type": "DATASET", "confidence": 0.8707988262176514}, {"text": "fine-tuning", "start_pos": 68, "end_pos": 79, "type": "METRIC", "confidence": 0.9552884101867676}]}]}