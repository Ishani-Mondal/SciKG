{"title": [{"text": "RNN Embeddings for Identifying Difficult to Understand Medical Words", "labels": [], "entities": [{"text": "Identifying Difficult to Understand Medical Words", "start_pos": 19, "end_pos": 68, "type": "TASK", "confidence": 0.8977855642636617}]}], "abstractContent": [{"text": "Patients and their families often require a better understanding of medical information provided by doctors.", "labels": [], "entities": []}, {"text": "We currently address this issue by improving the identification of difficult to understand medical words.", "labels": [], "entities": [{"text": "identification of difficult to understand medical words", "start_pos": 49, "end_pos": 104, "type": "TASK", "confidence": 0.8503076008387974}]}, {"text": "We introduce novel embeddings received from RNN-FrnnMUTE (French RNN Medical Under-standability Text Embeddings) which allow to reach up to 87.0 F1 score in identification of difficult words.", "labels": [], "entities": [{"text": "RNN-FrnnMUTE (French RNN Medical Under-standability Text Embeddings)", "start_pos": 44, "end_pos": 112, "type": "DATASET", "confidence": 0.8296530312962003}, {"text": "F1 score", "start_pos": 145, "end_pos": 153, "type": "METRIC", "confidence": 0.9821416437625885}, {"text": "identification of difficult words", "start_pos": 157, "end_pos": 190, "type": "TASK", "confidence": 0.8233178853988647}]}, {"text": "We also note that adding pre-trained FastText word embeddings to the feature set substantially improves the performance of the model which classifies words according to their difficulty.", "labels": [], "entities": []}, {"text": "We study the gen-eralizability of different models through three cross-validation scenarios which allow testing classifiers in real-world conditions: understanding of medical words by new users, and classification of new unseen words by the automatic models.", "labels": [], "entities": [{"text": "classification of new unseen words", "start_pos": 199, "end_pos": 233, "type": "TASK", "confidence": 0.8171431064605713}]}, {"text": "The RNN-FrnnMUTE em-beddings and the categorization code are being made available for the research.", "labels": [], "entities": [{"text": "RNN-FrnnMUTE em-beddings", "start_pos": 4, "end_pos": 28, "type": "DATASET", "confidence": 0.8530084192752838}]}], "introductionContent": [{"text": "Specialized areas, such as medical area, convey and use technical words, or terms, which are typically related to knowledge developed within these areas.", "labels": [], "entities": []}, {"text": "In the medical area, this specific knowledge often corresponds to fundamental medical notions related to disorders, procedures, treatments, and human anatomy.", "labels": [], "entities": []}, {"text": "For instance, technical terms like blepharospasm (abnormal contraction or twitch of the eyelid), alexithymia (inability to identify and describe emotions in the self), appendicectomy (surgical removal of the vermiform appendix from intestine), or lombalgia (low back pain) are frequently used by experts in the medical area texts.", "labels": [], "entities": []}, {"text": "As in any specialized areas, two main kinds of users exist in the medical area: experts of the domain, i.e. medical doctors, both researchers or practitioners; consumers of the healthcare process, i.e. patients and their relatives.", "labels": [], "entities": []}, {"text": "The latter usually do not have expert knowledge in the medical domain, while it is important that they understand the purpose and issues of their healthcare process.", "labels": [], "entities": []}, {"text": "The existing literature provides several studies dedicated to the understanding of medical notions and terms by non-expert users, and of how the level of health literacy of patients impacts on a successful healthcare process, as indeed it is quite common that patients and their relatives must face technical health documents and information.", "labels": [], "entities": [{"text": "understanding of medical notions and terms", "start_pos": 66, "end_pos": 108, "type": "TASK", "confidence": 0.7483597348133723}]}, {"text": "These observations provide the main motivation for our work.", "labels": [], "entities": []}, {"text": "Hence, we address the need of non-specialized users in the medical domain to understand medical and health information.", "labels": [], "entities": []}, {"text": "In this paper, we propose to apply deep learning techniques to improve identification of readability and understandability of medical words by nonexpert users.", "labels": [], "entities": []}, {"text": "In particular, we will tackle the word categorization task and compare the performance of classification model on different feature sets: standard linguistic and non-linguistic features described in section 4, features obtained using different deep learning approaches, and the combinations of all of them.", "labels": [], "entities": [{"text": "word categorization task", "start_pos": 34, "end_pos": 58, "type": "TASK", "confidence": 0.791530172030131}]}, {"text": "We also investigate how different feature sets perform with three different cross-validation settings, described in section 5.", "labels": [], "entities": []}, {"text": "The medical data used in this work are in French.", "labels": [], "entities": []}, {"text": "Three human annotators participated in the creation of the reference data (specifying the understandability of words).", "labels": [], "entities": []}], "datasetContent": [{"text": "We study the impact of adding words embeddings as features for identifying difficult for understanding words.", "labels": [], "entities": []}, {"text": "First, we observe how FastText word embeddings influence the quality of classification in different cross-validation scenarios.", "labels": [], "entities": []}, {"text": "Then, we study how FrnnMUTE used as features impact on classification quality in all the same crossvalidation scenarios.", "labels": [], "entities": [{"text": "FrnnMUTE", "start_pos": 19, "end_pos": 27, "type": "DATASET", "confidence": 0.8847959637641907}]}, {"text": "The quality of the classifications is evaluated using four standard macroaveraging) measures: accuracy A, precision P , recall Rand F1-measure F .", "labels": [], "entities": [{"text": "accuracy A", "start_pos": 94, "end_pos": 104, "type": "METRIC", "confidence": 0.965634286403656}, {"text": "precision P", "start_pos": 106, "end_pos": 117, "type": "METRIC", "confidence": 0.9647559821605682}, {"text": "recall Rand F1-measure F", "start_pos": 120, "end_pos": 144, "type": "METRIC", "confidence": 0.9039196819067001}]}], "tableCaptions": [{"text": " Table 2: Experiments on user-in vocabulary-out cross-validation. The best score for a combination of quality  measure and experiment is in bold.", "labels": [], "entities": []}, {"text": " Table 3: Experiments on user-out vocabulary-in cross-validation.", "labels": [], "entities": []}, {"text": " Table 4: Experiments on user-out vocabulary-out cross-validation.", "labels": [], "entities": []}, {"text": " Table 5: Mean, standard deviation and maximum of F1 scores", "labels": [], "entities": [{"text": "Mean", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9995288848876953}, {"text": "F1", "start_pos": 50, "end_pos": 52, "type": "METRIC", "confidence": 0.9658886790275574}]}]}