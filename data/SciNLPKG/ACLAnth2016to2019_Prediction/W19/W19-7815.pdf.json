{"title": [{"text": "Artificially Evolved Chunks for Morphosyntactic Analysis", "labels": [], "entities": [{"text": "Morphosyntactic Analysis", "start_pos": 32, "end_pos": 56, "type": "TASK", "confidence": 0.7128877937793732}]}], "abstractContent": [{"text": "We introduce a language-agnostic evolutionary technique for automatically extracting chunks from dependency treebanks.", "labels": [], "entities": []}, {"text": "We evaluate these chunks on a number of morphosyntactic tasks, namely POS 1 tagging, morphological feature tagging, and dependency parsing.", "labels": [], "entities": [{"text": "POS 1 tagging", "start_pos": 70, "end_pos": 83, "type": "TASK", "confidence": 0.6573251585165659}, {"text": "morphological feature tagging", "start_pos": 85, "end_pos": 114, "type": "TASK", "confidence": 0.6514165500799814}, {"text": "dependency parsing", "start_pos": 120, "end_pos": 138, "type": "TASK", "confidence": 0.8455665409564972}]}, {"text": "We test the utility of these chunks in a host of different ways.", "labels": [], "entities": []}, {"text": "We first learn chunking as one task in a shared multi-task framework together with POS and morphological feature tagging.", "labels": [], "entities": []}, {"text": "The predictions from this network are then used as input to augment sequence-labelling dependency parsing.", "labels": [], "entities": [{"text": "sequence-labelling dependency parsing", "start_pos": 68, "end_pos": 105, "type": "TASK", "confidence": 0.6300847232341766}]}, {"text": "Finally, we investigate the impact chunks have on dependency parsing in a multi-task framework.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 50, "end_pos": 68, "type": "TASK", "confidence": 0.8264805674552917}]}, {"text": "Our results from these analyses show that these chunks improve performance at different levels of syntactic abstraction on English UD treebanks and a small, diverse subset of non-English UD treebanks.", "labels": [], "entities": [{"text": "English UD treebanks", "start_pos": 123, "end_pos": 143, "type": "DATASET", "confidence": 0.653417319059372}]}], "introductionContent": [{"text": "Shallow parsing, or chunking, consists of identifying constituent phrases.", "labels": [], "entities": [{"text": "Shallow parsing", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.6945730447769165}]}, {"text": "As such, it is fundamentally associated with constituency parsing, as it can be used as a first step for finding a full constituency tree ().", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 45, "end_pos": 65, "type": "TASK", "confidence": 0.8994015753269196}]}, {"text": "However, chunking information can also be beneficial for dependency parsing, and vice versa (.", "labels": [], "entities": [{"text": "chunking information", "start_pos": 9, "end_pos": 29, "type": "TASK", "confidence": 0.9062632620334625}, {"text": "dependency parsing", "start_pos": 57, "end_pos": 75, "type": "TASK", "confidence": 0.8777770102024078}]}, {"text": "Latterly, explored the efficacy of noun phrase (NP) chunking with respect to universal dependency (UD) parsing and POS tagging for English treebanks.", "labels": [], "entities": [{"text": "noun phrase (NP) chunking", "start_pos": 35, "end_pos": 60, "type": "TASK", "confidence": 0.6196363766988119}, {"text": "universal dependency (UD) parsing", "start_pos": 77, "end_pos": 110, "type": "TASK", "confidence": 0.6722956647475561}, {"text": "POS tagging", "start_pos": 115, "end_pos": 126, "type": "TASK", "confidence": 0.7717137336730957}]}, {"text": "As UD treebanks do not contain chunking annotation, they deduced chunks by adopting linguistic-based phrase rules.", "labels": [], "entities": [{"text": "UD treebanks", "start_pos": 3, "end_pos": 15, "type": "DATASET", "confidence": 0.7197056263685226}]}, {"text": "They observed improvements on POS and morphological feature tagging in a shared multi-task framework for the English treebanks in UD version 2.1 (.", "labels": [], "entities": [{"text": "morphological feature tagging", "start_pos": 38, "end_pos": 67, "type": "TASK", "confidence": 0.6966635982195536}]}, {"text": "However, an increase in performance for parsing was only obtained for one treebank.", "labels": [], "entities": [{"text": "parsing", "start_pos": 40, "end_pos": 47, "type": "TASK", "confidence": 0.9907762408256531}]}, {"text": "We first relax the standard definition of chunks and present an evolutionary method to automatically deduce chunks for any language given a dependency treebank.", "labels": [], "entities": []}, {"text": "2. We show that chunking information can improve performances for POS tagging, morphological feature tagging, and dependency parsing, both in a multi-task and a single-task framework.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 66, "end_pos": 77, "type": "TASK", "confidence": 0.8042644560337067}, {"text": "morphological feature tagging", "start_pos": 79, "end_pos": 108, "type": "TASK", "confidence": 0.7035043438275655}, {"text": "dependency parsing", "start_pos": 114, "end_pos": 132, "type": "TASK", "confidence": 0.7881561815738678}]}], "datasetContent": [{"text": "Data The analyses were undertaken using the English treebanks (EWT, GUM, LinES, and ParTUT) and also Bulgarian-BTB, German-GSD, and Japanese-GSD from UD v2.3 (Nivre et al., 2018).", "labels": [], "entities": [{"text": "English treebanks", "start_pos": 44, "end_pos": 61, "type": "DATASET", "confidence": 0.9381328523159027}, {"text": "EWT", "start_pos": 63, "end_pos": 66, "type": "DATASET", "confidence": 0.5925727486610413}, {"text": "LinES", "start_pos": 73, "end_pos": 78, "type": "METRIC", "confidence": 0.7615876793861389}, {"text": "ParTUT", "start_pos": 84, "end_pos": 90, "type": "METRIC", "confidence": 0.8815986514091492}]}, {"text": "No results are given for Japanese-GSD for morphological feature tagging as it does not contain this information.", "labels": [], "entities": [{"text": "morphological feature tagging", "start_pos": 42, "end_pos": 71, "type": "TASK", "confidence": 0.6679806609948477}]}, {"text": "Network hyperparameters We used the framework as described above and hyperparameters from  which can be seen in in the Appendix B. The standard input to the system consisted of word embeddings concatenated with character embeddings.", "labels": [], "entities": []}, {"text": "All embeddings were randomly initialised.", "labels": [], "entities": []}, {"text": "Figure 3: Multi-task architecture shown with sequence-labelling dependency parsing (as described in subsection 4.1), POS tagging, and chunking as shared tasks.", "labels": [], "entities": [{"text": "sequence-labelling dependency parsing", "start_pos": 45, "end_pos": 82, "type": "TASK", "confidence": 0.6391824384530386}, {"text": "POS tagging", "start_pos": 117, "end_pos": 128, "type": "TASK", "confidence": 0.8212856352329254}]}, {"text": "Network input is a concatenation of word embeddings (circles) and character-level word embeddings (triangles) obtained from a character-based LSTM layer.", "labels": [], "entities": []}, {"text": "The network is constructed of BiLSTM layers followed by a softmax layer for inference.", "labels": [], "entities": []}, {"text": "Experiment 1 We tested the impact of our chunks on POS and morphological feature tagging in a shared multi-task setting.", "labels": [], "entities": [{"text": "morphological feature tagging", "start_pos": 59, "end_pos": 88, "type": "TASK", "confidence": 0.6360216240088145}]}, {"text": "This entails feeding word and character embeddings as input to the network with the output being some combination of POS tags, morphological feature tags, and chunk labels.", "labels": [], "entities": []}, {"text": "These results were compared against the baseline taggers (single-task networks and POS and morphological features shared only).", "labels": [], "entities": []}, {"text": "As a further baseline we include results for POS and morphological feature tagging using UDPipe 2.2 (Straka and Strakov\u00e1, 2019).", "labels": [], "entities": [{"text": "morphological feature tagging", "start_pos": 53, "end_pos": 82, "type": "TASK", "confidence": 0.6348950763543447}]}, {"text": "Experiment 2 We used the best predictions (when using chunking) from experiment 1 as additional features fora sequence-labelling dependency parser (.", "labels": [], "entities": []}, {"text": "Therefore, network input consisted of word and character embedding and then some combination of POS tags, morphological feature tags, or chunk labels with the sole output being a dependency parser tag.", "labels": [], "entities": []}, {"text": "We used gold tags and labels as input during training, but at runtime we used predicted tags and labels.", "labels": [], "entities": []}, {"text": "For baselines we train a model with no features which is decoded with predicted POS tags using UDPipe 2.2 (as the sequencelabelling encoding we are using requires POS tags to resolve dependency heads) and also a model trained with POS tags as features but also using UDPipe 2.2 predicted POS tags at runtime.", "labels": [], "entities": []}, {"text": "We tested the impact of our chunks on a sequence-labelling dependency parser in a multi-task framework with and without the other tasks.", "labels": [], "entities": []}, {"text": "POS tagging was treated as a secondary main task with a weight of 0.5 (as POS tags are needed to decode the sequence-labelling scheme for the dependency parser) and chunks and morphological features were considered auxiliary tasks with a weight of 0.25 when used.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.6775169968605042}]}, {"text": "The input during this experiment were only word and character embeddings.", "labels": [], "entities": []}, {"text": "An example is shown in where the shared tasks are chunking, POS tagging, and dependency parsing.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 60, "end_pos": 71, "type": "TASK", "confidence": 0.847257137298584}, {"text": "dependency parsing", "start_pos": 77, "end_pos": 95, "type": "TASK", "confidence": 0.8134017884731293}]}, {"text": "The baseline used here is a model trained solely to predict dependency parsing tags which are then decoded using predicted POS tags from UDPipe 2.2.", "labels": [], "entities": [{"text": "dependency parsing tags", "start_pos": 60, "end_pos": 83, "type": "TASK", "confidence": 0.7769306302070618}]}], "tableCaptions": [{"text": " Table 1: Chunking statistics on test data for each treebank used where # rules is the number of rules in a  ruleset for a given threshold and C/sent corresponds to the number of chunks per sentence found.", "labels": [], "entities": [{"text": "Chunking", "start_pos": 10, "end_pos": 18, "type": "TASK", "confidence": 0.9612972140312195}]}, {"text": " Table 2: Multi-task tagging performance on English UD treebanks (en-ewt, en-gum, en-lines, and en- partut), Bulgarian-BTB (bg), German-GSD (de), and Japanese-GSD (ja) UD treebanks: single, single- task training; pos, with POS tagging; feats, with morphological feature tagging (except Japanese (ja)  which has no morphological features); and chunks x , with chunks with threshold x.", "labels": [], "entities": [{"text": "Multi-task tagging", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.7242712378501892}, {"text": "English UD treebanks", "start_pos": 44, "end_pos": 64, "type": "DATASET", "confidence": 0.5768701235453287}, {"text": "POS tagging", "start_pos": 223, "end_pos": 234, "type": "TASK", "confidence": 0.6802299320697784}]}, {"text": " Table 3: Chunker F1 scores in multi task setting where the baseline presented is from training the chunker  for a given ruleset with threshold 75% or 95% as a single task and multi is from training with pos and  morphological feature tagging except for Japanese (ja) which has no morphological features.", "labels": [], "entities": [{"text": "F1", "start_pos": 18, "end_pos": 20, "type": "METRIC", "confidence": 0.8450721502304077}]}, {"text": " Table 5: Multi-task parsing results for English (en-ewt, en-gum, en-lines, and en-partut), Bulgarian-BTB  (bg), German-GSD (de), and Japanese-GSD (ja) UD treebanks: single ud pipe , parsing as single task with  UDPipe predicted POS tags used to decode parser output; pos, with POS tagging as aux. task; feats, with  morphological feature tagging as aux. task; and chunks x , with chunking as aux. task for threshold x.", "labels": [], "entities": [{"text": "Multi-task parsing", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.7083562612533569}, {"text": "UD treebanks", "start_pos": 152, "end_pos": 164, "type": "DATASET", "confidence": 0.7242358922958374}]}, {"text": " Table 6: Hyperparameters for the evolutionary algorithm: k-best, the number of best parents chosen to  seed next generation; P mutate , the probability an individual will mutate; P mutate gene , the probability a given  gene will mutate; P crossover , the probability a pair of individuals will crossover; and decay is how much  P mutate and P crossover decrease after each generation.", "labels": [], "entities": []}, {"text": " Table 7: Hyperparameters for the neural-net chunker used during the evolutionary algorithm.", "labels": [], "entities": []}]}