{"title": [{"text": "Automatic Data-Driven Approaches for Evaluating the Phonemic Verbal Fluency Task with Healthy Adults", "labels": [], "entities": [{"text": "Phonemic Verbal Fluency Task", "start_pos": 52, "end_pos": 80, "type": "TASK", "confidence": 0.790593296289444}]}], "abstractContent": [{"text": "Phonemic Verbal Fluency (PVF) is a cogni-tive assessment task where a patient is asked to produce words constrained to a given alphabetical letter fora specified time duration.", "labels": [], "entities": [{"text": "Phonemic Verbal Fluency (PVF)", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7168986399968466}]}, {"text": "Patient productions are later evaluated based on strategies to reveal crucial diagnostic information by manually scoring results according to predetermined clinical criteria.", "labels": [], "entities": []}, {"text": "In this paper, we propose four alternative similarity metrics and evaluate them in a twofold argument, using the clinical criteria as a baseline.", "labels": [], "entities": []}, {"text": "First, we consider the capacity of each metric to model PVF production using a rank-based approach, and then consider the metrics ability to compute finer resolution clinical measures that are indicative of the underlying strategy.", "labels": [], "entities": []}, {"text": "Automation of the clinical criteria and proposed met-rics are evaluated on PVF performances for 16 letters from 32 healthy German students (n=512).", "labels": [], "entities": []}, {"text": "Weighted phonemic edit distance performed best overall for modelling both production and strategy.", "labels": [], "entities": [{"text": "phonemic edit distance", "start_pos": 9, "end_pos": 31, "type": "METRIC", "confidence": 0.5942723949750265}]}], "introductionContent": [{"text": "Phonemic Verbal Fluency (PVF) is a standard neuropsychological test that is used to assess cognitive abilities.", "labels": [], "entities": [{"text": "Phonemic Verbal Fluency (PVF)", "start_pos": 0, "end_pos": 29, "type": "METRIC", "confidence": 0.6038445482651392}]}, {"text": "During this task, a person is asked to produce as many words as possible starting with a given letter in a specified amount of time.", "labels": [], "entities": []}, {"text": "Classically, the PVF performance is then scored by counting the total number of unique words produced, however more fine-grained measures of performance (i.e. strategy) have been established to differentiate between multiple pathologies (.) first proposed a framework for assessing the strategy of a PVF performance: a rule-based system to determine phonemic clusters by manually defining criteria for phonemic similarity ().", "labels": [], "entities": []}, {"text": "According to this criteria, consecutive words in a production are lumped into categories if they share common first letters (e.g. arm & art), rhyme (e.g. stand & sand), share first and last sounds (e.g. sat, seat & soot) or are homonyms (e.g. some & sum).", "labels": [], "entities": [{"text": "rhyme", "start_pos": 142, "end_pos": 147, "type": "METRIC", "confidence": 0.9780840277671814}]}, {"text": "While modelling production strategy (i.e., clustering and switching measures) is crucial for clinical cognitive considerations, the traditional manual approach is subjective and time consuming.", "labels": [], "entities": []}, {"text": "There is a clear need fora data-driven automatic approach that addresses these limitations.", "labels": [], "entities": []}, {"text": "Novel computational approaches to the analysis of semantic verbal fluency (SVF), where patients are asked to produce words based on a semantic cue (e.g. animals), could help to overcome the current limitations in PVF analysis (.", "labels": [], "entities": [{"text": "analysis of semantic verbal fluency (SVF)", "start_pos": 38, "end_pos": 79, "type": "TASK", "confidence": 0.7470890916883945}, {"text": "PVF analysis", "start_pos": 213, "end_pos": 225, "type": "TASK", "confidence": 0.8227196037769318}]}, {"text": "The underlying rationale is to use a global similarity metric that is learned from data to derive a notion of relatedness between produced words, which can later be used to determine structures of related clusters as proxy for production strategy.", "labels": [], "entities": []}, {"text": "In the case of SVF, the similarity metric is semantically motivated.", "labels": [], "entities": []}, {"text": "Given the sparse body of research on automatic PVF analysis schemes modelling both production and strategy, further investigation on more sophisticated data-driven modelling approaches to PVF is needed.", "labels": [], "entities": [{"text": "PVF analysis", "start_pos": 47, "end_pos": 59, "type": "TASK", "confidence": 0.8231092393398285}]}, {"text": "The goal of this paper is two-fold: (1) First, we aim to introduce and compare the performance of five different similarity metrics for modelling production of PVF-in cognitively healthy participants-across sixteen letter categories, including an automated version of the current clinical criteria.", "labels": [], "entities": []}, {"text": "(2) Second, we propose a data-driven clustering scheme for determining phonemic clusters as a means of evaluating production strategy.", "labels": [], "entities": []}, {"text": "In both experimental conditions, we compare the novel metrics to an implementation of the classic clinical Troyer baseline, described previously, to evaluate performance.", "labels": [], "entities": []}], "datasetContent": [{"text": "The quality of the AP clustering technique on this task is evaluated using the silhouette coefficient.", "labels": [], "entities": [{"text": "AP clustering", "start_pos": 19, "end_pos": 32, "type": "TASK", "confidence": 0.9147589802742004}]}, {"text": "This measure is ideal as it does not require aground truth.", "labels": [], "entities": []}, {"text": "This measure looks at the fit of a cluster by considering if every point is in its closest cluster, or if another cluster would be more suitable.", "labels": [], "entities": []}, {"text": "Each point in the dataset is considered.", "labels": [], "entities": []}, {"text": "First, the average distance between the chosen point and all points in its own cluster (distance cohesion ) is calculated.", "labels": [], "entities": []}, {"text": "Then, the average distance between the same point and all points in next nearest cluster is calculated (distance separation ).", "labels": [], "entities": [{"text": "distance separation", "start_pos": 104, "end_pos": 123, "type": "METRIC", "confidence": 0.9235754013061523}]}, {"text": "The silhouette coefficient is bounded from -1 to 1, where positive values indicate higher quality clusters and negative values typically indicate that a point has been incorrectly clustered.", "labels": [], "entities": []}, {"text": "The ability of the metrics to model strategy is evaluated by looking at the average rank cost within clusters as well as the average rank cost between clusters, or switches.", "labels": [], "entities": []}, {"text": "The rank cost tables created previously are used to calculate this respectively.", "labels": [], "entities": []}, {"text": "The average rank cost of clusters is calculated by looking at the rank cost of transitions between words in each cluster and normalized by the number of transitions in a cluster.", "labels": [], "entities": []}, {"text": "The average rank cost of switches in a production is calculated by summing the rank costs of transitions between cluster boundaries and normalizing by the number of switch transitions.", "labels": [], "entities": []}, {"text": "Metrics with a lower average rank cost within clusters and higher average rank cost of switching are seen to better model strategy.", "labels": [], "entities": []}, {"text": "For the first experiment, one minute PVF performances of 32 German students (9 male, 23 female; Age 22.88) from 16 different letter categories (i.e. A, B, D, F, G, H, K, L, M, N, P, R, S, T, V, Z) were collected.", "labels": [], "entities": []}, {"text": "These were manually transcribed on a word level into sequences of correct responses.", "labels": [], "entities": []}, {"text": "Words were converted into phoneme (IPA) representations using the python epitran 1 package.", "labels": [], "entities": []}, {"text": "For each letter category c, a vocabulary V c was constructed to calculate the RC f of each sample as described in Section 4.", "labels": [], "entities": [{"text": "RC f", "start_pos": 78, "end_pos": 82, "type": "METRIC", "confidence": 0.9343877732753754}]}, {"text": "Statistical analysis was performed using R (software version 3.4.0).", "labels": [], "entities": [{"text": "Statistical analysis", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8489421606063843}]}, {"text": "Performance of metrics overall letters was examined with a linear mixed effects analysis using the lme4 ( package.", "labels": [], "entities": []}, {"text": "Each RC f was modelled as a single data point and letter and metric were represented as fixed effects.", "labels": [], "entities": []}, {"text": "The participant identifier was modelled as a random intercept.", "labels": [], "entities": []}, {"text": "The affinity propagation clustering algorithm was implemented in python from scikit-learn framework (Pedregosa et al., 2011).", "labels": [], "entities": [{"text": "affinity propagation clustering", "start_pos": 4, "end_pos": 35, "type": "TASK", "confidence": 0.8844393094380697}]}, {"text": "The same parameters were used to determine all models.", "labels": [], "entities": []}, {"text": "The preference parameter serves as an indicator of how fit a word in the vocabulary is to bean exemplar, higher values indicate that it is more likely whereas lower values indicate that it is less likely.", "labels": [], "entities": []}, {"text": "This also influences the number of clusters produced, where higher preference values lead to more clusters and lower preference values lead to fewer cluster.", "labels": [], "entities": []}, {"text": "The preference parameter was set for each word in the vocabulary as the Zipf word frequency as determined by the python wordfreq package).", "labels": [], "entities": []}, {"text": "The zipf word frequency represents the frequency of the word in a large, in this case German, corpus on a 'human-friendly' scale.", "labels": [], "entities": []}, {"text": "The result is a value between 1.0 and 8.0, where the larger the value, the more frequent the word is in the language.", "labels": [], "entities": []}, {"text": "The goal of using the word frequency during clustering is to give a high exemplar weight to more frequent words to make the clusters relevant to the PVF production task.", "labels": [], "entities": [{"text": "PVF production task", "start_pos": 149, "end_pos": 168, "type": "TASK", "confidence": 0.8219938476880392}]}, {"text": "The remaining parameters were left at their default values; the damping factor was set to 0.5 and convergence iteration rate at 200.", "labels": [], "entities": [{"text": "convergence iteration rate", "start_pos": 98, "end_pos": 124, "type": "METRIC", "confidence": 0.9501247604688009}]}, {"text": "Each previously computed similarity matrix Sc was used as an input to generate clusters for each metric f . The average rank cost of clusters in a production was computed as described in 3.2.2.", "labels": [], "entities": []}, {"text": "Results are displayed in, where a better fit is indicated by lower RC f . One boxplot is shown for each letter category.", "labels": [], "entities": []}, {"text": "The threshold for rejecting a null hypothesis and determining statistical significance is set at 0.05 for all tests performed.", "labels": [], "entities": []}, {"text": "The linear models were created as described in 3.1.2 and revealed that RC f values were significantly lower for the phon and significantly greater for the sem metric.", "labels": [], "entities": []}, {"text": "Performances varied across letter categories with the lowest overall RC f values being observed for the letter N and the highest for S.", "labels": [], "entities": [{"text": "RC f values", "start_pos": 69, "end_pos": 80, "type": "METRIC", "confidence": 0.923141082127889}]}, {"text": "Evaluation of cluster quality as produced by the AP clustering algorithm is monitored via their silhouette coefficients as described in section 3.2.2 and are shown in.", "labels": [], "entities": [{"text": "AP clustering", "start_pos": 49, "end_pos": 62, "type": "TASK", "confidence": 0.5548196732997894}]}, {"text": "The highest quality clusters were produced by the phon metric.", "labels": [], "entities": []}, {"text": "The pos metric had the second highest quality on average.", "labels": [], "entities": []}, {"text": "The remaining metrics all produced relatively close values for all letter categories with Troyer performing slightly better than LD and sem.", "labels": [], "entities": []}, {"text": "Overall, all metrics on average produced positive cluster values.", "labels": [], "entities": []}, {"text": "uses beanplots to compare each metric by the distribution of average rank cost within a cluster and the average rank cost of switches.", "labels": [], "entities": []}, {"text": "Phon had a much lower average rank cost within clusters whereas all other metrics were relatively equal, with Troyer having slightly lower than LD.", "labels": [], "entities": []}, {"text": "Sem had the highest average cluster rank cost.", "labels": [], "entities": []}, {"text": "For each metric, a paired-samples t-test was conducted to compare average RC f , aggregated across letter categories, between clustering and switching conditions.", "labels": [], "entities": []}, {"text": "There were significant differences in average rank cost for clustering and switching for phon (t(222)=-20.17, p<0.05), sem (t(222)=3.69, p<0.05) and pos (t(222)=-2.372, p<0.05).", "labels": [], "entities": []}, {"text": "No significant differences were found for the metrics LD or Troyer.", "labels": [], "entities": [{"text": "Troyer", "start_pos": 60, "end_pos": 66, "type": "METRIC", "confidence": 0.913478672504425}]}], "tableCaptions": []}