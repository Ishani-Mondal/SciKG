{"title": [{"text": "Identification, Interpretability, and Bayesian Word Embeddings", "labels": [], "entities": []}], "abstractContent": [{"text": "Social scientists have recently turned to analyzing text using tools from natural language processing like word embeddings to measure concepts like ideology, bias, and affinity.", "labels": [], "entities": []}, {"text": "However, word embeddings are difficult to use in the regression framework familiar to social scientists: embeddings are are neither identified , nor directly interpretable.", "labels": [], "entities": []}, {"text": "I offer two advances on standard embedding models to remedy these problems.", "labels": [], "entities": []}, {"text": "First, I develop Bayesian Word Embeddings with Automatic Relevance Determination priors, relaxing the assumption that all embedding dimensions have equal weight.", "labels": [], "entities": []}, {"text": "Second, I apply work identifying latent variable models to anchor the dimensions of the resulting embeddings, identifying them, and making them interpretable and usable in a regression.", "labels": [], "entities": []}, {"text": "I then apply this model and anchoring approach to two cases, the shift in interna-tionalist rhetoric in the American presidents' inaugural addresses, and the relationship between bellicosity in American foreign policy decision-makers' deliberations.", "labels": [], "entities": []}, {"text": "I find that inaugural addresses became less international-ist after 1945, which goes against the conventional wisdom, and that an increase in bellicos-ity is associated with an increase in hostile actions by the United States, showing that elite deliberations are not cheap talk, and helping confirm the validity of the model.", "labels": [], "entities": []}], "introductionContent": [{"text": "Important questions in the social sciences turn on the meanings of words used to express ideas like language change, emotion, and ideological affinity (.", "labels": [], "entities": []}, {"text": "One increasingly popular way to represent meaning, originating in natural language processing, is through the use of word embeddings.", "labels": [], "entities": []}, {"text": "This class of models learns a set of coefficients which encode meaning by predicting a word given the surrounding words (.", "labels": [], "entities": []}, {"text": "These coefficients are the embeddings, which can then be used to analyze word meanings.", "labels": [], "entities": []}, {"text": "Unfortunately, existing embedding models are not always appropriate for answering social scientists' questions.", "labels": [], "entities": []}, {"text": "Embeddings are not identified, and the dimensions are not directly interpretable, which makes it difficult to perform statistical inference on the embeddings produced by standard models, for example, using them as covariates in a regression model.", "labels": [], "entities": []}, {"text": "To resolve these issues, I cast word embeddings as a Bayesian latent variable model.", "labels": [], "entities": []}, {"text": "Identifying multidimensional latent variable models is a known problem, and I draw on solutions proposed in the ideal point modeling literature) to render embeddings interpretable and usable in a regression framework.", "labels": [], "entities": []}, {"text": "I demonstrate these results on two corpora: a collection of inaugural addresses, and a selection of declassified diplomatic documents from the Foreign Relation of the United States.", "labels": [], "entities": []}, {"text": "In the inaugural addresses, I find rhetoric became more domestically-focused after 1945, a shift which existing social science approaches cannot detect.", "labels": [], "entities": []}, {"text": "This finding stands in contrast to what existing theories of international relations would have us expect.", "labels": [], "entities": []}, {"text": "In the FRUS documents, I find that more bellicose rhetoric results in more aggressive American foreign policy behavior, helping confirm that elite deliberation matters for shaping foreign policy, and that the measurements I create correlate with existing datasets, helping to establish the validity of the model results.", "labels": [], "entities": [{"text": "FRUS documents", "start_pos": 7, "end_pos": 21, "type": "DATASET", "confidence": 0.9621321558952332}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: The top words from a subset of components estimated from UMAP. Components include a variety of  regional and substantive themes. These results help highlight the validity of the embeddings: semantically similar  words are appearing near each other in cosine space.", "labels": [], "entities": [{"text": "UMAP", "start_pos": 67, "end_pos": 71, "type": "DATASET", "confidence": 0.851553201675415}]}]}