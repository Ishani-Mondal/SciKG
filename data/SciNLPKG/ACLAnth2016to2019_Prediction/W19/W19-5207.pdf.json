{"title": [{"text": "Hierarchical Document Encoder for Parallel Corpus Mining", "labels": [], "entities": [{"text": "Hierarchical Document Encoder", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6789486010869344}]}], "abstractContent": [{"text": "We explore using multilingual document em-beddings for nearest neighbor mining of parallel data.", "labels": [], "entities": []}, {"text": "Three document-level representations are investigated: (i) document embed-dings generated by simply averaging multilingual sentence embeddings; (ii) a neural bag-of-words (BoW) document encoding model; (iii) a hierarchical multilingual document en-coder (HiDE) that builds on our sentence-level model.", "labels": [], "entities": []}, {"text": "The results show document embed-dings derived from sentence-level averaging are surprisingly effective for clean datasets, but suggest models trained hierarchically at the document-level are more effective on noisy data.", "labels": [], "entities": []}, {"text": "Analysis experiments demonstrate our hierarchical models are very robust to variations in the underlying sentence embedding quality.", "labels": [], "entities": []}, {"text": "Using document embeddings trained with HiDE achieves state-of-the-art performance on United Nations (UN) parallel document mining, 94.9% P@1 1 for en-fr and 97.3% P@1 for en-es.", "labels": [], "entities": [{"text": "HiDE", "start_pos": 39, "end_pos": 43, "type": "DATASET", "confidence": 0.8774880170822144}, {"text": "United Nations (UN) parallel document mining", "start_pos": 85, "end_pos": 129, "type": "TASK", "confidence": 0.5280312038958073}, {"text": "P@1 1", "start_pos": 137, "end_pos": 142, "type": "METRIC", "confidence": 0.9347383826971054}]}], "introductionContent": [{"text": "Obtaining a high-quality parallel training corpus is one of the most critical issues in machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.850773960351944}]}, {"text": "Previous work on parallel document mining using large distributed systems has proven effective (), but these systems are often heavily engineered and computationally intensive.", "labels": [], "entities": [{"text": "parallel document mining", "start_pos": 17, "end_pos": 41, "type": "TASK", "confidence": 0.5903469125429789}]}, {"text": "Recent work on parallel data mining has focused on sentence-level embeddings (.", "labels": [], "entities": [{"text": "parallel data mining", "start_pos": 15, "end_pos": 35, "type": "TASK", "confidence": 0.6853267451127371}]}, {"text": "However, these sentence embedding methods have had limited success when applied to documentlevel mining tasks (.", "labels": [], "entities": [{"text": "documentlevel mining tasks", "start_pos": 83, "end_pos": 109, "type": "TASK", "confidence": 0.7553780972957611}]}, {"text": "A recent study from shows that document embeddings obtained from averaging sentence embeddings can achieve state-of-the-art performance in document retrieval on the United Nation (UN) corpus.", "labels": [], "entities": [{"text": "United Nation (UN) corpus", "start_pos": 165, "end_pos": 190, "type": "DATASET", "confidence": 0.6169913212458292}]}, {"text": "This simple averaging approach, however, heavily relies on high quality sentence embeddings and the cleanliness of documents in the application domain.", "labels": [], "entities": []}, {"text": "In our work, we explore using three variants of document-level embeddings for parallel document mining: (i) simple averaging of embeddings from a multilingual sentence embedding model (; (ii) trained document-level embeddings based on document unigrams; (iii) a simple hierarchical document encoder (HiDE) trained on documents pairs using the output of our sentencelevel model.", "labels": [], "entities": [{"text": "parallel document mining", "start_pos": 78, "end_pos": 102, "type": "TASK", "confidence": 0.6748976310094198}]}, {"text": "The results show document embeddings are able to achieve strong performance on parallel document mining.", "labels": [], "entities": [{"text": "parallel document mining", "start_pos": 79, "end_pos": 103, "type": "TASK", "confidence": 0.6370031535625458}]}, {"text": "On a test set mined from the web, all models achieve strong retrieval performance, the best being 91.4% P@1 for en-fr and 81.8% for en-es from the hierarchical document models.", "labels": [], "entities": [{"text": "P@1", "start_pos": 104, "end_pos": 107, "type": "METRIC", "confidence": 0.9419992963473002}]}, {"text": "On the United Nations (UN) document mining task (), our best model achieves 96.7% P@1 for en-fr and 97.3% P@1 for en-es, a 3%+ absolute improvement over the prior state-of-the-art ().", "labels": [], "entities": [{"text": "United Nations (UN) document mining task", "start_pos": 7, "end_pos": 47, "type": "TASK", "confidence": 0.5472635067999363}, {"text": "P@1", "start_pos": 82, "end_pos": 85, "type": "METRIC", "confidence": 0.9614724119504293}, {"text": "P@1", "start_pos": 106, "end_pos": 109, "type": "METRIC", "confidence": 0.917894184589386}]}, {"text": "We also evaluate on a noisier version of the UN task where we do not have the ground truth sentence alignments from the original corpus.", "labels": [], "entities": []}, {"text": "An off-the-shelf sentence splitter is used to split the document into sentences.", "labels": [], "entities": [{"text": "sentence splitter", "start_pos": 17, "end_pos": 34, "type": "TASK", "confidence": 0.7673774361610413}]}, {"text": "The results shows that the HiDE model is robust to the noisy sentence segmentations, while the averaging of sentence embeddings approach is more sensitive.", "labels": [], "entities": [{"text": "HiDE", "start_pos": 27, "end_pos": 31, "type": "TASK", "confidence": 0.6006931662559509}]}, {"text": "We further perform analysis on the robustness of our models based on different quality sentence-level embeddings, and show that the HiDE model performs well even when the underlying sentence-level model is relatively weak.", "labels": [], "entities": []}, {"text": "We summarize our contributions as follows: \u2022 We introduce and explore different approaches for using document embeddings in parallel document mining.", "labels": [], "entities": [{"text": "parallel document mining", "start_pos": 124, "end_pos": 148, "type": "TASK", "confidence": 0.70408167441686}]}, {"text": "\u2022 We adapt the previous work on hierarchical networks to introduce a simple hierarchical document encoder trained on document pairs for this task.", "labels": [], "entities": []}, {"text": "\u2022 Empirical results show our best document embedding model leads to state-of-the-art results on the document-level bitext retrieval task on two different datasets.", "labels": [], "entities": [{"text": "document-level bitext retrieval task", "start_pos": 100, "end_pos": 136, "type": "TASK", "confidence": 0.6165982186794281}]}, {"text": "The proposed hierarchical models are very robust to variations in sentence splitting and the underlying sentence embedding quality.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.7210725098848343}]}], "datasetContent": [{"text": "This section describes our training data, model configurations, and retrieval results for our embedding models: Sentence-Avg, Document BoW, HiDE DNN\u2192pooling , and HiDE pooling\u2192DNN .  Translation candidates are mined with approximate nearest neighbor (ANN) () search over our multilingual embeddings (.", "labels": [], "entities": []}, {"text": "The evaluation metric is precision at N (P@N), which evaluates if the true translation is in the top N candidates returned by the model.", "labels": [], "entities": [{"text": "precision", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9994620680809021}]}, {"text": "presents document embedding P@N retrieval performance using our WebData test set, for N = 1, 3, 10.", "labels": [], "entities": [{"text": "WebData test set", "start_pos": 64, "end_pos": 80, "type": "DATASET", "confidence": 0.9603700041770935}]}, {"text": "The evaluation uses 1M candidate documents for en-fr and 0.6M for en-es.", "labels": [], "entities": []}, {"text": "We obtain the best performance from our hierarchical models, HiDE * . Adapting the sentence embeddings prior to pooling, HiDE DNN\u2192pooling performs better than attempting to adapt the representation after pooling, HiDE pooling\u2192DNN . Document BoW embeddings outperform Sentence-Avg, showing training a simple model for document-level representations (DAN) outperforms pooling of sentence embeddings from a complex model (Transformer).", "labels": [], "entities": []}, {"text": "shows document matching P@1 for our models on both the original UN dataset sentence segmentation and on the noisier sentence segmentation.", "labels": [], "entities": [{"text": "UN dataset sentence segmentation", "start_pos": 64, "end_pos": 96, "type": "DATASET", "confidence": 0.7763916254043579}, {"text": "noisier sentence segmentation", "start_pos": 108, "end_pos": 137, "type": "TASK", "confidence": 0.6957557400067648}]}, {"text": "P@1 is evaluated using all of the UN documents in a target language as translation candidates.", "labels": [], "entities": []}, {"text": "Using both the official and noisy sentence segmentations, HiDE DNN\u2192pooling outperforms, a heavily engineered system that incorporates both MT and monolingual duplicated document detection.", "labels": [], "entities": [{"text": "MT and monolingual duplicated document detection", "start_pos": 139, "end_pos": 187, "type": "TASK", "confidence": 0.5943404485781988}]}, {"text": "uses sentence-to-sentence alignments to heuristically identify document pairs.", "labels": [], "entities": [{"text": "sentence-to-sentence alignments", "start_pos": 5, "end_pos": 36, "type": "TASK", "confidence": 0.7179734110832214}]}, {"text": "Alignments were computed using sentence embeddings generated over the UN corpus annotated sentence splits.", "labels": [], "entities": [{"text": "UN corpus annotated sentence splits", "start_pos": 70, "end_pos": 105, "type": "DATASET", "confidence": 0.888613247871399}]}, {"text": "With corpus annotated splits, Sentence-Avg performs better than.", "labels": [], "entities": []}, {"text": "Furthermore, even with noisy sentence splits HiDE * outperforms.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Precision at N (P@N) of target document retrieval on the WebData test set. Models attempt to select the  true translation target for a source document from the entire corpus (1 million parallel documents for en-fr, and 0.6  million for en-es).", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9919450879096985}, {"text": "WebData test set", "start_pos": 67, "end_pos": 83, "type": "DATASET", "confidence": 0.9572586218516032}]}, {"text": " Table 3: Document matching on the UN corpus eval- uated using P@1. For methods that require sentence  splitting, we report results using both the UN sentence  annotations and an off-the-shelf sentence splitter.", "labels": [], "entities": [{"text": "Document matching", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.8543911576271057}, {"text": "UN corpus eval- uated", "start_pos": 35, "end_pos": 56, "type": "DATASET", "confidence": 0.900257408618927}, {"text": "sentence  splitting", "start_pos": 93, "end_pos": 112, "type": "TASK", "confidence": 0.7290041148662567}]}, {"text": " Table 5: P@1 of target document retrieval on WebData test set and noisy UN corpus for HiDE DNN\u2192pooling and  Sentence-Avg models with different sentence-level P@1 performance . The sentence-level peroformance is mea- sured on the sentence-level UN retrieval task from the entire corpus (11.3 million sentence candidates).", "labels": [], "entities": [{"text": "WebData test set", "start_pos": 46, "end_pos": 62, "type": "DATASET", "confidence": 0.9690203468004862}]}]}