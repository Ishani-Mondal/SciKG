{"title": [{"text": "Terminology-Aware Segmentation and Domain Feature for the WMT19 Biomedical Translation Task", "labels": [], "entities": [{"text": "Terminology-Aware Segmentation", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8364110887050629}, {"text": "WMT19 Biomedical Translation", "start_pos": 58, "end_pos": 86, "type": "TASK", "confidence": 0.7633380691210429}]}], "abstractContent": [{"text": "In this work, we give a description of the TALP-UPC systems submitted for the WMT19 Biomedical Translation Task.", "labels": [], "entities": [{"text": "WMT19 Biomedical Translation Task", "start_pos": 78, "end_pos": 111, "type": "TASK", "confidence": 0.7840975970029831}]}, {"text": "Our proposed strategy is NMT model-independent and relies only on one ingredient, a biomedi-cal terminology list.", "labels": [], "entities": []}, {"text": "We first extracted such a terminology list by labelling biomedical words in our training dataset using the BabelNet API.", "labels": [], "entities": []}, {"text": "Then, we designed a data preparation strategy to insert the terms information at a token level.", "labels": [], "entities": [{"text": "data preparation", "start_pos": 20, "end_pos": 36, "type": "TASK", "confidence": 0.7203065156936646}]}, {"text": "Finally, we trained the Transformer model (Vaswani et al., 2017) with this terms-informed data.", "labels": [], "entities": []}, {"text": "Our best-submitted system ranked 2nd and 3rd for Spanish-English and English-Spanish translation directions, respectively .", "labels": [], "entities": [{"text": "translation directions", "start_pos": 85, "end_pos": 107, "type": "TASK", "confidence": 0.7739211916923523}]}], "introductionContent": [{"text": "Domain adaptation in Neural Machine Translation (NMT) remains one of the main challenges (.", "labels": [], "entities": [{"text": "Domain adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7720159590244293}, {"text": "Neural Machine Translation (NMT)", "start_pos": 21, "end_pos": 53, "type": "TASK", "confidence": 0.8083489437898}]}, {"text": "Domain-specific translations are especially relevant for industrial applications where there is a need for achieving both fluency and terminology in translations.", "labels": [], "entities": [{"text": "Domain-specific translations", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6270750313997269}]}, {"text": "Current state-of-the-art NMT systems achieve high performances when trained with large-scale parallel corpora.", "labels": [], "entities": []}, {"text": "However, most of the time, largescale parallel corpora are not available for specific domains.", "labels": [], "entities": []}, {"text": "Consequently, NMT models perform poorly for domain-specific translation when trained in low-resource scenario (.", "labels": [], "entities": [{"text": "domain-specific translation", "start_pos": 44, "end_pos": 71, "type": "TASK", "confidence": 0.6548581570386887}]}, {"text": "Several works have been proposed to overcome the lack of domain parallel data by leveraging on both monolingual domain data and parallel out-of-domain data ( to improve the performance of domain-specific systems.", "labels": [], "entities": []}, {"text": "Furthermore, some attempts have been made to directly insert external knowledge into NMT models through terminology ( and domain information (.", "labels": [], "entities": []}, {"text": "In this work, we designed a data preparation strategy for domainspecific translation systems to enrich data with terminology information without affecting the model architecture.", "labels": [], "entities": []}, {"text": "The approach consists on two main steps: 1) Retrieve a biomedical terms list from on our training data 2) use terms to add a domain feature on the source side and define a terminology-aware segmentation.", "labels": [], "entities": []}, {"text": "The data preparation is a model-independent process which generates terms-informed token representations that can be used to train any NMT model.", "labels": [], "entities": []}, {"text": "For the Biomedical WMT19 task, we decided to train one of the state-of-the-art neural models, the transformer ().", "labels": [], "entities": [{"text": "Biomedical WMT19 task", "start_pos": 8, "end_pos": 29, "type": "TASK", "confidence": 0.7418312231699625}]}, {"text": "In our knowledge, this is the first attempt to design a domain-specific text segmentation based on a given terminology list.", "labels": [], "entities": [{"text": "domain-specific text segmentation", "start_pos": 56, "end_pos": 89, "type": "TASK", "confidence": 0.687653104464213}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "2, we described how terminology is extracted from BabelNet; in Sec.", "labels": [], "entities": []}, {"text": "3 and 4, we defined the terminology-aware segmentation and the domain feature approach, respectively; in Sec.", "labels": [], "entities": [{"text": "terminology-aware segmentation", "start_pos": 24, "end_pos": 54, "type": "TASK", "confidence": 0.7954842150211334}]}, {"text": "5, we described the experiments performed, the performance evaluation and the results of the WMT19 competition.", "labels": [], "entities": [{"text": "WMT19 competition", "start_pos": 93, "end_pos": 110, "type": "DATASET", "confidence": 0.8123063147068024}]}, {"text": "6 describes the conclusion and future works.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section describes the experiments we performed.", "labels": [], "entities": []}, {"text": "We first start with the data collection and preprocessing processes.", "labels": [], "entities": [{"text": "data collection", "start_pos": 24, "end_pos": 39, "type": "TASK", "confidence": 0.7285082638263702}]}, {"text": "Then, we describe trained systems and their evaluations.", "labels": [], "entities": []}, {"text": "Finally, we present the results of the competition in terms of BLEU score.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 63, "end_pos": 73, "type": "METRIC", "confidence": 0.9718978703022003}]}, {"text": "We evaluated all the models calculating the BLEU score on the WMT18 test set with the 'multi-bleudetok.sh' script in the Moses distribution (.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 44, "end_pos": 54, "type": "METRIC", "confidence": 0.9747158885002136}, {"text": "WMT18 test set", "start_pos": 62, "end_pos": 76, "type": "DATASET", "confidence": 0.9842842221260071}]}, {"text": "For the WMT19 competition, we first calculated the averages of the training checkpoints that achieved the highest BLEU scores on the validation set.", "labels": [], "entities": [{"text": "WMT19 competition", "start_pos": 8, "end_pos": 25, "type": "DATASET", "confidence": 0.6531271636486053}, {"text": "BLEU", "start_pos": 114, "end_pos": 118, "type": "METRIC", "confidence": 0.9991713762283325}]}, {"text": "Then, we submitted these averages as our best models.", "labels": [], "entities": []}, {"text": "The results for both WMT18 and WMT19 test sets are shown in table 3 and 4.", "labels": [], "entities": [{"text": "WMT18", "start_pos": 21, "end_pos": 26, "type": "DATASET", "confidence": 0.8931805491447449}, {"text": "WMT19 test sets", "start_pos": 31, "end_pos": 46, "type": "DATASET", "confidence": 0.902364194393158}]}, {"text": "In, we also calculated how many biomedical terms are found in the validation and WMT18/WMT19 test sets to have an idea of the coverage of the terminology list on the out-oftraining data.", "labels": [], "entities": [{"text": "WMT18/WMT19 test sets", "start_pos": 81, "end_pos": 102, "type": "DATASET", "confidence": 0.8437204599380493}]}, {"text": "On the WMT18 test set, our proposed models performed better than the baseline, indicating that the Transformer model () took advantages from the bpe-terms segmentation.", "labels": [], "entities": [{"text": "WMT18 test set", "start_pos": 7, "end_pos": 21, "type": "DATASET", "confidence": 0.9621257781982422}]}, {"text": "On the contrary, the domain feature approach overall hurts the test set performances.", "labels": [], "entities": []}, {"text": "The best performing system evaluated on the WMT19 test set is the one with bpe-terms segmentation plus shared vocabulary and embedding layers for both source/target and encoder/decoder layers, respectively, showing consistency across both es/en direction.", "labels": [], "entities": [{"text": "WMT19 test set", "start_pos": 44, "end_pos": 58, "type": "DATASET", "confidence": 0.9535575906435648}]}, {"text": "As a result, we placed 2nd for es2en and 3rd for en2es in the WMT19 competition.", "labels": [], "entities": [{"text": "WMT19 competition", "start_pos": 62, "end_pos": 79, "type": "DATASET", "confidence": 0.8164795637130737}]}, {"text": "Validation set WMT18 WMT19 es 713 355 399 en 831 363 502: The number of biomedical terms from the terminology list found in the validation set and the WMT18 and WMT19 test sets.", "labels": [], "entities": [{"text": "WMT18 WMT19 es 713", "start_pos": 15, "end_pos": 33, "type": "DATASET", "confidence": 0.8397566229104996}, {"text": "WMT18", "start_pos": 151, "end_pos": 156, "type": "DATASET", "confidence": 0.9291659593582153}, {"text": "WMT19 test sets", "start_pos": 161, "end_pos": 176, "type": "DATASET", "confidence": 0.89032510916392}]}], "tableCaptions": [{"text": " Table 3: The BLEU scores calculated on the WMT18 test set for the three systems compared with the baseline.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 14, "end_pos": 18, "type": "METRIC", "confidence": 0.999515175819397}, {"text": "WMT18 test set", "start_pos": 44, "end_pos": 58, "type": "DATASET", "confidence": 0.9803543090820312}]}, {"text": " Table 4: The BLEU scores calculated on the WMT19 test set for the three systems.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 14, "end_pos": 18, "type": "METRIC", "confidence": 0.9993570446968079}, {"text": "WMT19 test set", "start_pos": 44, "end_pos": 58, "type": "DATASET", "confidence": 0.9787194728851318}]}]}