{"title": [{"text": "The NiuTrans Machine Translation Systems for WMT19", "labels": [], "entities": [{"text": "NiuTrans Machine Translation", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.8005375862121582}, {"text": "WMT19", "start_pos": 45, "end_pos": 50, "type": "TASK", "confidence": 0.6714188456535339}]}], "abstractContent": [{"text": "This paper described NiuTrans neural machine translation systems for the WMT 2019 news translation tasks.", "labels": [], "entities": [{"text": "NiuTrans neural machine translation", "start_pos": 21, "end_pos": 56, "type": "TASK", "confidence": 0.5964595675468445}, {"text": "WMT 2019 news translation tasks", "start_pos": 73, "end_pos": 104, "type": "TASK", "confidence": 0.7450677633285523}]}, {"text": "We participated in 13 translation directions, including 11 supervised tasks, namely EN\u2194{ZH, DE, RU, KK, LT}, GU\u2192EN and the unsupervised DE\u2194CS sub-track.", "labels": [], "entities": []}, {"text": "Our systems were built on deep Transformer and several back-translation methods.", "labels": [], "entities": []}, {"text": "Iterative knowledge distillation and ensem-ble+reranking were also employed to obtain stronger models.", "labels": [], "entities": []}, {"text": "Our unsupervised submissions were based on NMT enhanced by SMT.", "labels": [], "entities": [{"text": "NMT", "start_pos": 43, "end_pos": 46, "type": "DATASET", "confidence": 0.8246142864227295}, {"text": "SMT", "start_pos": 59, "end_pos": 62, "type": "TASK", "confidence": 0.5794910788536072}]}, {"text": "As a result, we achieved the highest BLEU scores in {KK\u2194EN, GU\u2192EN} directions, ranking 2nd in {RU\u2192EN, DE\u2194CS} and 3rd in {ZH\u2192EN, LT\u2192EN, EN\u2192RU, EN\u2194DE} among all constrained submissions.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 37, "end_pos": 41, "type": "METRIC", "confidence": 0.9991274476051331}]}], "introductionContent": [{"text": "Our NiuTrans team participated in 13 WMT19 shared news translation tasks, including 11 supervised and 2 unsupervised sub-tracks.", "labels": [], "entities": [{"text": "WMT19 shared news translation", "start_pos": 37, "end_pos": 66, "type": "TASK", "confidence": 0.6796250939369202}]}, {"text": "We reused some effective approaches of our WMT18 submissions ( , including backtranslation by beam search), BPE () and further strengthened our systems by exploiting some new techniques this year.", "labels": [], "entities": [{"text": "WMT18 submissions", "start_pos": 43, "end_pos": 60, "type": "DATASET", "confidence": 0.7417092621326447}, {"text": "BPE", "start_pos": 108, "end_pos": 111, "type": "METRIC", "confidence": 0.9204210638999939}]}, {"text": "For our supervised task submissions, all the language pairs shared similar model architectures and training flow.", "labels": [], "entities": []}, {"text": "We proposed four novel Deep-Transformer architectures based on ( as our baseline, which outperformed the standard Transformer-Big significantly in terms of both translation quality and convergence speed.", "labels": [], "entities": []}, {"text": "As for the data augmentation aspect, we experimented several back-translation methods), including beam search, unrestricted sampling and sampling-topK proposed by, to leverage the targetside monolingual data.", "labels": [], "entities": [{"text": "beam search", "start_pos": 98, "end_pos": 109, "type": "TASK", "confidence": 0.7953984141349792}]}, {"text": "We also applied iterative knowledge distillation ( to leverage the source-side monolingual data.", "labels": [], "entities": [{"text": "knowledge distillation", "start_pos": 26, "end_pos": 48, "type": "TASK", "confidence": 0.7313568741083145}]}, {"text": "Our system also employed the conventional combination methods including ensemble and feature-based re-ranking to further improve the translation quality.", "labels": [], "entities": []}, {"text": "We proposed a simple greedy search algorithm to find the best ensemble combination effectively and efficiently.", "labels": [], "entities": []}, {"text": "Hypothesis combination () was also adopted to generate more diverse hypotheses for better reranking.", "labels": [], "entities": [{"text": "Hypothesis", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9514346122741699}]}, {"text": "For unsupervised tasks, we mainly investigated the methodology of unsupervised SMT and NMT () to build our baselines, then presented a joint training strategy on top of these baselines to boost their performances.", "labels": [], "entities": [{"text": "SMT", "start_pos": 79, "end_pos": 82, "type": "TASK", "confidence": 0.8998023271560669}]}, {"text": "This paper was structured as follows: we described the details of our novel Deep-Transformer in Section 2, then in Section 3 we presented an overview of our universal training flow for all supervised language pairs and the unsupervised methods.", "labels": [], "entities": []}, {"text": "The experiment settings and main results were shown in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "For all supervised tasks, we used deep selfattentional models as our baseline, and we also experimented the shallow and wide counterparts to verify its effectiveness with the same training corpus.", "labels": [], "entities": []}, {"text": "Preliminary experiments indicated that our deep models can even outperform the standard Transformer-Big by 0.7-1.3 BLEU scores on different language pairs.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 115, "end_pos": 119, "type": "METRIC", "confidence": 0.9986061453819275}]}, {"text": "All of our experiments employed 25/30 encoder layers and 6 decoder layers, both embedding and hidden size have a dimension of 512, 8 heads for the self-attention and encoder-decoder attention mechanisms.", "labels": [], "entities": []}, {"text": "We shared the target-side embedding and softmax matrix.", "labels": [], "entities": []}, {"text": "All BLEU scores were reported with mtevalv13a.pl 5 . Next, we will show details for different language pairs in the following subsections.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.9977174997329712}]}, {"text": "We implemented deep fashion models based on Tensor2Tensor, all models were trained on eight 1080Ti GPUs.", "labels": [], "entities": []}, {"text": "We used the Adam optimizer with \u03b2 1 = 0.97, \u03b2 2 = 0.997 and = 10 \u22126 as well as gradient accumulation due to the high GPU memory consumption.", "labels": [], "entities": []}, {"text": "The training data was reshuffled after finishing each training epoch, and we batched sentence pairs by target-side sentences lengths, with 8192 tokens per GPU.", "labels": [], "entities": []}, {"text": "Large learning rate and warmup-steps were chosen for faster convergence.", "labels": [], "entities": []}, {"text": "We set max learning rate as 0.002 and warmup-steps as 8000 for most language pairs including EN\u2194{ZH, RU, KK, LT}.", "labels": [], "entities": [{"text": "max learning rate", "start_pos": 7, "end_pos": 24, "type": "METRIC", "confidence": 0.9162231882413229}]}, {"text": "Specifically in EN\u2194DE task, 16000 warmup-steps achieved better results.", "labels": [], "entities": []}, {"text": "During training, we also employed label smoothing with a confidence score 0.9 and all the dropout probabilities were set to 0.1.", "labels": [], "entities": [{"text": "label smoothing", "start_pos": 34, "end_pos": 49, "type": "TASK", "confidence": 0.69129379093647}]}, {"text": "Furthermore, we averaged the last 15 checkpoints of a single training process for all language pairs.", "labels": [], "entities": []}, {"text": "The models were saved and validated every 20 minutes.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1.  Surprisingly, adding pseudo corpus hindered our  system improvement on newstest2019, yet gained  +3.7 BLEU improvement on newstest2018. One  possible explanation is that the construction of test  set in this year is different from those in previous  years.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 113, "end_pos": 117, "type": "METRIC", "confidence": 0.999271810054779}]}, {"text": " Table 1: Results for EN\u2194ZH on official WMT test", "labels": [], "entities": [{"text": "EN", "start_pos": 22, "end_pos": 24, "type": "METRIC", "confidence": 0.6281734108924866}, {"text": "official WMT test", "start_pos": 31, "end_pos": 48, "type": "DATASET", "confidence": 0.7701695561408997}]}, {"text": " Table 2: Results for EN\u2194DE on official WMT test set", "labels": [], "entities": [{"text": "DE", "start_pos": 25, "end_pos": 27, "type": "METRIC", "confidence": 0.8564784526824951}, {"text": "official WMT test set", "start_pos": 31, "end_pos": 52, "type": "DATASET", "confidence": 0.8365558087825775}]}, {"text": " Table  3. We observed the same phenomenon as in  EN\u2192ZH, where back-translation could yield bet- ter results on newstest2018 but inferior ones on  newstest2019.", "labels": [], "entities": [{"text": "newstest2018", "start_pos": 112, "end_pos": 124, "type": "DATASET", "confidence": 0.9521046876907349}, {"text": "newstest2019", "start_pos": 147, "end_pos": 159, "type": "DATASET", "confidence": 0.9549016952514648}]}, {"text": " Table 3: Results for EN\u2194RU on official WMT test set", "labels": [], "entities": [{"text": "EN", "start_pos": 22, "end_pos": 24, "type": "METRIC", "confidence": 0.7488769292831421}, {"text": "RU", "start_pos": 25, "end_pos": 27, "type": "METRIC", "confidence": 0.6105776429176331}, {"text": "official WMT test set", "start_pos": 31, "end_pos": 52, "type": "DATASET", "confidence": 0.8337972909212112}]}, {"text": " Table 4: Results for EN\u2194KK on official WMT test set", "labels": [], "entities": [{"text": "EN\u2194KK", "start_pos": 22, "end_pos": 27, "type": "TASK", "confidence": 0.43403716882069904}, {"text": "official WMT test set", "start_pos": 31, "end_pos": 52, "type": "DATASET", "confidence": 0.8329303413629532}]}, {"text": " Table 5: Results for EN\u2194LT on official WMT test set", "labels": [], "entities": [{"text": "EN\u2194LT", "start_pos": 22, "end_pos": 27, "type": "TASK", "confidence": 0.5401410758495331}, {"text": "official WMT test set", "start_pos": 31, "end_pos": 52, "type": "DATASET", "confidence": 0.8407833874225616}]}, {"text": " Table 6: Results for EN\u2192GU on official WMT test set", "labels": [], "entities": [{"text": "GU", "start_pos": 25, "end_pos": 27, "type": "METRIC", "confidence": 0.5692283511161804}, {"text": "official WMT test set", "start_pos": 31, "end_pos": 52, "type": "DATASET", "confidence": 0.7884020507335663}]}, {"text": " Table 7: Unsupervised results for DE\u2194CS on official  WMT test set, note that the newstest2019 contains 1997  sentence pairs for both directions", "labels": [], "entities": [{"text": "DE\u2194CS", "start_pos": 35, "end_pos": 40, "type": "DATASET", "confidence": 0.548791358868281}, {"text": "WMT test set", "start_pos": 54, "end_pos": 66, "type": "DATASET", "confidence": 0.820993592341741}]}]}