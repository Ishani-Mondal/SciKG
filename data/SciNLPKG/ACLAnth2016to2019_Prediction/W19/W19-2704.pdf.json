{"title": [{"text": "From News to Medical: Cross-domain Discourse Segmentation", "labels": [], "entities": [{"text": "Cross-domain Discourse Segmentation", "start_pos": 22, "end_pos": 57, "type": "TASK", "confidence": 0.7091270883878072}]}], "abstractContent": [{"text": "The first step in discourse analysis involves dividing a text into segments.", "labels": [], "entities": [{"text": "discourse analysis", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.7576513290405273}]}, {"text": "We annotate the first high-quality small-scale medical corpus in English with discourse segments and analyze how well news-trained segmenters perform on this domain.", "labels": [], "entities": []}, {"text": "While we expectedly find a drop in performance, the nature of the segmentation errors suggests some problems can be addressed earlier in the pipeline, while others would require expanding the corpus to a trainable size to learn the nuances of the medical domain.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 66, "end_pos": 78, "type": "TASK", "confidence": 0.9637384414672852}]}], "introductionContent": [{"text": "Dividing a text into units is the first step in analyzing a discourse.", "labels": [], "entities": []}, {"text": "In the framework of Rhetorical Structure Theory (RST), the segments are termed elementary discourse units (EDUs), and a complete RST-style discourse analysis consists of building EDUs into a tree that spans the entire document.", "labels": [], "entities": [{"text": "Rhetorical Structure Theory (RST)", "start_pos": 20, "end_pos": 53, "type": "TASK", "confidence": 0.8213000496228536}, {"text": "RST-style discourse analysis", "start_pos": 129, "end_pos": 157, "type": "TASK", "confidence": 0.8910784522692362}]}, {"text": "The tree edges are labeled with relations types, and nodes are categorized by their nuclearity (roughly, importance).", "labels": [], "entities": []}, {"text": "RST segmentation is often regarded as a solved problem because automated segmenters achieve high performance (F1=94.3) on a task with high inter-annotator agreement (kappa=0.92) ( ).", "labels": [], "entities": [{"text": "RST segmentation", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.9852346181869507}, {"text": "F1", "start_pos": 110, "end_pos": 112, "type": "METRIC", "confidence": 0.9975739121437073}]}, {"text": "In fact, many RST parsers do not include a segmenter and simply evaluate on gold EDUs.", "labels": [], "entities": [{"text": "RST parsers", "start_pos": 14, "end_pos": 25, "type": "TASK", "confidence": 0.9373037815093994}]}, {"text": "However, numerous studies have shown errors in segmentation area primary bottleneck for accurate discourse parsing.", "labels": [], "entities": [{"text": "accurate discourse parsing", "start_pos": 88, "end_pos": 114, "type": "TASK", "confidence": 0.5730945269266764}]}, {"text": "Notably, even when using a top-performing segmenter, results degrade by 10% on the downstream tasks of span, nuclearity and relation labeling when using predicted instead of gold EDUs.", "labels": [], "entities": [{"text": "relation labeling", "start_pos": 124, "end_pos": 141, "type": "TASK", "confidence": 0.7515622675418854}]}, {"text": "Separately, all available discourse segmenters are trained on news, and their ability to generalize to other domains, such as medical text, has not been well-studied.", "labels": [], "entities": []}, {"text": "In our work, we focus on the medical domain because it has garnered crossdisciplinary research interest with wide-reaching applications.", "labels": [], "entities": []}, {"text": "For example, the Biomedical Discourse Relation Bank was created for PDTBstyle discourse parsing of biomedical texts, and has been used to analyze author revisions and causal relations (.", "labels": [], "entities": [{"text": "Biomedical Discourse Relation", "start_pos": 17, "end_pos": 46, "type": "TASK", "confidence": 0.7112108469009399}, {"text": "PDTBstyle discourse parsing of biomedical texts", "start_pos": 68, "end_pos": 115, "type": "TASK", "confidence": 0.8489887018998464}, {"text": "author revisions", "start_pos": 146, "end_pos": 162, "type": "TASK", "confidence": 0.7152489125728607}]}, {"text": "This work studies discourse segmentation in the medical domain.", "labels": [], "entities": [{"text": "discourse segmentation", "start_pos": 18, "end_pos": 40, "type": "TASK", "confidence": 0.7230379432439804}]}, {"text": "In particular, we: (1) seek to identify difficulties that news-trained segmenters have on medical; (2) investigate how features of the segmenter impact the type of errors seen in medical; and (3) examine the relationship between annotator agreement and segmenter performance for different types of medical data.", "labels": [], "entities": []}, {"text": "To this end, we present the first small-scale medical corpus in English, annotated by trained linguists (sample in).", "labels": [], "entities": []}, {"text": "We evaluate this corpus with three RST segmenters, finding an expected gap in the medical domain.", "labels": [], "entities": [{"text": "RST segmenters", "start_pos": 35, "end_pos": 49, "type": "TASK", "confidence": 0.8715077936649323}]}, {"text": "We perform a detailed error analysis that shows medical-specific punctuation is the largest source of errors in the medical domain, followed by different word usage in syntactic constructions which are likely caused by news-derived word embeddings.", "labels": [], "entities": []}, {"text": "Second, by comparing segmenters which use word embeddings versus syntax trees, we find access to parsed trees may not be helpful in reducing syntactically-resolvable errors, while an improved tokenizer would provide small benefits.", "labels": [], "entities": []}, {"text": "Third, we note patterns between humans and segmenters where both perform better on extremely short texts and worse on those with more complex discourse.", "labels": [], "entities": []}, {"text": "We conclude with suggestions to improve the segmenter on the medical domain and recommendations for future annotation experiments.", "labels": [], "entities": []}, {"text": "Our contributions in this work are two-fold: a high-quality small-scale corpus of medical documents annotated with RST-style discourse segments; a quantitative and qualitative analysis of the discourse segmentation errors in the medical domain that lays the groundwork for understanding both the strengths and limits of existing RST segmenters, and the next concrete steps towards a better segmenter for the medical domain.", "labels": [], "entities": [{"text": "RST-style discourse segments", "start_pos": 115, "end_pos": 143, "type": "TASK", "confidence": 0.8406244317690531}, {"text": "RST segmenters", "start_pos": 329, "end_pos": 343, "type": "TASK", "confidence": 0.8929449021816254}]}], "datasetContent": [{"text": "We automatically segment the documents in RST-DT SMALL and MEDICAL using three segmenters: (1) DPLP 3 uses features from syntactic and dependency parses fora linear support vector classifier; (2)TWO-PASS) is a CRF segmenter that derives features from syntax parses but also uses global features to perform a second pass of segmentation; (3) NEURAL ( ) is a neural BiLSTM-CRF model that uses ELMo embeddings ().", "labels": [], "entities": [{"text": "RST-DT SMALL", "start_pos": 42, "end_pos": 54, "type": "TASK", "confidence": 0.6926592886447906}]}, {"text": "We choose these segmenters because they are widelyused and publicly available (most RST parsers do not include a segmenter).", "labels": [], "entities": []}, {"text": "DPLP has been cited in several works showing discourse helps on different NLP tasks (  trees.", "labels": [], "entities": []}, {"text": "NEURAL now holds SOTA in RST discourse segmentation.", "labels": [], "entities": [{"text": "NEURAL", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9150577783584595}, {"text": "SOTA", "start_pos": 17, "end_pos": 21, "type": "METRIC", "confidence": 0.9246322512626648}, {"text": "RST discourse segmentation", "start_pos": 25, "end_pos": 51, "type": "TASK", "confidence": 0.9261852105458578}]}, {"text": "We evaluate the segmenter's ability to detect all EDU boundaries present in the gold data (not just intra-sentential) using the metrics of precision (P), recall (R) and F1.", "labels": [], "entities": [{"text": "precision (P)", "start_pos": 139, "end_pos": 152, "type": "METRIC", "confidence": 0.9551226943731308}, {"text": "recall (R)", "start_pos": 154, "end_pos": 164, "type": "METRIC", "confidence": 0.9600512236356735}, {"text": "F1", "start_pos": 169, "end_pos": 171, "type": "METRIC", "confidence": 0.9966500401496887}]}, {"text": "The DPLP and TWO-PASS segmenters, both of which employ the Stanford Core NLP pipeline (), were updated to use the same version of this software (2018-10-05).", "labels": [], "entities": [{"text": "DPLP", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.8240538835525513}, {"text": "TWO-PASS segmenters", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.6306646764278412}, {"text": "Stanford Core NLP pipeline", "start_pos": 59, "end_pos": 85, "type": "DATASET", "confidence": 0.9295071363449097}]}, {"text": "lists our results on News and Medical for correctly identifying EDU boundaries using the three discourse segmenters.", "labels": [], "entities": [{"text": "News and Medical", "start_pos": 21, "end_pos": 37, "type": "DATASET", "confidence": 0.8809695243835449}]}, {"text": "As expected, the News domain outperforms the Medical domain, regardless of which segmenter is used.", "labels": [], "entities": [{"text": "News domain", "start_pos": 17, "end_pos": 28, "type": "DATASET", "confidence": 0.9085346460342407}, {"text": "Medical domain", "start_pos": 45, "end_pos": 59, "type": "DATASET", "confidence": 0.919358640909195}]}, {"text": "In the case of the DPLP segmenter, the gap between the two domains is about 7.4 F1 points.", "labels": [], "entities": [{"text": "DPLP segmenter", "start_pos": 19, "end_pos": 33, "type": "TASK", "confidence": 0.623934730887413}, {"text": "F1", "start_pos": 80, "end_pos": 82, "type": "METRIC", "confidence": 0.9962802529335022}]}, {"text": "Note that the performance of DPLP on News lags considerably behind the state of the art (-14.76 F1 points).", "labels": [], "entities": [{"text": "DPLP on News", "start_pos": 29, "end_pos": 41, "type": "DATASET", "confidence": 0.6316277285416921}, {"text": "F1", "start_pos": 96, "end_pos": 98, "type": "METRIC", "confidence": 0.9967229962348938}]}, {"text": "When switching to the TWO-PASS segmenter, the performance on News increases dramatically (+13 F1 points).", "labels": [], "entities": [{"text": "TWO-PASS segmenter", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.6975659728050232}, {"text": "News", "start_pos": 61, "end_pos": 65, "type": "DATASET", "confidence": 0.9586990475654602}, {"text": "F1", "start_pos": 94, "end_pos": 96, "type": "METRIC", "confidence": 0.9943976402282715}]}, {"text": "However, the performance on Medical increases by only 3.75 F1 points.", "labels": [], "entities": [{"text": "Medical", "start_pos": 28, "end_pos": 35, "type": "DATASET", "confidence": 0.9705784916877747}, {"text": "F1", "start_pos": 59, "end_pos": 61, "type": "METRIC", "confidence": 0.9993276596069336}]}, {"text": "Thus, large gains in News translate into only a small gain in Medical.", "labels": [], "entities": [{"text": "News", "start_pos": 21, "end_pos": 25, "type": "DATASET", "confidence": 0.9178407192230225}, {"text": "Medical", "start_pos": 62, "end_pos": 69, "type": "METRIC", "confidence": 0.7454437017440796}]}, {"text": "The NEURAL segmenter achieves the best performance on News and is also able to more successfully close the gap on Medical, with only a 5.64 F1 difference, largely attributable to lower recall.", "labels": [], "entities": [{"text": "NEURAL segmenter", "start_pos": 4, "end_pos": 20, "type": "TASK", "confidence": 0.6257573813199997}, {"text": "News", "start_pos": 54, "end_pos": 58, "type": "DATASET", "confidence": 0.9638804197311401}, {"text": "Medical", "start_pos": 114, "end_pos": 121, "type": "DATASET", "confidence": 0.4849976599216461}, {"text": "F1 difference", "start_pos": 140, "end_pos": 153, "type": "METRIC", "confidence": 0.9784661829471588}, {"text": "recall", "start_pos": 185, "end_pos": 191, "type": "METRIC", "confidence": 0.9991409778594971}]}], "tableCaptions": [{"text": " Table 3: F1, precision (P) and recall (R) of RST dis- course segmenters on two domains (best numbers for  News are underlined, for Medical are bolded).", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.999752938747406}, {"text": "precision (P)", "start_pos": 14, "end_pos": 27, "type": "METRIC", "confidence": 0.9499388784170151}, {"text": "recall (R)", "start_pos": 32, "end_pos": 42, "type": "METRIC", "confidence": 0.9618291109800339}, {"text": "RST dis- course segmenters", "start_pos": 46, "end_pos": 72, "type": "TASK", "confidence": 0.8566979169845581}]}, {"text": " Table 5: Average inter-annotator agreement per sec- tion, ordered from highest to lowest, the corresponding  average F1 of the NEURAL segmenter, and number of  tokens (there are 2 documents per section, except 1 for  Summary).", "labels": [], "entities": [{"text": "F1", "start_pos": 118, "end_pos": 120, "type": "METRIC", "confidence": 0.9932335019111633}, {"text": "NEURAL segmenter", "start_pos": 128, "end_pos": 144, "type": "TASK", "confidence": 0.48723073303699493}]}]}