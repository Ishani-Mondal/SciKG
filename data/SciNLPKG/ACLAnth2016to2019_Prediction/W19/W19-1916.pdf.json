{"title": [{"text": "Medical Word Embeddings for Spanish: Development and Evaluation", "labels": [], "entities": []}], "abstractContent": [{"text": "Word embeddings are representations of words in a dense vector space.", "labels": [], "entities": []}, {"text": "Although they are not recent phenomena in Natural Language Processing (NLP), they have gained momentum after the recent developments of neural methods and Word2Vec.", "labels": [], "entities": [{"text": "Natural Language Processing (NLP)", "start_pos": 42, "end_pos": 75, "type": "TASK", "confidence": 0.7018618981043497}, {"text": "Word2Vec", "start_pos": 155, "end_pos": 163, "type": "DATASET", "confidence": 0.926332414150238}]}, {"text": "Regarding their applications in medical and clinical NLP, they are invaluable resources when training in-domain named entity recognition systems, classifiers or taggers, for instance.", "labels": [], "entities": []}, {"text": "Thus, the development of tailored word embeddings for medical NLP is of great interest.", "labels": [], "entities": []}, {"text": "However, we identified a gap in the literature which we aim to fill in this paper: the availability of embeddings for medical NLP in Spanish, as well as a standardized form of intrinsic evaluation.", "labels": [], "entities": []}, {"text": "Since most work has been done for English, some established datasets for intrinsic evaluation are already available.", "labels": [], "entities": []}, {"text": "In this paper, we show the steps we employed to adapt such datasets for the first time to Spanish, of particular relevance due to the considerable volume of EHRs in this language, as well as the creation of in-domain medical word embeddings for the Spanish using the state-of-the-art Fast-Text model.", "labels": [], "entities": []}, {"text": "We performed intrinsic evaluation with our adapted datasets, as well as ex-trinsic evaluation with a named entity recognition systems using a baseline embedding of general-domain.", "labels": [], "entities": []}, {"text": "Both experiments proved that our embeddings are suitable for use in medical NLP in the Spanish language, and are more accurate than general-domain ones.", "labels": [], "entities": []}], "introductionContent": [{"text": "Representation of words in vector space, or word embedding, is not anew concept in Natural Language Processing (NLP) and are used in a several number of statistical and neural models (.", "labels": [], "entities": [{"text": "Representation of words in vector space", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.8433061639467875}]}, {"text": "Word embeddings (WE) can include semantic information and are based on the general idea of an association of elements (words) with certain contexts and the similarity in word meanings.", "labels": [], "entities": [{"text": "Word embeddings (WE)", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.6668047428131103}]}, {"text": "In more recent neural networks, embeddings are used to encode words in a space that is subsequently used as input for many possible models.", "labels": [], "entities": []}], "datasetContent": [{"text": "For the evaluation of our embeddings, we use both intrinsic and extrinsic evaluation, which are now detailed, as well as the baseline word embedding.", "labels": [], "entities": []}, {"text": "In this section, we detail how the experiments were carried out and the results we obtained for both intrinsic and extrinsic evaluation methods, as well as the comparisons with the baseline embedding presented in Section 3.2.3 and our embeddings, which we now call Spanish Health Embedding (SHE).", "labels": [], "entities": [{"text": "Spanish Health Embedding (SHE)", "start_pos": 265, "end_pos": 295, "type": "DATASET", "confidence": 0.8329469362894694}]}, {"text": "In, we show the PCA (Principal Component Analysis) projections of our embeddings and the SBWC, respectively.", "labels": [], "entities": []}, {"text": "We tried to follow the standards of to categorize the terms using UMLS semantic types in the following categories: symptoms, diseases and drugs.", "labels": [], "entities": []}, {"text": "Better quality and larger figures can be accessed online 12 Comparison of the extrinsic evaluation between the proposed embeddings (SHE) and the general-domain ones (SBWC).", "labels": [], "entities": []}, {"text": "Bold numbers represent the best results for each metric and data parition, with Val meaning validation set.", "labels": [], "entities": [{"text": "data parition", "start_pos": 60, "end_pos": 73, "type": "TASK", "confidence": 0.7200458347797394}, {"text": "Val", "start_pos": 80, "end_pos": 83, "type": "METRIC", "confidence": 0.9726945161819458}]}, {"text": "One can notice that in, there is some overlapping between the disease and symptoms categories, but they are not as much overlapped as shown in.", "labels": [], "entities": []}, {"text": "In addition, in our embeddings, on the top of the drugs cluster, one can see that most of the antibiotics are clustered together (e.g. penicilina, eritromicina, cefazolina, doxiciclina).", "labels": [], "entities": []}, {"text": "However, in the SBWC projection, such drugs are spread inside the cluster.", "labels": [], "entities": [{"text": "SBWC projection", "start_pos": 16, "end_pos": 31, "type": "DATASET", "confidence": 0.8029199242591858}]}, {"text": "Interestingly, for both embeddings, the words hierro, calamina, ajo, alcohol are the ones that are more closer to the other two clusters.", "labels": [], "entities": []}, {"text": "Figure 2: PCA projection of the UMNSRS concepts using our embeddings.", "labels": [], "entities": [{"text": "UMNSRS", "start_pos": 32, "end_pos": 38, "type": "DATASET", "confidence": 0.8140268921852112}]}, {"text": "Black means symptoms-related terms, red means disease-related terms, while green means drug-related terms.", "labels": [], "entities": []}], "tableCaptions": []}