{"title": [{"text": "Ensemble Methods to Distinguish Mainland and Taiwan Chinese", "labels": [], "entities": [{"text": "Distinguish Mainland and Taiwan", "start_pos": 20, "end_pos": 51, "type": "TASK", "confidence": 0.6224693432450294}]}], "abstractContent": [{"text": "This paper describes the IUCL system at Var-Dial 2019 evaluation campaign for the task of discriminating between Mainland and Taiwan variation of mandarin Chinese.", "labels": [], "entities": [{"text": "IUCL system at Var-Dial 2019 evaluation", "start_pos": 25, "end_pos": 64, "type": "DATASET", "confidence": 0.7562442471583685}]}, {"text": "We first build several base classifiers, including a Naive Bayes classifier with word n-gram as features, SVMs with both character and syntactic features , and neural networks with pre-trained character/word embeddings.", "labels": [], "entities": []}, {"text": "Then we adopt ensemble methods to combine output from base classifiers to make final predictions.", "labels": [], "entities": []}, {"text": "Our ensemble models achieve the highest F1 score (0.893) in simplified Chinese track and the second highest (0.901) in traditional Chinese track.", "labels": [], "entities": [{"text": "F1 score (0.893)", "start_pos": 40, "end_pos": 56, "type": "METRIC", "confidence": 0.9598073720932007}]}, {"text": "Our results demonstrate the effectiveness and robustness of the ensemble method.", "labels": [], "entities": []}], "introductionContent": [{"text": "Like many other languages in the world, Mandarin has several varieties among different speaking communities, mainland China, Taiwan, Malaysia, Indonesia, etc.", "labels": [], "entities": []}, {"text": "Previous research on these varieties are mainly focused on language differences and integration.", "labels": [], "entities": []}, {"text": "Discriminating between the Mainland and Taiwan variations of Mandarin Chinese (DMT) is one of the shared tasks at VarDial evaluation campaign 2019, aiming to determine if a given sentence is taken from news articles from Mainland China or Taiwan ().", "labels": [], "entities": [{"text": "Discriminating between the Mainland and Taiwan variations of Mandarin Chinese (DMT)", "start_pos": 0, "end_pos": 83, "type": "TASK", "confidence": 0.6461696647680722}, {"text": "VarDial evaluation campaign 2019", "start_pos": 114, "end_pos": 146, "type": "DATASET", "confidence": 0.8661071211099625}]}, {"text": "This task not only serves as a platform to test various models, but also encourages linguists to rethink the different linguistic features among those varieties.", "labels": [], "entities": []}, {"text": "This paper describes the IUCL (Indiana University Computational Linguistics) systems and submissions at VarDial 2019.", "labels": [], "entities": [{"text": "IUCL (Indiana University Computational Linguistics)", "start_pos": 25, "end_pos": 76, "type": "TASK", "confidence": 0.577281334570476}, {"text": "VarDial 2019", "start_pos": 104, "end_pos": 116, "type": "DATASET", "confidence": 0.9106979966163635}]}, {"text": "We first build several base classifiers: a Naive Bayes classifier with word n-gram as features, Support Vector Machines (SVM) using both character and syntactic features, * Equal contribution and neural networks such as LSTM and BERT.", "labels": [], "entities": [{"text": "BERT", "start_pos": 229, "end_pos": 233, "type": "METRIC", "confidence": 0.9607970714569092}]}, {"text": "We then build ensemble models by using the maximum probability among all base classifiers, or choosing the class with maximum average probability, or training another SVM on top of the output of base classifiers.", "labels": [], "entities": []}, {"text": "We apply the three ensemble models for both the simplified Chinese track and the traditional Chinese track, which also correspond to our three submissions on both tracks.", "labels": [], "entities": []}, {"text": "As shown in the official evaluation results, our SVM ensemble is ranked the first place on the simplified Chinese test data with a macro-averaged F1 score of 0.893, and our ensemble model using maximum probability from base classifiers ranked second on the traditional Chinese test data with a macro-averaged F1 score of 0.901.", "labels": [], "entities": [{"text": "Chinese test data", "start_pos": 106, "end_pos": 123, "type": "DATASET", "confidence": 0.682148943344752}, {"text": "F1 score", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.9710690677165985}, {"text": "F1 score", "start_pos": 309, "end_pos": 317, "type": "METRIC", "confidence": 0.9756859540939331}]}, {"text": "In this paper, we will briefly review related work in Section 2, describe our single classifiers and three ensemble methods in Section 3, and finally present and discuss our results in Section 4, with a conclusion in Section 5.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Macro-averaged F score on development set for simplified and traditional Chinese. BERT: classifier  using BERT pre-trained Chinese model. LSTM: word-level LSTM. SEQ: word-level sequential model classifier.  EMB: neural network using pre-trained Chinese word embeddings. NB: word-level Naive-Bayes model. SYN:  SVM with syntactic features.", "labels": [], "entities": [{"text": "F score", "start_pos": 25, "end_pos": 32, "type": "METRIC", "confidence": 0.946988582611084}, {"text": "BERT", "start_pos": 92, "end_pos": 96, "type": "METRIC", "confidence": 0.9960938096046448}, {"text": "BERT", "start_pos": 116, "end_pos": 120, "type": "METRIC", "confidence": 0.9079907536506653}]}, {"text": " Table 2: Macro-averaged F score on test set for simplified and traditional Chinese using ensemble models.", "labels": [], "entities": [{"text": "F score", "start_pos": 25, "end_pos": 32, "type": "METRIC", "confidence": 0.9713447093963623}]}, {"text": " Table 3: Top 20 features selected by information gain", "labels": [], "entities": []}]}