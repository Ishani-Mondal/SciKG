{"title": [{"text": "A Systematic Comparison of English Noun Compound Representations", "labels": [], "entities": [{"text": "Systematic Comparison of English Noun Compound Representations", "start_pos": 2, "end_pos": 64, "type": "TASK", "confidence": 0.6069626723017011}]}], "abstractContent": [{"text": "Building meaningful representations of noun compounds is not trivial since many of them scarcely appear in the corpus.", "labels": [], "entities": []}, {"text": "To that end, composition functions approximate the distri-butional representation of a noun compound by combining its constituent distributional vectors.", "labels": [], "entities": []}, {"text": "In the more general case, phrase embeddings have been trained by minimizing the distance between the vectors representing paraphrases.", "labels": [], "entities": []}, {"text": "We compare various types of noun compound representations, including distributional, compositional, and paraphrase-based representations, through a series of tasks and analyses, and with an extensive number of underlying word embeddings.", "labels": [], "entities": []}, {"text": "We find that indeed, inmost cases, composition functions produce higher quality representations than distributional ones, and they improve with computational power.", "labels": [], "entities": []}, {"text": "No single function performs best in all scenarios, suggesting that a joint training objective may produce improved representations.", "labels": [], "entities": []}], "introductionContent": [{"text": "The simplest way to obtain a vector representation fora multiword term is to treat it as a single token, e.g. by replacing spaces with underscores, and train a standard word embedding algorithm.", "labels": [], "entities": []}, {"text": "This is typically done for common n-grams, which often include named entities (e.g. New York), but in theory can also be based on syntactic criteria, for instance in order to learn noun compound vectors.", "labels": [], "entities": []}, {"text": "The main issue with this approach is that word embedding algorithms require sufficient term frequency to obtain meaningful representations, and many noun compounds rarely occur in text corpora ().", "labels": [], "entities": []}, {"text": "To overcome the sparsity issue, it is common to learn a composition function which computes a noun compound vector from its constituents' distributional representations, e.g. vec(cost estimate) = f(vec(cost), vec(estimate)).", "labels": [], "entities": []}, {"text": "Various functions have been proposed in the literature, typically based on vector arithmetics (e.g..", "labels": [], "entities": []}, {"text": "Such functions are learned with the objective of minimizing the distance between the observed (distributional) vector and the composed vector of each noun compound, and most functions are limited to binary noun compounds.", "labels": [], "entities": []}, {"text": "A parallel line of work computes phrase embeddings for variable-length phrases, by adapting the word embedding training objective or by minimizing the distance between the representations of paraphrases.", "labels": [], "entities": []}, {"text": "Paraphrase-based phrase embeddings require a large number of paraphrases as training instances.", "labels": [], "entities": [{"text": "Paraphrase-based phrase embeddings", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7872272928555807}]}, {"text": "Such paraphrases are often generated by translating an English phrase into a foreign language and back to English, considering variations in translation as paraphrases.", "labels": [], "entities": []}, {"text": "This technique is referred to as \"bilingual pivoting\" or \"backtranslation\" (.", "labels": [], "entities": []}, {"text": "In this work we test the quality of noun compound representations produced by different methods, including distributional representations, composition functions, and paraphrase-based phrase embeddings.", "labels": [], "entities": []}, {"text": "We extend the work of, who evaluated various composition functions on the noun compound relation classification task, in several aspects.", "labels": [], "entities": [{"text": "noun compound relation classification task", "start_pos": 74, "end_pos": 116, "type": "TASK", "confidence": 0.7810280084609985}]}, {"text": "First, we test a broader range of representations, which may differ both in their architectures and in their training objectives.", "labels": [], "entities": []}, {"text": "Second, we train each representation with a wide variety of underlying word embeddings, and analyze the representation's behaviour across the different word embeddings.", "labels": [], "entities": []}, {"text": "Finally, we use several tasks to evaluate the representation quality: relation classification (what is the relationship between the constituents?), property classification (is a cheese wheel round?), as well as a qualitative and quantitative analysis of the nearest neighbours.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 70, "end_pos": 93, "type": "TASK", "confidence": 0.804163783788681}, {"text": "property classification", "start_pos": 148, "end_pos": 171, "type": "TASK", "confidence": 0.7308473885059357}]}, {"text": "The results confirm that the distributional representations of rare noun compounds are indeed of low quality.", "labels": [], "entities": []}, {"text": "Across representations, the nearest neighbours of a target noun compound vector typically include many trivial similarities such as other noun compounds with a shared constituent.", "labels": [], "entities": []}, {"text": "Among the composition functions, functions with more computational power and parameters generally produced higher quality representations.", "labels": [], "entities": []}, {"text": "The paraphrase-based functions outperformed the others in the property prediction task, while the compositional functions performed better on relation classification.", "labels": [], "entities": [{"text": "property prediction", "start_pos": 62, "end_pos": 81, "type": "TASK", "confidence": 0.7383241653442383}, {"text": "relation classification", "start_pos": 142, "end_pos": 165, "type": "TASK", "confidence": 0.8460041880607605}]}, {"text": "The results suggest that learning a composition function with a combined training objective is a promising research direction that may result in improved noun compound representations.", "labels": [], "entities": [{"text": "noun compound representations", "start_pos": 154, "end_pos": 183, "type": "TASK", "confidence": 0.77670951684316}]}], "datasetContent": [{"text": "We compare the various representations in 3 experiments: an analysis of the nearest neighbours of each noun compound vector (Section 3.1), an evaluation on property prediction (Section 3.2), and an evaluation on noun compound relation classification (Section 3.3).", "labels": [], "entities": [{"text": "property prediction", "start_pos": 156, "end_pos": 175, "type": "TASK", "confidence": 0.7568779587745667}, {"text": "noun compound relation classification", "start_pos": 212, "end_pos": 249, "type": "TASK", "confidence": 0.6947518438100815}]}, {"text": "We evaluate on the Tratz (2011) dataset, which consists of 19,158 instances, labeled in 37 finegrained relations or 12 coarse-grained relations.", "labels": [], "entities": [{"text": "Tratz (2011) dataset", "start_pos": 19, "end_pos": 39, "type": "DATASET", "confidence": 0.6062122762203217}]}, {"text": "We follow the data splits from Shwartz and, reporting performance on both the random split and the lexical split, in which there are no shared constituents between the train, validation, and test sets.", "labels": [], "entities": []}, {"text": "Since we focus on compositional noun compounds, we remove the LEXI-CALIZED relation (which consists of many noncompositional noun compounds).", "labels": [], "entities": [{"text": "LEXI-CALIZED", "start_pos": 62, "end_pos": 74, "type": "METRIC", "confidence": 0.9958479404449463}]}, {"text": "We also remove the PERSONAL NAME and PERSONAL TITLE relations which consist of named entities.", "labels": [], "entities": [{"text": "PERSONAL", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.6736078262329102}, {"text": "NAME", "start_pos": 28, "end_pos": 32, "type": "METRIC", "confidence": 0.48719945549964905}, {"text": "PERSONAL", "start_pos": 37, "end_pos": 45, "type": "DATASET", "confidence": 0.5912820100784302}, {"text": "TITLE", "start_pos": 46, "end_pos": 51, "type": "METRIC", "confidence": 0.6381606459617615}]}, {"text": "We train various classifiers on the vectors obtained by each DSM fora given noun compound, choosing the best performing classifier with respect to the validation F 1 score.", "labels": [], "entities": [{"text": "validation F 1 score", "start_pos": 151, "end_pos": 171, "type": "METRIC", "confidence": 0.6941784992814064}]}, {"text": "It is important to note that the categorization of noun compounds to a fixed inventory of semantic relations that may hold between their constituents is often subjective, making the data noisy.", "labels": [], "entities": []}, {"text": "Previous work suggested that many noun compounds fit into more than one relation, and that some relations in the fine-grained version of the data are overlapping.", "labels": [], "entities": []}, {"text": "With that said, this data is still a useful proxy for measuring and comparing the quality of representations.", "labels": [], "entities": []}, {"text": "shows the mean and the standard deviation of F 1 scores per representation across DSMs, while displays the best DSM for each dataset.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 45, "end_pos": 55, "type": "METRIC", "confidence": 0.9350076715151469}, {"text": "DSM", "start_pos": 112, "end_pos": 115, "type": "DATASET", "confidence": 0.839424729347229}]}], "tableCaptions": [{"text": " Table 2: Mean and standard deviation of F 1 scores across DSMs, for each representation and property combination.  The majority baseline F 1 score is 0 for all properties, since it always predicts False.", "labels": [], "entities": [{"text": "Mean", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9927984476089478}, {"text": "standard deviation of F 1 scores", "start_pos": 19, "end_pos": 51, "type": "METRIC", "confidence": 0.8236072560151418}, {"text": "F 1 score", "start_pos": 138, "end_pos": 147, "type": "METRIC", "confidence": 0.9001589814821879}, {"text": "False", "start_pos": 198, "end_pos": 203, "type": "METRIC", "confidence": 0.9822539687156677}]}, {"text": " Table 3: The performance of the best setting for each property.", "labels": [], "entities": []}, {"text": " Table 4: Mean and standard deviation of F 1 scores across word embeddings, windows and dimensions, for each  composition function and dataset combination.", "labels": [], "entities": [{"text": "Mean", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9954786896705627}, {"text": "standard deviation of F 1 scores", "start_pos": 19, "end_pos": 51, "type": "METRIC", "confidence": 0.8315777083237966}]}, {"text": " Table 5: The performance of the best setting for each noun compound relation classification dataset.", "labels": [], "entities": [{"text": "noun compound relation classification", "start_pos": 55, "end_pos": 92, "type": "TASK", "confidence": 0.6435813829302788}]}]}