{"title": [{"text": "The BLCU System in the BEA 2019 Shared Task", "labels": [], "entities": [{"text": "BLCU", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.703800618648529}, {"text": "BEA 2019 Shared Task", "start_pos": 23, "end_pos": 43, "type": "DATASET", "confidence": 0.9444057047367096}]}], "abstractContent": [{"text": "This paper describes the BLCU Group submissions to the Building Educational Applications (BEA) 2019 Shared Task on Grammatical Error Correction (GEC).", "labels": [], "entities": [{"text": "BLCU Group", "start_pos": 25, "end_pos": 35, "type": "DATASET", "confidence": 0.8942572176456451}, {"text": "Building Educational Applications (BEA) 2019 Shared Task on Grammatical Error Correction (GEC)", "start_pos": 55, "end_pos": 149, "type": "TASK", "confidence": 0.6032678261399269}]}, {"text": "The task is to detect and correct grammatical errors that occurred in essays.", "labels": [], "entities": []}, {"text": "We participate in 2 tracks including the Restricted Track and the Unrestricted Track.", "labels": [], "entities": []}, {"text": "Our system is based on a Transformer model architecture.", "labels": [], "entities": []}, {"text": "We integrate many effective methods proposed in recent years, such as Byte Pair Encoding, model ensemble, checkpoints average and spellchecker.", "labels": [], "entities": []}], "introductionContent": [{"text": "The GEC task has attracted wide interest in recent years.", "labels": [], "entities": [{"text": "GEC task", "start_pos": 4, "end_pos": 12, "type": "DATASET", "confidence": 0.7329323291778564}]}, {"text": "The goal of GEC is to detect and correct errors in essays made by English as a Second Language (ESL) learners.", "labels": [], "entities": [{"text": "correct errors in essays made by English as a Second Language (ESL) learners", "start_pos": 33, "end_pos": 109, "type": "TASK", "confidence": 0.6886497775713603}]}, {"text": "Since the end of both CoNLL2013 ( ) and CoNLL2014 (), many GEC researchers have used the two test sets as benchmark evaluation sets.", "labels": [], "entities": [{"text": "CoNLL2013", "start_pos": 22, "end_pos": 31, "type": "DATASET", "confidence": 0.8567248582839966}, {"text": "CoNLL2014", "start_pos": 40, "end_pos": 49, "type": "DATASET", "confidence": 0.9015873074531555}]}, {"text": "Because of using different training sets, such as Lang-8, NUCLE, FCE, the performance of the systems are not comparable, even though they are evaluated on the same test sets.", "labels": [], "entities": [{"text": "Lang-8", "start_pos": 50, "end_pos": 56, "type": "DATASET", "confidence": 0.9692832827568054}, {"text": "NUCLE", "start_pos": 58, "end_pos": 63, "type": "DATASET", "confidence": 0.9076184034347534}, {"text": "FCE", "start_pos": 65, "end_pos": 68, "type": "METRIC", "confidence": 0.682364821434021}]}, {"text": "The Building Educational Applications 2019 Shared Task provides a forum for participating teams to evaluate on the same blind test set using the same training sets and evaluation metric.", "labels": [], "entities": [{"text": "Building Educational Applications 2019 Shared Task", "start_pos": 4, "end_pos": 54, "type": "TASK", "confidence": 0.7905685404936472}]}, {"text": "The distribution of different levels is shown in.", "labels": [], "entities": []}, {"text": "The training set includes essays at different levels of language ability, but no articles written by native students.", "labels": [], "entities": []}, {"text": "There are three tracks in this shared task: Restricted Track, Unrestricted Track and Low Resource Track.", "labels": [], "entities": []}, {"text": "Each sub-task restricts the error-corrected corpus that can be used except the Unrestricted Track.", "labels": [], "entities": []}, {"text": "It means that the model needs to learn useful information from a large number of data written by ESL in order to correct the errors written by native learners.", "labels": [], "entities": []}, {"text": "In this paper, we describe the submissions from the group of Beijing Language and Culture University (BLCU) in the first two tracks.", "labels": [], "entities": [{"text": "Beijing Language and Culture University (BLCU)", "start_pos": 61, "end_pos": 107, "type": "DATASET", "confidence": 0.9188184589147568}]}, {"text": "This shared task aims to tackle the full set of grammar errors, classified into 56 kinds of errors.", "labels": [], "entities": []}, {"text": "More types of errors represent an increase in difficulty.", "labels": [], "entities": [{"text": "difficulty", "start_pos": 46, "end_pos": 56, "type": "METRIC", "confidence": 0.9680414795875549}]}, {"text": "Subtask one of the shared task (Restricted Track) restricts participants to use only the learner corpus provided by the organizers.", "labels": [], "entities": []}, {"text": "We believe that effective use of monolingual data will enable the model to achieve better performance.", "labels": [], "entities": []}, {"text": "Therefore, we propose a data augmentation method to corrupt a monolingual corpus with a fixed probability according to the proportion of errors in the development set and integrate many techniques proposed in recent years.", "labels": [], "entities": []}, {"text": "We also participate in the second subtask (Unrestricted Track) which allows participants to use any learner corpus.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we will detail the data sets, the hyper-parameters and the open source tools we use.", "labels": [], "entities": []}, {"text": "In) to train transformer with inverse squared root schedule which decays the learning rate based on the inverse square root of the warm-up steps.", "labels": [], "entities": []}, {"text": "The initial learning rate is 5 \u00d7 10 \u22124 and the warm-up step is set to be 4000.", "labels": [], "entities": []}, {"text": "We use a batch size of approximately 32,000 tokens and fine-tune the model on learner corpus for 50,000 steps.", "labels": [], "entities": []}, {"text": "Dropout is applied at a ratio of 0.3.", "labels": [], "entities": []}, {"text": "The loss factor \u039b is set to 1.2.", "labels": [], "entities": [{"text": "loss factor \u039b", "start_pos": 4, "end_pos": 17, "type": "METRIC", "confidence": 0.837525208791097}]}, {"text": "The ensemble model is composed of 8 identical Transformers trained and fine-tuned separately.", "labels": [], "entities": []}, {"text": "The only difference between them is that they use different random seeds.", "labels": [], "entities": []}, {"text": "During model inference, we run beam search with the emsemble model and set the beam size to 12.", "labels": [], "entities": []}, {"text": "We use ERRANT 8 to evaluate the decoding results.", "labels": [], "entities": [{"text": "ERRANT 8", "start_pos": 7, "end_pos": 15, "type": "METRIC", "confidence": 0.9439749419689178}]}, {"text": "shows the performance of our model with different settings.", "labels": [], "entities": []}, {"text": "For the without LM Spell Checker columns, we do not use language model based spellchecker to correct spelling mistakes, while with LM Spell Checker is the opposite.", "labels": [], "entities": []}, {"text": "The first two lines report the result with a single Transformer model, and the last line with the ensemble model.", "labels": [], "entities": []}, {"text": "+ CC means that we pretrain the transformer model using the corrupted corpus and then fine-tune with learner corpus.", "labels": [], "entities": []}, {"text": "We submit the best model, namely the ensemble model, for the shared task.", "labels": [], "entities": []}, {"text": "In, we can see that the main contribution comes from the corruption method.", "labels": [], "entities": []}, {"text": "About 20 million monolingual data have brought about an increase of 3.06 in terms of F-measure on a single model.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 85, "end_pos": 94, "type": "METRIC", "confidence": 0.9953599572181702}]}, {"text": "The spellchecker based on the language model improves the performance of the model by about one point.", "labels": [], "entities": []}, {"text": "We use an ensemble of identical models (except for the random seed), but we will attempt to use different types of models in future work.", "labels": [], "entities": []}, {"text": "shows the result on the test set which is evaluated by the organizers.", "labels": [], "entities": []}, {"text": "Comparing the results of the two tracks, we find that training with the Non-public Lang-8 data can significantly improve the recall about 5-10 points.", "labels": [], "entities": [{"text": "Non-public Lang-8 data", "start_pos": 72, "end_pos": 94, "type": "DATASET", "confidence": 0.624486118555069}, {"text": "recall", "start_pos": 125, "end_pos": 131, "type": "METRIC", "confidence": 0.9995214939117432}]}, {"text": "However, in terms of F 0.5 , the performance of the model has only been significantly improved on the test data at A and B levels, and has dropped by about two points in C and N.", "labels": [], "entities": [{"text": "F 0.5", "start_pos": 21, "end_pos": 26, "type": "METRIC", "confidence": 0.9680882692337036}]}, {"text": "One possible explanation is that the errors contained in the Non-public Lang-8 belong to the lower CEFR level.", "labels": [], "entities": [{"text": "CEFR level", "start_pos": 99, "end_pos": 109, "type": "DATASET", "confidence": 0.9035312831401825}]}, {"text": "Overtraining in a large amount of data containing beginner errors has reduced the performance of our system at C and N levels.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 6. We implement the  pre-processing method mentioned in Section 3.1  for both tracks. The first four rows list the fine- tuning datasets we use in track one. The fifth line  summaries the above datasets. The Non-public  Lang-8 in the sixth line is the additional corpus we  collect from Lang-8 5 . It is worth mentioning that  some instances of Non-public Lang-8 also exist in  Lang-8. We use the union of all learner corpora as  the training data for track two, including 6 million", "labels": [], "entities": []}, {"text": " Table 4: The evaluation of our system on the track one development set. Transformer single refers to the single  model, while transformer ensemble denotes the ensemble of 8 single models. CC means use additional corrupted  corpus.", "labels": [], "entities": []}, {"text": " Table 5: The evaluation of our system on the test set.", "labels": [], "entities": []}, {"text": " Table 6: Number of the sentence pair for different  dataset. Track one summaries the statistic of all of the  data we use in track one, and so does Track Two. Non- public Lang-8 is the additional corpus we use in track  two. W&I+L(dev,test) is provided by the organizers. *  indicates that this corpus has no target available.", "labels": [], "entities": []}]}