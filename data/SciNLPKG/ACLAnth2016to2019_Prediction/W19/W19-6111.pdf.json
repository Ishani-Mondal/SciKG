{"title": [{"text": "Comparing the Performance of Feature Representations for the Categorization of the Easy-to-Read Variety vs Standard Language", "labels": [], "entities": []}], "abstractContent": [{"text": "We explore the effectiveness of four feature representations-bag-of-words, word embeddings, principal components and autoencoders-for the binary categoriza-tion of the easy-to-read variety vs standard language.", "labels": [], "entities": []}, {"text": "\"Standard language\" refers to the ordinary language variety used by a population as a whole or by a community, while the \"easy-to-read\" variety is a simpler (or a simplified) version of the standard language.", "labels": [], "entities": []}, {"text": "We test the efficiency of these feature representations on three corpora , which differ in size, class balance, unit of analysis, language and topic.", "labels": [], "entities": []}, {"text": "We rely on supervised and unsupervised machine learning algorithms.", "labels": [], "entities": []}, {"text": "Results show that bag-of-words is a robust and straightforward feature representation for this task and performs well in many experimental settings.", "labels": [], "entities": []}, {"text": "Its performance is equivalent or equal to the performance achieved with principal components and autoen-corders, whose preprocessing is however more time-consuming.", "labels": [], "entities": []}, {"text": "Word embeddings are less accurate than the other feature representations for this classification task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Broadly speaking, a language variety is any specific form of language variation, such as standard language, dialects, registers or jargons.", "labels": [], "entities": []}, {"text": "In this paper, we focus on two language varieties, namely the standard language variety and the easy-to-read variety.", "labels": [], "entities": []}, {"text": "In this context, \"standard language\" refers to the official and ordinary language variety used by a population as a whole, or to a variety that is normally employed within a community.", "labels": [], "entities": []}, {"text": "For example, \"Standard English\" is the form of the English language widely accepted as the usual correct form, while within the medical community it is the specialized medical jargon that is considered to be standard language.", "labels": [], "entities": []}, {"text": "In contrast, the easy-toread variety is a simpler version of a standard language.", "labels": [], "entities": []}, {"text": "The need of an easy-to-read variety stems from the difficulties that certain groups of people experience with standard language, such as people with dyslexia and other learning disabilities, the elderly, children, non-native speakers and soon.", "labels": [], "entities": []}, {"text": "In order to meet the needs of a simpler language that makes information easy to read and understand for all, European Standards have been established , and an important initiative like Wikipedia has created a special edition called Simple English Wikipedia 2 . These are not isolated phenomena.", "labels": [], "entities": []}, {"text": "For instance, in Sweden public authorities (sv: myndigheter) provide an easy-to-read version (a.k.a. simple Swedish or sv: l\u00e4ttl\u00e4st) of their written documentation.", "labels": [], "entities": []}, {"text": "Both in the case of the Simple English Wikipedia and in the case of Swedish public authorities, the simplified documents are manually written.", "labels": [], "entities": [{"text": "Simple English Wikipedia", "start_pos": 24, "end_pos": 48, "type": "DATASET", "confidence": 0.7319278120994568}]}, {"text": "Since the manual production of simplified texts is time-consuming, the task called Text Simplification (TS) is very active in Natural Language Processing (NLP) in the attempt to streamline this type of text production.", "labels": [], "entities": [{"text": "Text Simplification (TS)", "start_pos": 83, "end_pos": 107, "type": "TASK", "confidence": 0.8192013084888459}]}, {"text": "TS is a fast-growing research area that can bring about practical benefits, e.g. the automatic generation of simplified texts.", "labels": [], "entities": [{"text": "TS", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.8822446465492249}, {"text": "automatic generation of simplified texts", "start_pos": 85, "end_pos": 125, "type": "TASK", "confidence": 0.7583559453487396}]}, {"text": "There is, however, a TS subtask that is still underexplored: the categorization of the easy-to-read variety vs standard language.", "labels": [], "entities": [{"text": "TS", "start_pos": 21, "end_pos": 23, "type": "TASK", "confidence": 0.8531690239906311}]}, {"text": "The findings presented in this paper contribute to start filling this gap.", "labels": [], "entities": []}, {"text": "The automatic separation of standard texts from easy-to-read texts could be particularly useful for other TS subtasks, such as the bootstrapping of monolingual corpora from the web or the extraction of simplified terminology.", "labels": [], "entities": [{"text": "TS subtasks", "start_pos": 106, "end_pos": 117, "type": "TASK", "confidence": 0.8879065811634064}]}, {"text": "Other areas that could benefit from it include information retrieval (e.g. for the retrieval of easy-to-read or patient-friendly medical information) and deep learning-based dialogue systems (e.g. customized chatbots for expert users or naive users).", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 47, "end_pos": 68, "type": "TASK", "confidence": 0.7980927228927612}]}, {"text": "The research question we would like to answer is: which is the most suitable feature representation for this categorization task?", "labels": [], "entities": []}, {"text": "In order to answer this question, we compare four different feature representations that can potentially make sense of the lexical makeup that differentiates easy-to-read from standard language, namely bag-of-words (BoWs), word embeddings, principal components and autoencoders.", "labels": [], "entities": []}, {"text": "It goes without saying that these four feature representations are just a few of the many possible feature representations for this kind of task.", "labels": [], "entities": []}, {"text": "We start our long-term exploration with these four feature representations because they are straightforward and easy to extract automatically from any corpora.", "labels": [], "entities": []}, {"text": "We test the efficiency of the four feature representations with three types of machine learning algorithms: traditional supervised machine learning, deep learning and clustering . The experiments are based on three corpora belonging to different domains.", "labels": [], "entities": []}, {"text": "From these corpora, we extracted three datasets of different sizes, different class balance, different units of analysis (sentence vs document), different languages (Swedish and English).", "labels": [], "entities": []}, {"text": "The ultimate goal of the experiments presented in this paper is to propose a first empirical baseline for the categorization of the easy-to-read variety vs standard language.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our experiments, we use three corpora, two in Swedish and one in English.", "labels": [], "entities": []}, {"text": "More precisely, we rely on 1) a subset of the eCare corpus) in Swedish; 2) a subset of the DigInclude corpus) in Swedish and 3) a subset of the Simple English Wikipedia corpus) in English.", "labels": [], "entities": [{"text": "eCare corpus", "start_pos": 46, "end_pos": 58, "type": "DATASET", "confidence": 0.9003677070140839}, {"text": "DigInclude corpus", "start_pos": 91, "end_pos": 108, "type": "DATASET", "confidence": 0.8594586849212646}, {"text": "Simple English Wikipedia corpus", "start_pos": 144, "end_pos": 175, "type": "DATASET", "confidence": 0.763349249958992}]}, {"text": "The eCare corpus is a domain-specific web corpus.", "labels": [], "entities": [{"text": "eCare corpus", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.873017281293869}]}, {"text": "The domain of interest is the medical field of chronic diseases.", "labels": [], "entities": []}, {"text": "From the current version of the corpus we re-use a labelled subset.", "labels": [], "entities": []}, {"text": "The eCare subset contains 462 webpages without boilerplates.", "labels": [], "entities": []}, {"text": "The webpages have been labelled as 'lay' or 'specialized' by a lay native speaker.", "labels": [], "entities": []}, {"text": "Lay sublanguage is an easy-to-read version of the standard language (the medical jargon) used by healthcare pro-fessionals.", "labels": [], "entities": []}, {"text": "The 462 webpages of the eCare dataset (amounting to 424,278 words) have been labelled in the following way: 388 specialized webpages (66%) and 154 lay webpages (33%).", "labels": [], "entities": [{"text": "eCare dataset", "start_pos": 24, "end_pos": 37, "type": "DATASET", "confidence": 0.9487228393554688}]}, {"text": "The unit of analysis that we use in these experiments is the document.", "labels": [], "entities": []}, {"text": "The DigInclude corpus is a collection of easyto-read sentences aligned to standard language sentences.", "labels": [], "entities": [{"text": "DigInclude corpus", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.8054998815059662}]}, {"text": "The corpus has been crawled from a number of Swedish authorities' websites.", "labels": [], "entities": []}, {"text": "The DigInclude datasets contains 17,502 sentences, 3,827 simple sentences (22%) and 13,675 standard sentences (78%), amounting to 233,094 words.", "labels": [], "entities": [{"text": "DigInclude datasets", "start_pos": 4, "end_pos": 23, "type": "DATASET", "confidence": 0.9198217988014221}]}, {"text": "The dataset is heavily unbalanced.", "labels": [], "entities": []}, {"text": "The unit of analysis is the sentence.", "labels": [], "entities": []}, {"text": "The Simple English Wikipedia (SEW) corpus was generated by aligning Simple English Wikipedia and standard English Wikipedia.", "labels": [], "entities": [{"text": "Simple English Wikipedia (SEW) corpus", "start_pos": 4, "end_pos": 41, "type": "DATASET", "confidence": 0.7432108308587756}, {"text": "Simple English Wikipedia", "start_pos": 68, "end_pos": 92, "type": "DATASET", "confidence": 0.8252478639284769}]}, {"text": "Two different versions of the corpus exist (V1 and V2).", "labels": [], "entities": []}, {"text": "V2 has been packaged in sentences and in documents.", "labels": [], "entities": [{"text": "V2", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.8581831455230713}]}, {"text": "We used the subset of V2 divided into sentences.", "labels": [], "entities": []}, {"text": "The SEW dataset contains 325,245 sentences, 159,713 easy-to-read sentences (49.1%) and 165,532 standard sentences (50.9%), amounting to words.", "labels": [], "entities": [{"text": "SEW dataset", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.9667403995990753}]}, {"text": "The dataset is fairly balanced.", "labels": [], "entities": []}, {"text": "The unit of analysis is the sentence.", "labels": [], "entities": []}, {"text": "In this section, we describe the categorization schemes, the baselines and the evaluation metrics used for comparison.", "labels": [], "entities": []}, {"text": "We use three different learning methods, namely an implementation of SVM, an implementation of multilayer perceptron (MLP) and an implementation of K-Means for clustering.", "labels": [], "entities": []}, {"text": "The rationale behind these choices is to compare the behaviour of the four feature representations described above with learning schemes that have a different inductive biases, and to assess the difference (if any) between the performance achieved with labelled data (supervised algorithms) and unlabelled data (clustering).", "labels": [], "entities": []}, {"text": "We calculate a random baseline with the ZeroR classifier.", "labels": [], "entities": []}, {"text": "All the categorization schemes are described below.", "labels": [], "entities": []}, {"text": "The ZeroR is based on the Zero Rule algorithm and predicts the class value that has the most observations in the training dataset.", "labels": [], "entities": []}, {"text": "It is more reliable than a completely random baseline.", "labels": [], "entities": []}, {"text": "SVM: traditional supervised machine learning.", "labels": [], "entities": []}, {"text": "SVM is a classic and powerful supervised machine learning algorithm that performs extremely well in text classification tasks with numerous features.", "labels": [], "entities": [{"text": "text classification tasks", "start_pos": 100, "end_pos": 125, "type": "TASK", "confidence": 0.8482124408086141}]}, {"text": "Weka's SVM implementation is called SMO and includes John Platt's sequential minimal optimization algorithm) for training a support vector classifier.", "labels": [], "entities": []}, {"text": "Since two corpora are highly unbalanced, we also combined SMO with filters that can correct class unbalance.", "labels": [], "entities": [{"text": "SMO", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.8969895839691162}]}, {"text": "More specifically, we relied on ClassBalancer, which reweights the instances in the data so that each class has the same total weight; Resample, which produces a random subsample of a dataset using either sampling with replacement or without replacement; SMOTE, which resamples a dataset by applying the Synthetic Minority Oversampling TEchnique (SMOTE); and SpreadSubsample, which produces a random subsample of a dataset.", "labels": [], "entities": []}, {"text": "All the models built with SMO are based on Weka's standard parameters.", "labels": [], "entities": [{"text": "SMO", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.8843088150024414}, {"text": "Weka", "start_pos": 43, "end_pos": 47, "type": "DATASET", "confidence": 0.9507166147232056}]}, {"text": "Multilayer Perceptron: Deep Learning.", "labels": [], "entities": []}, {"text": "Weka provides several implementations of MLP.", "labels": [], "entities": [{"text": "Weka", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9704189300537109}]}, {"text": "We relied on the WekaDeeplearning4j package that is described in.", "labels": [], "entities": [{"text": "WekaDeeplearning4j package", "start_pos": 17, "end_pos": 43, "type": "DATASET", "confidence": 0.9593123197555542}]}, {"text": "The main classifier in this package is named DI4jMlpClassifier and is a wrapper for the DeepLearning4j library to train a multilayer perceptron.", "labels": [], "entities": [{"text": "DI4jMlpClassifier", "start_pos": 45, "end_pos": 62, "type": "DATASET", "confidence": 0.8467995524406433}]}, {"text": "While features like BoWs, principal components and autoencoders can be fed to any classifiers within the Weka workbench (if they are wrapped in filters), word embeddings can be handled only by the DI4jMlpClassifier (this explains N/A in Table 2).", "labels": [], "entities": [{"text": "BoWs", "start_pos": 20, "end_pos": 24, "type": "DATASET", "confidence": 0.8476880192756653}, {"text": "Weka workbench", "start_pos": 105, "end_pos": 119, "type": "DATASET", "confidence": 0.9693149924278259}]}, {"text": "We used the standard configuration of the DI4jMlpClassifier (which includes only one output layer) for BoWs, principal components and autoencoders.", "labels": [], "entities": [{"text": "BoWs", "start_pos": 103, "end_pos": 107, "type": "DATASET", "confidence": 0.9194645285606384}]}, {"text": "Conversely, the configuration used with word embeddings was cutomized in the following way: word embeddings were passed through four layers (two convulational layers, a GlobalPoolingLayer and a OutputLayer); the number of epochs was set to 100; the instance iterator was set on CnnTextEmbeddingInstanceIterator; we used the polyglot embeddings for Swedish and English, as mentioned above.", "labels": [], "entities": []}, {"text": "We compare the performance of the supervised classification with clustering (fully unsupervised categorization).", "labels": [], "entities": []}, {"text": "We use the traditional K-Means algorithm) that in Weka is called SimpleKMeans.", "labels": [], "entities": [{"text": "Weka", "start_pos": 50, "end_pos": 54, "type": "DATASET", "confidence": 0.9555791616439819}]}, {"text": "Since we know the number of classes in advance (i.e. two classes), we evaluate the quality of the clusters against existing classes using the option Classes to cluster evaluation, which first ignores the class attribute and generates the clus-ters, then during the test phase assigns classes to the clusters, based on the majority value of the class attribute within each cluster.", "labels": [], "entities": []}, {"text": "We compare the performances on the Weighted Averaged F-Measure (AvgF), which is the sum of all the classes' Fmeasures, each weighted according to the number of instances with that particular class label.", "labels": [], "entities": [{"text": "Weighted Averaged F-Measure (AvgF)", "start_pos": 35, "end_pos": 69, "type": "METRIC", "confidence": 0.8971615632375082}]}, {"text": "In order to reliably assess the performance based on AvgF, we also use k-statistic and the ROC area value.", "labels": [], "entities": [{"text": "AvgF", "start_pos": 53, "end_pos": 57, "type": "METRIC", "confidence": 0.9197772741317749}, {"text": "ROC area value", "start_pos": 91, "end_pos": 105, "type": "METRIC", "confidence": 0.942893366018931}]}, {"text": "K-statistic indicates the agreement of prediction with true class; when the value is 0 the agreement is random.", "labels": [], "entities": []}, {"text": "The quality of a classifier can also be assessed with the help of the ROC area value which indicates the area under the ROC curve (AUC).", "labels": [], "entities": [{"text": "ROC area value", "start_pos": 70, "end_pos": 84, "type": "METRIC", "confidence": 0.9395006696383158}, {"text": "ROC curve (AUC)", "start_pos": 120, "end_pos": 135, "type": "METRIC", "confidence": 0.9656372308731079}]}, {"text": "It is used to measure how well a classifier performs.", "labels": [], "entities": []}, {"text": "The ROC area value lies between about 0.500 to 1, where 0.500 (and below) denotes a bad classifier and 1 denotes an excellent classifier.", "labels": [], "entities": [{"text": "ROC area value", "start_pos": 4, "end_pos": 18, "type": "METRIC", "confidence": 0.9421209096908569}]}, {"text": "shows a breakdown of the baselines returned by the ZeroR classifier on the three corpora.", "labels": [], "entities": []}, {"text": "These baselines imply that the k-statistic is 0 and the ROC area value is below or equal to 0.500.", "labels": [], "entities": [{"text": "ROC area value", "start_pos": 56, "end_pos": 70, "type": "METRIC", "confidence": 0.9359217286109924}]}], "tableCaptions": [{"text": " Table 1: ZeroR baselines, breakdown", "labels": [], "entities": [{"text": "ZeroR baselines", "start_pos": 10, "end_pos": 25, "type": "DATASET", "confidence": 0.6178905218839645}]}, {"text": " Table 2: Summary table (AvgF): easy-to-read variety vs standard language", "labels": [], "entities": [{"text": "Summary table (AvgF)", "start_pos": 10, "end_pos": 30, "type": "METRIC", "confidence": 0.8045816063880921}]}, {"text": " Table 3: Summary table (AvgF): unbalanced datasets (BoWs + class balancing filters applied to SMO)", "labels": [], "entities": []}, {"text": " Table 4: 5 top frequent words and 5 bottom fre- quent words in one of the SEW models", "labels": [], "entities": [{"text": "SEW", "start_pos": 75, "end_pos": 78, "type": "DATASET", "confidence": 0.8947912454605103}]}, {"text": " Table 8: eCare -Class balancing filters, break- down", "labels": [], "entities": []}]}