{"title": [{"text": "Does NMT make a difference when post-editing closely related languages? The case of Spanish-Catalan", "labels": [], "entities": []}], "abstractContent": [{"text": "In the last years, we have witnessed an increase in the use of post-editing of machine translation (PEMT) in the translation industry.", "labels": [], "entities": [{"text": "post-editing of machine translation (PEMT)", "start_pos": 63, "end_pos": 105, "type": "TASK", "confidence": 0.7730150946549007}]}, {"text": "It has been included as part of the translation workflow because it increases productivity of translators.", "labels": [], "entities": [{"text": "translation workflow", "start_pos": 36, "end_pos": 56, "type": "TASK", "confidence": 0.9128763675689697}]}, {"text": "Currently , many Language Service Providers offer PEMT as a service.", "labels": [], "entities": []}, {"text": "For many years now, (closely) related languages have been post-edited using rule-based and phrase-based machine translation (MT) systems because they present less challenges due to their morphological and syntactic similarities.", "labels": [], "entities": [{"text": "phrase-based machine translation (MT)", "start_pos": 91, "end_pos": 128, "type": "TASK", "confidence": 0.7801254143317541}]}, {"text": "Given the recent popularity of neural MT (NMT), this paper analyzes the performance of this approach compared to phrase-based statistical MT (PBSMT) on in-domain and general domain documents.", "labels": [], "entities": [{"text": "phrase-based statistical MT", "start_pos": 113, "end_pos": 140, "type": "TASK", "confidence": 0.5876807371775309}]}, {"text": "We use standard automatic measures and temporal and technical effort to assess if NMT yields areal improvement when it comes to post-editing the Spanish-Catalan language pair.", "labels": [], "entities": []}], "introductionContent": [{"text": "Machine translation (MT) between (closely) related languages presents less challenges and has received less attention than translation between distant languages because it shows a smaller number of translation errors.", "labels": [], "entities": [{"text": "Machine translation (MT)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.906866729259491}]}, {"text": "For along time now, postediting of machine translation (PEMT) has been included as a regular practice for these language combinations because it increases productivity and reduces costs.", "labels": [], "entities": [{"text": "postediting of machine translation (PEMT)", "start_pos": 20, "end_pos": 61, "type": "TASK", "confidence": 0.8725312267030988}]}, {"text": "Catalan and Spanish are closely-related languages derived from Latin.", "labels": [], "entities": []}, {"text": "They share many morphological, syntactic and semantic similarities.", "labels": [], "entities": []}, {"text": "This yields good results for rule-based and statistical-based systems.", "labels": [], "entities": []}, {"text": "These systems are currently being used for post-editing both general and in-domain texts in many different companies and official organizations.", "labels": [], "entities": []}, {"text": "The quality of the MT output is one of the main elements that determines the post-editing effort.", "labels": [], "entities": [{"text": "MT", "start_pos": 19, "end_pos": 21, "type": "TASK", "confidence": 0.9858828186988831}]}, {"text": "The higher the MT quality, the more effective postediting can be.", "labels": [], "entities": [{"text": "MT", "start_pos": 15, "end_pos": 17, "type": "TASK", "confidence": 0.9426906108856201}, {"text": "postediting", "start_pos": 46, "end_pos": 57, "type": "TASK", "confidence": 0.9438800811767578}]}, {"text": "However, automatic metrics generally used to assess the quality of MT do not always correlate to the required post-editing effort.", "labels": [], "entities": [{"text": "MT", "start_pos": 67, "end_pos": 69, "type": "TASK", "confidence": 0.9899862408638}]}, {"text": "Nor does translators' perception tend to match PE effort.", "labels": [], "entities": [{"text": "PE", "start_pos": 47, "end_pos": 49, "type": "TASK", "confidence": 0.8686651587486267}]}, {"text": "Research in this field has mainly focused on measuring the post-editing effort related to MT output quality, productivity (O', translator's usability and perceived post-editing effort.", "labels": [], "entities": [{"text": "MT output", "start_pos": 90, "end_pos": 99, "type": "TASK", "confidence": 0.890507310628891}]}, {"text": "Regarding post-editing effort, all research uses the three separated, but inter-related, dimensions established by: temporal, technical and cognitive.", "labels": [], "entities": []}, {"text": "Temporal effort measures the time spent post-editing the MT output.", "labels": [], "entities": [{"text": "MT output", "start_pos": 57, "end_pos": 66, "type": "TASK", "confidence": 0.8968084454536438}]}, {"text": "Technical effort makes reference to the insertions and deletions applied by the translator and is usually measured with keystroke analysis with HTER).", "labels": [], "entities": []}, {"text": "Cognitive effort relates to the cognitive processes taking place during post-editing and has been measured by eye-tracking or think-aloud protocols.", "labels": [], "entities": []}, {"text": "claimed that post-editing effort could be determined as a combination of all three dimensions.", "labels": [], "entities": []}, {"text": "Even though no current measure includes them all, cognitive effort correlates with technical and temporal PE effort ().", "labels": [], "entities": []}, {"text": "In recent years, neural MT has gained popularity because the results obtained in terms of quality have been very successful as evidenced in WMT 2016 (.", "labels": [], "entities": [{"text": "neural MT", "start_pos": 17, "end_pos": 26, "type": "TASK", "confidence": 0.5206644535064697}, {"text": "WMT 2016", "start_pos": 140, "end_pos": 148, "type": "DATASET", "confidence": 0.9278281033039093}]}, {"text": "These results have initiated a shift from statistical machine translation (SMT) to neural machine translation (NMT) in many translation industry scenarios.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 42, "end_pos": 79, "type": "TASK", "confidence": 0.7952588150898615}, {"text": "neural machine translation (NMT)", "start_pos": 83, "end_pos": 115, "type": "TASK", "confidence": 0.8045224050680796}]}, {"text": "Google, for example, which first used rulebased MT, and then (phrase-based) SMT, has very recently replaced some of their statistical MT engines by NMT engines ().", "labels": [], "entities": []}, {"text": "As NMT is becoming more popular among language service providers and translators, it is essential to test if it can really improve the post-editing process compared to phrase-based SMT (PSMT).", "labels": [], "entities": [{"text": "phrase-based SMT", "start_pos": 168, "end_pos": 184, "type": "TASK", "confidence": 0.5352731943130493}]}, {"text": "Recent research ( has shown an improved quality of NTM for post-editing certain language pairs, such as German,.", "labels": [], "entities": []}, {"text": "But as far as we know, post-editing closely related languages has been scarcely analyzed before.", "labels": [], "entities": []}, {"text": "We carryout two sets of experiments.", "labels": [], "entities": []}, {"text": "The first experiments compare the post-editing of NMT and PBSMT output for general news texts from Spanish into Catalan.", "labels": [], "entities": [{"text": "NMT and PBSMT output", "start_pos": 50, "end_pos": 70, "type": "DATASET", "confidence": 0.7143073007464409}]}, {"text": "The second batch of experiments focus on in-domain formal documents and study the post-editing of NMT and PBSMT output for Spanish to Catalan UE documents.", "labels": [], "entities": [{"text": "NMT and PBSMT output for Spanish to Catalan UE documents", "start_pos": 98, "end_pos": 154, "type": "DATASET", "confidence": 0.6397090703248978}]}, {"text": "The latter texts tend to have more fixed syntactic structures than the former, but present a larger use of technical content and terminology.", "labels": [], "entities": []}, {"text": "In both sets of experiments we compare post-editing temporal and technical effort with automatic metrics.", "labels": [], "entities": []}, {"text": "We also carryout a manual analysis of the machine translation outputs.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.6726837456226349}]}, {"text": "Given the similarities between Spanish and Catalan, we want to test if NMT improves temporal or technical post-editing effort for these two languages.", "labels": [], "entities": []}, {"text": "This leads us to the main questions that this paper tries to solve:", "labels": [], "entities": []}], "datasetContent": [{"text": "The systems have been automatically evaluated using mteval to obtain the values for BLEU, NIST and WER.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 84, "end_pos": 88, "type": "METRIC", "confidence": 0.9979950189590454}, {"text": "NIST", "start_pos": 90, "end_pos": 94, "type": "DATASET", "confidence": 0.6649932861328125}, {"text": "WER", "start_pos": 99, "end_pos": 102, "type": "METRIC", "confidence": 0.9783738851547241}]}, {"text": "includes the evaluation figures for all the MT systems used.", "labels": [], "entities": [{"text": "MT", "start_pos": 44, "end_pos": 46, "type": "TASK", "confidence": 0.9730623364448547}]}, {"text": "As a reference, we also include the metrics for Google Translate for the same evaluation sets.", "labels": [], "entities": []}, {"text": "We have carried two sets of experiments to assess the correlation of MT metrics with the post-editing time and technical effort.", "labels": [], "entities": [{"text": "MT", "start_pos": 69, "end_pos": 71, "type": "TASK", "confidence": 0.9906631708145142}]}, {"text": "The participants were students in their last year of the Degree in Translation and Language Sciences.", "labels": [], "entities": [{"text": "Translation and Language Sciences", "start_pos": 67, "end_pos": 100, "type": "TASK", "confidence": 0.8172244131565094}]}, {"text": "They post-edited during a PE task organized as part of a course on Localization taught by one of the authors.", "labels": [], "entities": [{"text": "PE task", "start_pos": 26, "end_pos": 33, "type": "TASK", "confidence": 0.907835990190506}]}, {"text": "They all acknowledged a C2 level of both languages.", "labels": [], "entities": []}, {"text": "Although students may not be experienced professionals, the participants have translated into this specific language combination during their translation degree program, and have received specific PE training during the course before carrying out the PE task.", "labels": [], "entities": [{"text": "PE task", "start_pos": 251, "end_pos": 258, "type": "TASK", "confidence": 0.9102470874786377}]}, {"text": "For these reasons, we can consider them semiprofessionals).", "labels": [], "entities": []}, {"text": "In the first experiment, 12 participants postedited a short text (441 words, 14 segments) from Spanish into Catalan translated with our in-domain PBSMT Moses, our in-domain NMT Marian and NMT Google Translate systems.", "labels": [], "entities": [{"text": "PBSMT Moses", "start_pos": 146, "end_pos": 157, "type": "DATASET", "confidence": 0.9467568099498749}, {"text": "NMT Marian", "start_pos": 173, "end_pos": 183, "type": "DATASET", "confidence": 0.898971825838089}, {"text": "NMT Google Translate", "start_pos": 188, "end_pos": 208, "type": "DATASET", "confidence": 0.8362829883893331}]}, {"text": "The text was a passage from a UE document, which presented more fixed syntactic structures, but larger technical content.", "labels": [], "entities": [{"text": "UE document", "start_pos": 30, "end_pos": 41, "type": "DATASET", "confidence": 0.9167880117893219}]}, {"text": "They had to carry the task using PET (), a computer-assisted translation tool that supports post-editing.", "labels": [], "entities": []}, {"text": "It logs both postediting time and edits (keystrokes, insertions and deletions, that is, technical effort).", "labels": [], "entities": []}, {"text": "As it was a short text, they were asked to post-edit it without any pauses.", "labels": [], "entities": []}, {"text": "The main characteristics of the postediting tool were also explained before beginning the task.", "labels": [], "entities": []}, {"text": "In the second experiment, the same 12 participants post-edited a general domain short text (379 words, 17 segments) from Spanish into Catalan translated with our general purpose PBSMT Moses, our NMT Marian and NMT Google Translate systems.", "labels": [], "entities": [{"text": "PBSMT Moses", "start_pos": 178, "end_pos": 189, "type": "DATASET", "confidence": 0.9674572646617889}, {"text": "NMT Marian", "start_pos": 195, "end_pos": 205, "type": "DATASET", "confidence": 0.9024738073348999}, {"text": "NMT Google Translate", "start_pos": 210, "end_pos": 230, "type": "DATASET", "confidence": 0.8493430614471436}]}, {"text": "The text was a fragment from apiece of news appeared in the newspaper El Pa\u00eds on April 4th, 2019.", "labels": [], "entities": [{"text": "news appeared in the newspaper El Pa\u00eds on April 4th", "start_pos": 39, "end_pos": 90, "type": "DATASET", "confidence": 0.824821749329567}]}, {"text": "They post-edited the text with the same tool and conditions as in the first experiment.", "labels": [], "entities": []}, {"text": "In order to avoid bias, participants never postedited the same text twice.", "labels": [], "entities": []}, {"text": "We divided the 12 posteditors into groups of 4 people.", "labels": [], "entities": []}, {"text": "All the members of each group post-edited the in-domain text translated with an MT system.", "labels": [], "entities": []}, {"text": "They also post-edited the general text output for the same MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 59, "end_pos": 61, "type": "TASK", "confidence": 0.8900429606437683}]}], "tableCaptions": [{"text": " Table 1: Size of the training corpora", "labels": [], "entities": [{"text": "Size", "start_pos": 10, "end_pos": 14, "type": "TASK", "confidence": 0.9800365567207336}]}, {"text": " Table 3: Temporal post-editing effort (secs/segment)", "labels": [], "entities": []}, {"text": " Table 4: Technical post-editing effort (keystrokes/segment)", "labels": [], "entities": []}, {"text": " Table 5: Percentage of unmodified segments", "labels": [], "entities": [{"text": "Percentage", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9766898155212402}]}, {"text": " Table 6: Number of errors according to the linguistic level", "labels": [], "entities": []}]}