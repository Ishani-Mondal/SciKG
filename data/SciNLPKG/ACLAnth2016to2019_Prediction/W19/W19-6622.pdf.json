{"title": [{"text": "Lost in Translation: Loss and Decay of Linguistic Richness in Machine Translation", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 62, "end_pos": 81, "type": "TASK", "confidence": 0.7515033185482025}]}], "abstractContent": [{"text": "This work presents an empirical approach to quantifying the loss of lexical richness in Machine Translation (MT) systems compared to Human Translation (HT).", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 88, "end_pos": 112, "type": "TASK", "confidence": 0.8514225482940674}, {"text": "Human Translation (HT)", "start_pos": 133, "end_pos": 155, "type": "TASK", "confidence": 0.8353864073753356}]}, {"text": "Our experiments show how current MT systems indeed fail to render the lexical diversity of human generated or translated text.", "labels": [], "entities": [{"text": "MT", "start_pos": 33, "end_pos": 35, "type": "TASK", "confidence": 0.9854816198348999}]}, {"text": "The inability of MT systems to generate diverse outputs and its tendency to exacerbate already frequent patterns while ignoring less frequent ones, might be the underlying cause for, among others, the currently heavily debated issues related to gender biased output.", "labels": [], "entities": [{"text": "MT", "start_pos": 17, "end_pos": 19, "type": "TASK", "confidence": 0.988298773765564}]}, {"text": "Can we indeed, aside from biased data, talk about an algorithm that exacerbates seen biases?", "labels": [], "entities": []}], "introductionContent": [{"text": "Berman (2000) observed that the translation process consists of deformation processes, one of which he refers to as 'quantitative impoverishment', a loss of lexical richness and diversity.", "labels": [], "entities": []}, {"text": "Although mitigated by a human translator, this loss is to some extent inevitable as it is hard to respect the multitude of signifiers and constructions when translating one language into another.", "labels": [], "entities": []}, {"text": "While Berman (2000) studied the decrease of lexical richness of human translations (HTs) from a theoretical point of view, Kruger (2012) demonstrated using empirical methods that there is indeed a lexical loss when comparing translations to original texts.", "labels": [], "entities": [{"text": "lexical richness of human translations (HTs)", "start_pos": 44, "end_pos": 88, "type": "TASK", "confidence": 0.7305193543434143}]}, {"text": "In the field of Machine Translation (MT), showed that Statistical MT (SMT) suffers considerably more from lexical loss than HTs in a study focused on lexical tightness and text cohesion.", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 16, "end_pos": 40, "type": "TASK", "confidence": 0.8715787649154663}, {"text": "Statistical MT (SMT", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.694808654487133}]}, {"text": "We are not aware of any other research in this direction.", "labels": [], "entities": []}, {"text": "As generating accurate translations has been the main objective of current MT systems, maintaining lexical richness and creating diverse outputs has understandably not been a priority.", "labels": [], "entities": [{"text": "MT", "start_pos": 75, "end_pos": 77, "type": "TASK", "confidence": 0.9847887754440308}]}, {"text": "Nevertheless, the issue of lexical loss in MT might at the same time be a symptom and a cause of a more serious issue underlying the current systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 43, "end_pos": 45, "type": "TASK", "confidence": 0.9420216679573059}]}, {"text": "The difference between a one-to-many relationship such as the one illustrated in, is very different from the one illustrated in or from a (human) translator point of view.", "labels": [], "entities": []}, {"text": "However, from a statistical point of view, they are not always clearly distinguishable.", "labels": [], "entities": []}, {"text": "When presented with an ambiguous sentence, like 'I am intelligent' or 'See?'", "labels": [], "entities": []}, {"text": "where there is little context to decide on a particular target variant of the same source word, it essentially boils down to the same thing: picking the translation that maximizes the probability over the entire sentence.", "labels": [], "entities": []}, {"text": "As such, the loss of richness and diversity and the exacerbation of already frequent patterns might not simply be limited to the loss of (near) synonyms or rare words, but could also be the underlying cause of, for example, the inability of statistical MT systems to handle morphologically richer language correctly (, the already observed issues with gender bias () in MT output or the difficulties of dealing with agglutinative languages (.", "labels": [], "entities": [{"text": "MT", "start_pos": 253, "end_pos": 255, "type": "TASK", "confidence": 0.9490721821784973}, {"text": "MT output", "start_pos": 370, "end_pos": 379, "type": "TASK", "confidence": 0.8703160285949707}]}, {"text": "The inability of neural models to generate diverse output has already been observed for tasks involving language generation, where creating intrinsically diverse outputs is more of a necessity.", "labels": [], "entities": [{"text": "language generation", "start_pos": 104, "end_pos": 123, "type": "TASK", "confidence": 0.7313665896654129}]}, {"text": "However, from a translation point of view, the ability of MT systems to be (1) consistent and (2) learn and generalize well are -compared to previous MT systems-the biggest asset of NMT.", "labels": [], "entities": [{"text": "MT", "start_pos": 58, "end_pos": 60, "type": "TASK", "confidence": 0.9648796916007996}]}, {"text": "We however, hypothesize that this type of generalization might as well have serious drawbacks and that diversity, although not deemed a priority, is of importance for the field of MT as well.", "labels": [], "entities": [{"text": "MT", "start_pos": 180, "end_pos": 182, "type": "TASK", "confidence": 0.9937090873718262}]}, {"text": "Overgeneralization over a seen input and the exacerbation of dominant forms might not only lead to a loss of lexical choice, but could also be the underlying cause of gender bias exacerbation.", "labels": [], "entities": []}, {"text": "Although, in the context of gender, some researchers have already alluded to the existence of so-called 'algorithmic bias' (, no empirical evidence has been provided so far.", "labels": [], "entities": []}, {"text": "With our empirical approach, comparing the lexical diversity of different MT systems and further analyzing the frequencies of words, we aim to shed some light on the relation between the loss of diversity and the exacerbation or loss of certain words.", "labels": [], "entities": [{"text": "MT", "start_pos": 74, "end_pos": 76, "type": "TASK", "confidence": 0.9637248516082764}]}, {"text": "Thus, the first objective of our work is to verify how NMT compares to SMT and HT in terms of lexical richness or the loss thereof.", "labels": [], "entities": [{"text": "SMT", "start_pos": 71, "end_pos": 74, "type": "TASK", "confidence": 0.9024337530136108}]}, {"text": "The second objective is to quantify to what extent the different MT architectures favour translations that are more frequently observed in the training data.", "labels": [], "entities": [{"text": "MT", "start_pos": 65, "end_pos": 67, "type": "TASK", "confidence": 0.9557749032974243}]}, {"text": "The structure of the paper is the following: related work is described in Section 2; Our hypotheses are defined in details in Section 3; information on the data and the MT systems used in our experiments is provided in Section 4; Section 5 discusses the results of our experiments and finally, we conclude and provide some ideas for future work in Section 6.", "labels": [], "entities": [{"text": "MT", "start_pos": 169, "end_pos": 171, "type": "TASK", "confidence": 0.9572321176528931}]}], "datasetContent": [{"text": "To test our hypothesis we built three types of MT systems and analysed their output for two language pairs on Europarl ( To draw more general conclusions on the effects of bias propagation and loss of lexical richness, we assessed output from seen (during training) and unseen data.", "labels": [], "entities": [{"text": "MT", "start_pos": 47, "end_pos": 49, "type": "TASK", "confidence": 0.9762874245643616}, {"text": "Europarl", "start_pos": 110, "end_pos": 118, "type": "DATASET", "confidence": 0.9947803020477295}]}, {"text": "Data We used +/-2M sentence pairs from the Europarl corpora for each of the language pairs.", "labels": [], "entities": [{"text": "Europarl corpora", "start_pos": 43, "end_pos": 59, "type": "DATASET", "confidence": 0.9888337552547455}]}, {"text": "We randomised the order of the sentence pairs and split the data into train, test and development sets, filtering out empty lines.", "labels": [], "entities": []}, {"text": "Details on the different datasets can be found in.", "labels": [], "entities": []}, {"text": "We chose to include large quantities of data in our test sets -the unseen data -in order to maximise the language variability and explore general tendencies.", "labels": [], "entities": []}, {"text": "MT systems For each of the three MT architectures we first trained a standard MT system (the forward or FF system) on the original data.", "labels": [], "entities": [{"text": "MT", "start_pos": 33, "end_pos": 35, "type": "TASK", "confidence": 0.9615982174873352}]}, {"text": "For the RNN and Transformer systems we used OpenNMT-py.", "labels": [], "entities": []}, {"text": "The systems were trained for 150K steps, saving an intermediate model every 5000 steps.", "labels": [], "entities": []}, {"text": "We scored the perplexity of each model on the development set and chose the one with the lowest perplexity as our best model, used later for translation.", "labels": [], "entities": [{"text": "translation", "start_pos": 141, "end_pos": 152, "type": "TASK", "confidence": 0.9863182306289673}]}, {"text": "The options we used for the neural systems are as follows: \u2022 RNN: size: 512, RNN type: bidirectional LSTM, number of layers of the encoder and of the decoder: 4, attention type: mlp, dropout: 0.2, batch size: 128, learning optimizer: adam (Kingma and Ba, 2014) and learning rate: 0.0001.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 265, "end_pos": 278, "type": "METRIC", "confidence": 0.9432073533535004}]}, {"text": "\u2022  tings suggested by the OpenNMT community 2 as the optimal ones that lead to quality on par with the original Transformer work (.", "labels": [], "entities": [{"text": "OpenNMT community 2", "start_pos": 26, "end_pos": 45, "type": "DATASET", "confidence": 0.8549150228500366}]}, {"text": "For the SMT systems we use Moses () with default settings and a 5-gram language model with pruning of bigrams.", "labels": [], "entities": [{"text": "SMT", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.9897733330726624}]}, {"text": "Each system is further tuned with MERT (Och and Ney, 2003) until convergence or fora maximum of 25 iterations.", "labels": [], "entities": [{"text": "MERT", "start_pos": 34, "end_pos": 38, "type": "METRIC", "confidence": 0.991393506526947}]}, {"text": "For the neural systems, we opted not to use subword units as is typically done for NMT.", "labels": [], "entities": []}, {"text": "This is because we focus on the word frequencies in the translations and do not want any algorithm for splitting into sub-word units to add extra variability in our data.", "labels": [], "entities": []}, {"text": "To construct the dictionaries we use all words in our training data.", "labels": [], "entities": []}, {"text": "(first two columns) shows the training vocabularies for the source and target sides.", "labels": [], "entities": []}, {"text": "To assess how MT amplifies bias and loss of lexical richness, along with the original-data systems, we trained MT with backtranslated (BT) data, which is typically used to complement original data for MT training when the quantity of the original data is not sufficient for reaching high translation quality.", "labels": [], "entities": [{"text": "MT amplifies bias", "start_pos": 14, "end_pos": 31, "type": "TASK", "confidence": 0.7930023471514384}, {"text": "MT", "start_pos": 111, "end_pos": 113, "type": "TASK", "confidence": 0.9065340161323547}, {"text": "MT training", "start_pos": 201, "end_pos": 212, "type": "TASK", "confidence": 0.9110269546508789}]}, {"text": "We first trained MT systems for the reverse language directions, i.e. for FR-EN and ES-EN.", "labels": [], "entities": [{"text": "MT", "start_pos": 17, "end_pos": 19, "type": "TASK", "confidence": 0.9787550568580627}, {"text": "FR-EN", "start_pos": 74, "end_pos": 79, "type": "METRIC", "confidence": 0.6567652821540833}]}, {"text": "We used the same data sets, but reversed the associations of the source and the target with FR/ES \u2192 EN instead of EN \u2192 FR/ES.", "labels": [], "entities": [{"text": "FR/ES \u2192 EN", "start_pos": 92, "end_pos": 102, "type": "METRIC", "confidence": 0.8515536665916443}, {"text": "FR", "start_pos": 119, "end_pos": 121, "type": "METRIC", "confidence": 0.8176442980766296}]}, {"text": "We then used these reversed (REV or rev) systems to translate the training set: the same set used for training the FF systems and the REV systems.", "labels": [], "entities": []}, {"text": "That is, we use a system trained on (say) FR-EN data to translate the same FR set into English (EN*).", "labels": [], "entities": [{"text": "FR-EN data", "start_pos": 42, "end_pos": 52, "type": "DATASET", "confidence": 0.8446127772331238}]}, {"text": "The aim is to see what is the impact of the underlying algorithms on the data in the most-favourable scenario; when the data has already been seen.", "labels": [], "entities": []}, {"text": "With the trans-  be seen as a combination of back-translation and round-trip-translation.", "labels": [], "entities": []}, {"text": "See fora visualization of the pipeline of systems.", "labels": [], "entities": []}, {"text": "For the REV and BACK systems we used the same settings as for the FF ones.", "labels": [], "entities": [{"text": "REV", "start_pos": 8, "end_pos": 11, "type": "DATASET", "confidence": 0.49825042486190796}, {"text": "BACK", "start_pos": 16, "end_pos": 20, "type": "DATASET", "confidence": 0.5174603462219238}]}, {"text": "However, at this stage, the source side of the training data is different and thus impacts the learnable vocabulary.", "labels": [], "entities": []}, {"text": "presents the source-side vocabulary sizes for the RNN, SMT and Transformer systems.", "labels": [], "entities": []}, {"text": "These are in practice the number of distinct words of the translations produced by the REV systems.", "labels": [], "entities": [{"text": "REV systems", "start_pos": 87, "end_pos": 98, "type": "DATASET", "confidence": 0.8136898875236511}]}, {"text": "Compared to shows how source and target vocabularies are comparable in the original datasets, but translating the same original English dataset with the neural REV systems (RNN and Transformer) results in a huge drop in vocabulary size; with the SMT REV systems the decrease is still significant, but not as profound as in the former cases.", "labels": [], "entities": [{"text": "SMT REV", "start_pos": 246, "end_pos": 253, "type": "TASK", "confidence": 0.8568678796291351}]}, {"text": "In we present automatic evaluation scores -BLEU () and TER () -for the 12 analysed systems.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 43, "end_pos": 47, "type": "METRIC", "confidence": 0.9798734188079834}, {"text": "TER", "start_pos": 55, "end_pos": 58, "type": "METRIC", "confidence": 0.9983617663383484}]}, {"text": "For completeness we present BLEU and TER for the REV systems in, although we do not consider them in our analysis.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 28, "end_pos": 32, "type": "METRIC", "confidence": 0.9995191097259521}, {"text": "TER", "start_pos": 37, "end_pos": 40, "type": "METRIC", "confidence": 0.9982319474220276}]}, {"text": "For the test set we performed a statistical significance test using the multeval tool).", "labels": [], "entities": []}, {"text": "Evaluated output In total we trained 18 MT systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 40, "end_pos": 42, "type": "TASK", "confidence": 0.9871315956115723}]}, {"text": "To assess the validity of our hypothesis and to provide a quantitative analysis of the investigated phenomena, we use the outputs from the FF and the BACK systems; the REV systems are used just to generate the backtranslated data.", "labels": [], "entities": [{"text": "FF", "start_pos": 139, "end_pos": 141, "type": "METRIC", "confidence": 0.8926587700843811}, {"text": "BACK", "start_pos": 150, "end_pos": 154, "type": "METRIC", "confidence": 0.8608734011650085}, {"text": "REV", "start_pos": 168, "end_pos": 171, "type": "METRIC", "confidence": 0.957438051700592}]}], "tableCaptions": [{"text": " Table 1: Number of parallel sentences in the train, test and  development splits for the language pairs we used.", "labels": [], "entities": []}, {"text": " Table 2: Training vocabularies for the English, French and  Spanish data used for our models.", "labels": [], "entities": []}, {"text": " Table 5: Automatic evaluation scores (BLEU and TER) for  the REV systems.", "labels": [], "entities": [{"text": "Automatic evaluation scores", "start_pos": 10, "end_pos": 37, "type": "METRIC", "confidence": 0.85635373989741}, {"text": "BLEU", "start_pos": 39, "end_pos": 43, "type": "METRIC", "confidence": 0.9432909488677979}, {"text": "TER", "start_pos": 48, "end_pos": 51, "type": "METRIC", "confidence": 0.9631487727165222}]}, {"text": " Table 6: Lexical richness metrics (Train set).", "labels": [], "entities": []}, {"text": " Table 7: Lexical richness metrics (Test set).", "labels": [], "entities": []}, {"text": " Table 8: Frequency exacerbation and decay count (Train set)", "labels": [], "entities": [{"text": "decay count", "start_pos": 37, "end_pos": 48, "type": "METRIC", "confidence": 0.8207067251205444}]}, {"text": " Table 9: Frequency exacerbation and decay count (Test set)", "labels": [], "entities": []}, {"text": " Table 10: Accumulated frequency differences (Train set)", "labels": [], "entities": [{"text": "Accumulated frequency differences", "start_pos": 11, "end_pos": 44, "type": "METRIC", "confidence": 0.927177369594574}]}, {"text": " Table 11: Accumulated frequency differences (Test set)", "labels": [], "entities": [{"text": "Accumulated frequency differences", "start_pos": 11, "end_pos": 44, "type": "METRIC", "confidence": 0.9235048492749532}]}]}