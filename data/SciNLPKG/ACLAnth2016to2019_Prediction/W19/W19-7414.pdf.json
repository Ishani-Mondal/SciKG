{"title": [{"text": "Automatic Diacritization as Prerequisite Towards the Automatic Generation of Arabic Lexical Recognition Tests", "labels": [], "entities": [{"text": "Automatic Diacritization", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6451745331287384}, {"text": "Automatic Generation of Arabic Lexical Recognition", "start_pos": 53, "end_pos": 103, "type": "TASK", "confidence": 0.7865833838780721}]}], "abstractContent": [{"text": "The automatic generation of Arabic lexical recognition tests entails several NLP challenges , including corpus linguistics, automatic diacritization, lemmatization and language modeling.", "labels": [], "entities": [{"text": "automatic generation of Arabic lexical recognition tests", "start_pos": 4, "end_pos": 60, "type": "TASK", "confidence": 0.7847666612693242}, {"text": "language modeling", "start_pos": 168, "end_pos": 185, "type": "TASK", "confidence": 0.7177674472332001}]}, {"text": "Here, we only address the problem of automatic diacritization, a step that paves the road for the automatic generation of Arabic LRTs.", "labels": [], "entities": []}, {"text": "We conduct a comparative study between the available tools for diacritization (Farasa and Madamira) and a strong baseline.", "labels": [], "entities": []}, {"text": "We evaluate the error rates for these systems using a set of publicly available (almost) fully diacritized corpora, but in a relaxed evaluation mode to ensure fair comparison.", "labels": [], "entities": []}, {"text": "Farasa out-performs Madamira and the baseline under all conditions.", "labels": [], "entities": []}], "introductionContent": [{"text": "Lexical recognition tests are widely used to assess vocabulary knowledge.", "labels": [], "entities": [{"text": "Lexical recognition", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8726930916309357}]}, {"text": "LRTs are based on the assumption that recognizing a word is sufficient for 'knowing' the word).", "labels": [], "entities": [{"text": "LRTs", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.8993277549743652}]}, {"text": "In such tests, the participants are being shown a list of items, containing words and nonwords.", "labels": [], "entities": []}, {"text": "Their task is based on word recognition approach, i.e. they have to say 'Yes' when the item is word and 'No' otherwise -see.", "labels": [], "entities": [{"text": "word recognition", "start_pos": 23, "end_pos": 39, "type": "TASK", "confidence": 0.7484020888805389}]}, {"text": "In the past LRTs were manually generated, as in LexTALE 1 and other LexTALE-like tests.", "labels": [], "entities": [{"text": "LexTALE 1", "start_pos": 48, "end_pos": 57, "type": "DATASET", "confidence": 0.8975602984428406}, {"text": "LexTALE-like tests", "start_pos": 68, "end_pos": 86, "type": "DATASET", "confidence": 0.9148843288421631}]}, {"text": "However, for the repetitive testing as used informative assessment, LRT's test stimuli need to be generated automatically using natural language processing (NLP) techniques.", "labels": [], "entities": []}, {"text": "The automatic generation of LRTs involves two NLP tasks: (i) a simple task: words selection from a corpus, and (ii) a complex task: nonwords generation.", "labels": [], "entities": [{"text": "automatic generation of LRTs", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.677506759762764}, {"text": "words selection from a corpus", "start_pos": 76, "end_pos": 105, "type": "TASK", "confidence": 0.8178687810897827}, {"text": "nonwords generation", "start_pos": 132, "end_pos": 151, "type": "TASK", "confidence": 0.7307555377483368}]}, {"text": "Some researchers have recently proposed an approach to The Lexical Test for Advanced Learners of English generate nonwords automatically using character n-gram language models as obtained from Brown corpus (Hamed and Zesch).", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 193, "end_pos": 205, "type": "DATASET", "confidence": 0.9065783321857452}]}, {"text": "They applied their approach to English, and considered word selection using frequency per million word.", "labels": [], "entities": [{"text": "word selection", "start_pos": 55, "end_pos": 69, "type": "TASK", "confidence": 0.7805843949317932}]}, {"text": "We want to generalize their approach to other languages, and more specifically Arabic, which is both interesting and challenging language.", "labels": [], "entities": []}, {"text": "Creating Arabic lexical recognition tests is a task that entails a lot of NLP challenges regarding automatic diacritization, corpus linguistic, morphological analysis e.g. lemmatization and language modeling.", "labels": [], "entities": [{"text": "Creating Arabic lexical recognition", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.714622363448143}, {"text": "language modeling", "start_pos": 190, "end_pos": 207, "type": "TASK", "confidence": 0.7753985226154327}]}, {"text": "While there exist well-established lexical recognition tests for English, and other European languages like German and Dutch), French and Spanish, for many under-resourced languages, like Arabic, a lot of challenges still remain.", "labels": [], "entities": []}, {"text": "We are aware of very few studies for Arabic, like).", "labels": [], "entities": []}, {"text": "Both studies were conducted without any diacritical marks, which means that the respondent claims to know the most frequent diacritized form of a word.", "labels": [], "entities": []}, {"text": "Although some researchers have recently shown that the diacritical marks play a vital role in improving the difficulty of Arabic LRTs (Hamed and Zesch, 2017), they did not automate the whole process.", "labels": [], "entities": []}, {"text": "In this paper, we address one of these NLP challenges by taking a closer look on the different approaches for Arabic automatic diacritization, a dominant step in the design process of Arabic tests and especially the role of lexical diacritics that area defining feature of Arabic word sense.", "labels": [], "entities": [{"text": "Arabic automatic diacritization", "start_pos": 110, "end_pos": 141, "type": "TASK", "confidence": 0.630221943060557}]}, {"text": "Next, we provide some background on lexical recognition tests, followed by the entailed NLP challenges.", "labels": [], "entities": [{"text": "lexical recognition", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.7184502631425858}]}], "datasetContent": [{"text": "The evaluation was conducted across the character and word levels.", "labels": [], "entities": []}, {"text": "For the Arabic LRTs, the test stimuli are not fully diacritized, instead they conform to specific diacritization (no default diacritics, no case-endings) settings.", "labels": [], "entities": []}, {"text": "Thus, the different error rates are reported in relaxed mode, not in strict mode: Strict Mode Whenever a letter has a set of diacritics in the gold standard, the tools are expected to predict exactly this set.", "labels": [], "entities": []}, {"text": "This means that we punish tools that only provide a partial diacritization, e.g. by not returning some default diacritics.", "labels": [], "entities": []}, {"text": "For example () /qAl/ instead of ( ) /qaAl/.", "labels": [], "entities": []}, {"text": "Relaxed Mode Whenever a letter has a set of diacritics in the gold standard, we do not expect the tool to predict exactly this set.", "labels": [], "entities": []}, {"text": "Which means that we do not punish the tools on a letter that does not hold a diacritic.", "labels": [], "entities": []}, {"text": "Instead, we only count for the letters that holds diacritic.", "labels": [], "entities": []}, {"text": "This assumption remains valid only for words that are labeled with at least one diacritic by the diacritization tool (i.e. the tool is punished if no-diacritics are provided).", "labels": [], "entities": []}, {"text": "The following pre/post-processing steps are applied on the text to do the comparison in relaxed mode.", "labels": [], "entities": []}, {"text": "\u2022 Comply to Default Diacritics It is important to note that both Madamira and Farasa ignore the default diacritics, so that we normalize the gold sequence in such away that also ignores the default diacritics to ensure fair comparison.", "labels": [], "entities": []}, {"text": "\u2022 Sukun Removal Some writing styles use the Sukun diacritic to mark un-diacritized letters and some styles leave such letters without any diacritic.", "labels": [], "entities": [{"text": "Sukun Removal", "start_pos": 2, "end_pos": 15, "type": "TASK", "confidence": 0.5854217708110809}]}, {"text": "To overcome these differences when computing the error rates, we discard the Sukun to neglect it in our evaluation.", "labels": [], "entities": [{"text": "Sukun", "start_pos": 77, "end_pos": 82, "type": "DATASET", "confidence": 0.8016158938407898}]}, {"text": "The experiments are carried out using DKPro TC, the open-source UIMA-based framework for supervised text classification ().", "labels": [], "entities": [{"text": "DKPro TC", "start_pos": 38, "end_pos": 46, "type": "DATASET", "confidence": 0.8818334639072418}, {"text": "supervised text classification", "start_pos": 89, "end_pos": 119, "type": "TASK", "confidence": 0.6436864137649536}]}, {"text": "All the experiments were conducted as tenfold (1 part testing, 9 parts training) cross validation reporting the average over the ten folds.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: List of Arabic Diacritization Systems.", "labels": [], "entities": []}, {"text": " Table 3: Statistics of corpora sub-datasets used in  this study.", "labels": [], "entities": []}, {"text": " Table 4: Average number of diacritics per letter  (Avg.), and the ratio of letters with diacritics (Ra- tio).", "labels": [], "entities": [{"text": "Avg.)", "start_pos": 52, "end_pos": 57, "type": "METRIC", "confidence": 0.9675510227680206}]}, {"text": " Table 5: Error rates in relaxed evaluation mode.", "labels": [], "entities": [{"text": "Error", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9923133254051208}]}]}