{"title": [{"text": "The AIP-Tohoku System at the BEA-2019 Shared Task", "labels": [], "entities": [{"text": "AIP-Tohoku System at the BEA-2019 Shared Task", "start_pos": 4, "end_pos": 49, "type": "DATASET", "confidence": 0.8319286618913923}]}], "abstractContent": [{"text": "We introduce the AIP-Tohoku grammatical error correction (GEC) system for the BEA-2019 shared task in Track 1 (Restricted Track) and Track 2 (Unrestricted Track) using the same system architecture.", "labels": [], "entities": [{"text": "AIP-Tohoku grammatical error correction (GEC)", "start_pos": 17, "end_pos": 62, "type": "TASK", "confidence": 0.6790013526167188}, {"text": "BEA-2019", "start_pos": 78, "end_pos": 86, "type": "DATASET", "confidence": 0.8007044196128845}]}, {"text": "Our system comprises two key components: error generation and sentence-level error detection.", "labels": [], "entities": [{"text": "error generation", "start_pos": 41, "end_pos": 57, "type": "TASK", "confidence": 0.7470548152923584}, {"text": "sentence-level error detection", "start_pos": 62, "end_pos": 92, "type": "TASK", "confidence": 0.6330214043458303}]}, {"text": "In particular , GEC with sentence-level grammatical error detection is a novel and versatile approach, and we experimentally demonstrate that it significantly improves the precision of the base model.", "labels": [], "entities": [{"text": "GEC", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.9061904549598694}, {"text": "sentence-level grammatical error detection", "start_pos": 25, "end_pos": 67, "type": "TASK", "confidence": 0.587081253528595}, {"text": "precision", "start_pos": 172, "end_pos": 181, "type": "METRIC", "confidence": 0.9991027116775513}]}, {"text": "Our system is ranked 9th in Track 1 and 2nd in Track 2.", "labels": [], "entities": []}], "introductionContent": [{"text": "As part of the BEA-2019 shared task, we participated in Track 1 (Restricted Track) and Track 2 (Unrestricted Track).", "labels": [], "entities": [{"text": "BEA-2019", "start_pos": 15, "end_pos": 23, "type": "DATASET", "confidence": 0.7126715183258057}]}, {"text": "We utilized the Transformer ( architecture as abase GEC model for machine translation systems as it has become a state-of-the-art approach for grammatical error correction (GEC).", "labels": [], "entities": [{"text": "machine translation", "start_pos": 66, "end_pos": 85, "type": "TASK", "confidence": 0.7776732742786407}, {"text": "grammatical error correction (GEC)", "start_pos": 143, "end_pos": 177, "type": "TASK", "confidence": 0.7638302544752756}]}, {"text": "In our system, the error correction model collaborates with a sentence-level error detection model.", "labels": [], "entities": [{"text": "error correction", "start_pos": 19, "end_pos": 35, "type": "TASK", "confidence": 0.681944340467453}, {"text": "sentence-level error detection", "start_pos": 62, "end_pos": 92, "type": "TASK", "confidence": 0.6341072817643484}]}, {"text": "In GEC, F 0.5 is used for evaluation because precision is more important than recall.", "labels": [], "entities": [{"text": "F 0.5", "start_pos": 8, "end_pos": 13, "type": "METRIC", "confidence": 0.9783822596073151}, {"text": "precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9993197917938232}, {"text": "recall", "start_pos": 78, "end_pos": 84, "type": "METRIC", "confidence": 0.9984959363937378}]}, {"text": "To improve the precision score on the test set, our system corrected the input sentences by detecting errors using a sentence-level error detection model (which we denote as SED).", "labels": [], "entities": [{"text": "precision score", "start_pos": 15, "end_pos": 30, "type": "METRIC", "confidence": 0.9819915592670441}, {"text": "SED", "start_pos": 174, "end_pos": 177, "type": "METRIC", "confidence": 0.9868424534797668}]}, {"text": "We applied the bidirectional encoder representations from transformers (BERT) model) for sentence-level error detection.", "labels": [], "entities": [{"text": "BERT", "start_pos": 72, "end_pos": 76, "type": "METRIC", "confidence": 0.9714571237564087}, {"text": "sentence-level error detection", "start_pos": 89, "end_pos": 119, "type": "TASK", "confidence": 0.6517191231250763}]}, {"text": "In order to improve the performance of SED, we propose an SED model taking the learner's proficiency into * Current affiliation: Yahoo Japan Corporation, hiroasan@yahoo-corp.jp \u2020 Current affiliation: Future Corporation, mizumoto.tomoya.mh7@is.naist.jp account.", "labels": [], "entities": [{"text": "SED", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.9672749638557434}, {"text": "Yahoo Japan Corporation", "start_pos": 129, "end_pos": 152, "type": "DATASET", "confidence": 0.9355177879333496}]}, {"text": "To the best of our knowledge, this is the first study that has combined GEC with SED.", "labels": [], "entities": [{"text": "GEC", "start_pos": 72, "end_pos": 75, "type": "DATASET", "confidence": 0.6146644353866577}, {"text": "SED", "start_pos": 81, "end_pos": 84, "type": "TASK", "confidence": 0.4249779284000397}]}, {"text": "Because grammatical correctness is required for output sentences in GEC, the target side of parallel training corpora should not contain noisy sentences.", "labels": [], "entities": []}, {"text": "Our correction model is trained to correct sentence pairs, which were identified by our sentence-level grammatical error detection model.", "labels": [], "entities": [{"text": "sentence-level grammatical error detection", "start_pos": 88, "end_pos": 130, "type": "TASK", "confidence": 0.5910688266158104}]}, {"text": "We call this data cleaning process BERT-Cleaning.", "labels": [], "entities": [{"text": "BERT-Cleaning", "start_pos": 35, "end_pos": 48, "type": "METRIC", "confidence": 0.9898077845573425}]}, {"text": "For Track 1, similar to back-translation, we augmented the parallel training corpus with errors generated from monolingual data.", "labels": [], "entities": []}, {"text": "After addition of the generated data and SED process, the F 0.5 score on the base model improved.", "labels": [], "entities": [{"text": "SED", "start_pos": 41, "end_pos": 44, "type": "METRIC", "confidence": 0.9729040265083313}, {"text": "F 0.5 score", "start_pos": 58, "end_pos": 69, "type": "METRIC", "confidence": 0.9852244655291239}]}, {"text": "For Track 2, we used the EF-Cambridge Open Language Database (EFCAMDAT)) and non-public Lang-8 as the external language learner corpus.", "labels": [], "entities": [{"text": "EF-Cambridge Open Language Database (EFCAMDAT))", "start_pos": 25, "end_pos": 72, "type": "DATASET", "confidence": 0.9127386382647923}]}], "datasetContent": [{"text": "We will now describe the training data and tools used to train our model.", "labels": [], "entities": []}, {"text": "For training our transformer-based GEC system, we used the BEA-2019 workshop official data: the First Certificate in English corpus (FCE)), the Lang-8 Corpus of Learner English (Lang-8), the National University of Singapore Corpus of Learner English (NUCLE) (, and W&I+LOCNESS (.", "labels": [], "entities": [{"text": "BEA-2019 workshop official data", "start_pos": 59, "end_pos": 90, "type": "DATASET", "confidence": 0.9576731026172638}, {"text": "First Certificate in English corpus (FCE))", "start_pos": 96, "end_pos": 138, "type": "DATASET", "confidence": 0.6459173001348972}, {"text": "Lang-8 Corpus of Learner English (Lang-8)", "start_pos": 144, "end_pos": 185, "type": "DATASET", "confidence": 0.9225768521428108}, {"text": "National University of Singapore Corpus of Learner English (NUCLE)", "start_pos": 191, "end_pos": 257, "type": "DATASET", "confidence": 0.7229896702549674}, {"text": "LOCNESS", "start_pos": 269, "end_pos": 276, "type": "METRIC", "confidence": 0.6762580871582031}]}, {"text": "Our pre-processing for training data is the same as that reported previously (.", "labels": [], "entities": []}, {"text": "As the result, we obtained 564,565 sentence pairs.", "labels": [], "entities": []}, {"text": "With respect to Simple Wikipedia, we ignored sentences that were longer than 60 tokens.", "labels": [], "entities": [{"text": "Simple Wikipedia", "start_pos": 16, "end_pos": 32, "type": "DATASET", "confidence": 0.8689147233963013}]}, {"text": "To remove erroneous sentences, we applied BERT-Cleaning to the essay scoring data sets.", "labels": [], "entities": [{"text": "BERT-Cleaning", "start_pos": 42, "end_pos": 55, "type": "METRIC", "confidence": 0.9975983500480652}, {"text": "essay scoring data sets", "start_pos": 63, "end_pos": 86, "type": "DATASET", "confidence": 0.7208663448691368}]}, {"text": "After BERT-Cleaning and preprocessing, we obtained 1,426,354 sentence pairs by error generation.", "labels": [], "entities": [{"text": "BERT-Cleaning", "start_pos": 6, "end_pos": 19, "type": "METRIC", "confidence": 0.9799874424934387}]}, {"text": "We used EFCAMDAT and non-public Lang-8 as the external language learner corpus.", "labels": [], "entities": [{"text": "EFCAMDAT", "start_pos": 8, "end_pos": 16, "type": "DATASET", "confidence": 0.8684072494506836}]}, {"text": "The EFCAMDAT is constructed by the Department of Theoretical and Applied Linguistics at the University of Cambridge. were the first the researchers to use the EF-CAMDAT for the GEC task.", "labels": [], "entities": [{"text": "EFCAMDAT", "start_pos": 4, "end_pos": 12, "type": "DATASET", "confidence": 0.829420804977417}, {"text": "GEC task", "start_pos": 177, "end_pos": 185, "type": "TASK", "confidence": 0.7360787987709045}]}, {"text": "However, the system trained with the EFCAMDAT gave lower performance than the system trained with the Lang-8 Corpus.", "labels": [], "entities": [{"text": "EFCAMDAT", "start_pos": 37, "end_pos": 45, "type": "DATASET", "confidence": 0.8801993727684021}, {"text": "Lang-8 Corpus", "start_pos": 102, "end_pos": 115, "type": "DATASET", "confidence": 0.9802379608154297}]}, {"text": "One of the causes of the lower performance is that many errors are found in the EF-CAMDAT corrected sentences.", "labels": [], "entities": [{"text": "EF-CAMDAT corrected sentences", "start_pos": 80, "end_pos": 109, "type": "DATASET", "confidence": 0.8213086724281311}]}, {"text": "Thus, we applied BERT-Cleaning to the EFCAMDAT to remove the erroneous sentences.", "labels": [], "entities": [{"text": "BERT-Cleaning", "start_pos": 17, "end_pos": 30, "type": "METRIC", "confidence": 0.996950626373291}, {"text": "EFCAMDAT", "start_pos": 38, "end_pos": 46, "type": "DATASET", "confidence": 0.9335362911224365}]}, {"text": "Consequently, the number of sentence pairs of EFCAMDAT was reduced from 1,157,339 to 760,393.", "labels": [], "entities": []}, {"text": "Finally, we used 7,739,577 sentence pairs (non-public Lang-8 + Cleand EF-CAMDAT) by using pre-processing as the additional training data.", "labels": [], "entities": []}], "tableCaptions": []}