{"title": [{"text": "The many dimensions of algorithmic fairness in educational applications", "labels": [], "entities": []}], "abstractContent": [{"text": "The issues of algorithmic fairness and bias have recently featured prominently in many publications highlighting the fact that training the algorithms for maximum performance may often result in predictions that are biased against various groups.", "labels": [], "entities": []}, {"text": "Educational applications based on NLP and speech processing technologies often combine multiple complex machine learning algorithms and are thus vulnerable to the same sources of bias as other machine learning systems.", "labels": [], "entities": []}, {"text": "Yet such systems can have high impact on people's lives especially when deployed as part of high-stakes tests.", "labels": [], "entities": []}, {"text": "In this paper we discuss different definitions of fairness and possible ways to apply them to educational applications.", "labels": [], "entities": []}, {"text": "We then use simulated and real data to consider how test-takers' native language backgrounds can affect their automated scores on an English language proficiency assessment.", "labels": [], "entities": []}, {"text": "We illustrate that total fairness may not be achievable and that different definitions of fairness may require different solutions.", "labels": [], "entities": []}], "introductionContent": [{"text": "The issues of algorithmic fairness and bias have recently featured prominently in many publications highlighting the fact that training the algorithms for maximum performance may often result in predictions that are biased against various groups.", "labels": [], "entities": []}, {"text": "Like any algorithm, NLP systems are not immune to such bias (.", "labels": [], "entities": []}, {"text": "These days it is hardly necessary to justify the importance of ensuring algorithmic fairness, especially in applications that can have a substantial impact on users' lives.", "labels": [], "entities": []}, {"text": "Automated test scoring is one such application, and the educational measurement community has been concerned with the fairness of automated scoring since long before this topic gained wide popularity.", "labels": [], "entities": [{"text": "Automated test scoring", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6979371706644694}]}, {"text": "There exist a variety of standard measures generally recommended for evaluating fairness of the automated scoring systems as well as open-source tools for computing such measures (.", "labels": [], "entities": []}, {"text": "In this paper we use the data from an operational spoken language proficiency assessment and an automated speech scoring engine to show that the application of these measures may sometimes lead to seemingly contradictory results.", "labels": [], "entities": []}, {"text": "We apply the insight from the machine learning community that there are different ways to formally define algorithmic fairness, and propose a framework which leverages work from both educational measurement and machine learning to formalize these definitions in the context of automated scoring.", "labels": [], "entities": []}], "datasetContent": [{"text": "We first computed standardized mean difference (SMD) a standard measure used to evaluate the fairness of automated scoring engines ().", "labels": [], "entities": [{"text": "standardized mean difference (SMD)", "start_pos": 18, "end_pos": 52, "type": "METRIC", "confidence": 0.9267094631989797}]}, {"text": "To do so, both human and system scores were converted to z-scores using their respective means and standard deviations.", "labels": [], "entities": []}, {"text": "SMD for each group is the average difference between such standardized human and system scores within this group (System score -human score).", "labels": [], "entities": [{"text": "System score -human score)", "start_pos": 114, "end_pos": 140, "type": "METRIC", "confidence": 0.8470058937867483}]}, {"text": "Absolute values above 0.1 are considered an issue of concern and require further evaluation ( shows SMDs for the four models.", "labels": [], "entities": [{"text": "SMDs", "start_pos": 100, "end_pos": 104, "type": "TASK", "confidence": 0.9305634498596191}]}, {"text": "As we predicted, the speakers of all languages would be disadvantaged by using the META model.", "labels": [], "entities": [{"text": "META", "start_pos": 83, "end_pos": 87, "type": "DATASET", "confidence": 0.5241201519966125}]}, {"text": "Yet surprisingly, even in the case of the \u223cPERFECT model two of the languages, GER and JPN, show absolute SMDs slightly above the recommended 0.1 threshold.", "labels": [], "entities": [{"text": "GER", "start_pos": 79, "end_pos": 82, "type": "DATASET", "confidence": 0.5550193786621094}]}, {"text": "In other words, the evaluation suggests that speakers of these two languages are not treated fairly by the model: GER speakers are underscored while JPN speakers are over-scored.", "labels": [], "entities": [{"text": "GER", "start_pos": 114, "end_pos": 117, "type": "METRIC", "confidence": 0.8025903105735779}]}, {"text": "Yet we know that the \u223cPERFECT model by design is blind to test-taker's L1.", "labels": [], "entities": [{"text": "PERFECT", "start_pos": 22, "end_pos": 29, "type": "METRIC", "confidence": 0.9086027145385742}]}, {"text": "Why then do we see relatively large SMDs?", "labels": [], "entities": [{"text": "SMDs", "start_pos": 36, "end_pos": 40, "type": "TASK", "confidence": 0.9585443735122681}]}, {"text": "The reason is the unusual score distribution for these two groups of test-takers and consequently the large difference in their mean scores.", "labels": [], "entities": []}, {"text": "As shown in, the scores are not distributed uniformly: the propor-: Proportion of responses assigned each of the four possible human scores for test-takers with each L1 and mean human score for each group tion of '2' and '3' is much higher (80% of all scores) than the proportion of '1' and '4'.", "labels": [], "entities": [{"text": "Proportion", "start_pos": 68, "end_pos": 78, "type": "METRIC", "confidence": 0.9677993655204773}]}, {"text": "Furthermore, proficiency levels as measured by human scores vary greatly across the 6 groups in our study: GER speakers have a very high proportion of score 4 responses (40.9%) and a mean score of 3.35, while JPN speakers have a high number of responses scored as '1' or '2' (63%) and a mean score of 2.286.", "labels": [], "entities": []}, {"text": "The very uneven score distribution in the training set, in combination with the noise we introduced to the 'feature', resulted in greater prediction error at the edges of the scale: mean standardized score differences is 0.35 for responses scored 1 and -0.29 for responses scored 4 vs. 0.17 for responses scored 2 and -0.05 for responses scored 3.", "labels": [], "entities": [{"text": "prediction error", "start_pos": 138, "end_pos": 154, "type": "METRIC", "confidence": 0.9381621479988098}, {"text": "standardized score differences", "start_pos": 187, "end_pos": 217, "type": "METRIC", "confidence": 0.9108294248580933}]}, {"text": "This in combination with the unusual score distribution lead to higher absolute SMDs for GER and JPN speakers.", "labels": [], "entities": [{"text": "SMDs", "start_pos": 80, "end_pos": 84, "type": "TASK", "confidence": 0.9000669717788696}, {"text": "GER", "start_pos": 89, "end_pos": 92, "type": "DATASET", "confidence": 0.7519615888595581}]}, {"text": "To confirm that the observed differences are due to score distribution and are not an artefact of the model-training process, we sampled from the test set a subset of 2,700 responses (450 responses per group) with identical (but not uniform) distributions of human scores in each group: the sample sizes for each score level were determined by the maximum number of responses available for this score level from all L1s.", "labels": [], "entities": []}, {"text": "As a result, 80% in this sample received a score of '3', 13% received a score of '2', 5% received a score of '4' and 1% received a score of '1'.", "labels": [], "entities": []}, {"text": "The mean human score for all subgroups was 2.9.", "labels": [], "entities": []}, {"text": "We then recomputed SMDs using only this subset.", "labels": [], "entities": [{"text": "SMDs", "start_pos": 19, "end_pos": 23, "type": "TASK", "confidence": 0.9807987809181213}]}, {"text": "While SMDs for the META model remained high, the absolute SMDs for the other three models were all below 0.02.", "labels": [], "entities": [{"text": "SMDs", "start_pos": 6, "end_pos": 10, "type": "METRIC", "confidence": 0.9438586831092834}, {"text": "META model", "start_pos": 19, "end_pos": 29, "type": "DATASET", "confidence": 0.9277227222919464}, {"text": "absolute SMDs", "start_pos": 49, "end_pos": 62, "type": "METRIC", "confidence": 0.7007869780063629}]}], "tableCaptions": [{"text": " Table 1: Standardized mean difference (system- human) for 6 languages in our corpus for scores gen- erated by different models. Absolute values above 0.1  threshold are highlighted in bold", "labels": [], "entities": [{"text": "Standardized mean difference", "start_pos": 10, "end_pos": 38, "type": "METRIC", "confidence": 0.825380543867747}]}, {"text": " Table 2: Proportion of responses assigned each of the  four possible human scores for test-takers with each L1  and mean human score for each group", "labels": [], "entities": []}, {"text": " Table 3: Adjusted R 2 showing the percentage of vari- ance in scoring error attributed to L1 for different mod- els and score distributions (equal and actual score dis- tribution). Larger values correspond to the greater im- pact of L1 on scoring error. Cells marked 'ns' mean  that the effect of L1 was not significant at \u03b1=0.01. See  section 4.2 for further explanation.", "labels": [], "entities": [{"text": "R", "start_pos": 19, "end_pos": 20, "type": "METRIC", "confidence": 0.9335826635360718}, {"text": "vari- ance in scoring error attributed", "start_pos": 49, "end_pos": 87, "type": "METRIC", "confidence": 0.6982497317450387}, {"text": "actual score dis- tribution", "start_pos": 152, "end_pos": 179, "type": "METRIC", "confidence": 0.7183396220207214}, {"text": "im- pact", "start_pos": 222, "end_pos": 230, "type": "METRIC", "confidence": 0.8891049226125082}]}, {"text": " Table 4. For the BASE model, test- taker L1 explained 1.7% of variance in OSD and  6.2% of variance in CSD. There also was a small  difference in OSA. In other words, these evalua- tions pointed towards a small but significant bias  in model performance.", "labels": [], "entities": [{"text": "BASE", "start_pos": 18, "end_pos": 22, "type": "DATASET", "confidence": 0.38819923996925354}]}, {"text": " Table 4: Adjusted R 2 showing percentage of variance  in scoring error attributed to L1 for different models  and score distributions. See caption to Table 3 and sec- tion 4.2 for further explanation", "labels": [], "entities": [{"text": "Adjusted R 2", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.7097590068976084}, {"text": "percentage of variance  in scoring error attributed", "start_pos": 31, "end_pos": 82, "type": "METRIC", "confidence": 0.7436869783060891}]}, {"text": " Table 5: Model estimates for 6 languages in our corpus  for scores generated by the BASE model. SPA is used as  a reference category.", "labels": [], "entities": [{"text": "BASE", "start_pos": 85, "end_pos": 89, "type": "METRIC", "confidence": 0.6164284348487854}]}, {"text": " Table 6. As in  the case of simulated models, SMDs allowed us  to reach the same general conclusion: L1 model  is the least fair and FAIR(ER) model is proba- bly the most fair of the three models. Yet in  this case SMDs also obscure the fact that both  BASE and FAIR(ER) model might be over-scoring  GER speakers: in fact the SMDs for the two mod- els have the opposite sign.", "labels": [], "entities": [{"text": "SMDs", "start_pos": 47, "end_pos": 51, "type": "TASK", "confidence": 0.9851661324501038}, {"text": "FAIR", "start_pos": 134, "end_pos": 138, "type": "METRIC", "confidence": 0.99008709192276}, {"text": "SMDs", "start_pos": 216, "end_pos": 220, "type": "TASK", "confidence": 0.9622569680213928}, {"text": "BASE", "start_pos": 254, "end_pos": 258, "type": "METRIC", "confidence": 0.9435091614723206}, {"text": "FAIR", "start_pos": 263, "end_pos": 267, "type": "METRIC", "confidence": 0.8560068607330322}]}, {"text": " Table 6: Standardized mean difference for 6 languages  in our corpus for scores generated by different models.  Absolute values above the 0.1 threshold are highlighted  in bold", "labels": [], "entities": [{"text": "Standardized mean difference", "start_pos": 10, "end_pos": 38, "type": "METRIC", "confidence": 0.7956072290738424}]}]}