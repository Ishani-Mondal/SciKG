{"title": [{"text": "Deep Reinforcement Learning For Modeling Chit-Chat Dialog With Discrete Attributes", "labels": [], "entities": [{"text": "Modeling Chit-Chat Dialog", "start_pos": 32, "end_pos": 57, "type": "TASK", "confidence": 0.7581621011098226}]}], "abstractContent": [{"text": "Open domain dialog systems face the challenge of being repetitive and producing generic responses.", "labels": [], "entities": []}, {"text": "In this paper, we demonstrate that by conditioning the response generation on interpretable discrete dialog attributes and composed attributes, it helps improve the model perplexity and results in diverse and interesting non-redundant responses.", "labels": [], "entities": [{"text": "response generation", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.7204145789146423}]}, {"text": "We propose to formulate the dialog attribute prediction as a reinforcement learning (RL) problem and use policy gradients methods to optimize utterance generation using long-term rewards.", "labels": [], "entities": [{"text": "dialog attribute prediction", "start_pos": 28, "end_pos": 55, "type": "TASK", "confidence": 0.6632593671480814}, {"text": "reinforcement learning (RL)", "start_pos": 61, "end_pos": 88, "type": "TASK", "confidence": 0.7173488020896912}, {"text": "utterance generation", "start_pos": 142, "end_pos": 162, "type": "TASK", "confidence": 0.7198195159435272}]}, {"text": "Unlike existing RL approaches which formulate the token prediction as a policy, our method reduces the complexity of the policy optimization by limiting the action space to dialog attributes, thereby making the policy optimization more practical and sample efficient.", "labels": [], "entities": [{"text": "formulate the token prediction", "start_pos": 36, "end_pos": 66, "type": "TASK", "confidence": 0.6693308874964714}]}, {"text": "We demonstrate this with experimental and human evaluations.", "labels": [], "entities": []}], "introductionContent": [{"text": "Following the success of neural machine translation systems (, there has been a growing interest in adapting the encoder-decoder models to model open-domain conversations).This is done by framing the next utterance generation as a machine translation problem by treating the dialog history as the source sequence and the next utterance as the target sequence.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 25, "end_pos": 51, "type": "TASK", "confidence": 0.7803171475728353}, {"text": "machine translation", "start_pos": 231, "end_pos": 250, "type": "TASK", "confidence": 0.7021931558847427}]}, {"text": "Then the models are trained end-to-end with Maximum Likelihood (MLE) objective without any hand crafted structures like slot-value pairs, dialog manager, etc used in conventional dialog modeling).", "labels": [], "entities": [{"text": "Maximum Likelihood (MLE) objective", "start_pos": 44, "end_pos": 78, "type": "METRIC", "confidence": 0.8250997761885325}]}, {"text": "Such data driven approaches are worth pursuing in the context of open-domain conversations since the next utterance distribution in open-domain conversations * Work done during internship at Google exhibit high entropy which makes it impractical to manually craft good features.", "labels": [], "entities": []}, {"text": "While the encoder-decoder approaches are promising, lack of specificity has been one of the many challenges () in modelling non-goal oriented dialogs.", "labels": [], "entities": []}, {"text": "Recent encoder-decoder based models usually tend to generate generic or dull responses like \"I don't know.\".", "labels": [], "entities": []}, {"text": "One of the main causes are the implicit imbalances present in the dialog datasets that tend to potentially handicap the models into generating uninteresting responses.", "labels": [], "entities": []}, {"text": "Imbalances in a dialog dataset can be broadly divided into two categories: many-to-one and oneto-many.", "labels": [], "entities": []}, {"text": "Many-to-one imbalance occurs when the dataset contain very similar responses to several different dialog contexts.", "labels": [], "entities": []}, {"text": "In such scenarios, decoder learns to ignore the context (considering it as noise) and behaves like a regular language model.", "labels": [], "entities": []}, {"text": "Such a decoder would not generalize to new contexts and will end up predicting generic responses for all contexts.", "labels": [], "entities": []}, {"text": "In the one-to-many case, the dataset may exhibit a different type of imbalance where a certain type of generic response maybe present in abundance compared to other plausible interesting responses for the same dialog context (.", "labels": [], "entities": []}, {"text": "When trained with a maximum-likelihood (MLE) objective, generative models usually tend to place more probability mass around the most commonly observed responses fora given context.", "labels": [], "entities": []}, {"text": "So, we end up observing little variance in the generated responses in such cases.", "labels": [], "entities": []}, {"text": "While these two imbalances are problematic for training a dialog model, they are also inherent characteristics of a dialog dataset which cannot be removed.", "labels": [], "entities": []}, {"text": "Several approaches have been proposed in the literature to address the generic response generation issue.", "labels": [], "entities": [{"text": "generic response generation", "start_pos": 71, "end_pos": 98, "type": "TASK", "confidence": 0.8805139263470968}]}, {"text": "propose to modify the loss function to increase the diversity in the generated responses.", "labels": [], "entities": []}, {"text": "Multi-resolution RNN ( ) addresses the above issue by additionally conditioning with entity information in the previous utterances.", "labels": [], "entities": []}, {"text": "Alternatively, uses external knowledge from a retrieval model to condition the response generation.", "labels": [], "entities": []}, {"text": "Latent variable models inspired by Conditional Variational Autoencoders (CVAEs) are explored in).", "labels": [], "entities": []}, {"text": "While models with continuous latent variables tend to be uninterpretable, discrete latent variable models exhibit high variance during inference.", "labels": [], "entities": []}, {"text": "append discrete attributes such as sentiment to the latent representation to generate next utterance.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we present the experimental results along with qualitative analysis.", "labels": [], "entities": []}, {"text": "In Section 4.1, we discuss the dialog attribute classification results for different model architectures trained on the Reddit, Switchboard and Frames datasets.", "labels": [], "entities": [{"text": "dialog attribute classification", "start_pos": 31, "end_pos": 62, "type": "TASK", "confidence": 0.6883626182874044}, {"text": "Frames datasets", "start_pos": 144, "end_pos": 159, "type": "DATASET", "confidence": 0.8899584114551544}]}, {"text": "In Section 4.2, we first demonstrate quantitative improvements (token perplexity/embedding based metrics) for the Attribute conditional HRED model with the manually annotated Reddit dataset.", "labels": [], "entities": [{"text": "Reddit dataset", "start_pos": 175, "end_pos": 189, "type": "DATASET", "confidence": 0.9398144781589508}]}, {"text": "Further, we discuss the model perplexity improvements along with sample conversations and human evaluation results on the Open-Subtitles dataset.", "labels": [], "entities": [{"text": "Open-Subtitles dataset", "start_pos": 122, "end_pos": 144, "type": "DATASET", "confidence": 0.9243071973323822}]}, {"text": "We annotate it with sentiment and dialog-acts (from Switchboard/Frames datasets) using pre-trained classifiers described in Section 4.1.", "labels": [], "entities": [{"text": "Frames datasets", "start_pos": 64, "end_pos": 79, "type": "DATASET", "confidence": 0.7355849891901016}]}, {"text": "Finally, in Section 4.3, we analyze the quality of the generated responses after RL fine-tuning us-ing diversity scores (distinct-1, distinct-2), sample conversations and human evaluation results for diversity and relevance.", "labels": [], "entities": [{"text": "RL fine-tuning us-ing diversity", "start_pos": 81, "end_pos": 112, "type": "TASK", "confidence": 0.7663323432207108}]}, {"text": "Following  Reddit: First, we evaluate Seq2Seq models trained on the manually annotated Reddit corpus as shown in.", "labels": [], "entities": [{"text": "Reddit corpus", "start_pos": 87, "end_pos": 100, "type": "DATASET", "confidence": 0.8397218286991119}]}, {"text": "Seq2Seq+Attr refers to our model where we condition on the dialog-acts additionally.", "labels": [], "entities": []}, {"text": "Please note that we use the notation \"Attr\" hereto maintain generality as it may refer to other dialog attributes like sentiment later in this section.", "labels": [], "entities": [{"text": "Attr", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.9772340059280396}]}, {"text": "For both the baseline and conditional Seq2Seq models, we consider a dialog context involving the previous two turns as we did not observe significant performance improvement with three or more turns.", "labels": [], "entities": []}, {"text": "We use a 2-layer GRU language model as a baseline for comparison.", "labels": [], "entities": []}, {"text": "As seen from, Seq2Seq+Attr fares well both in terms of perplexity and embedding metrics.", "labels": [], "entities": []}, {"text": "Higher perplexity observed in the Reddit corpus could be due to the presence of several topics in the dataset (exhibits high entropy) and fewer dialogs compared to other open domain dialog datasets.", "labels": [], "entities": [{"text": "Reddit corpus", "start_pos": 34, "end_pos": 47, "type": "DATASET", "confidence": 0.8689415156841278}]}, {"text": "Open-Subtitles: With promising results on the manually tagged Reddit corpus, we now evaluate our attribute conditional HRED model on the unannotated Open-Subtitles dataset.", "labels": [], "entities": [{"text": "Reddit corpus", "start_pos": 62, "end_pos": 75, "type": "DATASET", "confidence": 0.9282913506031036}, {"text": "HRED", "start_pos": 119, "end_pos": 123, "type": "METRIC", "confidence": 0.9170888662338257}, {"text": "Open-Subtitles dataset", "start_pos": 149, "end_pos": 171, "type": "DATASET", "confidence": 0.7102649360895157}]}, {"text": "We tag the OpenSubtitles dataset with the sentiment tags using the Stanford Core-NLP tool (  dialog-acts from Frames & Switchboard corpus using the pre-trained classifiers described in Section 4.1.", "labels": [], "entities": [{"text": "OpenSubtitles dataset", "start_pos": 11, "end_pos": 32, "type": "DATASET", "confidence": 0.922676682472229}, {"text": "Stanford Core-NLP", "start_pos": 67, "end_pos": 84, "type": "DATASET", "confidence": 0.9475585222244263}]}, {"text": "In, we compare the model perplexity when trained on varying dialog corpus size.", "labels": [], "entities": []}, {"text": "In most of the cases, we observe that the conditioning with acts from both the frames and switchboard yields the lowest perplexity.", "labels": [], "entities": []}, {"text": "We observe that the perplexity improvement is substantial for smaller datasets which is also corroborated from the experiments with the Reddit dataset.", "labels": [], "entities": [{"text": "Reddit dataset", "start_pos": 136, "end_pos": 150, "type": "DATASET", "confidence": 0.9304202198982239}]}, {"text": "Human Evaluation: Following the human evaluation setting in ( , we randomly sample 200 input message and the generated outputs from the Seq2Seq+Attr & Seq2Seq models.", "labels": [], "entities": []}, {"text": "We present each of them to 3 judges and ask them to decide which of the two outputs is 1) relevant and 2) diverse or interesting.", "labels": [], "entities": []}, {"text": "Results for human evaluation are shown in.", "labels": [], "entities": []}, {"text": "We observe that Seq2Seq+Attr performs better than the Seq2Seq model both in terms of diversity and relevance.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Dialog-acts prediction accuracy for classifiers  trained on validation set of different datasets.", "labels": [], "entities": [{"text": "Dialog-acts prediction", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.7964440286159515}, {"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9445380568504333}]}, {"text": " Table 3: Perplexity and Embedding Metrics for the  Reddit validation set.", "labels": [], "entities": [{"text": "Reddit validation set", "start_pos": 52, "end_pos": 73, "type": "DATASET", "confidence": 0.8576098283131918}]}, {"text": " Table 4: Validation Perplexity for the Open-Subtitles  dataset.", "labels": [], "entities": [{"text": "Open-Subtitles  dataset", "start_pos": 40, "end_pos": 63, "type": "DATASET", "confidence": 0.8432157039642334}]}, {"text": " Table 5: Human Evaluation results: Seq2Seq+Attr vs  Seq2Seq", "labels": [], "entities": [{"text": "Attr", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.8974470496177673}]}, {"text": " Table 7: Diversity scores on the Open-Subtitles valida- tion set after RL fine-tuning .", "labels": [], "entities": [{"text": "Open-Subtitles valida- tion set", "start_pos": 34, "end_pos": 65, "type": "DATASET", "confidence": 0.7066020727157593}]}, {"text": " Table 8:  Human Evaluation results:RL vs  Seq2Seq+Attr", "labels": [], "entities": [{"text": "RL", "start_pos": 36, "end_pos": 38, "type": "METRIC", "confidence": 0.6157263517379761}]}, {"text": " Table 9: Percentage of generic responses after RL fine- tuning.", "labels": [], "entities": [{"text": "Percentage", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9594202041625977}, {"text": "RL fine- tuning", "start_pos": 48, "end_pos": 63, "type": "TASK", "confidence": 0.6299100667238235}]}]}