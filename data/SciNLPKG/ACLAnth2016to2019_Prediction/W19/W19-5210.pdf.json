{"title": [{"text": "Integration of Dubbing Constraints into Machine Translation", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.7109552621841431}]}], "abstractContent": [{"text": "Translation systems aim to perform a meaning-preserving conversion of linguistic material (typically text but also speech) from a source to a target language (and, to a lesser degree, the corresponding socio-cultural contexts).", "labels": [], "entities": []}, {"text": "Dub-bing, i. e., the lip-synchronous translation and revoicing of speech adds to this constraints about the close matching of phonetic and resulting visemic synchrony characteristics of source and target material.", "labels": [], "entities": []}, {"text": "There is an inherent conflict between a translation's meaning preservation and its 'dubbability' and the resulting trade-off can be controlled by weighing the synchrony constraints.", "labels": [], "entities": [{"text": "translation's meaning preservation", "start_pos": 40, "end_pos": 74, "type": "TASK", "confidence": 0.6462087780237198}]}, {"text": "We introduce our work, which to the best of our knowledge is the first of its kind, on integrating syn-chrony constraints into the machine translation paradigm.", "labels": [], "entities": [{"text": "machine translation paradigm", "start_pos": 131, "end_pos": 159, "type": "TASK", "confidence": 0.8172640204429626}]}, {"text": "We present first results for the integration of synchrony constraints into encoder decoder-based neural machine translation and show that considerably more 'dubbable' translations can be achieved with only a small impact on BLEU score, and dubbability improves more steeply than BLEU degrades.", "labels": [], "entities": [{"text": "encoder decoder-based neural machine translation", "start_pos": 75, "end_pos": 123, "type": "TASK", "confidence": 0.6316180944442749}, {"text": "BLEU score", "start_pos": 224, "end_pos": 234, "type": "METRIC", "confidence": 0.9792958199977875}, {"text": "BLEU", "start_pos": 279, "end_pos": 283, "type": "METRIC", "confidence": 0.9608160257339478}]}], "introductionContent": [{"text": "Dubbing, the lip-synchronous translation and revoicing of audio-visual media, is essential for the full-fledged reception of foreign movies, TV shows, instructional videos, advertisements, or short social media clips.", "labels": [], "entities": []}, {"text": "Dubbing does not contend for the viewers' visual attention like subtitles) do, and unlike voice-over or asynchronous speech there is no (or only little) mismatch of visual and auditory impression where the resulting cognitive dissonance would otherwise increase the viewers' cognitive load, or even lead to understanding errors *This work was performed during an internship at.", "labels": [], "entities": []}, {"text": "Dubbing is still primarily studied in audiovisual translation and performed manually, unlike textual translation, which is largely being automated or supported by computer-aided translation.", "labels": [], "entities": [{"text": "Dubbing", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.9436711668968201}, {"text": "audiovisual translation", "start_pos": 38, "end_pos": 61, "type": "TASK", "confidence": 0.7523399889469147}, {"text": "textual translation", "start_pos": 93, "end_pos": 112, "type": "TASK", "confidence": 0.7455443143844604}]}, {"text": "Recent break-throughs in speech-to-speech translation (, do not yield translations that systematically observe dubbing constraints, i. e. do not match phonetically (or rather: visemically) the original source (we call this 'dubbability').", "labels": [], "entities": [{"text": "speech-to-speech translation", "start_pos": 25, "end_pos": 53, "type": "TASK", "confidence": 0.7033944427967072}]}, {"text": "It is our goal to create MT systems where the dubbability of the translation can be controlled so as to optimize the trade-off between translation quality and lip-synchrony of the dubbed speech.", "labels": [], "entities": [{"text": "MT", "start_pos": 25, "end_pos": 27, "type": "TASK", "confidence": 0.9847527146339417}]}, {"text": "We hope that more widely available dubbing across languages will help to stimulate access to foreign media and foster inter-cultural exchange.", "labels": [], "entities": []}, {"text": "We argue that dubbable MT will not simply emerge from training on dubbed audio-visual corpora, i. e. implicitly.", "labels": [], "entities": [{"text": "dubbable MT", "start_pos": 14, "end_pos": 25, "type": "TASK", "confidence": 0.6772258579730988}]}, {"text": "By comparison, audio-visual corpora will always remain smaller than pure textto-text translation corpora.", "labels": [], "entities": []}, {"text": "As a result, merely relying on training a conventional MT system on large amounts of dubbing texts is bound to severely limit performance.", "labels": [], "entities": [{"text": "MT", "start_pos": 55, "end_pos": 57, "type": "TASK", "confidence": 0.955248236656189}]}, {"text": "What's more, the task of dubbing combines the constraints of several areas (meaningpreserving as well as prosodically similar translation) which have different properties.", "labels": [], "entities": [{"text": "dubbing", "start_pos": 25, "end_pos": 32, "type": "TASK", "confidence": 0.9816396832466125}]}, {"text": "For example, for speech from the off or without the speaker's face visible, there are no limitations on prosodic similarity while it maybe critical in close-up scenes; the translation system would thus need to consider video as well (but only very selectively so).", "labels": [], "entities": []}, {"text": "Thus, we are looking fora flexible weighing of these two aspects which we achieve by introducing phonetic synchrony constraints that describe the 'dubbability' of a proposed translation, i. e., how well it is expected to allow for lip-synchronous revoicing in source (en): No, no.", "labels": [], "entities": []}, {"text": "Each individual's blood chemistry is unique, like fingerprints.", "labels": [], "entities": []}, {"text": "dubbed (es): No, no.", "labels": [], "entities": []}, {"text": "La sangre de cada individuo es\u00fanicaes\u00fanica, como una huella.", "labels": [], "entities": []}, {"text": "faithful: No, no.", "labels": [], "entities": []}, {"text": "La qu\u00edmica de la sangre de cada individuo es\u00fanicaes\u00fanica, como las huellas dactilares.) in its English original and Spanish dubbed revoicing, as well as a meaning-preserving translation.", "labels": [], "entities": []}, {"text": "The latter results in about 70 % too many syllables (32 vs. 19 in the source), and would be next to impossible to revoice in a lip-synchronous manner.", "labels": [], "entities": []}, {"text": "The human translator (and dubbing expert) resolved the issue by sacrificing some detail in the translation: two terms, \"blood chemistry\" and \"fingerprints\" can easily be translated slightly differently (leaving out the \"chemistry\" and \"finger\" aspects, as well as singularizing \"prints\") which reduces the syllable difference down to 20 % without sacrificing the overall meaning conveyed by the utterance.", "labels": [], "entities": []}, {"text": "We describe how synchrony constraints can be included in the MT process, in particular in the search/decoding process of neural MT, in the following section and then describe our implemented system in Section 3 and present results of our experimentation in Section 5.", "labels": [], "entities": [{"text": "MT process", "start_pos": 61, "end_pos": 71, "type": "TASK", "confidence": 0.9078209102153778}]}, {"text": "We conclude in Section 6 where we also present our plans for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Ideally, a dubbing-optimal translation system should be evaluated on dubbed material.", "labels": [], "entities": [{"text": "dubbing-optimal translation", "start_pos": 11, "end_pos": 38, "type": "TASK", "confidence": 0.9703757762908936}]}, {"text": "We use the HEROes dubbing corpus ( \u00a8 Oktem et al., 2018) a corpus of the TV show with the same name with the source (English) and dubbing into Spanish.", "labels": [], "entities": [{"text": "HEROes dubbing corpus", "start_pos": 11, "end_pos": 32, "type": "DATASET", "confidence": 0.7022922237714132}]}, {"text": "The corpus contains a total of 7000 manually aligned utterance pairs in 9.5 hours of speech and based on forced alignment of video subtitles to the audio tracks.", "labels": [], "entities": []}, {"text": "The audio material (in both is not yet used in the experiments reported below.", "labels": [], "entities": []}, {"text": "We find that the HEROes corpus contains 85,767 (resp. 83,561) syllables for English (resp. dubbed Spanish), as computed with Pyphen.", "labels": [], "entities": [{"text": "HEROes corpus", "start_pos": 17, "end_pos": 30, "type": "DATASET", "confidence": 0.810904860496521}, {"text": "Pyphen", "start_pos": 125, "end_pos": 131, "type": "METRIC", "confidence": 0.9005568623542786}]}, {"text": "The average number of syllables per utterance is 12.25 for English and 11.94 for Spanish.", "labels": [], "entities": []}, {"text": "We conclude that, on average, both languages use almost the same number of syllables and hence our phonetic similarity measure based on syllables should be useful.", "labels": [], "entities": []}, {"text": "(It would be possible, for other language pairs where the notion of syllable differs, e. g. when considering the mora-driven Japanese, to compute some sort of correction factor between the languages.", "labels": [], "entities": []}, {"text": "In our case, we simply ignore the relative difference in syllables of < 3 % between the languages.)", "labels": [], "entities": []}, {"text": "Although large fora dubbing corpus, the 7,000 utterances are far too little to train an NMT model on.", "labels": [], "entities": []}, {"text": "We hence use the English \u2192 Spanish parallel data in the Europarl corpus () for training and will evaluate on both the dubbing corpus and a test set based on the Europarl corpus.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 56, "end_pos": 71, "type": "DATASET", "confidence": 0.9713370203971863}, {"text": "Europarl corpus", "start_pos": 161, "end_pos": 176, "type": "DATASET", "confidence": 0.9805963337421417}]}, {"text": "The genre of science fiction TV shows may differ radically from parliament proceedings.", "labels": [], "entities": []}, {"text": "However, this merely results in lower BLEU performance on the out-of-domain data.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.9989689588546753}]}, {"text": "We believe that model adaptation (e.g. or relatively more in-domain training material (e.g. would work orthogonal to the dubbing-specific improvements in our paper.", "labels": [], "entities": []}, {"text": "Text pre-processing is identical for both corpora.", "labels": [], "entities": []}, {"text": "We measure the translation performance in terms of BLEU () as computed with the SacreBLEU software 8.", "labels": [], "entities": [{"text": "translation", "start_pos": 15, "end_pos": 26, "type": "TASK", "confidence": 0.9610632658004761}, {"text": "BLEU", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.9989873766899109}]}, {"text": "Dubbingoptimality of translations in the test-set T is determined by micro-averaging the dubbing-scores as follows: by synchrony-score for test-set T defined as: synchrony-score(T ) = e\u2208T abs(syll(NMT(e)) \u2212 syll(e)) e\u2208T syll(e)) where NMT(e) is the target translation given by the NMT model P (y|x) (with or without dubbing constraints applied) for English source text e.", "labels": [], "entities": [{"text": "Dubbingoptimality of translations", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.796045204003652}]}, {"text": "As is evident, the lower the synchrony score the better is the dubbing optimality.", "labels": [], "entities": [{"text": "dubbing", "start_pos": 63, "end_pos": 70, "type": "TASK", "confidence": 0.9667190909385681}]}, {"text": "We run our experiment to analyze the variation of BLEU vs. synchrony score for different rescoring factors \u03b1.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 50, "end_pos": 54, "type": "METRIC", "confidence": 0.9983081817626953}]}, {"text": "We use the trained NMT model as described in the above section.", "labels": [], "entities": []}, {"text": "Our decoding algorithm is as described in Algorithm 1, which we use to compute the relation between translation performance and dubbing-optimality of translations.", "labels": [], "entities": []}, {"text": "It has previously been pointed out that NMT performance suffers from abeam search size beyond 5 or 10 ( and numerous methods have been proposed to circumvent this.", "labels": [], "entities": []}, {"text": "However, for our present way of dubbing-optimization based on N-best rescoring, high beam sizes are essential for the dubbingrescoring described in Algorithm 1 to have some material to work with.", "labels": [], "entities": [{"text": "dubbing-optimization", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.9701066017150879}]}, {"text": "With only few candidates to be rescored, it might not necessarily give us the most 'dubbable' result.", "labels": [], "entities": []}, {"text": "We experimented with various beam sizes and found no BLEU degradation fora beam size of 50.", "labels": [], "entities": [{"text": "BLEU degradation", "start_pos": 53, "end_pos": 69, "type": "METRIC", "confidence": 0.986172616481781}]}, {"text": "Larger beams may eventually lead to a degradation and run time would become overly long as it linearly increases with the beam size.", "labels": [], "entities": []}, {"text": "Owing to the best of both worlds, we resort to abeam size of 50 for the experiments reported below.", "labels": [], "entities": []}, {"text": "shows BLEU scores (left scale, higher is better) and synchrony score (right scale, lower is better) of our proposed system fora range of \u03b1 between 0 and 1.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 6, "end_pos": 10, "type": "METRIC", "confidence": 0.9994121789932251}]}, {"text": "Notice that \u03b1 = 0 corresponds to no rescoring, i. e. the baseline system.", "labels": [], "entities": []}, {"text": "The relatively low BLEU score of 13.67 for the baseline system reflects the domain-mismatch between HEROes and Europarl.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 19, "end_pos": 29, "type": "METRIC", "confidence": 0.9846251904964447}, {"text": "HEROes", "start_pos": 100, "end_pos": 106, "type": "METRIC", "confidence": 0.7844358682632446}, {"text": "Europarl", "start_pos": 111, "end_pos": 119, "type": "DATASET", "confidence": 0.9800353646278381}]}, {"text": "We find that BLEU score is impacted only moderately for relatively low values of \u03b1, with a relative decrease of 2 % for \u03b1 = .3.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 13, "end_pos": 23, "type": "METRIC", "confidence": 0.9697891175746918}]}, {"text": "At the same time, we find the synchrony score to improve drastically already with small values of \u03b1: while the difference in syllables between source and target is almost one quarter in the baseline system, this is almost halved, down to 14 % for \u03b1 = .3.", "labels": [], "entities": []}, {"text": "also contains the synchrony score of the proposed translations vs. the actual gold-standard dubbed texts (dotted line in the.", "labels": [], "entities": []}, {"text": "As can be seen, the similarity increases up to about \u03b1 = .3 and then flattens out.", "labels": [], "entities": [{"text": "similarity", "start_pos": 20, "end_pos": 30, "type": "METRIC", "confidence": 0.9881995916366577}, {"text": "\u03b1", "start_pos": 53, "end_pos": 54, "type": "METRIC", "confidence": 0.9617469310760498}]}, {"text": "This is inline with our observation that, while source and target number of syllables correlate highly, there is no perfect match, indicating that our synchrony constraint has only limited value.", "labels": [], "entities": []}, {"text": "However, it also points to the fact that a human dubbing expert needs to find the middle ground between faithful translation and perfect synchrony.", "labels": [], "entities": []}, {"text": "Given that two differing linguistic systems are involved, a perfect synchrony is simply impossible if the meaning is to remain approximately correct.", "labels": [], "entities": []}, {"text": "We also evaluate our method in-domain, on test data sampled from Europarl (excluded from training).", "labels": [], "entities": [{"text": "Europarl", "start_pos": 65, "end_pos": 73, "type": "DATASET", "confidence": 0.9259682297706604}]}, {"text": "In particular, we use those source sentences for which multiple reference translations are contained in the corpus (about 18k instances).", "labels": [], "entities": []}, {"text": "Europarl translations, of course, are not transcripts of lip-synchronously dubbed speech.", "labels": [], "entities": [{"text": "Europarl translations", "start_pos": 0, "end_pos": 21, "type": "DATASET", "confidence": 0.9355337023735046}]}, {"text": "Thus, our expectations for synchrony constraints are somewhat lower.", "labels": [], "entities": []}, {"text": "However, testing in-domain still helps greatly to validate our out-of-domain results above.", "labels": [], "entities": []}, {"text": "As can be seen in, we see a similar decrease in BLEU scores (and only very gradually for small \u03b1 values) and more strongly improving synchrony scores.", "labels": [], "entities": [{"text": "BLEU scores", "start_pos": 48, "end_pos": 59, "type": "METRIC", "confidence": 0.9798920452594757}]}, {"text": "This again points towards a useful trade-off when combining synchrony constraints with the requirement of meaning-preserving translations.", "labels": [], "entities": []}, {"text": "There is a range of possible reasons why our method does notwork as well for Europarl as for the HEROes corpus.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 77, "end_pos": 85, "type": "DATASET", "confidence": 0.9697147011756897}, {"text": "HEROes corpus", "start_pos": 97, "end_pos": 110, "type": "DATASET", "confidence": 0.8955596685409546}]}, {"text": "In particular, Europarl is not transcribed speech and hence maybe less 'dubbable' by nature; many phrases in Europarl may translate to phrases with a different number of syllables in the target language, yet the model is reluctant to give up this translation in the in-domain condition; the proxy-target of syllables may work less well for longer, more specific words as found in legal texts, where a focus on only accentuated syllables maybe more useful.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Custom hyperparameters of our convolutional  encoder-decoder model; all other hyperparameters are  set as by Gehring et al. (2017).", "labels": [], "entities": []}]}