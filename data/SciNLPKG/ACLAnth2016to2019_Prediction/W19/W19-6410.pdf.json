{"title": [], "abstractContent": [{"text": "We present the approach developed at the Faculty of Engineering of the University of Porto to participate in FinTOC-2019 Financial Document Structure Extraction-Detection of titles sub-task.", "labels": [], "entities": [{"text": "FinTOC-2019 Financial Document Structure Extraction-Detection of titles", "start_pos": 109, "end_pos": 180, "type": "TASK", "confidence": 0.7785315258162362}]}, {"text": "Several financial documents are produced in machine-readable format.", "labels": [], "entities": []}, {"text": "Due to the poor structure of these documents, it is an arduous task to retrieve the desired information from them.", "labels": [], "entities": []}, {"text": "The aim of this sub-task is to detect titles in this kind of documents.", "labels": [], "entities": []}, {"text": "We propose a supervised learning approach making use of linguistic, semantic and morphological features to classify a text block as title or non title.", "labels": [], "entities": []}, {"text": "The proposed methodology got a F1 score of 97.01%.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9868139922618866}]}], "introductionContent": [{"text": "Several financial documents are produced, everyday, for different financial applications.", "labels": [], "entities": []}, {"text": "Some of these documents are mandatory bylaw, however they are not created following the same standard and sometimes have a poor structure, making it difficult to retrieve the desired information.", "labels": [], "entities": []}, {"text": "These documents are usually published in machine-readable format (such as Portable Document Format (PDF) files) but unfortunately, they remain untagged -they have no tags for identifying layout items such as paragraphs, columns, or tables.", "labels": [], "entities": []}, {"text": "Document structuring has clear benefits to users, enabling them to gain direct access to the relevant part of the document (which can be lengthy), improving also search performance.", "labels": [], "entities": [{"text": "Document structuring", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8719982802867889}]}, {"text": "Financial Prospectuses are financial documents where investment funds are described, and have a non-standard content format.", "labels": [], "entities": []}, {"text": "These documents need to be consulted by distinct persons and fast retrievals of data are desired.", "labels": [], "entities": []}, {"text": "A lot of effort has already been put to label the structure of documents.", "labels": [], "entities": []}, {"text": "Some known projects are the Million Book project, the Open Content Alliance (OCA) (, or the digitisation of Google).", "labels": [], "entities": [{"text": "Million Book project", "start_pos": 28, "end_pos": 48, "type": "DATASET", "confidence": 0.9079596598943075}]}, {"text": "Projects that have aim at automatically recognizing document structure take, as input, a document in PDF format, or its content obtained via Optical Character Recognition (OCR).", "labels": [], "entities": []}, {"text": "Document structure extraction is a well studied problem in document analysis, and has been applied in distinct types of documents and in different domains.", "labels": [], "entities": [{"text": "Document structure extraction", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8887796600659689}, {"text": "document analysis", "start_pos": 59, "end_pos": 76, "type": "TASK", "confidence": 0.7307284474372864}]}, {"text": "Works on this matter go from scientific articles ()) to books.) make use of three types of features: geometrical (width, height, X position, among others), morphological (the font and other characteristics, such as italics, bold, and so on) and semantic (language, is numeric, and so on).", "labels": [], "entities": []}, {"text": "Bitew (Bitew, 2018) also includes three distinct categories: textual features (similar to semantic), markup features (similar to morphological) and linguistic (related with Part of Speech).", "labels": [], "entities": [{"text": "Bitew (Bitew, 2018)", "start_pos": 0, "end_pos": 19, "type": "DATASET", "confidence": 0.8752876122792562}]}, {"text": "As described, some authors groups features in categories; however, some studies use only one category, including, who make use of morphological elements only for logical structured extraction.", "labels": [], "entities": [{"text": "logical structured extraction", "start_pos": 162, "end_pos": 191, "type": "TASK", "confidence": 0.745236357053121}]}, {"text": "The methodologies used to address this problem include rule-based and machine learning approaches (.", "labels": [], "entities": []}, {"text": "In this paper we present a supervised approach to automatically classify a text block as title or non title (a binary classification problem), making use of linguistic, semantic and morphological features.", "labels": [], "entities": []}, {"text": "In Section 2, we describe the FinTOC Sub-Task on title detection, and in Section 3 we analyze the provided data.", "labels": [], "entities": [{"text": "title detection", "start_pos": 49, "end_pos": 64, "type": "TASK", "confidence": 0.7912213504314423}]}, {"text": "In Section 4 we present our approach, followed by the experimental setup in Section 5.", "labels": [], "entities": []}, {"text": "Results are discussed in Section 6.", "labels": [], "entities": []}, {"text": "In Section 7 we conclude.", "labels": [], "entities": []}], "datasetContent": [{"text": "FinTOC organizers provide an excel file with text blocks information.", "labels": [], "entities": []}, {"text": "Each line represents one text block and each column their characteristics: \u2022 text blocks: text block textual content; \u2022 begins with numbering: 1 if the text block begins with a numbering such as 1., A/, b), III., etc.", "labels": [], "entities": []}, {"text": "The test set has the same format as the training set, but without information in the last column of the CSV file.", "labels": [], "entities": [{"text": "CSV file", "start_pos": 104, "end_pos": 112, "type": "DATASET", "confidence": 0.9812874495983124}]}, {"text": "This column is meant to be filled in by systems participating in the task.", "labels": [], "entities": []}, {"text": "The training set contains 44 distinct documents, not standardized.", "labels": [], "entities": []}, {"text": "The CSV file used as training set contains 75625 annotated rows.", "labels": [], "entities": [{"text": "CSV file", "start_pos": 4, "end_pos": 12, "type": "DATASET", "confidence": 0.9697198867797852}]}, {"text": "More details about the training set are included on.", "labels": [], "entities": []}, {"text": "The test set is composed of 7 PDF files (whose length ranges from 35 to 134 pages, with an average of 64 pages).", "labels": [], "entities": []}, {"text": "The CSV file is composed of 14816 non-annotated rows.", "labels": [], "entities": [{"text": "CSV file", "start_pos": 4, "end_pos": 12, "type": "DATASET", "confidence": 0.9529288113117218}]}, {"text": "The set of features used in each experimental setup is shown in.", "labels": [], "entities": []}, {"text": "Experiment 5 (E 5) is our baseline, as this setup includes all the features available in the dataset.", "labels": [], "entities": []}, {"text": "We combine all the available features with all extracted by us in Experiment 2 (E 2).", "labels": [], "entities": []}, {"text": "We create a model based on E 2 and select all the features with an importance above 0.03 to compose Experiment 3 (E 3) and above 0.07 to include in Experiment 4 (E 4).", "labels": [], "entities": []}, {"text": "Experiment 1 (E 1) was based in our analysis regarding text blocks number of characters categories distribution, such as presented in.", "labels": [], "entities": []}, {"text": "Several combinations of features and algorithms were applied to solve the title classification problem.", "labels": [], "entities": [{"text": "title classification problem", "start_pos": 74, "end_pos": 102, "type": "TASK", "confidence": 0.8856844504674276}]}, {"text": "The results obtained are shown in.: Results E 5 is the experiment that has as feature set all the features available upfront with the dataset.", "labels": [], "entities": []}, {"text": "This experiment got similar results using distinct supervised learning algorithms.", "labels": [], "entities": []}, {"text": "The results obtained indicate that this set of features are not enough to classify block text titles, showing a high number of false negatives and a low number of true positives.", "labels": [], "entities": [{"text": "classify block text titles", "start_pos": 74, "end_pos": 100, "type": "TASK", "confidence": 0.8780067265033722}]}, {"text": "The DT 1 and DTC 1 algorithms have distinct configurations, however they presented the same results when exposed to the same feature set.", "labels": [], "entities": []}, {"text": "The GBC 1 algorithm configuration was more sensible when exposed to a specific feature set -in E 1, this algorithm has shown the higher number of false positives obtained in our experiments.", "labels": [], "entities": [{"text": "GBC 1 algorithm", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.8094475666681925}]}, {"text": "GBC 2 was the worst configuration algorithm used in this classification, having the lowest value of true positives.", "labels": [], "entities": [{"text": "GBC", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8975881934165955}]}, {"text": "The feature set used in E 1 includes all features provided by the competition organizers.", "labels": [], "entities": [{"text": "E 1", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.7930339276790619}]}, {"text": "Other features were added, some of them related to how the text appears in the text block (such as number of characters or sentences), and also language dependent features (such as the case of F11).", "labels": [], "entities": [{"text": "F11", "start_pos": 193, "end_pos": 196, "type": "METRIC", "confidence": 0.978906512260437}]}, {"text": "Except for GBC 1, all other algorithm configurations reached their best result.", "labels": [], "entities": [{"text": "GBC", "start_pos": 11, "end_pos": 14, "type": "DATASET", "confidence": 0.854354977607727}]}, {"text": "EXT 1 got the best performance in the task of title classification.", "labels": [], "entities": [{"text": "EXT 1", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9725213050842285}, {"text": "title classification", "start_pos": 46, "end_pos": 66, "type": "TASK", "confidence": 0.7135602682828903}]}, {"text": "FinTOC-2019 received two submissions for each participant, on which we achieved F1 score of 97.01% on E 1 with EXT 1 reaching the fifth position and the sixth position with F1 score of 96.84% on E 1 with DT 1.", "labels": [], "entities": [{"text": "FinTOC-2019", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.8964316248893738}, {"text": "F1 score", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9865039885044098}, {"text": "F1 score", "start_pos": 173, "end_pos": 181, "type": "METRIC", "confidence": 0.9866517186164856}]}], "tableCaptions": [{"text": " Table 1: Training set statistics (TB = text block; NC =  number of characters).", "labels": [], "entities": []}, {"text": " Table 2: Number of characters distributed in categories  and in the training set (TS)", "labels": [], "entities": []}]}