{"title": [{"text": "Development of a Universal Dependencies treebank for Welsh", "labels": [], "entities": [{"text": "Universal Dependencies treebank", "start_pos": 17, "end_pos": 48, "type": "DATASET", "confidence": 0.7462111711502075}, {"text": "Welsh", "start_pos": 53, "end_pos": 58, "type": "DATASET", "confidence": 0.7026744484901428}]}], "abstractContent": [{"text": "This paper describes the development of the first syntactically-annotated corpus of Welsh within the Universal Dependencies (UD) project.", "labels": [], "entities": [{"text": "Universal Dependencies (UD) project", "start_pos": 101, "end_pos": 136, "type": "DATASET", "confidence": 0.5275846521059672}]}, {"text": "We explain how the corpus was prepared, and some Welsh-specific constructions that require attention.", "labels": [], "entities": []}, {"text": "The treebank currently contains 10 756 tokens.", "labels": [], "entities": []}, {"text": "An 10-fold cross evaluation shows that results of both, tagging and dependency parsing, are similar to other treebanks of comparable size, notably the other Celtic language treebanks within the UD project.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.7646400332450867}, {"text": "Celtic language treebanks within the UD project", "start_pos": 157, "end_pos": 204, "type": "DATASET", "confidence": 0.6630721134798867}]}], "introductionContent": [{"text": "The Welsh Treebank is the third Celtic language within the Universal Dependencies project, after Irish ( and.", "labels": [], "entities": [{"text": "Welsh Treebank", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.9686727821826935}]}, {"text": "The main goal of the Universal Dependencies treebanks is to have many different languages annotated with identical guidelines and universally defined set of universal POS tags and dependency relations.", "labels": [], "entities": [{"text": "Universal Dependencies treebanks", "start_pos": 21, "end_pos": 53, "type": "DATASET", "confidence": 0.5721048613389333}]}, {"text": "These cross-linguistically consistent grammatical annotations can be used, for instance, for typological language comparison or developping and evaluating cross-linguistic tagging and parsing tools.", "labels": [], "entities": [{"text": "typological language comparison", "start_pos": 93, "end_pos": 124, "type": "TASK", "confidence": 0.6660450597604116}, {"text": "cross-linguistic tagging and parsing", "start_pos": 155, "end_pos": 191, "type": "TASK", "confidence": 0.6754500418901443}]}, {"text": "The motivation was twofold: To have a Welsh treebank annotated using the same guidelines as many existing treebanks which permits language comparison and to have a (start for a) treebank which can be used to train dependency parsers.", "labels": [], "entities": [{"text": "Welsh treebank annotated", "start_pos": 38, "end_pos": 62, "type": "DATASET", "confidence": 0.9200293819109598}, {"text": "language comparison", "start_pos": 130, "end_pos": 149, "type": "TASK", "confidence": 0.686781570315361}]}, {"text": "Since the UD project already contains 146 treebanks for 83 languages and provides annotation principles which have been used in typological very different languages, we chose to develop the Welsh treebank within the UD project.", "labels": [], "entities": [{"text": "UD project", "start_pos": 10, "end_pos": 20, "type": "DATASET", "confidence": 0.9096264541149139}, {"text": "Welsh treebank", "start_pos": 190, "end_pos": 204, "type": "DATASET", "confidence": 0.9681737124919891}, {"text": "UD project", "start_pos": 216, "end_pos": 226, "type": "DATASET", "confidence": 0.8594691455364227}]}, {"text": "At the time of writing 601 sentences with 10 756 tokens in total have been annotated and released with UD version 2.4.", "labels": [], "entities": []}, {"text": "The paper is laid out as follows: in Section 2 we give a short typological overview of Welsh.", "labels": [], "entities": []}, {"text": "Section 3 describes briefly prior work for Welsh in computational linguistics and syntax as well as existing resources.", "labels": [], "entities": []}, {"text": "In sections 4 and 5 we describe the annotated corpus, the preprocessing steps and present some particularities of Welsh and how we annotate them.", "labels": [], "entities": []}, {"text": "Section 6 explains the validation process.", "labels": [], "entities": [{"text": "validation", "start_pos": 23, "end_pos": 33, "type": "TASK", "confidence": 0.9872776865959167}]}, {"text": "We conclude with a short evaluation in section 7 and some remarks on future work (section 8).", "labels": [], "entities": []}], "datasetContent": [{"text": "Even though the treebank currently contains only 601 sentences, tests for tagging and dependency parsing show results comparable with similar sized treebanks (   Nearly half of the word forms in the test corpus are out-of-vocabulary (OOV) with respect to the training corpus.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.7765151560306549}]}, {"text": "The dictionary provided roughly half of the missing words.", "labels": [], "entities": []}, {"text": "Thus a quarter of the words in the test corpus remains OOV, which may explain the unexpected low performance (UDpipe switches off its guesser, if a dictionary is provided).", "labels": [], "entities": [{"text": "OOV", "start_pos": 55, "end_pos": 58, "type": "METRIC", "confidence": 0.9852713346481323}]}, {"text": "The results of dependency analysis are presented in table 6 using 3 of the standard metrics for dependency parsing, Labelled Attachment Score (LAS, evaluates heads and dependency labels) or Content Word LAS (CLAS, as LAS, but only for dependency relations of content words (excluding aux, cop, mark, det, clf, case, cc).", "labels": [], "entities": [{"text": "dependency analysis", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.8207053542137146}, {"text": "dependency parsing", "start_pos": 96, "end_pos": 114, "type": "TASK", "confidence": 0.7300408035516739}]}, {"text": "We run four tests, a model trained solely on the treebank, with dependencies parsed on the results of the tagger, and dependencies parsed using gold tags.", "labels": [], "entities": []}, {"text": "The other two tests use the Eurfa dictionary again.", "labels": [], "entities": [{"text": "Eurfa dictionary", "start_pos": 28, "end_pos": 44, "type": "DATASET", "confidence": 0.8929254114627838}]}, {"text": "The better results of tagging with the full form lexicon, also improves the dependency parsing, if the parsing is done on predicted POS tags.", "labels": [], "entities": [{"text": "tagging", "start_pos": 22, "end_pos": 29, "type": "TASK", "confidence": 0.9730654954910278}, {"text": "dependency parsing", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.6651543974876404}]}, {"text": "All three metrics increase accordingly.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: relative frequency of (some) UPOS, XPOS", "labels": [], "entities": [{"text": "XPOS", "start_pos": 45, "end_pos": 49, "type": "DATASET", "confidence": 0.5716341733932495}]}, {"text": " Table 3: relative frequency of all 34 used deprels", "labels": [], "entities": [{"text": "relative frequency", "start_pos": 10, "end_pos": 28, "type": "METRIC", "confidence": 0.7655213475227356}]}, {"text": " Table 4: results of POS tagging and lemmatisation (F- measure", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 21, "end_pos": 32, "type": "TASK", "confidence": 0.8203605711460114}, {"text": "F- measure", "start_pos": 52, "end_pos": 62, "type": "METRIC", "confidence": 0.9035106698671976}]}, {"text": " Table 6: results of dependency parsing", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.8446430563926697}]}]}