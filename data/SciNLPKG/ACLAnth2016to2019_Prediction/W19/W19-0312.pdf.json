{"title": [{"text": "Is this the end? Two-step tokenization of sentence boundaries", "labels": [], "entities": [{"text": "tokenization of sentence boundaries", "start_pos": 26, "end_pos": 61, "type": "TASK", "confidence": 0.8198110014200211}]}], "abstractContent": [{"text": "A period does not only mark the end of a sentence; it can also be part of an abbreviation and numerical expressions.", "labels": [], "entities": []}, {"text": "When analysing corpus text linguistically we need to know where a sentence begins and where it ends.", "labels": [], "entities": []}, {"text": "In traditional corpus analysis, typically a sentence is identified before linguistic analysis is performed.", "labels": [], "entities": []}, {"text": "In this work we propose an approach where we do basic linguistic analysis before we decide what a sentence is.", "labels": [], "entities": []}, {"text": "As the interpretation of a period after abbreviations and numerical expressions is ambiguous, we leave the ambiguity in the initial tokenization.", "labels": [], "entities": []}, {"text": "Ina second step we remove the ambiguity based on the linguistic context of the period.", "labels": [], "entities": []}, {"text": "We compare the previous approach to the new one and show how the new two-step approach to tokenization improves the identification of sentence boundaries.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 90, "end_pos": 102, "type": "TASK", "confidence": 0.9739856123924255}, {"text": "identification of sentence boundaries", "start_pos": 116, "end_pos": 153, "type": "TASK", "confidence": 0.8640917092561722}]}, {"text": "Abstract Piste ei ole vain merkki lauseen p\u00e4\u00e4tt\u00e4misest\u00e4, se voi my\u00f6s olla osa lyhen-nett\u00e4 tai numeroa.", "labels": [], "entities": [{"text": "Piste", "start_pos": 9, "end_pos": 14, "type": "TASK", "confidence": 0.7218800187110901}]}, {"text": "Kun analysoidaan korpustekstej\u00e4 kielitieteellisesti, t\u00e4ytyy ti-et\u00e4\u00e4, miss\u00e4 on lauseen alku ja loppu.", "labels": [], "entities": []}, {"text": "Perinteisesti lauseen loppu on l\u00f6ydetty en-nen kielitieteellist\u00e4 analyysia.", "labels": [], "entities": []}, {"text": "T\u00e4ss\u00e4 artikkelissa ehdotamme menettely\u00e4, jonka mukaan kielitieteellinen perusanalyysi on tehty ennen lauseiden l\u00f6yt\u00e4mist\u00e4.", "labels": [], "entities": []}, {"text": "Koska lyhyen ja numeerisen ilmaisun j\u00e4lkeisen pisteen tulkinta on ep\u00e4selv\u00e4, j\u00e4t\u00e4mme ep\u00e4selvyyden selvitt\u00e4misen tekem\u00e4tt\u00e4 prosessoimisen alkuvaiheessa.", "labels": [], "entities": []}, {"text": "Toisessa vaiheessa poistamme ep\u00e4selvyyden lauseen kielellisen kontekstin perusteella.", "labels": [], "entities": []}, {"text": "Ver-tailemme aikaisemmat l\u00e4hestymistavat uuteen j\u00e4 n\u00e4yt\u00e4mme, miten uusi kaksivai-heinen l\u00e4hestymistapa j\u00e4sent\u00e4miseen parantaa lauserajojen tunnistamisen.", "labels": [], "entities": []}, {"text": "Abstract \u010cuokkis ii du\u0161\u0161e mearkkat cealkkaloahpa; muhtumin dat lea oan\u00e1dusa oassi ja lohkos\u00e1tnedajaldaga oassi.", "labels": [], "entities": []}, {"text": "Go mii analyseret korpusteavstta lingvisttala\u010d\u010dat, de d\u00e1rbbahit diehtit gokko cealkka \u00e1lg\u00e1 ja gokko dat loahpp\u00e1.", "labels": [], "entities": []}, {"text": "\u00c1rbevirola\u0161 kor-pusanalysas l\u00e1ve cealkka mearriduvvot ovdal lingvisttala\u0161 vuo\u0111\u0111oanalysa.", "labels": [], "entities": []}, {"text": "D\u00e1n This work is licensed under a Creative Commons Attribution 4.0 International Licence.", "labels": [], "entities": [{"text": "D\u00e1n", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9378723502159119}]}, {"text": "Licence details: http://creativecommons.org/licenses/by/4.0/ 142 barggus mii \u00e1rvalit lahkonanvuogi mas mii dahkat lingvisttala\u0161 analysa ovdal go mearridit mii cealkka lea.", "labels": [], "entities": []}, {"text": "Danin go \u010duogg\u00e1 mann\u00e1 dulkot guovtti l\u00e1dje oan\u00e1dusa ja lohkos\u00e1tnedajaldaga ma\u014bis, de mii diktit ambiguitehta orrut \u00e1lgotokeniseremis.", "labels": [], "entities": []}, {"text": "Nuppi l\u00e1vkkis mii fas dulkot daid nu ahte ambiguitehta j\u00e1vk\u00e1-\u010duogg\u00e1 lingvistta-la\u0161 birrasa vuo\u0111ul.", "labels": [], "entities": []}, {"text": "Mii buohtastahttit ovdala\u0161 lahkonanvuogi dainna o\u0111\u0111a vugiin ja \u010d\u00e1jehit got o\u0111\u0111a guovttel\u00e1vkkat vuohki tokeniseret dahk\u00e1 \u00e1lkibun mearridit cealkkar\u00e1jiid.", "labels": [], "entities": []}], "introductionContent": [{"text": "North S\u00e1mi is a Uralic language with a complex morphological structure spoken in Norway, Sweden and Finland by approximately 25 700 speakers (.", "labels": [], "entities": []}, {"text": "In corpus analysis the first challenge is the correct identification of the basic syntactic frame, the sentence.", "labels": [], "entities": []}, {"text": "While a combination of period and whitespace is typically seen as a reliable indicator for the sentence, there are many contexts in which this is not the case.", "labels": [], "entities": []}, {"text": "In this paper we challenge this rather rigid and local analysis of potential sentence boundaries and suggest a flexible approach initially assuming ambiguity and later disambiguating this ambiguity by means of morpho-syntactic context conditions.", "labels": [], "entities": []}, {"text": "In the method we present we are using a morphological analyser as a centerpiece of tokenization of free text using hfst-pmatch and hfst-tokenise, and we specifically look at sentence boundary detection and disambiguation, using the morphological analysis of various abbreviated expressions to help identify sentence boundaries.", "labels": [], "entities": [{"text": "sentence boundary detection", "start_pos": 174, "end_pos": 201, "type": "TASK", "confidence": 0.6484096050262451}]}, {"text": "Combining a transducer with a tokenization tool lets us delay the resolution of ambiguous tokenization, including sentence boundaries.", "labels": [], "entities": [{"text": "resolution of ambiguous tokenization", "start_pos": 66, "end_pos": 102, "type": "TASK", "confidence": 0.7871087342500687}]}, {"text": "We then use a Constraint Grammar (CG -see below) module that looks at the context of the ambiguous sentence boundaries to disambiguate and decide whether a period is also an end of sentence mark, or just part of an abbreviated expression or numerical expressions like dates and ordinals.", "labels": [], "entities": []}, {"text": "Due to the typology of North S\u00e1mi combined with the scarcity of corpus resources, using a lexicon-based finite state transducer for morphological analysis it is the only viable option.", "labels": [], "entities": []}, {"text": "Both the typology and lack of corpus material are shared with most other Uralic languages, so what is done for North S\u00e1mi should be quite relevant for the other languages in the family, as well as for other languages with similar typology.", "labels": [], "entities": []}, {"text": "For the same reason we do not consider statistical approaches fruitful, there just is not enough material for most of these languages.", "labels": [], "entities": []}, {"text": "A comparison with deep machine learning methods would bean interesting task fora future project.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we are going to evaluate our new approach to tokenization.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 61, "end_pos": 73, "type": "TASK", "confidence": 0.9736835360527039}]}, {"text": "A common method for splitting sentences in a complete pipeline (used for example by LanguageTool) is to tokenise first, then do sentence splitting, followed by other stages of linguistic analysis.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 128, "end_pos": 146, "type": "TASK", "confidence": 0.71133653819561}]}, {"text": "The quantitative evaluation is split in two: the first part only looks at expressions ending in a full stop that are truly ambiguous with respect to sentence boundariesthe full stop can both be and not be a sentence boundary depending on the context.", "labels": [], "entities": []}, {"text": "The evaluation looks at the performance of the pipeline for this specific subset of the corpus.", "labels": [], "entities": []}, {"text": "The second evaluation looks at all instances of expressions ending in full stops, both the unambiguous and the ambiguous ones, and compare the performance of two different approaches as measured to a gold standard version of the tokenized text.", "labels": [], "entities": []}, {"text": "Again, we only look at sentence boundaries, but in this evaluation we look at the overall performance.", "labels": [], "entities": []}, {"text": "The two pipelines evaluated are the old pipeline and the new pipeline described elsewhere in this article.", "labels": [], "entities": []}, {"text": "Within the qualitative evaluation where we analyze the cases of unsuccessful sentence boundary identification and analyze the reasons for the shortcomings.", "labels": [], "entities": [{"text": "sentence boundary identification", "start_pos": 77, "end_pos": 109, "type": "TASK", "confidence": 0.6722007989883423}]}, {"text": "In this part of the evaluation, we particularly focus on the performance of the tokenizer in contexts that are ambiguous, and we evaluate the identification of sentence boundaries rather than successful tokenization in general.", "labels": [], "entities": []}, {"text": "In the quantitative evaluation of ambiguous sentence boundary (SB) detection we calculated both precision (correct fraction of all decisions), recall (correct fraction of all targeted constructions) and accuracy (all correct decisions as fraction of all decisions).", "labels": [], "entities": [{"text": "ambiguous sentence boundary (SB) detection", "start_pos": 34, "end_pos": 76, "type": "TASK", "confidence": 0.6970317193440029}, {"text": "precision", "start_pos": 96, "end_pos": 105, "type": "METRIC", "confidence": 0.9994643330574036}, {"text": "recall", "start_pos": 143, "end_pos": 149, "type": "METRIC", "confidence": 0.9994774460792542}, {"text": "accuracy", "start_pos": 203, "end_pos": 211, "type": "METRIC", "confidence": 0.9993346333503723}]}, {"text": "As an evaluation corpus we chose a newspaper corpus containing the 2014 texts of the daily North S\u00e1mi newspaper \u00c1vvir 4 .The corpus used contains 556 644 space separated strings, as reported by the Unix tool wc.", "labels": [], "entities": [{"text": "newspaper corpus containing the 2014 texts of the daily North S\u00e1mi newspaper \u00c1vvir 4", "start_pos": 35, "end_pos": 119, "type": "DATASET", "confidence": 0.7557526933295386}]}, {"text": "The exact number of tokens will vary depending on tokenization methods, as described below.: Quantitative evaluation of ambiguous sentence boundary tokenization after morphological analysis  While some errors in the sentence boundary identification are due to problems in the lexicon, others require more precise rules in the disambiguation grammar mwedis.cg3.", "labels": [], "entities": [{"text": "sentence boundary identification", "start_pos": 216, "end_pos": 248, "type": "TASK", "confidence": 0.6522850592931112}]}, {"text": "(11), the period after the pronoun su 'her, his' is not correctly identified as a sentence boundary, it is a false positive.", "labels": [], "entities": []}, {"text": "Instead su=sulli 'approximately' is identified as an abbreviation with the period being part of the expression.", "labels": [], "entities": []}, {"text": "The pronoun reading does not even appear in the analysis.", "labels": [], "entities": []}, {"text": "\"<su.>\" \"su\" Adv ABBR Gram/NumNoAbbr <W:0.0000000000 > ; \".\"", "labels": [], "entities": [{"text": "ABBR", "start_pos": 17, "end_pos": 21, "type": "METRIC", "confidence": 0.9510864019393921}]}, {"text": "CLB <W:0.0000000000 > \"<.>\" ; \"su\" Adv ABBR Gram/NumNoAbbr <W:0.0000000000 > \"<su >\" This is due to an issue in the lexicon that is easily solvable, but had not been detected at the time of doing the analysis used as basis for the evaluation.", "labels": [], "entities": [{"text": "ABBR", "start_pos": 39, "end_pos": 43, "type": "METRIC", "confidence": 0.9715691804885864}]}, {"text": "The core of the issue is that some pronouns, such as su above, can also be abbreviated adverbs with obligatory full stops.", "labels": [], "entities": []}, {"text": "What was missing in the lexicon is a signal for such abbreviated adverbs that will trigger retokenization.", "labels": [], "entities": []}, {"text": "Such triggers are easy to add, and needs to be added only once for the whole category.", "labels": [], "entities": []}, {"text": "(12), the time expression 20.00 (Sem/Time-clock) is ambiguous with a date expression (Sem/Date).", "labels": [], "entities": []}, {"text": "This needs to be corrected in the morphological analyzer as 20.00 is not a valid date.", "labels": [], "entities": []}, {"text": "The time expression is erroneously removed and the sentence boundary is not identified.", "labels": [], "entities": []}, {"text": "gaskal between 13.00 13.00 ja and 20.00. 20.00 'between 1 and 8 pm.", "labels": [], "entities": []}, {"text": "' \" <13.00 >\" \"13.00\" Num Arab Sg Gen <W:0.0000000000 > \"13.00\" Num Sem/Time -clock Sg Gen <W:0.0000000000 > : \"<ja >\" \"ja\" CC <W:0.0000000000 > : \" <20.00.", "labels": [], "entities": []}, {"text": ">\" \"20.00\" Num Sem/Date Sg Gen <W:0.0000000000 > ; \".\"", "labels": [], "entities": []}, {"text": "CLB <W:0> \"<.>\" ; \"20.00\" Num Sem/Time -clock Sg Nom <W:0> \" <20.00 >\" REMOVE :2426: longest -match ; \".\"", "labels": [], "entities": [{"text": "CLB", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9152897000312805}, {"text": "REMOVE", "start_pos": 71, "end_pos": 77, "type": "METRIC", "confidence": 0.935860276222229}, {"text": "longest -match", "start_pos": 85, "end_pos": 99, "type": "METRIC", "confidence": 0.9424426158269247}]}, {"text": "CLB <W:0> \"<.>\" In other cases, the error in the analysis is due to shortcomings in the disambiguation file mwe-dis.cg3.", "labels": [], "entities": []}, {"text": "(13), the name is is followed by two initials before the surname.", "labels": [], "entities": []}, {"text": "The period after the first initial is erroneously interpreted as a sentence boundary.", "labels": [], "entities": []}, {"text": "There is a rule that removes the sentence boundary reading if there is one initial after a first and before the surname.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Quantitative evalu- ation of ambiguous sentence  boundary tokenization after  morphological analysis", "labels": [], "entities": [{"text": "Quantitative evalu- ation of ambiguous sentence  boundary tokenization", "start_pos": 10, "end_pos": 80, "type": "TASK", "confidence": 0.7661693228615655}]}, {"text": " Table 2: Quantitative evaluation and com- parison of the OLD and the NEW sentence  boundary detection pipelines.", "labels": [], "entities": [{"text": "OLD", "start_pos": 58, "end_pos": 61, "type": "DATASET", "confidence": 0.6950104236602783}, {"text": "NEW sentence  boundary detection pipelines", "start_pos": 70, "end_pos": 112, "type": "TASK", "confidence": 0.8141461491584778}]}]}