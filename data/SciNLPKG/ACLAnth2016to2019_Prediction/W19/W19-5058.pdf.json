{"title": [], "abstractContent": [{"text": "This study describes the model design of the NCUEE system for the MEDIQA challenge at the ACL-BioNLP 2019 workshop.", "labels": [], "entities": [{"text": "MEDIQA challenge at the ACL-BioNLP 2019 workshop", "start_pos": 66, "end_pos": 114, "type": "TASK", "confidence": 0.5339450921331134}]}, {"text": "We use the BERT (Bidirectional Encoder Representations from Transformers) as the word embedding method to integrate the BiLSTM (Bidirectional Long Short-Term Memory) network with an attention mechanism for medical text inferences.", "labels": [], "entities": [{"text": "BERT", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.986775279045105}, {"text": "medical text inferences", "start_pos": 206, "end_pos": 229, "type": "TASK", "confidence": 0.6282482445240021}]}, {"text": "A total of 42 teams participated in natural language inference task at MEDIQA 2019.", "labels": [], "entities": [{"text": "natural language inference task", "start_pos": 36, "end_pos": 67, "type": "TASK", "confidence": 0.6868287548422813}, {"text": "MEDIQA 2019", "start_pos": 71, "end_pos": 82, "type": "DATASET", "confidence": 0.8369031250476837}]}, {"text": "Our best accuracy score of 0.84 ranked the top-third among all submissions in the leaderboard.", "labels": [], "entities": [{"text": "accuracy score", "start_pos": 9, "end_pos": 23, "type": "METRIC", "confidence": 0.974485456943512}]}], "introductionContent": [{"text": "Natural Language Inference (NLI) is the task of determining whether a given hypothesis is true (entailment), false (contradiction) or undetermined (neutral) by inferring a given premise.", "labels": [], "entities": [{"text": "Natural Language Inference (NLI)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8043528149525324}]}, {"text": "The Stanford Natural Language Inference (SNLI) corpus is a well-known dataset and serves as a benchmark for NLI system evaluations (.", "labels": [], "entities": [{"text": "Stanford Natural Language Inference (SNLI) corpus", "start_pos": 4, "end_pos": 53, "type": "DATASET", "confidence": 0.5770282074809074}]}, {"text": "However, it is restricted to a single text genre.", "labels": [], "entities": []}, {"text": "Therefore, the MedNLI dataset, which is annotated by doctors and grounded in patients' medical histories, was built to perform NLI tasks in the clinical domain.", "labels": [], "entities": [{"text": "MedNLI dataset", "start_pos": 15, "end_pos": 29, "type": "DATASET", "confidence": 0.9617857933044434}]}, {"text": "In addition to feature-based methods and bag-of-words (BOW) models, other experiments have tested several modern neural networks-based models for the specialized and knowledge intensive field of medicine, including InferSent () and ESIM ( The MEDIQA challenge focuses on attracting research efforts in Natural Language Inference (NLI), Recognizing Question Entailment (RQE) and their applications in medical Question Answering (QA).", "labels": [], "entities": [{"text": "ESIM", "start_pos": 232, "end_pos": 236, "type": "METRIC", "confidence": 0.8083410859107971}, {"text": "Recognizing Question Entailment (RQE)", "start_pos": 336, "end_pos": 373, "type": "TASK", "confidence": 0.7396901448567709}, {"text": "medical Question Answering (QA)", "start_pos": 400, "end_pos": 431, "type": "TASK", "confidence": 0.7970118721326193}]}, {"text": "The MEDIQA challenge includes three tasks: 1) NLI: identifying three inference relations between two medical sentences, that is, entailment, neutral and contradiction.", "labels": [], "entities": []}, {"text": "2) RQE: identifying entailment between two questions in the context of QA.", "labels": [], "entities": [{"text": "RQE", "start_pos": 3, "end_pos": 6, "type": "METRIC", "confidence": 0.5188319683074951}, {"text": "identifying entailment between two questions", "start_pos": 8, "end_pos": 52, "type": "TASK", "confidence": 0.8907765507698059}]}, {"text": "3) QA: filtering and improving the input ranks of retrieved answers, generated by the medical QA system CHiQA.", "labels": [], "entities": []}, {"text": "The reuse of NLI and/or RQE systems for this task is highly recommended.", "labels": [], "entities": []}, {"text": "Under the policies of the MEDIQA challenge, we only participated in the first NLI task.", "labels": [], "entities": [{"text": "MEDIQA challenge", "start_pos": 26, "end_pos": 42, "type": "DATASET", "confidence": 0.6939206421375275}]}, {"text": "Recently, anew method of pre-training language representations named BERT (Bidirectional Encoder Representations from Transformers) has obtained groundbreaking results on a wide array of natural language processing tasks.", "labels": [], "entities": [{"text": "BERT", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.9966235160827637}]}, {"text": "This achievement motivates us to explore using a BERT based model to tackle the textual inference problem in the medical domain.", "labels": [], "entities": [{"text": "BERT", "start_pos": 49, "end_pos": 53, "type": "METRIC", "confidence": 0.9852448105812073}]}, {"text": "This paper describes the NCUEE (National Central University, Dept. of Electrical Engineering) system for the NLI task of the MEDIQA challenge at the ACL-BioNLP 2019 workshop.", "labels": [], "entities": [{"text": "NCUEE (National Central University, Dept. of Electrical Engineering)", "start_pos": 25, "end_pos": 93, "type": "DATASET", "confidence": 0.8669560389085249}, {"text": "MEDIQA challenge at the ACL-BioNLP 2019 workshop", "start_pos": 125, "end_pos": 173, "type": "TASK", "confidence": 0.48475001965250286}]}, {"text": "Our solution explores a BERT-based model, in which the BiLSTM network with attention mechanism is integrated for textual inference.", "labels": [], "entities": [{"text": "BERT-based", "start_pos": 24, "end_pos": 34, "type": "METRIC", "confidence": 0.9499530792236328}]}, {"text": "The input sentence-pair is represented as a sequence of words.", "labels": [], "entities": []}, {"text": "Each word refers to distributed vectors from a pretrained BERT to form as an embedding matrix.", "labels": [], "entities": [{"text": "BERT", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.9366788268089294}]}, {"text": "The datasets provided by the task organizers are used to train the BiLSTM network with attention model for the prediction task.", "labels": [], "entities": []}, {"text": "The output is a value from 0 to 1 representing the estimated class probability.", "labels": [], "entities": []}, {"text": "The class with the highest probability (that is, one of entailment, neutral and contradiction) will be regarded as the inference result.", "labels": [], "entities": []}, {"text": "Our best accuracy score of 0.84 ranked in the top-third of all 42 submissions in the leaderboard.", "labels": [], "entities": [{"text": "accuracy score", "start_pos": 9, "end_pos": 23, "type": "METRIC", "confidence": 0.9750080108642578}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Results of BERT vs. BioBERT", "labels": [], "entities": [{"text": "BERT", "start_pos": 21, "end_pos": 25, "type": "METRIC", "confidence": 0.8712426424026489}, {"text": "BioBERT", "start_pos": 30, "end_pos": 37, "type": "DATASET", "confidence": 0.64656001329422}]}]}