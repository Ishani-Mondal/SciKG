{"title": [{"text": "Team JUST at the MADAR Shared Task on Arabic Fine-Grained Dialect Identification", "labels": [], "entities": [{"text": "JUST", "start_pos": 5, "end_pos": 9, "type": "METRIC", "confidence": 0.9211602807044983}, {"text": "MADAR Shared Task", "start_pos": 17, "end_pos": 34, "type": "TASK", "confidence": 0.6587581038475037}, {"text": "Arabic Fine-Grained Dialect Identification", "start_pos": 38, "end_pos": 80, "type": "TASK", "confidence": 0.6295142769813538}]}], "abstractContent": [{"text": "In this paper, we describe our team's effort on the MADAR Shared Task on Arabic Fine-Grained Dialect Identification.", "labels": [], "entities": [{"text": "MADAR Shared Task on Arabic Fine-Grained Dialect Identification", "start_pos": 52, "end_pos": 115, "type": "TASK", "confidence": 0.5412642881274223}]}, {"text": "The task requires building a system capable of differentiating between 25 different Ara-bic dialects in addition to MSA.", "labels": [], "entities": []}, {"text": "After preprocessing the data, we use Data Augmentation (DA) to enlarge the training data six times.", "labels": [], "entities": []}, {"text": "We then build a language model and extract n-gram word-level and character-level TF-IDF features and feed them into an MNB classifier.", "labels": [], "entities": []}, {"text": "Despite its simplicity, the resulting model performs really well producing the 4th highest F-measure and region-level accuracy and the 5th highest precision, recall , city-level accuracy and country-level accuracy among the participating teams.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 91, "end_pos": 100, "type": "METRIC", "confidence": 0.9968639612197876}, {"text": "accuracy", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.9729772210121155}, {"text": "precision", "start_pos": 147, "end_pos": 156, "type": "METRIC", "confidence": 0.9994065761566162}, {"text": "recall", "start_pos": 158, "end_pos": 164, "type": "METRIC", "confidence": 0.9977627992630005}, {"text": "accuracy", "start_pos": 178, "end_pos": 186, "type": "METRIC", "confidence": 0.9298365712165833}, {"text": "accuracy", "start_pos": 205, "end_pos": 213, "type": "METRIC", "confidence": 0.9292295575141907}]}], "introductionContent": [{"text": "Give apiece of text, the Dialect Identification (DI) is concerned with automatically determining the dialect in which it is written.", "labels": [], "entities": []}, {"text": "This is a very important problem in many languages including Arabic.", "labels": [], "entities": []}, {"text": "Unlike previous works on Arabic DI (ADI), which take a coarse-grained approach by considering regional-level or country-level () dialects, anew task has been proposed for the fine-grained ADI focusing on a large number of city-/countrylevel dialects.", "labels": [], "entities": []}, {"text": "This task is quite challenging as it covers 25 different dialects in addition to Modern Standard Arabic (MSA).", "labels": [], "entities": [{"text": "Modern Standard Arabic (MSA)", "start_pos": 81, "end_pos": 109, "type": "DATASET", "confidence": 0.8941531479358673}]}, {"text": "Some of these dialects are very close to each other as we observe in our analysis of the training data (see Section 2).", "labels": [], "entities": []}, {"text": "Also, due to the relatively small size of the dataset, cuttingedge techniques for document/sentence classification, which are based on word embeddings and deep learning models, perform poorly on it.", "labels": [], "entities": [{"text": "document/sentence classification", "start_pos": 82, "end_pos": 114, "type": "TASK", "confidence": 0.5847510620951653}]}, {"text": "In fact, according to, the top performing systems for this task as well as the previously published baseline (  all use traditional (non-neural) machine learning approaches.", "labels": [], "entities": []}, {"text": "This is very surprising if one takes into account that the use of Deep Learning in Arabic NLP is still at its early stages . In this paper, we describe our team's effort to tackle this task.", "labels": [], "entities": []}, {"text": "After preprocessing the data, we use Data Augmentation (DA) to enlarge the training data six times.", "labels": [], "entities": []}, {"text": "We then build a language model and extract n-gram word-level and characterlevel TF-IDF features and feed them into a Multinomial Naive Bayes (MNB) classifier.", "labels": [], "entities": []}, {"text": "Despite its simplicity, the resulting model performs really well producing the 4th highest Macro-F1 measure (66.33%) and Region-level Accuracy (84.54%) and the 5th highest Macro-Precision (66.56%), Macro-Recall (66.42%), City-level Accuracy (66.42%) and Country-level Accuracy (74.71%) among the participating teams.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 134, "end_pos": 142, "type": "METRIC", "confidence": 0.7874752879142761}, {"text": "Accuracy", "start_pos": 232, "end_pos": 240, "type": "METRIC", "confidence": 0.7391584515571594}, {"text": "Country-level", "start_pos": 254, "end_pos": 267, "type": "METRIC", "confidence": 0.8929833769798279}, {"text": "Accuracy", "start_pos": 268, "end_pos": 276, "type": "METRIC", "confidence": 0.5252955555915833}]}, {"text": "Unfortunately, due to a problem with our submission file, the official results for our system were extremely poor, which placed our team at the bottom of the official ranking.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we discuss the task at hand while analyzing the provided data.", "labels": [], "entities": []}, {"text": "In Section 3, we describe our system and its details while, in Section 4, we present and analyze its results and performance.", "labels": [], "entities": []}, {"text": "Finally, the paper is concluded in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "The shared task at hand comprises of two subtasks.", "labels": [], "entities": []}, {"text": "The first one is the Travel Domain ADI, whose data are taken from Multi-Arabic Dialect Applications and Resources (MADAR) project . Our team only focused on this subtask.", "labels": [], "entities": [{"text": "Travel Domain ADI", "start_pos": 21, "end_pos": 38, "type": "DATASET", "confidence": 0.719807505607605}]}, {"text": "The second subtask is the Twitter User ADI and it is outside the scope of this work.", "labels": [], "entities": [{"text": "Twitter User ADI", "start_pos": 26, "end_pos": 42, "type": "DATASET", "confidence": 0.8197792371114095}]}, {"text": "For the subtask at hand, the organizers provide three sets: train (stored in a file called MADAR-Corpus-26-train and we refer to it as Corpus-26), development (dev) and test.", "labels": [], "entities": [{"text": "MADAR-Corpus-26-train", "start_pos": 91, "end_pos": 112, "type": "DATASET", "confidence": 0.8765187859535217}, {"text": "Corpus-26", "start_pos": 135, "end_pos": 144, "type": "DATASET", "confidence": 0.9357771873474121}]}, {"text": "The train, dev and test sets consist of 41,600, 5,200 and 5,200 parallel sentences, respectively, written in MSA as well as the local dialect of 25 cities: Rabat (RAB), Fes (FES), Algiers (ALG), Tu- To aid in the training and model building processes, the organizers also provide additional train & dev data sets consisting of 54,000 and 6,000 parallel sentences covering only six dialects: BEI, CAI, DOH, MSA, RAB and TUN.", "labels": [], "entities": [{"text": "BEI", "start_pos": 391, "end_pos": 394, "type": "METRIC", "confidence": 0.9624838829040527}]}, {"text": "The additional train set is stored in a file called MADAR-Corpus-6-train and we refer to it as Corpus-6.", "labels": [], "entities": [{"text": "MADAR-Corpus-6-train", "start_pos": 52, "end_pos": 72, "type": "DATASET", "confidence": 0.8937613368034363}, {"text": "Corpus-6", "start_pos": 95, "end_pos": 103, "type": "DATASET", "confidence": 0.9912170171737671}]}, {"text": "Before we go into the details of our system, we present a simple analysis of the provided data.", "labels": [], "entities": []}, {"text": "Figure 1 shows that the sentences of the dialects do not differ much in terms of average word/sentence lengths per dialect) or the number of unique words per dialect).", "labels": [], "entities": []}, {"text": "Our analysis shows that while there are 27,501 unique words in all dialects, there is a small number of words (specifically, 84 words) common in all dialects.", "labels": [], "entities": []}, {"text": "Examples of such words include: . Now, the most interesting part in our analysis is the varying similarity between the different dialects pairs under consideration.", "labels": [], "entities": []}, {"text": "Overall, there are 7,280 common sentences between dialects pairs and the average number of common sentences between dialects pairs, on average the- re is 22.4 common sentences between any dialects pairs.", "labels": [], "entities": []}, {"text": "Another relevant observation is the repetition of sentences across different dialects pairs, which is not limited to the dialects from the same country or region.", "labels": [], "entities": []}, {"text": "For example, the dialect pairs with 100 or more common sentences are: AMM-JER, DAM-ALE, JER-SAL, AMM-SAL, DAM-JER & AMM-DAM, whereas, the pairs with less than 5 common sentences are: BEI-FES, MSA-BEI, MSA-MOS, MSA-SFX, MSA-TRI, MSA-TUN, RAB-ASW, RAB-KHA, RAB-RIY, RAB-SAN, RAB-BAS & RAB-MOS.", "labels": [], "entities": [{"text": "BEI-FES", "start_pos": 183, "end_pos": 190, "type": "METRIC", "confidence": 0.9787557125091553}]}, {"text": "Below, we list all dialects under consideration grouped per country and per region.", "labels": [], "entities": []}, {"text": "We also list in the parentheses the average number of common sentences within each country (with more than one dialect) and each region.", "labels": [], "entities": []}, {"text": "This list shows that Levant dialects are the most similar while the Maghrib ones are the least similar.", "labels": [], "entities": []}, {"text": "Finally, to evaluate the participating systems, the subtask organizers use Accuracy (on the city, country and region levels denoted hereby Acc cty , Acc cntr and Acc rgn , respectively) in addition to Macro-averaged Precision, Recall and F1 measure (denoted hereby Pre, Rec and F1, respectively).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9994096755981445}, {"text": "Acc", "start_pos": 139, "end_pos": 142, "type": "METRIC", "confidence": 0.9572287201881409}, {"text": "Acc", "start_pos": 149, "end_pos": 152, "type": "METRIC", "confidence": 0.902033269405365}, {"text": "Acc rgn", "start_pos": 162, "end_pos": 169, "type": "METRIC", "confidence": 0.93442702293396}, {"text": "Recall", "start_pos": 227, "end_pos": 233, "type": "METRIC", "confidence": 0.7810388803482056}, {"text": "F1 measure", "start_pos": 238, "end_pos": 248, "type": "METRIC", "confidence": 0.9828919172286987}, {"text": "F1", "start_pos": 278, "end_pos": 280, "type": "METRIC", "confidence": 0.9730995893478394}]}], "tableCaptions": [{"text": " Table 2: Effect of DA", "labels": [], "entities": [{"text": "Effect", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9895221590995789}, {"text": "DA", "start_pos": 20, "end_pos": 22, "type": "TASK", "confidence": 0.6930819153785706}]}]}