{"title": [{"text": "Grammatical-Error-Aware Incorrect Example Retrieval System for Learners of Japanese as a Second Language", "labels": [], "entities": [{"text": "Grammatical-Error-Aware Incorrect Example Retrieval", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.7606164813041687}]}], "abstractContent": [{"text": "Existing example retrieval systems do not include grammatically incorrect examples, or only present a few examples, if any.", "labels": [], "entities": []}, {"text": "Even if a retrieval system has a wide coverage of incorrect examples along with the correct counterparts , learners need to know whether their query includes errors.", "labels": [], "entities": []}, {"text": "Considering the usabil-ity of retrieving incorrect examples, our proposed method uses a large-scale corpus and presents correct expressions along with incorrect expressions using a grammatical error detection system so that the learner does not need to be aware of how to search for examples.", "labels": [], "entities": []}, {"text": "Intrinsic and extrinsic evaluations indicate that our method improves the accuracy of example sentence retrieval and the quality of a learner's writing.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9990200996398926}, {"text": "example sentence retrieval", "start_pos": 86, "end_pos": 112, "type": "TASK", "confidence": 0.5979963342348734}]}], "introductionContent": [{"text": "Grammatical error detection for learners of English as a second language (ESL) is widely studied.", "labels": [], "entities": [{"text": "Grammatical error detection", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8040415247281393}, {"text": "learners of English as a second language (ESL)", "start_pos": 32, "end_pos": 78, "type": "TASK", "confidence": 0.665592274069786}]}, {"text": "However, there are few studies on grammatical error detection for learners of Japanese as a second language (JSL).", "labels": [], "entities": [{"text": "grammatical error detection", "start_pos": 34, "end_pos": 61, "type": "TASK", "confidence": 0.5590247412522634}, {"text": "learners of Japanese as a second language (JSL)", "start_pos": 66, "end_pos": 113, "type": "TASK", "confidence": 0.6708036303520203}]}, {"text": "Most studies on grammatical error detection in Japanese focus on a learner's particular error types, mainly with particles ().", "labels": [], "entities": [{"text": "grammatical error detection", "start_pos": 16, "end_pos": 43, "type": "TASK", "confidence": 0.6270996630191803}]}, {"text": "Among others, there are studies using phrase-based statistical machine translation (PB-SMT), which does not limit the types of grammatical errors made by a learner).", "labels": [], "entities": [{"text": "phrase-based statistical machine translation", "start_pos": 38, "end_pos": 82, "type": "TASK", "confidence": 0.67425736784935}]}, {"text": "However, PBSMT-based grammatical error detection cannot consider long-distance relationships because it relies on either character or word n-grams.", "labels": [], "entities": [{"text": "PBSMT-based grammatical error detection", "start_pos": 9, "end_pos": 48, "type": "TASK", "confidence": 0.7473564147949219}]}, {"text": "A standard method that supports the effort of learning a second language is the use of examples.", "labels": [], "entities": []}, {"text": "Example retrieval systems such as and in particular check for the appropriate use of words based on the context in which they are written.", "labels": [], "entities": []}, {"text": "However, in such a system, if the query word is incorrect, finding appropriate examples is impossible using ordinary search engines, such as Google.", "labels": [], "entities": []}, {"text": "Even if learners have access to an incorrect example retrieval system, such as and, they do not know how to search for the examples because they do not know whether their query includes errors.", "labels": [], "entities": []}, {"text": "Moreover, they are often unable to rewrite a composition in the absence of correct versions of the incorrect examples.", "labels": [], "entities": []}, {"text": "These systems are primarily developed for use by Japanese teachers.", "labels": [], "entities": []}, {"text": "As such, they are not as helpful for learners who do not have a strong background in Japanese.", "labels": [], "entities": []}, {"text": "Considering this, our study develops an example sentence retrieval system 1 with grammatical error detection using the large-scale Lang-8 2 dataset for JSL by focusing on the usability of automatic incorrect example retrieval.", "labels": [], "entities": [{"text": "sentence retrieval", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.7420990169048309}, {"text": "grammatical error detection", "start_pos": 81, "end_pos": 108, "type": "TASK", "confidence": 0.6176729102929434}, {"text": "Lang-8 2 dataset", "start_pos": 131, "end_pos": 147, "type": "DATASET", "confidence": 0.8203116257985433}, {"text": "automatic incorrect example retrieval", "start_pos": 188, "end_pos": 225, "type": "TASK", "confidence": 0.7149528414011002}]}, {"text": "The main contributions of this work are as follows: \u2022 This is the first study that tackles grammatical error detection in Japanese using a neural network.", "labels": [], "entities": [{"text": "grammatical error detection in Japanese", "start_pos": 91, "end_pos": 130, "type": "TASK", "confidence": 0.7939807176589966}]}, {"text": "It shows the state-of-the-art F score on the Lang-8 dataset and establishes anew baseline.", "labels": [], "entities": [{"text": "F score", "start_pos": 30, "end_pos": 37, "type": "METRIC", "confidence": 0.9784666001796722}, {"text": "Lang-8 dataset", "start_pos": 45, "end_pos": 59, "type": "DATASET", "confidence": 0.9766978025436401}]}, {"text": "\u2022 To the best of our knowledge, our system is the first incorrect example sentence retrieval system using neural grammatical error detection.", "labels": [], "entities": [{"text": "sentence retrieval", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.7409652173519135}, {"text": "neural grammatical error detection", "start_pos": 106, "end_pos": 140, "type": "TASK", "confidence": 0.6249886080622673}]}, {"text": "This function allows a user to recognize which part of the query is wrong.", "labels": [], "entities": []}, {"text": "\u2022 Our system seamlessly shows the incorrect sentences, and the corresponding sentences corrected by a native speaker.", "labels": [], "entities": []}, {"text": "Thus, learners: Features of example retrieval systems for Japanese language learners.", "labels": [], "entities": []}, {"text": "\"Correct Sent.\" indicates whether the system can display the correct sentences; \"Incorrect Sent.\" indicates whether the system can display the incorrect sentences; \"Revised Sent.\" indicates whether the system can display the revised sentence corresponding to the incorrect sentence; and \"Error Detection\" denotes whether the system has a grammatical error detection system.", "labels": [], "entities": [{"text": "Correct", "start_pos": 1, "end_pos": 8, "type": "METRIC", "confidence": 0.9733317494392395}, {"text": "Error Detection\"", "start_pos": 288, "end_pos": 304, "type": "METRIC", "confidence": 0.9217168291409811}]}, {"text": "can rectify their mistakes while writing the composition.", "labels": [], "entities": []}, {"text": "\u2022 Our intrinsic evaluation shows that our system is good at correcting lexical choice and misformation errors in a learner's writing.", "labels": [], "entities": [{"text": "correcting lexical choice", "start_pos": 60, "end_pos": 85, "type": "TASK", "confidence": 0.7928476730982462}]}, {"text": "Our extrinsic evaluation also shows that our example sentence retrieval system improves the quality of a learner's writing.", "labels": [], "entities": [{"text": "example sentence retrieval", "start_pos": 45, "end_pos": 71, "type": "TASK", "confidence": 0.6395201583703359}]}], "datasetContent": [{"text": "In this study, we use the Lang-8 Learner Corpora created by.", "labels": [], "entities": [{"text": "Lang-8 Learner Corpora", "start_pos": 26, "end_pos": 48, "type": "DATASET", "confidence": 0.895755390326182}]}, {"text": "The developers of the dataset used it for Japanese grammatical error correction, whereas we used it as an example retrieval database for JSL.", "labels": [], "entities": [{"text": "Japanese grammatical error correction", "start_pos": 42, "end_pos": 79, "type": "TASK", "confidence": 0.7330636829137802}]}, {"text": "Each learner's sentence has at least one revised sentence.", "labels": [], "entities": []}, {"text": "A learner's sentence is combined with a revised sentence to make a sentence pair.", "labels": [], "entities": []}, {"text": "If a learner's sentence has more than one revised sentence, each of the revised sentences is paired with the learner's sentence as separate sentence pairs.", "labels": [], "entities": []}, {"text": "Sentences with a length of more than 100 words or with a Levenshtein distance of more than 7 are eliminated to remove the noise in the corpus.", "labels": [], "entities": [{"text": "Levenshtein distance", "start_pos": 57, "end_pos": 77, "type": "METRIC", "confidence": 0.8596368134021759}]}, {"text": "We extracted 1.4 million pairs of learner sentences written by Japanese language learners and revised sentences corrected by Japanese native speakers.", "labels": [], "entities": []}, {"text": "The total number of included Japanese essays was 185,991.", "labels": [], "entities": []}, {"text": "The learner sentences and the revised sentences were tokenized by the morphological analyzer, MeCab (ver. 0.996) with UniDic (ver. 2.2.0).", "labels": [], "entities": [{"text": "MeCab", "start_pos": 94, "end_pos": 99, "type": "DATASET", "confidence": 0.9162573218345642}]}, {"text": "We used gensim 7 to create the sentence vectors.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Accuracy of detection of writing errors made  by Japanese learner.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9956709146499634}]}, {"text": " Table 6: Examples of test results. The column \"Incorrect phrase\" contains the phrases written by the learner. These  are extracted from the Lang-8 test set. The column \"Ours\" shows whether our system was able to find the correct  answer for that phrase.The column \"type\" shows the error type of each phrase.", "labels": [], "entities": [{"text": "Lang-8 test set", "start_pos": 141, "end_pos": 156, "type": "DATASET", "confidence": 0.9656384388605753}, {"text": "type", "start_pos": 266, "end_pos": 270, "type": "METRIC", "confidence": 0.9683042168617249}]}, {"text": " Table 7: Frequency and relevance of each system (in- trinsic evaluation).", "labels": [], "entities": [{"text": "Frequency", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9716569781303406}]}, {"text": " Table 8: Prompts for extrinsic evaluation.", "labels": [], "entities": [{"text": "extrinsic evaluation", "start_pos": 22, "end_pos": 42, "type": "TASK", "confidence": 0.7717629671096802}]}, {"text": " Table 9: Result of extrinsic evaluation.", "labels": [], "entities": []}, {"text": " Table 10: Frequency and relevance of our system for  an actual learner's composition (extrinsic evaluation).", "labels": [], "entities": []}]}