{"title": [{"text": "Distributional Semantics Meets Construction Grammar. Towards a Unified Usage-Based Model of Grammar and Meaning", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we propose anew type of semantic representation of Construction Grammar that combines constructions with the vector representations used in Distributional Semantics.", "labels": [], "entities": []}, {"text": "We introduce anew framework, Distribu-tional Construction Grammar, where grammar and meaning are systematically modeled from language use, and finally, we discuss the kind of contributions that distributional models can provide to CxG representation from a linguistic and cognitive perspective.", "labels": [], "entities": [{"text": "Distribu-tional Construction Grammar", "start_pos": 29, "end_pos": 65, "type": "TASK", "confidence": 0.777819812297821}, {"text": "CxG representation", "start_pos": 231, "end_pos": 249, "type": "TASK", "confidence": 0.7690902054309845}]}], "introductionContent": [{"text": "In the last decades, usage-based models of language have captured the attention of linguistics and cognitive science.", "labels": [], "entities": []}, {"text": "The different approaches covered by this label are based on the assumptions that linguistic knowledge is embodied in mental processing and representations that are sensitive to context and statistical probabilities, and that language structures at all levels, from morphology to syntax, emerge out of facts of actual language usage.", "labels": [], "entities": []}, {"text": "A usage-based framework that turned out to be extremely influential is Construction Grammar (CxG), a family of theories sharing the fundamental idea that language is a collection of form-meaning pairings called constructions (henceforth Cxs)).", "labels": [], "entities": []}, {"text": "Cxs differ for their degree of schematicity, ranging from morphemes (e.g., pre-, -ing), to complex words (e.g., daredevil) to filled or partially-filled idioms (e.g., give the devil his dues or Jog (someones) memory) to more abstract patterns like the ditransitive Cxs [Subj V Obj1 Obj2]).", "labels": [], "entities": []}, {"text": "It is worth stressing that, even if the concept of construction is based on the idea that linguistic properties actually emerge from language use, CxG theories have typically preferred to model the semantic content of constructions in terms of hand-made, formal representations like those of Frame Semantics (.", "labels": [], "entities": []}, {"text": "This leaves open the issue of how semantic representations can be learned from empirical evidence, and how do they relate to the usage-based nature of Cxs.", "labels": [], "entities": []}, {"text": "In fact, fora usage-based model of grammar based on a strong syntax-semantics parallelism, it would be desirable to be grounded on a framework allowing to learn the semantic content of Cxs from language use.", "labels": [], "entities": []}, {"text": "In this perspective, a promising solution for representing constructional semantics is given by an approach to meaning representations that has gained a rising interest in both computational linguistics and cognitive science, namely Distributional Semantics (henceforth DS).", "labels": [], "entities": [{"text": "representing constructional semantics", "start_pos": 46, "end_pos": 83, "type": "TASK", "confidence": 0.7150336702664694}]}, {"text": "DS is a usagebased model of word meaning, based on the wellestablished assumption that the statistical distribution of linguistic items in context plays a key role in characterizing their semantic behaviour).", "labels": [], "entities": [{"text": "word meaning", "start_pos": 28, "end_pos": 40, "type": "TASK", "confidence": 0.7215591669082642}]}, {"text": "More precisely, Distributional Semantic Models (DSMs) represent the lexicon in terms of vector spaces, where a lexical target is described in terms of a vector (also known as embedding) built by identifying in a corpus its syntactic and lexical contexts.", "labels": [], "entities": []}, {"text": "Lately, neural models to learn distributional vectors have gained massive popularity: these algorithms build low-dimensional vector representations by learning to optimally predict the contexts of the target words ().", "labels": [], "entities": []}, {"text": "On the negative side, DS lacks a clear connection with usage-based theoretical frameworks.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, existing attempts of linking DS with models of grammar have rather targeted formal theories like Montague Grammar and Categorial Grammar (.", "labels": [], "entities": [{"text": "Montague Grammar", "start_pos": 127, "end_pos": 143, "type": "DATASET", "confidence": 0.8287175297737122}]}, {"text": "To sum up, both CxG and DS share the assumption that linguistic structures naturally emerge from language usage, and that a representation of both form and meaning of any linguistic item can be modeled through its distributional statistics, and more generally, with the quantitative information derived from corpus data.", "labels": [], "entities": []}, {"text": "However, these two models still live in parallel worlds.", "labels": [], "entities": []}, {"text": "On the one hand, CxG is a model of grammar in search fora consistent usage-based model of meaning, and, conversely, DS is a computational framework to build semantic representations in search for an empirically adequate theory of grammar.", "labels": [], "entities": []}, {"text": "As we illustrate in Section 2, occasional encounters between DS and CxG have already happened, but we believe that new fruitful advances could come from the exploitation of the mutual synergies between CxG and DS, and by letting these two worlds finally meet and interact in a more systematic way.", "labels": [], "entities": []}, {"text": "Following this direction of research, we introduce anew representation framework called Distributional Construction Grammar, which aims at bringing together these two theoretical paradigms.", "labels": [], "entities": [{"text": "Distributional Construction Grammar", "start_pos": 88, "end_pos": 123, "type": "TASK", "confidence": 0.837057371934255}]}, {"text": "Our goal is to integrate distributional information into constructions by completing their semantic structures with distributional vectors extracted from large textual corpora, as samples of language usage.", "labels": [], "entities": []}, {"text": "These pages are structured as follows: after reviewing existing literature on CxG and related computational studies, in Section 3 we outline the key characteristics of our theoretical proposal, while Section 4 provides a general discussion about what contributions DSMs can provide to CxG representation from a linguistic and cognitive perspective.", "labels": [], "entities": [{"text": "CxG representation", "start_pos": 285, "end_pos": 303, "type": "TASK", "confidence": 0.8351138830184937}]}, {"text": "Although this is essentially a theoretical contribution, we outline ongoing work focusing on its computational implementation and empirical validation.", "labels": [], "entities": []}, {"text": "We conclude by reporting future perspectives of research.", "labels": [], "entities": []}], "datasetContent": [{"text": "DSMs have proved to be very useful in modeling human performance in psycholinguistic tasks (.", "labels": [], "entities": []}, {"text": "This is an important finding, since it allows to test the predictions of Construction Grammar theories against data derived from behavioral experiments.", "labels": [], "entities": []}, {"text": "To cite an example from the DS literature, the models proposed by replicated the priming effect of the lexical decision task by, where the participants were asked to judge whether a given verb was areal word or not, after being exposed to an argument structure construction in the form of a Jabberwocky sentence.", "labels": [], "entities": []}, {"text": "The authors of the study created distributional representations of constructions as combinations of the vectors of their typical verbs, and measured their cosine similarity with the verbs of the original experiment, showing that their model can accurately reproduce the results reported by.", "labels": [], "entities": []}], "tableCaptions": []}