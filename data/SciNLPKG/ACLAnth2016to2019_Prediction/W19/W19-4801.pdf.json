{"title": [{"text": "Transcoding compositionally: using attention to find more generalizable solutions", "labels": [], "entities": [{"text": "Transcoding compositionally", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8790071308612823}]}], "abstractContent": [{"text": "While sequence-to-sequence models have shown remarkable generalization power across several natural language tasks, their construct of solutions are argued to be less composi-tional than human-like generalization.", "labels": [], "entities": []}, {"text": "In this paper, we present seq2attn, anew architecture that is specifically designed to exploit attention to find compositional patterns in the input.", "labels": [], "entities": []}, {"text": "In seq2attn, the two standard components of an encoder-decoder model are connected via a transcoder, that modulates the information flow between them.", "labels": [], "entities": []}, {"text": "We show that seq2attn can successfully generalize, without requiring any additional supervision, on two tasks which are specifically constructed to challenge the com-positional skills of neural networks.", "labels": [], "entities": []}, {"text": "The solutions found by the model are highly inter-pretable, allowing easy analysis of both the types of solutions that are found and potential causes for mistakes.", "labels": [], "entities": []}, {"text": "We exploit this opportunity to introduce anew paradigm to test com-positionality that studies the extent to which a model overgeneralizes when confronted with exceptions.", "labels": [], "entities": []}, {"text": "We show that seq2attn exhibits such overgeneralization to a larger degree than a standard sequence-to-sequence model.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, deep artificial neural networks have been at the root of many successes in a wide variety of AI tasks, including sequential tasks, for which encoder-decoder models are the de facto standard ().", "labels": [], "entities": []}, {"text": "These successes have also caused a renewed interest in the types of solutions that they learn () and, in particular, have prompted the question: to what extent can their high accuracy betaken as evidence that they in fact understood the task they are modeling.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 175, "end_pos": 183, "type": "METRIC", "confidence": 0.9816678762435913}]}, {"text": "A number of recent studies argues that it cannot, when 'understanding the task' is explained as understanding the implicit rules by which it is governed (e.g.,.", "labels": [], "entities": []}, {"text": "More specifically, they argue that rather than understanding those implicit rules and being able to compositionally apply them, RNN models exploit biases in the data that are unrelated to the underlying system.", "labels": [], "entities": []}, {"text": "While the latter strategy is remarkably effective when large amounts of training data are available, the lack of understanding of the actual task leads to sample inefficiency, inability to transfer knowledge between tasks and difficulty to generalize to sequences that are drawn from the same rule space, but differ distributionally from the training data.", "labels": [], "entities": []}, {"text": "Furthermore, the use of such strategies, which deviate largely from human approaches, that are typically compositional (, makes it difficult to understand what a model does and when it may make a mistake.", "labels": [], "entities": []}, {"text": "In this work, we propose anew component that aims to address this particular weakness of seq2seq models.", "labels": [], "entities": []}, {"text": "This component, which is a recurrent attention module that can be integrated in any form of encoder-decoder model, modulates the information flow from encoder to decoder.", "labels": [], "entities": []}, {"text": "We test our module, which we dub seq2attn, in a recurrent encoder-decoder model.", "labels": [], "entities": []}, {"text": "Using two tasks that are designed such that their accuracy reflects directly whether the underlying rule-based system is learned -the lookup table task ( and SCAN (Lake and) -we show that seq2attn strongly encourages rule-based behaviour, which is easily interpreted by studying the attention patterns generated by the module.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9966835379600525}]}, {"text": "Additionally, we propose anew testing paradigm based on overgeneralization, that can be used to gain more insights in the biases of a model which cannot be inferred from task success alone.", "labels": [], "entities": []}], "datasetContent": [{"text": "The ability to learn and compositionally apply symbolic rules is considered to bean important prerequisite for understanding and modeling natural language.", "labels": [], "entities": []}, {"text": "While (gated) recurrent neural networks are in principle capable of modeling compositional systems (e.g.,), whether they in fact do so when trained on large amounts of data to perform natural language processing tasks remains an open question.", "labels": [], "entities": []}, {"text": "Some positive results in this direction have been presented (e.g.,), but a number of recent papers have argued that, rather than understanding the underlying compositional structure of a problem, RNNs rely on heuristics and exploit biases in the data.", "labels": [], "entities": []}, {"text": "Particularly relevant to the current work are the studies of Lake and  and, who both present data sets specifically designed to reflect compositionality in their task accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 167, "end_pos": 175, "type": "METRIC", "confidence": 0.9473153352737427}]}, {"text": "Using their compositional tests, they show that vanilla seq2seq models do not readily generalize to solutions that exhibit an understanding of the underlying rule system of the tasks.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Mean sequence accuracies and standard  deviation on the lookup tables task of a baseline  seq2seq model with additional components of seq2attn.  G=Gumbel-Softmax, E=embeddings as attention val- ues, F=full focus, T=transcoder.", "labels": [], "entities": []}, {"text": " Table 3: Hyperparameters (embedding dimensions, RNN dimensions, RNN layers, RNN type, dropout rate) used  for both the seq2seq baseline and seq2attn model for both tasks.", "labels": [], "entities": []}]}