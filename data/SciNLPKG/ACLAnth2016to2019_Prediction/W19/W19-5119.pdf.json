{"title": [{"text": "Cross-lingual Transfer Learning and Multitask Learning for Capturing Multiword Expressions", "labels": [], "entities": [{"text": "Cross-lingual Transfer Learning", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7777658303578695}, {"text": "Capturing Multiword Expressions", "start_pos": 59, "end_pos": 90, "type": "TASK", "confidence": 0.8055907090504965}]}], "abstractContent": [{"text": "Recent developments in deep learning have prompted a surge of interest in the application of multitask and transfer learning to NLP problems.", "labels": [], "entities": []}, {"text": "In this study, we explore for the first time, the application of transfer learning (TRL) and multitask learning (MTL) to the identification of Multiword Expressions (MWEs).", "labels": [], "entities": [{"text": "identification of Multiword Expressions (MWEs)", "start_pos": 125, "end_pos": 171, "type": "TASK", "confidence": 0.8804237842559814}]}, {"text": "For MTL, we exploit the shared syntactic information between MWE and dependency parsing models to jointly train a single model on both tasks.", "labels": [], "entities": [{"text": "MTL", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9696500897407532}, {"text": "dependency parsing", "start_pos": 69, "end_pos": 87, "type": "TASK", "confidence": 0.6560255140066147}]}, {"text": "We specifically predict two types of labels: MWE and dependency parse.", "labels": [], "entities": [{"text": "dependency parse", "start_pos": 53, "end_pos": 69, "type": "TASK", "confidence": 0.745546281337738}]}, {"text": "Our neural MTL architecture utilises the supervision of dependency parsing in lower layers and predicts MWE tags in upper layers.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 56, "end_pos": 74, "type": "TASK", "confidence": 0.7965145111083984}]}, {"text": "In the TRL scenario, we overcome the scarcity of data by learning a model on a larger MWE dataset and transferring the knowledge to a resource-poor setting in another language.", "labels": [], "entities": [{"text": "TRL", "start_pos": 7, "end_pos": 10, "type": "TASK", "confidence": 0.9344075322151184}, {"text": "MWE dataset", "start_pos": 86, "end_pos": 97, "type": "DATASET", "confidence": 0.8829164505004883}]}, {"text": "In both scenarios, the resulting models achieved higher performance compared to standard neural approaches.", "labels": [], "entities": []}], "introductionContent": [{"text": "Multiword Expressions (MWEs) are combinations of two or more lexical components that form non/semi-compositional meaning units.", "labels": [], "entities": [{"text": "Multiword Expressions (MWEs)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7313809156417846}]}, {"text": "Due to their idiosyncratic behaviour, MWEs have been studied using various statistical and machine learning approaches including supervised classification (, tagging (, and unsupervised prediction).", "labels": [], "entities": [{"text": "MWEs", "start_pos": 38, "end_pos": 42, "type": "TASK", "confidence": 0.9587897658348083}, {"text": "supervised classification", "start_pos": 129, "end_pos": 154, "type": "TASK", "confidence": 0.6790561825037003}]}, {"text": "Studies have focused on both their syntactic and semantic (Van de Cruys and Moir\u00f3n, 2007) features.", "labels": [], "entities": []}, {"text": "Recently, the PARSEME project provided an extensive multilingual dataset of verbal MWEs (.", "labels": [], "entities": [{"text": "PARSEME", "start_pos": 14, "end_pos": 21, "type": "DATASET", "confidence": 0.7512101531028748}]}, {"text": "Datasets of certain languages in this resource are rich with a huge number of tagged sequences while others are considerably smaller.", "labels": [], "entities": []}, {"text": "Several notable systems have been proposed to train sequence labelling models on this dataset including neural) and non-neural systems (.", "labels": [], "entities": []}, {"text": "MWE prediction for some of these languages has proved to be more challenging due to several reasons including scarcity of data, higher percentage of unseen MWE instances in the test set, and prevalence of discontinuous or variable MWEs.", "labels": [], "entities": [{"text": "MWE prediction", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.9837453067302704}]}, {"text": "In this paper, we focus on one of those languages for which the results were collectively low (interestingly it was English) and explore two neural approaches in order to address the shortcomings of the current neural models and enhance learning.", "labels": [], "entities": []}, {"text": "The two approaches are: multitask learning and transfer learning, with two different motivations.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.907032698392868}]}, {"text": "Syntactic and semantic idiosyncrasies in MWEs call for special treatment, with models that take them into account from different perspectives.", "labels": [], "entities": []}, {"text": "Syntactic and semantic information are commonly fed to the models as input features.", "labels": [], "entities": []}, {"text": "However, we consider an alternative way to exploit this information.", "labels": [], "entities": []}, {"text": "Specifically, in a supervised setting, we add dependency syntax information as auxiliary supervision.", "labels": [], "entities": []}, {"text": "Therefore we perform multitask learning between MWE and dependency parse tags.", "labels": [], "entities": [{"text": "dependency parse tags", "start_pos": 56, "end_pos": 77, "type": "TASK", "confidence": 0.7314377625783285}]}, {"text": "Syntactic dependency information has been previously proven to be successful in identifying MWEs.", "labels": [], "entities": [{"text": "identifying MWEs", "start_pos": 80, "end_pos": 96, "type": "TASK", "confidence": 0.6237072348594666}]}, {"text": "However, neural processing methodologies are yet to be deeply explored for MWE modelling.", "labels": [], "entities": [{"text": "MWE modelling", "start_pos": 75, "end_pos": 88, "type": "TASK", "confidence": 0.9802189767360687}]}, {"text": "In multitask learning we have several different prediction tasks over the same input.", "labels": [], "entities": []}, {"text": "The idea is that the process of learning features for one task can be helpful for another.", "labels": [], "entities": []}, {"text": "In order to deal with data scarcity in the English dataset, in another setting we train our model on a language with a larger data and transfer the learned knowledge for predicting MWE tags in English.", "labels": [], "entities": [{"text": "English dataset", "start_pos": 43, "end_pos": 58, "type": "DATASET", "confidence": 0.6913455277681351}, {"text": "predicting MWE tags", "start_pos": 170, "end_pos": 189, "type": "TASK", "confidence": 0.8736592332522074}]}, {"text": "In this study we build upon recent neural network systems that have proved to be successful in representing syntactic and semantic features of text and design novel multitask and transfer learning architectures for MWE identification.", "labels": [], "entities": [{"text": "MWE identification", "start_pos": 215, "end_pos": 233, "type": "TASK", "confidence": 0.9822724759578705}]}, {"text": "The contributions of this work are: 1) we propose a neural model that improves MWE identification by jointly learning MWE and dependency parse labels; 2) We show that MWE identification models, when multitasked with dependency parsing, outperform the models which naively add dependency parse information as additional features; 3) we propose, to the best of our knowledge for the first time, a cross-lingual transfer learning method for processing MWEs, thus making a contribution towards the study of low-resource languages.", "labels": [], "entities": [{"text": "MWE identification", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.9852891564369202}, {"text": "MWE identification", "start_pos": 167, "end_pos": 185, "type": "TASK", "confidence": 0.9578009247779846}, {"text": "dependency parsing", "start_pos": 216, "end_pos": 234, "type": "TASK", "confidence": 0.7692610919475555}]}], "datasetContent": [{"text": "We experiment with the multilingual dataset from the PARSEME project () which was made available for the shared task on identification of verbal MWEs (.", "labels": [], "entities": [{"text": "PARSEME project", "start_pos": 53, "end_pos": 68, "type": "DATASET", "confidence": 0.8857296407222748}, {"text": "identification of verbal MWEs", "start_pos": 120, "end_pos": 149, "type": "TASK", "confidence": 0.8217968344688416}]}, {"text": "Verbal MWEs in the dataset include idioms, verb particle constructions, and light verb constructions, among others.", "labels": [], "entities": []}, {"text": "MWE tags in the dataset are similar to IOB labels, since there is a distinction between the beginning and other components of an MWE.", "labels": [], "entities": []}, {"text": "We target the data for English which is surprisingly small in this dataset (with 3, 471 training and 3, 965 test sequences) and try to use MTL and TRL to improve MWE identification.", "labels": [], "entities": [{"text": "MTL", "start_pos": 139, "end_pos": 142, "type": "DATASET", "confidence": 0.5641992688179016}, {"text": "MWE identification", "start_pos": 162, "end_pos": 180, "type": "TASK", "confidence": 0.9669992327690125}]}, {"text": "The inputs to our system are combinations of ELMo embeddings which are trained on our data using the implementation provided by and one-hot encoded POS tags.", "labels": [], "entities": []}, {"text": "In cases where we add dependency parse information as inputs, the representation for dependency arcs and labels are as follows.", "labels": [], "entities": [{"text": "dependency parse information", "start_pos": 22, "end_pos": 50, "type": "TASK", "confidence": 0.8035745422045389}]}, {"text": "In order to represent arcs, we use adjacency matrix representation for each sentence.", "labels": [], "entities": []}, {"text": "In the adjacency matrix, each token is assigned a row in which all cells are zero except for the one corresponding to the head of the token in dependency tree.", "labels": [], "entities": []}, {"text": "Dependency labels, though are one-hot encoded.", "labels": [], "entities": []}, {"text": "We set hyperparameters based on the ones used in a similar architecture proposed by which was implemented fora single task and mono-lingual setting.", "labels": [], "entities": []}, {"text": "The CNN layers have 200 neurons, one with filter size 2 and the other with size 3, both with relu activation.", "labels": [], "entities": []}, {"text": "BiLSTM layers have both 300 neurons, dropout 0.5, and recurrent dropout of 0.2.", "labels": [], "entities": []}, {"text": "We use the Adam optimizer for all settings.", "labels": [], "entities": []}, {"text": "shows the whole architecture for MTL.", "labels": [], "entities": [{"text": "MTL", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.8122708797454834}]}, {"text": "The model architecture for standard setting and TRL is the same excluding the auxiliary components.", "labels": [], "entities": [{"text": "TRL", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.6897087693214417}]}, {"text": "In the MTL setting, we make comparison between the case when the model is trained only on MWE tags (single-task, STL) to when jointly trained to predict MWE and dependency parsing tags in a multitask scenario (MTL).", "labels": [], "entities": [{"text": "MTL", "start_pos": 7, "end_pos": 10, "type": "TASK", "confidence": 0.962830662727356}, {"text": "dependency parsing tags", "start_pos": 161, "end_pos": 184, "type": "TASK", "confidence": 0.7376499772071838}]}, {"text": "We also compare the results of joint prediction with the case when dependency information is directly fed as additional input.", "labels": [], "entities": [{"text": "joint prediction", "start_pos": 31, "end_pos": 47, "type": "TASK", "confidence": 0.6582608222961426}]}, {"text": "In the TRL setting, we first train our model on the German data which has 6, 734 training sequences.", "labels": [], "entities": [{"text": "TRL", "start_pos": 7, "end_pos": 10, "type": "TASK", "confidence": 0.5679751634597778}, {"text": "German data", "start_pos": 52, "end_pos": 63, "type": "DATASET", "confidence": 0.9421158730983734}]}, {"text": "We finally compare the results from TRL with all other results.", "labels": [], "entities": [{"text": "TRL", "start_pos": 36, "end_pos": 39, "type": "DATASET", "confidence": 0.8136181235313416}]}, {"text": "We evaluate the models using F1-score in two settings: 1) strict matching (MWE-based) in which all components of an MWE are considered as a unit that should be correctly classified; and 2) fuzzy matching (token-based) in which any correctly predicted token of the data is counted).", "labels": [], "entities": [{"text": "F1-score", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9957391023635864}]}], "tableCaptions": [{"text": " Table 1: Comparing the performance of the CNN-biLSTM model (in terms of average F1 over 5 runs with standard  deviation) in single (STL), multitask (MTL) and transfer learning (TRL) scenarios.", "labels": [], "entities": [{"text": "F1", "start_pos": 81, "end_pos": 83, "type": "METRIC", "confidence": 0.9954707622528076}]}, {"text": " Table 2: Comparing the performance of transfer learn- ing (TRL) with the standard setting (STL).", "labels": [], "entities": [{"text": "transfer learn- ing (TRL)", "start_pos": 39, "end_pos": 64, "type": "TASK", "confidence": 0.6743543190615517}]}]}