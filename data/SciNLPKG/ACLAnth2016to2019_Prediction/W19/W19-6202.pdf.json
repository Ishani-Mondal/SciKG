{"title": [{"text": "Improving Semantic Dependency Parsing with Syntactic Features", "labels": [], "entities": [{"text": "Improving Semantic Dependency Parsing", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8832042068243027}]}], "abstractContent": [{"text": "We extend a state-of-the-art deep neural architecture for semantic dependency parsing with features defined over syntactic dependency trees.", "labels": [], "entities": [{"text": "semantic dependency parsing", "start_pos": 58, "end_pos": 85, "type": "TASK", "confidence": 0.6752072274684906}]}, {"text": "Our empirical results show that only gold-standard syntactic information leads to consistent improvements in semantic parsing accuracy, and that the magnitude of these improvements varies with the specific combination of the syntactic and the semantic representation used.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 109, "end_pos": 125, "type": "TASK", "confidence": 0.7619270980358124}, {"text": "accuracy", "start_pos": 126, "end_pos": 134, "type": "METRIC", "confidence": 0.9156472682952881}]}, {"text": "In contrast, automatically predicted syntax does not seem to help semantic parsing.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 66, "end_pos": 82, "type": "TASK", "confidence": 0.756500780582428}]}, {"text": "Our error analysis suggests that there is a significant overlap between syntactic and semantic representations.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semantic dependency parsing (SDP) is the task of mapping a sentence into a formal representation of its meaning in the form of a directed graph with arcs between pairs of words.", "labels": [], "entities": [{"text": "Semantic dependency parsing (SDP) is the task of mapping a sentence into a formal representation of its meaning in the form of a directed graph with arcs between pairs of words", "start_pos": 0, "end_pos": 176, "type": "Description", "confidence": 0.7859159771240118}]}, {"text": "Ever since the release of the now-standard datasets for this task), most of the approaches to semantic dependency parsing have been based on previous and ongoing work in syntactic parsing.", "labels": [], "entities": [{"text": "semantic dependency parsing", "start_pos": 94, "end_pos": 121, "type": "TASK", "confidence": 0.7225091656049093}, {"text": "syntactic parsing", "start_pos": 170, "end_pos": 187, "type": "TASK", "confidence": 0.7710120379924774}]}, {"text": "In particular, several semantic parsers make use of features defined over syntactic dependency trees; one recent example is the system of.", "labels": [], "entities": []}, {"text": "In this paper we study to what extent semantic dependency parsing actually benefits from syntactic features.", "labels": [], "entities": [{"text": "semantic dependency parsing", "start_pos": 38, "end_pos": 65, "type": "TASK", "confidence": 0.7445689837137858}]}, {"text": "More specifically, we carryout experiments to identify those combinations of semantic and syntactic representations that yield the highest parsing accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 147, "end_pos": 155, "type": "METRIC", "confidence": 0.9276085495948792}]}, {"text": "This is interesting not only for parser developers -using improvement or non-improvement in parsing accuracy as an indicator, our study also contributes to a better understanding of the similarities and contentful differences between semantic and syntactic representations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.7776068449020386}]}, {"text": "Semantic dependency parsers are typically conceptualized as systems for structured prediction, combining a data-driven component that learns how to score dependency graphs with a decoder that retrieves one or several highest-scoring target graphs from the exponentially large search space of candidate graphs.", "labels": [], "entities": [{"text": "Semantic dependency parsers", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7317995627721151}, {"text": "structured prediction", "start_pos": 72, "end_pos": 93, "type": "TASK", "confidence": 0.7436399459838867}]}, {"text": "Among decoding algorithms we find approaches based on integer linear programming (, dynamic programming algorithms that support exact decoding for restricted classes of graphs (, and transition-based approaches introducing new shift-reduce-style automata (.", "labels": [], "entities": []}, {"text": "Regarding the learning component, state-of-the-art parsing results have been achieved using neural architectures ().", "labels": [], "entities": []}, {"text": "The system of  even draws essentially all of its strength from its neural core, employing a trivial decoder.", "labels": [], "entities": []}, {"text": "The parser used in this paper is a (slightly modified) re-implementation of that system developed by, which adds syntactic information via a simple head feature, along the lines of.", "labels": [], "entities": []}, {"text": "After providing some background in Section 2, we describe the architecture of our parser in Section 3, and our data and experimental setup in Section 4.", "labels": [], "entities": []}, {"text": "In Section 5 we present our empirical results and complement them with an error analysis in Section 6.", "labels": [], "entities": []}, {"text": "Section 7 concludes the paper and provides an outlook on future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We train three types of semantic dependency parsing models: no syntactic features (N), features extracted from gold-standard syntax trees (G), and features extracted from predicted syntax trees (P).", "labels": [], "entities": [{"text": "semantic dependency parsing", "start_pos": 24, "end_pos": 51, "type": "TASK", "confidence": 0.6728749672571818}]}, {"text": "The models of type N serve as our baseline and perform on par with the parser of   Our three syntactic models (for SB, DT, and EWT) were trained using the same architecture and specifications as the semantic models, but use the factorized approach with CLE-decoding instead.", "labels": [], "entities": []}, {"text": "Their accuracy is reported in, with additional results from StanfordNLP ( and UDPipe (Straka and Strakov\u00e1, 2017) for reference.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 6, "end_pos": 14, "type": "METRIC", "confidence": 0.9993901252746582}, {"text": "StanfordNLP", "start_pos": 60, "end_pos": 71, "type": "DATASET", "confidence": 0.9529370665550232}]}, {"text": "We note that in contrast to those systems' results, ours were achieved without gold POS tags.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Network sizes and training parameters.", "labels": [], "entities": []}, {"text": " Table 3: Parsing accuracy for our syntactic models  on the in-domain (id) and out-of-domain (ood) test  sets for the SDP data, and the regular test set for  the EWT data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9865970015525818}, {"text": "SDP data", "start_pos": 118, "end_pos": 126, "type": "DATASET", "confidence": 0.7917992174625397}, {"text": "EWT data", "start_pos": 162, "end_pos": 170, "type": "DATASET", "confidence": 0.9715298116207123}]}, {"text": " Table 4: Labeled F1 for our semantic parsers on the in-domain (id) and out-of-domain (ood) test sets.", "labels": [], "entities": [{"text": "F1", "start_pos": 18, "end_pos": 20, "type": "METRIC", "confidence": 0.9810216426849365}]}]}