{"title": [], "abstractContent": [{"text": "We demo a chatbot in a personal finance domain that delivers content in the form of virtual dialogues automatically produced from plain texts extracted and selected from documents.", "labels": [], "entities": []}, {"text": "Given an initial query, this chatbot finds documents, extracts topics from them, organizes these topics in clusters according to conflicting viewpoints, receives from the user clarification on which cluster is most relevant to her opinion, and provides the content for this cluster.", "labels": [], "entities": []}, {"text": "This content is provided in the form of a virtual dialogue where the answers are derived from the found and selected documents and its split results, and questions are automatically generated for these answers.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "Evaluating the effectiveness of information delivery via virtual dialogues, we compare the conventional chatbot sessions where users were given plain-text answers, and the ones where users were given a content via virtual dialogues.", "labels": [], "entities": [{"text": "information delivery", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.7105545848608017}]}, {"text": "We assess dialogues with respect to following usability properties.", "labels": [], "entities": []}, {"text": "The speed of arriving to a decision to commit a transaction such as purchase or product selection.", "labels": [], "entities": []}, {"text": "A user is expected to accumulate sufficient information, and this information should be convincing enough for making such decision; We also measure how many entities (in linguistic sense) were explored during a session with the chatbot.", "labels": [], "entities": []}, {"text": "We are interested in how thorough and comprehensive the chatbot session is.", "labels": [], "entities": []}, {"text": "This assessment is sometimes opposite to the above two measures but nevertheless is important for understanding the overall usability of various conversational modes.", "labels": [], "entities": []}, {"text": "We do not compare precision and recall of search sessions with either dialogue mode since the same information is delivered, but in distinct modes.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9991877675056458}, {"text": "recall", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.9982594847679138}]}, {"text": "In the first and second rows, we assess the stand-alone systems.", "labels": [], "entities": []}, {"text": "Virtual dialogues take less iteration on average for information access and about the same number of iterations for decisions as conventional dialogues do.", "labels": [], "entities": []}, {"text": "In the bottom two rows, we observe the usability of the hybrid system.", "labels": [], "entities": []}, {"text": "When a conventional dialogue is followed by a virtual one, a lower portion of users is satisfied by the first step in comparison to the inverse architecture, where virtual is followed by conventional.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Evaluation of comparative effectiveness of  conventional and virtual dialogues  Conventional  dialogues  Virtual dialogues", "labels": [], "entities": []}]}