{"title": [{"text": "Discourse Representation Structure Parsing with Recurrent Neural Networks and the Transformer Model", "labels": [], "entities": [{"text": "Discourse Representation Structure Parsing", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.7381202802062035}]}], "abstractContent": [{"text": "We describe the systems we developed for Discourse Representation Structure (DRS) parsing as part of the IWCS-2019 Shared Task of DRS Parsing.", "labels": [], "entities": [{"text": "Discourse Representation Structure (DRS) parsing", "start_pos": 41, "end_pos": 89, "type": "TASK", "confidence": 0.8409516726221357}, {"text": "IWCS-2019 Shared Task of DRS Parsing", "start_pos": 105, "end_pos": 141, "type": "TASK", "confidence": 0.6653073926766714}]}, {"text": "1 Our systems are based on sequence-to-sequence modeling.", "labels": [], "entities": []}, {"text": "To implement our model, we use the open-source neural machine translation system implemented in PyTorch, OpenNMT-py.", "labels": [], "entities": []}, {"text": "We experimented with a variety of encoder-decoder models based on recurrent neural networks and the Transformer model.", "labels": [], "entities": []}, {"text": "We conduct experiments on the standard benchmark of the Parallel Meaning Bank (PMB 2.2.0).", "labels": [], "entities": [{"text": "Parallel Meaning Bank (PMB 2.2.0)", "start_pos": 56, "end_pos": 89, "type": "DATASET", "confidence": 0.6588023815836225}]}, {"text": "Our best system achieves a score of 84.8% F 1 in the DRS parsing shared task.", "labels": [], "entities": [{"text": "F 1", "start_pos": 42, "end_pos": 45, "type": "METRIC", "confidence": 0.989651620388031}, {"text": "DRS parsing shared task", "start_pos": 53, "end_pos": 76, "type": "TASK", "confidence": 0.7697095051407814}]}], "introductionContent": [{"text": "Discourse Representation Theory is a popular theory of meaning representation designed to account fora variety of linguistic phenomena, including the interpretation of pronouns and temporal expressions within and across sentences.", "labels": [], "entities": [{"text": "Discourse Representation Theory", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8203490674495697}, {"text": "meaning representation", "start_pos": 55, "end_pos": 77, "type": "TASK", "confidence": 0.7233487963676453}]}, {"text": "The Groningen Meaning Bank (GMB;) provides a large collection of English texts annotated with Discourse Representation Structures (DRS), while the Parallel Meaning Bank (PMB;) provides DRSs in English, German, Italian and Dutch.", "labels": [], "entities": [{"text": "Groningen Meaning Bank (GMB", "start_pos": 4, "end_pos": 31, "type": "DATASET", "confidence": 0.7224208891391755}]}, {"text": "Furthermore, the PMB introduces clause representation, as shown on the top of.", "labels": [], "entities": [{"text": "PMB", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.5355650186538696}, {"text": "clause representation", "start_pos": 32, "end_pos": 53, "type": "TASK", "confidence": 0.7884872555732727}]}, {"text": "With the recent introduction of neural network learning to the Natural Language Processing community, several neural DRS parsers have been developed for the problem of DRS parsing, i.e. the problem of taking a document or a sentence as input, and outputting their corresponding DRS.", "labels": [], "entities": [{"text": "DRS parsing", "start_pos": 168, "end_pos": 179, "type": "TASK", "confidence": 0.9067055284976959}]}, {"text": "convert box-style DRSs to tree-style DRSs and propose the three-step tree DRS parser on the GMB, while van  adopt a neural machine translation approach to parse sentences to their clause-style DRSs on PMB.", "labels": [], "entities": [{"text": "GMB", "start_pos": 92, "end_pos": 95, "type": "DATASET", "confidence": 0.9871178865432739}, {"text": "PMB", "start_pos": 201, "end_pos": 204, "type": "DATASET", "confidence": 0.9732192754745483}]}, {"text": "Due to the different standard of annotations between GMB and PMB, and that the IWCS-2019 Shared Task of DRS Parsing mainly focuses on averagely short sentences in PMB annotations, our systems take sentences as input and output a clause-style DRS of PMB represented as a sequence for the IWCS-2018 Shared Task of DRS parsing ().", "labels": [], "entities": [{"text": "DRS parsing", "start_pos": 312, "end_pos": 323, "type": "TASK", "confidence": 0.6995064318180084}]}, {"text": "shows the data pipeline in our system for both training and parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 60, "end_pos": 67, "type": "TASK", "confidence": 0.9577786922454834}]}, {"text": "There are three main parts: (a) The component Preprocess, which prepares the input data to make it suitable for training and parsing models; (b) The component Neural Model which is based on OpenNMT; (c) The component Postprocess which contains some rules to ensure the system output is a well-formed DRSs.", "labels": [], "entities": [{"text": "Preprocess", "start_pos": 46, "end_pos": 56, "type": "METRIC", "confidence": 0.9829634428024292}]}, {"text": "b1 REF e1 b1 live \"v.01\" e1 b1 REF t1 b1 time \"n.08\" t1 b1 EQU t1 \"now\" b1 Location e1 x1 b1 Theme e1 \"speaker\" b2 REF x1 b1 Time e1 t1 b2 ground floor \"n.01\" x1 e1 t1 b1", "labels": [], "entities": []}], "datasetContent": [{"text": "We adopt the postprocessing scripts of van  to transform back the output of our models to the clause format, and then use COUNTER  as our evaluation metric.", "labels": [], "entities": [{"text": "COUNTER", "start_pos": 122, "end_pos": 129, "type": "METRIC", "confidence": 0.9685335755348206}]}, {"text": "In this section, we introduce the training data that we used and the results on the PMB benchmarks.", "labels": [], "entities": [{"text": "PMB benchmarks", "start_pos": 84, "end_pos": 98, "type": "DATASET", "confidence": 0.7863066792488098}]}], "tableCaptions": [{"text": " Table 1: Choice of hyperparameters for our neural network models.", "labels": [], "entities": []}, {"text": " Table 2: Results on test partition of the Parallel Meaning Bank.", "labels": [], "entities": [{"text": "Parallel Meaning Bank", "start_pos": 43, "end_pos": 64, "type": "DATASET", "confidence": 0.6478488941987356}]}, {"text": " Table 3: Results on test dataset by word transformer", "labels": [], "entities": [{"text": "word transformer", "start_pos": 37, "end_pos": 53, "type": "TASK", "confidence": 0.6774812042713165}]}, {"text": " Table 4: F 1 -scores of fine-grained evaluation on test dataset.", "labels": [], "entities": [{"text": "F 1", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9894275069236755}]}]}