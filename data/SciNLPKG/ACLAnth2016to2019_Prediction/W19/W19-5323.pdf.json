{"title": [], "abstractContent": [{"text": "In this paper we describe the CUNI translation system used for the unsupervised news shared task of the ACL 2019 Fourth Conference on Machine Translation (WMT19).", "labels": [], "entities": [{"text": "CUNI translation", "start_pos": 30, "end_pos": 46, "type": "TASK", "confidence": 0.7180399000644684}, {"text": "unsupervised news shared task of the ACL 2019 Fourth Conference on Machine Translation (WMT19)", "start_pos": 67, "end_pos": 161, "type": "TASK", "confidence": 0.6794296260923147}]}, {"text": "We follow the strategy of Artetxe et al.", "labels": [], "entities": []}, {"text": "(2018b), creating a seed phrase-based system where the phrase table is initialized from cross-lingual embedding mappings trained on monolingual data, followed by a neural machine translation system trained on synthetic parallel data.", "labels": [], "entities": []}, {"text": "The synthetic corpus was produced from a mono-lingual corpus by a tuned PBMT model refined through iterative back-translation.", "labels": [], "entities": []}, {"text": "We further focus on the handling of named entities, i.e. the part of vocabulary where the cross-lingual embedding mapping suffers most.", "labels": [], "entities": []}, {"text": "Our system reaches a BLEU score of 15.3 on the German-Czech WMT19 shared task.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 21, "end_pos": 31, "type": "METRIC", "confidence": 0.9794090092182159}, {"text": "German-Czech WMT19 shared task", "start_pos": 47, "end_pos": 77, "type": "DATASET", "confidence": 0.6841715574264526}]}, {"text": "PBMT PBMT-Unsupervised-bestBLEU PBMT-Unsupervised-wordOrder SynthCorpus-Initial DE-CS SynthCorpus-noCzech DE-CS SynthCorpus-noCzech-reordered DE-CS SynthCorpus-noCzech-reordered-NER DE-CS CS NewsCrawl DE NewsCrawl phrase2vec + VecMap NMT CUNI-Unsupervised-base CUNI-Unsupervised CUNI-Unsupervised-NER Post-processing CUNI-Unsupervised-NER-post CUNI-Unsupervised-combined Phrase Embeddings Monolingual data Synthetic Parallel Data Figure 1: The training pipeline and an overview of our resulting systems.", "labels": [], "entities": []}, {"text": "Corpora are displayed as rounded rectangles, MT systems as grey ovals.", "labels": [], "entities": [{"text": "MT", "start_pos": 45, "end_pos": 47, "type": "TASK", "confidence": 0.8252089023590088}]}, {"text": "DE \u2192 CS Initial model DE original CS translated inference CS \u2192 DE Iteration 1 CS original DE translated inference DE \u2192 CS Iteration 1 DE original CS translated inference CS \u2192 DE Iteration 2 CS original DE translated inference Model Data", "labels": [], "entities": []}], "introductionContent": [{"text": "Unsupervised machine translation is of particular significance for low-resource language pairs.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.7380744814872742}]}, {"text": "In contrast to traditional machine translation, it does not rely on large amounts of parallel data.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.7512613534927368}]}, {"text": "When parallel data is scarce, both neural machine translation (NMT) and phrase-based machine translation (PBMT) systems can be trained using large monolingual corpora (.", "labels": [], "entities": [{"text": "neural machine translation (NMT)", "start_pos": 35, "end_pos": 67, "type": "TASK", "confidence": 0.8442646761735281}, {"text": "phrase-based machine translation (PBMT)", "start_pos": 72, "end_pos": 111, "type": "TASK", "confidence": 0.7724726249774297}]}, {"text": "Our translation systems submitted to WMT19 were created in several steps.", "labels": [], "entities": [{"text": "WMT19", "start_pos": 37, "end_pos": 42, "type": "DATASET", "confidence": 0.8769360184669495}]}, {"text": "Following the strategy of, we first train monolingual phrase embeddings and map them to the cross-lingual space.", "labels": [], "entities": []}, {"text": "Secondly, we use the mapped embeddings to initialize the phrase table of the PBMT system which is first tuned and later refined with back-translation.", "labels": [], "entities": []}, {"text": "We then translate the Czech monolingual corpus by the PBMT system to produce several synthetic parallel German-Czech corpora.", "labels": [], "entities": []}, {"text": "Finally, we train a supervised NMT system on a filtered synthetic data set, where we exclude sentences tagged as \"not Czech\", shuffle the word order and handle mistranslated name entities.", "labels": [], "entities": []}, {"text": "The training pipeline is illustrated in.", "labels": [], "entities": []}, {"text": "The structure of this paper is the following.", "labels": [], "entities": []}, {"text": "The existing approaches used to build our system are described in Section 2.", "labels": [], "entities": []}, {"text": "The data for this shared task is described in Section 3.", "labels": [], "entities": []}, {"text": "Section 4 gives details on phrase embeddings.", "labels": [], "entities": []}, {"text": "Section 5 describe the phrase-based model and how it was used to create synthetic corpora.", "labels": [], "entities": []}, {"text": "Section 6 proceeds to the neural model trained on the synthetic data.", "labels": [], "entities": []}, {"text": "Section 7 introduces our benchmarks and Section 8 reports the results of the experiments.", "labels": [], "entities": []}, {"text": "Finally, Section 9 summarizes and concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "The systems submitted to WMT19 are listed in along with our benchmarks.", "labels": [], "entities": [{"text": "WMT19", "start_pos": 25, "end_pos": 30, "type": "DATASET", "confidence": 0.7840592861175537}]}, {"text": "In addition to BLEU, we also report BEER) and CharacTER ( scores.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 15, "end_pos": 19, "type": "METRIC", "confidence": 0.9991995692253113}, {"text": "BEER", "start_pos": 36, "end_pos": 40, "type": "METRIC", "confidence": 0.9990565180778503}, {"text": "CharacTER", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.9919257760047913}]}, {"text": "summarizes the improvement we gained by introducing a special named entity treatment.", "labels": [], "entities": []}, {"text": "We manualy evaluated three systems, CUNI-Unsupervised, CUNI-Unsupervised-NER and CUNI-Unsupervised-NER-post on a stratified subset of the validation data set created by randomly selecting 100 sentences with NEs and 100 sentences without NEs.", "labels": [], "entities": []}, {"text": "The results are presented in two steps, the first table shows that finetuning the system CUNI-Unsupervised-NER on a synthetic corpus with amended NEs proved beneficial in 52% of tested sentences which included NEs and it did not harm in 20% of sentences.", "labels": [], "entities": [{"text": "CUNI-Unsupervised-NER", "start_pos": 89, "end_pos": 110, "type": "DATASET", "confidence": 0.916397750377655}]}, {"text": "When comparing the two systems on sentences", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Our systems and their performance on newstest2019 (* indicates our WMT submissions and ** indicates  our primary system).", "labels": [], "entities": [{"text": "WMT", "start_pos": 77, "end_pos": 80, "type": "DATASET", "confidence": 0.7817217707633972}]}, {"text": " Table 4: Sample translations showing that fine-tuning on synthetic corpus with cleaned NEs (CUNI-Unsupervised- NER) alleviates a part of the NE problem while post-processing can handle the rest. However, note the imperfect  translation of Lyriker as novelist rather than poet and the extra word StB which was not tagged as a NE and therefore  not treated during post-processing.", "labels": [], "entities": [{"text": "Sample translations", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.8284468054771423}]}, {"text": " Table 5: Results of manual evaluation of three systems  on a stratified subset of the validation data set created  by randomly selecting 100 sentences with NEs and 100  sentences without NEs.", "labels": [], "entities": [{"text": "validation data set", "start_pos": 87, "end_pos": 106, "type": "DATASET", "confidence": 0.7937679092089335}]}]}