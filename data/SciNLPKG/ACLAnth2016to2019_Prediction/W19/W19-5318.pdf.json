{"title": [{"text": "The AFRL WMT19 Systems: Old Favorites and New Tricks", "labels": [], "entities": [{"text": "AFRL WMT19", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.8123126029968262}]}], "abstractContent": [{"text": "This paper describes the Air Force Research Laboratory (AFRL) machine translation systems and the improvements that were developed during the WMT19 evaluation campaign.", "labels": [], "entities": [{"text": "Air Force Research Laboratory (AFRL) machine translation", "start_pos": 25, "end_pos": 81, "type": "TASK", "confidence": 0.8461260596911112}, {"text": "WMT19 evaluation", "start_pos": 142, "end_pos": 158, "type": "TASK", "confidence": 0.8645942211151123}]}, {"text": "This year, we refine our approach to training popular neural machine translation toolk-its, experiment with anew domain adaptation technique and again measure improvements in performance on the Russian-English language pair.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 54, "end_pos": 80, "type": "TASK", "confidence": 0.7596965829531351}]}], "introductionContent": [{"text": "As part of the 2019 Conference on Machine Translation () news-translation shared task, the AFRL Human Language Technology team participated in the Russian-English portion of the competition.", "labels": [], "entities": [{"text": "Machine Translation () news-translation shared task", "start_pos": 34, "end_pos": 85, "type": "TASK", "confidence": 0.7812518725792567}, {"text": "AFRL Human Language Technology team", "start_pos": 91, "end_pos": 126, "type": "DATASET", "confidence": 0.8296709418296814}]}, {"text": "We build on our strategies from last year (, adding additional language ID based data processing and optimizing subword segmentation strategies.", "labels": [], "entities": [{"text": "subword segmentation", "start_pos": 112, "end_pos": 132, "type": "TASK", "confidence": 0.7228729575872421}]}, {"text": "For RussianEnglish we again submitted an entry comprising our best systems trained with Marian), Sockeye () with Elastic Weight Consolidation (EWC) (,, and Moses () combined using the Jane system combination method).", "labels": [], "entities": [{"text": "RussianEnglish", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.9482372999191284}, {"text": "Sockeye", "start_pos": 97, "end_pos": 104, "type": "DATASET", "confidence": 0.8602657318115234}, {"text": "Elastic Weight Consolidation (EWC)", "start_pos": 113, "end_pos": 147, "type": "METRIC", "confidence": 0.6059542993704478}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Training corpus total and retained lines after  fastText filtering", "labels": [], "entities": [{"text": "fastText", "start_pos": 58, "end_pos": 66, "type": "DATASET", "confidence": 0.9136972427368164}]}, {"text": " Table 2: Test set comparison for non-filtered WMT18  training corpus and filtered WMT19 training corpus  measured by SacreBLEU.", "labels": [], "entities": [{"text": "WMT18  training corpus", "start_pos": 47, "end_pos": 69, "type": "DATASET", "confidence": 0.8009108106295267}, {"text": "WMT19 training corpus", "start_pos": 83, "end_pos": 104, "type": "DATASET", "confidence": 0.7788307468096415}]}, {"text": " Table 3: Cased, detokenized BLEU for various test sets and BPE merge-value treatments. Best scores for each test  set are denoted with bold text.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 29, "end_pos": 33, "type": "METRIC", "confidence": 0.9802873730659485}, {"text": "BPE", "start_pos": 60, "end_pos": 63, "type": "METRIC", "confidence": 0.8919323086738586}]}, {"text": " Table 4: Test set comparison for baseline bi-deep, transformer, untuned and tuned ensembles for various test sets  measured in cased, detokenized BLEU. Best scores for each test set are denoted with bold text.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 147, "end_pos": 151, "type": "METRIC", "confidence": 0.9850618243217468}]}, {"text": " Table 5: Sockeye system scores for newstest2014  (in-domain) and newstest2018 (out-of-domain) test  sets for various training conditions measured in Sacre- BLEU.", "labels": [], "entities": [{"text": "newstest2014", "start_pos": 36, "end_pos": 48, "type": "DATASET", "confidence": 0.9295529127120972}, {"text": "Sacre-", "start_pos": 150, "end_pos": 156, "type": "DATASET", "confidence": 0.7203781008720398}, {"text": "BLEU", "start_pos": 157, "end_pos": 161, "type": "METRIC", "confidence": 0.5327990651130676}]}, {"text": " Table 6: System combination and input system scores  measured in cased, detokenized BLEU and BEER on  the newstest2018 test set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 85, "end_pos": 89, "type": "METRIC", "confidence": 0.9792572259902954}, {"text": "BEER", "start_pos": 94, "end_pos": 98, "type": "METRIC", "confidence": 0.9973135590553284}, {"text": "newstest2018 test set", "start_pos": 107, "end_pos": 128, "type": "DATASET", "confidence": 0.977704922358195}]}, {"text": " Table 7: Final submission system scores measured in  cased BLEU and BEER on the newstest2019 test set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 60, "end_pos": 64, "type": "METRIC", "confidence": 0.9797233939170837}, {"text": "BEER", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.9986538887023926}, {"text": "newstest2019 test set", "start_pos": 81, "end_pos": 102, "type": "DATASET", "confidence": 0.9780999024709066}]}]}