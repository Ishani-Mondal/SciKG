{"title": [{"text": "On Understanding the Relation between Expert Annotations of Text Readability and Target Reader Comprehension", "labels": [], "entities": [{"text": "Understanding the Relation between Expert Annotations of Text Readability", "start_pos": 3, "end_pos": 76, "type": "TASK", "confidence": 0.692983071009318}]}], "abstractContent": [{"text": "Automatic readability assessment aims to ensure that readers read texts that they can comprehend.", "labels": [], "entities": [{"text": "Automatic readability assessment", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6976905465126038}]}, {"text": "However, computational models are typically trained on texts created from the perspective of the text writer, not the target reader.", "labels": [], "entities": []}, {"text": "There is little experimental research on the relationship between expert annotations of read-ability, reader's language proficiency, and different levels of reading comprehension.", "labels": [], "entities": []}, {"text": "To address this gap, we conducted a user study in which over a 100 participants read texts of different reading levels and answered questions created to test three forms of comprehension.", "labels": [], "entities": []}, {"text": "Our results indicate that more than readability annotation or reader proficiency, it is the type of comprehension question asked that shows differences between reader responses-infer-ential questions were difficult for users of all levels of proficiency across reading levels.", "labels": [], "entities": []}, {"text": "The data collected from this study is released with this paper 1 , which will, for the first time, provide a collection of 45 reader bench marked texts to evaluate readability assessment systems developed for adult learners of English.", "labels": [], "entities": []}, {"text": "It can also potentially be useful for the development of question generation approaches in intelligent tutoring systems research.", "labels": [], "entities": [{"text": "question generation", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.7717835605144501}]}], "introductionContent": [{"text": "Readability assessment refers to the task of predicting the reading difficulty of a text and its suitability to a target user's reading abilities.", "labels": [], "entities": [{"text": "Readability assessment", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8399868011474609}]}, {"text": "However, atypical computational approach relies on standard corpora that are created based on the writer's perception of what is difficult fora reader, and not on the target readers' comprehension data.", "labels": [], "entities": []}, {"text": "While it is difficult to create such validated corpora in large samples sufficient to build automated models, lack of such data also raises a question about the validity of such models (.", "labels": [], "entities": []}, {"text": "A reasonably sized corpus of readers' comprehension scores for texts of varying reading levels can be a starting point in this direction, as it can enable evaluating the suitability of an existing readability assessment system for that target group as well as look for the validity of the labeled dataset.", "labels": [], "entities": []}, {"text": "This issue then raises a question of how we should evaluate comprehension.", "labels": [], "entities": []}, {"text": "There is a significant body of research on forming questions to assess different levels of comprehension in educational and tutoring systems research (e.g.,.", "labels": [], "entities": []}, {"text": "Readability is not considered as a factor in such studies.", "labels": [], "entities": []}, {"text": "In the few user studies that do consider readability), differences between different levels of comprehension were not considered.", "labels": [], "entities": []}, {"text": "In this paper, we take first steps towards understanding the relation between expert annotations, reader proficiency and comprehension for automatic readability assessment research by conducting a web-based reading study with over 100 participants in a natural reading environment.", "labels": [], "entities": []}, {"text": "Participants read six newspaper texts, and answered six questions on each text, covering three levels of comprehension.", "labels": [], "entities": []}, {"text": "We analyzed our results by using methods from educational assessment research.", "labels": [], "entities": []}, {"text": "We are releasing the data from this study, which for the first time, creates a freely available reader response based dataset for evaluating readability assessment systems.", "labels": [], "entities": []}, {"text": "While it is not a large dataset and we cannot claim to have solved the problem of validating the readability annotations against target user groups, we believe this study is a first step in a much needed direction.", "labels": [], "entities": []}, {"text": "Our paper's contributions can be summarized as follows: we conducted a user study with over 100 participants by, \u2022 asking questions of different forms (short answer, T/F) that target three levels of comprehension (literal, re-organization, inference) for the first time, \u2022 using a web-based reading setup where the readers read the full text in a normal computer based interaction setting, which can make the results potentially more relevant to practical, non-lab scenarios.", "labels": [], "entities": [{"text": "T/F)", "start_pos": 166, "end_pos": 170, "type": "METRIC", "confidence": 0.7652924209833145}]}, {"text": "\u2022 using methods from educational assessment to show the differences in user responses for different levels of comprehension.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows: Section 2 summarizes related research.", "labels": [], "entities": []}, {"text": "Sections 3 and 4 describe the study and results.", "labels": [], "entities": []}, {"text": "Section 5 summarizes the insights gained from this study.", "labels": [], "entities": []}], "datasetContent": [{"text": "Texts: We randomly selected 15 texts from the OneStopEnglish corpus, consisting of manually simplified news articles from The Guardian, by English teachers, to suit beginner, intermediate, and advanced readers of English as Second Language (ESL).", "labels": [], "entities": [{"text": "OneStopEnglish corpus, consisting of manually simplified news articles from The Guardian", "start_pos": 46, "end_pos": 134, "type": "DATASET", "confidence": 0.6523567090431849}]}, {"text": "This corpus was also used in past user studies related to readability assessment).", "labels": [], "entities": []}, {"text": "2 Participants: 112 non-native English speaking participants were recruited for this study from among the student population of an American university by means of an internal email advertisement.", "labels": [], "entities": []}, {"text": "Participants were compensated for their participation with Amazon.com gift coupons.", "labels": [], "entities": []}, {"text": "Questions: The onestopenglish.com news lessons included comprehension questions at the end of each article.", "labels": [], "entities": [{"text": "onestopenglish.com news lessons", "start_pos": 15, "end_pos": 46, "type": "DATASET", "confidence": 0.9071802695592245}]}, {"text": "However, these questions were primarily fill-in-the-blank and multiple choice questions, and they were not the same across all the reading levels for the same article.", "labels": [], "entities": []}, {"text": "Further, they did not cover different forms of comprehension we wanted to check.", "labels": [], "entities": []}, {"text": "Hence, the questions (and appropriate responses) for this study were created by an experienced language instructor following the guidelines of), and manually checked by the authors.", "labels": [], "entities": []}, {"text": "Questions covered three levels of comprehension: literal, re-organization, and inferential.", "labels": [], "entities": []}, {"text": "Literal comprehension questions require learner's understanding of the straightforward meaning of the text.", "labels": [], "entities": []}, {"text": "Therefore, the answers to such questions can be found directly and explicitly in the text.", "labels": [], "entities": []}, {"text": "Reorganization questions require similar understanding, but learners are required to combine information from various portions of the text in order to provide a correct answer.", "labels": [], "entities": []}, {"text": "Inference questions require a deeper understanding of the text, as the answer to such questions is not explicitly stated.", "labels": [], "entities": []}, {"text": "The correct answer requires a combination of literal understanding of the text, learner's background knowledge and the ability to infer from what is written.", "labels": [], "entities": []}, {"text": "Questions were created such that answers are the same for all three reading level versions of a given text (i.e., content deleted or added between versions will not affect answering these questions).", "labels": [], "entities": []}, {"text": "Six questions were created per text, covering three levels of comprehension, and two question forms (True-False, short answer).", "labels": [], "entities": []}, {"text": "Proficiency Test: All the participants completed a free English language proficiency test provided by the British Council 4 after they completed reading all the texts and answering all the questions.", "labels": [], "entities": [{"text": "British Council", "start_pos": 106, "end_pos": 121, "type": "DATASET", "confidence": 0.9892100691795349}]}, {"text": "The test gave a percentage score, and hence was on a scale of 0-100.", "labels": [], "entities": []}, {"text": "Study Procedure: After IRB approval, the first step involved developing a web-based application for setting up the reading study.", "labels": [], "entities": [{"text": "IRB", "start_pos": 23, "end_pos": 26, "type": "DATASET", "confidence": 0.5296369791030884}]}, {"text": "We developed a Python and MySQL based web application that allowed users to login and read the displayed texts and their responses were stored.", "labels": [], "entities": []}, {"text": "Each reader read 6 of the 15 texts randomly chosen balancing for reading level i.e., each user read two texts per reading level, and without reading the same text in multiple versions.", "labels": [], "entities": []}, {"text": "After reading each text, they first saw two questions dealing with factual comprehension.", "labels": [], "entities": []}, {"text": "The text was not visible while answering these questions.", "labels": [], "entities": []}, {"text": "The next page had the text along with reorganization questions and the third page had the text along with inference questions.", "labels": [], "entities": []}, {"text": "Reading time was calculated based on the time taken to click on the next page but was not used in our analysis.", "labels": [], "entities": [{"text": "Reading time", "start_pos": 0, "end_pos": 12, "type": "METRIC", "confidence": 0.6932335048913956}]}, {"text": "After finishing reading all texts and answering questions, the participants did the proficiency test.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Summary of participant responses", "labels": [], "entities": []}, {"text": " Table 2: Correlations between participant scores for  different comprehension types", "labels": [], "entities": []}, {"text": " Table 3: Regression model with full data", "labels": [], "entities": [{"text": "Regression", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.8743719458580017}]}, {"text": " Table 4: Regression model with low proficiency data", "labels": [], "entities": [{"text": "Regression", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9487920999526978}]}, {"text": " Table 5: MFRM for types of comprehension", "labels": [], "entities": []}, {"text": " Table 6: MFRM for forms of questions", "labels": [], "entities": [{"text": "MFRM", "start_pos": 10, "end_pos": 14, "type": "DATASET", "confidence": 0.489808589220047}]}, {"text": " Table 7: MFRM for forms of questions and factual ver- sus inferential comprehension", "labels": [], "entities": []}]}