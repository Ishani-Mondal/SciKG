{"title": [], "abstractContent": [{"text": "This paper describes how we tackle the FinSBD-2019 shared task in IJCAI-2019.", "labels": [], "entities": [{"text": "FinSBD-2019", "start_pos": 39, "end_pos": 50, "type": "DATASET", "confidence": 0.8753527402877808}, {"text": "IJCAI-2019", "start_pos": 66, "end_pos": 76, "type": "DATASET", "confidence": 0.5821282863616943}]}, {"text": "The deep attention model based on word embedding is proposed to detect the sentence boundary in noisy English and French texts extracted from the financial documents.", "labels": [], "entities": []}, {"text": "The experiment is shown that the model has good performance for predicting beginning and end index of sentence in the two tasks which the result achieved the score of F1 for BS, ES are 0.88,0.91 respectively in English task, and score of F1 for BS, ES are 0.91, 0.92 respectively in French task.", "labels": [], "entities": [{"text": "F1", "start_pos": 167, "end_pos": 169, "type": "METRIC", "confidence": 0.998374342918396}, {"text": "ES", "start_pos": 178, "end_pos": 180, "type": "METRIC", "confidence": 0.864658772945404}, {"text": "F1", "start_pos": 238, "end_pos": 240, "type": "METRIC", "confidence": 0.9982582926750183}]}], "introductionContent": [{"text": "The first step of many language tasks, such as POS tagging, discourse parsing, machine translation, etc., is the sentence boundary detection (SBD), which detects the end of the sentence.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 47, "end_pos": 58, "type": "TASK", "confidence": 0.8768547177314758}, {"text": "discourse parsing", "start_pos": 60, "end_pos": 77, "type": "TASK", "confidence": 0.724600076675415}, {"text": "machine translation", "start_pos": 79, "end_pos": 98, "type": "TASK", "confidence": 0.79118412733078}, {"text": "sentence boundary detection (SBD)", "start_pos": 113, "end_pos": 146, "type": "TASK", "confidence": 0.7439205646514893}]}, {"text": "This makes the task of detecting the beginning and ending very important, which helps in processing the written language text.", "labels": [], "entities": [{"text": "detecting the beginning and ending", "start_pos": 23, "end_pos": 57, "type": "TASK", "confidence": 0.8293049335479736}]}, {"text": "However, detecting the end of the sentence is a complicated task due to the ambiguousness of punctuation and words in the sentence.", "labels": [], "entities": [{"text": "detecting the end of the sentence", "start_pos": 9, "end_pos": 42, "type": "TASK", "confidence": 0.8992720941702524}]}, {"text": "For example, punctuation marks like \".\" and \"!\" don't always represent the end part of sentence text and have several functions.", "labels": [], "entities": []}, {"text": "The \".\" can be part of a number like 2.34 or an abbreviation of a phrase, and \"!'", "labels": [], "entities": []}, {"text": "can represent a word of surprise or shock.", "labels": [], "entities": []}, {"text": "A number of research pieces in sentence boundaries mainly used the machine learning methods, such as the hidden Markov model, Maximum entropy [Jeffrey C., conditional random fields, and neural networks.", "labels": [], "entities": [{"text": "sentence boundaries", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.7152892053127289}]}, {"text": "Recently, deep learning models have been applied to solve this issue and achieve good performance [Carlos Emiliano Gonzalez.", "labels": [], "entities": []}, {"text": "Until now, research about SBD has been confined to formal texts, such as news and European parliament proceedings, which have high accuracy using rule-based machine learning and deep learning methods due to the perfectly clean text data.", "labels": [], "entities": [{"text": "SBD", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.9783937335014343}, {"text": "accuracy", "start_pos": 131, "end_pos": 139, "type": "METRIC", "confidence": 0.9959751963615417}]}, {"text": "There is no research about the SBD in noisy text that was extracted from the files in machine-readable formats.", "labels": [], "entities": [{"text": "SBD", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.9374085068702698}]}, {"text": "The FinNLP workshop in IJCAI-2019 is the first proposal of FinSBD-2019 shared tasks that detect sentence boundary in noisy text of finance documents [A Ait.", "labels": [], "entities": [{"text": "FinNLP workshop in IJCAI-2019", "start_pos": 4, "end_pos": 33, "type": "DATASET", "confidence": 0.868724063038826}]}, {"text": "The purpose of FinSBD-2019 shared tasks is to detect the beginning and ending parts of sentences in the noisy text extracted from financial pdf documents in two languages: English and French.", "labels": [], "entities": [{"text": "FinSBD-2019", "start_pos": 15, "end_pos": 26, "type": "DATASET", "confidence": 0.8705824017524719}]}, {"text": "As shown in the English text T1, the provided dataset is a json file containing \"text\" that has been word tokenized using NLTK, and begin_sentence and end_sentence correspond to all indexes of tokens marking the beginning and the ending of well-formed sentences in the text., 'end_sentence':]} The goal of the task is to detect the beginning and ending index of English and French sentence text that has been tokenized.", "labels": [], "entities": []}, {"text": "We observed that the critical words in the sentence clearly indicated the beginning and ending part of a sentence.", "labels": [], "entities": []}, {"text": "For example, in the English text, most of the time, '.', ';' and et al. are at the end of a sentence.", "labels": [], "entities": []}, {"text": "The attention mechanism is useful for detecting the weights of words in NLP tasks.", "labels": [], "entities": []}, {"text": "Therefore, the word2vec-based deep attention model is proposed to detect the beginning and ending index in English and French sentence texts.", "labels": [], "entities": []}, {"text": "Section 2 explains the details of our methods.", "labels": [], "entities": []}, {"text": "Section 3 shows experimental configurations and discusses the results.", "labels": [], "entities": []}, {"text": "Then, we conclude this paper in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the experiment, rule-based, CNN and the proposed deep attention model have been implemented in the task.", "labels": [], "entities": [{"text": "CNN", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.9212732315063477}]}, {"text": "Moreover, in the data processing stage, keep the upper letter of words to train the word embedding in the English and French text.", "labels": [], "entities": []}, {"text": "In addition, we test the different numbers of words surrounding each tokenized word.", "labels": [], "entities": []}, {"text": "The numbers 5, 8, 10 are taken to be tested in the experiment.", "labels": [], "entities": []}, {"text": "As the simple rule-based method in the experiment.", "labels": [], "entities": []}, {"text": "In the English task, we just determined the end index by the '.', '.\\n', '!', ':', ';' token words, and the beginning index is detected by the word that the beginning character of token word is upper letter or the token word is '('.", "labels": [], "entities": []}, {"text": "As the French task, the beginning index is determined by the word that the beginning character of token word is upper letter, and the end index is detected by the '.', '.\\n', '!', ':', ';' token words.", "labels": [], "entities": []}, {"text": "The 10-fold cross-validation to predict the test data is used in the model.", "labels": [], "entities": []}, {"text": "The deep model in our research was implemented with Keras Based on the evaluation requirements of the FinSBD Task, the F-scores are taken to evaluate the performance of the proposed model in the paper.", "labels": [], "entities": [{"text": "FinSBD Task", "start_pos": 102, "end_pos": 113, "type": "DATASET", "confidence": 0.9013303220272064}, {"text": "F-scores", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.9913540482521057}]}], "tableCaptions": [{"text": " Table 1. Experiment Results: F-score of English, French  tasks using Rule-based, CNN and Attention-LSTM, and the  surrounding number of words is 5", "labels": [], "entities": [{"text": "F-score", "start_pos": 30, "end_pos": 37, "type": "METRIC", "confidence": 0.9980106949806213}]}, {"text": " Table 2. Experiment Results: F-score of English, French  tasks, and the surrounding number of words is 5, 8,10 respec- tively for deep attention model", "labels": [], "entities": [{"text": "F-score", "start_pos": 30, "end_pos": 37, "type": "METRIC", "confidence": 0.9983193278312683}]}, {"text": " Table 3 Leaderboard FinSBD in English task", "labels": [], "entities": [{"text": "Leaderboard FinSBD", "start_pos": 9, "end_pos": 27, "type": "DATASET", "confidence": 0.728155642747879}]}, {"text": " Table 4 Leaderboard FinSBD in French task", "labels": [], "entities": [{"text": "Leaderboard FinSBD", "start_pos": 9, "end_pos": 27, "type": "DATASET", "confidence": 0.6793130934238434}]}]}