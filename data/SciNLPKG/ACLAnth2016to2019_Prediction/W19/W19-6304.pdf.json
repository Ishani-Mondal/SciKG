{"title": [{"text": "Linguistic features and proficiency classification in L2 Spanish and L2 Portuguese", "labels": [], "entities": []}], "abstractContent": [{"text": "This work explores the relationship between L2 proficiency levels and certain linguistic features through experiments in automatic proficiency classification.", "labels": [], "entities": [{"text": "automatic proficiency classification", "start_pos": 121, "end_pos": 157, "type": "TASK", "confidence": 0.6181829770406088}]}, {"text": "We use L2 Spanish and L2 Por-tuguese data and perform monolingual and cross-lingual experiments.", "labels": [], "entities": []}, {"text": "We also compare native and leaner Spanish texts.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this is the first work that performs automatic proficiency classification for L2 Spanish, as well as cross-lingual proficiency classification between L2 Portuguese and L2 Spanish.", "labels": [], "entities": [{"text": "proficiency classification", "start_pos": 77, "end_pos": 103, "type": "TASK", "confidence": 0.6921816915273666}, {"text": "cross-lingual proficiency classification", "start_pos": 131, "end_pos": 171, "type": "TASK", "confidence": 0.6175152162710825}]}, {"text": "Our results for L2 Spanish are similar to the state-of-the-art, while our cross-lingual experiments got lower results than similar works.", "labels": [], "entities": []}, {"text": "In general, all the experiments suggest new insights about the relationship between linguistic features and proficiency levels in L2 Portuguese and L2 Spanish.", "labels": [], "entities": []}], "introductionContent": [{"text": "Proficiency classification is a common task in second language learning.", "labels": [], "entities": [{"text": "Proficiency classification", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8742198348045349}]}, {"text": "The linguistic development of the learner is usually defined through a scale that accounts for different levels of linguistic complexity.", "labels": [], "entities": []}, {"text": "One of the most common scales is the one described in the Common European Framework of Reference for Languages (CEFR) ().", "labels": [], "entities": [{"text": "Common European Framework of Reference for Languages (CEFR)", "start_pos": 58, "end_pos": 117, "type": "DATASET", "confidence": 0.7879853039979935}]}, {"text": "The CEFR defines 3 broad divisions: A, basic user; B, independent user; C, proficient user.", "labels": [], "entities": [{"text": "CEFR", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.954241156578064}]}, {"text": "These classes are subdivided into 6 development levels: A1 (beginner), A2 (elementary), B1 ( to specific linguistic features and skills, and the whole scale establishes a progression from a very rudimentary language to a performance close to a native production.", "labels": [], "entities": []}, {"text": "CEFR has become the most common framework for second language learning in Europe, and in this context, it is common that learners perform placement tests that define their proficiency level according to the CEFR scale.", "labels": [], "entities": [{"text": "CEFR", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9625105857849121}]}, {"text": "The interest of an automatic system that can perform this task is, therefore, evident.", "labels": [], "entities": []}, {"text": "Automatic proficiency classification is considered as a type of Automatic Essay Scoring (AES) task.", "labels": [], "entities": [{"text": "Automatic proficiency classification", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.7463513811429342}, {"text": "Automatic Essay Scoring (AES) task", "start_pos": 64, "end_pos": 98, "type": "TASK", "confidence": 0.7296815897737231}]}, {"text": "AES has been explored mainly for English, but recent approaches have dealt with other languages.", "labels": [], "entities": [{"text": "AES", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.4998581111431122}]}, {"text": "Researchers have modeled AES as a regression (), a ranking or a classification problem.", "labels": [], "entities": [{"text": "AES", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.9014222025871277}]}, {"text": "Different types of features have been used in the task, from Bagof-words (BOW) to more abstract representations that use higher levels of linguistic information (morphological, syntactic or even discursive).", "labels": [], "entities": [{"text": "BOW", "start_pos": 74, "end_pos": 77, "type": "METRIC", "confidence": 0.42067664861679077}]}, {"text": "It is also very common the use of metrics that have been linked to proficiency development and/or linguistic complexity in the area of Second Language Acquisition (SLA), like lexical richness or syntactic complexity.", "labels": [], "entities": [{"text": "Second Language Acquisition (SLA)", "start_pos": 135, "end_pos": 168, "type": "TASK", "confidence": 0.7881017128626505}]}, {"text": "Automatic proficiency classification has been approached mainly as a monolingual task, but recent approaches like have explored multi and crosslingual perspectives.", "labels": [], "entities": [{"text": "Automatic proficiency classification", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.7148273090521494}]}, {"text": "In our experiments, we use the main levels of the CEFR scale (A, B, C) and supervised machine learning techniques to classify L2 Portuguese and L2 Spanish texts.", "labels": [], "entities": [{"text": "CEFR scale", "start_pos": 50, "end_pos": 60, "type": "DATASET", "confidence": 0.682210773229599}]}, {"text": "As features, we test different linguistic representations, from BOW to syntactic dependencies, and some complexity features.", "labels": [], "entities": [{"text": "BOW", "start_pos": 64, "end_pos": 67, "type": "METRIC", "confidence": 0.9142658710479736}]}, {"text": "We perform monolingual and cross-lingual experiments, and we compare native to L2 productions in Spanish.", "labels": [], "entities": []}, {"text": "Furthermore, we try to answer the following questions: which linguistic features capture better the proficiency of a L2 text in Spanish and Portuguese?", "labels": [], "entities": []}, {"text": "Are those features similar between these two close languages?", "labels": [], "entities": []}, {"text": "When comparing L1 and L2 Spanish, which linguistic characteristics allow for predicting the level of linguistic development of a text?", "labels": [], "entities": []}, {"text": "We present relevant related work in section 2, and our methodology in section 3.", "labels": [], "entities": []}, {"text": "In section 4 we describe the experiments performed and discuss our results, while in section 5 we summarize our conclusions and future directions of work.", "labels": [], "entities": []}], "datasetContent": [{"text": "As we have seen, the task of proficiency testing can be considered as a classification or a regression problem, depending on the way we consider We will make the scripts available after the publication of the paper.", "labels": [], "entities": []}, {"text": "Counts are normalized by text length with the following formula: number of nouns/total words in text*1000.", "labels": [], "entities": []}, {"text": "the proficiency levels, that is, as discrete or continuous units.", "labels": [], "entities": []}, {"text": "In this work we are interested in conceptualizing proficiency levels in the same way that the CEFR scale does, that is, as discrete entities.", "labels": [], "entities": [{"text": "CEFR scale", "start_pos": 94, "end_pos": 104, "type": "DATASET", "confidence": 0.8902915120124817}]}, {"text": "Therefore, we modeled the problem as a classification task.", "labels": [], "entities": []}, {"text": "Another reason to choose classification over regression is presented in, who compared both approaches and got better results with the classification model.", "labels": [], "entities": []}, {"text": "We used the scikit-learn package (Pedregosa et al., 2011) for training and testing the models and for feature selection.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 102, "end_pos": 119, "type": "TASK", "confidence": 0.6831733137369156}]}, {"text": "We split both datasets in training and test sets (20% of data) for all the experiments.", "labels": [], "entities": []}, {"text": "In general, for each experiment we performed initial tests to check which algorithm worked better with each set of features.", "labels": [], "entities": []}, {"text": "In these previous experiments, we performed 10-fold cross-validation with the training set, training a different classifier for each set of features to support a comparison of them.", "labels": [], "entities": []}, {"text": "We evaluated a varied group of linear and nonlinear algorithms: Logistic Regression (LR), Linear Discriminant Analysis (LDA), KNeighborsClassifier (KNN), DecisionTreeClassifier(CART), GaussianNB (NB), Support Vector Clustering (SVC), LogitBoost (LB) and Random Forests (RF).", "labels": [], "entities": []}, {"text": "For each set of features, we selected the best performing model and we evaluated it against the test set.", "labels": [], "entities": []}, {"text": "We use accuracy as the main measure to evaluate the performance of our trained models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 7, "end_pos": 15, "type": "METRIC", "confidence": 0.9994174242019653}]}, {"text": "We also report weighted-F1 score because the datasets are unbalanced.", "labels": [], "entities": [{"text": "weighted-F1 score", "start_pos": 15, "end_pos": 32, "type": "METRIC", "confidence": 0.8403808772563934}]}, {"text": "Weighted-F1 score is computed as the weighted average of the F1 score for each label, taking label support (i.e., number of instances for each label in the data) into account.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.976558655500412}]}, {"text": "We also show F1 score per class, to analyze in detail the performance of the classifiers by level.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.981064647436142}]}, {"text": "We use text length as the general baseline.", "labels": [], "entities": []}, {"text": "We have performed different classification experiments to investigate the relationship between the linguistic features selected and the main CEFR proficiency levels.", "labels": [], "entities": [{"text": "CEFR", "start_pos": 141, "end_pos": 145, "type": "DATASET", "confidence": 0.8938233256340027}]}, {"text": "We investigate this relationship in three different scenarios.", "labels": [], "entities": []}, {"text": "First, we study the interaction of features and proficiency levels for L2 Spanish, using CEDEL2 texts.", "labels": [], "entities": [{"text": "CEDEL2 texts", "start_pos": 89, "end_pos": 101, "type": "DATASET", "confidence": 0.9694526791572571}]}, {"text": "Our main research question is: which linguistic features in our two sets allow for an accurate classification of CEFR proficiency levels in L2 Spanish?", "labels": [], "entities": []}, {"text": "This is a monolingual approach similar to the ones presented in the related work section.", "labels": [], "entities": []}, {"text": "Secondly, we investigate the same interaction in a cross-lingual scenario, from Spanish to Portuguese and vice versa.", "labels": [], "entities": []}, {"text": "With this experiment, we try to reply to two research questions: (i) are the linguistic patterns linked to each proficiency level in our two L2 languages similar to the extent that a model trained in one language can be transferred to the other?; (ii) if so, which features work better in the cross-lingual model?", "labels": [], "entities": []}, {"text": "This is an experiment similar to the one presented in, where a model trained with German texts is applied to a Czech and an Italian test set.", "labels": [], "entities": []}, {"text": "From the typological point of view, German is not close to Czech or Italian, while Portuguese and Spanish are similar languages, with a close morphology and Latin vocabulary.", "labels": [], "entities": []}, {"text": "Considering this fact, a priori we could expect good results in the cross-lingual experiments.", "labels": [], "entities": []}, {"text": "Finally, we study the relationship between learner and native texts, using our sets of features.", "labels": [], "entities": []}, {"text": "For those experiments, we were interested in replying to the following research question: which are the best linguistic features to differentiate a learner text from a native one?", "labels": [], "entities": []}, {"text": "We present our results in the sections below.", "labels": [], "entities": []}, {"text": "In this case, we used (L2) CEDEL2 and NLI-PT datasets and we performed cross-lingual experiments.", "labels": [], "entities": [{"text": "NLI-PT datasets", "start_pos": 38, "end_pos": 53, "type": "DATASET", "confidence": 0.9159113168716431}]}, {"text": "We tested both directions: Spanish to Portuguese and vice versa.", "labels": [], "entities": []}, {"text": "We performed the same type of experiments as for the monolingual dataset, with the only difference that, in this case, we use the whole monolingual corpus as the training dataset, and a section of the other dataset as the testing one.", "labels": [], "entities": []}, {"text": "We can see that, in general, we get poor results in the cross-lingual models.", "labels": [], "entities": []}, {"text": "For Spanish to Portuguese, none of the trained classifiers beats the baseline, and only the combination of POS and complexity features gets close.", "labels": [], "entities": [{"text": "POS", "start_pos": 107, "end_pos": 110, "type": "METRIC", "confidence": 0.8928380608558655}]}, {"text": "The only onefeature set that performs similar to the baseline is the POS one, but if we check table 6 we can see that the F1 score for level C is 0.", "labels": [], "entities": [{"text": "POS", "start_pos": 69, "end_pos": 72, "type": "DATASET", "confidence": 0.7739496231079102}, {"text": "F1 score", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9836326837539673}]}, {"text": "All the combinations with complexity features get results below the baseline, being the descriptive metrics the ones with the best score.", "labels": [], "entities": []}, {"text": "These numbers seem to be inline with the ones obtained for the monolingual dataset, with the POS and descriptive features as the most relevant in the classification task.", "labels": [], "entities": [{"text": "POS", "start_pos": 93, "end_pos": 96, "type": "METRIC", "confidence": 0.9382766485214233}, {"text": "classification task", "start_pos": 150, "end_pos": 169, "type": "TASK", "confidence": 0.8881958425045013}]}, {"text": "Concerning the results per class, POS features are the best to predict the A and B level, and lexical-complexity features the best for C.", "labels": [], "entities": []}, {"text": "Interestingly, seven of the twelve models get a F1 score of 0 for this level, while they are able to classify the other two levels, and only the complexity features are useful to classify level C.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9895636737346649}]}, {"text": "On the other hand, all the models get the best results for the A level.", "labels": [], "entities": [{"text": "A", "start_pos": 63, "end_pos": 64, "type": "METRIC", "confidence": 0.9850329756736755}]}, {"text": "Linguistic features are the more accurate for predicting this level, especially the POS features, which also get a high F1 score predicting the B level.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.9812560081481934}, {"text": "B", "start_pos": 144, "end_pos": 145, "type": "METRIC", "confidence": 0.8551331162452698}]}, {"text": "However, they obtain a 0 F1 score predicting the C level.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9784872531890869}]}, {"text": "We can see in table 7 that for Portuguese to Spanish, POS features are also the best among linguistic features to predict level A and B, while they are the worst to predict level C.", "labels": [], "entities": [{"text": "POS", "start_pos": 54, "end_pos": 57, "type": "METRIC", "confidence": 0.9019343256950378}]}, {"text": "This fact seems to indicate that A and B level show certain recurrent morpho-syntactic patterns that allow for their identification cross-linguistically, while level C does not.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Distribution of learner texts by CEFR  proficiency level in CEDEL2.", "labels": [], "entities": [{"text": "CEFR  proficiency level", "start_pos": 43, "end_pos": 66, "type": "DATASET", "confidence": 0.8287246624628702}, {"text": "CEDEL2", "start_pos": 70, "end_pos": 76, "type": "DATASET", "confidence": 0.6627317070960999}]}, {"text": " Table 3: General results for L2 Spanish.", "labels": [], "entities": []}, {"text": " Table 4: Results per class for L2 Spanish.", "labels": [], "entities": [{"text": "L2 Spanish", "start_pos": 32, "end_pos": 42, "type": "TASK", "confidence": 0.6046736538410187}]}, {"text": " Table 5: General cross-lingual results for Spanish  to Portuguese.", "labels": [], "entities": []}, {"text": " Table 6: Results per class for cross-lingual Span- ish to Portuguese.", "labels": [], "entities": [{"text": "Span- ish to Portuguese", "start_pos": 46, "end_pos": 69, "type": "TASK", "confidence": 0.6608939588069915}]}, {"text": " Table 7: General cross-lingual results for Por- tuguese to Spanish.", "labels": [], "entities": []}, {"text": " Table 8: Results per class for cross-lingual Por- tuguese to Spanish.", "labels": [], "entities": []}, {"text": " Table 9: Classification including native texts.", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.974054753780365}]}, {"text": " Table 10: Classification including native texts, per  level.", "labels": [], "entities": [{"text": "Classification", "start_pos": 11, "end_pos": 25, "type": "TASK", "confidence": 0.9631062150001526}]}, {"text": " Table 11: LING model in L2+NAT Spanish.", "labels": [], "entities": [{"text": "LING", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.9174711108207703}, {"text": "NAT", "start_pos": 28, "end_pos": 31, "type": "METRIC", "confidence": 0.8913589119911194}]}, {"text": " Table 12: LING model in L2 Spanish.", "labels": [], "entities": [{"text": "LING", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.882125735282898}]}, {"text": " Table 13: COMP model in L2+NAT Spanish.", "labels": [], "entities": []}, {"text": " Table 14: COMP model in L2 Spanish.", "labels": [], "entities": []}, {"text": " Table 15: POS model in L2+NAT Spanish.", "labels": [], "entities": []}]}