{"title": [{"text": "An Incremental Iterated Response Model of Pragmatics", "labels": [], "entities": []}], "abstractContent": [{"text": "Recent Iterated Response (IR) models of prag-matics conceptualize language use as a recur-sive process in which agents reason about each other to increase communicative efficiency.", "labels": [], "entities": []}, {"text": "These models are generally defined over complete utterances.", "labels": [], "entities": []}, {"text": "However, there is substantial evidence that pragmatic reasoning takes place incrementally during production and comprehension.", "labels": [], "entities": []}, {"text": "We address this with an incremen-tal IR model.", "labels": [], "entities": []}, {"text": "We compare the incremental and global versions using computational simulations , and we assess the incremental model against existing experimental data and in the TUNA corpus for referring expression generation , showing that the model can capture phenomena out of reach of global versions.", "labels": [], "entities": [{"text": "TUNA corpus", "start_pos": 163, "end_pos": 174, "type": "DATASET", "confidence": 0.962176501750946}, {"text": "referring expression generation", "start_pos": 179, "end_pos": 210, "type": "TASK", "confidence": 0.7964475154876709}]}], "introductionContent": [{"text": "A number of recent Bayesian models of pragmatics conceptualize language use as a recursive process in which abstract speaker and listener agents reason about each other to increase communicative efficiency and enrich the meanings of the utterances they hear in context-dependent ways; for overviews, see.", "labels": [], "entities": []}, {"text": "For example, in these models, pragmatic listeners reason, not about the literal semantics of the utterances they hear, but rather about pragmatic speakers reasoning about simpler listeners that are defined directly in terms of the literal semantics.", "labels": [], "entities": []}, {"text": "In this back-andforth, many phenomena characterized by as conversational implicatures emerge naturally as probabilistic inferences.", "labels": [], "entities": []}, {"text": "In general, these iterated response (IR) models separate pragmatic reasoning from incremental processing, in that the calculations are done in terms of complete utterances.", "labels": [], "entities": []}, {"text": "However, there is substantial evidence that pragmatic processing is incremental: listeners venture pragmatic inferences over the time-course of the utterances they hear, which influences the choices that speakers make.", "labels": [], "entities": []}, {"text": "To address this, we develop an IR model that is incremental in the sense that pragmatic reasoning takes place word-by-word (though the process could be defined in terms of different linguistic units, like morphemes or phrases).", "labels": [], "entities": [{"text": "IR", "start_pos": 31, "end_pos": 33, "type": "TASK", "confidence": 0.9540614485740662}]}, {"text": "A variant of this model was applied successfully to pragmatic image captioning by; here we concentrate on its qualitative behavior and linguistic predictions.", "labels": [], "entities": [{"text": "pragmatic image captioning", "start_pos": 52, "end_pos": 78, "type": "TASK", "confidence": 0.6269452273845673}]}, {"text": "We present computational experiments which demonstrate that incremental and global pragmatics make different predictions, and we show that a speaker that incrementally makes pragmatically informative choices arrives at an utterance which is globally informative.", "labels": [], "entities": []}, {"text": "We then argue that an incremental model can account for two empirical observations out of reach of a global model: (i) the asymmetry between adjective-noun and nounadjective languages in over-informative referential behavior, and (ii) the anticipatory implicatures arising from contrastive modifiers.", "labels": [], "entities": []}, {"text": "The first of these observations requires a model of language production, while the second requires a model of language interpretation, and as such these case studies serve to demonstrate both aspects of incremental pragmatics.", "labels": [], "entities": [{"text": "language interpretation", "start_pos": 110, "end_pos": 133, "type": "TASK", "confidence": 0.715090349316597}]}, {"text": "Finally, we apply the model to the TUNA corpus for referring expression generation (, showing that it makes more realistic predictions about attributive modifiers than does its global counterpart.", "labels": [], "entities": [{"text": "TUNA corpus", "start_pos": 35, "end_pos": 46, "type": "DATASET", "confidence": 0.9309376180171967}, {"text": "referring expression generation", "start_pos": 51, "end_pos": 82, "type": "TASK", "confidence": 0.8147427241007487}]}], "datasetContent": [{"text": "In order to observe the behavior of our incremental pragmatic model on real data, we make use of the TUNA corpus).", "labels": [], "entities": [{"text": "TUNA corpus", "start_pos": 101, "end_pos": 112, "type": "DATASET", "confidence": 0.957796573638916}]}, {"text": "TUNA is built around a referring expression task grounded in images.", "labels": [], "entities": []}, {"text": "The images are coded using a fixed set of attributes, and the human-produced utterances are coded using the same attributes.", "labels": [], "entities": []}, {"text": "Thus, TUNA lets us study the core content of naturally produced referring expressions without forcing us to confront the full complexity of natural language.", "labels": [], "entities": []}, {"text": "Our goal is to show that, when a cost is imposed which prefers shorter utterances, the incremental model S UTT-IP 1 is less affected, and on average produces more two-word utterances than S UTT-GP 1 . We hypothesize this on the basis of the preference of S UTT-IP 1 for utterances where the choice of each word is made with high certainty.", "labels": [], "entities": []}, {"text": "This means that informative one-word utterances which have reasonable probability of being extended with a second word will score lower than two-word utterances where the choice of the first word all but fixes the choice of the second.", "labels": [], "entities": []}, {"text": "Since most oneword utterances admit the possibility of an extension to a second word, this dynamic would result in a preference for the longer, two-word utterances.", "labels": [], "entities": []}, {"text": "This would provide further evidence that the dynamic described in section 3.1 generalizes from an idealized example to real language.", "labels": [], "entities": []}], "tableCaptions": []}