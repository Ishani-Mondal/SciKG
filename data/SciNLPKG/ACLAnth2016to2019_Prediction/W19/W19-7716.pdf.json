{"title": [{"text": "Dependency Parsing as Sequence Labeling with Head-Based Encoding and Multi-Task Learning", "labels": [], "entities": [{"text": "Dependency Parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7213605344295502}, {"text": "Sequence Labeling", "start_pos": 22, "end_pos": 39, "type": "TASK", "confidence": 0.7886016070842743}]}], "abstractContent": [{"text": "Dependency parsing as sequence labeling has recently proved to be a relevant alternative to the traditional transition-and graph-based approaches.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8878184258937836}]}, {"text": "It offers a good trade-off between parsing accuracy and speed.", "labels": [], "entities": [{"text": "parsing", "start_pos": 35, "end_pos": 42, "type": "TASK", "confidence": 0.9727020859718323}, {"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.964424192905426}, {"text": "speed", "start_pos": 56, "end_pos": 61, "type": "METRIC", "confidence": 0.9884268641471863}]}, {"text": "However, recent work on dependency parsing as sequence labeling ignore the pre-processing time of Part-of-Speech tagging-which is required for this task-in the evaluation of speed while other studies showed that Part-of-Speech tags are not essential to achieve state-of-the-art parsing scores.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.8411394655704498}, {"text": "sequence labeling", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.6453993916511536}, {"text": "Part-of-Speech tagging-which", "start_pos": 98, "end_pos": 126, "type": "TASK", "confidence": 0.7109679579734802}, {"text": "speed", "start_pos": 174, "end_pos": 179, "type": "METRIC", "confidence": 0.968748927116394}]}, {"text": "In this paper, we compare the accuracy and speed of shared and stacked multi-task learning strategies-as well as a strategy that combines both-to learn Part-of-Speech tagging and dependency parsing in a single sequence labeling pipeline.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9988792538642883}, {"text": "Part-of-Speech tagging", "start_pos": 152, "end_pos": 174, "type": "TASK", "confidence": 0.7560573518276215}, {"text": "dependency parsing", "start_pos": 179, "end_pos": 197, "type": "TASK", "confidence": 0.7478504776954651}]}, {"text": "In addition, we propose an alternative encoding of the dependencies as labels which does not use Part-of-Speech tags and improves dependency parsing accuracy for most of the languages we evaluate.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 130, "end_pos": 148, "type": "TASK", "confidence": 0.7450497150421143}, {"text": "accuracy", "start_pos": 149, "end_pos": 157, "type": "METRIC", "confidence": 0.9475892782211304}]}], "introductionContent": [{"text": "Traditional dependency parsers are transition based () or graph based).", "labels": [], "entities": []}, {"text": "In contrast to previous studies, recently showed that dependency parsing reframed as a sequence labeling problem is also a competitive strategy.", "labels": [], "entities": [{"text": "dependency parsing reframed as a sequence labeling problem", "start_pos": 54, "end_pos": 112, "type": "TASK", "confidence": 0.7405524663627148}]}, {"text": "The idea is, fora given token in a sentence, to encode into a single tag the information about which token is its parent in the dependency tree (and the label of the incoming dependency).", "labels": [], "entities": []}, {"text": "These tags can be predicted in a sequence labeling process and then be decoded in order to rebuild the dependency tree.", "labels": [], "entities": []}, {"text": "compare the performance of dependency parsing as sequence labeling using several encodings of the dependencies which have been presented in previous work and show that the best encoding leads to state-of-the-art performance.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.8695524036884308}]}, {"text": "One of the main arguments for performing dependency parsing as sequence labeling is to achieve a good speed-accuracy tradeoff (leveraging the efficiency of deep learning frameworks running on GPUs).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.7895763218402863}, {"text": "sequence labeling", "start_pos": 63, "end_pos": 80, "type": "TASK", "confidence": 0.6541570276021957}]}, {"text": "However, the encoding that is reported as the best one in (, requires Part-of-Speech (PoS) tags to encode and decode the dependencies.", "labels": [], "entities": []}, {"text": "The method thus involves a pre-processing step of PoS-tagging which is not considered in the evaluation of the parsing speed, whereas previous studies ( showed that PoS-tagging is not a requirement for neural transition-based parsers -using word embeddings as input -in order to achieve state-of-the-art performance.", "labels": [], "entities": []}, {"text": "In this work, we setup a single pipeline that performs both PoS-tagging and dependency parsing in order to study the performance of several architectures.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.7350796461105347}]}, {"text": "We compare the shared (S\u00f8gaard and Goldberg, 2016) and stacked (Hashimoto et al., 2017) multi-task learning strategies to a strategy that combines both, with the aim of identifying a proper trade-off between parsing accuracy and speed.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 216, "end_pos": 224, "type": "METRIC", "confidence": 0.9167846441268921}]}, {"text": "We also present an alternative encoding that does not use PoS-tags to encode the dependencies.", "labels": [], "entities": []}, {"text": "It, however, requires an additional step of head tagging which consists of predicting which tokens in a sentence are parents of other tokens (i.e., have dependents in the dependency tree).", "labels": [], "entities": [{"text": "head tagging", "start_pos": 44, "end_pos": 56, "type": "TASK", "confidence": 0.7770715951919556}]}, {"text": "Hence, the following task of dependency parsing consists of predicting to which of these parents the tokens are attached.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.8559056222438812}]}, {"text": "We use a similar encoding as in.", "labels": [], "entities": []}, {"text": "This new encoding aims at reducing the complexity of the attachment step correcting some of the flaws of the original PoS-based encoding.", "labels": [], "entities": []}, {"text": "We finally evaluate whether ablating PoS-tagging in the pipeline using the new encoding affects dependency parsing performance.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 96, "end_pos": 114, "type": "TASK", "confidence": 0.7535474896430969}]}, {"text": "Contribution We (i) combine two multi-task learning strategies to setup an efficient pipeline for PoStagging and dependency parsing as sequence labeling and (ii) propose anew encoding of the dependencies as labels that does not use PoS-tags.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 113, "end_pos": 131, "type": "TASK", "confidence": 0.7553317248821259}]}], "datasetContent": [{"text": "Models We design three types of experiments.", "labels": [], "entities": []}, {"text": "Ina first set of experiments, we compare the shared and stacked learning strategies with the combined strategy.", "labels": [], "entities": []}, {"text": "For each experiment, we train four tasks (simultaneously or sequentially): PoS-tagging, (morphological) feature tagging, label (dependency relation) tagging and dependency attachment.", "labels": [], "entities": [{"text": "label (dependency relation) tagging", "start_pos": 121, "end_pos": 156, "type": "TASK", "confidence": 0.5966660330692927}, {"text": "dependency attachment", "start_pos": 161, "end_pos": 182, "type": "TASK", "confidence": 0.7684490084648132}]}, {"text": "For the combined strategy, we define two groups of tasks (trained in the following order): PoS-tagging/feature tagging, followed by label tagging/dependency attachment.", "labels": [], "entities": [{"text": "PoS-tagging/feature tagging", "start_pos": 91, "end_pos": 118, "type": "TASK", "confidence": 0.6117430180311203}, {"text": "label tagging/dependency attachment", "start_pos": 132, "end_pos": 167, "type": "TASK", "confidence": 0.6268387138843536}]}, {"text": "As a second experiment, we compare the performance of the combined system using different encodings of the dependencies (PoS-based and head-based).", "labels": [], "entities": []}, {"text": "When using our proposed head-based encodings, the groups are (trained in this order): PoS-tagging/feature tagging/head tagging, followed by label tagging/dependency attachment.", "labels": [], "entities": [{"text": "head tagging", "start_pos": 114, "end_pos": 126, "type": "TASK", "confidence": 0.7112633585929871}, {"text": "label tagging/dependency attachment", "start_pos": 140, "end_pos": 175, "type": "TASK", "confidence": 0.6238694190979004}]}, {"text": "Third, we train the pipeline without PoS-tagging and feature tagging (-PoS/feats), using only head tagging as a first group.", "labels": [], "entities": []}, {"text": "Setup We use the pre-trained word embeddings of.", "labels": [], "entities": []}, {"text": "For each task or group of tasks, we use 2 hidden layers of dimension 256.", "labels": [], "entities": []}, {"text": "Dimension of the hidden layer for training character embeddings is 128.", "labels": [], "entities": []}, {"text": "Data We use the Universal Dependencies 2.2 (Nivre et al., 2018) dataset for training and evaluating.", "labels": [], "entities": [{"text": "Universal Dependencies 2.2 (Nivre et al., 2018) dataset", "start_pos": 16, "end_pos": 71, "type": "DATASET", "confidence": 0.6589176790280775}]}, {"text": "Following de, we select a subset of the treebanks: Czech-PDT (cs), English-EWT (en), Finnish-TDT (fi), Ancient Greek-PROIEL (grc), Hebrew-HTB (he), Kazakh-KTB (kk), Tamil-TTB (ta) and Chinese-GSD (zh).", "labels": [], "entities": []}, {"text": "Universal PoS-tags (UPOS) are used for PoS-tagging and PoS-based encoding.", "labels": [], "entities": [{"text": "PoS-based encoding", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.7005959153175354}]}, {"text": "Head tags are deduced from the gold universal dependencies and PoS-tags as stated in Section 3.", "labels": [], "entities": []}, {"text": "We average the scores on 5 runs (with different random seeds) for each experiment.", "labels": [], "entities": []}, {"text": "We calculate the unlabeled attachment score (UAS) and the labeled attachment score (LAS) following the guideline of the.", "labels": [], "entities": [{"text": "unlabeled attachment score (UAS)", "start_pos": 17, "end_pos": 49, "type": "METRIC", "confidence": 0.804256891210874}, {"text": "labeled attachment score (LAS)", "start_pos": 58, "end_pos": 88, "type": "METRIC", "confidence": 0.8865889807542165}]}, {"text": "We also evaluate precision on heads, i.e., percentage of correctly tagged parents.", "labels": [], "entities": [{"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9996358156204224}]}], "tableCaptions": [{"text": " Table 1: Dependency parsing scores (+ average sentence per second on CPU) using the PoS-tag based  encoding for the different learning strategies (best in bold;  \u2020 marks statistical significance; T-test with  p<0.05). STR19 scores are reported from Strzyz et al. (2019) (besides from Tamil for which they use  gold PoS-tags).", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.6630652397871017}, {"text": "T-test", "start_pos": 197, "end_pos": 203, "type": "METRIC", "confidence": 0.9865431785583496}, {"text": "STR19", "start_pos": 219, "end_pos": 224, "type": "METRIC", "confidence": 0.8176397085189819}]}, {"text": " Table 2: Dependency parsing scores (+ precision on heads) with the different dependency encodings,  using the combined learning strategy (best in bold;  \u2020 marks statistical significance).", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.7244388610124588}, {"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9928804039955139}]}]}