{"title": [{"text": "A Comparison between NMT and PBSMT Performance for Translating Noisy User-Generated Content", "labels": [], "entities": [{"text": "PBSMT", "start_pos": 29, "end_pos": 34, "type": "METRIC", "confidence": 0.5028879642486572}, {"text": "Translating Noisy User-Generated Content", "start_pos": 51, "end_pos": 91, "type": "TASK", "confidence": 0.7773266285657883}]}], "abstractContent": [{"text": "This work compares the performances achieved by Phrase-Based Statistical Machine Translation systems (PBSMT) and attention-based Neural Machine Translation systems (NMT) when translating User Generated Content (UGC), as encountered in social medias, from French to English.", "labels": [], "entities": [{"text": "Phrase-Based Statistical Machine Translation", "start_pos": 48, "end_pos": 92, "type": "TASK", "confidence": 0.5682321339845657}, {"text": "attention-based Neural Machine Translation", "start_pos": 113, "end_pos": 155, "type": "TASK", "confidence": 0.6767626255750656}]}, {"text": "We show that, contrary to what could be expected , PBSMT outperforms NMT when translating non-canonical inputs.", "labels": [], "entities": []}, {"text": "Our error analysis uncovers the specificities of UGC that are problematic for sequential NMT architectures and suggests new avenue for improving NMT models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Neural Machine Translation) and, more specifically, attention-based models ( have recently become the method of choice for machine translation: many works have shown that Neural Machine Translation (NMT) outperforms classic PhraseBased Statistical Machine Translation (PBSMT) approaches over a wide array of datasets.", "labels": [], "entities": [{"text": "Neural Machine Translation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6634776095549265}, {"text": "machine translation", "start_pos": 123, "end_pos": 142, "type": "TASK", "confidence": 0.8015315234661102}, {"text": "Neural Machine Translation (NMT)", "start_pos": 171, "end_pos": 203, "type": "TASK", "confidence": 0.8252967794736227}, {"text": "PhraseBased Statistical Machine Translation (PBSMT)", "start_pos": 224, "end_pos": 275, "type": "TASK", "confidence": 0.7490653225353786}]}, {"text": "Indeed, NMT provides better generalization and accuracy capabilities) even if it has well-identified limits such as over-translating and dropping translations (.", "labels": [], "entities": [{"text": "NMT", "start_pos": 8, "end_pos": 11, "type": "DATASET", "confidence": 0.749964714050293}, {"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9980803728103638}]}, {"text": "This work aims at studying how these interactions impact machine translation of noisy texts as generally found in social media and web forums and often denoted as User Generated Content (UGC).", "labels": [], "entities": [{"text": "machine translation of noisy texts", "start_pos": 57, "end_pos": 91, "type": "TASK", "confidence": 0.8315283358097076}]}, {"text": "Given the increasing importance of social medias, this type of texts has been extensively studied over the years, e.g..", "labels": [], "entities": []}, {"text": "In this work we focus on UGC in which no grammatical, orthographic or coherence rules are respected, other than those considered by the writer.", "labels": [], "entities": []}, {"text": "Such rule-free environment promotes a plethora of vocabulary and grammar variations, which account for the large increase of out-of-vocabulary tokens (OOVs) in UGC corpora with respect to canonical parallel training data.", "labels": [], "entities": []}, {"text": "Translating UGC raises several challenges as it corresponds to both a low-resource scenarioproducing parallel UGC corpora is very costly and often problematic due to inconsistencies between translators -and a domain adaptation scenario -only canonical parallel corpora are widely available to train MT systems and they must be adapted to the specificities of UGC.", "labels": [], "entities": [{"text": "MT", "start_pos": 299, "end_pos": 301, "type": "TASK", "confidence": 0.9768247008323669}]}, {"text": "We therefore believe that translating UGC provides a challenging testbed to identify the limits of NMT approaches and to better understand how they are working.", "labels": [], "entities": [{"text": "translating UGC", "start_pos": 26, "end_pos": 41, "type": "TASK", "confidence": 0.7478400766849518}]}, {"text": "This corpus is much noisier than existing UGC corpora.", "labels": [], "entities": []}, {"text": "All our data sets are available at https://gitlab.inria.", "labels": [], "entities": []}, {"text": "fr/seddah/parsiti.", "labels": [], "entities": []}], "datasetContent": [{"text": "As the goal of this work is to compare the output of NMT and PBSMT when translating UGC corpora.", "labels": [], "entities": [{"text": "NMT", "start_pos": 53, "end_pos": 56, "type": "DATASET", "confidence": 0.8469505310058594}, {"text": "translating UGC corpora", "start_pos": 72, "end_pos": 95, "type": "TASK", "confidence": 0.8035929203033447}]}, {"text": "Because of the lack of manually translated UGC, we consider a out-domain scenario in which our systems are trained on the canonical corpora generally used in MT evaluation campaigns and tested on UGC data.", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 158, "end_pos": 171, "type": "TASK", "confidence": 0.9139928817749023}, {"text": "UGC data", "start_pos": 196, "end_pos": 204, "type": "DATASET", "confidence": 0.8088826239109039}]}, {"text": "We will first describe the datasets used in this work ( \u00a73.1), then the different systems we have considered ( \u00a73.2) and finally the pre-and post-processing applied ( \u00a73.3).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics on the French side of the corpora used in our experiments. TTR stands for Type-to-Token", "labels": [], "entities": [{"text": "French side", "start_pos": 28, "end_pos": 39, "type": "DATASET", "confidence": 0.9382783472537994}, {"text": "TTR", "start_pos": 80, "end_pos": 83, "type": "METRIC", "confidence": 0.8507274985313416}]}, {"text": " Table 4: Domain-related measure on the source side (FR), between Test sets and Large OpenSubtitles  training set. Dags indicate UGC corpora.", "labels": [], "entities": [{"text": "FR)", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.968776673078537}]}, {"text": " Table 5: BLEU score results for our three models for the different train-test combinations. All the MT  predictions have been treated to replace UNK tokens according to Section 3.3.2. The best result for each  test set is marked in bold, best result for each system (row-wise) in blue color and score for in-domain  test sets with a dag. 'Crap', 'MTNT', 'News' and 'Open' stand, respectively, for the Cr#pbank, MTNT,  newstest'14 and OpenSubtitlesTest test sets.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9990757703781128}, {"text": "MT", "start_pos": 101, "end_pos": 103, "type": "TASK", "confidence": 0.9482388496398926}, {"text": "MTNT", "start_pos": 412, "end_pos": 416, "type": "DATASET", "confidence": 0.8198707699775696}, {"text": "OpenSubtitlesTest test sets", "start_pos": 435, "end_pos": 462, "type": "DATASET", "confidence": 0.9325170715649923}]}, {"text": " Table 6: Noise added by the MT system estimated  with the TSNR metric for the Cr#pbank corpus,  the lower the better.", "labels": [], "entities": [{"text": "MT", "start_pos": 29, "end_pos": 31, "type": "TASK", "confidence": 0.9570255279541016}, {"text": "TSNR", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.7839645743370056}, {"text": "Cr#pbank corpus", "start_pos": 79, "end_pos": 94, "type": "DATASET", "confidence": 0.8446329683065414}]}, {"text": " Table 7: BLEU score results comparison on the  Cr#pbank and MTNT blind test sets. N&G18 stands for", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9701730608940125}, {"text": "Cr#pbank", "start_pos": 48, "end_pos": 56, "type": "DATASET", "confidence": 0.7525546550750732}, {"text": "MTNT blind test sets", "start_pos": 61, "end_pos": 81, "type": "DATASET", "confidence": 0.8396861404180527}, {"text": "N&G18", "start_pos": 83, "end_pos": 88, "type": "METRIC", "confidence": 0.8596030672391256}]}]}