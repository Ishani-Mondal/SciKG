{"title": [{"text": "The Karlsruhe Institute of Technology Systems for the News Translation Task in WMT 2018", "labels": [], "entities": [{"text": "News Translation Task in WMT", "start_pos": 54, "end_pos": 82, "type": "TASK", "confidence": 0.6507158577442169}]}], "abstractContent": [{"text": "We present our experiments in the scope of the news translation task in WMT 2018, in directions: English\u2192German.", "labels": [], "entities": [{"text": "news translation task", "start_pos": 47, "end_pos": 68, "type": "TASK", "confidence": 0.7512173354625702}, {"text": "WMT 2018", "start_pos": 72, "end_pos": 80, "type": "DATASET", "confidence": 0.8583761155605316}]}, {"text": "The core of our systems is the encoder-decoder based neural machine translation models using the transformer architecture.", "labels": [], "entities": []}, {"text": "We enhanced the model with a deeper architecture.", "labels": [], "entities": []}, {"text": "By using techniques to limit the memory consumption, we were able to train models that are 4 times larger on one GPU and improve the performance by 1.2 BLEU points.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 152, "end_pos": 156, "type": "METRIC", "confidence": 0.9989635944366455}]}, {"text": "Furthermore, we performed sentence selection for the newly available ParaCrawl corpus.", "labels": [], "entities": [{"text": "sentence selection", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.791947066783905}, {"text": "ParaCrawl corpus", "start_pos": 69, "end_pos": 85, "type": "DATASET", "confidence": 0.8974365592002869}]}, {"text": "Thereby, we could improve the effectiveness of the corpus by 0.5 BLEU points.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 65, "end_pos": 69, "type": "METRIC", "confidence": 0.9995611310005188}]}], "introductionContent": [{"text": "This manuscript provides the technical details regarding our submission in the WMT18 shared task on English\u2192German news translation.", "labels": [], "entities": [{"text": "WMT18 shared task", "start_pos": 79, "end_pos": 96, "type": "DATASET", "confidence": 0.8036400675773621}, {"text": "English\u2192German news translation", "start_pos": 100, "end_pos": 131, "type": "TASK", "confidence": 0.6278491020202637}]}, {"text": "Our submission has two major research contributions: Firstly, the development of a deep, efficient neural architectures and secondly, the cleaning and data selection of web crawled data.", "labels": [], "entities": [{"text": "data selection of web crawled data", "start_pos": 151, "end_pos": 185, "type": "TASK", "confidence": 0.8083987782398859}]}, {"text": "We developed a efficient approach to train a deep transformer model on a single GPU.", "labels": [], "entities": []}, {"text": "This allows use to train a 4 times deeper model than state-of-the-art models on one GPUs.", "labels": [], "entities": []}, {"text": "In the experiments we are able to show that these models perform 1.2 BLEU points better than the baseline model using already 8 layers.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.9992375373840332}]}, {"text": "Secondly, we performed additional filtering on the ParaCrawl corpus.", "labels": [], "entities": [{"text": "ParaCrawl corpus", "start_pos": 51, "end_pos": 67, "type": "DATASET", "confidence": 0.9516800940036774}]}, {"text": "We are using the logprobabilities of a baseline NMT system to filter the low quality translations.", "labels": [], "entities": []}, {"text": "While we are only able to improve the translation quality slightly by 0.3 BLUE points using all ParaCrawl data, the integration of the clean cropus improved the translation quality of 0.8 BLEU points.", "labels": [], "entities": [{"text": "BLUE", "start_pos": 74, "end_pos": 78, "type": "METRIC", "confidence": 0.9986760020256042}, {"text": "ParaCrawl data", "start_pos": 96, "end_pos": 110, "type": "DATASET", "confidence": 0.9285667836666107}, {"text": "BLEU", "start_pos": 188, "end_pos": 192, "type": "METRIC", "confidence": 0.9984544515609741}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2:  RNNs vs Transformers (various depths)  trained without paraCrawl.", "labels": [], "entities": [{"text": "paraCrawl", "start_pos": 66, "end_pos": 75, "type": "DATASET", "confidence": 0.8946729302406311}]}, {"text": " Table 3: Experiments using different data sizes", "labels": [], "entities": []}, {"text": " Table 4: Experiments using dropout, with large data including filtered paraCrawl.", "labels": [], "entities": []}, {"text": " Table 5: Experiments using different layers, with large  data including filtered paraCrawl.", "labels": [], "entities": []}, {"text": " Table 6: Systems used in the final submission", "labels": [], "entities": []}]}