{"title": [{"text": "Cyberbullying Detection Task: The EBSI-LIA-UNAM system (ELU) at COLING'18 TRAC-1", "labels": [], "entities": [{"text": "Cyberbullying Detection", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.730679988861084}, {"text": "EBSI-LIA-UNAM system (ELU) at COLING'18 TRAC-1", "start_pos": 34, "end_pos": 80, "type": "DATASET", "confidence": 0.7911467850208282}]}], "abstractContent": [{"text": "The phenomenon of cyberbullying has growing in worrying proportions with the development of social networks.", "labels": [], "entities": []}, {"text": "Forums and chat rooms are spaces where serious damage can now be done to others, while the tools for avoiding on-line spills are still limited.", "labels": [], "entities": []}, {"text": "This study aims to assess the ability that both classical and state-of-the-art vector space modeling methods provide to well known learning machines to identify aggression levels in social network cyberbullying (i.e. social network posts manually labeled as Overtly Aggressive, Covertly Aggressive and Non-aggressive).", "labels": [], "entities": []}, {"text": "To this end, an exploratory stage was performed first in order to find relevant settings to test, i.e. by using training and development samples, we trained multiple learning machines using multiple vector space modeling methods and discarded the less informative configurations.", "labels": [], "entities": []}, {"text": "Finally, we selected the two best settings and their voting combination to form three competing systems.", "labels": [], "entities": []}, {"text": "These systems were submitted to the competition of the TRACK-1 task of the Workshop on Trolling, Aggression and Cyberbullying.", "labels": [], "entities": [{"text": "TRACK-1 task", "start_pos": 55, "end_pos": 67, "type": "TASK", "confidence": 0.42081309854984283}]}, {"text": "Our voting combination system resulted second place in predicting Aggression levels on a test set of untagged social network posts.", "labels": [], "entities": [{"text": "Aggression levels", "start_pos": 66, "end_pos": 83, "type": "METRIC", "confidence": 0.9272733330726624}]}], "introductionContent": [{"text": "The introduction of the Internet and its democratization in the public sphere has fostered the emergence of many sociological phenomena.", "labels": [], "entities": []}, {"text": "It opens the possibility of forming friendly relations and information sharing from online networking platforms.", "labels": [], "entities": [{"text": "information sharing", "start_pos": 59, "end_pos": 78, "type": "TASK", "confidence": 0.7357560694217682}]}, {"text": "These platforms, which are often the subject of strong ownership by young users, introduce a paradigm shift in interpersonal relationships since they are now interactive spaces where it is hard to put regulation rules in place.", "labels": [], "entities": []}, {"text": "Thus, each time more we seethe appearing of aggressive behaviors that were confined to the physical space until recently.", "labels": [], "entities": []}, {"text": "These aggressions can take different forms: insults, intimidation, humiliation, exclusion, etc.", "labels": [], "entities": []}, {"text": "All them have for common point to take place in a space where it is possible to cause serious moral damage without suffering the consequences, in particular because of the possibility of evolving in a completely anonymous way.", "labels": [], "entities": []}, {"text": "This phenomenon, referred to as cyberbullying, or Internet harassment, is defined as \"the use of information and communication technologies to repeatedly, intentionally, and aggressively engage in behavior with respect to an individual or a group with the intention of causing harm to others\" -Belsey.", "labels": [], "entities": [{"text": "the use of information and communication technologies to repeatedly, intentionally, and aggressively engage in behavior with respect to an individual or a group with the intention of causing harm to others", "start_pos": 86, "end_pos": 291, "type": "Description", "confidence": 0.8480584693677498}]}, {"text": "Several solutions have been proposed, often based on a behavioral and pedagogical approach (ignore the attacker, confront him or even denounce him).", "labels": [], "entities": []}, {"text": "However, it becomes necessary to think about relevant algorithmic strategies to better protect Internet users from cyberbullying.", "labels": [], "entities": []}, {"text": "Such strategies would allow the establishment of an automated system to detect cyberbullying in social media.", "labels": [], "entities": []}, {"text": "This assist moderators to identify the most serious cases, and thus to contribute to a safer virtual space for both the youngest and the adults.", "labels": [], "entities": []}, {"text": "In this paper we propose an approach based on multiple classical text mining pipelines.", "labels": [], "entities": [{"text": "text mining pipelines", "start_pos": 65, "end_pos": 86, "type": "TASK", "confidence": 0.7786949773629507}]}, {"text": "The aim of this is to explore the actual difficulties linguistic and extralinguistic phenomena may imply to effectively identify aggression levels of cyberbullying in social network posts manually labeled as Overtly Aggressive (OAG), Covertly Aggressive (CAG) and Non-aggressive (NAG).", "labels": [], "entities": []}, {"text": "Our exploratory approach has two main stages.", "labels": [], "entities": []}, {"text": "First, we tested multiple vector space modeling methods along with multiple well known learning machines (classifiers) for predicting each of aggression levels individually.", "labels": [], "entities": []}, {"text": "The vector space modeling techniques included TF-IDF vectors, Latent Semantic Analysis (LSA, of varied dimensionalities) of TF-IDF vectors.", "labels": [], "entities": []}, {"text": "Both TF-IDF and LSA were computed for character and word n\u2212gram features.", "labels": [], "entities": [{"text": "TF-IDF", "start_pos": 5, "end_pos": 11, "type": "METRIC", "confidence": 0.5407034754753113}, {"text": "LSA", "start_pos": 16, "end_pos": 19, "type": "METRIC", "confidence": 0.8717280626296997}]}, {"text": "In addition, we used word embedding-based representations of posts.", "labels": [], "entities": []}, {"text": "Learning machines that were evaluated along with the aforementioned vector space modeling methods include Na\u00efve Bayes, Linear Perceptron, Support Vector Machine (SVM) and Passive-Aggressive classifier.", "labels": [], "entities": []}, {"text": "Once this first stage gives us several preliminary results, we selected the two configurations giving the best accuracies as competing systems for the first two runs.", "labels": [], "entities": []}, {"text": "As a third run, we combined these two systems, which incorporates a random class generator based on class frequencies of the training and development sets.", "labels": [], "entities": []}, {"text": "This class generator draws one of the three classes in the case of disagreement of the combined systems.", "labels": [], "entities": []}, {"text": "This approach resulted in 2nd place of the Facebook competition dataset with 0.6315 of weighted F1 score.", "labels": [], "entities": [{"text": "Facebook competition dataset", "start_pos": 43, "end_pos": 71, "type": "DATASET", "confidence": 0.9008712371190389}, {"text": "F1 score", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.9698096811771393}]}, {"text": "In the Social Media dataset, our best system resulted in 4th place with 0.5716 of weighted F1 score.", "labels": [], "entities": [{"text": "Social Media dataset", "start_pos": 7, "end_pos": 27, "type": "DATASET", "confidence": 0.8656783302625021}, {"text": "F1 score", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9726880192756653}]}, {"text": "This paper is organized as follows: the section 2 shows the state of-the-art, section 3 describes the methodology and the COLING'18 TRAC-1 dataset used, section 4 shows the results and finally the section 5 conclude our paper.", "labels": [], "entities": [{"text": "COLING'18 TRAC-1 dataset", "start_pos": 122, "end_pos": 146, "type": "DATASET", "confidence": 0.6400669515132904}]}], "datasetContent": [{"text": "The TRAC-1 dataset () has been used in order to train our systems.", "labels": [], "entities": [{"text": "TRAC-1 dataset", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.7673153281211853}]}, {"text": "The available dataset is composed of samples with a variable class distribution according to the task.", "labels": [], "entities": []}, {"text": "It is divided into two subsets: a training set and a development set.", "labels": [], "entities": []}, {"text": "The training set contains 12014 instances.", "labels": [], "entities": []}, {"text": "4241 of them are labeled as Covertly Aggressive (CAG), 5055 of them are labeled as Non-aggressive (NAG), and 2708 of them are labeled as Overtly Aggressive (OAG).", "labels": [], "entities": []}, {"text": "The development dataset is constituted by 3003 samples.", "labels": [], "entities": []}, {"text": "1058 of them are labeled as CAG, 1233 of them are labeled as NAG and 711 of them are labeled as OAG.", "labels": [], "entities": []}, {"text": "See that there is a class imbalance mainly affecting the distribution of the OAG class.", "labels": [], "entities": []}, {"text": "In the we show results (in terms of accuracy) of four approaches, i.e. Na\u00efve Bayes (NB), Perceptron, SVM and Passive-Aggressive (PA), in identifying independently each of the three levels of aggression (OAG, CAG, NAG) in a OVR fashion.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.999010443687439}, {"text": "Na\u00efve Bayes (NB)", "start_pos": 71, "end_pos": 87, "type": "METRIC", "confidence": 0.8569549798965455}]}, {"text": "To model the input vector space of these algorithms we used two baseline representation methods, i.e. Hashing (Bag of Words, BoW) and TF-IDF, and one state-of-the-art word embedding-based method, i.e. WISSE.", "labels": [], "entities": [{"text": "WISSE", "start_pos": 201, "end_pos": 206, "type": "DATASET", "confidence": 0.9181416034698486}]}, {"text": "One of the main things we observed during the exploratory stage was how the amount of training samples influenced the accuracy of the classifiers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.9988208413124084}]}, {"text": "Therefore we plotted the accuracy as a function of the amount of training samples (from the whole training set).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9996961355209351}]}, {"text": "The accuracy was measured on the development dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9996008276939392}, {"text": "development dataset", "start_pos": 33, "end_pos": 52, "type": "DATASET", "confidence": 0.6848134994506836}]}, {"text": "The results show that NB, PA and SVM classifiers perform in similar ways.", "labels": [], "entities": [{"text": "PA", "start_pos": 26, "end_pos": 28, "type": "METRIC", "confidence": 0.9271578192710876}, {"text": "SVM classifiers", "start_pos": 33, "end_pos": 48, "type": "TASK", "confidence": 0.630762368440628}]}, {"text": "However, the Perceptron showed to be a bit unstable and performed the worst.", "labels": [], "entities": [{"text": "Perceptron", "start_pos": 13, "end_pos": 23, "type": "DATASET", "confidence": 0.8166664242744446}]}, {"text": "In most cases, the classifiers attained relatively stable performance after 5000 training samples.", "labels": [], "entities": []}, {"text": "In this sense, with respect to NAG and CAG, identifying OAG aggressions represented much less complexity as a classification problem (2000 \u2212 3000 TF-IDFtransformed samples were required by classifiers to stabilize their performance).", "labels": [], "entities": []}, {"text": "On the other hand, identifying CAG resulted in a much more complex task for the classifiers.", "labels": [], "entities": [{"text": "identifying CAG", "start_pos": 19, "end_pos": 34, "type": "TASK", "confidence": 0.8727997243404388}]}, {"text": "Perceptron was again the worst while Na\u00efve Bayes and linear SVM performed better, but barely surpassed 65% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.9970870614051819}]}, {"text": "Detecting NAG aggressions required much more samples to allow the classifiers to be relatively stable.", "labels": [], "entities": [{"text": "Detecting NAG aggressions", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8427092432975769}]}, {"text": "Furthermore, it was hard for the classifiers to reach 73 \u2212 74% of accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9971975088119507}]}, {"text": "Overall TF-IDF representations allowed the classifiers to be much more stable than Hashing did.", "labels": [], "entities": []}, {"text": "Two additional experiments were conducted for exploring baseline representations on CAG detection in more detail.", "labels": [], "entities": [{"text": "CAG detection", "start_pos": 84, "end_pos": 97, "type": "TASK", "confidence": 0.9484050869941711}]}, {"text": "First, we used Singular Value Decomposition (SVD) for dimensionality reduction on the word-based TF-IDF representations of the posts.", "labels": [], "entities": []}, {"text": "Although a number of dimensionalities were tested (50, 100, 200, 300, 400), this modification neither showed improvements with respect to sparse TF-IDF representations.", "labels": [], "entities": []}, {"text": "Nonetheless, training time increased considerably as the implementations are better prepared for sparse presentations.", "labels": [], "entities": []}, {"text": "Secondly, we segmented documents into character n-grams before represent them by means of TF-IDF.", "labels": [], "entities": []}, {"text": "Surprisingly the classification accuracy was much better (+10%) in general.", "labels": [], "entities": [{"text": "classification", "start_pos": 17, "end_pos": 31, "type": "TASK", "confidence": 0.8882284760475159}, {"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9891582727432251}]}, {"text": "This time, the Passive-Aggressive and linear SVM classifiers attained about 70% of accuracy in CAG identification by segmenting the input posts into a range of character-based n-grams.", "labels": [], "entities": [{"text": "SVM classifiers", "start_pos": 45, "end_pos": 60, "type": "TASK", "confidence": 0.8271995186805725}, {"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9994298815727234}, {"text": "CAG identification", "start_pos": 95, "end_pos": 113, "type": "TASK", "confidence": 0.9668644666671753}]}, {"text": "To observe this performance, more than 9000 samples were needed (See).", "labels": [], "entities": []}, {"text": "Other n-gram ranges did not perform better (e.g. 2 \u2212 5, 3 \u2212 5, 1 \u2212 6, 2 \u2212 6, etc.).", "labels": [], "entities": []}, {"text": "We also used word embedding-based representations to represent the posts as sentence embeddings.", "labels": [], "entities": []}, {"text": "Even when these embeddings showed state-of-the-art performance in STS, their performance in Aggression Identification was not better than the baseline methods presented above (see.", "labels": [], "entities": [{"text": "Aggression Identification", "start_pos": 92, "end_pos": 117, "type": "TASK", "confidence": 0.7162779867649078}]}, {"text": "The behavior of classifiers with sentence embeddings showed much more unstable and the performance diminished by 5% in general with respect to the character-based TF-IDF sparse representations.", "labels": [], "entities": []}, {"text": "Although the sparse representations are high dimensional (thousands of dimensions), 5% or less of their entries are nonzero.", "labels": [], "entities": []}, {"text": "Most state-of-the-art implementations of the classifiers are prepared to deal efficiently with this  issue.", "labels": [], "entities": []}, {"text": "Therefore, the classifier ends by learning from 100 or less nonzero entries by sample.", "labels": [], "entities": []}, {"text": "Conversely, sentence embeddings based on word embeddings are dense representations of 300 dimensions, which adds complexity to the learning problem (varying dimensions of the embeddings did not offered improvements and the learning instability held).", "labels": [], "entities": []}, {"text": "Furthermore, the original purpose of sentence embeddings is to represent an approximation of each word semantics, and then of the whole sentence semantics.", "labels": [], "entities": []}, {"text": "This may result in much more complex patterns represented by sentence embeddings than what is needed for aggression identification.", "labels": [], "entities": [{"text": "aggression identification", "start_pos": 105, "end_pos": 130, "type": "TASK", "confidence": 0.7547531723976135}]}, {"text": "This additional complexity in their input space can lead to over-fitting of the classifiers.", "labels": [], "entities": []}, {"text": "The Aggression Identification competition required participants to apply their systems on a test dataset.", "labels": [], "entities": [{"text": "Aggression Identification", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.7517136037349701}]}, {"text": "This dataset consists of two files.", "labels": [], "entities": []}, {"text": "The first one having a class distribution similar to the training set, and the second one with a so-called \"surprise\" configuration.", "labels": [], "entities": []}, {"text": "Three runs were conducted on the TRAC-1 test dataset, that was splitted into two files: Facebook and Social Media.", "labels": [], "entities": [{"text": "TRAC-1 test dataset", "start_pos": 33, "end_pos": 52, "type": "DATASET", "confidence": 0.9519197146097819}]}, {"text": "There are 916 samples on the Facebook set, and 1257 samples on the Social Media set (.", "labels": [], "entities": [{"text": "Facebook set", "start_pos": 29, "end_pos": 41, "type": "DATASET", "confidence": 0.8964356184005737}, {"text": "Social Media set", "start_pos": 67, "end_pos": 83, "type": "DATASET", "confidence": 0.8860023220380148}]}, {"text": "During the exploratory stage we selected the two classifiers that performed the best inmost experiments conducted, i.e. the Passive-Aggressive (PA) and the SVM classifiers.", "labels": [], "entities": []}, {"text": "Therefore, our run 1 was executed by using a PA classifier whose hyperparameters were the best ones found via 3-fold cross-validation on the training dataset; the run 2 was executed by a SVM classifier whose hyperparameters were the best ones found with same method than for PA.", "labels": [], "entities": []}, {"text": "And the run 3 was the fusion of both coupled with a probabilistic distribution of the classes.", "labels": [], "entities": []}, {"text": "The PA and SVM implementations we used are the provided ones by) (for the SVM we used the SGD version, Stochastic Gradient Descent).", "labels": [], "entities": []}, {"text": "Furthermore, we selected the vector representation that best performed during the exploration stage, i.e. character based n-gram TF-IDF sparse representations with n \u2208 {1, 5}.", "labels": [], "entities": []}, {"text": "Because their low performance during the exploratory stage, we decided do not use the word embedding-based representations during the competition stage.", "labels": [], "entities": []}, {"text": "shows our rank position on the English Facebook (2nd place) and Social Media (4th place) tasks respectively.", "labels": [], "entities": [{"text": "English Facebook", "start_pos": 31, "end_pos": 47, "type": "DATASET", "confidence": 0.8139120638370514}]}, {"text": "The: Results for the English (Social Media) task.", "labels": [], "entities": [{"text": "English (Social Media) task", "start_pos": 21, "end_pos": 48, "type": "TASK", "confidence": 0.5390856266021729}]}, {"text": "Our model EBSI-LIA-UNAM (ELU) is placed in 4th rank.", "labels": [], "entities": [{"text": "EBSI-LIA-UNAM (ELU)", "start_pos": 10, "end_pos": 29, "type": "DATASET", "confidence": 0.8553071320056915}]}, {"text": "data, shows that the OAG and CAG classes are the most difficult to classify (with 52% error rate for OAG, 53% error rate for CAG).", "labels": [], "entities": [{"text": "OAG", "start_pos": 21, "end_pos": 24, "type": "DATASET", "confidence": 0.7227639555931091}, {"text": "error rate", "start_pos": 86, "end_pos": 96, "type": "METRIC", "confidence": 0.9758444130420685}]}, {"text": "For the Social Media file, the CAG and OAG classes were the most difficult to categorize (with 53% error rate for OAG, 64% error rate for CAG).", "labels": [], "entities": [{"text": "Social Media file", "start_pos": 8, "end_pos": 25, "type": "DATASET", "confidence": 0.8494005004564921}, {"text": "error rate", "start_pos": 99, "end_pos": 109, "type": "METRIC", "confidence": 0.9743678867816925}]}, {"text": "In both sets, the NAG class was detected correctly (33% and 11% error rate).", "labels": [], "entities": [{"text": "error rate", "start_pos": 64, "end_pos": 74, "type": "METRIC", "confidence": 0.9606011509895325}]}], "tableCaptions": [{"text": " Table 1: Results for the English (Facebook) task. Our model EBSI-LIA-UNAM (ELU) is placed in 2nd  rank.", "labels": [], "entities": [{"text": "EBSI-LIA-UNAM (ELU)", "start_pos": 61, "end_pos": 80, "type": "DATASET", "confidence": 0.8139324635267258}]}, {"text": " Table 2: Results for the English (Social Media) task. Our model EBSI-LIA-UNAM (ELU) is placed in  4th rank.", "labels": [], "entities": [{"text": "English (Social Media) task", "start_pos": 26, "end_pos": 53, "type": "TASK", "confidence": 0.616850326458613}, {"text": "EBSI-LIA-UNAM (ELU)", "start_pos": 65, "end_pos": 84, "type": "DATASET", "confidence": 0.8237219154834747}]}]}