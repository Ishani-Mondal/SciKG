{"title": [{"text": "Using Rhetorical Topics for Automatic Summarization", "labels": [], "entities": [{"text": "Summarization", "start_pos": 38, "end_pos": 51, "type": "TASK", "confidence": 0.8309611082077026}]}], "abstractContent": [{"text": "Summarization involves finding the most important information in a text in order to convey the meaning of the document.", "labels": [], "entities": [{"text": "Summarization", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.976058840751648}]}, {"text": "In this paper, I present a method for using topic information to influence which content is selected fora summary.", "labels": [], "entities": []}, {"text": "Texts are divided into topics using rhetorical information that creates a partition of a text into a sequence of non-overlapping topics.", "labels": [], "entities": []}, {"text": "To investigate the effect of this topic structure, I compare the output of summarizing an entire text without topics to summarizing individual topics and combining them into a complete summary.", "labels": [], "entities": [{"text": "summarizing an entire text without topics", "start_pos": 75, "end_pos": 116, "type": "TASK", "confidence": 0.812083383401235}]}, {"text": "The results show that the use of these rhetorical topics improves summarization performance compared to a summarization system that incorporates no topic information, demonstrating the utility of topic structure and rhetorical information for automatic summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 66, "end_pos": 79, "type": "TASK", "confidence": 0.9884045124053955}, {"text": "summarization", "start_pos": 253, "end_pos": 266, "type": "TASK", "confidence": 0.8818768858909607}]}], "introductionContent": [{"text": "Summarization is the task of creating a shortened version of an input document that retains the important information from the original text but in a more concise form.", "labels": [], "entities": [{"text": "Summarization", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.9801211357116699}]}, {"text": "The goal of summarization is to convey the main concepts of the original document so that a summary user can understand what the document is about without reading the entire text.", "labels": [], "entities": [{"text": "summarization", "start_pos": 12, "end_pos": 25, "type": "TASK", "confidence": 0.989355742931366}]}, {"text": "With large amounts of text available online, it has become increasingly necessary to find ways to allow people to quickly and easily find the information they need.", "labels": [], "entities": []}, {"text": "Summarization is useful for this task because it condenses information into a shorter form that can be read instead of a longer text if it provides all the information a user needs or it can be read in order to determine whether the original text contains information relevant to the user's needs, allowing the user to decide which texts would be most useful.", "labels": [], "entities": [{"text": "Summarization", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.9417675733566284}]}, {"text": "In order for summaries to achieve this goal, they must convey the important concepts from the text without including unnecessary information.", "labels": [], "entities": [{"text": "summaries", "start_pos": 13, "end_pos": 22, "type": "TASK", "confidence": 0.9628618955612183}]}, {"text": "Most summarization systems perform extractive summarization, which involves creating a summary by extracting complete sentences from the original document (.", "labels": [], "entities": [{"text": "summarization", "start_pos": 5, "end_pos": 18, "type": "TASK", "confidence": 0.9624843001365662}]}, {"text": "The current research is also focused on extractive summarization.", "labels": [], "entities": [{"text": "extractive summarization", "start_pos": 40, "end_pos": 64, "type": "TASK", "confidence": 0.9275893270969391}]}, {"text": "Different representations of texts and text structure make different assumptions about how texts convey information and how summarization is performed.", "labels": [], "entities": [{"text": "summarization", "start_pos": 124, "end_pos": 137, "type": "TASK", "confidence": 0.9728843569755554}]}, {"text": "Much work on summarization does not assume anything about the structure of text.", "labels": [], "entities": [{"text": "summarization", "start_pos": 13, "end_pos": 26, "type": "TASK", "confidence": 0.9918164610862732}]}, {"text": "The work in this paper aims to demonstrate that attention to the linguistic structure of a text is useful in performing summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 120, "end_pos": 133, "type": "TASK", "confidence": 0.9903886914253235}]}, {"text": "The type of linguistic structure and textual organization explored in this work is the notion of topic.", "labels": [], "entities": []}, {"text": "In linguistics, there are different notions of what it means to be a topic).", "labels": [], "entities": []}, {"text": "Intuitively, texts are organized into topics or groups of sentences that are more related to each other than they are to sentences in other groups.", "labels": [], "entities": []}, {"text": "A summary should include coverage of all these topics.", "labels": [], "entities": [{"text": "coverage", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9509336352348328}]}, {"text": "One crucial factor that motivates grouping texts into topics for summarization has to do with summary length.", "labels": [], "entities": [{"text": "summarization", "start_pos": 65, "end_pos": 78, "type": "TASK", "confidence": 0.986579954624176}]}, {"text": "A summary is a condensed form of the original text.", "labels": [], "entities": []}, {"text": "One of the challenges of summarization is determining how to convey the same information as the original text in a more limited space.", "labels": [], "entities": [{"text": "summarization", "start_pos": 25, "end_pos": 38, "type": "TASK", "confidence": 0.9930921792984009}]}, {"text": "In order to convey the same information, there should bean emphasis on covering the text by including some amount of information about all of the important ideas and by limiting redundancy and indepth coverage of a particular topic in favor of wider coverage of all topics.", "labels": [], "entities": []}, {"text": "In order to see how useful topics are for summarization, topic information was incorporated into a summarization system.", "labels": [], "entities": [{"text": "summarization", "start_pos": 42, "end_pos": 55, "type": "TASK", "confidence": 0.9887690544128418}]}, {"text": "To compare the effects of using topics versus not using topics, summarization was either performed at the level of the whole text or at the level of individual topics.", "labels": [], "entities": [{"text": "summarization", "start_pos": 64, "end_pos": 77, "type": "TASK", "confidence": 0.9679421782493591}]}, {"text": "Specifically, the process for incorporating topics into summarization included the following steps: divide a text into topics, summarize the text of each topic, and concatenate the summaries of each topic to create a summary for the whole text.", "labels": [], "entities": [{"text": "summarization", "start_pos": 56, "end_pos": 69, "type": "TASK", "confidence": 0.9687961339950562}]}, {"text": "With this method, topics are treated as independent pieces of text that contribute to the overall meaning of the text, and each topic will be represented in the final summary.", "labels": [], "entities": []}, {"text": "This agrees with the intuition that texts can be divided into topics and a good summary should contain coverage of all topics that appear in the original text.", "labels": [], "entities": []}, {"text": "This is a straightforward way to see how topics affect summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 55, "end_pos": 68, "type": "TASK", "confidence": 0.9827885031700134}]}, {"text": "Section 2 describes how texts are separated into topics using rhetorical information.", "labels": [], "entities": []}, {"text": "Section 3 describes the techniques used for summarizing texts.", "labels": [], "entities": [{"text": "summarizing texts", "start_pos": 44, "end_pos": 61, "type": "TASK", "confidence": 0.9371615350246429}]}, {"text": "Section 4 presents the methods and results of the experiments that were performed.", "labels": [], "entities": []}, {"text": "Section 5 summarizes the findings and contributions of this work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Experiments were conducted to see how topic structure influences summarization performance.", "labels": [], "entities": [{"text": "summarization", "start_pos": 65, "end_pos": 78, "type": "TASK", "confidence": 0.9853159785270691}]}, {"text": "The first condition did not incorporate topic structure.", "labels": [], "entities": []}, {"text": "Entire texts were summarized using the summarizers described in the previous section.", "labels": [], "entities": []}, {"text": "The second condition used RST topics.", "labels": [], "entities": [{"text": "RST", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.7761383652687073}]}, {"text": "Texts were divided into topics as described above.", "labels": [], "entities": []}, {"text": "Each of the topics was summarized, and the outputs were combined to create a summary of the entire text.", "labels": [], "entities": []}, {"text": "The third condition used random topics.", "labels": [], "entities": []}, {"text": "Using the topic sizes from the RST topics, texts were randomly divided into topics of the same size.", "labels": [], "entities": [{"text": "RST topics", "start_pos": 31, "end_pos": 41, "type": "TASK", "confidence": 0.8414486944675446}]}, {"text": "This condition provided a control to see whether topic divisions informed by RST information resulted in better summaries than random divisions or whether simply dividing a text into smaller sections improves performance.", "labels": [], "entities": []}, {"text": "Summary evaluation is a difficult task.", "labels": [], "entities": [{"text": "Summary evaluation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9226616621017456}]}, {"text": "There can be more than one good summary of a text, and when people are instructed to create summaries, they do not necessarily contain the same sentences.", "labels": [], "entities": []}, {"text": "Since there is no single correct answer for what a summary should contain, evaluation typically involves comparing a system-produced summary to a manually-created reference summary.", "labels": [], "entities": []}, {"text": "Summary quality is based on some measure of similarity or overlap with a reference summary.", "labels": [], "entities": []}, {"text": "ROUGE) is a measure to evaluate performance on the task of automatic summarization.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9712439775466919}]}, {"text": "ROUGE is a standard measure used in the field of summarization (.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9718634486198425}, {"text": "summarization", "start_pos": 49, "end_pos": 62, "type": "TASK", "confidence": 0.9722427725791931}]}, {"text": "RecallOriented Understudy for Gisting Evaluation involves comparing a summary produced by a summarization system to reference or gold-standard summaries created by humans.", "labels": [], "entities": [{"text": "Gisting Evaluation", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.9216686189174652}]}, {"text": "Specifically, ROUGE-N measures n-gram) recall between a system summary and a reference summary.", "labels": [], "entities": [{"text": "ROUGE-N", "start_pos": 14, "end_pos": 21, "type": "METRIC", "confidence": 0.9947150349617004}, {"text": "recall", "start_pos": 39, "end_pos": 45, "type": "METRIC", "confidence": 0.9798955917358398}]}, {"text": "Recall refers to how many of the reference n-grams were included in the system summary.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9549196362495422}]}, {"text": "The equation for ROUGE-N is presented below.", "labels": [], "entities": [{"text": "ROUGE-N", "start_pos": 17, "end_pos": 24, "type": "METRIC", "confidence": 0.9866226315498352}]}, {"text": "In this equation, \u00ed \u00b5\u00ed\u00b1\u009b refers to the size of the n-gram, such as unigram (1) or bigram (2).", "labels": [], "entities": [{"text": "\u00ed \u00b5\u00ed\u00b1\u009b", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.8831137220064799}]}, {"text": "An n-gram itself is represented by \u00ed \u00b5\u00ed\u00b1\u0094\u00ed \u00b5\u00ed\u00b1\u009f\u00ed \u00b5\u00ed\u00b1\u008e\u00ed \u00b5\u00ed\u00b1\u009a $ , and \u00ed \u00b5\u00ed\u00b0 \u00b6\u00ed \u00b5\u00ed\u00b1\u009c\u00ed \u00b5\u00ed\u00b1\u00a2\u00ed \u00b5\u00ed\u00b1\u009b\u00ed \u00b5\u00ed\u00b1\u00a1 /.%FG (\u00ed \u00b5\u00ed\u00b1\u0094\u00ed \u00b5\u00ed\u00b1\u009f\u00ed \u00b5\u00ed\u00b1\u008e\u00ed \u00b5\u00ed\u00b1\u009a $ ) refers to the number of times that the n-gram \u00ed \u00b5\u00ed\u00b1\u0094\u00ed \u00b5\u00ed\u00b1\u009f\u00ed \u00b5\u00ed\u00b1\u008e\u00ed \u00b5\u00ed\u00b1\u009a $ appears in the system summary.", "labels": [], "entities": [{"text": "FG", "start_pos": 103, "end_pos": 105, "type": "METRIC", "confidence": 0.9950646758079529}]}, {"text": "Therefore, the numerator is the number of matching n-grams, and the denominator is the total number of n-grams in the reference summaries.", "labels": [], "entities": []}, {"text": "One downside of ROUGE is that it is entirely recall-based.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 16, "end_pos": 21, "type": "METRIC", "confidence": 0.9354914426803589}, {"text": "recall-based", "start_pos": 45, "end_pos": 57, "type": "METRIC", "confidence": 0.9878645539283752}]}, {"text": "In general, a summary will be rewarded for including more n-grams without being penalized for containing n-grams that do not appear in the reference summary.", "labels": [], "entities": []}, {"text": "In the extreme case, a summary that is the same length as the original text being summarized could achieve perfect recall even though such a summary would clearly not be considered a good summary, since the goal of summarization is to produce a shortened version of the input.", "labels": [], "entities": [{"text": "recall", "start_pos": 115, "end_pos": 121, "type": "METRIC", "confidence": 0.9980559349060059}, {"text": "summarization", "start_pos": 215, "end_pos": 228, "type": "TASK", "confidence": 0.9708741307258606}]}, {"text": "In order to avoid this problem, summary length must be controlled.", "labels": [], "entities": [{"text": "length", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.4864288866519928}]}, {"text": "Specifically, since ROUGE-N is a word-based evaluation measure, the summary length in terms of word count must be controlled so that system-produced summaries are similar in length to the reference summaries.", "labels": [], "entities": [{"text": "ROUGE-N", "start_pos": 20, "end_pos": 27, "type": "METRIC", "confidence": 0.9160593152046204}]}, {"text": "Unit overlap is another evaluation measure for summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 47, "end_pos": 60, "type": "TASK", "confidence": 0.9900807738304138}]}, {"text": "It finds the similarity between two texts by looking at the number of words they have in common compared to the number of non-overlapping words they contain.", "labels": [], "entities": []}, {"text": "\u00ed \u00b5\u00ed\u00b1\u008b and \u00ed \u00b5\u00ed\u00b1\u008c are the words in the documents being compared.", "labels": [], "entities": [{"text": "\u00ed \u00b5\u00ed\u00b1\u008b", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.6757545073827108}]}, {"text": "In contrast to ROUGE, unit overlap penalizes an evaluated text for containing words that do not appear in the gold-standard text.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 15, "end_pos": 20, "type": "METRIC", "confidence": 0.9506439566612244}]}, {"text": "A summary will not be rewarded simply for being longer.", "labels": [], "entities": [{"text": "summary", "start_pos": 2, "end_pos": 9, "type": "METRIC", "confidence": 0.9003550410270691}]}, {"text": "The final evaluation measure used is cosine similarity.", "labels": [], "entities": []}, {"text": "It is a measure of similarity between documents using vectors of word frequency.", "labels": [], "entities": []}, {"text": "Similar to unit overlap, cosine similarity takes document length into account and prevents texts from being rewarded for being longer.", "labels": [], "entities": []}, {"text": "To evaluate the summaries, each system-produced summary is evaluated against each of the two corresponding gold-standard summaries.", "labels": [], "entities": []}, {"text": "Scores are calculated for each document, and the scores from all documents in the corpus are averaged to produce an overall value for each measure.", "labels": [], "entities": []}, {"text": "shows the results of using three different summarizers to summarize texts with and without topics.", "labels": [], "entities": []}, {"text": "These are the results when a summarization percentage of 20% was used.", "labels": [], "entities": []}, {"text": "Each pair of columns shows the result of a different summarizer.", "labels": [], "entities": []}, {"text": "The first column in each pair shows the results without using topics, and the second shows the results of using RST topics.", "labels": [], "entities": [{"text": "RST topics", "start_pos": 112, "end_pos": 122, "type": "TASK", "confidence": 0.7778831422328949}]}, {"text": "The highest value for each measure is in bold.", "labels": [], "entities": []}, {"text": "Looking at the results shows several interesting effects.", "labels": [], "entities": []}, {"text": "For each measure, the highest value is achieved when using topics.", "labels": [], "entities": []}, {"text": "The highest ROUGE values are found with TextRank, and the highest values for unit overlap and cosine similarity are found with LexRank.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 12, "end_pos": 17, "type": "METRIC", "confidence": 0.9963797926902771}, {"text": "TextRank", "start_pos": 40, "end_pos": 48, "type": "DATASET", "confidence": 0.9745720028877258}, {"text": "unit overlap", "start_pos": 77, "end_pos": 89, "type": "METRIC", "confidence": 0.7627453207969666}, {"text": "LexRank", "start_pos": 127, "end_pos": 134, "type": "DATASET", "confidence": 0.989891529083252}]}, {"text": "In these cases, using topics results in improvements in performance of around 5%.", "labels": [], "entities": []}, {"text": "While different summarizers perform slightly better on different measures, in this paper I am interested in the fact that regardless of evaluation measure or summarizer, the inclusion of topics improves performance.", "labels": [], "entities": []}, {"text": "[During the next decade, Mr. Kume said, Nissan plans to boost overseas vehicle production sufficiently to account fora majority of sales outside Japan.", "labels": [], "entities": []}, {"text": "Last year, Mr. Kume said, Nissan exported slightly over one million vehicles, and produced 570,000 cars and trucks at its factories in North America, Europe and Australia.", "labels": [], "entities": []}, {"text": "But by 1992, he added, Nissan will build one million vehicles a year outside Japan, or sufficient to equal exports.", "labels": [], "entities": []}, {"text": "\"By the end of the 1990s,\" he said, \"we want to be producing roughly two vehicles overseas for every vehicle that we export from Japan.\"", "labels": [], "entities": []}, {"text": "That will involve a substantial increase in overseas manufacturing capacity, he acknowledged, but didn't provide specific details.]", "labels": [], "entities": []}, {"text": "Topic 2 Summary without Topics: But by 1992, he added, Nissan will build one million vehicles a year outside Japan, or sufficient to equal exports.", "labels": [], "entities": []}, {"text": "\"By the end of the 1990s,\" he said, \"we want to be producing roughly two vehicles overseas for every vehicle that we export from Japan.\"", "labels": [], "entities": []}, {"text": "Summary with RST Topics: Nissan Motor Co. expects net income to reach 120 billion yen (U.S. $857 million) in its current fiscal year, up from 114.6 billion yen in the previous year, Yutaka Kume, president, said.", "labels": [], "entities": [{"text": "RST", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.6223254203796387}, {"text": "Nissan Motor Co.", "start_pos": 25, "end_pos": 41, "type": "DATASET", "confidence": 0.9161634047826132}]}, {"text": "During the next decade, Mr. Kume said, Nissan plans to boost overseas vehicle production sufficiently to account fora majority of sales outside Japan.", "labels": [], "entities": []}, {"text": "On the other hand, there are smaller increases for the other measures.", "labels": [], "entities": []}, {"text": "ROUGE has such large and consistent increases because it is recall-based, so longer summaries will always perform better.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9449485540390015}, {"text": "recall-based", "start_pos": 60, "end_pos": 72, "type": "METRIC", "confidence": 0.9962053894996643}]}, {"text": "This issue will be discussed further below.", "labels": [], "entities": []}, {"text": "The results show that topics create more of an improvement in performance when the percentage is lower and the summaries are smaller, suggesting that topics do provide useful information for summarization, and that information is the most useful when space is the most limited.", "labels": [], "entities": [{"text": "summarization", "start_pos": 191, "end_pos": 204, "type": "TASK", "confidence": 0.978729784488678}]}, {"text": "provides an example text along with the summaries produced when no topics are used and when RST topics are used.", "labels": [], "entities": [{"text": "RST topics", "start_pos": 92, "end_pos": 102, "type": "TASK", "confidence": 0.8563094735145569}]}, {"text": "When no topic structure is used, all sentences in the summary come from one topic, showing how topic structure is needed to ensure coverage of all ideas in the text.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Linear Regression Results for LexRank", "labels": [], "entities": [{"text": "LexRank", "start_pos": 40, "end_pos": 47, "type": "DATASET", "confidence": 0.9419590830802917}]}, {"text": " Table 3: Results when using LSA topics compared to no  topics and RST topics; Mean = mean of LSA runs", "labels": [], "entities": [{"text": "RST", "start_pos": 67, "end_pos": 70, "type": "METRIC", "confidence": 0.5849941968917847}, {"text": "Mean", "start_pos": 79, "end_pos": 83, "type": "METRIC", "confidence": 0.992510199546814}]}]}