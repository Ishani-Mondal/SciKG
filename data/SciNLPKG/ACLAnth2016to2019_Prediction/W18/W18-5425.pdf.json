{"title": [{"text": "Closing Brackets with Recurrent Neural Networks", "labels": [], "entities": []}], "abstractContent": [{"text": "Many natural and formal languages contain words or symbols that require a matching counterpart for making an expression well-formed.", "labels": [], "entities": []}, {"text": "The combination of opening and closing brackets is atypical example of such a construction.", "labels": [], "entities": []}, {"text": "Due to their commonness, the ability to follow such rules is important for language modeling.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 75, "end_pos": 92, "type": "TASK", "confidence": 0.7613644599914551}]}, {"text": "Currently, recurrent neu-ral networks (RNNs) are extensively used for this task.", "labels": [], "entities": []}, {"text": "We investigate whether they are capable of learning the rules of opening and closing brackets by applying them to synthetic Dyck languages that consist of different types of brackets.", "labels": [], "entities": []}, {"text": "We provide an analysis of the statistical properties of these languages as a baseline and show strengths and limits of Elman-RNNs, GRUs and LSTMs in experiments on random samples of these languages.", "labels": [], "entities": []}, {"text": "In terms of perplexity and prediction accuracy, the RNNs get close to the theoretical baseline inmost cases.", "labels": [], "entities": [{"text": "prediction", "start_pos": 27, "end_pos": 37, "type": "TASK", "confidence": 0.8603993654251099}, {"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9716550707817078}]}], "introductionContent": [{"text": "Brackets area challenge for language models.", "labels": [], "entities": []}, {"text": "They regularly appear in texts, they typically produce long-range dependencies, and a failure to properly close them is readily recognized by a human evaluator as a severe error.", "labels": [], "entities": []}, {"text": "Beyond the syntactical level, many natural languages exhibit brackets-like structures.", "labels": [], "entities": []}, {"text": "For example, the German language is infamous for its convoluted sentences with verb-particle constructions, in which words from the beginning have to be properly closed at the end.", "labels": [], "entities": []}, {"text": "In this paper we present a dedicated study of the capability of Elman-RNNs, GRUs and LSTMs to model expressions with brackets and properly * Both authors contributed equally.", "labels": [], "entities": []}, {"text": "Towards this end, we conduct experiments on Dyck languages, which consist of balanced bracket expressions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Baseline respectively mean test perplex- ity PP n for T BPTT settings between 1 and 16 in  steps of 1 for different architectures (cf.", "labels": [], "entities": []}, {"text": " Table 2: Accuracy for the task of finding the last  bracket of a Dyck word, together with measured  values for the average length \u00af  L of the words and  the average length of the task \u00af  (see the text for a  definition).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9966525435447693}, {"text": "finding the last  bracket of a Dyck word", "start_pos": 35, "end_pos": 75, "type": "TASK", "confidence": 0.6622098721563816}]}]}