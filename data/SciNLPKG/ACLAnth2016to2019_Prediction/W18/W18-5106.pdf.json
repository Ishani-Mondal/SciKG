{"title": [{"text": "Aggression Detection on Social Media Text Using Deep Neural Networks", "labels": [], "entities": [{"text": "Aggression Detection", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.93934565782547}]}], "abstractContent": [{"text": "In the past few years, bully and aggressive posts on social media have grown significantly , causing serious consequences for vic-tims/users of all demographics.", "labels": [], "entities": []}, {"text": "Majority of the work in this field has been done for En-glish only.", "labels": [], "entities": []}, {"text": "In this paper, we introduce a deep learning based classification system for Face-book posts and comments of Hindi-English Code-Mixed text to detect the aggressive behaviour of/towards users.", "labels": [], "entities": []}, {"text": "Our work focuses on text from users majorly in the Indian Subcon-tinent.", "labels": [], "entities": []}, {"text": "The dataset that we used for our models is provided by TRAC-1 1 in their shared task.", "labels": [], "entities": [{"text": "TRAC-1 1", "start_pos": 55, "end_pos": 63, "type": "DATASET", "confidence": 0.7638885974884033}]}, {"text": "Our classification model assigns each Facebook post/comment to one of the three predefined categories: \"Overtly Aggressive\", \"Covertly Aggressive\" and \"Non-Aggressive\".", "labels": [], "entities": []}, {"text": "We experimented with 6 classification models and our CNN model on a 10 K-fold cross-validation gave the best result with the prediction accuracy of 73.2%.", "labels": [], "entities": [{"text": "prediction", "start_pos": 125, "end_pos": 135, "type": "METRIC", "confidence": 0.96299147605896}, {"text": "accuracy", "start_pos": 136, "end_pos": 144, "type": "METRIC", "confidence": 0.5736873745918274}]}], "introductionContent": [{"text": "It is observed that multilingual speakers often switchback and forth between languages when speaking or writing, mostly in informal settings.", "labels": [], "entities": []}, {"text": "This language interchange involves complexing grammar, and the terms \"code-switching\" and \"code-mixing\" are used to describe it.", "labels": [], "entities": []}, {"text": "Code-mixing refers to the use of linguistic units from different languages in a single utterance or sentence, whereas code-switching refers to the co-occurrence of speech extracts belonging to two different grammatical systems.", "labels": [], "entities": []}, {"text": "As both phenomena are frequently observed on social media platforms in similar contexts, we have considered the Code-Mixing scenario for our work.", "labels": [], "entities": []}, {"text": "Following is an instance from the dataset used: T1 : \"Post tabah krne se kuch nhi hoga 2 k badale 200 ko maro\" Translation: \"No point in destroying the Post, kill 200 in return for your 2 dead.\"", "labels": [], "entities": [{"text": "T1", "start_pos": 48, "end_pos": 50, "type": "METRIC", "confidence": 0.8130384683609009}]}, {"text": "Due to the massive rise of user-generated web content, in particular on social media networks, the amount of hate, aggressive, bully text is also steadily increasing.", "labels": [], "entities": []}, {"text": "It has been estimated that there has been an increase of approximately 25% in the number of tweets per minutes and 22% increase in the number of Facebook posts per minute in the last 3 years.", "labels": [], "entities": []}, {"text": "It is estimated that approximately 500 million tweets are sent per day, 4.3 billion Facebook messages are posted and more than 200 million emails are sent each day, and approximately 2 million new blog posts are created daily over the web 2 . Over the past years, interest in online hate/aggression/bullying detection and particularly the automatization of this task has continuously grown, along with the societal impact of the phenomenon.", "labels": [], "entities": [{"text": "hate/aggression/bullying detection", "start_pos": 283, "end_pos": 317, "type": "TASK", "confidence": 0.6334206412235895}]}, {"text": "Natural language processing methods focusing specifically on this phenomenon are required since basic word filters do not provide a sufficient remedy.", "labels": [], "entities": [{"text": "Natural language processing", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6017247041066488}]}, {"text": "What is considered as an aggressive text might be influenced by aspects such as the domain of an utterance, its discourse context, as well as context consisting of co-occurring media objects (e.g. images, videos, audio), the exact time of posting and world events at this moment, identity of author and targeted recipient.", "labels": [], "entities": []}, {"text": "Hence, we can say that aggression and bullying by/against an individual can be performed in several ways beyond just using obvious abusive language) () -e.g., via constant sarcasm, trolling, etc.", "labels": [], "entities": []}, {"text": "This can have deep effects on one's mental as well as social health and status.", "labels": [], "entities": []}, {"text": "The structure of this paper is as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we review related research in the area of hate/aggression/bullying detection in social media texts.", "labels": [], "entities": [{"text": "hate/aggression/bullying detection in social media texts", "start_pos": 56, "end_pos": 112, "type": "TASK", "confidence": 0.6857562601566315}]}, {"text": "In Section 3, we describe the process of dataset creation which is a work of (.", "labels": [], "entities": [{"text": "dataset creation", "start_pos": 41, "end_pos": 57, "type": "TASK", "confidence": 0.7109521776437759}]}, {"text": "In Section 4, we discuss the pre-processing and data statistics.", "labels": [], "entities": []}, {"text": "In Section 5, we summarize our classification systems and the construction of the feature vectors.", "labels": [], "entities": []}, {"text": "In Section 6, we present the results of experiments conducted using various features and classification models along with CNN.", "labels": [], "entities": [{"text": "CNN", "start_pos": 122, "end_pos": 125, "type": "DATASET", "confidence": 0.966772198677063}]}, {"text": "In the last section, we conclude our paper, followed by future work and references.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used the Hindi-English code-mixed dataset () published as a shared task for 1 st Workshop on Trolling, aggression and Cyberbullying (TRAC-1) . The data was crawled from public Facebook Pages and Twitter.", "labels": [], "entities": [{"text": "Hindi-English code-mixed dataset", "start_pos": 12, "end_pos": 44, "type": "DATASET", "confidence": 0.5756873190402985}, {"text": "Trolling, aggression and Cyberbullying (TRAC-1)", "start_pos": 96, "end_pos": 143, "type": "TASK", "confidence": 0.5939142107963562}]}, {"text": "The data was mainly collected from the pages/issues that are expected to be discussed more among the Indians (and in Hindi) for the reason of the presence of Code-Mixed text.", "labels": [], "entities": []}, {"text": "While collecting data from Facebook more than 40 pages were identified and crawled.", "labels": [], "entities": []}, {"text": "It included pages of the below-mentioned types: \u2022 News websites/organizations like NDTV, ABP News, Zee News, etc.", "labels": [], "entities": [{"text": "NDTV", "start_pos": 83, "end_pos": 87, "type": "DATASET", "confidence": 0.9333089590072632}, {"text": "ABP News", "start_pos": 89, "end_pos": 97, "type": "DATASET", "confidence": 0.8592504560947418}]}, {"text": "\u2022 Web-based forums/portals like Firstost, The Logical Indian, etc.", "labels": [], "entities": [{"text": "Firstost, The Logical Indian", "start_pos": 32, "end_pos": 60, "type": "DATASET", "confidence": 0.695224380493164}]}, {"text": "\u2022 Political Parties/groups like INC, BJP, etc.", "labels": [], "entities": []}, {"text": "\u2022 Students' organisations/groups like SFI, JNUSU, AISA, etc.", "labels": [], "entities": [{"text": "SFI", "start_pos": 38, "end_pos": 41, "type": "DATASET", "confidence": 0.6800370812416077}, {"text": "JNUSU", "start_pos": 43, "end_pos": 48, "type": "DATASET", "confidence": 0.7076778411865234}]}, {"text": "\u2022 Support and opposition groups built around incidents in last 2 years in Indian Universities of higher education like Rohith Vemula's suicide in HCU, February 9, 2016, incident in JNU, etc.", "labels": [], "entities": [{"text": "HCU", "start_pos": 146, "end_pos": 149, "type": "DATASET", "confidence": 0.8241757750511169}, {"text": "JNU", "start_pos": 181, "end_pos": 184, "type": "DATASET", "confidence": 0.8472155332565308}]}, {"text": "For Twitter, the data was collected using some of the popular hashtags around such contentious themes as \"beef ban\", \"India vs. Pakistan cricket match\", \"election results\", \"opinions on movies\", etc.", "labels": [], "entities": [{"text": "beef ban\"", "start_pos": 106, "end_pos": 115, "type": "TASK", "confidence": 0.7238985101381937}]}, {"text": "During collection, the data was not sampled on the basis of language and so it included data from English, Hindi as well as some other Indian languages.", "labels": [], "entities": []}, {"text": "In the later stages, the data belonging to other languages was removed leaving only Hindi, English and Hindi-English CodeMixed data.", "labels": [], "entities": []}, {"text": "The collected dataset was labelled into three classes naming: Covertly-Aggressive (CAG): It refers to texts which are an indirect attack against the victim and is often packaged as (insincere) polite expressions (through the use of conventionalized polite structures), In general, a lot of cases of satire, rhetorical questions, etc.", "labels": [], "entities": []}, {"text": "An example is given below -T2 : \"Harish Om kya anti-national ko bail mil sakti hai?", "labels": [], "entities": []}, {"text": "Translation: \"Harish Om can an anti-national get bail?\"", "labels": [], "entities": []}, {"text": "Overtly-Aggressive (OAG): This refers to the texts in which aggression is overtly expressed either through the use of specific kind of lexical items or lexical features which is considered aggressive and/or certain syntactic structures.", "labels": [], "entities": [{"text": "Overtly-Aggressive (OAG)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6218463405966759}]}, {"text": "An example is given below -T1 : \"Agar inke bas ki nahi hai toh Hume bhej do border\" Translation: \"If they can't handle it, then send us to border\" Non-Aggressive (NAG): It refers to texts which are not lying in the above two categories.", "labels": [], "entities": []}, {"text": "An example is given below -T1 : \"Waise bandhu jet lag se bachne ke liye Raat ko 10 baje ke baad so jao\" Translation: \"By the way brother, sleep after 10 o'clock at night to avoid jet lag\"  This section presents the experiments we performed with different combinations of features and models.", "labels": [], "entities": []}, {"text": "The models on which we ran experiments are: \u2022 Multimodal Naive Bayes \u2022 Decision Tree \u2022 Support Vector Machine (SVM) \u2022 Multi layer Perceptrons (MLPs) \u2022 Long-short Term Memory (LSTM) Networks \u2022 Convolutional Neural Networks (CNNs) For experiments on the first three models, we used only the text as features and used library feature extraction method which turns our text content into numerical features with bag-of-words strategy, ignoring the relative positions of words.", "labels": [], "entities": [{"text": "library feature extraction", "start_pos": 315, "end_pos": 341, "type": "TASK", "confidence": 0.6731460293134054}]}, {"text": "The classification report for these three models has been shown in, 6, 7 respectively with their accuracy as shown in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9995331764221191}]}, {"text": "The support for each tag during the experiments on our models shown in, 6 and 7 have the same numbers of data per tag which is shown in.", "labels": [], "entities": []}, {"text": "We then experimented with the three above mentioned neural networks and their classification report is shown in In order to determine the effect of each feature and parameter of different models, we performed several experiments with some and all feature at a time simultaneously changing the values of the parameters as well.", "labels": [], "entities": []}, {"text": "We arrived at the provided values of parameters and hyper-parameters after fine empirical tuning.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Average post length of different class text", "labels": [], "entities": [{"text": "Average post length", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.833918551603953}]}, {"text": " Table 4: Average word length in different class text", "labels": [], "entities": [{"text": "Average word length", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.7476924061775208}]}, {"text": " Table 5: Multi-modal Naive Bayes Model", "labels": [], "entities": [{"text": "Multi-modal Naive Bayes", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.6491149266560873}]}, {"text": " Table 6: Decision Tree Model", "labels": [], "entities": []}, {"text": " Table 7: SVM Model with L2 penalty", "labels": [], "entities": []}, {"text": " Table 11: Support Test instances for each Tags", "labels": [], "entities": [{"text": "Tags", "start_pos": 43, "end_pos": 47, "type": "TASK", "confidence": 0.6114218831062317}]}, {"text": " Table 12: Test Accuracy of different models", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9227091073989868}]}, {"text": " Table 13: Impact Of Each Feature Calculated By  Eliminating One at A Time for CNN Model.", "labels": [], "entities": [{"text": "CNN Model", "start_pos": 79, "end_pos": 88, "type": "DATASET", "confidence": 0.9625957608222961}]}]}