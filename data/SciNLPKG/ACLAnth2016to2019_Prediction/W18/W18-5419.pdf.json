{"title": [{"text": "Analysing the potential of seq-to-seq models for incremental interpretation in task-oriented dialogue", "labels": [], "entities": []}], "abstractContent": [{"text": "We investigate how encoder-decoder models trained on a synthetic dataset of task-oriented dialogues process disfluencies, such as hesitations and self-corrections.", "labels": [], "entities": []}, {"text": "We find that, contrary to earlier results, disfluencies have very little impact on the task success of seq-to-seq models with attention.", "labels": [], "entities": []}, {"text": "Using visualisations and diagnostic classifiers, we analyse the representations that are incrementally built by the model, and discover that models develop little to no awareness of the structure of disfluen-cies.", "labels": [], "entities": []}, {"text": "However, adding disfluencies to the data appears to help the model create clearer representations overall, as evidenced by the attention patterns the different models exhibit.", "labels": [], "entities": []}], "introductionContent": [{"text": "The use of Recurrent Neural Networks (RNNs) to tackle sequential language tasks has become standard in natural language processing, after impressive accomplishments in speech recognition, machine translation, and entailment (e.g.,.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 103, "end_pos": 130, "type": "TASK", "confidence": 0.6553669472535452}, {"text": "speech recognition", "start_pos": 168, "end_pos": 186, "type": "TASK", "confidence": 0.728580504655838}, {"text": "machine translation", "start_pos": 188, "end_pos": 207, "type": "TASK", "confidence": 0.8100249469280243}]}, {"text": "Recently, RNNs have also been exploited as tools to model dialogue systems.", "labels": [], "entities": []}, {"text": "Inspired by neural machine translation, researchers such as and pioneered an approach to opendomain chit-chat conversation based on sequenceto-sequence models.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 12, "end_pos": 38, "type": "TASK", "confidence": 0.8037315607070923}]}, {"text": "In this paper, we focus on task-oriented dialogue, where the conversation serves to fulfil an independent goal in a given domain.", "labels": [], "entities": []}, {"text": "Current neural dialogue models for task-oriented dialogue tend to equip systems with external memory components (, since key information needs to be stored for potentially longtime spans.", "labels": [], "entities": []}, {"text": "One of our goals here is to analyse to what extent sequence-to-sequence models without external memory can deal with this challenge.", "labels": [], "entities": []}, {"text": "In addition, we consider language realisations that include disfluencies common in dialogue interaction, such as repetitions and self-corrections (e.g., I'd like to make a reservation for six, I mean, for eight people).", "labels": [], "entities": [{"text": "language realisations", "start_pos": 25, "end_pos": 46, "type": "TASK", "confidence": 0.7350524365901947}]}, {"text": "Disfluencies have been investigated extensively in psycholinguistics, with a range of studies showing that they affect sentence processing in intricate ways).", "labels": [], "entities": []}, {"text": "Most computational work on disfluencies, however, has focused on detection rather than on disfluency processing and interpretation (e.g.,.", "labels": [], "entities": [{"text": "disfluency processing and interpretation", "start_pos": 90, "end_pos": 130, "type": "TASK", "confidence": 0.6877047568559647}]}, {"text": "In contrast, our aim is to get a better understanding of how RNNs process disfluent utterances and to analyse the impact of such disfluencies on a downstream task-in this case, issuing an API request reflecting the preferences of the user in a task-oriented dialogue.", "labels": [], "entities": []}, {"text": "For our experiments, we use the synthetic dataset bAbI () and a modified version of it called bAbI+ which includes disfluencies ( ).", "labels": [], "entities": []}, {"text": "The dataset contains simple dialogues between a user and a system in the restaurant reservation domain, which terminate with the system issuing an API call that encodes the user's request.", "labels": [], "entities": []}, {"text": "In bAbI+, disfluencies are probabilistically inserted into user turns, following distributions inhuman data.", "labels": [], "entities": []}, {"text": "Thus, while the data is artificial and certainly simplistic, its goal-oriented nature offers a rare opportunity: by assessing whether the system issues the right API call, we can study, in a controlled way, whether and how the model builds up a relevant semantic/pragmatic interpretation when processing a disfluent utterance-a key aspect that would not be available with unannotated natural data.", "labels": [], "entities": []}], "datasetContent": [{"text": "Following , we use a 2\u00d72 paradigm in which we train models either on bAbI or bAbI+ data and evaluate their performance on the test set of the same dataset, as well as across datasets.", "labels": [], "entities": []}, {"text": "We report both the percentage of correct words in the generated responses (word accuracy) and the percentage of responses that were entirely correct (sequence accuracy).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.8265666961669922}, {"text": "sequence accuracy", "start_pos": 150, "end_pos": 167, "type": "METRIC", "confidence": 0.7318399250507355}]}, {"text": "Additionally, we separately report the word and sequence accuracy of the API calls generated at the end of each dialogue.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.8692391514778137}]}, {"text": "Note that these metrics are more challenging than the retrieval-based ones used by and , as the correct response has to be generated word byword, rather than merely being selected from a set of already available candidate utterances.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Sequence accuracy (word accuracy in brackets) on the test set for utterances (non-API call  responses) and API calls only. The last column shows accuracy on the test set for the retrieval-based  memory-network system, as reported by", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9680335521697998}, {"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.630673348903656}, {"text": "accuracy", "start_pos": 155, "end_pos": 163, "type": "METRIC", "confidence": 0.9991111159324646}]}, {"text": " Table 2: Sequence accuracies of all sequences with  and without editing term, averaged over 5 runs.", "labels": [], "entities": []}, {"text": " Table 3: Precision / recall of diagnostic classifiers  to identify reparanda, editing terms and repairs.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9820980429649353}, {"text": "recall", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.941517174243927}]}, {"text": " Table 4: Accuracy per slot type in the word-by- word experiment.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9982650876045227}]}]}