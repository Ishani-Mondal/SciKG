{"title": [{"text": "Exploiting Attention to Reveal Shortcomings in Memory Models", "labels": [], "entities": [{"text": "Exploiting Attention to Reveal Shortcomings in Memory", "start_pos": 0, "end_pos": 53, "type": "TASK", "confidence": 0.8343196085521153}]}], "abstractContent": [{"text": "The decision making processes of deep networks are difficult to understand and while their accuracy often improves with increased architectural complexity, so too does their opacity.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9985584616661072}]}, {"text": "Practical use of machine learning models, especially for question and answering applications, demands a system that is inter-pretable.", "labels": [], "entities": [{"text": "question and answering", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.7458944916725159}]}, {"text": "We analyze the attention of a memory network model to reconcile contradictory performance on a challenging question-answering dataset that is inspired by theory-of-mind experiments.", "labels": [], "entities": []}, {"text": "We equate success on questions to task classification, which explains not only test-time failures but also how well the model generalizes to new training conditions .", "labels": [], "entities": [{"text": "task classification", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.7093088924884796}]}], "introductionContent": [], "datasetContent": [{"text": "We train jointly overall task types without noise, but evaluate success on a test set with noise sentences generated randomly at different positions (i.e. ToM (noised)).", "labels": [], "entities": []}, {"text": "We first examine how the model performs across a range of parameter and initialization values.", "labels": [], "entities": []}, {"text": "Because MemN2N models are very sensitive to the network initialization, for each set of parameters, the best result out of 10 runs is used for each configuration of hyperparameters.", "labels": [], "entities": []}, {"text": "To understand why failures occur, we plot the average attention overall instances of each task-question combination.", "labels": [], "entities": []}, {"text": "shows the average attention of the best performing 3-hop model on the firstorder (left) and second-order (right) belief tasks.", "labels": [], "entities": []}, {"text": "Only the attention over memory slots with relevant story sentences is displayed.", "labels": [], "entities": []}, {"text": "Surprisingly, the model is successful on the \"harder\" second-order belief question but not on the first-order one.", "labels": [], "entities": []}, {"text": "Indeed, the pattern of attention across hops in response to the second-order belief question is more varied across task conditions and attends to sentences that provide information about agents' transition in the world (i.e., \"Sally exited the kitchen\").", "labels": [], "entities": []}, {"text": "On the other hand, the left hand side of the figure shows that, in response to the first-order belief question, the attention is not sensitive to the task type (i.e., true-, false-or second-order-belief).", "labels": [], "entities": []}, {"text": "Considering each belief question as a task classification, as shown in, can explain this result.", "labels": [], "entities": []}, {"text": "The answer to the first-order question is different for false-belief and second-order falsebelief tasks while it is the same for the secondorder question.", "labels": [], "entities": []}, {"text": "Given the similarity of these 2 tasks (e.g., Sally moves between rooms in both tasks, both contain the word \"exited\"), the \"classification\" problem is much easier when the two questions have the same answer.", "labels": [], "entities": []}, {"text": "To answer the first-order question correctly -where the answers are different for the false-belief and second-order false-belief tasks -the model needs to learn to distinguish between between these very similar tasks.", "labels": [], "entities": []}, {"text": "To further test this hypothesis, we created an inaccurate version of the ToM dataset where the answer to the false belief question was modified to be the second location of the object as opposed to the first.", "labels": [], "entities": [{"text": "ToM dataset", "start_pos": 73, "end_pos": 84, "type": "DATASET", "confidence": 0.8859838247299194}]}, {"text": "With the difficulty of classifying false-belief from second-order false belief tasks removed, the models were able to successfully answer all of the first order belief questions.", "labels": [], "entities": []}], "tableCaptions": []}