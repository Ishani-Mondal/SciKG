{"title": [{"text": "Coverage and Cynicism: The AFRL Submission to the WMT 2018 Parallel Corpus Filtering Task", "labels": [], "entities": [{"text": "AFRL Submission to the WMT 2018 Parallel Corpus Filtering Task", "start_pos": 27, "end_pos": 89, "type": "DATASET", "confidence": 0.7566851615905762}]}], "abstractContent": [{"text": "The WMT 2018 Parallel Corpus Filtering Task aims to test various methods of filtering a noisy parallel corpus, to make it useful for training machine translation systems.", "labels": [], "entities": [{"text": "WMT 2018 Parallel Corpus Filtering Task", "start_pos": 4, "end_pos": 43, "type": "TASK", "confidence": 0.7843723197778066}, {"text": "machine translation", "start_pos": 142, "end_pos": 161, "type": "TASK", "confidence": 0.7173355966806412}]}, {"text": "We describe the AFRL submissions, including their prepro-cessing methods and quality metrics.", "labels": [], "entities": [{"text": "AFRL", "start_pos": 16, "end_pos": 20, "type": "DATASET", "confidence": 0.746769368648529}]}, {"text": "Numerical results indicate relative benefits of different options and show where our methods are competitive .", "labels": [], "entities": []}], "introductionContent": [{"text": "For this task the participants were provided with a large corpus of parallel data in English and German.", "labels": [], "entities": []}, {"text": "The corpus contains approximately 10 8 lines, with approximately 10 9 words in each language.", "labels": [], "entities": []}, {"text": "Hunalign scores () also were provided for each line.", "labels": [], "entities": [{"text": "Hunalign scores", "start_pos": 0, "end_pos": 15, "type": "METRIC", "confidence": 0.9199727177619934}]}, {"text": "The task organizers built statistical machine translation (SMT) and neural machine translation (NMT) systems from the scores produced, based on parallel training sets of 10 6 and 10 7 words.", "labels": [], "entities": [{"text": "statistical machine translation (SMT) and neural machine translation (NMT)", "start_pos": 26, "end_pos": 100, "type": "TASK", "confidence": 0.7896448648892916}]}, {"text": "Subset selection techniques often strive to reduce a set to the most useful.", "labels": [], "entities": [{"text": "Subset selection", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.9255586862564087}]}, {"text": "In this circumstance, this entails: \u2022 Avoiding selecting a line with undue repetition of content of other selected lines.", "labels": [], "entities": [{"text": "Avoiding", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9284467101097107}]}, {"text": "This can extend training times and/or skew the translation system to favor this type of line.", "labels": [], "entities": [{"text": "translation", "start_pos": 47, "end_pos": 58, "type": "TASK", "confidence": 0.963045060634613}]}, {"text": "\u2022 Avoid selecting long lines, which will be ignored in training an NMT system.", "labels": [], "entities": [{"text": "Avoid", "start_pos": 2, "end_pos": 7, "type": "METRIC", "confidence": 0.9651928544044495}]}, {"text": "In addition to adapting the corpus to the building of a general-purpose machine translation system, we must also deal with its significant noise.", "labels": [], "entities": [{"text": "general-purpose machine translation", "start_pos": 56, "end_pos": 91, "type": "TASK", "confidence": 0.6334611276785532}]}, {"text": "The main types of noise present in the given data are: \u2022 Not natural language \u2022 One or both languages are incorrect \u2022 Correct languages and natural language, but not translations of each other", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: BLEU scores of created systems, 10 6 -word SMT. Filter mean excludes the development set (new- stest2017). The two additional systems listed are the best performing in the task, by mean test set BLEU score. Set  score statistics are over the 43 task submissions from other participants.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9990894794464111}, {"text": "SMT", "start_pos": 53, "end_pos": 56, "type": "TASK", "confidence": 0.9120928049087524}, {"text": "Filter mean", "start_pos": 58, "end_pos": 69, "type": "METRIC", "confidence": 0.9743779897689819}, {"text": "BLEU", "start_pos": 205, "end_pos": 209, "type": "METRIC", "confidence": 0.9856744408607483}]}, {"text": " Table 2: BLEU scores of created systems, 10 7 -word SMT. Filter mean excludes the development set (new- stest2017). The two additional systems listed are the best performing in the task, by mean test set BLEU score. Set  score statistics are over the 43 task submissions from other participants.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9991360306739807}, {"text": "SMT", "start_pos": 53, "end_pos": 56, "type": "TASK", "confidence": 0.9181904196739197}, {"text": "Filter mean", "start_pos": 58, "end_pos": 69, "type": "METRIC", "confidence": 0.9745429456233978}, {"text": "BLEU", "start_pos": 205, "end_pos": 209, "type": "METRIC", "confidence": 0.9856442213058472}]}, {"text": " Table 3: BLEU scores of created systems, 10 6 -word NMT. Filter mean excludes the development set (new- stest2017). The two additional systems listed are the best performing in the task, by mean test set BLEU score. Set  score statistics are over the 43 task submissions from other participants.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9990266561508179}, {"text": "Filter mean", "start_pos": 58, "end_pos": 69, "type": "METRIC", "confidence": 0.9767461121082306}, {"text": "BLEU", "start_pos": 205, "end_pos": 209, "type": "METRIC", "confidence": 0.9850010871887207}]}, {"text": " Table 4: BLEU scores of created systems, 10 7 -word NMT. Filter mean excludes the development set (new- stest2017). The two additional systems listed are the best performing in the task, by mean test set BLEU score. Set  score statistics are over the 40 task submissions from other participants.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9990411400794983}, {"text": "Filter mean", "start_pos": 58, "end_pos": 69, "type": "METRIC", "confidence": 0.9768551290035248}, {"text": "BLEU", "start_pos": 205, "end_pos": 209, "type": "METRIC", "confidence": 0.984095573425293}]}]}