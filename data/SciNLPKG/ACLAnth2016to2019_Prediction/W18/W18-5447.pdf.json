{"title": [{"text": "Explicitly modeling case improves neural dependency parsing", "labels": [], "entities": [{"text": "neural dependency parsing", "start_pos": 34, "end_pos": 59, "type": "TASK", "confidence": 0.6251136263211569}]}], "abstractContent": [{"text": "Neural dependency parsing models that compose word representations from characters can presumably exploit morphosyntax when making attachment decisions.", "labels": [], "entities": [{"text": "Neural dependency parsing", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.640552282333374}]}, {"text": "How much do they know about morphology?", "labels": [], "entities": []}, {"text": "We investigate how well they handle morphological case, which is important for parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 79, "end_pos": 86, "type": "TASK", "confidence": 0.9841669201850891}]}, {"text": "Our experiments on Czech, German and Russian suggest that adding explicit morphological case-either oracle or predicted-improves neural dependency parsing, indicating that the learned representations in these models do not fully encode the morphological knowledge that they need, and can still benefit from targeted forms of explicit linguistic modeling.", "labels": [], "entities": [{"text": "neural dependency parsing", "start_pos": 129, "end_pos": 154, "type": "TASK", "confidence": 0.6207941869894663}]}], "introductionContent": [{"text": "Parsing morphologically rich languages (MRLs) is difficult due to the complex relationship of syntax to morphology.", "labels": [], "entities": [{"text": "Parsing morphologically rich languages (MRLs)", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.9155713319778442}]}, {"text": "But the success of neural networks offer an appealing solution to this problem by computing word representation from characters.", "labels": [], "entities": []}, {"text": "Character-level models ( learn relationship between similar word forms and have shown to be effective for parsing MRLs (.", "labels": [], "entities": [{"text": "parsing MRLs", "start_pos": 106, "end_pos": 118, "type": "TASK", "confidence": 0.9365922510623932}]}, {"text": "Does that mean that we can do away with explicit modeling of morphology altogether?", "labels": [], "entities": []}, {"text": "Consider two challenges in parsing MRLs raised by: \u2022 Can we represent words abstractly so as to reflect shared morphological aspects between them?", "labels": [], "entities": [{"text": "parsing MRLs", "start_pos": 27, "end_pos": 39, "type": "TASK", "confidence": 0.8980711400508881}]}, {"text": "\u2022 Which types of morphological information should we include in the parsing model?", "labels": [], "entities": [{"text": "parsing", "start_pos": 68, "end_pos": 75, "type": "TASK", "confidence": 0.9649489521980286}]}, {"text": "It is tempting to hypothesize that character-level models effectively solve the first problem.", "labels": [], "entities": []}, {"text": "For the second, and reported that morphological case is beneficial across morphologically rich languages with extensive case systems, where case syncretism is pervasive and often hurts parsing performance.", "labels": [], "entities": []}, {"text": "But these studies focus on vintage parsers; do neural parsers with character-level representations also solve this second problem?", "labels": [], "entities": []}, {"text": "We attempt to answer this question by asking whether an explicit model of morphological case helps dependency parsing, and our results show that it does.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 99, "end_pos": 117, "type": "TASK", "confidence": 0.8590067028999329}]}, {"text": "Furthermore, a pipeline model in which we feed predicted case to the parser outperforms multi-task learning in which case prediction is an auxiliary task.", "labels": [], "entities": []}, {"text": "These results suggest that neural dependency parsers do not adequately infer this crucial linguistic feature directly from the input text.", "labels": [], "entities": []}], "datasetContent": [{"text": "We experiment with three fusional languages with extensive case systems: Czech, German, and Rus- sian; and we consider four forms of input (e(w i ), \u00a72): word (embedding), characters, characters with gold case, and characters with predicted case.", "labels": [], "entities": []}, {"text": "For the latter two, we append the case label to the character sequence, e.g. b, a, t, Acc represents bat with accusative case.", "labels": [], "entities": [{"text": "Acc", "start_pos": 86, "end_pos": 89, "type": "METRIC", "confidence": 0.9549501538276672}]}, {"text": "Using the same method, we also supply the gold full analysis, to tease out the importance of case specifically.", "labels": [], "entities": [{"text": "gold full analysis", "start_pos": 42, "end_pos": 60, "type": "METRIC", "confidence": 0.5875605444113413}]}, {"text": "Finally, we experiment with multitask learning (MTL;, using the bi-LSTM states of the lower layer of the bi-LSTM encoder to predict case feature.", "labels": [], "entities": []}, {"text": "We then look at the performance when we replace gold case with predicted case.", "labels": [], "entities": []}, {"text": "We train a morphological tagger to predict case information.", "labels": [], "entities": []}, {"text": "The tagger has the same structure as the parser's encoder, with an additional feedforward neural network with one hidden layer followed by a softmax layer.", "labels": [], "entities": []}, {"text": "We found that predicted case improves accuracy, although the effect is different across languages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9991409778594971}]}, {"text": "These results are interesting, since in vintage parsers, predicted case usually harmed accuracy (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9988855719566345}]}, {"text": "However, we note that our taggers use gold POS, which might help.", "labels": [], "entities": [{"text": "POS", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.8428031206130981}]}, {"text": "Pipeline model vs. Multi-task learning In general, MTL models achieve similar or slightly better performance than the character-only models, suggesting that supplying casein this way is beneficial.", "labels": [], "entities": []}, {"text": "However, we found that using predicted casein a pipeline model gives more improvements than MTL.", "labels": [], "entities": [{"text": "MTL", "start_pos": 92, "end_pos": 95, "type": "DATASET", "confidence": 0.5806527137756348}]}, {"text": "We also observe an interesting pattern in which MTL achieves better tagging accuracy than the pipeline model but lower performance in parsing.", "labels": [], "entities": [{"text": "MTL", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.8273459672927856}, {"text": "tagging", "start_pos": 68, "end_pos": 75, "type": "TASK", "confidence": 0.9362456798553467}, {"text": "accuracy", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9122306108474731}]}, {"text": "This is surprising since it suggests that the MTL model must learn to effectively encode casein the model's representation, but must not effectively use it for parsing.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Label Attachment Score (LAS) results.  For each language, we show the number of train- ing sentences.", "labels": [], "entities": [{"text": "Label Attachment Score (LAS)", "start_pos": 10, "end_pos": 38, "type": "METRIC", "confidence": 0.8370225330193838}]}]}