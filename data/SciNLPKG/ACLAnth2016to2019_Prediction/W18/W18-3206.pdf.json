{"title": [{"text": "Language Identification and Analysis of Code-Switched Social Media Text", "labels": [], "entities": [{"text": "Language Identification and Analysis of Code-Switched Social Media Text", "start_pos": 0, "end_pos": 71, "type": "TASK", "confidence": 0.7573768099149069}]}], "abstractContent": [{"text": "In this paper, we detail our work on comparing different word-level language identification systems for code-switched Hindi-English data and a standard Spanish-English dataset.", "labels": [], "entities": [{"text": "word-level language identification", "start_pos": 57, "end_pos": 91, "type": "TASK", "confidence": 0.6381128132343292}]}, {"text": "In this regard, we build anew code-switched dataset for Hindi-English.", "labels": [], "entities": []}, {"text": "To understand the code-switching patterns in these language pairs, we investigate different code-switching metrics.", "labels": [], "entities": []}, {"text": "We find that the CRF model outperforms the neural network based models by a margin of 2-5 percentage points for Spanish-English and 3-5 percentage points for Hindi-English.", "labels": [], "entities": []}], "introductionContent": [{"text": "Code-switching occurs when a person switches between two or more languages in a single instance of spoken or written communication).", "labels": [], "entities": []}, {"text": "Codeswitching instances are prevalent in modern informal communications between multilingual individuals specially, in social media platforms such as Facebook and Twitter.", "labels": [], "entities": []}, {"text": "Given this prevalence of code-switching, there is value in automatic processing and understanding of such data.", "labels": [], "entities": []}, {"text": "Language identification at the word level is the first step in computational modeling of code-switched data.", "labels": [], "entities": [{"text": "Language identification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6953021734952927}]}, {"text": "Language identification is important fora wide variety of end user applications such as information extraction systems, voice assistant interfaces, machine translation, as well as for tools to assist language assessment in bilingual children (.", "labels": [], "entities": [{"text": "Language identification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7352966815233231}, {"text": "information extraction", "start_pos": 88, "end_pos": 110, "type": "TASK", "confidence": 0.7381161898374557}, {"text": "machine translation", "start_pos": 148, "end_pos": 167, "type": "TASK", "confidence": 0.8167677223682404}]}, {"text": "Language detection, in addition, enables sociolinguistics and pragmatic studies of code-switching behavior.", "labels": [], "entities": [{"text": "Language detection", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7105175703763962}]}, {"text": "Code-switching in speech is well studied in linguistics, psycholinguistic and sociolinguistics).", "labels": [], "entities": []}, {"text": "The alternation of languages across sentence boundaries is known as code-switching and the alternation within a sentence is known as code-mixing.", "labels": [], "entities": []}, {"text": "In this paper we will refer to both instances as code-switching and differentiate between the types of code switching when necessary.", "labels": [], "entities": []}, {"text": "shows examples of code-switching for Hindi-English and Spanish-English.", "labels": [], "entities": []}], "datasetContent": [{"text": "For CRF, we run experiments with different combinations of hand-crafted features discussed in the previous section.", "labels": [], "entities": [{"text": "CRF", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.946911096572876}]}, {"text": "We run three different sets of experiments-with no contextual information, and with surrounding words of context window sizes 1 and 2.", "labels": [], "entities": []}, {"text": "shows results from these experiments.", "labels": [], "entities": []}, {"text": "For the RNN-based systems, we use pre-trained fastText word embeddings.", "labels": [], "entities": []}, {"text": "We learn the embeddings using a large monolingual corpus for each of the languages and a smaller code-switched corpus for the language pairs.", "labels": [], "entities": []}, {"text": "The rationale for using a large monolingual data is that it is readily available and that it can account for the different contexts in which words appear in different languages -thus providing an accurate separation between the languages.", "labels": [], "entities": []}, {"text": "We train three separate sets of embeddings each for SPA-ENG, HIN-ENG, and SPA-ENG + HIN-ENG.", "labels": [], "entities": [{"text": "HIN-ENG", "start_pos": 61, "end_pos": 68, "type": "METRIC", "confidence": 0.9157875776290894}]}, {"text": "The embeddings for SPA-ENG are trained by combining a portion of English Gigaword corpus ( and Spanish Gigaword corpus), and a subset of tweets from.", "labels": [], "entities": [{"text": "SPA-ENG", "start_pos": 19, "end_pos": 26, "type": "TASK", "confidence": 0.9100736975669861}, {"text": "English Gigaword corpus", "start_pos": 65, "end_pos": 88, "type": "DATASET", "confidence": 0.8587594628334045}]}, {"text": "For HIN-ENG, we combine a portion of English Gigaword corpus, transliterated Hindi monolingual corpus, and Facebook posts that contain code-switching.", "labels": [], "entities": [{"text": "English Gigaword corpus", "start_pos": 37, "end_pos": 60, "type": "DATASET", "confidence": 0.8275936245918274}]}, {"text": "All  Context-0 Context-1 Context-2 Baseline 85.02 --Word + 1 to 5 char n-grams: Token-level F1-weighted score of the CRF model for different feature combinations for SPA-ENG.", "labels": [], "entities": [{"text": "F1-weighted score", "start_pos": 92, "end_pos": 109, "type": "METRIC", "confidence": 0.8720876276493073}]}, {"text": "these corpora are used to train the embeddings for SPA-ENG + HIN-ENG.", "labels": [], "entities": [{"text": "HIN-ENG", "start_pos": 61, "end_pos": 68, "type": "METRIC", "confidence": 0.8783591985702515}]}, {"text": "This helps to capture the word usage in the context of each language and eliminates the ambiguity for the words that have same surface form in multiple languages.", "labels": [], "entities": []}, {"text": "We train 300-dimension embedding vectors using fastText skip-gram model for 250 epochs with a learning rate of 0.001 and a minimum word count threshold of 5.", "labels": [], "entities": []}, {"text": "For BLSTM model, we initialize the embedding layer with the pre-trained fastText word embeddings and feed the output sequence from this layer to the BLSTM layer.", "labels": [], "entities": []}, {"text": "At the output layer a softmax activation function is applied over the hidden representation learned in the BLSTM layer.", "labels": [], "entities": [{"text": "BLSTM layer", "start_pos": 107, "end_pos": 118, "type": "DATASET", "confidence": 0.7322641015052795}]}, {"text": "For word-char model, we initialize the word embedding matrix with fastText embeddings and use random initialization for character embedding matrix.", "labels": [], "entities": []}, {"text": "We train both the RNN-based models by optimizing the cross entropy objective function with Adam () optimizer.", "labels": [], "entities": []}, {"text": "We use dropout masks after BLSTM layer in BLSTM model, LSTM layers in word-char model, and embedding layer in each model to mitigate overfitting.", "labels": [], "entities": []}, {"text": "The reported BLSTM model and wordchar models have hidden units of size 80 and 100 respectively in the LSTM layers.", "labels": [], "entities": [{"text": "BLSTM", "start_pos": 13, "end_pos": 18, "type": "METRIC", "confidence": 0.6066623330116272}]}, {"text": "For word-char model, for each token we try a neighboring token window size of 1, 2, and 3.", "labels": [], "entities": []}, {"text": "The context window size of 2 gives better results and is reported here.", "labels": [], "entities": []}, {"text": "trained mostly on monolingual data, this dependency does not constrain the systems.", "labels": [], "entities": []}, {"text": "We use a simple lexicon-based model as baseline for our language identification systems.", "labels": [], "entities": [{"text": "language identification", "start_pos": 56, "end_pos": 79, "type": "TASK", "confidence": 0.734036773443222}]}, {"text": "We use F1-weighted scores for model evaluations to account for the imbalance in label distributions (Table 2).", "labels": [], "entities": [{"text": "F1-weighted scores", "start_pos": 7, "end_pos": 25, "type": "METRIC", "confidence": 0.9569913744926453}]}, {"text": "All the models improve the performance over the respective baseline models by 7 to 25 percentage points.", "labels": [], "entities": []}, {"text": "For CRF, which is the best performing model across language pairs, the current word and its character n-grams are the most important features.", "labels": [], "entities": []}, {"text": "Adding POS tags does not improve these results by much.", "labels": [], "entities": []}, {"text": "This could be because the POS taggers are optimized for monolingual data and their output for the code-switched data contains noise.", "labels": [], "entities": [{"text": "POS taggers", "start_pos": 26, "end_pos": 37, "type": "TASK", "confidence": 0.6669443696737289}]}, {"text": "Using contextual information improves the results for HIN-ENG, but not for SPA-ENG.", "labels": [], "entities": [{"text": "HIN-ENG", "start_pos": 54, "end_pos": 61, "type": "METRIC", "confidence": 0.6656641364097595}]}, {"text": "In   based models and the CRF model.", "labels": [], "entities": []}, {"text": "We consider the performance of the CRF model using only the language independent features with a context size of 2 fora fair comparison.", "labels": [], "entities": []}, {"text": "Among the RNN-based systems, while the results are competitive overall, there is no single system that performs the best across language pairs.", "labels": [], "entities": []}, {"text": "The BLSTM system performs better for HIN-ENG, while word-char system performs better for SPA-ENG.", "labels": [], "entities": [{"text": "BLSTM", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.8951078653335571}]}, {"text": "The BLSTM model captures long distance dependencies in a sequence and this is inline with the observation made above with the CRF model-more context helps for HIN-ENG.", "labels": [], "entities": [{"text": "BLSTM", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.910279393196106}]}, {"text": "It is also consistent with the code-switching patterns discussed in Section 5.", "labels": [], "entities": []}, {"text": "A majority of code-switched tweets in SPA-ENG have a single instance of word insertion and these are being miss-labeled by the models.", "labels": [], "entities": [{"text": "word insertion", "start_pos": 72, "end_pos": 86, "type": "TASK", "confidence": 0.6957840174436569}]}, {"text": "The overall better results for SPA-ENG are because of a larger training data used.", "labels": [], "entities": [{"text": "SPA-ENG", "start_pos": 31, "end_pos": 38, "type": "TASK", "confidence": 0.9505918622016907}]}, {"text": "The baseline results for SPA-ENG + HIN-ENG is relatively low as compared to the individual language pairs.", "labels": [], "entities": [{"text": "HIN-ENG", "start_pos": 35, "end_pos": 42, "type": "METRIC", "confidence": 0.9337038993835449}]}, {"text": "This shows that simultaneously identifying language for multiple language pair is harder.", "labels": [], "entities": []}, {"text": "We obtain reasonable results for these initial experiments with all the models.", "labels": [], "entities": []}, {"text": "To understand these results better, we look at the label-wise F1-score for lang1, lang2 and ne).", "labels": [], "entities": [{"text": "F1-score", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9319230318069458}]}, {"text": "The F1-scores for CRF is better across the labels and the difference is significantly high for ne.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.999055802822113}]}, {"text": "The F1-score ne is relatively high for HIN-ENG, which can be attributed to the fact that around 58% of the named-entities in the test set appear in the training set.", "labels": [], "entities": [{"text": "F1-score ne", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9714263677597046}, {"text": "HIN-ENG", "start_pos": 39, "end_pos": 46, "type": "METRIC", "confidence": 0.5587758421897888}]}, {"text": "This overlap is only 17% for SPA-ENG.", "labels": [], "entities": [{"text": "overlap", "start_pos": 5, "end_pos": 12, "type": "METRIC", "confidence": 0.9881250858306885}, {"text": "SPA-ENG", "start_pos": 29, "end_pos": 36, "type": "DATASET", "confidence": 0.6807236671447754}]}, {"text": "So, infrequent named-entities seems to be hardest to accurately label.", "labels": [], "entities": []}, {"text": "In addition, the RNN-based models are more sensitive to amount of training samples.", "labels": [], "entities": []}, {"text": "Further, we examine the transitions learned by our best CRF model for each of the language pairs).", "labels": [], "entities": []}, {"text": "For both language pairs, the transitions between the same languages are more likely than switching.", "labels": [], "entities": []}, {"text": "But we also observe that the transitions from lang1 to lang2 and vice-versa rank higher for HIN-ENG than SPA-ENG.", "labels": [], "entities": [{"text": "HIN-ENG", "start_pos": 92, "end_pos": 99, "type": "METRIC", "confidence": 0.8777607679367065}]}, {"text": "This is because there are fewer code-switching points in SPA-ENG as compared to HIN-ENG in these datasets.", "labels": [], "entities": []}, {"text": "(a) BLSTM Model (b) Word-char LSTM Model: Projection of word representations learned by the neural networks model for HIN-ENG + SPA-ENG.", "labels": [], "entities": [{"text": "BLSTM", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.8962969183921814}]}, {"text": "We reduce the word vector dimensions using PCA.", "labels": [], "entities": []}, {"text": "The mapping of labels to colors: lang1 -red, lang2 -green, lang3 -blue, ne -black, other -orange, ambiguous -purple, mixed -purple, fw -yellow, unk -yellow.", "labels": [], "entities": []}, {"text": "We also visualize the feature representations learned by the RNN-based models by projecting the word embeddings fora randomly selected subset of words from the development datasets for SPA-ENG + HIN-ENG ().", "labels": [], "entities": []}, {"text": "The wordchar model gives a clearer separation between the three languages, the words belonging to the labels other and ne.", "labels": [], "entities": []}, {"text": "While the BLSTM model also provides clear separation between the language words, there is an overlap with the tokens from other.", "labels": [], "entities": []}, {"text": "These results show that these models can be scaled to detect code-switching in multiple language pairs without any additional feature engineering.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: A brief description of the labels and label distribution for HIN-ENG and SPA-ENG datasets.", "labels": [], "entities": [{"text": "SPA-ENG datasets", "start_pos": 83, "end_pos": 99, "type": "DATASET", "confidence": 0.7391931861639023}]}, {"text": " Table 3: Corpus statistics for the language pairs.  Token ratio is the percentage of the total tokens  that are unique. A higher token ratio implies a  richer corpus vocabulary.", "labels": [], "entities": []}, {"text": " Table 4: Post-level language distribution in the  datasets. Column 5 corresponds to the instances  that do not have any words with language tags.  lang1: ENG, lang2: HIN/SPA.", "labels": [], "entities": []}, {"text": " Table 5: CS Metrics for the datasets.", "labels": [], "entities": []}, {"text": " Table 6: Token-level F1-weighted score of the CRF model for different feature combinations for HIN- ENG.", "labels": [], "entities": [{"text": "F1-weighted score", "start_pos": 22, "end_pos": 39, "type": "METRIC", "confidence": 0.956002950668335}, {"text": "HIN- ENG", "start_pos": 96, "end_pos": 104, "type": "TASK", "confidence": 0.4046823779741923}]}, {"text": " Table 7: Token-level F1-weighted score of the CRF model for different feature combinations for SPA- ENG.", "labels": [], "entities": [{"text": "F1-weighted score", "start_pos": 22, "end_pos": 39, "type": "METRIC", "confidence": 0.9540278911590576}, {"text": "SPA- ENG", "start_pos": 96, "end_pos": 104, "type": "TASK", "confidence": 0.7927314043045044}]}, {"text": " Table 8: Token-level F1-weighted score for lan- guage identification systems.", "labels": [], "entities": [{"text": "F1-weighted score", "start_pos": 22, "end_pos": 39, "type": "METRIC", "confidence": 0.9398045539855957}]}, {"text": " Table 9: The top 10 most likely transitions learned by the best CRF model for HIN-ENG and SPA-ENG  datasets.", "labels": [], "entities": [{"text": "SPA-ENG  datasets", "start_pos": 91, "end_pos": 108, "type": "DATASET", "confidence": 0.757999986410141}]}, {"text": " Table 10: Token-level F1-score of majority labels -lang1,", "labels": [], "entities": [{"text": "F1-score", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.864239513874054}]}]}