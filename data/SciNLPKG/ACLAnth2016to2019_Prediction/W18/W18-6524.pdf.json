{"title": [{"text": "Automatic Evaluation of Neural Personality-based Chatbots", "labels": [], "entities": []}], "abstractContent": [{"text": "Stylistic variation is critical to render the utterances generated by conversational agents natural and engaging.", "labels": [], "entities": []}, {"text": "In this paper, we focus on sequence-to-sequence models for open-domain dialogue response generation and propose anew method to evaluate the extent to which such models are able to generate responses that reflect different personality traits.", "labels": [], "entities": [{"text": "open-domain dialogue response generation", "start_pos": 59, "end_pos": 99, "type": "TASK", "confidence": 0.6921703964471817}]}], "introductionContent": [{"text": "The advent of deep learning methods has led to the development of data-driven conversational agents for informal open-domain dialogue (see, fora review).", "labels": [], "entities": []}, {"text": "These chatbot systems model conversation as a sequence-tosequence (SEQ2SEQ) problem) and rely on large amounts of unannotated dialogue data for training.", "labels": [], "entities": []}, {"text": "We investigate whether such models are able to generate responses that reflect different personality traits.", "labels": [], "entities": []}, {"text": "We test two kinds of models: The speaker-based model by, where response generation is conditioned on the individual speaker, and a personality-based model similar to, where generation is conditioned on a personality type.", "labels": [], "entities": []}, {"text": "Evaluating the output of chatbot systems is remarkably difficult (.", "labels": [], "entities": []}, {"text": "To make progress in this direction with regards to personality aspects, we propose anew statistical evaluation method that leverages an existing personality recogniser (, thus avoiding the need for specialised corpora or manual annotations.", "labels": [], "entities": []}, {"text": "We adopt the Big Five psychological model of personality, also called OCEAN for the initials of the five personality traits considered: Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism.", "labels": [], "entities": [{"text": "Agreeableness", "start_pos": 179, "end_pos": 192, "type": "METRIC", "confidence": 0.9862776398658752}]}, {"text": "Each of the traits is represented by a scalar value on a scale from 1 to 7.", "labels": [], "entities": []}, {"text": "In the remainder of the paper, we introduce the models we examine and describe our new evaluation method.", "labels": [], "entities": []}, {"text": "Our results show that the models are able to generate output that reflects distinct personalities, over a baseline encoding chance personality variation.", "labels": [], "entities": []}, {"text": "We conclude with a brief discussion on related work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use transcripts from two American situation comedy television series: Friends 4 and The Big Bang Theory.", "labels": [], "entities": []}, {"text": "We consider only those characters who contribute a minimum of 2000 turns, which results in 13 characters (6 from Friends and 7 from The Big Bang Theory).", "labels": [], "entities": []}, {"text": "We assign a unique speaker id to each character.", "labels": [], "entities": []}, {"text": "In addition, we estimate the personality of each character as follows: for each character, we randomly select 50 samples of 500 utterances each, and estimate the OCEAN scores for each sample using the personality recogniser by, which exploits linguistic features from 'Linguistic Inquiry and Word Count') and the MRC Psycholinguistic database.", "labels": [], "entities": [{"text": "OCEAN", "start_pos": 162, "end_pos": 167, "type": "METRIC", "confidence": 0.997646152973175}, {"text": "MRC Psycholinguistic database", "start_pos": 313, "end_pos": 342, "type": "DATASET", "confidence": 0.9377378622690836}]}, {"text": "We assign to each character the OCEAN score resulting from taking the arithmetic mean of the estimated scores for the corresponding 50 samples.", "labels": [], "entities": [{"text": "OCEAN score", "start_pos": 32, "end_pos": 43, "type": "METRIC", "confidence": 0.9572305679321289}]}, {"text": "We consider every two consecutive turns in a scene to be a context-response pair and annotate each response with either the speaker id or the speaker's OCEAN scores.", "labels": [], "entities": [{"text": "OCEAN", "start_pos": 152, "end_pos": 157, "type": "METRIC", "confidence": 0.9875720739364624}]}, {"text": "The resulting dataset contains \u223c86k context-response pairs, of which around 2000 pairs were randomly selected and reserved for validation.", "labels": [], "entities": []}, {"text": "We propose anew evaluation method to measure whether persona-based neural dialogue generation models are able to produce responses with distinguishable personality traits for different characters and different personality types.", "labels": [], "entities": [{"text": "persona-based neural dialogue generation", "start_pos": 53, "end_pos": 93, "type": "TASK", "confidence": 0.7098345458507538}]}, {"text": "Using the evaluation set, for each character we randomly select 250 samples of 500 responses and calculate the OCEAN scores for each sample.", "labels": [], "entities": [{"text": "OCEAN", "start_pos": 111, "end_pos": 116, "type": "METRIC", "confidence": 0.9538757801055908}]}, {"text": "Recall that the OCEAN scores correspond to 5-dimensional vectors.", "labels": [], "entities": [{"text": "OCEAN", "start_pos": 16, "end_pos": 21, "type": "METRIC", "confidence": 0.62937992811203}]}, {"text": "We label each of these 250 vectors with the corresponding character.", "labels": [], "entities": []}, {"text": "This gives us 13 gold classes-one for each characterwith 250 datapoints each.", "labels": [], "entities": []}, {"text": "We then use a support vector machine classifier to test to what extent the OCEAN scores estimated from the generated responses allow us to recover the gold character classes.", "labels": [], "entities": [{"text": "OCEAN", "start_pos": 75, "end_pos": 80, "type": "METRIC", "confidence": 0.8072469830513}]}, {"text": "We compute results using 5-fold crossvalidation (training on 80% of the set and testing on the remaining 20% once for each fold).", "labels": [], "entities": []}, {"text": "We report average scores over ten iterations of this procedure (i.e., 5 \u00d7 10).", "labels": [], "entities": []}, {"text": "We consider a baseline obtained by randomising the gold character label in the set of generated responses, which indicates the level of performance we may expect by chance.", "labels": [], "entities": []}, {"text": "In addition, we use the procedure described above to discriminate between characters using their original (gold) utterances from the transcripts, rather than modelgenerated responses.", "labels": [], "entities": []}, {"text": "This serves as a sanity check for the personality recogniser used to estimate the OCEAN scores-if the recogniser cannot detect personality differences among the characters in the original transcripts, it is not reasonable to expect that the models will be able to generate responses with different personality styles-and provides an upper bound for the performance we can expect to achieve when evaluating generated responses.", "labels": [], "entities": [{"text": "OCEAN", "start_pos": 82, "end_pos": 87, "type": "METRIC", "confidence": 0.4475502073764801}]}, {"text": "Given that the particular personality recogniser we use ( was not optimised for dialogues from TV-series transcripts, as an additional sanity check we compare its performance on the original (gold) utterances with a bag-ofwords (BoW) approach.", "labels": [], "entities": []}, {"text": "This allows us to test whether the recogniser may only be detecting trivial patterns of word usage.", "labels": [], "entities": [{"text": "detecting trivial patterns of word usage", "start_pos": 58, "end_pos": 98, "type": "TASK", "confidence": 0.5828299274047216}]}, {"text": "We select the top 200 most frequent words over the original utterances as features, without removing words typically considered stop words such as pronouns or discourse markers, since they maybe personality indicators.", "labels": [], "entities": []}, {"text": "Then we run the same classification procedure using these BoW representations.", "labels": [], "entities": [{"text": "BoW", "start_pos": 58, "end_pos": 61, "type": "DATASET", "confidence": 0.9350911974906921}]}], "tableCaptions": [{"text": " Table 2: Average scores for personality types with  high value for different OCEAN personality traits", "labels": [], "entities": []}]}