{"title": [{"text": "Keep It or Not: Word Level Quality Estimation for Post-Editing", "labels": [], "entities": []}], "abstractContent": [{"text": "The paper presents our participation in the WMT 2018 shared task on word level quality estimation (QE) of machine translated (MT) text, i.e., to predict whether a word in MT output fora given source context is correctly translated and hence should be retained in the post-edited translation (PE), or not.", "labels": [], "entities": [{"text": "WMT 2018 shared task", "start_pos": 44, "end_pos": 64, "type": "TASK", "confidence": 0.6575458496809006}, {"text": "word level quality estimation (QE) of machine translated (MT) text", "start_pos": 68, "end_pos": 134, "type": "TASK", "confidence": 0.6746657299143928}]}, {"text": "To perform the QE task, we measure the similarity of the source context of the target MT word with the context for which the word is retained in PE in the training data.", "labels": [], "entities": [{"text": "QE task", "start_pos": 15, "end_pos": 22, "type": "TASK", "confidence": 0.8844611048698425}]}, {"text": "This is achieved in two different ways, using Bag-of-Words (BoW) model and Document-to-Vector (Doc2Vec) model.", "labels": [], "entities": []}, {"text": "In the BoW model, we compute the cosine similarity while in the Doc2Vec model we consider the Doc2Vec similarity.", "labels": [], "entities": [{"text": "BoW", "start_pos": 7, "end_pos": 10, "type": "DATASET", "confidence": 0.9588677883148193}]}, {"text": "By applying the Kneedle algorithm on the F1-mult vs. similarity score plot, we derive the threshold based on which OK/BAD decisions are taken for the MT words.", "labels": [], "entities": [{"text": "F1-mult vs. similarity score", "start_pos": 41, "end_pos": 69, "type": "METRIC", "confidence": 0.8402603417634964}, {"text": "BAD", "start_pos": 118, "end_pos": 121, "type": "METRIC", "confidence": 0.6824509501457214}, {"text": "MT words", "start_pos": 150, "end_pos": 158, "type": "TASK", "confidence": 0.8552621603012085}]}, {"text": "Experimental results revealed that the Doc2Vec model performs better than the BoW model on the word level QE task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Evaluating and estimating quality of a machine translation (MT) system without referring the actual translation is now one of the key research areas in MT domain (.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 39, "end_pos": 63, "type": "TASK", "confidence": 0.8379377722740173}, {"text": "MT", "start_pos": 152, "end_pos": 154, "type": "TASK", "confidence": 0.9506748914718628}]}, {"text": "Ina machine translated document quality estimation can be performed at various granularities like word level, phrase level or sentence level (.", "labels": [], "entities": [{"text": "Ina machine translated document quality estimation", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.6143246392409006}]}, {"text": "produced their task in WMT16 in document level quality estimation with winning result in two different models.", "labels": [], "entities": [{"text": "WMT16", "start_pos": 23, "end_pos": 28, "type": "DATASET", "confidence": 0.8055826425552368}, {"text": "document level quality estimation", "start_pos": 32, "end_pos": 65, "type": "TASK", "confidence": 0.67878457903862}]}, {"text": "One model used discourse features and SVR and another model employed word embedding feature and Gaussian Process for quality estimation.", "labels": [], "entities": []}, {"text": "predicted translation performance with referential translation machines at word level, sentence level and at phrase level.", "labels": [], "entities": [{"text": "translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9604260325431824}, {"text": "referential translation", "start_pos": 39, "end_pos": 62, "type": "TASK", "confidence": 0.7439802587032318}]}, {"text": "() submitted task on bi-lexical word embedding in WMT17 QE shared task, which produced promising results in sentence level Quality Estimation.", "labels": [], "entities": [{"text": "WMT17 QE shared task", "start_pos": 50, "end_pos": 70, "type": "DATASET", "confidence": 0.8278331309556961}, {"text": "sentence level Quality Estimation", "start_pos": 108, "end_pos": 141, "type": "TASK", "confidence": 0.5355575010180473}]}, {"text": "Some studies ( show that the quality of MT output along with PE can produce better result than human editor in certain situations.", "labels": [], "entities": [{"text": "MT", "start_pos": 40, "end_pos": 42, "type": "TASK", "confidence": 0.9890692830085754}, {"text": "PE", "start_pos": 61, "end_pos": 63, "type": "METRIC", "confidence": 0.92420494556427}]}, {"text": "In our work we mainly focus on word level quality estimation.", "labels": [], "entities": [{"text": "word level quality estimation", "start_pos": 31, "end_pos": 60, "type": "TASK", "confidence": 0.6582177951931953}]}, {"text": "The distributional structure of words was first described by.", "labels": [], "entities": []}, {"text": "() illustrated representations of words in semi-supervised learning.", "labels": [], "entities": []}, {"text": "proposed neural probabilistic language model by using a distributed representation of words., described how a convolutional neural network architecture could be used to make different language processing predictions, such as semantically similar words, etc.", "labels": [], "entities": []}, {"text": "proposed a fast hierarchical language model along with a feature based algorithm which automatically builds word trees from data.", "labels": [], "entities": []}, {"text": "proposed vector representation of words with the help of negative sampling (instead of softmax function) that improves both word vector quality and training speed.", "labels": [], "entities": []}, {"text": "Their work showed prediction of a word from a context by adding two word vectors from the same context.", "labels": [], "entities": [{"text": "prediction of a word from a context", "start_pos": 18, "end_pos": 53, "type": "TASK", "confidence": 0.8559846111706325}]}, {"text": "() proposed a novel approach to represent words as fixed length vectors, widely known as word2vec model and they reported state-of-theart performance on word similarity task.", "labels": [], "entities": []}, {"text": "() extend their model to vector representation of a document known as Paragraph Vector model or commonly Document-to-Vector (Doc2Vec) model.", "labels": [], "entities": []}, {"text": "This paper reports our submission in the WMT 2018 Shared Task on Word-Level Quality Estima-tion (QE task-2) on English-German (IT domain) SMT data.", "labels": [], "entities": [{"text": "WMT 2018 Shared Task on Word-Level Quality Estima-tion (QE task-2) on English-German (IT domain) SMT", "start_pos": 41, "end_pos": 141, "type": "TASK", "confidence": 0.5215946749637002}]}, {"text": "The proposed model has been developed in two ways -one using the standard Bagof-Words model and another using the Doc2Vec model.", "labels": [], "entities": [{"text": "Bagof-Words model", "start_pos": 74, "end_pos": 91, "type": "DATASET", "confidence": 0.9364516735076904}]}, {"text": "The motivation behind the use of Doc2Vec model is to achieve more accurate semantic similarity compared to the simple cosine similarity on Bag-of-Words model.", "labels": [], "entities": []}, {"text": "The Doc2Vec model captures semantic similarity which the Bag-of-Words model cannot.", "labels": [], "entities": []}, {"text": "Our word level error estimation is mainly based on Translation Error Rate () between MT and PE.", "labels": [], "entities": [{"text": "word level error estimation", "start_pos": 4, "end_pos": 31, "type": "TASK", "confidence": 0.4798867329955101}, {"text": "Translation Error Rate", "start_pos": 51, "end_pos": 73, "type": "METRIC", "confidence": 0.880391538143158}]}], "datasetContent": [{"text": "We used the WMT-2018 English-German (EN-DE) word level QE dataset for our experiments.", "labels": [], "entities": [{"text": "WMT-2018 English-German (EN-DE) word level QE dataset", "start_pos": 12, "end_pos": 65, "type": "DATASET", "confidence": 0.8845264977878995}]}, {"text": "presents the statistics of the training, development and test sets.", "labels": [], "entities": []}, {"text": "Stop words generally occur very frequently and their number of occurrences across BoW could easily mislead wordlevel QE.", "labels": [], "entities": [{"text": "BoW", "start_pos": 82, "end_pos": 85, "type": "DATASET", "confidence": 0.9775235056877136}]}, {"text": "Therefore we process the training data by removing stop words for both German 2 and English from all the data sets, i.e., neither we consider them while building our context bags, nor we consider their QE.", "labels": [], "entities": [{"text": "QE", "start_pos": 202, "end_pos": 204, "type": "METRIC", "confidence": 0.8109371662139893}]}, {"text": "We considered 9 thresholds for the BoW model.", "labels": [], "entities": [{"text": "BoW", "start_pos": 35, "end_pos": 38, "type": "DATASET", "confidence": 0.8333610892295837}]}, {"text": "shows word specific assignment of binary scores to each threshold.", "labels": [], "entities": []}, {"text": "For a word with QE decision OK, a word-threshold cell is assigned to 1 if the similarity score for the corresponding word is higher than the corresponding threshold, and   0 otherwise.", "labels": [], "entities": [{"text": "similarity score", "start_pos": 78, "end_pos": 94, "type": "METRIC", "confidence": 0.9420790076255798}]}, {"text": "For words with PE decision BAD, scores are assigned the other way round.", "labels": [], "entities": [{"text": "PE decision BAD", "start_pos": 15, "end_pos": 30, "type": "METRIC", "confidence": 0.7766145269076029}]}, {"text": "It is to be noted that our model can only predict the QE decision for words that are already seen in the training set.", "labels": [], "entities": []}, {"text": "Words that are not present in the training set (including stop words) are simply retained.", "labels": [], "entities": []}, {"text": "Kneedle algorithm on the Segments vs. F 1 -mult plot on the development set (cf.) leads to the segment 4 as the knee point and the corresponding similarity score of 0.25 (cf.) serves as the threshold, which produces the optimal F 1 -mult for the BoW model.", "labels": [], "entities": [{"text": "similarity score", "start_pos": 145, "end_pos": 161, "type": "METRIC", "confidence": 0.9693968296051025}, {"text": "BoW", "start_pos": 246, "end_pos": 249, "type": "DATASET", "confidence": 0.9205113649368286}]}], "tableCaptions": [{"text": " Table 1: Statistics of the the WMT-2018 Word Level  QE Shared Task Data Set.", "labels": [], "entities": [{"text": "WMT-2018 Word Level  QE Shared Task Data Set", "start_pos": 32, "end_pos": 76, "type": "DATASET", "confidence": 0.8423106744885445}]}, {"text": " Table 2: Segment versus Threshold values for the BOW  model", "labels": [], "entities": [{"text": "Segment", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9761031270027161}, {"text": "Threshold", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9981420040130615}]}, {"text": " Table 3: A snapshot of the intermediate table showing word-threshold pair assignment", "labels": [], "entities": []}, {"text": " Table 5: Evaluation Results on the WMT18 Word level Quality Estimation (Task 2)", "labels": [], "entities": [{"text": "WMT18 Word level Quality Estimation", "start_pos": 36, "end_pos": 71, "type": "TASK", "confidence": 0.6129490733146667}]}]}