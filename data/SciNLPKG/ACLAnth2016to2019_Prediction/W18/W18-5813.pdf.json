{"title": [{"text": "Sounds Wilde Phonetically extended embeddings for author-stylized poetry generation", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper addresses author-stylized text generation.", "labels": [], "entities": [{"text": "author-stylized text generation", "start_pos": 21, "end_pos": 52, "type": "TASK", "confidence": 0.5801765223344167}]}, {"text": "Using aversion of a language model with extended phonetic and semantic embed-dings for poetry generation we show that phonetics has comparable contribution to the overall model performance as the information on the target author.", "labels": [], "entities": [{"text": "poetry generation", "start_pos": 87, "end_pos": 104, "type": "TASK", "confidence": 0.7714627683162689}]}, {"text": "Phonetic information is shown to be important for English and Russian language.", "labels": [], "entities": []}, {"text": "Humans tend to attribute machine generated texts to the target author.", "labels": [], "entities": []}], "introductionContent": [{"text": "Generative models for natural languages and for poetry specifically are discussed for more than fifty years.", "labels": [], "entities": []}, {"text": "provides a detailed overview of generative poetry techniques.", "labels": [], "entities": [{"text": "generative poetry", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.9820474088191986}]}, {"text": "This particular paper addresses the issue of author stylized poetry) and shows the importance of phonetics for the author-stylized poetry generation.", "labels": [], "entities": []}, {"text": "The structure of the poem can vary across different languages starting with highly specific and distinct structures of Chinese poems ( and finishing with poems where formal structure hardly exists, e.g. American poetry of the twentieth century (say, the lyrics of Charles Bukowski) or so-called white poems in Russian.", "labels": [], "entities": []}, {"text": "The structure and standards of poems can depend on various factors primarily phonetic in thier nature.", "labels": [], "entities": []}, {"text": "In the broadest sense, rhymes in a classical western sonnet, a structure of a Persian ruba'i, a sequence of tones in a Chinese quatrain or a structure within rap bars could be expressed as a set of phonetic rules based on a certain understanding of expressiveness and euphony shared across a given culture or, sometimes, an artistic community.", "labels": [], "entities": []}, {"text": "Some cultures and styles also have particular semantic limitations or 'standards', for example, 'centrality' of certain topics in classical Japanese poetry, see.", "labels": [], "entities": []}, {"text": "We do not make attempts to address high-level semantic structure, however one can add some kind of pseudo-semantic rules to the model discussed further, say via some mechanism inline with ( or (.", "labels": [], "entities": []}, {"text": "The importance of phonetics in poetical texts was broadly discussed among Russian futuristic poets, see.", "labels": [], "entities": []}, {"text": "Several Russian linguistic circles and art groups (particularly OPOJAZ) in the first quarter of 20th century were actively discussing the concept of the abstruse language, see, stressing also that the form of a poem, and especially its acoustic structure, is a number one priority for the future of literature.", "labels": [], "entities": []}, {"text": "In their recent paper ( have challenged the broadly accepted idea that sound and meaning are not interdependent: unrelated languages very often use (or avoid) the same sounds for specific referents.", "labels": [], "entities": []}, {"text": "In ( and () it was show that acoustic word embeddings improve algorithm performance on a number of NLP tasks.", "labels": [], "entities": []}, {"text": "In line with these ideas, one of the key features of the model that we discuss below is its concatenated embedding that contains information on the phonetics of every word preprocessed by a bi-directional Long Short-Term Memory (LSTM) network alongside with its vectorized semantic representation.", "labels": [], "entities": []}, {"text": "In) a model for generation of texts resembling the writing style of a particular author within the training data set was proposed.", "labels": [], "entities": [{"text": "training data set", "start_pos": 99, "end_pos": 116, "type": "DATASET", "confidence": 0.7193439602851868}]}, {"text": "In this paper we quantify the stylistic similarity of the generated texts and show the importance of extension of the word embeddings with phonetic information for the overall performance of the model.", "labels": [], "entities": []}, {"text": "The proposed model might also be applicable to prose, but diverse phonetic structure of the poetry discussed above makes it better suited for the purposes of this paper.", "labels": [], "entities": []}, {"text": "Also, since one would like to incorporated human judgement of the generated text and measure how well a human reader can attribute generated text to the target author, poetry seems preferable to prose for its stylistic expressiveness.", "labels": [], "entities": []}, {"text": "The contribution of this paper is three-fold: (1) we propose an LSTM with extended phonetic and semantic embeddings and quantify the quality of the obtained stylized poems both subjectively through a survey and objectively with BLEU metrics; (2) we show that phonetic information plays key role in a author-stylized poetry generation we demonstrate that the proposed approach works in a multilingual setting, providing examples in English and in Russian.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 228, "end_pos": 232, "type": "METRIC", "confidence": 0.9970347881317139}]}], "datasetContent": [{"text": "Two proprietary datasets of English and Russian poetry were used for training.", "labels": [], "entities": []}, {"text": "All punctuation was deleted, every character was transferred to a lowercase.", "labels": [], "entities": []}, {"text": "No other preprocessing was made.", "labels": [], "entities": []}, {"text": "The datasets sizes can be found in The model produces results of comparable quality for both languages, so in order to make this paper shorter, we further address generative poems in English only and provide the experimental results for Russian in the Appendix.", "labels": [], "entities": [{"text": "generative poems", "start_pos": 163, "end_pos": 179, "type": "TASK", "confidence": 0.8989858031272888}]}, {"text": "We want to emphasize that we do not see any excessive difficulties in implementation of the proposed model for other languages for which one can form a training corpus and provide a phonetically transcribed vocabulary.", "labels": [], "entities": []}, {"text": "shows some generated stylized poetry examples.", "labels": [], "entities": []}, {"text": "The model captures syntactic characteristics of the author (note the double negation in the first and the last line of Neuro-marley) alongside with the vocabulary ('burden', 'darkness', 'fears' could be subjectively associated with gothic lyrics of Poe, whereas 'sunshine', 'fun', 'fighting every rule' could be associated with positive yet rebellious reggae music).", "labels": [], "entities": []}, {"text": "Author-specific vocabulary can technically imply specific phonetics that characterizes a given author, however this implication is not self evident and generally speaking does not have to hold.", "labels": [], "entities": []}, {"text": "As we demonstrate later, phonetics does, indeed, contribute to the author stylization significantly.", "labels": [], "entities": []}, {"text": "In (Tikhonov and Yamshchikov, 2018a) the detailed description of the experiments is provided alongside with anew metric for automated stylization quality estimation -sample cross entropy.", "labels": [], "entities": []}, {"text": "In this submission we specifically address the results that deal with the phonetics of the generated texts.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Parameters of the training datasets.", "labels": [], "entities": [{"text": "Parameters", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9273896217346191}]}, {"text": " Table 2: Number of words in the training datasets for  human-peer tested lyrics.", "labels": [], "entities": []}, {"text": " Table 2. This  allowed to have approximately 330 000 verses in  train dataset and another 10 000 verses forming a  test dataset for Russian poetry. For English poetry  train data consisted of 360 000 verses with approx- imately 40 000 verses forming the test data.  The model was trained for English (William  Shakespeare, Edgar Allan Poe, Lewis Carroll, Os- car Wilde and Bob Marley as well as lyrics of  the American band Nirvana and UK band Muse)  and Russian (Alexander Pushkin, Sergey Esenin,", "labels": [], "entities": []}, {"text": " Table 5: Results of a survey with 140 respondents. Shares of each out of 5 different answers given by people when  reading an exempt of a poetic text by the author stated in the first column. The two biggest values in each row are  marked with * and ** and a bold typeface.", "labels": [], "entities": []}]}