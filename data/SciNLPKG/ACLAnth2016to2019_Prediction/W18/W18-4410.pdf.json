{"title": [{"text": "A K-Competitive Autoencoder for Aggression Detection in Social Media text", "labels": [], "entities": [{"text": "Aggression Detection", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.9203391671180725}]}], "abstractContent": [{"text": "We present an approach to detect aggression from social media text in this work.", "labels": [], "entities": []}, {"text": "A winner-takes-all autoencoder, called Emoti-KATE is proposed for this purpose.", "labels": [], "entities": [{"text": "Emoti-KATE", "start_pos": 39, "end_pos": 49, "type": "DATASET", "confidence": 0.9066144824028015}]}, {"text": "Using a log-normalized, weighted word-count vector at input dimensions, the autoencoder simulates a competition between neurons in the hidden layer to minimize the reconstruction loss between the input and final output layers.", "labels": [], "entities": []}, {"text": "We have evaluated the performance of our system on the datasets provided by the organizers of TRAC workshop, 2018.", "labels": [], "entities": [{"text": "TRAC workshop", "start_pos": 94, "end_pos": 107, "type": "DATASET", "confidence": 0.8552513718605042}]}, {"text": "Using the encoding generated by Emoti-KATE, a 3-way classification is performed for every social media text in the dataset.", "labels": [], "entities": [{"text": "Emoti-KATE", "start_pos": 32, "end_pos": 42, "type": "DATASET", "confidence": 0.9243186712265015}]}, {"text": "Each data point is classified as 'Overtly Aggressive', 'Covertly Aggressive' or 'Non-aggressive'.", "labels": [], "entities": [{"text": "Covertly Aggressive", "start_pos": 56, "end_pos": 75, "type": "METRIC", "confidence": 0.8871402144432068}]}, {"text": "Results show that our proposed method is able to achieve promising results on some of these datasets.", "labels": [], "entities": []}, {"text": "In this paper, we have described the effects of introducing an winner-takes-all autoencoder for the task of aggression detection, reported its performance on four different datasets, analyzed some of its limitations and how to improve its performance in future works.", "labels": [], "entities": [{"text": "aggression detection", "start_pos": 108, "end_pos": 128, "type": "TASK", "confidence": 0.7589063346385956}]}], "introductionContent": [{"text": "With the rapid growth of unregulated social media platforms, a major problem coming to surface is the aggressive nature of text used by people while interacting in these mediums.", "labels": [], "entities": []}, {"text": "Manual monitoring or filtering of this user generated data is a challenging task due to its sheer scale.", "labels": [], "entities": []}, {"text": "Therefore, automatic detection of aggressive text is the logical first step to combat the issue.", "labels": [], "entities": [{"text": "automatic detection of aggressive text", "start_pos": 11, "end_pos": 49, "type": "TASK", "confidence": 0.8151181638240814}]}, {"text": "There has been an increased interest among contemporary researchers to propose an acceptable solution of this problem in recent years.", "labels": [], "entities": []}, {"text": "However, proposing an automated solution for this problem has some inherent obstacles.", "labels": [], "entities": []}, {"text": "One of the most challenging obstacles among this to annotate these texts with an appropriate sentiment score.", "labels": [], "entities": []}, {"text": "Social media texts are almost always short in length, and exhibit ambiguous grammatical syntax including abbreviated forms, typo errors, repeated alphabets to emphasize intentions as well as coinage of new words.", "labels": [], "entities": []}, {"text": "Additionally, detecting aggression on social media posts or comments is especially challenging due to its lack of context.", "labels": [], "entities": [{"text": "detecting aggression on social media posts or comments", "start_pos": 14, "end_pos": 68, "type": "TASK", "confidence": 0.8807368502020836}]}, {"text": "Almost all of these posts are provide very little to no context.", "labels": [], "entities": []}, {"text": "Detecting common 'hate-words' using a bag-of-words analysis does notwork in these cases as conventionally non-aggressive words can be deemed aggressive when used sarcastically.", "labels": [], "entities": []}, {"text": "In this paper we have proposed Emoti-KATE, a winner-takes-all autoencoder for representing social media text.", "labels": [], "entities": []}, {"text": "Performance of our autoencoder is evaluated on a downstream task of classifying the text based on its aggression level.", "labels": [], "entities": []}, {"text": "We have broadly categorized asocial media post or comment into one of three categories: Overtly Aggressive, Covertly Aggressive and Non-Aggressive.", "labels": [], "entities": []}, {"text": "In recent times, researchers (; have established that autoencoders can be effectively used to learn representations of document text for various applications.", "labels": [], "entities": []}, {"text": "However, they have some inherent limitations.", "labels": [], "entities": []}, {"text": "As) has pointed out, in a traditional autoencoder, contributions of most of the hidden neurons in reconstructing the input vector are often redundant.", "labels": [], "entities": []}, {"text": "They have shown that introducing competition among these hidden neurons can help get rid of these redundancies.", "labels": [], "entities": []}, {"text": "The output vectors generated by such winner-takes-all approach outperform most of the popular, contemporary document representation techniques as well.", "labels": [], "entities": [{"text": "document representation", "start_pos": 108, "end_pos": 131, "type": "TASK", "confidence": 0.7129683792591095}]}, {"text": "Inspired by their success, we have taken a similar approach in this work.", "labels": [], "entities": []}, {"text": "Emoti-KATE introduces a K-competition layer between the input and output layers to generate the vector representation of each social media text.", "labels": [], "entities": [{"text": "Emoti-KATE", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9070357084274292}]}, {"text": "We have evaluated the performance of our approach on a dataset of 15,000 aggression-annotated Facebook posts and comments each in Hindi (in both Roman and Devanagari script) and English.", "labels": [], "entities": []}, {"text": "After basic preprocessing on the raw data 1 , the winner-takes-all autoencoder is deployed with a log-normalized vector at its input dimensions.", "labels": [], "entities": []}, {"text": "Results show that while our system's performance is promising in case of English texts (weighted F1 score of 0.5694), the classifier has much scope of improvement for Hindi texts (weighted F1 score of 0.4189).", "labels": [], "entities": [{"text": "F1 score", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9732032120227814}, {"text": "F1 score", "start_pos": 189, "end_pos": 197, "type": "METRIC", "confidence": 0.9586362242698669}]}, {"text": "The main contribution of this work is an exhaustive investigation into the performance of K-competitive autoencoders) in identifying aggression level in short, sparsely contexualized social media posts and comments.", "labels": [], "entities": [{"text": "identifying aggression level in short, sparsely contexualized social media posts and comments", "start_pos": 121, "end_pos": 214, "type": "TASK", "confidence": 0.6392341485390296}]}, {"text": "Our experimental result suggests that introducing a competitive hidden layer in a autoencoder framework improves the performance of aggression detection in sparse social media texts.", "labels": [], "entities": [{"text": "aggression detection in sparse social media texts", "start_pos": 132, "end_pos": 181, "type": "TASK", "confidence": 0.715177310364587}]}, {"text": "A complete pseudocode of our system is presented in Algorithm 1.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: Section 2 gives a brief overview of the work already done in this field.", "labels": [], "entities": []}, {"text": "Section 3 describes the details of the dataset, preprocessing steps and the system we have used to address the problem.", "labels": [], "entities": []}, {"text": "Section 4 presents the analysis of results and finally, the conclusion and future scopes are discussed in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "A K-competitive autoencoder for aggression detection in social media text is proposed in this work.", "labels": [], "entities": [{"text": "aggression detection in social media text", "start_pos": 32, "end_pos": 73, "type": "TASK", "confidence": 0.7501093794902166}]}, {"text": "A detailed description of the dataset, some of its interesting characteristics and our approach towards this task will be presented in this section.", "labels": [], "entities": []}, {"text": "The aggression-annotated dataset used in this shared task() has been collected and prepaed by.", "labels": [], "entities": []}, {"text": "Collecting approximately 18k tweets and 21k facebook comments from social media users in India, they used Crowdflower, a crowd-sourced platform to annotate the entire dataset.", "labels": [], "entities": []}, {"text": "This dataset is code-mixed i.e., it contains text in English and Hindi (written in both Roman and Devanagari script).", "labels": [], "entities": []}, {"text": "A total of 3 top-level and 10 level-2 tags were assigned to the entire dataset.", "labels": [], "entities": []}, {"text": "In this shared task, we have only considered the top-level tags, which are as follows: 'Overtly Aggressive', 'Covertly Aggressive', and 'Non-aggressive'.", "labels": [], "entities": []}, {"text": "The organizers of TRAC 2018 have divided this dataset into a number of smaller datasets based on their origin (social media platform from where it was collected) and language.", "labels": [], "entities": []}, {"text": "This resulted in 4 different datasets for this task, which are as follows, English-Facebook dataset, English-Social Media dataset, Hindi-Facebook dataset, and Hindi-Social Media dataset.", "labels": [], "entities": [{"text": "English-Facebook dataset", "start_pos": 75, "end_pos": 99, "type": "DATASET", "confidence": 0.8009387850761414}, {"text": "English-Social Media dataset", "start_pos": 101, "end_pos": 129, "type": "DATASET", "confidence": 0.6271518071492513}, {"text": "Hindi-Facebook dataset", "start_pos": 131, "end_pos": 153, "type": "DATASET", "confidence": 0.6760122179985046}, {"text": "Hindi-Social Media dataset", "start_pos": 159, "end_pos": 185, "type": "DATASET", "confidence": 0.6836726168791453}]}, {"text": "We have evaluated and reported the performance of Emoti-KATE in Section 4, for each of these datasets.", "labels": [], "entities": [{"text": "Emoti-KATE", "start_pos": 50, "end_pos": 60, "type": "DATASET", "confidence": 0.8548458814620972}]}, {"text": "Our system performed best in English Facebook texts with a weighted F1 score of 0.5694 for the input vector X 3 , i.e., the input vector that considered Sentiment Score weighted Word Count vector augmented with capitalization feature and 'hashtag' analyzer.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9802953004837036}]}, {"text": "The primary reason of our system performing better on this particular dataset is the length of the texts.", "labels": [], "entities": []}, {"text": "Typically, texts present in this dataset were longer offering more context, resulting in a less sparse vector which ultimately improved the performance of the classifier.", "labels": [], "entities": []}, {"text": "Performance of Emoti-KATE on this dataset, for three different variations of input vectors is presented in.", "labels": [], "entities": []}, {"text": "We have also reported a class wise performance analysis for the best performance (X 3 ) of our system in.", "labels": [], "entities": []}, {"text": "A heatmap representing the confusion matrix of this run is presented in  Even though our approach achieved promising score in one of the English datasets, for the English social media (Twitter) dataset, it has significant scope of improvement.", "labels": [], "entities": [{"text": "English datasets", "start_pos": 137, "end_pos": 153, "type": "DATASET", "confidence": 0.8782539069652557}, {"text": "English social media (Twitter) dataset", "start_pos": 163, "end_pos": 201, "type": "DATASET", "confidence": 0.5620556814329964}]}, {"text": "The best run for this dataset could only achieve a weighted F1 score of 0.3379.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.985283762216568}]}, {"text": "Two main reasons for this are as follows: (1) social media texts, specially tweets consists of a lot of abbreviated forms, repeating characters in a word, newly coined terms etc.", "labels": [], "entities": []}, {"text": "which was not efficiently normalized, therefore not present during the training of the classifier, and (2) length of the texts in this dataset was also very short which eventually resulted in sparse vectors.", "labels": [], "entities": []}, {"text": "Performance of our system for three different variations of input vectors has been described in.", "labels": [], "entities": []}, {"text": "We have also reported a class wise performance analysis for the best performance (X 1 ) of our system in.", "labels": [], "entities": []}, {"text": "The heatmap representing a confusion matrix for this run is presented in.", "labels": [], "entities": []}, {"text": "For both the datasets in English, one interesting observation that came up from the confusion matrix is that the system is biased towards the class NAG and this resulted in achieving higher recall in that particular class (highest 80.639%).", "labels": [], "entities": [{"text": "recall", "start_pos": 190, "end_pos": 196, "type": "METRIC", "confidence": 0.9993884563446045}]}, {"text": "Similar to English, our system performs better in classifying Hindi Facebook texts than the social media dataset (Twitter) by achieving a weighted F1 score of 0.4189, which is higher than the random baseline.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 147, "end_pos": 155, "type": "METRIC", "confidence": 0.9826284646987915}]}, {"text": "However, this dataset failed to score at par with the English dataset mainly due to the lack of good quality sentiment lexicon resource in Hindi.", "labels": [], "entities": [{"text": "English dataset", "start_pos": 54, "end_pos": 69, "type": "DATASET", "confidence": 0.7232735008001328}]}, {"text": "Performance of Emoti-KATE on this dataset, for three different variations of input vectors is presented in.", "labels": [], "entities": []}, {"text": "We have also reported a class wise performance analysis for the best performance (X 3 ) of our system in.", "labels": [], "entities": []}, {"text": "A heatmap representing the confusion matrix of this run is presented in.", "labels": [], "entities": []}, {"text": "Similar to English-Social Media dataset, there is a lot of scope to improve the performance of our system on the Hindi-Social Media dataset.", "labels": [], "entities": [{"text": "English-Social Media dataset", "start_pos": 11, "end_pos": 39, "type": "DATASET", "confidence": 0.7563901940981547}, {"text": "Hindi-Social Media dataset", "start_pos": 113, "end_pos": 139, "type": "DATASET", "confidence": 0.7996525367101034}]}, {"text": "We observed that unlike the English dataset, the inclusion of the 'hashtag' analyzer module did not improve the performance of this particular dataset.", "labels": [], "entities": [{"text": "English dataset", "start_pos": 28, "end_pos": 43, "type": "DATASET", "confidence": 0.7258753329515457}]}, {"text": "This is because (1) 'hashtags' only consisted about 10 to 30 percent of the entire text on average which was not enough to offset the performance for the entire text content, and (2) the 'hashtag' segmentation module did not leverage a code mixed corpus to generate all possible unique segmentations for this dataset.", "labels": [], "entities": []}, {"text": "Training Emoti-KATE on sufficiently large code mixed corpus for 'hashtag' analysis as well as feature vector generation mark some of the most significant future scopes of research.", "labels": [], "entities": [{"text": "hashtag' analysis", "start_pos": 65, "end_pos": 82, "type": "TASK", "confidence": 0.7487359642982483}, {"text": "feature vector generation", "start_pos": 94, "end_pos": 119, "type": "TASK", "confidence": 0.6577937404314677}]}, {"text": "Performance of our system on this dataset, for three different variations of input vectors is presented in.", "labels": [], "entities": []}, {"text": "Similar to the rest of the datasets, We have reported a class wise performance analysis for the best performance (X 2 ) of our system in for this dataset also.", "labels": [], "entities": []}, {"text": "A heatmap representing the confusion matrix of this run is also presented in.", "labels": [], "entities": []}, {"text": "We observe that our system is biased towards the class CAG in Hindi datasets.", "labels": [], "entities": [{"text": "Hindi datasets", "start_pos": 62, "end_pos": 76, "type": "DATASET", "confidence": 0.6762133240699768}]}, {"text": "Interestingly, highest recall values were obtained for the class CAG for both of the Hindi datasets in our experimental setup.", "labels": [], "entities": [{"text": "recall", "start_pos": 23, "end_pos": 29, "type": "METRIC", "confidence": 0.9994426369667053}, {"text": "Hindi datasets", "start_pos": 85, "end_pos": 99, "type": "DATASET", "confidence": 0.745492696762085}]}], "tableCaptions": [{"text": " Table 2: Results of Emoti-KATE on experimental datasets", "labels": [], "entities": [{"text": "Emoti-KATE", "start_pos": 21, "end_pos": 31, "type": "DATASET", "confidence": 0.8814040422439575}]}, {"text": " Table 3: Class-wise distribution of  Precision and Recall for the best  result observed (X 3 )", "labels": [], "entities": [{"text": "Precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.998471200466156}, {"text": "Recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9981330037117004}]}, {"text": " Table 2. We have also reported a class wise performance analysis for the best performance (X 3 ) of  our system in", "labels": [], "entities": []}, {"text": " Table 5. A heatmap representing the confusion matrix of this run is presented in", "labels": [], "entities": []}, {"text": " Table 4: Class-wise distribution of  Precision and Recall for the best  result observed (X 1 )", "labels": [], "entities": [{"text": "Precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9984234571456909}, {"text": "Recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9981545805931091}]}, {"text": " Table 5: Class-wise distribution of  Precision and Recall for the best  result observed (X 3 )", "labels": [], "entities": [{"text": "Precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9984161853790283}, {"text": "Recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9980260133743286}]}, {"text": " Table 6: Class-wise distribution of  Precision and Recall for the best  result observed (X 2 )", "labels": [], "entities": [{"text": "Precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9984878301620483}, {"text": "Recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9981772899627686}]}]}