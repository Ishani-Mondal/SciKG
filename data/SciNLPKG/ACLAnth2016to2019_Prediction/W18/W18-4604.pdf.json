{"title": [{"text": "Comparing morphological complexity of Spanish, Otomi and Nahuatl", "labels": [], "entities": []}], "abstractContent": [{"text": "We use two small parallel corpora for comparing the morphological complexity of Spanish, Otomi and Nahuatl.", "labels": [], "entities": []}, {"text": "These are languages that belong to different linguistic families, the latter are low-resourced.", "labels": [], "entities": []}, {"text": "We take into account two quantitative criteria, on one hand the distribution of types over tokens in a corpus, on the other, perplexity and entropy as indicators of word structure predictability.", "labels": [], "entities": [{"text": "word structure predictability", "start_pos": 165, "end_pos": 194, "type": "TASK", "confidence": 0.6498678922653198}]}, {"text": "We show that a language can be complex in terms of how many different morphological word forms can produce, however, it maybe less complex in terms of predictability of its internal structure of words.", "labels": [], "entities": []}], "introductionContent": [{"text": "Morphology deals with the internal structure of words (.", "labels": [], "entities": []}, {"text": "Languages of the world have different word production processes.", "labels": [], "entities": [{"text": "word production", "start_pos": 38, "end_pos": 53, "type": "TASK", "confidence": 0.7122630029916763}]}, {"text": "Morphological richness vary from language to language, depending on their linguistic typology.", "labels": [], "entities": [{"text": "Morphological richness", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8719137907028198}]}, {"text": "In natural language processing (NLP), taking into account the morphological complexity inherent to each language could be important for improving or adapting the existing methods, since the amount of semantic and grammatical information encoded at the word level, may vary significantly from language to language.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 3, "end_pos": 36, "type": "TASK", "confidence": 0.8090082307656606}]}, {"text": "Conceptualizing and quantifying linguistic complexity is not an easy task, many quantitative and qualitative dimensions must betaken into account.", "labels": [], "entities": [{"text": "quantifying linguistic complexity", "start_pos": 20, "end_pos": 53, "type": "TASK", "confidence": 0.7620376547177633}]}, {"text": "On one hand we can try to answer what is complexity in a language and which mechanisms express it, on the other hand, we can try to find out if there is a language with more complex phenomena (phonological, morphological, syntactical) than other and how can we measure it. distinguishes between two types of complexity: the absolute, which defines complexity in terms of the number of parts of a system; and the relative, which is related to the cost and difficulty faced by language users.", "labels": [], "entities": []}, {"text": "Some authors focuses in the absolute approach since it is less subjective.", "labels": [], "entities": []}, {"text": "Another common complexity distinction is between global and particular.", "labels": [], "entities": []}, {"text": "Global complexity characterizes entire languages, e.g., as easy or difficult to learn, while particular complexity refers only to a level of the whole language (for example phonological complexity, morphological complexity, syntactical complexity).", "labels": [], "entities": []}, {"text": "We focus on morphological complexity.", "labels": [], "entities": []}, {"text": "Many definitions of this term have been proposed.", "labels": [], "entities": []}, {"text": "From the computational linguistics perspective there has been a special interest in corpus based approaches to quantify it, i.e., methods that estimate the morphological complexity of a language directly from the production of morphological instances over a corpus.", "labels": [], "entities": []}, {"text": "This type of approach usually represents a relatively easy and reproducible way to quantify complexity without the strict need of linguistic annotated data.", "labels": [], "entities": []}, {"text": "The underlying intuition of corpus based methods is that morphological complexity depends on the morphological system of a language, like its inflectional and derivational processes.", "labels": [], "entities": []}, {"text": "Avery productive system will produce a lot of different word forms.", "labels": [], "entities": []}, {"text": "This morphological richness can be captured with several statistical measures, e.g., information theory measures or type token relationships.", "labels": [], "entities": []}, {"text": "For example, Bybee (2010, p. 9) affirms that \"the token frequency of certain items in constructions [i.e., words] as well as the range of types determines representation of the construction as well as its productivity\".", "labels": [], "entities": [{"text": "Bybee", "start_pos": 13, "end_pos": 18, "type": "DATASET", "confidence": 0.9599111676216125}]}, {"text": "In this work, we are interested in using corpus based approaches; however, we would like to quantify the complexity not only by the type and token distributions over a corpus, but also by taking into account other important dimension: the predictability of a morph sequence (.", "labels": [], "entities": []}, {"text": "This is a preliminary work that takes as a case of study the distant languages Otomi, Nahuatl and Spanish.", "labels": [], "entities": []}, {"text": "The general idea is to use parallel corpora, type-token relationship and some NLP strategies for measuring the predictability in statistical language models.", "labels": [], "entities": []}, {"text": "Additionally, most of the previous works do not analyze how the complexity changes when different types of morphological normalization procedures are applied to a language, e.g., lemmatization, stemming, morphological segmentation.", "labels": [], "entities": [{"text": "morphological segmentation", "start_pos": 204, "end_pos": 230, "type": "TASK", "confidence": 0.7123797386884689}]}, {"text": "This information could be useful for linguistic analysis and for measuring the impact of different word form normalization tools depending of the language.", "labels": [], "entities": [{"text": "linguistic analysis", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.710270881652832}, {"text": "word form normalization", "start_pos": 99, "end_pos": 122, "type": "TASK", "confidence": 0.7207181056340536}]}, {"text": "In this work, we analyze how the type-token relationship changes using different types of morphological normalization techniques.", "labels": [], "entities": []}], "datasetContent": [{"text": "We work with two language pairs that are spoken in the same country (Mexico) but they are typologically distant languages: Spanish (Indo-European)-Nahuatl (Uto-Aztecan) and Spanish-Otomi (OtoManguean).", "labels": [], "entities": []}, {"text": "Both, Nahuatl and Otomi are low-resource languages that face scarcity of digital parallel and monolingual corpora.", "labels": [], "entities": []}, {"text": "Nahuatl is an indigenous language with agglutinative and polysynthethic morphological phenomena.", "labels": [], "entities": []}, {"text": "It can agglutinate many different prefixes and suffixes to build complex words.", "labels": [], "entities": []}, {"text": "Spanish also has rich morphology, but it mainly uses suffixes and it can have a fusional behavior, where morphemes can be fused or overlaid into a single one that encodes several grammatical meanings.", "labels": [], "entities": []}, {"text": "Regarding to Otomi, its morphology also has a fusional tendency, and it is head-marking.", "labels": [], "entities": []}, {"text": "Otomi morphology is usually considered quite complex (Palancar, 2012) as it exhibits different phenomena like stem alternation, inflectional class changes and suprasegmental variation, just to mention some.", "labels": [], "entities": [{"text": "Otomi morphology", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.752918928861618}]}, {"text": "Since we are dealing with low resource languages that have a lot of dialectal and orthographic variation, it is difficult to obtain a standard big parallel corpus.", "labels": [], "entities": []}, {"text": "We work with two different parallel corpora, i.e., Spanish-Nahuatl and Spanish-Otomi.", "labels": [], "entities": []}, {"text": "Therefore the complexity comparisons are always in reference to Spanish.", "labels": [], "entities": []}, {"text": "We used a Spanish-Nahuatl parallel corpus created by.", "labels": [], "entities": []}, {"text": "However, we used only a subset since the whole corpus is not homogeneous, i.e., it comprises several Nahuatl dialects, sources, periods of time and it lacks of a general orthographic normalization.", "labels": [], "entities": []}, {"text": "We chose the texts that had a more or less systematic writing.", "labels": [], "entities": []}, {"text": "On the other hand, we used a Spanish-Otomi parallel corpus (Lastra, 1992) conformed by 38 texts transcribed from speech.", "labels": [], "entities": []}, {"text": "This corpus was obtained in San Andr\u00e9s Cuexcontitlan.", "labels": [], "entities": []}, {"text": "It is principally composed by narrative texts, but also counts with dialogues and elicited data.", "labels": [], "entities": []}, {"text": "shows the size of the parallel corpora used for the experiments.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Size of the parallel corpus", "labels": [], "entities": [{"text": "Size", "start_pos": 10, "end_pos": 14, "type": "TASK", "confidence": 0.9565364122390747}]}, {"text": " Table 2: TTR for Nahuatl-Spanish corpus", "labels": [], "entities": [{"text": "TTR", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.8255930542945862}]}, {"text": " Table 3: TTR for Otomi-Spanish corpus", "labels": [], "entities": [{"text": "TTR", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9306091070175171}]}, {"text": " Table 4: Perplexity obtained in the different parallel corpora", "labels": [], "entities": [{"text": "Perplexity", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9220643043518066}]}, {"text": " Table 5: Entropy obtained in the different parallel corpora", "labels": [], "entities": [{"text": "Entropy", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9422083497047424}]}]}