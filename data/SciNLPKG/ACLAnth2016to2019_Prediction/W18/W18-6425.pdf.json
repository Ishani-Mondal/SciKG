{"title": [{"text": "The University of Helsinki submissions to the WMT18 news task", "labels": [], "entities": [{"text": "WMT18 news", "start_pos": 46, "end_pos": 56, "type": "DATASET", "confidence": 0.9456090927124023}]}], "abstractContent": [{"text": "This paper describes the University of Helsinki's submissions to the WMT18 shared news translation task for English-Finnish and English-Estonian, in both directions.", "labels": [], "entities": [{"text": "WMT18 shared news translation task", "start_pos": 69, "end_pos": 103, "type": "TASK", "confidence": 0.697217482328415}]}, {"text": "This year, our main submissions employ a novel neural architecture, the Transformer, using the open-source OpenNMT framework.", "labels": [], "entities": []}, {"text": "Our experiments couple domain labeling and fine tuned multilingual models with shared vocabularies between the source and target language, using the provided parallel data of the shared task and additional back-translations.", "labels": [], "entities": []}, {"text": "Finally, we compare, for the English-to-Finnish case, the effectiveness of different machine translation architectures, starting from a rule-based approach to our best neural model, analyzing the output and highlighting future research.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 85, "end_pos": 104, "type": "TASK", "confidence": 0.7106384634971619}]}], "introductionContent": [{"text": "The University of Helsinki participated in the WMT 2018 shared task on news translation with seven primary submissions.", "labels": [], "entities": [{"text": "WMT 2018 shared task on news translation", "start_pos": 47, "end_pos": 87, "type": "TASK", "confidence": 0.6724493333271572}]}, {"text": "While the main focus of our work lay on the English-to-Finnish translation direction, we also participated in the Finnishto-English, English-to-Estonian and Estonian-toEnglish translation directions.", "labels": [], "entities": [{"text": "English-to-Finnish translation direction", "start_pos": 44, "end_pos": 84, "type": "TASK", "confidence": 0.6307697097460429}]}, {"text": "In 2017, the University of Helsinki participated in WMT with an in-house implementation of an attentional encoder-decoder architecture based on the Theano framework, called HNMT ( \u00a8.", "labels": [], "entities": [{"text": "WMT", "start_pos": 52, "end_pos": 55, "type": "TASK", "confidence": 0.8143473863601685}, {"text": "Theano framework", "start_pos": 148, "end_pos": 164, "type": "DATASET", "confidence": 0.9099050760269165}]}, {"text": "Since then, the development of Theano has stopped, and various open-source Neural Machine Translation (NMT) toolkits based on alternative frameworks have been made available (.", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT)", "start_pos": 75, "end_pos": 107, "type": "TASK", "confidence": 0.8279097775618235}]}, {"text": "In parallel, a novel neural network architecture for machine translation, called Transformer, has been introduced (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.7728258073329926}]}, {"text": "The Transformer follows the encoder-decoder paradigm, but does not use any recurrent layers.", "labels": [], "entities": []}, {"text": "Instead, its architecture relies primarily on attention mechanisms, stacking on each layer multiple attention components.", "labels": [], "entities": []}, {"text": "Preliminary experiments with the Transformer architecture and its implementation in OpenNMT-py ( showed consistent performance improvements compared to our 2017 architecture.", "labels": [], "entities": []}, {"text": "Consequently, we used this setup for our main WMT 2018 submissions.", "labels": [], "entities": [{"text": "WMT 2018 submissions", "start_pos": 46, "end_pos": 66, "type": "TASK", "confidence": 0.5645676155885061}]}, {"text": "For English-Finnish, our submissions also include a rule-based system, an SMT system, and a NMT system making use of a morphological analyzer and generator.", "labels": [], "entities": [{"text": "SMT", "start_pos": 74, "end_pos": 77, "type": "TASK", "confidence": 0.9831615686416626}]}, {"text": "This year's WMT news translation task contains a multilingual sub-track, which includes all models that make use of third language data.", "labels": [], "entities": [{"text": "WMT news translation task", "start_pos": 12, "end_pos": 37, "type": "TASK", "confidence": 0.8728131353855133}]}, {"text": "We trained a multilingual model with data coming from three languages, English, Finnish and Estonian and then fine-tuned on a single language pair.", "labels": [], "entities": []}, {"text": "We also generated synthetic English-Estonian data by pivoting through Finnish.", "labels": [], "entities": []}, {"text": "Additionally, following recent approaches we added a domain label to each input sentence, according to the data source.", "labels": [], "entities": []}, {"text": "For example, each sentence from the Europarl corpus was prepended with the EUROPARL label.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 36, "end_pos": 51, "type": "DATASET", "confidence": 0.9908595979213715}, {"text": "EUROPARL", "start_pos": 75, "end_pos": 83, "type": "DATASET", "confidence": 0.8601470589637756}]}, {"text": "The overall idea of domain labelling is that data coming from different sources are of different quality and represent different genres and writing styles.", "labels": [], "entities": []}, {"text": "In this way, the translation model can be informed of the data source without increasing the number of parameters.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we detail the setup of our experiments.", "labels": [], "entities": []}, {"text": "We first describe the size of the training data and the details of the training; we then report and discuss the performance of each model according to the BLEU score as reported on the online evaluation matrix . shows the statistics on the number of training sentences.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 155, "end_pos": 159, "type": "METRIC", "confidence": 0.9984800219535828}]}, {"text": "The backtranslations allow us to more than triple the original size of the training data for all the directions.", "labels": [], "entities": []}, {"text": "We trained our models: BLEU-cased scores on newstest2018 for the English-Estonian language pair in various configurations using domain labels (Label), backtranslated data (Back), or synthetic data (Synth).", "labels": [], "entities": [{"text": "BLEU-cased", "start_pos": 23, "end_pos": 33, "type": "METRIC", "confidence": 0.9990022778511047}]}, {"text": "Our primary submissions are marked with *.", "labels": [], "entities": []}, {"text": "for 20 epochs, evaluating each of them on the development set after every epoch, taking the best iteration as final model.", "labels": [], "entities": []}, {"text": "As hyper-parameters, we used the base version of the Transformer architecture, following the suggestion of the OpenNMT-py tool, 5 including a shared word embedding space between encoder and decoder among others.", "labels": [], "entities": []}, {"text": "Unlike last year, we did not include any averaging or ensembling techniques.", "labels": [], "entities": []}, {"text": "shows the performance of our models for the EnglishEstonian language pair.", "labels": [], "entities": []}, {"text": "In general, the best models include back-translation and synthetic data, improving the BLEU score by around 4 points.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 87, "end_pos": 97, "type": "METRIC", "confidence": 0.9793663024902344}]}, {"text": "The domain labels help when translating into Estonian, while they slightly hurt the performance when translating into English.", "labels": [], "entities": [{"text": "translating into Estonian", "start_pos": 28, "end_pos": 53, "type": "TASK", "confidence": 0.8177037636439005}]}, {"text": "This behavior could be explained by the different nature of the two languages, Estonian being a morphologically rich language, it could benefit from having a source label indicating good quality translations even if they come from a different domain.", "labels": [], "entities": []}, {"text": "As concerns our multilingual model, it achieves results close to our best score, specially for the Estonian-to-English direction.", "labels": [], "entities": [{"text": "Estonian-to-English direction", "start_pos": 99, "end_pos": 128, "type": "TASK", "confidence": 0.6554013639688492}]}, {"text": "We recall that this model also uses domain labels, and this suggests that, in this case, the Finnish-English data are indeed helpful to achieve a better BLEU score for the Estonian-to-English language pair.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 153, "end_pos": 157, "type": "METRIC", "confidence": 0.9992577433586121}]}, {"text": "models included domain labeling, motivated by the fact that news data are present in the training data, and also by the consistent performance improvements observed in initial experiments.", "labels": [], "entities": [{"text": "domain labeling", "start_pos": 16, "end_pos": 31, "type": "TASK", "confidence": 0.7289002239704132}]}, {"text": "Overall, back-translations again improve the BLEU scores for both directions.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 45, "end_pos": 49, "type": "METRIC", "confidence": 0.9984468817710876}]}, {"text": "The multilingual model achieves lower scores than the standard bilingual model, suggesting that the Estonian data do not provide useful complementary information, in particular because the Estonian data set is rather small compared to its Finnish counterpart and comes from exactly the same source.", "labels": [], "entities": [{"text": "Estonian data set", "start_pos": 189, "end_pos": 206, "type": "DATASET", "confidence": 0.7822402616341909}]}, {"text": "Finally, we also compare our transformer-based models to other machine translation paradigms.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.7138605266809464}]}, {"text": "reports the BLEU scores of the rule based system described in Section 2.3, the SMT system (Section 2.4) and an additional 2-layer sequence-to-sequence model () trained on the same data as the Transformer models.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 12, "end_pos": 16, "type": "METRIC", "confidence": 0.9990444779396057}, {"text": "SMT", "start_pos": 79, "end_pos": 82, "type": "TASK", "confidence": 0.9516170620918274}]}, {"text": "Clearly, the Transformer paradigm achieves the best BLEU scores.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 52, "end_pos": 56, "type": "METRIC", "confidence": 0.9987173080444336}]}, {"text": "Overall, our best English-to-Finnish model reaches the second position in the online ranking using automatic evaluation metrics.", "labels": [], "entities": []}, {"text": "Finally, in the manual evaluation of the official results of the WMT18 News Translation task (, our best system shared first place in both English-to-Finnish and Finnish-to-English translation directions.", "labels": [], "entities": [{"text": "WMT18 News Translation task", "start_pos": 65, "end_pos": 92, "type": "TASK", "confidence": 0.7693134099245071}]}], "tableCaptions": [{"text": " Table 1: Number of training sentences, with and  without back-translation (Back) and synthetic data  (Synth).", "labels": [], "entities": []}, {"text": " Table 2: BLEU-cased scores on newstest2018 for  the English-Estonian language pair in various con- figurations using domain labels (Label), backtrans- lated data (Back), or synthetic data (Synth). Our  primary submissions are marked with *.", "labels": [], "entities": [{"text": "BLEU-cased", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.999270498752594}]}, {"text": " Table 3: BLEU-cased scores on newstest2018 for  the English-Finnish language pair for various sys- tem architectures. Our primary submissions are  marked with *.", "labels": [], "entities": [{"text": "BLEU-cased", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9992814660072327}, {"text": "newstest2018", "start_pos": 31, "end_pos": 43, "type": "DATASET", "confidence": 0.95576012134552}]}]}