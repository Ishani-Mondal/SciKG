{"title": [{"text": "Modelling Pro-drop with the Rational Speech Acts Model", "labels": [], "entities": []}], "abstractContent": [{"text": "We extend the classic Referring Expressions Generation task by considering zero pronouns in \"pro-drop\" languages such as Chinese, modelling their use by means of the Bayesian Rational Speech Acts model (Frank and Goodman, 2012).", "labels": [], "entities": [{"text": "Referring Expressions Generation", "start_pos": 22, "end_pos": 54, "type": "TASK", "confidence": 0.926688551902771}]}, {"text": "By assuming that highly salient referents are most likely to be referred to by zero pronouns (i.e., pro-drop is more likely for salient refer-ents than the less salient ones), the model offers an attractive explanation of a phenomenon not previously addressed proba-bilistically.", "labels": [], "entities": []}], "introductionContent": [{"text": "Languages such as Chinese and Japanese make liberal use of zero pronouns (ZP).", "labels": [], "entities": []}, {"text": "The analysis of  on a large Chinese-English parallel dialogue corpus shows that 26% of the English pronouns are dropped in Chinese.", "labels": [], "entities": []}, {"text": "Such an abundant use of zero pronouns has been a key factor in linguist's idea) that Chinese is a \"cool\" language or a discourse-oriented language, i.e., one that relies heavily on context.", "labels": [], "entities": []}, {"text": "To exemplify zero pronouns in Chinese, consider the question \"\u4f60\u4eca\u5929\u770b\u89c1\u6bd4\u5c14\u4e86\u5417?\"", "labels": [], "entities": []}, {"text": "(Did you see Bill today?).", "labels": [], "entities": []}, {"text": "A Chinese speaker can respond in a variety of shorter expressions which are equivalent to \"\u6211\u770b\u89c1\u4ed6\u4e86\" (Yes, I saw him), for example, \"\u2205\u770b\u89c1\u4ed6\u4e86\" (Yes, \u2205 saw him), \"\u6211\u770b \u89c1\u2205\u4e86\" (Yes, I saw \u2205), or even \"\u2205\u770b\u89c1\u2205\u4e86\" (Yes, \u2205 saw \u2205).", "labels": [], "entities": []}, {"text": "Here the \u2205 symbol indicates the place from where a pronoun appears to have been \"dropped\" from a full sentence.", "labels": [], "entities": []}, {"text": "Generating zero pronouns (only) where they are appropriate is a difficult challenge for Referring Expression Generation (REG)), and more specifically for the task of choosing referential form, a key step in the classic Natural Language Generation (NLG) architecture).", "labels": [], "entities": [{"text": "Referring Expression Generation (REG))", "start_pos": 88, "end_pos": 126, "type": "TASK", "confidence": 0.8157262702782949}, {"text": "Natural Language Generation (NLG)", "start_pos": 219, "end_pos": 252, "type": "TASK", "confidence": 0.8159882624944051}]}, {"text": "Traditionally, choosing referential form is framed as modelling speakers' behaviour of deciding whether entities are referred to using a pronoun, a proper name, or a description.", "labels": [], "entities": []}, {"text": "However, for \"cool\" languages, an extra option, namely of choosing a zero pronoun, needs to be added) for fully simulating speakers' behaviour.", "labels": [], "entities": []}, {"text": "In this paper, we model the use of zero pronouns in Chinese with the Rational Speech Acts (RSA) model) by assuming that speakers tend to choose a ZP if it is salient enough for successful communication (see \u00a72).", "labels": [], "entities": [{"text": "Rational Speech Acts (RSA)", "start_pos": 69, "end_pos": 95, "type": "TASK", "confidence": 0.6830877959728241}]}, {"text": "For computing discourse salience, we focus on ZPs that are recoverable, meaning that they either refer anaphorically to an entity mentioned earlier in the text (i.e., anaphoric ZPs, or AZPs for short), or to the speaker or hearer (i.e., deictic nonanaphoric ZPs or DNZPs for short); a ZP is unrecoverable if it cannot be linked to any referent, for example: 'there are 23 high-tech projects underdevelopment in the zone' in which the \u2205 cannot be recovered.", "labels": [], "entities": [{"text": "computing discourse salience", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.6221315960089365}]}], "datasetContent": [{"text": "We tested our model on the Chinese portion of OntoNotes Release 5.0 data), which has been widely used in (ZP) co-reference resolution tasks.", "labels": [], "entities": [{"text": "Chinese portion of OntoNotes Release 5.0 data", "start_pos": 27, "end_pos": 72, "type": "DATASET", "confidence": 0.8467360479491097}, {"text": "ZP) co-reference resolution tasks", "start_pos": 106, "end_pos": 139, "type": "TASK", "confidence": 0.6060495972633362}]}, {"text": "The corpus contains 1,729 documents, including 143620 referring expressions.", "labels": [], "entities": []}, {"text": "In, there is the basic statistics about the recoverable zero pronouns in OntoNotes corpus.", "labels": [], "entities": [{"text": "OntoNotes corpus", "start_pos": 73, "end_pos": 89, "type": "DATASET", "confidence": 0.965438574552536}]}, {"text": "As expected, the models that look back to the whole preceding discourse perform badly on predicting ZPs (i.e., 8.35% of accuracy), especially DNZPs.", "labels": [], "entities": [{"text": "predicting ZPs", "start_pos": 89, "end_pos": 103, "type": "TASK", "confidence": 0.7181063294410706}, {"text": "accuracy", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.9992358684539795}, {"text": "DNZPs", "start_pos": 142, "end_pos": 147, "type": "DATASET", "confidence": 0.9164618253707886}]}, {"text": "They tend to predict all REs as NZREs, which even performs worse than the model using simple rule (i.e., the baseline).", "labels": [], "entities": [{"text": "NZREs", "start_pos": 32, "end_pos": 37, "type": "DATASET", "confidence": 0.7613716125488281}]}, {"text": "In contrast, limiting the discourse history by applying discourse windows or replacing frequency with recency have a negative impact on predicting NZREs, more specifically pronouns.", "labels": [], "entities": [{"text": "predicting NZREs", "start_pos": 136, "end_pos": 152, "type": "TASK", "confidence": 0.6588186025619507}]}, {"text": "Such an impact is caused by the idea that every NZRE can always be resolved by the listener, which is not correct for pronouns.", "labels": [], "entities": []}, {"text": "However, so far, we cannot calculate the informativeness of pronouns properly since we do not know which referent (speaker or listener) a deictic pronoun in the corpus refers to.", "labels": [], "entities": []}, {"text": "For example, in the corpus, both the speaker and listener will use \"I\" to refer to themselves, so we don't know whether \"I\" refers to the speaker or the listener.", "labels": [], "entities": []}, {"text": "This setting will lead to over-estimation of the informativeness of pronouns.", "labels": [], "entities": []}, {"text": "On the other hand, computing cost by average length (as we do) overestimates the costs of pronouns, whose lengths are generally shorter than proper names.", "labels": [], "entities": []}, {"text": "The baseline model's performance is not bad, especially for predicting AZPs.", "labels": [], "entities": [{"text": "predicting AZPs", "start_pos": 60, "end_pos": 75, "type": "TASK", "confidence": 0.7170178294181824}]}, {"text": "This is partly because the rule predicts that all REs in object position are NZREs and this is nearly always correct.", "labels": [], "entities": [{"text": "NZREs", "start_pos": 77, "end_pos": 82, "type": "DATASET", "confidence": 0.5076548457145691}]}, {"text": "(Recall that 99.84% REs in object position are NZREs).", "labels": [], "entities": [{"text": "REs", "start_pos": 20, "end_pos": 23, "type": "METRIC", "confidence": 0.9582983255386353}, {"text": "NZREs", "start_pos": 47, "end_pos": 52, "type": "METRIC", "confidence": 0.4941145181655884}]}, {"text": "At the same time, if the referent was referred to in the immediately preceding sentence (as the baseline model requires), then it is clearly more salient than if it wasn't.", "labels": [], "entities": []}, {"text": "The baseline model is therefore quite similar to the model with discourse window, but its decisions are made in a simpler way (i.e., based on a simple \"if-then\" rule).", "labels": [], "entities": []}, {"text": "With respect to overall accuracy for predicting ZPs and NZREs, models with recency perform similarly to those that use a discourse window.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9989625215530396}, {"text": "predicting ZPs and NZREs", "start_pos": 37, "end_pos": 61, "type": "TASK", "confidence": 0.7628042697906494}]}, {"text": "However, recency offers better prediction on AZPs.", "labels": [], "entities": []}, {"text": "Adding a dropping ratio could significantly improve the performance on predicting DNZPs without decreasing the accuracies of AZPs and NZREs very much (i.e., accuracy increase from 62.02% to 95.35%).", "labels": [], "entities": [{"text": "predicting DNZPs", "start_pos": 71, "end_pos": 87, "type": "TASK", "confidence": 0.7694991827011108}, {"text": "accuracies", "start_pos": 111, "end_pos": 121, "type": "METRIC", "confidence": 0.9946346282958984}, {"text": "NZREs", "start_pos": 134, "end_pos": 139, "type": "DATASET", "confidence": 0.8186559677124023}, {"text": "accuracy", "start_pos": 157, "end_pos": 165, "type": "METRIC", "confidence": 0.9991542100906372}]}, {"text": "For the choice of cost function, we found that using global average length is the best.", "labels": [], "entities": [{"text": "global average length", "start_pos": 53, "end_pos": 74, "type": "METRIC", "confidence": 0.6925714313983917}]}], "tableCaptions": [{"text": " Table 2: Accuracies of each model, recall that AZP and DNZP are two sub-categories of ZP.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9966403245925903}, {"text": "AZP", "start_pos": 48, "end_pos": 51, "type": "METRIC", "confidence": 0.9898442029953003}]}]}