{"title": [{"text": "The Other Side of the Coin: Unsupervised Disambiguation of Potentially Idiomatic Expressions by Contrasting Senses", "labels": [], "entities": []}], "abstractContent": [{"text": "Disambiguation of potentially idiomatic expressions involves determining the sense of a potentially idiomatic expression in a given context, e.g. determining that make hay in 'Investment banks made hay while takeovers shone.' is used in a figurative sense.", "labels": [], "entities": []}, {"text": "This enables automatic interpretation of idiomatic expressions, which is important for applications like machine translation and sentiment analysis.", "labels": [], "entities": [{"text": "automatic interpretation of idiomatic expressions", "start_pos": 13, "end_pos": 62, "type": "TASK", "confidence": 0.7073443293571472}, {"text": "machine translation", "start_pos": 105, "end_pos": 124, "type": "TASK", "confidence": 0.8271367847919464}, {"text": "sentiment analysis", "start_pos": 129, "end_pos": 147, "type": "TASK", "confidence": 0.9490188956260681}]}, {"text": "In this work, we present an unsupervised approach for English that makes use of literalisations of idiom senses to improve disambiguation, which is based on the lexical cohesion graph-based method by Sporleder and Li (2009).", "labels": [], "entities": []}, {"text": "Experimental results show that, while literalisation carries novel information, its performance falls short of that of state-of-the-art unsupervised methods.", "labels": [], "entities": [{"text": "literalisation", "start_pos": 38, "end_pos": 52, "type": "TASK", "confidence": 0.978179931640625}]}], "introductionContent": [{"text": "Interpreting potentially idiomatic expressions (PIEs, for short) is the task of determining the meaning of PIEs in context.", "labels": [], "entities": [{"text": "Interpreting potentially idiomatic expressions (PIEs", "start_pos": 0, "end_pos": 52, "type": "TASK", "confidence": 0.858581135670344}]}, {"text": "In its most basic form, it consists of distinguishing between the figurative and literal usage of a given expression, as illustrated by hit the wall in Examples (1) and (2), respectively.", "labels": [], "entities": []}, {"text": "(1) Melanie hit the wall so familiar to British youth: not successful enough to manage, but too successful for help.", "labels": [], "entities": []}, {"text": "1209) There was still a dark blob, where it might have hit the wall.", "labels": [], "entities": []}, {"text": "1531) Distinguishing literal and figurative uses is a crucial step towards being able to automatically interpret the meaning of a text containing idiomatic expressions.", "labels": [], "entities": [{"text": "Distinguishing literal and figurative uses", "start_pos": 6, "end_pos": 48, "type": "TASK", "confidence": 0.8677869200706482}, {"text": "interpret the meaning of a text containing idiomatic expressions", "start_pos": 103, "end_pos": 167, "type": "TASK", "confidence": 0.7052711976899041}]}, {"text": "It has been shown that idiomatic expressions pose a challenge for various NLP applications (), including sentiment analysis () and machine translation (.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 105, "end_pos": 123, "type": "TASK", "confidence": 0.965805858373642}, {"text": "machine translation", "start_pos": 131, "end_pos": 150, "type": "TASK", "confidence": 0.8208824992179871}]}, {"text": "For the latter, it has also been shown that being able to interpret idioms indeed improves performance (.", "labels": [], "entities": []}, {"text": "In this work, we use a method for unsupervised disambiguation that exploits semantic cohesion between the PIE and its context, based on the lexical cohesion approach pioneered by.", "labels": [], "entities": []}, {"text": "We extend this method and evaluate it on English data in a comprehensive evaluation framework, in order to answer the following research question: Do contexts enriched with literalisations of idioms provide a useful new signal for disambiguation?", "labels": [], "entities": []}], "datasetContent": [{"text": "Our research question asks whether literalisations of figurative senses area useful source of information for improved disambiguation of PIEs.", "labels": [], "entities": []}, {"text": "To provide an answer, we test our lexical cohesion graph with and without literalisation on a collection of existing datasets (Section 3.1), and evaluate performance using both micro-and macro-accuracy (Section 3.2).", "labels": [], "entities": []}, {"text": "Performance is judged by three evaluation measures: macro-averaged accuracy ('macro-accuracy'), micro-averaged accuracy ('micro-accuracy'), and the harmonic mean of the two.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.8679892420768738}, {"text": "micro-averaged accuracy", "start_pos": 96, "end_pos": 119, "type": "METRIC", "confidence": 0.8464469611644745}]}, {"text": "Micro-accuracy reflects how good the disambiguation system is doing overall.", "labels": [], "entities": [{"text": "Micro-accuracy", "start_pos": 0, "end_pos": 14, "type": "METRIC", "confidence": 0.9669319987297058}]}, {"text": "Macro-accuracy serves to ensure that we do not just optimise on the most frequent types, since some PIE types are much more frequent than others.", "labels": [], "entities": []}, {"text": "By using the harmonic mean of the two, we can rely on a single value to indicate balanced performance.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Overview of existing corpora of sense-annotated PIEs. The source corpus indicates the cor- pora from which the PIE instances were selected, either the British National Corpus (Burnard, 2007) or  ukWaC (Ferraresi et al., 2008).", "labels": [], "entities": [{"text": "British National Corpus (Burnard, 2007)", "start_pos": 161, "end_pos": 200, "type": "DATASET", "confidence": 0.9100816920399666}, {"text": "ukWaC", "start_pos": 205, "end_pos": 210, "type": "DATASET", "confidence": 0.7305768132209778}]}, {"text": " Table 2: Results of the original and literalisation-extended cohesion graph classifiers on the combined  development set. Accuracy scores are micro-and macro-averages over PIE types, in addition to the  harmonic mean of the two.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.9990947246551514}]}, {"text": " Table 3: Results of the original and literalisation classifiers on the combined test set, compared to a most  frequent sense baseline. Accuracy scores are micro-and macro-averages over PIE types, in addition to  the harmonic mean of the two.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 136, "end_pos": 144, "type": "METRIC", "confidence": 0.9992871880531311}]}]}