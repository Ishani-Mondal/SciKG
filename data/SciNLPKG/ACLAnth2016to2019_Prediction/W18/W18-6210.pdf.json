{"title": [], "abstractContent": [{"text": "Sentiment analysis models often rely on training data that is several years old.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9478045701980591}]}, {"text": "In this paper, we show that lexical features change polarity overtime, leading to degrading performance.", "labels": [], "entities": []}, {"text": "This effect is particularly strong in sparse models relying only on highly predictive features.", "labels": [], "entities": []}, {"text": "Using predictive feature selection, we are able to significantly improve the accuracy of such models overtime.", "labels": [], "entities": [{"text": "predictive feature selection", "start_pos": 6, "end_pos": 34, "type": "TASK", "confidence": 0.7265232602755228}, {"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9990876913070679}]}], "introductionContent": [{"text": "Sentiment analysis models often rely on data that is several years old.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9450036585330963}]}, {"text": "Such data, e.g., product reviews, continuously undergo shifts, leading to changes in term frequency, for example.", "labels": [], "entities": [{"text": "term frequency", "start_pos": 85, "end_pos": 99, "type": "METRIC", "confidence": 0.7406075894832611}]}, {"text": "We also observe the emergence of novel expressions, as well as the amelioration and pejoration of words.", "labels": [], "entities": []}, {"text": "Such changes are typically studied over decades or centuries; however, we hypothesize that change is continuous, and small changes can be detected over shorter time spans (years), and that their cumulation can influence the quality of sentiment analysis models.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 235, "end_pos": 253, "type": "TASK", "confidence": 0.9371405243873596}]}, {"text": "In this paper, we analyze temporal polarity changes of individual features using product reviews data.", "labels": [], "entities": []}, {"text": "Additionally, we show that predictive feature selection, trying to counteract shifts in polarity, significantly improves model accuracy overtime.", "labels": [], "entities": [{"text": "predictive feature selection", "start_pos": 27, "end_pos": 55, "type": "TASK", "confidence": 0.8133944272994995}, {"text": "accuracy", "start_pos": 127, "end_pos": 135, "type": "METRIC", "confidence": 0.9931976795196533}]}, {"text": "Contributions First, we show deterioration of sentiment analysis model performance overtime.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.9507295489311218}]}, {"text": "We propose rank-based metrics for detecting polarity shifts and identify several examples of lexical features that exhibit temporal drift in our data.", "labels": [], "entities": [{"text": "detecting polarity shifts", "start_pos": 34, "end_pos": 59, "type": "TASK", "confidence": 0.883118212223053}]}, {"text": "Finally, we use our findings to design a predictive feature selection scheme, based on expected polarity changes, and show that models using predictive Sample positive review: \"Grand daughters really like this movie.", "labels": [], "entities": [{"text": "predictive feature selection", "start_pos": 41, "end_pos": 69, "type": "TASK", "confidence": 0.646839956442515}]}, {"text": "Good clean movie for all ages.", "labels": [], "entities": []}, {"text": "Good horse movie for girls.\"", "labels": [], "entities": []}, {"text": "Sample negative review: \"Not what I expected.", "labels": [], "entities": []}, {"text": "Very cheap and chintzy looking for the price.", "labels": [], "entities": []}, {"text": "Certainly did not look like a wallet.", "labels": [], "entities": []}, {"text": "Very disappointed in the quality.\"", "labels": [], "entities": []}], "datasetContent": [{"text": "The purpose of our second set of experiments is again to see how accuracy changesover time with models being trained on 'older' and 'newer' data subsets, but on identical feature sets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9982548356056213}]}, {"text": "Similar to the above experiments, years 2001 to 2004 were selected as our older training data subsets, and years 2008 to 2011 were selected as our newer data.", "labels": [], "entities": []}, {"text": "We again sample 40, 000 reviews per year and create 80/20 train-test splits.", "labels": [], "entities": []}, {"text": "The experiment was repeated three times with new samples to obtain the average accuracies seen below in.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 79, "end_pos": 89, "type": "METRIC", "confidence": 0.9672780632972717}]}, {"text": "The fixed feature set used was obtained by selecting the 5,000 most frequent unigrams and bigrams present in the training data for year 2001.We use simple count vectors to represent the reviews.", "labels": [], "entities": []}, {"text": "The deterioration of performance overtime is clearly visible from the plot in, by looking at the gap between the red and the green scatter points.", "labels": [], "entities": []}, {"text": "We believe these results support our hypothesis that overtime, the polarities of individual features may change, and the cumulation of such changes significantly influences performance of sentiment classifiers., and tested on year x, where x \u2208.", "labels": [], "entities": []}, {"text": "All possible combinations were run 3 times with different random yearly subsets to compute the average accuracies presented in the figure.", "labels": [], "entities": []}, {"text": "In the first experiment with temporally robust models, we used the difference of means to implement predictive feature selection.", "labels": [], "entities": [{"text": "predictive feature selection", "start_pos": 100, "end_pos": 128, "type": "TASK", "confidence": 0.8321324785550436}]}, {"text": "The data used to create baseline accuracy was a random subset of R reviews, where, again, R = 40, 000 reviews were selected uniformly at random from years 2001 to 2008.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9842628836631775}]}, {"text": "After using 80/20 splits, a subset of 32,000 reviews was used to train a logistic regression classifier, and following the training, K most negative and K most positive features were selected.", "labels": [], "entities": []}, {"text": "In contrast to the baseline model, the temporally robust model used the difference of means method to select K negative and K positive features using predictive feature selection described in the section above.", "labels": [], "entities": []}, {"text": "This setup was run 3 times with different random subsets of data for both the baseline and the temporally robust model.", "labels": [], "entities": []}, {"text": "The result obtained from the runs can be seen below in and   In this particular experiment K = 100 (i.e. 200 features in total), however, identical experiments were run also with K = 200 and K = 400 (see).", "labels": [], "entities": []}, {"text": "The results indicate that with the number of features limited to 200, the predictive feature selection on average outperforms our baseline model by a significant margin across all tested years, i.e. 2010 to 2014.", "labels": [], "entities": []}, {"text": "As can be seen above in, significantly increased performance is present even in models that use increased number of features, i.e. from K = 100 to K = 400.", "labels": [], "entities": []}, {"text": "Such a result suggests that predictive feature selection increases performance even when more features are used, and not only in the extremely sparse model with 200 features.", "labels": [], "entities": [{"text": "predictive feature selection", "start_pos": 28, "end_pos": 56, "type": "TASK", "confidence": 0.786322295665741}]}, {"text": "Furthermore, additional experiment with an identical experimental setup (K = 400) was performed; however, the predictive feature selection was implemented using linear regression method with p-value filter, as described above in the paper.", "labels": [], "entities": [{"text": "predictive feature selection", "start_pos": 110, "end_pos": 138, "type": "TASK", "confidence": 0.8614568114280701}]}, {"text": "Results, seen in, clearly show that this method also performs better than the baseline approach consisting of selecting only most polar features based on training data.", "labels": [], "entities": []}, {"text": "In general, both methods -difference of means and linear regression with p-value filter -achieve a similar performance, which is consistently better than our baseline model for all tested years and all tested numbers of features, i.e. K \u2208 [100, 200, 400].", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Classifier accuracy deterioration when  using older and newer training sets. Models were  trained using random independent data subsets  from periods 2001-2004 or 2008-2011 and tested  using random independent subsets from 2012- 2014. Subset size: K = 40, 000 with 80/20 split.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.962578296661377}]}, {"text": " Table 2: Example feature ranks obtained by train- ing a logistic regression classifier on 32,000 re- views from each year.", "labels": [], "entities": []}, {"text": " Table 3: Each value in the table represents an av- erage accuracy of either a baseline or a temporally  robust model tested on a data set of 8,000 reviews  from the designated year. Each average is made  over 3 experimental runs using different random  subsets as training and test data (with no overlap  between training and test). Every model used 100  positive and 100 negative features (i.e. K = 100).  The predictive feature selection was implemented  using the difference of means method.", "labels": [], "entities": [{"text": "av- erage accuracy", "start_pos": 48, "end_pos": 66, "type": "METRIC", "confidence": 0.5912051647901535}]}]}