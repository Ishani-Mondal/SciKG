{"title": [{"text": "Identifying Domain Independent Update Intents in Task Based Dialogs", "labels": [], "entities": [{"text": "Identifying Domain Independent Update Intents in Task Based Dialogs", "start_pos": 0, "end_pos": 67, "type": "TASK", "confidence": 0.7964707745446099}]}], "abstractContent": [{"text": "One important problem in task-based conversations is that of effectively updating the belief estimates of user-mentioned slot-value pairs.", "labels": [], "entities": []}, {"text": "Given a user utterance, the intent of a slot-value pair is captured using dialog acts (DA) expressed in that utterance.", "labels": [], "entities": []}, {"text": "However, in certain cases, DA's fail to capture the actual update intent of the user.", "labels": [], "entities": []}, {"text": "In this paper, we describe such cases and propose anew type of semantic class for user intents.", "labels": [], "entities": []}, {"text": "This new type, Update Intents (UI), is directly related to the type of update a user intends to perform fora slot-value pair.", "labels": [], "entities": []}, {"text": "We define five types of UI's, which are independent of the domain of the conversation.", "labels": [], "entities": []}, {"text": "We build a multi-class classification model using LSTM's to identify the type of UI in user utterances in the Restaurant and Shopping domains.", "labels": [], "entities": []}, {"text": "Experimental results show that our models achieve strong classification performance in terms of F-1 score.", "labels": [], "entities": [{"text": "F-1 score", "start_pos": 96, "end_pos": 105, "type": "METRIC", "confidence": 0.9810997843742371}]}], "introductionContent": [{"text": "An important part of dialog management in dialog systems is to detect the type of update to be performed fora slot after every turn in order to keep track of the dialog state.", "labels": [], "entities": [{"text": "dialog management", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.8904396593570709}]}, {"text": "(The dialog state reflects the user goals specified as slot-value pairs.)", "labels": [], "entities": []}, {"text": "User dialog acts express the user's intents towards slots mentioned in the conversation.", "labels": [], "entities": []}, {"text": "They are extracted in the spoken language understanding (SLU) module and are utilized by the downstream state tracking systems to update belief estimates ().", "labels": [], "entities": [{"text": "spoken language understanding (SLU)", "start_pos": 26, "end_pos": 61, "type": "TASK", "confidence": 0.7695773939291636}]}, {"text": "However, * The work was done when the author was at Yahoo Research, currently used dialog acts do not capture the update intended by the user in the following cases: 1.", "labels": [], "entities": []}, {"text": "Implicit denials: User denials for slot-values are expressed using the \"deny\" and \"negate\" dialog acts.", "labels": [], "entities": []}, {"text": "However, these acts only address explicit negations/denials such as \"no\", \"I do not want slot-value'.", "labels": [], "entities": []}, {"text": "But a user may express denial fora value implicitly.", "labels": [], "entities": []}, {"text": "Consider utterances 8 and 9 in where a user adds and removes people from a slot, PNAMES, which contains names of people going to an event.", "labels": [], "entities": []}, {"text": "Current SLU systems would detect the \"inform\" dialog act in both utterances and, hence, would miss the (implicit denial) \"remove\" update.", "labels": [], "entities": []}, {"text": "2. Updates to numeric slots: Numeric slots are the slots whose values can be increased and decreased in addition to getting set/replaced.", "labels": [], "entities": []}, {"text": "Since dialog acts do not capture the \"increase\" and \"decrease\" intents towards a numeric value, such updates cannot be handled using dialog acts alone.", "labels": [], "entities": []}, {"text": "For example, consider utterances 4, 5 and 6 in Table 1 where the value of a numeric slot, NGUEST (number of guests in an invite), is set, increased and decreased respectively.", "labels": [], "entities": [{"text": "NGUEST", "start_pos": 90, "end_pos": 96, "type": "METRIC", "confidence": 0.9689461588859558}]}, {"text": "The dialog act expressed in these utterances is \"inform\" which does not convey the update type.", "labels": [], "entities": [{"text": "inform", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.9663344025611877}]}, {"text": "3. Preference for slot values: The \"inform\" dialog act specifies values for slots but does not take into account the preferences for any particular slot value(s).", "labels": [], "entities": []}, {"text": "Consider utterances 1, 2 and 3 in where the location slot (LOC) is referred.", "labels": [], "entities": [{"text": "location slot (LOC)", "start_pos": 44, "end_pos": 63, "type": "METRIC", "confidence": 0.7217868804931641}]}, {"text": "In utterance 2, the user is equally interested in the three locations (\"Ross\", \"Napa\" and \"San Jose\").", "labels": [], "entities": []}, {"text": "However, in utterance 3 the user prefers \"Gilroy\" over other values and intends to replace the old values with \"Gilroy\".", "labels": [], "entities": [{"text": "Gilroy", "start_pos": 42, "end_pos": 48, "type": "DATASET", "confidence": 0.622083306312561}, {"text": "Gilroy", "start_pos": 112, "end_pos": 118, "type": "DATASET", "confidence": 0.8641090989112854}]}, {"text": "Clearly, the SLU output does not capture this change in the user intent.", "labels": [], "entities": []}, {"text": "We posit that identifying the above intents in user utterances as apart of SLU would improve estimation of user goals in task based dialogs.", "labels": [], "entities": []}, {"text": "To ad-: Example user-bot conversations with only user utterances.", "labels": [], "entities": []}, {"text": "For illustration, only the relevant slots are shown in the SLU output.", "labels": [], "entities": [{"text": "SLU output", "start_pos": 59, "end_pos": 69, "type": "DATASET", "confidence": 0.7883220016956329}]}, {"text": "dress the above issues, we propose five generic update intents (UI's) which are directly related to the type of update expressed by the user: Append, Remove, Replace, IncreaseBy and DecreaseBy, and build a model to identify them in a user utterance.", "labels": [], "entities": [{"text": "Append", "start_pos": 142, "end_pos": 148, "type": "METRIC", "confidence": 0.968077540397644}]}, {"text": "defines the five UI's.", "labels": [], "entities": []}, {"text": "We model the problem of identifying UI's as a multi-class classification.", "labels": [], "entities": []}, {"text": "For a user utterance, we classify UI's for all the slot-values present in the utterance into one of the five classes.", "labels": [], "entities": []}, {"text": "We treat an utterance as a sequence of tokens and slot-values, and perform sequence labeling using LSTM's for the classification.", "labels": [], "entities": []}, {"text": "It should be noted that the focus of this work is on identifying the UI's in user utterance and not on investigating the mechanisms of using them for belief tracking, which is part of our larger goal.", "labels": [], "entities": [{"text": "belief tracking", "start_pos": 150, "end_pos": 165, "type": "TASK", "confidence": 0.8088077902793884}]}, {"text": "UI's are generic in nature and independent of the dialog domain.", "labels": [], "entities": []}, {"text": "Given a slot type (such as numeric), they can be applied to any slot of that type.", "labels": [], "entities": []}, {"text": "This enables transfer learning across similar slots in different domains.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 13, "end_pos": 30, "type": "TASK", "confidence": 0.9487698376178741}]}, {"text": "To demonstrate this, we experiment with two domains (shopping and restaurants) and define three types of slots: 1.", "labels": [], "entities": []}, {"text": "Conjunctive multi-value (CMV) slots, and 3.", "labels": [], "entities": []}, {"text": "Disjunctive multi-value (DMV) slots (explained in Section 3.1.1).", "labels": [], "entities": []}, {"text": "We then delexicalize slot-values in user utterances with the corresponding slot type (not slot name) and conduct cross-domain training and testing experiments.", "labels": [], "entities": []}, {"text": "Experimental results demonstrate strong classification performance in individual domains as well as across domains.", "labels": [], "entities": []}, {"text": "Contributions: 1) We propose anew semantic class of slot-specific user intents (UI's) which are directly related to the update a user intends to perform fora slot.", "labels": [], "entities": []}, {"text": "2) The proposed UI's enable effective updates to slots.", "labels": [], "entities": []}, {"text": "3) Our models predict UI's with high accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9988861680030823}]}, {"text": "4) We present a novel delexicalization approach which enables transfer learning of UI's across domains.", "labels": [], "entities": [{"text": "transfer learning of UI", "start_pos": 62, "end_pos": 85, "type": "TASK", "confidence": 0.8146937489509583}]}], "datasetContent": [{"text": "We implement the proposed architecture in Section 3 using Keras (, a high-level neural networks API, with the Tensorflow (  done by mini-batch RMSProp () with a fixed learning rate.", "labels": [], "entities": []}, {"text": "In all our experiments, mini-batch size is fixed to 64.", "labels": [], "entities": [{"text": "mini-batch size", "start_pos": 24, "end_pos": 39, "type": "METRIC", "confidence": 0.8012652397155762}]}, {"text": "Training and inference are done on a per-utterance level.", "labels": [], "entities": []}, {"text": "The embedding layer in the model is initialized with 300-dimensional Glove word vectors obtained from common crawl ().", "labels": [], "entities": []}, {"text": "Embeddings for missing words are initialized randomly with values between \u22120.5 and 0.5.", "labels": [], "entities": []}, {"text": "Evaluation: Using a random split of train and test sets would have examples from the same editor in both train and test sets which would bias the estimation.", "labels": [], "entities": []}, {"text": "Therefore, we split our data into eight folds corresponding to the eight editors, i.e., each fold contains examples from only one of the editors.", "labels": [], "entities": []}, {"text": "To evaluate our models, we train and validate on the data from seven folds and test the performance on the held-out (eighth) fold.", "labels": [], "entities": []}, {"text": "We run this experiment for each editor, i.e., eight times, and average results across the eight folds.", "labels": [], "entities": []}, {"text": "For validation, we use 15% of the training data.", "labels": [], "entities": [{"text": "validation", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.9773263335227966}]}, {"text": "We use precision, recall and F-1 score to report the performance of our classifiers.", "labels": [], "entities": [{"text": "precision", "start_pos": 7, "end_pos": 16, "type": "METRIC", "confidence": 0.9996647834777832}, {"text": "recall", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9994402527809143}, {"text": "F-1 score", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.9809159636497498}]}, {"text": "Overall classification performance metrics are computed by taking the weighted average of the metrics for individual classes.", "labels": [], "entities": []}, {"text": "A class's weight is the ratio of the number of instances in it to the total number of instances.", "labels": [], "entities": []}, {"text": "Parameter tuning: In each experiment, 15% of the current training set is utilized as a development set for hyper-parameter tuning and the model with best setting is applied to the test set to report the results.", "labels": [], "entities": []}, {"text": "We tune learning rate, dropout via grid search on the development set.", "labels": [], "entities": []}, {"text": "In addition, we utilize early stopping to avoid over-fitting.", "labels": [], "entities": []}, {"text": "The optimal hyper-parameter settings for our classification experiments (reported in) is dropout = 0.3, learningrate = 0.001 for the restaurants domain and dropout = 0.25, learningrate = 0.001 for the shopping domain.", "labels": [], "entities": []}, {"text": "Baseline: We used n-grams based multinomial logistic regression as a baseline.", "labels": [], "entities": []}, {"text": "N-grams based models have been extensively used in text classification ().", "labels": [], "entities": [{"text": "text classification", "start_pos": 51, "end_pos": 70, "type": "TASK", "confidence": 0.8882744610309601}]}, {"text": "Such models have also been found to be effective as semantic tuple classifiers for dialog act detection and slot filling tasks ().", "labels": [], "entities": [{"text": "dialog act detection", "start_pos": 83, "end_pos": 103, "type": "TASK", "confidence": 0.7992722392082214}, {"text": "slot filling tasks", "start_pos": 108, "end_pos": 126, "type": "TASK", "confidence": 0.850601057211558}]}, {"text": "Since there can be multiple slot-values and, hence, multiple UI's expressed in a user utterance, the entire utterance cannot be used to extract n-grams for all the expressed UI's.", "labels": [], "entities": []}, {"text": "Therefore, we segment user utterances into relevant contexts for the slot-values and classify the contexts into one of the five UI classes.", "labels": [], "entities": []}, {"text": "A context fora value is an ordered list of words which are indicative of the update to be performed for the value.", "labels": [], "entities": []}, {"text": "We use two approaches for segmentation based on the k words window approach: a) hard segmentation, b) soft segmentation.", "labels": [], "entities": []}, {"text": "In the first approach, we assign the words around the value to its context based on the following constraints: 1.", "labels": [], "entities": []}, {"text": "If an utterance contains only one value, the entire utterance is taken as the context for the value.", "labels": [], "entities": []}, {"text": "2. If there are n words (s.t. n < 2k) between two slot values then the preference is given to the right value.", "labels": [], "entities": []}, {"text": "That is, k words are assigned to the context of the right value and n \u2212 k words are assigned to the context of the left value.", "labels": [], "entities": []}, {"text": "3. All the words to the left of the first value (in the utterance) are added to the value's context.", "labels": [], "entities": []}, {"text": "Similarly, all the words to the right of the last value are added to its context.", "labels": [], "entities": []}, {"text": "In soft segmentation, we do not perform a hard assignment of the words, between the two values to the context of one of the values.", "labels": [], "entities": [{"text": "soft segmentation", "start_pos": 3, "end_pos": 20, "type": "TASK", "confidence": 0.7067541629076004}]}, {"text": "Instead, we encode the words into one of these categories based on its position with respect to the value and if it is in between two values (and let the model learn weights for words in each category): 1) towards left of a value and between two values, 2) towards right of a value and between two values, 3) towards left of a value, 4) towards right of a value.", "labels": [], "entities": []}, {"text": "We extracted unigrams and bigrams from the context of slot-values.", "labels": [], "entities": []}, {"text": "We experimented with different window sizes and k=2 gave the best results.: Classification results on the two domains.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Tasks in the two domains with corresponding info slots, supported update intents and example  utterances. Slot-values in the utterances are in italics.", "labels": [], "entities": []}, {"text": " Table 5: Classification results on the two domains.", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9548033475875854}]}]}