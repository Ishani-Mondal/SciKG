{"title": [{"text": "Using the Nunavut Hansard Data for Experiments in Morphological Analysis and Machine Translation", "labels": [], "entities": [{"text": "Hansard Data", "start_pos": 18, "end_pos": 30, "type": "DATASET", "confidence": 0.7982299625873566}, {"text": "Morphological Analysis", "start_pos": 50, "end_pos": 72, "type": "TASK", "confidence": 0.7573349475860596}, {"text": "Machine Translation", "start_pos": 77, "end_pos": 96, "type": "TASK", "confidence": 0.7779603600502014}]}], "abstractContent": [{"text": "Inuktitut is a polysynthetic language spoken in Northern Canada and is one of the official languages of the Canadian territory of Nunavut.", "labels": [], "entities": []}, {"text": "As such, the Nunavut Legislature publishes all of its proceedings in parallel English and Inuktitut.", "labels": [], "entities": []}, {"text": "Several parallel English-Inuktitut corpora from these proceedings have been created from these data and are publically available.", "labels": [], "entities": []}, {"text": "The corpus used for current experiments is described.", "labels": [], "entities": []}, {"text": "Morphological processing of one of these corpora was carried out and details about the processing are provided.", "labels": [], "entities": []}, {"text": "Then, the processed corpus was used in morphological analysis and machine translation (MT) experiments.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.7082991302013397}, {"text": "machine translation (MT)", "start_pos": 66, "end_pos": 90, "type": "TASK", "confidence": 0.82737238407135}]}, {"text": "The morphological analysis experiments aimed to improve the coverage of morphological processing of the corpus, and compare an additional experimental condition to previously published results.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.8272502720355988}]}, {"text": "The machine translation experiments made use of the additional morphologically analyzed word types in a statistical machine translation system designed to translate to and from Inuktitut morphemes.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.7577742636203766}, {"text": "statistical machine translation", "start_pos": 104, "end_pos": 135, "type": "TASK", "confidence": 0.6922368804613749}]}, {"text": "Results are reported and next steps are defined.", "labels": [], "entities": []}], "introductionContent": [{"text": "Inuktitut is a polysynthetic language spoken in all areas of Canada north of the treeline, and is one of a group of closely related Inuit languages that includes Inuinnaqtun, Inuvialuktun, Kalaallisut (Greenlandic) and others; there are about 35,000 speakers of these languages in Canada.", "labels": [], "entities": []}, {"text": "Inuktitut is of great interest to researchers in machine translation (MT) because it is one of the official languages of a bureaucracy, the government of the Canadian territory of Nunavut, which is continually generating parallel texts: Inuktitut in parallel with English.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 49, "end_pos": 73, "type": "TASK", "confidence": 0.8641295552253723}]}, {"text": "High-quality MT depends on the existence of large quantities of parallel text that can be used to train MT systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 13, "end_pos": 15, "type": "TASK", "confidence": 0.9932083487510681}, {"text": "MT", "start_pos": 104, "end_pos": 106, "type": "TASK", "confidence": 0.9880251288414001}]}, {"text": "While its elevated status as an official language has helped to maintain its use, because of the low number of speakers, it has not received a lot of attention by the natural language processing (NLP) research and development community.", "labels": [], "entities": []}, {"text": "From a research point of view, the Inuktitut-English language pair is a best-case scenario for people interested in MT into and out of a polysynthetic language.", "labels": [], "entities": [{"text": "MT", "start_pos": 116, "end_pos": 118, "type": "TASK", "confidence": 0.9954491257667542}]}, {"text": "If we eventually succeed in building highquality Inuktitut-to-English and English-to-Inuktitut MT systems, the lessons learned maybe applicable to other language pairs in which one of the languages is polysynthetic.", "labels": [], "entities": []}, {"text": "From a practical point of view, good Inuktitut-to-English and English-to-Inuktitut MT systems could be used to generate firstdraft translations that would make translators working for the Nunavut government more productive, and thus assist the survival and revitalization of the Inuktitut language.", "labels": [], "entities": []}, {"text": "Furthermore, NLP tools such as spell checkers or machine translation would greatly benefit speakers of Inuktitut and help to maintain their language by enhancing the speakers' use of the internet or mobile technologies, for example.", "labels": [], "entities": [{"text": "spell checkers", "start_pos": 31, "end_pos": 45, "type": "TASK", "confidence": 0.7690201699733734}, {"text": "machine translation", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.7140164822340012}]}, {"text": "Because Inuktitut has complex morphology, any such NLP or MT tools will require the development of an accurate morphological analyzer.", "labels": [], "entities": []}, {"text": "The purpose of this current line of research is to further develop an existing morphological analyzer, the Uqailaut analyzer, and we report on progress and the use of this work in downstream machine translation experiments.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 191, "end_pos": 210, "type": "TASK", "confidence": 0.6522061228752136}]}, {"text": "The structure of this paper is as follows: first, we describe the Inuktitut language in terms of morphological complexity; second, we describe the Nunavut Hansard corpus and the processing that was applied to it; third we describe the existing morphological analyzer, the Uqailaut analyzer; fourth, we present an extension of previous experiments on morphological analysis; fifth, we describe machine translation experiments; finally, we discuss future work envisioned.", "labels": [], "entities": [{"text": "Nunavut Hansard corpus", "start_pos": 147, "end_pos": 169, "type": "DATASET", "confidence": 0.6502574384212494}, {"text": "machine translation", "start_pos": 393, "end_pos": 412, "type": "TASK", "confidence": 0.7523491978645325}]}], "datasetContent": [{"text": "The morphological analyses have been used in two sets of downstream experiments, and will be used in continued experiments in this line of research as it progresses.", "labels": [], "entities": []}, {"text": "One set of experiments involved learning a model from the analyzed data to perform morphological analysis of the remaining types which the Uqailaut analyzer could not analyze.", "labels": [], "entities": []}, {"text": "used a segmental recurrent neural network (SRNN) The results from that work are summarized and presented here for the reader's convenience, and anew experimental condition is reported.", "labels": [], "entities": []}, {"text": "The models in were trained with approximately 23K types having a single analysis from the Uqailaut analyzer.", "labels": [], "entities": [{"text": "Uqailaut analyzer", "start_pos": 90, "end_pos": 107, "type": "DATASET", "confidence": 0.9110759794712067}]}, {"text": "The reason for using only those with a single analysis is that they can be argued as being the most accurate, according to the Uqailaut analyzer, i.e. there is no ambiguous output to choose from.", "labels": [], "entities": [{"text": "Uqailaut analyzer", "start_pos": 127, "end_pos": 144, "type": "DATASET", "confidence": 0.8227091431617737}]}, {"text": "Inputs to the model are sequences of characters, and outputs are labels with the number of characters that each label covers.", "labels": [], "entities": []}, {"text": "Three experimental conditions were designed, reported in and summarized here.", "labels": [], "entities": []}, {"text": "The first condition (CG) used coarse-grained output labels (16 total), identifying the general type of morpheme, similar to POS tags.", "labels": [], "entities": []}, {"text": "The second (FG) used finegrained output labels (1691 total) reflecting complete morphological information about each morpheme.", "labels": [], "entities": [{"text": "FG", "start_pos": 12, "end_pos": 14, "type": "METRIC", "confidence": 0.6060946583747864}]}, {"text": "The third (FG-SO, \"fine-grained, suffixes only\") looked at whether the confusion produced by the model could be attributed at least somewhat to the root morphemes, likened to \"open-class\" vocabulary with high variation, by measuring the precision, recall and F-scores over suffixes alone, with the fine-grained label output.", "labels": [], "entities": [{"text": "FG-SO", "start_pos": 11, "end_pos": 16, "type": "METRIC", "confidence": 0.9519994854927063}, {"text": "precision", "start_pos": 237, "end_pos": 246, "type": "METRIC", "confidence": 0.999313235282898}, {"text": "recall", "start_pos": 248, "end_pos": 254, "type": "METRIC", "confidence": 0.9965751767158508}, {"text": "F-scores", "start_pos": 259, "end_pos": 267, "type": "METRIC", "confidence": 0.9634096026420593}]}, {"text": "The rational for this experimental condition is the following: root morphemes are similar to \"open-class\" words in that they represent objects and events.", "labels": [], "entities": []}, {"text": "The lexical postbases, grammatical suffixes, and clitics are similar to \"closed class\" words in that their number is fixed and the category cannot generally increase.", "labels": [], "entities": []}, {"text": "There are far fewer suffixes in Inuktitut than roots (potentially unbounded), and for this reason, it was hypothesized that the analyzer would be able to analyze most of the suffixes but perhaps not all of the roots.", "labels": [], "entities": []}, {"text": "Two held out sets (referred to as \"dev\" and \"test\", although the \"dev\" set was merely an additional test set and not used for development purposes) were created.", "labels": [], "entities": []}, {"text": "Initially, 1000 items for each set were held out, but because the neural network could not process unseen labels occurring in the two held-out sets, these were reduced to 449 test items each (see for details of the selection process).", "labels": [], "entities": []}, {"text": "The two test sets were then run through the model and precision, recall, and F-scores for both segmentation and segmentation+tagging were calculated on the output.", "labels": [], "entities": [{"text": "precision", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9994743466377258}, {"text": "recall", "start_pos": 65, "end_pos": 71, "type": "METRIC", "confidence": 0.9975409507751465}, {"text": "F-scores", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.998870313167572}, {"text": "segmentation", "start_pos": 95, "end_pos": 107, "type": "TASK", "confidence": 0.9603487849235535}, {"text": "segmentation+tagging", "start_pos": 112, "end_pos": 132, "type": "TASK", "confidence": 0.7555066545804342}]}, {"text": "These measures are typical in this type of research.", "labels": [], "entities": []}, {"text": "A fourth experimental condition, not yet published, was devised to address the modeling problem of unseen labels.", "labels": [], "entities": []}, {"text": "As is typically currently done in computational modeling of language, data items with fewer than a preselected number of items are replaced with an unknown symbol label (<UNK>) to ensure that all items found in test and development sets are present in training.", "labels": [], "entities": []}, {"text": "As such, the <UNK> label was added to the output vocabulary, and the two test sets were resampled, with 1000 items each.", "labels": [], "entities": []}, {"text": "Any label in the test sets not appearing in the training data was then changed to <UNK> and the experiments were re-run.", "labels": [], "entities": []}, {"text": "below summarizes the results from and the new results with <UNK> labels.", "labels": [], "entities": []}, {"text": "As can be seen, the CG output is the best, and this stands to reason, the model only has to decide between 16 labels, versus 1691 (or 1692 labels, in the case of FG-UNK).", "labels": [], "entities": [{"text": "FG-UNK", "start_pos": 162, "end_pos": 168, "type": "DATASET", "confidence": 0.956186056137085}]}, {"text": "The FG condition fares worse, only reaching approximately 86% or 83% accuracy in the segmentation only task, and even worse in the segmentation plus tagging task.", "labels": [], "entities": [{"text": "FG", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.8263182044029236}, {"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9958078861236572}, {"text": "segmentation plus tagging task", "start_pos": 131, "end_pos": 161, "type": "TASK", "confidence": 0.8275636285543442}]}, {"text": "However, this condition can only fairly be compared to the third condition, FG-SO, in which the test sets are identical.", "labels": [], "entities": [{"text": "FG-SO", "start_pos": 76, "end_pos": 81, "type": "METRIC", "confidence": 0.9063171744346619}]}, {"text": "In this case, the accuracy measured on the suffixes only is indeed better than that measured over the full words, which supports the idea that such an analyzer can at least do better on certain parts of the words it's analyzing, the suffixes, because the decision space is smaller and better defined.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9992226362228394}]}, {"text": "Indeed, the tagging task, although still lower than the segmentation task, is much improved in FG-SO compared to FG.", "labels": [], "entities": [{"text": "tagging", "start_pos": 12, "end_pos": 19, "type": "TASK", "confidence": 0.9766148924827576}, {"text": "FG-SO", "start_pos": 95, "end_pos": 100, "type": "DATASET", "confidence": 0.7331758737564087}, {"text": "FG", "start_pos": 113, "end_pos": 115, "type": "DATASET", "confidence": 0.881052553653717}]}, {"text": "The fourth condition (FG-UNK) can only fairly be compared to the first condition, CG.", "labels": [], "entities": [{"text": "FG-UNK)", "start_pos": 22, "end_pos": 29, "type": "METRIC", "confidence": 0.9663569927215576}]}, {"text": "We see lower segmentation and tagging scores, but the lower scores are not as dramatically low as in FG and FG-SO, which could partially be attributed to the lower number of test items in these sets.", "labels": [], "entities": [{"text": "FG", "start_pos": 101, "end_pos": 103, "type": "DATASET", "confidence": 0.6829524040222168}, {"text": "FG-SO", "start_pos": 108, "end_pos": 113, "type": "DATASET", "confidence": 0.6395103335380554}]}, {"text": "Given that the FG-UNK model is choosing among 1692 labels, as compared to the 16 labels in CG, the lower results should not be interpreted as a disappointment.", "labels": [], "entities": [{"text": "FG-UNK", "start_pos": 15, "end_pos": 21, "type": "DATASET", "confidence": 0.835849404335022}]}, {"text": "We report hereon a set of machine translation experiments 7 which made use of the morphologically analyzed corpus detailed earlier and the SRNN system details in the previous section.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.7563391625881195}, {"text": "SRNN", "start_pos": 139, "end_pos": 143, "type": "DATASET", "confidence": 0.7439498901367188}]}, {"text": "We experimented with statistical machine translation from Inuktitut to English and English to Inuktitut, incorporating the results of the previously discussed neural morphological analyzer, into the Nunavut Hansard corpus for words that do not have an analysis from the Uqailaut analyzer.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 21, "end_pos": 52, "type": "TASK", "confidence": 0.6271808842817942}, {"text": "Nunavut Hansard corpus", "start_pos": 199, "end_pos": 221, "type": "DATASET", "confidence": 0.6807718674341837}]}, {"text": "We used the segmentations obtained from the coarse-grained analyzer previously discussed, as these have the best scores out of all of the conditions examined.", "labels": [], "entities": []}, {"text": "We compared three conditions: 1) full Inuktitut words 2) segmented Inuktitut words for those words that the Uqailaut analyzer provided an analysis for, choosing the first analysis provided when multiple analyses are available, and 3) full segmentation, incorporating the segmentation from the SRNN described above for those words not having an analysis.", "labels": [], "entities": [{"text": "SRNN", "start_pos": 293, "end_pos": 297, "type": "DATASET", "confidence": 0.8599894642829895}]}, {"text": "We ran the experiments over two separate divisions of the data into training, dev and test sets, insuring no overlap between train/test or train/dev sets, and we computed statistical significance in each set according to the bootstrap resampling method presented in).", "labels": [], "entities": []}, {"text": "We used the Moses toolkit to create the models.", "labels": [], "entities": []}, {"text": "We report BLEU scores) for the full word systems, and m-BLEU scores for the morpheme-based systems.", "labels": [], "entities": [{"text": "BLEU scores", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9788255393505096}]}, {"text": "Admittedly, the results presented in are problematic.", "labels": [], "entities": []}, {"text": "Upon first glance, it appears that the morphologically analyzed (morphed) Inuktitut systems are all better than the systems that translate full words.", "labels": [], "entities": []}, {"text": "However, it should be noted that the morphed scores are m-BLEU scores, whereas those over the full word systems are normal BLEU scores.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 123, "end_pos": 127, "type": "METRIC", "confidence": 0.9958662986755371}]}, {"text": "To makeup for this mismatch, we recalculated the m-BLEU scores to yield BLEU scores by rejoining, wherever possible, strings of morphemes back into full words.", "labels": [], "entities": [{"text": "BLEU scores", "start_pos": 72, "end_pos": 83, "type": "METRIC", "confidence": 0.9749814569950104}]}, {"text": "While these scores do indeed come out higher, they are not shown to be significant, at either the p < 0.05 or p < 0.1 levels.", "labels": [], "entities": []}, {"text": "For set 1b, we get a BLEU score of 14.89 with a range of at 95% confidence and.11] at 90% confidence, and for set 2b, we get a BLEU score of 13.39, with a range of.59] at 95% and at 90%.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 21, "end_pos": 31, "type": "METRIC", "confidence": 0.9792468547821045}, {"text": "BLEU score", "start_pos": 127, "end_pos": 137, "type": "METRIC", "confidence": 0.9778261184692383}]}, {"text": "We do, however, get at least one significant result (at p < 0.05) when comparing the gains from having more words morphologically analyzed.", "labels": [], "entities": []}, {"text": "For set 2a, the 100% morphed 29.85 (95% confidence interval of) is indeed significant over the 28.34 score from the 70% morphed corpus.", "labels": [], "entities": [{"text": "100% morphed 29.85 (95% confidence interval", "start_pos": 16, "end_pos": 59, "type": "METRIC", "confidence": 0.6619437866740756}]}, {"text": "However we do not get the same significance for set 1.", "labels": [], "entities": [{"text": "significance", "start_pos": 31, "end_pos": 43, "type": "METRIC", "confidence": 0.9605215191841125}]}, {"text": "Both sets 1 and 2 were randomly chosen from the full corpus, avoiding any duplicates between train and test, and tune and test sets.", "labels": [], "entities": []}, {"text": "This situation points to significant differences in the two sets of data.", "labels": [], "entities": []}, {"text": "Indeed, we built the second set precisely because we did not measure significance on the first set and these results warrant further testing, by building additional sample sets, at a minimum.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Nunavut Hansard Corpus Statistics", "labels": [], "entities": [{"text": "Hansard Corpus Statistics", "start_pos": 18, "end_pos": 43, "type": "DATASET", "confidence": 0.8073694705963135}]}, {"text": " Table 2: SRNN Morphological Analysis Experimental Results : From (Micher, 2017) and new condition, FG- UNK reported", "labels": [], "entities": [{"text": "SRNN Morphological Analysis", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.6471483608086904}, {"text": "FG- UNK", "start_pos": 100, "end_pos": 107, "type": "DATASET", "confidence": 0.7246918479601542}]}, {"text": " Table 3: Statistical Machine Translation to and from English (*denotes statistical significance at p < 0.05)", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 10, "end_pos": 41, "type": "TASK", "confidence": 0.7778384486834208}]}]}