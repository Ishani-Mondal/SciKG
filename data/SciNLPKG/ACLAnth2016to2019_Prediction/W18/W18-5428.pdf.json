{"title": [{"text": "Interpreting Word-Level Hidden State Behaviour of Character-Level LSTM Language Models", "labels": [], "entities": [{"text": "Interpreting Word-Level Hidden State Behaviour of Character-Level LSTM Language Models", "start_pos": 0, "end_pos": 86, "type": "TASK", "confidence": 0.7811908781528473}]}], "abstractContent": [{"text": "While Long Short-Term Memory networks (LSTMs) and other forms of recurrent neural network have been successfully applied to language modeling on a character level, the hidden state dynamics of these models can be difficult to interpret.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 124, "end_pos": 141, "type": "TASK", "confidence": 0.7075712382793427}]}, {"text": "We investigate the hidden states of such a model by using the HDB-SCAN clustering algorithm to identify points in the text at which the hidden state is similar.", "labels": [], "entities": []}, {"text": "Focusing on whitespace characters prior to the beginning of a word reveals interpretable clusters that offer insight into how the LSTM may combine contextual and character-level information to identify parts of speech.", "labels": [], "entities": []}, {"text": "We also introduce a method for deriving word vectors from the hidden state representation in order to investigate the word-level knowledge of the model.", "labels": [], "entities": []}, {"text": "These word vectors encode meaningful semantic information even for words that appear only once in the training text.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recurrent Neural Networks (RNNs), including Long Short-Term Memory (LSTM) networks), have been widely applied to natural language processing tasks including character-level language modeling (.", "labels": [], "entities": [{"text": "character-level language modeling", "start_pos": 157, "end_pos": 190, "type": "TASK", "confidence": 0.6631201605002085}]}, {"text": "However, like other types of neural networks, the hidden states and behaviour of a given LSTM can be difficult to understand and interpret, due to both the distributed nature of the hidden state representations and the relatively opaque relationship between the hidden state and the final output of the network.", "labels": [], "entities": []}, {"text": "It is also not clear how a character-level LSTM language model takes advantage of orthographic patterns to infer higherlevel information.", "labels": [], "entities": []}, {"text": "In this paper, we investigate the hidden state dynamics of a character-level LSTM language model both directly and -through the use of output gate activations -indirectly.", "labels": [], "entities": []}, {"text": "As an overview, our main contributions are: 1.", "labels": [], "entities": []}, {"text": "We use clustering to investigate similar hidden states (and output gate activations) at different points in a text, paying special attention to whitespace characters.", "labels": [], "entities": []}, {"text": "We provide insight into the model's awareness of both orthographic patterns and word-level grammatical information.", "labels": [], "entities": []}, {"text": "2. Inspired by our findings from clustering, we introduce a method for extracting meaningful word embeddings from a character-level model, allowing us to investigate the wordlevel knowledge of the model.", "labels": [], "entities": []}, {"text": "First, we use the HDBSCAN clustering algorithm ( to reveal locations within a text at which the hidden state of the LSTM is similar, or at which a similar combination of cell state dimensions is relevant (as determined by output gates).", "labels": [], "entities": []}, {"text": "Interestingly, focusing on moments when the network must predict the first letter of a word reveals clusters that are interpretable on the level of words and which display both character-level patterns and grammatical structure (i.e. separating parts of speech).", "labels": [], "entities": []}, {"text": "We give examples of clusters of similar hidden states that appear to be heavily influenced by local orthographic patterns but also distinguish between different grammatical functions of the pattern -for example, a cluster containing whitespace characters following possessive uses, but not contractive uses, of the affix \"'s\".", "labels": [], "entities": []}, {"text": "This sheds light on the use of orthographic patterns to infer higher-level information.", "labels": [], "entities": []}, {"text": "We also introduce a method for extracting word embeddings from a character-level model and perform qualitative and quantitative analyses of these embeddings.", "labels": [], "entities": []}, {"text": "Surprisingly, this method can assign meaningful representations even to words that appear only once in the text, including associating the rare word \"scrutinizingly\" with \"questioningly\" and \"attentively\", and correctly identifying \"deck\" as a verb based on a single use despite its lack of meaningful subword components.", "labels": [], "entities": []}, {"text": "These results suggests that the model is capable of deducing meaningful information about a word based on the context of a single use.", "labels": [], "entities": []}, {"text": "While these embeddings do not achieve state-of-the-art performance on word similarity benchmarks, they do outperform the older methods of despite the small corpus size and the fact that our language model was not designed with the intent of producing word embeddings.", "labels": [], "entities": []}, {"text": "The rest of the paper is structured as follows: The following section describes related work.", "labels": [], "entities": []}, {"text": "Section 3 describes the architecture and training of the LSTM language model used in our experiments.", "labels": [], "entities": []}, {"text": "In Section 4, we describe our clustering methods and show examples of the clusters found, as well as apart of speech analysis.", "labels": [], "entities": []}, {"text": "In Section 5, we describe and analyze our method for extracting word embeddings from the character-level model.", "labels": [], "entities": []}, {"text": "Finally, we conclude and suggest directions for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We chose to use the HDBSCAN clustering algorithm (, since it is designed to work with non-globular clusters of varying density, does not require that an expected number of clusters be specified in advance, and is willing to avoid assigning points to a cluster if they do not  seem to be a good fit for any cluster.", "labels": [], "entities": [{"text": "HDBSCAN clustering", "start_pos": 20, "end_pos": 38, "type": "TASK", "confidence": 0.6335863769054413}]}, {"text": "We used the Python implementation of.", "labels": [], "entities": []}, {"text": "Using the \"full\" data set, we attempted to cluster the time steps according to either hidden state or output gate activations.", "labels": [], "entities": []}, {"text": "We used the Euclidean metric and the HDBSCAN parameters min cluster size=100 and min samples=10.", "labels": [], "entities": [{"text": "HDBSCAN", "start_pos": 37, "end_pos": 44, "type": "DATASET", "confidence": 0.8637710809707642}]}, {"text": "In some cases, these clusters seem to locate orthographic patterns that are useful in predicting the following character; for example, the characters in cluster 4 are often followed by an \"h\", and cluster 39 contains mostly letters at the end of a word (i.e. usually followed by whitespace).", "labels": [], "entities": []}, {"text": "However, we did not find clusters that were characterised only by the following characters and not by patterns in the preceding characters.", "labels": [], "entities": []}, {"text": "More interestingly, clusters consisting of points immediately preceding the start of a word tended to reflect word-level information relating to the preceding word.", "labels": [], "entities": []}, {"text": "For example, cluster 54 consists of spaces immediately following the pronouns \"he\" and \"she\", as well as the interrogative pronoun \"who\" 9 , while cluster 56 consists of spaces following certain prepositions.", "labels": [], "entities": []}, {"text": "This was observed in both the clusters based on hidden state and the clusters based on output gate activation.", "labels": [], "entities": []}, {"text": "This could be due to the fact that the output gate activations, which also impact the hidden state, can be intepreted as choosing which dimensions of the cell state are relevant for the network's \"decision\" at a given time, and we would expect that word-level information is relevant when choosing a distribution over the first letter of the next word.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Cluster members and POS statistics. Example cluster members (corresponding to whitespace characters)  are drawn uniformly at random from the cluster and are represented by the preceding word. Note that some words  appear multiple times since each appearance of the word in the text corresponds to a different data point. POS  tags are those used by the Stanford POS tagger. Statistics are reported for the three parts of speech with highest  precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 452, "end_pos": 461, "type": "METRIC", "confidence": 0.9976335763931274}]}, {"text": " Table 4: Performance of the word vectors derived from our Lancaster-Oslo/Bergen model on word similarity tasks,  compared with scores (taken from http://wordvectors.org (Faruqui and Dyer, 2014)) for the Metaopti- mize (Turian et al., 2010) and Skip-Gram (Mikolov et al., 2013) embeddings. For each set of embeddings and each  task we list the number of word pairs found and the measured correlation (Spearman's rank correlation coefficient).", "labels": [], "entities": [{"text": "word similarity tasks", "start_pos": 90, "end_pos": 111, "type": "TASK", "confidence": 0.7616947690645853}, {"text": "Spearman's rank correlation coefficient", "start_pos": 401, "end_pos": 440, "type": "METRIC", "confidence": 0.623901081085205}]}]}