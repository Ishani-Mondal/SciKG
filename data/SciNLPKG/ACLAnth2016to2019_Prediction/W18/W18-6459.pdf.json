{"title": [], "abstractContent": [{"text": "A huge amount of valuable resources is available on the web in English, which are often translated into local languages to facilitate knowledge sharing among local people who are not much familiar with English.", "labels": [], "entities": []}, {"text": "However , translating such content manually is very tedious, costly, and time-consuming process.", "labels": [], "entities": []}, {"text": "To this end, machine translation is an efficient approach to translate text without any human involvement.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.7775009870529175}]}, {"text": "Neural machine translation (NMT) is one of the most recent and effective translation technique amongst all existing machine translation systems.", "labels": [], "entities": [{"text": "Neural machine translation (NMT)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7972873349984487}, {"text": "machine translation", "start_pos": 116, "end_pos": 135, "type": "TASK", "confidence": 0.796446830034256}]}, {"text": "In this paper, we apply NMT for English-Tamil language pair.", "labels": [], "entities": [{"text": "NMT", "start_pos": 24, "end_pos": 27, "type": "METRIC", "confidence": 0.8444614410400391}]}, {"text": "We propose a novel neural machine translation technique using word-embedding along with Byte-Pair-Encoding (BPE) to develop an efficient translation system that overcomes the OOV (Out Of Vocabulary) problem for languages which do not have much translations available online.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 19, "end_pos": 45, "type": "TASK", "confidence": 0.8090994954109192}]}, {"text": "We use the BLEU score for evaluating the system performance.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 11, "end_pos": 21, "type": "METRIC", "confidence": 0.9694232940673828}]}, {"text": "Experimental results confirm that our proposed MIDAS translator (8.33 BLEU score) outper-forms Google translator (3.75 BLEU score).", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 70, "end_pos": 80, "type": "METRIC", "confidence": 0.976271390914917}, {"text": "BLEU score", "start_pos": 119, "end_pos": 129, "type": "METRIC", "confidence": 0.9769004881381989}]}], "introductionContent": [{"text": "Big countries such as India and China have several languages which change by regions.", "labels": [], "entities": []}, {"text": "For instance, India has 23 constitutionally recognized official languages (e.g., Hindi, Tamil, and Panjabi) and several hundreds unofficial local languages.", "labels": [], "entities": []}, {"text": "Despite Indian population is approximately 1.3 billion, only approximately 10% of them English speak English.", "labels": [], "entities": []}, {"text": "Some studies say that out of these 10% English speakers only 2% can speak, write, and read English well, and rest 8% can merely understand simple English and speak broken English with an amazing variety of accents (sta).", "labels": [], "entities": []}, {"text": "Considering a significant amount of valuable resources is available on the web in English and most people in India cannot understand it well, it is essential to translate such content in to local languages to facilitate people.", "labels": [], "entities": []}, {"text": "Sharing information between people is necessary not only for business purposes but also for sharing their feelings, opinions, and acts.", "labels": [], "entities": [{"text": "Sharing information between people", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8907196074724197}]}, {"text": "To this end, translation plays an important role in minimizing the communication gap between different people.", "labels": [], "entities": []}, {"text": "Considering the vast amount of information, it is not feasible to translate the content manually.", "labels": [], "entities": []}, {"text": "Hence, it is essential to translate text from one language (say, English) to another language (say, Tamil) automatically.", "labels": [], "entities": []}, {"text": "This process is also known as machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.8371560275554657}]}, {"text": "There are many challenges in machine translation for Indian languages.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.7933945953845978}]}, {"text": "For instance, (i) the size of parallel corpora and (ii) differences amongst languages, mainly the morphological richness and word order differences due to syntactical divergence are two of the major challenges.", "labels": [], "entities": []}, {"text": "Indian languages (IL) suffer both of these problems, especially when they are being translated from English.", "labels": [], "entities": []}, {"text": "There are only a few parallel corpora for English and Indian languages.", "labels": [], "entities": []}, {"text": "Moreover, Indian languages such as Tamil differ from English in word order as well as in morphological complexity.", "labels": [], "entities": []}, {"text": "For instance, English has Subject-Verb-Object (SVO) whereas Tamil has Subject-Object-Verb (SOV).", "labels": [], "entities": []}, {"text": "Moreover, English is a fusional whereas Tamil is agglutinative languages.", "labels": [], "entities": []}, {"text": "While syntactic differences contribute to difficulties of translation models, morphological differences contribute to data sparsity.", "labels": [], "entities": [{"text": "translation", "start_pos": 58, "end_pos": 69, "type": "TASK", "confidence": 0.968306303024292}]}, {"text": "We attempt to address both issues in this paper.", "labels": [], "entities": []}, {"text": "Though much work is being done on machine translation for foreign and Indian languages but apart from foreign languages most of works on Indian languages are limited to conventional machine translation techniques.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.7881912887096405}, {"text": "machine translation", "start_pos": 182, "end_pos": 201, "type": "TASK", "confidence": 0.7895578444004059}]}, {"text": "We observe that the techniques like word-embedding and Byte-pairencoding (BPE) are not applied on many Indian languages which have shown a great improvement in natural language processing.", "labels": [], "entities": []}, {"text": "Thus, in this paper, we apply a neural machine translation technique (torch implementation) with word embedding and BPE.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 32, "end_pos": 58, "type": "TASK", "confidence": 0.7367043495178223}, {"text": "BPE", "start_pos": 116, "end_pos": 119, "type": "METRIC", "confidence": 0.8170123100280762}]}, {"text": "Especially, we work on EnglishTamil language pair as it is one of the most difficult language pair (Zdenek\u017dabokrtsk`yZdenek\u02c7Zdenek\u017dabokrtsk`Zdenek\u017dabokrtsk`y, 2012) to translate due to morphologically richness of Tamil language.", "labels": [], "entities": []}, {"text": "We obtain the data from EnTamv2.0 and Opus, and evaluate our result using widely used evaluation matric BLEU.", "labels": [], "entities": [{"text": "EnTamv2.0", "start_pos": 24, "end_pos": 33, "type": "DATASET", "confidence": 0.9255003333091736}, {"text": "Opus", "start_pos": 38, "end_pos": 42, "type": "DATASET", "confidence": 0.8869565725326538}, {"text": "BLEU", "start_pos": 104, "end_pos": 108, "type": "METRIC", "confidence": 0.9873276352882385}]}, {"text": "Experimental results confirm that we got much better results than conventional machine translation techniques on Tamil language.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 79, "end_pos": 98, "type": "TASK", "confidence": 0.7832426428794861}]}, {"text": "We believe that our work can also be applied to other Indian language pairs too.", "labels": [], "entities": []}, {"text": "Main contributions of our work are as follows: \u2022 This is the first work to apply BPE with word embedding on Indian language pair (EnglishTamil) with NMT technique.", "labels": [], "entities": [{"text": "BPE", "start_pos": 81, "end_pos": 84, "type": "TASK", "confidence": 0.549192488193512}]}, {"text": "\u2022 We achieve comparable accuracy with a simpler model in less training time rather then training on deep and complex neural network which requires much time to train.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9994244575500488}]}, {"text": "\u2022 We have shown how and why data preprocessing is a crucial step in neural machine translation.", "labels": [], "entities": [{"text": "data preprocessing", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.7475822865962982}, {"text": "neural machine translation", "start_pos": 68, "end_pos": 94, "type": "TASK", "confidence": 0.6786356667677561}]}, {"text": "\u2022 Our model outperforms Google translator with margin of 4.58 BLEU score.", "labels": [], "entities": [{"text": "margin", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.9788790941238403}, {"text": "BLEU", "start_pos": 62, "end_pos": 66, "type": "METRIC", "confidence": 0.9978598952293396}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Sections 2 and 3 describe related work and the methodology of our MIDAS translator, respectively.", "labels": [], "entities": [{"text": "MIDAS translator", "start_pos": 66, "end_pos": 82, "type": "TASK", "confidence": 0.618863433599472}]}, {"text": "Evaluation is presented in Section 4.", "labels": [], "entities": []}, {"text": "Finally, Section 5 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "The BLEU score or bilingual evaluation understudy is a method to measure the difference between machine and human translations ().", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9774300158023834}]}, {"text": "The approach works by counting and matching n-grams in result translation to ngrams in the reference text, where unigram would be each token and a bigram comparison would be each word pair and soon.", "labels": [], "entities": []}, {"text": "The comparison is made regardless of word order.", "labels": [], "entities": []}, {"text": "This method is a modification of a simple precision method.", "labels": [], "entities": [{"text": "precision", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9501234889030457}]}, {"text": "We used the datasets obtained from EnTam V2.0 5 and Opus.", "labels": [], "entities": [{"text": "EnTam V2.0 5", "start_pos": 35, "end_pos": 47, "type": "DATASET", "confidence": 0.9553623596827189}, {"text": "Opus", "start_pos": 52, "end_pos": 56, "type": "DATASET", "confidence": 0.9269304871559143}]}, {"text": "The sentences are taken from various domains like news, bible, cinema, movie subtitles and combined to build our final parallel dataset.", "labels": [], "entities": []}, {"text": "After preprocessing and splitting it to train, test, and validation, our final dataset contains 1,83,451 training corpus, 1,000 validation and 2,000 test corpus from English to Tamil.", "labels": [], "entities": []}, {"text": "The data used is encoded in UTF-8 format.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: BLEU Score of English-Tamil translated  system. Symbols have the following meanings:  Bi-L= Bi-LSTM, S= SGD(Wu et al., 2016), L=  LSTM, A=Adam(Vaswani et al., 2017), B= Bah- danau (Bahdanau et al., 2014), E=Word Embed- ding, Lu=Luong(Luong et al., 2015))", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9949358701705933}, {"text": "Bi-L", "start_pos": 96, "end_pos": 100, "type": "METRIC", "confidence": 0.9470322728157043}, {"text": "Word Embed- ding", "start_pos": 217, "end_pos": 233, "type": "DATASET", "confidence": 0.8297023177146912}]}]}