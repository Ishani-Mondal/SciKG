{"title": [{"text": "Enabling Code-Mixed Translation: Parallel Corpus Creation and MT Augmentation Approach", "labels": [], "entities": [{"text": "Enabling Code-Mixed Translation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.6148574650287628}, {"text": "Parallel Corpus Creation", "start_pos": 33, "end_pos": 57, "type": "TASK", "confidence": 0.5720457633336385}, {"text": "MT Augmentation Approach", "start_pos": 62, "end_pos": 86, "type": "TASK", "confidence": 0.7442172765731812}]}], "abstractContent": [{"text": "Code-mixing, use of two or more languages in a single sentence, is generated by multilingual speakers across the world.", "labels": [], "entities": []}, {"text": "The phenomenon presents itself prominently in social media discourse.", "labels": [], "entities": []}, {"text": "Consequently, there is a growing need for translating code-mixed hybrid language into standard languages.", "labels": [], "entities": []}, {"text": "However, due to the lack of gold parallel data, existing machine translation systems fail to properly translate code-mixed text.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.7264763116836548}]}, {"text": "In an effort to initiate the task of machine translation of code-mixed content, we present a newly created parallel corpus of code-mixed English-Hindi and English.", "labels": [], "entities": [{"text": "machine translation of code-mixed content", "start_pos": 37, "end_pos": 78, "type": "TASK", "confidence": 0.8092382431030274}]}, {"text": "We selected previously available English-Hindi code-mixed data as a starting point for our parallel corpus, and 4 human translators , fluent in both English and Hindi, translated the 6,096 code-mixed English-Hindi sentences into English.", "labels": [], "entities": []}, {"text": "With the help of the created parallel corpus, we analyzed the structure of English-Hindi code-mixed data and present a technique to augment run-of-the-mill machine translation (MT) approaches that can help achieve superior translations without the need for specially designed translation systems.", "labels": [], "entities": [{"text": "run-of-the-mill machine translation (MT)", "start_pos": 140, "end_pos": 180, "type": "TASK", "confidence": 0.8035987615585327}]}, {"text": "The augmentation pipeline is presented as a pre-processing step and can be plugged with any existing MT system, which we demonstrate by improving code-mixed translations done by systems like Moses, Google Neural Machine Translation System (NMTS) and Bing Translator.", "labels": [], "entities": [{"text": "Google Neural Machine Translation System (NMTS)", "start_pos": 198, "end_pos": 245, "type": "TASK", "confidence": 0.6718162447214127}]}], "introductionContent": [{"text": "In the last decade, digital communication mediums like e-mail, Facebook, Twitter, etc.", "labels": [], "entities": []}, {"text": "have allowed people to have conversations in a much more informal manner than before.", "labels": [], "entities": []}, {"text": "This informal nature of conversations has given rise to anew form of hybrid language, called code-mixed language, that lacks a formally defined structure.", "labels": [], "entities": []}, {"text": "Myers-Scotton (1993) defines code-mixing as \"the embedding of linguistic units such as phrases, words and morphemes of one language into an utterance of another language\".", "labels": [], "entities": []}, {"text": "Code-switching is a similar concept, except that code-mixing is observed entirely in a single sentence, while code-switching occurs across sentences.", "labels": [], "entities": []}, {"text": "For the purposes of this study, however, we will not make a difference between code-mixing and code-switching and treat them both as code-mixing.", "labels": [], "entities": []}, {"text": "Code-mixing of Hindi and English, where sentences follow the syntax of Hindi but borrow some vocabulary from English is very prevalent on social media content in India, where most people are multilingual.", "labels": [], "entities": []}, {"text": "An example of a code-mixed English-Hindi sentence is presented below: \u2022 \"Main kal movie dekhne jaa rahi thi and raaste me I met Sam.\"", "labels": [], "entities": []}, {"text": "Gloss : I yesterday to-see go Continous-marker was way in.", "labels": [], "entities": [{"text": "Gloss", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.986177921295166}]}, {"text": "English Translation : I was going to a movie yesterday and I met Sam on the way.", "labels": [], "entities": []}, {"text": "This phenomenon is present in informal communication in almost every multi-lingual society, as studied by.", "labels": [], "entities": []}, {"text": "They investigated how language used on these social media platforms, which they have called texting language, differs from the standard language that is found in more formal texts like books.", "labels": [], "entities": []}, {"text": "It is also more common in the areas of the world where people are naturally bi-or multi-lingual.", "labels": [], "entities": []}, {"text": "Usually, these are the areas where languages changeover short geo-spatial distances and people generally have at least a basic knowledge of the neighbouring languages (.", "labels": [], "entities": []}, {"text": "Avery good example for this is a country like India which has an extensive language diversity and where dialectal changes frequently instigate code-mixing.", "labels": [], "entities": []}, {"text": "In recent times, we have seen an explosion of Computer Mediated Communication (CMC) worldwide.", "labels": [], "entities": [{"text": "Computer Mediated Communication (CMC)", "start_pos": 46, "end_pos": 83, "type": "TASK", "confidence": 0.7964201619227728}]}, {"text": "In CMC, language use lies somewhere in between spoken and written forms of a language and tend to use simple shorter constructions, contractions and phrasal repetitions typical of speech.", "labels": [], "entities": []}, {"text": "Such conversations, especially in social-media are both multi-party and multilingual, with mixing occurring between two or more languages, where the choice of languageuse being highly influenced by the speakers and their communicative goals.", "labels": [], "entities": []}, {"text": "With multiple languages coming into play, and the variety of factors which influence the usage of those, the task of processing text becomes quite difficult.", "labels": [], "entities": []}, {"text": "As of now, according to the data of internetworldstats.com, the Internet has four-hundred fifty million English speaking users out of one billion five hundred million total users.", "labels": [], "entities": []}, {"text": "This means that the market for English language is slightly less than one third of the total market.", "labels": [], "entities": []}, {"text": "In other terms, most current approaches to information extraction exploiting social media and user-generated content (UGC), that are predominantly developed for English, are working with a mere third of the total data available.", "labels": [], "entities": [{"text": "information extraction exploiting social media and user-generated content (UGC)", "start_pos": 43, "end_pos": 122, "type": "TASK", "confidence": 0.8618203564123674}]}, {"text": "The huge part of UGC that is not in English is currently being neglected mostly due to the relatively ephemeral character of UGC in general.", "labels": [], "entities": [{"text": "UGC", "start_pos": 17, "end_pos": 20, "type": "DATASET", "confidence": 0.9332826137542725}]}, {"text": "All this leads to an enormous body of information being constantly generated which is also being constantly lost behind language barriers: the consolidation of Web 2.0 has caused an unprecedented increase in the amount of data and each individual user is currently being deprived of most of it (.", "labels": [], "entities": []}, {"text": "These language barriers are intensified by the fact that a huge number of people don't use just one language, but multiple languages simultaneously, in the form of code-mixing.", "labels": [], "entities": []}, {"text": "Even if we were able to create a system capable of processing information in every language, or perhaps a system capable of translating text from any given language to another, we would still not be able to breakdown the language barrier completely, due to the phenomenon of code-mixing.", "labels": [], "entities": []}, {"text": "This is where code-mixed translation comes into play.", "labels": [], "entities": [{"text": "code-mixed translation", "start_pos": 14, "end_pos": 36, "type": "TASK", "confidence": 0.568235456943512}]}, {"text": "While translation of code-mixed text has been a requirement for sometime, there is a noticeable lack of resources for this task.", "labels": [], "entities": [{"text": "translation of code-mixed text", "start_pos": 6, "end_pos": 36, "type": "TASK", "confidence": 0.8723198920488358}]}, {"text": "To tackle this problem, we have created a set of 6096 English-Hindi code-mixed and monolingual English gold standard parallel sentences as an initial attempt to promote generation of data resources for this domain.", "labels": [], "entities": []}, {"text": "However, most MT systems require a significant number of \"parallel\" sentences to perform well.", "labels": [], "entities": [{"text": "MT", "start_pos": 14, "end_pos": 16, "type": "TASK", "confidence": 0.990868091583252}]}, {"text": "While we wait for large parallel corpora for code-mixed text to be developed, we could make do by equipping the existing state-of-the-art MT systems to handle code-mixed content.", "labels": [], "entities": []}, {"text": "This necessity has motivated us to develop an augmentation pipeline to support code-mixing on existing MT systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 103, "end_pos": 105, "type": "TASK", "confidence": 0.9218776226043701}]}, {"text": "To summarize, the main contributions of this work are as follows: \u2022 We are releasing 1 a gold standard parallel corpus consisting of 6096 English-Hindi code-mixed and monolingual English that we created.", "labels": [], "entities": []}, {"text": "\u2022 We have developed an augmentation pipeline for existing machine translation systems that can boost their translation performance on code-mixed content.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 58, "end_pos": 77, "type": "TASK", "confidence": 0.7142638862133026}]}, {"text": "\u2022 We carryout experiments involving various machine translation systems like Moses, Google NMTS and Bing Translator to compare their translation performance on code-mixed text, and demonstrate how our augmentation pipeline improves their translation results.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.7367025017738342}, {"text": "Google NMTS", "start_pos": 84, "end_pos": 95, "type": "DATASET", "confidence": 0.8454226553440094}]}, {"text": "The rest of our paper is divided into the following sections: We begin with a study of research conducted in this domain in Section 2.", "labels": [], "entities": []}, {"text": "We discuss the process of creation of the corpus and its features in Section 3.", "labels": [], "entities": []}, {"text": "In Section 4, we introduce our augmentation pipeline for machine translation systems and describe the approach in detail.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.7890043556690216}]}, {"text": "Then in Section 5, we perform experiments with existing machine translation systems, and describe the impact of our augmentation pipeline on their translation accuracy for code-mixed data, proceeded by a discussion of our results.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.7159686982631683}, {"text": "accuracy", "start_pos": 159, "end_pos": 167, "type": "METRIC", "confidence": 0.9084820747375488}]}], "datasetContent": [{"text": "In order to evaluate our methods of augmentation, we consider the following existing machine translation systems: Moses For training a translation model for Moses, we used the English-Hindi parallel corpus released by.", "labels": [], "entities": []}, {"text": "This dataset consists of 1,492,827 parallel monolingual English and monolingual Hindi sentences.", "labels": [], "entities": []}, {"text": "The Hindi sentences were in the Devanagari script, and required pre-processing for use with our code-mixed dataset, which is entirely in Roman script.", "labels": [], "entities": []}, {"text": "We compare the output translations of these MT systems for code-mixed data, with and without the augmentation by our system.", "labels": [], "entities": [{"text": "MT", "start_pos": 44, "end_pos": 46, "type": "TASK", "confidence": 0.9436460733413696}]}, {"text": "For accuracy metrics, we chose BLEU score, Word Error Rate (WER) and Translation Error Rate (TER) as they are ideal for use with machine translation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9969845414161682}, {"text": "BLEU score", "start_pos": 31, "end_pos": 41, "type": "METRIC", "confidence": 0.9854511618614197}, {"text": "Word Error Rate (WER)", "start_pos": 43, "end_pos": 64, "type": "METRIC", "confidence": 0.9252512753009796}, {"text": "Translation Error Rate (TER)", "start_pos": 69, "end_pos": 97, "type": "METRIC", "confidence": 0.9710217912991842}, {"text": "machine translation", "start_pos": 129, "end_pos": 148, "type": "TASK", "confidence": 0.7491267919540405}]}, {"text": "As can be observed from, our augmentation pipeline significantly improves the translation accuracy of existing machine translation systems.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9057376384735107}, {"text": "machine translation", "start_pos": 111, "end_pos": 130, "type": "TASK", "confidence": 0.7378774285316467}]}, {"text": "Note that among the systems themselves, Google NMTS performs much better on code-mixed English-Hindi data as compared to traditional phrase based systems like Moses and even neural systems like Bing Translator.", "labels": [], "entities": []}, {"text": "Even though Moses does not perform as well as the other systems described here for code-mixed data, our pipeline is still able to boost its performance significantly.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Augmenting Google Translate with our pipeline", "labels": [], "entities": [{"text": "Augmenting Google Translate", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.8452462156613668}]}, {"text": " Table 3: Comparison of performance with and without using our augmentation pipeline. (Note: BLEU - higher is better, (WER,TER) -lower is better.)", "labels": [], "entities": [{"text": "BLEU", "start_pos": 93, "end_pos": 97, "type": "METRIC", "confidence": 0.9996217489242554}, {"text": "WER,TER) -lower", "start_pos": 119, "end_pos": 134, "type": "METRIC", "confidence": 0.9615565687417984}]}]}