{"title": [{"text": "What makes us laugh? Investigations into Automatic Humor Classification", "labels": [], "entities": [{"text": "Investigations into Automatic Humor", "start_pos": 21, "end_pos": 56, "type": "TASK", "confidence": 0.631629005074501}]}], "abstractContent": [{"text": "Most scholarly works in the field of computational detection of humour derive their inspiration from the incongruity theory.", "labels": [], "entities": [{"text": "computational detection of humour", "start_pos": 37, "end_pos": 70, "type": "TASK", "confidence": 0.8395500183105469}]}, {"text": "Incongruity is an indispensable facet in drawing a line between humorous and non-humorous occurrences but is immensely inadequate in shedding light on what actually made the particular occurrence a funny one.", "labels": [], "entities": [{"text": "Incongruity", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.8209149241447449}]}, {"text": "Classical theories like Script-based Semantic Theory of Humour and General Verbal Theory of Humour try and achieve this feat to an adequate extent.", "labels": [], "entities": [{"text": "Script-based Semantic Theory of Humour", "start_pos": 24, "end_pos": 62, "type": "TASK", "confidence": 0.685321182012558}, {"text": "General Verbal Theory of Humour", "start_pos": 67, "end_pos": 98, "type": "TASK", "confidence": 0.5832308053970336}]}, {"text": "In this paper we adhere to a more holistic approach towards classification of humour based on these classical theories with a few improvements and revisions.", "labels": [], "entities": [{"text": "classification of humour", "start_pos": 60, "end_pos": 84, "type": "TASK", "confidence": 0.916522204875946}]}, {"text": "Through experiments based on our linear approach and performed on large data-sets of jokes, we are able to demonstrate the adaptability and show componentiz-ability of our model, and that a host of classification techniques can be used to overcome the challenging problem of distinguishing between various categories and sub-categories of jokes.", "labels": [], "entities": []}], "introductionContent": [{"text": "Humor is the tendency of particular cognitive experiences to provoke laughter and provide amusement.", "labels": [], "entities": [{"text": "Humor", "start_pos": 0, "end_pos": 5, "type": "TASK", "confidence": 0.8829370141029358}]}, {"text": "Humor is an essential element of all verbal communication.", "labels": [], "entities": [{"text": "Humor", "start_pos": 0, "end_pos": 5, "type": "TASK", "confidence": 0.9405621886253357}]}, {"text": "Natural language systems should be able to handle humor as it will improve userfriendliness and human-computer interaction.", "labels": [], "entities": []}, {"text": "Humour has been studied fora number of years in computational linguistics in terms of both humour generation (,) and detection, but no such work has been done to create a classification of humor.", "labels": [], "entities": [{"text": "humour generation", "start_pos": 91, "end_pos": 108, "type": "TASK", "confidence": 0.6763351857662201}]}, {"text": "Humor Detection has been approached as a classification problem by).", "labels": [], "entities": [{"text": "Humor Detection", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.9596394896507263}]}, {"text": "Classification of humour is a very dif- * * Both authors have contributed equally towards the paper (names in lexicographic sequence).", "labels": [], "entities": [{"text": "Classification of humour", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9121839006741842}]}, {"text": "ficult task because even theoretically there is not much consensus among theorists regarding what exactly humour is?", "labels": [], "entities": []}, {"text": "Even if there were a specific theory as to what are the categories of humor, the sense of humour varies from person to person and therefore giving its types is even more difficult.", "labels": [], "entities": []}, {"text": "Consensus is yet to be achieved regarding the categorization of humour (.", "labels": [], "entities": [{"text": "categorization of humour", "start_pos": 46, "end_pos": 70, "type": "TASK", "confidence": 0.7260373830795288}]}, {"text": "To achieve this difficult feat of classification we try to answer the most basic question of Why do we laugh on a joke?.", "labels": [], "entities": [{"text": "classification", "start_pos": 34, "end_pos": 48, "type": "TASK", "confidence": 0.9470600485801697}]}, {"text": "This is the most novel thing that only we are trying to achieve as of now.", "labels": [], "entities": []}, {"text": "First of all the possible types of humor can be virtually infinite.", "labels": [], "entities": []}, {"text": "Some researchers reduce humor to just one, or a few types, for example, incongruity).", "labels": [], "entities": []}, {"text": "Since there are infinite possible types, there is a continued lack of any generally accepted taxonomy of humor, thus it maybe classified according to different purposes.", "labels": [], "entities": []}, {"text": "These classifications may often overlap.", "labels": [], "entities": []}, {"text": "For instance the joke: A clean desk is a sign of a cluttered desk drawer can be labeled as a sarcastic joke as well as a wordplay joke/pun(antonyms).", "labels": [], "entities": []}, {"text": "We are trying to formulate the problem of determining different types of humor as a traditional classification task by feeding positive and negative datasets to a classifier.", "labels": [], "entities": []}, {"text": "The data-set consists of one liners jokes of different types collected from many jokes websites, multiple subreddits and multiple twitter handles.", "labels": [], "entities": []}, {"text": "In short, our contributions can be summarized as follows: \u2022 We present a theoretical framework which also provides the base for the task of computational classification of avast array of types of jokes into categories and sub-categories \u2022 We present a comparative study of a wide range of topic detection methods on large 1 data sets of one-liner jokes.", "labels": [], "entities": [{"text": "computational classification of avast array of types of jokes into categories", "start_pos": 140, "end_pos": 217, "type": "TASK", "confidence": 0.8429656760259108}, {"text": "topic detection", "start_pos": 289, "end_pos": 304, "type": "TASK", "confidence": 0.735637977719307}]}, {"text": "\u2022 We analyze jokes based on the theme that they expresses and the emotion that they evoke.", "labels": [], "entities": []}, {"text": "The remainder of the paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 provides an overview of related work and their shortcomings.", "labels": [], "entities": []}, {"text": "Section 3 presents the framework proposed.", "labels": [], "entities": []}, {"text": "Section 4 presents the dataset along with some pre-processing steps.", "labels": [], "entities": []}, {"text": "Section 5 presents the various experiments conducted on the data set.", "labels": [], "entities": []}, {"text": "Section 6 discusses the results, while Section 7 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "\u2022 Topic Detection : For the task of topic detection in Jokes we mined many jokes websites and collected their tags and considered those our topics.", "labels": [], "entities": [{"text": "Topic Detection", "start_pos": 2, "end_pos": 17, "type": "TASK", "confidence": 0.8358622789382935}, {"text": "topic detection in Jokes", "start_pos": 36, "end_pos": 60, "type": "TASK", "confidence": 0.7593379467725754}]}, {"text": "We have restricted our Jokes to the following categories: Animal, Blonde, Fat, Food, Profession, Kids, Marriage, Money, Nationality, Sports, News/politics, Police/military , Technology, Height, Men/Women, Celebrities/Pop Culture, Travel, Doctor, Lawyer, God/religion, Pick up lines, school, party, Walks into a bar, Yo-mama.", "labels": [], "entities": []}, {"text": "Most of the jokes websites had the above topics as common topics.", "labels": [], "entities": []}, {"text": "We mined nearly 40,000 one liners jokes belonging to these 25 categories for the use of Topic Detection.", "labels": [], "entities": [{"text": "Topic Detection", "start_pos": 88, "end_pos": 103, "type": "TASK", "confidence": 0.8568972647190094}]}, {"text": "Since they were collected automatically, it is possible to have noise in the dataset.", "labels": [], "entities": []}, {"text": "\u2022 Sarcastic Jokes : For the task of Sarcasm Detection we mined Sarcastic jokes(positive) from reddit and other jokes websites which had sarcasm tags in it.", "labels": [], "entities": [{"text": "Sarcastic Jokes", "start_pos": 2, "end_pos": 17, "type": "TASK", "confidence": 0.7620145678520203}, {"text": "Sarcasm Detection", "start_pos": 36, "end_pos": 53, "type": "TASK", "confidence": 0.9334158897399902}]}, {"text": "For negative data we considered data under tags other than Sarcasm and manually verified the jokes.", "labels": [], "entities": [{"text": "Sarcasm", "start_pos": 59, "end_pos": 66, "type": "DATASET", "confidence": 0.802557110786438}]}, {"text": "We created a dataset of 5000 jokes with 2500 belonging to the the positive set and and equal amount of negative instances and manually verified them \u2022 NSFW Jokes : These are the types of jokes which are most famous on the online media.These types of jokes are mainly associated with heavy nudity, sexual content, heavy profanity and adult slangs.", "labels": [], "entities": [{"text": "NSFW Jokes", "start_pos": 151, "end_pos": 161, "type": "DATASET", "confidence": 0.8768777549266815}]}, {"text": "We collected multiple one liner jokes from subreddit /r/dirtyjokes and took jokes from various jokes websites with tags NSFW, dirty, adult and sexual.", "labels": [], "entities": [{"text": "NSFW", "start_pos": 120, "end_pos": 124, "type": "DATASET", "confidence": 0.8479214906692505}]}, {"text": "We created a dataset of 5000 jokes with 2500 belonging to the positive instances and equal number of negative instances verified manually.", "labels": [], "entities": []}, {"text": "\u2022 Insults : These kinds of jokes mainly consists mainly of offensive insults directed someone else or towards the speaker itself.)", "labels": [], "entities": []}, {"text": "Typical targets for insult include individuals in the show's audience, or the subject of a roast.", "labels": [], "entities": []}, {"text": "The speaker of an insult joke often maintains a competitive relationship with the listener.", "labels": [], "entities": []}, {"text": "We collected multiple jokes from the subreddit /r/roastme and after manual verification we had 2000 jokes of positive instances and for negative instances we manually created a dataset of 2000 one liner jokes.", "labels": [], "entities": []}, {"text": "\u2022 Gross : A joke having to do with disgusting acts or other things people might find grotesque.", "labels": [], "entities": []}, {"text": "We extracted 500 jokes various jokes website which had a \"gross\" category/tag in it.", "labels": [], "entities": []}, {"text": "We selected equal number of non gross jokes from the above datatset.", "labels": [], "entities": []}, {"text": "After manual verification we had a total of 1000 jokes in this category, 500 belonging to both positive and negative sets.", "labels": [], "entities": []}, {"text": "\u2022 Dark Humor : It's a form of humor involving a twist or joke making the joke seen as offensive, harsh, horrid, yet the joke is still funny.", "labels": [], "entities": [{"text": "Dark Humor", "start_pos": 2, "end_pos": 12, "type": "TASK", "confidence": 0.6919223219156265}]}, {"text": "We collected multiple jokes from subreddit /r/darkjokes as well as as many jokes websites containing the tag Dark Humor.", "labels": [], "entities": []}, {"text": "After removing duplicates we had a dataset of 3500 dark jokes.", "labels": [], "entities": []}, {"text": "For negative samples we randomly selected 3500 jokes from the jokes websites which did not contain Dark Humor in their tags and manually verified them.", "labels": [], "entities": []}, {"text": "We performed various experiments on our dataset.", "labels": [], "entities": []}, {"text": "For the evaluation we randomly divided our dataset into 90% training and 10% testing.", "labels": [], "entities": []}, {"text": "All the experiments were conducted 10 fold and the final performance is reported by averaging the result.", "labels": [], "entities": []}, {"text": "\u2022 Topic Detection : There area wide variety of methods and variables and they greatly affect the quality of results.", "labels": [], "entities": [{"text": "Topic Detection", "start_pos": 2, "end_pos": 17, "type": "TASK", "confidence": 0.8251500427722931}]}, {"text": "We compare results from three topic detection methods on our dataset to detect topics of these jokes.", "labels": [], "entities": [{"text": "topic detection", "start_pos": 30, "end_pos": 45, "type": "TASK", "confidence": 0.7131621986627579}]}, {"text": "We use LDA, Naive Bayes and SVM along with lexical and Pragmatic features and compared their results.", "labels": [], "entities": [{"text": "Pragmatic", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.9638631343841553}]}, {"text": "We also augment the used approaches by boosting proper nouns and then, recalculating the experiment results on the same dataset.", "labels": [], "entities": []}, {"text": "The boosting techniques that we have used are duplication proper nouns.", "labels": [], "entities": [{"text": "duplication proper nouns", "start_pos": 46, "end_pos": 70, "type": "TASK", "confidence": 0.8838113943735758}]}, {"text": "This boosting technique was chosen keeping in mind the need to give priority to the tweet semantic.", "labels": [], "entities": []}, {"text": "\u2022 Sarcastic : We treat sarcasm detection as a classification problem.", "labels": [], "entities": [{"text": "sarcasm detection", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.986811488866806}]}, {"text": "After pre-processing the data we extracted n-grams more precisely, unigrams and bigrams from the dataset and then were added to the feature dictionary.", "labels": [], "entities": []}, {"text": "Along with this we used brown clustering which helped us to put similar kinds of words in same cluster.", "labels": [], "entities": []}, {"text": "Along with these features we also took sentiment values of the different parts of joke(here 3) as a feature because there is usually a great difference in sentiment scores in different part of a sarcastic joke or a tweet.", "labels": [], "entities": []}, {"text": "Using these lexical as well as pragmatic features as in () we train a logistic regression and a SVM to distinguish between sarcastic jokes from non sarcastic jokes.", "labels": [], "entities": []}, {"text": "\u2022 Exaggeration : These are types of statements that represents something as better or worse than it really is.", "labels": [], "entities": []}, {"text": "They can create a comical effect when used appropriately.", "labels": [], "entities": []}, {"text": "For eg: In the joke \"You grandma is as old as mountains\", the intensity of the statement is increased by using phrase like \"as old as\".", "labels": [], "entities": []}, {"text": "We detect such intense phrases in jokes to categorize under this category by getting sentiment score of every token.", "labels": [], "entities": [{"text": "sentiment score", "start_pos": 85, "end_pos": 100, "type": "METRIC", "confidence": 0.9009798169136047}]}, {"text": "Individual sentiment score of every token in phase as well the combined sentiment score will be in positive range to generate an exaggeration effect.", "labels": [], "entities": []}, {"text": "\u2022 Antonyms/Semantic Opposites : An antonym is one of a pair of words with opposite meanings.", "labels": [], "entities": []}, {"text": "Each word in the pair is the antithesis of the other.", "labels": [], "entities": []}, {"text": "We use the antonym relation in WORDNET among noun, adjectives and verbs and used approach similar to \u2022 Phonetic Features : Rhyming words also create a joke.", "labels": [], "entities": []}, {"text": "For instance the joke -Coca Cola went to town, Diet Pepsi shot him down.", "labels": [], "entities": []}, {"text": "Dr. Pepper fixed him up, Now we are drinking 7up creates a comical effect due the fact that town and down , up and 7up are rhyming words.", "labels": [], "entities": []}, {"text": "Similar rhetorical devices play an important role in wordplay jokes, and are often used in.", "labels": [], "entities": []}, {"text": "We used CMU Pronunciation Dictionary to detect rhyming words \u2022 Secondary Meaning : These are the types of the jokes where we find that there is semantic relation among words in a jokes and that relation could be in a form located in, part of, type of, related to, has, etc.", "labels": [], "entities": [{"text": "CMU Pronunciation Dictionary", "start_pos": 8, "end_pos": 36, "type": "DATASET", "confidence": 0.9120974739392599}]}, {"text": "For eg: In the joke \"Those who like the sport fishing can really get hooked\" comical effect is created due to the relation between \"hook\" and \"fishing\".", "labels": [], "entities": []}, {"text": "In order to detect these relations in a joke we are using Concept Net (.", "labels": [], "entities": []}, {"text": "It is a multilingual knowledge base, representing words and phrases that people use and the common-sense relationships between them.", "labels": [], "entities": []}, {"text": "So, using concept net we are able to give a used in relationship between hook and fishing.", "labels": [], "entities": []}, {"text": "We are going upto three levels to detect secondary relationship between different terms in a joke.", "labels": [], "entities": []}, {"text": "\u2022 Dark Humor : It is a comic style that makes light of subject matter that is generally considered taboo, particularly subjects that are normally considered serious or painful to discuss such as death.", "labels": [], "entities": [{"text": "Dark Humor", "start_pos": 2, "end_pos": 12, "type": "TASK", "confidence": 0.7688628435134888}]}, {"text": "Some comedians use it as a tool for exploring vulgar issues, thus provoking discomfort and serious thought as well as amusement in their audience.", "labels": [], "entities": []}, {"text": "Popular themes of the genre include violence, discrimination, disease, religion and barbarism.", "labels": [], "entities": []}, {"text": "Treating it as a classification problem, we extracted unigrams from the dataset.", "labels": [], "entities": []}, {"text": "We also  \u2022 Adult Slangs/Sexual Jokes : These types of jokes are most famous on the internet.After pre-processing we extracted unigrams and bigrams.", "labels": [], "entities": [{"text": "Adult Slangs/Sexual Jokes", "start_pos": 11, "end_pos": 36, "type": "TASK", "confidence": 0.7161329984664917}]}, {"text": "To detect these types of jokes we used a slang dictionary called Slang SD (.", "labels": [], "entities": [{"text": "Slang SD", "start_pos": 65, "end_pos": 73, "type": "TASK", "confidence": 0.5805745720863342}]}, {"text": "It contains over 90,000 slang words/phrases along with their sentiment scores.", "labels": [], "entities": []}, {"text": "We used these features and compared accuracies of classification methods such as SVM and Logistic Regression.", "labels": [], "entities": []}, {"text": "\u2022 Gross : Treating the problem of detecting Gross Jokes as a classification problem, unigrams are extracted after pre-processing.", "labels": [], "entities": []}, {"text": "We kept a list of top 100 gross words according to their tf-idf score.", "labels": [], "entities": []}, {"text": "This feature indicated the presence of gross words.", "labels": [], "entities": []}, {"text": "Along with this we also maintain sentiment scores because of the   hypothesis that gross jokes tends to have a negative sentiment.", "labels": [], "entities": [{"text": "sentiment scores", "start_pos": 33, "end_pos": 49, "type": "METRIC", "confidence": 0.8456509113311768}]}, {"text": "Using all these features we compare accuracies using SVM and Logistic Regression.", "labels": [], "entities": []}, {"text": "\u2022 Insults: After pre-processing we are extracting unigrams and bigrams from the dataset.", "labels": [], "entities": []}, {"text": "Along with this we are creating a list of insulting words using top 100 words according to their Tfidf score.", "labels": [], "entities": [{"text": "Tfidf score", "start_pos": 97, "end_pos": 108, "type": "METRIC", "confidence": 0.665757566690445}]}, {"text": "Along with this we calculated semantic scores of each of the joke and used these features in a Naive Bayes Classifier and a SVM.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 6: Adult Slang/Sexual Jokes", "labels": [], "entities": [{"text": "Adult Slang/Sexual Jokes", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.7011700928211212}]}]}