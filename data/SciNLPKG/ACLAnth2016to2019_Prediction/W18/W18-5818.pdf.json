{"title": [], "abstractContent": [{"text": "Modeling morphological inflection is an important task in Natural Language Processing.", "labels": [], "entities": [{"text": "Modeling morphological inflection", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.934207022190094}, {"text": "Natural Language Processing", "start_pos": 58, "end_pos": 85, "type": "TASK", "confidence": 0.6346724033355713}]}, {"text": "In contrast to earlier work that has largely used orthographic representations, we experiment with this task in a phonetic character space, representing inputs as either IPA segments or bundles of phonological distinctive features.", "labels": [], "entities": []}, {"text": "We show that both of these inputs, somewhat counterintuitively, achieve similar accuracies on morphological inflection, slightly lower than orthographic models.", "labels": [], "entities": []}, {"text": "We conclude that providing detailed phonological representations is largely redundant when compared to IPA segments, and that articulatory distinctions relevant for word inflection are already latently present in the distributional properties of many graphemic writing systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "Models of morphology are important to many tasks in Natural Language Processing, but also present new challenges of their own.", "labels": [], "entities": [{"text": "Natural Language Processing", "start_pos": 52, "end_pos": 79, "type": "TASK", "confidence": 0.628138393163681}]}, {"text": "Morphologically complex languages require analysis that is often only captured at the morpheme level, but is essential for syntactic or semantic representations.", "labels": [], "entities": []}, {"text": "This requires effective morphological analysis, which often receives less attention than other subfields of Natural Language Processing.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.701689139008522}]}, {"text": "One relevant task in morphology is that of morphological inflection: automatically generating the inflected form of a lemma according to a given morphological specification.", "labels": [], "entities": []}, {"text": "An example of this in English is walk + 3 + SG + PRES \u2192 walks . There has been recent success in adopting the encoder-decoder architecture (, which has been effective in machine translation ( , to this task.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 170, "end_pos": 189, "type": "TASK", "confidence": 0.7960889637470245}]}, {"text": "In this work, we explore representing the inputs to such an encoder-decoder model for morphological inflection in two additional ways: IPA segments and bundles of phonological distinctive features.", "labels": [], "entities": []}, {"text": "Representing the inputs to an inflection model in phonetic space can unify the character inventory between languages with separate orthographies.", "labels": [], "entities": []}, {"text": "The shared character inventory could also enable transfer learning in some instances where it otherwise would be impossible.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 49, "end_pos": 66, "type": "TASK", "confidence": 0.9652320146560669}]}, {"text": "There are also confusing idiosyncrasies in some orthographies that are not necessarily present in an IPA representation.", "labels": [], "entities": []}, {"text": "For example, there are many instances of gemination in English that do not occur in the phonetic realizations of such words, as in control \u2192 controlled.", "labels": [], "entities": []}, {"text": "English also exhibits several examples of the same sound expressed by completely different orthographic realizations as in fly \u2192 flies, or conversely arch (/tS/) \u223c monarch (/k/).", "labels": [], "entities": []}, {"text": "Furthermore, a phonetic representation serves as an interface to an even richer representation of characters: phonological distinctive features.", "labels": [], "entities": []}, {"text": "We explore this by representing each IPA segment in a sequence as the combination of its distinctive features.", "labels": [], "entities": []}, {"text": "This is potentially useful because (1) a model can learn representations fora fixed set of distinctive features, rather than for each unique IPA segment, and (2) the differences between similar phonemes should be more readily apparent in the distinctive feature representations than the IPA representations.", "labels": [], "entities": []}, {"text": "When tasked with generating the past tense of the English verb \"stop\", transcribed as /stAp/, a model may need to distinguish between both /t/ and /d/ as past tense suffixes, having seen such examples as \"kick\": /kIk/ \u2192 /kIkt/, or \"rig\": /\u00f4Ig/ \u2192 /\u00f4Igd/.", "labels": [], "entities": []}, {"text": "Rather than the model needing to learn good representations for both /p/ and /k/ as unrelated segments that precede a /t/ in the past tense, a phonological distinctive feature representation would explicitly capture that they share the feature.", "labels": [], "entities": []}, {"text": "This encourages a model to more quickly find the parameters that correctly gener-ate this voicing assimilation, and produce the form /stApt/.", "labels": [], "entities": []}, {"text": "That is, the model that learns from phonological features should quickly be able to generalize that this English past tense is realized as /t/ before voiceless segments.", "labels": [], "entities": []}, {"text": "Similarly, in the example of \"rob\": /\u00f4Ab/ \u2192 /\u00f4Abd/, the generated /d/ can be conditioned on rather than the individual segment /b/.", "labels": [], "entities": []}, {"text": "An alternative hypothesis is that the proposed distinctive feature representation may, however, not have such a profound effect on the inflection model.", "labels": [], "entities": []}, {"text": "This is because distributional representations of IPA segments or phonemic graphemes have been shown to capture good approximations of the distinctive feature space (.", "labels": [], "entities": []}, {"text": "In order to test these two hypotheses, we experiment on a subset of data provided by task 1 of the CoNLL-SIGMORPHON 2017 Shared Task on Universal Morphological Reinflection, which introduced 42 more languages than the year before ( fora total of 52 languages.", "labels": [], "entities": [{"text": "CoNLL-SIGMORPHON 2017 Shared Task on Universal Morphological Reinflection", "start_pos": 99, "end_pos": 172, "type": "TASK", "confidence": 0.645689819008112}]}, {"text": "We use an existing tool to perform G2P on the data, and, as a second step, to produce distinctive feature vectors from the resulting IPA segments.", "labels": [], "entities": []}, {"text": "We evaluate the resulting models on their ability to generate IPA segments.", "labels": [], "entities": []}, {"text": "Related Work Phonetic distributional vectors have been explored for their effectiveness in several NLP applications; especially for informing scenarios that utilize borrowing or transfer learning (.", "labels": [], "entities": [{"text": "borrowing or transfer learning", "start_pos": 165, "end_pos": 195, "type": "TASK", "confidence": 0.7307452708482742}]}, {"text": "Phonological distinctive features have also been successfully used to inform NER ( . However, to our knowledge, there does not seem to be work in learning distributional properties of phonological features that compares them directly to vectors of IPA segments.", "labels": [], "entities": [{"text": "NER", "start_pos": 77, "end_pos": 80, "type": "TASK", "confidence": 0.9509783983230591}]}], "datasetContent": [{"text": "We evaluate these models on 8 languages that are at the intersection of CoNLL-SIGMORPHON data, Epitran, and PanPhon supported languages, selected to exhibit typological diversity.", "labels": [], "entities": [{"text": "CoNLL-SIGMORPHON data", "start_pos": 72, "end_pos": 93, "type": "DATASET", "confidence": 0.9259248375892639}]}, {"text": "The languages, split into 2 training settings per the shared task data: Medium (\u223c1,000 training examples), and High (\u223c10,000 training examples), and their accuracies are given in.", "labels": [], "entities": []}, {"text": "In the high data setting using orthographic inputs, our implementation performed comparably to the best shared task systems for each language.", "labels": [], "entities": []}, {"text": "The slight degradation in performance can be attributed to the fact that we did not use ensemble voting, as the top performing systems in the shared task did, and that this is a comparison to the maximum score of 25 systems per language, which increases the likelihood that the optimal initialization will have been found.", "labels": [], "entities": []}, {"text": "In the medium setting, the difference inaccuracy is much more apparent.", "labels": [], "entities": []}, {"text": "This is due to the fact that all of the top performing systems in the shared task also used either some type of data augmentation method (,,, ,) a hard alignment method (), or both (.", "labels": [], "entities": []}, {"text": "These results illustrate the common observation that neural systems require a large amount of data to be very accurate,  which can be partially addressed by artificially expanding the training data, or enforcing some copy bias into the system.", "labels": [], "entities": []}, {"text": "For both phonetic representation experiments, the decoded outputs are in the inventory of IPA segments, the gold standard of which comes from the deterministic mappings implemented in Epitran.", "labels": [], "entities": []}, {"text": "This means that they differ only in terms of the input representation in the encoder.", "labels": [], "entities": []}, {"text": "Models trained on both IPA and feature inputs perform comparably to the text model on both the medium and the high setting.", "labels": [], "entities": []}, {"text": "There are two main points of interest in the results.", "labels": [], "entities": []}, {"text": "(1) The lower performance on average of the IPA and feature models when compared to the text model is almost exclusively due to differences inaccuracy for German and English.", "labels": [], "entities": []}, {"text": "We attribute this on the one hand to the fact that the orthography of English is often dissimilar to pronunciations and that their orthographies reflect etymological information which is useful in determining a word's inflectional behavior.", "labels": [], "entities": []}, {"text": "An example of the discrepancy between spelling and pronunciation is that the English vowel space has about 13 phonetic vowels, whereas in the orthographic alphabet, there are only 5.", "labels": [], "entities": []}, {"text": "Furthermore, the unstressed vowel, schwa (@), can essentially replace any vowel in an unstressed context.", "labels": [], "entities": []}, {"text": "We observe that the majority of inaccuracies in the English predictions are related to vowels, and most commonly to a schwa.", "labels": [], "entities": []}, {"text": "This indicates that converting the character space to IPA can introduce some new complications.", "labels": [], "entities": []}, {"text": "Regarding German, there is no obvious explanation for the lower accuracy, and we believe that a more detailed analysis of the G2P performance is needed in order to explore this.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.999316930770874}]}, {"text": "Experiments on orthographically and morphophonemically similar languages may also be revealing.", "labels": [], "entities": []}, {"text": "An Ensemble Oracle of all three models is given in in order to check if the systems vary in what they learn to predict.", "labels": [], "entities": []}, {"text": "The results show that this ensemble outperforms each individual system for any given language.", "labels": [], "entities": []}, {"text": "However, when compared to an Ensemble Oracle of three text models, the results are rather similar.", "labels": [], "entities": []}, {"text": "The increase inaccuracy may simply be due to varying parameters from different random initializations, yielding an effect that is similar to the boosted scores that can be observed in many of the shared task results.", "labels": [], "entities": []}, {"text": "More interesting is the fact that (2) both the IPA and feature representation seem to yield extremely similar accuracies with a paired permutation test p-value of 0.43 overall languages.", "labels": [], "entities": []}, {"text": "Even when the training data is rather sparse as in the medium setting, the accuracies remain extremely similar.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 75, "end_pos": 85, "type": "METRIC", "confidence": 0.9851572513580322}]}, {"text": "This suggests that the distributional properties of IPA segments capture the information expressed by distinctive features.", "labels": [], "entities": []}, {"text": "Any benefit that representing a segment in terms of its features might have is already available in the IPA embeddings.", "labels": [], "entities": []}, {"text": "To further compare these representations, we experiment with models that combine the IPA and feature representations.", "labels": [], "entities": []}, {"text": "We attempt to simply add a 'feature' to the distinctive feature vectors for each IPA segment.", "labels": [], "entities": []}, {"text": "That is, the feature vector for /@/ would have a 1 for all of its distinctive features, and an additional 1 for that specific segment.", "labels": [], "entities": []}, {"text": "We also experiment with concatenation of the embedding found from the feature vector combination and the IPA embedding.", "labels": [], "entities": []}, {"text": "The input to the model is a vector of double the embedding size to account for concatenation.", "labels": [], "entities": []}, {"text": "The results, given in, show that neither experiment seems to have much effect, and the accuracies reflect the initial results.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 87, "end_pos": 97, "type": "METRIC", "confidence": 0.9658403992652893}]}], "tableCaptions": [{"text": " Table 1: Overall accuracy for each model (orthographic, IPA-based, and distinctive feature-based), and comparison with the", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.99946528673172}]}, {"text": " Table 2: Ensemble Oracles for each language. If the cor-", "labels": [], "entities": []}, {"text": " Table 3: Results for the combination of feature and IPA", "labels": [], "entities": [{"text": "IPA", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.9552608728408813}]}]}