{"title": [{"text": "Changing the Level of Directness in Dialogue using Dialogue Vector Models and Recurrent Neural Networks", "labels": [], "entities": []}], "abstractContent": [{"text": "In cooperative dialogues, identifying the intent of ones conversation partner and acting accordingly is of great importance.", "labels": [], "entities": []}, {"text": "While this endeavour is facilitated by phrasing intentions as directly as possible , we can observe in human-human communication that a number of factors such as cultural norms and politeness may result in expressing one's intent indirectly.", "labels": [], "entities": []}, {"text": "Therefore, in human-computer communication we have to anticipate the possibility of users being indirect and be prepared to interpret their actual meaning.", "labels": [], "entities": []}, {"text": "Furthermore , a dialogue system should be able to conform to human expectations by adjusting the degree of directness it uses to improve the user experience.", "labels": [], "entities": []}, {"text": "To reach those goals, we propose an approach to differentiate between direct and indirect utterances and find utterances of the opposite characteristic that express the same intent.", "labels": [], "entities": []}, {"text": "In this endeavour, we employ dialogue vector models and recurrent neural networks.", "labels": [], "entities": []}], "introductionContent": [{"text": "An important part of any conversation is understanding the meaning your conversation partner is trying to convey.", "labels": [], "entities": []}, {"text": "If we do not obscure our intent and phrase it as directly as possible, our conversation partner will have an easier time to recognise our goal and cooperate in achieving it.", "labels": [], "entities": []}, {"text": "Thereby, we can enable a successful conversation.", "labels": [], "entities": []}, {"text": "Nevertheless, there are countless instances in which humans choose to express their meaning indirectly, as evidenced by the work of and, among others.", "labels": [], "entities": []}, {"text": "Answering the question 'How is the weather?' with 'Let's rather stay inside.'", "labels": [], "entities": []}, {"text": "gives no concrete information about the weather conditions, but is commonly understood.", "labels": [], "entities": []}, {"text": "There are several reasons why humans could choose to express their intent indirectly, such as cultural preferences, politeness, embarrassment, or simply using common figures of speech such as 'Can you tell me the time?'.", "labels": [], "entities": []}, {"text": "Considering the frequency of indirectness in human-human communication, we need to anticipate the use of indirectness in human-computer communication and enable dialogue systems to handle it.", "labels": [], "entities": []}, {"text": "In this work, we introduce an approach to exchanging utterances with others that express the same intent in the dialogue but exhibit a differing level of directness.", "labels": [], "entities": []}, {"text": "More concretely, our approach would replace the second utterance of the exchange 'What pizza do you want?'", "labels": [], "entities": []}, {"text": "-'I want a vegetarian pizza.' with an utterance like 'I don't like meat'.", "labels": [], "entities": []}, {"text": "To this end, we employ models that can estimate the level of directness of an utterance on the one hand and the degree to which utterances express the same intent on the other.", "labels": [], "entities": []}, {"text": "Our approach can be applied to solve two challenges of indirectness for dialogue systems: On the side of the language analysis, the true intent of the user needs to be recognised so that the dialogue system can react in an appropriate, cooperative manner.", "labels": [], "entities": []}, {"text": "If the language analysis is able to not only recognise the user's intended meaning, but also when the user is being indirect, this information can further be utilised by the dialogue manager, e.g. by scheduling a confirmation if the user is believed to have used indirectness.", "labels": [], "entities": []}, {"text": "Our approach estimates the level of directness of an utterance as a first step.", "labels": [], "entities": []}, {"text": "If the utterance is classified as indirect, this information can be provided to the dialogue manager.", "labels": [], "entities": []}, {"text": "Furthermore, our approach exchanges the indirect utterance fora direct counterpart that more accurately reflects the users intent, thereby facilitating the task of the lan-guage analysis.", "labels": [], "entities": []}, {"text": "The second area of dialogue system that can benefit from taking into account indirectness is the language generation.", "labels": [], "entities": [{"text": "language generation", "start_pos": 97, "end_pos": 116, "type": "TASK", "confidence": 0.718891829252243}]}, {"text": "Studies could show that under specific circumstances indirectness is preferred not only from human conversation partners, but also in human-computer interaction (e.g. ().", "labels": [], "entities": []}, {"text": "Therefore, dialogue systems that can adjust the level of directness in their output to the user and their circumstances should be able to provide an improved user experience.", "labels": [], "entities": []}, {"text": "If a certain level of directness is determined to be desirable with regards to the current circumstances, our algorithm can determine whether the utterance chosen as system output possesses the targeted level of directness and exchange it fora more suitable alternative if it does not.", "labels": [], "entities": []}, {"text": "In the following, we will discuss related work, before presenting our general approach and its concrete implementation.", "labels": [], "entities": []}, {"text": "This approach is evaluated in Section 4.", "labels": [], "entities": []}, {"text": "Here, we introduce the dialogue corpus we created to obtain a reliable ground truth and discuss the results of our evaluation.", "labels": [], "entities": []}, {"text": "Finally, we draw a conclusion in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section presents the evaluation of the proposed approach.", "labels": [], "entities": []}, {"text": "We first introduce a dialogue corpus that is suitable to train the required models and provides a reliable ground truth to compare the results of our approach to.", "labels": [], "entities": []}, {"text": "Afterwards, the setup of the evaluation is described and its results presented and discussed.", "labels": [], "entities": []}, {"text": "It is a time-delay network with a one step delay from the input layer to the hidden layer, which contains ten nodes.", "labels": [], "entities": []}, {"text": "The output layer gives the probability that the input belongs to a class for each of the three classes.", "labels": [], "entities": []}, {"text": "For the evaluation of our approach we determine its accuracy in finding an utterance that shares the dialogue action with the original utterance and is of the opposite level of directness.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9994244575500488}]}, {"text": "The ground truth for both criteria is given by the previously presented dialogue corpus.", "labels": [], "entities": []}, {"text": "In addition, we also evaluate the performance of the trained classifier and investigate how it influences the overall performance.", "labels": [], "entities": []}, {"text": "As the ability of DVM to group utterances that share a dialogue action has already been shown in), it will not be part of this evaluation.", "labels": [], "entities": []}, {"text": "To investigate the effects of the amount of available data, we use several DVMs that are trained on only a fraction of the complete corpus.", "labels": [], "entities": []}, {"text": "Corpus sizes of 0.1, 0.2, 0.4, 0.6, 0.8 and of course the full corpus are considered.", "labels": [], "entities": []}, {"text": "The dialogues that are part of the reduced corpora are chosen at random.", "labels": [], "entities": []}, {"text": "Another aspect we study is the impact of the amount of available annotated training data for the classifier on its performance.", "labels": [], "entities": []}, {"text": "As usual, we use ten-fold cross-validation in our evaluation.", "labels": [], "entities": []}, {"text": "However, instead of only using 90% of the utterances for training and 10% for testing, we also evaluate our approach using 10% of the utterances for training and 90% for testing.", "labels": [], "entities": []}, {"text": "With this, we want to investigate how our approach performs given only a limited amount of annotated data.", "labels": [], "entities": []}, {"text": "Finally, we compare the performance of the classifier when using only dialogue vectors as input and when using both dialogue vectors and the sum of word vectors.", "labels": [], "entities": []}, {"text": "As DVMs map functionally similar utterances in close vicinity to each other, direct and indirect utterances should be hard to distinguish with just the information from those models.", "labels": [], "entities": []}, {"text": "On the other hand, the sum of word vectors might be missing important context information for the identification of the directness level.", "labels": [], "entities": []}, {"text": "We believe that the combination of both the sum of word vectors and dialogue vectors will improve the performance of the classifier.", "labels": [], "entities": []}, {"text": "The DVMs we utilise in our evaluation as similarity measure and as input to the RNN are trained on the presented dialogue corpus.", "labels": [], "entities": []}, {"text": "The network additionally receives the sum of the word vectors of an utterance, based on the Google News Corpus model (), as input.", "labels": [], "entities": [{"text": "Google News Corpus model", "start_pos": 92, "end_pos": 116, "type": "DATASET", "confidence": 0.8526790142059326}]}, {"text": "The evaluation of our approach yields promising results and shows its high potential.", "labels": [], "entities": []}, {"text": "However, we need to take into account that those results were achieved using an artificially generated corpus.", "labels": [], "entities": []}, {"text": "Furthermore, we tested the performance of our approach in a theoretical setting, not its impact in an actual application.", "labels": [], "entities": []}, {"text": "This section discusses the limitations of our evaluation.", "labels": [], "entities": []}, {"text": "Natural dialogue possess a greater variability than automatically generated dialogue, and therefore finding reliable patterns in them is a more difficult task.", "labels": [], "entities": []}, {"text": "It is likely that the quality of both the classifier and the DVMs decreases if they are trained on a comparable amount of natural dialogue data compared to artificially generated data.", "labels": [], "entities": []}, {"text": "We could show in the evaluation that the quality of the classifier and DVM has a major impact on the performance of our approach.", "labels": [], "entities": []}, {"text": "This implies that more data is needed for natural dialogues than for automatically generated dialogues to achieve comparable results.", "labels": [], "entities": []}, {"text": "One of the main reasons to use an automatically generated dialogue corpus was to ensure the presence of pairs of direct and indirect utterances.", "labels": [], "entities": []}, {"text": "This is important not only for the training of the classifier and DVM, but also to ensure that a suitable substitute is known.", "labels": [], "entities": []}, {"text": "As our approach searches fora replacement in a set of established utterances, it can only be successful if the set does contain a suitable utterance.", "labels": [], "entities": []}, {"text": "While the likelihood for the presence of a suitable substitute increases with the size of the dialogue corpus, it cannot be guaranteed that a replacement is present in natural dialogues.", "labels": [], "entities": []}, {"text": "When transferring our approach to actual applications, this might present a challenge.", "labels": [], "entities": []}, {"text": "To address this challenge, the generation of suitable utterances rather than their identification should be investigated.", "labels": [], "entities": [{"text": "generation of suitable utterances", "start_pos": 31, "end_pos": 64, "type": "TASK", "confidence": 0.7829755991697311}]}, {"text": "While our evaluation shows what accuracy our approach can achieve given different circumstances, we did not yet investigate what accuracy it needs to achieve in actual applications to positively impact the user experience.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9959420561790466}, {"text": "accuracy", "start_pos": 129, "end_pos": 137, "type": "METRIC", "confidence": 0.992598295211792}]}, {"text": "Without this information, it is difficult to estimate which level of accuracy should be targeted and, as a consequence, the amount of training data needed.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9991508722305298}]}], "tableCaptions": []}