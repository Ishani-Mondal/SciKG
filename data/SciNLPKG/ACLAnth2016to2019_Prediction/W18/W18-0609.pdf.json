{"title": [{"text": "Deep Learning for Depression Detection of Twitter Users", "labels": [], "entities": [{"text": "Depression Detection of Twitter", "start_pos": 18, "end_pos": 49, "type": "TASK", "confidence": 0.8317241668701172}]}], "abstractContent": [], "introductionContent": [{"text": "Mental disorder is defined as a \"syndrome characterized by a clinically significant disturbance in an individual's cognition, emotion regulation, or behavior that reflects a dysfunction in the psychological, biological, or developmental processes underlying mental functioning\" (American Psychiatric.", "labels": [], "entities": [{"text": "American Psychiatric.", "start_pos": 279, "end_pos": 300, "type": "DATASET", "confidence": 0.9539036154747009}]}, {"text": "According to Canadian Mental Health Association (2016), 20% of Canadians belonging to different demographics have experienced mental illnesses during their lifetime, and around 8% of adults have gone through a major depression.", "labels": [], "entities": [{"text": "Canadian Mental Health Association (2016)", "start_pos": 13, "end_pos": 54, "type": "DATASET", "confidence": 0.846102067402431}]}, {"text": "According to World Health Organization (2014) statistics, nearly 20% of children and adolescents have experienced mental illnesses and half of these mental illnesses start before the age of 14.", "labels": [], "entities": []}, {"text": "In addition, around 23% of deaths in the world were caused due to mental and substance use disorders.", "labels": [], "entities": []}, {"text": "The broad implication of mental illness can be identified from the level of suicide in Canada where nearly 4,000 Canadians have died from suicide and 90% of them were identified as having some form of a mental disorder (Mental Health Commission of.", "labels": [], "entities": [{"text": "Mental Health Commission of.", "start_pos": 220, "end_pos": 248, "type": "DATASET", "confidence": 0.7716854989528656}]}, {"text": "Apart from the severity of mental disorders and their influence on one's mental and physical health, the social stigma (e.g., \"mental disorders cannot be cured\") or discrimination has made the individuals to be neglected by the community as well as to avoid taking the necessary treatments.", "labels": [], "entities": []}, {"text": "The inherent complexity of detecting mental disorders using social media platforms can be seen in the literature, where many researchers have tried to identify key indicators utilizing different natural language processing approaches.", "labels": [], "entities": []}, {"text": "To extract the most prominent features to develop an accurate predictive model, one must acquire a sufficient amount of knowledge related to the particular area of research.", "labels": [], "entities": []}, {"text": "Even if such features were extracted, this does not assure that those features are the key contributors to obtaining improved accuracies.", "labels": [], "entities": []}, {"text": "Due to these reasons, we investigate the possibility of using deep neural architectures because the features are learned within the architecture itself.", "labels": [], "entities": []}, {"text": "Here, we explore a few selected deep neural network architectures to detect mental disorders, specifically depression.", "labels": [], "entities": []}, {"text": "We used the data released for the Computational Linguistics and Clinical Psychology (CLPsych) 2015 shared task).", "labels": [], "entities": [{"text": "Computational Linguistics and Clinical Psychology (CLPsych) 2015 shared task", "start_pos": 34, "end_pos": 110, "type": "TASK", "confidence": 0.6305136761882089}]}, {"text": "Even though the task is comprised of three subtasks: detecting Post-Traumatic Stress Disorder (PTSD) vs. control, depression vs. control and PTSD vs. depression, our primary objective was to detect depression using the most effective deep neural architecture from two of the most popular deep learning approaches in the field of natural language processing: Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), given the limited amount (i.e., in comparison to most of the deep neural network architectures) of unstructured data.", "labels": [], "entities": [{"text": "detecting Post-Traumatic Stress Disorder (PTSD)", "start_pos": 53, "end_pos": 100, "type": "TASK", "confidence": 0.8785389236041478}]}, {"text": "Our approach and key contributions can be summarized as follows.", "labels": [], "entities": []}, {"text": "\u2022 Word embedding optimization: we propose a novel approach to optimize word-embedding for classification with a focus on identifying users suffering from depression based on their social posts such as tweets.", "labels": [], "entities": [{"text": "Word embedding optimization", "start_pos": 2, "end_pos": 29, "type": "TASK", "confidence": 0.7783534526824951}]}, {"text": "We use our approach to improve the performance of two tasks: depression detection on the CLPsych2015 dataset and test generalization capability on the Bell Lets Talk dataset (Jamil et al., 2017).", "labels": [], "entities": [{"text": "depression detection", "start_pos": 61, "end_pos": 81, "type": "TASK", "confidence": 0.6777263730764389}, {"text": "CLPsych2015 dataset", "start_pos": 89, "end_pos": 108, "type": "DATASET", "confidence": 0.9856628775596619}, {"text": "Bell Lets Talk dataset", "start_pos": 151, "end_pos": 173, "type": "DATASET", "confidence": 0.8900579065084457}]}, {"text": "\u2022 Comparative evaluation: we investigate and report the performance of several deep learning architectures commonly used in NLP tasks, in particular, to detect mental disorders.", "labels": [], "entities": []}, {"text": "We also expand our investigation to include different word embeddings and hyperparameter tuning.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our approach using two experiments, 1) depression detection on the CLPsych2015 dataset (Section 3) and 2) test generalization ability on the Bell Let's Talk dataset (Section 3).", "labels": [], "entities": [{"text": "depression detection", "start_pos": 51, "end_pos": 71, "type": "TASK", "confidence": 0.6664932817220688}, {"text": "CLPsych2015 dataset", "start_pos": 79, "end_pos": 98, "type": "DATASET", "confidence": 0.9895038902759552}, {"text": "Bell Let's Talk dataset", "start_pos": 153, "end_pos": 176, "type": "DATASET", "confidence": 0.8938041925430298}]}, {"text": "We use different word embeddings for our experiments with the deep neural network models.", "labels": [], "entities": []}, {"text": "In the first experiment, we perform a comparison on the selected models for depression detection.", "labels": [], "entities": [{"text": "depression detection", "start_pos": 76, "end_pos": 96, "type": "TASK", "confidence": 0.8105912208557129}]}, {"text": "In the second experiment, since the dataset is imbalanced, we perform 5-fold cross-validation with stratified sampling to report results.", "labels": [], "entities": []}, {"text": "Data points are shuffled for each split while maintaining the class distribution.", "labels": [], "entities": []}, {"text": "After that, we test the generalization ability of the models selected, for which we use 80% and 20% of the data for train-   ing and development, respectively.", "labels": [], "entities": [{"text": "train-   ing", "start_pos": 116, "end_pos": 128, "type": "TASK", "confidence": 0.634709636370341}]}, {"text": "The trained models are used afterward for evaluation on unseen data, which is Bell Let's Talk; i.e., 154 users (Section 3).", "labels": [], "entities": [{"text": "Bell Let's Talk", "start_pos": 78, "end_pos": 93, "type": "DATASET", "confidence": 0.9217296838760376}]}, {"text": "The metrics used for our evaluation are accuracy, ROC area-under-the-curve (AUC), precision, recall, and F-measure.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9997134804725647}, {"text": "ROC area-under-the-curve (AUC)", "start_pos": 50, "end_pos": 80, "type": "METRIC", "confidence": 0.9543211102485657}, {"text": "precision", "start_pos": 82, "end_pos": 91, "type": "METRIC", "confidence": 0.999476969242096}, {"text": "recall", "start_pos": 93, "end_pos": 99, "type": "METRIC", "confidence": 0.9996304512023926}, {"text": "F-measure", "start_pos": 105, "end_pos": 114, "type": "METRIC", "confidence": 0.9977310299873352}]}, {"text": "We use precision and recall since data is imbalanced, which may return imprecise accuracy results.", "labels": [], "entities": [{"text": "precision", "start_pos": 7, "end_pos": 16, "type": "METRIC", "confidence": 0.9995643496513367}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9994175434112549}, {"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9934240579605103}]}, {"text": "We compared model performances based on the AUC score, which is calculated on the validation set and averaged over the five splits with standard deviation.", "labels": [], "entities": [{"text": "AUC", "start_pos": 44, "end_pos": 47, "type": "METRIC", "confidence": 0.9426206946372986}]}, {"text": "A low precision will be identified when the classifier reports more false positives (FP); i.e., users are inaccurately predicted to have depression.", "labels": [], "entities": [{"text": "precision", "start_pos": 6, "end_pos": 15, "type": "METRIC", "confidence": 0.9943307638168335}, {"text": "false positives (FP)", "start_pos": 68, "end_pos": 88, "type": "METRIC", "confidence": 0.7168519377708436}]}, {"text": "A low recall will be identified when the classifier reports more false negatives (FN); i.e., users who suffer from depression are not recognized.", "labels": [], "entities": [{"text": "recall", "start_pos": 6, "end_pos": 12, "type": "METRIC", "confidence": 0.9991313815116882}, {"text": "false negatives (FN)", "start_pos": 65, "end_pos": 85, "type": "METRIC", "confidence": 0.7095194220542907}]}, {"text": "We consider precision, recall, and F-measure for the positive classes obtained from the test datasets.", "labels": [], "entities": [{"text": "precision", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.999640703201294}, {"text": "recall", "start_pos": 23, "end_pos": 29, "type": "METRIC", "confidence": 0.9996129870414734}, {"text": "F-measure", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.9993677735328674}]}, {"text": "We aim to be close to a perfect balance (1.0) for both precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.9996566772460938}, {"text": "recall", "start_pos": 69, "end_pos": 75, "type": "METRIC", "confidence": 0.9979945421218872}]}, {"text": "The majority of the researchers have relied on support vector machine (SVM) classifiers to distinguish users with mental disorders from control groups and different mental disorder categories except when trying to identify the level of depression with the use of regression models ().", "labels": [], "entities": []}, {"text": "We used the SVM linear classifier with TF-IDF to initiate a baseline for the binary classification task.", "labels": [], "entities": [{"text": "binary classification task", "start_pos": 77, "end_pos": 103, "type": "TASK", "confidence": 0.7400178710619608}]}, {"text": "For evaluation, we used fivefold cross-validation, and the resulting best model was used on the Bell Let's Talk dataset to predict users with depression.", "labels": [], "entities": [{"text": "Bell Let's Talk dataset", "start_pos": 96, "end_pos": 119, "type": "DATASET", "confidence": 0.949007260799408}]}, {"text": "The results are reported both on the validation and test data.", "labels": [], "entities": []}, {"text": "shows good standings results for depression detection, which indicates that regularization and hyperparameter tuning helped resolve the overfitting issues.", "labels": [], "entities": [{"text": "depression detection", "start_pos": 33, "end_pos": 53, "type": "TASK", "confidence": 0.7770425975322723}]}, {"text": "CNN-based with max-pooling models reported better performance than RNN-based models.", "labels": [], "entities": [{"text": "CNN-based", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.8646465539932251}]}, {"text": "The CNNWithMax models using our optimized embedding reported higher accuracy (87.957%), F1 (86.967%), AUC (0.951), precision (87.435%), and recall (87.029%), as compared to other models.", "labels": [], "entities": [{"text": "CNNWithMax", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.9413983821868896}, {"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.999476969242096}, {"text": "F1", "start_pos": 88, "end_pos": 90, "type": "METRIC", "confidence": 0.9997689127922058}, {"text": "AUC (0.951)", "start_pos": 102, "end_pos": 113, "type": "METRIC", "confidence": 0.9458257555961609}, {"text": "precision", "start_pos": 115, "end_pos": 124, "type": "METRIC", "confidence": 0.9993113279342651}, {"text": "recall", "start_pos": 140, "end_pos": 146, "type": "METRIC", "confidence": 0.9998071789741516}]}, {"text": "reports that CNNbased models' results are close to each other, as opposed to RNN-based models, which at best reported 83.236% with trainable random embedding (trainable).", "labels": [], "entities": []}, {"text": "Interestingly, CNN models performed better than RNN models for depression detection.", "labels": [], "entities": [{"text": "depression detection", "start_pos": 63, "end_pos": 83, "type": "TASK", "confidence": 0.7312628328800201}]}, {"text": "reports the generalization ability of our approach on the unseen dataset (Section 3).", "labels": [], "entities": []}, {"text": "The models trained using our optimized embedding managed to maintain their performance with generalization ability.", "labels": [], "entities": []}, {"text": "Our embedding performs better because it is optimized using the CLPsych2015 dataset, which includes depression and PTSD labeled data.", "labels": [], "entities": [{"text": "CLPsych2015 dataset", "start_pos": 64, "end_pos": 83, "type": "DATASET", "confidence": 0.9788711369037628}]}, {"text": "shows that the results of the CNN models are competitive, as opposed to RNN models.", "labels": [], "entities": []}, {"text": "The best performing RNN model reported 91.425%.", "labels": [], "entities": []}, {"text": "CBOW embedding performed the least as compared to others, including the random embedding.", "labels": [], "entities": [{"text": "CBOW", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.869420051574707}]}, {"text": "In particular, pre-trained CBOW and skip-gram models do not perform as expected, mainly due to the size of the CLPsych2015 corpus, which is nearly around 22 million words.", "labels": [], "entities": [{"text": "CLPsych2015 corpus", "start_pos": 111, "end_pos": 129, "type": "DATASET", "confidence": 0.9402487576007843}]}, {"text": "Furthermore, optimized and trainable random embeddings have an advantage for being able to update their weights during training.", "labels": [], "entities": []}, {"text": "We conclude that user-level classification for depression detection performs well even with datasets that are small and/or imbalanced. and reported high results for the CLPsych2015 shared task using topic models.", "labels": [], "entities": [{"text": "user-level classification", "start_pos": 17, "end_pos": 42, "type": "TASK", "confidence": 0.6315796077251434}, {"text": "depression detection", "start_pos": 47, "end_pos": 67, "type": "TASK", "confidence": 0.7213202565908432}]}, {"text": "However, their results are not comparable, as they are reported on the official testing set that was not available to us.", "labels": [], "entities": []}, {"text": "Alternatively, we performed a five-fold cross-validation on the shared task training data).", "labels": [], "entities": []}, {"text": "We report better performance when testing on the Bell Let's Talk dataset as compared to.", "labels": [], "entities": [{"text": "Bell Let's Talk dataset", "start_pos": 49, "end_pos": 72, "type": "DATASET", "confidence": 0.9589874505996704}]}], "tableCaptions": [{"text": " Table 1: CLPSych 2015 shared task dataset statis- tics", "labels": [], "entities": [{"text": "CLPSych 2015 shared task dataset statis- tics", "start_pos": 10, "end_pos": 55, "type": "DATASET", "confidence": 0.8704615160822868}]}, {"text": " Table 2: Performance of our models on the CLPsych 2015 dataset with 5-fold cross-validation. The rows  are highlighted according to the highest AUC score.", "labels": [], "entities": [{"text": "CLPsych 2015 dataset", "start_pos": 43, "end_pos": 63, "type": "DATASET", "confidence": 0.9622178475062052}, {"text": "AUC", "start_pos": 145, "end_pos": 148, "type": "METRIC", "confidence": 0.9425333142280579}]}, {"text": " Table 3: Performance of our models on the Bell Let's Talk dataset. The rows are highlighted according  to the highest AUC score.", "labels": [], "entities": [{"text": "Bell Let's Talk dataset", "start_pos": 43, "end_pos": 66, "type": "DATASET", "confidence": 0.9403571248054504}, {"text": "AUC score", "start_pos": 119, "end_pos": 128, "type": "METRIC", "confidence": 0.9306857287883759}]}]}