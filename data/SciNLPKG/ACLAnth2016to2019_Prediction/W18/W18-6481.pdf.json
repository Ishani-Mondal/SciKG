{"title": [{"text": "Accurate semantic textual similarity for cleaning noisy parallel corpora using semantic machine translation evaluation metric: The NRC supervised submissions to the Parallel Corpus Filtering task", "labels": [], "entities": [{"text": "semantic machine translation evaluation", "start_pos": 79, "end_pos": 118, "type": "TASK", "confidence": 0.7215287014842033}, {"text": "Parallel Corpus Filtering", "start_pos": 165, "end_pos": 190, "type": "TASK", "confidence": 0.7035563588142395}]}], "abstractContent": [{"text": "We present our semantic textual similarity approach in filtering a noisy web crawled parallel corpus using YiSi-a novel semantic machine translation evaluation metric.", "labels": [], "entities": [{"text": "semantic machine translation evaluation", "start_pos": 120, "end_pos": 159, "type": "TASK", "confidence": 0.722796767950058}]}, {"text": "The systems mainly based on this supervised approach perform well in the WMT18 Parallel Corpus Filtering shared task (4th place in 100-million-word evaluation, 8th place in 10-million-word evaluation, and 6th place overall, out of 48 submissions).", "labels": [], "entities": [{"text": "WMT18 Parallel Corpus Filtering shared task", "start_pos": 73, "end_pos": 116, "type": "TASK", "confidence": 0.6116323967774709}]}, {"text": "In fact, our best performing system-NRC-yisi-bicov is one of the only four submissions ranked top 10 in both evaluations.", "labels": [], "entities": []}, {"text": "Our submitted systems also include some initial filtering steps for scaling down the size of the test corpus and a final redundancy removal step for better semantic and token coverage of the filtered corpus.", "labels": [], "entities": []}, {"text": "In this paper, we also describe our unsuccessful attempt in automatically synthesizing a noisy parallel development corpus for tuning the weights to combine different parallelism and fluency features.", "labels": [], "entities": []}], "introductionContent": [{"text": "The WMT18 shared task on parallel corpus filtering () challenged teams to find clean sentence pairs from ParaCrawl, a humongous high-recall, low-precision web crawled parallel corpus (), for training machine translation (MT) systems.", "labels": [], "entities": [{"text": "WMT18", "start_pos": 4, "end_pos": 9, "type": "DATASET", "confidence": 0.769182562828064}, {"text": "parallel corpus filtering", "start_pos": 25, "end_pos": 50, "type": "TASK", "confidence": 0.5077084998289744}, {"text": "training machine translation (MT)", "start_pos": 191, "end_pos": 224, "type": "TASK", "confidence": 0.7861427267392477}]}, {"text": "Data cleanliness of parallel corpora for MT systems is affected by a wide range of factors, e.g., the parallelism of the sentence pairs, the fluency of the sentences in the output language, etc.", "labels": [], "entities": [{"text": "MT", "start_pos": 41, "end_pos": 43, "type": "TASK", "confidence": 0.9841947555541992}]}, {"text": "Previous work ( showed that different types of errors in the parallel training data degrade MT quality at different levels.", "labels": [], "entities": [{"text": "MT", "start_pos": 92, "end_pos": 94, "type": "TASK", "confidence": 0.9915809035301208}]}, {"text": "Intuitively, the crosslingual semantic textual similarity of the sentence pairs in the corpora is one of the most important factors affecting the parallelism of the target sentence pairs.", "labels": [], "entities": []}, {"text": "scored crosslingual semantic textual similarity crosslingually, using a semantic MT quality estimation metric with fewer resource requirements, or monolingually, using a pipeline of MT system and semantic MT evaluation metric with better performance.", "labels": [], "entities": []}, {"text": "The core of the National Research Council of Canada (NRC) supervised submissions (NRC-yisi-bicov and NRC-yisi) of the parallel corpus filtering shared task were developed in the same philosophy using anew semantic MT evaluation metric, YiSi.", "labels": [], "entities": []}, {"text": "The participants of the parallel corpus filtering shared task were given a large set of \"clean\" German-English monolingual and bilingual training corpora for the WMT18 news translation shared task (except a filtered version of ParaCrawl) and tasked to score the cleanliness of each sentence pair in the \"dirty\" ParaCrawl corpus.", "labels": [], "entities": [{"text": "WMT18 news translation shared task", "start_pos": 162, "end_pos": 196, "type": "TASK", "confidence": 0.6494545102119446}, {"text": "ParaCrawl corpus", "start_pos": 311, "end_pos": 327, "type": "DATASET", "confidence": 0.9193030595779419}]}, {"text": "Our supervised submissions used the given parallel data to train an MT system to translate the German side of the dirty corpus into English.", "labels": [], "entities": [{"text": "MT", "start_pos": 68, "end_pos": 70, "type": "TASK", "confidence": 0.9362431764602661}, {"text": "German side of the dirty corpus", "start_pos": 95, "end_pos": 126, "type": "DATASET", "confidence": 0.566209132472674}]}, {"text": "The provided version of the dirty ParaCrawl corpus contains raw data crawled from the web with minimal de-duplication processing only, and includes non-parallel, or even non-linguistic data.", "labels": [], "entities": [{"text": "ParaCrawl corpus", "start_pos": 34, "end_pos": 50, "type": "DATASET", "confidence": 0.8121172785758972}]}, {"text": "It contains 104 million German-English sentence pairs, with 1 billion English tokens and 964 million German tokens before punctuation tokenization.", "labels": [], "entities": []}, {"text": "A 10-million-word (10M-word) and a 100-millionword (100M-word) corpus sub-selected by the participating cleanliness scoring system were used to train statistical machine translation (SMT) and neural machine translation (NMT) systems.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 150, "end_pos": 187, "type": "TASK", "confidence": 0.7794433832168579}, {"text": "neural machine translation (NMT)", "start_pos": 192, "end_pos": 224, "type": "TASK", "confidence": 0.8252165218194326}]}, {"text": "The success of the participating scoring systems was determined by the quality of the MT output from the four MT systems as measured by BLEU () on some in-domain and out-ofdomain evaluation sets.", "labels": [], "entities": [{"text": "MT", "start_pos": 86, "end_pos": 88, "type": "TASK", "confidence": 0.9828743934631348}, {"text": "MT", "start_pos": 110, "end_pos": 112, "type": "TASK", "confidence": 0.9516491293907166}, {"text": "BLEU", "start_pos": 136, "end_pos": 140, "type": "METRIC", "confidence": 0.9988946318626404}]}, {"text": "In this paper, we describe the efforts in developing our supervised submissions: the initial fil-tering steps for scaling down the size of the given ParaCrawl dirty corpus, the wide range of features experimented for measuring parallelism, fluency and grammaticality, the failed attempt to combine useful features and the final redundancy removal for improving token coverage of the filtered corpus.", "labels": [], "entities": [{"text": "ParaCrawl dirty corpus", "start_pos": 149, "end_pos": 171, "type": "DATASET", "confidence": 0.7857939799626669}]}, {"text": "Despite the simple single-feature architecture used in the NRC best-performing supervised submission (NRC-yisi-bicov), it performed well in the MT quality evaluation compared to other participants.", "labels": [], "entities": [{"text": "NRC best-performing supervised submission (NRC-yisi-bicov)", "start_pos": 59, "end_pos": 117, "type": "DATASET", "confidence": 0.7735966188567025}, {"text": "MT", "start_pos": 144, "end_pos": 146, "type": "TASK", "confidence": 0.9824380278587341}]}, {"text": "It ranked 4th in the 100-million-word evaluation, 8th in the 10-million-word evaluation and 6th overall among 48 submissions.", "labels": [], "entities": []}, {"text": "It is one of the only four submissions ranked top 10 in both evaluations.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Precision on the 300-annotated sentence pairs.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9901121258735657}]}, {"text": " Table 2: BLEU scores of SMT and NMT systems trained on the 10M-and 100M-word corpora subselected by the  scoring systems. \"bicov\" indicates that the final bigram coverage step ( \u00a72.4) was performed. The development set  is newstest2017 and the test set is newstest2018.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9989185333251953}, {"text": "SMT", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.9538151621818542}, {"text": "newstest2018", "start_pos": 257, "end_pos": 269, "type": "DATASET", "confidence": 0.9452778100967407}]}]}