{"title": [], "abstractContent": [{"text": "Probabilistic approaches have proven themselves well in learning phonological structure.", "labels": [], "entities": [{"text": "learning phonological structure", "start_pos": 56, "end_pos": 87, "type": "TASK", "confidence": 0.803370734055837}]}, {"text": "In contrast, theoretical linguistics usually works with deterministic generalizations.", "labels": [], "entities": []}, {"text": "The goal of this paper is to explore possible interactions between information-theoretic methods and deterministic linguistic knowledge and to examine some ways in which both can be used in tandem to extract phonological and morphophonological patterns from a small annotated dataset.", "labels": [], "entities": []}, {"text": "Local and nonlocal processes in Mishar Tatar (Turkic/Kipchak) are examined as a case study.", "labels": [], "entities": [{"text": "Mishar Tatar (Turkic/Kipchak)", "start_pos": 32, "end_pos": 61, "type": "TASK", "confidence": 0.858317392213004}]}], "introductionContent": [{"text": "Morphophonology, or the interface between morphology and phonology, encompasses a wide range of phenomena.", "labels": [], "entities": []}, {"text": "While this paper primarily focuses on learning phonological rules from a dataset, it is difficult to draw generalizations based only on surface strings, since the rules maybe morphologically specific.", "labels": [], "entities": []}, {"text": "The challenge goes beyond learning which phonotactic sequences are allowed, also incorporating surface realizations of morphemes and rules governing their distribution.", "labels": [], "entities": []}, {"text": "Large unannotated corpora are used by a large portion of the existing work on learning phonological patterns e.g. approaches to learning vowel harmony).", "labels": [], "entities": [{"text": "learning vowel harmony", "start_pos": 128, "end_pos": 150, "type": "TASK", "confidence": 0.605631818373998}]}, {"text": "However, in the case of rare languages, a large corpus maybe unavailable.", "labels": [], "entities": []}, {"text": "On the other hand, small hand-annotated examples or texts area natural output of linguistic fieldwork and readily available even for underresourced and under-studied languages.", "labels": [], "entities": []}, {"text": "Interlinear glossed text is a format traditionally utilized in linguistic papers for presenting language data.", "labels": [], "entities": []}, {"text": "It annotates each morpheme with a label, or gloss tag.", "labels": [], "entities": []}, {"text": "When the amount of data is insufficient, the role of such linguistic knowledge in making generalizations becomes more prominent; see) for approaches to extraction of morphological rules that take this path.", "labels": [], "entities": []}, {"text": "When it comes to morphophonology, agglutinative languages are of special interest.", "labels": [], "entities": []}, {"text": "They tend to exhibit a variety of interacting processes which give rise to multiple surface realizations of most morphemes.", "labels": [], "entities": []}, {"text": "1 A small dataset is very likely to contain only a subset of possible allomorphs -an additional challenge for the learning algorithm.", "labels": [], "entities": []}, {"text": "As a case study, this paper focuses on Mishar dialect of Tatar language (Turkic/Kipchak).", "labels": [], "entities": []}, {"text": "The data sample used here is a hand-glossed collection of texts elicited from native speakers in the course of fieldwork (MSU linguistic expedition 1999-2012) (3090 word tokens; 1740 types).", "labels": [], "entities": [{"text": "MSU linguistic expedition 1999-2012)", "start_pos": 122, "end_pos": 158, "type": "DATASET", "confidence": 0.8982980966567993}]}], "datasetContent": [{"text": "Due to the limited data, the learner cannot be expected to have access to all possible contexts.", "labels": [], "entities": []}, {"text": "Moreover, as shown in above, the rankings of segments produced by calculating PMI tend to contain some degree of noise.", "labels": [], "entities": [{"text": "PMI", "start_pos": 78, "end_pos": 81, "type": "TASK", "confidence": 0.6732836961746216}]}, {"text": "It is at this point that phonological features come into play.", "labels": [], "entities": []}, {"text": "Adopting the standard textbook definition, a natural class is a set of segments that share a particular value for some feature or a set of features.", "labels": [], "entities": []}, {"text": "A rule is considered phonologically viable just in case the sets of triggers of all alternants correspond to disjoint natural classes.", "labels": [], "entities": []}, {"text": "Phonological viability introduces a straightforward way of producing generalizations.", "labels": [], "entities": [{"text": "Phonological viability", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8624721765518188}]}, {"text": "Combined with PMI rankings, it can be used to generate phonologically meaningful rules for known alternations.", "labels": [], "entities": []}, {"text": "First, each trigger set is extended with segments in its natural class that have not occurred in the context of the given alternation.", "labels": [], "entities": []}, {"text": "Second, any transparent segments that were accidentally added to the transparent list is removed from it if they are also found in one of the expanded trigger sets.", "labels": [], "entities": []}, {"text": "These modifications produce generalized rules.", "labels": [], "entities": []}, {"text": "We use two metrics to evaluate and compare these rules.", "labels": [], "entities": []}, {"text": "The primary objective is to explain as many instances of the given alternation as possible.", "labels": [], "entities": []}, {"text": "This intuition is easy to formalize: an example is explained if it contains a correct trigger which is either adjacent to the alternant or separated only by transparent segments.", "labels": [], "entities": []}, {"text": "Another option is to calculate the average PMI overall (segment, alternant) pairs, following the standard definition of mutual information shown in (24).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Bigrams for {e, 7} in the word ba\u01617N", "labels": [], "entities": []}, {"text": " Table 4. For each  alternation, MI and explained examples ratio (EE)  are shown for the best rule based on left and right  contexts. Colored rows indicate that the learner  has both partitioned the set of attested context seg- ments and determined whether the trigger is to the  left or to the right correctly with respect to the  ground truth.", "labels": [], "entities": [{"text": "MI", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.9976689219474792}, {"text": "explained examples ratio (EE)", "start_pos": 40, "end_pos": 69, "type": "METRIC", "confidence": 0.8455746670564016}]}, {"text": " Table 4: Rule evaluation for correct and incomplete  alternations", "labels": [], "entities": []}]}