{"title": [], "abstractContent": [{"text": "This paper describes the submissions to the efficiency track for GPUs at the Workshop for Neural Machine Translation and Generation by members of the University of Edinburgh, Adam Mickiewicz University , Tilde and University of Alicante.", "labels": [], "entities": [{"text": "Neural Machine Translation and Generation", "start_pos": 90, "end_pos": 131, "type": "TASK", "confidence": 0.766032612323761}, {"text": "Tilde", "start_pos": 204, "end_pos": 209, "type": "DATASET", "confidence": 0.9219884872436523}]}, {"text": "We focus on efficient implementation of the recurrent deep-learning model as implemented in Amun, the fast inference engine for neural machine translation.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 128, "end_pos": 154, "type": "TASK", "confidence": 0.7132435043652853}]}, {"text": "We improve the performance with an efficient mini-batching algorithm, and by fusing the softmax operation with the k-best extraction algorithm.", "labels": [], "entities": []}, {"text": "Submissions using Amun were first, second and third fastest in the GPU efficiency track.", "labels": [], "entities": [{"text": "Amun", "start_pos": 18, "end_pos": 22, "type": "DATASET", "confidence": 0.9071507453918457}]}], "introductionContent": [{"text": "As neural machine translation (NMT) models have become the new state-of-the-art, the challenge is to make their deployment efficient and economical.", "labels": [], "entities": [{"text": "neural machine translation (NMT)", "start_pos": 3, "end_pos": 35, "type": "TASK", "confidence": 0.8138220608234406}]}, {"text": "This is the challenge that this shared task ) is shining a spotlight on.", "labels": [], "entities": []}, {"text": "One approach is to use an off-the-shelf deeplearning toolkit to complete the shared task where the novelty comes from selecting the appropriate models and tuning parameters within the toolkit for optimal performance.", "labels": [], "entities": []}, {"text": "We take an opposing approach by eschewing model selection and parameter tuning in favour of efficient implementation.", "labels": [], "entities": [{"text": "model selection", "start_pos": 42, "end_pos": 57, "type": "TASK", "confidence": 0.7046134620904922}, {"text": "parameter tuning", "start_pos": 62, "end_pos": 78, "type": "TASK", "confidence": 0.728590190410614}]}, {"text": "We use and enhanced a custom inference engine, Amun), which we developed on the premise that fast deep-learning inference is an issue that deserves dedicated tools that are not compromised by competing objectives such as training or support for multiple models.", "labels": [], "entities": []}, {"text": "As well as delivering on the practical goal of fast inference, it can serve as a test-bed for novel ideas on neural network inference, and it is useful as a means to explore the upper bound of the possible speed fora particular model and hardware.", "labels": [], "entities": []}, {"text": "That is, Amun is an inference-only engine that supports a limited number of NMT models that put fast inference on modern GPU above all other considerations.", "labels": [], "entities": [{"text": "Amun", "start_pos": 9, "end_pos": 13, "type": "DATASET", "confidence": 0.794522762298584}]}, {"text": "We submitted two systems to this year's shared task for the efficient translation on GPU.", "labels": [], "entities": [{"text": "GPU", "start_pos": 85, "end_pos": 88, "type": "DATASET", "confidence": 0.9812522530555725}]}, {"text": "Our first submission was tailored to be as fast as possible while being above the baseline BLEU score.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 91, "end_pos": 101, "type": "METRIC", "confidence": 0.962732195854187}]}, {"text": "Our second submission trades some of the speed of the first submission to return better quality translations.", "labels": [], "entities": [{"text": "speed", "start_pos": 41, "end_pos": 46, "type": "METRIC", "confidence": 0.9927752017974854}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Validation set BLEU (newstest2014) for  GRU-based model", "labels": [], "entities": [{"text": "BLEU", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9881992340087891}, {"text": "newstest2014", "start_pos": 31, "end_pos": 43, "type": "DATASET", "confidence": 0.9351007342338562}]}, {"text": " Table 2: Validation set BLEU for mLSTM-based  model", "labels": [], "entities": [{"text": "BLEU", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.998285710811615}]}, {"text": " Table 3: Time taken (sec) breakdown", "labels": [], "entities": [{"text": "Time taken", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9768070876598358}]}, {"text": " Table 4: Time taken (sec) using Tensor Cores", "labels": [], "entities": [{"text": "Time taken", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.952924907207489}]}]}