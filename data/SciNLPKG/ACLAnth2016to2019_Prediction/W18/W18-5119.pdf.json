{"title": [{"text": "Decipherment for Adversarial Offensive Language Detection", "labels": [], "entities": [{"text": "Adversarial Offensive Language Detection", "start_pos": 17, "end_pos": 57, "type": "TASK", "confidence": 0.6685721725225449}]}], "abstractContent": [{"text": "Automated filters are commonly used by on-line services to stop users from sending age-inappropriate, bullying messages, or asking others to expose personal information.", "labels": [], "entities": []}, {"text": "Previous work has focused on rules or classifiers to detect and filter offensive messages, but these are vulnerable to cleverly disguised plaintext and unseen expressions especially in an adver-sarial setting where the users can repeatedly try to bypass the filter.", "labels": [], "entities": []}, {"text": "In this paper, we model the disguised messages as if they are produced by encrypting the original message using an invented cipher.", "labels": [], "entities": []}, {"text": "We apply automatic decipher-ment techniques to decode the disguised malicious text, which can be then filtered using rules or classifiers.", "labels": [], "entities": []}, {"text": "We provide experimental results on three different datasets and show that decipherment is an effective tool for this task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Under-aged social media users and users of chat rooms associated with software like video games are routinely exposed to offensive language including sexting, profanities, age-inappropriate languages, cyber-bullying, and requests for personal identifying information.", "labels": [], "entities": []}, {"text": "A common approach is to have a filter to block such messages.", "labels": [], "entities": []}, {"text": "Filters are either rule-based ( or machine learning classifiers ().", "labels": [], "entities": []}, {"text": "However, users wishing to bypass such filters can subtly transform messages in novel ways which can be hard to detect.", "labels": [], "entities": []}, {"text": "Since malicious users and spammers can change their attacks to avoid being filtered, an approach to offensive text detection that takes into account this adversarial relationship is what can deal with real-world abusive language detection better.", "labels": [], "entities": [{"text": "offensive text detection", "start_pos": 100, "end_pos": 124, "type": "TASK", "confidence": 0.735876719156901}]}, {"text": "Techniques like spelling correction have been used to correct misspelled words in user generated content (, but in an adversarial setting it is easy to defeat a spelling correction system trained on predictable errors.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 16, "end_pos": 35, "type": "TASK", "confidence": 0.8931645154953003}, {"text": "spelling correction", "start_pos": 161, "end_pos": 180, "type": "TASK", "confidence": 0.7002522200345993}]}, {"text": "Context based normalization methods have been proposed to convert erroneous user generated text from social media to standard text.", "labels": [], "entities": [{"text": "Context based normalization", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6591046849886576}]}, {"text": "We, however, treat this problem as follows: we model malicious users trying to bypass a filtering system as having invented anew cipher, and our goal is to decipher their encrypted messages back to plaintext.", "labels": [], "entities": []}, {"text": "We use a large space of possible ciphers that could be invented by those seeking to bypass a filter.", "labels": [], "entities": []}, {"text": "This paper addresses the problem of finding and filtering offensive messages as a special case of decipherment.", "labels": [], "entities": [{"text": "finding and filtering offensive messages", "start_pos": 36, "end_pos": 76, "type": "TASK", "confidence": 0.7174763381481171}]}, {"text": "In decipherment, a message in plaintext (original text) is converted into ciphertext (encrypted text).", "labels": [], "entities": []}, {"text": "Encryption disguises the content of the original plaintext to a ciphertext so that it cannot be filtered out or blocked.", "labels": [], "entities": []}, {"text": "Decryption or decipherment is the process of recovering the plaintext from the ciphertext.", "labels": [], "entities": []}, {"text": "We treat disguised inappropriate content as ciphertext, and the actual intended content as the plaintext.", "labels": [], "entities": []}, {"text": "Then we apply decipherment to recover more recognizable plaintext from the ciphertext and apply filters on the plaintext.", "labels": [], "entities": []}, {"text": "Conceivably these users may create very complex unbreakable ciphers which cannot be deciphered by our system, but in such cases the ciphers are likely to also be unreadable by other humans who are the intended audience.", "labels": [], "entities": []}, {"text": "We do not see many examples of this in our real-world chat messages.", "labels": [], "entities": []}, {"text": "We use Expectation Maximization and Hidden Markov Models) for our unsupervised decipherment method).", "labels": [], "entities": [{"text": "Expectation Maximization", "start_pos": 7, "end_pos": 31, "type": "TASK", "confidence": 0.6851199865341187}]}, {"text": "We use an efficient beam search decoding algorithm to decipher ciphertext into the most likely plaintext.", "labels": [], "entities": []}, {"text": "We also compare against supervised noisy channel models and a state-of-art spelling correction system (Aspell).", "labels": [], "entities": []}, {"text": "We discover that our method is immune to many previously unobserved types of changes made by users to disguise the original message.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our approach in terms of the classifier accuracy and the risk level from the rule-based filtering system for the real chat messages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9874804615974426}]}, {"text": "We are using a simple logistic regression classifer from the LibShortText toolkit () to train a classifier to classifies offensive and normal sentences.", "labels": [], "entities": []}, {"text": "After training the classifier, we classify the original test sentences without any encryption.", "labels": [], "entities": []}, {"text": "We do not use a very sophisticated classifier because the goal of classification here is not to correctly classify offensive messages, but rather, to measure how well the decipherment method can recover the original messages containing offensive text back from the encrypted messages.", "labels": [], "entities": []}, {"text": "We compare the classification accuracy between the original and deciphered messages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9077427983283997}]}, {"text": "If the classification accuracy gap between the original and deciphered messages is small, the decipherment approach can recover the original user-intended messages from encrypted messages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.8800339698791504}]}, {"text": "Tuning: We have a set of 179 sentences as the development set which is used for tuning the classifier and other hyper-parameters.", "labels": [], "entities": []}, {"text": "After tuning, we were able to achieve the highest classification accuracy of 86%.", "labels": [], "entities": [{"text": "classification", "start_pos": 50, "end_pos": 64, "type": "METRIC", "confidence": 0.5235403776168823}, {"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.8625707030296326}]}, {"text": "On the test sets A, B and C (see Sec. 3.1), in both our experiments on Caesar ciphers and Leet code, we first measure the number of offensive instances that were correctly classified by our logistic regression classifier.", "labels": [], "entities": []}, {"text": "Then, the same classifier is run on the encrypted versions of these messages.", "labels": [], "entities": []}, {"text": "The first two columns in the?", "labels": [], "entities": [{"text": "?", "start_pos": 28, "end_pos": 29, "type": "DATASET", "confidence": 0.6747274398803711}]}, {"text": "show the classification accuracy obtained in those settings.", "labels": [], "entities": [{"text": "classification", "start_pos": 9, "end_pos": 23, "type": "TASK", "confidence": 0.9257051944732666}, {"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9617685675621033}]}, {"text": "In our experiments, we apply Spelling Correction and our Decipherment techniques on the encrypted messages separately and finally use our classifier to determine the number of offensive instances that were correctly classified in decrypted text.", "labels": [], "entities": []}, {"text": "The objective here is to measure how well either of the techniques is able to recover the originally intended message from the encrypted version of the message, simulating areal online user's behaviour of disguising an offensive text to beat a rule-based filter.", "labels": [], "entities": []}, {"text": "In other words, we aim at decreasing the gap between the classification accuracies on a test set and its encrypted form.", "labels": [], "entities": []}, {"text": "In each of the offensive test sets A, B and C, the offensive keywords in the messages are substituted with real human corrupted words obtained from real-word chat messages.", "labels": [], "entities": []}, {"text": "These chats are transformed versions of these offensive words that are matched using a hand-written rule-based system.", "labels": [], "entities": []}, {"text": "We used enciphered offensive words collected from real chat messages and the corresponding plain text for this task.", "labels": [], "entities": []}, {"text": "Original Text: hes really bitchy in the morning Encryption: hes really bitchyou in the morning Decipherment: hes really bitchy in the morning Spelling Correction: hes really bitchy in the morning Since this quasi-encryption is based on real chat messages, it closely mimics the inventive ways users employ to disguise their messages to bypass the filter system, which can involve both insertion and deletion.", "labels": [], "entities": []}, {"text": "It is then imperative that we handle insertion, deletion and substitution in the disguised words to recover the original plain text words.", "labels": [], "entities": []}, {"text": "In the insertion case, for example, if the original word hello is disguised as helo, a NULL symbol is inserted inside the disguised word helo to decipher.", "labels": [], "entities": []}, {"text": "The ideal position to insert the NULL symbol is he<NULL>lo but it is not known during training.", "labels": [], "entities": []}, {"text": "To circumvent this, we experiment with two techniques: (1) to insert NULL at random before the beginning of the EM training, and (2) to insert the NULL using the method in Sec.", "labels": [], "entities": [{"text": "EM training", "start_pos": 112, "end_pos": 123, "type": "TASK", "confidence": 0.7982840538024902}]}, {"text": "This insertion techniques uses the word-, the n-gram count based insertion decipherment has a higher classification accuracy than the random insertion NULL decipherment.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.8558683395385742}]}, {"text": "An advantage of this type of HMM decipherment method is that it tends to not change the words that are already correct since these words have the highest language model score.", "labels": [], "entities": [{"text": "HMM decipherment", "start_pos": 29, "end_pos": 45, "type": "TASK", "confidence": 0.8769474625587463}]}, {"text": "Rather, it changes the words that are corrupted or misspelled.", "labels": [], "entities": []}, {"text": "Irrespective of the type of encryption, the HMM decipherment approach always deciphers the messages which fit with the language model we trained.", "labels": [], "entities": []}, {"text": "We conducted an additional experiment to test with the Aspell program.", "labels": [], "entities": [{"text": "Aspell program", "start_pos": 55, "end_pos": 69, "type": "DATASET", "confidence": 0.8817779421806335}]}, {"text": "shows that deciphered messages obtain better accuracies than Aspell on test sets B and C while on test set A, it is about 5% less accurate.", "labels": [], "entities": []}, {"text": "Note that the noisy channel model was trained on data obtained from a hand-tuned filtering system that was domain specific and created specifically for these chat messages.", "labels": [], "entities": []}, {"text": "What we find in our results is that the decipherment system can match this domain expertise using unsupervised learning without any domain specific knowledge.", "labels": [], "entities": []}, {"text": "shows every loglikelihood value in 100 random restarts on test-set B.", "labels": [], "entities": []}, {"text": "The mean of loglikelihood is -41444.7 and the standard deviation was 115.53.", "labels": [], "entities": []}, {"text": "The greater diversity among the real chat offensive words renders the decipherment much harder than controlled synthetic-scenarios.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Classification Accuracy of Spelling Correction and Decipherment Results in Caesar Cipher Encrypted Text", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9703521728515625}, {"text": "Caesar Cipher Encrypted Text", "start_pos": 85, "end_pos": 113, "type": "DATASET", "confidence": 0.5992414206266403}]}, {"text": " Table 2: Classification Accuracy of Spelling Correction and Decipherment Results in Leet Substitution Cipher with Beam", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9549069404602051}]}]}