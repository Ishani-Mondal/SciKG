{"title": [{"text": "Building and Learning Structures in a Situated Blocks World Through Deep Language Understanding", "labels": [], "entities": [{"text": "Deep Language Understanding", "start_pos": 68, "end_pos": 95, "type": "TASK", "confidence": 0.6785262227058411}]}], "abstractContent": [{"text": "We demonstrate a system for understanding natural language utterances for structure description and placement in a situated blocks world context.", "labels": [], "entities": [{"text": "structure description and placement", "start_pos": 74, "end_pos": 109, "type": "TASK", "confidence": 0.7490411251783371}]}, {"text": "By relying on a rich, domain-specific adaptation of a generic ontology and a logical form structure produced by a semantic parser, we obviate the need for an intermediate , domain-specific representation and can produce a reasoner that grounds and reasons over concepts and constraints with real-valued data.", "labels": [], "entities": []}, {"text": "This linguistic base enables more flexibility in interpreting natural language expressions invoking intrinsic concepts and features of structures and space.", "labels": [], "entities": [{"text": "interpreting natural language expressions invoking intrinsic concepts and features of structures and space", "start_pos": 49, "end_pos": 155, "type": "TASK", "confidence": 0.8125342038961557}]}, {"text": "We demonstrate some of the capabilities of a system grounded in deep language understanding and present initial results in a structure learning task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Even as early as one of the first Blocks World natural language interaction systems, SHRDLU, discussions about structures and space have been viewed as the foundation for future language understanding systems dealing with more abstract and higher-level concepts.", "labels": [], "entities": []}, {"text": "Since then, the field has advanced in the task of learning how to understand utterances in Blocks World and other situated environments by using statistical methods grounding syntactic trees to entities and actions in the world to learn placement descriptions (, predicates, actions) or a combination of paths and actions).", "labels": [], "entities": []}, {"text": "However, rather than considering grounding solely as a mapping to actions and objects in the world, we use the deep language understanding capabilities of the TRIPS parser () to find deeper conceptual connections to primitive, composable, and often recursive aspects of structures, and use this knowledge to better understand conceptually-rich utterances without the need for training data.", "labels": [], "entities": []}, {"text": "Inspired by the cognitive linguistic theory of conceptual mappings, we focus on projection mappings between structure and set features and demonstrate instances of common situated language that makes use of such mappings.", "labels": [], "entities": []}, {"text": "With these concepts grounded in a situated space, we believe we will be poised to extend the concepts in Blocks World into more abstract reasoning and language through grounded metaphor.", "labels": [], "entities": []}, {"text": "We also demonstrate the ability of our system to buildup a model of a class of structures through natural language dialogue.", "labels": [], "entities": []}, {"text": "Rather than constructing anew domain-specific representation for storing such knowledge, as in work by, we retain the semantic logical form structure as our base representation, using ontological concepts of comparison and semantic argument structures to ground concepts and predicates in the situated environment.", "labels": [], "entities": []}, {"text": "We therefore aim to show that a linguistic structures from a semantic parser can serve as a strong base for reasoning and model-building in a situated context.", "labels": [], "entities": []}], "datasetContent": [{"text": "Currently evaluation is in preliminary stages, with an emphasis on expanding capabilities in terms of the variety of structures able to be built and recognized.", "labels": [], "entities": []}, {"text": "A comprehensive evaluation task can be difficult for this system, given its symbolic backing.", "labels": [], "entities": []}, {"text": "As there is no statistical learning, the usefulness of the system is primarily determined by the coverage of understood linguistic constructions at two levels -at the semantic parser level and at the level of interpretation given a correct semantic parse.", "labels": [], "entities": []}, {"text": "One challenge faced in accurately evaluating the system is that users in a dialogue can be biased to choose language that the system understands, thereby reducing the average expressivity and linguistic complexity of their utterances.", "labels": [], "entities": []}, {"text": "To partially address this, we have begun evaluations of our structure learning task, as we believe this task better illustrates the variety of language used to describe spatial concepts and structures, compared to the structure building task, which often consists solely of simple \"place a block \u2329loca-tion\u232a\" utterances.", "labels": [], "entities": []}, {"text": "Users are provided with positive and negative examples of a structure class () and must teach the system the concept.", "labels": [], "entities": []}, {"text": "Our initial evaluation to determine possible areas of improvement before actual trials began with: In the structure learning task, the user must determine the patterns followed by the positive examples that do not match the negative examples and explain these constraints to the system.", "labels": [], "entities": []}, {"text": "An advantage of a Wizard of Oz task is that the user maintains the complexity of their utterances as they see positive results from their descriptions, providing us with valuable insight into the various types of utterances our system must understand.", "labels": [], "entities": []}, {"text": "We conducted 3 tasks with each of the 3 participants who were unaware of the details of the project, yielding 90 user utterances.", "labels": [], "entities": []}, {"text": "A researcher took the place of the system by asking questions and presenting examples.", "labels": [], "entities": []}, {"text": "By using a tablet that generated common questions and responses to bespoken by the avatar, these experiments could be carried out without the participants aware of the researcher's role as a stand-in for the system.", "labels": [], "entities": []}, {"text": "To evaluate the system's performance at the semantic parser level, we ran the parser on the users' utterances in these experiments and correctly parsed 89% of the utterances.", "labels": [], "entities": []}, {"text": "In evaluating the grounded interpretation level, we determine which of the correct parsed trees yield the desired constraint.", "labels": [], "entities": []}, {"text": "Of the correctly parsed utterances, 90% yielded the desired constraint in the current state of the system with some development occurring after these trials.", "labels": [], "entities": []}, {"text": "Further testing is required once the system's capabilities are finalized to seethe performance of the system in an unrestricted setting with new users.", "labels": [], "entities": []}, {"text": "Typical failures of the grounded interpretation level of the system involve utterances containing ordinal references (e.g., the second column), multiple values for constraints, ranges for feature values, or negative examples.", "labels": [], "entities": []}, {"text": "All of these system abilities are near-future work.", "labels": [], "entities": []}, {"text": "During this evaluation we also found that dialogue actions such as asking about features greatly simplified user utterances and therefore improved performance.", "labels": [], "entities": []}, {"text": "We also have begun trials of the complete dialogue system with promising results.", "labels": [], "entities": []}, {"text": "The system is able to understand a number of different structure classes through dialogue, such as a staircase, an L shape, and a U shape.", "labels": [], "entities": []}, {"text": "An example dialogue is shown in, where the user was presented with the visual examples in.", "labels": [], "entities": []}, {"text": "User: I want to teach you a shape.", "labels": [], "entities": []}, {"text": "Can you tell me something about the structure?", "labels": [], "entities": []}, {"text": "User: The bottom row must beat least 2.", "labels": [], "entities": []}, {"text": "System: Hmm, I didn't quite get that.", "labels": [], "entities": []}, {"text": "User: The bottom row has at least 2 blocks.", "labels": [], "entities": []}, {"text": "What is the greatest the width can be?", "labels": [], "entities": [{"text": "width", "start_pos": 25, "end_pos": 30, "type": "METRIC", "confidence": 0.9959934949874878}]}, {"text": "System: Okay, got it.", "labels": [], "entities": []}, {"text": "Can you show mean example?", "labels": [], "entities": []}, {"text": "\u2329user shows example\u232a System: Okay.", "labels": [], "entities": []}, {"text": "Where can the top block be?", "labels": [], "entities": []}, {"text": "User: The top block is always on the left.", "labels": [], "entities": []}, {"text": "User: \u2329user builds example\u232a Is this right?", "labels": [], "entities": []}, {"text": "System: I think so, because the bottom row's number is greater than or equal to 2 and the width is less than or equal to 5 and the top block is on the left.", "labels": [], "entities": [{"text": "width", "start_pos": 90, "end_pos": 95, "type": "METRIC", "confidence": 0.9785559177398682}]}], "tableCaptions": []}