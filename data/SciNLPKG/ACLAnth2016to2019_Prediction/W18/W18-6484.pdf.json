{"title": [{"text": "The ILSP/ARC submission to the WMT 2018 Parallel Corpus Filtering Shared Task", "labels": [], "entities": [{"text": "ILSP/ARC submission to the WMT 2018 Parallel Corpus Filtering Shared Task", "start_pos": 4, "end_pos": 77, "type": "DATASET", "confidence": 0.8026247024536133}]}], "abstractContent": [{"text": "This paper describes the submission of the Institute for Language and Speech Process-ing/Athena Research and Innovation Center (ILSP/ARC) for the WMT 2018 Parallel Corpus Filtering shared task.", "labels": [], "entities": [{"text": "Athena Research and Innovation Center (ILSP/ARC)", "start_pos": 89, "end_pos": 137, "type": "DATASET", "confidence": 0.9207461595535278}, {"text": "WMT 2018 Parallel Corpus Filtering shared task", "start_pos": 146, "end_pos": 192, "type": "TASK", "confidence": 0.8039559381348746}]}, {"text": "We explore several properties of sentences and sentence pairs that our system explored in the context of the task with the purpose of clustering sentence pairs according to their appropriateness in training MT systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 207, "end_pos": 209, "type": "TASK", "confidence": 0.9642497301101685}]}, {"text": "We also discuss alternative methods for ranking the sentence pairs of the most appropriate clusters with the aim of generating the two datasets (of 10 and 100 million words as required in the task) that were evaluated.", "labels": [], "entities": []}, {"text": "By summarizing the results of several experiments that were carried out by the organizers during the evaluation phase, our submission achieved an average BLEU score of 26.41, even though it does not make use of any language-specific resources like bilingual lex-ica, monolingual corpora, or MT output, while the average score of the best participant system was 27.91.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 154, "end_pos": 164, "type": "METRIC", "confidence": 0.9847591519355774}, {"text": "MT", "start_pos": 291, "end_pos": 293, "type": "TASK", "confidence": 0.9231124520301819}]}], "introductionContent": [{"text": "There is a growing literature on using webacquired data for constructing various types of language resources, including monolingual and parallel corpora.", "labels": [], "entities": []}, {"text": "As shown in, among others, and, such resources can be exploited in training generic or domain-specific machine translation systems.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 103, "end_pos": 122, "type": "TASK", "confidence": 0.6756288558244705}]}, {"text": "Nevertheless, compared to the acquisition of monolingual data from the web, construction of parallel resources is more challenging.", "labels": [], "entities": []}, {"text": "Apart from the identification of document pairs that are translations of each other and can be crawled from multilingual websites, the extraction of sentence pairs and, crucially, the selection of sentence pairs of good quality are far from straightforward.", "labels": [], "entities": []}, {"text": "Zarin\u00b8a exploit already available parallel corpora in order to get word alignments, which are then used to identify mistranslations.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 67, "end_pos": 82, "type": "TASK", "confidence": 0.6857912987470627}]}, {"text": "use N-gram language models built from monolingual corpora to estimate probabilities of source and target sentences, in a manner of assigning high scores to grammatical sentences and lower scores to ungrammatical sentences and non-sentences such as site maps, large lists of names, and blog comments.", "labels": [], "entities": []}, {"text": "Aiming to select sentence pairs of good adequacy and fluency, generate probabilistic dictionaries and n-gram models from Europarl corpora. and extract features based on translation and language models, and word alignments from the dataset under examination (i.e. this dataset is used to train models instead of using external language resources) and then apply unsupervised techniques such as outlier detection of estimated probability density and graph-based random walk algorithm to discard sentence pairs that are of limited or no importance.", "labels": [], "entities": [{"text": "Europarl corpora.", "start_pos": 121, "end_pos": 138, "type": "DATASET", "confidence": 0.9873110949993134}]}, {"text": "In the case of web acquired data, shallow features like aligners' scores, length ratio, and patterns in URLs from which the content was originated, have been proposed Esp\u00ec a-Gomis and Forcada, 2010).", "labels": [], "entities": [{"text": "length ratio", "start_pos": 74, "end_pos": 86, "type": "METRIC", "confidence": 0.8982520699501038}]}, {"text": "Ina different manner, many researchers have approached data selection as a domain-matching issue.", "labels": [], "entities": []}, {"text": "For instance, proposed the use of a neural language model trained on a domain-specific corpus to identify in-domain sentence pairs in a large corpus.", "labels": [], "entities": []}, {"text": "This paper describes the submission of IL-SP/ARC for the WMT 2018 Parallel Corpus Filtering shared task.", "labels": [], "entities": [{"text": "WMT 2018 Parallel Corpus Filtering shared task", "start_pos": 57, "end_pos": 103, "type": "TASK", "confidence": 0.5978494840008872}]}, {"text": "The task consisted in cleaning a very noisy English-German parallel corpus of 104 million sentence pairs provided by the organizers, with each EN-DE sentence pair accompanied by a score generated by the Hunalign sentence aligner.", "labels": [], "entities": []}, {"text": "The participants were to assign a quality score for each sentence pair, with higher scores indicating sentence pairs of better quality.", "labels": [], "entities": []}, {"text": "As reported in the shared task webpage 1 , \"Evaluation of the quality scores will be done by subsampling 10m and 100m word corpora based on these scores, training statistical and neural machine translation systems with these corpora, and evaluating translation quality on blind test sets using the BLEU score.\"", "labels": [], "entities": [{"text": "statistical and neural machine translation", "start_pos": 163, "end_pos": 205, "type": "TASK", "confidence": 0.6799760341644288}, {"text": "BLEU", "start_pos": 298, "end_pos": 302, "type": "METRIC", "confidence": 0.9964434504508972}]}, {"text": "Given that the organizers discouraged participants from subsampling the corpus for relevance to a specific domain (e.g. the news domain), domain adaptation approaches like the ones mentioned above seem to not fit this task.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 138, "end_pos": 155, "type": "TASK", "confidence": 0.749764084815979}]}, {"text": "In the shared task webpage, the organizers also released a development environment with configuration files and scripts that allowed participants to subsample corpora based on quality scores and to replicate the testing procedure with a development test set.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the evaluation experiments conducted by the organizers, four different translation systems were trained, namely (a) a Moses statistical system", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Examples of sentence pairs grouped to different clusters based on the shallow features detailed  in Section 2.2.", "labels": [], "entities": []}, {"text": " Table 3: BLEU evaluation scores (ranking was  based on the combination of clusters and Hunalign  scores)", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9961360096931458}, {"text": "Hunalign", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.8951498866081238}]}, {"text": " Table 4: BLEU evaluation scores (ranking was  based on the combination of clusters' scores and  sentences' length)", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9964052438735962}]}]}