{"title": [{"text": "Zero-Shot Dialog Generation with Cross-Domain Latent Actions", "labels": [], "entities": [{"text": "Zero-Shot Dialog Generation", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6966314017772675}]}], "abstractContent": [{"text": "This paper introduces zero-shot dialog generation (ZSDG), as a step towards neu-ral dialog systems that can instantly generalize to new situations with minimal data.", "labels": [], "entities": [{"text": "zero-shot dialog generation (ZSDG)", "start_pos": 22, "end_pos": 56, "type": "TASK", "confidence": 0.6709189663330714}]}, {"text": "ZSDG enables an end-to-end generative dialog system to generalize to anew domain for which only a domain description is provided and no training dialogs are available.", "labels": [], "entities": [{"text": "ZSDG", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9239970445632935}]}, {"text": "Then a novel learning framework , Action Matching, is proposed.", "labels": [], "entities": [{"text": "Action Matching", "start_pos": 34, "end_pos": 49, "type": "TASK", "confidence": 0.796586275100708}]}, {"text": "This algorithm can learn a cross-domain embedding space that models the semantics of dialog responses which, in turn, lets a neural dialog generation model generalize to new domains.", "labels": [], "entities": []}, {"text": "We evaluate our methods on anew synthetic dialog dataset, and an existing human-human dialog dataset.", "labels": [], "entities": []}, {"text": "Results show that our method has superior performance in learning dialog models that rapidly adapt their behavior to new domains and suggests promising future research.", "labels": [], "entities": []}], "introductionContent": [{"text": "The generative end-to-end dialog model (GEDM) is one of the most powerful methods of learning dialog agents from raw conversational data in both chat-oriented and task-oriented domains ().", "labels": [], "entities": [{"text": "generative end-to-end dialog model (GEDM)", "start_pos": 4, "end_pos": 45, "type": "TASK", "confidence": 0.708256449018206}]}, {"text": "Its base model is an encoder-decoder network () that uses an encoder network to encode the dialog context and generate the next response via a decoder network.", "labels": [], "entities": []}, {"text": "Yet prior work in GEDMs has overlooked an important issue, i.e. the data scarcity problem.", "labels": [], "entities": []}, {"text": "In fact, the data scarcity problem is extremely common inmost dialog applications due to the wide range of potential domains that dialog systems can be applied to.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, current GEDMs are data-hungry and have only been successfully applied to domains with abundant training material.", "labels": [], "entities": []}, {"text": "This limitation prohibits the possibility of using the GEDMs for rapid prototyping in new domains and is only useful for domains with large datasets.", "labels": [], "entities": []}, {"text": "The key idea of this paper lies in developing domain descriptions that can capture domain-specific information and anew type of GEDM model that can generalize to anew domain based on the domain description.", "labels": [], "entities": []}, {"text": "Humans exhibit incredible efficiency in achieving this type of adaptation.", "labels": [], "entities": []}, {"text": "Imagine that a customer service agent in the shoe department is transferred to the clothing department.", "labels": [], "entities": []}, {"text": "After reading some relevant instructions and documentation, this agent can immediately begin to deal with clothes-related calls without the need for any example dialogs.", "labels": [], "entities": []}, {"text": "We also argue that it is more efficient and natural for domain experts to express their knowledge in terms of domain descriptions rather than example dialogs.", "labels": [], "entities": []}, {"text": "This is because creating example dialogs involves writing down imagined dialog exchanges that can be shared across multiple domains and are not relevant to the unique proprieties of a specific domain.", "labels": [], "entities": []}, {"text": "However, current state-of-the-art GEDMs are not designed to incorporate such knowledge and are therefore incapable of adapting its behavior to unseen domains.", "labels": [], "entities": []}, {"text": "This paper introduces the use of zero-shot dialog generation (ZSDG) in order to enable GEDMs to generalize to unseen situations using minimal dialog data.", "labels": [], "entities": [{"text": "zero-shot dialog generation", "start_pos": 33, "end_pos": 60, "type": "TASK", "confidence": 0.6713561713695526}]}, {"text": "Building on zero-shot classification (), we formalize ZSDG as a learning problem where the training data contains dialog data from source domains along with domain descriptions from both the source and tar-get domains.", "labels": [], "entities": [{"text": "zero-shot classification", "start_pos": 12, "end_pos": 36, "type": "TASK", "confidence": 0.7254629731178284}]}, {"text": "Then at testing time, ZSDG models are evaluated on the target domain, where no training dialogs were available.", "labels": [], "entities": []}, {"text": "We approach ZSDG by first discovering a dialog policy network that can be shared between the source and target domains.", "labels": [], "entities": []}, {"text": "The output from this policy is distributed vectors which are referred to as latent actions.", "labels": [], "entities": []}, {"text": "Then, in order to transform the latent actions from any domain back to natural language utterances, a novel Action Matching (AM) algorithm is proposed that learns a cross-domain latent action space that models the semantics of dialog responses.", "labels": [], "entities": [{"text": "Action Matching (AM)", "start_pos": 108, "end_pos": 128, "type": "TASK", "confidence": 0.716669225692749}]}, {"text": "This in turns enables the GEDM to generate responses in the target domains even when it has never observed full dialogs in them.", "labels": [], "entities": [{"text": "GEDM", "start_pos": 26, "end_pos": 30, "type": "TASK", "confidence": 0.7935632467269897}]}, {"text": "Finally the proposed methods and baselines are evaluated on two dialog datasets.", "labels": [], "entities": []}, {"text": "The first one is anew synthetic dialog dataset generated by SimDial, which was developed for this study.", "labels": [], "entities": []}, {"text": "SimDial enables us to easily generate task-oriented dialogs in a large number of domains, and provides a test bed to evaluate different ZSDG approaches.", "labels": [], "entities": []}, {"text": "We further test our methods on a recently released multi-domain human-human corpus () to validate whether performance can generalize to real-world conversations.", "labels": [], "entities": []}, {"text": "Experimental results show that our methods are effective in incorporating knowledge from domain descriptions and achieve strong ZSDG performance.", "labels": [], "entities": []}], "datasetContent": [{"text": "The baseline models include 1.", "labels": [], "entities": []}, {"text": "hierarchical recurrent encoder with attention decoder (+Attn)).", "labels": [], "entities": [{"text": "Attn", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.9597991108894348}]}, {"text": "2. hierarchical recurrent encoder with copy decoder (Merity et al., 2016) (+Copy), which has achieved very good performance on task-oriented dialogs).", "labels": [], "entities": []}, {"text": "We then augment both baseline models with the proposed cross-domain AM training procedure and denote them as +Attn+AM and +Copy+AM.", "labels": [], "entities": []}, {"text": "Evaluating generative dialog systems is challenging since the model can generate free-form responses.", "labels": [], "entities": [{"text": "generative dialog", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.8845022618770599}]}, {"text": "Fortunately, we have access to the internal semantic frames of the SimDial data, so we use the automatic measures used in () that employ four metrics to quantify the performance of a task-oriented dialog model.", "labels": [], "entities": [{"text": "SimDial data", "start_pos": 67, "end_pos": 79, "type": "DATASET", "confidence": 0.8370471000671387}]}, {"text": "BLEU is the corpus-level BLEU-4 between the generated response and the reference ones ().", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9737846851348877}, {"text": "BLEU-4", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.960357129573822}]}, {"text": "Entity F 1 checks if a generated response contains the correct entities (slots) in the reference response.", "labels": [], "entities": [{"text": "Entity F 1", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.7176903684933981}]}, {"text": "Act F 1 measures whether the generated responses reflect the dialog acts in the reference responses, which compensates for BLEU's limitation of looking for exact word choices.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 123, "end_pos": 127, "type": "METRIC", "confidence": 0.9626105427742004}]}, {"text": "A onevs-rest support vector machine () with bi-gram features is trained to tag the dialogs in a response.", "labels": [], "entities": []}, {"text": "KB F 1 checks all the key words in a KB query that the system issues to the KB backend.", "labels": [], "entities": [{"text": "KB F 1", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.6694934765497843}]}, {"text": "Finally, we introduce BEAK = 4 \u221a bleu \u00d7 ent \u00d7 act \u00d7 kb, the geometric mean of these four scores, to quantify a system's overall performance.", "labels": [], "entities": [{"text": "BEAK", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.9995998740196228}]}, {"text": "Meanwhile, since the oracle dialog acts and KB queries are not provided in the SMD data), we only report BLEU and entity F 1 results on SMD.", "labels": [], "entities": [{"text": "SMD", "start_pos": 79, "end_pos": 82, "type": "TASK", "confidence": 0.9364262223243713}, {"text": "BLEU", "start_pos": 105, "end_pos": 109, "type": "METRIC", "confidence": 0.9979609251022339}, {"text": "SMD", "start_pos": 136, "end_pos": 139, "type": "TASK", "confidence": 0.9002041220664978}]}], "tableCaptions": [{"text": " Table 1: Evaluation results on test dialogs from  SimDial Data. Bold values indicate the best per- formance.", "labels": [], "entities": [{"text": "SimDial Data", "start_pos": 51, "end_pos": 63, "type": "DATASET", "confidence": 0.9158142507076263}]}, {"text": " Table 2: Evaluation on SMD data. The bold do- main title is the one that was excluded from train- ing.", "labels": [], "entities": [{"text": "SMD", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.9744354486465454}]}]}