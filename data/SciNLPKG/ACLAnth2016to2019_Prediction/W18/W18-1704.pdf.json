{"title": [{"text": "Multi-Sentence Compression with Word Vertex-Labeled Graphs and Integer Linear Programming", "labels": [], "entities": []}], "abstractContent": [{"text": "Multi-Sentence Compression (MSC) aims to generate a short sentence with key information from a cluster of closely related sentences.", "labels": [], "entities": [{"text": "Multi-Sentence Compression (MSC)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7584690451622009}]}, {"text": "MSC enables summarization and question-answering systems to generate outputs combining fully formed sentences from one or several documents.", "labels": [], "entities": [{"text": "MSC", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.732992947101593}, {"text": "summarization", "start_pos": 12, "end_pos": 25, "type": "TASK", "confidence": 0.9626362919807434}]}, {"text": "This paper describes anew Integer Linear Programming method for MSC using a vertex-labeled graph to select different keywords, and novel 3-grams scores to generate more informative sentences while maintaining their grammaticality.", "labels": [], "entities": [{"text": "MSC", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.9269819259643555}]}, {"text": "Our system is of good quality and outperforms the state-of-the-art for evaluations led on news dataset.", "labels": [], "entities": []}, {"text": "We led both automatic and manual evaluations to determine the informativeness and the gram-maticality of compressions for each dataset.", "labels": [], "entities": []}, {"text": "Additional tests, which take advantage of the fact that the length of compressions can be modulated, still improve ROUGE scores with shorter output sentences.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 115, "end_pos": 120, "type": "METRIC", "confidence": 0.979438304901123}]}], "introductionContent": [{"text": "The increased number of electronic devices (smartphones, tablets, etc.) have made access to information easier and faster.", "labels": [], "entities": []}, {"text": "Websites such as Wikipedia or news aggregators can provide detailed data on various issues but texts maybe long and convey a lot of information.", "labels": [], "entities": []}, {"text": "One solution to this problem is the generation of summaries containing only key information.", "labels": [], "entities": []}, {"text": "Among the various applications of Natural Language Processing (NLP), Automatic Text Summarization (ATS) aims to automatically identify the relevant data inside one or more documents, and create a condensed text with the main information.", "labels": [], "entities": [{"text": "Automatic Text Summarization (ATS)", "start_pos": 69, "end_pos": 103, "type": "TASK", "confidence": 0.7651009410619736}]}, {"text": "Summarization systems usually rely on statistical, morphological and syntactic analysis approaches).", "labels": [], "entities": [{"text": "Summarization", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.9624178409576416}]}, {"text": "Some of them use MultiSentence Compression (MSC) in order to produce from a set of similar sentences a small-sized sentence which is both grammatically correct and informative.", "labels": [], "entities": []}, {"text": "Although compression is a challenging task, it is appropriate to generate summaries that are more informative than state-of-the-art extraction methods for ATS.", "labels": [], "entities": []}, {"text": "The contributions of this article are two-fold.", "labels": [], "entities": []}, {"text": "(i) We present anew model for MSC that extends the common approach based on Graph Theory, using vertex-labeled graphs and Integer Linear Programming (ILP) to select the best compression.", "labels": [], "entities": [{"text": "MSC", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.9226582646369934}, {"text": "Graph Theory", "start_pos": 76, "end_pos": 88, "type": "TASK", "confidence": 0.6775321215391159}]}, {"text": "The vertex-labeled graphs are used to model a cluster of similar sentences with keywords, while the optimization criterion introduces a novel 3-grams score to enhance the correctness of sentences.", "labels": [], "entities": []}, {"text": "(ii) We can setup a maximum length for the compression.", "labels": [], "entities": []}, {"text": "The system can generate shorter compressions losing some information, or privilege the informativeness generating longer compressions.", "labels": [], "entities": []}, {"text": "Evaluations led with both automatic metrics and human evaluations show that our ILP model consistently generate more informative sentences than two baselines while maintaining their grammaticality.", "labels": [], "entities": []}, {"text": "Our approach is able to choose the amount of information to keep in the compression output, through the definition of the number of keywords to consider in documents.", "labels": [], "entities": []}, {"text": "This paper is organized as follows: we describe and survey the MSC problem in Section 2.", "labels": [], "entities": [{"text": "MSC problem", "start_pos": 63, "end_pos": 74, "type": "TASK", "confidence": 0.9084995687007904}]}, {"text": "Next, we detail our approach in Section 3.", "labels": [], "entities": []}, {"text": "The experiments and the results are discussed in Sections 4 and 5.", "labels": [], "entities": []}, {"text": "Lastly, we provide the Conclusion and some final comments in Section 6.", "labels": [], "entities": [{"text": "Conclusion", "start_pos": 23, "end_pos": 33, "type": "METRIC", "confidence": 0.9798256754875183}]}], "datasetContent": [{"text": "Algorithms were implemented using the Python programming language with the takahe 4 and gensim 5 libraries.", "labels": [], "entities": []}, {"text": "The mathematical model was implemented in C++ with the Concert library and we used the solver CPLEX 12.6 6 . We define the keyword bonus as the geometric average 7 of all arc weights in the graph.", "labels": [], "entities": [{"text": "solver CPLEX 12.6", "start_pos": 87, "end_pos": 104, "type": "TASK", "confidence": 0.6947167714436849}]}, {"text": "Various corpora have been developed for MSC and are composed of clusters of similar sentences from different source news in English, French, Spanish or Vietnamese languages.", "labels": [], "entities": []}, {"text": "The corpora used by and contain clusters of at least 7 or 8 similar sentences, whereas the data of and have clusters limited to pairs of sentences.", "labels": [], "entities": []}, {"text": "https: //www-01.ibm.com/software/ websphere/products/optimization/ cplex-studio-community-edition/ 7 Each WG has different weight arcs, so it is important that keyword bonus has a correct value to allow the generation of slightly longer compressions.", "labels": [], "entities": []}, {"text": "We tested several metrics (fixed values, arithmetic average, median, and geometric average of weights arcs of WG) to define the keyword bonus of WG and empirically found that the geometric average outperformed the others.", "labels": [], "entities": []}, {"text": "(2015) made their corpora publicly available but only the corpus of is more suited to multi-document summarization or question-answering because the documents to analyze are usually composed of many similar sentences.", "labels": [], "entities": [{"text": "multi-document summarization", "start_pos": 86, "end_pos": 114, "type": "TASK", "confidence": 0.6091044545173645}]}, {"text": "Therefore, we use this corpus made of 618 French sentences spread over 40 clusters.", "labels": [], "entities": []}, {"text": "Each cluster has 3 sentences compressed by native speakers, references having a compression rate of 60%.", "labels": [], "entities": []}, {"text": "The most important features of MSC are informativeness and grammaticality.", "labels": [], "entities": [{"text": "MSC", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.9208947420120239}]}, {"text": "Informativeness measures how informational is the generated text.", "labels": [], "entities": []}, {"text": "As references are assumed to contain the key information, we calculated informativeness scores counting the n-grams in common between the compression and the reference compressions using the ROUGE system).", "labels": [], "entities": []}, {"text": "In particular, we used the F-measure metrics ROUGE-1 and ROUGE-2, F-measure being preferred to recall fora fair comparison of various lengths of compressed sentences.", "labels": [], "entities": [{"text": "F-measure metrics ROUGE-1", "start_pos": 27, "end_pos": 52, "type": "METRIC", "confidence": 0.8148451447486877}, {"text": "ROUGE-2", "start_pos": 57, "end_pos": 64, "type": "METRIC", "confidence": 0.9816842675209045}, {"text": "F-measure", "start_pos": 66, "end_pos": 75, "type": "METRIC", "confidence": 0.9480366110801697}, {"text": "recall", "start_pos": 95, "end_pos": 101, "type": "METRIC", "confidence": 0.9543079137802124}]}, {"text": "Like in, ROUGE metrics are calculated with stopwords removal and French stemming 8 . Due to limitations of ROUGE systems that only analyze 1-grams and 2-grams, we also led a manual evaluation with 5 French native speakers.", "labels": [], "entities": []}, {"text": "The native speakers evaluated the compression in two aspects: informativeness and grammaticality.", "labels": [], "entities": []}, {"text": "In the same way as, the native speakers evaluated the grammaticality in a 3-point scale: 2 points fora correct sentence; 1 point if the sentence has minor mistakes; 0 point if it is none of the above.", "labels": [], "entities": []}, {"text": "Like grammaticality, informativeness is evaluated in the same range: 2 points if the compression contains the main information; 1 point if the compression misses some relevant information; 0 point if the compression is not related to the main topic.", "labels": [], "entities": []}, {"text": "Compression rates are strongly correlated with human judgments of meaning and grammaticality).", "labels": [], "entities": []}, {"text": "On the one hand, too short compressions may compromise sentence structure, reducing the informativeness and grammaticality.", "labels": [], "entities": []}, {"text": "On the other hand, longer compressions are more interesting for ATS when informa-tiveness and grammaticality are decisive features.", "labels": [], "entities": [{"text": "ATS", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.8780004978179932}]}, {"text": "Consequently, we generate two kinds of compressions according to the number of keywords in the graph (5 or 10), which acts on the final size of the output sentences.", "labels": [], "entities": []}, {"text": "The result tables are split into two parts, each having similar CRs and calculated from LSI, LDA or TextRank methods to identify the keywords of the clusters.", "labels": [], "entities": []}, {"text": "describes the results for the French corpus using ROUGE.", "labels": [], "entities": [{"text": "French corpus", "start_pos": 30, "end_pos": 43, "type": "DATASET", "confidence": 0.9232552945613861}, {"text": "ROUGE", "start_pos": 50, "end_pos": 55, "type": "METRIC", "confidence": 0.968388020992279}]}, {"text": "The first two lines display the evaluation of the two baseline systems; the ROUGE scores measured with our method using either 5 or 10 keywords are shown in the next three lines and the last three lines respectively.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 76, "end_pos": 81, "type": "METRIC", "confidence": 0.99489426612854}]}, {"text": "Informativeness: ROUGE results and manual evaluations on the French corpus.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 17, "end_pos": 22, "type": "METRIC", "confidence": 0.9856265187263489}, {"text": "French corpus", "start_pos": 61, "end_pos": 74, "type": "DATASET", "confidence": 0.9160703122615814}]}, {"text": "The results in italics represent the best results with CR closed to the baselines.", "labels": [], "entities": [{"text": "CR", "start_pos": 55, "end_pos": 57, "type": "METRIC", "confidence": 0.9951985478401184}]}, {"text": "The best ROUGE results are in bold.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 9, "end_pos": 14, "type": "METRIC", "confidence": 0.9914275407791138}]}], "tableCaptions": [{"text": " Table 1: ROUGE results and manual evaluations on the French corpus. The results in italics represent  the best results with CR closed to the baselines. The best ROUGE results are in bold.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.822063684463501}, {"text": "French corpus", "start_pos": 54, "end_pos": 67, "type": "DATASET", "confidence": 0.9614061713218689}, {"text": "CR", "start_pos": 125, "end_pos": 127, "type": "METRIC", "confidence": 0.9838571548461914}]}, {"text": " Table 2: Compression length (#words), standard  deviation and number of used keywords computed  on the French corpus.", "labels": [], "entities": [{"text": "Compression length", "start_pos": 10, "end_pos": 28, "type": "METRIC", "confidence": 0.9698877036571503}, {"text": "standard", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.964718222618103}, {"text": "French corpus", "start_pos": 104, "end_pos": 117, "type": "DATASET", "confidence": 0.9452933669090271}]}]}