{"title": [{"text": "The Fine Line between Linguistic Generalization and Failure in Seq2Seq-Attention Models", "labels": [], "entities": [{"text": "Linguistic Generalization", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.7973692417144775}]}], "abstractContent": [{"text": "Seq2Seq based neural architectures have become the go-to architecture to apply to sequence to sequence language tasks.", "labels": [], "entities": []}, {"text": "Despite their excellent performance on these tasks, recent work has noted that these models usually do not fully capture the linguistic structure required to generalize beyond the dense sections of the data distribution (Ettinger et al., 2017), and as such, are likely to fail on samples from the tail end of the distribution (such as inputs that are noisy (Belinkov and Bisk, 2018) or of different lengths (Bentivogli et al., 2016)).", "labels": [], "entities": []}, {"text": "In this paper, we look at a model's ability to generalize on a simple symbol rewriting task with a clearly defined structure.", "labels": [], "entities": []}, {"text": "We find that the model's ability to generalize this structure beyond the training distribution depends greatly on the chosen random seed, even when performance on the standard test set remains the same.", "labels": [], "entities": []}, {"text": "This suggests that a model's ability to capture generalizable structure is highly sensitive.", "labels": [], "entities": []}, {"text": "Moreover, this sensitivity may not be apparent when evaluating it on standard test sets.", "labels": [], "entities": []}], "introductionContent": [{"text": "It is well known that language has certain structural properties which allows natural language speakers to make \"infinite use of finite means\".", "labels": [], "entities": []}, {"text": "This structure allows us to generalize beyond the typical machine learning definition of generalization) (which considers performance on the distribution that generated the training set), permitting the understanding of any utterance sharing the same structure, regardless of probability.", "labels": [], "entities": []}, {"text": "We refer to this notion as linguistic generalization 1 . Many problems in NLP are treated as sequence to sequence tasks with solutions built on seq2seq- * *These authors contributed equally to this work.", "labels": [], "entities": [{"text": "linguistic generalization", "start_pos": 27, "end_pos": 52, "type": "TASK", "confidence": 0.6991381198167801}]}, {"text": "From hereon, mentions of generalization refer to the linguistic kind.", "labels": [], "entities": []}, {"text": "While these models perform very well on standard datasets and also appear to capture some linguistic structure (, they also can be quite brittle, typically breaking on uncharacteristic inputs.", "labels": [], "entities": []}, {"text": "Due to the high capacity of these models, it is not unreasonable to expect them to learn some structure from the data.", "labels": [], "entities": []}, {"text": "However, learning structure is not a sufficient condition to achieving linguistic generalization.", "labels": [], "entities": [{"text": "linguistic generalization", "start_pos": 71, "end_pos": 96, "type": "TASK", "confidence": 0.7133224010467529}]}, {"text": "If this structure is to be usable on data outside the training distribution, the model must learn the structure without additionally learning patterns specific to the training data.", "labels": [], "entities": []}, {"text": "In this work, we look at the feasibility of training seq2seq-attention models so they generalize in this linguistic sense.", "labels": [], "entities": []}, {"text": "We train models on a symbol replacement task with a well defined generalizable structure.", "labels": [], "entities": [{"text": "symbol replacement task", "start_pos": 21, "end_pos": 44, "type": "TASK", "confidence": 0.7946577072143555}]}, {"text": "The task is simple enough that all models achieve near perfect accuracy on the standard test set, i.e., where the inputs are drawn from the same distribution as that of the training set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.998481810092926}]}, {"text": "We then test these models for linguistic generalization by creating test sets of uncharacteristic inputs, i.e., inputs that are not typical in the training distribution but still solvable given that the generalizable structure was learned.", "labels": [], "entities": [{"text": "linguistic generalization", "start_pos": 30, "end_pos": 55, "type": "TASK", "confidence": 0.7018067687749863}]}, {"text": "Our results show that generalization is highly sensitive 2 ; even changes in the random seed can drastically affect the ability to generalize.", "labels": [], "entities": [{"text": "generalization", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.9859905242919922}]}, {"text": "This suggests that the line between generalization and failure is quite fine, and may not be feasible to reach by tuning alone.", "labels": [], "entities": [{"text": "generalization", "start_pos": 36, "end_pos": 50, "type": "TASK", "confidence": 0.960721492767334}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Details about the four test sets used in our  experiments.", "labels": [], "entities": []}, {"text": " Table 3: Accuracy % summarized across all 50  runs with different random seeds.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.998749852180481}]}, {"text": " Table 4: Accuracy % on the test sets for selected  runs out of 50 with different random seeds.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9987223744392395}]}]}