{"title": [{"text": "Alibaba's Neural Machine Translation Systems for WMT18", "labels": [], "entities": [{"text": "Neural Machine Translation", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.579989492893219}, {"text": "WMT18", "start_pos": 49, "end_pos": 54, "type": "TASK", "confidence": 0.5416733622550964}]}], "abstractContent": [{"text": "This paper describes the submission systems of Alibaba for WMT18 shared news translation task.", "labels": [], "entities": [{"text": "Alibaba", "start_pos": 47, "end_pos": 54, "type": "DATASET", "confidence": 0.9587268829345703}, {"text": "WMT18 shared news translation task", "start_pos": 59, "end_pos": 93, "type": "TASK", "confidence": 0.772331702709198}]}, {"text": "We participated in 5 translation directions including English \u2194 Russian, English \u2194 Turkish in both directions and English \u2192 Chinese.", "labels": [], "entities": []}, {"text": "Our systems are based on Google's Transformer model architecture, into which we integrated the most recent features from the academic research.", "labels": [], "entities": []}, {"text": "We also employed most techniques that have been proven effective during the past WMT years, such as BPE, back translation, data selection, model ensembling and reranking, at industrial scale.", "labels": [], "entities": [{"text": "WMT", "start_pos": 81, "end_pos": 84, "type": "TASK", "confidence": 0.9246070981025696}, {"text": "BPE", "start_pos": 100, "end_pos": 103, "type": "METRIC", "confidence": 0.52712082862854}, {"text": "back translation", "start_pos": 105, "end_pos": 121, "type": "TASK", "confidence": 0.7627317905426025}, {"text": "data selection", "start_pos": 123, "end_pos": 137, "type": "TASK", "confidence": 0.8195607662200928}, {"text": "model ensembling", "start_pos": 139, "end_pos": 155, "type": "TASK", "confidence": 0.7209055125713348}]}, {"text": "For some morphologically-rich languages, we also incorporated linguistic knowledge into our neu-ral network.", "labels": [], "entities": []}, {"text": "For the translation tasks in which we have participated, our resulting systems achieved the best case sensitive BLEU score in all 5 directions.", "labels": [], "entities": [{"text": "translation tasks", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.903544694185257}, {"text": "BLEU score", "start_pos": 112, "end_pos": 122, "type": "METRIC", "confidence": 0.9764161705970764}]}, {"text": "Notably, our English \u2192 Rus-sian system outperformed the second reranked system by 5 BLEU score.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 84, "end_pos": 94, "type": "METRIC", "confidence": 0.9728919565677643}]}], "introductionContent": [{"text": "We participated in the WMT18 shared news translation task in 3 different language pairs: English \u2194 Russian, English \u2194 Turkish and English \u2192 Chinese.", "labels": [], "entities": [{"text": "WMT18 shared news translation task", "start_pos": 23, "end_pos": 57, "type": "TASK", "confidence": 0.7993098735809326}]}, {"text": "English \u2194 Russian is a traditional WMT language pair possessing a large amount of bilingual training and development data.", "labels": [], "entities": [{"text": "WMT language", "start_pos": 35, "end_pos": 47, "type": "TASK", "confidence": 0.905026912689209}]}, {"text": "And especially this year, 16 million new translation units are available for the training.", "labels": [], "entities": []}, {"text": "However for some more recent language pairs, the situation of bilingual resources is less promising: English \u2194 Turkish language pair only has 200 K bitexts and for English \u2192 Chinese, the amount of bilingual resources remains the same as last year.", "labels": [], "entities": []}, {"text": "In the following sections of this article, We will see that the availability of bilingual resources can differentiate the performance of the final system.", "labels": [], "entities": []}, {"text": "More * Equal contribution precisely, more bilingual data means greater ability to interact and absorb target side monolingual knowledge through the process of back translation, as well as its ability to retrieve the pertinent in-domain data during the data selection process.", "labels": [], "entities": []}, {"text": "We share a very similar model architecture and training flow for different languages directions.", "labels": [], "entities": []}, {"text": "Our models are based on the Google's Transformer architecture (.", "labels": [], "entities": []}, {"text": "In order to improve our single system's performance, we experiment with some latest research findings such as transformer with relative position attention (, weighted transformer () and neural suffix prediction for Russian () which will be developed in the next section.", "labels": [], "entities": [{"text": "neural suffix prediction", "start_pos": 186, "end_pos": 210, "type": "TASK", "confidence": 0.6144403219223022}]}, {"text": "We will also see that different well-known multi-system based techniques such as model ensembling and model reranking can still improve the performance of a very strong single system, even though we have to push further the limit in term of the number of models to employ as well as the methods to combine them together.", "labels": [], "entities": [{"text": "model ensembling", "start_pos": 81, "end_pos": 97, "type": "TASK", "confidence": 0.7082031220197678}]}, {"text": "The paper is structured as follows: Section 2 will describe the novelties of our model architecture compared to the Google's standard Transformer framework, then we present a detailed overview of our system in Section 3, before giving the experimental settings and main results across languages in Section 4.", "labels": [], "entities": []}, {"text": "Finally, Section 5 will draw a brief conclusion of our work for WMT18.", "labels": [], "entities": [{"text": "WMT18", "start_pos": 64, "end_pos": 69, "type": "DATASET", "confidence": 0.9297900795936584}]}], "datasetContent": [{"text": "Preliminary experiments showed that the model features described in the section 2 yielded similar improvements reported in the original papers, or on par with the standard Transformer.", "labels": [], "entities": []}, {"text": "For all of our baseline systems, we integrated these features into our model architecture, except the neural suffix prediction which is only used for the English \u2192 Russian system.", "labels": [], "entities": [{"text": "neural suffix prediction", "start_pos": 102, "end_pos": 126, "type": "TASK", "confidence": 0.6424727241198221}]}, {"text": "1 http://www.statmt.org/moses/ All of our experiments employ 6 encoder and decoder self-attention layers, both embedding and hidden size have a dimension of 512, 8 heads for the self-attention.", "labels": [], "entities": []}, {"text": "We use FFN layer with 2048 cells and Swish ( as activation function.", "labels": [], "entities": []}, {"text": "Warmup step is set to 16000 with a learning rate equals to 0.0003.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 35, "end_pos": 48, "type": "METRIC", "confidence": 0.9502966105937958}]}, {"text": "We use label smoothing with a confidence score 0.9 and all the dropout probabilities are set to 0.1.", "labels": [], "entities": [{"text": "label smoothing", "start_pos": 7, "end_pos": 22, "type": "TASK", "confidence": 0.7572872340679169}]}, {"text": "All baseline systems are trained with 4 to 8 GPUs using synchronous-SGD with moving average mechanism where the average is taken in time and in space ( . We use BLEU as evaluation metric).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 161, "end_pos": 165, "type": "METRIC", "confidence": 0.9971163272857666}]}, {"text": "For English \u2194 Russian and English \u2194 Turkish, all reported scores are calculated over tokenized texts except for the 2018 submission which is end2end BLEU.", "labels": [], "entities": [{"text": "end2end", "start_pos": 141, "end_pos": 148, "type": "DATASET", "confidence": 0.5679899454116821}, {"text": "BLEU", "start_pos": 149, "end_pos": 153, "type": "METRIC", "confidence": 0.8811116218566895}]}, {"text": "For English \u2192 Chinese, all reported scores are end2end BLEU score using the SACREBLEU toolkit 2 (Post, 2018).", "labels": [], "entities": [{"text": "end2end", "start_pos": 47, "end_pos": 54, "type": "METRIC", "confidence": 0.970570981502533}, {"text": "BLEU", "start_pos": 55, "end_pos": 59, "type": "METRIC", "confidence": 0.8749879002571106}, {"text": "SACREBLEU toolkit 2 (Post, 2018)", "start_pos": 76, "end_pos": 108, "type": "DATASET", "confidence": 0.9001902192831039}]}], "tableCaptions": [{"text": " Table 1: Synthetic data usage. Authentic: the amount  of authentic parallel data after cleaning; Synthetic  (critical): the maximal amount of synthetic data added  to the parallel data with improvement; Synthetic (up- per bound tested): the maximal amount of synthetic  data tested", "labels": [], "entities": [{"text": "Authentic", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9877270460128784}]}, {"text": " Table 2: Perplexity analysis of the effect of back trans- lation with English \u2192 Russian examples", "labels": [], "entities": []}, {"text": " Table 4: EN \u2192 ZH BLEU results on newsdev2017 and  newstest2017", "labels": [], "entities": [{"text": "BLEU", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.8577193021774292}, {"text": "newsdev2017", "start_pos": 34, "end_pos": 45, "type": "DATASET", "confidence": 0.947687566280365}, {"text": "newstest2017", "start_pos": 51, "end_pos": 63, "type": "DATASET", "confidence": 0.8885131478309631}]}, {"text": " Table 5: EN \u2192 RU BLEU results on newstest2016 and  newstest2017", "labels": [], "entities": [{"text": "RU", "start_pos": 15, "end_pos": 17, "type": "METRIC", "confidence": 0.8801227807998657}, {"text": "BLEU", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.903788149356842}, {"text": "newstest2017", "start_pos": 52, "end_pos": 64, "type": "DATASET", "confidence": 0.859844982624054}]}, {"text": " Table 6: RU \u2192 EN BLEU results on newstest2016 and  newstest2017", "labels": [], "entities": [{"text": "RU", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.8059854507446289}, {"text": "EN", "start_pos": 15, "end_pos": 17, "type": "METRIC", "confidence": 0.6038336157798767}, {"text": "BLEU", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.873863697052002}, {"text": "newstest2017", "start_pos": 52, "end_pos": 64, "type": "DATASET", "confidence": 0.8618868589401245}]}, {"text": " Table 7: EN \u2192 TR BLEU results on newstest2016 and  newstest2017", "labels": [], "entities": [{"text": "TR", "start_pos": 15, "end_pos": 17, "type": "METRIC", "confidence": 0.906075656414032}, {"text": "BLEU", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.881184995174408}, {"text": "newstest2017", "start_pos": 52, "end_pos": 64, "type": "DATASET", "confidence": 0.8645131587982178}]}, {"text": " Table 8: TR \u2192 EN BLEU results on newstest2016 and  newstest2017", "labels": [], "entities": [{"text": "TR \u2192 EN", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.5304572979609171}, {"text": "BLEU", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.763800323009491}, {"text": "newstest2017", "start_pos": 52, "end_pos": 64, "type": "DATASET", "confidence": 0.8633946180343628}]}]}