{"title": [{"text": "Disney at IEST 2018: Predicting Emotions using an Ensemble", "labels": [], "entities": [{"text": "Disney at IEST 2018", "start_pos": 0, "end_pos": 19, "type": "DATASET", "confidence": 0.6830274313688278}, {"text": "Predicting Emotions", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.8894135355949402}]}], "abstractContent": [{"text": "This paper describes our participating system in the WASSA 2018 shared task on emotion prediction.", "labels": [], "entities": [{"text": "WASSA 2018 shared task on emotion prediction", "start_pos": 53, "end_pos": 97, "type": "TASK", "confidence": 0.698594446693148}]}, {"text": "The task focuses on implicit emotion prediction in a tweet.", "labels": [], "entities": [{"text": "implicit emotion prediction in a tweet", "start_pos": 20, "end_pos": 58, "type": "TASK", "confidence": 0.7261554499467214}]}, {"text": "In this task, keywords corresponding to the six emotion labels used (anger, fear, disgust, joy, sad, and surprise) have been removed from the tweet text, making emotion prediction implicit and the task challenging.", "labels": [], "entities": [{"text": "emotion prediction", "start_pos": 161, "end_pos": 179, "type": "TASK", "confidence": 0.7275949418544769}]}, {"text": "We propose a model based on an ensemble of classifiers for prediction.", "labels": [], "entities": []}, {"text": "Each classifier uses a sequence of Convolutional Neural Network (CNN) architecture blocks and uses ELMo (Embeddings from Language Model) as an input.", "labels": [], "entities": []}, {"text": "Our system achieves a 66.2% F1 score on the test set.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9860950410366058}]}, {"text": "The best performing system in the shared task has reported a 71.4% F1 score.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.9855102300643921}]}], "introductionContent": [{"text": "Besides understanding the language humans communicate in, AI systems that naturally interact with humans should also understand implicit emotions in language.", "labels": [], "entities": []}, {"text": "To be consistent and meaningful, an AI system conversing with humans should reply while taking into account the emotion of the utterance spoken by the human.", "labels": [], "entities": []}, {"text": "If the user appears to be unhappy, a subsequent joyful response from the system would likely detract from the engagement of the user in the conversation.", "labels": [], "entities": []}, {"text": "In recent years, several researchers have attempted to address this problem by developing automated emotion prediction for text.", "labels": [], "entities": [{"text": "automated emotion prediction", "start_pos": 90, "end_pos": 118, "type": "TASK", "confidence": 0.6921277940273285}]}, {"text": "Predicting emotions implicit in natural language is not trivial.", "labels": [], "entities": []}, {"text": "A na\u00a8\u0131vena\u00a8\u0131ve attempt to classify text based on emotion keywords may not always work due to the presence of various linguistic phenomena (e.g., negation, ambiguities, etc.) in the text.", "labels": [], "entities": []}, {"text": "Moreover, emotion maybe triggered by a sequence of words and not just a single keyword, requiring an * indicates equal contribution.", "labels": [], "entities": []}, {"text": "automated system to understand the underlying semantics of the text.", "labels": [], "entities": []}, {"text": "In the WASSA shared task, keywords describing the emotion label have been removed, making the emotion implicit in the text.", "labels": [], "entities": [{"text": "WASSA shared task", "start_pos": 7, "end_pos": 24, "type": "TASK", "confidence": 0.8698462049166361}]}, {"text": "This makes the task more challenging.", "labels": [], "entities": []}, {"text": "Typically, a system developed for implicit emotion prediction must understand the meaning of the entire text and not just predict using a few keywords.", "labels": [], "entities": [{"text": "implicit emotion prediction", "start_pos": 34, "end_pos": 61, "type": "TASK", "confidence": 0.8044119477272034}]}, {"text": "We propose a model which uses a CNN based architecture) for emotion prediction.", "labels": [], "entities": [{"text": "emotion prediction", "start_pos": 60, "end_pos": 78, "type": "TASK", "confidence": 0.8188031613826752}]}, {"text": "The model stacks CNN blocks on ELMo (Embeddings from Language Model), as introduced by.", "labels": [], "entities": []}, {"text": "Additionally, we include word level Valence, Arousal, and Dominance (VAD) features for guiding our model towards prediction.", "labels": [], "entities": [{"text": "word level Valence, Arousal, and Dominance (VAD)", "start_pos": 25, "end_pos": 73, "type": "METRIC", "confidence": 0.7415882619944486}]}, {"text": "We describe our model in detail in Section 4.", "labels": [], "entities": []}, {"text": "As described in Section 6, our model achieves 66% accuracy on the WASSA task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9995889067649841}, {"text": "WASSA task", "start_pos": 66, "end_pos": 76, "type": "TASK", "confidence": 0.659006804227829}]}, {"text": "We further investigate the generalizability of our model by experimenting on the Cornell movie dataset as shown in Section 7.", "labels": [], "entities": [{"text": "Cornell movie dataset", "start_pos": 81, "end_pos": 102, "type": "DATASET", "confidence": 0.9761346379915873}]}], "datasetContent": [{"text": "In this section, we describe the procedure for training classifiers as part of the Ensemble Classifier.", "labels": [], "entities": []}, {"text": "The parameters were tuned based on both validation loss and accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9956507086753845}]}, {"text": "For our experiments, we used the Cornell Movie Corpus built by Danescu-Niculescu-Mizil and Lee (2011), which is composed of around 300,000 utterances extracted from 600 movies.", "labels": [], "entities": [{"text": "Cornell Movie Corpus built", "start_pos": 33, "end_pos": 59, "type": "DATASET", "confidence": 0.971706435084343}]}, {"text": "A group of internal annotators manually annotated a subset of 58,000 lines, with at most 2 of 7 emotion labels (fear, surprise, anger, disgust, joy, sad, neutral", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Label distribution of the provided corpus.", "labels": [], "entities": []}, {"text": " Table 2: Validation accuracy for each classifier (note:  high accuracy scores for binary classifiers come from  unbalanced classes).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9707068800926208}, {"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9874279499053955}]}, {"text": " Table 3: F1 Score on test set.", "labels": [], "entities": [{"text": "F1 Score", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9745955169200897}]}]}