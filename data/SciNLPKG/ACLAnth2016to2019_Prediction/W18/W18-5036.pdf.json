{"title": [{"text": "Toward Zero-shot Entity Recognition in Task-oriented Conversational Agents", "labels": [], "entities": [{"text": "Zero-shot Entity Recognition", "start_pos": 7, "end_pos": 35, "type": "TASK", "confidence": 0.6750776271025339}]}], "abstractContent": [{"text": "We present a domain portable zero-shot learning approach for entity recognition in task-oriented conversational agents, which does not assume any annotated sentences at training time.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.7398620843887329}]}, {"text": "Rather, we derive a neu-ral model of the entity names based only on available gazetteers, and then apply the model to recognize new entities in the context of user utterances.", "labels": [], "entities": []}, {"text": "In order to evaluate our working hypothesis we focus on nominal entities that are largely used in e-commerce to name products.", "labels": [], "entities": []}, {"text": "Through a set of experiments in two languages (En-glish and Italian) and three different domains (furniture, food, clothing), we show that the neural gazetteer-based approach outperforms several competitive baselines, with minimal requirements of linguistic features.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper we focus on user utterance understanding, where a conversational system has to interpret the content of a user dialogue turn.", "labels": [], "entities": [{"text": "user utterance understanding", "start_pos": 26, "end_pos": 54, "type": "TASK", "confidence": 0.8850307464599609}]}, {"text": "At this step, most of conversational systems try to capture both the intent of the utterance and the relevant entities and relations that are mentioned.", "labels": [], "entities": []}, {"text": "As an example, given a user query like: Can I find a Canada Goose parka blue for -30?, an online shop assistant should be able to recognize that the intent of the utterance is 'Search' and that the following entities are mentioned: Product Category = parka; Brand = Canada Goose; Color = blue; Min temperature = -30.", "labels": [], "entities": [{"text": "Canada Goose parka blue", "start_pos": 53, "end_pos": 76, "type": "DATASET", "confidence": 0.9010023027658463}, {"text": "Canada Goose", "start_pos": 266, "end_pos": 278, "type": "DATASET", "confidence": 0.9196027219295502}, {"text": "Min temperature", "start_pos": 294, "end_pos": 309, "type": "METRIC", "confidence": 0.9799061119556427}]}, {"text": "Finally, we are interested in domains where available repositories can only cover a portion of the possible entity names that a user can express in an interaction.", "labels": [], "entities": []}, {"text": "Our working hypothesis is that, in such scenarios, current entity recognition approaches based on supervision (i.e. we call them pattern-based as they need utterances annotated with entities in the context they occur), need a huge amount of supervision to manage the variety of entity names, which would make those approaches ineffective inmost practical situations.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.7243462353944778}]}, {"text": "Thus, we propose an entity recognition method, we call it gazetteerbased, which takes advantage of available entity names fora certain category to train a neural model that is then applied to label new unseen entities in a user utterance.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 20, "end_pos": 38, "type": "TASK", "confidence": 0.7233074009418488}]}, {"text": "This method shares several features with recent proposals in zero-shot learning (), as we do not assume any annotated utterances at training time, and we make use of entity names as \"side information\".", "labels": [], "entities": []}, {"text": "We run several experiments on three ecommerce domains (furniture, food, clothing) and two languages (English and Italian), with different characteristics in terms of entity names, and show that: (i) the gazetteer-based approach significantly outperforms the pattern-based approach in our domains and languages; (ii) the method captures linguistic properties of the entity names related to their compositionality, which are reliable indicators of the complexity of the task.", "labels": [], "entities": []}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 introduces the entity recognition task we are addressing.", "labels": [], "entities": [{"text": "entity recognition task", "start_pos": 25, "end_pos": 48, "type": "TASK", "confidence": 0.8496731917063395}]}, {"text": "Section 3 provides background and relevant related work.", "labels": [], "entities": []}, {"text": "Section 4 describes the gazetteer-based methodology that we adopt for entity recognition in user utterances.", "labels": [], "entities": [{"text": "entity recognition in user utterances", "start_pos": 70, "end_pos": 107, "type": "TASK", "confidence": 0.7952071905136109}]}, {"text": "Finally, section 5 and 6 describe, respectively, the experimental setting and the obtained results.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we first introduce two alternative approaches for entity recognition that we used as Algorithm 2 Rule-based entity recognition 1: G : tokens in Gazetteer -excluding stopwords.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.7672566473484039}, {"text": "Algorithm 2 Rule-based entity recognition", "start_pos": 101, "end_pos": 142, "type": "TASK", "confidence": 0.4626901388168335}]}, {"text": "morpho : morphological variations of token.", "labels": [], "entities": []}, {"text": "3: P OS : possible PoS tags for the token.", "labels": [], "entities": []}, {"text": "bigram : All bi-grams in Gazetteer.", "labels": [], "entities": []}, {"text": "We experimented entity recognition in three ecommerce domains and two languages fora total of six configurations.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.8303976356983185}]}, {"text": "The three domains are respectively: food, clothing and furniture.", "labels": [], "entities": []}, {"text": "Languages are Italian and English.", "labels": [], "entities": []}, {"text": "In order to run our experiments the following datasets were used.", "labels": [], "entities": []}, {"text": "Entity gazetteers (positive examples for NN g ).", "labels": [], "entities": []}, {"text": "We collected a gazetteer of nominal entities for each domain-language pair.", "labels": [], "entities": []}, {"text": "To allow for consistent comparisons across languages and domains we scraped just one website per domain and extracted the English/Italian gazetteers versions.", "labels": [], "entities": []}, {"text": "In we describe each gazetteer, reporting its size in terms of number of entity names, the average length of the names (in number of tokens), plus the length variability of such names (standard deviation, SD).", "labels": [], "entities": [{"text": "SD", "start_pos": 204, "end_pos": 206, "type": "METRIC", "confidence": 0.8763571381568909}]}, {"text": "With these measures we are able to partially quantify how difficult it is to recognize the length of an entity, how difficult is to individuate the boundaries of an entity (ratio of type 1 and type 2 tokens), how much compositionality there is starting from basic entities (i.e. how many new entities can be potentially constructed by adding new tokens).", "labels": [], "entities": []}, {"text": "Note that type 1 and type 2 ratios can cover cases in common with sub-entity ratio, but they model different phenomena: given white tshirt, the entity name black and white skirt represents a case of type 1 token for white but without sub-entity matching, while white t-shirt with long sleeves represents a sub-entity matching without making white a type 1 token.", "labels": [], "entities": []}, {"text": "Synthetic Gazetteers (positive + negative examples for NN g ) (SG).", "labels": [], "entities": []}, {"text": "To train NN g , we apply the methodology described in Section 4.1 to obtain synthetic negative data.", "labels": [], "entities": []}, {"text": "After splitting each gazetteer using a 64:16:20 ratio (train:dev:test), we created the aforementioned data sets, where -for each entity i (positive example) present in the train-dev splits -we added two negative examples obtained by randomly selecting one of the methodologies described in Section 4.1.", "labels": [], "entities": []}, {"text": "The optimal number of negative examples was obtained during the training phase by varying their ratio.", "labels": [], "entities": []}, {"text": "Synthetic Utterances (training for NN p , test data for all approaches) (SU).", "labels": [], "entities": []}, {"text": "To test our approaches we used synthetic sentences produced by lexicalizing templates, following the idea presented in).", "labels": [], "entities": []}, {"text": "These recent approaches show the feasibility of using synthetic sentences both for training and test.", "labels": [], "entities": []}, {"text": "More generally, there's a growing interest in using synthetic data for conversational agents, e.g. the bAbI datasets -meant to de-Gazetteer #entities #tokens length \u00b1 SD TTR type 1 (%) type 2 (%) sub-entity   velop learning algorithms for text understanding and reasoning -were all constructed in a synthetic way).", "labels": [], "entities": [{"text": "bAbI datasets", "start_pos": 103, "end_pos": 116, "type": "DATASET", "confidence": 0.789324164390564}, {"text": "text understanding and reasoning", "start_pos": 239, "end_pos": 271, "type": "TASK", "confidence": 0.7692759931087494}]}, {"text": "We created 237 templates for English and the same amount for Italian.", "labels": [], "entities": []}, {"text": "These templates were manually designed in order to be domain independent (e.g. using terminology that can be applied to any domain), and correspond to typical intents that can be found in the e-commerce scenario (e.g. buy, add to list, rate item, etc.) and were evenly distributed in order to contain 1 to 3 entity names.", "labels": [], "entities": []}, {"text": "A few examples are given in.", "labels": [], "entities": []}, {"text": "We split the templates in a 64:16:20 ratio (train:dev:test) before lexicalization: to lexicalize SU train we randomly choose entities that were in the train split of the gazetteers, while for SU test we randomly choose entities than were in the test split of the gazetteers.", "labels": [], "entities": []}, {"text": "It should be noted that we used this procedure to better isolate the effect of entity name and their compositional nature over learning approaches, in fact: (i) we controlled for the impact of patterns on learning by using the same patterns across data sets train and test splits.", "labels": [], "entities": []}, {"text": "(ii) we made the task more challenging than in standard situations, since no entity present in the training can be present in the test sets as well.", "labels": [], "entities": []}, {"text": "In this way we can assess the ability of the approaches to learn the structure of entity names and generalize it to NN g features config.", "labels": [], "entities": []}, {"text": "F1  We run two different sets of experiments to explore the impact of compositionality on the task of entity recognition.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 102, "end_pos": 120, "type": "TASK", "confidence": 0.7604458928108215}]}, {"text": "The first set was meant to find the optimal feature configuration for NN g , and the second one was the comparison of the three main approaches over the six SU datasets.", "labels": [], "entities": [{"text": "SU datasets", "start_pos": 157, "end_pos": 168, "type": "DATASET", "confidence": 0.7007509022951126}]}, {"text": "We run a set of experiments to assess the best feature configuration for the gazetteer-based approach.", "labels": [], "entities": []}, {"text": "In we report the overall results of NN g using different feature configurations, over the six SG data sets.", "labels": [], "entities": [{"text": "SG data sets", "start_pos": 94, "end_pos": 106, "type": "DATASET", "confidence": 0.7885673542817434}]}, {"text": "The topological configuration of NN g is kept constant, as described in Section 4.", "labels": [], "entities": []}, {"text": "As can be seen, the configuration using all features is the best one (F1 89.95), and also the one with the lowest standard deviation (4.05).", "labels": [], "entities": [{"text": "F1 89.95", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9462769329547882}, {"text": "standard deviation", "start_pos": 114, "end_pos": 132, "type": "METRIC", "confidence": 0.943882554769516}]}, {"text": "This means not only that this configuration provides the best results on average but also the most consistent ones across all data sets.", "labels": [], "entities": []}, {"text": "Interestingly, the configuration that uses no external linguistic knowledge (Gazetteer-info)  is the second best, indicating that even in the worst case, in which no linguistic resource is available, we can still expect to obtain competitive results.", "labels": [], "entities": []}, {"text": "2. Experiments and Comparison on SU.", "labels": [], "entities": [{"text": "SU", "start_pos": 33, "end_pos": 35, "type": "TASK", "confidence": 0.8837336301803589}]}, {"text": "Table 5 reports the comparison among the rule-based baseline, the NN p baseline, and the NN g approach.", "labels": [], "entities": []}, {"text": "NN g is the best approach on all domains and languages.", "labels": [], "entities": []}, {"text": "This confirms our initial hypothesis that the structure of entity names induced by gazetteers is fundamental when having little knowledge of the context in which entities occur within utterances (i.e. having few training examples).", "labels": [], "entities": []}, {"text": "It should be noted that the effect of entity name complexity (reported in) emerges clearly from the experiments: all the approaches tend to be affected by it.", "labels": [], "entities": []}, {"text": "In both languages we have the following order in term of performances food < furniture < clothing.", "labels": [], "entities": []}, {"text": "While for food results are evident (the highest length-SD, TTR, type 1 and type 2 token ratios and high sub-entity ratio affect the performances even if the gazetteers are big) for furniture and clothing we need to look closer at the metrics in.", "labels": [], "entities": [{"text": "length-SD", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.9757053256034851}, {"text": "TTR", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.9279886484146118}]}, {"text": "Neglecting the possible effects of gazetteer size, we see that clothing tends to have higher ratio of type 1 or type 2 tokens: this is due to the large use of modifiers, such as colour, typical of the domain (depending on language the modifier is attached before or after the head white t-shirt vs maglietta bianca).", "labels": [], "entities": []}, {"text": "Still, being the other token type almost 0, either the beginning or the end of an entity name is unambiguous, and in case of adjacent entities in a sentence this is enough to recognize the boundaries between the two.", "labels": [], "entities": []}, {"text": "The NN g version that uses only gazetteer features (i.e. no linguistic knowledge is assumed), even if not reported in, showed to perform more poorly than the version using all features.", "labels": [], "entities": []}, {"text": "Still, it is competitive against NN p , outperforming it in five SU data sets out of six, and providing an average F1 improvement of 10 points.", "labels": [], "entities": [{"text": "SU data sets", "start_pos": 65, "end_pos": 77, "type": "DATASET", "confidence": 0.8056062161922455}, {"text": "F1", "start_pos": 115, "end_pos": 117, "type": "METRIC", "confidence": 0.999718964099884}]}, {"text": "Finally, in we report the results of an additional analysis, where we computed the F1 scores according to the number of entities present in the test sentences (all domain and languages).", "labels": [], "entities": [{"text": "F1", "start_pos": 83, "end_pos": 85, "type": "METRIC", "confidence": 0.9988730549812317}]}, {"text": "As can be seen, NN g is the least sensitive to the number of entities present in the test sentences (i.e. NN g is the most consistent in term of performance under all circumstances).", "labels": [], "entities": []}, {"text": "This can be explained by the fact that NN g , being focused on recognizing entities rather than patterns, is less sensitive to cases of contiguous occurrences of entities that can be wrongly segmented by other approaches.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Gazetteers used in the experiments. Description in terms of number of entity names, total  number of tokens, average length and standard deviation (SD) of entities, type-token ratio (TTR, norm  obtained by repeated sampling of 200 tokens), type 1 and type 2 unique tokens ratio and sub-entity ratio.", "labels": [], "entities": [{"text": "average length and standard deviation (SD)", "start_pos": 119, "end_pos": 161, "type": "METRIC", "confidence": 0.8227062597870827}]}, {"text": " Table 4: Average F1 and standard deviation for  various features configurations of NN g over the six  SG data sets (three domains and two languages).", "labels": [], "entities": [{"text": "F1", "start_pos": 18, "end_pos": 20, "type": "METRIC", "confidence": 0.9807049632072449}, {"text": "standard deviation", "start_pos": 25, "end_pos": 43, "type": "METRIC", "confidence": 0.9410379230976105}, {"text": "SG data sets", "start_pos": 103, "end_pos": 115, "type": "DATASET", "confidence": 0.8185859123865763}]}, {"text": " Table 5: Experimental results (F1) over the six domain-language data sets.", "labels": [], "entities": [{"text": "F1", "start_pos": 32, "end_pos": 34, "type": "METRIC", "confidence": 0.9976849555969238}]}, {"text": " Table 6: Results (F1) of the three approaches  according to the number of entities in the SU  datasets.", "labels": [], "entities": [{"text": "F1", "start_pos": 19, "end_pos": 21, "type": "METRIC", "confidence": 0.9953736662864685}, {"text": "SU  datasets", "start_pos": 91, "end_pos": 103, "type": "DATASET", "confidence": 0.7880986332893372}]}]}