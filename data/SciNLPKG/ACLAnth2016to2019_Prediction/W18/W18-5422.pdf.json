{"title": [{"text": "Learning and Evaluating Sparse Interpretable Sentence Embeddings", "labels": [], "entities": []}], "abstractContent": [{"text": "Previous research on word embeddings has shown that sparse representations, which can be either learned on top of existing dense embeddings or obtained through model constraints during training time, have the benefit of increased interpretability properties: to some degree, each dimension can be understood by a human and associated with a recognizable feature in the data.", "labels": [], "entities": []}, {"text": "In this paper, we transfer this idea to sentence embeddings and explore several approaches to obtain a sparse representation.", "labels": [], "entities": []}, {"text": "We further introduce a novel, quantitative and automated evaluation metric for sentence embedding interpretability, based on topic coherence methods.", "labels": [], "entities": [{"text": "sentence embedding interpretability", "start_pos": 79, "end_pos": 114, "type": "TASK", "confidence": 0.6877451042334238}]}, {"text": "We observe an increase in interpretability compared to dense models, on a dataset of movie dialogs and on the scene descriptions from the MS COCO dataset.", "labels": [], "entities": [{"text": "MS COCO dataset", "start_pos": 138, "end_pos": 153, "type": "DATASET", "confidence": 0.9268349210421244}]}], "introductionContent": [{"text": "In the word embeddings literature, it has previously been of interest to find interpretable representations: individual dimensions should capture a distinct semantic meaning, such that humans are able to understand why a word is encoded in a particular vector.", "labels": [], "entities": []}, {"text": "With a cognitive plausibility argument from, the interpretability can be linked to sparse representations: they argue that the representation should model a wide range of features in the data and that every sample should be characterized by the presence of a small number of key features.", "labels": [], "entities": []}, {"text": "use this idea to recover and disentangle the different meanings of polysemous words.", "labels": [], "entities": []}, {"text": "The above-named approaches, as well as those by;, recover an interpretable sparse representation in a separate, post-processing step on top of * Work done during an internship at ETH Z\u00fcrich.", "labels": [], "entities": []}, {"text": "the uninterpretable, dense embeddings of the original model (often word2vec or GloVe).", "labels": [], "entities": []}, {"text": "This is commonly done using sparse coding or a downstream model.", "labels": [], "entities": []}, {"text": "Additionally to understanding a model's intermediate representation, there has been work on constructing models that inherently use a sparse embedded representation by learning it during the training process ().", "labels": [], "entities": []}, {"text": "This is motivated by the idea that the model should include the prior that each word is a sparse combination of disentangled features from the very beginning.", "labels": [], "entities": []}, {"text": "In contrast, when computing dense embeddings first, it is less likely that this representation will be easily disentanglable in the post-processing step.", "labels": [], "entities": []}, {"text": "Goh argues that sparse representations can be used to explain image and sentence embeddings as well.", "labels": [], "entities": []}, {"text": "To be precise, the author focuses on encoder-decoder neural networks and uses sparse coding to recover interpretable features in the latent spaces of a variational autoencoder ( and an image captioning system based on (.", "labels": [], "entities": []}, {"text": "In this paper, we aim to use sparse methods to disentangle sentence embeddings' dimensions.", "labels": [], "entities": []}, {"text": "We focus on a simple sentence autoencoder model, and apply both a sparse-coding-based postprocessing technique, as well as model constraints during training time, to obtain sparse vector representations of sentences.", "labels": [], "entities": []}, {"text": "We aim to increase the understanding of the latent space, which helps us gain insight into how the inference and learning process works by identifying the patterns in the data that the model learns to recognize and encode in this representation.", "labels": [], "entities": []}, {"text": "To compare our different approaches, as well as measure the improvement compared to the baseline of a dense autoencoder model, we introduce a novel, quantitative and automated metric of the mentioned interpretability properties.", "labels": [], "entities": []}, {"text": "It is based on the notion of topic coherence and further develops it for the case of sentences.", "labels": [], "entities": []}, {"text": "We observe that the new measure reflects our manual judgment on the interpretability of the embeddings.", "labels": [], "entities": []}, {"text": "Additionally, we track reconstruction quality and performance in downstream tasks, showing that sparse approaches can obtain a remarkable increase in interpretability at a moderate cost in quality.", "labels": [], "entities": [{"text": "interpretability", "start_pos": 150, "end_pos": 166, "type": "TASK", "confidence": 0.9614241123199463}]}], "datasetContent": [{"text": "The most common quantitative interpretability measure for embeddings (in particular word embeddings) is the intrusion test, first introduced in (.", "labels": [], "entities": []}, {"text": "This test involves generating 5-tuples of samples, where according to the embeddings model four are related and one stands out.", "labels": [], "entities": []}, {"text": "The better human judges identify the intruder, the more interpretable the model is considered.", "labels": [], "entities": []}, {"text": "This evaluation method has the drawback of requiring human attention, thereby it is expensive and slow to evaluate.", "labels": [], "entities": []}, {"text": "For our evaluation, we introduce an automated interpretability test, based on topic coherence, that does not require human attention.", "labels": [], "entities": []}, {"text": "We describe our method in this section.", "labels": [], "entities": []}, {"text": "A topic model defines a set of topics in a corpus of documents and allows us to find the top n most likely words that belong to each topic.", "labels": [], "entities": []}, {"text": "Topic coherence is an automated evaluation method of the interpretability of topic models, which has been shown to correlate well with human assessments).", "labels": [], "entities": []}, {"text": "The total topic coherence of the model is the mean coherence overall topics.", "labels": [], "entities": []}, {"text": "We devise an evaluation scheme based on topic coherence.", "labels": [], "entities": []}, {"text": "Instead of looking at words in topics, we consider the highest-ranked sentences in the dimensions of our embeddings and replace the word similarity measure with a sentence similarity measure.", "labels": [], "entities": [{"text": "word similarity measure", "start_pos": 132, "end_pos": 155, "type": "METRIC", "confidence": 0.7149423062801361}]}, {"text": "Let x (p) d be the sample that has rank pin the order given by the d-th dimension in the embedding.", "labels": [], "entities": []}, {"text": "For a similarity measure sim * , the coherence of a single dimension dis defined as: The coherence of the model is defined as the mean coherence overall dimensions: In addition, to determine how much the coherence deteriorates when looking beyond the top ranks, we consider all non-zero samples of a dimension and we evaluate Equation 3 on n sentences sampled at random and without replacement from d . We compute this on the validation set of our data.", "labels": [], "entities": []}, {"text": "We strip all stop words from all sentences.", "labels": [], "entities": []}, {"text": "We consider n = 10 sentences per dimension, unless a dimension has a non-zero value for less than n samples, in which case we compute Equation 3 on all pairs of sentences.", "labels": [], "entities": [{"text": "Equation 3", "start_pos": 134, "end_pos": 144, "type": "METRIC", "confidence": 0.9390676915645599}]}, {"text": "In the following, we define three choices fora sentence similarity measure sim * . Jaccard Similarity.", "labels": [], "entities": []}, {"text": "We regard the sentences as sets of words and compute the Jaccard similarity: BoW Similarity.", "labels": [], "entities": [{"text": "Jaccard similarity: BoW Similarity", "start_pos": 57, "end_pos": 91, "type": "METRIC", "confidence": 0.6849175453186035}]}, {"text": "We consider the Bag-of-Words (BoW) vectors bi , b j of the two sentences, i.e. the vectors with the number of occurrences of each vocabulary word in xi , x j , respectively.", "labels": [], "entities": []}, {"text": "The similarity is defined as the cosine of the angle between these vectors: WMD Similarity.", "labels": [], "entities": [{"text": "similarity", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9523204565048218}]}, {"text": "The Jaccard and BoW similarity measures have a drawback in that they do not take semantic relatedness of different words into account.", "labels": [], "entities": [{"text": "BoW", "start_pos": 16, "end_pos": 19, "type": "DATASET", "confidence": 0.6792216300964355}, {"text": "similarity", "start_pos": 20, "end_pos": 30, "type": "METRIC", "confidence": 0.4571482837200165}]}, {"text": "The Word Mover's Distance (WMD;) remedies this problem: the authors define a document distance measure that relies on the word2vec latent space to make a better assessment of the semantic distance of sentences, based on the distance of the words they consist of.", "labels": [], "entities": []}, {"text": "We use the negative WMD to obtain a similarity measure: 5 Results  In we additionally report the coherence coh WMD (d) of the presented dimensions d (see Equations 3, 7).", "labels": [], "entities": [{"text": "coherence coh WMD (d)", "start_pos": 97, "end_pos": 118, "type": "METRIC", "confidence": 0.8190260132153829}]}, {"text": "We observe that this score correlates with our empirical assessment of the interpretability of the dimension.", "labels": [], "entities": []}, {"text": "For example, we observe on the COCO dataset that, while unrelated groups of sentences usually have a coherence score of < \u22123, sentences with common or semantically related subjects and objects have higher coherence scores (usually between \u22122.8 and \u22122.2).", "labels": [], "entities": [{"text": "COCO dataset", "start_pos": 31, "end_pos": 43, "type": "DATASET", "confidence": 0.9670900702476501}]}, {"text": "Groups of sentences with very close semantic meaning or large common prefixes have coherence scores around \u22122 or higher.", "labels": [], "entities": []}, {"text": "We report the topic coherence of our models (Equation 4) in.", "labels": [], "entities": []}, {"text": "As rough reference values for the metrics, we include the mean similarity of pairs of random sentences from the dataset (estimated on 500 randomly sampled pairs), and the topic coherence of a 500-dimensional dense autoencoder model.", "labels": [], "entities": []}, {"text": "In accordance with our empirical observations, we see an increase in interpretability in the sparse models.", "labels": [], "entities": []}, {"text": "For example, on the COCO Captions data, a random pair of sentences has a WMDbased similarity of -3.12, and the WMD-based coherence score of a dense autoencoder model is -3.", "labels": [], "entities": [{"text": "COCO Captions data", "start_pos": 20, "end_pos": 38, "type": "DATASET", "confidence": 0.8076993624369303}, {"text": "WMDbased similarity", "start_pos": 73, "end_pos": 92, "type": "METRIC", "confidence": 0.7294241786003113}]}, {"text": "With the additional sparse coding step on top of that, we can increase the coherence to -2.86.", "labels": [], "entities": []}], "tableCaptions": []}