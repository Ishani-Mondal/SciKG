{"title": [{"text": "An Empirical Study of Self-Disclosure in Spoken Dialogue Systems", "labels": [], "entities": []}], "abstractContent": [{"text": "Self-disclosure is a key social strategy employed in conversation to build relations and increase conversational depth.", "labels": [], "entities": []}, {"text": "It has been heavily studied in psychology and linguistic literature, particularly for its ability to induce self-disclosure from the recipient, a phenomena known as reciprocity.", "labels": [], "entities": []}, {"text": "However, we know little about how self-disclosure manifests in conversation with automated dialog systems, especially as any self-disclosure on the part of a dialog system is patently disingenu-ous.", "labels": [], "entities": []}, {"text": "In this work, we run a large-scale quantitative analysis on the effect of self-disclosure by analyzing interactions between real-world users and a spoken dialog system in the context of social conversation.", "labels": [], "entities": []}, {"text": "We find that indicators of reciprocity occur even in human-machine dialog , with far-reaching implications for chatbots in a variety of domains including education, negotiation and social dialog.", "labels": [], "entities": []}], "introductionContent": [{"text": "Humans employ different strategies during a conversation in pursuit of their social goals.", "labels": [], "entities": []}, {"text": "The contributions to a conversation can be categorized as those which serve propositional functions by adding new information to the dialog, those which serve interactional functions by driving the interaction and those which serve interpersonal functions, by building up the relationship between the involved parties.", "labels": [], "entities": []}, {"text": "When fulfilling interpersonal functions, people either consciously or sub-consciously employ social conversational strategies in order to connect and build relationships with each other (.", "labels": [], "entities": []}, {"text": "This feeling of  rapport, of connecting and having common ground with another human being is one of the fundamental aspects of good human conversation.", "labels": [], "entities": []}, {"text": "Maintaining conversational harmony has shown to be effective in several domains such as education ( and negotiation.", "labels": [], "entities": [{"text": "Maintaining conversational harmony", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.9288201332092285}, {"text": "negotiation", "start_pos": 104, "end_pos": 115, "type": "TASK", "confidence": 0.9683964252471924}]}, {"text": "Self-disclosure is the conversational act of disclosing information about oneself to others.", "labels": [], "entities": []}, {"text": "We consider the definition of self-disclosure within the theoretical framework of social penetration theory, where it is defined as the voluntary sharing of opinions, thoughts, beliefs, experiences, preferences, values and personal history.", "labels": [], "entities": [{"text": "social penetration theory", "start_pos": 82, "end_pos": 107, "type": "TASK", "confidence": 0.8372047146161398}]}, {"text": "The effect of self-disclosure has been well-studied in the psychology community, in particular it's ability to induce reciprocity in dyadic interaction.", "labels": [], "entities": []}, {"text": "Several studies have shown that selfdisclosure reciprocity characterizes initial social interactions between people () and further, that disclosure promotes disclosure ().", "labels": [], "entities": []}, {"text": "This brings us to a natural question: how does such behavior manifest itself in interactions with dialog systems?", "labels": [], "entities": []}, {"text": "A subtle but crucial aspect is that humans are aware that machines do not have feelings or experiences of their own, so any attempt at self-disclosure on the part of the machine is inherently disingenuous.", "labels": [], "entities": []}, {"text": "However, suggests that humans tend to view computers as social actors, and interact with them in much the same way they do with humans.", "labels": [], "entities": []}, {"text": "Disclosure reciprocity in such a setting would have far-reaching implications for dialog systems which aim to elicit information from the user in order to offer more personalized experiences for example, or to better achieve task completion.", "labels": [], "entities": []}, {"text": "In this work, we study this phenomena by building an open-domain chatbot ( \u00a73) which engages in social conversation with hundreds of Amazon Alexa users.), and gains insights into two aspects of human-machine self-disclosure.", "labels": [], "entities": []}, {"text": "First, self-disclosure by the dialog agent is strongly correlated with instances of self-disclosure by the user indicating disclosure reciprocity in interactions with spoken dialog systems ( \u00a74.1).", "labels": [], "entities": []}, {"text": "Second, initial self-disclosure by the user can characterize user behavior throughout the conversation ( \u00a74.2).", "labels": [], "entities": []}, {"text": "We additionally study the effect of self-disclosure and likability, but find no reliable linear relationship with the amount of self-disclosure in the conversation ( \u00a74.3).", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this work is the first large-scale study of reciprocity and self-disclosure between users in the real world and spoken dialog systems.", "labels": [], "entities": []}], "datasetContent": [{"text": "The data for this study was collected by having users from the real-world interact with our open-domain dialog agent.", "labels": [], "entities": []}, {"text": "The dialog agent was hosted on Amazon Alexa devices as part of the AlexaPrize competition ( and was one of sixteen socialbots that could be invoked by any user within the United States through the command 'Let's chat!'.", "labels": [], "entities": []}, {"text": "The users that interacted with our socialbot were randomly chosen, and did not know which of the sixteen systems they were interacting with.", "labels": [], "entities": []}, {"text": "Users who interacted with our bot over a span of three days (N=1507) were randomly assigned to two groups: one received a bot that self-disclosed at high depth from the beginning of the conversation while the other group interacted with a socialbot that self-disclosed only later about superficial topics like movies and TV shows.", "labels": [], "entities": []}, {"text": "At the end, both socialbots engaged in free-form conversation with the user, where the initiative of the interaction was on the user and both bots were free to self-disclose at any depth.", "labels": [], "entities": []}, {"text": "The users were also free to end the interaction at anytime, and thus had no motivation for continuing the conversation besides their own enter-tainment.", "labels": [], "entities": []}, {"text": "To control the direction of the conversation and bot utterance, we utilize a finite state transducer-based dialog system that chats with the user about movies and TV shows, as well as plays games and supports open-domain conversation (.", "labels": [], "entities": []}, {"text": "State transitions are decided based on sentiment analysis of user utterances, in order to gauge interest in a particular topic.", "labels": [], "entities": [{"text": "State transitions", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7016084045171738}]}, {"text": "Initially the dialog system takes initiative in the conversation and steers the topic of discussion, however later there is a handoff to the user whereby the user can determine the focus of the conversation.", "labels": [], "entities": []}, {"text": "In this way, the socialbot leads the user through the following topics, conditioned on user interest as shown in: Greeting : In this phase, our dialog agent greets the user and asks them about their day.", "labels": [], "entities": []}, {"text": "The bot which performs high self-disclosure initially also responds with information about it's day and a personal anecdote.", "labels": [], "entities": []}, {"text": "TV Shows: The next phase involves chitchat about popular TV shows.", "labels": [], "entities": []}, {"text": "The dialog agent asks the user if they are an enthusiast of a recent popular TV show and moves onto the next phase of the conversation if they aren't.", "labels": [], "entities": []}, {"text": "Movie: In this phase, the dialog agent attempts to engage the user in conversations about movies, asking them if they have seen any of the recent ones.", "labels": [], "entities": []}, {"text": "Word Game: In this phase, the dialog agent requests the user to play a word game.", "labels": [], "entities": []}, {"text": "Participation in the game is completely optional and the user can move onto the next phase by stating that they do not wish to play.", "labels": [], "entities": []}, {"text": "CQA: The last phase supports uninhibited freeform conversation.", "labels": [], "entities": [{"text": "CQA", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8962866067886353}]}, {"text": "The initiative of the exchange is now on the user and conversation is stateless.", "labels": [], "entities": []}, {"text": "The dialog system response is determined by a retrieval model.", "labels": [], "entities": []}, {"text": "For each utterance, the socialbot attempts to retrieve the most relevant response from the Yahoo L6 dataset (yl6, 2017), a dataset containing approximately 4 million questions and The users were then allowed to rate the interaction on a scale of 1-5, based on the question 'Would you interact with this socialbot again?'.", "labels": [], "entities": [{"text": "Yahoo L6 dataset (yl6, 2017)", "start_pos": 91, "end_pos": 119, "type": "DATASET", "confidence": 0.9393000677227974}]}, {"text": "319 users rated the socialbot (Group 1) and 1507 users interacted with our system in total (Group 2).", "labels": [], "entities": []}, {"text": "Following this, to preserve confidentiality of the interaction data, one annotator annotated all turns of conversation from Group 1 for self-disclosure.", "labels": [], "entities": []}, {"text": "Annotator reliability was determined by calculating inter-annotator agreement from three external annotators on a carefully prepared anonymized subset of the data amounting to 62 interactions comprising of over 816 turns.", "labels": [], "entities": []}, {"text": "The Fleiss' kappa from the four annotators was 63.8, indicating substantial agreement.", "labels": [], "entities": []}, {"text": "Atleast two of three annotators agreed on 93.6% of the reference annotations.", "labels": [], "entities": []}, {"text": "The full dataset contains a total of 319 conversations, spanning 10751 conversational turns.", "labels": [], "entities": []}, {"text": "Out of the 5216 human dialog utterances, 13.8% featured some form of self-disclosure.", "labels": [], "entities": []}, {"text": "Since our agent is a spoken dialog system in the real world there is some amount of noise in the dataset caused due to ASR errors.", "labels": [], "entities": [{"text": "ASR", "start_pos": 119, "end_pos": 122, "type": "TASK", "confidence": 0.9293723702430725}]}, {"text": "To estimate this, we randomly sample 100 utterances from the dataset and annotate these utterances for whether they contained an ASR mistake, and if the sentence meaning was still apparent either from context or from the utterance itself.", "labels": [], "entities": [{"text": "ASR mistake", "start_pos": 129, "end_pos": 140, "type": "TASK", "confidence": 0.7791263461112976}]}, {"text": "We find that at least one ASR error occurs in 13% of user utterances, but 46.1% of utterances with ASR mistakes can still be understood.", "labels": [], "entities": [{"text": "ASR", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.9544388651847839}]}, {"text": "Since our dialog agent relies on sentiment-based FST transitions during the initial stages of the conversation, we also analyze the rate of false transitions in the data.", "labels": [], "entities": []}, {"text": "We randomly sample 100 utterances from across choice points of all conversations and find that 11% of them consisted of incorrect responses, either due to mistakes in sentiment analysis or due to nu-3 answers.yahoo.com ance in the user utterances which rendered a response from the dialog agent unusable.", "labels": [], "entities": []}, {"text": "Finally, we analyze how many users had multiple interactions with our dialog agent during the course of our study.", "labels": [], "entities": []}, {"text": "This is relevant as user behavior during a second interaction with the system might differ from initial interaction.", "labels": [], "entities": []}, {"text": "Users are identifiable only by an anonymized hash key provided by Amazon along with the conversation data.", "labels": [], "entities": []}, {"text": "We find that out of 316 users who interacted with our dialog agent and left a rating, only 3 interacted with our agent twice and none of them interacted with our agent more than two times, largely allowing us to disregard this effect.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Classification performance(%) of mod- els at identifying user utterances to contain self- disclosure.", "labels": [], "entities": []}, {"text": " Table 2: Various effects of conversation with a  dialog system that self-discloses right off-the-bat  and with a control dialog system that only self- discloses later. * indicates p<0.05 after Bonfer- roni correction.", "labels": [], "entities": [{"text": "Bonfer- roni correction", "start_pos": 194, "end_pos": 217, "type": "METRIC", "confidence": 0.6956654787063599}]}]}