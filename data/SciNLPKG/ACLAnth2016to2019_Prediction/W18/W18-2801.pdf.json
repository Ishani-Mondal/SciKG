{"title": [{"text": "Predicting Brain Activation with WordNet Embeddings", "labels": [], "entities": [{"text": "Predicting Brain Activation", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8797247409820557}]}], "abstractContent": [{"text": "The task of taking a semantic representation of a noun and predicting the brain activity triggered by it in terms of fMRI spatial patterns was pioneered by Mitchell et al.", "labels": [], "entities": []}, {"text": "That seminal work used word co-occurrence features to represent the meaning of the nouns.", "labels": [], "entities": []}, {"text": "Even though the task does not impose any specific type of semantic representation, the vast majority of subsequent approaches resort to feature-based models or to semantic spaces (aka word embeddings).", "labels": [], "entities": []}, {"text": "We address this task, with competitive results, by using instead a semantic network to encode lexical semantics , thus providing further evidence for the cognitive plausibility of this approach to model lexical meaning.", "labels": [], "entities": []}], "introductionContent": [{"text": "Neurosemantics studies the mapping between concepts and the corresponding brain activity, bringing together neuroscientists doing brain imaging research and linguists doing research on the semantics of natural language expressions.", "labels": [], "entities": []}, {"text": "The task introduced by consists of taking a semantic representation of a noun and predicting the functional magnetic resonance imaging (fMRI) spatial activation patterns in the brain triggered by that noun.", "labels": [], "entities": []}, {"text": "That is, given a meaning representation of a word, it should be the basis to predict the activation strength at each point (voxel) in the 3D volume of the brain associated to the cognitive handling of that word.", "labels": [], "entities": []}, {"text": "This allows to make testable predictions of fMRI activity, even for nouns for which there is no fMRI data available, as long as there is someway to model and represent the semantics of a lexicon.", "labels": [], "entities": []}, {"text": "In lexical semantics, three broad families of approaches have emerged to model meaning, namely (i) semantic networks, (ii) feature-based models, and (iii) semantic spaces.", "labels": [], "entities": []}, {"text": "The models of the lexicon produced under these approaches have been embedded in wider models of the whole grammar or in language technology applications and tasks, including synonym identification, analogies detection a.o., were they have been tested on behavioral data sets.", "labels": [], "entities": [{"text": "synonym identification", "start_pos": 174, "end_pos": 196, "type": "TASK", "confidence": 0.9410345256328583}, {"text": "analogies detection", "start_pos": 198, "end_pos": 217, "type": "TASK", "confidence": 0.721980556845665}]}, {"text": "The prediction of brain activation considered here is agnostic regarding the approach used to model lexical meaning, thus providing another way of assessing the cognitive plausibility of lexical semantic representations of different sorts.", "labels": [], "entities": []}, {"text": "While most approaches to this task have resorted to feature-based models or to semantic spaces (aka word embeddings), here we address the task of prediciting the brain activation triggred by nouns rather by using a semantic network, thus providing further evidence for the cognitive plausibility of this approach to model lexical meaning.", "labels": [], "entities": []}, {"text": "In this paper, we report on the competitive results of resolving the brain activation task by taking a mainstream lexical semantics network, WordNet, and resorting to intermediate word embeddings obatined with a novel methodology () for generating semantic spaces from semantic networks.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 141, "end_pos": 148, "type": "DATASET", "confidence": 0.9564259052276611}]}], "datasetContent": [{"text": "The good results obtained with wnet2vec in the semantic similarity task lead to experiment with them also in the brain activation prediction task.", "labels": [], "entities": [{"text": "semantic similarity task", "start_pos": 47, "end_pos": 71, "type": "TASK", "confidence": 0.7946646412213644}, {"text": "brain activation prediction task", "start_pos": 113, "end_pos": 145, "type": "TASK", "confidence": 0.7360853850841522}]}, {"text": "We followed the usual evaluation procedure for this framework.", "labels": [], "entities": []}, {"text": "The cross-validated, leave-twoout mean accuracy was 0.71.", "labels": [], "entities": [{"text": "leave-twoout mean", "start_pos": 21, "end_pos": 38, "type": "METRIC", "confidence": 0.770628035068512}, {"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.5459165573120117}]}, {"text": "The full scores, together with the scores from the original paper, are summarized in and shown graphically in (0.50 corresponds to chance).", "labels": [], "entities": [{"text": "chance", "start_pos": 131, "end_pos": 137, "type": "METRIC", "confidence": 0.9753754138946533}]}, {"text": "When comparing the scores per participant, the bulk of the wnet2vec losses are due to P5, P6 and P8.", "labels": [], "entities": []}, {"text": "For the other subjects, results are close or, in three cases, even better than those from the seminal paper.", "labels": [], "entities": []}, {"text": "This highlights the point already made in (, that different methods have different error patterns, which suggests that an ensemble of classifiers could lead to better overall accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 175, "end_pos": 183, "type": "METRIC", "confidence": 0.995080828666687}]}, {"text": "And also, that a dataset with only 9 subjects -the dataset used in the literature on this task since () -may be hindering better empirically grounded conclusions.", "labels": [], "entities": []}, {"text": "Finally, it should be noted that these competitive results were obtained with wnet2vec generated on the basis of 60k words only, thus less than half of WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 152, "end_pos": 159, "type": "DATASET", "confidence": 0.9822230339050293}]}, {"text": "It will be very interesting to see how the performance of this approach progresses when larger portions of WordNet are taken into account as computational limitations can be overcome.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 107, "end_pos": 114, "type": "DATASET", "confidence": 0.9351311326026917}]}], "tableCaptions": [{"text": " Table 1: Accuracy results for the 9 subjects", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9994900226593018}]}]}