{"title": [{"text": "GBD-NER at PARSEME Shared Task 2018: Multiword Expression Detection Using Bidirectional Long-Short-Term Memory Networks and Graph-Based Decoding", "labels": [], "entities": [{"text": "PARSEME Shared Task", "start_pos": 11, "end_pos": 30, "type": "DATASET", "confidence": 0.7030356923739115}, {"text": "Multiword Expression Detection", "start_pos": 37, "end_pos": 67, "type": "TASK", "confidence": 0.9010598063468933}]}], "abstractContent": [{"text": "This paper addresses the issue of multiword expression (MWE) detection by employing anew decoding strategy inspired after graph-based parsing.", "labels": [], "entities": [{"text": "multiword expression (MWE) detection", "start_pos": 34, "end_pos": 70, "type": "TASK", "confidence": 0.7635885775089264}]}, {"text": "We show that this architecture achieves state-of-the-art results with minimum feature-engineering, just by relying on lexicalized and morphological attributes.", "labels": [], "entities": []}, {"text": "We validate our approach in a multilingual setting, using standard MWE corpora supplied in the PARSEME Shared Task.", "labels": [], "entities": [{"text": "PARSEME Shared Task", "start_pos": 95, "end_pos": 114, "type": "DATASET", "confidence": 0.8242401679356893}]}], "introductionContent": [{"text": "Multiword expression (MWE) detection is a challenging Natural Language Processing (NLP) task that consists in finding isolated tokens or sequences of tokens that form high-level structures (i.e. multiword expressions).", "labels": [], "entities": [{"text": "Multiword expression (MWE) detection", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.8284412026405334}]}, {"text": "Naively, this can be regarded as a sequence labeling task, which in fact influenced legacy methods for MWE detection to use this strategy.", "labels": [], "entities": [{"text": "sequence labeling task", "start_pos": 35, "end_pos": 57, "type": "TASK", "confidence": 0.7546392480532328}, {"text": "MWE detection", "start_pos": 103, "end_pos": 116, "type": "TASK", "confidence": 0.9944795966148376}]}, {"text": "In fact, this is not far fetched, since this approach has yielded highly accurate results so far.", "labels": [], "entities": []}, {"text": "However, we have to point a couple of task-specific details: \u2022 Sparsity: Inside an utterance there are only a couple of tokens that must be labeled as named entities or multiword expressions.", "labels": [], "entities": [{"text": "Sparsity", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9384893178939819}]}, {"text": "This actually yields data sparsity and could bias the model towards not identifying any of the tokens as part of a multiword expression; \u2022 Overlapping: MWE corpora contains many examples where high-level entities share tokens among each other.", "labels": [], "entities": []}, {"text": "There are several ways in which this issue can be mitigated, for instance training several different classifiers for each type of label; \u2022 Long spans: It is often the case that MWE tokens are distantly distributed across a single utterance.", "labels": [], "entities": []}, {"text": "Classical classifiers and even modern LSTM-based approaches are unable to detect such long range dependencies (though the later mentioned approach should), mainly because these cases are rare inside the training data and there is insufficient statistical evidence to support them.", "labels": [], "entities": []}, {"text": "In what follows, we propose anew methodology for learning dependencies within MWE tokens which mitigates the impact of the previously mentioned issues.", "labels": [], "entities": []}, {"text": "Particularly, we use Bidirectional Long-ShortTerm Memory (BDLSTM) (Graves and others, 2012) networks, but we do not employ a naive tagging approach as it is done in similar related work (see section 2).", "labels": [], "entities": []}, {"text": "Instead, we use a strategy inspired by the graph-based parser of, with the following major differences: (a) the network is trained to produce fully connected subgraphs (not parsing trees); (b) we use a different graph-decoding strategy that is tailored for MWEs; (c) our feature-set is composed of morphological and lexicalized features and we apply a two-tier dropout methodology (explained in Section 3) in order to increase the generalization capability of our models.", "labels": [], "entities": []}, {"text": "The proposed methodology was evaluated during the PARSEME Shared Task on Verbal Multiword Expression Detection () and the full evaluation details for all languages are available in our blog 1 .", "labels": [], "entities": [{"text": "PARSEME Shared Task on Verbal Multiword Expression Detection", "start_pos": 50, "end_pos": 110, "type": "TASK", "confidence": 0.5942177958786488}]}], "datasetContent": [{"text": "We validated our approach using the multilingual corpora provided by the PARSEME corpus.", "labels": [], "entities": [{"text": "PARSEME corpus", "start_pos": 73, "end_pos": 87, "type": "DATASET", "confidence": 0.9416792690753937}]}, {"text": "The data covers 19 languages and comes in CUPT format.", "labels": [], "entities": []}, {"text": "The CUPT format is similar to CONLLU, but adds anew annotation layer for VMWE expressions.", "labels": [], "entities": []}, {"text": "For each entry inside a sentence contains the word, it's lemma, UPOS, XPOS and ATTRs, which are automatically labeled using UDPipe (.", "labels": [], "entities": [{"text": "UPOS", "start_pos": 64, "end_pos": 68, "type": "METRIC", "confidence": 0.8711036443710327}, {"text": "XPOS", "start_pos": 70, "end_pos": 74, "type": "METRIC", "confidence": 0.9781842827796936}, {"text": "ATTRs", "start_pos": 79, "end_pos": 84, "type": "METRIC", "confidence": 0.9894511103630066}]}, {"text": "The \"AVG\" entry refers to the macro-average computed overall languages.", "labels": [], "entities": []}, {"text": "This means that the precision and recall are computed for all languages and then F-score is recalculated using the standard equation.", "labels": [], "entities": [{"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9996576309204102}, {"text": "recall", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.9995319843292236}, {"text": "F-score", "start_pos": 81, "end_pos": 88, "type": "METRIC", "confidence": 0.9979597330093384}]}, {"text": "For every language, as well as for the overall result, we include the absolute ranking ('#') of our system based on the results from the official runs.", "labels": [], "entities": []}, {"text": "our software was affected by a bug that caused it to ignore any lexical information in the CUPT files.", "labels": [], "entities": [{"text": "CUPT files", "start_pos": 91, "end_pos": 101, "type": "DATASET", "confidence": 0.9347236454486847}]}, {"text": "The results shown in the table refer to the corrected version of our system and we do provide full access to the source-code 3 for anyone interested.", "labels": [], "entities": []}, {"text": "As shown, this methodology achieves overall higher results, but it does not always produce state-ofthe-art results for certain languages.", "labels": [], "entities": []}, {"text": "The lower scores for languages such as EN, HE and LT can be explained by the fact that those languages were only provided with small training sets and no development data.", "labels": [], "entities": []}, {"text": "It is somewhat expected that deep learning methods require a critical mass of input data in order to provide good generalization.", "labels": [], "entities": []}, {"text": "Also, the proportion of MWEs that were previously unseen in the training data for EN is 92%, 37% for HE and 94% for LT.", "labels": [], "entities": [{"text": "EN", "start_pos": 82, "end_pos": 84, "type": "DATASET", "confidence": 0.7687406539916992}]}, {"text": "Without using external data such as word embeddings our intuition is that it is hard to learn patterns that have to do with \"word semantics\" (the case of MWEs) with so few training examples.", "labels": [], "entities": []}, {"text": "Also, we have to mention that some training sets contained \"single token\" multiword expressions, which, as the name suggests, means that a multiword expression contained only one token.", "labels": [], "entities": []}, {"text": "Our algorithm was originally designed to work by detecting dependencies between each pair of tokens inside a MWE, which is not the case here because the MWEs only contain one word.", "labels": [], "entities": []}, {"text": "In order to do this, we adapted our algorithm by introducing a virtual \"ROOT\" in every sentence.", "labels": [], "entities": [{"text": "ROOT", "start_pos": 72, "end_pos": 76, "type": "METRIC", "confidence": 0.9859219193458557}]}, {"text": "During training we modified the system to output links between all MWE tokens and the ROOT.", "labels": [], "entities": [{"text": "ROOT", "start_pos": 86, "end_pos": 90, "type": "DATASET", "confidence": 0.7282536625862122}]}, {"text": "This solved the issue with single-token MWEs, but biased the model for multiword tokens.", "labels": [], "entities": []}, {"text": "For instance, the single token MWE proportion for HU is 74%, and our f-score on this type of expressions is 84.17% using this tweak.", "labels": [], "entities": [{"text": "HU", "start_pos": 50, "end_pos": 52, "type": "DATASET", "confidence": 0.8091773390769958}]}, {"text": "However, if we compare the new f-score for multiword MWEs we get an absolute drop of 7%.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results obtained on the PARSEME VMWE identification Shared Task", "labels": [], "entities": [{"text": "PARSEME VMWE identification Shared Task", "start_pos": 34, "end_pos": 73, "type": "DATASET", "confidence": 0.7783516049385071}]}]}