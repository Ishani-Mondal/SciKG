{"title": [{"text": "Paths for Uncertainty: Exploring the Intricacies of Uncertainty Identification for News", "labels": [], "entities": []}], "abstractContent": [{"text": "Currently, news articles are produced, shared and consumed at an extremely rapid rate.", "labels": [], "entities": []}, {"text": "Although their quantity is increasing, at the same time, their quality and trustworthiness is becoming fuzzier.", "labels": [], "entities": []}, {"text": "Hence, it is important not only to automate information extraction but also to quantify the certainty of this information.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 44, "end_pos": 66, "type": "TASK", "confidence": 0.7632153630256653}, {"text": "certainty", "start_pos": 92, "end_pos": 101, "type": "METRIC", "confidence": 0.9914965629577637}]}, {"text": "Automated identification of expressions that affect certainty has been studied both in the scientific and newswire domains, but performance is considerably higher in tasks fo-cusing on scientific text.", "labels": [], "entities": [{"text": "Automated identification of expressions that affect certainty", "start_pos": 0, "end_pos": 61, "type": "TASK", "confidence": 0.7926681169441768}]}, {"text": "We compare the differences in the definition and expression of uncertainty between a scientific domain, i.e., biomedicine, and newswire.", "labels": [], "entities": []}, {"text": "We delve into the different aspects that affect the certainty of an extracted event in a news article and examine whether they can be easily identified by techniques already validated in the biomedical domain.", "labels": [], "entities": [{"text": "certainty", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.9495519995689392}]}, {"text": "Finally, we present a comparison of the syntactic and lexical differences between the the expression of certainty in the biomedical and newswire domains, using two annotated corpora.", "labels": [], "entities": []}], "introductionContent": [{"text": "The increasing amount of data readily available in digital form across various domains presents challenges for both researchers and the general public.", "labels": [], "entities": []}, {"text": "Although this has greatly improved access to data and dissemination of knowledge, it is becoming increasingly difficult to quickly identify apiece of information that is pertinent to our needs among the vast amounts of data, as well as to assess its certainty and credibility.", "labels": [], "entities": [{"text": "certainty", "start_pos": 250, "end_pos": 259, "type": "METRIC", "confidence": 0.9941704869270325}]}, {"text": "Advances in information extraction methods and in particular event extraction tasks, capture complex information structures to that can capture n-ary relations between entities, and better represent facts and statements made by authors.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 12, "end_pos": 34, "type": "TASK", "confidence": 0.7762607336044312}, {"text": "event extraction", "start_pos": 61, "end_pos": 77, "type": "TASK", "confidence": 0.7343883067369461}]}, {"text": "While being able to extract rich information in a structured manner is important, not all extracted information is equally trustworthy.", "labels": [], "entities": []}, {"text": "It is thus necessary to apply measures of confidence that will allow us to assess the credibility of events mined from different documents.", "labels": [], "entities": []}, {"text": "Such measures may take into account different factors affecting our confidence in a specific event, such as the reliability of the source, the timeliness of the event, the performance of the event extraction tool etc.", "labels": [], "entities": [{"text": "reliability", "start_pos": 112, "end_pos": 123, "type": "METRIC", "confidence": 0.9753676056861877}, {"text": "timeliness", "start_pos": 143, "end_pos": 153, "type": "METRIC", "confidence": 0.984391450881958}, {"text": "event extraction", "start_pos": 191, "end_pos": 207, "type": "TASK", "confidence": 0.7450386881828308}]}, {"text": "Along with such \"external\" factors affecting our trust in the event, another important aspect is how certainty is expressed in the context of the event by the author, since not all information mentioned in text is expressed with equal certainty.", "labels": [], "entities": [{"text": "certainty", "start_pos": 101, "end_pos": 110, "type": "METRIC", "confidence": 0.9857860803604126}]}, {"text": "Some events are explicitly identified as speculations, as hypothetical situations, as disputed allegations, as conditional facts, and soon.", "labels": [], "entities": []}, {"text": "Thus, it is important to complement event extraction methods with identification of such textual phenomena, in order to enrich extracted events with an attribute of certainty.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 36, "end_pos": 52, "type": "TASK", "confidence": 0.7393601834774017}]}, {"text": "Identification of textual uncertainty and hedging is a mature research topic, with an emphasis on the scientific domain.", "labels": [], "entities": [{"text": "Identification of textual uncertainty and hedging", "start_pos": 0, "end_pos": 49, "type": "TASK", "confidence": 0.8902266224225363}]}, {"text": "Methods to detect certainty and related types of information are widely applied in the field of biomedical text mining to assess the veracity of information, and the problem is approached both in terms of framing certainty and annotating corpora accordingly, and by applying machine learning techniques for the automated identification of uncertain statements and events ().", "labels": [], "entities": [{"text": "biomedical text mining", "start_pos": 96, "end_pos": 118, "type": "TASK", "confidence": 0.6274913847446442}]}, {"text": "In the news domain, while machine learning techniques have been used to mine sentiment, subjectivity etc, efforts concerned with (un)certainty identification have focussed mostly on the provision of classification framework for uncertainty or its combination with polarity to determine event factuality (.", "labels": [], "entities": [{"text": "certainty identification", "start_pos": 133, "end_pos": 157, "type": "TASK", "confidence": 0.7127750813961029}]}, {"text": "However, there has been less emphasis on applications that focus on automatically recognising uncertainty, especially in relation to events.", "labels": [], "entities": []}, {"text": "Moreover, early attempts at automated identification of uncertainty cues (weasels) in both the general and biomedical domains showed more than 0.30 difference in F-score between the two domains (0.50 for Wikipedia versus 0.87 for Bio (), thus illustrating the challenges of uncertainty identification in the general language domain.", "labels": [], "entities": [{"text": "automated identification of uncertainty cues (weasels)", "start_pos": 28, "end_pos": 82, "type": "TASK", "confidence": 0.7235193848609924}, {"text": "F-score", "start_pos": 162, "end_pos": 169, "type": "METRIC", "confidence": 0.9993982315063477}, {"text": "uncertainty identification", "start_pos": 274, "end_pos": 300, "type": "TASK", "confidence": 0.7706594467163086}]}, {"text": "Newswire text can prove more problematic in terms of uncertainty identification, since news stories tend to be reported in a subjective manner and allow for less strict use of language, while the truth value of reported events greatly depends on the time and context in which an article is written.", "labels": [], "entities": [{"text": "uncertainty identification", "start_pos": 53, "end_pos": 79, "type": "TASK", "confidence": 0.7423721551895142}]}, {"text": "As uncertainty identification is affected by various textual phenomena which are challenging to contextualise (metaphorical speech, colloquial expressions, etc), methods that identify event uncertainty from context are becoming increasingly crucial.", "labels": [], "entities": [{"text": "uncertainty identification", "start_pos": 3, "end_pos": 29, "type": "TASK", "confidence": 0.7469016015529633}]}, {"text": "The widespread use of the term \"fake news\" in recent years highlights the need to distinguish valuable and reliable facts, especially when it comes to automated information extraction.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 161, "end_pos": 183, "type": "TASK", "confidence": 0.6993606835603714}]}, {"text": "While detection of fake news is an involved process requiring more in depth discourse and stance analysis, identifying certainty of extracted events is an important parameter towards the assessment of credibility of such events.", "labels": [], "entities": []}, {"text": "The availability of an increasing number of resources annotated with news events and concepts related to uncertainty provide good opportunities to apply and adapt uncertainty identification techniques that are focussed on news articles.", "labels": [], "entities": [{"text": "uncertainty identification", "start_pos": 163, "end_pos": 189, "type": "TASK", "confidence": 0.7448509633541107}]}, {"text": "In this work, we present our efforts on adapting uncertainty event extraction techniques developed for biomedical text, to allow them to be applied to newswire text.", "labels": [], "entities": [{"text": "uncertainty event extraction", "start_pos": 49, "end_pos": 77, "type": "TASK", "confidence": 0.6615779598553976}]}, {"text": "We use two corpora annotated with events and meta-knowledge (different types of interpretative information within a sentence that can affect an event) to analyse the differences between the two domains and we discuss the challenges that arise.", "labels": [], "entities": []}, {"text": "We evaluate a hybrid machine learning approach to the identification of different uncertainty aspects (see Section 3.2.1) and propose ways of improving and customising uncertainty identification for newswire.", "labels": [], "entities": [{"text": "uncertainty identification", "start_pos": 168, "end_pos": 194, "type": "TASK", "confidence": 0.6960733234882355}]}], "datasetContent": [{"text": "We focus our analysis for the newswire domain on the recent annotations of the ACE 2005 corpus () (English version).", "labels": [], "entities": [{"text": "ACE 2005 corpus", "start_pos": 79, "end_pos": 94, "type": "DATASET", "confidence": 0.9757568836212158}]}, {"text": "The corpus was originally annotated with named entities (NEs), events, as well as some metaknowledge information and has been subsequently enriched with additional meta-knowledge annotations (.", "labels": [], "entities": []}, {"text": "We refer to the meta-knowledge annotated version of the corpus as ACE-MK 1 . The corpus comprises of 600 news articles originating from various sources, and contains annotations for 5349 events.", "labels": [], "entities": [{"text": "ACE-MK 1", "start_pos": 66, "end_pos": 74, "type": "DATASET", "confidence": 0.8884581327438354}]}, {"text": "The ACE-MK meta-knowledge annotation scheme, includes 6 meta-knowledge attributes, of which four (4) were present in the original 2005 annotated corpus and the rest were introduced in the 2017 annotation enrichment effort (the latter are marked with an asterisk in the enumeration that follows).", "labels": [], "entities": []}, {"text": "The respective cues for each type were annotated whenever present within a sentence.", "labels": [], "entities": []}, {"text": "1. Subjectivity (*) towards the event by the source.", "labels": [], "entities": [{"text": "Subjectivity", "start_pos": 3, "end_pos": 15, "type": "METRIC", "confidence": 0.9511277079582214}]}, {"text": "Can be Positive, Negative, Neutral or Multi-valued (two or more sources expressing opposite sentiments for the same event).", "labels": [], "entities": []}, {"text": "2. Source (*), that can be Author, Involved (attributed to a specified source, somehow involved with the event) or Third-Party.", "labels": [], "entities": []}, {"text": "3. Modality, that can have four possible values; Asserted, Speculated, Presupposed(*) and Other 4.", "labels": [], "entities": [{"text": "Presupposed", "start_pos": 71, "end_pos": 82, "type": "METRIC", "confidence": 0.96686190366745}]}, {"text": "Polarity, that can be either Positive or Negative.", "labels": [], "entities": [{"text": "Polarity", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.897668719291687}]}, {"text": "5. Tense, that can be Past, Present, Future or Unspecified.", "labels": [], "entities": []}, {"text": "6. Genericity, that can either be Specific (event referring to a specific occurrence) or Generic.", "labels": [], "entities": []}, {"text": "As discussed in Section 2, various concepts, such as modality, subjectivity, genericity and timeliness have been linked to uncertainty in the newswire domain.", "labels": [], "entities": []}, {"text": "In fact, most of the aforementioned event attributes annotated in ACE-MK could affect event certainty.", "labels": [], "entities": [{"text": "ACE-MK", "start_pos": 66, "end_pos": 72, "type": "DATASET", "confidence": 0.8664394617080688}, {"text": "certainty", "start_pos": 92, "end_pos": 101, "type": "METRIC", "confidence": 0.895527184009552}]}, {"text": "In this work, we focus on the dimensions of Modality,) Considering these three different attributes as well as their combination as uncertainty indicators, we generate four different test-sets, each corresponding to a different uncertainty definition: 1.", "labels": [], "entities": [{"text": "Modality", "start_pos": 44, "end_pos": 52, "type": "TASK", "confidence": 0.9504802823066711}]}, {"text": "M: uncertainty corresponds only to Modality, and only Asserted events are equivalent to Certain.", "labels": [], "entities": []}, {"text": "Based on descriptions in ().", "labels": [], "entities": []}, {"text": "2. G: uncertainty corresponds only to Genericity, and only Specific events are equivalent to Certain.", "labels": [], "entities": [{"text": "G", "start_pos": 3, "end_pos": 4, "type": "METRIC", "confidence": 0.9839419722557068}]}, {"text": "We thus claim that that generic, more vague events lack certainty, inspired by the distinction between abstract and specific statements in (Rubin, 2010).", "labels": [], "entities": [{"text": "certainty", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9732090830802917}]}, {"text": "3. S: uncertainty corresponds only to Subjectivity, and only Neutral events are equivalent to Certain.", "labels": [], "entities": []}, {"text": "Based on (Wiebe and) which has shown that positive or negative bias can affect the certainty of an event.", "labels": [], "entities": [{"text": "certainty", "start_pos": 83, "end_pos": 92, "type": "METRIC", "confidence": 0.9800539612770081}]}, {"text": "Multi-valued instances are treated as Uncertain since contradictory assertions have also been linked to uncertainty).", "labels": [], "entities": []}, {"text": "4. MGS : uncertainty corresponds to the union of the above; only an event that is Asserted, Neutral and Specific is considered Certain.", "labels": [], "entities": [{"text": "MGS", "start_pos": 3, "end_pos": 6, "type": "METRIC", "confidence": 0.6946125030517578}, {"text": "uncertainty", "start_pos": 9, "end_pos": 20, "type": "METRIC", "confidence": 0.9826443791389465}]}, {"text": "In both corpora, the annotations of all metaknowledge dimensions are on the event level (the values of each event annotated separately).", "labels": [], "entities": []}, {"text": "The evidence, if it can be attributed to one or more words in the same sentence as the event, is annotated as a cue, for the dimension annotated, and linked to the event(s) that it affects.", "labels": [], "entities": []}, {"text": "In (ab) we demonstrate one example from each corpus where the cue affects only one of the events in a sentence.", "labels": [], "entities": []}, {"text": "While in both corpora for most dimensions investigated the cues are word sequences different than the trigger of the event, for Subjectivity, we have cases where the trigger is also acting like a Subjectivity cue.", "labels": [], "entities": []}, {"text": "This is because based on the definition of Subjectivity for ACE-MK, biased attitude expressed in text denotes subjectivity (including expressions of intention, command, fear, hope, condemn etc).", "labels": [], "entities": []}, {"text": "Example (c) in demonstrates such a case.", "labels": [], "entities": []}, {"text": "We train and test separate classifiers for each case and discuss their performance and the implication on the predictability of uncertainty.", "labels": [], "entities": []}, {"text": "We should note that Polarity has been identified as a dimension that is orthogonal to uncertainty) and thus we choose not to include it in our investigation, although both corpora contain such annotations.", "labels": [], "entities": []}, {"text": "In future work, we would like to further investigate the combination of certainty and polarity and maybe expand our analysis on the FactBank corpus.", "labels": [], "entities": [{"text": "certainty", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.954251229763031}, {"text": "FactBank corpus", "start_pos": 132, "end_pos": 147, "type": "DATASET", "confidence": 0.9713918268680573}]}, {"text": "It would also be interesting, as future work, to expand our experiments and investigate whether Tense could also be used to account for the timeliness aspect, or whether Source could help to identify weaselling phenomena, thus expanding the coverage of uncertainty.", "labels": [], "entities": []}, {"text": "For an efficient accounting of these two dimensions in future work, we would like to include additional resources such as timeliness or citation analysis components.", "labels": [], "entities": [{"text": "citation analysis", "start_pos": 136, "end_pos": 153, "type": "TASK", "confidence": 0.7667904794216156}]}, {"text": "Apart from comparing performance among the different uncertainty-related definitions described above, we compare our results for ACE-MK with those obtained fora biomedical corpus, GENIA-MK (), for binary uncertainty identification using the same hybrid method, as reported in (.", "labels": [], "entities": [{"text": "GENIA-MK", "start_pos": 180, "end_pos": 188, "type": "DATASET", "confidence": 0.8775766491889954}, {"text": "binary uncertainty identification", "start_pos": 197, "end_pos": 230, "type": "TASK", "confidence": 0.6163815557956696}]}, {"text": "The GENIA-MK corpus consists of 1000 abstracts extracted from PubMed and annotated with 36,858 events 2 . It has also been annotated with meta-knowledge attributes for each event, and the respective cues.", "labels": [], "entities": [{"text": "GENIA-MK corpus", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.9351411163806915}, {"text": "PubMed", "start_pos": 62, "end_pos": 68, "type": "DATASET", "confidence": 0.9703800082206726}]}, {"text": "The meta-knowledge attributes for each event include Certainty Level (L1, L2, L3), Polarity (Positive, Negative), Manner (High, Low and Neutral), Source (Current, Other) and Knowledge Type (Investigation, Observation, Analysis, Method, Fact, Other).", "labels": [], "entities": [{"text": "Manner", "start_pos": 114, "end_pos": 120, "type": "METRIC", "confidence": 0.998193085193634}]}, {"text": "Of those, Certainty Level L1 and L2 as well as Knowledge type of Investigation were treated as uncertainty indicators (denoting an event as Uncertain).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance of uncertainty identification  on each uncertainty test-case using GENIA-MK  (GEN) and ACE-MK (ACE) cues.", "labels": [], "entities": [{"text": "uncertainty identification", "start_pos": 25, "end_pos": 51, "type": "TASK", "confidence": 0.7141236513853073}, {"text": "GENIA-MK", "start_pos": 89, "end_pos": 97, "type": "DATASET", "confidence": 0.7749630212783813}]}, {"text": " Table 2: Performance for uncertainty identification  on GENIA-MK corpus using different cues.", "labels": [], "entities": [{"text": "uncertainty identification", "start_pos": 26, "end_pos": 52, "type": "TASK", "confidence": 0.729606956243515}, {"text": "GENIA-MK corpus", "start_pos": 57, "end_pos": 72, "type": "DATASET", "confidence": 0.9586425721645355}]}]}