{"title": [], "abstractContent": [{"text": "Existing entailment datasets mainly pose problems which can be answered without attention to grammar or word order.", "labels": [], "entities": []}, {"text": "Learning syntax requires comparing examples where different grammar and word order change the desired classification.", "labels": [], "entities": []}, {"text": "We introduce several datasets based on synthetic transformations of natural entailment examples in SNLI or FEVER, to teach aspects of grammar and word order.", "labels": [], "entities": [{"text": "FEVER", "start_pos": 107, "end_pos": 112, "type": "METRIC", "confidence": 0.9496201276779175}]}, {"text": "We show that without retraining, popular entail-ment models are unaware that these syntactic differences change meaning.", "labels": [], "entities": []}, {"text": "With retraining , some but not all popular entailment models can learn to compare the syntax properly.", "labels": [], "entities": []}], "introductionContent": [{"text": "Natural language inference (NLI) is a task to identify the entailment relationship between a premise sentence and a hypothesis sentence.", "labels": [], "entities": [{"text": "Natural language inference (NLI)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7663616637388865}]}, {"text": "Given the premise, a hypothesis maybe true (entailment), false (contradiction), or not clearly determined (neutral).", "labels": [], "entities": []}, {"text": "NLI is an essential aspect of natural language understanding.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 30, "end_pos": 60, "type": "TASK", "confidence": 0.6661657691001892}]}, {"text": "The release of datasets with hundreds of thousands of example pairs, such as SNLI () and MultiNLI (, has enabled the development of models based on deep neural networks that have achieved near human level performance.", "labels": [], "entities": []}, {"text": "However, high accuracies on these datasets do not mean that the NLI problem is solved.", "labels": [], "entities": []}, {"text": "Annotation artifacts make it possible to correctly guess the label for many hypotheses without even considering the premise (.", "labels": [], "entities": []}, {"text": "Successful trained systems can be disturbed by small changes to the input (.", "labels": [], "entities": []}, {"text": "In this paper, we show that existing trained NLI systems are mostly unaware of the relation between syntax and semantics, particularly of how word order affects meaning.", "labels": [], "entities": []}, {"text": "We develop a technique, \"adversarial distraction,\" to teach networks to properly use this information.", "labels": [], "entities": []}, {"text": "The adversarial distraction technique consists of creating pairs of examples where information matching the premise is present in the hypothesis in both cases, but differing syntactic structure leads to different entailment labels.", "labels": [], "entities": [{"text": "adversarial distraction", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.7338559329509735}]}, {"text": "We generate adversarial distractions automatically from SNLI and an NLI dataset derived from FEVER (, thus augmenting the datasets.", "labels": [], "entities": [{"text": "NLI dataset", "start_pos": 68, "end_pos": 79, "type": "DATASET", "confidence": 0.8645837903022766}, {"text": "FEVER", "start_pos": 93, "end_pos": 98, "type": "METRIC", "confidence": 0.9655850529670715}]}, {"text": "We observe the behavior of several existing NLI models on the added examples, finding that they are mostly unaware that the syntactic changes have affected the meaning.", "labels": [], "entities": []}, {"text": "We then retrain the models with the added examples, and find whether these weaknesses are limitations of the models or simply due to the lack of appropriate training data.", "labels": [], "entities": []}], "datasetContent": [{"text": "We consider three NLI systems based on deep neural networks: Decomposable Attention (DA) (), ESIM (, and a Finetuned Transformer Language Model (FTLM) (.", "labels": [], "entities": []}, {"text": "For Decomposable Attention we take the AllenNLP implementation () without ELMo features (; for the others, we take the releases from the authors.", "labels": [], "entities": [{"text": "AllenNLP", "start_pos": 39, "end_pos": 47, "type": "DATASET", "confidence": 0.9669517278671265}]}, {"text": "We modify the code released for FTLM to support entailment classification, following the description in the paper.", "labels": [], "entities": [{"text": "FTLM", "start_pos": 32, "end_pos": 36, "type": "DATASET", "confidence": 0.7662057280540466}, {"text": "entailment classification", "start_pos": 48, "end_pos": 73, "type": "TASK", "confidence": 0.8786313235759735}]}, {"text": "For the FEVER-based datasets, for DA and ESIM, we reweight each class in the training data   in inverse proportion to its number of examples.", "labels": [], "entities": [{"text": "FEVER-based datasets", "start_pos": 8, "end_pos": 28, "type": "DATASET", "confidence": 0.9288452565670013}]}, {"text": "This reweighting is necessary to produce nontrivial (most frequent class) results; the NLI training set we derive from FEVER has 92% neutral, 6% entailment, and 2% contradiction examples.", "labels": [], "entities": [{"text": "NLI training set", "start_pos": 87, "end_pos": 103, "type": "DATASET", "confidence": 0.6314668655395508}, {"text": "FEVER", "start_pos": 119, "end_pos": 124, "type": "METRIC", "confidence": 0.7397235035896301}]}, {"text": "FTLM requires no such reweighting.", "labels": [], "entities": [{"text": "FTLM", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9004900455474854}]}, {"text": "When evaluating on the original FEVER examples, we report Cohen's Kappa between predicted and ground truth classifications, in addition to accuracy, because the imbalance pushes DA and ESIM below the accuracy of a trivial classifier.", "labels": [], "entities": [{"text": "FEVER", "start_pos": 32, "end_pos": 37, "type": "METRIC", "confidence": 0.5287272334098816}, {"text": "accuracy", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.9995243549346924}, {"text": "DA", "start_pos": 178, "end_pos": 180, "type": "METRIC", "confidence": 0.8552365899085999}, {"text": "ESIM", "start_pos": 185, "end_pos": 189, "type": "METRIC", "confidence": 0.8580693602561951}, {"text": "accuracy", "start_pos": 200, "end_pos": 208, "type": "METRIC", "confidence": 0.9981899857521057}]}, {"text": "Whereas FTLM uses a byte-pair encoding vocabulary () that can represent any word as a combination of subword tokens, DA and ESIM rely on word embeddings from GloVe (, with a single out-ofvocabulary (OOV) token shared for all unknown words.", "labels": [], "entities": [{"text": "FTLM", "start_pos": 8, "end_pos": 12, "type": "DATASET", "confidence": 0.7456810474395752}]}, {"text": "Therefore it is unreasonable to expect DA and ESIM not to confuse named entities in FEVER tasks.", "labels": [], "entities": [{"text": "FEVER", "start_pos": 84, "end_pos": 89, "type": "METRIC", "confidence": 0.48732292652130127}]}, {"text": "We extend each of these models by allocating 10,000 random vectors for out-ofvocabulary words, and taking a hash of each OOV word to select one of the vectors.", "labels": [], "entities": []}, {"text": "The vectors are initialized from a normal distribution with mean 0 and standard deviation 1.", "labels": [], "entities": [{"text": "standard", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.9608345031738281}]}], "tableCaptions": [{"text": " Table 1: The number of examples in the original SNLI and FEVER data, and the number of examples generated  for each adversarial distraction.", "labels": [], "entities": [{"text": "FEVER data", "start_pos": 58, "end_pos": 68, "type": "DATASET", "confidence": 0.8840977251529694}]}, {"text": " Table 2: Accuracy and (Cohen's Kappa) when training on original SNLI or FEVER data and testing on original or  added examples.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.999559223651886}, {"text": "Cohen's Kappa)", "start_pos": 24, "end_pos": 38, "type": "METRIC", "confidence": 0.6544684395194054}, {"text": "FEVER", "start_pos": 73, "end_pos": 78, "type": "METRIC", "confidence": 0.7247751951217651}]}, {"text": " Table 3: Accuracy and (Cohen's Kappa) when training on augmented SNLI (SNLI + passive + passive reversal) or  augmented FEVER (FEVER + person reversal or FEVER + birthday) and testing on original or added examples.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9993502497673035}, {"text": "FEVER", "start_pos": 121, "end_pos": 126, "type": "METRIC", "confidence": 0.940363347530365}, {"text": "FEVER + birthday", "start_pos": 155, "end_pos": 171, "type": "METRIC", "confidence": 0.8386009335517883}]}]}