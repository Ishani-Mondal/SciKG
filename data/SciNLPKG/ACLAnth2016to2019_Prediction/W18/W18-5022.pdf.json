{"title": [{"text": "Cost-Sensitive Active Learning for Dialogue State Tracking", "labels": [], "entities": [{"text": "Dialogue State Tracking", "start_pos": 35, "end_pos": 58, "type": "TASK", "confidence": 0.7096585631370544}]}], "abstractContent": [{"text": "Dialogue state tracking (DST), when formulated as a supervised learning problem, relies on labelled data.", "labels": [], "entities": [{"text": "Dialogue state tracking (DST)", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8386703630288442}]}, {"text": "Since dialogue state annotation usually requires labelling all turns of a single dialogue and utilizing context information, it is very expensive to annotate all available unlabelled data.", "labels": [], "entities": [{"text": "dialogue state annotation", "start_pos": 6, "end_pos": 31, "type": "TASK", "confidence": 0.7697535157203674}]}, {"text": "In this paper, a novel cost-sensitive active learning framework is proposed based on a set of new dialogue-level query strategies.", "labels": [], "entities": []}, {"text": "This is the first attempt to apply active learning for dialogue state tracking.", "labels": [], "entities": [{"text": "dialogue state tracking", "start_pos": 55, "end_pos": 78, "type": "TASK", "confidence": 0.7977547645568848}]}, {"text": "Experiments on DSTC2 show that active learning with mixed data query strategies can effectively achieve the same DST performance with significantly less data annotation compared to traditional training approaches.", "labels": [], "entities": [{"text": "DST", "start_pos": 113, "end_pos": 116, "type": "TASK", "confidence": 0.9531945586204529}]}], "introductionContent": [{"text": "The dialogue state tracker, an important component of a spoken dialogue system, tracks the internal belief state of the system based on the history of the dialogue.", "labels": [], "entities": [{"text": "dialogue state tracker", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.5995999077955881}]}, {"text": "For each turn, the tracker outputs a distribution over possible dialogue states, on which the dialogue system relies to take proper actions to interact with users.", "labels": [], "entities": []}, {"text": "Various approaches have been proposed for dialogue state tracking, including hand-crafted rules (), generative models ) and discriminative models.", "labels": [], "entities": [{"text": "dialogue state tracking", "start_pos": 42, "end_pos": 65, "type": "TASK", "confidence": 0.7837140162785848}]}, {"text": "For discriminative models, recent studies on data-driven approaches have shown promising performance, especially on Recurrent Neural Network (RNN) (.", "labels": [], "entities": []}, {"text": "As for datasets, the Dialog State Tracking Challenge (DSTC) series) have provided common testbeds for this task.", "labels": [], "entities": [{"text": "Dialog State Tracking Challenge (DSTC)", "start_pos": 21, "end_pos": 59, "type": "TASK", "confidence": 0.7683558676924024}]}, {"text": "Though data-driven approaches have achieved promising performance, they require large amounts of labelled data, which are costly to be fully annotated.", "labels": [], "entities": []}, {"text": "Besides this, it is quite difficult to label a single dialogue because, for every dialogue turn, experts need to label all the semantic slots and typically, to label a single turn accurately, they need to pay attention to the context rather than the current turn only.", "labels": [], "entities": []}, {"text": "Active learning (AL) can be applied to select valuable samples to label.", "labels": [], "entities": []}, {"text": "Using the AL approach, we need fewer labelled samples when training the model to reach the same or even better performance compared to traditional training approaches.", "labels": [], "entities": []}, {"text": "Although it is often assumed that the labelling costs are the same for all samples in some tasks, it is appropriate to consider different labelling costs for the dialogue state tracking task where different dialogues vary in the number of turns.", "labels": [], "entities": [{"text": "dialogue state tracking task", "start_pos": 162, "end_pos": 190, "type": "TASK", "confidence": 0.7737821638584137}]}, {"text": "In this paper, we define the labelling cost for each dialogue sample with respect to its number of dialogue turns.", "labels": [], "entities": []}, {"text": "Then we provide anew AL query criterion called diversity, and finally propose a novel cost-sensitive active learning approach based on three dimensions: cost, uncertainty, and diversity.", "labels": [], "entities": []}, {"text": "The results of experiments on the DSTC2 dataset () demonstrate that our approaches are more effective compared to traditional training methods.", "labels": [], "entities": [{"text": "DSTC2 dataset", "start_pos": 34, "end_pos": 47, "type": "DATASET", "confidence": 0.9878492653369904}]}, {"text": "In the next section, we will present the proposed cost-sensitive active learning framework for dialogue state tracking.", "labels": [], "entities": [{"text": "dialogue state tracking", "start_pos": 95, "end_pos": 118, "type": "TASK", "confidence": 0.794554074605306}]}, {"text": "Then in Section 3 we will describe the experimental setup and show the results of experiments on the DSTC2 dataset, followed by our conclusions and future work in Section 4.", "labels": [], "entities": [{"text": "DSTC2 dataset", "start_pos": 101, "end_pos": 114, "type": "DATASET", "confidence": 0.9922830164432526}]}], "datasetContent": [{"text": "Experiments are conducted to assess the performance of different query strategies on single slot and joint goal respectively.", "labels": [], "entities": []}, {"text": "The dataset we use is the second Dialogue State Tracking Challenge (DSTC2) dataset, which focuses on the restaurant information domain and contains 7 slots of which 4 are informable and all 7 are requestable.", "labels": [], "entities": [{"text": "Dialogue State Tracking Challenge (DSTC2)", "start_pos": 33, "end_pos": 74, "type": "TASK", "confidence": 0.7679900058678218}]}, {"text": "We implement the dialogue state tracker as described in Section 2.1.", "labels": [], "entities": [{"text": "dialogue state tracker", "start_pos": 17, "end_pos": 39, "type": "TASK", "confidence": 0.6326419214407603}]}, {"text": "The model is trained using Stochastic Gradient Descent (SGD), collaborating with a gradient clipping heuristic () to avoid the exploding gradient problems.", "labels": [], "entities": []}], "tableCaptions": []}