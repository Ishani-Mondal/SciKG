{"title": [{"text": "A Report on the Complex Word Identification Shared Task 2018", "labels": [], "entities": [{"text": "Complex Word Identification Shared Task", "start_pos": 16, "end_pos": 55, "type": "TASK", "confidence": 0.753989976644516}]}], "abstractContent": [{"text": "We report the findings of the second Complex Word Identification (CWI) shared task organized as part of the BEA workshop co-located with NAACL-HLT'2018.", "labels": [], "entities": [{"text": "Complex Word Identification (CWI) shared task", "start_pos": 37, "end_pos": 82, "type": "TASK", "confidence": 0.8036069944500923}, {"text": "BEA", "start_pos": 108, "end_pos": 111, "type": "METRIC", "confidence": 0.4137366712093353}, {"text": "NAACL-HLT'2018", "start_pos": 137, "end_pos": 151, "type": "DATASET", "confidence": 0.5480914115905762}]}, {"text": "The second CWI shared task featured multilingual and multi-genre datasets divided into four tracks: English monolingual, German monolingual, Spanish monolingual, and a multilingual track with a French test set, and two tasks: binary classification and probabilistic classification.", "labels": [], "entities": [{"text": "binary classification", "start_pos": 226, "end_pos": 247, "type": "TASK", "confidence": 0.720961183309555}]}, {"text": "A total of 12 teams submitted their results in different task/track combinations and 11 of them wrote system description papers that are referred to in this report and appear in the BEA workshop proceedings.", "labels": [], "entities": [{"text": "BEA workshop proceedings", "start_pos": 182, "end_pos": 206, "type": "DATASET", "confidence": 0.8801421125729879}]}], "introductionContent": [{"text": "The most common first step in lexical simplification pipelines is identifying which words are considered complex by a given target population.", "labels": [], "entities": [{"text": "lexical simplification pipelines", "start_pos": 30, "end_pos": 62, "type": "TASK", "confidence": 0.7722756663958231}]}, {"text": "This task is known as complex word identification (CWI) and it has been attracting attention from the research community in the past few years.", "labels": [], "entities": [{"text": "complex word identification (CWI)", "start_pos": 22, "end_pos": 55, "type": "TASK", "confidence": 0.7639789879322052}]}, {"text": "In this paper we present the findings of the second Complex Word Identification (CWI) shared task organized as part of the thirteenth Workshop on Innovative Use of NLP for Building Educational Applications (BEA) co-located with NAACL-HLT'2018.", "labels": [], "entities": [{"text": "Complex Word Identification (CWI) shared task", "start_pos": 52, "end_pos": 97, "type": "TASK", "confidence": 0.8177175968885422}, {"text": "NAACL-HLT'2018", "start_pos": 228, "end_pos": 242, "type": "DATASET", "confidence": 0.8672454953193665}]}, {"text": "The second CWI shared task follows a successful first edition featuring 21 teams organized at.", "labels": [], "entities": []}, {"text": "While the first CWI shared task targeted an English dataset, the second edition focused on multilingualism providing datasets containing four languages: English, German, French, and Spanish.", "labels": [], "entities": []}, {"text": "In an evaluation paper (, it has been shown that the performance of an ensemble classifier built on top of the predictions of the participating systems in the 2016 task degraded, the more systems were added.", "labels": [], "entities": []}, {"text": "The low performance of the CWI systems that competed in the first CWI task left much room for improvement and was one of the reasons that motivated us to organize this second edition.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have used the CWIG3G2 datasets from for the complex word identification (CWI) shared task 2018.", "labels": [], "entities": [{"text": "CWIG3G2 datasets", "start_pos": 17, "end_pos": 33, "type": "DATASET", "confidence": 0.9438862502574921}, {"text": "complex word identification (CWI) shared task", "start_pos": 47, "end_pos": 92, "type": "TASK", "confidence": 0.8007843419909477}]}, {"text": "The datasets are collected for multiple languages (English, German, Spanish).", "labels": [], "entities": []}, {"text": "The English datasets cover different text genres, namely News (professionally written news), WikiNews (news written by amateurs), and Wikipedia articles.", "labels": [], "entities": []}, {"text": "Below, we will briefly describe the annotation process and the statistics of collected datasets.", "labels": [], "entities": []}, {"text": "For detail explanation of the datasets, please refer to the works of Furthermore, to bolster the cross-lingual CWI experiment, we have collected a CWI dataset for French.", "labels": [], "entities": [{"text": "CWI dataset", "start_pos": 147, "end_pos": 158, "type": "DATASET", "confidence": 0.8708510100841522}]}, {"text": "The French dataset was collected through the same method used for the CWIG3G2 corpus (.", "labels": [], "entities": [{"text": "French dataset", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.965452253818512}, {"text": "CWIG3G2 corpus", "start_pos": 70, "end_pos": 84, "type": "DATASET", "confidence": 0.9712463021278381}]}, {"text": "The dataset contains Wikipedia texts extracted from a comparable simplified corpus collected by.", "labels": [], "entities": []}, {"text": "Similar to CWIG3G2, for each article, all paragraphs containing between 5 and 10 sentences were extracted.", "labels": [], "entities": [{"text": "CWIG3G2", "start_pos": 11, "end_pos": 18, "type": "DATASET", "confidence": 0.9271636605262756}]}, {"text": "From this pool of paragraphs, only the best paragraph was selected via a ranking procedure maximizing sentence length and lexical richness, and minimizing the ratio of named entities and foreign words.", "labels": [], "entities": []}, {"text": "From this large selection of best paragraphs per article, an optimal subset of 100 paragraphs was then selected using a greedy search procedure similar to that of, minimizing the vocabulary overlap between pairs of paragraphs using the Jaccard coefficient.", "labels": [], "entities": []}, {"text": "Finally, a random test split of 24 paragraphs was selected to be annotated.", "labels": [], "entities": []}, {"text": "For the German annotation task, we have fewer annotators than the other languages.", "labels": [], "entities": []}, {"text": "As it can be seen from, there are more native annotators, but they participate on fewer HITs than the non-native annotators (on average, 6.1 nonnative speakers and 3.9 native speakers participated in a HIT).", "labels": [], "entities": []}, {"text": "Unlike the English annotation task, non-native annotators have a higher interannotator agreement (70.66%) than the native annotators (58.5%).", "labels": [], "entities": [{"text": "interannotator agreement", "start_pos": 72, "end_pos": 96, "type": "METRIC", "confidence": 0.9340467154979706}]}, {"text": "The Spanish annotation task is different from both the English and the German annotation tasks since its annotations come almost exclusively from native annotators.", "labels": [], "entities": []}, {"text": "In general, Spanish annotators have shown lower agreements than the English and German annotators.", "labels": [], "entities": [{"text": "agreements", "start_pos": 48, "end_pos": 58, "type": "METRIC", "confidence": 0.959293782711029}]}, {"text": "Also the Spanish annotators highlight more MWEs than the English and German annotators.", "labels": [], "entities": []}, {"text": "Regarding the French annotation task, we observe a comparable distribution in the number of native and non-native annotators compared to the German annotation task).", "labels": [], "entities": []}, {"text": "There were slightly more non-native participants than native ones, but the number of native annotators who completed the same number of HITs was considerably larger.", "labels": [], "entities": []}, {"text": "This means that although there were more non-native participants, they did not participate equally in all HITs.", "labels": [], "entities": [{"text": "HITs", "start_pos": 106, "end_pos": 110, "type": "DATASET", "confidence": 0.7231200933456421}]}], "tableCaptions": [{"text": " Table 1: SemEval 2016 CWI -Systems and approaches", "labels": [], "entities": [{"text": "SemEval 2016 CWI", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.7393745581309}]}, {"text": " Table 2: The number of annotators for different lan- guages", "labels": [], "entities": []}, {"text": " Table 3: The number of instances for each training, de- velopment and test set", "labels": [], "entities": []}, {"text": " Table 4: The number (#) and ratio (%) of complex in- stances per language", "labels": [], "entities": [{"text": "ratio", "start_pos": 29, "end_pos": 34, "type": "METRIC", "confidence": 0.9693235158920288}]}, {"text": " Table 5: The distribution of single and MWE annota- tions of complex words per language", "labels": [], "entities": []}, {"text": " Table 7: Binary classification results for the multilingual German, Spanish and French tracks.", "labels": [], "entities": [{"text": "Binary classification", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.7634542882442474}]}, {"text": " Table 8: Probablistic classification results for the monolingual English tracks.", "labels": [], "entities": [{"text": "Probablistic classification", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.7511637806892395}]}, {"text": " Table 9: Probablistic classification results for the multilingual German, Spanish, and French tracks.", "labels": [], "entities": [{"text": "Probablistic classification", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.707120731472969}]}]}