{"title": [{"text": "Combining Quality Estimation and Automatic Post-editing to Enhance Machine Translation Output", "labels": [], "entities": [{"text": "Machine Translation Output", "start_pos": 67, "end_pos": 93, "type": "TASK", "confidence": 0.7718514998753866}]}], "abstractContent": [{"text": "We investigate different strategies for combining quality estimation (QE) and automatic post-editing (APE) to improve the output of machine translation (MT) systems.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 132, "end_pos": 156, "type": "TASK", "confidence": 0.8146576523780823}]}, {"text": "The joint contribution of the two technologies is analyzed in different settings, in which QE serves as either: i) an activator of APE corrections, or ii) a guidance to APE corrections, or iii) a selector of the final output to be returned to the user.", "labels": [], "entities": [{"text": "APE corrections", "start_pos": 131, "end_pos": 146, "type": "TASK", "confidence": 0.6533294022083282}, {"text": "APE corrections", "start_pos": 169, "end_pos": 184, "type": "TASK", "confidence": 0.7924066781997681}]}, {"text": "In the first case (QE as activator), sentence-level predictions on the raw MT output quality are used to trigger its automatic correction when the estimated (TER) scores are below a certain threshold.", "labels": [], "entities": [{"text": "MT output", "start_pos": 75, "end_pos": 84, "type": "TASK", "confidence": 0.8759181201457977}, {"text": "TER) scores", "start_pos": 158, "end_pos": 169, "type": "METRIC", "confidence": 0.8935256203015646}]}, {"text": "In the second case (QE as guidance), word-level binary quality predictions (\"good\"/\"bad\") are used to inform APE about problematic words in the MT output that should be corrected.", "labels": [], "entities": [{"text": "APE", "start_pos": 109, "end_pos": 112, "type": "TASK", "confidence": 0.7715469598770142}, {"text": "MT", "start_pos": 144, "end_pos": 146, "type": "TASK", "confidence": 0.6113502979278564}]}, {"text": "In the last case (QE as selector), both sentence-and word-level quality predictions are used to identify the most accurate translation between the original MT output and its post-edited version.", "labels": [], "entities": []}, {"text": "For the sake of comparison, the underlying APE technologies explored in our evaluation are both phrase-based and neural.", "labels": [], "entities": [{"text": "APE", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.8963570594787598}]}, {"text": "Experiments are carried out on the English-German data used for the QE/APE shared tasks organized within the First Conference on Machine Translation (WMT 2016).", "labels": [], "entities": [{"text": "QE/APE shared tasks organized within the First Conference on Machine Translation (WMT 2016)", "start_pos": 68, "end_pos": 159, "type": "TASK", "confidence": 0.6686670937958885}]}, {"text": "Our evaluation shows positive but mixed results, with higher performance observed when word-level QE is used as a selector for neural APE applied to the output of a phrase-based MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 178, "end_pos": 180, "type": "TASK", "confidence": 0.8741436004638672}]}, {"text": "Overall, our findings motivate further investigation on QE technologies.", "labels": [], "entities": [{"text": "QE", "start_pos": 56, "end_pos": 58, "type": "TASK", "confidence": 0.8734174966812134}]}, {"text": "By reducing the gap between the performance of current solutions and \"oracle\" results, QE could significantly add to competitive APE technologies.", "labels": [], "entities": [{"text": "APE", "start_pos": 129, "end_pos": 132, "type": "TASK", "confidence": 0.9056599140167236}]}], "introductionContent": [{"text": "run-time, that is when reference-based evaluation is unfeasible (the typical scenario when MT is deployed in production).", "labels": [], "entities": [{"text": "MT", "start_pos": 91, "end_pos": 93, "type": "TASK", "confidence": 0.9195637106895447}]}, {"text": "APE () is motivated by the need of improving MT systems' output in black-box conditions, in which the translation models are not accessible for internal modification, retraining or adaptation (a typical situation for companies that rely on third-party MT systems).", "labels": [], "entities": [{"text": "MT", "start_pos": 45, "end_pos": 47, "type": "TASK", "confidence": 0.9734521508216858}]}, {"text": "Both QE and APE have been successfully explored as standalone tasks in previous work, in particular within the well-established framework of the Conference on Machine Translation (WMT 1 ).", "labels": [], "entities": [{"text": "APE", "start_pos": 12, "end_pos": 15, "type": "METRIC", "confidence": 0.601224422454834}, {"text": "Machine Translation (WMT 1 )", "start_pos": 159, "end_pos": 187, "type": "TASK", "confidence": 0.8488049407800039}]}, {"text": "In six editions of the WMT QE shared task, the MT quality prediction problem has been formulated in different ways (e.g. ranking, scoring) and attacked at different levels of granularity (sentence/phrase/word-level).", "labels": [], "entities": [{"text": "WMT QE shared task", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.5512170195579529}, {"text": "MT quality prediction", "start_pos": 47, "end_pos": 68, "type": "TASK", "confidence": 0.9202527403831482}]}, {"text": "Constant state-of-the-art advancements are making QE a more appealing technology, for instance to enhance the productivity of human translators operating with computer-assisted translation tools (.", "labels": [], "entities": []}, {"text": "Three rounds of the APE shared task at WMT (2015-2017) followed a similar trend, with improvements that reflect a steady progress of the underlying technology developed by participants.", "labels": [], "entities": [{"text": "APE shared task", "start_pos": 20, "end_pos": 35, "type": "TASK", "confidence": 0.8882643580436707}, {"text": "WMT", "start_pos": 39, "end_pos": 42, "type": "DATASET", "confidence": 0.8884103894233704}]}, {"text": "Despite the growing interest in the two tasks and the fact that the proposed evaluation exercises shared the same training/test data, previous research on both topics has mainly followed independent paths.", "labels": [], "entities": []}, {"text": "As a consequence, the potential usefulness of leveraging the two technologies to achieve better MT has been scarcely explored and no systematic analysis of the possible combination strategies has been reported.", "labels": [], "entities": [{"text": "MT", "start_pos": 96, "end_pos": 98, "type": "TASK", "confidence": 0.990584135055542}]}, {"text": "Along this direction, this paper investigates how QE and APE can be jointly deployed to boost the overall quality of the output produced by an MT system, without any intervention on the actual MT technology.", "labels": [], "entities": [{"text": "APE", "start_pos": 57, "end_pos": 60, "type": "METRIC", "confidence": 0.9683055281639099}, {"text": "MT", "start_pos": 143, "end_pos": 145, "type": "TASK", "confidence": 0.9661535620689392}]}, {"text": "By experimenting with the same data, we explore different ways to approach the problem.", "labels": [], "entities": []}, {"text": "The main difference between the proposed strategies lies in the degree of integration between the two technologies.", "labels": [], "entities": []}, {"text": "A light integration is pursued when QE is used either to trigger the automatic correction of machine-translated text (QE as activator, see Section 3.1) or to validate an automatic correction by comparing it with the original MT output (QE as selector, see Section 3.3).", "labels": [], "entities": []}, {"text": "A tighter integration is pursued when QE is used to inform the automatic correction process by identifying problematic passages in the machine-translated text (QE as guidance, see Section 3.2).", "labels": [], "entities": [{"text": "automatic correction", "start_pos": 63, "end_pos": 83, "type": "TASK", "confidence": 0.6504886001348495}, {"text": "QE", "start_pos": 160, "end_pos": 162, "type": "METRIC", "confidence": 0.8172313570976257}]}, {"text": "Depending on the applied strategy, QE predictions can be done at different levels of granularity.", "labels": [], "entities": [{"text": "QE predictions", "start_pos": 35, "end_pos": 49, "type": "TASK", "confidence": 0.9514310956001282}]}, {"text": "In this first exploration we focus on the two most studied levels, namely sentence and word levels, leaving for future work the exploitation of phrase-level estimates (.", "labels": [], "entities": []}, {"text": "Overall, this paper presents the following main contributions: \u2022 The first systematic analysis of different strategies for the integration of QE and APE towards better MT quality; \u2022 Experimental results, computed on the same public test set, indicating that state-of-the-art QE methods can improve APE and that, in turn, their joint contribution can boost MT output quality; \u2022 A verification of our findings, based on \"oracle\" quality scores, indicating a large room for improvement conditioned to the reliability of QE predictions.", "labels": [], "entities": [{"text": "MT", "start_pos": 168, "end_pos": 170, "type": "TASK", "confidence": 0.9863384366035461}, {"text": "APE", "start_pos": 298, "end_pos": 301, "type": "TASK", "confidence": 0.7771390676498413}, {"text": "MT output", "start_pos": 356, "end_pos": 365, "type": "TASK", "confidence": 0.8943010568618774}]}, {"text": "This motivates further research on the task.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: QE as APE activator (BLEU scores). These results are obtained using a threshold of  10 TER points.", "labels": [], "entities": [{"text": "QE", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9581194519996643}, {"text": "APE", "start_pos": 16, "end_pos": 19, "type": "METRIC", "confidence": 0.7649624347686768}, {"text": "BLEU", "start_pos": 31, "end_pos": 35, "type": "METRIC", "confidence": 0.9560956358909607}, {"text": "TER", "start_pos": 97, "end_pos": 100, "type": "METRIC", "confidence": 0.9987738728523254}]}, {"text": " Table 2: QE as APE guidance (BLEU scores).", "labels": [], "entities": [{"text": "QE", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9581994414329529}, {"text": "APE guidance", "start_pos": 16, "end_pos": 28, "type": "METRIC", "confidence": 0.9319284558296204}, {"text": "BLEU scores", "start_pos": 30, "end_pos": 41, "type": "METRIC", "confidence": 0.9585046768188477}]}, {"text": " Table 3: QE as MT/APE selector (BLEU scores). Word-level QE annotations are produced only  for the MT segment.", "labels": [], "entities": [{"text": "MT/APE selector", "start_pos": 16, "end_pos": 31, "type": "TASK", "confidence": 0.5194936841726303}, {"text": "BLEU", "start_pos": 33, "end_pos": 37, "type": "METRIC", "confidence": 0.9863053560256958}, {"text": "MT segment", "start_pos": 100, "end_pos": 110, "type": "TASK", "confidence": 0.7363414466381073}]}, {"text": " Table 4: QE as MT/APE selector (BLEU scores). Sentence-level QE annotations both on the  MT and APE segments.", "labels": [], "entities": [{"text": "QE", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.7104482650756836}, {"text": "MT/APE", "start_pos": 16, "end_pos": 22, "type": "TASK", "confidence": 0.40471066037813824}, {"text": "BLEU", "start_pos": 33, "end_pos": 37, "type": "METRIC", "confidence": 0.9902079701423645}]}, {"text": " Table 5: QE as MT/APE selector (BLEU scores). Word-level QE annotations both on the MT  and APE segments.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 33, "end_pos": 37, "type": "METRIC", "confidence": 0.991755485534668}]}]}