{"title": [{"text": "Statistical NLG for Generating the Content and Form of Referring Expressions", "labels": [], "entities": [{"text": "Statistical NLG", "start_pos": 0, "end_pos": 15, "type": "DATASET", "confidence": 0.6252479553222656}, {"text": "Form of Referring Expressions", "start_pos": 47, "end_pos": 76, "type": "TASK", "confidence": 0.6366310939192772}]}], "abstractContent": [{"text": "This paper argues that anew generic approach to statistical NLG can be made to perform Referring Expression Generation (REG) successfully.", "labels": [], "entities": [{"text": "Referring Expression Generation (REG)", "start_pos": 87, "end_pos": 124, "type": "TASK", "confidence": 0.825984517733256}]}, {"text": "The model does not only select attributes and values for referring to a target referent, but also performs Linguistic Realisation, generating an actual Noun Phrase.", "labels": [], "entities": [{"text": "Linguistic Realisation", "start_pos": 107, "end_pos": 129, "type": "TASK", "confidence": 0.7123827040195465}]}, {"text": "Our evaluations suggest that the attribute selection aspect of the algorithm exceeds classic REG algorithms, while the Noun Phrases generated are as similar to those in a previously developed corpus as were Noun Phrases produced by anew set of human speakers.", "labels": [], "entities": []}], "introductionContent": [{"text": "Referring Expressions Generation (REG) is a subtask of Natural Language Generation (NLG) that decides how to distinguish a target referent from its distractors, as when we say \"the sofa\", \"the red sofa\", and soon, to distinguish the referent from other furniture.", "labels": [], "entities": [{"text": "Referring Expressions Generation (REG)", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.7898615300655365}, {"text": "Natural Language Generation (NLG)", "start_pos": 55, "end_pos": 88, "type": "TASK", "confidence": 0.8118728299935659}]}, {"text": "Most current REG algorithms are rule-based (, though Machine Learning is also starting to be used (e.g. Di.", "labels": [], "entities": []}, {"text": "REG is usually treated as an independent stage or component of NLG pipelines (e.g..", "labels": [], "entities": []}, {"text": "The present paper changes the relationship between NLG and REG: it regards REG as a special case of usual NLG, and proposes a vector-based algorithm to transform REG tasks into a generic NLG tasks.", "labels": [], "entities": []}, {"text": "The paper adopts the NLG algorithm of our previous work (which is also vector-based;, but certain adaptations needed to be made to allow the algorithm to perform the traditional REG attribute selection task.", "labels": [], "entities": [{"text": "REG attribute selection task", "start_pos": 178, "end_pos": 206, "type": "TASK", "confidence": 0.8329985439777374}]}, {"text": "Our REG algorithm produces referring expressions (REs) by learning from a data-text corpus of REs.", "labels": [], "entities": []}, {"text": "Ina nutshell, the algorithm splits the textual expressions in the training corpus into small spans according to their meaning, and reassembles these spans into new expressions when it refers to a referent.", "labels": [], "entities": []}, {"text": "We evaluate the performance of the REG function on the Tuna corpus () against 3 strong baselines.", "labels": [], "entities": [{"text": "REG", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.5156235098838806}, {"text": "Tuna corpus", "start_pos": 55, "end_pos": 66, "type": "DATASET", "confidence": 0.9633210301399231}]}, {"text": "Experimental results show that our algorithm outperforms the baselines in terms of Dice scores.", "labels": [], "entities": [{"text": "Dice scores", "start_pos": 83, "end_pos": 94, "type": "METRIC", "confidence": 0.7790747880935669}]}, {"text": "An additional experiment also shows positive results for our algorithm on an experts-based evaluation based on a BLEU-based comparison between algorithmgenerated and human-produced referring expressions.", "labels": [], "entities": [{"text": "BLEU-based", "start_pos": 113, "end_pos": 123, "type": "METRIC", "confidence": 0.9974648952484131}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 4: REG evaluation results, showing Dice  scores, standard deviation (SD), PRP scores  Furniture  People", "labels": [], "entities": [{"text": "REG", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.5817450284957886}, {"text": "standard deviation (SD)", "start_pos": 56, "end_pos": 79, "type": "METRIC", "confidence": 0.9543706059455872}]}, {"text": " Table 5: The performance comparison of our al- gorithm (VB-REG) with the Incremental Algo- rithms, Full Brevity algorithm, and Greedy Algo- rithm on Furniture domain.", "labels": [], "entities": []}, {"text": " Table 6: Performance comparison of our al- gorithm (VB-REG) with the Incremental Algo- rithms, Full Brevity algorithm, and Greedy Algo- rithm on the People domain.", "labels": [], "entities": [{"text": "People domain", "start_pos": 150, "end_pos": 163, "type": "DATASET", "confidence": 0.9339827597141266}]}, {"text": " Table 7: 10 fold REG evaluation results of BLEU  scores  Furniture  People  VB-REG expert VB-REG expert", "labels": [], "entities": [{"text": "BLEU", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.9945476055145264}]}]}