{"title": [{"text": "Using Neural Transfer Learning for Morpho-syntactic Tagging of South-Slavic Languages Tweets", "labels": [], "entities": [{"text": "Morpho-syntactic Tagging of South-Slavic Languages Tweets", "start_pos": 35, "end_pos": 92, "type": "TASK", "confidence": 0.8522899647553762}]}], "abstractContent": [{"text": "In this paper, we describe a morpho-syntactic tagger of tweets, an important component of the CEA List DeepLIMA tool which is a multilingual text analysis platform based on deep learning.", "labels": [], "entities": [{"text": "CEA List DeepLIMA", "start_pos": 94, "end_pos": 111, "type": "DATASET", "confidence": 0.9312874873479208}]}, {"text": "This tagger is built for the Morpho-syntactic Tagging of Tweets (MTT) Shared task of the 2018 VarDial Evaluation Campaign.", "labels": [], "entities": [{"text": "Morpho-syntactic Tagging of Tweets (MTT) Shared task", "start_pos": 29, "end_pos": 81, "type": "TASK", "confidence": 0.7477288047472636}, {"text": "VarDial Evaluation Campaign", "start_pos": 94, "end_pos": 121, "type": "DATASET", "confidence": 0.6721197962760925}]}, {"text": "The MTT task focuses on morpho-syntactic annotation of non-canonical Twitter varieties of three South-Slavic languages: Slovene, Croatian and Serbian.", "labels": [], "entities": [{"text": "MTT task", "start_pos": 4, "end_pos": 12, "type": "TASK", "confidence": 0.9070066213607788}]}, {"text": "We propose to use a neural network model trained in an end-to-end manner for the three languages without any need for task or domain specific features engineering.", "labels": [], "entities": []}, {"text": "The proposed approach combines both character and word level representations.", "labels": [], "entities": []}, {"text": "Considering the lack of annotated data in the social media domain for South-Slavic languages, we have also implemented a cross-domain Transfer Learning (TL) approach to exploit any available related out-of-domain annotated data.", "labels": [], "entities": [{"text": "cross-domain Transfer Learning (TL)", "start_pos": 121, "end_pos": 156, "type": "TASK", "confidence": 0.8265355030695597}]}], "introductionContent": [{"text": "Part-of-Speech (POS) tagging is one of the basic and indispensable tasks in any Natural Language Processing (NLP) pipeline; it consists of assigning adequate and unique grammatical categories (Part-ofSpeech tags) to words in the sentence.", "labels": [], "entities": [{"text": "Part-of-Speech (POS) tagging", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.620840460062027}]}, {"text": "When POS tags are enriched by Morpho-Syntactic Descriptions (MSDs), such as gender, case, tenses, etc.", "labels": [], "entities": []}, {"text": "the task is called Morpho-Syntactic Tagging (MST).", "labels": [], "entities": [{"text": "Morpho-Syntactic Tagging (MST)", "start_pos": 19, "end_pos": 49, "type": "TASK", "confidence": 0.7800425469875336}]}, {"text": "As an example, we provide a Slovene sentence with its MS tags in.", "labels": [], "entities": []}, {"text": "MST is a challenging task especially for languages with rich word inflections and free word order like South-Slavic languages.", "labels": [], "entities": [{"text": "MST", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9652714133262634}]}, {"text": "In addition, MST of informal text like social media content of these languages is a more complex task, especially conversational texts.", "labels": [], "entities": [{"text": "MST", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9851323962211609}]}, {"text": "This is due to the conversational nature of the text, the lack of conventional orthography, the noise, linguistic errors, spelling inconsistencies, informal abbreviations and the idiosyncratic style.", "labels": [], "entities": []}, {"text": "Also, social media platforms such as Twitter pose an additional issue by imposing 280 characters limit for each tweet.", "labels": [], "entities": []}, {"text": "While recent approaches based on end-to-end Deep Neural Networks (DNNs) have shown promising results for sequence tagging in many languages such as English, much less work has been done on neural models for MST of Slavic languages.", "labels": [], "entities": [{"text": "sequence tagging", "start_pos": 105, "end_pos": 121, "type": "TASK", "confidence": 0.7034492492675781}, {"text": "MST", "start_pos": 207, "end_pos": 210, "type": "TASK", "confidence": 0.9713906645774841}]}, {"text": "In this paper, we evaluate the effect of using neural networks techniques for MST of South-Slavic tweets, where we are faced with a large number of possible wordclass tags and only a small hand-tagged in-domain dataset.", "labels": [], "entities": [{"text": "MST", "start_pos": 78, "end_pos": 81, "type": "TASK", "confidence": 0.9701547622680664}]}, {"text": "NLP neural models with high performance often require huge volumes of annotated data to produce powerful models and prevent over-fitting.", "labels": [], "entities": []}, {"text": "Consequently, in the case of social media content, it is difficult to achieve the performances of state-of-the-art models based on hand-crafted features by applying neural models trained on small amounts of annotated data.", "labels": [], "entities": []}, {"text": "For this reason, Transfer Learning (TL) was proposed to exploit annotated out-of-domain data-sets.", "labels": [], "entities": [{"text": "Transfer Learning (TL)", "start_pos": 17, "end_pos": 39, "type": "TASK", "confidence": 0.925075089931488}]}, {"text": "TL aims at performing a task on a target dataset using features learned from a source dataset.", "labels": [], "entities": [{"text": "TL", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.7887406945228577}]}, {"text": "The method presented in this work aims to overcome the problem of the lack of annotated data by significantly limiting the necessary data and instead extrapolating the relevant knowledge from another, related domain.", "labels": [], "entities": []}, {"text": "This contribution generalizes previous results for POS tagging of user generated content in social media for five languages: English, French, Italian, German and Spanish (, by applying our approach on three Twitter corpora of South-Slavic languages: Slovene, Croatian, and Serbian.: Example of a morphologically-tagged sentence in Slovene: Toni nobena novost (\"This is not a novelty\" in English) .", "labels": [], "entities": [{"text": "POS tagging of user generated content in social media", "start_pos": 51, "end_pos": 104, "type": "TASK", "confidence": 0.880109084977044}]}], "datasetContent": [{"text": "Cross-domain TL is evaluated on the three languages: Slovene, Serbian and Croatian, following three main phases: (1) training the parent network on the source problem on rich out-of-domain data, (2) transferring weights of the first set of parameters to the target problem (these weights are used to initialize the child model's first set of parameters, rather than starting from a random position 2 ), and finally (3) fine-tuning the child network on low-resource in-domain data.", "labels": [], "entities": [{"text": "TL", "start_pos": 13, "end_pos": 15, "type": "TASK", "confidence": 0.7380000948905945}]}, {"text": "Our experiments have shown that using a smaller learning rate for weights that will be fine-tuned (first set of weights), in comparison to the randomly initialized weights (second set of weights) leads to slightly improvements.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the different source and target data-sets.", "labels": [], "entities": []}, {"text": " Table 3: Ablation study on character-level embedding and pre-trained words embedding for Slovene  tweets MS tagging.", "labels": [], "entities": [{"text": "Slovene  tweets MS tagging", "start_pos": 90, "end_pos": 116, "type": "TASK", "confidence": 0.5375531017780304}]}, {"text": " Table 4: Comparison between our model accuracy on Slovene on the full MSD features and on POS tags.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9463443160057068}, {"text": "Slovene", "start_pos": 51, "end_pos": 58, "type": "DATASET", "confidence": 0.9198806881904602}]}, {"text": " Table 5: Modifications made by transfer learning on Slovene data-set.", "labels": [], "entities": [{"text": "Slovene data-set", "start_pos": 53, "end_pos": 69, "type": "DATASET", "confidence": 0.9147898256778717}]}, {"text": " Table 6: The impact of transfer learning on POS tags prediction on Slovene data-set.", "labels": [], "entities": [{"text": "POS tags prediction", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.7327672441800436}, {"text": "Slovene data-set", "start_pos": 68, "end_pos": 84, "type": "DATASET", "confidence": 0.8068612515926361}]}, {"text": " Table 7: Comparison between the model's performances using Softmax and CRFs layers.", "labels": [], "entities": []}]}