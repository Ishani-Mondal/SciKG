{"title": [{"text": "Aggressive language in an online hacking forum", "labels": [], "entities": [{"text": "Aggressive language", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.6973336935043335}]}], "abstractContent": [{"text": "We probe the heterogeneity in levels of abusive language in different sections of the Inter-net, using an annotated corpus of Wikipedia page edit comments to train a binary classi-fier for abuse detection.", "labels": [], "entities": [{"text": "Inter-net", "start_pos": 86, "end_pos": 95, "type": "DATASET", "confidence": 0.9724001288414001}, {"text": "abuse detection", "start_pos": 189, "end_pos": 204, "type": "TASK", "confidence": 0.7379805147647858}]}, {"text": "Our test data come from the CrimeBB Corpus of hacking-related forum posts and we find that (a) forum interactions are rarely abusive, (b) the abusive language which does exist tends to be relatively mild compared to that found in the Wikipedia comments domain, and tends to involve aggressive posturing rather than hate speech or threats of violence.", "labels": [], "entities": [{"text": "CrimeBB Corpus of hacking-related forum posts", "start_pos": 28, "end_pos": 73, "type": "DATASET", "confidence": 0.9626658161481222}]}, {"text": "We observe that the purpose of conversations in online forums tend to be more constructive and informative than those in Wikipedia page edit comments which are geared more towards adversarial interactions , and that this may explain the lower levels of abuse found in our forum data than in Wikipedia comments.", "labels": [], "entities": []}, {"text": "Further work remains to be done to compare these results with other inter-domain classification experiments, and to understand the impact of aggressive language in forum conversations.", "labels": [], "entities": [{"text": "inter-domain classification", "start_pos": 68, "end_pos": 95, "type": "TASK", "confidence": 0.7572479546070099}]}], "introductionContent": [{"text": "The automatic identification of abusive language online 1 is of growing interest and concerns have proliferated about aggressive Internet behaviours commonly known as 'trolling'.", "labels": [], "entities": [{"text": "automatic identification of abusive language online 1", "start_pos": 4, "end_pos": 57, "type": "TASK", "confidence": 0.7963870338031224}]}, {"text": "From an applications perspective, the accurate detection of vitriolic language is one of the clearest examples of natural language processing for social good, assuming data has been collected ethically and stored legally, and that any intervention is left to the appropriate authorities (.", "labels": [], "entities": [{"text": "accurate detection of vitriolic language", "start_pos": 38, "end_pos": 78, "type": "TASK", "confidence": 0.7287949204444886}, {"text": "natural language processing", "start_pos": 114, "end_pos": 141, "type": "TASK", "confidence": 0.7254221638043722}]}, {"text": "Meanwhile from a theoretical point of view, there are many outstanding linguistic and sociological research questions surrounding Internet aggression and how it manifests itself in writing ().", "labels": [], "entities": []}, {"text": "The question we address here is whether online abusive language is of one type or whether there is discernible variation in the level of abuse found in different subsections of the Internet.", "labels": [], "entities": []}, {"text": "We do not claim to have the final answer to this nebulous question, but instead we have addressed one small part of the whole: is the level of abuse found in one Internet domain -namely discussions about English Wikipedia page edits -similar to that found in another domain, that of an online hacking forum?", "labels": [], "entities": []}, {"text": "We show that the type of abusive language occurring in the latter is more closely aligned with the milder levels of abuse of those found in Wikipedia discussions, and consider why this might be.", "labels": [], "entities": []}, {"text": "We observe that the online hacking forum tends to contain texts aimed at helping or informing other users, whereas the Wikipedia conversations are inherently more adversarial since they relate to recent page edits and disputes arising.", "labels": [], "entities": []}, {"text": "Where abusive language is found in the online hacking forum, it tends to involve profane namecalling, insults and heated disputes, rather than hate speech or threats of violence -those which have tended to be the more prominent causes for public concern.", "labels": [], "entities": []}, {"text": "Note here that we make a distinction between aggressive and offensive language: the former often involves the latter, but not always so.", "labels": [], "entities": []}, {"text": "Offensive language -identifiable word tokens such as swearwords and the like -may offend but is not always used aggressively; sometimes it is used in a jocular fashion, for example.", "labels": [], "entities": []}, {"text": "Aggressive language, which more often than not is built on the composition of many words, involves a hostile stance from one speaker or writer to another.", "labels": [], "entities": []}, {"text": "It is this which might seem to be abusive and which we seek to automatically detect and better understand.", "labels": [], "entities": []}, {"text": "We also distinguish aggressive language from hate speech -that which might be characterised as prejudicial diatribes to provoke action, perhaps violent, against a group or groups -and from cyberbullying -that which involves a sustained period of persecution against an individual or individuals.", "labels": [], "entities": []}, {"text": "Certainly the distinctions are fuzzy at the edges, but these might bethought of as the canonical definitions of these abuse types.", "labels": [], "entities": []}, {"text": "We are dealing with what we deem to be one-off instances of aggression in online communities, though if these were shown to be prejudicial against a group, or sustained against an individual, then the instances start to move into hate speech or cyberbullying behaviours.", "labels": [], "entities": []}, {"text": "In both Wikipedia edits and the online hacking forum, abusive comments are infrequent in the community as a whole and the general objective of gaining reputation in the domain dis-incentivises aggressive behaviour.", "labels": [], "entities": []}, {"text": "Nevertheless we show that aggressive language which does occur maybe detected fairly well by training on the Wikipedia edits corpus -the advantage being that it has been multiply and widely annotated -and setting the threshold fora binary aggression classifier at a fairly moderate level relative to the worst types of abuse found in Wikipedia comments.", "labels": [], "entities": [{"text": "Wikipedia edits corpus", "start_pos": 109, "end_pos": 131, "type": "DATASET", "confidence": 0.8869555592536926}]}, {"text": "Future work remains to be done to more broadly characterise intra-community behaviour in different subsections of the Internet.", "labels": [], "entities": []}], "datasetContent": [{"text": "We trained a binary aggression classifier on the WikiComments Corpus setting the true/false threshold tat each attack score from 1 to 10 and testing the classifier on our annotated set of 4123 HackForums posts from the CrimeBB Corpus.", "labels": [], "entities": [{"text": "WikiComments Corpus", "start_pos": 49, "end_pos": 68, "type": "DATASET", "confidence": 0.9653416872024536}, {"text": "HackForums posts from the CrimeBB Corpus", "start_pos": 193, "end_pos": 233, "type": "DATASET", "confidence": 0.8152529696623484}]}, {"text": "We are interested in the successful classification of aggressive posts only and therefore, rather than reporting precision, recall and F -measures, we re-  port accuracy as in equation: Accuracy = true positives true positives + false negatives (1)", "labels": [], "entities": [{"text": "classification of aggressive posts", "start_pos": 36, "end_pos": 70, "type": "TASK", "confidence": 0.8078276515007019}, {"text": "precision", "start_pos": 113, "end_pos": 122, "type": "METRIC", "confidence": 0.9948092699050903}, {"text": "recall", "start_pos": 124, "end_pos": 130, "type": "METRIC", "confidence": 0.9993892908096313}, {"text": "F -measures", "start_pos": 135, "end_pos": 146, "type": "METRIC", "confidence": 0.995533287525177}, {"text": "accuracy", "start_pos": 161, "end_pos": 169, "type": "METRIC", "confidence": 0.9989604949951172}, {"text": "Accuracy", "start_pos": 186, "end_pos": 194, "type": "METRIC", "confidence": 0.9989567995071411}]}], "tableCaptions": [{"text": " Table 1: Examples, the number of posts, and the cumulative size (in reverse order) for each attack score subset of  the Wikipedia Comments Corpus (Wulczyn et al., 2017).", "labels": [], "entities": [{"text": "Wikipedia Comments Corpus", "start_pos": 121, "end_pos": 146, "type": "DATASET", "confidence": 0.8698018590609232}]}, {"text": " Table 3: Classification accuracy for aggressive posts in  the CrimeBB Corpus, with a varying true/false training  threshold t from 1 to 10, the size of the aggression:true  set in WikiComments for different values of t, accu- racy for all training WikiComments instances, and a  controlled experiment sampling 3223 true and false in- stances (averaged over 100 runs).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9819791316986084}, {"text": "CrimeBB Corpus", "start_pos": 63, "end_pos": 77, "type": "DATASET", "confidence": 0.9824781715869904}, {"text": "accu", "start_pos": 221, "end_pos": 225, "type": "METRIC", "confidence": 0.9792836904525757}]}]}