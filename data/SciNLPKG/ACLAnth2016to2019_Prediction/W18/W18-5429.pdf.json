{"title": [{"text": "Importance of Self-Attention for Sentiment Analysis", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 33, "end_pos": 51, "type": "TASK", "confidence": 0.9793522953987122}]}], "abstractContent": [{"text": "Despite their superior performance, deep learning models often lack interpretability.", "labels": [], "entities": []}, {"text": "In this paper, we explore the modeling of insight-ful relations between words, in order to understand and enhance predictions.", "labels": [], "entities": []}, {"text": "To this effect , we propose the Self-Attention Network (SANet), a flexible and interpretable architecture for text classification.", "labels": [], "entities": [{"text": "text classification", "start_pos": 110, "end_pos": 129, "type": "TASK", "confidence": 0.8203675448894501}]}, {"text": "Experiments indicate that gains obtained by self-attention is task-dependent.", "labels": [], "entities": []}, {"text": "For instance, experiments on sentiment analysis tasks showed an improvement of around 2% when using self-attention compared to a baseline without attention , while topic classification showed no gain.", "labels": [], "entities": [{"text": "sentiment analysis tasks", "start_pos": 29, "end_pos": 53, "type": "TASK", "confidence": 0.9517112374305725}, {"text": "topic classification", "start_pos": 164, "end_pos": 184, "type": "TASK", "confidence": 0.8119833469390869}]}, {"text": "Interpretability brought forward by our architecture highlighted the importance of neighboring word interactions to extract sentiment.", "labels": [], "entities": []}], "introductionContent": [{"text": "Deep neural networks have achieved great successes on numerous tasks.", "labels": [], "entities": []}, {"text": "However, they are often seen as black boxes, lacking interpretability.", "labels": [], "entities": []}, {"text": "Research efforts in order to solve this issue have steadily increased.", "labels": [], "entities": []}, {"text": "In language modeling, interpretability often takes place via an attention mechanism in the neural network.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 3, "end_pos": 20, "type": "TASK", "confidence": 0.7322774827480316}, {"text": "interpretability", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.9602678418159485}]}, {"text": "In this context, attention essentially allows a network to identify which words in a sentence are more relevant.", "labels": [], "entities": []}, {"text": "Beyond interpretability, this often results in improved decision making by the network.", "labels": [], "entities": []}, {"text": "Recently, proposed the Transformer architecture for machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.8352709412574768}]}, {"text": "It relies only on attention mechanisms, instead of making use of either recurrent or convolutional * Authors contributed equally to this work.", "labels": [], "entities": []}, {"text": "This architecture contains layers called self-attention (or intra-attention) which allow each word in the sequence to pay attention to other words in the sequence, independently of their positions.", "labels": [], "entities": []}, {"text": "We modified this architecture, resulting in the following contributions: \u2022 A novel architecture for text classification called Self-Attention Network (SANet) that models the interactions between all input word pairs.", "labels": [], "entities": [{"text": "text classification", "start_pos": 100, "end_pos": 119, "type": "TASK", "confidence": 0.7343255877494812}]}, {"text": "It is sequence length-agnostic, thanks to a global max pooling layer.", "labels": [], "entities": []}, {"text": "\u2022 A study on the impact of this self-attention mechanism on large scale datasets.", "labels": [], "entities": []}, {"text": "In particular, we empirically demonstrate the positive impact of self-attention in terms of performance and interpretability for sentiment analysis, compared to topic classification.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 129, "end_pos": 147, "type": "TASK", "confidence": 0.9589762389659882}, {"text": "topic classification", "start_pos": 161, "end_pos": 181, "type": "TASK", "confidence": 0.7278295010328293}]}, {"text": "In the study, we make use of two quantitative metrics (Gini coefficient and diagonality) that exhibit particular behaviors for attention mechanisms in sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 151, "end_pos": 169, "type": "TASK", "confidence": 0.9549405574798584}]}], "datasetContent": [{"text": "We evaluated our model on seven large scale text classification datasets introduced by, grouped into two kinds of tasks.", "labels": [], "entities": [{"text": "text classification", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.723243236541748}]}, {"text": "The first one is topic classification: AG's News with 4 classes of news articles, DBPedia with 14 classes of the Wikipedia ontology and Yahoo!", "labels": [], "entities": [{"text": "topic classification", "start_pos": 17, "end_pos": 37, "type": "TASK", "confidence": 0.79381063580513}, {"text": "AG's News", "start_pos": 39, "end_pos": 48, "type": "DATASET", "confidence": 0.9090579152107239}, {"text": "DBPedia", "start_pos": 82, "end_pos": 89, "type": "DATASET", "confidence": 0.9166227579116821}]}, {"text": "Answers containing 10 categories of questions/answers.", "labels": [], "entities": []}, {"text": "Yelp and Amazon reviews involve sentiment analysis with ratings from 1 to 5 stars.", "labels": [], "entities": [{"text": "Yelp", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9771564602851868}, {"text": "sentiment analysis", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.9642059803009033}]}, {"text": "Two versions are derived from those datasets: one for predicting the number of stars, and the other involving the polarity of the reviews (negative for 1-2 stars, positive for 4-5 stars).", "labels": [], "entities": []}, {"text": "Each text entry was split into sentences and tokenized using NLTK ().", "labels": [], "entities": [{"text": "NLTK", "start_pos": 61, "end_pos": 65, "type": "DATASET", "confidence": 0.804397463798523}]}, {"text": "Sequences longer than 1000 tokens were truncated to accommodate GPU memory limitations, only affecting a negligible portion of the texts.", "labels": [], "entities": []}, {"text": "See for: Test error rates (%) for text classification.", "labels": [], "entities": [{"text": "Test error rates", "start_pos": 9, "end_pos": 25, "type": "METRIC", "confidence": 0.7801809112230936}, {"text": "text classification", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.831422358751297}]}, {"text": "In bold, the state-of-the-art and in italic, our best model.", "labels": [], "entities": []}, {"text": "'s results provided by We used 20% of the training texts for validation.", "labels": [], "entities": []}, {"text": "The vocabulary was built using every word appearing in the training and validation sets.", "labels": [], "entities": []}, {"text": "The words embeddings were initialized using pre-trained word vectors from GloVe () when available, or randomly initialized otherwise.", "labels": [], "entities": []}, {"text": "We experimented with two configurations for our proposed SANet.", "labels": [], "entities": []}, {"text": "The base model used N = 1 self-attention blocks, an embedding size of 100 and a hidden size of d = 128.", "labels": [], "entities": []}, {"text": "The big model doubled these numbers, i.e. N = 2 self-attention blocks, embedding size of 200 and hidden size d = 256.", "labels": [], "entities": []}, {"text": "For each configuration, we also trained a baseline network without any attention mechanisms, replacing each self-attention layer with a feed forward layer.", "labels": [], "entities": []}, {"text": "Training was performed using SGD with a momentum of 0.9, a learning rate of 0.01 and minibatches of size 128.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 59, "end_pos": 72, "type": "METRIC", "confidence": 0.9696733951568604}]}, {"text": "For the embeddings, a learning rate of 0.001 was applied without momentum.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 22, "end_pos": 35, "type": "METRIC", "confidence": 0.9767059981822968}]}, {"text": "All learning rates were halved for the big model.", "labels": [], "entities": []}, {"text": "We trained for 40 epochs and selected the best epoch, based on validation accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9331761598587036}]}], "tableCaptions": [{"text": " Table 1: Test error rates (%) for text classification. In bold, the state-of-the-art and in italic, our best  model.", "labels": [], "entities": [{"text": "Test error rates", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.8652371366818746}, {"text": "text classification", "start_pos": 35, "end_pos": 54, "type": "TASK", "confidence": 0.8623611629009247}]}, {"text": " Table 2: Quantitative statistics of the self-attention mechanism behavior for the two text classification  tasks. Metrics are computed on the testing sets using the SANet base model.", "labels": [], "entities": [{"text": "text classification  tasks", "start_pos": 87, "end_pos": 113, "type": "TASK", "confidence": 0.7773693104585012}, {"text": "SANet base model", "start_pos": 166, "end_pos": 182, "type": "DATASET", "confidence": 0.8776742219924927}]}]}