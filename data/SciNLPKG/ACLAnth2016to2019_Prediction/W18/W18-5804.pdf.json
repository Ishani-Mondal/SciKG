{"title": [{"text": "Adaptor Grammars for the Linguist: Word Segmentation Experiments for Very Low-Resource Languages", "labels": [], "entities": [{"text": "Word Segmentation", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.7281686067581177}]}], "abstractContent": [{"text": "Computational Language Documentation attempts to make the most recent research in speech and language technologies available to linguists working on language preservation and documentation.", "labels": [], "entities": [{"text": "Computational Language Documentation", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.7490822672843933}, {"text": "language preservation and documentation", "start_pos": 149, "end_pos": 188, "type": "TASK", "confidence": 0.7584795206785202}]}, {"text": "In this paper, we pursue two main goals along these lines.", "labels": [], "entities": []}, {"text": "The first is to improve upon a strong baseline for the unsu-pervised word discovery task on two very low-resource Bantu languages, taking advantage of the expertise of linguists on these particular languages.", "labels": [], "entities": [{"text": "word discovery task", "start_pos": 69, "end_pos": 88, "type": "TASK", "confidence": 0.8185636599858602}]}, {"text": "The second consists in exploring the Adaptor Grammar framework as a decision and prediction tool for linguists studying anew language.", "labels": [], "entities": [{"text": "decision and prediction", "start_pos": 68, "end_pos": 91, "type": "TASK", "confidence": 0.679009219010671}]}, {"text": "We experiment 162 grammar configurations for each language and show that using Adaptor Grammars for word segmenta-tion enables us to test hypotheses about a language.", "labels": [], "entities": []}, {"text": "Specializing a generic grammar with language specific knowledge leads to great improvements for the word discovery task, ultimately achieving a leap of about 30% token F-score from the results of a strong baseline.", "labels": [], "entities": [{"text": "word discovery task", "start_pos": 100, "end_pos": 119, "type": "TASK", "confidence": 0.870540996392568}, {"text": "F-score", "start_pos": 168, "end_pos": 175, "type": "METRIC", "confidence": 0.972019612789154}]}], "introductionContent": [{"text": "A large number of the world's languages are expected to go extinct during this century -as much as half of them according to and.", "labels": [], "entities": []}, {"text": "Such predictions have subsequently fostered a growing interest fora new field, Computational Language Documentation (CLD), as it is now clear that traditional field linguistics alone will not meet the challenge of preserving and documenting all of these languages.", "labels": [], "entities": [{"text": "Computational Language Documentation (CLD)", "start_pos": 79, "end_pos": 121, "type": "TASK", "confidence": 0.8211424152056376}]}, {"text": "CLD attempts to make the most recent research in speech and language technologies available to linguists working on language preservation and documentation (e.g. ().", "labels": [], "entities": [{"text": "CLD", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8671073317527771}, {"text": "language preservation and documentation", "start_pos": 116, "end_pos": 155, "type": "TASK", "confidence": 0.7596803307533264}]}, {"text": "A remarkable effort in this direction has improved the data collection tools to be used on the field (), enabling to collect corpora for several endangered languages . In parallel, the language technology community is investing more efforts to design methodologies tailored for the new challenges posed by the analysis of such linguistic material: the extreme variability of the orthographic representation, the scarcity of annotated data (both written and oral), as well as the modeling of complex tonal systems.", "labels": [], "entities": []}, {"text": "This effort could greatly benefit from a tighter collaboration between the two main research communities involved in this endeavor, which often struggle to cooperate efficiently.", "labels": [], "entities": []}, {"text": "Knowledge background differs between linguists and computer scientists; the definition of why a problem is interesting or not may not be the same for the two communities, theoretical and experimental platforms do not intersect much, etc.", "labels": [], "entities": []}, {"text": "Consequently, for lack of investing enough energy working on the same problems with the same tools and towards the same goals, we might not achieve the efficiency that is needed, as time is running out for many languages.", "labels": [], "entities": []}, {"text": "This view constitutes the underlying motivation of the work reported here.", "labels": [], "entities": []}, {"text": "We pursue two main goals in this spirit.", "labels": [], "entities": []}, {"text": "The first one is to improve upon a strong baseline () for the unsupervised word discovery task 1 on two low-resource languages, by teaming up with linguist experts.", "labels": [], "entities": [{"text": "word discovery task", "start_pos": 75, "end_pos": 94, "type": "TASK", "confidence": 0.8113648295402527}]}, {"text": "A natural idea to achieve this goal is to engage them in formalizing their linguistic knowledge regarding the languages or language families understudy, in the hope that it will compensate for the small amount of available data.", "labels": [], "entities": []}, {"text": "In our case, this expertise corresponds to morphological and phonotactic constraints for two Bantu languages displaying very similar structures (see Section 3).", "labels": [], "entities": []}, {"text": "For one language, we were also able to elicit a list of prefixes and some additional knowledge regarding the consonantal system.", "labels": [], "entities": []}, {"text": "Such expert knowledge can readily be integrated in grammar rules using the framework of Adaptor Grammars (see Section 6).", "labels": [], "entities": []}, {"text": "Another interesting property of this framework is its compatibility with two strategies that are usually thought as being mutually exclusive: rule-based learning, still in wide use inside the linguistics community, and statistical learning, prevalent in natural language processing circles.", "labels": [], "entities": []}, {"text": "Our second goal is to study ways to help linguists explore language data when little expert knowledge is available.", "labels": [], "entities": []}, {"text": "Our proposal is to complement the grammatical description activity with task-oriented search procedures, that will speedup the exploration of competing hypotheses.", "labels": [], "entities": [{"text": "grammatical description", "start_pos": 34, "end_pos": 57, "type": "TASK", "confidence": 0.695514053106308}]}, {"text": "The intuition is that better grammars should not only truthfully match the empirical data, but also improve the quality of automatic analysis processes.", "labels": [], "entities": []}, {"text": "The word discovery task considered below should thus be viewed as an extrinsic validation procedure, rather than a goal in and of itself.", "labels": [], "entities": [{"text": "word discovery task", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.840145210425059}]}, {"text": "This process might also yield new linguistic insights regarding the language(s) under focus.", "labels": [], "entities": []}, {"text": "To sum up, the main contribution of this paper is a methodology for systematically exploring (a subpart of) the space of possible grammars, refining grammar rules (from the most generic to the most language specific) at four levels of description (see Section 4).", "labels": [], "entities": []}, {"text": "This results in a comparison of 162 alternative accounts of the grammar for two languages.", "labels": [], "entities": []}, {"text": "Our results (analyzed in Section 5) show that enriching grammar rules with language specific knowledge has a consistent positive impact in performance for the segmentation task.", "labels": [], "entities": [{"text": "segmentation task", "start_pos": 159, "end_pos": 176, "type": "TASK", "confidence": 0.9203062355518341}]}, {"text": "They validate our hypotheses that (a) improved grammatical descriptions actually correlate with better automatic analysis; (b) Adaptor Grammars provide a framework around which linguists and computer scientists can effectively collaborate, with tangible results for both communities.", "labels": [], "entities": []}], "datasetContent": [{"text": "We now experiment along the methodology presented in Section 4.", "labels": [], "entities": []}, {"text": "We report word segmentation performance using precision, recall, and Fmeasure on tokens (WP, WR, WF), and types (LP, LR, LF).", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.7141472548246384}, {"text": "precision", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.999404788017273}, {"text": "recall", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.9988239407539368}, {"text": "Fmeasure", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9994925260543823}]}, {"text": "We also report the exact-match (X) metric which calculates the proportion of correctly segmented utterances.", "labels": [], "entities": [{"text": "exact-match (X) metric", "start_pos": 19, "end_pos": 41, "type": "METRIC", "confidence": 0.9614927649497986}]}, {"text": "For each language, we evaluate our 162 grammar configurations using Mark Johnson's code, collecting parses after 2,000 sampling steps.", "labels": [], "entities": []}, {"text": "We adapt all non-recursive non-terminals and use a Dirichlet prior to estimate the rule probabilities.", "labels": [], "entities": []}, {"text": "We place a uniform Beta prior on the discount parameter of the Pitman-Yor process, and a vague Gamma prior on the concentration parameter.", "labels": [], "entities": []}, {"text": "presents token metrics (WP, WR, WF) and type metrics (LP, LR, LF), as well as sentence exact-match (X) for both corpora on all grammars.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1.  The Mboshi corpus is more comprehensively de- scribed in (", "labels": [], "entities": [{"text": "Mboshi corpus", "start_pos": 15, "end_pos": 28, "type": "DATASET", "confidence": 0.9343646764755249}]}]}