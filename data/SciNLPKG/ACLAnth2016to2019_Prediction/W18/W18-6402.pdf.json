{"title": [{"text": "Findings of the Third Shared Task on Multimodal Machine Translation", "labels": [], "entities": [{"text": "Multimodal Machine Translation", "start_pos": 37, "end_pos": 67, "type": "TASK", "confidence": 0.6464204986890157}]}], "abstractContent": [{"text": "We present the results from the third shared task on multimodal machine translation.", "labels": [], "entities": [{"text": "multimodal machine translation", "start_pos": 53, "end_pos": 83, "type": "TASK", "confidence": 0.622799148162206}]}, {"text": "In this task a source sentence in English is supplemented by an image and participating systems are required to generate a translation for such a sentence into German, French or Czech.", "labels": [], "entities": []}, {"text": "The image can be used in addition to (or instead of) the source sentence.", "labels": [], "entities": []}, {"text": "This year the task was extended with a third target language (Czech) and anew test set.", "labels": [], "entities": []}, {"text": "In addition, a variant of this task was introduced with its own test set where the source sentence is given in multiple languages: English, French and German, and participating systems are required to generate a translation in Czech.", "labels": [], "entities": []}, {"text": "Seven teams submitted 45 different systems to the two variants of the task.", "labels": [], "entities": []}, {"text": "Compared to last year, the performance of the multimodal submissions improved, but text-only systems remain competitive.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Shared Task on Multimodal Machine Translation tackles the problem of generating a description of an image in a target language using the image itself and its English description.", "labels": [], "entities": [{"text": "Multimodal Machine Translation", "start_pos": 19, "end_pos": 49, "type": "TASK", "confidence": 0.5864240229129791}]}, {"text": "This task can be addressed as either a pure translation task from the source English descriptions (ignoring the corresponding image), or as a multimodal translation task where the translation process is guided by the image in addition to the source description.", "labels": [], "entities": []}, {"text": "Initial results in this area showed the potential for visual context to improve translation quality).", "labels": [], "entities": [{"text": "translation", "start_pos": 80, "end_pos": 91, "type": "TASK", "confidence": 0.9528629183769226}]}, {"text": "This was followed by a wide range of work in the first two editions of this shared task at the WMT in . This year we challenged participants to target the task of multimodal translation, with two variants: \u2022 Task 1: Multimodal translation takes an image with a source language description that is then translated into a target language.", "labels": [], "entities": [{"text": "WMT in", "start_pos": 95, "end_pos": 101, "type": "DATASET", "confidence": 0.9469489455223083}, {"text": "multimodal translation", "start_pos": 163, "end_pos": 185, "type": "TASK", "confidence": 0.723324716091156}, {"text": "Multimodal translation", "start_pos": 216, "end_pos": 238, "type": "TASK", "confidence": 0.7681529819965363}]}, {"text": "The training data consists of source-target parallel sentences and their corresponding images.", "labels": [], "entities": []}, {"text": "\u2022 Task 1b: Multisource multimodal translation takes an image with a description in three source languages that is then translated into a target language.", "labels": [], "entities": [{"text": "Multisource multimodal translation", "start_pos": 11, "end_pos": 45, "type": "TASK", "confidence": 0.6913896997769674}]}, {"text": "The training data consists of source-target parallel data and their corresponding images, but where the source sentences are presented in three different languages, all parallel.", "labels": [], "entities": []}, {"text": "Task 1 is identical to previous editions of the shared task, however, it now includes an additional Czech target language.", "labels": [], "entities": []}, {"text": "Therefore, participants can submit translations to any of the following languages: German, French and Czech.", "labels": [], "entities": []}, {"text": "This extension means the Multi30K dataset ) is now 5-way aligned, with images described in English, which are translated into German, French and Czech.", "labels": [], "entities": [{"text": "Multi30K dataset", "start_pos": 25, "end_pos": 41, "type": "DATASET", "confidence": 0.9421861171722412}]}, {"text": "1 Task 1b is similar to Task 1; the main difference is that multiple source languages can be used (simultaneously) and Czech is the only target language.", "labels": [], "entities": []}, {"text": "We introduce two new evaluation sets that extend the existing Multi30K dataset: a set of 1071 English sentences and their corresponding images and translations for Task 1, and 1,000 translations for the 2017 test set into Czech for Task 1b.", "labels": [], "entities": [{"text": "Multi30K dataset", "start_pos": 62, "end_pos": 78, "type": "DATASET", "confidence": 0.9174988567829132}]}, {"text": "Another new feature of this year's shared task is the introduction of anew evaluation metric: Lexical Translation Accuracy (LTA), which measures the accuracy of a system at translating correctly a subset of ambiguous source language words.", "labels": [], "entities": [{"text": "Lexical Translation Accuracy (LTA)", "start_pos": 94, "end_pos": 128, "type": "METRIC", "confidence": 0.7571540127197901}, {"text": "accuracy", "start_pos": 149, "end_pos": 157, "type": "METRIC", "confidence": 0.9932543635368347}]}, {"text": "Participants could submit both constrained (shared task data only) and unconstrained (any data) systems for both tasks, with a limit of two systems per task variant and language pair per team.", "labels": [], "entities": []}], "datasetContent": [{"text": "The Multi30K dataset ) is the primary resource for the shared task.", "labels": [], "entities": [{"text": "Multi30K dataset", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.9156704843044281}]}, {"text": "It contains 31K images originally described in) with two types of multilingual data: a collection of professionally translated German sentences, and a collection of independently crowdsourced German descriptions.", "labels": [], "entities": []}, {"text": "Over the two last years, we have extended the Multi30K dataset with 2,071 new images and two additional languages for the translation task: French and Czech.", "labels": [], "entities": [{"text": "Multi30K dataset", "start_pos": 46, "end_pos": 62, "type": "DATASET", "confidence": 0.9211144149303436}, {"text": "translation task", "start_pos": 122, "end_pos": 138, "type": "TASK", "confidence": 0.916453629732132}]}, {"text": "presents an overview of the new evaluation datasets.", "labels": [], "entities": []}, {"text": "shows an example of an image with an aligned EnglishGerman-French-Czech description.", "labels": [], "entities": []}, {"text": "This year we also released anew version of the evaluation datasets featuring a subset of sentences that contain ambiguous source language words, which may have different senses in the target language.", "labels": [], "entities": []}, {"text": "We expect that these ambiguous words could benefit from additional visual context.", "labels": [], "entities": []}, {"text": "In addition to releasing the parallel text, we also distributed two types of visual features extracted from a pre-trained ResNet-50 object recognition model) for all of the images, namely the 'res4 relu' convolutional features (which preserve the spatial location of a feature in the original image) and averaged pooled features.", "labels": [], "entities": [{"text": "ResNet-50 object recognition", "start_pos": 122, "end_pos": 150, "type": "TASK", "confidence": 0.6120907465616862}]}, {"text": "As our new evaluation data for Task 1, we collected German, French and Czech translations for the test set used in the 2017 edition of the Multilingual Image Description Generation task, which only contained English descriptions.", "labels": [], "entities": [{"text": "Multilingual Image Description Generation task", "start_pos": 139, "end_pos": 185, "type": "TASK", "confidence": 0.8101451694965363}]}, {"text": "This test set contains images from five of the six Flickr groups used to create the original Flickr30K dataset 2 . We Training set Development set Test set 2018 - 1,000  sampled additional images from two thematically related groups (Everything Outdoor and Flickr Social Club) because Outdoor Activities only returned 10 new CC-licensed images and Flickr-Social no longer exists.", "labels": [], "entities": [{"text": "Flickr30K dataset 2 . We Training set Development set Test set", "start_pos": 93, "end_pos": 155, "type": "DATASET", "confidence": 0.9325819232247092}, {"text": "Flickr-Social", "start_pos": 348, "end_pos": 361, "type": "DATASET", "confidence": 0.9562633633613586}]}, {"text": "The translations were collected using the same procedure as before for each of the languages: professional translations for German and internally crowdsourced translations for French and Czech (see ), as described above.", "labels": [], "entities": []}, {"text": "The new evaluation data for Task 1b consists of Czech translations, which we collected following the procedure described above.", "labels": [], "entities": []}, {"text": "shows the distribution of images across the groups and tasks.", "labels": [], "entities": []}, {"text": "We initially downloaded 2,000 images per Flickr group, which were then manually filtered by three of the authors.", "labels": [], "entities": [{"text": "Flickr group", "start_pos": 41, "end_pos": 53, "type": "DATASET", "confidence": 0.9451971054077148}]}, {"text": "The filtering was done to remove (near) duplicate images, clearly watermarked images, and images with dubious content.", "labels": [], "entities": []}, {"text": "This process resulted in a total of 2,071 images, 1,000 were used for Task 1 and 1,071 for Task 1b.", "labels": [], "entities": []}, {"text": "In this year's task we also evaluate systems using Lexical Translation Accuracy (LTA) (Lala and Specia, 2018).", "labels": [], "entities": [{"text": "Lexical Translation Accuracy (LTA)", "start_pos": 51, "end_pos": 85, "type": "METRIC", "confidence": 0.7296354174613953}]}, {"text": "LTA measures how accurately a system translates a subset of ambiguous words found in the Multi30K corpus.", "labels": [], "entities": [{"text": "Multi30K corpus", "start_pos": 89, "end_pos": 104, "type": "DATASET", "confidence": 0.9217047691345215}]}, {"text": "To measure this accuracy, we extract a subset of triplets form the Multi30K dataset in the form (i, aw, clt) where i is the index representing an instance in the test set, aw is an ambiguous word in English found in that instance i, and clt is the set of correct lexical translations of aw in the target language that conform to the context i.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9993683695793152}, {"text": "Multi30K dataset", "start_pos": 67, "end_pos": 83, "type": "DATASET", "confidence": 0.9795706868171692}]}, {"text": "A word is said to be ambiguous in the source language if it has multiple translations (as given in the Multi30K corpus) with different meanings.", "labels": [], "entities": [{"text": "Multi30K corpus", "start_pos": 103, "end_pos": 118, "type": "DATASET", "confidence": 0.911120742559433}]}, {"text": "We prepared the evaluation dataset following the procedure described in , with some additional steps.", "labels": [], "entities": []}, {"text": "First, the parallel text in the Multi30K training and the validation sets are decompounded with SECOS () (for German only) and lemmatised . Second, we perform automatic word alignment using fast align to identify the English words that are aligned to two or more different words in the target language.", "labels": [], "entities": [{"text": "SECOS", "start_pos": 96, "end_pos": 101, "type": "METRIC", "confidence": 0.9944018721580505}, {"text": "word alignment", "start_pos": 169, "end_pos": 183, "type": "TASK", "confidence": 0.689164936542511}]}, {"text": "This step results in a dictionary of {key : val} pairs, where key is a potentially ambiguous English word, and val is the set of words in the target language that align to key.", "labels": [], "entities": []}, {"text": "This dictionary is then filtered by humans, students of translation studies who are fluent in both the source and target languages, to remove incorrect/noisy alignments and unambiguous instances, resulting in a cleaned dictionary containing {aw : lt} pairs, where aw is an ambiguous English word, and lt is the set of lexical translations of aw in the corpus.", "labels": [], "entities": []}, {"text": "For English-Czech, we were unable to perform this 'human filtering' step, and so we use the unfiltered, noisy dictionary.", "labels": [], "entities": []}, {"text": "Table 3 shows summary statistics about number of ambiguous words and the total number of their instances in the training and validation sets.", "labels": [], "entities": []}, {"text": "Given a dictionary, we identify instances i in the test sets which contain an ambiguous word aw from the dictionary, resulting in triplets of the form (i, aw, lt  annotators (students of translation studies) to select, from the set of lexical translations lt, only those translations, denoted as clt, which conform to the source context i -both image and its English description.", "labels": [], "entities": []}, {"text": "For example, in the test instance shown in, hat is an ambiguous word aw and {kappe, m\u00fctze, h\u00fcten, kopf, kopfbedeckung, kopfbedeckungen, hut, helm, h\u00fcte, helmen, m\u00fctzen} is the set of its lexical translations lt.", "labels": [], "entities": []}, {"text": "The human annotator looked at both the image and its description and then selected the following subset {kappe, m\u00fctze, m\u00fctzen} as the correct lexical translations clt that conform to the context of the test instance in.", "labels": [], "entities": []}, {"text": "We also asked annotators to expand the clt set with other synonyms outside the lt set that satisfy the context if they can.", "labels": [], "entities": []}, {"text": "The number of ambiguous words and instances for each language pair in the resulting dataset for the test instances is given in.", "labels": [], "entities": []}, {"text": "For English-Czech, while the first human filtering step (dictionary filtering) was not performed, the second human filtering step (test set filtering) was done.", "labels": [], "entities": [{"text": "dictionary filtering)", "start_pos": 57, "end_pos": 78, "type": "TASK", "confidence": 0.7662597000598907}]}, {"text": "We note that this cleaning done by the Czech-English annotators was very selective, most likely due to the noisier nature of the initial annotations from the unfiltered dictionary.", "labels": [], "entities": []}, {"text": "Given a human filtered dictionary, the LTA evaluation is straight forward: for each MT system submission, we check if any word in clt is found in the translation of the submission's i th instance.The preprocessing steps may result in mismatches due to sub-optimal handling of morphological variants, but we do not expect this to be a rare event because the dictionaries, gold standard text, and system submissions are pre-processed using the same tools.", "labels": [], "entities": [{"text": "MT system submission", "start_pos": 84, "end_pos": 104, "type": "TASK", "confidence": 0.8766476313273112}]}], "tableCaptions": [{"text": " Table 1: Overview of the Multi30K training, development and 2018 test datasets. The figures correspond  to tuples with an image and parallel sentences in four languages: English, German, French and Czech.", "labels": [], "entities": []}, {"text": " Table 2: Distribution of images in the Test 2018  dataset by Flickr group.", "labels": [], "entities": [{"text": "Test 2018  dataset", "start_pos": 40, "end_pos": 58, "type": "DATASET", "confidence": 0.9635325272878011}, {"text": "Flickr group", "start_pos": 62, "end_pos": 74, "type": "DATASET", "confidence": 0.8910134732723236}]}, {"text": " Table 3: Statistics of the ambiguous words extracted  from the training and validation sets after human  filtering (dictionary filtering). For EN-CS, the num- bers are larger because we could not perform the  dictionary filtering step.", "labels": [], "entities": [{"text": "dictionary filtering", "start_pos": 117, "end_pos": 137, "type": "TASK", "confidence": 0.6952763646841049}, {"text": "dictionary filtering", "start_pos": 210, "end_pos": 230, "type": "TASK", "confidence": 0.7212099432945251}]}, {"text": " Table 4: Statistics of dataset used for the LTA eval- uation after human filtering.", "labels": [], "entities": [{"text": "LTA eval- uation", "start_pos": 45, "end_pos": 61, "type": "TASK", "confidence": 0.7556933164596558}]}, {"text": " Table 6: Official automatic results for the MMT18 Task 1 on the English \u2192 German Test 2018 dataset  (ordered by Meteor). Grey background indicate use of resources that fall outside the constraints provided  for the shared task. (P) indicate a primary system designated for human evaluation.", "labels": [], "entities": [{"text": "MMT18 Task 1", "start_pos": 45, "end_pos": 57, "type": "TASK", "confidence": 0.6551192204157511}, {"text": "English \u2192 German Test 2018 dataset", "start_pos": 65, "end_pos": 99, "type": "DATASET", "confidence": 0.7609191636244456}, {"text": "Meteor", "start_pos": 113, "end_pos": 119, "type": "DATASET", "confidence": 0.7266556024551392}]}, {"text": " Table 7: Official automatic results for the MMT18 Task 1 on the English \u2192 French Test 2018 dataset  (ordered by Meteor). Grey background indicate use of resources that fall outside the constraints provided  for the shared task. (P) indicate a primary system designated for human evaluation.", "labels": [], "entities": [{"text": "MMT18 Task 1", "start_pos": 45, "end_pos": 57, "type": "TASK", "confidence": 0.631276269753774}, {"text": "French Test 2018 dataset", "start_pos": 75, "end_pos": 99, "type": "DATASET", "confidence": 0.8901225924491882}, {"text": "Meteor", "start_pos": 113, "end_pos": 119, "type": "DATASET", "confidence": 0.7203693389892578}]}, {"text": " Table 8: Official automatic results for the MMT18 Task 1 on the English \u2192 Czech Test 2018 dataset  (ordered by Meteor). Grey background indicate use of resources that fall outside the constraints provided  for the shared task. (P) indicate a primary system designated for human evaluation. Submissions marked  with * are not significantly different from the Baseline.", "labels": [], "entities": [{"text": "MMT18 Task 1", "start_pos": 45, "end_pos": 57, "type": "TASK", "confidence": 0.6311364571253458}, {"text": "English \u2192 Czech Test 2018 dataset", "start_pos": 65, "end_pos": 98, "type": "DATASET", "confidence": 0.754085565606753}, {"text": "Meteor", "start_pos": 112, "end_pos": 118, "type": "DATASET", "confidence": 0.7002449035644531}]}, {"text": " Table 9: Official automatic results for the MMT18 Task 1b on the English,German,French \u2192 Czech Test  2018 dataset (ordered by Meteor). Submissions marked with * are not significantly different from the  Baseline.", "labels": [], "entities": [{"text": "MMT18 Task", "start_pos": 45, "end_pos": 55, "type": "TASK", "confidence": 0.6655556261539459}, {"text": "English,German,French \u2192 Czech Test  2018 dataset", "start_pos": 66, "end_pos": 114, "type": "DATASET", "confidence": 0.7258156388998032}, {"text": "Meteor", "start_pos": 127, "end_pos": 133, "type": "DATASET", "confidence": 0.7511193752288818}]}, {"text": " Table 10: Results of the human evaluation of the WMT18 English-German Multimodal Translation task  (Test 2018 dataset). Systems are ordered by standardized mean DA scores (z) and clustered according  to Wilcoxon signed-rank test at p-level p \u2264 0.05. Systems within a cluster are considered tied, although  systems within a cluster may be statistically significantly different from each other (see", "labels": [], "entities": [{"text": "WMT18 English-German Multimodal Translation task", "start_pos": 50, "end_pos": 98, "type": "TASK", "confidence": 0.7977150559425354}, {"text": "Test 2018 dataset)", "start_pos": 101, "end_pos": 119, "type": "DATASET", "confidence": 0.7849994450807571}, {"text": "standardized mean DA scores (z)", "start_pos": 144, "end_pos": 175, "type": "METRIC", "confidence": 0.8560888852391925}]}, {"text": " Table 13: Results of the human evaluation of the WMT18 English,French,German-Czech Multisource  Multimodal Translation task (Test 2018 dataset). Systems are ordered by standardized mean DA score (z)", "labels": [], "entities": [{"text": "WMT18 English,French,German-Czech Multisource  Multimodal Translation task", "start_pos": 50, "end_pos": 124, "type": "TASK", "confidence": 0.664692203203837}, {"text": "Test 2018 dataset", "start_pos": 126, "end_pos": 143, "type": "DATASET", "confidence": 0.8648072481155396}, {"text": "standardized mean DA score", "start_pos": 169, "end_pos": 195, "type": "METRIC", "confidence": 0.871387243270874}]}]}