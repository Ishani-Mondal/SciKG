{"title": [{"text": "Cyclegen: Cyclic consistency based product review generator from attributes", "labels": [], "entities": [{"text": "Cyclegen", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.880102276802063}]}], "abstractContent": [{"text": "In this paper we present an automatic review generator system which can generate personalized reviews based on the user identity, product identity and designated rating the user wishes to allot to the review.", "labels": [], "entities": []}, {"text": "We combine this with a sentiment analysis system which performs the com-plimentary task of assigning ratings to reviews based purely on the textual content of the review.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.9203411042690277}]}, {"text": "We introduce an additional loss term to ensure cyclic consistency of the sentiment rating of the generated review with the conditioning rating used to generate the review.", "labels": [], "entities": [{"text": "consistency", "start_pos": 54, "end_pos": 65, "type": "METRIC", "confidence": 0.8787158131599426}]}, {"text": "The introduction of this new loss term constraints the generation space while forcing it to generate reviews adhering better to the requested rating.", "labels": [], "entities": []}, {"text": "The use of 'soft' generation and cyclic consistency allows us to train our model in an end to end fashion.", "labels": [], "entities": [{"text": "consistency", "start_pos": 40, "end_pos": 51, "type": "METRIC", "confidence": 0.8504784107208252}]}, {"text": "We demonstrate the working of our model on product reviews from Amazon dataset.", "labels": [], "entities": [{"text": "Amazon dataset", "start_pos": 64, "end_pos": 78, "type": "DATASET", "confidence": 0.937717467546463}]}], "introductionContent": [{"text": "In this age of growing e-commerce markets, reviews are taken very seriously, however, manually writing these reviews has become an extremely laborious task.", "labels": [], "entities": []}, {"text": "This leads us to work on systems which can automatically generate realistic looking reviews which can be automatically customized to the user writing it, the product being reviewed and the desired rating the generated review should express.", "labels": [], "entities": []}, {"text": "This makes the reviewing process much easier which can potentially increase the number of reviews posted leading to a more informed choice for potential buyers.", "labels": [], "entities": []}, {"text": "Natural Language Generation has always been one of the most challenging task in the field of natural language processing.", "labels": [], "entities": [{"text": "Natural Language Generation", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.749005655447642}, {"text": "natural language processing", "start_pos": 93, "end_pos": 120, "type": "TASK", "confidence": 0.653064618508021}]}, {"text": "Most of the present day approaches very loosely constraint the generation process often leading to ill formed or meaningless generations.", "labels": [], "entities": []}, {"text": "Ensuring semantic and syntactic coherence across the generated sentence is also an immensely challenging task.", "labels": [], "entities": []}, {"text": "We explore enforcing additional constraints on the generation process which we hope will restrict the generation manifold and generate more meaningful and semantically consistent sentence also adhering to the desired ratings.", "labels": [], "entities": []}, {"text": "In this paper we attempt to perform the following tasks: \u2022 We implement an automatic review generator using Long Short Term Memory Networks (LSTM) (Hochreiter and Schmidhuber, 1997), which has proved useful in remembering context and modelling sentence syntax.", "labels": [], "entities": [{"text": "remembering context", "start_pos": 210, "end_pos": 229, "type": "TASK", "confidence": 0.8694886863231659}, {"text": "modelling sentence syntax", "start_pos": 234, "end_pos": 259, "type": "TASK", "confidence": 0.6732584337393442}]}, {"text": "We also incorporate a soft attention mechanism which helps the model to attend better to the relevant context and generate better reviews.", "labels": [], "entities": []}, {"text": "Such a review generator system caters to each individual users reviewing style and would convert a user provided rating into a review personalized to the users writing style and based on their rating.", "labels": [], "entities": []}, {"text": "\u2022 Sentiment Analysis from reviews.", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 2, "end_pos": 20, "type": "TASK", "confidence": 0.9745539426803589}]}, {"text": "This includes going through the reviews and trying to gauge user sentiment and assign a score based on it.", "labels": [], "entities": []}, {"text": "Score parameters have been found to be much easier to go through and base ones decisions upon rather than manually going through hundreds of reviews.", "labels": [], "entities": []}, {"text": "\u2022 In this paper we propose an additional cyclic consistency loss term which allows for joint training of the generation network with the sentiment analysis network.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 137, "end_pos": 155, "type": "TASK", "confidence": 0.8455020487308502}]}, {"text": "This improves the generator network which is now more constrained and is forced to generate reviews which adhere to the provided rating.", "labels": [], "entities": []}, {"text": "\u2022 The use of 'soft' generation instead of a sampling based generation allows end to end gradient propagation allowing us to train our models end to end.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this paper we validate our generation framework on the Amazon dataset which contains reviews and scores for products sold on amazon.com and is part of the dataset collected by.", "labels": [], "entities": [{"text": "Amazon dataset", "start_pos": 58, "end_pos": 72, "type": "DATASET", "confidence": 0.9659670889377594}]}, {"text": "We used the reviews in the books category.", "labels": [], "entities": []}, {"text": "Specifically, we have 80,256 books and 19,675 users after using the same preprocessing as used in ().", "labels": [], "entities": []}, {"text": "The ratings are converted into 5 integer levels from 1-5.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Some examples from the review generator network for various users, products and rating scores", "labels": [], "entities": []}, {"text": " Table 3: Accuracy of polarity (positive/negative)  of the generated sentences by manual human com- parison against input polarities (1-3 is considered  negative and 4-5 is considered positive)", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9932760000228882}]}]}