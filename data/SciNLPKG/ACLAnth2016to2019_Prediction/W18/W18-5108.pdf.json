{"title": [{"text": "Improving Moderation of Online Discussions via Interpretable Neural Models", "labels": [], "entities": [{"text": "Improving Moderation of Online Discussions", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.8991532683372497}]}], "abstractContent": [{"text": "Growing amount of comments make online discussions difficult to moderate by human moderators only.", "labels": [], "entities": []}, {"text": "Antisocial behavior is a common occurrence that often discourages other users from participating in discussion.", "labels": [], "entities": []}, {"text": "We propose a neural network based method that partially automates the moderation process.", "labels": [], "entities": []}, {"text": "It consists of two steps.", "labels": [], "entities": []}, {"text": "First, we detect inappropriate comments for moderators to see.", "labels": [], "entities": []}, {"text": "Second , we highlight inappropriate parts within these comments to make the moderation faster.", "labels": [], "entities": []}, {"text": "We evaluated our method on data from a major Slovak news discussion platform.", "labels": [], "entities": [{"text": "Slovak news discussion platform", "start_pos": 45, "end_pos": 76, "type": "DATASET", "confidence": 0.7242395430803299}]}], "introductionContent": [{"text": "Keeping the discussion on a website civil is important for user satisfaction as well as for legal reasons (European court of human rights, 2015).", "labels": [], "entities": []}, {"text": "Manually moderating all the comments might be too time consuming.", "labels": [], "entities": []}, {"text": "Larger news and discussion websites receive hundreds of comments per minute which might require huge moderator teams.", "labels": [], "entities": []}, {"text": "In addition it is easy to overlook inappropriate comments due to human error.", "labels": [], "entities": []}, {"text": "Automated solutions are being developed to reduce moderation time requirements and to mitigate the error rate.", "labels": [], "entities": []}, {"text": "In this work we propose a neural network based method to speedup the moderation process.", "labels": [], "entities": []}, {"text": "First, we use trained classifier to automatically detect inappropriate comments.", "labels": [], "entities": []}, {"text": "Second, a subset of words is selected with a method by ( ) based on reinforcement learning.", "labels": [], "entities": []}, {"text": "These selected words should form a rationale why a comment was classified as inappropriate by our model.", "labels": [], "entities": []}, {"text": "Selected words are then highlighted for moderators so they can quickly focus on problematic parts of comments.", "labels": [], "entities": []}, {"text": "We also managed to evaluate our solution on a major dataset (millions of comments) and in real world conditions at an important Slovak news discussion platform.", "labels": [], "entities": [{"text": "Slovak news discussion platform", "start_pos": 128, "end_pos": 159, "type": "DATASET", "confidence": 0.8612542450428009}]}], "datasetContent": [{"text": "We used a proprietary dataset of more than 20 million comments from a major Slovak news discussion platform.", "labels": [], "entities": [{"text": "Slovak news discussion platform", "start_pos": 76, "end_pos": 107, "type": "DATASET", "confidence": 0.6813464313745499}]}, {"text": "Over the years a team of moderators was considering reported comments and removing the inappropriate ones while also selecting a reason(s) from prepared list of possible discussion code violations.", "labels": [], "entities": []}, {"text": "In this work we consider only those that were flagged because of following reasons: insults, racism, profanity or spam.", "labels": [], "entities": []}, {"text": "The rest of the comments are considered appropriate.", "labels": [], "entities": []}, {"text": "We split the dataset in train, validation and test set where validation and test set both were balanced to contain 10,000 appropriate and 10,000 inappropriate comments.", "labels": [], "entities": []}, {"text": "Rest of the dataset forms the training set.", "labels": [], "entities": []}, {"text": "Test and validation sets were sampled from the most recent months.", "labels": [], "entities": []}, {"text": "During the training we balance it on batch level by supersampling inappropriate comments.", "labels": [], "entities": []}, {"text": "We did not have any annotations on rationales in the dataset.", "labels": [], "entities": []}, {"text": "We created a test set by manually selecting words that should form the rationales in randomly picked 100 comments.", "labels": [], "entities": []}, {"text": "This way we created a test set containing 3,600 annotated words.", "labels": [], "entities": []}, {"text": "We trained our own fastText embeddings () on our dataset.", "labels": [], "entities": []}, {"text": "These take into account character level information and are therefore suitable for inflected languages (such as Slovak) and online discussions where lots of grammatical and typing errors occur.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison of test set performance of mul- tiple classification models. Baseline models (first four)  use various text representations that are classified by  boosted decision trees (1,000 trees) (Freund and Scha- pire, 1995).", "labels": [], "entities": [{"text": "mul- tiple classification", "start_pos": 48, "end_pos": 73, "type": "TASK", "confidence": 0.5092311948537827}]}]}