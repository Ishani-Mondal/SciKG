{"title": [{"text": "A Farewell to Arms: Non-verbal Communication for Non-humanoid Robots *", "labels": [], "entities": []}], "abstractContent": [{"text": "Human-robot interactions situated in a dynamic environment create a unique mix of challenges for conversational systems.", "labels": [], "entities": []}, {"text": "We argue that, on the one hand, NLG can contribute to addressing these challenges and that, on the other hand, they pose interesting research problems for NLG.", "labels": [], "entities": [{"text": "NLG", "start_pos": 155, "end_pos": 158, "type": "TASK", "confidence": 0.8280441164970398}]}, {"text": "To illustrate our position we describe our research on non-humanoid robots using non-verbal signals to support communication.", "labels": [], "entities": []}], "introductionContent": [{"text": "Our research is about interaction strategies for robots who have to approach and communicate with strangers in busy public spaces.", "labels": [], "entities": []}, {"text": "For example, in one of our target scenarios a delivery robot in a busy academic building on a college campus has to solicit help to operate the elevator from humans passing by.", "labels": [], "entities": []}, {"text": "In another scenario a robot is recruiting survey participants in a shopping mall.", "labels": [], "entities": []}, {"text": "In order to develop solutions that will work in a real-world deployment, we collect data and study human-robot interaction not just in laboratory experiments but also in field studies conducted in the wild.", "labels": [], "entities": []}, {"text": "In these field studies we have encountered challenges that are traditionally not addressed by the natural language generation (NLG) pipeline.", "labels": [], "entities": [{"text": "natural language generation (NLG)", "start_pos": 98, "end_pos": 131, "type": "TASK", "confidence": 0.7903761068979899}]}, {"text": "However, we would like to argue that an NLG system aware of these issues can contribute to a better solution and that they also pose interesting research problems for NLG.", "labels": [], "entities": []}, {"text": "In particular, the following two sources of challenges have stood out to us.", "labels": [], "entities": []}, {"text": "First, the robot is situated in a dynamic environment with human interaction partners that can act while the robot is * Position paper presented at the workshop on natural language generation for human-robot communication at speaking or planning an utterance.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 164, "end_pos": 191, "type": "TASK", "confidence": 0.7662792801856995}]}, {"text": "As in other situated communication tasks) the timing of the robot's utterances is important.", "labels": [], "entities": [{"text": "timing", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.98002690076828}]}, {"text": "For fluent interactions the robot needs to monitor the human's actions and changes in the environment and react to them in a timely manner, potentially by interrupting itself or modifying an utterance mid-stream).", "labels": [], "entities": []}, {"text": "Second, many environmental factors may hinder communication and are not controllable by us or the robot.", "labels": [], "entities": []}, {"text": "For example, in a busy public space the background noise level maybe high, making it hard for people to hear the robot.", "labels": [], "entities": []}, {"text": "People maybe passing by and even in between the robot and the addressee.", "labels": [], "entities": []}, {"text": "The robot will encounter many different reactions from addressees; some will be surprised, scared, or embarrassed to interact with it.", "labels": [], "entities": []}, {"text": "One approach to these challenges would be to solve these issues first in order to create a situation where a \"traditional\" NLG pipeline, based on NLG for text generation, can be used optimally.", "labels": [], "entities": [{"text": "text generation", "start_pos": 154, "end_pos": 169, "type": "TASK", "confidence": 0.753098726272583}]}, {"text": "For example, we could try to develop a module that perfectly times utterances, make sure to adjust the audio level to always be above the environmental noise level, and only communicate with addressees that are directly in front of the robot.", "labels": [], "entities": []}, {"text": "However, these goals maybe impossible to achieve.", "labels": [], "entities": []}, {"text": "For example, while it makes sense to optimize the timing of utterances, most contributing factors are out of our control, so that the robot will always have to be prepared to deal with unexpected actions by the human addressee, changes in the environment, or network delays.", "labels": [], "entities": []}, {"text": "Furthermore, this approach may lead to suboptimal results.", "labels": [], "entities": []}, {"text": "For instance, if the robot only communicates with people if they are positioned right in front of it, in a busy space with people passing through, many opportunities for interaction maybe lost.", "labels": [], "entities": []}, {"text": "Therefore, we believe that NLG should be aware of these issues and can contribute to a solution.", "labels": [], "entities": [{"text": "NLG", "start_pos": 27, "end_pos": 30, "type": "DATASET", "confidence": 0.8280069828033447}]}, {"text": "For example: An incremental NLG module maybe able to better time utterances and react to unexpected changes (.", "labels": [], "entities": []}, {"text": "When the environment is noisy or the robot is faraway from the addressee, generating shorter utterances using simpler words and complementing speech with nonverbal signals might be more effective.", "labels": [], "entities": []}, {"text": "Previous work has explored the problem of adapting the form and content of generated utterances to situational constraints (e.g.), but typically not in the context of human-robot interaction.", "labels": [], "entities": []}, {"text": "In order to illustrate our position, we will describe some results and observations from our ongoing research on making human-robot communication more robust using non-verbal signals.", "labels": [], "entities": []}, {"text": "A lot of work has been done on generating non-verbal signals, like gestures, facial expressions, and posture for animated characters (known as embodied conversational agents or virtual humans).", "labels": [], "entities": []}, {"text": "Some of this work has been transferred to humanoid robots.", "labels": [], "entities": []}, {"text": "However, because of our application scenario, the use of humanoid robots is not practical for us.", "labels": [], "entities": []}, {"text": "We need robots that are tall enough to interact with standing humans and that are not too expensive to be deployed in a busy public space.", "labels": [], "entities": []}, {"text": "We work with robots that have a wheeled base and a mounted screen (see).", "labels": [], "entities": []}, {"text": "The research challenge is, therefore, to find out what non-verbal signals are effective communicative devices for these non-humanoid robots.", "labels": [], "entities": []}, {"text": "These signals may mimic human behaviors, or they maybe visual metaphors that express the robot's intentions in away that is not modeling realistic human behavior, similar to the way comics express a character's movement or emotions.", "labels": [], "entities": []}], "datasetContent": [{"text": "Signals for Non-humanoid robots We describe three studies we have carried out or are currently conducting to explore how nonverbal behaviors can contribute to communication between humans and non-humanoid robots.", "labels": [], "entities": []}, {"text": "In these studies we explore non-verbal robot behaviors modeled on human behaviors as well as robot behaviors designed to communicate metaphorically through movement.", "labels": [], "entities": []}, {"text": "The two robots we have used for this work, SARAH and VALERIE, both have a mobile base, a screen on which a simple cartoon face can be displayed, and a suite of cameras and depth sensors (VALERIE is shown in.", "labels": [], "entities": [{"text": "SARAH", "start_pos": 43, "end_pos": 48, "type": "METRIC", "confidence": 0.9350694417953491}, {"text": "VALERIE", "start_pos": 53, "end_pos": 60, "type": "METRIC", "confidence": 0.993162989616394}, {"text": "VALERIE", "start_pos": 187, "end_pos": 194, "type": "METRIC", "confidence": 0.9653764963150024}]}, {"text": "Importantly, the robots have a non-humanoid form, lacking the typical mechanisms for human non-verbal expression.", "labels": [], "entities": []}, {"text": "Our experiments are conducted using: VALERIE a Wizard of Oz (WoZ) protocol, in which a human wizard remotely controls the robot unbeknownst to the participants.", "labels": [], "entities": [{"text": "VALERIE", "start_pos": 37, "end_pos": 44, "type": "METRIC", "confidence": 0.9987126588821411}]}, {"text": "The wizard interface provides a set of pre-planned behaviors the wizard can initiate, as well as lower-level controls for the robot.", "labels": [], "entities": []}], "tableCaptions": []}