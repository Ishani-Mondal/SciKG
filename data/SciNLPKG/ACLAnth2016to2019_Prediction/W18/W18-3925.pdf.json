{"title": [{"text": "Twist Bytes -German Dialect Identification with Data Mining Optimization", "labels": [], "entities": [{"text": "Twist Bytes -German Dialect Identification", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.7688694695631663}]}], "abstractContent": [{"text": "We describe our approaches used in the German Dialect Identification (GDI) task at the VarDial Evaluation Campaign 2018.", "labels": [], "entities": [{"text": "German Dialect Identification (GDI) task", "start_pos": 39, "end_pos": 79, "type": "TASK", "confidence": 0.7584217190742493}, {"text": "VarDial Evaluation Campaign 2018", "start_pos": 87, "end_pos": 119, "type": "DATASET", "confidence": 0.6884567514061928}]}, {"text": "The goal was to identify to which out of four dialects spoken in German speaking part of Switzerland a sentence belonged to.", "labels": [], "entities": []}, {"text": "We adopted two different meta-classifier approaches and used some data mining insights to improve the preprocessing and the meta-classifier parameters.", "labels": [], "entities": []}, {"text": "Especially, we focused on using different feature extraction methods and how to combine them, since they influenced the performance very differently of the system.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.7444845139980316}]}, {"text": "Our system achieved second place out of 8 teams, with a macro averaged F-1 of 64.6%.", "labels": [], "entities": [{"text": "F-1", "start_pos": 71, "end_pos": 74, "type": "METRIC", "confidence": 0.951678454875946}]}, {"text": "We also participated on the surprise dialect task with a multi-label approach.", "labels": [], "entities": []}], "introductionContent": [{"text": "The German Dialect Identification (GDI) task (, organized by the VarDial Evaluation Campaign 2018, was a continuation of last year's competitions ( . It consisted in classifying sentences into classes corresponding to different selected dialects.", "labels": [], "entities": [{"text": "German Dialect Identification (GDI) task", "start_pos": 4, "end_pos": 44, "type": "TASK", "confidence": 0.7788079125540597}, {"text": "VarDial Evaluation Campaign 2018", "start_pos": 65, "end_pos": 97, "type": "DATASET", "confidence": 0.8373753130435944}]}, {"text": "In the German speaking part of Switzerland, there are many dialects which are quite different, and speakers of one dialect might even have difficulty understanding other dialects of regions not faraway.", "labels": [], "entities": []}, {"text": "The selected dialects were roughly represented by cantons Bern, Basel (Basel-Stadt and Baselland), Luzern (Luzern and Nidwalden) and Zurich.", "labels": [], "entities": []}, {"text": "Geographically speaking, the cantons chosen to represent the dialects create roughly a square with each side of 100 kilometers.", "labels": [], "entities": []}, {"text": "Each sentence was transcribed and annotated with the canton of the speaker.", "labels": [], "entities": [{"text": "canton", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9936524629592896}]}, {"text": "The identification of dialect based on the script for non-standardized dialects is a difficult task.", "labels": [], "entities": []}, {"text": "Not only it is difficult to transcribe the dialects (although there are guidelines), but the annotation process can be very subjective.", "labels": [], "entities": []}, {"text": "This subjectivity of the annotation manifests in similar tasks such as in labelling multi-label samples.", "labels": [], "entities": []}, {"text": "A good example, found in this competition's dataset, was \"sch\u00f6n\" and \"sch\u00f6\u00f6n\", both meaning beautiful and both labelled with Luzern dialect.", "labels": [], "entities": []}, {"text": "An interesting restriction was that no additional information than the task data should be used (closed submission).", "labels": [], "entities": []}, {"text": "Notably this year's competition had a special task, to predict a surprise dialect in the test set.", "labels": [], "entities": []}, {"text": "Thus, the training data had no data on that new dialect (training set data 4 classes, test set data 5 classes).", "labels": [], "entities": []}, {"text": "Such a task is particularly difficult because of the small amount of training data.", "labels": [], "entities": []}, {"text": "We describe here the approaches taken by our team Twist Bytes.", "labels": [], "entities": []}, {"text": "We achieved second place 1 with one of our approaches.", "labels": [], "entities": []}, {"text": "The key feature of the approaches is based on the fact that we investigated the data set using data mining methods and applied feature optimization to build two different meta-classifiers.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Number of instances by Canton and Set", "labels": [], "entities": [{"text": "Number", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9722270965576172}, {"text": "Canton", "start_pos": 33, "end_pos": 39, "type": "DATASET", "confidence": 0.9250428676605225}]}, {"text": " Table 2: Per Feature System Results for the GDI Task from 2017 (using dev set). TB-Meta is Twist Bytes  Meta classifier and TB-Hierarchical is Twist Bytes Hierarchical one. RF stands for random forests. CB  stands for CounterVectorizer (scikit-learn TF with analyzer). Baseline random assignment (over 10 runs):  weighted F-1 0.246 \u00b1 0.003, macro F-1 0.250 \u00b1 0.005", "labels": [], "entities": []}, {"text": " Table 3: Results for the GDI task. TB-Meta is Twist Bytes Meta classifier and TB-Hierarchical is  Twist Bytes Hierarchical classifier. TB-Meta-all is TB-Meta with Complete Training Set. Best TB- system in competition marked in bold. Submitted column states if system was actually submitted to the  competition. Only best submissions were placed.", "labels": [], "entities": [{"text": "GDI task", "start_pos": 26, "end_pos": 34, "type": "TASK", "confidence": 0.7671851813793182}]}]}