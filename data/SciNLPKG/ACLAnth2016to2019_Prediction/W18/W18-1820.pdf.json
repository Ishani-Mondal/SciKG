{"title": [{"text": "The SOCKEYE Neural Machine Translation Toolkit at AMTA 2018", "labels": [], "entities": [{"text": "SOCKEYE Neural Machine Translation", "start_pos": 4, "end_pos": 38, "type": "TASK", "confidence": 0.7306814193725586}, {"text": "AMTA 2018", "start_pos": 50, "end_pos": 59, "type": "DATASET", "confidence": 0.7491294741630554}]}], "abstractContent": [{"text": "We describe SOCKEYE, 1 an open-source sequence-to-sequence toolkit for Neural Machine Translation (NMT).", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT)", "start_pos": 71, "end_pos": 103, "type": "TASK", "confidence": 0.8389544586340586}]}, {"text": "SOCKEYE is a production-ready framework for training and applying models as well as an experimental platform for researchers.", "labels": [], "entities": [{"text": "SOCKEYE", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.7146686911582947}]}, {"text": "Written in Python and built on MXNET, the toolkit offers scalable training and inference for the three most prominent encoder-decoder architectures: attentional recurrent neural networks, self-attentional transformers, and fully convolutional networks.", "labels": [], "entities": []}, {"text": "SOCKEYE also supports a wide range of optimizers, normalization and regularization techniques, and inference improvements from current NMT literature.", "labels": [], "entities": []}, {"text": "Users can easily run standard training recipes, explore different model settings, and incorporate new ideas.", "labels": [], "entities": []}, {"text": "The SOCKEYE toolkit is free software released under the Apache 2.0 license.", "labels": [], "entities": []}], "introductionContent": [{"text": "For all its success, Neural Machine Translation (NMT) presents a range of new challenges.", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT)", "start_pos": 21, "end_pos": 53, "type": "TASK", "confidence": 0.7733471641937891}]}, {"text": "While popular encoder-decoder models are attractively simple, recent literature and the results of shared evaluation tasks show that a significant amount of engineering is required to achieve \"production-ready\" performance in both translation quality and computational efficiency.", "labels": [], "entities": []}, {"text": "Ina trend that carries over from Statistical Machine Translation (SMT), the strongest NMT systems benefit from subtle architecture modifications, hyper-parameter tuning, and empirically effective heuristics.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 33, "end_pos": 70, "type": "TASK", "confidence": 0.8602065046628317}]}, {"text": "To address these challenges, we introduce SOCKEYE, a neural sequence-to-sequence toolkit written in Python and built on Apache MXNET 2.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, SOCKEYE is the only toolkit that includes implementations of all three major neural translation architectures: attentional recurrent neural networks, selfattentional transformers, and fully convolutional networks.", "labels": [], "entities": []}, {"text": "These implementations are supported by a wide and continually updated range of features reflecting the best ideas from recent literature.", "labels": [], "entities": []}, {"text": "Users can easily train models based on the latest research, compare different architectures, and extend them by adding their own code.", "labels": [], "entities": []}, {"text": "SOCKEYE is under active development that follows best practice for both research and production software, including clear coding and documentation guidelines, comprehensive automatic tests, and peer review for code contributions.", "labels": [], "entities": [{"text": "SOCKEYE", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.7447106242179871}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: BLEU scores for evaluated toolkits and architectures using \"best found\" settings on  WMT newstest2017.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9987420439720154}, {"text": "WMT newstest2017", "start_pos": 95, "end_pos": 111, "type": "DATASET", "confidence": 0.9473144114017487}]}]}