{"title": [{"text": "IIIDYT at IEST 2018: Implicit Emotion Classification With Deep Contextualized Word Representations", "labels": [], "entities": [{"text": "Implicit Emotion Classification", "start_pos": 21, "end_pos": 52, "type": "TASK", "confidence": 0.8716368873914083}]}], "abstractContent": [{"text": "In this paper we describe our system designed for the WASSA 2018 Implicit Emotion Shared Task (IEST), which obtained 2 nd place out of 30 teams with a test macro F1 score of 0.710.", "labels": [], "entities": [{"text": "WASSA 2018 Implicit Emotion Shared Task (IEST)", "start_pos": 54, "end_pos": 100, "type": "TASK", "confidence": 0.8197233014636569}, {"text": "F1 score", "start_pos": 162, "end_pos": 170, "type": "METRIC", "confidence": 0.9681418836116791}]}, {"text": "The system is composed of a single pre-trained ELMo layer for encoding words, a Bidirectional Long-Short Memory Network BiLSTM for enriching word representations with context, a max-pooling operation for creating sentence representations from them, and a Dense Layer for projecting the sentence representations into label space.", "labels": [], "entities": []}, {"text": "Our official submission was obtained by ensembling 6 of these models initialized with different random seeds.", "labels": [], "entities": []}, {"text": "The code for replicating this paper is available at https://github.com/ jabalazs/implicit_emotion.", "labels": [], "entities": [{"text": "replicating", "start_pos": 13, "end_pos": 24, "type": "TASK", "confidence": 0.965671956539154}]}], "introductionContent": [{"text": "Although the definition of emotion is still debated among the scientific community, the automatic identification and understanding of human emotions by machines has long been of interest in computer science.", "labels": [], "entities": [{"text": "definition of emotion", "start_pos": 13, "end_pos": 34, "type": "TASK", "confidence": 0.8397035400072733}, {"text": "automatic identification and understanding of human emotions", "start_pos": 88, "end_pos": 148, "type": "TASK", "confidence": 0.7885188971246991}]}, {"text": "It has usually been assumed that emotions are triggered by the interpretation of a stimulus event according to its meaning.", "labels": [], "entities": []}, {"text": "As language usually reflects the emotional state of an individual, it is natural to study human emotions by understanding how they are reflected in text.", "labels": [], "entities": []}, {"text": "We see that many words indeed have affect as a core part of their meaning, for example, dejected and wistful denote some amount of sadness, and are thus associated with sadness.", "labels": [], "entities": []}, {"text": "On the other hand, some words are associated with affect even though they do not denote affect.", "labels": [], "entities": []}, {"text": "For example, failure and death describe concepts that are usually accompanied by sadness and thus they denote some amount of sadness.", "labels": [], "entities": []}, {"text": "In this context, the task of automatically recognizing emotions from text has recently attracted the attention of researchers in Natural Language Processing.", "labels": [], "entities": [{"text": "automatically recognizing emotions from text", "start_pos": 29, "end_pos": 73, "type": "TASK", "confidence": 0.7220708549022674}, {"text": "Natural Language Processing", "start_pos": 129, "end_pos": 156, "type": "TASK", "confidence": 0.6310827334721884}]}, {"text": "This task is usually formalized as the classification of words, phrases, or documents into predefined discrete emotion categories or dimensions.", "labels": [], "entities": [{"text": "classification of words, phrases, or documents into predefined discrete emotion categories or dimensions", "start_pos": 39, "end_pos": 143, "type": "TASK", "confidence": 0.6949749171733857}]}, {"text": "Some approaches have aimed at also predicting the degree to which an emotion is expressed in text.", "labels": [], "entities": []}, {"text": "In light of this, the WASSA 2018 Implicit Emotion Shared Task (IEST) () was proposed to help find ways to automatically learn the link between situations and the emotion they trigger.", "labels": [], "entities": [{"text": "WASSA 2018 Implicit Emotion Shared Task (IEST)", "start_pos": 22, "end_pos": 68, "type": "TASK", "confidence": 0.748264385594262}]}, {"text": "The task consisted in predicting the emotion of a word excluded from a tweet.", "labels": [], "entities": [{"text": "predicting the emotion of a word excluded from a tweet", "start_pos": 22, "end_pos": 76, "type": "TASK", "confidence": 0.8267200469970704}]}, {"text": "Removed words, or trigger-words, included the terms \"sad\", \"happy\", \"disgusted\", \"surprised\", \"angry\", \"afraid\" and their synonyms, and the task was to predict the emotion they conveyed, specifically sadness, joy, disgust, surprise, anger and fear.", "labels": [], "entities": []}, {"text": "From a machine learning perspective, this problem can be seen as sentence classification, in which the goal is to classify a sentence, or in particular a tweet, into one of several categories.", "labels": [], "entities": [{"text": "sentence classification", "start_pos": 65, "end_pos": 88, "type": "TASK", "confidence": 0.7236923575401306}]}, {"text": "In the case of IEST, the problem is specially challenging since tweets contain informal language, the heavy usage of emoji, hashtags and username mentions.", "labels": [], "entities": []}, {"text": "In this paper we describe our system designed for IEST, which obtained the second place out of 30 teams.", "labels": [], "entities": [{"text": "IEST", "start_pos": 50, "end_pos": 54, "type": "DATASET", "confidence": 0.714203953742981}]}, {"text": "Our system did not require manual feature engineering and only minimal use of external data.", "labels": [], "entities": []}, {"text": "Concretely, our approach is composed of a single pre-trained ELMo layer for encoding words (), a Bidirectional LongShort Memory Network (BiLSTM) (, for enriching word representations with context, a maxpooling operation for creating sentence representations from said word vectors, and finally a Dense Layer for projecting the sentence representations into label space.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, our system, which we plan to release, is the first to utilize ELMo for emotion recognition.", "labels": [], "entities": [{"text": "emotion recognition", "start_pos": 101, "end_pos": 120, "type": "TASK", "confidence": 0.7977523803710938}]}], "datasetContent": [{"text": "We performed several experiments to gain insights on how the proposed model's performance interacts with the shared task's data.", "labels": [], "entities": []}, {"text": "We performed an ablation study to see how some of the main hyperparameters affect performance, and an analysis of tweets containing hashtags and emoji to understand how these two types of tokens help the model predict the trigger-word's emotion.", "labels": [], "entities": []}, {"text": "We also observed the effects of varying the amount of data used for training the model to evaluate whether it would be worthwhile to gather more training data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Ablation study results.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9829802513122559}]}, {"text": " Table 3: Classification Report (Test Set).", "labels": [], "entities": [{"text": "Classification Report (Test Set)", "start_pos": 10, "end_pos": 42, "type": "DATASET", "confidence": 0.7669470508893331}]}, {"text": " Table 5: Fine grained performance on tweets con- taining emoji, and the effect of removing them.", "labels": [], "entities": []}]}