{"title": [{"text": "Automatic Identification of Drugs and Adverse Drug Reaction Related Tweets", "labels": [], "entities": [{"text": "Automatic Identification of Drugs and Adverse Drug Reaction Related Tweets", "start_pos": 0, "end_pos": 74, "type": "TASK", "confidence": 0.7598024308681488}]}], "abstractContent": [{"text": "We describe our submissions to the Third Social Media Mining for Health Applications Shared Task.", "labels": [], "entities": [{"text": "Third Social Media Mining for Health Applications Shared Task", "start_pos": 35, "end_pos": 96, "type": "TASK", "confidence": 0.6947093307971954}]}, {"text": "We participated in two tasks (tasks 1 and 3).", "labels": [], "entities": []}, {"text": "For both tasks, we experimented with a traditional machine learning model (Naive Bayes Support Vector Machine (NBSVM)), deep learning models (Con-volutional Neural Networks (CNN), Long Short-Term Memory (LSTM), and Bidirec-tional LSTM (BiLSTM)), and the combination of deep learning model with SVM.", "labels": [], "entities": []}, {"text": "We observed that the NBSVM reaches superior performance on both tasks on our development split of the training data sets.", "labels": [], "entities": [{"text": "NBSVM", "start_pos": 21, "end_pos": 26, "type": "DATASET", "confidence": 0.8908883929252625}, {"text": "training data sets", "start_pos": 102, "end_pos": 120, "type": "DATASET", "confidence": 0.802275538444519}]}, {"text": "Official result for task 1 based on the blind evaluation data shows that the predictions of the NBSVM achieved our team's best F-score of 0.910 which is above the average score received by all submissions to the task.", "labels": [], "entities": [{"text": "NBSVM", "start_pos": 96, "end_pos": 101, "type": "DATASET", "confidence": 0.9546164274215698}, {"text": "F-score", "start_pos": 127, "end_pos": 134, "type": "METRIC", "confidence": 0.998007595539093}]}, {"text": "On task 3, the combination of of BiLSTM and SVM gives our best F-score for the positive class of 0.394.", "labels": [], "entities": [{"text": "BiLSTM", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.8304378986358643}, {"text": "F-score", "start_pos": 63, "end_pos": 70, "type": "METRIC", "confidence": 0.9990723133087158}]}], "introductionContent": [{"text": "The emergence of social media platforms such as Twitter has led to the availability of huge amount of data for research purposes.", "labels": [], "entities": []}, {"text": "Public health monitoring using this non-traditional mode of communication has received attention in recent times.", "labels": [], "entities": []}, {"text": "The third edition of Social Media Mining for Health Applications (SMM4H) ( shared task aims to facilitate pharmacovigilance research using social media data.", "labels": [], "entities": [{"text": "Social Media Mining for Health Applications (SMM4H)", "start_pos": 21, "end_pos": 72, "type": "TASK", "confidence": 0.7271526323424445}]}, {"text": "We participated in tasks 1 and 3.", "labels": [], "entities": []}, {"text": "The purpose of task 1 is to identify tweets that contain drug name(s) while task 3 focuses on recognizing Twitter posts mentioning adverse drug reaction (ADR).", "labels": [], "entities": [{"text": "recognizing Twitter posts mentioning adverse drug reaction (ADR)", "start_pos": 94, "end_pos": 158, "type": "TASK", "confidence": 0.6169889628887176}]}, {"text": "Both tasks are binary classification tasks.", "labels": [], "entities": [{"text": "binary classification tasks", "start_pos": 15, "end_pos": 42, "type": "TASK", "confidence": 0.7905608812967936}]}, {"text": "The evaluation metrics for both tasks are the precision, recall, and F1 scores of the positive class.", "labels": [], "entities": [{"text": "precision", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.9997338652610779}, {"text": "recall", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.994993269443512}, {"text": "F1", "start_pos": 69, "end_pos": 71, "type": "METRIC", "confidence": 0.9998539686203003}]}, {"text": "In the following sections, we describe the data, our approach, results, and conclusion.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: F1 Score of the Positive Class on our Devel- opment Split of the Training set using NBSVM and  Deep Learning Models (For the deep learning models,  the scores are the average of three runs and the values  in parenthesis are for the corresponding character level  model)", "labels": [], "entities": [{"text": "F1 Score", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9794834554195404}, {"text": "NBSVM", "start_pos": 94, "end_pos": 99, "type": "DATASET", "confidence": 0.972740650177002}]}, {"text": " Table 3: Scores on the Evaluation Data for Task 1 (P- Precision; R-Recall; F-F1 measure)", "labels": [], "entities": [{"text": "P- Precision", "start_pos": 52, "end_pos": 64, "type": "METRIC", "confidence": 0.8944063385327657}, {"text": "F-F1 measure", "start_pos": 76, "end_pos": 88, "type": "METRIC", "confidence": 0.856681227684021}]}, {"text": " Table 4: Scores on the Evaluation Data for Task 3 (P- Precision for the ADR class; R-Recall for the ADR  class; F-F1 measure for the ADR class)", "labels": [], "entities": [{"text": "P- Precision", "start_pos": 52, "end_pos": 64, "type": "METRIC", "confidence": 0.7485988140106201}, {"text": "F-F1 measure", "start_pos": 113, "end_pos": 125, "type": "METRIC", "confidence": 0.9140751659870148}]}]}