{"title": [{"text": "Coreference and Coherence in Neural Machine Translation: A Study Using Oracle Experiments", "labels": [], "entities": [{"text": "Neural Machine Translation", "start_pos": 29, "end_pos": 55, "type": "TASK", "confidence": 0.6100739240646362}]}], "abstractContent": [{"text": "Cross-sentence context can provide valuable information in Machine Translation and is critical for translation of anaphoric pronouns and for providing consistent translations.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 59, "end_pos": 78, "type": "TASK", "confidence": 0.8606667518615723}, {"text": "translation of anaphoric pronouns", "start_pos": 99, "end_pos": 132, "type": "TASK", "confidence": 0.8473038822412491}]}, {"text": "In this paper, we devise simple oracle experiments targeting coreference and coherence.", "labels": [], "entities": []}, {"text": "Oracles are an easy way to evaluate the effect of different discourse-level phenomena in NMT using BLEU and eliminate the necessity to manually define challenge sets for this purpose.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 99, "end_pos": 103, "type": "METRIC", "confidence": 0.9962738752365112}]}, {"text": "We propose two context-aware NMT models and compare them against models working on a concatenation of consecutive sentences.", "labels": [], "entities": []}, {"text": "Concatenation models perform better, but are computationally expensive.", "labels": [], "entities": []}, {"text": "We show that NMT models taking advantage of context oracle signals can achieve considerable gains in BLEU, of up to 7.02 BLEU for corefer-ence and 1.89 BLEU for coherence on subtitles translation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 101, "end_pos": 105, "type": "METRIC", "confidence": 0.9996243715286255}, {"text": "BLEU", "start_pos": 121, "end_pos": 125, "type": "METRIC", "confidence": 0.997137188911438}, {"text": "BLEU", "start_pos": 152, "end_pos": 156, "type": "METRIC", "confidence": 0.997352123260498}, {"text": "subtitles translation", "start_pos": 174, "end_pos": 195, "type": "TASK", "confidence": 0.7518502771854401}]}, {"text": "Access to strong signals allows us to make clear comparisons between context-aware models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Neural Machine Translation (NMT) () is a state-of-the-art approach to MT.", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7848599255084991}, {"text": "MT", "start_pos": 70, "end_pos": 72, "type": "TASK", "confidence": 0.9961503744125366}]}, {"text": "Standard NMT models translate an input language sentence to an output language sentence, and do not take into account discourse-level phenomena.", "labels": [], "entities": []}, {"text": "Cross-sentence context has already proven useful for language modeling ( and dialogue systems (.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 53, "end_pos": 70, "type": "TASK", "confidence": 0.7254079133272171}]}, {"text": "It has also been of interest in Statistical Machine Translation (SMT) research, and NMT research (.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 32, "end_pos": 69, "type": "TASK", "confidence": 0.855590949455897}]}, {"text": "Two important discourse phenomena for MT are coreference and coherence.", "labels": [], "entities": [{"text": "MT", "start_pos": 38, "end_pos": 40, "type": "TASK", "confidence": 0.9947819113731384}, {"text": "coreference", "start_pos": 45, "end_pos": 56, "type": "TASK", "confidence": 0.9710751175880432}]}, {"text": "Pronominal coreference relates to the issue of translating anaphoric pronouns and is tackled in several works and is the central motivation for the DiscoMT shared task on cross-lingual pronoun prediction (.", "labels": [], "entities": [{"text": "Pronominal coreference", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8502097725868225}, {"text": "translating anaphoric pronouns", "start_pos": 47, "end_pos": 77, "type": "TASK", "confidence": 0.8752625187238058}, {"text": "DiscoMT shared", "start_pos": 148, "end_pos": 162, "type": "TASK", "confidence": 0.6245442628860474}, {"text": "cross-lingual pronoun prediction", "start_pos": 171, "end_pos": 203, "type": "TASK", "confidence": 0.6913801232973734}]}, {"text": "Coherence on the other hand, is important for producing consistent and coherent translations throughout a document, especially for domain-specific terminology and it is helpful to properly disambiguate polysemous words.", "labels": [], "entities": []}, {"text": "Modeling discourse-level phenomena for MT is a challenging endeavor because of difficulties in acquiring relevant linguistic signals.", "labels": [], "entities": [{"text": "MT", "start_pos": 39, "end_pos": 41, "type": "TASK", "confidence": 0.9900908470153809}]}, {"text": "Measuring the effect of discourse-level phenomena with automatic metrics such as BLEU is also difficult as pointed out by.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 81, "end_pos": 85, "type": "METRIC", "confidence": 0.996764063835144}]}, {"text": "In this paper, we address these issues by proposing several oracle experimental setups for evaluating the effect of coreference resolution (CR) and coherence in MT.", "labels": [], "entities": [{"text": "coreference resolution (CR)", "start_pos": 116, "end_pos": 143, "type": "METRIC", "confidence": 0.7154054403305053}, {"text": "MT", "start_pos": 161, "end_pos": 163, "type": "TASK", "confidence": 0.9749282002449036}]}, {"text": "Oracle experiments provide strong linguistic signals that enable strongly visible effects on BLEU scores, thus alleviating the difficulty of using BLEU to evaluate discourselevel phenomena in MT.", "labels": [], "entities": [{"text": "BLEU scores", "start_pos": 93, "end_pos": 104, "type": "METRIC", "confidence": 0.9682848155498505}, {"text": "BLEU", "start_pos": 147, "end_pos": 151, "type": "METRIC", "confidence": 0.9263753890991211}, {"text": "MT", "start_pos": 192, "end_pos": 194, "type": "TASK", "confidence": 0.9807327389717102}]}, {"text": "Oracles highlight the capability of NMT systems to use context (which we call context-aware NMT) and to handle different discourse-level phenomena.", "labels": [], "entities": []}, {"text": "They provide a variety of scenarios that can easily beset up for any domain, dataset or language pair, unlike discourse-specific challenge sets () which must be manually created.", "labels": [], "entities": []}, {"text": "Furthermore, strong linguistic signals from oracles enable us to easily study how the models use context.", "labels": [], "entities": []}, {"text": "Our primary task is translating subtitles from English to German.", "labels": [], "entities": [{"text": "translating subtitles from English", "start_pos": 20, "end_pos": 54, "type": "TASK", "confidence": 0.8521396219730377}]}, {"text": "Subtitles provide fora reasonable diversity of topics necessary for testing coherence.", "labels": [], "entities": []}, {"text": "They also contain a large amount of short, informal and conversational text, where anaphoric pronouns are very important.", "labels": [], "entities": []}, {"text": "We study coreference by aiding pronoun translation and coherence by providing disambiguation signals for translation of polysemous words.", "labels": [], "entities": [{"text": "pronoun translation", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.7692423462867737}]}, {"text": "The oracles are automatically created and targeted for each discourse phenomenon.", "labels": [], "entities": []}, {"text": "We additionally include a previous target sentence oracle, where the context consists of the previous target sentence, as a more generic way of including context.", "labels": [], "entities": []}, {"text": "This is an interesting oracle, but this scenario is actually also beneficial for online post-editing, because the gold standard previous target sentence is available there.", "labels": [], "entities": []}, {"text": "We propose a simple, yet effective extension to standard RNN models for NMT (which we refer to as NMT(RNN)) which models context by employing attention over word embeddings only.", "labels": [], "entities": []}, {"text": "We compare it against a standard NMT(RNN) model working on a concatenation of consecutive sentences (.", "labels": [], "entities": []}, {"text": "Additionally, we evaluate the Transformer ( and propose a context-aware NMT(Transformer) extension.", "labels": [], "entities": []}, {"text": "Our oracles allow us to compare the context-aware NMT models with the baselines and make strong conclusions.", "labels": [], "entities": []}, {"text": "Moreover, we study how comparable oracles are with the challenge sets proposed by by analyzing the performance of our context-aware model with both approaches.", "labels": [], "entities": []}, {"text": "Finally, we conduct a qualitative study and show the inner workings of context-aware models under different oracle settings.", "labels": [], "entities": []}, {"text": "Contributions: (i) We modify the data using an oracle experimental setup in order to accommodate evaluating coreference and coherence in NMT.", "labels": [], "entities": []}, {"text": "(ii) Our evaluation is independent of carefully constructed challenge sets, and can easily be transferred across language pairs and domains.", "labels": [], "entities": []}, {"text": "(iii) Results clearly show context-aware NMT(RNN) and NMT(Transformer) can improve performance over NMT models without access to context.", "labels": [], "entities": []}, {"text": "(iv) We empirically analyze the pros and cons of the major approaches to context-aware NMT and explain how different modeling decisions interact with different discourse phenomena.", "labels": [], "entities": []}, {"text": "(v) We present the trade-offs in modeling power versus speed that are important when considering multiple sentences of context.", "labels": [], "entities": []}], "datasetContent": [{"text": "We train our models on OpenSubtitles2016 En-De with \u2248 13.9M parallel sentences.", "labels": [], "entities": [{"text": "OpenSubtitles2016 En-De", "start_pos": 23, "end_pos": 46, "type": "DATASET", "confidence": 0.8235651850700378}]}, {"text": "The development and test set consist of 6 and 7 documents randomly sampled from the dataset, containing 3172 and 4627 sentences respectively.", "labels": [], "entities": []}, {"text": "In the coreference oracle setup \u2248 7.8M training samples were modified and added the appropriate context, while in the coherence setup only \u2248 0.8M.", "labels": [], "entities": []}, {"text": "The remaining samples are unchanged and have no context.", "labels": [], "entities": []}, {"text": "We apply tokenization, truecasing and BPE splitting computed jointly on both languages with 59500 operations.", "labels": [], "entities": [{"text": "BPE splitting", "start_pos": 38, "end_pos": 51, "type": "TASK", "confidence": 0.8907549977302551}]}, {"text": "All sentences with length above 60 tokens are discarded.", "labels": [], "entities": []}, {"text": "All embeddings are tied) including the ones in the context part of the architecture.", "labels": [], "entities": []}, {"text": "Dropout (Gal and Ghahramani, 2016) of 0.2 is applied and 0.1 on the embeddings.", "labels": [], "entities": [{"text": "Dropout", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9390904903411865}]}, {"text": "We apply layer ( and weight normalization ().", "labels": [], "entities": []}, {"text": "The models are trained with early-stopping based on the development set's cost.", "labels": [], "entities": []}, {"text": "We report BLEU score on detokenized text.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.8513893783092499}]}, {"text": "Our RNN-based model is implemented as an extension to Nematus 2 ( . We used the Sockeye 3 (Hieber et al., 2017) implementation of the Transformer.", "labels": [], "entities": [{"text": "Sockeye 3 (Hieber et al., 2017)", "start_pos": 80, "end_pos": 111, "type": "DATASET", "confidence": 0.9083720114496019}]}, {"text": "For the Transformer we use hyper-parameters as similar as possible to the ones in the Nematus models.", "labels": [], "entities": []}, {"text": "We additionally use label smoothing of value 0.1.", "labels": [], "entities": [{"text": "label smoothing", "start_pos": 20, "end_pos": 35, "type": "TASK", "confidence": 0.7238859385251999}]}, {"text": "Both, the baseline and context-aware model have 4 layers.", "labels": [], "entities": []}, {"text": "We didn't do any special hyper-parameter tuning for the context-aware models, so further performance improvements are possible.", "labels": [], "entities": []}, {"text": "The datasets and the source code for our context-aware models are publicly available 4 .", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: BLEU scores from all of the oracle experimental", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.999354898929596}]}]}