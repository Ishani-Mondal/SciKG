{"title": [{"text": "Modeling Linguistic and Personality Adaptation for Natural Language Generation", "labels": [], "entities": [{"text": "Modeling Linguistic and Personality Adaptation", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.8583587169647217}]}], "abstractContent": [{"text": "Previous work has shown that conversants adapt to many aspects of their partners' language.", "labels": [], "entities": []}, {"text": "Other work has shown that while every person is unique, they often share general patterns of behavior.", "labels": [], "entities": []}, {"text": "Theories of personality aim to explain these shared patterns , and studies have shown that many linguistic cues are correlated with personality traits.", "labels": [], "entities": []}, {"text": "We propose an adaptation measure for adaptive natural language generation for dialogs that integrates the predictions of both personality theories and adaptation theories, that can be applied as a dialog unfolds , on a turn by turn basis.", "labels": [], "entities": [{"text": "adaptive natural language generation", "start_pos": 37, "end_pos": 73, "type": "TASK", "confidence": 0.738205149769783}]}, {"text": "We show that our measure meets criteria for validity , and that adaptation varies according to corpora and task, speaker, and the set of features used to model it.", "labels": [], "entities": []}, {"text": "We also produce fine-grained models according to the dialog segmentation or the speaker, and demonstrate the decaying trend of adaptation.", "labels": [], "entities": []}], "introductionContent": [{"text": "Every person is unique, yet they often share general patterns of behavior.", "labels": [], "entities": []}, {"text": "Theories of personality aim to explain these patterns in terms of personality traits, e.g. the Big Five traits of extraversion or agreeableness.", "labels": [], "entities": []}, {"text": "Previous work has shown: (1) the language that people generate includes linguistic features that express these personality traits; (2) it is possible to train models to automatically recognize a person's personality from his language; and (3) it is possible to automatically train models for natural language generation that express personality traits.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 292, "end_pos": 319, "type": "TASK", "confidence": 0.7424991726875305}]}, {"text": "A distinct line of work has shown that people adapt to one another's conversational behaviors and that conversants reliably re-use or mimic many Speaker (Utterance #): Utterance F97: okay I'm on pacific avenue and plaza D98: okay so you just take aright once your out of pacific lane you go wait no to late to your left.", "labels": [], "entities": []}, {"text": "F98: okay D99: and I think.", "labels": [], "entities": []}, {"text": "it's right ther-alright so I'm walking down pacific okay so it's right before the object it's right before the mission and pacific avenue intersection okay it's like umm almost brown and kinda like tan colored F99: is it tan D100: yeah it's like two different colors its like dark brown and orangey kinda like gold color its kinda like um F100: okay is it kinda like a vase type of a thing D101: yeah it has yeah like a vase).", "labels": [], "entities": [{"text": "F100", "start_pos": 339, "end_pos": 343, "type": "METRIC", "confidence": 0.9731446504592896}]}, {"text": "Previous work primarily focuses on developing methods on measuring adaptation in dialog, and studies have shown that adaptation measures are correlated with task success, and that social variables such as power affect adaptation (Danescu-Niculescu-Mizil et al., 2012).", "labels": [], "entities": []}, {"text": "We posit that it is crucial to enable adaptation in computer agents in order to make them more human-like.", "labels": [], "entities": []}, {"text": "However, we need models to control the amount of adaptation in natural language generation.", "labels": [], "entities": []}, {"text": "A primary challenge is that dialogs exhibit many different types of linguistic features, any or all of which, in principle, could be adapted.", "labels": [], "entities": []}, {"text": "Previous work has often focused on individual features when measuring adaptation, and referring expressions have often been the focus, but the conversants in the dialog in from the ArtWalk Corpus appear to be adapting to the discourse marker okay in D98 and F98, the hedge kinda like in F100, and to the adjectival phrase like a vase in D101.", "labels": [], "entities": [{"text": "ArtWalk Corpus", "start_pos": 181, "end_pos": 195, "type": "DATASET", "confidence": 0.9107311069965363}, {"text": "F100", "start_pos": 287, "end_pos": 291, "type": "METRIC", "confidence": 0.728010892868042}]}, {"text": "Therefore we propose a novel adaptation measure, Dialog Adaptation Score (DAS), which can model adaptation on any subset of linguistic features and can be applied on a turn by turn basis to any segment of dialog.", "labels": [], "entities": [{"text": "Dialog Adaptation Score (DAS)", "start_pos": 49, "end_pos": 78, "type": "METRIC", "confidence": 0.7274788469076157}]}, {"text": "Consider the example shown in, where the context (prime) is taken from an actual dialog.", "labels": [], "entities": []}, {"text": "A response (target) with no adaptation makes the utterance stiff (DAS = 0), and too much adaptation (to all four discourse markers in prime, DAS = 1) makes the utterance unnatural.", "labels": [], "entities": [{"text": "DAS", "start_pos": 66, "end_pos": 69, "type": "METRIC", "confidence": 0.9908315539360046}, {"text": "DAS", "start_pos": 141, "end_pos": 144, "type": "METRIC", "confidence": 0.9855142831802368}]}, {"text": "Our hypothesis is that we can learn models to approximate the appropriate amount of adaptation from the actual human response to the context (to discourse marker \"okay\", DAS = 0.25).", "labels": [], "entities": [{"text": "DAS", "start_pos": 170, "end_pos": 173, "type": "METRIC", "confidence": 0.9972732663154602}]}, {"text": "Conversants in dialogs express their own personality and adapt to their dialog partners simultaneously.", "labels": [], "entities": []}, {"text": "Our measure of adaptation produces models for adaptive natural language generation (NLG) for dialogs that integrates the predictions of both personality theories and adaptation theories.", "labels": [], "entities": [{"text": "adaptive natural language generation (NLG)", "start_pos": 46, "end_pos": 88, "type": "TASK", "confidence": 0.830019303730556}]}, {"text": "NLGs need to operate as a dialog unfolds on a turnby-turn basis, thus the requirements fora model of adaptation for NLG are different than simply measuring adaptation.", "labels": [], "entities": []}, {"text": "We apply our method to multiple corpora to investigate how the dialog situation and speaker roles affect the level and type of adaptation to the other speaker.", "labels": [], "entities": []}, {"text": "We show that: \u2022 Different feature sets and conversational situations can have different adaptation models; \u2022 Speakers usually adapt more when they have the initiative; \u2022 The degree of adaptation may vary over the course of a dialog, and decreases as the adaptation window size increases.", "labels": [], "entities": []}], "datasetContent": [{"text": "We consider the following feature sets: unigram, bigram, referring expressions, hedges/discourse markers, and Linguistic Inquiry and Word Count (LIWC) features.", "labels": [], "entities": []}, {"text": "Previous computational work on measuring linguistic adaptation in textual corpora have largely focused on lexical and syntactical features, which are included as baselines.", "labels": [], "entities": []}, {"text": "Referring expressions and discourse markers are key features that are commonly studied for adaptation behaviors in task-oriented dialogs, which are often hand annotated.", "labels": [], "entities": []}, {"text": "Here we automatically extract these features by rules.", "labels": [], "entities": []}, {"text": "To model adaptation on the personality level, we draw features that correlate significantly with personality ratings from LIWC features.", "labels": [], "entities": []}, {"text": "We hypothesize that our feature sets will demonstrate different adaptation models.", "labels": [], "entities": []}, {"text": "We lemmatize, POS tag and derive constituency structures using Stanford CoreNLP ().", "labels": [], "entities": [{"text": "Stanford CoreNLP", "start_pos": 63, "end_pos": 79, "type": "DATASET", "confidence": 0.9294982552528381}]}, {"text": "We then extract the following linguistic features from annotations and raw text.", "labels": [], "entities": []}, {"text": "The following example features are based on D137 in.", "labels": [], "entities": []}, {"text": "We use lemma combined with POS tags to distinguish word senses.", "labels": [], "entities": []}, {"text": "E.g., lemmapos building/NN and lemmapos brick/NNS in D137.", "labels": [], "entities": [{"text": "D137", "start_pos": 53, "end_pos": 57, "type": "DATASET", "confidence": 0.9188881516456604}]}, {"text": "E.g., bigram the-brick and bigram side-of in D137.", "labels": [], "entities": [{"text": "D137", "start_pos": 45, "end_pos": 49, "type": "DATASET", "confidence": 0.908399224281311}]}, {"text": "(2006b), we take all the subtrees from a constituency parse tree (excluding the leaf nodes that contain words) as features.", "labels": [], "entities": []}, {"text": "E.g., syntax VP->VBP+PP and syntax ADJP-> DT+JJ in D137.", "labels": [], "entities": []}, {"text": "The difference is that we use Stanford Parser rather than hand annotations.", "labels": [], "entities": []}, {"text": "Referring expressions are usually noun phrases.", "labels": [], "entities": []}, {"text": "We start by taking all constituency subtrees with root NP, then map the subtrees to their actual phrases in the text and remove all articles from the phrase, e.g., referexp little-concrete and referexp math-building in D137.", "labels": [], "entities": [{"text": "D137", "start_pos": 219, "end_pos": 223, "type": "DATASET", "confidence": 0.8879518508911133}]}, {"text": "Hedges are mitigating words used to lessen the impact of an utterance, such as \"actually\" and \"somewhat\".", "labels": [], "entities": [{"text": "Hedges", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.7963165044784546}]}, {"text": "Discourse markers are words or phrases that manage the flow and structure of discourse, such as \"you know\" and \"I mean\".", "labels": [], "entities": [{"text": "Discourse markers are words or phrases that manage the flow and structure of discourse, such as \"you know\" and \"I mean\"", "start_pos": 0, "end_pos": 119, "type": "Description", "confidence": 0.7668501276236314}]}, {"text": "We construct a dictionary of hedges and discourse markers, and use string matching to extract features, e.g., hedge you-know and hedge like in D137.", "labels": [], "entities": []}, {"text": "Linguistic Inquiry and Word Count) is a text analysis program that counts words in over 80 linguistic (e.g., pronouns, conjunctions), psychological (e.g., anger, positive emotion), and topical (e.g., leisure, money) categories.", "labels": [], "entities": []}, {"text": "E.g., liwc second-person and liwc informal in D137.", "labels": [], "entities": []}, {"text": "In this section, we apply our DAS measure on the corpora introduced in Section 3.", "labels": [], "entities": [{"text": "DAS measure", "start_pos": 30, "end_pos": 41, "type": "METRIC", "confidence": 0.9726302027702332}]}], "tableCaptions": [{"text": " Table 3: Number of dialogs in four corpora, and av- erage DAS scores of different feature sets for origi- nal and randomized dialogs. Bold numbers indicate  statistically significant differences (p < 0.0001)  between DAS scores for original and randomized  dialogs in paired t-tests .", "labels": [], "entities": [{"text": "av- erage DAS scores", "start_pos": 49, "end_pos": 69, "type": "METRIC", "confidence": 0.752298891544342}]}, {"text": " Table 4: Average DAS scores for each feature set.", "labels": [], "entities": [{"text": "Average DAS scores", "start_pos": 10, "end_pos": 28, "type": "METRIC", "confidence": 0.7863215406735738}]}]}