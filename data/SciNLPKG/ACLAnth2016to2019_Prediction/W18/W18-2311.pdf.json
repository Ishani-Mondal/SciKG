{"title": [{"text": "Biomedical Event Extraction Using Convolutional Neural Networks and Dependency Parsing", "labels": [], "entities": [{"text": "Biomedical Event Extraction", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7952572305997213}]}], "abstractContent": [{"text": "Event and relation extraction are central tasks in biomedical text mining.", "labels": [], "entities": [{"text": "Event and relation extraction", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.5798328220844269}, {"text": "biomedical text mining", "start_pos": 51, "end_pos": 73, "type": "TASK", "confidence": 0.7348274191220602}]}, {"text": "Where relation extraction concerns the detection of semantic connections between pairs of entities, event extraction expands this concept with the addition of trigger words, multiple arguments and nested events, in order to more accurately model the diversity of natural language.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 6, "end_pos": 25, "type": "TASK", "confidence": 0.7978987991809845}, {"text": "detection of semantic connections between pairs of entities", "start_pos": 39, "end_pos": 98, "type": "TASK", "confidence": 0.7378928810358047}, {"text": "event extraction", "start_pos": 100, "end_pos": 116, "type": "TASK", "confidence": 0.7149387151002884}]}, {"text": "In this work we develop a convolutional neural network that can be used for both event and relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 91, "end_pos": 110, "type": "TASK", "confidence": 0.7362251281738281}]}, {"text": "We use a linear representation of the input text, where information is encoded with various vector space embeddings.", "labels": [], "entities": []}, {"text": "Most notably, we encode the parse graph into this linear space using dependency path embeddings.", "labels": [], "entities": []}, {"text": "We integrate our neural network into the open source Turku Event Extraction System (TEES) framework.", "labels": [], "entities": [{"text": "Turku Event Extraction", "start_pos": 53, "end_pos": 75, "type": "TASK", "confidence": 0.7157324155171713}]}, {"text": "Using this system , our machine learning model can be easily applied to a large set of corpora from e.g. the BioNLP, DDI Extraction and BioCreative shared tasks.", "labels": [], "entities": [{"text": "BioNLP", "start_pos": 109, "end_pos": 115, "type": "DATASET", "confidence": 0.8541447520256042}]}, {"text": "We evaluate our system on 12 different event, relation and NER corpora, showing good general-izability to many tasks and achieving improved performance on several corpora.", "labels": [], "entities": []}], "introductionContent": [{"text": "Detection of semantic relations is a central task in biomedical text mining where information is retrieved from massive document sets, such as scientific literature or patient records.", "labels": [], "entities": [{"text": "Detection of semantic relations", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.926837682723999}, {"text": "biomedical text mining", "start_pos": 53, "end_pos": 75, "type": "TASK", "confidence": 0.6390434205532074}]}, {"text": "This information often consists of statements of interactions between named entities, such as signaling pathways between proteins in cells, or the combinatorial effects of drugs administered to a patient.", "labels": [], "entities": []}, {"text": "Relation and event extraction are the primary methods for retrieving such information.", "labels": [], "entities": [{"text": "Relation", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.9497671127319336}, {"text": "event extraction", "start_pos": 13, "end_pos": 29, "type": "TASK", "confidence": 0.7367609441280365}]}, {"text": "Relations are usually described as typed, sometimes directed, pairwise links between defined named entities.", "labels": [], "entities": []}, {"text": "Automated relation extraction aims to develop computational methods for their detection.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.7360253483057022}]}, {"text": "Event extraction is a proposed alternative for relation extraction.", "labels": [], "entities": [{"text": "Event extraction", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7327780425548553}, {"text": "relation extraction", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.9518694579601288}]}, {"text": "Events differ from relations in that they can connect together more than two entities, that they have an annotated trigger word (usually a verb) and that events can act as arguments of other events.", "labels": [], "entities": []}, {"text": "In the GENIA corpus, a sentence stating \"The binding of proteins A and B is regulated by protein C\" would be annotated with two nested events REGULATION(C, BIND(A, B)).", "labels": [], "entities": [{"text": "GENIA corpus", "start_pos": 7, "end_pos": 19, "type": "DATASET", "confidence": 0.9643173515796661}, {"text": "REGULATION", "start_pos": 142, "end_pos": 152, "type": "METRIC", "confidence": 0.99720698595047}, {"text": "BIND", "start_pos": 156, "end_pos": 160, "type": "METRIC", "confidence": 0.9913110733032227}]}, {"text": "While events can capture the semantics of text more accurately, their added complexity makes their extraction a more complicated task.", "labels": [], "entities": []}, {"text": "Many methods have been developed for relation extraction, with various kernel methods such as the graph kernel being widely used.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.9464405477046967}]}, {"text": "For the more complex task of event extraction approaches such as pipeline systems, semantic parsing) and joint inference ( ) have been explored.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 29, "end_pos": 45, "type": "TASK", "confidence": 0.7728087604045868}, {"text": "semantic parsing", "start_pos": 83, "end_pos": 99, "type": "TASK", "confidence": 0.7080323100090027}]}, {"text": "In recent years, the advent of deep learning has resulted in advances in many fields, and relation and event extraction are no exception.", "labels": [], "entities": [{"text": "relation and event extraction", "start_pos": 90, "end_pos": 119, "type": "TASK", "confidence": 0.6836777403950691}]}, {"text": "Considerable performance increases have been gained with methods such as convolutional () and recurrent neural networks.", "labels": [], "entities": []}, {"text": "Some proposed systems have relied entirely on word embeddings (, while others have developed various network architectures for utilizing parse graphs as an additional source of information.", "labels": [], "entities": []}, {"text": "In this work we present anew convolutional neural network method for extraction of both events and relations.", "labels": [], "entities": []}, {"text": "We integrate our network as a classification module into the Turku Event Extraction System , allowing it to be easily applied to corpora or texts stored in the TEES XML format.", "labels": [], "entities": [{"text": "Turku Event Extraction System", "start_pos": 61, "end_pos": 90, "type": "DATASET", "confidence": 0.810560554265976}, {"text": "TEES XML format", "start_pos": 160, "end_pos": 175, "type": "DATASET", "confidence": 0.864316721757253}]}, {"text": "Our neural network model is characterized by a unified representation of input examples that can be applied to detection of both keywords as well as their relations.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: The corpora used in this work are listed  with their domain, number of event and entity  types (E), number of event argument and relation  types (I), and number of sentences (S).", "labels": [], "entities": []}, {"text": " Table 2: Results. Performance is shown in Precision, Recall and F-score, measured on the corpus test  set for related work and our TEES CNN method (single best model, 5 model ensemble, or mixed 5 model  ensemble with randomized train/validation set split). Shared task winning results are indicated with *  and shared task participant results with  \u2020. The highest F-score for each corpus is shown in bold. All of  our results except for DDI11 are evaluated using the official evaluation program or server of each task.", "labels": [], "entities": [{"text": "Precision", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.9977734684944153}, {"text": "Recall", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.9688209891319275}, {"text": "F-score", "start_pos": 65, "end_pos": 72, "type": "METRIC", "confidence": 0.9979396462440491}, {"text": "TEES CNN", "start_pos": 132, "end_pos": 140, "type": "METRIC", "confidence": 0.7230569422245026}, {"text": "F-score", "start_pos": 365, "end_pos": 372, "type": "METRIC", "confidence": 0.975477933883667}, {"text": "DDI11", "start_pos": 438, "end_pos": 443, "type": "DATASET", "confidence": 0.9472442865371704}]}, {"text": " Table 3: The effect of path embeddings. The im- pact of using increasing depths of paths for em- beddings is shown in terms of averaged F-score  on the development set for entity (n) and edge (e)  detection.", "labels": [], "entities": [{"text": "F-score", "start_pos": 137, "end_pos": 144, "type": "METRIC", "confidence": 0.9940934777259827}]}]}