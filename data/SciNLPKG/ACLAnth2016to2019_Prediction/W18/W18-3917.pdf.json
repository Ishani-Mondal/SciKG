{"title": [{"text": "Comparing CRF and LSTM performance on the task of morphosyntactic tagging of non-standard varieties of South Slavic languages", "labels": [], "entities": [{"text": "LSTM", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.8224706649780273}, {"text": "morphosyntactic tagging of non-standard varieties of South Slavic languages", "start_pos": 50, "end_pos": 125, "type": "TASK", "confidence": 0.8265666166941324}]}], "abstractContent": [{"text": "This paper presents two systems taking part in the Morphosyntactic Tagging of Tweets shared task on Slovene, Croatian and Serbian data, organized inside the VarDial Evaluation Campaign.", "labels": [], "entities": [{"text": "Morphosyntactic Tagging of Tweets shared task", "start_pos": 51, "end_pos": 96, "type": "TASK", "confidence": 0.8516288797060648}, {"text": "VarDial Evaluation Campaign", "start_pos": 157, "end_pos": 184, "type": "DATASET", "confidence": 0.7898384928703308}]}, {"text": "While one system relies on the traditional method for sequence labeling (conditional random fields), the other relies on its neural alternative (bidirectional long short-term memory).", "labels": [], "entities": []}, {"text": "We investigate the similarities and differences of these two approaches, showing that both methods yield very good and quite similar results, with the neural model outperforming the traditional one more as the level of non-standardness of the text increases.", "labels": [], "entities": []}, {"text": "Through an error analysis we show that the neural system is better at long-range dependencies, while the traditional system excels and slightly outperforms the neural system at the local ones.", "labels": [], "entities": []}, {"text": "We present in the paper new state-of-the-art results in morphosyntactic annotation of non-standard text for Slovene, Croatian and Serbian.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper we present two systems taking part in the MTT (Morphosyntactic Tagging of Tweets) shared task, part of the VarDial Evaluation Campaign (.", "labels": [], "entities": [{"text": "MTT (Morphosyntactic Tagging of Tweets) shared task", "start_pos": 56, "end_pos": 107, "type": "TASK", "confidence": 0.7697994642787509}, {"text": "VarDial Evaluation Campaign", "start_pos": 121, "end_pos": 148, "type": "DATASET", "confidence": 0.7374650637308756}]}, {"text": "In the task, general-domain and indomain datasets with tokens manually annotated with morphosyntactic descriptions (MSDs), are given, together with large web-based datasets, for three South Slavic languages: Slovene, Croatian and Serbian.", "labels": [], "entities": []}, {"text": "The challenge of the task is to exploit similarity of standard vs. non-standard variants, as well as the overall proximity of the three languages in question.", "labels": [], "entities": [{"text": "similarity", "start_pos": 40, "end_pos": 50, "type": "METRIC", "confidence": 0.9619181156158447}]}, {"text": "While the first system, JANES, relies on the traditional method for sequence labeling, namely conditional random fields (CRF), the second system, JSI, relies on the currently hugely popular neural networks, more precisely bidirectional long short-term memories (BiLSTM).", "labels": [], "entities": [{"text": "JANES", "start_pos": 24, "end_pos": 29, "type": "DATASET", "confidence": 0.8452276587486267}, {"text": "JSI", "start_pos": 146, "end_pos": 149, "type": "DATASET", "confidence": 0.7834481596946716}]}, {"text": "The contributions of this paper are the following: (1) a direct comparison of CRFs and BiLSTMs on a series of datasets, where CRFs are equipped with carefully engineered features, not generic ones, and (2) anew state-of-the-art in tagging non-standard varieties of the three languages in question.", "labels": [], "entities": []}], "datasetContent": [{"text": "Before we describe our two systems participating in the task, we quickly quantify the available resources through token number in as these heavily influence our decisions in the system setup.", "labels": [], "entities": []}, {"text": "* datasets come from the Janes-Tag manually annotated dataset of Slovene computermediated communication () and the ReLDI-NormTagNER-* manually annotated datasets of Croatian) and Serbian) tweets.", "labels": [], "entities": [{"text": "Janes-Tag manually annotated dataset", "start_pos": 25, "end_pos": 61, "type": "DATASET", "confidence": 0.8120080530643463}, {"text": "ReLDI-NormTagNER-* manually annotated datasets", "start_pos": 115, "end_pos": 161, "type": "DATASET", "confidence": 0.6190699100494385}]}, {"text": "They are all similar in size, with cca.", "labels": [], "entities": []}, {"text": "40 thousand tokens available for training, 8 thousand for development and 20 thousand for testing.", "labels": [], "entities": []}, {"text": "The standard.train datasets mostly cover the general domain.", "labels": [], "entities": []}, {"text": "While the Slovene and Croatian datasets are similar in size with around 500 thousand tokens, the Serbian dataset is significantly smaller with only 87 thousand tokens.", "labels": [], "entities": []}, {"text": "The web.auto datasets are large web-based datasets, slWac for Slovene ( , hrWaC for Croatian and srWaC for Serbian).", "labels": [], "entities": [{"text": "web.auto datasets", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.7394921779632568}]}, {"text": "These are automatically annotated with state-of-the-art taggers of standard language for Slovene and: Size of datasets distributed through the MTT shared task.", "labels": [], "entities": [{"text": "MTT shared task", "start_pos": 143, "end_pos": 158, "type": "TASK", "confidence": 0.5198373794555664}]}, {"text": "Sizes are in number of tokens.", "labels": [], "entities": []}, {"text": "The third experiment considers the impact of not training the network on a simple merge of all the available relevant training data, but also fine-tuning the network exclusively on in-domain data.", "labels": [], "entities": []}, {"text": "Running three epochs on the concatenation of all datasets, and then additional two epochs only on the in-domain Twitter data, consistently improved the results for around half an accuracy point.", "labels": [], "entities": [{"text": "Twitter data", "start_pos": 112, "end_pos": 124, "type": "DATASET", "confidence": 0.8116970658302307}, {"text": "accuracy", "start_pos": 179, "end_pos": 187, "type": "METRIC", "confidence": 0.9994441866874695}]}, {"text": "This method is somewhat similar to the oversampling method applied on the JANES system.", "labels": [], "entities": [{"text": "JANES system", "start_pos": 74, "end_pos": 86, "type": "DATASET", "confidence": 0.9483561813831329}]}, {"text": "It is, however, more elegant as it gives greater control over the amount and order of data fed into the system.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Size of datasets distributed through the MTT shared task. Sizes are in number of tokens.", "labels": [], "entities": [{"text": "MTT shared task", "start_pos": 51, "end_pos": 66, "type": "TASK", "confidence": 0.5348367094993591}]}, {"text": " Table 3: Results of the two systems, their two adaptations and the baseline on the test data. Reported  metric is token-level accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 127, "end_pos": 135, "type": "METRIC", "confidence": 0.9533292055130005}]}]}