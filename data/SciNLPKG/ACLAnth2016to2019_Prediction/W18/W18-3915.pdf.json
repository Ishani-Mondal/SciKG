{"title": [{"text": "HeLI-based Experiments in Discriminating Between Dutch and Flemish Subtitles", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents the experiments and results obtained by the SUKI team in the Discriminating between Dutch and Flemish in Subtitles shared task of the VarDial 2018 Evaluation Campaign.", "labels": [], "entities": [{"text": "Discriminating between Dutch and Flemish in Subtitles shared task", "start_pos": 81, "end_pos": 146, "type": "TASK", "confidence": 0.7016047371758355}, {"text": "VarDial 2018 Evaluation Campaign", "start_pos": 154, "end_pos": 186, "type": "DATASET", "confidence": 0.8591531366109848}]}, {"text": "Our best submission was ranked 8th, obtaining macro F1-score of 0.61.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9066137671470642}]}, {"text": "Our best results were produced by a language identifier implementing the HeLI method without any modifications.", "labels": [], "entities": []}, {"text": "We describe, in addition to the best method we used, some of the experiments we did with unsupervised clustering.", "labels": [], "entities": []}], "introductionContent": [{"text": "The four first VarDial workshops have hosted several shared tasks concentrating on language identification of close languages or language varieties.", "labels": [], "entities": [{"text": "language identification of close languages or language varieties", "start_pos": 83, "end_pos": 147, "type": "TASK", "confidence": 0.8493175581097603}]}, {"text": "The fifth VarDial workshop ( ) introduced anew shared task concentrating on finding differences between the subtitles written in Netherlandic.", "labels": [], "entities": []}, {"text": "Netherlandic Dutch and Flemish Dutch are considered the same language by the ISO-639-3 standard since the Belgian dialect (Flemish) is only slightly different from the Dutch used in the Netherlands ().", "labels": [], "entities": []}, {"text": "We had never experimented with the language identification of Dutch varieties and we were interested to see how well it can be done with the methods we have used in the past.", "labels": [], "entities": [{"text": "language identification of Dutch varieties", "start_pos": 35, "end_pos": 77, "type": "TASK", "confidence": 0.8364118099212646}]}, {"text": "For the past five years we have been developing a language identifying method, which we call HeLI, for the Finno-Ugric Languages and the Internet project ().", "labels": [], "entities": [{"text": "Finno-Ugric Languages and the Internet project", "start_pos": 107, "end_pos": 153, "type": "DATASET", "confidence": 0.8198040227095286}]}, {"text": "The HeLI method is a general purpose language identification method relying on observations of word and character n-gram frequencies from a language labeled corpus.", "labels": [], "entities": [{"text": "language identification", "start_pos": 37, "end_pos": 60, "type": "TASK", "confidence": 0.7507564425468445}]}, {"text": "The method is similar to Naive Bayes when using only relative frequencies of words as probabilities.", "labels": [], "entities": []}, {"text": "Unlike Naive Bayes, it uses a back-off scheme to calculate the probabilities of individual words if the words themselves are not found in the language models.", "labels": [], "entities": []}, {"text": "The optimal combination of language models used with the back-off scheme depend on the situation and is determined empirically using a development set.", "labels": [], "entities": []}, {"text": "The choice is affected for example by the number and type of languages and the amount of training material.", "labels": [], "entities": []}, {"text": "The back-off scheme begins from the most rarely seen features and backs off to more common features.", "labels": [], "entities": []}, {"text": "We have participated in the shared tasks of three previous VarDial workshops ( with language identifiers using the HeLI method or its variations ().", "labels": [], "entities": []}, {"text": "The method has turned out to be robust and competitive with other state-of-the-art language identification methods.", "labels": [], "entities": [{"text": "language identification", "start_pos": 83, "end_pos": 106, "type": "TASK", "confidence": 0.7773833274841309}]}, {"text": "For the current workshop, we wanted to tryout some more variations and possible improvements to the original method.", "labels": [], "entities": []}, {"text": "In addition to the adaptive language models we experimented with unsupervised clustering.", "labels": [], "entities": []}], "datasetContent": [{"text": "We wanted to tryout an idea that using unsupervised clustering on the test set before actual language identification might be beneficial.", "labels": [], "entities": [{"text": "language identification", "start_pos": 93, "end_pos": 116, "type": "TASK", "confidence": 0.6817834675312042}]}, {"text": "The idea is that the lines of the test set written in the same language might be more alike with each other than with the material used for training the language identifier.", "labels": [], "entities": []}, {"text": "Grouping similar lines together would make it easier for the language identifier to identify the text as the length of the text to be identified is usually directly related to the accuracy of the identification).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 180, "end_pos": 188, "type": "METRIC", "confidence": 0.9989033937454224}]}, {"text": "To our knowledge, this strategy has not been used previously.", "labels": [], "entities": []}, {"text": "We decided to try clustering with an ad-hoc nearest neighbor clustering-method using the HeLI method as the similarity measure.", "labels": [], "entities": []}, {"text": "In our nearest neighbor clustering each line is considered a separate language and language models are created for them.", "labels": [], "entities": []}, {"text": "Each line is then scored using these models with the language model of the line itself omitted from the repertoire.", "labels": [], "entities": []}, {"text": "After scoring, each line is grouped in the same group with the line whose model gave the best score.", "labels": [], "entities": []}, {"text": "In this way each identified group would include at least two lines.", "labels": [], "entities": []}, {"text": "We created a separate language model for each of the 500 lines in the development set.", "labels": [], "entities": []}, {"text": "We tested clustering with lowercased character n-gram models.", "labels": [], "entities": []}, {"text": "The results of the accuracy of any line being paired with a line from the same language can be seen in  Character trigrams made the best clusters with accuracy of 59%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9991042017936707}, {"text": "accuracy", "start_pos": 151, "end_pos": 159, "type": "METRIC", "confidence": 0.9990274906158447}]}, {"text": "However, the grouping created by the unsupervised method seemed to be too random, so we concluded that identifying the groups would only make results worse and did not continue with these experiments.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Baseline HeLI recall in development data with different combinations of parameters.", "labels": [], "entities": [{"text": "HeLI", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.6463059186935425}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.7366405725479126}]}, {"text": " Table 2: Baseline HeLI statistics for run 1.", "labels": [], "entities": [{"text": "HeLI", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.47680360078811646}]}, {"text": " Table 3: Recall in development with different combinations of language models.", "labels": [], "entities": []}, {"text": " Table 4: Clustering accuracy with different language models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9916113018989563}]}]}