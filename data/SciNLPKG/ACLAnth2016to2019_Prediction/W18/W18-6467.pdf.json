{"title": [{"text": "MS-UEdin Submission to the WMT2018 APE Shared Task: Dual-Source Transformer for Automatic Post-Editing", "labels": [], "entities": [{"text": "WMT2018 APE", "start_pos": 27, "end_pos": 38, "type": "TASK", "confidence": 0.6605988144874573}]}], "abstractContent": [{"text": "This paper describes the Microsoft and University of Edinburgh submission to the Automatic Post-editing shared task at WMT2018.", "labels": [], "entities": [{"text": "WMT2018", "start_pos": 119, "end_pos": 126, "type": "DATASET", "confidence": 0.5840051174163818}]}, {"text": "Based on training data and systems from the WMT2017 shared task, we re-implement our own models from the last shared task and introduce improvements based on extensive parameter sharing.", "labels": [], "entities": [{"text": "WMT2017 shared task", "start_pos": 44, "end_pos": 63, "type": "DATASET", "confidence": 0.8328303098678589}]}, {"text": "Next we experiment with our implementation of dual-source transformer models and data selection for the IT domain.", "labels": [], "entities": [{"text": "data selection", "start_pos": 81, "end_pos": 95, "type": "TASK", "confidence": 0.7345717251300812}]}, {"text": "Our submissions decisively wins the SMT post-editing sub-task establishing the new state-of-the-art and is a very close second (or equal, 16.46 vs 16.50 TER) in the NMT sub-task.", "labels": [], "entities": [{"text": "SMT post-editing", "start_pos": 36, "end_pos": 52, "type": "TASK", "confidence": 0.8843410611152649}, {"text": "TER", "start_pos": 153, "end_pos": 156, "type": "METRIC", "confidence": 0.993431031703949}, {"text": "NMT sub-task", "start_pos": 165, "end_pos": 177, "type": "DATASET", "confidence": 0.7134198248386383}]}, {"text": "Based on the rather weak results in the NMT sub-task, we hypothesize that neural-on-neural APE might not be actually useful.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes the Microsoft (MS) and University of Edinburgh (UEdin) submission to the Automatic Post-editing shared task at WMT2018 ( . Based on training data and systems from the WMT2017 shared task, we re-implement our own models from the last shared task and introduce a few small improvements based on extensive parameter sharing.", "labels": [], "entities": [{"text": "WMT2018", "start_pos": 132, "end_pos": 139, "type": "DATASET", "confidence": 0.8258050084114075}, {"text": "WMT2017 shared task", "start_pos": 188, "end_pos": 207, "type": "DATASET", "confidence": 0.9007531603177389}]}, {"text": "Next, we experiment with our implementation of dual-source transformer models which have been available in our NMT toolkit Marian (Junczys-Dowmunt et al., 2018) since version v1.0 (November 2017).", "labels": [], "entities": [{"text": "NMT toolkit Marian (Junczys-Dowmunt et al., 2018)", "start_pos": 111, "end_pos": 160, "type": "DATASET", "confidence": 0.9355913877487183}]}, {"text": "We believe this is one of the first descriptions of such an architectures for Automatic Post-Editing (APE) purposes, but similar approaches have been used for two-step decoding, for instance in.", "labels": [], "entities": []}, {"text": "We further extend this model to share parameters across encoders with improved results for APE.", "labels": [], "entities": [{"text": "APE", "start_pos": 91, "end_pos": 94, "type": "TASK", "confidence": 0.4876556694507599}]}, {"text": "Our submissions decisively wins the SMT postediting sub-task establishing the new state-of-theart and is a very close second (or equal, 16.46 vs 16.50 TER) in the NMT sub-task.", "labels": [], "entities": [{"text": "SMT postediting", "start_pos": 36, "end_pos": 51, "type": "TASK", "confidence": 0.9074049293994904}, {"text": "TER", "start_pos": 151, "end_pos": 154, "type": "METRIC", "confidence": 0.9950475692749023}, {"text": "NMT sub-task", "start_pos": 163, "end_pos": 175, "type": "DATASET", "confidence": 0.7860889136791229}]}], "datasetContent": [{"text": "During the WMT2017 APE shared task we submitted a dual-source model with soft and hard attention which placed second right after a very similar dualsource model by the FBK team.", "labels": [], "entities": [{"text": "WMT2017 APE shared task", "start_pos": 11, "end_pos": 34, "type": "TASK", "confidence": 0.5289203375577927}, {"text": "FBK team", "start_pos": 168, "end_pos": 176, "type": "DATASET", "confidence": 0.9643228054046631}]}, {"text": "We include the performance of those models based on the shared task descriptions in, systems WMT17:FBK and WMT17:AMU (ours).", "labels": [], "entities": [{"text": "WMT17:FBK", "start_pos": 93, "end_pos": 102, "type": "DATASET", "confidence": 0.6998171508312225}, {"text": "WMT17:AMU", "start_pos": 107, "end_pos": 116, "type": "DATASET", "confidence": 0.7824737230936686}]}, {"text": "We mostly worked on the APE sub-task for automatic post-editing for the SMT system.", "labels": [], "entities": [{"text": "APE", "start_pos": 24, "end_pos": 27, "type": "METRIC", "confidence": 0.5438584685325623}, {"text": "SMT", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.9863944053649902}]}, {"text": "The system in the NMT sub-task seemed to have only small margins for improvements.", "labels": [], "entities": [{"text": "NMT sub-task", "start_pos": 18, "end_pos": 30, "type": "DATASET", "confidence": 0.6799988746643066}]}, {"text": "So far, we only trained on data that was available during WMT2017.", "labels": [], "entities": [{"text": "WMT2017", "start_pos": 58, "end_pos": 65, "type": "DATASET", "confidence": 0.7411884665489197}]}, {"text": "This year, the task organizers added anew large corpus created for automatic post-editing across many domains.", "labels": [], "entities": []}, {"text": "We experimented with domain selection algorithms for this corpus and tried to find subsets that would be better suited to the given IT domain.", "labels": [], "entities": []}, {"text": "We trained an 5-gram language model on a 10M words randomly sampled subset of the German IT training data and a similarly size language model on the eSCAPE data.", "labels": [], "entities": [{"text": "German IT training data", "start_pos": 82, "end_pos": 105, "type": "DATASET", "confidence": 0.8978828489780426}, {"text": "eSCAPE data", "start_pos": 149, "end_pos": 160, "type": "DATASET", "confidence": 0.9811205863952637}]}, {"text": "Next we applied cross-entropy filtering to produce domain scores.", "labels": [], "entities": []}, {"text": "We sorted eSCAPE by these scores and selected different sizes of subsets.", "labels": [], "entities": []}, {"text": "Smaller subsets should be more in-domain.", "labels": [], "entities": []}, {"text": "We experimented with 1M, 2M, 4M and all sentences (nearly 8M).", "labels": [], "entities": []}, {"text": "Results) remain however inconclusive.", "labels": [], "entities": []}, {"text": "Adding eSCAPE to the training data was generally helpful, but we did not see a clear winner across subsets and test sets.", "labels": [], "entities": []}, {"text": "In the end we use all the experimental models as components of a 4x ensemble.", "labels": [], "entities": []}, {"text": "The different training sets might as well serve as additional randomization factors potentially beneficial for ensembling.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Experiments with WMT 2017 data, correcting a phrase-base system.", "labels": [], "entities": [{"text": "WMT 2017 data", "start_pos": 27, "end_pos": 40, "type": "DATASET", "confidence": 0.9464348753293356}]}, {"text": " Table 2: Experiments with WMT 2017+eSCAPE data for SMT system.", "labels": [], "entities": [{"text": "WMT 2017+eSCAPE data", "start_pos": 27, "end_pos": 47, "type": "DATASET", "confidence": 0.830543053150177}, {"text": "SMT", "start_pos": 52, "end_pos": 55, "type": "TASK", "confidence": 0.9783118963241577}]}, {"text": " Table 3: APE Results provided by shared task orga- nizers. We only include best-scored results by each  team, see Chatterjee et al. (2018) for the full list of  results.", "labels": [], "entities": [{"text": "APE", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.6890034079551697}]}]}