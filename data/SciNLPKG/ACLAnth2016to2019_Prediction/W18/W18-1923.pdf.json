{"title": [{"text": "Portable speech-to-speech translation on an Android smartphone: The MFLTS system", "labels": [], "entities": [{"text": "MFLTS", "start_pos": 68, "end_pos": 73, "type": "DATASET", "confidence": 0.799803614616394}]}], "abstractContent": [{"text": "For US troops on the ground in countries like Iraq and Afghanistan, one of the key objectives, \"Winning the Heart and Minds\" of the local population, presents a formidable challenge due to the language barrier involved.", "labels": [], "entities": [{"text": "Winning the Heart and Minds\"", "start_pos": 96, "end_pos": 124, "type": "TASK", "confidence": 0.7588521142800649}]}, {"text": "Employing human interpreters to address the issue has many of its own challenges, foremost availability of locals to willingly act as such.", "labels": [], "entities": []}, {"text": "Because of this bottleneck, many of the Army's humanitarian missions are hindered as they require significant interaction between soldiers and the local population.", "labels": [], "entities": []}, {"text": "The Machine Foreign Language Translation System (MFLTS), a US Army project that originated out of DARPA's \"TransTac\" research effort, aims to address this bottleneck by equipping each soldier with a personal translation device running on a COTS Android smartphone.", "labels": [], "entities": [{"text": "Machine Foreign Language Translation System (MFLTS)", "start_pos": 4, "end_pos": 55, "type": "TASK", "confidence": 0.7375797927379608}]}, {"text": "With it, soldiers can maintain basic free-form conversations with individuals in a turn-based \"radio interview\" style, with specific focus on topics such as checkpoints, information gathering and medical help.", "labels": [], "entities": [{"text": "information gathering", "start_pos": 170, "end_pos": 191, "type": "TASK", "confidence": 0.7936471998691559}]}, {"text": "It can also be operated with optional peripherals that ease the interaction and improve the overall accuracy of the system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.9988489151000977}]}], "introductionContent": [{"text": "The paper is structured as follows: In Section 1 we outline the history of the MFLTS program, and in Section 2 we present the distinct challenges that have to be overcome when designing a speech-to-speech (S2S) Android application.", "labels": [], "entities": []}, {"text": "Section 3 presents a conclusion that looks forward to where the application could go.", "labels": [], "entities": []}], "datasetContent": [{"text": "When building a complex application such as an S2S application, it is not immediately obvious how to evaluate it in order to make improvements.", "labels": [], "entities": []}, {"text": "The simplest way, and this was done in the early days of the TransTac program, is by evaluating the systems through their individual components' performance: \u2022 Speech recognition: Word Error Rate (WER) \u2022 Machine translation: BLEU (and others) Because WER and BLEU scores are easily generated and compared, they are instinctively chosen for evaluation, but there is an assumption riding on using these low-level statistics, which is that an improvement in either of those scores translates to an improvement in the usability of the application.", "labels": [], "entities": [{"text": "Speech recognition", "start_pos": 160, "end_pos": 178, "type": "TASK", "confidence": 0.681966558098793}, {"text": "Word Error Rate (WER)", "start_pos": 180, "end_pos": 201, "type": "METRIC", "confidence": 0.870342622200648}, {"text": "Machine translation", "start_pos": 204, "end_pos": 223, "type": "TASK", "confidence": 0.7261432409286499}, {"text": "BLEU", "start_pos": 225, "end_pos": 229, "type": "METRIC", "confidence": 0.996830403804779}, {"text": "BLEU", "start_pos": 259, "end_pos": 263, "type": "METRIC", "confidence": 0.9926816821098328}]}, {"text": "What we found during the many iterations of the application is that, often that is not the case.", "labels": [], "entities": []}, {"text": "In fact, minute changes in the user interface often would cause far more drastic improvements in user satisfaction.", "labels": [], "entities": []}, {"text": "Because of this, later evaluations added the measurement of \"High Level Concept Transfer\": During an evaluation a soldier would be given a list of specific information he is trying to establish (e.g., \"what days of the week do supply trucks come through this town?\") by asking the FLE.", "labels": [], "entities": [{"text": "High Level Concept Transfer\"", "start_pos": 61, "end_pos": 89, "type": "TASK", "confidence": 0.6170135557651519}, {"text": "FLE", "start_pos": 281, "end_pos": 284, "type": "METRIC", "confidence": 0.9053170680999756}]}, {"text": "Systems were then compared by how many concepts (i.e. pieces of pertinent information) they were able to transmit in a given time period.", "labels": [], "entities": []}, {"text": "By the time of the MFLTS program, the software was being evaluated in mock exercises where it was being used (successfully) to gather actionable intelligence that helped soldiers achieve their mission objective.", "labels": [], "entities": [{"text": "MFLTS", "start_pos": 19, "end_pos": 24, "type": "TASK", "confidence": 0.7716345191001892}]}], "tableCaptions": []}