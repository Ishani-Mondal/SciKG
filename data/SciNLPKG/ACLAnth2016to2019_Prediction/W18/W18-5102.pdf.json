{"title": [{"text": "Hate Speech Dataset from a White Supremacy Forum", "labels": [], "entities": [{"text": "Hate Speech Dataset from a White Supremacy Forum", "start_pos": 0, "end_pos": 48, "type": "DATASET", "confidence": 0.8357024639844894}]}], "abstractContent": [{"text": "Hate speech is commonly defined as any communication that disparages a target group of people based on some characteristic such as race, colour, ethnicity, gender, sexual orientation , nationality, religion, or other characteristic.", "labels": [], "entities": [{"text": "Hate speech is commonly defined as any communication that disparages a target group of people based on some characteristic such as race, colour, ethnicity, gender, sexual orientation , nationality, religion, or other", "start_pos": 0, "end_pos": 216, "type": "Description", "confidence": 0.8646734043171531}]}, {"text": "Due to the massive rise of user-generated web content on social media, the amount of hate speech is also steadily increasing.", "labels": [], "entities": []}, {"text": "Over the past years, interest in online hate speech detection and, particularly, the automation of this task has continuously grown, along with the societal impact of the phenomenon.", "labels": [], "entities": [{"text": "hate speech detection", "start_pos": 40, "end_pos": 61, "type": "TASK", "confidence": 0.7248485088348389}, {"text": "automation", "start_pos": 85, "end_pos": 95, "type": "METRIC", "confidence": 0.9870266318321228}]}, {"text": "This paper describes a hate speech dataset composed of thousands of sentences manually labelled as containing hate speech or not.", "labels": [], "entities": []}, {"text": "The sentences have been extracted from Storm-front, a white supremacist forum.", "labels": [], "entities": [{"text": "Storm-front", "start_pos": 39, "end_pos": 50, "type": "DATASET", "confidence": 0.9278032779693604}]}, {"text": "A custom annotation tool has been developed to carryout the manual labelling task which, among other things, allows the annotators to choose whether to read the context of a sentence before labelling it.", "labels": [], "entities": []}, {"text": "The paper also provides a thoughtful qualitative and quantitative study of the resulting dataset and several baseline experiments with different classification models.", "labels": [], "entities": []}, {"text": "The dataset is publicly available.", "labels": [], "entities": []}], "introductionContent": [{"text": "The rapid growth of content in social networks such as Facebook, Twitter and blogs, makes it impossible to monitor what is being said.", "labels": [], "entities": []}, {"text": "The increase of cyberbullying and cyberterrorism, and the use of hate on the Internet, make the identification of hate in the web an essential ingredient for anti-bullying policies of social media, as Facebook's CEO Mark Zuckerberg recently acknowledged . This paper releases anew dataset of hate speech to further investigate the problem.", "labels": [], "entities": []}, {"text": "Although there is no universal definition for hate speech, the most accepted definition is provided by: \"any communication that disparages a target group of people based on some characteristic such as race, colour, ethnicity, gender, sexual orientation, nationality, religion, or other characteristic\".", "labels": [], "entities": [{"text": "any communication that disparages a target group of people based on some characteristic such as race, colour, ethnicity, gender, sexual orientation, nationality, religion, or other", "start_pos": 105, "end_pos": 285, "type": "Description", "confidence": 0.837896678596735}]}, {"text": "Consider the following 2 : (1) \"God bless them all, to hell with the blacks\" This sentence clearly contains hate speech against a target group because of their skin colour.", "labels": [], "entities": []}, {"text": "However, the identification of hate speech is often not so straightforward.", "labels": [], "entities": [{"text": "identification of hate speech", "start_pos": 13, "end_pos": 42, "type": "TASK", "confidence": 0.9250556528568268}]}, {"text": "Besides defining hate speech as a verbal abuse directed to a group of people because of specific characteristics, other definitions of hate speech in previous studies care to include the speaker's determination to inflect harm (.", "labels": [], "entities": []}, {"text": "In all, there seems to be a pattern shared by most of the literature consulted, which would define hate speech as a) a deliberate attack, b) directed towards a specific group of people, and c) motivated by actual or perceived aspects that form the group's identity.", "labels": [], "entities": []}, {"text": "This paper presents the first public dataset of hate speech annotated on Internet forum posts in English at sentence-level.", "labels": [], "entities": []}, {"text": "The dataset is publicly available in GitHub . The source forum is Stormfront 4 , the largest online community of white nationalists, characterised by pseudo-rational discussions of race, which include different degrees of offensiveness.", "labels": [], "entities": []}, {"text": "Stormfront is known as the first hate website).", "labels": [], "entities": [{"text": "Stormfront", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.945105791091919}]}], "datasetContent": [{"text": "This paper presents the first dataset of textual hate speech annotated at sentence-level.", "labels": [], "entities": []}, {"text": "Sentence-level annotation allows to work with the minimum unit containing hate speech and reduce noise introduced by other sentences that are clean.", "labels": [], "entities": [{"text": "Sentence-level annotation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8361819982528687}]}, {"text": "A total number of 10,568 sentences have been extracted from Stormfront and classified as conveying hate speech or not, and into two other auxiliary classes, as per the guidelines described in Section 3.2.", "labels": [], "entities": [{"text": "Stormfront", "start_pos": 60, "end_pos": 70, "type": "DATASET", "confidence": 0.899750828742981}]}, {"text": "In addition, the following information is also given for each sentence: a post identifier and the sentence's position in the post, a user identifier, a sub-forum identifier . This information makes it possible re-build the conversations these sentences belong to.", "labels": [], "entities": []}, {"text": "Furthermore, the number of previous posts the annotator had to read before making a decision over the category of the sentence is also given.", "labels": [], "entities": []}, {"text": "This section provides a quantitative description and statistical analysis of the clean dataset published.", "labels": [], "entities": []}, {"text": "shows the distribution of the sentences over categories.", "labels": [], "entities": []}, {"text": "The dataset is unbalanced as there exist many more sentences not conveying hate speech than 'hateful\" ones.", "labels": [], "entities": []}, {"text": "refers to the subset of sentences that have required reading additional context (i.e. previous comments to the one being annotated) to make an informed decision by the human annotators.", "labels": [], "entities": []}, {"text": "The category HATE is the one that requires more context, usually due to the use of slang unknown to the annotator or because the annotator needed to find out the actual target of an offensive mention.", "labels": [], "entities": [{"text": "HATE", "start_pos": 13, "end_pos": 17, "type": "METRIC", "confidence": 0.7323098182678223}]}, {"text": "The remaining of the section focuses only on the subset of the dataset composed of the categories HATE and NOHATE, which are the core of this work.", "labels": [], "entities": [{"text": "HATE", "start_pos": 98, "end_pos": 102, "type": "METRIC", "confidence": 0.9631916880607605}, {"text": "NOHATE", "start_pos": 107, "end_pos": 113, "type": "METRIC", "confidence": 0.9301275014877319}]}, {"text": "Regarding the distribution of sentences over Stormfront accounts, the dataset is balanced as there is no account that contributes notably more than any other: the average percentage of sentences is of 0.50 \u00b1 0.42 per account, the total amount of accounts in the dataset being 2,723.", "labels": [], "entities": [{"text": "Stormfront accounts", "start_pos": 45, "end_pos": 64, "type": "DATASET", "confidence": 0.9285153448581696}]}, {"text": "The sub-forums that contain more HATE belong to the category of news, discussion of views, politics, philosophy, as well as to specific countries (i.e., Ireland, Britain, and Canada).", "labels": [], "entities": []}, {"text": "In contrast, the subforums that contain more NOHATE sentences are about education and homeschooling, gatherings, and youth issues.", "labels": [], "entities": []}, {"text": "In order to obtain a more qualitative insight of the dataset, a HATE score (HS) has been calculated based on the Pointwise Mutual Information (PMI) value for each word towards the categories HATE and NOHATE.", "labels": [], "entities": [{"text": "HATE score (HS)", "start_pos": 64, "end_pos": 79, "type": "METRIC", "confidence": 0.9724566340446472}, {"text": "Pointwise Mutual Information (PMI) value", "start_pos": 113, "end_pos": 153, "type": "METRIC", "confidence": 0.7401543600218636}, {"text": "NOHATE", "start_pos": 200, "end_pos": 206, "type": "DATASET", "confidence": 0.5736943483352661}]}, {"text": "PMI allows calculating the corre-lation of each word with respect to each category.", "labels": [], "entities": [{"text": "PMI", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7466766238212585}]}, {"text": "The difference of the PMI value of a word wand the category HATE and the PMI of the same word wand the category NOHATE results in the HATE score of w, as shown in Formula 1.", "labels": [], "entities": [{"text": "PMI", "start_pos": 22, "end_pos": 25, "type": "METRIC", "confidence": 0.8361415266990662}, {"text": "PMI", "start_pos": 73, "end_pos": 76, "type": "METRIC", "confidence": 0.956167995929718}, {"text": "NOHATE", "start_pos": 112, "end_pos": 118, "type": "METRIC", "confidence": 0.8072431087493896}, {"text": "HATE score", "start_pos": 134, "end_pos": 144, "type": "METRIC", "confidence": 0.9846950471401215}]}, {"text": "Intuitively, this score is a simple way of capturing whether the presence of a word in a HATE context occurs significantly more often than in a NO-HATE context.", "labels": [], "entities": []}, {"text": "The results show that the most hateful words are derogatory or refer to targeted groups of hate speech.", "labels": [], "entities": []}, {"text": "On the other hand, the least hateful words are neutral in this regard and belong to the semantic fields of Internet, or temporal expressions, among others.", "labels": [], "entities": []}, {"text": "This shows that the vocabulary is discernible by category, which in turn suggests that the annotation and guidelines are sound.", "labels": [], "entities": []}, {"text": "Performing the same calculation with bi-grams yields expressions such as \"gene pool\", \"race traitor\", and \"white guilt\" for the most hateful category, which appear to be concepts related to race issues.", "labels": [], "entities": []}, {"text": "The less hateful terms are expressions such as \"white power\", \"white nationalism\" and \"pro white\", which clearly state the right-wing extremist politics of the forum users.", "labels": [], "entities": []}, {"text": "Finally, the dataset has been contrasted against the English vocabulary in Hatebase.", "labels": [], "entities": [{"text": "Hatebase", "start_pos": 75, "end_pos": 83, "type": "DATASET", "confidence": 0.9136053323745728}]}, {"text": "9.28% of HATE vocabulary overlaps with Hatebase, a higher percentage than for NOHATE vocabulary, of which 6.57% of the words can be found in Hatebase.", "labels": [], "entities": [{"text": "Hatebase", "start_pos": 39, "end_pos": 47, "type": "DATASET", "confidence": 0.9464257955551147}, {"text": "Hatebase", "start_pos": 141, "end_pos": 149, "type": "DATASET", "confidence": 0.973530650138855}]}, {"text": "In, the distribution of HATE vocabulary is shown over Hatebase's 8 categories.", "labels": [], "entities": [{"text": "Hatebase", "start_pos": 54, "end_pos": 62, "type": "DATASET", "confidence": 0.9453026056289673}]}, {"text": "Although some percentages are not high, all 8 categories are present in the corpus.", "labels": [], "entities": []}, {"text": "Most of the HATE words from the dataset belong to ethnicity, followed by gender.", "labels": [], "entities": [{"text": "HATE words", "start_pos": 12, "end_pos": 22, "type": "TASK", "confidence": 0.7095860242843628}]}, {"text": "This is in agreement with, who conducted a study to analyse the targets of hate in social networks and showed that hate based on race was the most common.", "labels": [], "entities": []}, {"text": "In order to further inspect the resulting dataset and to check the validity of the annotations (i.e. whether the two annotated classes are separable based solely on the text of the labelled instances) a set of baseline experiments have been conducted.", "labels": [], "entities": [{"text": "validity", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.9533315896987915}]}, {"text": "These experiments do not exploit any external resource such as lexicons, heuristics or rules.", "labels": [], "entities": []}, {"text": "The experiments just use the provided dataset and well-known approaches from the literature to provide a baseline for further research and improvement in the future.", "labels": [], "entities": []}, {"text": "The experiments are based on a balanced subset of labelled sentences.", "labels": [], "entities": []}, {"text": "All the sentences labelled as HATE have been collected, and an equivalent number of NOHATE sentences have been randomly sampled, summing up 2k labelled sentences.", "labels": [], "entities": [{"text": "HATE", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.9865090250968933}, {"text": "NOHATE", "start_pos": 84, "end_pos": 90, "type": "METRIC", "confidence": 0.9672113060951233}]}, {"text": "From this amount, the 80% has been used for training and the remaining 20% for testing.", "labels": [], "entities": []}, {"text": "The evaluated algorithms are the following: \u2022 Support Vector Machines (SVM)) over Bag-of-Words vectors.", "labels": [], "entities": []}, {"text": "Word-count-based vectors have been computed and fed into a Python Scikit-learn LinearSVM 11 classifier to separate HATE and NOHATE instances.", "labels": [], "entities": [{"text": "HATE", "start_pos": 115, "end_pos": 119, "type": "METRIC", "confidence": 0.7826424241065979}, {"text": "NOHATE", "start_pos": 124, "end_pos": 130, "type": "METRIC", "confidence": 0.5617508888244629}]}, {"text": "\u2022 Convolutional Neural Networks (CNN), as described in.", "labels": [], "entities": [{"text": "Convolutional Neural Networks (CNN)", "start_pos": 2, "end_pos": 37, "type": "TASK", "confidence": 0.6647245536247889}]}, {"text": "The implementation is a simplified version using a single input channel of randomly initialized word embeddings 12 . \u2022 Recurrent Neural Networks with Long Shortterm Memories (LSTM).", "labels": [], "entities": []}, {"text": "A LSTM layer of size 128 over word embeddings of size 300.", "labels": [], "entities": []}, {"text": "All the hyperparameters are left to the usual values reported in the literature (.", "labels": [], "entities": []}, {"text": "No hyperparameter tuning has been performed.", "labels": [], "entities": []}, {"text": "A more comprehensive experimentation and research has been left for future work.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Inter-annotator agreements on batches 1 and 2", "labels": [], "entities": []}, {"text": " Table 2: Distribution of sentences over categories in the  clean dataset", "labels": [], "entities": []}, {"text": " Table 3: Percentage of sentences for which the human  annotators asked for additional context", "labels": [], "entities": []}, {"text": " Table 4: Size of the categories HATE and NOHATE in  the clean dataset", "labels": [], "entities": [{"text": "HATE", "start_pos": 33, "end_pos": 37, "type": "METRIC", "confidence": 0.9958950281143188}, {"text": "NOHATE", "start_pos": 42, "end_pos": 48, "type": "METRIC", "confidence": 0.9826567769050598}]}, {"text": " Table 7: Results excluding sentences that required ad- ditional context for manual annotation", "labels": [], "entities": []}, {"text": " Table 8: Results including sentences that required ad- ditional context for manual annotation", "labels": [], "entities": []}]}