{"title": [{"text": "An Analysis of Attention Mechanisms: The Case of Word Sense Disambiguation in Neural Machine Translation", "labels": [], "entities": [{"text": "Word Sense Disambiguation in Neural Machine Translation", "start_pos": 49, "end_pos": 104, "type": "TASK", "confidence": 0.6362806516034263}]}], "abstractContent": [{"text": "Recent work has shown that the encoder-decoder attention mechanisms in neural machine translation (NMT) are different from the word alignment in statistical machine translation.", "labels": [], "entities": [{"text": "neural machine translation (NMT)", "start_pos": 71, "end_pos": 103, "type": "TASK", "confidence": 0.8405401309331259}, {"text": "word alignment", "start_pos": 127, "end_pos": 141, "type": "TASK", "confidence": 0.7081525027751923}, {"text": "statistical machine translation", "start_pos": 145, "end_pos": 176, "type": "TASK", "confidence": 0.6428998013337454}]}, {"text": "In this paper, we focus on analyzing encoder-decoder attention mechanisms, in the case of word sense disambiguation (WSD) in NMT models.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 90, "end_pos": 121, "type": "TASK", "confidence": 0.7747249354918798}]}, {"text": "We hypothesize that attention mechanisms pay more attention to context tokens when translating ambiguous words.", "labels": [], "entities": []}, {"text": "We explore the attention distribution patterns when translating ambiguous nouns.", "labels": [], "entities": []}, {"text": "Counter-intuitively, we find that attention mechanisms are likely to distribute more attention to the ambiguous noun itself rather than context tokens , in comparison to other nouns.", "labels": [], "entities": []}, {"text": "We conclude that attention is not the main mechanism used by NMT models to incorporate con-textual information for WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 115, "end_pos": 118, "type": "TASK", "confidence": 0.9615208506584167}]}, {"text": "The experimental results suggest that NMT models learn to encode contextual information necessary for WSD in the encoder hidden states.", "labels": [], "entities": [{"text": "WSD", "start_pos": 102, "end_pos": 105, "type": "TASK", "confidence": 0.9237286448478699}]}, {"text": "For the attention mechanism in Transformer models, we reveal that the first few layers gradually learn to \"align\" source and target tokens and the last few layers learn to extract features from the related but unaligned context tokens.", "labels": [], "entities": []}], "introductionContent": [{"text": "Human languages exhibit many different types of ambiguity.", "labels": [], "entities": []}, {"text": "Lexical ambiguity refers to the fact that words can have more than one semantic meaning.", "labels": [], "entities": [{"text": "Lexical ambiguity", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8537052869796753}]}, {"text": "Dealing with these lexical ambiguities is a challenge for various NLP tasks.", "labels": [], "entities": []}, {"text": "Word sense disambiguation (WSD) is recognizing the correct meaning of an ambiguous word, with the help of contextual information.", "labels": [], "entities": [{"text": "Word sense disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8304163664579391}, {"text": "recognizing the correct meaning of an ambiguous word", "start_pos": 35, "end_pos": 87, "type": "TASK", "confidence": 0.7210261523723602}]}, {"text": "In statistical machine translation (SMT) (, a system could explicitly take context tokens into account to improve the translation of ambiguous words).", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 3, "end_pos": 40, "type": "TASK", "confidence": 0.8067351231972376}]}, {"text": "By contrast, in neural machine translation (NMT)), especially in attentional NMT (, each hidden state incorporates contextual information.", "labels": [], "entities": [{"text": "neural machine translation (NMT))", "start_pos": 16, "end_pos": 49, "type": "TASK", "confidence": 0.8648372193177541}]}, {"text": "Hence, NMT models could potentially perform WSD well.", "labels": [], "entities": [{"text": "WSD", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.9511842727661133}]}, {"text": "However, there are no empirical results to indicate that the hidden states encode the contextual information needed for disambiguation.", "labels": [], "entities": []}, {"text": "Moreover, how the attention mechanism 1 deals with ambiguous words is also not known yet.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the question of how encoder-decoder attention mechanisms deal with ambiguous nouns.", "labels": [], "entities": []}, {"text": "We explore two different attention mechanisms.", "labels": [], "entities": []}, {"text": "One is the vanilla one-layer attention mechanism (, and the other one is the Transformer attention mechanism (.", "labels": [], "entities": [{"text": "Transformer attention", "start_pos": 77, "end_pos": 98, "type": "TASK", "confidence": 0.7015694379806519}]}, {"text": "find that attentional NMT models perform well in translating ambiguous words with frequent senses, 2 while show that there are plenty of incorrect translations of ambiguous words.", "labels": [], "entities": [{"text": "translating ambiguous words", "start_pos": 49, "end_pos": 76, "type": "TASK", "confidence": 0.8852642973264059}]}, {"text": "In Section 4, we evaluate the translations of ambiguous nouns, using the test set from.", "labels": [], "entities": []}, {"text": "In this setting, we expect to get a more accurate picture of the WSD performance of NMT models.", "labels": [], "entities": [{"text": "WSD", "start_pos": 65, "end_pos": 68, "type": "TASK", "confidence": 0.9316179752349854}]}, {"text": "In Section 5, we present a fine-grained investigation of attention distributions of different attention mechanisms.", "labels": [], "entities": []}, {"text": "We focus on the process of translating the given ambiguous nouns.", "labels": [], "entities": []}, {"text": "Previous studies have shown that attention mechanisms learn to pay attention to some unaligned but useful context tokens for predictions.", "labels": [], "entities": []}, {"text": "Thus, we hypothesize that attention mechanisms distribute more attention to context tokens when translating ambiguous nouns, compared to when translating other words.", "labels": [], "entities": []}, {"text": "To test this hypothesis, we compare the attention weight over ambiguous nouns with the attention weight overall words and all nouns.", "labels": [], "entities": []}, {"text": "In Section 6, we first compare the two different attention mechanisms.", "labels": [], "entities": []}, {"text": "Then, we explore the relation between accuracy and attention distributions when translating ambiguous nouns.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9986590147018433}, {"text": "translating ambiguous nouns", "start_pos": 80, "end_pos": 107, "type": "TASK", "confidence": 0.823687732219696}]}, {"text": "In the end, we investigate the error distributions over frequency.", "labels": [], "entities": []}, {"text": "Our main findings are summarized as follows: \u2022 We find that WSD is challenging in NMT, and data sparsity is one of the main issues.", "labels": [], "entities": [{"text": "WSD", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.9566161036491394}]}, {"text": "\u2022 We show that attention mechanisms prefer to pay more attention to the ambiguous nouns rather than context tokens when translating ambiguous nouns.", "labels": [], "entities": []}, {"text": "\u2022 We conclude that encoder-decoder attention is not the main mechanism used by NMT models to incorporate contextual information for WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 132, "end_pos": 135, "type": "TASK", "confidence": 0.8812013864517212}]}, {"text": "Experimental results suggest that models learn to encode contextual information necessary for WSD in the encoder hidden states.", "labels": [], "entities": [{"text": "WSD", "start_pos": 94, "end_pos": 97, "type": "TASK", "confidence": 0.9260514974594116}]}, {"text": "\u2022 We reveal that the attention mechanism in Transformers first gradually learns to extract features from the \"aligned\" source tokens.", "labels": [], "entities": []}, {"text": "Then, it learns to capture features from the related but unaligned source context tokens.", "labels": [], "entities": []}], "datasetContent": [{"text": "Instead of using NMT models to score the contrastive translations, we use NMT models to translate source sentences and evaluate the translations of the ambiguous nouns directly.", "labels": [], "entities": []}, {"text": "We evaluate two popular NMT models with different attention mechanisms.", "labels": [], "entities": []}, {"text": "One is RNNS2S with the vanilla attention mechanism, and the other is Transformer with the advanced attention mechanism.", "labels": [], "entities": []}, {"text": "We apply fast-align () to get the aligned translations of ambiguous nouns.", "labels": [], "entities": []}, {"text": "To achieve better alignment, we run fast-align on both training data and test data which includes reference translations and generated translations.", "labels": [], "entities": [{"text": "alignment", "start_pos": 18, "end_pos": 27, "type": "TASK", "confidence": 0.9526868462562561}]}, {"text": "However, for some ambiguous nouns, there is no alignment.", "labels": [], "entities": []}, {"text": "We call these ambiguous nouns filtered.", "labels": [], "entities": []}, {"text": "There are multiple reference translations for each ambiguous noun in ContraWSD.", "labels": [], "entities": [{"text": "ContraWSD", "start_pos": 69, "end_pos": 78, "type": "DATASET", "confidence": 0.8858587145805359}]}, {"text": "We additionally add their synonyms 4 into the reference translations as well.", "labels": [], "entities": []}, {"text": "The non-reference translations are crawled from the Internet . In addition to the filtered nouns, the translations of the ambiguous nouns are classified into six groups, depending on which class (references, incorrect senses, no translation) the translations at aligned/unaligned positions belong to, as described in.", "labels": [], "entities": []}, {"text": "For instance, in C3, there is neither a correct nor an incorrect sense at the aligned position.", "labels": [], "entities": []}, {"text": "However, there is a reference translation at an unaligned position.", "labels": [], "entities": []}, {"text": "We use the Sockeye (Hieber et al., 2017) toolkit, which is based on MXNet (, to train models.", "labels": [], "entities": [{"text": "Sockeye (Hieber et al., 2017) toolkit", "start_pos": 11, "end_pos": 48, "type": "DATASET", "confidence": 0.9295072423087226}, {"text": "MXNet", "start_pos": 68, "end_pos": 73, "type": "DATASET", "confidence": 0.9291520714759827}]}, {"text": "In addition, we have extended Sockeye to output the distributions of encoder-decoder attention in Transformer models, from different attention heads and different attention layers.", "labels": [], "entities": []}, {"text": "All the models are trained with 2 GPUs.", "labels": [], "entities": []}, {"text": "During training, each mini-batch contains 4096 tokens.", "labels": [], "entities": []}, {"text": "A model checkpoint is saved every 4,000 updates.", "labels": [], "entities": []}, {"text": "We use Adam ( as the optimizer.", "labels": [], "entities": []}, {"text": "The initial learning rate is set to 0.0002.", "labels": [], "entities": []}, {"text": "If the performance on the validation set has not improved for 8 checkpoints, the learning rate is multiplied by 0.7.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 81, "end_pos": 94, "type": "METRIC", "confidence": 0.9641678035259247}]}, {"text": "We set the early stopping patience to 32 checkpoints.", "labels": [], "entities": [{"text": "early stopping", "start_pos": 11, "end_pos": 25, "type": "TASK", "confidence": 0.5968718826770782}]}, {"text": "All the neural networks have 8 layers.", "labels": [], "entities": []}, {"text": "For RNNS2S, the encoder has 1 bi-directional LSTM and 6 stacked uni-directional LSTMs, and the decoder is a stack of 8 unidirectional LSTMs.", "labels": [], "entities": []}, {"text": "The size of embeddings and hidden states is 512.", "labels": [], "entities": []}, {"text": "We apply layer-normalization and label smoothing (0.1) in all models.", "labels": [], "entities": []}, {"text": "We tie the source and target embeddings.", "labels": [], "entities": []}, {"text": "The dropout rate of embeddings and Transformer blocks is set to 0.1.", "labels": [], "entities": [{"text": "dropout rate", "start_pos": 4, "end_pos": 16, "type": "METRIC", "confidence": 0.9362712502479553}]}, {"text": "The dropout rate of RNNs is 0.2.", "labels": [], "entities": [{"text": "dropout rate", "start_pos": 4, "end_pos": 16, "type": "METRIC", "confidence": 0.9733812808990479}]}, {"text": "The attention mechanism in Transformer has 8 heads.", "labels": [], "entities": []}, {"text": "We use the training data from the WMT17 shared task.", "labels": [], "entities": [{"text": "WMT17 shared task", "start_pos": 34, "end_pos": 51, "type": "DATASET", "confidence": 0.8630529244740804}]}, {"text": "We choose newstest2013 as the validation set, and use newstest2014 and newstest2017 as the test sets.", "labels": [], "entities": []}, {"text": "All the BLEU scores are measured by SacreBLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 8, "end_pos": 12, "type": "METRIC", "confidence": 0.9985114932060242}, {"text": "SacreBLEU", "start_pos": 36, "end_pos": 45, "type": "DATASET", "confidence": 0.8833757638931274}]}, {"text": "There are about 5.9 million sentence pairs in the training set after preprocessing with Moses scripts.", "labels": [], "entities": []}, {"text": "We learn a joint BPE model with 32,000 subword units ().", "labels": [], "entities": []}, {"text": "There are 6,330 sentences left after filtering the sentences with segmented ambiguous nouns.", "labels": [], "entities": []}, {"text": "We employ the models that have the best perplexity on the validation set for the evaluation.", "labels": [], "entities": []}, {"text": "gives the performance of NMT models on newstests and ContraWSD.", "labels": [], "entities": [{"text": "ContraWSD", "start_pos": 53, "end_pos": 62, "type": "DATASET", "confidence": 0.9246547222137451}]}, {"text": "The detailed translation distributions over different groups are also provided.", "labels": [], "entities": []}, {"text": "Transformer is much better than RNNS2S in both newstests and ContraWSD.", "labels": [], "entities": [{"text": "Transformer", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.6261465549468994}, {"text": "ContraWSD", "start_pos": 61, "end_pos": 70, "type": "DATASET", "confidence": 0.9469640254974365}]}, {"text": "Compared to the accuracy of scoring contrastive translation pairs (Score), the accuracy of evaluating the translations (Acc.) is apparently lower.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9987872242927551}, {"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9995006322860718}, {"text": "Acc.)", "start_pos": 120, "end_pos": 125, "type": "METRIC", "confidence": 0.9789319038391113}]}], "tableCaptions": [{"text": " Table 2: Evaluation results of NMT models and the distributions of translations. 2014 and 2017 denote the BLEU  scores on newstest2014 and newstest2017, Acc. (in %) is short for accuracy. Score (in %) is the accuracy using  NMT models to score contrastive translation pairs. Filtered is the amount of translations that there is no learnt  alignment for the ambiguous nouns.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 107, "end_pos": 111, "type": "METRIC", "confidence": 0.9996381998062134}, {"text": "newstest2014", "start_pos": 123, "end_pos": 135, "type": "DATASET", "confidence": 0.9413979649543762}, {"text": "newstest2017", "start_pos": 140, "end_pos": 152, "type": "DATASET", "confidence": 0.8826571702957153}, {"text": "Acc.", "start_pos": 154, "end_pos": 158, "type": "METRIC", "confidence": 0.9826233685016632}, {"text": "accuracy", "start_pos": 179, "end_pos": 187, "type": "METRIC", "confidence": 0.9992085099220276}, {"text": "accuracy", "start_pos": 209, "end_pos": 217, "type": "METRIC", "confidence": 0.9940308928489685}]}, {"text": " Table 3: Average attention weights over ambiguous  nouns, non-subword tokens, and nouns.", "labels": [], "entities": [{"text": "Average attention weights", "start_pos": 10, "end_pos": 35, "type": "METRIC", "confidence": 0.8509014248847961}]}]}