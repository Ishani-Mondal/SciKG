{"title": [{"text": "Exploring Gap Filling as a Cheaper Alternative to Reading Comprehension Questionnaires when Evaluating Machine Translation for Gisting", "labels": [], "entities": [{"text": "Exploring Gap Filling", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7255585590998331}, {"text": "Evaluating Machine Translation", "start_pos": 92, "end_pos": 122, "type": "TASK", "confidence": 0.7442134022712708}, {"text": "Gisting", "start_pos": 127, "end_pos": 134, "type": "TASK", "confidence": 0.6819742321968079}]}], "abstractContent": [{"text": "A popular application of machine translation (MT) is gisting: MT is consumed as is to make sense of text in a foreign language.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.8529167234897613}]}, {"text": "Evaluation of the usefulness of MT for gist-ing is surprisingly uncommon.", "labels": [], "entities": [{"text": "MT", "start_pos": 32, "end_pos": 34, "type": "TASK", "confidence": 0.9857478737831116}]}, {"text": "The classical method uses reading comprehension questionnaires (RCQ), in which informants are asked to answer professionally-written questions in their language about a foreign text that has been machine-translated into their language.", "labels": [], "entities": []}, {"text": "Recently, gap-filling (GF), a form of cloze testing , has been proposed as a cheaper alternative to RCQ.", "labels": [], "entities": []}, {"text": "In GF, certain words are removed from reference translations and readers are asked to fill the gaps left using the machine-translated text as a hint.", "labels": [], "entities": []}, {"text": "This paper reports, for the first time, a comparative evaluation , using both RCQ and GF, of translations from multiple MT systems for the same foreign texts, and a systematic study on the effect of variables such as gap density, gap-selection strategies, and document context in GF.", "labels": [], "entities": []}, {"text": "The main findings of the study are: (a) both RCQ and GF clearly identify MT to be useful; (b) global RCQ and GF rankings for the MT systems are mostly in agreement; (c) GF scores vary very widely across informants, making comparisons among MT systems hard, and (d) unlike RCQ, which is framed around documents , GF evaluation can be framed at the sentence level.", "labels": [], "entities": [{"text": "MT", "start_pos": 73, "end_pos": 75, "type": "TASK", "confidence": 0.9022178053855896}]}, {"text": "These findings support the use of GF as a cheaper alternative to RCQ.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "A straightforward (but costly) way to evaluate MT for gisting measures the performance of targetlanguage readers in a text-mediated task -for instance, a software installation task)-by using raw MT and compares it with the performance reached using a professional translation of the text.", "labels": [], "entities": [{"text": "MT", "start_pos": 47, "end_pos": 49, "type": "TASK", "confidence": 0.9846190810203552}]}, {"text": "However, there maybe scenarios without an obvious associated task: news, product and service reviews, or literature.", "labels": [], "entities": []}, {"text": "On the other hand, even with a clear associated task, task completion evaluation is also quite expensive.", "labels": [], "entities": [{"text": "task completion evaluation", "start_pos": 54, "end_pos": 80, "type": "TASK", "confidence": 0.7720528642336527}]}, {"text": "It is therefore desirable to have alternative objective indicators which work as good surrogates for actual task-oriented success.", "labels": [], "entities": []}, {"text": "Some authors have proposed eye-tracking) as a measure of machine translation usefulness, but the technique is expensive and the evidence gathered is rather indirect and does not have a straightforward interpretation in terms of usefulness.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.8111984729766846}]}, {"text": "Direct assessments of adequacy and MT ranking are the official evaluation procedure for the most recent WMT translation shared task campaigns.", "labels": [], "entities": [{"text": "MT ranking", "start_pos": 35, "end_pos": 45, "type": "TASK", "confidence": 0.6450454294681549}, {"text": "WMT translation shared task", "start_pos": 104, "end_pos": 131, "type": "TASK", "confidence": 0.9391391277313232}]}, {"text": "Other researchers use post-task questionnaires ( to assess the perceived usefulness of MT output.", "labels": [], "entities": [{"text": "MT output", "start_pos": 87, "end_pos": 96, "type": "TASK", "confidence": 0.8948634266853333}]}, {"text": "Direct assessment, ranking or post-task questionnaire evaluation methods are clearly subjective and require informants to make \"in vitro\" judgements about the quality of MT outputs, without considering their usefulness fora specific \"in vivo\", real-world application.", "labels": [], "entities": [{"text": "MT outputs", "start_pos": 170, "end_pos": 180, "type": "TASK", "confidence": 0.9117072224617004}]}, {"text": "An alternative approach to RCQs, gap filling (GF), has been recently proposed) based on another typical way of measuring reading comprehension: cloze (or closure) testing.", "labels": [], "entities": [{"text": "gap filling (GF)", "start_pos": 33, "end_pos": 49, "type": "TASK", "confidence": 0.8098652243614197}]}, {"text": "Instead of a question, readers get an incomplete sentence with one or more words replaced by gaps, and are asked to fill the gaps.", "labels": [], "entities": []}, {"text": "Indeed, GF maybe seen as equivalent to the answering of simple reading comprehension questions: for instance, a question like Who was the president of the Green Party in 2011?", "labels": [], "entities": [{"text": "GF", "start_pos": 8, "end_pos": 10, "type": "TASK", "confidence": 0.9526874423027039}, {"text": "Who was the president of the Green Party in 2011?", "start_pos": 126, "end_pos": 175, "type": "TASK", "confidence": 0.560616439039057}]}, {"text": "would be equivalent to the sentence with one gap In 2011, was the president of the Green Party.", "labels": [], "entities": []}, {"text": "GF tasks are prepared by automatically punching gaps in reference sentences taken from a professional translation of the source text.", "labels": [], "entities": [{"text": "GF tasks", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.8141448199748993}]}, {"text": "Informants are given the machine-translated sentence as a \"hint\" for the gap-filling task; therefore, we may view GF as away of automatically generating questions to evaluate the MT output.", "labels": [], "entities": [{"text": "MT output", "start_pos": 179, "end_pos": 188, "type": "TASK", "confidence": 0.8807547688484192}]}, {"text": "The evaluation measure is the proportion of gaps that can be successfully filled using MT as a hint.", "labels": [], "entities": []}, {"text": "This can be compared with the success rate in the case where no hint (MT) is provided, to give an estimate of the usefulness of MT output.", "labels": [], "entities": [{"text": "MT", "start_pos": 128, "end_pos": 130, "type": "TASK", "confidence": 0.9507269263267517}]}, {"text": "Note that cloze testing evaluation of machine translation was attempted decades ago in a completely different readability setting: gaps were then punched in machine-translated output and informants tried to complete them without any further hint.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.7153756022453308}]}, {"text": "This work was reviewed and extended later by.", "labels": [], "entities": []}, {"text": "But filling gaps in machine-translated output maybe unnecessarily challenging and therefore make evaluation less adequate: for instance, informants would sometimes have to fill gaps in disfluent or ungrammatical text, which is much harder than filling them in a fluent, professionally translated reference, or, even in fluent output, a crucial content word that has been removed maybe very hard to guess unless the surrounding text is very redundant.", "labels": [], "entities": []}, {"text": "Moreover, the GF method described here has an easier interpretation in terms of its analogy to RCQ.", "labels": [], "entities": []}, {"text": "This paper systematically builds upon previous work on GF to obtain experimental evidence that gap-filling is a viable, lower-cost alternative to RCQ evaluation.", "labels": [], "entities": [{"text": "GF", "start_pos": 55, "end_pos": 57, "type": "TASK", "confidence": 0.8249416351318359}, {"text": "RCQ evaluation", "start_pos": 146, "end_pos": 160, "type": "TASK", "confidence": 0.8455320298671722}]}, {"text": "Its main contributions are: \u2022 While Trosterud and Unhammer (2012), O'Regan and Forcada (2013), and used GF just to demonstrate the usefulness of a single rule-based MT system for each language pair studied, this paper, like, performs a comparison of several MT systems for the same language pair.", "labels": [], "entities": []}, {"text": "\u2022 Previous work) simply assumes the validity of GF as an evaluation method for MT gisting, in some cases arguing about its equivalence to RCQ.", "labels": [], "entities": [{"text": "MT gisting", "start_pos": 79, "end_pos": 89, "type": "TASK", "confidence": 0.8998577892780304}]}, {"text": "Ours is the first work to actually compare GF and RCQ evaluation of the same MT systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 77, "end_pos": 79, "type": "TASK", "confidence": 0.9745875000953674}]}, {"text": "\u2022 Previous work used sentences) or short excerpts of text (Jordan-), but did not study the influence of a larger, documentlevel machine-translated context around the target sentence, as it is done here.", "labels": [], "entities": []}, {"text": "\u2022 This paper explores for the first time a gappositioning strategy based on an approximate computation of gap entropy, and compares it to random placing of gaps.", "labels": [], "entities": []}, {"text": "The paper is organized as follows: section 2 describes the design and implementation of both evaluation methods, RCQ and GF; then section 3 reports and discusses the results obtained; and, finally, concluding remarks (section 4) close the paper.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: A comparison of BLEU and NIST scores, RCQ marks in the three possible weightings, and GF success rates at", "labels": [], "entities": [{"text": "BLEU", "start_pos": 26, "end_pos": 30, "type": "METRIC", "confidence": 0.9947959780693054}, {"text": "NIST", "start_pos": 35, "end_pos": 39, "type": "DATASET", "confidence": 0.8074043989181519}, {"text": "GF success", "start_pos": 96, "end_pos": 106, "type": "METRIC", "confidence": 0.9379464089870453}]}, {"text": " Table 2: Effect in success rates of allowing for synonyms in GF", "labels": [], "entities": [{"text": "GF", "start_pos": 62, "end_pos": 64, "type": "TASK", "confidence": 0.4547898471355438}]}]}