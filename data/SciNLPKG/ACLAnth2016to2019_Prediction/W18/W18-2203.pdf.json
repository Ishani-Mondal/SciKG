{"title": [{"text": "Tibetan-Chinese Neural Machine Translation based on Syllable Segmentation", "labels": [], "entities": [{"text": "Neural Machine Translation", "start_pos": 16, "end_pos": 42, "type": "TASK", "confidence": 0.6108564833799998}, {"text": "Syllable Segmentation", "start_pos": 52, "end_pos": 73, "type": "TASK", "confidence": 0.7681888937950134}]}], "abstractContent": [{"text": "Machine translation is one of the important research directions in natural language processing.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8680408298969269}, {"text": "natural language processing", "start_pos": 67, "end_pos": 94, "type": "TASK", "confidence": 0.6520664095878601}]}, {"text": "In recent years, neural machine translation methods have surpassed traditional statistical machine translation methods in translation performance of most of language and have become the mainstream methods of machine translation.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 17, "end_pos": 43, "type": "TASK", "confidence": 0.7216982444127401}, {"text": "statistical machine translation", "start_pos": 79, "end_pos": 110, "type": "TASK", "confidence": 0.7416577537854513}, {"text": "machine translation", "start_pos": 208, "end_pos": 227, "type": "TASK", "confidence": 0.7784730494022369}]}, {"text": "In this paper, we proposed syllable segmentation in Tibetan translation tasks for the first time and achieved better results than Tibetan word segmentation.", "labels": [], "entities": [{"text": "syllable segmentation", "start_pos": 27, "end_pos": 48, "type": "TASK", "confidence": 0.7261428534984589}, {"text": "Tibetan translation tasks", "start_pos": 52, "end_pos": 77, "type": "TASK", "confidence": 0.7261791129906973}, {"text": "Tibetan word segmentation", "start_pos": 130, "end_pos": 155, "type": "TASK", "confidence": 0.6494968136151632}]}, {"text": "Four kinds of neural machine translation methods, which are influential in recent years, are compared and analyzed in Tibetan-Chinese corpus.", "labels": [], "entities": []}, {"text": "Experimental results showed that the translation model based on the complete self-attention mechanism performed best in the translation task of Tibetan-Chinese corpus, and performance of the most of the neural machine translation methods surpassed performance of the traditional statistical machine translation methods.", "labels": [], "entities": [{"text": "translation task", "start_pos": 124, "end_pos": 140, "type": "TASK", "confidence": 0.898349791765213}]}], "introductionContent": [{"text": "Machine translation, studies on how to use computers to achieve the automatic translation between natural languages, is one of the important research directions in areas of artificial intelligence and natural language processing (.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8412951231002808}]}, {"text": "Natural language processing (including machine translation) is a discipline that crosses computer science and linguistics.", "labels": [], "entities": [{"text": "Natural language processing (including machine translation)", "start_pos": 0, "end_pos": 59, "type": "TASK", "confidence": 0.6848457418382168}]}, {"text": "Based on characteristics of this discipline, the system of machine translation can be divided into two categories, which are the rule-based methods and the corpus-based methods.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 59, "end_pos": 78, "type": "TASK", "confidence": 0.7247034013271332}]}, {"text": "Among them, corpus-based methods can be divided into statistics-based methods and example-based methods ().", "labels": [], "entities": []}, {"text": "In recent years, with the development of internet technology, machine translation has achieved fruitful results both in academia and industry.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 62, "end_pos": 81, "type": "TASK", "confidence": 0.8463893830776215}]}, {"text": "Since the advent of the neural network in the 1940s, it has experienced the different stages of rising, low tide, and rising.", "labels": [], "entities": []}, {"text": "Until 2006, Hinton et al. solved the historic problem of neural networks), and the related researches of deep learning and neural network returned to people's attention again.", "labels": [], "entities": []}, {"text": "Since then, with the deepening of theoretical research and improvement of computing speed of computers, neural networks have been gradually applied to various fields of artificial intelligence and have made major breakthroughs.", "labels": [], "entities": []}, {"text": "Researches about natural language processing have also made a rapid progress along with this tide.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 17, "end_pos": 44, "type": "TASK", "confidence": 0.6731459498405457}]}, {"text": "In 2012, With the Hinton research group participated in the ImageNet image recognition contest and won the championship, which opened the prelude of deep learning in the big bang in various fields of artificial intelligence.", "labels": [], "entities": [{"text": "Hinton research group", "start_pos": 18, "end_pos": 39, "type": "DATASET", "confidence": 0.9654572606086731}, {"text": "ImageNet image recognition contest", "start_pos": 60, "end_pos": 94, "type": "TASK", "confidence": 0.745310865342617}]}, {"text": "Neural machine translation (NMT) is also a machine translation method that is gradually emerging at this stage.", "labels": [], "entities": [{"text": "Neural machine translation (NMT)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7958917220433553}, {"text": "machine translation", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.7707518935203552}]}, {"text": "The main processes of neural machine translation are as follows: Firstly, it uses neural networks) to encode the source language into word embedding.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 22, "end_pos": 48, "type": "TASK", "confidence": 0.6865907609462738}]}, {"text": "Secondly, the word-embedding generates the target language by decoding . Among them, in the neural network training, the problem of long distance dependence can be solved well by the proper joining of long-short term memory (LSTM) networks and attention mechanisms.", "labels": [], "entities": []}, {"text": "Tibetan is a kind of pinyin character, and its syllables are composed of 34 vowel consonants, then Tibetan words are composed of syllables.", "labels": [], "entities": []}, {"text": "A single character in a Tibetan text is a unit, and it is separated by a syllable separator \"\u0f0b\" between words.", "labels": [], "entities": []}, {"text": "Based on the characteristics of Tibetan language, at present, the statistical machine translation model is mainly used in the research on Tibetan translation model, and the relevant theoretical research has basically stopped at the stage of word processing and other corpus preprocessing such as the phrase-based Tibetan-Chinese statistical machine translation system (; besides, related tibetan preprocessing research) and soon.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 66, "end_pos": 97, "type": "TASK", "confidence": 0.6303852101167043}, {"text": "Tibetan translation", "start_pos": 138, "end_pos": 157, "type": "TASK", "confidence": 0.6702148616313934}, {"text": "phrase-based Tibetan-Chinese statistical machine translation", "start_pos": 300, "end_pos": 360, "type": "TASK", "confidence": 0.5805044412612915}]}, {"text": "On the whole, compared with research on machine translation of other rich languages, the research on Tibetan-Chinese machine translation is obviously behind.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.7713774144649506}, {"text": "Tibetan-Chinese machine translation", "start_pos": 101, "end_pos": 136, "type": "TASK", "confidence": 0.6199119091033936}]}, {"text": "There are few researches on using neural network model in Tibetan corpus (.", "labels": [], "entities": [{"text": "Tibetan corpus", "start_pos": 58, "end_pos": 72, "type": "DATASET", "confidence": 0.7767773866653442}]}, {"text": "Tibetan texts are all word segmentation pre-processed in traditional Tibetan machine translations.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 22, "end_pos": 39, "type": "TASK", "confidence": 0.7681969404220581}]}, {"text": "In this article, the traditional method of Tibetan word segmentation is completely abandoned, and Tibetan texts are directly divided by syllables.", "labels": [], "entities": [{"text": "Tibetan word segmentation", "start_pos": 43, "end_pos": 68, "type": "TASK", "confidence": 0.6378047863642374}]}, {"text": "It gets a better performance than Tibetan word segmentation.", "labels": [], "entities": [{"text": "Tibetan word segmentation", "start_pos": 34, "end_pos": 59, "type": "TASK", "confidence": 0.5951488812764486}]}, {"text": "In this paper, four kinds of influential machine translation models of neural networks are applied to the task of Tibetan-Chinese machine translation, and the final translation results are analyzed in detail.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.7223935127258301}, {"text": "Tibetan-Chinese machine translation", "start_pos": 114, "end_pos": 149, "type": "TASK", "confidence": 0.6018576622009277}]}, {"text": "The experimental results show that the application of neural network machine translation model on Tibetan-Chinese machine translation has basically surpassed the performance of the traditional statistical machine translation model.", "labels": [], "entities": [{"text": "neural network machine translation", "start_pos": 54, "end_pos": 88, "type": "TASK", "confidence": 0.7403165251016617}, {"text": "Tibetan-Chinese machine translation", "start_pos": 98, "end_pos": 133, "type": "TASK", "confidence": 0.5945141613483429}, {"text": "statistical machine translation", "start_pos": 193, "end_pos": 224, "type": "TASK", "confidence": 0.7269082069396973}]}, {"text": "By using the method of syllable segmentation in Tibetan machine translation tasks, it has a better translation performance than the method of word segmentation.", "labels": [], "entities": [{"text": "syllable segmentation", "start_pos": 23, "end_pos": 44, "type": "TASK", "confidence": 0.7525595426559448}, {"text": "Tibetan machine translation", "start_pos": 48, "end_pos": 75, "type": "TASK", "confidence": 0.6017595728238424}, {"text": "word segmentation", "start_pos": 142, "end_pos": 159, "type": "TASK", "confidence": 0.7136153280735016}]}], "datasetContent": [{"text": "This paper uses the evaluation corpus of the 13th National machine translation symposium(CWMT 2017 in china, http://ee.dlut.edu.cn/CWMT2017/index.html).", "labels": [], "entities": [{"text": "machine translation symposium", "start_pos": 59, "end_pos": 88, "type": "TASK", "confidence": 0.7512310643990835}]}, {"text": "These corpora are processed into Tibetan-Chinese sentence pairs, which contains word segmentation, syllable segmentation and some alignment process.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 80, "end_pos": 97, "type": "TASK", "confidence": 0.6785368919372559}, {"text": "syllable segmentation", "start_pos": 99, "end_pos": 120, "type": "TASK", "confidence": 0.6797418892383575}]}, {"text": "These corpora are shown in following  In the experiment, in order to reflect the performance of neural machine translation, phrasebased statistical machine translation model Nitutrans) developed by natural language processing laboratory in northeastern university (in china) is used in the statistical machine translation model.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 96, "end_pos": 122, "type": "TASK", "confidence": 0.7559555570284525}, {"text": "phrasebased statistical machine translation", "start_pos": 124, "end_pos": 167, "type": "TASK", "confidence": 0.5073434263467789}, {"text": "statistical machine translation", "start_pos": 290, "end_pos": 321, "type": "TASK", "confidence": 0.632578064997991}]}, {"text": "In this paper, four models of neural machine translation are consistent in the basic parameter settings (the vocabulary size of sub-words is set to 32000 and the number of training iterations is 200000).", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 30, "end_pos": 56, "type": "TASK", "confidence": 0.704721212387085}]}, {"text": "Because each model has its own architecture, it is difficult to achieve consistent in terms of performance of parameters.", "labels": [], "entities": []}, {"text": "In addition, with the language characteristics of the Tibetan-Chinese bilingual corpus, in this paper, based on each model, hyperparameters are adjusted to achieve maximum of translation performance.", "labels": [], "entities": []}, {"text": "Bilingual evaluation understudy (BLEU) is used as evaluation index in this paper).", "labels": [], "entities": [{"text": "Bilingual evaluation understudy (BLEU)", "start_pos": 0, "end_pos": 38, "type": "METRIC", "confidence": 0.5240170409282049}]}], "tableCaptions": [{"text": " Table 2 Corpus Statistics in Experimental", "labels": [], "entities": []}, {"text": " Table 7 Different Neural Machine Translation Models in Tibetan -Chinese Corpus (Tibetan-Chinese)", "labels": [], "entities": [{"text": "Neural Machine Translation", "start_pos": 19, "end_pos": 45, "type": "TASK", "confidence": 0.6446511646111807}]}]}