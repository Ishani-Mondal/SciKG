{"title": [{"text": "Automatic Glossing in a Low-Resource Setting for Language Documentation", "labels": [], "entities": []}], "abstractContent": [{"text": "Morphological analysis of morphologically rich and low-resource languages is important to both descriptive linguistics and natural language processing.", "labels": [], "entities": [{"text": "Morphological analysis of morphologically rich and low-resource languages", "start_pos": 0, "end_pos": 73, "type": "TASK", "confidence": 0.8646631091833115}, {"text": "descriptive linguistics", "start_pos": 95, "end_pos": 118, "type": "TASK", "confidence": 0.8697637021541595}, {"text": "natural language processing", "start_pos": 123, "end_pos": 150, "type": "TASK", "confidence": 0.6523716747760773}]}, {"text": "Field efforts usually procure analyzed data in cooperation with native speakers who are capable of providing some level of linguistic information.", "labels": [], "entities": []}, {"text": "Manually annotating such data is very expensive and the traditional process is arguably too slow in the face of language endangerment and loss.", "labels": [], "entities": []}, {"text": "We report on a case study of learning to automatically gloss a Nakh-Daghestanian language, Lezgi, from a very small amount of seed data.", "labels": [], "entities": []}, {"text": "We compare a conditional random field based sequence labeler and a neural encoder-decoder model and show that a nearly 0.9 F 1-score on labeled accuracy of morphemes can be achieved with 3,000 words of transcribed oral text.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 144, "end_pos": 152, "type": "METRIC", "confidence": 0.7550718784332275}]}, {"text": "Errors are mostly limited to morphemes with high allomorphy.", "labels": [], "entities": []}, {"text": "These results are potentially useful for developing rapid annotation and fieldwork tools to support documentation of other morphologically rich, endangered languages.", "labels": [], "entities": []}], "introductionContent": [{"text": "Thousands of languages lack documented data necessary to describe them accurately.", "labels": [], "entities": []}, {"text": "In the early 1990s it was suggested that linguistics might be the first academic discipline to preside over the its own demise, since numbers indicated that as much as 90% of the world's languages would be extinct by the end of the 21st century.", "labels": [], "entities": []}, {"text": "Linguists quickly responded by developing methodology to record previously under-or undocumented languages.", "labels": [], "entities": []}, {"text": "Almost as quickly, they realized that unannotated data of a language that is no longer spoken is almost as inaccessible as an undocumented language.", "labels": [], "entities": []}, {"text": "Language documentation and the initial descriptive work that often accompanies it is time-and labor-intensive work, but it is foundational to the study of new languages.", "labels": [], "entities": [{"text": "Language documentation", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7031118273735046}]}, {"text": "It also benefits the community of speakers by supporting efforts to revitalize or maintain the language.", "labels": [], "entities": []}, {"text": "Although the estimated number of languages in imminent danger of extinction has been reduced, the task remains urgent.", "labels": [], "entities": []}, {"text": "Computational linguistics generally considers human annotation prohibitively expensive because it relies on linguistic expertise.", "labels": [], "entities": [{"text": "Computational linguistics", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8378847539424896}]}, {"text": "However, employing this expertise has long been accepted practice in documentary and descriptive linguistics.", "labels": [], "entities": [{"text": "descriptive linguistics", "start_pos": 85, "end_pos": 108, "type": "TASK", "confidence": 0.7510683834552765}]}, {"text": "Documentation data is not produced by a linguist alone; rather, it is created in close cooperation with native speakers who receive minimal training in general linguistics and software.", "labels": [], "entities": []}, {"text": "The documentation work includes transcription of oral recordings, translation, then ends with, as descriptive work begins with, interlinearization (i.e. POS-tagging, morpheme segmentation, and glossing).", "labels": [], "entities": [{"text": "translation", "start_pos": 66, "end_pos": 77, "type": "TASK", "confidence": 0.9724562764167786}, {"text": "morpheme segmentation", "start_pos": 166, "end_pos": 187, "type": "TASK", "confidence": 0.716668114066124}]}, {"text": "The first task alone may takes an average of 39 times longer than the original recording, according to a recent survey of field linguists.", "labels": [], "entities": []}, {"text": "No matter how many oral texts are recorded during afield project, time constraints often mean that only the annotations required to support a particular short-term goal are completed.", "labels": [], "entities": []}, {"text": "For example, the data used in the current paper was collected by a linguist for his MA thesis.", "labels": [], "entities": []}, {"text": "Since his topic was verbs, only the verbs were thoroughly annotated.", "labels": [], "entities": []}, {"text": "More funds had to be found to hire another native speaker who could simultaneously: Flowchart of language data production.", "labels": [], "entities": [{"text": "Flowchart of language data production", "start_pos": 84, "end_pos": 121, "type": "TASK", "confidence": 0.5820269405841827}]}, {"text": "Descriptive linguists (a) collaborate with native speakers of a language (b) to produce documentary data for all subfields of linguistics, language development efforts by the community of speakers, and the extension of NLP tools to low-resource languages.", "labels": [], "entities": []}, {"text": "A bottleneck of time-consuming annotation (c) keeps much of the data inaccessible to all but the community of speakers.", "labels": [], "entities": []}, {"text": "The models described in this paper (d) attempt to employ semi-automated interlinearization to increase the trickle of data by . learn and do basic linguistic analysis.", "labels": [], "entities": []}, {"text": "Such manual work is slow and inevitably produces inconsistent annotations.", "labels": [], "entities": []}, {"text": "It is noteworthy that many mistakes are not due to the difficulty of the task but because of its repetitive nature.", "labels": [], "entities": []}, {"text": "In case marking languages, for example, morphemes marking subjects will be found in practically every clause and those marking objects, dative, or genitive arguments maybe nearly as frequent.", "labels": [], "entities": [{"text": "case marking languages", "start_pos": 3, "end_pos": 25, "type": "TASK", "confidence": 0.7838861842950186}]}, {"text": "Only a small percentage of tokens contain unusual and interesting morphological forms.", "labels": [], "entities": []}, {"text": "Thus, a large chunk of this highly time-consuming work is as monotonous to the annotator as it is uninformative to language science-in short, we are faced with a bottleneck (.", "labels": [], "entities": []}, {"text": "After nearly 30 years of emphasis on increasing accessible documentation data, very few computational tools have been applied to this bottleneck.", "labels": [], "entities": []}, {"text": "The most popular software packages designed for linguistic analysis, and, provide almost no automated aid for common, repetitive tasks, although FLEx does copy the annotator's work onto subsequent tokens if they are identical to previously analyzed tokens.", "labels": [], "entities": [{"text": "linguistic analysis", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.7349613606929779}, {"text": "FLEx", "start_pos": 145, "end_pos": 149, "type": "DATASET", "confidence": 0.8051444888114929}]}, {"text": "To address this problem, we apply machine learning models to two common tasks applied to documentation data: morpheme segmentation and glossing.", "labels": [], "entities": [{"text": "morpheme segmentation", "start_pos": 109, "end_pos": 130, "type": "TASK", "confidence": 0.6931523680686951}]}, {"text": "The models use about 3,000 words of manuallyannotated data that train sequence models to predict morpheme labels (and glosses).", "labels": [], "entities": []}, {"text": "The goal is to achieve accurate results on more data in less time.", "labels": [], "entities": [{"text": "accurate", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9570416808128357}]}, {"text": "A case study on explores three issues as a first step toward integrating the models into linguistic analysis software.", "labels": [], "entities": []}, {"text": "First, can the linguist and native speaker expect machine learning techniques to successfully widen the data bottleneck after they have manually annotated a few transcribed texts?", "labels": [], "entities": []}, {"text": "Second, could a sequence labeler achieve reasonable accuracy using features that are generalizable to most languages?", "labels": [], "entities": [{"text": "sequence labeler", "start_pos": 16, "end_pos": 32, "type": "TASK", "confidence": 0.7153345942497253}, {"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9962838292121887}]}, {"text": "If a feature-based tool could be applied to several languages without tweaking features in a language-specific fashion, it would be accessible even to native speakers without linguistic skills who wish to create structured language data.", "labels": [], "entities": []}, {"text": "At the same time, if high accuracy is achieved an agglutinative language like Lezgi, then minimal feature-tweaking could make the model equally successful on more fusional languages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9982849955558777}]}, {"text": "Lastly, what might the errors in the case study indicate for typologically different languages?", "labels": [], "entities": []}, {"text": "Section 2 reviews related work.", "labels": [], "entities": []}, {"text": "Section 3 introduces the case study and Section 4 describes the models used.", "labels": [], "entities": []}, {"text": "The results are compared and analyzed in Section 5.", "labels": [], "entities": []}, {"text": "Implications and future work are discussed in Section 6, before the conclusion in Section 7.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Labeled position results (F 1 -score) compared across CRF-only, CRF+SVM pipeline, and  seq2seq models. The first two are averages across multiple runs on random data splits.", "labels": [], "entities": [{"text": "F 1 -score)", "start_pos": 36, "end_pos": 47, "type": "METRIC", "confidence": 0.9756945967674255}]}, {"text": " Table 3: CRF-only model labeled position results from one run over a randomized test set with 80/20  split. Averages are macroaverages.", "labels": [], "entities": []}]}