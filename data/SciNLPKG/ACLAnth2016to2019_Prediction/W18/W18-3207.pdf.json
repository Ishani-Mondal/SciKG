{"title": [{"text": "Code-Switching Language Modeling using Syntax-Aware Multi-Task Learning", "labels": [], "entities": [{"text": "Code-Switching Language Modeling", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.5882880290349325}]}], "abstractContent": [{"text": "Lack of text data has been the major issue on code-switching language model-ing.", "labels": [], "entities": []}, {"text": "In this paper, we introduce multi-task learning based language model which shares syntax representation of languages to leverage linguistic information and tackle the low resource data issue.", "labels": [], "entities": []}, {"text": "Our model jointly learns both language mod-eling and Part-of-Speech tagging on code-switched utterances.", "labels": [], "entities": [{"text": "Part-of-Speech tagging", "start_pos": 53, "end_pos": 75, "type": "TASK", "confidence": 0.7509914338588715}]}, {"text": "In this way, the model is able to identify the location of code-switching points and improves the prediction of next word.", "labels": [], "entities": []}, {"text": "Our approach outperforms standard LSTM based language model, with an improvement of 9.7% and 7.4% in perplexity on SEAME Phase I and Phase II dataset respectively.", "labels": [], "entities": [{"text": "SEAME Phase I and Phase II dataset", "start_pos": 115, "end_pos": 149, "type": "DATASET", "confidence": 0.7528453895023891}]}], "introductionContent": [{"text": "Code-switching has received a lot of attention from speech and computational linguistic communities especially on how to automatically recognize text from speech and understand the structure within it.", "labels": [], "entities": []}, {"text": "This phenomenon is very common in bilingual and multilingual communities.", "labels": [], "entities": []}, {"text": "For decades, linguists studied this phenomenon and found that speakers switch at certain points, not randomly and obeys several constraints which point to the code-switched position in an utterance.", "labels": [], "entities": []}, {"text": "These hypotheses have been empirically proven by observing that bilinguals tend to code-switch intra-sententially at certain (morpho)-syntactic boundaries.", "labels": [], "entities": []}, {"text": "defined the well-known theory that constraints the code-switch between a functional head and its complement is given the strong relationship between the two constituents, which corresponds to a hierarchical structure in terms of Part-of-Speech (POS) tags.", "labels": [], "entities": []}, {"text": "introduced Matrix-Language Model Framework for an intra-sentential case where the primary language is called Matrix Language and the second one called Embedded Language).", "labels": [], "entities": []}, {"text": "A language island was then introduced which is a constituent composed entirely of the language morphemes.", "labels": [], "entities": []}, {"text": "From the Matrix-Language Frame Model, both matrix language (ML) island and embedded language (EL) islands are well-formed in their grammars and the EL islands are constrained under ML grammar.) studied determiner-noun switches in Spanish-English bilinguals . Code-switching can be classified into two categories: intra-sentential and inter-sentential switches.", "labels": [], "entities": [{"text": "determiner-noun switches", "start_pos": 202, "end_pos": 226, "type": "TASK", "confidence": 0.7071528732776642}]}, {"text": "Intra-sentential switch defines a shift from one language to another language within an utterance.", "labels": [], "entities": [{"text": "Intra-sentential switch", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6836247146129608}]}, {"text": "Inter-sentential switch refers to the change between two languages in a single discourse, where the switching occurs after a sentence in the first language has been completed and the next sentence starts with anew language.", "labels": [], "entities": [{"text": "Inter-sentential switch", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7294673472642899}]}, {"text": "The example of the intra-sentential switch is shown in (1), and the inter-sentential switch is shown in (2).", "labels": [], "entities": []}, {"text": "(1) \u6211 \u8981 \u53bb check.", "labels": [], "entities": [{"text": "\u53bb check", "start_pos": 8, "end_pos": 15, "type": "METRIC", "confidence": 0.7354336977005005}]}, {"text": "(I want to go) check.", "labels": [], "entities": []}, {"text": "(2) \u6211 \u4e0d \u61c2 \u8981 \u600e\u4e48 \u8bb2 \u4e00 \u4e2a \u5c0f\u65f6 seriously I didn't have so much things to say (I don't understand how to speak for an hour) seriously I didn't have so much things to say Language modeling using only word lexicons is not adequate to learn the complexity of codeswitching patterns, especially in a low resource setting.", "labels": [], "entities": [{"text": "Language modeling", "start_pos": 162, "end_pos": 179, "type": "TASK", "confidence": 0.7565706968307495}]}, {"text": "Learning at the same time syntactic features such as POS tag and language identifier allows to have a shared grammatical information that constraint the next word prediction.", "labels": [], "entities": []}, {"text": "Due to this reason, we propose a multi-task learning framework for code-switching language modeling task which is able to leverage syntactic features such as language and POS tag.", "labels": [], "entities": []}, {"text": "The main contribution of this paper is twofold.", "labels": [], "entities": []}, {"text": "First, multi-task learning model is proposed to jointly learn language modeling task and POS sequence tagging task on code-switched utterances.", "labels": [], "entities": [{"text": "POS sequence tagging task", "start_pos": 89, "end_pos": 114, "type": "TASK", "confidence": 0.6756317988038063}]}, {"text": "Second, we incorporate language information into POS tags to create bilingual tags -it distinguishes tags between Chinese and English.", "labels": [], "entities": []}, {"text": "The POS tag features are shared towards the language model and enrich the features to better learn whereto switch.", "labels": [], "entities": []}, {"text": "From our experiments result, we found that our method improves the perplexity on SEAME Phase I and Phase II dataset (Nanyang Technological University, 2015).", "labels": [], "entities": [{"text": "SEAME Phase I and Phase II dataset", "start_pos": 81, "end_pos": 115, "type": "DATASET", "confidence": 0.6076543884617942}, {"text": "Nanyang Technological University, 2015)", "start_pos": 117, "end_pos": 156, "type": "DATASET", "confidence": 0.9586048622926077}]}], "datasetContent": [{"text": "In this section, we present the experimental setting for this task Corpus: SEAME (South East Asia MandarinEnglish), a conversational Mandarin-English code-switching speech corpus consists of spontaneously spoken interviews and conversations (Nanyang Technological University, 2015).", "labels": [], "entities": [{"text": "SEAME", "start_pos": 75, "end_pos": 80, "type": "METRIC", "confidence": 0.9265598654747009}, {"text": "Nanyang Technological University, 2015)", "start_pos": 242, "end_pos": 281, "type": "DATASET", "confidence": 0.9671611189842224}]}, {"text": "Our dataset (LDC2015S04) is the most updated version of the Linguistic Data Consortium (LDC) database.", "labels": [], "entities": [{"text": "Linguistic Data Consortium (LDC) database", "start_pos": 60, "end_pos": 101, "type": "DATASET", "confidence": 0.8069482403142112}]}, {"text": "However, the statistics are not identical to.", "labels": [], "entities": []}, {"text": "The corpus consists of two phases.", "labels": [], "entities": []}, {"text": "In Phase I, only selected audio segments were transcribed.", "labels": [], "entities": []}, {"text": "In Phase II, most of the audio segments were transcribed.", "labels": [], "entities": []}, {"text": "According to the authors, it was not possible to restore the original dataset.", "labels": [], "entities": []}, {"text": "The authors only used Phase I corpus.", "labels": [], "entities": []}, {"text": "Few speaker ids are not in the speaker list provided by the authors.", "labels": [], "entities": []}, {"text": "Therefore as a workaround, we added these ids to the train set.", "labels": [], "entities": []}, {"text": "As our future reference, the recording lists are included in the supplementary material.", "labels": [], "entities": []}, {"text": "Preprocessing: First, we tokenized English and Chinese word using Stanford NLP toolkit ().", "labels": [], "entities": [{"text": "Stanford NLP toolkit", "start_pos": 66, "end_pos": 86, "type": "DATASET", "confidence": 0.936163584391276}]}, {"text": "Second, all hesitations and punctuations were removed except apostrophe, for examples: \"let's\" and \"it's\". and show the statistics of SEAME Phase I and II corpora.", "labels": [], "entities": [{"text": "apostrophe", "start_pos": 61, "end_pos": 71, "type": "METRIC", "confidence": 0.9606582522392273}, {"text": "SEAME Phase I", "start_pos": 134, "end_pos": 147, "type": "TASK", "confidence": 0.6409028172492981}]}, {"text": "shows the most common trigger POS tag for Phase II corpus.", "labels": [], "entities": []}, {"text": "Training: The baseline model was trained using RNNLM . Then, we trained our LSTM models with different hidden sizes.", "labels": [], "entities": [{"text": "RNNLM", "start_pos": 47, "end_pos": 52, "type": "DATASET", "confidence": 0.9173926115036011}]}, {"text": "All LSTMs have 2 layers and unrolled for 35 steps.", "labels": [], "entities": []}, {"text": "The embedding size is equal to the LSTM hidden size.", "labels": [], "entities": []}, {"text": "A dropout regularization () was applied to the word embedding vector and POS tag embedding vector, and to the recurrent output () with values between [0.2, 0.4].", "labels": [], "entities": []}, {"text": "We used a batch size of 20 in the training.", "labels": [], "entities": []}, {"text": "EOS tag was used to separate every sentence.", "labels": [], "entities": [{"text": "EOS tag", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.6464441418647766}]}, {"text": "We chose Stochastic Gradient Descent and started with a learning rate of 20 and if there was no improvement during the evaluation, we reduced the learning rate by a factor of 0.75.", "labels": [], "entities": [{"text": "Stochastic Gradient Descent", "start_pos": 9, "end_pos": 36, "type": "TASK", "confidence": 0.5632985333601633}, {"text": "learning rate", "start_pos": 56, "end_pos": 69, "type": "METRIC", "confidence": 0.9727847874164581}, {"text": "learning rate", "start_pos": 146, "end_pos": 159, "type": "METRIC", "confidence": 0.9338074624538422}]}, {"text": "The gradient was clipped to a maximum of 0.25.", "labels": [], "entities": []}, {"text": "For the multi-task learning, we used different loss weights hyperparameters pin the range of.", "labels": [], "entities": []}, {"text": "We tuned our model with the development set and we evaluated our best model using the test set, taking perplexity as the final evaluation metric.", "labels": [], "entities": []}, {"text": "Where the latter was calculated by taking the exponential of the error in the negative log-form. and show the results of multitask learning with different values of the hyperparameter p.", "labels": [], "entities": []}, {"text": "We observe that the multi-task model with p = 0.25 achieved the best performance.", "labels": [], "entities": []}, {"text": "We compare our multi-task learning model against RNNLM and LSTM baselines.", "labels": [], "entities": []}, {"text": "The baselines correspond to recurrent neural networks that are trained with word lexicons.", "labels": [], "entities": []}, {"text": "present the overall results from different models.", "labels": [], "entities": []}, {"text": "The multi-task model performs better than LSTM baseline by 9.7% perplexity in Phase I and 7.4% perplexity in Phase II.", "labels": [], "entities": []}, {"text": "The performance of our model in Phase II is also better than the RNNLM (8.9%) and far better than the one presented in      conduct two analysis by visualizing our prediction examples in a) Measure the improvement of the target word's log probability by multi-task model compared to standard LSTM model.", "labels": [], "entities": [{"text": "RNNLM", "start_pos": 65, "end_pos": 70, "type": "DATASET", "confidence": 0.5229692459106445}]}, {"text": "This is computed by calculating the log probability difference between two models.", "labels": [], "entities": []}, {"text": "According to, inmost of the cases, the multi-task model improves the prediction of the monolingual segments and particularly in code-switching points such as \"under\", \"security\", \"generation\", \"then\", \"graduate\", \"\u4ed6\", and \"\u7684\".", "labels": [], "entities": []}, {"text": "It also shows that the multi-task model is more precise in learning whereto switch language.", "labels": [], "entities": []}, {"text": "On the other hand, shows the relative frequency of the trigger POS tag.", "labels": [], "entities": []}, {"text": "The word \"then\" belong to RB EN , which is one of the most common trigger words in the list.", "labels": [], "entities": [{"text": "RB EN", "start_pos": 26, "end_pos": 31, "type": "METRIC", "confidence": 0.7084477543830872}]}, {"text": "Furthermore, the target word prediction is significantly improved inmost of the trigger words.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Data Statistics in SEAME Phase I  Train set Dev set Test set  # Speakers  139  8  8  # Utterances  45,916  1,938  1,228  # Tokens  762K  31K  17K  Avg. segments  length  3.67  3.68  3.18", "labels": [], "entities": [{"text": "SEAME Phase I  Train set Dev set Test set", "start_pos": 29, "end_pos": 70, "type": "DATASET", "confidence": 0.7886423733499315}]}, {"text": " Table 2: Data Statistics in SEAME Phase II  Train set Dev set Test set  # Speakers  138  8  8  # Utterances  78,815  4,764  3,933  # Tokens  1.2M  65K  60K  Avg. segment  length  4.21  3.59  3.99", "labels": [], "entities": [{"text": "SEAME Phase II  Train set Dev set Test set", "start_pos": 29, "end_pos": 71, "type": "DATASET", "confidence": 0.7888656059900919}]}, {"text": " Table 3: Code-Switching Trigger Words in  SEAME Phase II  POS Tag  Freq  POS Tag Freq  VV ZH  107,133 NN EN  31,031  AD ZH  97,681 RB EN  12,498  PN ZH  92,117 NNP EN  11,734  NN ZH  45,088 JJ EN  5,040  VA ZH  27,442 IN EN  4,801  CD ZH  20,158 VB EN  4,703", "labels": [], "entities": [{"text": "SEAME Phase II  POS Tag  Freq  POS Tag Freq  VV ZH  107,133 NN EN  31,031  AD ZH  97,681 RB EN  12,498  PN ZH  92,117 NNP EN  11,734  NN ZH  45,088 JJ EN  5,040  VA ZH  27,442 IN EN  4,801  CD ZH  20,158 VB EN  4,703", "start_pos": 43, "end_pos": 259, "type": "DATASET", "confidence": 0.825144440597958}]}, {"text": " Table 4: Multi-task results with different weighted  loss hyper-parameter in Phase I  Hidden  size  p  PPL  Dev", "labels": [], "entities": []}, {"text": " Table 5: Multi-task results with different weighted  loss hyper-parameter in Phase II  Hidden  size  p  PPL  Dev", "labels": [], "entities": []}, {"text": " Table 6: Results in Phase I", "labels": [], "entities": [{"text": "Phase I", "start_pos": 21, "end_pos": 28, "type": "TASK", "confidence": 0.6933066248893738}]}, {"text": " Table 7: Results in Phase II", "labels": [], "entities": []}]}