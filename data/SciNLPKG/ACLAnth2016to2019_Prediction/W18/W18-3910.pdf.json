{"title": [{"text": "Varying image description tasks: spoken versus written descriptions", "labels": [], "entities": [{"text": "Varying image description", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.917187511920929}]}], "abstractContent": [{"text": "Automatic image description systems are commonly trained and evaluated on written image descriptions.", "labels": [], "entities": [{"text": "image description", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.6675108075141907}]}, {"text": "At the same time, these systems are often used to provide spoken descriptions (e.g. for visually impaired users) through apps like TapTapSee or Seeing AI.", "labels": [], "entities": []}, {"text": "This is not a problem, as long as spoken and written descriptions are very similar.", "labels": [], "entities": []}, {"text": "However, linguistic research suggests that spoken language often differs from written language.", "labels": [], "entities": []}, {"text": "These differences are not regular, and vary from context to context.", "labels": [], "entities": []}, {"text": "Therefore, this paper investigates whether there are differences between written and spoken image descriptions, even if they are elicited through similar tasks.", "labels": [], "entities": []}, {"text": "We compare descriptions produced in two languages (English and Dutch), and in both languages observe substantial differences between spoken and written descriptions.", "labels": [], "entities": []}, {"text": "Future research should see if users prefer the spoken over the written style and, if so, aim to emulate spoken descriptions.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic image description systems ( are commonly trained and evaluated on datasets of described images, such as Flickr30K and MS COCO ().", "labels": [], "entities": [{"text": "image description", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.6928668320178986}, {"text": "Flickr30K", "start_pos": 114, "end_pos": 123, "type": "DATASET", "confidence": 0.9465272426605225}, {"text": "MS COCO", "start_pos": 128, "end_pos": 135, "type": "DATASET", "confidence": 0.8248237371444702}]}, {"text": "These datasets have been collected by asking workers on Mechanical Turk to write English descriptions that capture the contents of the images that are presented to them.", "labels": [], "entities": [{"text": "Mechanical Turk", "start_pos": 56, "end_pos": 71, "type": "DATASET", "confidence": 0.8369365930557251}]}, {"text": "But how much are these descriptions influenced by the modality of the task?", "labels": [], "entities": []}, {"text": "This paper explores the differences between spoken and written image descriptions.", "labels": [], "entities": []}, {"text": "While many papers at VarDial aim to distinguish similar dialects using machine learning (e.g. in shared tasks such as those in, we aim to identify the features distinguishing two similar varieties (spoken and written language) of the same language (either English or Dutch) in a particular domain (image descriptions).", "labels": [], "entities": [{"text": "VarDial", "start_pos": 21, "end_pos": 28, "type": "DATASET", "confidence": 0.85553377866745}]}, {"text": "One of the motivations behind automatic image description research is to support blind or visually impaired people (e.g., and indeed apps are starting to appear which describe visual content for blind users (e.g. TapTapSee or Microsoft's Seeing AI 1 ).", "labels": [], "entities": [{"text": "automatic image description", "start_pos": 30, "end_pos": 57, "type": "TASK", "confidence": 0.6407597263654073}]}, {"text": "These apps are commonly used together with screen readers, which convert on-screen text to speech.", "labels": [], "entities": []}, {"text": "Given this presentation through speech, it is worth asking: should we not also collect spoken rather than written training data?", "labels": [], "entities": []}, {"text": "That might give us more natural-sounding descriptions.", "labels": [], "entities": []}, {"text": "But a big downside of collecting spoken training data is that it also requires a costly transcription procedure (unless we go for an end-to-end approach, see).", "labels": [], "entities": []}, {"text": "An alternative is to try to understand what the differences are between written and spoken image descriptions.", "labels": [], "entities": []}, {"text": "Once we know those differences, and we know what kind of descriptions users prefer, we maybe able to direct image description systems to produce more human-like descriptions, similar to the way we can modify the style of the descriptions, for example with positive/negative sentiment (, or humorous descriptions (.", "labels": [], "entities": []}, {"text": "This paper presents an exploratory study of the differences between spoken and written image descriptions, for two languages: English and Dutch.", "labels": [], "entities": []}, {"text": "We provide an overview of the variables that have been found to differ between spoken and written language, and see whether these differences also hold between English spoken and written image descriptions.", "labels": [], "entities": []}, {"text": "Following this, we repeat the same experiment for Dutch.", "labels": [], "entities": []}, {"text": "Our main findings are that spoken descriptions (1) tend to be longer than written descriptions, (2) contain more adverbs than written descriptions, (3) contain more pseudo-quantifiers and allness terms, and (4) tend to reflect the certainty of the speaker's beliefs more-so than written descriptions.", "labels": [], "entities": []}, {"text": "Our work paves the way fora future controlled replication study, and follow-up studies to assess what kind of descriptions users prefer.", "labels": [], "entities": []}, {"text": "All of our code and data is available online.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Top-10 most frequent nouns for all three datasets.  Flickr30K and MS COCO are fairly similar (they have a  larger overlap), but Places differs from the other two.", "labels": [], "entities": [{"text": "Flickr30K", "start_pos": 62, "end_pos": 71, "type": "DATASET", "confidence": 0.9251098036766052}, {"text": "MS COCO", "start_pos": 76, "end_pos": 83, "type": "DATASET", "confidence": 0.8481042385101318}]}, {"text": " Table 4: Results for our analysis of the Dutch spoken and written descriptions.", "labels": [], "entities": []}]}