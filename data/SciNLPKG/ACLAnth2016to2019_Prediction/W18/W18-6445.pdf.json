{"title": [{"text": "Ensemble of Translators with Automatic Selection of the Best Translation -the submission of FOKUS to the WMT 18 biomedical translation task", "labels": [], "entities": [{"text": "FOKUS", "start_pos": 92, "end_pos": 97, "type": "DATASET", "confidence": 0.8141947984695435}, {"text": "WMT 18 biomedical translation", "start_pos": 105, "end_pos": 134, "type": "TASK", "confidence": 0.7408281788229942}]}], "abstractContent": [{"text": "This paper describes the system of Fraunhofer FOKUS for the WMT 2018 biomedical translation task.", "labels": [], "entities": [{"text": "Fraunhofer", "start_pos": 35, "end_pos": 45, "type": "DATASET", "confidence": 0.7867217659950256}, {"text": "FOKUS", "start_pos": 46, "end_pos": 51, "type": "METRIC", "confidence": 0.5638043880462646}, {"text": "WMT 2018 biomedical translation task", "start_pos": 60, "end_pos": 96, "type": "TASK", "confidence": 0.8651455283164978}]}, {"text": "Our approach, described here, was to automatically select the most promising translation from a set of candidates produced with NMT (Transformer) models.", "labels": [], "entities": []}, {"text": "We selected the highest fidelity translation of each sentence by using a dictionary, stemming and a set of heuristics.", "labels": [], "entities": []}, {"text": "Our method is simple, can use any machine translators, and requires no further training in addition to that already employed to build the NMT models.", "labels": [], "entities": []}, {"text": "The down-side is that the score did not increase over the best in ensemble, but was quite close to it (dif-ference about 0.5 BLEU).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 125, "end_pos": 129, "type": "METRIC", "confidence": 0.9987251162528992}]}], "introductionContent": [{"text": "As previously noted in (, the neural machine translation models tend to provide good fluency but sometimes at the expense of the fidelity -they may struggle to cope with rare words, and can exhibit poor coverage/fidelity by ignoring altogether parts of the source.", "labels": [], "entities": []}, {"text": "By training even the same networks on different data one obtains models that have different strengths and weaknesses, sometimes one model provides the better translation, sometimes another one, even if on average they are of rather equal performance.", "labels": [], "entities": []}, {"text": "Our approach, described here, was to automatically select the best translation from a set of candidates produced by an ensemble of neural translators.", "labels": [], "entities": []}, {"text": "As the fluency was generally good, as is typically the case with NMT, our heuristic scoring of the translation quality focused on the bidirectional coverage, estimated by making use of a dictionary aided by a set of heuristic rules for the words not found in the dictionary.", "labels": [], "entities": []}, {"text": "We aimed to Combining translators is not new, the most interesting result known to us is (, where the authors report improvements of over 5 BLEU points in Chinese-to-English translation by combining the outputs of SMT and NMT systems using a neural network.", "labels": [], "entities": [{"text": "Combining translators", "start_pos": 12, "end_pos": 33, "type": "TASK", "confidence": 0.9466373920440674}, {"text": "BLEU", "start_pos": 140, "end_pos": 144, "type": "METRIC", "confidence": 0.9987084865570068}]}, {"text": "Our method is much simpler, has the additional advantage of using the NMT models as blackboxes, and requires no further training in addition to that already employed to build the NMT models.", "labels": [], "entities": []}, {"text": "The downside is that the BLEU score did not increase over the best in the ensemble (was within 0.5 BLEU of it) on anon directly comparable task, the biomedical field English-to-Romanian translation task of the WMT 2018 workshop.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.9800207614898682}, {"text": "BLEU", "start_pos": 99, "end_pos": 103, "type": "METRIC", "confidence": 0.9981365203857422}, {"text": "biomedical field English-to-Romanian translation task", "start_pos": 149, "end_pos": 202, "type": "TASK", "confidence": 0.6312002062797546}, {"text": "WMT 2018 workshop", "start_pos": 210, "end_pos": 227, "type": "DATASET", "confidence": 0.7447396318117777}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Diacritics usage in the datasets used here - number of lines containing a certain letter", "labels": [], "entities": []}, {"text": " Table 3: Transformer models trained. Models 1-3 used an external Byte Pair Encoding, whereas models 4-6 used  the subwords in the tensor2tensor framework to achieve the capability of translating previously unseen words.", "labels": [], "entities": [{"text": "translating previously unseen words", "start_pos": 184, "end_pos": 219, "type": "TASK", "confidence": 0.8219310939311981}]}, {"text": " Table 4: BLEU scores evaluated using t2t-bleu from  tensor2tensor and multi-bleu-detok from Moses", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9986230134963989}, {"text": "tensor2tensor", "start_pos": 53, "end_pos": 66, "type": "DATASET", "confidence": 0.8727490305900574}]}]}