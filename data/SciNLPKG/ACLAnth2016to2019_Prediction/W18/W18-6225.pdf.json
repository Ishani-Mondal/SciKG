{"title": [{"text": "HUMIR at IEST-2018: Lexicon-Sensitive and Left-Right Context-Sensitive BiLSTM for Implicit Emotion Recognition", "labels": [], "entities": [{"text": "IEST-2018", "start_pos": 9, "end_pos": 18, "type": "DATASET", "confidence": 0.6478250622749329}, {"text": "Implicit Emotion Recognition", "start_pos": 82, "end_pos": 110, "type": "TASK", "confidence": 0.6434651215871176}]}], "abstractContent": [{"text": "This paper describes the approaches used in HUMIR system for the WASSA-2018 shared task on the implicit emotion recognition.", "labels": [], "entities": [{"text": "WASSA-2018 shared task", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.6557809114456177}, {"text": "implicit emotion recognition", "start_pos": 95, "end_pos": 123, "type": "TASK", "confidence": 0.6085192064444224}]}, {"text": "The objective of this task is to predict the emotion expressed by the target word that has been excluded from the given tweet.", "labels": [], "entities": []}, {"text": "We suppose this task as a word sense disambiguation in which the target word is considered as a synthetic word that can express 6 emotions depending on the context.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 26, "end_pos": 51, "type": "TASK", "confidence": 0.6836930414040884}]}, {"text": "To predict the correct emotion , we propose a deep neural network model that uses two BiLSTM networks to represent the contexts in the left and right sides of the target word.", "labels": [], "entities": []}, {"text": "The BiLSTM outputs achieved from the left and right contexts are considered as context-sensitive features.", "labels": [], "entities": []}, {"text": "These features are used in a feed-forward neural network to predict the target word emotion.", "labels": [], "entities": []}, {"text": "Besides this approach, we also combine the BiL-STM model with lexicon-based and emotion-based features.", "labels": [], "entities": []}, {"text": "Finally, we employ all models in the final system using Bagging ensemble method.", "labels": [], "entities": []}, {"text": "We achieved macro F-measure value of 68.8 on the official test set and ranked sixth out of 30 participants.", "labels": [], "entities": [{"text": "F-measure value", "start_pos": 18, "end_pos": 33, "type": "METRIC", "confidence": 0.9526157677173615}]}], "introductionContent": [{"text": "Textual emotion recognition has received increasing attention in the natural language processing and computational linguistics in the recent decade.", "labels": [], "entities": [{"text": "Textual emotion recognition", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8808853626251221}, {"text": "natural language processing", "start_pos": 69, "end_pos": 96, "type": "TASK", "confidence": 0.6549170911312103}]}, {"text": "It aims to identify the emotion expressed by the given text based on two emotion models: categorical model and dimensional model.", "labels": [], "entities": []}, {"text": "While the categorical one uses discrete emotional categories such as Ekman's six basic emotions, the dimensional one defines emotions in a k-dimensional space; each dimension represents an attribute of the emotion such as valence, arousal and dominance.", "labels": [], "entities": []}, {"text": "However, the objective of the Implicit Emotion Shared Task (IEST) is to predict the emotion expressed by the target word excluded from the given tweet instead of the emotion expressed by the tweet (.", "labels": [], "entities": [{"text": "Implicit Emotion Shared Task (IEST)", "start_pos": 30, "end_pos": 65, "type": "TASK", "confidence": 0.7069885304995945}]}, {"text": "This task is organized based on the categorical model over 6 emotion categories as anger, disgust, fear, joy, sadness, and surprise.", "labels": [], "entities": []}, {"text": "Many approaches have been proposed for textual emotion recognition task.", "labels": [], "entities": [{"text": "textual emotion recognition task", "start_pos": 39, "end_pos": 71, "type": "TASK", "confidence": 0.8291643261909485}]}, {"text": "In general, these approaches can be grouped into 3 main categories: rule-based approaches, machine learning approaches and deep learning approaches.", "labels": [], "entities": []}, {"text": "Rule based approaches exploit linguistic lexical resources like WordNet-Affect () as well as unsupervised techniques such as Latent Semantic Analysis (LSA) in rule-based classifiers ().", "labels": [], "entities": []}, {"text": "The second group of the approaches employs machine learning algorithms -such as support vector machines, naive Bayes, random forest, logistic regression, etc-to classify a text into emotion categories (.", "labels": [], "entities": []}, {"text": "This group of approaches needs an extensive feature engineering as well as domain knowledge.", "labels": [], "entities": []}, {"text": "Furthermore, in this group, many of emotion lexicons which are generated manually or automatically play an important role in extracting emotion-specific features.", "labels": [], "entities": []}, {"text": "For instance, ( proposes an SVM classifier based on a variety of feature sets extracted from manually and automatically generated sentiment lexicons and ( exploits several lexicon-based features and employs them in the random forest classifier.", "labels": [], "entities": []}, {"text": "Unlike the previous approach, deep learning methods do not require any extensive feature engineering and can automatically extract features from raw text.", "labels": [], "entities": []}, {"text": "Long Short-Term Memory (LSTM) and Convolutional Neural Network (CNN) are the basis of many approaches in deep learning for emotion recognition).", "labels": [], "entities": [{"text": "emotion recognition", "start_pos": 123, "end_pos": 142, "type": "TASK", "confidence": 0.7309233844280243}]}, {"text": "The key objective of the both LSTM and CNN methods is to handle the semantic compositionality and to model the compositional changes on the text semantic according to its syntactic and semantic structure.", "labels": [], "entities": []}, {"text": "However, some methods train CNN and LSTM models jointly ( or use a CNN followed by a LSTM (.", "labels": [], "entities": []}, {"text": "In this paper, we suppose the target word as a synthetic ambiguous word that can express 6 emotions depending on the context.", "labels": [], "entities": []}, {"text": "To predict the correct emotion, we propose 7 deep neural network models that use three context-sensitive, lexiconbased and emotion-weight features.", "labels": [], "entities": []}, {"text": "The influence of these features is investigated over the proposed deep neural network models where they are employed to identify the context-dependent emotion of the target word.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the proposed models on the shared task official test set.", "labels": [], "entities": [{"text": "shared task official test set", "start_pos": 39, "end_pos": 68, "type": "DATASET", "confidence": 0.6984161794185638}]}, {"text": "shows the results according to the shared task evaluation measuresmicro and macro averaged F-measure-over all 6 emotion classes.", "labels": [], "entities": [{"text": "F-measure-over", "start_pos": 91, "end_pos": 105, "type": "METRIC", "confidence": 0.850873589515686}]}, {"text": "According to the results, the proposed Left-Right context-sensitive BiLSTM approach (i.e. LR-BiLSTM-3 and LR-BiLSTM-4) achieves the best official score of 67.8 among other individual models.", "labels": [], "entities": []}, {"text": "The macro F1-score increases to 68.6 when using all models in our ensemble system.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.86687833070755}]}, {"text": "According to the macro-F1 score achieved from BiLSTM and Lexicon-BiLSTM models, we can observe that two sets of lexicon-based and emotion-weight features improve the performance of BiLSTM model.", "labels": [], "entities": []}, {"text": "However, this growth is not seen in all classes.", "labels": [], "entities": []}, {"text": "For example, in two joy and sad classes, BiLSTM model performs better than Lexicon-BiLSTM.", "labels": [], "entities": [{"text": "BiLSTM", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.7962769269943237}]}, {"text": "In addition, the macro and micro averaged F-measure values obtained from the Lexicon-MLP (see) indicate that the lexicon-based and emotion-weight features are effective on less than 50% of test instances.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9336570501327515}]}, {"text": "This can raise two facts about the test set (1) a small number of affective clue words are used in the tweets (2) the syntactic structure of the context changes the emotions expressed by the affective clue words in the tweets.", "labels": [], "entities": []}, {"text": "This issue will be further discussed in Section 4.1.", "labels": [], "entities": []}, {"text": "Another important finding is that all models give a weak performance on the anger and surprise emotions.", "labels": [], "entities": []}, {"text": "The confusion matrix shown in indicates that our final system predicts tweets as anger instead of surprise in 402 cases and vice versa in 519 cases.", "labels": [], "entities": []}, {"text": "These are the highest False Negative (FN) errors with respect to anger and surprise emotion classes and show that these two emotions occur in similar contexts.", "labels": [], "entities": [{"text": "False Negative (FN) errors", "start_pos": 22, "end_pos": 48, "type": "METRIC", "confidence": 0.9442181487878164}]}, {"text": "It means that the senses expressed by these two emotion classes are much similar to each other in some tweets in which our system cannot distinguish them from each other.", "labels": [], "entities": []}, {"text": "Moreover, from, anger and surprise emotions constitute the highest portion of the FN errors in the other emotion classes.", "labels": [], "entities": [{"text": "FN errors", "start_pos": 82, "end_pos": 91, "type": "METRIC", "confidence": 0.5079304426908493}]}], "tableCaptions": [{"text": " Table 2: The accuracy of SVM and MLP on the devel- opment set", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9997535347938538}, {"text": "MLP", "start_pos": 34, "end_pos": 37, "type": "METRIC", "confidence": 0.9613933563232422}]}, {"text": " Table 3: The best results on the development set", "labels": [], "entities": []}, {"text": " Table 4: The performance of all models on the official test set", "labels": [], "entities": [{"text": "official test set", "start_pos": 47, "end_pos": 64, "type": "DATASET", "confidence": 0.7803794940312704}]}, {"text": " Table 5: Confusion matrix for final system", "labels": [], "entities": [{"text": "final", "start_pos": 31, "end_pos": 36, "type": "TASK", "confidence": 0.9632917046546936}]}]}