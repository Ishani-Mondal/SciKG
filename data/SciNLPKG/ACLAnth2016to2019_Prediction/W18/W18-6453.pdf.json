{"title": [{"text": "Findings of the WMT 2018 Shared Task on Parallel Corpus Filtering", "labels": [], "entities": [{"text": "WMT 2018 Shared Task", "start_pos": 16, "end_pos": 36, "type": "TASK", "confidence": 0.5918512046337128}, {"text": "Parallel Corpus Filtering", "start_pos": 40, "end_pos": 65, "type": "TASK", "confidence": 0.546167403459549}]}], "abstractContent": [{"text": "We posed the shared task of assigning sentence level quality scores fora very noisy corpus of sentence pairs crawled from the web, with the goal of sub-selecting 1% and 10% of high-quality data to be used to train machine translation systems.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 214, "end_pos": 233, "type": "TASK", "confidence": 0.7399488687515259}]}, {"text": "Seventeen participants from companies, national research labs, and universities participated in this task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Training corpora for machine translation come in varying degrees of quality.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.8488346636295319}]}, {"text": "On the one extreme end they are carefully professionally translated specifically for this purpose which may have done under the instruction to provide fairly literal translations and adherence to sentence-bysentence correspondences.", "labels": [], "entities": []}, {"text": "The other extreme are sentence pairs extracted with fully automatic processes from indiscriminate crawling of the World Wide Web.", "labels": [], "entities": []}, {"text": "The Shared Task on Parallel Corpus Filtering targets the second extreme, although the methods developed for this data condition should also carryover to less noisy parallel corpora.", "labels": [], "entities": [{"text": "Parallel Corpus Filtering", "start_pos": 19, "end_pos": 44, "type": "TASK", "confidence": 0.5857118467489878}]}, {"text": "In setting this task, we were motivated by our ongoing efforts to create large publicly available parallel corpora from web sources and the recognition that noisy parallel data is especially a concern for neural machine translation . This paper gives an overview of the task, presents its results and provides some analysis.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 205, "end_pos": 231, "type": "TASK", "confidence": 0.6740567982196808}]}], "datasetContent": [{"text": "The testing setup mirrors the development environment that we provided to the participants.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Noise in the raw Paracrawl corpus.", "labels": [], "entities": [{"text": "Paracrawl corpus", "start_pos": 27, "end_pos": 43, "type": "DATASET", "confidence": 0.9287456274032593}]}, {"text": " Table 2: Statistics for the test sets used to evalu- ate the machine translation systems trained on the  subsampled data sets. Word counts are obtained  with wc on untokenized text.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 62, "end_pos": 81, "type": "TASK", "confidence": 0.6948412954807281}]}, {"text": " Table 4: Main results. BLEU scores (case-insensitive) are reported on the average of 6 test sets. Best  performance on a test set is reported in bright green, scores within 0.5 BLEU points off the best in light  green, and scores within 1 BLEU point off the best in light yellow.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.9992462396621704}, {"text": "BLEU", "start_pos": 178, "end_pos": 182, "type": "METRIC", "confidence": 0.997502863407135}, {"text": "BLEU", "start_pos": 240, "end_pos": 244, "type": "METRIC", "confidence": 0.9982978701591492}]}, {"text": " Table 5: Detailed results for SMT performance. BLEU scores (case-insensitive) are reported on all the 6  test sets. The best performance on a test set is reported in bright green, scores within 0.5 BLEU points  off the best in light green, and scores within 1 BLEU point off the best in light yellow.", "labels": [], "entities": [{"text": "SMT", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.997443675994873}, {"text": "BLEU", "start_pos": 48, "end_pos": 52, "type": "METRIC", "confidence": 0.999322772026062}, {"text": "BLEU", "start_pos": 199, "end_pos": 203, "type": "METRIC", "confidence": 0.9974876642227173}, {"text": "BLEU", "start_pos": 261, "end_pos": 265, "type": "METRIC", "confidence": 0.9985582232475281}]}, {"text": " Table 6: Detailed results for NMT performance. BLEU scores (case-insensitive) are reported on all the 6  test sets. The best performance on a test set is reported in bright green, scores within 0.5 BLEU points  off the best in light green, and scores within 1 BLEU point off the best in light yellow.", "labels": [], "entities": [{"text": "NMT", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.9195895195007324}, {"text": "BLEU", "start_pos": 48, "end_pos": 52, "type": "METRIC", "confidence": 0.9992780089378357}, {"text": "BLEU", "start_pos": 199, "end_pos": 203, "type": "METRIC", "confidence": 0.9973461627960205}, {"text": "BLEU", "start_pos": 261, "end_pos": 265, "type": "METRIC", "confidence": 0.9984001517295837}]}]}