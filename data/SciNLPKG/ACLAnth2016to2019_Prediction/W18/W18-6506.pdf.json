{"title": [{"text": "SimpleNLG-ZH: a Linguistic Realisation Engine for Mandarin", "labels": [], "entities": [{"text": "SimpleNLG-ZH", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.8818207383155823}]}], "abstractContent": [{"text": "We introduce SimpleNLG-ZH, a realisa-tion engine for Mandarin that follows the software design paradigm of SimpleNLG (Gatt and Reiter, 2009).", "labels": [], "entities": []}, {"text": "We explain the core grammar (morphology and syntax) and the lexicon of SimpleNLG-ZH, which is very different from English and other languages for which SimpleNLG engines have been built.", "labels": [], "entities": [{"text": "SimpleNLG-ZH", "start_pos": 71, "end_pos": 83, "type": "DATASET", "confidence": 0.9156549572944641}]}, {"text": "The system was evaluated by regenerating expressions from a body of test sentences and a corpus of human-authored expressions.", "labels": [], "entities": []}, {"text": "Human evaluation was conducted to estimate the quality of regenerated sentences.", "labels": [], "entities": []}], "introductionContent": [{"text": "A classic natural language generation (NLG) system) is a pipeline consisting of document planning, sentence planning and surface realisation (in that order).", "labels": [], "entities": [{"text": "natural language generation (NLG)", "start_pos": 10, "end_pos": 43, "type": "TASK", "confidence": 0.8361085951328278}, {"text": "sentence planning", "start_pos": 99, "end_pos": 116, "type": "TASK", "confidence": 0.7166679948568344}]}, {"text": "Surface realisation maps information produced by earlier components to well-formed output strings in the target language.", "labels": [], "entities": [{"text": "Surface realisation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7349456250667572}]}, {"text": "A (surface) realiser employs languagespecific morpho-syntactic constraints to achieve proper word ordering, inflection, and selection of function words.", "labels": [], "entities": []}, {"text": "Different types of realisers exist (.", "labels": [], "entities": []}, {"text": "Unlike approaches that aim primarily for linguistic depth and coverage (, realisers in the SimpleNLG tradition aim primarily for ease of use and extendibility , and have become the realisation method of choice in many practical NLG applications, such as BabyTalk () and Absum.", "labels": [], "entities": [{"text": "linguistic depth", "start_pos": 41, "end_pos": 57, "type": "TASK", "confidence": 0.6892699003219604}, {"text": "Absum", "start_pos": 270, "end_pos": 275, "type": "DATASET", "confidence": 0.8928968906402588}]}, {"text": "SimpleNLG, as a human-crafted grammarbased realisation engine, performs linearisation and morphological inflection.", "labels": [], "entities": [{"text": "SimpleNLG", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.8965377807617188}]}, {"text": "Another realisation strategy uses statistical methods for acquiring probabilistic grammar from large corpora.", "labels": [], "entities": []}, {"text": "For example,) built a grammar bank based on Combinatorial Categorial Grammar, extracted from the Penn Treebank (.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 97, "end_pos": 110, "type": "DATASET", "confidence": 0.9959426820278168}]}, {"text": "When realising, OpenCCG applies a chart-based algorithm to generate all possible surface forms, which are then re-ranked by language models.", "labels": [], "entities": [{"text": "OpenCCG", "start_pos": 16, "end_pos": 23, "type": "DATASET", "confidence": 0.9103965759277344}]}, {"text": "Such an approach tends to have broader coverage, but less controllability and extendibility, which may explain why SimpleNLG is more popular in practical applications.", "labels": [], "entities": []}, {"text": "To date, the original English SimpleNLG has been adapted to German,, Portuguese),), Spanish (, Filipino () and Telugu (.", "labels": [], "entities": []}, {"text": "There is no such adaptation work yet for Sino-Tibetan languages, whose morphosyntactic structure is very different from the above languages.", "labels": [], "entities": []}, {"text": "Mandarin, a Sino-Tibetan language with nearly 1 billion first-language speakers, offers huge opportunities for natural language generation, yet only a limited amount of work has focused on Mandarin realisation.", "labels": [], "entities": [{"text": "Mandarin realisation", "start_pos": 189, "end_pos": 209, "type": "TASK", "confidence": 0.7303861975669861}]}, {"text": "KPML, a largescale multilingual generation and development, supports limited sentence structures in Mandarin (.", "labels": [], "entities": [{"text": "KPML", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8647719025611877}, {"text": "largescale multilingual generation", "start_pos": 8, "end_pos": 42, "type": "TASK", "confidence": 0.6837018132209778}]}, {"text": "introduced a data-driven generator, with dependency trees as input.", "labels": [], "entities": []}, {"text": "They used divide-and-conquer to break the dependency tree into sub-trees, realising each sub-tree using a log-linear model recursively.", "labels": [], "entities": []}, {"text": "However, their system needs a large amount of fully inflected dependency trees as training data.", "labels": [], "entities": []}, {"text": "This paper describes a realisation engine fol-lowing the design principles of SimpleNLG, i.e., keeping a clear separation between morphological and syntactic operations . Although we took existing SimpleNLG systems as a source of inspiration, the system is, in many ways, a re-design . For example, Mandarin, as a highly analytical language, needs far fewer morphological operations but many more syntactic constraints than English ().", "labels": [], "entities": []}, {"text": "SimpleNLG-ZH 2 (\"Zhongwen\" is Mandarin for \"Chinese\") was firstly built as a realiser for generating referring expressions in Mandarin) which are mostly noun phrases together with simple verb phrases, and then extended to coverage other constructions and phenomena in Mandarin.", "labels": [], "entities": []}, {"text": "It was developed as an adaptation from V4.4.8 of the original SimpleNLG 3 (SimpleNLG-EN).", "labels": [], "entities": [{"text": "SimpleNLG 3 (SimpleNLG-EN)", "start_pos": 62, "end_pos": 88, "type": "DATASET", "confidence": 0.8780031204223633}]}, {"text": "We show that SimpleNLG-ZH has wide coverage on test-sentences, and on the human authored corpus as well.", "labels": [], "entities": []}], "datasetContent": [{"text": "We decided to evaluate SimpleNLG-ZH in two ways.", "labels": [], "entities": [{"text": "SimpleNLG-ZH", "start_pos": 23, "end_pos": 35, "type": "DATASET", "confidence": 0.65116286277771}]}, {"text": "Firstly, following and, we applied a set of unit test to each module of the system, using the test cases https://github.com/ UniversalDependencies/UD_Chinese-CFL/ tree/master Lexical Category Universal POS: Relationship between Universal POS tags and lexical categories in SimpleNLG-ZH. from SimpleNLG-EN plus a set of newly constructed test cases that address some of the peculiarities of Mandarin (e.g., the \"\u628a\" construct).", "labels": [], "entities": []}, {"text": "Secondly, we evaluated the system using a set of expressions from a corpus of actual language use; this was reminiscent of and, but using a larger set of expressions.", "labels": [], "entities": []}, {"text": "In all cases, when faced with an input expression (i.e., from a test set or corpus), we used this expression to construct a formatted input that was then passed to SimpleNLG-ZH to produce an output expression which was then compared to the input expression.", "labels": [], "entities": [{"text": "SimpleNLG-ZH", "start_pos": 164, "end_pos": 176, "type": "DATASET", "confidence": 0.8460984826087952}]}, {"text": "The test cases consist of 144 sentences manually translated and adapted from SimpleNLG V4.4.8 JUnit Tests and two reference grammar books ().", "labels": [], "entities": [{"text": "SimpleNLG V4.4.8 JUnit Tests", "start_pos": 77, "end_pos": 105, "type": "DATASET", "confidence": 0.8962712287902832}]}, {"text": "The test cases coverall the linguistic features discussed in previous sections and all possible syntactic structures of referring expressions in Mandarin introduced in van.", "labels": [], "entities": []}, {"text": "All the tests were passed by SimpleNLG-ZH, that is, the generated sentences were all identical verbatim to the inputs.", "labels": [], "entities": [{"text": "SimpleNLG-ZH", "start_pos": 29, "end_pos": 41, "type": "DATASET", "confidence": 0.5782409310340881}]}, {"text": "We picked 100 noun phrases at random from the MTuna corpus, which is the corpus that first version of SimpleNLG-ZH focus on as stated in \u00a71.", "labels": [], "entities": [{"text": "MTuna corpus", "start_pos": 46, "end_pos": 58, "type": "DATASET", "confidence": 0.9718490540981293}]}, {"text": "MTuna is a corpus that has totally 1,650 referring expressions.", "labels": [], "entities": [{"text": "MTuna", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9524649381637573}]}, {"text": "We then re-generated these expressions using SimpleNLG-ZH.", "labels": [], "entities": [{"text": "SimpleNLG-ZH", "start_pos": 45, "end_pos": 57, "type": "DATASET", "confidence": 0.7075856924057007}]}, {"text": "Not all regenerated NPs were identical verbatim to the original MTuna NPs.", "labels": [], "entities": [{"text": "MTuna NPs", "start_pos": 64, "end_pos": 73, "type": "DATASET", "confidence": 0.9664362072944641}]}, {"text": "35 noun phrases did not match completely (i.e., verbatim) with the original noun phrases.", "labels": [], "entities": []}, {"text": "lists some typical examples, showing differences in word ordering, punctuation, and soon.", "labels": [], "entities": [{"text": "word ordering", "start_pos": 52, "end_pos": 65, "type": "TASK", "confidence": 0.6933897286653519}, {"text": "soon", "start_pos": 84, "end_pos": 88, "type": "METRIC", "confidence": 0.9718583226203918}]}, {"text": "We ran a human evaluation to find out whether the realised sentences were acceptable (i.e., are they fluent and do they have the same meaning as their inputs).", "labels": [], "entities": []}, {"text": "Two native speak-  (failed) No 7 \u6b63\u671d\u5411\u6211\u4eec\u7684\u5c0f\u7684\u6905\u5b50\u548c\u6b63\u671d\u5411\u6211\u4eec\u7684 \u5927\u7684\u98ce\u6247 zh\u00e8ngch\u00e1ox\u00ec ang w\u02c7om\u00e9nw\u02c7om\u00e9n de xi\u02c7aoxi\u02c7ao de y\u02c7\u0131z`\u0131y\u02c7\u0131z`y\u02c7\u0131z`\u0131 h\u00e9 zh\u00e8ngch\u00e1ox\u00ec ang w\u02c7om\u00e9nw\u02c7om\u00e9n de d` a de f\u00af engsh\u00e0n the fronting small chair and the fronting large fan zh\u00e8ngch\u00e1ox\u00ec ang w\u02c7ow\u02c7o de xi\u02c7aoxi\u02c7ao de y\u02c7\u0131z`\u0131y\u02c7\u0131z`y\u02c7\u0131z`\u0131 h\u00e9 zh\u00e8ngch\u00e1ox\u00ec ang w\u02c7ow\u02c7o de d` a de f\u00af engsh\u00e0n: Example sentences (with their Pinyin and translations) that were not identical to the inputs from MTuna (unmatched sentences).", "labels": [], "entities": [{"text": "MTuna", "start_pos": 431, "end_pos": 436, "type": "DATASET", "confidence": 0.8824878931045532}]}, {"text": "The last column says whether the output was judged to be acceptable by our annotators.", "labels": [], "entities": []}], "tableCaptions": []}