{"title": [{"text": "Joint Modeling for Query Expansion and Information Extraction with Reinforcement Learning", "labels": [], "entities": [{"text": "Information Extraction", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.7485183477401733}]}], "abstractContent": [{"text": "Information extraction about an event can be improved by incorporating external evidence.", "labels": [], "entities": [{"text": "Information extraction about an event", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8559615731239318}]}, {"text": "In this study, we propose a joint model for pseudo-relevance feedback based query expansion and information extraction with reinforcement learning.", "labels": [], "entities": [{"text": "query expansion", "start_pos": 76, "end_pos": 91, "type": "TASK", "confidence": 0.7052226364612579}, {"text": "information extraction", "start_pos": 96, "end_pos": 118, "type": "TASK", "confidence": 0.7831574976444244}]}, {"text": "Our model generates an event-specific query to effectively retrieve documents relevant to the event.", "labels": [], "entities": []}, {"text": "We demonstrate that our model is comparable or has better performance than the previous model in two publicly available datasets.", "labels": [], "entities": []}, {"text": "Furthermore, we analyzed the influences of the retrieval effectiveness in our model on the extraction performance .", "labels": [], "entities": []}], "introductionContent": [{"text": "Information extraction about an event is gaining growing interest because of the increases in text data.", "labels": [], "entities": [{"text": "Information extraction about an event", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8781159281730652}]}, {"text": "The task of information extraction about an event from a text is defined to identify a set of values including entities, temporal expressions and numerical expressions that serve as a participant or attribute of the event.", "labels": [], "entities": [{"text": "information extraction about an event from a text", "start_pos": 12, "end_pos": 61, "type": "TASK", "confidence": 0.8774652183055878}]}, {"text": "The extracted information is useful for various applications such as risk monitoring and decision making support ().", "labels": [], "entities": [{"text": "risk monitoring", "start_pos": 69, "end_pos": 84, "type": "TASK", "confidence": 0.7779741287231445}, {"text": "decision making support", "start_pos": 89, "end_pos": 112, "type": "TASK", "confidence": 0.9111972649892172}]}, {"text": "Conventional information extraction systems provide higher performance if the amount of labeled data is larger.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 13, "end_pos": 35, "type": "TASK", "confidence": 0.7623873651027679}]}, {"text": "Labeled training data is expensive to produce and thus the data amount is limited.", "labels": [], "entities": []}, {"text": "In this case, extraction accuracy can be improved using an alternative approach that incorporates evidence from external sources such as the Web (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9271267652511597}]}, {"text": "However, this approach faces the following challenges: issuing an effective query to the external source, identifying documents relevant to a target event from retrieval results and reconciling the values extracted from the relevant documents.", "labels": [], "entities": []}, {"text": "To overcome these problems, several attempts have been made to model the decisions as a Markov Decision Process (MDP) with deep reinforcement learning (RL).", "labels": [], "entities": []}, {"text": "The agent of these models is trained to maximize expected rewards (extraction accuracy) by performing actions to select an expanded query for external source and to reconcile values extracted from documents retrieved from the external source.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9500102996826172}]}, {"text": "The models use the title of source document as an original query and templates to expand this query.", "labels": [], "entities": []}, {"text": "Expansion terms of the template are same in any event even though an optimal query depends on the event.", "labels": [], "entities": []}, {"text": "Therefore, it is still a challenge to issue an effective query to an external source.", "labels": [], "entities": []}, {"text": "In this study, we extended the previous models by introducing a query expansion based on pseudo-relevance feedback (PRF) (.", "labels": [], "entities": [{"text": "pseudo-relevance feedback (PRF)", "start_pos": 89, "end_pos": 120, "type": "METRIC", "confidence": 0.6672887742519379}]}, {"text": "The PRF based query expansion assumes that the top-ranked documents retrieved by an original query are relevant to the original query.", "labels": [], "entities": []}, {"text": "An agent of our model selects a term from those documents and generates an expanded query by adding the term into the original query.", "labels": [], "entities": []}, {"text": "The PRF based query expansion enables us to add an eventspecific term into the query without additional resources.", "labels": [], "entities": []}, {"text": "For instance, let us consider an information extraction about a shooting incident.", "labels": [], "entities": [{"text": "information extraction about a shooting incident", "start_pos": 33, "end_pos": 81, "type": "TASK", "confidence": 0.8455448100964228}]}, {"text": "The query \"Shooting on Warren Ave.", "labels": [], "entities": [{"text": "Shooting", "start_pos": 11, "end_pos": 19, "type": "TASK", "confidence": 0.8760332465171814}, {"text": "Warren Ave", "start_pos": 23, "end_pos": 33, "type": "DATASET", "confidence": 0.6988423466682434}]}, {"text": "leaves one dead\" retrieves the documents which may contain the term \"New York\".", "labels": [], "entities": []}, {"text": "The addition of the eventspecific term \"New York\" to the query leads to the filtering out of irrelevant documents, and thus to improves retrieval performance because \"Warren Ave.\" is located in \"New York\".", "labels": [], "entities": [{"text": "Warren Ave.\"", "start_pos": 167, "end_pos": 179, "type": "DATASET", "confidence": 0.9591942032178243}]}, {"text": "Therefore, we expect to improve extraction accuracy by introducing PRF based query expansion.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9694542288780212}]}, {"text": "In contrast to the previous models, candidate terms for query expansion in our model vary de- pending on an event.", "labels": [], "entities": [{"text": "query expansion", "start_pos": 56, "end_pos": 71, "type": "TASK", "confidence": 0.727534294128418}]}, {"text": "Therefore, we exploit an original query and its candidate terms information as inputs of policy networks in addition to state information.", "labels": [], "entities": []}, {"text": "The contributions of this paper are follows: \u2022 We propose a joint model for PRF based query expansion and information extraction with RL.", "labels": [], "entities": [{"text": "PRF based query expansion", "start_pos": 76, "end_pos": 101, "type": "TASK", "confidence": 0.6927408203482628}, {"text": "information extraction", "start_pos": 106, "end_pos": 128, "type": "TASK", "confidence": 0.8061218857765198}]}, {"text": "\u2022 We investigated the oracle extraction accuracy as an indicator of the model's retrieval performance to reveal that the PRF based query expansion outperforms the template query in two publicly available datasets.", "labels": [], "entities": [{"text": "oracle extraction", "start_pos": 22, "end_pos": 39, "type": "TASK", "confidence": 0.7461462616920471}, {"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.6770948767662048}]}, {"text": "\u2022 We demonstrate that our model is comparable or better extraction performance compared to the previous model in the datasets.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated our model on Shooting and Adulteration datasets that used in.", "labels": [], "entities": [{"text": "Shooting and Adulteration datasets", "start_pos": 26, "end_pos": 60, "type": "DATASET", "confidence": 0.5836118534207344}]}, {"text": "For each an original query, we collected the candidate terms obtained from the first M words of the top-K documents retrieved through Bing Search API 1 . The vocabulary size of the candidate terms N is defined as M K + 1 because the null token, namely no query expansion, is also included in the candidate terms.", "labels": [], "entities": []}, {"text": "We downloaded the top 20 documents from the Bing Search API as the external sources through an expanded query.", "labels": [], "entities": []}, {"text": "Statistics of the original datasets and downloaded documents is described in.", "labels": [], "entities": []}, {"text": "Word embeddings are set to fixed vectors of 300 dimensions and is initialized with word2vec embedding trained on Google News Dataset 2 . We set the unit size of FC S1 and FC S2 to 20, FC Q1 to 300, FC V and FC Q2 to 1.", "labels": [], "entities": [{"text": "Google News Dataset 2", "start_pos": 113, "end_pos": 134, "type": "DATASET", "confidence": 0.9514197707176208}]}, {"text": "Further, we set the number of feature maps of CNN to 200 and the window size of CNN to 3.", "labels": [], "entities": [{"text": "CNN", "start_pos": 80, "end_pos": 83, "type": "DATASET", "confidence": 0.931696355342865}]}, {"text": "Discount factor and the constant of entropy regularization were set to 0.8 and 0.01, respectively.", "labels": [], "entities": [{"text": "Discount factor", "start_pos": 0, "end_pos": 15, "type": "METRIC", "confidence": 0.9802536368370056}]}, {"text": "We utilize RMSprop () as the optimizer and set the number of threads in A3C to 16.", "labels": [], "entities": []}, {"text": "We employed RLIE-A3C () as a baseline model to compare with our model.", "labels": [], "entities": [{"text": "RLIE-A3C", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9429088234901428}]}, {"text": "We used their public implementation 3 .", "labels": [], "entities": []}], "tableCaptions": []}