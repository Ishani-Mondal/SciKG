{"title": [{"text": "Stylistic Variation in Social Media Part-of-Speech Tagging", "labels": [], "entities": [{"text": "Stylistic Variation in Social Media Part-of-Speech Tagging", "start_pos": 0, "end_pos": 58, "type": "TASK", "confidence": 0.6413497286183494}]}], "abstractContent": [{"text": "Social media features substantial stylistic variation , raising new challenges for syntactic analysis of online writing.", "labels": [], "entities": [{"text": "syntactic analysis of online writing", "start_pos": 83, "end_pos": 119, "type": "TASK", "confidence": 0.8098078966140747}]}, {"text": "However, this variation is often aligned with author attributes such as age, gender, and geography, as well as more readily-available social network meta-data.", "labels": [], "entities": []}, {"text": "In this paper, we report new evidence on the link between language and social networks in the task of part-of-speech tagging.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 102, "end_pos": 124, "type": "TASK", "confidence": 0.7704223394393921}]}, {"text": "We find that tagger error rates are correlated with network structure, with high accuracy in some parts of the network, and lower accuracy elsewhere.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9986140727996826}, {"text": "accuracy", "start_pos": 130, "end_pos": 138, "type": "METRIC", "confidence": 0.9981114864349365}]}, {"text": "As a result, tagger accuracy depends on training from a balanced sample of the network, rather than training on texts from a narrow subcommunity.", "labels": [], "entities": [{"text": "tagger", "start_pos": 13, "end_pos": 19, "type": "TASK", "confidence": 0.9654486775398254}, {"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9296807646751404}]}, {"text": "We also describe our attempts to add robustness to stylistic variation, by building a mixture-of-experts model in which each expert is associated with a region of the social network.", "labels": [], "entities": []}, {"text": "While prior work found that similar approaches yield performance improvements in sentiment analysis and entity linking, we were unable to obtain performance improvements in part-of-speech tagging, despite strong evidence for the link between part-of-speech error rates and social network structure.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.9412840008735657}, {"text": "entity linking", "start_pos": 104, "end_pos": 118, "type": "TASK", "confidence": 0.7488403916358948}, {"text": "part-of-speech tagging", "start_pos": 173, "end_pos": 195, "type": "TASK", "confidence": 0.6947295516729355}]}], "introductionContent": [{"text": "Social media feature greater diversity than the formal genres that constitute classic datasets such as the Penn Treebank () and the Brown Corpus: there are more authors, more kinds of authors, more varied communicative settings, fewer rules, and more stylistic variation (.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 107, "end_pos": 120, "type": "DATASET", "confidence": 0.9944044053554535}, {"text": "Brown Corpus", "start_pos": 132, "end_pos": 144, "type": "DATASET", "confidence": 0.947576254606247}]}, {"text": "Previous work has demonstrated precipitous declines in the performance of stateof-the-art systems for core tasks such as part-ofspeech tagging () and namedentity recognition () when these systems are applied to social media text, and stylistic diversity seems the likely culprit.", "labels": [], "entities": [{"text": "part-ofspeech tagging", "start_pos": 121, "end_pos": 142, "type": "TASK", "confidence": 0.7102452516555786}, {"text": "namedentity recognition", "start_pos": 150, "end_pos": 173, "type": "TASK", "confidence": 0.6662749797105789}]}, {"text": "However, we still lack quantitative evidence of the role played by language variation in the performance of NLP systems in social media, and existing solutions to this problem are piecemeal at best.", "labels": [], "entities": []}, {"text": "In this paper, we attempt to address both issues: we quantify the impact of one form of sociolinguistic variation on part-of-speech tagging accuracy, and we design a model that attempts to adapt to this variation.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 117, "end_pos": 139, "type": "TASK", "confidence": 0.6183572560548782}, {"text": "accuracy", "start_pos": 140, "end_pos": 148, "type": "METRIC", "confidence": 0.8831931948661804}]}, {"text": "Our contribution focuses on the impact of language variation that is aligned with one or more social networks among authors on the microblogging platform Twitter.", "labels": [], "entities": []}, {"text": "We choose Twitter because language styles in this platform are particularly diverse ( , and because moderately large labeled datasets are available).", "labels": [], "entities": []}, {"text": "We choose social networks for several reasons.", "labels": [], "entities": []}, {"text": "First, they can readily be obtained from both metadata and behavioral traces on multiple social media platforms (.", "labels": [], "entities": []}, {"text": "Second, social networks are strongly correlated with \"demographic\" author-level variables such as age (), gender), race, and geography, thanks to the phenomenon of homophily, also known as assortative mixing ().", "labels": [], "entities": []}, {"text": "These demographic variables are in turn closely linked to language variation in American English, and have been shown to improve some document classification tasks.", "labels": [], "entities": [{"text": "document classification", "start_pos": 134, "end_pos": 157, "type": "TASK", "confidence": 0.7851150035858154}]}, {"text": "Third, there is growing evidence of the strong relationship between social network structures and language variation, even beyond the extent to which the social network acts as a proxy for demographic attributes.", "labels": [], "entities": []}, {"text": "To measure the impact of socially-linked language variation, we focus on part-of-speech tagging, a fundamental task for syntactic analysis.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 73, "end_pos": 95, "type": "TASK", "confidence": 0.72612564265728}, {"text": "syntactic analysis", "start_pos": 120, "end_pos": 138, "type": "TASK", "confidence": 0.8410004079341888}]}, {"text": "First, we measure the extent to which tagger performance is correlated with network structure, finding that tagger performance on friends is significantly more correlated than would be expected by chance.", "labels": [], "entities": []}, {"text": "We then design alternative training and test splits that are aligned with network structure, and find that test set performance decreases in this scenario, which corresponds to domain adaptation across social network communities.", "labels": [], "entities": []}, {"text": "This speaks to the importance of covering all relevant social network communities in training data.", "labels": [], "entities": []}, {"text": "We then consider how to address the problem of language variation, by building social awareness into a recurrent neural tagging model.", "labels": [], "entities": [{"text": "language variation", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.7219168394804001}]}, {"text": "Our modeling approach is inspired by, who train a mixture-of-experts for sentiment analysis, where the expert weights are computed from social network node embeddings.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 73, "end_pos": 91, "type": "TASK", "confidence": 0.9402036666870117}]}, {"text": "But while prior work demonstrated improvements in sentiment analysis and information extraction (, this approach does not yield any gains on part-of-speech tagging.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 50, "end_pos": 68, "type": "TASK", "confidence": 0.9719983339309692}, {"text": "information extraction", "start_pos": 73, "end_pos": 95, "type": "TASK", "confidence": 0.8147498965263367}, {"text": "part-of-speech tagging", "start_pos": 141, "end_pos": 163, "type": "TASK", "confidence": 0.7247089445590973}]}, {"text": "We conclude the paper by briefly considering possible reasons for this discrepancy, and propose approaches for future work in social adaptation of syntactic analysis.", "labels": [], "entities": [{"text": "social adaptation of syntactic analysis", "start_pos": 126, "end_pos": 165, "type": "TASK", "confidence": 0.6484088182449341}]}], "datasetContent": [{"text": "Our evaluation focuses on the DAILY547 dataset (.", "labels": [], "entities": [{"text": "DAILY547 dataset", "start_pos": 30, "end_pos": 46, "type": "DATASET", "confidence": 0.9709329903125763}]}, {"text": "We train our system on the train and dev splits of the OCT27 dataset () and use the test split of OCT27 as our validation dataset and evaluate on the DAILY547 dataset.", "labels": [], "entities": [{"text": "OCT27 dataset", "start_pos": 55, "end_pos": 68, "type": "DATASET", "confidence": 0.9598899483680725}, {"text": "OCT27", "start_pos": 98, "end_pos": 103, "type": "DATASET", "confidence": 0.9414577484130859}, {"text": "DAILY547 dataset", "start_pos": 150, "end_pos": 166, "type": "DATASET", "confidence": 0.9741332828998566}]}, {"text": "Accuracy of the tokens is our evaluation metric for the model.", "labels": [], "entities": []}, {"text": "We compare our results to our baseline model and the state of the art results on the Twitter OCT27+Daily547 dataset.", "labels": [], "entities": [{"text": "Twitter OCT27+Daily547 dataset", "start_pos": 85, "end_pos": 115, "type": "DATASET", "confidence": 0.7960532426834106}]}, {"text": "We use 100-dimensional pretrained Twitter GloVe embeddings () which are   trained on about two billion tweets.", "labels": [], "entities": []}, {"text": "We use onelayer for both the character-level and the wordlevel bi-LSTM model with hidden state sizes of 50 and 150 dimensions respectively.", "labels": [], "entities": []}, {"text": "The dimensions of character embeddings is set to be 30 and the learned word embeddings is 50.", "labels": [], "entities": []}, {"text": "We use tanh activation functions all throughout the model and use Xavier initialization for the parameters.", "labels": [], "entities": []}, {"text": "The model is trained with ADAM optimizer) on L2-regularized negative log-likelihood.", "labels": [], "entities": []}, {"text": "The regularization strength was set to 0.01, and the dropout was set to 0.35.", "labels": [], "entities": [{"text": "regularization strength", "start_pos": 4, "end_pos": 27, "type": "METRIC", "confidence": 0.8575121164321899}]}, {"text": "The best hyper-parameters for the number of basis classifiers is K = 3 for the follow and mention networks, and K = 4 for the retweet network..", "labels": [], "entities": []}, {"text": "We also evaluate the performance of the trained Social Attention model on the subset of authors who can be located in the social network.", "labels": [], "entities": []}, {"text": "The accuracy on these authors is similar to the overall performance on the full dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9995898604393005}]}, {"text": "We also observe the attention distributions of the authors in the social network on the basis models in the ensemble.", "labels": [], "entities": []}, {"text": "For every pair of authors a i and a j connected in the social network we compute \u03a3 k |\u03c0 a i ,k \u2212 \u03c0 a j ,k | and average it across all pairs in the network.", "labels": [], "entities": []}, {"text": "This  is compared with against a randomly rewired network.", "labels": [], "entities": []}, {"text": "If this value is lower for the social network, then this indicates that the connected authors tend to have similar attentional distributions as explained in \u00a7 4.", "labels": [], "entities": []}, {"text": "The results are presented in.", "labels": [], "entities": []}, {"text": "These results clearly indicate that the authors who are connected in the social network tend to have similar attentional distributions.", "labels": [], "entities": []}, {"text": "While the analyses in \u00a7 3 indicated a strong degree of linguistic homophily, we do not observe any significant gain in performance.", "labels": [], "entities": []}, {"text": "We think the following factors played an important role:", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2 specifies the  number of tweets and tokens in each dataset. The  tagset for this dataset is explained in Owoputi et al.  (2013); it differs significantly from the Penn Tree- bank and Universal Dependencies tagsets.  In September 2017, we extracted author IDs  for each of the tweets and constructed three au- thor social networks based on the follow, mention,  and retweet relations between the authors in the", "labels": [], "entities": [{"text": "Penn Tree- bank", "start_pos": 172, "end_pos": 187, "type": "DATASET", "confidence": 0.9847194701433182}]}, {"text": " Table 3: Comparison of tagger accuracy using  network-based and random training/test splits", "labels": [], "entities": [{"text": "tagger", "start_pos": 24, "end_pos": 30, "type": "TASK", "confidence": 0.9722539186477661}, {"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.8826331496238708}]}, {"text": " Table 4: Accuracy of the models on the DAILY547  dataset. The best results are in bold.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9976094961166382}, {"text": "DAILY547  dataset", "start_pos": 40, "end_pos": 57, "type": "DATASET", "confidence": 0.9816995859146118}]}, {"text": " Table 5: Accuracy of the social attention model,  across each of the three networks.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.972920835018158}]}, {"text": " Table 6: Comparison of the mean absolute dif- ference in attention distributions of connected au- thors in actual social networks versus randomly  rewired networks.", "labels": [], "entities": [{"text": "mean absolute dif- ference", "start_pos": 28, "end_pos": 54, "type": "METRIC", "confidence": 0.6435263216495514}]}]}