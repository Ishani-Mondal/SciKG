{"title": [{"text": "Neural User Simulation for Corpus-based Policy Optimisation for Spoken Dialogue Systems", "labels": [], "entities": [{"text": "Neural User Simulation", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7148546973864237}]}], "abstractContent": [{"text": "User Simulators are one of the major tools that enable offline training of task-oriented dialogue systems.", "labels": [], "entities": [{"text": "User Simulators", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7118763774633408}]}, {"text": "For this task the Agenda-Based User Simulator (ABUS) is often used.", "labels": [], "entities": []}, {"text": "The ABUS is based on hand-crafted rules and its output is in semantic form.", "labels": [], "entities": [{"text": "ABUS", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.631244421005249}]}, {"text": "Issues arise from both properties such as limited diversity and the inability to interface a text-level belief tracker.", "labels": [], "entities": []}, {"text": "This paper introduces the Neural User Simu-lator (NUS) whose behaviour is learned from a corpus and which generates natural language, hence needing a less labelled dataset than simulators generating a semantic output.", "labels": [], "entities": []}, {"text": "In comparison to much of the past work on this topic, which evaluates user simulators on corpus-based met-rics, we use the NUS to train the policy of a reinforcement learning based Spoken Dialogue System.", "labels": [], "entities": [{"text": "NUS", "start_pos": 123, "end_pos": 126, "type": "DATASET", "confidence": 0.9591426849365234}]}, {"text": "The NUS is compared to the ABUS by evaluating the policies that were trained using the simulators.", "labels": [], "entities": [{"text": "NUS", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.8552762866020203}, {"text": "ABUS", "start_pos": 27, "end_pos": 31, "type": "DATASET", "confidence": 0.5061098337173462}]}, {"text": "Cross-model evaluation is performed i.e. training on one simulator and testing on the other.", "labels": [], "entities": []}, {"text": "Furthermore, the trained policies are tested on real users.", "labels": [], "entities": []}, {"text": "In both evaluation tasks the NUS outperformed the ABUS.", "labels": [], "entities": [{"text": "NUS", "start_pos": 29, "end_pos": 32, "type": "DATASET", "confidence": 0.8198372721672058}, {"text": "ABUS", "start_pos": 50, "end_pos": 54, "type": "METRIC", "confidence": 0.5960361361503601}]}], "introductionContent": [{"text": "Spoken Dialogue Systems (SDS) allow humancomputer interaction using natural speech.", "labels": [], "entities": []}, {"text": "Taskoriented dialogue systems, the focus of this work, help users achieve goals such as finding restaurants or booking flights ().", "labels": [], "entities": []}, {"text": "Teaching a system how to respond appropriately in a task-oriented setting is non-trivial.", "labels": [], "entities": []}, {"text": "In state-ofthe-art systems this dialogue management task is often formulated as a reinforcement learning (RL) problem (.", "labels": [], "entities": [{"text": "dialogue management task", "start_pos": 32, "end_pos": 56, "type": "TASK", "confidence": 0.815639317035675}]}, {"text": "In this framework, the system learns by atrial and error process governed by a reward function.", "labels": [], "entities": []}, {"text": "User Simulators can be used to train the policy of a dialogue manager (DM) without real user interactions.", "labels": [], "entities": []}, {"text": "Furthermore, they allow an unlimited number of dialogues to be created with each dialogue being faster than a dialogue with a human.", "labels": [], "entities": []}, {"text": "In this paper the Neural User Simulator (NUS) is introduced which outputs natural language and whose behaviour is learned from a corpus.", "labels": [], "entities": [{"text": "Neural User Simulator (NUS)", "start_pos": 18, "end_pos": 45, "type": "TASK", "confidence": 0.7728533546129862}]}, {"text": "The main component, inspired by ), consists of a feature extractor and a neural network based sequence-to-sequence model).", "labels": [], "entities": []}, {"text": "The sequence-tosequence model consists of a recurrent neural network (RNN) encoder that encodes the dialogue history and a decoder RNN which outputs natural language.", "labels": [], "entities": []}, {"text": "Furthermore, the NUS generates its own goal and possibly changes it during a dialogue.", "labels": [], "entities": []}, {"text": "This allows the model to be deployed for training more sophisticated DM policies.", "labels": [], "entities": []}, {"text": "To achieve this, a method is proposed that transforms the goal-labels of the used dataset (DSTC2) into labels whose behaviour can be replicated during deployment.", "labels": [], "entities": []}, {"text": "The NUS is trained on dialogues between real users and an SDS in a restaurant recommendation domain.", "labels": [], "entities": [{"text": "NUS", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.9339426755905151}]}, {"text": "Compared to much of the related work on user simulation, we use the trained NUS to train the policy of a reinforcement learning based SDS.", "labels": [], "entities": []}, {"text": "In order to evaluate the NUS, an Agenda-Based User-Simulator (ABUS) () is used to train another policy.", "labels": [], "entities": []}, {"text": "The two policies are compared against each other by using crossmodel evaluation ().", "labels": [], "entities": []}, {"text": "This means to train on one model and to test on the other.", "labels": [], "entities": []}, {"text": "Furthermore, both trained policies are tested on real users.", "labels": [], "entities": []}, {"text": "On both evaluation tasks the NUS outperforms the ABUS, which is currently one of the most popular off-line training tools for reinforcement learning based Spoken Dialogue Systems (.", "labels": [], "entities": [{"text": "NUS", "start_pos": 29, "end_pos": 32, "type": "DATASET", "confidence": 0.8293583989143372}, {"text": "ABUS", "start_pos": 49, "end_pos": 53, "type": "METRIC", "confidence": 0.973839282989502}]}, {"text": "The remainder of this paper is organised as follows.", "labels": [], "entities": []}, {"text": "Section 2 briefly describes task-oriented dialogue.", "labels": [], "entities": []}, {"text": "Section 3 describes the motivation for the NUS and discusses related work.", "labels": [], "entities": [{"text": "NUS", "start_pos": 43, "end_pos": 46, "type": "DATASET", "confidence": 0.6205950379371643}]}, {"text": "Section 4 explains the structure of the NUS, how it is trained and how it is deployed for training a DM's policy.", "labels": [], "entities": [{"text": "NUS", "start_pos": 40, "end_pos": 43, "type": "DATASET", "confidence": 0.8667305111885071}]}, {"text": "Sections 5 and 6 present the experimental setup and results.", "labels": [], "entities": []}, {"text": "Finally, Section 7 gives conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "The evaluation of user simulators is an ongoing area of research and a variety of techniques can be found in the literature.", "labels": [], "entities": []}, {"text": "Most papers published on user simulation evaluate their US using direct methods.", "labels": [], "entities": []}, {"text": "These methods evaluate the US through a statistical measure of similarity between the outputs of the US and areal user on a test set.", "labels": [], "entities": []}, {"text": "Multiple models can outperform the ABUS on these metrics.", "labels": [], "entities": [{"text": "ABUS", "start_pos": 35, "end_pos": 39, "type": "METRIC", "confidence": 0.9776776432991028}]}, {"text": "However, this is unsurprising since these user simulators were trained on the same or similar metrics.", "labels": [], "entities": []}, {"text": "The ABUS was explicitly proposed as a tool to train the policy of a dialogue manager and it is still the dominant form of US used for this task.", "labels": [], "entities": [{"text": "ABUS", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.7151836156845093}, {"text": "US", "start_pos": 122, "end_pos": 124, "type": "METRIC", "confidence": 0.8733251094818115}]}, {"text": "Therefore, the only fair comparison between anew US model and the ABUS is to use the indirect method of evaluating the policies that were obtained by training with each US.", "labels": [], "entities": [{"text": "ABUS", "start_pos": 66, "end_pos": 70, "type": "DATASET", "confidence": 0.5931398868560791}]}, {"text": "98.0% (NUS).", "labels": [], "entities": [{"text": "NUS)", "start_pos": 7, "end_pos": 11, "type": "DATASET", "confidence": 0.8368344008922577}]}, {"text": "This shows that the behaviour of the Neural User Simulator is realistic and diverse enough to train policies that can also perform very well on the Agenda-Based User Simulator.", "labels": [], "entities": []}, {"text": "Of the five policies, for each US, the policy performing best on the NUS was not the best performing policy on the ABUS.", "labels": [], "entities": [{"text": "NUS", "start_pos": 69, "end_pos": 72, "type": "DATASET", "confidence": 0.9658268690109253}, {"text": "ABUS", "start_pos": 115, "end_pos": 119, "type": "DATASET", "confidence": 0.9430903792381287}]}, {"text": "This could indicate that the policy \"overfits\" to a particular user simulator.", "labels": [], "entities": []}, {"text": "Overfitting usually manifests itself in worse results as the model is trained for longer.", "labels": [], "entities": []}, {"text": "Five policies trained on each US for only 1000 dialogues were also evaluated, the results of which can be seen in.", "labels": [], "entities": []}, {"text": "After training for 1000 dialogues, the average SR of the policies trained on the NUS when tested on the ABUS was 97.3% in comparison to 94.0% after 4000 dialogues.", "labels": [], "entities": [{"text": "SR", "start_pos": 47, "end_pos": 49, "type": "METRIC", "confidence": 0.9987049102783203}, {"text": "NUS", "start_pos": 81, "end_pos": 84, "type": "DATASET", "confidence": 0.9454754590988159}, {"text": "ABUS", "start_pos": 104, "end_pos": 108, "type": "DATASET", "confidence": 0.5628126859664917}]}, {"text": "This behaviour was observed for all five seeds, which indicates that the policy indeed overfits to the NUS.", "labels": [], "entities": [{"text": "NUS", "start_pos": 103, "end_pos": 106, "type": "DATASET", "confidence": 0.9792829155921936}]}, {"text": "For the policies trained with the ABUS this was not observed.", "labels": [], "entities": [{"text": "ABUS", "start_pos": 34, "end_pos": 38, "type": "DATASET", "confidence": 0.5061349272727966}]}, {"text": "This could indicate that the policy can learn to exploit some of the shortcomings of the trained NUS.", "labels": [], "entities": [{"text": "NUS", "start_pos": 97, "end_pos": 100, "type": "DATASET", "confidence": 0.8899897336959839}]}, {"text": "The results of the human evaluation are shown in for 250 dialogues per policy.", "labels": [], "entities": []}, {"text": "In policies are marked using an ID (U \u03b1 ) that translates to results in and 3 since all user goals were achievable.", "labels": [], "entities": []}, {"text": "on the ABUS in terms of both reward and success rate.", "labels": [], "entities": [{"text": "ABUS", "start_pos": 7, "end_pos": 11, "type": "METRIC", "confidence": 0.8927003741264343}, {"text": "reward", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.9923321008682251}, {"text": "success rate", "start_pos": 40, "end_pos": 52, "type": "METRIC", "confidence": 0.9319738447666168}]}, {"text": "The best performing policy trained on the NUS achieves a 93.4% success rate and 13.8 average rewards whilst the best performing policy trained with the ABUS achieves only a 90.0% success rate and 13.3 average reward.", "labels": [], "entities": [{"text": "NUS", "start_pos": 42, "end_pos": 45, "type": "DATASET", "confidence": 0.9236904978752136}, {"text": "ABUS", "start_pos": 152, "end_pos": 156, "type": "DATASET", "confidence": 0.6759529709815979}]}, {"text": "This shows that the good performance of the NUS on the crossmodel evaluation transfers to real users.", "labels": [], "entities": [{"text": "NUS", "start_pos": 44, "end_pos": 47, "type": "DATASET", "confidence": 0.9074574112892151}]}, {"text": "Furthermore, the overfitting to a particular US is also observed in the real user evaluation.", "labels": [], "entities": []}, {"text": "For not only the policies trained on the NUS, but also those trained on the ABUS, the best performing policy was the policy that performed best on the other US.", "labels": [], "entities": [{"text": "NUS", "start_pos": 41, "end_pos": 44, "type": "DATASET", "confidence": 0.9693072438240051}, {"text": "ABUS", "start_pos": 76, "end_pos": 80, "type": "DATASET", "confidence": 0.7934775948524475}]}], "tableCaptions": [{"text": " Table 2: Results for policies trained for 4000 di- alogues on NUS and ABUS when tested on both  USs for 1000 dialogues. Five policies with differ- ent initialisations were trained for each US. Both  average and best results are shown.", "labels": [], "entities": [{"text": "NUS", "start_pos": 63, "end_pos": 66, "type": "DATASET", "confidence": 0.980789840221405}, {"text": "ABUS", "start_pos": 71, "end_pos": 75, "type": "DATASET", "confidence": 0.48932117223739624}]}, {"text": " Table 4: Real User Evaluation. Results over 250  dialogues with human users. N 1 and A 1 per- formed best on the NUS. N 2 and A 2 performed  best on the ABUS. Rewards are not comparable to", "labels": [], "entities": [{"text": "NUS", "start_pos": 114, "end_pos": 117, "type": "DATASET", "confidence": 0.9742971658706665}, {"text": "ABUS", "start_pos": 154, "end_pos": 158, "type": "DATASET", "confidence": 0.5596172213554382}, {"text": "Rewards", "start_pos": 160, "end_pos": 167, "type": "METRIC", "confidence": 0.9953807592391968}]}]}