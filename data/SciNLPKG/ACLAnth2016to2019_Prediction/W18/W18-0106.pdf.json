{"title": [{"text": "Modeling bilingual word associations as connected monolingual networks", "labels": [], "entities": []}], "abstractContent": [{"text": "Word associations area common tool in research on the mental lexicon.", "labels": [], "entities": []}, {"text": "Studies report that bilinguals produce different word associations in their non-native language than monolinguals, and propose at least three mechanisms responsible for this difference: bilinguals may rely on their native associations (through translation), on collo-cational patterns, and on the phonological similarity between words.", "labels": [], "entities": []}, {"text": "In this paper, we first test the differences between monolin-gual and bilingual responses, showing that these differences are consistent and significant.", "labels": [], "entities": []}, {"text": "Second, we present a computational model of bilingual word associations, implemented as a semantic network paired with a retrieval mechanism.", "labels": [], "entities": []}, {"text": "Our model predicts bilingual word associations better than monolingual baselines, and translation is the main mechanism explaining its success , while collocational and phonological associations do not improve the model.", "labels": [], "entities": []}], "introductionContent": [{"text": "Ina free association task, participants are given a cue word (e.g., apple) and produce the first word that comes to their mind (e.g., red or fruit).", "labels": [], "entities": []}, {"text": "Free associations have been a common tool in the study of the mental lexicon because the observed pattern of associations can reflect the nature and strength of connections between words in semantic memory.", "labels": [], "entities": []}, {"text": "We focus on free associations as a means to better understand the structure and processing of the mental lexicon in bilinguals.", "labels": [], "entities": []}, {"text": "Bilingual word associations have been studied for decades (see an overview in.", "labels": [], "entities": [{"text": "Bilingual word associations", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8585901657740275}]}, {"text": "Despite a number of important findings, which we summarize in the following section, high-level conclusions about the association norms in bilinguals' non-native language are unclear -not only because of high variability in bilingual populations), but also due to methodological factors (as explained by).", "labels": [], "entities": []}, {"text": "Of specific concern for us is the lack of robust statistical analyses of the results.", "labels": [], "entities": []}, {"text": "Many studies provide a selective qualitative analysis of the responses, and their findings can be inconsistent.", "labels": [], "entities": []}, {"text": "In particular, it is unclear whether there are significant differences between native and non-native word associations (as compared, for example, to the instability of responses within a group of speakers over time).", "labels": [], "entities": []}, {"text": "We address this issue by providing a statistical analysis of the differences in English word association responses of Dutch[L1]-English bilinguals (collected by van Hell and de Groot, 1998) compared to English monolingual word association norms.", "labels": [], "entities": []}, {"text": "After demonstrating a quantifiable difference between them, we then present the first computational model of bilingual word associations, which we use to investigate how the structure and processing of the bilingual lexicon could lead to the observed differences.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the test task, the model receives a set of cue words and generates multiple responses to each cue.", "labels": [], "entities": []}, {"text": "Only English nodes can serve as responses, and their probabilities are normalized to sum to 1.", "labels": [], "entities": []}, {"text": "The model responses are compared to human data using the measures defined in Section 3.1.", "labels": [], "entities": []}, {"text": "Our main goal is to test which types of edges systematically contribute to predicting bilinguals' (non-native) free word associations, and which do not.", "labels": [], "entities": [{"text": "predicting bilinguals' (non-native) free word associations", "start_pos": 75, "end_pos": 133, "type": "TASK", "confidence": 0.8700589239597321}]}, {"text": "We have six parameters of the model related to edge weights (\u03ba weights for the six types of edges) and a relatively low number of test items (58 cue words).", "labels": [], "entities": []}, {"text": "To prevent overfitting, we perform: Distances between model and human responses (averaged per cue word and per iteration).", "labels": [], "entities": []}, {"text": "Best performance for each measure is in bold.", "labels": [], "entities": []}, {"text": "score cross-validation on our data set, initially fitting only some of the \u03ba parameters.", "labels": [], "entities": []}, {"text": "Specifically, we first determine the best weights for the word association edges (\u03ba DA and \u03ba EA , which are essential for the task) and for the cross-language edges (\u03ba TE and \u03ba CG , which ensure that activation can pass from English to Dutch and back).", "labels": [], "entities": [{"text": "EA", "start_pos": 93, "end_pos": 95, "type": "METRIC", "confidence": 0.94559246301651}]}, {"text": "We later test whether adding other edge types (SY and OR) improves the model.", "labels": [], "entities": [{"text": "OR", "start_pos": 54, "end_pos": 56, "type": "METRIC", "confidence": 0.9739442467689514}]}, {"text": "For cross-validation, we use the Monte-Carlo method with 10, 000 iterations: in each iteration, the 58 cue words are randomly split into 48 training items and 10 test items.", "labels": [], "entities": []}, {"text": "For each training subsample, we consider values {0, 1, 5, 10, 20, 25} for each edge weight (\u03ba DA , \u03ba EA , \u03ba TE , \u03ba CG ), run a grid search to find the best combination, and choose the four combinations (one per evaluation measure) which minimize the distance between the human and the model responses.", "labels": [], "entities": []}, {"text": "These combinations are then evaluated on the respective test sub-sample.", "labels": [], "entities": []}, {"text": "provides average cross-validation scores for the two baselines and the two models.", "labels": [], "entities": []}, {"text": "Recall that our scores are distances from human data, so lower values are better.", "labels": [], "entities": []}, {"text": "We see that BASE-AN is a stronger baseline than BASE-SA.", "labels": [], "entities": [{"text": "BASE-AN", "start_pos": 12, "end_pos": 19, "type": "METRIC", "confidence": 0.9225211143493652}, {"text": "BASE-SA", "start_pos": 48, "end_pos": 55, "type": "METRIC", "confidence": 0.7020379304885864}]}, {"text": "The UCS model shows little to no improvement over the baselines, and we only consider the CS model henceforth.", "labels": [], "entities": [{"text": "UCS", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.7237730026245117}]}, {"text": "The CS model shows a noticeable improvement over the stronger BASE-AN baseline, of 0.03-0.04 in terms of absolute distances, an improvement of 5%-6%.", "labels": [], "entities": [{"text": "BASE-AN baseline", "start_pos": 62, "end_pos": 78, "type": "DATASET", "confidence": 0.7543478906154633}]}], "tableCaptions": [{"text": " Table 1: Distances between model and human re- sponses (averaged per cue word and per iteration).  Best performance for each measure is in bold.", "labels": [], "entities": []}, {"text": " Table 2: Cue words for which the absolute differ- ence between CS and BASE-AN is higher than 0.25  on at least one measure.", "labels": [], "entities": [{"text": "absolute differ- ence", "start_pos": 34, "end_pos": 55, "type": "METRIC", "confidence": 0.8240868449211121}, {"text": "BASE-AN", "start_pos": 71, "end_pos": 78, "type": "METRIC", "confidence": 0.8990111351013184}]}]}