{"title": [{"text": "Firearms and Tigers are Dangerous, Kitchen Knives and Zebras are Not: Testing whether Word Embeddings Can Tell", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents an approach for investigating the nature of semantic information captured byword embeddings.", "labels": [], "entities": []}, {"text": "We propose a method that extends an existing human-elicited semantic property dataset with gold negative examples using crowd judgments.", "labels": [], "entities": []}, {"text": "Our experimental approach tests the ability of supervised classifiers to identify semantic features in word embedding vectors and compares this to a feature-identification method based on full vector cosine similarity.", "labels": [], "entities": []}, {"text": "The idea behind this method is that properties identified by classifiers, but not through full vector comparison are captured by embeddings.", "labels": [], "entities": []}, {"text": "Properties that cannot be identified by either method are not.", "labels": [], "entities": []}, {"text": "Our results provide an initial indication that semantic properties relevant for the way entities interact (e.g. dangerous) are captured, while perceptual information (e.g. colors) is not represented.", "labels": [], "entities": []}, {"text": "We conclude that, though preliminary, these results show that our method is suitable for identifying which properties are captured by embeddings.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word embeddings are widely used in NLP and have been shown to boost performance in a large selection of tasks ranging from morphological analysis to sentiment analysis (; Zhou and Xu, 2015, among many others).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 149, "end_pos": 167, "type": "TASK", "confidence": 0.9165839850902557}]}, {"text": "Despite a number of different approaches to evaluation, our understanding of what type of information is represented by the vectors remains limited.", "labels": [], "entities": []}, {"text": "Most approaches focus on full-vector comparison which treat vectors as points in a space, which are evaluated by performance on semantic similarity or relatedness test sets and analogy questions (.", "labels": [], "entities": []}, {"text": "Previous work, however, has shown that high performance does not necessarily mean that vectors actually contain the information required to solve the task (.", "labels": [], "entities": []}, {"text": "Better understanding of the kind of semantic information captured byword embeddings can increase our understanding of how they help improve downstream tasks.", "labels": [], "entities": []}, {"text": "In general, understanding what information is present in (often prominent) input embeddings forms an essential component of gaining deeper understanding of the nature of information and manner in which it travels through the hidden layers of a neural network.", "labels": [], "entities": []}, {"text": "In this paper, we propose a method that investigates what kind of semantic information is encoded in vectors using a human-elicited dataset of semantic properties.", "labels": [], "entities": []}, {"text": "We compare the output of supervised classifiers to an approach based on full-vector comparison that cannot access individual dimensions.", "labels": [], "entities": []}, {"text": "The assumptions behind this approach are that (1) both full-vector comparison and the supervised classifier will perform well on identifying semantic properties that correlate highly with general similarity; (2) the classifier will outperform full-vector analysis on properties that are reflected by the context, but shared among a diverse set of entities and (3) that neither approach will perform well on properties that are not represented directly or indirectly in the text.", "labels": [], "entities": []}, {"text": "The last two outcomes can indicate whether a semantic property is encoded in embeddings (2) or not (3).", "labels": [], "entities": []}, {"text": "The main contribution of this paper lies in the new method and corpus it proposes.", "labels": [], "entities": []}, {"text": "To our knowledge, this is the first approach that aims at identifying whether specific semantic properties are captured by individual dimensions or complex patterns in the vector.", "labels": [], "entities": []}, {"text": "In addition, we provide specific hypotheses as to which properties are captured well by which method and test them using our approach.", "labels": [], "entities": []}, {"text": "Our general hypothesis states that se-mantic properties that are relevant for the way entities interact with the world are well represented (e.g. functions of objects, activities entities are frequently involved in), whereas properties of relatively little consequence for the way entities interact with the world are not (e.g. perceptual properties such as shapes and colors, which either have no function or highly diverse functions).", "labels": [], "entities": []}, {"text": "Though preliminary due to the complexity of the task, results indicate that these tendencies hold.", "labels": [], "entities": []}, {"text": "Moreover, the overall outcome shows that the method and data are complementary to existing intrinsic evaluation methods.", "labels": [], "entities": []}, {"text": "The rest of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "We discuss related work in Section 2.", "labels": [], "entities": []}, {"text": "Our method is outlined in Section 3.", "labels": [], "entities": []}, {"text": "Section 4 presents our experiments and results.", "labels": [], "entities": []}, {"text": "We finish with a critical discussion and overview of future work in Section 5.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Hypotheses about whether selected semantic  properties can be learned by a supervised classifier", "labels": [], "entities": []}, {"text": " Table 2: Performance of different approaches in rela- tion to the average cosine similarity of words associ- ated with a property (cos). The last row shows the  Spearman Rank correlation between f1-scores and av- erage cosine similarity. Property types are listed un- der type (p = part, vp = visual-perceptual, op = other- perceptual, e = encyclopaedic, f = functional, t = taxo- nomic).", "labels": [], "entities": [{"text": "rela- tion", "start_pos": 49, "end_pos": 59, "type": "TASK", "confidence": 0.6758718093236288}]}, {"text": " Table 3: Class distribution in dataset consisting of the  clean datasets derived from the CSLB set and the ad- ditional crowd judgments (marked full ). For some  properties, we included the dataset consisting of crowd- judgments only, as it is more balanced across seman- tic categories than the full set (marked crowd ). For  all properties, a leave-one-out approach was applied to  evaluation except for is animal and is food.", "labels": [], "entities": [{"text": "CSLB set", "start_pos": 91, "end_pos": 99, "type": "DATASET", "confidence": 0.9296571910381317}]}, {"text": " Table 4: F1 scores achieved by logistic regression (lr)  two runs of a neural net classifier (net1 and net2 and the  n-best nearest neighbors evaluated with leave-one-out  on the full datasets (marked as full and the crow-only  sets (marked as crowd ).", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9992678761482239}]}]}