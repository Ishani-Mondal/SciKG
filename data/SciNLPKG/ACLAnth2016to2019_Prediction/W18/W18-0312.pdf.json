{"title": [{"text": "Conditions on abruptness in a gradient-ascent Maximum Entropy learner *", "labels": [], "entities": []}], "abstractContent": [{"text": "When does a gradual learning rule translate into gradual learning performance?", "labels": [], "entities": []}, {"text": "This paper studies a gradient-ascent Maximum En-tropy phonotactic learner, as applied to two-alternative forced-choice performance expressed as log-odds.", "labels": [], "entities": []}, {"text": "The main result is that slow initial performance cannot accelerate later if the initial weights are near zero, but can if they are not.", "labels": [], "entities": []}, {"text": "Stated another way, abrupt-ness in this learner is an effect of transfer, either from Universal Grammar in the form of an initial weighting, or from previous learning in the form of an acquired weighting.", "labels": [], "entities": []}], "introductionContent": [{"text": "An important class of constraint-based phonological learning models responds to training by making small changes in the weight or rank of constraints (reviewed in Jarosz 2016).", "labels": [], "entities": []}, {"text": "The gradualness of the learning rule seems to suggest that performance ought to change gradually as well, resembling the first rather than the second panel in.", "labels": [], "entities": []}, {"text": "In work on non-linguistic pattern learning, abrupt improvement has been cited as diagnostic of an explicit, \"rule-based\" learning algorithm which serially tests hypotheses, as opposed to a \"cue-based\" one which slowly learns association weights ().", "labels": [], "entities": [{"text": "non-linguistic pattern learning", "start_pos": 11, "end_pos": 42, "type": "TASK", "confidence": 0.6918243765830994}]}, {"text": "Abruptness gradient ascent on log-likelihood, no prior, and no restrictions on weights, and that makes twoalternative forced-choice (2AFC) decisions using the Luce choice rule.", "labels": [], "entities": []}, {"text": "Gradient ascent Max-Ent is of interest not only in its own right, but because of its close relation to the Gradual Learning Algorithms for Stochastic Optimality Theory, Harmonic Grammar and Noisy Harmonic Grammar, and models of non-linguistic learning such as the Perceptron (.", "labels": [], "entities": []}, {"text": "The results can be summarized as follows: Regardless of what the constraints actually are, if the initial weights are exactly zero then -provided that the training and test distributions are chosen in a particular way -2AFC performance improves fastest at the outset of learning, making abrupt learning impossible.", "labels": [], "entities": []}, {"text": "Even if, instead, the initial weights are only near zero, the 2AFC learning curve tracks that of a learner whose initial weights are exactly zero, in that the two learners' trajectories in weight space steadily converge, and the closer they are in weight space, the more similar their 2AFC performance is.", "labels": [], "entities": []}, {"text": "An example is given to show that large non-zero initial weights can, but need not, lead to abrupt 2AFC performance.", "labels": [], "entities": []}], "datasetContent": [{"text": "The universe of candidates is a finite set X = {x 1 , . .", "labels": [], "entities": []}, {"text": ", x n }, known to the experimenter.", "labels": [], "entities": []}, {"text": "The model uses an unobservable set of constraints c 1 , . .", "labels": [], "entities": []}, {"text": ", cm and an unobservable weight vector w = (w 1 , . .", "labels": [], "entities": []}, {"text": ", w m ) to assign unobservable probabilities p = (p 1 , . .", "labels": [], "entities": []}, {"text": ", p n ) to the candidate.", "labels": [], "entities": []}, {"text": "The testis assumed not to change the state of the model.", "labels": [], "entities": []}, {"text": "At the beginning of the experiment, the experimenter chooses two probability distributions r + and r \u2212 . On each test trial, one candidate is sampled from X with probabilities given by r + , and the other is sampled from X with probabilities given by r \u2212 . The experimenter can also train the model by giving it a candidate xi as an example of a legal word.", "labels": [], "entities": []}, {"text": "Instead of training on individual candidates (stochastic gradient ascent), we instead run the learner in batch mode (gradient ascent); i.e., instead of a candidate on each trial, the learner receives a distribution p + , where p + i corresponds to the probability of presenting xi on a stochastic gradient ascent training trial.", "labels": [], "entities": [{"text": "stochastic gradient ascent", "start_pos": 46, "end_pos": 72, "type": "TASK", "confidence": 0.6639339526494344}]}, {"text": "The model updates its weights according to the following rule: This the Maximum Entropy gradient-ascent update rule, as described by.", "labels": [], "entities": [{"text": "Entropy gradient-ascent update", "start_pos": 80, "end_pos": 110, "type": "METRIC", "confidence": 0.8695323864618937}]}, {"text": "Its contribution to the update is independent of p \u2212 , the probabilities of the negative training candidates; i.e., the learner does \"unsupervised\" learning.", "labels": [], "entities": []}, {"text": "Below a continuous approximation to this discrete update rule is used, substituting dw i /dt for \u2206w i . The learning rate parameter \u03b7 is omitted by setting it to 1; i.e., the training-time unit is defined to be how long it takes a constraint to change its weight by one weight unit when E emp [c i ] \u2212 E w [c i ] = 1.", "labels": [], "entities": [{"text": "learning rate parameter \u03b7", "start_pos": 108, "end_pos": 133, "type": "METRIC", "confidence": 0.8153990060091019}]}, {"text": "The step size in weight space is thus fixed, rather than decreasing on a preset schedule) or adaptively (Boyd and Vandenberghe, 1999, Section 5.2.1).", "labels": [], "entities": []}, {"text": "In this paper, \"abrupt\" is used to mean that performance improves slowly at the outset of the experiment, then accelerates later (e.g., a sigmoid).", "labels": [], "entities": [{"text": "abrupt", "start_pos": 16, "end_pos": 22, "type": "METRIC", "confidence": 0.9613706469535828}]}, {"text": "Performance is expressed here as log-odds rather than proportion correct because (A) log-odds is more transparently related both to the learning model and to the statistical models fit to experimental results, and (B) proportion correct acts as a squashing function, reducing the visible influence of changing large weights and thus exaggerating the effect whose existence we are arguing for on other grounds.", "labels": [], "entities": []}], "tableCaptions": []}