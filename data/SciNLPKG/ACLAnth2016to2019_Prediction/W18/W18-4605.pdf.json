{"title": [{"text": "Uniform Information Density Effects on Syntactic Choice in Hindi", "labels": [], "entities": [{"text": "Uniform Information Density", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6559426089127859}, {"text": "Syntactic Choice", "start_pos": 39, "end_pos": 55, "type": "TASK", "confidence": 0.9154659509658813}]}], "abstractContent": [{"text": "According to the UNIFORM INFORMATION DENSITY (UID) hypothesis (Levy and Jaeger, 2007; Jaeger, 2010), speakers tend to distribute information density across the signal uniformly while producing language.", "labels": [], "entities": []}, {"text": "The prior works cited above studied syntactic reduction in language production at particular choice points in a sentence.", "labels": [], "entities": [{"text": "syntactic reduction", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.757521003484726}]}, {"text": "In contrast, we use a variant of the above UID hypothesis in order to investigate the extent to which word order choices in Hindi are influenced by the drive to minimize the variance of information across entire sentences.", "labels": [], "entities": []}, {"text": "To this end, we propose multiple lexical and syntactic measures (at both word and constituent levels) to capture the uniform spread of information across a sentence.", "labels": [], "entities": []}, {"text": "Subsequently, we incorporate these measures in machine learning models aimed to distinguish between a naturally occurring corpus sentence and its grammatical variants (expressing the same idea).", "labels": [], "entities": []}, {"text": "Our results indicate that our UID measures are not a significant factor in predicting the corpus sentence in the presence of lexical surprisal, a competing control predictor.", "labels": [], "entities": []}, {"text": "Finally, in the light of other recent works, we conclude with a discussion of reasons for UID not being suitable fora theory of word order.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Uniform Information Density (henceforth UID) hypothesis states that language production exhibits a preference for distributing information uniformly across a linguistic signal.", "labels": [], "entities": [{"text": "Uniform Information Density (henceforth UID)", "start_pos": 4, "end_pos": 48, "type": "TASK", "confidence": 0.7124594151973724}]}, {"text": "This hypothesis has along history in the literature and Ferrer-i- traces the idea to the pioneering work of) and developed further in subsequent articles, for an overview).", "labels": [], "entities": []}, {"text": "In recent years, this hypothesis has gained substantial traction with the work on syntactic reduction done by Florian Jaeger and colleagues.", "labels": [], "entities": [{"text": "syntactic reduction", "start_pos": 82, "end_pos": 101, "type": "TASK", "confidence": 0.8578859865665436}]}, {"text": "They show that speakers achieve uniformity of information across utterances either by omitting optional function words (like the that complementizer) or by explicitly mentioning them.", "labels": [], "entities": []}, {"text": "In contrast to the two prior works cited above, which look at information density at particular choice points in language production, we examine a variant of the UID hypothesis stated above in the case of entire sentences created by syntactic alternations.", "labels": [], "entities": []}, {"text": "In this work, we test the hypothesis that reference sentences obtained from a corpus of naturally occurring written text exhibit greater uniformity in the spread of information in comparison to grammatical variants expressing the same idea.", "labels": [], "entities": []}, {"text": "To this end, inspired from Collins (2014), we propose five distinct UID measures quantifying the uniformity of information density at both syntactic and lexical levels.", "labels": [], "entities": []}, {"text": "We test two different versions of these measures at word as well as constituent boundaries.", "labels": [], "entities": []}, {"text": "We examine the impact our UID measures in predicting syntactic choice in Hindi, an Indo-Aryan language with predominantly SOV word order and case-marking postpositions.", "labels": [], "entities": [{"text": "predicting syntactic choice", "start_pos": 42, "end_pos": 69, "type": "TASK", "confidence": 0.8068331281344095}]}, {"text": "This is the first work on the Hindi language (to the best of our knowledge), which studies its information-theoretic properties pertaining to syntac-tic choice.", "labels": [], "entities": []}, {"text": "In comparison to English (SVO order and prepositions), Hindi has relatively flexible word order).", "labels": [], "entities": []}, {"text": "Our study uses written data from the Hindi-Urdu Treebank (HUTB) corpus) consisting of newswire text.", "labels": [], "entities": [{"text": "Hindi-Urdu Treebank (HUTB) corpus", "start_pos": 37, "end_pos": 70, "type": "DATASET", "confidence": 0.8874580959479014}]}, {"text": "Hence the sentences used in our study are by default set in a given context.", "labels": [], "entities": []}, {"text": "In addition to production ease, the language production system also factors in communicative considerations pertaining to facilitating comprehension for listeners (i.e. audience design) and for the speakers themselves (Jaeger and Buz, in press).", "labels": [], "entities": []}, {"text": "Moreover, written text is often edited, taking into account comprehensibility considerations explicitly . From the perspective of online language comprehension, processing difficulty is quantified by surprisal.", "labels": [], "entities": []}, {"text": "We examine whether the UID measures we defined are significant predictors of syntactic choice even amidst lexical and syntactic surprisal as control factors (modelling comprehension considerations).", "labels": [], "entities": []}, {"text": "Our experiments primarily involved the task of classifying Hindi data into reference sentences and artificial generated variants created by linearizing dependency trees corresponding to reference sentences in the HUTB corpus.", "labels": [], "entities": [{"text": "HUTB corpus", "start_pos": 213, "end_pos": 224, "type": "DATASET", "confidence": 0.9002896845340729}]}, {"text": "Our UID measures were deployed as features in machine learning models to perform this binary classification task.", "labels": [], "entities": [{"text": "binary classification task", "start_pos": 86, "end_pos": 112, "type": "TASK", "confidence": 0.7304482460021973}]}, {"text": "Our results indicate that logistic regression models containing lexical surprisal along with our lexical and syntactic UID measures (across words as well as constituents) do not significantly outperform a strong baseline model containing only lexical surprisal (estimated using a simple trigram model over words).", "labels": [], "entities": []}, {"text": "Weak effects of both lexical and syntactic UID measures are attested in some non-canonical word order sequences involving object fronting.", "labels": [], "entities": [{"text": "object fronting", "start_pos": 122, "end_pos": 137, "type": "TASK", "confidence": 0.7214887142181396}]}, {"text": "However, these are not in the expected direction i.e., corpus sentences are characterized by spikes and troughs in information across words compared to their artificially generated variants.", "labels": [], "entities": []}, {"text": "This result is very similar to that reported in the work of, where the authors showed that object-first orders are in conflict with their formulation of the UID hypothesis.", "labels": [], "entities": []}, {"text": "Using a corpus study as well as results from judgement tasks, they show that such orders cause troughs in the signal compared to other orders because of the disproportionate amount of information clustered around the object, making subsequent elements of the sentence redundant.", "labels": [], "entities": []}, {"text": "They also point out the failure of their version of the UID hypothesis in the case of SOV languages.", "labels": [], "entities": []}, {"text": "They attribute it to the presence of other stronger factors in such languages.", "labels": [], "entities": []}, {"text": "On a related note, Ferrer-i-Cancho (2017) discuss how predicting the final verb is a stronger processing pressure in verb-final languages compared to other competing principles like dependency length minimization.", "labels": [], "entities": [{"text": "predicting the final verb", "start_pos": 54, "end_pos": 79, "type": "TASK", "confidence": 0.8692979216575623}, {"text": "dependency length minimization", "start_pos": 182, "end_pos": 212, "type": "TASK", "confidence": 0.6968783736228943}]}, {"text": "Our result demonstrating lexical surprisal as a robust predictor of Hindi syntactic choice, adds support to predictability as a strong determinant of syntactic choice.", "labels": [], "entities": [{"text": "Hindi syntactic choice", "start_pos": 68, "end_pos": 90, "type": "TASK", "confidence": 0.6668505469957987}]}, {"text": "Thus we conclude that the UID hypothesis (as defined by our measures) does not shape word order choices in Hindi when other control factors like predictability are considered.", "labels": [], "entities": []}, {"text": "We discuss possible reasons for this by alluding to the work of.", "labels": [], "entities": []}, {"text": "This recent work suggests that UID might not be appropriate fora theory of word order of languages and UID might be restricted to account for syntactic reduction phenomena only.", "labels": [], "entities": [{"text": "UID", "start_pos": 103, "end_pos": 106, "type": "METRIC", "confidence": 0.7922746539115906}, {"text": "syntactic reduction", "start_pos": 142, "end_pos": 161, "type": "TASK", "confidence": 0.7531203627586365}]}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 offers a brief background on the UID hypothesis and surprisal.", "labels": [], "entities": [{"text": "UID", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.957086443901062}]}, {"text": "Section 3 describes the UID measures we proposed as part of this work.", "labels": [], "entities": [{"text": "UID", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.7731795907020569}]}, {"text": "Section 4 provides details of the datasets and models we used for testing our hypotheses.", "labels": [], "entities": []}, {"text": "Section 5 presents the experiments conducted as part of the study and Section 6 discusses the implications of the results obtained fora theory of word order.", "labels": [], "entities": [{"text": "word order", "start_pos": 146, "end_pos": 156, "type": "TASK", "confidence": 0.709527462720871}]}, {"text": "Finally, Section 7 summarizes the conclusions as well as reflects on possible directions of future inquiry.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe our experiments quantifying the impact of the UID measures (proposed in Section 3) on word order choice.", "labels": [], "entities": [{"text": "word order choice", "start_pos": 115, "end_pos": 132, "type": "TASK", "confidence": 0.7356616059939066}]}], "tableCaptions": [{"text": " Table 1: Classification performance of various word and constituent-based UID measures", "labels": [], "entities": []}, {"text": " Table 2: Pearson correlation coefficient between: 1. Lexical surprisal and lexical UID measures (Row 1)  2. Syntactic surprisal and syntactic UID measures (Row 2)", "labels": [], "entities": [{"text": "Pearson correlation coefficient", "start_pos": 10, "end_pos": 41, "type": "METRIC", "confidence": 0.9094266692797343}]}, {"text": " Table 3: UID and non-canonical word order choices ('+' stands for 'Lexical surprisal +')", "labels": [], "entities": []}]}