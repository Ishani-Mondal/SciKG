{"title": [{"text": "Talking about other people: an endless range of possibilities", "labels": [], "entities": []}], "abstractContent": [{"text": "Image description datasets, such as Flickr30K and MS COCO, show a high degree of variation in the ways that crowd-workers talk about the world.", "labels": [], "entities": [{"text": "Flickr30K", "start_pos": 36, "end_pos": 45, "type": "DATASET", "confidence": 0.9545072913169861}, {"text": "MS COCO", "start_pos": 50, "end_pos": 57, "type": "DATASET", "confidence": 0.8655264973640442}]}, {"text": "Although this gives us a rich and diverse collection of data to work with, it also introduces uncertainty about how the world should be described.", "labels": [], "entities": []}, {"text": "This paper shows the extent of this uncertainty in the PEOPLE domain.", "labels": [], "entities": [{"text": "PEOPLE domain", "start_pos": 55, "end_pos": 68, "type": "DATASET", "confidence": 0.7323265969753265}]}, {"text": "We present a taxonomy of different ways to talk about other people.", "labels": [], "entities": []}, {"text": "This taxonomy serves as a reference point to think about how other people should be described, and can be used to classify and compute statistics about labels applied to people.", "labels": [], "entities": []}], "introductionContent": [{"text": "There are currently two major data sets used to train and evaluate automatic description systems: Flickr30K and MS COCO ().", "labels": [], "entities": [{"text": "Flickr30K", "start_pos": 98, "end_pos": 107, "type": "DATASET", "confidence": 0.8053708076477051}, {"text": "MS COCO", "start_pos": 112, "end_pos": 119, "type": "DATASET", "confidence": 0.6874569654464722}]}, {"text": "Both of these data sets contain images with multiple crowd-sourced descriptions per image.", "labels": [], "entities": []}, {"text": "These datasets are typically used to train data-driven natural language generation systems to automatically learn to associate visual features with natural language descriptions (.", "labels": [], "entities": []}, {"text": "Following the training phase, image description systems are evaluated by comparing their output with human generated descriptions for the same image (using textual similarity metrics like BLEU or METEOR,).", "labels": [], "entities": [{"text": "image description", "start_pos": 30, "end_pos": 47, "type": "TASK", "confidence": 0.7185891568660736}, {"text": "BLEU", "start_pos": 188, "end_pos": 192, "type": "METRIC", "confidence": 0.9969915151596069}, {"text": "METEOR", "start_pos": 196, "end_pos": 202, "type": "METRIC", "confidence": 0.8775706887245178}]}, {"text": "The standard for what the image descriptions should look like is implicit in the corpus.", "labels": [], "entities": []}, {"text": "The only point at which any explicit guidelines are provided is during the crowd-sourcing task, where annotators are given general instructions about what their description should look like.", "labels": [], "entities": []}, {"text": "Here are the Flickr30K instructions (the MS COCO instructions are similar): 1.", "labels": [], "entities": [{"text": "Flickr30K", "start_pos": 13, "end_pos": 22, "type": "DATASET", "confidence": 0.6799830794334412}, {"text": "MS COCO instructions", "start_pos": 41, "end_pos": 61, "type": "DATASET", "confidence": 0.9114339351654053}]}, {"text": "Describe the image in one complete but simple sentence.", "labels": [], "entities": []}, {"text": "2. Provide an explicit description of prominent entities.", "labels": [], "entities": []}, {"text": "3. Do not make unfounded assumptions about what is occurring.", "labels": [], "entities": []}, {"text": "4. Only talk about entities that appear in the image.", "labels": [], "entities": []}, {"text": "5. Provide an accurate description of the activities, people, animals and objects you see depicted in the image.", "labels": [], "entities": []}, {"text": "6. Each description must be a single sentence under 100 characters.", "labels": [], "entities": []}, {"text": "(, edited for brevity) These guidelines leave much of the task open for interpretation by the annotator.", "labels": [], "entities": []}, {"text": "For example, it is unclear how the descriptions will be used, or what the target audience is (as pointed out by van).", "labels": [], "entities": []}, {"text": "Thus, the underspecified nature of the task invites variation and creativity.", "labels": [], "entities": []}, {"text": "It is important for us to understand the extent of this variation because image description corpora currently set the standard for what an image description should look like.", "labels": [], "entities": []}, {"text": "Earlier work has looked at stereotyping behavior, reporting bias, and the use of negations in image descriptions, and recently Van provided an overview of measures to quantify diversity.", "labels": [], "entities": []}, {"text": "This paper looks at the variation in the labels used to refer to other people, and presents a taxonomy (based on the Flickr30K dataset) that shows the range of properties that crowd-workers consider in the description process.", "labels": [], "entities": [{"text": "Flickr30K dataset", "start_pos": 117, "end_pos": 134, "type": "DATASET", "confidence": 0.9783578515052795}]}, {"text": "This taxonomy ranges from physical attributes, such as hair color, to attributes concerning socio-economic status (e.g. unemployed).", "labels": [], "entities": []}, {"text": "After discussing related work ( \u00a72), we present our method to select person-labels and to categorize (partial) labels into semantic categories ( \u00a73).", "labels": [], "entities": []}, {"text": "Following this, Section 4 shows the resulting taxonomy, with examples from the Flickr30K dataset.", "labels": [], "entities": [{"text": "Flickr30K dataset", "start_pos": 79, "end_pos": 96, "type": "DATASET", "confidence": 0.9896593391895294}]}, {"text": "Section 5 discusses our taxonomy in light of the recently published Face2Text dataset (, and considers the reliability of perceived attributes.", "labels": [], "entities": [{"text": "Face2Text dataset", "start_pos": 68, "end_pos": 85, "type": "DATASET", "confidence": 0.9589429795742035}]}, {"text": "We believe these contributions will be useful for practitioners interested in the generation of person-descriptions.", "labels": [], "entities": [{"text": "generation of person-descriptions", "start_pos": 82, "end_pos": 115, "type": "TASK", "confidence": 0.8588975071907043}]}, {"text": "Our code and data is publicly available online.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}