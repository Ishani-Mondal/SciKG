{"title": [{"text": "Explainable Autonomy: A Study of Explanation Styles for Building Clear Mental Models", "labels": [], "entities": []}], "abstractContent": [{"text": "As unmanned vehicles become more autonomous , it is important to maintain a high level of transparency regarding their behaviour and how they operate.", "labels": [], "entities": []}, {"text": "This is particularly important in remote locations where they cannot be directly observed.", "labels": [], "entities": []}, {"text": "Here, we describe a method for generating explanations in natural language of autonomous system behaviour and reasoning.", "labels": [], "entities": []}, {"text": "Our method involves deriving an interpretable model of autonomy through having an expert 'speak aloud' and providing various levels of detail based on this model.", "labels": [], "entities": []}, {"text": "Through an online evaluation study with operators, we show it is best to generate explanations with multiple possible reasons but tersely worded.", "labels": [], "entities": []}, {"text": "This work has implications for designing interfaces for autonomy as well as for explainable AI and operator training.", "labels": [], "entities": []}], "introductionContent": [{"text": "Robots and autonomous systems are increasingly being operated remotely in hazardous environments such as in the nuclear or energy sector domains (.", "labels": [], "entities": []}, {"text": "Typically, these remote robots instil less trust than those co-located (.", "labels": [], "entities": []}, {"text": "Thus, the interface between the operator and autonomous systems is key to maintaining situation awareness and understanding between the system and the human operator ( . It is this aspect of understanding that we examine herewith respect to aligning the operator's mental model, in terms of both what the system can do and why it is doing certain behaviours.", "labels": [], "entities": []}, {"text": "We propose that this type of explainability will increase trust and therefore adoption of remote autonomous systems.", "labels": [], "entities": []}, {"text": "According to, varying the natural language generation of explanations in terms of verbosity (i.e. how many reasons to give or completeness) and the level of detail (soundness) changes the effectiveness of the explanations in terms of improving the user's mental model.", "labels": [], "entities": []}, {"text": "It also affects whether the user thinks that it was \"worth it\" to read the explanation.", "labels": [], "entities": []}, {"text": "It is these aspects of explanation generation that we explore here.", "labels": [], "entities": [{"text": "explanation generation", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.9028140008449554}]}, {"text": "We focus on the natural language generation of explanations as apart of an interactive multimodal system called MIRIAM for situation awareness for autonomous underwater vehicles (AUVs).", "labels": [], "entities": [{"text": "natural language generation of explanations", "start_pos": 16, "end_pos": 59, "type": "TASK", "confidence": 0.7987428784370423}, {"text": "MIRIAM", "start_pos": 112, "end_pos": 118, "type": "METRIC", "confidence": 0.8964048624038696}, {"text": "situation awareness", "start_pos": 123, "end_pos": 142, "type": "TASK", "confidence": 0.7042237520217896}]}, {"text": "This interface was developed in conjunction with industry partner SeeByte Ltd (see) and runs alongside their commercial UI called SeeTrack with a chat interface, which gives status and mission updates.", "labels": [], "entities": [{"text": "SeeByte Ltd", "start_pos": 66, "end_pos": 77, "type": "DATASET", "confidence": 0.9713413715362549}, {"text": "SeeTrack", "start_pos": 130, "end_pos": 138, "type": "DATASET", "confidence": 0.9708705544471741}]}, {"text": "This multimodal interface has been shown to increase situation awareness () both by using chat and graphical interface over just graphical interface alone.", "labels": [], "entities": [{"text": "situation awareness", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.7713460922241211}]}, {"text": "We describe a method of explanation generation that is agnostic to the type of autonomy or vehicle.", "labels": [], "entities": [{"text": "explanation generation", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.7440005242824554}]}, {"text": "Our contribution is through the 'speak-aloud' method for deriving a model of autonomy for explanations and through the analysis of the forms that these explanations would take to maximally improve the user's mental model.", "labels": [], "entities": []}, {"text": "The findings reported here can be used as heuristics for explaining behaviour of remote autonomous systems but also face-to-face robotics () and other explainable AI tasks such as explaining recommendations ().", "labels": [], "entities": []}, {"text": "Finally, they could be used to improve operator training.", "labels": [], "entities": [{"text": "operator training", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.8851752579212189}]}], "datasetContent": [{"text": "The experiment was a between-subjects experiment with three conditions, examples of which are given in.", "labels": [], "entities": []}, {"text": "C1(HiSoundHiComp): High Soundness, High Completeness -multiple explanations, each explaining all of the autonomy model in detail; 2.", "labels": [], "entities": []}, {"text": "C2(HiSoundLoComp): High Soundness, Low Completeness -one detailed explanation that explains all of the autonomy model; 3.", "labels": [], "entities": [{"text": "Completeness", "start_pos": 39, "end_pos": 51, "type": "METRIC", "confidence": 0.7808229327201843}]}, {"text": "C3(LoSoundHiComp): Low Soundness, High Completeness -multiple explanations each explaining just the top layer of the autonomy model.", "labels": [], "entities": []}, {"text": "The experiment consisted of an on-line questionnaire with a pre-questionnaire to gather demographic data and two questions regarding the subjects' pre-existing mental model with regards AUVs: \"I have a good understanding of how AUVs work\" (Pre-MM-Q1) and \"I have a good understanding of what AUVs can do\" (Pre-MM-Q2).", "labels": [], "entities": []}, {"text": "We were initially looking to investigate trust and so the users were asked to fill out a propensity to trust questionnaire.", "labels": [], "entities": []}, {"text": "After the pre-questionnaire, the participants watched 3 scenario videos.", "labels": [], "entities": []}, {"text": "After each video, they answered 4 questions regarding the quality of the explanations (US-Q1-4).", "labels": [], "entities": []}, {"text": "These questions were modified from the PARADISE-style questionnaire () for interactive systems and summed to create a User Satisfaction score.", "labels": [], "entities": []}, {"text": "In addition, the participants were asked one question on whether the explanations were \"worth it\" and two questions on their post-explanation mental model (MM-Q1/2).", "labels": [], "entities": []}, {"text": "All questions were on a Likert scale with 7 values: from strongly disagree (1) to strongly agree (7).", "labels": [], "entities": []}, {"text": "1. US-Q1: The system chat responses were easy to understand.", "labels": [], "entities": [{"text": "US-Q1", "start_pos": 3, "end_pos": 8, "type": "DATASET", "confidence": 0.9502478837966919}]}, {"text": "2. US-Q2: The system explanations were easy to understand.", "labels": [], "entities": [{"text": "US-Q2", "start_pos": 3, "end_pos": 8, "type": "DATASET", "confidence": 0.9572769999504089}]}, {"text": "3. US-Q3: The system explanations were useful.", "labels": [], "entities": [{"text": "US-Q3", "start_pos": 3, "end_pos": 8, "type": "DATASET", "confidence": 0.976599395275116}]}, {"text": "4. US-Q4: The system explanations were as expected.", "labels": [], "entities": [{"text": "US-Q4", "start_pos": 3, "end_pos": 8, "type": "DATASET", "confidence": 0.9734733700752258}]}, {"text": "5. \"Worth it\" question: It would be worth reading the explanations to understand how the system is behaving.", "labels": [], "entities": []}, {"text": "6. MM-Q1: The system explanations in this video help me to increase my understanding of how AUVs work.", "labels": [], "entities": [{"text": "MM-Q1", "start_pos": 3, "end_pos": 8, "type": "DATASET", "confidence": 0.8842964172363281}]}, {"text": "7. MM-Q2: The system explanations in this video help me to increase my understanding of what the AUVs were doing.", "labels": [], "entities": [{"text": "MM-Q2", "start_pos": 3, "end_pos": 8, "type": "DATASET", "confidence": 0.8898259401321411}]}, {"text": "The mental model questions aim to capture two different dimensions of the user's mental model: structurally so how AUVs work (MM-Q1) and functionally so what the AUVs were doing (MM-Q2).", "labels": [], "entities": [{"text": "MM-Q1", "start_pos": 126, "end_pos": 131, "type": "DATASET", "confidence": 0.8311346769332886}, {"text": "MM-Q2", "start_pos": 179, "end_pos": 184, "type": "DATASET", "confidence": 0.8617159128189087}]}, {"text": "We will also refer to the mean of these two scores as the general mental model score, MM-G.", "labels": [], "entities": []}, {"text": "After watching the 3 scenarios, a final questionnaire was administrated, which asked about trust and derived a general trust score using the Schaefer scale (Schaefer, 2013).", "labels": [], "entities": []}], "tableCaptions": []}