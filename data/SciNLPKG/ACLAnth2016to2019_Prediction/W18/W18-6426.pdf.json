{"title": [], "abstractContent": [{"text": "This paper describes the statistical machine translation systems developed at RWTH Aachen University for the German\u2192English, English\u2192Turkish and Chinese\u2192English translation tasks of the EMNLP 2018 Third Conference on Machine Translation (WMT 2018).", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 25, "end_pos": 56, "type": "TASK", "confidence": 0.6068834265073141}, {"text": "English\u2192Turkish and Chinese\u2192English translation tasks of the EMNLP 2018 Third Conference on Machine Translation (WMT 2018)", "start_pos": 125, "end_pos": 247, "type": "TASK", "confidence": 0.7098774611949921}]}, {"text": "We use ensembles of neural machine translation systems based on the Transformer architecture.", "labels": [], "entities": []}, {"text": "Our main focus is on the German\u2192English task where we scored first with respect to all automatic metrics provided by the organizers.", "labels": [], "entities": []}, {"text": "We identify data selection, fine-tuning, batch size and model dimension as important hyperpa-rameters.", "labels": [], "entities": []}, {"text": "In total we improve by 6.8% BLEU over our last year's submission and by 4.8% BLEU over the winning system of the 2017 German\u2192English task.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 28, "end_pos": 32, "type": "METRIC", "confidence": 0.9995890259742737}, {"text": "BLEU", "start_pos": 77, "end_pos": 81, "type": "METRIC", "confidence": 0.9995928406715393}]}, {"text": "In English\u2192Turkish task, we show 3.6% BLEU improvement over the last year's winning system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.999786913394928}]}, {"text": "We further report results on the Chinese\u2192English task where we improve 2.2% BLEU on average over our baseline systems but stay behind the 2018 winning systems.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 76, "end_pos": 80, "type": "METRIC", "confidence": 0.9995812773704529}]}], "introductionContent": [{"text": "In this paper we describe the supervised statistical machine translation (SMT) systems developed by RWTH Aachen University for the news translation task of the EMNLP 2018 Third Conference on Machine Translation.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 41, "end_pos": 78, "type": "TASK", "confidence": 0.7872830132643381}, {"text": "news translation task of the EMNLP 2018 Third Conference on Machine Translation", "start_pos": 131, "end_pos": 210, "type": "TASK", "confidence": 0.7903910353779793}]}, {"text": "We use ensembles of neural machine translation systems to participate in the German\u2192English, English\u2192Turkish and Chinese\u2192English tasks of the WMT 2018 evaluation campaign.", "labels": [], "entities": [{"text": "WMT 2018 evaluation campaign", "start_pos": 142, "end_pos": 170, "type": "TASK", "confidence": 0.627898134291172}]}, {"text": "For this year's WMT we switch towards the Transformer architecture ( implemented in Sockeye (.", "labels": [], "entities": [{"text": "WMT", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.6074804067611694}, {"text": "Sockeye", "start_pos": 84, "end_pos": 91, "type": "DATASET", "confidence": 0.975774884223938}]}, {"text": "We experiment with different selections from the training data and various model configurations.", "labels": [], "entities": []}, {"text": "This paper is organized as follows: In Section 2 we describe our data preprocessing.", "labels": [], "entities": []}, {"text": "Our translation software and baseline setups are explained in Section 3.", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9672799706459045}]}, {"text": "The results of the experiments for the various language pairs are summarized in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we present our results on the three tasks we participated in, with the primary focus on 2 Note that this is by now also the default behavior of the Tensor2Tensor implementation https://github.com/ tensorflow/tensor2tensor, differing from the original paper.", "labels": [], "entities": []}, {"text": "building a strong system for the German\u2192English system.", "labels": [], "entities": []}, {"text": "For evaluation we use mteval-v13a from the Moses toolkit ( and TERCom 3 to score our systems on the BLEU () respectively TER () measures.", "labels": [], "entities": [{"text": "Moses toolkit", "start_pos": 43, "end_pos": 56, "type": "DATASET", "confidence": 0.9162413477897644}, {"text": "TERCom", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.9248552322387695}, {"text": "BLEU", "start_pos": 100, "end_pos": 104, "type": "METRIC", "confidence": 0.9982176423072815}, {"text": "TER", "start_pos": 121, "end_pos": 124, "type": "METRIC", "confidence": 0.968585729598999}]}, {"text": "In addition we report CTER scores 4 (.", "labels": [], "entities": [{"text": "CTER", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.981797456741333}]}, {"text": "All reported scores are given in percentage and the specific options of the tools are set to be consistent with the calculations of the organizers.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Baseline results and analysis of data condi- tions (De\u2192En). Our baseline starts of with the stan- dard WMT 2018 training data excluding ParaCrawl  but including already backtranslated NewsCrawl 2015.  \"Filtering\" refers to filtering ParaCrawl only (50% LM  driven).", "labels": [], "entities": [{"text": "WMT 2018 training data", "start_pos": 113, "end_pos": 135, "type": "DATASET", "confidence": 0.8692762851715088}, {"text": "ParaCrawl", "start_pos": 146, "end_pos": 155, "type": "DATASET", "confidence": 0.7954673171043396}, {"text": "NewsCrawl 2015", "start_pos": 194, "end_pos": 208, "type": "DATASET", "confidence": 0.9048160016536713}, {"text": "ParaCrawl", "start_pos": 243, "end_pos": 252, "type": "DATASET", "confidence": 0.897132158279419}]}, {"text": " Table 4: Comparison with last years' submissions on  newstest2015+2017 (De\u2192En). The winning sys- tem of 2017 was submitted by UEDIN. Missing scores  are due to inconsistent calculations or unavailability.", "labels": [], "entities": [{"text": "newstest2015+2017", "start_pos": 54, "end_pos": 71, "type": "DATASET", "confidence": 0.9129772384961446}, {"text": "UEDIN", "start_pos": 127, "end_pos": 132, "type": "DATASET", "confidence": 0.9455736875534058}]}, {"text": " Table 5: English\u2192Turkish results. Row 6 is the submitted system.", "labels": [], "entities": []}, {"text": " Table 6: Results measured in BLEU [%], TER [%] and CTER [%] for Chinese\u2192English. The TER computation on  newstest2018 fails.  \u2020 indicates the submitted system which is the ensemble of 4 non-converged checkpoints  of the large Transformer.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.9991100430488586}, {"text": "TER", "start_pos": 40, "end_pos": 43, "type": "METRIC", "confidence": 0.9957054257392883}, {"text": "CTER", "start_pos": 52, "end_pos": 56, "type": "METRIC", "confidence": 0.9950548410415649}, {"text": "TER", "start_pos": 86, "end_pos": 89, "type": "METRIC", "confidence": 0.9166783690452576}]}]}