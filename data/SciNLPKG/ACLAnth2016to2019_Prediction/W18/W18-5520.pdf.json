{"title": [{"text": "Integrating Entity Linking and Evidence Ranking for Fact Extraction and Verification", "labels": [], "entities": [{"text": "Integrating Entity Linking", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7663552562395731}, {"text": "Fact Extraction and Verification", "start_pos": 52, "end_pos": 84, "type": "TASK", "confidence": 0.7792671769857407}]}], "abstractContent": [{"text": "We describe here our system and results on the FEVER shared task.", "labels": [], "entities": [{"text": "FEVER", "start_pos": 47, "end_pos": 52, "type": "METRIC", "confidence": 0.9915224313735962}]}, {"text": "We prepared a pipeline system which composes of a document selection , a sentence retrieval, and a recognizing textual entailment (RTE) components.", "labels": [], "entities": []}, {"text": "A simple entity linking approach with text match is used as the document selection component, this component identifies relevant documents fora given claim by using mentioned entities as clues.", "labels": [], "entities": [{"text": "entity linking", "start_pos": 9, "end_pos": 23, "type": "TASK", "confidence": 0.7351628839969635}]}, {"text": "The sentence retrieval component selects relevant sentences as candidate evidence from the documents based on TF-IDF.", "labels": [], "entities": [{"text": "sentence retrieval", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.7048477828502655}, {"text": "TF-IDF", "start_pos": 110, "end_pos": 116, "type": "DATASET", "confidence": 0.9018713235855103}]}, {"text": "Finally, the RTE component selects evidence sentences by ranking the sentences and classifies the claim simultaneously.", "labels": [], "entities": [{"text": "RTE", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.7902238368988037}]}, {"text": "The experimental results show that our system achieved the FEVER score of 0.4016 and outperformed the official baseline system.", "labels": [], "entities": [{"text": "FEVER score", "start_pos": 59, "end_pos": 70, "type": "METRIC", "confidence": 0.99114790558815}]}], "introductionContent": [{"text": "The increasing amounts of textual information on the Web have brought demands to develop techniques to extract and verify a fact.", "labels": [], "entities": []}, {"text": "The Fact Extraction and VERification (FEVER) task) focuses on verification of textual claims against evidence.", "labels": [], "entities": [{"text": "Fact Extraction and VERification (FEVER) task", "start_pos": 4, "end_pos": 49, "type": "TASK", "confidence": 0.676531545817852}]}, {"text": "In the FEVER shared task, a given claim is classified as SUPPORTED, REFUTED, or NOTENOUGHINFO (NEI).", "labels": [], "entities": [{"text": "FEVER", "start_pos": 7, "end_pos": 12, "type": "METRIC", "confidence": 0.7687203884124756}, {"text": "SUPPORTED", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.9016491174697876}, {"text": "REFUTED", "start_pos": 68, "end_pos": 75, "type": "METRIC", "confidence": 0.9910035133361816}, {"text": "NOTENOUGHINFO", "start_pos": 80, "end_pos": 93, "type": "METRIC", "confidence": 0.7252723574638367}]}, {"text": "Evidence to justify a given claim is required for SUPPORTED or REFUTED claims.", "labels": [], "entities": [{"text": "SUPPORTED", "start_pos": 50, "end_pos": 59, "type": "TASK", "confidence": 0.8622958660125732}, {"text": "REFUTED", "start_pos": 63, "end_pos": 70, "type": "METRIC", "confidence": 0.883683443069458}]}, {"text": "The evidence is not given and must be retrieved from Wikipedia.", "labels": [], "entities": []}, {"text": "This paper describes our participating system in the FEVER shared task.", "labels": [], "entities": [{"text": "FEVER", "start_pos": 53, "end_pos": 58, "type": "METRIC", "confidence": 0.8726624846458435}]}, {"text": "The architecture of our system is designed by following the official baseline system.", "labels": [], "entities": []}, {"text": "There are two * Authors contributed equally main differences between our system and the baseline system.", "labels": [], "entities": []}, {"text": "The first one is identifying documents that contain evidence by using text match between mentioned entities in a given claim and Wikipedia page title.", "labels": [], "entities": []}, {"text": "The details are described in Section 2.1.", "labels": [], "entities": []}, {"text": "The next one is a neural network based model, details of which are described in Section 2.3, for selecting evidence sentences as ranking task and classifying a claim simultaneously.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used official training dataset for training RTE component.", "labels": [], "entities": [{"text": "RTE", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.6288959383964539}]}, {"text": "For parameter tuning and performance evaluation, we used a development and test datasets used in (.", "labels": [], "entities": [{"text": "parameter tuning", "start_pos": 4, "end_pos": 20, "type": "TASK", "confidence": 0.7363702952861786}]}, {"text": "shows statistics of each dataset.: The number of claims in each datasets.", "labels": [], "entities": []}, {"text": "We evaluated our system and baseline system on the test dataset with FEVER score, label accuracy, evidence precision, evidence recall and evidence F1.", "labels": [], "entities": [{"text": "FEVER score", "start_pos": 69, "end_pos": 80, "type": "METRIC", "confidence": 0.982332170009613}, {"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.6508258581161499}, {"text": "precision", "start_pos": 107, "end_pos": 116, "type": "METRIC", "confidence": 0.5445788502693176}, {"text": "recall", "start_pos": 127, "end_pos": 133, "type": "METRIC", "confidence": 0.8929620385169983}, {"text": "F1", "start_pos": 147, "end_pos": 149, "type": "METRIC", "confidence": 0.5351418256759644}]}, {"text": "FEVER score is classification accuracy of claims if the correct evidence is selected.", "labels": [], "entities": [{"text": "FEVER score", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9811510741710663}, {"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9331891536712646}]}, {"text": "Label accuracy is classification accuracy of claims if the requirement for correct evidence is ignored.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 6, "end_pos": 14, "type": "METRIC", "confidence": 0.7041980028152466}, {"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.6593039631843567}]}, {"text": "shows the evaluation results on the test dataset.", "labels": [], "entities": []}, {"text": "Our system achieved FEVER score of 0.4016 and outperformed the baseline system.", "labels": [], "entities": [{"text": "FEVER score", "start_pos": 20, "end_pos": 31, "type": "METRIC", "confidence": 0.9709047675132751}]}, {"text": "As expected, our system produced a significant improvement of 59 points in evidence precision against the baseline system.", "labels": [], "entities": [{"text": "precision", "start_pos": 84, "end_pos": 93, "type": "METRIC", "confidence": 0.9684001803398132}]}, {"text": "Though evidence recall decreased, evidence F1 increased by 17 points compared to the baseline system.", "labels": [], "entities": [{"text": "recall", "start_pos": 16, "end_pos": 22, "type": "METRIC", "confidence": 0.9855666160583496}, {"text": "F1", "start_pos": 43, "end_pos": 45, "type": "METRIC", "confidence": 0.510192334651947}]}, {"text": "presents the evaluation results of our submissions.", "labels": [], "entities": []}, {"text": "The models showed similar behavior as in the in-house experiment excepting evidence F1.", "labels": [], "entities": []}, {"text": "Our submission were ranked in 9th place.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The number of claims in each datasets.", "labels": [], "entities": []}, {"text": " Table 2: Evaluation results on the test dataset.", "labels": [], "entities": []}, {"text": " Table 3: Confusion matrix on the development dataset.", "labels": [], "entities": []}, {"text": " Table 4: Final results of our submissions.", "labels": [], "entities": []}]}