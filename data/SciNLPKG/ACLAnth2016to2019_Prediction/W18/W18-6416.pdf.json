{"title": [], "abstractContent": [{"text": "We participated in the WMT 2018 shared news translation task in three language pairs: English-Estonian, English-Finnish, and English-Czech.", "labels": [], "entities": [{"text": "WMT 2018 shared news translation task", "start_pos": 23, "end_pos": 60, "type": "TASK", "confidence": 0.6755212048689524}]}, {"text": "Our main focus was the low-resource language pair of Estonian and En-glish for which we utilized Finnish parallel data in a simple method.", "labels": [], "entities": []}, {"text": "We first train a \"parent model\" for the high-resource language pair followed by adaptation on the related low-resource language pair.", "labels": [], "entities": []}, {"text": "This approach brings a substantial performance boost over the base-line system trained only on Estonian-English parallel data.", "labels": [], "entities": []}, {"text": "Our systems are based on the Transformer architecture.", "labels": [], "entities": []}, {"text": "For the English to Czech translation, we have evaluated our last year models of hybrid phrase-based approach and neural machine translation mainly for comparison purposes.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 113, "end_pos": 139, "type": "TASK", "confidence": 0.7376211881637573}]}], "introductionContent": [{"text": "This paper describes the Charles University's submission to WMT 2018 Shared Task: Machine Translation of News.", "labels": [], "entities": [{"text": "Charles University", "start_pos": 25, "end_pos": 43, "type": "DATASET", "confidence": 0.9623913764953613}, {"text": "WMT 2018 Shared Task: Machine Translation of News", "start_pos": 60, "end_pos": 109, "type": "TASK", "confidence": 0.7886190745565627}]}, {"text": "We have experimented with three language pairs: Czech (CS), Estonian (ET) and Finnish (FI) paired with English (EN).", "labels": [], "entities": []}, {"text": "Altogether, we covered five directions: both direction for EnglishEstonian, both directions for English-Finnish and English to Czech translation.", "labels": [], "entities": [{"text": "English to Czech translation", "start_pos": 116, "end_pos": 144, "type": "TASK", "confidence": 0.6679240763187408}]}, {"text": "Our main focus is improving the low-resource language translation and therefore we concentrate on the English and Estonian language pair with the help of Finnish-English parallel data.", "labels": [], "entities": [{"text": "low-resource language translation", "start_pos": 32, "end_pos": 65, "type": "TASK", "confidence": 0.7655339439709982}]}, {"text": "The Finnish is a good candidate since it is closely related to the Estonian language but considerably more training data are available.", "labels": [], "entities": []}, {"text": "For the Finnish and English language pair, we use standard Neural Machine translation (NMT) system Transformer () with model averaging.", "labels": [], "entities": [{"text": "Neural Machine translation (NMT)", "start_pos": 59, "end_pos": 91, "type": "TASK", "confidence": 0.7951430380344391}]}, {"text": "Our last language pair of interest is English to Czech translation, where we use our last year's model for comparison purposes.", "labels": [], "entities": [{"text": "English to Czech translation", "start_pos": 38, "end_pos": 66, "type": "TASK", "confidence": 0.5958939120173454}]}, {"text": "The system is based on a hybrid combination of phrase-based, transfer-based and NMT approaches.", "labels": [], "entities": []}, {"text": "The structure of the paper is the following.", "labels": [], "entities": []}, {"text": "In Section 2, we describe the setup of our main systems for Estonian and Finnish.", "labels": [], "entities": []}, {"text": "Section 3 presents the English-Czech model.", "labels": [], "entities": []}, {"text": "Section 4 is devoted to the description of our datasets.", "labels": [], "entities": []}, {"text": "Section 5 details the results achieved by our systems.", "labels": [], "entities": []}, {"text": "Section 6 discusses other works in the area of multi-lingual translation systems.", "labels": [], "entities": [{"text": "multi-lingual translation systems", "start_pos": 47, "end_pos": 80, "type": "TASK", "confidence": 0.7724522352218628}]}, {"text": "And finally Section 7 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Uncased BLEU scores for transfer learning  of child models on various combinations of parent and  child. The baseline is obtained by training only on the  child parallel data. \"Only Parent\" represent result when  no adaptation of parent model is done, i.e. running MT  for the wrong language. The results are only compa- rable within each row. Results significantly better than  the baseline are marked with  \u2021.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.9901037216186523}]}, {"text": " Table 3: The maximal score reached by the English-to- Estonian child models for decreasing sizes of child's  training data, trained on an English to Finnish parent  (all models build upon the same parent ENFI after 800k  steps trained on the whole ENFI training set). The  baselines use only the reduced English-Estonian data.", "labels": [], "entities": []}, {"text": " Table 4: Results with backtranslated data, either up to  the size of the original parallel corpus (\"Equal Size\")  or all available (\"All\"). The significance is computed  between \"Equal Size\" and \"All\". The bold results are  with additional use of transfer learning.", "labels": [], "entities": []}, {"text": " Table 5: WMT18 newstest BLEU scores for the base- line runs and the runs submitted as \"CUNI-Kocmi-*\"  for manual evaluation.", "labels": [], "entities": [{"text": "WMT18 newstest", "start_pos": 10, "end_pos": 24, "type": "DATASET", "confidence": 0.8659649193286896}, {"text": "BLEU", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9851254224777222}]}, {"text": " Table 6: Cased-BLEU results from matrix.statmt.org.", "labels": [], "entities": []}]}