{"title": [{"text": "Veyn at PARSEME Shared Task 2018: Recurrent Neural Networks for VMWE Identification", "labels": [], "entities": [{"text": "PARSEME Shared Task 2018", "start_pos": 8, "end_pos": 32, "type": "DATASET", "confidence": 0.7789822220802307}, {"text": "VMWE Identification", "start_pos": 64, "end_pos": 83, "type": "TASK", "confidence": 0.6839680373668671}]}], "abstractContent": [{"text": "This paper describes the Veyn system, submitted to the closed track of the PARSEME Shared Task 2018 on automatic identification of verbal multiword expressions (VMWEs).", "labels": [], "entities": [{"text": "PARSEME Shared Task 2018", "start_pos": 75, "end_pos": 99, "type": "DATASET", "confidence": 0.6664223819971085}, {"text": "automatic identification of verbal multiword expressions (VMWEs)", "start_pos": 103, "end_pos": 167, "type": "TASK", "confidence": 0.7815358373853896}]}, {"text": "Veyn is based on a sequence tagger using recurrent neural networks.", "labels": [], "entities": []}, {"text": "We represent VMWEs using a variant of the begin-inside-outside encoding scheme combined with the VMWE category tag.", "labels": [], "entities": [{"text": "VMWE category tag", "start_pos": 97, "end_pos": 114, "type": "DATASET", "confidence": 0.8557309905687968}]}, {"text": "In addition to the system description, we present development experiments to determine the best tagging scheme.", "labels": [], "entities": []}, {"text": "Veyn is freely available, covers 19 languages, and was ranked ninth (MWE-based) and eight (Token-based) among 13 submissions, considering macro-averaged F1 across languages.", "labels": [], "entities": [{"text": "Veyn", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8629087805747986}, {"text": "MWE-based", "start_pos": 69, "end_pos": 78, "type": "DATASET", "confidence": 0.792258620262146}, {"text": "F1", "start_pos": 153, "end_pos": 155, "type": "METRIC", "confidence": 0.8881446719169617}]}], "introductionContent": [{"text": "Multiword expressions (MWEs) pose problem for NLP systems such as machine translation.", "labels": [], "entities": [{"text": "Multiword expressions (MWEs", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7118088006973267}, {"text": "machine translation", "start_pos": 66, "end_pos": 85, "type": "TASK", "confidence": 0.7989015281200409}]}, {"text": "For instance, in English there are plenty more fish in the sea would be translated into French as une de perdu, dix de retrouv\u00e9es (lit.", "labels": [], "entities": []}, {"text": "one lost, ten found) and not word-by-word as il ya plus de poissons dans la mer.", "labels": [], "entities": []}, {"text": "To be able to translate MWEs correctly, however, we have to first identify them.", "labels": [], "entities": [{"text": "translate MWEs", "start_pos": 14, "end_pos": 28, "type": "TASK", "confidence": 0.821503221988678}]}, {"text": "Automatic identification of MWEs, and in particular of verbal MWEs (VMWEs), is the topic of this paper.", "labels": [], "entities": [{"text": "Automatic identification of MWEs", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7253498658537865}]}, {"text": "The PARSEME shared task 2018 is an evaluation campaign of systems for the identification of VMWEs ( . This task presents many challenges, such as the presence of variants, discontinuous and ambiguous).", "labels": [], "entities": [{"text": "PARSEME shared task 2018", "start_pos": 4, "end_pos": 28, "type": "DATASET", "confidence": 0.7013490945100784}, {"text": "identification of VMWEs", "start_pos": 74, "end_pos": 97, "type": "TASK", "confidence": 0.7105244199434916}]}, {"text": "Our system \"Veyn\" is based on a sequence tagger using recurrent neural networks (RNNs).", "labels": [], "entities": []}, {"text": "We represent VMWEs using a variant of the standard begin-inside-outside (BIO) encoding scheme.", "labels": [], "entities": []}, {"text": "Moreover, we achieve VMWE categorization by combining the VMWE category with BIO tags.", "labels": [], "entities": [{"text": "VMWE categorization", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.6964991688728333}, {"text": "VMWE category", "start_pos": 58, "end_pos": 71, "type": "DATASET", "confidence": 0.8991032540798187}]}, {"text": "The goal of the RNN is to predict the correct BIO+category tag for each token.", "labels": [], "entities": []}, {"text": "We use no external corpus or word embeddings to train our system, hence we participated in the closed track.", "labels": [], "entities": []}, {"text": "Veyn is freely available, 2 and covers 19 of the 20 languages of the shared task (all except Arabic, which required a special license).", "labels": [], "entities": [{"text": "Veyn", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8715081810951233}]}, {"text": "Sequence taggers were successfully employed by many systems for MWE identification in the past.", "labels": [], "entities": [{"text": "Sequence taggers", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8994905352592468}, {"text": "MWE identification", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.9843010902404785}]}, {"text": "Most existing models and systems, however, represent features as discrete values taken from finite sets instead of continuous vectors.", "labels": [], "entities": []}, {"text": "Examples of such systems employ conditional random fields ( and structured perceptron ().", "labels": [], "entities": []}, {"text": "Most recent NLP systems for sequence tagging, however, are based on RNNs.", "labels": [], "entities": [{"text": "sequence tagging", "start_pos": 28, "end_pos": 44, "type": "TASK", "confidence": 0.7617639601230621}]}, {"text": "Our system follows this trend by adapting an RNN model successful in other tagging tasks to VMWE identification.", "labels": [], "entities": [{"text": "VMWE identification", "start_pos": 92, "end_pos": 111, "type": "TASK", "confidence": 0.7172224074602127}]}, {"text": "Our system is similar to MUMULS, submitted to the previous PARSEME shared task, edition 1.0 (.", "labels": [], "entities": [{"text": "MUMULS", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.4995846748352051}, {"text": "PARSEME shared task", "start_pos": 59, "end_pos": 78, "type": "TASK", "confidence": 0.6172622243563334}]}, {"text": "MUMULS was evaluated on fifteen languages with variable results.", "labels": [], "entities": [{"text": "MUMULS", "start_pos": 0, "end_pos": 6, "type": "TASK", "confidence": 0.4199029505252838}]}, {"text": "Our system differs from MUMULS in the hyper-parameter configuration, the tag encoding scheme (IO for MU-MULS, BIO for Veyn), the use of pre-initialized embeddings (not used by MUMULS) and the number of recurrent layers (1 in MUMULS, 2 in Veyn).", "labels": [], "entities": [{"text": "IO", "start_pos": 94, "end_pos": 96, "type": "METRIC", "confidence": 0.9752511382102966}, {"text": "BIO", "start_pos": 110, "end_pos": 113, "type": "METRIC", "confidence": 0.9932854175567627}]}, {"text": "In the remainder of this paper, we describe the system architecture (Sec.", "labels": [], "entities": []}, {"text": "2), the tuning experiments on the development data (Sec. 3), and the results at the shared task (Sec. 4), before concluding (Sec. 5).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Average (avg) of characteristics and categories on the development corpus and on the test corpus.", "labels": [], "entities": [{"text": "Average (avg)", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9392174184322357}]}]}