{"title": [{"text": "Part-of-Speech Annotation of English-Assamese code-mixed texts: Two Approaches", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we discuss the development of a part-of-speech tagger for English-Assamese code-mixed texts.", "labels": [], "entities": []}, {"text": "We provide a comparison of 2 approaches to annotating code-mixed data a) annotation of the texts from the two languages using monolingual resources from each language and b) annotation of the text through a different resource created specifically for code-mixed data.", "labels": [], "entities": []}, {"text": "We present a comparative study of the efforts required in each approach and the final performance of the system.", "labels": [], "entities": []}, {"text": "Based on this, we argue that it might be a better approach to develop new technologies using code-mixed data instead of monolingual, 'clean' data, especially for those languages where we do not have significant tools and technologies available till now.", "labels": [], "entities": []}], "introductionContent": [{"text": "Code-mixing and code-switching in multilingual societies are two of the most well-studied phenomena within the field of sociolinguistics.", "labels": [], "entities": []}, {"text": "Generally, code-mixing is considered intra-sentential in the sense that it refers to mixing of words, phrases or clauses within the same sentence while code-switching is inter-sentential or even inter-clausal in the sense that one switches to the other language while speaking.", "labels": [], "entities": []}, {"text": "In this paper, we will use code-mixing to refer to both these phenomena.", "labels": [], "entities": []}, {"text": "While code-mixing is a very well-studied phenomena within the field of theoretical linguistics, there have been few works computational modelling of code-mixing.", "labels": [], "entities": []}, {"text": "In the past of few years, with the explosion of social media and an urgent need to process the social media data, we have seen quite a few efforts at modelling, automatic identification and processing of code-mixing (most notable among them being () and several others in the two workshops on computational approaches to code-mixing).", "labels": [], "entities": []}, {"text": "In this paper, we discuss the development of a part-of-speech tagger for English-Assamese code-mixed data and also present a comparative study of two different approaches to annotating code-mixed data a monolingual ensemble approach: reuse the already available tools for individual languages in an ensemble to process the code-mixed data and b novel multilingual approach: develop new tools exclusively for code-mixed data from the scratch.", "labels": [], "entities": []}, {"text": "It is often argued that it is a much more resource-intensive task to develop separate tools for different kinds of natural language processing of code-mixed data.", "labels": [], "entities": []}, {"text": "As such it is desirable to use the pre-existing tools that were developed for different languages for processing code-mixed texts.", "labels": [], "entities": []}, {"text": "While this argument holds merit if the languages under consideration have sufficiently large number of tools and applications already available, which maybe used.", "labels": [], "entities": []}, {"text": "However, this is not the case fora large number of Indian 95 languages, including the major ones.", "labels": [], "entities": []}, {"text": "Barring a few exceptions, there is hardly any basic technologies available for most of the Indian languages.", "labels": [], "entities": []}, {"text": "In such a situation, developing tools and technologies for code-mixed, multilingual texts might prove to be more efficient and effective than those for monolingual texts.", "labels": [], "entities": []}, {"text": "Also, it might be the case that the tools developed for code-mixed texts work better with monolingual texts in comparison to the performance of the tools developed for monolingual texts used with code-mixed texts.", "labels": [], "entities": []}, {"text": "In this paper, we discuss the challenges and issues of both the approaches to processing code-mixed data and also discuss the comparative performance of both the approaches and argue fora rather provocative stand -it will be a better and more fruitful idea to develop technologies based on a multilingual, code-mixed data instead of what is considered 'clean', monolingual data not only because code-mixed data will become norm in the near future but also because these technologies might prove to be 'overall' better performing ones of the two.", "labels": [], "entities": []}], "datasetContent": [{"text": "The data was annotated with both the information about the language at the word-level as well as with the part-of-speech tags.", "labels": [], "entities": []}, {"text": "The tagset used for the language annotation is given in.", "labels": [], "entities": []}, {"text": "The data was annotated at 3 levels Matrix Language, Fragment Language and Word-level Codemixing (WLCM).", "labels": [], "entities": []}, {"text": "Matrix language refers to the language of the whole comment and it maybe monolingual (Assamese or English), code-mixed (Mix), universal (UNIV) and named entity (NE).", "labels": [], "entities": []}, {"text": "If the language is neither of these three, it is annotated as Other -it allows for further annotation of these comments in the dataset with specific language.", "labels": [], "entities": []}, {"text": "Fragment language is the word-level annotation of the language and it was annotated with the same set of languages as the matrix language, except Mix.", "labels": [], "entities": []}, {"text": "WLCM refers to the phenomenon where the root form of a word is in one language and the affix is in another language.", "labels": [], "entities": []}, {"text": "In such cases, the language of the word is annotated as a combination of the two languages which makes up the word.", "labels": [], "entities": []}, {"text": "Let us take a look at the following example -  Assamese-Other AS-OT 1.10 Other-Assamese OT-AS 1.11 English-Other EN-OT 1.12 Other-English OT-EN: Language Identification Tagset  Universal part-of-speech tags, proposed by the Universal Dependencies was used for annotating the data with part-of-speech information.", "labels": [], "entities": [{"text": "Assamese-Other AS-OT 1.10 Other-Assamese OT-AS 1.11 English-Other EN-OT 1.12 Other-English OT-EN", "start_pos": 47, "end_pos": 143, "type": "DATASET", "confidence": 0.728512620384043}, {"text": "Universal Dependencies", "start_pos": 224, "end_pos": 246, "type": "DATASET", "confidence": 0.9140746593475342}]}, {"text": "The tagset is reproduced in.", "labels": [], "entities": []}, {"text": "In addition to the 17 universal tags included in the Universal Dependencies tagset, 2 tags suffix and prefix -were included in the tagset.", "labels": [], "entities": [{"text": "Universal Dependencies tagset", "start_pos": 53, "end_pos": 82, "type": "DATASET", "confidence": 0.9377389152844747}]}, {"text": "It was necessitated by the kind of data that we encountered in our dataset.", "labels": [], "entities": []}, {"text": "There were several instances where the affixes in the Assamese text (written in Roman script) were not attached to their root.", "labels": [], "entities": []}, {"text": "Let us take a look at an example belowIt was generally observed that the classifiers and genitive markers were not attached to their root form while writing in Roman.", "labels": [], "entities": []}, {"text": "This could be possibly because of the lack of a standardized writing convention in a non-native script like Roman and the identification of a false word boundary by the speakers, which led them to separate the root and the affix in the texts.", "labels": [], "entities": []}, {"text": "We did not normalize such instances and in order to annotate such fragments, the 2 new tags were introduced.", "labels": [], "entities": []}, {"text": "The reason for not normalzsing texts like these was 2-fold -a) these could actually bean indication towards the way language is processed and word boundaries recognised by the speakers and b) in case there is a variation, it may point towards sociopragmatic usage of separating out certain kinds of 'affixes' from their roots.", "labels": [], "entities": []}, {"text": "All the other tags carry the same meaning as in the universal dependencies tagset.", "labels": [], "entities": []}, {"text": "Emojis in the text were marked as Symbol.", "labels": [], "entities": []}, {"text": "In addition to the code-mixed annotated dataset that we created, we also acquired monolingual Assamese dataset, prepared as part of Indian Languages Corpora Initiative (ILCI) and made available through Technology Development for Indian Languages (TDIL), Govt. of India.", "labels": [], "entities": [{"text": "Assamese dataset", "start_pos": 94, "end_pos": 110, "type": "DATASET", "confidence": 0.728511855006218}]}, {"text": "The dataset contains 2 kinds of data original Assamese texts from newspapers, magazines, etc from more than 10 different domains and translated Assamese texts (source language: Hindi) from the two domains of entertainment and agriculture.", "labels": [], "entities": []}, {"text": "The total dataset that is currently available consists of 52,000 part-of-speech annotated sentences.", "labels": [], "entities": []}, {"text": "However, we use only a small portion of the dataset for this study.", "labels": [], "entities": []}, {"text": "The data was annotated using the Bureau of Indian Standards (BIS) tagset that has been declared the national standard for annotating Indian languages data.", "labels": [], "entities": [{"text": "Bureau of Indian Standards (BIS) tagset", "start_pos": 33, "end_pos": 72, "type": "DATASET", "confidence": 0.6553878113627434}]}, {"text": "However, since all other datasets used in the experiments have been annotated with Universal Dependencies tagset, it was necessary that Assamese dataset also uses the same tagset.", "labels": [], "entities": [{"text": "Assamese dataset", "start_pos": 136, "end_pos": 152, "type": "DATASET", "confidence": 0.7537358105182648}]}, {"text": "Since there is no Assamese dataset annotated with Universal Dependencies POS tagset available, we developed a simple mapper to map the tags of BIS tagset to those of Universal Dependencies.", "labels": [], "entities": [{"text": "Assamese dataset", "start_pos": 18, "end_pos": 34, "type": "DATASET", "confidence": 0.7568367719650269}, {"text": "Universal Dependencies POS tagset", "start_pos": 50, "end_pos": 83, "type": "DATASET", "confidence": 0.8590943962335587}, {"text": "BIS tagset", "start_pos": 143, "end_pos": 153, "type": "DATASET", "confidence": 0.897884875535965}, {"text": "Universal Dependencies", "start_pos": 166, "end_pos": 188, "type": "DATASET", "confidence": 0.9600345194339752}]}, {"text": "Since BIS tagset is  now Raj brother-NOM break CLF give-EMP happen and Now, may rajda give the break and thats it more fine-grained than the UD tagset, it was a rather simple task to map the tags from BIS to UD tagset.", "labels": [], "entities": [{"text": "BIS tagset", "start_pos": 6, "end_pos": 16, "type": "DATASET", "confidence": 0.8315936028957367}, {"text": "UD tagset", "start_pos": 208, "end_pos": 217, "type": "DATASET", "confidence": 0.7942360639572144}]}, {"text": "The mapping is given in.", "labels": [], "entities": []}, {"text": "While for the most part the mapping was quite straightforward and simple to implement, there were a couple of instances where the differing guidelines made the things a little difficult.", "labels": [], "entities": []}, {"text": "One was the case of general quantifiers.", "labels": [], "entities": []}, {"text": "Generally, quantifiers occur at the position of demonstrative in a syntactic structure and this is probably the reason why quantifiers are classified as determiners and not numerals in UD.", "labels": [], "entities": []}, {"text": "However, in the BIS tagset, it is grouped with the numerals.", "labels": [], "entities": [{"text": "BIS tagset", "start_pos": 16, "end_pos": 26, "type": "DATASET", "confidence": 0.9694680869579315}]}, {"text": "Similarly, BIS tagset do not have determiners as a separate category but they have demonstratives which do not appear in UD.", "labels": [], "entities": [{"text": "BIS tagset", "start_pos": 11, "end_pos": 21, "type": "DATASET", "confidence": 0.8782502710819244}]}, {"text": "The reasons again seem to be syntactic -since UD is more generally designed for syntactic parsing, the POS categories are accordingly defined.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 80, "end_pos": 97, "type": "TASK", "confidence": 0.721202552318573}]}, {"text": "In both these cases, we followed the UD guidelines while mapping since that is the tagset which is being mapped into.", "labels": [], "entities": []}, {"text": "In addition to these, UD does not have echo-word at POS level -it has been included as a morphological feature, which is pretty obvious.", "labels": [], "entities": []}, {"text": "Since it was not possible to map this to any POS category in UD, we used anew category called 'suffix' to map echo-word to.", "labels": [], "entities": [{"text": "UD", "start_pos": 61, "end_pos": 63, "type": "DATASET", "confidence": 0.8148632645606995}]}, {"text": "It could be argued that it is not a POS category but it is also not meant to be so.", "labels": [], "entities": []}, {"text": "It is only a placeholder such that it could be properly handled at the morphemic level.", "labels": [], "entities": []}, {"text": "Furthermore, since we are using this category in annotating the social media data also, it also provided some kind of consistency.", "labels": [], "entities": [{"text": "consistency", "start_pos": 118, "end_pos": 129, "type": "METRIC", "confidence": 0.9654002785682678}]}, {"text": "Aside from all this, what was surprising was that the Assamese dataset was not annotated with the information about 'classifiers'.", "labels": [], "entities": [{"text": "Assamese dataset", "start_pos": 54, "end_pos": 70, "type": "DATASET", "confidence": 0.8635227680206299}]}, {"text": "Since BIS tagset provides fora category called 'classifier' and Assamese is quite rich in terms of classifiers, this category must have been included.", "labels": [], "entities": [{"text": "BIS tagset", "start_pos": 6, "end_pos": 16, "type": "DATASET", "confidence": 0.8963066339492798}]}, {"text": "However since it was not present in our dataset, we have not mapped it to any other category.", "labels": [], "entities": []}, {"text": "In any case, it does appear in some dataset, like echo-word, it could also be mapped to 'suffix'.", "labels": [], "entities": []}, {"text": "For English, the monolingual annotated dataset was obtained from the dataset provided for CoNLL 2018 shared task.", "labels": [], "entities": [{"text": "CoNLL 2018 shared task", "start_pos": 90, "end_pos": 112, "type": "DATASET", "confidence": 0.8669824004173279}]}, {"text": "The dataset was annotated using the Universal Dependencies tagset.", "labels": [], "entities": [{"text": "Universal Dependencies tagset", "start_pos": 36, "end_pos": 65, "type": "DATASET", "confidence": 0.9118138551712036}]}, {"text": "We used the Universal Dependencies English Web Treebank v2.2, which consists of 16,622 sentences, taken from five genres of web media: weblogs, newsgroups, emails, reviews, and Yahoo!", "labels": [], "entities": [{"text": "Universal Dependencies English Web Treebank v2.2", "start_pos": 12, "end_pos": 60, "type": "DATASET", "confidence": 0.7365784496068954}]}, {"text": "As with the Assamese dataset, we used only a randomly sampled small subset of this dataset for our experiments.", "labels": [], "entities": [{"text": "Assamese dataset", "start_pos": 12, "end_pos": 28, "type": "DATASET", "confidence": 0.8443571329116821}]}, {"text": "We developed 3 different part-of-speech taggers -Assamese, English and Code-mixed -as part of our experiments.", "labels": [], "entities": []}, {"text": "All the 3 taggers were trained on a dataset of approximately 1,700 sentences each.", "labels": [], "entities": []}, {"text": "We divide the dataset into train:test ratio of 90:10.", "labels": [], "entities": []}, {"text": "The train set is used for training a Linear SVM classifier using 5-fold cross-validation.", "labels": [], "entities": [{"text": "Linear SVM classifier", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.7152944207191467}]}, {"text": "We tune only C hyperparamter of the classifier and arrive at the best classifier using Grid Search technique.", "labels": [], "entities": []}, {"text": "We use scikit-learn library (in Python) for all our experiments.", "labels": [], "entities": []}, {"text": "The following set of features gave the best performance for all the three classifiersWord-level Features: We used the current word, previous 2 words and next 2 words as features.", "labels": [], "entities": []}, {"text": "Tag-level Features: We used the tags of previous 2 words as features.", "labels": [], "entities": []}, {"text": "We will be releasing the dataset and the models trained during the experiments for further research as well as reproducibility of our results These classifiers were tested in 3 different ways to assess the relative performance of the systems developed using the two different approaches to processing code-mixed data.", "labels": [], "entities": []}, {"text": "These are discussed in the following subsections.", "labels": [], "entities": []}, {"text": "This is the classical testing of the classifiers where we test the classifiers on the dataset of the same language as it was trained on.", "labels": [], "entities": []}, {"text": "Thus the classifier trained on Assamese monolingual dataset was tested on Assamese monolingual dataset and soon.", "labels": [], "entities": [{"text": "Assamese monolingual dataset", "start_pos": 31, "end_pos": 59, "type": "DATASET", "confidence": 0.6076233883698782}, {"text": "Assamese monolingual dataset", "start_pos": 74, "end_pos": 102, "type": "DATASET", "confidence": 0.6687433024247488}]}, {"text": "The test results set a benchmark to compare the loss of performance when tested on the other datasets.", "labels": [], "entities": []}, {"text": "The performance of the classifiers is summarised in: Performance of part-of-speech taggers tested on the dataset of same language As we could see, the classifier for code-mixed data performs the worst.", "labels": [], "entities": []}, {"text": "This is not very surprising given the low amount of data that was used for training.", "labels": [], "entities": []}, {"text": "However, with similar amount of data, the other 2 classifiers performed comparatively better.", "labels": [], "entities": []}, {"text": "This could be attributed to the fact that the monolingual dataset is more consistent and noise-free than the code-mixed data and thus comparatively easier to fit than the code-mixed data.", "labels": [], "entities": []}, {"text": "Moreover, it must be noted that in this case, it is not just that the code is mixed; rather the dataset is from social media and contains several other kinds of inconsistencies including nonstandard spelling and punctuation, use of emoticons, presence of hyperlinks, etc.", "labels": [], "entities": []}, {"text": "As such, the training data required for training a code-mixed classifier is more than that required for monolingual classifier, in order to achieve a comparable performance.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Performance of part-of-speech taggers tested on the dataset of same language", "labels": [], "entities": [{"text": "part-of-speech taggers", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.718120738863945}]}, {"text": " Table 5: Performance of part-of-speech taggers trained on code-mixed dataset and tested on the mono- lingual dataset", "labels": [], "entities": [{"text": "part-of-speech taggers", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.7162361145019531}]}, {"text": " Table 6: Performance of part-of-speech taggers tested on code-mixed data", "labels": [], "entities": [{"text": "part-of-speech taggers", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.7349111437797546}]}]}