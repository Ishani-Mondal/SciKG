{"title": [{"text": "Chinese Grammatical Error Diagnosis Based on Policy Gradient LSTM Model", "labels": [], "entities": [{"text": "Chinese Grammatical Error Diagnosis", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.72495536506176}]}], "abstractContent": [{"text": "Chinese Grammatical Error Diagnosis (CGED) is a natural language processing task for the NLPTEA2018 workshop held during ACL2018.", "labels": [], "entities": [{"text": "Chinese Grammatical Error Diagnosis (CGED)", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.802914138351168}, {"text": "natural language processing task", "start_pos": 48, "end_pos": 80, "type": "TASK", "confidence": 0.7298671901226044}, {"text": "ACL2018", "start_pos": 121, "end_pos": 128, "type": "DATASET", "confidence": 0.495703786611557}]}, {"text": "The goal of this task is to diagnose Chinese sentences containing four kinds of grammatical errors through the model and find out the sentence errors.", "labels": [], "entities": []}, {"text": "Chinese grammatical error diagnosis system is a very important tool, which can help Chinese learners automatically diagnose grammatical errors in many scenarios.", "labels": [], "entities": [{"text": "Chinese grammatical error diagnosis", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.5397045090794563}, {"text": "Chinese learners automatically diagnose grammatical errors", "start_pos": 84, "end_pos": 142, "type": "TASK", "confidence": 0.7101446886857351}]}, {"text": "However, due to the limitations of the Chinese language's own characteristics and datasets, the traditional model faces the problem of extreme imbalances in the positive and negative samples and the disappearance of gradients.", "labels": [], "entities": []}, {"text": "In this paper, we propose a sequence labeling method based on the Policy Gradient LSTM model and apply it to this task to solve the above problems.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 28, "end_pos": 45, "type": "TASK", "confidence": 0.6318682432174683}, {"text": "Policy Gradient LSTM", "start_pos": 66, "end_pos": 86, "type": "TASK", "confidence": 0.5301269690195719}]}, {"text": "The results show that our model can achieve higher precision scores in the case of lower False positive rate (FPR) and it is convenient to optimize the model on-line.", "labels": [], "entities": [{"text": "precision scores", "start_pos": 51, "end_pos": 67, "type": "METRIC", "confidence": 0.9770389795303345}, {"text": "False positive rate (FPR)", "start_pos": 89, "end_pos": 114, "type": "METRIC", "confidence": 0.9705774386723837}]}], "introductionContent": [{"text": "In English and many other languages , the space is a good approximation of a word divider (word delimiter), a sentence separated by spaces into multiple words.", "labels": [], "entities": [{"text": "word divider (word delimiter)", "start_pos": 77, "end_pos": 106, "type": "TASK", "confidence": 0.6950606455405554}]}, {"text": "Unlike the English, Chinese does not have a separator on the written scripts, a sentence consists of Chinese characters that are next to each other, where sentences but not words are delimited.", "labels": [], "entities": []}, {"text": "This is very difficult for the machine or learner without a Chinese foundation to analyze Chinese grammar, because it first has to face the problem of Chinese word segmentation).", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 151, "end_pos": 176, "type": "TASK", "confidence": 0.6516241927941641}]}, {"text": "Compared to English, Chinese has neither singular/plural change, nor the tense changes of the verb, and it uses more short sentences but less clauses.", "labels": [], "entities": []}, {"text": "In addition, the same word may express different meanings in different contexts, namely ambiguity.", "labels": [], "entities": []}, {"text": "All these problems make learning Chinese very difficult.", "labels": [], "entities": []}, {"text": "Most non-native Chinese language learners usually need professional Chinese teachers to guide them and correct grammatical errors.", "labels": [], "entities": []}, {"text": "However, online teaching has recently become the main channel for language learning, which requires the system to automatically diagnose and give advice to a large number of learners' grammatical errors.", "labels": [], "entities": [{"text": "language learning", "start_pos": 66, "end_pos": 83, "type": "TASK", "confidence": 0.8184770345687866}]}, {"text": "Therefore, the study of Chinese grammatical error automatic diagnosis system is very important.", "labels": [], "entities": [{"text": "Chinese grammatical error automatic diagnosis", "start_pos": 24, "end_pos": 69, "type": "TASK", "confidence": 0.6693655133247376}]}, {"text": "The goal of Chinese Grammatical Error Diagnosis (CGED) is to build a system that can automatically diagnose errors in Chinese sentences.", "labels": [], "entities": [{"text": "Chinese Grammatical Error Diagnosis (CGED)", "start_pos": 12, "end_pos": 54, "type": "TASK", "confidence": 0.8241187334060669}]}, {"text": "Such errors are defined as redundant words (denoted as a capital \"R\"), missing words (\"M\"), word selection errors (\"S\"), and word ordering errors (\"W\").", "labels": [], "entities": []}, {"text": "Evaluation includes three levels, which are detection level, identification level and position level.", "labels": [], "entities": []}, {"text": "At present, most methods regard the Chinese grammatical error diagnosis task as a sequence labeling task, such as using a conditional random field construction sequence labeling model ( and a sequence labeling model constructed using LSTM.", "labels": [], "entities": [{"text": "Chinese grammatical error diagnosis task", "start_pos": 36, "end_pos": 76, "type": "TASK", "confidence": 0.6348470389842987}]}, {"text": "However, the characteristics of Chinese language leads to a obvious problem in constructing Chinese grammatical error diagnosis model, which is the imbalance between positive and negative samples.", "labels": [], "entities": [{"text": "Chinese grammatical error diagnosis", "start_pos": 92, "end_pos": 127, "type": "TASK", "confidence": 0.5365640446543694}]}, {"text": "For example, a sentence to be labeling is: , The correct labeling result should be: where N denotes a negative label, ie there is no wrong label, P denotes a positive label, ie there is a wrong label.", "labels": [], "entities": []}, {"text": "We can see that the proportion of positive and negative sample labels in a not very long sentence is seriously unbalanced, in the above example, the ratio is 2:27, which is a serious problem faced by the Chinese grammatical error diagnosis model.", "labels": [], "entities": [{"text": "Chinese grammatical error diagnosis", "start_pos": 204, "end_pos": 239, "type": "TASK", "confidence": 0.5034040585160255}]}, {"text": "In order to solve the above problems, we propose a Policy Gradient-based model to tag Chinese sentences.", "labels": [], "entities": []}, {"text": "Similar to the recent work, we also use the LSTM model to handle this task as a sequence labeling problem ().", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 80, "end_pos": 97, "type": "TASK", "confidence": 0.5764616429805756}]}, {"text": "Moreover, we use the Policy Gradient method to deal with the imbalance of positive and negative samples.", "labels": [], "entities": []}, {"text": "The results show that our method can achieve better results.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 introduces some related work . Section 3 briefly describes the CGED Shared Task.", "labels": [], "entities": []}, {"text": "Section 4 illustrates our methodology, including data preparation, model description and the details of policy gradient method.", "labels": [], "entities": [{"text": "data preparation", "start_pos": 49, "end_pos": 65, "type": "TASK", "confidence": 0.7545002698898315}, {"text": "model description", "start_pos": 67, "end_pos": 84, "type": "TASK", "confidence": 0.7031012922525406}]}, {"text": "Section 5 shows the experiment settings and results.", "labels": [], "entities": []}, {"text": "And finally, section 6 concludes the paper and presents future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we introduce the entire process of the experiment.", "labels": [], "entities": []}, {"text": "First of all, we introduce the use of data sets and division, and then briefly introduce the CGED experimental results evaluation method.", "labels": [], "entities": [{"text": "CGED experimental results evaluation", "start_pos": 93, "end_pos": 129, "type": "DATASET", "confidence": 0.7973480522632599}]}, {"text": "Finally, we introduce the results on the validation dataset and the results from the evaluation dataset based on our proposed model.", "labels": [], "entities": []}, {"text": "During the training of the model, we use the collection of training set of CGED2017 and training set of CGED2018 as the training dataset.", "labels": [], "entities": [{"text": "CGED2017", "start_pos": 75, "end_pos": 83, "type": "DATASET", "confidence": 0.9787135720252991}, {"text": "CGED2018", "start_pos": 104, "end_pos": 112, "type": "DATASET", "confidence": 0.955112099647522}]}, {"text": "In CGED2017 training set, provide 10,449 training units with a total of 26,448 grammatical errors, categorized as redundant (5,852 instances), missing (7,010), word selection (11,591) and word ordering.", "labels": [], "entities": [{"text": "CGED2017 training set", "start_pos": 3, "end_pos": 24, "type": "DATASET", "confidence": 0.9682646989822388}, {"text": "word selection", "start_pos": 160, "end_pos": 174, "type": "TASK", "confidence": 0.779437392950058}, {"text": "word ordering", "start_pos": 188, "end_pos": 201, "type": "TASK", "confidence": 0.7941944301128387}]}, {"text": "In the CGED2018 training set, contain total of 1,067 grammatical errors, categorized as redundant   The criteria for judging correctness are determined at three levels, (1)Detection-level: Binary classification of a given sentence, that is, corrector incorrect, should be completely identical with the gold standard.", "labels": [], "entities": [{"text": "CGED2018 training set", "start_pos": 7, "end_pos": 28, "type": "DATASET", "confidence": 0.9811870455741882}]}, {"text": "All error types will be regarded as incorrect.", "labels": [], "entities": []}, {"text": "(2)Identification-level: This level could be considered as a multi-class categorization problem.", "labels": [], "entities": []}, {"text": "All error types should be clearly identified.", "labels": [], "entities": []}, {"text": "A correct case should be completely identical with the gold standard of the given error type.", "labels": [], "entities": []}, {"text": "(3)Position-level: In addition to identifying the error types, this level also judges the occurrence range of the grammatical error.", "labels": [], "entities": []}, {"text": "That is to say, the system results should be perfectly identical with the quadruples of the gold standard.", "labels": [], "entities": []}, {"text": "The False Positive Rate(FPR), Accuracy (Acc), Precision (Pre), Recall (Rec) and F1 score(F1) are measured at all levels with the help of the confusion matrix.", "labels": [], "entities": [{"text": "False Positive Rate(FPR)", "start_pos": 4, "end_pos": 28, "type": "METRIC", "confidence": 0.9552540977795919}, {"text": "Accuracy (Acc)", "start_pos": 30, "end_pos": 44, "type": "METRIC", "confidence": 0.9482049196958542}, {"text": "Precision (Pre)", "start_pos": 46, "end_pos": 61, "type": "METRIC", "confidence": 0.9356885552406311}, {"text": "Recall (Rec)", "start_pos": 63, "end_pos": 75, "type": "METRIC", "confidence": 0.9536105692386627}, {"text": "F1 score(F1)", "start_pos": 80, "end_pos": 92, "type": "METRIC", "confidence": 0.920167076587677}]}, {"text": "We use the above data partitioning to train and converge the training set based on our proposed Policy Gradient-based model, the trained model was tested on the validation set and evaluation set.", "labels": [], "entities": []}, {"text": "We refer to the model's results on the validation dataset and select the best hyper-parameters model.", "labels": [], "entities": []}, {"text": "We testing on the final evaluation dataset for CGED2018 test set, the result showing with table 5.", "labels": [], "entities": [{"text": "CGED2018 test set", "start_pos": 47, "end_pos": 64, "type": "DATASET", "confidence": 0.9848939379056295}]}, {"text": "As we can see, our model can obtain better identification score and position score while obtaining a better detection level score.", "labels": [], "entities": [{"text": "position score", "start_pos": 68, "end_pos": 82, "type": "METRIC", "confidence": 0.8733613789081573}]}, {"text": "Our model obtains good results at three levels, and the Policy Gradient-based model can be easily applied to online tasks to optimize the network structure through continuous interaction and attempting to obtain maximum rewards.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Results on Validation Dataset", "labels": [], "entities": []}]}