{"title": [{"text": "Joint learning of frequency and word embeddings for multilingual readability assessment", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes two models that employ word frequency embeddings to deal with the problem of readability assessment in multiple languages.", "labels": [], "entities": []}, {"text": "The task is to determine the difficulty level of a given document , i.e., how hard it is fora reader to fully comprehend the text.", "labels": [], "entities": []}, {"text": "The proposed models show how frequency information can be integrated to improve the readability assessment.", "labels": [], "entities": []}, {"text": "The experimental results testing on both English and Chi-nese datasets show that the proposed models improve the results notably when comparing to those using only traditional word embeddings.", "labels": [], "entities": []}], "introductionContent": [{"text": "Readability assessment is the task of determining how difficult a given document is to understand.", "labels": [], "entities": [{"text": "Readability assessment", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8385105729103088}]}, {"text": "It is useful in many applications such as selecting learning material for children of different grade levels, for language learners, for comprehension tests, skills training, text summarisation, simplification systems and soon.", "labels": [], "entities": [{"text": "text summarisation", "start_pos": 175, "end_pos": 193, "type": "TASK", "confidence": 0.7660300731658936}]}, {"text": "Readability assessment has along research history, and many methods have been developed in the last couple of decades (.", "labels": [], "entities": [{"text": "Readability assessment", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9219622313976288}]}, {"text": "These approaches, however, rely on hand-crafted features that depend heavily on the languages and require adjustment when applying to anew language.", "labels": [], "entities": []}, {"text": "Our aim is to develop a universal method that can be used in a multilingual setting, which involve little effort when extending to other languages.", "labels": [], "entities": []}, {"text": "Recent machine learning techniques, such as convolutional neural networks (CNN)) typically do not have to be supplied with hand-crafted features.", "labels": [], "entities": []}, {"text": "These models often use pre-trained word embeddings for NLP tasks and have been proven to achieve good results on multiple benchmarks ().", "labels": [], "entities": []}, {"text": "The pre-trained word embeddings are generally designed in away that they can capture word meaning and topics.", "labels": [], "entities": []}, {"text": "Though they are useful since topics are good indications of whether a document is difficult to comprehend, word embeddings do not directly reflect the frequency levels of words.", "labels": [], "entities": []}, {"text": "In our scenario, it is desirable that the system can take into account the frequency level of words rather purely focusing on their meanings.", "labels": [], "entities": []}, {"text": "It is based on the assumption that more frequent words are supposed to be easier to understand.", "labels": [], "entities": []}, {"text": "We therefore propose two models that jointly represent words based on their meanings with traditional word embeddings and their frequency levels with the so-called frequency embeddings.", "labels": [], "entities": []}, {"text": "These two embedding layers are employed in a CNN architecture to determine the readability level of a given document.", "labels": [], "entities": []}, {"text": "Since this model does not depend on hand-crafted features, it can be easily adapted to multiple languages.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our methods for English and Chinese readability assessment on two datasets collected by).", "labels": [], "entities": [{"text": "English and Chinese readability assessment", "start_pos": 28, "end_pos": 70, "type": "TASK", "confidence": 0.5368160367012024}]}, {"text": "The first dataset, ENCT, was built with four reading levels from English New Concept textbook.", "labels": [], "entities": [{"text": "ENCT", "start_pos": 19, "end_pos": 23, "type": "DATASET", "confidence": 0.696409285068512}, {"text": "English New Concept textbook", "start_pos": 65, "end_pos": 93, "type": "DATASET", "confidence": 0.9503831118345261}]}, {"text": "The second dataset, CPT, was collected from Chinese primary textbook and contains six difficulty levels.", "labels": [], "entities": [{"text": "CPT", "start_pos": 20, "end_pos": 23, "type": "DATASET", "confidence": 0.5275596976280212}, {"text": "Chinese primary textbook", "start_pos": 44, "end_pos": 68, "type": "DATASET", "confidence": 0.9003576834996542}]}, {"text": "In total, there are 279 documents with 4671 sentences in ENCT and 637 documents with 16145 sentences in CPT.", "labels": [], "entities": [{"text": "ENCT", "start_pos": 57, "end_pos": 61, "type": "DATASET", "confidence": 0.8520522117614746}, {"text": "CPT", "start_pos": 104, "end_pos": 107, "type": "DATASET", "confidence": 0.9012369513511658}]}, {"text": "In both datasets, the difficulty levels were assigned by human experts.", "labels": [], "entities": []}, {"text": "We split randomly the dataset 70% for training, 27% for testing and 3% fora development set.", "labels": [], "entities": []}, {"text": "The New Dale-Chall Readability level) is a traditional readability test.", "labels": [], "entities": [{"text": "New Dale-Chall Readability level", "start_pos": 4, "end_pos": 36, "type": "DATASET", "confidence": 0.880947545170784}]}, {"text": "P DW is the percentage of difficult words in a document, calculated as the number of difficult words divided by the total number of words in the document.", "labels": [], "entities": [{"text": "P DW", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9518779814243317}]}, {"text": "Raw score \u03a6 is calculated as: \u03a6 = 0.1579 \u00d7 P DW + 0.0496 \u00d7 n w n s where n w is the number of words and n sis the number of sentences in the whole corpus, hence n w n s represents the average sentence length in the corpus.", "labels": [], "entities": []}, {"text": "Finally, if P DW is above 5%, then add 3.6365 to the raw score \u03a6 to get the adjusted score.", "labels": [], "entities": [{"text": "P DW", "start_pos": 12, "end_pos": 16, "type": "METRIC", "confidence": 0.8618006706237793}]}, {"text": "We implemented the New Dale-Chall Readability level (NDC) and converted the raw score \u03a6 to corresponding readability levels as follows: Grade 4 and Below level 1 level 1 5.0 to 5.9 Grades 5 -6 level 1 level 2 6.0 to 6.9 Grades 7 -8 level 2 level 3 7.0 to 7.9 Grades 9 -10 level 3 level 4 8.0 to 8.9 Grades 11 -12 level 3 level 5 9.0 to 9.9 College level 4 level 6 \u226510 College Graduate level 4 level 6 Word embeddings (WE).", "labels": [], "entities": [{"text": "New Dale-Chall Readability level (NDC)", "start_pos": 19, "end_pos": 57, "type": "DATASET", "confidence": 0.82380040202822}]}, {"text": "For English, we used the pre-trained word2vec by (Mikolov et al., 2013b) on Google News.", "labels": [], "entities": []}, {"text": "For Chinese, we collected a dataset consisting of news (\u2248 320K documents) and Wikipedia, tokenised and trained the word embeddings on it.", "labels": [], "entities": []}, {"text": "We used the pretrained frequency lists for English obtained from, and created our own Chinese frequency lists using the same dataset used for Chinese word embeddings.", "labels": [], "entities": []}, {"text": "We followed the setting as suggested in).", "labels": [], "entities": []}, {"text": "The filter windows' sizes are 3, 4, 5 with 100 feature maps each.", "labels": [], "entities": []}, {"text": "We used rectified linear units as activation functions for the convolutional layers, dropout rate of 0.5 and mini-batch size of 50.", "labels": [], "entities": []}, {"text": "These two settings followed the method in, where all words are kept either static (in static setting) or updated (in non-static setting) including the unknown ones while others parameters are learned.", "labels": [], "entities": []}, {"text": "All words are randomly initialised and modified while training.", "labels": [], "entities": []}, {"text": "Each static and non-static WE is treated as one channel while gradients are backpropagated only through one of the channels.", "labels": [], "entities": []}, {"text": "Only frequency embeddings are used in this setting (without word embeddings).", "labels": [], "entities": []}, {"text": "Word Frequency Embeddings (WFE).", "labels": [], "entities": [{"text": "Word Frequency Embeddings (WFE)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.49699540932973224}]}, {"text": "We concatenate the pre-trained word embeddings and the frequency embeddings as explained in section 3.", "labels": [], "entities": []}, {"text": "In the WFE setting, we use the three frequency metrics: raw counts, ranking and frequency class, while in the WFE-class setting, we use only the frequency class metric.", "labels": [], "entities": [{"text": "WFE", "start_pos": 7, "end_pos": 10, "type": "DATASET", "confidence": 0.8913483619689941}, {"text": "WFE-class", "start_pos": 110, "end_pos": 119, "type": "DATASET", "confidence": 0.9141820669174194}]}, {"text": "In both settings, the frequency embeddings are kept static during training.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracy of readability assessment with  different settings", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9966309666633606}]}]}