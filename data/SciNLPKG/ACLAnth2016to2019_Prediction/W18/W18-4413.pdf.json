{"title": [{"text": "Degree based Classification of Harmful Speech using Twitter Data", "labels": [], "entities": [{"text": "Classification of Harmful Speech", "start_pos": 13, "end_pos": 45, "type": "TASK", "confidence": 0.8256046622991562}]}], "abstractContent": [{"text": "Harmful speech has various forms and it has been plaguing the social media in different ways.", "labels": [], "entities": [{"text": "Harmful speech", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8038651943206787}]}, {"text": "If we need to crackdown different degrees of hate speech and abusive behavior amongst it, the classification needs to be based on complex ramifications which needs to be defined and hold accountable for, other than racist, sexist or against some particular group and community.", "labels": [], "entities": []}, {"text": "This paper primarily describes how we created an ontological classification of harmful speech based on degree of hateful intent, and used it to annotate twitter data accordingly.", "labels": [], "entities": []}, {"text": "The key contribution of this paper is the new dataset of tweets we created based on ontological classes and degrees of harmful speech found in the text.", "labels": [], "entities": []}, {"text": "We also propose supervised classification system for recognizing these respective harmful speech classes in the texts hence.", "labels": [], "entities": []}, {"text": "This serves as a preliminary work to lay down foundation on defining different classes of harmful speech and subsequent work will be done in making it's automatic detection more robust and efficient.", "labels": [], "entities": [{"text": "automatic detection", "start_pos": 153, "end_pos": 172, "type": "TASK", "confidence": 0.7571859061717987}]}], "introductionContent": [{"text": "Hate, as a simple standalone word is easily understood by everyone.", "labels": [], "entities": []}, {"text": "But as a concept, hate is vast, complex and has multiple themes and extensions.", "labels": [], "entities": []}, {"text": "The issue of harmful speech has been widely debated and analyzed by scholars in multiple fields of knowledge.", "labels": [], "entities": []}, {"text": "If youve been on social media lately, chances are good that you stumbled across something that might be classified as harmful speech online.", "labels": [], "entities": []}, {"text": "Perhaps you would have read a tweet that used offensive language to describe its recipient, or maybe you saw a Facebook post that was designed to demean a particular group of people.", "labels": [], "entities": []}, {"text": "Modern artificial intelligence has proven useful in detecting patterns, whether that be in images for facial recognition or audio for speech regulation.", "labels": [], "entities": [{"text": "facial recognition", "start_pos": 102, "end_pos": 120, "type": "TASK", "confidence": 0.7222845554351807}, {"text": "speech regulation", "start_pos": 134, "end_pos": 151, "type": "TASK", "confidence": 0.7028783857822418}]}, {"text": "But language is fluid, and as Mark Zuckerberg also recently noted in his testimony 1 before the US Congress that harmful speech can be heavily dependent on the context around the hateful words used and intent of the speaker.", "labels": [], "entities": []}, {"text": "Some terms found in hate speech are slang, and hence not part of the common vernacular used to train AI.", "labels": [], "entities": []}, {"text": "Other pressing issues remain determining different ways of expression of hate and the degree to which it affects people and communities, trying to make a fine line differentiating freedom of speech with hate speech, with making guidelines in defining hate speech.", "labels": [], "entities": []}, {"text": "Harmful speech has many manifestations, in speeches, prose, literature, real like conversations; and thus it does define it's own certain form in online discourse.", "labels": [], "entities": []}, {"text": "It's important for us to understand the amplifications and extensions of harmful speech online, plaguing the social media primarily (.", "labels": [], "entities": []}, {"text": "Twitter is also actively in an ongoing process to enforce new guidelines related to how it handles hateful conduct and abusive behavior, by users, taking place on its platform.", "labels": [], "entities": []}, {"text": "In addition to threatening violence or physical harm, they also want to look for accounts affiliated with certain respective groups that promote violence against citizens to move further in their hateful intentions.", "labels": [], "entities": []}, {"text": "Any content that glorifies violence or the perpetrators of a violent act will also be incorporated in violation of Twitters new guidelines to combat hate speech.", "labels": [], "entities": []}, {"text": "All these new developments in tackling hate speech in online discourse with a spectrum showcasing various degrees and ways (sarcasm, troll, profanity, violent threats etc) manifests a need to studying \"Harmful speech online\" in detail.", "labels": [], "entities": [{"text": "tackling hate speech in online discourse", "start_pos": 30, "end_pos": 70, "type": "TASK", "confidence": 0.8359581132729849}]}, {"text": "This motivated us to develop a classification based on an ontological view of harmful speech, taking inspiration from philosophical and social point of view of hate speech, the intent of speakers involved, affiliation of recipient to an ideology/group or individuality , and deduce them into classes marking some difference in degree of hateful intent.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we presented our machine learning models which are trained and tested on the respective dataset described in the previous sections.", "labels": [], "entities": []}, {"text": "We performed experiments with three different classifiers for multi-class classification namely Support Vector Machines with linear function kernel, Naive Bayes method and Random Forest Classifier.", "labels": [], "entities": [{"text": "multi-class classification", "start_pos": 62, "end_pos": 88, "type": "TASK", "confidence": 0.7116141021251678}]}, {"text": "For training our system classifier, we have used Scikit-learn).", "labels": [], "entities": []}, {"text": "In all the experiments, we carried out 10-fold cross validation.", "labels": [], "entities": []}, {"text": "describe the accuracy of each model used, in the case of Naive Bayes, Support vector machine and Random forest classifier respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9994282126426697}]}, {"text": "The feature set used for SVM and Naive Bayes methods included tf-idf method, and for Random Forest classifier, we used bag of words.", "labels": [], "entities": []}, {"text": "Random forest classifier performed the best out of the three and gave a highest accuracy of 76.42%, while the other two models also gave relevant accuracy with Naive Bayes with 73.42% and SVM with linear function kernel with 71.71%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9994712471961975}, {"text": "accuracy", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.9790265560150146}]}], "tableCaptions": [{"text": " Table 2: Twitter harmful speech dataset statistics", "labels": [], "entities": [{"text": "Twitter harmful speech dataset", "start_pos": 10, "end_pos": 40, "type": "DATASET", "confidence": 0.7504909336566925}]}]}