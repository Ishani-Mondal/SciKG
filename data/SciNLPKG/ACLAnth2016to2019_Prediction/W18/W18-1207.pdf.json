{"title": [{"text": "Meaningless yet Meaningful: Morphology Grounded Subword-level NMT", "labels": [], "entities": [{"text": "NMT", "start_pos": 62, "end_pos": 65, "type": "TASK", "confidence": 0.49550625681877136}]}], "abstractContent": [{"text": "We explore the use of two independent subsystems, namely Byte Pair Encoding (BPE) and Morfessor as basic units for subword-level neural machine translation (NMT).", "labels": [], "entities": [{"text": "subword-level neural machine translation (NMT)", "start_pos": 115, "end_pos": 161, "type": "TASK", "confidence": 0.7439518017428262}]}, {"text": "We have shown that for linguistically distant language-pairs Morfessor-based segmentation algorithm produces significantly better quality translation than BPE.", "labels": [], "entities": [{"text": "Morfessor-based segmentation", "start_pos": 61, "end_pos": 89, "type": "TASK", "confidence": 0.8019441068172455}]}, {"text": "However, for close language-pairs BPE-based subword-NMT may translate better than Morfessor-based subword-NMT.", "labels": [], "entities": []}, {"text": "We have proposed a combined approach of these two segmenta-tion algorithms Morfessor-BPE (M-BPE) which outperforms these two baseline systems in terms of BLEU score.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 154, "end_pos": 164, "type": "METRIC", "confidence": 0.9816386103630066}]}, {"text": "Our results are supported by experiments on three language-pairs:", "labels": [], "entities": []}], "introductionContent": [{"text": "Subword-level NMT is an NMT approach that can tackle OOV problem.", "labels": [], "entities": [{"text": "OOV problem", "start_pos": 53, "end_pos": 64, "type": "TASK", "confidence": 0.7471112608909607}]}, {"text": "In order to train an NMT () model fora languagepair, the size of vocabularies for source and target languages should be constant.", "labels": [], "entities": []}, {"text": "But in reality, the vocabulary of a natural language is open.", "labels": [], "entities": []}, {"text": "Some words in test data maybe absent in system vocabulary.", "labels": [], "entities": []}, {"text": "NMT model cannot interpret the semantics of these OOV words.", "labels": [], "entities": [{"text": "NMT", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7982648611068726}]}, {"text": "So, translation quality deteriorates as the number of unseen (rare) words increases ().", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9583398103713989}]}, {"text": "OOV words are mainly of three types described in.", "labels": [], "entities": []}, {"text": "The first type of OOV words needs transliteration.", "labels": [], "entities": []}, {"text": "But for translating the second type of OOV words, we need to look deeper.", "labels": [], "entities": [{"text": "translating", "start_pos": 8, "end_pos": 19, "type": "TASK", "confidence": 0.9786388874053955}]}, {"text": "A word based NMT system treats 'house' and 'houses' as two com-", "labels": [], "entities": []}], "datasetContent": [{"text": "There are three systems of subword segmentation in our experiment, namely-BPE, Morfessor and M-BPE.", "labels": [], "entities": [{"text": "subword segmentation", "start_pos": 27, "end_pos": 47, "type": "TASK", "confidence": 0.7987364530563354}]}, {"text": "We have used subwordnmt 1 for BPE segmentation, Flatcat) and NLP Indic Library 2 for producing morphological segmentation of English and Indian words.", "labels": [], "entities": [{"text": "BPE segmentation", "start_pos": 30, "end_pos": 46, "type": "TASK", "confidence": 0.737723246216774}, {"text": "Flatcat", "start_pos": 48, "end_pos": 55, "type": "DATASET", "confidence": 0.9435341954231262}, {"text": "NLP Indic Library 2", "start_pos": 61, "end_pos": 80, "type": "DATASET", "confidence": 0.838329404592514}, {"text": "morphological segmentation of English and Indian words", "start_pos": 95, "end_pos": 149, "type": "TASK", "confidence": 0.8283436468669346}]}, {"text": "We have used data from English-Hindi (EnHi), English-Bengali (En-Bn) and BengaliHindi (Bn-Hi) language-pairs from health and tourism domain multilingual parallel Indian Language Corpora Intitiative (ILCI) corpus.", "labels": [], "entities": []}, {"text": "We clean and tokenize the training corpus.", "labels": [], "entities": []}, {"text": "English data was tokenized using the Stanford tokenizer () and then true-cased using truecase.perl provided in MOSES toolkit 3 . For Hindi and Bengali data, we tokenized using NLP Indic Library ().", "labels": [], "entities": [{"text": "MOSES toolkit 3", "start_pos": 111, "end_pos": 126, "type": "DATASET", "confidence": 0.8857338627179464}]}, {"text": "Then parallel sentences were divided into three parts for training, testing and tuning/validation.", "labels": [], "entities": [{"text": "tuning/validation", "start_pos": 80, "end_pos": 97, "type": "TASK", "confidence": 0.7930461764335632}]}, {"text": "For each language-pair, we have 44,777 sentence-pairs in training data, 1,000 sentence-pairs in tuning data and 2,000 sentence-pairs in test data.", "labels": [], "entities": []}], "tableCaptions": []}