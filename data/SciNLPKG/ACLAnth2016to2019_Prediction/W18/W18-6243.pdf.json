{"title": [{"text": "Emo2Vec: Learning Generalized Emotion Representation by Multi-task Training", "labels": [], "entities": [{"text": "Learning Generalized Emotion Representation", "start_pos": 9, "end_pos": 52, "type": "TASK", "confidence": 0.5538376718759537}]}], "abstractContent": [{"text": "In this paper, we propose Emo2Vec which encodes emotional semantics into vectors.", "labels": [], "entities": []}, {"text": "We train Emo2Vec by multi-task learning six different emotion-related tasks, including emo-tion/sentiment analysis, sarcasm classification, stress detection, abusive language classification , insult detection, and personality recognition.", "labels": [], "entities": [{"text": "emo-tion/sentiment analysis", "start_pos": 87, "end_pos": 114, "type": "TASK", "confidence": 0.7063077315688133}, {"text": "sarcasm classification", "start_pos": 116, "end_pos": 138, "type": "TASK", "confidence": 0.8474142551422119}, {"text": "stress detection", "start_pos": 140, "end_pos": 156, "type": "TASK", "confidence": 0.7235923260450363}, {"text": "abusive language classification", "start_pos": 158, "end_pos": 189, "type": "TASK", "confidence": 0.6412626604239146}, {"text": "insult detection", "start_pos": 192, "end_pos": 208, "type": "TASK", "confidence": 0.7957662343978882}, {"text": "personality recognition", "start_pos": 214, "end_pos": 237, "type": "TASK", "confidence": 0.7175563126802444}]}, {"text": "Our evaluation of Emo2Vec shows that it outperforms existing affect-related representations , such as Sentiment-Specific Word Embedding and DeepMoji embeddings with much smaller training corpora.", "labels": [], "entities": []}, {"text": "When concate-nated with GloVe, Emo2Vec achieves competitive performances to state-of-the-art results on several tasks using a simple logistic regression classifier.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent work on word representation has been focusing on embedding syntactic and semantic information into fixed-sized vectors () based on the distributional hypothesis, and have proven to be useful in many natural language tasks).", "labels": [], "entities": [{"text": "word representation", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.7748880088329315}]}, {"text": "However, despite the rising popularity regarding the use of word embeddings, they often fail to capture the emotional semantics the words convey.", "labels": [], "entities": []}, {"text": "For example, the GloVe vector captures the semantic meaning of \"headache\", as it is closer to words of ill symptoms like \"fever\" and \"toothache\", but misses the emotional association that the word carries.", "labels": [], "entities": []}, {"text": "The word \"headache\" in the sentence \"You are giving me a headache\" does not really mean that the speaker will get a headache, but instead implies the negative emotion of the speaker.", "labels": [], "entities": []}, {"text": "To include affective information into the word representation, proposed Sentiment-Specific Word Embeddings (SSWE) which encodes both positive/negative sentiment and syntactic contextual information in a vector space.", "labels": [], "entities": []}, {"text": "This work demonstrates the effectiveness of incorporating sentiment labels in a wordlevel information for sentiment-related tasks compared to other word embeddings.", "labels": [], "entities": []}, {"text": "However, they only focus on binary labels, which weakens their generalization ability on other affect tasks.", "labels": [], "entities": []}, {"text": "instead uses emotion lexicons to tune the vector space, which gives them better results.", "labels": [], "entities": []}, {"text": "Nevertheless, this method requires human-labeled lexicons and cannot scale to large amounts of data.", "labels": [], "entities": []}, {"text": "achieves good results on affect tasks by training a two-layer bidirectional Long Short-Term Memory (bi-LSTM) model, named DeepMoji, to predict emoji of the input document using a huge dataset of 1.2 billions of tweets.", "labels": [], "entities": []}, {"text": "However, collecting billions of tweets is expensive and time consuming for researchers.", "labels": [], "entities": []}, {"text": "Furthermore, most works in sentiment and emotion analysis have focused solely on a single task.", "labels": [], "entities": [{"text": "sentiment and emotion analysis", "start_pos": 27, "end_pos": 57, "type": "TASK", "confidence": 0.9060976207256317}]}, {"text": "Nevertheless, as emotion is a complex concept, we believe that all emotion involving situations such as stress, hate speech, sarcasm, and insult, should be included fora deeper understanding of emotion.", "labels": [], "entities": []}, {"text": "Thus, one way to achieve this is through a multi-task training framework, as we present here.", "labels": [], "entities": []}, {"text": "Contributions: 1) We propose Emo2Vec 1 which are word-level representations that encode emotional semantics into fixed-sized, real-valued vectors.", "labels": [], "entities": []}, {"text": "2) We propose to learn Emo2Vec with a multi-task learning framework by including six different emotion-related tasks.", "labels": [], "entities": []}, {"text": "3) Compared to existing affect-related embeddings, Emo2Vec achieves better results on more than ten datasets with much less training data (1.9M vs 1.2B documents).", "labels": [], "entities": []}, {"text": "Furthermore, with a simple logistic regression classifier, Emo2Vec reaches competitive performance to state-of-the-art results on several", "labels": [], "entities": []}], "datasetContent": [{"text": "We collect a larger dataset from Twitter with hashtags as distant supervision.", "labels": [], "entities": []}, {"text": "Such distant supervision method using hashtags has already been proved to provide reasonably relevant emotion labels by previous works ().We construct our hashtag corpus from, and 2 . More tweets between January and October 2017 are additionally added using the Twitter Firehose API by using the hashtags based on the hierarchy mentioned in.", "labels": [], "entities": []}, {"text": "The hashtags are transformed into corresponding emotion labels of Joy, Sadness, Anger, and Fear.", "labels": [], "entities": [{"text": "Joy", "start_pos": 66, "end_pos": 69, "type": "METRIC", "confidence": 0.9842634797096252}]}, {"text": "When extending the dataset, we only use documents with emotional hashtags at the end and filter out any documents with URLs, quotations, or less than five words as did.", "labels": [], "entities": []}, {"text": "The total number of documents is about 1.9 million with four classes: joy (36.5%), sadness (33.8%), anger (23.5%), and fear (6%).", "labels": [], "entities": [{"text": "joy", "start_pos": 70, "end_pos": 73, "type": "METRIC", "confidence": 0.9486868381500244}]}, {"text": "The dataset is randomly split into a train (70%), validation (15%), and test set (15%) for experiments..", "labels": [], "entities": []}, {"text": "We further include 6 other affect-related datasets.", "labels": [], "entities": []}, {"text": "(1,2) SCv1-GEN and SCv2-GEN for sarcasm detection, (3) Stress (Winata et al., 2018), (4) Abusive.", "labels": [], "entities": [{"text": "sarcasm detection", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.8892815411090851}]}, {"text": "The detailed statistics can be found in and in Supplemental Material.", "labels": [], "entities": [{"text": "Supplemental Material", "start_pos": 47, "end_pos": 68, "type": "DATASET", "confidence": 0.815067857503891}]}, {"text": "Baselines: We use 50-dimension Sentiment-  input document using a huge dataset of 1.2 billion tweets.", "labels": [], "entities": []}, {"text": "Their embedding layer is implicitly encoded with emotion knowledge.", "labels": [], "entities": []}, {"text": "Thus, we use the DeepMoji embedding, the 256-dimension embedding layer of DeepMoji as another baseline.", "labels": [], "entities": []}, {"text": "Evaluation method: To make a fair comparison with other baseline representations, we first take one dataset d i out from n small datasets as the test set.", "labels": [], "entities": []}, {"text": "The remaining n \u2212 1 small datasets and the larger dataset are used to train Emo2Vec through multi-task learning.", "labels": [], "entities": []}, {"text": "We take the trained Emo2Vec as the feature ford i and train a logistic regression on d i to compare the performance with other baseline representations.", "labels": [], "entities": []}, {"text": "The procedure is repeated n times to seethe generalization ability on different datasets.", "labels": [], "entities": []}, {"text": "We release Emo2Vec trained on all datasets.", "labels": [], "entities": []}, {"text": "For sentiment tasks, accuracy score is reported.", "labels": [], "entities": [{"text": "sentiment tasks", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.9249408543109894}, {"text": "accuracy score", "start_pos": 21, "end_pos": 35, "type": "METRIC", "confidence": 0.9780170917510986}]}, {"text": "For other tasks, if it is binary task, we report f1 score for the positive class.", "labels": [], "entities": [{"text": "f1 score", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9057224094867706}]}, {"text": "If it is multiclass classification tasks, we make it binary classification problem for each class and report averaged f1 score.", "labels": [], "entities": [{"text": "multiclass classification tasks", "start_pos": 9, "end_pos": 40, "type": "TASK", "confidence": 0.7451446354389191}]}], "tableCaptions": [{"text": " Table 1: Comparison between different emotion representations on sentiment datasets, all results are reported with  accuracy. The best results are highlighted with bold fonts. Emo2Vec achieves best average score.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.9985094666481018}]}, {"text": " Table 2: Comparison between different representations on other affect related datasets. All results are reported  with f1 score. The best results are highlighted with bold fonts. On average, Emo2Vec achieves best f1 score.", "labels": [], "entities": [{"text": "f1 score", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.9488692581653595}]}, {"text": " Table 2.  Compared with CNN embedding: Emo2Vec  works better than CNN embedding on 14/18  datasets, giving 2.6% absolute accuracy improve- ment for the sentiment task and 1.6% absolute f1- score improvement on the other tasks. It shows  multi-task training helps to create better general- ized word emotion representations than just using  a single task.  Compared with SSWE: Emo2Vec works much  better on all datasets except SS-T datasets, which  gives 3.3% accuracy improvement and 4.7% f1", "labels": [], "entities": [{"text": "14/18  datasets", "start_pos": 84, "end_pos": 99, "type": "DATASET", "confidence": 0.7063055634498596}, {"text": "accuracy improve- ment", "start_pos": 122, "end_pos": 144, "type": "METRIC", "confidence": 0.9397881031036377}, {"text": "absolute f1- score", "start_pos": 177, "end_pos": 195, "type": "METRIC", "confidence": 0.7562428191304207}, {"text": "SS-T datasets", "start_pos": 427, "end_pos": 440, "type": "DATASET", "confidence": 0.8602976500988007}, {"text": "accuracy", "start_pos": 460, "end_pos": 468, "type": "METRIC", "confidence": 0.9972034692764282}]}, {"text": " Table 3: Comparison between different word-level emotion representations with state-of-the-art results. The best  results are in bold. New state-of-the-art results Emo2Vec that achieves are highlighted with boxes.", "labels": [], "entities": []}]}