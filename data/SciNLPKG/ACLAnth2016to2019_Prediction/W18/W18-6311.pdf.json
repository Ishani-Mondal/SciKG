{"title": [{"text": "Contextual Neural Model for Translating Bilingual Multi-Speaker Conversations", "labels": [], "entities": [{"text": "Translating Bilingual Multi-Speaker Conversations", "start_pos": 28, "end_pos": 77, "type": "TASK", "confidence": 0.7816986590623856}]}], "abstractContent": [{"text": "Recent works in neural machine translation have begun to explore document translation.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 16, "end_pos": 42, "type": "TASK", "confidence": 0.7504679560661316}, {"text": "document translation", "start_pos": 65, "end_pos": 85, "type": "TASK", "confidence": 0.7986847162246704}]}, {"text": "However, translating online multi-speaker conversations is still an open problem.", "labels": [], "entities": [{"text": "translating online multi-speaker conversations", "start_pos": 9, "end_pos": 55, "type": "TASK", "confidence": 0.9011069089174271}]}, {"text": "In this work, we propose the task of translating Bilingual Multi-Speaker Conversations, and explore neural architectures which exploit both source and target-side conversation histories for this task.", "labels": [], "entities": [{"text": "translating Bilingual Multi-Speaker Conversations", "start_pos": 37, "end_pos": 86, "type": "TASK", "confidence": 0.8598435670137405}]}, {"text": "To initiate an evaluation for this task, we introduce datasets extracted from Europarl v7 and OpenSubtitles2016.", "labels": [], "entities": [{"text": "Europarl v7", "start_pos": 78, "end_pos": 89, "type": "DATASET", "confidence": 0.9410507082939148}, {"text": "OpenSubtitles2016", "start_pos": 94, "end_pos": 111, "type": "DATASET", "confidence": 0.8330856561660767}]}, {"text": "Our experiments on four language-pairs confirm the significance of leveraging conversation history , both in terms of BLEU and manual evaluation .", "labels": [], "entities": [{"text": "BLEU", "start_pos": 118, "end_pos": 122, "type": "METRIC", "confidence": 0.9995135068893433}]}], "introductionContent": [{"text": "Translating a conversation online is ubiquitous in real life, e.g. in the European Parliament, United Nations, and customer service chats.", "labels": [], "entities": [{"text": "Translating a conversation online", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8706840127706528}]}, {"text": "This scenario involves leveraging the conversation history in multiple languages.", "labels": [], "entities": []}, {"text": "The goal of this paper is to propose and explore a simplified version of such a setting, referred to as Bilingual Multi-Speaker Machine Translation (Bi-MSMT), where speakers' turns in the conversation switch the source and target languages.", "labels": [], "entities": [{"text": "Bilingual Multi-Speaker Machine Translation (Bi-MSMT)", "start_pos": 104, "end_pos": 157, "type": "TASK", "confidence": 0.6895386832101005}]}, {"text": "We investigate neural architectures that exploit the bilingual conversation history for this scenario, which is a challenging problem as the history consists of utterances in both languages.", "labels": [], "entities": []}, {"text": "The ultimate aim of all machine translation systems for dialogue is to enable a multi-lingual conversation between multiple speakers.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.7397488653659821}]}, {"text": "However, translation of such conversations is not wellexplored in the literature.", "labels": [], "entities": [{"text": "translation", "start_pos": 9, "end_pos": 20, "type": "TASK", "confidence": 0.9850912094116211}]}, {"text": "Recently, there has been work focusing on using the discourse or document context to improve NMT, in an online setting, by using the past context (, and in an offline setting, using the past and future context.", "labels": [], "entities": [{"text": "NMT", "start_pos": 93, "end_pos": 96, "type": "TASK", "confidence": 0.9147768616676331}]}, {"text": "In this paper, we design and evaluate a conversational Bi-MSMT model, where we incorporate the source and target-side conversation histories into a sentence-based attentional model (.", "labels": [], "entities": []}, {"text": "Here, the source history comprises of sentences in the original language for both languages, and the target history consists of their corresponding translations.", "labels": [], "entities": []}, {"text": "We experiment with different ways of computing the source context representation for this task.", "labels": [], "entities": []}, {"text": "Furthermore, we present an effective approach to leverage the target-side context, and also present an intuitive approach for incorporating both contexts simultaneously.", "labels": [], "entities": []}, {"text": "To evaluate this task, we introduce datasets extracted from Europarl v7 and OpenSubtitles2016, containing speaker information.", "labels": [], "entities": [{"text": "Europarl v7", "start_pos": 60, "end_pos": 71, "type": "DATASET", "confidence": 0.9359420239925385}, {"text": "OpenSubtitles2016", "start_pos": 76, "end_pos": 93, "type": "DATASET", "confidence": 0.8017258048057556}]}, {"text": "Our experiments on English-French, English-Estonian, EnglishGerman and English-Russian language-pairs show improvements of +1.44, +1.16, +1.75 and +0.30 BLEU, respectively, for our best model over the context-free baseline.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 153, "end_pos": 157, "type": "METRIC", "confidence": 0.9980120658874512}]}, {"text": "The results show the impact of conversation history on translation of bilingual multi-speaker conversations and can be used as benchmark for future work on this task.", "labels": [], "entities": [{"text": "translation of bilingual multi-speaker conversations", "start_pos": 55, "end_pos": 107, "type": "TASK", "confidence": 0.7825902342796326}]}], "datasetContent": [{"text": "Implementation and Hyperparameters We implement our conversational Bi-MSMT model in C++ using the DyNet library ().", "labels": [], "entities": []}, {"text": "The base model is built using mantis (  which is an implementation of the generic sentence-level NMT model using DyNet.", "labels": [], "entities": []}, {"text": "The base model has single layer bidirectional GRUs in the encoder and 2-layer GRU in the decoder 8 . The hidden dimensions and word embedding sizes are set to 256, and the alignment dimension (for the attention mechanism in the decoder) is set to 128.", "labels": [], "entities": [{"text": "alignment dimension", "start_pos": 172, "end_pos": 191, "type": "METRIC", "confidence": 0.949434757232666}]}, {"text": "Training For the base model, we make use of stochastic gradient descent (SGD) with initial learning rate of 0.1 and a decay factor of 0.5 after the fifth epoch fora total of 15 epochs.", "labels": [], "entities": [{"text": "initial learning rate", "start_pos": 83, "end_pos": 104, "type": "METRIC", "confidence": 0.8103365500768026}]}, {"text": "For the contextual model, we use SGD with an initial learning rate of 0.08 and a decay factor of 0.9 after the first epoch fora total of 30 epochs.", "labels": [], "entities": []}, {"text": "To avoid overfitting, we employ dropout and set its rate to 0.2.", "labels": [], "entities": []}, {"text": "To reduce the training time of our contextual model, we perform computation of one turn at a time, for instance, when using the source context, we run the Turn-RNNs for previous turns once and re-run the Turn-RNN only for sentences in the current turn.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: General statistics for training set.", "labels": [], "entities": []}, {"text": " Table 2: BLEU scores for the bilingual test sets. Here all contexts are incorporated as InitDec for Europarl and  InitDec+AddDec for Subtitles unless otherwise specified. bold: Best performance,  \u2020: Statistically significantly  better than the base model, based on bootstrap resampling", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9994377493858337}, {"text": "Europarl", "start_pos": 101, "end_pos": 109, "type": "DATASET", "confidence": 0.9783865213394165}]}, {"text": " Table 3: BLEU scores for the bilingual test sets. bold:  Best performance,  \u2020: Statistically significantly better  than the contextual baseline.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9991387128829956}]}, {"text": " Table 4: BLEU scores for En-De bilingual test set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9990692734718323}, {"text": "En-De bilingual test set", "start_pos": 26, "end_pos": 50, "type": "DATASET", "confidence": 0.7649197801947594}]}, {"text": " Table 8: General statistics for development and test  sets.", "labels": [], "entities": []}]}