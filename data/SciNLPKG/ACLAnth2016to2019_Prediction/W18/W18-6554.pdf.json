{"title": [{"text": "Characterizing Variation in Crowd-Sourced Data for Training Neural Language Generators to Produce Stylistically Varied Outputs", "labels": [], "entities": []}], "abstractContent": [{"text": "One of the biggest challenges of end-to-end language generation from meaning representations in dialogue systems is making the outputs more natural and varied.", "labels": [], "entities": [{"text": "end-to-end language generation", "start_pos": 33, "end_pos": 63, "type": "TASK", "confidence": 0.7319676876068115}]}, {"text": "Here we take a large corpus of 50K crowd-sourced utterances in the restaurant domain and develop text analysis methods that systematically characterize types of sentences in the training data.", "labels": [], "entities": []}, {"text": "We then automatically label the training data to allow us to conduct two kinds of experiments with a neural generator.", "labels": [], "entities": []}, {"text": "First, we test the effect of training the system with different stylistic partitions and quantify the effect of smaller, but more stylistically controlled training data.", "labels": [], "entities": []}, {"text": "Second, we propose a method of labeling the style variants during training, and show that we can modify the style of the generated utterances using our stylistic labels.", "labels": [], "entities": []}, {"text": "We contrast and compare these methods that can be used with any existing large corpus, showing how they vary in terms of semantic quality and stylistic control.", "labels": [], "entities": []}], "introductionContent": [{"text": "Dialogue systems have become one of the key applications in natural language processing, but there are still many ways in which these systems can be improved.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 60, "end_pos": 87, "type": "TASK", "confidence": 0.651991218328476}]}, {"text": "One obvious possible improvement is in the system's language generation to make it more natural and more varied.", "labels": [], "entities": []}, {"text": "Both a benefit and a challenge of neural natural language generation (NLG) models is that they are very good at reducing noise in the training data.", "labels": [], "entities": [{"text": "neural natural language generation (NLG)", "start_pos": 34, "end_pos": 74, "type": "TASK", "confidence": 0.8288492390087673}]}, {"text": "When they are trained on a sufficiently large dataset, they learn to generalize and become capable of applying the acquired knowledge to unseen inputs.", "labels": [], "entities": []}, {"text": "The more data the models are trained on, the more robust they become, which minimizes the effect of noise in the data on their learning.", "labels": [], "entities": []}, {"text": "However, the higher amount of training data can also drown out interesting stylistic features and variations that may not be very frequent in the data.", "labels": [], "entities": []}, {"text": "In other words, the model, being statistical, will prefer producing the most common sentence structures, i.e. those which it observed most frequently in the training data and is thus most confident about.", "labels": [], "entities": []}, {"text": "In our work, we consider language generators whose inputs are structured meaning representations (MRs) describing a list of key concepts to be conveyed to the human user during the dialogue.", "labels": [], "entities": []}, {"text": "Each piece of information is represented by a slotvalue pair, where the slot identifies the type of information and the value is the corresponding content.", "labels": [], "entities": []}, {"text": "A language generator must produce a syntactically and semantically correct utterance from a given MR.", "labels": [], "entities": []}, {"text": "The utterance should express all the information contained in the MR, in a natural and conversational way.", "labels": [], "entities": [{"text": "MR", "start_pos": 66, "end_pos": 68, "type": "DATASET", "confidence": 0.6700774431228638}]}, {"text": "shows an example MR fora restaurant called \"The Waterman\" paired with two (out of many) possible output utterances, the first of which might be considered stylistically interesting, since the name of the restaurant follows some aspects of the description and contains a concession, while the second example might be considered as more stylistically conventional.", "labels": [], "entities": []}, {"text": "Recently, the size of training corpora for NLG has become larger, and these same corpora have begun to manifest interesting stylistic variations.", "labels": [], "entities": []}, {"text": "Here we start from the recently released E2E dataset () with nearly 50K samples of crowd-sourced utterances in the restaurant domain provided as part of the E2E NLG Challenge.", "labels": [], "entities": [{"text": "E2E dataset", "start_pos": 41, "end_pos": 52, "type": "DATASET", "confidence": 0.9401274621486664}, {"text": "E2E NLG Challenge", "start_pos": 157, "end_pos": 174, "type": "DATASET", "confidence": 0.8202715714772543}]}, {"text": "We first develop text analysis methods that systematically characterize types of sen-MR name, food, priceRange, customer rating, area [city centre], familyFriendly Utt.", "labels": [], "entities": [{"text": "familyFriendly Utt", "start_pos": 149, "end_pos": 167, "type": "DATASET", "confidence": 0.8213768899440765}]}, {"text": "#1 There is a cheap, family-friendly restaurant in the city centre, called The Waterman.", "labels": [], "entities": [{"text": "The Waterman", "start_pos": 75, "end_pos": 87, "type": "DATASET", "confidence": 0.615055650472641}]}, {"text": "It serves English food, but received a low rating by customers.", "labels": [], "entities": []}], "datasetContent": [{"text": "We perform the stylistic selection on the E2E dataset (.", "labels": [], "entities": [{"text": "E2E dataset", "start_pos": 42, "end_pos": 53, "type": "DATASET", "confidence": 0.9842011630535126}]}, {"text": "It is by far the largest dataset available for task-oriented language generation in the restaurant domain.", "labels": [], "entities": [{"text": "task-oriented language generation", "start_pos": 47, "end_pos": 80, "type": "TASK", "confidence": 0.7310286164283752}]}, {"text": "It offers almost 10 times more data than the San Francisco restaurant dataset, which had frequently been used for NLG benchmarks.", "labels": [], "entities": [{"text": "San Francisco restaurant dataset", "start_pos": 45, "end_pos": 77, "type": "DATASET", "confidence": 0.578432634472847}]}, {"text": "This significant increase in size allows successful training of neural models on smaller subsets of the dataset.", "labels": [], "entities": []}, {"text": "Careful selection of the training subset can be used to influence the style of the utterances produced by the model, as we show in this paper.", "labels": [], "entities": []}, {"text": "A portion of the human reference utterances: Average number of sentences in the reference utterance fora given number of slots in the corresponding MR, along with the proportion of MRs with specific slot counts. was collected using pictures as the source of information, which was shown to inspire more natural utterances compared to textual MRs (.", "labels": [], "entities": []}, {"text": "The reference utterances in the E2E dataset exhibit superior lexical richness and syntactic variation, including more complex discourse phenomena.", "labels": [], "entities": [{"text": "E2E dataset", "start_pos": 32, "end_pos": 43, "type": "DATASET", "confidence": 0.9526905119419098}]}, {"text": "It aims to provide higherquality training data for end-to-end NLG systems to learn to produce better phrased and more naturally sounding utterances.", "labels": [], "entities": []}, {"text": "Although the E2E dataset contains a large number of samples, each MR is associated on average with more than 8 different reference utterances, effectively supplying almost 5K unique MRs in the training set).", "labels": [], "entities": [{"text": "E2E dataset", "start_pos": 13, "end_pos": 24, "type": "DATASET", "confidence": 0.9609676897525787}]}, {"text": "It thus offers multiple alternative ways of expressing the same information in an utterance, which the model can learn.", "labels": [], "entities": []}, {"text": "We take advantage of this aspect of the dataset when selecting the subset of samples for training with a particular purpose of stylistic variation.", "labels": [], "entities": []}, {"text": "The dataset contains 8 different slot types, which are fairly equally distributed in the dataset.", "labels": [], "entities": []}, {"text": "Each MR comprises 3 to 8 slots, whereas the majority of MRs consist of 5 and 6 slots.", "labels": [], "entities": []}, {"text": "Even though most of the MRs contain many slots, the majority of the corresponding human utterances consist of one or two sentences only, suggesting a reasonably high level of sentence complexity in the references.", "labels": [], "entities": []}, {"text": "This section gives an overview of different discourse phenomena in the E2E dataset that we consider relevant in the context of a task-oriented dialogue in the restaurant domain.", "labels": [], "entities": [{"text": "E2E dataset", "start_pos": 71, "end_pos": 82, "type": "DATASET", "confidence": 0.9484110474586487}]}, {"text": "The majority of   For our sequence-to-sequence NLG model we use the standard encoder-decoder () architecture equipped with an attention mechanism as defined in.", "labels": [], "entities": []}, {"text": "The samples are delexicalized before being fed into the model as input, so as to enhance the ability of the model to generalize the learned concepts to unseen MRs.", "labels": [], "entities": []}, {"text": "We only delexicalize categorical slots whose values always propagate verbatim from the MR to the utterance.", "labels": [], "entities": []}, {"text": "The corresponding values in the input MR get thus replaced with placeholder tokens for which the values from the original MR are eventually substituted in the output utterance as apart of post-processing.", "labels": [], "entities": []}, {"text": "We use a 4-layer bidirectional LSTM (Hochreiter and Schmidhuber, 1997) encoder and a 4-layer LSTM decoder, both with 512 cells per layer.", "labels": [], "entities": []}, {"text": "During inference time, we use beam search with the beam width of 10 and length normalization of the beams as defined in.", "labels": [], "entities": []}, {"text": "The length penalty that we determined was providing the best results on the E2E dataset was 0.6.", "labels": [], "entities": [{"text": "length", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9940276145935059}, {"text": "E2E dataset", "start_pos": 76, "end_pos": 87, "type": "DATASET", "confidence": 0.9835634529590607}]}, {"text": "The beam search candidates are reranked using a heuristic slot aligner as described in, and the top candidate is returned as the final utterance.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Number of samples vs. unique meaning  representations in the training, validation and test  set of the E2E dataset.", "labels": [], "entities": [{"text": "E2E dataset", "start_pos": 113, "end_pos": 124, "type": "DATASET", "confidence": 0.9357636272907257}]}, {"text": " Table 3: Average number of sentences in the ref- erence utterance for a given number of slots in the  corresponding MR, along with the proportion of  MRs with specific slot counts.", "labels": [], "entities": []}, {"text": " Table 6: The weighting schema for different discourse markers for each introduced category of discourse  phenomena.", "labels": [], "entities": []}, {"text": " Table 9: Comparison of the emphasis realization  success rate (precision) and the slot realization er- ror rate in the generated outputs using data an- notation against the reference utterances, as well  as the outputs of the same model trained on non- annotated data.", "labels": [], "entities": [{"text": "precision", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.9844990372657776}, {"text": "slot realization er- ror rate", "start_pos": 83, "end_pos": 112, "type": "METRIC", "confidence": 0.896705279747645}]}]}