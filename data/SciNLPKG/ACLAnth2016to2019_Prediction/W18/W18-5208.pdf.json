{"title": [{"text": "Argument Component Classification for Classroom Discussions", "labels": [], "entities": [{"text": "Argument Component Classification", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7474152743816376}]}], "abstractContent": [{"text": "This paper focuses on argument component classification for transcribed spoken classroom discussions, with the goal of automatically classifying student utterances into claims, evidence , and warrants.", "labels": [], "entities": [{"text": "argument component classification", "start_pos": 22, "end_pos": 55, "type": "TASK", "confidence": 0.6497512956460317}]}, {"text": "We show that an existing method for argument component classification developed for another educationally-oriented domain performs poorly on our dataset.", "labels": [], "entities": [{"text": "argument component classification", "start_pos": 36, "end_pos": 69, "type": "TASK", "confidence": 0.7055632472038269}]}, {"text": "We then show that feature sets from prior work on argument mining for student essays and online dialogues can be used to improve performance considerably.", "labels": [], "entities": [{"text": "argument mining for student essays and online dialogues", "start_pos": 50, "end_pos": 105, "type": "TASK", "confidence": 0.7534620016813278}]}, {"text": "We also provide a comparison between convolutional neural networks and recurrent neural networks when trained under different conditions to classify argument components in classroom discussions.", "labels": [], "entities": []}, {"text": "While neu-ral network models are not always able to out-perform a logistic regression model, we were able to gain some useful insights: convolu-tional networks are more robust than recurrent networks both at the character and at the word level, and specificity information can help boost performance in multi-task training.", "labels": [], "entities": []}], "introductionContent": [{"text": "Although there is no universally agreed upon definition, argument mining is an area of natural language processing which aims to extract structured knowledge from free-form unstructured language.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 57, "end_pos": 72, "type": "TASK", "confidence": 0.8565185070037842}]}, {"text": "In particular, argument mining systems are built with goals such as: detecting what parts of a text express an argument component, known as argument component identification; categorizing arguments into different component types (e.g. claim, evidence), known as argument component classification; understanding if/how different components are connected to form an argumentative structure (e.g. using evidence to support/attack a claim), known as argument relation identification.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 15, "end_pos": 30, "type": "TASK", "confidence": 0.8189145624637604}, {"text": "argument component identification", "start_pos": 140, "end_pos": 173, "type": "TASK", "confidence": 0.6690117915471395}, {"text": "argument component classification; understanding if/how different components are connected to form an argumentative structure (e.g. using evidence to support/attack a claim", "start_pos": 262, "end_pos": 434, "type": "Description", "confidence": 0.7195639466797864}, {"text": "argument relation identification", "start_pos": 446, "end_pos": 478, "type": "TASK", "confidence": 0.5606385171413422}]}, {"text": "The development and release to the public of corpora and annotations in recent years have contributed to the increasing interest in the area.", "labels": [], "entities": []}, {"text": "One domain in which argument mining is rarely found in the literature is educational discussions.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 20, "end_pos": 35, "type": "TASK", "confidence": 0.8905946314334869}]}, {"text": "Classroom discussions area part of students' daily life, and they area common pedagogical approach for enhancing student skills.", "labels": [], "entities": []}, {"text": "For example, studentcentered classroom discussions are an important contributor to the development of students' reading, writing, and reasoning skills in the context of English Language Arts (ELA) classes.", "labels": [], "entities": []}, {"text": "This impact is reflected in students' problem solving and disciplinary skills.", "labels": [], "entities": [{"text": "problem solving", "start_pos": 38, "end_pos": 53, "type": "TASK", "confidence": 0.8243629932403564}]}, {"text": "With the increasing importance of argumentation in classrooms, especially in the context of studentcentered discussions, automatically performing argument component classification is a first step for building tools aimed at helping teachers analyze and better understand student arguments, with the goal of improving students' learning outcomes.", "labels": [], "entities": [{"text": "argument component classification", "start_pos": 146, "end_pos": 179, "type": "TASK", "confidence": 0.7291757067044576}]}, {"text": "Many current argument mining systems focus on analyzing argumentation in student essays, online dialogues (, or in the legal domain.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 13, "end_pos": 28, "type": "TASK", "confidence": 0.8331765234470367}, {"text": "analyzing argumentation in student essays", "start_pos": 46, "end_pos": 87, "type": "TASK", "confidence": 0.7019140958786011}]}, {"text": "A key difference between these studies and our work consists in the source of linguistic content: although we analyze written transcriptions of discussions, the original source for our corpora consists of spoken, multi-party, educational discussions, and the difference in cognitive skills and grammatical structure between written and spoken language introduces additional complexity.", "labels": [], "entities": []}, {"text": "Our work and previous research studies on student essays share the trait of analyzing argumentation in an educational context.", "labels": [], "entities": []}, {"text": "However, while student essays are typically written by an individual student, in classroom discussions arguments are formed collaboratively between multiple parties (i.e. multiple students and possibly teachers).", "labels": [], "entities": []}, {"text": "While our work shares the multi-party context in which arguments are made with research aimed at argument mining in online dialogues, prior online dialogue studies have not been contextualized in the educational domain.", "labels": [], "entities": [{"text": "argument mining in online dialogues", "start_pos": 97, "end_pos": 132, "type": "TASK", "confidence": 0.7301429808139801}]}, {"text": "Given these differences, we believe that argument mining models for student essays and online dialogues will perform poorly when directly applied to educational discussions.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 41, "end_pos": 56, "type": "TASK", "confidence": 0.7203308492898941}]}, {"text": "However, since similarities between the domains do exist, we expect that features exploited by such argument mining models can help us in classifying argument components in classroom discussions.", "labels": [], "entities": []}, {"text": "Moreover, unlike the other two domains, we have access to labels belonging to a different (but related) class, specificity, which we can try to incorporate in argumentation models to boost performance.", "labels": [], "entities": []}, {"text": "Our contributions are as follows.", "labels": [], "entities": []}, {"text": "We first experimentally evaluate the performance of an existing argument mining system developed for essay scoring (named wLDA) when applied off-the-shelf to predict argument component labels for transcribed classroom discussions.", "labels": [], "entities": [{"text": "essay scoring", "start_pos": 101, "end_pos": 114, "type": "TASK", "confidence": 0.6764928549528122}]}, {"text": "We then analyze the performance obtained when using the same features as wLDA to train a classifier specifically on our dataset.", "labels": [], "entities": []}, {"text": "We combine the wLDA feature set with features used in argument mining in the context of online dialogues and show that they are able to capture some of the similarities between online dialogues and our domain, and considerably improve the model.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 54, "end_pos": 69, "type": "TASK", "confidence": 0.7479634881019592}]}, {"text": "We then evaluate two neural network models in several different scenarios pertaining to their input modality, the inclusion of handcrafted features, and the effect of multi-task learning when including specificity information.", "labels": [], "entities": []}], "datasetContent": [{"text": "We collected 73 transcripts of text-based classroom discussions, i.e. discussions centered on a text or literature piece (e.g. play, speech, book), for ELA high school level classes.", "labels": [], "entities": [{"text": "ELA high school level", "start_pos": 152, "end_pos": 173, "type": "TASK", "confidence": 0.6527984887361526}]}, {"text": "Some of the transcripts were gathered from published articles and dissertations, while the rest originated from videos which were transcribed by one of our annotators (see below).", "labels": [], "entities": []}, {"text": "While detailed demographic information for students participating in each discussion was not available, our dataset consists of a mix of small group (16 out of 73) versus whole class (57/73) discussions, both teacher-mediated (64/73) versus student only (9/73).", "labels": [], "entities": []}, {"text": "Additionally, the discussions originated in urban schools (28/73), suburban schools (42/73), and schools located in small towns (3/73).", "labels": [], "entities": []}, {"text": "The unit of analysis for our work is argument move, which consists of a segment of text containing an argumentative discourse unit (ADU).", "labels": [], "entities": []}, {"text": "Starting with transcripts broken down into turns at talk, an expert annotator segmented turns at talk into multiple argument moves when necessary: turns at talk containing multiple ADUs have been segmented into several argument moves, each consisting of a single ADU.", "labels": [], "entities": []}, {"text": "Turn segmentation effectively corresponds to argument component identification, and it is carried out manually.", "labels": [], "entities": [{"text": "Turn segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7567709982395172}, {"text": "argument component identification", "start_pos": 45, "end_pos": 78, "type": "TASK", "confidence": 0.6510042548179626}]}, {"text": "We conducted a reliability study on turn segmentation with two annotators on a subset of the dataset consisting of 53 transcripts.", "labels": [], "entities": [{"text": "turn segmentation", "start_pos": 36, "end_pos": 53, "type": "TASK", "confidence": 0.9117534756660461}]}, {"text": "The reliability analysis resulted in Krippendorff \u03b1 U = 0.952, which shows that turns at talk can be reliably segmented.", "labels": [], "entities": [{"text": "Krippendorff \u03b1 U", "start_pos": 37, "end_pos": 53, "type": "METRIC", "confidence": 0.796745498975118}]}, {"text": "After segmentation, the data was manually annotated to capture two aspects of classroom talk, argument component and specificity, using the ELA classroom-oriented annotation scheme developed by.", "labels": [], "entities": []}, {"text": "The argument component types in this scheme, which is based on the Toulmin model, are: (i) Claim: an arguable statement that presents a particular interpretation of a text or topic.", "labels": [], "entities": []}, {"text": "(ii) Evidence 1 : facts, documentation, text reference, or testimony used to support or justify a claim.", "labels": [], "entities": []}, {"text": "(iii) Warrant: rea-sons explaining how a specific evidence instance supports a specific claim.", "labels": [], "entities": []}, {"text": "Chisholm and Godley (2011) observed how specificity has an impact on the quality of the discussion, while noted that a relationship exists between specificity and the quality of arguments in online forum dialogues.", "labels": [], "entities": []}, {"text": "For the purpose of investigating whether there exists a relationship between specificity and argument components, we additionally annotated data for specificity following the same coding scheme (.", "labels": [], "entities": []}, {"text": "Specificity labels are directly related to four elements for an argument move: (1) it is specific to one (or a few) character or scene; (2) it makes significant qualifications or elaborations; (3) it uses content-specific vocabulary (e.g. quotes from the text); (4) it provides a chain of reasons.", "labels": [], "entities": [{"text": "Specificity labels", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8722201883792877}]}, {"text": "The specificity annotation scheme by Lugini et al. includes three labels along a linear scale: (i) Low: statement that does not contain any of these elements.", "labels": [], "entities": []}, {"text": "(ii) Medium: statement that accomplishes one of these elements.", "labels": [], "entities": []}, {"text": "(iii) High: statement that clearly accomplishes at least two specificity elements.", "labels": [], "entities": []}, {"text": "Only student turns were considered for annotations; teacher turns at talk were filtered out and do not appear in the final dataset.", "labels": [], "entities": []}, {"text": "shows a coded excerpt of a transcript from a discussion about the movie Princess Bride.", "labels": [], "entities": []}, {"text": "The resulting dataset consists of 2047 argument moves from 73 discussions.", "labels": [], "entities": []}, {"text": "As we can see from the label distribution shown in, students produced a high number of claims, while warrant is the minority class.", "labels": [], "entities": []}, {"text": "We can also observe a class imbalance for specificity labels, though the ratio between majority and minority classes is lower than that for argument component labels.", "labels": [], "entities": []}, {"text": "We evaluated inter-rater reliability on a subset of our dataset composed of 1049 argument moves from 50 discussions double-coded by two annotators.", "labels": [], "entities": [{"text": "reliability", "start_pos": 25, "end_pos": 36, "type": "METRIC", "confidence": 0.8168395161628723}]}, {"text": "Cohen's unweighted kappa for argument component labels was 0.629, while quadraticweighted kappa for specificity labels (since they are ordered) was 0.641, which shows substantial agreement.", "labels": [], "entities": []}, {"text": "The average number of argument moves among the discussions is 27.3 while the standard deviation is 25.6, which shows a high variability in discussion length.", "labels": [], "entities": []}, {"text": "The average number of words per argument move and standard deviation are 22.6 and 22.1, respectively, which also shows large variability in how much students speak.", "labels": [], "entities": [{"text": "standard", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9812628626823425}]}, {"text": "This section provides our experimental results.", "labels": [], "entities": []}, {"text": "In Section 5.1 we will test our first hypothesis: using an argument mining system trained in a different domain will result in low performance, which can be improved by re-training on classroom discussions and by adding new features.", "labels": [], "entities": [{"text": "argument mining", "start_pos": 59, "end_pos": 74, "type": "TASK", "confidence": 0.7204428166151047}]}, {"text": "Section 5.2 will be used to test our second hypothesis: neural network models can automatically extract important features for argument component classification.", "labels": [], "entities": [{"text": "argument component classification", "start_pos": 127, "end_pos": 160, "type": "TASK", "confidence": 0.6553917825222015}]}, {"text": "Our third hypothesis will be tested in Section 5.3: adding handcrafted features (i.e. online dialogue features, wLDA features) to the ones automatically extracted by neural networks will result in an increase of performance.", "labels": [], "entities": []}, {"text": "Lastly, we will test our fourth hypothesis in Section 5.4: jointly learning to predict argument component type and specificity will result in more robust models and achieve a further performance improvement.", "labels": [], "entities": []}, {"text": "Our experiments evaluate every model using a leave-one-transcript-out cross validation: each fold contains one transcript as test set and the remaining 72 as training set.", "labels": [], "entities": []}, {"text": "Cohen kappa, and unweighted precision, recall, and f-score were used as evaluation metrics.", "labels": [], "entities": [{"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9798191785812378}, {"text": "recall", "start_pos": 39, "end_pos": 45, "type": "METRIC", "confidence": 0.9988589286804199}, {"text": "f-score", "start_pos": 51, "end_pos": 58, "type": "METRIC", "confidence": 0.982700526714325}]}, {"text": "The following python libraries were used for implementing and testing the different models: Scikit-learn), Tensorflow (,), NLTK (.", "labels": [], "entities": []}, {"text": "Given that in our dataset warrants appear much less frequently than claims and evidence, data imbalance is a problem we need to address.", "labels": [], "entities": []}, {"text": "If trained naively, the limited amount of training data and the unbalanced class distribution lead the neural network models to specialize towards claims and evidence, with much weaker performance on warrants.", "labels": [], "entities": []}, {"text": "This is also the case for non neural network models, although the impact on performance is lower.", "labels": [], "entities": []}, {"text": "To combat this phenomenon we decided to use oversampling () in order to create a balanced dataset, hoping to further reduce the performance gap between the different classes 3 . After computing the class frequency distribution on the training set, we randomly sampled moves from the two minority classes and added them to the current training set, repeating the process until the class distribution was completely balanced (i.e. until the number of argument moves for each class equals the number of moves in the majority class) , while the test set was unchanged.", "labels": [], "entities": []}, {"text": "shows the results for all experiments.", "labels": [], "entities": []}, {"text": "The statistical significance results in the table use the system in row 3 as the comparison baseline, as wLDA represents a system specifically designed for argument component classification (among other tasks).", "labels": [], "entities": [{"text": "argument component classification", "start_pos": 156, "end_pos": 189, "type": "TASK", "confidence": 0.6634330749511719}]}, {"text": "Additional statistical comparisons are provided in the text as well.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Coded excerpt of a discussion of the movie Princess Bride. Student S1 first makes a claim about  Fezzik's behavior, then provides evidence by listing a series of events, then connects such events to his  claim using a warrant. As the argument progresses, the specificity level increases.", "labels": [], "entities": []}, {"text": " Table 2: Distribution of class labels for argument  component type and specificity in our dataset.", "labels": [], "entities": []}, {"text": " Table 3: Results obtained with the baseline model/features and the proposed neural network models using  different feature sets. Each line represents the average of a transcript-wise cross validation. Best results  are in bold. ,  \u2020 , and  \u2021 indicate statistical significance at the 0.1, 0.05, and 0.01 levels respectively,  compared to the model in row 3. The three right-most columns represent per-class F-score for evidence,  warrants, and claims respectively.", "labels": [], "entities": [{"text": "F-score", "start_pos": 407, "end_pos": 414, "type": "METRIC", "confidence": 0.9125468730926514}]}]}