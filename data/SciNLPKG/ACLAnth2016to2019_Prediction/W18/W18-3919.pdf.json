{"title": [{"text": "Character Level Convolutional Neural Network for German Dialect Identification", "labels": [], "entities": [{"text": "German Dialect Identification", "start_pos": 49, "end_pos": 78, "type": "TASK", "confidence": 0.5716206530729929}]}], "abstractContent": [{"text": "This paper presents the systems submitted by the safina team to the German Dialect Identification (GDI) shared task at the VarDial Evaluation Campaign 2018.", "labels": [], "entities": [{"text": "German Dialect Identification (GDI) shared task at the VarDial Evaluation Campaign 2018", "start_pos": 68, "end_pos": 155, "type": "TASK", "confidence": 0.6687442894492831}]}, {"text": "The GDI shared task included four German dialects: Basel, Bern, Lucerne and Zurich in addition to a fifth \"surprise dialect\" for which no training data is available.", "labels": [], "entities": []}, {"text": "The proposed approach is to use character-level convo-lution neural network to distinguish the four dialects.", "labels": [], "entities": []}, {"text": "We submitted three models with the same architecture except for the first layer.", "labels": [], "entities": []}, {"text": "The first system uses one-hot character representation as input to the convolution layer.", "labels": [], "entities": []}, {"text": "The second system uses an embedding layer before the convolu-tion layer.", "labels": [], "entities": []}, {"text": "The third system uses a recurrent layer before the convolution layer.", "labels": [], "entities": []}, {"text": "The best results were obtained using the third model achieving 64.49% F1-score, ranked the second among eight teams.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9993336796760559}]}], "introductionContent": [{"text": "German language has different national and regional variants.", "labels": [], "entities": []}, {"text": "Standard national varieties spoken in Germany, Austria, and Switzerland co-exist with a number of dialects spoken in everyday communication.", "labels": [], "entities": []}, {"text": "The German Dialect Identification task is concerned with identifying the specific German dialect in a written form.", "labels": [], "entities": [{"text": "German Dialect Identification task", "start_pos": 4, "end_pos": 38, "type": "TASK", "confidence": 0.6943204924464226}]}, {"text": "The German Dialect Identification was part of the VarDial Evaluation Campaign 2017 and it attracted many researchers, since 10 teams have participated in that task ( . That task included Swiss German dialects from four areas: Basel, Bern, Lucerne and Zurich and the goal was to train a model to detect the dialect using speech transcript.", "labels": [], "entities": [{"text": "German Dialect Identification", "start_pos": 4, "end_pos": 33, "type": "TASK", "confidence": 0.6629341840744019}, {"text": "VarDial Evaluation Campaign 2017", "start_pos": 50, "end_pos": 82, "type": "DATASET", "confidence": 0.8280126303434372}]}, {"text": "In this paper we present the safina team's submissions for the 2018 GDI shared task which was organized as apart of Vardial Evaluation Campaign 2018 (.", "labels": [], "entities": [{"text": "GDI shared task", "start_pos": 68, "end_pos": 83, "type": "TASK", "confidence": 0.5731104016304016}, {"text": "Vardial Evaluation Campaign 2018", "start_pos": 116, "end_pos": 148, "type": "DATASET", "confidence": 0.8062985241413116}]}, {"text": "In this year version, the organizers added a fifth \"surprise dialect\" for which no training data is available.", "labels": [], "entities": []}, {"text": "The participants could take part in two sub-tracks: the four-way classification (without surprise dialect) and the five-way classification (with surprise dialect).", "labels": [], "entities": []}, {"text": "We have participated in the four-way track only.", "labels": [], "entities": []}, {"text": "We have used a Character-level Convolutional Neural Network approach to identify German dialects using lexical features.", "labels": [], "entities": []}, {"text": "Our team ranked the second with F1-weighted score 64.49%.", "labels": [], "entities": [{"text": "F1-weighted score", "start_pos": 32, "end_pos": 49, "type": "METRIC", "confidence": 0.9828693866729736}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Our three runs results, the best run in bold", "labels": [], "entities": []}]}