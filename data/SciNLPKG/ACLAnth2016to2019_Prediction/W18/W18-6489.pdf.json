{"title": [{"text": "NICT's Corpus Filtering Systems for the WMT18 Parallel Corpus Filtering Task", "labels": [], "entities": [{"text": "NICT", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8986185789108276}, {"text": "WMT18 Parallel Corpus Filtering", "start_pos": 40, "end_pos": 71, "type": "TASK", "confidence": 0.7016323655843735}]}], "abstractContent": [{"text": "This paper presents the NICT's participation in the WMT18 shared parallel corpus filtering task.", "labels": [], "entities": [{"text": "WMT18 shared parallel corpus filtering task", "start_pos": 52, "end_pos": 95, "type": "TASK", "confidence": 0.7341117362181345}]}, {"text": "The organizers provided 1 billion words German-English corpus crawled from the web as part of the Paracrawl project.", "labels": [], "entities": []}, {"text": "This corpus is too noisy to build an acceptable neural machine translation (NMT) system.", "labels": [], "entities": [{"text": "neural machine translation (NMT)", "start_pos": 48, "end_pos": 80, "type": "TASK", "confidence": 0.8186038037141165}]}, {"text": "Using the clean data of the WMT18 shared news translation task, we designed several features and trained a classifier to score each sentence pairs in the noisy data.", "labels": [], "entities": [{"text": "WMT18 shared news translation task", "start_pos": 28, "end_pos": 62, "type": "TASK", "confidence": 0.8402984261512756}]}, {"text": "Finally, we sampled 100 million and 10 million words and built corresponding NMT systems.", "labels": [], "entities": []}, {"text": "Empirical results show that our NMT systems trained on sampled data achieve promising performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes the corpus filtering system built for the participation of the National Institute of Information and Communications Technology (NICT) to the WMT18 shared parallel corpus filtering task.", "labels": [], "entities": [{"text": "corpus filtering", "start_pos": 25, "end_pos": 41, "type": "TASK", "confidence": 0.7715200483798981}, {"text": "WMT18 shared parallel corpus filtering task", "start_pos": 162, "end_pos": 205, "type": "TASK", "confidence": 0.8032771646976471}]}, {"text": "NMT has shown large gains in quality over Statistical machine translation (SMT) and set several new benchmarks.", "labels": [], "entities": [{"text": "NMT", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7700656652450562}, {"text": "Statistical machine translation (SMT)", "start_pos": 42, "end_pos": 79, "type": "TASK", "confidence": 0.8319349388281504}]}, {"text": "However, NMT is much more sensitive to domain () and noise . The reason is that NMT is a single neural network structure, which would be affected by each instance during the training procedure (.", "labels": [], "entities": []}, {"text": "In comparison, SMT is a combination of distributed models, such as a phrase-table and a language model.", "labels": [], "entities": [{"text": "SMT", "start_pos": 15, "end_pos": 18, "type": "TASK", "confidence": 0.9892839789390564}]}, {"text": "Even if some instances in the phrase-table or the language model are noisy, they can only affect part of the models and would not affect the entire system so much.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, there are only few works investigating the impact of the noise problem in NMT (.", "labels": [], "entities": []}, {"text": "* The first two authors have equal contributions.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the performance of NMT trained on noisy parallel data.", "labels": [], "entities": []}, {"text": "We adopt the clean data of WMT18 News Translation Task to train a classifier and compute informative features.", "labels": [], "entities": [{"text": "WMT18 News Translation", "start_pos": 27, "end_pos": 49, "type": "TASK", "confidence": 0.7883053421974182}]}, {"text": "Using this classifier, we score each sentence in the noisy data and sample the top ranked sentences to construct the pseudo clean data.", "labels": [], "entities": []}, {"text": "The new pseudo clean data are used to train a robust NMT system.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we introduce the task and data.", "labels": [], "entities": []}, {"text": "In Section 3, we introduce the features that we designed to score sentences in the noisy corpus.", "labels": [], "entities": []}, {"text": "We use these features to train a classifier and the sentences in the noisy corpus are scored by this classifier.", "labels": [], "entities": []}, {"text": "Empirical results produced with our systems are showed and analyzed in Section 4, and Section 5 concludes this paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: WMT official results.", "labels": [], "entities": [{"text": "WMT", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.8156071305274963}]}]}