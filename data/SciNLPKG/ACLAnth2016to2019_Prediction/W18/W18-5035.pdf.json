{"title": [{"text": "Automatic Extraction of Causal Relations from Text using Linguistically Informed Deep Neural Networks", "labels": [], "entities": [{"text": "Automatic Extraction of Causal Relations from Text", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.7918063529900142}]}], "abstractContent": [{"text": "In this paper we have proposed a linguistically informed recursive neural network architecture for automatic extraction of cause-effect relations from text.", "labels": [], "entities": [{"text": "automatic extraction of cause-effect relations from text", "start_pos": 99, "end_pos": 155, "type": "TASK", "confidence": 0.8085910337311881}]}, {"text": "These relations can be expressed in arbitrarily complex ways.", "labels": [], "entities": []}, {"text": "The architecture uses word level embeddings and other linguistic features to detect causal events and their effects mentioned within a sentence.", "labels": [], "entities": []}, {"text": "The extracted events and their relations are used to build a causal-graph after clustering and appropriate generalization , which is then used for predictive purposes.", "labels": [], "entities": []}, {"text": "We have evaluated the performance of the proposed extraction model with respect to two baseline systems,one a rule-based classifier, and the other a conditional random field (CRF) based supervised model.", "labels": [], "entities": []}, {"text": "We have also compared our results with related work reported in the past by other authors on SEMEVAL data set, and found that the proposed bi-directional LSTM model enhanced with an additional linguistic layer performs better.", "labels": [], "entities": [{"text": "SEMEVAL data set", "start_pos": 93, "end_pos": 109, "type": "DATASET", "confidence": 0.8487269481023153}]}, {"text": "We have also worked extensively on creating new annotated datasets from publicly available data, which we are willing to share with the community.", "labels": [], "entities": []}], "introductionContent": [{"text": "The concept of causality can be informally introduced as a relationship between two events e 1 and e 2 such that occurrence of e 1 results in the occurrence of e 2 . Curating causal relations from text documents help in automatically building causal networks which can be used for predictive tasks.", "labels": [], "entities": []}, {"text": "Expression of causality can be expressed within text documents in arbitrarily complex ways.", "labels": [], "entities": []}, {"text": "For example, in the sentence \"Aircel files for bankruptcy over mounting financial troubles\", the event \"mounting financial troubles\" is causing the event \"Aircel filed for bankruptcy.\"", "labels": [], "entities": [{"text": "Aircel", "start_pos": 30, "end_pos": 36, "type": "DATASET", "confidence": 0.9399807453155518}, {"text": "Aircel", "start_pos": 155, "end_pos": 161, "type": "DATASET", "confidence": 0.9442384839057922}]}, {"text": "Ina more complicated scenario, \"Company recalled some vehicles to fix loose bolts that could lead to engine stall\" we can observe nested cause-effect pairs.", "labels": [], "entities": []}, {"text": "Here, the effect \"company recalled vehicle\" is caused by the event \"to fix loose bolts is not easy to extract.", "labels": [], "entities": []}, {"text": "That the cause \"loose bolts\" could lead to engine stall\", is even more difficult to detect.", "labels": [], "entities": []}, {"text": "While there has been a considerable body of researchers working in the area whose work has been reviewed in section 2, there are many challenges that are still not properly addressed.", "labels": [], "entities": []}, {"text": "Most of the earlier approaches have considered rule based or traditional machine learning algorithms which heavily depend on careful feature engineering.", "labels": [], "entities": []}, {"text": "Though one sees adoption of deep learning techniques for causality extraction, it is still considerably low compared to other text mining tasks.", "labels": [], "entities": [{"text": "causality extraction", "start_pos": 57, "end_pos": 77, "type": "TASK", "confidence": 0.7972810864448547}, {"text": "text mining tasks", "start_pos": 126, "end_pos": 143, "type": "TASK", "confidence": 0.8155263861020406}]}, {"text": "This is largely due to the unavailability of adequate annotated data: the only available dataset for evaluation is the SEMEVAL-10 Task 8 which is woefully inadequate to train such deep models.", "labels": [], "entities": [{"text": "SEMEVAL-10 Task 8", "start_pos": 119, "end_pos": 136, "type": "DATASET", "confidence": 0.6232830484708151}]}, {"text": "There are challenges with annotations of this data also.", "labels": [], "entities": []}, {"text": "Most of the existing extraction mechanisms look for single word representation of events within a sentence, thereby yielding wrong results.", "labels": [], "entities": []}, {"text": "For example, in the sentence \"The AIDS pandemic caused by the spread of HIV infection\" the cause and effect are both multi-word phrases i.e. \"spread of HIV infection\" and 'AIDS pandemic'.", "labels": [], "entities": []}, {"text": "However, SEMEVAL 2010 annotated dataset for this task mentions the cause and effect as \"infection\" and \"pandemic\" only.", "labels": [], "entities": [{"text": "SEMEVAL 2010 annotated dataset", "start_pos": 9, "end_pos": 39, "type": "DATASET", "confidence": 0.8544634133577347}]}, {"text": "In another example, \"Infectious diseases or communicable diseases are caused by bacteria, viruses, and parasites.\", the need to extract multiple causal as well as effect events is obvious.", "labels": [], "entities": []}, {"text": "The example sentence in the first paragraph not only demonstrates the need to extract phrases as events, but also highlights how complex such statements can be, often without the use of known causal connectives like \"causes, because of, leads to, after, due to\" etc.", "labels": [], "entities": []}, {"text": "which have been traditionally exploited by the community.", "labels": [], "entities": []}, {"text": "In this work, we explore the use of bidirectional LSTMs that can learn to detect causal instances from sentences.", "labels": [], "entities": []}, {"text": "To address the paucity of training data, we propose the use of additional linguistic feature embeddings, over and above the regular word embeddings.", "labels": [], "entities": []}, {"text": "With the use of such linguistically-informed deep architecture, we avoid the task of complex feature engineering.", "labels": [], "entities": []}, {"text": "A major contribution of this work is in developing annotated datasets with information curated from multiple sources spanning across different domains.", "labels": [], "entities": []}, {"text": "To do this, we have collected news articles and generate annotations.", "labels": [], "entities": []}, {"text": "Beside SE-MEVAL dataset we have also used another available dataset that has annotated data about drugs and their adverse effect extracted from Medline ().", "labels": [], "entities": [{"text": "SE-MEVAL dataset", "start_pos": 7, "end_pos": 23, "type": "DATASET", "confidence": 0.7976434230804443}, {"text": "Medline", "start_pos": 144, "end_pos": 151, "type": "DATASET", "confidence": 0.9632423520088196}]}, {"text": "We have done intensive experimentations with parts of the dataset for training and testing which will be discussed in the following sections.", "labels": [], "entities": []}, {"text": "Detection of causal relation from text has many analytical and predictive applications.", "labels": [], "entities": [{"text": "Detection of causal relation from text", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.8682054082552592}]}, {"text": "Few of these are: detecting cause-effect relations in medical documents, learning about after effects of natural disasters, learning causes for safety related incidents etc..", "labels": [], "entities": [{"text": "detecting cause-effect relations in medical documents", "start_pos": 18, "end_pos": 71, "type": "TASK", "confidence": 0.8952789306640625}]}, {"text": "However to build a meaningful application that can detect an event from texts and predict its possible effects, there is a need to curate large volume of cause-effect event pairs.", "labels": [], "entities": []}, {"text": "Further, similar events need to be grouped and generalized to super classes, over which the predictive framework can be built(.", "labels": [], "entities": []}, {"text": "In this paper, we have proposed a k-means clustering of causal and effect events detected from text, using word vector representations.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 summarizes challenges and related works on causality detection.", "labels": [], "entities": [{"text": "causality detection", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.7957344055175781}]}, {"text": "Section 3 presents the resource creation and the architecture of the proposed causality extraction framework.", "labels": [], "entities": [{"text": "causality extraction", "start_pos": 78, "end_pos": 98, "type": "TASK", "confidence": 0.7329905182123184}]}, {"text": "Experiments and evaluation are detailed in Section 4.", "labels": [], "entities": []}, {"text": "Finally, in section 5 we conclude the paper..", "labels": [], "entities": []}, {"text": "Marked Causality is where there is a linguistic signal of causation present.", "labels": [], "entities": []}, {"text": "For example, \"I attended the event because I was invited\".", "labels": [], "entities": []}, {"text": "Here, causality is marked by because.", "labels": [], "entities": []}, {"text": "On the other hand in \"Drive slowly.", "labels": [], "entities": []}, {"text": "There are potholes\", causality is unmarked.", "labels": [], "entities": []}, {"text": "Explicit Causality is where both cause and effect are stated.", "labels": [], "entities": []}, {"text": "For example, \"The burst has been caused by water hammer pressure\" has both cause and effect stated explicitly.", "labels": [], "entities": []}, {"text": "However, \"The car ran over his leg\" does not have the effect of the accident explicitly stated.", "labels": [], "entities": []}, {"text": "Automatic extraction of cause-effect relations are primarily based on three different approaches namely, Linguistic rule based, supervised and unsupervised machine learning approaches.", "labels": [], "entities": [{"text": "Automatic extraction of cause-effect relations", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.8437053084373474}]}, {"text": "Both SemEval-2007 ( had tasks aimed at identifying different relations from text, including CauseEffect relations.", "labels": [], "entities": []}, {"text": "Both tasks offered a corpus of annotated gold standard data to researchers.", "labels": [], "entities": []}, {"text": "However, the task has primarily focused on extracting single word cause-effect pairs.", "labels": [], "entities": [{"text": "extracting single word cause-effect pairs", "start_pos": 43, "end_pos": 84, "type": "TASK", "confidence": 0.850392746925354}]}, {"text": "Early work in this area relied totally on hand-coded patterns.", "labels": [], "entities": []}, {"text": "These were heavily dependent on both domain and linguistic knowledge, due to the nature of the patterns, and were hard to scale up.", "labels": [], "entities": []}, {"text": "PROTEUS and COATIS (Garcia, 1997) were two early systems that used such non-statistical techniques.", "labels": [], "entities": [{"text": "PROTEUS", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.746479868888855}, {"text": "COATIS", "start_pos": 12, "end_pos": 18, "type": "METRIC", "confidence": 0.8528147339820862}]}, {"text": "C.G Khoo carried out extensive development of this train of thought in a series of works () (), and eliminated a lot of the need for domain knowledge.", "labels": [], "entities": []}, {"text": "A method of automatically identifying linguistic patterns that indicate causal relations and a semi-supervised method of validation of patterns obtained was proposed by ().", "labels": [], "entities": []}, {"text": "In particular, this work introduced the usage of WordNet hierarchal classes, namely, human action, phenomenon, state, psychological feature and event, as a distinguishing feature.", "labels": [], "entities": []}, {"text": "Radinsky et al. in their work uses statistical inferencing combined with hierarchical clustering technique to predict future events from news (.", "labels": [], "entities": []}, {"text": "Logistic regression was employed ( to extract drugs (cause) and virus mutation (effect) occurrences from medical literature.", "labels": [], "entities": [{"text": "Logistic regression", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8919100165367126}]}, {"text": "The relatively untouched task of extracting implicit cause-effect from sentences was tackled by Ittoo et.al ().", "labels": [], "entities": []}, {"text": "More recently,) have proposed novel causality network embeddings for the abstract representation of causal events from News headlines.", "labels": [], "entities": []}, {"text": "Here, the authors have primarily used four common causal connectives namely, \"because\", \"after\", \"because of\" and \"lead to\" to extract causal mentions in news headlines and constructed a network of causal relations.", "labels": [], "entities": []}, {"text": "The authors have proposed a novel generalization technique to represent \"specific events\" into more abstract form.", "labels": [], "entities": []}, {"text": "Finally, they proposed a dual cause-effect model that uses the causal network embeddings and optimize the margin based loss function to predict effect of a given cause.", "labels": [], "entities": []}, {"text": "Although the work is commendable, there are various factors that need to be addressed further.", "labels": [], "entities": []}, {"text": "For example, construction of the causal network itself is anon trivial task.", "labels": [], "entities": []}, {"text": "Some of the linguistic challenges have already mentioned earlier in this section.", "labels": [], "entities": []}, {"text": "Further, Zhao et al. worked with only unambiguous causal connectives.", "labels": [], "entities": []}, {"text": "On the contrary causal connectives can be ambiguous also) For example, from in \"Profits from the sale were given to charity\" implies causation of profits due to the sale, while from in \"Sales profits increased from 1.2% to 2%\" does not have any causality involved in it.", "labels": [], "entities": []}, {"text": "Analysis of such complex constructs are yet to be addressed.", "labels": [], "entities": []}], "datasetContent": [{"text": "We perform a number of different experiments to evaluate and compare the performance of our proposed system with the baseline systems.", "labels": [], "entities": []}, {"text": "In general we classify the experiments into three different groups.", "labels": [], "entities": []}, {"text": "Each group uses different techniques to identify causality in text.", "labels": [], "entities": []}, {"text": "Group-1 uses rule based method, group-2 uses a CRF based classification model, group-3 uses Bi-LSTM model and group-4 uses our proposed linguistically informed Bi-LSTM model.", "labels": [], "entities": []}, {"text": "The outputs of the experiments are evaluated in terms of the five given datasets that are explained earlier.", "labels": [], "entities": []}, {"text": "Again, corresponding to each group, we define three different evaluation tasks.", "labels": [], "entities": []}, {"text": "The tasks are distinguished in terms of the way each datasets are divided for training, development and testing purposes.", "labels": [], "entities": []}, {"text": "In Task-I, we took the five datasets separately and each dataset is divided into 80%, 10% and 10% for training, testing and development respectively.", "labels": [], "entities": []}, {"text": "The F1 scores obtained by each system on the datasets by this model are reported in for identified Cause, Effect and Causal Connec-", "labels": [], "entities": [{"text": "F1", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.9991739392280579}, {"text": "Cause", "start_pos": 99, "end_pos": 104, "type": "METRIC", "confidence": 0.9362426996231079}, {"text": "Effect", "start_pos": 106, "end_pos": 112, "type": "METRIC", "confidence": 0.718616247177124}]}], "tableCaptions": [{"text": " Table 4: Comparing F-scores of the Cause (C), Effect(E)", "labels": [], "entities": [{"text": "F-scores", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.807543933391571}, {"text": "Effect(E", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9523892800013224}]}]}