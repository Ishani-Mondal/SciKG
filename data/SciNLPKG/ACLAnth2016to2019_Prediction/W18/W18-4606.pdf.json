{"title": [{"text": "Investigating the importance of linguistic complexity features across different datasets related to language learning", "labels": [], "entities": []}], "abstractContent": [{"text": "We present the results of our investigations aiming at identifying the most informative linguistic complexity features for classifying language learning levels in three different datasets.", "labels": [], "entities": []}, {"text": "The datasets vary across two dimensions: the size of the instances (texts vs. sentences) and the language learning skill they involve (reading comprehension texts vs. texts written by learners themselves).", "labels": [], "entities": []}, {"text": "We present a subset of the most predictive features for each dataset, taking into consideration significant differences in their per-class mean values and show that these subsets lead not only to simpler models, but also to an improved classification performance.", "labels": [], "entities": []}, {"text": "Furthermore, we pinpoint fourteen central features that are good predictors regardless of the size of the linguistic unit analyzed or the skills involved, which include both morpho-syntactic and lexical dimensions.", "labels": [], "entities": []}], "introductionContent": [{"text": "Linguistic complexity, especially in cross-linguistic studies, is often approached in absolute terms, describing complexity as a property of a linguistic system in terms of e.g. number of contrastive sounds.", "labels": [], "entities": []}, {"text": "In this paper, however, we investigate a relative type of linguistic complexity from a cognitive perspective, our focus being the ability of L2 learners to processor produce certain linguistic elements in writing at different stages of proficiency.", "labels": [], "entities": []}, {"text": "We operationalize the term linguistic complexity as the set of lexicosemantic, morphological and syntactic characteristics reflected in texts (or sentences) that determine the magnitude of the language skills and competences required to processor produce them.", "labels": [], "entities": []}, {"text": "In this work, we use linguistic complexity analysis as a means to predict second language learning (L2) levels.", "labels": [], "entities": [{"text": "linguistic complexity analysis", "start_pos": 21, "end_pos": 51, "type": "TASK", "confidence": 0.681846926609675}]}, {"text": "The scale of learning (proficiency) levels adopted here is the CEFR, the Common European Framework of Reference for Languages) which proposes a six-point scale of proficiency levels: from A1 (beginner) to C2 (advanced) level.", "labels": [], "entities": [{"text": "CEFR", "start_pos": 63, "end_pos": 67, "type": "DATASET", "confidence": 0.9736299514770508}]}, {"text": "Large corpora in the language learning domain are rather scarce due to either copy-right issues, privacy reasons or the need for digitizing them.", "labels": [], "entities": []}, {"text": "For the Swedish language, a number of resources have become available recently (), which, although somewhat small in size, encompass texts involving different skills and CEFR levels.", "labels": [], "entities": [{"text": "CEFR", "start_pos": 170, "end_pos": 174, "type": "METRIC", "confidence": 0.8862118124961853}]}, {"text": "This allows for investigations about the similarities and differences between linguistic complexity observable at different proficiency levels for different skill types, namely receptive skills, required when learners process passages produced by others and productive skills, when learners produce the texts themselves.", "labels": [], "entities": []}, {"text": "We perform linguistic complexity analyses across two different dimensions: the type of learner skills involved when dealing with the texts and the size of the linguistic context investigated.", "labels": [], "entities": []}, {"text": "In the latter case, we carryout experiments both at the text and at the sentence level.", "labels": [], "entities": []}, {"text": "Throughout the years, a large number of linguistic features related to complexity has been proposed.", "labels": [], "entities": []}, {"text": "Typically, out of the features suggested fora specific task some are more useful than others.", "labels": [], "entities": []}, {"text": "Eliminating redundant features can result in simpler and improved models that are not only faster, but might also generalize better on unseen data.", "labels": [], "entities": []}, {"text": "Such selection can also contribute to understand further the main factors playing role in linguistic complexity, which can be a useful means for determining whether non-native speakers can understand or produce certain linguistic input at different learning levels.", "labels": [], "entities": []}, {"text": "In this paper, we investigate therefore the importance of individual linguistic complexity features for predicting proficiency levels across different L2 datasets.", "labels": [], "entities": []}, {"text": "The two main research questions we investigate are: (i) Which linguistic complexity features are most useful for determining proficiency levels for each L2 dataset?", "labels": [], "entities": []}, {"text": "(ii) Are there features that are relevant regardless of the context size and the type of skill considered?", "labels": [], "entities": []}, {"text": "Our contributions include, on the one hand, a subset of the most informative features for each dataset whose use leads to improved classification results.", "labels": [], "entities": []}, {"text": "On the other hand, we identify some lexical, morphological and syntactic features that are good indicators of complexity across all three datasets, namely, reading comprehension texts, essays and sentences.", "labels": [], "entities": []}, {"text": "In Section 2, we provide an overview of previous work related to linguistic complexity analysis, followed by the description of our datasets in Section 3.", "labels": [], "entities": [{"text": "linguistic complexity analysis", "start_pos": 65, "end_pos": 95, "type": "TASK", "confidence": 0.7527367870012919}]}, {"text": "In Section 4, we present the set of features used and highlight their relevance for modeling linguistic complexity in the L2 context.", "labels": [], "entities": []}, {"text": "We then describe our experiments and their results in Section 5, presenting the most informative features and their effect on classification performance.", "labels": [], "entities": [{"text": "classification", "start_pos": 126, "end_pos": 140, "type": "TASK", "confidence": 0.9624113440513611}]}, {"text": "Finally, we conclude our results and outline future work in Section 6. 2 Previous literature on linguistic complexity for predicting L2 levels Expert-written (receptive) texts In the L2 context, specific scales reflecting progress in language proficiency have been proposed.", "labels": [], "entities": []}, {"text": "One such scale is the CEFR, introduced in section 1.", "labels": [], "entities": [{"text": "CEFR", "start_pos": 22, "end_pos": 26, "type": "DATASET", "confidence": 0.739992618560791}]}, {"text": "An alternative to the CEFR is the 7-point scale of the Interagency Language Roundtable (ILR), common in the United States.", "labels": [], "entities": [{"text": "Interagency Language Roundtable (ILR)", "start_pos": 55, "end_pos": 92, "type": "TASK", "confidence": 0.45786162714163464}]}, {"text": "In, we provide an overview of studies targeting L2 receptive complexity and compare the target language, the type and amount of training data and the methods used.", "labels": [], "entities": []}, {"text": "The studies are ordered alphabetically based on the target language of the linguistic complexity analysis.", "labels": [], "entities": []}, {"text": "We only include previous work here that shares the following characteristics: (i) texts rather than single sentences are the unit of analysis; (ii) receptive linguistic complexity is measured; and (iii) NLP tools are combined with machine learning algorithms.", "labels": [], "entities": []}, {"text": "Under dataset size, we report the number of texts used (except for), where whole books were employed), followed by the number of tokens in parenthesis when available.: An overview of studies on L2 receptive complexity.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used two L2 Swedish corpora consisting of texts in our experiments: SweLL (Volodina et al., 2016b) comprised of essays written by L2 learners and COCTAILL () containing L2 coursebooks authored or adapted by experts for L2 learners.", "labels": [], "entities": [{"text": "SweLL", "start_pos": 71, "end_pos": 76, "type": "METRIC", "confidence": 0.6347817778587341}]}, {"text": "The SweLL corpus consists of essays produced by adult learners of L2 Swedish on a variety of topics (TEXT-E).", "labels": [], "entities": [{"text": "SweLL corpus", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.7488352954387665}, {"text": "TEXT-E", "start_pos": 101, "end_pos": 107, "type": "METRIC", "confidence": 0.9906697273254395}]}, {"text": "From the coursebook corpus, we only include whole texts meant for reading comprehension practice (TEXT-R) since the linguistic annotation of other coursebook elements (e.g. gap-filling exercises) maybe prone to automatic linguistic annotation errors.", "labels": [], "entities": [{"text": "coursebook corpus", "start_pos": 9, "end_pos": 26, "type": "DATASET", "confidence": 0.8297680616378784}, {"text": "TEXT-R", "start_pos": 98, "end_pos": 104, "type": "METRIC", "confidence": 0.9309971332550049}]}, {"text": "These two corpora cover five CEFR levels (A1 to C1).", "labels": [], "entities": []}, {"text": "Each SweLL essay has been assigned a CEFR level by teachers.", "labels": [], "entities": [{"text": "CEFR level", "start_pos": 37, "end_pos": 47, "type": "METRIC", "confidence": 0.9730352461338043}]}, {"text": "For reading texts, CEFR levels were derived from the level of the lesson (chapter) they occur in.", "labels": [], "entities": [{"text": "CEFR", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.981109619140625}]}, {"text": "It is worth mentioning that these two corpora are independent from each other, i.e. the essays written by the learners are not based on, or inspired by, the reading passages.", "labels": [], "entities": []}, {"text": "The distribution of texts per type and CEFR level in the datasets is shown in.", "labels": [], "entities": [{"text": "CEFR level", "start_pos": 39, "end_pos": 49, "type": "METRIC", "confidence": 0.9355971217155457}]}, {"text": "The total number of tokens in the coursebook-based dataset was 289,312, while in the learner essay data it was 43,033.", "labels": [], "entities": [{"text": "coursebook-based dataset", "start_pos": 34, "end_pos": 58, "type": "DATASET", "confidence": 0.7972202599048615}]}, {"text": "At the sentence level, we use a small dataset 1 (SENT) based on the user evaluation of a corpus example selection system, HitEx, which we described in detail in . HitEx aims at identifying sentences from corpora suitable as exercise items.", "labels": [], "entities": []}, {"text": "The sentences in this dataset have been automatically assessed for their CEFR level and have been filtered for their well-formedness, independence from the rest of their textual context and some additional lexical and structural criteria (e.g. abbreviations, interrogative form) using HitEx.", "labels": [], "entities": [{"text": "CEFR level", "start_pos": 73, "end_pos": 83, "type": "METRIC", "confidence": 0.9498720765113831}, {"text": "HitEx", "start_pos": 285, "end_pos": 290, "type": "DATASET", "confidence": 0.9861656427383423}]}, {"text": "Out of the original 330 sentences from the evaluation material, we only included in this dataset the subset of sentences: (i) that were found overall suitable (with an evaluation score >= 2.5 out of 4); and (ii) where a majority of teachers agreed with the CEFR level assigned automatically by HitEx.", "labels": [], "entities": [{"text": "CEFR level", "start_pos": 257, "end_pos": 267, "type": "METRIC", "confidence": 0.8282838761806488}, {"text": "HitEx", "start_pos": 294, "end_pos": 299, "type": "DATASET", "confidence": 0.937386155128479}]}, {"text": "This subset was complemented with 90 sentences for the otherwise insufficiently represented A1 level from the COCTAILL corpus.", "labels": [], "entities": [{"text": "COCTAILL corpus", "start_pos": 110, "end_pos": 125, "type": "DATASET", "confidence": 0.9383443295955658}]}, {"text": "Only individually occurring sentences in lists and non-gapped exercises were considered, thus these are not a subset of the text-level dataset described above.", "labels": [], "entities": []}, {"text": "The distribution of sentences per CEFR level in the dataset is presented in.", "labels": [], "entities": []}, {"text": "The total number of tokens in the dataset is 4,060.", "labels": [], "entities": []}, {"text": "All three corpora are equipped also with automatic linguistic annotation which includes lemmatization, part-of-speech (POS) tagging and dependency parsing based on the Sparv 2 pipeline.", "labels": [], "entities": [{"text": "part-of-speech (POS) tagging", "start_pos": 103, "end_pos": 131, "type": "TASK", "confidence": 0.6479380488395691}, {"text": "dependency parsing", "start_pos": 136, "end_pos": 154, "type": "TASK", "confidence": 0.7028189897537231}]}, {"text": "In this section, we describe the results of our feature selection experiments on the three datasets presented in Section 3.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 48, "end_pos": 65, "type": "TASK", "confidence": 0.7345539033412933}]}, {"text": "These experiments differ from the ones we described previously in  and in a number of respects.", "labels": [], "entities": []}, {"text": "In this work, the worth of individual features is evaluated rather than that of the complete set of features or groups of features.", "labels": [], "entities": []}, {"text": "Moreover, as mentioned in section 4, most lexical features are based on L2 word lists rather than KELLY.", "labels": [], "entities": [{"text": "KELLY", "start_pos": 98, "end_pos": 103, "type": "METRIC", "confidence": 0.8514658808708191}]}, {"text": "We use 85% of each dataset for identifying the most informative features (DEV).", "labels": [], "entities": []}, {"text": "The reported classification results using this part of the data are based on a stratified 5-fold cross-validation setup, that is, the original distribution of instances per CEFR level in the dataset has been preserved in all folds.", "labels": [], "entities": [{"text": "CEFR level in the dataset", "start_pos": 173, "end_pos": 198, "type": "DATASET", "confidence": 0.752910828590393}]}, {"text": "We evaluated the generalizability of the selected subset of features on the remaining 15% of the data (TEST).", "labels": [], "entities": [{"text": "TEST", "start_pos": 103, "end_pos": 107, "type": "METRIC", "confidence": 0.9888433218002319}]}, {"text": "As learning algorithm for these models, we used LinearSVC as implemented in scikit-learn), which has been successfully applied in recent years in a number of NLP areas.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: An overview of studies on L2 receptive complexity.", "labels": [], "entities": []}, {"text": " Table 2. The total  number of tokens in the dataset is 4,060.", "labels": [], "entities": []}, {"text": " Table 2: CEFR-level annotated Swedish datasets.", "labels": [], "entities": [{"text": "CEFR-level annotated Swedish datasets", "start_pos": 10, "end_pos": 47, "type": "DATASET", "confidence": 0.8929635286331177}]}, {"text": " Table 4: Accuracy with feature selection across datasets.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9837262034416199}]}, {"text": " Table 5: K-best features and their rank across different datasets.", "labels": [], "entities": []}]}