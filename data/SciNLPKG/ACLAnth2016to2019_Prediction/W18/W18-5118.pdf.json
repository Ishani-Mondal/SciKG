{"title": [{"text": "Did you offend me? Classification of Offensive Tweets in Hinglish Language", "labels": [], "entities": [{"text": "Classification of Offensive Tweets", "start_pos": 19, "end_pos": 53, "type": "TASK", "confidence": 0.8956563323736191}, {"text": "Hinglish Language", "start_pos": 57, "end_pos": 74, "type": "DATASET", "confidence": 0.759211540222168}]}], "abstractContent": [{"text": "The use of code-switched languages (e.g., Hinglish, which is derived by the blending of Hindi with the English language) is getting much popular on Twitter due to their ease of communication in native languages.", "labels": [], "entities": []}, {"text": "However, spelling variations and absence of grammar rules introduce ambiguity and make it difficult to understand the text automatically.", "labels": [], "entities": []}, {"text": "This paper presents the Multi-Input Multi-Channel Transfer Learning based model (MIMCT) to detect offensive (hate speech or abusive) Hinglish tweets from the proposed Hinglish Offensive Tweet (HOT) dataset using transfer learning coupled with multiple feature inputs.", "labels": [], "entities": [{"text": "detect offensive (hate speech or abusive) Hinglish tweets", "start_pos": 91, "end_pos": 148, "type": "TASK", "confidence": 0.6627379417419433}, {"text": "Hinglish Offensive Tweet (HOT) dataset", "start_pos": 167, "end_pos": 205, "type": "DATASET", "confidence": 0.5396908181054252}]}, {"text": "Specifically, it takes multiple primary word embedding along with secondary extracted features as inputs to train a multi-channel CNN-LSTM architecture that has been pre-trained on English tweets through transfer learning.", "labels": [], "entities": []}, {"text": "The proposed MIMCT model outperforms the baseline supervised classification models, transfer learning based CNN and LSTM models to establish itself as the state of the art in the unexplored domain of Hinglish offensive text classification.", "labels": [], "entities": [{"text": "Hinglish offensive text classification", "start_pos": 200, "end_pos": 238, "type": "TASK", "confidence": 0.7310234904289246}]}], "introductionContent": [{"text": "Increasing penetration of social media websites such as Twitter in linguistically distinct demographic regions has led to a blend of natively spoken languages with English, known as codeswitched languages.", "labels": [], "entities": []}, {"text": "Social media is rife with such offensive content that can be broadly classified as abusive and hate-inducing on the basis of severity and target of the discrimination.", "labels": [], "entities": []}, {"text": "Hate speech () is an act of offending a person or a group as a whole on the basis of certain key attributes such as religion, race, sexual orientation, gender, ideological background, mental and physical disability.", "labels": [], "entities": [{"text": "Hate speech", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.8209419548511505}]}, {"text": "On the other hand, abusive speech is offensive speech with a vague target and mild intention to hurt the sentiments of the receiver.", "labels": [], "entities": []}, {"text": "Most social media platforms delete such offensive content when: (i) either someone reports manually or (ii) an offensive content classifier automatically detects them.", "labels": [], "entities": []}, {"text": "However, people often use such code-switched languages to write offensive content on social media so that English trained classifiers cannot detect them automatically, necessitating an efficient classifier that can detect offensive content automatically from codeswitched languages.", "labels": [], "entities": []}, {"text": "In 2015, India ranked fourth on the Social Hostilities Index with an index value of 8.7 out of 10 (, making it imperative to filter the tremendously high offensive online content in Hinglish.", "labels": [], "entities": [{"text": "Hinglish", "start_pos": 182, "end_pos": 190, "type": "DATASET", "confidence": 0.924954354763031}]}, {"text": "Hinglish has the following characteristics: (i) it is formed of words spoken in Hindi (Indic) language but written in Roman script instead of the standard Devanagari script, (ii) it is one of the many pronunciations based pseudo languages created natively by social media users for the ease of communication and (iii) it has no fixed grammar rules but rather borrows the grammatical setup from native Hindi and compliments it with Roman script along with a plethora of slurs, slang and phonetic variations due to regional influence.", "labels": [], "entities": []}, {"text": "Hence, such code-switched language presents challenging limitations in terms of the randomized spelling variations in explicit words due to a foreign script and compounded ambiguity arising due to the various interpretations of words in different contextual situations.", "labels": [], "entities": []}, {"text": "For instance, the sentence: Main tujhe se pyaar karta hun is in Hinglish language which means I love you.", "labels": [], "entities": []}, {"text": "Careful observation highlights how the word pyaar meaning 'love' can suffer from phonetic variations due to multiple possible pronunciations such as pyar, pyaar or pyara.", "labels": [], "entities": []}, {"text": "Also, the explicit word byword translation of the above sentence, I you love do, is grammatically incorrect in English.", "labels": [], "entities": []}, {"text": "We present deep learning techniques that classify the input tweets in Hinglish as: (i) nonoffensive, (ii) abusive and (iii) hate-inducing.", "labels": [], "entities": [{"text": "Hinglish", "start_pos": 70, "end_pos": 78, "type": "DATASET", "confidence": 0.9378894567489624}]}, {"text": "Since transfer learning can act as an effective strategy to reuse already learned features in learning a specialized task through cross domain knowledge transfer, hate speech classification on a large English corpus can act as source tasks to help in obtaining pre-trained deep learning classifiers for the target task of classifying tweets translated in English from Hinglish language.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 6, "end_pos": 23, "type": "TASK", "confidence": 0.8812446296215057}, {"text": "hate speech classification", "start_pos": 163, "end_pos": 189, "type": "TASK", "confidence": 0.6452049016952515}, {"text": "classifying tweets translated in English from Hinglish language", "start_pos": 322, "end_pos": 385, "type": "TASK", "confidence": 0.7022165209054947}]}, {"text": "Representation vectors constructed by CNN consider local relationship values while the feature vectors constructed by LSTM stress on overall dependencies of the whole sentence.", "labels": [], "entities": []}, {"text": "The proposed MIMCT model employs both CNN and LSTM as concurrent information channels that benefit from local as well as overall semantic relationship and is further supported by primary features (multiple word embeddings) and secondary external features (LIWC feature, profanity vector and sentiment score), as described in Section 3.3.", "labels": [], "entities": []}, {"text": "The complete MIMCT model is pre-trained on English Offensive Tweet (EOT) dataset, which is an open source dataset of annotated English tweets that was obtained from CrowdFlower 1 and is an abridged version of the original dataset created by, followed by re-training on the proposed HOT dataset.", "labels": [], "entities": [{"text": "English Offensive Tweet (EOT) dataset", "start_pos": 43, "end_pos": 80, "type": "DATASET", "confidence": 0.6102428095681327}, {"text": "HOT dataset", "start_pos": 282, "end_pos": 293, "type": "DATASET", "confidence": 0.9148264825344086}]}, {"text": "The main contributions of our work can be summarized as follows: \u2022 Building an annotated Hinglish Offensive Tweet (HOT) dataset 2 . \u2022 We ascertain the usefulness of transfer learning for classifying offensive Hinglish tweets.", "labels": [], "entities": [{"text": "Hinglish Offensive Tweet (HOT) dataset", "start_pos": 89, "end_pos": 127, "type": "DATASET", "confidence": 0.565675403390612}, {"text": "classifying offensive Hinglish tweets", "start_pos": 187, "end_pos": 224, "type": "TASK", "confidence": 0.8363803178071976}]}, {"text": "\u2022 We build a novel MIMCT model that outperforms the baseline models on HOT.", "labels": [], "entities": [{"text": "HOT", "start_pos": 71, "end_pos": 74, "type": "DATASET", "confidence": 0.9545721411705017}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Sections 2 and 3 discuss the related work and methodologies in detail, respectively.", "labels": [], "entities": []}, {"text": "Discussions and evaluations are done in Section 4 followed by conclusion and future work in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We provide an extensive description of the sources, ground truth annotation scheme and statistics of the proposed Hinglish Offensive Tweets (HOT) dataset in Section 4.1.", "labels": [], "entities": [{"text": "Hinglish Offensive Tweets (HOT) dataset", "start_pos": 114, "end_pos": 153, "type": "DATASET", "confidence": 0.767668332372393}]}, {"text": "Next, we discuss implementation details of baseline, transfer learning and MIMCT model in Section 4.2 followed by results analysis in Section 4.3.", "labels": [], "entities": []}, {"text": "HOT tweets were done by three annotators having sufficient background in NLP research.", "labels": [], "entities": [{"text": "HOT", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.776084840297699}]}, {"text": "The tweets were labeled as hate speech if they satisfied one or more of the conditions: (i) tweet used sexist or racial slur to target a minority, (ii) undignified stereotyping or (iii) supporting a problematic hashtags such as #ReligiousSc*m.", "labels": [], "entities": []}, {"text": "The label chosen by at least two out of three independent annotators was taken as final ground truth for each tweet.", "labels": [], "entities": []}, {"text": "In case of conflict amongst the annotators, an NLP expert would finally assign the ground truth annotation for ambiguous tweets.", "labels": [], "entities": []}, {"text": "In this way, 386 tweets needed expert annotation, while 2803 tweets were labeled through consensus of annotators with an average value of Cohen Kappa's inter-annotator agreement \u03ba = 0.83.", "labels": [], "entities": []}, {"text": "shows the internal agreement between our annotators.", "labels": [], "entities": []}, {"text": "A curated list of profane words was extracted to form the Hinglish profanity list 4 , which was created by accumulating Hinglish swear words from curated social media blog posts and dedicated swearword forums . Each swearword was assigned an integer score on the scale of (1-10) based on the degree of profanity.", "labels": [], "entities": [{"text": "Hinglish profanity list 4", "start_pos": 58, "end_pos": 83, "type": "DATASET", "confidence": 0.9331730753183365}]}, {"text": "This assignment of profanity scores was accomplished through discussion amongst four independent code-switching linguistic experts having an extensive background in social media analysis.", "labels": [], "entities": []}, {"text": "The   Devanagari Hindi was achieved using datasets provided by.", "labels": [], "entities": [{"text": "Devanagari Hindi", "start_pos": 6, "end_pos": 22, "type": "DATASET", "confidence": 0.7185831367969513}]}, {"text": "The words so obtained were further translated into Roman script using a Hindi-English dictionary consisting of 136110 word pairs mined from CFILT, IIT Bombay 6 . Additionally, the English translations present of the words in Hinglish Profanity list were added to form a map based HinglishEnglish dictionary.", "labels": [], "entities": [{"text": "CFILT, IIT Bombay 6", "start_pos": 140, "end_pos": 159, "type": "DATASET", "confidence": 0.8411910176277161}, {"text": "Hinglish Profanity list", "start_pos": 225, "end_pos": 248, "type": "DATASET", "confidence": 0.9424075484275818}, {"text": "HinglishEnglish dictionary", "start_pos": 280, "end_pos": 306, "type": "DATASET", "confidence": 0.9159692823886871}]}, {"text": "A pertinent challenge in dealing with Hinglish language was the presence of spelling variants, homophones and homonyms that are used frequently in a loose context.", "labels": [], "entities": []}, {"text": "Thus the spelling variations of various popular Hinglish words were added to the corpus.", "labels": [], "entities": []}, {"text": "The HinglishEnglish dictionary thus formed, comprising of 7193 word pairs, was used as the basis for all further Hinglish to English tweet conversions.", "labels": [], "entities": [{"text": "HinglishEnglish dictionary", "start_pos": 4, "end_pos": 30, "type": "DATASET", "confidence": 0.9661460220813751}, {"text": "Hinglish to English tweet conversions", "start_pos": 113, "end_pos": 150, "type": "TASK", "confidence": 0.5465282380580903}]}, {"text": "gives detailed examples of word pairs in Hinglish-English dictionary along with a few swear words and their profanity scores.", "labels": [], "entities": [{"text": "Hinglish-English dictionary", "start_pos": 41, "end_pos": 68, "type": "DATASET", "confidence": 0.9748847782611847}]}, {"text": "Approximately, 29% of the tokens in preprocessed tweets are in Hinglish, a whopping 65% of the tokens are in English, while the remaining are Hinglish named entities like persons, events, organizations or places.", "labels": [], "entities": []}, {"text": "The higher instances of swear swear swear swear swear swear swear swear swear) plot of the HOT dataset shows the probability distribution of words in terms of the tokens used in tweets as represented by.", "labels": [], "entities": [{"text": "HOT dataset", "start_pos": 91, "end_pos": 102, "type": "DATASET", "confidence": 0.97220179438591}]}, {"text": "We also computed a few metrics to understand code-switching patterns in our dataset, so as to rationalize the performance of the classification models.", "labels": [], "entities": []}, {"text": "language tags distribution in a corpus of at least two languages ().", "labels": [], "entities": []}, {"text": "Let k be the total number of languages and p j is the total number of words in the language j over the total number of words in the corpus.", "labels": [], "entities": []}, {"text": "The value of M i ranges between 0 and 1 where, a value of 0 corresponds to a monolingual corpus and 1 corresponds to a corpus with equal number of tokens from each language.", "labels": [], "entities": []}, {"text": "Equation 1 depicts the M i which is approximately equal to 0.601, indicating that a majority of words are in Hinglish.", "labels": [], "entities": [{"text": "Hinglish", "start_pos": 109, "end_pos": 117, "type": "DATASET", "confidence": 0.9606045484542847}]}, {"text": "Integration Index (I i ): Integration Index is the approximate probability that any given token in the corpus is a switch point.", "labels": [], "entities": [{"text": "Integration Index (I i )", "start_pos": 0, "end_pos": 24, "type": "METRIC", "confidence": 0.8520206908384959}, {"text": "Integration Index", "start_pos": 26, "end_pos": 43, "type": "METRIC", "confidence": 0.9048405587673187}]}, {"text": "This metric quantifies the frequency of code-switching in a corpus.", "labels": [], "entities": []}, {"text": "Given a corpus composed of tokens tagged by language {l j }, i ranges from 1 ton \u2212 1, where n the size of the corpus.", "labels": [], "entities": []}, {"text": "S(l i , l j ) = 1 if l i = l j and 0 otherwise in Equation 2.", "labels": [], "entities": []}, {"text": "The value of I i computed is approximateedly 0.079 portraying a high frequency of codeswitching points.", "labels": [], "entities": []}, {"text": "(1) 4.2 Implementation Details", "labels": [], "entities": [{"text": "Implementation Details", "start_pos": 8, "end_pos": 30, "type": "TASK", "confidence": 0.6726487278938293}]}], "tableCaptions": [{"text": " Table 1: LIWC linguistic attributes used in the MIMCT model", "labels": [], "entities": []}, {"text": " Table 2: Tweet distributions in EOT and HOT.", "labels": [], "entities": [{"text": "HOT", "start_pos": 41, "end_pos": 44, "type": "DATASET", "confidence": 0.7252283692359924}]}, {"text": " Table 5: Cohen's Kappa for three annotators  A 1 , A 2 and A 3", "labels": [], "entities": [{"text": "Cohen's Kappa", "start_pos": 10, "end_pos": 23, "type": "DATASET", "confidence": 0.754377414782842}]}, {"text": " Table 6: Baseline results for non-offensive, abu- sive, hate-inducing tweet classification on HOT", "labels": [], "entities": [{"text": "Baseline", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9706832766532898}, {"text": "hate-inducing tweet classification", "start_pos": 57, "end_pos": 91, "type": "TASK", "confidence": 0.6618790129820505}, {"text": "HOT", "start_pos": 95, "end_pos": 98, "type": "DATASET", "confidence": 0.890099823474884}]}, {"text": " Table 7: Results for non-offensive, abusive, hate-inducing tweet classification on EOT, HOT and the  HOT dataset with transfer learning (TFL) for Glove, Twitter Word2vec and FastText embeddings", "labels": [], "entities": [{"text": "hate-inducing tweet classification", "start_pos": 46, "end_pos": 80, "type": "TASK", "confidence": 0.6747108896573385}, {"text": "EOT", "start_pos": 84, "end_pos": 87, "type": "DATASET", "confidence": 0.9048573970794678}, {"text": "HOT", "start_pos": 89, "end_pos": 92, "type": "DATASET", "confidence": 0.7479147911071777}, {"text": "HOT dataset", "start_pos": 102, "end_pos": 113, "type": "DATASET", "confidence": 0.8543420732021332}]}, {"text": " Table 8: Results of the MIMCT model with various  input features HOT compared to previous base- line. Primary inputs are enclosed within parenthe- ses, e.g., (Tw), and secondary inputs are enclosed  within square brackets, e.g. [ LIWC ].", "labels": [], "entities": [{"text": "HOT", "start_pos": 66, "end_pos": 69, "type": "METRIC", "confidence": 0.9769044518470764}]}]}