{"title": [], "abstractContent": [{"text": "Run-on sentences are common grammatical mistakes but little research has tackled this problem to date.", "labels": [], "entities": []}, {"text": "This work introduces two machine learning models to correct run-on sentences that outperform leading methods for related tasks, punctuation restoration and whole-sentence grammatical error correction.", "labels": [], "entities": [{"text": "punctuation restoration", "start_pos": 128, "end_pos": 151, "type": "TASK", "confidence": 0.7929301261901855}, {"text": "whole-sentence grammatical error correction", "start_pos": 156, "end_pos": 199, "type": "TASK", "confidence": 0.6547470241785049}]}, {"text": "Due to the limited annotated data for this error, we experiment with artificially generating training data from clean newswire text.", "labels": [], "entities": []}, {"text": "Our findings suggest artificial training data is viable for this task.", "labels": [], "entities": []}, {"text": "We discuss implications for correcting run-ons and other types of mistakes that have low coverage in error-annotated corpora.", "labels": [], "entities": []}], "introductionContent": [{"text": "A run-on sentence is defined as having at least two main or independent clauses that lack either a conjunction to connect them or a punctuation mark to separate them.", "labels": [], "entities": []}, {"text": "Run-ons are problematic because they not only make the sentence unfriendly to the reader but potentially also to the local discourse.", "labels": [], "entities": []}, {"text": "In the field of grammatical error correction (GEC), most work has typically focused on determiner, preposition, verb and other errors which non-native writers make more frequently.", "labels": [], "entities": [{"text": "grammatical error correction (GEC)", "start_pos": 16, "end_pos": 50, "type": "TASK", "confidence": 0.8080570697784424}]}, {"text": "Runons have received little to no attention even though they are common errors for both native and nonnative speakers.", "labels": [], "entities": []}, {"text": "Among college students in the United States, run-on sentences are the 18th most frequent error and the 8th most frequent error made by students who are not native English speakers ().", "labels": [], "entities": []}, {"text": "Correcting run-on sentences is challenging) for several reasons: \u2022 They are sentence-level mistakes with longdistance dependencies, whereas most other grammatical errors are local and only need a small window for decent accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 220, "end_pos": 228, "type": "METRIC", "confidence": 0.9795314073562622}]}], "datasetContent": [{"text": "Metrics: We report precision, recall, and the F 0.5 score.", "labels": [], "entities": [{"text": "Metrics", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9768424034118652}, {"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9993711113929749}, {"text": "recall", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.9997777342796326}, {"text": "F 0.5 score", "start_pos": 46, "end_pos": 57, "type": "METRIC", "confidence": 0.984166701634725}]}, {"text": "In GEC, precision is more important than recall, and therefore the standard metric for evaluation is F 0.5 , which weights precision twice as much as recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 8, "end_pos": 17, "type": "METRIC", "confidence": 0.9992737174034119}, {"text": "recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.9993746876716614}, {"text": "F 0.5", "start_pos": 101, "end_pos": 106, "type": "METRIC", "confidence": 0.974824070930481}, {"text": "precision", "start_pos": 123, "end_pos": 132, "type": "METRIC", "confidence": 0.9978165626525879}, {"text": "recall", "start_pos": 150, "end_pos": 156, "type": "METRIC", "confidence": 0.9966273903846741}]}, {"text": "Baselines: We report results on a balanced random baseline and state-of-the-art models from whole-sentence GEC (NUS18) and punctuation restoration (the Punctuator).", "labels": [], "entities": [{"text": "NUS18", "start_pos": 112, "end_pos": 117, "type": "DATASET", "confidence": 0.6891241669654846}, {"text": "punctuation restoration", "start_pos": 123, "end_pos": 146, "type": "TASK", "confidence": 0.7082969546318054}]}, {"text": "NUS18 is the released GEC model of, trained on two GEC corpora, NUCLE and Lang-8 ().", "labels": [], "entities": [{"text": "NUS18", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.982326328754425}, {"text": "NUCLE", "start_pos": 64, "end_pos": 69, "type": "DATASET", "confidence": 0.9216653108596802}]}, {"text": "We test two versions of the Punctuator: Punctuator-EU is the released model, trained on English Europarl v7, and Punctuator-RO, which we trained on artificial clean data (FakeGiga-Train) using the authors' code.", "labels": [], "entities": [{"text": "English Europarl v7", "start_pos": 88, "end_pos": 107, "type": "DATASET", "confidence": 0.8175731301307678}]}, {"text": "1 roCRF: We train our model with 1-regularization and c = 10 using the CRF++ toolkit.", "labels": [], "entities": []}, {"text": "Only features that occur at least 5 times in the training set were included.", "labels": [], "entities": []}, {"text": "Spaces are labeled to contain missing punctuation when the marginal probability is less than 0.70.", "labels": [], "entities": []}, {"text": "Parameters are tuned to F 0.5 on 25k held-out sentences.: Performance on clean v. noisy artificial data with 10% run-ons, and real v. artificial data with 1% run-ons.", "labels": [], "entities": [{"text": "Parameters", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9588525891304016}, {"text": "F", "start_pos": 24, "end_pos": 25, "type": "METRIC", "confidence": 0.9896010756492615}]}, {"text": "roS2S: Both the encoder and decoder have a single layer, 1028-dimensional hidden states, and a vocabulary of 100k words.", "labels": [], "entities": []}, {"text": "We limit the input sequences to 100 words and use 300-dimensional pre-trained GloVe word embeddings ().", "labels": [], "entities": []}, {"text": "The dropout rate is 0.5 and minibatches are size 128.", "labels": [], "entities": [{"text": "dropout rate", "start_pos": 4, "end_pos": 16, "type": "METRIC", "confidence": 0.9149770140647888}]}, {"text": "We train using Ada-grad with a learning rate of 0.0001 and a decay of 0.5.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 31, "end_pos": 44, "type": "METRIC", "confidence": 0.9693402051925659}]}], "tableCaptions": [{"text": " Table 3: Number of run-on (RO) and non-run-on  (Non-RO) sentences in our datasets.", "labels": [], "entities": []}, {"text": " Table 4: Performance on clean v. noisy artificial data with 10% run-ons, and real v. artificial data with 1% run-ons.", "labels": [], "entities": []}]}