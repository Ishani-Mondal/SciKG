{"title": [{"text": "Do Character-Level Neural Network Language Models Capture Knowledge of Multiword Expression Compositionality?", "labels": [], "entities": [{"text": "Character-Level Neural Network Language Models Capture Knowledge of Multiword Expression Compositionality", "start_pos": 3, "end_pos": 108, "type": "TASK", "confidence": 0.5746566707437689}]}], "abstractContent": [{"text": "In this paper we propose the first model for multiword expression (MWE) compositionality prediction based on character-level neural network language models.", "labels": [], "entities": [{"text": "multiword expression (MWE) compositionality prediction", "start_pos": 45, "end_pos": 99, "type": "TASK", "confidence": 0.7677002549171448}]}, {"text": "Experimental results on two kinds of MWEs (noun compounds and verb-particle constructions) and two languages (English and German) suggest that character-level neural network language models capture knowledge of multiword expression compositionality, in particular for English noun compounds and the particle component of English verb-particle constructions.", "labels": [], "entities": [{"text": "multiword expression compositionality", "start_pos": 211, "end_pos": 248, "type": "TASK", "confidence": 0.6553583840529124}]}, {"text": "In contrast to many other approaches to MWE compositionality prediction, this character-level approach does not require token-level identification of MWEs in a training corpus, and can potentially predict the compositionality of out-of-vocabulary MWEs.", "labels": [], "entities": [{"text": "MWE compositionality prediction", "start_pos": 40, "end_pos": 71, "type": "TASK", "confidence": 0.9745862682660421}]}], "introductionContent": [{"text": "Multiword expressions (MWEs) are lexical items that are composed of multiple words, and exhibit some degree of idiomaticity ( , for example semantic idiomaticity, in which the meaning of an MWE is not entirely transparent from the meanings of its component words, as in spill the beans, which has an idiomatic meaning of 'reveal a secret'.", "labels": [], "entities": [{"text": "Multiword expressions (MWEs)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6772768318653106}]}, {"text": "Compositionality is the degree to which the meaning of an MWE is predictable from the meanings of its component words.", "labels": [], "entities": []}, {"text": "It is typically viewed as lying on a continuum, with expressions such as speed limit and gravy train lying towards the compositional and non-compositional ends of the spectrum, respectively, and expressions such as rush hour and fine line falling somewhere in between as semi-compositional.", "labels": [], "entities": []}, {"text": "Compositionality can also be viewed with respect to an individual component word of an MWE, where an MWE component word is compositional if its meaning is reflected in the meaning of the expression.", "labels": [], "entities": []}, {"text": "For example, in spelling bee and grandfather clock, the first and second component words, respectively, are compositional, while the others are not.", "labels": [], "entities": [{"text": "spelling bee", "start_pos": 16, "end_pos": 28, "type": "TASK", "confidence": 0.6716271638870239}]}, {"text": "Knowledge of multiword expressions is important for natural language processing (NLP) tasks such as parsing ( and machine translation).", "labels": [], "entities": [{"text": "parsing", "start_pos": 100, "end_pos": 107, "type": "TASK", "confidence": 0.962023913860321}, {"text": "machine translation)", "start_pos": 114, "end_pos": 134, "type": "TASK", "confidence": 0.791904995838801}]}, {"text": "In the case of translation, compositionality is particularly important because a word-for-word translation would typically be incorrect fora non-compositional expression.", "labels": [], "entities": [{"text": "translation", "start_pos": 15, "end_pos": 26, "type": "TASK", "confidence": 0.9599593877792358}]}, {"text": "Much research has therefore focused on compositionality prediction of MWEs, primarily at the type level.", "labels": [], "entities": [{"text": "compositionality prediction of MWEs", "start_pos": 39, "end_pos": 74, "type": "TASK", "confidence": 0.7211302742362022}]}, {"text": "One common approach to measuring compositionality is to compare distributional representations of an MWE and its component words (e.g.,).", "labels": [], "entities": []}, {"text": "The hypothesis behind this line of work is that the representation of a compositional MWE will be more similar to the representations of its component words than the representation of a non-compositional MWE will be to those of its component words.", "labels": [], "entities": []}, {"text": "One issue faced by such approaches is that token-level instances of MWEs must be identified in a corpus in order to form distributional representations of them.", "labels": [], "entities": []}, {"text": "Token-level MWE identification has been studied for specific types of MWEs such as verb-particle constructions (e.g., ) and verb-noun idioms (e.g.,.", "labels": [], "entities": [{"text": "Token-level MWE identification", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8229578534762064}]}, {"text": "Broad coverage MWE identification has also been studied, and remains a challenge (.", "labels": [], "entities": [{"text": "Broad coverage MWE identification", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.6249287500977516}]}, {"text": "Language models are common throughout NLP in tasks including machine translation (, speech recognition (), and question answering).", "labels": [], "entities": [{"text": "machine translation", "start_pos": 61, "end_pos": 80, "type": "TASK", "confidence": 0.8021324872970581}, {"text": "speech recognition", "start_pos": 84, "end_pos": 102, "type": "TASK", "confidence": 0.7389870136976242}, {"text": "question answering", "start_pos": 111, "end_pos": 129, "type": "TASK", "confidence": 0.8511307537555695}]}, {"text": "Although word-level language models are widely used, and their performance can be higher than character-level language models, character-level models have the advantage that they can model out-of-vocabulary words ().", "labels": [], "entities": []}, {"text": "Owing to this advantage, character-level language models have been applied in a range of NLP tasks, including authorship attribution, (, part-of-speech tagging), case restoration (, and stock price prediction (dos Santos.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 110, "end_pos": 132, "type": "TASK", "confidence": 0.7739689648151398}, {"text": "part-of-speech tagging", "start_pos": 137, "end_pos": 159, "type": "TASK", "confidence": 0.7508929073810577}, {"text": "case restoration", "start_pos": 162, "end_pos": 178, "type": "TASK", "confidence": 0.9153112769126892}, {"text": "stock price prediction", "start_pos": 186, "end_pos": 208, "type": "TASK", "confidence": 0.6089551250139872}]}, {"text": "Moreover, character-level information can be composed to form representations of words (.", "labels": [], "entities": []}, {"text": "In this paper we consider whether character-level neural network language models capture knowledge of MWE compositionality.", "labels": [], "entities": [{"text": "MWE compositionality", "start_pos": 102, "end_pos": 122, "type": "TASK", "confidence": 0.947801798582077}]}, {"text": "We train character-level language models based on recurrent neural networks -including long short-term memory (LSTM, Hochreiter and Schmidhuber, 1997) and gated recurrent unit (GRU,).", "labels": [], "entities": []}, {"text": "We then use these language models to form continuous vector representations of MWEs and their component words.", "labels": [], "entities": []}, {"text": "Following prior work, we then use these representations to predict the compositionality of MWEs.", "labels": [], "entities": []}, {"text": "This method overcomes the limitation of previous work in this vein of having to identify token instances of MWEs in a corpus in order to form a distributional representation of them.", "labels": [], "entities": []}, {"text": "Moreover, this approach could potentially be applied to predict the compositionality of out-of-vocabulary expressions that were not seen in the corpus on which the language model was trained.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this is the first work to apply character-level neural network language models to predict MWE compositionality.", "labels": [], "entities": [{"text": "MWE compositionality", "start_pos": 120, "end_pos": 140, "type": "TASK", "confidence": 0.9695762991905212}]}, {"text": "Our experiments on two kinds of MWEs (noun compounds and verb-particle constructions) and two languages (English and German) produce mixed results, but suggest that character-level neural network language models do indeed capture some knowledge of multiword expression compositionality, in particular for English noun compounds and the particle component of English verb-particle constructions.", "labels": [], "entities": [{"text": "multiword expression compositionality", "start_pos": 248, "end_pos": 285, "type": "TASK", "confidence": 0.6796397765477499}]}], "datasetContent": [{"text": "The proposed model is evaluated over the same three datasets as, which cover two languages (English and German) and two kinds of MWEs (noun compounds and verb-particle constructions).", "labels": [], "entities": []}, {"text": "EVPC This dataset consists of 160 English verb-particle constructions (e.g., add up, figure out) which are rated on a binary scale for the compositionality of each of the verb and particle component words) by multiple annotators; no ratings for the overall compositionality of MWEs are provided in this dataset.", "labels": [], "entities": [{"text": "EVPC This dataset", "start_pos": 0, "end_pos": 17, "type": "DATASET", "confidence": 0.8318933248519897}]}, {"text": "The binary compositionality judgements are converted to continuous values as in by dividing the number of judgements that an expression is compositional by the total number of judgements.", "labels": [], "entities": []}, {"text": "GNC This dataset contains 244 German noun compounds (e.g., Ahornblatt 'maple leaf', Knoblauch 'garlic') which are annotated on a scale of for their overall compositionality, and the compositionality of each component word (von der Heide and Borgwaldt, 2009).", "labels": [], "entities": [{"text": "GNC This dataset", "start_pos": 0, "end_pos": 16, "type": "DATASET", "confidence": 0.9248324433962504}]}, {"text": "We evaluate our proposed approach following by computing Pearson's correlation between the predicted compositionality (i.e., from either comp 1 or comp 2 ) and human ratings for overall compositionality.", "labels": [], "entities": [{"text": "Pearson's correlation", "start_pos": 57, "end_pos": 78, "type": "METRIC", "confidence": 0.8896076480547587}]}, {"text": "For EVPC, no overall compositionality ratings are provided.", "labels": [], "entities": [{"text": "EVPC", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.753704845905304}]}, {"text": "In this case we report the correlation between the predicted compositionality scores and both the verb and particle compositionality judgements.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Pearson's correlation (r) for each dataset, using comp 1 and comp 2 . Significant correlations (p <  0.05) are indicated with *. The best results from Salehi et al. (2015) using comp 1 with representations  of the MWE and component words obtained from word2vec (Mikolov et al., 2013), are also shown.", "labels": [], "entities": [{"text": "Pearson's correlation (r)", "start_pos": 10, "end_pos": 35, "type": "METRIC", "confidence": 0.8263645271460215}]}, {"text": " Table 3: Pearson's correlation (r) for the ENC and EVPC datasets for each of component word 1 and 2.  Significant correlations (p < 0.05) are indicated with *.", "labels": [], "entities": [{"text": "Pearson's correlation (r)", "start_pos": 10, "end_pos": 35, "type": "METRIC", "confidence": 0.891841987768809}, {"text": "ENC", "start_pos": 44, "end_pos": 47, "type": "DATASET", "confidence": 0.9374433755874634}, {"text": "EVPC datasets", "start_pos": 52, "end_pos": 65, "type": "DATASET", "confidence": 0.8210465013980865}]}, {"text": " Table 4: Pearson's correlation (r) for MWEs that are attested, and unattested, in each dataset, using  comp 1 and comp 2 . Significant correlations (p < 0.05) are indicated with *. The number of attested and  unattested MWEs in each dataset is also shown.", "labels": [], "entities": [{"text": "Pearson's correlation (r)", "start_pos": 10, "end_pos": 35, "type": "METRIC", "confidence": 0.9096498886744181}]}]}