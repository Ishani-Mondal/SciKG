{"title": [{"text": "A Unified Neural Architecture for Joint Dialog Act Segmentation and Recognition in Spoken Dialog System", "labels": [], "entities": [{"text": "Joint Dialog Act Segmentation and Recognition", "start_pos": 34, "end_pos": 79, "type": "TASK", "confidence": 0.7317054470380148}]}], "abstractContent": [{"text": "In spoken dialog systems (SDSs), dialog act (DA) segmentation and recognition provide essential information for response generation.", "labels": [], "entities": [{"text": "dialog act (DA) segmentation", "start_pos": 33, "end_pos": 61, "type": "TASK", "confidence": 0.6752240161101023}, {"text": "response generation", "start_pos": 112, "end_pos": 131, "type": "TASK", "confidence": 0.7804339230060577}]}, {"text": "A majority of previous works assumed ground-truth segmen-tation of DA units, which is not available from automatic speech recognition (ASR) in SDS.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 105, "end_pos": 139, "type": "TASK", "confidence": 0.7494877874851227}]}, {"text": "We propose a unified architecture based on neural networks, which consists of a sequence tagger for segmenta-tion and a classifier for recognition.", "labels": [], "entities": []}, {"text": "The DA recognition model is based on hierarchical neural networks to incorporate the context of preceding sentences.", "labels": [], "entities": [{"text": "DA recognition", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.9677135646343231}]}, {"text": "We investigate sharing some layers of the two components so that they can be trained jointly and learn generalized features from both tasks.", "labels": [], "entities": []}, {"text": "An evaluation on the Switchboard Dialog Act (SwDA) corpus shows that the jointly-trained models outperform independently-trained models, single-step models, and other reported results in DA segmentation, recognition, and joint tasks.", "labels": [], "entities": [{"text": "Switchboard Dialog Act (SwDA)", "start_pos": 21, "end_pos": 50, "type": "TASK", "confidence": 0.8447328408559164}, {"text": "DA segmentation, recognition", "start_pos": 187, "end_pos": 215, "type": "TASK", "confidence": 0.7691548317670822}]}], "introductionContent": [{"text": "A growing interest in interactive conversational agents and robots has motivated research focus on spoken language understanding (SLU).", "labels": [], "entities": [{"text": "spoken language understanding (SLU)", "start_pos": 99, "end_pos": 134, "type": "TASK", "confidence": 0.7905946175257365}]}, {"text": "As an essential part of spoken dialog system (SDS), SLU analyzes user input, and provides the dialog system with information to make a response.", "labels": [], "entities": [{"text": "spoken dialog system (SDS)", "start_pos": 24, "end_pos": 50, "type": "TASK", "confidence": 0.6277629882097244}]}, {"text": "In conversations, dialog act (DA) represents the communicative function of an utterance ().", "labels": [], "entities": []}, {"text": "For instance, we can use DA tag Statement to describe utterance \"Me, I'm in the legal department.\" and use Yes-No-Question to describe \"Do you have to have any special training?\".", "labels": [], "entities": []}, {"text": "Recognition of DA benefits the understanding of dialog structure, thus allows SDS to conduct meaningful and smooth conversation, e.g. a Yes-Answer or No-Answer to a Yes-No-Question, and end the conversation after a Conventional-closing.", "labels": [], "entities": []}, {"text": "Most of previous works focused on DA recognition given transcriptions that are manually segmented (.", "labels": [], "entities": [{"text": "DA recognition", "start_pos": 34, "end_pos": 48, "type": "TASK", "confidence": 0.9936968982219696}]}, {"text": "Early works applied decision trees, Hidden Markov Model (), and ngram models ( to classify DA tags.", "labels": [], "entities": []}, {"text": "Recently, hierarchical neural networks have been introduced to the task.", "labels": [], "entities": []}, {"text": "Such models encode a DA segment into a sentence encoding by one network and apply the other network for DA recognition given a sequence of sentence encoding.", "labels": [], "entities": [{"text": "DA recognition", "start_pos": 104, "end_pos": 118, "type": "TASK", "confidence": 0.8041540086269379}]}, {"text": "Different combinations of networks such as CNN-ANN, RNN-ANN (, and RNN-RNN () are shown to greatly improve the accuracy of DA recognition.", "labels": [], "entities": [{"text": "CNN-ANN", "start_pos": 43, "end_pos": 50, "type": "DATASET", "confidence": 0.8846759796142578}, {"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9978479146957397}, {"text": "DA recognition", "start_pos": 123, "end_pos": 137, "type": "TASK", "confidence": 0.988402783870697}]}, {"text": "introduced an extra latent variable to a hierarchical RNN model to represent discourse relation.", "labels": [], "entities": []}, {"text": "Jointly training the latent variable model on DA recognition and language modeling tasks yields competitive results.", "labels": [], "entities": [{"text": "DA recognition", "start_pos": 46, "end_pos": 60, "type": "TASK", "confidence": 0.968472421169281}, {"text": "language modeling tasks", "start_pos": 65, "end_pos": 88, "type": "TASK", "confidence": 0.7779397567113241}]}, {"text": "Recent works ( on DA recognition use a hierarchical encoder to generate a vector representation for each DA segment, then a Conditional Random Field (CRF) tagger is applied to sequence labeling given the sequence of segment representations.", "labels": [], "entities": [{"text": "DA recognition", "start_pos": 18, "end_pos": 32, "type": "TASK", "confidence": 0.9730240702629089}]}, {"text": "reported an accuracy of 79.2% on SwDA, while achieved the current state-of-the-art accuracy of 81.3% by incorporating attentional mechanism and extra inputs (character embeddings, Part-Words okay so I guess it starts recording now: DA segmentation and recognition: \"I\" tag refers to inside of a segment, and \"E\" is the end of a segment. of-Speech tags, and named entitiy tags).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9993436932563782}, {"text": "SwDA", "start_pos": 33, "end_pos": 37, "type": "DATASET", "confidence": 0.7422797679901123}, {"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9982618689537048}]}, {"text": "However, these models with CRF layer assume that complete dialog is given before prediction.", "labels": [], "entities": []}, {"text": "Thus the reported performances will not apply to real-time SDS, where DA tags are often predicted incrementally.", "labels": [], "entities": [{"text": "SDS", "start_pos": 59, "end_pos": 62, "type": "TASK", "confidence": 0.7997887134552002}]}, {"text": "As shown in, an utterance in a conversational turn can consist of several DA units.", "labels": [], "entities": []}, {"text": "In the example, we use \"E\" tag to denote the end of a segment and \"I\" for inside.", "labels": [], "entities": []}, {"text": "The utterance \"okay so I guess it starts recording now\" are split into two segments, which area Backchannel and a Statement respectively.", "labels": [], "entities": [{"text": "Backchannel", "start_pos": 96, "end_pos": 107, "type": "METRIC", "confidence": 0.7254970669746399}]}, {"text": "However, automatic speech recognition (ASR) in SDS usually provides no punctuation that gives hints for DA segmentation, thus it is necessary to build a sequence labeler for automatic DA segmentation.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 9, "end_pos": 43, "type": "TASK", "confidence": 0.7786214699347814}, {"text": "DA segmentation", "start_pos": 104, "end_pos": 119, "type": "TASK", "confidence": 0.8565674424171448}, {"text": "DA segmentation", "start_pos": 184, "end_pos": 199, "type": "TASK", "confidence": 0.822152704000473}]}, {"text": "A majority of previous works of DA segmentation formulated DA segmentation and recognition in a single step (.", "labels": [], "entities": [{"text": "DA segmentation", "start_pos": 32, "end_pos": 47, "type": "TASK", "confidence": 0.9672916233539581}, {"text": "DA segmentation and recognition", "start_pos": 59, "end_pos": 90, "type": "TASK", "confidence": 0.7349264472723007}]}, {"text": "Segmentation labels are combined with DA labels (e.g. \"E Statement\" denotes the end of a Statement segment), and a sequence labeling model is applied to predict tags for both tasks.", "labels": [], "entities": []}, {"text": "This approach has a merit of integration so that recognition helps segmentation and segmentation errors are not propagated to the recognition step.", "labels": [], "entities": []}, {"text": "On the other hand, it has a drawback that it can hardly incorporate a history of preceding sentences to predict the DA tag of the current sentence.", "labels": [], "entities": [{"text": "DA tag", "start_pos": 116, "end_pos": 122, "type": "METRIC", "confidence": 0.9283507466316223}]}, {"text": "Another approach is to process the data in a pipeline manner.", "labels": [], "entities": []}, {"text": "used a CRF for DA segmentation and a Supported Vector Machine (SVM) for DA recognition given predicted segments.", "labels": [], "entities": [{"text": "DA segmentation", "start_pos": 15, "end_pos": 30, "type": "TASK", "confidence": 0.9618490636348724}, {"text": "DA recognition", "start_pos": 72, "end_pos": 86, "type": "TASK", "confidence": 0.9264312088489532}]}, {"text": "For pipeline methods, downstream task (e.g. DA recognition) is vulnerable to errors from upstream task (e.g. DA segmentation).", "labels": [], "entities": [{"text": "DA recognition)", "start_pos": 44, "end_pos": 59, "type": "TASK", "confidence": 0.7968041698137919}, {"text": "DA segmentation", "start_pos": 109, "end_pos": 124, "type": "TASK", "confidence": 0.6431823670864105}]}, {"text": "In this paper we propose a unified architecture based on neural networks for DA segmentation and recognition to solve the aforementioned problems.", "labels": [], "entities": [{"text": "DA segmentation and recognition", "start_pos": 77, "end_pos": 108, "type": "TASK", "confidence": 0.8128491938114166}]}, {"text": "Our method uses separate models for DA segmentation and recognition but introduces joint learning so that the models can learn from both tasks.", "labels": [], "entities": [{"text": "DA segmentation", "start_pos": 36, "end_pos": 51, "type": "TASK", "confidence": 0.9654465019702911}]}, {"text": "Joint learning (also multi-task learning) allows a model to learn from different tasks in parallel, which benefits the generalization of the model.", "labels": [], "entities": []}, {"text": "introduced a unified architecture based on Convolutional Neural Networks (CNNs) to natural language processing tasks such as Part-of-Speech (POS) tagging and chunking, and showed that joint learning of related tasks improves model performance.", "labels": [], "entities": [{"text": "Part-of-Speech (POS) tagging", "start_pos": 125, "end_pos": 153, "type": "TASK", "confidence": 0.6852303743362427}]}, {"text": "Inspired by this work, we investigate joint learning of DA segmentation and recognition for better generalized model.", "labels": [], "entities": [{"text": "DA segmentation and recognition", "start_pos": 56, "end_pos": 87, "type": "TASK", "confidence": 0.7915237247943878}]}, {"text": "We compare the jointly-trained models under the unified architecture with models trained separately and previous works on the Switchboard Dialog Act (SwDA) corpus.", "labels": [], "entities": [{"text": "Switchboard Dialog Act (SwDA) corpus", "start_pos": 126, "end_pos": 162, "type": "DATASET", "confidence": 0.7903140783309937}]}], "datasetContent": [{"text": "Three sets of experiments are conducted to evaluate model performance on the DA segmentation task, the DA recognition task, and their joint task respectively.", "labels": [], "entities": [{"text": "DA segmentation task", "start_pos": 77, "end_pos": 97, "type": "TASK", "confidence": 0.9111067851384481}, {"text": "DA recognition task", "start_pos": 103, "end_pos": 122, "type": "TASK", "confidence": 0.8925472696622213}]}, {"text": "In the segmentation task, we use the word sequence tagger to predict segmentation labels given a sequence of words in a turn.", "labels": [], "entities": [{"text": "segmentation task", "start_pos": 7, "end_pos": 24, "type": "TASK", "confidence": 0.9215853214263916}]}, {"text": "In the recognition task, segments with correct boundaries are given as inputs, and we use the sentence classifier to predict a DA tag for each segment.", "labels": [], "entities": []}, {"text": "Lastly in the joint task, instead of using segments with correct boundaries, we split each turn into segments according to the predicted segmentation labels by the sequence tagger.", "labels": [], "entities": []}, {"text": "Then the sentence classifier outputs DA tags for the predicted segments.", "labels": [], "entities": []}, {"text": "Word-level error rate is used to assess performance on the segmentation task.", "labels": [], "entities": [{"text": "Word-level error rate", "start_pos": 0, "end_pos": 21, "type": "METRIC", "confidence": 0.6389944056669871}, {"text": "segmentation task", "start_pos": 59, "end_pos": 76, "type": "TASK", "confidence": 0.915206640958786}]}, {"text": "It compares the predicted boundaries with ground-truth boundaries and counts the number of words that lie in wrongly: An example of the calculation of metrics for segmentation and joint tasks, where word-level segmentation error rate is 54.5% (6/11), and word-level joint error rate is 72.7% (8/11).", "labels": [], "entities": [{"text": "word-level segmentation error rate", "start_pos": 199, "end_pos": 233, "type": "METRIC", "confidence": 0.6131852865219116}, {"text": "word-level joint error rate", "start_pos": 255, "end_pos": 282, "type": "METRIC", "confidence": 0.6394731551408768}]}, {"text": "The joint task is evaluated on word level as well.", "labels": [], "entities": []}, {"text": "However, it additionally takes DA tags into consideration.", "labels": [], "entities": []}, {"text": "An example of the calculation of these metrics is illustrated by.", "labels": [], "entities": []}, {"text": "The DA recognition task is evaluated by accuracy.", "labels": [], "entities": [{"text": "DA recognition task", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.9524041612943014}, {"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9991995692253113}]}, {"text": "We use the mini-batch gradient descent with momentum to optimize the models with a mini-batch size of 32 for 20 epochs.", "labels": [], "entities": []}, {"text": "The learning rate is set as 1 initially and decays in half when the total loss of development dataset does not decrease.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 4, "end_pos": 17, "type": "METRIC", "confidence": 0.9217728078365326}]}, {"text": "Gradients are clipped between [-0.5, 0.5] to avoid exploding.", "labels": [], "entities": []}, {"text": "We also experiment with different values of history length k from 1 to 5, which is the number of preceding sentence encodings used in the upperlevel LSTM of the DA recognition.", "labels": [], "entities": [{"text": "DA recognition", "start_pos": 161, "end_pos": 175, "type": "TASK", "confidence": 0.9121923446655273}]}, {"text": "For all the implemented models, we choose 200, 100 as the dimension of word embedding and the dimension of LSTM hidden states respectively.", "labels": [], "entities": []}, {"text": "Both word sequence encoding BiLSTM and sentence encoding BiLSTM consist of two hidden layers, while the sentence sequence encoding LSTM has only one hidden layer.", "labels": [], "entities": [{"text": "sentence encoding BiLSTM", "start_pos": 39, "end_pos": 63, "type": "TASK", "confidence": 0.5224784513314565}]}, {"text": "Dropout () is applied after the word embedding layer and between the BiLSTM layers with a drop probability of 0.5.", "labels": [], "entities": []}, {"text": "The error rates of the three models are shown in.", "labels": [], "entities": [{"text": "error", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.965137243270874}]}, {"text": "With punctuation and slash marks removed, segmentation error rates are fairly high (from 18.7% to 20.8%).", "labels": [], "entities": [{"text": "segmentation", "start_pos": 42, "end_pos": 54, "type": "TASK", "confidence": 0.9593797922134399}, {"text": "error", "start_pos": 55, "end_pos": 60, "type": "METRIC", "confidence": 0.5823199152946472}]}, {"text": "However, the jointlytrained models (Model 2 and 3) always result in lower error rates than Model 1.", "labels": [], "entities": []}, {"text": "It indicates that joint training benefits the segmentation model in the unified architecture.", "labels": [], "entities": []}, {"text": "Specifically, there is a statistically significant error rate reduction of 1.3% when comparing the best result of Model 2 (18.7%) with that of Model 1 (20.0%), and also a statistically significant reduction of 0.9% when compared with the single-step model's 19.6%.", "labels": [], "entities": [{"text": "error rate reduction", "start_pos": 51, "end_pos": 71, "type": "METRIC", "confidence": 0.9773484865824381}]}, {"text": "(2011) reported a segmentation error rate of 1.4% using CRF model in their work.", "labels": [], "entities": [{"text": "segmentation error rate", "start_pos": 18, "end_pos": 41, "type": "METRIC", "confidence": 0.8014248112837473}]}, {"text": "However, they used punctuation and slash marks which we removed, thus it is inappropriate to directly compare the results.", "labels": [], "entities": []}, {"text": "As shown in, Model 1 achieves 77.1% at a history length of 5 and gives a strong baseline.", "labels": [], "entities": [{"text": "history length", "start_pos": 41, "end_pos": 55, "type": "METRIC", "confidence": 0.9245285987854004}]}, {"text": "Through joint training, Model 2 and 3 further improved the accuracy to 77.7% and 77.8% at history length of 1 and 2.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9990947246551514}, {"text": "history length", "start_pos": 90, "end_pos": 104, "type": "METRIC", "confidence": 0.9184049069881439}]}, {"text": "Since the single model simulta- 73.1 DRLM ( 77.0 Hierarchical GRU ( 79.4 * * * The CRF used punctuation and slash marks for segmentation.", "labels": [], "entities": [{"text": "GRU", "start_pos": 62, "end_pos": 65, "type": "METRIC", "confidence": 0.5527280569076538}]}, {"text": "For reference, when punctuation and slash marks are reserved in our experiments, Model 2 gets a word-level segmentation error rate of 0.3% and a joint error rate of 20.5%.", "labels": [], "entities": [{"text": "word-level segmentation error rate", "start_pos": 96, "end_pos": 130, "type": "TASK", "confidence": 0.7097600698471069}, {"text": "joint error rate", "start_pos": 145, "end_pos": 161, "type": "METRIC", "confidence": 0.843992551167806}]}, {"text": "* * Non-textual features were used in this work.", "labels": [], "entities": []}, {"text": "shows word-level joint error rates of the proposed models.", "labels": [], "entities": []}, {"text": "Model 1, 2, and 3 have lowest error rates of 31.8%, 30.6%, and 31.0% respectively.", "labels": [], "entities": [{"text": "error rates", "start_pos": 30, "end_pos": 41, "type": "METRIC", "confidence": 0.9918464720249176}]}, {"text": "We can see that Model 2 and 3 have better results than Model 1 for all history lengths, which suggests jointly-trained models consistently perform better.", "labels": [], "entities": []}, {"text": "It is confirmed from the results that joint learning gives a statistically significant error rate reduction (1.2% reduction from 31.8% of Model 1 to 30.6% of Model 2).", "labels": [], "entities": [{"text": "error rate", "start_pos": 87, "end_pos": 97, "type": "METRIC", "confidence": 0.9751732349395752}]}, {"text": "The singlestep neural network results in 33.5% joint error rate, much higher than the proposed models.", "labels": [], "entities": [{"text": "joint error rate", "start_pos": 47, "end_pos": 63, "type": "METRIC", "confidence": 0.8583143949508667}]}, {"text": "A major reason is that the single-step model cannot capture context of preceding sentences, thus degrading recognition accuracy and leading to poor performance in the joint task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.954310417175293}]}, {"text": "A single-step CRF model by, which uses word and Part-of-Speech (POS) n-grams features, reached a word-level joint error rate of 29.1% while its segmentation error rate reached 1.4% using punctuation and slash marks in transcription.", "labels": [], "entities": [{"text": "word-level joint error rate", "start_pos": 97, "end_pos": 124, "type": "METRIC", "confidence": 0.6637090966105461}]}, {"text": "If we also reserve punctuation and slash marks in our experiments, Model 2 is able to get a lowest joint error rate of 20.5% with a segmentation error rate of only 0.3%.", "labels": [], "entities": [{"text": "joint error rate", "start_pos": 99, "end_pos": 115, "type": "METRIC", "confidence": 0.8630531628926595}, {"text": "segmentation error rate", "start_pos": 132, "end_pos": 155, "type": "METRIC", "confidence": 0.8008531928062439}]}, {"text": "Model 3 shares the higher-level layers than Model 2 but does not develop consistent and significant advantage.", "labels": [], "entities": []}, {"text": "We noticed that the segmentation performance and recognition performance of Model 3 have a reverse trend, i.e. the recognition accuracy decreases when the segmentation error rate reduces.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 127, "end_pos": 135, "type": "METRIC", "confidence": 0.8811582326889038}]}, {"text": "We suspect that since most parameters in the segmentation components are shared (all layers except for the segmentation decoding layer) in Model 3, signals from the DA recognition side can affect the entire segmentation model and lead to problems in optimization.", "labels": [], "entities": [{"text": "DA recognition", "start_pos": 165, "end_pos": 179, "type": "TASK", "confidence": 0.7946281135082245}]}, {"text": "The best results of the mentioned models in segmentation, recognition, and joint tasks are summarized in.", "labels": [], "entities": [{"text": "segmentation, recognition", "start_pos": 44, "end_pos": 69, "type": "TASK", "confidence": 0.6032814284165701}]}], "tableCaptions": [{"text": " Table 3: Corpus statistics of SwDA.", "labels": [], "entities": [{"text": "Corpus statistics of SwDA", "start_pos": 10, "end_pos": 35, "type": "DATASET", "confidence": 0.6654839813709259}]}]}