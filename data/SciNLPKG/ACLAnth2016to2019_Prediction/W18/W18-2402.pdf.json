{"title": [{"text": "Connecting Distant Entities with Induction through Conditional Random Fields for Named Entity Recognition: Precursor-Induced CRF", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 81, "end_pos": 105, "type": "TASK", "confidence": 0.6353425880273184}, {"text": "CRF", "start_pos": 125, "end_pos": 128, "type": "TASK", "confidence": 0.33033379912376404}]}], "abstractContent": [{"text": "This paper presents a method of designing specific high-order dependency factor on the linear chain conditional random fields (CRFs) for named entity recognition (NER).", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 137, "end_pos": 167, "type": "TASK", "confidence": 0.7846677750349045}]}, {"text": "Named entities tend to be separated from each other by multiple outside tokens in a text, and thus the first-order CRF, as well as the second-order CRF, may innately lose transition information between distant named entities.", "labels": [], "entities": []}, {"text": "The proposed design uses outside label in NER as a transmission medium of precedent entity information on the CRF.", "labels": [], "entities": []}, {"text": "Then, empirical results apparently demonstrate that it is possible to exploit long-distance label dependency in the original first-order linear chain CRF structure upon NER while reducing computational loss rather than in the second-order CRF.", "labels": [], "entities": []}], "introductionContent": [{"text": "The concept of conditional random fields (CRFs)) has been successfully adapted in many sequence labeling problems).", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 87, "end_pos": 104, "type": "TASK", "confidence": 0.6401546448469162}]}, {"text": "Even in deep-learning architecture, CRF has been used as a fundamental element in named entity recognition.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 82, "end_pos": 106, "type": "TASK", "confidence": 0.6684964994589487}]}, {"text": "One of the primary advantages of applying the CRF to language processing is that it learns transition factors between hidden variables corresponding to the label of single word.", "labels": [], "entities": []}, {"text": "The fundamental assumption of the model is that the current hidden state is conditioned on present observation as well as the previous state.", "labels": [], "entities": []}, {"text": "For example, a part-ofspeech (POS) tag depends on the word itself, as well as the POS tag transitions from the previous word.", "labels": [], "entities": []}, {"text": "In the problem, the POS tags are adjacent to each other in a text forming a tag sequence; therefore, the sequence labeling model can fully capture dependencies between labels.", "labels": [], "entities": []}, {"text": "In contrast, a CRF in named entity recognition (NER) cannot fully capture dependencies between named entity (NE) labels.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 22, "end_pos": 52, "type": "TASK", "confidence": 0.8351916670799255}]}, {"text": "According to, named entities in a text are separated by successive \"outside tokens\" (i.e., words that are non-named entities syntactically linking two NEs) and considerable number of NEs have a tendency to exist at a distance from each other.", "labels": [], "entities": []}, {"text": "Therefore, high-order interdependencies of named entities between successive outside tokens are not captured by first-order or second-order transition factors.", "labels": [], "entities": []}, {"text": "One major issue in previous studies was concerned with the way in which to explore long-distance dependencies in NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 113, "end_pos": 116, "type": "TASK", "confidence": 0.9358623623847961}]}, {"text": "Only dependencies between neighbor labels are generally used in practice because conventional high-order CRFs are known to be intractable in NER.", "labels": [], "entities": []}, {"text": "Previous studies have demonstrated that implementation of the higherorder CRF exploiting pre-defined label patterns leads to slight performance improvement in the conventional CRF in NER.", "labels": [], "entities": []}, {"text": "However, there are certain drawbacks associated with handling named entity transitions within arbitrary length outside tokens.", "labels": [], "entities": []}, {"text": "In an attempt to utilize long-distance transition information of NEs through non-named entity to-kens, this study explores the method which modifies the first-order linear-chain CRF by using the induction method.", "labels": [], "entities": []}], "datasetContent": [{"text": "All the experiments were performed by implementing both the original and precursor-induced CRF . The activity refers to CRF implemented in MALLET).", "labels": [], "entities": []}, {"text": "To compare precursor-induced CRF with the original CRF in NER on the real-world clinical documents and biomedical literatures, three annotated NER corpus were used; i2b2 2012 NLP shared task data 1 https://github.com/jinsamdol/precursor-induced_CRF, discharge summaries of rheumatism patients at Seoul National University Hospital (SNUH), and JNLPBA 2004 Bio-Entity Recognition shared task data).", "labels": [], "entities": [{"text": "i2b2 2012 NLP shared task data", "start_pos": 165, "end_pos": 195, "type": "DATASET", "confidence": 0.6565121114253998}, {"text": "JNLPBA 2004 Bio-Entity Recognition shared task data", "start_pos": 343, "end_pos": 394, "type": "DATASET", "confidence": 0.7115248952593122}]}, {"text": "The discharge summary of rheumatism patient corpus is built for this evaluation.", "labels": [], "entities": []}, {"text": "This corpus consists of 200 electronic clinical documents where English and Korean words are jointly used for recording patient history.", "labels": [], "entities": []}, {"text": "We used the division of training and test set provided by the i2b2 2012 and JNLPBA corpus in this evaluation.", "labels": [], "entities": [{"text": "JNLPBA corpus", "start_pos": 76, "end_pos": 89, "type": "DATASET", "confidence": 0.8504111766815186}]}, {"text": "For the SNUH corpus, 10-fold cross validation was used.", "labels": [], "entities": [{"text": "SNUH corpus", "start_pos": 8, "end_pos": 19, "type": "DATASET", "confidence": 0.8109514713287354}]}, {"text": "Annotated named entities involved in the clinical NER evaluation are related to mentions describing the patient's history.", "labels": [], "entities": [{"text": "NER evaluation", "start_pos": 50, "end_pos": 64, "type": "TASK", "confidence": 0.9370998442173004}]}, {"text": "In the i2b2 2012 corpus, problem, test, and treatment named entity classes are used.", "labels": [], "entities": [{"text": "i2b2 2012 corpus", "start_pos": 7, "end_pos": 23, "type": "DATASET", "confidence": 0.8020195364952087}]}, {"text": "In the SNUH corpus, symptom, test, diagnosis, medication, and procedure-operation classes are used.", "labels": [], "entities": [{"text": "SNUH corpus", "start_pos": 7, "end_pos": 18, "type": "DATASET", "confidence": 0.8156433999538422}]}, {"text": "The named entity classes in the biomedical NER evaluation are DNA, RNA, protein, cell line, and cell type.", "labels": [], "entities": [{"text": "NER evaluation", "start_pos": 43, "end_pos": 57, "type": "TASK", "confidence": 0.8783583343029022}]}, {"text": "Median value of the distance between consecutive entities tend to be within 3-4 in the datasets.", "labels": [], "entities": []}, {"text": "The long distance dependency is restricted within a single instance (i.e., a sentence).", "labels": [], "entities": []}, {"text": "To perform NER evaluation, two types of feature families are used: (a) token itself and neighbor tokens in window size 3.", "labels": [], "entities": [{"text": "NER evaluation", "start_pos": 11, "end_pos": 25, "type": "TASK", "confidence": 0.9386158883571625}]}, {"text": "In addition, morphologically normalized tokens are used together.", "labels": [], "entities": []}, {"text": "(b) morphology features such as character prefix and suffix of length 2-4.", "labels": [], "entities": []}, {"text": "Our feature setting 1 uses the single feature family (a) and feature setting 2 simultaneously uses both of the feature family (a) and (b).", "labels": [], "entities": []}, {"text": "The reason for setting these simple feature configurations is for the purpose of reducing bias that the feature will affect the performance comparison of the models.", "labels": [], "entities": []}, {"text": "In order to compare the proposed model with the conventional CRF, both the first-order and the second-order CRF are used as baseline models.", "labels": [], "entities": []}, {"text": "The performance comparison result is shown in the.", "labels": [], "entities": []}, {"text": "The result shows a tendency that precursor-induced (pre-induced) CRF leads to a slight performance improvement compared to both the first-order and second-order CRFs inmost cases.", "labels": [], "entities": []}, {"text": "However, the overall improvement is small.", "labels": [], "entities": []}, {"text": "compares the elapsed time per iteration in parameter training for each model.", "labels": [], "entities": []}, {"text": "The result shows that the second-order CRF takes quite more time than the first-order CRF to compute one training iteration.", "labels": [], "entities": []}, {"text": "The pre-induced CRF takes 1.7 times more computation time than the first-order CRF in average.", "labels": [], "entities": []}, {"text": "The pre-induced CRF takes significantly less time than the second-order CRF while the preinduced CRF exploits longer label transition dependency than the second-order CRF.", "labels": [], "entities": []}, {"text": "These results indicate that the precursor-induced CRF, where long-distance dependency is introduced in CRF by label induction, slightly improves the effectiveness in clinical and biomedical NER while also significantly reducing computational cost rather than building second-or higher-order CRFs.", "labels": [], "entities": [{"text": "NER", "start_pos": 190, "end_pos": 193, "type": "TASK", "confidence": 0.8366327881813049}]}], "tableCaptions": [{"text": " Table 2: Elapsed training time (s/iteration)", "labels": [], "entities": []}]}