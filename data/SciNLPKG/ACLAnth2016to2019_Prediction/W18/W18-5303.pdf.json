{"title": [{"text": "Macquarie University at BioASQ 6b: Deep learning and deep reinforcement learning for query-based multi-document summarisation", "labels": [], "entities": [{"text": "Macquarie University at BioASQ 6b", "start_pos": 0, "end_pos": 33, "type": "DATASET", "confidence": 0.9047679901123047}, {"text": "summarisation", "start_pos": 112, "end_pos": 125, "type": "TASK", "confidence": 0.7653878331184387}]}], "abstractContent": [{"text": "This paper describes Macquarie Univer-sity's contribution to the BioASQ Challenge (BioASQ 6b, Phase B).", "labels": [], "entities": [{"text": "Macquarie", "start_pos": 21, "end_pos": 30, "type": "DATASET", "confidence": 0.953384280204773}]}, {"text": "We focused on the extraction of the ideal answers, and the task was approached as an instance of query-based multi-document summarisation.", "labels": [], "entities": []}, {"text": "In particular , this paper focuses on the experiments related to the deep learning and reinforcement learning approaches used in the submitted runs.", "labels": [], "entities": []}, {"text": "The best run used a deep learning model under a regression-based framework.", "labels": [], "entities": []}, {"text": "The deep learning architecture used features derived from the output of LSTM chains on word embeddings, plus features based on similarity with the query, and sentence position.", "labels": [], "entities": []}, {"text": "The reinforcement learning approach was a proof-of-concept prototype that trained a global policy using REINFORCE.", "labels": [], "entities": [{"text": "reinforcement learning", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.8949435353279114}, {"text": "REINFORCE", "start_pos": 104, "end_pos": 113, "type": "METRIC", "confidence": 0.8483559489250183}]}, {"text": "The global policy was implemented as a neural network that used tf.idf features encoding the candidate sentence, question, and context.", "labels": [], "entities": []}], "introductionContent": [{"text": "The BioASQ Challenge 1 consists of various tasks related to biomedical semantic indexing and question answering.", "labels": [], "entities": [{"text": "biomedical semantic indexing", "start_pos": 60, "end_pos": 88, "type": "TASK", "confidence": 0.7034639020760854}, {"text": "question answering", "start_pos": 93, "end_pos": 111, "type": "TASK", "confidence": 0.8305858075618744}]}, {"text": "Our participation in BioASQ for 2018 focused on Task B Phase B, where our system attempted to find the ideal answer given a question and a collection of relevant snippets of text.", "labels": [], "entities": []}, {"text": "We approached this task as an instance of query-based multi-document summarisation, where the ideal answer is the summary to produce.", "labels": [], "entities": [{"text": "multi-document summarisation", "start_pos": 54, "end_pos": 82, "type": "TASK", "confidence": 0.535079762339592}]}, {"text": "The BioASQ challenge focuses on a restricted domain, namely biomedical literature.", "labels": [], "entities": []}, {"text": "Nevertheless, the techniques developed for our system were domain-agnostic and can be applied to any domain, provided that the domain has enough training data and a specialised corpus large enough to train word embeddings.", "labels": [], "entities": []}, {"text": "We were interested in exploring the use of deep learning and reinforcement learning for this task.", "labels": [], "entities": []}, {"text": "Thus, Section 2 explains our experiments using deep learning techniques.", "labels": [], "entities": []}, {"text": "Section 3 details our experiments using reinforcement learning.", "labels": [], "entities": []}, {"text": "Section 4 specifies the settings used in the experiments.", "labels": [], "entities": []}, {"text": "Section 5 shows and discusses the results, and Section 6 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Settings used in the SVR experiments.", "labels": [], "entities": [{"text": "SVR", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.8141413331031799}]}, {"text": " Table 3: Settings used in the deep learning experi- ments.", "labels": [], "entities": []}]}