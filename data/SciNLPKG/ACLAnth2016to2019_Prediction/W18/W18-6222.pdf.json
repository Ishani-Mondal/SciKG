{"title": [{"text": "Sentiment Expression Boundaries in Sentiment Polarity Classification", "labels": [], "entities": [{"text": "Sentiment Expression Boundaries", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8826539119084676}, {"text": "Sentiment Polarity Classification", "start_pos": 35, "end_pos": 68, "type": "TASK", "confidence": 0.7002322475115458}]}], "abstractContent": [{"text": "We investigate the effect of using sentiment expression boundaries in predicting sentiment polarity in aspect-level sentiment analysis.", "labels": [], "entities": [{"text": "predicting sentiment polarity", "start_pos": 70, "end_pos": 99, "type": "TASK", "confidence": 0.7209961215655009}, {"text": "aspect-level sentiment analysis", "start_pos": 103, "end_pos": 134, "type": "TASK", "confidence": 0.6811584830284119}]}, {"text": "We manually annotate a freely available English sentiment polarity dataset with these boundaries and carryout a series of experiments which demonstrate that high quality sentiment expressions can boost the performance of polarity classification.", "labels": [], "entities": [{"text": "English sentiment polarity dataset", "start_pos": 40, "end_pos": 74, "type": "DATASET", "confidence": 0.601222038269043}, {"text": "polarity classification", "start_pos": 221, "end_pos": 244, "type": "TASK", "confidence": 0.8165608644485474}]}, {"text": "Our experiments with neural architectures also show that CNN networks outperform LSTMs on this task and dataset.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sentiment analysis is a much studied problem in natural language processing research, yet it is far from solved, especially when a fine-grained analysis is required.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9494396150112152}]}, {"text": "Aspect-based sentiment analysis () is concerned with multi-faceted opinions.", "labels": [], "entities": [{"text": "Aspect-based sentiment analysis", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8790273865063986}]}, {"text": "Consider, for example, a restaurant review which states that the food was delicious but the place was too noisy.", "labels": [], "entities": []}, {"text": "For anyone using such a review to inform a decision about whereto dine, this aspect-based information is more useful than one overall sentiment score.", "labels": [], "entities": []}, {"text": "In this work, we aim to improve the performance of sentence-level aspect-based sentiment polarity classification.", "labels": [], "entities": [{"text": "sentence-level aspect-based sentiment polarity classification", "start_pos": 51, "end_pos": 112, "type": "TASK", "confidence": 0.6657192945480347}]}, {"text": "We compare several neural architectures and we investigate whether identifying and highlighting the parts of the sentence which carry the sentiment can be beneficial for this task.", "labels": [], "entities": []}, {"text": "The data that we use in our experiments is an English dataset used in the SemEval 2016 Task on Aspect-Based Sentiment Analysis (, which consists of consumer reviews of restaurants and laptops.", "labels": [], "entities": [{"text": "SemEval 2016 Task on Aspect-Based Sentiment Analysis", "start_pos": 74, "end_pos": 126, "type": "TASK", "confidence": 0.7984296764646258}]}, {"text": "Each sentence is annotated with the aspect of the restaurant or laptop that is being discussed in the sentence together with the polarity of the sentiment towards that aspect.", "labels": [], "entities": []}, {"text": "Some aspects are quite general to any product or service, e.g. value for money, but many are domain-specific, e.g. battery life and performance for laptops, and ambience and food quality for restaurants.", "labels": [], "entities": []}, {"text": "We first apply two very widely used neural architectures -CNNs () and LSTMs -to the problem of predicting the polarity towards an aspect.", "labels": [], "entities": [{"text": "predicting the polarity towards an aspect", "start_pos": 95, "end_pos": 136, "type": "TASK", "confidence": 0.7928758859634399}]}, {"text": "We show that CNNs work better than LSTMs, and experiment with two ways of combining the two networks, neither of which provide a significant improvement over CNNs.", "labels": [], "entities": []}, {"text": "We compare to those SemEval 2016 shared task systems which also used a neural architecture, and confirm that our systems are competitive.", "labels": [], "entities": [{"text": "SemEval 2016 shared task", "start_pos": 20, "end_pos": 44, "type": "TASK", "confidence": 0.6258754581212997}]}, {"text": "Our next step is to provide a further layer of annotation to the data by marking those words in a sentence which are contributing towards the sentiment.", "labels": [], "entities": []}, {"text": "Once the data is annotated with sentiment expressions, we use the annotation to augment our baseline models and show that this information increases polarity classification accuracy by approximately six percentage points on average.", "labels": [], "entities": [{"text": "polarity classification", "start_pos": 149, "end_pos": 172, "type": "TASK", "confidence": 0.6874225437641144}, {"text": "accuracy", "start_pos": 173, "end_pos": 181, "type": "METRIC", "confidence": 0.9617809057235718}]}, {"text": "We then experiment with multi-task learning) in order to jointly learn sentiment expression boundaries and polarities.", "labels": [], "entities": []}, {"text": "However, we do not see an improvement in polarity classification with our joint architecture.", "labels": [], "entities": [{"text": "polarity classification", "start_pos": 41, "end_pos": 64, "type": "TASK", "confidence": 0.7017998844385147}]}, {"text": "The paper is organised as follows: in Section 2 we describe our data in more detail; in Section 3 we describe the architectures of our baseline systems and compare to other neural systems; in Section 4, we describe the process of enriching the original dataset with sentiment expression annotations; in Section 5, our sentiment polarity classification experiments involving this enriched dataset are presented; we review related work on senti-", "labels": [], "entities": [{"text": "sentiment polarity classification", "start_pos": 318, "end_pos": 351, "type": "TASK", "confidence": 0.7484935919443766}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: SemEval 2016 Task 5 Dataset Examples (D: domain, R: restaurant, L: laptop)", "labels": [], "entities": [{"text": "SemEval 2016 Task 5 Dataset", "start_pos": 10, "end_pos": 37, "type": "DATASET", "confidence": 0.7337288737297059}]}, {"text": " Table 2: Number of sentences, aspect categories  and their polarity distributions in the datasets", "labels": [], "entities": []}, {"text": " Table 1. Each aspect category is of the  form E#A, where E is an entity and A is some at- tribute of that entity. There are 11 distinct aspect  categories in the restaurant dataset and 31 in the  laptop dataset.  The SemEval 2016 shared task, and its previous  iterations in 2014 and 2015, were concerned with  several sentence-level subtasks including identi- fying aspect categories, opinion target expres-", "labels": [], "entities": [{"text": "laptop dataset", "start_pos": 197, "end_pos": 211, "type": "DATASET", "confidence": 0.7981880009174347}, {"text": "SemEval 2016 shared task", "start_pos": 218, "end_pos": 242, "type": "TASK", "confidence": 0.8240187615156174}]}, {"text": " Table 3: Accuracy of aspect-based sentiment polarity classification models (gse: using gold-standard  sentiment expressions, filtered: filtering non-SE tokens)", "labels": [], "entities": [{"text": "sentiment polarity classification", "start_pos": 35, "end_pos": 68, "type": "TASK", "confidence": 0.7443593541781107}]}, {"text": " Table 4: Test set accuracy of neural systems who participated in the SemEval 2016 polarity classification  task for aspect-based sentiment analysis", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9729740619659424}, {"text": "SemEval 2016 polarity classification  task", "start_pos": 70, "end_pos": 112, "type": "TASK", "confidence": 0.9231706619262695}, {"text": "aspect-based sentiment analysis", "start_pos": 117, "end_pos": 148, "type": "TASK", "confidence": 0.6820487181345621}]}, {"text": " Table 5: SemEval 2016 Task 5 Dataset Examples with Sentiment Expressions (in bold)", "labels": [], "entities": [{"text": "SemEval 2016 Task 5 Dataset", "start_pos": 10, "end_pos": 37, "type": "DATASET", "confidence": 0.840531075000763}]}]}