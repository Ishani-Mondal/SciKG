{"title": [], "abstractContent": [{"text": "This paper describes the unsupervised neu-ral machine translation (NMT) systems of the RWTH Aachen University developed for the English \u2194 German news translation task of the EMNLP 2018 Third Conference on Machine Translation (WMT 2018).", "labels": [], "entities": [{"text": "neu-ral machine translation (NMT)", "start_pos": 38, "end_pos": 71, "type": "TASK", "confidence": 0.7143073429663976}, {"text": "RWTH Aachen University", "start_pos": 87, "end_pos": 109, "type": "DATASET", "confidence": 0.7653070489565531}, {"text": "English \u2194 German news translation task of the EMNLP 2018 Third Conference on Machine Translation (WMT 2018)", "start_pos": 128, "end_pos": 235, "type": "TASK", "confidence": 0.8181432658120206}]}, {"text": "Our work is based on iterative back-translation using a shared encoder-decoder NMT model.", "labels": [], "entities": []}, {"text": "We extensively compare different vocabulary types, word embedding initialization schemes and optimization methods for our model.", "labels": [], "entities": [{"text": "word embedding initialization", "start_pos": 51, "end_pos": 80, "type": "TASK", "confidence": 0.6546773612499237}]}, {"text": "We also investigate gating and weight normalization for the word embedding layer.", "labels": [], "entities": []}], "introductionContent": [{"text": "Unsupervised NMT was recently investigated in ( and has shown promising results in language pairs like German to English.", "labels": [], "entities": []}, {"text": "For the WMT 2018 unsupervised learning track, we combine the concepts proposed in previous research and perform a thorough comparison of the main components of each method.", "labels": [], "entities": [{"text": "WMT 2018 unsupervised learning track", "start_pos": 8, "end_pos": 44, "type": "DATASET", "confidence": 0.7724408030509948}]}, {"text": "Additionally, we augment the word embedding initialization with weight normalization to improve its integration in the model and with a gating technique to allow the model to learn task specific information.", "labels": [], "entities": [{"text": "word embedding initialization", "start_pos": 29, "end_pos": 58, "type": "TASK", "confidence": 0.6171766221523285}]}, {"text": "The main findings of this paper are: (i) the iterative method ( ) outperforms the online training method (, (ii) cross-lingual embedding initialization is required in the online method and (iii) byte-pair encoding (BPE)-based vocabularies () outperform word-based vocabularies in online training.", "labels": [], "entities": []}, {"text": "This paper is organized as follows: Section 2 describes pre-and postprocessing pipelines, corpora selection and vocabularies used in our experiments.", "labels": [], "entities": []}, {"text": "Section 3 details the models used in this work together with the embedding augmentation techniques.", "labels": [], "entities": []}, {"text": "The experimental evaluation is presented in Sections 4 and 5 and finally we conclude with Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "All processing steps and experiments were organized with Sisyphus (Peter et al., 2018) 2 as workflow manager.", "labels": [], "entities": []}, {"text": "We constrain our results to the newstest2017 and newstest2018 data sets in the German \u2192 English translation direction.", "labels": [], "entities": [{"text": "newstest2018 data sets", "start_pos": 49, "end_pos": 71, "type": "DATASET", "confidence": 0.9272247751553854}]}, {"text": "BLEU (), computed with mteval from the Moses toolkit (, and TER (), computed with TERCom, are used as evaluation metrics.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9858391880989075}, {"text": "TER", "start_pos": 60, "end_pos": 63, "type": "METRIC", "confidence": 0.9956113696098328}, {"text": "TERCom", "start_pos": 82, "end_pos": 88, "type": "METRIC", "confidence": 0.8950208425521851}]}, {"text": "BLEU scores are casesensitive and TER is scored lower-cased.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9909595251083374}, {"text": "TER", "start_pos": 34, "end_pos": 37, "type": "METRIC", "confidence": 0.9994565844535828}]}, {"text": "All presented scores are percentages.", "labels": [], "entities": []}, {"text": "For the experiments in Sections 5.3 and 5.4 we additionally test for statistical significance with.", "labels": [], "entities": [{"text": "statistical significance", "start_pos": 69, "end_pos": 93, "type": "METRIC", "confidence": 0.7357820570468903}]}, {"text": "propose a model selection criterion based on round-trip BLEU scores, however we do not notice a correlation of this measure and BLEU between experiments.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.9773714542388916}, {"text": "BLEU", "start_pos": 128, "end_pos": 132, "type": "METRIC", "confidence": 0.9987286925315857}]}, {"text": "The more expressive the model is, the better round-trip BLEU scores it will get, whereas BLEU itself does not change.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.9743116497993469}, {"text": "BLEU", "start_pos": 89, "end_pos": 93, "type": "METRIC", "confidence": 0.9970389604568481}]}, {"text": "Therefore we choose to validate on newstest2015 on the German \u2192 English translation direction for the feature study.", "labels": [], "entities": []}, {"text": "For our final submission, we select optimization method, embedding initialization and vocabulary types based on BLEU on the German \u2192 English direction of newstest2017 and select the best hyperparameter settings using the metric from.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 112, "end_pos": 116, "type": "METRIC", "confidence": 0.9971317052841187}, {"text": "German \u2192 English direction of newstest2017", "start_pos": 124, "end_pos": 166, "type": "DATASET", "confidence": 0.6410863300164541}]}, {"text": "In this case, we only consider models that have trained exactly 6 iterations.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Vocabulary comparison between different op- timization methods for German \u2192 English. All sys- tems are initialized with cross-lingual word embed- dings.", "labels": [], "entities": []}, {"text": " Table 3: Embedding initialization comparison between  different optimization methods for German \u2192 English.  Online systems use joint BPE with 50k merge opera- tions, whereas batch systems use seperate word-based  vocabularies. Word-by-word initialization is only used  for the batch optimized system.", "labels": [], "entities": [{"text": "Embedding initialization", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.6257218718528748}, {"text": "BPE", "start_pos": 134, "end_pos": 137, "type": "METRIC", "confidence": 0.9712644219398499}, {"text": "Word-by-word initialization", "start_pos": 228, "end_pos": 255, "type": "TASK", "confidence": 0.6183288842439651}]}, {"text": " Table 4: Results for different embedding initialization  on systems optimized with the online strategy for Ger- man \u2192 English. The baseline system uses batch opti- mization, cross-lingual embeddings and shared vocab- ularies. WN stands for weight normalization.  *  denotes  a p-value of < 0.01 w.r.t. the baseline.", "labels": [], "entities": []}, {"text": " Table 5: Results for training variations on German \u2192  English. The baseline system uses batch optimization,  cross-lingual embeddings and shared vocabularies.  *   denotes a p-value of < 0.01 w.r.t. the baseline.", "labels": [], "entities": []}, {"text": " Table 6: Results for longer training iterations for Ger- man \u2194 English. The baseline system uses batch opti- mization, cross-lingual embeddings and shared vocab- ularies.", "labels": [], "entities": []}, {"text": " Table 7: Submission systems for the WMT 2018 German \u2194 English news translation task.", "labels": [], "entities": [{"text": "WMT 2018 German \u2194 English news translation task", "start_pos": 37, "end_pos": 84, "type": "TASK", "confidence": 0.7463468983769417}]}]}