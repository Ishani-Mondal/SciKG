{"title": [{"text": "What do RNN Language Models Learn about Filler-Gap Dependencies?", "labels": [], "entities": []}], "abstractContent": [{"text": "RNN language models have achieved state-of-the-art perplexity results and have proven useful in a suite of NLP tasks, but it is as yet unclear what syntactic generalizations they learn.", "labels": [], "entities": []}, {"text": "Here we investigate whether state-of-the-art RNN language models represent long-distance filler-gap dependencies and constraints on them.", "labels": [], "entities": []}, {"text": "Examining RNN behavior on experimentally controlled sentences designed to expose filler-gap dependencies, we show that RNNs can represent the relationship in multiple syntactic positions and overlarge spans of text.", "labels": [], "entities": []}, {"text": "Furthermore, we show that RNNs learn a subset of the known restrictions on filler-gap dependencies, known as island constraints: RNNs show evidence for wh-islands, adjunct islands, and complex NP islands.", "labels": [], "entities": []}, {"text": "These studies demonstrates that state-of-the-art RNN models are able to learn and generalize about empty syntactic positions.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many recent advancements in Natural Language Processing have come from the introduction of Recurrent Neural Networks (RNN).", "labels": [], "entities": [{"text": "Natural Language Processing", "start_pos": 28, "end_pos": 55, "type": "TASK", "confidence": 0.6463345984617869}]}, {"text": "One class of RNNs, the Long Short-Term Memory RNN (LSTM)) has been able to achieve impressive results on a suite of NLP tasks, including machine translation, language modeling, and syntactic parsing.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 137, "end_pos": 156, "type": "TASK", "confidence": 0.8126139044761658}, {"text": "language modeling", "start_pos": 158, "end_pos": 175, "type": "TASK", "confidence": 0.7357282042503357}, {"text": "syntactic parsing", "start_pos": 181, "end_pos": 198, "type": "TASK", "confidence": 0.7525209784507751}]}, {"text": "But the nature of the representations learned by these models is not properly understood.", "labels": [], "entities": []}, {"text": "As these models are being deployed with increasing frequency, this poses both engineering, accountability, and theoretical problems.", "labels": [], "entities": []}, {"text": "One promising line of research aims to crack open these 'black boxes' by investigating how LSTM language models perform on specially controlled sentences designed to draw out behavior that indicates representation of a syntactic dependency.", "labels": [], "entities": []}, {"text": "Using this method, and demonstrated that these models are able to successfully learn the number agreement dependency between a subject and its verb, even when there are intervening elements, and found that RNNs learn the hierarchical rules of English auxiliary inversion.", "labels": [], "entities": []}, {"text": "In this paper, we broaden and deepen this line of inquiry by examining what LSTMs learn about an unexplored syntactic relationship: the filler-gap dependency.", "labels": [], "entities": []}, {"text": "The filler-gap dependency is novel, insofar as learning it requires the network to generalize about the absence of material.", "labels": [], "entities": []}, {"text": "For our purposes, filler-gap dependency refers to a relationship between a filler, which is a whcomplementizer such as 'what' or 'who', and a gap, which is an empty syntactic position licensed by the filler.", "labels": [], "entities": []}, {"text": "In example (1a), the filler is 'what' and the gap appears after 'devoured', indicated with underscores.", "labels": [], "entities": []}, {"text": "If the filler were not present, the gap would be ungrammatical, as in (1b).", "labels": [], "entities": []}, {"text": "I know what the lion devoured at sunrise.", "labels": [], "entities": []}, {"text": "b.*I know that the lion devoured at sunrise.", "labels": [], "entities": []}, {"text": "There is also a semantic relationship between the filler and the gap, in the sense that \"what\" is semantically the direct object of \"devoured\".", "labels": [], "entities": []}, {"text": "In this work, we study the behavior of language models, and so we treat the filler-gap dependency purely as a licensing relationship.", "labels": [], "entities": []}, {"text": "found that simple distributed models have some success predicting post-verbal gaps in sentences containing object-extracted relative clauses.", "labels": [], "entities": []}, {"text": "However, correct representation of filler-gap dependencies and the constraints on them has proven challenging even in handengineered symbolic models.", "labels": [], "entities": []}, {"text": "Furthermore, they are subject to numerous complex island constraints.", "labels": [], "entities": []}, {"text": "Because of their complex-ity and ubiquity, these dependencies have figured prominently in arguments that natural language would be unlearnable by children without a great deal of innate knowledge (cf.) The remainder of the paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents our methods in more detail.", "labels": [], "entities": []}, {"text": "Section 3 gives evidence that LSTM language models represent the basic filler-gap dependency in multiple syntactic positions despite intervening material.", "labels": [], "entities": []}, {"text": "Section 4 investigates whether LSTM language models are sensitive to various constraints: wh-islands, adjunct islands, complex NP islands, and subject islands.", "labels": [], "entities": []}, {"text": "We find that the language models are sensitive to some but not all of these constraints.", "labels": [], "entities": []}], "datasetContent": [{"text": "We test whether the LSTM language models have learned filler-gap dependencies by looking fora 2x2 interaction between the presence of a gap and the presence of a wh-licensor.", "labels": [], "entities": []}, {"text": "This interaction indicates the extent to which a wh-licensor reduces the surprisal associated with a gap, so we call it the wh-licensing interaction.", "labels": [], "entities": []}, {"text": "In studying constraints on filler-gap dependencies, we look for interactions between the wh-licensing interaction and other factors: for example, whether the whlicensing interaction decreases when a gap is in a syntactic island position as opposed to a syntactically licit position (Section 4).", "labels": [], "entities": []}, {"text": "We use experimental items where the gap is located in an obligatory argument position, e.g. in subject position or as the direct object of a transitive verb, as judged by the authors.", "labels": [], "entities": []}, {"text": "The phrase with the gap is embedded inside a complement clause.", "labels": [], "entities": []}, {"text": "We chose this paradigm over bare whquestions because it eliminates do-support and tense manipulation of the main verb, resulting in higher similarity across conditions.", "labels": [], "entities": []}, {"text": "Each item appears in four conditions, reflecting a 2 \u00d7 2 experimental design manipulating presence of a whlicensor and presence of a gap.", "labels": [], "entities": []}, {"text": "For example: 1 (2) a.", "labels": [], "entities": []}, {"text": "I know that the lion devoured a gazelle at sunrise.", "labels": [], "entities": []}, {"text": "[no wh-licensor, no gap] b.*I know what the lion devoured a gazelle at sunrise.", "labels": [], "entities": []}, {"text": "[wh-licensor, no gap] c.", "labels": [], "entities": []}, {"text": "*I know that the lion devoured at sunrise.", "labels": [], "entities": []}, {"text": "[no wh-licensor, gap] d.", "labels": [], "entities": []}, {"text": "I know what the lion devoured at sunrise.", "labels": [], "entities": []}, {"text": "[wh-licensor, gap] We measure surprisal in two places: at the word immediately following a (filled) gap and summed over the whole region from the gap to the end of the embedded clause.", "labels": [], "entities": []}, {"text": "We look at immediateword surprisal because a gap's licitness should have local effects on network expectation.", "labels": [], "entities": []}, {"text": "We look at whole-region surprisal because the presence of a filler also changes expectations about overall well-formedness of the sentence-a global phenomenon.", "labels": [], "entities": []}, {"text": "Until the final punctuation is reached in (2b) there are potential gap-containing continuations that render the sentence syntactically licit (e.g. 'with .').", "labels": [], "entities": []}, {"text": "Therefore, we might expect no large spike in surprisal at anyone point, but small increases in surprisal when the network encounters filled argument-structure roles and at the end of the sentence.", "labels": [], "entities": []}, {"text": "Measuring summed surprisal captures these distributed, global effects.", "labels": [], "entities": []}, {"text": "If the network is learning the licensing relationship between fillers and gaps then two things should be true: First, if a wh-licensor sets up a global expectation for the presence of a gap, then in sentences containing a wh-licensor but no gap we expect higher surprisal in syntactic positions where a gap is likely to occur resulting in higher summed surprisal.", "labels": [], "entities": []}, {"text": "That is, S((2b)) \u2212 S((2a)) should be a large positive number.", "labels": [], "entities": []}, {"text": "Second, the presence of a gap in the absence of a whlicensor should also result in higher surprisal than when the wh-licensor is present, that is S((2d)) \u2212 S((2c)) should be a large negative number.", "labels": [], "entities": [{"text": "surprisal", "start_pos": 90, "end_pos": 99, "type": "METRIC", "confidence": 0.9785399436950684}]}, {"text": "Given the four sentences in (2), the full wh-licensing interaction is: (S(2b) -S(2a)) -(S(2d) -S(2c)) This represents how well the network learns both parts of the licensing relationship.", "labels": [], "entities": []}, {"text": "A positive whlicensing interaction means the model represents a filler-gap dependency between the wh-word and the gap site; a licensing interaction indistinguishable from zero indicates no such dependency.", "labels": [], "entities": []}, {"text": "For the purposes of brevity, we will give examples that mirror item (2d), above, but items of type (2a)-(2c) were also constructed in order to calculate the full licensing interaction.", "labels": [], "entities": []}, {"text": "Following standard practice in psycholinguistics, we derive the statistical significance of the interaction from a mixed-effects linear regression model predicting surprisal given sum-coded conditions (.", "labels": [], "entities": []}, {"text": "We include random intercepts by item; random slopes are not necessary because we do not have repeated observations within items and conditions ().", "labels": [], "entities": []}, {"text": "In our figures, error bars represent 95% confidence intervals of the contrasts between conditions, computed by subtracting out the by-item means before calculating the intervals as advocated in.", "labels": [], "entities": []}, {"text": "Although our method can indicate whether there is a link between fillers and gaps, the relationship between language model probability and grammaticality is complex ( and interpreting our patterns in terms of grammaticality judgments would require auxiliary assumptions that we don't pursue here.", "labels": [], "entities": []}, {"text": "To be clear: our goal is to investigate whether RNNs model the probabilistic dependencies between fillers and gaps at all, not whether the outputs of such models can be used to classify sentences as 'grammatical' or not.", "labels": [], "entities": []}], "tableCaptions": []}