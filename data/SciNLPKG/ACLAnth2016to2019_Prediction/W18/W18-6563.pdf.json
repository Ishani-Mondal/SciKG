{"title": [{"text": "Decoding Strategies for Neural Referring Expression Generation", "labels": [], "entities": [{"text": "Neural Referring Expression", "start_pos": 24, "end_pos": 51, "type": "TASK", "confidence": 0.8519363403320312}]}], "abstractContent": [{"text": "RNN-based sequence generation is now widely used in NLP and NLG (natural language generation).", "labels": [], "entities": [{"text": "RNN-based sequence generation", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7453479369481405}, {"text": "natural language generation", "start_pos": 65, "end_pos": 92, "type": "TASK", "confidence": 0.5843202471733093}]}, {"text": "Most work focusses on how to train RNNs, even though also decoding is not necessarily straightforward: previous work on neural MT found seq2seq models to radically prefer short candidates, and has proposed a number of beam search heuristics to deal with this.", "labels": [], "entities": []}, {"text": "In this work, we assess decoding strategies for referring expression generation with neural models.", "labels": [], "entities": [{"text": "referring expression generation", "start_pos": 48, "end_pos": 79, "type": "TASK", "confidence": 0.7384031216303507}]}, {"text": "Here, expression length is crucial: output should neither contain too much or too little information, in order to be pragmatically adequate.", "labels": [], "entities": []}, {"text": "We find that most beam search heuristics developed for MT do not generalize well to referring expression generation (REG), and do not generally outperform greedy decoding.", "labels": [], "entities": [{"text": "beam search heuristics", "start_pos": 18, "end_pos": 40, "type": "TASK", "confidence": 0.8299253185590109}, {"text": "MT", "start_pos": 55, "end_pos": 57, "type": "TASK", "confidence": 0.9918193817138672}, {"text": "referring expression generation (REG)", "start_pos": 84, "end_pos": 121, "type": "TASK", "confidence": 0.8006683985392252}]}, {"text": "We observe that beam search heuristics for termination seem to override the model's knowledge of what a good stopping point is.", "labels": [], "entities": [{"text": "termination", "start_pos": 43, "end_pos": 54, "type": "TASK", "confidence": 0.9438532590866089}]}, {"text": "Therefore, we also explore a recent approach called trainable decoding, which uses a small network to modify the RNN's hidden state for better decoding results.", "labels": [], "entities": []}, {"text": "We find this approach to consistently outperform greedy decoding for REG.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recently, many NLP problems that involve some form of natural language generation have been modeled with encoder-decoder architectures based on recurrent neural networks, e.g. in machine translation (), summarization (, conversation modeling (, image captioning to apply the decoder model during testing is to generate the most likely word at each time step, until an end symbol has been generated or the maximal number of time steps has been reached.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 179, "end_pos": 198, "type": "TASK", "confidence": 0.7320172637701035}, {"text": "summarization", "start_pos": 203, "end_pos": 216, "type": "TASK", "confidence": 0.9863771796226501}, {"text": "conversation modeling", "start_pos": 220, "end_pos": 241, "type": "TASK", "confidence": 0.739440530538559}]}, {"text": "However, this greedy search method does not generally produce optimal generation output, and has been shown to produce repetitive or invariable sentences in certain tasks, e.g. ().", "labels": [], "entities": []}, {"text": "Thus, a common practice (particularly in MT) is to use beam search where a fixed number of hypotheses are considered (and expanded) at each time step.", "labels": [], "entities": [{"text": "MT)", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.9532179832458496}, {"text": "beam search", "start_pos": 55, "end_pos": 66, "type": "TASK", "confidence": 0.9058383107185364}]}, {"text": "Unfortunately, beam search is a heuristic algorithm that can be defined and parametrized in different ways, and brings with it further modeling decisions that need to be explored.", "labels": [], "entities": [{"text": "beam search", "start_pos": 15, "end_pos": 26, "type": "TASK", "confidence": 0.9410087466239929}]}, {"text": "A particularly tricky issue in neural MT, for instance, is to define a good stopping criterion for search, as neural models tend to radically prefer short hypotheses.", "labels": [], "entities": [{"text": "MT", "start_pos": 38, "end_pos": 40, "type": "TASK", "confidence": 0.6616073250770569}]}, {"text": "To the best of our knowledge, it has not yet been systematically investigated whether beam search heuristics developed for MT carryover to other generation tasks, in particular, to tasks in the area of language and vision.", "labels": [], "entities": [{"text": "MT", "start_pos": 123, "end_pos": 125, "type": "TASK", "confidence": 0.9947748184204102}]}, {"text": "In this paper, we investigate decoding strategies for neural referring expression generation (REG) applied to objects in real-world images.", "labels": [], "entities": [{"text": "neural referring expression generation (REG)", "start_pos": 54, "end_pos": 98, "type": "TASK", "confidence": 0.7625146125044141}]}, {"text": "This task is closely related to image captioning in the sense that a visual entity has to be described by a verbal, semantically adequate expression.", "labels": [], "entities": [{"text": "image captioning", "start_pos": 32, "end_pos": 48, "type": "TASK", "confidence": 0.7497085928916931}]}, {"text": "But beyond semantic adequacy, REG also requires pragmatic reasoning: referring expressions typically do not only depend on the object they refer to, but also on the visual context of that object, as human speakers tend to tailor their utterances such that a listener can easily understand them in the current context.", "labels": [], "entities": [{"text": "REG", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.9841320514678955}]}, {"text": "For instance, a short RE that simply names the object (e.g. lady in) is unlikely to be produced than in a scene that contains more objects of the same category, see(a).", "labels": [], "entities": []}, {"text": "Thus, previous work on neural REG has investigated techniques of incorporating contextual knowledge into the model during training, looking at different visual representations and optimization techniques (.", "labels": [], "entities": []}, {"text": "Somewhat surprisingly, however, relatively complex architectural set-ups are needed to improve oversimple, context-agnostic baselines that generate descriptions for the objects as captioning models do for entire images (.", "labels": [], "entities": []}, {"text": "In this paper, we take a closer look at the decoding step in neural REG.", "labels": [], "entities": []}, {"text": "As referring expressions tend to be much shorter than full sentences in MT, for instance, it is not guaranteed that heuristics developed for beam search in MT are equally successful.", "labels": [], "entities": [{"text": "MT", "start_pos": 72, "end_pos": 74, "type": "TASK", "confidence": 0.8755536079406738}, {"text": "beam search", "start_pos": 141, "end_pos": 152, "type": "TASK", "confidence": 0.873145580291748}, {"text": "MT", "start_pos": 156, "end_pos": 158, "type": "TASK", "confidence": 0.784869372844696}]}, {"text": "More importantly even, the problem of determining the appropriate length of a referring expression, i.e. terminating beam search, is conceptually different than determining the length of a good translation: a translation is complete when it covers the meaning of the words in the source sentence, and indeed, the length of the source is used as criterion in beam search for MT (see Section 2.3).", "labels": [], "entities": [{"text": "beam search", "start_pos": 358, "end_pos": 369, "type": "TASK", "confidence": 0.8796936571598053}, {"text": "MT", "start_pos": 374, "end_pos": 376, "type": "TASK", "confidence": 0.9873720407485962}]}, {"text": "A referring expression, on the other hand, is complete when it describes the visual target in a pragmatically adequate way, i.e. when it neither provides too little nor too much information.", "labels": [], "entities": []}, {"text": "We explore a range of different variants of beam search that have been proposed for MT and, interestingly, find that most of them decrease performance as compared to simple greedy decoding in REG.", "labels": [], "entities": [{"text": "beam search", "start_pos": 44, "end_pos": 55, "type": "TASK", "confidence": 0.8430993258953094}, {"text": "MT", "start_pos": 84, "end_pos": 86, "type": "TASK", "confidence": 0.9929030537605286}]}, {"text": "Whereas greedy decoding leads to referring expressions that, on average, have an adequate length, beam search produces REs that are markedly shorter and various heuristics can only partially remedy for this problem.", "labels": [], "entities": [{"text": "beam search", "start_pos": 98, "end_pos": 109, "type": "TASK", "confidence": 0.8460957407951355}]}, {"text": "Therefore, we look at trainable decoding, a method proposed by, that offers a principled solution for obtaining a decoder that maximizes a given objective (e.g. BLEU scores).", "labels": [], "entities": [{"text": "BLEU scores", "start_pos": 161, "end_pos": 172, "type": "METRIC", "confidence": 0.9715405702590942}]}, {"text": "This method has been shown to outperform greedy decoding and to be computationally more efficient than beam search in MT ().", "labels": [], "entities": [{"text": "beam search", "start_pos": 103, "end_pos": 114, "type": "TASK", "confidence": 0.8653662800788879}]}, {"text": "We find that it qualitatively outperforms both greedy and beam search in the case of neural REG.", "labels": [], "entities": []}], "datasetContent": [{"text": "Since we compare a whole range of REG models and decoding strategies, we opt for automatic evaluation measures, even though these might not fully reflect the performance that would be achieved in interaction with human users, cf. ( In the experiments below, we look at three measures: BLEU 1 for unigrams (), and lenr (length ratio) as provided by the MSCOCO evaluation server.", "labels": [], "entities": [{"text": "BLEU 1", "start_pos": 285, "end_pos": 291, "type": "METRIC", "confidence": 0.9858675599098206}, {"text": "lenr (length ratio)", "start_pos": 313, "end_pos": 332, "type": "METRIC", "confidence": 0.7937626361846923}, {"text": "MSCOCO evaluation server", "start_pos": 352, "end_pos": 376, "type": "DATASET", "confidence": 0.922814150651296}]}, {"text": "We are interested in the length ratio as a simple approximation of traditionally used measures in REG (, reflecting whether the generation output contains too much or too little information (attributes or words).", "labels": [], "entities": [{"text": "length ratio", "start_pos": 25, "end_pos": 37, "type": "METRIC", "confidence": 0.9081237018108368}]}, {"text": "BLEU 1 gives us an indication of the lexical overlap between output and target, whereas CIDEr operates on the level of n-grams.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9824939370155334}]}], "tableCaptions": [{"text": " Table 1: Beam search variants, y refers to generation candidates", "labels": [], "entities": [{"text": "Beam search", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.8058664500713348}]}, {"text": " Table 2: Effect of beam size K on generation performance (beam with K = 1 corresponds to greedy decoding); comparing", "labels": [], "entities": []}, {"text": " Table 3: Model with linear decoding layer, different ways of normalizing/parametrizing beam search", "labels": [], "entities": []}, {"text": " Table 4: Results for trainable decoding (actor model)", "labels": [], "entities": []}]}