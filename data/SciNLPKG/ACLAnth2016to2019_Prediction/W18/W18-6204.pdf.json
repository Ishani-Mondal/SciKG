{"title": [{"text": "Language Independent Sentiment Analysis with Sentiment-Specific Word Embeddings", "labels": [], "entities": [{"text": "Language Independent Sentiment Analysis", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.5591973438858986}]}], "abstractContent": [{"text": "Data annotation is a critical step to train a text model but it is tedious, expensive and time-consuming.", "labels": [], "entities": [{"text": "Data annotation", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.740205705165863}]}, {"text": "We present a language independent method to train a sentiment polarity model with limited amount of manually-labeled data.", "labels": [], "entities": [{"text": "sentiment polarity", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.7574542164802551}]}, {"text": "Word embeddings such as Word2Vec are efficient at incorporating semantic and syntactic properties of words, yielding good results for document classification.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 24, "end_pos": 32, "type": "DATASET", "confidence": 0.9336791038513184}, {"text": "document classification", "start_pos": 134, "end_pos": 157, "type": "TASK", "confidence": 0.7340998649597168}]}, {"text": "However, these embeddings might map words with opposite polarities, to vectors close to each other.", "labels": [], "entities": []}, {"text": "We train Sentiment Specific Word Embeddings (SSWE) on top of an unsu-pervised Word2Vec model, using either Recurrent Neural Networks (RNN) or Convolutional Neural Networks (CNN) on data auto-labeled as \"Positive\" or \"Negative\".", "labels": [], "entities": []}, {"text": "For this task, we rely on the universality of emojis and emoti-cons to auto-label a large number of French tweets using a small set of positive and negative emojis and emoticons.", "labels": [], "entities": []}, {"text": "Finally, we apply a transfer learning approach to refine the network weights with a small-size manually-labeled training data set.", "labels": [], "entities": []}, {"text": "Experiments are conducted to evaluate the performance of this approach on French sentiment classification using benchmark data sets from SemEval 2016 competition.", "labels": [], "entities": [{"text": "French sentiment classification", "start_pos": 74, "end_pos": 105, "type": "TASK", "confidence": 0.7330572605133057}, {"text": "SemEval 2016 competition", "start_pos": 137, "end_pos": 161, "type": "TASK", "confidence": 0.5838764309883118}]}, {"text": "We were able to achieve a performance improvement by using SSWE over Word2Vec.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 69, "end_pos": 77, "type": "DATASET", "confidence": 0.9610945582389832}]}, {"text": "We also used a graph-based approach for label propagation to auto-generate a sentiment lexicon.", "labels": [], "entities": [{"text": "label propagation", "start_pos": 40, "end_pos": 57, "type": "TASK", "confidence": 0.7611718773841858}]}], "introductionContent": [{"text": "Text sentiment analysis is defined as the computational study of documents, sentences or phrases (aspect level), to detect opinions, sentiments, emotions, etc.", "labels": [], "entities": [{"text": "Text sentiment analysis", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8415265480677286}]}, {"text": "It is particularly useful for companies to collect feedback about their products, analyze the public opinion about their brand, for political parties to monitor the population support, etc.", "labels": [], "entities": []}, {"text": "Document-level sentiment analysis corresponds to assigning an overall sentiment polarity to a document.", "labels": [], "entities": [{"text": "Document-level sentiment analysis", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.84097288052241}]}, {"text": "It can be formulated as a two-class classification problem: positive or negative, excluding the neutral case of documents with no polarity (.", "labels": [], "entities": []}, {"text": "For this task, both supervised and unsupervised learning approaches have been used.", "labels": [], "entities": []}, {"text": "Supervised learning methods typically use bag-of-words (which ignores word orders and semantics and suffers from high dimensionality and sparsity), or, more recently, word embeddings, which requires unsupervised training on a big corpus of data.", "labels": [], "entities": []}, {"text": "It provides a mapping of words to dense vectors of fixed length, encoding semantic and syntactic properties of those words.", "labels": [], "entities": []}, {"text": "The document can then be represented by the average embedding vector of the words it contains.", "labels": [], "entities": []}, {"text": "Language-dependent features such as Part of Speech, grammatical analysis, lexicons of opinions and emotions have also been applied successfully (.", "labels": [], "entities": [{"text": "grammatical analysis", "start_pos": 52, "end_pos": 72, "type": "TASK", "confidence": 0.6771581918001175}]}, {"text": "While the use of standard word embedding techniques such as Word2Vec () or C&W) can enhance the performance of prediction models and perform well on general classification task, sentiment is not properly encoded in those vectors.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 60, "end_pos": 68, "type": "DATASET", "confidence": 0.9556370973587036}, {"text": "general classification", "start_pos": 149, "end_pos": 171, "type": "TASK", "confidence": 0.6341966092586517}]}, {"text": "According to, words such as \"good\" and \"bad\" might be close in the embeddings space, although they have opposite polarities, because of similar usage and grammatical rules.", "labels": [], "entities": []}, {"text": "We show in this paper that training Sentiment Specific Word Embeddings (SSWE) by updating an initial Word2Vec model trained on a big corpus of tweets provides better word embeddings for the task of sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 198, "end_pos": 222, "type": "TASK", "confidence": 0.9350321590900421}]}, {"text": "SSWE training is performed by updating word embeddings as part of a supervised deep learning framework, by training a model on sentiment-labeled data.", "labels": [], "entities": [{"text": "SSWE training", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.8870382010936737}]}, {"text": "Through backpropagation, the weights of the Embedding Layer will be adjusted and incorporate sentiment.", "labels": [], "entities": []}, {"text": "At the end of the training, the embedding matrix can be extracted from the model and will be used to featurize words and documents.", "labels": [], "entities": []}, {"text": "As a result, this process needs a big amount of data labeled with \"Positive\" and \"Negative\".", "labels": [], "entities": []}, {"text": "While labeled data sets and sentiment lexicons exist in English and can be used to label a big number of documents to build the SSWE (e.g. SentiWordNet or ANEW in English as lexicons), they are scarce in other languages (.", "labels": [], "entities": []}, {"text": "Hence the need to find a systematic way of labeling a big number of documents without any language knowledge, then let prediction models \"learn\" from them.", "labels": [], "entities": [{"text": "labeling a big number of documents", "start_pos": 43, "end_pos": 77, "type": "TASK", "confidence": 0.7870905796686808}]}, {"text": "One way to do it, is to rely on a universal opinion lexicon that would hold true in any language.", "labels": [], "entities": []}, {"text": "With the rise of social media, the widespread use of emojis 1 provide us with such a tool.", "labels": [], "entities": []}, {"text": "In particular, Twitter is one of the biggest online social media where users post over 500 million \"tweets\" everyday, with a frequent use of emojis 2 . A tweet is a short (up to 140 characters) user-generated text, typically noisy and written in a very casual language.", "labels": [], "entities": []}, {"text": "By accessing and querying a big number of tweets of a specific language and which have specific emojis, we can auto-label them based on the polarity of those emojis.", "labels": [], "entities": []}, {"text": "The assumption is that if emojis are found in a tweet, then it expresses a sentiment (ie. it is not neutral) which has the same polarity as the emoji.", "labels": [], "entities": []}, {"text": "This method is called distant-supervised learning and has been applied successfully in several similar scenarios.", "labels": [], "entities": []}, {"text": "In this paper, we focus on French, assuming no language knowledge.", "labels": [], "entities": []}, {"text": "The SSWE we get through the described methodology is then used to featurize documents when training a prediction model on anew French data set for sentiment analysis.", "labels": [], "entities": [{"text": "French data set", "start_pos": 127, "end_pos": 142, "type": "DATASET", "confidence": 0.9138941168785095}, {"text": "sentiment analysis", "start_pos": 147, "end_pos": 165, "type": "TASK", "confidence": 0.9150091707706451}]}, {"text": "The major contributions of the work presented in this paper are: -We develop SSWE models by updating Word2Vec embeddings trained on tweets, through supervised learning with Recurrent Neural Networks (RNN) and Convolutional Neural Networks (CNN), on a big data set of tweets auto-labeled through emojis.", "labels": [], "entities": [{"text": "SSWE", "start_pos": 77, "end_pos": 81, "type": "TASK", "confidence": 0.9470120072364807}]}, {"text": "-We show that SSWE perform better than the underlying Word2Vec embeddings, even In this paper, we will use the word \"emojis\" to refer to both \"emojis\" and \"emoticons\".", "labels": [], "entities": []}, {"text": "Twitter statistics: http://www.", "labels": [], "entities": []}, {"text": "internetlivestats.com/twitter-statistics on data sets different and much less noisy than tweets.", "labels": [], "entities": []}, {"text": "SSWE trained with auto-labeled tweets from which the emojis were removed, improve the sentiment prediction on data sets that have no or little emojis.", "labels": [], "entities": [{"text": "SSWE", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9048677086830139}, {"text": "sentiment prediction", "start_pos": 86, "end_pos": 106, "type": "TASK", "confidence": 0.9322388172149658}]}, {"text": "-We show that transfer learning starting with the deep learning model used to train the SSWE performs better than training anew traditional ML prediction model from scratch and using SSWE as features.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 14, "end_pos": 31, "type": "TASK", "confidence": 0.9034262895584106}, {"text": "ML prediction", "start_pos": 140, "end_pos": 153, "type": "TASK", "confidence": 0.8976433873176575}]}, {"text": "In Section 2, we present a literature review.", "labels": [], "entities": []}, {"text": "In Section 3, we present the methodology used to auto-label tweets, train a Word2Vec model and update it into SSWE.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 76, "end_pos": 84, "type": "DATASET", "confidence": 0.9131118655204773}, {"text": "SSWE", "start_pos": 110, "end_pos": 114, "type": "DATASET", "confidence": 0.8565216064453125}]}, {"text": "Section 4 describes the experiment we conducted and discusses results.", "labels": [], "entities": []}, {"text": "Finally, in section 5 we summarize our results and present directions for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments conducted and their results are summarized in.", "labels": [], "entities": []}, {"text": "In order to establish the importance of the SSWE for sentiment analysis, we trained multiple models using standard features (word ngrams, character ngrams) or more advanced features (Word2Vec, SSWE: average sentence embedding) with standard classifiers (logistic regression (LR), SVM, Random Forest) or deep learning frameworks (CNN or RNN with transfer learning on the data set Train), then evaluated them on Test1, Test2, and Test3.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.9713898599147797}, {"text": "Word2Vec", "start_pos": 183, "end_pos": 191, "type": "DATASET", "confidence": 0.9388017058372498}]}, {"text": "More precisely, we used the following approaches as baselines, training a Logistic Regression (LR), SVM and Random Forest with word and character ngrams, Word2Vec, or both (experiments 1-3).", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 154, "end_pos": 162, "type": "DATASET", "confidence": 0.9363406896591187}]}, {"text": "The three baselines were compared to four methods using SSWE trained with either RNN (taking the last output of the recurrent sequence) or CNN trained on the auto-labeled data and used for feature extraction on Train.", "labels": [], "entities": [{"text": "CNN", "start_pos": 139, "end_pos": 142, "type": "METRIC", "confidence": 0.9570788741111755}, {"text": "feature extraction", "start_pos": 189, "end_pos": 207, "type": "TASK", "confidence": 0.8198962509632111}]}, {"text": "We compared the performance with SSWE trained on auto-labeled data cleaned from the emojis to prevent the model from giving a high weight to emojis (experiments 4-7).", "labels": [], "entities": []}, {"text": "We compared those approaches with the use of average or maximum of the output sequences of the RNN (trained on auto-labeled data without emoji, then used for feature engineering on Train) (experiments 8-9).", "labels": [], "entities": [{"text": "RNN", "start_pos": 95, "end_pos": 98, "type": "DATASET", "confidence": 0.8727381229400635}]}, {"text": "We then add the character and ngrams features (experiments 10-15).", "labels": [], "entities": []}, {"text": "Finally, we compared them with deep learning and transfer learning.", "labels": [], "entities": []}, {"text": "Keeping the same network that was used to train the SSWE, we fix the SSWE and let the last layer(s) be trainable on Train.", "labels": [], "entities": [{"text": "SSWE", "start_pos": 52, "end_pos": 56, "type": "DATASET", "confidence": 0.9398507475852966}, {"text": "SSWE", "start_pos": 69, "end_pos": 73, "type": "DATASET", "confidence": 0.9544172286987305}, {"text": "Train", "start_pos": 116, "end_pos": 121, "type": "DATASET", "confidence": 0.9685466885566711}]}, {"text": "For the RNN, the dense layer and softmax are trainable.", "labels": [], "entities": []}, {"text": "For the CNN, training only the dense layer and softmax as part of transfer learning yields poor results, so we train the dense layer and ReLu as well as the last dense layer and softmax during transfer learning.", "labels": [], "entities": []}, {"text": "The reason why transfer learning is used instead of direct training on Train is the lack of data: Train having only 1338 unique documents, this is not enough to tune a deep learning model which has a much larger number of parameters.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.9144875109195709}]}, {"text": "(experiments 16-21) We also explored two additional methods that do not require any knowledge of the language and that will be detailed in subsequent sections: 1) using a dictionary auto-built by label propagation using specific emoji seeds on the Word2Vec model (experiments 22-24).", "labels": [], "entities": [{"text": "Word2Vec model", "start_pos": 248, "end_pos": 262, "type": "DATASET", "confidence": 0.9569815993309021}]}, {"text": "2) repeating the experiment on data for which two or more repetitions of characters are replaced with two characters.", "labels": [], "entities": []}, {"text": "All approaches with Logistic Regression, SVM or Random Forest used the Scikit-Learn Python package.", "labels": [], "entities": []}, {"text": "Word2Vec models were built using genism, while SSWE and deep learning frameworks used Keras with Tensorflow backend.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9231443405151367}]}, {"text": "For models trained with Logistic Regression, SVM and Random Forest, we decided to report and compare only results obtained with Logistic Regression for fair comparison.", "labels": [], "entities": []}, {"text": "The reported results correspond to those achieved with a set of parameters giving the best results on part of the training set, through sweeping.", "labels": [], "entities": []}, {"text": "The parameters that were swept on in Logistic Regression are: size of word ngrams, size of character ngrams, lowercasing of words, maximum number of iterations for the 'lbfgs' solver, inverse of regularization strength for 'l2' penalty.", "labels": [], "entities": [{"text": "Logistic Regression", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.8766322731971741}]}, {"text": "For models trained with Deep Learning, multiple combinations of epochs and batch sizes were used, and we report here the best results obtained.", "labels": [], "entities": []}, {"text": "While F-score and Accuracy (since there is no class imbalance) can be fair ways of evaluating the performance, we decided to rely mainly on the AUC (Area under the Curve) since it is independent of the classification threshold choice and is a good indicator of the ability of the models to distinguish between Positive and Negative examples.", "labels": [], "entities": [{"text": "F-score", "start_pos": 6, "end_pos": 13, "type": "METRIC", "confidence": 0.9950945377349854}, {"text": "Accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9990867376327515}, {"text": "AUC (Area under the Curve)", "start_pos": 144, "end_pos": 170, "type": "METRIC", "confidence": 0.7980303849492755}]}], "tableCaptions": [{"text": " Table 1: Characteristics of the auto-labeled tweets used  in this paper.", "labels": [], "entities": []}, {"text": " Table 2: Characteristics of the training and testing sets  used.", "labels": [], "entities": []}, {"text": " Table 3: Experiments Results with Logistic Regres- sion, Transfer Learning and Dictionary Lookup in  terms of AUC (in %).", "labels": [], "entities": [{"text": "AUC", "start_pos": 111, "end_pos": 114, "type": "METRIC", "confidence": 0.9845792055130005}]}]}