{"title": [{"text": "Ternary Twitter Sentiment Classification with Distant Supervision and Sentiment-Specific Word Embeddings", "labels": [], "entities": [{"text": "Ternary Twitter Sentiment Classification", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.6689838469028473}]}], "abstractContent": [{"text": "The paper proposes the Ternary Sentiment Embedding Model, anew model for creating sentiment embeddings based on the Hybrid Ranking Model of Tang et al.", "labels": [], "entities": []}, {"text": "(2016), but trained on ternary-labeled data instead of binary-labeled, utilizing sentiment embed-dings from datasets made with different distant supervision methods.", "labels": [], "entities": []}, {"text": "The model is used as part of a complete Twitter Sentiment Analysis system and empirically compared to existing systems, showing that it outperforms Hybrid Ranking and that the quality of the distant-supervised dataset has a great impact on the quality of the produced sentiment embeddings.", "labels": [], "entities": [{"text": "Twitter Sentiment Analysis", "start_pos": 40, "end_pos": 66, "type": "TASK", "confidence": 0.6740050713221232}]}], "introductionContent": [{"text": "introduced word embeddings as a technique for representing words as low-dimensional real-valued vectors capturing the words' semantic and lexical properties, based on ideas dating back to the 1950s.", "labels": [], "entities": []}, {"text": "showed the utility of using pre-trained word embeddings, and after the introduction of word2vec (, which is much faster to train than its predecessors, word embeddings have become ubiquitous.", "labels": [], "entities": []}, {"text": "This effectuated a dramatic shift in 2016 at the International Workshop on Semantic Evaluation (SemEval), with eight of the top-10 Twitter Sentiment Analysis systems using word embeddings.", "labels": [], "entities": [{"text": "International Workshop on Semantic Evaluation (SemEval)", "start_pos": 49, "end_pos": 104, "type": "TASK", "confidence": 0.5814684480428696}, {"text": "Twitter Sentiment Analysis", "start_pos": 131, "end_pos": 157, "type": "TASK", "confidence": 0.6011608441670736}]}, {"text": "Word embeddings learn the representation of a word by looking at its contexts (word neighbours in a text), making it difficult to discriminate between words with opposite sentiments that appear in similar contexts, such as \"good\" and \"bad\".", "labels": [], "entities": []}, {"text": "Hence, presented SentimentSpecific Word Embeddings (or Sentiment Embeddings), a model employing both context and sentiment information in word embeddings.", "labels": [], "entities": []}, {"text": "Training sentiment embeddings requires large amounts of sentiment annotated data.", "labels": [], "entities": [{"text": "sentiment embeddings", "start_pos": 9, "end_pos": 29, "type": "TASK", "confidence": 0.7876097559928894}]}, {"text": "Manual annotation is too expensive for this purpose, so fast, automatic annotation is used to set low-quality (weak) labels on large corpora; a procedure referred to as distant supervision.", "labels": [], "entities": []}, {"text": "The traditional approach is to use occurrences of emoticons to guess binary sentiment (positive / negative).", "labels": [], "entities": []}, {"text": "Motivated by the possible performance gains of focusing on the ternary task (where tweets can also be classified as neutral), this paper compares distant supervision methods on a large corpus of tweets that can be used to train sentiment embeddings.", "labels": [], "entities": []}, {"text": "To this end, anew model architecture was developed with anew loss function trained on three-way classified distant supervised data.", "labels": [], "entities": []}, {"text": "Various lexicon-based sentiment classifiers are compared, with their performance as distant supervision methods tested as part of a complete Twitter Sentiment Analysis system, evaluating both prediction quality and speed.", "labels": [], "entities": []}, {"text": "The paper is laid out as follows: Section 2 introduces related work on word and sentiment embeddings.", "labels": [], "entities": [{"text": "word and sentiment embeddings", "start_pos": 71, "end_pos": 100, "type": "TASK", "confidence": 0.6122147217392921}]}, {"text": "Section 3 describes the proposed model for training ternary sentiment embeddings.", "labels": [], "entities": [{"text": "ternary sentiment embeddings", "start_pos": 52, "end_pos": 80, "type": "TASK", "confidence": 0.7777689695358276}]}, {"text": "Section 4 introduces a set of distant supervision methods and a comparison between them.", "labels": [], "entities": []}, {"text": "Section 5 explores the optimal setup for the Ternary Sentiment Embedding Model through hyperparameter searches and dataset comparisons, while Section 6 compares the model against baselines and other methods to establish its performance.", "labels": [], "entities": []}, {"text": "Section 7 concludes and suggests future improvements.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Sentiment distribution in the datasets", "labels": [], "entities": [{"text": "Sentiment", "start_pos": 10, "end_pos": 19, "type": "TASK", "confidence": 0.9730844497680664}]}, {"text": " Table 2: Distant supervision, SemEval 2013-2016", "labels": [], "entities": [{"text": "Distant supervision", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.7474501430988312}]}, {"text": " Table 3: Distant supervision method comparison", "labels": [], "entities": [{"text": "Distant supervision", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.8583055436611176}]}, {"text": " Table 4: The final Ternary Sentiment Embedding  Model compared to baselines (Macro F 1 -scores)", "labels": [], "entities": [{"text": "Ternary Sentiment Embedding", "start_pos": 20, "end_pos": 47, "type": "TASK", "confidence": 0.8268549044926962}, {"text": "Macro F 1 -scores", "start_pos": 78, "end_pos": 95, "type": "METRIC", "confidence": 0.6957588255405426}]}, {"text": " Table 5: Ternary Sentiment Embedding Model vs.  Tang et al.'s Hybrid Ranking (Macro F 1 -scores)", "labels": [], "entities": [{"text": "Macro F 1 -scores", "start_pos": 79, "end_pos": 96, "type": "METRIC", "confidence": 0.715090012550354}]}, {"text": " Table 6: Comparison to top results from differ- ent SemEvals (F P N", "labels": [], "entities": []}]}