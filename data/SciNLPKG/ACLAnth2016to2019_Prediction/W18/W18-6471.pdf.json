{"title": [{"text": "Multi-source Transformer with Combined Losses for Automatic Post-Editing", "labels": [], "entities": []}], "abstractContent": [{"text": "Recent approaches to the Automatic Post-editing (APE) of Machine Translation (MT) have shown that best results are obtained by neural multi-source models that correct the raw MT output by also considering information from the corresponding source sentence.", "labels": [], "entities": [{"text": "Automatic Post-editing (APE) of Machine Translation (MT)", "start_pos": 25, "end_pos": 81, "type": "TASK", "confidence": 0.6943612152879889}]}, {"text": "To this aim, we present for the first time a neural multi-source APE model based on the Transformer architecture.", "labels": [], "entities": []}, {"text": "Moreover, we employ sequence-level loss functions in order to avoid exposure bias during training and to be consistent with the automatic evaluation met-rics used for the task.", "labels": [], "entities": []}, {"text": "These are the main features of our submissions to the WMT 2018 APE shared task, where we participated both in the PBSMT subtask (i.e. the correction of MT outputs from a phrase-based system) and in the NMT subtask (i.e. the correction of neu-ral outputs).", "labels": [], "entities": [{"text": "WMT 2018 APE shared task", "start_pos": 54, "end_pos": 78, "type": "DATASET", "confidence": 0.7811379313468934}]}, {"text": "In the first subtask, our system improves over the baseline up to-5.3 TER and +8.23 BLEU points ranking second out of 11 submitted runs.", "labels": [], "entities": [{"text": "TER", "start_pos": 70, "end_pos": 73, "type": "METRIC", "confidence": 0.9995977282524109}, {"text": "BLEU", "start_pos": 84, "end_pos": 88, "type": "METRIC", "confidence": 0.9734751582145691}]}, {"text": "In the second one, characterized by the higher quality of the initial translations , we report lower but statistically significant gains (up to-0.38 TER and +0.8 BLEU), ranking first out of 10 submissions.", "labels": [], "entities": [{"text": "TER", "start_pos": 149, "end_pos": 152, "type": "METRIC", "confidence": 0.999082088470459}, {"text": "BLEU", "start_pos": 162, "end_pos": 166, "type": "METRIC", "confidence": 0.9919614195823669}]}], "introductionContent": [{"text": "The purpose of Automatic Post-Editing (APE) is to correct the raw output of a Machine Translation system by learning from human corrections.", "labels": [], "entities": [{"text": "Automatic Post-Editing (APE)", "start_pos": 15, "end_pos": 43, "type": "TASK", "confidence": 0.5880318701267242}, {"text": "Machine Translation", "start_pos": 78, "end_pos": 97, "type": "TASK", "confidence": 0.6836552917957306}]}, {"text": "Since the inner workings of MT engines are often not accessible (e.g. by users relying on Google Translate), hence impossible to modify and improve, APE becomes a solution to enhance the quality of the translated segments.", "labels": [], "entities": [{"text": "MT engines", "start_pos": 28, "end_pos": 38, "type": "TASK", "confidence": 0.9204610586166382}]}, {"text": "Good solutions to the problem have high potential in the translation industry, where better translation means lower costs for human revision and where the adaptations of third-party, general-purpose systems to new projects is a major need.", "labels": [], "entities": [{"text": "translation", "start_pos": 57, "end_pos": 68, "type": "TASK", "confidence": 0.9783921241760254}, {"text": "human revision", "start_pos": 126, "end_pos": 140, "type": "TASK", "confidence": 0.7280713319778442}]}, {"text": "In the last few years, the APE shared tasks at WMT ( have renewed the interests in this topic and boosted the technology around it.", "labels": [], "entities": [{"text": "WMT", "start_pos": 47, "end_pos": 50, "type": "DATASET", "confidence": 0.9370158314704895}]}, {"text": "Moving from the phrase-based approaches used in the first editions of the task (, last year the multi-source neural models ( have shown their capability to significantly improve the output of a PBSMT system.", "labels": [], "entities": []}, {"text": "These APE systems shared several features and implementation choices, namely: 1) an RNN-based architecture, 2) the use of large artificial corpora for training, 3) model ensembling techniques, 4) parameter optimization based on Maximum Likelihood Estimation (MLE) and 5) vocabulary reduction using the Byte Pair Encoding (BPE) technique.", "labels": [], "entities": [{"text": "model ensembling", "start_pos": 164, "end_pos": 180, "type": "TASK", "confidence": 0.711398184299469}, {"text": "vocabulary reduction", "start_pos": 271, "end_pos": 291, "type": "TASK", "confidence": 0.795924186706543}]}, {"text": "Although they achieve good performance and impressive translation quality improvements, some of these techniques are not optimal for the actual deployment of APE technology in the translation industry.", "labels": [], "entities": [{"text": "APE", "start_pos": 158, "end_pos": 161, "type": "TASK", "confidence": 0.9673308730125427}]}, {"text": "The main reasons are the longtime required for model training and the high maintenance costs of complex architectures that combine multiple models.", "labels": [], "entities": []}, {"text": "To make APE solutions usable and useful for the industrial market, our submissions focus on the development of an end-to-end system that does not require multiple models and external components (e.g. hypothesis re-ranker), but leverages a fast to train architecture, effective pre-processing methods and task-specific losses to boost performance.", "labels": [], "entities": [{"text": "APE", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.9887813329696655}]}, {"text": "Our main contributions are: \u2022 We adapt the Transformer ( to the APE problem, so that multiple encoders can be exploited to leverage information both from the MT output to be corrected and from the corresponding source sentence (multi-source encoding).", "labels": [], "entities": [{"text": "APE problem", "start_pos": 64, "end_pos": 75, "type": "TASK", "confidence": 0.6785861253738403}]}, {"text": "\u2022 We explore different strategies for combining token and sentence level losses.", "labels": [], "entities": []}, {"text": "\u2022 We apply ad hoc pre-processing for the German language by re-implementing the pipeline used by the best system at the WMT'17 Translation task.", "labels": [], "entities": [{"text": "WMT'17 Translation task", "start_pos": 120, "end_pos": 143, "type": "TASK", "confidence": 0.7678040067354838}]}, {"text": "\u2022 In addition to the artificial data released by, we make extensive use of a synthetic corpus of 7.2M English-German triplets), which was provided by the organizers as additional training material.", "labels": [], "entities": []}, {"text": "We participated in both the APE'18 subtasks with positive results.", "labels": [], "entities": [{"text": "APE'18 subtasks", "start_pos": 28, "end_pos": 43, "type": "DATASET", "confidence": 0.7261411249637604}]}, {"text": "In the PBSMT subtask our top run improves the baseline up to -5.3 TER and +8.23 BLEU points (ranking second out of 11 submissions) while, in the NMT subtask, it achieves a -0.38 TER and +0.8 BLEU improvement (ranking first out of 10 submissions).", "labels": [], "entities": [{"text": "PBSMT subtask", "start_pos": 7, "end_pos": 20, "type": "DATASET", "confidence": 0.9523588716983795}, {"text": "TER", "start_pos": 66, "end_pos": 69, "type": "METRIC", "confidence": 0.9889335632324219}, {"text": "BLEU", "start_pos": 80, "end_pos": 84, "type": "METRIC", "confidence": 0.9828125834465027}, {"text": "NMT subtask", "start_pos": 145, "end_pos": 156, "type": "DATASET", "confidence": 0.9670364558696747}, {"text": "TER", "start_pos": 178, "end_pos": 181, "type": "METRIC", "confidence": 0.9918586611747742}, {"text": "BLEU", "start_pos": 191, "end_pos": 195, "type": "METRIC", "confidence": 0.9932044744491577}]}], "datasetContent": [{"text": "In order to evaluate our models, we use the two automatic evaluation metrics: i) TER which is computed based on edit distance) and ii) BLEU which is the geometric mean of ngram precisions multiplied to the brevity penalty ().", "labels": [], "entities": [{"text": "TER", "start_pos": 81, "end_pos": 84, "type": "METRIC", "confidence": 0.9984631538391113}, {"text": "BLEU", "start_pos": 135, "end_pos": 139, "type": "METRIC", "confidence": 0.9991366267204285}]}], "tableCaptions": [{"text": " Table 1: Results of the multi-source Transformer with  specific losses on the PBSMT outputs. The perfor- mance of the MT baseline are 24.81 TER and 62.92  BLEU. Superscript 1 denotes that improvement over  MLE is statistically significant.", "labels": [], "entities": [{"text": "TER", "start_pos": 141, "end_pos": 144, "type": "METRIC", "confidence": 0.9974172115325928}, {"text": "BLEU", "start_pos": 156, "end_pos": 160, "type": "METRIC", "confidence": 0.9988697171211243}, {"text": "MLE", "start_pos": 207, "end_pos": 210, "type": "METRIC", "confidence": 0.821261465549469}]}, {"text": " Table 2: Results of the multi-source Transformer with  specific losses on the NMT outputs. The performance  of the MT baseline are 15.08 TER and 76.76 BLEU.", "labels": [], "entities": [{"text": "MT", "start_pos": 116, "end_pos": 118, "type": "TASK", "confidence": 0.8472501039505005}, {"text": "TER", "start_pos": 138, "end_pos": 141, "type": "METRIC", "confidence": 0.9982692003250122}, {"text": "BLEU", "start_pos": 152, "end_pos": 156, "type": "METRIC", "confidence": 0.9989290833473206}]}, {"text": " Table 3: Submissions at the WMT APE shared task.", "labels": [], "entities": [{"text": "WMT APE shared task", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.6762994676828384}]}]}