{"title": [{"text": "Sub-word information in pre-trained biomedical word representations: evaluation and hyper-parameter optimization", "labels": [], "entities": []}], "abstractContent": [{"text": "Word2vec embeddings are limited to computing vectors for in-vocabulary terms and do not take into account sub-word information.", "labels": [], "entities": []}, {"text": "Character-based representations, such as fastText, mitigate such limitations.", "labels": [], "entities": []}, {"text": "We optimize and compare these representations for the biomedical domain.", "labels": [], "entities": []}, {"text": "fastText was found to consistently outperform word2vec in named entity recognition tasks for entities such as chemicals and genes.", "labels": [], "entities": [{"text": "named entity recognition tasks", "start_pos": 58, "end_pos": 88, "type": "TASK", "confidence": 0.7641133666038513}]}, {"text": "This is likely due to gained information from computed out-of-vocabulary term vectors, as well as the word compositionality of such entities.", "labels": [], "entities": []}, {"text": "Contrastingly, performance varied on intrinsic datasets.", "labels": [], "entities": []}, {"text": "Optimal hyper-parameters were intrinsic dataset-dependent, likely due to differences in term types distributions.", "labels": [], "entities": []}, {"text": "This indicates embeddings should be chosen based on the task at hand.", "labels": [], "entities": []}, {"text": "We therefore provide a number of optimized hyper-parameter sets and pre-trained word2vec and fastText models, available on https://github.com/dterg/bionlp-embed.", "labels": [], "entities": []}], "introductionContent": [{"text": ") and GloVe () models area popular choice for word embeddings, representing words by vectors for downstream natural language processing.", "labels": [], "entities": [{"text": "GloVe", "start_pos": 6, "end_pos": 11, "type": "METRIC", "confidence": 0.5785720348358154}]}, {"text": "Optimization of word2vec has been thoroughly investigated by for biomedical text.", "labels": [], "entities": []}, {"text": "However, word2vec has two main limitations: i) out-of-vocabulary (OOV) terms cannot be represented, losing potentially useful information; and ii) training is based on co-occurrence of terms, not taking into account sub-word information.", "labels": [], "entities": []}, {"text": "With new entities such as genetic variants, pathogens, chemicals and drugs, these limitations can be critical in biomedical NLP.", "labels": [], "entities": [{"text": "biomedical NLP", "start_pos": 113, "end_pos": 127, "type": "TASK", "confidence": 0.6694368124008179}]}, {"text": "Sub-word information has played a critical role in improving NLP task performances and has predominantly depended on feature-engineering.", "labels": [], "entities": [{"text": "NLP task", "start_pos": 61, "end_pos": 69, "type": "TASK", "confidence": 0.8628846704959869}]}, {"text": "More recently, character-based neural networks for tasks such as named entity recognition have been developed and evaluated on biomedical literature.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 65, "end_pos": 89, "type": "TASK", "confidence": 0.6119385461012522}]}, {"text": "This has achieved state-ofthe-art performances but is limited by the quantity of supervised training data.", "labels": [], "entities": []}, {"text": "Character-based representation models such as fastText () and MIMICK () exploit word compositionality to learn distributional embeddings, allowing to compute vectors for OOV words.", "labels": [], "entities": [{"text": "word compositionality", "start_pos": 80, "end_pos": 101, "type": "TASK", "confidence": 0.7218955159187317}]}, {"text": "Briefly, fastText uses a feed-forward architecture to learn n-gram and word embeddings, whereas MIMICK uses a Bi-LSTM architecture to learn character-based embeddings in the same space of another pre-trained embeddings, such as word-based word2vec.", "labels": [], "entities": []}, {"text": "Here we evaluate and optimize pre-trained character-based word representations with the fastText implementation for biomedical terms.", "labels": [], "entities": []}, {"text": "To compare with word2vec models, we also optimize word2vec by extending the work by.", "labels": [], "entities": []}, {"text": "We report that fastText outperforms word2vec in all named entity recognition tasks of feature-rich entities such as chemicals and genes.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 52, "end_pos": 76, "type": "TASK", "confidence": 0.7692589163780212}]}, {"text": "However, in intrinsic evaluation, results and optimal hyper-parameters vary.", "labels": [], "entities": []}, {"text": "This is likely due to different entity type distributions within the intrinsic standards.", "labels": [], "entities": []}, {"text": "This indicates representations should be selected and optimized based on the task at hand and the entities of interest.", "labels": [], "entities": []}, {"text": "We evaluate and provide optimized generalized fastText and word2vec models and models optimized on individual datasets, outperforming a number of current state-of-the-art embeddings.", "labels": [], "entities": []}], "datasetContent": [{"text": "Intrinsic evaluation of word embeddings is commonly performed by correlating the cosine similarity between term pairs, as determined by the trained embeddings, and a reference list.", "labels": [], "entities": []}, {"text": "We use the manually curated UMNSRS covering disorders, symptoms, and drugs (, and compute graph-based similarity and relatedness using the human disease ontology graph () (HDO) and the Xenopus anatomy and development ontology graph () (XADO).", "labels": [], "entities": []}, {"text": "1 million pairwise combinations of entities and ontologies were JNLPBA FastT CHEMDNER CHEMDNER FastT randomly computed from each graph and entities which did not map to the ontology map or were multi-token were not considered.", "labels": [], "entities": [{"text": "JNLPBA FastT CHEMDNER CHEMDNER FastT randomly", "start_pos": 64, "end_pos": 109, "type": "METRIC", "confidence": 0.6018933802843094}]}, {"text": "Similarity between a pair of terms was computed using the similarity metric, and relatedness was determined by a simplified.", "labels": [], "entities": []}, {"text": "In the latter, token intersection (excluding stopwords) was calculated between definitions and normalized by the maximum definition length.", "labels": [], "entities": []}, {"text": "Pairs which did not have definition statements for any of the terms were excluded.", "labels": [], "entities": []}, {"text": "As with UMNSRS, the computed similarity and relatedness scores were correlated with the cosine similarity determined by the embeddings models.", "labels": [], "entities": [{"text": "similarity", "start_pos": 29, "end_pos": 39, "type": "METRIC", "confidence": 0.9268786907196045}]}, {"text": "As word2vec is not capable of representing OOV words, in literature pair terms which are not in vocabulary are commonly not considered for evaluation.", "labels": [], "entities": []}, {"text": "To allow for comparison between the word2vec and fastText models, we represent OOV words as null vectors -as originally performed by.", "labels": [], "entities": []}, {"text": "However, to determine the difference in performance of invocabulary word embeddings and OOV word embeddings, we measure correlation with only invocabulary terms, and with OOV terms pairs considered and null-imputed for word2vec.", "labels": [], "entities": []}, {"text": "Intrinsic evaluation by itself may provide limited insights and may not represent the true downstream performance).", "labels": [], "entities": []}, {"text": "Therefore, we perform extrinsic evaluation using 3 named entity recognition corpora: (i) the BioCreative II Gene Mention task corpus (BC2GM) () for genes; (ii) the JNLPBA corpus () annotating proteins, cell lines, cell types, DNA, and RNA; and (iii) the CHEMDNER corpus () which annotates drugs and chemicals, as made available from.", "labels": [], "entities": [{"text": "BioCreative II Gene Mention task", "start_pos": 93, "end_pos": 125, "type": "TASK", "confidence": 0.562830114364624}, {"text": "JNLPBA corpus", "start_pos": 164, "end_pos": 177, "type": "DATASET", "confidence": 0.8747384250164032}, {"text": "CHEMDNER corpus", "start_pos": 254, "end_pos": 269, "type": "DATASET", "confidence": 0.8026333153247833}]}, {"text": "Each of these corpora are originally split into a train, development, and test sets -the same splits and sentence ordering were retained here.", "labels": [], "entities": []}, {"text": "The state-of-the-art BiLSTM-CRF neural network architecture (, as implemented in the anago package, was used to train NER models and predict the development set of each corpus for each parameter.", "labels": [], "entities": []}, {"text": "Accuracy was determined by the F-score.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9972061514854431}, {"text": "F-score", "start_pos": 31, "end_pos": 38, "type": "METRIC", "confidence": 0.9978518486022949}]}, {"text": "Each model was run for up to 10 epochs and the best accuracy on the development set was recorded.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9995943903923035}]}, {"text": "While the overall performance trends with various hyper-parameters for fastText are similar to those obtained by word2vec, we report a number of notable differences.", "labels": [], "entities": []}, {"text": "When intrinsically evaluated with UMNSRS, word2vec representations consistently achieved higher similarity and relatedness compared to fastText for hyper-parameters such as: window size, dimensions and negative sampling, irrespective of the selected hyper-parameters.", "labels": [], "entities": [{"text": "similarity", "start_pos": 96, "end_pos": 106, "type": "METRIC", "confidence": 0.9758989810943604}]}, {"text": "However, evaluating with HDO and XADO intrinsic datasets, results were more variable.", "labels": [], "entities": [{"text": "XADO intrinsic datasets", "start_pos": 33, "end_pos": 56, "type": "DATASET", "confidence": 0.6524366537729899}]}, {"text": "fastText tended to perform similar to or outperform word2vec across negative sampling size, dimensions and window size hyper-parameter ranges.", "labels": [], "entities": []}, {"text": "Differences in performance between datasets maybe a result of differences in: (i) number of OOV terms; (ii) rarity of terms; and (iii) term types.", "labels": [], "entities": []}, {"text": "As UMNSRS is a manually curated reference list of term pairs with the vocabulary of multiple corpora, including PubMed Central, only up JNLPBA FastT CHEMDNER CHEMDNER FastT to 9 total tokens were OOV (1.3%; Supp.).", "labels": [], "entities": [{"text": "JNLPBA FastT CHEMDNER CHEMDNER FastT", "start_pos": 136, "end_pos": 172, "type": "DATASET", "confidence": 0.6991299033164978}, {"text": "OOV", "start_pos": 196, "end_pos": 199, "type": "METRIC", "confidence": 0.9950308799743652}, {"text": "Supp.", "start_pos": 207, "end_pos": 212, "type": "METRIC", "confidence": 0.9877753257751465}]}, {"text": "HDO contained up to 5% OOV terms.", "labels": [], "entities": [{"text": "HDO", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9198797345161438}, {"text": "OOV", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.9877181053161621}]}, {"text": "As OOV terms are represented by null vectors for word2vec models, a decrease in performance with increase in OOV terms is expected.", "labels": [], "entities": []}, {"text": "Skipping OOV term pairs from evaluation (rather than imputing) obtained similar performance trends across datasets, indicating that OOV is not the major contributing factor in such intrinsic performance differences.", "labels": [], "entities": []}, {"text": "However, this may also imply that fastText degrades the performance for invocabulary terms of the UMNSRS dataset.", "labels": [], "entities": [{"text": "UMNSRS dataset", "start_pos": 98, "end_pos": 112, "type": "DATASET", "confidence": 0.949428141117096}]}, {"text": "Similar results were reported by the original authors when assessed on the English WS353 dataset (.", "labels": [], "entities": [{"text": "English WS353 dataset", "start_pos": 75, "end_pos": 96, "type": "DATASET", "confidence": 0.9052220980326334}]}, {"text": "Despite terms being in-vocabulary, the frequency by which these occur in the training dataset may vary.", "labels": [], "entities": []}, {"text": "This is indeed the case for UMNSRS and HDO, where UMNSRS has a median rank invocabulary frequency 4 times higher than HDO.", "labels": [], "entities": []}, {"text": "This may indicate fastText provides better representations for rarer terms.", "labels": [], "entities": []}, {"text": "XADO, however, has a median rank in-vocabulary frequency within 1.3 times of UMNSRS.", "labels": [], "entities": [{"text": "XADO", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8041217923164368}, {"text": "UMNSRS", "start_pos": 77, "end_pos": 83, "type": "DATASET", "confidence": 0.9497358202934265}]}, {"text": "This implies there are additional contributing factors to such performance differences, including potentially differences in the quality of the ontology graph.", "labels": [], "entities": []}, {"text": "As the intrinsic standards contain various entity classes, differences in representation models' performance (and optimal hyper-parameters) maybe dependent on the distribution of entity types.", "labels": [], "entities": []}, {"text": "fastText authors reported that fastText outperforms word2vec in languages like German, Arabic, Russian and in rare English words (.", "labels": [], "entities": []}, {"text": "This indicates that word2vec and fastText's performance is dependent on the compositionality and word character features, and may therefore be expected to vary between biomedical entity classes.", "labels": [], "entities": []}, {"text": "Biomedical text generally contains terms such as chemicals, genes, proteins and cell-lines which are rich in features such as punctuation, special characters, digits, and mixed-case characters.", "labels": [], "entities": []}, {"text": "Such orthographic features have been manually extracted in traditional machine learning methods, or more recently combined with word embeddings, and have been shown to have discriminating power in tasks such as named entity recognition ().", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 211, "end_pos": 235, "type": "TASK", "confidence": 0.6179010967413584}]}, {"text": "When performing named entity recognition as extrinsic evaluation of the word representations models, fastText consistently outperformed word2vec at any hyper-parameter value, and consistently across all 3 corpora (.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 16, "end_pos": 40, "type": "TASK", "confidence": 0.6316547195116679}]}, {"text": "With 9-13% total OOV tokens, and 14-34% OOV entity tokens (Supp.", "labels": [], "entities": []}, {"text": "Table 3, Supp., this indicates the overall likely positive JNLPBA FastT CHEMDNER CHEMDNER FastT contribution of gained information from computed OOV vectors.", "labels": [], "entities": [{"text": "JNLPBA FastT CHEMDNER CHEMDNER FastT contribution", "start_pos": 59, "end_pos": 108, "type": "METRIC", "confidence": 0.7781826754411062}]}, {"text": "In terms of the specific corpora, the largest performance difference was recorded for genes (BC2GM) and chemical names (CHEMDNER).", "labels": [], "entities": []}, {"text": "As these two corpora only tag one entity type, entity variation is lower than JNLPBA which tags 5 entity classes and therefore this may contribute to the dissimilarities in performance difference between the corpora.", "labels": [], "entities": [{"text": "JNLPBA", "start_pos": 78, "end_pos": 84, "type": "DATASET", "confidence": 0.8487133383750916}]}, {"text": "In addition to the rich and unique features, outperformance of fastText in extrinsic evaluation may also be attributed to the standardized nomenclature used in biomedical entities which provides additional within-token structure.", "labels": [], "entities": []}, {"text": "For example, systematic chemical names follow the IUPAC nomenclature.", "labels": [], "entities": [{"text": "IUPAC nomenclature", "start_pos": 50, "end_pos": 68, "type": "DATASET", "confidence": 0.8668379187583923}]}, {"text": "Prefixes such as mono, di, and tri indicate number of identical substituents in a compound.", "labels": [], "entities": []}, {"text": "Similarly, residual groups are represented by prefixes such as methyl-and bromo-.", "labels": [], "entities": []}, {"text": "Additionally, the backbone structure of the molecule is assigned a suffix that indicates structure features (e.g. simple hydrocarbon molecules utilize suffixes to indicate number of single, double or more bonds, where -ane indicates single bonds, -ene double bonds, -ynes triple bonds etc).", "labels": [], "entities": []}, {"text": "With such structure, as fastText is a characterlevel model, for chemicals such as 1,2-dichloromethane, most similar words include chemicals which share the substituents and their specific position, defined by the 1,2-dichloro-prefix.", "labels": [], "entities": []}, {"text": "Therefore, fastText provides more structurally-similar chemicals, whereas word2vec would treat 1,2-dichloromethane and 2-dichloromethane as two completely different/unrelated terms (when excluding context or setting a small window size).", "labels": [], "entities": []}, {"text": "As chemicals can be synthesized and named, it is likely for very specific and big molecules such as 1-(dimethylamino)-2-methyl-3,4-diphenylbutane-1,3-diol to be OOV.", "labels": [], "entities": []}, {"text": "This is a great advantage of character-level embeddings which still enable computing a representation.", "labels": [], "entities": []}, {"text": "Given the highly standardized and structured nomenclature of chemicals, we briefly observed that fastText models are also able to recall structural analogs when performing analogy tasks.", "labels": [], "entities": []}, {"text": "For example, methanol \u2192 methanal is an oxidation reaction where an alcohol is converted to an aldehyde, specifically the -OH group is converted to a =O group.", "labels": [], "entities": []}, {"text": "Given ethanol and performing analogy task vector arithmetic, the aldehyde ethanal is returned.", "labels": [], "entities": [{"text": "analogy task vector arithmetic", "start_pos": 29, "end_pos": 59, "type": "TASK", "confidence": 0.5595041215419769}]}, {"text": "Similar results were observed for sulfuric_acid -sulfur + phosphorous, giving phosphoric_acid.", "labels": [], "entities": []}, {"text": "Formal evaluation on analogy tasks is required to assess how character-based embeddings perform compared to word2vec.", "labels": [], "entities": []}, {"text": "Genes and proteins have full names as well as short symbolic identifiers which are usually acronymic abbreviations.", "labels": [], "entities": []}, {"text": "These are less structured than chemical names, however, as the root portion of the symbols represents a gene family, this accounts for the similarity performance of characterbased embeddings.", "labels": [], "entities": []}, {"text": "ZNF560 is an example of OOV protein that was assigned a vector close to ZNF* genes as well as SOX1.", "labels": [], "entities": []}, {"text": "While SOX1 does not share character n-grams with ZNF560, similarity was determined based on cooccurrence of ZNF genes and SOX1 -genes which are associated with adenocarcinomas (.", "labels": [], "entities": [{"text": "similarity", "start_pos": 57, "end_pos": 67, "type": "METRIC", "confidence": 0.9768175482749939}]}, {"text": "While the advantages of character-based similarity for OOV terms are clear, from intrinsic evaluation it appears that for some entities word2vec provides better embeddings.", "labels": [], "entities": []}, {"text": "An example of this is when querying phosphatidylinositol-4,5-bisphosphate (Supp).", "labels": [], "entities": [{"text": "Supp)", "start_pos": 75, "end_pos": 80, "type": "DATASET", "confidence": 0.7358948588371277}]}, {"text": "Whereas the top 5 most similar terms returned by fastText are orthographically, morphologically, and structurally similar, word2vec recalled PIP2 and PI(4,5)P2.", "labels": [], "entities": []}, {"text": "These are synonyms of the queried term hence more similar than phosphatidylinositol-4-phosphate, for example.", "labels": [], "entities": []}, {"text": "A similar result was also observed for genetic variants (SNPs).", "labels": [], "entities": []}, {"text": "While fastText returned rs-prefixed terms as most similar terms to the reference SNP identifier rs2243250 (which refers to the SNP Interleukin 4 -590C/T polymorphism), word2vec recalled terms 590C>T and 590C/T; the nucleotide polymorphism specified by the identifier itself (Supp 1,2-dichloromethane 1-(dimethylamino)-2-methyl-3,4-diphenylbutane-1,3-diol ZNF560 1,2-dichloroethane 8-(N,N-diethylamino)octyl-3,4,5-trimethoxybenzoate: Top 5 most similar words to a selection of out-of-vocabulary terms (two chemical systematic names and a protein symbol; top row).", "labels": [], "entities": []}, {"text": "Sequences in bold indicate overlap with queried term.).", "labels": [], "entities": []}, {"text": "Additional examples comparing word2vec and fastText's most similar terms for chemicals, genes and diseases are provided in Supp.", "labels": [], "entities": [{"text": "Supp", "start_pos": 123, "end_pos": 127, "type": "DATASET", "confidence": 0.9105209112167358}]}, {"text": "From the quantitative results and the above qualitative examples, we observe a trade-off between character sequence similarity and context.", "labels": [], "entities": []}, {"text": "The importance of which depends on the entity types -just as different languages benefit differently from word2vec and fastText models ().", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3. Intrinsic and extrinsic performance for word2vec and fastText models optimized on  optimum hyper-parameters from intrinsic (int) and extrinsic (ex) datasets (Supp", "labels": [], "entities": [{"text": "Supp", "start_pos": 168, "end_pos": 172, "type": "DATASET", "confidence": 0.5116806030273438}]}, {"text": " Table 2: Intrinsic (UMNSRS, HDO, XADO; upper row = similarity, lower row = relatedness) and ex- trinsic (BC2GM, JNLPBA, CHEMDNER) evaluation of the effect of character n-gram ranges on per- formance. Highest absolute accuracy is indicated in bold and accuracies within the standard error of the  highest accuracy is italicized.", "labels": [], "entities": [{"text": "Intrinsic", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.989791214466095}, {"text": "accuracy", "start_pos": 218, "end_pos": 226, "type": "METRIC", "confidence": 0.8362360000610352}, {"text": "accuracy", "start_pos": 305, "end_pos": 313, "type": "METRIC", "confidence": 0.9503669738769531}]}]}