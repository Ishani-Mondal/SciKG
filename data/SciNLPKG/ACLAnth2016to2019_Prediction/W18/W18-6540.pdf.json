{"title": [{"text": "Adapting Descriptions of People to the Point of View of a Moving Observer", "labels": [], "entities": [{"text": "Adapting Descriptions of People", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.9168006628751755}]}], "abstractContent": [{"text": "This paper addresses the task of generating descriptions of people for an observer that is moving within a scene.", "labels": [], "entities": []}, {"text": "As the observer moves, the descriptions of the people around him also change.", "labels": [], "entities": []}, {"text": "A referring expression generation algorithm adapted to this task needs to continuously monitor the changes in the field of view of the observer, his relative position to the people being described, and the relative position of these people to any landmarks around them, and to take these changes into account in the referring expressions generated.", "labels": [], "entities": [{"text": "referring expression generation", "start_pos": 2, "end_pos": 33, "type": "TASK", "confidence": 0.7188580433527628}]}, {"text": "This task presents two advantages: many of the mechanisms already available for static contexts maybe applied with small adaptations, and it introduces the concept of changing conditions into the task of referring expression generation.", "labels": [], "entities": [{"text": "referring expression generation", "start_pos": 204, "end_pos": 235, "type": "TASK", "confidence": 0.7854396303494772}]}, {"text": "In this paper we describe the design of an algorithm that takes these aspects into account in order to create descriptions of people within a 3D virtual environment.", "labels": [], "entities": []}, {"text": "The evaluation of this algorithm has shown that, by changing the descriptions in real time according to the observers point of view, they are able to identify the described person quickly and effectively.", "labels": [], "entities": []}], "introductionContent": [{"text": "The task of Referring Expression Generation (REG) has traditionally been considered in static contexts, where neither the properties of the objects being described nor their relation to the observer changeover time.", "labels": [], "entities": [{"text": "Referring Expression Generation (REG)", "start_pos": 12, "end_pos": 49, "type": "TASK", "confidence": 0.9250101745128632}]}, {"text": "This is a good starting point to address the problem because it includes the elements that are involved in more complex situations.", "labels": [], "entities": []}, {"text": "The case where the observer is moving along a static context is a slight departure from the basic static case, with two significant advantages: many of the mechanisms available for static contexts maybe applied with small adaptations, and it introduces the concept of changing conditions into the task of referring expression generation.", "labels": [], "entities": [{"text": "referring expression generation", "start_pos": 305, "end_pos": 336, "type": "TASK", "confidence": 0.7848881880442301}]}, {"text": "For this reason, it is a worthwhile problem to explore.", "labels": [], "entities": []}, {"text": "A challenge when trying to address this problem is the need to continuously gather data on the relevant conditions -the field of view of the observer, his relative position to the people being described, and the relative position of these people to any landmarks around them in terms of how they appear in the field of view of the observer.", "labels": [], "entities": []}, {"text": "Gathering these data in areal life context maybe very difficult, but if the situation is modeled in a 3D environment that represents the chosen scene, with a camera following the observer in first person mode, the compilation of all these data becomes a feasible task, and the generation of descriptions in real time becomes possible.", "labels": [], "entities": []}, {"text": "We have studied different proposals to solve similar problems and have developed a metaalgorithm based on the work depicted in (, where the authors studied the behavior of classic REG algorithms applied to this problem (section 3).", "labels": [], "entities": []}, {"text": "Then, we have built a 3D scene and have populated it with people in order to test this meta-algorithm when the observer can move around the scene (section 4).", "labels": [], "entities": []}, {"text": "The results of this evaluation have shown that the descriptions can be improved in order for the observers to find the target person more easily, so we have extended the previous algorithm to include additional information to the descriptions (section 5).", "labels": [], "entities": []}, {"text": "We have subsequently evaluated the new algorithm using the same scenes (section 6) and the results show that the observers are able to find the target person faster and with a much higher hit rate than before.", "labels": [], "entities": [{"text": "hit rate", "start_pos": 188, "end_pos": 196, "type": "METRIC", "confidence": 0.8305639326572418}]}], "datasetContent": [{"text": "One of the difficulties when generating descriptions in changing environments is to decide when and how to change the referring expression we use to describe an element's situation, even more if we take into account that not everybody refers to an element in the same manner.", "labels": [], "entities": []}, {"text": "In order to generate this kind of descriptions, the first step we took was to test the behavior of the meta-algorithm described in section 3 in dynamic conditions, in order to check the suitability of the generated descriptions as the user's viewpoint changed.", "labels": [], "entities": []}, {"text": "A survey was carried out in order to study how the changes in the user's point of view affected the perceived accuracy of the descriptions generated by algorithms thought to work in static conditions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 110, "end_pos": 118, "type": "METRIC", "confidence": 0.990415096282959}]}, {"text": "The survey was completed by 27 people (45% of women and 55% of men), with ages from 20 to 45 years old.", "labels": [], "entities": []}, {"text": "The users were shown ten scenes in a 3D virtual environment, together with the description of the target character they had to identify in each of them, generated by the meta-algorithm.", "labels": [], "entities": []}, {"text": "The description was presented to the users as a written message on the top part of the screen, and it was kept there until the users clicked on what they considered to be the target character.", "labels": [], "entities": []}, {"text": "They were not told whether they could seethe target character or not, and they could move around the environment in order to find the described person.", "labels": [], "entities": []}, {"text": "The users had to click on it once they thought they had found it, but the provided description did not change as they moved.", "labels": [], "entities": []}, {"text": "All the scenes were reproductions of pictures taken in our canteen (so they all represent real situations), and all of them included more than 30 characters, both male and female, most of them between 18 and 25 years old, with varied characteristics, and typical actions included people speaking, drinking or working together, either standing up or sitting down.", "labels": [], "entities": []}, {"text": "The scenes and characters were selected so that they put to test some difficult situations, such as characters that were initially out of sight, other characters that might get out of sight as the users moved around the scene, or some others that were difficult to see from along distance and that looked similar to other characters close to them.", "labels": [], "entities": []}, {"text": "shows the description generated for each scene of the evaluation, along with the algorithm selected by the meta-algorithm to generate it and the percentage of users that found the described character.", "labels": [], "entities": []}, {"text": "Most correct clicks were achieved when the descriptions were generated by the nearby objects or people algorithms to describe the target; some of these descriptions made reference to the posture of the target to describe it.", "labels": [], "entities": []}, {"text": "In contrast, the incremental algorithm has got low hit rates in the two scenes where it was selected by the meta-algorithm to generate the descriptions.", "labels": [], "entities": []}, {"text": "The reason behind it is that this al-gorithm is selected when there are no salient objects or characters than can be used by other algorithms, and the incremental algorithm does not provide enough discriminating power when there are too many characters that look like the target one.", "labels": [], "entities": []}, {"text": "This, in turn, has more to do with the difficulty to describe the characters in these scenes than with the algorithm itself, as it has been selected by the meta-algorithm precisely because it works better than the rest in these situations.", "labels": [], "entities": []}, {"text": "An advantage of the incremental algorithm is the inclusion of the distance between the user position and the target character as a descriptor.", "labels": [], "entities": []}, {"text": "However, as the user moves around the scene, the metaalgorithm fails in updating this reference, thus making the description invalid.", "labels": [], "entities": []}, {"text": "This points to the need of changing the description as the user moves, to keep it aligned with the user perspective of the scene, which will be included in the algorithm described in the next section.", "labels": [], "entities": []}, {"text": "Many users got some scenes wrong when they had to find easy to identify persons, because there was a character that looked like them in the users' field of view at the start.", "labels": [], "entities": []}, {"text": "A way to fix this is to specify in the description if the target is in the user's field of view or not, and if it is near or far.", "labels": [], "entities": []}, {"text": "Regarding the distance, the users were sometimes confused by the indication of the target being far, when they considered that it was not that far.", "labels": [], "entities": []}, {"text": "Thus, a finer distinction of the distance to the target may also improve the quality of the descriptions.", "labels": [], "entities": []}, {"text": "A second evaluation was carried out six months after the first one, using the same conditions and instructions as in the first one.", "labels": [], "entities": []}, {"text": "The main objective of this evaluation was to test the improvements added to the meta-algorithm by comparing the obtained results with those of the first survey.", "labels": [], "entities": []}, {"text": "Therefore, the people that had to be found by the observer, and the scenes used for it, were the same as in the previous one.", "labels": [], "entities": []}, {"text": "This way, a reliable comparison could be made between both versions of the meta-algorithm in order to test their effectiveness.", "labels": [], "entities": []}, {"text": "A sample scene used for this evaluation can be seen in.", "labels": [], "entities": []}, {"text": "The number of people that completed the survey was twenty seven, the same as in the first survey.", "labels": [], "entities": []}, {"text": "85% of them were between 20 and 30 years old, and the remaining 15% were between 30 and 40.", "labels": [], "entities": []}, {"text": "63% of the participants were male, and the remaining 37% were female.", "labels": [], "entities": []}, {"text": "Five of the evaluators had also completed the first survey, but after six months they assured they did not notice the scenes and characters were the same as in the first one.", "labels": [], "entities": []}, {"text": "shows the results obtained in this evaluation.", "labels": [], "entities": []}, {"text": "The column corresponding to the description only shows the initial descriptions of the tar-", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Average response times (in seconds) for  each scene", "labels": [], "entities": [{"text": "Average response times", "start_pos": 10, "end_pos": 32, "type": "METRIC", "confidence": 0.8822992444038391}]}]}