{"title": [{"text": "The AFRL WMT18 Systems: Ensembling, Continuation and Combination", "labels": [], "entities": [{"text": "AFRL WMT18", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.8339940905570984}]}], "abstractContent": [{"text": "This paper describes the Air Force Research Laboratory (AFRL) machine translation systems and the improvements that were developed during the WMT18 evaluation campaign.", "labels": [], "entities": [{"text": "Air Force Research Laboratory (AFRL) machine translation", "start_pos": 25, "end_pos": 81, "type": "TASK", "confidence": 0.8480780588255988}, {"text": "WMT18 evaluation", "start_pos": 142, "end_pos": 158, "type": "TASK", "confidence": 0.8494952619075775}]}, {"text": "This year, we examined the developments and additions to popular neural machine translation toolkits and measure improvements in performance on the Russian-English language pair.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 65, "end_pos": 91, "type": "TASK", "confidence": 0.7496294975280762}]}], "introductionContent": [{"text": "As part of the 2018 Conference on Machine Translation () news-translation shared task, the AFRL human language technology team participated in the Russian-English portion of the competition.", "labels": [], "entities": [{"text": "Machine Translation () news-translation shared task", "start_pos": 34, "end_pos": 85, "type": "TASK", "confidence": 0.7856668184200922}, {"text": "AFRL", "start_pos": 91, "end_pos": 95, "type": "DATASET", "confidence": 0.8337246179580688}]}, {"text": "We largely employed our strategies from last year (, but adapted them to the past year's developments, including the University of Edinburgh's \"bi-deep\" ) and Google's transformer architectures.", "labels": [], "entities": []}, {"text": "For Russian-English we again submitted an entry comprising our best systems trained with Marian (), OpenNMT (, and Moses () combined using the Jane system combination method ().", "labels": [], "entities": [{"text": "Marian", "start_pos": 89, "end_pos": 95, "type": "DATASET", "confidence": 0.949591875076294}, {"text": "OpenNMT", "start_pos": 100, "end_pos": 107, "type": "DATASET", "confidence": 0.8982682228088379}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Comparison between using cross-entropy, BLEU and BEER as validation metrics with Marian systems.  Scores for various WMT test sets measured in cased BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 50, "end_pos": 54, "type": "METRIC", "confidence": 0.9985352754592896}, {"text": "BEER", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.9971057772636414}, {"text": "WMT test sets", "start_pos": 127, "end_pos": 140, "type": "DATASET", "confidence": 0.7492334544658661}, {"text": "BLEU", "start_pos": 159, "end_pos": 163, "type": "METRIC", "confidence": 0.9915457367897034}]}, {"text": " Table 2: Comparison on using pretrained word embeddings with Marian systems. Scores for various WMT test  sets measured in cased BLEU.", "labels": [], "entities": [{"text": "WMT test  sets", "start_pos": 97, "end_pos": 111, "type": "DATASET", "confidence": 0.7405637999375662}, {"text": "BLEU", "start_pos": 130, "end_pos": 134, "type": "METRIC", "confidence": 0.9877164959907532}]}, {"text": " Table 3: Comparison of different training corpora conditions. Scores for various WMT test sets measured in cased  BLEU.", "labels": [], "entities": [{"text": "WMT", "start_pos": 82, "end_pos": 85, "type": "TASK", "confidence": 0.9122247695922852}, {"text": "BLEU", "start_pos": 115, "end_pos": 119, "type": "METRIC", "confidence": 0.985755980014801}]}, {"text": " Table 5. The final system  combination output comprised our entry to the  Russian-English portion of the WMT18 news task  evaluation.", "labels": [], "entities": [{"text": "WMT18 news task  evaluation", "start_pos": 106, "end_pos": 133, "type": "DATASET", "confidence": 0.9068804681301117}]}, {"text": " Table 5: System combination and input system scores  measured in BLEU and BEER on the newstest2018  test set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 66, "end_pos": 70, "type": "METRIC", "confidence": 0.9992597699165344}, {"text": "BEER", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.9978660941123962}, {"text": "newstest2018  test set", "start_pos": 87, "end_pos": 109, "type": "DATASET", "confidence": 0.974249521891276}]}]}