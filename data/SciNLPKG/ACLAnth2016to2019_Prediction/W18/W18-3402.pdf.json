{"title": [{"text": "Training a Neural Network in a Low-Resource Setting on Automatically Annotated Noisy Data", "labels": [], "entities": []}], "abstractContent": [{"text": "Manually labeled corpora are expensive to create and often not available for low-resource languages or domains.", "labels": [], "entities": []}, {"text": "Automatic labeling approaches are an alternative way to obtain labeled data in a quicker and cheaper way.", "labels": [], "entities": [{"text": "Automatic labeling", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.5849333852529526}]}, {"text": "However, these labels often contain more errors which can deteriorate a classifier's performance when trained on this data.", "labels": [], "entities": []}, {"text": "We propose a noise layer that is added to a neural network architecture.", "labels": [], "entities": []}, {"text": "This allows modeling the noise and train on a combination of clean and noisy data.", "labels": [], "entities": []}, {"text": "We show that in a low-resource NER task we can improve performance by up to 35% by using additional, noisy data and handling the noise.", "labels": [], "entities": [{"text": "NER task", "start_pos": 31, "end_pos": 39, "type": "TASK", "confidence": 0.912206619977951}]}], "introductionContent": [{"text": "For training statistical models in a supervised way, labeled datasets are required.", "labels": [], "entities": []}, {"text": "For many natural language processing tasks like part-of-speech tagging (POS) or named entity recognition (NER), every word in a corpus needs to be annotated.", "labels": [], "entities": [{"text": "part-of-speech tagging (POS)", "start_pos": 48, "end_pos": 76, "type": "TASK", "confidence": 0.8402723908424378}, {"text": "named entity recognition (NER)", "start_pos": 80, "end_pos": 110, "type": "TASK", "confidence": 0.8106114864349365}]}, {"text": "While the large effort of manual annotation is regularly done for English, for other languages this is often not the case.", "labels": [], "entities": []}, {"text": "And even for English, the corpora are usually limited to certain domains like newspaper articles.", "labels": [], "entities": []}, {"text": "For tasks in low-resource areas there tend to be no or only few labeled words available.", "labels": [], "entities": []}, {"text": "Distant supervision and automatic labeling approaches are an alternative to manually creating labels.", "labels": [], "entities": []}, {"text": "These exploit the fact that frequently large amounts of unannotated texts do exist in the targeted domain, e.g. from web crawls.", "labels": [], "entities": []}, {"text": "The labels are then assigned using techniques like transferring information from high-resource languages () or simple look-ups in knowledge bases or gazetteers.", "labels": [], "entities": []}, {"text": "Once such an automatic labeling system is setup, the amount of text to annotate becomes nearly irrelevant, especially in comparison to manual annotation.", "labels": [], "entities": []}, {"text": "Also, it is often rather easy to apply the system to different settings, e.g. by using a knowledge base in a different language.", "labels": [], "entities": []}, {"text": "However, while easily obtainable in large amounts, the automatically annotated data usually contains more errors than the manually annotated.", "labels": [], "entities": []}, {"text": "When training a machine learning algorithm on such noisy training data, this can result in a low performance.", "labels": [], "entities": []}, {"text": "Furthermore, the combination of noisy and clean training instances can perform even worse than just using clean data.", "labels": [], "entities": []}, {"text": "In this work, we present an approach to training a neural network with a combination of a small amount of clean data and a larger set of automatically annotated, noisy instances.", "labels": [], "entities": []}, {"text": "We model the noise explicitly using a noise layer that is added to the network architecture.", "labels": [], "entities": []}, {"text": "This allows us to directly optimize the network weights using standard techniques.", "labels": [], "entities": []}, {"text": "After training, the noise layer is not needed anymore, removing any added complexity.", "labels": [], "entities": []}, {"text": "This technique is applicable to different classification scenarios and in this work, we apply it to an NER task.", "labels": [], "entities": [{"text": "NER task", "start_pos": 103, "end_pos": 111, "type": "TASK", "confidence": 0.9013969302177429}]}, {"text": "To obtain a non-synthetic, realistic source of noise, we use look-ups from gazetteers for automatically annotating the data.", "labels": [], "entities": []}, {"text": "In the lowresource setting, we show the performance boost obtained from training with both clean and noisy instances and from handling the noise in the data.", "labels": [], "entities": []}, {"text": "We also compare to another recent neural network noise-handling approach and we give some more insight into the impact of using additional noisy data and into the learned noise model.", "labels": [], "entities": []}], "datasetContent": [{"text": "Named Entity Recognition (NER) is the task of assigning phrases in a text an entity label.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7761517961819967}]}, {"text": "In the sentence Only France backed Fischler's proposal.", "labels": [], "entities": []}, {"text": "the country France is of the entity class location and Fischler refers to a person.", "labels": [], "entities": [{"text": "Fischler", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.8978967666625977}]}, {"text": "Creating training data for this task requires that each word in the text is labeled with its corresponding class.", "labels": [], "entities": []}, {"text": "The effort to create a sufficiently large dataset might be too large fora low-resource language.", "labels": [], "entities": []}, {"text": "The dataset is labeled with the classes person (PER), location (LOC), organization (ORG), miscellaneous name (MISC) and the null class (O).", "labels": [], "entities": [{"text": "organization (ORG)", "start_pos": 70, "end_pos": 88, "type": "METRIC", "confidence": 0.8084843307733536}]}, {"text": "It consists of a training, a development and a test set.", "labels": [], "entities": []}, {"text": "To obtain a low-resource setting, we randomly sample a subset of the training set as clean data C.", "labels": [], "entities": []}, {"text": "In the experiments, we vary this size between ca.", "labels": [], "entities": []}, {"text": "The rest of the labels are removed from the training set.", "labels": [], "entities": []}, {"text": "We then label the whole training set using the method by in the version with heuristics.", "labels": [], "entities": []}, {"text": "This approach of automatically labeling words allows to quickly obtain large amounts of labeled text.", "labels": [], "entities": []}, {"text": "However, both precision and recall tend to be lower than for manually labeled corpora (cf.).", "labels": [], "entities": [{"text": "precision", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9997124075889587}, {"text": "recall", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.9997314810752869}]}, {"text": "It should be noted that the MISC class is not covered with this technique which is an additional source of noise in the automatically annotated data.", "labels": [], "entities": [{"text": "MISC class", "start_pos": 28, "end_pos": 38, "type": "DATASET", "confidence": 0.7327266335487366}]}, {"text": "We use this as our noisy data N .  In this section, we report on our experiments and their results.", "labels": [], "entities": []}, {"text": "The training on noisy data as well as the randomness in training neural networks in general lead to a certain amount of variance in the evaluation scores.", "labels": [], "entities": []}, {"text": "Therefore, we repeat all experiments five times and report the average as well as the standard error.", "labels": [], "entities": [{"text": "standard error", "start_pos": 86, "end_pos": 100, "type": "METRIC", "confidence": 0.9621957242488861}]}, {"text": "To obtain meaningful results, no noise is added to the test data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Evaluation of the automatic labeling on  the full English CoNLL-2003 training set (which  we use as noisy dataset N ).", "labels": [], "entities": [{"text": "English CoNLL-2003 training set", "start_pos": 60, "end_pos": 91, "type": "DATASET", "confidence": 0.8084259629249573}]}]}