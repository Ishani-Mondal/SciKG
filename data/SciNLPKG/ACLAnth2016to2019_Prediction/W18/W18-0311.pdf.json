{"title": [{"text": "Phonologically Informed Edit Distance Algorithms for Word Alignment with Low-Resource Languages", "labels": [], "entities": [{"text": "Word Alignment", "start_pos": 53, "end_pos": 67, "type": "TASK", "confidence": 0.7371316403150558}]}], "abstractContent": [{"text": "Edit distance is commonly used to relate cog-nates across languages.", "labels": [], "entities": []}, {"text": "This technique is particularly relevant for the processing of low-resource languages because the sparse data from such a language can be significantly bolstered by connecting words in the low-resource language with cognates in a related, higher-resource language.", "labels": [], "entities": []}, {"text": "We present three methods for weighting edit distance algorithms based on linguistic information.", "labels": [], "entities": [{"text": "weighting edit distance", "start_pos": 29, "end_pos": 52, "type": "TASK", "confidence": 0.8548202117284139}]}, {"text": "These methods base their penalties on (i) phonolog-ical features, (ii) distributional character em-beddings, or (iii) differences between cognate words.", "labels": [], "entities": []}, {"text": "We also introduce a novel method for evaluating edit distance through the task of low-resource word alignment by using edit-distance neighbors in a high-resource pivot language to inform alignments from the low-resource language.", "labels": [], "entities": [{"text": "low-resource word alignment", "start_pos": 82, "end_pos": 109, "type": "TASK", "confidence": 0.7100855906804403}]}, {"text": "At this task, the cognate-based scheme outperforms our other methods and the Levenshtein edit distance base-line, showing that NLP applications can benefit from information about cross-linguistic phonological patterns.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many NLP techniques require large quantities of training data, which is a problem for low-resource languages (languages with little available data).", "labels": [], "entities": []}, {"text": "Work on low-resource languages often focuses on tackling this low-data problem, such as by creating more data, collecting more data from the Internet () or from * Work done while at Yale University.", "labels": [], "entities": []}, {"text": "scholarly papers (, efficiently eliciting informative data), or crowdsourcing the collection of corpora (.", "labels": [], "entities": []}, {"text": "One promising approach is to supplement the available data fora low-resource language with data from higher-resource languages, an approach which has been applied to tasks ranging from speech recognition () to machine translation ().", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 185, "end_pos": 203, "type": "TASK", "confidence": 0.7464688122272491}, {"text": "machine translation", "start_pos": 210, "end_pos": 229, "type": "TASK", "confidence": 0.7943067252635956}]}, {"text": "An open problem within this approach is finding the best way to map information from one language to another.", "labels": [], "entities": []}, {"text": "When connecting related languages, a natural place to start is with cognates, and many works use edit distance for cognate detection.", "labels": [], "entities": [{"text": "cognate detection", "start_pos": 115, "end_pos": 132, "type": "TASK", "confidence": 0.7821570932865143}]}, {"text": "Edit distance refers to the difference between two strings, and this paper explores several techniques for determining edit distance.", "labels": [], "entities": []}, {"text": "Our baseline is the Levenshtein edit distance algorithm, and we introduce three novel edit distance algorithms, namely feature-based edit distance, char2vec-based edit distance, and cognatebased edit distance, and assess their performance at transferring information across languages using the task of low-resource cognate identification.", "labels": [], "entities": [{"text": "low-resource cognate identification", "start_pos": 302, "end_pos": 337, "type": "TASK", "confidence": 0.8151556253433228}]}, {"text": "Finally, we introduce a novel method for evaluating edit distance algorithms through the task of word alignment.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 97, "end_pos": 111, "type": "TASK", "confidence": 0.7679172158241272}]}, {"text": "first presented schemes for training weighted edit distances, and others such as have proposed modifications to this method.", "labels": [], "entities": []}, {"text": "Weighted edit distance and other weighted schemes for computing string similarity such as point-wise mutual information have been used by several authors for cognate detection.", "labels": [], "entities": [{"text": "cognate detection", "start_pos": 158, "end_pos": 175, "type": "TASK", "confidence": 0.8080654144287109}]}, {"text": "This paper's novel contribution is to extend this technique to a low-resource setting.", "labels": [], "entities": []}, {"text": "The prior work in edit-distance-based cognate detection has relied on phonetic transcriptions, information about word meaning, or hand-created lists of cognates on which to train a system.", "labels": [], "entities": [{"text": "edit-distance-based cognate detection", "start_pos": 18, "end_pos": 55, "type": "TASK", "confidence": 0.6734593609968821}]}, {"text": "Here we investigate how to assign edit distance weights when no such information is available for one of the languages in question.", "labels": [], "entities": []}, {"text": "Several prior systems have used word similarity to assess historical linguistic claims about language phylogeny, but here we follow the inverse strategy of using knowledge about language phylogeny to inform the determination of string similarity by compensating for the lack of resources about a language with information from closely related and better-resourced languages.", "labels": [], "entities": [{"text": "determination of string similarity", "start_pos": 211, "end_pos": 245, "type": "TASK", "confidence": 0.6715961843729019}]}, {"text": "An additional novel contribution of this paper is to propose anew technique for assessing string similarity metrics based on how much a given metric can improve performance on a practical NLP task.", "labels": [], "entities": []}], "datasetContent": [{"text": "For all experiments, Spanish is treated as if it is a low-resource language for which we wish to gain information based on its high-resource relatives of Portuguese, Italian, and French.", "labels": [], "entities": []}, {"text": "Although Spanish is a very high-resource language in real life, for these experiments we simulate low-resourcedness by not providing the computer with any Spanish training data; thus, the test data is the computer's only exposure to Spanish.", "labels": [], "entities": []}, {"text": "We chose this path rather than using a truly low-resource language because it is much easier to create gold standards for evaluation fora high-resource language.", "labels": [], "entities": []}, {"text": "As in real life, Portuguese, Italian, and French are treated as high-resource (that is, there is ample training data for these languages), as is English, which is used in the word alignment experiments.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 175, "end_pos": 189, "type": "TASK", "confidence": 0.7825261354446411}]}, {"text": "Thus, the char2vec embeddings are trained on Portuguese data, and the cognate-based edit distances are trained on Portuguese, French, and Italian data.", "labels": [], "entities": []}, {"text": "All experiments used the Europarl parallel corpus () as sources of text in the languages of interest.", "labels": [], "entities": [{"text": "Europarl parallel corpus", "start_pos": 25, "end_pos": 49, "type": "DATASET", "confidence": 0.9381998380025228}]}, {"text": "This corpus comes from the proceedings of the European Parliament, a governing body of the European Union.", "labels": [], "entities": []}, {"text": "An advantage of the word alignment task is that we can straightforwardly quantify the results via the Alignment Error Rate (AER), defined as where P is the number of predicted alignments that are correct, c is the number of alignments in the gold standard, and p is the number of predicted alignments (where an alignment is defined as a connection between one Spanish word and one English word).", "labels": [], "entities": [{"text": "word alignment", "start_pos": 20, "end_pos": 34, "type": "TASK", "confidence": 0.7506867945194244}, {"text": "Alignment Error Rate (AER)", "start_pos": 102, "end_pos": 128, "type": "METRIC", "confidence": 0.9632207751274109}]}, {"text": "AER falls within the range of 0 to 1, where it is best to be as close to 0 as possible.", "labels": [], "entities": [{"text": "AER", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9894914627075195}]}], "tableCaptions": [{"text": " Table 3. The cognate-based results are re- ported with d = 2, where d is the maximum edit dis- tance between French/Italian, French/Portuguese,", "labels": [], "entities": []}, {"text": " Table 4: Smoothed word alignment results for various experimental settings.", "labels": [], "entities": [{"text": "Smoothed word alignment", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.7484262585639954}]}]}