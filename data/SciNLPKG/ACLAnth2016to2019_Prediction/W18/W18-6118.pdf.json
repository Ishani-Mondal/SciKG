{"title": [{"text": "Lexical Analysis and Content Extraction from Customer-Agent Interactions", "labels": [], "entities": [{"text": "Lexical Analysis", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8760808706283569}, {"text": "Content Extraction from Customer-Agent Interactions", "start_pos": 21, "end_pos": 72, "type": "TASK", "confidence": 0.8263213753700256}]}], "abstractContent": [{"text": "In this paper, we provide a lexical comparative analysis of the vocabulary used by customers and agents in an Enterprise Resource Planning (ERP) environment and a potential solution to clean the data and extract relevant content for NLP.", "labels": [], "entities": []}, {"text": "As a result, we demonstrate that the actual vocabulary for the language that prevails in the ERP conversations is highly divergent from the standardized dictionary and further different from general language usage as extracted from the Common Crawl corpus.", "labels": [], "entities": [{"text": "Common Crawl corpus", "start_pos": 236, "end_pos": 255, "type": "DATASET", "confidence": 0.8992252349853516}]}, {"text": "Moreover, in specific business communication circumstances, where it is expected to observe a high usage of standardized language , code switching and non-standard expression are predominant, emphasizing once more the discrepancy between the day-today use of language and the standardized one.", "labels": [], "entities": [{"text": "code switching", "start_pos": 132, "end_pos": 146, "type": "TASK", "confidence": 0.7369482219219208}]}], "introductionContent": [{"text": "It is often the case for companies that make use of a customer relationship management software, to collect large amounts of noisy data from the interactions of their customers with human agents.", "labels": [], "entities": [{"text": "customer relationship management", "start_pos": 54, "end_pos": 86, "type": "TASK", "confidence": 0.6468817392985026}]}, {"text": "The customer-agent communication can have a wide range of channels from speech, live chat, email or some other application-level protocol that is wrapped over SMTP.", "labels": [], "entities": []}, {"text": "If such data is stored in a structured manner, companies can use it to optimize procedures, retrieve information quickly, and decrease redundancy which overall can prove beneficial for their customers and maybe, more important, for the well-being of their employees working as agents, who can use technology to ease their day-to-day job.", "labels": [], "entities": []}, {"text": "In our paper, we work with email exchanges that have been previously stored as raw text or html dumps into a database and attempt bring up some possible issues in dealing with this kind of data lexically, from an NLP perspective, but also to forward a solution for cleaning and extracting useful content from raw text.", "labels": [], "entities": []}, {"text": "Given the large amounts of unstructured data that is being collected as email exchanges, we believe that our proposed method can be a viable solution for content extraction and cleanup as a preprocessing step for indexing and search, near-duplicate detection, accurate classification by categories, user intent extraction or automatic reply generation.", "labels": [], "entities": [{"text": "content extraction", "start_pos": 154, "end_pos": 172, "type": "TASK", "confidence": 0.733900249004364}, {"text": "near-duplicate detection", "start_pos": 234, "end_pos": 258, "type": "TASK", "confidence": 0.7431755065917969}, {"text": "user intent extraction", "start_pos": 299, "end_pos": 321, "type": "TASK", "confidence": 0.6514418125152588}, {"text": "reply generation", "start_pos": 335, "end_pos": 351, "type": "TASK", "confidence": 0.6814047396183014}]}, {"text": "We carry our analysis for Romanian (ISO 639-1 ro) -a Romance language spoken by almost 24 million people, but with a relatively limited number of NLP resources.", "labels": [], "entities": []}, {"text": "The purpose of our approach is twofold -to provide a comparative analysis between how words are used in questionanswer interactions between customers and call center agents (at the corpus level) and language as it is standardized in an official dictionary, and to provide a possible solution to extract meaningful content that can be used in natural language processing pipelines.", "labels": [], "entities": []}, {"text": "Last, but not least, our hope is to increase the amount of digital resources available for Romanian by releasing parts of our data.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Question answering corpus size", "labels": [], "entities": [{"text": "Question answering", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.9317896664142609}]}, {"text": " Table 2: Comparison of overlapping dictionaries", "labels": [], "entities": []}, {"text": " Table 3: Average number of features / question or an- swer", "labels": [], "entities": [{"text": "Average", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9753722548484802}]}, {"text": " Table 4: Samples of most similar words from Q/A word embeddings compared to Common Crawl. English  translation is provided between parentheses.", "labels": [], "entities": [{"text": "English  translation", "start_pos": 91, "end_pos": 111, "type": "TASK", "confidence": 0.5971745550632477}]}, {"text": " Table 5: Cross-validation scores for different corpus  cleanup methods.", "labels": [], "entities": []}]}