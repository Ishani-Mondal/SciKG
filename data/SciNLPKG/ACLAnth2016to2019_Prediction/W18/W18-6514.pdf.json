{"title": [{"text": "Improving Context Modelling in Multimodal Dialogue Generation", "labels": [], "entities": [{"text": "Improving Context Modelling", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.892204205195109}]}], "abstractContent": [{"text": "In this work, we investigate the task of tex-tual response generation in a multimodal task-oriented dialogue system.", "labels": [], "entities": [{"text": "tex-tual response generation", "start_pos": 41, "end_pos": 69, "type": "TASK", "confidence": 0.6498163441816965}]}, {"text": "Our work is based on the recently released Mul-timodal Dialogue (MMD) dataset (Saha et al., 2017) in the fashion domain.", "labels": [], "entities": [{"text": "Mul-timodal Dialogue (MMD) dataset", "start_pos": 43, "end_pos": 77, "type": "DATASET", "confidence": 0.6420054237047831}]}, {"text": "We introduce a multimodal extension to the Hierarchical Recurrent Encoder-Decoder (HRED) model and show that this extension outperforms strong baselines in terms of text-based similarity metrics.", "labels": [], "entities": []}, {"text": "We also showcase the shortcomings of current vision and language models by performing an error analysis on our system's output.", "labels": [], "entities": []}], "introductionContent": [{"text": "This work aims to learn strategies for textual response generation in a multimodal conversation directly from data.", "labels": [], "entities": [{"text": "textual response generation", "start_pos": 39, "end_pos": 66, "type": "TASK", "confidence": 0.7287931044896444}]}, {"text": "Conversational AI has great potential for online retail: It greatly enhances user experience and in turn directly affects user retention (), especially if the interaction is multi-modal in nature.", "labels": [], "entities": [{"text": "Conversational AI", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7682695388793945}]}, {"text": "So far, most conversational agents are uni-modal -ranging from opendomain conversation) to task oriented dialogue systems (.", "labels": [], "entities": []}, {"text": "While recent progress in deep learning has unified research at the intersection of vision and language, the availability of open-source multimodal dialogue datasets still remains a bottleneck.", "labels": [], "entities": []}, {"text": "This research makes use of a recently released Multimodal Dialogue (MMD) dataset (, which contains multiple dialogue sessions in the fashion domain.", "labels": [], "entities": []}, {"text": "The MMD dataset provides an interesting new challenge, combining recent efforts on task-oriented dialogue systems, as well as visually grounded dialogue.", "labels": [], "entities": [{"text": "MMD dataset", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.8491986691951752}]}, {"text": "In contrast to simple QA tasks in visually grounded dialogue, e.g. (, it contains conversations with a clear end-goal.", "labels": [], "entities": []}, {"text": "However, in contrast to previous slot-filling dialogue systems, e.g. (, it heavily relies on the extra visual modality to drive the conversation forward (see.", "labels": [], "entities": []}, {"text": "In the following, we propose a fully data-driven response generation model for this task.", "labels": [], "entities": [{"text": "response generation", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.6998403072357178}]}, {"text": "Our work is able to ground the system's textual response with language and images by learning the semantic correspondence between them while modelling long-term dialogue context.: Example of a user-agent interaction in the fashion domain.", "labels": [], "entities": []}, {"text": "In this work, we are interested in the textual response generation fora user query.", "labels": [], "entities": [{"text": "textual response generation", "start_pos": 39, "end_pos": 66, "type": "TASK", "confidence": 0.6260319848855337}]}, {"text": "Both user query and agent response can be multimodal in nature.", "labels": [], "entities": []}], "datasetContent": [{"text": "The MMD dataset ( consists of 100/11/11k train/validation/test chat sessions comprising 3.5M context-response pairs for the model.", "labels": [], "entities": [{"text": "MMD dataset", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.9248151481151581}]}, {"text": "Each session contains an average of 40 dialogue turns (average of 8 words per textual response, 4 images per image response).", "labels": [], "entities": []}, {"text": "The data contains complex user queries, which pose new challenges for multimodal, task-based dialogue, such as quantitative inference (sorting, counting and filtering): \"Show me more images of the 3rd product in some different directions\", inference using domain knowledge and long term context: \"Will the 5th result go well with a large sized messenger bag?\", inference over aggregate of images: \"List more in the upper material of the 5th image and style as the 3rd and the 5th\", co-reference resolution.", "labels": [], "entities": []}, {"text": "Note that we started with the raw transcripts of dialogue sessions to create our own version of the dataset for the model.", "labels": [], "entities": []}, {"text": "This is done since the authors originally consider each image as a different context, while we consider all the images in a single turn as one concatenated context (cf.).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Sentence-level BLEU-4, METEOR and  ROUGE-L results for the response generation  task on the MMD corpus. \"Cxt\" represents con- text size considered by the model. Our best per- forming model is M-HRED-attn over a context of  5 turns. *Saha et al. has been trained on a different  version of the dataset.", "labels": [], "entities": [{"text": "BLEU-4", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9701964855194092}, {"text": "METEOR", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.9881117343902588}, {"text": "ROUGE-L", "start_pos": 45, "end_pos": 52, "type": "METRIC", "confidence": 0.9970533847808838}, {"text": "response generation", "start_pos": 69, "end_pos": 88, "type": "TASK", "confidence": 0.7876050472259521}, {"text": "MMD corpus", "start_pos": 102, "end_pos": 112, "type": "DATASET", "confidence": 0.7905621826648712}]}]}