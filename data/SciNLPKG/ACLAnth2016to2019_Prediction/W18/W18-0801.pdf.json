{"title": [], "abstractContent": [{"text": "In this position paper, we propose that the community consider encouraging researchers to include two riders, a \"Lay Summary\" and an \"AI Safety Disclosure\", as part of future NLP papers published in ACL forums that present user-facing systems.", "labels": [], "entities": []}, {"text": "The goal is to encourage researchers-via a relatively non-intrusive mechanism-to consider the societal implications of technologies carrying (un)known and/or (un)knowable long-term risks, to highlight failure cases, and to provide a mechanism by which the general public (and scientists in other disciplines) can more readily engage in the discussion in an informed manner.", "labels": [], "entities": []}, {"text": "This simple proposal requires minimal additional up-front costs for researchers; the lay summary, at least, has significant precedence in the medical literature and other areas of science ; and the proposal is aimed to supplement, rather than replace, existing approaches for encouraging researchers to consider the ethical implications of their work, such as those of the Collaborative Institutional Training Initiative (CITI) Program and institutional review boards (IRBs).", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent research advances in natural language processing have the potential to translate into realworld products and applications.", "labels": [], "entities": []}, {"text": "As with the broader field of artificial intelligence (AI), more generally, there is not abroad consensus on whether the long-term social impact of such advances will be positive or negative-and to whom any future negative impacts will be most acutely dealt.", "labels": [], "entities": []}, {"text": "However, there is perhaps consensus that it is useful for researchers to at least consider the potential societal impacts of their work.", "labels": [], "entities": []}, {"text": "The concern is not entirely speculative, as user-facing applications of NLP today in areas such as education, for example, have the potential to have large proportions of users who are minors and/or members of at-risk groups, with the output of such systems used in high-stakes educational assessment.", "labels": [], "entities": []}, {"text": "To encourage NLP researchers to consider the societal impacts of their work and to involve the general public in the discussion, we propose that the community consider encouraging authors-on a voluntary basis field-tested in a workshop settingto include two riders for papers describing userfacing systems or methods.", "labels": [], "entities": []}, {"text": "One, a \"Lay Summary\", which has precedence in journals in other scientific fields, is a short summary aimed at a non-specialist audience designed to reduce misinformation and engage the public.", "labels": [], "entities": []}, {"text": "The second, an \"AI Safety Disclosure\", is a brief overview of potential failure scenarios of which real-world implementations, downstream applications, and future research should be aware.", "labels": [], "entities": []}, {"text": "We surmise that the utility of these riders will be particularly high for NLP papers for which the proposed approaches or methods are aimed at eventually building user-facing systems (e.g., for machine translation, grammar correction, or summarization), but for which the actual research did not directly involve human subjects and thus (rightly so), fall outside the purview of traditional mechanisms such as institutional review boards.", "labels": [], "entities": [{"text": "machine translation, grammar correction", "start_pos": 194, "end_pos": 233, "type": "TASK", "confidence": 0.6933696627616882}]}], "datasetContent": [], "tableCaptions": []}