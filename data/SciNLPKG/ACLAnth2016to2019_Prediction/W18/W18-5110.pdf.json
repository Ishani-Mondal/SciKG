{"title": [{"text": "The Effects of User Features on Twitter Hate Speech Detection", "labels": [], "entities": [{"text": "Hate Speech Detection", "start_pos": 40, "end_pos": 61, "type": "TASK", "confidence": 0.606851706902186}]}], "abstractContent": [{"text": "The paper investigates the potential effects user features have on hate speech classification.", "labels": [], "entities": [{"text": "hate speech classification", "start_pos": 67, "end_pos": 93, "type": "TASK", "confidence": 0.7999441027641296}]}, {"text": "A quantitative analysis of Twitter data was conducted to better understand user characteristics , but no correlations were found between hateful text and the characteristics of the users who had posted it.", "labels": [], "entities": []}, {"text": "However, experiments with a hate speech classifier based on datasets from three different languages showed that combining certain user features with textual features gave slight improvements of classification performance.", "labels": [], "entities": []}, {"text": "While the incorporation of user features resulted in varying impact on performance for the different datasets used, user network-related features provided the most consistent improvements.", "labels": [], "entities": []}], "introductionContent": [{"text": "Detecting hate speech has become an increasingly important task for online communities, but automatic hate speech detection is a challenging task, which the majority of the research in the field is targeting through textual features.", "labels": [], "entities": [{"text": "Detecting hate speech", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8989474972089132}, {"text": "automatic hate speech detection", "start_pos": 92, "end_pos": 123, "type": "TASK", "confidence": 0.6044798716902733}]}, {"text": "However, as shown by, e.g.,, there is a need for further efforts to improve the quality and efficiency of detection methods, motivating for studies on how non-textual features can be utilised to enhance detection performance.", "labels": [], "entities": []}, {"text": "The goal of this research is to investigate information related to users in the Twitter community that can be helpful in identifying online hate speech, and use this as features in hate speech classification.", "labels": [], "entities": [{"text": "identifying online hate speech", "start_pos": 121, "end_pos": 151, "type": "TASK", "confidence": 0.8387452811002731}, {"text": "hate speech classification", "start_pos": 181, "end_pos": 207, "type": "TASK", "confidence": 0.6926893889904022}]}, {"text": "Information about the users could be either known factors, such as age and gender, or factors derived from behaviour.", "labels": [], "entities": []}, {"text": "There exists research that investigates the impact of different features, and research about the personality and behaviour of users expressing hate speech.", "labels": [], "entities": []}, {"text": "However, there is little research that combines the two topics.", "labels": [], "entities": []}, {"text": "Most early studies on automatic recognition of online hate speech focused on lexicon-based approaches for detecting \"bad\" words, with finding that 83% of their data was annotated racist due to the presence of offensive words.", "labels": [], "entities": [{"text": "automatic recognition of online hate speech", "start_pos": 22, "end_pos": 65, "type": "TASK", "confidence": 0.8323478053013483}]}, {"text": "However, these approaches tend to give low precision by mistakenly classifying all messages containing specific terms as hate speech, which is particularly problematic on social media sites that have a relatively high prevalence of offensive words ().", "labels": [], "entities": [{"text": "precision", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.9970711469650269}]}, {"text": "After all, hate speech can be much more sophisticated than that.", "labels": [], "entities": [{"text": "hate speech", "start_pos": 11, "end_pos": 22, "type": "TASK", "confidence": 0.9520692527294159}]}, {"text": "Finding the features that best represent the underlying phenomenon of hate speech is challenging.", "labels": [], "entities": []}, {"text": "Later studies have mainly focused on contentbased text classification using features such as the appearance or frequency of words, spelling mistakes or semantic meaning, but while these methods perform relatively well, there is still need for improvements to increase the quality of detection.", "labels": [], "entities": [{"text": "contentbased text classification", "start_pos": 37, "end_pos": 69, "type": "TASK", "confidence": 0.6308159728844961}]}, {"text": "The rest of the paper is structured as follows: Section 2 discusses previous studies related to the authors of hate speech and Section 3 presents the datasets used together with an analysis of user characteristics.", "labels": [], "entities": []}, {"text": "Section 4 describes the classifier developed, while Section 5 details the experiments conducted to measure the impact of user features.", "labels": [], "entities": []}, {"text": "Section 6 sums up the research contributions along with suggestions for potential future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "The English dataset by is publicly available on GitHub.", "labels": [], "entities": [{"text": "English dataset", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.8092186450958252}]}, {"text": "The Twitter search API was used to collect the corpus, and in total 16,907 tweets (from 2,399 users) were annotated either as racist, sexist or neither.", "labels": [], "entities": []}, {"text": "The dataset contains more instances of neutral than racist or sexist tweets.", "labels": [], "entities": []}, {"text": "This unbalance was intended by the developers, to make the corpus more representative of the real world, where hate speech is a limited phenomenon.", "labels": [], "entities": []}, {"text": "Since the dataset was developed in 2016, the Python library Tweepy was used hereto filter out any unavailable tweets and users.", "labels": [], "entities": []}, {"text": "Furthermore, the original \"Sexism\" and \"Racism\" classes were merged into one \"Hate speech\" class.", "labels": [], "entities": []}, {"text": "1,180 of the original tweets were no longer available, which also impacted the number of users in the dataset.", "labels": [], "entities": []}, {"text": "The remaining tweets and users are presented in, in the 'ENG' column.", "labels": [], "entities": [{"text": "ENG", "start_pos": 57, "end_pos": 60, "type": "METRIC", "confidence": 0.9680256247520447}]}, {"text": "Fortuna (2017) developed a dataset consisting of 5,668 Portuguese tweets and made it available through the INESC TEC research data repository.", "labels": [], "entities": [{"text": "INESC TEC research data repository", "start_pos": 107, "end_pos": 141, "type": "DATASET", "confidence": 0.9506597638130188}]}, {"text": "Tweets were collected through the Twitter API with searches based on keywords related to hate speech and Twitter profiles known for posting hate messages.", "labels": [], "entities": []}, {"text": "Fortuna aimed to have a higher proportion of hate speech messages than other related datasets, and 22% of the tweets were annotated as hate speech.", "labels": [], "entities": [{"text": "Fortuna", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9124413728713989}]}, {"text": "She annotated nine direct hate speech sub-classes, but in the present work those will be merged into one hate speech class.", "labels": [], "entities": []}, {"text": "In total there are 5,668 annotated tweets by 1,156 distinct users; however, the distribution of users within the target classes was not specified.", "labels": [], "entities": []}, {"text": "Today, close to half of the tweets in both classes are unavailable; however, as shown in the 'POR' column of, there are still 1,010 users available, meaning that the unavailability of tweets did not heavily affect the number of users.", "labels": [], "entities": [{"text": "POR' column", "start_pos": 94, "end_pos": 105, "type": "METRIC", "confidence": 0.9605170687039694}]}, {"text": "While the original dataset had a binary value for the presence of hate speech and subcategories as labels, the target classes were here changed to \"Hate speech\" and \"None\".", "labels": [], "entities": []}, {"text": "To investigate the issue of reliability concerning hate speech annotation, compiled a German hate speech corpus with tweets linked to the refugee crisis in Europe.", "labels": [], "entities": [{"text": "hate speech annotation", "start_pos": 51, "end_pos": 73, "type": "TASK", "confidence": 0.7421063979466757}, {"text": "German hate speech corpus", "start_pos": 86, "end_pos": 111, "type": "DATASET", "confidence": 0.7112323045730591}]}, {"text": "By using known insulting or offensive hashtags, a total of 13,766 tweets were collected, 469 of which were annotated by two annotators for presence or absence of hate speech.", "labels": [], "entities": []}, {"text": "In the column 'GER' shows the availability of the tweets in the dataset and the number of users in each target class.", "labels": [], "entities": [{"text": "GER", "start_pos": 15, "end_pos": 18, "type": "METRIC", "confidence": 0.9634474515914917}]}, {"text": "It was beneficial to transform the labels of the dataset into binary classes, to equal the labelling of the other datasets.", "labels": [], "entities": []}, {"text": "Therefore, a tweet that was labelled \"Yes\" by one or both of the annotators was assigned to the \"Hate speech\" class.", "labels": [], "entities": [{"text": "Hate speech\" class", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.6795740723609924}]}, {"text": "Hence, the \"Hate speech\" class consists of 65 available tweets labelled as hate speech by one annotator, and 33 labelled hate speech by both annotators.", "labels": [], "entities": []}, {"text": "The datasets were initially split into training data and test data to ensure that the model performance was evaluated on unseen data.", "labels": [], "entities": []}, {"text": "A grid search with 10-fold cross-validation over the training data was used for selecting model parameters.", "labels": [], "entities": []}, {"text": "This section first presents results from baseline classification with only n-gram features, and then discusses the effects of incorporating user features.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Available tweets and users in the datasets", "labels": [], "entities": []}, {"text": " Table 2: User profile characteristics (%)", "labels": [], "entities": []}, {"text": " Table 3: Grid search of n-gram parameters", "labels": [], "entities": []}, {"text": " Table 4: Baseline model performance on test data", "labels": [], "entities": []}, {"text": " Table 5: Impact of different user feature sets", "labels": [], "entities": []}]}