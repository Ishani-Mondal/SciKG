{"title": [{"text": "Analyzing Learned Representations of a Deep ASR Performance Prediction Model", "labels": [], "entities": [{"text": "ASR Performance Prediction", "start_pos": 44, "end_pos": 70, "type": "TASK", "confidence": 0.8926265041033427}]}], "abstractContent": [{"text": "This paper addresses a relatively new task: prediction of ASR performance on unseen broadcast programs.", "labels": [], "entities": [{"text": "prediction", "start_pos": 44, "end_pos": 54, "type": "TASK", "confidence": 0.9672579169273376}, {"text": "ASR", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.7614297270774841}]}, {"text": "Ina previous paper, we presented an ASR performance prediction system using CNNs that encode both text (ASR transcript) and speech, in order to predict word error rate.", "labels": [], "entities": [{"text": "ASR performance prediction", "start_pos": 36, "end_pos": 62, "type": "TASK", "confidence": 0.8962200085322062}]}, {"text": "This work is dedicated to the analysis of speech signal embeddings and text em-beddings learnt by the CNN while training our prediction model.", "labels": [], "entities": []}, {"text": "We try to better understand which information is captured by the deep model and its relation with different conditioning factors.", "labels": [], "entities": []}, {"text": "It is shown that hidden layers convey a clear signal about speech style, accent and broadcast type.", "labels": [], "entities": []}, {"text": "We then try to leverage these 3 types of information at training time through multi-task learning.", "labels": [], "entities": []}, {"text": "Our experiments show that this allows to train slightly more efficient ASR performance prediction systems that-in addition-simultaneously tag the analyzed utterances according to their speech style, accent and broadcast program origin.", "labels": [], "entities": [{"text": "ASR performance prediction", "start_pos": 71, "end_pos": 97, "type": "TASK", "confidence": 0.9087167382240295}]}], "introductionContent": [{"text": "Predicting automatic speech recognition (ASR) performance on unseen speech recordings is an important Grail of speech research.", "labels": [], "entities": [{"text": "Predicting automatic speech recognition (ASR) performance", "start_pos": 0, "end_pos": 57, "type": "TASK", "confidence": 0.8929199129343033}]}, {"text": "Ina previous paper (, we presented a framework for modeling and evaluating ASR performance prediction on unseen broadcast programs.", "labels": [], "entities": [{"text": "ASR performance prediction", "start_pos": 75, "end_pos": 101, "type": "TASK", "confidence": 0.8690617481867472}]}, {"text": "CNNs were very efficient encoding both text (ASR transcript) and speech to predict ASR word error rate (WER).", "labels": [], "entities": [{"text": "ASR word error rate (WER)", "start_pos": 83, "end_pos": 108, "type": "METRIC", "confidence": 0.7919229567050934}]}, {"text": "However, while achieving state-of-the-art performance prediction results, our CNN approach is more difficult to understand compared to conventional approaches based on engineered features such as TransRater 1 for instance.", "labels": [], "entities": [{"text": "performance prediction", "start_pos": 42, "end_pos": 64, "type": "TASK", "confidence": 0.7358764708042145}]}, {"text": "This lack of interpretability of the representations learned by deep neural networks is a 1 https://github.com/hlt-mt/TranscRater general problem in AI.", "labels": [], "entities": []}, {"text": "Recent papers started to address this issue and analyzed hidden representations learned during training of different natural language processing models (.", "labels": [], "entities": []}, {"text": "This work is dedicated to the analysis of speech signal embeddings and text embeddings learnt by the CNN during training of our ASR performance prediction model.", "labels": [], "entities": [{"text": "ASR performance prediction", "start_pos": 128, "end_pos": 154, "type": "TASK", "confidence": 0.9052256941795349}]}, {"text": "Our goal is to better understand which information is captured by the deep model and its relation with conditioning factors such as speech style, accent or broadcast program type.", "labels": [], "entities": []}, {"text": "For this, we use a data set presented in () which contains a large amount of speech utterances taken from various collections of French broadcast programs.", "labels": [], "entities": []}, {"text": "Following a methodology similar to, our deep performance prediction model is used to generate utterance level features that are given to a shallow classifier trained to solve secondary classification tasks.", "labels": [], "entities": [{"text": "deep performance prediction", "start_pos": 40, "end_pos": 67, "type": "TASK", "confidence": 0.6874621311823527}]}, {"text": "It is shown that hidden layers convey a clear signal about speech style, accent and show.", "labels": [], "entities": []}, {"text": "We then try to leverage these 3 types of information at training time through multi-task learning.", "labels": [], "entities": []}, {"text": "Our experiments show that this allows to train slightly more efficient ASR performance prediction systems thatin addition -simultaneously tag the analyzed utterances according to their speech style, accent and broadcast program origin.", "labels": [], "entities": [{"text": "ASR performance prediction", "start_pos": 71, "end_pos": 97, "type": "TASK", "confidence": 0.905104915301005}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "In section 2, we present a brief overview of related works and present our ASR performance prediction system in section 3.", "labels": [], "entities": [{"text": "ASR performance prediction", "start_pos": 75, "end_pos": 101, "type": "TASK", "confidence": 0.877861479918162}]}, {"text": "Then, we detail our methodology to evaluate learned representations in section 4.", "labels": [], "entities": []}, {"text": "Our multi-task learning experiments for ASR performance prediction are presented in section 5.", "labels": [], "entities": [{"text": "ASR performance prediction", "start_pos": 40, "end_pos": 66, "type": "TASK", "confidence": 0.9071049888928732}]}, {"text": "Finally, section 6 concludes this work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Distribution of our utterances between  non spontaneous and spontaneous styles, native  and non native accents", "labels": [], "entities": []}, {"text": " Table 2: Number of utterances for each broadcast  program", "labels": [], "entities": []}, {"text": " Table 3: Description of our balanced data set for  each category", "labels": [], "entities": []}, {"text": " Table 5: Evaluation of ASR performance prediction with multi-tasks models (DEV ||T EST ) computed  with MAE and Kendall -secondary classification tasks accuracy is also reported", "labels": [], "entities": [{"text": "ASR performance prediction", "start_pos": 24, "end_pos": 50, "type": "TASK", "confidence": 0.8929467995961508}, {"text": "T EST )", "start_pos": 82, "end_pos": 89, "type": "METRIC", "confidence": 0.9368635416030884}, {"text": "MAE", "start_pos": 105, "end_pos": 108, "type": "METRIC", "confidence": 0.9862276911735535}, {"text": "accuracy", "start_pos": 153, "end_pos": 161, "type": "METRIC", "confidence": 0.9519574642181396}]}]}