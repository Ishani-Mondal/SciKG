{"title": [{"text": "Data Augmentation for Neural Online Chat Response Selection", "labels": [], "entities": [{"text": "Data Augmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6642488390207291}, {"text": "Neural Online Chat Response Selection", "start_pos": 22, "end_pos": 59, "type": "TASK", "confidence": 0.8095308542251587}]}], "abstractContent": [{"text": "Data augmentation seeks to manipulate the available data for training to improve the generalization ability of models.", "labels": [], "entities": [{"text": "Data augmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7066406905651093}]}, {"text": "We investigate two data augmentation proxies, permutation and flipping, for neural dialog response selection task on various models over multiple datasets, including both Chinese and English languages.", "labels": [], "entities": [{"text": "neural dialog response selection", "start_pos": 76, "end_pos": 108, "type": "TASK", "confidence": 0.5900525152683258}]}, {"text": "Different from standard data augmentation techniques, our method combines the original and synthesized data for prediction.", "labels": [], "entities": []}, {"text": "Empirical results show that our approach can gain 1 to 3 recall-at-1 points over baseline models in both full-scale and small-scale settings .", "labels": [], "entities": [{"text": "recall-at-1", "start_pos": 57, "end_pos": 68, "type": "METRIC", "confidence": 0.9986087679862976}]}], "introductionContent": [{"text": "Building machines that are capable of conversing like humans is one of the primary goals of artificial intelligence.", "labels": [], "entities": []}, {"text": "Extensive manual labor is typically required by traditional rule-based systems, limiting the scalability of such systems across multiple domains.", "labels": [], "entities": []}, {"text": "With the success of machine learning, the quest of building data-driven dialog systems has come into focus over the past few years ().", "labels": [], "entities": []}, {"text": "Existing approaches in this area can be categorized into generation-based methods and retrieval-based methods.", "labels": [], "entities": []}, {"text": "While generation-based methods are still far from reliably generating informative responses, retrieval-based methods have the advantage of fluency and groundedness, since they select responses from existing data.", "labels": [], "entities": []}, {"text": "We concentrate on retrieval-based methods in this paper, though we believe the proposed techniques could also improve generation-based models.", "labels": [], "entities": []}, {"text": "While current state-of-the-art results for dialog models are achieved by deep learning approaches, the performance of neural models largely depends on the amount of training data.", "labels": [], "entities": []}, {"text": "However, acquiring conversational data can be difficult at times.", "labels": [], "entities": []}, {"text": "On the other hand, even with thousands of data points, it is unclear whether these models can optimally benefit from them.", "labels": [], "entities": []}, {"text": "Therefore, data augmentation and its efficient use becomes an important problem.", "labels": [], "entities": [{"text": "data augmentation", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.8357824087142944}]}, {"text": "Our main contribution is that we investigated new ways to manipulate chat data and neural model architectures to improve performance.", "labels": [], "entities": []}, {"text": "To our knowledge, we are the first to evaluate data augmentation on different types of neural conversation models over multiple domains and languages.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 6: Numbers on recall-at-1. Best results for each dataset and each model are highlighted.", "labels": [], "entities": [{"text": "recall-at-1", "start_pos": 21, "end_pos": 32, "type": "METRIC", "confidence": 0.9976740479469299}]}]}