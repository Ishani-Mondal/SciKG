{"title": [{"text": "Computationally Constructed Concepts: A Machine Learning Approach to Metaphor Interpretation Using Usage-Based Construction Grammatical Cues", "labels": [], "entities": []}], "abstractContent": [{"text": "The current study seeks to implement a deep learning classification algorithm using argument-structure level representation of metaphoric constructions, for the identification of source domain mappings in metaphoric utterances.", "labels": [], "entities": [{"text": "deep learning classification", "start_pos": 39, "end_pos": 67, "type": "TASK", "confidence": 0.6939016580581665}, {"text": "identification of source domain mappings in metaphoric utterances", "start_pos": 161, "end_pos": 226, "type": "TASK", "confidence": 0.7621477618813515}]}, {"text": "It thus builds on previous work in computational metaphor interpretation (Mohler et al.", "labels": [], "entities": [{"text": "computational metaphor interpretation", "start_pos": 35, "end_pos": 72, "type": "TASK", "confidence": 0.7554269134998322}]}, {"text": "2014; Shutova 2010; Bolle-gala & Shutova 2013; Hong 2016; Su et al.", "labels": [], "entities": []}, {"text": "2017) while implementing a theoretical framework based off of work in the interface of metaphor and construction grammar (Sullivan 2006, 2007, 2013).", "labels": [], "entities": []}, {"text": "The results indicate that it is possible to achieve an accuracy of approximately 80.4% using the proposed method, combining construction grammatical features with a simple deep learning NN.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9994250535964966}]}, {"text": "I attribute this increase inaccuracy to the use of con-structional cues, extracted from the raw text of metaphoric instances.", "labels": [], "entities": []}], "introductionContent": [{"text": "Lakoff's theory of conceptual metaphor has been highly influential in cognitive linguistic research since its initial publication.", "labels": [], "entities": [{"text": "conceptual metaphor", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.7677492499351501}]}, {"text": "Conceptual metaphors represent finegrained mappings of abstract concepts like \"love\" to more concrete, tangible phenomena, like \"journeys\" which have material and culturally salient attributes like a PATH, various LANDMARKS, and a THEME which undergoes movement from a SOURCE to a GOAL.", "labels": [], "entities": [{"text": "PATH", "start_pos": 200, "end_pos": 204, "type": "METRIC", "confidence": 0.9104471802711487}, {"text": "THEME", "start_pos": 231, "end_pos": 236, "type": "METRIC", "confidence": 0.6634092330932617}, {"text": "GOAL", "start_pos": 281, "end_pos": 285, "type": "METRIC", "confidence": 0.8918485641479492}]}, {"text": "These tangible phenomena then serve as the basis for models from which speakers can reason about abstract ideas in a culturally transmissible manner.", "labels": [], "entities": []}, {"text": "For example, consider the following metaphoric mappings for the metaphor LOVE IS MAGIC, as shown in.", "labels": [], "entities": [{"text": "LOVE IS MAGIC", "start_pos": 73, "end_pos": 86, "type": "METRIC", "confidence": 0.7548908392588297}]}, {"text": "To date, while automatic metaphor detection has been explored in some length, computational metaphor interpretation is still relatively new, and a growing number of researchers are beginning to explore the topic in greater depth.", "labels": [], "entities": [{"text": "automatic metaphor detection", "start_pos": 15, "end_pos": 43, "type": "TASK", "confidence": 0.682797392209371}, {"text": "computational metaphor interpretation", "start_pos": 78, "end_pos": 115, "type": "TASK", "confidence": 0.7349827686945597}]}, {"text": "Recently, work by the team behind Berkeley's MetaNet has shown that a constructional and frame-semantic ontology can be used to accurately identify metaphoric utterances and generate possible source domain mappings, though at the cost of requiring a large database of metaphoric exemplars (.", "labels": [], "entities": []}, {"text": "Other approaches have included developing literal paraphrases of metaphoric utterances, and, as an ancestor to the current study, clustering thematic co-occurents-the AGENT, PATIENT, and ATTRIBUTE of the metaphoric sentence-which allowed researchers to predict a possible source domain label-think: \"The bill blocked the way forward\", where for the word \"bill\" the system predicted that it mapped to a \"PHYSICAL OB-JECT\" role in the source domain).", "labels": [], "entities": [{"text": "AGENT", "start_pos": 167, "end_pos": 172, "type": "METRIC", "confidence": 0.9273359775543213}, {"text": "PATIENT", "start_pos": 174, "end_pos": 181, "type": "METRIC", "confidence": 0.9437366724014282}, {"text": "ATTRIBUTE", "start_pos": 187, "end_pos": 196, "type": "METRIC", "confidence": 0.9965813755989075}]}], "datasetContent": [{"text": "The DNN architecture as described accurately predicted the source domain label from the LCC  dataset 80.4% of the time, with a testing loss value of 1.51.", "labels": [], "entities": [{"text": "LCC  dataset", "start_pos": 88, "end_pos": 100, "type": "DATASET", "confidence": 0.9114276766777039}]}, {"text": "I compared the output of the feedforward network to a similar DNN build without the interactions from (essentially, only using the extracted argument structure as seen in).", "labels": [], "entities": []}, {"text": "I then also compared the DNN architecture with the interactions in, to an LSTM neural network without those same constructional features.", "labels": [], "entities": []}, {"text": "The results for the highest and lowest accuracy in a set of five test runs for each of these networks are compared in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9978949427604675}]}], "tableCaptions": []}