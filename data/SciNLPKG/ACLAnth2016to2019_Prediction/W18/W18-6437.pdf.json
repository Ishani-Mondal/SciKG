{"title": [{"text": "The Word Sense Disambiguation Test Suite at WMT18", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.6557018160820007}, {"text": "WMT18", "start_pos": 44, "end_pos": 49, "type": "DATASET", "confidence": 0.8340975046157837}]}], "abstractContent": [{"text": "We present a task to measure an MT system's capability to translate ambiguous words with their correct sense according to the given context.", "labels": [], "entities": [{"text": "MT", "start_pos": 32, "end_pos": 34, "type": "TASK", "confidence": 0.9835970997810364}]}, {"text": "The task is based on the German-English Word Sense Disambiguation (WSD) test set ContraWSD (Rios Gonzales et al., 2017), but it has been filtered to reduce noise, and the evaluation has been adapted to assess MT output directly rather than scoring existing translations.", "labels": [], "entities": [{"text": "German-English Word Sense Disambiguation (WSD) test set ContraWSD (Rios Gonzales et al., 2017)", "start_pos": 25, "end_pos": 119, "type": "DATASET", "confidence": 0.7922689053747389}, {"text": "MT", "start_pos": 209, "end_pos": 211, "type": "TASK", "confidence": 0.9831719398498535}]}, {"text": "We evaluate all German-English submissions to the WMT'18 shared translation task, plus a number of submissions from previous years, and find that performance on the task has markedly improved compared to the 2016 WMT submissions (81%\u219293% accuracy on the WSD task).", "labels": [], "entities": [{"text": "WMT'18 shared translation task", "start_pos": 50, "end_pos": 80, "type": "TASK", "confidence": 0.7718012928962708}, {"text": "accuracy", "start_pos": 238, "end_pos": 246, "type": "METRIC", "confidence": 0.9970468878746033}]}, {"text": "We also find that the unsupervised submissions to the task have a low WSD capability, and predominantly translate ambiguous source words with the same sense.", "labels": [], "entities": []}], "introductionContent": [{"text": "Ambiguous words are often difficult to translate automatically, since the MT system has to decide which sense is correct in the given context.", "labels": [], "entities": [{"text": "MT", "start_pos": 74, "end_pos": 76, "type": "TASK", "confidence": 0.9394824504852295}]}, {"text": "Errors in lexical choice can result in bad or even incomprehensible translations.", "labels": [], "entities": []}, {"text": "However, documentlevel metrics, such as BLEU ( are not fine-grained enough to assess this type of error.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.9969691634178162}]}, {"text": "Early evaluations have shown that neural machine translation (NMT) produces translations that are substantially more fluent, i.e. more grammatical and natural, than the previously dominant phrase-based/syntax-based statistical models, but results are more mixed when comparing adequacy, the semantic faithfulness of the translation to the original (.", "labels": [], "entities": [{"text": "neural machine translation (NMT)", "start_pos": 34, "end_pos": 66, "type": "TASK", "confidence": 0.8338875075181326}]}, {"text": "For example, in the fine-grained human evaluation by, mistranslations were the most frequent error category for the NMT system they evaluated, whereas fluency errors dominated in phrase-based machine translation.", "labels": [], "entities": [{"text": "phrase-based machine translation", "start_pos": 179, "end_pos": 211, "type": "TASK", "confidence": 0.628580222527186}]}, {"text": "Our aim is to quantify one aspect of adequacy, word sense disambiguation (WSD), in a reproducible and semi-automatic way, to track progress overtime and compare different types of systems in this respect.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 47, "end_pos": 78, "type": "TASK", "confidence": 0.6843136499325434}]}, {"text": "We present a German\u2192English test set to semiautomatically assess an MT systems performance on word sense disambiguation.", "labels": [], "entities": [{"text": "MT", "start_pos": 68, "end_pos": 70, "type": "TASK", "confidence": 0.9835272431373596}, {"text": "word sense disambiguation", "start_pos": 94, "end_pos": 119, "type": "TASK", "confidence": 0.6991065045197805}]}, {"text": "The test set is based on ContraWSD, but has been further filtered to reduce noise, and we use a different evaluation protocol.", "labels": [], "entities": [{"text": "ContraWSD", "start_pos": 25, "end_pos": 34, "type": "DATASET", "confidence": 0.8024245500564575}]}, {"text": "Instead of scoring a set of translations and measuring whether the reference translation is scored highest, we base the evaluation on the 1-best translation output to make the evaluation applicable to black-box systems.", "labels": [], "entities": []}, {"text": "We report results on all German\u2192English submissions to the WMT 2018 shared translation task (, plus a number of baseline systems from previous years.", "labels": [], "entities": [{"text": "WMT 2018 shared translation task", "start_pos": 59, "end_pos": 91, "type": "TASK", "confidence": 0.7208560109138489}]}], "datasetContent": [{"text": "The large majority of translation outputs could be categorized as corrector wrong automatically.", "labels": [], "entities": []}, {"text": "For the remaining approximately 5%, we manually assigned a label.", "labels": [], "entities": []}, {"text": "Overall, around 25% of these were labelled as correct.", "labels": [], "entities": []}, {"text": "source Im Allgemeinen l\u00e4sst sich deshalb mit Recht behaupten, dass -mit der richtigen Beratung und Sorgfalt -Hedge-Fund-Anlagen nicht zwangsl\u00e4ufig risikoreicher sind als traditionelle Anlagen.", "labels": [], "entities": []}, {"text": "reference It is therefore fair to say that properly advised hedge fund investments are, generally speaking, not necessarily riskier than traditional investments.", "labels": [], "entities": []}, {"text": "MT translation In general, therefore, it is fair to say that, with the right advice and care, hedge fund assets are not necessarily more risky than traditional plants. with an example from one of the baseline systems, where the ambiguous word Anlage occurs twice, both times in the financial sense.", "labels": [], "entities": [{"text": "MT translation", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.566545844078064}, {"text": "Anlage", "start_pos": 243, "end_pos": 249, "type": "METRIC", "confidence": 0.9797244071960449}]}, {"text": "The MT system translates the first form correctly, but the second with one of its other meanings, plant.", "labels": [], "entities": [{"text": "MT", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.7162086963653564}]}, {"text": "Case 4 can indicate that the ambiguous source word was translated into a variant not covered by our automatic patterns, or left untranslated.", "labels": [], "entities": []}, {"text": "8 Manual assessment by the main author is used to distinguish between the two.", "labels": [], "entities": []}, {"text": "We present results for all submissions to the WMT'18 shared translation task for German\u2192English.", "labels": [], "entities": [{"text": "WMT'18 shared translation task", "start_pos": 46, "end_pos": 76, "type": "TASK", "confidence": 0.7389610111713409}]}, {"text": "In addition, we include several baseline systems in our evaluation to track performance overtime.", "labels": [], "entities": []}, {"text": "We report results for Edinburgh's WMT'16 and WMT'17 submitted neural systems for German\u2192English ( , which were ranked first in 2016, and tied first in 2017.", "labels": [], "entities": [{"text": "Edinburgh's WMT'16", "start_pos": 22, "end_pos": 40, "type": "DATASET", "confidence": 0.8550165692965189}, {"text": "WMT'17", "start_pos": 45, "end_pos": 51, "type": "DATASET", "confidence": 0.8592851758003235}]}, {"text": "We also include Edinburgh's WMT'16 syntax-based system (, ranked tied second in 2016, to compare the now dominant neural systems to a more traditional SMT system.", "labels": [], "entities": [{"text": "Edinburgh's WMT'16 syntax-based system", "start_pos": 16, "end_pos": 54, "type": "DATASET", "confidence": 0.8550082802772522}, {"text": "SMT", "start_pos": 151, "end_pos": 154, "type": "TASK", "confidence": 0.9815235733985901}]}, {"text": "We report the WSD accuracy for each system, in two variants: automatic and full.", "labels": [], "entities": [{"text": "WSD", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.7642282843589783}, {"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.8982449173927307}]}, {"text": "For automatic accuracy only case 1 is considered correct, and cases 2-4 are considered wrong.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9046120047569275}]}, {"text": "Full accuracy considers some cases 3 and 4 (where both a correct and an incorrect translation, or none of the listed translations, are found) correct, if they were found to be correct upon manual inspection.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 5, "end_pos": 13, "type": "METRIC", "confidence": 0.9991756081581116}]}, {"text": "We also report BLEU scores on newstest2018, and on the WSD test suite, for comparison.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 15, "end_pos": 19, "type": "METRIC", "confidence": 0.9994470477104187}, {"text": "newstest2018", "start_pos": 30, "end_pos": 42, "type": "DATASET", "confidence": 0.9839015603065491}, {"text": "WSD test suite", "start_pos": 55, "end_pos": 69, "type": "DATASET", "confidence": 0.9330317378044128}]}], "tableCaptions": [{"text": " Table 3: Results on WSD test suite. WSD accuracy before and after manual inspection, and BLEU on  newstest2018, and on references from WSD test suite.", "labels": [], "entities": [{"text": "WSD test suite", "start_pos": 21, "end_pos": 35, "type": "DATASET", "confidence": 0.9464648763338724}, {"text": "WSD", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.6077382564544678}, {"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9271985292434692}, {"text": "BLEU", "start_pos": 90, "end_pos": 94, "type": "METRIC", "confidence": 0.9998243451118469}, {"text": "newstest2018", "start_pos": 99, "end_pos": 111, "type": "DATASET", "confidence": 0.9543425440788269}, {"text": "WSD test suite", "start_pos": 136, "end_pos": 150, "type": "DATASET", "confidence": 0.9622510671615601}]}, {"text": " Table 4: Proportion of ambiguous words trans- lated with the wrong sense, or left untranslated (in  %).", "labels": [], "entities": []}, {"text": " Table 5: Results on WSD test suite, ignoring sen- tences from WMT dev/test data. WSD accuracy  before and after manual inspection.", "labels": [], "entities": [{"text": "WSD test suite", "start_pos": 21, "end_pos": 35, "type": "DATASET", "confidence": 0.8032199243704478}, {"text": "WMT dev/test data", "start_pos": 63, "end_pos": 80, "type": "DATASET", "confidence": 0.8370995402336121}, {"text": "WSD", "start_pos": 82, "end_pos": 85, "type": "TASK", "confidence": 0.6626625657081604}, {"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9746522903442383}]}]}