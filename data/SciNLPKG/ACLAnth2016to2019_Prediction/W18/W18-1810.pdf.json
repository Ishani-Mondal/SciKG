{"title": [{"text": "An Evaluation of Two Vocabulary Reduction Methods for Neural Machine Translation", "labels": [], "entities": [{"text": "Neural Machine Translation", "start_pos": 54, "end_pos": 80, "type": "TASK", "confidence": 0.7755088210105896}]}], "abstractContent": [{"text": "Neural machine translation (NMT) models are conventionally trained with fixed-size vocabularies to control the computational complexity and the quality of the learned word representations.", "labels": [], "entities": [{"text": "Neural machine translation (NMT)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8208509087562561}]}, {"text": "This, however, limits the accuracy and the generalization capability of the models, especially for morphologically-rich languages, which usually have very sparse vocabularies containing rare inflected or derivated word forms.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9980325102806091}]}, {"text": "Some studies tried to overcome this problem by segmenting words into subword level representations and modeling translation at this level.", "labels": [], "entities": []}, {"text": "However, recent findings have shown that if these methods interrupt the word structure during segmentation, they might cause semantic or syntactic losses and lead to generating inaccurate translations.", "labels": [], "entities": []}, {"text": "In order to investigate this phenomenon, we present an extensive evaluation of two unsupervised vocabulary reduction methods in NMT.", "labels": [], "entities": [{"text": "vocabulary reduction", "start_pos": 96, "end_pos": 116, "type": "TASK", "confidence": 0.7151318192481995}]}, {"text": "The first is the well-known byte-pair-encoding (BPE), a statistical subword segmentation method, whereas the second is linguistically-motivated vocabulary reduction (LMVR), a segmentation method which also considers morphological properties of subwords.", "labels": [], "entities": [{"text": "statistical subword segmentation", "start_pos": 56, "end_pos": 88, "type": "TASK", "confidence": 0.696397582689921}, {"text": "vocabulary reduction", "start_pos": 144, "end_pos": 164, "type": "TASK", "confidence": 0.7147301286458969}]}, {"text": "We compare both approaches on ten translation directions involving English and five other languages (Arabic, Czech, German, Ital-ian and Turkish), each representing a distinct language family and morphological typology.", "labels": [], "entities": []}, {"text": "LMVR obtains significantly better performance inmost languages, showing gains proportional to the sparseness of the vocabulary and the morphological complexity of the tested language.", "labels": [], "entities": []}], "introductionContent": [{"text": "Neural machine translation (NMT) has provided significant improvements to the state-of-theart in machine translation (.", "labels": [], "entities": [{"text": "Neural machine translation (NMT)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7829781274000803}, {"text": "machine translation", "start_pos": 97, "end_pos": 116, "type": "TASK", "confidence": 0.7576914727687836}]}, {"text": "However, it has also brought quite a few practical issues.", "labels": [], "entities": []}, {"text": "Avery important one of these is the low accuracy in translating rare words, caused by two of the main properties of the model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9993751645088196}, {"text": "translating rare words", "start_pos": 52, "end_pos": 74, "type": "TASK", "confidence": 0.9115832448005676}]}, {"text": "The first is related to the requirement of observing many examples of a word until its internal representation becomes accurate, and the second is due to the difficulty of handling large vocabularies, as this has an impact on the computational complexity of the model.", "labels": [], "entities": []}, {"text": "Current implementations of NMT models require long training time and large memory space due to the high number of parameters to optimize.", "labels": [], "entities": []}, {"text": "Hence, even with the most advanced machinery, deploying networks that can learn reliable representations for all words observed in the training corpus becomes practically impossible.", "labels": [], "entities": []}, {"text": "In order to control the model complexity and the quality of the word representations, a straightforward approach is to fix the vocabularies to a maximum size, e.g. 100,000 lexical units, prior to training.", "labels": [], "entities": []}, {"text": "Clearly, a word can only be translated if an exact match of it is found in the vocabulary.", "labels": [], "entities": []}, {"text": "This requirement leads to critical restrictions in translating morphologically-rich languages, where the word vocabulary tends to be very large and sparse.", "labels": [], "entities": [{"text": "translating morphologically-rich languages", "start_pos": 51, "end_pos": 93, "type": "TASK", "confidence": 0.8974920511245728}]}, {"text": "For example, in our case study, despite the relatively small size of our training corpora, the size of the source vocabulary found in the Turkish-English training corpus is around 170,000, i.e. much larger than the maximum size that is generally used.", "labels": [], "entities": []}, {"text": "Some studies have tried to overcome this problem by redefining the model vocabulary in terms of interior orthographic units compounding the words.", "labels": [], "entities": []}, {"text": "These units could be individual characters (, hybrid word/character units, or subwords (, i.e. character sequences segmented according to their frequency in the training corpus.", "labels": [], "entities": []}, {"text": "The prominent approach used today is to treat these subwords as individual lexical units.", "labels": [], "entities": []}, {"text": "Hence, NMT is learned as a bilingual mapping between subword units of two languages.", "labels": [], "entities": []}, {"text": "In addition to providing anew perspective to modeling translation at the sublexical level, these approaches have alleviated the out-of-vocabulary problem in NMT.", "labels": [], "entities": []}, {"text": "The sore point of these methods, however, is that they disregard any linguistic notion during segmentation.", "labels": [], "entities": []}, {"text": "Many studies have shown that using subword segmentation methods which do not preserve the morpheme boundaries inside words may lead to loss of information related to the semantic or syntactic properties of words and generate inaccurate translations (.", "labels": [], "entities": [{"text": "subword segmentation", "start_pos": 35, "end_pos": 55, "type": "TASK", "confidence": 0.7467725574970245}]}, {"text": "A more linguistically motivated solution was recently proposed by, which segments words into subwords by estimating their likeliness of being morphemes and their morphological categories.", "labels": [], "entities": []}, {"text": "This approach provided significant improvements for translation of Turkish, an agglutinative language with a very sparse vocabulary.", "labels": [], "entities": [{"text": "translation of Turkish", "start_pos": 52, "end_pos": 74, "type": "TASK", "confidence": 0.8840507666269938}]}, {"text": "In this paper, we present a comparative study on two unsupervised word segmentation methods: Byte-Pair Encoding (BPE) () and the Linguistically-Motivated Vocabulary Reduction (LMVR) method by for NMT.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 66, "end_pos": 83, "type": "TASK", "confidence": 0.7396536767482758}]}, {"text": "Our analysis aims at understanding the important factors related to the statistical and formal characteristics of lexical units, mainly induced by morphology, and how they affect the translation quality.", "labels": [], "entities": []}, {"text": "For this purpose, we setup an evaluation benchmark pairing English with five inflected languages: Arabic, Czech, German, Italian and Turkish, where each language represents a language family with distinct morphological characteristics.", "labels": [], "entities": []}, {"text": "The experimental results show that the translation quality obtained using LMVR) in three of the languages (Arabic, Czech and Turkish) is significantly better than that with BPE ().", "labels": [], "entities": [{"text": "translation", "start_pos": 39, "end_pos": 50, "type": "TASK", "confidence": 0.932992696762085}]}, {"text": "All of these languages share the common feature of having a high level of sparseness or a morphology with agglutinating or concatenating properties.", "labels": [], "entities": []}, {"text": "For the remaining two languages with fusional characteristics and lower sparseness: German and Italian, the two segmentation methods yield comparable performance.", "labels": [], "entities": []}, {"text": "In general, both word segmentation methods outperform the simple frequency-based vocabulary reduction method proposed by.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 17, "end_pos": 34, "type": "TASK", "confidence": 0.7349445819854736}, {"text": "vocabulary reduction", "start_pos": 81, "end_pos": 101, "type": "TASK", "confidence": 0.7093071043491364}]}, {"text": "Our study suggests that considering the morphological characteristics of the chosen language pair is essential in order to choose the most appropriate subword segmentation approach in NMT.", "labels": [], "entities": [{"text": "subword segmentation", "start_pos": 151, "end_pos": 171, "type": "TASK", "confidence": 0.7740731835365295}]}], "datasetContent": [{"text": "In order to evaluate different subword segmentation methods, we setup a common benchmark to observe the effect of each method on languages with different statistical properties.", "labels": [], "entities": [{"text": "subword segmentation", "start_pos": 31, "end_pos": 51, "type": "TASK", "confidence": 0.7823345959186554}]}, {"text": "Our benchmark couples English (either as source or target) with five languages: Arabic, Czech, German, Italian and Turkish.", "labels": [], "entities": []}, {"text": "Thus, each language pair represents different statistical properties reflected by the level of agglutination or fusion observed in their formal morphology.", "labels": [], "entities": []}, {"text": "We perform NMT by keeping the segmentation on the English side fixed and applying different segmentation approaches to the other languages.", "labels": [], "entities": [{"text": "NMT", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.8080337643623352}]}, {"text": "This aids us in avoiding a combinatorial explosion in the number of experiments, while ensuring the results between each language are comparable.", "labels": [], "entities": []}, {"text": "We later vary the segmentation method applied to the English side to investigate its effects on both sides of translation.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 18, "end_pos": 30, "type": "TASK", "confidence": 0.9621151685714722}]}, {"text": "We limit these experiments only to the English-Italian and English-Turkish pairs, as they represent two extreme cases in our setting, i.e. from low to high morphological complexity.", "labels": [], "entities": []}, {"text": "All experiments consider each tested language both at the source and the target side of translations.", "labels": [], "entities": []}, {"text": "The two subword segmentation methods, LMVR and BPE, are also compared with the frequency-based vocabulary pruning method suggested by, and described at the end of Section 2, which is henceforth referred to as Word method.", "labels": [], "entities": [{"text": "subword segmentation", "start_pos": 8, "end_pos": 28, "type": "TASK", "confidence": 0.7694116532802582}, {"text": "BPE", "start_pos": 47, "end_pos": 50, "type": "METRIC", "confidence": 0.922906756401062}]}], "tableCaptions": [{"text": " Table 2: Above: Training sets. Below: Development and Testing Sets. All data set are official  evaluation sets from IWSLT. (M: Million, K: Thousand.)", "labels": [], "entities": [{"text": "IWSLT", "start_pos": 117, "end_pos": 122, "type": "DATASET", "confidence": 0.967409074306488}]}]}