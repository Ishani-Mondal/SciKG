{"title": [{"text": "Representation of Word Meaning in the Intermediate Projection Layer of a Neural Language Model", "labels": [], "entities": [{"text": "Representation of Word Meaning", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8853605687618256}]}], "abstractContent": [{"text": "Performance in language modelling has been significantly improved by training recurrent neural networks on large corpora.", "labels": [], "entities": [{"text": "language modelling", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.843393087387085}]}, {"text": "This progress has come at the cost of interpretabil-ity and an understanding of how these archi-tectures function, making principled development of better language models more difficult.", "labels": [], "entities": []}, {"text": "We look inside a state-of-the-art neural language model to analyse how this model represents high-level lexico-semantic information.", "labels": [], "entities": []}, {"text": "In particular, we investigate how the model represents words by extracting activation patterns where they occur in the text, and compare these representations directly to human semantic knowledge.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}