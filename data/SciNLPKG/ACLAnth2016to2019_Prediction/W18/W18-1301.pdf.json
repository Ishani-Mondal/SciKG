{"title": [{"text": "Using Hedge Detection to Improve Committed Belief Tagging", "labels": [], "entities": [{"text": "Hedge Detection", "start_pos": 6, "end_pos": 21, "type": "TASK", "confidence": 0.7960897982120514}, {"text": "Improve Committed Belief Tagging", "start_pos": 25, "end_pos": 57, "type": "TASK", "confidence": 0.8210868686437607}]}], "abstractContent": [{"text": "We describe a novel method for identifying hedge terms using a set of manually constructed rules.", "labels": [], "entities": []}, {"text": "We present experiments adding hedge features to a committed belief system to improve classification.", "labels": [], "entities": []}, {"text": "We compare performance of this system (a) without hedging features , (b) with dictionary-based features, and (c) with rule-based features.", "labels": [], "entities": []}, {"text": "We find that using hedge features improves performance of the committed belief system, particularly in identifying instances of non-committed belief and reported belief.", "labels": [], "entities": []}], "introductionContent": [{"text": "Hedging refers to the use of words, sounds, or constructions that add ambiguity or uncertainty to spoken or written language.", "labels": [], "entities": [{"text": "Hedging refers to the use of words, sounds, or constructions that add ambiguity or uncertainty to spoken or written language", "start_pos": 0, "end_pos": 124, "type": "Description", "confidence": 0.833066696470434}]}, {"text": "Hedges are often used by speakers to indicate lack of commitment to what they say; so, the ability to classify words and phrases as hedges is very relevant to the task of committed belief tagging-that is, determining the level of commitment a speaker has toward the belief expressed in a given proposition.", "labels": [], "entities": [{"text": "committed belief tagging-that", "start_pos": 171, "end_pos": 200, "type": "TASK", "confidence": 0.7170372207959493}]}, {"text": "A major challenge in identifying hedges is that many hedge words and phrases are ambiguous.", "labels": [], "entities": []}, {"text": "For example, In (1), around is used as a hedge, but not in (2).", "labels": [], "entities": []}, {"text": "(1) She weighs around a hundred pounds.", "labels": [], "entities": []}, {"text": "(2) Suddenly she turned around.", "labels": [], "entities": []}, {"text": "Currently there are few corpora annotated for hedging, and these are in a limited number of genres.", "labels": [], "entities": [{"text": "hedging", "start_pos": 46, "end_pos": 53, "type": "TASK", "confidence": 0.9756267070770264}]}, {"text": "In particular, there is currently no corpus of informal language annotated with hedge behavior.", "labels": [], "entities": []}, {"text": "Acquiring expert annotations on text in other genres can be time consuming and maybe cost prohibitive, which is an impediment to exploring how hedging can help with applications based on text and other genres.", "labels": [], "entities": []}, {"text": "In this paper, the application we focus on is committed belief tagging on a corpus of forum posts.", "labels": [], "entities": [{"text": "belief tagging", "start_pos": 56, "end_pos": 70, "type": "TASK", "confidence": 0.6857737600803375}]}, {"text": "Since we currently lack a labeled hedging corpus in this genre, we introduce anew method for disambiguating potential hedges using a set of manually-constructed rules.", "labels": [], "entities": []}, {"text": "We then show that detecting hedges using this method improves the performance of a committed belief tagger.", "labels": [], "entities": []}, {"text": "In Section 2, we discuss related work.", "labels": [], "entities": []}, {"text": "In Section 3, we describe how we identify hedges.", "labels": [], "entities": []}, {"text": "We describe the committed belief tagger used for our experiments in Section 4.", "labels": [], "entities": []}, {"text": "In Section 5, we describe our experiments and our results.", "labels": [], "entities": []}, {"text": "We conclude and discuss future work in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "All the experiments reported below use 5-fold cross validation on the 2014 Darpa DEFT Committed Belief Corpus (Release No. LDC2014E55).", "labels": [], "entities": [{"text": "2014 Darpa DEFT Committed Belief Corpus (Release No. LDC2014E55)", "start_pos": 70, "end_pos": 134, "type": "DATASET", "confidence": 0.888910485939546}]}, {"text": "The documents in this corpus are from English discussion forum data.", "labels": [], "entities": [{"text": "English discussion forum data", "start_pos": 38, "end_pos": 67, "type": "DATASET", "confidence": 0.6267900392413139}]}, {"text": "We compare the performance of the system using (a) no hedge features (b) hedge features obtained using the dictionary-based tagger, and (c) hedge features obtained using the rule-based tagger.", "labels": [], "entities": []}, {"text": "Note that our baseline results differ slightly from the System C results presented in because the training/evaluation datasets used are different.", "labels": [], "entities": []}, {"text": "Additionally, our baseline uses no hedge features while System C uses simple word-based hedge features based on an earlier version of our hedging dictionary.", "labels": [], "entities": []}, {"text": "As we might expect, hedge features are most significant in detecting instances of reported belief and non-committed belief.", "labels": [], "entities": []}, {"text": "Since these represent only a small portion of the full corpus, the effect on the overall performance is not large.", "labels": [], "entities": []}, {"text": "However it is still significant.", "labels": [], "entities": []}, {"text": "Using dictionary-based hedge features, we see an increase of 1.82 in the f-measure for ROB as compared to the baseline, from 23.29 to 25.11, and an increase of 2.29 for NCB, from 23.66 to 25.95.", "labels": [], "entities": [{"text": "ROB", "start_pos": 87, "end_pos": 90, "type": "METRIC", "confidence": 0.9639761447906494}, {"text": "NCB", "start_pos": 169, "end_pos": 172, "type": "DATASET", "confidence": 0.9294977188110352}]}, {"text": "The overall f-score increases 0.43, from 67.52 to 69.95.", "labels": [], "entities": [{"text": "f-score", "start_pos": 12, "end_pos": 19, "type": "METRIC", "confidence": 0.9955434203147888}]}, {"text": "Using rulebased hedge features, the increase compared to the baseline is more significant.", "labels": [], "entities": []}, {"text": "For ROB, the f-score shows an increase of 4.14, from 23.29 to 27.43.", "labels": [], "entities": [{"text": "ROB", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9811113476753235}, {"text": "f-score", "start_pos": 13, "end_pos": 20, "type": "METRIC", "confidence": 0.9928191304206848}]}, {"text": "For NCB, the f-score increases 6.77, from 23.66 to 30.43.", "labels": [], "entities": [{"text": "NCB", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.8863467574119568}, {"text": "f-score", "start_pos": 13, "end_pos": 20, "type": "METRIC", "confidence": 0.9975835084915161}]}, {"text": "The overall increase in the f-score using the rule-based hedge features is 0.55, from 67.52 to 68.07.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Belief results using (a) no hedge detection, (b)  dictionary-based hedge detection, and (c) rule-based  hedge detection.", "labels": [], "entities": [{"text": "dictionary-based hedge detection", "start_pos": 60, "end_pos": 92, "type": "TASK", "confidence": 0.5744925538698832}, {"text": "rule-based  hedge detection", "start_pos": 102, "end_pos": 129, "type": "TASK", "confidence": 0.5907630225022634}]}]}