{"title": [{"text": "Predicting the Usefulness of Amazon Reviews Using Off-The-Shelf Argumentation Mining", "labels": [], "entities": []}], "abstractContent": [{"text": "Internet users generate content at unprecedented rates.", "labels": [], "entities": []}, {"text": "Building intelligent systems capable of discriminating useful content within this ocean of information is thus becoming a urgent need.", "labels": [], "entities": []}, {"text": "In this paper, we aim to predict the usefulness of Amazon reviews, and to do this we exploit features coming from an off-the-shelf argumentation mining system.", "labels": [], "entities": []}, {"text": "We argue that the usefulness of a review, in fact, is strictly related to its argumentative content, whereas the use of an already trained system avoids the costly need of relabeling a novel dataset.", "labels": [], "entities": []}, {"text": "Results obtained on a large publicly available corpus support this hypothesis.", "labels": [], "entities": []}], "introductionContent": [{"text": "In our digital era, reviews affect our everyday decisions.", "labels": [], "entities": []}, {"text": "More and more people resort to digital reviews before buying a good or deciding whereto eat or stay.", "labels": [], "entities": []}, {"text": "In fact, helpful reviews allow users to grasp more clearly the features of a product they are about to buy, and thus to understand whether it fits their needs.", "labels": [], "entities": []}, {"text": "The same can be said for users who want to book hotels or restaurants.", "labels": [], "entities": []}, {"text": "Companies have started to exploit the importance of reviews.", "labels": [], "entities": []}, {"text": "For example, when browsing fora specific product, we are usually presented reviews that have been judged helpful by other users.", "labels": [], "entities": []}, {"text": "Moreover, we are often given the possibility to sort reviews according to the number of people who judged them as helpful.", "labels": [], "entities": []}, {"text": "That said, a review can also be helpful for companies who want to monitor what people think about their brand.", "labels": [], "entities": []}, {"text": "Being able to identify helpful reviews has thus many important applications, both for users and for companies, and in multiple domains.", "labels": [], "entities": []}, {"text": "The automatic identification of helpful reviews is not as easy as it may seem, because the review content has to be semantically analyzed.", "labels": [], "entities": [{"text": "automatic identification of helpful reviews", "start_pos": 4, "end_pos": 47, "type": "TASK", "confidence": 0.7280374944210053}]}, {"text": "Therefore, this process is traditionally done by asking users fora judgment.", "labels": [], "entities": []}, {"text": "To overcome this issue, some approaches have been proposed.", "labels": [], "entities": []}, {"text": "One of the earliest studies) aims to rank Amazon reviews by their usefulness by training a regressor with a combination of different features extracted from text and metadata of the reviews, as well as features of the product.", "labels": [], "entities": []}, {"text": "Similar approaches employ different sets of features, for example including the reputation of reviewers too (.", "labels": [], "entities": []}, {"text": "Another significant work) builds a customer model that describes which features of an Amazon review affect its perceived usefulness, and then it uses such features to build a regression model to predict the usefulness, expressed as the percentage of the number of people who judged a review to be useful.", "labels": [], "entities": []}, {"text": "A hybrid regression model) combines text and additional features describing users (recency, frequency, monetary value) to predict the number of people who judged as useful reviews taken from Amazon and Yelp.", "labels": [], "entities": [{"text": "Yelp", "start_pos": 202, "end_pos": 206, "type": "DATASET", "confidence": 0.906348705291748}]}, {"text": "A more complete work considers both regression and classification (.", "labels": [], "entities": [{"text": "regression", "start_pos": 36, "end_pos": 46, "type": "TASK", "confidence": 0.9719879627227783}, {"text": "classification", "start_pos": 51, "end_pos": 65, "type": "TASK", "confidence": 0.9142014384269714}]}, {"text": "It proves different hypotheses, starting with expressing the usefulness of an Amazon review as a function of readability and subjectivity cues, and then converting the usefulness, expressed with a continuous value, into a binary usefulness, that is predicting if a review is useful or not useful.", "labels": [], "entities": []}, {"text": "Another recent work () presents an approach that explores an similar assumption to ours: helpful reviews are typically argumentative.", "labels": [], "entities": []}, {"text": "In fact, what we hope to read in a review is something that goes beyond plain opinions or sentiment, being rather a collection of reasons and evidence that motivate and support the overall judgment of the product or service that is reviewed.", "labels": [], "entities": []}, {"text": "These characteristics are usually cap-tured by an argumentation analysis, and could be automatically detected by an argumentation mining system ().", "labels": [], "entities": []}, {"text": "The work in () considers a set of 110 hotel reviews, it presents a complete and manual labeling of the arguments in such reviews, and it exploits such information as additional features fora machine learning classifier that predicts usefulness.", "labels": [], "entities": []}, {"text": "In this paper, instead, we investigate the possibility to predict the usefulness of Amazon reviews by using features coming from an automatic argumentation mining system, thus not directly using human-annotated arguments.", "labels": [], "entities": []}, {"text": "A preliminary experimental study conducted on a large publicly dataset (117,000 Amazon reviews) confirms that this could be really doable and a very fruitful research direction.", "labels": [], "entities": [{"text": "publicly dataset (117,000 Amazon reviews", "start_pos": 54, "end_pos": 94, "type": "DATASET", "confidence": 0.6984079480171204}]}], "datasetContent": [{"text": "To evaluate the proposed approach we use the public Amazon Reviews dataset, in particular, we worked with the so called \"5-core\" subset, that is, a subset of the data in which all users and items have at least five reviews.", "labels": [], "entities": [{"text": "Amazon Reviews dataset", "start_pos": 52, "end_pos": 74, "type": "DATASET", "confidence": 0.9214624961217245}]}, {"text": "Each element of this dataset contains a product review and metadata related to it.", "labels": [], "entities": []}, {"text": "Since we aim to predict usefulness, for each review we compute the ratio between the number of people who voted and judged that review as useful, and the total number of people who expressed a judgment about that review.", "labels": [], "entities": []}, {"text": "Then, we define useful reviews as the ones whose percentage of usefulness is equal or above 0.7 (that means that at least 70% of the people who judged a review, judged it as useful), while the remaining are considered not to be useful, and thus they represent our negative class.", "labels": [], "entities": []}, {"text": "The Amazon Review dataset is split into product categories.", "labels": [], "entities": [{"text": "Amazon Review dataset", "start_pos": 4, "end_pos": 25, "type": "DATASET", "confidence": 0.9823691248893738}]}, {"text": "For our experiments we picked three of them, chosen among those with the highest number of reviews.", "labels": [], "entities": []}, {"text": "Our choice has fallen upon the \"CDs and Vinyl\" \"Electronics\" and \"Movies and TV\" categories.", "labels": [], "entities": []}, {"text": "We further selected only the reviews having at least 75 rates, in order to assess usefulness on a reasonably large set of samples.", "labels": [], "entities": []}, {"text": "Finally, we randomly selected 39,000 reviews for each category, ending up with an almost balanced number of helpful and unhelpful reviews.", "labels": [], "entities": []}, {"text": "Our goal in executing the experiments is to predict whether a review is considered useful, by taking into account either its textual content only, or, additionally, also the argumentation mining data coming from MARGOT.", "labels": [], "entities": [{"text": "MARGOT", "start_pos": 212, "end_pos": 218, "type": "DATASET", "confidence": 0.8376985192298889}]}, {"text": "In other words, we are working in a binary classification scenario.", "labels": [], "entities": []}, {"text": "In these experiments we use a stochastic gradient descent classifier 2 with a hinge loss, which is a classic solution in binary classification tasks.", "labels": [], "entities": [{"text": "binary classification tasks", "start_pos": 121, "end_pos": 148, "type": "TASK", "confidence": 0.7339955568313599}]}, {"text": "We performed the tuning of the \u03b1 and parameters with a 5-fold cross validation over the training set, and we then used the best model to predict over the test set.", "labels": [], "entities": []}, {"text": "From the original set of 39,000 reviews, 50% of them is used as training set, and the other half as the test set.", "labels": [], "entities": []}, {"text": "Each category is treated singularly.", "labels": [], "entities": []}, {"text": "We run experiments both employing a plain Bag-of-Words model, and with TF-IDF features.", "labels": [], "entities": []}, {"text": "Both preprocessing variants perform tokenization and stemming and exclude stopwords and words that do not appear more than five times in the whole training set.", "labels": [], "entities": []}, {"text": "To regularize the different magnitude of the features, both textual features and argumentation mining features are normalized using the L2 normalization in all our experiments.", "labels": [], "entities": []}, {"text": "Textual and argumentative features are simply concatenated into a single vector.", "labels": [], "entities": []}, {"text": "The performance is measured in terms of accuracy (A), precision (P), recall (R), and F 1 , as in standard text classification applications.", "labels": [], "entities": [{"text": "accuracy (A)", "start_pos": 40, "end_pos": 52, "type": "METRIC", "confidence": 0.9291095733642578}, {"text": "precision (P)", "start_pos": 54, "end_pos": 67, "type": "METRIC", "confidence": 0.9563051760196686}, {"text": "recall (R)", "start_pos": 69, "end_pos": 79, "type": "METRIC", "confidence": 0.9684543311595917}, {"text": "F 1", "start_pos": 85, "end_pos": 88, "type": "METRIC", "confidence": 0.9905513525009155}, {"text": "text classification", "start_pos": 106, "end_pos": 125, "type": "TASK", "confidence": 0.7548195719718933}]}, {"text": "shows that, even using only the features obtained from MARGOT, thus completely ignoring the textual content of the review, the accuracy of the classifier is far above a random baseline.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 127, "end_pos": 135, "type": "METRIC", "confidence": 0.9993756413459778}]}, {"text": "Moreover, results clearly highlights how the improvement obtained by using argumentative features is consistent across all product categories, both using plain BoW and TF-IDF weighting.", "labels": [], "entities": [{"text": "BoW", "start_pos": 160, "end_pos": 163, "type": "DATASET", "confidence": 0.7262863516807556}]}, {"text": "For the \"CDs and Vinyl\"and \"Electronics\"categories We used Snowball from python nltk library.", "labels": [], "entities": [{"text": "Snowball", "start_pos": 59, "end_pos": 67, "type": "DATASET", "confidence": 0.9796178936958313}]}, {"text": "the difference between the classifier exploiting TF-IDF with MARGOT and the one using TF-IDF only is statistically significant according to a McNemar's test, with p-value < 0.01.", "labels": [], "entities": [{"text": "MARGOT", "start_pos": 61, "end_pos": 67, "type": "METRIC", "confidence": 0.5038658976554871}, {"text": "McNemar's test", "start_pos": 142, "end_pos": 156, "type": "DATASET", "confidence": 0.8085527817408243}]}, {"text": "The same holds for the BOW classifier, for the \"Electronics\"and \"Movies and TV\"categories.", "labels": [], "entities": [{"text": "BOW", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.5263468623161316}]}, {"text": "It is interesting to notice that, while the \"CDs and Vinyl\" and the \"Movies and TV\" categories have similar performance, even when using textual data only, the category \"Electronics\" results to be the most difficult to predict.", "labels": [], "entities": []}, {"text": "One plausible explanation for this is the heterogeneity of such category, that includes many different types of electronic devices.", "labels": [], "entities": []}, {"text": "The other two categories, instead, include more homogeneous products.", "labels": [], "entities": []}, {"text": "It would be very interesting to further investigate whether certain product categories result to be more suitable for argumentation studies.", "labels": [], "entities": [{"text": "argumentation", "start_pos": 118, "end_pos": 131, "type": "TASK", "confidence": 0.964046835899353}]}], "tableCaptions": [{"text": " Table 1: Performance on three Amazon categories us- ing different sets of features: Margot features (M),  Bag-of-Words (BoW), Bag-of-Words weighted by TF- IDF (TF-IDF), and combinations thereof.", "labels": [], "entities": [{"text": "Margot features (M)", "start_pos": 85, "end_pos": 104, "type": "METRIC", "confidence": 0.8771250128746033}, {"text": "Bag-of-Words (BoW)", "start_pos": 107, "end_pos": 125, "type": "METRIC", "confidence": 0.8483703434467316}]}]}