{"title": [{"text": "Rating Distributions and Bayesian Inference: Enhancing Cognitive Models of Spatial Language Use", "labels": [], "entities": []}], "abstractContent": [{"text": "We present two methods that improve the assessment of cognitive models.", "labels": [], "entities": []}, {"text": "The first method is applicable to models computing average acceptability ratings.", "labels": [], "entities": []}, {"text": "For these models, we propose an extension that simulates a full rating distribution (instead of average ratings) and allows generating individual ratings.", "labels": [], "entities": []}, {"text": "Our second method enables Bayesian inference for models generating individual data.", "labels": [], "entities": []}, {"text": "To this end, we propose to use the cross-match test (Rosenbaum, 2005) as a likelihood function.", "labels": [], "entities": []}, {"text": "We exemplarily present both methods using cogni-tive models from the domain of spatial language use.", "labels": [], "entities": []}, {"text": "For spatial language use, determining linguistic acceptability judgments of a spatial preposition fora depicted spatial relation is assumed to be a crucial process (Logan and Sadler, 1996).", "labels": [], "entities": []}, {"text": "Existing models of this process compute an average acceptability rating.", "labels": [], "entities": []}, {"text": "We extend the models and-based on existing data-show that the extended models allow extracting more information from the empirical data and yield more readily interpretable information about model successes and failures.", "labels": [], "entities": []}, {"text": "Applying Bayesian inference, we find that model performance relies lesson mechanisms of capturing geometrical aspects than on mapping the captured geometry to a rating interval.", "labels": [], "entities": []}], "introductionContent": [{"text": "Acceptability judgments are an important measure throughout linguistic research.", "labels": [], "entities": [{"text": "Acceptability", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.9649962186813354}]}, {"text": "For instance, recently proposed to use confidence ratings to assess models of artificial language learning.", "labels": [], "entities": []}, {"text": "Likewise, in research on the evaluation of spatial language given visual displays, a common experimental paradigm is to ask how well a spatial term describes a depicted situation (e.g.,.", "labels": [], "entities": [{"text": "evaluation of spatial language", "start_pos": 29, "end_pos": 59, "type": "TASK", "confidence": 0.7834460586309433}]}, {"text": "This paradigm results in individual acceptability judgments on Likert scales.", "labels": [], "entities": []}, {"text": "These rating data are the main source for assessing computational models in the spatial language domain (e.g.,).", "labels": [], "entities": []}, {"text": "In other linguistic domains, similar empirical rating data are predicted by computational models (e.g., grammaticality judgments,, or semantic plausibility judgments; see also).", "labels": [], "entities": []}, {"text": "Generally speaking, researchers consider a rating-model appropriate if it can closely account for empirical mean ratings for the given stimuli (averaged across subjects) -the closer the fit to the empirical mean data, the more appropriate the model.", "labels": [], "entities": []}, {"text": "However, the use of mean ratings instead of full rating distributions misses the opportunity to use all available empirical information for model assessment.", "labels": [], "entities": []}, {"text": "This is why we present a model extension that adds the simulation of a probability distribution overall ratings.", "labels": [], "entities": []}, {"text": "We illustrate our extension by equipping spatial language models with full empirical rating distributions.", "labels": [], "entities": []}, {"text": "The second proposal of our paper (Bayesian inference) relies on the fact that our proposed model extension enables the generation of individual ratings by sampling from the simulated probability distribution.", "labels": [], "entities": []}, {"text": "This opens up the possibility to apply Bayesian inference (e.g., to reason about the likely values of model parameters).", "labels": [], "entities": []}, {"text": "Many cognitive models lack a likelihood function that specifies how likely the empirical data are given a specific parameter set.", "labels": [], "entities": []}, {"text": "This prevents the use of Bayesian inference.", "labels": [], "entities": []}, {"text": "In this contribution, we propose the cross-match test developed by as a means for computing the likelihood for cognitive models that are able to generate individual data.", "labels": [], "entities": []}, {"text": "Again, we use a spatial language model to exemplify the application of the cross-match method.", "labels": [], "entities": []}, {"text": "The thus computed posterior distribution of the model's parameters has surprising implications for the interpretation of the model.", "labels": [], "entities": []}, {"text": "Before we come to this, we start with presenting the example models, followed by our model extension to simulate rating distributions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Example input for the cross-match  test", "labels": [], "entities": []}]}