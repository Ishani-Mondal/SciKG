{"title": [{"text": "The Data Challenge in Misinformation Detection: Source Reputation vs. Content Veracity", "labels": [], "entities": [{"text": "Misinformation Detection", "start_pos": 22, "end_pos": 46, "type": "TASK", "confidence": 0.971371203660965}]}], "abstractContent": [{"text": "Misinformation detection at the level of full news articles is a text classification problem.", "labels": [], "entities": [{"text": "Misinformation detection", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9871145486831665}, {"text": "text classification", "start_pos": 65, "end_pos": 84, "type": "TASK", "confidence": 0.740922600030899}]}, {"text": "Reliably labeled data in this domain is rare.", "labels": [], "entities": []}, {"text": "Previous work relied on news articles collected from so-called \"reputable\" and \"suspicious\" websites and labeled accordingly.", "labels": [], "entities": []}, {"text": "We leverage fact-checking websites to collect individually-labeled news articles with regard to the verac-ity of their content and use this data to test the cross-domain generalization of a classifier trained on bigger text collections but labeled according to source reputation.", "labels": [], "entities": []}, {"text": "Our results suggest that reputation-based classification is not sufficient for predicting the veracity level of the majority of news articles, and that the system performance on different test datasets depends on topic distribution.", "labels": [], "entities": [{"text": "reputation-based classification", "start_pos": 25, "end_pos": 56, "type": "TASK", "confidence": 0.624343752861023}]}, {"text": "Therefore collecting well-balanced and carefully-assessed training data is a priority for developing robust misinformation detection systems.", "labels": [], "entities": [{"text": "misinformation detection", "start_pos": 108, "end_pos": 132, "type": "TASK", "confidence": 0.8733620047569275}]}], "introductionContent": [{"text": "Automatic detection of fake from legitimate news in different formats such as headlines, tweets and full news articles has been approached in recent Natural Language Processing literature.", "labels": [], "entities": []}, {"text": "The most important challenge in automatic misinformation detection using modern NLP techniques, especially at the level of full news articles, is data.", "labels": [], "entities": [{"text": "automatic misinformation detection", "start_pos": 32, "end_pos": 66, "type": "TASK", "confidence": 0.6454465091228485}]}, {"text": "Most previous systems built to identify fake news articles rely on training data labeled with respect to the general reputation of the sources, i.e., domains/user accounts (.", "labels": [], "entities": []}, {"text": "Even though some of these studies try to identify fake news based on linguistic cues, the question is whether they learn publishers' general writing style (e.g., common writing features of a few clickbaity websites) or deceptive style (similarities among news articles that contain misinformation).", "labels": [], "entities": []}, {"text": "In this study, we collect two new datasets that include the full text of news articles and individually assigned veracity labels.", "labels": [], "entities": []}, {"text": "We then address the above question, by conducting a set of crossdomain experiments: training a text classification system on data collected in a batch manner from suspicious and reputable websites and then testing the system on news articles that have been assessed in a one-by-one fashion.", "labels": [], "entities": [{"text": "text classification", "start_pos": 95, "end_pos": 114, "type": "TASK", "confidence": 0.7010899186134338}]}, {"text": "Our experiments reveal that the generalization power of a model trained on reputation-based labeled data is not impressive on individually assessed articles.", "labels": [], "entities": []}, {"text": "Therefore, we propose to collect and verify larger collections of news articles with reliably assigned labels that would be useful for building more robust fake news detection systems.", "labels": [], "entities": [{"text": "fake news detection", "start_pos": 156, "end_pos": 175, "type": "TASK", "confidence": 0.7562089363733927}]}], "datasetContent": [{"text": "In text classification, Convolutional Neural Networks (CNNs) have been competing with the TF-IDF model, a simple but strong baseline using scored n-grams ().", "labels": [], "entities": [{"text": "text classification", "start_pos": 3, "end_pos": 22, "type": "TASK", "confidence": 0.8061284124851227}]}, {"text": "These methods have been used for fake news detection in previous work  fore, we use this model to demonstrate how a classifier trained on data labeled according to publisher's reputation would identify misinformative news articles.", "labels": [], "entities": [{"text": "fake news detection", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.6623480319976807}]}, {"text": "It is evident in the first section of, that the model performs well on similarly collected test items, i.e., Hoax, Satire, Propaganda and Trusted news articles within Rashkin et al.'s test dataset.", "labels": [], "entities": []}, {"text": "However, when the model is applied to Rubin et al.'s data, which was carefully assessed for satirical cues in each and every article, the performance drops considerably (See the second section of the.", "labels": [], "entities": []}, {"text": "Although the classifier detects more of the satirical texts in Rubin et al.'s data, the distribution of the given labels is not very different to that of legitimate texts.", "labels": [], "entities": []}, {"text": "One important feature of Rubin et al.'s data is that topics of the legitimate instances were matched and balanced with topics of the satirical instances.", "labels": [], "entities": []}, {"text": "The results here suggest that similarities captured by the classifier can be very dependent on the topics of the news articles.", "labels": [], "entities": []}, {"text": "Next we examine the same model on our collected datasets, BuzzfeedUSE and Snopes312, as test material.", "labels": [], "entities": [{"text": "BuzzfeedUSE", "start_pos": 58, "end_pos": 69, "type": "DATASET", "confidence": 0.9701148271560669}, {"text": "Snopes312", "start_pos": 74, "end_pos": 83, "type": "DATASET", "confidence": 0.750663161277771}]}, {"text": "The BuzzfeedUSE data comes with 4 categories).", "labels": [], "entities": [{"text": "BuzzfeedUSE data", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.9610087275505066}]}, {"text": "The classifier does seem to have some sensitivity to true vs. false information in this dataset, as more of the mostly true articles were labeled as Trusted.", "labels": [], "entities": []}, {"text": "The difference with mostly false articles, however, is negligible.", "labels": [], "entities": []}, {"text": "The most frequent label assigned by the classifier was Hoax in all four categories, which suggests that most BuzzfeedUSE articles looked like Hoax in Rashkin's data.", "labels": [], "entities": []}, {"text": "Finally, the last section of 1 shows the results on the Snopes312 plotted fier was significantly better on both dev and test sets: 0.96 and 0.75 F1-score, respectively, compared to 0.91 and 0.65 reported in their paper.", "labels": [], "entities": [{"text": "Snopes312 plotted fier", "start_pos": 56, "end_pos": 78, "type": "DATASET", "confidence": 0.9335873126983643}, {"text": "F1-score", "start_pos": 145, "end_pos": 153, "type": "METRIC", "confidence": 0.9990505576133728}]}, {"text": "Source code will be made available at https://github.com/sfudiscourse-lab/Misinformation_detection along the 6-category distinction.", "labels": [], "entities": [{"text": "Misinformation_detection", "start_pos": 74, "end_pos": 98, "type": "TASK", "confidence": 0.8335615197817484}]}, {"text": "A stronger correlation can be observed between the classifier decisions and the veracity labels in this data compared to BuzzfeedUSE.", "labels": [], "entities": []}, {"text": "This suggests that distinguishing between news articles with true and false information is a more difficult task when topics are the same (BuzzfeedUSE data is all related to the US election).", "labels": [], "entities": [{"text": "distinguishing between news articles with true and false information", "start_pos": 19, "end_pos": 87, "type": "TASK", "confidence": 0.738619069258372}, {"text": "BuzzfeedUSE data", "start_pos": 139, "end_pos": 155, "type": "DATASET", "confidence": 0.8871088325977325}]}, {"text": "In Snopes312, news articles come from a variety of topics.", "labels": [], "entities": [{"text": "Snopes312", "start_pos": 3, "end_pos": 12, "type": "DATASET", "confidence": 0.9432514905929565}]}, {"text": "The strong alignment between the classifier's Propaganda and Hoax labels with the mostly false and [fully] false categories in this dataset reveals that most misinformative news articles indeed discuss the topics or use the language of generally suspicious publishers.", "labels": [], "entities": []}, {"text": "This is an encouraging result in the sense that, with surface features such as n-grams and approximate reputationbased training data, we already can detect some of the misinformative news articles.", "labels": [], "entities": []}, {"text": "Observing classification errors across these experiments, however, indicates that the model performance varies a lot with the type of test material: Ina focused topic situation, it fails to distinguish between categories (false vs. true, or satirical vs. legitimate articles).", "labels": [], "entities": []}, {"text": "While a correlation is consistently observed between labels assigned by the classifier and the actual labels of target news articles, 3 reputationbased classification does not seem to be sufficient for predicting the veracity level of the majority of news articles.", "labels": [], "entities": [{"text": "veracity", "start_pos": 217, "end_pos": 225, "type": "METRIC", "confidence": 0.9583004117012024}]}], "tableCaptions": [{"text": " Table 1: Results of the manual assessment of Snopes312 collection for items of each veracity label", "labels": [], "entities": [{"text": "Snopes312 collection", "start_pos": 46, "end_pos": 66, "type": "DATASET", "confidence": 0.8881916403770447}]}, {"text": " Table 2: Contingency table on disagreements between the first and second annotator in Snopes312 dataset", "labels": [], "entities": [{"text": "Snopes312 dataset", "start_pos": 87, "end_pos": 104, "type": "DATASET", "confidence": 0.9520216286182404}]}]}