{"title": [{"text": "HeLI-based Experiments in Swiss German Dialect Identification", "labels": [], "entities": [{"text": "HeLI-based", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.4727257490158081}, {"text": "Swiss German Dialect Identification", "start_pos": 26, "end_pos": 61, "type": "TASK", "confidence": 0.7342716604471207}]}], "abstractContent": [{"text": "In this paper we present the experiments and results by the SUKI team in the German Dialect Identification shared task of the VarDial 2018 Evaluation Campaign.", "labels": [], "entities": [{"text": "Dialect Identification shared task", "start_pos": 84, "end_pos": 118, "type": "TASK", "confidence": 0.6223758459091187}, {"text": "VarDial 2018 Evaluation Campaign", "start_pos": 126, "end_pos": 158, "type": "DATASET", "confidence": 0.7942629456520081}]}, {"text": "Our submission using HeLI with adaptive language models obtained the best results in the shared task with a macro F1-score of 0.686, which is clearly higher than the other submitted results.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.7899144887924194}]}, {"text": "Without some form of unsupervised adaptation on the test set, it might not be possible to reach as high an F1-score with the level of domain difference between the datasets of the shared task.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.9987913966178894}]}, {"text": "We describe the methods used in detail, as well as some additional experiments carried out during the shared task.", "labels": [], "entities": []}], "introductionContent": [{"text": "The fifth VarDial workshop ( ) included for the second time a shared task for German Dialect Identification (GDI).", "labels": [], "entities": [{"text": "German Dialect Identification (GDI)", "start_pos": 78, "end_pos": 113, "type": "TASK", "confidence": 0.7287585188945135}]}, {"text": "The varieties of German were from the areas of Basel, Bern, Lucerne, and Zurich.", "labels": [], "entities": []}, {"text": "These varieties are considered dialects of Swiss German (gsw) by the ISO-639-3 standard ().", "labels": [], "entities": []}, {"text": "For the first time the GDI shared task included a separate track for unknown language detection.", "labels": [], "entities": [{"text": "unknown language detection", "start_pos": 69, "end_pos": 95, "type": "TASK", "confidence": 0.6644237339496613}]}, {"text": "We have used the HeLI method and its variations in the shared tasks of the three previous VarDial workshops ().", "labels": [], "entities": []}, {"text": "The HeLI method is robust and competes with the other state-of-the-art language identification methods.", "labels": [], "entities": [{"text": "language identification", "start_pos": 71, "end_pos": 94, "type": "TASK", "confidence": 0.7707341015338898}]}, {"text": "For the current workshop we wanted to tryout some variations and possible improvements to the original method.", "labels": [], "entities": []}, {"text": "We submitted two different runs on the four-way classification track and in the end we did not submit any runs on the unknown language detection track.", "labels": [], "entities": [{"text": "unknown language detection", "start_pos": 118, "end_pos": 144, "type": "TASK", "confidence": 0.6633743246396383}]}], "datasetContent": [{"text": "The training dataset was completely written in lowercase so we used only lowercased versions of the language models.", "labels": [], "entities": []}, {"text": "First we tested the effect of not using all the data in the language models with varying the cut-off parameter con the development set.", "labels": [], "entities": []}, {"text": "The largest language model was the character 6-gram model for the Basel-area dialect with 16,947 different 6-grams.", "labels": [], "entities": [{"text": "Basel-area dialect", "start_pos": 66, "end_pos": 84, "type": "DATASET", "confidence": 0.9563693702220917}]}, {"text": "The results using optimized penalty values for each care presented in.", "labels": [], "entities": []}, {"text": "The results would seem to indicate that the recall starts to decline in an increasing manner as soon as some of the material from the language models is left out.", "labels": [], "entities": [{"text": "recall", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.999103307723999}]}, {"text": "This is something we have noticed before in settings where the training data is of very good quality.", "labels": [], "entities": []}, {"text": "If we are using the identifier in a production setting with, for example, Wikipedia-derived language models, some of the models include so much noice that not using the complete models improves the results (Jauhiainen et al., 2017b).", "labels": [], "entities": []}, {"text": "The optimal penalty value is also clearly tied to the maximum size of the used language models.", "labels": [], "entities": []}, {"text": "We decided to use all the available data and then optimized the used language models and the penalty value p.", "labels": [], "entities": []}, {"text": "The results on the development set with different model combinations can be seen in.", "labels": [], "entities": []}, {"text": "The penalty value p presented in the third column was the optimal one for each configuration.", "labels": [], "entities": []}, {"text": "The HeLI method using character n-grams from one to four attained the best recall 65.97%.: Basic HeLI method results on the development set using different language model combinations.", "labels": [], "entities": [{"text": "recall", "start_pos": 75, "end_pos": 81, "type": "METRIC", "confidence": 0.999372661113739}]}, {"text": "We also experimented with leaving out the lower order n-grams.", "labels": [], "entities": []}, {"text": "The results of these experiments on the development set can be seen in.", "labels": [], "entities": []}, {"text": "To our surprise, the best results were attained using only the 4-grams of characters, which means that the backoff function of the HeLI method is not used at all.", "labels": [], "entities": []}, {"text": "The recall on the development set was 66.10%.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9982702732086182}]}, {"text": "We also re-tested using lower cut-offs c, but leaving off any material in the language models only made the results worse again.: Basic HeLI method results on the development set with different n-gram ranges.", "labels": [], "entities": []}, {"text": "We decided to use the character 4-grams and the penalty value of 5.8 for the first run.", "labels": [], "entities": []}, {"text": "We added the development data to the training data and generated new models.", "labels": [], "entities": []}, {"text": "The system attained a recall of 63.97% on the test set, which was somewhat less than what we had seen with the development set.", "labels": [], "entities": [{"text": "recall", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9942469596862793}]}, {"text": "The basic HeLI method always maps the mystery text M into one of the languages it has been trained with.", "labels": [], "entities": []}, {"text": "The 2015 Discriminating Between Similar Languages shared task included an unknown category which contained several a priori unknown languages.", "labels": [], "entities": [{"text": "Discriminating Between Similar Languages shared task", "start_pos": 9, "end_pos": 61, "type": "TASK", "confidence": 0.7769590119520823}]}, {"text": "One of the methods we used in 2015 was using a threshold for the score R g (M ) to detect the unknown language.", "labels": [], "entities": []}, {"text": "In order to assess the suitability of using the threshold score with the German dialects, we compared the range of the scores when g was correctly or incorrectly identified using the character 4-gram language models on the development set.", "labels": [], "entities": []}, {"text": "The score ranges can be seen in, where the line with correct identifications is bolded.", "labels": [], "entities": []}, {"text": "The lower the score, the better the mystery text fits the language.", "labels": [], "entities": []}, {"text": "The scores ranged from 1.28 to 4.56 when the dialect was correctly identified, with most of the scores higher than the lower ranges of the incorrect identifications.", "labels": [], "entities": []}, {"text": "The fact that the worst absolute score (4.56) was attained with a correct identification drove us to the conclusion that simply using the score as a cut-off would not be a quick solution to the unseen language problem.", "labels": [], "entities": [{"text": "absolute score (4.56)", "start_pos": 24, "end_pos": 45, "type": "METRIC", "confidence": 0.9006187081336975}]}, {"text": "Due to time restrictions, we did not pursue this investigation further.", "labels": [], "entities": []}, {"text": "We were also unable to test the language set based thresholding method we are using in the production environment.", "labels": [], "entities": []}, {"text": "In the end, we did not submit any results to the unknown language detection track.: Score ranges when trying to identify the dialect from Zurich area.", "labels": [], "entities": [{"text": "Zurich area", "start_pos": 138, "end_pos": 149, "type": "DATASET", "confidence": 0.9130606353282928}]}], "tableCaptions": [{"text": " Table 1. The methods used are listed in the first  column, used features in the second column, best reached weighted F1-score in the third column, and the  describing article in the fourth column.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.9715120196342468}]}, {"text": " Table 1: The weighted F1-scores using different methods on the 2017 GDI test set.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9867558479309082}, {"text": "GDI test set", "start_pos": 69, "end_pos": 81, "type": "DATASET", "confidence": 0.8847470084826151}]}, {"text": " Table 2. The first track of the shared task was a standard four-way language identification between the  four German dialects present in the training set.", "labels": [], "entities": []}, {"text": " Table 2: The sizes in words of the datasets distributed for the 2018 GDI shared task.", "labels": [], "entities": [{"text": "GDI shared task", "start_pos": 70, "end_pos": 85, "type": "TASK", "confidence": 0.4943791429201762}]}, {"text": " Table 3: Basic HeLI method results on the development set with varying c.", "labels": [], "entities": []}, {"text": " Table 4.  The penalty value p presented in the third column was the optimal one for each configuration. The HeLI  method using character n-grams from one to four attained the best recall 65.97%.", "labels": [], "entities": [{"text": "HeLI", "start_pos": 109, "end_pos": 113, "type": "METRIC", "confidence": 0.8788829445838928}, {"text": "recall", "start_pos": 181, "end_pos": 187, "type": "METRIC", "confidence": 0.9994252920150757}]}, {"text": " Table 4: Basic HeLI method results on the development set using different language model combinations.", "labels": [], "entities": []}, {"text": " Table 5. To our surprise, the best results were attained using only the  4-grams of characters, which means that the backoff function of the HeLI method is not used at all. The  recall on the development set was 66.10%. We also re-tested using lower cut-offs c, but leaving off any  material in the language models only made the results worse again.", "labels": [], "entities": [{"text": "recall", "start_pos": 179, "end_pos": 185, "type": "METRIC", "confidence": 0.9985688924789429}]}, {"text": " Table 5: Basic HeLI method results on the development set with different n-gram ranges.", "labels": [], "entities": []}, {"text": " Table 6: Baseline HeLI recalls using different combinations of training and development sets.", "labels": [], "entities": [{"text": "Baseline HeLI", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.2897622585296631}]}, {"text": " Table 7: Results compared with the other submitted runs. Our submitted results are bolded.", "labels": [], "entities": []}, {"text": " Table 8: Score ranges when trying to identify the dialect from Zurich area.", "labels": [], "entities": [{"text": "Score", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9584293961524963}, {"text": "Zurich area", "start_pos": 64, "end_pos": 75, "type": "DATASET", "confidence": 0.9217348992824554}]}]}