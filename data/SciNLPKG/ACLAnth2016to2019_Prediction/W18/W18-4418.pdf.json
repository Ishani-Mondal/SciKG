{"title": [{"text": "Aggression Identification Using Deep Learning and Data Augmentation", "labels": [], "entities": [{"text": "Aggression Identification", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.9464455842971802}, {"text": "Data Augmentation", "start_pos": 50, "end_pos": 67, "type": "TASK", "confidence": 0.7532183825969696}]}], "abstractContent": [{"text": "Social media platforms allow users to share and discuss their opinions online.", "labels": [], "entities": []}, {"text": "However, a minority of user posts is aggressive, thereby hinders respectful discussion, and-at an extreme level-is liable to prosecution.", "labels": [], "entities": []}, {"text": "The automatic identification of such harmful posts is important, because it can support the costly manual moderation of online discussions.", "labels": [], "entities": []}, {"text": "Further, the automation allows unprecedented analyses of discussion datasets that contain millions of posts.", "labels": [], "entities": []}, {"text": "This system description paper presents our submission to the First Shared Task on Aggression Identification.", "labels": [], "entities": [{"text": "Aggression Identification", "start_pos": 82, "end_pos": 107, "type": "TASK", "confidence": 0.7975711822509766}]}, {"text": "We propose to augment the provided dataset to increase the number of labeled comments from 15,000 to 60,000.", "labels": [], "entities": []}, {"text": "Thereby, we introduce linguistic variety into the dataset.", "labels": [], "entities": []}, {"text": "As a consequence of the larger amount of training data, we are able to train a special deep neural net, which generalizes especially well to unseen data.", "labels": [], "entities": []}, {"text": "To further boost the performance, we combine this neural net with three logistic regression classifiers trained on character and word n-grams, and hand-picked syntactic features.", "labels": [], "entities": []}, {"text": "This ensemble is more robust than the individual single models.", "labels": [], "entities": []}, {"text": "Our team named \"Julian\" achieves an F1-score of 60% on both English datasets, 63% on the Hindi Facebook dataset, and 38% on the Hindi Twitter dataset.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9997654557228088}, {"text": "English datasets", "start_pos": 60, "end_pos": 76, "type": "DATASET", "confidence": 0.9207316040992737}, {"text": "Hindi Facebook dataset", "start_pos": 89, "end_pos": 111, "type": "DATASET", "confidence": 0.9388149380683899}, {"text": "Hindi Twitter dataset", "start_pos": 128, "end_pos": 149, "type": "DATASET", "confidence": 0.9198355078697205}]}], "introductionContent": [{"text": "Social media platforms, such as Facebook, YouTube, Twitter, and Instagram, enable millions to publicly share user-generated content.", "labels": [], "entities": []}, {"text": "Regardless of different content types, such as text, photos, videos, and events, a crucial point of these platforms is that users can discuss content.", "labels": [], "entities": []}, {"text": "The opportunity to articulate opinions and ideas online is a valuable good: It is part of the freedom of expression, which is declared in the Universal Declaration of Human Rights.", "labels": [], "entities": [{"text": "Universal Declaration of Human Rights", "start_pos": 142, "end_pos": 179, "type": "DATASET", "confidence": 0.9144860982894898}]}, {"text": "However, aggressive and/or hateful posts can disrupt otherwise respectful discussions.", "labels": [], "entities": []}, {"text": "Such posts are called \"toxic\", because they poison a conversation so that other users abandon it.", "labels": [], "entities": []}, {"text": "Toxicity is manifold and comprises, for example, obscene language, insults, threats, and identity hate.", "labels": [], "entities": []}, {"text": "Such statements are not covered by the freedom of expression, because they harm others.", "labels": [], "entities": []}, {"text": "The boundaries of the freedom of expression area controversial topic.", "labels": [], "entities": []}, {"text": "In moderated online discussions, it is the task of human moderators to identify toxic comments and potentially delete them.", "labels": [], "entities": []}, {"text": "An automatic identification of toxic posts could support (or even to some extent replace) the costly manual moderation of online discussions.", "labels": [], "entities": []}, {"text": "For example, it could draw the attention of moderators to posts that have been automatically identified as toxic.", "labels": [], "entities": []}, {"text": "Another advantage of the automatic identification of toxic posts is that it allows the analysis of much larger datasets.", "labels": [], "entities": [{"text": "automatic identification of toxic posts", "start_pos": 25, "end_pos": 64, "type": "TASK", "confidence": 0.7519570589065552}]}, {"text": "For example, classifiers that were trained on a rather small hand-labeled dataset have been successfully used to machine-label and analyze datasets with tens of millions of posts (.", "labels": [], "entities": []}, {"text": "The First Shared Task on Aggression Identification () deals with the classification of the aggression level of user posts at different social media platforms.", "labels": [], "entities": [{"text": "Aggression Identification", "start_pos": 25, "end_pos": 50, "type": "TASK", "confidence": 0.6666790992021561}]}, {"text": "It is part of the First Workshop on Trolling, Aggression and Cyberbullying at the 27th International Conference of Computational Linguistics.", "labels": [], "entities": [{"text": "Trolling, Aggression and Cyberbullying at the 27th International Conference of Computational Linguistics", "start_pos": 36, "end_pos": 140, "type": "TASK", "confidence": 0.7213259568581214}]}, {"text": "The task is a three-way classification problem with the three classes \"overtly aggressive\" (OAG), \"covertly aggressive\" (CAG), and \"non-aggressive\" (NAG).", "labels": [], "entities": []}, {"text": "The training data consists of 15,000 aggression-annotated Facebook posts each in Hindi and English.", "labels": [], "entities": []}, {"text": "Weighted macro-averaged F1-scores serve as the evaluation metric: The individual F1-score of each class is weighted by the proportion of the concerned class in the test set and the final F1-score is the average of these individual F-scores of each class.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9216410517692566}, {"text": "F1-score", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9815529584884644}, {"text": "F1-score", "start_pos": 187, "end_pos": 195, "type": "METRIC", "confidence": 0.9892454147338867}]}, {"text": "In this system description paper, we introduce our implemented system as submitted for the shared task.", "labels": [], "entities": []}, {"text": "Our approach is based on a recurrent neural network, more specifically, a bi-directional gated recurrent unit (GRU) layer with max pooling and average pooling.", "labels": [], "entities": []}, {"text": "However, the relatively small size of the training dataset is a strong limitation for deep learning approaches.", "labels": [], "entities": []}, {"text": "Therefore, we propose to augment the training dataset: We use machine translation to translate each English comment into a foreign language, e.g. French, and translate it back into English afterwards.", "labels": [], "entities": []}, {"text": "The result of these translations is another English comment that typically uses slightly different words compared to the initial comment.", "labels": [], "entities": []}, {"text": "Examples for these translations are given in Section 3.1 and the augmented dataset together with our implementation is published online . Our contributions can be summarized as providing a: 1.", "labels": [], "entities": []}, {"text": "data augmentation method that triples the dataset size, 2.", "labels": [], "entities": []}, {"text": "neural network architecture based on a GRU layer for the task of Aggression Identification, 3.", "labels": [], "entities": [{"text": "Aggression Identification", "start_pos": 65, "end_pos": 90, "type": "TASK", "confidence": 0.7562764585018158}]}, {"text": "comparison of our results at the different subtasks and an error analysis of our approach.", "labels": [], "entities": []}, {"text": "Section 2 gives an overview of related work.", "labels": [], "entities": []}, {"text": "Section 3 explains our approach and goes into detail about the proposed data augmentation method and the neural network architecture.", "labels": [], "entities": []}, {"text": "We lists our results at the different subtasks in Section 4 and discuss how the proposed approach generalizes to unseen data.", "labels": [], "entities": []}, {"text": "Finally, we conclude and outline possible paths for future work in Section 5.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. The word n-gram and the character n-gram models have the highest correlation. In contrast, the  recurrent neural network and the word n-gram model have a rather low correlation. Their low correlation  motivates to combine their predictions, because we can assume that they complement each other well. If  they both have a similarly high F1-score, their combination outperforms the single models.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 347, "end_pos": 355, "type": "METRIC", "confidence": 0.9978150129318237}]}, {"text": " Table 2: F1-scores with 10-fold cross-validation on English Facebook dataset (En FB) and Hindi Face- book dataset (Hi FB). F1-score of the RNN approach is improved on the augmented (augm.) dataset.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9986522793769836}, {"text": "English Facebook dataset (En FB)", "start_pos": 53, "end_pos": 85, "type": "DATASET", "confidence": 0.8287849681718009}, {"text": "Hindi Face- book dataset (Hi FB", "start_pos": 90, "end_pos": 121, "type": "DATASET", "confidence": 0.648018192499876}, {"text": "F1-score", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.9969511032104492}]}, {"text": " Table 3: F1-scores on the test set. The ensemble achieves higher F1-scores on the test set than the single  models in the cross-validation.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9987200498580933}, {"text": "F1-scores", "start_pos": 66, "end_pos": 75, "type": "METRIC", "confidence": 0.9972149133682251}]}]}