{"title": [{"text": "Robust parfda Statistical Machine Translation Results", "labels": [], "entities": [{"text": "Robust parfda Statistical Machine Translation", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.596514904499054}]}], "abstractContent": [{"text": "We build parallel feature decay algorithms (parfda) Moses statistical machine translation (SMT) models for language pairs in the translation task.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 58, "end_pos": 95, "type": "TASK", "confidence": 0.7732548167308172}]}, {"text": "parfda obtains results close to the top constrained phrase-based SMT with an average of 2.252 BLEU points difference on WMT 2017 datasets using significantly less computation for building SMT systems than that would be spent using all available corpora.", "labels": [], "entities": [{"text": "SMT", "start_pos": 65, "end_pos": 68, "type": "TASK", "confidence": 0.8010278344154358}, {"text": "BLEU points difference", "start_pos": 94, "end_pos": 116, "type": "METRIC", "confidence": 0.9591743151346842}, {"text": "WMT 2017 datasets", "start_pos": 120, "end_pos": 137, "type": "DATASET", "confidence": 0.9667100111643473}]}, {"text": "We obtain BLEU upper bounds based on target coverage to identify which systems used additional data.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9986805319786072}]}, {"text": "We use PRO for tuning to decrease fluctuations in the results and post-process translation outputs to decrease translation errors due to the casing of words.", "labels": [], "entities": []}, {"text": "F 1 scores on the key phrases of the English to Turkish testsuite that we prepared reveal that parfda achieves 2nd best results.", "labels": [], "entities": [{"text": "F 1", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9797839224338531}, {"text": "Turkish testsuite", "start_pos": 48, "end_pos": 65, "type": "DATASET", "confidence": 0.702292874455452}]}, {"text": "Truecas-ing translations before scoring obtained the best results overall.", "labels": [], "entities": []}], "introductionContent": [{"text": "Statistical machine translation is widely prone to errors in text including encoding, tokenization, morphological variations and the mass they take, the size of the training and language model datasets used, and model errors.", "labels": [], "entities": [{"text": "Statistical machine translation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.6933605372905731}]}, {"text": "parfda is an instance selection tool based on feature decay algorithms) we use to select training and language model instances to build Moses phrase-based SMT systems to translate the test sets in the news translation task at WMT18.", "labels": [], "entities": [{"text": "SMT", "start_pos": 155, "end_pos": 158, "type": "TASK", "confidence": 0.9059704542160034}, {"text": "news translation task", "start_pos": 201, "end_pos": 222, "type": "TASK", "confidence": 0.7665977080663046}, {"text": "WMT18", "start_pos": 226, "end_pos": 231, "type": "DATASET", "confidence": 0.9122557640075684}]}, {"text": "As we work towards tools that can be used for multiple languages at the same time, we aim to obtain robust results for comparison and record the statistics of the data and the resources used.", "labels": [], "entities": []}, {"text": "We obtain parfda Moses phrase-based SMT () results for the language pairs in both directions in the WMT18 news translation task, which include English-Czech (en-cs), English-Estonian (en-et), English-German (ende), English-Finnish (en-fi), English-Russian (en-ru), and English-Turkish (en-tr).", "labels": [], "entities": [{"text": "SMT", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.7954992651939392}, {"text": "WMT18 news translation task", "start_pos": 100, "end_pos": 127, "type": "TASK", "confidence": 0.8006327152252197}]}, {"text": "Building a language independent system that can perform well in translation tasks is a challenging task and SMT systems participating at WMT18 have been largely built dependent on the translation direction.", "labels": [], "entities": [{"text": "translation tasks", "start_pos": 64, "end_pos": 81, "type": "TASK", "confidence": 0.904566615819931}, {"text": "SMT", "start_pos": 108, "end_pos": 111, "type": "TASK", "confidence": 0.9940947890281677}, {"text": "WMT18", "start_pos": 137, "end_pos": 142, "type": "DATASET", "confidence": 0.8083728551864624}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Statistics for the training and LM corpora in the constrained (C) setting compared with the parfda  selected data. #words is in millions (M) and #sents in thousands (K). TCOV is target 2-gram coverage.", "labels": [], "entities": [{"text": "TCOV", "start_pos": 180, "end_pos": 184, "type": "METRIC", "confidence": 0.9334462285041809}]}, {"text": " Table 2: Test set SCOV and TCOV for n-grams.", "labels": [], "entities": [{"text": "TCOV", "start_pos": 28, "end_pos": 32, "type": "METRIC", "confidence": 0.9839169383049011}]}, {"text": " Table 3: Best performing en-tr and tr-en translation results detailed with their types of errors.", "labels": [], "entities": []}, {"text": " Table 4: Lexical translation table comparison.", "labels": [], "entities": [{"text": "Lexical translation", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.7511890530586243}]}, {"text": " Table 5: Key phrases we look for in the translations.", "labels": [], "entities": []}, {"text": " Table 6: parfda tokenized and cased results with different text processing settings. Baseline is tc 0 (in italic).  bold lists the best for a translation direction.", "labels": [], "entities": []}, {"text": " Table 7: parfda results compared with the top results in WMT18 and their difference. 1", "labels": [], "entities": [{"text": "parfda", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9420906901359558}, {"text": "WMT18", "start_pos": 58, "end_pos": 63, "type": "DATASET", "confidence": 0.8838239312171936}]}, {"text": " Table 8: parfda results compared with the top results in WMT17 and their difference.", "labels": [], "entities": [{"text": "parfda", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9465465545654297}, {"text": "WMT17", "start_pos": 58, "end_pos": 63, "type": "DATASET", "confidence": 0.8470714688301086}]}, {"text": " Table 11: Testsuite F 1 scores with key phrases.", "labels": [], "entities": [{"text": "Testsuite F 1", "start_pos": 11, "end_pos": 24, "type": "METRIC", "confidence": 0.6337422927220663}]}, {"text": " Table 12: Testsuite BLEU and F 1 results.", "labels": [], "entities": [{"text": "Testsuite", "start_pos": 11, "end_pos": 20, "type": "DATASET", "confidence": 0.630897045135498}, {"text": "BLEU", "start_pos": 21, "end_pos": 25, "type": "METRIC", "confidence": 0.9873329997062683}, {"text": "F 1", "start_pos": 30, "end_pos": 33, "type": "METRIC", "confidence": 0.9876788556575775}]}]}