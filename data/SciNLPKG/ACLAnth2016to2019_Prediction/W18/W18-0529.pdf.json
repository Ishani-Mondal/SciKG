{"title": [{"text": "Language Model Based Grammatical Error Correction without Annotated Training Data", "labels": [], "entities": []}], "abstractContent": [{"text": "Since the end of the CoNLL-2014 shared task on grammatical error correction (GEC), research into language model (LM) based approaches to GEC has largely stagnated.", "labels": [], "entities": [{"text": "CoNLL-2014 shared task on grammatical error correction (GEC)", "start_pos": 21, "end_pos": 81, "type": "TASK", "confidence": 0.6864898413419723}, {"text": "GEC", "start_pos": 137, "end_pos": 140, "type": "TASK", "confidence": 0.9384760856628418}]}, {"text": "In this paper, we reexamine LMs in GEC and show that it is entirely possible to build a simple system that not only requires minimal annotated data (\u223c1000 sentences), but is also fairly competitive with several state-of-the-art systems.", "labels": [], "entities": [{"text": "GEC", "start_pos": 35, "end_pos": 38, "type": "DATASET", "confidence": 0.8665488362312317}]}, {"text": "This approach should be of particular interest for languages where very little annotated training data exists, although we also hope to use it as a baseline to motivate future research.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the CoNLL-2014 shared task on Grammatical Error Correction (GEC) ( ), the top three teams all employed a combination of statistical machine translation (SMT) or classifierbased approaches).", "labels": [], "entities": [{"text": "CoNLL-2014 shared task on Grammatical Error Correction (GEC)", "start_pos": 7, "end_pos": 67, "type": "TASK", "confidence": 0.6918826997280121}, {"text": "statistical machine translation (SMT)", "start_pos": 123, "end_pos": 160, "type": "TASK", "confidence": 0.7725215603907903}]}, {"text": "These approaches have since come to dominate the field, and a lot of recent research has focused on fine-tuning SMT systems, reranking SMT output ( , combining SMT and classifier systems (, and developing various neural architectures.", "labels": [], "entities": [{"text": "SMT", "start_pos": 112, "end_pos": 115, "type": "TASK", "confidence": 0.950821578502655}, {"text": "SMT output", "start_pos": 135, "end_pos": 145, "type": "TASK", "confidence": 0.875451922416687}]}, {"text": "Despite coming a fairly competitive fourth in the shared task however (, research into language model (LM) based approaches to GEC has largely stagnated.", "labels": [], "entities": [{"text": "GEC", "start_pos": 127, "end_pos": 130, "type": "TASK", "confidence": 0.9268553256988525}]}, {"text": "The main aim of this paper is hence to re-examine language modelling in the context of GEC and show that it is still possible to achieve competitive results even with very simple systems.", "labels": [], "entities": [{"text": "language modelling", "start_pos": 50, "end_pos": 68, "type": "TASK", "confidence": 0.7250087708234787}, {"text": "GEC", "start_pos": 87, "end_pos": 90, "type": "DATASET", "confidence": 0.7310264706611633}]}, {"text": "In fact, a notable strength of LM-based approaches is that they rely on very little annotated data (purely for tuning purposes), and so it is entirely possible to build a reasonable correction system for any language given enough native text.", "labels": [], "entities": []}, {"text": "In contrast, this is simply not possible with SMT and other popular approaches which always require (lots of) labelled data.", "labels": [], "entities": [{"text": "SMT", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.9910518527030945}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: A step-by-step example of our approach as described in Section 2. All scores are log probabilities.", "labels": [], "entities": []}, {"text": " Table 2: Various stats about the learner corpora we use.", "labels": [], "entities": []}, {"text": " Table 3: Our LM-based approach is compared against several state-of-the-art results. AMU16 SM T +LSTM and  CAMB16 SM T +LSTM were both originally reported by Yannakoudakis et al. (2017), while Lee and Lee (2014) is  the system entered by POST in CoNLL-2014. Only our approach does not use annotated training data.", "labels": [], "entities": [{"text": "POST in CoNLL-2014", "start_pos": 239, "end_pos": 257, "type": "DATASET", "confidence": 0.7654656370480856}]}]}