{"title": [{"text": "Robust Document Retrieval and Individual Evidence Modeling for Fact Extraction and Verification", "labels": [], "entities": [{"text": "Robust Document Retrieval", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8263010183970133}, {"text": "Individual Evidence Modeling", "start_pos": 30, "end_pos": 58, "type": "TASK", "confidence": 0.5913247068723043}, {"text": "Fact Extraction", "start_pos": 63, "end_pos": 78, "type": "TASK", "confidence": 0.8138946294784546}]}], "abstractContent": [{"text": "This paper presents the ColumbiaNLP submission for the FEVER Workshop Shared Task.", "labels": [], "entities": [{"text": "ColumbiaNLP", "start_pos": 24, "end_pos": 35, "type": "DATASET", "confidence": 0.9644485712051392}, {"text": "FEVER Workshop Shared Task", "start_pos": 55, "end_pos": 81, "type": "DATASET", "confidence": 0.6914807111024857}]}, {"text": "Our system is an end-to-end pipeline that extracts factual evidence from Wikipedia and infers a decision about the truthfulness of the claim based on the extracted evidence.", "labels": [], "entities": []}, {"text": "Our pipeline achieves significant improvement over the baseline for all the components (Doc-ument Retrieval, Sentence Selection and Tex-tual Entailment) both on the development set and the test set.", "labels": [], "entities": [{"text": "Doc-ument Retrieval", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.55290387570858}, {"text": "Sentence Selection", "start_pos": 109, "end_pos": 127, "type": "TASK", "confidence": 0.8097391426563263}]}, {"text": "Our team finished 6th out of 24 teams on the leader-board based on the preliminary results with a FEVER score of 49.06 on the blind test set compared to 27.45 of the baseline system.", "labels": [], "entities": [{"text": "FEVER score", "start_pos": 98, "end_pos": 109, "type": "METRIC", "confidence": 0.9807639122009277}]}], "introductionContent": [], "datasetContent": [{"text": "Accuracy Shared Task Dev 58.77 Blind Test Set 57.45 Our entailment accuracy on the shared task dev and test set is 7 and 9 points better than the baseline respectively.", "labels": [], "entities": [{"text": "Accuracy Shared Task Dev 58.77 Blind Test Set 57.45", "start_pos": 0, "end_pos": 51, "type": "DATASET", "confidence": 0.8013212945726182}, {"text": "accuracy", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.9901250600814819}]}, {"text": "The batch size is kept as 64.", "labels": [], "entities": []}, {"text": "The model is trained for 15 epochs using Adam optimizer with a learning rate of 0.001.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 63, "end_pos": 76, "type": "METRIC", "confidence": 0.957872599363327}]}, {"text": "The size of the LSTM hidden units is set to 512 and for the classifier, we use a MLP with 1 hidden-layer of 512 hidden units.", "labels": [], "entities": []}, {"text": "The embedding dimension of the words is set to 300.", "labels": [], "entities": []}, {"text": "shows the overall FEVER score obtained by our pipeline on the dev and test sets.", "labels": [], "entities": [{"text": "FEVER score", "start_pos": 18, "end_pos": 29, "type": "METRIC", "confidence": 0.9798204600811005}]}, {"text": "In the provisional ranking our system ranked 6th.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Coverage of claims that can be fully supported  or refuted by the retrieved documents (dev set)", "labels": [], "entities": []}, {"text": " Table 4: FEVER scores on shared task dev and test set", "labels": [], "entities": [{"text": "FEVER", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9993672966957092}]}, {"text": " Table 7: Wrong gold label (NOT ENOUGH INFO)", "labels": [], "entities": [{"text": "Wrong gold label", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.6901377439498901}, {"text": "NOT", "start_pos": 28, "end_pos": 31, "type": "METRIC", "confidence": 0.9256266355514526}, {"text": "ENOUGH", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.606731116771698}, {"text": "INFO", "start_pos": 39, "end_pos": 43, "type": "METRIC", "confidence": 0.6102551221847534}]}, {"text": " Table 8: Confusion matrix of entailment predictions  on shared task dev set", "labels": [], "entities": []}]}