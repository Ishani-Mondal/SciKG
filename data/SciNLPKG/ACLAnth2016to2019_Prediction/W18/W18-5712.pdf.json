{"title": [{"text": "Why are Sequence-to-Sequence Models So Dull? Understanding the Low-Diversity Problem of Chatbots", "labels": [], "entities": []}], "abstractContent": [{"text": "Diversity is a long-studied topic in information retrieval that usually refers to the requirement that retrieved results should be non-repetitive and cover different aspects.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.7276160717010498}]}, {"text": "Ina conversational setting, an additional dimension of diversity matters: an engaging response generation system should be able to output responses that are diverse and interesting.", "labels": [], "entities": []}, {"text": "Sequence-to-sequence (Seq2Seq) models have been shown to be very effective for response generation.", "labels": [], "entities": [{"text": "response generation", "start_pos": 79, "end_pos": 98, "type": "TASK", "confidence": 0.8987619280815125}]}, {"text": "However, dialogue responses generated by Seq2Seq models tend to have low diversity.", "labels": [], "entities": []}, {"text": "In this paper , we review known sources and existing approaches to this low-diversity problem.", "labels": [], "entities": []}, {"text": "We also identify a source of low diversity that has been little studied so far, namely model over-confidence.", "labels": [], "entities": []}, {"text": "We sketch several directions for tackling model over-confidence and, hence, the low-diversity problem, including confidence penalties and label smoothing.", "labels": [], "entities": [{"text": "label smoothing", "start_pos": 138, "end_pos": 153, "type": "TASK", "confidence": 0.7590679824352264}]}], "introductionContent": [{"text": "Sequence-to-sequence (Seq2Seq) models () have been designed for sequence learning.", "labels": [], "entities": [{"text": "sequence learning", "start_pos": 64, "end_pos": 81, "type": "TASK", "confidence": 0.7861260175704956}]}, {"text": "Generally, a Seq2Seq model consists of two recurrent neural networks (RNN) as its encoder and decoder, respectively, through which the model cannot only deal with inputs and outputs with variable lengths separately, but also be trained end-to-end.", "labels": [], "entities": []}, {"text": "Seq2Seq models can use different settings for the encoder and decoder networks, such as the number of input/output units, ways of stacking layers, dictionary, etc.", "labels": [], "entities": []}, {"text": "After showing promising results in machine translation (MT) tasks), Seq2Seq models also proved to be effective for tasks like question answering (, dialogue response generation (), text summarization (, constituency parsing (), image captioning (, and soon.", "labels": [], "entities": [{"text": "machine translation (MT) tasks", "start_pos": 35, "end_pos": 65, "type": "TASK", "confidence": 0.8584900697072347}, {"text": "question answering", "start_pos": 126, "end_pos": 144, "type": "TASK", "confidence": 0.8788636922836304}, {"text": "dialogue response generation", "start_pos": 148, "end_pos": 176, "type": "TASK", "confidence": 0.7262857953707377}, {"text": "text summarization", "start_pos": 181, "end_pos": 199, "type": "TASK", "confidence": 0.7700643837451935}, {"text": "constituency parsing", "start_pos": 203, "end_pos": 223, "type": "TASK", "confidence": 0.8468528091907501}, {"text": "image captioning", "start_pos": 228, "end_pos": 244, "type": "TASK", "confidence": 0.7663793563842773}]}, {"text": "Seq2Seq models form the cornerstone of modern response generation models (.", "labels": [], "entities": []}, {"text": "Although Seq2Seq models can generate grammatical and fluent responses, it has also been reported that the corpus-level diversity of Seq2Seq models is usually low, as many responses are trivial or non-committal, like \"I don't know\", \"I'm sorry\" or \"I'm OK\" (.", "labels": [], "entities": []}, {"text": "We refer to this problem as the low-diversity problem.", "labels": [], "entities": []}, {"text": "In recent years, there have been several types of approach to diagnosing and addressing the lowdiversity problem.", "labels": [], "entities": []}, {"text": "The purpose of this paper is to understand the low-diversity problem, to understand what diagnoses and solutions have been proposed so far, and to explore possible new approaches.", "labels": [], "entities": []}, {"text": "We first review the theory of Seq2Seq models, then we give an overview of known causes and existing solutions to the low-diversity problem.", "labels": [], "entities": []}, {"text": "We then connect the low-diversity problem to the concept of model over-confidence, and propose approaches to address the over-confidence problem and, hence, the low-diversity problem.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}