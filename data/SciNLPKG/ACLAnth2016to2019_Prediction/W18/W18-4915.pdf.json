{"title": [{"text": "Developing and Evaluating Annotation Procedures for Twitter Data during Hazard Events", "labels": [], "entities": []}], "abstractContent": [{"text": "When a hazard such as a hurricane threatens, people are forced to make a wide variety of decisions , and the information they receive and produce can influence their own and others' actions.", "labels": [], "entities": []}, {"text": "As social media grows more popular, an increasing number of people are using social media platforms to obtain and share information about approaching threats and discuss their interpretations of the threat and their protective decisions.", "labels": [], "entities": []}, {"text": "This work aims to improve understanding of natural disasters through social media and provide an annotation scheme to identify themes in user's social media behavior and facilitate efforts in supervised machine learning.", "labels": [], "entities": []}, {"text": "To that end, this work has three contributions: (1) the creation of an annotation scheme to consistently identify hazard-related themes in Twitter, (2) an overview of agreement rates and difficulties in identifying annotation categories, and (3) a public release of both the dataset and guidelines developed from this scheme.", "labels": [], "entities": []}, {"text": "1 Background People's responses to hurricane events encompass a variety of factors, including their behavior, attitudes, and perceptions of information.", "labels": [], "entities": []}, {"text": "As social media becomes more and more prevalent, analysis of data from platforms such as Twitter offers potential to build understanding of how and why people make different protective decisions as a hazard approaches.", "labels": [], "entities": []}, {"text": "This understanding can then be used to help design strategies to enhance hazard risk communication and support protective decision making (Morss et al., 2017).", "labels": [], "entities": [{"text": "hazard risk communication", "start_pos": 73, "end_pos": 98, "type": "TASK", "confidence": 0.6219611664613088}, {"text": "protective decision making", "start_pos": 111, "end_pos": 137, "type": "TASK", "confidence": 0.6451196471850077}]}, {"text": "Ethnographic and qualitative content analyses of Twitter data from recent hazard events indicate that careful analysis of data can reveal new insights about how people interpret different types of information, evaluate and respond to risks, and manage impacts as a hazard approaches and arrives.", "labels": [], "entities": []}, {"text": "Such analyses are resource-intensive, however, taking time and computing power both in terms of selecting a suitable sample and in reading and analyzing the data.", "labels": [], "entities": []}, {"text": "Automated extraction offers significant potential for helping narrow down the vast volume of Twitter data to that which is likely to be of greatest interest for research focused on different topics, thus supporting in-depth qualitative analyses.", "labels": [], "entities": [{"text": "Automated extraction", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7143044769763947}]}, {"text": "Machine learning can also aid the quantitative analysis of macroscale patterns in the data, such as how mentions of different topics evolve overtime.", "labels": [], "entities": []}, {"text": "Here, we are interested in what is salient to people who are at risk from a hazard as they gather and process information, assess risks, and decide how to respond as the threat and its impacts evolve.", "labels": [], "entities": []}, {"text": "Our qualitative analyses of Twitter narratives to date indicate that these data can help reveal how people use forecasts, evacuation orders, environmental and social cues, and other information to help assess risks.", "labels": [], "entities": []}, {"text": "These analyses also reveal that Twitter data contains content related to people's cognitive risk perceptions, their affective responses to the risk and the event's impacts, and their protective and coping behaviors (Anderson et al., 2016; Demuth et al., 2018; Mileti and Sorenson, 1990).", "labels": [], "entities": []}, {"text": "Thus, the annotation reported here focuses on identifying these types of topics, as they are represented in the Twitter data.", "labels": [], "entities": [{"text": "Twitter data", "start_pos": 112, "end_pos": 124, "type": "DATASET", "confidence": 0.7346577644348145}]}, {"text": "This work is licensed under a Creative Commons Attribution 4.0 International License.", "labels": [], "entities": []}, {"text": "License details: http:// creativecommons.org/licenses/by/4.0/", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Tweet and User counts by Scheme", "labels": [], "entities": []}, {"text": " Table 2: Relevance : Counts and Agreement Rates for annotation of relevant tweets", "labels": [], "entities": [{"text": "Relevance", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9819314479827881}, {"text": "Counts", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9894376993179321}, {"text": "Agreement Rates", "start_pos": 33, "end_pos": 48, "type": "METRIC", "confidence": 0.9664946794509888}]}, {"text": " Table 3: Inter-annotator Agreement as F1 across Schema. Bold numbers are those that showed agreement  over .75.", "labels": [], "entities": [{"text": "F1", "start_pos": 39, "end_pos": 41, "type": "METRIC", "confidence": 0.9949091076850891}]}]}