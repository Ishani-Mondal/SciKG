{"title": [], "abstractContent": [{"text": "This paper describes the participation of the IRIT team to the TRAC 2018 shared task on Aggression Identification and more precisely to the shared task in English language.", "labels": [], "entities": [{"text": "TRAC 2018 shared task", "start_pos": 63, "end_pos": 84, "type": "DATASET", "confidence": 0.7577020078897476}, {"text": "Aggression Identification", "start_pos": 88, "end_pos": 113, "type": "TASK", "confidence": 0.7854239046573639}]}, {"text": "The three following methods have been used: a) a combination of machine learning techniques that relies on a set of features and document/text vectorization, b) Convolutional Neural Network (CNN) and c) a combination of Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM).", "labels": [], "entities": []}, {"text": "Best results were obtained when using the method (a) on the English test data from Facebook which ranked our method sixteenth out of thirty teams, and the method (c) on the English test data from other social media, where we obtained the fifteenth rank out of thirty.", "labels": [], "entities": [{"text": "English test data from Facebook", "start_pos": 60, "end_pos": 91, "type": "DATASET", "confidence": 0.9227257370948792}, {"text": "English test data", "start_pos": 173, "end_pos": 190, "type": "DATASET", "confidence": 0.7328729331493378}]}], "introductionContent": [{"text": "In recent years, the emergence of social media platforms like Facebook, Twitter, etc.", "labels": [], "entities": []}, {"text": "changes the way people communicate.", "labels": [], "entities": []}, {"text": "Although these platforms give many benefits to their users, they can also have several negative impacts where people can be hurt for example by some aggressive texts ().", "labels": [], "entities": []}, {"text": "The aggression on social media platforms is actually more harmful than traditional bullying for many reasons such as allowing people to hide behind an alias.", "labels": [], "entities": []}, {"text": "Unfortunately, such phenomena of on-line aggression and bullying not only have created psychological and mental health issues for on-line users, but it can end by forcing some of them to change several things in their lives and can even conduct them to suicide according to).", "labels": [], "entities": []}, {"text": "The TRAC 2018 workshop has been created in order to study these problems ().", "labels": [], "entities": [{"text": "TRAC 2018 workshop", "start_pos": 4, "end_pos": 22, "type": "DATASET", "confidence": 0.8358611663182577}]}, {"text": "The TRAC 2018 workshop aims at providing the framework for evaluatig systems that aim at detecting/identifying aggression, trolling, cyberbullying and other related phenomena in both speech and text from social media ().", "labels": [], "entities": [{"text": "TRAC 2018 workshop", "start_pos": 4, "end_pos": 22, "type": "DATASET", "confidence": 0.8489283720652262}, {"text": "detecting/identifying aggression, trolling, cyberbullying and other related phenomena in both speech and text from social media", "start_pos": 89, "end_pos": 216, "type": "Description", "confidence": 0.7829136595129966}]}, {"text": "The shared task challenge consists in distinguishing three levels of aggression from text: overtly aggressive, covertly aggressive and non-aggressive.", "labels": [], "entities": []}, {"text": "Overtly aggressive means that there is an expression of aggression directly with specific words or keywords.", "labels": [], "entities": []}, {"text": "Covertly aggressive expresses aggression subtly such as indirect attack or with more polite expressions.", "labels": [], "entities": []}, {"text": "Two different languages are studied independently: English and Hindi.", "labels": [], "entities": []}, {"text": "The shared task was organized into two different stages: training and testing.", "labels": [], "entities": []}, {"text": "During the training stage, two datasets of 15, 000 aggression-annotated Facebook posts and comments, one in English and the other in Hindi, were provided.", "labels": [], "entities": []}, {"text": "During testing stage, the organizers also included a data set from a second social media platform.", "labels": [], "entities": []}, {"text": "Overall, the test data set contains four sub-collections: two from Facebook and two from another social media (not named by the organizers); for each source, one sub-collection is in English while the other is in Hindi.Participants could participate to one or several of the four subtasks which are: (1) English (Facebook) task, (2) Hindi (Facebook) task, (3) English (another social media) task, and (4) Hindi (another social media).", "labels": [], "entities": []}, {"text": "More details about the task can be found in ().", "labels": [], "entities": []}, {"text": "Our team, IRIT, participated to shared task in English language for both Facebook and the other social media platform: subtask (1) and (3).", "labels": [], "entities": [{"text": "IRIT", "start_pos": 10, "end_pos": 14, "type": "DATASET", "confidence": 0.5111777186393738}]}, {"text": "http://creativecommons.org/licenses/by/4.0/ In this paper, we report the methods we proposed when participating to the subtasks; we have developed three approaches that we compare in this paper on the problem of aggression identification in texts.", "labels": [], "entities": [{"text": "aggression identification in texts", "start_pos": 212, "end_pos": 246, "type": "TASK", "confidence": 0.8259823396801949}]}, {"text": "The first method is a combination of two classifiers : random forest that relies on features ranging from surface features to more linguistic features and logistic regression based on text vectorization.", "labels": [], "entities": []}, {"text": "We named this method Trac-RF LR.", "labels": [], "entities": []}, {"text": "The second approach is a deep learning technique widely used in image area and adapted for text classification.", "labels": [], "entities": [{"text": "image area", "start_pos": 64, "end_pos": 74, "type": "TASK", "confidence": 0.7302761524915695}, {"text": "text classification", "start_pos": 91, "end_pos": 110, "type": "TASK", "confidence": 0.8554655909538269}]}, {"text": "It uses a Convolutional Neural Network and we named it Trac-CNN in the rest of the paper.", "labels": [], "entities": [{"text": "Trac-CNN", "start_pos": 55, "end_pos": 63, "type": "DATASET", "confidence": 0.7917627096176147}]}, {"text": "Finally, the third approach is a combination of two deep learning techniques: Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM).", "labels": [], "entities": []}, {"text": "We named this method Trac-CNN LSTM.", "labels": [], "entities": [{"text": "Trac-CNN LSTM", "start_pos": 21, "end_pos": 34, "type": "DATASET", "confidence": 0.7375756204128265}]}, {"text": "The remaining of this paper is organized as follows: Section 2 is an overview of state-of-the-art approaches for aggression detection.", "labels": [], "entities": [{"text": "aggression detection", "start_pos": 113, "end_pos": 133, "type": "TASK", "confidence": 0.9050616323947906}]}, {"text": "Section 3 details the methods we developed.", "labels": [], "entities": []}, {"text": "Section 4 reports the results as well as the data sets and Section 5 concludes this paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Distribution of training, validation and testing data on TRAC 2018 data collection.", "labels": [], "entities": [{"text": "TRAC 2018 data collection", "start_pos": 67, "end_pos": 92, "type": "DATASET", "confidence": 0.9546305984258652}]}, {"text": " Table 3: Results for the English (Facebook and other social media) task. Bold value is the best perfor- mance.", "labels": [], "entities": []}, {"text": " Table 4: Results of top 5 teams vs our results which are in Bold.", "labels": [], "entities": []}]}