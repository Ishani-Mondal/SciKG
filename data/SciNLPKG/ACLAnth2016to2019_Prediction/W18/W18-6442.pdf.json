{"title": [{"text": "Sheffield Submissions for WMT18 Multimodal Translation Shared Task", "labels": [], "entities": [{"text": "WMT18 Multimodal Translation Shared", "start_pos": 26, "end_pos": 61, "type": "TASK", "confidence": 0.7368974536657333}]}], "abstractContent": [{"text": "This paper describes the University of Sheffield's submissions to the WMT18 Mul-timodal Machine Translation shared task.", "labels": [], "entities": [{"text": "WMT18 Mul-timodal Machine Translation shared task", "start_pos": 70, "end_pos": 119, "type": "TASK", "confidence": 0.7255589862664541}]}, {"text": "We participated in both tasks 1 and 1b.", "labels": [], "entities": []}, {"text": "For task 1, we build on a standard sequence to sequence attention-based neural machine translation system (NMT) and investigate the utility of multimodal re-ranking approaches.", "labels": [], "entities": [{"text": "attention-based neural machine translation", "start_pos": 56, "end_pos": 98, "type": "TASK", "confidence": 0.6659415438771248}]}, {"text": "More specifically, n-best translation candidates from this system are re-ranked using novel multimodal cross-lingual word sense disam-biguation models.", "labels": [], "entities": []}, {"text": "For task 1b, we explore three approaches: (i) re-ranking based on cross-lingual word sense disambiguation (as for task 1), (ii) re-ranking based on consensus of NMT n-best lists from German-Czech, French-Czech and English-Czech systems, and (iii) data augmentation by generating En-glish source data through machine translation from French to English and from German to English followed by hypothesis selection using a multimodal-reranker.", "labels": [], "entities": [{"text": "cross-lingual word sense disambiguation", "start_pos": 66, "end_pos": 105, "type": "TASK", "confidence": 0.6319459825754166}]}], "introductionContent": [{"text": "This paper describes the University of Sheffield's submissions for both Tasks 1 and 1b of the third edition of the Multimodal Machine Translation shared task.", "labels": [], "entities": [{"text": "Multimodal Machine Translation shared task", "start_pos": 115, "end_pos": 157, "type": "TASK", "confidence": 0.8323143362998963}]}, {"text": "Task 1 consists in translating source sentences in English that describe an image into German (DE) or French (FR) or Czech (CS), given the image.", "labels": [], "entities": []}, {"text": "Task 1b consists in translating source sentences in English that describe an image into Czech, given the image and the French and German translations of the source sentence.", "labels": [], "entities": []}, {"text": "This task poses the challenging problem of building models that use both language and image modalities.", "labels": [], "entities": []}, {"text": "The dataset for the shared task ( has sentences with simple language constructions and it has been observed by earlier systems that standard text-only sequence to sequence neural machine translation models (NMT) with attention are able to obtain very high performance.", "labels": [], "entities": [{"text": "text-only sequence to sequence neural machine translation", "start_pos": 141, "end_pos": 198, "type": "TASK", "confidence": 0.6295595467090607}]}, {"text": "Building on this, for further inspection, we built our own standard NMT systems for EN-DE, EN-FR and EN-CS language directions and noticed that the translation hypotheses besides the 1-best output are also of high quality.", "labels": [], "entities": []}, {"text": "We made our systems produce 20 translation hypotheses for English descriptions in the validation set and selected the hypothesis with the highest sentencelevel METEOR) score, called the Oracle, and compared this to the 1-best.", "labels": [], "entities": [{"text": "METEOR) score", "start_pos": 160, "end_pos": 173, "type": "METRIC", "confidence": 0.9563262263933817}]}, {"text": "In this experiment, we observed that the Oracle performs way better (11 to 13.5 METEOR points) than the 1-best output (See).", "labels": [], "entities": [{"text": "METEOR", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.9988486766815186}]}, {"text": "This preliminary experiment motivated us to investigate re-ranking approaches.: Motivation for re-ranking.", "labels": [], "entities": []}, {"text": "In this preliminary experiment, we observe that re-ranking of the 20-best translation hypotheses generated by a standard NMT model has the potential of improving translation by upto 10.84 to 13.49 METEOR points for the three language pairs.", "labels": [], "entities": [{"text": "METEOR", "start_pos": 197, "end_pos": 203, "type": "METRIC", "confidence": 0.9987137317657471}]}, {"text": "For a re-ranking strategy, we were inspired by how humans use images to translate image descriptions.", "labels": [], "entities": []}, {"text": "We believe humans look at the image usually to disambiguate ambiguous words in the source sentence especially in those instances where the text alone is not sufficient.", "labels": [], "entities": []}, {"text": "For example, translating 'A sportsperson is playing football' into French requires us to know whether the sportsperson is a male or a female and accordingly the translation is 'Une sportif joue au football' (male) or 'Une sportive joue au football' (female).", "labels": [], "entities": []}, {"text": "In such cases, humans usually look at the image to disambiguate and select the correct translation which is what we try to mimic in our approach.", "labels": [], "entities": []}, {"text": "More specifically, in our systems we adopt a two-step pipeline approach.", "labels": [], "entities": []}, {"text": "In the first step, we use an ensemble of text-only models initialized with different seeds to produce lists of 10-best translation hypotheses.", "labels": [], "entities": []}, {"text": "In the second step, we rerank the 10-best hypotheses using a novel multimodal cross-lingual Word Sense Disambiguation (WSD) approach.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 92, "end_pos": 123, "type": "TASK", "confidence": 0.7372102638085684}]}, {"text": "For control experiments, we also compare our results with monomodal crosslingual WSD () and a system that performs re-ranking using the Most Frequent Sense (MFS) baseline (Section 3.1.2).", "labels": [], "entities": []}, {"text": "Our main goal is to investigate a multimodal, image-based, cross-lingual WSD that predicts the translation candidate which correctly disambiguates ambiguous words in the source sentence.", "labels": [], "entities": [{"text": "WSD", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.8229144215583801}]}, {"text": "Our baseline NMT system is based on the attentive encoder-decoder () approach with a Conditional GRU (CGRU) () decoder and is built using NMTPY toolkit.", "labels": [], "entities": []}, {"text": "Our cross-lingual WSD models are based on neural sequence learning models for WSD applied to the Multimodal Lexical Translation Dataset (Lala and Specia, 2018).", "labels": [], "entities": [{"text": "WSD", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.8795842528343201}, {"text": "Multimodal Lexical Translation", "start_pos": 97, "end_pos": 127, "type": "TASK", "confidence": 0.5457390149434408}]}, {"text": "For task 1b, we explore three approaches.", "labels": [], "entities": []}, {"text": "The first approach concatenates the 10-best translation hypotheses from DE-CS, FR-CS and EN-CS MT systems and then re-ranks them using the imageaware multimodal cross-lingual WSD mentioned earlier (the same way as in Task 1) (Section 3.1.2).", "labels": [], "entities": [{"text": "FR-CS", "start_pos": 79, "end_pos": 84, "type": "DATASET", "confidence": 0.8074489235877991}]}, {"text": "The second approach explores the consensus between the different 10-best lists.", "labels": [], "entities": []}, {"text": "The best hypothesis is selected according to the number of times it appeared in the different 10-best lists.", "labels": [], "entities": []}, {"text": "We followed the order of the n-best lists, meaning that the highest ranked hypothesis with the majority votes was selected.", "labels": [], "entities": []}, {"text": "The third approach uses data augmentation that hinges on the fact that the objective is to translate from English into Czech.", "labels": [], "entities": []}, {"text": "Extra source data is generated by building systems that translate from German into English and French into English.", "labels": [], "entities": []}, {"text": "With this extra data, we build an EN-CS system.", "labels": [], "entities": []}, {"text": "We then obtain a 10-best list over training, development and test sets respectively.", "labels": [], "entities": []}, {"text": "For selecting the best hypothesis from the 10-best list, we experiment with a classification-based approach.", "labels": [], "entities": []}, {"text": "We calculate METEOR) scores for each hypothesis in the 10-best list of the training set and threshold the scores to build classifiers to distinguish good from bad translations using a) word embeddings and image features with a Random Forest model and b) a multimodal Recurrent Neural Network (RNN) model.", "labels": [], "entities": [{"text": "METEOR) scores", "start_pos": 13, "end_pos": 27, "type": "METRIC", "confidence": 0.9483025272687277}]}, {"text": "In Section 3 we describe our systems in detail.", "labels": [], "entities": []}, {"text": "We describe the data preprocessing in Section 2.", "labels": [], "entities": []}, {"text": "The results are discussed in Section 4.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Motivation for re-ranking. In this prelim- inary experiment, we observe that re-ranking of the  20-best translation hypotheses generated by a standard  NMT model has the potential of improving translation  by upto 10.84 to 13.49 METEOR points for the three  language pairs.", "labels": [], "entities": [{"text": "METEOR", "start_pos": 239, "end_pos": 245, "type": "METRIC", "confidence": 0.9988897442817688}]}, {"text": " Table 2: Performance of cross-lingual WSD models  (Section 3.1.2) measured in terms of accuracy: propor- tion of correctly translated ambiguous words.", "labels": [], "entities": [{"text": "WSD", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.8709231615066528}, {"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9990170001983643}]}, {"text": " Table 3: Evaluation of our systems and the baseline for Task 1. We show METEOR, BLEU and TER scores.", "labels": [], "entities": [{"text": "METEOR", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.9986080527305603}, {"text": "BLEU", "start_pos": 81, "end_pos": 85, "type": "METRIC", "confidence": 0.9985137581825256}, {"text": "TER scores", "start_pos": 90, "end_pos": 100, "type": "METRIC", "confidence": 0.972566694021225}]}, {"text": " Table 4: The effect of re-ranking approaches on the  baseline NMT model outputs. The number outside the  bracket shows the number of instances that are affected  due to re-ranking in the 1071 test instances. The num- ber inside the bracket '()' shows the number of words  in the entire test set that are affected (deleted, added or  replaced) due to re-ranking.", "labels": [], "entities": []}, {"text": " Table 5: Evaluation of our systems and the baseline  for Task 1b.", "labels": [], "entities": []}]}