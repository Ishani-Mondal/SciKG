{"title": [{"text": "Neural Morphological Tagging of Lemma Sequences for Machine Translation Costanza Conforti", "labels": [], "entities": [{"text": "Neural Morphological Tagging of Lemma Sequences", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.8419225613276163}, {"text": "Machine Translation", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.7410460710525513}]}], "abstractContent": [{"text": "Translation to morphologically rich languages is a difficult task because of sparsity caused by morphological richness.", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9413220286369324}]}, {"text": "In this work we perform a pilot study on predicting the morphologically rich POS tags of sequences of lemmas.", "labels": [], "entities": []}, {"text": "Similar studies have been conducted in the context of phrase-based statistical machine translation.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation", "start_pos": 54, "end_pos": 98, "type": "TASK", "confidence": 0.653690792620182}]}, {"text": "We implement a state-of-the-art tagger taking lemmas as input and show that we can successfully predict the morphologically rich POS tags, with accuracies of up to 91%.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 144, "end_pos": 154, "type": "METRIC", "confidence": 0.9930505752563477}]}], "introductionContent": [{"text": "Modeling sequences of tokens in morphologically rich languages (MRLs) is a difficult task of great importance in many applications of NLP.", "labels": [], "entities": [{"text": "Modeling sequences of tokens in morphologically rich languages (MRLs)", "start_pos": 0, "end_pos": 69, "type": "TASK", "confidence": 0.8646751804785295}]}, {"text": "For instance, translation from a morphologically poor language (such as English) to an MRL (such as German or Czech) is known to be difficult.", "labels": [], "entities": [{"text": "translation", "start_pos": 14, "end_pos": 25, "type": "TASK", "confidence": 0.9759878516197205}]}, {"text": "An effective approach for modeling MRLs is to break the sequence into a factorized representation, such as lemmas paired with their morphologically rich POS representations (e.g., fora German noun, the rich representation includes the noun POS tag, and the three grammatical features gender, number, and case).", "labels": [], "entities": [{"text": "MRLs", "start_pos": 35, "end_pos": 39, "type": "TASK", "confidence": 0.9791795611381531}]}, {"text": "In this paper, we assume that we have a good system for generating lemmas and study whether we can automatically recover the morphologically rich POS representation.", "labels": [], "entities": []}, {"text": "This is more difficult than morphologically rich POS tagging, which takes a sequence of surface forms and recovers the most likely morphologically rich POS representation, because lemma input is underspecified.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 49, "end_pos": 60, "type": "TASK", "confidence": 0.7978837490081787}]}, {"text": "This task was previously studied by.", "labels": [], "entities": []}, {"text": "We differ in two ways: we implement a state-of-the-art neural tagger, rather than a Maximum Entropy Markov model, and we predict rich morphological POS, rather than surface forms.", "labels": [], "entities": []}, {"text": "Studying the prediction of morphologically rich POS given lemmas is an interesting problem in its own right.", "labels": [], "entities": [{"text": "prediction of morphologically rich POS", "start_pos": 13, "end_pos": 51, "type": "TASK", "confidence": 0.7721781134605408}]}, {"text": "It has implications for NLP applications involving the generation of MRL sentences including machine translation.", "labels": [], "entities": [{"text": "generation of MRL sentences", "start_pos": 55, "end_pos": 82, "type": "TASK", "confidence": 0.6746176183223724}, {"text": "machine translation", "start_pos": 93, "end_pos": 112, "type": "TASK", "confidence": 0.7606091797351837}]}, {"text": "A concrete application is to apply it in an end-to-end MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 55, "end_pos": 57, "type": "TASK", "confidence": 0.9821134209632874}]}, {"text": "Similar morphological prediction systems have been applied by, and in phrase-based SMT.", "labels": [], "entities": [{"text": "morphological prediction", "start_pos": 8, "end_pos": 32, "type": "TASK", "confidence": 0.7056582868099213}, {"text": "phrase-based SMT", "start_pos": 70, "end_pos": 86, "type": "TASK", "confidence": 0.5891773700714111}]}, {"text": "A pipeline of such a system is depicted in.", "labels": [], "entities": []}, {"text": "Given the promising results in this initial study, we plan to combine our tagger with a standard neural machine translation model, resulting in a multi-task system which produces pairs of lemmas and morphologically rich POS tags.", "labels": [], "entities": []}, {"text": "An important benefit of such a system over previous approaches which produce such pairs directly using a standard NMT model (e.g.,) is that we will be able to train it in a multi-task fashion, where some: Example of a machine translation system using our morphology tagger (in red) as an intermediate step in the translation process into a target MRL.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 218, "end_pos": 237, "type": "TASK", "confidence": 0.705512136220932}]}, {"text": "training examples contain source language text (from parallel data), while others do not (from monolingual data).", "labels": [], "entities": []}, {"text": "In this paper, we present our language-independent neural tagging system implemented and trained for this task.", "labels": [], "entities": [{"text": "language-independent neural tagging", "start_pos": 30, "end_pos": 65, "type": "TASK", "confidence": 0.5869348247845968}]}, {"text": "German, an MRL belonging to the Indo-European family, has been chosen fora case study.", "labels": [], "entities": [{"text": "German", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8989320993423462}]}, {"text": "This choice is motivated by the fact that, within MRLs, German has been widely studied in recent years, and many resources are publicly available.", "labels": [], "entities": [{"text": "MRLs", "start_pos": 50, "end_pos": 54, "type": "TASK", "confidence": 0.9571917057037354}]}], "datasetContent": [{"text": "Three non-neural baselines have been built to provide lower bounds, two dummy classifiers and a CRF-based model: \u2022 Maximum frequency.", "labels": [], "entities": []}, {"text": "The first baseline (Max. Freq.) always predicts the most frequent label in the tagset.", "labels": [], "entities": []}, {"text": "The second baseline (Freq. Lookup) uses a lookup table to return, for each lemma, the label it is most frequently annotated within the training corpus.", "labels": [], "entities": [{"text": "Freq. Lookup)", "start_pos": 21, "end_pos": 34, "type": "DATASET", "confidence": 0.8608094056447347}]}, {"text": "A CRF model was trained on the lemmatized Europarl corpus, using the MARMOT toolkit with its default parameters.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 42, "end_pos": 57, "type": "DATASET", "confidence": 0.9845947027206421}]}, {"text": "reports on the results of tagging on the development and test set.", "labels": [], "entities": []}, {"text": "Our neural tagger clearly beats all the baselines taken as lower bound, considering both tagsets.", "labels": [], "entities": []}, {"text": "In order to understand the performance of our models at predicting each single feature, the morphological labels were split into their components and performance is measured according to the following metrics: \u2022 F1-score A.", "labels": [], "entities": [{"text": "F1-score A", "start_pos": 212, "end_pos": 222, "type": "METRIC", "confidence": 0.8949195444583893}]}, {"text": "Performance is measured only across word classes which present the given feature in the gold.", "labels": [], "entities": []}, {"text": "For example, degree is measured only in adjectives.", "labels": [], "entities": [{"text": "degree", "start_pos": 13, "end_pos": 19, "type": "METRIC", "confidence": 0.9830005168914795}]}, {"text": "Performance is measured across all word classes.", "labels": [], "entities": []}, {"text": "If a given feature is not predicted fora label, or it is not present in the gold annotation, its value is set to an artificial NNN class.", "labels": [], "entities": []}, {"text": "In this way, features which are correctly not predicted by the system, such as gender for verbs, count as true positives.", "labels": [], "entities": []}, {"text": "Results of this evaluation are reported in.", "labels": [], "entities": []}, {"text": "The overall feature performance is satisfactory inline with both evaluation criteria.", "labels": [], "entities": []}, {"text": "The performance scores for all features are slightly improved using the model predicting POS+morph labels.", "labels": [], "entities": []}, {"text": "In fact, as POS tags are indicators of word classes, jointly predicting them with the morphological labels could help the system learn which features should be predicted and which should not be produced.", "labels": [], "entities": []}, {"text": "Considering evaluation of type A, the best results are obtained for the gender feature.", "labels": [], "entities": []}, {"text": "Contrary to what happens for the other features, gender constitutes a lexical attribute of nouns, and an inflectional feature for other nominal constituents.", "labels": [], "entities": []}, {"text": "This could have had the effect of simplifying the classification problem for nouns, thus also strengthening performance on dependent tokens, such as determiners and adjectives.", "labels": [], "entities": []}, {"text": "Moving to evaluation of type B, an overall enhancement in performance can be observed for all features, suggesting that the systems are successfully able to learn when a certain morphological feature should be predicted or not.", "labels": [], "entities": []}, {"text": "In general, the performance of tagging with respect to single morphological features seems to highly depend on the distributional characteristics of the corpus, as well as on the relative balance within a single feature's values.", "labels": [], "entities": []}, {"text": "Highest performance is obtained on the morphological features which present the highest support in the training set.", "labels": [], "entities": []}, {"text": "reports the confusion: Normalized confusion matrices considering the morphological features gender, number, case, and tense.", "labels": [], "entities": []}, {"text": "The value NNN refers to morphological labels where the given feature is not present in gold or predicted by the system, while * indicates that the given feature is present or predicted, but undefined.", "labels": [], "entities": []}, {"text": "matrices of case and gender, two highly frequent morphological features which distinguish between the highest number of possible values.", "labels": [], "entities": []}, {"text": "Considering case, the tagger was able to learn to discriminate relatively well between the four cases, due to their distributionally different characteristics.", "labels": [], "entities": []}, {"text": "The highest number of misclassifications occurs between Nom and Acc, which present some similar distributional patterns in the German language.", "labels": [], "entities": [{"text": "Acc", "start_pos": 64, "end_pos": 67, "type": "DATASET", "confidence": 0.5958969593048096}]}, {"text": "Excluding the * value, which occurs with a support lower than 1%, the lowest performance is obtained on Gen, which is also the less frequent value for this morphological feature.", "labels": [], "entities": [{"text": "Gen", "start_pos": 104, "end_pos": 107, "type": "DATASET", "confidence": 0.8867404460906982}]}, {"text": "Moving to gender, the best performance is achieved with Fem.", "labels": [], "entities": []}, {"text": "This is not only the most frequent value, but also the gender which contains most of the substantives obtained through derivational morphology, thus presenting a pattern which can be easily spotted by the suffix feature.", "labels": [], "entities": []}, {"text": "In contrast, misclassifications are more common in case of morphological features which present a high class imbalance, especially when the classes tend to appear in similar context.", "labels": [], "entities": []}, {"text": "This is exemplified by the features number and tense, whose confusion matrices are reported in.", "labels": [], "entities": []}, {"text": "In the case of number, the morphological feature with the highest support, our tagger tends to misclassify Plur occurrences in favour of the most frequent value Sing, which occurs roughly twice as often.", "labels": [], "entities": []}, {"text": "The same pattern can be observed also in the confusion matrix of tense, a feature with a considerably lower support in the training corpus (as it occurs only for verbs).", "labels": [], "entities": []}, {"text": "Here, the extreme feature imbalance induces the system to wrongly label almost half of the Past occurrences as Pres, which accounts alone for almost 85% of the training samples.", "labels": [], "entities": []}, {"text": "Inflection generation, also called morphology generation, is the NLP task of generating an inflected word from its lemma paired with its morphological tag.", "labels": [], "entities": [{"text": "Inflection generation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8248012065887451}, {"text": "morphology generation", "start_pos": 35, "end_pos": 56, "type": "TASK", "confidence": 0.7063351422548294}]}, {"text": "This task offers a nice opportunity for an extrinsic evaluation of our tagger's predictions.", "labels": [], "entities": []}, {"text": "We implemented an inexpensive lookup-based inflection generation system.", "labels": [], "entities": [{"text": "lookup-based inflection generation", "start_pos": 30, "end_pos": 64, "type": "TASK", "confidence": 0.6887461940447489}]}, {"text": "At each position i, the inflected word w i corresponding to the lemma l i is produced according to the following chain of backoff operations: 4.", "labels": [], "entities": []}, {"text": "Lemma unigram: max 5.", "labels": [], "entities": []}, {"text": "Unseen lemma: where ti corresponds to the POS+morph label predicted by our tagger.", "labels": [], "entities": []}, {"text": "Lookup tables are calculated over the training corpus.", "labels": [], "entities": []}, {"text": "We build neural machine translation engines to evaluate the pipelined MT approach as illustrated in.", "labels": [], "entities": [{"text": "neural machine translation", "start_pos": 9, "end_pos": 35, "type": "TASK", "confidence": 0.7087126771608988}, {"text": "MT", "start_pos": 70, "end_pos": 72, "type": "TASK", "confidence": 0.9283520579338074}]}, {"text": "For comparison, a baseline NMT system translates directly from English to fully inflected German word surface forms.", "labels": [], "entities": []}, {"text": "The pipelined architecture from is evaluated against this baseline.", "labels": [], "entities": []}, {"text": "For the pipelined architecture, we train an NMT engine on a parallel corpus with lemmatized German target side.", "labels": [], "entities": []}, {"text": "At test time, the latter engine performs the first step (MT from English words to German lemmas) in the pipeline.", "labels": [], "entities": [{"text": "MT from English words", "start_pos": 57, "end_pos": 78, "type": "TASK", "confidence": 0.8502658754587173}]}, {"text": "The second step is conducted by our tagger, which annotates the lemma hypothesis translation with morphological tags.", "labels": [], "entities": []}, {"text": "Finally, the lookup-based inflection generator from Section 4.2 is employed to map the paired lemmas and predicted morphological tags to inflected German words.", "labels": [], "entities": []}, {"text": "We use the Nematus toolkit's implementation of encoder-decoder NMT with attention and GRUs (.", "labels": [], "entities": [{"text": "GRUs", "start_pos": 86, "end_pos": 90, "type": "METRIC", "confidence": 0.9189376831054688}]}, {"text": "We train and test on the English-German Europarl data.", "labels": [], "entities": [{"text": "Europarl data", "start_pos": 40, "end_pos": 53, "type": "DATASET", "confidence": 0.8904594779014587}]}, {"text": "In the NMT systems' training corpus, words are tokenized and frequent-cased, then segmented via byte-pair-encoding (BPE) () with 50K merge operations; likewise for lemmas, but with BPE operations extracted from the lemmatized data.", "labels": [], "entities": [{"text": "BPE", "start_pos": 181, "end_pos": 184, "type": "METRIC", "confidence": 0.9318735003471375}]}, {"text": "We configure dimensions of 500 for the embeddings and 1024 for the hidden layer.", "labels": [], "entities": []}, {"text": "We train with the Adam optimizer, a learning rate of 0.0001, batch size of 50, and dropout with probability 0.2 applied to the hidden layer.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 36, "end_pos": 49, "type": "METRIC", "confidence": 0.9198663234710693}]}, {"text": "Translation quality is measured case-sensitive with BLEU ().", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9485898017883301}, {"text": "BLEU", "start_pos": 52, "end_pos": 56, "type": "METRIC", "confidence": 0.9988709092140198}]}, {"text": "In, we use BLEU computed on lemmas (Lemma-BLEU), to show that we get a small gain in lexical choice (of the lemma) in the pipelined approach, where the NMT engine is trained to produce lemmas.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.9969700574874878}]}, {"text": "However, the BLEU scores over fully inflected words in suggest that a simple pipelined approach is not sufficient for end-to-end MT.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 13, "end_pos": 17, "type": "METRIC", "confidence": 0.9993767142295837}, {"text": "MT", "start_pos": 129, "end_pos": 131, "type": "TASK", "confidence": 0.9640300869941711}]}, {"text": "We looked at the MT output and saw that it was mostly coherent, but there was confusion on features like number, tense, and mood.", "labels": [], "entities": [{"text": "MT output", "start_pos": 17, "end_pos": 26, "type": "DATASET", "confidence": 0.8493311405181885}]}, {"text": "The slightly improved lexical choice of the lemma does not compensate for the loss that derives from the inherent limitations of completely decoupling lemma prediction and morphology prediction, as was discussed intuitively in Section 2.2 and later highlighted in detail empirically (Section 4.1,,).", "labels": [], "entities": [{"text": "decoupling lemma prediction", "start_pos": 140, "end_pos": 167, "type": "TASK", "confidence": 0.7437819639841715}, {"text": "morphology prediction", "start_pos": 172, "end_pos": 193, "type": "TASK", "confidence": 0.8583929240703583}]}, {"text": "The neural architecture yields surprisingly strong accuracy at morphological tagging of lemma sequences, but the pipelined approach from with completely underspecified lemma sequences and strict decoupling of the different components is too limiting for MT.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9960098266601562}, {"text": "MT", "start_pos": 254, "end_pos": 256, "type": "TASK", "confidence": 0.9883707761764526}]}], "tableCaptions": [{"text": " Table 3: Hyperparameters of the network.", "labels": [], "entities": []}, {"text": " Table 4: Accuracy obtained on morphological tagging of lemmas considering morph and  POS+morph tagsets.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9742851853370667}]}, {"text": " Table 5: Performance of tagging considering single morphological features. Support is defined  as the number of labels where a given feature is defined, divided by the total number of labels  in the training set.", "labels": [], "entities": [{"text": "tagging", "start_pos": 25, "end_pos": 32, "type": "TASK", "confidence": 0.9756832122802734}, {"text": "Support", "start_pos": 76, "end_pos": 83, "type": "METRIC", "confidence": 0.984926700592041}]}, {"text": " Table 7: Quality of lemma translation. Base- line hypothesis translations and references  have been lemmatized with LEMMING.", "labels": [], "entities": [{"text": "lemma translation", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.698395699262619}, {"text": "LEMMING", "start_pos": 117, "end_pos": 124, "type": "METRIC", "confidence": 0.994844913482666}]}, {"text": " Table 8: Machine translation quality. We  report case-sensitive BLEU of fully inflected,  postprocessed translations.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.7234739065170288}, {"text": "BLEU", "start_pos": 65, "end_pos": 69, "type": "METRIC", "confidence": 0.9813319444656372}]}]}