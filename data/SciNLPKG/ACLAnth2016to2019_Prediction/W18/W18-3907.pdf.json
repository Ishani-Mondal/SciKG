{"title": [{"text": "Iterative Language Model Adaptation for Indo-Aryan Language Identification", "labels": [], "entities": [{"text": "Iterative Language Model Adaptation", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.6069527789950371}, {"text": "Indo-Aryan Language Identification", "start_pos": 40, "end_pos": 74, "type": "TASK", "confidence": 0.6449946065743765}]}], "abstractContent": [{"text": "This paper presents the experiments and results obtained by the SUKI team in the Indo-Aryan Language Identification shared task of the VarDial 2018 Evaluation Campaign.", "labels": [], "entities": [{"text": "Indo-Aryan Language Identification shared task", "start_pos": 81, "end_pos": 127, "type": "TASK", "confidence": 0.8102976202964782}, {"text": "VarDial 2018 Evaluation Campaign", "start_pos": 135, "end_pos": 167, "type": "DATASET", "confidence": 0.8185659497976303}]}, {"text": "The shared task was an open one, but we did not use any corpora other than what was distributed by the organizers.", "labels": [], "entities": []}, {"text": "A total of eight teams provided results for this shared task.", "labels": [], "entities": []}, {"text": "Our submission using a HeLI-method based language identifier with iterative language model adaptation obtained the best results in the shared task with a macro F1-score of 0.958.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 160, "end_pos": 168, "type": "METRIC", "confidence": 0.7229059338569641}]}], "introductionContent": [{"text": "In the past, the VarDial workshops have hosted several different shared tasks related to language identification and especially the identification of close languages, language varieties, and dialects ().", "labels": [], "entities": [{"text": "language identification", "start_pos": 89, "end_pos": 112, "type": "TASK", "confidence": 0.7187954634428024}]}, {"text": "The fifth VarDial workshop included for the first time a shared task for Indo-Aryan language identification (ILI) ( . The goal of the shared task was to identify the language used in unlabeled texts written in Hindi and four related languages using the Devanagari script: Bhojpuri, Awadhi, Magahi, and Braj.", "labels": [], "entities": [{"text": "Indo-Aryan language identification (ILI)", "start_pos": 73, "end_pos": 113, "type": "TASK", "confidence": 0.7879079580307007}]}, {"text": "We have participated in the shared tasks of three previous VarDial workshops using systems based on different variations of the HeLI method ().", "labels": [], "entities": []}, {"text": "The HeLI method has turned out to be robust and competitive with other state-of-the-art language identification methods, gaining shared first place in the VarDial 2016 Discriminating between Similar Languages (DSL) shared task.", "labels": [], "entities": [{"text": "language identification", "start_pos": 88, "end_pos": 111, "type": "TASK", "confidence": 0.7686826288700104}, {"text": "VarDial 2016 Discriminating between Similar Languages (DSL) shared task", "start_pos": 155, "end_pos": 226, "type": "TASK", "confidence": 0.5962744138457559}]}, {"text": "The HeLI method is not especially tailored to be a dialect identification method, but it is a general purpose language identification method capable of distinguishing between hundreds of languages, some of which might be very close to each other ().", "labels": [], "entities": [{"text": "dialect identification", "start_pos": 51, "end_pos": 73, "type": "TASK", "confidence": 0.7470957338809967}, {"text": "language identification", "start_pos": 110, "end_pos": 133, "type": "TASK", "confidence": 0.7565904855728149}]}, {"text": "In the Kone foundation funded Finno-Ugric Languages and the Internet project, a language identifier implementing the HeLI method has been used together with the Heritrix web-crawler to collect text in Uralic languages from the internet ().", "labels": [], "entities": []}, {"text": "The language identifier using the HeLI method is available for download in GitHub 1 . In the current workshop, we wanted to tryout some new variations and possible improvements to the original method.", "labels": [], "entities": []}, {"text": "For the ILI task, we used the basic HeLI method, HeLI with adaptive language models, as well as an iterative version of the language model adaptation method.", "labels": [], "entities": []}], "datasetContent": [{"text": "We experimented with leaving out shorter lowercased n-grams with n max = 6.", "labels": [], "entities": []}, {"text": "Leaving out character unigrams and bigrams did not affect the recall, but leaving out trigrams dropped the recall to 94.53% indicating that the HeLI back-off function is also needed for these languages.", "labels": [], "entities": [{"text": "recall", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.9993427395820618}, {"text": "recall", "start_pos": 107, "end_pos": 113, "type": "METRIC", "confidence": 0.9996161460876465}]}, {"text": "With the German dialect identification task we ended up using only 4-grams of characters.", "labels": [], "entities": [{"text": "German dialect identification", "start_pos": 9, "end_pos": 38, "type": "TASK", "confidence": 0.646610846122106}]}, {"text": "We also experimented with an unsupervised language set adaptation method.", "labels": [], "entities": [{"text": "language set adaptation", "start_pos": 42, "end_pos": 65, "type": "TASK", "confidence": 0.680362602074941}]}, {"text": "In unsupervised language set adaptation, the mystery text is first identified using all the available languages.", "labels": [], "entities": [{"text": "language set adaptation", "start_pos": 16, "end_pos": 39, "type": "TASK", "confidence": 0.7500059008598328}]}, {"text": "The language with the worst score is left out and the text re-identified with the remaining languages.", "labels": [], "entities": []}, {"text": "The process is continued until only one language is left.", "labels": [], "entities": []}, {"text": "Ina non-discriminative language identification method, the effect of leaving out languages with the worst scores does not affect the order of the top scoring languages.", "labels": [], "entities": [{"text": "language identification", "start_pos": 23, "end_pos": 46, "type": "TASK", "confidence": 0.7721402943134308}]}, {"text": "However, if the back-off function of the HeLI method is used, it gives equal penalty values to those languages in which a word is not found.", "labels": [], "entities": []}, {"text": "If the word was found in an otherwise poorly scoring language, which was subsequently left out, the following run might use the back-off function with the word in question and find a difference between the better candidates using character n-grams.", "labels": [], "entities": []}, {"text": "We expected the effect to be small, and it turned out to be slightly negative reducing the recall from 95.26% to 95.22%.", "labels": [], "entities": [{"text": "recall", "start_pos": 91, "end_pos": 97, "type": "METRIC", "confidence": 0.9986447691917419}]}, {"text": "We, furthermore, evaluated the same non-linear mappings, the gamma and the loglike functions, we used in the DSL shared task at.", "labels": [], "entities": [{"text": "DSL shared task", "start_pos": 109, "end_pos": 124, "type": "TASK", "confidence": 0.6768876910209656}]}, {"text": "The experiments with the gamma function ended up with the same recall of 95.26% as the original method.", "labels": [], "entities": [{"text": "recall", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.9993981122970581}]}, {"text": "Several different trials with loglike functions fell short of the recall of the original method at 95.25%.", "labels": [], "entities": [{"text": "recall", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.9997207522392273}]}], "tableCaptions": [{"text": " Table 1. The size of the training material was considerably smaller for the  Awadhi language at slightly over 9,000 lines compared with the others which were around 15,000 long.  The difference in size of the training material might produce problems for some methods that have been  used for language identification. The HeLI method has turned out to be very robust in this respect, so we  did not need to take this into any special consideration.", "labels": [], "entities": [{"text": "language identification", "start_pos": 293, "end_pos": 316, "type": "TASK", "confidence": 0.7146449238061905}]}, {"text": " Table 1: List of languages with the sizes of their training and development sets.", "labels": [], "entities": []}, {"text": " Table 2. \"Original n max \" refers to the maximum size used with the original n-grams and  \"Lowercased n max \" to the size used with the lowercased n-grams. The differences in recall between the  combinations are not very high.", "labels": [], "entities": [{"text": "recall", "start_pos": 176, "end_pos": 182, "type": "METRIC", "confidence": 0.9990131855010986}]}, {"text": " Table 2: Baseline HeLI recall in development data with different combinations of parameters.", "labels": [], "entities": [{"text": "HeLI", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.6899455189704895}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.7357740998268127}]}, {"text": " Table 3: Macro F1 scores obtained by different runs submitted by the SUKI-team (bolded) and the best  runs of the other teams.", "labels": [], "entities": [{"text": "F1 scores", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9437854886054993}, {"text": "SUKI-team", "start_pos": 70, "end_pos": 79, "type": "DATASET", "confidence": 0.8424725532531738}]}]}