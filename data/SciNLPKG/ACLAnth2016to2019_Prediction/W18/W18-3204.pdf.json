{"title": [{"text": "Code-Mixed Question Answering Challenge: Crowd-sourcing Data and Techniques", "labels": [], "entities": [{"text": "Code-Mixed Question Answering Challenge", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.6361305564641953}]}], "abstractContent": [{"text": "Code-Mixing (CM) is the phenomenon of alternating between two or more languages which is prevalent in bi-and multilingual communities.", "labels": [], "entities": [{"text": "Code-Mixing (CM)", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.5788685977458954}]}, {"text": "Most NLP applications today are still designed with the assumption of a single interaction language and are most likely to break given a CM utterance with multiple languages mixed at a morphological , phrase or sentence level.", "labels": [], "entities": []}, {"text": "For example , popular commercial search engines do not yet fully understand the intents expressed in CM queries.", "labels": [], "entities": []}, {"text": "As a first step towards fostering research which supports CM in NLP applications , we systematically crowd-sourced and curated an evaluation dataset for factoid question answering in three CM languages-Hinglish (Hindi+English), Tenglish (Telugu+English) and Tamlish (Tamil+English) which belong to two language families.", "labels": [], "entities": [{"text": "factoid question answering", "start_pos": 153, "end_pos": 179, "type": "TASK", "confidence": 0.7660428682963053}]}, {"text": "We share the details of our data collection process, techniques which were used to avoid inducing lexical bias amongst the crowd workers and other CM specific linguistic properties of the dataset.", "labels": [], "entities": []}, {"text": "Our final dataset, which is available freely for research purposes, has 1,694 Hinglish, 2,848 Tamlish and 1,391 Tenglish factoid questions and their answers.", "labels": [], "entities": [{"text": "Hinglish", "start_pos": 78, "end_pos": 86, "type": "DATASET", "confidence": 0.8516141772270203}, {"text": "Tamlish", "start_pos": 94, "end_pos": 101, "type": "METRIC", "confidence": 0.7416990399360657}]}, {"text": "We discuss the techniques used by the participants for the first edition of this ongoing challenge.", "labels": [], "entities": []}], "introductionContent": [{"text": "Code-Mixing (CM) is formally defined as the embedding of linguistic units such as phrases, words, and morphemes of one language into an utterance of another language, which is commonly observed in multilingual communities (),,).", "labels": [], "entities": [{"text": "Code-Mixing (CM)", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.5898173078894615}]}, {"text": "Traditionally, some studies () have viewed the mixing of two independent codes as lack of fluency of the segment of population in either of the languages.", "labels": [], "entities": []}, {"text": "However, an alternate perspective argues that mixing of two traditionally isolated linguistic codes potentially creates a third legitimate code.", "labels": [], "entities": []}, {"text": "Researchers have also presented several sociocultural reasons and motivations for switching.", "labels": [], "entities": []}, {"text": "There have been studies to depict the usage of particular language based on the emotional attachment and the sentiment of the person towards that topic (.", "labels": [], "entities": []}, {"text": "In this paper, we adopt the perspective of descriptive linguistics and make an effort to describe this prevalent form of language as it occurs, without adopting a prescriptive approach.", "labels": [], "entities": [{"text": "descriptive linguistics", "start_pos": 43, "end_pos": 66, "type": "TASK", "confidence": 0.7787599563598633}]}, {"text": "Ubiquitous access to social media tools and platforms have also made CM the preferred choice for both formal and informal communication.", "labels": [], "entities": []}, {"text": "In such settings, where the communication is either semi-formal or informal, researchers (( ), () have observed a higher tendency for multilingual speakers to use CM.", "labels": [], "entities": []}, {"text": "We studied a sample of conversation logs from a commercial chitchat based conversational agent in the Indian market.", "labels": [], "entities": []}, {"text": "The agent was trained to engage in informal chat conversations with the help of a database of Twitter conversations from the Indian market.", "labels": [], "entities": []}, {"text": "Since India is a multilingual country with a large number of multilingual speakers, we notice that users often freely use each language individually or their CM versions while conversing with the agent.", "labels": [], "entities": []}, {"text": "We notice that, in around 3% of overall conversations, users were found to be chatting with the agent in CM language such as 'hello, kya chal raha hai' (Meaning: hello, what's up?).", "labels": [], "entities": []}, {"text": "Interestingly, in cases where the response of the agent was in CM language such as 'sorry yaar' (Meaning: sorry friend), users too responded back in CM language in 27% of those times.", "labels": [], "entities": []}, {"text": "There have been other studies regarding the quantitative and qualitative aspects of codeswitching on social media along similar lines).", "labels": [], "entities": []}, {"text": "However, a large number of NLP applications, such as Question Answering (QA), Dialogue Systems, Summarization etc, still continue to be designed with the assumption of a single interaction language such as English (), Hindi ((), Chinese ((,).", "labels": [], "entities": [{"text": "Question Answering (QA)", "start_pos": 53, "end_pos": 76, "type": "TASK", "confidence": 0.8681629419326782}, {"text": "Summarization", "start_pos": 96, "end_pos": 109, "type": "TASK", "confidence": 0.9703174829483032}]}, {"text": "Such systems are most likely to break given a CM utterance which has multiple languages mixed at sentence, phrase or morphological level.", "labels": [], "entities": []}, {"text": "Hence, it is highly imperative for researchers to focus on building more robust end-user NLP applications which can understand and process CM language.", "labels": [], "entities": []}, {"text": "Building a good evaluation dataset for Factoid QA in CM is wrought with challenges such as a) ensuring that the annotators are unbiased in anyway to artificially use CM b) recruiting a good team of native bi-lingual speakers as annotators c) maintaining a good quality and diversity of questions across intents, answer types and entities.", "labels": [], "entities": []}, {"text": "In this paper, we describe our experience in dealing with the above challenges while creating the dataset.", "labels": [], "entities": []}, {"text": "We used a crowd-sourcing platform for collecting data where the crowd workers were restricted to only native language (Hindi, Telugu and Tamil) speakers.", "labels": [], "entities": []}, {"text": "We shared a detailed set of guidelines and instructions about the task with the crowd workers and also ran them through some basic quality checks before collection of actual data.", "labels": [], "entities": []}, {"text": "Finally, we were able to collect around 1,694 Hinglish, 2,848 Tamlish and 1,391 Tenglish factoid questions along with their answers.", "labels": [], "entities": [{"text": "Hinglish", "start_pos": 46, "end_pos": 54, "type": "DATASET", "confidence": 0.9441935420036316}]}, {"text": "We have organized a Code-Mixed Question Answering challenge based on this data for the first edition of this challenge.", "labels": [], "entities": [{"text": "Code-Mixed Question Answering challenge", "start_pos": 20, "end_pos": 59, "type": "TASK", "confidence": 0.6865241304039955}]}, {"text": "There are 7 teams that registered and took the data from us.", "labels": [], "entities": []}, {"text": "In this paper, we discuss the preliminary techniques that 2 of these groups used.", "labels": [], "entities": []}, {"text": "To summarize, the following are the main contributions of this paper: \u2022 We curated an evaluation dataset for the task of Factoid QA in CM languages with more than 5000 QA pairs for Hinglish, Tamlish and Tenglish languages.", "labels": [], "entities": [{"text": "Factoid QA", "start_pos": 121, "end_pos": 131, "type": "TASK", "confidence": 0.7545610964298248}, {"text": "Hinglish", "start_pos": 181, "end_pos": 189, "type": "DATASET", "confidence": 0.9255732297897339}, {"text": "Tenglish languages", "start_pos": 203, "end_pos": 221, "type": "DATASET", "confidence": 0.7644126713275909}]}, {"text": "We also make it freely available for research purposes.", "labels": [], "entities": []}, {"text": "\u2022 We share our experiences related to eliciting lexically unbiased CM questions by using images as anchor points.", "labels": [], "entities": []}, {"text": "\u2022 We present the techniques used in the first edition of the CM QA challenge.", "labels": [], "entities": [{"text": "CM QA challenge", "start_pos": 61, "end_pos": 76, "type": "TASK", "confidence": 0.5190330743789673}]}], "datasetContent": [{"text": "In order to study differences between lexical bias from entrainment and elicit lexically diverse questions, we employ two modes of data collection: eliciting code-mixed questions from a) images and b) code-mixed articles.", "labels": [], "entities": []}, {"text": "The former are general questions and the latter are context specific questions (similar to machine reading).", "labels": [], "entities": []}, {"text": "Techniques of collecting queries fora dialog system by presenting scenarios symbolically and diagrammatically was previously used) in order to minimize supplying lexical and phrasal cues.", "labels": [], "entities": []}, {"text": "For collection of Hinglish data, we used both these approaches whereas for collecting Tenglish and Tamlish data, we used only images.", "labels": [], "entities": [{"text": "Hinglish data", "start_pos": 18, "end_pos": 31, "type": "DATASET", "confidence": 0.8882216215133667}, {"text": "Tenglish and Tamlish data", "start_pos": 86, "end_pos": 111, "type": "DATASET", "confidence": 0.7148022279143333}]}, {"text": "This is because for Hinglish, we could find informative blogging websites based on which it is easier to frame factoid code-mixed questions.", "labels": [], "entities": [{"text": "Hinglish", "start_pos": 20, "end_pos": 28, "type": "DATASET", "confidence": 0.9358832836151123}]}, {"text": "However, to the best of our knowledge, during the time of our annotation, such fact based code-mixed content was still not available in Tenglish/Tamlish.", "labels": [], "entities": [{"text": "Tenglish/Tamlish", "start_pos": 136, "end_pos": 152, "type": "DATASET", "confidence": 0.8717151085535685}]}, {"text": "It is also noted that it is less likely to get questions that have abstract answers (beyond the realm of physical entities) when they are collected based on images.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1:  Data Statistics: The code-mixing metrics for Hinglish (Hindi+English), Tamlish  (Tamil+English) and Tenglish (Telugu+English) questions", "labels": [], "entities": [{"text": "Hinglish", "start_pos": 56, "end_pos": 64, "type": "DATASET", "confidence": 0.9508430361747742}, {"text": "Tamlish", "start_pos": 82, "end_pos": 89, "type": "METRIC", "confidence": 0.8749756217002869}, {"text": "Tenglish (Telugu+English)", "start_pos": 111, "end_pos": 136, "type": "TASK", "confidence": 0.5040411353111267}]}]}