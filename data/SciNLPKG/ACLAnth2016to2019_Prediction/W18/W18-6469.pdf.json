{"title": [{"text": "DFKI-MLT System Description for the WMT18 Automatic Post-editing Task", "labels": [], "entities": [{"text": "DFKI-MLT", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8615286350250244}, {"text": "WMT18", "start_pos": 36, "end_pos": 41, "type": "DATASET", "confidence": 0.7002846598625183}]}], "abstractContent": [{"text": "This paper presents the Automatic Post-editing (APE) systems submitted by the DFKI-MLT group to the WMT'18 APE shared task.", "labels": [], "entities": [{"text": "DFKI-MLT", "start_pos": 78, "end_pos": 86, "type": "DATASET", "confidence": 0.9239377975463867}, {"text": "WMT'18 APE shared task", "start_pos": 100, "end_pos": 122, "type": "TASK", "confidence": 0.7022558897733688}]}, {"text": "Three monolingual neural sequence-to-sequence APE systems were trained using target-language data only: one using an at-tentional recurrent neural network architecture and two using the attention-only (trans-former) architecture.", "labels": [], "entities": [{"text": "APE", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.8980152010917664}]}, {"text": "The training data was composed of machine translated (MT) output used as source to the APE model aligned with their manually post-edited version or reference translation as target.", "labels": [], "entities": []}, {"text": "We made use of the provided training sets only and trained APE models applicable to phrase-based and neural MT outputs.", "labels": [], "entities": [{"text": "APE", "start_pos": 59, "end_pos": 62, "type": "TASK", "confidence": 0.7541048526763916}, {"text": "MT outputs", "start_pos": 108, "end_pos": 118, "type": "TASK", "confidence": 0.7646512091159821}]}, {"text": "Results show better performances reached by the attention-only model over the recurrent one, significant improvement over the baseline when post-editing phrase-based MT output but degradation when applied to neural MT output.", "labels": [], "entities": []}], "introductionContent": [{"text": "For the 2018 edition of the WMT automatic postediting (APE) task, two novelties were added compared to the previous editions: post-editing of neural machine translation (NMT) output in addition to phrase-based (PBMT) output, and the availability of larger training sets.", "labels": [], "entities": [{"text": "WMT automatic postediting (APE) task", "start_pos": 28, "end_pos": 64, "type": "TASK", "confidence": 0.8907836249896458}, {"text": "post-editing of neural machine translation (NMT) output", "start_pos": 126, "end_pos": 181, "type": "TASK", "confidence": 0.7911794781684875}]}, {"text": "The DFKI-MLT systems developed for this shared task aimed at handling outputs from PBMT and NMT jointly with a single APE model.", "labels": [], "entities": []}, {"text": "This was achieved by using artificial tokens indicating which type of MT system was used to produce the source segment and from which corpus the segment pair was extracted (inspired by).", "labels": [], "entities": [{"text": "MT", "start_pos": 70, "end_pos": 72, "type": "TASK", "confidence": 0.9693710803985596}]}, {"text": "Two NMT architectures were used to train our APE models, one using gated recurrent layers with global attention (, and one using attention and feed-forward layers without recurrence ().", "labels": [], "entities": [{"text": "APE", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.8991178870201111}]}, {"text": "The training data was composed of the official training set released by the shared task organizers plus subsets of the two additional resources filtered with bilingual cross-entropy difference).", "labels": [], "entities": []}, {"text": "The NMT architectures are described in Section 2 and the data preparation process is presented in Section 3.", "labels": [], "entities": [{"text": "data preparation", "start_pos": 57, "end_pos": 73, "type": "TASK", "confidence": 0.7163600325584412}]}, {"text": "The results obtained by our APE models are compared to the baseline in Section 4.", "labels": [], "entities": [{"text": "APE", "start_pos": 28, "end_pos": 31, "type": "DATASET", "confidence": 0.6748654246330261}]}, {"text": "Finally, a conclusion is given in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "The three APE models trained for the shared task were used to post-edit the test set released by the organizers.", "labels": [], "entities": []}, {"text": "Automatic evaluation with BLEU) and TER () was conducted by the organizers and the obtained scores on the official test set are reported in Table 1.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 26, "end_pos": 30, "type": "METRIC", "confidence": 0.9990035891532898}, {"text": "TER", "start_pos": 36, "end_pos": 39, "type": "METRIC", "confidence": 0.9992547631263733}]}, {"text": "The automatic metrics results are obtained by comparing each system output to the manually post-edited MT output (TER pe and BLEU pe ), to an independent translation (TER ref and BLEU ref ) and finally using both post-edited MT output and independent translation simultaneously as a multireference evaluation approach (TER pe+ref and BLEU pe+ref ).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 125, "end_pos": 129, "type": "METRIC", "confidence": 0.9787089228630066}, {"text": "TER ref", "start_pos": 167, "end_pos": 174, "type": "METRIC", "confidence": 0.9370880424976349}, {"text": "BLEU", "start_pos": 179, "end_pos": 183, "type": "METRIC", "confidence": 0.8324890732765198}, {"text": "BLEU", "start_pos": 334, "end_pos": 338, "type": "METRIC", "confidence": 0.9927778840065002}]}, {"text": "The results obtained by the nonpost-edited MT output is presented as a baseline.", "labels": [], "entities": [{"text": "MT", "start_pos": 43, "end_pos": 45, "type": "TASK", "confidence": 0.9564144611358643}]}], "tableCaptions": [{"text": " Table 1: Automatic metrics results on the test set obtained by our APE models and compared to the baseline using  three evaluation methods. Result in bold indicates significant improvement over the baseline.", "labels": [], "entities": [{"text": "APE", "start_pos": 68, "end_pos": 71, "type": "DATASET", "confidence": 0.7316066026687622}]}]}