{"title": [{"text": "Sentence Packaging in Text Generation from Semantic Graphs as a Community Detection Problem", "labels": [], "entities": [{"text": "Sentence Packaging in Text Generation", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.7366099894046784}]}], "abstractContent": [{"text": "An increasing amount of research tackles the challenge of text generation from abstract ontological or semantic structures, which are in their very nature potentially large connected graphs.", "labels": [], "entities": [{"text": "text generation from abstract ontological or semantic structures", "start_pos": 58, "end_pos": 122, "type": "TASK", "confidence": 0.7823596894741058}]}, {"text": "These graphs must be \"packaged\" into sentence-wise subgraphs.", "labels": [], "entities": []}, {"text": "We interpret the problem of sentence packaging as a community detection problem with post optimization.", "labels": [], "entities": [{"text": "sentence packaging", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.7471702098846436}]}, {"text": "Experiments on the texts of the Verb-Net/FrameNet structure annotated-Penn Treebank, which have been converted into graphs by a coreference merge using Stan-ford CoreNLP, show a high F 1-score of 0.738.", "labels": [], "entities": [{"text": "Verb-Net/FrameNet structure annotated-Penn Treebank", "start_pos": 32, "end_pos": 83, "type": "DATASET", "confidence": 0.8681593537330627}, {"text": "F 1-score", "start_pos": 183, "end_pos": 192, "type": "METRIC", "confidence": 0.9927993714809418}]}], "introductionContent": [{"text": "An increasing amount of research in Natural Language Text Generation (NLTG) tackles the challenge of generation from abstract ontological ( or semantic structures.", "labels": [], "entities": [{"text": "Natural Language Text Generation (NLTG)", "start_pos": 36, "end_pos": 75, "type": "TASK", "confidence": 0.7523090073040554}]}, {"text": "Unlike input structures to surface generation, which are syntactic trees, ontological and genuine semantic representations are predominantly connected graphs or collections of elementary statements (as, e.g., RDF-triples or minimal predicate-argument structures) in which re-occurring elements are duplicated (but which can be, again, considered to be a connected graph).", "labels": [], "entities": []}, {"text": "In both cases, the problem of the division of the graph into sentential subgraphs, which we will refer henceforth to as \"sentence packaging\", arises.", "labels": [], "entities": [{"text": "sentence packaging", "start_pos": 121, "end_pos": 139, "type": "TASK", "confidence": 0.7430587708950043}]}, {"text": "In the traditional generation task distribution, sentence packaging is largely avoided.", "labels": [], "entities": [{"text": "sentence packaging", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.811329573392868}]}, {"text": "It is assumed that the text planning module creates a text plan from selected elementary statements (elementary discourse units), establishing discourse relations between them.", "labels": [], "entities": []}, {"text": "The sentence planning module then either aggregates the elementary statements contained in the text plan into more complex statements or keeps them as separate simple statements, depending on the language, style, preferences of the targeted reader, etc..", "labels": [], "entities": []}, {"text": "Even if datadriven, as, e.g., in, this strategy may suggest itself mainly for input representations with a limited number of elementary elements and simple sentential structures as target.", "labels": [], "entities": []}, {"text": "In the context of scalable report (or any other narration) generation, which can be assumed to start, for instance, from large RDF-graphs (i.e., RDFtriples with cross-referenced elements), or from large semantic graphs, the aggregation challenge is incomparably more complex.", "labels": [], "entities": []}, {"text": "In the light of this challenge and the fact that in a narration the discourse structure is, as a rule, defined over sentential structures rather than elementary statements, sentence packaging on semantic representations appears as an alternative that is worth to be explored.", "labels": [], "entities": [{"text": "sentence packaging", "start_pos": 173, "end_pos": 191, "type": "TASK", "confidence": 0.7373852878808975}]}, {"text": "More recent data-driven concept-to-text approaches to NLTG, e.g.,), text simplification, e.g., , dialogue act realization, e.g.,, deal with sentence packaging, but, as a rule, all of them concern inputs of limited size, with at most 3 to 5 resulting sentence packages, while realistic large input semantic graphs may give rise to dozens.", "labels": [], "entities": [{"text": "dialogue act realization", "start_pos": 97, "end_pos": 121, "type": "TASK", "confidence": 0.6377224028110504}, {"text": "sentence packaging", "start_pos": 140, "end_pos": 158, "type": "TASK", "confidence": 0.7094435840845108}]}, {"text": "In what follows, we present a model for sentence packaging of large semantic graphs, which contain up to 75 sentences.", "labels": [], "entities": [{"text": "sentence packaging", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.7126764208078384}]}, {"text": "In general, the problem of sentence packaging consists in the optimal decomposition of a given graph into subgraphs, such that: (i) each subgraph is in itself a connected graph; (ii) the outgoing edges of the predicative vertices in a subgraph fulfil the valency conditions of these vertices (i.e., the obligatory arguments of a predicative vertice must be included in the subgraph); (iii) the appearance of a vertice in several subgraphs is subject to linguistic restrictions of co-reference.", "labels": [], "entities": [{"text": "sentence packaging", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.766803503036499}]}, {"text": "In graphtheoretical terms, sentence packaging can be thus viewed as an approximation of dense subgraph decomposition, which is a very prominent area of research in graph theory.", "labels": [], "entities": [{"text": "sentence packaging", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.7806499004364014}]}, {"text": "It has been also studied in the context of numerous applications, including biomedicine (e.g., for protein interaction network ( or brain connectivity analysis (), web mining (, influence analysis), community detection (, etc.", "labels": [], "entities": [{"text": "protein interaction network ( or brain connectivity analysis", "start_pos": 99, "end_pos": 159, "type": "TASK", "confidence": 0.6522729098796844}, {"text": "web mining", "start_pos": 164, "end_pos": 174, "type": "TASK", "confidence": 0.7858469486236572}, {"text": "influence analysis)", "start_pos": 178, "end_pos": 197, "type": "TASK", "confidence": 0.7999415695667267}, {"text": "community detection", "start_pos": 199, "end_pos": 218, "type": "TASK", "confidence": 0.7874963581562042}]}, {"text": "Our model is inspired by the work on community detection.", "labels": [], "entities": [{"text": "community detection", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.7385278046131134}]}, {"text": "The model has been validated in experiments on the VerbNet/FrameNet annotated version of the Penn TreeBank (, in which coreferences in the individual texts of the corpus have been identified using the Stanford CoreNLP toolkit () and fused to obtain a graph representation.", "labels": [], "entities": [{"text": "VerbNet/FrameNet annotated version of the Penn TreeBank", "start_pos": 51, "end_pos": 106, "type": "DATASET", "confidence": 0.7856108413802253}]}, {"text": "The experiments show that we achieve an F 1 -score of 0.738 (with a precision of 0.792 and a recall of 0.73), which means that our model is able to cope with the problem of sentence packaging in NLTG.", "labels": [], "entities": [{"text": "F 1 -score", "start_pos": 40, "end_pos": 50, "type": "METRIC", "confidence": 0.9901294559240341}, {"text": "precision", "start_pos": 68, "end_pos": 77, "type": "METRIC", "confidence": 0.9903604984283447}, {"text": "recall", "start_pos": 93, "end_pos": 99, "type": "METRIC", "confidence": 0.9994723200798035}, {"text": "sentence packaging", "start_pos": 173, "end_pos": 191, "type": "TASK", "confidence": 0.739327996969223}]}, {"text": "The remainder of the paper is structured as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we introduce the semantic graphs that are assumed to be decomposed and analyze them.", "labels": [], "entities": []}, {"text": "Section 3 outlines the experiments we carried out, and Section 4 discusses the outcome of these experiments.", "labels": [], "entities": []}, {"text": "In Section 5, we briefly review the work that is related to ours.", "labels": [], "entities": []}, {"text": "In Section 6, finally, we draw some conclusions and outline possible lines of future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We first began to experiment with three community detection algorithms:, METIS), and COPRA.", "labels": [], "entities": [{"text": "community detection", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.7329066097736359}, {"text": "METIS", "start_pos": 73, "end_pos": 78, "type": "METRIC", "confidence": 0.6745373010635376}]}, {"text": "However, already the first simple tests showed that COPRA performed poorly on our data in that it decomposed each graph into a small set of isolated subgraphs that did not include all the vertices of the original graph (see the exact figures below).", "labels": [], "entities": []}, {"text": "Therefore, we discarded COPRA from further experiments, while LOUVAIN and METIS were taken to serve as baselines.", "labels": [], "entities": [{"text": "COPRA", "start_pos": 24, "end_pos": 29, "type": "METRIC", "confidence": 0.9335945844650269}, {"text": "LOUVAIN", "start_pos": 62, "end_pos": 69, "type": "METRIC", "confidence": 0.9965458512306213}, {"text": "METIS", "start_pos": 74, "end_pos": 79, "type": "METRIC", "confidence": 0.9638684391975403}]}, {"text": "Since METIS requires as input the number of communities (= sentences) into which a given graph is to be decomposed, we use linear regression presented in Subsection 2.2.1 as preprocessing stage.", "labels": [], "entities": []}, {"text": "To improve the quality of the initial decomposition made using community detection algorithms (i.e., our baselines) we carried out a local descent search, adding neighbour vertices to each subgraph one by one and keeping them if the correspondence of the subgraph to the multivariate distribution increased.", "labels": [], "entities": []}, {"text": "The optimization is performed as a post-processing stage as follows: 1.", "labels": [], "entities": []}, {"text": "for each s \u2208 S, with S: = set of sentence subgraphs obtained by LOUVAIN / METIS (a) determine the degree of correspondence to the joint distribution (in case of several subgraphs, choose the most appropriate one) that is to be optimized.", "labels": [], "entities": [{"text": "LOUVAIN", "start_pos": 64, "end_pos": 71, "type": "METRIC", "confidence": 0.9957270622253418}, {"text": "METIS", "start_pos": 74, "end_pos": 79, "type": "METRIC", "confidence": 0.8992867469787598}]}, {"text": "(b) apply local descent search, adding nodes from s \u2208 S (with s = s) iteratively each time when it leads to the increase of the optimized parameter (subgraphs can share common nodes, i.e., overlap) 2.", "labels": [], "entities": [{"text": "local descent search", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.7226967215538025}]}, {"text": "stop local descent search when there is no node that improves s.", "labels": [], "entities": []}, {"text": "F 1 -score was chosen as a measure for the comparison of the quality of decompositions obtained by different algorithms on the test set.", "labels": [], "entities": [{"text": "F 1 -score", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9616728276014328}]}, {"text": "It is calculated for each original sentence since we consider a sentence as a separate unit.", "labels": [], "entities": []}, {"text": "Its value takes into account which part of the original sentence was covered by the obtained subgraph and how many nodes that did not belong to the original sentence were mistakenly appended.", "labels": [], "entities": []}, {"text": "Each isolated subgraph corresponds to one unit only, although it can include several original sentences.", "labels": [], "entities": []}, {"text": "For those original sentences that are not captured in the majority of their nodes in any individual subgraph, F 1 -score is equal to 0.", "labels": [], "entities": [{"text": "F 1 -score", "start_pos": 110, "end_pos": 120, "type": "METRIC", "confidence": 0.9880337566137314}]}, {"text": "The macro-F 1 , i.e. the average F 1 -score overall sentences, is a final measure.", "labels": [], "entities": [{"text": "F 1 -score", "start_pos": 33, "end_pos": 43, "type": "METRIC", "confidence": 0.9148766994476318}]}, {"text": "The results are displayed in.", "labels": [], "entities": []}, {"text": "'No decomposition' stands for the case when any graph in the test set is considered to be a sentence (it can be considered as an additional baseline); 'METIS LR ' for \"METIS with linear regression as a preprocessing stage\", 'DC K ' for \"descent search with K-means\", and 'DC \u00acK ' \"for descent search without K-means\".", "labels": [], "entities": [{"text": "METIS LR '", "start_pos": 152, "end_pos": 162, "type": "METRIC", "confidence": 0.8266974687576294}]}, {"text": "As already mentioned above, COPRA showed a very poor performance on our data.", "labels": [], "entities": []}, {"text": "The exact numbers were: mean recall = 0.113, mean precision = 0.088, and mean F 1 -score = 0.084).", "labels": [], "entities": [{"text": "mean", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.9791727066040039}, {"text": "recall", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.9134806394577026}, {"text": "mean", "start_pos": 45, "end_pos": 49, "type": "METRIC", "confidence": 0.9431668519973755}, {"text": "precision", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.7192610502243042}, {"text": "F 1 -score", "start_pos": 78, "end_pos": 88, "type": "METRIC", "confidence": 0.9277258515357971}]}, {"text": "Therefore, we did not include them into and did not combine COPRA with other techniques.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the features in the develop- ment set used for building up the linear regression  model", "labels": [], "entities": []}, {"text": " Table 2. 'No de- composition' stands for the case when any graph  in the test set is considered to be a sentence  (it can be considered as an additional baseline);  'METIS LR ' for \"METIS with linear regression as  a preprocessing stage\", 'DC K ' for \"descent search  with K-means\", and 'DC \u00acK ' \"for descent search  without K-means\".", "labels": [], "entities": [{"text": "METIS LR '", "start_pos": 167, "end_pos": 177, "type": "METRIC", "confidence": 0.8636035521825155}]}, {"text": " Table 2: Results of testing the obtained models", "labels": [], "entities": []}]}