{"title": [{"text": "Alibaba Submission for WMT18 Quality Estimation Task", "labels": [], "entities": [{"text": "WMT18 Quality Estimation", "start_pos": 23, "end_pos": 47, "type": "TASK", "confidence": 0.6683584749698639}]}], "abstractContent": [{"text": "The goal of WMT 2018 Shared Task on Translation Quality Estimation is to investigate automatic methods for estimating the quality of machine translation results without reference translations.", "labels": [], "entities": [{"text": "WMT 2018 Shared Task on Translation Quality Estimation", "start_pos": 12, "end_pos": 66, "type": "TASK", "confidence": 0.5674599222838879}]}, {"text": "This paper presents the QE Brain system, which proposes the neural Bilingual Expert model as a feature extractor based on conditional target language model with a bidi-rectional transformer and then processes the semantic representations of source and the translation output with a Bi-LSTM predictive model for automatic quality estimation.", "labels": [], "entities": [{"text": "QE Brain system", "start_pos": 24, "end_pos": 39, "type": "DATASET", "confidence": 0.818157434463501}]}, {"text": "The system has been applied to the sentence-level scoring and ranking tasks as well as the word-level tasks for finding errors for each word in translations.", "labels": [], "entities": []}, {"text": "An extensive set of experimental results have shown that our system outper-formed the best results in WMT 2017 Quality Estimation tasks and obtained top results in WMT 2018.", "labels": [], "entities": [{"text": "WMT 2017 Quality Estimation tasks", "start_pos": 102, "end_pos": 135, "type": "TASK", "confidence": 0.7488706827163696}, {"text": "WMT", "start_pos": 164, "end_pos": 167, "type": "DATASET", "confidence": 0.88727205991745}]}], "introductionContent": [{"text": "Quality Estimation (QE) is a task to estimate the quality of a Machine Translation (MT) system without the presence of any manually annotated reference translations.", "labels": [], "entities": [{"text": "Quality Estimation (QE)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7518678069114685}, {"text": "Machine Translation (MT)", "start_pos": 63, "end_pos": 87, "type": "TASK", "confidence": 0.8330960631370544}]}, {"text": "It can serve in a variety of computer-aided scenarios such as translation results screening before release or translation quality comparison between different MT systems.", "labels": [], "entities": [{"text": "translation results screening before release", "start_pos": 62, "end_pos": 106, "type": "TASK", "confidence": 0.8922199487686158}, {"text": "MT", "start_pos": 159, "end_pos": 161, "type": "TASK", "confidence": 0.8117374181747437}]}, {"text": "Currently, the classical and widely-used method to evaluate an MT system is measured by BLEU (), a statistical language-independent metric that requires human golden references for validation.", "labels": [], "entities": [{"text": "MT", "start_pos": 63, "end_pos": 65, "type": "TASK", "confidence": 0.9845077991485596}, {"text": "BLEU", "start_pos": 88, "end_pos": 92, "type": "METRIC", "confidence": 0.9987334609031677}]}, {"text": "What if we expect to efficiently get the detailed quality evaluation feedbacks (e.g. sentence or token-wise scoring) from an extremely large number of machine translation outputs?", "labels": [], "entities": []}, {"text": "An automatic method with no access to any reference is highly appreciated.", "labels": [], "entities": []}, {"text": "* * indicates equal contribution.", "labels": [], "entities": [{"text": "equal contribution", "start_pos": 14, "end_pos": 32, "type": "METRIC", "confidence": 0.9002662003040314}]}, {"text": "The common approach to automatic translation quality estimation is to transform the problem into a supervised regression or classification task for sentence-level scoring and word-level labeling respectively.", "labels": [], "entities": [{"text": "translation quality estimation", "start_pos": 33, "end_pos": 63, "type": "TASK", "confidence": 0.8305866718292236}, {"text": "word-level labeling", "start_pos": 175, "end_pos": 194, "type": "TASK", "confidence": 0.6654686480760574}]}, {"text": "Traditional baseline models in WMT 12-17 have two modules: human-crafted rulebased feature extraction model via QuEst++) (sentence-level task) or Marmot 1 (word-level task); and an SVM regression with an RBF kernel as well as grid search algorithms for predicting how much effort is needed to fix translations to acceptable results (sentence-level task) or a sequence-labeling model with CRFSuit toolkit to predict which word in the translation output needs to be edited (word-level task).", "labels": [], "entities": [{"text": "WMT 12-17", "start_pos": 31, "end_pos": 40, "type": "TASK", "confidence": 0.6368158459663391}, {"text": "human-crafted rulebased feature extraction", "start_pos": 59, "end_pos": 101, "type": "TASK", "confidence": 0.6517611443996429}]}, {"text": "A recently proposed predictor-estimator model with stack propagation) is a recurrent neural network (RNN) based feature extractor and quality prediction model that ranked first place in WMT17.", "labels": [], "entities": [{"text": "feature extractor and quality prediction", "start_pos": 112, "end_pos": 152, "type": "TASK", "confidence": 0.668421995639801}, {"text": "WMT17", "start_pos": 186, "end_pos": 191, "type": "DATASET", "confidence": 0.8732424378395081}]}, {"text": "Another novel method is to train an Automatic Post-Editing (APE) system and adapt it to predict sentence-level quality scores and word-level quality labels.", "labels": [], "entities": []}, {"text": "A promising APE system can serve as a guidance to QE system by explicitly explaining errors in the translation output.", "labels": [], "entities": []}, {"text": "Our submitted system for sentence and word level QE tasks in WMT18, named QE Brain has two phases: feature extraction and quality estimation.", "labels": [], "entities": [{"text": "WMT18", "start_pos": 61, "end_pos": 66, "type": "DATASET", "confidence": 0.9274476170539856}, {"text": "feature extraction", "start_pos": 99, "end_pos": 117, "type": "TASK", "confidence": 0.6952202171087265}]}, {"text": "In the phase of feature extraction, it extracts high-level latent joint semantics and alignment information between the source and the translation output, relying on the \"neural Bilingual Expert model\" introduced by as a prior knowledge model, which is trained on a large parallel corpus.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.7205160409212112}]}, {"text": "The high-level latent semantic features and manually designed mis-matching features) exported from the prior knowledge model are fed into a predictive model in the phase of quality estimation, with which the scoring prediction for the sentence-level task and erroneous or missing word predictions for the word-level task are targeted.", "labels": [], "entities": []}, {"text": "This paper presents our submissions for the WMT18 Quality Estimation English-German and German-English Shared Tasks, namely, (i) a sentence-level QE scoring prediction system and (ii) a word-level QE labeling prediction system including word predictions and gap predictions.", "labels": [], "entities": [{"text": "WMT18 Quality Estimation English-German", "start_pos": 44, "end_pos": 83, "type": "TASK", "confidence": 0.5634778141975403}, {"text": "QE labeling prediction", "start_pos": 197, "end_pos": 219, "type": "TASK", "confidence": 0.7322349548339844}]}, {"text": "Since both systems are supposed to understand the complex semantic relationship between the source and the translation output, the features produced by a pre-trained neural Bilingual Expert model can be shared by the two level tasks per language direction.", "labels": [], "entities": []}, {"text": "In Section 3, we will discuss several techniques to boost our system's performance.", "labels": [], "entities": []}, {"text": "We make use of extra human-crafted baseline features including basic descriptive statistics, language model (LM) probabilities and alignments information of the source and the translation output.", "labels": [], "entities": []}, {"text": "They are combined with features from the neural Bilingual Expert model to predict the sentence-level scores.", "labels": [], "entities": []}, {"text": "In addition, to makeup the shortage of QE training data, we apply the round-trip translation technique to generate some artificial QE data that increases the error diversity and prevents overfitting.", "labels": [], "entities": [{"text": "QE training", "start_pos": 39, "end_pos": 50, "type": "TASK", "confidence": 0.821918249130249}]}, {"text": "To further enhance our model's performance, we use a greedy algorithm based ensemble selection method to decrease the individual error among a bunch of single quality estimation models.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we will report the experimental results of our approach for WMT 2017 and 2018.", "labels": [], "entities": [{"text": "WMT", "start_pos": 77, "end_pos": 80, "type": "TASK", "confidence": 0.5693411231040955}]}, {"text": "For WMT17 QE task, we tried to verify our proposed strategies.", "labels": [], "entities": [{"text": "WMT17 QE task", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.5467966397603353}]}, {"text": "For WMT18 QE task, we mainly participated in the sentence-level scoring and ranking tasks and the word-level word prediction tasks for English-German SMT, EnglishGerman NMT and German-English SMT.", "labels": [], "entities": [{"text": "WMT18 QE task", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.7717888752619425}, {"text": "word-level word prediction", "start_pos": 98, "end_pos": 124, "type": "TASK", "confidence": 0.5602864027023315}, {"text": "SMT", "start_pos": 150, "end_pos": 153, "type": "TASK", "confidence": 0.7025306820869446}, {"text": "EnglishGerman NMT", "start_pos": 155, "end_pos": 172, "type": "DATASET", "confidence": 0.8524579703807831}, {"text": "German-English SMT", "start_pos": 177, "end_pos": 195, "type": "TASK", "confidence": 0.45379143953323364}]}, {"text": "In addition, we also submitted results for the wordlevel gap predictions for English-German SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 92, "end_pos": 95, "type": "TASK", "confidence": 0.6417695879936218}]}, {"text": "In, results of WMT18 QE tasks are listed according to the WMT18 QE website.", "labels": [], "entities": [{"text": "WMT18 QE tasks", "start_pos": 15, "end_pos": 29, "type": "TASK", "confidence": 0.5765641132990519}, {"text": "WMT18 QE website", "start_pos": 58, "end_pos": 74, "type": "DATASET", "confidence": 0.9583325386047363}]}], "tableCaptions": [{"text": " Table 1: Results of sentence-level scoring and ranking on WMT17. HF: human features; FT: fine-tune strategy  with artificial QE data.", "labels": [], "entities": [{"text": "WMT17", "start_pos": 59, "end_pos": 64, "type": "DATASET", "confidence": 0.9494784474372864}, {"text": "HF", "start_pos": 66, "end_pos": 68, "type": "METRIC", "confidence": 0.893619179725647}, {"text": "FT", "start_pos": 86, "end_pos": 88, "type": "METRIC", "confidence": 0.9951594471931458}]}, {"text": " Table 2: Results of sent level QE on WMT2018", "labels": [], "entities": [{"text": "sent level QE", "start_pos": 21, "end_pos": 34, "type": "TASK", "confidence": 0.5880549550056458}, {"text": "WMT2018", "start_pos": 38, "end_pos": 45, "type": "DATASET", "confidence": 0.766706645488739}]}, {"text": " Table 3: Results of word-level word prediction on  WMT17/18", "labels": [], "entities": [{"text": "word-level word prediction", "start_pos": 21, "end_pos": 47, "type": "TASK", "confidence": 0.6543896993001302}, {"text": "WMT17/18", "start_pos": 52, "end_pos": 60, "type": "DATASET", "confidence": 0.9375003973642985}]}, {"text": " Table 4: Results of word-level gap prediction on  WMT18 En-De SMT", "labels": [], "entities": [{"text": "word-level gap prediction", "start_pos": 21, "end_pos": 46, "type": "TASK", "confidence": 0.7658523718516032}, {"text": "WMT18 En-De", "start_pos": 51, "end_pos": 62, "type": "DATASET", "confidence": 0.8250147104263306}, {"text": "SMT", "start_pos": 63, "end_pos": 66, "type": "TASK", "confidence": 0.4983363151550293}]}]}