{"title": [{"text": "End-to-End Argument Mining for Discussion Threads Based on Parallel Constrained Pointer Architecture", "labels": [], "entities": [{"text": "End-to-End Argument Mining", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.5405102372169495}]}], "abstractContent": [{"text": "Argument Mining (AM) is a relatively recent discipline, which concentrates on extracting claims or premises from discourses, and inferring their structures.", "labels": [], "entities": [{"text": "Argument Mining (AM)", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9043538808822632}]}, {"text": "However, many existing works do not consider micro-level AM studies on discussion threads sufficiently.", "labels": [], "entities": []}, {"text": "In this paper , we tackle AM for discussion threads.", "labels": [], "entities": [{"text": "AM", "start_pos": 26, "end_pos": 28, "type": "TASK", "confidence": 0.7319617867469788}]}, {"text": "Our main contributions are follows: (1) A novel combination scheme focusing on micro-level inner-and inter-post schemes fora discussion thread.", "labels": [], "entities": []}, {"text": "(2) Annotation of large-scale civic discussion threads with the scheme.", "labels": [], "entities": []}, {"text": "(3) Parallel constrained pointer architecture (PCPA), a novel end-to-end technique to discriminate sentence types, inner-post relations, and inter-post interactions simultaneously.", "labels": [], "entities": [{"text": "Parallel constrained pointer architecture (PCPA)", "start_pos": 4, "end_pos": 52, "type": "TASK", "confidence": 0.5833003010068621}]}, {"text": "1 The experimental results demonstrate that our proposed model shows better accuracy in terms of relations extraction, in comparison to existing state-of-the-art models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9994992017745972}, {"text": "relations extraction", "start_pos": 97, "end_pos": 117, "type": "TASK", "confidence": 0.7373412698507309}]}], "introductionContent": [{"text": "Argument Mining (AM) is a discipline which concentrates on extracting claims or premises, and inferring their structures from a discourse.", "labels": [], "entities": [{"text": "Argument Mining (AM)", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9177017450332642}]}, {"text": "In (, they construed an argument as the pairing of a single claim and a (possibly empty) set of premises, which justifies the claim.", "labels": [], "entities": []}, {"text": "Generally, identifying structures for argument components (i.e., premises and claims) is categorized as a micro-level approach, and among complete arguments as a macro-level approach.", "labels": [], "entities": []}, {"text": "There are some micro-level approaches (, however, few AM studies aggressively consider a scheme of micro-level reply-to interactions in a thread.", "labels": [], "entities": []}, {"text": "Though provided a micro-level thread structured dataset, they considered an entire thread as a discourse.", "labels": [], "entities": []}, {"text": "Thus, they allowed a premise that links to a claim in another post, while a post should be considered as a stand-alone discourse because a writer for each post is different.", "labels": [], "entities": []}, {"text": "Also, we need to consider post-to-post interactions with the stand-alone assumption as a backdrop.", "labels": [], "entities": []}, {"text": "Moreover, the dataset of () with only 78 threads is too small to apply state-of-the-art neural discrimination models.", "labels": [], "entities": []}, {"text": "In addition to the shortage of micro-level anotations for discussion threads, no empirical study on end-to-end discrimination models which tackle discussion threads exist, to the best of our knowledge.", "labels": [], "entities": []}, {"text": "Motivated by the weaknesses above, this paper commits to the empirical study for discussion threads.", "labels": [], "entities": []}, {"text": "Our main three contributions are as follows: (1) A novel combination scheme to apply AM to discussion threads.", "labels": [], "entities": [{"text": "AM", "start_pos": 85, "end_pos": 87, "type": "TASK", "confidence": 0.9555531144142151}]}, {"text": "We introduce innerpost and inter-post schemes in combination.", "labels": [], "entities": []}, {"text": "This combination enables us to discriminate arguments per post, rather than per thread as in ().", "labels": [], "entities": []}, {"text": "In the former scheme, a post is assumed as a stand-alone discourse and a micro-level annotation is provided.", "labels": [], "entities": []}, {"text": "In the second scheme, we introduce inter-post micro-level interactions.", "labels": [], "entities": []}, {"text": "The introduction of the interactions allows us to capture informative argumentative relations between posts.", "labels": [], "entities": []}, {"text": "(2) Large-scale online civic discussions are annotated by the proposed scheme.", "labels": [], "entities": []}, {"text": "Specifically, we provide two phase annotation, and evaluate inter-annotator agreements.", "labels": [], "entities": []}, {"text": "(3) A parallel constrained pointer architecture (PCPA) is proposed, which is a novel end-to-end neural model.", "labels": [], "entities": []}, {"text": "The model can discriminate types of sentences (e.g., claim or premise), inner-post relations and inter-post interactions, simultaneously.", "labels": [], "entities": []}, {"text": "In particu-: Example of our scheme fora thread.", "labels": [], "entities": []}, {"text": "lar, our PCPA achieved a significant improvement on challenging relation extractions in comparison to the existing state-of-the-art models).", "labels": [], "entities": [{"text": "PCPA", "start_pos": 9, "end_pos": 13, "type": "DATASET", "confidence": 0.8554829359054565}, {"text": "relation extractions", "start_pos": 64, "end_pos": 84, "type": "TASK", "confidence": 0.7851381003856659}]}, {"text": "An advantage of our model is that the constraints of a thread structure are considered.", "labels": [], "entities": []}, {"text": "The constraints make our architectures effective at learning and inferring, unlike existing pointer models.", "labels": [], "entities": []}, {"text": "While our dataset of discussion threads will make further advances in AM, the proposed PCPA will make end-to-end AM studies going forward.", "labels": [], "entities": [{"text": "AM", "start_pos": 70, "end_pos": 72, "type": "TASK", "confidence": 0.9880188703536987}, {"text": "PCPA", "start_pos": 87, "end_pos": 91, "type": "DATASET", "confidence": 0.9180201292037964}]}], "datasetContent": [{"text": "To develop a sufficient AM corpus for discussion threads, we have annotated an original large-scale online civic discussion).", "labels": [], "entities": []}, {"text": "The civic discussion data is obtained by an online civic engagement on the COLLAGREE () including a thread structure.", "labels": [], "entities": [{"text": "COLLAGREE", "start_pos": 75, "end_pos": 84, "type": "DATASET", "confidence": 0.8227002620697021}]}, {"text": "The discussion was held from the end of 2016 to the beginning of 2017, and co-hosted by the government of Nagoya City, Japan.", "labels": [], "entities": []}, {"text": "The accumulated data includes 204 citizens, 399 threads, 1327 posts, 5559 sentences and 120241 tokens spelled in Japanese.", "labels": [], "entities": []}, {"text": "To the best of our knowl-edge, this work is the first approach which annotates large-scale civic discussions for AM.", "labels": [], "entities": [{"text": "AM", "start_pos": 113, "end_pos": 115, "type": "TASK", "confidence": 0.8903018832206726}]}, {"text": "For the evaluation of ACC types, IPR and IPI discrimination, we adopt precision, recall and F1 scores.", "labels": [], "entities": [{"text": "IPI discrimination", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.6264959126710892}, {"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9997594952583313}, {"text": "recall", "start_pos": 81, "end_pos": 87, "type": "METRIC", "confidence": 0.9993159770965576}, {"text": "F1", "start_pos": 92, "end_pos": 94, "type": "METRIC", "confidence": 0.9995098114013672}]}, {"text": "To obtain the precision and recall, we introduce away to compute positive and negative cases by creating relations, excluding self-pointers.", "labels": [], "entities": [{"text": "precision", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9996370077133179}, {"text": "recall", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.9993663430213928}]}, {"text": "8 9  STagBLSTM shows lower scores in terms of both IPR and IPI identification, implying the difficulty of the use of the multi-task learning of BiL-2014) with a mini batch size of 16.", "labels": [], "entities": [{"text": "IPI identification", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.6768644750118256}, {"text": "BiL-2014", "start_pos": 144, "end_pos": 152, "type": "DATASET", "confidence": 0.8801212310791016}]}, {"text": "In addition, (Middle) also illustrates that most neural models yield better F1 scores in comparison with the task specific models.", "labels": [], "entities": [{"text": "F1 scores", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9840621650218964}]}, {"text": "In addition, the logistic regression and RF are overfitted, despite that cross validations are employed.", "labels": [], "entities": [{"text": "RF", "start_pos": 41, "end_pos": 43, "type": "METRIC", "confidence": 0.9963248372077942}]}, {"text": "Thus, end-to-end learning assumes an important role for AM, even in thread structures.", "labels": [], "entities": [{"text": "AM", "start_pos": 56, "end_pos": 58, "type": "TASK", "confidence": 0.9715352058410645}]}], "tableCaptions": [{"text": " Table 1: Inter-annotator agreement scores for the  two corpora.", "labels": [], "entities": []}, {"text": " Table 2: Top: Our models vs. joint baselines (%). * indicates significant. at p < 0.01, two-sided  Wilcoxon signed rank test (Derryberry et al., 2010), compared with each baseline. Middle: Perfor- mances of task specific baselines. Bottom: Performances of joint models w/o separator representations.", "labels": [], "entities": [{"text": "two-sided  Wilcoxon signed rank test", "start_pos": 89, "end_pos": 125, "type": "METRIC", "confidence": 0.6236296415328979}]}, {"text": " Table 4: The effect of parameter sharing of the two  pointer architectures.", "labels": [], "entities": []}]}