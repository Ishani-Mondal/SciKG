{"title": [{"text": "Building Dialogue Structure from Discourse Tree of a Question", "labels": [], "entities": []}], "abstractContent": [{"text": "In this section we propose a reasoning-based approach to a dialogue management fora customer support chat bot.", "labels": [], "entities": []}, {"text": "To build a dialogue scenario, we analyze the discourse tree (DT) of an initial query of a customer support dialogue that is frequently complex and multi-sentence.", "labels": [], "entities": []}, {"text": "We then enforce rhetorical agreement between DT of the initial query and that of the answers, requests and responses.", "labels": [], "entities": [{"text": "DT", "start_pos": 45, "end_pos": 47, "type": "METRIC", "confidence": 0.723792552947998}]}, {"text": "The chat bot finds answers, which are not only relevant by topic but also suitable fora given step of a conversation and match the question by style, communication means, experience level and other domain-independent attributes.", "labels": [], "entities": []}, {"text": "We evaluate a performance of proposed algorithm in car repair domain and observe a 5 to 10% improvement for single and three-step dialogues respectively, in comparison with baseline approaches to dialogue management.", "labels": [], "entities": [{"text": "car repair domain", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.7656485537687937}]}], "introductionContent": [{"text": "Answering questions, a chat bot needs to reason to properly select answers from candidates.", "labels": [], "entities": []}, {"text": "In industrial applications of search, reasoning is often substituted by learning from conversational logs or user choices.", "labels": [], "entities": []}, {"text": "It helps to make search more relevant as long as a similar question has been asked many times.", "labels": [], "entities": []}, {"text": "If there is no data on previous similar question, which is frequently the case, a chat bot needs to apply some form of reasoning to select from candidate answers.", "labels": [], "entities": []}, {"text": "Most frequent type of reasoning is associated with topical relevance.", "labels": [], "entities": []}, {"text": "It requires ontology and is domain-specific.", "labels": [], "entities": []}, {"text": "Difficulties in building domain ontologies are well known, and in this paper we take a different reasoning-based approach.", "labels": [], "entities": []}, {"text": "Once a set of candidate answers or replies is available, how to select most suitable ones?", "labels": [], "entities": []}, {"text": "The suitability criteria are two-dimensional: 1) topical relevance; and 2) an appropriateness not associated with topic but instead connected with communicative discourse.", "labels": [], "entities": []}, {"text": "Whereas topical relevance has been thoroughly investigated, chat bot's capability to maintain the cohesive flow, style and merits of conversation is an underexplored area.", "labels": [], "entities": [{"text": "topical relevance", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.7843058705329895}]}, {"text": "When a question (Q) is detailed and includes multiple sentences, there are certain expectations concerning the style of an answer (A).", "labels": [], "entities": []}, {"text": "Although topical agreement between questions and answers has been extensively addressed, a correspondence in style and suitability for the given step of a dialogue between questions and answers has not been thoroughly explored.", "labels": [], "entities": []}, {"text": "In this study we focus on assessment of the cohesiveness of the Q/A flow, which is important fora chat bots supporting longer conversation.", "labels": [], "entities": []}, {"text": "When an answer is in a style disagreement with a question, a user can find this answer inappropriate even when a topical relevance is high.", "labels": [], "entities": []}, {"text": "Matching rhetorical structures of questions and answers is a systematic way to implement high-level reasoning for dialogue management, to be explored in this work.", "labels": [], "entities": [{"text": "dialogue management", "start_pos": 114, "end_pos": 133, "type": "TASK", "confidence": 0.8268279731273651}]}, {"text": "A problem in communicative discourse occurs mostly for complex questions, arising in miscommunication, alack of understanding, and requiring clarification, argumentation and other means to bring the answer's author point across.", "labels": [], "entities": []}, {"text": "Rhetorical disagreement is associated with a broken dialogue and is usually evident via the means an answer is communicated, explained or backed up.", "labels": [], "entities": []}, {"text": "Our paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we discuss basic notions of discourse tree text representation.", "labels": [], "entities": [{"text": "discourse tree text representation", "start_pos": 41, "end_pos": 75, "type": "TASK", "confidence": 0.6342511549592018}]}, {"text": "In Section 3 we consider details our approach to building a dialogue based on discourse trees.", "labels": [], "entities": []}, {"text": "In Section 4 we present evaluation results for the one of the Q/A tasks.", "labels": [], "entities": []}, {"text": "The system described in this paper is available on our GitHub 1 .", "labels": [], "entities": [{"text": "GitHub 1", "start_pos": 55, "end_pos": 63, "type": "DATASET", "confidence": 0.929612934589386}]}], "datasetContent": [{"text": "We formed a dataset of 9300 Q/A pairs related to car repair recommendations from www.2carpros.com.", "labels": [], "entities": [{"text": "car repair recommendations", "start_pos": 49, "end_pos": 75, "type": "TASK", "confidence": 0.7252171138922373}]}, {"text": "These pairs were extracted from dialogues as first and second utterance, so that the question is 7 -15 keywords and answer is 3 to 6 sentences.", "labels": [], "entities": []}, {"text": "This resource was obtained to train a dialogue support system but it also proved to be useful to evaluate search.", "labels": [], "entities": []}, {"text": "The dataset is available online 2 in our GitHub.", "labels": [], "entities": []}, {"text": "To automate the relevance assessment, we considered the dialogue built correctly if an actual dialogue from the dataset is formed, given the first Q as a seed.", "labels": [], "entities": []}, {"text": "Otherwise, if the sequence of utterances does not occur in the dataset, we consider it to be incorrect.", "labels": [], "entities": []}, {"text": "There are some deficiencies of this approach since some actual dialogs are illogical and some synthetic dialogues built from distinct ones can be plausible, but it allows avoiding a manual tagging and construction of dialogues.", "labels": [], "entities": []}, {"text": "The number of formed answers is limit to three: once initial Q is given, the system forms A 1 , a set of A 2i and A 3j . A 1 is followed by the actual C 1 from the dialogue Q, so the proper A 2 needs to be selected.", "labels": [], "entities": []}, {"text": "Analogously, once actual C 2 (if applicable) is provided, proper A 3 needs to be selected.", "labels": [], "entities": [{"text": "A 3", "start_pos": 65, "end_pos": 68, "type": "METRIC", "confidence": 0.9487141668796539}]}, {"text": "As a first baseline approach, we selected dialogue construction based on keyword similarity only, without taking into account a dialogue flow by considering a DT-Q.", "labels": [], "entities": [{"text": "dialogue construction", "start_pos": 42, "end_pos": 63, "type": "TASK", "confidence": 0.832315981388092}]}, {"text": "As a second baseline approach, we augment keyword similarity with linguistic relevance by computing maximal common sub-parse trees between the Q and A i.", "labels": [], "entities": []}, {"text": "For the selected dataset, baseline approach is capable of building correct scenarios in the cases when similar keywords or similar linguistic phrases deliver the only dialogue scenario that is correct.", "labels": [], "entities": []}, {"text": "On the contrary, DT-Q dialogue formation does not always succeed because some scenarios deviate from actual ones in the training set, alt-hough they are still plausible.", "labels": [], "entities": [{"text": "DT-Q dialogue formation", "start_pos": 17, "end_pos": 40, "type": "TASK", "confidence": 0.9485645294189453}]}, {"text": "Hence we see 10 and 5% improvement over the first and second baselines respectively fora basic, single-step scenario.", "labels": [], "entities": []}, {"text": "As scenario becomes more complex, the chance that the proper scenario is selected by topic relevance decreases.", "labels": [], "entities": []}, {"text": "At the same time, overall scenario formation complexity increases, and therefore an error rate for DT-Q approach increases as well.", "labels": [], "entities": [{"text": "scenario formation", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.8743397295475006}]}, {"text": "For the most complex, 3-step dialogue scenarios, DT-Q approach exceeds the baselines by 13 and 10% respectively.", "labels": [], "entities": []}], "tableCaptions": []}