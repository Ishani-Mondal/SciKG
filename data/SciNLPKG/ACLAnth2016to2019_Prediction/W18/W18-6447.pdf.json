{"title": [{"text": "Hunter NMT System for WMT18 Biomedical Translation Task: Transfer Learning in Neural Machine Translation", "labels": [], "entities": [{"text": "WMT18 Biomedical Translation", "start_pos": 22, "end_pos": 50, "type": "TASK", "confidence": 0.8282648126284281}, {"text": "Neural Machine Translation", "start_pos": 78, "end_pos": 104, "type": "TASK", "confidence": 0.6665871143341064}]}], "abstractContent": [{"text": "This paper describes the submission of Hunter Neural Machine Translation (NMT) to the WMT'18 Biomedical translation task from English to French.", "labels": [], "entities": [{"text": "Hunter Neural Machine Translation (NMT)", "start_pos": 39, "end_pos": 78, "type": "TASK", "confidence": 0.6878929138183594}, {"text": "WMT'18 Biomedical translation task", "start_pos": 86, "end_pos": 120, "type": "TASK", "confidence": 0.775498129427433}]}, {"text": "The discrepancy between training and test data distribution brings a challenge to translate text in new domains.", "labels": [], "entities": []}, {"text": "Beyond the previous work of combining in-domain with out-of-domain models, we found accuracy and efficiency gain in combining different in-domain models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9995604157447815}]}, {"text": "We conduct extensive experiments on NMT with transfer learning.", "labels": [], "entities": []}, {"text": "We train on different in-domain Biomedical datasets one after another.", "labels": [], "entities": [{"text": "Biomedical datasets", "start_pos": 32, "end_pos": 51, "type": "DATASET", "confidence": 0.7370040416717529}]}, {"text": "That means parameters of the previous training serve as the initialization of the next one.", "labels": [], "entities": []}, {"text": "Together with a pre-trained out-of-domain News model, we enhanced translation quality with 3.73 BLEU points over the baseline.", "labels": [], "entities": [{"text": "translation", "start_pos": 66, "end_pos": 77, "type": "TASK", "confidence": 0.9456465244293213}, {"text": "BLEU", "start_pos": 96, "end_pos": 100, "type": "METRIC", "confidence": 0.9992164373397827}]}, {"text": "Furthermore, we applied ensemble learning on training models of intermediate epochs and achieved an improvement of 4.02 BLEU points over the baseline.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 120, "end_pos": 124, "type": "METRIC", "confidence": 0.9996269941329956}]}, {"text": "Overall, our system is 11.29 BLEU points above the best system of last year on the EDP 2017 test set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 29, "end_pos": 33, "type": "METRIC", "confidence": 0.9997437596321106}, {"text": "EDP 2017 test set", "start_pos": 83, "end_pos": 100, "type": "DATASET", "confidence": 0.9477844089269638}]}], "introductionContent": [{"text": "Data-driven machine translation models assume the training data and test data have the same distribution and feature space, which is rare in real-world applications).", "labels": [], "entities": [{"text": "Data-driven machine translation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.5836321810881296}]}, {"text": "In statistical machine translation, a standard solution is to apply domain adaptation (.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 3, "end_pos": 34, "type": "TASK", "confidence": 0.6904672384262085}]}, {"text": "For example, interpolating phrase or word probabilities in a sentence learned on in-domain and outof-domain data and then computing their product.", "labels": [], "entities": []}, {"text": "In NMT, we apply ensemble learning instead of * Both authors have contributed equally to this work.", "labels": [], "entities": []}, {"text": "\u2020 The author was working as a visiting student at Hunter College, CUNY  interpolation.", "labels": [], "entities": []}, {"text": "Moreover, we initialize neural networks with parameters trained with out-of-domain data.", "labels": [], "entities": []}, {"text": "Studies show that this approach results in fast training and higher accuracy, such as in ().", "labels": [], "entities": [{"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9994271993637085}]}, {"text": "These methods focus on combining an indomain model with an out-of-domain model.", "labels": [], "entities": []}, {"text": "Nonetheless, often, the training data is a mixture of multiple in-domain corpora and out-of-domain corpora.", "labels": [], "entities": []}, {"text": "If one concatenates all the in-domain corpora to train a model, then training is more expensive for the memory and time.", "labels": [], "entities": []}, {"text": "Furthermore, the distribution of one corpus maybe closer than the others to the test set.", "labels": [], "entities": []}, {"text": "Thus, the statistics of the closer corpus may vanish in the merged corpus.", "labels": [], "entities": []}, {"text": "The WMT'18 Biomedical translation task is atypical scenario.", "labels": [], "entities": [{"text": "WMT'18 Biomedical translation task", "start_pos": 4, "end_pos": 38, "type": "TASK", "confidence": 0.7157575339078903}]}, {"text": "There are two sets of in-domain data: the Biomedical training set of WMT'18 (with 2.8M sentences) and WMT'14 (19 M), besides an out-of-domain training set on News (41 M), see.", "labels": [], "entities": [{"text": "WMT'18", "start_pos": 69, "end_pos": 75, "type": "DATASET", "confidence": 0.6498136520385742}, {"text": "WMT'14", "start_pos": 102, "end_pos": 108, "type": "DATASET", "confidence": 0.9385412931442261}, {"text": "News", "start_pos": 158, "end_pos": 162, "type": "DATASET", "confidence": 0.9850350618362427}]}, {"text": "To separately train on WMT'18 and WMT'14 Biomedical data, anew challenge arises: How to efficiently combine the training on different in-domain training sets?", "labels": [], "entities": [{"text": "WMT'18", "start_pos": 23, "end_pos": 29, "type": "DATASET", "confidence": 0.978996753692627}, {"text": "WMT'14 Biomedical data", "start_pos": 34, "end_pos": 56, "type": "DATASET", "confidence": 0.9063209295272827}]}, {"text": "To answer this question, this work presents an empirical study of efficient training on multiple in-domain and out-of-domain datasets.", "labels": [], "entities": []}, {"text": "We applied transfer learning by training NMT systems with different datasets one after another carrying on the previous parameters.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.9679148495197296}]}, {"text": "More precisely, we first initialize the NMT with the existing out-ofdomain model trained on the out-of-domain News data.", "labels": [], "entities": [{"text": "NMT", "start_pos": 40, "end_pos": 43, "type": "DATASET", "confidence": 0.7159633040428162}, {"text": "News data", "start_pos": 110, "end_pos": 119, "type": "DATASET", "confidence": 0.8307039439678192}]}, {"text": "Then, we train the NMT with the in-domain Biomedical dataset of 2018.", "labels": [], "entities": [{"text": "NMT", "start_pos": 19, "end_pos": 22, "type": "DATASET", "confidence": 0.8556262850761414}, {"text": "Biomedical dataset of 2018", "start_pos": 42, "end_pos": 68, "type": "DATASET", "confidence": 0.9526197910308838}]}, {"text": "Afterward, we take the newly estimated parameters as the initialization and further train the NMT on the in-domain Biomedical dataset of 2014.", "labels": [], "entities": [{"text": "NMT", "start_pos": 94, "end_pos": 97, "type": "DATASET", "confidence": 0.7174575328826904}, {"text": "Biomedical dataset of 2014", "start_pos": 115, "end_pos": 141, "type": "DATASET", "confidence": 0.9314188063144684}]}, {"text": "In this way, a previous model's output initializes the parameters of the next model, so that we train on every single data set at a time instead all at once.", "labels": [], "entities": []}, {"text": "We further experimented with ensemble learning.", "labels": [], "entities": []}, {"text": "We saved the model (checkpoint) after every epoch during training.", "labels": [], "entities": []}, {"text": "Once training finishes, we performed checkpoint ensembling by picking various combinations of checkpoint outputs from the training on the last dataset.", "labels": [], "entities": [{"text": "checkpoint ensembling", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.793126255273819}]}, {"text": "We conduct our experiments on Biomedical translation task of WMT'18.", "labels": [], "entities": [{"text": "Biomedical translation", "start_pos": 30, "end_pos": 52, "type": "TASK", "confidence": 0.8796713054180145}, {"text": "WMT'18", "start_pos": 61, "end_pos": 67, "type": "DATASET", "confidence": 0.9267748594284058}]}, {"text": "We observe a significant accuracy improvement of 3.73 BLEU points for single models and 4.02 BLEU points for ensembles over our baseline trained with one indomain dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9995610117912292}, {"text": "BLEU", "start_pos": 54, "end_pos": 58, "type": "METRIC", "confidence": 0.9991044402122498}, {"text": "BLEU", "start_pos": 93, "end_pos": 97, "type": "METRIC", "confidence": 0.9989597797393799}]}, {"text": "While some of these improvements are due to differences in training data, preprocessing and hyper-parameters, most of the increase is due to the use of different data sets for initialization and subsequent training.", "labels": [], "entities": [{"text": "initialization", "start_pos": 176, "end_pos": 190, "type": "TASK", "confidence": 0.9647783637046814}]}], "datasetContent": [{"text": "This section describes the datasets, tools, and settings used for the Biomedical translation task.", "labels": [], "entities": [{"text": "Biomedical translation task", "start_pos": 70, "end_pos": 97, "type": "TASK", "confidence": 0.9680065512657166}]}, {"text": "We used the WMT'18 Biomedical shared task English-French (EN-FR) data for training.", "labels": [], "entities": [{"text": "WMT'18 Biomedical shared task English-French (EN-FR) data", "start_pos": 12, "end_pos": 69, "type": "DATASET", "confidence": 0.8388823469479879}]}, {"text": "In this paper, this data is the UFAL medical corpus 2 . We also used WMT'14 Biomedical EN-FR data (PatTR 3 only) as additional in-domain data.", "labels": [], "entities": [{"text": "UFAL medical corpus", "start_pos": 32, "end_pos": 51, "type": "DATASET", "confidence": 0.9369052449862162}, {"text": "WMT'14 Biomedical EN-FR data", "start_pos": 69, "end_pos": 97, "type": "DATASET", "confidence": 0.8737111538648605}]}, {"text": "For out-of-domain training, we used WMT'14 News EN-FR training data.", "labels": [], "entities": [{"text": "WMT'14 News EN-FR training data", "start_pos": 36, "end_pos": 67, "type": "DATASET", "confidence": 0.965844476222992}]}, {"text": "We validated each training epoch on Khresmoi and HIML development datasets.", "labels": [], "entities": [{"text": "Khresmoi and HIML development datasets", "start_pos": 36, "end_pos": 74, "type": "DATASET", "confidence": 0.7836004972457886}]}, {"text": "We use the WMT'17 EDP ( as test data to evaluate.", "labels": [], "entities": [{"text": "WMT'17 EDP", "start_pos": 11, "end_pos": 21, "type": "DATASET", "confidence": 0.9054161310195923}]}, {"text": "Statistics for the development and test data sets is mentioned in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Raw and preprocessed data statistics for  the three datasets used in the experiments. S R is  the sentences in the raw data, S P is the sentences in  preprocessed data, V R is the running words and V is  the vocabulary size. Running words & Vocabulary are  for both source and target represented as source/target", "labels": [], "entities": []}, {"text": " Table 2: Development and test data stats. Kh refers to  the Khresmoi development data. S R is the sentences in  the raw data, S P is the sentences in preprocessed data,  V R is the running words, V is the vocabulary size and  OOV is the unique Out-Of-Vocabulary words. Run- ning words, Vocabulary & Out-Of-Vocabulary words  are represented as source/target.", "labels": [], "entities": [{"text": "Khresmoi development data", "start_pos": 61, "end_pos": 86, "type": "DATASET", "confidence": 0.8139604926109314}, {"text": "OOV", "start_pos": 227, "end_pos": 230, "type": "METRIC", "confidence": 0.9773492217063904}]}, {"text": " Table 3: Training time for each dataset. Training  time is for a single epoch in hours.", "labels": [], "entities": []}, {"text": " Table 4: BLEU scores for different models on EDP'17 test data. Single is the single model which gave minimum  loss on the Khresmoi development set. Results with (*) are calculated using multi-eval tool. All other results are  calculated using multi-bleu tool.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9993300437927246}, {"text": "EDP'17 test data", "start_pos": 46, "end_pos": 62, "type": "DATASET", "confidence": 0.9792392055193583}, {"text": "Khresmoi development set", "start_pos": 123, "end_pos": 147, "type": "DATASET", "confidence": 0.9021926323572794}]}, {"text": " Table 5: Results of different development sets for  tuning all the models. BLEU scores are calculated  on EDP'17 test data.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 76, "end_pos": 80, "type": "METRIC", "confidence": 0.9988794922828674}, {"text": "EDP'17 test data", "start_pos": 107, "end_pos": 123, "type": "DATASET", "confidence": 0.9803739190101624}]}, {"text": " Table 6: BLEU scores for different checkpoint en- sembles for Exp 2", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9993395209312439}]}]}