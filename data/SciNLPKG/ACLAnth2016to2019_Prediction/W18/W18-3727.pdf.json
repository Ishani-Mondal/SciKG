{"title": [{"text": "Detecting Simultaneously Chinese Grammar Errors Based on a BiLSTM-CRF Model", "labels": [], "entities": [{"text": "Detecting Simultaneously Chinese Grammar Errors", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.8570245742797852}]}], "abstractContent": [{"text": "In the process of learning and using Chinese, many learners of Chinese as foreign language(CFL) may have grammar errors due to negative migration of their native languages.", "labels": [], "entities": []}, {"text": "This paper introduces our system that can simultaneously diagnose four types of grammatical errors including redundant (R), missing (M), selection (S), disorder (W) in NLPTEA-5 shared task.", "labels": [], "entities": []}, {"text": "We proposed a Bidirectional LSTM CRF neural network (BiLSTM-CRF) that combines BiLSTM and CRF without hand-craft features for Chinese Grammatical Error Diagnosis (CGED).", "labels": [], "entities": [{"text": "Chinese Grammatical Error Diagnosis (CGED)", "start_pos": 126, "end_pos": 168, "type": "TASK", "confidence": 0.7627517070089068}]}, {"text": "Evaluation includes three levels, which are detection level, identification level and position level.", "labels": [], "entities": []}, {"text": "At the detection level and identification level, our system got the third recall scores, and achieved good F1 values.", "labels": [], "entities": [{"text": "recall", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.9977490305900574}, {"text": "F1", "start_pos": 107, "end_pos": 109, "type": "METRIC", "confidence": 0.999708354473114}]}], "introductionContent": [{"text": "With the rapid development of China's economy, \"Chinese Fever\" has been set off in the world and more foreigners begin to learn Chinese.", "labels": [], "entities": [{"text": "Chinese Fever\"", "start_pos": 48, "end_pos": 62, "type": "TASK", "confidence": 0.6564372877279917}]}, {"text": "Writing is an important part of Chinese learning, and the grammar is the basis of writing.", "labels": [], "entities": []}, {"text": "In the process of writing and communicating with each other using Chinese, learners of Chinese as foreign language(CFL) may have grammar errors due to negative migration of their native languages.", "labels": [], "entities": []}, {"text": "Traditional learning methods for CFL rely on heavily manual work to point out grammar errors, which costs a lot of time and labor.", "labels": [], "entities": [{"text": "CFL", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.9816283583641052}]}, {"text": "In order to reduce the workload of manual identification, it is necessary to explore effective methods for Chinese Grammatical Error Diagnosis (CGED).", "labels": [], "entities": [{"text": "manual identification", "start_pos": 35, "end_pos": 56, "type": "TASK", "confidence": 0.7257872521877289}, {"text": "Chinese Grammatical Error Diagnosis (CGED)", "start_pos": 107, "end_pos": 149, "type": "TASK", "confidence": 0.778711519071034}]}, {"text": "In the field of natural language processing, CGED is a great challenge because of the flexibility and irregularity in Chinese, so a series of CGED evaluation tasks are arranged.", "labels": [], "entities": []}, {"text": "The CGED evaluation tasks provided a platform for many researchers to study the automatic detection of Chinese grammatical errors.", "labels": [], "entities": [{"text": "automatic detection of Chinese grammatical errors", "start_pos": 80, "end_pos": 129, "type": "TASK", "confidence": 0.8037510464588801}]}, {"text": "The CGED 2018 evaluation task defines Chinese grammatical errors as four categories: redundant(R), selection (S), missing(M), disorder(W).", "labels": [], "entities": [{"text": "CGED 2018 evaluation task", "start_pos": 4, "end_pos": 29, "type": "DATASET", "confidence": 0.9354471266269684}]}, {"text": "As shown in, the example sentences corresponding to each error are given.", "labels": [], "entities": []}, {"text": "In this paper, we regarded the CGED 2018 shared task as a character-based sequence labeling task.", "labels": [], "entities": [{"text": "CGED 2018 shared task", "start_pos": 31, "end_pos": 52, "type": "DATASET", "confidence": 0.8993019461631775}, {"text": "character-based sequence labeling task", "start_pos": 58, "end_pos": 96, "type": "TASK", "confidence": 0.6614813581109047}]}, {"text": "We proposed a Bidirectional LSTM CRF(BiLSTM-CRF) neural network that combines LSTM and CRF for sequence labeling without any hand-craft features.", "labels": [], "entities": []}, {"text": "Firstly, we use BiLSTM network to learn the information in the sentence and extract features, then we utilize CRF for sequence labeling to complete automatically Chinese grammatical errors detection.", "labels": [], "entities": [{"text": "Chinese grammatical errors detection", "start_pos": 162, "end_pos": 198, "type": "TASK", "confidence": 0.7526746392250061}]}, {"text": "The rest of this paper is organized as follows: Section 2 briefly introduces related work in this field.", "labels": [], "entities": []}, {"text": "Section 3 introduces the model that we proposed.", "labels": [], "entities": []}, {"text": "Section 4 discusses experiments and results analysis, including data preprocessing, hyperparameters and experiment results.", "labels": [], "entities": []}, {"text": "Finally, conclusion and prospects are arranged.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this paper, based on the CGED series evaluations, we adopted the dataset of CGED 2016 and CGED 2018 shared tasks as out training dataset, then we manually deleted some incorrect sentenc-es in the training set and rebuilt the dataset.", "labels": [], "entities": [{"text": "CGED series evaluations", "start_pos": 28, "end_pos": 51, "type": "DATASET", "confidence": 0.9561699231465658}, {"text": "CGED 2016 and CGED 2018 shared tasks", "start_pos": 79, "end_pos": 115, "type": "DATASET", "confidence": 0.9085552522114345}]}, {"text": "The CGED 2017 test set was selected as the validation set and the CGED 2018 test set was used as the test set.", "labels": [], "entities": [{"text": "CGED 2017 test set", "start_pos": 4, "end_pos": 22, "type": "DATASET", "confidence": 0.9798003882169724}, {"text": "CGED 2018 test set", "start_pos": 66, "end_pos": 84, "type": "DATASET", "confidence": 0.9773618131875992}]}, {"text": "We selected BiLSTM-CRF model for CGED 2018 shared task.", "labels": [], "entities": [{"text": "CGED 2018 shared task", "start_pos": 33, "end_pos": 54, "type": "DATASET", "confidence": 0.89315564930439}]}, {"text": "This part mainly includes data preprocessing, parameter settings, results analysis on the validation set and the test set.", "labels": [], "entities": []}, {"text": "In this paper, we use two different models to conduct experiments respectively, which are CRF model (M1) and BiLSTM-CRF model (M2).", "labels": [], "entities": [{"text": "BiLSTM-CRF", "start_pos": 109, "end_pos": 119, "type": "METRIC", "confidence": 0.9724864959716797}]}, {"text": "BiLSTM-CRF model: The BiLSTM-CRF model combines LSTM and CRF for sequence labeling.", "labels": [], "entities": []}, {"text": "Firstly, we use BiLSTM network to learn information in the sentence and extract features, then we utilize CRF for sequence labeling to complete automatically CGED shared work.", "labels": [], "entities": []}, {"text": "The results on the validation set: The valuation set used in this paper is the test set in the CGED2017 shared task.", "labels": [], "entities": [{"text": "CGED2017 shared task", "start_pos": 95, "end_pos": 115, "type": "DATASET", "confidence": 0.8670022487640381}]}, {"text": "Two different models are used to conduct experiments on the valuation set, results are shown in.", "labels": [], "entities": []}, {"text": "From, we can see that CRF model has lower False Positive Rate (FPR) than BiLSTM-CRF model, and CRF model achieves better precision performance at the detection level and the identification level, because that CRF model has more features information such as bi-gram, trigram.", "labels": [], "entities": [{"text": "False Positive Rate (FPR)", "start_pos": 42, "end_pos": 67, "type": "METRIC", "confidence": 0.9611023863156637}, {"text": "precision", "start_pos": 121, "end_pos": 130, "type": "METRIC", "confidence": 0.993156373500824}]}, {"text": "However, CRF model and BiLSTM-CRF model are not good at position level.", "labels": [], "entities": [{"text": "BiLSTM-CRF", "start_pos": 23, "end_pos": 33, "type": "METRIC", "confidence": 0.7717337608337402}]}, {"text": "We think that our models are short of identification of position boundary.", "labels": [], "entities": []}, {"text": "Next, we will focus on the position level by adding character position features.", "labels": [], "entities": []}, {"text": "The results on the test set: The test set is the test set in the CGED 2018 shared task.", "labels": [], "entities": [{"text": "CGED 2018 shared task", "start_pos": 65, "end_pos": 86, "type": "DATASET", "confidence": 0.9429293274879456}]}, {"text": "We submitted only one result in this task.", "labels": [], "entities": []}, {"text": "The lists the result Run1 we submitted and the test result based on CRF model.", "labels": [], "entities": []}, {"text": "At the error detection level and error identification level, our system achieves a third recall rate and gets a good F1 value.", "labels": [], "entities": [{"text": "error detection", "start_pos": 7, "end_pos": 22, "type": "TASK", "confidence": 0.7921900749206543}, {"text": "error identification", "start_pos": 33, "end_pos": 53, "type": "TASK", "confidence": 0.8012556433677673}, {"text": "recall rate", "start_pos": 89, "end_pos": 100, "type": "METRIC", "confidence": 0.9915849566459656}, {"text": "F1", "start_pos": 117, "end_pos": 119, "type": "METRIC", "confidence": 0.9995564818382263}]}, {"text": "However, our system has a poor performance at the error position level and FPR.", "labels": [], "entities": [{"text": "error position level", "start_pos": 50, "end_pos": 70, "type": "METRIC", "confidence": 0.953993022441864}, {"text": "FPR", "start_pos": 75, "end_pos": 78, "type": "METRIC", "confidence": 0.9980231523513794}]}, {"text": "Since our system recognizes four types of errors at the same time, increasing the difficulty of recognition, it is easier to identify a correct sentence as an error sentence, it results in lower FPR performance on the test set.", "labels": [], "entities": [{"text": "FPR", "start_pos": 195, "end_pos": 198, "type": "METRIC", "confidence": 0.9908589720726013}]}, {"text": "In addition, our system is based on character level, although the BiLSTM network has a powerful long-term memory function, the lack of word collocation information also results in lower position level efficiency.", "labels": [], "entities": [{"text": "BiLSTM network", "start_pos": 66, "end_pos": 80, "type": "DATASET", "confidence": 0.8550075590610504}]}, {"text": "Another reason for low position level efficiency is that tag does not distinguish among locations.", "labels": [], "entities": []}, {"text": "In this sentence, \"\u53ef\u770b\" should be corrected as \"\u6709 \u6548\".", "labels": [], "entities": []}, {"text": "There was no distinction in two \"/S\", so we think it leads to lower position level efficiency.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: The examples of data preprocessing.", "labels": [], "entities": [{"text": "data preprocessing", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.7004076540470123}]}, {"text": " Table 3: The results on the validation set.", "labels": [], "entities": []}, {"text": " Table 4: The results on the test set.", "labels": [], "entities": []}]}