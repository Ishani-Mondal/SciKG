{"title": [{"text": "CAMB at CWI Shared Task 2018: Complex Word Identification with Ensemble-Based Voting", "labels": [], "entities": [{"text": "Complex Word Identification", "start_pos": 30, "end_pos": 57, "type": "TASK", "confidence": 0.6807607014973959}]}], "abstractContent": [{"text": "This paper presents the winning systems we submitted to the Complex Word Identification Shared Task 2018.", "labels": [], "entities": [{"text": "Complex Word Identification Shared Task", "start_pos": 60, "end_pos": 99, "type": "TASK", "confidence": 0.7546365439891816}]}, {"text": "We describe our best performing systems' implementations and discuss our key findings from this research.", "labels": [], "entities": []}, {"text": "Our best-performing systems achieve an F 1 score of 0.8736 on the NEWS, 0.8400 on the WIKINEWS and 0.8115 on the WIKIPEDIA test sets in the monolingual English binary classification track, and a mean absolute error of 0.0558 on the NEWS, 0.0674 on the WIKINEWS and 0.0739 on the WIKIPEDIA test sets in the probabilistic track.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9929660558700562}, {"text": "NEWS", "start_pos": 66, "end_pos": 70, "type": "DATASET", "confidence": 0.9824628829956055}, {"text": "WIKINEWS", "start_pos": 86, "end_pos": 94, "type": "DATASET", "confidence": 0.9725207686424255}, {"text": "WIKIPEDIA test sets", "start_pos": 113, "end_pos": 132, "type": "DATASET", "confidence": 0.9588411251703898}, {"text": "mean absolute error", "start_pos": 195, "end_pos": 214, "type": "METRIC", "confidence": 0.7313380936781565}, {"text": "NEWS", "start_pos": 232, "end_pos": 236, "type": "DATASET", "confidence": 0.9867730736732483}, {"text": "WIKINEWS", "start_pos": 252, "end_pos": 260, "type": "DATASET", "confidence": 0.9830921292304993}, {"text": "WIKIPEDIA test sets", "start_pos": 279, "end_pos": 298, "type": "DATASET", "confidence": 0.9724176923433939}]}], "introductionContent": [{"text": "Poor reading comprehension often caused by the presence of complex technical terms can have serious practical consequences).", "labels": [], "entities": []}, {"text": "Although proper text simplification requires a wide range of transformations, it has been shown that application of lexical simplification (LS) techniques alone improves reader understanding and information retention (.", "labels": [], "entities": [{"text": "text simplification", "start_pos": 16, "end_pos": 35, "type": "TASK", "confidence": 0.7041110843420029}, {"text": "reader understanding", "start_pos": 170, "end_pos": 190, "type": "TASK", "confidence": 0.8382267951965332}, {"text": "information retention", "start_pos": 195, "end_pos": 216, "type": "TASK", "confidence": 0.767702579498291}]}, {"text": "Complex Word Identification (CWI) is concerned with automated identification of words that might present challenge for the target readers and should thus be simplified.", "labels": [], "entities": [{"text": "Complex Word Identification (CWI)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7663844426472982}]}, {"text": "Early studies on LS () do not consider CWI as part of the simplification pipeline, but recent studies argue that simplification systems benefit from applying CWI as the first step in the LS pipeline.", "labels": [], "entities": []}, {"text": "Inadequate identification of complex words in text might result in an overly difficult text if many potential candidates are missed, or in meaning distortion if many simple words are falsely identified as complex.", "labels": [], "entities": []}, {"text": "CWI cannot only be used as a component of LS systems, but also as a stand-alone application within intelligent tutoring systems for second language learners or in reading devices for people with low literacy skills.", "labels": [], "entities": []}, {"text": "For instance, shows that at least 95% of text should be familiar to the reader in order for them to understand the content.", "labels": [], "entities": []}, {"text": "A CWI system can help identify the unfamiliar words and provide readers with their definitions even when simpler alternatives are not available.", "labels": [], "entities": []}, {"text": "This has the potential to help a wide variety of target reader groups, including general readers of technical texts.", "labels": [], "entities": []}, {"text": "Following the SemEval 2016 shared task, the Shared Task 2018 frames CWI as the process of identifying words that are difficult fora given target population (for example, non-native speakers of English) based on the annotation from a sample of that target population (.", "labels": [], "entities": [{"text": "SemEval 2016 shared task", "start_pos": 14, "end_pos": 38, "type": "TASK", "confidence": 0.7623845487833023}]}, {"text": "We overview the related work in the field in Section 2 and discuss the CWI shared task framework in Section 3.", "labels": [], "entities": []}, {"text": "We have participated in the binary and probabilistic classification tasks in the monolingual English track, and scored first in the binary setting on all three data sources, as well as on two out of three data sources in the probabilistic setting.", "labels": [], "entities": []}, {"text": "Section 4 presents the implementation details of our systems including features and methods used.", "labels": [], "entities": []}, {"text": "In Section 5 we present the results obtained with our systems, and discuss the key findings.", "labels": [], "entities": []}, {"text": "Finally, we outline future directions for this research in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "The systems in the bin setting are evaluated using F-score.", "labels": [], "entities": [{"text": "F-score", "start_pos": 51, "end_pos": 58, "type": "METRIC", "confidence": 0.9888167381286621}]}, {"text": "The systems in the prob setting are evaluated using mean absolute error (MAE) which estimates the average difference between the values in the gold standard and values predicted by the system across all test instances.", "labels": [], "entities": [{"text": "mean absolute error (MAE)", "start_pos": 52, "end_pos": 77, "type": "METRIC", "confidence": 0.9225847721099854}]}, {"text": "The effectiveness of features varies according to the data set classified.", "labels": [], "entities": []}, {"text": "For the WIKINEWS and NEWS all aforementioned features are integrated into the systems.", "labels": [], "entities": [{"text": "WIKINEWS", "start_pos": 8, "end_pos": 16, "type": "DATASET", "confidence": 0.9008850455284119}, {"text": "NEWS", "start_pos": 21, "end_pos": 25, "type": "DATASET", "confidence": 0.9376205801963806}]}, {"text": "The feature set for WIKIPEDIA does not include MCR psycholinguistic features.", "labels": [], "entities": [{"text": "WIKIPEDIA", "start_pos": 20, "end_pos": 29, "type": "DATASET", "confidence": 0.8717312812805176}]}], "tableCaptions": [{"text": " Table 1: Number of instances", "labels": [], "entities": []}, {"text": " Table 2: Annotation labels break-down (%)", "labels": [], "entities": []}, {"text": " Table 3: Test set results", "labels": [], "entities": []}, {"text": " Table 4: Unique words distribution", "labels": [], "entities": []}, {"text": " Table 5: Binary classification results for the phrase  classification in the test set", "labels": [], "entities": [{"text": "Binary classification", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.9641084372997284}, {"text": "phrase  classification", "start_pos": 48, "end_pos": 70, "type": "TASK", "confidence": 0.7462420463562012}]}, {"text": " Table 6: Test set results using n-gram phrase classifier", "labels": [], "entities": []}, {"text": " Table 7: Gini coefficient for feature contribution", "labels": [], "entities": [{"text": "Gini coefficient", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.9013466536998749}]}, {"text": " Table 9: POS Classification Metrics", "labels": [], "entities": [{"text": "POS Classification Metrics", "start_pos": 10, "end_pos": 36, "type": "DATASET", "confidence": 0.6795529921849569}]}]}