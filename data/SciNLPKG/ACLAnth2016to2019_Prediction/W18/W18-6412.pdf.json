{"title": [{"text": "The University of Edinburgh's Submissions to the WMT18 News Translation Task", "labels": [], "entities": [{"text": "Submissions to the WMT18 News Translation", "start_pos": 30, "end_pos": 71, "type": "TASK", "confidence": 0.7396332621574402}]}], "abstractContent": [{"text": "The University of Edinburgh made submissions to all 14 language pairs in the news translation task, with strong performances inmost pairs.", "labels": [], "entities": [{"text": "news translation task", "start_pos": 77, "end_pos": 98, "type": "TASK", "confidence": 0.7804625928401947}]}, {"text": "We introduce new RNN-variant, mixed RNN/Transformer ensembles, data selection and weighting, and extensions to back-translation.", "labels": [], "entities": [{"text": "data selection", "start_pos": 63, "end_pos": 77, "type": "TASK", "confidence": 0.7376053035259247}]}], "introductionContent": [{"text": "For the WMT18 news translation task, we were the only team to make submissions to all 14 language pairs.", "labels": [], "entities": [{"text": "WMT18 news translation task", "start_pos": 8, "end_pos": 35, "type": "TASK", "confidence": 0.7877671867609024}]}, {"text": "Our submissions built on our strong results of the WMT16 and WMT17 tasks, in that we used neural machine translation (NMT) with byte-pair encoding (BPE) (), back-translation () and deep RNNs (Miceli . For this year's submissions we experimented with new architectures, and new ways of data handling.", "labels": [], "entities": [{"text": "WMT16 and WMT17 tasks", "start_pos": 51, "end_pos": 72, "type": "DATASET", "confidence": 0.6426098793745041}, {"text": "neural machine translation (NMT)", "start_pos": 90, "end_pos": 122, "type": "TASK", "confidence": 0.7767471472422282}, {"text": "data handling", "start_pos": 285, "end_pos": 298, "type": "TASK", "confidence": 0.7240334153175354}]}, {"text": "In brief, the innovations that we introduced this year are: Architecture This year we experimented with the Transformer architecture (, as implemented by Marian (, as well as introducing anew variant on the deep RNN architectire (Section 2.3).", "labels": [], "entities": [{"text": "Marian", "start_pos": 154, "end_pos": 160, "type": "DATASET", "confidence": 0.9615371823310852}]}, {"text": "Data selection and weighting For some language pairs, we experimented with different data selection schemes, motivated by the introduction of the noisy ParaCrawl corpora to the task (Section 2.1).", "labels": [], "entities": [{"text": "Data selection", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8138012290000916}]}, {"text": "We also applied weighting of different corpora to most language pairs, particularly DE\u2194EN (Section 3.5).", "labels": [], "entities": []}, {"text": "Extensions to Back-translation For TR\u2194EN (Section 3.7) we used copied monolingual data () and iterative back-translation.", "labels": [], "entities": []}, {"text": "In-domain Fine-tuning For RU\u2194EN (Section 3.6) we fine-tuned using a specially constructed \"in-domain\" data set.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we present results of some postsubmission experiments, which attempted to provide more insight into the contribution of different features of our system.", "labels": [], "entities": []}, {"text": "We were especially interested in understanding why our systems tended to lag behind the performance of the best systems (in BLEU, at least).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 124, "end_pos": 128, "type": "METRIC", "confidence": 0.9933386445045471}]}, {"text": "Mostly the experiments were conducted on EN\u2194{CS,ET,FI}.", "labels": [], "entities": []}, {"text": "The results are given on newstest2017 (devtest) and newstest2018 (test), except for ET\u2194EN, where devtest is half of newsdev2018.", "labels": [], "entities": [{"text": "ET\u2194EN", "start_pos": 84, "end_pos": 89, "type": "METRIC", "confidence": 0.7988948027292887}]}], "tableCaptions": [{"text": " Table 1: Blend of data for training the DE\u2194EN en- semble models (40M sentence pairs total).", "labels": [], "entities": [{"text": "Blend", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9712001085281372}]}, {"text": " Table 3: Impact of in-domain fine-tuning on the RU \u2194 EN task. Reported are best validation-BLEU scores  averaged over all single models of the denoted type in the submitted ensemble systems. Statistical significance  was established using a paired, two-tailed t-test.", "labels": [], "entities": [{"text": "significance", "start_pos": 204, "end_pos": 216, "type": "METRIC", "confidence": 0.5193372964859009}]}, {"text": " Table 5: Results for EN\u2194TR systems on official WMT  test sets.", "labels": [], "entities": [{"text": "WMT  test sets", "start_pos": 48, "end_pos": 62, "type": "DATASET", "confidence": 0.8441012700398763}]}, {"text": " Table 6: Overall BLEU scores of our systems, compared to the top-scoring constrained systems. We also show the  difference with the direct assessment (DA) score of the best constrained system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.999359667301178}, {"text": "direct assessment (DA) score", "start_pos": 133, "end_pos": 161, "type": "METRIC", "confidence": 0.7883696357409159}]}, {"text": " Table 7: Comparison of performance of deep RNN  models with/without the multihop/multihead exten- sion.", "labels": [], "entities": []}, {"text": " Table 8: Effect of reducing vocabulary size for deep  RNN models. We used 89,500 BPE merges for our  submissions, but tried reducing it to 30,000 for post- submission experiments.", "labels": [], "entities": [{"text": "BPE", "start_pos": 82, "end_pos": 85, "type": "METRIC", "confidence": 0.8951901793479919}]}, {"text": " Table 9: Effect of reducing vocabulary size for Transformer models. We used 89,500 BPE merges for our sub- missions, but tried reducing it to 30,000 for post-submission experiments. We also show the effect of tying all  embeddings.", "labels": [], "entities": [{"text": "BPE", "start_pos": 84, "end_pos": 87, "type": "METRIC", "confidence": 0.9516222476959229}]}, {"text": " Table 10: Effect of mixed versus uniform ensembles. The ensembles are either 2 deep RNNs and 2 transformers,  or 4 RNNs.", "labels": [], "entities": []}]}