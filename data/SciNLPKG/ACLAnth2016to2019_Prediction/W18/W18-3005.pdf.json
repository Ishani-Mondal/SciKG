{"title": [{"text": "Text Completion using a Context-Integrating Dependency Parser", "labels": [], "entities": [{"text": "Text Completion", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.6927786022424698}]}], "abstractContent": [{"text": "Incomplete linguistic input, i.e. due to a noisy environment, is one of the challenges that a successful communication system has to deal with.", "labels": [], "entities": []}, {"text": "In this paper, we study text completion with a data set composed of sentences with gaps where a successful completion cannot be achieved through a uni-modal (language-based) approach.", "labels": [], "entities": [{"text": "text completion", "start_pos": 24, "end_pos": 39, "type": "TASK", "confidence": 0.759519636631012}]}, {"text": "We present a solution based on a context-integrating dependency parser incorporating an additional non-linguistic modality.", "labels": [], "entities": []}, {"text": "An incompleteness in one channel is compensated by information from another one and the parser learns the association between the two modalities from a multiple level knowledge representation.", "labels": [], "entities": []}, {"text": "We examined several model variations by adjusting the degree of influence of different modalities in the decision making on possible filler words and their exact reference to a non-linguistic context element.", "labels": [], "entities": []}, {"text": "Our model is able to fill the gap with 95.4% word and 95.2% exact reference accuracy hence the successful prediction can be achieved not only on the word level (such as mug) but also with respect to the correct identification of its context reference (such as mug 2 among several mug instances).", "labels": [], "entities": [{"text": "exact reference accuracy", "start_pos": 60, "end_pos": 84, "type": "METRIC", "confidence": 0.8845710953076681}]}], "introductionContent": [{"text": "Text completion/prediction is a crucial element of communication systems, due to its role in increasing the fluency and the effectiveness of the communication in scenarios where the environment is noisy, or the communication partner suffers * *These authors contributed equally to this work from a motor, or cognitive impairment.", "labels": [], "entities": [{"text": "Text completion/prediction", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.84677554666996}]}, {"text": "In this study, we tackle the problem of compensating the incompleteness of the verbal channel by additional information from visual modality.", "labels": [], "entities": []}, {"text": "This capability for multi-modal integration can be a very specific yet crucial feature in resolving references and/or performing commands for i.e. a helper robot that aids people in their daily activities.", "labels": [], "entities": []}, {"text": "To the authors' knowledge, there is no multi-modal data set fora text completion task that systematically addresses challenging linguistic structures (i.e. syntactic or referential ambiguities) for environments where helper robots, who have access to visual information, would be employed.", "labels": [], "entities": [{"text": "text completion", "start_pos": 65, "end_pos": 80, "type": "TASK", "confidence": 0.6975812911987305}]}, {"text": "The completion is performed by predicting tenable fillers for the missing, unknown, or vague parts in the input sentences through varying techniques, using single or hybrid methods.", "labels": [], "entities": [{"text": "predicting tenable fillers", "start_pos": 31, "end_pos": 57, "type": "TASK", "confidence": 0.8094545006752014}]}, {"text": "The prediction process utilizes the available resources, usually linguistic information (morphological, syntactic, and semantic properties).", "labels": [], "entities": []}, {"text": "It can also use additional information sources such as the linguistic, or visual context ().", "labels": [], "entities": []}, {"text": "If only the linguistic level is available, a language model can be used to predict the probability of a syntactic category in a certain context).", "labels": [], "entities": []}, {"text": "N-grams is a popular method for this task since they provide very robust predictions for local dependencies.", "labels": [], "entities": []}, {"text": "Nevertheless, they loose their power for structures with long-range dependencies.", "labels": [], "entities": []}, {"text": "Furthermore, if there are multiple instances of the same object class (c.f.), a text completion based on N-gram could not differentiate between them to select the proper instance reference.", "labels": [], "entities": []}, {"text": "As shown in several studies (), a language model employing the syntactic dependencies of a sentence brings the relevant contexts closer.", "labels": [], "entities": []}, {"text": "Using the Microsoft Research Sentence Completion Challenge (, have showed that incorporating syntactic information leads to grammatically better options fora semantic text completion task.", "labels": [], "entities": [{"text": "semantic text completion task", "start_pos": 158, "end_pos": 187, "type": "TASK", "confidence": 0.7145297080278397}]}, {"text": "On the other hand, semantic clustering or classification (like in ontologies) can be used to derive predictions on the semantic level.", "labels": [], "entities": [{"text": "semantic clustering or classification", "start_pos": 19, "end_pos": 56, "type": "TASK", "confidence": 0.6926336735486984}]}, {"text": "However, when it comes to the description of daily activities, contextual information coming from another modality would be more beneficial, since linguistic distributions alone could hardly contribute enough clues to distinguish the action of washing a pan from washing a mug, which is a crucial difference for helper robots.", "labels": [], "entities": []}, {"text": "A popular trick in natural language processing consists in training a model on one task, and then apply it to an entirely different one.", "labels": [], "entities": []}, {"text": "We adopt this method by training a multi-modal dependency parser using noise-free sentences combined with a description of their visual context.", "labels": [], "entities": []}, {"text": "In the second step, we make use of the trained parser to predict the best fillers of the gaps (guided by the context modality).", "labels": [], "entities": []}, {"text": "The paper starts by introducing our multi-modal approach for the text completion task.", "labels": [], "entities": [{"text": "text completion task", "start_pos": 65, "end_pos": 85, "type": "TASK", "confidence": 0.8843316634496053}]}, {"text": "In section 3, we present the experimental setup including the compiled dataset.", "labels": [], "entities": []}, {"text": "The implementation is described in section 4.", "labels": [], "entities": []}, {"text": "Experimental results are presented and discussed in section 5.", "labels": [], "entities": []}, {"text": "Conclusions are drawn and future directions of research are pointed out at the end of the paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: POS templates, the number of sentences and gaps for each sentence types, and the number of  gaps for each POS category", "labels": [], "entities": []}, {"text": " Table 2: Complexity of the contextual information  for the visual scenes in the data set", "labels": [], "entities": []}, {"text": " Table 3: The results of the different model variations", "labels": [], "entities": []}]}