{"title": [{"text": "Syntactic Dependency Representations in Neural Relation Classification", "labels": [], "entities": [{"text": "Syntactic Dependency Representations", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.8960230151812235}, {"text": "Neural Relation Classification", "start_pos": 40, "end_pos": 70, "type": "TASK", "confidence": 0.7823046843210856}]}], "abstractContent": [{"text": "We investigate the use of different syntactic dependency representations in a neu-ral relation classification task and compare the CoNLL, Stanford Basic and Universal Dependencies schemes.", "labels": [], "entities": [{"text": "relation classification task", "start_pos": 86, "end_pos": 114, "type": "TASK", "confidence": 0.801086962223053}, {"text": "CoNLL", "start_pos": 131, "end_pos": 136, "type": "DATASET", "confidence": 0.9121471643447876}]}, {"text": "We further compare with a syntax-agnostic approach and perform an error analysis in order to gain a better understanding of the results.", "labels": [], "entities": []}], "introductionContent": [{"text": "The neural advances in the field of NLP challenge long held assumptions regarding system architectures.", "labels": [], "entities": []}, {"text": "The classical NLP systems, where components of increasing complexity are combined in a pipeline architecture are being challenged by endto-end architectures that are trained on distributed word representations to directly produce different types of analyses traditionally assigned to downstream tasks.", "labels": [], "entities": []}, {"text": "Syntactic parsing has been viewed as a crucial component for many tasks aimed at extracting various aspects of meaning from text, but recent work challenges many of these assumptions.", "labels": [], "entities": [{"text": "Syntactic parsing", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8938365280628204}]}, {"text": "For the task of semantic role labeling for instance, systems that make little or no use of syntactic information, have achieved state-of-theart results.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 16, "end_pos": 38, "type": "TASK", "confidence": 0.712788462638855}]}, {"text": "For tasks where syntactic information is still viewed as useful, a variety of new methods for the incorporation of syntactic information are employed, such as recursive models over parse trees , tree-structured attention mechanisms (, multi-task learning (, or the use of various types of syntactically aware input representations, such as embeddings over syntactic dependency paths ().", "labels": [], "entities": []}, {"text": "Dependency representations have by now become widely used representations for syntactic analysis, often motivated by their usefulness in downstream application.", "labels": [], "entities": [{"text": "syntactic analysis", "start_pos": 78, "end_pos": 96, "type": "TASK", "confidence": 0.8625166118144989}]}, {"text": "There is currently a wide range of different types of dependency representations in use, which vary mainly in terms of choices concerning syntactic head status.", "labels": [], "entities": []}, {"text": "Some previous studies have examined the effects of dependency representations in various downstream applications ().", "labels": [], "entities": []}, {"text": "Most recently, the Shared Task on Extrinsic Parser Evaluation () was aimed at providing better estimates of the relative utility of different types of dependency representations and syntactic parsers for downstream applications.", "labels": [], "entities": [{"text": "Shared Task on Extrinsic Parser Evaluation", "start_pos": 19, "end_pos": 61, "type": "TASK", "confidence": 0.6195102284351984}]}, {"text": "The downstream systems in this previous work have, however, been limited to traditional (non-neural) systems and there is still a need fora better understanding of the contribution of syntactic information in neural downstream systems.", "labels": [], "entities": []}, {"text": "In this paper, we examine the use of syntactic representations in a neural approach to the task of relation classification.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 99, "end_pos": 122, "type": "TASK", "confidence": 0.9051854312419891}]}, {"text": "We quantify the effect of syntax by comparing to a syntax-agnostic approach and further compare different syntactic dependency representations that are used to generate embeddings over dependency paths.", "labels": [], "entities": []}, {"text": "illustrates the three different dependency representations we compare: the socalled CoNLL-style dependencies which were used for the shared tasks of the Conference on Natural Language Learning (CoNLL), the Stanford 'basic' dependencies (SB)) and the Universal Dependencies (v1.3) (UD;.", "labels": [], "entities": []}, {"text": "We see that the analyses differ both in terms of their choices of heads vs. dependents and the inventory of dependency types.", "labels": [], "entities": []}, {"text": "Where CoNLL analyses tend to view functional words as heads (e.g., the auxiliary verb are), the Stanford scheme capitalizes more on content words as heads (e.g., the main verb treated).", "labels": [], "entities": []}, {"text": "UD takes the tendency to select contentful heads one step further, analyzing the prepositional complement functions as ahead, with the preposition as itself as a dependent case marker.", "labels": [], "entities": [{"text": "UD", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.537265419960022}]}, {"text": "This is in contrast to the CoNLL and Stanford scheme, where the preposition is head.", "labels": [], "entities": [{"text": "CoNLL", "start_pos": 27, "end_pos": 32, "type": "DATASET", "confidence": 0.92952960729599}]}], "datasetContent": [{"text": "We use the SemEval-2018, Task 7 dataset () from its Subtask 1.1.", "labels": [], "entities": [{"text": "SemEval-2018, Task 7 dataset", "start_pos": 11, "end_pos": 39, "type": "DATASET", "confidence": 0.6914962649345398}]}, {"text": "The training data contains abstracts of 350 papers from the ACL Anthology Corpus, annotated for concepts and semantic relations.", "labels": [], "entities": [{"text": "ACL Anthology Corpus", "start_pos": 60, "end_pos": 80, "type": "DATASET", "confidence": 0.9552812377611796}]}, {"text": "Given an abstract of a scientific paper with pre-annotated domain concepts, the task is to perform relation classification.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 99, "end_pos": 122, "type": "TASK", "confidence": 0.910729318857193}]}, {"text": "The classification sub-task 1.1 contains 1228 entity pairs that are annotated based on five asymmetric relations (USAGE, RESULT, MODEL-FEATURE, PART WHOLE, TOPIC) and one symmetric relation (COMPARE).", "labels": [], "entities": [{"text": "USAGE", "start_pos": 114, "end_pos": 119, "type": "DATASET", "confidence": 0.9351198077201843}, {"text": "RESULT", "start_pos": 121, "end_pos": 127, "type": "METRIC", "confidence": 0.9841055274009705}, {"text": "MODEL-FEATURE", "start_pos": 129, "end_pos": 142, "type": "METRIC", "confidence": 0.9587399363517761}, {"text": "PART WHOLE", "start_pos": 144, "end_pos": 154, "type": "METRIC", "confidence": 0.8242847323417664}, {"text": "TOPIC", "start_pos": 156, "end_pos": 161, "type": "METRIC", "confidence": 0.870047926902771}]}, {"text": "The relation instance along with its directionality are provided in both the training and the test data sets.", "labels": [], "entities": []}, {"text": "The official evaluation metric is the macro-averaged F1-scores for the six semantic relations, therefore we will compare the impact of different dependency representations on the macro-averaged F1-scores.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.938697338104248}]}, {"text": "The training set for Subtask 1.1 is quite small, which is a challenge for end-to-end neural methods.", "labels": [], "entities": []}, {"text": "To overcome this, we combined the provided datasets for Subtask 1.1 and Subtask 1.2 (relation classification on noisy data), which provides additional 350 abstracts and 1248 labeled entity pairs to train our model.", "labels": [], "entities": [{"text": "relation classification on noisy data", "start_pos": 85, "end_pos": 122, "type": "TASK", "confidence": 0.8309277892112732}]}, {"text": "This yields a positive impact (+16.00% F1) on the classification task in our initial experiments.", "labels": [], "entities": [{"text": "F1", "start_pos": 39, "end_pos": 41, "type": "METRIC", "confidence": 0.9994471669197083}, {"text": "classification", "start_pos": 50, "end_pos": 64, "type": "TASK", "confidence": 0.9806540608406067}]}, {"text": "We run all the experiments with a multi-channel setting in which the first channel is initialized with pre-trained embeddings 6 in static mode (i.e. it is not updated during training) and the second one is initialized randomly and is fine-tuned during training (non-static mode).", "labels": [], "entities": []}, {"text": "The macro F1-score is measured by 5-fold cross validation and to deal with the effects of class imbalance, we weight the cost by the ratio of class instances, thus each observation receives a weight, depending on the class it belongs to.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.8842989206314087}]}], "tableCaptions": [{"text": " Table 2: Hyper parameter optimization results for each model with different representation. The max  pooling strategy consistently performs better in all model variations.", "labels": [], "entities": [{"text": "Hyper parameter optimization", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.7217403054237366}]}, {"text": " Table 1: Effect of using the shortest dependency  path on each relation type.", "labels": [], "entities": []}, {"text": " Table 4: The examples for which the CoNLL/SB-based models correctly predict the relation type in  5-fold trials, whereas the UD based model has an incorrect prediction.", "labels": [], "entities": []}, {"text": " Table 3: Effect of using the different parser repre- sentation on each relation type.", "labels": [], "entities": []}]}