{"title": [{"text": "Exploiting Common Characters in Chinese and Japanese to Learn Cross-lingual Word Embeddings via Matrix Factorization", "labels": [], "entities": []}], "abstractContent": [{"text": "Learning vector space representation of words (i.e., word embeddings) has recently attracted wide research interests , and has been extended to cross-lingual scenario.", "labels": [], "entities": []}, {"text": "Currently most cross-lingual word embedding learning models are based on sentence alignment, which inevitably introduces much noise.", "labels": [], "entities": [{"text": "sentence alignment", "start_pos": 73, "end_pos": 91, "type": "TASK", "confidence": 0.7212343662977219}]}, {"text": "In this paper, we show in Chinese and Japanese, the acquisition of semantic relation among words can benefit from the large number of common characters shared by both languages ; inspired by this unique feature , we design a method named CJC targeting to generate cross-lingual context of words.", "labels": [], "entities": []}, {"text": "We combine CJC with GloVe based on matrix factorization, and then propose an integrated model named CJ-Glo.", "labels": [], "entities": []}, {"text": "Taking two sentence-aligned models and CJ-BOC (also exploits common characters but is based on CBOW) as baseline algorithms, we compare them with CJ-Glo on a series of NLP tasks including cross-lingual synonym, word analogy and sentence alignment.", "labels": [], "entities": [{"text": "word analogy", "start_pos": 211, "end_pos": 223, "type": "TASK", "confidence": 0.7946431040763855}, {"text": "sentence alignment", "start_pos": 228, "end_pos": 246, "type": "TASK", "confidence": 0.769707977771759}]}, {"text": "The result indicates CJ-Glo achieves the best performance among these methods, and is more stable in cross-lingual tasks; moreover, compared with CJ-BOC, CJ-Glo is less sensitive to the alteration of parameters.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word representation is critical to various NLP tasks, and the traditional one-hot representation, despite its simplicity, suffers from at least two aspects: the vector dimensionality increases with vocabulary size, leading to \"curse of dimensionality\"; more importantly, it fails to capture the semantic relation among words.", "labels": [], "entities": [{"text": "Word representation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.698435440659523}]}, {"text": "Due to the defects of one-hot representation, the majority of research interests now have switched to distributed word representation (also known as \"word embedding\"), which represents word as a real-valued vector.", "labels": [], "entities": []}, {"text": "Represented as vectors, the semantics of words are better reflected, as the relatedness of words can be quantified using vector arithmetic.", "labels": [], "entities": []}, {"text": "To efficiently train word embeddings, a range of models have been proposed, most of them targeting to train monolingual word embedding.", "labels": [], "entities": []}, {"text": "Though word embedding is often discussed under monolingual scenario, crosslingual embedding can serve as a useful tool in several NLP tasks including machine translation (, word sense disambiguation (, and soon.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 150, "end_pos": 169, "type": "TASK", "confidence": 0.8266721665859222}, {"text": "word sense disambiguation", "start_pos": 173, "end_pos": 198, "type": "TASK", "confidence": 0.6702408194541931}]}, {"text": "This is because cross-lingual word embeddings map words from two languages into one vector space, thereby making it possible to measure the semantic relation among words from different languages.", "labels": [], "entities": []}, {"text": "However, compared with the bulk of works studying monolingual word embedding, cross-lingual word embedding is still at its initial stage, with no learning model being widely accepted.", "labels": [], "entities": []}, {"text": "In this paper, we present a method named CJC (Chinese-Japanese Common Character) aiming to extract cross-lingual context of words from sentence aligned Chinese-Japanese corpus.", "labels": [], "entities": []}, {"text": "Given the large amount of common characters shared by both languages and the rich semantic connections thereof, we exploit them to acquire potential word level alignment.", "labels": [], "entities": [{"text": "word level alignment", "start_pos": 149, "end_pos": 169, "type": "TASK", "confidence": 0.6873737374941508}]}, {"text": "The acquired cross-lingual contexts can be flexibly integrated with various models; in this paper, CJC is mainly integrated with a matrix factorization model called Glove, and the integrated model is thus called CJ-Glo.", "labels": [], "entities": []}, {"text": "To evaluate the performance of CJ-Glo, we take 2 sentence aligned models respectively based on CBOW( and GloVe, and CJ-BOC model (based on Common Character + CBOW) (  as contrast, and compare the trained word embeddings of these methods using three typical NLP tasks, including cross-lingual synonym, word analogy and sentence alignment.", "labels": [], "entities": [{"text": "word analogy", "start_pos": 301, "end_pos": 313, "type": "TASK", "confidence": 0.7983394265174866}, {"text": "sentence alignment", "start_pos": 318, "end_pos": 336, "type": "TASK", "confidence": 0.7479324340820312}]}, {"text": "According to the experiment results, the acquired word embeddings by using CJ-Glo have better quality than those of the other models; moreover, CJ-Glo performs more stably than its competitors, and is less sensitive to parameter alteration.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the quality of cross-lingual word embeddings obtained from various models, we conducted three groups of experiments: 1) the straightforward cross-lingual synonym comparison; 2) cross-lingual word analogy; 3) sentence alignment.", "labels": [], "entities": [{"text": "cross-lingual word analogy", "start_pos": 189, "end_pos": 215, "type": "TASK", "confidence": 0.6560441156228384}, {"text": "sentence alignment", "start_pos": 220, "end_pos": 238, "type": "TASK", "confidence": 0.7440345585346222}]}, {"text": "In monolingual scenario, the word embeddings of a pair of synonyms should have a high cosine similarity.", "labels": [], "entities": []}, {"text": "This property is also applicable in cross-lingual word embeddings, i.e., the cosine similarity between a word embedding and its translated counterpart should also be high.", "labels": [], "entities": []}, {"text": "In real applications, the correspondence between words in source language and words in target language can be one-to-one, one-to-many, or vice versa.", "labels": [], "entities": []}, {"text": "Ambiguity is eliminated in all these word pairs, so a large rate is therefore favored.", "labels": [], "entities": [{"text": "Ambiguity", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9713616371154785}]}, {"text": "Word analogy is probably the most widely adopted task to evaluate the performance of word embeddings, because it depicts the connection between trained vector space and word semantics.", "labels": [], "entities": [{"text": "Word analogy", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.7108415216207504}]}, {"text": "Both CBOW() and GloVe() used a dataset with 19,544 queries for evaluation.", "labels": [], "entities": [{"text": "CBOW", "start_pos": 5, "end_pos": 9, "type": "DATASET", "confidence": 0.8079375624656677}]}, {"text": "Given several related words from different languages, cross-lingual analogical reasoning works as follows: y=v(\u306f \u306f)-v(\u3061 \u3061)+v(\u7537 \u5b69), we hope that the relatedness between Japanese words \"\u306f\u306f (mother)\" and \"\u3061\u3061 (father)\" could help us find the Chinese word \"\u5973 \u5b69 (girl)\" and Japanese \"\u5973 \u306e \u5b50 (girl)\" through Chinese word \"\u7537\u5b69 (boy)\".", "labels": [], "entities": [{"text": "cross-lingual analogical reasoning", "start_pos": 54, "end_pos": 88, "type": "TASK", "confidence": 0.7402462164560953}]}, {"text": "More formally, the cross-lingual analogy task was undertaken as follows: 1.", "labels": [], "entities": [{"text": "cross-lingual analogy", "start_pos": 19, "end_pos": 40, "type": "TASK", "confidence": 0.7740086019039154}]}, {"text": "Input a quadruple of word embeddings \u27e8w 1 : w 2 :: w 3 : w 4 \u27e9, where each word could be either Chinese or Japanese; 2.", "labels": [], "entities": []}, {"text": "Compute the target vector u = w 2 \u2212w 1 +w 3 , acquire the corresponding rank and rate as in cross-lingual synonym comparison for u \u2192 w 4 ; 3.", "labels": [], "entities": []}, {"text": "Based on the ratio of Chinese word count to Japanese word count in the quadruple \u27e8w 1 : w 2 :: w 3 : w 4 \u27e9, the word analogy task is divided into 5 subtasks, whose ratio are (0 : 4), (1 : 3), (2 : 2), (3 : 1) and (4 : 0), and their respective query amount is 420, 1680, 2520, 1680, and 420 in our experiment; 4.", "labels": [], "entities": [{"text": "word analogy task", "start_pos": 112, "end_pos": 129, "type": "TASK", "confidence": 0.7979464729626974}]}, {"text": "Calculate the average rate on every subtask.", "labels": [], "entities": [{"text": "average rate", "start_pos": 14, "end_pos": 26, "type": "METRIC", "confidence": 0.8912646472454071}]}, {"text": "Also, the average rate here is expected to be as large as possible.", "labels": [], "entities": [{"text": "average rate", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.702094554901123}]}, {"text": "The above experiments respectively evaluated the direct similarity and cross-lingual feature of word embeddings.", "labels": [], "entities": []}, {"text": "And now we consider a more complicated task: sentence alignment.", "labels": [], "entities": [{"text": "sentence alignment", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.8022241592407227}]}, {"text": "In the dataset from (), other than training data, a manual test dataset was also attached, which are 198 sentence pairs.", "labels": [], "entities": []}, {"text": "Using this dataset, we conduct this experiment as follows: 1.", "labels": [], "entities": []}, {"text": "For a Chinese sentence S zh,i , calculate its average vector U zh,i and all U ja of all sentences S ja , and compute the cosine similarity.", "labels": [], "entities": []}, {"text": "2. Sort all the cosine similarities in step 2, and acquire the rank of the average vector U ja,i of S ja,i (the parallel sentence of S zh,i ).", "labels": [], "entities": []}, {"text": "3. Transform rank into rate using formula 10, where total number is 198.", "labels": [], "entities": []}, {"text": "4. Compute the average rate S zh \u2192 S ja ; 5.", "labels": [], "entities": [{"text": "average rate S zh", "start_pos": 15, "end_pos": 32, "type": "METRIC", "confidence": 0.8686013519763947}]}, {"text": "Follow the same steps above to generate Compared with the previous experiments, which evaluate only the relation between individual word embeddings, sentence alignment is a comprehensive task using word embedding, and is a critical indicator for the overall quality of the trained word embeddings.", "labels": [], "entities": [{"text": "sentence alignment", "start_pos": 149, "end_pos": 167, "type": "TASK", "confidence": 0.7806147336959839}]}, {"text": "As mentioned previously, () generated a parallel corpus including ChineseJapanese sentence pairs from Wikipedia; train.ja and train.zh in this dataset were used throughout our empirical study, both containing 126,811 lines of text.", "labels": [], "entities": []}, {"text": "Concretely, every single line in these two files is a complete sentence, which is parallel to its counterpart in the other file.", "labels": [], "entities": []}, {"text": "As the preprocessing for datasets, both files were segmented using MeCab 1 and Jieba 2 for Japanese and Chinese, respectively.", "labels": [], "entities": []}, {"text": "During the preprocessing, we assured the segmentation on Chinese and  Japanese were approximately grained, by tuning parameters.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 41, "end_pos": 53, "type": "TASK", "confidence": 0.959220290184021}]}, {"text": "Four models in total are put into comparison in our experiment: 1.", "labels": [], "entities": []}, {"text": "SenBow model is the bilingual CBOW model applying sentence-aligned method; 2.", "labels": [], "entities": []}, {"text": "CJ-BOC model from ( , considered as a CJC+CBOW model; 3.", "labels": [], "entities": []}, {"text": "SenGlo model applies sentence-aligned method to GloVe model; 4.", "labels": [], "entities": []}, {"text": "CJ-Glo model is our CJC method enhanced GloVe model.", "labels": [], "entities": []}, {"text": "The parameters of CJC learning rate \u03bb and sentence learning rate \u00b5 are showed in.", "labels": [], "entities": [{"text": "sentence learning rate \u00b5", "start_pos": 42, "end_pos": 66, "type": "METRIC", "confidence": 0.677337221801281}]}, {"text": "Both SenGlo and CJ-Glo have am max of 100, and an \u03b1 of 3 4 . The thread count is 16 in the implementations of all these four models, the output vector dimensionality is 100, and the training process is iterated 15 times.", "labels": [], "entities": [{"text": "am max", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.97690549492836}]}, {"text": "We set the parameters to the above values, since these models achieved the optimal performances under such settings in our evaluation.", "labels": [], "entities": []}, {"text": "All models are implemented using C language, and the code can be found on GitHub 3 .: Cross-lingual word analogy experiment result.", "labels": [], "entities": [{"text": "Cross-lingual word analogy", "start_pos": 86, "end_pos": 112, "type": "TASK", "confidence": 0.6520415743192037}]}, {"text": "X-axis is the number ratio of Chinese words and Japanese words in the analogy query (w 1 : w 2 :: w 3 : w 4 ).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Estimated MI and CMI of 5 Common  Characters.", "labels": [], "entities": [{"text": "Estimated", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9974350333213806}, {"text": "MI", "start_pos": 20, "end_pos": 22, "type": "METRIC", "confidence": 0.8643369674682617}, {"text": "CMI", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.871004045009613}]}, {"text": " Table 3: Parameters of CJC and sentence  learning rates in each models.", "labels": [], "entities": []}, {"text": " Table 4: Cross-lingual synonym comparison  results on 200 one-to-one word pairs, the av- erage rates(%) of each models.", "labels": [], "entities": [{"text": "Cross-lingual synonym comparison", "start_pos": 10, "end_pos": 42, "type": "TASK", "confidence": 0.8087726831436157}, {"text": "av- erage rates", "start_pos": 86, "end_pos": 101, "type": "METRIC", "confidence": 0.8560765832662582}]}, {"text": " Table 3.  Both SenGlo and CJ-Glo have a m max of 100,  and an \u03b1 of 3  4 . The thread count is 16 in the  implementations of all these four models, the  output vector dimensionality is 100, and the  training process is iterated 15 times. We set  the parameters to the above values, since these  models achieved the optimal performances un- der such settings in our evaluation. All mod- els are implemented using C language, and the  code can be found on GitHub 3 .", "labels": [], "entities": []}, {"text": " Table 5: Sentence alignment results on 198  parallel sentence pairs, the average rates(%)  of each models.", "labels": [], "entities": [{"text": "Sentence alignment", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.9516394138336182}]}]}