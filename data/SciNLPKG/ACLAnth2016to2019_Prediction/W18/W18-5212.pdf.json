{"title": [{"text": "Incorporating Topic Aspects for Online Comment Convincingness Evaluation", "labels": [], "entities": [{"text": "Incorporating Topic Aspects", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7064002752304077}, {"text": "Online Comment Convincingness", "start_pos": 32, "end_pos": 61, "type": "TASK", "confidence": 0.6137616038322449}]}], "abstractContent": [{"text": "In this paper, we propose to incorporate topic aspects information for online comments con-vincingness evaluation.", "labels": [], "entities": []}, {"text": "Our model makes use of graph convolutional network to utilize implicit topic information within a discussion thread to assist the evaluation of convincing-ness of each single comment.", "labels": [], "entities": []}, {"text": "In order to test the effectiveness of our proposed model, we annotate topic information on top of a public dataset for argument convincingness evaluation.", "labels": [], "entities": [{"text": "argument convincingness evaluation", "start_pos": 119, "end_pos": 153, "type": "TASK", "confidence": 0.8170873522758484}]}, {"text": "Experimental results show that topic information is able to improve the performance for convincingness evaluation.", "labels": [], "entities": [{"text": "convincingness evaluation", "start_pos": 88, "end_pos": 113, "type": "TASK", "confidence": 0.769778698682785}]}, {"text": "We also make a move to detect topic aspects automatically.", "labels": [], "entities": []}], "introductionContent": [{"text": "With the popularity of online forums such as idebate and convinceme , researchers have been paying increasing attention to analyzing persuasion content.", "labels": [], "entities": []}, {"text": "Argument convincingness assessment plays an important role in persuasion content analysis.", "labels": [], "entities": [{"text": "Argument convincingness assessment", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7910434504350027}, {"text": "persuasion content analysis", "start_pos": 62, "end_pos": 89, "type": "TASK", "confidence": 0.899588386217753}]}, {"text": "Previous researchers attribute the convincingness of arguments to argument structure, strong evidence), specific argument components, interactions, domain knowledge ( and soon.", "labels": [], "entities": []}, {"text": "Most efforts of convincingness evaluation focus on using explicit linguistic features, such as words ( and part-of-speech (POS) (  To illustrate this idea, gives a brief example of an argument pair.", "labels": [], "entities": []}, {"text": "Both arguments express opinions against the banning of plastic water bottles.", "labels": [], "entities": []}, {"text": "Argument 1 is expressed from the topic aspect of economy while Argument 2 makes the point from the aspect of convenience and health.", "labels": [], "entities": []}, {"text": "As we can see, fora specific discussion subject, different aspects might reveal various degree of convincingness. has already made attempt to make use of latent persuasive strengths of topic aspects for quality evaluation on a formal debate dataset.", "labels": [], "entities": []}, {"text": "However, there is still no further research on online debating texts, which is un-structured with multiple participants.", "labels": [], "entities": []}, {"text": "In this paper, we propose to incorporate latent topic aspects information to evaluate the convincingness of comments in online forum.", "labels": [], "entities": []}, {"text": "We make use of graph convolutional networks (GCN) to utilize the latent topic information of comments fora specific subject.", "labels": [], "entities": []}, {"text": "We assume that arguments sharing the same topic aspect are more likely to have similar degree of convincingness, and GCN is able to make use of the topic similarity among arguments.", "labels": [], "entities": [{"text": "GCN", "start_pos": 117, "end_pos": 120, "type": "DATASET", "confidence": 0.7952957153320312}]}, {"text": "Bi-directional long short-term memory (Bi-LSTM) is used to encode each argument.", "labels": [], "entities": []}, {"text": "We annotate topic aspects information on top of a public dataset collected from online forum to evaluate our proposed model.", "labels": [], "entities": []}, {"text": "Main contribution of this article are three folds: (1) we annotate topic aspects for each argument in an existing dataset over 16 discussion threads (2 stances for each subject); (2) we propose a BiLSTM-GCN model and prove the effectiveness of topic aspects in convincingness evaluation; (3) we implement several baseline models to detect the topic aspect automatically.", "labels": [], "entities": []}], "datasetContent": [{"text": "We test our model on the dataset depicted in Section 2 to evaluate convincingness of arguments.", "labels": [], "entities": []}, {"text": "To compare with the algorithms applied in the initial task (Habernal and Gurevych, 2016b), we still use 32-fold cross-split cross-validation, which means 31 splits are training data and the other one is test data.", "labels": [], "entities": []}, {"text": "The preprocessing part is the same as the original task as well.", "labels": [], "entities": []}, {"text": "And we train our BiLSTM-GCN model as described in Section 3 and evaluate prediction accuracy on the test split.", "labels": [], "entities": [{"text": "BiLSTM-GCN", "start_pos": 17, "end_pos": 27, "type": "METRIC", "confidence": 0.714989423751831}, {"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9474836587905884}]}, {"text": "In this paper, we implement our BiLSTM-GCN model by Pytorch.", "labels": [], "entities": []}, {"text": "Each split is considered as a batch to train and test.", "labels": [], "entities": []}, {"text": "The loss function we use is simply the quadratic loss function.", "labels": [], "entities": []}, {"text": "We have tried the cross entropy loss and the quadratic loss, and latter performs better when using our classifier.", "labels": [], "entities": []}, {"text": "The batch loss is calculated by summing the loss of each argument pair.", "labels": [], "entities": []}, {"text": "The weights of the parameter matrix classifier are initialized randomly from the normal distribution, and the initial hidden state of our BiLSTM is set to zero.", "labels": [], "entities": []}, {"text": "And we take topic aspects to build adjacency matrix in convincingness evaluation task.", "labels": [], "entities": []}, {"text": "This part, we compare our BiLSTM-GCN model with baselines mentioned above.", "labels": [], "entities": []}, {"text": "lists the results of convincingness evaluation task.", "labels": [], "entities": []}, {"text": "The adjacency matrix of our BiLSTM-GCN model in is based on our topic aspects annotations.", "labels": [], "entities": []}, {"text": "In, We test other adjacency matrix building methods as described above and analyze the results.", "labels": [], "entities": [{"text": "adjacency matrix building", "start_pos": 18, "end_pos": 43, "type": "TASK", "confidence": 0.642551859219869}]}, {"text": "The result shows that our BiLSTM-GCN model performs better than best baseline model, and obviously better than models utilized in the initial task.", "labels": [], "entities": []}, {"text": "What's more, we have proved that the interrelationships of arguments can help us evaluate the convincingness better by using GCN.", "labels": [], "entities": [{"text": "GCN", "start_pos": 125, "end_pos": 128, "type": "DATASET", "confidence": 0.9055012464523315}]}, {"text": "The results in show that our annotations perform the best among all the metrics, which   means topic aspect is an excellent way to evaluate the relationship between arguments.", "labels": [], "entities": []}, {"text": "And we can know that some state-of-the-art text similarity metric like word mover's distance performs better than classical text similarity metrics like Jaccard similarity and cosine similarity.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results of convincingness evaluation task", "labels": [], "entities": []}, {"text": " Table 3: Results of BiLSTM-GCN model with various  adjacency matrix building methods", "labels": [], "entities": []}]}