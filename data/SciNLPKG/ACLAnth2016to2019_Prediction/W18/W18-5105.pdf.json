{"title": [{"text": "Challenges for Toxic Comment Classification: An In-Depth Error Analysis", "labels": [], "entities": [{"text": "Toxic Comment Classification", "start_pos": 15, "end_pos": 43, "type": "TASK", "confidence": 0.7004897395769755}]}], "abstractContent": [{"text": "Toxic comment classification has become an active research field with many recently proposed approaches.", "labels": [], "entities": [{"text": "Toxic comment classification", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.9197754462560018}]}, {"text": "However, while these approaches address some of the task's challenges others still remain unsolved and directions for further research are needed.", "labels": [], "entities": []}, {"text": "To this end, we compare different deep learning and shallow approaches on anew, large comment dataset and propose an ensemble that outperforms all individual models.", "labels": [], "entities": []}, {"text": "Further, we validate our findings on a second dataset.", "labels": [], "entities": []}, {"text": "The results of the ensemble enable us to perform an extensive error analysis, which reveals open challenges for state-of-the-art methods and directions towards pending future research.", "labels": [], "entities": []}, {"text": "These challenges include missing paradigmatic context and inconsistent dataset labels.", "labels": [], "entities": []}], "introductionContent": [{"text": "Keeping online conversations constructive and inclusive is a crucial task for platform providers.", "labels": [], "entities": []}, {"text": "Automatic classification of toxic comments, such as hate speech, threats, and insults, can help in keeping discussions fruitful.", "labels": [], "entities": [{"text": "classification of toxic comments", "start_pos": 10, "end_pos": 42, "type": "TASK", "confidence": 0.8230114877223969}]}, {"text": "In addition, new regulations in certain European countries have been established enforcing to delete illegal content in less than 72 hours.", "labels": [], "entities": []}, {"text": "Active research on the topic deals with common challenges of natural language processing, such as long-range dependencies or misspelled and idiosyncratic words.", "labels": [], "entities": []}, {"text": "Proposed solutions include bidirectional recurrent neural networks with attention ( and the use of pretrained word embeddings (.", "labels": [], "entities": []}, {"text": "However, many classifiers suffer from insufficient variance in methods and training data and therefore often tend to fail on the long tail of real world data (.", "labels": [], "entities": []}, {"text": "For future research, it is essential to know which challenges https://www.bbc.com/news/technology-42510868 are already addressed by state-of-the-art classifiers and for which challenges current solutions are still error-prone.", "labels": [], "entities": []}, {"text": "We take two datasets into account to investigate these errors: comments on Wikipedia talk pages presented by Google Jigsaw during Kaggle's Toxic Comment Classification Challenge 2 and a Twitter Dataset by.", "labels": [], "entities": [{"text": "Kaggle's Toxic Comment Classification Challenge 2", "start_pos": 130, "end_pos": 179, "type": "TASK", "confidence": 0.6367293511118207}, {"text": "Twitter Dataset", "start_pos": 186, "end_pos": 201, "type": "DATASET", "confidence": 0.7832902669906616}]}, {"text": "These sets include common difficulties in datasets for the task: They are labeled based on different definitions; they include diverse language from user comments and Tweets; and they present a multi-class and a multi-label classification task respectively.", "labels": [], "entities": []}, {"text": "On these datasets we propose an ensemble of state-of-the-art classifiers.", "labels": [], "entities": []}, {"text": "By analysing false negatives and false positives of the ensemble we get insights about open challenges that all of the approaches share.", "labels": [], "entities": []}, {"text": "Therefore, our main contributions are: 1) We are the first to apply and compare a range of strong classifiers to anew public multilabel dataset of more than 200,000 user comments.", "labels": [], "entities": []}, {"text": "Each classifier, such as Logistic Regression, bidirectional RNN and CNN, is meant to tackle specific challenges for text classification.", "labels": [], "entities": [{"text": "CNN", "start_pos": 68, "end_pos": 71, "type": "DATASET", "confidence": 0.6711258292198181}, {"text": "text classification", "start_pos": 116, "end_pos": 135, "type": "TASK", "confidence": 0.7863485813140869}]}, {"text": "We apply the same classifiers to a dataset of Tweets to validate our results on a different domain.", "labels": [], "entities": []}, {"text": "2) We apply two different pretrained word embeddings for the domain of user comments and Tweets to compensate errors such as idiosyncratic and misspelled words.", "labels": [], "entities": []}, {"text": "3) We compare the classifiers' predictions and show that they make different errors as measured by Pearson correlation coefficients and F1-measures.", "labels": [], "entities": [{"text": "Pearson correlation coefficients", "start_pos": 99, "end_pos": 131, "type": "METRIC", "confidence": 0.9386611382166544}, {"text": "F1-measures", "start_pos": 136, "end_pos": 147, "type": "METRIC", "confidence": 0.9853267669677734}]}, {"text": "Based on this, we create an ensemble that improves macro-averaged F1-measure especially on sparse classes and data with high variance.", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 66, "end_pos": 76, "type": "METRIC", "confidence": 0.9260030388832092}]}, {"text": "4) We perform a detailed error analysis on results of the ensemble.", "labels": [], "entities": []}, {"text": "The analysis points to common errors of all current approaches.", "labels": [], "entities": []}, {"text": "We propose directions for future work based on these unsolved challenges.", "labels": [], "entities": []}], "datasetContent": [{"text": "The task of toxic comment classification lacks a consistently labeled standard dataset for comparative evaluation.", "labels": [], "entities": [{"text": "toxic comment classification", "start_pos": 12, "end_pos": 40, "type": "TASK", "confidence": 0.8207098245620728}]}, {"text": "While there area number of annotated public datasets in adjacent fields, such as hate speech (, racism/sexism) or harassment () detection, most of them follow different definitions for labeling and therefore often constitute different problems.", "labels": [], "entities": []}, {"text": "We analyse a dataset published by Google Jigsaw in December 2017 over the course of the 'Toxic Comment Classification Challenge' on Kaggle.", "labels": [], "entities": [{"text": "Toxic Comment Classification Challenge", "start_pos": 89, "end_pos": 127, "type": "TASK", "confidence": 0.6312951073050499}, {"text": "Kaggle", "start_pos": 132, "end_pos": 138, "type": "DATASET", "confidence": 0.8858442306518555}]}, {"text": "It includes 223,549 annotated user comments collected from Wikipedia talk pages and is the largest publicly available for the task.", "labels": [], "entities": []}, {"text": "These comments were annotated by human raters with the six labels 'toxic', 'severe toxic, 'insult', 'threat', 'obscene' and 'identity hate'.", "labels": [], "entities": []}, {"text": "Comments can be associated with multiple classes at once, which frames the task as a multi-label classification problem.", "labels": [], "entities": []}, {"text": "Jigsaw has not published official definitions for the six classes.", "labels": [], "entities": [{"text": "Jigsaw", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9446794390678406}]}, {"text": "But they do state that they defined a toxic comment as \"a rude, disrespectful, or unreasonable comment that is likely to make you leave a discussion\".", "labels": [], "entities": []}, {"text": "The dataset features an unbalanced class distribution, shown in.", "labels": [], "entities": []}, {"text": "201,081 samples fall under the majority 'clear' class matching none of the six categories, whereas 22,468 samples belong to at least one of the other classes.", "labels": [], "entities": []}, {"text": "While the 'toxic' class includes 9.6% of the samples, only 0.3% are labeled as 'threat', marking the smallest class.", "labels": [], "entities": []}, {"text": "Comments were collected from the English Wikipedia and are mostly written in English with some outliers, e.g., in Arabic, Chinese or German language.", "labels": [], "entities": [{"text": "English Wikipedia", "start_pos": 33, "end_pos": 50, "type": "DATASET", "confidence": 0.8922877907752991}]}, {"text": "The domain covered is not strictly locatable, due to various article topics being discussed.", "labels": [], "entities": []}, {"text": "Still it is possible to apply a simple categorization of comments as follows: 4 1) 'community-related': Example: \"If you continue to vandalize Wikipedia, you will be blocked from editing.\"", "labels": [], "entities": []}, {"text": "2) 'article-related': Example: \"Dark Jedi Miraluka from the MidRim world of Katarr, Visas Marr is the lone surviving member of her species.\"", "labels": [], "entities": [{"text": "MidRim world of Katarr", "start_pos": 60, "end_pos": 82, "type": "DATASET", "confidence": 0.8982756435871124}]}, {"text": "3) 'off-topic': Example: \"== I hate how my life goes today == Just kill me now.\"", "labels": [], "entities": []}, {"text": "Additionally we investigate a dataset introduced by  Our hypothesis is that the ensemble learns to choose an optimal combination of classifiers based on a set of comment features.", "labels": [], "entities": []}, {"text": "Because the classifiers have different strengths and weaknesses, we expect the ensemble to outperform each individual classifier.", "labels": [], "entities": []}, {"text": "Based on results from previous experiments mentioned in Section 2 we expect that the state-of-the-art models have a comparable performance and none outperforms the others significantly.", "labels": [], "entities": []}, {"text": "This is important because otherwise the ensemble learner constantly prioritizes the outperforming classifier.", "labels": [], "entities": []}, {"text": "We expect our ensemble to perform well on both online comments and Tweets despite their differing language characteristics such as comment length and use of slang words.", "labels": [], "entities": []}, {"text": "As shown in our ensemble outperforms the strongest individual method on the Wikipedia dataset by approximately one percent F1-measure.", "labels": [], "entities": [{"text": "Wikipedia dataset", "start_pos": 76, "end_pos": 93, "type": "DATASET", "confidence": 0.9757213294506073}, {"text": "F1-measure", "start_pos": 123, "end_pos": 133, "type": "METRIC", "confidence": 0.9992625117301941}]}, {"text": "We see that the difference in F1-measure between the best individual classifier and the ensemble is higher on the Wikipedia dataset as on the Twitter dataset.", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 30, "end_pos": 40, "type": "METRIC", "confidence": 0.9988505840301514}, {"text": "Wikipedia dataset", "start_pos": 114, "end_pos": 131, "type": "DATASET", "confidence": 0.9825514256954193}, {"text": "Twitter dataset", "start_pos": 142, "end_pos": 157, "type": "DATASET", "confidence": 0.9133424460887909}]}, {"text": "This finding is accompanied by the results in which show that most classifier combinations present a high correlation on the Twitter dataset and are therefore less effective on the ensemble.", "labels": [], "entities": [{"text": "Twitter dataset", "start_pos": 125, "end_pos": 140, "type": "DATASET", "confidence": 0.8578051328659058}]}, {"text": "An explanation for this effect is that the text sequences within the Twitter set show less variance than the ones in the Wikipedia dataset.", "labels": [], "entities": [{"text": "Wikipedia dataset", "start_pos": 121, "end_pos": 138, "type": "DATASET", "confidence": 0.9670876562595367}]}, {"text": "This can be reasoned from 1) their sampling strategy based on a list of terms, 2) the smaller size of the dataset and 3) less disparity within the three defined classes than in the six from the Wikipedia dataset.", "labels": [], "entities": [{"text": "Wikipedia dataset", "start_pos": 194, "end_pos": 211, "type": "DATASET", "confidence": 0.9555636644363403}]}, {"text": "With less variant data one selected classifier fora type of text can be sufficient.", "labels": [], "entities": []}, {"text": "As the results in show, ensembling is especially effective on the sparse classes \"threat\" (Wikipedia) and \"hate\" (Twitter).", "labels": [], "entities": [{"text": "ensembling", "start_pos": 24, "end_pos": 34, "type": "TASK", "confidence": 0.9589692950248718}]}, {"text": "The predictions for these two classes have the weakest correlation.", "labels": [], "entities": []}, {"text": "This can be exploited when dealing with strongly imbalanced datasets, as often the casein toxic comment classification and related tasks.", "labels": [], "entities": [{"text": "casein toxic comment classification", "start_pos": 83, "end_pos": 118, "type": "TASK", "confidence": 0.7118910551071167}]}, {"text": "to that we see that the different word embeddings used do not lead to strongly differing predictions.", "labels": [], "entities": []}, {"text": "Another finding is that word and character ngrams learned by our Logistic Regression classifier produce strongly uncorrelated predictions that can be combined for increasing accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 174, "end_pos": 182, "type": "METRIC", "confidence": 0.9946170449256897}]}], "tableCaptions": [{"text": " Table 1: Class distribution of Wikipedia dataset. The  distribution shows a strong class imbalance.", "labels": [], "entities": [{"text": "Wikipedia dataset", "start_pos": 32, "end_pos": 49, "type": "DATASET", "confidence": 0.9492121934890747}]}, {"text": " Table 2: Class distribution of Twitter dataset. The ma- jority class of the dataset consists of offensive Tweets.", "labels": [], "entities": [{"text": "Twitter dataset", "start_pos": 32, "end_pos": 47, "type": "DATASET", "confidence": 0.811913013458252}]}, {"text": " Table 3: Comparison of precision, recall, F1-measure, and ROC AUC on two datasets. The results show that the  ensemble outperforms the individual classifiers in F1-measure. The strongest individual classifier on both datasets  is a bidirectional GRU network with attention layer.", "labels": [], "entities": [{"text": "precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9993889331817627}, {"text": "recall", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9988530874252319}, {"text": "F1-measure", "start_pos": 43, "end_pos": 53, "type": "METRIC", "confidence": 0.9933671355247498}, {"text": "ROC AUC", "start_pos": 59, "end_pos": 66, "type": "METRIC", "confidence": 0.9310033619403839}]}, {"text": " Table 4: F1-measures and Pearson correlations of dif- ferent combinations of classifiers. When the pearson  score is low and F1 is similar, an ensemble performs  best. We see that this appears mostly on the Wikipedia  dataset and on the respective minority classes 'threat'  and 'hate'. 'W': Wikipedia dataset; 'T': Twitter  dataset; 'G': Glove embeddings; 'FT': FastText em- beddings; 'avg.': Averaged", "labels": [], "entities": [{"text": "F1-measures", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9781798124313354}, {"text": "Pearson correlations", "start_pos": 26, "end_pos": 46, "type": "METRIC", "confidence": 0.9576297998428345}, {"text": "Wikipedia  dataset", "start_pos": 208, "end_pos": 226, "type": "DATASET", "confidence": 0.979766458272934}, {"text": "Wikipedia dataset", "start_pos": 293, "end_pos": 310, "type": "DATASET", "confidence": 0.9703380167484283}, {"text": "Twitter  dataset", "start_pos": 317, "end_pos": 333, "type": "DATASET", "confidence": 0.8653753697872162}, {"text": "FT", "start_pos": 359, "end_pos": 361, "type": "METRIC", "confidence": 0.9711050987243652}]}]}