{"title": [{"text": "Shot Or Not: Comparison of NLP Approaches for Vaccination Behaviour Detection", "labels": [], "entities": [{"text": "Vaccination Behaviour Detection", "start_pos": 46, "end_pos": 77, "type": "TASK", "confidence": 0.6557684540748596}]}], "abstractContent": [{"text": "Vaccination behaviour detection deals with predicting whether or not a person re-ceived/was about to receive a vaccine.", "labels": [], "entities": [{"text": "Vaccination behaviour detection", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.9017336368560791}]}, {"text": "We present our submission for vaccination behaviour detection shared task at the SMM4H workshop.", "labels": [], "entities": [{"text": "vaccination behaviour detection shared task", "start_pos": 30, "end_pos": 73, "type": "TASK", "confidence": 0.8810157299041748}, {"text": "SMM4H workshop", "start_pos": 81, "end_pos": 95, "type": "DATASET", "confidence": 0.7174454033374786}]}, {"text": "Our findings are based on three prevalent text classification approaches: rule-based, statistical and deep learning-based.", "labels": [], "entities": [{"text": "text classification", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.7316300719976425}]}, {"text": "Our final submissions are: (1) an ensemble of statistical classifiers with task-specific features derived using lexicons, language processing tools and word embeddings; and, (2) a LSTM classifier with pre-trained language models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Public opinion about vaccines is diverse.", "labels": [], "entities": []}, {"text": "Most people support vaccination, but some of these people do not receive vaccination.", "labels": [], "entities": []}, {"text": "On the other hand, people who are vaccinated may also have concerns regarding the safety or efficacy of vaccines.", "labels": [], "entities": []}, {"text": "In other words, a person's stance towards vaccines (referred to as 'vaccine hesitancy') is distinct from whether or not they received a vaccine shot (referred to as 'vaccination behaviour').", "labels": [], "entities": []}, {"text": "While automatic detection of vaccine hesitancy has been explored in the past, computational approaches to detect vaccination behaviour have been limited.", "labels": [], "entities": [{"text": "automatic detection of vaccine hesitancy", "start_pos": 6, "end_pos": 46, "type": "TASK", "confidence": 0.7476227402687072}]}, {"text": "Towards this, our paper deals with vaccination behaviour detection (SMM4H shared task #4).", "labels": [], "entities": [{"text": "vaccination behaviour detection", "start_pos": 35, "end_pos": 66, "type": "TASK", "confidence": 0.8444496591885885}, {"text": "SMM4H shared task #", "start_pos": 68, "end_pos": 87, "type": "TASK", "confidence": 0.8143137693405151}]}, {"text": "Vaccination behaviour and vaccine hesitancy can together help to understand penetration of vaccination programmes and the trust that communities place in large-scale vaccination programmes.", "labels": [], "entities": [{"text": "vaccine hesitancy", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.6634177565574646}]}, {"text": "Vaccination behaviour detection is the task of predicting whether or not a given piece of text refers to a person receiving or intending to receive a vaccine.", "labels": [], "entities": [{"text": "Vaccination behaviour detection", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8418510357538859}, {"text": "predicting whether or not a given piece of text refers to a person receiving or intending to receive a vaccine", "start_pos": 47, "end_pos": 157, "type": "TASK", "confidence": 0.6754759207367897}]}, {"text": "For example, the tweet 'I took the vaccine this morning, feeling great!' is positive because the speaker reports having received the vaccine.", "labels": [], "entities": []}, {"text": "On the contrary, 'Vaccines drastically reduce risks of infection' is negative because the tweet describes vaccines but does not report a vaccine being administered.", "labels": [], "entities": []}, {"text": "Past work in vaccination behaviour detection uses n-grams as features of a statistical classifier (.", "labels": [], "entities": [{"text": "vaccination behaviour detection", "start_pos": 13, "end_pos": 44, "type": "TASK", "confidence": 0.8314992785453796}]}, {"text": "However, alternatives to n-grams have shown promise in several Natural Language Processing (NLP) tasks.", "labels": [], "entities": []}, {"text": "Therefore, we compare three typical NLP approaches for vaccination behaviour detection: rule-based, statistical and deep learning techniques.", "labels": [], "entities": [{"text": "vaccination behaviour detection", "start_pos": 55, "end_pos": 86, "type": "TASK", "confidence": 0.7874629894892374}]}, {"text": "Our submissions to the shared task use statistical and deep learning-based text classification.", "labels": [], "entities": [{"text": "deep learning-based text classification", "start_pos": 55, "end_pos": 94, "type": "TASK", "confidence": 0.6759135276079178}]}, {"text": "The systems are trained on a concatenation of the training and the validation set.", "labels": [], "entities": []}, {"text": "The work reported in this paper ranked first among nine teams, as communicated by the shared task committee.", "labels": [], "entities": []}], "datasetContent": [{"text": "The shared task provided three labeled datasets of tweets for evaluation: a training dataset (5751 tweets of which 1692 are positive), a validation dataset (1215 tweets of which 306 are positive) and a test dataset (161 tweets, labels undisclosed).", "labels": [], "entities": []}, {"text": "We re-implement two past works as baselines ().", "labels": [], "entities": []}, {"text": "The two baselines use n-grams as features of statistical classifier.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: 10-fold cross-validation results (%) on the  training dataset.", "labels": [], "entities": [{"text": "training dataset", "start_pos": 55, "end_pos": 71, "type": "DATASET", "confidence": 0.69829460978508}]}, {"text": " Table 3: Performance (%) on the test dataset.", "labels": [], "entities": []}, {"text": " Table 4: F-scores (%) of the two best-performing ap- proaches for varying size of the training set.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9983799457550049}]}, {"text": " Table 5: Degradation in F-scores (%) of the statistical  approach when each of the features is removed.", "labels": [], "entities": [{"text": "Degradation", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9832041263580322}, {"text": "F-scores", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9802299737930298}]}, {"text": " Table 6: F-scores (%) of the LSTM-LM when language  model is pretrained on different source data.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9978598952293396}]}]}