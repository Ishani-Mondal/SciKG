{"title": [{"text": "Treatment Side Effect Prediction from Online User-generated Content", "labels": [], "entities": []}], "abstractContent": [{"text": "With Health 2.0, patients and caregivers increasingly seek information regarding possible drug side effects during their medical treatments in online health communities.", "labels": [], "entities": []}, {"text": "These are helpful platforms for non-professional medical opinions, yet pose risk of being unreliable in quality and insufficient in quantity to cover the wide range of potential drug reactions.", "labels": [], "entities": []}, {"text": "Existing approaches which analyze such user-generated content in online forums heavily rely on feature engineering of both documents and users, and often overlook the relationships between posts within a common discussion thread.", "labels": [], "entities": []}, {"text": "Inspired by recent advancements, we propose a neural architecture that models the textual content of user-generated documents and user experiences in online communities to predict side effects during treatment.", "labels": [], "entities": []}, {"text": "Experimental results show that our proposed architecture outperforms baseline models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Seeking medical opinions from online health communities has become commonplace: 71% of age 18-29 (equivalent to 59% of all U.S. adults) reported consulting online health opinion.", "labels": [], "entities": [{"text": "Seeking medical opinions from online health communities", "start_pos": 0, "end_pos": 55, "type": "TASK", "confidence": 0.8901118976729256}]}, {"text": "These opinions come from an estimated twenty to one hundred thousand healthrelated websites (), inclusive of online health communities that network patients with each other to provide information and social support (.", "labels": [], "entities": []}, {"text": "Platforms such as HealthBoards and MedHelp 2 feature users reporting their own health experiences, inclusive of their self-reviewed drugs and medical treatments.", "labels": [], "entities": [{"text": "HealthBoards", "start_pos": 18, "end_pos": 30, "type": "DATASET", "confidence": 0.9450905919075012}]}, {"text": "Hence, they are valuable sources for researchers (.", "labels": [], "entities": []}, {"text": "Although readers use these platforms to get valuable information about potential drug reactions during treatment, this is not without potentially serious problems.", "labels": [], "entities": []}, {"text": "There is lexical variation: users do refer side effects differently: \"dizziness\" can be expressed as \"giddiness\" or \"my head is spinning\".", "labels": [], "entities": []}, {"text": "More concern is that discussions rarely coverall possible prescribed drugs and their side effects during a treatment, and some topics refer to a condition without mentioning any particular drug.", "labels": [], "entities": []}, {"text": "Relying on such information could lead to adverse reactions.", "labels": [], "entities": []}, {"text": "It is important to note that a tool that looks up mentioned drugs' side effects from a static database would not return answers with sufficient coverage.", "labels": [], "entities": []}, {"text": "There are also common concerns regarding credibility of user-generated contents -() have shown that online health information is of variable quality and approached with caution.", "labels": [], "entities": []}, {"text": "Having these caveats in mind though, experienced users can provide valuable expertise.", "labels": [], "entities": []}, {"text": "For instance, while reporting expected side effects fora specific treatment, patients with long-term use of certain drugs can be valuable authorities.", "labels": [], "entities": []}, {"text": "E.g.: While my experience of 10 years is with Paxil, I expect that Zoloft will be the same.", "labels": [], "entities": []}, {"text": "You should definitely feel better within 2 weeks.", "labels": [], "entities": []}, {"text": "One way I found to make it easier to sleep was to get lots of exercize.", "labels": [], "entities": []}, {"text": "Walk or run or whatever to burn off that anxiety.", "labels": [], "entities": []}, {"text": "This is an answer to a thread asking for expected side effects for depression treatment with Zoloft.", "labels": [], "entities": []}, {"text": "User 3690's history of actively discussing about other anti-depressants such as Lexapro and Xanax gives insights in predicting potential drug reactions during the treatment of depression.", "labels": [], "entities": [{"text": "Lexapro", "start_pos": 80, "end_pos": 87, "type": "DATASET", "confidence": 0.9420565962791443}]}, {"text": "Table 1 shows that Zoloft (mentioned in the thread) shares many common side effects with the other two anti-depressants: \"changed behavior,\" \"dry mouth,\" and \"sleepiness or unusual drowsiness.\"", "labels": [], "entities": []}, {"text": "A method that could differentiate trustworthy user-generated content would be valuable, allowing us to macroscopically harness a large amount of online information that would pave the way to many critical tasks such as digital pharmacovigilance and disease monitoring.", "labels": [], "entities": [{"text": "disease monitoring", "start_pos": 249, "end_pos": 267, "type": "TASK", "confidence": 0.7242185473442078}]}], "datasetContent": [{"text": "We conduct experiments to validate the effectiveness of our proposed model.", "labels": [], "entities": []}, {"text": "In specific, (1) we want to compare our architecture with text encoding baselines, (2) highlight performance improvements incrementally, and evaluate and analyze the obtained results, both at the macroscopic and microscopic levels.", "labels": [], "entities": []}, {"text": "We conduct our experiments on the same dataset as () including 15,000 users and 2.8 million posts extracted from 620,510 HealthBoards 1 threads.", "labels": [], "entities": [{"text": "HealthBoards 1 threads", "start_pos": 121, "end_pos": 143, "type": "DATASET", "confidence": 0.9160743554433187}]}, {"text": "Ground truth possible side effects experienced during treatment are defined as the side effects of drugs mentioned in the discussion.", "labels": [], "entities": []}, {"text": "As annotating such amount of posts is expensive, drug side effects are extracted from Mayo Clinic's Drugs and Supplements portal and are used as surrogates for potential reactions of treatments.", "labels": [], "entities": [{"text": "Mayo Clinic's Drugs and Supplements portal", "start_pos": 86, "end_pos": 128, "type": "DATASET", "confidence": 0.8138361317770821}]}, {"text": "We applied a standard natural language preprocessing -Snowball stemming and stop-word elimination -before representation modeling.", "labels": [], "entities": [{"text": "Snowball stemming", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.7786685228347778}, {"text": "stop-word elimination", "start_pos": 76, "end_pos": 97, "type": "TASK", "confidence": 0.7147546708583832}, {"text": "representation modeling", "start_pos": 106, "end_pos": 129, "type": "TASK", "confidence": 0.8963881433010101}]}, {"text": "From the original dataset, we only extract threads that are annotated with drugs and their side effects, along with the lists of contained posts and corresponding users.", "labels": [], "entities": []}, {"text": "Experimental results with both actual (Experiment 1) and Strict (Experiment 2) settings.", "labels": [], "entities": []}, {"text": "In the Component columns, \"CW\", \"UE\", \"CA\" denote \"Credibility Weights\", \"User Expertise\" and \"Cluster Attention module components\", respectively.", "labels": [], "entities": [{"text": "CA", "start_pos": 39, "end_pos": 41, "type": "METRIC", "confidence": 0.6604223847389221}]}, {"text": "folds to perform cross-validation (8,1,1 folds for training, validation, and testing respectively).", "labels": [], "entities": []}, {"text": "We perform PCA and K-means clustering on training set, using scikitlearn's built-in modules (Pedregosa et al., 2011), with g = 50 principal components and k = 100 clusters.", "labels": [], "entities": []}, {"text": "For CNN-KIM, we experiment with filters with varying window sizes from 2 to 5, and set the number of feature maps for each filter to 256 and dropout to 0.5.", "labels": [], "entities": []}, {"text": "For our proposed model and baseline models using the RNN architecture, when performing post content encoding, we set the number of units in the LSTM cell to 128.", "labels": [], "entities": [{"text": "post content encoding", "start_pos": 87, "end_pos": 108, "type": "TASK", "confidence": 0.6445322831471761}]}, {"text": "Dropout rates of 0.2 and 0.5 are used in our LSTM cells and FC layers, respectively.", "labels": [], "entities": []}, {"text": "Cluster attention vectors and user credibility values are initialized with values ranging from -1.0 to 1.0.", "labels": [], "entities": []}, {"text": "For each user u, we initialize her expertise vector with the value of v u obtained in Section 4 and allow training to fine-tune.", "labels": [], "entities": []}, {"text": "All models are trained using Tensorflow 4 library.", "labels": [], "entities": []}, {"text": "We conducted two separate experiments: \u2022 Experiment 1: We keep the text as-is.", "labels": [], "entities": []}, {"text": "Any mentioned drugs are retained inside the thread.", "labels": [], "entities": []}, {"text": "\u2022 Experiment 2: We remove all mentions of any drug in our drug list.", "labels": [], "entities": []}, {"text": "This is a more aggressive experiment which asks the model to predict the treatment's side effects without any mention of the experienced drugs.", "labels": [], "entities": []}, {"text": "shows the precision, recall, and F 1 obtained by our method and the four baselines.", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9997774958610535}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9996503591537476}, {"text": "F 1", "start_pos": 33, "end_pos": 36, "type": "METRIC", "confidence": 0.9908726215362549}]}, {"text": "Macroscopic Analysis: Firstly, all of the three models that apply credibility weighting (CW) -WPE, WPEU and our model -outperform both RNN and CNN baselines in both experiments.", "labels": [], "entities": [{"text": "Macroscopic Analysis", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7990373075008392}, {"text": "credibility weighting (CW) -WPE", "start_pos": 66, "end_pos": 97, "type": "METRIC", "confidence": 0.7762183206421989}]}, {"text": "Specifically, weighting each post by its author credibility improves the performance of naive post encoder by 6.32%, 2.15% and 3.86% on precision, recall and F 1 respectively for Experiment 1.", "labels": [], "entities": [{"text": "precision", "start_pos": 136, "end_pos": 145, "type": "METRIC", "confidence": 0.9996020197868347}, {"text": "recall", "start_pos": 147, "end_pos": 153, "type": "METRIC", "confidence": 0.9992689490318298}, {"text": "F 1", "start_pos": 158, "end_pos": 161, "type": "METRIC", "confidence": 0.9938031733036041}]}, {"text": "Results for Experiment 2 are similar.", "labels": [], "entities": []}, {"text": "This demonstrates the effectiveness of accounting for author credibility when encoding thread content, improving side effect prediction.", "labels": [], "entities": []}, {"text": "Improvements by incorporating user experience (UE) are less pronounced.", "labels": [], "entities": []}, {"text": "In Experiment 1, adding UE (WPEU vs. WPE) improves recall by 2.65% and 0.8% in F 1 . Again, the stricter Experiment 2 shows similar performance trends.", "labels": [], "entities": [{"text": "UE", "start_pos": 24, "end_pos": 26, "type": "METRIC", "confidence": 0.9869379997253418}, {"text": "recall", "start_pos": 51, "end_pos": 57, "type": "METRIC", "confidence": 0.9997149109840393}, {"text": "F 1", "start_pos": 79, "end_pos": 82, "type": "METRIC", "confidence": 0.8960974812507629}]}, {"text": "On a macro scale, these statistics indicate that our model successfully learns to include more side effects in its prediction, where many are relevant to the ground truth.", "labels": [], "entities": []}, {"text": "This is consistent with our hypothesis that considering author experience of each post is effective in predicting out-of-context side effects.", "labels": [], "entities": []}, {"text": "Applying cluster-sensitive attention (CA) in combining RNN's hidden states also improves the performance.", "labels": [], "entities": [{"text": "cluster-sensitive attention (CA)", "start_pos": 9, "end_pos": 41, "type": "METRIC", "confidence": 0.7873888969421386}]}, {"text": "In Experiment 1, we observe that adding CA (our model vs. WPEU) also improves recall and F 1 , where again, Experiment 2 demonstrates similar but slightly more pronounced performance changes.", "labels": [], "entities": [{"text": "CA", "start_pos": 40, "end_pos": 42, "type": "METRIC", "confidence": 0.9746080040931702}, {"text": "WPEU", "start_pos": 58, "end_pos": 62, "type": "DATASET", "confidence": 0.8025684952735901}, {"text": "recall", "start_pos": 78, "end_pos": 84, "type": "METRIC", "confidence": 0.9997105002403259}, {"text": "F 1", "start_pos": 89, "end_pos": 92, "type": "METRIC", "confidence": 0.9837634563446045}]}, {"text": "These indicate that the attention mechanism is more effective when the drugs are present since the drug names in our documents are the phrases that receive greater emphasis.", "labels": [], "entities": []}, {"text": "As settings in Experiment 1 start with more information compared with those in Experiment 2, the task is easier and thus performance is improved (12.7% to 14.15% in F 1 ).", "labels": [], "entities": []}, {"text": "The margin for improvement for Experiment 2 is larger, which explains why absolute score improvements are larger in Experiment 2.", "labels": [], "entities": [{"text": "margin", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.981046736240387}, {"text": "absolute score improvements", "start_pos": 74, "end_pos": 101, "type": "METRIC", "confidence": 0.9575924078623453}]}, {"text": "When measuring relative improvement, the gains are comparable.", "labels": [], "entities": []}, {"text": "Generally, according to the macroscopic analysis of results in, we conclude that all of the three components in our proposed architecture, namely, CW, UE, and CA have a positive impact on the overall performance of the model.", "labels": [], "entities": []}, {"text": "We observe consistent improvements in F 1 after adding each component is consistent with our stated hypotheses, in both experimental settings.", "labels": [], "entities": [{"text": "F 1", "start_pos": 38, "end_pos": 41, "type": "METRIC", "confidence": 0.99301877617836}]}, {"text": "Microscopic Analysis: We also analyze our model performance at per-sample level to check whether they are consistent with the macroscopic results.", "labels": [], "entities": [{"text": "Microscopic Analysis", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7931266129016876}]}, {"text": "We aim to confirm three hypotheses: (1) Considering author expertise improves prediction on out-of-context side effects.", "labels": [], "entities": []}, {"text": "(2) Considering author credibility improves the extraction of both inand out-of-context side effects from trustworthy users' content.", "labels": [], "entities": []}, {"text": "(3) Placing attention on different parts of the document enhances the performance of in-context side effect extraction.", "labels": [], "entities": [{"text": "in-context side effect extraction", "start_pos": 85, "end_pos": 118, "type": "TASK", "confidence": 0.7254871428012848}]}, {"text": "show a sample testing thread, its users' commonly experienced drugs, and its side effects.", "labels": [], "entities": []}, {"text": "We observe that CNN-KIM and the simple, RNN-based post encoding can capture side effects that are mentioned both directly (e.g.,\"skin rash\") as well as indirectly (e.g., \"diarrhea\"), but fail to capture the remaining symptoms, many of which are out-of-context.", "labels": [], "entities": []}, {"text": "Considering User 1537's credibility shows performance improvements.", "labels": [], "entities": [{"text": "User 1537's credibility", "start_pos": 12, "end_pos": 35, "type": "DATASET", "confidence": 0.8967671692371368}]}, {"text": "In her posts, User 1537 indirectly refers to \"headache\" by mentioning \"bug crawling under my skalp sensations\".", "labels": [], "entities": [{"text": "User 1537", "start_pos": 14, "end_pos": 23, "type": "DATASET", "confidence": 0.8790212571620941}]}, {"text": "The calculated higher credibility score weights User 1537 experiences with \"sleepiness\" higher in the WPEU (CW + UE) baseline prediction, which is correct.", "labels": [], "entities": [{"text": "credibility score", "start_pos": 22, "end_pos": 39, "type": "METRIC", "confidence": 0.9484412968158722}, {"text": "WPEU (CW + UE) baseline prediction", "start_pos": 102, "end_pos": 136, "type": "METRIC", "confidence": 0.7223896533250809}]}, {"text": "These observations are consistent with our hypothesis about user credibility.", "labels": [], "entities": []}, {"text": "User experience is effective in predicting outof-context symptoms.", "labels": [], "entities": [{"text": "predicting outof-context symptoms", "start_pos": 32, "end_pos": 65, "type": "TASK", "confidence": 0.8484295606613159}]}, {"text": "In the illustrated sample training set, all of the four users have experience with similar drugs with common side effects such as \"unusual tiredness and weakness\", \"nausea\", and \"fever\".", "labels": [], "entities": [{"text": "fever", "start_pos": 179, "end_pos": 184, "type": "METRIC", "confidence": 0.9481522440910339}]}, {"text": "As \"bad breath\" is also a shared side effect, it is comprehensible that the model outputs \"bad breath\".", "labels": [], "entities": []}, {"text": "Nonetheless, it is intuitive for the model to pickup such commonness among users and compute relevant results.", "labels": [], "entities": []}, {"text": "These observations are consistent with our hypothesis on user experience.", "labels": [], "entities": []}, {"text": "Finally, the model with CA can learn different parts of the documents.", "labels": [], "entities": []}, {"text": "Especially for User 16248's posts that mentioned digestive problems, hidden states encode phrases such as \"increasingly sensitive to more foods\", and \"damage to your intestines\" receive higher attention, resulting in the prediction of \"heartburn\", \"belching\", \"indigestion\", \"acid stomach'', and \"difficult bowel movement\".", "labels": [], "entities": []}, {"text": "This functionality is consistent with our original purpose and expectation for adding attention to the post encoder architecture.", "labels": [], "entities": []}], "tableCaptions": []}