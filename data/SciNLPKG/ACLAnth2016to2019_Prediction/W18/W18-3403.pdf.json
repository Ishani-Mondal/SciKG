{"title": [{"text": "Multi-task learning for historical text normalization: Size matters", "labels": [], "entities": [{"text": "historical text normalization", "start_pos": 24, "end_pos": 53, "type": "TASK", "confidence": 0.7474862734476725}]}], "abstractContent": [{"text": "Historical text normalization suffers from small datasets that exhibit high variance, and previous work has shown that multi-task learning can be used to leverage data from related problems in order to obtain more robust models.", "labels": [], "entities": [{"text": "Historical text normalization", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7000721792380015}]}, {"text": "Previous work has been limited to datasets from a specific language and a specific historical period, and it is not clear whether results generalize.", "labels": [], "entities": []}, {"text": "It therefore remains an open problem, when historical text normalization benefits from multi-task learning.", "labels": [], "entities": [{"text": "historical text normalization", "start_pos": 43, "end_pos": 72, "type": "TASK", "confidence": 0.5884718596935272}]}, {"text": "We explore the benefits of multi-task learning across 10 different datasets, representing different languages and periods.", "labels": [], "entities": []}, {"text": "Our main finding-contrary to what has been observed for other NLP tasks-is that multi-task learning mainly works when target task data is very scarce.", "labels": [], "entities": []}], "introductionContent": [{"text": "Historical text normalization is the problem of translating historical documents written in the absence of modern spelling conventions and making them amenable to search by today's scholars, processable by natural language processing models, and readable to laypeople.", "labels": [], "entities": [{"text": "Historical text normalization", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7189071377118429}]}, {"text": "In other words, historical text normalization is a text-to-text generation, where the input is a text written centuries ago, and the output is a text that has the same contents, but uses the orthography of modern-day language.", "labels": [], "entities": [{"text": "historical text normalization", "start_pos": 16, "end_pos": 45, "type": "TASK", "confidence": 0.6394039690494537}]}, {"text": "In this paper, we limit ourselves to word-by-word normalization, ignoring the syntactic differences between modern-day languages and their historic predecessors.", "labels": [], "entities": [{"text": "word-by-word normalization", "start_pos": 37, "end_pos": 63, "type": "TASK", "confidence": 0.7241954505443573}]}, {"text": "Resources for historical text normalization are scarce.", "labels": [], "entities": [{"text": "historical text normalization", "start_pos": 14, "end_pos": 43, "type": "TASK", "confidence": 0.6869312822818756}]}, {"text": "Even for major languages like English and German, we have very little training data for inducing normalization models, and the models we induce maybe very specific to these datasets and not scale to writings from other historic periodsor even just writings from another monastery or by another author. and recently showed that we can obtain more robust historical text normalization models by exploiting synergies across historical text normalization datasets and with related tasks.", "labels": [], "entities": [{"text": "historical text normalization", "start_pos": 353, "end_pos": 382, "type": "TASK", "confidence": 0.6739572385946909}]}, {"text": "Specifically, showed that multitask learning with German grapheme-to-phoneme translation as an auxiliary task improves a stateof-the-art sequence-to-sequence model for historical text normalization of medieval German manuscripts.", "labels": [], "entities": [{"text": "German grapheme-to-phoneme translation", "start_pos": 50, "end_pos": 88, "type": "TASK", "confidence": 0.6239657898743948}, {"text": "historical text normalization of medieval German manuscripts", "start_pos": 168, "end_pos": 228, "type": "TASK", "confidence": 0.7819534497601646}]}, {"text": "Contributions We study when multi-task learning leads to improvements in historical text normalization.", "labels": [], "entities": [{"text": "historical text normalization", "start_pos": 73, "end_pos": 102, "type": "TASK", "confidence": 0.5942783852418264}]}, {"text": "Specifically, we evaluate a state-ofthe-art approach to historical text normalization () with and without various auxiliary tasks, across 10 historical text normalization datasets.", "labels": [], "entities": [{"text": "historical text normalization", "start_pos": 56, "end_pos": 85, "type": "TASK", "confidence": 0.6615393658479055}, {"text": "historical text normalization", "start_pos": 141, "end_pos": 170, "type": "TASK", "confidence": 0.6642872293790182}]}, {"text": "We also include an experiment in English historical text normalization using data from Twitter and a grammatical error correction corpus (FCE) as auxiliary datasets.", "labels": [], "entities": [{"text": "English historical text normalization", "start_pos": 33, "end_pos": 70, "type": "TASK", "confidence": 0.569896973669529}]}, {"text": "Across the board, we find that, unlike what has been observed for other NLP tasks, multi-task learning only helps when target task data is scarce.", "labels": [], "entities": []}], "datasetContent": [{"text": "We consider 10 datasets from 8 different languages: German, using the Anselm dataset (taken from  For the Anselm dataset, we concatenate the individual training, development, and test sets from to obtain a single dataset.", "labels": [], "entities": [{"text": "Anselm dataset", "start_pos": 70, "end_pos": 84, "type": "DATASET", "confidence": 0.8902810215950012}, {"text": "Anselm dataset", "start_pos": 106, "end_pos": 120, "type": "DATASET", "confidence": 0.860144168138504}]}, {"text": "For RIDGES, we use 16 texts and randomly sample 70% of all sentences from each text for the training set, and 15% for the dev/test sets.", "labels": [], "entities": []}, {"text": "The Spanish and Portuguese datasets consist of manually normalized subsets of the Post Scriptum corpus; here, we randomly sample 80% (train) and 10% (dev/test) of all sentences per century represented in the corpus.", "labels": [], "entities": [{"text": "Spanish and Portuguese datasets", "start_pos": 4, "end_pos": 35, "type": "DATASET", "confidence": 0.6483136937022209}, {"text": "Post Scriptum corpus", "start_pos": 82, "end_pos": 102, "type": "DATASET", "confidence": 0.8327446977297465}]}, {"text": "Dataset splits for the other languages are taken from and.", "labels": [], "entities": []}, {"text": "We preprocessed all datasets to remove punctuation, perform Unicode normalization, replace digits that do not require normalization with a dummy symbol, and lowercase all tokens.", "labels": [], "entities": [{"text": "Unicode normalization", "start_pos": 60, "end_pos": 81, "type": "TASK", "confidence": 0.7252474725246429}]}, {"text": "gives an overview of all historical datasets, the approximate time period of historical texts that they cover, as well as the size of the dataset splits.", "labels": [], "entities": []}, {"text": "Note that, to the best of our knowledge, the Spanish, Portuguese, and German RIDGES datasets have not been used in the context of automatic historical text normalization before.", "labels": [], "entities": [{"text": "RIDGES datasets", "start_pos": 77, "end_pos": 92, "type": "DATASET", "confidence": 0.7073784470558167}, {"text": "historical text normalization", "start_pos": 140, "end_pos": 169, "type": "TASK", "confidence": 0.6274380087852478}]}, {"text": "additionally gives some examples of historical word forms and their gold-standard normalizations from each of these datasets.", "labels": [], "entities": []}, {"text": "Model We use the same encoder-decoder architecture with attention as described in.", "labels": [], "entities": []}, {"text": "This is a fairly standard model consisting of one bidirectional LSTM unit in the encoder and one (unidirectional) LSTM unit in the decoder.", "labels": [], "entities": []}, {"text": "The input for the encoder is a single historical word form represented as a sequence of characters and padded with word boundary symbols; i.e., we only input single tokens in isolation, not full sentences.", "labels": [], "entities": []}, {"text": "The decoder attends over the encoder's outputs and generates the normalized output characters.", "labels": [], "entities": []}, {"text": "Hyperparameters We use the same hyperparameters across all our experiments: The dimensionality of the embedding layer is 60, the size of the LSTM layers is set to 300, and we use a dropout rate of 0.2.", "labels": [], "entities": []}, {"text": "We use the Adam optimizer) with a character-wise cross-entropy loss.", "labels": [], "entities": []}, {"text": "Training is done on mini-batches of 50 samples with early stopping based on validation on the individual development sets.", "labels": [], "entities": [{"text": "early stopping", "start_pos": 52, "end_pos": 66, "type": "METRIC", "confidence": 0.9217087924480438}]}, {"text": "The hyperparameters were set on a randomly selected subset of 50,000 tokens from each of the following datasets: English, German (Anselm), Hungarian, Icelandic, and Slovene (Gaj).", "labels": [], "entities": []}, {"text": "also describe a multi-task learning (MTL) scenario where the encoder-decoder model is trained on two datasets in parallel.", "labels": [], "entities": [{"text": "multi-task learning (MTL)", "start_pos": 16, "end_pos": 41, "type": "TASK", "confidence": 0.6779624044895172}]}, {"text": "We perform similar experiments on pairwise combinations of our datasets.: Examples of input tokens (first line) and reference normalization (second line) for each of the historical datasets.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Historical datasets used in our experiments", "labels": [], "entities": []}, {"text": " Table 3: Normalization accuracy (in percent) us- ing the full or sparse training sets, both for the  single-task setup and the best-performing multi- task (MTL) setup.", "labels": [], "entities": [{"text": "Normalization", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.917070209980011}, {"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.6450253129005432}]}, {"text": " Table 4: Normalization accuracy for English  (sparse): Single and MTL from", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.7752232551574707}]}]}