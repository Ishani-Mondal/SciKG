{"title": [], "abstractContent": [{"text": "Aiming to expand the current research paradigm for training conversational AI agents that can address real-world challenges, we take a step away from traditional slot-filling goal-oriented spoken dialogue systems (SDS) and model the dialogue in away that allows users to be more expressive in describing their needs.", "labels": [], "entities": []}, {"text": "The goal is to help users make informed decisions rather than being fed matching items.", "labels": [], "entities": []}, {"text": "To this end, we describe the Linked-Data SDS (LD-SDS), a system that exploits semantic knowledge bases that connect to linked data, and supports complex constraints and preferences.", "labels": [], "entities": [{"text": "Linked-Data SDS (LD-SDS)", "start_pos": 29, "end_pos": 53, "type": "TASK", "confidence": 0.7966990828514099}]}, {"text": "We describe the required changes in language understanding and state tracking, and the need for mined features, and we report the promising results (in terms of semantic errors, effort, etc) of a preliminary evaluation after training two statistical dialogue managers in various conditions.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 36, "end_pos": 58, "type": "TASK", "confidence": 0.7246958315372467}, {"text": "state tracking", "start_pos": 63, "end_pos": 77, "type": "TASK", "confidence": 0.7012465745210648}]}], "introductionContent": [{"text": "There has been an increasing amount of research being conducted on many aspects of Spoken Dialogue Systems (SDS) with applications ranging from welldefined goal-oriented tasks to open-ended dialogue, e.g.,.", "labels": [], "entities": [{"text": "Spoken Dialogue Systems (SDS)", "start_pos": 83, "end_pos": 112, "type": "TASK", "confidence": 0.7842633525530497}]}, {"text": "Deep learning and joint optimisations of SDS components are becoming the standard approach e.g.,, showing many benefits but also limitations and disadvantages.", "labels": [], "entities": [{"text": "SDS", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.9665359258651733}]}, {"text": "Due to the complexity of the problem, most of these approaches focus on limited applications e.g., information retrieval on small domains or shallowunderstanding chat-bots.", "labels": [], "entities": [{"text": "information retrieval on small domains", "start_pos": 99, "end_pos": 137, "type": "TASK", "confidence": 0.8387824892997742}]}, {"text": "Moving towards conversational AI, we shift the paradigm to information navigation and present in this work a more realistic goal-oriented setup.", "labels": [], "entities": [{"text": "information navigation", "start_pos": 59, "end_pos": 81, "type": "TASK", "confidence": 0.7438760697841644}]}, {"text": "The proposed paradigm is designed towards complex interactions using semantic knowledge bases and linked data (, and allows users to be more expressive in describing their constraints and preferences.", "labels": [], "entities": []}, {"text": "We aim to enable users to make informed decisions by understanding their needs and priorities through conversation with an intelligent agent.", "labels": [], "entities": []}, {"text": "In this work we extend the Linked Data Spoken Dialogue System (LD-SDS) system proposed in) in the following directions: a) we propose features mined over the set and the order of objects in the current user focus, b) we modify the language understanding and belief state tracking modules to support the proposed complex interactions over rich information spaces, c) we apply an agenda-based user simulator to train two statistical dialogue manager models, and d) we conduct a preliminary evaluation with promising results.", "labels": [], "entities": []}], "datasetContent": [{"text": "To assess how well current statistical DMs perform in this setting, we compare a hand-crafted dialogue policy (HDC) against a DM trained with GP-SARSA (GPS)) and one trained with Deep Q Networks with eligibility traces (DQN-\u03bb) -an adapted version of.", "labels": [], "entities": []}, {"text": "HDC, GPS, and DQN (without eligibility traces) have been the top performing algorithms in a recent benchmark evaluation . We test the DMs under various conditions, presented in.", "labels": [], "entities": [{"text": "HDC", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8830215930938721}]}, {"text": "Semantic Error refers to simulated errors, where we change either the type of dialogue act, slot, value, or operator that the simulated user issues, based on some probability.", "labels": [], "entities": []}, {"text": "This can happen multiple times, to generate multiple SLU hypotheses.", "labels": [], "entities": []}, {"text": "SLU N-Best Size is the maximum size of the N-best list of SLU hypotheses, after the simulated error stage.", "labels": [], "entities": []}, {"text": "User Patience is the maximum number of times the simulated user tolerates the same action being issued by the DM.", "labels": [], "entities": []}, {"text": "Max User Constraints is the maximum number of constraints in the simulated user's goal (e.g., price \u2264 70).", "labels": [], "entities": []}, {"text": "One important observation is that task success is very hard to define, as we consider a cluster of ranked items to be a valid system response.", "labels": [], "entities": []}, {"text": "Some users may want to get exactly one option while for some it maybe acceptable to get no more than four.", "labels": [], "entities": []}, {"text": "Therefore, we add a feature to our user simulator to indicate the number of items a user will accept as a final result (provided that all of them meet the user's constraints).", "labels": [], "entities": []}, {"text": "We sample this uniformly from the set {1, ..., acceptable}, as defined in (Acceptable Num. Items).", "labels": [], "entities": [{"text": "Acceptable", "start_pos": 75, "end_pos": 85, "type": "METRIC", "confidence": 0.95302814245224}]}, {"text": "While this is a rough approximation of real world conditions, we expect that it introduces one more layer of complexity that the statistical DMs need to model.", "labels": [], "entities": []}, {"text": "We evaluated the statistical DMs on a single domain and on a multi-domain setting (as described in section 4.1).", "labels": [], "entities": []}, {"text": "summarizes the results of our evaluation in simulation in the four environments we have defined, where each entry is the average of 5 runs of 1,000 training and 100 evaluation dialogues.", "labels": [], "entities": []}, {"text": "DQN-\u03bb performs better with the rich (dense) domainindependent feature set in the multi-domain scenario, likely because it is exposed to more variability in the data and therefore needs less iterations to learn wellperforming policies.", "labels": [], "entities": [{"text": "DQN-\u03bb", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8574506044387817}]}, {"text": "In fact, it is able to cope very well in deteriorating conditions, by learning to adapt e.g., by asking for more confirmations.", "labels": [], "entities": []}, {"text": "GPS shows the opposite trend, preferring the sparse belief state features of the single-domain scenario, needing many more dialogues (than the 1,000 allowed here) to reach good performance in the multi-domain case.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Four environments (parameter settings) under  which our DMs were evaluated.", "labels": [], "entities": []}]}