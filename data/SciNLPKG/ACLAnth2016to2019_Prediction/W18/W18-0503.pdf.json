{"title": [{"text": "Predicting misreadings from gaze in children with reading difficulties", "labels": [], "entities": [{"text": "Predicting misreadings", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8874143958091736}]}], "abstractContent": [{"text": "We present the first work on predicting reading mistakes in children with reading difficulties based on eye-tracking data from real-world reading teaching.", "labels": [], "entities": [{"text": "predicting reading mistakes", "start_pos": 29, "end_pos": 56, "type": "TASK", "confidence": 0.8238732218742371}]}, {"text": "Our approach employs several linguistic and gaze-based features to inform an ensemble of different classifiers, including multi-task learning models that let us transfer knowledge about individual readers to attain better predictions.", "labels": [], "entities": []}, {"text": "Notably, the data we use in this work stems from noisy readings in the wild, outside of controlled lab conditions.", "labels": [], "entities": []}, {"text": "Our experiments show that despite the noise and despite the small fraction of mis-readings, gaze data improves the performance more than any other feature group and our models achieve good performance.", "labels": [], "entities": []}, {"text": "We further show that gaze patterns for misread words do not fully generalize across readers, but that we can transfer some knowledge between readers using multitask learning at least in some cases.", "labels": [], "entities": []}, {"text": "Applications of our models include partial automation of reading assessment as well as per-sonalized text simplification.", "labels": [], "entities": [{"text": "reading assessment", "start_pos": 57, "end_pos": 75, "type": "TASK", "confidence": 0.8632455766201019}]}], "introductionContent": [{"text": "Reading disabilities are impairments affecting individuals' access to written sources, with downstream effects such as low self-confidence in the classroom and limited access to higher education.", "labels": [], "entities": []}, {"text": "Dyslexia, for instance, while being highly prevalent with estimates reaching up to 17.5% of the entire population of the U.S. (Interagency Committee on, often goes undiagnosed, such that unattributed weaknesses in reading comprehension further intimidate affected persons.", "labels": [], "entities": [{"text": "Dyslexia", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9834228754043579}]}, {"text": "Due to these severe and broadranging impacts of reading difficulties, many governments have implemented early screening tests for dyslexia and other reading difficulties and provide special training and assistance for struggling readers throughout the educational system and into adulthood.", "labels": [], "entities": []}, {"text": "In Denmark, for example, such programs provide children with specialist training through focused multi-week reading courses in one-on-one or small group settings.", "labels": [], "entities": []}, {"text": "Still, the specialized teachers can only attend to one student at a time when closely monitoring their reading, and the quality of any analysis is strictly limited by the human observer's processing \"bandwidth\" while attending the live reading.", "labels": [], "entities": []}, {"text": "As a possible mitigation, advances in eyetracking technology-in particular the increased availability of eye trackers-have made it possible to reliably record children's gaze during reading, both allowing teachers to attend to their students' reading post-hoc as well as providing additional insight into reading strategies based on gaze, including the development of these strategies overtime.", "labels": [], "entities": []}, {"text": "For the teacher to track and keep records of reading mistakes (henceforth referred to as misreadings), however, the students are still required to readout loud, and the teacher has to review the entire reading and annotate for misreadings.", "labels": [], "entities": []}, {"text": "In this work, we investigate to what extent we can predict misreadings from gaze patterns for individual words.", "labels": [], "entities": []}, {"text": "While the aim is not to fully automate reading reviews, being able to successfully predict misreadings from gaze data can be part of a semi-automatic system for reading quality assessment and increase teacher efficiency by pointing out potential misreadings for closer review.", "labels": [], "entities": []}, {"text": "Another motivation for this work comes from text simplification, in particular from the observation that individuals' highly specific reading strengths and weaknesses require text simplification models to be customized to specific users in order to unfold their full potential and truly be helpful.", "labels": [], "entities": [{"text": "text simplification", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.7734775245189667}]}, {"text": "Predicting misreadings in concrete reading scenarios and based on individual gaze patterns can be used as a first step in the typical lexical simplification pipeline.", "labels": [], "entities": []}, {"text": "1 This task, known as complex word identification, has received a considerable amount of attention in the literature, but has exclusively been approached in a user-agnostic fashion.", "labels": [], "entities": [{"text": "complex word identification", "start_pos": 22, "end_pos": 49, "type": "TASK", "confidence": 0.6087258259455363}]}, {"text": "The data used in this study are gaze recordings of children with reading difficulties, reading Danish texts assigned by their reading teacher as part of their reading intervention.", "labels": [], "entities": []}, {"text": "The recordings stem from EyeJustRead, an eye-tracking based software used in special reading intervention in Danish schools.", "labels": [], "entities": []}, {"text": "In Section 3, we discuss further aspects of the treatment of gaze data in general and the collection of the data used in this study in particular.", "labels": [], "entities": []}, {"text": "While the difficulty of processing a word is undoubtedly reflected in the fixation time on that word (), many other factors affect fixation durations, the most prominent being word length and word frequency, but also predictability and relative position in sentence have strong effects-see fora particularly clear example from our dataset.", "labels": [], "entities": []}, {"text": "Notably, almost all analyses of eye-tracking reading data use data collected in research laboratories, where these-1 While today it may hardly sound plausible to equip each laptop with an eye-tracker in order to track people's reading, further technological advances may well make this possible in the future.", "labels": [], "entities": []}, {"text": "Recent development in eye-tracking technology has taken it from expensive research equipment to a gaming interface with a price point as low as $100.", "labels": [], "entities": []}, {"text": "2 http://www.eyejustread.com otherwise confounding-factors can be controlled for.", "labels": [], "entities": []}, {"text": "We show that we can perform reasonable misreading detection on real-world eye tracking data, including a limited number of textual features to control for these factors.", "labels": [], "entities": [{"text": "misreading detection", "start_pos": 39, "end_pos": 59, "type": "TASK", "confidence": 0.742858499288559}]}, {"text": "Contributions a) We present the first work on the automatic detection of misreadings based on gaze patterns of children with reading difficulties.", "labels": [], "entities": [{"text": "automatic detection of misreadings", "start_pos": 50, "end_pos": 84, "type": "TASK", "confidence": 0.773732379078865}]}, {"text": "b) This is, to the best of our knowledge, the first attempt at modeling noisy, real-world eye-tracking data from readers.", "labels": [], "entities": []}, {"text": "c) We also present, to the best of our knowledge, the first published results using a multi-task learning setup to transfer knowledge between individual readers for personalized, complex word identification.", "labels": [], "entities": [{"text": "word identification", "start_pos": 187, "end_pos": 206, "type": "TASK", "confidence": 0.6926596462726593}]}], "datasetContent": [{"text": "As a first experiment, we investigate the performance of our models and the predictiveness of the individual feature groups through 10-fold cross validation across the entire dataset.", "labels": [], "entities": []}, {"text": "At each fold, we reserve one tenth of the data for testing and another tenth to monitor validation loss of the network as the early stopping criterion.", "labels": [], "entities": []}, {"text": "Note that we split the data randomly and do not stratify the cross-validation splits in anyway.", "labels": [], "entities": []}, {"text": "In conjunction with the strong class imbalance, this means that we are likely to encounter very different class distributions across splits.", "labels": [], "entities": []}, {"text": "This setup may generally lead to lower performance scores, likely with greater variance.", "labels": [], "entities": []}, {"text": "However, this was a deliberate choice as we cannot assume a consistent class distribution across train and test set in the real world, or in fact hardly any prior knowledge with regards to class distribution in the test set.", "labels": [], "entities": []}, {"text": "Random splitting also means that data from the same reading will likely be distributed across train and test partitions fora certain cross-validation iteration.", "labels": [], "entities": [{"text": "Random splitting", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7072043865919113}]}, {"text": "We perform a first baseline experiment with   only the basic features that we list in Section 2.", "labels": [], "entities": []}, {"text": "On top of this baseline feature set, we perform further experiments, incorporating all combinations over the other feature groups.", "labels": [], "entities": []}, {"text": "The results we present in are based on the best respective model architecture for each feature combination, evaluated via the average over validation splits.", "labels": [], "entities": []}, {"text": "Without reader's own data Ina second experiment, we are interested in how well our model can predict misreadings for specific readers.", "labels": [], "entities": []}, {"text": "For this, we identify the three readers with most reading sessions and perform a range of experiments, testing our models on the readings of each of these readers after training them on all other data.", "labels": [], "entities": []}, {"text": "We denote the three most active readers by their unique, anonymized IDs as they appear in the dataset: 10, 15 and 16.", "labels": [], "entities": []}, {"text": "These readers have 7, 6 and 5 recorded and marked readings, respectively, and we present statistics on these readings in Table 4 and.", "labels": [], "entities": []}, {"text": "As in the previous experiment, we optimize our model through cross validation to tune hyperparameters and perform early stopping.", "labels": [], "entities": []}, {"text": "We report test data results for the model with optimal validation performance in, broken down into each reader's different sessions.", "labels": [], "entities": []}, {"text": "Learning from reader's own data Complementing the setup above, we now investigate how data from the same reader, but from different reading sessions, can inform our models.", "labels": [], "entities": []}, {"text": "Therefore, we further perform cross-validation experiments across each reader's sessions.", "labels": [], "entities": []}, {"text": "More concretely, fora reader with n marked readings, we perform nfold cross validation, holding out one reading a time as a test set and another to monitor validation loss for early stopping of the neural model, while training on the remaining n \u2212 2 readings.", "labels": [], "entities": [{"text": "nfold cross validation", "start_pos": 64, "end_pos": 86, "type": "TASK", "confidence": 0.5682658950487772}]}, {"text": "MTL As outlined in Section 4.1, we now view readers as tasks in an MTL model.", "labels": [], "entities": [{"text": "MTL", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7757284045219421}]}, {"text": "For each of the three readers identified above and for each test reading, we train an ensemble whose neural MTL models define two outputs: one for the reader in question and one combined output for all other readers in the entire dataset.", "labels": [], "entities": []}, {"text": "The random forest classifiers are trained on all remaining data except the held-out validation and test readings.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Dataset size after each cleaning step", "labels": [], "entities": []}, {"text": " Table 4: Statistics of (misread) words in sessions for the three readers with most readings.", "labels": [], "entities": []}]}