{"title": [{"text": "A Neural Approach to Language Variety Translation", "labels": [], "entities": [{"text": "Neural Approach to Language Variety Translation", "start_pos": 2, "end_pos": 49, "type": "TASK", "confidence": 0.7042592664559683}]}], "abstractContent": [{"text": "In this paper we present the first neural-based machine translation system trained to translate between standard national varieties of the same language.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.7522317171096802}]}, {"text": "We take the pair Brazilian-European Portuguese as an example and compare the performance of this method to a phrase-based statistical machine translation system.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation", "start_pos": 109, "end_pos": 153, "type": "TASK", "confidence": 0.5964242741465569}]}, {"text": "We report a performance improvement of 0.9 BLEU points in translating from European to Brazilian Portuguese and 0.2 BLEU points when translating in the opposite direction.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 43, "end_pos": 47, "type": "METRIC", "confidence": 0.9992339611053467}, {"text": "translating from European to Brazilian Portuguese", "start_pos": 58, "end_pos": 107, "type": "TASK", "confidence": 0.8969936271508535}, {"text": "BLEU", "start_pos": 116, "end_pos": 120, "type": "METRIC", "confidence": 0.9993368983268738}]}, {"text": "We also carried out a human evaluation experiment with native speakers of Brazilian Portuguese which indicates that humans prefer the output produced by the neural-based system in comparison to the statistical system.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the last five years Neural Machine Translation (NMT) has evolved from anew and promising paradigm in Machine Translation (MT) to an established state-of-the-art technology.", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT)", "start_pos": 23, "end_pos": 55, "type": "TASK", "confidence": 0.7845718562602997}, {"text": "Machine Translation (MT)", "start_pos": 104, "end_pos": 128, "type": "TASK", "confidence": 0.8474367022514343}]}, {"text": "A few studies pose that performance difference between Statistical Machine Translation (SMT) and NMT is not as a great as one could imagine) while others show interesting challenges for NMT (compared to SMT) such as learning with limited amount of data, out-of-domain, long sentences, low frequency words or lack of word alignment model (.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 55, "end_pos": 92, "type": "TASK", "confidence": 0.8244335452715555}, {"text": "SMT", "start_pos": 203, "end_pos": 206, "type": "TASK", "confidence": 0.9667744636535645}, {"text": "word alignment", "start_pos": 316, "end_pos": 330, "type": "TASK", "confidence": 0.704656645655632}]}, {"text": "Even so, NMT systems have constantly ranked in the top positions in the competitions held in MT conferences and workshops such as WMT () and WAT (.", "labels": [], "entities": [{"text": "MT", "start_pos": 93, "end_pos": 95, "type": "TASK", "confidence": 0.9535884857177734}, {"text": "WMT", "start_pos": 130, "end_pos": 133, "type": "DATASET", "confidence": 0.7715432047843933}, {"text": "WAT", "start_pos": 141, "end_pos": 144, "type": "DATASET", "confidence": 0.5695715546607971}]}, {"text": "They have also been achieving commercial success (e.g. Google's GNMT ().", "labels": [], "entities": []}, {"text": "Far from being settled, the architecture of NMT systems is constantly evolving.", "labels": [], "entities": []}, {"text": "Given the youth of the paradigm and while the main structure of encoder-decoder is still maintained, the implementation of such is done either using recurrent neural networks (RNN) with attention mechanisms (, to convolutional neural networks (CNN) and to only attention mechanisms ().", "labels": [], "entities": []}, {"text": "For the same reason, research in NMT goes in many directions, including minimal units (, unsupervised training and low resources () or transfer learning (, to name and cite just a few.", "labels": [], "entities": [{"text": "NMT", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.9210312366485596}]}, {"text": "In this paper we tackle an under-explored problem and apply NMT techniques to translate between language varieties.", "labels": [], "entities": []}, {"text": "In previous work, NMT has been used to translate between Spanish and Catalan, two closely-related Romance languages from the Iberian peninsula, outperforming phrase-based SMT approaches.", "labels": [], "entities": [{"text": "SMT", "start_pos": 171, "end_pos": 174, "type": "TASK", "confidence": 0.8685644865036011}]}, {"text": "In this paper we test whether this is also true for national varieties of the same language taking Brazilian and European Portuguese as a case study.", "labels": [], "entities": []}, {"text": "To the best of our knowledge the use of NMT to translate between national language varieties has not yet been studied and this paper contributes to opening new avenues for future research.", "labels": [], "entities": [{"text": "translate between national language varieties", "start_pos": 47, "end_pos": 92, "type": "TASK", "confidence": 0.8737648487091064}]}], "datasetContent": [{"text": "Following the best practice in translation evaluation, as observed in the WMT shared tasks (, we present two human evaluation experiments to validate the results obtained with the automatic evaluation metrics.", "labels": [], "entities": [{"text": "translation evaluation", "start_pos": 31, "end_pos": 53, "type": "TASK", "confidence": 0.9832791686058044}, {"text": "WMT shared tasks", "start_pos": 74, "end_pos": 90, "type": "TASK", "confidence": 0.5357952217260996}]}, {"text": "The first one is a ranking experiment in which participants were asked to choose which translation of a given segment they preferred without knowing which system produced the translations.", "labels": [], "entities": []}, {"text": "The second one is a pilot rating experiment in which participants were asked to rate translations using a 1 to 7 Likert scale.", "labels": [], "entities": [{"text": "Likert scale", "start_pos": 113, "end_pos": 125, "type": "METRIC", "confidence": 0.8892767131328583}]}, {"text": "We start by reporting the results obtained in the ranking experiment.", "labels": [], "entities": []}, {"text": "We evaluated the quality of the EP-BP translation direction asking a group of seven native speakers of BP to rank sentences produced by the SMT system and by the NMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 140, "end_pos": 143, "type": "TASK", "confidence": 0.9710215926170349}, {"text": "NMT system", "start_pos": 162, "end_pos": 172, "type": "DATASET", "confidence": 0.9236461818218231}]}, {"text": "We presented native speakers with the source segment in EP and two translations in BP.", "labels": [], "entities": [{"text": "EP", "start_pos": 56, "end_pos": 58, "type": "DATASET", "confidence": 0.9358764886856079}, {"text": "BP", "start_pos": 83, "end_pos": 85, "type": "DATASET", "confidence": 0.699722170829773}]}, {"text": "Their task was to select the best output (ties were allowed).", "labels": [], "entities": []}, {"text": "The decision to use only BP native speakers was motivated by the findings reported in ( which indicate that speakers of BP are generally not familiar with what is acceptable in the European variety and vice-versa.", "labels": [], "entities": []}, {"text": "We considered the full set of 2,000 test sentences and disregard sentences where 1) no transformation has been made (the source, outputs, and the reference are the same), and 2) transformations have been made but NMT and SMT outputs are the same.", "labels": [], "entities": [{"text": "SMT", "start_pos": 221, "end_pos": 224, "type": "TASK", "confidence": 0.9438965916633606}]}, {"text": "After filtering, 679 distinct segments were left for the human evaluation.", "labels": [], "entities": []}, {"text": "We randomly selected 20% of these segments 679 (136 sentences) and presented them to two annotators to calculate inter-annotator agreement.", "labels": [], "entities": []}, {"text": "Finally, the set of 815 segments, 679 segments plus 136 segments (20% redundancy), divided into 23 sub-sets and presented to each of the annotators.", "labels": [], "entities": []}, {"text": "Each annotator evaluated between three and four sub-sets.", "labels": [], "entities": []}, {"text": "To assess the reliability of the rankings, we first compute the agreement between the annotators.", "labels": [], "entities": [{"text": "reliability", "start_pos": 14, "end_pos": 25, "type": "METRIC", "confidence": 0.9709672927856445}]}, {"text": "We report substantial inter-annotator agreement achieving 0.88 pairwise Kappa score.", "labels": [], "entities": [{"text": "Kappa score", "start_pos": 72, "end_pos": 83, "type": "METRIC", "confidence": 0.859606146812439}]}, {"text": "We present the results obtained by the ranking experiment in terms of the percentage of segments in which 1) NMT was preferred by the annotator, 2) the two segments were consider the same, 3) SMT was preferred by the annotator.", "labels": [], "entities": [{"text": "SMT", "start_pos": 192, "end_pos": 195, "type": "TASK", "confidence": 0.7769942879676819}]}, {"text": "We observed that the NMT output was judged to be equal or better the SMT output in 57.81% of the cases.", "labels": [], "entities": [{"text": "SMT", "start_pos": 69, "end_pos": 72, "type": "TASK", "confidence": 0.9671423435211182}]}, {"text": "The NMT output was preferred in 48.43% of the rankings and judged to be of same quality as SMT in 9.38% of the cases.", "labels": [], "entities": [{"text": "NMT output", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.7541367411613464}, {"text": "SMT", "start_pos": 91, "end_pos": 94, "type": "TASK", "confidence": 0.9393205642700195}]}], "tableCaptions": [{"text": " Table 1: European to Brazilian Portuguese translation results in terms of BLEU score.", "labels": [], "entities": [{"text": "European to Brazilian Portuguese translation", "start_pos": 10, "end_pos": 54, "type": "TASK", "confidence": 0.600580894947052}, {"text": "BLEU score", "start_pos": 75, "end_pos": 85, "type": "METRIC", "confidence": 0.9736584424972534}]}, {"text": " Table 2: Brazilian to European Portuguese translation results in terms of BLEU score.", "labels": [], "entities": [{"text": "Brazilian to European Portuguese translation", "start_pos": 10, "end_pos": 54, "type": "TASK", "confidence": 0.5923233032226562}, {"text": "BLEU score", "start_pos": 75, "end_pos": 85, "type": "METRIC", "confidence": 0.9745082855224609}]}]}