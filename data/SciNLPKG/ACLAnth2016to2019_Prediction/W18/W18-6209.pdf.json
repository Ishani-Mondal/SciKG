{"title": [{"text": "NTUA-SLP at IEST 2018: Ensemble of Neural Transfer Methods for Implicit Emotion Classification", "labels": [], "entities": [{"text": "NTUA-SLP at IEST 2018", "start_pos": 0, "end_pos": 21, "type": "DATASET", "confidence": 0.7450506091117859}, {"text": "Implicit Emotion Classification", "start_pos": 63, "end_pos": 94, "type": "TASK", "confidence": 0.7418464223543803}]}], "abstractContent": [{"text": "In this paper we present our approach to tackle the Implicit Emotion Shared Task (IEST) organized as part of WASSA 2018 at EMNLP 2018.", "labels": [], "entities": [{"text": "Implicit Emotion Shared Task (IEST)", "start_pos": 52, "end_pos": 87, "type": "TASK", "confidence": 0.7170965884413038}, {"text": "WASSA 2018 at EMNLP 2018", "start_pos": 109, "end_pos": 133, "type": "TASK", "confidence": 0.5103885173797608}]}, {"text": "Given a tweet, from which a certain word has been removed, we are asked to predict the emotion of the missing word.", "labels": [], "entities": []}, {"text": "In this work, we experiment with neural Transfer Learning (TL) methods.", "labels": [], "entities": [{"text": "neural Transfer Learning (TL)", "start_pos": 33, "end_pos": 62, "type": "TASK", "confidence": 0.8520187735557556}]}, {"text": "Our models are based on LSTM networks, augmented with a self-attention mechanism.", "labels": [], "entities": []}, {"text": "We use the weights of various pretrained models, for initializing specific layers of our networks.", "labels": [], "entities": []}, {"text": "We leverage a big collection of unlabeled Twitter messages, for pretraining word2vec word embeddings and a set of diverse language models.", "labels": [], "entities": []}, {"text": "Moreover, we utilize a sentiment analysis dataset for pre-training a model, which encodes emotion related information.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.8561550974845886}]}, {"text": "The submitted model consists of an ensemble of the aforementioned TL models.", "labels": [], "entities": []}, {"text": "Our team ranked 3 rd out of 30 participants , achieving an F 1 score of 0.703.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9928295612335205}]}], "introductionContent": [{"text": "Social media, especially micro-blogging services like Twitter, have attracted lots of attention from the NLP community.", "labels": [], "entities": []}, {"text": "The language used is constantly evolving by incorporating new syntactic and semantic constructs, such as emojis or hashtags, abbreviations and slang, making natural language processing in this domain even more demanding.", "labels": [], "entities": []}, {"text": "Moreover, the analysis of such content leverages the high availability of datasets offered from Twitter, satisfying the need for large amounts of data for training.", "labels": [], "entities": []}, {"text": "* *These authors contributed equally to this work.", "labels": [], "entities": []}, {"text": "Emotion recognition is particularly interesting in social media, as it has useful applications in numerous tasks, such as public opinion detection about political tendencies), stock market monitoring (), tracking product perception, even detection of suicide-related communication ().", "labels": [], "entities": [{"text": "Emotion recognition", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9319921135902405}, {"text": "public opinion detection about political tendencies", "start_pos": 122, "end_pos": 173, "type": "TASK", "confidence": 0.8273527026176453}, {"text": "stock market monitoring", "start_pos": 176, "end_pos": 199, "type": "TASK", "confidence": 0.6144379675388336}, {"text": "tracking product perception", "start_pos": 204, "end_pos": 231, "type": "TASK", "confidence": 0.8450330098470052}, {"text": "detection of suicide-related communication", "start_pos": 238, "end_pos": 280, "type": "TASK", "confidence": 0.8167230784893036}]}, {"text": "In the past, emotion analysis, like most NLP tasks, was tackled by traditional methods that included hand-crafted features or features from sentiment lexicons) which were fed to classifiers such as Naive).", "labels": [], "entities": [{"text": "emotion analysis", "start_pos": 13, "end_pos": 29, "type": "TASK", "confidence": 0.8018430471420288}]}, {"text": "However, deep neural networks achieve increased performance compared to traditional methods, due to their ability to learn more abstract features from large amounts of data, producing state-of-the-art results in emotion recognition and sentiment analysis (.", "labels": [], "entities": [{"text": "emotion recognition", "start_pos": 212, "end_pos": 231, "type": "TASK", "confidence": 0.8136948049068451}, {"text": "sentiment analysis", "start_pos": 236, "end_pos": 254, "type": "TASK", "confidence": 0.96021369099617}]}, {"text": "In this paper, we present our work submitted to the WASSA 2018 IEST ().", "labels": [], "entities": [{"text": "WASSA 2018 IEST", "start_pos": 52, "end_pos": 67, "type": "DATASET", "confidence": 0.6409989794095358}]}, {"text": "In the given task, the word that triggers emotion is removed from each tweet and is replaced by the token.", "labels": [], "entities": []}, {"text": "The objective is to predict its emotion category among 6 classes: anger, disgust, fear, joy, sadness and surprise.", "labels": [], "entities": []}, {"text": "Our proposed model employs 3 different TL schemes of pretrained models: word embeddings, a sentiment model and language models.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use Adam algorithm) to optimize our networks, with minibatches of size 64 and clip the norm of the gradients () at 0.5, as an extra safety measure against exploding gradients.", "labels": [], "entities": []}, {"text": "We also used PyTorch ( and Scikitlearn ().", "labels": [], "entities": []}, {"text": "For all our models, we employ the same 2-layer attention-based LSTM architecture (Sec. 3).", "labels": [], "entities": []}, {"text": "All the hyperparameters used are shown in: Hyper-parameters of our models.", "labels": [], "entities": [{"text": "Hyper-parameters", "start_pos": 43, "end_pos": 59, "type": "METRIC", "confidence": 0.938731849193573}]}, {"text": "In we compare the proposed TL approaches against two strong baselines: (1) a Bag-of-Words (BoW) model with TF-IDF weighting and (2) a Bag-of-Embeddings (BoE) model, where we retrieve the word2vec representations of the words in a tweet and compute the tweet representation as the centroid of the constituent word2vec representations.", "labels": [], "entities": []}, {"text": "Both BoW and BoE features are then fed to a linear SVM classifier, with tuned C = 0.6.", "labels": [], "entities": [{"text": "BoW", "start_pos": 5, "end_pos": 8, "type": "DATASET", "confidence": 0.8391013145446777}]}, {"text": "All of our reported F1-scores are calculated on the evaluation (dev) set, due to time constraints.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9964981079101562}]}, {"text": "P-Emb and P-Sent models (4.1, 4.2).", "labels": [], "entities": []}, {"text": "We evaluate the P-Emb and P-Sent models, using both bidirectional and unidirectional LSTMs.", "labels": [], "entities": []}, {"text": "The F1 score of our best models is shown in.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9755947589874268}]}, {"text": "As expected, bi-LSTM models achieve higher performance.", "labels": [], "entities": []}, {"text": "For the experiments with the pretrained LMs, we intend to transfer not just the first layer of our network, but rather the whole model, so as to capture more high-level features of language.", "labels": [], "entities": []}, {"text": "As mentioned above, there are three distinct steps concerning the training procedure of this TL approach:   We transfer their weights to our final emotion classifier, we add attention to the LSTM layers and we experiment again with our 2 ways of fine-tuning and the concatenation method proposed in Sec.", "labels": [], "entities": []}, {"text": "In we present all possible combinations of transferring the P-LM to the IEST task.", "labels": [], "entities": []}, {"text": "We observe that SGU consistently outperforms Simple Fine-Tuning (Simple FT).", "labels": [], "entities": [{"text": "SGU", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.7943928837776184}, {"text": "Simple Fine-Tuning (Simple FT)", "start_pos": 45, "end_pos": 75, "type": "METRIC", "confidence": 0.6200860242048899}]}, {"text": "Due to the difficulty in running experiments for all possible combinations, we compare our best approach, namely SGU + Concat., with P-LMs trained on our three unlabeled Twitter corpora, as depicted in.", "labels": [], "entities": []}, {"text": "Even though EmoCorpus contains less training examples, P-LMs trained on it learn to encode more useful information for the task at hand.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Hyper-parameters of our models.", "labels": [], "entities": []}, {"text": " Table 2: Results of the WASSA IEST competition.", "labels": [], "entities": [{"text": "WASSA IEST", "start_pos": 25, "end_pos": 35, "type": "TASK", "confidence": 0.5644884407520294}]}, {"text": " Table 3: Results of the P-LM, trained on the Emo- Corpus. The first column refers to the way we fine- tune each LM on the IEST dataset and the second  to the way we finally fine-tune the classifier on the  same dataset.", "labels": [], "entities": [{"text": "Emo- Corpus", "start_pos": 46, "end_pos": 57, "type": "DATASET", "confidence": 0.9194402496019999}, {"text": "IEST dataset", "start_pos": 123, "end_pos": 135, "type": "DATASET", "confidence": 0.9433545172214508}]}]}