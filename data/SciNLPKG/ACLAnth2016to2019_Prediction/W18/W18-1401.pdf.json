{"title": [{"text": "Exploring the Functional and Geometric Bias of Spatial Relations Using Neural Language Models", "labels": [], "entities": []}], "abstractContent": [{"text": "The challenge for computational models of spatial descriptions for situated dialogue systems is the integration of information from different modalities.", "labels": [], "entities": []}, {"text": "The semantics of spatial descriptions are grounded in at least two sources of information: (i) a geometric representation of space and (ii) the functional interaction of related objects that.", "labels": [], "entities": []}, {"text": "We train several neural language models on descriptions of scenes from a dataset of image captions and examine whether the functional or geometric bias of spatial descriptions reported in the literature is reflected in the estimated perplexity of these models.", "labels": [], "entities": []}, {"text": "The results of these experiments have implications for the creation of models of spatial lexical semantics for human-robot dialogue systems.", "labels": [], "entities": []}, {"text": "Furthermore, they also provide an insight into the kinds of the semantic knowledge captured by neural language models trained on spatial descriptions, which has implications for image captioning systems.", "labels": [], "entities": [{"text": "image captioning", "start_pos": 178, "end_pos": 194, "type": "TASK", "confidence": 0.7208493202924728}]}], "introductionContent": [{"text": "Spatial language understanding is fundamental requirement for human-robot interaction through dialogue.", "labels": [], "entities": [{"text": "Spatial language understanding", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8607153495152792}]}, {"text": "A natural task fora human to request a robot to fulfil is to retrieve or replace an object for them.", "labels": [], "entities": []}, {"text": "Consequently, a particularly frequent form of spatial description within human-robot interaction is a locative expression.", "labels": [], "entities": []}, {"text": "A locative expression is a noun phrase that describes the location of one object (the target object) relative to another object (the landmark).", "labels": [], "entities": []}, {"text": "The relative location of the target object is specified through a prepositional phrase: Bring me the big red book In order to understand these forms of spatial descriptions a robot must be equipped with computational models of the spatial semantics of prepositions that enable them to ground the semantics of the locative expression relative to the context of the situated dialogue.", "labels": [], "entities": []}, {"text": "A natural approach to developing these computational models is to define them in terms of scene geometry.", "labels": [], "entities": []}, {"text": "And, indeed, there is a tradition of research that follows this path, see for example.", "labels": [], "entities": []}, {"text": "However, there is also a body of experimental and computational research that has highlighted that the semantics of spatial descriptions are dependent on several sources of information beyond scene geometry, including functional semantics (which encompasses a range of factors such as world knowledge about the typical interactions between objects, and object affordances) ().", "labels": [], "entities": []}, {"text": "We can illustrate this distinction between geometric and functionally defined semantics using a number of examples.", "labels": [], "entities": []}, {"text": "To illustrate a geometric semantics: assuming a spatial meaning, anything can be described as to left of anything else so long the spatial configuration of the two objects is geometrically correct.", "labels": [], "entities": []}, {"text": "However, as) has shown the spatial description the umbrella is over the man is sensitive to the protective affordances of the umbrella to stop rain, and is appropriate in contexts where, the umbrella is not in a geometrically prototypical position above the man, so long as the umbrella is protecting the man from the rain.", "labels": [], "entities": []}, {"text": "A further complication with regard to modelling the semantics of spatial descriptions is that experimental results indicate that the contribution of geometrical and functional factors is not the same for every spatial relation ().", "labels": [], "entities": []}, {"text": "This experimental work shows that there is an interplay between function and ge-1 ometry in the definition of spatial semantics and therefore the spatial meaning of given spatial relation is neither fully functional nor fully geometric.", "labels": [], "entities": []}, {"text": "Rather, spatial terms can be ordered on a spectrum based on the sensitivity of their semantics to geometric or functional factors.", "labels": [], "entities": []}, {"text": "Given the distinction between geometric and functional factors in shaping spatial semantics, a useful analysis that would inform the design and creation of computational models of spatial semantics is to identify the particular semantic bias (geometric/functional) that each spatial term evinces.", "labels": [], "entities": []}, {"text": "However, such an analysis is difficult.", "labels": [], "entities": []}, {"text": "Native speakers do not have strong intuitions about the bias of prepositions and such bias had to be established experimentally) or through linguistic analysis.", "labels": [], "entities": []}, {"text": "Reviewing the literature on this experimental and analytic work reveals that prepositions such as in, on, at, over, under have been identified as being functionally biased, whereas above, below, left of and right of are geometrically biased.", "labels": [], "entities": []}, {"text": "Other spatial relations maybe somewhere in between.", "labels": [], "entities": []}, {"text": "In this paper we will use these relations as groundtruth pointers against which our methods will be evaluated.", "labels": [], "entities": []}, {"text": "If the method is successful, then we are able to make predictions about those relations that have not been verified for their bias experimentally.", "labels": [], "entities": []}, {"text": "Knowing the bias of a spatial relation is useful both theoretically and practically.", "labels": [], "entities": []}, {"text": "Theoretically, it informs us about the complexity of grounded semantics of spatial relations.", "labels": [], "entities": []}, {"text": "In particular, it engages with the \"what\" and \"where\" debate where it has been argued that spatial relations are not only spatial (i.e. geometric) (.", "labels": [], "entities": []}, {"text": "Practically, the procedure to estimate the bias is useful for natural language generation systems, for example in situated robotic applications that cannot be trained end-to-end.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 62, "end_pos": 89, "type": "TASK", "confidence": 0.7194605271021525}]}, {"text": "Given that a particular pair of objects can be described geometrically with several spatial relations, the knowledge of functional bias maybe used as a filter, prioritising those relations that are more likely fora particular pair of objects, thereby incorporat- The discussion of Herskovits focuses on interaction of objects conceptualised as geometric shapes, for example on: contiguity with line or surface.", "labels": [], "entities": []}, {"text": "The fact that the interacting objects can be conceptualised as different geometric shapes points and therefore related by a particular prepositions points to their functional nature as discussed here.", "labels": [], "entities": []}, {"text": "This approach to generation of spatial descriptions is therefore similar to the approach that introduces a cognitive load based hierarchy of spatial relations) or a classification-based approach that combines geometric (related to the bounding box), textual (word2vec embeddings) and visual features (final layer of a convolutional network) (.", "labels": [], "entities": [{"text": "generation of spatial descriptions", "start_pos": 17, "end_pos": 51, "type": "TASK", "confidence": 0.7854845523834229}]}, {"text": "The functional geometric bias of spatial relations could also be used to inform semantic parsing, for example in prepositional phrase attachment resolution (.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 80, "end_pos": 96, "type": "TASK", "confidence": 0.7428385615348816}, {"text": "prepositional phrase attachment resolution", "start_pos": 113, "end_pos": 155, "type": "TASK", "confidence": 0.708958625793457}]}, {"text": "Previous work has investigated metrics of the semantic bias of spatial prepositions, see.) uses (i) normalised entropy of targetlandmark pairs to estimate variation of targets and landmarks per relation and (ii) log likelihood ratio to predict the strength of association of targetlandmark pairs with a spatial relation and presents ranked lists of relations by the degree of argument variation or strength of the association respectively.", "labels": [], "entities": [{"text": "log likelihood ratio", "start_pos": 212, "end_pos": 232, "type": "METRIC", "confidence": 0.7683355013529459}]}, {"text": "The approach hypothesises that functionally biased relations are more selective in the kind of targets and landmarks they co-occur with.", "labels": [], "entities": []}, {"text": "The reasoning behind this is that geometrically it is possible to relate a wider range of objects than in the case where additional functional constrains between objects are also applied.) generalises over landmarks and targets in WordNet hierarchy and estimates the generality of the types of landmark.", "labels": [], "entities": []}, {"text": "Again, the work hypothesises that functional relations are more restricted in their choice of target and landmark objects and therefore are generally more specific in terms of the WordNet hierarchy.", "labels": [], "entities": []}, {"text": "Both papers present results compatible with the hypotheses where the functional or geometric nature of prepositions is predicted inline with the experimental studies ().", "labels": [], "entities": []}, {"text": "Sensitive to the fact that relations such as in and on not only have spatial usage but also usages that maybe considered metaphoric, both and were based on an analysis of a corpus of image captions.", "labels": [], "entities": []}, {"text": "The idea being that descriptions of images are more likely to contain spatial descriptions grounded in the image.", "labels": [], "entities": []}, {"text": "For similar reasons, we also employ a corpus of image descriptions (larger than in the previous work).", "labels": [], "entities": []}, {"text": "This paper adopts a similar research hypothesis to, namely that: it is possible to distinguish between functionally biased and geometrically biased spatial relations by examining the diversity of the contexts in which they occur.", "labels": [], "entities": []}, {"text": "Defining the concept of context in terms of the target and landmark object pairs that a relation occurs within, the rationale of this hypothesis is that: geometrically biased relations are more likely to be observed in a more diverse set of contexts, compared to functionally biased relations, because the use of a geometrically biased relation only presupposes the appropriate geometric configuration whereas the use of a functionally biased relation is also constrained by object affordances or typical interactions.", "labels": [], "entities": []}, {"text": "However, the work presented in this paper provides a more general analytical technique based on a neural language model () which is applied to a larger dataset of spatial descriptions.", "labels": [], "entities": []}, {"text": "We use neural language models as the basic tool for our analysis because they are already commonly used to learn the syntax and semantics of words in an unsupervised way.", "labels": [], "entities": []}, {"text": "The contribution of this paper in relation to (i) the previous analyses of geometric and functional aspects of spatial relations is that it examines whether similar predictions can be made using these more general tools of representing meaning of words and phrases; the contribution to (ii) deep learning of language and vision is that it examines to what extent highly specific world-knowledge can be extracted from a neural language model.", "labels": [], "entities": []}, {"text": "The paper proceeds as follows: in Section 2 we describe the datasets and their processing, in Section 3 we describe the basics behind language models and the notion of perplexity, in Section 4 and 5 we present and discuss our results.", "labels": [], "entities": []}, {"text": "We conclude in Section 6.", "labels": [], "entities": []}, {"text": "The code that was used to produce the datasets and results discussed in this paper can be found at: https://github.com/GU-CLASP/ functional-geometric-lm.", "labels": [], "entities": []}], "datasetContent": [{"text": "The Amsterdam Metaphor Corpus ( which is based on a subsection of a BNC reveals that the spatial sense of prepositions are very rare in genres such as news, fiction and academic texts.", "labels": [], "entities": [{"text": "Amsterdam Metaphor Corpus", "start_pos": 4, "end_pos": 29, "type": "DATASET", "confidence": 0.9218650658925375}]}, {"text": "For example, below only has two instances that are not labelled as a metaphor and more than 60% of fragments within, on, and over are not used in their spatial sense.", "labels": [], "entities": []}, {"text": "For this reason use two image description corpora (IAPR TC-12 () and Flickr8k () where spatial uses of prepositions are common.", "labels": [], "entities": [{"text": "IAPR TC-12", "start_pos": 51, "end_pos": 61, "type": "DATASET", "confidence": 0.8018451035022736}, {"text": "Flickr8k", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.8875553607940674}]}, {"text": "They apply a dependency parser and a set of post-processing rules to extract spatial relations, target and landmark object triplets.", "labels": [], "entities": []}, {"text": "The size of this extracted dataset is 96,749 instances and is relatively small for training a neural language model.", "labels": [], "entities": []}, {"text": "() released CLEF 2017 multimodal spatial role labelling dataset (mSpRL) which is a human annotated subset of the IAPR TC-12 Benchmark corpus for spatial relations, targets and landmarks) containing 613 text files and 1,213 sentences.", "labels": [], "entities": [{"text": "CLEF 2017 multimodal spatial role labelling dataset (mSpRL)", "start_pos": 12, "end_pos": 71, "type": "DATASET", "confidence": 0.8412439882755279}, {"text": "IAPR TC-12 Benchmark corpus", "start_pos": 113, "end_pos": 140, "type": "DATASET", "confidence": 0.9287629872560501}]}, {"text": "While this dataset could not be used to train a language model directly, a spatial role labelling classifier could be trained on it to identify spatial relations and arguments which would then be used to produce a bootstrapped dataset for training a neural language model.", "labels": [], "entities": []}, {"text": "Recently, Visual Genome ( has been released which is a crowd-source annotated corpus of 108K images which also includes annotations of relationships between (previously annotated) bounding boxes.", "labels": [], "entities": []}, {"text": "Relationships are predicates that relate objects which include spatial relations (2404639, \"cup on table\"), verbs (2367163, \"girl holding onto bear\") as well as combinations of verbs and spatial relations (2317920, \"woman standing on snow\") and others.", "labels": [], "entities": []}, {"text": "We use this dataset in the work reported here.", "labels": [], "entities": []}, {"text": "Its advantage is that it contains a large number of annotated relationships but the disadvantage is that these are collected in a crowd-sourced setting and are therefore sometimes noisy but we assume these are still of better quality than those from a bootstrapped machine annotated dataset.", "labels": [], "entities": []}, {"text": "To extract spatial relations from the annotated relationships, we created a dictionary of their syntactic forms based on the lists of English spatial relations in and.", "labels": [], "entities": []}, {"text": "For the training data we preserve all items annotated as relationships as single tokens (\"jumping over\") and we simplify some of the composite spatial relations based on our dictionary, e.g. \"left of\" and \"to the left of\" become \"left\" to increase the frequency of instances.", "labels": [], "entities": []}, {"text": "This choice could have affected our results if done without careful consid-eration.", "labels": [], "entities": []}, {"text": "While compound variants of spatial relations have slightly different meanings, we only collapsed those relations for which we assumed this would not affect their geometric or functional bias.", "labels": [], "entities": []}, {"text": "Furthermore, show that compound relations cluster with their non-compound variants using normalised entropy of target-landmark pairs as a metric.", "labels": [], "entities": []}, {"text": "Finally, some variation was due to the shorthand notation used by the annotators, e.g. \"to left of\".", "labels": [], "entities": []}, {"text": "The reason behind keeping all relation(ships) in the training set is to train the language model on as many targets and landmarks as possible and to learn paradigmatic relations between them.", "labels": [], "entities": []}, {"text": "We normalise all words to lowercase and remove the duplicate descriptions per image (created by different annotators).", "labels": [], "entities": []}, {"text": "We also check for and remove instances where a spatial relation is used as an object, e.g. \"chair on left\".", "labels": [], "entities": []}, {"text": "We remove instances where one of the words has fewer than 100 occurrences in the whole dataset which reduces the dataset size by 10%.", "labels": [], "entities": []}, {"text": "We add start and end tokens to the triplets (s target relation landmark /s) as required for training and testing a language model.", "labels": [], "entities": []}, {"text": "The dataset is shuffled and split into 10 folds that are later used in cross-validation.", "labels": [], "entities": []}, {"text": "In the evaluation, we take 20 samples per spatial relation from the held out data of those relations that are members of the dictionary created previously.", "labels": [], "entities": []}, {"text": "This way the average perplexity is always calculated on the same number of samples per each relation.", "labels": [], "entities": []}], "tableCaptions": []}