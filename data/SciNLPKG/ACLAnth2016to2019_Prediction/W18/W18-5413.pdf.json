{"title": [{"text": "Rearranging the Familiar: Testing Compositional Generalization in Recurrent Networks", "labels": [], "entities": [{"text": "Compositional Generalization", "start_pos": 34, "end_pos": 62, "type": "TASK", "confidence": 0.7909419238567352}]}], "abstractContent": [{"text": "Systematic compositionality is the ability to recombine meaningful units with regular and predictable outcomes, and it's seen as key to the human capacity for generalization in language.", "labels": [], "entities": [{"text": "Systematic compositionality", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8065580129623413}]}, {"text": "Recent work (Lake and Baroni, 2018) has studied systematic compositional-ity in modern seq2seq models using generalization to novel navigation instructions in a grounded environment as a probing tool.", "labels": [], "entities": []}, {"text": "Lake and Baroni's main experiment required the models to quickly bootstrap the meaning of new words.", "labels": [], "entities": []}, {"text": "We extend this framework hereto settings where the model needs only to re-combine well-trained functional words (such as \"around\" and \"right\") in novel contexts.", "labels": [], "entities": []}, {"text": "Our findings confirm and strengthen the earlier ones: seq2seq models can be impressively good at generalizing to novel combinations of previously-seen input, but only when they receive extensive training on the specific pattern to be generalized (e.g., generalizing from many examples of \"X around right\" to \"jump around right\"), while failing when generalization requires novel application of com-positional rules (e.g., inferring the meaning of \"around right\" from those of \"right\" and \"around\").", "labels": [], "entities": []}], "introductionContent": [{"text": "Human language learning enjoys a good kind of combinatorial explosion -if a person knows the meaning of \"to run\" and that of \"slowly\", she can immediately understand what it means \"to run slowly\", even if she has never uttered or heard this expression before.", "labels": [], "entities": []}, {"text": "This is an example of compositionality, the algebraic capacity to understand and produce novel combinations from known components.", "labels": [], "entities": []}, {"text": "This principle helps to explain how, when acquiring a language, we can quickly bootstrap to a potentially infinite number of expressions from very limited training data.", "labels": [], "entities": []}, {"text": "Neural networks have recently been successfully applied to many tasks requiring considerable generalization abilities (, including applications in the domain of natural language.", "labels": [], "entities": []}, {"text": "However, it has also been observed that they require a very large number of training examples to succeed, which suggests that they lack compositional abilities (.", "labels": [], "entities": []}, {"text": "There has been a substantial earlier debate on the extent to which neural networks display some degree of compositional generalization (e.g.,.", "labels": [], "entities": []}, {"text": "Recently, Lake and Baroni (2018) revisited these issues in light of the latest advances in deep neural networks for natural language processing.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 116, "end_pos": 143, "type": "TASK", "confidence": 0.6507590711116791}]}, {"text": "The authors introduced the SCAN dataset for studying compositionality in sequence-tosequence (seq2seq) neural network models).", "labels": [], "entities": [{"text": "SCAN dataset", "start_pos": 27, "end_pos": 39, "type": "DATASET", "confidence": 0.7341553270816803}]}, {"text": "SCAN is a simple language-driven navigation environment that supports one-shot learning experiments, where the trained agent must execute test commands that it has never encountered in training, but are assembled from the same components as the training commands.", "labels": [], "entities": []}, {"text": "Lake and Baroni found that state-of-the-art recurrent neural networks (RNNs) showed impressive zero-shot generalization capabilities when commands were arbitrarily split between train and test set, but they failed in cases that required systematic compositionality, that is, to extract algebraic composition rules from the training examples.", "labels": [], "entities": []}, {"text": "To begin with, RNNs failed when they had to generalize to commands requiring longer action sequences to be executed.", "labels": [], "entities": []}, {"text": "This is not too surprising, as longer sequences are notoriously challeng-ing for seq2seq models).", "labels": [], "entities": []}, {"text": "More interestingly, Lake and Baroni found that RNNs do not correctly generalize the usage of anew action verb (shown in isolation during training) to contexts that are familiar from other verbs.", "labels": [], "entities": []}, {"text": "In other words, RNNs fail the following basic compositionality test: Even after they acquired the meaning of \"to run again\" and \"to dax\", they do not understand \"to dax again\" on first encounter.", "labels": [], "entities": []}, {"text": "As Lake and Baroni show, the generalization problem is linked to the fact that RNNs fail to learn a representation (an embedding) for the new verb (\"to dax\") that is similar to those of known verbs (\"to run\", \"to look\"), and consequently it cannot rely on similarity information to correctly generalize verb usage.", "labels": [], "entities": [{"text": "generalize verb usage", "start_pos": 292, "end_pos": 313, "type": "TASK", "confidence": 0.7960075537363688}]}, {"text": "This is arguably more of an instance of the problem of quickly learning meaningful new-word embeddings, than strictly a failure of compositionality.", "labels": [], "entities": []}, {"text": "In this paper, we repurpose SCAN to test another kind of compositionality, namely one that requires combining highly familiar words in new ways to create novel meaning.", "labels": [], "entities": []}, {"text": "As illustrated above, this is what we do when we combine a functional term such as \"slowly\" with the verb \"to run\" to obtain the phrase \"to run slowly\".", "labels": [], "entities": []}, {"text": "Or, in terms of the SCAN commands that we test here, this is what is required to understand an expression such as \"jump around right\" when the meanings of \"jump\", \"right\" and \"around\" are known.", "labels": [], "entities": []}, {"text": "Our results confirm and strengthen the conclusions of Lake and Baroni.", "labels": [], "entities": []}, {"text": "On the one hand, RNNs do show a considerable degree of generalization in our experiments as well.", "labels": [], "entities": []}, {"text": "However, their performance dramatically decreases as the difference between training and testing becomes more systematic, even though all test examples could be correctly processed by relying on simple composition rules amply illustrated in the training data.", "labels": [], "entities": []}], "datasetContent": [{"text": "All reported accuracies correspond to the percentage of instances where the model successfully predicted the entire output sequence.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 13, "end_pos": 23, "type": "METRIC", "confidence": 0.989357054233551}]}, {"text": "All experiments were run using the overall best neural network from Lake and Baroni (2018): a seq2seq 2-layer, 200-unit LSTM with 50% dropout.", "labels": [], "entities": []}, {"text": "The values of all other hyperparameters were those specified by Lake and Baroni.", "labels": [], "entities": []}, {"text": "This model was very successful in their basic, randomsplit experiment, where it achieved 99.8% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9972444772720337}]}, {"text": "We also tried the best attention-augmented model from Lake and Baroni, but it was outperformed by the overall-best in all experiments, and is thus omitted here.", "labels": [], "entities": []}, {"text": "All test-set accuracies are reported with mean and standard deviation across 5 runs: in experiments where the splits were created by random sampling, each run corresponds to a different sample.", "labels": [], "entities": []}, {"text": "Though the size of the training set varies across conditions, the training regime is always fixed at 100k presentations (approximately 5 epochs for the condition with the largest training set): in practice, this was sufficient for near- perfect training set accuracy in all conditions 1 .  In order to probe the network's ability to recombine well-trained words as well as to assess the factors that render that task easier or harder, we compared performance across 4 different train-test splits.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 258, "end_pos": 266, "type": "METRIC", "confidence": 0.9840242266654968}]}, {"text": "In the first one we leave out examples containing the subcommand \"jump around right\" (a specific instance of Template 12) whereas in the other 3 we leave out all instances of different templates described in-depth in.", "labels": [], "entities": []}, {"text": "In all of the splits, the network is tasked with generalizing to novel commands involving \"right\" by exploiting the \"left\"/\"right\" symmetry in the training set and/or the distributional similarity among primitives.", "labels": [], "entities": []}, {"text": "We present the splits in order of conjectured increasing complexity, in terms of systematic gaps between training and test sets.", "labels": [], "entities": []}, {"text": "shows examples of commands in the training and test set for the different conditions.", "labels": [], "entities": []}, {"text": "\u2022 jump around right: The test set consists of all commands containing the phrase \"jump around right\", while all remaining commands are in the training set, including uses of \"jump around left\" and \"Primitive around right\" for the other primitives.", "labels": [], "entities": []}, {"text": "The network is thus exposed to plenty of evidence that \"jump\" has the same distribution as the other primitives (thus, it should easily discover the similarity of \"jump\" to the other primitives), and it sees many instances of the \"Primitive around right\" template with all other primitive fillers but \"jump\".", "labels": [], "entities": []}, {"text": "\u2022 Primitive right: The test set consists of all commands containing \"Primitive right\" (Template 4 in), with all remaining templates (and their conjunctions and quantifications) in the training set.", "labels": [], "entities": []}, {"text": "In this case, the network is exposed to \"Primitive left\" and many examples illustrating the \"left\"/\"right\" symmetry during training, and it must bootstrap to the simplest usage of \"right\" attest time.", "labels": [], "entities": []}, {"text": "\u2022 Primitive opposite right: The test set consists of all commands containing templates of the form \"Primitive opposite right\" (Template 8), with the remaining templates (and their conjunctions and quantifications) in the training set.", "labels": [], "entities": []}, {"text": "Here, the network is never exposed to the \"Primitive opposite right\" template with any primitive filler, and it has to bootstrap the combined effect of \"opposite\" and \"right\" based on seeing them applied independently, plus the \"left\"/\"right\" symmetry.", "labels": [], "entities": []}, {"text": "\u2022 Primitive around right: The test set consists of all commands containing templates of the form \"Primitive around right\" (Template 12), with the remaining templates in the training set.", "labels": [], "entities": []}, {"text": "This is analogous to \"Primitive opposite right\", but requires executing a longer action sequence due to the different SCAN semantics of \"opposite\" (two turning+Primitive steps to turn in the opposite direction) vs. \"around\" (four turning+Primitive steps to perform a full roundabout, refer to).", "labels": [], "entities": []}, {"text": "Observe that \"turn\" in SCAN has a different semantics from the other actions verbs (see).", "labels": [], "entities": []}, {"text": "We found that removing all commands where \"turn\" appeared in the target expression (e.g. \"turn around right\" in the \"Primitive around right\" condition, \"turn opposite right\" in the \"Primitive opposite right\" condition etc.) from both training and test sets systematically increased accuracy, and we thus report results in this setup.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 282, "end_pos": 290, "type": "METRIC", "confidence": 0.9991899132728577}]}, {"text": "Results: A summary of the results is presented in.", "labels": [], "entities": []}, {"text": "We see that the network had no problem generalizing to \"jump around right\" when being exposed to all commands containing this template with all other possible fillers.", "labels": [], "entities": []}, {"text": "This confirms Lake and Baroni's result that modern RNNs do to some extent generalize to new combinations.", "labels": [], "entities": []}, {"text": "However, the remaining results also confirm their finding of alack of systematicity in generalization.", "labels": [], "entities": [{"text": "systematicity", "start_pos": 70, "end_pos": 83, "type": "TASK", "confidence": 0.9429628849029541}]}, {"text": "Interestingly, the poor performance in the \"Primitive right\" condition shows that generalization is problematic for RNNs not only when they have to bootstrap to longer constructions, but also when they have to systematically generalize to shorter ones (a network exposed to \"run left\", \"run opposite right\", \"jump left\", \"jump around right\" etc. fails to execute \"run right\" or \"jump right\").", "labels": [], "entities": []}, {"text": "The dramatic difference inaccuracy between training without \"around right\" commands vs. training on all templates except \"jump around right\" commands (2.46% vs. 98.43%) points to the network being able to generalize the application of \"around right\" across primitives, but not being able to directly apply \"right\" and \"around\" to a primitive, without having seen them presented together.", "labels": [], "entities": []}, {"text": "The failure modes in the \"Primitive around right\" condition further showcase, qualitatively, the lack of systematicity.", "labels": [], "entities": []}, {"text": "For instance, though the network correctly interprets the complex expression \"jump right after walk around right\", it fails to do so for the subcommand \"walk around right\", where it flips one of the four \"right\" turns fora \"left\" one.", "labels": [], "entities": []}, {"text": "Surprisingly, the network, while still far from perfect, has considerably higher accuracy (47.62%) when generalizing to \"opposite right,\" a simpler command of the same nature as \"around right.\"", "labels": [], "entities": [{"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9992533326148987}]}, {"text": "This suggests that memory factors (learning to repeat the relevant steps 4 times instead of  One interesting result of Experiment 1 is that the number of distinct primitive fillers of a template that the network sees in training affects its ability to generalize the template, as shown by the striking performance difference between the \"Primitive around right\" (0 fillers of the relevant template seen in training, very low accuracy) and \"jump around right\" conditions (3 fillers seen in training, near-perfect generalization).", "labels": [], "entities": [{"text": "Primitive", "start_pos": 338, "end_pos": 347, "type": "METRIC", "confidence": 0.9592369794845581}, {"text": "accuracy", "start_pos": 425, "end_pos": 433, "type": "METRIC", "confidence": 0.9981670379638672}]}, {"text": "In Experiment 2, we take a detailed look at this phenomenon by varying the number of primitive fillers for this template (Template 12 in) that the model observes during training, with the goal of learning the full abstract template.", "labels": [], "entities": []}, {"text": "We fix the test set across all conditions by making it consist only of the commands containing the expression \"jump around right\" -this allows for more direct comparison across the conditions.", "labels": [], "entities": []}, {"text": "Again, commands containing the expression \"turn around right\" were removed to avoid interference.", "labels": [], "entities": []}, {"text": "The different conditions for this experiment are, in order of decreasing difficulty: \u2022 0 fillers: The training set contains no examples of Template 12, e.g., no command of the form \"Primitive around right\".", "labels": [], "entities": []}, {"text": "It does contain all other complete templates (1-11) in Table 1.", "labels": [], "entities": []}, {"text": "\u2022 1 filler: The training set has commands containing \"look around right\" for Template 12 as well as all other complete templates in Table 1. 2 \u2022 2 fillers: The training set has commands containing \"look around right\" and \"walk around right\" for Template 12 as well as all other complete templates in.", "labels": [], "entities": []}, {"text": "\u2022 3 fillers: The training set has commands containing the templates \"look around right\", \"walk around right\" and \"run around right\" for Template 12 as well as all other complete templates in.", "labels": [], "entities": []}, {"text": "Each new template corresponds to roughly an additional 1,100 distinct examples in the training set.", "labels": [], "entities": []}, {"text": "Note that the actual primitives chosen for each condition do not matter, as their distribution is identical.", "labels": [], "entities": []}, {"text": "Results: A summary of the results is shown in.", "labels": [], "entities": []}, {"text": "We observe that the network only needs examples of 1 primitive filler to start generalizing almost perfectly to other fillers of the template.", "labels": [], "entities": []}, {"text": "So, crucially, the network seems able to perform some analogical generalization from a verb to the other in the \"around right\" context, but not to productively apply the \"right\" and \"around\" rules to a verb, when their combined effect has never been observed.", "labels": [], "entities": [{"text": "analogical generalization", "start_pos": 54, "end_pos": 79, "type": "TASK", "confidence": 0.6958124041557312}]}, {"text": "We consider here a further level of granularity.", "labels": [], "entities": []}, {"text": "Adding one additional primitive filler, as we did in Experiment 2, corresponds to about 1,100 additional distinct training examples.", "labels": [], "entities": []}, {"text": "Are they all needed, or is it sufficient to observe the target complex template in a smaller number of examples?", "labels": [], "entities": []}, {"text": "This question is the subject of Experiment 3.", "labels": [], "entities": []}, {"text": "In order to analyze the sample complexity of the model's generalizations, we now take the 0 filler condition from Experiment 2 and progressively add examples from the 1 filler condition.", "labels": [], "entities": []}, {"text": "More precisely, we randomly add 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, or 1,024 commands containing \"look around right\", but no other command of the form \"Primitive around right\", to the training set of the 0 filler condition.", "labels": [], "entities": []}, {"text": "As before, all other templates (1-11) and their conjunctions and quantifications are also provided during training.", "labels": [], "entities": []}, {"text": "Note that 1,024 is approximately the difference in distinct examples between the 0 and 1 filler conditions, such that this experiment spans the entire range from one to the other.", "labels": [], "entities": []}, {"text": "Results: A summary of the results is shown in Figure 3.", "labels": [], "entities": []}, {"text": "On the one hand, the sample complexity with which performance ramps up is quite impressive, being at a respectable 70% with 64 additional examples and peaking at 512 examples.", "labels": [], "entities": []}, {"text": "On the other hand, the very fact that performance increases gradually, and that it takes so long for the network to peak points to a failure to generalize systematically: instead of piecing together the general rule, the network seems to be rather accumulating evidence for some specific cases.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: All command templates in the SCAN dataset, along with the target output. Here, \"Primitive\" can stand  for \"jump\", \"walk\", \"run\", or \"look\", with the corresponding output", "labels": [], "entities": [{"text": "SCAN dataset", "start_pos": 39, "end_pos": 51, "type": "DATASET", "confidence": 0.755908191204071}]}]}