{"title": [{"text": "Complex Word Identification Based on Frequency in a Learner Corpus", "labels": [], "entities": [{"text": "Complex Word Identification", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6181042293707529}]}], "abstractContent": [{"text": "We introduce the TMU systems for the complex word identification (CWI) shared task 2018.", "labels": [], "entities": [{"text": "complex word identification (CWI) shared task", "start_pos": 37, "end_pos": 82, "type": "TASK", "confidence": 0.8187507465481758}]}, {"text": "TMU systems use random forest clas-sifiers and regressors whose features are the number of characters and words and the frequency of target words in various corpora.", "labels": [], "entities": []}, {"text": "Our simple systems performed best on 5 of the 12 tracks.", "labels": [], "entities": []}, {"text": "Ablation analysis confirmed the usefulness of a learner corpus fora CWI task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Lexical simplification ) is one of the approaches for text simplification, which facilitates children and language learners reading comprehension.", "labels": [], "entities": [{"text": "Lexical simplification )", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9032367269198099}, {"text": "text simplification", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.7842752039432526}]}, {"text": "Lexical simplification comprises the following steps: 1.", "labels": [], "entities": [{"text": "Lexical simplification", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9141874015331268}]}], "datasetContent": [{"text": "The dump data of Wikipedia and WikiNews on December 01, 2017, were downloaded and divided into sentences using WikiExtractor and NLTK . All corpora (Train / Dev / Test and Wikipedia / WikiNews / Lang-8) were tokenized and lowercased in the script of the statistical machine translation tool Moses 5 (.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 254, "end_pos": 285, "type": "TASK", "confidence": 0.6181476016839346}]}, {"text": "displays the number of sentences in each corpus.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Example instances of the English dataset.", "labels": [], "entities": [{"text": "English dataset", "start_pos": 35, "end_pos": 50, "type": "DATASET", "confidence": 0.8686385452747345}]}, {"text": " Table 2: Number of instances.", "labels": [], "entities": []}, {"text": " Table 4: Number of sentences.", "labels": [], "entities": []}, {"text": " Table 7: Ablation analysis of frequency and probability features.", "labels": [], "entities": [{"text": "Ablation analysis", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.8367787897586823}]}, {"text": " Table 8: Ablation analysis of corpora.", "labels": [], "entities": [{"text": "Ablation analysis", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.8220941722393036}]}]}