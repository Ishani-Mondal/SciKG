{"title": [{"text": "Neural Network Architectures for Arabic Dialect Identification", "labels": [], "entities": [{"text": "Arabic Dialect Identification", "start_pos": 33, "end_pos": 62, "type": "TASK", "confidence": 0.683247317870458}]}], "abstractContent": [{"text": "SYSTRAN competes this year for the first time to the DSL shared task, in the Arabic Dialect Identification subtask.", "labels": [], "entities": [{"text": "SYSTRAN", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8071029186248779}, {"text": "DSL shared task", "start_pos": 53, "end_pos": 68, "type": "TASK", "confidence": 0.5133601427078247}, {"text": "Arabic Dialect Identification subtask", "start_pos": 77, "end_pos": 114, "type": "DATASET", "confidence": 0.7636943012475967}]}, {"text": "We participate by training several Neural Network models showing that we can obtain competitive results despite the limited amount of training data available for learning.", "labels": [], "entities": []}, {"text": "We report our experiments and detail the network architecture and parameters of our 3 runs: our best performing system consists in a Multi-Input CNN that learns separate embeddings for lexical, phonetic and acoustic input features (F1: 0.5289); we also built a CNN-biLSTM network aimed at capturing both spatial and sequential features directly from speech spectrograms (F1: 0.3894 at submission time, F1: 0.4235 with later found parameters); and finally a system relying on binary CNN-biLSTMs (F1: 0.4339).", "labels": [], "entities": [{"text": "F1", "start_pos": 232, "end_pos": 234, "type": "METRIC", "confidence": 0.9939658045768738}, {"text": "F1", "start_pos": 371, "end_pos": 373, "type": "METRIC", "confidence": 0.9893707036972046}, {"text": "F1", "start_pos": 402, "end_pos": 404, "type": "METRIC", "confidence": 0.9865586757659912}, {"text": "F1", "start_pos": 495, "end_pos": 497, "type": "METRIC", "confidence": 0.9671188592910767}]}], "introductionContent": [{"text": "Dialect identification (DID) consists in automatically identifying the corresponding dialect of an utterance, either written or spoken.", "labels": [], "entities": [{"text": "Dialect identification (DID)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8577812492847443}]}, {"text": "This task is a particularly challenging case of language identification since dialects are closely related languages.", "labels": [], "entities": [{"text": "language identification", "start_pos": 48, "end_pos": 71, "type": "TASK", "confidence": 0.7127457112073898}]}, {"text": "It is not only useful but often a requirement for various Natural Language Processing (NLP) tasks such as Machine Translation (MT) or Automatic Speech Recognition (ASR).", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 106, "end_pos": 130, "type": "TASK", "confidence": 0.8392707467079162}, {"text": "Automatic Speech Recognition (ASR)", "start_pos": 134, "end_pos": 168, "type": "TASK", "confidence": 0.7808427313963572}]}, {"text": "In the context of the shared task Discriminating between Similar Languages, Varieties and Dialects (DSL), dialect identification can be seen as a multi-class sentence classification problem, in which participants must predict a label for each sentence, given several features describing the sentence.", "labels": [], "entities": [{"text": "Discriminating between Similar Languages, Varieties and Dialects (DSL)", "start_pos": 34, "end_pos": 104, "type": "TASK", "confidence": 0.6440496796911414}, {"text": "dialect identification", "start_pos": 106, "end_pos": 128, "type": "TASK", "confidence": 0.7216254472732544}, {"text": "multi-class sentence classification", "start_pos": 146, "end_pos": 181, "type": "TASK", "confidence": 0.7653358181317648}]}, {"text": "We present our results for the Arabic Dialect Identification (ADI) subtask, where the similar languages to discriminate are Modern Standard Arabic and four dialects of Arabic: Egyptian, Gulf, Levantine and North African.", "labels": [], "entities": [{"text": "Arabic Dialect Identification (ADI)", "start_pos": 31, "end_pos": 66, "type": "TASK", "confidence": 0.7461716334025065}]}, {"text": "Given their high success in many other NLP tasks and lower cost in feature engineering compared to more traditional machine learning methods, in this paper we mostly focus on the design of suitable Neural Networks, knowing that the limited size of the training dataset is a well known handicap for such models as already pointed out in previous editions of the DSL workshop.", "labels": [], "entities": [{"text": "DSL workshop", "start_pos": 361, "end_pos": 373, "type": "DATASET", "confidence": 0.8678427338600159}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Distribution of dialects and percentage of empty word transcripts in 2018 ADI datasets.", "labels": [], "entities": [{"text": "ADI datasets", "start_pos": 84, "end_pos": 96, "type": "DATASET", "confidence": 0.8964312970638275}]}, {"text": " Table 2: Results for the ADI task (macro-averaged F1 scores).", "labels": [], "entities": [{"text": "ADI task", "start_pos": 26, "end_pos": 34, "type": "TASK", "confidence": 0.562185600399971}, {"text": "F1", "start_pos": 51, "end_pos": 53, "type": "METRIC", "confidence": 0.926054060459137}]}, {"text": " Table 3: Results of the SVM models (macro-averaged F1 scores).", "labels": [], "entities": [{"text": "F1", "start_pos": 52, "end_pos": 54, "type": "METRIC", "confidence": 0.9575509428977966}]}, {"text": " Table 4: Results of the Multi-Input CNN models (macro-averaged F1 scores).", "labels": [], "entities": [{"text": "F1", "start_pos": 64, "end_pos": 66, "type": "METRIC", "confidence": 0.939888060092926}]}, {"text": " Table 5: Results for the CNN-biLSTM models (macro-averaged F1 scores). Layers are described with  the convention filter size*number of filters.", "labels": [], "entities": [{"text": "F1", "start_pos": 60, "end_pos": 62, "type": "METRIC", "confidence": 0.9281419515609741}]}, {"text": " Table 6: Results by dialect in the 5 binary systems and final system (F1 scores).", "labels": [], "entities": [{"text": "F1 scores", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.9804250299930573}]}]}