{"title": [], "abstractContent": [{"text": "This paper describes the POSTECH's submission to the WMT 2018 shared task on Automatic Post-Editing (APE).", "labels": [], "entities": [{"text": "WMT 2018 shared task on Automatic Post-Editing (APE)", "start_pos": 53, "end_pos": 105, "type": "TASK", "confidence": 0.645329287648201}]}, {"text": "We propose anew neural end-to-end post-editing model based on the transformer network.", "labels": [], "entities": []}, {"text": "We modified the encoder-decoder attention to reflect the relation between the machine translation output, the source and the post-edited translation in APE problem.", "labels": [], "entities": []}, {"text": "Experiments on WMT17 English-German APE data set show an improvement in both TER and BLEU score over the best result of WMT17 APE shared task.", "labels": [], "entities": [{"text": "WMT17 English-German APE data set", "start_pos": 15, "end_pos": 48, "type": "DATASET", "confidence": 0.8973100423812866}, {"text": "TER", "start_pos": 77, "end_pos": 80, "type": "METRIC", "confidence": 0.999504566192627}, {"text": "BLEU score", "start_pos": 85, "end_pos": 95, "type": "METRIC", "confidence": 0.9765028655529022}, {"text": "WMT17 APE shared task", "start_pos": 120, "end_pos": 141, "type": "TASK", "confidence": 0.6851463466882706}]}, {"text": "Our primary submission achieves-4.52 TER and +6.81 BLEU score on PBSMT task and-0.13 TER and +0.40 BLEU score for NMT task compare to the baseline.", "labels": [], "entities": [{"text": "TER", "start_pos": 37, "end_pos": 40, "type": "METRIC", "confidence": 0.9977928400039673}, {"text": "BLEU", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.9839943647384644}, {"text": "TER", "start_pos": 85, "end_pos": 88, "type": "METRIC", "confidence": 0.9966055154800415}, {"text": "BLEU", "start_pos": 99, "end_pos": 103, "type": "METRIC", "confidence": 0.9939166903495789}]}], "introductionContent": [{"text": "Although machine translation technology has improved, machine translation output inevitably involves errors and the type of errors in the output varies depending on the machine translation system.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 9, "end_pos": 28, "type": "TASK", "confidence": 0.7947120368480682}, {"text": "machine translation output", "start_pos": 54, "end_pos": 80, "type": "TASK", "confidence": 0.8253729939460754}]}, {"text": "Correcting those systematic errors inside the system may cause other problems such as increase of the decoding complexity ( . For this reason, Automatic Post-Editing (APE) is suggested as an alternative to enhance the performance of the machine translation.", "labels": [], "entities": [{"text": "Automatic Post-Editing (APE)", "start_pos": 143, "end_pos": 171, "type": "METRIC", "confidence": 0.7892507553100586}, {"text": "machine translation", "start_pos": 237, "end_pos": 256, "type": "TASK", "confidence": 0.7183208465576172}]}, {"text": "APE aims at the automatic correction of systematic errors in the machine translation output without any modification of the original machine translation system ().", "labels": [], "entities": [{"text": "APE", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.41657277941703796}]}, {"text": "Basically, APE problem can be defined as a translation problem from machine translation output (mt) to post-edited sentence (pe), but source sentence (src) is used as an additional source for the problem.", "labels": [], "entities": [{"text": "APE problem", "start_pos": 11, "end_pos": 22, "type": "TASK", "confidence": 0.9127154350280762}]}, {"text": "As a result, APE problem becomes a multi-source translation problem between two sources (mt, src) and a target (pe).", "labels": [], "entities": [{"text": "APE", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9066830277442932}]}, {"text": "Due to the additional source, APE has two translation directions, the mt\u2192pe direction and the src\u2192pe direction.", "labels": [], "entities": [{"text": "APE", "start_pos": 30, "end_pos": 33, "type": "METRIC", "confidence": 0.5000340938568115}]}, {"text": "Previous researches have suggested various methods to combine the two directions with neural network architecture, such as loglinear combination of two translation models, factored translation model and multiencoder architecture (.", "labels": [], "entities": []}, {"text": "Among the methods, we focus on the multi-encoder approach because it is more appropriate to model the multi-source translation problem.", "labels": [], "entities": [{"text": "multi-source translation problem", "start_pos": 102, "end_pos": 134, "type": "TASK", "confidence": 0.7469802896181742}]}, {"text": "Also, considering the importance of proper attention mechanism, as shown in the research of JunczysDowmunt and, we use the transformer network ( composed of a novel attention mechanism.", "labels": [], "entities": [{"text": "JunczysDowmunt", "start_pos": 92, "end_pos": 106, "type": "DATASET", "confidence": 0.9682060480117798}]}, {"text": "With this consideration, our submission to the WMT 2018 shared task on Automatic Post-Editing is a neural multi-encoder model based on the transformer network.", "labels": [], "entities": [{"text": "WMT 2018 shared task", "start_pos": 47, "end_pos": 67, "type": "DATASET", "confidence": 0.7503877878189087}]}, {"text": "We extend the transformer network implementation in library to implement our model.", "labels": [], "entities": []}, {"text": "We participated in both PBSMT task and NMT task with this multi-encoder model.", "labels": [], "entities": []}, {"text": "In this paper, we introduce the multi-encoder transformer network for APE.", "labels": [], "entities": [{"text": "APE", "start_pos": 70, "end_pos": 73, "type": "TASK", "confidence": 0.5455104112625122}]}, {"text": "The remainder of the paper is organized as follows: Section 2 contains the related work.", "labels": [], "entities": []}, {"text": "Section 3 describes our method.", "labels": [], "entities": []}, {"text": "Section 4 gives the experimental results, and Section 5 is the conclusion.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated the models using the WMT data set, computing the TER () and BLEU () scores on the decoded output.", "labels": [], "entities": [{"text": "WMT data set", "start_pos": 34, "end_pos": 46, "type": "DATASET", "confidence": 0.9147717952728271}, {"text": "TER", "start_pos": 62, "end_pos": 65, "type": "METRIC", "confidence": 0.9989455342292786}, {"text": "BLEU", "start_pos": 73, "end_pos": 77, "type": "METRIC", "confidence": 0.9890068769454956}]}, {"text": "The decoding parameter is the same as the default decoding parameter of the Tensor2tensor.", "labels": [], "entities": []}, {"text": "We used the scores of original machine translation output as the baseline to compare our results.", "labels": [], "entities": []}, {"text": "shows the results of the evaluation on PBSMT data set and NMT data set.", "labels": [], "entities": [{"text": "PBSMT data set", "start_pos": 39, "end_pos": 53, "type": "DATASET", "confidence": 0.9852039019266764}, {"text": "NMT data set", "start_pos": 58, "end_pos": 70, "type": "DATASET", "confidence": 0.9777400493621826}]}, {"text": "The result on PBSMT data set is comparable to the last year's top result without any additional post-processing.", "labels": [], "entities": [{"text": "PBSMT data set", "start_pos": 14, "end_pos": 28, "type": "DATASET", "confidence": 0.987968921661377}]}, {"text": "In contrast, the result on NMT data set shows almost no improvement.", "labels": [], "entities": [{"text": "NMT data set", "start_pos": 27, "end_pos": 39, "type": "DATASET", "confidence": 0.9536414742469788}]}, {"text": "We guess that the different characteristics of PBSMT artificial data set from the NMT training data set causes the result.", "labels": [], "entities": [{"text": "PBSMT artificial data set", "start_pos": 47, "end_pos": 72, "type": "DATASET", "confidence": 0.8168904632329941}, {"text": "NMT training data set", "start_pos": 82, "end_pos": 103, "type": "DATASET", "confidence": 0.903127446770668}]}], "tableCaptions": [{"text": " Table 1: Statistics for WMT APE data sets.", "labels": [], "entities": [{"text": "WMT APE data sets", "start_pos": 25, "end_pos": 42, "type": "DATASET", "confidence": 0.7549722790718079}]}, {"text": " Table 4: The official results of the submitted models to WMT18 APE task..", "labels": [], "entities": [{"text": "WMT18 APE task.", "start_pos": 58, "end_pos": 73, "type": "TASK", "confidence": 0.6199563344319662}]}, {"text": " Table 3: The results of submitted models on WMT APE data set.", "labels": [], "entities": [{"text": "WMT APE data set", "start_pos": 45, "end_pos": 61, "type": "DATASET", "confidence": 0.9217195361852646}]}, {"text": " Table 2: The result of multi-encoder transformer network on WMT APE data set.", "labels": [], "entities": [{"text": "WMT APE data set", "start_pos": 61, "end_pos": 77, "type": "DATASET", "confidence": 0.9389637112617493}]}]}