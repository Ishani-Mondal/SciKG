{"title": [{"text": "On the Role of Text Preprocessing in Neural Network Architectures: An Evaluation Study on Text Categorization and Sentiment Analysis", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 114, "end_pos": 132, "type": "TASK", "confidence": 0.8260524570941925}]}], "abstractContent": [{"text": "Text preprocessing is often the first step in the pipeline of a Natural Language Processing (NLP) system, with potential impact in its final performance.", "labels": [], "entities": [{"text": "Text preprocessing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7552466094493866}]}, {"text": "Despite its importance, text preprocessing has not received much attention in the deep learning literature.", "labels": [], "entities": [{"text": "text preprocessing", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.8313849866390228}]}, {"text": "In this paper we investigate the impact of simple text preprocessing decisions (particularly tokeniz-ing, lemmatizing, lowercasing and multiword grouping) on the performance of a standard neural text classifier.", "labels": [], "entities": [{"text": "multiword grouping", "start_pos": 135, "end_pos": 153, "type": "TASK", "confidence": 0.7772727012634277}]}, {"text": "We perform an extensive evaluation on standard benchmarks from text categorization and sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 87, "end_pos": 105, "type": "TASK", "confidence": 0.9325539767742157}]}, {"text": "While our experiments show that a simple tokeniza-tion of input text is generally adequate, they also highlight significant degrees of variability across preprocessing techniques.", "labels": [], "entities": []}, {"text": "This reveals the importance of paying attention to this usually-overlooked step in the pipeline, particularly when comparing different models.", "labels": [], "entities": []}, {"text": "Finally , our evaluation provides insights into the best preprocessing practices for training word embeddings.", "labels": [], "entities": []}], "introductionContent": [{"text": "Words are often considered as the basic constituents of texts for many languages, including English.", "labels": [], "entities": []}, {"text": "The first module in an NLP pipeline is a tokenizer which transforms texts to sequences of words.", "labels": [], "entities": []}, {"text": "However, in practise, other preprocessing techniques can be (and are) further used together with tokenization.", "labels": [], "entities": []}, {"text": "These include lemmatization, lowercasing and multiword grouping, among others.", "labels": [], "entities": [{"text": "multiword grouping", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.860737681388855}]}, {"text": "Although these preprocessing decisions have been studied in the context of conventional text classification techniques (;), little attention has been paid to them in the more recent neural-based models.", "labels": [], "entities": [{"text": "text classification", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.725790336728096}]}, {"text": "The most similar study to ours is, which analyzed different encoding levels for English and Asian languages such as Chinese, Japanese and Korean.", "labels": [], "entities": []}, {"text": "As opposed to our work, their analysis was focused on UTF-8 bytes, characters, words, romanized characters and romanized words as encoding levels, rather than the preprocessing techniques analyzed in this paper.", "labels": [], "entities": []}, {"text": "Additionally, word embeddings have been shown to play an important role in boosting the generalization capabilities of neural systems).", "labels": [], "entities": []}, {"text": "However, while some studies have focused on intrinsically analyzing the role of lemmatization in their underlying training corpus, the impact on their extrinsic performance when integrated into a neural network architecture has remained understudied.", "labels": [], "entities": []}, {"text": "In this paper we focus on the role of preprocessing the input text, particularly in how it is split into individual (meaning-bearing) tokens and how it affects the performance of standard neural text classification models based on Convolutional Neural Networks (.", "labels": [], "entities": []}, {"text": "CNNs have proven to be effective in a wide range of NLP applications, including text classification tasks such as topic categorization) and polarity detection, which are the tasks considered in this work.", "labels": [], "entities": [{"text": "text classification tasks such as topic categorization", "start_pos": 80, "end_pos": 134, "type": "TASK", "confidence": 0.7175163115773883}, {"text": "polarity detection", "start_pos": 140, "end_pos": 158, "type": "TASK", "confidence": 0.7607423365116119}]}, {"text": "The goal of our evaluation study is to find answers to the following two questions: 1.", "labels": [], "entities": []}, {"text": "Are neural network architectures (in particular CNNs) affected by seemingly small preprocessing decisions in the input text?", "labels": [], "entities": []}, {"text": "2. Does the preprocessing of the embeddings' underlying training corpus have an impact on the final performance of a state-of-the-art neural network text classifier?", "labels": [], "entities": []}, {"text": "According to our experiments in topic categorization and polarity detection, these decisions are important in certain cases.", "labels": [], "entities": [{"text": "topic categorization", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.7221659570932388}, {"text": "polarity detection", "start_pos": 57, "end_pos": 75, "type": "TASK", "confidence": 0.6969495564699173}]}, {"text": "Moreover, we shed some light on the motivations of each preprocessing decision and provide some hints on how to normalize the input corpus to better suit each setting.", "labels": [], "entities": []}, {"text": "The accompanying materials of this submission can be downloaded at the following repository: https://github.com/pedrada88/ preproc-textclassification.", "labels": [], "entities": []}], "datasetContent": [{"text": "We considered two tasks for our experiments: topic categorization, i.e. assigning a topic to a given document from a pre-defined set of topics, and polarity detection, i.e. detecting if the sentiment of a given piece of text is positive or negative (.", "labels": [], "entities": [{"text": "polarity detection", "start_pos": 148, "end_pos": 166, "type": "TASK", "confidence": 0.7143238633871078}, {"text": "detecting if the sentiment of a given piece of text", "start_pos": 173, "end_pos": 224, "type": "TASK", "confidence": 0.6419743567705154}]}, {"text": "Two different settings were studied: (1) word embedding's training corpus and the evaluation dataset were preprocessed in a similar manner (Section 3.2); and (2) the two were preprocessed differently).", "labels": [], "entities": []}, {"text": "In what follows we describe the common experimental setting as well as the datasets and preprocessing used for the evaluation.", "labels": [], "entities": []}, {"text": "We tried with two classification models.", "labels": [], "entities": []}, {"text": "The first one is a standard CNN model similar to that of, using ReLU ( as non-linear activation function.", "labels": [], "entities": [{"text": "ReLU", "start_pos": 64, "end_pos": 68, "type": "METRIC", "confidence": 0.8474467992782593}]}, {"text": "In the second model, we add a recurrent layer (specifically an LSTM (Hochreiter and Schmidhuber, 1997)) before passing the pooled features directly to the fully connected softmax layer.", "labels": [], "entities": []}, {"text": "The inclusion of this LSTM layer has been shown to be able to effectively replace multiple layers of convolution and be beneficial particularly for large inputs).", "labels": [], "entities": []}, {"text": "These models were used for both topic categorization and polarity detection tasks, with slight hyperparameter variations given their different natures (mainly in their text size) which were fixed across all datasets.", "labels": [], "entities": [{"text": "topic categorization and polarity detection tasks", "start_pos": 32, "end_pos": 81, "type": "TASK", "confidence": 0.7663744886716207}]}, {"text": "The embedding layer was initialized using 300-dimensional CBOW Word2vec embeddings () trained on the 3B-word UMBC WebBase corpus () with standard hyperparameters 4 . Evaluation datasets.", "labels": [], "entities": [{"text": "CBOW Word2vec embeddings", "start_pos": 58, "end_pos": 82, "type": "DATASET", "confidence": 0.7913749615351359}, {"text": "UMBC WebBase corpus", "start_pos": 109, "end_pos": 128, "type": "DATASET", "confidence": 0.9080701073010763}]}, {"text": "For the topic categorization task we used the BBC news dataset), 20News (Lang, 1995), Reuters 6 () and Ohsumed 7 . The code for this CNN implementation is the same as in (, which is available at https://github.", "labels": [], "entities": [{"text": "topic categorization", "start_pos": 8, "end_pos": 28, "type": "TASK", "confidence": 0.8144496977329254}, {"text": "BBC news dataset", "start_pos": 46, "end_pos": 62, "type": "DATASET", "confidence": 0.981381873289744}, {"text": "20News (Lang, 1995)", "start_pos": 65, "end_pos": 84, "type": "DATASET", "confidence": 0.8912382225195566}, {"text": "Reuters 6", "start_pos": 86, "end_pos": 95, "type": "DATASET", "confidence": 0.8987262547016144}]}, {"text": "com/pilehvar/sensecnn Context window of 5 words and hierarchical softmax.", "labels": [], "entities": []}, {"text": "5 http://mlg.ucd.ie/datasets/bbc.html Due to the large number of labels in the original Reuters (i.e. 91) and to be consistent with the other datasets, we reduce the dataset to its 8 most frequent labels, a reduction already performed in previous works Preprocessing.", "labels": [], "entities": [{"text": "Reuters", "start_pos": 88, "end_pos": 95, "type": "DATASET", "confidence": 0.973141610622406}, {"text": "Preprocessing", "start_pos": 253, "end_pos": 266, "type": "DATASET", "confidence": 0.818453311920166}]}, {"text": "Four different techniques (see Section 2) were used to preprocess the datasets as well as the corpus which was used to train word embeddings (i.e. UMBC).", "labels": [], "entities": []}, {"text": "For tokenization and lemmatization we relied on Stanford CoreNLP ().", "labels": [], "entities": [{"text": "tokenization", "start_pos": 4, "end_pos": 16, "type": "TASK", "confidence": 0.9855768084526062}, {"text": "Stanford CoreNLP", "start_pos": 48, "end_pos": 64, "type": "DATASET", "confidence": 0.9402427077293396}]}, {"text": "As for multiwords, we used the phrases from the pre-trained Google News Word2vec vectors, which were obtained using a simple statistical approach (Mikolov et al., 2013b).", "labels": [], "entities": [{"text": "Google News Word2vec vectors", "start_pos": 60, "end_pos": 88, "type": "DATASET", "confidence": 0.7687109187245369}]}, {"text": "12 We mapped the numerical value of phrases to either negative (from 0 to 0.4) or positive (from 0.6 to 1), removing the neutral phrases according to the scale (from 0.4 to 0.6).", "labels": [], "entities": []}, {"text": "For the datasets with train-test partitions, the sizes of the test sets are the following: 7,532 for 20News; 12,733 for Ohsumed; 25,000 for IMDb; and 1,000 for RTC.", "labels": [], "entities": [{"text": "20News", "start_pos": 101, "end_pos": 107, "type": "DATASET", "confidence": 0.9332297444343567}, {"text": "Ohsumed", "start_pos": 120, "end_pos": 127, "type": "DATASET", "confidence": 0.9678674936294556}, {"text": "RTC", "start_pos": 160, "end_pos": 163, "type": "DATASET", "confidence": 0.9299964308738708}]}, {"text": "For future work it would be interesting to explore more complex methods to learn embeddings for multiword expressions (.", "labels": [], "entities": []}, {"text": "Computed by averaging accuracy of two different runs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9788200259208679}]}, {"text": "The statistical significance was calculated according to an unpaired t-test at the 5% significance level..", "labels": [], "entities": [{"text": "significance", "start_pos": 16, "end_pos": 28, "type": "METRIC", "confidence": 0.6643637418746948}, {"text": "significance", "start_pos": 86, "end_pos": 98, "type": "METRIC", "confidence": 0.9250493049621582}]}, {"text": "This suggests that the preprocessing decisions are not so important when the training data is large enough, but they are indeed relevant in benchmarks where the training data is limited.", "labels": [], "entities": []}, {"text": "As far as the individual preprocessing techniques are concerned, the vanilla setting (tokenization only) proves to be consistent across datasets and tasks, as it performs in the same ballpark as the best result in 8 of the 9 datasets for both models (with no noticeable differences between topic categorization and polarity detection).", "labels": [], "entities": [{"text": "polarity detection", "start_pos": 315, "end_pos": 333, "type": "TASK", "confidence": 0.7289398312568665}]}, {"text": "The only topic categorization dataset in which tokenization does not seem enough is Ohsumed, which, unlike the more general nature of other categorization datasets (news), belongs to a specialized domain (medical) for which fine-grained distinctions are required to classify cardiovascular diseases.", "labels": [], "entities": [{"text": "Ohsumed", "start_pos": 84, "end_pos": 91, "type": "DATASET", "confidence": 0.6225008368492126}]}, {"text": "In particular for this dataset, word embeddings trained on a general-domain corpus like UMBC may not accurately capture the specialized meaning of medical terms and hence, sparsity becomes an issue.", "labels": [], "entities": [{"text": "UMBC", "start_pos": 88, "end_pos": 92, "type": "DATASET", "confidence": 0.931021511554718}]}, {"text": "In fact, lowercasing and lemmatizing, which are mainly aimed at reducing sparsity, outperform the vanilla setting by over six points in the CNN+LSTM setting and clearly outperform the other preprocessing techniques on the single CNN model as well.", "labels": [], "entities": [{"text": "CNN+LSTM setting", "start_pos": 140, "end_pos": 156, "type": "DATASET", "confidence": 0.8023172467947006}]}, {"text": "Nevertheless, the use of more complex preprocessing techniques such as lemmatization and multiword grouping does not help in general.", "labels": [], "entities": [{"text": "multiword grouping", "start_pos": 89, "end_pos": 107, "type": "TASK", "confidence": 0.8639610707759857}]}, {"text": "Even though lemmatization has proved useful in conventional linear models as an effective way to deal with sparsity (), neural network architectures seem to be more capable of overcoming sparsity thanks to the generalization power of word embeddings.", "labels": [], "entities": []}, {"text": "This experiment aims at studying the impact of using different word embeddings (with differently preprocessed training corpora) on tokenized datasets (vanilla setting).", "labels": [], "entities": []}, {"text": "shows the results for this experiment.", "labels": [], "entities": []}, {"text": "In this experiment we observe a different trend, with multiwordenhanced vectors exhibiting a better performance both on the single CNN model (best overall performance in seven of the nine datasets) and on the CNN+LSTM model (best performance in four datasets and in the same ballpark as the best results in four of the remaining five datasets).", "labels": [], "entities": [{"text": "CNN+LSTM model", "start_pos": 209, "end_pos": 223, "type": "DATASET", "confidence": 0.804197832942009}]}, {"text": "In this case the same set of words is learnt but single tokens inside multiword expressions are not trained.", "labels": [], "entities": []}, {"text": "Instead, these single tokens are considered in isolation only, without the added noise when considered inside the multiword expression as well.", "labels": [], "entities": []}, {"text": "For instance, the word Apple has a clearly different meaning in isolation from the one inside  the multiword expression Big Apple, hence it can be seen as beneficial not to train the word Apple when part of this multiword expression.", "labels": [], "entities": []}, {"text": "Interestingly, using multiword-wise embeddings on the vanilla setting leads to consistently better results than using them on the same multiwordgrouped preprocessed dataset in eight of the nine datasets.", "labels": [], "entities": []}, {"text": "This could provide hints on the excellent results provided by pre-trained Word2vec embeddings trained on the Google News corpus, which learns multiwords similarly to our setting.", "labels": [], "entities": [{"text": "Google News corpus", "start_pos": 109, "end_pos": 127, "type": "DATASET", "confidence": 0.840110182762146}]}, {"text": "Apart from this somewhat surprising finding, the use of the embeddings trained on a simple tokenized corpus (i.e. vanilla) proved again competitive, as different preprocessing techniques such as lowercasing and lemmatizing do not seem to help.", "labels": [], "entities": []}, {"text": "In fact, the relatively weaker performance of lemmatization and lowercasing in this crossprocessing experiment is somehow expected as the coverage of word embeddings in vanilla-tokenized datasets is limited, e.g., many entities which are capitalized in the datasets are not covered in the case of lowercasing, and inflected forms are missing in the case of lemmatizing.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Evaluation datasets for topic categoriza- tion and polarity detection.", "labels": [], "entities": [{"text": "polarity detection", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.7101468592882156}]}, {"text": " Table 2: Accuracy on the topic categorization and polarity detection tasks using various preprocessing  techniques for the CNN and CNN+LSTM models.  \u2020 indicates results that are statistically significant with  respect to the top result.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9758769273757935}, {"text": "polarity detection", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.7065984308719635}, {"text": "CNN", "start_pos": 124, "end_pos": 127, "type": "DATASET", "confidence": 0.9334388971328735}, {"text": "CNN+LSTM", "start_pos": 132, "end_pos": 140, "type": "DATASET", "confidence": 0.7586238185564677}]}, {"text": " Table 3: Cross-preprocessing evaluation: accuracy on the topic categorization and polarity detection  tasks using different sets of word embeddings to initialize the embedding layer of the two classifiers.  All datasets were preprocessed similarly according to the vanilla setting.  \u2020 indicates results that are  statistically significant with respect to the top result.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9991843104362488}, {"text": "polarity detection", "start_pos": 83, "end_pos": 101, "type": "TASK", "confidence": 0.7184503972530365}]}]}