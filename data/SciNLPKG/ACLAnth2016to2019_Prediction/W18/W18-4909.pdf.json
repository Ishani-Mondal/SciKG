{"title": [{"text": "Fine-Grained Termhood Prediction for German Compound Terms Using Neural Networks", "labels": [], "entities": []}], "abstractContent": [{"text": "Automatic term identification and investigating the understandability of terms in a specialized domain are often treated as two separate lines of research.", "labels": [], "entities": [{"text": "term identification", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.7099005579948425}]}, {"text": "We propose a combined approach for this matter, by defining fine-grained classes of termhood and framing a classification task.", "labels": [], "entities": []}, {"text": "The classes reflect tiers of a term's association to a domain.", "labels": [], "entities": []}, {"text": "The new setup is applied to Ger-man closed compounds as term candidates in the domain of cooking.", "labels": [], "entities": []}, {"text": "For the prediction of the classes, we compare several neural network architectures and also take salient information about the compounds' components into account.", "labels": [], "entities": []}, {"text": "We show that applying a similar class distinction to the compounds' components and propagating this information within the network improves the compound class prediction results.", "labels": [], "entities": [{"text": "compound class prediction", "start_pos": 144, "end_pos": 169, "type": "TASK", "confidence": 0.6081418593724569}]}], "introductionContent": [{"text": "DOMAIN-SPECIFIC TERMS are linguistic expressions which characterize a domain, and the automatic recognition of terms is an important basis for further NLP tasks, such as thesaurus creation, automatic translation, and, more generally, for domain knowledge acquisition and for improving the comprehension of a domain.", "labels": [], "entities": [{"text": "DOMAIN-SPECIFIC", "start_pos": 0, "end_pos": 15, "type": "DATASET", "confidence": 0.4366842210292816}, {"text": "TERMS", "start_pos": 16, "end_pos": 21, "type": "METRIC", "confidence": 0.47815701365470886}, {"text": "thesaurus creation", "start_pos": 170, "end_pos": 188, "type": "TASK", "confidence": 0.7730177044868469}, {"text": "automatic translation", "start_pos": 190, "end_pos": 211, "type": "TASK", "confidence": 0.6618753671646118}, {"text": "domain knowledge acquisition", "start_pos": 238, "end_pos": 266, "type": "TASK", "confidence": 0.631282220284144}]}, {"text": "Automatic term recognition often comprises two steps: to evaluate a term candidate for its unithood, i.e. identifying boundaries of meaningful phrases, and then to evaluate its termhood, i.e. determining the degree of association to a specific domain (.", "labels": [], "entities": [{"text": "Automatic term recognition", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6718717018763224}]}, {"text": "A related task to term recognition is the identification of domain terms unfamiliar to non-experts, i.e., identifying terms the average reader does not understand.", "labels": [], "entities": [{"text": "term recognition", "start_pos": 18, "end_pos": 34, "type": "TASK", "confidence": 0.8818699419498444}, {"text": "identification of domain terms unfamiliar", "start_pos": 42, "end_pos": 83, "type": "TASK", "confidence": 0.8130150437355042}]}, {"text": "This technology is mostly applied to the health domain, such as medical terms extracted to improve the communication between doctors and patients.", "labels": [], "entities": []}, {"text": "The evaluated terms are mostly extracted from medical terminologies).", "labels": [], "entities": []}, {"text": "Since these terminologies are available, what constitutes a term can often betaken as a given.", "labels": [], "entities": []}, {"text": "However, difficult terms occur in other domains as well, and huge terminologies are not always available.", "labels": [], "entities": []}, {"text": "In this work, we make a first attempt to combine the two tasks of automatic term recognition and term difficulty identification by reformulating them as one problem considering different tiers of termhood.", "labels": [], "entities": [{"text": "term recognition", "start_pos": 76, "end_pos": 92, "type": "TASK", "confidence": 0.7928038835525513}, {"text": "term difficulty identification", "start_pos": 97, "end_pos": 127, "type": "TASK", "confidence": 0.7128725449244181}]}, {"text": "In our proposal, we define four classes of termhood, which range from general-language words to obscure, domain-specific terms.", "labels": [], "entities": []}, {"text": "This replaces the concept of termhood treated as a binary problem often seen in term annotation () and identification tasks (;.", "labels": [], "entities": []}, {"text": "We demonstrate the effectiveness of our tier system by first conducting an annotation task, followed by an automatic classification using neural networks tailored for our task.", "labels": [], "entities": []}, {"text": "In this work, we focus on the cooking domain and the German language.", "labels": [], "entities": []}, {"text": "As a basis for the experiments, 400 German closed compounds are taken as term candidates.", "labels": [], "entities": []}, {"text": "We focus on closed compounds for the following reasons: Closed compounds are complex expressions that consist of two or more simple words and contain no spaces or hyphens, e.g. Meeresfr\u00fcchte \"seafood\".", "labels": [], "entities": []}, {"text": "In German, closed compounds area common way and highly productive way of creating multi-word expressions.", "labels": [], "entities": []}, {"text": "Since most terms are usually longer than one word - find that terms most frequently have a length of two words -closed compounds represent a large proportion of German terms.", "labels": [], "entities": []}, {"text": "Furthermore, unithood of closed compound term candidates does not have to be evaluated, since the components are naturally agglutinated and phrase boundaries are evident (in contrast to other multi-word expressions).", "labels": [], "entities": []}, {"text": "Instead, compound splitting is required, and the split points are relatively obvious to native speakers, while detecting unithood is not.", "labels": [], "entities": [{"text": "compound splitting", "start_pos": 9, "end_pos": 27, "type": "TASK", "confidence": 0.6693405956029892}]}, {"text": "Another advantage of taking compounds as a basis here is that by addressing complex phrases we can illustrate and exploit the interplay between the termhood tiers of the compounds and their components.", "labels": [], "entities": []}, {"text": "To address the fine-grained termhood prediction of German compound terms, we design a system with three steps: (i) performing compound splitting, (ii) computing features for the compounds and their components, and (iii) applying neural network classifiers to predict the termhood classes.", "labels": [], "entities": [{"text": "termhood prediction of German compound terms", "start_pos": 28, "end_pos": 72, "type": "TASK", "confidence": 0.8135427633921305}, {"text": "compound splitting", "start_pos": 126, "end_pos": 144, "type": "TASK", "confidence": 0.70560123026371}]}, {"text": "For the neural classifiers, we first adapt the network to German compound words so that it takes information about the components into account.", "labels": [], "entities": []}, {"text": "As a second step, we apply a corresponding termhood tier distinction to the compounds' components which further improves the compound class prediction results.", "labels": [], "entities": [{"text": "compound class prediction", "start_pos": 125, "end_pos": 150, "type": "TASK", "confidence": 0.607667068640391}]}, {"text": "The paper is structured as following: Section 2 describes related work for terminology identification.", "labels": [], "entities": [{"text": "terminology identification", "start_pos": 75, "end_pos": 101, "type": "TASK", "confidence": 0.9612720012664795}]}, {"text": "We illustrate the problem in Section 3 and define the termhood classes.", "labels": [], "entities": []}, {"text": "In Section 4, the model for term class prediction is introduced.", "labels": [], "entities": [{"text": "term class prediction", "start_pos": 28, "end_pos": 49, "type": "TASK", "confidence": 0.672242651383082}]}, {"text": "Section 5 explains the data annotation and evaluation.", "labels": [], "entities": []}, {"text": "In Section 6, results are presented and discussed.", "labels": [], "entities": []}, {"text": "We conclude in Section 7.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Number of annotated terms per class.", "labels": [], "entities": []}, {"text": " Table 3: Splitting performances of the three compound splitters.", "labels": [], "entities": [{"text": "Splitting", "start_pos": 10, "end_pos": 19, "type": "TASK", "confidence": 0.9929693341255188}, {"text": "compound splitters", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.7605350613594055}]}, {"text": " Table 4: Results for baselines and advanced models per class.", "labels": [], "entities": []}]}