{"title": [{"text": "Treat the system like a human student: Automatic naturalness evaluation of generated text without reference texts", "labels": [], "entities": []}], "abstractContent": [{"text": "The current most popular method for automatic Natural Language Generation (NLG) evaluation is comparing generated text with human-written reference sentences using a metrics system, which has drawbacks around reliability and scalabil-ity.", "labels": [], "entities": [{"text": "automatic Natural Language Generation (NLG) evaluation", "start_pos": 36, "end_pos": 90, "type": "TASK", "confidence": 0.814424566924572}, {"text": "reliability", "start_pos": 209, "end_pos": 220, "type": "METRIC", "confidence": 0.9795007705688477}]}, {"text": "We draw inspiration from second language (L2) assessment and extract a set of linguistic features to predict human judgments of sentence naturalness.", "labels": [], "entities": []}, {"text": "Our experiment using a small dataset showed that the feature-based approach yields promising results, with the added potential of providing interpretability into the source of the problems.", "labels": [], "entities": []}], "introductionContent": [{"text": "More and more text is generated in Machine Translation, Text Summarization, Image Captioning, and Dialogue Systems.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 35, "end_pos": 54, "type": "TASK", "confidence": 0.764031857252121}, {"text": "Text Summarization", "start_pos": 56, "end_pos": 74, "type": "TASK", "confidence": 0.7819271385669708}, {"text": "Image Captioning", "start_pos": 76, "end_pos": 92, "type": "TASK", "confidence": 0.7630796134471893}]}, {"text": "With this increased usage of Natural Language Generation (NLG) comes an increase in the importance of evaluating the language generated, and an increase in the difficulty of doing so as the quantity and variety of output increases.", "labels": [], "entities": [{"text": "Natural Language Generation (NLG)", "start_pos": 29, "end_pos": 62, "type": "TASK", "confidence": 0.8111307124296824}]}, {"text": "Automatic NLG evaluation focuses on two areas: accuracy and fluency.", "labels": [], "entities": [{"text": "NLG evaluation", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.7989338934421539}, {"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9992645382881165}]}, {"text": "The former assesses how well the generated text conveys the desired meaning, while the latter assesses how well the language flows: the 'linguistic quality of the text' ( and whether it sounds like something a native speaker of the language would naturally produce.", "labels": [], "entities": []}, {"text": "This paper focuses on the latter.", "labels": [], "entities": []}, {"text": "We first review current approaches in metrics-based evaluation, in referenceless evaluation and in second language (L2) language assessment; we then present our experiment in section 3.", "labels": [], "entities": [{"text": "second language (L2) language assessment", "start_pos": 99, "end_pos": 139, "type": "TASK", "confidence": 0.6408179913248334}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Feature list. Highest contribution features indicated by *", "labels": [], "entities": []}, {"text": " Table 2: Results of baselines, top two feature-based classifiers and models using subset of features.", "labels": [], "entities": []}, {"text": " Table 3: E2E NLG Challenge data: Spearman's \u21e2 for mean  fluency and grammaticality human judgments (model trained  on E2E task data).", "labels": [], "entities": [{"text": "E2E NLG Challenge data", "start_pos": 10, "end_pos": 32, "type": "DATASET", "confidence": 0.896208256483078}, {"text": "E2E task data", "start_pos": 119, "end_pos": 132, "type": "DATASET", "confidence": 0.726827601591746}]}, {"text": " Table 4: WebNLG Challenge data: Spearman's \u21e2 correla- tion with mean fluency and grammaticality human judgments  (model trained on WebNLG task data). All p <0.001", "labels": [], "entities": [{"text": "WebNLG Challenge data", "start_pos": 10, "end_pos": 31, "type": "DATASET", "confidence": 0.8538431723912557}, {"text": "WebNLG task data", "start_pos": 132, "end_pos": 148, "type": "DATASET", "confidence": 0.8258423010508219}]}]}