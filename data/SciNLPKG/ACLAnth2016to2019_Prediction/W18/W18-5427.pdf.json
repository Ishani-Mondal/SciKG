{"title": [{"text": "Iterative Recursive Attention Model for Interpretable Sequence Classification", "labels": [], "entities": [{"text": "Interpretable Sequence Classification", "start_pos": 40, "end_pos": 77, "type": "TASK", "confidence": 0.6518178582191467}]}], "abstractContent": [{"text": "Natural language processing has greatly benefited from the introduction of the attention mechanism.", "labels": [], "entities": [{"text": "Natural language processing", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6602049867312113}]}, {"text": "However, standard attention models are of limited interpretability for tasks that involve a series of inference steps.", "labels": [], "entities": []}, {"text": "We describe an iterative recursive attention model, which constructs incremental representations of input data through reusing results of previously computed queries.", "labels": [], "entities": []}, {"text": "We train our model on sentiment classification datasets and demonstrate its capacity to identify and combine different aspects of the input in an easily interpretable manner, while obtaining performance close to the state of the art.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 22, "end_pos": 46, "type": "TASK", "confidence": 0.8748275339603424}]}], "introductionContent": [{"text": "The introduction of the attention mechanism () offered away to demystify the inference process of neural models.", "labels": [], "entities": []}, {"text": "By assigning scalar weights to different elements of the input, we are able to visualize and potentially understand why the model made the decision it made, or discover a deficiency in the model by tracing down a relevant aspect of the input being overlooked by the model.", "labels": [], "entities": []}, {"text": "Specifically in natural language processing (NLP), which abounds with variable-length word sequence classification tasks, attention alleviates the issue of learning long-term dependencies in recurrent neural networks by offering the model a glimpse into previously processed tokens.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 16, "end_pos": 49, "type": "TASK", "confidence": 0.8077381650606791}, {"text": "word sequence classification tasks", "start_pos": 86, "end_pos": 120, "type": "TASK", "confidence": 0.7846200913190842}]}, {"text": "Attention offers a good retrospective explanation of the classification decision by indicating what parts of the input contributed the most to the decision.", "labels": [], "entities": []}, {"text": "However, in many cases the final decision is best interpreted as a result of a series of inference steps, each of which can potentially affect its polarity.", "labels": [], "entities": []}, {"text": "A casein point is sentiment analysis, in which contrastive clauses and negations act as polarity switches of the overall sentence sentiment.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.9577627778053284}]}, {"text": "In such cases, attention will only point to the part of the input sentence whose polarity matches that of the final decision.", "labels": [], "entities": []}, {"text": "However, unfolding the inference process of a model into a series of interpretable steps would make the model more interpretable and allow one to identify its shortcomings.", "labels": [], "entities": []}, {"text": "As a step toward that goal, we propose an extension of the iterative attention mechanism (, which we call the iterative recursive attention model (IRAM), where the result of an attentive query is nonlinearly transformed and then added to the set of vector representations of the input sequence.", "labels": [], "entities": []}, {"text": "The nonlinear transformation, along with reusing the representations obtained in previous steps, allows the model to construct a recursive representation and process the input sequence bit by bit.", "labels": [], "entities": []}, {"text": "The upshot is that we can inspect how the model weighs the different parts of the sentence and recursively combines them to give the final decision.", "labels": [], "entities": []}, {"text": "We test the model on two sentiment analysis tasks and demonstrate its capacity to isolate different task-related aspects of the input, while reaching performance comparable with the state of the art.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.9327519237995148}]}], "datasetContent": [{"text": "We test IRAM on two sentiment classification datasets.", "labels": [], "entities": [{"text": "IRAM", "start_pos": 8, "end_pos": 12, "type": "TASK", "confidence": 0.9273697137832642}, {"text": "sentiment classification", "start_pos": 20, "end_pos": 44, "type": "TASK", "confidence": 0.8326224982738495}]}, {"text": "The first is the Stanford Sentiment Treebank (SST)), a dataset derived from movie reviews on Rotten Tomatoes and containing 11,855 sentences labeled into five classes at the sentence level and at the level of each node in the constituency parse tree.", "labels": [], "entities": [{"text": "Stanford Sentiment Treebank (SST))", "start_pos": 17, "end_pos": 51, "type": "DATASET", "confidence": 0.8148727466662725}]}, {"text": "The binary version with the neutral class removed contains 56,400 instances, while the fine-grained version with scores ranging from 1 (very negative) to 5 (very positive) contains 94,200 text-sentiment pairs.", "labels": [], "entities": []}, {"text": "Unless stated otherwise, all weights are initialized from a Gaussian distribution with zero mean and standard deviation of 0.01.", "labels": [], "entities": []}, {"text": "We use the Adam optimizer () with the AmsGrad modification () and \u03b1 = 0.0003.", "labels": [], "entities": []}, {"text": "We clip the global norm of the gradients to 1.0 and set weight decay to 0.00003.", "labels": [], "entities": [{"text": "weight decay", "start_pos": 56, "end_pos": 68, "type": "METRIC", "confidence": 0.8938375413417816}]}, {"text": "We use 300-dimensional GloVe word embeddings trained on the Common Crawl corpus and 100-dimensional character embeddings.", "labels": [], "entities": [{"text": "Common Crawl corpus", "start_pos": 60, "end_pos": 79, "type": "DATASET", "confidence": 0.9286185105641683}]}, {"text": "We follow the recommendation of and standardize the embeddings.", "labels": [], "entities": []}, {"text": "Dropout of 0.1 is applied to the word embedding matrix.", "labels": [], "entities": []}, {"text": "For both datasets, we set l ctx = 2 and l query = 1.", "labels": [], "entities": []}, {"text": "The highway network for fine-tuning the input embeddings has two layers, while the ones fine-tuning the query and the summary have a single layer.", "labels": [], "entities": []}, {"text": "All highway networks' gate biases are initialized to 1, as recommended by, as well as the biases of the LSTM forget gates.", "labels": [], "entities": []}, {"text": "The maxout network uses two 200-dimensional layers with a pool size of 4.", "labels": [], "entities": []}, {"text": "Throughout our experiments, we have experimented with selecting the batch size from {32, 64}, dropout for the recurrent layers and the maxout classifier from {0.1, 0.2, 0.3, 0.4}, and the LSTM hidden state size from {400, 500, 1000}.", "labels": [], "entities": []}, {"text": "The word and character n-gram vectors are kept fixed for SST but are learned for the IMDb dataset.", "labels": [], "entities": [{"text": "SST", "start_pos": 57, "end_pos": 60, "type": "TASK", "confidence": 0.9908022284507751}, {"text": "IMDb dataset", "start_pos": 85, "end_pos": 97, "type": "DATASET", "confidence": 0.9760282933712006}]}, {"text": "These parameters are optimized using cross-validation, and the best configuration is ran on the test set.", "labels": [], "entities": []}, {"text": "As IMDb has no official validation set, we randomly select 10% of the dataset and use it for all of the experiments.", "labels": [], "entities": [{"text": "IMDb", "start_pos": 3, "end_pos": 7, "type": "DATASET", "confidence": 0.9380604028701782}]}, {"text": "The values of other hyperparameters were selected through inexhaustive search.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Classification accuracy on the test sets", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9338364601135254}, {"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9769954681396484}]}]}