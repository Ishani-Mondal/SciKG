{"title": [], "abstractContent": [{"text": "Discourse analysis is necessary for different tasks of Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "Discourse analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8079815804958344}, {"text": "Natural Language Processing (NLP)", "start_pos": 55, "end_pos": 88, "type": "TASK", "confidence": 0.7480215628941854}]}, {"text": "As two of the most spoken languages in the world, discourse analysis between Spanish and Chinese is important for NLP research.", "labels": [], "entities": [{"text": "discourse analysis between Spanish and Chinese", "start_pos": 50, "end_pos": 96, "type": "TASK", "confidence": 0.81825090944767}]}, {"text": "This paper aims to present the first open Spanish-Chinese parallel corpus annotated with discourse information, whose theoretical framework is based on the Rhetorical Structure Theory (RST).", "labels": [], "entities": [{"text": "Rhetorical Structure Theory (RST)", "start_pos": 156, "end_pos": 189, "type": "TASK", "confidence": 0.6923860112826029}]}, {"text": "We have evaluated and harmonized each annotation part to obtain a high annotated-quality corpus.", "labels": [], "entities": []}, {"text": "The corpus is already available to the public.", "labels": [], "entities": []}], "introductionContent": [{"text": "Spanish and Chinese are two of the most spoken languages in the world; the language pair occupies an important position in the Natural Language Processing (NLP) research world.", "labels": [], "entities": []}, {"text": "Recently, discourse analysis has called much attention as an unsolved problem and is crucial for many NLP tasks ().", "labels": [], "entities": [{"text": "discourse analysis", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.824601024389267}]}, {"text": "The great language distance causes a great number of discourse differences between Spanish and Chinese.", "labels": [], "entities": []}, {"text": "Comparative or contrastive studies of discourse structures reveal information to identify properly equivalent discourse elements in a language pair.", "labels": [], "entities": []}, {"text": "Here we give an example to show the discourse similarity and difference between the two languages.", "labels": [], "entities": []}, {"text": "Ex.1 1 : 1.1 Sp: Aunque a\u00fan no contamos con resultados, intuimos que el modelo ser\u00e1 m\u00e1s amplio que el del sintagma nominal.", "labels": [], "entities": []}, {"text": "[. DMs are used to signal discourse relations in a text segment.", "labels": [], "entities": []}, {"text": "Specially, the DMs in our work are traditional markers and markers including verbal structures, as da Cunha indicates.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this annotation level, we use Cohen Kappa to measure inter-annotator agreement of the segmented discourse units . Kappa calculates the agreement between annotators as: \ud97b\udf59 r \ud97b\udf59nno t \ud97b\udf59nio \ud97b\udf59 t \ud97b\udf59nio where (A) represents the current observed agreement, and P(E) represents chance agreement.", "labels": [], "entities": []}, {"text": "Kappa was calculated by considering titles, parentheses, and verbs, as EDUs candidates.", "labels": [], "entities": [{"text": "Kappa", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.8912437558174133}]}, {"text": "includes the agreement between the annotators for the Spanish subcorpus and the Chinese subcorpus., we can see that, for the Spanish subcorpus, the highest agreement between the annotators is 0.945, and the lowest agreement is 0.716.", "labels": [], "entities": []}, {"text": "The agreement for the whole Spanish subcorpus is 0.87.", "labels": [], "entities": [{"text": "Spanish subcorpus", "start_pos": 28, "end_pos": 45, "type": "DATASET", "confidence": 0.9408912658691406}]}, {"text": "The highest agreement result for the Chinese subcorpus is 0.815, and the lowest agreement result is 0.616.", "labels": [], "entities": [{"text": "agreement result", "start_pos": 12, "end_pos": 28, "type": "METRIC", "confidence": 0.9781721234321594}, {"text": "Chinese subcorpus", "start_pos": 37, "end_pos": 54, "type": "DATASET", "confidence": 0.9505498707294464}, {"text": "agreement result", "start_pos": 80, "end_pos": 96, "type": "METRIC", "confidence": 0.9678019285202026}]}, {"text": "The agreement for the entire Chinese subcorpus is 0.76.", "labels": [], "entities": [{"text": "Chinese subcorpus", "start_pos": 29, "end_pos": 46, "type": "DATASET", "confidence": 0.9437877833843231}]}, {"text": "The annotation results prove the segmentation criteria are reliable for the language pair.", "labels": [], "entities": []}, {"text": "Based on the results, we analyze the segmentation errors to improve the segmentation annotation quality.", "labels": [], "entities": []}, {"text": "Same as the segmentation evaluation, we also use Kappa to measure the CU annotation agreement for exact match.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 12, "end_pos": 24, "type": "TASK", "confidence": 0.9854511022567749}]}, {"text": "shows the evaluation results of the Spanish subcorpus and reflects the agreement of the Chinese subcorpus.", "labels": [], "entities": [{"text": "Spanish subcorpus", "start_pos": 36, "end_pos": 53, "type": "DATASET", "confidence": 0.9245421886444092}, {"text": "Chinese subcorpus", "start_pos": 88, "end_pos": 105, "type": "DATASET", "confidence": 0.8555912971496582}]}, {"text": "From, we can see that for the Spanish subcorpus, the agreement is 0.961 and the agreement is 0.977 for the Chinese subcorpus (see).", "labels": [], "entities": [{"text": "Spanish subcorpus", "start_pos": 30, "end_pos": 47, "type": "DATASET", "confidence": 0.8839901685714722}, {"text": "Chinese subcorpus", "start_pos": 107, "end_pos": 124, "type": "DATASET", "confidence": 0.9134686589241028}]}, {"text": "The results show that the CU annotation for the whole corpus is almost perfect.", "labels": [], "entities": []}, {"text": "For all the annotation steps, the Spanish-Chinese bilingual annotator is assigned as A1, the two Spanish annotators are assigned as A2 (considering as one annotator) and the Chinese annotator is assigned as A3.", "labels": [], "entities": [{"text": "A2", "start_pos": 132, "end_pos": 134, "type": "METRIC", "confidence": 0.9855279326438904}]}, {"text": "The agreement are measured between A1 and A2, A1 and A3.", "labels": [], "entities": [{"text": "A1", "start_pos": 35, "end_pos": 37, "type": "METRIC", "confidence": 0.9828168153762817}, {"text": "A2", "start_pos": 42, "end_pos": 44, "type": "METRIC", "confidence": 0.8884060382843018}, {"text": "A1", "start_pos": 46, "end_pos": 48, "type": "METRIC", "confidence": 0.9870943427085876}, {"text": "A3", "start_pos": 53, "end_pos": 55, "type": "DATASET", "confidence": 0.6212069392204285}]}, {"text": "For the discourse structure annotation evaluation, we follow a newly created qualitative method by Iruskieta, da.", "labels": [], "entities": [{"text": "discourse structure annotation evaluation", "start_pos": 8, "end_pos": 49, "type": "TASK", "confidence": 0.6712098568677902}]}, {"text": "Under this qualitative method, four elements are being examined by using F-measure: Nuclearity (N), Relation (R), Composition (C) and Attachment (A).", "labels": [], "entities": [{"text": "F-measure", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9758228063583374}, {"text": "Relation (R)", "start_pos": 100, "end_pos": 112, "type": "METRIC", "confidence": 0.9328552782535553}, {"text": "Attachment (A)", "start_pos": 134, "end_pos": 148, "type": "METRIC", "confidence": 0.95729960501194}]}, {"text": "In addition, to use this method for the discourse evaluation between two or more languages, the comparison parts must be aligned and must contain the same number of EDUs, to avoid confusing analysis disagreement and segmentation disagreement.", "labels": [], "entities": []}, {"text": "The following example explains how we follow this comparison rule by using our corpus:", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Statistical information of EDUs and CUs in the corpus", "labels": [], "entities": []}, {"text": " Table 4: Segmentation annotation agreement of the entire corpus", "labels": [], "entities": [{"text": "Segmentation annotation agreement", "start_pos": 10, "end_pos": 43, "type": "TASK", "confidence": 0.8529211680094401}]}, {"text": " Table 5: CU annotation evaluation result of the Spanish subcorpus", "labels": [], "entities": [{"text": "Spanish subcorpus", "start_pos": 49, "end_pos": 66, "type": "DATASET", "confidence": 0.9117042720317841}]}, {"text": " Table 6: CU annotation evaluation result of the Chinese subcorpus", "labels": [], "entities": [{"text": "Chinese subcorpus", "start_pos": 49, "end_pos": 66, "type": "DATASET", "confidence": 0.9159997403621674}]}, {"text": " Table 7: Qualitative evaluation of the Spanish annotation and Chinese annotation", "labels": [], "entities": []}]}