{"title": [{"text": "Extraction Meets Abstraction: Ideal Answer Generation for Biomedical Questions", "labels": [], "entities": [{"text": "Extraction Meets Abstraction", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8851548234621683}, {"text": "Ideal Answer Generation", "start_pos": 30, "end_pos": 53, "type": "TASK", "confidence": 0.8888689875602722}]}], "abstractContent": [{"text": "The growing number of biomedical publications is a challenge for human researchers, who invest considerable effort to search for relevant documents and pinpointed answers.", "labels": [], "entities": []}, {"text": "Biomedical Question Answering can automatically generate answers fora user's topic or question, significantly reducing the effort required to locate the most relevant information in a large document corpus.", "labels": [], "entities": [{"text": "Biomedical Question Answering", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8153366645177206}]}, {"text": "Extractive sum-marization techniques, which concatenate the most relevant text units drawn from multiple documents, perform well on automatic evaluation metrics like ROUGE, but score poorly on human readability, due to the presence of redundant text and grammatical errors in the answer.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 166, "end_pos": 171, "type": "METRIC", "confidence": 0.9077402353286743}]}, {"text": "This work moves toward abstractive summarization, which attempts to distill and present the meaning of the original text in a more coherent way.", "labels": [], "entities": [{"text": "abstractive summarization", "start_pos": 23, "end_pos": 48, "type": "TASK", "confidence": 0.5084949731826782}]}, {"text": "We incorporate a sentence fusion approach, based on Integer Linear Programming, along with three novel approaches for sentence ordering, in an attempt to improve the human readability of ideal answers.", "labels": [], "entities": [{"text": "sentence fusion", "start_pos": 17, "end_pos": 32, "type": "TASK", "confidence": 0.7472571432590485}, {"text": "sentence ordering", "start_pos": 118, "end_pos": 135, "type": "TASK", "confidence": 0.7388429343700409}]}, {"text": "Using an open framework for configuration space exploration (BOOM), we tested over 2000 unique system configurations in order to identify the best-performing combinations for the sixth edition of Phase B of the BioASQ challenge.", "labels": [], "entities": [{"text": "configuration space exploration (BOOM)", "start_pos": 28, "end_pos": 66, "type": "TASK", "confidence": 0.7569284240404764}]}], "introductionContent": [{"text": "Human researchers invest considerable effort when searching very large text corpora for answers to their questions.", "labels": [], "entities": []}, {"text": "Existing search engines like PubMed () only partially address this need, since they return relevant documents but do not provide a direct answer for the user's question.", "labels": [], "entities": []}, {"text": "The process of filtering and combine information from relevant documents to obtain an ideal answer is still time consuming.", "labels": [], "entities": []}, {"text": "Biomedical Question Answering (BQA) systems can automatically generate ideal answers fora user's question, signif- * denotes equal contribution icantly reducing the effort required to locate the most relevant information in a large corpus.", "labels": [], "entities": [{"text": "Biomedical Question Answering (BQA)", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.7448159356911978}]}, {"text": "Our goal is to build an effective BQA system to generate coherent, query-oriented, non-redundant, human-readable summaries for biomedical questions.", "labels": [], "entities": []}, {"text": "Our approach is based on an extractive BQA system () which performed well on automatic metrics (ROUGE) in the 5th edition of the BioASQ challenge.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 96, "end_pos": 101, "type": "METRIC", "confidence": 0.6157046556472778}]}, {"text": "However, owing to the extractive nature of this system, it suffers from problems inhuman readability and coherence.", "labels": [], "entities": []}, {"text": "In particular, extractive summaries which concatenate the most relevant text units from multiple documents are often incoherent to the reader, especially when the answer sentences jump back and forth between topics.", "labels": [], "entities": []}, {"text": "Although the existing extractive approach explicitly attempts to reduce redundancy at the sentence level (via SoftMMR), stitching together existing sentences always admits the possibility of redundant text at the phrase level.", "labels": [], "entities": []}, {"text": "We improve upon the baseline extractive system in 3 ways: (1) re-ordering the sentences that are selected by the extractive algorithm; (2) fusing words and sentences to form a more humanireadable summary; and (3) using automatic methods to explore a much larger space of system configurations and hyperparameter values when optimizing system performance.", "labels": [], "entities": []}, {"text": "We hypothesize that the first two techniques will improve the coherence and human readability, while the third technique provides an efficient framework for tuning these approaches in order to maximize automatic evaluation (ROUGE) scores.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Manual evaluation of sentence ordering", "labels": [], "entities": [{"text": "sentence ordering", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.7258794456720352}]}, {"text": " Table 2: Performance of different module combinations on Test Batch 4, BioASQ 4th edition.", "labels": [], "entities": [{"text": "BioASQ 4th edition", "start_pos": 72, "end_pos": 90, "type": "DATASET", "confidence": 0.90518186489741}]}]}