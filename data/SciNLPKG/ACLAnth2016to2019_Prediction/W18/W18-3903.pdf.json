{"title": [{"text": "A High Coverage Method for Automatic False Friends Detection for Spanish and Portuguese", "labels": [], "entities": [{"text": "False Friends Detection", "start_pos": 37, "end_pos": 60, "type": "TASK", "confidence": 0.7420536279678345}]}], "abstractContent": [{"text": "False friends are words in two languages that look or sound similar, but have different meanings.", "labels": [], "entities": []}, {"text": "They area common source of confusion among language learners.", "labels": [], "entities": []}, {"text": "Methods to detect them automatically do exist, however they make use of large aligned bilingual corpora, which are hard to find and expensive to build, or encounter problems dealing with infrequent words.", "labels": [], "entities": []}, {"text": "In this work we propose a high coverage method that uses word vector representations to build a false friends classifier for any pair of languages, which we apply to the particular case of Spanish and Portuguese.", "labels": [], "entities": []}, {"text": "The required resources area large corpus for each language and a small bilingual lexicon for the pair.", "labels": [], "entities": []}], "introductionContent": [{"text": "Closely related languages often share a significant number of similar words which may have different meanings in each language.", "labels": [], "entities": []}, {"text": "Similar words with different meanings are called false friends, while similar words sharing meaning are called cognates.", "labels": [], "entities": []}, {"text": "For instance, between Spanish and Portuguese, the amount of cognates reaches the 85% of the total vocabulary.", "labels": [], "entities": []}, {"text": "This fact represents a clear advantage for language learners, but it may also lead to an important number of interferences, since similar words will be interpreted as in the native language, which is not correct in the case of false friends.", "labels": [], "entities": []}, {"text": "Generally, the expression false friends refers not only to pairs of identical words, but also to pairs of similar words, differing in a few characters.", "labels": [], "entities": []}, {"text": "Thus, the Spanish verb halagar (\"to flatten\") and the similar Portuguese verb alagar (\"to flood\") are usually considered false friends.", "labels": [], "entities": []}, {"text": "Besides traditional false friends, that are similar words with different meanings, analyses three more types.", "labels": [], "entities": []}, {"text": "First, he mentions words with similar meanings but used in different contexts, as esclarecer, which is used in a few contexts in Spanish (esclarecer un crimen, \"clarify a crime\"), but not in other contexts where aclarar is used (aclarar una duda, \"clarify a doubt\"), while in Portuguese esclarecer is used in all these contexts.", "labels": [], "entities": []}, {"text": "Secondly, there are similar words with partial meaning differences, as abrigo, which in Spanish means \"shelter\" and \"coat\", but in Portuguese has just the first meaning.", "labels": [], "entities": []}, {"text": "Finally, Humbl\u00e9 (2006) also considers false friends as similar words with the same meaning but used in different syntactic structures in each language, as the Spanish verb hablar (\"to speak\"), which does not accept a sentential direct object, and its Portuguese equivalent falar, which does (*yo habl\u00e9 que . .", "labels": [], "entities": []}, {"text": "/ eu falei que . .", "labels": [], "entities": []}, {"text": ", *\"I spoke that . .", "labels": [], "entities": []}, {"text": "These non-traditional false friends are more difficult to detect by language learners than traditional ones, because of their subtle differences.", "labels": [], "entities": []}, {"text": "Having a list of false friends can help native speakers of one language to avoid confusion when speaking and writing in the other language.", "labels": [], "entities": []}, {"text": "Such a list could be integrated into a writing assistant to prevent the writer when using these words.", "labels": [], "entities": []}, {"text": "For Spanish/Portuguese, in particular, while there are printed dictionaries that compile false friends), we did not find a complete digital false friends list, therefore, an automatic method for false friends detection would be useful.", "labels": [], "entities": [{"text": "false friends detection", "start_pos": 195, "end_pos": 218, "type": "TASK", "confidence": 0.7067873080571493}]}, {"text": "Furthermore, it is interesting to study methods which could generate false friends lists for any pair of similar languages, particularly, languages for which this phenomenon has not been studied.", "labels": [], "entities": []}, {"text": "In this work we present an automatic method for false friends detection.", "labels": [], "entities": [{"text": "false friends detection", "start_pos": 48, "end_pos": 71, "type": "TASK", "confidence": 0.6721713642279307}]}, {"text": "We focus on the traditional false friends definition (similar words with different meanings) because of the dataset we count with and also to present our method in a simple context.", "labels": [], "entities": []}, {"text": "We describe a supervised classifier we constructed to distinguish false friends from cognates based on word embeddings.", "labels": [], "entities": []}, {"text": "Although for the method development and evaluation we used Spanish and Portuguese, the method could be applied to other language pairs, provided that the resources needed for the method building are available.", "labels": [], "entities": []}, {"text": "We do not deal with the problem of determining if two words are similar or not, which is prior to the issue we tackle.", "labels": [], "entities": []}, {"text": "The paper is organized as follows: in Section 2 we describe some related work, in Section 3 we introduce the word embeddings used in this work, in Section 4 we describe our method, in Section 5 we present and analyze the experiments carried out.", "labels": [], "entities": []}, {"text": "Finally, in Section 6, we present our conclusions and sketch some future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Unfortunately, we are notable to compare our method to several others presented by other authors as they are not only based on non-public code, but also on non-public datasets which are not directly comparable with the one used here.", "labels": [], "entities": []}, {"text": "Nevertheless, we compare our technique against several methods, for the particular case of Spanish and Portuguese and show it is solid.", "labels": [], "entities": []}, {"text": "First, we set a simple baseline that does the following: it checks if there exist a WordNet synset which contains both pair words within the Spanish and Portuguese words of it, and if it is does, then they are considered cognates.", "labels": [], "entities": []}, {"text": "Then, we compare to the Machine Translation software Apertium 3 : we take one of the pair words, translate it and check if the translation matches the other word.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.7771655023097992}]}, {"text": "We chose this software since it can be accessed offline and it is freely available.", "labels": [], "entities": []}, {"text": "Apart from this, we compare with Sep\u00falveda and Alu\u00edsio (2011, experiment 2 and 3.2) method and also with a variant of our method that adds a word frequency feature (the relative number of times each word appeared in the corpus).", "labels": [], "entities": []}, {"text": "Word frequencies are used by other authors and we believe they area different data source from what the word2vec vectors can provide.", "labels": [], "entities": []}, {"text": "For these experiments we use the same data set as in (Sep\u00falveda and Alu\u00edsio, 2011).", "labels": [], "entities": []}, {"text": "This resource is composed by 710 Spanish-Portuguese word pairs: 338 cognates and 372 false friends.", "labels": [], "entities": []}, {"text": "The word pairs were selected from the following resources: an online Spanish-Brazilian Portuguese dictionary, an online Spanish-Portuguese dictionary, a list of the most frequent words in Portuguese and Spanish and an online list of different words in Portuguese and Spanish.", "labels": [], "entities": []}, {"text": "There are not multi-word expressions and roughly half of the pairs are composed of identically spelled words.", "labels": [], "entities": []}, {"text": "It was annotated by two people.", "labels": [], "entities": []}, {"text": "It is important to consider that the word coverage is a concern in this task since every method can only works when the pair words are present in their resources (in other words, they are not out of a method's vocabulary).", "labels": [], "entities": []}, {"text": "The accuracy thus only takes into account the covered pairs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.999474823474884}]}, {"text": "The coverage for the simple baseline can be measured by counting the pairs were both words are present in WordNet.", "labels": [], "entities": [{"text": "coverage", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9691706299781799}, {"text": "WordNet", "start_pos": 106, "end_pos": 113, "type": "DATASET", "confidence": 0.9832944869995117}]}, {"text": "Sep\u00falveda and Alu\u00edsio (2011, experiment 2) only considers orthographic and phonetic differences, so always covers all pairs.", "labels": [], "entities": []}, {"text": "Sep\u00falveda and Alu\u00edsio (2011, experiment 3.2) uses a dictionary, then the pairs that are in it count towards the coverage.", "labels": [], "entities": [{"text": "coverage", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.9594888091087341}]}, {"text": "The words that could not be translated by Apertium are counted against the coverage of its related method.", "labels": [], "entities": [{"text": "Apertium", "start_pos": 42, "end_pos": 50, "type": "DATASET", "confidence": 0.8919411897659302}]}, {"text": "Finally, the pairs that cannot be translated into vectors are counted as not covered by our methods.", "labels": [], "entities": []}, {"text": "It can be appreciated that our method provides both high accuracy and coverage, and that word embedding information can be further improved if additional information, such as the word frequencies, is included.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9990953207015991}, {"text": "coverage", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9795742034912109}]}, {"text": "We also tested aversion of our method that only uses Feature 1 via logistic regression, which reduced the accuracy by 3% roughly, showing that the other two features add some missing information to improve the accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9995498061180115}, {"text": "accuracy", "start_pos": 210, "end_pos": 218, "type": "METRIC", "confidence": 0.9979121088981628}]}, {"text": "As an additional experiment, we tried exploiting: Results (%) obtained by the different methods.", "labels": [], "entities": []}, {"text": "WN Baseline and Apertium methods were measured using the whole dataset, whereas our method's evaluation was carried outwith a five-fold cross-validation.", "labels": [], "entities": [{"text": "WN Baseline", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.8697245717048645}, {"text": "Apertium", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9891579151153564}]}, {"text": "WordNet to compute taxonomy-based distances as features in the same manner as did, but we did not obtain a significant difference, thus we conclude that it does not add information to what already lays in the features built upon the embeddings.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9770909547805786}]}, {"text": "(2013b) did, we wondered how our method works under different vector configurations, hence we carried out several experiments, varying vector space dimensions.", "labels": [], "entities": []}, {"text": "We also experimented with vectors for phrases up to two words.", "labels": [], "entities": []}, {"text": "Finally, we evaluated how the election of the source language, Spanish or Portuguese, affects the results.", "labels": [], "entities": []}, {"text": "Accuracy obtained for the ten best configurations, and for the experiment with two word vectors are presented in.", "labels": [], "entities": []}, {"text": "For the experiment we used the vector dimensions 100, 200, 400 and 800; source vector space Spanish and Portuguese; and we also tried with a single run with two-word phrases (with Spanish as source and 100 as the vector dimension), summing up 33 configurations in total.", "labels": [], "entities": []}, {"text": "As it can be noted, there are no significant differences in the accuracy of our method when varying the vector sizes.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9995974898338318}]}, {"text": "Higher dimensions do not provide better results and they even worsen when the target language dimension is greater than or equal to the source language dimension, as claimed.", "labels": [], "entities": []}, {"text": "Taking Spanish as the source language seems to be better, maybe this is due to the corpus sizes: the corpus used to generate the Spanish vector space is 1.4 times larger than the one used for Portuguese.", "labels": [], "entities": []}, {"text": "Finally, we can observe that including vectors for two-word phrases does not improve results.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results (%) obtained by the different methods. WN Baseline and Apertium methods were  measured using the whole dataset, whereas our method's evaluation was carried out with a five-fold  cross-validation.", "labels": [], "entities": [{"text": "WN Baseline", "start_pos": 57, "end_pos": 68, "type": "DATASET", "confidence": 0.7905531823635101}, {"text": "Apertium", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.983781099319458}]}]}