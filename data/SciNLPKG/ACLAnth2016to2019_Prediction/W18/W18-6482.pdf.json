{"title": [{"text": "Alibaba Submission to the WMT18 Parallel Corpus Filtering Task", "labels": [], "entities": [{"text": "WMT18 Parallel Corpus Filtering", "start_pos": 26, "end_pos": 57, "type": "TASK", "confidence": 0.6731426119804382}]}], "abstractContent": [{"text": "This paper describes the Alibaba Machine Translation Group submissions to the WMT 2018 Shared Task on Parallel Corpus Filtering.", "labels": [], "entities": [{"text": "Alibaba Machine Translation", "start_pos": 25, "end_pos": 52, "type": "TASK", "confidence": 0.7705236673355103}, {"text": "WMT 2018 Shared Task on Parallel Corpus Filtering", "start_pos": 78, "end_pos": 127, "type": "TASK", "confidence": 0.5469586923718452}]}, {"text": "While evaluating the quality of the parallel corpus, the three characteristics of the corpus are investigated, i.e. 1) the bilin-gual/translation quality, 2) the monolingual quality and 3) the corpus diversity.", "labels": [], "entities": []}, {"text": "Both rule-based and model-based methods are adapted to score the parallel sentence pairs.", "labels": [], "entities": []}, {"text": "The final parallel corpus filtering system is reliable, easy to build and adapt to other language pairs.", "labels": [], "entities": [{"text": "parallel corpus filtering", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.672744631767273}]}], "introductionContent": [{"text": "The parallel corpus is an essential resource for machine translation and multilingual natural language processing.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.799553245306015}, {"text": "multilingual natural language processing", "start_pos": 73, "end_pos": 113, "type": "TASK", "confidence": 0.6380723118782043}]}, {"text": "Apart from the quantity and domain, the quality of parallel corpus is also very important in MT system training (.", "labels": [], "entities": [{"text": "MT system training", "start_pos": 93, "end_pos": 111, "type": "TASK", "confidence": 0.9095717469851176}]}, {"text": "The Internet contains a large number of multilingual resources, including parallel and comparable sentences).", "labels": [], "entities": []}, {"text": "Many successful machine translation systems are built using the corpus crawled from the web.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 16, "end_pos": 35, "type": "TASK", "confidence": 0.7047947198152542}]}, {"text": "But in practice, this kind of parallel corpus maybe very noisy.", "labels": [], "entities": []}, {"text": "The task of Parallel Corpus Filtering tackles the problem of cleaning noisy parallel corpus.", "labels": [], "entities": [{"text": "Parallel Corpus Filtering", "start_pos": 12, "end_pos": 37, "type": "TASK", "confidence": 0.7730575998624166}]}, {"text": "In this task, we can divide the corpus cleaning task into three parts.", "labels": [], "entities": [{"text": "corpus cleaning task", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.8283942341804504}]}, {"text": "Firstly, a high-quality parallel sentence pair should have the property that its target sentence precisely translates the source sentence, and vice versa.", "labels": [], "entities": []}, {"text": "In this task, we attempt to quantify the translation quality (also called bilingual score) and accuracy of the sentence pair.", "labels": [], "entities": [{"text": "bilingual score)", "start_pos": 74, "end_pos": 90, "type": "METRIC", "confidence": 0.8105354507764181}, {"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9984130859375}]}, {"text": "Secondly, the quality of the target and/or source sentences of the parallel corpus should also be evaluated.", "labels": [], "entities": []}, {"text": "In this work, the target side sentences are concerned a lot for their importance in NMT.", "labels": [], "entities": [{"text": "NMT", "start_pos": 84, "end_pos": 87, "type": "TASK", "confidence": 0.9177276492118835}]}, {"text": "Thirdly, as described by the Parallel Corpus Filtering task, the participants should not pay attention to the domain-relatedness.", "labels": [], "entities": [{"text": "Parallel Corpus Filtering task", "start_pos": 29, "end_pos": 59, "type": "TASK", "confidence": 0.7005755305290222}]}, {"text": "We need to focus on all the domains so that the resulting MT system can be widely used.", "labels": [], "entities": [{"text": "MT", "start_pos": 58, "end_pos": 60, "type": "TASK", "confidence": 0.9793468117713928}]}, {"text": "So the diversity should be evaluated while subsampling the parallel corpus.", "labels": [], "entities": []}, {"text": "Finally, the three characteristics of the parallel corpus are combined to build the final clean corpus.", "labels": [], "entities": []}, {"text": "The paper is structured as follows: Section 2 describes our methods which are used in parallel corpus filtering.", "labels": [], "entities": [{"text": "parallel corpus filtering", "start_pos": 86, "end_pos": 111, "type": "TASK", "confidence": 0.6287911236286163}]}, {"text": "Section 3 specifies the experiments and results.", "labels": [], "entities": []}, {"text": "The dataset for building model-based methods is also detailed in this section.", "labels": [], "entities": []}, {"text": "Conclusions are drawn in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "Here, we describe the noisy corpus filtering rules and two kinds of translation quality evaluation methods: (1) Word Alignment Based bilingual scoring and (2) Bitoken CNN Classifier based bilingual scoring).", "labels": [], "entities": [{"text": "Word Alignment", "start_pos": 112, "end_pos": 126, "type": "TASK", "confidence": 0.6689614802598953}]}, {"text": "Rule based Filtering A few rules are applied to filtering the sentence pairs whose source or target side are not good.", "labels": [], "entities": []}, {"text": "These rules are: \u2022 The length of the sentence which is too short (\u2264 2 words) or too long (> 80 words) will be dropped.", "labels": [], "entities": []}, {"text": "\u2022 The ratio of valid tokens counts to the length of the sentence.", "labels": [], "entities": []}, {"text": "Here, valid tokens are the tokens which contain the letters in the corresponding language.", "labels": [], "entities": []}, {"text": "For example, a valid token in English should contain English letters.", "labels": [], "entities": []}, {"text": "In our system, the sentence is filtered if its valid-tokens ratio is less than 0.2.", "labels": [], "entities": []}, {"text": "For German-English parallel corpus, the source and target sentences' languages should be English and German.", "labels": [], "entities": []}, {"text": "We can detect the sentence's language by using a language detection tool we developed . The sentences pair is filtered if the languages of its source and target sides are not German and English.", "labels": [], "entities": []}, {"text": "In this section, we specify the experimental settings and results in corpus filtering task.", "labels": [], "entities": [{"text": "corpus filtering", "start_pos": 69, "end_pos": 85, "type": "TASK", "confidence": 0.7571095824241638}]}, {"text": "Firstly, the whole corpus which contains about 100 million sentence pairs was evaluated by training the SMT and NMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 104, "end_pos": 107, "type": "TASK", "confidence": 0.9055209755897522}]}, {"text": "The final BLEU scores are 21.21 and 7.8 respectively.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9959296584129333}]}, {"text": "This experiment shows that the whole corpus is really noisy.", "labels": [], "entities": []}, {"text": "Other experimental results are detailed in Table 1.", "labels": [], "entities": []}, {"text": "The randomly sub-selected corpus' performance is also very poor.", "labels": [], "entities": []}, {"text": "The sys 1 system uses the bilingual/monolingual rules and alignment scoring, which performed much better.", "labels": [], "entities": [{"text": "alignment scoring", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.7367445528507233}]}, {"text": "We replace the alignment scoring method by bitoken CNN method and then build the sys 2 system.", "labels": [], "entities": [{"text": "alignment scoring", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.8713372349739075}]}, {"text": "We find that the alignment scoring method and bitoken CNN method are very similar in sentences pairs scoring.", "labels": [], "entities": [{"text": "sentences pairs scoring", "start_pos": 85, "end_pos": 108, "type": "TASK", "confidence": 0.616149107615153}]}, {"text": "As a result, a lot of sentence pairs (about 70% in the subset) are selected by both methods.", "labels": [], "entities": []}, {"text": "The two methods are combined in sys 3, which has a little improvement.", "labels": [], "entities": []}, {"text": "the original scores are normalized to the interval, and then the linear model is used to produce anew score.", "labels": [], "entities": []}, {"text": "In sys 3 system, the weights of alignment score and bitoken CNN score are 0.4 and 0.6 respectively.", "labels": [], "entities": [{"text": "alignment score", "start_pos": 32, "end_pos": 47, "type": "METRIC", "confidence": 0.9574375450611115}, {"text": "bitoken CNN score", "start_pos": 52, "end_pos": 69, "type": "METRIC", "confidence": 0.7021753787994385}]}, {"text": "The sys 4 introduced language mode score based on sys 3.", "labels": [], "entities": []}, {"text": "The weights of the alignment score, bitoken CNN score, and the language model score are 0.4, 0.6 and 0.8 respectively.", "labels": [], "entities": []}, {"text": "It shows that the language model is useful in selecting clean sentences pairs.", "labels": [], "entities": []}, {"text": "Finally, based on sys 4, the corpus diversity filtering rules and scoring are introduced in sys 5.", "labels": [], "entities": [{"text": "corpus diversity filtering", "start_pos": 29, "end_pos": 55, "type": "TASK", "confidence": 0.6310263176759084}]}, {"text": "We find that the diversity method (only Parallel Phrases Diversity Scoring is used in sys 5 system) works well in selecting the smaller subset corpus, e.g. the 10 million words corpus.", "labels": [], "entities": [{"text": "Parallel Phrases Diversity Scoring", "start_pos": 40, "end_pos": 74, "type": "TASK", "confidence": 0.6362676545977592}]}, {"text": "For large subset corpus selection, it almost has no improvement.", "labels": [], "entities": []}, {"text": "We attribute this to the sufficiently high diversity of larger subset corpus.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Methods used in Corpus selection and their performance", "labels": [], "entities": [{"text": "Corpus selection", "start_pos": 26, "end_pos": 42, "type": "TASK", "confidence": 0.956671953201294}]}]}