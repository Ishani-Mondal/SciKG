{"title": [{"text": "Modeling Violations of Selectional Restrictions with Distributional Semantics", "labels": [], "entities": [{"text": "Modeling Violations of Selectional Restrictions", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.8726635694503784}]}], "abstractContent": [{"text": "Distributional Semantic Models have been successfully used for modeling selectional preferences in a variety of scenarios, since distributional similarity naturally provides an estimate of the degree to which an argument satisfies the requirement of a given predicate.", "labels": [], "entities": []}, {"text": "However, we argue that the performance of such models on rare verb-argument combinations has received relatively little attention: it is not clear whether they are able to distinguish the combinations that are simply atypical, or implausible, from the semantically anomalous ones, and in particular, they have never been tested on the task of modeling their differences in processing complexity.", "labels": [], "entities": []}, {"text": "In this paper, we compare two different models of thematic fit by testing their ability of identifying violations of selectional restrictions in two datasets from the experimental studies.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, Distributional Semantic Models (henceforth DSMs) have been at the core of one of the most active research areas in NLP, and have been applied to a wide variety of tasks.", "labels": [], "entities": [{"text": "Distributional Semantic Models (henceforth DSMs)", "start_pos": 17, "end_pos": 65, "type": "TASK", "confidence": 0.6982723133904594}]}, {"text": "Among these, distributional modeling of selectional preferences has been quite popular in computational psycholinguistics, since the similarity estimated by DSMs works very well for predicting the thematic fit between an argument and a verb.", "labels": [], "entities": []}, {"text": "That is to say, the more the argument vector is similar to some kind of vector representation of the ideal filler of the verb slot (it can be either an abstract prototype, or a cluster of exemplars), the more the argument will satisfy the semantic requirements of the slot.", "labels": [], "entities": []}, {"text": "The notion of thematic fit, as it has been proposed by the recent psycholinguistic research 1 , is related to, but not totally equivalent to the classical notion of selectional preferences, since the former refers to a gradient compatibility between verb and role, whereas the latter conceives such compatibility as as boolean constraint evaluated on discrete semantic features (.", "labels": [], "entities": []}, {"text": "The distributional models of thematic fit have been evaluated by comparing the plausibility scores produced by the models with human-elicited judgements, showing significant correlations.", "labels": [], "entities": []}, {"text": "Moreover, they have been used to predict the composition and the update of argument expectations, and for modeling reading times of experimental studies on complement coercion (.", "labels": [], "entities": []}, {"text": "However, an issue regarding their evaluation has not been addressed yet, i.e. their ability of capturing different levels of implausibility.", "labels": [], "entities": []}, {"text": "Our processing system is sensitive to minimal variations in predictability between highly unpredictable word combinations, and such sensitivity has been shown to have an influence on reading times.", "labels": [], "entities": []}, {"text": "Moreover, word combinations that are simply rare and/or unlikely and word combinations that are semantically deviant have been shown to have different consequences on processing complexity for an overview.", "labels": [], "entities": []}, {"text": "A partial exception is the study on semantic deviance by.", "labels": [], "entities": []}, {"text": "However, they focus on the acceptability of adjectival phrases, rather than on selectional preferences.", "labels": [], "entities": []}, {"text": "From this point of view, thematic fit models represent an interesting alternative to the traditional probabilistic ones: they use distributional information about typical arguments to create an abstract representation of the \"ideal\" filler of the argument slot, and thus they are more capable of generalizing to the unseen.", "labels": [], "entities": []}, {"text": "In other words, it does not matter if a specific verb-argument combination is attested in the training corpus of our system or not: its plausibility will still be computed on the basis of the similarity of the argument with the words that typically satisfy the requirements of the verb.", "labels": [], "entities": []}, {"text": "It is important to stress that the inability to work with rare expressions has been fora longtime a general point of criticism of statistical approaches to language, precisely because they could not explain why a given linguistic expression is not attested in the data).", "labels": [], "entities": []}, {"text": "In the present contribution, we take the first step toward the evaluation of thematic fit models on semantic anomaly detection.", "labels": [], "entities": [{"text": "semantic anomaly detection", "start_pos": 100, "end_pos": 126, "type": "TASK", "confidence": 0.7229365309079488}]}, {"text": "We setup a simple classification task on two datasets that have been recently introduced in the literature, and we test two different models on their ability to discriminate between atypical anomalous condition, i.e. the violation of a selectional restriction, and other highly unpredictable conditions.", "labels": [], "entities": []}], "datasetContent": [{"text": "Selectional restrictions can be defined as the set of semantic features that a verb requires of its arguments (.", "labels": [], "entities": []}, {"text": "Modular theories argued that they were represented in the lexicon, which was seen as a specialized module (: it was generally assumed that the human comprehension system initially uses the knowledge available in such modules, and only later uses general world knowledge.", "labels": [], "entities": []}, {"text": "Since now there is evidence speaking against the modularity of the lexicon) and in favor of the access to world knowledge in the early stages of the comprehension process, it was questioned whether selectional restrictions have an independent reality, instead of being just part of a general world knowledge about events and participants.", "labels": [], "entities": []}, {"text": "However, an EEG experiment by showed that the processing difficulty of a sentence is affected differently by violation of selectional restrictions, with respect to simple event knowledge violation.", "labels": [], "entities": [{"text": "simple event knowledge violation", "start_pos": 164, "end_pos": 196, "type": "TASK", "confidence": 0.6032333672046661}]}, {"text": "The authors recorded ERPs on post-verbal Agent arguments as participants read passive English sentences, and they noticed that the N400 evoked by incoming animate Agent arguments violating event knowledge (e.g. The bass was strummed by the drummer) was strongly attenuated when they were semantically related to the context (e.g. the drummer is related to a concert-type scenario).", "labels": [], "entities": []}, {"text": "In contrast, semantic relatedness did not modulate the N400 evoked by inanimate Agent arguments that violated the preceding verbs animacy selection restrictions (e.g. The bass was strummed by the drum).", "labels": [], "entities": []}, {"text": "Such a result led the researchers to the conclusion that the two types of violations are actually distinct at the brain processing level.", "labels": [], "entities": []}, {"text": "Moreover, recently brought new evidence that the violation of a selectional restriction determines higher processing complexity than simple event implausibility.", "labels": [], "entities": []}, {"text": "In an eye-tracking experiment, the authors compared the reading times between sentences in three different experimental conditions: a plausible condition (i.e. The hamster explored a backpack), an implausible condition with no violation of selectional restrictions (The hamster lifted a backpack) and an impossible condition with violation (The hamster entertained a backpack).", "labels": [], "entities": []}, {"text": "Although the difference inhuman possibility ratings was not statistically significant between the last two conditions, eye-movements evidenced longer disruption in the violation condition compared to the other two.", "labels": [], "entities": []}, {"text": "They concluded suggesting that selectional restrictions could actually be coarse-grained semantic features, derived by means of abstractions over exemplar-type representations of events in memory.", "labels": [], "entities": []}, {"text": "Violations of coarse-grained semantic features are likely to be detected earlier by the readers and cause more difficulty also in the later stages of processing, as they lead to such a degree of semantic anomaly that it becomes hard to build a coherent discourse model for the sentence (.", "labels": [], "entities": []}, {"text": "Most importantly, from a computational perspective, word combinations corresponding to the violations either of world knowledge (the implausible condition in Warren's data) or of selectional restrictions are not likely to be found in corpora of natural language data, and thus they cannot be distinguished on the basis of probabilistic methods.", "labels": [], "entities": []}, {"text": "In our work we aim at testing the ability of thematic fit models to spot the difference and to assign different degrees of anomaly to the two conditions.", "labels": [], "entities": []}, {"text": "The idea, intuitively, is that the degree of semantic anomaly goes hand in hand with an increase in processing complexity.", "labels": [], "entities": []}, {"text": "For our experiments, we used two evaluation datasets: the sentences from the studies of and.", "labels": [], "entities": []}, {"text": "The first study presented a magnetoencephalography experiment, with the goal of investigating the brain response to anomaly and to complement coercion, i.e. the case of a type clash between an event-selecting verb and an entity-denoting direct object.", "labels": [], "entities": []}, {"text": "The experimental subjects were exposed to sentences in three different conditions: i) sentences with atypical verb-object combination (The journalist wrote the article after his coffee break); ii) sentences with a complement coercion (The journalist began the article after his coffee break); iii) sentences with a selectional restriction violation (The journalist astonished the article after his coffee break).", "labels": [], "entities": []}, {"text": "This dataset is interesting for us because it will allow a direct comparison between violations of selectional restrictions and a similar phenomenon, the only difference being that a coercion involves the inference of a hidden verb (in the case of the example above, writing) that is not present in the linguistic input, leading to a sort of 'repair' of the violation.", "labels": [], "entities": []}, {"text": "Discriminating between the two conditions is likely to be a difficult task.", "labels": [], "entities": []}, {"text": "The Warren dataset is the same of the study mentioned in Section 2.2.", "labels": [], "entities": [{"text": "Warren dataset", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.8775306642055511}]}, {"text": "We are going to compare the items in the three conditions (plausible, implausible with no violation and impossible violation: seethe examples in Section 2.2) of the experiment of Warren and colleagues, and we are particularly interested in the ability of the models to set the violation condition apart from the others.", "labels": [], "entities": []}, {"text": "As declared by the authors themselves, they have built the sentences in away than even the events described in the plausible condition are rare, or very unlikely.", "labels": [], "entities": []}, {"text": "The test on this dataset will be particularly indicative of the performance of thematic fit models when they have to deal with different types of rare verb-argument combinations.", "labels": [], "entities": []}, {"text": "In both the datasets, we expect our thematic fit models to assign the lowest score to the violation condition, thus being able to distinguish between combinations that are simply unlikely and others that are really anomalous.", "labels": [], "entities": []}, {"text": "Datasets The Pylkk\u00e4nen dataset is composed by 33 triplets of sentences, while the Warren dataset is composed by 30 triplets.", "labels": [], "entities": [{"text": "Pylkk\u00e4nen dataset", "start_pos": 13, "end_pos": 30, "type": "DATASET", "confidence": 0.932743489742279}, {"text": "Warren dataset", "start_pos": 82, "end_pos": 96, "type": "DATASET", "confidence": 0.9664576053619385}]}, {"text": "We converted the experimental sentences in subject-verb-object triples.", "labels": [], "entities": []}, {"text": "Here is one example from the Pylkk\u00e4nen dataset (1) and one from the Warren dataset (2): We extracted all the dependencies for the 20K most frequent words in the corpora, including the words of our datasets.", "labels": [], "entities": [{"text": "Pylkk\u00e4nen dataset", "start_pos": 29, "end_pos": 46, "type": "DATASET", "confidence": 0.9413192868232727}, {"text": "Warren dataset", "start_pos": 68, "end_pos": 82, "type": "DATASET", "confidence": 0.9414667189121246}]}, {"text": "Every co-occurrence between a target word and another context word in a given syntactic relation was weighted by means of Positive Local Mutual Information).", "labels": [], "entities": []}, {"text": "Given a target t, a relation rand a context word c occurring in the relation r with the target (e.g. t = bark, r = sbj, c = dog), we computed both their cooccurrence O trc , and the expected co-occurrence E trc under the assumption of statistical independence.", "labels": [], "entities": []}, {"text": "The Positive Local Mutual Information (henceforth PLMI) is then computed as follows: P LM I(t, r, c) = max(LM I(t, r, c), 0) Finally, each target word is represented by a vector of PLMI-weighted syntactic co-occurrences.", "labels": [], "entities": []}, {"text": "Each contextual dimension corresponds to the co-occurrence of the target with a word in a given syntactic relation.", "labels": [], "entities": []}, {"text": "For example, the vector of the verb write-v has dimensions such as journalist-n:subj,articlen:obj etc.", "labels": [], "entities": []}, {"text": "Method As in, the thematic fit of a word fora given verb role is computed as the distributional similarity of that word with a prototype representation of the typical role filler.", "labels": [], "entities": []}, {"text": "Such representation is obtained by averaging the vectors of the most typical fillers, i.e. words that are strongly associated with that verb-specific role.", "labels": [], "entities": []}, {"text": "More concretely, the authors used syntactic functions to approximate thematic roles, and considered the most typical subjects of a verb as the fillers for the agent role, and the most typical objects as the fillers for the patient role.", "labels": [], "entities": []}, {"text": "Typicality was measured by means of PLMI values: given a target verb t and a syntactic relation r, the typical fillers for the corresponding role were the 20 words with the highest PLMI association score with (t, r).", "labels": [], "entities": [{"text": "PLMI association score", "start_pos": 181, "end_pos": 203, "type": "METRIC", "confidence": 0.8024851282437643}]}, {"text": "Some examples of the extracted fillers are provided in.", "labels": [], "entities": []}, {"text": "Once built the prototype, the thematic fit of each candidate filler is assessed as the cosine similarity between the filler vector and the prototype itself.", "labels": [], "entities": []}, {"text": "For example, the prototype for the patient of entertain-v will be built out of the typical objects of the verb, such as public, player etc.", "labels": [], "entities": []}, {"text": "Words that are distributionally similar to such fillers (i.e. fan) are likely to have a high thematic fit for the role.", "labels": [], "entities": []}, {"text": "Models In our experiments, we compared two different models of thematic fit.", "labels": [], "entities": []}, {"text": "B&L2010 is a 'classical' model of thematic fit, and it consists of a direct reimplementation of: since we are scoring sentences which differ for the degree of typicality of the verb-object combination, the scores assigned by this model will be the thematic fit scores \u03b8 of the object of each sentence given the verb and the patient role.", "labels": [], "entities": [{"text": "B&L2010", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8934650421142578}]}, {"text": "In Equation 3, t is the target verb and c is a word occurring as an object (obj) of t: For example, the score of the sentence of the example 1a will be the thematic fit of the object article-n as a patient of write-v.", "labels": [], "entities": []}, {"text": "The second model is inspired by the proposal of who, instead of seeing the thematic fit as a simple measure of congruence between a predicate and an argument, considered it as a more general measure of the semantic coherence of an event.", "labels": [], "entities": []}, {"text": "The global degree of semantic coherence is given by the product of the partial \u03b8 scores of all the event participants.", "labels": [], "entities": []}, {"text": "Similarly to Baroni and Lenci's model, each \u03b8 score is defined as the cosine similarity between an argument vector and the prototype vector for the slot, built as the centroid of its typical fillers.", "labels": [], "entities": []}, {"text": "Once computed the partial \u03b8 scores, they are combined to find the global score \u03b8 e . where t is a target word in the event e 7 , r is a syntactic relation and c is a context word occurring in the relation r with t (it is read as: the thematic fit score of c given the word t and the relation r).", "labels": [], "entities": []}, {"text": "For example, for the verb-argument triple of the example 1a, the three partial components of the final score would be: i) the thematic fit of the subject journalist-n as an agent of write-v; ii) the thematic fit of the object article-n as a patient of write-v; iii) the thematic fit of the object article-n as a co-argument of the subject journalist-n.", "labels": [], "entities": []}, {"text": "The intuition of the authors was that the semantic coherence of an event does not depend simply on predicate-argument congruence scores, taken in isolation, but on a general degree of mutual typicality between all the participants.", "labels": [], "entities": []}, {"text": "We will refer to this variant of the thematic fit model as CBL2016.", "labels": [], "entities": [{"text": "CBL2016", "start_pos": 59, "end_pos": 66, "type": "DATASET", "confidence": 0.9730976819992065}]}, {"text": "Task We evaluate the accuracy of the models in a classification task: for each triplet in the datasets, we compute the thematic fit scores for the subject-verb-object triples in the three conditions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9988576173782349}]}, {"text": "We score a hit fora model each time it assigns the lowest score to the triple in the violation condition.", "labels": [], "entities": []}, {"text": "The performance of both thematic fit models is compared to the one of a random baseline (since we have three different conditions, the accuracy is estimated to be 33.33%).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 135, "end_pos": 143, "type": "METRIC", "confidence": 0.9995155334472656}]}, {"text": "We also use statistical tests to check in what measure the scores between the violation and the other conditions differ.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Accuracy scores for the Warren dataset.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9990543723106384}, {"text": "Warren dataset", "start_pos": 34, "end_pos": 48, "type": "DATASET", "confidence": 0.9538336098194122}]}, {"text": " Table 3: Accuracy scores for the Pylkk\u00e4nen dataset.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9988910555839539}, {"text": "Pylkk\u00e4nen dataset", "start_pos": 34, "end_pos": 51, "type": "DATASET", "confidence": 0.948186606168747}]}]}