{"title": [{"text": "Investigating the Challenges of Temporal Relation Extraction from Clinical Text", "labels": [], "entities": [{"text": "Temporal Relation Extraction from Clinical Text", "start_pos": 32, "end_pos": 79, "type": "TASK", "confidence": 0.8446955680847168}]}], "abstractContent": [{"text": "Temporal reasoning remains as an unsolved task for Natural Language Processing (NLP), particularly demonstrated in the clinical domain.", "labels": [], "entities": [{"text": "Temporal reasoning", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9639948904514313}, {"text": "Natural Language Processing (NLP)", "start_pos": 51, "end_pos": 84, "type": "TASK", "confidence": 0.7340229054292043}]}, {"text": "The complexity of temporal representation in language is evident as results of the 2016 Clinical TempEval challenge indicate: the current state-of-the-art systems perform well in solving mention-identification tasks of event and time expressions but poorly in temporal relation extraction, showing a gap of around 0.25 point below human performance.", "labels": [], "entities": [{"text": "temporal relation extraction", "start_pos": 260, "end_pos": 288, "type": "TASK", "confidence": 0.6189696689446768}]}, {"text": "We explore to adapt the tree-based LSTM-RNN model proposed by Miwa and Bansal (2016) to temporal relation extraction from clinical text, obtaining a five point improvement over the best 2016 Clinical TempEval system and two points over the state-of-the-art.", "labels": [], "entities": [{"text": "temporal relation extraction from clinical text", "start_pos": 88, "end_pos": 135, "type": "TASK", "confidence": 0.7687725226084391}]}, {"text": "We deliver a deep analysis of the results and discuss the next step towards human-like temporal reasoning.", "labels": [], "entities": [{"text": "human-like temporal reasoning", "start_pos": 76, "end_pos": 105, "type": "TASK", "confidence": 0.675818145275116}]}], "introductionContent": [{"text": "Temporal Information Extraction (TIE) is an active research area in NLP, where the ultimate goal is to be able to represent the development of a story overtime.", "labels": [], "entities": [{"text": "Temporal Information Extraction (TIE)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8001197675863901}]}, {"text": "TIE is a key to text processing tasks including Question Answering and Text Summarization and follows the traditional pipeline of named entity recognition (NER) and relation extraction separately.", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.8646877706050873}, {"text": "Text Summarization", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.7545474767684937}, {"text": "named entity recognition (NER)", "start_pos": 130, "end_pos": 160, "type": "TASK", "confidence": 0.8042921920617422}, {"text": "relation extraction", "start_pos": 165, "end_pos": 184, "type": "TASK", "confidence": 0.7957634031772614}]}, {"text": "Research on this area has been led by TempEval shared tasks but in recent years, the target domain has been shifted to the clinical domain.", "labels": [], "entities": []}, {"text": "The resulting Clinical TempEval challenges ( introduced the adoption of narrative containers to their annotation schema, based on the widely used TIE annotation standard ISOTimeML ( ).", "labels": [], "entities": [{"text": "ISOTimeML", "start_pos": 170, "end_pos": 179, "type": "DATASET", "confidence": 0.5904560685157776}]}, {"text": "Narrative containers were defined by Pustejovsky and Stubbs (2011) as an effort to reduce the scope of temporal relations between pairs of events and time expressions.", "labels": [], "entities": [{"text": "Narrative containers", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9057762324810028}]}, {"text": "As illustrated in, narrative containers can bethought of as temporal buckets in which an event or series of events may fall.", "labels": [], "entities": []}, {"text": "They help visualize the temporal relations within a text and facilitate the identification of other temporal relation types.", "labels": [], "entities": []}, {"text": "Until now, the only corpus annotated with narrative containers is limited to clinical texts.", "labels": [], "entities": []}], "datasetContent": [{"text": "Similar to 2016 Clinical TempEval, we used the THYME corpus) for evaluation, a dataset of 600 clinical notes and pathology reports from colon cancer patients at the Mayo Clinic.", "labels": [], "entities": [{"text": "THYME corpus", "start_pos": 47, "end_pos": 59, "type": "DATASET", "confidence": 0.7747784554958344}]}, {"text": "The corpus is annotated at the document level and identified entities are given a set of attributes depending on their type: DocTimeRel, Type, Polarity, Degree, Contextual Modality and Contextual Aspect for EVENTs and Class for TIMEX3.", "labels": [], "entities": [{"text": "DocTimeRel", "start_pos": 125, "end_pos": 135, "type": "DATASET", "confidence": 0.8368232846260071}]}, {"text": "Temporal relation annotations specify source and target entities along with one of the following TLINK types: BEFORE, BEGINS-ON, CON-TAINS, ENDS-ON and OVERLAP.", "labels": [], "entities": [{"text": "BEFORE", "start_pos": 110, "end_pos": 116, "type": "METRIC", "confidence": 0.9976288676261902}, {"text": "BEGINS-ON", "start_pos": 118, "end_pos": 127, "type": "METRIC", "confidence": 0.9885693192481995}, {"text": "ENDS-ON", "start_pos": 140, "end_pos": 147, "type": "METRIC", "confidence": 0.8609759211540222}, {"text": "OVERLAP", "start_pos": 152, "end_pos": 159, "type": "METRIC", "confidence": 0.9002665281295776}]}, {"text": "Sentence-level annotations are necessary to meet's input requirements.", "labels": [], "entities": []}, {"text": "Therefore, we used the Clinical Language Annotation, Modeling and Processing (CLAMP) toolkit 1 for tokenization and sentence boundary detection.", "labels": [], "entities": [{"text": "Clinical Language Annotation, Modeling and Processing (CLAMP)", "start_pos": 23, "end_pos": 84, "type": "TASK", "confidence": 0.7094288051128388}, {"text": "tokenization", "start_pos": 99, "end_pos": 111, "type": "TASK", "confidence": 0.9757384657859802}, {"text": "sentence boundary detection", "start_pos": 116, "end_pos": 143, "type": "TASK", "confidence": 0.6988349755605062}]}, {"text": "We matched all entities spans from the gold standard with the sentence offsets on the CLAMP output to identify those within the same sentence.", "labels": [], "entities": [{"text": "CLAMP output", "start_pos": 86, "end_pos": 98, "type": "DATASET", "confidence": 0.9444281756877899}]}, {"text": "As a result, the new annotations con-   tain a pair of words, their offsets in the sentence, the temporal relation between them marked on the gold standard and the directionality of the arguments.", "labels": [], "entities": []}, {"text": "Example 1 shows an example annotation of the TLINK CONTAINS(lifelong, nonsmoker) in the sentence He is a lifelong nonsmoker.", "labels": [], "entities": [{"text": "TLINK CONTAINS", "start_pos": 45, "end_pos": 59, "type": "METRIC", "confidence": 0.8265071511268616}]}, {"text": "(1) Since any two EVENT/TIMEX3 can be a candidate pair, we took all entities in a sentence to generate all pair combinations as candidates.", "labels": [], "entities": []}, {"text": "Pairs that do not have any temporal relation were labeled as NONE.", "labels": [], "entities": [{"text": "NONE", "start_pos": 61, "end_pos": 65, "type": "METRIC", "confidence": 0.7062432765960693}]}, {"text": "Due to the large number of negative instances produced by this procedure, it was applied only to CONTAINS.", "labels": [], "entities": [{"text": "CONTAINS", "start_pos": 97, "end_pos": 105, "type": "DATASET", "confidence": 0.715954065322876}]}, {"text": "No negative instances were generated for the remaining TLINK types and we did not extend the set of TLINKs to its transitive closure (i.e. A CONTAINS B ^ B CONTAINS C \u00d1 A CONTAINS C).", "labels": [], "entities": []}, {"text": "detail the resulting datasets.: Results of our four experiments on the THYME test set.", "labels": [], "entities": [{"text": "THYME test set", "start_pos": 71, "end_pos": 85, "type": "DATASET", "confidence": 0.9721553921699524}]}, {"text": "FNE refers to filtered negative examples.", "labels": [], "entities": [{"text": "FNE", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.6212425231933594}]}, {"text": "We followed the same experimental settings described in presents the results of previous approaches compared to human performance.", "labels": [], "entities": []}, {"text": "The first row shows the top performance in 2016 Clinical TempEval using binary classification.", "labels": [], "entities": [{"text": "Clinical TempEval", "start_pos": 48, "end_pos": 65, "type": "TASK", "confidence": 0.44801825284957886}]}, {"text": "The second and third rows are the latests results outside the competition.", "labels": [], "entities": []}, {"text": "Following the steps of the Clinical TempEval narrative container identification task, we only tried to predict TLINKs of CONTAINS type.", "labels": [], "entities": [{"text": "Clinical TempEval narrative container identification task", "start_pos": 27, "end_pos": 84, "type": "TASK", "confidence": 0.7339310099681219}, {"text": "TLINKs", "start_pos": 111, "end_pos": 117, "type": "METRIC", "confidence": 0.8799585700035095}]}, {"text": "In doing so we obtained an F1 score of 0.629, outperforming UTHealth's system.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.986455500125885}, {"text": "UTHealth", "start_pos": 60, "end_pos": 68, "type": "DATASET", "confidence": 0.8060091733932495}]}, {"text": "The model shows a high precision but lower recall than UTHealth; this is probably because of NONE relations prevailing in the dataset.", "labels": [], "entities": [{"text": "precision", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9992325305938721}, {"text": "recall", "start_pos": 43, "end_pos": 49, "type": "METRIC", "confidence": 0.9993988275527954}, {"text": "UTHealth", "start_pos": 55, "end_pos": 63, "type": "DATASET", "confidence": 0.736011803150177}]}, {"text": "By handling the task as binary classification, given a pair of entities we are already assuming there is some kind of temporal relation and the classifier's task is to decide whether it is CONTAINS or not.", "labels": [], "entities": []}, {"text": "We performed this experiment in order to have results comparable with those of UTHealth.", "labels": [], "entities": [{"text": "UTHealth", "start_pos": 79, "end_pos": 87, "type": "DATASET", "confidence": 0.8522882461547852}]}, {"text": "However, we cannot compare this re-sult to the state-of-the-art since was a multi-class classification approach.", "labels": [], "entities": []}, {"text": "reports our experimental results of a single run with the four different settings 5 . Switching from binary classification to multi-class classification we observe a significant drop in precision and a lower F1 score.", "labels": [], "entities": [{"text": "precision", "start_pos": 186, "end_pos": 195, "type": "METRIC", "confidence": 0.9996989965438843}, {"text": "F1 score", "start_pos": 208, "end_pos": 216, "type": "METRIC", "confidence": 0.9876312911510468}]}, {"text": "This is expected since the classifier now has more TLINK as options from whereto decide.", "labels": [], "entities": [{"text": "TLINK", "start_pos": 51, "end_pos": 56, "type": "METRIC", "confidence": 0.997765302658081}]}, {"text": "Despite of this change, the model keeps outperforming both UTHealth and the stateof-the-art.", "labels": [], "entities": [{"text": "UTHealth", "start_pos": 59, "end_pos": 67, "type": "DATASET", "confidence": 0.8265573382377625}]}], "tableCaptions": [{"text": " Table 1: Label distribution of pre-processed dataset for  binary classification.", "labels": [], "entities": [{"text": "binary classification", "start_pos": 59, "end_pos": 80, "type": "TASK", "confidence": 0.7131034135818481}]}, {"text": " Table 2: Label distribution of pre-processed dataset for  multi-class classification.", "labels": [], "entities": [{"text": "multi-class classification", "start_pos": 59, "end_pos": 85, "type": "TASK", "confidence": 0.7691011726856232}]}, {"text": " Table 3: Performance of systems and humans on iden- tifying CONTAINS relations.", "labels": [], "entities": []}, {"text": " Table 4: Results of our four experiments on the THYME test set. FNE refers to filtered negative examples.", "labels": [], "entities": [{"text": "THYME test set", "start_pos": 49, "end_pos": 63, "type": "DATASET", "confidence": 0.9584901531537374}, {"text": "FNE", "start_pos": 65, "end_pos": 68, "type": "METRIC", "confidence": 0.9832282066345215}]}, {"text": " Table 6: Distribution of misclassified CONTAINS and  OVERLAP Event-Event pairs by type of EVENT. Ab- breviations: V, Verb; NV, Non-Verb", "labels": [], "entities": [{"text": "Ab- breviations", "start_pos": 98, "end_pos": 113, "type": "METRIC", "confidence": 0.9457898338635763}]}]}