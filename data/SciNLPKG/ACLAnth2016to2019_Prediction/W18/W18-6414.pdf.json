{"title": [{"text": "The MLLP-UPV German-English Machine Translation System for WMT18", "labels": [], "entities": [{"text": "MLLP-UPV German-English Machine Translation", "start_pos": 4, "end_pos": 47, "type": "TASK", "confidence": 0.6687175035476685}, {"text": "WMT18", "start_pos": 59, "end_pos": 64, "type": "TASK", "confidence": 0.6828678250312805}]}], "abstractContent": [{"text": "This paper describes the statistical machine translation system built by the MLLP research group of Universitat Polit\u00e8cnica de Va\u00ec encia for the German\u2192English news translation shared task of the EMNLP 2018 Third Conference on Machine Translation (WMT18).", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 25, "end_pos": 56, "type": "TASK", "confidence": 0.6229783395926157}, {"text": "German\u2192English news translation shared task of the EMNLP 2018 Third Conference on Machine Translation (WMT18)", "start_pos": 145, "end_pos": 254, "type": "TASK", "confidence": 0.7957931223668551}]}, {"text": "We used an ensemble of Transformer architecture-based neural machine translation systems.", "labels": [], "entities": [{"text": "Transformer architecture-based neural machine translation", "start_pos": 23, "end_pos": 80, "type": "TASK", "confidence": 0.7874900341033936}]}, {"text": "To train our system under \"constrained\" conditions, we filtered the provided parallel data with a scoring technique using character-based language models, and we added parallel data based on synthetic source sentences generated from the provided mono-lingual corpora.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper we describe the statistical machine translation (SMT) system built by the MLLP research group of Universitat Polit\u00e8cnica deVa\u00ec encia for the German\u2192English news translation shared task of the EMNLP 2018 Third Conference on Machine Translation (WMT18).", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 30, "end_pos": 67, "type": "TASK", "confidence": 0.7855834811925888}, {"text": "German\u2192English news translation shared task of the EMNLP 2018 Third Conference on Machine Translation (WMT18)", "start_pos": 155, "end_pos": 264, "type": "TASK", "confidence": 0.7826478387180128}]}, {"text": "Neural Machine Translation (NMT) has made great advances over the last few years, and in particular it has come to outperform Phrase-Based Machine Translation (PBMT) and PBMT-NMT combinations in the most recent WMT shared news translation tasks (.", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8089314003785452}, {"text": "Phrase-Based Machine Translation (PBMT)", "start_pos": 126, "end_pos": 165, "type": "TASK", "confidence": 0.820776641368866}, {"text": "WMT shared news translation", "start_pos": 211, "end_pos": 238, "type": "TASK", "confidence": 0.9079030901193619}]}, {"text": "Taking this into account, we decided to build an NMT system taking as a basis the Transformer architecture, which has been shown to provide stateof-the-art SMT results while requiring relatively short times to train.", "labels": [], "entities": [{"text": "SMT", "start_pos": 156, "end_pos": 159, "type": "TASK", "confidence": 0.9943410158157349}]}, {"text": "Apart from the SMT system itself, we also describe our work on parallel-corpus preprocessing and filtering, an aspect which has gained importance in WMT18 with the addition of the much larger and noisier parallel corpus ParaCrawl.", "labels": [], "entities": [{"text": "SMT", "start_pos": 15, "end_pos": 18, "type": "TASK", "confidence": 0.9869208335876465}, {"text": "WMT18", "start_pos": 149, "end_pos": 154, "type": "DATASET", "confidence": 0.8544495701789856}]}, {"text": "Regarding data augmentation, we report as well how we extended the provided parallel dataset with data based on synthetic source sentences generated from the provided target-language monolingual corpora (in compliance with this shared task's \"constrained\" conditions).", "labels": [], "entities": [{"text": "data augmentation", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.6818542927503586}]}, {"text": "This paper is organized as follows: in Section 2, we outline the data preparation techniques that were used (corpus preprocessing, corpus filtering, and data augmentation with synthetic source sentences); Section 3 shows the architecture and parameters of our NMT system and our system combination; in Section 4, we report our experiments and results (including on data preparation and on final system evaluation); and we draw our final conclusions in Section 5.", "labels": [], "entities": [{"text": "corpus filtering", "start_pos": 131, "end_pos": 147, "type": "TASK", "confidence": 0.7507087290287018}, {"text": "data preparation", "start_pos": 365, "end_pos": 381, "type": "TASK", "confidence": 0.7419270277023315}]}], "datasetContent": [{"text": "In this section, we outline our experimental setup (Section 4.1); we report our experiments and results on corpus filtering (Section 4.2); we detail our setup for parallel data augmentation with synthetic source sentences (Section 4.3); and we discuss our final German\u2192English NMT system evaluation and results (Section 4.4).", "labels": [], "entities": [{"text": "corpus filtering", "start_pos": 107, "end_pos": 123, "type": "TASK", "confidence": 0.7010862082242966}]}, {"text": "For our experiments, we used newstest2015 as the development set and newstest2017 as the test set.", "labels": [], "entities": []}, {"text": "We also report the results obtained with this year's newstest2018.", "labels": [], "entities": [{"text": "newstest2018", "start_pos": 53, "end_pos": 65, "type": "DATASET", "confidence": 0.8532449007034302}]}, {"text": "We evaluated our systems using the BLEU () and TER () measures, using mteval from the Moses SMT toolkit () and tercom, respectively.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 35, "end_pos": 39, "type": "METRIC", "confidence": 0.9989233613014221}, {"text": "TER", "start_pos": 47, "end_pos": 50, "type": "METRIC", "confidence": 0.9878641963005066}, {"text": "Moses SMT toolkit", "start_pos": 86, "end_pos": 103, "type": "DATASET", "confidence": 0.6754845082759857}]}, {"text": "All reported scores are according to the instructions on system output formatting provided by the WMT18 organization.", "labels": [], "entities": [{"text": "system output formatting", "start_pos": 57, "end_pos": 81, "type": "TASK", "confidence": 0.6313123106956482}, {"text": "WMT18 organization", "start_pos": 98, "end_pos": 116, "type": "DATASET", "confidence": 0.9401562213897705}]}, {"text": "We will now describe the most significant results obtained with the German\u2192English NMT models we trained for WMT18 (based on the architecture and parameters outlined in Section 3).", "labels": [], "entities": [{"text": "WMT18", "start_pos": 109, "end_pos": 114, "type": "DATASET", "confidence": 0.795198380947113}]}, {"text": "These results are shown in.", "labels": [], "entities": []}, {"text": "Our baseline model was trained excluding the ParaCrawl corpus from the training data, since using the full WMT18 corpus (with ParaCrawl) actually led to worse results (as we saw in Section 4.2).", "labels": [], "entities": [{"text": "ParaCrawl corpus", "start_pos": 45, "end_pos": 61, "type": "DATASET", "confidence": 0.9305533468723297}, {"text": "WMT18 corpus", "start_pos": 107, "end_pos": 119, "type": "DATASET", "confidence": 0.9626007080078125}, {"text": "ParaCrawl", "start_pos": 126, "end_pos": 135, "type": "DATASET", "confidence": 0.9153343439102173}]}, {"text": "As mentioned in Section 3, this system was trained with 20K BPE operations (as is the case with the next system we will describe).", "labels": [], "entities": [{"text": "BPE", "start_pos": 60, "end_pos": 63, "type": "METRIC", "confidence": 0.8183218240737915}]}, {"text": "Our first step to improve these baseline results was filtering the full WMT18 corpus (including ParaCrawl), as explained in Section 4.2.", "labels": [], "entities": [{"text": "WMT18 corpus", "start_pos": 72, "end_pos": 84, "type": "DATASET", "confidence": 0.9644814133644104}]}, {"text": "In Ta- we show the result obtained with a system trained on our best filtered corpus.", "labels": [], "entities": []}, {"text": "As we saw in Section 4.2, the 10M filtered corpus provides an improvement of 2.5 BLEU and 1.7 TER in the test set over the baseline model.", "labels": [], "entities": [{"text": "10M filtered corpus", "start_pos": 30, "end_pos": 49, "type": "DATASET", "confidence": 0.6047349969546}, {"text": "BLEU", "start_pos": 81, "end_pos": 85, "type": "METRIC", "confidence": 0.9994915723800659}, {"text": "TER", "start_pos": 94, "end_pos": 97, "type": "METRIC", "confidence": 0.9967917799949646}]}, {"text": "This shows how our data-filtering approach has allowed us to extract useful sentences from the noisy ParaCrawl corpus and improve our system performance.", "labels": [], "entities": [{"text": "ParaCrawl corpus", "start_pos": 101, "end_pos": 117, "type": "DATASET", "confidence": 0.9075524806976318}]}, {"text": "For our final systems, we added 20M synthetic sentence pairs as described in Section 4.3, and we oversampled the previous 10M filtered bilingual training set by duplicating it, which gave us a final training set with a total of 40M sentence pairs 1 . We also increased the number of BPE operations from 20K to 40K.", "labels": [], "entities": []}, {"text": "A single system trained with this configuration obtained 35.9 BLEU and 51.2 TER in the test set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 62, "end_pos": 66, "type": "METRIC", "confidence": 0.9994738698005676}, {"text": "TER", "start_pos": 76, "end_pos": 79, "type": "METRIC", "confidence": 0.9982130527496338}]}, {"text": "This represents a significant improvement of 1.4 BLEU and 1.7 TER over the previous model, explained by a combination of the additional sentence pairs and the increase in vocabulary size.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 49, "end_pos": 53, "type": "METRIC", "confidence": 0.9960820078849792}, {"text": "TER", "start_pos": 62, "end_pos": 65, "type": "METRIC", "confidence": 0.9959554672241211}]}, {"text": "As reference of the training times required, training a system with this final configuration took approx. 120 hours on a single-GPU system (Nvidia GeForce GTX 1080 Ti) 2 . Finally, our primary submission for WMT18 consists of an ensemble of 4 independent training runs with this final configuration, resulting in 36.2 BLEU and 51.0 TER in our test set, and 45.1 BLEU and 40.8 TER in newstest2018.", "labels": [], "entities": [{"text": "Nvidia GeForce GTX 1080 Ti", "start_pos": 140, "end_pos": 166, "type": "DATASET", "confidence": 0.9210368990898132}, {"text": "WMT18", "start_pos": 208, "end_pos": 213, "type": "DATASET", "confidence": 0.7621728777885437}, {"text": "BLEU", "start_pos": 318, "end_pos": 322, "type": "METRIC", "confidence": 0.9983217120170593}, {"text": "TER", "start_pos": 332, "end_pos": 335, "type": "METRIC", "confidence": 0.9870184659957886}, {"text": "BLEU", "start_pos": 362, "end_pos": 366, "type": "METRIC", "confidence": 0.9989001750946045}, {"text": "TER", "start_pos": 376, "end_pos": 379, "type": "METRIC", "confidence": 0.9774296283721924}, {"text": "newstest2018", "start_pos": 383, "end_pos": 395, "type": "DATASET", "confidence": 0.9804288148880005}]}, {"text": "Oversampling the 10M original training set was a measure intended to keep in check the weight of the comparatively large 20M synthetic training data.", "labels": [], "entities": []}, {"text": "We left for future work experimenting with different ratios of synthetic versus original data, such as 1:1 (, as additional comparison terms to determine the best performing configuration.", "labels": [], "entities": []}, {"text": "While our systems were trained on single-GPU machines, multi-GPU system training with proportionally larger batch sizes (larger than the 3000 words per batch we used, as noted in Section 3) could deliver better translation quality results ().", "labels": [], "entities": []}, {"text": "We left this for future work.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Size by corpus of the WMT18 parallel dataset", "labels": [], "entities": [{"text": "Size", "start_pos": 10, "end_pos": 14, "type": "TASK", "confidence": 0.9861606359481812}, {"text": "WMT18 parallel dataset", "start_pos": 32, "end_pos": 54, "type": "DATASET", "confidence": 0.8894012570381165}]}, {"text": " Table 2: Results of 9-gram character-based language model data filtering, by number of selected sentences", "labels": [], "entities": [{"text": "9-gram character-based language model data filtering", "start_pos": 21, "end_pos": 73, "type": "TASK", "confidence": 0.5772939821084341}]}, {"text": " Table 3: Results of German\u2192English MT system evaluations", "labels": [], "entities": [{"text": "MT system evaluations", "start_pos": 36, "end_pos": 57, "type": "TASK", "confidence": 0.7902082204818726}]}]}