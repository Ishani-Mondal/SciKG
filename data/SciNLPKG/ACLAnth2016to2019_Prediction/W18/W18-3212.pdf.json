{"title": [{"text": "GHHT at CALCS 2018: Named Entity Recognition for Dialectal Arabic Using Neural Networks", "labels": [], "entities": [{"text": "GHHT at CALCS 2018", "start_pos": 0, "end_pos": 18, "type": "DATASET", "confidence": 0.7661163657903671}, {"text": "Entity Recognition", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.7345698773860931}, {"text": "Dialectal Arabic Using Neural Networks", "start_pos": 49, "end_pos": 87, "type": "TASK", "confidence": 0.6681139349937439}]}], "abstractContent": [{"text": "This paper describes our system submission to the CALCS 2018 shared task on named entity recognition on code-switched data for the language variant pair of Modern Standard Arabic and Egyp-tian dialectal Arabic.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 76, "end_pos": 100, "type": "TASK", "confidence": 0.6404559711615244}, {"text": "Modern Standard Arabic and Egyp-tian dialectal Arabic", "start_pos": 156, "end_pos": 209, "type": "DATASET", "confidence": 0.8384971874100822}]}, {"text": "We build a a Deep Neural Network that combines word and character-based representations in convo-lutional and recurrent networks with a CRF layer.", "labels": [], "entities": []}, {"text": "The model is augmented with stacked layers of enriched information such pre-trained embeddings, Brown clusters and named entity gazetteers.", "labels": [], "entities": []}, {"text": "Our system is ranked second among those participating in the shared task achieving an FB1 average of 70.09%.", "labels": [], "entities": [{"text": "FB1 average", "start_pos": 86, "end_pos": 97, "type": "METRIC", "confidence": 0.985547661781311}]}], "introductionContent": [{"text": "The CALCS 2018 shared task () is about performing named entity recognition (NER) on Modern Standard Arabic (MSA) -Egyptian Arabic (EGY) code-switched tweets.", "labels": [], "entities": [{"text": "named entity recognition (NER) on Modern Standard Arabic (MSA) -Egyptian Arabic (EGY) code-switched tweets", "start_pos": 50, "end_pos": 156, "type": "TASK", "confidence": 0.7094329652332124}]}, {"text": "Unlike previous shared tasks on code-switching, the data provided contains no code-switching annotation.", "labels": [], "entities": []}, {"text": "Only nine categories of named entities are annotated using BIO tagging.", "labels": [], "entities": [{"text": "BIO tagging", "start_pos": 59, "end_pos": 70, "type": "TASK", "confidence": 0.7276561558246613}]}, {"text": "While this makes the task a \"pure\" NER task, the difficulty is to design a model which can cope with the noise introduced by code-switching, challenging old systems tailored around MSA.", "labels": [], "entities": []}, {"text": "NER is a well-studied sequence labeling problem.", "labels": [], "entities": [{"text": "NER", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.894770622253418}, {"text": "sequence labeling", "start_pos": 22, "end_pos": 39, "type": "TASK", "confidence": 0.5910821110010147}]}, {"text": "Earlier work has applied standard supervised learning techniques to the problem, such as Hidden Markov Models (HMM) (), Maximum-Entropy Model (ME) (), Support Vector Machines (SVM)), and Conditional Random Fields (CRF).", "labels": [], "entities": []}, {"text": "Standard data sets came from the English MUC-6 and the multilingual CoNLL-02) and 03 shared tasks.", "labels": [], "entities": [{"text": "English MUC-6", "start_pos": 33, "end_pos": 46, "type": "DATASET", "confidence": 0.7299301624298096}, {"text": "CoNLL-02", "start_pos": 68, "end_pos": 76, "type": "DATASET", "confidence": 0.8449700474739075}]}, {"text": "More recent work relies on neural networks.", "labels": [], "entities": []}, {"text": "A number of architecture variants have proven to be effective (.", "labels": [], "entities": []}, {"text": "What they have in common is that they use a bidirectional LSTM (bi-LSTM) over vector representations of the input words in order model their left and right contexts.", "labels": [], "entities": []}, {"text": "On top of the bi-LSTM, they use a CRF layer to take the final tagging decisions.", "labels": [], "entities": []}, {"text": "Other than a softmax layer which would treat tagging decisions independently, the CRF is able to model the linear dependencies between labels.", "labels": [], "entities": []}, {"text": "This is essential for NER, where for instance, B-LOCATION cannot be followed by I-PERSON.", "labels": [], "entities": [{"text": "NER", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.8687280416488647}, {"text": "B-LOCATION", "start_pos": 47, "end_pos": 57, "type": "METRIC", "confidence": 0.9798992872238159}]}, {"text": "The architectures differ in their way of obtaining a vector representation for the input words.", "labels": [], "entities": []}, {"text": "For instance, in, each word embedding is obtained as a concatenation of the output of a bidirectional LSTM (bi-LSTM) over its characters and a pretrained word vector.", "labels": [], "entities": []}, {"text": "Ma and Hovy (2016) use convolutions over character embeddings with maxpooling for obtaining morphological features from the character level, similar to Chiu and Nichols (2016).", "labels": [], "entities": []}, {"text": "Our system also relies on the bi-LSTM-CRF architecture.", "labels": [], "entities": []}, {"text": "As input representation, we use both word embeddings and a character-level representation based on CNNs.", "labels": [], "entities": []}, {"text": "Our system additionally employs a Brown Cluster representation, oversampling, and NE gazetteers.", "labels": [], "entities": []}, {"text": "The remainder of the paper is structured as follows in the following section, we provide a short decription of the task and the data set.", "labels": [], "entities": []}, {"text": "3 describes our system in detail.", "labels": [], "entities": []}, {"text": "4 presents our experiments, and Sect.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: DNN experiments and Results", "labels": [], "entities": []}, {"text": " Table 3: Results breakdown on the validation set", "labels": [], "entities": []}]}