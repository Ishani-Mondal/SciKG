{"title": [{"text": "Dual Memory Network Model for Biased Product Review Classification", "labels": [], "entities": []}], "abstractContent": [{"text": "In sentiment analysis (SA) of product reviews, both user and product information are proven to be useful.", "labels": [], "entities": [{"text": "sentiment analysis (SA) of product reviews", "start_pos": 3, "end_pos": 45, "type": "TASK", "confidence": 0.9169160574674606}]}, {"text": "Current tasks handle user profile and product information in a unified model which may not be able to learn salient features of users and products effectively.", "labels": [], "entities": []}, {"text": "In this work, we propose a dual user and product memory network (DUPMN) model to learn user profiles and product reviews using separate memory networks.", "labels": [], "entities": []}, {"text": "Then, the two representations are used jointly for sentiment prediction.", "labels": [], "entities": [{"text": "sentiment prediction", "start_pos": 51, "end_pos": 71, "type": "TASK", "confidence": 0.9738470315933228}]}, {"text": "The use of separate models aims to capture user profiles and product information more effectively.", "labels": [], "entities": []}, {"text": "Compared to state-of-the-art unified prediction models, the evaluations on three benchmark datasets, IMDB, Yelp13, and Yelp14, show that our dual learning model gives performance gain of 0.6%, 1.2%, and 0.9%, respectively.", "labels": [], "entities": [{"text": "IMDB", "start_pos": 101, "end_pos": 105, "type": "DATASET", "confidence": 0.7678788304328918}, {"text": "Yelp13", "start_pos": 107, "end_pos": 113, "type": "DATASET", "confidence": 0.6374622583389282}, {"text": "Yelp14", "start_pos": 119, "end_pos": 125, "type": "DATASET", "confidence": 0.756625235080719}]}, {"text": "The improvements are also deemed very significant measured by p-values.", "labels": [], "entities": []}], "introductionContent": [{"text": "Written text is often meant to express sentiments of individuals.", "labels": [], "entities": []}, {"text": "Recognizing the underlying sentiment expressed in the text is essential to understand the full meaning of the text.", "labels": [], "entities": []}, {"text": "The SA community is increasingly interested in using natural language processing (NLP) techniques as well as sentiment theories to identify sentiment expressions in the text.", "labels": [], "entities": []}, {"text": "Recently, deep learning based methods have taken over feature engineering approaches to gain further performance improvement in SA.", "labels": [], "entities": [{"text": "SA", "start_pos": 128, "end_pos": 130, "type": "TASK", "confidence": 0.9786447286605835}]}, {"text": "Typical neural network models include Convolutional Neural Network (CNN), Recursive auto-encoders (), Long-Short Term Memory (LSTM) (, and many more.", "labels": [], "entities": []}, {"text": "Attention-based models are introduced to highlight important words and sentences in apiece of text.", "labels": [], "entities": []}, {"text": "Different attention models are built using information embedded in the text including users, products and text in local context (.", "labels": [], "entities": []}, {"text": "In order to incorporate other aspects of knowledge, developed a model to employ additional linguistic resources to benefit sentiment classification. and proposed cognition-based attention models learned from cognition grounded eye-tracking data.", "labels": [], "entities": [{"text": "sentiment classification.", "start_pos": 123, "end_pos": 148, "type": "TASK", "confidence": 0.9203397035598755}]}, {"text": "Most text-based SA is modeled as sentiment classification tasks.", "labels": [], "entities": [{"text": "text-based SA", "start_pos": 5, "end_pos": 18, "type": "TASK", "confidence": 0.49115312099456787}, {"text": "sentiment classification tasks", "start_pos": 33, "end_pos": 63, "type": "TASK", "confidence": 0.9407969117164612}]}, {"text": "In this work, SA is for product reviews.", "labels": [], "entities": [{"text": "SA", "start_pos": 14, "end_pos": 16, "type": "METRIC", "confidence": 0.9849435687065125}]}, {"text": "We use the term users to refer to writers of text, and products to refer to the targets of reviews in the text.", "labels": [], "entities": []}, {"text": "A user profile is defined by the collection of reviews a user writes.", "labels": [], "entities": []}, {"text": "Product information defined fora product is the collection of reviews for this product.", "labels": [], "entities": []}, {"text": "Note that user profiles and product information are not independent of each other.", "labels": [], "entities": []}, {"text": "That is one reason why previous works use unified models.", "labels": [], "entities": []}, {"text": "By commonsense we know that review text written by a person maybe subjective or biased towards his/her own preferences.", "labels": [], "entities": []}, {"text": "Lenient users tend to give higher ratings than finicky ones even if they review the same products.", "labels": [], "entities": []}, {"text": "Popular products do receive higher ratings than those unpopular ones because the aggregation of user reviews still shows the difference in opinion for different products.", "labels": [], "entities": []}, {"text": "While users and products both play crucial roles in sentiment analysis, they are fundamentally different.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.9577206075191498}]}, {"text": "Reviews written by a user can be affected by user preference which is more subjective whereas reviews fora product are useful only if they are from a collection of different reviewers, because we know individual reviews can be biased.", "labels": [], "entities": []}, {"text": "The popularity of a product tends to reflect the general impression of a collection of users as an aggregated result.", "labels": [], "entities": []}, {"text": "Therefore, sentiment prediction of a product should give dual consideration to individual users as well as all reviews as a collection.", "labels": [], "entities": [{"text": "sentiment prediction", "start_pos": 11, "end_pos": 31, "type": "TASK", "confidence": 0.9448089897632599}]}, {"text": "In this paper, we address the aforementioned issue by proposing to learn user profiles and product review information separately before making a joint prediction on sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 165, "end_pos": 189, "type": "TASK", "confidence": 0.9508205652236938}]}, {"text": "In the proposed Dual User and Product Memory Network (DUPMN) model, we first build a hierarchical LSTM) model to generate document representations.", "labels": [], "entities": []}, {"text": "Then a user memory network (UMN) and a product memory network (PMN) are separately built based on document representation of user comments and product reviews.", "labels": [], "entities": []}, {"text": "Finally, sentiment prediction is learned from a dual model.", "labels": [], "entities": [{"text": "sentiment prediction", "start_pos": 9, "end_pos": 29, "type": "TASK", "confidence": 0.9723368585109711}]}, {"text": "To validate the effectiveness of our proposed model, evaluations are conducted on three benchmarking review datasets from IMDB and Yelp data challenge (including Yelp13 and Yelp14) ().", "labels": [], "entities": [{"text": "IMDB", "start_pos": 122, "end_pos": 126, "type": "DATASET", "confidence": 0.938129723072052}, {"text": "Yelp data challenge", "start_pos": 131, "end_pos": 150, "type": "DATASET", "confidence": 0.9641810059547424}, {"text": "Yelp14", "start_pos": 173, "end_pos": 179, "type": "DATASET", "confidence": 0.8442527651786804}]}, {"text": "Experimental results show that our algorithm can outperform baseline methods by large margins.", "labels": [], "entities": []}, {"text": "Compared to the state-ofthe-art method, DUPMN made 0.6%, 1.2%, and 0.9% increase inaccuracy with p-values 0.007, 0.004, and 0.001 in the three benchmark datasets respectively.", "labels": [], "entities": [{"text": "DUPMN", "start_pos": 40, "end_pos": 45, "type": "DATASET", "confidence": 0.5879278182983398}]}, {"text": "Results show that leveraging user profile and product information separately can be more effective for sentiment predictions.", "labels": [], "entities": [{"text": "sentiment predictions", "start_pos": 103, "end_pos": 124, "type": "TASK", "confidence": 0.9826407730579376}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 gives related work, especially memory network models.", "labels": [], "entities": []}, {"text": "Section 3 introduces our proposed DUPMN model.", "labels": [], "entities": []}, {"text": "Section 4 gives the evaluation compared to state-of-the-art methods on three datasets.", "labels": [], "entities": []}, {"text": "Section 5 concludes this paper and gives some future directions in sentiment analysis models to consider individual bias.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 67, "end_pos": 85, "type": "TASK", "confidence": 0.9626595675945282}]}], "datasetContent": [{"text": "Performance evaluations are conducted on three datasets and DUPMN is compared with a set of commonly used baseline methods including the state-of-the-art LSTM based method ().", "labels": [], "entities": []}, {"text": "The three benchmarking datasets include movie reviews from IMDB, restaurant reviews from Yelp13 and Yelp14 developed by Tang (2015a).", "labels": [], "entities": [{"text": "IMDB", "start_pos": 59, "end_pos": 63, "type": "DATASET", "confidence": 0.9038219451904297}, {"text": "Yelp13", "start_pos": 89, "end_pos": 95, "type": "DATASET", "confidence": 0.94749915599823}, {"text": "Yelp14", "start_pos": 100, "end_pos": 106, "type": "DATASET", "confidence": 0.9116285443305969}]}, {"text": "All datasets are tokenized using the Stanford NLP tool ( Since postings in social networks by both users and products follow the long tail distribution (, we only show the distribution of total number of posts for different products.", "labels": [], "entities": [{"text": "Stanford NLP", "start_pos": 37, "end_pos": 49, "type": "DATASET", "confidence": 0.877127468585968}]}, {"text": "For example, #p(0-50) means the number of products which have reviews between the size of 0 to 50.", "labels": [], "entities": [{"text": "#p(0-50)", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.7977071046829224}]}, {"text": "We split train/development/test sets at the rate of 8:1:1 following the same setting in ().", "labels": [], "entities": []}, {"text": "The best configuration by the development dataset is used for the test set to obtain the final result.", "labels": [], "entities": []}, {"text": "Four sets of experiments are conducted.", "labels": [], "entities": []}, {"text": "The first experiment compares DUPMN with other sentiment analysis methods.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.9195353984832764}]}, {"text": "The second experiment evaluates the effectiveness of different hop size K of memory network.", "labels": [], "entities": []}, {"text": "The third experiment evaluates the effectiveness of UMN and PMN in different datasets.", "labels": [], "entities": []}, {"text": "The fourth set of experiment examines the effect of memory size m on the performance of DUPMN.", "labels": [], "entities": [{"text": "DUPMN", "start_pos": 88, "end_pos": 93, "type": "DATASET", "confidence": 0.7881270051002502}]}, {"text": "Performance measures include Accuracy (ACC), Root-Mean-Square-Error (RMSE), and Mean Absolute Error (MAE) for our model.", "labels": [], "entities": [{"text": "Accuracy (ACC)", "start_pos": 29, "end_pos": 43, "type": "METRIC", "confidence": 0.9609073251485825}, {"text": "Root-Mean-Square-Error (RMSE)", "start_pos": 45, "end_pos": 74, "type": "METRIC", "confidence": 0.9124608635902405}, {"text": "Mean Absolute Error (MAE)", "start_pos": 80, "end_pos": 105, "type": "METRIC", "confidence": 0.9731044967969259}]}, {"text": "For other baseline methods in Group 2 and Group 3, their reported results are used.", "labels": [], "entities": []}, {"text": "We also show the p-value by comparing the result of 10 random tests for both our model and the state-ofthe-art model 1 in the t-test 2 . Compared to other state-of-the-art models shows the result of the first experiment.", "labels": [], "entities": []}, {"text": "DUPMN uses one hop (the best performer) with m being set at 100, a commonly used memory size for memory networks.", "labels": [], "entities": [{"text": "DUPMN", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9043921232223511}]}, {"text": "Generally speaking, Group 2 performs better than Group 1.", "labels": [], "entities": []}, {"text": "This is because Group 1 uses a traditional SVM with feature engineering (Chang and Lin, 2011) and Group 2 uses more advanced deep learning methods proven to be effective by recent studies.", "labels": [], "entities": []}, {"text": "However, some feature engineering methods are no worse than some deep learning methods.", "labels": [], "entities": []}, {"text": "For example, the TextFeature model outperforms SSWE by a significant margin.", "labels": [], "entities": []}, {"text": "When comparing Group 2 and Group 3 methods, we can see that user profiles and product information can improve performance as most of the methods in Group 3 perform better than methods in Group 2.", "labels": [], "entities": []}, {"text": "This is more obvious in the IMDB dataset which naturally contains more subjectivity.", "labels": [], "entities": [{"text": "IMDB dataset", "start_pos": 28, "end_pos": 40, "type": "DATASET", "confidence": 0.9594886302947998}]}, {"text": "In the IMDB dataset, almost all models with user and product information outperform the text-only models in Group 2 except LSTM+CBA ().", "labels": [], "entities": [{"text": "IMDB dataset", "start_pos": 7, "end_pos": 19, "type": "DATASET", "confidence": 0.9702600240707397}]}, {"text": "However, the two LSTM models in Group 2 which include local attention mechanism do show that attention base methods can outperform methods using user profile and product information.", "labels": [], "entities": []}, {"text": "In fact, the LSTM+CBA model using attention mechanism based on cognition grounded eye-tracking data in Group 2 outperforms quite a number of methods in Group 3.", "labels": [], "entities": []}, {"text": "LSTM+CBA in Group 2 is only inferior to LSTM+UPA in Group 3 because of the additional user profile and production information used in LSTM+UPA.", "labels": [], "entities": []}, {"text": "Most importantly, the DUPMN model with both user memory and product memory significantly outperforms all the baseline methods including the state-of-the-art LSTM+UPA model ( ).", "labels": [], "entities": []}, {"text": "By using user profiles and product information in memory networks, DUPMN outperforms LSTM+UPA in all three datasets.", "labels": [], "entities": []}, {"text": "In the IMDB dataset, our model makes 0.6 % improvement over LSTM+UPA inaccuracy with p\u2212value of 0.007.", "labels": [], "entities": [{"text": "IMDB dataset", "start_pos": 7, "end_pos": 19, "type": "DATASET", "confidence": 0.9754771590232849}]}, {"text": "Our model also achieves lower RMSE value.", "labels": [], "entities": [{"text": "RMSE", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.991657018661499}]}, {"text": "In the Yelp review dataset, the improvement is even more significant.", "labels": [], "entities": [{"text": "Yelp review dataset", "start_pos": 7, "end_pos": 26, "type": "DATASET", "confidence": 0.9724923968315125}]}, {"text": "DUPMN achieves 1.2% improvement inaccuracy in Yelp13 with p\u2212value of 0.004 and 0.9% in Yelp14 with p \u2212 value of 0.001, and the lower RMSE obtained by DUPMN also indicates that the proposed model can predict review ratings more accurately.", "labels": [], "entities": [{"text": "DUPMN", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9428280591964722}, {"text": "inaccuracy", "start_pos": 32, "end_pos": 42, "type": "METRIC", "confidence": 0.943747878074646}, {"text": "Yelp13", "start_pos": 46, "end_pos": 52, "type": "DATASET", "confidence": 0.9020428657531738}, {"text": "Yelp14", "start_pos": 87, "end_pos": 93, "type": "DATASET", "confidence": 0.9439916610717773}, {"text": "RMSE", "start_pos": 133, "end_pos": 137, "type": "METRIC", "confidence": 0.9982602000236511}, {"text": "DUPMN", "start_pos": 150, "end_pos": 155, "type": "DATASET", "confidence": 0.8940706253051758}]}], "tableCaptions": [{"text": " Table 1: Statistics of the three benchmark datasets", "labels": [], "entities": []}, {"text": " Table 2: Evaluation of different methods; best result/group in accuracy is marked in bold; second best is underlined.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9964337348937988}]}, {"text": " Table 3: Evaluation of different memory network hops and user and product information utilization 3", "labels": [], "entities": []}, {"text": " Table 4: Average weight of UMN and PMN in different  datasets", "labels": [], "entities": [{"text": "Average weight", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.9408435821533203}]}]}