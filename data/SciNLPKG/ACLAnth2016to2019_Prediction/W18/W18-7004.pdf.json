{"title": [{"text": "Assisted Lexical Simplification for French Native Children with Reading Difficulties", "labels": [], "entities": [{"text": "Assisted Lexical Simplification", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8233187794685364}]}], "abstractContent": [{"text": "For poor-readers and dyslexic children, reading is often a pitfall to social integration and academic progress.", "labels": [], "entities": []}, {"text": "The school support of these children usually requires adapted texts, specialised glossaries and dedicated management tools.", "labels": [], "entities": []}, {"text": "In this paper , we propose a method which exploits French lexical resources to automatically simplify words in order to provide adapted texts.", "labels": [], "entities": []}, {"text": "Despite the difficulty of the task, the conducted evaluations show that the proposed methodology yields better results than the state of the art word2vec techniques for lexical simplification.", "labels": [], "entities": []}], "introductionContent": [{"text": "Learning to read is a complex and lengthy process leading to a fundamental skill which is crucial for academic, professional and personal success.", "labels": [], "entities": []}, {"text": "Yet, according to the Progress in International Reading Literacy (PIRLS 1 ) 2001, the overall performances of French young readers is gradually decreasing from evaluation to evaluation: 39% of the students are in difficulty at the end of primary school according to the study carried by the Cycle of Disciplinary Evaluations Performed on Samples 2 . Statistically, every year, 2 to 5 children in a classroom present a specific language impairment (from poor-reading to dyslexia, with a large variability).", "labels": [], "entities": [{"text": "International Reading Literacy (PIRLS 1 ) 2001", "start_pos": 34, "end_pos": 80, "type": "DATASET", "confidence": 0.5643089115619659}]}, {"text": "show that the problems of comprehension among children with reading difficulties are mostly due to the difficulties in decoding words in order to recognise them.", "labels": [], "entities": []}, {"text": "In other words, these children do not suffer from https://timssandpirls.bc.edu/ pirls2001i/pdf/p1_IR_book.pdf 2 Cycle des \u00c9valuations Disciplinaires R\u00e9alis\u00e9es sur \u00c9chantillons (CEDRE).", "labels": [], "entities": []}, {"text": "However, when it comes to reading a text, it turns out that all their efforts are so focused on decoding that they exhaust their cognitive capacity.", "labels": [], "entities": []}, {"text": "Out of hand, they get tired, give up reading and lose the meaning of what they have already read.", "labels": [], "entities": []}, {"text": "In this context, scholars have found it valuable to control the reading difficulty of pedagogical materials using readability formulae).", "labels": [], "entities": []}, {"text": "Text readability can be defined as the ease with which a reader can read and understand a text.", "labels": [], "entities": [{"text": "Text readability", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7532256543636322}]}, {"text": "Readability assessment techniques enable a better association between texts and readers, which tends to increase the benefits of reading practices.", "labels": [], "entities": [{"text": "Readability assessment", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8020091950893402}]}, {"text": "However, even if readability formulae are useful to find appropriate texts fora given level of reading proficiency, they do not allow to adapt a given text to a specific reader, as is generally needed for poor readers or readers with dyslexia.", "labels": [], "entities": []}, {"text": "More recently, Natural Language Processing (NLP) techniques have allowed the development of more efficient tools to support reading.", "labels": [], "entities": []}, {"text": "Among them are advanced readability models) that automatically assess the readability of a text from a larger number of text characteristics.", "labels": [], "entities": []}, {"text": "Another promising area is automated text simplification (ATS), which aims to automatically substitute complex linguistic phenomena in texts by simpler equivalents while keeping the meaning preserved as much as possible.", "labels": [], "entities": [{"text": "text simplification (ATS)", "start_pos": 36, "end_pos": 61, "type": "TASK", "confidence": 0.8582454681396484}]}, {"text": "ATS is generally described as involving two sub-tasks: syntactic simplification and lexical simplification (LS).", "labels": [], "entities": [{"text": "ATS", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8778043389320374}, {"text": "lexical simplification (LS)", "start_pos": 84, "end_pos": 111, "type": "TASK", "confidence": 0.7014302015304565}]}, {"text": "In this paper, we will be concerned with the second one, because, as far as poor and dyslexic readers are concerned, automatic lexical simplification is a first and crucial step in order to simplify a text for this population.", "labels": [], "entities": [{"text": "automatic lexical simplification", "start_pos": 117, "end_pos": 149, "type": "TASK", "confidence": 0.607191413640976}]}, {"text": "As it has been highlighted in the literature, long and less frequent words are especially difficult for poor readers).", "labels": [], "entities": []}, {"text": "also identified that, for French children with dyslexia, inconsistent words as far as the grapheme-phoneme relation is concerned (different length of the number of letters and phonemes in a word) contribute to the difficulty in reading.", "labels": [], "entities": []}, {"text": "In this paper, we address the challenging task of LS, which has not yet been systematically investigated for French.", "labels": [], "entities": [{"text": "LS", "start_pos": 50, "end_pos": 52, "type": "TASK", "confidence": 0.8016568422317505}]}, {"text": "We compare two approaches: the first one is based on the exploitation of a lexical resource, ReSyf, which contains disambiguated ranked synonyms in French; the second one is based on word embedding and draws from.", "labels": [], "entities": [{"text": "ReSyf", "start_pos": 93, "end_pos": 98, "type": "DATASET", "confidence": 0.8598587512969971}]}, {"text": "Although previous studies have prioritised statistical methods over the use of resources to acquire synonyms, we are not aware of a previous study having compared statistical models with a disambiguated synonym resource.", "labels": [], "entities": []}, {"text": "We believe that this property could significantly enhance the selection of relevant candidates for substitution in a given context.", "labels": [], "entities": []}, {"text": "Another property of ReSyf is that synonyms have already been ranked by reading difficulty using method.", "labels": [], "entities": []}, {"text": "The paper is organised as follows: Section 2 presents existing methods for LS.", "labels": [], "entities": [{"text": "LS", "start_pos": 75, "end_pos": 77, "type": "TASK", "confidence": 0.9863690137863159}]}, {"text": "Section 3 describes our method and Section 4 discusses on the results.", "labels": [], "entities": []}, {"text": "Some concluding remarks are to be found at the end, along with future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our aim is to assess the use of lexical resource such as ReSyf for the task of lexical simplification.", "labels": [], "entities": []}, {"text": "We hypothesise that having already a disambiguated set of synonyms reduces the amount of noisy candidates created by statistical algorithms.", "labels": [], "entities": []}, {"text": "To check this hypothesis, we have evaluated the quality of the substitutions produced by the two methods: the baseline based on and our method based on ReSyf, relying on the evaluation made by two experts.", "labels": [], "entities": [{"text": "ReSyf", "start_pos": 152, "end_pos": 157, "type": "DATASET", "confidence": 0.8040907979011536}]}, {"text": "The corpus used for evaluation contains literary and scientific texts usually read in classrooms at primary levels (children aged 7 to 9 years old) in France.", "labels": [], "entities": []}, {"text": "Within the 187 sentences of the corpus, experts have identified 190 complex words that have to be simplified (thus, we have an average of 1 complex word per sentence).", "labels": [], "entities": []}, {"text": "In this paper, the simplifications have been evaluated according to their complexity and the context where they appear.", "labels": [], "entities": []}, {"text": "Three substitutes are proposed for every complex word.", "labels": [], "entities": []}, {"text": "The provided simplifications were assessed by two evaluators following these instructions: \u2022 The substitute must be simpler than the complex word \u2022 The substitute must fit the context of the sentence \u2022 If the complex word appears as a substitute, it is invalidated The table 2 shows examples of the evaluation.", "labels": [], "entities": []}, {"text": "Beau and fort do not match the context.", "labels": [], "entities": [{"text": "Beau", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9285146594047546}, {"text": "fort", "start_pos": 9, "end_pos": 13, "type": "METRIC", "confidence": 0.8326352834701538}]}, {"text": "We computed the inter-rater reliability of the human annotation.", "labels": [], "entities": [{"text": "reliability", "start_pos": 28, "end_pos": 39, "type": "METRIC", "confidence": 0.6357871890068054}]}, {"text": "Even though selecting good candidates for simplification has been regarded as a complex task for human, we obtained a \u03ba of 0.625 for the baseline model and a \u03ba of 0.656 for the annotation of ReSyf's results.", "labels": [], "entities": []}, {"text": "Based on this human annotation, we have computed two evaluation metrics.", "labels": [], "entities": []}, {"text": "Precision1 is a global precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.976200520992279}]}, {"text": "Every simplification is considered as an independent sentence.", "labels": [], "entities": []}, {"text": "This measure aims to calculate the number of valid simplifications among all the provided ones (i.e simplified sentences).", "labels": [], "entities": []}, {"text": "Precision2 allows us to verify, for an initial sentence if, at least, one valid simplification appears among the three proposed ones.", "labels": [], "entities": []}, {"text": "For each original sentence, only one valid simplification is counted, even if there are two or three valid ones.", "labels": [], "entities": []}, {"text": "If none of the three simplifications are correct, then the count is 0.", "labels": [], "entities": []}, {"text": "This measure counts the number of initial sentences that have at least one valid simplification.", "labels": [], "entities": []}, {"text": "By analysing the simplifications produced by the baseline and our method, table 3 shows that ReSyf provides better results than Word2Vec techniques.", "labels": [], "entities": []}, {"text": "In table 3, Precision1 and Precision2 count valid simplifications only if both of the annotators agree on the proposed substitute.", "labels": [], "entities": []}, {"text": "This table also shows that our method produces more suitable simplifications (16.3% and 51.9%) than the baseline (15.7% and 49.4%).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Evaluation example for simplified versions of the sentence Le castor est un excellent nageur.", "labels": [], "entities": []}, {"text": " Table 3: LS evaluation result of annotators 1 and 2", "labels": [], "entities": []}]}