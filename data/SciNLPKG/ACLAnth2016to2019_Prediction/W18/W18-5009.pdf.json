{"title": [{"text": "Automatic Token and Turn Level Language Identification for Code-Switched Text Dialog: An Analysis Across Language Pairs and Corpora", "labels": [], "entities": [{"text": "Turn Level Language Identification", "start_pos": 20, "end_pos": 54, "type": "TASK", "confidence": 0.5503906086087227}]}], "abstractContent": [{"text": "We examine the efficacy of various feature-learner combinations for language identification in different types of text-based code-switched interactions-human-human dialog, human-machine dialog, as well as monolog-at both the token and turn levels.", "labels": [], "entities": [{"text": "language identification", "start_pos": 68, "end_pos": 91, "type": "TASK", "confidence": 0.7137200087308884}]}, {"text": "In order to examine the generalization of such methods across language pairs and datasets, we analyze ten different datasets of code-switched text.", "labels": [], "entities": []}, {"text": "We extract a variety of character-and word-based text features and pass them into multiple learners, including conditional random fields, logistic regressors, and recurrent neural networks.", "labels": [], "entities": []}, {"text": "We further examine the efficacy of character-level embedding and GloVe features in improving performance and observe that our best-performing text system significantly outperforms the majority vote baseline across language pairs and datasets.", "labels": [], "entities": []}], "introductionContent": [{"text": "Code-switching refers to multilingual speakers' alternating use of two or more languages or language varieties within the context of a single conversation or discourse in a manner consistent with the syntax and phonology of each variety).", "labels": [], "entities": []}, {"text": "Increasing globalization and the continued rise of multilingual societies around the world makes research and development of automated tools for the processing of code-switched speech a very relevant and interesting problem for the scientific community.", "labels": [], "entities": []}, {"text": "In our case, an important additional motivating factor for studying and developing tools to elicit and process code-switched or crutched 1 language comes from the education domain, specifically language learning.", "labels": [], "entities": []}, {"text": "Recent findings in the literature suggest that strategic use of code-switching of bilinguals' L1 and L2 in instruction serves multiple pedagogic functions across lexical, cultural, and cross-linguistic dimensions, and could enhance students' bilingual development and maximize their learning efficacy).", "labels": [], "entities": []}, {"text": "This seems to be a particularly effective strategy especially when instructing low proficient language learners.", "labels": [], "entities": []}, {"text": "Therefore, the understanding of code-switched dialog and development of computational tools for automatically processing code-switched conversations would provide an important pedagogic aid for teachers and learners in classrooms, and potentially even enhance learning at scale and personalized learning.", "labels": [], "entities": []}, {"text": "Automated processing of code-switched text dialog poses an interesting, albeit challenging problem for the scientific community.", "labels": [], "entities": []}, {"text": "This is because the hurdles observed during traditional dialog processing tasks such as spoken language understanding (SLU), natural language generation (NLG) and dialog management (DM) are exacerbated in the case of code-switched text where the language the speaker is using at any given instant is not known apriori.", "labels": [], "entities": [{"text": "spoken language understanding (SLU)", "start_pos": 88, "end_pos": 123, "type": "TASK", "confidence": 0.8165034651756287}, {"text": "natural language generation (NLG)", "start_pos": 125, "end_pos": 158, "type": "TASK", "confidence": 0.825517495473226}, {"text": "dialog management (DM)", "start_pos": 163, "end_pos": 185, "type": "TASK", "confidence": 0.8302560031414032}]}, {"text": "Integrating an explicit language identification (or LID) step into the processing pipeline can potentially alleviate these issues.", "labels": [], "entities": []}, {"text": "Take for example a use case of designing conversational applications for non-native English language learners (ELLs) from multiple native language (or L1) backgrounds.", "labels": [], "entities": []}, {"text": "Many such learners tend to \"crutch\" on their L1 while speaking in the target language (or L2) that they are learning, es-pecially if they are low proficiency learners, resulting in mixed-language speech.", "labels": [], "entities": []}, {"text": "In such a case, LID becomes particularly important for SLU and DM, where the dialog designer/language expert may want the conversational agent to perform different dialog actions depending on whether the speaker used his/her L1 alone, the L2 alone, or a mixture of both during the previous turn.", "labels": [], "entities": [{"text": "LID", "start_pos": 16, "end_pos": 19, "type": "METRIC", "confidence": 0.9762430787086487}]}, {"text": "Researchers have made significant progress in the automated processing of code-switched text in recent years (.", "labels": [], "entities": []}, {"text": "While Joshi had already proposed a formal computational linguistics framework to analyze and parse code-switched text in the early eighties, it was not until recently that significant strides were made in the large-scale analysis of code-switched text.", "labels": [], "entities": []}, {"text": "These have been facilitated by burgeoning multilingual text corpora (thanks largely to the rise of social media) and corpus analysis studies (see for example, which have in turn facilitated advances in automated processing.", "labels": [], "entities": [{"text": "corpus analysis", "start_pos": 117, "end_pos": 132, "type": "TASK", "confidence": 0.797664999961853}]}, {"text": "Particularly relevant to our work is prior art on predicting code-switch points and language identification (.", "labels": [], "entities": [{"text": "predicting code-switch points", "start_pos": 50, "end_pos": 79, "type": "TASK", "confidence": 0.8621071974436442}, {"text": "language identification", "start_pos": 84, "end_pos": 107, "type": "TASK", "confidence": 0.7853847444057465}]}, {"text": "Researchers have made much progress on LID in code-switched text (tweets, in particular) thanks to recent workshops dedicated to the topic (.", "labels": [], "entities": [{"text": "LID", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.9491317868232727}]}, {"text": "One of the top-performing systems used character n-gram, prefix and suffix features, letter case and special character features and explored logistic regression and conditional random field (CRF) learners to achieve the best performance for Spanish-English codeswitched text).", "labels": [], "entities": []}, {"text": "Yet another successful system leveraged bi-directional long short term memory networks (BLSTMs) and CRFs (along with word and character embedding features) on both SpanishEnglish and Standard Arabic-Egyptian language pairs ().", "labels": [], "entities": [{"text": "SpanishEnglish", "start_pos": 164, "end_pos": 178, "type": "DATASET", "confidence": 0.9412804841995239}]}, {"text": "While there is comparatively less work in the literature on automated analysis of codeswitched speech and dialog, the number of corpora and studies is steadily growing in several language pairs -for instance, MandarinEnglish (, Cantonese-English () and HindiEnglish.", "labels": [], "entities": []}, {"text": "As far as dialog is concerned, the Bangor Corpus consists of human-human dialog conversations in Spanish-English, Welsh-English and SpanishWelsh ().", "labels": [], "entities": [{"text": "Bangor Corpus", "start_pos": 35, "end_pos": 48, "type": "DATASET", "confidence": 0.9929522275924683}]}, {"text": "More recently, Ramanarayanan and Suendermann-Oeft (2017) also proposed a multimodal dialog corpus of human-machine Hindi-English and SpanishEnglish code-switched data.", "labels": [], "entities": []}, {"text": "In order to understand how turn-level LID systems for dialog perform across different languages and corpora, this paper explores the efficacy of different text-based features on multiple human-human and humanmachine dialog corpora of code-switched data in multiple language pairs.", "labels": [], "entities": []}, {"text": "To that end, this paper builds on other recent work that examined this phenomenon for the Bangor Miami Corpus of English-Spanish human-human dialog) and expands it significantly (note however, that this study does not examine speech data).", "labels": [], "entities": [{"text": "Bangor Miami Corpus of English-Spanish human-human dialog", "start_pos": 90, "end_pos": 147, "type": "DATASET", "confidence": 0.9485632266317096}]}, {"text": "To our knowledge, this is the first such comprehensive exploration of turn-level LID performance in human-human code-switched text dialog.", "labels": [], "entities": []}, {"text": "With that in mind, the specific contributions of this paper are to examine: 1.", "labels": [], "entities": []}, {"text": "The performance of: (i) a range of text features (including word-and character-level embedding features) for (ii) both word-level and turn-level LID; 2.", "labels": [], "entities": []}, {"text": "How generalizable these features are across different datasets comprising different language pairs and styles of codeswitched text -human-human dialog, human-machine dialog and monolog (tweets); 3.", "labels": [], "entities": []}, {"text": "Turn-level LID performance by (i) using word-level LID followed by aggregation over the entire turn v.s.", "labels": [], "entities": []}, {"text": "(ii) directly training classifiers at the turn-level.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows: Section 2 describes the various corpora used for our turn-level LID experiments.", "labels": [], "entities": []}, {"text": "We then elucidate the various featuresets and learners we explored in Sections 3 and 4 respectively, followed by details of the experimental setup in Section 5.", "labels": [], "entities": []}, {"text": "Next, Section 6 presents the results of our LID experiments as well as analyses of performance numbers across featureset-learner combinations, language pairs and dataset style.", "labels": [], "entities": []}, {"text": "Finally, we conclude with a discussion of current observations and an outlook for future work in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted 10-fold cross-validation experiments for all datasets.", "labels": [], "entities": []}, {"text": "For each dataset, we first extracted the word and character level features described in Section 3.", "labels": [], "entities": []}, {"text": "We experimented with different learner configurations and parameter settings and summarize the best performing featureset and learner combination in the Results section.", "labels": [], "entities": []}, {"text": "We used a grid search method to find optimal character embedding size for each dataset (among values of 25, 50 and 100).", "labels": [], "entities": []}, {"text": "We set the word-embedding size to 100 and used 25 and 100 recurrent units in the character-level and word-level BiLSTMs, respectively, following.: Weighted average F1 scores obtained by different featureset-learner combinations on each codeswitching dataset.", "labels": [], "entities": [{"text": "F1", "start_pos": 164, "end_pos": 166, "type": "METRIC", "confidence": 0.992557168006897}]}, {"text": "Notice that datasets are organized first by language pair, and then according to type of interaction (human-human vs. human-machine vs. Twitter).", "labels": [], "entities": []}, {"text": "Each cell of the table contains two numbers: the overall weighted F1 score on top and the F1 score of the code-switched class in parentheses at the bottom.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9814631044864655}, {"text": "F1 score", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9852341413497925}]}, {"text": "Note that we obtained performance numbers for pre-trained word and character embeddings only for language pairs with more than one dataset, i.e., ENG-SPA and ENG-CHI.", "labels": [], "entities": []}, {"text": "Also shown for benchmarking purposes are the best tweet-level performance numbers from the 1 stand 2 nd codeswitching challenges for some of the Twitter datasets.", "labels": [], "entities": [{"text": "Twitter datasets", "start_pos": 145, "end_pos": 161, "type": "DATASET", "confidence": 0.824222207069397}]}, {"text": "However, note that this is not a completely fair comparison, because the train-test partitions in our case are different: we used only the train data from the 1 st code-switching challenge in order to perform 10-fold cross-validation experiments.", "labels": [], "entities": []}, {"text": "Also seethe text for more details.: Weighted average F1 scores for token-level predictions after 10-fold crossvalidation.", "labels": [], "entities": [{"text": "Weighted average F1 scores", "start_pos": 36, "end_pos": 62, "type": "METRIC", "confidence": 0.8592571914196014}]}, {"text": "Also shown for benchmarking purposes are the best token-level performance numbers from the 1 stand 2 nd codeswitching challenges.", "labels": [], "entities": []}, {"text": "However, note that this is not a fair comparison, because the train-test partitions in our case are different: we used only the train data from the 1 st code-switching challenge in order to perform 10-fold cross-validation experiments.", "labels": [], "entities": []}, {"text": "Also seethe text for more details.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the different code-switching corpora considered in this paper. Note that H2H stands for human-to-human while H2M stands", "labels": [], "entities": []}, {"text": " Table 3: Weighted average F1 scores for token-level predictions after 10-fold crossvalidation. Also  shown for benchmarking purposes are the best token-level performance numbers from the 1 st and 2 nd  codeswitching challenges. However, note that this is not a fair comparison, because the train-test parti- tions in our case are different: we used only the train data from the 1 st code-switching challenge in order  to perform 10-fold cross-validation experiments. Also see the text for more details.", "labels": [], "entities": [{"text": "F1", "start_pos": 27, "end_pos": 29, "type": "METRIC", "confidence": 0.9676546454429626}]}]}