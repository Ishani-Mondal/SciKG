{"title": [{"text": "Automated Acquisition of Patterns for Coding Political Event Data: Two Case Studies", "labels": [], "entities": [{"text": "Automated Acquisition of Patterns", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7533450573682785}, {"text": "Coding Political Event Data", "start_pos": 38, "end_pos": 65, "type": "TASK", "confidence": 0.857254758477211}]}], "abstractContent": [{"text": "We present a simple approach to the generation and labeling of extraction patterns for coding political event data, an important task in computational social science.", "labels": [], "entities": [{"text": "generation and labeling of extraction patterns", "start_pos": 36, "end_pos": 82, "type": "TASK", "confidence": 0.7424493382374445}, {"text": "coding political event data", "start_pos": 87, "end_pos": 114, "type": "TASK", "confidence": 0.8543426543474197}]}, {"text": "We use weak supervision to identify pattern candidates and learn distributed representations for them.", "labels": [], "entities": []}, {"text": "Given seed extraction patterns from existing pattern dictionaries, we use label propagation to label pattern candidates.", "labels": [], "entities": []}, {"text": "We present two case studies.", "labels": [], "entities": []}, {"text": "i) We derive patterns of acceptable quality fora number of international relations & conflicts categories using pattern candidates of O'Connor et al.", "labels": [], "entities": [{"text": "O'Connor et al", "start_pos": 134, "end_pos": 148, "type": "DATASET", "confidence": 0.8633382121721903}]}, {"text": "ii) We derive patterns for coding protest events that outperform an established set of TABARI / PETRARCH hand-crafted patterns.", "labels": [], "entities": [{"text": "TABARI / PETRARCH", "start_pos": 87, "end_pos": 104, "type": "METRIC", "confidence": 0.6513938506444296}]}], "introductionContent": [], "datasetContent": [{"text": "We next evaluate the quality of the labeled pattern candidates.", "labels": [], "entities": []}, {"text": "Event patterns are intended as highprecision classifiers: The words making a pattern are chosen carefully to generate as few false positives as possible.", "labels": [], "entities": []}, {"text": "Pattern-based classifiers are typically weak in recall as it maybe difficult to construct sufficiently many unambiguous patterns.", "labels": [], "entities": [{"text": "recall", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.99598628282547}]}, {"text": "Thus, any good new pattern potentially contributes to higher recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 61, "end_pos": 67, "type": "METRIC", "confidence": 0.9983751773834229}]}, {"text": "Does our automated approach produce good new patterns?", "labels": [], "entities": []}, {"text": "An evaluation that we conduct for IR patterns Step 1: Edge weight matrix Define edge weight matrix W \u2208 R m\u00d7m as where cos \u03b8 is the cosine similarity between row vectors u tr p, * and u tr q, * of U tr , the distributed representations of patterns p and q.", "labels": [], "entities": [{"text": "IR", "start_pos": 34, "end_pos": 36, "type": "TASK", "confidence": 0.9734104871749878}]}, {"text": "Step 2: Label propagation (After) Given some seed patterns, define matrix F (0) \u2208 R m\u00d7c , where m is the number of patterns and c is the number of categories, as 1 if p is a seed pattern for category k, 0 otherwise Define transition matrix T \u2208 R m\u00d7m as tpq = wpq m r=0 wrq Let F (\u221e) be the label matrix after convergence is reached.", "labels": [], "entities": [{"text": "Label propagation", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.824713796377182}]}, {"text": "Label unlabeled patterns q with\u02c6kwith\u02c6 with\u02c6k = arg max k f Procedure 2: Labeling of pattern candidates by label propagation through pattern similarity graph.", "labels": [], "entities": [{"text": "Labeling of pattern candidates", "start_pos": 73, "end_pos": 103, "type": "TASK", "confidence": 0.822221651673317}]}, {"text": "aims at estimating the proportion of correct new patterns at various ranks, when ordered by label score f qk . For protest events, we measure precision and recall on an annotated corpus.", "labels": [], "entities": [{"text": "precision", "start_pos": 142, "end_pos": 151, "type": "METRIC", "confidence": 0.999440610408783}, {"text": "recall", "start_pos": 156, "end_pos": 162, "type": "METRIC", "confidence": 0.99933260679245}]}, {"text": "We use IR patterns to code newswire documents from the LexisNexis data service.", "labels": [], "entities": [{"text": "LexisNexis data service", "start_pos": 55, "end_pos": 78, "type": "DATASET", "confidence": 0.892710546652476}]}, {"text": "Out of twenty CAMEO categories, we randomly sample eight: For each category k, we order the pattern candidates fork by label score f (\u221e) qk in descending order and randomly sample fifteen pattern candidates from among the first 50, 50-100, and 100-150 pattern candidates.", "labels": [], "entities": []}, {"text": "We pair the sampled candidates with category labels and turn the resulting patterns to the TABARI / PETRARCH dictionary format.", "labels": [], "entities": [{"text": "TABARI", "start_pos": 91, "end_pos": 97, "type": "METRIC", "confidence": 0.963390052318573}]}, {"text": "We use PETRARCH to code actors and events with the help of these patterns.", "labels": [], "entities": []}, {"text": "We also check that each event match respects the dependency path of the pattern.", "labels": [], "entities": []}, {"text": "For each pattern, we randomly sample up to two sentences that it matches.", "labels": [], "entities": []}, {"text": "This gives us a total of 551 sentences.", "labels": [], "entities": []}, {"text": "To this, we add 130 sentences matched by thirteen patterns randomly sampled from the seeds of each category, with up to two sentences per pattern.", "labels": [], "entities": []}, {"text": "To estimate the proportion of correct new patterns, the author and one political science doctoral student check the predicted categories of all the sentences.", "labels": [], "entities": []}, {"text": "The human coders try to indicate, whenever possible, whether the predicted category is incorrect fora reason other than the pattern assigning a wrong code.", "labels": [], "entities": []}, {"text": "We exclude such cases from calculations.", "labels": [], "entities": []}, {"text": "With this strategy, we aim to evaluate the (average stratified) precision of the patterns (i.e. their intended property as high-precision classifiers) irrespective of their frequency.", "labels": [], "entities": [{"text": "precision", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.993433952331543}]}, {"text": "13 This is in contrast with estimating the precision of the entire pattern-based classifier, which would inevitably be dominated by high-frequency patterns.", "labels": [], "entities": [{"text": "precision", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.9985306262969971}]}, {"text": "The patterns for the categories with many seeds (groups A and B) perform well and compare favorably to seed patterns.", "labels": [], "entities": []}, {"text": "Group C produce very few coded sentences, and no sentence is correctly coded.", "labels": [], "entities": []}, {"text": "About eleven percent of all the sentences have been excluded.", "labels": [], "entities": []}, {"text": "The most common causes for that are sentences from sports news (34%), hypothetical constructions (23%), negation (22%), and wrongly coded actors (12%).", "labels": [], "entities": []}, {"text": "These sources of error are clearly failures not of the automatically generated patterns but the automated coder, e.g. its inability to take into account negation or check whether a pattern match is embedded under a modal verb.", "labels": [], "entities": []}, {"text": "The inter-coder agreement for this evaluation is modest, with a Cohen's kappa of 0.64.", "labels": [], "entities": []}, {"text": "We use the corpus of of English Gigaword documents annotated with protest events and resembling standard benchmark datasets for event extraction, e.g. the.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 128, "end_pos": 144, "type": "TASK", "confidence": 0.7303815186023712}]}, {"text": "Unlike the IR patterns for which we resort to a complex evaluation strategy, with this corpus, we can directly and fully automatically estimate both precision and recall.", "labels": [], "entities": [{"text": "IR", "start_pos": 11, "end_pos": 13, "type": "TASK", "confidence": 0.9616249203681946}, {"text": "precision", "start_pos": 149, "end_pos": 158, "type": "METRIC", "confidence": 0.9992627501487732}, {"text": "recall", "start_pos": 163, "end_pos": 169, "type": "METRIC", "confidence": 0.9970623850822449}]}, {"text": "We select sentences for which at least two of the coders code the same event.", "labels": [], "entities": []}, {"text": "We only use sentences which feature event types that correspond to the five CAMEO protest codes.", "labels": [], "entities": [{"text": "CAMEO protest codes", "start_pos": 76, "end_pos": 95, "type": "DATASET", "confidence": 0.7570285598436991}]}, {"text": "We obtain a total of 572 labeled sentences.", "labels": [], "entities": []}, {"text": "We randomly sample another 600 sentences of newswire text not from the corpus and use them to approximate the negative class, i.e. sentences without protest events.", "labels": [], "entities": []}, {"text": "Collective actions often do not mention a target actor directly (as in e.g. \"protest against the antigay law\").", "labels": [], "entities": []}, {"text": "Since an automated coder codes an event only if both source and target actors are matched, we choose to evaluate protest patterns without actor coding (otherwise, only very few events would be coded).", "labels": [], "entities": []}, {"text": "We note that some positive-class sentences cannot be coded without the knowledge of the context of the document.", "labels": [], "entities": []}, {"text": "Another complication is that protest events are often referred to with standalone nouns like \"demonstration\" or \"rally\" and not verb phrases denoting protest actions, e.g. \"the Florence demonstration was expected to be the biggest in the country\" or \"a group of rowdy youths broke away from the peaceful demonstration\".", "labels": [], "entities": [{"text": "Florence demonstration", "start_pos": 177, "end_pos": 199, "type": "DATASET", "confidence": 0.9090151190757751}]}, {"text": "Such cases, therefore, cannot be coded by a pattern-based coder that associates events with verb phrases.", "labels": [], "entities": []}, {"text": "This suggests that the upper bound on recall in this evaluation is much below 100%.", "labels": [], "entities": [{"text": "recall", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9995352029800415}]}, {"text": "We compare the following conditions: i) We code with seed patterns plus, for each of the five protest subcategories, the first m new patterns, when ranked by label score in descending order.", "labels": [], "entities": []}, {"text": "We let m range from 0 to 400.", "labels": [], "entities": []}, {"text": "We apply patterns by matching their dependency paths.", "labels": [], "entities": []}, {"text": "ii) As our baseline, we run PETRARCH with its default pattern dictionary (of a few hundreds of protest event patterns) and the actor coding function switched off.", "labels": [], "entities": [{"text": "PETRARCH", "start_pos": 28, "end_pos": 36, "type": "DATASET", "confidence": 0.7317596673965454}]}, {"text": "Additionally, we test a condition in which we consider category (051) Rally Support For as another protest category: Many protest events with a positive stance on an issue (as in \"rallied for immigrant rights\") end up being coded this code.", "labels": [], "entities": []}, {"text": "We manually check the events that either system finds in the negative-class sentences.", "labels": [], "entities": []}, {"text": "We find eight sentences with protest events, which we then count as instances of the positive class.", "labels": [], "entities": []}, {"text": "The results indicate () that new patterns dramatically increase recall and precision remains high.", "labels": [], "entities": [{"text": "recall", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.9993564486503601}, {"text": "precision", "start_pos": 75, "end_pos": 84, "type": "METRIC", "confidence": 0.9996252059936523}]}, {"text": "Most matches by PETRARCH come from matching single verbs: \"demonstrate\", \"protest\", \"rally\".", "labels": [], "entities": [{"text": "PETRARCH", "start_pos": 16, "end_pos": 24, "type": "DATASET", "confidence": 0.6046059131622314}]}, {"text": "The new patterns, on the other hand, are more lexically diverse: Patterns that fire feature forty seven (at m = 50) to fifty five (at m = 400) different verbs.", "labels": [], "entities": []}], "tableCaptions": []}