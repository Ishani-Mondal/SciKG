{"title": [{"text": "Zero-shot Relation Classification as Textual Entailment", "labels": [], "entities": [{"text": "Zero-shot Relation Classification", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.6916417678197225}, {"text": "Textual Entailment", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.686251312494278}]}], "abstractContent": [{"text": "We consider the task of relation classification, and pose this task as one of textual entailment.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 24, "end_pos": 47, "type": "TASK", "confidence": 0.9215513169765472}]}, {"text": "We show that this formulation leads to several advantages, including the ability to (i) perform zero-shot relation classification by exploiting relation descriptions, (ii) utilize existing tex-tual entailment models, and (iii) leverage readily available textual entailment datasets, to enhance the performance of relation classification systems.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 106, "end_pos": 129, "type": "TASK", "confidence": 0.7028786540031433}, {"text": "relation classification", "start_pos": 313, "end_pos": 336, "type": "TASK", "confidence": 0.7384499609470367}]}, {"text": "Our experiments show that the proposed approach achieves 20.16% and 61.32% in F1 zero-shot classification performance on two datasets, which further improved to 22.80% and 64.78% respectively with the use of conditional encoding.", "labels": [], "entities": [{"text": "F1", "start_pos": 78, "end_pos": 80, "type": "METRIC", "confidence": 0.9866175055503845}, {"text": "zero-shot classification", "start_pos": 81, "end_pos": 105, "type": "TASK", "confidence": 0.6873541474342346}]}], "introductionContent": [{"text": "The task of determining the relation between various entities from text is an important one for many natural language understanding systems, including question answering, knowledge base construction and web search.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 101, "end_pos": 131, "type": "TASK", "confidence": 0.686304529507955}, {"text": "question answering", "start_pos": 151, "end_pos": 169, "type": "TASK", "confidence": 0.9016100764274597}, {"text": "knowledge base construction", "start_pos": 171, "end_pos": 198, "type": "TASK", "confidence": 0.6186663309733073}]}, {"text": "Relation classification is an essential part of many high-performing relation extraction systems in the NIST-organised TAC Knowledge Base Population (TAC-KBP) track (.", "labels": [], "entities": [{"text": "Relation classification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9522121846675873}, {"text": "relation extraction", "start_pos": 69, "end_pos": 88, "type": "TASK", "confidence": 0.8166145980358124}, {"text": "NIST-organised TAC Knowledge Base Population (TAC-KBP) track", "start_pos": 104, "end_pos": 164, "type": "DATASET", "confidence": 0.927889002694024}]}, {"text": "As a result of its wide application, many approaches and systems have been proposed for this task (.", "labels": [], "entities": []}, {"text": "A shortcoming common to previous proposed approaches, however, is that they identify only relations observed at training time, and are unable to generalize to new (unobserved) relations attest time.", "labels": [], "entities": []}, {"text": "To address this challenge, we propose to formulate relation classification as follows: Given a unit of text T which mentions a subject X and a candidate object Y of a knowledge base relation R(X, Y ), and a natural language description d of R, we wish to evaluate whether T expresses R(X, Y ).", "labels": [], "entities": [{"text": "relation classification", "start_pos": 51, "end_pos": 74, "type": "TASK", "confidence": 0.7952222228050232}]}, {"text": "We formulate this task as a textual entailment problem in which the unit of text and the relation description can be considered as the premise P and hypothesis H respectively.", "labels": [], "entities": []}, {"text": "The challenge then becomes that of determining the truthfulness of the hypothesis given the premise.", "labels": [], "entities": []}, {"text": "gives examples of knowledge base relations and their natural language descriptions.", "labels": [], "entities": []}, {"text": "This formulation brings a number of advantages.", "labels": [], "entities": []}, {"text": "First, we are able to perform zero-shot classification of new relations by generalizing from the descriptions of seen training relations to those of unseen relations attest time.", "labels": [], "entities": [{"text": "zero-shot classification", "start_pos": 30, "end_pos": 54, "type": "TASK", "confidence": 0.5915375202894211}]}, {"text": "Given a collection of relations, for instance, spouse(X,Y) and city of birth(X,Y) together with their natural language descriptions and training examples, we can learn a model that can classify other instances of these relations, as well as instances of other relations that were not observed at training time, for instance child(X,Y), given their descriptions.", "labels": [], "entities": []}, {"text": "In addition to being able to utilize existing state-ofthe-art textual entailment models for relation classification, our approach can use distant supervision data together with data from textual entailment as additional supervision for relation classification.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 92, "end_pos": 115, "type": "TASK", "confidence": 0.9062401950359344}, {"text": "relation classification", "start_pos": 236, "end_pos": 259, "type": "TASK", "confidence": 0.8914948403835297}]}, {"text": "In experiments on two datasets, we assess the performance of our approach in two supervision settings: in a zero-shot setting, where no supervision examples are available for new relations, and in a few-shot setting, where our models have access to limited supervision examples of new relations.", "labels": [], "entities": []}, {"text": "In the former setting our approach achieves 20.16% and 61.32% in F1 classification performance in the two datasets considered, which further improved to 22.80% and 64.78% respectively with the use of conditional encoding.", "labels": [], "entities": [{"text": "F1", "start_pos": 65, "end_pos": 67, "type": "METRIC", "confidence": 0.9875501990318298}]}, {"text": "Similar improvements hold in the latter setting as well.", "labels": [], "entities": []}, {"text": "Y is the designer of X: Examples of relations, entities, sample text instances, and relation descriptions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our approach using the datasets of and ().", "labels": [], "entities": []}, {"text": "The dataset of (LMU-RC) is split into training, development and evaluation sets.", "labels": [], "entities": []}, {"text": "The training set was generated by distant supervision, and the development and test data were obtained from manually annotated TAC-KBP system outputs.", "labels": [], "entities": []}, {"text": "We obtained the descriptions for the relations from the TAC-KBP relation ontology guidelines.", "labels": [], "entities": [{"text": "TAC-KBP relation ontology", "start_pos": 56, "end_pos": 81, "type": "TASK", "confidence": 0.680535634358724}]}, {"text": "This resulted in a dataset of about 6 million positive and negative instances, each consisting of a relation, its subject and object entities, a sentence containing both entities and a relation description.", "labels": [], "entities": []}, {"text": "We applied a similar process to the relation extraction dataset of () (UW-RE).", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.7368101924657822}, {"text": "UW-RE", "start_pos": 71, "end_pos": 76, "type": "DATASET", "confidence": 0.9063094258308411}]}, {"text": "It consists of 120 relations and a set of question templates for each relation, containing both positive and negative relation instances, with each instance consisting of a subject entity, a knowledge base relation, a question template for the relation, and a sentence retrieved from the subject entity's Wikipedia page.", "labels": [], "entities": []}, {"text": "We wrote descriptions for each of the 120 relations in the dataset, with each relation's question templates serving as a guide.", "labels": [], "entities": []}, {"text": "Thus all instances in the dataset (30 million positive and 2 million negative ones) now include the corresponding relation description, making them suitable for relation classification using our approach.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 161, "end_pos": 184, "type": "TASK", "confidence": 0.9175367057323456}]}, {"text": "In addition to the two datasets, we also utilize the MultiNLI natural language inference corpus ( in our experiments as a source of supervision.", "labels": [], "entities": [{"text": "MultiNLI natural language inference corpus", "start_pos": 53, "end_pos": 95, "type": "DATASET", "confidence": 0.8595905423164367}]}, {"text": "We map its entailment and contradiction class instances to positive and negative relation instances respectively.", "labels": [], "entities": []}, {"text": "We conduct two sets of experiments.", "labels": [], "entities": []}, {"text": "The first set of experiments tests the performance of our approach in the zero-shot setting, where no supervision instances are available for new relations (Section 5.1).", "labels": [], "entities": []}, {"text": "The second set of experiments measures the performance of our approach in the limited supervision regime, where varying levels of supervision is available (Section 5.2).", "labels": [], "entities": []}, {"text": "Implementation Details Our model is implemented in Tensorflow ( correspond to DS only supervision.", "labels": [], "entities": [{"text": "Implementation", "start_pos": 0, "end_pos": 14, "type": "METRIC", "confidence": 0.8730459809303284}]}, {"text": "We initialize word embeddings with 300D Glove () vectors.", "labels": [], "entities": []}, {"text": "We found a few epochs of training (generally less than 5) to be sufficient for convergence.", "labels": [], "entities": [{"text": "convergence", "start_pos": 79, "end_pos": 90, "type": "TASK", "confidence": 0.9144920110702515}]}, {"text": "We apply Dropout with a keep probability of 0.9 to all layers.", "labels": [], "entities": [{"text": "keep probability", "start_pos": 24, "end_pos": 40, "type": "METRIC", "confidence": 0.9828798174858093}]}, {"text": "The result reported for each experiment is the average taken over five runs with independent random initializations.", "labels": [], "entities": []}, {"text": "In order to prevent overfitting to specific entities, we mask out the subject and object entities with the tokens SUBJECT ENTITY and OBJECT ENTITY respectively.", "labels": [], "entities": [{"text": "OBJECT ENTITY", "start_pos": 133, "end_pos": 146, "type": "METRIC", "confidence": 0.8816275596618652}]}], "tableCaptions": [{"text": " Table 2: Zero-shot relation learning results for  ESIM and CIM.", "labels": [], "entities": []}, {"text": " Table 3: Zero-shot relation learning results for  model CIM pre-trained on two sources of data:  Textual Entailment (TE), or both Distant Supervi- sion and Textual Entailment (TE+DS). The results  in", "labels": [], "entities": []}]}