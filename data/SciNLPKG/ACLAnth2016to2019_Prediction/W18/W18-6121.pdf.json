{"title": [{"text": "Classification of Tweets about Reported Events using Neural Networks", "labels": [], "entities": [{"text": "Classification of Tweets about Reported Events", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.8796868125597636}]}], "abstractContent": [{"text": "We developed a system that automatically extracts \"Event-describing Tweets\" which include incidents or accidents information for creating news reports.", "labels": [], "entities": []}, {"text": "Event-describing Tweets can be classified into \"Reported-event Tweets\" and \"New-information Tweets.\"", "labels": [], "entities": []}, {"text": "Reported-event Tweets cite news agencies or user generated content sites, and New-information Tweets are other Event-describing Tweets.", "labels": [], "entities": []}, {"text": "A system is needed to classify them so that creators of factual TV programs can use them in their productions.", "labels": [], "entities": []}, {"text": "Proposing this Tweet classification task is one of the contributions of this paper, because no prior papers have used the same task even though program creators and other events information collectors have to do it to extract required information from social networking sites.", "labels": [], "entities": [{"text": "Tweet classification task", "start_pos": 15, "end_pos": 40, "type": "TASK", "confidence": 0.90113765001297}]}, {"text": "To classify Tweets in this task, this paper proposes a method to input and concatenate character and word sequences in Japanese Tweets by using convolutional neural networks.", "labels": [], "entities": []}, {"text": "This proposed method is another contribution of this paper.", "labels": [], "entities": []}, {"text": "For comparison, character or word input methods and other neural networks are also used.", "labels": [], "entities": []}, {"text": "Results show that a system using the proposed method and architectures can classify Tweets with an F1 score of 88 %.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9860957860946655}]}], "introductionContent": [{"text": "Many companies including news agencies have increasingly been extracting news information from postings on Social Networking Sites (SNSs) such as Twitter and Facebook and using it for various purposes.", "labels": [], "entities": [{"text": "extracting news information from postings on Social Networking Sites (SNSs)", "start_pos": 62, "end_pos": 137, "type": "TASK", "confidence": 0.7792860070864359}]}, {"text": "However, choosing important information for news reports from Twitter is very tough, because Twitter contains avast amount of posts.", "labels": [], "entities": []}, {"text": "For this reason, many researchers have studied how to extract important posts for each purpose (;.", "labels": [], "entities": []}, {"text": "A system using Neural Networks (NNs) has been developed by using models that are trained by extracting Tweets in factual TV program production, and these systems extract \"Event-describing Tweets (EVENT)\" which include incidents or accidents information for news reports from a large amount of Tweets (.", "labels": [], "entities": []}, {"text": "However, there are many Tweets, so there can be many extracted Tweets which include EVENT for news reports about any event.", "labels": [], "entities": [{"text": "EVENT", "start_pos": 84, "end_pos": 89, "type": "METRIC", "confidence": 0.9990400671958923}]}, {"text": "Hence, people have difficulty monitoring all EVENT.", "labels": [], "entities": [{"text": "EVENT", "start_pos": 45, "end_pos": 50, "type": "METRIC", "confidence": 0.9007153511047363}]}, {"text": "In addition, EVENT are used differently in different types of programs.", "labels": [], "entities": [{"text": "EVENT", "start_pos": 13, "end_pos": 18, "type": "METRIC", "confidence": 0.9559136629104614}]}, {"text": "For these purposes, it is better to display only Tweets suitable to the program contents.", "labels": [], "entities": []}, {"text": "For example, program creators who want to obtain primary reports of an event posted by Twitter users do not require Tweets putout by news agencies and User Generated Content (UGC) sites or Tweets that quote or cite them.", "labels": [], "entities": []}, {"text": "The part of new information of these Tweets is able to begotten by crawling each site, so no longer these Tweets do not include new events information for program creators.", "labels": [], "entities": []}, {"text": "We call these Tweets \"I: Reportedevent Tweets (REPORTED)\" and others \"II: Newinformation Tweets (NEW).\"", "labels": [], "entities": []}, {"text": "Both types of Tweets are requested for different reasons.", "labels": [], "entities": []}, {"text": "Only types of Tweets suitable to creators' purpose need to be displayed, but extracting EVENT and classifying them are essentially different processes.", "labels": [], "entities": []}, {"text": "For these reasons, this paper uses a two-stage processing system that separates EVENT from a large amount of Tweets by using an existing system and classifies them into REPORTED and NEW by using text-based machine learning methods in real-time (Section 4).", "labels": [], "entities": [{"text": "REPORTED", "start_pos": 169, "end_pos": 177, "type": "METRIC", "confidence": 0.9351087212562561}]}, {"text": "Our proposed method inputs both character and word sequences (Section 5.2).", "labels": [], "entities": []}, {"text": "Both proposed and conventional methods use several NN architectures including Recurrent NNs (RNNs) and Convolutional NNs (CNNs) (Sec-tion 5).", "labels": [], "entities": []}, {"text": "Evaluation results show that the proposed method outperformed the conventional methods in all NN architectures.", "labels": [], "entities": []}, {"text": "This paper makes two contributions.", "labels": [], "entities": []}, {"text": "One is proposing anew task for classifying extracted EVENT into two classes: REPORTED and NEW.", "labels": [], "entities": [{"text": "classifying extracted EVENT", "start_pos": 31, "end_pos": 58, "type": "TASK", "confidence": 0.7323790192604065}, {"text": "REPORTED", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9946326017379761}, {"text": "NEW", "start_pos": 90, "end_pos": 93, "type": "DATASET", "confidence": 0.7462552189826965}]}, {"text": "TV program creators need to do this task for program production automatically and do it first to track reports about an event.", "labels": [], "entities": []}, {"text": "However, there have been no prior studies about this task.", "labels": [], "entities": []}, {"text": "The other is proposing anew method for NN architectures that inputs entire character sequences and entire word sequences in parallel and concatenates them in the intermediate layer and evaluating its performance.", "labels": [], "entities": []}, {"text": "This method can utilize the advantages of character sequences (i.e., there are fewer unknown characters than unknown words and it does not need morphological analyzers even when in Japanese which is very difficult to divide words especially for noisy texts) and word sequences (i.e., words are more effective than characters for the task).", "labels": [], "entities": []}, {"text": "The method can be used for any other tasks that need to both character and word sequences.", "labels": [], "entities": []}], "datasetContent": [{"text": "The performances of classification methods are evaluated in an experimental evaluation.", "labels": [], "entities": []}, {"text": "For comparison, baseline methods are used that use keyword filtering or Support Vector Machines (SVMs), which are well known to having high classification performance (.", "labels": [], "entities": [{"text": "keyword filtering", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.7104179561138153}]}, {"text": "In this paper,  For both training data and test data, EVENT for news reports extracted by the extraction process in Section 4.1 are used.", "labels": [], "entities": [{"text": "EVENT", "start_pos": 54, "end_pos": 59, "type": "METRIC", "confidence": 0.9994664788246155}]}, {"text": "Training data is all 44,670 Tweets obtained in the extraction process on June 6th, 8th, 10th, and 12th, 2017.", "labels": [], "entities": []}, {"text": "Test data is 10,000 randomly sampled Tweets obtained in the extraction process output Tweets on July 6th, 8th, 10th, and 12th, 2017.", "labels": [], "entities": []}, {"text": "Output data is annotated into three categories I-1 \u20dd: REPORTED with explicit sources, I-2 \u20dd: REPORTED without explicit sources, and II: NEW by an annotator person.", "labels": [], "entities": [{"text": "REPORTED", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9520065784454346}, {"text": "REPORTED", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.9058117866516113}]}, {"text": "shows the amount of each type of annotated data.", "labels": [], "entities": []}, {"text": "shows the configuration of experimental parameters.", "labels": [], "entities": []}, {"text": "shows precision, recall, and F1 score for each method with input as character, word, or character and word.", "labels": [], "entities": [{"text": "precision", "start_pos": 6, "end_pos": 15, "type": "METRIC", "confidence": 0.9996418952941895}, {"text": "recall", "start_pos": 17, "end_pos": 23, "type": "METRIC", "confidence": 0.9992339611053467}, {"text": "F1 score", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9830222427845001}]}, {"text": "shows recall performance of using REPORTED to evaluate the performance with and without explicit sources.", "labels": [], "entities": [{"text": "recall", "start_pos": 6, "end_pos": 12, "type": "METRIC", "confidence": 0.9987099170684814}, {"text": "REPORTED", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9768623113632202}]}, {"text": "False negatives are judged for only REPORTED and cannot be divided into REPORTED with and without explicit sources, thus precision and F1 score cannot be used in this evaluation.", "labels": [], "entities": [{"text": "REPORTED", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9903895258903503}, {"text": "REPORTED", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9807181358337402}, {"text": "precision", "start_pos": 121, "end_pos": 130, "type": "METRIC", "confidence": 0.9997598528862}, {"text": "F1 score", "start_pos": 135, "end_pos": 143, "type": "METRIC", "confidence": 0.9897024035453796}]}, {"text": "shows the time required to learn each NN.", "labels": [], "entities": []}, {"text": "Finally, shows the F1 score of SVM baseline methods and CNN architectures trained by each number of random sampled training data.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9771610498428345}]}, {"text": "From, the keyword baseline method has 94.1% precision and 34.0% recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9995042085647583}, {"text": "recall", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.9991269707679749}]}, {"text": "From, its recall is 73.5 % lower when using only I-2 \u20dd than when using only I-1 \u20dd (3.4 % vs. 76.9 %).", "labels": [], "entities": [{"text": "recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9997351765632629}]}, {"text": "All NN architectures outperform all baseline methods.", "labels": [], "entities": []}, {"text": "Although word input using FFNN, which has the lowest F1 score of the NN architectures, has the same precision as the SVM word input baseline method, which has highest F1 score of the baseline methods, it has higher recall (76.7 % vs. 75.7 %) and F1 score (84.2 % vs. 83.6 %).", "labels": [], "entities": [{"text": "F1 score", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9777429401874542}, {"text": "precision", "start_pos": 100, "end_pos": 109, "type": "METRIC", "confidence": 0.9990320205688477}, {"text": "F1 score", "start_pos": 167, "end_pos": 175, "type": "METRIC", "confidence": 0.9845653474330902}, {"text": "recall", "start_pos": 215, "end_pos": 221, "type": "METRIC", "confidence": 0.9993215799331665}, {"text": "F1 score", "start_pos": 246, "end_pos": 254, "type": "METRIC", "confidence": 0.9912185966968536}]}, {"text": "Its recall is 22.5 % lower when using only I-2 \u20dd than when using only I-1 \u20dd (67.3 % vs. 89.8 %).", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9997037053108215}]}, {"text": "In each NN architecture, the F1 score for character input is 0.3-2.0% higher than for word input.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9882029294967651}]}, {"text": "When both characters and words are input, LSTM has the highest F1 score, 0.5-2.2% higher than those of other NNs.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.989645391702652}]}, {"text": "When the conventional method is used, the highest F1 score so far is 86.7 % for LSTM architecture using character input.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9884289801120758}]}, {"text": "For this LSTM recall is 15.8 % higher when using only I-1 \u20dd than when using only I-2 \u20dd (94.6 % vs. 78.8 %).", "labels": [], "entities": [{"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9672819972038269}]}, {"text": "The proposed concat input method has a higher F1 score than character input for each NN architecture.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.988324910402298}]}, {"text": "Especially, F1 scores for the LSTM and CNN architectures improved from 86.7 % and 86.2 % to 88.2%.", "labels": [], "entities": [{"text": "F1", "start_pos": 12, "end_pos": 14, "type": "METRIC", "confidence": 0.9997288584709167}]}, {"text": "With the proposed concat input method, the difference between recall for CNNs with and without explicit sources is only 18.5 % (95% vs. 76.5%), whereas it is 22.1% and 23.8% with character and word input NNs.", "labels": [], "entities": [{"text": "recall", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.9988025426864624}]}, {"text": "In addition, the training time of the CNN architecture is almost 1/3 that of the LSTM architecture, as shown in Table 6.", "labels": [], "entities": []}, {"text": "From, baseline SVM methods have higher F1 scores than CNN architectures when they are trained by using fewer than 10,000 training data.", "labels": [], "entities": [{"text": "F1 scores", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.983587384223938}]}, {"text": "However, CNN architectures have higher F1 scores than SVM methods when they are trained by using more than 25,000 training data.", "labels": [], "entities": [{"text": "F1 scores", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9843024909496307}]}, {"text": "The architecture using the proposed method has a lower F1 score than other architectures when trained by using fewer than 13,000 training data but has the highest F1 score when trained by using more than 20,000 training data.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9890193343162537}, {"text": "F1 score", "start_pos": 163, "end_pos": 171, "type": "METRIC", "confidence": 0.9870352447032928}]}, {"text": "For the keyword baseline method, since Tweets with the same source used as training data can be detected for I-1 \u20dd in test data, there are few false detections and overall precision is relatively high.", "labels": [], "entities": [{"text": "precision", "start_pos": 172, "end_pos": 181, "type": "METRIC", "confidence": 0.9995896220207214}]}, {"text": "However, the keyword baseline method can barely detect Tweets for I-2 \u20dd.", "labels": [], "entities": []}, {"text": "In contrast, all other methods can obtain recall rates of at least 67 % for I-      gathered on the basis of feedback from the TV program production, so training each time the kind of classification changes is also assumed.", "labels": [], "entities": [{"text": "recall rates", "start_pos": 42, "end_pos": 54, "type": "METRIC", "confidence": 0.9891280829906464}, {"text": "I-", "start_pos": 76, "end_pos": 78, "type": "TASK", "confidence": 0.7082040309906006}]}, {"text": "Under these conditions, a short training time is highly convenient and is a big advantage.", "labels": [], "entities": []}, {"text": "From this result, a CNN using the proposed method has the best balance of speed and accuracy, so it is the most suitable for our system.", "labels": [], "entities": [{"text": "speed", "start_pos": 74, "end_pos": 79, "type": "METRIC", "confidence": 0.9969045519828796}, {"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9986675977706909}]}, {"text": "CNN architectures trained by using a few training data (less than 10,000) have lower F1 scores than SVM methods, seems to be caused by CNN architectures having many training parameters.", "labels": [], "entities": [{"text": "F1 scores", "start_pos": 85, "end_pos": 94, "type": "METRIC", "confidence": 0.9840537011623383}]}, {"text": "Specifically, the CNN architecture using the proposed method has the lowest F1 score when it has the most training parameters.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9892652928829193}]}, {"text": "However, it has the highest F1 score when it is trained by using a lot of training data.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9862565100193024}]}, {"text": "When collecting at least 10,000 and ideally more than 30,000 training data, NN architectures are effective for the classification task in this paper.", "labels": [], "entities": [{"text": "classification", "start_pos": 115, "end_pos": 129, "type": "TASK", "confidence": 0.964686393737793}]}], "tableCaptions": [{"text": " Table 2: No. of each Tweets.", "labels": [], "entities": [{"text": "No.", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9807166457176208}]}, {"text": " Table 3: Configuration of experimental parameters.", "labels": [], "entities": []}, {"text": " Table 4: Macro average performance of proposed clas- sification methods (%).", "labels": [], "entities": []}, {"text": " Table 5: Macro average recall performance for types of  each test data (%).", "labels": [], "entities": [{"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.8534860610961914}]}, {"text": " Table 6: Training time of NNs (seconds).", "labels": [], "entities": [{"text": "Training time", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9122230708599091}]}]}