{"title": [{"text": "A Sequential Matching Framework for Multi-Turn Response Selection in Retrieval-Based Chatbots under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) license Computational Linguistics", "labels": [], "entities": [{"text": "Sequential Matching", "start_pos": 2, "end_pos": 21, "type": "TASK", "confidence": 0.7175805866718292}, {"text": "Multi-Turn Response Selection", "start_pos": 36, "end_pos": 65, "type": "TASK", "confidence": 0.7332217892011007}]}], "abstractContent": [{"text": "Volume 45, Number 1 We study the problem of response selection for multi-turn conversation in retrieval-based chatbots.", "labels": [], "entities": [{"text": "response selection", "start_pos": 44, "end_pos": 62, "type": "TASK", "confidence": 0.7871224880218506}]}, {"text": "The task involves matching a response candidate with a conversation context, the challenges for which include how to recognize important parts of the context, and how to model the relationships among utterances in the context.", "labels": [], "entities": []}, {"text": "Existing matching methods may lose important information in contexts as we can interpret them with a unified framework in which contexts are transformed to fixed-length vectors without any interaction with responses before matching.", "labels": [], "entities": []}, {"text": "This motivates us to propose anew matching framework that can sufficiently carry important information in contexts to matching and model relationships among utterances at the same time.", "labels": [], "entities": []}, {"text": "The new framework, which we calla sequential matching framework (SMF), lets each utterance in a context interact with a response candidate at the first step and transforms the pair to a matching vector.", "labels": [], "entities": []}, {"text": "The matching vectors are then accumulated following the order of the utterances in the context with a recurrent neural network (RNN) that models relationships among utterances.", "labels": [], "entities": []}, {"text": "Context-response matching is then calculated with the hidden states of the RNN.", "labels": [], "entities": []}, {"text": "Under SMF, we propose a sequential convolutional network and sequential attention network and conduct experiments on two public data sets to test their performance.", "labels": [], "entities": [{"text": "SMF", "start_pos": 6, "end_pos": 9, "type": "TASK", "confidence": 0.9687747359275818}]}, {"text": "Experiment results show that both models can significantly outperform state-of-the-art matching methods.", "labels": [], "entities": []}, {"text": "We also show that the models are interpretable with visualizations that provide us insights on how they capture and leverage important information in contexts for matching.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent years have witnessed a surge of interest on building conversational agents both in industry and academia.", "labels": [], "entities": []}, {"text": "Existing conversational agents can be categorized into taskoriented dialog systems and non-task-oriented chatbots.", "labels": [], "entities": []}, {"text": "Dialog systems focus on helping people complete specific tasks in vertical domains (), such as flight booking, bus route enquiry, restaurant recommendation, and so forth; chatbots aim to naturally and meaningfully converse with humans on open domain topics.", "labels": [], "entities": [{"text": "flight booking, bus route enquiry, restaurant recommendation", "start_pos": 95, "end_pos": 155, "type": "TASK", "confidence": 0.6207253701157041}]}, {"text": "Building an open domain chatbot is challenging, because it requires the conversational engine to be capable of responding to any input from humans that covers a wide range of topics.", "labels": [], "entities": []}, {"text": "To address the problem, researchers have considered leveraging the large amount of conversation data available on the Internet, and proposed generation-based methods) and retrieval-based methods (; Ji, Lu, and Li 2014;; Yan, Song, and Wu 2016;).", "labels": [], "entities": []}, {"text": "Generation-based methods generate responses with natural language generation models learned from conversation data, while retrieval-based methods re-use the existing responses by selecting proper ones from an index of the conversation data.", "labels": [], "entities": []}, {"text": "In this work, we study the problem of response selection in retrieval-based chatbots, because retrieval-based chatbots have the advantage of returning informative and fluent responses.", "labels": [], "entities": [{"text": "response selection", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.8017741143703461}]}, {"text": "Although most existing work on retrieval-based chatbots studies response selection for single-turn conversation () in which conversation history is ignored, we study the problem in a multi-turn scenario.", "labels": [], "entities": []}, {"text": "Ina chatbot, multi-turn response selection takes a message and utterances in its previous turns as an input and selects a response that is natural and relevant to the entire context.", "labels": [], "entities": [{"text": "multi-turn response selection", "start_pos": 13, "end_pos": 42, "type": "TASK", "confidence": 0.585901697476705}]}, {"text": "A key step in response selection is measuring matching degree between an input and response candidates.", "labels": [], "entities": [{"text": "response selection", "start_pos": 14, "end_pos": 32, "type": "TASK", "confidence": 0.9370450079441071}, {"text": "matching degree", "start_pos": 46, "end_pos": 61, "type": "METRIC", "confidence": 0.9173310101032257}]}, {"text": "Different from single-turn conversation, in which the input is a single utterance (i.e., the message), multi-turn conversation requires context-response 164 matching where both the current message and the utterances in its previous turns should betaken into consideration.", "labels": [], "entities": []}, {"text": "The challenges of the task include (1) how to extract important information (words, phrases, and sentences) from the context and leverage the information in matching; and (2) how to model relationships and dependencies among the utterances in the context.", "labels": [], "entities": []}, {"text": "uses an example to illustrate the challenges.", "labels": [], "entities": []}, {"text": "First, to find a proper response for the context, the chatbot must know that \"hold a drum class\" and \"drum\" are important points.", "labels": [], "entities": []}, {"text": "Without them, it may return a response relevant to the message (i.e., Turn-5 in the context) but nonsensical in the context (e.g., \"what lessons do you want?\").", "labels": [], "entities": []}, {"text": "On the other hand, words like \"Shanghai\" and \"Lujiazui\" are less useful and even noisy to response selection.", "labels": [], "entities": [{"text": "Shanghai", "start_pos": 31, "end_pos": 39, "type": "DATASET", "confidence": 0.9197016358375549}, {"text": "response selection", "start_pos": 90, "end_pos": 108, "type": "TASK", "confidence": 0.8244573771953583}]}, {"text": "The responses from the chatbot may drift to the topic of \"Shanghai\" if the chatbot pays significant attention to these words.", "labels": [], "entities": []}, {"text": "Therefore, it is crucial yet non-trivial to let the chatbot understand the important points in the context and leverage them in matching and at the same time circumvent noise.", "labels": [], "entities": []}, {"text": "Second, there is a clear dependency between Turn-5 and Turn-2 in the context, and the order of utterances matters in response selection because there will be different proper responses if we exchange Turn-3 and Turn-5.", "labels": [], "entities": [{"text": "response selection", "start_pos": 117, "end_pos": 135, "type": "TASK", "confidence": 0.7610493302345276}]}, {"text": "Existing work, including the recurrent neural network architectures proposed by, the deep learning to respond architecture proposed by, and the multi-view architecture proposed by, may lose important information in context-response matching because they follow the same paradigm to perform matching, which suffers clear drawbacks.", "labels": [], "entities": [{"text": "context-response matching", "start_pos": 215, "end_pos": 240, "type": "TASK", "confidence": 0.7080628275871277}]}, {"text": "In fact, although these models have different structures, they can be interpreted with a unified framework: A context and a response are first individually represented as vectors, and then their matching score is computed with the vectors.", "labels": [], "entities": []}, {"text": "The context representation includes two layers.", "labels": [], "entities": []}, {"text": "The first layer represents utterances in the context, and the second layer takes the output of the first layer as an input and represents the entire context.", "labels": [], "entities": []}, {"text": "The existing work differs in how they design the context representation and the response representation and how they calculate the matching score with the two representations.", "labels": [], "entities": []}, {"text": "The framework view unifies the existing models and indicates the common drawbacks they have: everything in the context is compressed to one or more fixed-length vectors before matching is conducted; and there is no interaction between the context and the response in the formation of their representations.", "labels": [], "entities": []}, {"text": "The context is represented without enough supervision from the response, and so is the response.", "labels": [], "entities": []}, {"text": "To overcome the drawbacks, we propose a sequential matching network (SMN) for context-response matching in our early work () where we construct An example of multi-turn conversation.", "labels": [], "entities": [{"text": "sequential matching network (SMN)", "start_pos": 40, "end_pos": 73, "type": "TASK", "confidence": 0.6699163417021433}, {"text": "context-response matching", "start_pos": 78, "end_pos": 103, "type": "TASK", "confidence": 0.7178847938776016}]}], "datasetContent": [{"text": "We test SAN and SCN on two public data sets with both quantitative metrics and qualitative analysis.", "labels": [], "entities": []}, {"text": "In experiments on the Ubuntu corpus, we followed and used recall at position kin n candidates (R n @k) as evaluation metrics.", "labels": [], "entities": [{"text": "Ubuntu corpus", "start_pos": 22, "end_pos": 35, "type": "DATASET", "confidence": 0.9170688092708588}, {"text": "recall", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.9852451682090759}]}, {"text": "Here the matching models are required to return k most likely responses, and Rn @k = 1 if the true response is among the k candidates.", "labels": [], "entities": []}, {"text": "Rn @k will become larger when k gets larger or n gets smaller.", "labels": [], "entities": []}, {"text": "Rn @k has bias when there are multiple true candidates fora context.", "labels": [], "entities": []}, {"text": "Hence, on the Douban corpus, apart from Rn @ks, we also followed the convention of information retrieval and used mean average precision (MAP) (Baeza-Yates,), mean reciprocal rank (MRR), and precision at position 1 (P@1) as evaluation metrics, which are defined as follows where rank i refers to the position of the first relevant response to context s i in the ranking list; r j refers to the response ranked at the j-th position; rel(r j , s i ) = 1 if r j is an appropriate response to context s i , otherwise rel(r j , s i ) = 0; r top1 is the response ranked at the top position; S is the universal set of contexts; and N r denotes the number of retrieved responses.", "labels": [], "entities": [{"text": "Douban corpus", "start_pos": 14, "end_pos": 27, "type": "DATASET", "confidence": 0.8847026526927948}, {"text": "information retrieval", "start_pos": 83, "end_pos": 104, "type": "TASK", "confidence": 0.7291990965604782}, {"text": "mean average precision (MAP)", "start_pos": 114, "end_pos": 142, "type": "METRIC", "confidence": 0.8848232527573904}, {"text": "mean reciprocal rank (MRR)", "start_pos": 159, "end_pos": 185, "type": "METRIC", "confidence": 0.8836260338624319}, {"text": "precision", "start_pos": 191, "end_pos": 200, "type": "METRIC", "confidence": 0.993013322353363}]}, {"text": "We did not calculate R 2 @1 for the test data in the Douban corpus because one context could have more than one correct response, and we have to randomly sample one for R 2 @1, which may bring bias to the evaluation.", "labels": [], "entities": [{"text": "R 2 @1", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9445044994354248}, {"text": "Douban corpus", "start_pos": 53, "end_pos": 66, "type": "DATASET", "confidence": 0.9023977816104889}]}, {"text": "SAN is better than SCN on both data sets, which might be attributed to three reasons.", "labels": [], "entities": [{"text": "SAN", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.5550340414047241}]}, {"text": "The first reason is that SAN uses vectors instead of scalars to represent interactions between words or text segments.", "labels": [], "entities": []}, {"text": "Therefore, the matching vectors in SAN can encode more information from the pairs than those in SCN.", "labels": [], "entities": []}, {"text": "The second reason is that SAN uses a soft attention mechanism to emphasize important words or segments Evaluation results on the Ubuntu corpus.", "labels": [], "entities": [{"text": "Ubuntu corpus", "start_pos": 129, "end_pos": 142, "type": "DATASET", "confidence": 0.9421173334121704}]}, {"text": "Subscripts including last, static, and dynamic indicate three approaches to predicting a matching score as described in Section 5.3.", "labels": [], "entities": []}, {"text": "Numbers in bold mean that the improvement from the models is statistically significant over the best baseline method.", "labels": [], "entities": []}, {"text": "R 2 @1 R 10 @1 R 10 @2 R 10 @5  Evaluation results on the Douban corpus.", "labels": [], "entities": [{"text": "Douban corpus", "start_pos": 58, "end_pos": 71, "type": "DATASET", "confidence": 0.9498060643672943}]}, {"text": "Notations have the same meaning as those in.", "labels": [], "entities": []}, {"text": "On R 10 @5, only SAN significantly outperforms baseline methods.", "labels": [], "entities": []}, {"text": "in utterances, whereas SCN uses a max pooling operation to select important information from similarity matrices.", "labels": [], "entities": []}, {"text": "When multiple words or segments are important in an utterance-response pair, a max pooling operation just selects the top one, but the attention mechanism can leverage all of them.", "labels": [], "entities": []}, {"text": "The last reason is that SAN models the sequential relationship and dependency among words or segments in the interaction aggregation module, whereas SCN only considers n-grams.", "labels": [], "entities": []}, {"text": "The three approaches to matching prediction do not show much difference in both SCN and SAN, but dynamic average and static average are better than the last state on the Ubuntu corpus and worse than it on the Douban corpus.", "labels": [], "entities": [{"text": "matching prediction", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.9650150835514069}, {"text": "Ubuntu corpus", "start_pos": 170, "end_pos": 183, "type": "DATASET", "confidence": 0.961685836315155}, {"text": "Douban corpus", "start_pos": 209, "end_pos": 222, "type": "DATASET", "confidence": 0.9440621435642242}]}, {"text": "This is because contexts in the Ubuntu corpus are longer than those in the Douban corpus (average context length 10.1 vs. 6.7), and thus the last hidden state may lose information in history on the Ubuntu data.", "labels": [], "entities": [{"text": "Ubuntu corpus", "start_pos": 32, "end_pos": 45, "type": "DATASET", "confidence": 0.9224682748317719}, {"text": "Douban corpus", "start_pos": 75, "end_pos": 88, "type": "DATASET", "confidence": 0.9348771572113037}, {"text": "Ubuntu data", "start_pos": 198, "end_pos": 209, "type": "DATASET", "confidence": 0.9404771327972412}]}, {"text": "In contrast, the Douban corpus has shorter contexts but longer utterances (average utterance length 18.5 vs. 12.4), and thus noise maybe involved in response selection if more hidden states are taken into consideration.", "labels": [], "entities": [{"text": "Douban corpus", "start_pos": 17, "end_pos": 30, "type": "DATASET", "confidence": 0.9362783133983612}, {"text": "response selection", "start_pos": 149, "end_pos": 167, "type": "TASK", "confidence": 0.7608632445335388}]}], "tableCaptions": [{"text": " Table 3  Statistics of the two data sets.", "labels": [], "entities": []}, {"text": " Table 4  Evaluation results on the Ubuntu corpus. Subscripts including last, static, and dynamic indicate  three approaches to predicting a matching score as described in Section 5.3. Numbers in bold  mean that the improvement from the models is statistically significant over the best baseline  method.", "labels": [], "entities": [{"text": "Ubuntu corpus", "start_pos": 36, "end_pos": 49, "type": "DATASET", "confidence": 0.93217733502388}]}, {"text": " Table 4.  On R 10 @5, only SAN significantly outperforms baseline methods.", "labels": [], "entities": []}, {"text": " Table 6  Evaluation results of model ablation.", "labels": [], "entities": []}, {"text": " Table 7  Evaluation results in terms of different word embedding sizes.", "labels": [], "entities": []}]}