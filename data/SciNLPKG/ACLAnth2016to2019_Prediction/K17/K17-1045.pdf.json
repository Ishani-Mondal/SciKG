{"title": [], "abstractContent": [{"text": "We propose a neural multi-document sum-marization (MDS) system that incorporates sentence relation graphs.", "labels": [], "entities": []}, {"text": "We employ a Graph Convolutional Network (GCN) on the relation graphs, with sentence em-beddings obtained from Recurrent Neural Networks as input node features.", "labels": [], "entities": []}, {"text": "Through multiple layer-wise propagation, the GCN generates high-level hidden sentence features for salience estimation.", "labels": [], "entities": [{"text": "salience estimation", "start_pos": 99, "end_pos": 118, "type": "TASK", "confidence": 0.852223128080368}]}, {"text": "We then use a greedy heuristic to extract salient sentences while avoiding redundancy.", "labels": [], "entities": []}, {"text": "In our experiments on DUC 2004, we consider three types of sentence relation graphs and demonstrate the advantage of combining sentence relations in graphs with the representation power of deep neural networks.", "labels": [], "entities": [{"text": "DUC 2004", "start_pos": 22, "end_pos": 30, "type": "DATASET", "confidence": 0.9519063234329224}]}, {"text": "Our model improves upon traditional graph-based extractive approaches and the vanilla GRU sequence model with no graph, and it achieves competitive results against other state-of-the-art multi-document summarization systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "Document summarization aims to produce fluent and coherent summaries covering salient information in the documents.", "labels": [], "entities": [{"text": "Document summarization", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.92336505651474}]}, {"text": "Many previous summarization systems employ an extractive approach by identifying and concatenating the most salient text units (often whole sentences) in the document.", "labels": [], "entities": [{"text": "summarization", "start_pos": 14, "end_pos": 27, "type": "TASK", "confidence": 0.9702641367912292}]}, {"text": "Traditional extractive summarizers produce the summary in two steps: sentence ranking and sentence selection.", "labels": [], "entities": [{"text": "sentence ranking", "start_pos": 69, "end_pos": 85, "type": "TASK", "confidence": 0.7213454693555832}, {"text": "sentence selection", "start_pos": 90, "end_pos": 108, "type": "TASK", "confidence": 0.7554654181003571}]}, {"text": "First, they utilize humanengineered features such as sentence position and length, word frequency and importance), among others, to rank sentence salience.", "labels": [], "entities": []}, {"text": "Then, they select summary-worthy sentences using a range of algorithms, such as graph centrality (), constraint optimization via Integer Linear Programming, or Support Vector Regression ( algorithms.", "labels": [], "entities": [{"text": "constraint optimization", "start_pos": 101, "end_pos": 124, "type": "TASK", "confidence": 0.6951341927051544}, {"text": "Support Vector Regression", "start_pos": 160, "end_pos": 185, "type": "TASK", "confidence": 0.5718479653199514}]}, {"text": "Optionally, sentence reordering) can follow to improve coherence of the summary.", "labels": [], "entities": []}, {"text": "Recently, thanks to their strong representation power, neural approaches have become popular in text summarization, especially in sentence compression () and single-document summarization.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 96, "end_pos": 114, "type": "TASK", "confidence": 0.747683048248291}, {"text": "sentence compression", "start_pos": 130, "end_pos": 150, "type": "TASK", "confidence": 0.7571028769016266}, {"text": "single-document summarization", "start_pos": 158, "end_pos": 187, "type": "TASK", "confidence": 0.6648075580596924}]}, {"text": "Despite their popularity, neural networks still have issues when dealing with multi-document summarization (MDS).", "labels": [], "entities": [{"text": "multi-document summarization (MDS)", "start_pos": 78, "end_pos": 112, "type": "TASK", "confidence": 0.8246858179569244}]}, {"text": "In previous neural multi-document summarizers (, all the sentences in the same document cluster are processed independently.", "labels": [], "entities": []}, {"text": "Hence, the relationships between sentences and thus the relationships between different documents are ignored.", "labels": [], "entities": []}, {"text": "However, demonstrates the importance of considering discourse relations among sentences in multi-document summarization.", "labels": [], "entities": []}, {"text": "This work proposes a multi-document summarization system that exploits the representational power of deep neural networks and the sentence relation information encoded in graph representations of document clusters.", "labels": [], "entities": [{"text": "multi-document summarization", "start_pos": 21, "end_pos": 49, "type": "TASK", "confidence": 0.5673894733190536}]}, {"text": "Specifically, we apply Graph Convolutional Networks () on sentence relation graphs.", "labels": [], "entities": []}, {"text": "First, we discuss three different techniques to produce sentence relation graphs, where nodes represent sentences in a cluster and edges capture the connections between sentences.", "labels": [], "entities": []}, {"text": "Given a relation graph, our summarization model apples a Graph Convolutional Network (GCN), which takes in sentence embeddings from Recurrent Neural Networks as input node features.", "labels": [], "entities": []}, {"text": "Through multiple layer-wise prop-agation, the GCN generates high-level hidden features for the sentences.", "labels": [], "entities": []}, {"text": "We then obtain sentence salience estimations through a regression on top, and extract salient sentences in a greedy manner while avoiding redundancy.", "labels": [], "entities": [{"text": "sentence salience estimations", "start_pos": 15, "end_pos": 44, "type": "TASK", "confidence": 0.7206012010574341}]}, {"text": "We evaluate our model on the DUC 2004 multidocument summarization (MDS) task.", "labels": [], "entities": [{"text": "DUC 2004 multidocument summarization (MDS) task", "start_pos": 29, "end_pos": 76, "type": "TASK", "confidence": 0.8521112501621246}]}, {"text": "Our model shows a clear advantage over traditional graphbased extractive summarizers, as well as a baseline GRU model that does not use any graph, and achieves competitive results with other state-ofthe-art MDS systems.", "labels": [], "entities": []}, {"text": "This work provides anew gateway to incorporating graph-based techniques into neural summarization.", "labels": [], "entities": [{"text": "neural summarization", "start_pos": 77, "end_pos": 97, "type": "TASK", "confidence": 0.6128954887390137}]}], "datasetContent": [{"text": "In this section, we evaluate our model on benchmark MDS data sets, and compare with other state-of-the-art systems.", "labels": [], "entities": [{"text": "MDS data sets", "start_pos": 52, "end_pos": 65, "type": "DATASET", "confidence": 0.8146963020165762}]}, {"text": "We aim to show that our model, by combining sentence relations in graphs with the representation power of deep neural networks, can improve upon other traditional graphbased extractive approaches and the vanilla GRU model which does not use any graph.", "labels": [], "entities": []}, {"text": "In addition,  we further study the effect of graph and different graph representations on the summarization performance and investigate the correlation of graph structure and sentence salience estimation.", "labels": [], "entities": [{"text": "summarization", "start_pos": 94, "end_pos": 107, "type": "TASK", "confidence": 0.9862797260284424}, {"text": "sentence salience estimation", "start_pos": 175, "end_pos": 203, "type": "TASK", "confidence": 0.7644835511843363}]}, {"text": "We use the benchmark data sets from the Document Understanding Conferences (DUC) containing clusters of English news articles and human reference summaries.", "labels": [], "entities": []}, {"text": "We conduct four experiments on our model: three using each of the three types of graphs discussed earlier, and one without using any graph.", "labels": [], "entities": []}, {"text": "In the experiments with graphs, for each document cluster, we tokenize all the documents into sentences and generate a graph representation of their relations by the three methods: Cosine Similarity Graph, Approximate Discourse Graph (ADG) from G-Flow, and our Personalized Discourse Graph (PDG).", "labels": [], "entities": []}, {"text": "Note that for the Cosine Similarity Graph, we compute the tf-idf cosine similarity for every pair of sentences using the bag-of-word model and add an edge for similarity above 0.2.", "labels": [], "entities": []}, {"text": "The weight of the edge is the value of similarity.", "labels": [], "entities": [{"text": "similarity", "start_pos": 39, "end_pos": 49, "type": "METRIC", "confidence": 0.9733625650405884}]}, {"text": "We apply GCNs with the graphs in the final step of sentence encoding.", "labels": [], "entities": [{"text": "sentence encoding", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.7484980821609497}]}, {"text": "For the experiment without any graph, we omit the GCN part and simply use the GRU sentence and cluster encoders.", "labels": [], "entities": []}, {"text": "We use 300-dimensional pre-trained word2vec embeddings ( The rescaling factor \u03b1 in the objective function (Eq 13) is chosen as 40 from {10, 20, 30, 40, 50, 100} based on the validation performance.", "labels": [], "entities": [{"text": "rescaling factor \u03b1", "start_pos": 61, "end_pos": 79, "type": "METRIC", "confidence": 0.9416916569073995}]}, {"text": "The objective function is optimized using Adam ( stochastic gradient descent with a learning rate of 0.001 and a batch size of 1.", "labels": [], "entities": []}, {"text": "We use gradient clipping with a maximum gradient norm of 1.0.", "labels": [], "entities": []}, {"text": "The model is validated every 10 iterations, and the training is stopped early if the validation performance does not improve for 10 consecutive steps.", "labels": [], "entities": []}, {"text": "We trained using a single Tesla K80 GPU.", "labels": [], "entities": []}, {"text": "For all the experiments, the training took approximately 30 minutes until a stop.", "labels": [], "entities": []}, {"text": "First we take our simple GRU model as the baseline of the RNNbased regression approach.", "labels": [], "entities": []}, {"text": "As seen from the table, the addition of Cosine Similarity Graph on top of the GRU clearly boosts the performance.", "labels": [], "entities": [{"text": "Cosine Similarity Graph", "start_pos": 40, "end_pos": 63, "type": "METRIC", "confidence": 0.8297879099845886}, {"text": "GRU", "start_pos": 78, "end_pos": 81, "type": "DATASET", "confidence": 0.8133375644683838}]}, {"text": "Furthermore, the addition of ADG from G-Flow gives a slighly better performance.", "labels": [], "entities": []}, {"text": "Our Personalized Discourse Graph (PDG) enhances the R-1 score by more than 1.50.", "labels": [], "entities": [{"text": "R-1 score", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.8975378274917603}]}, {"text": "The improvement indicates that the combination of graphs and GCNs processes sentence relations across documents better than the vanilla RNN sequence models.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Statistics for DUC Multi-Document Sum- marization Data Sets.", "labels": [], "entities": [{"text": "DUC Multi-Document Sum- marization Data Sets", "start_pos": 25, "end_pos": 69, "type": "DATASET", "confidence": 0.7292213269642421}]}, {"text": " Table 3: ROUGE Recalls on DUC 2004. We show  mean (and standard deviation for R-1) over 10 re- peated trials for each of our experiments.", "labels": [], "entities": [{"text": "ROUGE Recalls", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.8193932175636292}, {"text": "DUC 2004", "start_pos": 27, "end_pos": 35, "type": "DATASET", "confidence": 0.8788148164749146}, {"text": "mean", "start_pos": 46, "end_pos": 50, "type": "METRIC", "confidence": 0.9788581728935242}]}, {"text": " Table 4: Training statistics for the four experi- ments. The first row shows the number of itera- tions the model took to reach the best validation  result before an early stop. The train cost and val- idation cost at that time step are shown in the sec- ond row and third row, respectively. All the values  are the average over 10 repeated trials.", "labels": [], "entities": [{"text": "val- idation cost", "start_pos": 198, "end_pos": 215, "type": "METRIC", "confidence": 0.933065801858902}]}, {"text": " Table 5: Characteristics of the three graph repre- sentations, averaged over the clusters (i.e. graphs)  in DUC 2004. Note that max edge weight in all  three representations is 1.0 due to rescaling for  consistency. The degree of each node is calculated  as the sum of edge weights.", "labels": [], "entities": [{"text": "DUC 2004", "start_pos": 109, "end_pos": 117, "type": "DATASET", "confidence": 0.9639894962310791}, {"text": "max edge weight", "start_pos": 129, "end_pos": 144, "type": "METRIC", "confidence": 0.8926024039586385}]}]}