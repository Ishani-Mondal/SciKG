{"title": [{"text": "Parsing for Grammatical Relations via Graph Merging", "labels": [], "entities": [{"text": "Grammatical Relations", "start_pos": 12, "end_pos": 33, "type": "TASK", "confidence": 0.8133201897144318}]}], "abstractContent": [{"text": "This paper is concerned with building deep grammatical relation (GR) analysis using data-driven approach.", "labels": [], "entities": [{"text": "deep grammatical relation (GR) analysis", "start_pos": 38, "end_pos": 77, "type": "TASK", "confidence": 0.745387213570731}]}, {"text": "To deal with this problem, we propose graph merging, anew perspective, for building flexible dependency graphs: Constructing complex graphs via constructing simple subgraphs.", "labels": [], "entities": [{"text": "graph merging", "start_pos": 38, "end_pos": 51, "type": "TASK", "confidence": 0.7644530832767487}]}, {"text": "We discuss two key problems in this perspective: (1) how to decompose a complex graph into simple subgraphs, and (2) how to combine subgraphs into a coherent complex graph.", "labels": [], "entities": []}, {"text": "Experiments demonstrate the effectiveness of graph merging.", "labels": [], "entities": [{"text": "graph merging", "start_pos": 45, "end_pos": 58, "type": "TASK", "confidence": 0.7280476242303848}]}, {"text": "Our parser reaches state-of-the-art performance and is significantly better than two transition-based parsers.", "labels": [], "entities": []}], "introductionContent": [{"text": "Grammatical relations (GRs) represent functional relationships between language units in a sentence.", "labels": [], "entities": []}, {"text": "Marking not only local but also a wide variety of long distance dependencies, GRs encode in-depth information of natural language sentences.", "labels": [], "entities": []}, {"text": "Traditionally, GRs are generated as a byproduct by grammar-guided parsers, e.g. RASP), C&C) and Enju ().", "labels": [], "entities": []}, {"text": "Very recently, by representing GR analysis using general directed dependency graphs, and showed that considerably good GR structures can be directly obtained using data-driven, transition-based parsing techniques.", "labels": [], "entities": [{"text": "GR analysis", "start_pos": 31, "end_pos": 42, "type": "TASK", "confidence": 0.9364337027072906}]}, {"text": "We follow their encouraging work and study the data-driven approach for producing GR analyses.", "labels": [], "entities": [{"text": "GR analyses", "start_pos": 82, "end_pos": 93, "type": "TASK", "confidence": 0.907968133687973}]}, {"text": "The key challenge of building GR graphs is due to their flexibility.", "labels": [], "entities": []}, {"text": "Different from surface syntax, the GR graphs are not constrained to trees, which is a fundamental consideration in designing parsing algorithms.", "labels": [], "entities": []}, {"text": "To deal with this problem, we propose graph merging, anew perspective, for building flexible representations.", "labels": [], "entities": [{"text": "graph merging", "start_pos": 38, "end_pos": 51, "type": "TASK", "confidence": 0.7532133460044861}]}, {"text": "The basic idea is to decompose a GR graph into several subgraphs, each of which captures most but not the complete information.", "labels": [], "entities": []}, {"text": "On the one hand, each subgraph is simple enough to allow efficient construction.", "labels": [], "entities": []}, {"text": "On the other hand, the combination of all subgraphs enables whole target GR structure to be produced.", "labels": [], "entities": []}, {"text": "There are two major problems in the graph merging perspective.", "labels": [], "entities": [{"text": "graph merging", "start_pos": 36, "end_pos": 49, "type": "TASK", "confidence": 0.7414135038852692}]}, {"text": "First, how to decompose a complex graph into simple subgraphs in a principled way?", "labels": [], "entities": []}, {"text": "To deal with this problem, we considered structure-specific properties of the syntactically-motivated GR graphs.", "labels": [], "entities": []}, {"text": "One key property is their reachability: Ina given GR graph, almost every node is reachable from a same and unique root.", "labels": [], "entities": []}, {"text": "If anode is not reachable, it is disconnected from other nodes.", "labels": [], "entities": []}, {"text": "This property ensures a GR graph to be successfully decomposed into limited number of forests, which in turn can be accurately and efficiently built via tree parsing.", "labels": [], "entities": []}, {"text": "We model the graph decomposition problem as an optimization problem and employ Lagrangian Relaxation for solutions.", "labels": [], "entities": [{"text": "graph decomposition", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.7671690881252289}]}, {"text": "Second, how to merge subgraphs into one coherent structure in a principled way?", "labels": [], "entities": []}, {"text": "The problem of finding an optimal graph that consistently combines the subgraphs obtained through individual models is non-trivial.", "labels": [], "entities": []}, {"text": "We treat this problem as a combinatory optimization problem and also employ Lagrangian Relaxation to solve the problem.", "labels": [], "entities": []}, {"text": "In particular, the parsing phase consists of two steps.", "labels": [], "entities": [{"text": "parsing phase", "start_pos": 19, "end_pos": 32, "type": "TASK", "confidence": 0.8991435766220093}]}, {"text": "First, graph-based models are applied to assign scores to individual arcs and various tuples of arcs.", "labels": [], "entities": []}, {"text": "Then, a Lagrangian Relaxation-based joint decoder is applied to efficiently produces globally optimal GR graphs according to all graph-based models.", "labels": [], "entities": []}, {"text": "We conduct experiments on Chinese GRBank ().", "labels": [], "entities": [{"text": "Chinese GRBank", "start_pos": 26, "end_pos": 40, "type": "DATASET", "confidence": 0.7772694826126099}]}, {"text": "Though our parser does not use any phrase-structure information, it produces high-quality GR analysis with respect to dependency matching.", "labels": [], "entities": [{"text": "GR analysis", "start_pos": 90, "end_pos": 101, "type": "TASK", "confidence": 0.8969580829143524}, {"text": "dependency matching", "start_pos": 118, "end_pos": 137, "type": "TASK", "confidence": 0.7557985186576843}]}, {"text": "Our parsers obtain a labeled fscore of 84.57 on the test set, resulting in an error reduction of 15.13% over's single system. and 10.86% over's system.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 78, "end_pos": 93, "type": "METRIC", "confidence": 0.9774436354637146}]}, {"text": "The remarkable parsing result demonstrates the effectiveness of the graph merging framework.", "labels": [], "entities": [{"text": "graph merging", "start_pos": 68, "end_pos": 81, "type": "TASK", "confidence": 0.7336121499538422}]}, {"text": "This framework can be adopted to other types of flexible representations, e.g. semantic dependency graphs ( and abstract meaning representations ().", "labels": [], "entities": []}], "datasetContent": [{"text": "We conduct experiments on Chinese GRBank (), an LFG-style GR corpus for Mandarin Chinese.", "labels": [], "entities": []}, {"text": "Linguistically speaking, this deep dependency annotation directly encodes information such as coordination, extraction, raising, control as well as many other long-range dependencies.", "labels": [], "entities": [{"text": "coordination, extraction, raising", "start_pos": 94, "end_pos": 127, "type": "TASK", "confidence": 0.7263247489929199}]}, {"text": "The selection for training, development, test data is also according to  The measure for comparing two dependency graphs is precision/recall of GR tokens which are defined as w h , w d , l tuples, where w h is the head, w dis the dependent and l is the relation.", "labels": [], "entities": [{"text": "precision", "start_pos": 124, "end_pos": 133, "type": "METRIC", "confidence": 0.9993849992752075}, {"text": "recall", "start_pos": 134, "end_pos": 140, "type": "METRIC", "confidence": 0.9766581654548645}]}, {"text": "Labeled precision/recall (LP/LR) is the ratio of tuples correctly identified by the automatic generator, while unlabeled precision/recall (UP/UR) is the ratio regardless of l.", "labels": [], "entities": [{"text": "precision/recall (LP/LR)", "start_pos": 8, "end_pos": 32, "type": "METRIC", "confidence": 0.8556649759411812}, {"text": "precision/recall (UP/UR)", "start_pos": 121, "end_pos": 145, "type": "METRIC", "confidence": 0.8490859866142273}]}, {"text": "F-score is a harmonic mean of precision and recall.", "labels": [], "entities": [{"text": "F-score", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9714664816856384}, {"text": "precision", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9995357990264893}, {"text": "recall", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.9972677230834961}]}, {"text": "These measures correspond to attachment scores (LAS/UAS) in dependency tree parsing.", "labels": [], "entities": [{"text": "attachment scores (LAS/UAS)", "start_pos": 29, "end_pos": 56, "type": "METRIC", "confidence": 0.8927062579563686}, {"text": "dependency tree parsing", "start_pos": 60, "end_pos": 83, "type": "TASK", "confidence": 0.6583877007166544}]}, {"text": "To evaluate our GR parsing models that will be introduced later, we also report these metrics.", "labels": [], "entities": [{"text": "GR parsing", "start_pos": 16, "end_pos": 26, "type": "TASK", "confidence": 0.8689206838607788}]}, {"text": "shows the results of graph decomposition on the training set.", "labels": [], "entities": []}, {"text": "If we use simple decomposition, say, directly extracting three trees from a graph, we get three subgraphs.", "labels": [], "entities": []}, {"text": "On the training set, each kind of the subgraphs cover around 90% edges and 30% sentences.", "labels": [], "entities": []}, {"text": "When we merge them together, they cover nearly 97% edges and over 70% sentences.", "labels": [], "entities": []}, {"text": "This indicates that the ability of a singletree is limited and three trees can cover most of the edges.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results on development set. SM is for Simple Merging, and LR for Lagrangian Relaxation.", "labels": [], "entities": [{"text": "SM", "start_pos": 38, "end_pos": 40, "type": "METRIC", "confidence": 0.9313046932220459}, {"text": "LR", "start_pos": 68, "end_pos": 70, "type": "METRIC", "confidence": 0.9485155344009399}]}, {"text": " Table 2: Lagrangian Relaxation Results on test set.", "labels": [], "entities": []}, {"text": " Table 3: Results of graph decomposition. SD is  for Simple Decomposition and LR for Lagrangian  Relaxation", "labels": [], "entities": [{"text": "graph decomposition", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.7284304648637772}, {"text": "LR", "start_pos": 78, "end_pos": 80, "type": "METRIC", "confidence": 0.9581040143966675}]}]}