{"title": [{"text": "Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies", "labels": [], "entities": [{"text": "Multilingual Parsing from Raw Text", "start_pos": 13, "end_pos": 47, "type": "TASK", "confidence": 0.8294702887535095}]}], "abstractContent": [{"text": "In this paper, we present our multilingual dependency parser developed for the CoNLL 2017 UD Shared Task dealing with \"Multilingual Parsing from Raw Text to Universal Dependencies\" 1.", "labels": [], "entities": [{"text": "CoNLL 2017 UD Shared Task", "start_pos": 79, "end_pos": 104, "type": "DATASET", "confidence": 0.8334473848342896}, {"text": "Multilingual Parsing from Raw Text", "start_pos": 119, "end_pos": 153, "type": "TASK", "confidence": 0.7595504999160767}]}, {"text": "Our parser extends the monolingual BIST-parser as a multi-source multilingual trainable parser.", "labels": [], "entities": [{"text": "BIST-parser", "start_pos": 35, "end_pos": 46, "type": "DATASET", "confidence": 0.7865746021270752}]}, {"text": "Thanks to multilingual word embeddings and one hot encodings for languages, our system can use both monolingual and multi-source training.", "labels": [], "entities": []}, {"text": "We trained 69 monolingual language models and 13 multilingual models for the shared task.", "labels": [], "entities": []}, {"text": "Our multilingual approach making use of different resources yield better results than the monolingual approach for 11 languages.", "labels": [], "entities": []}, {"text": "Our system ranked 5 th and achieved 70.93 overall LAS score over the 81 test corpora (macro-averaged LAS F1 score).", "labels": [], "entities": [{"text": "LAS score", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.9698852598667145}, {"text": "macro-averaged LAS F1 score", "start_pos": 86, "end_pos": 113, "type": "METRIC", "confidence": 0.6800581067800522}]}], "introductionContent": [{"text": "Many existing parsers are trainable on monolingual data.", "labels": [], "entities": []}, {"text": "Normally such systems take a monolingual corpus in input, along with monolingual word embeddings and possibly monolingual dictionaries as well as other knowledge sources.", "labels": [], "entities": []}, {"text": "However for resource-poor languages such as Kurmanji and Buryat 2 , there are generally not enough resources to train an efficient parser.", "labels": [], "entities": []}, {"text": "One reasonable approach is then to infer knowledge from similar languages.", "labels": [], "entities": []}, {"text": "Developing tools to process several languages including resource-poor languages has been conducted in many different ways in the past.", "labels": [], "entities": []}, {"text": "Thanks to Universal Dependency (, it is now possible to train a system for several languages from the same set of POS tags.", "labels": [], "entities": []}, {"text": "It has also been demonstrated that, with current machine learning approaches, parsing accuracy improves when using multilingual word embeddings (i.e. word embeddings inferred from corpora in different languages) even for resource-rich languages.", "labels": [], "entities": [{"text": "parsing", "start_pos": 78, "end_pos": 85, "type": "TASK", "confidence": 0.9722938537597656}, {"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.929039716720581}]}, {"text": "In this paper, we describe the development of a system using either a monolingual or multilingual strategy (depending on the kind of resources available for each language considered) for the CoNLL 2017 shared task (.", "labels": [], "entities": [{"text": "CoNLL 2017 shared task", "start_pos": 191, "end_pos": 213, "type": "DATASET", "confidence": 0.7971500009298325}]}, {"text": "For the multilingual model, we assume that learning over words and POS sequences is a first step from which better parsers can then be derived.", "labels": [], "entities": []}, {"text": "For this reason, we re-used most of the training algorithms implemented for the BIST-parser since these have proven to be effective when dealing with sequential information even for long sentences, thanks to bidirectional LSTM feature representations.", "labels": [], "entities": [{"text": "BIST-parser", "start_pos": 80, "end_pos": 91, "type": "DATASET", "confidence": 0.8868550062179565}]}, {"text": "In addition, our parser can also have recourse to multilingual word embeddings that merge different word vectors in a single vector space in order to get multi-source models.", "labels": [], "entities": []}, {"text": "As for multilingual word embeddings, we extend the bilingual word mapping approach ( to be able to deal with multilingual data.", "labels": [], "entities": [{"text": "bilingual word mapping", "start_pos": 51, "end_pos": 73, "type": "TASK", "confidence": 0.6758986711502075}]}, {"text": "We have only used this approach based on multilingual word embeddings for two different language groups in this experiment: (i) for resource-poor languages for which less than 30 sentences were provided for training such as surprise languages and Kazakh, and (ii) for another group of 7 resource-rich languages that are all Indo-European languages.", "labels": [], "entities": []}, {"text": "This is to show that even the analysis of resource-rich languages can be improved thanks to a multilingual approach.", "labels": [], "entities": []}, {"text": "Although we could theoretically train a single model for all the languages considered in the evaluation based on our multilingual approach, relevant results can only be obtained if one takes into account language similarities and typological information.", "labels": [], "entities": []}, {"text": "Moreover, given the limited time and the specific resource environment designed for the shared task, it was hard to get better results using a multilingual approach than using a monolingual approach for resource-rich languages since training new word embeddings requires time.", "labels": [], "entities": []}, {"text": "Thus, we processed 69 corpora with monolingual models, and only 13 corpora with our multilingual approach.", "labels": [], "entities": []}, {"text": "In what follows we describe the architecture of our system (section 2), our monolingual (section 3) as well as our multilingual approach (section 4).", "labels": [], "entities": []}, {"text": "Finally, we compare the results with the baseline provided by UDPipe1.1 and with the results of other teams (section 5).", "labels": [], "entities": [{"text": "UDPipe1.1", "start_pos": 62, "end_pos": 71, "type": "DATASET", "confidence": 0.955726683139801}]}], "datasetContent": [{"text": "Because we wanted to focus on the dependency parsing task, we used automatically annotated corpora for testing and also trained all models with the annotated corpora provided by UDPipe (.", "labels": [], "entities": [{"text": "dependency parsing task", "start_pos": 34, "end_pos": 57, "type": "TASK", "confidence": 0.849820613861084}, {"text": "UDPipe", "start_pos": 178, "end_pos": 184, "type": "DATASET", "confidence": 0.9231228232383728}]}, {"text": "As described in section 4, we used different word embeddings and training corpora for multilingual models.", "labels": [], "entities": []}, {"text": "As for monolingual models, we simply trained the system with monolingual embeddings (see details in section 3).", "labels": [], "entities": []}, {"text": "Overall results., 3 and 4 show the official results (except for it ParTUT), using the F1-measure computed by the TIRA platform () for the CoNLL 2017 Shared task 9 . Our system achieved 70.93 F1 (LAS) on the overall 81 test sets and ranked 5 th out of 33 teams.", "labels": [], "entities": [{"text": "ParTUT", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.8336890339851379}, {"text": "F1-measure", "start_pos": 86, "end_pos": 96, "type": "METRIC", "confidence": 0.9883421063423157}, {"text": "TIRA platform", "start_pos": 113, "end_pos": 126, "type": "DATASET", "confidence": 0.7493500411510468}, {"text": "CoNLL 2017 Shared task 9", "start_pos": 138, "end_pos": 162, "type": "DATASET", "confidence": 0.8787339210510254}, {"text": "F1 (LAS)", "start_pos": 191, "end_pos": 199, "type": "METRIC", "confidence": 0.9523640125989914}]}, {"text": "The average gap between the baseline obtained with UDPipe1.1 (Straka et al., 2016) and our system is 2.58 LAS in our favor.", "labels": [], "entities": [{"text": "LAS", "start_pos": 106, "end_pos": 109, "type": "METRIC", "confidence": 0.9953599572181702}]}, {"text": "Our system shows better results in avoiding over-fitting issues.", "labels": [], "entities": []}, {"text": "Performance gaps are narrowed when considering only http://universaldependencies.org/conll17/results.html PUD test sets (for example, our system ranked second best for processing English PUD and Russian PUD), which is encouraging for practical applications.", "labels": [], "entities": []}, {"text": "shows the results obtained when using the multilingual models on the small treebank dataset (fr partut, ga, gl treegal, kk, la, sl sst, ug, uk).", "labels": [], "entities": [{"text": "treebank dataset", "start_pos": 75, "end_pos": 91, "type": "DATASET", "confidence": 0.6893623918294907}]}, {"text": "We ranked 4 th , with 54.78 LAS score on this group of languages.", "labels": [], "entities": [{"text": "LAS score", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9745243489742279}]}, {"text": "However, in terms of extremely resource-poor languages (surprise languages), we have ranked only 12 th , with 36.93 LAS score.", "labels": [], "entities": [{"text": "LAS", "start_pos": 116, "end_pos": 119, "type": "METRIC", "confidence": 0.9966967105865479}]}, {"text": "This is slightly lower than the UDPipe1.1 baseline model: we assume this is the result of using half of the corpus for training surprise languages (section 4).", "labels": [], "entities": [{"text": "UDPipe1.1 baseline", "start_pos": 32, "end_pos": 50, "type": "DATASET", "confidence": 0.7737050354480743}]}, {"text": "If we compare monolingual models of surprise languages with multilingual ones, we see an improvement between 2.5 and 9.31 percent.", "labels": [], "entities": []}, {"text": "The same kind of improvement can be observed for the ParTUT group.", "labels": [], "entities": [{"text": "ParTUT group", "start_pos": 53, "end_pos": 65, "type": "DATASET", "confidence": 0.8954850435256958}]}, {"text": "In this case, the multilingual approach improves performance by almost 3 points.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Official experiment results with rank. (number): number of corpora", "labels": [], "entities": []}, {"text": " Table 3: Official experiment results processed by monolingual models.", "labels": [], "entities": []}, {"text": " Table 4: Official experiment results processed by multilingual models.", "labels": [], "entities": []}]}