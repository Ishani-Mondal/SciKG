{"title": [{"text": "Training Data Augmentation for Low-Resource Morphological Inflection", "labels": [], "entities": [{"text": "Training Data Augmentation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6096947193145752}, {"text": "Low-Resource Morphological Inflection", "start_pos": 31, "end_pos": 68, "type": "TASK", "confidence": 0.6457629402478536}]}], "abstractContent": [{"text": "This work describes the UoE-LMU submission for the CoNLL-SIGMORPHON 2017 Shared Task on Universal Morphological Reinflection, Subtask 1: given a lemma and target morphological tags, generate the target inflected form.", "labels": [], "entities": []}, {"text": "We evaluate several ways to improve performance in the 1000-example setting: three methods to augment the training data with identical input-output pairs (i.e., autoencod-ing), a heuristic approach to identify likely pairs of inflectional variants from an un-labeled corpus, and a method for cross-lingual knowledge transfer.", "labels": [], "entities": [{"text": "cross-lingual knowledge transfer", "start_pos": 292, "end_pos": 324, "type": "TASK", "confidence": 0.6389927268028259}]}, {"text": "We find that autoencoding random strings works surprisingly well, outperformed only slightly by autoencoding words from an unlabelled corpus.", "labels": [], "entities": []}, {"text": "The random string method also works well in the 10,000-example setting despite not being tuned for it.", "labels": [], "entities": []}, {"text": "Among 18 submissions our system takes 1st and 6th place in the 10k and 1k settings, respectively .", "labels": [], "entities": []}], "introductionContent": [{"text": "Morphological variation is a major contributor to the sparse data problem in NLP, especially for under-resourced languages. and) aimed to inspire researchers to develop better systems for morphological inflection across a wide range of languages with varying training resources.", "labels": [], "entities": [{"text": "Morphological variation", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8689909279346466}]}, {"text": "In 2016, when over 10,000 training examples were provided for each language, neural network-based systems performed considerably better than other approaches).", "labels": [], "entities": []}, {"text": "The 2017 Shared Task therefore included settings with different amounts of training data (100, 1000, or 10,000 examples), to examine which approaches might work best when data is even more limited.", "labels": [], "entities": []}, {"text": "We focus on the 1000-example setting of Subtask 1: given a lemma with its part of speech and target morphological tags, generate the target inflected form.", "labels": [], "entities": []}, {"text": "Our baseline system is the winning system from 2016, the morphological encoderdecoder (MED) from LMU (.", "labels": [], "entities": [{"text": "LMU", "start_pos": 97, "end_pos": 100, "type": "DATASET", "confidence": 0.9530623555183411}]}, {"text": "We explore methods for improving its performance in the face of fewer training examples, either with or without additional data from unlabeled corpora.", "labels": [], "entities": []}, {"text": "In particular, we focus on various training data augmentation methods.", "labels": [], "entities": []}, {"text": "One uses a heuristic approach to identify likely pairs of inflectional variants from an unlabeled corpus in an unsupervised way, and uses these as input-output pairs.", "labels": [], "entities": []}, {"text": "Three other methods augment the training data with identical input-output pairs-i.e., simultaneously training the network to perform autoencoding.", "labels": [], "entities": []}, {"text": "We compare three types of autoencoder inputs: either lemmas and inflected forms from the training data, words from an unlabeled corpus, or random strings.", "labels": [], "entities": []}, {"text": "We present detailed results and comparisons for various amounts of added training data for all 52 languages of the shared task.", "labels": [], "entities": []}, {"text": "We find that all methods improve considerably over the MED baseline (7.2-10.7% across all languages; a 15.5% improvement over the shared task baseline).", "labels": [], "entities": []}, {"text": "Most of the benefit comes with only 4k extra examples, but performance continues to improve up to 16k added examples.", "labels": [], "entities": []}, {"text": "After controlling for the amount of additional data, we see only a small benefit from autoencoding corpus words rather than random strings.", "labels": [], "entities": []}, {"text": "Using hypothesized morphological variants works as well as random strings.", "labels": [], "entities": []}, {"text": "These results suggest that the main advantage of all these methods is providing a strong bias towards learning the identity transformation and/or working as regularizers, rather than learning language-specific phonotactics or morpho-phonological changes.", "labels": [], "entities": []}, {"text": "Finally, following , we test whether cross-lingual knowledge transfer can help, by multilingual training of joint models for groups of up to 10 related languages.", "labels": [], "entities": [{"text": "cross-lingual knowledge transfer", "start_pos": 37, "end_pos": 69, "type": "TASK", "confidence": 0.6346677740414938}]}, {"text": "However, we find no improvement as compared to using an equivalent amount of random-string autoencoder examples.", "labels": [], "entities": []}, {"text": "Our final submission to the shared task consists of two submissions for Subtask 1 (Inflection): the random string autoencoder for the medium and high data settings of the restricted (main) track and the corpus word autoencoder for the medium data setting of the bonus track (track with external monolingual corpora).", "labels": [], "entities": []}, {"text": "All systems use 16K autoencoder examples and an ensemble of three training runs with majority voting.", "labels": [], "entities": []}, {"text": "In the high resource setting of the restricted track, our system outperforms all 17 other submissions, with an average test set accuracy of 95.32% over 52 languages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 128, "end_pos": 136, "type": "METRIC", "confidence": 0.9448165893554688}]}, {"text": "In the medium resource setting, among 18 submissions our system takes the 6th place with 81.02% (1.78% below the top system).", "labels": [], "entities": []}, {"text": "In the medium resource setting of the bonus track, among 2 submissions our system comes first with 82.37%.", "labels": [], "entities": []}], "datasetContent": [{"text": "Datasets The official shared task data consists of sets for 52 different languages, of which 40 were released as development languages.", "labels": [], "entities": []}, {"text": "We used these for our preliminary experiments to compare different systems and quantities of additional training data.", "labels": [], "entities": []}, {"text": "The remaining 12 \"surprise\" languages were released shortly before the test phase of the shared task, and we report results for our best systems on these as well.", "labels": [], "entities": []}, {"text": "In the \"medium\" training data setting, which we focus on in this work, 1000 training instances are given for each language, except for Scottish Gaelic with only 681 instances.", "labels": [], "entities": []}, {"text": "Additionally, development sets with 1000 instances are available for all languages except for Basque, Bengali, Haida, Welsh with 100 and Scottish Gaelic with 50.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: The average performance over all lan- guages except Haida and Khaling (see text).", "labels": [], "entities": []}, {"text": " Table 3: Multilingual training. We report average development set accuracies, weighted by the number  of examples in each development set. The letter X in AE-TD-RS-XK, stands for the number of random  string autoencoding examples added (see  \u00a74 for more details).", "labels": [], "entities": [{"text": "AE-TD-RS-XK", "start_pos": 156, "end_pos": 167, "type": "METRIC", "confidence": 0.9678235650062561}]}]}