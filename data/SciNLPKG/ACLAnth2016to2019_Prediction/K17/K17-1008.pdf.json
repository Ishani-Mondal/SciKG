{"title": [{"text": "Named Entity Disambiguation for Noisy Text", "labels": [], "entities": [{"text": "Entity Disambiguation", "start_pos": 6, "end_pos": 27, "type": "TASK", "confidence": 0.6862930953502655}]}], "abstractContent": [{"text": "We address the task of Named Entity Disambiguation (NED) for noisy text.", "labels": [], "entities": [{"text": "Named Entity Disambiguation (NED)", "start_pos": 23, "end_pos": 56, "type": "TASK", "confidence": 0.748631939291954}]}, {"text": "We present WikilinksNED, a large-scale NED dataset of text fragments from the web, which is significantly noisier and more challenging than existing news-based datasets.", "labels": [], "entities": []}, {"text": "To capture the limited and noisy local context surrounding each mention, we design a neural model and train it with a novel method for sampling informative negative examples.", "labels": [], "entities": []}, {"text": "We also describe anew way of initializing word and entity embeddings that significantly improves performance.", "labels": [], "entities": [{"text": "initializing word and entity embeddings", "start_pos": 29, "end_pos": 68, "type": "TASK", "confidence": 0.8118735194206238}]}, {"text": "Our model significantly outperforms existing state-of-the-art methods on WikilinksNED while achieving comparable performance on a smaller newswire dataset.", "labels": [], "entities": []}], "introductionContent": [{"text": "Named Entity Disambiguation (NED) is the task of linking mentions of entities in text to a given knowledge base, such as Freebase or Wikipedia.", "labels": [], "entities": [{"text": "Named Entity Disambiguation (NED)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7650570720434189}]}, {"text": "NED is a key component in Entity Linking (EL) systems, focusing on the disambiguation task itself, independently from the tasks of Named Entity Recognition (detecting mention bounds) and Candidate Generation (retrieving the set of potential candidate entities).", "labels": [], "entities": [{"text": "Entity Linking (EL)", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.7617487907409668}, {"text": "Named Entity Recognition", "start_pos": 131, "end_pos": 155, "type": "TASK", "confidence": 0.6543368399143219}, {"text": "Candidate Generation", "start_pos": 187, "end_pos": 207, "type": "TASK", "confidence": 0.801705926656723}]}, {"text": "NED has been recognized as an important component in NLP tasks such as semantic parsing.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 71, "end_pos": 87, "type": "TASK", "confidence": 0.728499636054039}]}, {"text": "Current research on NED is mostly driven by a number of standard datasets, such as CoNLL-YAGO), TAC KBP () and ACE ().", "labels": [], "entities": [{"text": "NED", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9382646083831787}, {"text": "CoNLL-YAGO", "start_pos": 83, "end_pos": 93, "type": "DATASET", "confidence": 0.7619946599006653}, {"text": "TAC KBP", "start_pos": 96, "end_pos": 103, "type": "DATASET", "confidence": 0.58649080991745}, {"text": "ACE", "start_pos": 111, "end_pos": 114, "type": "DATASET", "confidence": 0.8622108697891235}]}, {"text": "These datasets are based on news corpora and Wikipedia, which are naturally coherent, well-structured, and rich in context.", "labels": [], "entities": []}, {"text": "Global disambiguation models leverage this coherency by jointly disambiguating all the mentions in a single document.", "labels": [], "entities": []}, {"text": "However, domains such as webpage fragments, social media, or search queries, are often short, noisy, and less coherent; such domains lack the necessary contextual information for global methods to payoff, and present a more challenging setting in general.", "labels": [], "entities": []}, {"text": "In this work, we investigate the task of NED in a setting where only local and noisy context is available.", "labels": [], "entities": []}, {"text": "In particular, we create a dataset of 3.2M short text fragments extracted from web pages, each containing a mention of a named entity.", "labels": [], "entities": []}, {"text": "Our dataset is far larger than previously collected datasets, and contains 18K unique mentions linking to over 100K unique entities.", "labels": [], "entities": []}, {"text": "We have empirically found it to be noisier and more challenging than existing datasets.", "labels": [], "entities": []}, {"text": "For example: \"I had no choice but to experiment with other indoor games.", "labels": [], "entities": []}, {"text": "I was born in Atlantic City so the obvious next choice was Monopoly.", "labels": [], "entities": []}, {"text": "I played until I became a successful Captain of Industry.\"", "labels": [], "entities": []}, {"text": "This short fragment is considerably less structured and with a more personal tone than atypical news article.", "labels": [], "entities": []}, {"text": "It references the entity Monopoly (Game), however expressions such as \"experiment\" and \"Industry\" can distract a naive disambiguation model because they are also related the much more common entity Monopoly (economics term).", "labels": [], "entities": []}, {"text": "Some sense of local semantics must be considered in order to separate the useful signals (e.g. \"indoor games\", \"played\") from the noisy ones.", "labels": [], "entities": []}, {"text": "We therefore propose anew model that leverages local contextual information to disambiguate entities.", "labels": [], "entities": []}, {"text": "Our neural approach (based on RNNs with attention) leverages the vast amount of training data in WikilinksNED to learn representations for entity and context, allowing it to extract signals from noisy and unexpected context patterns.", "labels": [], "entities": []}, {"text": "While convolutional neural networks and probabilistic attention () have been applied to the task, this is the first model to use RNNs and a neural attention model for NED.", "labels": [], "entities": [{"text": "NED", "start_pos": 167, "end_pos": 170, "type": "TASK", "confidence": 0.9276837110519409}]}, {"text": "RNNs account for the sequential nature of textual context while the attention model is applied to reduce the impact of noise in the text.", "labels": [], "entities": []}, {"text": "Our experiments show that our model significantly outperforms existing state-of-the-art NED algorithms on WikilinksNED, suggesting that RNNs with attention are able to model short and noisy context better than current approaches.", "labels": [], "entities": []}, {"text": "In addition, we evaluate our algorithm on CoNLL-YAGO), a dataset of annotated news articles.", "labels": [], "entities": []}, {"text": "We use a simple domain adaptation technique since CoNLL-YAGO lacks a large enough training set for our model, and achieve comparable results to other state-of-the-art methods.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 16, "end_pos": 33, "type": "TASK", "confidence": 0.7573399245738983}]}, {"text": "These experiments highlight the difference between the two datasets, indicating that our NED benchmark is substantially more challenging.", "labels": [], "entities": []}, {"text": "Code and data used for our experiments can be found at https://github.com/ yotam-happy/NEDforNoisyText", "labels": [], "entities": [{"text": "NEDforNoisyText", "start_pos": 87, "end_pos": 102, "type": "DATASET", "confidence": 0.5001877546310425}]}], "datasetContent": [{"text": "We introduce WikilinksNED, a large-scale NED dataset based on text fragments from the web.", "labels": [], "entities": []}, {"text": "Our dataset is derived from the Wikilinks corpus (), which was constructed by crawling the web and collecting hyperlinks (mentions) linking to Wikipedia concepts (entities) and their surrounding text (context).", "labels": [], "entities": [{"text": "Wikilinks corpus", "start_pos": 32, "end_pos": 48, "type": "DATASET", "confidence": 0.8862648606300354}]}, {"text": "Wikilinks contains 40 million mentions covering 3 million entities, collected from over 10 million web pages.", "labels": [], "entities": [{"text": "Wikilinks", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9069038033485413}]}, {"text": "Wikilinks can be seen as a large-scale, naturally-occurring, crowd-sourced dataset where thousands of human annotators provide ground truths for mentions of interest.", "labels": [], "entities": []}, {"text": "This means that the dataset contains various kinds of noise, especially due to incoherent contexts.", "labels": [], "entities": []}, {"text": "The contextual noise presents an interesting test-case that supplements existing datasets that are sourced from mostly coherent and well-formed text.", "labels": [], "entities": []}, {"text": "To get a sense of textual noise we have setup a small experiment where we measure the similarity between entities mentioned in WikilinksNED and their surrounding context, and compare the results to CoNLL-YAGO.", "labels": [], "entities": []}, {"text": "We use state-of-the-art word and entity embeddings obtained from and compute cosine similarity between embeddings of the correct entity assignment and the mean of context words.", "labels": [], "entities": []}, {"text": "We compare results from all mentions in CoNLL-YAGO to a sample of 50000 web fragments taken from WikilinksNED, using a window of words of size 40 around entity mentions.", "labels": [], "entities": []}, {"text": "We find that similarity between context and correct entity is indeed lower for web mentions (0.163) than for CoNLL-YAGO mentions (0.188), and find this result to be statistically significant with very high probability (p < 10 \u22125 ) . This result indicates that web fragments in WikilinksNED are indeed noisier compared to CoNLL-YAGO documents.", "labels": [], "entities": [{"text": "similarity", "start_pos": 13, "end_pos": 23, "type": "METRIC", "confidence": 0.9810008406639099}]}, {"text": "We prepare our dataset from the local-context version of Wikilinks 1 , and resolve ground-truth links using a Wikipedia dump from April 2016 2 . We use the page and redirect tables for resolution, and keep the database pageid column as a unique identifier for Wikipedia entities.", "labels": [], "entities": [{"text": "Wikipedia dump from April 2016", "start_pos": 110, "end_pos": 140, "type": "DATASET", "confidence": 0.8906321406364441}]}, {"text": "We discard mentions where the ground-truth could not be resolved (only 3% of mentions).", "labels": [], "entities": []}, {"text": "We collect all pairs of mention m and entity e appearing in the dataset, and compute the number of times m refers toe (#(m, e)), as well as the conditional probability of e given m: P (e|m) = #(m, e)/ e #(m, e ).", "labels": [], "entities": []}, {"text": "Examining these distributions reveals many mentions belong to two extremes -either they have very little ambiguity, or they appear in the dataset only a handful of times and refer to different entities only a couple of times each.", "labels": [], "entities": []}, {"text": "We deem the former to be less interesting for the purpose of NED, and suspect the latter to be noise with high probability.", "labels": [], "entities": [{"text": "NED", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.7366474866867065}]}, {"text": "To filter these cases, we keep only mentions for which at least two different entities have 10 mentions each (#(m, e) \u2265 10) and consist of at least 10% of occurrences (P (e|m) \u2265 0.1).", "labels": [], "entities": []}, {"text": "This procedure aggressively filters our dataset and we are left with 3.2M mentions.", "labels": [], "entities": []}, {"text": "Finally, we randomly split the data into train (80%), validation (10%), and test (10%), according to website domains in order to minimize lexical memorization ().", "labels": [], "entities": []}, {"text": "In this section, we describe our experimental setup and compare our model to the state of the art on two datasets: our new WikilinksNED dataset, as well as the commonly-used CoNLL-YAGO dataset).", "labels": [], "entities": [{"text": "WikilinksNED dataset", "start_pos": 123, "end_pos": 143, "type": "DATASET", "confidence": 0.9230866730213165}, {"text": "CoNLL-YAGO dataset", "start_pos": 174, "end_pos": 192, "type": "DATASET", "confidence": 0.9491644501686096}]}, {"text": "We also examine the effect of different corrupt-sampling schemes, and of initializing our model with pre-trained word and entity embeddings.", "labels": [], "entities": []}, {"text": "In all experiments, our model was trained with fixed-size left and right contexts (20 words in each side).", "labels": [], "entities": []}, {"text": "We used a special padding symbol when the actual context was shorter than the window.", "labels": [], "entities": []}, {"text": "Further, we filtered stopwords using NLTK's stopword list prior to selecting the window in order to focus on more informative words.", "labels": [], "entities": [{"text": "NLTK's stopword list", "start_pos": 37, "end_pos": 57, "type": "DATASET", "confidence": 0.878651037812233}]}, {"text": "Our model was implemented using the: Evaluation on noisy web data (WikilinksNED)", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Evaluation on noisy web data (WikilinksNED)", "labels": [], "entities": []}, {"text": " Table 2: Evaluation of training steps on CoNLL- YAGO.", "labels": [], "entities": [{"text": "CoNLL- YAGO", "start_pos": 42, "end_pos": 53, "type": "DATASET", "confidence": 0.7143011291821798}]}, {"text": " Table 3: Evaluation on CoNLL-YAGO.", "labels": [], "entities": [{"text": "CoNLL-YAGO", "start_pos": 24, "end_pos": 34, "type": "DATASET", "confidence": 0.8273645043373108}]}]}