{"title": [], "abstractContent": [{"text": "This paper presents a collaborative partitioning algorithm-a novel ensemble-based approach to coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 94, "end_pos": 116, "type": "TASK", "confidence": 0.9612000286579132}]}, {"text": "Starting from the all-singleton partition, we search fora solution close to the en-semble's outputs in terms of a task-specific similarity measure.", "labels": [], "entities": []}, {"text": "Our approach assumes a loose integration of individual components of the ensemble and can therefore combine arbitrary coreference resolvers, regardless of their models.", "labels": [], "entities": []}, {"text": "Our experiments on the CoNLL dataset show that collaborative partitioning yields results superior to those attained by the individual components, for ensembles of both strong and weak systems.", "labels": [], "entities": [{"text": "CoNLL dataset", "start_pos": 23, "end_pos": 36, "type": "DATASET", "confidence": 0.961552083492279}]}, {"text": "Moreover, by applying the collaborative partitioning algorithm on top of three state-of-the-art resolvers, we obtain the second-best coreference performance reported so far in the literature (MELA v08 score of 64.47).", "labels": [], "entities": [{"text": "MELA v08 score", "start_pos": 192, "end_pos": 206, "type": "METRIC", "confidence": 0.7683906952540079}]}], "introductionContent": [{"text": "Coreference resolution has been one of the key areas of NLP for several decades.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9333692193031311}]}, {"text": "Major modeling breakthroughs have been achieved, not surprisingly, following three successful shared tasks, such as MUC), ACE () and, most recently, CoNLL).", "labels": [], "entities": [{"text": "MUC", "start_pos": 116, "end_pos": 119, "type": "DATASET", "confidence": 0.525170624256134}, {"text": "ACE", "start_pos": 122, "end_pos": 125, "type": "METRIC", "confidence": 0.7942379117012024}]}, {"text": "As of today, several high-performing systems are available publicly and, in addition, novel algorithms are being proposed regularly, even if without any code release.", "labels": [], "entities": []}, {"text": "Our study aims at making a good use of these resources through a novel ensemble resolution method.", "labels": [], "entities": [{"text": "ensemble resolution", "start_pos": 71, "end_pos": 90, "type": "TASK", "confidence": 0.7661924064159393}]}, {"text": "Coreference is a heterogeneous task that requires a combination of accurate and robust processing for relatively easy cases (e.g., namematching) with very complex modeling of difficult cases (e.g., nominal anaphora or some types of pronouns).", "labels": [], "entities": []}, {"text": "The general feeling in the community is that we are currently approaching the upper bound for the easy cases and our next step should involve more complex resolution.", "labels": [], "entities": []}, {"text": "If true, this means that most state-of-the-art systems should produce very similar outputs: correctly resolving easy anaphora and failing on less trivial examples.", "labels": [], "entities": []}, {"text": "scores the outputs of the three best systems from the CoNLL-2012 shared task against each other.", "labels": [], "entities": [{"text": "CoNLL-2012 shared task", "start_pos": 54, "end_pos": 76, "type": "DATASET", "confidence": 0.7646867632865906}]}, {"text": "As it can be seen, the three systems are rather different, each of them being only slightly closer to each other than to the gold key.", "labels": [], "entities": []}, {"text": "This suggests that a meta-algorithm could merge their outputs in an intelligent way, combining the correct decisions of individual systems to arrive at a superior partition.", "labels": [], "entities": []}, {"text": "Although several coreference resolution toolkits exist for over a decade, to our knowledge, there have been no attempts at trying to merge their outputs.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 17, "end_pos": 39, "type": "TASK", "confidence": 0.8945444524288177}]}, {"text": "The very few ensemble methods reported in the literature focus on combining several resolution strategies within the same system.", "labels": [], "entities": []}, {"text": "Following the success of the CoNLL shared task), however, multiple complex approaches have been investigated, with very different underlying models.", "labels": [], "entities": []}, {"text": "This means that a re-implementation of all these algorithms within a single system requires a considerable engineering effort.", "labels": [], "entities": []}, {"text": "In the present study, we combine the final outputs of the individual systems, without making any assumptions on their specifications.", "labels": [], "entities": []}, {"text": "This means that our approach is completely modular, allowing to combine third-party software as black boxes.", "labels": [], "entities": []}, {"text": "The present study aims at finding a partition combining the outputs of individual coreference resolvers in a collaborative way.", "labels": [], "entities": [{"text": "coreference resolvers", "start_pos": 82, "end_pos": 103, "type": "TASK", "confidence": 0.8070088326931}]}, {"text": "To this end, we search the space of possible partitions, starting from the all-singleton solution and incrementally growing coreference entities, with the objective of getting a partition similar to the individual outputs.", "labels": [], "entities": []}, {"text": "As a measure of similarity, we rely on task-specific metrics, such as, for example, MUC or MELA scores.", "labels": [], "entities": [{"text": "MUC", "start_pos": 84, "end_pos": 87, "type": "METRIC", "confidence": 0.8581350445747375}, {"text": "MELA", "start_pos": 91, "end_pos": 95, "type": "METRIC", "confidence": 0.9313094615936279}]}, {"text": "To our knowledge, this is the first ensemble-based approach to coreference, operating directly on the partition level.", "labels": [], "entities": []}, {"text": "While traditional ensemble techniques, such as boosting or co-training, have been successfully used for coreference resolution before, they are applicable to classification tasks and can only be used on lower levels (e.g., for classifying mention pairs).", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 104, "end_pos": 126, "type": "TASK", "confidence": 0.9519845545291901}]}, {"text": "Combining partitions directly is a non-trivial problem that requires an extra modeling effort.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In the next section, we discuss the previous ensemble-based approaches to coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 74, "end_pos": 96, "type": "TASK", "confidence": 0.9708222448825836}]}, {"text": "Section 3 presents our collaborative partitioning algorithm.", "labels": [], "entities": []}, {"text": "In Section 4, we evaluate our approach on the English portion of the OntoNotes dataset.", "labels": [], "entities": [{"text": "OntoNotes dataset", "start_pos": 69, "end_pos": 86, "type": "DATASET", "confidence": 0.8942168951034546}]}, {"text": "Section 5 summarizes our contributions and highlights directions for future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we evaluate empirically the performance of the collaborative partitioning approach fora variety of ensembles.", "labels": [], "entities": []}, {"text": "In particular, we investigate ensembles of different size and composition with respect to the components' quality and assess different coreference scoring metrics as criteria for partition similarity.", "labels": [], "entities": []}, {"text": "In our experiments, we rely on the English portion of the CoNLL-2012 dataset ().", "labels": [], "entities": [{"text": "CoNLL-2012 dataset", "start_pos": 58, "end_pos": 76, "type": "DATASET", "confidence": 0.9519623816013336}]}, {"text": "We use the outputs of the CoNLL submissions on the test data, made available publicly by the organizers.", "labels": [], "entities": []}, {"text": "To speedup the system, we use the techniques discussed in Section 3.1 above.", "labels": [], "entities": []}, {"text": "In particular, we rely on a very simple unweighted voting scheme: each component contributes equally to the final score.", "labels": [], "entities": []}, {"text": "The per-component score fora candidate merge between e 1 and e 2 is computed as follows: if either e 1 ore 2 are not represented in a component's output, it abstains from voting (score = 0).", "labels": [], "entities": []}, {"text": "Otherwise, the component upvotes candidate merges if the underlying coreference score increases (score = 2) and downvotes, if it decreases (score = \u22121).", "labels": [], "entities": []}, {"text": "The preference for positive votes (2 vs. 1) is motivated by the fact, that most state-of-the-art models explicitly model coreference, but not non-coreference: if two entities are annotated as non-coreferent by the system, it can be due to several factors, such as the lack of relevant features or algorithm peculiarities that limit the search space.", "labels": [], "entities": []}, {"text": "The positive information in the systems' output is therefore more reliable than the negative one.", "labels": [], "entities": []}, {"text": "The specific threshold (2 : 1) has been chosen arbitrary without any tuning.", "labels": [], "entities": []}, {"text": "Finally, the termination threshold has been set to 0.", "labels": [], "entities": [{"text": "termination threshold", "start_pos": 13, "end_pos": 34, "type": "METRIC", "confidence": 0.9705616235733032}]}], "tableCaptions": [{"text": " Table 1: Scoring top CoNLL-2012 systems  against each other, MELA v08.", "labels": [], "entities": [{"text": "MELA v08", "start_pos": 62, "end_pos": 70, "type": "DATASET", "confidence": 0.5520360171794891}]}, {"text": " Table 3: Collaborative partitioning with the 3 top CoNLL-2012 systems, using different coreference  metrics when assessing candidate merges. Boldface indicates the best performing system for each score.", "labels": [], "entities": []}, {"text": " Table 4: Ensembles of 3 classifiers for different tiers, using MELA for merging. Boldface indicates the  best performing system for each tier.", "labels": [], "entities": [{"text": "MELA", "start_pos": 64, "end_pos": 68, "type": "METRIC", "confidence": 0.9033933281898499}]}, {"text": " Table 5: Ensembles of 3 classifiers for different tiers, using MUC for merging. Boldface indicates the  best performing system for each tier.", "labels": [], "entities": [{"text": "MUC", "start_pos": 64, "end_pos": 67, "type": "DATASET", "confidence": 0.8219745755195618}]}, {"text": " Table 6: Ensembles of different sizes, using MUC  for merging.", "labels": [], "entities": [{"text": "MUC", "start_pos": 46, "end_pos": 49, "type": "DATASET", "confidence": 0.7935505509376526}]}, {"text": " Table 7: Competitive vs. collaborative partition- ing, using MELA for selection (competitive) or  merging (collaborative).", "labels": [], "entities": [{"text": "MELA", "start_pos": 62, "end_pos": 66, "type": "METRIC", "confidence": 0.6764400005340576}]}, {"text": " Table 8: Collaborative partitioning for state-of- the-art systems, using MELA for merging. Bold- face indicates the best result for each score.", "labels": [], "entities": [{"text": "MELA", "start_pos": 74, "end_pos": 78, "type": "METRIC", "confidence": 0.9178600907325745}]}]}