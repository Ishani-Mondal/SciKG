{"title": [{"text": "Align and Copy: UZH at SIGMORPHON 2017 Shared Task for Morphological Reinflection", "labels": [], "entities": [{"text": "Morphological Reinflection", "start_pos": 55, "end_pos": 81, "type": "TASK", "confidence": 0.8112908601760864}]}], "abstractContent": [{"text": "This paper presents the submissions by the University of Zurich to the SIGMOR-PHON 2017 shared task on morphological reinflection.", "labels": [], "entities": [{"text": "SIGMOR-PHON 2017 shared task", "start_pos": 71, "end_pos": 99, "type": "TASK", "confidence": 0.6003641337156296}, {"text": "morphological reinflection", "start_pos": 103, "end_pos": 129, "type": "TASK", "confidence": 0.7165627777576447}]}, {"text": "The task is to predict the inflected form given a lemma and a set of morpho-syntactic features.", "labels": [], "entities": []}, {"text": "We focus on neural network approaches that can tackle the task in a limited-resource setting.", "labels": [], "entities": []}, {"text": "As the transduction of the lemma into the inflected form is dominated by copying over lemma characters, we propose two recurrent neural network archi-tectures with hard monotonic attention that are strong at copying and, yet, substantially different in how they achieve this.", "labels": [], "entities": []}, {"text": "The first approach is an encoder-decoder model with a copy mechanism.", "labels": [], "entities": []}, {"text": "The second approach is a neural state-transition system over a set of explicit edit actions, including a designated COPY action.", "labels": [], "entities": []}, {"text": "We experiment with character alignment and find that naive, greedy alignment consistently produces strong results for some languages.", "labels": [], "entities": [{"text": "character alignment", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.8606845736503601}]}, {"text": "Our best system combination is the overall winner of the SIG-MORPHON 2017 Shared Task 1 without external resources.", "labels": [], "entities": [{"text": "SIG-MORPHON 2017 Shared Task 1", "start_pos": 57, "end_pos": 87, "type": "TASK", "confidence": 0.4920513153076172}]}, {"text": "At a setting with 100 training samples, both our approaches, as ensembles of models, outperform the next best competitor.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes our approaches and results for Task 1 (without external resources) of the CoNLL-SIGMORPHON 2017 challenge on Universal Morphological Reinflection (.", "labels": [], "entities": [{"text": "CoNLL-SIGMORPHON 2017 challenge on Universal Morphological Reinflection", "start_pos": 95, "end_pos": 166, "type": "TASK", "confidence": 0.6971723437309265}]}, {"text": "This task consists in generating inflected * These two authors contributed equally.", "labels": [], "entities": []}, {"text": "word forms for 52 languages given a lemma and a morphological feature specification) as input ( There are three task setups: a low setting where training data are only 100 (!) samples, a medium setting with 1K training samples, and a high setting with 10K samples.", "labels": [], "entities": []}, {"text": "We consider the problem of tackling morphological inflection generation at a low-resource setting with a neural network approach, which is hard for plain soft-attention encoder-decoder models.", "labels": [], "entities": [{"text": "tackling morphological inflection generation", "start_pos": 27, "end_pos": 71, "type": "TASK", "confidence": 0.6498232334852219}]}, {"text": "We present two systems that are based on the hard monotonic attention model of;, which is strong on smaller-sized training datasets.", "labels": [], "entities": []}, {"text": "We observe that to excel at a lowresource setting, a model needs to be good at copying lemma characters over to the inflected formby far the most common operation of string transduction in the morphological inflection generation task.", "labels": [], "entities": [{"text": "morphological inflection generation task", "start_pos": 193, "end_pos": 233, "type": "TASK", "confidence": 0.7139961495995522}]}, {"text": "In our first approach, we extend the hard monotonic attention model with a copy mechanism that produces a mixture distribution from the character generation and character copying distributions.", "labels": [], "entities": []}, {"text": "This idea is reminiscent of the pointer-generator model of and the CopyNet model of.", "labels": [], "entities": []}, {"text": "Our second approach is a neural state-transition system that explicitly learns the copy action and thus does away with character decoding altogether whenever a character needs to be copied over.", "labels": [], "entities": []}, {"text": "This approach is inspired by shift-reduce parsing with stack and transitionbased named entity recognition ().", "labels": [], "entities": [{"text": "transitionbased named entity recognition", "start_pos": 65, "end_pos": 105, "type": "TASK", "confidence": 0.6548435464501381}]}], "datasetContent": [{"text": "We submit seven runs: a) two runs (1 and 2) for the HACM model; b) two runs (3 and 4) for the system HACM HAEM alignment S NS N low 5 5 medium 5 5 3 high 5 3 2 MAX { Run 5, Run 6 } HAEM model; and c) three runs (5, 6, and 7) that combine both systems.", "labels": [], "entities": [{"text": "MAX", "start_pos": 160, "end_pos": 163, "type": "METRIC", "confidence": 0.9421236515045166}]}, {"text": "Detailed information on training regimes and the choice of hyperparameter values (e.g. layer dimensions, the application of dropout, etc.) for all the runs is provided in the Appendix.", "labels": [], "entities": []}, {"text": "Crucially, for both systems and all settings and languages, we train models with both smart and naive alignments of Section 2.3.", "labels": [], "entities": []}, {"text": "shows the number of single models for each system, setting, and alignment.", "labels": [], "entities": []}, {"text": "We decode using greedy search.", "labels": [], "entities": []}, {"text": "We apply a simple post-processing filter that replaces any inflected form containing an endlessly repeating character with the lemma.", "labels": [], "entities": []}, {"text": "This affects a small number of test samples-57 for HACM and 238 for HAEM across all languages and alignment regimes-and primarily at the low setting.", "labels": [], "entities": []}, {"text": "All runs aggregate the results of multiple single models, and we use a number of aggregation strategies.", "labels": [], "entities": []}, {"text": "For system runs 1 through 4, these are: Max strategy For each language l, we compute two ensembles over single models-one ensemble E(S) over smart alignment models and one ensemble E(N ) over naive alignment models.", "labels": [], "entities": []}, {"text": "We then pick the ensemble with the highest development set accuracy for l: Ensemble n strategy For each language l, we pick at most n models from all single models such that they have the best development set accuracies for l.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.7153884172439575}]}, {"text": "We then compute one ensemble over them: Runs 5, 6, and 7 are built with aggregation strategies that use as building blocks the MAX and ENSEMBLE n strategies.", "labels": [], "entities": [{"text": "MAX", "start_pos": 127, "end_pos": 130, "type": "DATASET", "confidence": 0.7160713076591492}]}, {"text": "shows the strategies employed in each run.", "labels": [], "entities": []}, {"text": "At the high setting, Runs 5, 6, and 7 additionally feature a single run produced with Nematus (), a soft-attention encoderdecoder system for machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 141, "end_pos": 160, "type": "TASK", "confidence": 0.764731764793396}]}, {"text": "In all these runs, the Nematus run complements the HAEM models, which perform much worse at the high setting on average.", "labels": [], "entities": []}, {"text": "We refer the reader to the Appendix for further information on data preprocessing, hyperparameter values, and training for the Nematus run.", "labels": [], "entities": []}, {"text": "gives an overview on the average (macro) performance for each run on the official development and test sets at all settings.", "labels": [], "entities": []}, {"text": "Accuracy measures the percentage of word forms that are inflected correctly (without a single character error).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9911144971847534}]}, {"text": "For the best system combination, we also report the average Levenshtein distance between the gold standard word form and the system prediction, which represents a softer criterion for correctness.", "labels": [], "entities": [{"text": "Levenshtein distance", "start_pos": 60, "end_pos": 80, "type": "METRIC", "confidence": 0.9091622531414032}]}, {"text": "Also, we include the performance of the shared task baseline system, which is a rule-based model that extracts prefix-changing and suffix-changing rules using alignments of each training sample with Levenshtein distance and associates the rules with the features of the sample.", "labels": [], "entities": []}, {"text": "6 All our official runs beat the baseline by a large margin on average in terms of accuracy and also in terms of Levenshtein distance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9996258020401001}, {"text": "Levenshtein distance", "start_pos": 113, "end_pos": 133, "type": "METRIC", "confidence": 0.6894459426403046}]}, {"text": "For all settings, we see an improvement by applying the more complex ensembling strategies (   At the low setting, HAEM outperforms HACM on average by 2-3 percentage points accuracy and is, therefore, especially suited fora low resource situation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 173, "end_pos": 181, "type": "METRIC", "confidence": 0.9933804273605347}]}, {"text": "At the medium setting, the performance of HACM is slightly better using smart alignments.", "labels": [], "entities": []}, {"text": "The HAEM system does not seem to learn well with naive alignment for this amount of data.", "labels": [], "entities": []}, {"text": "The poorer performance of HAEM whenever more training data are available is particularly obvious at the high-resource setting where the difference between HACM and HAEM is quite large.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Examples of generating German \"flog\" from \"fliegen\": HACM (left), HAEM (right). i is the  attention pointer, x i the currently attended lemma character, a the sequence of actions, y the output, t the  index over actions.", "labels": [], "entities": [{"text": "HACM", "start_pos": 63, "end_pos": 67, "type": "METRIC", "confidence": 0.9630845785140991}, {"text": "HAEM", "start_pos": 76, "end_pos": 80, "type": "METRIC", "confidence": 0.8381586074829102}]}, {"text": " Table 4: Macro average results over all languages for all settings on the official development and test set.  N=Naive alignment, S=Smart alignment, BS=Baseline system, Acc=Accuracy, Lev=Levenshtein.", "labels": [], "entities": [{"text": "Acc=Accuracy", "start_pos": 169, "end_pos": 181, "type": "METRIC", "confidence": 0.8085241715113322}]}]}