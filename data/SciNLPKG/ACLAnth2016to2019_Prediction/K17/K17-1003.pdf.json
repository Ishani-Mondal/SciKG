{"title": [{"text": "Exploring the Syntactic Abilities of RNNs with Multi-task Learning", "labels": [], "entities": []}], "abstractContent": [{"text": "Recent work has explored the syntactic abilities of RNNs using the subject-verb agreement task, which diagnoses sensitivity to sentence structure.", "labels": [], "entities": []}, {"text": "RNNs performed this task well in common cases, but faltered in complex sentences (Linzen et al., 2016).", "labels": [], "entities": []}, {"text": "We test whether these errors are due to inherent limitations of the architecture or to the relatively indirect supervision provided by most agreement dependencies in a corpus.", "labels": [], "entities": []}, {"text": "We trained a single RNN to perform both the agreement task and an additional task, either CCG su-pertagging or language modeling.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 111, "end_pos": 128, "type": "TASK", "confidence": 0.7446525692939758}]}, {"text": "Multi-task training led to significantly lower error rates, in particular on complex sentences , suggesting that RNNs have the ability to evolve more sophisticated syntactic representations than shown before.", "labels": [], "entities": [{"text": "error", "start_pos": 47, "end_pos": 52, "type": "METRIC", "confidence": 0.9542158842086792}]}, {"text": "We also show that easily available agreement training data can improve performance on other syntactic tasks, in particular when only a limited amount of training data is available for those tasks.", "labels": [], "entities": []}, {"text": "The multi-task paradigm can also be leveraged to inject grammatical knowledge into language models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recurrent neural networks (RNNs) have seen rapid adoption in natural language processing applications.", "labels": [], "entities": [{"text": "Recurrent neural networks (RNNs)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6846907039483389}]}, {"text": "Since these models are not equipped with explicit linguistic representations such as dependency parses or logical forms, new methods are needed to characterize the linguistic generalizations that they capture.", "labels": [], "entities": []}, {"text": "One such method is drawn from behavioral psychology: the network is tested on cases that are carefully selected to be informative as to the generalizations that the network has acquired.", "labels": [], "entities": []}, {"text": "have recently applied this methodology to evaluate how well a trained RNN captures sentence structure, using the agreement prediction task.", "labels": [], "entities": [{"text": "agreement prediction", "start_pos": 113, "end_pos": 133, "type": "TASK", "confidence": 0.7740855813026428}]}, {"text": "The form of an English verb often depends on its subject.", "labels": [], "entities": []}, {"text": "Identifying the subject of a given verb of requires sensitivity to sentence structure.", "labels": [], "entities": []}, {"text": "Consequently, testing an RNN on its ability to choose the correct form of a verb in context can shed light on the sophistication of its syntactic representations (see Section 2.1 for details).", "labels": [], "entities": []}, {"text": "RNNs trained specifically to perform the agreement task can achieve very good average performance on a corpus, with accuracy close to 99%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9993447661399841}]}, {"text": "However, error rates increase substantially on complex sentences (, suggesting that the syntactic knowledge acquired by the RNN is imperfect.", "labels": [], "entities": [{"text": "error", "start_pos": 9, "end_pos": 14, "type": "METRIC", "confidence": 0.9785757660865784}]}, {"text": "Finally, when the RNN is trained as a language model rather than specifically on the agreement task, its sensitivity to subject-verb agreement, measured as the relative probability of the grammatical and ungrammatical forms of the verb, degrades dramatically.", "labels": [], "entities": []}, {"text": "Are the limitations that RNNs showed in previous work inherent to their architecture, or can these limitations be mitigated by stronger supervision?", "labels": [], "entities": []}, {"text": "We address this question using multitask learning, where the same model is encouraged to develop representations that are simultaneously useful for multiple tasks.", "labels": [], "entities": []}, {"text": "To provide the RNN with an incentive to develop more sophisticated representations, we trained it to perform one of two tasks: the first is combinatory categorical grammar (CCG) supertagging), a sequence labeling task likely to require robust syntactic representations; the second task is language modeling.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 289, "end_pos": 306, "type": "TASK", "confidence": 0.7914014756679535}]}, {"text": "We also investigate the inverse question: can tasks such as supertagging benefit from joint training with the agreement task?", "labels": [], "entities": []}, {"text": "This question is of practical interest.", "labels": [], "entities": []}, {"text": "Large training sets for the agreement task are much easier to create than training sets for supertagging, which are based on manually parsed sentences.", "labels": [], "entities": []}, {"text": "If the training signal from the agreement prediction task proves to be beneficial for supertagging, this could lead to improved supertagging (and therefore parsing) performance in languages in which we only have a small amount of parsed training sentences.", "labels": [], "entities": [{"text": "agreement prediction task", "start_pos": 32, "end_pos": 57, "type": "TASK", "confidence": 0.7876077393690745}, {"text": "parsing", "start_pos": 156, "end_pos": 163, "type": "TASK", "confidence": 0.9607593417167664}]}, {"text": "We found that multi-task learning, either with LM or with CCG supertagging, improved the performance of the RNN on the agreement prediction task.", "labels": [], "entities": [{"text": "agreement prediction task", "start_pos": 119, "end_pos": 144, "type": "TASK", "confidence": 0.8235268791516622}]}, {"text": "The benefits of combined training with supertagging can be quite large: accuracy in challenging relative clause sentences increased from 50.6% to 76.2%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9994751811027527}]}, {"text": "This suggests that RNNs are in principle capable of acquiring much better syntactic representations than those they learned from the corpus in.", "labels": [], "entities": []}, {"text": "In the other direction, joint training on the agreement prediction task did not improve overall language model perplexity, but made the model more syntax-aware: grammatically appropriate verb forms had higher probability than grammatically inappropriate ones.", "labels": [], "entities": [{"text": "agreement prediction task", "start_pos": 46, "end_pos": 71, "type": "TASK", "confidence": 0.8425523638725281}]}, {"text": "When a limited amount of CCG training data was available, joint training on agreement prediction led to improved supertagging accuracy.", "labels": [], "entities": [{"text": "agreement prediction", "start_pos": 76, "end_pos": 96, "type": "TASK", "confidence": 0.7838000953197479}, {"text": "accuracy", "start_pos": 126, "end_pos": 134, "type": "METRIC", "confidence": 0.9928230047225952}]}, {"text": "These findings suggest that multitask training with auxiliary syntactic tasks such as agreement prediction can lead to improved performance on standard NLP tasks.", "labels": [], "entities": [{"text": "agreement prediction", "start_pos": 86, "end_pos": 106, "type": "TASK", "confidence": 0.801828920841217}]}], "datasetContent": [{"text": "We used two training datasets.", "labels": [], "entities": []}, {"text": "The first is the corpus of approximately 1.5 million sentences from the English Wikipedia compiled by.", "labels": [], "entities": []}, {"text": "All sentences had at most 50 words and contained at least one third-person present-tense agreement dependency.", "labels": [], "entities": []}, {"text": "Following, we replaced rare words by their part-ofspeech tags, using the Penn Treebank tag set.", "labels": [], "entities": [{"text": "Penn Treebank tag set", "start_pos": 73, "end_pos": 94, "type": "DATASET", "confidence": 0.9955934584140778}]}, {"text": "The second data set we used is the CCG-Bank (, a CCG version of the Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 68, "end_pos": 81, "type": "DATASET", "confidence": 0.9941818416118622}]}, {"text": "This corpus contained 48934 English sentences, 27299 of which include a present tense third-person verb agreement dependency.", "labels": [], "entities": []}, {"text": "A negligible number of sentences longer than 90 words were removed.", "labels": [], "entities": []}, {"text": "We applied the traditional split where Sections 2-21 are used for training and Section 23 for testing (41294 and 2407 sentences respectively).", "labels": [], "entities": []}, {"text": "Out of the 1363 different supertags that occur in the corpus, we only attempted to predict the 452 supertags that occurred at least ten times; we replaced the rest (0.2% of the tokens) by a dummy value.", "labels": [], "entities": []}], "tableCaptions": []}