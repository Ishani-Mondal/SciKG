{"title": [{"text": "Embedding Words and Senses Together via Joint Knowledge-Enhanced Training", "labels": [], "entities": []}], "abstractContent": [{"text": "Word embeddings are widely used in Natural Language Processing, mainly due to their success in capturing semantic information from massive corpora.", "labels": [], "entities": [{"text": "Natural Language Processing", "start_pos": 35, "end_pos": 62, "type": "TASK", "confidence": 0.6682655314604441}]}, {"text": "However, their creation process does not allow the different meanings of a word to be automatically separated, as it conflates them into a single vector.", "labels": [], "entities": []}, {"text": "We address this issue by proposing anew model which learns word and sense embeddings jointly.", "labels": [], "entities": []}, {"text": "Our model exploits large corpora and knowledge from semantic networks in order to produce a unified vector space of word and sense embeddings.", "labels": [], "entities": []}, {"text": "We evaluate the main features of our approach both qualitatively and quantitatively in a variety of tasks, highlighting the advantages of the proposed method in comparison to state-of-the-art word-and sense-based models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recently, approaches based on neural networks which embed words into low-dimensional vector spaces from text corpora (i.e. word embeddings) have become increasingly popular ().", "labels": [], "entities": []}, {"text": "Word embeddings have proved to be beneficial in many Natural Language Processing tasks, such as Machine Translation (, syntactic parsing (, and Question Answering (), to name a few.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 96, "end_pos": 115, "type": "TASK", "confidence": 0.8624947667121887}, {"text": "syntactic parsing", "start_pos": 119, "end_pos": 136, "type": "TASK", "confidence": 0.7848708033561707}, {"text": "Question Answering", "start_pos": 144, "end_pos": 162, "type": "TASK", "confidence": 0.8284987211227417}]}, {"text": "Despite their success in capturing semantic properties of words, these representations are generally hampered by an important limitation: the inability to discriminate among different meanings of the same word.", "labels": [], "entities": []}, {"text": "Authors marked with an asterisk (*) contributed equally.", "labels": [], "entities": []}, {"text": "Previous works have addressed this limitation by automatically inducing word senses from monolingual corpora, or bilingual parallel data.", "labels": [], "entities": []}, {"text": "However, these approaches learn solely on the basis of statistics extracted from text corpora and do not exploit knowledge from semantic networks.", "labels": [], "entities": []}, {"text": "Additionally, their induced senses are neither readily interpretable ( nor easily mappable to lexical resources, which limits their application.", "labels": [], "entities": []}, {"text": "Recent approaches have utilized semantic networks to inject knowledge into existing word representations (), but without solving the meaning conflation issue.", "labels": [], "entities": []}, {"text": "In order to obtain a representation for each sense of a word, a number of approaches have leveraged lexical resources to learn sense embeddings as a result of post-processing conventional word embeddings.", "labels": [], "entities": []}, {"text": "Instead, we propose SW2V (Senses and Words to Vectors), a neural model that exploits knowledge from both text corpora and semantic networks in order to simultaneously learn embeddings for both words and senses.", "labels": [], "entities": []}, {"text": "Moreover, our model provides three additional key features: (1) both word and sense embeddings are represented in the same vector space, (2) it is flexible, as it can be applied to different predictive models, and (3) it is scalable for very large semantic networks and text corpora.", "labels": [], "entities": []}], "datasetContent": [{"text": "We perform a qualitative and quantitative evaluation of important features of SW2V in three different tasks.", "labels": [], "entities": [{"text": "SW2V", "start_pos": 78, "end_pos": 82, "type": "TASK", "confidence": 0.8228636980056763}]}, {"text": "First, in order to compare our model against standard word-based approaches, we evaluate our system in the word similarity task (Section 6.1).", "labels": [], "entities": []}, {"text": "Second, we measure the quality of our sense embeddings in a sense-specific application: sense clustering (Section 6.2).", "labels": [], "entities": [{"text": "sense clustering", "start_pos": 88, "end_pos": 104, "type": "TASK", "confidence": 0.7107372432947159}]}, {"text": "Finally, we evaluate the coherence of our unified vector space by measuring the interconnectivity of word and sense embeddings (Section 6.3).", "labels": [], "entities": []}, {"text": "Throughout all the experiments we use the same standard hyperparameters mentioned in Section 5 for both the original word2vec implementation and our proposed model SW2V.", "labels": [], "entities": []}, {"text": "For SW2V we use the same optimal configuration according to the analysis of the previous section (only senses as input, and both words and senses as output) for all tasks.", "labels": [], "entities": []}, {"text": "As training corpus we take the full 3B-words UMBC webbase corpus and the Wikipedia (Wikipedia dump of November 2014), used by three of the comparison systems.", "labels": [], "entities": [{"text": "UMBC webbase corpus", "start_pos": 45, "end_pos": 64, "type": "DATASET", "confidence": 0.9525263508160909}, {"text": "Wikipedia (Wikipedia dump of November 2014)", "start_pos": 73, "end_pos": 116, "type": "DATASET", "confidence": 0.9151291623711586}]}, {"text": "We use BabelNet 3.0 (SW2V BN ) and WordNet 3.0 (SW2V WN ) as semantic networks.", "labels": [], "entities": [{"text": "WordNet 3.0 (SW2V WN )", "start_pos": 35, "end_pos": 57, "type": "DATASET", "confidence": 0.8811627129713694}]}, {"text": "We compare with the publicly available pre-trained sense embeddings of four state-of-the-art models: and AutoExtend) based on WordNet, and SensEmbed and NASARI 12) based on BabelNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 126, "end_pos": 133, "type": "DATASET", "confidence": 0.9510690569877625}]}], "tableCaptions": [{"text": " Table 1: Pearson (r) and Spearman (\u03c1) correlation performance of the nine configurations of SW2V", "labels": [], "entities": [{"text": "Pearson (r)", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9560430943965912}, {"text": "Spearman (\u03c1) correlation", "start_pos": 26, "end_pos": 50, "type": "METRIC", "confidence": 0.9072160959243775}, {"text": "SW2V", "start_pos": 93, "end_pos": 97, "type": "TASK", "confidence": 0.48787546157836914}]}, {"text": " Table 2: Pearson (r) and Spearman (\u03c1) correla- tion performance of SW2V integrating our shal- low word-sense connectivity algorithm (default),  Babelfy, or Babelfy*.", "labels": [], "entities": [{"text": "Pearson (r)", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9350477308034897}]}, {"text": " Table 3: Pearson (r) and Spearman (\u03c1) correlation performance on the SimLex-999 and MEN word  similarity datasets.", "labels": [], "entities": [{"text": "Pearson (r)", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9618062525987625}, {"text": "Spearman (\u03c1) correlation", "start_pos": 26, "end_pos": 50, "type": "METRIC", "confidence": 0.9250628709793091}, {"text": "MEN word  similarity datasets", "start_pos": 85, "end_pos": 114, "type": "DATASET", "confidence": 0.697718620300293}]}, {"text": " Table 4: Accuracy and F-Measure percentages of  different systems on the SemEval Wikipedia sense  clustering dataset.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9983363747596741}, {"text": "F-Measure percentages", "start_pos": 23, "end_pos": 44, "type": "METRIC", "confidence": 0.9772006869316101}, {"text": "SemEval Wikipedia sense  clustering dataset", "start_pos": 74, "end_pos": 117, "type": "DATASET", "confidence": 0.7348605751991272}]}, {"text": " Table 5: F-Measure percentage of different MCS  strategies on the SemEval-2007 and SemEval- 2013 WSD datasets.", "labels": [], "entities": [{"text": "F-Measure", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9946946501731873}, {"text": "SemEval- 2013 WSD datasets", "start_pos": 84, "end_pos": 110, "type": "DATASET", "confidence": 0.724167424440384}]}]}