{"title": [{"text": "Initial Explorations of CCG Supertagging for Universal Dependency Parsing", "labels": [], "entities": [{"text": "Universal Dependency Parsing", "start_pos": 45, "end_pos": 73, "type": "TASK", "confidence": 0.5574165284633636}]}], "abstractContent": [{"text": "In this paper we describe the system by METU team for universal dependency parsing of multilingual text.", "labels": [], "entities": [{"text": "METU team", "start_pos": 40, "end_pos": 49, "type": "DATASET", "confidence": 0.9373899698257446}, {"text": "universal dependency parsing of multilingual text", "start_pos": 54, "end_pos": 103, "type": "TASK", "confidence": 0.7719931105772654}]}, {"text": "We use a neu-ral network-based dependency parser that has a greedy transition approach to dependency parsing.", "labels": [], "entities": [{"text": "dependency parser", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.6225339472293854}, {"text": "dependency parsing", "start_pos": 90, "end_pos": 108, "type": "TASK", "confidence": 0.7773826420307159}]}, {"text": "CCG supertags contain rich structural information that proves useful in certain NLP tasks.", "labels": [], "entities": []}, {"text": "We experiment with CCG supertags as additional features in our experiments.", "labels": [], "entities": []}, {"text": "The neural network parser is trained together with dependencies and simplified CCG tags as well as other features provided.", "labels": [], "entities": []}], "introductionContent": [{"text": "Combinatory Categorial Grammar) (CCG) is widely used for natural language processing for its desirable properties of generative expressiveness and its transparent interface of syntax and underlying semantic interpretation.", "labels": [], "entities": [{"text": "Combinatory Categorial Grammar) (CCG)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.7772055012839181}, {"text": "natural language processing", "start_pos": 57, "end_pos": 84, "type": "TASK", "confidence": 0.6884883046150208}, {"text": "generative expressiveness", "start_pos": 117, "end_pos": 142, "type": "TASK", "confidence": 0.9338537156581879}]}, {"text": "CCG has been used for creating fast and accurate parsers,,,).", "labels": [], "entities": [{"text": "CCG", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.784610390663147}]}, {"text": "In addition to this, the structural information in the CCG categories, which is a lexicalised grammar, has been shown to improve performance of various other systems when used indirectly.", "labels": [], "entities": []}, {"text": "Examples are multilingual dependency parsing and machine translation.", "labels": [], "entities": [{"text": "multilingual dependency parsing", "start_pos": 13, "end_pos": 44, "type": "TASK", "confidence": 0.6739448507626852}, {"text": "machine translation", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.8210154473781586}]}, {"text": "In this paper, we describe a system we created for CoNLL Shared Task of 2017 () Multilingual Parsing from Raw Text to 1 . We use CCG categories induced from the CCGBank () to Results are announced at http://universaldependencies.", "labels": [], "entities": [{"text": "CoNLL Shared Task of 2017", "start_pos": 51, "end_pos": 76, "type": "DATASET", "confidence": 0.8033120274543762}]}, {"text": "org/conll17/results.html supertag different languages with these structural information-packed tags.", "labels": [], "entities": []}, {"text": "We aim to show that CCG categories for English maybe used to improve parsing results for other languages, especially similar ones.", "labels": [], "entities": []}, {"text": "In the next section, we give a brief background on the dependency parsing problem and CCG categories that have been shown to improve performance on various tasks either directly or indirectly.", "labels": [], "entities": [{"text": "dependency parsing problem", "start_pos": 55, "end_pos": 81, "type": "TASK", "confidence": 0.8684421380360922}]}, {"text": "Section 3 gives the implementation details for the METU system and in Section 4 results are discussed.", "labels": [], "entities": [{"text": "METU", "start_pos": 51, "end_pos": 55, "type": "DATASET", "confidence": 0.8056982755661011}]}], "datasetContent": [{"text": "In MSTParser pre-evaluation experiments, we use the Penn Treebank Wall Street Journal segmentation split as sections 2-21 for training and section 23 as the test set.", "labels": [], "entities": [{"text": "Penn Treebank Wall Street Journal segmentation split", "start_pos": 52, "end_pos": 104, "type": "DATASET", "confidence": 0.9707194992474147}]}, {"text": "Extra training parameters are as the following: training \u2212 k = 5 loss \u2212 type = nopunc decode \u2212 type = proj order = 2 unless stated otherwise in the results.", "labels": [], "entities": [{"text": "training", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.956365704536438}]}, {"text": "Detailed descriptions of these parameters can be found in.", "labels": [], "entities": []}, {"text": "These parameters reproduce similar results as which we use as a baseline to compare our improvements.", "labels": [], "entities": []}, {"text": "The version in which the CCG supertags were added also uses the same configuration.", "labels": [], "entities": [{"text": "CCG supertags", "start_pos": 25, "end_pos": 38, "type": "DATASET", "confidence": 0.9309973120689392}]}, {"text": "In the pre-evaluation's parser experiment, we also use the Penn Treebank for English as sections 2-21 for training, section 22 as development and section 23 as the test set.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 59, "end_pos": 72, "type": "DATASET", "confidence": 0.9930214881896973}]}, {"text": "For word embedding file, GloVe 50 dimensional data is used ().", "labels": [], "entities": []}, {"text": "Extra configurational parameters are: \u2212maxIter : 20000 \u2212trainingT hreads : 10 \u2212embeddingSize : 50 where maxIter stands for maximum iteration step in neural network training, trainingT hreads for number of threads to use during training and embeddingSize for embedding vector size for words, POS tags and supertags.", "labels": [], "entities": []}, {"text": "Reproduction of the results from the original study and our results with our supertags are given in.", "labels": [], "entities": []}, {"text": "These results are obtained by the evaluation method of the original parser.", "labels": [], "entities": []}, {"text": "Also, in the pre-evaluation phase, we test our Chen and Manning (2014) parser-based system on Turkish, German and French data.", "labels": [], "entities": []}, {"text": "Shared taskprovided data is used for training and development purposes.", "labels": [], "entities": []}, {"text": "Word embeddings are used as 100 dimensional vectors from", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 6: Accuracy on MSTParser with CCG su- pertags in English (pre-evaluation)", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.99755859375}, {"text": "MSTParser", "start_pos": 22, "end_pos": 31, "type": "DATASET", "confidence": 0.8021760582923889}]}, {"text": " Table 7: Accuracy on (Chen and Manning, 2014)  parser with CCG tags in English (pre-evaluation)", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9940714240074158}]}, {"text": " Table 8: Accuracy on the Chen and Manning  (2014) parser with CCG-based supertags in other  languages (pre-evaluation). pre-UAS and pre- LAS stands for accuracies obtained with Chen  & Manning, while post-UAS and post-LAS with  Chen & Manning + Supertags.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9964321851730347}, {"text": "pre- LAS", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.8290675481160482}]}, {"text": " Table 9: Our CONLL 2017 Shared task results vs  Shared Task baselines (LAS F1 Score)", "labels": [], "entities": [{"text": "CONLL 2017", "start_pos": 14, "end_pos": 24, "type": "DATASET", "confidence": 0.6982898414134979}, {"text": "LAS F1 Score", "start_pos": 72, "end_pos": 84, "type": "METRIC", "confidence": 0.8680336276690165}]}]}