{"title": [{"text": "UParse: the Edinburgh system for the CoNLL 2017 UD shared task", "labels": [], "entities": [{"text": "UParse", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.7490924000740051}, {"text": "Edinburgh system", "start_pos": 12, "end_pos": 28, "type": "DATASET", "confidence": 0.9372908174991608}, {"text": "CoNLL 2017 UD shared task", "start_pos": 37, "end_pos": 62, "type": "DATASET", "confidence": 0.9040491819381714}]}], "abstractContent": [{"text": "This paper presents our submissions for the CoNLL 2017 UD Shared Task.", "labels": [], "entities": [{"text": "CoNLL 2017 UD Shared Task", "start_pos": 44, "end_pos": 69, "type": "DATASET", "confidence": 0.7552529454231263}]}, {"text": "Our parser, called UParse, is based on a neural network graph-based dependency parser.", "labels": [], "entities": []}, {"text": "The parser uses features from a bidirec-tional LSTM to produce a distribution over possible heads for each word in the sentence.", "labels": [], "entities": []}, {"text": "To allow transfer learning for low-resource treebanks and surprise languages, we train several multilingual models for related languages, grouped by their genus and language families.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 9, "end_pos": 26, "type": "TASK", "confidence": 0.885521799325943}]}, {"text": "Out of 33 participants , our system achieves rank 9th in the main results, with 75.49 UAS and 68.87 LAS F-1 scores (average across 81 tree-banks).", "labels": [], "entities": [{"text": "UAS", "start_pos": 86, "end_pos": 89, "type": "METRIC", "confidence": 0.9597443342208862}, {"text": "LAS F-1 scores", "start_pos": 100, "end_pos": 114, "type": "METRIC", "confidence": 0.8846072753270467}]}], "introductionContent": [{"text": "Dependency parsing aims to automatically extract dependencies between words in a sentence, in the form of tree structure.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8781017363071442}]}, {"text": "These dependencies define the grammatical structure of the sentence, which makes it beneficial for many natural language applications, such as question answering (), machine translation, and information extraction (.", "labels": [], "entities": [{"text": "question answering", "start_pos": 143, "end_pos": 161, "type": "TASK", "confidence": 0.8820950090885162}, {"text": "machine translation", "start_pos": 166, "end_pos": 185, "type": "TASK", "confidence": 0.8291880786418915}, {"text": "information extraction", "start_pos": 191, "end_pos": 213, "type": "TASK", "confidence": 0.844114363193512}]}, {"text": "The most common approaches for dependency parsing are transitionbased () or graph-based).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.8393671810626984}]}, {"text": "Recent works also apply neural network approaches for dependency parsing, particularly for learning rich feature representations that improve parser accuracy.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 54, "end_pos": 72, "type": "TASK", "confidence": 0.857771247625351}, {"text": "accuracy", "start_pos": 149, "end_pos": 157, "type": "METRIC", "confidence": 0.796602189540863}]}, {"text": "To train a high-quality parser, one typically needs a large treebank, annotated with some linguistic information, such as part of speech (POS) tags, lemmas, and morphological features.", "labels": [], "entities": []}, {"text": "However, human annotations are expensive.", "labels": [], "entities": []}, {"text": "As a result, most of the work has been focused on few languages, such as English, Czech, or Chinese.", "labels": [], "entities": []}, {"text": "The Universal Dependencies (UD;) is an initiative to develop consistent treebank annotations across many languages.", "labels": [], "entities": []}, {"text": "It provides an opportunity to perform model transferusing model trained on high-resource languages to parse low-resource languages, allowing the development of treebanks for many more languages.", "labels": [], "entities": []}, {"text": "Several works have shown that this technique can help improve accuracy for low-resource languages, and in fact recent work of demonstrated that it is possible to train a single multilingual model that works well both in low-resource and high-resource settings.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9951387643814087}]}, {"text": "The CoNLL 2017 UD Shared Task () uses Universal Dependencies version 2.0 ( , with training data consists of 64 treebanks from 45 languages.", "labels": [], "entities": [{"text": "CoNLL 2017 UD Shared Task", "start_pos": 4, "end_pos": 29, "type": "DATASET", "confidence": 0.9011330127716064}]}, {"text": "Some of the challenges are the truly low-resource treebanks (e.g., Kazakh and Uyghur with only 30 and 100 training sentences, respectively), small treebanks without development data (e.g., Irish, FrenchParTUT, Galician-TreeGal, Ukrainian), and the surprise languages and treebanks needed to be parse during test phase.", "labels": [], "entities": []}, {"text": "To address these challenges, we designed our system for the shared task to use both monolingual and multilingual models.", "labels": [], "entities": []}, {"text": "In particular: \u2022 We train one monolingual model per highresource treebank in the training set.", "labels": [], "entities": []}, {"text": "\u2022 For low-resource treebanks, we train several multilingual models, each for related languages grouped by their genus and language families.", "labels": [], "entities": []}, {"text": "\u2022 For surprise languages, we train several delexalized parsers using treebanks that are closest to the surprise languages in terms of language family.", "labels": [], "entities": []}, {"text": "Our parsing model uses pretrained word vectors, gold universal POS tags (UPOS), and gold morphological analysis (XFEATS, if available).", "labels": [], "entities": []}, {"text": "For the multilingual models, we also use language ID and replace pre-trained word vectors with multilingual word vectors.", "labels": [], "entities": []}, {"text": "For the delexicalized models, we remove the word vectors from our feature set because we want to use the model for other languages which use different vocabularies.", "labels": [], "entities": []}, {"text": "We submitted three systems, which are described in Section 5.", "labels": [], "entities": []}, {"text": "The final ranking of the shared task brings our parser to the ninth place, with average UAS and LAS, 75.49 and 68.87, respectively.", "labels": [], "entities": [{"text": "UAS", "start_pos": 88, "end_pos": 91, "type": "METRIC", "confidence": 0.9699984788894653}, {"text": "LAS", "start_pos": 96, "end_pos": 99, "type": "METRIC", "confidence": 0.9937830567359924}]}, {"text": "On the surprise languages, our system reaches the 6th rank, with 39.17 LAS.", "labels": [], "entities": [{"text": "LAS", "start_pos": 71, "end_pos": 74, "type": "METRIC", "confidence": 0.989211916923523}]}], "datasetContent": [{"text": "Prior to our participation in the shared task, we ran a number of preliminary experiments that informed the design of the final system.", "labels": [], "entities": []}, {"text": "Our shared task submission is based on these results.", "labels": [], "entities": []}, {"text": "In our preliminary experiments, our main goal is to evaluate the multilingual model of UParse.", "labels": [], "entities": []}, {"text": "These experiments are mainly inspired by the   In addition, we also compare our parser performance for the monolingual models with UDPipe parser. and 3 present the performance of our parser compared to UDPipe (monolingual) and MALOPA (multilingual) parsers.", "labels": [], "entities": []}, {"text": "In terms of UAS, our multilingual model achieves the best scores, except for English, German, and French.", "labels": [], "entities": [{"text": "UAS", "start_pos": 12, "end_pos": 15, "type": "DATASET", "confidence": 0.5822069048881531}]}, {"text": "The results for LAS are slightly different.", "labels": [], "entities": [{"text": "LAS", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.8594024777412415}]}, {"text": "We found that for languages where we have more than 10K training sentences, our monolingual model outperforms the other models, with an exception on Italian.", "labels": [], "entities": []}, {"text": "For the smaller treebanks, although we see UAS improvements for Portuguese and Swedish when we use multilingual model, we only obtain LAS improvement on Portuguese.", "labels": [], "entities": [{"text": "UAS", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.9490442872047424}, {"text": "LAS", "start_pos": 134, "end_pos": 137, "type": "METRIC", "confidence": 0.9972172975540161}]}, {"text": "We believe that these mixed results are due to poor accuracy of our label classifier, since the UAS results demonstrate that the parser itself is quite effective in predicting the dependency arcs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9986787438392639}, {"text": "UAS", "start_pos": 96, "end_pos": 99, "type": "DATASET", "confidence": 0.7656412124633789}]}, {"text": "This section describes the experimental design, training, and also our submissions to the shared task.", "labels": [], "entities": []}, {"text": "After looking at the results of our preliminary experiments, we decided to train both monolingual and multilingual parsers, evaluate them on the shared task development data and choose the best settings for our submissions.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: UAS results for monolingual and multilingual model of UParse on the Universal Dependencies  version 1.2.", "labels": [], "entities": [{"text": "UAS", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.5534661412239075}, {"text": "Universal Dependencies  version 1.2", "start_pos": 78, "end_pos": 113, "type": "DATASET", "confidence": 0.8042304739356041}]}, {"text": " Table 3: LAS results for monolingual and multilingual model of UParse on the Universal Dependencies  version 1.2. MALOPA is the multilingual parser of Ammar et al. (2016).", "labels": [], "entities": [{"text": "LAS", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9673460125923157}, {"text": "Universal Dependencies  version 1.2", "start_pos": 78, "end_pos": 113, "type": "DATASET", "confidence": 0.7637030109763145}]}, {"text": " Table 6: Macro-averaged LAS F1 score on devel- opment data.", "labels": [], "entities": [{"text": "LAS F1 score", "start_pos": 25, "end_pos": 37, "type": "METRIC", "confidence": 0.7855377395947775}]}, {"text": " Table 8: LAS, UAS, and CLAS results of our pri- mary system, UP-1.", "labels": [], "entities": [{"text": "LAS", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9940928816795349}, {"text": "UAS", "start_pos": 15, "end_pos": 18, "type": "METRIC", "confidence": 0.9299585223197937}]}, {"text": " Table 9: LAS F-1 scores for each treebank in the test data. (*) denotes treebanks which are predicted  using UDPipe baseline models in the UP-1 system and the best accuracies are shown in bold.", "labels": [], "entities": [{"text": "LAS F-1", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.8643835186958313}]}]}