{"title": [{"text": "Automatic Selection of Context Configurations for Improved Class-Specific Word Representations", "labels": [], "entities": [{"text": "Automatic Selection of Context Configurations", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.6518573582172393}, {"text": "Improved Class-Specific Word Representations", "start_pos": 50, "end_pos": 94, "type": "TASK", "confidence": 0.5697811022400856}]}], "abstractContent": [{"text": "This paper is concerned with identifying contexts useful for training word representation models for different word classes such as adjectives (A), verbs (V), and nouns (N).", "labels": [], "entities": []}, {"text": "We introduce a simple yet effective framework for an automatic selection of class-specific context configurations.", "labels": [], "entities": []}, {"text": "We construct a context configuration space based on universal dependency relations between words, and efficiently search this space with an adapted beam search algorithm.", "labels": [], "entities": []}, {"text": "In word similarity tasks for each word class, we show that our framework is both effective and efficient.", "labels": [], "entities": [{"text": "word similarity tasks", "start_pos": 3, "end_pos": 24, "type": "TASK", "confidence": 0.7921914259592692}]}, {"text": "Particularly, it improves the Spearman's \u03c1 correlation with human scores on SimLex-999 over the best previously proposed class-specific contexts by 6 (A), 6 (V) and 5 (N) \u03c1 points.", "labels": [], "entities": [{"text": "Spearman's \u03c1 correlation", "start_pos": 30, "end_pos": 54, "type": "METRIC", "confidence": 0.5650808289647102}, {"text": "SimLex-999", "start_pos": 76, "end_pos": 86, "type": "DATASET", "confidence": 0.8912648558616638}]}, {"text": "With our selected context configurations, we train on only 14% (A), 26.2% (V), and 33.6% (N) of all dependency-based contexts, resulting in a reduced training time.", "labels": [], "entities": []}, {"text": "Our results gen-eralise: we show that the configurations our algorithm learns for one English training setup outperform previously proposed context types in another training setup for En-glish.", "labels": [], "entities": []}, {"text": "Moreover, basing the configuration space on universal dependencies, it is possible to transfer the learned configurations to German and Italian.", "labels": [], "entities": []}, {"text": "We also demonstrate improved per-class results over other context types in these two languages.", "labels": [], "entities": []}], "introductionContent": [{"text": "Dense real-valued word representations (embeddings) have become ubiquitous in NLP, serving as invaluable features in abroad range of tasks ().", "labels": [], "entities": []}, {"text": "The omnipresent word2vec skip-gram model with negative sampling (SGNS) () is still considered a robust and effective choice fora word representation model, due to its simplicity, fast training, as well as its solid performance across semantic tasks ().", "labels": [], "entities": []}, {"text": "The original SGNS implementation learns word representations from local bag-of-words contexts (BOW).", "labels": [], "entities": []}, {"text": "However, the underlying model is equally applicable with other context types ().", "labels": [], "entities": []}, {"text": "Recent work suggests that \"not all contexts are created equal\".", "labels": [], "entities": []}, {"text": "For example, reaching beyond standard BOW contexts towards contexts based on dependency parses () or symmetric patterns () yields significant improvements in learning representations for particular word classes such as adjectives (A) and verbs (V).", "labels": [], "entities": [{"text": "dependency parses", "start_pos": 77, "end_pos": 94, "type": "TASK", "confidence": 0.720735028386116}]}, {"text": "Moreover, demonstrated that a subset of dependency-based contexts which covers only coordination structures is particularly effective for SGNS training, both in terms of the quality of the induced representations and in the reduced training time of the model.", "labels": [], "entities": [{"text": "SGNS training", "start_pos": 138, "end_pos": 151, "type": "TASK", "confidence": 0.9455809593200684}]}, {"text": "Interestingly, they also demonstrated that despite the success with adjectives and verbs, BOW contexts are still the optimal choice when learning representations for nouns.", "labels": [], "entities": [{"text": "BOW", "start_pos": 90, "end_pos": 93, "type": "METRIC", "confidence": 0.794269859790802}]}, {"text": "In this work, we propose a simple yet effective framework for selecting context configurations, which yields improved representations for verbs, adjectives, and nouns.", "labels": [], "entities": []}, {"text": "We start with a definition of our context configuration space (Sect. 3.1).", "labels": [], "entities": []}, {"text": "Our basic definition of a context refers to a single typed (or labeled) dependency link between words (e.g., the amod link or the dobj link).", "labels": [], "entities": []}, {"text": "Our configuration space then naturally consists of all possible subsets of the set of labeled dependency links between words.", "labels": [], "entities": []}, {"text": "We employ the universal dependencies (UD) scheme to make our framework applicable across languages.", "labels": [], "entities": []}, {"text": "We then describe (Sect. 3.2) our adapted beam search algorithm that aims to select an optimal context configuration fora given word class.", "labels": [], "entities": []}, {"text": "We show that SGNS requires different context configurations to produce improved results for each word class.", "labels": [], "entities": []}, {"text": "For instance, our algorithm detects that the combination of amod and conj contexts is effective for adjective representation.", "labels": [], "entities": [{"text": "adjective representation", "start_pos": 100, "end_pos": 124, "type": "TASK", "confidence": 0.7476963698863983}]}, {"text": "Moreover, some contexts that boost representation learning for one word class (e.g., amod contexts for adjectives) maybe uninformative when learning representations for another class (e.g., amod for verbs).", "labels": [], "entities": []}, {"text": "By removing such dispensable contexts, we are able both to speedup the SGNS training and to improve representation quality.", "labels": [], "entities": [{"text": "SGNS", "start_pos": 71, "end_pos": 75, "type": "TASK", "confidence": 0.9761162996292114}]}, {"text": "We first experiment with the task of predicting similarity scores for the A/V/N portions of the benchmarking SimLex-999 evaluation set, running our algorithm in a standard SGNS experimental setup (.", "labels": [], "entities": [{"text": "predicting similarity", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.684553474187851}, {"text": "SimLex-999 evaluation set", "start_pos": 109, "end_pos": 134, "type": "DATASET", "confidence": 0.7626847426096598}]}, {"text": "When training SGNS with our learned context configurations it outperforms SGNS trained with the best previously proposed context type for each word class: the improvements in Spearman's \u03c1 rank correlations are 6 (A), 6 (V), and 5 (N) points.", "labels": [], "entities": []}, {"text": "We also show that by building context configurations we obtain improvements on the entire SimLex-999 (4 \u03c1 points over the best baseline).", "labels": [], "entities": [{"text": "SimLex-999", "start_pos": 90, "end_pos": 100, "type": "DATASET", "confidence": 0.9188780784606934}]}, {"text": "Interestingly, this context configuration is not the optimal configuration for any word class.", "labels": [], "entities": []}, {"text": "We then demonstrate that our approach is robust by showing that transferring the optimal configurations learned in the above setup to three other setups yields improved performance.", "labels": [], "entities": []}, {"text": "First, the above context configurations, learned with the SGNS training on the English Wikipedia corpus, have an even stronger impact on SimLex999 performance when SGNS is trained on a larger corpus.", "labels": [], "entities": [{"text": "English Wikipedia corpus", "start_pos": 79, "end_pos": 103, "type": "DATASET", "confidence": 0.8897977471351624}]}, {"text": "Second, the transferred configurations also result in competitive performance on the task of solving class-specific TOEFL questions.", "labels": [], "entities": [{"text": "TOEFL questions", "start_pos": 116, "end_pos": 131, "type": "TASK", "confidence": 0.6680763959884644}]}, {"text": "Finally, we transfer the learned context configurations across languages: these configurations improve the SGNS performance when trained with German or Italian corpora and evaluated on class-specific subsets of the multilingual SimLex-999 (, without any language-specific tuning.", "labels": [], "entities": [{"text": "SGNS", "start_pos": 107, "end_pos": 111, "type": "TASK", "confidence": 0.9449470639228821}]}], "datasetContent": [{"text": "We run the algorithm for context configuration selection only once, with the SGNS training setup described below.", "labels": [], "entities": [{"text": "context configuration selection", "start_pos": 25, "end_pos": 56, "type": "TASK", "confidence": 0.7635979056358337}]}, {"text": "Our main evaluation setup is presented below, but the learned configurations are tested in additional setups, detailed in Sect.", "labels": [], "entities": []}, {"text": "5.: we perform 2-fold cross-validation, where the context configurations are optimised on a development set, separate from the unseen test data.", "labels": [], "entities": []}, {"text": "Unless stated otherwise, the reported scores are always the averages of the 2 runs, computed in the standard fashion by applying the cosine similarity to the vectors of words participating in a pair.", "labels": [], "entities": []}, {"text": "Not All Context Bags are Created Equal First, we test the performance of individual context bags across SimLex-999 adjective, verb, and noun subsets.", "labels": [], "entities": []}, {"text": "Besides providing insight on the intuition behind context selection, these findings are important for the automatic selection of class-specific pools (line 1 of Alg. 1).", "labels": [], "entities": []}, {"text": "The results are shown in Tab.", "labels": [], "entities": [{"text": "Tab.", "start_pos": 25, "end_pos": 29, "type": "DATASET", "confidence": 0.9789746403694153}]}, {"text": "1. The experiment supports our intuition (see Sect. 3.2): some context bags are definitely not useful for some classes and maybe safely removed: Results on the SimLex-999 test data over (a) verbs and (b) nouns subsets.", "labels": [], "entities": [{"text": "SimLex-999 test data", "start_pos": 160, "end_pos": 180, "type": "DATASET", "confidence": 0.8185658057530721}]}, {"text": "Only a selection of context configurations optimised for verb and noun similarity are shown.", "labels": [], "entities": []}, {"text": "POOL-ALL denotes a configuration where all individual context bags from the verbs/nouns-oriented pools (see) are used.", "labels": [], "entities": [{"text": "POOL-ALL", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.7738747000694275}]}, {"text": "BEST denotes the best performing configuration found by Alg.", "labels": [], "entities": [{"text": "BEST", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9912086725234985}]}, {"text": "1. Other configurations visited by Alg.", "labels": [], "entities": [{"text": "Alg.", "start_pos": 35, "end_pos": 39, "type": "DATASET", "confidence": 0.9223852157592773}]}, {"text": "1 that score higher than the best scoring baseline context type for each word class are in gray.", "labels": [], "entities": []}, {"text": "Scores obtained using a greedy search algorithm instead of Alg.", "labels": [], "entities": []}, {"text": "1 are in italic, marked with across ( \u2020).: Results on the SimLex-999 adjectives subset with adjective-specific configurations.", "labels": [], "entities": []}, {"text": "when performing the class-specific SGNS training.", "labels": [], "entities": [{"text": "SGNS", "start_pos": 35, "end_pos": 39, "type": "TASK", "confidence": 0.9446044564247131}]}, {"text": "For instance, the amod bag is indeed important for adjective and noun similarity, and at the same time it does not encode any useful information regarding verb similarity.", "labels": [], "entities": [{"text": "noun similarity", "start_pos": 65, "end_pos": 80, "type": "TASK", "confidence": 0.6928942948579788}, {"text": "verb similarity", "start_pos": 155, "end_pos": 170, "type": "TASK", "confidence": 0.6966376453638077}]}, {"text": "compound is, as expected, useful only for nouns.", "labels": [], "entities": []}, {"text": "1 also suggests that some context bags (e.g., nummod) do not encode any informative contextual evidence regarding similarity, therefore they can be discarded.", "labels": [], "entities": []}, {"text": "The initial results with individual context bags help to reduce the pool of candidate bags (line 1 in Alg. 1), see Tab.", "labels": [], "entities": [{"text": "Tab.", "start_pos": 115, "end_pos": 119, "type": "DATASET", "confidence": 0.8561967611312866}]}, {"text": "2. Searching for Improved Configurations Next, we test if we can improve class-specific representations by selecting class-specific configurations.", "labels": [], "entities": []}, {"text": "Indeed, class-specific configurations yield better representations, as is evident from the scores: the improvements with the best class-specific configurations found by Alg.", "labels": [], "entities": []}, {"text": "1 are approximately 6 \u03c1 points for adjectives, 6 points for verbs, and 5 points for nouns over the best baseline for each class.", "labels": [], "entities": []}, {"text": "The improvements are visible even with configurations that simply pool all candidate individual bags (POOL-ALL), without running Alg.", "labels": [], "entities": [{"text": "POOL-ALL", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.985676646232605}, {"text": "Alg.", "start_pos": 129, "end_pos": 133, "type": "DATASET", "confidence": 0.8194944560527802}]}, {"text": "However, further careful context selection, i.e., traversing the configuration space using Alg.", "labels": [], "entities": []}, {"text": "1 leads to additional improvements for V and N (gains of 3 and 2.2 \u03c1 points).", "labels": [], "entities": []}, {"text": "Very similar improved scores are achieved with a variety of configurations (see 3), especially in the neighbourhood of the best configuration found by Alg.", "labels": [], "entities": []}, {"text": "1. This indicates that the method is quite robust: even sub-optimal 12 solutions result in improved class-specific representations.", "labels": [], "entities": []}, {"text": "Furthermore, our algorithm is able to find better configurations for verbs and nouns compared to its greedy variant.", "labels": [], "entities": []}, {"text": "Finally, our algorithm generalises well: the best scoring configuration on the dev set is always the best one on the test set.", "labels": [], "entities": []}, {"text": "Training: Fast and/or Accurate?", "labels": [], "entities": [{"text": "Accurate", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9956169128417969}]}, {"text": "Carefully selected configurations are also likely to reduce SGNS training times.", "labels": [], "entities": [{"text": "SGNS", "start_pos": 60, "end_pos": 64, "type": "TASK", "confidence": 0.9707276225090027}]}, {"text": "Indeed, the configurationbased model trains on only 14% (A), 26.2% (V), and 33.6% (N) of all dependency-based contexts.", "labels": [], "entities": []}, {"text": "The training times and statistics for each context type are displayed in Tab.", "labels": [], "entities": [{"text": "Tab", "start_pos": 73, "end_pos": 76, "type": "DATASET", "confidence": 0.9223712086677551}]}, {"text": "5. All models  were trained using parallel training on 10 Intel(R) Xeon(R) E5-2667 2.90GHz processors.", "labels": [], "entities": []}, {"text": "The results indicate that class-specific configurations are not as lightweight and fast as SP or COORD contexts ().", "labels": [], "entities": []}, {"text": "However, they also suggest that such configurations provide a good balance between accuracy and speed: they reach peak performances for each class, outscoring all baseline context types (including SP and COORD), while training is still much faster than with \"heavyweight\" context types such as BOW, POSIT or DEPS-All.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9991697072982788}, {"text": "COORD", "start_pos": 204, "end_pos": 209, "type": "METRIC", "confidence": 0.6290254592895508}, {"text": "BOW", "start_pos": 294, "end_pos": 297, "type": "METRIC", "confidence": 0.6261244416236877}, {"text": "DEPS-All", "start_pos": 308, "end_pos": 316, "type": "DATASET", "confidence": 0.6517918109893799}]}, {"text": "Now that we verified the decrease in training time our algorithm provides for the final training, it makes sense to ask whether the configurations it finds are valuable in other setups.", "labels": [], "entities": []}, {"text": "This will make the fast training of practical importance.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: 2-fold cross-validation results for an illus- trative selection of individual context bags. Results  are presented for the noun, verb and adjective sub- sets of SimLex-999. Values in parentheses denote  the class-specific initial pools to which each context  is selected based on its \u03c1 score (line 1 of Alg. 1).", "labels": [], "entities": []}, {"text": " Table 3: Results on the SimLex-999 test data over (a) verbs and (b) nouns subsets. Only a selection  of context configurations optimised for verb and noun similarity are shown. POOL-ALL denotes a  configuration where all individual context bags from the verbs/nouns-oriented pools (see", "labels": [], "entities": [{"text": "SimLex-999 test data", "start_pos": 25, "end_pos": 45, "type": "DATASET", "confidence": 0.8405656218528748}, {"text": "POOL-ALL", "start_pos": 178, "end_pos": 186, "type": "METRIC", "confidence": 0.843482494354248}]}, {"text": " Table 4: Results on the SimLex-999 adjectives sub- set with adjective-specific configurations.", "labels": [], "entities": [{"text": "SimLex-999 adjectives sub- set", "start_pos": 25, "end_pos": 55, "type": "DATASET", "confidence": 0.7618277072906494}]}, {"text": " Table 6: Results on the A/V/N SimLex-999 sub- sets, and on the entire set (All) in the setup from", "labels": [], "entities": [{"text": "A/V/N SimLex-999 sub- sets", "start_pos": 25, "end_pos": 51, "type": "DATASET", "confidence": 0.608274241288503}]}, {"text": " Table 7: Results on the A/V/N TOEFL question  subsets. The reported scores are in the following  form: correct_answers/overall_questions. Adj-Q  refers to the subset of TOEFL questions targeting  adjectives; similar for Verb-Q and Noun-Q. BEST-*  refer to the best class-specific configurations from  Tab. 3 and Tab. 4.", "labels": [], "entities": [{"text": "BEST", "start_pos": 240, "end_pos": 244, "type": "METRIC", "confidence": 0.9970048069953918}]}]}