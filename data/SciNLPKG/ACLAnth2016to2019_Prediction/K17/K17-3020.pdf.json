{"title": [{"text": "Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies", "labels": [], "entities": [{"text": "Multilingual Parsing from Raw Text", "start_pos": 13, "end_pos": 47, "type": "TASK", "confidence": 0.8294702887535095}]}], "abstractContent": [{"text": "This paper describes the system for our participation of team Wanghao-ftd-SJTU in the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies.", "labels": [], "entities": [{"text": "CoNLL 2017 Shared Task", "start_pos": 86, "end_pos": 108, "type": "DATASET", "confidence": 0.7908869534730911}]}, {"text": "In this work, we design a system based on UDPipe 1 for universal dependency parsing, where transition-based models are trained for different tree-banks.", "labels": [], "entities": [{"text": "universal dependency parsing", "start_pos": 55, "end_pos": 83, "type": "TASK", "confidence": 0.6683895190556844}]}, {"text": "Our system directly takes raw texts as input, performing several intermediate steps like tokenizing and tagging, and finally generates the corresponding dependency trees.", "labels": [], "entities": []}, {"text": "For the special surprise languages for this task, we adopt a delexical-ized strategy and predict based on transfer learning from other related languages.", "labels": [], "entities": []}, {"text": "In the final evaluation of the shared task, our system achieves a result of 66.53% in macro-averaged LAS F1-score.", "labels": [], "entities": [{"text": "LAS F1-score", "start_pos": 101, "end_pos": 113, "type": "METRIC", "confidence": 0.7342789173126221}]}], "introductionContent": [{"text": "Universal Dependencies (UD) () and universal dependency parsing take efforts to build cross-linguistically treebank annotation and develop cross-lingual learning to parse many languages even low-resource languages.", "labels": [], "entities": [{"text": "Universal Dependencies (UD)", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.5459389388561249}, {"text": "universal dependency parsing", "start_pos": 35, "end_pos": 63, "type": "TASK", "confidence": 0.7414984703063965}]}, {"text": "Universal Dependencies release 2.0 2 (Nivre et al., 2017b) includes rich languages and treebanks resources and the parsing task in CoNLL 2017 is * Correspondence author.", "labels": [], "entities": [{"text": "parsing", "start_pos": 115, "end_pos": 122, "type": "TASK", "confidence": 0.9608172178268433}, {"text": "CoNLL 2017", "start_pos": 131, "end_pos": 141, "type": "DATASET", "confidence": 0.8664020895957947}]}, {"text": "This paper was partially supported by based on this dataset.", "labels": [], "entities": []}, {"text": "In fact, dependency parsing has been adopted as topic of the shared task in, which have been the milestones for the researching field of parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 9, "end_pos": 27, "type": "TASK", "confidence": 0.8772552907466888}]}, {"text": "This time, the task is taking a universal annotation version and trying to exploit cross-linguistic similarities between various languages.", "labels": [], "entities": []}, {"text": "In this paper, we describe the system of team Wanghao-ftd-SJTU for the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to.", "labels": [], "entities": [{"text": "CoNLL 2017 Shared Task", "start_pos": 71, "end_pos": 93, "type": "DATASET", "confidence": 0.834917813539505}]}, {"text": "For this task, we only use provided treebanks to train models without any other resources including pretrained embeddings.", "labels": [], "entities": []}, {"text": "For dependency parsing, there have been two major parsing methods: graph-based and transition-based.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.8238905966281891}]}, {"text": "The former searches for the final tree through graph algorithms by decomposing trees into factors, utilizing ingenious dynamic programming algorithms); while the latter parses sentences by making a series of shift-reduce decisions).", "labels": [], "entities": []}, {"text": "In our system, we will utilize the transition-based system for its simplicity and relatively lower computation cost.", "labels": [], "entities": []}, {"text": "Transition-based dependency parsing takes linear time complexity and utilizes rich features to make structural prediction ().", "labels": [], "entities": [{"text": "Transition-based dependency parsing", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.5839383602142334}, {"text": "structural prediction", "start_pos": 100, "end_pos": 121, "type": "TASK", "confidence": 0.6562150716781616}]}, {"text": "Specifically, a buffer for input words, a stack for partially built structure and shift-reduce actions are basic elements in a transition-based dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 144, "end_pos": 162, "type": "TASK", "confidence": 0.6624942123889923}]}, {"text": "For the transition systems of dependency parsing, there have been two major ones: arc-standard and arc-eager.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.8202621936798096}]}, {"text": "Our system adopts the former, whose basic algorithm can be described as 191 following: where \u03c3, \u03b2, A represent the stack, queue and the actions respectively.", "labels": [], "entities": []}, {"text": "One major difference for parsing between the situation of current and that often years ago is that recently we have seen a rising of neural network based methods in the field of Natural Language Processing and parsing has also been greatly changed by the neural methods.", "labels": [], "entities": [{"text": "parsing", "start_pos": 25, "end_pos": 32, "type": "TASK", "confidence": 0.9883655309677124}, {"text": "parsing", "start_pos": 210, "end_pos": 217, "type": "TASK", "confidence": 0.9697731733322144}]}, {"text": "With distributed representation for words and sentences and the powerful non-linear calculation ability of the neural networks, we could explore deeper syntactic and maybe semantic meaning in text analysis, and both graph-based ( and transition-based) parsing have benefited a lot from neural representation learnings.", "labels": [], "entities": []}, {"text": "In our system, the model, which is trained by UDPipe, for the transition action predictor is also based on neural network, which is similar to the one of.", "labels": [], "entities": [{"text": "UDPipe", "start_pos": 46, "end_pos": 52, "type": "DATASET", "confidence": 0.790364146232605}, {"text": "transition action predictor", "start_pos": 62, "end_pos": 89, "type": "TASK", "confidence": 0.6577811539173126}]}, {"text": "For this shared task, our system is built based on UDpipe (, which provides a pipeline from raw text to dependency structures, including a tokenizer, taggers and the dependency predictor.", "labels": [], "entities": []}, {"text": "We trained and tuned the models on different treebanks, and in the final evaluation, a score of 66.53% in macro-averaged LAS F1-score measurement is achieved.", "labels": [], "entities": [{"text": "LAS F1-score measurement", "start_pos": 121, "end_pos": 145, "type": "METRIC", "confidence": 0.8186629414558411}]}, {"text": "In the task, there are several surprise languages which lack of annotated resources, which means it is hard to train specified models for those languages.", "labels": [], "entities": []}, {"text": "To tackle this problem, we exploit the universal part-of-speech (POS) tags, which could be represented as crosslingual knowledge to avoid language-specific information, and adopting a delexicalized and crosslingual method, which relies solely on universal POS tags and annotated data in close-related languages.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: Section 2 describes our system overview, Section 3 elaborates the components of the system, Section 4 shows the experiments and results for our participation in the shared task, and Section 5 concludes this paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Parameters for the training of parsers.", "labels": [], "entities": []}, {"text": " Table 5: Results of main types of treebanks.", "labels": [], "entities": []}, {"text": " Table 6: Final LAS scores for the surprise lan- guages.", "labels": [], "entities": [{"text": "LAS", "start_pos": 16, "end_pos": 19, "type": "METRIC", "confidence": 0.6751040816307068}]}, {"text": " Table 7: Final results for the task.", "labels": [], "entities": []}]}