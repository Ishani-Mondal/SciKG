{"title": [{"text": "Learning local and global contexts using a convolutional recurrent network model for relation classification in biomedical text", "labels": [], "entities": [{"text": "relation classification", "start_pos": 85, "end_pos": 108, "type": "TASK", "confidence": 0.8135989308357239}]}], "abstractContent": [{"text": "The task of relation classification in the biomedical domain is complex due to the presence of samples obtained from heterogeneous sources such as research articles , discharge summaries, or electronic health records.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 12, "end_pos": 35, "type": "TASK", "confidence": 0.9435025453567505}]}, {"text": "It is also a constraint for classifiers which employ manual feature engineering.", "labels": [], "entities": []}, {"text": "In this paper, we propose a convolutional recurrent neural network (CRNN) architecture that combines RNNs and CNNs in sequence to solve this problem.", "labels": [], "entities": []}, {"text": "The rationale behind our approach is that CNNs can effectively identify coarse-grained local features in a sentence , while RNNs are more suited for long-term dependencies.", "labels": [], "entities": []}, {"text": "We compare our CRNN model with several baselines on two biomedical datasets, namely the i2b2-2010 clinical relation extraction challenge dataset, and the SemEval-2013 DDI extraction dataset.", "labels": [], "entities": [{"text": "clinical relation extraction challenge", "start_pos": 98, "end_pos": 136, "type": "TASK", "confidence": 0.6450736373662949}, {"text": "SemEval-2013 DDI extraction dataset", "start_pos": 154, "end_pos": 189, "type": "DATASET", "confidence": 0.7066450640559196}]}, {"text": "We also evaluate an attentive pooling technique and report its performance in comparison with the conventional max pooling method.", "labels": [], "entities": []}, {"text": "Our results indicate that the proposed model achieves state-of-the-art performance on both datasets.", "labels": [], "entities": []}], "introductionContent": [{"text": "Relation classification is the task of identifying the semantic relation present between a given pair of entities in apiece of text.", "labels": [], "entities": [{"text": "Relation classification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9649509787559509}]}, {"text": "Since most search queries are some forms of binary factoids (), modern questionanswering systems rely heavily upon relation classification as a preprocessing step (Fleischman The code for the can be found at: https://github.com/desh2608/ crnn-relation-classification.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 115, "end_pos": 138, "type": "TASK", "confidence": 0.7513103783130646}]}, {"text": "Accurate relation classification also facilitates discourse processing and precise sentence interpretations.", "labels": [], "entities": [{"text": "Accurate relation classification", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.723081092039744}, {"text": "discourse processing", "start_pos": 50, "end_pos": 70, "type": "TASK", "confidence": 0.7183490693569183}, {"text": "precise sentence interpretations", "start_pos": 75, "end_pos": 107, "type": "TASK", "confidence": 0.6033217906951904}]}, {"text": "Hence, this task has witnessed a great deal of attention over the last decade ().", "labels": [], "entities": []}, {"text": "In the biomedical domain, in particular, extracting such tuples from data maybe essential for identifying protein and drug interactions, symptoms and causes of diseases, among others.", "labels": [], "entities": []}, {"text": "Further, since clinical data tends to be obtained from multiple (and diverse) information sources such as journal articles, discharge summaries, and electronic patient records, relation classification becomes a more challenging task.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 177, "end_pos": 200, "type": "TASK", "confidence": 0.9834169447422028}]}, {"text": "To identify relations between entities, a variety of lexical, syntactic, or pragmatic cues maybe exploited, which results in a challenging variability in the type of features used for classification purpose.", "labels": [], "entities": []}, {"text": "Due to this variability, a number of approaches have been suggested, some of which rely on features extracted from POS tagging, morphological analysis, dependency parsing, and world knowledge).", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 115, "end_pos": 126, "type": "TASK", "confidence": 0.7220539748668671}, {"text": "dependency parsing", "start_pos": 152, "end_pos": 170, "type": "TASK", "confidence": 0.7935278713703156}]}, {"text": "Deep learning architectures have recently gathered much interest because of their ability to conveniently extract relevant features without the need of explicit feature engineering.", "labels": [], "entities": []}, {"text": "For this reason, a number of convolutional and recurrent neural network models ( have been used for this task.", "labels": [], "entities": []}, {"text": "In this paper, we propose a model that uses recurrent neural networks (RNNs) and convolutional neural networks (CNNs) in sequence to learn global and local context, respectively.", "labels": [], "entities": []}, {"text": "We refer to this as CRNN, following the naming convention used in (.", "labels": [], "entities": [{"text": "CRNN", "start_pos": 20, "end_pos": 24, "type": "DATASET", "confidence": 0.9287102818489075}]}, {"text": "We argue that in order for any classification task to be effective, the regression layer must see a complete representation of the sentence, i.e., both short and long-term dependencies must be appropriately represented in the sentence embedding.", "labels": [], "entities": []}, {"text": "This argument forms the basis of our approach.", "labels": [], "entities": []}, {"text": "Ina deep learning framework, since the complete information available to the classifier at the top-level is obtained through manipulation of the sentence embedding itself, the task of relation classification essentially emulates other popular objectives such as text classification and sentiment analysis if the representation for the entity types are integrated in the sentence.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 184, "end_pos": 207, "type": "TASK", "confidence": 0.8007141351699829}, {"text": "text classification", "start_pos": 262, "end_pos": 281, "type": "TASK", "confidence": 0.7758468985557556}, {"text": "sentiment analysis", "start_pos": 286, "end_pos": 304, "type": "TASK", "confidence": 0.9279328286647797}]}, {"text": "Although our proposed model uses RNNs and CNNs in sequence, it is only two layers deep, as opposed to the very deep architectures proposed earlier ().", "labels": [], "entities": []}, {"text": "This simplicity allows for intuitive understanding of each level of the model, while still learning a sufficiently complex representation of the input sentence.", "labels": [], "entities": []}, {"text": "In addition to local and global contexts, we also experiment with attention for relation classification.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 80, "end_pos": 103, "type": "TASK", "confidence": 0.925938069820404}]}, {"text": "Although attention as a concept is relatively well-known, especially in computational neuroscience (, it became popular only recently with applications to image captioning and machine translation ().", "labels": [], "entities": [{"text": "image captioning", "start_pos": 155, "end_pos": 171, "type": "TASK", "confidence": 0.7410286515951157}, {"text": "machine translation", "start_pos": 176, "end_pos": 195, "type": "TASK", "confidence": 0.8306869268417358}]}, {"text": "Attention has also been employed to some success in relation classification tasks ().", "labels": [], "entities": [{"text": "relation classification tasks", "start_pos": 52, "end_pos": 81, "type": "TASK", "confidence": 0.9524468382199606}]}, {"text": "In our experiments, we use an attention-based pooling strategy and compare the results with those obtained using conventional pooling methods.", "labels": [], "entities": []}, {"text": "Our model variants are accordingly named CRNNMax and CRNN-Att, depending upong the pooling scheme used.", "labels": [], "entities": []}, {"text": "Our model is distinctive in that it does not rely upon any linguistic feature for relation classification.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 82, "end_pos": 105, "type": "TASK", "confidence": 0.8597531020641327}]}, {"text": "In domains such as biomedicine, texts may not always be written in syntactically/grammatically correct form.", "labels": [], "entities": []}, {"text": "Furthermore, lack of necessary training data may not provide good feature extractors such as those in generic domains.", "labels": [], "entities": []}, {"text": "Hence, we explored only models without any extra features.", "labels": [], "entities": []}, {"text": "Of course, adding other features such as part-of-speech taggers or dependency parsers, if they are available easily, may improve the performance further.", "labels": [], "entities": [{"text": "part-of-speech taggers", "start_pos": 41, "end_pos": 63, "type": "TASK", "confidence": 0.728384792804718}]}, {"text": "Our key contributions in this paper are as follows: \u2022 We propose and validate a two-layer architecture comprising RNNs and CNNs in sequence for relation classification in biomedical text.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 144, "end_pos": 167, "type": "TASK", "confidence": 0.8173583447933197}]}, {"text": "Our model's performance is comparable to the state-of-the-art on two benchmark datasets, namely the i2b2-2010 clinical relation extraction challenge, and the SemEval-2013 DDI extraction dataset, without any need for handcrafted features.", "labels": [], "entities": [{"text": "clinical relation extraction challenge", "start_pos": 110, "end_pos": 148, "type": "TASK", "confidence": 0.6567831486463547}, {"text": "SemEval-2013 DDI extraction", "start_pos": 158, "end_pos": 185, "type": "TASK", "confidence": 0.6121223072210947}]}, {"text": "\u2022 We analyze and discuss why such a model effectively captures short and long-term dependencies in a sentence, and demonstrate why this representation facilitates classification.", "labels": [], "entities": []}, {"text": "\u2022 We evaluate an attention-based pooling technique and compare its performance with conventional pooling strategies.", "labels": [], "entities": []}, {"text": "\u2022 We provide evidence to further the argument in favor of using RNNs to obtain regional embeddings in a sentence.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have used 2 datasets for experimentation, namely the i2b2-2010 clinical relation extraction challenge dataset (, and the SemEval-2013 DDI extraction dataset (Segura).", "labels": [], "entities": [{"text": "clinical relation extraction challenge", "start_pos": 66, "end_pos": 104, "type": "TASK", "confidence": 0.6755056455731392}, {"text": "SemEval-2013 DDI extraction dataset (Segura)", "start_pos": 124, "end_pos": 168, "type": "DATASET", "confidence": 0.7711180448532104}]}], "tableCaptions": [{"text": " Table 1: Number of training and testing instances for each  relation type in the i2b2 dataset.", "labels": [], "entities": []}, {"text": " Table 2: Number of training and testing instances for each  relation type in the DDI extraction dataset.", "labels": [], "entities": [{"text": "DDI extraction dataset", "start_pos": 82, "end_pos": 104, "type": "DATASET", "confidence": 0.8039985100428263}]}, {"text": " Table 3: Average F1 scores on varying filter sizes f1 and f2  in the CRNN-Att model for i2b2 dataset.", "labels": [], "entities": [{"text": "F1", "start_pos": 18, "end_pos": 20, "type": "METRIC", "confidence": 0.9940306544303894}, {"text": "CRNN-Att model for i2b2 dataset", "start_pos": 70, "end_pos": 101, "type": "DATASET", "confidence": 0.7702857375144958}]}, {"text": " Table 4: Comparison of our proposed models CRNN-Max and CRNN-Att, with baselines, on the i2b2-2010 and DDI extraction  datasets.", "labels": [], "entities": [{"text": "DDI extraction  datasets", "start_pos": 104, "end_pos": 128, "type": "DATASET", "confidence": 0.9041023055712382}]}, {"text": " Table 5: Effect of initialization and update of word embed- dings in our proposed models, in terms of F1 score, using the  i2b2-2010 datset.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 103, "end_pos": 111, "type": "METRIC", "confidence": 0.9870918691158295}]}, {"text": " Table 6: Classwise performance (in terms of F1 score) of  various models on the i2b2 dataset.", "labels": [], "entities": [{"text": "F1 score)", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.979737917582194}, {"text": "i2b2 dataset", "start_pos": 81, "end_pos": 93, "type": "DATASET", "confidence": 0.7298590540885925}]}, {"text": " Table 7: Classwise performance comparison between SVM  and CRNN-Max using linguistic features. #1 denotes num- ber of sentences of a class classified correctly by SVM but  incorrectly by CRNN-Max; #2 denotes vice-versa.", "labels": [], "entities": []}]}