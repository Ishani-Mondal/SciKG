{"title": [{"text": "Encoding of phonology in a recurrent neural model of grounded speech", "labels": [], "entities": []}], "abstractContent": [{"text": "We study the representation and encoding of phonemes in a recurrent neural network model of grounded speech.", "labels": [], "entities": []}, {"text": "We use a model which processes images and their spoken descriptions, and projects the visual and auditory representations into the same semantic space.", "labels": [], "entities": []}, {"text": "We perform a number of analyses on how information about individual phonemes is encoded in the MFCC features extracted from the speech signal, and the activations of the layers of the model.", "labels": [], "entities": []}, {"text": "Via experiments with phoneme decoding and phoneme discrimination we show that phoneme representations are most salient in the lower layers of the model, where low-level signals are processed at a fine-grained level, although a large amount of phonological information is retain at the top recurrent layer.", "labels": [], "entities": [{"text": "phoneme discrimination", "start_pos": 42, "end_pos": 64, "type": "TASK", "confidence": 0.7323834598064423}]}, {"text": "We further find out that the attention mechanism following the top recurrent layer significantly attenuates encoding of phonology and makes the utterance embeddings much more invariant to synonymy.", "labels": [], "entities": []}, {"text": "Moreover, a hierarchical clustering of phoneme representations learned by the network shows an organizational structure of phonemes similar to those proposed in linguistics.", "labels": [], "entities": []}], "introductionContent": [{"text": "Spoken language is a universal human means of communication.", "labels": [], "entities": []}, {"text": "As such, its acquisition and representation in the brain is an essential topic in the study of the cognition of our species.", "labels": [], "entities": []}, {"text": "In the field of neuroscience there has been a long-standing interest in the understanding of neural representations of linguistic input inhuman brains, most commonly via the analysis of neuro-imaging data of participants exposed to simplified, highly controlled inputs.", "labels": [], "entities": []}, {"text": "More recently, naturalistic data has been used and patterns in the brain have been correlated with patterns in the input (e.g..", "labels": [], "entities": []}, {"text": "This type of approach is relevant also when the goal is the understanding of the dynamics in complex neural network models of speech understanding.", "labels": [], "entities": [{"text": "speech understanding", "start_pos": 126, "end_pos": 146, "type": "TASK", "confidence": 0.743047684431076}]}, {"text": "Firstly because similar techniques are often applicable, but more importantly because the knowledge of how the workings of artificial and biological neural networks are similar or different is valuable for the general enterprise of cognitive science.", "labels": [], "entities": []}, {"text": "Recent studies have implemented models which learn to understand speech in a weakly and indirectly supervised fashion from correlated audio and visual signal:;;.", "labels": [], "entities": []}, {"text": "This is a departure from typical Automatic Speech Recognition (ASR) systems which rely on large amounts of transcribed speech, and these recent models come closer to the way humans acquire language in a grounded setting.", "labels": [], "entities": [{"text": "Automatic Speech Recognition (ASR)", "start_pos": 33, "end_pos": 67, "type": "TASK", "confidence": 0.8180191020170847}]}, {"text": "It is thus especially interesting to investigate to what extent the traditional levels of linguistic analysis such as phonology, morphology, syntax and semantics are encoded in the activations of the hidden layers of these models.", "labels": [], "entities": []}, {"text": "There area small number of studies which focus on the syntax and/or semantics in the context of neural models of written language (e.g..", "labels": [], "entities": []}, {"text": "Taking it a step further, and investigate the levels of representations in models which learn language from phonetic transcriptions and from the speech signal, respectively.", "labels": [], "entities": []}, {"text": "Neither of these tackles the representation of phonology in any great depth.", "labels": [], "entities": []}, {"text": "Instead they work with relatively coarse-grained distinctions between form and meaning.", "labels": [], "entities": []}, {"text": "In the current work we use controlled synthetic stimuli, as well as alignment between the audio signal and phonetic transcription of spoken utterances to extract phoneme representation vectors based on the activations on the hidden layers of a model of grounded speech perception.", "labels": [], "entities": []}, {"text": "We use these representations to carryout analyses of the representation of phonemes at a fine-grained level.", "labels": [], "entities": []}, {"text": "Ina series of experiments, we show that the lower layers of the model encode accurate representations of the phonemes which can be used in phoneme identification and classification with high accuracy.", "labels": [], "entities": [{"text": "phoneme identification and classification", "start_pos": 139, "end_pos": 180, "type": "TASK", "confidence": 0.6968028843402863}, {"text": "accuracy", "start_pos": 191, "end_pos": 199, "type": "METRIC", "confidence": 0.9866206645965576}]}, {"text": "We further investigate how the phoneme inventory is organised in the activation space of the model.", "labels": [], "entities": []}, {"text": "Finally, we tackle the general issue of the representation of phonological form versus meaning with a controlled task of synonym discrimination.", "labels": [], "entities": [{"text": "synonym discrimination", "start_pos": 121, "end_pos": 143, "type": "TASK", "confidence": 0.814204216003418}]}, {"text": "Our results show that the bottom layers in the multi-layer recurrent neural network learn invariances which enable it to encode phonemes independently of co-articulatory context, and that they represent phonemic categories closely matching usual classifications from linguistics.", "labels": [], "entities": []}, {"text": "Phonological form becomes harder to detect in higher layers of the network, which increasingly focus on representing meaning over form, but encoding of phonology persists to a significant degree up to the top recurrent layer.", "labels": [], "entities": []}, {"text": "We make the data and open-source code to reproduce our results publicly available at github.com/gchrupala/encoding-of-phonology.", "labels": [], "entities": []}], "datasetContent": [{"text": "The phoneme representations in each layer are calculated as the activations averaged over the duration of the phoneme occurrence in the input.", "labels": [], "entities": []}, {"text": "The average input vectors are similarly calculated as the MFCC vectors averaged over the time course of the articulation of the phoneme occurrence.", "labels": [], "entities": []}, {"text": "When we need to represent a phoneme type we do so by averaging the vectors of all its occurrences in the validation set.", "labels": [], "entities": []}, {"text": "shows the phoneme inventory we work with; this is also the inventory used by Gentle/Kaldi (see Section 4.3).", "labels": [], "entities": [{"text": "Gentle/Kaldi", "start_pos": 77, "end_pos": 89, "type": "DATASET", "confidence": 0.8963402708371481}]}, {"text": "In this section we report on four experiments which we designed to elucidate to what extent information about phonology is represented in the activations of the layers of the COCO Speech model.", "labels": [], "entities": [{"text": "COCO Speech model", "start_pos": 175, "end_pos": 192, "type": "DATASET", "confidence": 0.7119856476783752}]}, {"text": "In Section 5.1 we quantify how easy it is to decode phoneme identity from activations.", "labels": [], "entities": []}, {"text": "In Section 5.2 we determine phoneme discriminability in a controlled task with minimal pair stimuli.", "labels": [], "entities": []}, {"text": "organized in the activation space of the model.", "labels": [], "entities": []}, {"text": "Finally, in Section 5.4 we tackle the general issue of the representation of phonological form versus meaning with the controlled task of synonym discrimination.", "labels": [], "entities": [{"text": "synonym discrimination", "start_pos": 138, "end_pos": 160, "type": "TASK", "confidence": 0.8344610333442688}]}], "tableCaptions": [{"text": " Table 3: Accuracy of choosing the correct target  in an ABX task using different representations.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9885529279708862}]}, {"text": " Table 1. There is substan- tial degree of matching between the classes and  the structure of the hierarchy, but also some mix- ing between rounded back vowels and voiced plo- sives /b/ and /g/, which share articulatory features  such as lip movement or tongue position.", "labels": [], "entities": []}]}