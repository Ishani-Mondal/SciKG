{"title": [{"text": "Adversarial Training for Cross-Domain Universal Dependency Parsing", "labels": [], "entities": [{"text": "Cross-Domain Universal Dependency Parsing", "start_pos": 25, "end_pos": 66, "type": "TASK", "confidence": 0.5937403067946434}]}], "abstractContent": [{"text": "We describe our submission to the CoNLL 2017 shared task, which exploits the shared common knowledge of a language across different domains via a domain adaptation technique.", "labels": [], "entities": [{"text": "CoNLL 2017 shared task", "start_pos": 34, "end_pos": 56, "type": "DATASET", "confidence": 0.809009239077568}]}, {"text": "Our approach is an extension to the recently proposed ad-versarial training technique for domain adaptation, which we apply on top of a graph-based neural dependency parsing model on bidirectional LSTMs.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 90, "end_pos": 107, "type": "TASK", "confidence": 0.7673709988594055}]}, {"text": "In our experiments, we find our baseline graph-based parser already outperforms the official baseline model (UDPipe) by a large margin.", "labels": [], "entities": []}, {"text": "Further, by applying our technique to the treebanks of the same language with different domains, we observe an additional gain in the performance, in particular for the domains with less training data.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the CoNLL 2017 shared task (, some language data is available in more than one treebanks typically from different annotation projects.", "labels": [], "entities": [{"text": "CoNLL 2017 shared task", "start_pos": 7, "end_pos": 29, "type": "DATASET", "confidence": 0.8655291497707367}]}, {"text": "While the treebanks differ in many respects such as the genre and the source of the text (i.e., original or translated text), the most notable difference is that the size of the treebanks often varies significantly.", "labels": [], "entities": []}, {"text": "For example, there are three variants of English treebanks: en, en lines, and en parunt, in which the largest dataset en contains 12,543 training sentences while en lines and en parunt contain only 2,738 and 1,090 sentences, respectively.", "labels": [], "entities": []}, {"text": "In this paper, we describe our approach to improve the parser performance for the treebanks with lesser training data (e.g., en lines and en parunt), by jointly learning with the dominant treebank of the same language (e.g, en).", "labels": [], "entities": []}, {"text": "We formulate our approach as a kind of domain adaptation, in which we treat the dominant treebank as the source domain while the others as the target domains.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.7717853486537933}]}, {"text": "Our approach to domain adaptation, which we call SharedGateAdvNet, is an extension to the recently proposed neural architecture for domain adaptation () with adversarial training (), which learns domain-invariant feature representations through an adversarial domain classifier.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 16, "end_pos": 33, "type": "TASK", "confidence": 0.7626043558120728}, {"text": "domain adaptation", "start_pos": 132, "end_pos": 149, "type": "TASK", "confidence": 0.7455041110515594}]}, {"text": "We extend this architecture with an additional neural layer for each domain, which captures domainspecific feature representations.", "labels": [], "entities": []}, {"text": "To our knowledge this is the first study to apply the adversarial training-based domain adaptation to parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 102, "end_pos": 109, "type": "TASK", "confidence": 0.9663698077201843}]}, {"text": "We utilize this architecture to obtain the representation of each token of a sentence, and feed it into a graph-based dependency parsing model where each dependency arc score is calculated using bilinear attention).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 118, "end_pos": 136, "type": "TASK", "confidence": 0.7384079694747925}]}, {"text": "Specifically, we obtain the domainspecific and domain-invariant feature representations for each token via separate bidirectional LSTMs (Bi-LSTMs), and then combine them via a gated mechanism.", "labels": [], "entities": []}, {"text": "Our baseline method is our reimplementation of the graph-based dependency parser with LSTMs) trained with a single treebank.", "labels": [], "entities": []}, {"text": "First, we observe that this model is already much stronger than the official baseline model of UDPipe () inmost treebanks.", "labels": [], "entities": []}, {"text": "We then apply our domain adaptation technique to the set of treebanks of the same language, and inmost cases we observe a clear improvement of the scores, especially for the treebanks with lesser training data.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 18, "end_pos": 35, "type": "TASK", "confidence": 0.7048458606004715}]}, {"text": "We also try our architecture across multiple languages, i.e., a high-resource language with a large treebank, such as English, and a low-resource language with a small data set.", "labels": [], "entities": []}, {"text": "Interestingly, even though the mixed languages are completely different, we observe some score improvements in low-resource languages with this approach.", "labels": [], "entities": []}, {"text": "Finally we rank the 6th place on the main result of the shared task.", "labels": [], "entities": []}], "datasetContent": [{"text": "Before selecting the final submitted model for each treebank (Section 5.3) here we perform a small experiment on selected languages (English and French) to seethe effectiveness of our domain adaptation techniques.", "labels": [], "entities": []}, {"text": "English experiment First, for English, we compare the performances of several domain adaptation techniques as well as the baselines without adaptation, to see which technique performs better.", "labels": [], "entities": []}, {"text": "We compare the following six systems: \u2022 UDPipe: The official baseline parser (.", "labels": [], "entities": []}, {"text": "This is a transition-based parser selecting each action using neural networks.", "labels": [], "entities": []}, {"text": "\u2022 Biaffine: Our reimplementation of the graphbased parser of.", "labels": [], "entities": []}, {"text": "We use Chainer (Tokui et al., 2015) for our implementation.", "labels": [], "entities": []}, {"text": "We train this model independently on each treebank.", "labels": [], "entities": []}, {"text": "\u2022  this by removing the domain classification component in.", "labels": [], "entities": [{"text": "domain classification", "start_pos": 24, "end_pos": 45, "type": "TASK", "confidence": 0.7170852273702621}]}, {"text": "\u2022 Biaffine-MIX + Adv: The model in, which shares the same parameters across multiple domains but adversarial training facilitates learning domain-invariant representations.", "labels": [], "entities": []}, {"text": "\u2022 SharedGateNet: A simpler version of our proposed architecture), which does not have the adversarial component but has the gated unit controlling the strength of the two, domain-invariant and domain-specific Bi-LSTMs.", "labels": [], "entities": []}, {"text": "\u2022 SharedGateAdvNet: Our full architecture () with both adversarial training and the gated unit.", "labels": [], "entities": []}, {"text": "The result is shown in.", "labels": [], "entities": []}, {"text": "First, we find that our baseline biaffine parser already outperforms the official baseline parser (UDPipe) by a large margin (e.g., for English, 82.45 vs. 80.13 LAS), which suggests the strength of graphbased parsing with Bi-LSTMs that enable the model to capture the entire sentence as a context.", "labels": [], "entities": [{"text": "LAS", "start_pos": 161, "end_pos": 164, "type": "METRIC", "confidence": 0.9415379762649536}]}, {"text": "By just mixing the training treebanks (Biaffine-MIX), we observe a score improvement for the domains with less data, en lines and en parunt, which only contain 2,738 and 1,090 sentences, respectively.", "labels": [], "entities": [{"text": "Biaffine-MIX", "start_pos": 39, "end_pos": 51, "type": "METRIC", "confidence": 0.8291919231414795}]}, {"text": "We also observe an additional small gain with adversarial training (Biaffine-MIX Adv).", "labels": [], "entities": []}, {"text": "Comparing with this, our proposed architectures (SharedGateNet and SharedGateAdvNet) perform better.", "labels": [], "entities": []}, {"text": "This shows the importance of having the domain-specific network layers.", "labels": [], "entities": []}, {"text": "Our final architecture SharedGateAdvNet slightly outperforms SharedGateNet, indicating that the adversarial technique also has its own advantage.", "labels": [], "entities": []}, {"text": "Since SharedGateAdvNet consitently outperforms the others in English, we only try this method in the following experiments.", "labels": [], "entities": []}, {"text": "English and French experiment To seethe effects of our approach when combining completely different data, i.e., different language treebanks, we perform a small experiment using two languages: English and French.", "labels": [], "entities": []}, {"text": "French treebanks are also divided into three domains and also are imbalanced: fr (14,553 sentences), fr partut (620 sentences), and fr sequoria (2,231 sentences).", "labels": [], "entities": [{"text": "French treebanks", "start_pos": 0, "end_pos": 16, "type": "DATASET", "confidence": 0.9650668203830719}]}, {"text": "We compare the models trained within each language (3 domains for each), and the model trained with all six treebanks of English and French.", "labels": [], "entities": []}, {"text": "The result is shown in.", "labels": [], "entities": []}, {"text": "Interestingly, especially for fr partut and fr sequoria, we observe a small score improvement by jointly learning two languages.", "labels": [], "entities": []}, {"text": "The best model for fr is the biaffine model without joint training.", "labels": [], "entities": []}, {"text": "Note also that for en, the effect of the adaptation technique is very small, or: The result of our experiment for model selection on the development data.", "labels": [], "entities": []}, {"text": "(i), (ii), and (iii) correspond to the differnt domain adaptation strategies found in the body.", "labels": [], "entities": []}, {"text": "negative, and these suggest our approach maybe ineffective fora treebank that already contains sufficient amount of data.", "labels": [], "entities": []}, {"text": "Due to time constraints, we were unable to try many language pairs for joint training, but this result suggests the parser may benefit from training across different languages.", "labels": [], "entities": []}, {"text": "For the final experiment for model selection below, we try some other pairs for some languages, and select those models when they perform better.", "labels": [], "entities": [{"text": "model selection", "start_pos": 29, "end_pos": 44, "type": "TASK", "confidence": 0.6807606667280197}]}, {"text": "The main result of CoNLL 2017 shared task on the test data is shown in.", "labels": [], "entities": [{"text": "CoNLL 2017 shared task", "start_pos": 19, "end_pos": 41, "type": "DATASET", "confidence": 0.8394638150930405}]}, {"text": "In addition to the official baseline (UDPipe) and our system, we also report the scores of the winning system by the Stanford team.", "labels": [], "entities": []}, {"text": "See for the overview of the other participating systems.", "labels": [], "entities": []}, {"text": "Our system outperforms UDPipe in many test treebanks, 69 out of 81 treebanks.", "labels": [], "entities": []}, {"text": "We find many cases that UDPipe performs better are when the training teebank is very small, e.g., Kazakh (kk), Ukrainian (uk), and Uyghur (ug), or not available at all, i.e., surprise languages: Buryat (bxr), Kurmanji (kmr), Upper Sorbian (hsb), and North S` ami (sme), for which our approach is somewhat naive (Section 2) and UDPipe performs always better.", "labels": [], "entities": []}, {"text": "We can also see that for some treebanks (e.g., et, fi pub and hu), our system performs better in UAS while worse in LAS.", "labels": [], "entities": [{"text": "UAS", "start_pos": 97, "end_pos": 100, "type": "DATASET", "confidence": 0.6196622252464294}]}, {"text": "This maybe due to the design of the baseline biaffine model, which determines the best unlabeled tree before assigning the labels (Section 3), i.e., does not perform labeled parsing as a single task.", "labels": [], "entities": []}, {"text": "Our system (NAIST-SATO) achieves the overall average LAS of 70.13, which is the 6th rank among 33 participants in the shared task.", "labels": [], "entities": [{"text": "NAIST-SATO", "start_pos": 12, "end_pos": 22, "type": "DATASET", "confidence": 0.9367780089378357}, {"text": "LAS", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.9982134103775024}]}, {"text": "UDPipe (68.35) is the 13th rank.", "labels": [], "entities": [{"text": "UDPipe", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.6585157513618469}]}], "tableCaptions": [{"text": " Table 1: The result of our preliminary English experiment across multiple domains. UDPipe and Biaffine  are trained separately for each language, while the other models are trained across all domains jointly.", "labels": [], "entities": [{"text": "Biaffine", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.8974065184593201}]}, {"text": " Table 2: The result of our preliminary experiment across different languages (English and French). Ours  (domain) is trained for each language across multiple domains by SharedGateAdvNet. Ours (domain,  lang) is trained with all six treebanks of two languages jointly. Joint training of two languages brings a  small improvement on the smaller French treebanks (fr partut and fr sequoia).", "labels": [], "entities": []}, {"text": " Table 3: The result of our experiment for model selection on the development data. (i), (ii), and (iii)  correspond to the differnt domain adaptation strategies found in the body.", "labels": [], "entities": []}, {"text": " Table 4: The main result on the test data.", "labels": [], "entities": []}]}