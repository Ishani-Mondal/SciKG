{"title": [{"text": "Optimizing Differentiable Relaxations of Coreference Evaluation Metrics", "labels": [], "entities": [{"text": "Optimizing Differentiable Relaxations of Coreference Evaluation Metrics", "start_pos": 0, "end_pos": 71, "type": "TASK", "confidence": 0.7386707876409803}]}], "abstractContent": [{"text": "Coreference evaluation metrics are hard to optimize directly as they are non-differentiable functions, not easily decom-posable into elementary decisions.", "labels": [], "entities": [{"text": "Coreference evaluation", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8705945014953613}]}, {"text": "Consequently , most approaches optimize objectives only indirectly related to the end goal, resulting in suboptimal performance.", "labels": [], "entities": []}, {"text": "Instead, we propose a differentiable relaxation that lends itself to gradient-based optimisation, thus bypassing the need for reinforcement learning or heuristic modification of cross-entropy.", "labels": [], "entities": []}, {"text": "We show that by modifying the training objective of a competitive neural coreference system, we obtain a substantial gain in performance.", "labels": [], "entities": []}, {"text": "This suggests that our approach can be regarded as a viable alternative to using reinforcement learning or more computation-ally expensive imitation learning.", "labels": [], "entities": []}], "introductionContent": [{"text": "Coreference resolution is the task of identifying all mentions which refer to the same entity in a document.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9150610268115997}]}, {"text": "It has been shown beneficial in many natural language processing (NLP) applications, including question answering () and information extraction, and often regarded as a prerequisite to any text understanding task.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 37, "end_pos": 70, "type": "TASK", "confidence": 0.7551057537396749}, {"text": "question answering", "start_pos": 95, "end_pos": 113, "type": "TASK", "confidence": 0.8980478942394257}, {"text": "information extraction", "start_pos": 121, "end_pos": 143, "type": "TASK", "confidence": 0.8476179242134094}, {"text": "text understanding task", "start_pos": 189, "end_pos": 212, "type": "TASK", "confidence": 0.8568968971570333}]}, {"text": "Coreference resolution can be regarded as a clustering problem: each cluster corresponds to a single entity and consists of all its mentions in a given text.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9389287829399109}]}, {"text": "Consequently, it is natural to evaluate predicted clusters by comparing them with the ones annotated by human experts, and this is exactly what the standard metrics (e.g., MUC, B 3 , CEAF) do.", "labels": [], "entities": [{"text": "MUC", "start_pos": 172, "end_pos": 175, "type": "DATASET", "confidence": 0.7654005885124207}, {"text": "B 3", "start_pos": 177, "end_pos": 180, "type": "METRIC", "confidence": 0.5027606040239334}]}, {"text": "In contrast, most state-of-theart systems are optimized to make individual coreference decisions, and such losses are only indirectly related to the metrics.", "labels": [], "entities": []}, {"text": "One way to deal with this challenge is to optimize directly the non-differentiable metrics using reinforcement learning (RL), for example, relying on the REINFORCE policy gradient algorithm.", "labels": [], "entities": [{"text": "reinforcement learning (RL)", "start_pos": 97, "end_pos": 124, "type": "TASK", "confidence": 0.639135479927063}, {"text": "REINFORCE policy gradient", "start_pos": 154, "end_pos": 179, "type": "TASK", "confidence": 0.5905387898286184}]}, {"text": "However, this approach has not been very successful, which, as suggested by, is possibly due to the discrepancy between sampling decisions at training time and choosing the highest ranking ones attest time.", "labels": [], "entities": []}, {"text": "A more successful alternative is using a 'roll-out' stage to associate cost with possible decisions, as in, but it is computationally expensive.", "labels": [], "entities": []}, {"text": "Imitation learning (, though also exploiting metrics, requires access to an expert policy, with exact policies not directly computable for the metrics of interest.", "labels": [], "entities": [{"text": "Imitation learning", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9767401814460754}]}, {"text": "In this work, we aim at combining the best of both worlds by proposing a simple method that can turn popular coreference evaluation metrics into differentiable functions of model parameters.", "labels": [], "entities": []}, {"text": "As we show, this function can be computed recursively using scores of individual local decisions, resulting in a simple and efficient estimation procedure.", "labels": [], "entities": []}, {"text": "The key idea is to replace nondifferentiable indicator functions (e.g. the member function I(m \u2208 S)) with the corresponding posterior probabilities (p(m \u2208 S)) computed by the model.", "labels": [], "entities": []}, {"text": "Consequently, non-differentiable functions used within the metrics (e.g. the set size function |S| = m I(m \u2208 S)) become differentiable (|S| c = m p(m \u2208 S)).", "labels": [], "entities": []}, {"text": "Though we assume that the scores of the underlying statistical model can be used to define a probability model, we show that this is not a serious limitation.", "labels": [], "entities": []}, {"text": "Specifically, as a baseline we use a probabilistic version of the neural mention-ranking model of, which on its own outperforms the original one and achieves similar performance to its global version).", "labels": [], "entities": []}, {"text": "Importantly when we use the introduced differentiable relaxations in training, we observe a substantial gain in performance over our probabilistic baseline.", "labels": [], "entities": []}, {"text": "Interestingly, the absolute improvement (+0.52) is higher than the one reported in Clark and Manning (2016a) using RL (+0.05) and the one using reward rescaling 1 (+0.37).", "labels": [], "entities": [{"text": "absolute", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.983966052532196}, {"text": "RL", "start_pos": 115, "end_pos": 117, "type": "METRIC", "confidence": 0.9849615097045898}]}, {"text": "This suggests that our method provides a viable alternative to using RL and reward rescaling.", "labels": [], "entities": [{"text": "RL", "start_pos": 69, "end_pos": 71, "type": "TASK", "confidence": 0.921274721622467}]}, {"text": "The outline of our paper is as follows: we introduce our neural resolver baseline and the B 3 and LEA metrics in Section 2.", "labels": [], "entities": [{"text": "B 3 and LEA metrics", "start_pos": 90, "end_pos": 109, "type": "METRIC", "confidence": 0.8156638622283936}]}, {"text": "Our method to turn a mention ranking resolver into an entity-centric resolver is presented in Section 3, and the proposed differentiable relaxations in Section 4.", "labels": [], "entities": []}, {"text": "Section 5 shows our experimental results.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use five most popular metrics 4 , \u2022 MUC (Vilain et al., 1995), \u2022 B 3 (Bagga and Baldwin, 1998), \u2022 CEAF m , CEAF e (Luo, 2005), \u2022 BLANC ( ), \u2022 LEA (.", "labels": [], "entities": [{"text": "MUC", "start_pos": 39, "end_pos": 42, "type": "METRIC", "confidence": 0.8584851026535034}, {"text": "B 3", "start_pos": 68, "end_pos": 71, "type": "METRIC", "confidence": 0.9694895148277283}, {"text": "BLANC", "start_pos": 132, "end_pos": 137, "type": "METRIC", "confidence": 0.9977858066558838}, {"text": "LEA", "start_pos": 145, "end_pos": 148, "type": "METRIC", "confidence": 0.9944655299186707}]}, {"text": "However, because MUC is the least discriminative metric, whereas CEAF is slow to compute, out of the five most popular metrics we incorporate into our loss only B 3 . In addition, we integrate LEA, as it has been shown to provide a good balance between discriminativity and interpretability.", "labels": [], "entities": [{"text": "MUC", "start_pos": 17, "end_pos": 20, "type": "METRIC", "confidence": 0.7755780220031738}, {"text": "CEAF", "start_pos": 65, "end_pos": 69, "type": "METRIC", "confidence": 0.6081832051277161}, {"text": "LEA", "start_pos": 193, "end_pos": 196, "type": "METRIC", "confidence": 0.8510351777076721}]}, {"text": ".., G N } and S = {S 1 , S 2 , ..., S M } be the gold-standard entity set and an entity set given by a resolver.", "labels": [], "entities": []}, {"text": "Recall that an entity is a set of mentions.", "labels": [], "entities": []}, {"text": "The recall and precision of the B 3 metric is computed by: The LEA metric is computed as: where link(E) = |E| \u00d7 (|E| \u2212 1)/2 is the number of coreference links in entity E.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9993969202041626}, {"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9989325404167175}, {"text": "LEA metric", "start_pos": 63, "end_pos": 73, "type": "METRIC", "confidence": 0.9638617634773254}]}, {"text": "F \u03b2 , for both metrics, is defined by:: For each mention mu there is a potential entity Eu so that mu is the first mention in the chain.", "labels": [], "entities": []}, {"text": "Computing p(m i \u2208 Eu ), u < i takes into the account all directed paths from mi to Eu (black arrows).", "labels": [], "entities": []}, {"text": "Noting that there is no directed path from any m k , k < u to Eu because p(m k \u2208 Eu ) = 0.", "labels": [], "entities": []}, {"text": "(See text for more details.)", "labels": [], "entities": []}, {"text": "We now demonstrate how to use the proposed differentiable B 3 and LEA to train a coreference resolver.", "labels": [], "entities": [{"text": "LEA", "start_pos": 66, "end_pos": 69, "type": "METRIC", "confidence": 0.9214755296707153}, {"text": "coreference resolver", "start_pos": 81, "end_pos": 101, "type": "TASK", "confidence": 0.9074400067329407}]}, {"text": "The source code and trained models are available at https://github.com/ lephong/diffmetric_coref.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results (F 1 ) on CoNLL 2012 test set. CoNLL is the average of MUC, B 3 , and CEAF e .", "labels": [], "entities": [{"text": "CoNLL 2012 test set", "start_pos": 28, "end_pos": 47, "type": "DATASET", "confidence": 0.9633093923330307}, {"text": "CoNLL", "start_pos": 49, "end_pos": 54, "type": "DATASET", "confidence": 0.6435017585754395}, {"text": "MUC", "start_pos": 73, "end_pos": 76, "type": "DATASET", "confidence": 0.6451693773269653}, {"text": "CEAF", "start_pos": 88, "end_pos": 92, "type": "DATASET", "confidence": 0.5546678304672241}]}]}