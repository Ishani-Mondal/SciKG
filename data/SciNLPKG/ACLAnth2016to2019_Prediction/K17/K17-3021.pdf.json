{"title": [{"text": "Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies", "labels": [], "entities": [{"text": "Multilingual Parsing from Raw Text", "start_pos": 13, "end_pos": 47, "type": "TASK", "confidence": 0.8294702887535095}]}], "abstractContent": [{"text": "This paper describes UALing's approach to the CoNLL 2017 UD Shared Task using corpus selection techniques to reduce training data size.", "labels": [], "entities": [{"text": "CoNLL 2017 UD Shared Task", "start_pos": 46, "end_pos": 71, "type": "DATASET", "confidence": 0.8831810712814331}]}, {"text": "The methodology is simple: We use similarity measures to select a corpus from available training data (even from multiple corpora for surprise languages) and use the resulting corpus to complete the parsing task.", "labels": [], "entities": []}, {"text": "The training and parsing is done with the baseline UDPipe system (Straka et al., 2016).", "labels": [], "entities": [{"text": "parsing", "start_pos": 17, "end_pos": 24, "type": "TASK", "confidence": 0.9788197875022888}]}, {"text": "While our approach reduces the size of training data significantly , it retains performance within 0.5% of the baseline system.", "labels": [], "entities": []}, {"text": "Due to the reduction in training data size, our system performs faster than the na\u00a8\u0131vena\u00a8\u0131ve, complete corpus method.", "labels": [], "entities": []}, {"text": "Specifically, our system runs in less than 10 minutes, ranking it among the fastest entries for this task.", "labels": [], "entities": []}, {"text": "Our system is available at https://github.", "labels": [], "entities": []}, {"text": "com/CoNLL-UD-2017/UALING.", "labels": [], "entities": [{"text": "CoNLL-UD-2017/UALING.", "start_pos": 4, "end_pos": 25, "type": "DATASET", "confidence": 0.8447796255350113}]}], "introductionContent": [{"text": "Universal Dependencies (UDs) ( includes corpora from different languages annotated with identical types of labels.", "labels": [], "entities": []}, {"text": "This allows for the examination of different theoretical) and practical applications such as the CoNLL 2017 UD Shared Task (.", "labels": [], "entities": [{"text": "CoNLL 2017 UD Shared Task", "start_pos": 97, "end_pos": 122, "type": "DATASET", "confidence": 0.869398581981659}]}, {"text": "The specific practical task presented here involves using these corpora in a supervised learning approach in order to achieve the task's goal: Training with the multilingual UD data in order to find dependency relationships not just for http://universaldependencies.org/ conll17 these known languages, but also for unknown or little-known language.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Monolingual corpus selection results on dev datasets. The numerical entries are LAS, and the  bar indicates corpus compression amount. Length-based is trimmed based on the length of sentences in  training data. Tri-gram POS sequences and POS-relation-POS are trimmed based on similarities between  full training and dev data. intersection applies two feature extraction together (POS sequences and POS- relation-POS trimming). Threshold is fixed for all languages (0.1). We also indicate ratios of trimming  of training datasets alongside parsing results.", "labels": [], "entities": [{"text": "Monolingual corpus selection", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.6460981468359629}, {"text": "LAS", "start_pos": 90, "end_pos": 93, "type": "METRIC", "confidence": 0.9893643856048584}, {"text": "Threshold", "start_pos": 437, "end_pos": 446, "type": "METRIC", "confidence": 0.9991699457168579}]}, {"text": " Table 2: POS-dep-POS thresholds for surprise languages", "labels": [], "entities": []}, {"text": " Table 4: LAS results per treebank. We highlight the score where we can improve the results compared  to the baseline system.", "labels": [], "entities": [{"text": "LAS", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9252727627754211}]}]}