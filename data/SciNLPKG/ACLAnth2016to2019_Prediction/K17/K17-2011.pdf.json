{"title": [{"text": "Seq2seq for Morphological Reinflection: When Deep Learning Fails", "labels": [], "entities": [{"text": "Morphological Reinflection: When Deep Learning Fails", "start_pos": 12, "end_pos": 64, "type": "TASK", "confidence": 0.6629023637090411}]}], "abstractContent": [{"text": "Recent studies showed that the sequence-to-sequence (seq2seq) model is a promising approach for morphological reinflec-tion.", "labels": [], "entities": []}, {"text": "At the CoNLL-SIGMORPHON 2017 Shared Task for universal morphological reinflection, we basically followed the approach with some minor variations.", "labels": [], "entities": [{"text": "CoNLL-SIGMORPHON 2017 Shared Task", "start_pos": 7, "end_pos": 40, "type": "DATASET", "confidence": 0.8268586546182632}, {"text": "universal morphological reinflection", "start_pos": 45, "end_pos": 81, "type": "TASK", "confidence": 0.5881347258885702}]}, {"text": "The results were remarkable in a certain sense.", "labels": [], "entities": []}, {"text": "In high-resource scenarios our system achieved 91.46% accuracy (only modestly behind the best system by 3.85%), and in medium-resource scenarios the performance was 65.06% (almost the same as baseline).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9982054233551025}]}, {"text": "In low-resource settings, however , the performance was only 1.58%, ranking the worst among submitted systems.", "labels": [], "entities": []}, {"text": "In this paper, we present system description and error analysis for the results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Processing morphological inflection is a fundamental task for the analysis and generation of natural languages and serves as a building block for many tasks such as machine translation, text analytics, and question answering.", "labels": [], "entities": [{"text": "Processing morphological inflection", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.7508202791213989}, {"text": "machine translation", "start_pos": 165, "end_pos": 184, "type": "TASK", "confidence": 0.7759952247142792}, {"text": "text analytics", "start_pos": 186, "end_pos": 200, "type": "TASK", "confidence": 0.7662343084812164}, {"text": "question answering", "start_pos": 206, "end_pos": 224, "type": "TASK", "confidence": 0.927489310503006}]}, {"text": "Whereas English is morphologically simple and abundant for resources, other languages are often morphologically rich and resource-poor, resulting in severe performance degradation.", "labels": [], "entities": []}, {"text": "To tackle the issue, the CoNLL-SIGMORPHON 2017 Shared Task hosted a shared task on universal morphological reinflection (, in which participants must solve the task for 52 languages and for high-, medium-, and lowresource settings.", "labels": [], "entities": [{"text": "CoNLL-SIGMORPHON 2017 Shared Task", "start_pos": 25, "end_pos": 58, "type": "DATASET", "confidence": 0.816820353269577}]}, {"text": "Although the shared task comprised two subtasks, we participated only in Task 1.", "labels": [], "entities": []}, {"text": "Each data set in Task 1 consists of three columns.", "labels": [], "entities": []}, {"text": "The first and second column provides a lemma and a target form, respectively.", "labels": [], "entities": []}, {"text": "The third column lists morphosyntactic descriptions (MSDs), or the features fora target form, where each feature is taken from a universal set of morphological features called UniMorph.", "labels": [], "entities": []}, {"text": "The purpose of the task is to construct a system which can estimate a target form from a lemma and its MSDs.", "labels": [], "entities": []}, {"text": "For each of 52 languages, participants cope with the problem under varying sizes of training data (10,000 for high, 1,000 for medium, and 100 for low).", "labels": [], "entities": []}, {"text": "The use of external resources are not permitted in the main track, but allowed as a separate track.", "labels": [], "entities": []}, {"text": "To solve the problem, we basically followed, the winner of the Shared Task in the previous year . Unfortunately, our approach experienced severe difficulties in low-resource settings.", "labels": [], "entities": []}, {"text": "In high-resource settings, our system achieved 91.46% accuracy, the 12th among the 20 systems.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.991279661655426}]}, {"text": "In medium-resource setting, the performance was 65.06%, almost the same as that of the baseline (64.7%).", "labels": [], "entities": []}, {"text": "And in low-resource setting, the system achieved only 1.58%.", "labels": [], "entities": []}, {"text": "The cause of the problem is that if we decrease the number of examples, at some point, the accuracy of deep learning-based approach drastically drops.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.999489426612854}]}, {"text": "For our system, the point is somewhere between 110 and 150; at 150, we still retain the accuracy around 36% but at 110, the result becomes nonsensical (see Section 5).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9993295669555664}]}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we briefly summarize related researches in this field.", "labels": [], "entities": []}, {"text": "In Section 3, we describe the system description of our approach.", "labels": [], "entities": []}, {"text": "In Section 4, we present environmental settings used in our experiments and the main results of our work.", "labels": [], "entities": []}, {"text": "In Section 5, we discuss the error analysis of our results.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results of our system. Base represents the baseline system provided the organizers. Dev  represents the best result for development data. Test represents the final result of our system. Time  represents the number of examples for training convergence (unit: 10k). Note that Scottish Gaelic for  the high-resource setting is omitted because the data was not provided.", "labels": [], "entities": [{"text": "Time", "start_pos": 196, "end_pos": 200, "type": "METRIC", "confidence": 0.9633103013038635}]}]}