{"title": [{"text": "A Fast and Lightweight System for Multilingual Dependency Parsing", "labels": [], "entities": [{"text": "Multilingual Dependency Parsing", "start_pos": 34, "end_pos": 65, "type": "TASK", "confidence": 0.6728627483050028}]}], "abstractContent": [{"text": "Following Kiperwasser and Goldberg (2016), we present a multilingual dependency parser with a bidirectional-LSTM (BiLSTM) feature extractor and a multi-layer perceptron (MLP) classifier.", "labels": [], "entities": []}, {"text": "We trained our transition-based projective parser in UD version 2.0 datasets without any additional data.", "labels": [], "entities": [{"text": "transition-based projective parser", "start_pos": 15, "end_pos": 49, "type": "TASK", "confidence": 0.6285825967788696}, {"text": "UD version 2.0 datasets", "start_pos": 53, "end_pos": 76, "type": "DATASET", "confidence": 0.8382065147161484}]}, {"text": "The parser is fast, lightweight and effective on big treebanks.", "labels": [], "entities": []}, {"text": "In the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies, the official results show that the macro-averaged LAS F1 score of our system Mengest is 61.33%.", "labels": [], "entities": [{"text": "CoNLL 2017 Shared Task", "start_pos": 7, "end_pos": 29, "type": "DATASET", "confidence": 0.8555098474025726}, {"text": "Multilingual Parsing from Raw Text", "start_pos": 31, "end_pos": 65, "type": "TASK", "confidence": 0.7727365672588349}, {"text": "LAS F1 score", "start_pos": 143, "end_pos": 155, "type": "METRIC", "confidence": 0.8546112974484762}]}], "introductionContent": [{"text": "Developing tools that can process multiple languages has always been an important goal in NLP.", "labels": [], "entities": []}, {"text": "Ten years ago,) and) Shared Task were a major milestone for multilingual dependency parsing.", "labels": [], "entities": [{"text": "multilingual dependency parsing", "start_pos": 60, "end_pos": 91, "type": "TASK", "confidence": 0.6621170739332835}]}, {"text": "The) is an extension of the tasks addressed in previous years.", "labels": [], "entities": []}, {"text": "Unlike CoNLL 2006 and CoNLL 2007, the focus of the CoNLL 2017 UD Shared Task is learning syntactic dependency parsers on a universal syntactic annotation standard.", "labels": [], "entities": [{"text": "CoNLL 2017 UD Shared Task", "start_pos": 51, "end_pos": 76, "type": "DATASET", "confidence": 0.8004303574562073}]}, {"text": "This shared task requires participants to parse raw texts from different languages, which vary both in typology and training set size.", "labels": [], "entities": []}, {"text": "The CoNLL 2017 UD Shared Task provided universal dependencies description from LREC 2016 (), two datasets, which are UD version 2.0 datasets () and this task test datasets (), two baseline models, which are UDPipe () and SyntaxNet (, and the evaluation platform TIRA ().", "labels": [], "entities": [{"text": "CoNLL 2017 UD Shared Task", "start_pos": 4, "end_pos": 29, "type": "DATASET", "confidence": 0.8926916480064392}, {"text": "LREC 2016", "start_pos": 79, "end_pos": 88, "type": "DATASET", "confidence": 0.8849919438362122}, {"text": "UD version 2.0 datasets", "start_pos": 117, "end_pos": 140, "type": "DATASET", "confidence": 0.7109395861625671}]}, {"text": "In this paper, We present our multilingual dependency parsing system Mengest for CoNLL 2017 UD Shared Task.", "labels": [], "entities": [{"text": "multilingual dependency parsing", "start_pos": 30, "end_pos": 61, "type": "TASK", "confidence": 0.6410029927889506}, {"text": "CoNLL 2017 UD Shared Task", "start_pos": 81, "end_pos": 106, "type": "DATASET", "confidence": 0.8389240264892578}]}, {"text": "The system contains a BiLSTM feature extractor for feature representation and a MLP classifier for the transition system.", "labels": [], "entities": [{"text": "feature representation", "start_pos": 51, "end_pos": 73, "type": "TASK", "confidence": 0.7167541086673737}]}, {"text": "The inputs of our system are word form (lemma or stem, which depending on the particular treebank) and part of speech (POS) tags (coarse-grained and fine-grained) for each token.", "labels": [], "entities": []}, {"text": "Based on this input, the system finds a governor for each token, and assigns a universal dependency relation label to each syntactic dependency.", "labels": [], "entities": []}, {"text": "Our official submission obtains 61.33% macro-averaged LAS F1 score on all treebanks.", "labels": [], "entities": [{"text": "LAS F1 score", "start_pos": 54, "end_pos": 66, "type": "METRIC", "confidence": 0.8410690824190775}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 discusses the transition-based model and our implementation.", "labels": [], "entities": []}, {"text": "Section 3 explains how our system deals with parallel sets and surprise languages.", "labels": [], "entities": []}, {"text": "Finally, we present experimental and official results in Section 4.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Hyper-parameter values used in shared  task.", "labels": [], "entities": []}, {"text": " Table 2: The LAS score of two different token  representations on the 4 treebanks: Bulgarian(bg),  Catalan(ca), German(de), English(en).", "labels": [], "entities": [{"text": "LAS score", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9224755167961121}]}, {"text": " Table 3: Comparison of Simple and Extended fea- ture representations, we report LAS score, offline  training time, and TIRA testing time.", "labels": [], "entities": [{"text": "LAS score", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.9814321100711823}, {"text": "TIRA testing time", "start_pos": 120, "end_pos": 137, "type": "METRIC", "confidence": 0.90334552526474}]}]}