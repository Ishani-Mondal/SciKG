{"title": [{"text": "Knowledge Tracing in Sequential Learning of Inflected Vocabulary", "labels": [], "entities": [{"text": "Knowledge Tracing", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6834980100393295}, {"text": "Sequential Learning of Inflected Vocabulary", "start_pos": 21, "end_pos": 64, "type": "TASK", "confidence": 0.8049802184104919}]}], "abstractContent": [{"text": "We present a feature-rich knowledge tracing method that captures a student's acquisition and retention of knowledge during a foreign language phrase learning task.", "labels": [], "entities": [{"text": "knowledge tracing", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.7519223392009735}, {"text": "foreign language phrase learning task", "start_pos": 125, "end_pos": 162, "type": "TASK", "confidence": 0.6734760046005249}]}, {"text": "We model the student's behavior as making predictions under a log-linear model, and adopt a neural gating mechanism to model how the student updates their log-linear parameters in response to feedback.", "labels": [], "entities": []}, {"text": "The gating mechanism allows the model to learn complex patterns of retention and acquisition for each feature, while the log-linear parameterization results in an interpretable knowledge state.", "labels": [], "entities": []}, {"text": "We collect human data and evaluate several versions of the model.", "labels": [], "entities": []}], "introductionContent": [{"text": "Knowledge tracing attempts to reconstruct when a student acquired (or forgot) each of several facts.", "labels": [], "entities": [{"text": "Knowledge tracing", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7969428598880768}]}, {"text": "Yet we often hear that \"learning is not just memorizing facts.\"", "labels": [], "entities": []}, {"text": "Facts are not atomic objects to be discretely and independently manipulated.", "labels": [], "entities": []}, {"text": "Rather, we suppose, a student who recalls a fact in a given setting is demonstrating a skill-by solving a structured prediction problem that is akin to reconstructive memory or pattern completion.", "labels": [], "entities": [{"text": "pattern completion", "start_pos": 177, "end_pos": 195, "type": "TASK", "confidence": 0.7280373871326447}]}, {"text": "The attempt at structured prediction may draw on many cooperating feature weights, some of which maybe shared with other facts or skills.", "labels": [], "entities": [{"text": "structured prediction", "start_pos": 15, "end_pos": 36, "type": "TASK", "confidence": 0.6443552821874619}]}, {"text": "In this paper, for the task of foreign-language vocabulary learning, we will adopt a specific structured prediction model and learning algorithm.", "labels": [], "entities": [{"text": "foreign-language vocabulary learning", "start_pos": 31, "end_pos": 67, "type": "TASK", "confidence": 0.7564857204755148}]}, {"text": "Different knowledge states correspond to model parameter settings (feature weights).", "labels": [], "entities": []}, {"text": "Different learning styles correspond to different hyperparameters that govern the learning algorithm.", "labels": [], "entities": []}, {"text": "As we interact with each student through a simple online tutoring system, we would like to track their evolving knowledge state and identify their learning style.", "labels": [], "entities": []}, {"text": "That is, we would like to discover parameters and hyperparameters that can explain the evidence so far and predict how the student will react in future.", "labels": [], "entities": []}, {"text": "This could help us make good future choices about how to instruct this student, although we leave this reinforcement learning problem to future work.", "labels": [], "entities": []}, {"text": "In this paper, we show that we can predict the student's next answer.", "labels": [], "entities": []}, {"text": "In short, we expand the notion of a knowledge tracing model to include representations fora student's (i) current knowledge, (ii) retention of knowledge, and (iii) acquisition of new knowledge.", "labels": [], "entities": [{"text": "knowledge tracing", "start_pos": 36, "end_pos": 53, "type": "TASK", "confidence": 0.7299513220787048}]}, {"text": "Our reconstruction of the student's knowledge state remains interpretable, since it corresponds to the weights of hand-designed features (sub-skills).", "labels": [], "entities": []}, {"text": "Interpretability may help a future teaching system provide useful feedback to students and to human teachers, and help it construct educational stimuli that are targeted at improving particular sub-skills, such as features that select correct verb suffixes.", "labels": [], "entities": []}, {"text": "Our present paper considers a verb conjugation task, where a foreign language learner learns the verb conjugation paradigm by reviewing and interacting with a series of flash cards.", "labels": [], "entities": [{"text": "verb conjugation task", "start_pos": 30, "end_pos": 51, "type": "TASK", "confidence": 0.7733366588751475}]}, {"text": "This task is a good testbed, as it needs the learner to deploy sub-word features and to generalize to new examples.", "labels": [], "entities": []}, {"text": "For example, a student learning Spanish verb conjugation might encounter pairs such as (t\u00fa entras, you enter), (yo miro, I watch).", "labels": [], "entities": []}, {"text": "Using these examples, the student needs to recognize suffix patterns and apply them to new pairs seen such as (yo entro, I enter).", "labels": [], "entities": []}, {"text": "Vocabulary learning presents a challenging learning environment due to the large number of skills (words) that need to be traced.", "labels": [], "entities": [{"text": "Vocabulary learning", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8196875154972076}]}, {"text": "Learning vocabulary in conjunction with inflection further complicates the challenge due to the number of new sub-skills that are introduced.", "labels": [], "entities": []}, {"text": "suggest that modeling sub-skill interaction is crucial to several knowledge tracing domains.", "labels": [], "entities": [{"text": "knowledge tracing", "start_pos": 66, "end_pos": 83, "type": "TASK", "confidence": 0.7345925271511078}]}, {"text": "For our domain, a log-linear formulation elegantly allows for arbitrary sub-skills via feature functions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We partitioned the students into three groups: 80 students for training, 20 for development, and 21 for testing.", "labels": [], "entities": []}, {"text": "Most students found the task difficult; the average score on the 7-question quiz-was 2.81 correct, with maximum score of 6.", "labels": [], "entities": []}, {"text": "(Recall from section 3.2 that the quiz questions were typing questions, not multiple choice questions.)", "labels": [], "entities": []}, {"text": "After constructing each model, we evaluated it on the held-out data: the 728 responses from the 21 testing students.", "labels": [], "entities": []}, {"text": "We measure the log-probability under the model of each actual response (\"crossentropy\"), and also the fraction of responses that were correctly predicted if our prediction was the model's max-probability response (\"accuracy\").", "labels": [], "entities": [{"text": "accuracy", "start_pos": 215, "end_pos": 223, "type": "METRIC", "confidence": 0.9939804077148438}]}, {"text": "shows the results of our experiment.", "labels": [], "entities": []}, {"text": "All of our models were predictive, doing far better than a uniform baseline that assigned equal probability 1/|O| to all options.", "labels": [], "entities": [{"text": "O", "start_pos": 111, "end_pos": 112, "type": "METRIC", "confidence": 0.9591637253761292}]}, {"text": "Our best models are shown in the final two lines, RNG+VM and RNG+CM.", "labels": [], "entities": []}, {"text": "Which update scheme was best?", "labels": [], "entities": []}, {"text": "Interestingly, although the RG update vector is principled from a machine learning viewpoint, the NG update vector sometimes achieved better accuracy-though worse perplexity-when predicting the responses of human learners.", "labels": [], "entities": [{"text": "accuracy-though", "start_pos": 141, "end_pos": 156, "type": "METRIC", "confidence": 0.9988040924072266}]}, {"text": "We got our best results on both metrics by interpolating between RG and NG (the RNG scheme).", "labels": [], "entities": []}, {"text": "Recall that the NG scheme was motivated by the notion that students who guessed wrong may not study the alternative answers (even though one is correct), either because it is too much trouble to study them or because (for a TP card) those alternatives are not actually shown.", "labels": [], "entities": []}, {"text": "Which gating mechanism was best?", "labels": [], "entities": []}, {"text": "In almost all cases, we found that more parameters helped, with CM > VM > SM on accuracy, and a similar pattern on cross-entropy (with VM sometimes winning but only slightly).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9994062185287476}]}, {"text": "In short, it helps to use different learning rates for different features, and it probably helps to make them sensitive to the learning context.", "labels": [], "entities": []}, {"text": "Surprisingly, the simple FG scheme outperformed both RG and NG when used in conjunction with a scalar retention and acquisition gate.", "labels": [], "entities": [{"text": "FG", "start_pos": 25, "end_pos": 27, "type": "METRIC", "confidence": 0.4982827603816986}]}, {"text": "This, however, did not extend to more complex gates.", "labels": [], "entities": []}, {"text": "shows a breakdown of the prediction accuracy measures according to whether the card was MC or TP, and according to whether the student's answer was correct (C) or incorrect (IC).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.8190722465515137}, {"text": "answer was correct (C) or incorrect (IC)", "start_pos": 137, "end_pos": 177, "type": "METRIC", "confidence": 0.6759295517748053}]}, {"text": "Unsurprisingly, all the models have an easier time predicting the student's guess when the student is correct, since the predicted parameters \u03b8 twill often pick the correct answer.", "labels": [], "entities": []}, {"text": "However, this is where the vector and context gates far outperform the scalar gates.", "labels": [], "entities": []}, {"text": "All the models find predicting the incorrect answers of the students difficult.", "labels": [], "entities": [{"text": "predicting the incorrect answers", "start_pos": 20, "end_pos": 52, "type": "TASK", "confidence": 0.8755168914794922}]}, {"text": "Moreover, when predicting these incorrect answers, the RG models do slightly better than the NG models.", "labels": [], "entities": []}, {"text": "The models obviously have higher accuracy when predicting student answers for MC cards than for TP cards, as MC cards have fewer options.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.999213695526123}]}, {"text": "Again, within both of these modalities, the vector and context gates outperform the scalar gate.", "labels": [], "entities": []}, {"text": "Even the FG vector sometimes won (on both metrics!), but this happened only with the worst gating mechanism, SM.: prediction accuracy and crossentropy (in nats per prediction) for different models.", "labels": [], "entities": [{"text": "FG", "start_pos": 9, "end_pos": 11, "type": "METRIC", "confidence": 0.8835702538490295}, {"text": "accuracy", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.8746036887168884}, {"text": "crossentropy", "start_pos": 138, "end_pos": 150, "type": "METRIC", "confidence": 0.9654643535614014}]}, {"text": "Larger accuracies and smaller cross-entropies are better.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 7, "end_pos": 17, "type": "METRIC", "confidence": 0.9825828075408936}]}, {"text": "Within an update scheme, the \u2020 indicates significant improvement (McNemar's test, p < 0.05) over the next-best gating mechanism.", "labels": [], "entities": [{"text": "McNemar's test", "start_pos": 66, "end_pos": 80, "type": "METRIC", "confidence": 0.8588551680246989}]}, {"text": "Within g a gating mechanism, the * indicates significant improvement over the next-best update scheme.", "labels": [], "entities": []}, {"text": "For example, NG+CM is significantly better than NG+VM, so it receives a \u2020 ; it is also significantly better than RG+CM, and receives a * as well.", "labels": [], "entities": [{"text": "NG+VM", "start_pos": 48, "end_pos": 53, "type": "DATASET", "confidence": 0.828881045182546}]}, {"text": "These comparisons are conducted only among the pure update schemes (above the double line).", "labels": [], "entities": []}, {"text": "All other models are significantly better than RG+SM (p < 0.01).", "labels": [], "entities": []}, {"text": "Finally, examines how these models behave when making specific predictions over a training sequence fora single student.", "labels": [], "entities": []}, {"text": "At each step we plot the difference in log-probability between our model and a uniform baseline model.", "labels": [], "entities": []}, {"text": "Thus, a marker above 0 means that our model assigned the student's answer a probability higher than chance.", "labels": [], "entities": []}, {"text": "10 To contrast the performance difference, we show both the highest-accuracy model (RNG+CM) and the lowestaccuracy model (RG+SM).", "labels": [], "entities": []}, {"text": "For a high-scoring student (, we see RNG+CM has a large margin over RG+SM and a slight upward trend.", "labels": [], "entities": [{"text": "RNG+CM", "start_pos": 37, "end_pos": 43, "type": "DATASET", "confidence": 0.5189041395982107}]}, {"text": "A higher probability than chance is noticeable even when the student makes mistakes (indicated by hollow markers).", "labels": [], "entities": [{"text": "chance", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.9610263705253601}]}, {"text": "In contrast, for an average student, the margin between the two models is less perceptible.", "labels": [], "entities": []}, {"text": "While the CM+NG model is still above the SM+RG line, there are some answers where CM+NG does very poorly.", "labels": [], "entities": []}, {"text": "This is especially true for some of the wrong answers, for example at training steps 25, 29 and 33.", "labels": [], "entities": []}, {"text": "Upon closer inspection into the model's error in step 33, we found the prompt received at this training step was ekki mel\u00fc as a MC card, which had been shown to the student on three prior occasions, and the student even answered correctly on one of these occasions.", "labels": [], "entities": []}, {"text": "This explains why the model For MC cards, the chance probability is in { was surprised to seethe student make this error.", "labels": [], "entities": [{"text": "chance probability", "start_pos": 46, "end_pos": 64, "type": "METRIC", "confidence": 0.9784679412841797}]}], "tableCaptions": [{"text": " Table 4: Comparison of our best-performing PKT model  (RNG+CM) to our LSTM model. On our dataset, PKT outper- forms the LSTM both in terms of accuracy and cross-entropy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 143, "end_pos": 151, "type": "METRIC", "confidence": 0.9990084767341614}]}]}