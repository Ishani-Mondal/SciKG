{"title": [{"text": "Robust Coreference Resolution and Entity Linking on Dialogues: Character Identification on TV Show Transcripts", "labels": [], "entities": [{"text": "Robust Coreference Resolution", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7214663922786713}, {"text": "Entity Linking on Dialogues", "start_pos": 34, "end_pos": 61, "type": "TASK", "confidence": 0.738909050822258}, {"text": "Character Identification on TV Show Transcripts", "start_pos": 63, "end_pos": 110, "type": "TASK", "confidence": 0.7807806332906088}]}], "abstractContent": [{"text": "This paper presents a novel approach to character identification, that is an entity linking task that maps mentions to characters in dialogues from TV show transcripts.", "labels": [], "entities": [{"text": "character identification", "start_pos": 40, "end_pos": 64, "type": "TASK", "confidence": 0.9152094125747681}, {"text": "maps mentions to characters in dialogues from TV show transcripts", "start_pos": 102, "end_pos": 167, "type": "TASK", "confidence": 0.6289282232522965}]}, {"text": "We first augment and correct several cases of annotation errors in an existing corpus so the corpus is clearer and cleaner for statistical learning.", "labels": [], "entities": []}, {"text": "We also introduce the agglom-erative convolutional neural network that takes groups of features and learns mention and mention-pair embeddings for corefer-ence resolution.", "labels": [], "entities": [{"text": "corefer-ence resolution", "start_pos": 147, "end_pos": 170, "type": "TASK", "confidence": 0.8164100050926208}]}, {"text": "We then propose another neural model that employs the embeddings learned and creates cluster embeddings for entity linking.", "labels": [], "entities": []}, {"text": "Our coreference resolution model shows comparable results to other state-of-the-art systems.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.9251866042613983}]}, {"text": "Our entity linking model significantly outperforms the previous work, showing the F1 score of 86.76% and the accuracy of 95.30% for character identification.", "labels": [], "entities": [{"text": "entity linking", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.7667510807514191}, {"text": "F1 score", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.9896799921989441}, {"text": "accuracy", "start_pos": 109, "end_pos": 117, "type": "METRIC", "confidence": 0.9996107220649719}, {"text": "character identification", "start_pos": 132, "end_pos": 156, "type": "TASK", "confidence": 0.9129325151443481}]}], "introductionContent": [{"text": "Character identification) is a task that identifies each mention as a character in a multiparty dialogue.", "labels": [], "entities": [{"text": "Character identification)", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8842897017796835}]}, {"text": "1 Leta mention be a nominal referring to a human (e.g., she, mom, Judy), and an entity be a character in the dialogue.", "labels": [], "entities": []}, {"text": "The objective is to assign each mention to an entity, who mayor may not appear as a speaker in the dialogue.", "labels": [], "entities": []}, {"text": "For the example in, the mention comedian is not one of the speakers in the dialogue; nonetheless, it clearly refers to areal person that may appear in some other dialogues.", "labels": [], "entities": []}, {"text": "Identifying such mentions as actual characters requires cross-document entity resolution, which makes this task challenging.", "labels": [], "entities": [{"text": "Identifying such mentions as actual characters", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.8513808051745096}, {"text": "cross-document entity resolution", "start_pos": 56, "end_pos": 88, "type": "TASK", "confidence": 0.6435845891634623}]}, {"text": "Character identification can be viewed as a task of entity linking.", "labels": [], "entities": [{"text": "Character identification", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9009212553501129}]}, {"text": "Most of the previous work on entity linking focuses on Wikification (.", "labels": [], "entities": [{"text": "entity linking", "start_pos": 29, "end_pos": 43, "type": "TASK", "confidence": 0.7480071783065796}]}, {"text": "Unlike Wikification, entities in this task have no precompiled information from a knowledge base, which is another challenging aspect.", "labels": [], "entities": []}, {"text": "This task is similar to coreference resolution in the sense that it groups mentions into entities, but distinct because it requires the identification of mention groups as real entities.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.9478617310523987}]}, {"text": "Furthermore, even if it can be tackled as a coreference resolution task, only a few coreference resolution systems are designed to handle dialogues well) although several state-of-the-art systems have been proposed for the general domain (.", "labels": [], "entities": [{"text": "coreference resolution task", "start_pos": 44, "end_pos": 71, "type": "TASK", "confidence": 0.845333476861318}, {"text": "coreference resolution", "start_pos": 84, "end_pos": 106, "type": "TASK", "confidence": 0.7509491443634033}]}, {"text": "Due to the nature of multiparty dialogues where speakers take turns to complete a context, character identification becomes a critical step to adapt higher-level NLP tasks (e.g., question answering, summarization) to this domain.", "labels": [], "entities": [{"text": "character identification", "start_pos": 91, "end_pos": 115, "type": "TASK", "confidence": 0.8278771042823792}, {"text": "question answering", "start_pos": 179, "end_pos": 197, "type": "TASK", "confidence": 0.8530276417732239}, {"text": "summarization)", "start_pos": 199, "end_pos": 213, "type": "TASK", "confidence": 0.8604928255081177}]}, {"text": "This task can also bring another level of sophistication to intelligent personal assistants and intelligent tutoring systems.", "labels": [], "entities": []}, {"text": "Perhaps the most challenging aspect comes from colloquial writing that consists of ironies, metaphors, or rhetorical questions.", "labels": [], "entities": []}, {"text": "Despite all the challenges, we believe that the output of this task will enhance inference on dialogue contexts by providing finer-grained information about individuals.", "labels": [], "entities": []}, {"text": "In this paper, we augment and correct the existing corpus for character identification, and propose an end-to-end deep-learning system that combines neural models for coreference resolution and entity linking to tackle the task of character identification.", "labels": [], "entities": [{"text": "character identification", "start_pos": 62, "end_pos": 86, "type": "TASK", "confidence": 0.9180667102336884}, {"text": "coreference resolution", "start_pos": 167, "end_pos": 189, "type": "TASK", "confidence": 0.8712323606014252}, {"text": "entity linking", "start_pos": 194, "end_pos": 208, "type": "TASK", "confidence": 0.7349736243486404}, {"text": "character identification", "start_pos": 231, "end_pos": 255, "type": "TASK", "confidence": 0.9147635400295258}]}, {"text": "The updated corpus and the source code of our models are published and publicly available.", "labels": [], "entities": []}, {"text": "2 This combined system utilizes the strengths from both: An example of a multiparty dialogue extracted from the corpus. models.", "labels": [], "entities": []}, {"text": "We introduce a novel approach, agglomerative convolution neural network, for coreference resolution to learn mention, mention-pair, and cluster embeddings, and the results are taken as input to our entity linking model that assigns mentions to their real entities.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 77, "end_pos": 99, "type": "TASK", "confidence": 0.9142234325408936}]}, {"text": "Entities, including main characters and recurring support characters, are selected from a TV show to mimic a realistic scenario.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this is the first end-toend model that performs character identification on multiparty dialogues.", "labels": [], "entities": [{"text": "character identification", "start_pos": 78, "end_pos": 102, "type": "TASK", "confidence": 0.8206178247928619}]}], "datasetContent": [{"text": "Our coreference resolution model shows robust performance compared to other stateof-the-art systems (Section 6.2).", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.9061256945133209}]}, {"text": "Our entity linking model significantly outperforms the heuristic-based approach from the previous work (Section 6.3).", "labels": [], "entities": [{"text": "entity linking", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.7669190168380737}]}, {"text": "All models are evaluated on the gold mentions to focus purely on the analysis of these two tasks.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Counts of disambiguated mentions. P/S:  main and secondary character entities. C/G/N/O:  Collective/General/Generic/Other.", "labels": [], "entities": []}, {"text": " Table 4: Coreference resolution results on the evaluation set (in %).  \u00b5 = (MUC + B 3 + CEAF e ) / 3. |C|: the average cluster size.", "labels": [], "entities": [{"text": "\u00b5", "start_pos": 72, "end_pos": 73, "type": "METRIC", "confidence": 0.9699234366416931}, {"text": "MUC + B 3 + CEAF e )", "start_pos": 77, "end_pos": 97, "type": "METRIC", "confidence": 0.8307464644312859}]}, {"text": " Table 5: The training (TRN), development (DEV),  and evaluation (TST) sets. E/S/DC/C E /C S /M: the  numbers of episodes, scenes, distinct characters,  episode/scene-level clusters, and mentions.", "labels": [], "entities": []}, {"text": " Table 5. All  system outputs are evaluated with the MUC (Vi- lain et al., 1995), B 3 (Bagga and Baldwin, 1998),  and CEAF e (", "labels": [], "entities": [{"text": "MUC", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.527106523513794}, {"text": "B 3", "start_pos": 82, "end_pos": 85, "type": "METRIC", "confidence": 0.957356870174408}, {"text": "CEAF e", "start_pos": 118, "end_pos": 124, "type": "METRIC", "confidence": 0.9162339270114899}]}, {"text": " Table 6: Entity linking results on the evaluation set (in %). The F1 score is reported for each character.  E/S: episode/scene level. Unk.: unknown. Avg: the macro-average F1 score between all characters.  Acc: (the number of correctly labeled mentions) / (the total number of mentions).", "labels": [], "entities": [{"text": "F1 score", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.9859427809715271}, {"text": "Avg", "start_pos": 150, "end_pos": 153, "type": "METRIC", "confidence": 0.976335346698761}, {"text": "F1 score", "start_pos": 173, "end_pos": 181, "type": "METRIC", "confidence": 0.9495545029640198}, {"text": "Acc", "start_pos": 207, "end_pos": 210, "type": "METRIC", "confidence": 0.9966057538986206}]}]}