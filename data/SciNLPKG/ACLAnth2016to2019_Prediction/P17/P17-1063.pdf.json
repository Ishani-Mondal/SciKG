{"title": [], "abstractContent": [{"text": "The referring expressions (REs) produced by a natural language generation (NLG) system can be misunderstood by the hearer, even when they are semantically correct.", "labels": [], "entities": [{"text": "referring expressions (REs) produced by a natural language generation (NLG)", "start_pos": 4, "end_pos": 79, "type": "TASK", "confidence": 0.7289761602878571}]}, {"text": "In an interactive setting, the NLG system can try to recognize such misunderstandings and correct them.", "labels": [], "entities": []}, {"text": "We present an algorithm for generating corrective REs that use contrastive focus (\"no, the BLUE button\") to emphasize the information the hearer most likely misunderstood.", "labels": [], "entities": [{"text": "BLUE", "start_pos": 91, "end_pos": 95, "type": "METRIC", "confidence": 0.9907121062278748}]}, {"text": "We show empirically that these contrastive REs are preferred over REs without contrast marking.", "labels": [], "entities": []}], "introductionContent": [{"text": "Interactive natural language generation (NLG) systems face the task of detecting when they have been misunderstood, and reacting appropriately to fix the problem.", "labels": [], "entities": [{"text": "Interactive natural language generation (NLG)", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.7221332107271466}]}, {"text": "For instance, even when the system generated a semantically correct referring expression (RE), the user may still misunderstand it, i.e. resolve it to a different object from the one the system intended.", "labels": [], "entities": []}, {"text": "In an interactive setting, such as a dialogue system or a pedestrian navigation system, the system can try to detect such misunderstandings -e.g. by predicting what the hearer understood from their behavior () -and to produce further utterances which resolve the misunderstanding and get the hearer to identify the intended object after all.", "labels": [], "entities": []}, {"text": "When humans correct their own REs, they routinely employ contrastive focus to clarify the relationship to the original RE.", "labels": [], "entities": []}, {"text": "Say that we originally described an object b as \"the blue button\", but the hearer approaches a button b which is green, thus providing evidence that they misunderstood the RE to mean b . In this case, we would like to say \"no, the BLUE button\", with the contrastive focus realized by an appropriate pitch accent on \"BLUE\".", "labels": [], "entities": [{"text": "RE", "start_pos": 172, "end_pos": 174, "type": "METRIC", "confidence": 0.9736624360084534}, {"text": "BLUE", "start_pos": 316, "end_pos": 320, "type": "METRIC", "confidence": 0.9096308946609497}]}, {"text": "This utterance alerts the hearer to the fact that they misunderstood the original RE; it reiterates the information from the original RE; and it marks the attribute \"blue\" as a salient difference between band the object the original RE was intended to describe.", "labels": [], "entities": []}, {"text": "In this paper, we describe an algorithm for generating REs with contrastive focus.", "labels": [], "entities": []}, {"text": "We start from the modeling assumption that misunderstandings arise because the RE r s the system uttered was corrupted by a noisy channel into an RE r u which the user \"heard\" and then resolved correctly; in the example above, we assume the user literally heard \"the green button\".", "labels": [], "entities": [{"text": "RE", "start_pos": 79, "end_pos": 81, "type": "METRIC", "confidence": 0.9459156394004822}]}, {"text": "We compute this (hypothetical) RE r u as the RE which refers to band has the lowest edit distance from r s . Based on this, we mark the contrastive words in r s , i.e. we transform \"the blue button\" into \"the BLUE button\".", "labels": [], "entities": [{"text": "RE", "start_pos": 45, "end_pos": 47, "type": "METRIC", "confidence": 0.9609341025352478}, {"text": "BLUE", "start_pos": 209, "end_pos": 213, "type": "METRIC", "confidence": 0.966485857963562}]}, {"text": "We evaluate our system empirically on REs from the GIVE Challenge () and the TUNA Challenge (van der, and show that the contrastive REs generated by our system are preferred over a number of baselines.", "labels": [], "entities": [{"text": "GIVE Challenge", "start_pos": 51, "end_pos": 65, "type": "DATASET", "confidence": 0.7727614343166351}, {"text": "TUNA Challenge", "start_pos": 77, "end_pos": 91, "type": "DATASET", "confidence": 0.849673867225647}]}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "We first review related work in Section 2 and define the problem of generating contrastive REs in Section 3.", "labels": [], "entities": []}, {"text": "Section 4 sketches the general architecture for RE generation on which our system is based.", "labels": [], "entities": [{"text": "RE generation", "start_pos": 48, "end_pos": 61, "type": "TASK", "confidence": 0.9888569712638855}]}, {"text": "In Section 5, we present the corruption model and show how to use it to reconstruct r u . Section 6 describes how we use this information to generate contrastive markup in r s , and in Section 7 we evaluate our approach.", "labels": [], "entities": []}], "datasetContent": [{"text": "To test whether our algorithm for contrastive REs assigns contrastive focus correctly, we evaluated it against several baselines in crowdsourced pairwise comparison overhearer experiments.", "labels": [], "entities": [{"text": "contrastive REs", "start_pos": 34, "end_pos": 49, "type": "TASK", "confidence": 0.6424690783023834}]}, {"text": "Like, we opted for an overhearer experiment to focus our evaluation on the effects of contrastive feedback, as opposed to the challenges presented by the navigational and timing aspects of a fully interactive system.", "labels": [], "entities": []}, {"text": "Our first experiment tested four strategies against each other.", "labels": [], "entities": []}, {"text": "Each experimental subject was presented with two screenshots of 3D scenes with a marked object and an RE (see for an example).", "labels": [], "entities": [{"text": "RE", "start_pos": 102, "end_pos": 104, "type": "METRIC", "confidence": 0.985388457775116}]}, {"text": "Each subject was shown a total of 12 scenes, selected at random from 16 test scenes.", "labels": [], "entities": []}, {"text": "We collected 10 judgments for each possible combination of GIVE scene and pair of strategies, yielding a total of 943 judgements from 142 subjects after removing fake answers.", "labels": [], "entities": []}, {"text": "We compared the Emphasis and Shortening strategies from Section 6 against two baselines.", "labels": [], "entities": [{"text": "Emphasis", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.8556810021400452}]}, {"text": "The Repeat strategy simply presented r s as a \"contrastive\" RE, without any capitalization.", "labels": [], "entities": [{"text": "RE", "start_pos": 60, "end_pos": 62, "type": "METRIC", "confidence": 0.9134064316749573}]}, {"text": "Comparisons to Repeat test the hypothesis that subjects prefer explicit contrastive focus.", "labels": [], "entities": []}, {"text": "The Random strategy randomly capitalized adjectives, adverbs, and/or prepositions that were not capitalized by the Emphasis strategy.", "labels": [], "entities": []}, {"text": "Comparisons to Random verify that any preference for Emphasis is not only due to the presence of contrastive focus, but also because our method identifies precisely where that focus should be. shows the results of all pairwise comparisons.", "labels": [], "entities": [{"text": "Emphasis", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9767677187919617}]}, {"text": "For each row strategy Strat Rand each column strategy Strat C , the table value corresponds to Significance levels are taken from a two-tailed binomial test over the counts of preferences for each strategy.", "labels": [], "entities": [{"text": "Significance", "start_pos": 95, "end_pos": 107, "type": "METRIC", "confidence": 0.9563709497451782}]}, {"text": "We find a significant preference for the Emphasis strategy overall others, providing evidence that our algorithm assigns contrastive focus to the right words in the corrective RE.", "labels": [], "entities": []}, {"text": "While the Shortening strategy is numerically preferred over both baselines, the difference is not significant, and it is significantly worse than the Emphasis strategy.", "labels": [], "entities": [{"text": "Shortening", "start_pos": 10, "end_pos": 20, "type": "TASK", "confidence": 0.5227430462837219}, {"text": "Emphasis", "start_pos": 150, "end_pos": 158, "type": "METRIC", "confidence": 0.89519202709198}]}, {"text": "This is surprising, given our initial assumption that listeners prefer succinct REs.", "labels": [], "entities": []}, {"text": "It is possible that a different strategy for shortening contrastive REs would work better; this bears further study.", "labels": [], "entities": [{"text": "shortening contrastive REs", "start_pos": 45, "end_pos": 71, "type": "TASK", "confidence": 0.7418615619341532}]}, {"text": "In our second experiment, we paired the Emphasis, Repeat, and Random strategies against each other, this time evaluating each strategy in the TUNA people domain.", "labels": [], "entities": [{"text": "Random", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.9562740325927734}, {"text": "TUNA people domain", "start_pos": 142, "end_pos": 160, "type": "DATASET", "confidence": 0.8551440238952637}]}, {"text": "Due to its poor performance in Experiment 1, which was confirmed in pilot experiments for Experiment 2, the Shortening strategy was not included.", "labels": [], "entities": [{"text": "Shortening", "start_pos": 108, "end_pos": 118, "type": "TASK", "confidence": 0.9729138016700745}]}, {"text": "The experimental setup for the TUNA domain used 3x4 grids of pictures of people chosen at random from the TUNA Challenge, as shown in.", "labels": [], "entities": [{"text": "TUNA domain", "start_pos": 31, "end_pos": 42, "type": "DATASET", "confidence": 0.9064352214336395}, {"text": "TUNA Challenge", "start_pos": 106, "end_pos": 120, "type": "DATASET", "confidence": 0.8834185302257538}]}, {"text": "We generated 8 such grids, along with REs ranging from two to five attributes and requiring one or two attributes to establish the correct contrast.", "labels": [], "entities": []}, {"text": "The larger visual size of objects in the the TUNA scenes allowed us to mark both o sand o u in a single picture without excessive clutter.", "labels": [], "entities": []}, {"text": "The REs for Experiment 2 were designed to only include attributes from the referred objects, but no information about its position in relation to other objects.", "labels": [], "entities": []}, {"text": "The benefit is twofold: we avoid taxing our subjects' memory with extremely long REs, and we ensure that the overall length of the second set of REs is comparable to those in the previous experiment.", "labels": [], "entities": [{"text": "memory", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.9903239011764526}, {"text": "REs", "start_pos": 81, "end_pos": 84, "type": "METRIC", "confidence": 0.9470142722129822}, {"text": "REs", "start_pos": 145, "end_pos": 148, "type": "METRIC", "confidence": 0.8850583434104919}]}, {"text": "We obtained 240 judgements from 65 subjects (after removing fake answers).", "labels": [], "entities": []}, {"text": "shows the results of all pairwise comparisons.", "labels": [], "entities": []}, {"text": "We find that even in the presence of a larger number of attributes, our algorithm assigns contrastive focus to the correct words of the RE.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Pairwise comparisons between feedback strategies for experiments 1 and 2. A positive value  shows preference for the row strategy, significant at *** p < 0.001.", "labels": [], "entities": []}]}