{"title": [{"text": "How (not) to train a dependency parser: The curious case of jackknifing part-of-speech tagger\u0161 tagger\u0161", "labels": [], "entities": []}], "abstractContent": [{"text": "In dependency parsing, jackknifing tag-gers is indiscriminately used as a simple adaptation strategy.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 3, "end_pos": 21, "type": "TASK", "confidence": 0.8741941452026367}]}, {"text": "Here, we empirically evaluate when and how (not) to use jack-knifing in parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 72, "end_pos": 79, "type": "TASK", "confidence": 0.9635354280471802}]}, {"text": "On 26 languages, we reveal a preference that conflicts with, and surpasses the ubiquitous ten-folding.", "labels": [], "entities": []}, {"text": "We show no clear benefits of tagging the training data in cross-lingual parsing.", "labels": [], "entities": [{"text": "cross-lingual parsing", "start_pos": 58, "end_pos": 79, "type": "TASK", "confidence": 0.7151398658752441}]}], "introductionContent": [{"text": "Dependency parsers are trained over manually annotated treebank data.", "labels": [], "entities": [{"text": "Dependency parsers", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7577049136161804}]}, {"text": "By contrast, when applied in the real world, they parse over sequences of predicted parts of speech.", "labels": [], "entities": [{"text": "parse over sequences of predicted parts of speech", "start_pos": 50, "end_pos": 99, "type": "TASK", "confidence": 0.7152471989393234}]}, {"text": "As POS tagging accuracy drops due to domain change, the parsing quality declines proportionally.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 3, "end_pos": 14, "type": "TASK", "confidence": 0.8058960139751434}, {"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9504439830780029}, {"text": "parsing", "start_pos": 56, "end_pos": 63, "type": "TASK", "confidence": 0.9606674909591675}]}, {"text": "Bringing these two POS tag sources closer together thus makes fora reasonable adaptation strategy.", "labels": [], "entities": []}, {"text": "Arguably the simplest of such adaptations is nfold jackknifing.", "labels": [], "entities": []}, {"text": "In it, a treebank is divided into n equal parts, and the n-th part is POS-tagged with a tagger trained on the remainder.", "labels": [], "entities": [{"text": "POS-tagged", "start_pos": 70, "end_pos": 80, "type": "METRIC", "confidence": 0.7958201169967651}]}, {"text": "The procedure is repeated until all n parts are assigned with predicted POS tags.", "labels": [], "entities": []}, {"text": "A parser is then trained over the thus altered treebank, under the assumption that its POS features will now more closely resemble those of the input data.", "labels": [], "entities": []}, {"text": "Jackknifing is simplistic as it i) has a very limited adaptation range for n \u2208 N + , and it ii) does not in anyway take the input data into account, other than through a vague assumption of an undefined amount of tagging noise in the input.", "labels": [], "entities": []}, {"text": "As such, it exhibits very mixed results.", "labels": [], "entities": []}, {"text": "Still, the method is now ubiquitous in the parsing literature.", "labels": [], "entities": [{"text": "parsing", "start_pos": 43, "end_pos": 50, "type": "TASK", "confidence": 0.9685500264167786}]}, {"text": "In, we survey the ACL Anthology 1 for POS jackknifing.", "labels": [], "entities": [{"text": "ACL Anthology 1", "start_pos": 18, "end_pos": 33, "type": "DATASET", "confidence": 0.9355645577112833}, {"text": "POS jackknifing", "start_pos": 38, "end_pos": 53, "type": "DATASET", "confidence": 0.7640999257564545}]}, {"text": "We uncover that \u223c80% of the 70 http://aclweb.org/anthology/: Jackknifing in the ACL Anthology.", "labels": [], "entities": [{"text": "Jackknifing in the ACL Anthology", "start_pos": 61, "end_pos": 93, "type": "DATASET", "confidence": 0.8720409274101257}]}, {"text": "Distribution of n over 70 parsing papers that use tagger n-folding.", "labels": [], "entities": []}, {"text": "parsing papers we retrieved make use of ten-fold jackknifing.", "labels": [], "entities": []}, {"text": "This choice spans across the various languages and domains parsed in these papers, and is even motivated by simply \"following the traditions in literature\".", "labels": [], "entities": []}, {"text": "We evaluate jackknifing to establish whether its use is warranted in dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 69, "end_pos": 87, "type": "TASK", "confidence": 0.7891236245632172}]}, {"text": "Controlling for tagging quality in training and testing, we experiment with monolingual and delexicalized cross-lingual parsers over 26 languages, showing that: i) Indiscriminate use of ten-fold jackknifing results in sub-optimal parsing.", "labels": [], "entities": []}, {"text": "ii) Tagging the training data does not yield clear benefits in realistic cross-lingual parsing.", "labels": [], "entities": [{"text": "Tagging", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9674880504608154}, {"text": "cross-lingual parsing", "start_pos": 73, "end_pos": 94, "type": "TASK", "confidence": 0.6800686120986938}]}, {"text": "iii) Our jackknifing extension improves parsing through finer-grained adaptation.", "labels": [], "entities": [{"text": "parsing", "start_pos": 40, "end_pos": 47, "type": "TASK", "confidence": 0.9767390489578247}]}], "datasetContent": [{"text": "Our experiment aims at judging the adequacy of jackknifing in dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.7784408628940582}]}, {"text": "First, we outline the experiment setup, where we conduct two sets of experiments: i) monolingual, where lexicalized parsers are trained on treebanks for their respective languages, and ii) cross-lingual, that features SINGLE-best and MULTI-source delexicalized parsers.", "labels": [], "entities": []}, {"text": "By jackknifing we explore how the mismatch between training and test POS affects parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 81, "end_pos": 88, "type": "TASK", "confidence": 0.9657780528068542}]}, {"text": "Our setup thus critically relies on the sources of tags.", "labels": [], "entities": []}, {"text": "We tag our test sets using: i) PRED, the monolingual taggers, and ii) PROJ, the low-resource taggers by Agi\u00b4c, based on annotation projection.", "labels": [], "entities": []}, {"text": "We do not experiment with gold POS tags in the test sets.", "labels": [], "entities": []}, {"text": "Instead, we only focus on realistic parsing over predicted tags.", "labels": [], "entities": []}, {"text": "The tags in our training sets can be GOLD, PROJ, or they can be predicted through n-fold or linear jackknifing.", "labels": [], "entities": [{"text": "GOLD", "start_pos": 37, "end_pos": 41, "type": "METRIC", "confidence": 0.8755642175674438}, {"text": "PROJ", "start_pos": 43, "end_pos": 47, "type": "METRIC", "confidence": 0.9077253937721252}]}, {"text": "In n-fold jackknifing, we experiment with n \u2208 {2, 3, .., 20}, while for the linear extension we set p \u2208 {5, 10, ..., 95}.", "labels": [], "entities": []}, {"text": "We report the average parsing scores over 5 runs for each n and p so as to mitigate the effects of random shuffling in the two jackknifing procedures.", "labels": [], "entities": [{"text": "parsing", "start_pos": 22, "end_pos": 29, "type": "TASK", "confidence": 0.9543616771697998}]}, {"text": "In finding the optimal values of the parameters n max and p max , we report the highest values in case of ties.", "labels": [], "entities": []}, {"text": "For example, if n = 5 and n = 10 both yield the same maximum UAS, we set n max = 10.", "labels": [], "entities": [{"text": "UAS", "start_pos": 61, "end_pos": 64, "type": "METRIC", "confidence": 0.9857514500617981}]}, {"text": "We emphasize the importance of realistic settings especially in cross-lingual parsing.", "labels": [], "entities": [{"text": "cross-lingual parsing", "start_pos": 64, "end_pos": 85, "type": "TASK", "confidence": 0.7319543063640594}]}, {"text": "Thus, we commit to using PROJ taggers with an outlook on true low-resource languages.", "labels": [], "entities": [{"text": "PROJ taggers", "start_pos": 25, "end_pos": 37, "type": "TASK", "confidence": 0.7705118954181671}]}], "tableCaptions": [{"text": " Table 1: Parsing accuracy (UAS) in relation to the underlying sources of POS tags in training and at  runtime. Bold: best result for language, separately for PRED and PROJ test sets.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.835576057434082}, {"text": "accuracy (UAS)", "start_pos": 18, "end_pos": 32, "type": "METRIC", "confidence": 0.8757703304290771}, {"text": "PROJ test sets", "start_pos": 168, "end_pos": 182, "type": "DATASET", "confidence": 0.7831310828526815}]}, {"text": " Table 2: UAS scores for the delexicalized transfer  parsers. TRAINTEST indicates the training and  testing POS. Bold: best result for language, sepa- rate for MULTI and SINGLE transfer. For SINGLE,  best source names are also reported.", "labels": [], "entities": [{"text": "UAS", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.7242216467857361}, {"text": "TRAINTEST", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9993282556533813}, {"text": "POS", "start_pos": 108, "end_pos": 111, "type": "METRIC", "confidence": 0.9419173002243042}, {"text": "sepa- rate", "start_pos": 145, "end_pos": 155, "type": "METRIC", "confidence": 0.9332725207010905}, {"text": "MULTI", "start_pos": 160, "end_pos": 165, "type": "DATASET", "confidence": 0.5203995108604431}, {"text": "SINGLE transfer", "start_pos": 170, "end_pos": 185, "type": "TASK", "confidence": 0.6333379000425339}]}]}