{"title": [{"text": "Learning with Noise: Enhance Distantly Supervised Relation Extraction with Dynamic Transition Matrix", "labels": [], "entities": [{"text": "Enhance Distantly Supervised Relation Extraction", "start_pos": 21, "end_pos": 69, "type": "TASK", "confidence": 0.6720834016799927}]}], "abstractContent": [{"text": "Distant supervision significantly reduces human efforts in building training data for many classification tasks.", "labels": [], "entities": [{"text": "classification tasks", "start_pos": 91, "end_pos": 111, "type": "TASK", "confidence": 0.9000228643417358}]}, {"text": "While promising , this technique often introduces noise to the generated training data, which can severely affect the model performance.", "labels": [], "entities": []}, {"text": "In this paper, we take a deep look at the application of distant supervision in relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.9296135604381561}]}, {"text": "We show that the dynamic transition matrix can effectively characterize the noise in the training data built by distant supervision.", "labels": [], "entities": []}, {"text": "The transition matrix can be effectively trained using a novel curriculum learning based method without any direct supervision about the noise.", "labels": [], "entities": []}, {"text": "We thoroughly evaluate our approach under a wide range of extraction scenarios.", "labels": [], "entities": []}, {"text": "Experimental results show that our approach consistently improves the extraction results and outperforms the state-of-the-art in various evaluation scenarios.", "labels": [], "entities": []}], "introductionContent": [{"text": "Distant supervision (DS) is rapidly emerging as a viable means for supporting various classification tasks -from relation extraction ( and sentiment classification () to cross-lingual semantic analysis.", "labels": [], "entities": [{"text": "Distant supervision (DS)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8263481378555297}, {"text": "relation extraction", "start_pos": 113, "end_pos": 132, "type": "TASK", "confidence": 0.8923540711402893}, {"text": "sentiment classification", "start_pos": 139, "end_pos": 163, "type": "TASK", "confidence": 0.8802923560142517}, {"text": "cross-lingual semantic analysis", "start_pos": 170, "end_pos": 201, "type": "TASK", "confidence": 0.8258176843325297}]}, {"text": "By using knowledge learned from seed examples to label data, DS automatically prepares large scale training data for these tasks.", "labels": [], "entities": []}, {"text": "While promising, DS does not guarantee perfect results and often introduces noise to the generated data.", "labels": [], "entities": [{"text": "DS", "start_pos": 17, "end_pos": 19, "type": "TASK", "confidence": 0.9441598057746887}]}, {"text": "In the context of relation extraction, DS works by considering sentences containing both the subject and object of a <subj, rel, obj> triple as its supports.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.833629310131073}]}, {"text": "However, the generated data are not always perfect.", "labels": [], "entities": []}, {"text": "For instance, DS could match the knowledge base (KB) triple, <Donald Trump, born-in, New York> in false positive contexts like Donald Trump worked in New York City.", "labels": [], "entities": [{"text": "knowledge base (KB) triple", "start_pos": 33, "end_pos": 59, "type": "METRIC", "confidence": 0.7352781196435293}]}, {"text": "Prior works ( show that DS often mistakenly labels real positive instances as negative (false negative) or versa vice (false positive), and there could be confusions among positive labels as well.", "labels": [], "entities": []}, {"text": "These noises can severely affect training and lead to poorlyperforming models.", "labels": [], "entities": []}, {"text": "Tackling the noisy data problem of DS is nontrivial, since there usually lacks of explicit supervision to capture the noise.", "labels": [], "entities": []}, {"text": "Previous works have tried to remove sentences containing unreliable syntactic patterns (, design new models to capture certain types of noise or aggregate multiple predictions under the at-leastone assumption that at least one of the aligned sentences supports the triple in KB (.", "labels": [], "entities": []}, {"text": "These approaches represent a substantial leap forward towards making DS more practical.", "labels": [], "entities": [{"text": "DS", "start_pos": 69, "end_pos": 71, "type": "TASK", "confidence": 0.9891531467437744}]}, {"text": "however, are either tightly couple to certain types of noise, or have to rely on manual rules to filter noise, thus unable to scale.", "labels": [], "entities": []}, {"text": "Recent breakthrough in neural networks provides anew way to reduce the influence of incorrectly labeled data by aggregating multiple training instances attentively for relation classification, without explicitly characterizing the inherent noise (.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 168, "end_pos": 191, "type": "TASK", "confidence": 0.8593743443489075}]}, {"text": "Although promising, modeling noise within neural network architectures is still in its early stage and much remains to be done.", "labels": [], "entities": []}, {"text": "In this paper, we aim to enhance DS noise modeling by providing the capability to explicitly characterize the noise in the DS-style training data within neural networks architectures.", "labels": [], "entities": [{"text": "DS noise modeling", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.9322389761606852}]}, {"text": "We show that while noise is inevitable, it is possible to characterize the noise pattern in a unified framework along with its original classification objective.", "labels": [], "entities": []}, {"text": "Our key insight is that the DS-style training data typically contain useful clues about the noise pattern.", "labels": [], "entities": []}, {"text": "For example, we can infer that since some people work in their birthplaces, DS could wrongly label a training sentence describing a working place as a born-in relation.", "labels": [], "entities": []}, {"text": "Our novel approach to noisy modeling is to use a dynamically-generated transition matrix for each training instance to (1) characterize the possibility that the DS labeled relation is confused and (2) indicate its noise pattern.", "labels": [], "entities": []}, {"text": "To tackle the challenge of no direct guidance over the noise pattern, we employ a curriculum learning based training method to gradually model the noise pattern overtime, and utilize trace regularization to control the behavior of the transition matrix during training.", "labels": [], "entities": []}, {"text": "Our approach is flexiblewhile it does not make any assumptions about the data quality, the algorithm can make effective use of the data-quality prior knowledge to guide the learning procedure when such clues are available.", "labels": [], "entities": []}, {"text": "We apply our method to the relation extraction task and evaluate under various scenarios on two benchmark datasets.", "labels": [], "entities": [{"text": "relation extraction task", "start_pos": 27, "end_pos": 51, "type": "TASK", "confidence": 0.8892776767412821}]}, {"text": "Experimental results show that our approach consistently improves both extraction settings, outperforming the state-of-theart models in different settings.", "labels": [], "entities": []}, {"text": "Our work offers an effective way for tackling the noisy data problem of DS, making DS more practical at scale.", "labels": [], "entities": [{"text": "DS", "start_pos": 72, "end_pos": 74, "type": "TASK", "confidence": 0.9486425518989563}, {"text": "DS", "start_pos": 83, "end_pos": 85, "type": "TASK", "confidence": 0.9592751860618591}]}, {"text": "Our main contributions are to (1) design a dynamic transition matrix structure to characterize the noise introduced by DS, and (2) design a curriculum learning based framework to adaptively guide the training procedure to learn with noise.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments aim to answer two main questions: (1) is it possible to model the noise in the training data generated through DS, even when there is no prior knowledge to guide us? and whether the prior knowledge of data quality can help our approach better handle the noise.", "labels": [], "entities": []}, {"text": "We apply our approach to both sentence level and bag level extraction models, and evaluate in the situations where we do not have prior knowledge of the data quality as well as where such prior knowledge is available.", "labels": [], "entities": [{"text": "bag level extraction", "start_pos": 49, "end_pos": 69, "type": "TASK", "confidence": 0.6960161328315735}]}, {"text": "We evaluate our approach on two datasets.", "labels": [], "entities": []}, {"text": "TIMERE We build TIMERE by using DS to align time-related Wikidata) KB triples to Wikipedia text.", "labels": [], "entities": []}, {"text": "It contains 278,141 sentences with 12 types of relations between an entity mention and a time expression.", "labels": [], "entities": []}, {"text": "We choose to use time-related relations because time expressions speak for themselves in terms of reliability.", "labels": [], "entities": []}, {"text": "That is, given a KB triple <e, rel, t> and its aligned sentences, the finergrained the time expression t appears in the sentence, the more likely the sentence supports the existence of this triple.", "labels": [], "entities": []}, {"text": "For example, a sentence containing both Alphabet and October-2-2015 is very likely to express the inception-time of Alphabet, while a sentence containing both Alphabet and 2015 could instead talk about many events, e.g., releasing financial report of 2015, hiring anew CEO, etc.", "labels": [], "entities": [{"text": "Alphabet", "start_pos": 40, "end_pos": 48, "type": "DATASET", "confidence": 0.9843101501464844}, {"text": "Alphabet", "start_pos": 116, "end_pos": 124, "type": "DATASET", "confidence": 0.9765251874923706}]}, {"text": "Using this heuristics, we can split the dataset into 3 subsets according to different granularities of the time expressions involved, indicating different levels of reliability.", "labels": [], "entities": []}, {"text": "Our criteria for determining the reliability are as follows.", "labels": [], "entities": [{"text": "reliability", "start_pos": 33, "end_pos": 44, "type": "METRIC", "confidence": 0.9934404492378235}]}, {"text": "Instances with full date expressions, i.e., Year-Month-Day, can be seen as the most reliable data, while those with partial date expressions, e.g., Month-Year and Year-Only, are considered as less reliable.", "labels": [], "entities": []}, {"text": "Negative data are constructed heuristically that any entity-time pairs in a sentence without corresponding triples in Wikidata are treated as negative data.", "labels": [], "entities": []}, {"text": "During training, we can access 184,579 negative and 77,777 positive sentences, including 22,214 reliable, 2,094 and 53,469 less reliable ones.", "labels": [], "entities": []}, {"text": "The validation set and test set are randomly sampled from the reliable (full-date) data for relatively fair evaluations and contains 2,776, 2,771 positive sentences and 5,143, 5,095 negative sentences, respectively.", "labels": [], "entities": []}, {"text": "ENTITYRE is a widely-used entity relation extraction dataset, built by aligning triples in Freebase to the New York Times (NYT) corpus (  Hyper-parameters We use 200 convolution kernels with widow size 3.", "labels": [], "entities": [{"text": "ENTITYRE", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.6530980467796326}, {"text": "entity relation extraction", "start_pos": 26, "end_pos": 52, "type": "TASK", "confidence": 0.6322597960631052}, {"text": "NYT) corpus", "start_pos": 123, "end_pos": 134, "type": "DATASET", "confidence": 0.7063632806142172}]}, {"text": "During training, we use stochastic gradient descend (SGD) with batch size 20.", "labels": [], "entities": [{"text": "stochastic gradient descend (SGD)", "start_pos": 24, "end_pos": 57, "type": "METRIC", "confidence": 0.6978912701209387}]}, {"text": "The learning rates for sentence-level and bag-level models are 0.1 and 0.01, respectively.", "labels": [], "entities": []}, {"text": "Sentence level experiments are performed on TIMERE, using 100-d word embeddings pretrained using GloVe () on Wikipedia and Gigaword (Parker et al., 2011), and 20-d vectors for distance embeddings.", "labels": [], "entities": [{"text": "TIMERE", "start_pos": 44, "end_pos": 50, "type": "DATASET", "confidence": 0.8036516308784485}]}, {"text": "Each of the three subsets of TIMERE is added after the previous phase has run for 15 epochs.", "labels": [], "entities": [{"text": "TIMERE", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.7298873662948608}]}, {"text": "The trace regularization weights are \u03b2 1 = 0.01, \u03b2 2 = \u22120.01 and \u03b2 3 = \u22120.1, respectively, from the reliable to the most unreliable, with the ratio of \u03b2 3 and \u03b2 2 fixed to 10 or 5 when tuning.", "labels": [], "entities": []}, {"text": "Bag level experiments are performed on both TIMERE and ENTITYRE.", "labels": [], "entities": [{"text": "TIMERE", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.9307255744934082}, {"text": "ENTITYRE", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.8227903246879578}]}, {"text": "For TIMERE, we use the same parameters as above.", "labels": [], "entities": [{"text": "TIMERE", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.5585762858390808}]}, {"text": "For ENTITYRE, we use 50-d word embeddings pre-trained on the NYT corpus using word2vec, and 5-d vectors for distance embedding.", "labels": [], "entities": [{"text": "ENTITYRE", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.49701741337776184}, {"text": "NYT corpus", "start_pos": 61, "end_pos": 71, "type": "DATASET", "confidence": 0.9837977886199951}]}, {"text": "For both datasets, \u03b1 and \u03b2 in Eq.", "labels": [], "entities": [{"text": "Eq", "start_pos": 30, "end_pos": 32, "type": "DATASET", "confidence": 0.9035312533378601}]}, {"text": "5 are initialized to 1 and 0.1, respectively.", "labels": [], "entities": []}, {"text": "We tried various decay rates, {0.95, 0.9, 0.8}, and steps, {3, 5, 8}.", "labels": [], "entities": []}, {"text": "We found that using a decay rate of 0.9 with step of 5 gives best performance inmost cases.", "labels": [], "entities": []}, {"text": "The performance is reported using the precision-recall (PR) curve, which is a standard evaluation metric in relation extraction.", "labels": [], "entities": [{"text": "precision-recall (PR) curve", "start_pos": 38, "end_pos": 65, "type": "METRIC", "confidence": 0.9695563077926636}, {"text": "relation extraction", "start_pos": 108, "end_pos": 127, "type": "TASK", "confidence": 0.9101671576499939}]}, {"text": "Specifically, the extraction results are first ranked decreasingly by their confidence scores, then the precision and recall are calculated by setting the threshold to be the score of each extraction result one by one.", "labels": [], "entities": [{"text": "precision", "start_pos": 104, "end_pos": 113, "type": "METRIC", "confidence": 0.9997256398200989}, {"text": "recall", "start_pos": 118, "end_pos": 124, "type": "METRIC", "confidence": 0.999629020690918}]}, {"text": "Naming Conventions We evaluate our approach under a wide range of settings for sentence level (sent ) and bag level (bag ) models: (1) mix: trained on all three subsets of TIMERE mixed together; (2) reliable: trained using the reliable subset of TIMERE only; (3) PR: trained with prior knowledge of annotation quality, i.e., starting from the reliable data and then adding the unreliable data; (4) TM: trained with dynamic transition matrix; (5) GTM: trained with a global transition matrix.", "labels": [], "entities": []}, {"text": "In bag level, we also investigate the performance of average aggregation ( avg) and attention aggregation ( att)..", "labels": [], "entities": [{"text": "average aggregation ( avg)", "start_pos": 53, "end_pos": 79, "type": "METRIC", "confidence": 0.9095924854278564}, {"text": "attention aggregation ( att).", "start_pos": 84, "end_pos": 113, "type": "METRIC", "confidence": 0.835980224609375}]}, {"text": "We can see that mixing all subsets together (sent mix) gives the worst performance, significantly worse than using the reliable subset only (sent reliable).", "labels": [], "entities": []}, {"text": "This suggests the noisy nature of the training data obtained through DS and properly dealing with the noise is the key for DS fora wider range of applications.", "labels": [], "entities": []}, {"text": "When getting help from our dynamic transition matrix, the model (sent mix TM) significantly improves sent mix, delivering the same level of performance assent reliable inmost cases.", "labels": [], "entities": []}, {"text": "This suggests that our transition matrix can help to mitigate the bad influence of noisy training instances.", "labels": [], "entities": []}, {"text": "Now let us consider the PR scenario where one can build a curriculum by first training on the reliable subset, then gradually moving to both reliable and less reliable data.", "labels": [], "entities": [{"text": "PR", "start_pos": 24, "end_pos": 26, "type": "TASK", "confidence": 0.9858842492103577}]}, {"text": "We can see that, this simple curriculum learning based model (sent PR) further outperforms sent reliable significantly, indicating that the curriculum learning framework not only reduces the effect of noise, but also helps the model learn from noisy data.", "labels": [], "entities": []}, {"text": "When applying the transition matrix approach into this curriculum learning framework using one reliable subset and one unreliable subset generated by mixing our two less reliable subsets, our model (sent PR seg2 TM) further improves sent PR by utilizing the dynamic transition matrix to model the noise.", "labels": [], "entities": []}, {"text": "It is not surprising that when we use all three subsets separately, our model (sent PR TM) significantly outperforms all other models by a large margin..", "labels": [], "entities": []}, {"text": "In contrast to the sentence level, bag att mix outperforms bag att reliable by a large margin, because bag att mix has taken the at-least-one assumption into consideration through the attention aggregation mechanism (Eq.", "labels": [], "entities": []}, {"text": "3), which can be seen as a denoising step within the bag.", "labels": [], "entities": []}, {"text": "This may also be the reason that when we introduce either our dynamic transition matrix (bag att mix TM) or the curriculum of using prior knowledge of data quality (bag att PR) into the bag level models, the improvement regarding bag att mix is not as significant as in the sentence level.", "labels": [], "entities": []}, {"text": "However, when we apply our dynamic transition matrix into the curriculum built upon prior knowledge of data quality (bag att PR TM), the performance gets further improved.", "labels": [], "entities": [{"text": "bag att PR TM)", "start_pos": 117, "end_pos": 131, "type": "METRIC", "confidence": 0.6692697525024414}]}, {"text": "This happens especially in the high precision part compared to bag att PR.", "labels": [], "entities": [{"text": "precision", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9986088871955872}]}, {"text": "We also note that the bag level's at-least-one assumption does not always hold, and there are still false negative and false positive problems.", "labels": [], "entities": []}, {"text": "Therefore, using our transition matrix approach with or without prior knowledge of data quality, i.e., bag att mix TM and bag att PR TM, both improve the performance, and bag att PR TM performs slightly better.", "labels": [], "entities": []}, {"text": "The results of bag level models with average aggregation are shown in, where the relative ranking of various settings is similar to those with attention aggregation.", "labels": [], "entities": []}, {"text": "A notable difference  is that both bag avg PR and bag avg mix TM improve bag avg mix by a larger margin compared to that in the attention aggregation setting.", "labels": [], "entities": []}, {"text": "The reason maybe that the average aggregation mechanism is not as good as the attention aggregation in denoising within the bag, which leaves more space for our transition matrix approach or curriculum learning with prior knowledge to improve.", "labels": [], "entities": []}, {"text": "Also note that bag avg reliable performs best in the very-low-recall region but worst in general.", "labels": [], "entities": []}, {"text": "This is because that it ranks higher the sentences expressing either birth-date or death-date, the simplest but the most common relations in the dataset, but fails to learn other relations with limited or noisy training instances, given its relatively simple aggregation strategy.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison with feature-based methods.  P@R 10/20/30 refers to the precision when recall  equals 10%, 20% and 30%.", "labels": [], "entities": [{"text": "P@R 10", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.8611948639154434}, {"text": "precision", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9995050430297852}, {"text": "recall", "start_pos": 92, "end_pos": 98, "type": "METRIC", "confidence": 0.9357318878173828}]}]}