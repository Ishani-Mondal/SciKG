{"title": [{"text": "Separating Facts from Fiction: Linguistic Models to Classify Suspicious and Trusted News Posts on Twitter", "labels": [], "entities": [{"text": "Separating Facts from Fiction", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.883044645190239}]}], "abstractContent": [{"text": "Pew research polls report 62 percent of U.S. adults get news on social media (Got-tfried and Shearer, 2016).", "labels": [], "entities": []}, {"text": "Ina December poll, 64 percent of U.S. adults said that \"made-up news\" has caused a \"great deal of confusion\" about the facts of current events (Barthel et al., 2016).", "labels": [], "entities": []}, {"text": "Fabricated stories in social media, ranging from deliberate propaganda to hoaxes and satire, contributes to this confusion in addition to having serious effects on global stability.", "labels": [], "entities": []}, {"text": "In this work we build predictive models to classify 130 thousand news posts as suspicious or verified, and predict four sub-types of suspicious news-satire, hoaxes, clickbait and propaganda.", "labels": [], "entities": []}, {"text": "We show that neural network models trained on tweet content and social network interactions outperform lexical models.", "labels": [], "entities": []}, {"text": "Unlike previous work on deception detection, we find that adding syntax and grammar features to our models does not improve performance.", "labels": [], "entities": [{"text": "deception detection", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.9617079496383667}]}, {"text": "Incorporating linguistic features improves classification results, however, social interaction features are most informative for finer-grained separation between four types of suspicious news posts.", "labels": [], "entities": []}], "introductionContent": [{"text": "Popular social media platforms such as Twitter and Facebook have proven to be effective channels for disseminating falsified information, unverified claims, and fabricated attention-grabbing stories due to their wide reach and the speed at which this information can be shared.", "labels": [], "entities": []}, {"text": "Recently, there has been an increased number of disturbing incidents of fabricated stories proliferated through social media having a serious impact on real-world events False news stories distributed in social media vary depending on the intent behind falsification.", "labels": [], "entities": []}, {"text": "Unlike verified news, suspicious news tends to build narratives rather than report facts.", "labels": [], "entities": []}, {"text": "On one extreme is disinformation which communicates false facts to deliberately deceive readers or promote a biased agenda.", "labels": [], "entities": []}, {"text": "These include posts generated and retweeted from propaganda and so-called clickbait (\"eye-catching\" headlines) accounts.", "labels": [], "entities": []}, {"text": "The intent behind propaganda and clickbait varies from opinion manipulation and attention redirection to monetization and traffic attraction.", "labels": [], "entities": [{"text": "traffic attraction", "start_pos": 122, "end_pos": 140, "type": "TASK", "confidence": 0.6908804476261139}]}, {"text": "Hoaxes are another type of disinformation that aims to deliberately deceive the reader).", "labels": [], "entities": []}, {"text": "On the other extreme is satire, e.g., @TheOnion, where the writer's primary purpose is not to mislead the reader, but rather entertain or criticize ( . However, satirical news and hoaxes may also be harmful, especially when they are shared out of context ( . Our novel contributions in this paper are twofold.", "labels": [], "entities": [{"text": "TheOnion", "start_pos": 39, "end_pos": 47, "type": "DATASET", "confidence": 0.966783881187439}]}, {"text": "We first investigate several features and neural network architectures for automatically classifying verified and suspicious news posts, and four sub-types of suspicious news.", "labels": [], "entities": [{"text": "classifying verified and suspicious news posts", "start_pos": 89, "end_pos": 135, "type": "TASK", "confidence": 0.6809009512265524}]}, {"text": "We find that incorporating linguistic and network features via a \"late fusion\" technique boosts performance.", "labels": [], "entities": []}, {"text": "We then investigate differences between verified and suspicious news tweets by conducting a statistical analysis of linguistic features in both types of account.", "labels": [], "entities": []}, {"text": "We show significant differences in use of biased, subjective language and moral foundations behind suspicious and trustworthy news posts.", "labels": [], "entities": []}, {"text": "Our analysis and experiments rely on a large Twitter corpus 1 collected during a two-week pe- riod around terrorist attacks in Brussels in 2016.", "labels": [], "entities": []}, {"text": "Our method of collection ensures that our models learn from verified and suspicious news within a predefined timeframe, and further ensures homogeneity of deceptive texts in length and writing manner ( . Several tools have been recently developed to verify and reestablish trusted sources of information online e.g., Google fact checking and Facebook repost verification.", "labels": [], "entities": [{"text": "Google fact checking", "start_pos": 317, "end_pos": 337, "type": "TASK", "confidence": 0.6186993817488352}]}, {"text": "These projects, among others, teach news literacy 2 and contribute to fact-checking online.", "labels": [], "entities": [{"text": "news literacy", "start_pos": 36, "end_pos": 49, "type": "TASK", "confidence": 0.7380797564983368}]}, {"text": "We believe our models and novel findings on linguistic differences between suspicious and verified news will contribute to these fact-checking systems, as well as help readers to judge the accuracy of information they consume in social media.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 189, "end_pos": 197, "type": "METRIC", "confidence": 0.9712951183319092}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Twitter dataset statistics: news accounts, posts and  retweets per account (RTPA).", "labels": [], "entities": [{"text": "Twitter dataset statistics", "start_pos": 10, "end_pos": 36, "type": "DATASET", "confidence": 0.8211833437283834}, {"text": "retweets per account (RTPA)", "start_pos": 64, "end_pos": 91, "type": "METRIC", "confidence": 0.7187136312325796}]}, {"text": " Table 2: Classification results: predicting suspicion and ver- ified posts reported as A -accuracy, AP -average precision,  ROC -the area under the receiver operator characteristics  curve, and inferring types of suspicious news reported using  F1 micro and F1 macro scores.", "labels": [], "entities": [{"text": "ver", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.8340291976928711}, {"text": "A -accuracy", "start_pos": 88, "end_pos": 99, "type": "METRIC", "confidence": 0.9475561380386353}, {"text": "AP -average precision", "start_pos": 101, "end_pos": 122, "type": "METRIC", "confidence": 0.9290326088666916}, {"text": "ROC", "start_pos": 125, "end_pos": 128, "type": "METRIC", "confidence": 0.9949890971183777}, {"text": "F1 micro", "start_pos": 246, "end_pos": 254, "type": "METRIC", "confidence": 0.9688156545162201}, {"text": "F1 macro scores", "start_pos": 259, "end_pos": 274, "type": "METRIC", "confidence": 0.9126389225323995}]}, {"text": " Table 3: Linguistic analysis of moral foundations, bias and subjective language shown as the percentage of tweets with one  or more cues across verified (V) and suspicious (F) news -propaganda (P), hoaxes (H), satire (S) and clickbait (C). We report  only statistically significant differences: p-value \u2264 0.05\u2191, \u2264 0.01\u2191\u2191, \u2264 0.001\u2191\u2191\u2191 estimated using the Mann-Whitney U test.  Subjective lexicon is from (", "labels": [], "entities": []}]}