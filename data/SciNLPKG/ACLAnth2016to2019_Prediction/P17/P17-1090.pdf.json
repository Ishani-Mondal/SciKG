{"title": [{"text": "Joint Modeling of Content and Discourse Relations in Dialogues", "labels": [], "entities": [{"text": "Joint Modeling of Content and Discourse Relations in Dialogues", "start_pos": 0, "end_pos": 62, "type": "TASK", "confidence": 0.6887025435765585}]}], "abstractContent": [{"text": "We present a joint modeling approach to identify salient discussion points in spoken meetings as well as to label the discourse relations between speaker turns.", "labels": [], "entities": []}, {"text": "A variation of our model is also discussed when discourse relations are treated as latent variables.", "labels": [], "entities": []}, {"text": "Experimental results on two popular meeting corpora show that our joint model can outperform state-of-the-art approaches for both phrase-based content selection and discourse relation prediction tasks.", "labels": [], "entities": [{"text": "phrase-based content selection", "start_pos": 130, "end_pos": 160, "type": "TASK", "confidence": 0.7067943811416626}, {"text": "discourse relation prediction", "start_pos": 165, "end_pos": 194, "type": "TASK", "confidence": 0.7058607737223307}]}, {"text": "We also evaluate our model on predicting the consistency among team members' understanding of their group decisions.", "labels": [], "entities": []}, {"text": "Classifiers trained with features constructed from our model achieve significant better predictive performance than the state-of-the-art.", "labels": [], "entities": []}], "introductionContent": [{"text": "Goal-oriented dialogues, such as meetings, negotiations, or customer service transcripts, play an important role in our daily life.", "labels": [], "entities": []}, {"text": "Automatically extracting the critical points and important outcomes from dialogues would facilitate generating summaries for complicated conversations, understanding the decision-making process of meetings, or analyzing the effectiveness of collaborations.", "labels": [], "entities": []}, {"text": "We are interested in a specific type of dialogues -spoken meetings, which is a common way for collaboration and idea sharing.", "labels": [], "entities": []}, {"text": "Previous work) has shown that discourse structure can be used to capture the main discussion points and arguments put forward during problem-solving and decision-making processes in meetings.", "labels": [], "entities": []}, {"text": "Indeed, content of different speaker turns do not occur in isolation, and should be interpreted within the context of discourse.", "labels": [], "entities": []}, {"text": "Meanwhile, content can also reflect the purpose of speaker turns, thus facilitate with discourse relation understanding.", "labels": [], "entities": [{"text": "discourse relation understanding", "start_pos": 87, "end_pos": 119, "type": "TASK", "confidence": 0.6296920080979665}]}, {"text": "Take the meeting snippet from D: Three different types of batteries.", "labels": [], "entities": []}, {"text": "Um can either use a hand dynamo, or the kinetic type ones, you know that they use in watches, or else uh a solar powered one.", "labels": [], "entities": []}, {"text": "B: Um the bat uh the battery fora a watch wouldn't require a lot of power, would be my one query.", "labels": [], "entities": [{"text": "B", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.9692462086677551}]}, {"text": "Is a kinetic one going to be able to supply enough power?", "labels": [], "entities": []}, {"text": "Here we highlight salient phrases (in italics) that are relevant to the major topic discussed, i.e., \"which type of battery to use for the remote control\".", "labels": [], "entities": []}, {"text": "Arrows indicate discourse structure between speaker turns.", "labels": [], "entities": []}, {"text": "We also show some of the discourse relations for illustration.", "labels": [], "entities": []}, {"text": "AMI corpus ) in as an example.", "labels": [], "entities": [{"text": "AMI corpus", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9388574957847595}]}, {"text": "This discussion is annotated with discourse structure based on the Twente Argumentation Schema (TAS) by, which focuses on argumentative discourse information.", "labels": [], "entities": [{"text": "Twente Argumentation Schema (TAS)", "start_pos": 67, "end_pos": 100, "type": "TASK", "confidence": 0.5942008843024572}]}, {"text": "As can be seen, meeting participants evaluate different options by showing doubt (UNCERTAIN), bringing up alternative solution (OPTION), or giving feedback.", "labels": [], "entities": [{"text": "UNCERTAIN)", "start_pos": 82, "end_pos": 92, "type": "METRIC", "confidence": 0.9282025694847107}, {"text": "OPTION", "start_pos": 128, "end_pos": 134, "type": "METRIC", "confidence": 0.9104377031326294}]}, {"text": "The discourse information helps with the identification of the key discussion point, i.e., \"which type of battery to use\", by revealing the discussion flow.", "labels": [], "entities": []}, {"text": "To date, most efforts to leverage discourse information to detect salient content from dialogues have focused on encoding gold-standard discourse relations as features for use in classifier training ().", "labels": [], "entities": []}, {"text": "However, automatic discourse parsing in dialogues is still a challenging problem.", "labels": [], "entities": [{"text": "automatic discourse parsing in dialogues", "start_pos": 9, "end_pos": 49, "type": "TASK", "confidence": 0.713159590959549}]}, {"text": "Moreover, acquiring human annotation on discourse relations is a timeconsuming and expensive process, and does not scale for large datasets.", "labels": [], "entities": []}, {"text": "In this paper, we propose a joint modeling approach to select salient phrases reflecting key discussion points as well as label the discourse relations between speaker turns in spoken meetings.", "labels": [], "entities": []}, {"text": "We hypothesize that leveraging the interaction between content and discourse has the potential to yield better prediction performance on both phrase-based content selection and discourse relation prediction.", "labels": [], "entities": [{"text": "phrase-based content selection", "start_pos": 142, "end_pos": 172, "type": "TASK", "confidence": 0.6163862744967142}, {"text": "discourse relation prediction", "start_pos": 177, "end_pos": 206, "type": "TASK", "confidence": 0.6559097766876221}]}, {"text": "Specifically, we utilize argumentative discourse relations as defined in Twente Argument Schema (TAS) (), where discussions are organized into tree structures with discourse relations labeled between nodes (as shown in).", "labels": [], "entities": [{"text": "Twente Argument Schema (TAS)", "start_pos": 73, "end_pos": 101, "type": "TASK", "confidence": 0.5143677393595377}]}, {"text": "Algorithms for joint learning and joint inference are proposed for our model.", "labels": [], "entities": []}, {"text": "We also present a variation of our model to treat discourse relations as latent variables when true labels are not available for learning.", "labels": [], "entities": []}, {"text": "We envision that the extracted salient phrases by our model can be used as input to abstractive meeting summarization systems (.", "labels": [], "entities": [{"text": "abstractive meeting summarization", "start_pos": 84, "end_pos": 117, "type": "TASK", "confidence": 0.5429333547751108}]}, {"text": "Combined with the predicted discourse structure, a visualization tool can be exploited to display conversation flow to support intelligent meeting assistant systems.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, our work is the first to jointly model content and discourse relations in meetings.", "labels": [], "entities": []}, {"text": "We test our model with two meeting corpora -the AMI corpus) and the ICSI corpus (.", "labels": [], "entities": [{"text": "AMI corpus", "start_pos": 48, "end_pos": 58, "type": "DATASET", "confidence": 0.8741143345832825}, {"text": "ICSI corpus", "start_pos": 68, "end_pos": 79, "type": "DATASET", "confidence": 0.8597269356250763}]}, {"text": "Experimental results show that our model yields an accuracy of 63.2 on phrase selection, which is significantly better than a classifier based on Support Vector Machines (SVM).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9995890259742737}, {"text": "phrase selection", "start_pos": 71, "end_pos": 87, "type": "TASK", "confidence": 0.8107849955558777}]}, {"text": "Our discourse prediction component also obtains better accuracy than a state-of-the-art neural networkbased approach (59.2 vs. 54.2).", "labels": [], "entities": [{"text": "discourse prediction", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.7061811834573746}, {"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9992978572845459}]}, {"text": "Moreover, our model trained with latent discourse outperforms SVMs on both AMI and ICSI corpora for phrase selection.", "labels": [], "entities": [{"text": "AMI", "start_pos": 75, "end_pos": 78, "type": "DATASET", "confidence": 0.8005348443984985}, {"text": "phrase selection", "start_pos": 100, "end_pos": 116, "type": "TASK", "confidence": 0.8285524547100067}]}, {"text": "We further evaluate the usage of selected phrases as extractive meeting summaries.", "labels": [], "entities": []}, {"text": "Results evaluated by ROUGE () demonstrate that our system summaries obtain a ROUGE-SU4 F1 score of 21.3 on AMI corpus, which outperforms non-trivial extractive summarization baselines and a keyword selection algorithm proposed in.", "labels": [], "entities": [{"text": "ROUGE-SU4 F1 score", "start_pos": 77, "end_pos": 95, "type": "METRIC", "confidence": 0.8527005712191263}, {"text": "AMI corpus", "start_pos": 107, "end_pos": 117, "type": "DATASET", "confidence": 0.9405714273452759}]}, {"text": "Moreover, since both content and discourse structure are critical for building shared understanding among participants, we further investigate whether our learned model can be utilized to predict the consistency among team members' understanding of their group decisions.", "labels": [], "entities": []}, {"text": "This task is first defined as consistency of understanding (COU) prediction by, who have labeled a portion of AMI discussions with consistency or inconsistency labels.", "labels": [], "entities": [{"text": "consistency of understanding (COU) prediction", "start_pos": 30, "end_pos": 75, "type": "TASK", "confidence": 0.6753698757716587}]}, {"text": "We construct features from our model predictions to capture different discourse patterns and word entrainment scores for discussion with different COU level.", "labels": [], "entities": []}, {"text": "Results on AMI discussions show that SVM classifiers trained with our features significantly outperform the state-ofthe-art results) (F1: 63.1 vs. 50.5) and non-trivial baselines.", "labels": [], "entities": [{"text": "AMI", "start_pos": 11, "end_pos": 14, "type": "DATASET", "confidence": 0.7887600064277649}, {"text": "SVM classifiers", "start_pos": 37, "end_pos": 52, "type": "TASK", "confidence": 0.8712031841278076}, {"text": "F1", "start_pos": 134, "end_pos": 136, "type": "METRIC", "confidence": 0.9971933960914612}]}, {"text": "The rest of the paper is structured as follows: we first summarize related work in Section 2.", "labels": [], "entities": []}, {"text": "The joint model is presented in Section 3.", "labels": [], "entities": []}, {"text": "Datasets and experimental setup are described in Section 4, which is followed by experimental results (Section 5).", "labels": [], "entities": []}, {"text": "We then study the usage of our model for predicting consistency of understanding in groups in Section 6.", "labels": [], "entities": [{"text": "predicting consistency of understanding", "start_pos": 41, "end_pos": 80, "type": "TASK", "confidence": 0.7686975747346878}]}, {"text": "We finally conclude in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our joint model on two meeting corpora with rich annotations: the AMI meeting corpus ) and the ICSI meeting corpus (.", "labels": [], "entities": [{"text": "AMI meeting corpus", "start_pos": 78, "end_pos": 96, "type": "DATASET", "confidence": 0.8970375259717306}, {"text": "ICSI meeting corpus", "start_pos": 107, "end_pos": 126, "type": "DATASET", "confidence": 0.9334673881530762}]}, {"text": "AMI corpus consists of 139 scenario-driven meetings, and ICSI corpus contains 75 naturally occurring meetings.", "labels": [], "entities": [{"text": "AMI corpus", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9242430329322815}, {"text": "ICSI corpus", "start_pos": 57, "end_pos": 68, "type": "DATASET", "confidence": 0.7793025970458984}]}, {"text": "Both of the corpora are annotated with dialogue acts, adjacency pairs, and topic segmentation.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 75, "end_pos": 93, "type": "TASK", "confidence": 0.7290378659963608}]}, {"text": "We treat each topic segment as one discussion, and remove discussions with less than 10 turns or labeled as \"opening\" and \"chitchat\".", "labels": [], "entities": []}, {"text": "694 discussions from AMI and 1139 discussions from ICSI are extracted, and these two datasets are henceforth referred as AMI-FULL and ICSI-", "labels": [], "entities": [{"text": "AMI", "start_pos": 21, "end_pos": 24, "type": "DATASET", "confidence": 0.9311598539352417}, {"text": "ICSI", "start_pos": 51, "end_pos": 55, "type": "DATASET", "confidence": 0.89594966173172}, {"text": "AMI-FULL", "start_pos": 121, "end_pos": 129, "type": "DATASET", "confidence": 0.9042540192604065}]}], "tableCaptions": [{"text": " Table 1: Phrase-based content selection performance", "labels": [], "entities": [{"text": "Phrase-based content selection", "start_pos": 10, "end_pos": 40, "type": "TASK", "confidence": 0.9393941760063171}]}, {"text": " Table 2: Discourse relation prediction performance on", "labels": [], "entities": [{"text": "Discourse relation prediction", "start_pos": 10, "end_pos": 39, "type": "TASK", "confidence": 0.7319060762723287}]}, {"text": " Table 3: Phrase-based content selection performance", "labels": [], "entities": [{"text": "Phrase-based content selection", "start_pos": 10, "end_pos": 40, "type": "TASK", "confidence": 0.9387697378794352}]}, {"text": " Table 4: ROUGE scores for phrase-based extractive", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9917027354240417}, {"text": "phrase-based extractive", "start_pos": 27, "end_pos": 50, "type": "TASK", "confidence": 0.7236965298652649}]}, {"text": " Table 5: Consistency of Understanding (COU) predic-", "labels": [], "entities": []}]}