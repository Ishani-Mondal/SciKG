{"title": [{"text": "Don't understand a measure? Learn it: Structured Prediction for Coreference Resolution optimizing its measures", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 64, "end_pos": 86, "type": "TASK", "confidence": 0.9719472825527191}]}], "abstractContent": [{"text": "An assential aspect of structured prediction is the evaluation of an output structure against the gold standard.", "labels": [], "entities": [{"text": "structured prediction", "start_pos": 23, "end_pos": 44, "type": "TASK", "confidence": 0.7467828392982483}]}, {"text": "Especially in the loss-augmented setting, the need of finding the max-violating constraint has severely limited the expressivity of effective loss functions.", "labels": [], "entities": []}, {"text": "In this paper, we trade off exact computation for enabling the use of more complex loss functions for coreference resolution (CR).", "labels": [], "entities": [{"text": "coreference resolution (CR)", "start_pos": 102, "end_pos": 129, "type": "TASK", "confidence": 0.9412604451179505}]}, {"text": "Most noteworthily , we show that such functions can be (i) automatically learned also from controversial but commonly accepted CR measures, e.g., MELA, and (ii) successfully used in learning algorithms.", "labels": [], "entities": [{"text": "MELA", "start_pos": 146, "end_pos": 150, "type": "METRIC", "confidence": 0.8449817895889282}]}, {"text": "The accurate model comparison on the standard CoNLL-2012 setting shows the benefit of more expressive loss for Arabic and En-glish data.", "labels": [], "entities": [{"text": "CoNLL-2012 setting", "start_pos": 46, "end_pos": 64, "type": "DATASET", "confidence": 0.9136320650577545}]}], "introductionContent": [{"text": "In recent years, interesting structured prediction methods have been developed for coreference resolution (CR), e.g.,).", "labels": [], "entities": [{"text": "coreference resolution (CR)", "start_pos": 83, "end_pos": 110, "type": "TASK", "confidence": 0.9264803767204285}]}, {"text": "These models are supposed to output clusters but, to better control the exponential nature of the problem, the clusters are converted into tree structures.", "labels": [], "entities": []}, {"text": "Although this simplifies the problem, optimal solutions are associated with an exponential set of trees, requiring to maximize over such a set.", "labels": [], "entities": []}, {"text": "This originated latent models () optimizing the so-called lossaugmented objective functions.", "labels": [], "entities": []}, {"text": "In this setting, loss functions need to be factorizable together with the feature representations for finding the max-violating constraints.", "labels": [], "entities": []}, {"text": "The consequence is that only simple loss functions, basically just counting incorrect edges, were applied in previous work, giving up expressivity for simplicity.", "labels": [], "entities": []}, {"text": "This is a critical limitation as domain experts consider more information than just counting edges.", "labels": [], "entities": []}, {"text": "In this paper, we study the use of more expressive loss functions in the structured prediction framework for CR, although some findings are clearly applicable to more general settings.", "labels": [], "entities": [{"text": "CR", "start_pos": 109, "end_pos": 111, "type": "TASK", "confidence": 0.9579230546951294}]}, {"text": "We attempted to optimize the complicated official MELA measure 1 ( of CR within the learning algorithm.", "labels": [], "entities": [{"text": "MELA measure 1", "start_pos": 50, "end_pos": 64, "type": "METRIC", "confidence": 0.8429751992225647}, {"text": "CR", "start_pos": 70, "end_pos": 72, "type": "METRIC", "confidence": 0.8477840423583984}]}, {"text": "Unfortunately, MELA is the average of measures, among which CEAF e has an excessive computational complexity preventing its direct use.", "labels": [], "entities": [{"text": "MELA", "start_pos": 15, "end_pos": 19, "type": "METRIC", "confidence": 0.9570457935333252}]}, {"text": "To solve this problem, we defined a model for learning MELA from data using a fast linear regressor, which can be then effectively used in structured prediction algorithms.", "labels": [], "entities": []}, {"text": "We defined features to learn such a loss function, e.g., different link counts or aggregations such as Precision and Recall.", "labels": [], "entities": [{"text": "Precision", "start_pos": 103, "end_pos": 112, "type": "METRIC", "confidence": 0.980227530002594}, {"text": "Recall", "start_pos": 117, "end_pos": 123, "type": "METRIC", "confidence": 0.7952418923377991}]}, {"text": "Moreover, we designed methods for generating training data from which our regression loss algorithm (RL) can generalize well and accurately predict MELA values on unseen data.", "labels": [], "entities": []}, {"text": "Since RL is not factorizable 2 over a mention graph, we designed a latent structured perceptron (LSP) that can optimize non-factorizable loss functions on CR graphs.", "labels": [], "entities": []}, {"text": "We tested LSP using RL and other traditional loss functions using the same setting of the CoNLL-2012 Shared Task, thus enabling an exact comparison with previous work.", "labels": [], "entities": [{"text": "CoNLL-2012 Shared Task", "start_pos": 90, "end_pos": 112, "type": "DATASET", "confidence": 0.8163260022799174}]}, {"text": "The results confirmed that RL can be effectively learned and used in LSP, although the improvement was smaller than expected, considering that our RL provides the algorithm with a more accurate feedback.", "labels": [], "entities": []}, {"text": "Thus, we analyzed the theory behind this pro-cess by also contributing to the definition of the properties of loss optimality.", "labels": [], "entities": []}, {"text": "These show that the available loss functions, e.g., by Fernandes et al.; Yu and Joachims, are enough for optimizing MELA on the training set, at least when the data is separable.", "labels": [], "entities": []}, {"text": "Thus, in such conditions, we cannot expect a very large improvement from RL.", "labels": [], "entities": [{"text": "RL", "start_pos": 73, "end_pos": 75, "type": "METRIC", "confidence": 0.7437151074409485}]}, {"text": "To confirm such a conjecture, we tested the models in a more difficult setting, in terms of separability.", "labels": [], "entities": []}, {"text": "We used different feature sets of a smaller size and found out that in such conditions, RL requires less epochs for converging and produces better results than the other simpler loss functions.", "labels": [], "entities": [{"text": "RL", "start_pos": 88, "end_pos": 90, "type": "METRIC", "confidence": 0.7900617122650146}]}, {"text": "The accuracy of RL-based model, using 16 times less features, decreases by just 0.3 points, still improving the state of the art in structured prediction.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9995903372764587}, {"text": "structured prediction", "start_pos": 132, "end_pos": 153, "type": "TASK", "confidence": 0.7565983235836029}]}, {"text": "Accordingly, in the Arabic setting, where the available features are less discriminative, our approach highly improves the standard LSP.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our experiments, we first show that our regressor for learning MELA approximates it rather accurately.", "labels": [], "entities": [{"text": "MELA", "start_pos": 66, "end_pos": 70, "type": "METRIC", "confidence": 0.5436521172523499}]}, {"text": "Then, we examine the impact of our \u2206 \u03c1 on state-of-the-art systems in comparison with other loss functions.", "labels": [], "entities": []}, {"text": "Finally, we show that the impact of our model is amplified when learning in smaller feature spaces.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracy of the loss regressor on two different sets", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9987176656723022}]}, {"text": " Table 2: Results of our and previous work models evaluated", "labels": [], "entities": []}, {"text": " Table 3: Results on the test set using the same setting of", "labels": [], "entities": []}, {"text": " Table 4: Results of our and baseline models evaluated on", "labels": [], "entities": []}]}