{"title": [{"text": "Apples to Apples: Learning Semantics of Common Entities Through a Novel Comprehension Task", "labels": [], "entities": []}], "abstractContent": [{"text": "Understanding common entities and their attributes is a primary requirement for any system that comprehends natural language.", "labels": [], "entities": []}, {"text": "In order to enable learning about common entities, we introduce a novel machine comprehension task, GuessTwo: given a short paragraph comparing different aspects of two real-world semantically-similar entities, a system should guess what those entities are.", "labels": [], "entities": [{"text": "GuessTwo", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.9814090728759766}]}, {"text": "Accomplishing this task requires deep language understanding which enables inference , connecting each comparison paragraph to different levels of knowledge about world entities and their attributes.", "labels": [], "entities": []}, {"text": "So far we have crowdsourced a dataset of more than 14K comparison paragraphs comparing entities from a variety of categories such as fruits and animals.", "labels": [], "entities": []}, {"text": "We have designed two schemes for evaluation: open-ended, and binary-choice prediction.", "labels": [], "entities": [{"text": "binary-choice prediction", "start_pos": 61, "end_pos": 85, "type": "TASK", "confidence": 0.7373317182064056}]}, {"text": "For benchmarking further progress in the task, we have collected a set of paragraphs as the test set on which human can accomplish the task with an accuracy of 94.2% on open-ended prediction.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 148, "end_pos": 156, "type": "METRIC", "confidence": 0.9994111061096191}]}, {"text": "We have implemented various models for tackling the task, ranging from semantic-driven to neu-ral models.", "labels": [], "entities": []}, {"text": "The semantic-driven approach outperforms the neural models, however, the results indicate that the task is very challenging across the models.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the past few years, there has been great progress on core NLP tasks (e.g., parsing and part of speech tagging) which has renewed interest in primary language learning tasks which require text understanding and reasoning, such as machine comprehension (.", "labels": [], "entities": [{"text": "parsing", "start_pos": 78, "end_pos": 85, "type": "TASK", "confidence": 0.9756498336791992}, {"text": "speech tagging", "start_pos": 98, "end_pos": 112, "type": "TASK", "confidence": 0.6488837003707886}]}, {"text": "Our question is how far have we got in learning basic concepts of the world through language comprehension.", "labels": [], "entities": []}, {"text": "If we look at the large body of work on extracting knowledge from unstructured corpora, we will see that they often lack some very basic pieces of information.", "labels": [], "entities": []}, {"text": "For example, let us focus on the basic concept of apple, the fruit.", "labels": [], "entities": []}, {"text": "What do the state-of-the-art systems and resources know about an apple?", "labels": [], "entities": []}, {"text": "None of the state-of-the-art knowledge bases) include much precise information about the fact that apples have an edible skin, vary from sweet to sour, are round, and relatively the same size of a fist.", "labels": [], "entities": []}, {"text": "Moreover, there is no clear approach on how to extract such information, if any, from trained word embeddings.", "labels": [], "entities": []}, {"text": "This paper focuses on how we can automatically learn about various attributes of such generic entities in the world.", "labels": [], "entities": []}, {"text": "A key observation motivating this work is that we can learn more detail about objects when they are compared to other similar objects.", "labels": [], "entities": []}, {"text": "When we compare things we often contrast, that is, we count their similarities along with their dissimilarities.", "labels": [], "entities": []}, {"text": "This results in covering the primary attributes and aspects of objects.", "labels": [], "entities": []}, {"text": "As humans, we tend to recall and mention the difference between things (say green skin vs. redskin in apples) as opposed to absolute measures (say the existence of skin).", "labels": [], "entities": [{"text": "recall", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9877899885177612}]}, {"text": "Interestingly, there is evidence that human knowledge is structured by semantic similarity and the relations among objects are defined by their relative perceptual and conceptual properties, such as their form, function, behavior, and environment (.", "labels": [], "entities": []}, {"text": "Our idea is to leverage comparison as away of naturally learning about common world concepts and their specific attributes.", "labels": [], "entities": []}, {"text": "Comparison, where we name the similarities and differences between things, is a unique cognitive ability in humans 1 which requires memorizing facts, experiencing things and integration of concepts of the world.", "labels": [], "entities": []}, {"text": "It is clear that developing AI systems that are capable of comprehending comparison is crucial.", "labels": [], "entities": [{"text": "comprehending comparison", "start_pos": 59, "end_pos": 83, "type": "TASK", "confidence": 0.8501951694488525}]}, {"text": "In this paper, in order to enable learning through comparison, we introduce anew language comprehension task which requires understanding different attributes of basic entities that are being compared.", "labels": [], "entities": []}, {"text": "The contributions of this paper are as follows: (1) To equip learning about common entities through comparison comprehension, we have crowdsourced a dataset of more than 14K comparison paragraphs comparing entities from nine broad categories (Section 2).", "labels": [], "entities": []}, {"text": "This resource will be expanded overtime and will be released to the public.", "labels": [], "entities": []}, {"text": "(2) We introduce a novel task called GuessTwo, in which given a short paragraph comparing two entities, a system should guess what the two things are.", "labels": [], "entities": [{"text": "GuessTwo", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.8497346639633179}]}, {"text": "To make systematic benchmarking on the task possible, we vet a collection of comparison paragraphs to obtain a test set on which human performs with an accuracy 94.2%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 152, "end_pos": 160, "type": "METRIC", "confidence": 0.9989821314811707}]}, {"text": "(3) We present a host of neural approaches and a novel semantic-driven model for tackling the GuessTwo task (Sections 4, 5).", "labels": [], "entities": []}, {"text": "Our experiments show that the semantic approach outperforms the neural models.", "labels": [], "entities": []}, {"text": "The results strongly suggest that closing the gap between system and human performances requires richer semantic processing (Section 6).", "labels": [], "entities": []}, {"text": "We hope that this work will establish anew base fora machine comprehension test that requires systems to go beyond information extraction and towards levels of performing basic reasoning.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 115, "end_pos": 137, "type": "TASK", "confidence": 0.7267909497022629}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Statistics of the GuessTwo dataset as of  April 2017.", "labels": [], "entities": [{"text": "GuessTwo dataset", "start_pos": 28, "end_pos": 44, "type": "DATASET", "confidence": 0.9859611392021179}]}, {"text": " Table 3: System accuracy results on the GuessTwo  test set. A random baseline on binary choice task  achieves 51%. The open-ended evaluation has  two columns: exact-match (exact) and subcate- gory match (subcat), respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9957367181777954}, {"text": "GuessTwo  test set", "start_pos": 41, "end_pos": 59, "type": "DATASET", "confidence": 0.8865536451339722}]}]}