{"title": [{"text": "Improving Native Language Identification by Using Spelling Errors", "labels": [], "entities": [{"text": "Improving Native Language Identification", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.9282657951116562}]}], "abstractContent": [{"text": "In this paper, we explore spelling errors as a source of information for detecting the native language of a writer, a previously under-explored area.", "labels": [], "entities": [{"text": "detecting the native language of a writer", "start_pos": 73, "end_pos": 114, "type": "TASK", "confidence": 0.8242641857692173}]}, {"text": "We note that character n-grams from misspelled words are very indicative of the native language of the author.", "labels": [], "entities": []}, {"text": "In combination with other lexical features, spelling error features lead to 1.2% improvement inaccuracy on classifying texts in the TOEFL11 corpus by the author's native language, compared to systems participating in the NLI shared task 1 .", "labels": [], "entities": [{"text": "TOEFL11 corpus", "start_pos": 132, "end_pos": 146, "type": "DATASET", "confidence": 0.8860166072845459}]}], "introductionContent": [{"text": "Native Language Identification (NLI) aims to determine the native language (L1) of a writer based on his or her writings in a second language (L2).", "labels": [], "entities": [{"text": "Native Language Identification (NLI)", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.7758026123046875}]}, {"text": "Though initially motivated by the study of crosslinguistics influence, the value of NLI is not limited to education.", "labels": [], "entities": []}, {"text": "Potentially, it is also very valuable in academic, marketing, security and law enforcement fields.", "labels": [], "entities": []}, {"text": "Identifying the native language is based on the assumption that the L1 of an individual impacts his or her writing in L2 due to the language transfer effect.", "labels": [], "entities": [{"text": "Identifying the native language", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8308941423892975}]}, {"text": "We focus hereon the influences from L1 that surface as spelling errors in L2.", "labels": [], "entities": []}, {"text": "showed that syntactic patterns and lexical preferences from L1 appear in L2 systematically, and are very informative for identifying the writer's native language.", "labels": [], "entities": []}, {"text": "Texts written by authors with the same L1 also exhibit similarities with respect to the errors within.", "labels": [], "entities": []}, {"text": "In terms of spelling, in particular, both the sound of the words in different languages and the mapping from sounds to letters in L2 vs. L1, as well as the particular conventions of writing can https://sites.google.com/site/nlisharedtask2013/home have a visible impact.", "labels": [], "entities": []}, {"text": "In Italian, for example, each vowel has only one pronunciation, so it is very common for Italian writers to confuse the use of vowels in English: the English e can correspond to the sounds written either as i ore in Italian.", "labels": [], "entities": []}, {"text": "In Arabic, on the other hand, vowels are rarely written, and this could cause writers to miss vowels when writing in English.", "labels": [], "entities": []}, {"text": "In Chinese, since it uses a completely different writing system compared to English, there might be a higher probability for authors to make spelling errors when it comes to complicated words, because the mapping from English sounds to letters of the Roman alphabet is not one-to-one.", "labels": [], "entities": []}, {"text": "We test whether we are able to capture some of these phenomena by going below the word level to character level and testing their usefulness as features for identifying the native language of the author.", "labels": [], "entities": []}, {"text": "Spelling errors have been used as features for NLI since.", "labels": [], "entities": []}, {"text": "They considered syntax errors and eight types of spelling errors such as repeated letters, missing letters, and inversion of letters.", "labels": [], "entities": []}, {"text": "The relative frequency of each error type with regard to the length of the document is used as feature values.", "labels": [], "entities": []}, {"text": "By combining these with common features such as function words, they obtained a classification accuracy of 80.2% on a subcorpora of ICLEv1 that consists of five languages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9490073323249817}, {"text": "ICLEv1", "start_pos": 132, "end_pos": 138, "type": "DATASET", "confidence": 0.87556391954422}]}, {"text": "More recently, focused on the misspelled part of a word rather than the type of spelling errors.", "labels": [], "entities": []}, {"text": "They used pairs of correct and misspelled parts in a word as features.", "labels": [], "entities": []}, {"text": "adopted a similar approach to represent the spelling errors by the inner-most misspelled substring compared to the correct word.", "labels": [], "entities": []}, {"text": "Combined with other features, they obtained a test accuracy of 75.29% on the TOEFL11 dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.989844560623169}, {"text": "TOEFL11 dataset", "start_pos": 77, "end_pos": 92, "type": "DATASET", "confidence": 0.9850646555423737}]}, {"text": "Character n-grams have been explored, but not particularly for representing spelling errors.", "labels": [], "entities": []}, {"text": "showed that using char-acter unigrams, bigrams, and trigrams, the test accuracy can reach 37.4% for 7-class NLI on a subset of ICLEv2 corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.9901154041290283}, {"text": "ICLEv2 corpus", "start_pos": 127, "end_pos": 140, "type": "DATASET", "confidence": 0.907209575176239}]}, {"text": "For the NLI 2013 shared task, used as features character trigrams represented by their raw frequencies.", "labels": [], "entities": [{"text": "NLI 2013 shared task", "start_pos": 8, "end_pos": 28, "type": "DATASET", "confidence": 0.8479857593774796}]}, {"text": "It leads to a test accuracy of 57.77%, which shows that how often character combinations are used is indicative of the L1 of an author.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9889245629310608}]}, {"text": "Using complete words to represent spelling errors would not capture regularities that go beyond a single misspelled instance -like the preference of using i instead of e by Italian writers.", "labels": [], "entities": []}, {"text": "We investigate the representation of spelling errors through character n-grams with size up to 3.", "labels": [], "entities": [{"text": "representation of spelling errors", "start_pos": 19, "end_pos": 52, "type": "TASK", "confidence": 0.7878970354795456}]}, {"text": "We assess the effectiveness of using such feature representation for NLI and its contribution when combined with word and lemma n-grams, whose effectiveness has already been established ().", "labels": [], "entities": []}, {"text": "We report high classification results when using only spelling errors, and an improvement of 1.2 percentage points inaccuracy, compared to the best results obtained in NLI shared task, when using spelling errors in combination with word and lemma features.", "labels": [], "entities": []}], "datasetContent": [{"text": "The data is pre-processed by lower casing the tokenized version of the corpus.", "labels": [], "entities": []}, {"text": "Each text is represented through the sets of features described above.", "labels": [], "entities": []}, {"text": "The feature size of word n-grams up to size 3 are over 500,000 and that of lemma n-grams up to size 3 are over 400,000.", "labels": [], "entities": []}, {"text": "The combination of the two is over 600,000.", "labels": [], "entities": []}, {"text": "The hyper-parameter C of the linear SVM is set to 100, an optimal setting obtained by cross-validation on the train set.", "labels": [], "entities": []}, {"text": "The performance is evaluated by classification accuracy, as was done in the NLI shared task.", "labels": [], "entities": [{"text": "classification", "start_pos": 32, "end_pos": 46, "type": "TASK", "confidence": 0.9129382371902466}, {"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9101229906082153}]}, {"text": "We test the performance of the used feature sets through a 10-fold cross-validation on the train+development set before the final run on the test set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Classification accuracy of using dif- ferent features by 10-fold cross-validation on the  train+development set and test on the test set, the  accuracy scores are in %. The values in bracket  are the standard deviation of accuracy scores in  10-fold cross-validation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9289340376853943}, {"text": "accuracy", "start_pos": 153, "end_pos": 161, "type": "METRIC", "confidence": 0.999261200428009}, {"text": "accuracy", "start_pos": 232, "end_pos": 240, "type": "METRIC", "confidence": 0.990516722202301}]}]}