{"title": [{"text": "Learning Lexico-Functional Patterns for First-Person Affect", "labels": [], "entities": []}], "abstractContent": [{"text": "Informal first-person narratives area unique resource for computational models of everyday events and people's affec-tive reactions to them.", "labels": [], "entities": []}, {"text": "People blogging about their day tend not to explicitly say I am happy.", "labels": [], "entities": []}, {"text": "Instead they describe situations from which other humans can readily infer their affective reactions.", "labels": [], "entities": []}, {"text": "However current sentiment dictionaries are missing much of the information needed to make similar inferences.", "labels": [], "entities": [{"text": "sentiment dictionaries", "start_pos": 16, "end_pos": 38, "type": "TASK", "confidence": 0.8516328036785126}]}, {"text": "We build on recent work that models affect in terms of lexical predicate functions and affect on the pred-icate's arguments.", "labels": [], "entities": []}, {"text": "We present a method to learn proxies for these functions from first-person narratives.", "labels": [], "entities": []}, {"text": "We construct a novel fine-grained test set, and show that the patterns we learn improve our ability to predict first-person affective reactions to everyday events, from a Stanford sentiment baseline of .67F to .75F.", "labels": [], "entities": [{"text": "predict first-person affective reactions to everyday events", "start_pos": 103, "end_pos": 162, "type": "TASK", "confidence": 0.8457286528178624}]}], "introductionContent": [{"text": "Across social media, thousands of posts daily take the form of informal FIRST-PERSON NARRA-TIVES.", "labels": [], "entities": [{"text": "FIRST-PERSON NARRA-TIVES", "start_pos": 72, "end_pos": 96, "type": "DATASET", "confidence": 0.5073854029178619}]}, {"text": "These narratives provide a rich resource for computational modeling of how people feel about the events they report on.", "labels": [], "entities": []}, {"text": "Being able to reliably predict the affect a person may feel towards events they encounter has a range of potential applications, including monitoring mood and mental health () and getting conversational assistants to respond appropriately.", "labels": [], "entities": []}, {"text": "Moreover, as these narratives are told from the perspective of a protagonist, this research could be used to understand other types of protagonist-framed narratives, like those in fiction.", "labels": [], "entities": []}, {"text": "We are interested in the opinions that a protagonist has, not the author per se.", "labels": [], "entities": []}, {"text": "This is sometimes referred to as internal sentiment or self reflective sentiment.", "labels": [], "entities": []}, {"text": "While in many situations that is overlaid with the author's opinions, in first-personal narratives, because the author is the protagonist, the two perspectives align.", "labels": [], "entities": []}, {"text": "Here, we use the term affect to reference this protagonist-centered notion of opinion.", "labels": [], "entities": []}, {"text": "A central obstacle to reliable affect prediction is that that people tend not to explicitly flag their affective state, by saying I am happy.", "labels": [], "entities": [{"text": "affect prediction", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.7322957515716553}]}, {"text": "Large-scale sentiment dictionaries focus on compiling lexical items that bear a consistent affect all on their own ().", "labels": [], "entities": [{"text": "sentiment dictionaries", "start_pos": 12, "end_pos": 34, "type": "TASK", "confidence": 0.8587865233421326}]}, {"text": "But people tend to describe situations, such as My friend bought me flowers, or I got a parking ticket, from which other humans can readily infer their implicit affective reactions.", "labels": [], "entities": []}, {"text": "One approach to this problem aims to directly learn units larger than a lexical item that reliably bear some marker of polarity or emotion (: Functions for verbs of possession.", "labels": [], "entities": []}, {"text": "Another approach aims to model the speaker's affect to an event compositionally, e.g. proposed that the affect a lexical predicate communicates should be modeled as an n-ary function, taking as inputs the affect that the speaker bears towards each partici-pant.", "labels": [], "entities": []}, {"text": "contains A&R's functions for verbs of possession: a state in which X has Y or X lacks Y does not convey a clear affect unless we know what the speaker thinks of both X and Y . If the speaker has positive affect toward both X and Y (Row 1), then we infer that her attitude toward the event is positive, but if either is negative, then we infer that the speaker is negative toward the event.", "labels": [], "entities": []}, {"text": "Similarly, represent the typical affect communicated by particular predicates via connotation frames.", "labels": [], "entities": []}, {"text": "Here we are finding the internal sentiment of the speaker, or, as Rashkin et al. refer to it, the \"mental state\" of the speaker.", "labels": [], "entities": []}, {"text": "Inspired by A&R's framework, our work learns lexico-functional patterns (patterns involving lexical items or pairs of lexical items in specific grammatical relations that we show to capture functorargument relations in A&R's sense), about the effects of combining particular arguments with particular verbs (event types) from first-person narratives.", "labels": [], "entities": []}, {"text": "Our novel observation is that learning these compositional functions is greatly simplified in the case of first-person affect.", "labels": [], "entities": []}, {"text": "People bear positive affect to themselves, so sentences with first-person elements, e.g. I/we/me, reduce the problem for an approach like A&R's to learning the polarity that results from composing the verb with only one of its arguments, i.e. only Rows 1, 2 in need to be learned for first person subjects.", "labels": [], "entities": []}, {"text": "Firstperson narratives are full of such sentences.", "labels": [], "entities": []}, {"text": "We show that the learned patterns are often consonant with A&R's predictions, but are richer, including e.g. many private state descriptions ().", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experimental setup involves first creating a corpus of training and test sentences, then applying AutoSlog-TS a second time to learn linguistic patterns.", "labels": [], "entities": []}, {"text": "We then setup methods for cascading classifiers to explore whether ensemble classifiers improve our results.", "labels": [], "entities": []}, {"text": "Training Set: From the bootstrapped set of stories, we create a corpus of sentences.", "labels": [], "entities": []}, {"text": "A critical simplifying assumption of our method is that a multi-sentence story can be labelled as a whole as positive or negative, and that each of its sentences inherit this polarity.", "labels": [], "entities": []}, {"text": "This means we can learn the polarity of events in such narratives from their (noisy) inherited polarity without labelling individual sentences.", "labels": [], "entities": []}, {"text": "Our training set consists of 46,255 positive and 25,069 negative sentences.", "labels": [], "entities": []}, {"text": "Test Set: We create the test set by selecting 4k random first-person sentences.", "labels": [], "entities": []}, {"text": "First-person sentences either contain an explicit first person marker, i.e. we and my or start with either a progressive verb or pleonastic it.", "labels": [], "entities": []}, {"text": "To collect gold labels, we designed a qualifier and a HIT for Mechanical Turk, and put these out for annotation by 5 Turkers, who label each instance as positive, negative, or neutral.", "labels": [], "entities": [{"text": "HIT", "start_pos": 54, "end_pos": 57, "type": "METRIC", "confidence": 0.9958089590072632}]}, {"text": "To ensure the high quality of the test set, we select sentences that were labelled consistently positive or negative by 4 or 5 Turkers.", "labels": [], "entities": []}, {"text": "We collected 1,266 positive and 1,440 negative sentences.", "labels": [], "entities": []}, {"text": "Dev Set: We created the dev set using the same method as the test set, having Turkers annotate 2k random first-person sentences.", "labels": [], "entities": []}, {"text": "We collected 498 positive and 754 negative sentences.", "labels": [], "entities": []}, {"text": "The 4k test and dev sentences available for download at https://nlds.soe.ucsc.edu/first-person-sentiment.", "labels": [], "entities": []}, {"text": "In order to learn new affect functions, we develop a second sentence-level classifier using AutoSlog-TS.", "labels": [], "entities": []}, {"text": "We run AutoSlog over the training corpus, using the dev set to tune the parameters \u03b8 f , \u03b8 p and \u03b8 n (?), in order to maximize macro F-score.", "labels": [], "entities": [{"text": "F-score", "start_pos": 133, "end_pos": 140, "type": "METRIC", "confidence": 0.9157164096832275}]}, {"text": "Our best parameters on the dev set for positive is \u03b8 f =18, \u03b8 p =0.85 and \u03b8 n =1 and for negative is \u03b8 f =1, \u03b8 p =0.5 and \u03b8 n =1.", "labels": [], "entities": []}, {"text": "We specify that if the sentence is in both classes we rename it as neutral.", "labels": [], "entities": []}, {"text": "We will refer to this classifier as the AutoSlog classifier.", "labels": [], "entities": []}, {"text": "Our goal is to see whether the knowledge we learn using AutoSlog-TS complements existing sentiment classifiers.", "labels": [], "entities": []}, {"text": "We thus experiment with a number of baseline classifiers: the default SVM classifier from Weka with unigram features (), aversion of the NRC-Canada sentiment classifier (), provided to us by, and the Stanford Sentiment classifier).", "labels": [], "entities": [{"text": "Weka", "start_pos": 90, "end_pos": 94, "type": "DATASET", "confidence": 0.7756826281547546}, {"text": "NRC-Canada sentiment classifier", "start_pos": 137, "end_pos": 168, "type": "DATASET", "confidence": 0.8169976075490316}]}, {"text": "The Stanford Sentiment classifier is a based on Recursive Neural Networks, and trained on a compositional Sentiment Treebank, which includes fine-grained sentiment labels for 215,154 phrases from 11,855 sentences from movie reviews.", "labels": [], "entities": []}, {"text": "It can accurately predict some compositional semantic effects and handle negation.", "labels": [], "entities": []}, {"text": "However since it was trained on movie reviews, it is likely to be missing labelled data for some common phrases in our blogs.", "labels": [], "entities": []}, {"text": "Thus we also retrained it (RETRAINED STANFORD) on high precision phrases from AutoSlog extracted from our training data of positive and negative blogs.", "labels": [], "entities": [{"text": "RETRAINED STANFORD)", "start_pos": 27, "end_pos": 46, "type": "METRIC", "confidence": 0.8369406660397848}]}, {"text": "This provides 67,710 additional phrases, including 58,972 positive phrases and 8,738 negative phrases.", "labels": [], "entities": []}, {"text": "The retrained model includes both the labels from the original Sentiment Treebank and the AutoSlog high precision phrases.", "labels": [], "entities": [{"text": "Sentiment Treebank", "start_pos": 63, "end_pos": 81, "type": "DATASET", "confidence": 0.6985834687948227}]}], "tableCaptions": [{"text": " Table 4: Test Set Results", "labels": [], "entities": []}]}