{"title": [{"text": "On the Distribution of Lexical Features at Multiple Levels of Analysis", "labels": [], "entities": [{"text": "Distribution of Lexical Features at Multiple Levels of Analysis", "start_pos": 7, "end_pos": 70, "type": "TASK", "confidence": 0.6959915492269728}]}], "abstractContent": [{"text": "Natural language processing has increasingly moved from modeling documents and words toward studying the people behind the language.", "labels": [], "entities": [{"text": "Natural language processing", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.623938133319219}]}, {"text": "This move to working with data at the user or community level has presented the field with different characteristics of linguistic data.", "labels": [], "entities": []}, {"text": "In this paper, we empirically characterize various lexical distributions at different levels of analysis , showing that, while most features are decidedly sparse and non-normal at the message-level (as with traditional NLP), they follow the central limit theorem to become much more Log-normal or even Normal at the user-and county-levels.", "labels": [], "entities": []}, {"text": "Finally , we demonstrate that modeling lexical features for the correct level of analysis leads to marked improvements in common social scientific prediction tasks.", "labels": [], "entities": [{"text": "social scientific prediction tasks", "start_pos": 129, "end_pos": 163, "type": "TASK", "confidence": 0.727496013045311}]}], "introductionContent": [{"text": "NLP for studying people has grown rapidly as more than one-third of the human population use social media actively.", "labels": [], "entities": []}, {"text": "While traditional NLP tasks (e.g. POS tagging, parsing, sentiment analysis) mostly work at the word, sentence, or document level, the increased focus on social scientific applications has shifted attention to new levels of analysis (e.g. user-level and communitylevel) (.", "labels": [], "entities": [{"text": "POS tagging, parsing", "start_pos": 34, "end_pos": 54, "type": "TASK", "confidence": 0.6227559298276901}, {"text": "sentiment analysis", "start_pos": 56, "end_pos": 74, "type": "TASK", "confidence": 0.8225439786911011}]}, {"text": "shows the distribution of two unigrams, 'the' and 'love' at three levels of analysis.", "labels": [], "entities": []}, {"text": "While both words have zero counts inmost messages, 'the' starts to look Normal across 1 Social Insights; Global social media research summary 2017 users, and both words are approximately Normal at the county level.", "labels": [], "entities": [{"text": "Global social media research summary 2017 users", "start_pos": 105, "end_pos": 152, "type": "DATASET", "confidence": 0.8585930381502423}]}, {"text": "Methods performing optimally at the document level may suffer at the user or community level due to this shift in the distribution of lexical features.", "labels": [], "entities": []}, {"text": "In this paper, we ask a fundamental statistical question: How does the shift in unit-of-analysis from document-level to user-or-community level shift lexical distributions in social media?", "labels": [], "entities": []}, {"text": "The central limit theorem suggests that count data is better approximated by a Normal distribution as one increases the number of events, or as one aggregates more features (e.g. combining words using LDA topics or hand-built word sets).", "labels": [], "entities": []}, {"text": "However, we do not know how far towards a Normal these new levels of analysis bring us.", "labels": [], "entities": []}, {"text": "The question we ask harks back to work from pioneers in corpus-based computational linguistics, including Shannon (1948) who suggested that probabilistic distributions of ngrams could be used to solve a range of communications problems, and who found that a negative binomial distribution seemed to model unigram usage by authors of the Federalist Papers.", "labels": [], "entities": [{"text": "Federalist Papers", "start_pos": 337, "end_pos": 354, "type": "DATASET", "confidence": 0.8670667111873627}]}, {"text": "Numerous works have since continued the tradition of examining the distribution of lexical features.", "labels": [], "entities": []}, {"text": "For example, compares the results of probabilistic models based on multivariate Bernoulli with those based on multinomial distributions for document classification.", "labels": [], "entities": [{"text": "document classification", "start_pos": 140, "end_pos": 163, "type": "TASK", "confidence": 0.7571431398391724}]}, {"text": "Jansche: Histograms for unigrams \"the\" (a very frequent feature) and \"love\" (less frequent) at different levels of analysis: message, user, and community (from left to right).", "labels": [], "entities": []}, {"text": "The bars at zero are cut-off at the message and user levels to increase readability of the remaining distribution.", "labels": [], "entities": []}, {"text": "(2003) extended this line of work, observing lexical count data often display an extra probability mass concentrated at zero and suggesting ZeroInflated negative binomial distributions can capture this phenomenon better and are easier to implement than alternatives such as overdispersed binomial models.", "labels": [], "entities": []}, {"text": "While these works are numerous, none, to the best of our knowledge, have focused on distributions across social media or at multiple levels of analysis.", "labels": [], "entities": []}, {"text": "Our study is perhaps unconventional in modern computational linguistics due to the elementary nature of our contributions, focusing on understanding the empirical distributions of lexical features in Twitter.", "labels": [], "entities": []}, {"text": "First, we use zeroinflated kernel density estimated plots to show how distributions of different language features (words, LDA topics, and hand-curated word sets) vary with level of analysis (message, user, and county).", "labels": [], "entities": []}, {"text": "Second, we quantify which distributions best describe the different feature types and analysis levels of social media.", "labels": [], "entities": []}, {"text": "Finally, we show the utility of such information, finding that using the appropriate model for each feature type improves Naive Bayes classification results across three common social scientific tasks: sarcasm detection at the message-level, gender identification at the user-level, and political ideology classification at the community-level.", "labels": [], "entities": [{"text": "Naive Bayes classification", "start_pos": 122, "end_pos": 148, "type": "TASK", "confidence": 0.8775888284047445}, {"text": "sarcasm detection", "start_pos": 202, "end_pos": 219, "type": "TASK", "confidence": 0.899507075548172}]}], "datasetContent": [{"text": "We evaluate the distributions we considered by first characterizing the goodness of fit at different levels of analyses and then by their predictive performance on social media prediction tasks, both of which we describe below.", "labels": [], "entities": [{"text": "social media prediction tasks", "start_pos": 164, "end_pos": 193, "type": "TASK", "confidence": 0.7665288299322128}]}], "tableCaptions": [{"text": " Table 1: Percentage of best-fitted distributions in each level of message, user, and county for different types of features such", "labels": [], "entities": []}, {"text": " Table 2: F1-Score of Naive Bayes classifiers using various distributions and levels of analysis across tasks of sarcasm detec-", "labels": [], "entities": [{"text": "F1-Score", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9982594847679138}]}]}