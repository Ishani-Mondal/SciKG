{"title": [{"text": "Building a Non-Trivial Paraphrase Corpus using Multiple Machine Translation Systems", "labels": [], "entities": [{"text": "Multiple Machine Translation", "start_pos": 47, "end_pos": 75, "type": "TASK", "confidence": 0.6989389061927795}]}], "abstractContent": [{"text": "We propose a novel sentential paraphrase acquisition method.", "labels": [], "entities": [{"text": "sentential paraphrase acquisition", "start_pos": 19, "end_pos": 52, "type": "TASK", "confidence": 0.7042024532953898}]}, {"text": "To build a well-balanced corpus for Paraphrase Identification , we especially focus on acquiring both non-trivial positive and negative instances.", "labels": [], "entities": [{"text": "Paraphrase Identification", "start_pos": 36, "end_pos": 61, "type": "TASK", "confidence": 0.9561474323272705}]}, {"text": "We use multiple machine translation systems to generate positive candidates and a monolingual corpus to extract negative candidates.", "labels": [], "entities": []}, {"text": "To collect non-trivial instances, the candidates are uniformly sampled byword overlap rate.", "labels": [], "entities": []}, {"text": "Finally , annotators judge whether the candidates are either positive or negative.", "labels": [], "entities": []}, {"text": "Using this method, we built and released the first evaluation corpus for Japanese paraphrase identification, which comprises 655 sentence pairs.", "labels": [], "entities": [{"text": "Japanese paraphrase identification", "start_pos": 73, "end_pos": 107, "type": "TASK", "confidence": 0.6720650394757589}]}], "introductionContent": [{"text": "When two sentences share the same meaning but are written using different expressions, they are deemed to be a sentential paraphrase pair.", "labels": [], "entities": []}, {"text": "Paraphrase Identification (PI) is a task that recognizes whether a pair of sentences is a paraphrase.", "labels": [], "entities": [{"text": "Paraphrase Identification (PI)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.888487946987152}]}, {"text": "PI is useful in many applications such as information retrieval () or question answering.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 42, "end_pos": 63, "type": "TASK", "confidence": 0.7997278571128845}, {"text": "question answering", "start_pos": 70, "end_pos": 88, "type": "TASK", "confidence": 0.9195227921009064}]}, {"text": "Despite this usefulness, there are only a few corpora that can be used to develop and evaluate PI systems.", "labels": [], "entities": []}, {"text": "Moreover, such corpora are unavailable in many languages other than English.", "labels": [], "entities": []}, {"text": "This is because manual paraphrase generation tends to cost a lot.", "labels": [], "entities": [{"text": "manual paraphrase generation", "start_pos": 16, "end_pos": 44, "type": "TASK", "confidence": 0.6589905718962351}]}, {"text": "Furthermore, unlike a bilingual parallel corpus for machine translation, a monolingual parallel corpus for PI cannot be spontaneously built.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.7304930984973907}]}, {"text": "Even though some paraphrase corpora are available, there are some limitations on them.", "labels": [], "entities": []}, {"text": "For example, the Microsoft Research Paraphrase Corpus (MSRP)) is a standardized corpus in English for the PI task.", "labels": [], "entities": [{"text": "Microsoft Research Paraphrase Corpus (MSRP))", "start_pos": 17, "end_pos": 61, "type": "DATASET", "confidence": 0.7483134610312325}, {"text": "PI task", "start_pos": 106, "end_pos": 113, "type": "TASK", "confidence": 0.8689052164554596}]}, {"text": "However, as pointed out, MSRP collects candidate pairs using short edit distance, but this approach is limited to collecting positive instances with a low word overlap rate (WOR) (non-trivial positive instances, hereafter) . In contrast, the Twitter Paraphrase Corpus (TPC) () comprises short noisy user-generated texts; hence, it is difficult to acquire negative instances with a high WOR (non-trivial negative instances, hereafter) . To develop a more robust PI model, it is important to collect both \"non-trivial\" positive and negative instances for the evaluation corpus.", "labels": [], "entities": [{"text": "word overlap rate (WOR)", "start_pos": 155, "end_pos": 178, "type": "METRIC", "confidence": 0.8886953890323639}]}, {"text": "To create a useful evaluation corpus, we propose a novel paraphrase acquisition method that has two viewpoints of balancing the corpus: positive/negative and trivial/non-trivial.", "labels": [], "entities": [{"text": "paraphrase acquisition", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.7062557339668274}]}, {"text": "To balance between positive and negative, our method has a machine translation part collecting mainly positive instances and a random extraction part collecting negative instances.", "labels": [], "entities": []}, {"text": "In the machine translation part, we generate candidate sentence pairs using multiple machine translation systems.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 7, "end_pos": 26, "type": "TASK", "confidence": 0.7604725360870361}]}, {"text": "In the random extraction part, we extract candidate sentence pairs from a monolingual corpus.", "labels": [], "entities": []}, {"text": "To collect both trivial and non-trivial instances, we sample candidate pairs using WOR.", "labels": [], "entities": []}, {"text": "Finally, annotators judge whether the candidate pairs are paraphrases.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the Japanese PI task and build a monolingual parallel corpus for its evaluation as there is no Japanese sentential paraphrase corpus available.", "labels": [], "entities": []}, {"text": "As shows, we use phrase-based machine translation (PBMT) and neural machine translation (NMT) to generate two different Japanese sentences from one English sentence.", "labels": [], "entities": [{"text": "phrase-based machine translation", "start_pos": 17, "end_pos": 49, "type": "TASK", "confidence": 0.6230831245581309}, {"text": "neural machine translation", "start_pos": 61, "end_pos": 87, "type": "TASK", "confidence": 0.7567193905512491}]}, {"text": "We expect the two systems provide widely different translations with regard to surface form such as lexical variation and word order difference because they are known to have different characteristics (; for instance, PBMT produces more literal translations, whereas NMT produces more fluent translations.", "labels": [], "entities": []}, {"text": "We believe that when the translation succeeds, the two Japanese sentences have the same meaning but different expressions, which is a positive instance.", "labels": [], "entities": []}, {"text": "On the other hand, translated candidates can be negative instances when they include fluent mistranslations.", "labels": [], "entities": []}, {"text": "This occurs since adequacy is not checked during an annotation phase.", "labels": [], "entities": []}, {"text": "Thus, we can also acquire some negative instances in this manner.", "labels": [], "entities": []}, {"text": "To actively acquire negative instances, we use Wikipedia to randomly extract sentences.", "labels": [], "entities": []}, {"text": "In general, it is rare for sentences to become paraphrase when sentence pairs are collected randomly, so it is effective to acquire negative instances in this regard.", "labels": [], "entities": []}, {"text": "Our contributions are summarized as follows: \u2022 Generated paraphrases using multiple machine translation systems for the first time \u2022 Adjusted fora balance from two viewpoints: positive/negative and trivial/non-trivial \u2022 Released 3 the first evaluation corpus for the Japanese PI task", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Statistics on our corpus. The number inside ( ) of Negative column is the number of instances  extracted from Wikipedia and the other is that of machine-translated instances.", "labels": [], "entities": []}, {"text": " Table 3: The result of corpus analysis.", "labels": [], "entities": [{"text": "corpus analysis", "start_pos": 24, "end_pos": 39, "type": "TASK", "confidence": 0.7910818755626678}]}, {"text": " Table 4: Examples from our corpus. Bold words/phrases were replaced.", "labels": [], "entities": []}]}