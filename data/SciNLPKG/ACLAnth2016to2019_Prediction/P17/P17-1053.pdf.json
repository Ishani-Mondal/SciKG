{"title": [{"text": "Improved Neural Relation Detection for Knowledge Base Question Answering", "labels": [], "entities": [{"text": "Improved Neural Relation Detection", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.875212088227272}, {"text": "Knowledge Base Question Answering", "start_pos": 39, "end_pos": 72, "type": "TASK", "confidence": 0.5662378519773483}]}], "abstractContent": [{"text": "Relation detection is a core component of many NLP applications including Knowledge Base Question Answering (KBQA).", "labels": [], "entities": [{"text": "Relation detection", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.97037273645401}, {"text": "Knowledge Base Question Answering (KBQA)", "start_pos": 74, "end_pos": 114, "type": "TASK", "confidence": 0.7647192478179932}]}, {"text": "In this paper, we propose a hierarchical recurrent neural network enhanced by residual learning which detects KB relations given an input question.", "labels": [], "entities": []}, {"text": "Our method uses deep residual bidirectional LSTMs to compare questions and relation names via different levels of abstraction.", "labels": [], "entities": []}, {"text": "Additionally, we propose a simple KBQA system that integrates entity linking and our proposed relation detector to make the two components enhance each other.", "labels": [], "entities": []}, {"text": "Our experimental results show that our approach not only achieves outstanding relation detection performance, but more importantly, it helps our KBQA system achieve state-of-the-art accuracy for both single-relation (SimpleQuestions) and multi-relation (WebQSP) QA benchmarks .", "labels": [], "entities": [{"text": "relation detection", "start_pos": 78, "end_pos": 96, "type": "TASK", "confidence": 0.8093903958797455}, {"text": "accuracy", "start_pos": 182, "end_pos": 190, "type": "METRIC", "confidence": 0.9986999034881592}]}], "introductionContent": [{"text": "Knowledge Base Question Answering (KBQA) systems answer questions by obtaining information from KB tuples.", "labels": [], "entities": [{"text": "Knowledge Base Question Answering (KBQA)", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.6795881858893803}]}, {"text": "For an input question, these systems typically generate a KB query, which can be executed to retrieve the answers from a KB.", "labels": [], "entities": []}, {"text": "illustrates the process used to parse two sample questions in a KBQA system: (a) a single-relation question, which can be answered with a single <head-entity, relation, tail-entity> KB tuple; and (b) a more complex case, where some constraints need to be handled for multiple entities in the question.", "labels": [], "entities": []}, {"text": "The KBQA system in the figure performs two key tasks: (1) entity linking, which links n-grams in questions to KB entities, and (2) relation detection, which identifies the KB relation(s) a question refers to.", "labels": [], "entities": [{"text": "entity linking", "start_pos": 58, "end_pos": 72, "type": "TASK", "confidence": 0.7265845835208893}, {"text": "relation detection", "start_pos": 131, "end_pos": 149, "type": "TASK", "confidence": 0.769851416349411}]}, {"text": "The main focus of this work is to improve the relation detection subtask and further explore how it can contribute to the KBQA system.", "labels": [], "entities": [{"text": "relation detection", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.8703925311565399}]}, {"text": "Although general relation detection 1 methods are well studied in the NLP community, such studies usually do not take the end task of KBQA into consideration.", "labels": [], "entities": [{"text": "relation detection 1", "start_pos": 17, "end_pos": 37, "type": "TASK", "confidence": 0.7999854485193888}]}, {"text": "As a result, there is a significant gap between general relation detection studies and KB-specific relation detection.", "labels": [], "entities": [{"text": "general relation detection", "start_pos": 48, "end_pos": 74, "type": "TASK", "confidence": 0.6578266819318136}, {"text": "KB-specific relation detection", "start_pos": 87, "end_pos": 117, "type": "TASK", "confidence": 0.7214264273643494}]}, {"text": "First, inmost general relation detection tasks, the number of target relations is limited, normally smaller than 100.", "labels": [], "entities": [{"text": "relation detection tasks", "start_pos": 22, "end_pos": 46, "type": "TASK", "confidence": 0.8499950766563416}]}, {"text": "In contrast, in KBQA even a small KB, like Freebase2M (, contains more than 6,000 relation types.", "labels": [], "entities": []}, {"text": "Second, relation detection for KBQA often becomes a zero-shot learning task, since some test instances may have unseen relations in the training data.", "labels": [], "entities": [{"text": "relation detection", "start_pos": 8, "end_pos": 26, "type": "TASK", "confidence": 0.9182956516742706}]}, {"text": "For example, the SimpleQuestions () data set has 14% of the golden test relations not observed in golden training tuples.", "labels": [], "entities": [{"text": "SimpleQuestions () data set", "start_pos": 17, "end_pos": 44, "type": "DATASET", "confidence": 0.7492236271500587}]}, {"text": "Third, as shown in(b), for some KBQA tasks like WebQuestions (, we need to predict a chain of relations instead of a single relation.", "labels": [], "entities": []}, {"text": "This increases the number of target relation types and the sizes of candidate relation pools, further increasing the difficulty of KB relation detection.", "labels": [], "entities": [{"text": "KB relation detection", "start_pos": 131, "end_pos": 152, "type": "TASK", "confidence": 0.8518182436625162}]}, {"text": "Owing to these reasons, KB relation detection is significantly more challenging compared to general relation detection tasks.", "labels": [], "entities": [{"text": "KB relation detection", "start_pos": 24, "end_pos": 45, "type": "TASK", "confidence": 0.8898394306500753}, {"text": "relation detection", "start_pos": 100, "end_pos": 118, "type": "TASK", "confidence": 0.8039962351322174}]}, {"text": "This paper improves KB relation detection to cope with the problems mentioned above.", "labels": [], "entities": [{"text": "KB relation detection", "start_pos": 20, "end_pos": 41, "type": "TASK", "confidence": 0.8991642395655314}]}, {"text": "First, in order to deal with the unseen relations, we propose to break the relation names into word sequences for question-relation matching.", "labels": [], "entities": [{"text": "question-relation matching", "start_pos": 114, "end_pos": 140, "type": "TASK", "confidence": 0.7128712981939316}]}, {"text": "entity linking and then detect the relation asked by the question with relation detection (from all relations connecting the topic entity).", "labels": [], "entities": [{"text": "relation detection", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.67512346804142}]}, {"text": "Based on the detected entity and relation, we form a query to search the KB for the correct answer \"Love Will Find a Way\".", "labels": [], "entities": []}, {"text": "(b) A more complex question containing two entities.", "labels": [], "entities": []}, {"text": "By using \"Grant Show\" as the topic entity, we could detect a chain of relations \"starring roles-series\" pointing to the answer.", "labels": [], "entities": [{"text": "Grant Show\"", "start_pos": 10, "end_pos": 21, "type": "DATASET", "confidence": 0.9595010876655579}]}, {"text": "An additional constraint detection takes the other entity \"2008\" as a constraint, to filter the correct answer \"SwingTown\" from all candidates found by the topic entity and relation. that original relation names can sometimes help to match longer question contexts, we propose to build both relation-level and word-level relation representations.", "labels": [], "entities": []}, {"text": "Third, we use deep bidirectional LSTMs (BiLSTMs) to learn different levels of question representations in order to match the different levels of relation information.", "labels": [], "entities": []}, {"text": "Finally, we propose a residual learning method for sequence matching, which makes the model training easier and results in more abstract (deeper) question representations, thus improves hierarchical matching.", "labels": [], "entities": [{"text": "sequence matching", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.7441040277481079}]}, {"text": "In order to assess how the proposed improved relation detection could benefit the KBQA end task, we also propose a simple KBQA implementation composed of two-step relation detection.", "labels": [], "entities": [{"text": "relation detection", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.8521176278591156}, {"text": "relation detection", "start_pos": 163, "end_pos": 181, "type": "TASK", "confidence": 0.7339591085910797}]}, {"text": "Given an input question and a set of candidate entities retrieved by an entity linker based on the question, our proposed relation detection model plays a key role in the KBQA process: (1) Re-ranking the entity candidates according to whether they connect to high confident relations detected from the raw question text by the relation detection model.", "labels": [], "entities": [{"text": "relation detection", "start_pos": 122, "end_pos": 140, "type": "TASK", "confidence": 0.7115084379911423}]}, {"text": "This step is important to deal with the ambiguities normally present in entity linking results.", "labels": [], "entities": []}, {"text": "(2) Finding the core relation (chains) for each topic entity 2 selection from a much smaller candidate entity set after re-ranking.", "labels": [], "entities": []}, {"text": "The above steps are followed by an optional constraint detection step, when the question cannot be answered by single relations (e.g., multiple entities in the question).", "labels": [], "entities": [{"text": "constraint detection", "start_pos": 44, "end_pos": 64, "type": "TASK", "confidence": 0.7599614858627319}]}, {"text": "Finally the highest scored query from the above steps is used to query the KB for answers.", "labels": [], "entities": []}, {"text": "Our main contributions include: (i) An improved relation detection model by hierarchical matching between questions and relations with residual learning; (ii) We demonstrate that the improved relation detector enables our simple KBQA system to achieve state-of-the-art results on both single-relation and multi-relation KBQA tasks.", "labels": [], "entities": [{"text": "relation detection", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.7958998680114746}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Accuracy on the SimpleQuestions and WebQSP relation detection tasks (test sets). The top  shows performance of baselines. On the bottom we give the results of our proposed model together with  the ablation tests.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9914419054985046}, {"text": "WebQSP relation detection", "start_pos": 46, "end_pos": 71, "type": "TASK", "confidence": 0.796019991238912}]}, {"text": " Table 3: KBQA results on SimpleQuestions (SQ)  and WebQSP (WQ) test sets. The numbers in  green color are directly comparable to our results  since we start with the same entity linking results.", "labels": [], "entities": [{"text": "WebQSP (WQ) test sets", "start_pos": 52, "end_pos": 73, "type": "DATASET", "confidence": 0.8342043856779734}]}]}