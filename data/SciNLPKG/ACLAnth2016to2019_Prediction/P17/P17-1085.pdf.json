{"title": [{"text": "Going out on a limb: Joint Extraction of Entity Mentions and Relations without Dependency Trees", "labels": [], "entities": [{"text": "Joint Extraction of Entity Mentions", "start_pos": 21, "end_pos": 56, "type": "TASK", "confidence": 0.726141232252121}]}], "abstractContent": [{"text": "We present a novel attention-based recurrent neural network for joint extraction of entity mentions and relations.", "labels": [], "entities": [{"text": "joint extraction of entity mentions and relations", "start_pos": 64, "end_pos": 113, "type": "TASK", "confidence": 0.8542271511895316}]}, {"text": "We show that attention along with long short term memory (LSTM) network can extract semantic relations between entity mentions without having access to dependency trees.", "labels": [], "entities": []}, {"text": "Experiments on Automatic Content Extraction (ACE) corpora show that our model significantly outperforms feature-based joint model by Li and Ji (2014).", "labels": [], "entities": [{"text": "Automatic Content Extraction (ACE)", "start_pos": 15, "end_pos": 49, "type": "TASK", "confidence": 0.7564289967219034}]}, {"text": "We also compare our model with an end-to-end tree-based LSTM model (SPTree) by Miwa and Bansal (2016) and show that our model performs within 1% on entity mentions and 2% on relations.", "labels": [], "entities": []}, {"text": "Our fine-grained analysis also shows that our model performs significantly better on AGENT-ARTIFACT relations, while SPTree performs better on PHYSICAL and PART-WHOLE relations.", "labels": [], "entities": [{"text": "AGENT-ARTIFACT", "start_pos": 85, "end_pos": 99, "type": "METRIC", "confidence": 0.7283433675765991}]}], "introductionContent": [{"text": "Extraction of entities and their relations from text belongs to a very well-studied family of structured prediction tasks in NLP.", "labels": [], "entities": [{"text": "Extraction of entities and their relations from text", "start_pos": 0, "end_pos": 52, "type": "TASK", "confidence": 0.7606992870569229}]}, {"text": "There are several NLP tasks such as fine-grained opinion mining (), semantic role labeling (), etc., which have a similar structure; thus making it an important and a challenging task.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 49, "end_pos": 63, "type": "TASK", "confidence": 0.7221279740333557}, {"text": "semantic role labeling", "start_pos": 68, "end_pos": 90, "type": "TASK", "confidence": 0.6923739115397135}]}, {"text": "Several methods have been proposed for entity mention and relation extraction at the sentencelevel.", "labels": [], "entities": [{"text": "entity mention and relation extraction", "start_pos": 39, "end_pos": 77, "type": "TASK", "confidence": 0.6733391344547272}]}, {"text": "These can be broadly categorized into -1) pipeline models that treat the identification of entity mentions ( and relation classification () as two separate tasks; and 2) joint models, also the more recent, which simultaneously identify the entity mention and relations ().", "labels": [], "entities": [{"text": "relation classification", "start_pos": 113, "end_pos": 136, "type": "TASK", "confidence": 0.6851971745491028}]}, {"text": "Joint models have been argued to perform better than the pipeline models as knowledge of the typed relation can increase the confidence of the model on entity extraction and vice versa.", "labels": [], "entities": [{"text": "entity extraction", "start_pos": 152, "end_pos": 169, "type": "TASK", "confidence": 0.7465040981769562}]}, {"text": "Recurrent networks (RNNs)) have recently become very popular for sequence tagging tasks such as entity extraction that involves a set of contiguous tokens.", "labels": [], "entities": [{"text": "sequence tagging", "start_pos": 65, "end_pos": 81, "type": "TASK", "confidence": 0.7132967114448547}, {"text": "entity extraction", "start_pos": 96, "end_pos": 113, "type": "TASK", "confidence": 0.7541955709457397}]}, {"text": "However, their ability to identify relations between non-adjacent tokens in a sequence, e.g., the head nouns of two entities, is less explored.", "labels": [], "entities": []}, {"text": "For these tasks, RNNs that make use of tree structures have been deemed more suitable., for example, propose an RNN comprised of a sequencebased long short term memory (LSTM) for entity identification and a separate tree-based dependency LSTM layer for relation classification using shared parameters between the two components.", "labels": [], "entities": [{"text": "entity identification", "start_pos": 179, "end_pos": 200, "type": "TASK", "confidence": 0.7540281116962433}, {"text": "relation classification", "start_pos": 253, "end_pos": 276, "type": "TASK", "confidence": 0.7714612483978271}]}, {"text": "As a result, their model depends critically on access to dependency trees, restricting it to sentencelevel extraction and to languages for which (good) dependency parsers exist.", "labels": [], "entities": [{"text": "sentencelevel extraction", "start_pos": 93, "end_pos": 117, "type": "TASK", "confidence": 0.7573861479759216}]}, {"text": "Also, their model does not jointly extract entities and relations; they first extract all entities and then perform relation classification on all pairs of entities in a sentence.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 116, "end_pos": 139, "type": "TASK", "confidence": 0.7237745225429535}]}, {"text": "In our previous work, we address the same task in an opinion extraction context.", "labels": [], "entities": [{"text": "opinion extraction context", "start_pos": 53, "end_pos": 79, "type": "TASK", "confidence": 0.8086226185162863}]}, {"text": "Our LSTM-based formulation explicitly encodes distance between the head of entities into opinion relation labels.", "labels": [], "entities": []}, {"text": "The output space of our model is quadratic in size of the entity and relation label set and we do not specifically identify the relation type.", "labels": [], "entities": []}, {"text": "Unfortunately, adding relation type makes the output label space very sparse, making it difficult for the model to learn.", "labels": [], "entities": []}, {"text": "In this paper, we propose a novel RNN-based model for the joint extraction of entity mentions and relations.", "labels": [], "entities": [{"text": "joint extraction of entity mentions and relations", "start_pos": 58, "end_pos": 107, "type": "TASK", "confidence": 0.8257968085152763}]}, {"text": "Unlike other models, our model does not depend on any dependency tree information.", "labels": [], "entities": []}, {"text": "Our RNN-based model is a multi-layer bidirectional LSTM over a sequence.", "labels": [], "entities": []}, {"text": "We encode the output sequence from left-to-right.", "labels": [], "entities": []}, {"text": "At each time step, we use an attention-like model on the previously decoded time steps, to identify the tokens in a specified relation with the current token.", "labels": [], "entities": []}, {"text": "We also add an additional layer to our network to encode the output sequence from right-to-left and find significant improvement on the performance of relation identification using bi-directional encoding.", "labels": [], "entities": [{"text": "relation identification", "start_pos": 151, "end_pos": 174, "type": "TASK", "confidence": 0.8778270483016968}]}, {"text": "Our model significantly outperforms the feature-based structured perceptron model of, showing improvements on both entity and relation extraction on the ACE05 dataset.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 126, "end_pos": 145, "type": "TASK", "confidence": 0.7104330211877823}, {"text": "ACE05 dataset", "start_pos": 153, "end_pos": 166, "type": "DATASET", "confidence": 0.9845422506332397}]}, {"text": "In comparison to the dependency treebased LSTM model of, our model performs within 1% on entities and 2% on relations on ACE05 dataset.", "labels": [], "entities": [{"text": "ACE05 dataset", "start_pos": 121, "end_pos": 134, "type": "DATASET", "confidence": 0.9796627461910248}]}, {"text": "We also find that our model performs significantly better than their tree-based model on the AGENT-ARTIFACT relation, while their tree-based model performs better on PHYSICAL and PART-WHOLE relations; the two models perform comparably on all other relation types.", "labels": [], "entities": [{"text": "AGENT-ARTIFACT", "start_pos": 93, "end_pos": 107, "type": "METRIC", "confidence": 0.879112720489502}]}, {"text": "The very competitive performance of our non-tree-based model bodes well for relation extraction of non-adjacent entities in low-resource languages that lack good parsers.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 76, "end_pos": 95, "type": "TASK", "confidence": 0.8663245141506195}]}, {"text": "In the sections that follow, we describe related work (Section 2); our bi-directional LSTM model with attention (Section 3); the training (Section 4); the experiments on ACE dataset (Section 5); results (Section 6); error analysis (Section 7) and conclusion (Section 8).", "labels": [], "entities": [{"text": "ACE dataset", "start_pos": 170, "end_pos": 181, "type": "DATASET", "confidence": 0.9547223746776581}, {"text": "conclusion", "start_pos": 247, "end_pos": 257, "type": "METRIC", "confidence": 0.9848011136054993}]}], "datasetContent": [{"text": "In order to compare our system with the previous systems, we report micro F1-scores, Precision and Recall on both entities and relations similar to and.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.8977634310722351}, {"text": "Precision", "start_pos": 85, "end_pos": 94, "type": "METRIC", "confidence": 0.9994534850120544}, {"text": "Recall", "start_pos": 99, "end_pos": 105, "type": "METRIC", "confidence": 0.9980769157409668}]}, {"text": "An entity is considered correct if we can identify its head and the entity type correctly.", "labels": [], "entities": []}, {"text": "A relation is considered correct if we can identify the head of the argument entities and also the relation type.", "labels": [], "entities": []}, {"text": "We also report a combined score when both argument entities and relations are correct.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance on ACE05 test dataset. The dashed (\"-\") performance numbers were missing  in the original paper", "labels": [], "entities": [{"text": "ACE05 test dataset", "start_pos": 25, "end_pos": 43, "type": "DATASET", "confidence": 0.9619043866793314}]}, {"text": " Table 2: Performance of different encoding methods on ACE05 dataset.", "labels": [], "entities": [{"text": "ACE05 dataset", "start_pos": 55, "end_pos": 68, "type": "DATASET", "confidence": 0.9844577312469482}]}, {"text": " Table 3: Performance on ACE04 test dataset. The dashed (\"-\") performance numbers were missing in  the original paper (Miwa and Bansal, 2016).", "labels": [], "entities": [{"text": "ACE04 test dataset", "start_pos": 25, "end_pos": 43, "type": "DATASET", "confidence": 0.958147386709849}]}, {"text": " Table 4: Performance on different relation types  in ACE05 test dataset. Numbers in the bracket de- note the number of relations of each relation type  in the test set.", "labels": [], "entities": [{"text": "ACE05 test dataset", "start_pos": 54, "end_pos": 72, "type": "DATASET", "confidence": 0.9481309056282043}]}]}