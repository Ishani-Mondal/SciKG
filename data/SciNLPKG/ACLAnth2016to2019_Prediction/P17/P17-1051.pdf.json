{"title": [{"text": "MORSE: Semantic-ally Drive-n MORpheme SEgment-er", "labels": [], "entities": [{"text": "SEgment-er", "start_pos": 38, "end_pos": 48, "type": "TASK", "confidence": 0.5110580325126648}]}], "abstractContent": [{"text": "In this paper we present a novel framework for morpheme segmentation which uses the morpho-syntactic regularities preserved byword representations, in addition to orthographic features, to segment words into morphemes.", "labels": [], "entities": [{"text": "morpheme segmentation", "start_pos": 47, "end_pos": 68, "type": "TASK", "confidence": 0.7543470859527588}]}, {"text": "This framework is the first to consider vocabulary-wide syntactico-semantic information for this task.", "labels": [], "entities": []}, {"text": "We also analyze the deficiencies of available benchmarking datasets and introduce our own dataset that was created on the basis of compositionality.", "labels": [], "entities": []}, {"text": "We validate our algorithm across different datasets and languages and present new state-of-the-art results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Morpheme segmentation is a core natural language processing (NLP) task used as an integral component in related-fields such as information retrieval (IR), automatic speech recognition (ASR)), and machine translation (MT)).", "labels": [], "entities": [{"text": "Morpheme segmentation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8015850484371185}, {"text": "information retrieval (IR)", "start_pos": 127, "end_pos": 153, "type": "TASK", "confidence": 0.8429443120956421}, {"text": "automatic speech recognition (ASR))", "start_pos": 155, "end_pos": 190, "type": "TASK", "confidence": 0.7976216375827789}, {"text": "machine translation (MT))", "start_pos": 196, "end_pos": 221, "type": "TASK", "confidence": 0.853296947479248}]}, {"text": "Most previous works have relied solely on orthographic features, neglecting the underlying semantic information.", "labels": [], "entities": []}, {"text": "This has led to an over-segmentation of words because a change of the surface form pattern is a necessary but insufficient indication of a morphological change.", "labels": [], "entities": []}, {"text": "For example, the surface form of \"freshman\", hints that it should be segmented to \"fresh-man\", although \"freshman\" does not describe semantically the compositional meaning of \"fresh\" and \"man\".", "labels": [], "entities": []}, {"text": "To compensate for this lack of semantic knowledge, previous works;) have incorporated semantic knowledge locally by checking the semantic relatedness of possibly morphologically related pair of words.", "labels": [], "entities": []}, {"text": "check for semantic relatedness using cosine similarity in word representations (.", "labels": [], "entities": []}, {"text": "A limitation of such an approach is the inherent \"sample noise\" in specific word representations (exacerbated in the case of rare words).", "labels": [], "entities": []}, {"text": "Moreover, limitation to local comparison enforces modeling morphological relations via semantic relatedness, although it has been shown that difference vectors model morphological relations more accurately ().", "labels": [], "entities": []}, {"text": "To address this issue, we introduce anew framework (MORSE), the first to bring semantics into morpheme segmentation both on a local and a vocabulary-wide level.", "labels": [], "entities": [{"text": "MORSE", "start_pos": 52, "end_pos": 57, "type": "METRIC", "confidence": 0.6297269463539124}, {"text": "morpheme segmentation", "start_pos": 94, "end_pos": 115, "type": "TASK", "confidence": 0.7586354315280914}]}, {"text": "That is, when checking for the morphological relation between two words, we not only check for the semantic relatedness of the pair at hand (local), but also check if the difference vectors of pairs showing similar orthographic change are consistent (vocabulary-wide).", "labels": [], "entities": []}, {"text": "In summary, MORSE clusters pairs of words which only vary by an affix; for example, pairs such as (\"quick\", \"quickly\") and (\"hopeful\", \"hopefully\") get clustered together.", "labels": [], "entities": []}, {"text": "To verify the cluster of a specific affix from a semantic corpuswide standpoint, we check for the consistency of the difference vectors ().", "labels": [], "entities": [{"text": "consistency", "start_pos": 98, "end_pos": 109, "type": "METRIC", "confidence": 0.9873623847961426}]}, {"text": "To evaluate it from an orthographic corpus-wide perspective, we check for the size of each cluster of an affix.", "labels": [], "entities": []}, {"text": "To evaluate each pair in a cluster locally from a semantic standpoint, we check if a pair of words in a valid affix cluster are morphologically related by checking if its difference vector is consistent with other members in the cluster and if the words in the pair are semantically related (i.e. close in the vector space).", "labels": [], "entities": []}, {"text": "The reason for local evaluations is exemplified by (\"on\",\"only\") which belongs to the cluster of a valid affix (\"ly\"), although they are not (obviously) morphologically related.", "labels": [], "entities": []}, {"text": "We would expect such a pair to fail the last two local evaluation methods.", "labels": [], "entities": []}, {"text": "Our proposed segmentation algorithm is evaluated using benchmarking datasets from the Morpho Challenge (MC) for multiple languages and a newly introduced dataset for English which compensates for lack of discriminating capabilities in the MC dataset.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 13, "end_pos": 25, "type": "TASK", "confidence": 0.9710419178009033}, {"text": "Morpho Challenge (MC)", "start_pos": 86, "end_pos": 107, "type": "DATASET", "confidence": 0.7551864147186279}]}, {"text": "Experiments reveal that our proposed framework not only outperforms the widely used approach, but also performs better than published state-of-the-art results.", "labels": [], "entities": []}, {"text": "The central contribution of this work is a novel framework that performs morpheme segmentation resulting in new state-of-the-art results.", "labels": [], "entities": [{"text": "morpheme segmentation", "start_pos": 73, "end_pos": 94, "type": "TASK", "confidence": 0.7318595945835114}]}, {"text": "To the best of our knowledge this is the first unsupervised approach to consider the vocabulary-wide semantic knowledge of words and their affixes in addition to relying on their surface forms.", "labels": [], "entities": []}, {"text": "Moreover we point out the deficiencies in the MC datasets with respect to the compositionality of morphemes and introduce our own dataset free of these deficiencies.", "labels": [], "entities": [{"text": "MC datasets", "start_pos": 46, "end_pos": 57, "type": "DATASET", "confidence": 0.820574551820755}]}], "datasetContent": [{"text": "We conduct a variety of experiments to assess the performance of MORSE, and compare it with prior works.", "labels": [], "entities": [{"text": "MORSE", "start_pos": 65, "end_pos": 70, "type": "DATASET", "confidence": 0.4836692214012146}]}, {"text": "First, the performance is assessed intrinsically on the task of morpheme segmentation and against the most widely used morpheme segmenter: Morfessor 2.0.", "labels": [], "entities": [{"text": "morpheme segmentation", "start_pos": 64, "end_pos": 85, "type": "TASK", "confidence": 0.780469685792923}]}, {"text": "We evaluate the performance across three languages of varying morphology levels: English, Turkish, Finnish, with Finnish being the richest in morphology and English being the poorest.", "labels": [], "entities": []}, {"text": "Second, we show the inadequacies of benchmarking gold datasets for this task and describe anew dataset that we create to address the inadequacy.", "labels": [], "entities": []}, {"text": "Third, in order to highlight the effect of including semantic information, we compare MORSE against Morfessor on a set of words which should not be segmented from a semantic perspective although orthographically they seem to be segmentable (such as \"freshman\").", "labels": [], "entities": []}, {"text": "In all of our experiments (unless specified otherwise), we report precision and recall (and corresponding F1 scores) with locations of morpheme boundaries being considered positives and the rest of the locations considered negatives.", "labels": [], "entities": [{"text": "precision", "start_pos": 66, "end_pos": 75, "type": "METRIC", "confidence": 0.9987447261810303}, {"text": "recall", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.9991804957389832}, {"text": "F1 scores", "start_pos": 106, "end_pos": 115, "type": "METRIC", "confidence": 0.9866654872894287}]}, {"text": "It should be noted that we disregard starting and ending positions of words, since they form trivial boundaries (Virpioja et al., 2011).", "labels": [], "entities": []}, {"text": "As demonstrated in, MORSE performs better than Mofessor on English and Turkish, and worse on Finnish.", "labels": [], "entities": [{"text": "MORSE", "start_pos": 20, "end_pos": 25, "type": "METRIC", "confidence": 0.8331882953643799}]}, {"text": "Considering English first, using MORSE instead of Morfessor, resulted in a 6% absolute increase in F1 scores.", "labels": [], "entities": [{"text": "MORSE", "start_pos": 33, "end_pos": 38, "type": "METRIC", "confidence": 0.990533709526062}, {"text": "Morfessor", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.8426738977432251}, {"text": "F1 scores", "start_pos": 99, "end_pos": 108, "type": "METRIC", "confidence": 0.9840661287307739}]}, {"text": "This supports our claim for the need of semantic cues in morpheme segmentation, and also validates the method used in this paper.", "labels": [], "entities": [{"text": "morpheme segmentation", "start_pos": 57, "end_pos": 78, "type": "TASK", "confidence": 0.80720654129982}]}, {"text": "Since English is a less systematic language in terms of the orthographic structure of words, semantic cues are of greater need, and hence a system which relies on semantic cues is expected to perform better; indeed this is the case.", "labels": [], "entities": []}, {"text": "Similarly, MORSE performs better on Turkish with a 7% absolute margin in terms of F1 score.", "labels": [], "entities": [{"text": "MORSE", "start_pos": 11, "end_pos": 16, "type": "METRIC", "confidence": 0.7860978841781616}, {"text": "Turkish", "start_pos": 36, "end_pos": 43, "type": "DATASET", "confidence": 0.9302644729614258}, {"text": "absolute margin", "start_pos": 54, "end_pos": 69, "type": "METRIC", "confidence": 0.9417040646076202}, {"text": "F1 score", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.9822657108306885}]}, {"text": "On the other hand, Morfessor surpasses MORSE in performance on Finnish by a large margin as well, especially in terms of recall.", "labels": [], "entities": [{"text": "Morfessor", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.762488842010498}, {"text": "MORSE", "start_pos": 39, "end_pos": 44, "type": "METRIC", "confidence": 0.9875768423080444}, {"text": "Finnish", "start_pos": 63, "end_pos": 70, "type": "DATASET", "confidence": 0.8832741379737854}, {"text": "recall", "start_pos": 121, "end_pos": 127, "type": "METRIC", "confidence": 0.9982288479804993}]}, {"text": "The performance of MORSE and Morfessor on SD17 is shown in.", "labels": [], "entities": [{"text": "MORSE", "start_pos": 19, "end_pos": 24, "type": "METRIC", "confidence": 0.6570201516151428}]}, {"text": "The use of MC data (which does not adhere to the compositionality principle) to tune MORSE to be evaluated on SD17 (which does adhere to the compositionality principle) is not optimal.", "labels": [], "entities": []}, {"text": "Thus, we evaluate MORSE on SD17 using 5-fold cross validation, where 80% of the dataset is used to tune and 20% is used to evaluate.", "labels": [], "entities": [{"text": "MORSE", "start_pos": 18, "end_pos": 23, "type": "METRIC", "confidence": 0.6527374386787415}]}, {"text": "Precision, Recall, and F1 scores are averaged and reported in using the label MORSE-CV.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9928230047225952}, {"text": "Recall", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.9771404266357422}, {"text": "F1", "start_pos": 23, "end_pos": 25, "type": "METRIC", "confidence": 0.9985565543174744}, {"text": "MORSE-CV", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.5591405034065247}]}, {"text": "Based on the results in, we make the following observations.", "labels": [], "entities": []}, {"text": "Comparing MORSE-CV to MORSE reflects the fundamental difference between SD17 and MC datasets.", "labels": [], "entities": [{"text": "MC datasets", "start_pos": 81, "end_pos": 92, "type": "DATASET", "confidence": 0.6828004717826843}]}, {"text": "Knowing the basis of construction of SD17 and the fundamental weaknesses in MC datasets, we attribute the performance increase to the lack of compositionality in MC dataset.", "labels": [], "entities": [{"text": "MC datasets", "start_pos": 76, "end_pos": 87, "type": "DATASET", "confidence": 0.6827647984027863}, {"text": "MC dataset", "start_pos": 162, "end_pos": 172, "type": "DATASET", "confidence": 0.6979240328073502}]}, {"text": "Comparing MORSE-CV to Morfessor, we observe a significant jump in performance (an increase of 24%).", "labels": [], "entities": [{"text": "MORSE-CV", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.8244624733924866}, {"text": "Morfessor", "start_pos": 22, "end_pos": 31, "type": "DATASET", "confidence": 0.5253335237503052}]}, {"text": "In comparison, the increase on the MC dataset (6%) shows that the Morpho Challenge dataset underestimates the performance gap between Morfessor and MORSE due its inherent weaknesses.", "labels": [], "entities": [{"text": "MC dataset", "start_pos": 35, "end_pos": 45, "type": "DATASET", "confidence": 0.9176592528820038}, {"text": "Morpho Challenge dataset", "start_pos": 66, "end_pos": 90, "type": "DATASET", "confidence": 0.929776668548584}, {"text": "Morfessor", "start_pos": 134, "end_pos": 143, "type": "DATASET", "confidence": 0.894245445728302}, {"text": "MORSE", "start_pos": 148, "end_pos": 153, "type": "DATASET", "confidence": 0.7887261509895325}]}, {"text": "Since MORSE is equipped with the capability to retrieve full morphemes even when not present   in full orthographically, a capability that Morfessor lacks, we evaluated both systems on the canonical version of SD17.", "labels": [], "entities": [{"text": "MORSE", "start_pos": 6, "end_pos": 11, "type": "DATASET", "confidence": 0.7592800259590149}, {"text": "Morfessor", "start_pos": 139, "end_pos": 148, "type": "DATASET", "confidence": 0.9108145833015442}]}, {"text": "The results are reported in.", "labels": [], "entities": []}, {"text": "We notice that evaluating on the canonical form of SD17 gives a further edge for MORSE over Morfessor.", "labels": [], "entities": [{"text": "MORSE", "start_pos": 81, "end_pos": 86, "type": "METRIC", "confidence": 0.9167357683181763}, {"text": "Morfessor", "start_pos": 92, "end_pos": 101, "type": "DATASET", "confidence": 0.9328879714012146}]}, {"text": "For evaluation on the canonical version of SD17, we switch to morpheme-level evaluation instead of boundary-level as a more suitable method for Morfessor.", "labels": [], "entities": [{"text": "Morfessor", "start_pos": 144, "end_pos": 153, "type": "DATASET", "confidence": 0.8444739580154419}]}, {"text": "Morpheme-level evaluation is distinguished from boundary-level evaluation in that we evaluate the detection of morphemes instead of the boundary locations in the segmented word.", "labels": [], "entities": []}, {"text": "We next compare MORSE against published state-of-the-art results . As one can see in Table 7 MORSE significantly performs better than published state-of-the-art results, most notably () referred to as LLSM in the", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Morpho Challenge 2010 Dataset Sizes.", "labels": [], "entities": [{"text": "Morpho Challenge 2010 Dataset Sizes", "start_pos": 10, "end_pos": 45, "type": "DATASET", "confidence": 0.806572425365448}]}, {"text": " Table 3: Performance of MORSE on the MC dataset across three languages: English, Turkish, Finnish.", "labels": [], "entities": [{"text": "MORSE", "start_pos": 25, "end_pos": 30, "type": "METRIC", "confidence": 0.793556272983551}, {"text": "MC dataset", "start_pos": 38, "end_pos": 48, "type": "DATASET", "confidence": 0.7675615847110748}]}, {"text": " Table 5: Performance of MORSE against Morfes- sor on the non-canonical version of SD17", "labels": [], "entities": [{"text": "MORSE", "start_pos": 25, "end_pos": 30, "type": "METRIC", "confidence": 0.9359195828437805}]}, {"text": " Table 6: Performance of MORSE against Morfes- sor on the canonical version of SD17", "labels": [], "entities": [{"text": "MORSE", "start_pos": 25, "end_pos": 30, "type": "METRIC", "confidence": 0.925262451171875}, {"text": "Morfes- sor on the canonical version of SD17", "start_pos": 39, "end_pos": 83, "type": "DATASET", "confidence": 0.7920047574573092}]}, {"text": " Table 7: Performance of MORSE against pub- lished state-of-the-art results", "labels": [], "entities": [{"text": "MORSE", "start_pos": 25, "end_pos": 30, "type": "METRIC", "confidence": 0.7261650562286377}]}]}